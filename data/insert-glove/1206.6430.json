{"id": "1206.6430", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Variational Bayesian Inference with Stochastic Search", "abstract": "euro392 Mean - cityview field crostini variational cles inference arrack is a 816-822-1444 method for approximate Bayesian kacy posterior inference. 238.6 It approximates a full posterior 1,010 distribution with petherton a 78.21 factorized set biorefineries of distributions by maximizing a lower imagistic bound d'estaing on sanitize the 108.80 marginal pathfinders likelihood. 460-member This germs requires the 0745 ability juyuan to integrate carless a sum of terms in the trafigura log joint dorne likelihood 1,085 using andrzejewski this factorized j\u00e8rriais distribution. Often scalzi not bortezomib all 5-disc integrals are in closed form, which is swelters typically infrasonic handled by using hillsville a lower sub-system bound. We managua present an oatey alternative radif algorithm based ensuite on cengic stochastic optimization n.b.a. that oberlandesgericht allows poons for anachronistic direct unmasking optimization rat-man of deroin the variational lower bound. spitballs This method uses control variates slappers to reduce corretaje the mont-laurier variance stablemate of the arps stochastic pas-de-calais search gradient, in 63.88 which existing r&aw lower rendezvousing bounds can 8-david play an autolux important colitis role. dragoon We ivone demonstrate cl2 the approach on foral two non - gasser conjugate models: perotistas logistic swor regression 1391 and blink-182 an approximation 04-05 to el\u00e2z\u0131\u011f the HDP.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (575kb)", "http://arxiv.org/abs/1206.6430v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.CO stat.ML", "authors": ["john william paisley", "david m blei", "michael i jordan"], "accepted": true, "id": "1206.6430"}, "pdf": {"name": "1206.6430.pdf", "metadata": {"source": "META", "title": "Variational Bayesian Inference with Stochastic Search", "authors": ["John Paisley", "David M. Blei", "Michael I. Jordan"], "emails": ["jpaisley@berkeley.edu", "blei@cs.princeton.edu", "jordan@eecs.berkeley.edu"], "sections": [{"heading": "1. Introduction", "text": "Mean-field variational Bayesian (MFVB) inference is an optimization-based approach to approximating the full posterior of the latent variables of a Bayesian model (Jordan et al., 1999). It has been applied to many problem domains, for example mixture modeling (Blei & Jordan, 2006), sequential modeling (Beal, 2003) and factor analysis (Paisley & Carin, 2009). In addition, recent development of the theory has extended the method to online inference and stochastic optimization settings, making variational Bayes a viable approach for Bayesian learning with massive data sets (Hoffman et al., 2010; Wang et al., 2011).\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nVariational Bayes approximates the full posterior by attempting to minimize the Kullback-Leibler divergence between the true posterior and a predefined factorized distribution on the same variables. Minimizing this divergence is equivalent to maximizing the familiar variational objective function. To review, let \u0398 = {\u03b8i} represent the set of latent variables (random effects and parameters) in the model and X represent the data. The joint likelihood of X and \u0398 is P (X,\u0398|\u03a5), with \u03a5 the set of hyperparameters. Variational inference approximates the posterior P (\u0398|X,\u03a5) with a Q distribution that takes a set of variational parameters \u03a8 = {\u03c8i}. This distribution is factorized, Q(\u0398|\u03a8) = \u220f i qi(\u03b8i|\u03c8i), and the values of \u03a8 are optimized to maximize the objective function,\nL(X,\u03a8) = EQ[lnP (X,\u0398|\u03a5)] + H[Q(\u0398|\u03a8)]. (1)\nThe solution is only locally optimal when L is not convex, which is usually the case. Most variational inference algorithms optimize L by coordinate ascent, which repeatedly cycles through and optimizes with respect to each variational parameter \u03c8i. Often the locally optimal value of \u03c8i has a closed-form solution, for example in conjugate exponential models.\nThe log of the joint likelihood results in a sum of terms; a major issue that often arises in MFVB is that not all expectations in this sum are in closed form. A typical solution in this case is to replace the problematic function with another function of the same variables (plus auxiliary variables) that is a point-wise lower bound. This new function is selected such that the expectation is tractable. While inference can now proceed, a drawback of introducing bounds is that the true variational objective function is no longer being optimized, which may lead to a significantly worse posterior approximation. Therefore, much attention has been paid to developing tight bounds of commonly occurring functions (e.g., Jaakkola & Jordan (2000), Marlin et al. (2011), Leisink & Kappen (2001)).\nWe present a method for directly optimizing Eq. (1) for models in which not all expectations are tractable; we show how a stochastic approximation of \u2207\u03c8iL can allow for optimization of L when the expectation Eqi [lnP (X,\u0398|\u03a5)] is not in closed form. The approximation is unbiased, and so by using the proposed stochastic method we are directly optimizing L.\nOur stochastic approximation is based on Monte Carlo integration, for which the number of samples heavily depends on the variance of this approximation. We introduce a control variate (Ross, 2006) to significantly reduce the variance of this stochastic approximation. A control variate is a tractable function g that is highly correlated with the intractable function f . The function g replaces f in Eq. (1), and the gradient is then stochastically corrected for bias.\nExisting lower bounds have properties that make them ideal as control variates, and thus can improve the speed of the algorithm. However, a major advantage of the control variate methodology is that it does not require the tractable function g to bound f , but only to correlate well with it (i.e., to approximate it well modulo a scaling). This opens the door to many more functions that may give better approximations than a lower bound. One of these possible functions is the secondorder Taylor expansion, which often gives a very good approximation, while also allowing for closed-form expectations. We show the potential performance gain using this function as a control variate, which we denote the control variate delta method for MFVB.\nRelated work. Recent work by Knowles & Minka (2011) has also addressed the problem of intractable expectations in MFVB inference in the context of developing a more general variational message passing algorithm. Our solution arises from a different perspective and results in a new algorithm based on stochastic optimization. Graves (2011) considers a similar problem for neural networks, but a lack of control variates limits the algorithm to significantly simpler variational approximations. Stochastic search algorithms have also been developed for models of Evolution Strategies (see, e.g., Yi et al. (2009))."}, {"heading": "2. Mean-field variational inference", "text": "Mean-field variational Bayesian (MFVB) inference approximates the full posterior of the latent variables of a Bayesian model with a factorized distribution. As motivated in the introduction, let \u0398 = {\u03b8i} be these variables, X the data and \u03a5 all hyperparameters of the prior distributions on \u0398. We define the factorized distribution on \u0398 to be Q(\u0398|\u03a8) = \u220f i qi(\u03b8i|\u03c8i),\nwhere \u03c8i are the parameters of the qi distributions. The variational objective function arises by bounding the marginal likelihood using the Q distribution,\nlnP (X|\u03a5) = ln \u222b\n\u0398\nP (X,\u0398|\u03a5)d\u0398 (2)\n\u2265 \u222b\n\u0398\nQ(\u0398|\u03a8) ln P (X,\u0398|\u03a5) Q(\u0398|\u03a8) d\u0398.\nMaximizing this lower bound (denoted L) with respect to \u03a8 is equivalent to minimizing the KullbackLeibler divergence between Q(\u0398) and P (\u0398|X,\u03a5), which makes up the difference in Eq. (2).\nTo facilitate our discussion, we write the functions appearing in the log joint likelihood as lnP (X,\u0398|\u03a5) =\u2211 j fj(XAj ,\u0398Bj ), where Aj indexes the data appearing in function j and Bj indexes the latent variables appearing in function j. We note that the index j does not correspond to variables or distributions, but to the terms of the log joint likelihood. Using this notation, the variational lower bound in Eq. (1) becomes\nL = \u2211 j EQ[fj(XAj ,\u0398Bj )] + \u2211 iH[qi(\u03b8i|\u03c8i)]. (3)\nFor each function fj , those \u03b8i /\u2208 \u0398Bj will have their corresponding qi removed from the expectation. For those \u03b8i \u2208 \u0398Bj , the expectation of fj results in a new function of variational parameters \u03c8i \u2208 \u03a8Bj . Ideally, all expectations will be in closed form, allowing for the optimization of \u03a8 to proceed.\nIn the case where an expectation in Eq. (3) is not tractable, a nicer functional lower bound can replace the problematic function. That is, let Eqi [fj(\u03b8i)] be intractable.1 A common approach to dealing with this issue is to introduce a function g(\u03b8i, \u03be) that replaces fj and is a point-wise lower bound: fj(\u03b8i) \u2265 g(\u03b8i, \u03be) for all \u03b8i. The function g usually takes auxiliary variables \u03be, which determines how tightly g approximates fj and is tuned along with the other parameters during inference. The expectation Eqi [g(\u03b8i, \u03be)] has a closed-form solution, and gives a lower bound on the variational objective that can be optimized.\nTo illustrate, consider the case where fj is convex in \u03b8i. Then a bound g could be a first-order Taylor expansion of fj about the point \u03be, which has a closed-form expectation. Significantly tighter tractable bounds have also been developed for various frequently occurring functions (e.g., Marlin et al. (2011), Knowles & Minka (2011)). In general, the looser the bound the further one is from optimizing the variational objective, and learning of \u03c8i can suffer as a result.\n1We have simplified the notation for clarity."}, {"heading": "3. Stochastic search variational Bayes", "text": "We next present a method based on stochastic search for directly optimizing the variational objective function L in cases where some expectations cannot be computed in the log joint likelihood. This method uses a stochastic approximation of the gradient with respect to the variational parameters of the associated q distribution. To further simplify notation, we drop all indices; f is the intractable function of \u03b8 (plus other variational parameters), and \u03b8 has a variational distribution q taking parameters \u03c8.\nWe separate the lower bound L into two functions, Ef and h, where h(X,\u03a8) contains everything in L except for Ef . Notably, h contains all other functions of \u03c8 resulting from expectations calculated with respect to q. In coordinate ascent variational inference, the first step in optimizing q with respect to its parameters \u03c8 is to take the gradient of the variational objective,\n\u2207\u03c8L = \u2207\u03c8Eq[f(\u03b8)] +\u2207\u03c8h(X,\u03a8). (4)\nThis gradient contains a tractable term resulting from \u2207\u03c8h, and an intractable term \u2207\u03c8Eqf . Our goal is to make a stochastic approximation of this gradient. To this end, assuming the necessary regularity conditions, we rewrite this function as\n\u2207\u03c8Eq[f(\u03b8)] = \u2207\u03c8 \u222b \u03b8 f(\u03b8)q(\u03b8|\u03c8)d\u03b8 (5)\n= \u222b \u03b8 f(\u03b8)\u2207\u03c8q(\u03b8|\u03c8)d\u03b8\n= \u222b \u03b8 f(\u03b8)q(\u03b8|\u03c8)\u2207\u03c8 ln q(\u03b8|\u03c8)d\u03b8.\nWe use the identity \u2207\u03c8q(\u03b8|\u03c8) = q(\u03b8|\u03c8)\u2207\u03c8 ln q(\u03b8|\u03c8).\nIt follows that \u2207\u03c8Eq[f(\u03b8)] = Eq[f(\u03b8)\u2207\u03c8 ln q(\u03b8|\u03c8)]. We can stochastically approximate this expectation using Monte Carlo integration,\n\u2207\u03c8Eq[f(\u03b8)] \u2248 1\nS S\u2211 s=1 f(\u03b8(s))\u2207\u03c8 ln q(\u03b8(s)|\u03c8), (6)\nwhere \u03b8(s) iid\u223c q(\u03b8|\u03c8) for s = 1, . . . , S. We can therefore replace \u2207\u03c8Eq[f(\u03b8)] with the unbiased stochastic approximation of this gradient in Eq. (6). Denote this approximation as \u03b6. At iteration t, we update the variational parameter \u03c8 by taking a gradient step,\n\u03c8(t+1) = \u03c8(t) + \u03c1t\u2207\u03c8h(X,\u03a8(t)) + \u03c1t\u03b6t. (7)\nBy decreasing the step size \u03c1t such that \u2211\u221e t=1 \u03c1t =\u221e\nand \u2211\u221e t=1 \u03c1 2 t < \u221e, convergence to a local optimal solution of L is guaranteed. For example, \u03c1t = (w+ t)\u2212\u03b7 with \u03b7 \u2208 (0.5, 1] and w \u2265 0 satisfies this requirement."}, {"heading": "4. Searching with control variates", "text": "A practical issue with the stochastic approximation proposed in Sec. 3 is that the variance of the gradient approximation may be very large. Given S samples of a random vector X, the covariance of its unbiased sample mean X\u0304 is known to be Cov(X\u0304) = Cov(X)/S. When the diagonal values of Cov(X) are large, many samples will be required to bring this variance below a desired level for approximating the expectation. As our experiments will show in Sec. 6, the value of S can be very large in practice and lead to a slow algorithm. We therefore seek a variance reduction method to reduce the number of samples needed to construct the stochastic search direction.\nWe introduce a control variate (Ross, 2006) to reduce the variance of the stochastic gradient constructed in Eq. (6). A control variate is a random variable that is highly correlated with an intractable variable, but for which the expectation is tractable. In this case the random variable is f(\u03b8), for which we introduce a control variate g(\u03b8). Control variates are ideal for MFVB because they can leverage the existing bounds, though they also admit a larger class of functions. We next review this variance reduction technique for Ef , and discuss the modifications needed to account for the stochastic vector f(\u03b8)\u2207\u03c8 ln q(\u03b8|\u03c8)."}, {"heading": "4.1. A control variate for f(\u03b8)", "text": "Generally speaking, variance reduction works by modifying a function of a random variable such that its expectation remains the same, but its variance decreases. Toward this end, we introduce a control variate g(\u03b8), which approximates f(\u03b8) well in the highly probable regions as defined by q(\u03b8), but also has a closed-form expectation under q. Using g and a scalar a \u2208 R, we first form the new function f\u0302 ,\nf\u0302(\u03b8) = f(\u03b8)\u2212 a(g(\u03b8)\u2212 Eq[g(\u03b8)]). (8)\nThis function has the same expectation as f and therefore can replace it in L in Eq. (3).\nThe next step is to set the value of a to minimize the variance of f\u0302 . A simple calculation shows that\nVar(f\u0302) = Var(f)\u2212 2aCov(f, g) + a2Var(g). (9)\nTaking the derivative with respect to a and setting to zero gives the optimal value,\na = Cov(f, g)\nVar(g) . (10)\nAs is usual, this covariance and variance is unknown in the functions we encounter. We can approximate\nAlgorithm 1 Variational Bayes with stochastic search Goal To calculate \u2207\u03c8L = \u2207\u03c8Eq[f(\u03b8)] +\u2207\u03c8h(X,\u03a8). Approximate \u2207\u03c8L using stochastic search. input Variance reduction parameter . 1: Introduce the function g(\u03b8) as a control variate\nthat highly correlates with f(\u03b8). 2: Sample an initial (small) collection \u03b8(s) \u223c q(\u03b8|\u03c8). 3: Sum the sample variances and covariances \u03b2 = \u2211K k=1 Var(g \u2202 ln q \u2202\u03c8k ), \u03b3 = \u2211K k=1 Var(f \u2202 ln q \u2202\u03c8k ),\n\u03b1 = \u2211K k=1 Cov(f \u2202 ln q \u2202\u03c8k , g \u2202 ln q\u2202\u03c8k ).\n4: Set a\u0302 = \u03b1/\u03b2 and S = (\u03b3 \u2212 \u03b12/\u03b2)/ K. 5: Sample \u03b8(s) \u223c q(\u03b8|\u03c8) i.i.d. for s = 1, . . . , dSe. 6: Construct the stochastic search vector \u03b6 = 1S \u2211S s=1{f(\u03b8(s))\u2212 a\u0302g(\u03b8(s))}\u2207\u03c8 ln q(\u03b8(s)|\u03c8). 7: Step in the direction of the stochastic gradient \u03c8\u2032 = \u03c8 + \u03c1\u03b6 + \u03c1\u2207\u03c8(h(X,\u03a8) + a\u0302Eq[g(\u03b8)]).\na with a\u0302, found by plugging the sample variance and covariance into Eq. (10) using samples from the algorithm.\nThe potential reduction in variance is seen by plugging Eq. (10) into Eq. (9) and taking the ratio of the two variances,\nVar(f\u0302)/Var(f) = 1\u2212 Corr(f, g)2. (11)\nTherefore, the greater the correlation between f and g, the greater the variance reduction. Tight lower bounds of f by construction have this high correlation, but we note that tight upper bounds work as well, as do wellapproximating functions that do not bound f .\nUsing the control variate g, we now write the stochastic approximation to the gradient as\n\u2207\u03c8Eq[f\u0302(\u03b8)] \u2248 a\u0302\u2207\u03c8Eq[g(\u03b8)] (12)\n+ 1\nS S\u2211 s=1 {f(\u03b8(s))\u2212 a\u0302g(\u03b8(s))}\u2207\u03c8 ln q(\u03b8(s)|\u03c8),\nwhere \u03b8(s) iid\u223c q(\u03b8|\u03c8) for s = 1, . . . , S.\nWriting the stochastic approximation this way allows for a more intuitive understanding of the algorithm. By separating the tractable and stochastic parts as done in Eq. (12), we first replace the intractable function f with a tractable approximation g. (This resembles the standard method when g lower bounds f .) The gradient of Eg is then corrected by a stochastic vector. The variance of the correction is smaller than that of the original stochastic approximation in Sec. 3, since the function f(\u03b8) is close to a\u0302g(\u03b8). The gradient of Eg can be thought of as an initial guess, followed by a stochastic correction which ensures that we are optimizing the variational objective function."}, {"heading": "4.2. The stochastic search case", "text": "We have introduced a control variate for f(\u03b8), but in fact we would like to minimize the variance of the vector f(\u03b8)\u2207\u03c8 ln q(\u03b8|\u03c8) in Eq. (6). In this case, the control variate becomes g(\u03b8)\u2207\u03c8 ln q(\u03b8|\u03c8) and we have the following modification.\nLet \u03c8k be the kth dimension of \u03c8. Then for each dimension the discussion in Sec. 4.1 carries through, but for f \u2202 ln q\u2202\u03c8k and g \u2202 ln q \u2202\u03c8k instead of f and g. The variance of each dimension again follows Eq. (9), and we seek an a to minimize the sum of these equations. This results in the optimal value\na = \u2211 k Cov(f \u2202 ln q \u2202\u03c8k , g \u2202 ln q\u2202\u03c8k )/ \u2211 k Var(g \u2202 ln q \u2202\u03c8k ),\nwhich we approximate using samples. We summarize stochastic search variational Bayes in Algorithm 1."}, {"heading": "5. Stochastic search VB for two models", "text": "We next illustrate stochastic search variational inference on logistic regression and a finite approximation to the hierarchical Dirichlet process (Teh et al., 2007). For logistic regression, we will consider two control variates, one of which is a lower bound and the other of which is not a bound. For the finite HDP, we will consider a piecewise control variate, one part being an upper bound on the original function."}, {"heading": "5.1. Logistic regression", "text": "Binary logistic regression takes in d-dimensional data vectors xn and predicts the class yn \u2208 {\u22121, 1} to which each belongs. The parameter is \u03b8 \u2208 Rd and the prediction law is Pr(yn|xn, \u03b8) = \u03c3(ynxTn\u03b8) where \u03c3(\u00b7) is the sigmoid function, \u03c3(b) = (1+e\u2212b)\u22121. Bayesian logistic regression places a prior distribution on the coefficient vector, \u03b8 \u223c Normal(0, cI). For inference we define a Gaussian variational q distribution\nq(\u03b8) = Normal(\u00b5,\u03a3). (13)\nThe variational lower bound for this model is L = \u2211N n=1 Eq[ln\u03c3(ynxTn\u03b8)]+Eq[ln p(\u03b8)\u2212ln q(\u03b8)]. (14)\nThe expectations of fn(yn, xn; \u03b8) := ln\u03c3(ynx T n\u03b8) are intractable. One approach to avoiding this issue is to forgo variational inference and use Laplace\u2019s method to approximate q. This method sets \u00b5 to the MAP solution, and \u03a3\u22121 to the negative Hessian of the log joint likelihood evaluated at \u00b5. Another is to lower bound fn with the bound in, e.g., Jaakkola & Jordan (2000), which allows for closed-form variational inference. We consider this bound as a control variate.\nA lower bound control variate. The lower bound for fn developed by Jaakkola & Jordan (2000) is a useful control variate for variational logistic regression. For each pair (xn, yn), this bound takes an auxiliary parameter \u03ben > 0 and has the form\ngn(yn, xn; \u03b8, \u03ben) = ln\u03c3(\u03ben) + 1\n2 (ynx\nT n\u03b8 \u2212 \u03ben)\n\u2212 \u03bb(\u03ben)((xTn\u03b8)2 \u2212 \u03be2n). (15)\nWe have \u03bb(\u03ben) = (2\u03c3(\u03ben) \u2212 1)/(4\u03ben). We select this bound for illustrative purposes, but any lower bound will work in principle. For a multivariate Gaussian q distribution, having a quadratic term in g is essential for stochastically learning a full covariance matrix. In general, tighter bounds will require fewer samples, but for some functions finding tight bounds may require much effort. We next consider a general purpose control variate that can help in this case.\nControl variate delta method. We also consider the second-order Taylor expansion of f as a control variate. The second-order Taylor expansion often accurately approximates a function of interest, and when used alone is known as the delta method. In addition to accuracy, the quadratic approximation of the delta method results in a function for which the expectation with respect to q is very likely to be analytic.\nThe delta method arguably should not be used for mean-field variational inference because the secondorder Taylor expansion is not a lower bound. On the other hand, the first-order Taylor expansion often is a lower bound. Therefore, though their bounds are typically loose, first-order approximations are commonly employed for MFVB. An advantage of the proposed stochastic search algorithm is that second-order methods can now be used as a control variate to (i) more\naccurately approximate the function of interest, and (ii) significantly reduce the variance of the stochastic gradient. We call this approach of using Taylor expansion control variates the control variate delta method.\nWe consider a second-order Taylor expansion at \u00b5\u0302, the current mean of q, for approximating ln\u03c3(ynx T n\u03b8). Letting \u03c3n := \u03c3(ynx T n \u00b5\u0302), this control variate is\ngn(yn, xn; \u03b8, \u00b5\u0302) = ln\u03c3n + yn(1\u2212 \u03c3n)(\u03b8 \u2212 \u00b5\u0302)Txn (16)\n\u2212 1 2 \u03c3n(1\u2212 \u03c3n)(\u03b8 \u2212 \u00b5\u0302)TxnxTn (\u03b8 \u2212 \u00b5\u0302).\nAs with the Jaakkola & Jordan (2000) bound, this control variate contains a quadratic term that helps in learning the covariance matrix of q.\nWe compare these control variates in Figure 1. In these plots we show the difference fn \u2212 gn for two specific q distributions, and with x = 1. We also show 100 samples from q, which indicates the regions where these functions would be evaluated (for a = 1). The plots show that the second-order Taylor expansion approximates fn significantly better where it matters; we support this conclusion with the experiments in Sec. 6."}, {"heading": "5.2. Hierarchical Dirichlet processes", "text": "We also investigate a stochastic search VB algorithm for an approximation to the hierarchical Dirichlet process (Teh et al., 2007). We focus on the two-level generative structure using finite dimensional Dirichlet priors as an approximation to the infinite dimensional process\u2014in the limit the HDP is recovered. In this finite process, a top-level Dirichlet-distributed probability vector \u03b8 parameterizes the Dirichlet distribution for d = 1, . . . , D second-level probability vectors,\n(\u03c0d1, . . . , \u03c0dK) iid\u223c Dirichlet(\u03b2\u03b81, . . . , \u03b2\u03b8K),\n(\u03b81, . . . , \u03b8K) \u223c Dirichlet( \u03b1K , . . . , \u03b1 K ). (17)\nIn topic models, these \u03c0d vectors are often used as distributions on word distributions. In this section, we focus solely on the generic hierarchical structure in Eq. (17). We define the approximate posterior of \u03b8 as\nq(\u03b8) = Dirichlet(c1, . . . , cK). (18)\nThe part of the lower bound associated with \u03b8 is L\u03b8 = \u2211 k \u03b2Eq[\u03b8k] \u2211 d Eq[ln\u03c0dk]\u2212 \u2211 kDEq[ln \u0393(\u03b2\u03b8k)]\n+Eq[ln p(\u03b8)\u2212 ln q(\u03b8)]. (19)\nThe expectation Eq[ln \u0393(\u03b2\u03b8k)] is intractable for each k. We use a stochastic approximation, and introduce two control variates for this function, depending on the current expected value of \u03b2\u03b8k.\nAs \u03b2\u03b8k approaches zero, the function fk(\u03b2\u03b8k) = \u2212 ln \u0393(\u03b2\u03b8k) diverges to \u2212\u221e. By construction of the Dirichlet prior, many values of \u03b8k will be very small. (In the infinite limit, there are an infinite number of such values smaller than any \u03b4 > 0.) The variance in this region is massive\u2014when computer precision becomes an issue it can be infinite (see Figure 2).\nWe propose the control variate gk(\u03b2\u03b8k) = ln\u03b2\u03b8k, with Eq[ln \u03b8k] = \u03c6(ck)\u2212\u03c6( \u2211 j cj) where \u03c6(\u00b7) is the digamma function. This control variate not only correlates well with fk, but if a = 1, lim\u03b2\u03b8k\u21920 fk \u2212 agk = 0, as shown in Figure 2. This results from the equality\n\u2212 ln \u0393(\u03b2\u03b8k)\u2212 ln\u03b2\u03b8k = \u2212 ln \u0393(\u03b2\u03b8k + 1). (20)\nFor all other values of a, this equality does not hold, and the difference fk \u2212 agk diverges as \u03b2\u03b8k \u2192 0. For this model, we can thus give the optimal value of a in advance, and we set a = 1.\nFrom Figure 2, we also see that the approximation gets worse when \u03b2\u03b8k gets large, which can occur for a few highly probable dimensions when \u03b2 is large. Since fk is approximately linear in this regime, we use a firstorder Taylor expansion of fk about the mean \u03b8\u0304k = Eq[\u03b8k] as a control variate. This gives the following two control variates,\ngk = ln\u03b2\u03b8k, 0 < \u03b2\u03b8\u0304k < \u03ba1, (21) gk = \u2212 ln \u0393(\u03b2\u03b8\u0304k)\u2212 \u03b2(\u03b8k \u2212 \u03b8\u0304k)\u03c6(\u03b2\u03b8\u0304k), \u03b2\u03b8\u0304k > \u03ba2.\nSince fk is concave, this second control variate is an upper bound on L\u03b8 without the stochastic correction. We discuss the boundaries \u03ba1 and \u03ba2 in Sec. 6.\nThus far, we\u2019ve focused mainly on reducing the variance induced by fk, but in Sec. 4.2 we noted that \u2207 ln q introduces variance to the Monte Carlo integral as well. This suggests that we should look at other\nparts of the integral for potential variance reduction. We briefly show how this can be done for the HDP.\nThe lower bound in Eq. (19) contains a sum of K intractable integrals over the probability simplex \u2206K . We perform separate stochastic approximations of each gradient. Using the fact that each gamma function is over a single dimension of the simplex, for a function of \u03b8k the variables \u03b8i 6=k will integrate out. In this case, marginalizing a Dirichlet distribution to a single dimension yields a beta distribution. That is,\u222b \u03b8\u2208\u2206K ln \u0393(\u03b2\u03b8k)q(\u03b8|c)d\u03b8 = \u222b 1 0 ln \u0393(\u03b2\u03b8k)q \u2032 k(\u03b8k|c)d\u03b8k,\nwhere q\u2032k(\u03b8k|c) = Beta(\u03b8k|ck, \u2211 i6=k ci).\nWe can choose which of these integrals to stochastically approximate for gradient ascent. However, the stochastic gradient using q\u2032k results in significantly less variance than for q since \u03b8 (s) k will be near zero; the vector \u2207c ln q\u2032k has K \u2212 1 entries containing ln(1\u2212 \u03b8(s)k )\u2212Eq[ln(1\u2212 \u03b8k)], while these values will be ln \u03b8\n(s) i \u2212 Eq[ln \u03b8i] for i = 1, . . . ,K when using \u2207c ln q."}, {"heading": "6. Experiments", "text": "We perform experiments using stochastic search VB for binary classification with logistic regression and for topic modeling with the approximate HDP. We next give the details of the experiments we perform and the data sets and algorithms used for comparison.\nData and set-up. For logistic regression, we use five data sets from the UCI repository: Iris, Pima, SPECTF, Voting and WDBC. These data sets range from 150 to 768 labeled examples living in 5 to 45 dimensions, including a dimension of all ones to account for offset. We perform experiments with stochastic search variational inference using the two control variates discussed in Sec. 5.1. We compare with two additional methods for posterior approximation: variational inference with the Jaakkola & Jordan (2000) bound and Laplace\u2019s method. We evaluate performance on the true variational objective function in Eq. (14) using each posterior approximation.\nFor the HDP topic model, we use 8,000 documents with 3,012 vocabulary size from The New York Times. We compare with (i) a point estimate of the top-level probability vector using a delta q distribution, and (ii) fixing the top-level distribution to the uniform vector, which is equivalent to LDA (Blei et al., 2003). We perform experiments for different corpus sizes, different values of \u03b2, and we set K = 200.\nLogistic regression results. In Table 1 we show the variational lower bound for each model on each data set. Since all algorithms return an approximation of the posterior distribution on the vector \u03b8, this comparison is meaningful and gives a measure of how close each posterior is to the true posterior. We see a considerable improvement for the stochastic algorithms (denoted by their control variate). Since both stochastic algorithms optimize the same objective, the performance should be the same.\nWe show performance details of the stochastic search VB algorithm in Figure 3 and Table 2. In Figure 3, we show the number of samples, the variance reduction factor and the scaling a\u0302 as a function of iteration. We see that the control variates provide a major reduction in variance. Also, the Taylor expansion control variate (i.e., control variate delta method) requires significantly fewer samples than the bound control variate, which benefits the running time (see Table 2). While the non-sampling methods are faster, control variates make stochastic search VB a viable inference method when compared to the base algorithm of Sec. 3.\nHierarchical Dirichlet process results. We fit topic models to The New York Times using different numbers of documents (D = 1000 to 8000) and concentration parameter values \u03b2 \u2208 {1, 5, 10, 15}. As switch points for the two control variates, we set \u03ba1 = 1 and \u03ba2 = 2. We summarize our results in Table 3. In general, fitting a variational posterior on the top-level Dirichlet vector yielded a better posterior approximation than a point estimate and a \u03b8 fixed as uniform. However, this improvement was not as dramatic as for logistic regression.\nIn Figure 4, we show the number of samples required from the Dirichlet q distribution to approximate the stochastic integral. We compare the two methods discussed in Sec. 5.2 for reducing the variance of the stochastic vector \u2207c ln q by instead using \u2207c ln q\u2032k. We see a significant reduction in the number of samples. Experiments without control variates were not possible due to computer precision issues and the massive variance of ln \u0393(\u03b2\u03b8) near zero."}, {"heading": "7. Conclusion", "text": "We have presented stochastic search variational Bayes, a method for optimizing intractable variational objective functions such as those arising from nonconjugacy. The algorithm relies on a stochastic approximation of the gradient; we showed how control variates can significantly reduce the variance of this Monte Carlo integral. Since existing lower bounds can be recast as control variates, our approach is relevant to many existing MFVB algorithms. However, a lack\nof restrictions on control variates allows for other types of function approximations when a good bound is not readily available. We introduced the control variate delta method toward this end.\nAcknowledgements J.P. and M.J. are supported by ONR grant number N00014-11-1-0688 under the MURI program. D.B. is supported by ONR N00014-11-1-0651, NSF CAREER 0745520, AFOSR FA9550-09-1-0668, the Alfred P. Sloan foundation, and a grant from Google."}], "references": [{"title": "Variational Algorithms for Approximate Bayesian Inference", "author": ["M.J. Beal"], "venue": "PhD thesis, Gatsby Computational Neuroscience Unit,", "citeRegEx": "Beal,? \\Q2003\\E", "shortCiteRegEx": "Beal", "year": 2003}, {"title": "Variational inference for Dirichlet process mixtures", "author": ["D. Blei", "M. Jordan"], "venue": "Bayesian Analysis,", "citeRegEx": "Blei and Jordan,? \\Q2006\\E", "shortCiteRegEx": "Blei and Jordan", "year": 2006}, {"title": "Latent Dirichlet allocation", "author": ["D. Blei", "A. Ng", "M. Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Practical variational inference for neural networks", "author": ["A. Graves"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "Graves,? \\Q2011\\E", "shortCiteRegEx": "Graves", "year": 2011}, {"title": "Online learning for latent Dirichlet allocation", "author": ["M. Hoffman", "D. Blei", "F. Bach"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "Hoffman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hoffman et al\\.", "year": 2010}, {"title": "Bayesian parameter estimation via variational methods", "author": ["T. Jaakkola", "M.I. Jordan"], "venue": "Statistics and Computing,", "citeRegEx": "Jaakkola and Jordan,? \\Q2000\\E", "shortCiteRegEx": "Jaakkola and Jordan", "year": 2000}, {"title": "An introduction to variational methods for graphical models", "author": ["M.I. Jordan", "Z. Ghahramani", "T. Jaakkola", "L.K. Saul"], "venue": "Machine Learning,", "citeRegEx": "Jordan et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Jordan et al\\.", "year": 1999}, {"title": "Non-conjugate variational message passing for multinomial and binary regression", "author": ["D.A. Knowles", "T.P. Minka"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "Knowles and Minka,? \\Q2011\\E", "shortCiteRegEx": "Knowles and Minka", "year": 2011}, {"title": "A tighter bound for graphical models", "author": ["M.A.R. Leisink", "H.J. Kappen"], "venue": "Neural Computation,", "citeRegEx": "Leisink and Kappen,? \\Q2001\\E", "shortCiteRegEx": "Leisink and Kappen", "year": 2001}, {"title": "Piecewise bounds for estimating Bernoulli-logistic latent Gaussian models", "author": ["B. Marlin", "E. Khan", "K. Murphy"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Marlin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Marlin et al\\.", "year": 2011}, {"title": "Nonparametric factor analysis with beta process priors", "author": ["J. Paisley", "L. Carin"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Paisley and Carin,? \\Q2009\\E", "shortCiteRegEx": "Paisley and Carin", "year": 2009}, {"title": "Hierarchical Dirichlet processes", "author": ["Y. Teh", "M. Jordan", "M. Beal", "D. Blei"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Teh et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Teh et al\\.", "year": 2007}, {"title": "Online variational inference for the hierarchical Dirichlet process", "author": ["C. Wang", "J. Paisley", "D. Blei"], "venue": "In Artificial Intelligence and Statistics,", "citeRegEx": "Wang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2011}, {"title": "Stochastic search using the natural gradient", "author": ["S. Yi", "D. Wierstra", "T. Schaul", "J. Schmidhuber"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Yi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yi et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 6, "context": "Mean-field variational Bayesian (MFVB) inference is an optimization-based approach to approximating the full posterior of the latent variables of a Bayesian model (Jordan et al., 1999).", "startOffset": 163, "endOffset": 184}, {"referenceID": 0, "context": "It has been applied to many problem domains, for example mixture modeling (Blei & Jordan, 2006), sequential modeling (Beal, 2003) and factor analysis (Paisley & Carin, 2009).", "startOffset": 117, "endOffset": 129}, {"referenceID": 4, "context": "In addition, recent development of the theory has extended the method to online inference and stochastic optimization settings, making variational Bayes a viable approach for Bayesian learning with massive data sets (Hoffman et al., 2010; Wang et al., 2011).", "startOffset": 216, "endOffset": 257}, {"referenceID": 12, "context": "In addition, recent development of the theory has extended the method to online inference and stochastic optimization settings, making variational Bayes a viable approach for Bayesian learning with massive data sets (Hoffman et al., 2010; Wang et al., 2011).", "startOffset": 216, "endOffset": 257}, {"referenceID": 9, "context": ", Jaakkola & Jordan (2000), Marlin et al. (2011), Leisink & Kappen (2001)).", "startOffset": 28, "endOffset": 49}, {"referenceID": 9, "context": ", Jaakkola & Jordan (2000), Marlin et al. (2011), Leisink & Kappen (2001)).", "startOffset": 28, "endOffset": 74}, {"referenceID": 3, "context": "Graves (2011) considers a similar problem for neural networks, but a lack of control variates limits the algorithm to significantly simpler variational approximations.", "startOffset": 0, "endOffset": 14}, {"referenceID": 3, "context": "Graves (2011) considers a similar problem for neural networks, but a lack of control variates limits the algorithm to significantly simpler variational approximations. Stochastic search algorithms have also been developed for models of Evolution Strategies (see, e.g., Yi et al. (2009)).", "startOffset": 0, "endOffset": 286}, {"referenceID": 9, "context": ", Marlin et al. (2011), Knowles & Minka (2011)).", "startOffset": 2, "endOffset": 23}, {"referenceID": 9, "context": ", Marlin et al. (2011), Knowles & Minka (2011)).", "startOffset": 2, "endOffset": 47}, {"referenceID": 11, "context": "We next illustrate stochastic search variational inference on logistic regression and a finite approximation to the hierarchical Dirichlet process (Teh et al., 2007).", "startOffset": 147, "endOffset": 165}, {"referenceID": 11, "context": "We also investigate a stochastic search VB algorithm for an approximation to the hierarchical Dirichlet process (Teh et al., 2007).", "startOffset": 112, "endOffset": 130}, {"referenceID": 2, "context": "We compare with (i) a point estimate of the top-level probability vector using a delta q distribution, and (ii) fixing the top-level distribution to the uniform vector, which is equivalent to LDA (Blei et al., 2003).", "startOffset": 196, "endOffset": 215}], "year": 2012, "abstractText": "Mean-field variational inference is a method for approximate Bayesian posterior inference. It approximates a full posterior distribution with a factorized set of distributions by maximizing a lower bound on the marginal likelihood. This requires the ability to integrate a sum of terms in the log joint likelihood using this factorized distribution. Often not all integrals are in closed form, which is typically handled by using a lower bound. We present an alternative algorithm based on stochastic optimization that allows for direct optimization of the variational lower bound. This method uses control variates to reduce the variance of the stochastic search gradient, in which existing lower bounds can play an important role. We demonstrate the approach on two non-conjugate models: logistic regression and an approximation to the HDP.", "creator": "LaTeX with hyperref package"}}}