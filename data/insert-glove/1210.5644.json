{"id": "1210.5644", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Oct-2012", "title": "Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials", "abstract": "quilombo Most state - of - persoon the - art 1488 techniques blackwell for multi - larks class image kirkvaag segmentation 3-dimensional and labeling businesman use formigoni conditional random wnbc fields defined pectore over raffel pixels 16.4-billion or glanvill image regions. While region - level cardelli models 52.13 often newswire feature dense pairwise filk connectivity, papaloapan pixel - level bonafini models 113.63 are terasen considerably gunduli\u0107 larger and kosachev have only hoonah permitted sparse nugraha graph structures. straight-sided In this paper, maduravoyal we star consider cherone fully warnes connected pope CRF vistica models defined on the addai complete leukaemia set of pixels delighting in spacegodzilla an image. purana The u.n.-nato resulting impedance graphs have billions brimm of edges, u/19 making traditional inference algorithms ilaje impractical. Our registries main contribution shoygu is a third-tallest highly efficient lucht approximate stankina inference bishopton algorithm boalsburg for mureaux fully connected passe CRF models raindance in zanjanrud which nikolsky the klooga pairwise edge potentials are 61.32 defined bobdart by .35 a butina linear sijo combination of Gaussian 1,892 kernels. Our experiments 64-61 demonstrate that antena dense connectivity at the pixel computations level s\u01b0 substantially improves segmentation sauds and labeling 2-84 accuracy.", "histories": [["v1", "Sat, 20 Oct 2012 17:41:23 GMT  (3893kb,DS)", "http://arxiv.org/abs/1210.5644v1", "NIPS 2011"]], "COMMENTS": "NIPS 2011", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG", "authors": ["philipp kr\u00e4henb\u00fchl", "vladlen koltun"], "accepted": true, "id": "1210.5644"}, "pdf": {"name": "1210.5644.pdf", "metadata": {"source": "META", "title": "Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials", "authors": ["Philipp Kr\u00e4henb\u00fchl", "Vladlen Koltun"], "emails": ["philkr@cs.stanford.edu", "vladlen@cs.stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "Multi-class image segmentation and labeling is one of the most challenging and actively studied problems in computer vision. The goal is to label every pixel in the image with one of several predetermined object categories, thus concurrently performing recognition and segmentation of multiple object classes. A common approach is to pose this problem as maximum a posteriori (MAP) inference in a conditional random field (CRF) defined over pixels or image patches [8, 12, 18, 19, 9]. The CRF potentials incorporate smoothness terms that maximize label agreement between similar pixels, and can integrate more elaborate terms that model contextual relationships between object classes.\nBasic CRF models are composed of unary potentials on individual pixels or image patches and pairwise potentials on neighboring pixels or patches [19, 23, 7, 5]. The resulting adjacency CRF structure is limited in its ability to model long-range connections within the image and generally results in excessive smoothing of object boundaries. In order to improve segmentation and labeling accuracy, researchers have expanded the basic CRF framework to incorporate hierarchical connectivity and higher-order potentials defined on image regions [8, 12, 9, 13]. However, the accuracy of these approaches is necessarily restricted by the accuracy of unsupervised image segmentation, which is used to compute the regions on which the model operates. This limits the ability of region-based approaches to produce accurate label assignments around complex object boundaries, although significant progress has been made [9, 13, 14].\nIn this paper, we explore a different model structure for accurate semantic segmentation and labeling. We use a fully connected CRF that establishes pairwise potentials on all pairs of pixels in the image. Fully connected CRFs have been used for semantic image labeling in the past [18, 22, 6, 17], but the complexity of inference in fully connected models has restricted their application to sets of hundreds of image regions or fewer. The segmentation accuracy achieved by these approaches is again limited by the unsupervised segmentation that produces the regions. In contrast, our model connects all\nar X\niv :1\n21 0.\n56 44\nv1 [\ncs .C\nV ]\n2 0\nO ct\npairs of individual pixels in the image, enabling greatly refined segmentation and labeling. The main challenge is the size of the model, which has tens of thousands of nodes and billions of edges even on low-resolution images.\nOur main contribution is a highly efficient inference algorithm for fully connected CRF models in which the pairwise edge potentials are defined by a linear combination of Gaussian kernels in an arbitrary feature space. The algorithm is based on a mean field approximation to the CRF distribution. This approximation is iteratively optimized through a series of message passing steps, each of which updates a single variable by aggregating information from all other variables. We show that a mean field update of all variables in a fully connected CRF can be performed using Gaussian filtering in feature space. This allows us to reduce the computational complexity of message passing from quadratic to linear in the number of variables by employing efficient approximate high-dimensional filtering [16, 2, 1]. The resulting approximate inference algorithm is sublinear in the number of edges in the model.\nFigure 1 demonstrates the benefits of the presented algorithm on two images from the MSRC-21 dataset for multi-class image segmentation and labeling. Figure 1(d) shows the results of approximate MCMC inference in fully connected CRFs on these images [17]. The MCMC procedure was run for 36 hours and only partially converged for the bottom image. We have also experimented with graph cut inference in the fully connected models [11], but it did not converge within 72 hours. In contrast, a single-threaded implementation of our algorithm produces a detailed pixel-level labeling in 0.2 seconds, as shown in Figure 1(e). A quantitative evaluation on the MSRC-21 and the PASCAL VOC 2010 datasets is provided in Section 6. To the best of our knowledge, we are the first to demonstrate efficient inference in fully connected CRF models at the pixel level."}, {"heading": "2 The Fully Connected CRF Model", "text": "Consider a random field X defined over a set of variables {X1, . . . , XN}. The domain of each variable is a set of labels L = {l1, l2, . . . , lk}. Consider also a random field I defined over variables {I1, . . . , IN}. In our setting, I ranges over possible input images of size N and X ranges over possible pixel-level image labelings. Ij is the color vector of pixel j and Xj is the label assigned to pixel j.\nA conditional random field (I,X) is characterized by a Gibbs distribution P (X|I) = 1Z(I) exp(\u2212 \u2211 c\u2208CG \u03c6c(Xc|I)), where G = (V, E) is a graph on X and each clique c\nin a set of cliques CG in G induces a potential \u03c6c [15]. The Gibbs energy of a labeling x \u2208 LN is E(x|I) = \u2211 c\u2208CG \u03c6c(xc|I). The maximum a posteriori (MAP) labeling of the random field is x\u2217 = arg maxx\u2208LN P (x|I). For notational convenience we will omit the conditioning in the rest of the paper and use \u03c8c(xc) to denote \u03c6c(xc|I). In the fully connected pairwise CRF model, G is the complete graph on X and CG is the set of all unary and pairwise cliques. The corresponding Gibbs energy is\nE(x) = \u2211 i \u03c8u(xi) + \u2211 i<j \u03c8p(xi, xj), (1)\nwhere i and j range from 1 to N . The unary potential \u03c8u(xi) is computed independently for each pixel by a classifier that produces a distribution over the label assignment xi given image features. The unary potential used in our implementation incorporates shape, texture, location, and color descriptors and is described in Section 5. Since the output of the unary classifier for each pixel is produced independently from the outputs of the classifiers for other pixels, the MAP labeling produced by the unary classifiers alone is generally noisy and inconsistent, as shown in Figure 1(b).\nThe pairwise potentials in our model have the form \u03c8p(xi, xj) = \u00b5(xi, xj) \u2211K m=1 w\n(m)k(m)(fi, fj)\ufe38 \ufe37\ufe37 \ufe38 k(fi,fj) , (2)\nwhere each k(m) is a Gaussian kernel k(m)(fi, fj) = exp(\u2212 12 (fi \u2212 fj) T\u039b(m)(fi \u2212 fj)), the vectors fi and fj are feature vectors for pixels i and j in an arbitrary feature space, w(m) are linear combination weights, and \u00b5 is a label compatibility function. Each kernel k(m) is characterized by a symmetric, positive-definite precision matrix \u039b(m), which defines its shape.\nFor multi-class image segmentation and labeling we use contrast-sensitive two-kernel potentials, defined in terms of the color vectors Ii and Ij and positions pi and pj :\nk(fi, fj) = w (1) exp ( \u2212|pi \u2212 pj | 2\n2\u03b82\u03b1 \u2212 |Ii \u2212 Ij | 2 2\u03b82\u03b2 ) \ufe38 \ufe37\ufe37 \ufe38\nappearance kernel\n+w(2) exp ( \u2212|pi \u2212 pj | 2\n2\u03b82\u03b3 ) \ufe38 \ufe37\ufe37 \ufe38\nsmoothness kernel\n. (3)\nThe appearance kernel is inspired by the observation that nearby pixels with similar color are likely to be in the same class. The degrees of nearness and similarity are controlled by parameters \u03b8\u03b1 and \u03b8\u03b2 . The smoothness kernel removes small isolated regions [19]. The parameters are learned from data, as described in Section 4.\nA simple label compatibility function \u00b5 is given by the Potts model, \u00b5(xi, xj) = [xi 6= xj ]. It introduces a penalty for nearby similar pixels that are assigned different labels. While this simple model works well in practice, it is insensitive to compatibility between labels. For example, it penalizes a pair of nearby pixels labeled \u201csky\u201d and \u201cbird\u201d to the same extent as pixels labeled \u201csky\u201d and \u201ccat\u201d. We can instead learn a general symmetric compatibility function \u00b5(xi, xj) that takes interactions between labels into account, as described in Section 4."}, {"heading": "3 Efficient Inference in Fully Connected CRFs", "text": "Our algorithm is based on a mean field approximation to the CRF distribution. This approximation yields an iterative message passing algorithm for approximate inference. Our key observation is that message passing in the presented model can be performed using Gaussian filtering in feature space. This enables us to utilize highly efficient approximations for high-dimensional filtering, which reduce the complexity of message passing from quadratic to linear, resulting in an approximate inference algorithm for fully connected CRFs that is linear in the number of variables N and sublinear in the number of edges in the model."}, {"heading": "3.1 Mean Field Approximation", "text": "Instead of computing the exact distribution P (X), the mean field approximation computes a distribution Q(X) that minimizes the KL-divergence D(Q\u2016P ) among all distributions Q that can be expressed as a product of independent marginals, Q(X) = \u220f iQi(Xi) [10].\nMinimizing the KL-divergence, while constraining Q(X) and Qi(Xi) to be valid distributions, yields the following iterative update equation:\nQi(xi = l) = 1\nZi exp \u2212\u03c8u(xi)\u2212\u2211 l\u2032\u2208L \u00b5(l, l\u2032) K\u2211 m=1 w(m) \u2211 j 6=i k(m)(fi, fj)Qj(l \u2032)  . (4) A detailed derivation of Equation 4 is given in the supplementary material. This update equation leads to the following inference algorithm:\nAlgorithm 1 Mean field in fully connected CRFs\nInitialize Q . Qi(xi)\u2190 1Zi exp{\u2212\u03c6u(xi)} while not converged do . See Section 6 for convergence analysis\nQ\u0303 (m) i (l)\u2190 \u2211 j 6=i k\n(m)(fi, fj)Qj(l) for all m . Message passing from all Xj to all Xi Q\u0302i(xi)\u2190 \u2211 l\u2208L \u00b5 (m)(xi, l) \u2211 m w (m)Q\u0303 (m) i (l) . Compatibility transform Qi(xi)\u2190 exp{\u2212\u03c8u(xi)\u2212 Q\u0302i(xi)} . Local update normalize Qi(xi)\nend while\nEach iteration of Algorithm 1 performs a message passing step, a compatibility transform, and a local update. Both the compatibility transform and the local update run in linear time and are highly efficient. The computational bottleneck is message passing. For each variable, this step requires evaluating a sum over all other variables. A naive implementation thus has quadratic complexity in the number of variables N . Next, we show how approximate high-dimensional filtering can be used to reduce the computational cost of message passing to linear."}, {"heading": "3.2 Efficient Message Passing Using High-Dimensional Filtering", "text": "From a signal processing standpoint, the message passing step can be expressed as a convolution with a Gaussian kernel G\u039b(m) in feature space:\nQ\u0303 (m) i (l) = \u2211 j\u2208V k\n(m)(fi, fj)Qj(l)\u2212Qi(l)\ufe38 \ufe37\ufe37 \ufe38 message passing = [G\u039b(m) \u2297Q(l)] (fi)\ufe38 \ufe37\ufe37 \ufe38 Q\n(m) i (l)\n\u2212Qi(l). (5)\nWe subtract Qi(l) from the convolved function Q (m)\ni (l) because the convolution sums over all variables, while message passing does not sum over Qi.\nThis convolution performs a low-pass filter, essentially band-limiting Q (m)\ni (l). By the sampling theorem, this function can be reconstructed from a set of samples whose spacing is proportional to the standard deviation of the filter [20]. We can thus perform the convolution by downsampling Q(l), convolving the samples with G\u039b(m) , and upsampling the result at the feature points [16]. Algorithm 2 Efficient message passing: Q(m)i (l) = \u2211 j\u2208V k (m)(fi, fj)Qj(l)\nQ\u2193(l)\u2190 downsample(Q(l)) . Downsample \u2200i\u2208V\u2193Q (m) \u2193i (l)\u2190 \u2211 j\u2208V\u2193 k\n(m)(f\u2193i, f\u2193j)Q\u2193j(l) . Convolution on samples f\u2193 Q\n(m) (l)\u2190 upsample(Q(m)\u2193 (l)) . Upsample\nA common approximation to the Gaussian kernel is a truncated Gaussian, where all values beyond two standard deviations are set to zero. Since the spacing of the samples is proportional to the standard deviation, the support of the truncated kernel contains only a constant number of sample points. Thus the convolution can be approximately computed at each sample by aggregating values from only a constant number of neighboring samples. This implies that approximate message passing can be performed in O(N) time [16].\nHigh-dimensional filtering algorithms that follow this approach can still have computational complexity exponential in d. However, a clever filtering scheme can reduce the complexity of the convolution operation to O(Nd). We use the permutohedral lattice, a highly efficient convolution data\nstructure that tiles the feature space with simplices arranged along d+1 axes [1]. The permutohedral lattice exploits the separability of unit variance Gaussian kernels. Thus we need to apply a whitening transform f\u0303 = U f to the feature space in order to use it. The whitening transformation is found using the Cholesky decomposition of \u039b(m) into UUT. In the transformed space, the high-dimensional convolution can be separated into a sequence of one-dimensional convolutions along the axes of the lattice. The resulting approximate message passing procedure is highly efficient even with a fully sequential implementation that does not make use of parallelism or the streaming capabilities of graphics hardware, which can provide further acceleration if desired."}, {"heading": "4 Learning", "text": "We learn the parameters of the model by piecewise training. First, the boosted unary classifiers are trained using the JointBoost algorithm [21], using the features described in Section 5. Next we learn the appearance kernel parameters w(1), \u03b8\u03b1, and \u03b8\u03b2 for the Potts model. w(1) can be found efficiently by a combination of expectation maximization and high-dimensional filtering. Unfortunately, the kernel widths \u03b8\u03b1 and \u03b8\u03b2 cannot be computed effectively with this approach, since their gradient involves a sum of non-Gaussian kernels, which are not amenable to the same acceleration techniques. We found it to be more efficient to use grid search on a holdout validation set for all three kernel parameters w(1), \u03b8\u03b1 and \u03b8\u03b2 .\nThe smoothness kernel parameters w(2) and \u03b8\u03b3 do not significantly affect classification accuracy, but yield a small visual improvement. We found w(2) = \u03b8\u03b3 = 1 to work well in practice.\nThe compatibility parameters \u00b5(a, b) = \u00b5(b, a) are learned using L-BFGS to maximize the loglikelihood `(\u00b5 : I, T ) of the model for a validation set of images I with corresponding ground truth labelings T . L-BFGS requires the computation of the gradient of `, which is intractable to estimate exactly, since it requires computing the gradient of the partition function Z. Instead, we use the mean field approximation described in Section 3 to estimate the gradient of Z. This leads to a simple approximation of the gradient for each training image:\n\u2202\n\u2202\u00b5(a, b) `(\u00b5 : I(n), T (n)) \u2248 \u2212 \u2211 i T (n)i (a) \u2211 j 6=i k(fi, fj)T (n)j (b) + \u2211 i Qi(a) \u2211 j 6=i k(fi, fj)Qi(b),\n(6)\nwhere (I(n), T (n)) is a single training image with its ground truth labeling and T (n)(a) is a binary image in which the ith pixel T (n)i (a) has value 1 if the ground truth label at the ith pixel of T (n) is a and 0 otherwise. A detailed derivation of Equation 6 is given in the supplementary material.\nThe sums \u2211 j 6=i k(fi, fj)Tj(b) and \u2211 j 6=i k(fi, fj)Qi(b) are both computationally expensive to evaluate directly. As in Section 3.2, we use high-dimensional filtering to compute both sums efficiently. The runtime of the final learning algorithm is linear in the number of variables N ."}, {"heading": "5 Implementation", "text": "The unary potentials used in our implementation are derived from TextonBoost [19, 13]. We use the 17-dimensional filter bank suggested by Shotton et al. [19], and follow Ladicky\u0301 et al. [13] by adding color, histogram of oriented gradients (HOG), and pixel location features. Our evaluation on the MSRC-21 dataset uses this extended version of TextonBoost for the unary potentials. For the VOC 2010 dataset we include the response of bounding box object detectors [4] for each object class as 20 additional features. This increases the performance of the unary classifiers on the VOC 2010 from 13% to 22%. We gain an additional 5% by training a logistic regression classifier on the responses of the boosted classifier.\nFor efficient high-dimensional filtering, we use a publicly available implementation of the permutohedral lattice [1]. We found a downsampling rate of one standard deviation to work best for all our experiments. Sampling-based filtering algorithms underestimate the edge strength k(fi, fj) for very similar feature points. Proper normalization can cancel out most of this error. The permutohedral lattice allows for two types of normalizations. A global normalization by the average kernel strength\nk\u0302 = 1N \u2211 i,j k(fi, fj) can correct for constant error. A pixelwise normalization by k\u0302i = \u2211 j k(fi, fj) handles regional errors as well, but violates the CRF symmetry assumption \u03c8p(xi, xj) = \u03c8p(xj , xi). We found the pixelwise normalization to work better in practice."}, {"heading": "6 Evaluation", "text": "We evaluate the presented algorithm on two standard benchmarks for multi-class image segmentation and labeling. The first is the MSRC-21 dataset, which consists of 591 color images of size 320 \u00d7 213 with corresponding ground truth labelings of 21 object classes [19]. The second is the PASCAL VOC 2010 dataset, which contains 1928 color images of size approximately 500 \u00d7 400, with a total of 20 object classes and one background class [3]. The presented approach was evaluated alongside the adjacency (grid) CRF of Shotton et al. [19] and the Robust Pn CRF of Kohli et al. [9], using publicly available reference implementations. To ensure a fair comparison, all models used the unary potentials described in Section 5. All experiments were conducted on an Intel i7-930 processor clocked at 2.80GHz. Eight CPU cores were used for training; all other experiments were performed on a single core. The inference algorithm was implemented in a single CPU thread.\nConvergence. We first evaluate the convergence of the mean field approximation by analyzing the KL-divergence between Q and P . Figure 2 shows the KL-divergence between Q and P over successive iterations of the inference algorithm. The KL-divergence was estimated up to a constant as described in supplementary material. Results are shown for different standard deviations \u03b8\u03b1 and \u03b8\u03b2 of the kernels. The graphs were aligned at 20 iterations for visual comparison. The number of iterations was set to 10 in all subsequent experiments.\nMSRC-21 dataset. We use the standard split of the dataset into 45% training, 10% validation and 45% test images [19]. The unary potentials were learned on the training set, while the parameters of all CRF models were learned using holdout validation. The total CRF training time was 40 minutes. The learned label compatibility function performed on par with the Potts model on this dataset. Figure 3 provides qualitative and quantitative results on the dataset. We report the standard measures of multi-class segmentation accuracy: \u201cglobal\u201d denotes the overall percentage of correctly classified image pixels and \u201caverage\u201d is the unweighted average of per-category classification accuracy [19, 9]. The presented inference algorithm on the fully connected CRF significantly outperforms the other models, evaluated against the standard ground truth data provided with the dataset.\nThe ground truth labelings provided with the MSRC-21 dataset are quite imprecise. In particular, regions around object boundaries are often left unlabeled. This makes it difficult to quantitatively evaluate the performance of algorithms that strive for pixel-level accuracy. Following Kohli et al. [9], we manually produced accurate segmentations and labelings for a set of images from the MSRC-21 dataset. Each image was fully annotated at the pixel level, with careful labeling around complex boundaries. This labeling was performed by hand for 94 representative images from the MSRC21 dataset. Labeling a single image took 30 minutes on average. A number of images from this \u201caccurate ground truth\u201d set are shown in Figure 3. Figure 3 reports segmentation accuracy against this ground truth data alongside the evaluation against the standard ground truth. The results were obtained using 5-fold cross validation, where 45 of the 94 images were used to train the CRF pa-\nrameters. The unary potentials were learned on a separate training set that did not include the 94 accurately annotated images.\nWe also adopt the methodology proposed by Kohli et al. [9] for evaluating segmentation accuracy around boundaries. Specifically, we count the relative number of misclassified pixels within a narrow band (\u201ctrimap\u201d) surrounding actual object boundaries, obtained from the accurate ground truth images. As shown in Figure 4, our algorithm outperforms previous work across all trimap widths.\nPASCAL VOC 2010. Due to the lack of a publicly available ground truth labeling for the test set in the PASCAL VOC 2010, we use the training and validation data for all our experiments. We randomly partitioned the images into 3 groups: 40% training, 15% validation, and 45% test set. Segmentation accuracy was measured using the standard VOC measure [3]. The unary potentials were learned on the training set and yielded an average classification accuracy of 27.6%. The parameters for the Potts potentials in the fully connected CRF model were learned on the validation set. The\nfully connected model with Potts potentials yielded an average classification accuracy of 29.1%. The label compatibility function, learned on the validation set, further increased the classification accuracy to 30.2%. For comparison, the grid CRF achieves 28.3%. Training time was 2.5 hours and inference time is 0.5 seconds. Qualitative results are provided in Figure 5.\nLong-range connections. We have examined the value of long-range connections in our model by varying the spatial and color ranges \u03b8\u03b1 and \u03b8\u03b2 of the appearance kernel and analyzing the resulting classification accuracy. For this experiment, w(1) was held constant and w(2) was set to 0. The results are shown in Figure 6. Accuracy steadily increases as longer-range connections are added, peaking at spatial standard deviation of \u03b8\u03b1 = 61 pixels and color standard deviation \u03b8\u03b2 = 11. At this setting, more than 50% of the pairwise potential energy in the model was assigned to edges of length 35 pixels or higher. However, long-range connections can also propagate misleading information, as shown in Figure 7.\nDiscussion. We have presented a highly efficient approximate inference algorithm for fully connected CRF models. Our results demonstrate that dense pixel-level connectivity leads to significantly more accurate pixel-level classification performance. Our single-threaded implementation processes benchmark images in a fraction of a second and the algorithm can be parallelized for further performance gains.\nAcknowledgements. Philipp Kra\u0308henbu\u0308hl was supported in part by a Stanford Graduate Fellowship. We are grateful to Daphne Koller, Andrew Adams and Jongmin Baek for helpful discussions. Sergey Levine and Vangelis Kalogerakis provided comments on a draft of this paper."}], "references": [{"title": "Fast high-dimensional filtering using the permutohedral lattice", "author": ["A. Adams", "J. Baek", "M.A. Davis"], "venue": "Computer Graphics Forum, 29(2),", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Gaussian kd-trees for fast high-dimensional filtering", "author": ["A. Adams", "N. Gelfand", "J. Dolson", "M. Levoy"], "venue": "ACM Transactions on Graphics, 28(3),", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "The PASCAL Visual Object Classes (VOC) challenge", "author": ["M. Everingham", "L. Van Gool", "C.K.I. Williams", "J. Winn", "A. Zisserman"], "venue": "IJCV, 88(2),", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Cascade object detection with deformable part models", "author": ["P.F. Felzenszwalb", "R.B. Girshick", "D.A. McAllester"], "venue": "Proc. CVPR,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Class segmentation and object localization with superpixel neighborhoods", "author": ["B. Fulkerson", "A. Vedaldi", "S. Soatto"], "venue": "Proc. ICCV,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Object categorization using co-occurrence, location and appearance", "author": ["C. Galleguillos", "A. Rabinovich", "S. Belongie"], "venue": "Proc. CVPR,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Multi-class segmentation with relative location prior", "author": ["S. Gould", "J. Rodgers", "D. Cohen", "G. Elidan", "D. Koller"], "venue": "IJCV, 80(3),", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Multiscale conditional random fields for image labeling", "author": ["X. He", "R.S. Zemel", "M.A. Carreira-Perpinan"], "venue": "Proc. CVPR,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Robust higher order potentials for enforcing label consistency", "author": ["P. Kohli", "L. Ladick\u00fd", "P.H.S. Torr"], "venue": "IJCV, 82(3),", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": "MIT Press,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "What energy functions can be minimized via graph cuts? PAMI", "author": ["V. Kolmogorov", "R. Zabih"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "A hierarchical field framework for unified context-based classification", "author": ["S. Kumar", "M. Hebert"], "venue": "Proc. ICCV,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Associative hierarchical crfs for object class image segmentation", "author": ["L. Ladick\u00fd", "C. Russell", "P. Kohli", "P.H.S. Torr"], "venue": "Proc. ICCV,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Graph cut based inference with co-occurrence statistics", "author": ["L. Ladick\u00fd", "C. Russell", "P. Kohli", "P.H.S. Torr"], "venue": "Proc. ECCV,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J.D. Lafferty", "A. McCallum", "F.C.N. Pereira"], "venue": "Proc. ICML,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}, {"title": "A fast approximation of the bilateral filter using a signal processing approach", "author": ["S. Paris", "F. Durand"], "venue": "IJCV, 81(1),", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "RF) \u2013 random forest random field", "author": ["N. Payet", "S. Todorovic"], "venue": "Proc. NIPS.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Objects in context", "author": ["A. Rabinovich", "A. Vedaldi", "C. Galleguillos", "E. Wiewiora", "S. Belongie"], "venue": "Proc. ICCV,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture, layout, and context", "author": ["J. Shotton", "J.M. Winn", "C. Rother", "A. Criminisi"], "venue": "IJCV, 81(1),", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "The scientist and engineer\u2019s guide to digital signal processing", "author": ["S.W. Smith"], "venue": "California Technical Publishing,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1997}, {"title": "Sharing visual features for multiclass and multiview object detection", "author": ["A. Torralba", "K.P. Murphy", "W.T. Freeman"], "venue": "PAMI, 29(5),", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Random field model for integration of local information and global information", "author": ["T. Toyoda", "O. Hasegawa"], "venue": "PAMI, 30,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "Scene segmentation with crfs learned from partially labeled images", "author": ["J.J. Verbeek", "B. Triggs"], "venue": "Proc. NIPS,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 7, "context": "A common approach is to pose this problem as maximum a posteriori (MAP) inference in a conditional random field (CRF) defined over pixels or image patches [8, 12, 18, 19, 9].", "startOffset": 155, "endOffset": 173}, {"referenceID": 11, "context": "A common approach is to pose this problem as maximum a posteriori (MAP) inference in a conditional random field (CRF) defined over pixels or image patches [8, 12, 18, 19, 9].", "startOffset": 155, "endOffset": 173}, {"referenceID": 17, "context": "A common approach is to pose this problem as maximum a posteriori (MAP) inference in a conditional random field (CRF) defined over pixels or image patches [8, 12, 18, 19, 9].", "startOffset": 155, "endOffset": 173}, {"referenceID": 18, "context": "A common approach is to pose this problem as maximum a posteriori (MAP) inference in a conditional random field (CRF) defined over pixels or image patches [8, 12, 18, 19, 9].", "startOffset": 155, "endOffset": 173}, {"referenceID": 8, "context": "A common approach is to pose this problem as maximum a posteriori (MAP) inference in a conditional random field (CRF) defined over pixels or image patches [8, 12, 18, 19, 9].", "startOffset": 155, "endOffset": 173}, {"referenceID": 18, "context": "Basic CRF models are composed of unary potentials on individual pixels or image patches and pairwise potentials on neighboring pixels or patches [19, 23, 7, 5].", "startOffset": 145, "endOffset": 159}, {"referenceID": 22, "context": "Basic CRF models are composed of unary potentials on individual pixels or image patches and pairwise potentials on neighboring pixels or patches [19, 23, 7, 5].", "startOffset": 145, "endOffset": 159}, {"referenceID": 6, "context": "Basic CRF models are composed of unary potentials on individual pixels or image patches and pairwise potentials on neighboring pixels or patches [19, 23, 7, 5].", "startOffset": 145, "endOffset": 159}, {"referenceID": 4, "context": "Basic CRF models are composed of unary potentials on individual pixels or image patches and pairwise potentials on neighboring pixels or patches [19, 23, 7, 5].", "startOffset": 145, "endOffset": 159}, {"referenceID": 7, "context": "In order to improve segmentation and labeling accuracy, researchers have expanded the basic CRF framework to incorporate hierarchical connectivity and higher-order potentials defined on image regions [8, 12, 9, 13].", "startOffset": 200, "endOffset": 214}, {"referenceID": 11, "context": "In order to improve segmentation and labeling accuracy, researchers have expanded the basic CRF framework to incorporate hierarchical connectivity and higher-order potentials defined on image regions [8, 12, 9, 13].", "startOffset": 200, "endOffset": 214}, {"referenceID": 8, "context": "In order to improve segmentation and labeling accuracy, researchers have expanded the basic CRF framework to incorporate hierarchical connectivity and higher-order potentials defined on image regions [8, 12, 9, 13].", "startOffset": 200, "endOffset": 214}, {"referenceID": 12, "context": "In order to improve segmentation and labeling accuracy, researchers have expanded the basic CRF framework to incorporate hierarchical connectivity and higher-order potentials defined on image regions [8, 12, 9, 13].", "startOffset": 200, "endOffset": 214}, {"referenceID": 8, "context": "This limits the ability of region-based approaches to produce accurate label assignments around complex object boundaries, although significant progress has been made [9, 13, 14].", "startOffset": 167, "endOffset": 178}, {"referenceID": 12, "context": "This limits the ability of region-based approaches to produce accurate label assignments around complex object boundaries, although significant progress has been made [9, 13, 14].", "startOffset": 167, "endOffset": 178}, {"referenceID": 13, "context": "This limits the ability of region-based approaches to produce accurate label assignments around complex object boundaries, although significant progress has been made [9, 13, 14].", "startOffset": 167, "endOffset": 178}, {"referenceID": 17, "context": "Fully connected CRFs have been used for semantic image labeling in the past [18, 22, 6, 17], but the complexity of inference in fully connected models has restricted their application to sets of hundreds of image regions or fewer.", "startOffset": 76, "endOffset": 91}, {"referenceID": 21, "context": "Fully connected CRFs have been used for semantic image labeling in the past [18, 22, 6, 17], but the complexity of inference in fully connected models has restricted their application to sets of hundreds of image regions or fewer.", "startOffset": 76, "endOffset": 91}, {"referenceID": 5, "context": "Fully connected CRFs have been used for semantic image labeling in the past [18, 22, 6, 17], but the complexity of inference in fully connected models has restricted their application to sets of hundreds of image regions or fewer.", "startOffset": 76, "endOffset": 91}, {"referenceID": 16, "context": "Fully connected CRFs have been used for semantic image labeling in the past [18, 22, 6, 17], but the complexity of inference in fully connected models has restricted their application to sets of hundreds of image regions or fewer.", "startOffset": 76, "endOffset": 91}, {"referenceID": 8, "context": "(c) Classification produced by the Robust P CRF [9].", "startOffset": 48, "endOffset": 51}, {"referenceID": 16, "context": "(d) Classification produced by MCMC inference [17] in a fully connected pixel-level CRF model; the algorithm was run for 36 hours and only partially converged for the bottom image.", "startOffset": 46, "endOffset": 50}, {"referenceID": 15, "context": "This allows us to reduce the computational complexity of message passing from quadratic to linear in the number of variables by employing efficient approximate high-dimensional filtering [16, 2, 1].", "startOffset": 187, "endOffset": 197}, {"referenceID": 1, "context": "This allows us to reduce the computational complexity of message passing from quadratic to linear in the number of variables by employing efficient approximate high-dimensional filtering [16, 2, 1].", "startOffset": 187, "endOffset": 197}, {"referenceID": 0, "context": "This allows us to reduce the computational complexity of message passing from quadratic to linear in the number of variables by employing efficient approximate high-dimensional filtering [16, 2, 1].", "startOffset": 187, "endOffset": 197}, {"referenceID": 16, "context": "Figure 1(d) shows the results of approximate MCMC inference in fully connected CRFs on these images [17].", "startOffset": 100, "endOffset": 104}, {"referenceID": 10, "context": "We have also experimented with graph cut inference in the fully connected models [11], but it did not converge within 72 hours.", "startOffset": 81, "endOffset": 85}, {"referenceID": 14, "context": "in a set of cliques CG in G induces a potential \u03c6c [15].", "startOffset": 51, "endOffset": 55}, {"referenceID": 18, "context": "The smoothness kernel removes small isolated regions [19].", "startOffset": 53, "endOffset": 57}, {"referenceID": 9, "context": "Instead of computing the exact distribution P (X), the mean field approximation computes a distribution Q(X) that minimizes the KL-divergence D(Q\u2016P ) among all distributions Q that can be expressed as a product of independent marginals, Q(X) = \u220f iQi(Xi) [10].", "startOffset": 254, "endOffset": 258}, {"referenceID": 19, "context": "By the sampling theorem, this function can be reconstructed from a set of samples whose spacing is proportional to the standard deviation of the filter [20].", "startOffset": 152, "endOffset": 156}, {"referenceID": 15, "context": "We can thus perform the convolution by downsampling Q(l), convolving the samples with G\u039b(m) , and upsampling the result at the feature points [16].", "startOffset": 142, "endOffset": 146}, {"referenceID": 15, "context": "This implies that approximate message passing can be performed in O(N) time [16].", "startOffset": 76, "endOffset": 80}, {"referenceID": 0, "context": "structure that tiles the feature space with simplices arranged along d+1 axes [1].", "startOffset": 78, "endOffset": 81}, {"referenceID": 20, "context": "First, the boosted unary classifiers are trained using the JointBoost algorithm [21], using the features described in Section 5.", "startOffset": 80, "endOffset": 84}, {"referenceID": 18, "context": "The unary potentials used in our implementation are derived from TextonBoost [19, 13].", "startOffset": 77, "endOffset": 85}, {"referenceID": 12, "context": "The unary potentials used in our implementation are derived from TextonBoost [19, 13].", "startOffset": 77, "endOffset": 85}, {"referenceID": 18, "context": "[19], and follow Ladick\u00fd et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] by adding color, histogram of oriented gradients (HOG), and pixel location features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "For the VOC 2010 dataset we include the response of bounding box object detectors [4] for each object class as 20 additional features.", "startOffset": 82, "endOffset": 85}, {"referenceID": 0, "context": "For efficient high-dimensional filtering, we use a publicly available implementation of the permutohedral lattice [1].", "startOffset": 114, "endOffset": 117}, {"referenceID": 18, "context": "The first is the MSRC-21 dataset, which consists of 591 color images of size 320 \u00d7 213 with corresponding ground truth labelings of 21 object classes [19].", "startOffset": 150, "endOffset": 154}, {"referenceID": 2, "context": "The second is the PASCAL VOC 2010 dataset, which contains 1928 color images of size approximately 500 \u00d7 400, with a total of 20 object classes and one background class [3].", "startOffset": 168, "endOffset": 171}, {"referenceID": 18, "context": "[19] and the Robust P CRF of Kohli et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[9], using publicly available reference implementations.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "We use the standard split of the dataset into 45% training, 10% validation and 45% test images [19].", "startOffset": 95, "endOffset": 99}, {"referenceID": 18, "context": "We report the standard measures of multi-class segmentation accuracy: \u201cglobal\u201d denotes the overall percentage of correctly classified image pixels and \u201caverage\u201d is the unweighted average of per-category classification accuracy [19, 9].", "startOffset": 227, "endOffset": 234}, {"referenceID": 8, "context": "We report the standard measures of multi-class segmentation accuracy: \u201cglobal\u201d denotes the overall percentage of correctly classified image pixels and \u201caverage\u201d is the unweighted average of per-category classification accuracy [19, 9].", "startOffset": 227, "endOffset": 234}, {"referenceID": 8, "context": "[9], we manually produced accurate segmentations and labelings for a set of images from the MSRC-21 dataset.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] for evaluating segmentation accuracy around boundaries.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Segmentation accuracy was measured using the standard VOC measure [3].", "startOffset": 66, "endOffset": 69}], "year": 2012, "abstractText": "Most state-of-the-art techniques for multi-class image segmentation and labeling use conditional random fields defined over pixels or image regions. While regionlevel models often feature dense pairwise connectivity, pixel-level models are considerably larger and have only permitted sparse graph structures. In this paper, we consider fully connected CRF models defined on the complete set of pixels in an image. The resulting graphs have billions of edges, making traditional inference algorithms impractical. Our main contribution is a highly efficient approximate inference algorithm for fully connected CRF models in which the pairwise edge potentials are defined by a linear combination of Gaussian kernels. Our experiments demonstrate that dense connectivity at the pixel level substantially improves segmentation and labeling accuracy.", "creator": "Unknown"}}}