{"id": "1301.2307", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Decision-Theoretic Planning with Concurrent Temporally Extended Actions", "abstract": "d\u00e9cada We pi\u00f1eyro investigate strandzha a model for indulge planning reinaldo under uncertainty alaron with temporallyextended actions, where multiple actions 97.33 can be greybull taken concurrently camoys at reyne each decision win98 epoch. Our model is rs200 based sherard on pro-russian the options land framework, and brainstorms combines architeuthis it with factored state space sorel models, epinephrine where degroote the set of broomstick options controverisal can be ak-74 partitioned nagma into classes that kaiserlautern affectdisjoint endless state graine variables. We 25-room show that the set wujing of 219.6 decisionepochs riffled for yor concurrent options defines owc a semi - Markov decisionprocess, sunmicro if enson the underplaying underlying mugesera temporally extended samuni actions m72 being fappiano parallelized arerestricted to Markov options. This rupiahs property allows us to use -48 SMDPalgorithms gypsum for washing computing the value valkyria function over concurrentoptions. ogrin The concurrent options lexemes model allows ceratopsians overlapping execution y\u014dsh\u016b ofoptions gaurs in universalists order to 87.7 achieve sepp higher militarist performance chemeketa or in herriott order arbeiterpartei to performa minsi complex task. We mauritshuis describe arkansas-pine a stephenson simple astori experiment garnier using katzenell a clivia navigationtask populares which illustrates suppress how auray concurrent czarne options haimin results in a fugues faster planwhen rybkin compared to rutaremara the uhe case lodestone when only one dehlavi option vojnovic is taken nordnes at a time.", "histories": [["v1", "Thu, 10 Jan 2013 16:26:17 GMT  (1241kb)", "http://arxiv.org/abs/1301.2307v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["khashayar rohanimanesh", "sridhar mahadevan"], "accepted": false, "id": "1301.2307"}, "pdf": {"name": "1301.2307.pdf", "metadata": {"source": "CRF", "title": "Decision-Theoretic Planning with Concurrent Temporally Extended Actions", "authors": ["Khashayar Rohanimanesh", "Sridhar Mahadevan"], "emails": ["khash@cse.msu.edu", "mahadeva@cse.msu.edu"], "sections": null, "references": [{"title": "Exploiting structure in policy construction", "author": ["C. Boutilier", "M. Goldszmidt"], "venue": "In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence,", "citeRegEx": "Boutilier and Goldszmidt,? \\Q1995\\E", "shortCiteRegEx": "Boutilier and Goldszmidt", "year": 1995}, {"title": "Reinforcement learn\u00ad ing methods for continuous-time markov decision problems", "author": ["S. Bradtke", "M. Duff"], "venue": "Advances in Neural Information Process\u00ad ing Systems,", "citeRegEx": "Bradtke and Duff,? \\Q1995\\E", "shortCiteRegEx": "Bradtke and Duff", "year": 1995}, {"title": "Learning multidimensional control actions from delayed reinforcements", "author": ["P. Cichosz"], "venue": "Eighth Inter\u00ad national Symposium on System-Modelling-Control (SMC-8)", "citeRegEx": "Cichosz,? \\Q1995\\E", "shortCiteRegEx": "Cichosz", "year": 1995}, {"title": "Model minimization in markov decision processes", "author": ["T. Dean", "R. Givan"], "venue": "n Proceedings of the Fourteenth National Conference on Aritificial Intel\u00ad ligenceProceedings of AAAI", "citeRegEx": "Dean and Givan,? \\Q1997\\E", "shortCiteRegEx": "Dean and Givan", "year": 1997}, {"title": "Computing factored value functions for policies in structured mdps", "author": ["D. Koller", "R. Parr"], "venue": "16th International Joint Conference on Artificial Intelli\u00ad gence (IJCAI),", "citeRegEx": "Koller and Parr,? \\Q1999\\E", "shortCiteRegEx": "Koller and Parr", "year": 1999}, {"title": "How to dynamically merge markov decision processes", "author": ["S. Singh", "D. Cohn"], "venue": "Proceedings of NIPS", "citeRegEx": "Singh and Cohn,? \\Q1998\\E", "shortCiteRegEx": "Singh and Cohn", "year": 1998}, {"title": "Between MOPs and Semi-MDPs: A framework for tempo\u00ad ral abstraction in reinforcement learning", "author": ["R. Sutton", "D. Precup", "S. Singh"], "venue": "Artificial Intelligence,", "citeRegEx": "Sutton et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1999}], "referenceMentions": [{"referenceID": 6, "context": "We adopt the theoretical framework of options (Sutton et al., 1999) to model temporally extended actions, since it is both a well-developed rigorous framework that addresses planning under uncertainty with temporally extended actions, and it allows looking inside behaviors to im\u00ad prove composition of temporally extended actions.", "startOffset": 46, "endOffset": 67}, {"referenceID": 2, "context": "multi-dimensional vector action spaces (Cichosz, 1995) to planning with multiple simultaneous MDPs (Singh & Cohn, 1998), where the composite state space is the cross product of the state spaces of each individual", "startOffset": 39, "endOffset": 54}, {"referenceID": 6, "context": "Options are a generalization of primitive actions that include temporally extended courses of action in the context of reinforcement learning (Sutton et al., 1999).", "startOffset": 142, "endOffset": 163}, {"referenceID": 6, "context": "It has been shown earlier that the set of Markov options defines a semi-Markov decision process (SMDP) (Sutton et al., 1999).", "startOffset": 103, "endOffset": 124}, {"referenceID": 6, "context": "We adopt the rooms example from (Sutton et al., 1999) and we add doors in each of the four hallways (F igure 1).", "startOffset": 32, "endOffset": 53}, {"referenceID": 6, "context": "continuing the multi-option (Sutton et al., 1999).", "startOffset": 28, "endOffset": 49}], "year": 2011, "abstractText": "We investigate a model for planning un\u00ad der uncertainty with temporally extended ac\u00ad tions, where multiple actions can be taken concurrently at each decision epoch. Our model is based on the options framework, and combines it with factored state space mod\u00ad els, where the set of options can be parti\u00ad tioned into classes that affect disjoint state variables. We show that the set of deci\u00ad sion epochs for concurrent options defines a semi-Markov decision process, if the underly\u00ad ing temporally extended actions being paral\u00ad lelized are restricted to Markov options. This property allows us to use SMDP algorithms for computing the value function over concur\u00ad rent options. The concurrent options model allows overlapping execution of options in or\u00ad der to achieve higher performance or in or\u00ad der to perform a complex task. We describe a simple experiment using a navigation task which illustrates how concurrent options re\u00ad sults in a more optimal plan when compared to the case when only one option is taken at a time.", "creator": "pdftk 1.41 - www.pdftk.com"}}}