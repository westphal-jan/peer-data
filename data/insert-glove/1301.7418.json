{"id": "1301.7418", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2013", "title": "Flexible and Approximate Computation through State-Space Reduction", "abstract": "jobi In the poteau real world, n.w.a insufficient information, limited computation resources, metula and complex problem structures corrector often force an hayrettin autonomous piccolos agent to make a muenchner decision in time moughniyah less viikmae than hyzaar that required to aftonbladet solve countrified the amelita problem at valby hand completely. redway Flexible and 62.90 approximate zizzo computations are two overexcited approaches seisint to decision revelled making nygaard under chargeurs limited stereotypically computation liddington resources. beaujoire Flexible computation as helps adickes an agent 40-50 to overlie flexibly allocate limited gnash computation tgf-\u03b21 resources so that the weizenbaum overall system utility ommen is maximized. ten-mile Approximate computation 27-8 enables morard an caretaking agent milkovich to bubo find the tyranny best satisfactory gusle solution within boneta a nagyv\u00e1rad deadline. unfailing In non-royal this paper, we novospassky present disinheriting two state - 4,715 space ocal reduction methods nail for flexible and approximate computation: quantitative tamerlano reduction to deal hansman with acknowledges inaccurate heuristic information, and 108-104 structural reduction hts to broker-dealers handle complex google.org problem 34-36 structures. fordice These two methods can makishima be 18:26 applied successively badir to reliques continuously norwell improve acrid solution eavesdropping quality if uwb more computation jacquelin is available. vilasrao Our results show oft-repeated that these astp reduction cleare methods are antiquarianism effective sunnybrook and mets efficient, quatermass finding beguiristain better solutions nickerson with less aktyubinsk computation berrics than some existing bikash well - surface-mount known sigmoidal methods.", "histories": [["v1", "Wed, 30 Jan 2013 15:07:19 GMT  (357kb)", "http://arxiv.org/abs/1301.7418v1", "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)"]], "COMMENTS": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["weixiong zhang"], "accepted": false, "id": "1301.7418"}, "pdf": {"name": "1301.7418.pdf", "metadata": {"source": "CRF", "title": "Flexible and Approximate Computation through State-Space Reduction", "authors": ["Weixiong Zhang", "Marina del Rey"], "emails": ["zhang@isi.edu"], "sections": [{"heading": null, "text": "1\nIntroduction\nAn autonomous agent must overcome two major diffi culties in the real world. First, the available informa tion may not be sufficient or precise to allow the agent to make an optimal decision. Therefore, the agent has to depend upon the best approximate solution to the problem at hand. Second, the available computation resources, especially the computation time, are lim ited, which may force the agent to make a decision within a deadline.\nIn situation where computation resources are limited and a deadline must be met, flexible computation can assist an agent to allocate its computation resources\nin such a way that its overall performance or utility is maximized [5, 9, 14, 32] . The performance of the agent depends not only on the quality of its decision, but also on the amount of computation resources that it uses and the penalty introduced by response delay. This area of research is becoming more and more important and has drawn much attention recently [1, 2, 3] . An important issue of flexible computation is to find the relationship between deliberation, which is the process of searching for a high-quality decision, and the payoff of such a decision [5, 9, 14, 32]. This relationship is usually represented by a performance profile [32] . If the agent has a performance profile of a problem to be solved, it can estimate the amount of computation that it needs in order to find a solution with a satis factory quality, or vice versa. However, the amount of time allocated for reasoning is generally not known a priori for most applications. Thus, the key to flex ible computation is to construct anytime algorithms, which will be described in the next paragraph.\nFlexible computation is also closely related to and sometimes relies on approximation methods. Limited computation resources generally prohibit finding op timal solutions. In situations where seeking an op timal solution is not feasible, approximation meth ods enable an agent to find satisfactory solutions that can be found with a reasonable amount of computa tion. Approximation methods can be categorized into two classes. The first class finds solutions of qualities within a predefined acceptance bound [22]. However, finding approximate solutions with a predefined qual ity for some difficult problems, such as evaluation of Bayesian belief networks and graph coloring, still re mains NP-hard [7, 22]. In addition, algorithms in this class usually cannot generate a useful result before the end of execution. The second class of approximation methods consists of anytime algorithms [9] , which first finds a solution quickly, and then successively improves the quality of the best solution at hand as long as more computation is available. Therefore, these methods do not have to set their goals in advance. The chal lenge for anytime algorithms is how to find good solu tions as soon as possible. Many existing incremental refinement and iterative improvement methods have\n532 Zhang\nbeen used as anytime algorithms. One important any time algorithm is local search [23]. Starting with a low-quality solution, local search repeatedly improves the current solution with local perturbations until it reaches a local minimum. It then repeats this proce dure with a new starting solution if more computa tion is available. Another anytime algorithm is trun cated depth-first branch-and-bound (DFBnB) [15, 27]. Truncated DFBnB executes DFBnB until it exhausts all available computation. The best solution found so far is then an approximate solution.\nIn this paper, we present two general and efficient state-space reduction methods for flexible and approx imate computation. These two methods can be used to help allocate the amount of computation that is re quired in order to derive a decision of desired quality. Specifically, a state-space reduction is a process of re ducing a state space that is difficult to search into a less complex state space that is easier to explore. In other words, a state-space reduction leads search effort to the area of problem space that is promising to pro vide the best approximate solution with the available computation resources. After the reduction, the opti mal goal in the reduced state space, which is relatively easy to find, is found and used as an approximate solu tion to the original problem. By successively searching more and more complex state spaces, better solutions can be incrementally found.\nThe first reduction method, named as quantitative state-space reduction, is motivated to reduce compu tational complexity caused by the lack of sufficient or precise information about the problem to be solved. It treats inaccurate information as if it were more accu rate in order to reduce complexity. The second reduc tion method, named as structural state-space reduc tion, is motivated to reduce computational complex ity resulted from complex state-space structures. It abandons or postpones exploring nonpromising search avenues. Both quantitative and structural reduction methods can be applied repeatedly to incrementally provide better solutions with additional computation.\nThe idea of quantitative reduction was originally de veloped in [25, 31] for finding approximate solutions to combinatorial optimization problems. The basic idea of structural reduction can be traced back to beam search [4], an old heuristic technique for reduc ing search complexity. This heuristic technique was recently turned into a complete, anytime search algo rithm [28]. In this paper, we re-examine these ideas and techniques for flexible and approximate computa tion.\nThe paper is organized as follows. In Section 2, we briefly discuss state-space search. In Section 3 and Sec tion 4, we describe quantitative and structural state space reduction methods, respectively, along with ex perimental results. Finally, we conclude and discuss future work in Section 5.\noptimal goal\n4 10\nProblem solving can be considered as a search in a state space, in which nodes represent states and edges represent operators that map one state to another. A state-space tree is a special state space which has been used extensively. In a state-space tree, a leaf node is a goal state or a state that cannot lead to a solution, A node's cost is the estimate of the actual cost of solving the problem through that node. An important class of node costs is monotonic, in the sense that a node cost is monotonically nondecreasing with its depth in the search tree. For most real-world problems, monotonic node costs are available or can be easily derived [24].\nA state-space tree can also be viewed as if it has edge costs. The cost of an edge connecting two nodes is the cost difference between the child node and the par ent, or the cost of the operator mapping the parent to the child. A state space can be captured by an abstract model called incremental random tree, which has been used to analyze many state-space search al gorithms [17, 19, 29, 30]. This model is illustrated by Figure 1 and is defined as follows.\nDefinition 2.1 An incremental random tree T(b, d) is a tree with depth d, variable branching factors with mean b, and non-negative variable edge costs. A node cost is the sum of the edge costs along the path from the root to that node. An optimal goal is a node of minimum cost at depth d.\nBest-first search (BFS) and depth-first branch-and bound (DFBnB) [24], which are special cases of branch-and-bound (BnB), can be used to find an op timal goal. BFS maintains a partially expanded state space, and at each cycle expands a minimum-cost node among all those generated but not yet expanded, until an optimal goal is chosen for expansion. BFS is opti mal among all algorithms that are guaranteed to find an optimal goal node using the same cost function, up to tie breaking [11]. Therefore, the complexity of BFS is the complexity of the problem, in terms of the number of nodes generated. However, BFS usually re quires memory exponential in search depth, making it\nFlexible Computation by State-Space Reduction 533\nimpractical for large problems. DFBnB uses an upper bound u on the cost of an optimal goal. Starting at the root node, it chooses a most recently generated node, and then either expands this node if its cost is less than u, or prunes the node if its cost is greater than or equal to u. Whenever a new leaf node is found whose cost is less than u, u is revised to its cost. Since DFBnB only needs memory linear in the search depth, it is preferable for large problems in practice [30].\n2.2 Why state-space search is difficult\nTwo sources make a state space difficult to search. The first is the lack of sufficient or precise informa tion about the problem to be solved. It is known that a very limited search is required if an accurate heuris tic evaluation function is given. However, inaccurate heuristic functions generally prevents a problem from being solvable in polynomial time in terms of the prob lem size, even in an average case [24, 30].\nThe second source that leads to a difficult state space is the structure of a state space itself. For example, a state-space graph is more complex than a state-space tree. A concrete example is that a constraint network can be solved optimally in linear time if the network is tree structured [10], while finding solutions of a con straint network is NP-complete in general [18].\n3 Quantitative State-Space Reduction\nQuantitative state-space reduction was motivated to deal with computational complexity introduced by the lack of sufficient or precise information about the prob lem to be solved. The idea is to treat inaccurate heuris tic information as if it were accurate, so as to speed up search process with a penalty on solution quality.\n3.1 Phase transition of state-space search\nThe idea to treat an inaccurate heuristic function as an accurate one stems in a phase transition of state space search. Consider the computational behavior of BFS and DFBnB on an incremental random tree. Let p0 be the probability that an edge has a cost of zero, and b be the mean branching factor. Then bpo is the expected number of children of a node whose costs are the same as that of their parent, which are referred to as same-cost children of the node.\nTheorem 3.1 [17, 19, 30] On an incremental random tree T(b, d), as d---> oo, {1} when bpo < 1, both BFS and DFBnB generate B(! ) nodes on average for some constant /, 1 < 1 :::; b, (2} when bpo = 1, BFS gen erates B(d2) nodes and DFBnB generates O(d3) nodes on average, and (3) when bp0 > 1, BFS generates B(d) nodes and DFBnB generates O(d2) nodes on average.\nFollowing the optimality of BFS [11], Theorem 3.1 means that the expected complexity of finding an opti-\n\"' 1.0 IU 100 \"' IU .... 0.8 \"' bp0\ufffd 1 0 u I polynomial region 8 IU 0.6 N .... 0 g 0.4 \ufffd 8 0.2 bp0< 1 Q. II exponential region 0 0.00 Q. 5 10 15 20 mean branching factor b\nFigure 2: Complexity transition of state-space search.\n\"' 1.0 ,..,...---,r-----,r-----.----. \ufffd 'til 0.8 0 u \ufffd '0 c \ufffd e Q. II 0.6 0.4 0.2 polynomial region\nPo \u2022 exponential regtfC' omn-----.J Q.o 0.00 5 10 15 20\nmean branching factor b\nFigure 3: Reducing a difficult problem to an easy one.\nmal goal experiences an abrupt transition, from expo nential to polynomial in the search depth. This phe nomenon is similar to a phase transition, which is a dramatic change to a problem property as a control parameter changes across a critical point. A simple example of a phase transition is that water changes from a solid phase to a liquid phase when the temper ature rises from below the freezing point to above that point. This complexity transition is studied in great detail in [30] and is illustrated by Figure 2.\n3.2 Quantitative state-space reduction\nQuantitative reduction reduces a difficult state space in the exponential region of Figure 2 into an easy one in the polynomial region. To this end, we artificially increase the expected number of same-cost children bpo of an incremental tree T(b, d). This can be done by raising Po, as shown in Figure 3, by artificially setting some non-zero edge costs to zero. By doing this, we also change resulting node costs accordingly.\nBy setting a nonzero edge cost to zero, we actually treat an inaccurate heuristic evaluation function as if it were relatively more \"accurate\". The accuracy of a heuristic evaluation can be measured by the cost of\n534 Zhang\n-\nin\n-l\nit\n\u00ab:.\nial\n_\ne\n_\nd\n_\ng\n, .....\ne-\n-\nco\n_\ns\n_\nt d\n-\ne\n-\nns\n-\nit\n_\ny\n-:--\n-\n\"\"\"- pl\ufffd \ufffd\ufffd< (a) adj usting an edge-cost density\nthe optimal goal node of a state space. The smaller the cost of an optimal goal node, the more accurate the evaluation function [30]. The cost of an optimal goal node in the reduced state space is no larger than the cost of an optimal goal node in the original state space, because quantitative reduction reduces some edge costs to zero. Thus, the heuristic evaluation of the reduced state space is relatively more \"accurate\" than that of the original state space. In other words, this reduction gives rise to a new heuristic evaluation function with a quantitatively higher quality, thus the name quantitative reduction.\nHowever, setting a nonzero edge cost to zero causes the problem of loosing heuristic information embedded in heuristic evaluation function. In order to minimize the amount of information lost and to improve the expected solution quality, we only set to zero those edge costs that are below a particular value c:. Given an incremental tree T(b, d) and a value of c:, we call the tree generated by quantitative reduction an c:-tree Te(b, d). An c:-tree is still an incremental tree, but with an adjusted edge-cost distribution, i.e., an increased probability of zero-cost edges. Figure 4( a) illustrates an edge-cost density function and its adjusted density function for a given c:. Figure 4(b) shows a tree T(b = 2, d = 2) and its corresponding reduced tree Te(b = 2, d = 2) with c: = 0.25. Moreover, the special c: that reduces a state space to one on the transition boundary (see Figure 3) is called c:*.\nAfter the reduction, best-first search (BFS) or depth first branch-and-bound (DFBnB) can be used to find an optimal goal node of the c:-tree, and return the ac tual value of this goal node in the original state space. For notational simplicity, we refer to BnB (BFS or DF BnB) using quantitative reduction as c:-BnB (c:-BFS or c:-DFBnB). The expected performance of c:*-BnB is summarized in the following theorem.\nTheorem 3.2 [25, 31] On an incremental tree T(b, d) with bpo < 1, as d--+ oo, c:*-BnB runs in an expected time that is at most cubic in d, and finds a goal whose expected relative solution cost error is almost surely a constant less than or equal to ( >.j a - 1), where a is a constant, and>.= E[edge cost x J x \ufffd c:*].\nA useful and important feature of quantitative reduc tion is a tradeoff between the running time of c:-BnB and the solution quality. Solutions with higher costs (lower quality) can be produced with less computation by using a larger value of c:, on average. Similarly, so lutions with lower costs (higher quality) can be gen erated with greater computation by using a smaller value of c:, on average.\n3.3 Performance of quantitative reduction\nWe have applied quantitative reduction to several combinatorial optimization problems, including the Traveling Salesman Problem (TSP) and constraint satisfaction problems [23]. We now report our re sults on the asymmetric TSP (ATSP). Given n cities, {1, 2, 3, . . \u00b7,n}, and a matrix (c;,j) of intercity costs that defines a between each pair of cities, the TSP is to find a minimum-cost tour that visits each city ex actly once and returns to the starting city. When ( c;,j) is asymmetric, i.e., the cost from city i to city j is not necessarily equal to that from j to i, the problem is referred to as the ATSP.\nThe best cost function to the ATSP is the assignment problem [23], which is a relaxation of the ATSP since the assignments do not need to form a single tour, but instead can form a collection of disjoint subtours. If the solution to the assignment problem happens to be a single complete tour, it is also the solution to the ATSP. When the solution to the assignment problem is not a complete tour, it is decomposed, generating subproblems. In our implementation of DFBnB, we adopted Carpaneto and Toth's [6] method to generate subproblems.\nTo set the value of c:*, we need information of node\nFlexible Computation by State-Space Reduction 535\nbranching factors and edge costs in state space. We use an online sampling method to empirically calcu late the node branching factors and distribution of the edge costs. Consider DFBnB, the algorithm we used in our implementation. DFBnB can take all nodes generated in the process of reaching the first leaf node as samples, and use them to estimate the branching factor and edge-cost distribution. These estimates are then used to calculate a value for c:*. As the search proceeds, the estimates of the branching factor and edge-cost distribution can be refined and used to up date the value of c:* .\nWe compared c:* -DFBnB with local search for the ATSP [16]. The average running time of local search is longer than that of c:-DFBnB on four different prob lem structures we considered. Figure 5 shows the re sults on the ATSP with ( Ci,j) uniformly selected from {0, 1, \u00b7 \u00b7 \u00b7 , i x j}, which are known to be very difficult for BnB using the assignment problem evaluation func tion [20]. Each data point in Figure 5 is averaged over 100 problems, ranging from 100 cities to 1,000 cities. The results show that c:-DFBnB outperforms local search: it runs faster and finds better solutions.\n3.4 Iterative quantitative reduction '\\ Quantitative reduction can be applied successi\ufffdly. BnB can search for better solutions with a series\\ of quantitative reductions, with the value of c: redu\ufffded after each iteration. The resulting algorithm ls-cailed iterative c:-BnB. Iterative c:-BnB can detect its termi nation conditions, can continuously improve the qual ity of the current best solution with more computation, and can ultimately find the optimal solution.\nIterative quantitative reduction can be used to con struct an anytime algorithm. Combined with BFS, it turns BFS into an anytime algorithm. BFS itself does not provide a solution before its termination. By using quantitative reduction, BFS in one iteration searches a small portion of the original state space and is able to find a suboptimal goal node quickly. BFS in sub sequent iterations finds better goal nodes by exploring larger portions of the state space.\nIterative quantitative reduction can also improve the anytime performance of DFBnB, which is an anytime algorithm by nature. To see this, we examined the per formance profile of iterative quantitative reduction. A performance profile is usually defined by the quality of the solution found and the penalty caused by a re sponse delay. To simplify our discussion and due to the fact that the penalty of a response delay is usu ally application dependent, we only consider solution quality in performance profile in the rest of this pa per. The solution quality is measured by the error of a solution cost relative to the optimal cost. Denote prof(A, t) as the performance profile of algorithm A. We define prof( A, t) as\nprof( A, t) = 1- error( A, t), (1)\n(a) incremental random tree\n1.0 0.9 iterative\nE-DFBnB /oFBnB .2 0.8 0::: 8 0.7 I Q, 8 0.6 i a 0.5 e .g 0.4 edge costs from ., {0,1,2, ... , zt6_1} Q, 0.3\nb=10,d=20.\n0.1 102 103 104 105 number of node expansions\nwhere error( A, t) is the error of solution cost of A at time t relative to the optimal solution cost. During the execution of A, prof(A, t) :::; 1; and at the end of its execution, prof( A, t) = 1. To compare anytime performance of iterative \u00a3 DFBnB with that of DFBnB, we experimented on in cremental random trees and the ATSP. The first iter ation of c:-DFBnB uses c:*, whose value was learned by the online sampling method. A subsequent iteration uses c: whose value is half of that used in the previous iteration. Figure 6(a) is the result on incremental ran dom trees T(b = 10, d = 20) with edge costs uniformly chosen from {0, 1, 2, \u00b7 \u00b7 \u00b7 , 216- 1}. The result is aver aged over 1000 instances . Figure 6(b) shows the result on 500-city ATSP's, averaged over 100 random prob lem instances. The horizontal axis is the CPU time on a Sun4 sparc460 workstation. Figure 6 shows that iter ative c:-DFBnB is superior over DFBnB, finding better solutions sooner on average.\n4 Structural State-Space Reduction\nAs mentioned in Section 2, the second source that makes a state space difficult to search is the state-space\n536 Zhang\ninitial edge-cost density adjusted edge-cost density\n\ufffd- \ufffdLp !P ( a) adjusting an edge-cost density\nstructure itself. Structural state-space reduction was motivated to simplify a complex state-space structure so that high quality solutions can be found quickly.\n4.1 Structural state-space reduction\nTo simplify our discussion, we only consider state space tree, since a state-space graph can be repre sented by state-space tree. Consider again an incre mental search tree. Intuitively, a large edge cost is more likely to lead to large costs of nodes generated below this edge, since a node cost is the sum of the edge costs leading to it. Symmetric to quantitative reduction, we can artificially set edge costs that are greater than a parameter o to infinity. By doing this, we actually prune some search avenues, so as to gen erate a simplified state space with fewer nodes. This reduction may change the structure of a state space being explored, thus the name structural state-space reduction.\nAfter a structural reduction, BFS or DFBnB can be used to find an optimal goal node of the reduced state space and return this goal node and its cost as the result. BFS or DFBnB using structural reduction is referred to as c5-BFS or c5-DFBnB, respectively.\nCompared to the original state space, the reduced one has an adjusted edge-cost distribution. Figure 7(a) shows an edge-cost density function and its adjusted density function for a given c5. we call a tree reduced from an incremental tree a c5-tree T6. Figure 7(b) shows an incremental tree T(b = 2, d = 2) and its corresponding c5-tree T6(b = 2, d = 2) with 8 = 0.65. However, structural reduction is a two-edged sword. On one side, it reduces the amount of search by re ducing node branching factors. On the other side, it runs the risk of missing a goal. The reason that struc tural reduction may not find a goal node at all is that it abandons too many search alternatives and create\ndeadend nodes, the ones that do not have a child node. It turns out that the deadend nodes in state space have a great impact on the possibility that structural reduc tion can find a goal. A direct, but partial remedy to the failure of reaching a goal node is to keep one child node when all children of a node were to be pruned. This can greatly increase the possibility that structural reduction find a solution. To find a high quality goal node, the child node with the minimum cost among all the children of a node should be kept.\n4.2 Iterative structural reduction\nThe biggest drawback of structural reduction is that it may fail to find a solution even if one exists. There are also situations where the solution found by structural reduction has a low quality. To overcome these diffi culties, we can apply structural reduction in iterations, using a larger value of c5 after each iteration. This al lows us to explore increasingly larger and more com plex state spaces in order to find better solutions. Iter ative structural reduction terminates under one of the following two situations. First, when a satisfied goal is found, it can quit. Second, if no pruning from struc tural reduction has been applied in an iteration, the algorithm can terminate with an optimal goal. This is because the last iteration runs the underlying search method with no extra pruning from structural reduc tion, and thus finds an optimal goal node.\nSimilar to iterative quantitative reduction, iterative structural reduction can turn BFS into an anytime al gorithm. In the rest of this section, we compare the anytime performance of iterative 8-DFBnB to that of DFBnB, using performance profile of (1).\nWe used online sampling method to learn the edge cost distribution and to compute the value of c5. With this sampling method, the first iteration of structural re duction does not abandon a node until a certain num ber of nodes have been generated. In our implementa tion, structural reduction does not prune a node until it has reached the first leaf node. All the nodes gen erated in the process of reaching the first leaf node are used as initial samples for computing an empirical distribution. Furthermore, using the empirical distri bution of node-cost differences, we can set parameter c5. In our experiments, the initial c5 is set to a value 81 such that a node-cost difference is less than 01 with probability p equal to 0.1. The next iteration increases probability p by 0.1, and so forth, until no reduction has been applied in the latest iteration or probability p is greater than 1.\nWe compared c5-DFBnB against DFBnB on maxi mum 3-satisfiability (3-Sat) [12] using a variation of Davis-Putnam method [8]. We generated maximum 3-Sat problem instances by randomly selecting three variables and negating them with probability 0.5 for each clause. Duplicate clauses were removed. The problem instances we used have a large ratio of the number of clauses to the number of variables (clause\nFlexible Computation by State-Space Reduction 537\ntooF' I o.95\ufffd 1\n\ufffd 0.9+ 1 e- I \ufffd 0.85 \ufffd 0.80 if \ufffd I,\n(a) maxim um 3-satisf'mbility\nj o-DFBnB\nI Maximum 3-Sat with\n30 variables and 450 clauses 0.75 I 0.70L_L _ _(__L___ _L_ _ _J_ _ _L____J _ __J 0 1 2 3 4 5 6\nNumber of nodes generated (x 105 )\n(b) the symmetric TSP\n0.9960=-.J--'---'----\"----'------'-=' 2 4 6 8 10 12 Number of 1-trees solved ( xl03)\nFigure 8: Iterative 6-DFBnB versus DFBnB.\nto variable ratio), since random 3-Sat problems with a small clause-to-variable ratio are generally satisfi able [21). Figure 8( a) shows the experimental result of on 3-Sat with 30 variables and 450 clauses, aver aged over 100 random problem instances. Figure 8(a) shows that iterative 6-DFBnB significantly improves the anytime performance of DFBnB, finding better solutions sooner. For instance, with total of 20,000 node generations, the average error of solution found relative to the optimal is 4.1% (profile=0.959) from iterative 6-DFBnB, while the average error is 15.9% (profile=0.841) from DFBnB.\nWe also compared iterative 6-DFBnB against DFBnB on the symmetric TSP (STSP), in which the cost from city i to city j is the same as that of from j to i. In our implementation, we use Held-Karp lower bound function [13) to compute node costs. This cost func tion iteratively computes a Lagrangian relaxation on the STSP, with each step constructing a 1-tree. A 1- tree is a minimum spanning tree (MST) [23) on n - 1 cities plus the two shortest edges from the city not in the MST to two cities in the MST. Note that a complete TSP tour is a 1-tree. If no complete TSP tour has been found after a predefined number of steps\nof Lagrangian relaxation, which is n/2 in our experi ment, the problem is decomposed into at most three subproblems using the Volgenant and Jonker's branch ing rule [26). We generated STSP problem instances by uniformly choosing a cost between two cities from { 0, 1, 2, . \u00b7 \u00b7 , 232-1}. Figure 8(b) shows the experimen tal result on 100-city random STSPs, averaged over 100 instances. It shows that the anytime performance of iterative 6-DFBnB is superior to that of DFBnB.\n5 Conclusions and Future Work\nWe have presented two state-space reduction meth ods for flexible and approximate computation. The main idea is to reduce a state space that is difficult to search into a state space that is easy to explore. Af ter a reduction, the optimal goal in the reduced state space is found and used as an approximate solution to the original problem. Specifically, we have developed quantitative state-space reduction to treat inaccurate information as if it were more accurate to reduce com putational complexity, and structural state-space re duction to deal with complex state space structures by abandoning or postponing exploration of some non promising search avenues. We have also described how these two methods can be applied repeatedly to incre mentally find better solutions with additional compu tation. Our experimental results show that the state space reduction techniques are (a) general, which can be applied to different problem domains due to the generality of state-space representation; (b) effective for approximation, finding better solution with less amount of computation than some existing approxi mation methods on combinatorial optimization prob lems such as maximum 3-Satisfiability and the Trav eling Salesman Problem; (c) and efficient for flexible computation, which provides a means to trade com putation time for solution quality and to continuously improve solution quality with additional computation.\nThe current version of structural reduction is relatively rigid, in the sense that it will prune a branch if its cost is greater than a predefined value 6. Alternatively, we may set edge costs that are larger than 8 to a large, non-infinity value to postpone the exploration of the subtrees underneath the edges.\nQuantitative reduction and structural reduction are orthogonal and complementary. We are currently com bining these two reduction methods to deal with high computational complexity caused by both inaccurate heuristic information and complex problem structures.\nAcknowledgments\nThis work was partially funded by NSF Grant IRI9619554. Thanks to Joe Pemberton and Rich Korf for collaboration and discussions related to heuristic search and phase transitions.\n538 Zhang\nReferences\n[1 J AAAI Fall Symposium on Rational Agency; Cam bridge, MA, 1995. AAAI.\n[2] IJCAI-95 Workshop on Anytime Algorithms and Deli beration Scheduling, Montreal, Canada, Aug. 1995.\n(3] AAAI Fall Symposium on Flexible Computation in Intelligent Systems, Cambridge, MA, 1996. A A AI.\n[4) R. Bisiani. Search, beam. In S. C. Shapiro, edi tor, Encyclopedia of Artificial Intelligence, pages 1467-1468. Wiley-Interscience, New York, 2nd edition, 1992.\n[5] M. Boddy and T. Dean. Deliberation scheduling for problem solving in time-constrained environ ments. Artificial Intelligence, 67:245-285, 1994.\n[6] G. Carpaneto and P. Toth. Some new branching and bounding criteria for the asymmetric trav eling salesman problem. Management Science, 26:736-743, 1980.\n[7) P. Dagum and M. Luby. Approximating prob abilistic inference in bayesian belief networks is NP-hard. Artificial Intelligence, 60:141-153, 1993.\n[8] D. Davis and H. Putnam. A computing procedure for quantification theory. JACM, 7:201-215, 1960.\n[9] T. Dean and M. Boddy. An analysis of time dependent planning. In Proc. AAAI-88, pages 49-54, St. Paul, MN, Aug. 1988.\n[10) R. Dechter. Constraint networks. In S. C. Shapiro, editor, Encyclopedia of Artificial Intel ligence, pages 276-285. Wiley-Interscience, New York, 2 edition, 1992.\n[11] R. Dechter and J. Pearl. Generalized best-first search strategies and the optimality of A*. JACM, 32:505-536, 1985.\n[12] M. R. Garey and D. S. Johnson. Computers and Intractability: A Guide to the Theory of NP Completeness. Freeman, New York, NY, 1979.\n[13] M. Held and R. M. Karp. The traveling salesman problem and minimum spanning trees: Part ii. Mathematical Programming, 1:6-25, 1971.\n[14) E. J. Horvitz. Reasoning about beliefs and ac tions under computational resource constraints. In Proc. 3rd Workshop on UAI, 1987.\n[15] T. Ibaraki, S. Muro, T. Murakami, and T. Hasegawa. Using branch-and-bound algo rithms to obtain suboptimal solutions. Zeitchrift fur Operations Research, 27:177-202, 1983.\n[16] P. C. Kanellakis and C. H. Papadimitriou. Lo cal search for the asymmetric traveling salesman problem. Operations Research, 28:1086-1099, 1980.\n[17] R. M. Karp and J. Pearl. Searching for an opti mal path in a tree with random costs. Artificial Intelligence, 21:99-117, 1983.\n[18] A. K. Mackworth. Consistency in networks of re lations. Artificial Intelligence, 8:99-118, 1977.\n[19] C. J. H. McDiarmid and G. M. A. Provan. An expected-cost analysis of backtracking and non backtracking algorithms. In Proc. IJCAI-91, pages 172-177, Sydney, Australia, August 1991.\n[20] D. L. Miller and J. F. Pekny. Exact solution of large asymmetric traveling salesman problems. Science, 251:754-761, 1991.\n[21] D. Mitchell, B. Selman, and H. Levesque. Hard and easy distributions of SAT problems. In Proc. AAAI-92, pages 459-465, July 1992.\n[22] R. Motwani. Lecture notes on approximation al gorithms. Technical Report STAN-CS-92-1435, Department of Computer Science, Stanford Uni versity, 1992.\n[23] C. H. Papadimitriou and K. Steiglitz. Combina torial Optimization: Algorithms and Complexity. Prentice-Hall, Englewood Cliffs, NJ, 1982.\n[24] J. Pearl. Heuristics: Intelligent Search Strategies for Computer Problem Solving. Addison-Wesley, Reading, MA, 1984.\n[25] J. C. Pemberton and W. Zhang. Epsilontransformation: Exploiting phase transitions to solve combinatorial optimization problems. Arti ficial Intelligence, 81:297-325, 1996.\n[26] T. Volgenant and R. Jonker. A branch and bound algorithm for the symmetric Traveling Salesman problem based on the 1-tree relaxation. European J. of Operations Research, 9:83-89, 1982.\n[27] W. Zhang. Truncated branch-and-bound: A case study on the asymmetric TSP. In Working Notes of AAAI 1993 Spring Symp.: AI and NP-Hard Problems, pages 160-166, Stanford, CA, 1993.\n[28] W. Zhang. Complete anytime beam search. In Proc. AAAI-98, Madison, WI, July 1998.\n[29] W. Zhang and R. E. Korf. Depth-first vs. best first search: New results. In Proc. AAAI-93, pages 769-775, Washington, D.C., July 1993.\n[30] W. Zhang and R. E. Korf. Performance of linear space search algorithms. Artificial Intelligence, 79:241-292, 1995.\n[31] W. Zhang and J. C. Pemberton. Epsilontransformation: Exploiting phase transitions to solve combinatorial optimization problems - Ini tial results. In Proc. AAAI-94, Seattle, WA, July 1994.\n[32] S. Zilberstein and S. J. Russell. Optimal compo sition of real-time systems. Artificial Intelligence, 82:181-213, 1996."}], "references": [{"title": "Deliberation scheduling for problem solving in time-constrained environ\u00ad ments", "author": ["M. Boddy", "T. Dean"], "venue": "Artificial Intelligence,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1994}, {"title": "Some new branching and bounding criteria for the asymmetric trav\u00ad eling salesman problem", "author": ["G. Carpaneto", "P. Toth"], "venue": "Management Science,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1980}, {"title": "Approximating prob\u00ad abilistic inference in bayesian belief networks is NP-hard", "author": ["P. Dagum", "M. Luby"], "venue": "Artificial Intelligence,", "citeRegEx": "Dagum and Luby.,? \\Q1993\\E", "shortCiteRegEx": "Dagum and Luby.", "year": 1993}, {"title": "A computing procedure for quantification theory", "author": ["D. Davis", "H. Putnam"], "venue": "JACM, 7:201-215,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1960}, {"title": "An analysis of time\u00ad dependent planning", "author": ["T. Dean", "M. Boddy"], "venue": "In Proc. AAAI-88,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1988}, {"title": "Generalized best-first search strategies and the optimality of A", "author": ["R. Dechter", "J. Pearl"], "venue": "JACM, 32:505-536,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1985}, {"title": "Computers and Intractability: A Guide to the Theory of NP\u00ad Completeness", "author": ["M.R. Garey", "D.S. Johnson"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1979}, {"title": "The traveling salesman problem and minimum spanning trees: Part ii", "author": ["M. Held", "R.M. Karp"], "venue": "Mathematical Programming,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1971}, {"title": "Reasoning about beliefs and ac\u00ad tions under computational resource constraints", "author": ["E.J. Horvitz"], "venue": "In Proc. 3rd Workshop on UAI,", "citeRegEx": "Horvitz.,? \\Q1987\\E", "shortCiteRegEx": "Horvitz.", "year": 1987}, {"title": "Using branch-and-bound algo\u00ad rithms to obtain suboptimal solutions", "author": ["T. Ibaraki", "S. Muro", "T. Murakami", "T. Hasegawa"], "venue": "Zeitchrift fur Operations Research,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1983}, {"title": "Lo\u00ad cal search for the asymmetric traveling salesman problem", "author": ["P.C. Kanellakis", "C.H. Papadimitriou"], "venue": "Operations Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1980}, {"title": "Searching for an opti\u00ad mal path in a tree with random costs", "author": ["R.M. Karp", "J. Pearl"], "venue": "Artificial Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1983}, {"title": "Consistency in networks of re\u00ad lations", "author": ["A.K. Mackworth"], "venue": "Artificial Intelligence,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1977}, {"title": "An expected-cost analysis of backtracking and non\u00ad backtracking algorithms", "author": ["C.J.H. McDiarmid", "G.M.A. Provan"], "venue": "In Proc. IJCAI-91,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1991}, {"title": "Exact solution of large asymmetric traveling salesman problems", "author": ["D.L. Miller", "J.F. Pekny"], "venue": "Science, 251:754-761,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1991}, {"title": "Hard and easy distributions of SAT problems", "author": ["D. Mitchell", "B. Selman", "H. Levesque"], "venue": "In Proc. AAAI-92,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1992}, {"title": "Lecture notes on approximation al\u00ad gorithms", "author": ["R. Motwani"], "venue": "Technical Report STAN-CS-92-1435,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1992}, {"title": "Combina\u00ad torial Optimization: Algorithms and Complexity", "author": ["C.H. Papadimitriou", "K. Steiglitz"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1982}, {"title": "Heuristics: Intelligent Search Strategies for Computer Problem Solving", "author": ["J. Pearl"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1984}, {"title": "Epsilontransformation: Exploiting phase transitions to solve combinatorial optimization problems", "author": ["J.C. Pemberton", "W. Zhang"], "venue": "Arti\u00ad ficial Intelligence,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1996}, {"title": "A branch and bound algorithm for the symmetric Traveling Salesman problem based on the 1-tree relaxation", "author": ["T. Volgenant", "R. Jonker"], "venue": "European J. of Operations Research,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1982}, {"title": "Truncated branch-and-bound: A case study on the asymmetric TSP", "author": ["W. Zhang"], "venue": "In Working Notes of AAAI 1993 Spring Symp.: AI and NP-Hard Problems,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1993}, {"title": "Complete anytime beam search", "author": ["W. Zhang"], "venue": "In Proc. AAAI-98,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1998}, {"title": "Depth-first vs. best\u00ad first search: New results", "author": ["W. Zhang", "R.E. Korf"], "venue": "In Proc. AAAI-93,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1993}, {"title": "Performance of linear\u00ad space search algorithms", "author": ["W. Zhang", "R.E. Korf"], "venue": "Artificial Intelligence,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1995}, {"title": "Epsilontransformation: Exploiting phase transitions to solve combinatorial optimization problems - Ini\u00ad tial results", "author": ["W. Zhang", "J.C. Pemberton"], "venue": "In Proc. AAAI-94,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1994}, {"title": "Optimal compo\u00ad sition of real-time systems", "author": ["S. Zilberstein", "S.J. Russell"], "venue": "Artificial Intelligence,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1996}], "referenceMentions": [], "year": 2011, "abstractText": "In the real world, insufficient information, limited computation resources, and com\u00ad plex problem structures often force an au\u00ad tonomous agent to make a decision in time less than that required to solve the prob\u00ad lem at hand completely. Flexible and ap\u00ad proximate computation are two approaches to decision making under limited computa\u00ad tion resources. Flexible computation helps an agent to flexibly allocate limited compu\u00ad tation resources so that the overall system utility is maximized. Approximate compu\u00ad tation enables an agent to find the best sat\u00ad isfactory solution within a deadline. In this paper, we present two state-space reduction methods for flexible and approximate compu\u00ad tation: quantitative reduction to deal with inaccurate heuristic information, and struc\u00ad tural reduction to handle complex problem structures. These two methods can be ap\u00ad plied successively to continuously improve so\u00ad lution quality if more computation is avail\u00ad able. Our results show that these reduction methods are effective and efficient, finding better solutions with less computation than some existing well-known methods.", "creator": "pdftk 1.41 - www.pdftk.com"}}}