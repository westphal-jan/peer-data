{"id": "1302.1538", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Sequential Update of Bayesian Network Structure", "abstract": "There is yinglin an farnesyl obvious overaggressive need .0359 for improving the mentalist performance bochtler and accuracy thile of a Bayesian huat network as belhar new pagi data beanfield is observed. Because of fifthly errors impala in model construction 68.64 and changes in f16s the juncos dynamics of community-acquired the palestinian domains, we cannot aspens afford 12.62 to giandomenico ignore the information kyo in negrito new pasvik data. semati While lookalike sequential update fram of mcsween parameters bonnot for blazar a fixed lazuli structure pre-civil can \u015fim\u015fek be l'\u00e2me accomplished using nordsee standard 56,500 techniques, marx sequential update baldomir of milarepa network 60.02 structure is magnuson still carrum an open trenaunay problem. carrasquilla In this paper, gh1 we spartacus investigate sequential rof update of Bayesian guzman networks were both parameters partizansk and cve structure 1945-1947 are tholen expected charros to olavs change. 120.45 We introduce alekseyevich a new approach that nocera allows for the flexible ossington manipulation cottrer of mannheim the tradeoff between the splotched quality dabwali of the learned networks and mayos the amount pandemrix of information that is maintained about fictive past bomberg observations. takizawa We wads formally describe \u017erk our 2-seed approach including reluctance the necessary leidesdorff modifications ill\u00e9s to the scoring nka functions psr for nastya learning Bayesian networks, evaluate salala its inangahua effectiveness through an empirical democrazia study, and extend it schlecks to the ghalyoun case schnapps of missing data.", "histories": [["v1", "Wed, 6 Feb 2013 15:55:21 GMT  (1219kb)", "http://arxiv.org/abs/1302.1538v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["nir friedman", "moises goldszmidt"], "accepted": false, "id": "1302.1538"}, "pdf": {"name": "1302.1538.pdf", "metadata": {"source": "CRF", "title": "Sequential Update of Bayesian Network Structure", "authors": ["Nir Friedman", "Moises Goldszmidt"], "emails": ["nir@cs.berkeley.edu", "moises@erg.sri.com"], "sections": null, "references": [{"title": "A tutorial on learning Bayesian net\u00ad works", "author": ["D. Heckerman"], "venue": "Technical Report MSR-TR-95-06, Microsoft Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1995}, {"title": "Learning Bayesian belief networks. An approach based on the MDL principle", "author": ["W. Lam", "F. Bacchus"], "venue": "Comp. lnt. ,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1994}, {"title": "A new view of the EM algorithm that justifies incremental and other variants", "author": ["R.M. Neal", "G.E. Hinton"], "venue": "Unpublished manuscript,", "citeRegEx": "Neal and Hinton.,? \\Q1994\\E", "shortCiteRegEx": "Neal and Hinton.", "year": 1994}, {"title": "Estimating the dimension of a model", "author": ["G. Schwarz"], "venue": "Ann. of Stat. ,", "citeRegEx": "Schwarz.,? \\Q1978\\E", "shortCiteRegEx": "Schwarz.", "year": 1978}, {"title": "Sequential up\u00ad dating of conditional probabilities on directed graph\u00ad", "author": ["D.J. Spiegelhalter", "S.L. Lauritzen"], "venue": "ical structures. Networks,", "citeRegEx": "Spiegelhalter and Lauritzen.,? \\Q1990\\E", "shortCiteRegEx": "Spiegelhalter and Lauritzen.", "year": 1990}], "referenceMentions": [], "year": 2011, "abstractText": "There is an obvious need for improving the per\u00ad formance and accuracy of a Bayesian network as new data is observed. Because of errors in model construction and changes in the dynamics of the domains, we cannot afford to ignore the infor\u00ad mation in new data. While sequential update of parameters for a fixed structure can be accom\u00ad plished using standard techniques, sequential up\u00ad date of network structure is still an open problem. In this paper, we investigate sequential update of Bayesian networks were both parameters and structure are expected to change. We introduce a new approach that allows for the flexible ma\u00ad nipulation of the tradeoff between the quality of the learned networks and the amount of informa\u00ad tion that is maintained about past observations. We formally describe our approach including the necessary modifications to the scoring functions for learning Bayesian networks, evaluate its effec\u00ad tiveness through and empirical study, and extend it to the case of missing data.", "creator": "pdftk 1.41 - www.pdftk.com"}}}