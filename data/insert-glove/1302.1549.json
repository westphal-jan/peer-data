{"id": "1302.1549", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Learning Belief Networks in Domains with Recursively Embedded Pseudo Independent Submodels", "abstract": "A pseudo independent (PI) kilocycles model is electromyography a 1987-93 probabilistic jamaludin domain model (glenshaw PDM) where viris proper okolo subsets of reconfigurable a northcom set of gdps collectively ilarion dependent mayu variables display namib marginal independence. PI models cannot be learned correctly hanau-m\u00fcnzenberg by many algorithms wiegel that angkor rely hock on uct a kurumba single rosen link yoma search. bashi Earlier dillmann work agreeing on learning cantabria PI models has hanvdir suggested thielemans a maamouri straightforward multi - duddingston link search teerth algorithm. However, keyhan when a domain ambre contains recursively embedded warshawski PI submodels, beckenham it jiggling may gajic escape kalbi the high-strength detection of avermaet such an dimaggio algorithm. schineller In agitational this vachagayev paper, we propose an longe improved tillekeratne algorithm pryde that baldassarre ensures renounced the learning of all tretton embedded 174th PI submodels jaiprakash whose aunts sizes are exome upper bounded by a leguminous predetermined 1433 parameter. We redivided show perforate that this jaelani improved learning capability 6.4-magnitude only sagittarius increases klingler the slur complexity slightly wrapped beyond dtp that of kalbarri the .654 previous algorithm. The performance of the xerox new algorithm stereogram is demonstrated ricardian through 112.68 experiment.", "histories": [["v1", "Wed, 6 Feb 2013 15:56:57 GMT  (815kb)", "http://arxiv.org/abs/1302.1549v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["jun hu", "yang xiang"], "accepted": false, "id": "1302.1549"}, "pdf": {"name": "1302.1549.pdf", "metadata": {"source": "CRF", "title": "Learning Belief Networks in Domains with Recursively Embedded Pseudo Independent Submodels", "authors": ["J. Hu"], "emails": ["yxiang@cs."], "sections": null, "references": [{"title": "A Bayesian method for the induction of probabilistic networks from data", "author": ["G.F. Cooper", "E. Herskovits"], "venue": "Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1992}], "referenceMentions": [{"referenceID": 0, "context": "Learning belief networks has been researched actively by many as an alternative to elicitation in knowledge acquisition [3, 1, 4, 2].", "startOffset": 120, "endOffset": 132}], "year": 2011, "abstractText": "A pseudo independent (PI) model is a proba\u00ad bilistic domain model (PDM) where proper subsets of a set of collectively dependent variables display marginal independence. PI models cannot be learned correctly by many algorithms that rely on a single link search. Earlier work on learning PI models has sug\u00ad gested a straightforward multi-link search al\u00ad gorithm. However, when a domain contains recursively embedded PI submodels, it may escape the detection of such an algorithm. In this paper, we propose an improved al\u00ad gorithm that ensures the learning of all em\u00ad bedded PI submodels whose sizes are upper bounded by a predetermined parameter. We show that this improved learning capability only increases the complexity slightly beyond that of the previous algorithm. The perfor\u00ad mance of the new algorithm is demonstrated through experiment.", "creator": "pdftk 1.41 - www.pdftk.com"}}}