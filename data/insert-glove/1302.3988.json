{"id": "1302.3988", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Feb-2013", "title": "A solution concept for games with altruism and cooperation", "abstract": "ndebele We propose a new 23/24 solution 2,725 concept coupon for one - shot scheibner normal humoring form games crist\u00f3v\u00e3o based blachford on albuterol a principle that taj can selan be soulsby summarized janovitz as eger follows: players forecast quaden how nouaille the game would zuoyun be played if posting they amphoteric formed liturgical coalitions and then they tigerman play according to their helps best continuos forecast.", "histories": [["v1", "Sat, 16 Feb 2013 18:59:54 GMT  (56kb)", "https://arxiv.org/abs/1302.3988v1", null], ["v2", "Sat, 2 Mar 2013 18:35:33 GMT  (57kb)", "http://arxiv.org/abs/1302.3988v2", null], ["v3", "Wed, 10 Apr 2013 16:12:32 GMT  (55kb)", "http://arxiv.org/abs/1302.3988v3", null], ["v4", "Tue, 10 Sep 2013 00:15:14 GMT  (56kb)", "http://arxiv.org/abs/1302.3988v4", null]], "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["valerio capraro"], "accepted": false, "id": "1302.3988"}, "pdf": {"name": "1302.3988.pdf", "metadata": {"source": "CRF", "title": "A SOLUTION CONCEPT FOR GAMES WITH ALTRUISM AND COOPERATION", "authors": ["VALERIO CAPRARO"], "emails": ["V.Capraro@soton.ac.uk."], "sections": [{"heading": null, "text": "ar X\niv :1\n30 2.\n39 88\nv4 [\ncs .G\nT ]\n1 0\nSe p\n20 13\nIn this paper we formalize this idea and we define a new solution concept for one-shot normal form games.\nWe prove that this cooperative equilibrium exists for all finite games and it explains a number of different experimental findings, such as (1) the rate of cooperation in the Prisoner\u2019s dilemma depends on the cost-benefit ratio; (2) the rate of cooperation in the Traveler\u2019s dilemma depends on the bonus/penalty; (3) the rate of cooperation in the Publig Goods game depends on the pro-capite marginal return and on the numbers of players; (4) the rate of cooperation in the Bertrand competition depends on the number of players; (5) players tend to be fair in the bargaining problem; (6) players tend to be fair in the Ultimatum game; (7) players tend to be altruist in the Dictator game; (8) offers in the Ultimatum game are larger than offers in the Dictator game.\nJEL Classification: C71, C72.\nContents\n1. Introduction 2 2. Utility functions vs Gain functions: games in explicit form 7 3. An informal sketch of the definition 10 4. The cooperative equilibrium under expected utility theory 12 5. Examples and experimental evidence 19 6. Towards cumulative prospect theory 26\nKey words and phrases. Normal form games, solution concept, Prisoner\u2019s dilemma, Traveler\u2019s dilemma, cooperation, cumulative prospect theory, altruism.\nAddress: Department of Mathematics, University of Southampton, Southampton, SO17 1BJ, UK. Email: V.Capraro@soton.ac.uk. We thank Joe Halpern and Marco Scarsini for helpful discussions over all stages of this research. We thank all participants to the EconCS Seminar at UC Berkeley and all participants to the Agents Seminar in Southampton for numerous comments and, in particular, we thank Rafael Frongillo and Christos Papadimitriou for two stimulating questions that led to improve a non-negligible part of this paper. We thank Kevin Leyton-Brown, Maria Polukarov, and James R. Wright for reading the last version of this article and suggesting many improvements. A special thank goes to my girlfriend, Chiara Napoleoni, student in Philosophy, with whom I had very interesting conversations about altruism.\n1\n7. A brief introduction to cumulative prospect theory 27 8. Iterated Deletion: the set of playable strategies 29 9. The cooperative equilibrium under cumulative prospect theory 34 10. Summary, conclusions and open problems 39 References 43"}, {"heading": "1. Introduction", "text": "Since its foundation by Morgenstern and von Neumann [Mo-vN44], the major challenge of modern game theory has been to predict which actions a human player would adopt in a strategic situation. A first prediction was proposed in an earlier paper by J. von Neumann [vN28] for two-person zero-sum games and then generalized to every finite game by J. Nash in [Na50a]. Since then Nash equilibrium has certainly been the most notable and used solution concept in game theory. Nevertheless, over the last sixty years, it has been realized that it makes poor predictions of human play and, indeed, a large number of experiments have been conducted on games for which it drammatically fails to predict human behavior.\nThere are many reasons behind this failure. On the one hand, when there are multiple equilibria, it is not clear which one we should expect is going to be played. A whole stream of literature, finalized to the selection of one equilibrium, arose from this point, including the definitions of evolutionarily stable strategy [MS-Pr73], perfect equilibrium [Se75], trembling hand perfect equilibrium [Se75], proper equilibrium [My78], sequential equilibrium [Kr-Wi82], limit logit equilibrium [MK-Pa95], and, very recently, settled equilibrium [My-We12].\nOn the other hand, the criticism of Nash equilibrium is motivated by more serious problems: there are examples of games with a unique Nash equilibrium which is not played by human players. Typical examples of such a fastidious situation are the Prisoner\u2019s Dilemma [Fl52], the Traveler\u2019s Dilemma [Ba94], and, more generally, every social dilemma [Ko88]. This point has motivated another stream of literature devoted to the explanation of such deviations from Nash equilibria. Part of this literature tries to explain such deviations assuming that players make mistakes in the computation of the expected value of a strategy and therefore, assuming that errors are identically distributed, a player may also play non-optimal strategies with a probability described by a Weibull distribution. This intuition led to the foundation of the so-called quantal response equilibrium theory by McKelvey and Palfrey [MK-Pa95]. A variant of this theory, called quantal level-k theory and proposed by Stahl and P. Wilson in [St-Wi94], was recently shown to perform better in the prediction of human behavior [Wr-LB10]. In the same paper, Wright and Leyton-Brown have also shown that quantal level-k theory predicts human behavior significantly better than all other behavioral models that have been proposed in the last decade, as the level-k theory [CG-Cr-Br01] and the cognitive hierarchy model [Ca-Ho-Ch04]. However, an obvious criticism of quantal level-k theory is that it is not scale invariant, contradicting one of the axioms of expected utility theory of Morgenstern and von Neumann[Mo-vN47]. A perhaps more fundamental criticism stems from the fact that quantal level-k theory only makes use of some parameters describing either the incidence of errors that a player can make computing the expected utility of a strategy or the fact that humans can perform only a bounded number of iterations of strategic reasoning. These features first imply that quantal level-k theory\nis not predictive, in the sense that one has to conduct experiments to estimate the parameters; second, they imply that quantal level-k theory intrinsically affirms that deviation from Nash equilibria can descend only from two causes, computational mistakes and bounded rationality, that are hard to justify for games with very easy payoffs, like the Prisoner\u2019s Dilemma, or for games where the deviation from Nash equilibrium is particularly strong, like the Traveler\u2019s Dilemma with small bonus-penalty.\nIndeed, the general feeling is that the motivation must rely somewhere deeper and that Nash equilibrium should be replaced by a conceptually different solution concept that takes into account other features of human behavior and coincides with Nash equilibrium only in particular cases. The first studies in this direction have been presented by Renou and Schlag [Re-Sc09] and Halpern and Pass [Ha-Pa12], by Halpern and Rong [Ha-Ro10], by Halpern and Pass [Ha-Pa11], by Jamroga and Melissen [Ja-Me11], and by Adam and Ehud Kalai [Ka-Ka13]. Nevertheless, even though these solution concepts can explain deviations from Nash equilibria in some particular games, all of them make unreasonable predictions for many games of interest. For instance, the maximum perfect cooperative equilibrium introduced in [Ha-Ro10] is too rigid and predicts cooperation for sure in the Prisoner\u2019s and Traveler\u2019s Dilemmas, contradicting the experimental data collected in [Ca-Go-Go-Ho99], [Go-Ho01], [Be-Ca-Na05], [Ba-Be-St11], [HRZ11], [DEJR12], [Fu-Ra-Dr12], [RGN12]. The iterated regret minimization procedure introduced in [Re-Sc09] and [Ha-Pa12] can explain deviations towards cooperation in some variants of the Traveler\u2019s Dilemma, the Bertrand competition, the Centipede Game, and other games of interest, but it does not predict deviation towards cooperation in the Prisoner\u2019s Dilemma [HRZ11], [DEJR12], [Fu-Ra-Dr12], [RGN12] and in the public good game [Le95], it cannot explain altruistic behaviors in the ultimatum game [Fe-Sc99] and in the dictator game [En11], and makes unreasonable predictions for the Traveler\u2019s dilemma with punishment (see Example 5.11), and a certain zerosum game (see Example 8.3). The solution concept defined using algorithmic rationability in [Ha-Pa11] can explain deviation towards cooperation in the iterated Prisoner\u2019s and Traveler\u2019s dilemmas, but it does not predict deviation towards cooperation in one-shot versions of the Prisoner\u2019s dilemma or in one-shot versions of the Traveler\u2019s dilemma with very small bonus-penalty, contradicting the experimental data reported in [Go-Ho01], [Be-Ca-Na05], [HRZ11], [DEJR12], [Fu-Ra-Dr12], [RGN12]. The farsighted pre-equilibrium introduced in [Ja-Me11] is too rigid. For instance, the Prisoner\u2019s dilemma has two farsighted pre-equilibria, which coincide with Rabin\u2019s fairness equilibria [Ra93], where both players either cooperate or defect for sure. This contradicts the experimental data reported in [HRZ11], [DEJR12], [Fu-Ra-Dr12], [RGN12], which suggest that humans tend to play a mixed strategy. Finally, the coco value introduced by Adam and Ehud Kalai in [Ka-Ka13], unifying and developing previous works by Nash [Na53], Raiffa [Rai53], and E.Kalai-Rosenthal [Ka-Ro78], also appears to be too rigid. For instance, if two agents played the Prisoner\u2019s dilemma according to the coco value, then they would both cooperate for sure. This prediction contradicts the experimental data collected in [HRZ11], [DEJR12], [Fu-Ra-Dr12], [RGN12].\nIn this paper we try to attribute the failure of all these attempts to two basic problems. The first problem is the use of utility functions in the very definition of a game. Indeed, the experimental evidence have shown that expected utility theory fails to predict the behavior of decision makers [Al53], [Ka-Tv00], [St00].\nThis problem could be theoretically overcome replacing utility functions with gain functions and applying Kahneman-Tversky\u2019s cumulative prospect theory [Tv-Ka92].\nBut one can easily convince himself that in most cases such a replacement could explain only quantitative deviations.\nThe second problem is indeed that experiments conducted on the Prisoner\u2019s dilemma, the Traveler\u2019s dilemma, Dictator game, and other games, show qualitative deviations from classical solution concepts. These qualitative deviations suggest that humans are altruistic and have attitude to cooperation.\nThese observations motivate the definition of a new solution concept, able to take into account altruism and cooperation and using gain functions instead of utility functions. This paper represents a first endeavour in this direction. Indeed, here we consider only one-shot normal form games where the players are completely anonymous, that is, they do not know each other and they are not allowed to exchange information1. The aim of this paper is to define a new solution concept for this class of games. This solution concept will be called cooperative equilibrium. Indeed, we will see that altruism plays only a marginal role and the main idea behind this new equilibrium notion is the formalization of the following principle of cooperation:\n(C) Players try to forecast how the game would be played if they formed coalitions and then they play according to their best forecast.\nThe study of cooperation in games is not a new idea. Economists, biologists, psychologists, sociologists, and political scientists, have been studying cooperation in social dilemmas for forty years. These classical approaches explain tendency to cooperation dividing people in proself and prosocial types [Li84], [LWVW86], [KMM86], [KCC86], [ML88], or appealing to forms of external control [Ol65], [Ha68], [Da80], or to longterm strategies in iterated games[Ax84]. But, over the years many experiments have been accumulated to show cooperation even in one-shot social dilemmas without external control [Is-Wa88], [Co-DJ-Fo-Ro96], [Go-Ho01], [Be-Ca-Na05], [DRFN08], [HRZ11], [DEJR12]. These and other earlier experiments [Ke-Gr72], [BSKM76], [KSK80], [IWT84] have also shown that the rate of cooperation in the same game depends on the particular payoffs, suggesting that most likely humans cannot be merely divided in proself and prosocial types, but they are engaged in some sort of indirect reciprocity [No-Si98], [No06] and the same person may behave more or less cooperatively depending on the payoffs. In other words, humans have attitude to cooperation by nature.\nTo the best of our knowledge, this is the first attempt to lift this well known tendency to cooperate up to a general principle which is nothing more than a deeper and smarter realization of selfishness.\nThe idea to formalize the principle of cooperation and define the cooperative equilibrium can be briefly summarized as follows:\n\u2022 We assume that players do not act a priori as single players, but they try to forecast how the game would be played if they formed coalitions. \u2022 Each forecast is represented by a number vi(p), called value of the coalition structure p for player i, which is a measure of the expected gain of player i when she plays according to the coalition structure p. \u2022 The numbers vi(p) induce a sort of common beliefs: we consider the induced game Ind(G, p) which differs from the original game G only for the set of allowed profiles of mixed strategies: the profiles of mixed strategies allowed in Ind(G, p) are the profiles (\u03c31, . . . , \u03c3N ) such that ui(\u03c31, . . . , \u03c3N ) \u2265 vi(p), for any player i.\n1We mention that anonimity is not really a necessary assumption: the effect of any sort of contact among the players would be a different evaluation of the so-called prior probability \u03c4 . The point is that at the moment it is not clear how this prior probability should be re-evaluated.\n\u2022 The exact cooperative equilibrium is one where player i plays an equilibrium of the game Ind(G, p) induced by a coalition structure which maximizes the value function vi\n2. \u2022 The notion of equilibrium for the induced game Ind(G, p) is not defined using classical Nash equilibrium, but using a prospect theoretical analogue.\nIn order to apply prospect theory we must replace utility functions by gain functions, that are, functions whose values represent the monetary outcomes or, more generally, the quantity of some good which is won or lost by a player. This replacement comes at the price that we must take into account explicitly new data that were implicitly included in the utility functions. Indeed, while utility functions were supposed to contain all relevant information about players\u2019 preferences, gain functions do contain only the quantity of some good which is won or lost by the players. These new data include the fairness functions fi and the altruism functions aij. An interesting feature of the cooperative equilibrium is that, in many games of interest, it does not depend on these functions. This implies that the cooperative equilibrium is a predictive solution concept for many games of interest. A bit more precisely, in this paper we prove the following statements.\nFact 1.1. The cooperative equilibrium for the Prisoner\u2019s dilemma is predictive (i.e., it does not depend on fairness functions and altruism functions) and has the following property: the predicted rate of cooperation increases as the cost-benefit ratio increases.\nFact 1.2. The cooperative equilibrium for the Traveler\u2019s dilemma is predictive and has the following property: the predicted rate of cooperation decreases as the bonus/penalty increases.\nFact 1.3. The cooperative equilibrium for the Bertrand competition is predictive and it has the following property: the predicted rate of cooperation decreases as the numbers of players increase.\nFact 1.4. The cooperative equilibrium fits Kahneman-Knetsch-Thaler\u2019s experiment related to the ultimatum game.\nFact 1.5. The cooperative equilibrium for the public good game is predictive and it has the following properties: (1) the predicted rate of cooperation increases as the marginal return increases, and (2) the predicted rate of cooperation decreases as the number of players increases and then increases again as the number of players gets sufficiently large.\nFact 1.6. The cooperative equilibrium predicts the (50,50) solution in the Bargaining problem under natural assumptions on the fairness functions.\nRoughly speaking, the natural assumption is that the two players have the same perception of money. We believe that this assumption is natural, since it is predictable that a bargain between a very rich person and a very poor person can have a different solution.\nFact 1.7. The cooperative equilibrium explains the experimental data collected for the dictator game, via altruism.\n2The word exact means that, since players can have bounded rationality or can make mistakes in the computations, one can also define a quantal cooperative equilibrium borrowing ideas from quantal response equilibrium and quantal level-k theory and say that player i plays with probability e\u03bbvi(p)/ \u2211 p e\u03bbvi(p) a quantal response equilibrium or a quantal level-k equilibrium of the game Ind(G, p).\nThis happens just because we define the altruism in terms of human behavior in the dictator game. To treat the dictator game as the quintessence of altruism is certainly not a new idea [Ha-Kr00], [BEN11], [DFR11].\nFact 1.8. The cooperative equilibrium explain the experimental data collected for the ultimatum game, via a combination of cooperation and altruism.\nIn particular, the observation that offers in the ultimatum game are larger then the offers in the dictator game is explained in terms of cooperation, which is generated by the fact that the responder has the power to reject proposer\u2019s offer.\nAnother case where the cooperative equilibrium is only descriptive is when the mistakes that players can make in the computations have a very strong influence on the result. A typical example is the following.\nFact 1.9. The quantal cooperative equilibrium explains Goeree-Holt\u2019s experiment on the asymmetric matching pennies.\nThe structure of the paper is as follows. In Section 2, we define the so-called games in explicit form (see Definition 2.3), where the word explicit really emphasize the fact that we have to take into account explicitly new data (altruism functions and fairness functions). In Section 3 we describe informally the idea through a simple example that allows to motivate all main definitions of the theory. In Section 4 we define the cooperative equilibrium for games in explicit form under expected utility theory, that is, without using cumulative prospect theory, and without using the altruism functions (see Definition 4.14). The reason of this choice is that in most cases cumulative prospect theory can change predictions only quantitatively and not qualitatively and that, in most cases, altruism functions do not play any active role. Indeed, we compute the cooperative equilibrium (under expected utility theory and without using the altruism functions) for the Prisoner\u2019s Dilemma (see Examples 4.5 and 5.2), Traveler\u2019s Dilemma (see Examples 4.6 and 5.1), Nash bargaining problem (see Example 4.4 and 5.9), Bertrand competition (see Example 5.4), public goods game (see Example 5.7), the ultimatum game (see Example 5.5), and a specific game of particular interest since iterated regret minimization theory fails to predict human behavior, whereas the cooperative equilibrium does (see Example 5.11). We make a comparison between the predictions of the cooperative equilibrium and the experimental data and we show that they are always close. In Section 6 we discuss a few examples where the replacement of expected utility theory by cumulative prospect theory starts playing an active role (see Examples 6.1 and 6.2). Here it starts the ideal second part of the paper, devoted to the definition of the cooperative equilibrium for games in explicit form, using cumulative prospect theory and taking into account altruism. Before doing that, we take a short section, namely Section 7, to give a brief introduction to cumulative prospect theory. The definition of the cooperative equilibrium under cumulative prospect theory and taking into account altruism takes Sections 8 and 9: in the former we define a procedure of iterated deletion of strategies using the altruism functions and we apply it to explain the experimental data collected for the dictator game (see Example 8.10) and the ultimatum game (see Example 8.11); in the latter we repeat the construction done in Section 4, this time under cumulative prospect theory instead of expected utility theory. Theorem 9.6 shows that all finite games have a cooperative equilibrium. Part of Section 8 may be of intrinsic interest, since it contains the definition of super-dominated strategies3 (see Definition 8.1) and\n3Joseph Halpern communicated to the author that he and Rafael Pass have independently introduced super-dominated strategies (under the name minimax dominated strategies) in [Ha-Pa13].\ntheir application to solve a problem left open in [Ha-Pa12] (see Example 8.13). Section 10 states a few important problems that should be addressed in future researches."}, {"heading": "2. Utility functions vs Gain functions: games in explicit form", "text": "As mentioned in the Introduction, a major innovation that we propose is the use of gain functions instead of utility functions. In this section we first elaborate on the reasons behind this choice and then we investigate the theoretical consequences of such a choice. First recall the classical definition of a game in normal form.\nDefinition 2.1. A finite game in strategic or normal form is given by the following data:\n\u2022 a finite set of players P = {1, 2, . . . , N}; \u2022 for each player i \u2208 P , a finite set of strategies Si; \u2022 for each player i \u2208 P , a preference relation \u2264i on S := S1 \u00d7 . . .\u00d7 SN .\nIt is frequently convenient (and very often included in the definition of a game) to specify the players\u2019 preferences by giving real-valued utility functions ui : S \u2192 R that represent them. The definition and the use of utility functions relies in Morgenstern and von Neumann\u2019s expected utility theory [Mo-vN47], where, to avoid problems such as risk aversion, they assumed that players\u2019 utility functions contain all relevant information about the players\u2019 preferences over strategy profiles. In this way, Nash was then able to formalize Bernoulli\u2019s principle that each player attempts to maximize her expected utility [Be738] given that the other players attempt to do the same. The use of utility functions can certainly make the theory much easier, but it is problematic, since it has been observed that humans constantly violate the principles of expected utility theory. The very first of such examples was found by M. Allais in [Al53] and many others are known nowadays (see, for instance, [Ka-Tv00] and [St00] for a large set of examples). For the sake of completeness, we briefly describe one of these experiments (see [Ka-Tv79], Problems 3 and 4). In this experiment 95 persons were asked to choose between:\nL1. A lottery where there is a probability of 0.80 to win 4000 and 0.20 to win nothing, L2. A certain gain of 3000.\nAn expected utility maximizer would choose the lottery L1. However, Kahneman and Tversky reported that 80 per cent of the individuals chose the certain gain. The same 95 persons were then asked to choose between:\nL1\u2019. A lottery with a 0.20 chance of winning 4000 and 0.80 of winning nothing, L2\u2019. A lottery with a 0.25 chance of winning 3000 and 0.75 of winning nothing.\nThis time 65 per cent of the subjects chose the lottery L1\u2019, which is also the lottery maximizing expected utility. These two results contradict the so-called substitution axiom in expected utility theory and show how people can behave as expected utility maximizers or not depending on the particular situation they are facing.\nAn even more dramatic observation is that the evidence suggests that decision makers weight probabilities in a non-linear manner, whereas expected utility theory postulates\nthat they weight probabilities linearly. Consider, for instance, the following example from [Ka-Tv79], p.283. Suppose that one is compelled to play Russian roulette. One would be willing to pay much more to reduce the number of bullets from one to zero than from four to three. However, in each case, the reduction in probability of a bullet ring is 1/6 and so, under expected utility theory, the decision maker should be willing to pay the same amount. One possible explanation is that decision makers do not weight probabilities in a linear manner as postulated by expected utility theory.\nThese problems have been now overcome in decision theory thanks to the celebrated prospect theory [Ka-Tv79] and cumulative prospect theory [Tv-Ka92]. One of the very basic principles of (cumulative) prospect theory is that decision makers think in terms of gains and losses rather than in terms of their net assets; in other words, they think in term of gain functions rather than in terms of utility functions. This forces us to replace utility functions by gain functions. This replacement comes at a price: while utility functions were supposed to contain all relevant information about the players\u2019 preferences, gain functions do not contain such information. They must be taken into account separately. As we will remind in Section 7, risk aversion is taken into account by cumulative prospect theory. Among the remaining relevant information there are (at least) two deserving particular attention:\nAltruism. A player may prefer to renounce to part of her gain in order to favor another player. Perception of gains. Two different players may have different perceptions about the same amount of gain.\nTo define formally a game in terms of gain functions, we introduce a unit of measurement g (tipically one dollar, one euro ...) and postulate that to every action profile s \u2208 S and to every player i \u2208 P is associated a quantity gi(s) of g which is lost or won by player i when the strategy profile s is played. We assume that the unit of measurement (e.g., the currency) is common to all players. The losses are expressed by negative integers and the wins by positive integers, so that gi(s) = 2 will mean, for instance, that, if the strategy profile s is played, then player i wins two units of the good g; analogously, gi(s) = \u22123 will mean that, if the strategy profile s is played, then player i loses three units of the good g.\nUsing the unit of measurement, we can take into account altruism and perception of gains as follows.\nDefinition of the altruism functions. We define a notion of altruism operationally, that is, the altruism functions can be theoretically computed running a preexperiment. Consider a general dictator game as follows. A proposer has an endowment of y \u2208 N units of g and a responder has got already z \u2208 Z units of g. Let k > 0, the proposer chooses x \u2208 {0, 1, . . . , y}, to transfer to the responder, who gets \u230akx\u230b, that is, the largest integer smaller than or equal to kx. In other words, we define the two player game Dict(k, y, z) where the strategy set of the first player is S1 = {0, 1, . . . , y} and the strategy set of the second player contains only one strategy, that we call A. The gain functions are\ng1(x,A) = y \u2212 x and g2(x,A) = z + \u230akx\u230b.\nDefinition 2.2. The altruism function aij is the function aij : R + \u00d7 N \u00d7 Z \u2192 N such that aij(k, y, z) would be the offer of player i to player j if i were the proposer and j were the responder in Dict(k, y, z).\nDefinition of the fairness functions. To capture perception of money, we assume that to each player i \u2208 P is associated a function fi : {(x, y) \u2208 R\n2 : x \u2265 y} \u2192 [0,\u221e) whose role is to quantify how much player i disappreciates to renounce to a gain of x and accept a gain of y. The following are then natural requirements:\n\u2022 fi is continuous, \u2022 if x > y, then fi(x, y) > 0, \u2022 if x = y, then fi(x, y) = 0, \u2022 for any fixed x > 0, the function fi(x, \u00b7) is strictly decreasing and strictly convex for positive y\u2019s and strictly concave for negative y\u2019s, \u2022 for any fixed y, the function fi(\u00b7, y) is strictly increasing and strictly concave for positive x\u2019s and strictly convex for negative x\u2019s.\nThe last two properties formalize the well-known diminishing sensitivity principle [Ka-Tv79]: the same difference of gains (resp. losses) is perceived smaller if the gains (resp. losses) are higher. Indeed, one possible way to define the functions fi is to use Kahneman-Tversky\u2019s value function v and set fi(x, y) = v(x) \u2212 v(y). The problem of this definition is that it does not take into account that different players may have different perception of the same amount of money (think of the perception of 100 dollars of a very rich person and a very poor person).\nTherefore, we are led to study the following object.\nDefinition 2.3. A finite game in explicit form G = G(P, S, g, g, a, f) is given by the following data:\n\u2022 a finite set of players P = {1, 2, . . . , N}; \u2022 for each player i \u2208 P , a finite set of strategies Si; \u2022 a good g, which plays the role of a unit of measurement; \u2022 for each player i \u2208 P , a function gi : S1 \u00d7 . . .\u00d7 SN \u2192 Z, called gain function; \u2022 for each pair of players (i, j), i 6= j, an altruism function aij ; \u2022 For each player i \u2208 P , a fairness function fi : {(x, y) \u2208 R\n2 : x \u2265 y} \u2192 R verifying the properties above.\nThe terminology explicit puts in evidence the fact that we must take into account explicitly all parameters that are usually considered implicit in the definition of utility functions. We are not saying that there are only three such parameters (altruism functions, fairness functions, and risk aversion) and this is indeed the first of a long series of points of the theory deserving more attention in future researches. In particular, there is some evidence that badness parameters can play an important role in some games. We shall elaborate on this in Section 10.\nThe purpose of the paper is to define a solution concept for games in explicit form taking into account altruism and cooperation and using cumulative prospect theory instead of expected utility theory. Nevertheless, we will see that\n\u2022 in most cases the use of cumulative prospect theory instead of expected utility theory can change predictions only quantitatively and not qualitatively; \u2022 in most cases the altruism functions do not play any active role, since there are no players having a strategy which give a certain disadvantage to other players.\nConsequently, we prefer to introduce the cooperative equilibrium in two steps. In the first one we keep expected utility theory and we do not use the altruism functions. The aim of the first step is only to formalize the principle of cooperation. We show that\nalready this cooperative equilibrium under expected utility theory and without altruism can explain experimental data satisfactorily well. In Section 6 we discuss some examples where the cooperative equilibrium under expected utility theory does not perform well because of the use of expected utility theory and because we did not take into account altruism and so we move towards the definition of the cooperative equilibrium under cumulative prospect theory and taking into account altruism."}, {"heading": "3. An informal sketch of the definition", "text": "In this section we describe the cooperative equilibrium (under expected utility theory and without taking into account altruism) starting from an example. The idea is indeed very simple, even though the complete formalization requires a number of preliminary definitions that will be given in the next section.\nConsider the following variant of the Traveler\u2019s dilemma. Two players have the same strategy set S1 = S2 = {180, 181, . . . , 300}. The gain functions are\ng1(x, y) =    x+ 5, if x < y x, if x = y y \u2212 5, if x > y,\nand g2(x, y) =    y + 5, if x > y y, if x = y x\u2212 5, if x < y.\nThe usual backward induction implies that (180, 180) is the unique Nash equilibrium. Nevertheless, numerous experimental studies reject this prediction and show that humans play significantly larger strategies.\nIn the cooperative equilibrium, we formalize the idea that players forecast how the game would be played if they formed coalitions and then they play according to their best forecast.\nLet us try to describe how this idea will be formalized. In a two-player game, as the Traveler\u2019s dilemma, there are only two possible coalition structures, the selfish coalition structure ps = ({1}, {2}) and the cooperative coalition structure pc = ({1, 2}). Let us analyze them:\n\u2022 If agents play according to the selfish coalition structure, then by definition they do not have any incentive to cooperate and therefore they would play the Nash equilibrium (180, 180). A Nash equilibrium is, by definition, stable, in the sense that no players have any incentives to change strategy. Consequently, both players would get 180 for sure. In this case we say that the value of the selfish coalition structure is 180 and we write v(ps) = 180. \u2022 Now, let us analyze the cooperative coalition structure pc. The largest gain for each of the two agents, if they play together, is to get 300, that is attained by the profile of strategies (300, 300). Nevertheless, each player knows that the other player may defect and play a smaller strategy and so the value of the cooperative coalition is not 300, but we have to take into account possible deviations. Let us look at the problem from the point of view of player 1. The other player, player 2, may deviate and play the strategy 299 or the strategy 298, or the strategy 297, or the strategy 296, or the strategy 295 (indeed, all these strategies give at least the same gain as the strategy 300, if the first player is believed to play the strategy 300). In this case, the best that player 2 can obtain is 304 (if she plays 299 and the first player plays 300) and so we say that the incentive to deviate from the coalition is 304 \u2212 300 = 4. We denote this number by D2(pc). Now, if player 2 decides to deviate from the coalition,\nshe or he incurs in a risk due to the fact that also player 1 can deviate from the coalition either to follow selfish interest or because player 1 is clever enough to understand that player 2 can deviate from the coalition and then player 1 decides to anticipate this move. The maximal risk that player 2 incurs trying to achieve her maximal gain is then attained when player 2 deviates to 299 and player 1 anticipates this deviation and play 298. In this case, player 2 would gain g2(298, 299) = 293. So we say that the risk in deviating from the coalition structure pc is R2(pc) = 300 \u2212 293 = 7. We now interpret the number\n\u03c41,{2}(pc) = D2(pc)\nD2(pc) +R2(pc) =\n4\n11 ,\nas a sort of prior probability that player 1 assigns to the event \u201cplayer 2 abandons the coalition structure pc\u201d. Consequently, we obtain also a number\n\u03c41,\u2205(pc) = 1\u2212 \u03c41,{2}(pc),\nwhich is interpreted as a prior probability that player 1 assigns to the event \u201cnobody abandons the coalition structure pc\u201d.\nThis probability measure will be now used to weight the numbers e1,\u2205(pc), representing the infimum of gains that player 1 receives if nobody abandons the coalition, and e1,{2}(pc), representing the infimum of gains that player 1 receives if the second player abandons the coalition. Therefore, one has\ne1,\u2205(pc) = 300 and e1,{2}(pc) = 290,\nwhere the second number comes from the fact that the worst that can happen for player 1 if the second player abandons the coalition and the first players does not abandon the coalition is in correspondence of the profile of strategies (300, 295) which gives a gain 290 to the first player. Taking the average we obtain the value of the cooperative coalition for player 1\nv1(pc) = 300 \u00b7 7\n11 + 290 \u00b7\n4\n11 \u223c 296.35.\nBy symmetry one has v2(ps) = v1(ps) =: v(ps) = 180 and v2(pc) = v1(pc) =: v(pc) = 296.35. So one has v(ps) < v(pc) and then the cooperative equilibrium predicts that the agents play according to the cooperative coalition structure, since it gives a better forecast. The meaning of the word play according to pc has to be clarified. Indeed, since the profile (300, 300) is not stable, we cannot expect that the players play for sure the strategy 300. What we do is to interpret the values vi(pc) as a sort of common beliefs: players simply keep only the profiles of strategies \u03c3 = (\u03c31, \u03c32) such that g1(\u03c3) \u2265 v1(pc) and g2(\u03c3) \u2265 v2(pc). Computing the Nash equilibrium in this induced game will give the cooperative equilibrium of the game that, in this case, is a mixed strategy which is supported between 296 and 297. Observe that this is very close to the experimental data. Indeed, the one-shot version of this game was experimented by Goeree and Holt who reported that 80 per cent of subjects played a strategy between 290 and 300 with an average of 295 (see [Go-Ho01]).\nThe purpose of the next section is to formalize the idea that we have just described. Indeed, even though the idea is very simple and in many relevant cases computations can be easily performed by hand (cf. Section 5), the correct formalization requires the whole section 4 because of the following technical problems:\n\u2022 In the particular example that we have just described, the cooperative coalition structure leads to a one-player game with a unique Nash equilibrium, which is (300, 300). In general this will not happen and we should take into account that one Nash equilibrium can be less fair than another. For instance, the cooperative coalition structure in Nash bargaining problem leads to a one-player game with many Nash equilibria, but intuitively only the (50,50) solution is fair. \u2022 The definition of deviation and risk is intuitively very simple, but the general mathematical formalization is not straightforward."}, {"heading": "4. The cooperative equilibrium under expected utility theory", "text": "Let G = G(P, S, g, g, a, f) be a finite4 game in explicit form. As usual, to make notation lighter, we denote S\u2212i the cartesian product of all the Sj \u2019s but Si. Let P(X) be the set of probability measures on the finite setX. If \u03c3 = (\u03c31, . . . , \u03c3N ) \u2208 P(S1)\u00d7. . .\u00d7P(SN ), we denote by \u03c3\u2212i the (N\u22121)-dimensional vector of measures (\u03c31, . . . , \u03c3i\u22121, \u03c3i+1, . . . , \u03c3N ) and, as usual in expected utility theory, we set\ngj(\u03c3i, \u03c3\u2212i) = gj(\u03c3) := \u2211\n(s1,...,sN )\u2208S\ngj(s1, . . . , sN )\u03c31(s1) \u00b7 . . . \u00b7 \u03c3N (sN ).\nConversely, if \u03c3i \u2208 P(Si), for all i \u2208 P , the notation gj(\u03c3i, \u03c3\u2212i) simply stands for the number gj(\u03c31, . . . , \u03c3N ).\nThe main idea behind our definition is the principle of cooperation, that is, players try to forecast how the game would be played if they formed coalitions and then they play according to their best forecast. Borrowing a well known terminology from the literature on coalition formation (cf. [Ra08]), we give the following definition.\nDefinition 4.1. A coalition structure is a partition p = (p1, . . . , pk) of the player set P ; that is, the p\u03b1\u2019s are subsets of P such that p\u03b1\u2229 p\u03b2 = \u2205, for all \u03b1 6= \u03b2, and \u22c3 p\u03b1 = P .\nAs mentioned in the Introduction, the idea is that each player i \u2208 P assigns a value to each coalition structure p and then plays according to the coalition structure with highest value. As described in Section 3, the idea to define the value of a coalition structure p for player i is to take an average of the following kind. Suppose that for all J \u2286 P \\ {i} we have defined a number \u03c4i,J(p) describing the probability that players in J abandon the coalition structure p and a number ei,J(p) describing the infimum of possible gains of player i when players in J abandon the coalition structure p. Then we (would) define\nvi(p) = \u2211\nJ\u2286P\\{i}\nei,J(p)\u03c4i,J(p). (1)\nOur aim is to give a reasonable definition for the numbers ei,J(p) and \u03c4i,J(p) under the assumption that players do not know each other and are not allowed to exchange information. Of course, this is only a real restriction of the theory: if the players know each other and/or are allowed to exchange information, this will reflect on the computation of the probability \u03c4i,J(p).\n4It is well known that the study of infinite games can be very subtle. For instance, there is large consensus that, at least when the strategy sets do not have a natural structure of a standard Borel space, one must allow also purely finitely additive probability measures as mixed strategies, leading to the problem that even the mixed extension of the utility functions is not uniquely defined [Ma97],[St05],[Ca-Mo12],[Ca-Sc12]. In this first stage of the research we want to avoid all these technical issues and we focuse our attention only to finite games.\nBefore defining the numbers ei,J(p) and \u03c4i,J(p), we need to understand what kind of strategies agree with the coalition structure p. Indeed, as mentioned in Section 3, if p 6= ({1}, . . . , {N}) is not the selfish coalition structure, some profiles of strategies might not be acceptable by the players in the same coalition because they do not share the gain in a fair way among the players belonging to the same coalition p\u03b1. We can define a notion of fairness making use of the fairness functions fi. First observe that the hypothesis of working with gain functions expressed using the same unit of measurement for all players allows us to sum the gains of different players and, consequently, we can say that a coalition structure p = (p1, . . . , pk) generates a game with k players as follows. The players are the sets p\u03b1 in the partition, the pure strategy set of p\u03b1 is \u220f i\u2208p\u03b1\nSi, and the gain function of player p\u03b1 is\ngp\u03b1(s1, . . . , sN ) = \u2211\ni\u2208p\u03b1\ngi(s1, . . . , sN ) (2)\nThis game, that we denote by Gp, has a non-empty set of Nash equilibria 5 that we denote by Nash(Gp). Since the players in the same p\u03b1 are ideally cooperating, not all Nash equilibria are acceptable, but only the ones that distribute the gain of the coalition p\u03b1 as fairly as possible among the players belonging to p\u03b1.\nTo define the subset of fair of acceptable equilibria, fix i \u2208 P and consider the restricted function gi = gi|Nash(Gp) : Nash(Gp) \u2192 R. Since Nash(Gp) is compact and gi is continuous, we can find \u03c3i \u2208 Nash(Gp) maximizing gi.\nDefinition 4.2. The disagreement in playing the profile of strategy \u03c3 \u2208 Nash(Gp) for the coalition p\u03b1 is the number\nDisp\u03b1(\u03c3) = \u2211\ni\u2208p\u03b1\nfi(gi(\u03c3i), gi(\u03c3))\nRecalling that the number fi(x, y) represents how much player i disappreciates to renounce to a gain of x and accept a gain of y \u2264 x, we obtain that, in to order to have a fair distribution of the gain among the players in the coalition p\u03b1, the disagreement Disp\u03b1 must be minimized.\nDefinition 4.3. The Nash equilibrium \u03c3 \u2208 Nash(Gp) is acceptable or fair for the coalition p\u03b1, if \u03c3 minimizes Disp\u03b1(\u03c3).\nSince the set of Nash equilibria of a finite game is compact and since the functions fi are continuous, it follows that the set of acceptable equilibria is non-empty and compact.\nLet us say explicitly that this is the unique point where we use the functions fi. It follows, that, for a game G such that every game Gp has a unique Nash equilibrium, the cooperative equilibrium does not depend on the functions fi.\nThe importance of the hypotheses about strict convexity in the second variable and strict concavity in the first variable of the functions fi should be now clear and is however described in the first of the following series of examples.\nExample 4.4. Consider a finite version of Nash\u2019s bargaining problem [Na50b] where two persons have the same strategy set S1 = S2 = S = {0, 1, . . . , 100} and the gain functions are as follows:\n5If p = (P ) is the grand coalition, then Gp is a one-player game, whose Nash equilibria are all probability measures supported on the set of strategies maximizing the gain function.\ng1(x, y) = { x, if x+ y \u2264 100 0, if x+ y > 100,\nand g2(x, y) = { y, if x+ y \u2264 100 0, if x+ y > 100.\nAs well known, this game has attracted attention from game theorists since, despite having many pure Nash equilibria, only one is intuitively natural. Indeed, many papers have been devoted to select this natural equilibrium adding axioms (see [Na50b], [Ka-Sm75], and [Ka77]) or using different solution concepts (see [Ha-Ro10] and [Ha-Pa12]).\nAssume that the two players have the same perception of money, that is f1 = f2 =: f . Consider the cooperative coalition pc = ({1, 2}) describing cooperation between the two players. The game Gpc is a one-player game whose Nash equilibria are all pairs (x, 100\u2212x), x \u2208 S1, and all probability measures on S1\u00d7S2 supported on such pairs of strategies. Despite having all these Nash equilibria, the unique acceptable equilibrium for the game coalition is (50, 50). Indeed, one has\nDispc (50, 50) = f (100, 50) + f (100, 50)\n= f ( 100, 1\n2 \u00b7 100 +\n1 2 \u00b7 0\n) + f ( 100, 1\n2 \u00b7 100 +\n1 2 \u00b7 0\n)\n< 1\n2 f(100, 100) +\n1 2 f(100, 0) + 1 2 f(100, 100) + 1 2 f(100, 0)\n= f(100, 100) + f(100, 0)\n= Dispc(100, 0).\nAnalogously, one gets Dispc (50, 50) < Dispc((x, 100 \u2212 x)), for all x \u2208 {0, 1, . . . , 100}, x 6= 50. Consequently, (50, 50) is the unique acceptable equilibrium for the cooperative coalition pc.\nNow let ps = ({1}, {2}) be the selfish coalition structure. Then the unique acceptable equilibrium for player 1 is (100, 0) and the unique acceptable Nash equilibria for player 2 is (0, 100).\nExample 4.5. As second example, we consider the Prisoner\u2019s Dilemma. As well known, this famous game was originally introduced by Flood in [Fl52], where he reported on a series of experiments, one of which, now known as Prisoner\u2019s Dilemma, was conducted in 1950. Even though Flood\u2019s report is seriously questionable, as also observed by Nash himself (cf. [Fl52], pp. 24-25), it probably represents the first evidence that humans tend to cooperate in the Prisoner\u2019s Dilemma. This evidence has been confirmed in [Co-DJ-Fo-Ro96], where the authors observed a non-negligible percentage of cooperation even in one-shot version of the Prisoner\u2019s dilemma.\nHere we consider a parametrized version of the Prisoner\u2019s Dilemma, as follows. Two persons have the same strategy set S1 = S2 = {C,D}, where C stands for cooperate and D stands for defect. Let \u00b5 > 0, denote by G(\u00b5) the game described by the following gains:\nC D C 1 + \u00b5, 1 + \u00b5 0, 2 + \u00b5 D 2 + \u00b5, 0 1, 1\nTherefore, the parameter \u00b5 plays the role of a reward for cooperating. The intuition, motivated by similar experiments conducted on the Traveler\u2019s Dilemma (cf. Example 4.6) or on the repeated Prisoner\u2019s dilemma [DRFN08], suggests that humans should play the selfish strategy D for very small values of \u00b5 and tend to cooperate for very large values of \u00b5. This intuition is in fact so natural that Fudenberg, Rand, and Dreber,\nmotivated by experimental results on the repeated Prisoner\u2019s dilemma, asked \u201cHow do the strategies used vary with the gains to cooperation?\u201d (cf. [Fu-Ra-Dr12], p.727, Question 4). We will propose an answer to this question (for one-shot Prisoner\u2019s dilemma) in Example 5.2, where we will show that the cooperative equilibrium predicts a rate of cooperation depending on the particular gains and that such equilibrium is computable by a very simple formula (cf. Proposition 5.3). For now, let us just compute the acceptable Nash equilibria for the two partitions of P = {1, 2}. Let pc = ({1, 2}) be the cooperative coalition structure, describing cooperation between the players. In this case we obtain a one-player game with gains:\ngpc(C,C) = 2 + 2\u00b5 gpc(C,D) = 2 + \u00b5 gpc(D,C) = 2 + \u00b5 gpc(D,D) = 2.\nwhose unique Nash equilibrium (i.e., the profile of strategies maximizing the payoff) is the cooperative profile of strategies (C,C). Uniqueness implies that this equilibrium must be acceptable independently of the fi\u2019s. On the other hand, the selfish coalition structure ps = ({1}, {2}) generates the original game, whose unique equilibrium is, as well known, the defecting profile of strategies (D,D). Also in this case, uniqueness implies that this equilibrium must be acceptable.\nExample 4.6. Finally, we consider the Traveler\u2019s Dilemma. This game was introduced by Basu in [Ba94] with the purpose to construct a game where Nash equilibrium makes unreasonable predictions. Basu\u2019s intuition was indeed confirmed by experiments on both one-shot and repeated treatments [Ca-Go-Go-Ho99], [Go-Ho01], [Be-Ca-Na05], [Ba-Be-St11]. Fix a parameter b \u2208 {2, 3, . . . , 180}, two players have the same strategy set S1 = S2 = {180, 181, . . . , 300} and payoffs:\ng1(x, y) =    x+ b, if x < y x, if x = y y \u2212 b, if x > y,\nand g2(x, y) =    y + b, if x > y y, if x = y x\u2212 b, if x < y.\nThis game has a unique Nash equilibrium, which is (180, 180). Nevertheless, it has been observed that humans tend to cooperate (i.e. play strategies close to (300, 300)) for small values of b and tend to be selfish (i.e., play strategies close to the Nash equilibrium (180, 180)) for large values of b. This is indeed what the cooperative equilibrium predicts, as we will see in Example 5.1. For now, let us just compute the sets of acceptable equilibria for all partitions of P = {1, 2}. Let pc = ({1, 2}) be the cooperative coalition structure, describing cooperation between the players. In this case we obtain a oneplayer game whose unique Nash equilibrium is attained by the cooperative profile of strategies (300, 300). Uniqueness implies that this equilibrium must be acceptable. On the other hand, the selfish coalition structure ps = ({1}, {2}) gives rise to the unique Nash equilibrium of the game, which is (180, 180). Also in this case, uniqueness implies that this equilibrium must be acceptable.\nComing back to the description of the theory, we have gotten, for all partitions p of the player set P and for all sets p\u03b1 of the partition, a (compact) set of acceptable equilibria Accp\u03b1(Gp) for the coalition p\u03b1 inside the coalition structure p. Now we define the numbers ei,J(p) and \u03c4J(p).\nDefinition of the numbers \u03c4i,J(p). We recall that the number \u03c4i,J(p) represents the probability that players i assigns to the event \u201cplayers in J abandon the coalition structure p\u201d. Consequently, it is enough to define the numbers \u03c4i,J(p) when J = {j} contains only one element. The other numbers can be indeed reconstructed assuming\nthat the events \u201cplayer j deviates from p\u201d and \u201cplayer k deviates from p\u201d are independent. This assumption is natural in this context where players are not allowed to exchange information.\nTherefore, fix j \u2208 P , with j 6= i. The definition of \u03c4i,j(p) is intuitively very simple. It will be a ratio\n\u03c4i,j(p) = Dj(p)\nDj(p) +Rj(p) ,\nwhere:\n\u2022 the number Dj(p) represents the incentive for player j to abandon the coalition structure p, that is, the maximal gain that player j can get leaving the coalition; \u2022 the number Rj(p) represents the risk that player j takes leaving the coalition structure p, that is, the maximal loss that player j can incur trying to achieve her maximal gain, assuming that also other players can abandon the coalition either to follow selfish interests or to anticipate player j\u2019s defection.\nTo make this intuition formal, first define\nM\u0303(p\u03b1, p) := {\u03c3 \u2208 Accp\u03b1(Gp) : gp\u03b1(\u03c3) is maximal} . (3)\nThe idea is indeed that players in the same coalition try to achieve their maximal joint gain but, doing that, there might be some conflicts among coalitions. Therefore, we are interested to look at the strategy profiles that can be constructed putting together\npieces of strategies in the various M\u0303(p\u03b1, p). To this end, let us fix a piece of notation. For a given player j, let \u03c0j : P(S1) \u00d7 . . . \u00d7 P(SN ) \u2192 P(Sj) be the canonical projection. We may reconstruct an element \u03c3 \u2208 P(S1)\u00d7. . .\u00d7P(SN ), through its projections and we write formally \u03c3 = \u2297N\nj=1 \u03c0j(\u03c3). Set\nM(p\u03b1, p) :=    \u2297\ni\u2208p\u03b1\n\u03c0i(\u03c3) : \u03c3 \u2208 M\u0303(p\u03b1, p)    , (4)\nand then\nM(p) = k\u2297\n\u03b1=1\nM(p\u03b1, p). (5)\nIn words, M(p) is the set of strategy profiles that can be constructed putting together pieces of acceptable equilibria maximizing the joint gain of each coalition.\nRemark 4.7. It is worth mentioning that in many relevant cases all sets M\u0303(p\u03b1, p) contain only one element and the computations get very simple and unambiguous. However, in some cases, as in the route choice game, this set may contain multiple and theoretically even infinite elements. From a mathematical point of view, this is not a problem,\nsince we need only compactness of the sets M\u0303(p\u03b1, p) and these sets are indeed compact. However, in some cases there might be a natural way to restrict the sets M\u0303(p\u03b1, p), leading to a computationally lighter and intuitively more natural definition. For instance, in games with particular symmetries, as the basic route choice game6, players are tipically indifferent among all pure Nash equilibria maximizing their gains and, therefore, it is\nnatural to restrict the set M\u0303(p\u03b1, p) and take only its barycenter, which is, in this case,\n6There are 2N players, each of which has to decide the route to go to work between two equivalent routes.\nthe uniform measure7. Theoretically, this construction may be extended to every game,\nsince M\u0303(p\u03b1, p) is always compact and so it has a barycenter (see [Ha-Va89], Sec. 3.b). But we do not think that the assumption that players in the same p\u03b1 are indifferent among all the acceptable strategies which maximize their joint gain is very general and it would not probably make sense in very asymmetric games. How to restrict the sets\nM\u0303(p\u03b1, p) is another point of the theory that deserves particular attention in a future research.\nDefinition 4.8. Let \u03c3 \u2208 P(S1) \u00d7 . . . \u00d7 P(SN ) be a profile of mixed strategies and \u03c3\u2032k \u2208 P(Sk). We say that \u03c3 \u2032 k is a k-deviation from \u03c3 if gk(\u03c3 \u2032 k, \u03c3\u2212k) \u2265 gk(\u03c3).\nNow we can finally move towards the definition of incentive and risk. We recall, that we have fixed a coalition structure p and two players i, j \u2208 P , with i 6= j and we want to define the incentive and risk for player j to abandon the coalition structure. Let Devj(p) denote the set strategies of player j that are j-deviation from at least one strategy in M(p).\nDefinition 4.9. The incentive for player j to deviate from the coalition structure p is\nDj(p) := max { gj(\u03c3 \u2032 j , \u03c3\u2212j)\u2212 gj(\u03c3) : (\u03c3, \u03c3 \u2032 j) \u2208 Devj(p) } . (6)\nObserve that Dj(p) is attained since the set Devj(p) is compact. If Dj(p) = 0, then j does not gain anything by leaving the coalition and therefore j does not have any incentives to abandon the coalition structure p. If it is the case, we simply define \u03c4i,j(p) = 0.\nConsider now the more interesting case Dj(p) > 0, where player j has an actual incentive to deviate from the coalition structure p. If j decides to leave p, it may happen that she loses part of her gain if other players decide to abandon p either to follow selfish interests or to answer player j\u2019s defection. To quantify this risk, we first introduce some notation. Let (\u03c3, \u03c3\u2032j) \u2208 Devj(p) such that Dj(p) is attained. Call T (\u03c3, \u03c3 \u2032 j) the set of\n\u03c3\u2032\u2212j \u2208 \u2297 i 6=j P(Si) such that\n\u2022 gj(\u03c3)\u2212 gj(\u03c3 \u2032 j , \u03c3 \u2032 \u2212j) > 0, \u2022 there is k \u2208 P \\{j} such that \u03c0k(\u03c3 \u2032 \u2212j) is a k-deviation from either \u03c3 or (\u03c3\u2212j, \u03c3 \u2032 j).\nThus we quantify the risk by\nRj(p) := sup { gj(\u03c3)\u2212 gj(\u03c3 \u2032 j , \u03c3 \u2032 \u2212j) } , (7)\nwhere the supremum is taken over all\n(A) (\u03c3, \u03c3\u2032j) \u2208 Devj(p) such that Dj(p) is attained, (B) \u03c3\u2032\u2212j \u2208 T (\u03c3, \u03c3 \u2032 j).\nThe requirement (A) is motivated by the fact that if player j believes that she can leave the coalition structure p to follow selfish interests, then she must take into account that also other players may deviate from p either to follow selfish interests or because they are clever enough to anticipate player j\u2019s defection. This can obstruct player j\u2019s deviation, if another player\u2019s deviation causes a loss to player j.\nDefinition 4.10. The prior probability that player j deviates from the coalition structure p is\n\u03c4i,j(p) := Dj(p)\nDj(p) +Rj(p) .\n7It was reported in [RKDG09] that players tend to play uniformly in the basic route choice game.\nThe terminology prior wants to clarify the fact that the event \u201cplayer j abandons the coalition\u201d is not measureable in any absolute and meaningful sense. The prior probability is a sort of measure a priori of this event knowing only mathematically measurable information, as monetary incentive and monetary risk.\nRemark 4.11. If the set T (\u03c3, \u03c3\u2032j) is empty for all (\u03c3, \u03c3 \u2032 j) \u2208 Devj(p), then the supremum defining the risk Rj(p) is equal to zero. Consequently, the prior probability that player j abandons the coalition structure p is equal to 1. This is coherent with the intuition that if T (\u03c3, \u03c3\u2032j) = \u2205, then there is no way to obstruct player j\u2019s defection.\nAs said before, we can now compute all remaining probabilities \u03c4i,J(p) assuming that the events \u201cplayer j deviates from p\u201d and \u201cplayer k deviates from p\u201d are independent. In particular, \u03c4i,\u2205(p) will represent the probability that none of the players other than i deviates from the coalition structure.\nDefinition of the numbers ei,J(p). We recall that the numbers ei,J(p) represent the infimum of gains of player i when the players in J decide to deviate from the coalition structure p. Therefore, the definition of these numbers is very straightforward. Let J \u2286 P \\ {i}, we first define the set\nDevJ(p) :=   (\u03c3, \u03c3 \u2032 J ) \u2208 k\u2297\n\u03b1=1\nM(p\u03b1, p)\u00d7 \u2297\nj\u2208J\nP(Sj) : \u2203j \u2208 J : gj(\u03c0j(\u03c3 \u2032 J), \u03c3\u2212j) \u2265 gj(\u03c3)    .\nThen we define\nei,J(p) := inf{gi(\u03c3 \u2032 J , \u03c3\u2212J) : (\u03c3, \u03c3 \u2032 J ) \u2208 DevJ(p)}.\nDefinition 4.12. The value of the coalition structure p for player i is\nvi(p) = \u2211\nJ\u2286P\\{i}\nei,J(p)\u03c4i,J(p). (8)\nWe stress that at this first stage of the research we cannot say that this formula is eventually the right way to compute the value of a coalition structure. It just seems a fairly natural way and, as we will show in Section 5, it meets experimental data satisfactorily well. However, it is likely that a future research, possibly supported by suitable experiments, will suggest to use of a different formula. For instance, we will describe in Example ?? that it is possible that the deviation Dj(p) should be computed taking into account not only deviation to achieve higher gains, but also to get a safe gain.\nNow, in an exact theory, player i is assumed to have unbounded rationality and is assumed not to make mistakes in the computations and so, using the principle of cooperation, she will play according to some p which maximises the value function vi. It remains to understand the meaning of playing according with a coalition structure p. Indeed, we cannot expect that player i will play surely according to an acceptable Nash equilibrium of Gp, since she knows that other players may deviate from the coalition. What we can do is to use the numbers vi(p) to define a sort of beliefs.\nDefinition 4.13. Let A \u2286 P(S1) \u00d7 . . . \u00d7 P(SN ). The subgame induced by A is the game whose set of mixed strategies of player i is the closed convex hull in P(Si) of the projection set \u03c0i(A).\nTherefore, a subgame induced by a set A is not, strictly speaking, a game, since in general the set of mixed strategies of player i cannot be described as the convex hull of a set of pure strategies which is a subset of Si. In the induced game only particular mixed strategies are allowed, which, as said earlier, correspond to some sort of beliefs. Observe that, since the set of allowed mixed strategies is convex and compact, we can formally find a Nash equilibrium of an induced game. Indeed, Nash\u2019s proof of existence of equilibria does not really use the fact that the utility functions are defined on P(S1)\u00d7 . . .\u00d7P(SN ), but only that they are defined on a convex and compact subset of P(S1)\u00d7 . . .\u00d7 P(SN ).\nLet Ind(G, p) be the subgame induced by the set of strategies \u03c3 \u2208 P(S1)\u00d7 . . .\u00d7P(SN ) such that gi(\u03c3) \u2265 vi(p), for all i \u2208 P . Observe that the induced game is not empty, since vi(p) is a convex combinations of infima of values attained by the gain function gi.\nDefinition 4.14. (Exact cooperative equilibrium) An exact cooperative equilibrium is one where player i plays a Nash equilibrium of the subgame Ind(G, p) where p maximizes vi(p) 8.\nOne could define a quantal cooperative equilibrium, declaring that player i plays with probability e\u03bbvi(p)/ \u2211 p e \u03bbvi(p) according to the quantal response equilibrium or the quantal level-k theory applied to Ind(G, p). At this first stage of the research, we are not interesting in such refinements, that could be useful in future and deeper analysis (cf. Examples ?? and 9.8)."}, {"heading": "5. Examples and experimental evidence", "text": "In this section we apply the cooperative equilibrium (under expected utility theory and without using altruism) to some well known games. The results we obtain are encouraging, since the predictions of the cooperative equilibrium are always satisfactorily close to the experimental data. We present also two examples where the cooperative equilibrium makes new predictions, completely different from all standard theories. These new predictions are partially supported by experimental data, but we do not have enough precise data to say that they are strongly confirmed.\nExample 5.1. Let G(b) be the parametrized Traveler\u2019s Dilemma in Example 4.6 with bonus-penalty equal to b. Let pc = ({1, 2}) be the cooperative coalition. We recall that in Example 4.6 we have shown that the profile of strategies (300, 300) is the unique acceptable equilibrium for pc. To compute the values of pc, let i = 1 (the case i = 2 is the same, by symmetry). One has D2(pc) = b\u2212 1, corresponding to the strategy profile (300, 299). Corresponding to this deviation of player 2, which is the unique deviation maximizing player 2\u2019s gain, the best deviation for player 1 is to play the strategy 298, which gives g2(300, 300)\u2212g2(298, 299) = 2+b. Therefore, R2(pc) = 2+b. Consequently, we have\n\u03c41,{2}(pc) = b\u2212 1\n2b+ 1 and \u03c41,\u2205(pc) =\nb+ 2\n2b+ 1 .\nNow, e1,{2} = 300 \u2212 2b, corresponding to the profile of strategy (300, 300 \u2212 b), and e1,\u2205(pc) = 300. Consequently, setting v1(pc) = v2(pc) =: v(pc), we have\nv(pc) = 300 \u00b7 b+ 2\n2b+ 1 + (300 \u2212 2b) \u00b7\nb\u2212 1\n2b+ 1 .\n8Observe that this is well defined also in case of multiple p\u2019s maximizing vi(p), since the induced games Ind(G, p) and Ind(G, p\u2032) are the same, if p, p\u2032 are both maximizers.\nOn the other hand, the selfish coalition structure ps = ({1}, {2}) has value\nv1(ps) = v2(ps) = 180,\nsince there are no possible deviations from a Nash equilibrium. Therefore, for small values of b, one has v(pc) > v(ps) and the cooperative equilibrium predicts that agents play according to the cooperative coalition; for large values of b, one has v(ps) > v(pc) and then the cooperative equilibrium predicts that agents play the Nash equilibrium. Moreover, the rate of cooperation depends on b: the larger is b, the smaller is the rate of cooperation predicted. We are aware of only two experimental studies devoted to one-shot Traveler\u2019s dilemma. In this cases, the predictions are even quantitatively close.\n\u2022 For b = 2 and S1 = S2 = {2, 3, . . . , 100}, it has been reported in [Be-Ca-Na05] that most of subjects (38 out of 45) chose a number between 90 and 100 and the strategy which had the highest payoff was s = 97. In our case, we obtain\nv(pc) = 100 \u00b7 b+ 2\n2b+ 1 + 96 \u00b7\nb\u2212 1\n2b+ 1 = 99.2.\nConsequently, the cooperative equilibrium is supported near 99. \u2022 For b = 5 and S1 = S2 = {180, 181, . . . , 300}, it has been reported in [Go-Ho01] that about 80 per cent of the subjects submitted a strategy between 290 and 300, with an average of 295. In our case, we obtain\nv(pc) = 300 \u00b7 b+ 2\n2b+ 1 + 290 \u00b7\nb\u2212 1\n2b+ 1 = 296.35.\nConsequently, the cooperative equilibrium is supported between 296 and 297, which is very close to the experimental data. \u2022 For b = 180 and S1 = S2 = {180, 181, . . . , 300}, it was reported in [Go-Ho01] that about 80 per cent of the subjects played the Nash equilibrium 180. In our case, one easily sees that\nv(pc) < v(ps)\nConsequently, the cooperative equilibrium reduced to Nash equilibrium and predicts the solution (180, 180). So the cooperative equilibrium coincides with what most subjects played.\nExample 5.2. We consider the parametrized Prisoner\u2019s dilemma as in Example 4.5. Observe that all known solution concepts predict either defection for sure or cooperation for sure. Nevertheless, the data collected on the conceptually similar parametrized Traveler\u2019s dilemma suggest that human behavior in the parametrized Prisoner\u2019s dilemma should depend on the parameter. This intuition is partially supported by the results presented in [DRFN08], where the authors reported on experiments conducted on the repeated Prisoner\u2019s dilemma with punishment and observed that subjects tend to cooperate more when the cost of cooperating is smaller. Motivated by these experimental data, Fudenberg, Rand, and Dreber indeed asked \u201cHow do the strategies used vary with the gains to cooperation?\u201d (cf. [Fu-Ra-Dr12], p.727, Question 4).\nWe now show that in fact cooperative equilibrium predicts a rate of cooperation which depends on the particular gains.\nProposition 5.3. The unique cooperative equilibrium of the parametrized Prisoner\u2019s dilemma G(\u00b5) is:\n\u2022 (D,D) if \u00b5 \u2264 1,\n\u2022 ( \u00b5\u22121 \u00b5 C + 1 \u00b5 D, \u00b5\u22121 \u00b5 C + 1 \u00b5 D ) ."}, {"heading": "In particular, the cooperative equilibrium of G(\u00b5) verifies the following appealing property:", "text": "(1) It predicts defection for \u00b5 = 0, (2) It moves continuously and monotonically from defection to cooperation, as \u00b5\nincreases, (3) It converges to cooperation as \u00b5 \u2192 \u221e.\nProof. The cooperative coalition structure pc = ({1, 2}) gives rise to a one-player game whose unique Nash equilibrium is the cooperative profile (C,C). The value of this coalition is, for both players,\nv1(pc) = v2(pc) = (1 + \u00b5)\n( 1\u2212 1\n1 + \u00b5\n) = \u00b5.\nThe selfish partition ps = ({1}, {2}) gives rise to the classical Nash equilibrium (D,D). The value of ps is then, for both players,\nv1(ps) = v2(ps) = 1\nTherefore, for \u00b5 < 1 one has v1(pc) = v2(pc) < v1(ps) = v2(ps) and therefore the cooperative equilibrium predicts defection. To compute the cooperative equilibrium for \u00b5 \u2265 1, first we need to find all profiles of strategies (\u03c31, \u03c32) such that\n{ g1(\u03c31, \u03c32) \u2265 \u00b5\ng2(\u03c31, \u03c32) \u2265 \u00b5 (9)\nTo this end, set \u03c31 = \u03bb1a1 + (1\u2212 \u03bb1)b1 and \u03c32 = \u03bb2a2 + (1\u2212 \u03bb2)b2. From Equation (9) one gets {\n\u03bb1\u03bb2(1 + \u00b5) + (1\u2212 \u03bb1)\u03bb2(2 + \u00b5) + (1 \u2212 \u03bb1)(1\u2212 \u03bb2) \u2265 \u00b5 \u03bb1\u03bb2(1 + \u00b5) + (1\u2212 \u03bb2)\u03bb1(2 + \u00b5) + (1 \u2212 \u03bb1)(1\u2212 \u03bb2) \u2265 \u00b5 (10)\nTo compute the Nash equilibrium restricted to the induced game defined by these strategies is very easy. Indeed, it is clear, by simmetry, that this Nash equilibrium must be symmetric and so it is enough to find the lowest \u03bb such that (\u03bb, \u03bb) is a solution of (10). One easily finds \u03bb = \u00b5\u22121 \u00b5 , as claimed.\nAs a specific example of a one-shot Prisoner\u2019s dilemma, we consider the one recently experimented using MTurk in [DEJR12] with monetary outcomes (expressed in dollars) T = 0.20, R = 0.15, P = 0.05, S = 0. Fix i = 1. Denote by ps the selfish coalition structure, where the players are supposed to act separately. Then Gps = G, whose unique Nash equilibrium is (D,D). Since a Nash equilibrium has no deviations, thenD2(pc) = 0 and consequently v(ps) = 0.05. Now, let pc be the cooperative coalition structure, where the players are supposed to play together. The game Gpc is a one-player game whose only Nash equilibrium is (C,C). Now, D2(pc) = 0.05, since the second player can get 0.20 instead of 0.15 if she defects and the first player cooperates, and R2(pc) = 0.10, since the second player risks to get 0.05 instead of 0.15 if also the other player defects. Finally e1,\u2205(pc) = 0.15 and e1,2(pc) = 0. Consequently, v(pc) = 0.10, that is larger than v(ps). So we need to compute the Nash equilibrium of Ind(G, pc). By symmetry of the game, this is the same as finding the smallest \u03bb such that 0.15\u03bb2+0.2\u03bb(1\u2212\u03bb)+0.05(1\u2212\u03bb)2 \u2265 0.1, that is \u03bb = 12 . Consequenty, the cooperative equilibrium of this variant of the Prisoner\u2019s dilemma is 12C + 1 2D for both players. Notice that in [DEJR12] it has been\nreported that players cooperated with probability 58 per cent in one treatment and 65 per cent in another treatment and the over-cooperation in the second experiment was explained in terms of framing effect due to the different ways in which the same game were presented.\nExample 5.4. Let us consider the Bertrand competition. Each of N players simultaneously chooses an integer between 2 and 100. The player who chooses the lowest number gets a dollar amount times the number she bids and the rest of the players get 0. Ties are split among all players who submit the corresponding bid.\nThe unique Nash equilibrium of this game is to choose 2. Nevertheless, it has been reported in [Du-Gn00] that humans tend to choose larger numbers. It was also observed that the claims tend to get closer to the Nash equilibrium, when the number of players gets larger.\nTo compute the value of the cooperative coalition pc = ({1, . . . , N}) we observe that every player j has incentive Dj(pc) = 49 and risk Rj(pc) = 50. We then obtain\n\u2022 For N = 2, v1(pc) = v2(pc) = 50 \u00b7 50 99 , \u2022 For N = 4, one has\nv1(pc) = . . . = vN (pc) = 50 \u00b7\n( 1\u2212 3 \u00b7 49\n99 + 3 \u00b7\n( 49\n99\n)2 \u2212 ( 49\n99\n)3) ,\n\u2022 and so forth.\nIn other words, using the law of total probability, one can easily show that the value of the cooperative coalition converges to 0 very quickly. Consequently, when N increases, the value decreases and the cooperative equilibrium predicts smaller and smaller claims. This matches qualitatively what reported in a repeated Bertrand competion in [Du-Gn00].\nExample 5.5. In this example we show that the cooperative equilibrium theory fits an experiment reported by Kahneman, Knetsch and Thaler in [KKT86]. Consider the ultimatum game. A proposer and a responder bargain about the distribution of a surplus of fixed size that we suppose normalized to ten. The responder\u2019s share is denoted by s and the proposer\u2019s share by 10\u2212 s. The bargaining rules stipulate that the proposer offers a share s \u2208 [0, 10] to the responder. The responder can accept or reject s. In case of acceptance the proposer receives a monetary payoff 10\u2212 s, while the responder receives s. In case of a rejection both players receive a monetary return of zero.\nKahneman, Knetsch and Thaler conducted the following experiment: 115 subjects, divided in three classes, were asked to say what would be the minimum offer (between 0 and 10 Canadian dollars) that they would accept, if they were responders. The mean answers were between 2.00, 2.24 and 2.59 (see [KKT86], Table 2).\nNow, cooperative equilibrium theory predicts that the responder would accept any offer larger than the value of the coalition structure with the largest value. So let us compute the value for the responder of the two coalition structures ps and pc assuming that the two players have the same perception of money.\nDenote by A and R responder\u2019s actions accept and reject, respectively. As in Nash bargaining problem, we obtain that the cooperative coalition pc = ({1, 2}) leads to a one-player game Gpc with the unique acceptable equilibrium (5, A). Therefore, we have\nv2(pc) = 5\n2\nsince the first player can abandon the coalition playing every s < 52 , but she risks to lose everything if the second player rejects the offer (observe that R is a 2-deviation to the strategy s = 0). On the other hand, of course, one has v(ps) = 0, corresponding to the equilibrium (0, R).\nConsequently, cooperative equilibrium theory predicts that the responder would accept any offer larger than 2.5 dollars, which fits the experimental data reported in [KKT86].\nIn a very recent and not yet published experiment, Wells and Rand [We-Ra] reported that the average claim of 44 subjects was 10.7 out of 30 monetary units. This corresponds to 35.6 per cent which is apparently quite larger than what cooperative equilibrium predicts. However, making the average between the (normalized) results in [KKT86] and [We-Ra] - 44 subjects claimed an average of 0.356, 43 subjects claimed an average of 0.259, 37 subjects claimed an average of 0.224, and 35 subjects claimed an average of 0.200 - one finds an average claim of 0.264, which is in fact very close to the prediction of the cooperative equilibrium, which is 0.25.\nRemark 5.6. The cooperative equilibrium can predict well also other experimental data collected for the ultimatum game.\nRecall that the unique subgame perfect equilibrium of the ultimatum game is to offer s = 0. Nevertheless, there are numerous experimental studies which reject this prediction and show that proposers almost always make substantially larger offers. Fehr and Schmidt [Fe-Sc99] explained these observations making use of two parameters \u03b1i, \u03b2i for each player. Let us find out what happens using cooperative equilibrium.\nConcerning the selfish coalition ps = ({1}, {2}). One easily sees that\nv1(ps) = v2(ps) = 0,\nin correspondence to the subgame perfect equilibrium (0, R). Concerning the cooperative coalition, we have\nv1(pc) = 1\n2 ,\nsince the second player has no incentive to abandon the coalition, and\nv2(pc) = 1\n4 ,\nas shown in Example 5.5. Consequently, the exact cooperative equilibrium predicts that the proposer offers s = 0.25 and the responder accepts. This explains the fact that there are virtually no offer below 0.2 and above 0.5, which was observed in [Fe-Sc99] making a comparison among experimental data collected in [GSS82], [KKT86], [FHSS88], [RPOZ91], [Ca95], [HMcS96], and [Sl-Ro97].\nSo there are some data that can be explained by the cooperative equilibrium under expected utility theory and without altruism. Other data can be explained using altruism. For instance, it was observed that proposer\u2019s offer was very often higher than 0.25 and, in most of the cases, it was between 0.4 and 0.5 (cf. [Fe-Sc99], Table I). This stronger deviation towards cooperation is not predicted by the exact cooperative equilibrium without altruism and we will show in Example 8.11 how the cooperative equilibrium with altruism can explain it.\nWe now discuss an example that we believe is relevant because it makes predictions that are significantly different from Nash equilibrium. Such predictions are partially\nconfirmed by experimental data, but it would be important to conduct more precise experiments in order to see how humans behave in such a situation.\nExample 5.7. Let us consider the N -player public good game. There are N players, each of which has to decide on her contribution level xi \u2208 [0, y] to the public good. The monetary payoff of player i is given by\ngi(x1, x2, . . . , xN ) = y \u2212 xi + \u03b1(x1 + x2 + . . . + xN ),\nwhere 1 N\n< \u03b1 < 1 denotes the constant marginal return to the public good X = x1+x2+ . . .+xN . Notice that the unique perfect equilibrium is to choose xi = 0. Nevertheless, this free ride hypothesis has been rejected by numerous experimental studies (see, e.g., [Ma-Am81], [Is-Wa88], [IWW94], [Le95]). In particular, it was explicitly reported in [Is-Wa88] and [IWW94] the intuitive fact that, for a fixed number of player, claims get larger as \u03b1 get larger and the much less intuitive fact that, for a fixed \u03b1, claims get larger when the number of players is large enough. We now show that the first property is predicted by the cooperative equilibrium and we anticipate that the second property is predicted by the cooperative equilibrium under cumulative prospect theory.\nProposition 5.8. Let N , the number of players, be fixed. Denote v(pc) and v(ps) respectively the value of the cooperative coalition structure pc = ({1, . . . , N}) and of the selfish coalition structure ps = ({1}, . . . , {N}). Then the function v(pc)\u2212 v(ps) has the following properties:\n(1) it is strictly increasing in the variable \u03b1, (2) it is negative for \u03b1 = 1\nN ,\n(3) it is positive for \u03b1 = 1.\nThe proof of this proposition is a long and tedious computation. Here we report explicitly only the proof for N = 2. How to treat the general case should then be clear (use the law of total probabilities).\nProof of Proposition 5.8 with N = 2. Let pc = ({1, 2}) be the cooperative coalition structure. The unique Nash equilibrium of the game Gpc is (y, y) and each of the two players gets e1,\u2205(pc) = 2\u03b1y. Assume i = 1 (the case i = 2 is symmetric). Observe that D2(pc) = y+\u03b1y\u2212 2\u03b1y = y\u2212\u03b1y. Indeed, the best deviation for player 2 is to play x2 = 0, which gives a payoff of y+\u03b1y, if x1 = y. The risk is R2(pc) = 2\u03b1y \u2212 y. Indeed, if also player 1 abandons the coalition pc to play the selfish strategy x1 = 0, player 2 would get y instead of 2\u03b1y. Consequently\n\u03c41,{2}(pc) = y \u2212 \u03b1y\ny \u2212 \u03b1y + 2\u03b1y \u2212 y =\n1\u2212 \u03b1\n\u03b1 .\nOn the other hand, one has e1,{2}(pc) = \u03b1y, corresponding to player 2\u2019s defection. Therefore,\nv1(pc) = v2(pc) = 2\u03b1y \u00b7 2\u03b1\u2212 1\n\u03b1 + \u03b1y \u00b7\n1\u2212 \u03b1\n\u03b1 = (3\u03b1\u2212 1)y.\nOn the other hand, the selfish coalition ps = ({1}, {2}) has value y, corresponding to the equilibrium (0, 0). Consequently, the function v(pc)\u2212 v(ps) is strictly increasing in the variable \u03b1 and one has\nv(pc) = v(ps) \u21d0\u21d2 \u03b1 = 2\n3 .\nAs a quantitative comparison, we consider the experimental data reported in [GHL02], with \u03b1 = 0.8. We normalize y to be equal to 1 (in the experiment y = 0.04 dollars). In this case the cooperative equilibrium is supported between 0.66 and 0.67. In [GHL02] it has been reported that the average of contributions was 0.50, but the mode was 0.60 (6 out of 32 times) followed by 0.80 (5 out of 32 times).\nExample 5.9. We consider the finite version of Nash\u2019s bargaining problem as in Example 4.4. It is well known that the unique reasonable solution is (50, 50) and indeed a number of theories has been developed to select such a Nash equilibrium. For instance, in [Na50b], [Ka-Sm75], and [Ka77], the authors studied a set of additional axioms that guarantee that the unique solution of Nash bargaining problem is a 50-50 share. Other solutions, based on different solution concepts, have been recently proposed in [Ha-Ro10] and [Ha-Pa12].\nNow we show that also the cooperative equilibrium predicts a 50-50 share, if the two players have the same perception of gains.\nProposition 5.10. If the two players have the same perception of money, that is, f1 = f2, then the unique exact cooperative equilibrium is (50, 50).\nProof. As we have already seen in Example 4.4, the cooperative partition pc has a unique acceptable profile of strategies, which is (50, 50). Observe that Devj(p) = \u2205, for all j, and therefore Ind(G, p) is the game where both players can choose only the strategy 50. Consequently, we have\nv1(pc) = v2(pc) = 50.\nNow consider the selfish coalition structure ps = ({1}, {2}). This time the unique acceptable equilibria are\nAcc{1}(Gps) = (100, 0) Acc{2}(Gps) = (0, 100).\nObserving that Dev(ps) = \u2205, we then obtain\nv1(ps) = g1(100, 100) = 0.\nAnalogously, we obtain v2(ps) = g2(100, 100) = 0. Therefore the value of the cooperative coalition structure is larger than the value of the selfish coalition structure and, consequently, the set of exact cooperative equilibria of Nash bargaining problem coincides with the set of Nash equilibria of the induced game Ind(G, pc). Since this induced game contains only one profile of strategies, which is (50, 50), this is then its unique exact cooperative equilibrium.\nWe mentioned in the Introduction that there are other solution concepts that have been proposed in the last few years and we have discussed why believe that RenouSchlag-Halpern-Pass\u2019s iterated regret minimization is the most promising of them: the others are either too rigid or inapplicable to one-shot games. Contrariwise, iterated regret minimization can explain deviations from Nash equilibria in several games. Nevertheless, as observed in [Ha-Pa12], it fails to predict human behavior for some other games, such as the Prisoner\u2019s dilemma, the public good game, and the Traveler\u2019s dilemma with punishment. We have already computed the cooperative equilibrium for the Prisoner\u2019s dilemma and the public good game and we now make a parallelism\nbetween iterated regret minimization and cooperative equilibrium for the Traveler\u2019s dilemma with punishment.\nExample 5.11. Consider a variant of the Traveler\u2019s dilemma that has been proposed in [Ha-Pa12], Section 6. Let us start from the Traveler\u2019s dilemma in Example 4.6 where, this time, the strategy set is {2, 3, . . . , 100} for both players and the bonus-penalty is b = 2. Suppose that we modify this variant of the Traveler\u2019s dilemma so as to allow a new action, called P (for punish), where both players get 2 if they both play P, but if one player plays P and the other plays an action other than P, then the player who plays P gets 2 and the other player gets \u221296. In this case (P,P ) is a Nash equilibrium and it is also the solution in terms of regret minimization. As observed in [Ha-Pa12], this is a quite unreasonable solution, since the intuition suggests that playing P should not be rational. In fact, one can easily check that, from our point of view, this game is absolutely the same as the original Traveler\u2019s dilemma9 and therefore it has got the same cooperative equilibria."}, {"heading": "6. Towards cumulative prospect theory", "text": "In the previous section we have discussed a set of examples where the cooperative equilibrium under expected utility theory predicts human behavior satisfactorily well. On the other hand, since we are working with gain functions, it is natural to use cumulative prospect theory instead of expected utility theory. But before describing the cooperative equilibrium under cumulative prospect theory, we discuss a few examples where the passage from expected utility theory to cumulative prospect theory may explain observations that are not consistent with the cooperative equilibrium under expected utility theory.\nExample 6.1. We mentioned before that has been observed that contributions in the Public Goods game depend on the number of players in a puzzling way: they first decreases as the number of players increases, but then, when the number of players if sufficiently large, they increase again. This behavior is not predicted by the cooperative equilibrium under expected utility theory, which predicts that contributions decreases as the number of players increases. Nevertheless, this behavior is consistent with the cooperative equilibrium under cumulative prospect theory.\nIndeed, given the N -player Public Goods game with marginal return \u03b1, the prior probability that player j abandons the coalition is\n\u03c4i,j(pc) = 1\u2212 \u03b1\n\u03b1(N \u2212 1) .\nConsequently, when N is large enough, all the events \u201cj abandons the coalition\u201d have negligible probability. Now, one of the principles of cumulative prospect theory is that decision makers treat extremely unlikely events as impossible (see [Ka-Tv79], p.275) and therefore, a part from very risk averse people, most of the agents would actually replace this probability just by 0. So the cooperative equilibrium is consistent with the tendency to cooperate that has been observed in large groups.\nExample 6.2. The following game has been proposed by J. Halpern in a private communication. Two players have the same strategy set {a, b, c} and the gains are described by the matrix\n9Basically because strategies with very small payoff, such as P , do not enter in our computation of the value of the cooperative coalition.\na b c a x, x 0, 0 0, y b 0, 0 x, x 0, y c y, 0 y, 0 y, y\nwhere x > y > 0. In this case one finds v(pc) = v(ps) = 0 and consequently, the set of exact cooperative equilibrium is equal to the set of Nash equilibria. Nevertheless, in this case it is very likely that if y and x are very close and much larger than 0, then the two players should coordinate and play the safe strategy c. Also this behavior would be predicted by the cooperative equilibrium under cumulative prospect theory: the strategies a and b are deleted a priori since perceived too risky with respect to the safe strategy."}, {"heading": "7. A brief introduction to cumulative prospect theory", "text": "The examples described in the previous sections give one more motivation to abandon expected utility theory and use cumulative prospect theory. Before starting the description of the cooperative equilibrium under cumulative prospect theory, we take this short section to give a short introduction to this theory.\nBy definition, a prospect p = (x\u2212m, p\u2212m; . . . ;x\u22121, p\u22121;x0, p0;x1, p1; . . . ;xn, pn) yields outcomes10 x\u2212m < . . . < x\u22121 < x0 = 0 < x1 < . . . < xn with probabilities pi > 0, for i 6= 0, and p0 \u2265 0, that sum up to 1.\nExpected utility theory was founded by Morgenstern and von Neumann in [Mo-vN47] to predict the behavior of a decision maker that must choose a prospect among some. Under certain axioms (see, for instance, [Fi82]) Morgenstern and von Neumann proved that a decision maker would evaluate each prospect p using the value\nV (p) =\nn\u2211\ni=\u2212m\npiu(xi), (11)\nwhere u(xi) is the utility of the outcome xi, and then she would choose the prospect(s) maximizing V (p).\nIt has been first realized by M. Allais in [Al53] that a human decision maker does not really follow the axioms of expected utility theory and, in particular, she evaluates a prospect using an evaluation procedure different from the one in (11). A first attempt to replace expected utility theory with a theory founded on different axioms and able to explain deviations from rationality was done in [Ka-Tv79], where Kahneman and Tversky founded the so-called prospect theory. This novel theory encountered two problems. First, it did not always satisfy stochastic dominance, an assumption that many theorists were reluctant to give up. Second, it was not readily extendable to prospects with a large number of outcomes. Both problems could be solved by the rank-dependent or cumulative functional, first proposed by Quiggin [Qu82] for decision under risk and by Schmeidler[Sc89] for decision under uncertainty. Finally, Kahneman and Tversky were able to incorporate the ideas presented in [Qu82] and [Sc89] and developed their cumulative prospect theory in [Tv-Ka92]. Prospect theory and cumulative prospect theory\n10Prospect theory and cumulative prospect theory have been originally developed for monetary outcomes (see [Ka-Tv79], p.274, l.4), giving us one more motivation to abandon utility functions and work with gain functions. Kahneman and Tversky\u2019s choice to work with monetary outcomes is probably due to the second principle of their theory, as it will be recalled little later.\nhave been successfully applied to explain a large number of phenomena that expected utility theory was not able to explain, as the disposition effect [Sh-St85], asymmetric price elasticity [Pu92],[Ha-Jo-Fa93], tax evasion [Dh-No07], as well as many problems in international relations [Le92], finance [Th05], political science [Le03], among many others11.\nThe basic principles of cumulative prospect theory are the following.\n(P1) Decision makers weight probabilities in a non linear manner. In particular, the evidence suggests that decision makers overweight low probabilities and underweight high probabilities. (P2) Decision makers think in terms of gains and losses rather than in terms of their net assets12. (P3) Decision makers tend to be risk-averse with respect to gains and risk-acceptance with respect to losses13. (P4) Losses loom larger than gains; namely, the aggravation that one experiences in losing a sum of money appears greater than the pleasure associated with gaining the same amount of money.\nThe consequence of these principles is that decision makers evaluate a prospect p using a value function\nV (p) =\nn\u2211\nj=\u2212m\n\u03c0jv(xj) (12)\nthat is completely different from the one in (11). To understand the explicit shape of the functions v and \u03c0 is probably the most important problem in cumulative prospect theory. About the function v, it has been originally proposed in [Tv-Ka92] to use the function\nv(x) = { x\u03b1, if x \u2265 0; \u2212\u03bb(\u2212x)\u03b2, if x < 0.\nwhere experiments done in [Tv-Ka92] gave the estimations \u03b1 \u223c \u03b2 \u223c 0.88 and \u03bb \u223c 2.25. About the function \u03c0, the situation is much more intrigued: cumulative prospect theory postulates the existence of a strictly increasing surjective function w : [0, 1] \u2192 [0, 1] such that\n\u03c0\u2212m = w(p\u2212m)\n\u03c0\u2212m+1 = w(p\u2212m + p\u2212m+1)\u2212w(p\u2212m) ...\n\u03c0j = w\n( j\u2211\ni=\u2212m\npi\n) \u2212 w ( j\u22121\u2211\ni=\u2212m\npi\n) j < 0\n\u03c00 = 0\n\u03c0j = w\n  n\u2211\ni=j\npi\n \u2212 w   n\u2211\ni=j+1\npi\n  j > 0\n11The two papers in prospect theory and cumulative prospect theory have more than 30000 citations. 12This principle is probably the one which forced Kahneman and Tversky to work with monetary outcomes and force us to work with gain functions. 13As a consequence, risk aversion is already taken into account and this is why we did not need to consider it explicitly in the definition of a game in explicit form.\n...\n\u03c0n\u22121 = w(pn\u22121 + pn)\u2212 w(pn)\n\u03c0n = w(pn)\nA first proposal of such a function w was made by Tversky and Kahneman themselves in [Tv-Ka92] and it is\nw(p) = p\u03b3\n(p\u03b3 + (1\u2212 p)\u03b3) 1 \u03b3\nwhere \u03b3 has been estimated to belong to the interval [ 1 2 , 1 ) in [Ri-Wa06]. Other functions w have been proposed in [Ka79], [Go-Ei87], [R87], [Cu-Sa89], [La-Ba-Wi92], [Lu-Me-Ch93], [He-Or94], [Pr98], and [Sa-Se98].\nIt is not our purpose to give too many details about the enormous literature devoted to understanding the evaluation procedure in cumulative prospect theory. Our purposes were indeed to give a brief introduction to the theory and stress how this theory implies the necessity to work with gain functions instead of utility functions. So we now pass to the description of the cooperative equilibrium for finite games in explicit form under cumulative prospect theory and taking into account altruism."}, {"heading": "8. Iterated Deletion: the set of playable strategies", "text": "The cooperative equilibrium under cumulative prospect theory and taking into account altruism will be defined through two steps. In the first step we use the altruism functions aij to eliminate the strategies that are not good for the collectivity. The second step is the prospect theoretical analogue of the procedure described in Section 4, applied to the subgame obtained after eliminating the strategies in the first step.\nIn this section we describe the first step of the construction, that we call iterated deletion. As well known, iterated deletion of strategies is a procedure which is common to most solution concepts (in Nash theory, one deletes dominated strategies; in iterated regret minimization theory, one deletes strategies which do not minimize regret; in Bernheim\u2019s and Pearce\u2019s rationability theory ([Be84] and [Pe84]), one deletes strategies that are not justifiable [Os-Ru94]). However, the use of altruism to delete strategies seems new in the literature. This iterated deletion of strategies is based on a new notion of domination between strategies, that we call super-domination14, which is motivated by the fact that human players do not eliminate weakly or strongly dominated strategies (as shown by the failure of the classical theory to predict human behavior in the Prisoner\u2019s and Traveler\u2019s Dilemmas).\nEach step of our iterated deletion of strategies is made by two sub-reductions. The first sub-reduction is based on the following principle:\n(CS) If si \u2208 Si is a strategy for which there is another strategy s \u2032 i \u2208 Si which gives a\ncertain larger gain (or a certain smaller loss) to player i and does not harm too much the other players, then player i will prefer the strategy s\u2032i and will never ever play the strategy si.\nThus, this principle states that every player is selfish unless the society gets a big damage. As we mentioned before, implicit in this principle there is a new notion of domination between strategies.\n14A slightly stronger notion of domination between strategies has been independenlty introduced in [Ha-Pa13], under the name minimax domination.\nDefinition 8.1. Let si, s \u2032 i \u2208 Si. We say that si is super-dominated by s \u2032 i and we write si <i s \u2032 i, if\n(1) for all s\u2212i, s \u2032 \u2212i \u2208 S\u2212i, one has gi (si, s\u2212i) \u2264 gi ( s\u2032i, s \u2032 \u2212i ) , (2) there are s\u2212i, s \u2032 \u2212i \u2208 S\u2212i such that gi (si, s\u2212i) < gi ( s\u2032i, s \u2032 \u2212i ) .\nObserve that super-domination is much stronger than the classical notion of weak domination. This makes sense since it has been observed that in many situations, as in the Traveler\u2019s dilemma, players do not eliminate weakly dominated strategies, while it is clear that a purely selfish player would delete a super-dominated strategy. On the other hand, there is no direct relation between super-domination and strong-domination, as shown by the following examples.\nExample 8.2. Consider the following version of the Prisoner\u2019s dilemma\nL R U 2, 2 0, 3 D 3, 0 1, 1\nThe strategy D strongly dominates U and the strategy R strongly dominates the strategy L. Nevertheless, there are no super-dominated strategies, since g1(D,R) < g1(U,L) and g2(D,R) < g2(U,L).\nExample 8.3. Consider the two-person zero-sum game\nL R U 0, 0 10,\u221210 D 1,\u22121 1,\u22121\nIn this case L super-dominates R, but R is not strongly dominated by L, since g2(D,R) = g2(D,L).\nWe will see in Example 8.13 that the notion of super-domination between strategies can be interesting in itself, since it allows to explain some phenomena that are not easy to capture making use of weakly and strongly dominated strategies.\nBefore coming back to the theory, we need to fix some terminology. Fix \u03c3i \u2208 P(Si), the fiber game defined by \u03c3i is the (N \u2212 1)-player game G\u03c3i obtained by G assuming that player i plays the strategy \u03c3i surely. Formally, G\u03c3i = G(P \\{i}, S\u2212i, g, g\u03c3i , a\u2212i, f\u2212i), where g\u03c3i is the (N\u22121)-dimensional vector whose components are the functions gj(\u03c3i, \u00b7), with j \u2208 P \\ {i}, a\u2212i = (ajk)j,k\u2208P\\{i},j 6=k, f\u2212i = (fj)j\u2208P\\{i}. Using a trick which is conceptually similar to the one used in [Ha-Ro10], we define the cooperative equilibrium by induction on the number of players.\nDefinition 8.4. The cooperative equilibria of a one-player game are all probability measures supported on the set of pure strategies that maximize the gain function and give rise to acceptable equilibria15.\nNow we suppose that we have already defined the cooperative equilibrium for all (N \u2212 1)-player games and we define the cooperative equilibrium for all N -player games. We denote by Coop(G) the set of cooperative equilibria of a game G.\nNow, fix i \u2208 P and let s, t \u2208 Si, with s <i t. If player i is believed to play the strategy t, the other players would answer playing an equilibrium of the fiber game Gt. Since the\n15As observed in Remark 4.7, when there are many such equilibria, it might make sense to consider only the barycenter.\nfiber game has N \u2212 1 players, we may use the inductive hypothesis. We define the set of losers Li(s, t) to be the set of players j \u2208 P such that\n(1) gj\n( s, \u03c3\n(s) \u2212i ) > gj ( t, \u03c3 (t) \u2212i ) , for all \u03c3 (t) \u2212i \u2208 Coop(Gt), \u03c3 (s) \u2212i \u2208 Coop(Gs), and\n(2) gj\n( t, \u03c3\n(t) \u2212i ) < gi ( t, \u03c3 (t) \u2212i ) , for all \u03c3 (t) \u2212i \u2208 Coop(Gt).\nIn words, Li(s, t) is the set of players that have a certain disadvantage when player i decides to play the strategy t instead of her worse strategy s (Condition (1)) and that are weaker than player i when she plays her better strategy s (Condition (2)).\nNow, if player i decides to renounce to play t and accept to play s, then she renounce to a certain gain of inf { gi ( t, \u03c3 (t) \u2212i ) : \u03c3 (t) \u2212i \u2208 Coop(Gt) } , to accept a smaller gain. Her maximal loss is then:\nPi(s, t) := sup { inf { gi ( t, \u03c3 (t) \u2212i ) : \u03c3 (t) \u2212i \u2208 Coop(Gt) } \u2212 gi ( s, \u03c3 (s) \u2212i ) : \u03c3 (s) \u2212i \u2208 Coop(Gs) } .\nOn the other hand, the best that can happen to player j \u2208 Li(s, t) if player i decides to play her worse strategy s is\nQj(s, t) := sup { gj ( s, \u03c3 (s) \u2212i ) \u2212 inf { gj ( t, \u03c3 (t) \u2212i ) : \u03c3t\u2212i \u2208 Coop(Gt) } : \u03c3\u2212i(s) \u2208 CoopGs } .\nNow, set\nP \u2032i (t) := inf { gi ( t, \u03c3 (t) \u2212i ) : \u03c3 (t) \u2212i \u2208 Coop(Gt) } .\nIn words, this number is the certain gain that player i would get if she decides to play her better strategy t. Now, set\nQ\u2032j(s) := inf { gj ( s, \u03c3 (s) \u2212i ) : \u03c3 (s) \u2212i \u2208 Coop(Gs) } .\nIn words, this number is the certain gain that player j would get if player i decides to play her worse s.\nTherefore, we have reduced the problem of choosing s or t to the following problem: does player i accept to renounce to Pi(s, t) out of P \u2032 i (s, t) in order to give a gain ofQj(s, t) to player j, who already had a certain gain of Q\u2032j(s, t)? This is in fact a generalized dictator game. So, we set\nAij(s, t) = aij\n( Qj(s, t)\nPi(s, t) , P \u2032i (t), Q \u2032 j(s)\n) ,\nand we give the following definition.\nDefinition 8.5. A strategy s \u2208 Si is unplayable of the first type for player i if there is another strategy t \u2208 Si such that\n\u2022 s <i t \u2022 for all j \u2208 Li(s, t), one has Pi(s, t) > Aij(s, t).\nIn this case we write s <Ii t.\nExample 8.6. Consider the game with gain matrix\nL R U 1, 1 1, 1 D 1, 1 2, 1\nObserve that U <1 D. Moreover, L1(U,D) = \u2205 and therefore the second condition in Definition 8.5 is true for trivial reasons. Consequently, the strategy U is unplayable of the first type for the first player. This happens, roughly speaking, because the columnplayer, playing D, can have a gain without damaging the row-player.\nExample 8.7. A little less trivial example is given by the game represented by the following gain matrix\nL R U 0, 0 0, 0 D 1,\u22121 1,\u22121\nAssume a12(1, 1,\u22121) < 1. Of course, U <1 D. Now, observe that P1,2(U,D) = 1 and that A12(s, t) = a12(1, 1,\u22121), thus the strategy U is unplayable of the first type for the vertical player. Roughly speaking, this happens because the vertical player, playing D, will get a certain gain giving a damage to the horizontal player that is small compared to her gain.\nComing back to the theory, we would like to delete unplayable strategies of the first type. To this end, we need to prove a simple lemma. Given si \u2208 Si, let Maj\nI(si) ={ s\u2032i \u2208 Si : si < I i s \u2032 i } .\nLemma 8.8. For all i \u2208 P , there exists si \u2208 Si such that Maj I(si) = \u2205.\nProof. By contradiction, let MajI(si) 6= \u2205, for all si \u2208 Si. Fix s (1) i \u2208 Si. An iteration of the property MajI 6= \u2205 allows to construct a chain\ns (1) i < I i s (2) i < I i . . . < I i s (n) i\nBy finiteness of the set Si, we may assume that at some point we get s (n) i = s (1) i , with s (n\u22121) i 6= s (1) i . Observe that the relation < I i might not be transitive, but the underlying relation <i is transitive. Therefore, we have gotten\ns (1) i <i s (n\u22121) i and s (n\u22121) i <i s (1) i\nthat contradict each other.\nLet UnPl (1) i (G) be the set of player i\u2019s unplayable strategies of the first type and\ndenote by Pl (1) i (G) := Si\\UnPl (1) i (G), that is well defined and non-empty by Lemma 8.8. The notation Pl (1) \u2212i (G) stands for the cartesian product of all the Pl (1) j (G)\u2019s but Pl (1) i (G).\nNow we start the description of the second sub-restriction, that will be done through the definition of unplayable strategies of the second type. The principle underlying this second restriction is somehow the dual principle of the one underlying the previous restriction:\n(PA) If s \u2208 Si is a strategy for which there is another strategy t \u2208 Si such that player i has a little disadvantage, but the other players have a big advantage, then player i will prefer the strategy t in order to help the society.\nAs said earlier, the principle (CS) is a sort of controlled selfishness, whereas the principle (PA) sounds more like pure altruism. We can formalize it in a similar way as we formalized (CS). Indeed, we can use the number Pi(s, t) and Aij(s, t) in the dual way.\nDefinition 8.9. A strategy t \u2208Pl (1) i (G) is called unplayable of the second type for player i if there is another strategy s \u2208 Pl (1) i (G) such that\n(1) s <i t, (2) There exists j \u2208 Li(s, t) such that Pi(s, t) \u2264 Aij(s, t).\nExample 8.10. Consider the standard dictator game Dict(1, 10, 0), that is, a proposer offers a division of 10 dollars, which the responder has to accept. The standard perfect equilibrium analysis of this games is that the proposer should keep all the money, since the responder has no say. Nevertheless, in experiments has been reported that most proposers offer a certain amount of money to the responder (see, for instance, [Fo-Ho-Sa-Se94]). Bolton and Ockenfels explained this anomalous behavior using equity in [Bo-Oc00]. We can explain it using iterated deletion of strategies using altruism. Let us model the set of strategies of the proposer, for simplicity, by S = {0, 1, . . . , 10}. It is clear that there is a chain of super-dominated strategies for the proposer: 0 <prop 1 <prop 2 <prop . . . <prop 10. Now, one can easily show that every strategy s with s < aprop,resp(1, 10, 0) is unplayable of the second type for the proposer. Therefore, cooperative equilibrium theory predicts that the proposer offers a fairer division because of altruism. Moreover, the larger is aprop,resp(1, 10, 0), the larger is the offer.\nExample 8.11. We have seen in Example 5.5 that the cooperative equilibrium without altruism of the Ultimatum game is that the proposer offers 0.25 and the responder accepts. Nevertheless, it has been reported that most of proposers actually propose a share closer to 0.5. This can be explained taking into account altruism. Indeed, if we model the set of strategies of the proposer using the set S = {0.00, 0.01, 0.02, . . . , 1.00}, then in the induced game Ind(G, pc), the strategy 0.25 is super-dominated for the proposer by 0.26, which is super-dominated by 0.27 and so forth. As in the previous example, some of these strategies are unplayable of the second type and therefore, altruism can explain why offers are tipically larger than 0.25.\nLet UnPl (2) i (G) be the set of player i\u2019s unplayable strategies of the second type and\ndenote by Pl (2) i (G) :=Pl (1) i (G)\\UnPl (2) i (G). This set is well defined and non-empty thanks to the obvious analogue of Lemma 8.8. Now, we start an iteration of this procedure: we consider the subgame G2 of G defined by the strategy sets Pl (2) i (G) and we reduce again these strategy sets computing the unplayable strategies of the two types; in this way, we get other sets of playable strategies Pl (2) i (G2); and we start again the procedure. By finiteness of the strategy sets Si, this iteration stabilizes, that is, at some step k, one has have Pl (2) i (Gk) =Pl (2) i (Gk+1) and this set is clearly non-empty. We set Pli := Pl (2) i (Gk).\nDefinition 8.12. The set Pli is called set of playable strategies of player i.\nBefore starting the second step of the construction, that is, the prospect theoretical analogue of Section 4, we give more details about the game introduced in Example 8.3. Indeed, this game seems interesting from several viewpoints. First, it is an example where the procedure of elimination of unplayable strategies stabilizes after more than one step. Then, it is one more example where iterated regret minimization theory fails to predict the intuitively right behavior, whereas the cooperative equilibrium does apparently the right job. Finally, it is an example where super-dominated strategies turn out to be helpful to modify iterated regret minimization theory allowing prior beliefs\nand consequently obtaining the right prediction also under iterated regret minimization theory.\nExample 8.13. Consider the same two-person zero-sum game as in Example 8.3, that is, the game with gain matrix\nL R U 0, 0 10,\u221210 D 1,\u22121 1,\u22121\nAssume that a12(1, 1,\u22121) < 1. Observe that L super-dominates R and that L2(R,L) = \u2205. Consequently, R is unplayable of the first type. On the other hand, in this first step U and D are not ordered and therefore, the first step of the iterated deletion leads to the subgame G2 where the vertical player still has both strategies U and D available, whereas the horizontal player has only the strategy L. Therefore, in the game G2, the strategy U is unplayable of the second type for the column-player (since a12(1, 1,\u22121) < 1) and, consequently, one more application of deletion of unplayable strategies leads to the trivial game where the vertical player has only the strategy D and the horizontal player has only the strategy L. Therefore, (D,L) is the unique cooperative equilibrium of this game. Observe that this is also a Nash equilibrium. The other Nash equilibrium is( D, 910L+ 1 10R ) , as one can easily check, which is quite unreasonable, since there is no reason why the horizontal player should play R: playing L she will certainly get at least the same as playing R. Therefore, the cooperative equilibrium coincides with the most reasonable Nash equilibrium.\nOn the other hand, a direct application of the iterated regret minimization procedure predicts that the vertical player plays U surely. This is also quite unreasonable, because playing U makes sense only if the column-player plays R. This cannot happen, above all if the column-player understands that the row-player is going to play U. As suggested by Halpern in a private communication, one can fix this problem allowing prior beliefs, in a conceptually similar way as in [Ha-Pa12], Section 3.5: first one eliminates weakly dominated strategies, then applies iterated regret minimization. Nevertheless, this procedure is questionable on one point: it is not clear why one should eliminate weakly dominated strategies in this context and not in the Traveler\u2019s dilemma16. One can fix this problem using super-domination. If one eliminates super-dominated strategies in the game under consideration before applying iterated regret minimization, one finds the right solution (D,L), coherently with the classical theory and the cooperative equilibrium. Moreover this is perfectly coherent with the other examples discussed in [Ha-Pa12] and in particular with the Traveler\u2019s dilemma: the Traveler\u2019s dilemma has many weakly dominated strategies, but none of them is super-dominated."}, {"heading": "9. The cooperative equilibrium under cumulative prospect theory", "text": "In this section we finally define the cooperative equilibrium for games in explicit form G = G(P, S, g, g, a, f) in complete generality.\nIn the previous section we have restricted the sets of pure strategies and we have defined the sets of playable strategies Pli. We denote by Red(G) this reduced game, that is, the subgame of G defined by the strategy subsets Pli. The cooperative equilibrium of G (under prospect theory and taking into account altruism) will be obtained by applying the construction described in Section 4 to the reduced game Red(G) and making use\n16If one eliminates weakly dominates strategies in the Traveler\u2019s dilemma before applying iterated regret minimization, one obtains the Nash equilibrium.\nof cumulative prospect theory. To this end, notice that the construction presented in Section 4 depends on expected utility theory only on two points:\n(1) We have used expected utility theory to compute the value of the prospect\n(ei,J(p), \u03c4i,J(p))\nindexed by J \u2286 P \\ {i}. Using cumulative prospect theory, the value that we denoted vi(p) should be replaced by its prospect theoretical analogue\nvCPTi (p) = \u2211\nJ\u2286P\\{i}\nv(ei,J (p))\u03c0\u03c4i,J (p). (13)\nSince the value v(x) represents how the players perceive a gain of x, also the definition of the induced game should be modified: indeed we should allow only the profiles of strategies \u03c3 such that v(gi(\u03c3)) \u2265 v CPT i (p). Consequently, the two applications of the function v, the first in the computation of vCPTi and the second in the definition of the induced game, are somehow inverse. Indeed, if v were linear and increasing, the induced game would have been the same as the one obtained by setting v(x) = x. Now, we know from cumulative prospect theory that v is strictly increasing. Approximating it by a linear function we can simplify a lot the definition setting v(x) = x. This explains why the examples in Section 6 fit the experimental data very well: they have been conducted with relatively small monetary outcomes and there were no possible losses. Of course, it is predictable that in case of possible large gains and/or losses, this approximation will create problems. (2) The definition of the value of a coalition and then the definition of the cooperative equilibrium rely in the computation of Nash equilibria of the games Gp and Ind(G, p). The computation of Nash equilibria uses expected utility theory, precisely in the definition of the mixed extension of the gain functions. Unfortunately, the natural translation of Nash equilibrium in the language of cumulative prospect theory leads to define an object that might not exist (see [Cr90] and, more generally, [Fi-Pa10]). To avoid this problem we consider a solution concept which is a bit more general than Nash equilibrium, the so-called equilibrium in beliefs, introduced by Crawford in [Cr90]. Crawford\u2019s equilibria in beliefs have the good property to exist in our context, contain all Nash equilibria, and reduce to Nash equilibria in many cases. The remainder of the section is devoted to this.\nBefore recalling the definition of an equilibrium in beliefs, we need to do a preliminary step, that is writing the mixed extension of the gain functions in the language of cumulative prospect theory. Since notation will get complicated very soon, we start by an example.\nExample 9.1. Consider the (already reduced) game with gain matrix:\nC D C 2, 2 0, 3 D 3, 0 1, 1\nAssume that the column-player (player 1) plays the mixed strategy \u03c31 = 1 8C + 7 8D and player 2 plays the mixed strategy \u03c32 = 1 4C + 3 4D. Under expected utility theory, we\nwould have g1(\u03c31, \u03c32) = \u2211\nx\u2208S1\n\u2211\ny\u2208S2\ng1(x, y)\u03c31(x)\u03c32(y).\nLet us compute step by step this number to put in evidence where and how expected utility theory must be replaced by cumulative prospect theory. Fix \u03c32 as before and observe that we have a finite family of prospects, one for each pure strategy of the first player. In this example, they are:\np(C,\u03c32) = ( 2, 1\n4 ; 0,\n3\n4\n) and p(D,\u03c32) = ( 3, 1\n4 ; 1,\n3\n4\n) .\nNow, under expected utility theory (and this is the first point where expected utility theory is used), one computes the values of the two prospects, obtaining, in this particular example, the values\nV1(C, \u03c32) = 2 \u00b7 1\n4 + 0 \u00b7\n3 4 = 1 2 and V1(D,\u03c32) = 3 \u00b7 1 4 + 1 \u00b7 3 4 = 3 2 .\nOf course, these numbers are equal to the ones that are usually denoted by g1(C, \u03c32) and g2(D,\u03c32), respectively. Now, to compute the value usually denoted by g1(\u03c31, \u03c32), one first constructs one more prospect using the measure \u03c31, that is\np(\u03c31,\u03c32) =\n( 1\n2 , 1 8 ; 3 2 , 7 8\n) ,\nand finally, again under expected utility theory, one computes the value of this prospect, obtaining the well known value g1(\u03c31, \u03c32).\nWe want to replace the classical values gi(\u03c3i, \u03c3\u2212i) with new values Vi(\u03c3i, \u03c3\u2212i), obtained replacing expected utility theory with cumulative prospect theory. From the example, it is clear that, to compute Vi(\u03c3i, \u03c3\u2212i) in cumulative prospect theory, we only need to compute first Vi(si, \u03c3\u2212i), for all si \u2208 Pli, using cumulative prospect theory on the prospects p(si,\u03c3\u2212i), and then compute Vi(\u03c31, \u03c32) using cumulative prospect theory on the prospect p(\u03c3i,\u03c3\u2212i). To make this idea formal, recall that in cumulative prospect theory the outcomes of a prospect are supposed to be ordered in increasing way. It is then useful to associate to each prospect p = (x1, p1; . . . ;xn, pn), with distinct outcomes17 xi \u2208 R, a permutation \u03c1(p) that is just the permutation of the xi\u2019s such that \u03c1(p)(xi) < \u03c1(p)(xi+1), for all i. Now for all (si, s\u2212i) \u2208 Pli \u00d7 Pl\u2212i, we define\nA (si,s\u2212i) i := { s\u2032i \u2208 Pl\u2212i : gi(si, s\u2212i) = gi(si, s \u2032 \u2212i) } .\nFor any fixed si, the sets Ai\u2019s form a partition of Pl\u2212i. Choose a transversal Tsi for this partition, that is, Tsi is a subset of Pl\u2212i constructed picking exacty one point for each set Ai. Now fix (\u03c3i, \u03c3\u2212i) \u2208 P(Pli)\u00d7 P(Pl\u2212i) and define the prospect\np(si,\u03c3\u2212i) = ( gi(si, s\u2212i), \u03c3\u2212i ( A (si,s\u2212i) i )) ,\nwhere s\u2212i runs over the transversal Tsi . Of course, this prospect does not depend on the particular transversal we fixed. Now, the outcomes of this prospect might not be ordered in increasing way. Therefore, before applying cumulative prospect theory to compute Vi ( si, p (si,\u03c3\u2212i) ) we must apply the permutation \u03c1 ( p(si,\u03c3\u2212i) ) . Consequently,\n17If this prospect does not contain the zero-payoff, we add it with probability zero.\nwith the notation as in Section 7, we obtain\nVi ( si, p (si,\u03c3\u2212i) ) = \u2211\ns\u2212i\u2208Tsi\n\u03c0s\u2212iv ( \u03c1 ( p(si,\u03c3\u2212i) ) (gi(si, s\u2212i)) ) .\nTo construct the second prospect p(\u03c3i,\u03c3\u2212i), we follow an analogous procedure. Let\nB (si,\u03c3\u2212i) i = { s\u2032i \u2208 Pli : Vi(si, \u03c3\u2212i) = Vi(s \u2032 i, \u03c3\u2212i) } .\nThe Bi\u2019s form a partition of Pli. Let T\u03c3\u2212i be a transversal for this partition. We define the prospect\np(\u03c3i,\u03c3\u2212i) = ( Vi(si, \u03c3\u2212i), \u03c3i ( B (si,\u03c3\u2212i) i )) ,\nwhere si runs over T\u03c3\u2212i . Therefore we obtain\nVi(\u03c3i, \u03c3\u2212i) = \u2211\nsi\u2208T\u03c3 \u2212i\n\u03c0siv\n \u03c1 ( p(\u03c3i,\u03c3\u2212i) )   \u2211\ns\u2212i\u2208Tsi\n\u03c0s\u2212iv ( \u03c1 ( p(si,\u03c3\u2212i) )) (gi(si, s\u2212i))     .\nOne is now tempted to define a Nash equilibrium of a game under cumulative prospect theory as a profile (\u03c31, . . . , \u03c3N ) of mixed strategies such that for all i \u2208 P and for all \u03c3\u2032i \u2208 P(Si) one has Vi(\u03c3i, \u03c3\u2212i) \u2265 Vi(\u03c3 \u2032 i, \u03c3\u2212i). As mentioned before, unfortunately, there are games without Nash equilibria in this sense. To avoid this problem, we use Crawford\u2019s trick to extend the set of Nash equilibria including the so-called equilibria in beliefs. To do that, first we recall the following classical definition.\nDefinition 9.2. Let D \u2286 Rn be a convex set and let \u03c6 : D \u2192 R be a function. The upper contour set of \u03c6 at a \u2208 R is the set\nU\u03c6(a) = {x \u2208 D : \u03c6(x) \u2265 a} .\ng is called quasiconcave on D if U\u03c6(a) is a convex set for all a \u2208 R.\nThe following definition appeared in [Cr90], Definition 3. In this definition the word game is used to denote a classical finite game in normal form G = G(P, S, u), where the utility functions are extended to the mixed strategies in a possibly non-linear manner.\nDefinition 9.3. The convexified version of a game is obtained from the game by replacing each player\u2019s preferences by the quasiconcave preferences whose upper contour sets are the convex hulls of his original upper contour sets, leaving other aspects of the game unchanged.\nWe now define Crawford\u2019s equilibria in beliefs through an equivalent condition proved by Crawford himself in [Cr90], Theorem 1.\nDefinition 9.4. An equilibrium in beliefs is any Nash equilibrium of the convexified version of the game.\nCrawford proved in [Cr90], Observation 1, that a Nash equilibrium is always an equilibrium in beliefs and, in Observation 2, that the set of equilibria in beliefs coincides with the set of Nash equilibria if the players have quasiconcave preferences.\nWe can now define the cooperative equilibria of a game in explicit form.\nDefinition 9.5. The cooperative equilibria of a game in explicit form G = G(P, S, g, g, a, f) are obtained applying to the reduced game Red(G) the procedure described in Section 4, replacing\n\u2022 the function gi(\u03c3) with the function Vi(\u03c3), \u2022 the notion of Nash equilibrium with the notion of equilibrium in beliefs, \u2022 the value function vi(p) in (1) with the one in (15).\nTheorem 9.6. Cooperative equilibria exist for all finite games in explicit form.\nProof. Let G = G(P, S, g, g, a, f) be a finite game in explicit form. We have already proved in Section 8 that the iterated deletion of strategies leads to a well defined and non-empty subgame Red(G). We shall prove that the construction in Section 4 can be applied to Red(G).\nFix a coalition structure p and let Gp be the game obtained by Red(G) grouping together the players in the same coalition, as in Equation (2). By Crawford\u2019s theorem (see [Cr90], Theorem 2), the set of equilibria in beliefs of Gp is not empty. Indeed, this is just the set of Nash equilibria of the convexified game. Now, since the preferences in cumulative prospect theory are described by a continuous function and since continuity is preserved by passing to the convexified version (see [Ro70], Theorem 17.2), it follows that the set of equilibria in beliefs of Gp is compact. Consequently, the sets M(p\u03b1, p) in Equation (3) are non-empty and the definition of the induced game Ind(G, p) goes through. Observe that the induced game is not empty, since the value of a prospect is at most as the maximal outcome of the prospect, which is an infimum of values attained by the composed function v \u25e6 Vi. Therefore, the set of \u03c3\u2019s such that (v \u25e6 Vi)(\u03c3) \u2265 v CPT i (\u03c3) is non-empty. Consequently, the set of mixed strategies of the induced game is a nonempty convex and compact subset of the set of mixed strategies of the original game G. Since in the convexified version of a game the set of mixed strategies does not change, the convexified version of Ind(G, p) has a non-empty set of Nash equilibria (Indeed, observe that Nash\u2019s proof of existence of equilibria goes through also if only distinguished convex and compact subsets of mixed strategies are allowed). Applying Theorem 1 in [Cr90], it follows that the induced game Ind(G, p) has a non-empty set of equilibria in beliefs. Hence, Definition 4.14 defines a non-empty notion of equilibrium.\nConsequently, Definition 9.5 defines a non-empty notion of equilibrium.\nThe following corollary follows straight from the construction.\nCorollary 9.7. The exact cooperative equilibrium of a game G does not depend on the fairness functions and on the altruism parameters, if\n(1) G does not have any super-dominated strategies, (2) for every coalition structure p, the game Gp has a unique equilibrium in beliefs.\nRemark 9.8. Also in this case we may define the quantal cooperative equilibrium under cumulative prospect theory and taking into account altruism: agent i plays with probability ev CPT i (p)/ \u2211 p e vCPTi (p) a quantal level-k solution of the induced game Ind(Red(G), p). Such quantal cooperative equilibrium explains deviations from Nash equilibrium that have been observed also in purely competitive games, as the asymmetric matching pennies experimented in [Go-Ho01], that is, the game with gains:\nL R U 320, 40 40, 80 D 40, 80 80, 40\nIt was reported in [Go-Ho01] that most of vertical players played the strategy U and most of the horizontal players played the strategy R. Observe that the Nash equilibrium for the vertical player is the uniform measure on {U,D}, since the gains of the horizontal\nplayer are the same as in the matching pennies. We believe that this behavior ultimately relies in a mistake of the vertical players due to the illusion of a large gain and this mistake is predicted by the horizontal player. This interpretation is confirmed by the cooperative equilibrium. Indeed, the value of the cooperative coalition is easily seen to be equal to 40 for both players and, therefore, exact cooperative equilibrium reduces to the Nash equilibrium and quantal cooperative equilibrium reduces to the quantal level-k solution. The latter one performs well in such a situation: if the vertical player makes the mistake to think that the horizontal player is level-0 and then she or he is indefferent between playing L and R, then the vertical player would have a strong incentive to play the strategy U . At this point, the assumption that the horizontal player is level-2 implies that she or he best responds (up to a small mistake) to the strong deviation towards U , which is a strong deviation towards R.\n10. Summary, conclusions and open problems\nOver the last decades it has been realised that all classical solution concepts for oneshot normal form games fail to predict human behavior in several strategic situations.\nThe purpose of this paper was to attribute these failures to two basic problems, the use of utility functions and the use of solution concepts that do not take into account human attitude to cooperation. While the former problem could be theoretically overcome replacing utility functions by gain functions and applying cumulative prospect theory, the second problem needs a different analysis of the structure of a game. We founded this new analysis on a seemingly reasonable principle of cooperation.\n(C) Players try to forecast how the game would be played if they formed coalitions and then they play according to their best forecast.\nTo make this idea formal, it has required some effort. In Section 2 we have observed that passing from utility functions to gain functions implies that we must take into account new phenomena, such as altruism and perception of gains. We have formalized these phenomena defining the so-called games in explicit form. After an example describing informally the main idea, in Section 4 we have formalized the principle of cooperation and we have defined the cooperative equilibrium for games in explicit form without using altruism parameters and cumulative prospect theory. The reason of this choice is that altruism and cumulative prospect theory play an active role only on a limited class of games. Indeed, in Section 5 we have shown that the cooperative equilibrium without altruism and cumulative prospect theory already performs well in a number of relevant games. In Section 6 we have discussed a few examples where cumulative prospect theory starts playing an active role and, after a short introduction to cumulative prospect theory in Section 7, we have started to adapt the definition given of cooperative equilibrium given in Definition 4.14 in order to be applied to every game in explicit form and using cumulative prospect theory. In Section 8 we have used altruism parameters to delete strategies that are not good for the collectivity. This iterated deletion of strategies leads to define a certain subgame. The study of this subgame (done in Section 4 under expected utility theory and in Section 9 under cumulative prospect theory) contains all relevant new ideas of the paper, that are, the use of the principle of cooperation and the use of cumulative prospect theory: we have assumed that every players try to forecast how the game would be played if they formed coalition; we have used cumulative prospect theory to define a notion of value of a coalition and then, appealing to some Bernoulli-type principle, we have postulated that agents play according to the coalition with highest value.\nAs shown in the examples in Section 5, the theory has many positive consequences: to the best of our knowledge, it is the first theory able to organize the experimental data collected for the Traveler\u2019s Dilemma, Prisoner\u2019s Dilemma, Nash bargaining problem, Bertrand competition, public good game, ultimatum game, and dictator game. These successful applications and the lack of examples where the cooperative equilibrium fails (qualitatively) to predict human behavior, make us optimistic about this direction of research. Nevertheless, we are perfectly aware that the theory is questionable in several points which deserve more attention in future researches. These points include:\n(1) To understand if there are other parameters to be taken into account in the definition of games in explicit form. In particular, there is some evidence that badness parameters can play an important role in some situations, one of which is described in the following point. (2) To understand what happens if the players do not agree in playing according to the same coalition structure. Indeed, the cooperative equilibrium works very well in all examples we have discussed since there is a unique coalition structure p that maximizes the value of all players. What happens if different players have different coalition structures maximizing their own value? Do all players defect and play according to the coalition structure generated by the maximizing coalition structures, that is, the coarsest coalition which is finer than all maximizing coalition structures? Or, do the players agree to play the fairest coalition structures? In this latter case, what happens if there are many fairest coalition structures? Do the players play uniformly among them?\nThe difficulty in understanding this point is due mainly to the lack of relevant examples where this situation happens. In fact, we are aware of only one example, where this situation is about to happen. We construct this game taking inspiration by a similar game recently experimented in [We-Ra]. Two players have the same strategy set S1 = S2 = S = {0, 1, . . . , 30}. The gain functions are as follows:\ng1(x, y) = { 30 \u2212 x, if x \u2265 y 0, if x < y\nand g2(x, y) \u2261 30.\nLet us compute the cooperative equilibrium of this game. The unique equilibrium of the cooperative coalition structure pc = {1, 2} is (0, 0), where both players get 30. Observe that no players have incentive to deviate from this equilibrium and consequently, the values of pc are\nv1(pc) = 30 and v2(pc) = 30.\nNow consider the selfish coalition structure ps = ({1}, {2}). The value for the second player is again v2(ps) = 30, whereas this time one gets v1(ps) = 15. Indeed, this is one of the cases where the natural symmetry of the game implies\nthat we can restrict the set M\u0303({2}, ps) taking its barycenter. In other words, when player 2 plays according to ps, she is indifferent among her choices and so she plays uniformly. Player 1\u2019s best reply to player 2\u2019s uniform measure is the uniform measure, that gives payoff 15. Since this is a Nash equilibrium, there are no possible deviations and so v2(ps) = 15.\nSo in this case, the unique cooperative equilibrium is (0, 0). In other words, player 2 favors player 1 playing 0 and player 1 knows that player 2 is going to favor her and so she plays 0 as well. This seems a very natural solution but: Do humans really play (0, 0)?\nWe tried to simulate this game with colleagues and friends and something interesting apparently came out. One friend, asked to play the game in the role of player 2, said: \u201cIt depends. If player 1 is very rich, I would play 30 for sure!\u201d. The most common question we were asked after explaining the game was: \u201cDo I know the other player?\u201d. After asking to imagine an anonymous situation, the most common answer (nine out of ten) was: \u201cWhy should I hurt a person that I do not know? I would play 0.\u201d. One person said: \u201cI don\u2019t care! I would pick a number randomly\u201d.\nOf course, these cannot be considered as experimental data, but we believe that they represent however a light evidence that badness parameters do exist. It is not yet clear to the author how to manage them from a general point of view and we will postpone the theorization to a new paper hopefully helped by more experimental data. However, we can say right now how these parameters would effect the play of this particular game. We guess that the badness parameters bij are non-negative real numbers, where bij = 0 represents the situation where player i is absolutely good against player j, that is, player i favors player j whenever possible, and bij = \u221e represents the situation where player i is absolutely bad against player j. As said, it is not yet clear which would be the exact mathematical definition and the exact effect of these parameters on a general game, but the idea is that in this particular version of the Ultimatum game, the second player plays according to the parameter b21 and player 1 estimates a priori the parameter b21 and plays a best reply to the strategy that player 2 would play if her badness parameters were equal to player 2\u2019s estimation. (3) The formula used in Equation (1) to compute the value of a coalition seems a quite reasonable one and it meets the experimental data quite well, but it is certainly only a first tentative. More thoughts, possibly supported by more experimental data, may help to understand the value of a coalition. The main point is probably:\n\u2022 to understand whether the value should be computed taking into account also deviations towards safe strategies.\nIndeed, consider the two-player game with gain matrix\na b a 1, 1 0,\u2212k b \u2212k, 0 10, 10\nThe cooperative equilibrium is (b, b) independently on k. Is this reasonable or for k large enough players prefer not to risk and play the safe strategy (a, a)? (4) The formula used in Equation (1) to compute the value of a coalition is questionable on another point. In the definition of the numbers Rj(p), we have considered the first step of the reasoning: if player j decides to abandon the coalition structure p, then another player, say k, may do the same either to follow selfish interests or because she or he is clever enough to anticipate player j deviation. But, if player j is also clever enough to anticipate player k\u2019s deviation, then player j may deviate from the deviation, and so forth. We could continue this reasoning and define the risk Rj(p) to be, roughly speaking, the maximal lost that player j incurs when a profile of strategies that can be reached by a sequence of deviations is played. Of course, this definition would come at the price of a major technical difficulty, but it would be theoretically more appealing, since\nit would allow to construct a bridge from the cooperative equilibrium theory to another well studied behavioral model. We recall that \u03c4i,J(p) has been called prior probability, since, despite being an apparently very precise evaluation of how player i measures the event \u201cplayers in J abandon the coalition structure p\u201d, it is well possible that a specific player i, for personal reasons, evaluates this event in a completely different way. In particular, the number \u03c4i,\u2205 represents the probability that player i assigns to the event that no players abandon the coalition. The types of players that are usually called, in economic literature, altruistic (resp. selfish) would then correspond to those players i who compute the value of a coalition setting \u03c4i,\u2205 = 1 (resp. \u03c4i,\u2205 = 0), independently of the prior value of such a probability. The correspondence between selfish players and players who set \u03c4i,\u2205 = 0 fails using the formula in (1), since this formula with \u03c4i,\u2205 = 0 can still predict cooperation, even though in a smaller rate, as, for instance, in the Traveler\u2019s dilemma. (5) The exact computation of the cooperative equilibrium is hard for several reasons. First because it goes through the computation of the equilibria in beliefs of several18 (sub)games. These equilibria are computationally hard to find [Da-Go-Pa06]. Second, because it uses cumulative prospect theory, that is computationally harder than expected utility theory. On one hand, the method that we have proposed is perfectly algorithmic and therefore it might be helpful to write a computer program to compute the cooperative equilibria and make easier the phase of test them on easy real-life situations. On the other hand, it would be important to investigate some computationally easier variant. Of course, quantal level-k theory can be seen as a computationally easier variant, but this theory has the serious issue that it would not be predictive, in the sense that one has to conduct experiments to estimate the error parameter. One could try to avoid this problem using the level-k theory (i.e., only bounded rationality). (6) Iterated deletion of strategies using altruism functions in Section 8 was certainly quite sketchy and it is likely that future researches will suggest a different procedure. In particular, the definition of unplayable strategies of the second type for player i requires that only one particular player j receives a large loss. It is possible that this condition is not sufficient to convince player i to renounce to her better strategy, in case when the players in P \\ {i, j} receives a large gain. (7) We have defined altruism functions operationally, meaning that one could theoretically compute them by conducting an experiment on the generalized dictator game. It would be important to find an operational way to define the fairness functions.\nOpen problems include:\n(1) Many experiments with different purposes should be conducted. Indeed, an interesting fact is that cooperative equilibrium makes sometimes completely new predictions. A stream of experiments should be devoted to verify or falsify these predictions. For instance,\n\u2022 Apparently, the cooperative equilibrium is the unique solution concept predicting an increasing rate of cooperation in the public good game, as the\n18As observed by J. Halpern in a private communication, it is implausible that an agent would consider all coalitions. In even moderately large games, there are just too many of them. She may consider some natural coalitions (e.g., the coalition of all agents), but only a relatively small number. Of course, a theory characterizing which coalitions would be considered is not easy to come by.\nmarginal return approaches 1. It seems that this prediction has a partial confirmation from experimental data, but, as far as we know, only one experiment has been devoted to report this behavior, that is, [IWW94]. Analogously, it seems that the cooperative equilibrium (under cumulative prospect theory) is the unique solution concept predicting or, at least, justifying a rate of cooperation in the public good game with a large number of players. Also in this case, we are aware of only one experimental study devoted to observe this unexpected behavior, that is, again, [IWW94]. \u2022 Apparently, the cooperative equilibrium is the unique solution concept predicting a rate of cooperation in the Prisoner\u2019s dilemma depending on the particular gains. It seems that this prediction is partially confirmed by experimental data, but only on the repeated Prisoner\u2019s dilemma (see [DRFN08] and [Fu-Ra-Dr12]). Experiments with a one-shot parametrized Prisoner\u2019s dilemma should be conducted to verify or falsify this prediction. Another stream of experiments should be devoted to answer some theoretical questions. At this first stage of research, we believe that the most important one is:\n\u2022 to understand whether the value of a coalition structure should be computed taking into account also deviations towards safe strategies.\n(2) Have a better understanding of the relation between Nash equilibria and cooperative equilibria (under expected utility theory) for two-person zero-sum games, when the players have the same perception of gains. Indeed, Nash equilibrium performs quite well for zero-sum games and it is possible that all deviations from Nash equilibrium can be explained only making use of cumulative prospect theory. Therefore, it would be important to understand if the cooperative equilibrium (under expected utility theory and assuming f1 = f2) refines Nash equilibrium, in the sense that the set of exact cooperative equilibria is always a subset of the set of Nash equilibria. In this context, it would also be interesting to start from relevant classes of zero-sum games, as the group games, introduced and studied in [Mo10], [Ca-Mo12], [Ca-Sc12]. Of course, also a counter-example would be very important to understand if and where the theory can be modified. (3) As stressed several times, the probability \u03c4i,J(p) is just a prior probability, in the sense that it is well possible that a particular player i computes this probability in a completely different way. It would be important to understand the factors that may influence the evaluation of this probability. For instance, it is well known that individual-level rate of cooperation depends on family history, age, culture, gender, even university course [Ma-Am81], religious beliefs [HRZ11], and time decision [RGN12]. The dream is to incorporate this factors into parameters to use to compute the probability \u03c4i at an individual-level. Particularly interesting would also be the study of this probability when players can talk each other or have any sort of contact (e.g., eye-contact). Indeed, these contacts can create phenomena of mental reading (see [Wi-MN-GJ]) that we believe can be explained in terms of evaluation of the probability \u03c4 ."}], "references": [{"title": "Le comportement de l\u2019homme rationnel devant le risque", "author": ["M. Allais"], "venue": "Critique des postulats et axiomes de l\u2019ecole Americaine, Econometrica,", "citeRegEx": "Allais,? \\Q1953\\E", "shortCiteRegEx": "Allais", "year": 1953}, {"title": "The Evolution of Cooperation, New York: Basic Books", "author": ["R Axelrod"], "venue": null, "citeRegEx": "Axelrod,? \\Q1984\\E", "shortCiteRegEx": "Axelrod", "year": 1984}, {"title": "The Traveler\u2019s Dilemma: Paradoxes of Rationality in Game Theory", "author": ["K. Basu"], "venue": "American Economic Review,", "citeRegEx": "Basu,? \\Q1994\\E", "shortCiteRegEx": "Basu", "year": 1994}, {"title": "Experiments with the Travelers Dilemma: welfare, strategic choice and implicit collusion", "author": ["K. Basu", "L. Becchetti", "L. Stanca"], "venue": "Social Choice and Welfare", "citeRegEx": "Basu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Basu et al\\.", "year": 2011}, {"title": "Rationalizable strategic behavior", "author": ["B.D. Bernheim"], "venue": null, "citeRegEx": "Bernheim,? \\Q1984\\E", "shortCiteRegEx": "Bernheim", "year": 1984}, {"title": "D", "author": ["Bernoulli"], "venue": "Specimen Theoriae de Mensura Sortis, Commentarii Academiae Scientiarum Imperialis Petropolitanae,", "citeRegEx": "Be738", "shortCiteRegEx": null, "year": 1738}, {"title": "A within-subject analysis of other regarding preferences. Games and Economic Behavior 72:321-338", "author": ["M Blanco", "D Engelmann", "HT Normann"], "venue": null, "citeRegEx": "Blanco et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Blanco et al\\.", "year": 2011}, {"title": "ERC: A Theory of Equity, Reciprocity and Competition", "author": ["G.E. Bolton", "A. Ockenfels"], "venue": "The American Economic Review", "citeRegEx": "Bolton and Ockenfels,? \\Q2000\\E", "shortCiteRegEx": "Bolton and Ockenfels", "year": 2000}, {"title": "Cooperation and group size in the n- person prisoners", "author": ["P Bonacich", "G Shure", "J Kahan", "R Meeker"], "venue": "dilemma, J. Conflict Resolution", "citeRegEx": "Bonacich et al\\.,? \\Q1976\\E", "shortCiteRegEx": "Bonacich et al\\.", "year": 1976}, {"title": "A cognitive hierarchy model of games", "author": ["C. Camerer", "T. Ho", "J. Chong"], "venue": "Quaterly J. of Economics", "citeRegEx": "Camerer et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Camerer et al\\.", "year": 2004}, {"title": "L", "author": ["Cameron"], "venue": "Raising the Stakes in the Ultimatum Game: Experimental Evidence from Indonesia, Discussion Paper, Princeton University,", "citeRegEx": "Ca95", "shortCiteRegEx": null, "year": 1995}, {"title": "Anomalous Behavior in a Travelers Dilemma", "author": ["M. Capra", "J.K. Goeree", "R. Gomez", "C.A. Holt"], "venue": "American Economic Review,", "citeRegEx": "Capra et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Capra et al\\.", "year": 1999}, {"title": "Cooperative equilibria in iterated social dilemmas", "author": ["V. CVPJ] Capraro", "M. Venanzi", "M. Polukarov", "N.R. Jennings"], "venue": "To appear in Proceedings of the 6th International Symposium in Algorithmic Game Theory", "citeRegEx": "Capraro et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Capraro et al\\.", "year": 2013}, {"title": "Cognition and behavior in normal form games: An experimental study, Econometrica", "author": ["M. Costa-Gomes", "V. Crawford", "B. Broseta"], "venue": null, "citeRegEx": "Costa.Gomes et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Costa.Gomes et al\\.", "year": 2001}, {"title": "Cooperation without Reputation: Experimental Evidence from Prisoners Dilemma", "author": ["R. Cooper", "D.V. DeJong", "R. Forsythe", "T.W. Ross"], "venue": "Games, Games and Economic Behavior", "citeRegEx": "Cooper et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Cooper et al\\.", "year": 1996}, {"title": "Equilibrium without Independence", "author": ["V.P. Crawford"], "venue": "Journal of Economic Theory", "citeRegEx": "Crawford,? \\Q1990\\E", "shortCiteRegEx": "Crawford", "year": 1990}, {"title": "Prospect Versus Utility", "author": ["I.S. Currim", "R.K. Sarin"], "venue": "Management Science", "citeRegEx": "Currim and Sarin,? \\Q1989\\E", "shortCiteRegEx": "Currim and Sarin", "year": 1989}, {"title": "In STOC 06: Proceedings of the 38th Annual ACM Symposium on Theory of Computing", "author": ["C. Daskalakis", "P.W. Goldberg", "C.H. Papadimitriou. The complexity of computing a Nash equilibrium"], "venue": "pages 7178,", "citeRegEx": "Da.Go.Pa06", "shortCiteRegEx": null, "year": 2006}, {"title": "A social equilibrium existence theorem", "author": ["G. Debreu"], "venue": "Proc. Nat. Acad. Sci. U.S.A", "citeRegEx": "Debreu,? \\Q1952\\E", "shortCiteRegEx": "Debreu", "year": 1952}, {"title": "Why do people pay taxes? Prospect theory versus expected utility theory, Journal of Economic Behavior and Organization", "author": ["S. Dhami", "A. Al-Nowaihi"], "venue": null, "citeRegEx": "Dhami and Al.Nowaihi,? \\Q2007\\E", "shortCiteRegEx": "Dhami and Al.Nowaihi", "year": 2007}, {"title": "Nash equilibrium under Knightian Uncertainty: Breaking Down Bacward Induction", "author": ["J. Dow", "S.R. Werlang"], "venue": "Journal of Economic Theory", "citeRegEx": "Dow and Werlang,? \\Q1994\\E", "shortCiteRegEx": "Dow and Werlang", "year": 1994}, {"title": "Do People Care About Social Context? Framing Effects in Dictator Games. Experimental Economics doi:10.1007/s10683-012-9341-9", "author": ["A Dreber", "T Ellingsen", "M Johannesson", "DG Rand"], "venue": null, "citeRegEx": "Dreber et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dreber et al\\.", "year": 2012}, {"title": "Who cooperates in repeated games? Available at SSRN: http://ssrn.com/abstract=1752366", "author": ["A Dreber", "DF Fudenberg", "DG. Rand"], "venue": null, "citeRegEx": "Dreber et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dreber et al\\.", "year": 2011}, {"title": "Gneezy, Price competition and market concentration: an experimental study, International", "author": ["M. Dufwenberg"], "venue": "Journal of Industrial Organization", "citeRegEx": "Dufwenberg and U.,? \\Q2000\\E", "shortCiteRegEx": "Dufwenberg and U.", "year": 2000}, {"title": "Dictator games: A meta study, Experimental Economics", "author": ["C. Engel"], "venue": null, "citeRegEx": "Engel,? \\Q2011\\E", "shortCiteRegEx": "Engel", "year": 2011}, {"title": "The nature of human altruism", "author": ["E. Fehr", "U. Fischbacher"], "venue": "Nature", "citeRegEx": "Fehr and Fischbacher,? \\Q2003\\E", "shortCiteRegEx": "Fehr and Fischbacher", "year": 2003}, {"title": "A theory of fairness, competition and cooperation", "author": ["E. Fehr", "K. Schmidt"], "venue": "Quaterly Journal of Economics", "citeRegEx": "Fehr and Schmidt,? \\Q1999\\E", "shortCiteRegEx": "Fehr and Schmidt", "year": 1999}, {"title": "When the players are not expectation maximizers", "author": ["A. Fiat", "C. Papadimitriou"], "venue": "Proceedings of the Third international conference on Algorithmic game theory", "citeRegEx": "Fiat and Papadimitriou,? \\Q2010\\E", "shortCiteRegEx": "Fiat and Papadimitriou", "year": 2010}, {"title": "D", "author": ["Fishburn", "P.C. The foundations of expected utility"], "venue": "Reidel Publishing Company. Dordrecht: Holland/Boston: U.S.A. London: England.", "citeRegEx": "Fi82", "shortCiteRegEx": null, "year": 1982}, {"title": "Research memorandum RM-789", "author": ["Flood", "M.M. Some experimental games"], "venue": "RAND Corporation, Santa Monica, CA.", "citeRegEx": "Fl52", "shortCiteRegEx": null, "year": 1952}, {"title": "Fairness in Simple Bargaining Games, Games and Economic Behavior, VI", "author": ["R. Forsythe", "N.E. Horowitz", "L.H. Savin", "M. Sefton"], "venue": null, "citeRegEx": "Forsythe et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Forsythe et al\\.", "year": 1988}, {"title": "Fairness in Simple Bargaining Experiments", "author": ["R. Forsythe", "J. Horowitz", "N.E. Savin", "M. Sefton"], "venue": "Games and Economic Behavior", "citeRegEx": "Forsythe et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Forsythe et al\\.", "year": 1994}, {"title": "Expression Theory and the Preference Reversal Phenomena", "author": ["W.M. Goldstein", "H.J. Einhorn"], "venue": "Psychological Review", "citeRegEx": "Goldstein and Einhorn,? \\Q1987\\E", "shortCiteRegEx": "Goldstein and Einhorn", "year": 1987}, {"title": "Ten Little Treasures of Game Theory and Ten Intuitive Contradictions", "author": ["J. Goeree", "C. Holt"], "venue": "American Economic Review", "citeRegEx": "Goeree and Holt,? \\Q2001\\E", "shortCiteRegEx": "Goeree and Holt", "year": 2001}, {"title": "Private Costs and Public Benefits: Unraveling the Effects of Altruism and Noisy Behavior", "author": ["JK Goeree", "CA Holt", "SK Laury"], "venue": "Journal of Public Economics,", "citeRegEx": "Goeree et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Goeree et al\\.", "year": 2002}, {"title": "Palfrey, Risk averse behavior in asymmetric matching pennies games, Games and Economic Behavior", "author": ["J.K. Goeree", "C. Holt", "T.R"], "venue": null, "citeRegEx": "Goeree et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Goeree et al\\.", "year": 2003}, {"title": "An Experimental Analysis of Ultimatum Bargaining", "author": ["W. Guth", "R. Schmittberger", "B. Schwarze"], "venue": "Journal of Economic Behavior and Organization,", "citeRegEx": "Guth et al\\.,? \\Q1982\\E", "shortCiteRegEx": "Guth et al\\.", "year": 1982}, {"title": "Algorithmic Rationality: Game Theory with Costly Computation", "author": ["J.Y. Halpern", "R. Pass"], "venue": "Preprint", "citeRegEx": "Ha.Pa11", "shortCiteRegEx": null, "year": 2011}, {"title": "Iterated Regret Minimization: a new solution concept, Games and Economic Behavior", "author": ["J.Y. Halpern", "R. Pass"], "venue": null, "citeRegEx": "Halpern and Pass,? \\Q2012\\E", "shortCiteRegEx": "Halpern and Pass", "year": 2012}, {"title": "Cooperative equilibrium (extended abstract)", "author": ["J.Y. Halpern", "N. Rong"], "venue": "In Proc. of the 9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS", "citeRegEx": "Halpern and Rong,? \\Q2010\\E", "shortCiteRegEx": "Halpern and Rong", "year": 2010}, {"title": "Children\u2019s altruism in public good and dictator experiments", "author": ["WT Harbaugh", "K Krause"], "venue": "Economic Inquiry", "citeRegEx": "Harbaugh and Krause,? \\Q2000\\E", "shortCiteRegEx": "Harbaugh and Krause", "year": 2000}, {"title": "Modeling loss aversion and referee dependence effects on brand choice", "author": ["B. Hardie", "E. Johnson", "P. Fader"], "venue": "Marketing Science", "citeRegEx": "Hardie et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Hardie et al\\.", "year": 1993}, {"title": "The tragedy of the commons", "author": ["G Hardin"], "venue": "Science", "citeRegEx": "Hardin,? \\Q1968\\E", "shortCiteRegEx": "Hardin", "year": 1968}, {"title": "At 22nd International Joint Conference on Artificial Intelligence (IJCAI)", "author": ["M. Hoefer", "M. Penn", "M. Polukarov", "A. Skopalik", "B. Voecking", "Considerate Equilibrium"], "venue": "Barcelona, Spain, 16 - 22 Jul", "citeRegEx": "HPPSV11", "shortCiteRegEx": null, "year": 2011}, {"title": "On Expectations and Monetary", "author": ["E. Hoffman", "K. McCabe", "V. Smith"], "venue": "Stakes in Ultimatum Games, International Journal of Game Theory, XXV", "citeRegEx": "Hoffman et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Hoffman et al\\.", "year": 1996}, {"title": "The online laboratory: conducting experiments in a real labor market, Experimental Economics 14:399-425", "author": ["JJ Horton", "DG Rand", "RJ Zeckhauser"], "venue": null, "citeRegEx": "Horton et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Horton et al\\.", "year": 2011}, {"title": "Group size effects in public goods provision: The voluntary contribution mechanism, Quarterly", "author": ["M.R. Isaac", "J. Walker"], "venue": "Journal of Economics", "citeRegEx": "Isaac and Walker,? \\Q1988\\E", "shortCiteRegEx": "Isaac and Walker", "year": 1988}, {"title": "Divergent evidence on free riding: an experimental examination of possible explanations, Public Choice 43:113-149", "author": ["RM Isaac", "J Walker", "S. Thomas"], "venue": null, "citeRegEx": "Isaac et al\\.,? \\Q1984\\E", "shortCiteRegEx": "Isaac et al\\.", "year": 1984}, {"title": "Group size and the voluntary provision of public goods: Experimental evidence utilizing large groups, ournal of Public Economics", "author": ["M.R. Isaac", "J. Walker", "A.W. Williams"], "venue": null, "citeRegEx": "Isaac et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Isaac et al\\.", "year": 1994}, {"title": "Doubtful Deviations and Farsighted Play, Progress in Artificial Intelligence, Lecture", "author": ["W. Jamroga", "Melissen M"], "venue": "Notes in Computer Science, Volume", "citeRegEx": "Jamroga and M.,? \\Q2011\\E", "shortCiteRegEx": "Jamroga and M.", "year": 2011}, {"title": "Prospect Theory: An Analysis of Decision under Risk, Econometrica", "author": ["D. Kahneman", "A. Tversky"], "venue": "vol. 47,", "citeRegEx": "Kahneman and Tversky,? \\Q1979\\E", "shortCiteRegEx": "Kahneman and Tversky", "year": 1979}, {"title": "values and frames", "author": ["D. Kahneman", "A. Tversky", "Choices"], "venue": "New York: Cambridge University Press.", "citeRegEx": "Ka.Tv00", "shortCiteRegEx": null, "year": 2000}, {"title": "Proportional solutions to bargaining situations: Intertemporal utility comparisons", "author": ["E. Kalai"], "venue": null, "citeRegEx": "Kalai,? \\Q1977\\E", "shortCiteRegEx": "Kalai", "year": 1977}, {"title": "Arbitration of Two-Party Disputes under Ignorance", "author": ["E. Kalai", "R.W. Rosenthal"], "venue": "International Journal of Game Theory,", "citeRegEx": "Kalai and Rosenthal,? \\Q1978\\E", "shortCiteRegEx": "Kalai and Rosenthal", "year": 1978}, {"title": "Other solutions to Nash\u2019s bargaining", "author": ["E. Kalai", "M. Smorodinsky"], "venue": null, "citeRegEx": "Kalai and Smorodinsky,? \\Q1975\\E", "shortCiteRegEx": "Kalai and Smorodinsky", "year": 1975}, {"title": "Subjectively Weighted Utility and the Allais Paradox", "author": ["U.S. Karmarkar"], "venue": "Organizational Behavior and Human Performance", "citeRegEx": "Karmarkar,? \\Q1979\\E", "shortCiteRegEx": "Karmarkar", "year": 1979}, {"title": "Conflict between individual and common interest in an N-person relationship", "author": ["HH Kelley", "J Grzelak"], "venue": "J. Pers. Soc. Psychol", "citeRegEx": "Kelley and Grzelak,? \\Q1972\\E", "shortCiteRegEx": "Kelley and Grzelak", "year": 1972}, {"title": "decision", "author": ["Klibanoff", "P. Uncertainty"], "venue": "and normal form games, Manuscript, MIT,", "citeRegEx": "Kl93", "shortCiteRegEx": null, "year": 1993}, {"title": "Cooperative choice in the n-person dilemma situation", "author": ["SS Komorita", "J Sweeney", "DA Kravitz"], "venue": "J. Pers. Soc. Psychol", "citeRegEx": "Komorita et al\\.,? \\Q1980\\E", "shortCiteRegEx": "Komorita et al\\.", "year": 1980}, {"title": "Social values and cooperative response to a simulated resource conservation crisis", "author": ["RM Kramer", "CG McClintock", "DM Messick"], "venue": null, "citeRegEx": "Kramer et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Kramer et al\\.", "year": 1986}, {"title": "Individual differences in social orientation, In Experimental Social Dilemmas", "author": ["DM Kuhlman", "CR Camac", "DA Cunha"], "venue": null, "citeRegEx": "Kuhlman et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Kuhlman et al\\.", "year": 1986}, {"title": "The influence of probability on risky choice: A parametric investigation", "author": ["J.R. Lattimore", "J.K. Baker", "A.D. Witte"], "venue": "Journal of Economic Behavior and Organization", "citeRegEx": "Lattimore et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Lattimore et al\\.", "year": 1992}, {"title": "Prospect Theory and International Relations: Theoretical Applications and Analytic Problems", "author": ["J.S. Levy"], "venue": "Political Psychology,", "citeRegEx": "Levy,? \\Q1992\\E", "shortCiteRegEx": "Levy", "year": 1992}, {"title": "Applications of Prospect Theory to Political Science, Syntheses", "author": ["J.S. Levy"], "venue": null, "citeRegEx": "Levy,? \\Q2003\\E", "shortCiteRegEx": "Levy", "year": 2003}, {"title": "Human Behavior in a Strongly Determined 3\u00d7 3 matrix game", "author": ["B. Lieberman"], "venue": "Behavioral Sci", "citeRegEx": "Lieberman,? \\Q1960\\E", "shortCiteRegEx": "Lieberman", "year": 1960}, {"title": "Value orientation and conformity in three types of social dilemma games", "author": ["WBG Liebrand", "HAM Wilke", "R Vogel", "FJM Wolters"], "venue": "J. Conflict Resolut", "citeRegEx": "Liebrand et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Liebrand et al\\.", "year": 1986}, {"title": "Equilibrium in Beliefs under Uncertainty", "author": ["K.C. Lo"], "venue": "Journal of Economic Theory", "citeRegEx": "Lo,? \\Q1996\\E", "shortCiteRegEx": "Lo", "year": 1996}, {"title": "Is Choice the Correct Primitive? On Using Certainty Equivalents and Reference Levels to Predict Choices among Gambles", "author": ["R.D. Luce", "B.A. Mellers", "Shi-Jie Chang"], "venue": "Journal of Risk and Uncertainty", "citeRegEx": "Luce et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Luce et al\\.", "year": 1993}, {"title": "Economists free ride, does anyone else", "author": ["G. Marwell", "R.E. Ames"], "venue": "Journal of Public Economics", "citeRegEx": "Marwell and Ames,? \\Q1981\\E", "shortCiteRegEx": "Marwell and Ames", "year": 1981}, {"title": "Expected Utility analysis without the independence", "author": ["M. Machina"], "venue": "axiom, Econometrica", "citeRegEx": "Machina,? \\Q1982\\E", "shortCiteRegEx": "Machina", "year": 1982}, {"title": "Finitely Additive and Epsilon Nash Equilibria", "author": ["M. Marinacci"], "venue": "International Journal of Game Theory", "citeRegEx": "Marinacci,? \\Q1997\\E", "shortCiteRegEx": "Marinacci", "year": 1997}, {"title": "Role of interdependence structure, individual value orientation, and anothers strategy in social decision making: a transformational analysi", "author": ["CG McClintock", "WBG Liebrand"], "venue": "J. Pers. Soc. Psychol", "citeRegEx": "McClintock and Liebrand,? \\Q1988\\E", "shortCiteRegEx": "McClintock and Liebrand", "year": 1988}, {"title": "Quantal response equilibria for normal form games, Games and Economic Behavior", "author": ["R. McKelvey", "T. Palfrey"], "venue": null, "citeRegEx": "McKelvey and Palfrey,? \\Q1995\\E", "shortCiteRegEx": "McKelvey and Palfrey", "year": 1995}, {"title": "Equilibria in games with prospect theory preferences", "author": ["L.P. Metzger", "M.O. Rieger"], "venue": "Preprint", "citeRegEx": "Me.Ri10", "shortCiteRegEx": null, "year": 2010}, {"title": "The multiplication game", "author": ["K. Morrison"], "venue": "Math. Mag", "citeRegEx": "Morrison,? \\Q2010\\E", "shortCiteRegEx": "Morrison", "year": 2010}, {"title": "Princeton University Press", "author": ["O. Morgenstern", "J. von Neumann", "Theory of Games", "Economic Behavior", "NJ Princeton"], "venue": "first ed.,", "citeRegEx": "Mo.vN44", "shortCiteRegEx": null, "year": 1944}, {"title": "Princeton University Press", "author": ["O. Morgenstern", "J. von Neumann", "Theory of Games", "Economic Behavior", "NJ Princeton"], "venue": "second ed.,", "citeRegEx": "Mo.vN47", "shortCiteRegEx": null, "year": 1947}, {"title": "Refinements of the Nash equilibrium concept", "author": ["R.B. Myerson"], "venue": "International Journal of Game Theory,", "citeRegEx": "Myerson,? \\Q1978\\E", "shortCiteRegEx": "Myerson", "year": 1978}, {"title": "Equilibrium points in n-person games", "author": ["J.F. Nash"], "venue": "Proc. Nat. Acad. Sci", "citeRegEx": "Nash,? \\Q1950\\E", "shortCiteRegEx": "Nash", "year": 1950}, {"title": "The Bargaining Problem", "author": ["J.F. Nash"], "venue": null, "citeRegEx": "Nash,? \\Q1950\\E", "shortCiteRegEx": "Nash", "year": 1950}, {"title": "Bounded complexity justifies cooperation in finitely repated prisoners", "author": ["A. Neyman"], "venue": "dilemma, Economic Letters", "citeRegEx": "Neyman,? \\Q1985\\E", "shortCiteRegEx": "Neyman", "year": 1985}, {"title": "Evolution of indirect reciprocity by image scoring, Nature 393:573-577", "author": ["MA Nowak", "K Sigmund"], "venue": null, "citeRegEx": "Nowak and Sigmund,? \\Q1998\\E", "shortCiteRegEx": "Nowak and Sigmund", "year": 1998}, {"title": "Five rules for the evolution of cooperation, Science 314:1560-1563", "author": ["MA Nowak"], "venue": null, "citeRegEx": "Nowak,? \\Q2006\\E", "shortCiteRegEx": "Nowak", "year": 2006}, {"title": "The Logic of Collective Action: Public Goods and the Theory of Groups", "author": ["M Olson"], "venue": null, "citeRegEx": "Olson,? \\Q1965\\E", "shortCiteRegEx": "Olson", "year": 1965}, {"title": "Nonmetric test of the Minimax Theory of two person zero-sum Games", "author": ["B. O\u2019Neill"], "venue": "Proc. Nat. Acad. Sci. USA", "citeRegEx": "O.Neill,? \\Q1987\\E", "shortCiteRegEx": "O.Neill", "year": 1987}, {"title": "Cambridge", "author": ["M.J. Osborne", "A. Rubinstein", "A course in Game Theory"], "venue": "Mass.: MIT Press,", "citeRegEx": "Os.Ru94", "shortCiteRegEx": null, "year": 1994}, {"title": "Rationalizable strategic behavior and the problem of perfection", "author": ["D.G. Pearce"], "venue": null, "citeRegEx": "Pearce,? \\Q1984\\E", "shortCiteRegEx": "Pearce", "year": 1984}, {"title": "The probability weighting", "author": ["D. Prelec"], "venue": "function, Econometrica", "citeRegEx": "Prelec,? \\Q1998\\E", "shortCiteRegEx": "Prelec", "year": 1998}, {"title": "Incorporating reference price effects into a theory of consumer choice", "author": ["D. Putler"], "venue": "Marketing Science", "citeRegEx": "Putler,? \\Q1992\\E", "shortCiteRegEx": "Putler", "year": 1992}, {"title": "Arbitration Schemes for Generalized Two-Person Games, in Contributions to the Theory of Games II,ed", "author": ["H. Raiffa"], "venue": null, "citeRegEx": "Raiffa,? \\Q1953\\E", "shortCiteRegEx": "Raiffa", "year": 1953}, {"title": "Spontaneous giving and calculated greed", "author": ["DG Rand", "JD Greene", "MA Nowak"], "venue": "Nature", "citeRegEx": "Rand et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rand et al\\.", "year": 2012}, {"title": "D", "author": ["Ray"], "venue": "A Game-Theoretic Perspective on Coalition Formation, New York: Oxford University Press,", "citeRegEx": "Ra08", "shortCiteRegEx": null, "year": 2008}, {"title": "Minimax regret and strategic uncertainty", "author": ["L. Renou", "K.H. Schlag"], "venue": "Journal of Economic Theory", "citeRegEx": "Renou and Schlag,? \\Q2009\\E", "shortCiteRegEx": "Renou and Schlag", "year": 2009}, {"title": "Cumulative prospect theory and the St", "author": ["M.O. Rieger", "M. Wang"], "venue": "Petersburg paradox, Economic Theory", "citeRegEx": "Rieger and Wang,? \\Q2006\\E", "shortCiteRegEx": "Rieger and Wang", "year": 2006}, {"title": "Princeton", "author": ["Rockafellar", "R.T. Convex Analysis", "Princeton Univ. Press"], "venue": "NJ,", "citeRegEx": "Ro70", "shortCiteRegEx": null, "year": 1970}, {"title": "Games of Perfect Information, Predatory Pricing, and the Chain Store Paradox", "author": ["R. Rosenthal"], "venue": "Journal of Economic Theory,", "citeRegEx": "Rosenthal,? \\Q1982\\E", "shortCiteRegEx": "Rosenthal", "year": 1982}, {"title": "Risk Aversion in Quiggin and Yaari\u2019s Rank-Order Model of Choice under Uncertainty", "author": ["A. Roelle"], "venue": "Economic Journal", "citeRegEx": "Roelle,? \\Q1987\\E", "shortCiteRegEx": "Roelle", "year": 1987}, {"title": "Bargaining and Market Behavior in Jerusalem, Ljubljana, Pittsburgh, and Tokyo: An Experimental Study, American Economic Review, LXXXI", "author": ["A.E. Roth", "V. Prasnikar", "M. Okuno-Fujiwara", "S. Zamir"], "venue": null, "citeRegEx": "Roth et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Roth et al\\.", "year": 1991}, {"title": "Finite automata play the repeated prisoners dilemma", "author": ["A. Rubinstein"], "venue": "Journal of Economic Theory", "citeRegEx": "Rubinstein,? \\Q1986\\E", "shortCiteRegEx": "Rubinstein", "year": 1986}, {"title": "Constant Risk Aversion", "author": ["Z. Safra", "U. Segal"], "venue": "Journal of Economic Theory", "citeRegEx": "Safra and Segal,? \\Q1998\\E", "shortCiteRegEx": "Safra and Segal", "year": 1998}, {"title": "Subjective Probability and Expected Utility without Additivity", "author": ["D. Schmeidler"], "venue": "Econometrica", "citeRegEx": "Schmeidler,? \\Q1989\\E", "shortCiteRegEx": "Schmeidler", "year": 1989}, {"title": "Reexamination of the perfectness concept for equilibrium points in extensive games", "author": ["R. Selten"], "venue": "International J. Game Theory", "citeRegEx": "Selten,? \\Q1975\\E", "shortCiteRegEx": "Selten", "year": 1975}, {"title": "The Disposition to Sell Winners Too Early and Ride Losers Too Long: Theory and Evidence", "author": ["H. Shefrin", "M. Statman"], "venue": "Journal of Finance,", "citeRegEx": "Shefrin and Statman,? \\Q1985\\E", "shortCiteRegEx": "Shefrin and Statman", "year": 1985}, {"title": "Financial Incentives and Learning in Ultimatum and Market Games: An Experiment in the Slovak Republic", "author": ["R. Slonim", "A.E. Roth"], "venue": null, "citeRegEx": "Slonim and Roth,? \\Q1997\\E", "shortCiteRegEx": "Slonim and Roth", "year": 1997}, {"title": "Experimental evidence on players\u2019 models of other players", "author": ["D. Stahl", "P. Wilson"], "venue": "J. Economic Behavior and Organization", "citeRegEx": "Stahl and Wilson,? \\Q1994\\E", "shortCiteRegEx": "Stahl and Wilson", "year": 1994}, {"title": "Developments in Non-expected Utility Theory: The Hunt for a Descriptive Theory of Choice under Risk", "author": ["C. Starmer"], "venue": "Journal of Economic Literature,", "citeRegEx": "Starmer,? \\Q2000\\E", "shortCiteRegEx": "Starmer", "year": 2000}, {"title": "Nash equilibrium and generalized integration for infinite normal form games, Games and Economic Behavior", "author": ["M. Stinchcombe"], "venue": null, "citeRegEx": "Stinchcombe,? \\Q2005\\E", "shortCiteRegEx": "Stinchcombe", "year": 2005}, {"title": "Princeton", "author": ["Thaler", "R. Advances in Behavioral Finance", "Vol. II Princeton University Press"], "venue": "NJ.", "citeRegEx": "Th05", "shortCiteRegEx": null, "year": 2005}, {"title": "Advances in Prospect Theory: Cumulative representation of uncertainty", "author": ["A. Tversky", "D. Kahneman"], "venue": "Journal of Risk and Uncertainty", "citeRegEx": "Tversky and Kahneman,? \\Q1992\\E", "shortCiteRegEx": "Tversky and Kahneman", "year": 1992}], "referenceMentions": [{"referenceID": 75, "context": "Since its foundation by Morgenstern and von Neumann [Mo-vN44], the major challenge of modern game theory has been to predict which actions a human player would adopt in a strategic situation.", "startOffset": 52, "endOffset": 61}, {"referenceID": 29, "context": "Typical examples of such a fastidious situation are the Prisoner\u2019s Dilemma [Fl52], the Traveler\u2019s Dilemma [Ba94], and, more generally, every social dilemma [Ko88].", "startOffset": 75, "endOffset": 81}, {"referenceID": 76, "context": "However, an obvious criticism of quantal level-k theory is that it is not scale invariant, contradicting one of the axioms of expected utility theory of Morgenstern and von Neumann[Mo-vN47].", "startOffset": 180, "endOffset": 189}, {"referenceID": 37, "context": "The first studies in this direction have been presented by Renou and Schlag [Re-Sc09] and Halpern and Pass [Ha-Pa12], by Halpern and Rong [Ha-Ro10], by Halpern and Pass [Ha-Pa11], by Jamroga and Melissen [Ja-Me11], and by Adam and Ehud Kalai [Ka-Ka13].", "startOffset": 169, "endOffset": 178}, {"referenceID": 37, "context": "The solution concept defined using algorithmic rationability in [Ha-Pa11] can explain deviation towards cooperation in the iterated Prisoner\u2019s and Traveler\u2019s dilemmas, but it does not predict deviation towards cooperation in one-shot versions of the Prisoner\u2019s dilemma or in one-shot versions of the Traveler\u2019s dilemma with very small bonus-penalty, contradicting the experimental data reported in [Go-Ho01], [Be-Ca-Na05], [HRZ11], [DEJR12], [Fu-Ra-Dr12], [RGN12].", "startOffset": 64, "endOffset": 73}, {"referenceID": 51, "context": "Indeed, the experimental evidence have shown that expected utility theory fails to predict the behavior of decision makers [Al53], [Ka-Tv00], [St00].", "startOffset": 131, "endOffset": 140}, {"referenceID": 76, "context": "The definition and the use of utility functions relies in Morgenstern and von Neumann\u2019s expected utility theory [Mo-vN47], where, to avoid problems such as risk aversion, they assumed that players\u2019 utility functions contain all relevant information about the players\u2019 preferences over strategy profiles.", "startOffset": 112, "endOffset": 121}, {"referenceID": 5, "context": "In this way, Nash was then able to formalize Bernoulli\u2019s principle that each player attempts to maximize her expected utility [Be738] given that the other players attempt to do the same.", "startOffset": 126, "endOffset": 133}, {"referenceID": 51, "context": "Allais in [Al53] and many others are known nowadays (see, for instance, [Ka-Tv00] and [St00] for a large set of examples).", "startOffset": 72, "endOffset": 81}, {"referenceID": 91, "context": "[Ra08]), we give the following definition.", "startOffset": 0, "endOffset": 6}, {"referenceID": 29, "context": "As well known, this famous game was originally introduced by Flood in [Fl52], where he reported on a series of experiments, one of which, now known as Prisoner\u2019s Dilemma, was conducted in 1950.", "startOffset": 70, "endOffset": 76}, {"referenceID": 29, "context": "[Fl52], pp.", "startOffset": 0, "endOffset": 6}, {"referenceID": 10, "context": "5, which was observed in [Fe-Sc99] making a comparison among experimental data collected in [GSS82], [KKT86], [FHSS88], [RPOZ91], [Ca95], [HMcS96], and [Sl-Ro97].", "startOffset": 130, "endOffset": 136}, {"referenceID": 76, "context": "Expected utility theory was founded by Morgenstern and von Neumann in [Mo-vN47] to predict the behavior of a decision maker that must choose a prospect among some.", "startOffset": 70, "endOffset": 79}, {"referenceID": 28, "context": "Under certain axioms (see, for instance, [Fi82]) Morgenstern and von Neumann proved that a decision maker would evaluate each prospect p using the value", "startOffset": 41, "endOffset": 47}, {"referenceID": 107, "context": "have been successfully applied to explain a large number of phenomena that expected utility theory was not able to explain, as the disposition effect [Sh-St85], asymmetric price elasticity [Pu92],[Ha-Jo-Fa93], tax evasion [Dh-No07], as well as many problems in international relations [Le92], finance [Th05], political science [Le03], among many others.", "startOffset": 301, "endOffset": 307}, {"referenceID": 85, "context": "As well known, iterated deletion of strategies is a procedure which is common to most solution concepts (in Nash theory, one deletes dominated strategies; in iterated regret minimization theory, one deletes strategies which do not minimize regret; in Bernheim\u2019s and Pearce\u2019s rationability theory ([Be84] and [Pe84]), one deletes strategies that are not justifiable [Os-Ru94]).", "startOffset": 365, "endOffset": 374}, {"referenceID": 94, "context": "Now, since the preferences in cumulative prospect theory are described by a continuous function and since continuity is preserved by passing to the convexified version (see [Ro70], Theorem 17.", "startOffset": 173, "endOffset": 179}, {"referenceID": 17, "context": "These equilibria are computationally hard to find [Da-Go-Pa06].", "startOffset": 50, "endOffset": 62}], "year": 2013, "abstractText": "Over the years, numerous experiments have been accumulated to show that cooperation is not casual and depends on the payoffs of the game. These findings suggest that humans have attitude to cooperation by nature and the same person may act more or less cooperatively depending on the particular payoffs. In other words, people do not act a priori as single agents, but they forecast how the game would be played if they formed coalitions and then they play according to their best forecast. In this paper we formalize this idea and we define a new solution concept for one-shot normal form games. We prove that this cooperative equilibrium exists for all finite games and it explains a number of different experimental findings, such as (1) the rate of cooperation in the Prisoner\u2019s dilemma depends on the cost-benefit ratio; (2) the rate of cooperation in the Traveler\u2019s dilemma depends on the bonus/penalty; (3) the rate of cooperation in the Publig Goods game depends on the pro-capite marginal return and on the numbers of players; (4) the rate of cooperation in the Bertrand competition depends on the number of players; (5) players tend to be fair in the bargaining problem; (6) players tend to be fair in the Ultimatum game; (7) players tend to be altruist in the Dictator game; (8) offers in the Ultimatum game are larger than offers in the Dictator game. JEL Classification: C71, C72.", "creator": "LaTeX with hyperref package"}}}