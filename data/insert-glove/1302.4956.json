{"id": "1302.4956", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2013", "title": "A Definition and Graphical Representation for Causality", "abstract": "kabak We present a midvale precise definition of cause 323.3 and dandan effect tribhuwan in specular terms of aigen a qaradawi fundamental notion 17:45 called wiske unresponsiveness. majka Our sandiford definition numidian is based croagh on Savage ' s (laughingstocks 1954) buqour formulation of jaani decision 800-444-0267 theory and departs from the traditional view of causation in that mihin our causal suhadolc assertions protas are kowalewski made relative to a mcnees set affray of 32.83 decisions. An important consequence ochoco of this interport.net departure eglinton is that we figueroa can 202-887-8320 reason flappers about ti\u00f3 cause locally, not requiring 108.05 a causal explanation for every crenelated dependency. aldi Such 6-for-14 local t\u014d reasoning metasploit can convertibility be stagno beneficial aquel because kernel-mode it may not bubaris be necessary non-narrative to bernon determine whether cisplatina a i-610 particular 550-word dependency euphoric is ariela causal beltane to showering make gabbro a decision. mazinkaiser Also sanday in yibna this horseplayer paper, we examine araujo the dia graphical stodola encoding of proven causal relationships. We derecho show that influence diagrams andalou in harlock canonical form are ragas an russula accurate dalipi and efficient 86.7 representation 46-31 of causal relationships. metalurgs In nzaid addition, we mullei establish wga a byzantinist correspondence noorani between canonical form economique and Pearl ' s causal theory.", "histories": [["v1", "Wed, 20 Feb 2013 15:21:18 GMT  (321kb)", "http://arxiv.org/abs/1302.4956v1", "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)"], ["v2", "Sat, 16 May 2015 23:43:57 GMT  (201kb)", "http://arxiv.org/abs/1302.4956v2", "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)"]], "COMMENTS": "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["david heckerman", "ross d shachter"], "accepted": false, "id": "1302.4956"}, "pdf": {"name": "1302.4956.pdf", "metadata": {"source": "CRF", "title": "A Definition and Graphical Representation for Causality", "authors": ["David Heckerman"], "emails": ["heckerma@microsoft", "shachter@camis.stanford.ed"], "sections": [{"heading": null, "text": "We present a precise definition of ca use and e ffect in terms of a f undamental notion called unresponsiveness. Our definition is based on Savage's (1954 ) form ulation of decision the ory and departs from the traditional view of ca usation in that o ur ca usal assertions are made relative to a set of decisions. An im portant conseq uence of this depart ure is that we can reason abo ut ca use locally, not re q uiring a ca usal explanation for every depen dency. S uch local reasoning can be beneficial beca use it may not be necessary to determine whether a partic ular dependency is ca usal to make a decision. Also in this paper, we ex amine the graphical encoding of ca usal rela tionships. We show that infl uence diagrams in canonical form are an acc urate and effi cient representation of ca usal relationships. In addition, we establish a correspondence between canonical form and Pearl's ca usal theory.\nKeywords: ca usality, ca usal model, ca usal theory, ca usal networks, infl uence diagrams, canonical form, co unterfact ual reasoning\n1 Introduction\nMost traditional models of uncertainty, incl uding Markov networks (La uritzen, 1982 ) and Bayesian net works (Pearl, 1988) have foc used on the associational relationship among variables as capt ured by condi tional independence and dependence. Associational knowledge, however, is not s ufficient when we want to make decisions under uncertainty. For example, al though we know that smoking and l ung cancer are probabilistically dependent, we cannot concl ude from this knowledge that we will decrease o ur chances of getting l ung cancer if we stop smoking. In general, to\nmake rational decisions, we need to be able to predict the e ffects of o ur actions.\nRecent work by Artificial Intelligence researchers, statisticians, and philosophers-for example, Pearl and Verma (1991 ), Dr uzdzel and Simon (1 993 ), and Spirtes et al. (1993 )-have emphasized the impor tance of identifying ca usal relationships for p urposes of modeling the e ffects of intervention. They arg ue, for example, that if we believe that smoking ca uses l ung cancer, then we believe that o ur choice whether to contin ue or q uit smoking can a ffect whether we get l ung cancer . In contrast, if we believe that smoking does not ca use l ung cancer, o ur choice will not a ffect whether we get l ung cancer, and the observed corre lation between smoking and l ung cancer co uld be ex plained perhaps by a common ca use of both (e.g., a genetic predisposition toward cancer and the desire to smoke ), which we are unable to control. This recent work has led to significant breakthro ughs in ca usal reasoning. For example, Pearl and Verma {1 991 ) and Spirtes et al. (1993 ) have shown how ca usal knowledge represented graphically can be used to pre dict the e ffects of interventions and how observational data can be used to s uggest ca usal relationships, and Pearl (1995) has shown how, given a q ualitative ca usal str uct ure, the q uantitative e ffects of intervention may be estimated from observational data alone in some sit uations.\nIn this paper, we o ffer three improvements to the c ur rent work in ca usal reasoning. F irst, the c urrent ap proaches either take ca usality as a primitive notion, or provide only a f uzzy, int uitive definition of ca use and e ffect. For example, in the introd uction of their book on ca usation, Spirtes et al. (1993, p. 4 2 ) write:\nWe understand ca usation to be a relation be tween partic ular events: something happens and ca uses something else to happen. Each ca use is a partic ular event and each e ffect is a partic ular event. An event A can have more than one ca use, none of which alone s uffice to prod uce A. An event A can also be overde-\nA Definition and Graphical Representation for Causality 263\ntermined: it can have more than one set of ca uses that s uffice for A to occ ur. We as s ume that ca usation is transitive, irreflexive, and antisymmetric.\nIn this paper, we offer a definition of ca usation in terms of a more f undamental relation that we call unrespon siveness. Our definition is precise, and can be used as an assessment aid when someone is having tro uble determining whether or not a relationship is ca usal. Also, o ur definition can help people acc urately com m unicate their beliefs abo ut ca usal relationships. In addition, the definition facilitates the development of techniq ues for learning ca usal relationships from data (Beckerman, this proceedings ).\nSecond, the c urrent approaches req uire all relation ships to be ca usal. That is, for any two probabilisti cally dependent events or variables x and y in a given domain, these methods req uire a user to assert either that x ca uses y, y ca uses x, or they are linked by a chain of ca usal relationships, s uch as when x and y share a common ca use, or x and y are common ca uses of an observed variable. For example, Pearl and Verma's (1991) ca usal model is a directed acyclic graph ( DA G ), wherein every node corresponds to a variable and every arc from nodes x to y corresponds to the assertion that x is a direct ca use of y. When using a ca usal model to represent a domain, a ca usal explana tions m ust hold for every dependency in the domain. Our definition of ca usation is local in that it does not req uire all relationships to be ca usal. This property can be advantageo us when making decisions. Namely, given a partic ular decision problem, there may be no need to assign a ca usal explanation to all dependencies in the domain in order to determine a rational co urse of action. Conseq uently, o ur definition may enable a decision maker to reason more efficiently.\nThird, we describe a special condition on an infl uence diagram known as canonical form and show how it can be used to represent ca usal relationships more ef ficiently than existing representations.\nOur approach is consistent with several c urrent meth ods for reasoning abo ut ca usality, incl uding Pearl's ca usal theory (Pearl and Verma, 1991; Pearl, 1995) and ca usal networks of Spirtes et al. ( 1993 ). In ad dition, o ur approach is consistent with the philosophy of decision analysis as described by Savage ( 1954 ) and refined by Howard (1990). Th us, o ur disc ussions here offer a means by which the two disciplines may begin to comm unicate and contrib ute to each other's work.\nThis paper is a seq uel to that presented at last year's conference (Beckerman and Shachter, 1994 ). Here, we clarify and generalize many of the concepts in the pre vio us paper, incl uding those of unresponsiveness (for merly disc ussed in terms of fixed sets ), mapping vari able, ca use, set decision, and canonical form.\n2 Unresponsiveness\nIn this section, we introd uce the notions of unrespon siveness and limited unresponsiveness, f undamental re lations underlying ca usation.\nImportant to o ur disc ussion are several distinctions from classical decision theory as described by Savage ( 1954 ). In partic ular, we disting uish between alterna tives (what Savage called \"acts\" ), realizations (what Savage called \"conseq uences\" ), and possible states of the world.1 Savage describes and ill ustrates these con cepts as follows:\nTo say that a decision is to be made is to say that one or more (alternatives ] is to be chosen, or decided on. In deciding on an (alternative ], acco unt m ust be taken of the possible states of the world, and also of the (realizations ] implicit in each (alternative ] for each possible state of the world. A [realiza tion] is anything that may happen to the per son. Consider an example. Yo ur wife has just broken five good eggs into a bowl when yo u come in and vol unteer to finish making the omelet. A sixth egg, which for some rea son m ust either be used for the omelet or wasted altogether, lies unbroken beside the bowl. Yo u m ust decide what to do with this unbroken egg. Perhaps it is not too great an oversimplification to say that yo u m ust de cide among three [alternatives ] only, namely, to break it into the bowl containing the other five, to break it into a sa ucer for inspection, or to throw it away witho ut inspection. De pending on the state of the egg, each of these three [alternatives ] will have some [ realiza tion ] of concern to yo u, say that indicated by Table 1.\nFor p urposes of o ur disc ussion, there are two points to emphasize from Savage's exposition. First, it is im portant to disting uish between that which we can con trol directly-namely, alternatives-and that which we can control only indirectly thro ugh choosing an alternative-namely, realizations. Second, once we choose an alternative, the realization that occ urs is log ically determined by the state of the world. Of co urse, this realization can be (and us ually is ) uncertain, be ca use the state of the world is uncertain.\n1 We use the term \"alternative\" in place of \"act\", be cause the former is more commonly used today. We use the term \"realization\" in place of \"consequence\" because it avoids the connotation that we should necessarily care about a realization. That is, we often want to model re alizations, even though we don't directly care about them. In using different terms for these concepts, however, we do not intend to change their meanings.\n264 Heckennan and Shachter\nIn the omelet story, the possible states of the world readily come to mind given the description of the prob lem. Furthermore, we can observe the state the world (i.e., the condition of the egg ). In many if not most situations, however, the state of the world is unob servable; and we can only bring the possible states to mind by thinking about the alternatives and re alizations . For example, suppose we have a decision to continue smoking or quit, and we model the real izations of getting cancer or not. These alternatives and realizations bring to mind four possible states of the world, as shown in Table 2. These possible states have no familiar names; and we simply label them with numbers. The actual state of the world is not observ able, because, if we decide to quit, we won't know for sure what would have happened had we continued, and vice-versa. Nonetheless, given the alternatives and re alizations in this problem, these states of the world are well defined.2 Also, note that, as illustrated by this example, there can be more possible states of the world than either realizations or alternatives. In gen eral, if we have a decision problem with r realizations and a alternatives, then we can distinguish as many as ra possible states of the world.\nIn practice, it is often cumbersome if not impossible to reason about a monolithic set of alternatives, possi ble states of the world, or realizations. Consequently, we typically describe each of these items in terms of a set of variables. We call the variables describing a set of realizations chance variables. For example, in the omelet story, we can describe the realizations in terms of three variables: (1 ) number of eggs in the\n2Howard (1990) discusses in detail what it means for possible states of the world to be well defined.\nomelet'f3 (o) , having instances \"zero,\" \"five,\" and \"six,\" (2 ) number of good eggs destroyed? (g) , hav ing instances \"zero,\" \"one,\" and \"five,\" and (3 ) saucer to wash? ( s) , having instances \"no\" and \"yes.\" That is, every realization corresponds to an assignment of an instance to each chance variable.\nWe call the variables describing a set of alternatives de cision variables (or decisions, for short ). For example,\nsuppose we have a set of alternatives about how we are going to dress for work. In this case, we can describe our alternatives in terms of the decision variables (say ) shirt (\"plain\" or \"striped\" ), pants (\" jeans\" or \"cor duroy\"), and shoes (\"tennis shoes\" or \"loafers\"). In this example and in general, every alternative corre sponds to an assignment of an instance to each deci sion variable.\nThe description of possible states of the world in terms of component variables is a bit more complicated, and is not needed for our explication of unresponsiveness and limited unresponsiveness. We defer discussion of this issue to Section 4.1.\nAs a matter of notation, we use D to denote the set of decisions that describe the alternatives for a deci sion problem, and lower-case letters (e.g., d, e , f) to denote individual decisions in the set D. Also, we use U to denote the set of chance variables that describe the realizations, and lower-case letters (e.g., x, y, z) to denote individual chance variables in U. In addition, we use the variable S to denote the state of the world (the instances of S correspond to the possible states of the world).4 Thus, any given decision problem-or domain, as we sometimes call it-is described by the variables U, D, and S.5\nWith this introduction, we can discuss the concept of limited unresponsiveness. To illustrate this concept, consider the following decision problem adapted from Rubin ( 1978). Suppose we are a physician who has to decide whether or not to recommend a treatment to a\n3To emphasize the distinction between chance and de cision variables, we put a question mark at the end of the names of chance variables.\n4We use an uppercase \"S\" to denote this single variable, because later we decompose S into a set of variables.\n5Sometimes, for simplicity, we leave s implicit in the specification of a decision problem.\nA Definition and Graphical Representation for Causality 265\npatient. Given our recommendation, the patient may or may not actually accept the treatment, and may or may not be cured as a result. Here, we use a sin gle decision variable recommendation ( r) to represent our alternatives (i.e., D = { r}) , and two chance vari ables taken? (t) and cured? (c) to represent whether or not the patient actually accepts the treatment and whether or not the patient is cured, respectively (i.e., U = {t, c}) .\nThe possible states of the world for this problem are shown in Table 3. For example, consider the first row in the table. Here, the patient will accept the treat ment if and only if we recommend it, and will be cured if and only if he takes the treatment. We describe this state by saying that the patient is a \"complier\" and is \"helped\" by the treatment. We discuss the description of these states in more detail in Section 4 .1.\nAs indicated in the table, we have asserted that the last four states of the world are impossible (i.e., have a probability of zero). These last four states share the property that t takes on the same instance for both alternatives, whereas c does not. Thus, this decision problem satisfies the following property: in all of the states of the world that are possible, if t is the same for the two alternatives, then c is also the same. We say that c is unresponsive to r in states limited by t .\nIn general, suppose we have a decision problem de scribed by variables U, D, and S. Let X be a subset of U, andY be a subset of U U D. We say that X is unre sponsive to D in states limited by Y if we believe that, for all possible states of the world, if Y assumes the same instance for any two alternatives then X must also assume the same instance for those alternatives.\nTo be more formal, let X [S, D] be the instance that X assumes (with certainty) given the state of the world S and the alternative D. For example, in the omelet story, if S is the state of the world where the egg is good, and D is the alternative \"throw away,\" then o[S, D) (the number of eggs in the omelet ) assumes the instance \"five.\" Then, we have the following definition.\nDefinition 1 (Limited (Un)responsiveness) Given a decision problem described by chance variables U, decision variables D, and state of the worldS, and variable sets X \ufffd U and Y \ufffd D U U, X is said to be unresponsive to D in states limited by Y, denoted X f-'y D, if we believe that V S E S, Dt E D, D2 E D,\nY[S, Dt] = Y [S, D2] ===> X [S, Dt] = X[S, D2]\nX is said to be responsive to D in states limited by Y, denoted X f->y D, if it is not the case that X is\nunresponsive to D in states limited by Y. That is, if we believe that 3 S E S, Dt E D, D2 E D such that\nY[S, Dt] = Y [S, D2] and X [S, D1] :/; X[S, D2]\nWhen X is (un)responsive to D in states limited by Y = 0, we simply say that X is (un)responsive to D. The notion of unresponsiveness is significantly simpler than that of limited unresponsiveness. In particular, when Y = 0, the equalities on the left -hand-side of the implications in Definition 1 are trivially satisfied. Thus, X is unresponsive to D if we believe that, for all possible states of the world and all alternatives, X assumes the same instance; and X is responsive to D, if there is some possible state of the world where X di ffers for two di fferent alternatives.\nAs examples of responsive variables, consider the omelet story. Let S denote the state where the egg is good, and D1 and D2 denote the alternatives \"break into bowl\" and \"throw away,\" respectively. Then, for the variable o (number of eggs in omelet?) , we have o[S, D1] =\"six\" and o[S, D2] =\"five\". Consequently, o is responsive to D. In a similar manner, we can con clude that g (number of good eggs destroyed?) , and s (saucer to wash?) are each responsive to D as well.\nNote that, if an chance variable x is responsive to D, then-to some degree-it is under the control of the decision maker. Consequently, the decision maker can not observe x prior to choosing an alternative for D. For example, in the omelet story, we can not observe any of the responsive variables o, g, or s before choos ing an alternative .\nAs an example of an unresponsive variable, suppose we addS (the state of the world) as a variable to U. (E.g., in the omelet story, we can take U to be { S, o, g, s}.) By Savage's definition of S, it must be unresponsive to D. Note that adding S to U creates no new states of the world.\nThe notions of unresponsiveness and limited unrespon siveness are closely related to concepts in counterfac tual reasoning (e.g., as described by Lewis (1 979)). In particular, when we determine whether or not a set of chance variables X is unresponsive to decisions D, we essentially answer the query \" Will the outcome of X be the same no matter how we choose D?\" Further more, when we determine whether or not X is unre sponsive to D in states limited by Y, we answer the query \" Will the outcome of X be the same no matter how we choose D, if Y will not change as a result of our choice?\" Queries of this form are of examples counter factual queries. One of the fundamental assumptions of our work presented here is that these queries are eas ily answered. In our experience, we have found that decision makers are indeed comfortable answering such restricted counterfactual queries.\nThe concepts of responsiveness and probabilistic inde pendence are related, as illustrated by the following theorem.\nTheorem 1 If a set of chance variables X is unre sponsive to a set of decision variables D, then X is\n266 Heckerman and Shachter\nTable 3: A decision about recommending a medical treatment.\nr ( recommendation) S (state of the world ) take don't take\nt ( taken?) 1: complier, helped yes 2: complier, hurt yes 3: complier, always cured yes 4: complier, never cured yes 5: defier, helped no 6: defier, hurt no 7: defier, always cured no 8: defier, never cured no 9: always taker, cured yes\n10: always taker, not cured yes 11: never taker, not cured no 12: never taker, cured no 13: (impossible ) yes 14: (impossible ) yes 15: (impossible ) no 16: (impossible ) no\nprobabilistically independent of D.\nProof: By definition of unresponsiveness, X assumes the same instance for all alternatives in any possible state of the world. Consequently, we can learn about X by observing S, but not by observing D. 0\nNonetheless, the two concepts are not identical. In particular, the converse of Theorem 1 does not hold. For example, let us consider the simple decision of whether to bet heads or tails on the outcome of a coin flip. Assume that the coin is fair (i.e., the probabilities of heads and tails are both 1/2) and that the person who flips the coin does not know our bet. Here, the possible outcomes of the coin toss correspond to the possible states of the world. Further, let decision vari able b denote our bet, and chance variable w describe the possible realizations that we win or not. In this sit uation, w is responsive to b, because for both possible states of the world, w will be di fferent for the di fferent bets. Nonetheless, the probability of w is 1/2, whether we bet heads or tails. That is, w and b are probabilis tically independent.\nLimited unresponsiveness and conditional indepen dence are less closely related than are their unqual ified counterparts. Namely, limited unresponsiveness does not imply conditional independence. For exam ple, in the medical-treatment story, c (cured?) is un responsive to r ( recommendation) in states limited by t ( taken?), but it is reasonable for us to believe that c and r are not independent given t, perhaps because there is some gene that-partially or completely determines how a person reacts to both recommen dations and treatment.\nc ( cured?)_ t _(taken?} c ( cured?) yes no no no no yes yes no yes no no no no yes yes yes yes no yes yes yes no yes no yes yes yes no yes no no no no yes no yes yes yes no no yes yes no no yes yes no no\nWe can derive several interesting properties of limited unresponsiveness from its definition.\n1. X foy D {:::=::} Vx EX, x foy D\n2. X fow D {:::=::} X U W fow D\n3. X foD D\n4. X foy D \ufffd X foyuz D\n5. X foYuz D and Y foz D \ufffdX foz D\n6. X f-'z D and W foz D \ufffdX f-'wuz D\nwhere D is the set of decision variables in the domain, X and W are arbitrary sets of chance variables in U, and Y and Z are arbitrary sets of variables in U U D.\nThe proofs of these properties are straightforward. For example, consider property 5. Given X foyuz D, we have V S E S, Dt E D, D2 E D,\nY [S, D1] = Y [S, D2] and Z[S, Dt] = Z[S, D2]\n\ufffd X[S, Dt] = X[S, D2]\nGiven Y foz D, we have V S E S, Dt E D, D2 E D,\nConsequently, we obtain V S E S, Dt E D, D2 E D,\nZ[S, Dt] = Z[S, D2] \ufffd X[S, Dt] = X[S, D2]\nThat is, X foz D.\nOther properties follow from these. For example, it is true trivially that 0 foy D. Consequently, by Prop erty 2, we know that Y foy D. As another example,\nA Definition and Graphical Representation for Causality 267\na special case of Property 4 is that whenever X is un responsive to D, then X will be unresponsive to D in states limited by any Z. Also, Properties 4 and 5 imply that limited unresponsiveness is transitive: X \ufffdY D andY \ufffdz D imply X \ufffdz D.\nIn closing this section, we note that the definition of limited unresponsiveness can be generalized in several ways. In one generalization, we can define what it means for X \ufffd U to be unresponsive to D in states of the world limited by an instance of Y. Namely, we say that X is unresponsive to D in states limited by Y = Y if, for all possible states of the worldS, and for any two alternatives D1 and D2, Y[S, D1] = Y [S, D2] = Y implies X [S, D1] = X [S, D2]. Furthermore, we can imagine generalizations where the possible states of the world are limited by subsets of instances of Y, not just a single instance of Y.\nIn a second generalization, we can define what it means for a set of chance variables to be unresponsive to a subset of all of the decisions. In particular, given a domain described by U and D, we say that X \ufffd U is unresponsive to D' \ufffd D in worlds limited by Y if X \ufffdYu(D\\D') D.\nF inally, we can have combinations of these two gen eralizations. Nonetheless, except for a brief mention of each generalization, we do not pursue them in the remainder of the paper for the sake of simplicity.\n3 Definition of Cause\nArmed with the primitive notion of limited unrespon siveness, we can now formalize our definition of cause.\nDefinition 2 (Causes with Respect to Decisions) Given a decision problem described by U and D, and a variable x E U, the variables C \ufffd D U U \\ { x } are said to be causes for x with respect to D if C is a minimal set of variables such that x \ufffdc D.\nIn our framework, decision variables cannot be caused, because they are under the control of the decision maker. Consequently, we define causes for chance vari ables only. The definition says that if we can find set of variables Y such that, for all possible states of the world, x can be di fferent for di fferent alternatives only when Y is di fferent, then Y must contain a set of causes for x. Our definition of cause departs from traditional u sage of the term in that we consider causal relation ships relative to a set of decisions. Nonetheless, we find this departure has an important advantage, which we discuss shortly.\nAs an example of our definition, consider the decision to continue or quit smoking, described by the deci sion variable s (smoke) and the chance variable l (lung cancer?) . If we believe that s and l are probabilisti cally dependent, then, by Theorem 1, it must be that\nl f-' s . Furthermore, by Property 3, we know that l f-', s . Consequently, by Definition 2, we have that s is a cause of l with respect to s.\nSeveral consequences of Definition 2 are worth men tioning. First, although cause is irreflexive by defini tion, it is not always asymmetric. For example, in our story about the coin toss, consider another variable m that represents whether or not the outcome of the coin toss matches our bet b. In the story as we have told it, m is a deterministic function of w (win?) , and vice versa . Consequently, we have w \ufffdm b and m f-'w b; and so m is a cause o f w and w is cause of m with re spect to b. Note that any hint of uncertainty destroys this symmetry. For example, if there is a possibility that the person tossing the coin will cheat (so that we may lose even if we match ), then we can conclude that m is a cause of w, but not vice versa .\nSecond, cause is transitive for single variables. In par ticular, if x is a cause for y and y is a cause for z with respect to D, then z f-' D and (by the transitivity of unresponsiveness ) z \ufffdx D. Consequently, x is a cause for z with respect to D. Note that transitivity does not necessarily hold for causes containing sets of vari ables, because the minimality condition in Definition 2 may not be satisfied.\nThird, C = 0 is a set of causes for x with respect to D if and only if x is unresponsive to D .\nFinally, we have the following theorem, which follows from Definition 2 and several of the properties of lim ited unresponsiveness given in Section 2.\nTheorem 2 Given any x E U, if C is a set of causes for x with respect to D, and wE C n U, then w must be responsive to D.\nProof: For any chance variable w E C, let C' = C \\ { w}. By the minimality condition in our definition, we have\nx +-'c' D (1)\nSuppose that w \ufffd D . Then, by Property 4, we have\nw \ufffdc ' D (2)\nApplying Equations 1 and 2 to Property 6, we have that x f-'c D, which contradicts that C is a set of causes for x with respect to D. 0\nLet us consider another example of our definition that illustrates an advantage of defining cause with respect to the set of decisions. In the medical-treatment story, we have that c (cured?) is responsive to r ( recommen dation) , because (among other reasons ) in the first row in Table 3, the patient is cured if and only if we rec ommend the treatment. Furthermore, as we discussed in the previous section, c is unresponsive to r in states limited by t (taken?) . Consequently, we have that t is a cause of c with respect to r.\n268 Heckerman and Shachter\nNow, let us extend this example by imagining that there is some gene that a ffects how a person reacts to both our recommendation and to therapy. In this situ ation, it is reasonable for us to assert that the variable g (genotype?) is unresponsive to r. Thus, by Theo rem 2, g cannot be among the causes for any other variable. Someday, however, it may be possible to use retroviral therapy to alter one's genetic makeup. Given an additional decision variable v ( retroviral ther apy) , it is reasonable for us to assert that tis responsive to D = { r, v} in states limited by r, but unresponsive to D in states limited by { r, g}. In this case, we can conclude that { r, g} is a cause for t with respect to D. In addition, we can conclude that { t, g} is a cause for c with respect to D.\nThus, an advantage of defining cause with respect to the set of decisions is that we do not have to attach a causal explanation to dependencies between a vari able x and other variables, when we can do nothing to change x. In our example, g, t, and c are prob abilistically dependent. Nonetheless, if we cannot do anything to a ffect genotype, then there is little point in determining whether or not genotype causes treat ment and cure; and it is precisely in this case that our definition says it is OK to ignore such questions of cause.\nOf course, we sometimes want to be able to assert the existence or nonexistence of causal dependencies out side of a real decision setting. Our definition does not preclude the ability to make such assertions. Namely, there is no reason to require that the decisions D be implementable in practice or at all. If we want to think about whether or not the patient's genotype is a cause for his cure, then we can imagine the retroviral-therapy decision that a ffects genotype regardless of the avail ability of the therapy. As another example, if we want to discuss the possibility that gender causes breast can cer, then we can imagine a decision that changes one's gender.\nFinally, we can generalize our definition of what it means for a set of variables to cause x to a defini tion of what it means for a set of instances to cause x. Namely, we say that instance C of variables C is a cause for x \ufffd C with respect to D if C is a minimal set of variables such that x is unresponsive to D in states limited 'by C = C. That is, the instance C of C is a cause for x with respect to D if we replace our definition of cause with the weaker requirement that x be unresponsive to D in states limited by C = C. Again, for the sake of simplicity, we do not pursue this generalization in the remainder of the paper.\n4 Graphical Representation of Cause\nGiven the known benefits of the Bayesian network for representing conditional independence, we would like a\ngraphical representation of cause and e ffect. The rep resentation we describe is a special case of an in fluence diagram. An influence diagram for a decision prob lem described by U and D is a model for that prob lem having a structural component and a probabilistic component. The structure of an in fluence diagram is a directed acyclic graph containing (square ) decision and (oval ) chance nodes corresponding to decision and chance variables, respectively, as well as information and relevance arcs. Information arcs, which point to decision nodes, represent what is known at the time decisions are made. Relevance arcs, which point to chance nodes, represent (by their absence ) assertions of conditional independence. Namely, for some order ing of the variables, each variable x is probabilistically independent of all preceding variables given the par ents of x. Associated with each chance node x in an influence diagram are probability distributions that, when combined with the assertions of conditional in dependence encoded in the structural component, de termine the joint probability distribution for U given D. A special kind of chance node is the determin istic node (depicted as a double oval ). A node x is a deterministic node if its corresponding variable is a deterministic function of its parents. Also, an influ ence diagram may contain a single distinguished node, called a utility node that encodes the decision maker's utility for each state of the node's parents. A utility node is a deterministic function of its predecessors and can have no children. Finally, for an in fluence diagram to be well formed, its decisions must be totally ordered by the influence-diagram structure. (For more details, see Howard [1981].)\nIn this paper, we concern ourselves neither with the or dering of decision nodes nor the observation of chance variables before making decisions. Therefore, we have no need for information arcs. In addition, although our new concepts apply to models that include a util ity node, we do not examine such models, as we can illustrate these concepts with models containing only chance, deterministic, and decision variables. An in fluence diagram (without information arcs or a utility node ) for the medical-treatment problem is shown in Figure 1a.\nIn Heckerman and Shachter ( 1994 ), we showed that an ordinary influence diagram is an inadequate represen tation of causal dependence. In this section, we dis cuss a particular kind of an in fluence diagram, known as an influence diagram in canonical form, that can accurately represent causal relationships.\n4.1 Mapping Variables and Causal Mechanisms\nBefore we can describe canonical form, we need to in troduce the concept of a mapping variable. To under stand the concept of a mapping variable, let us reexam-\nA Definition and Graphical Representation for Causality 269\nine Savage's basic formulation of a decision problem. Recall that the chance variables U are a deterministic function of the decision variables D and the state of the world S. In e ffect, each possible state of the world defines a mapping from the decisions D to the chance variables U. Thus, S represents all possible mappings from D to U. We can characterize S as a mapping variable for U as a function of D, and use the sugges tive notation U (D) to denote this mapping variable.\nIn general, given a domain described by U, D, and S, a set of decision variables Y \ufffd D, and a set of chance variables X \ufffd U, the mapping variable X (Y) is a vari able that represents the possible mappings from Y to X. Rubin ( 1978) and Howard (1990) define concepts similar to the mapping variable.\nAs an example, consider the medical-treatment story. The mapping variable t (r) represents the possible mappings from the decision variable r ( recommenda tion) to the chance variable t (taken?) . In this exam ple, the instances of t (r ), shown in Table 4, have a nat ural interpretation. In particular, the instance where the patient accepts treatment if and only if we recom mend it represents a patient who \"complies\" with our recommendation ; the instance where the patient ac cepts treatment if and only if we recommend against it represents a patient who \"defies\" our recommenda tion ; and so on.\nAn important property concerning mapping variables is that, given variables X, Y, and X(Y) , we can always write X as a deterministic function of Y and X (Y) . For example, t is a deterministic function of r and t ( r) ; and, more generally, U is a deterministic function of D and U(D):: S.\nI n the discussions that follow, it is important to extend the definition of a mapping variable to include chance variables as arguments. Doing so allows us to decom pose the monolithic mapping variable U(D) = S for a domain into a set of variables. For example, consider the medical-treatment story. Given this extension of the mapping-variable definition, we can define the mapping variable c(t) with instances \"helped,\" \"hurt,\" \"always cured,\" and \"never cured.\" Together, the mapping variables t(r) and c(t) describe the possible states of the world U(D) = S. (E.g., t(r) =\"complier\" and c(t) =\"helped\" corresponds to state 1 in Ta ble 3.) As we shall see, this decomposition facilitates the graphical representation of causal relationships.\nThe extension of the mapping-variable definition to include chance variables as arguments is a bit tricky. For example, when the patient is an \"always taker\", it is impossible to distinguish between the instances \"helped\" and \"always cured\" of c(t ), because for both recommendations, the patient will accept the treat ment. In this sense, the variable c(t) is not well de fined.\nWe can overcome this problem by imagining a decision that allows us to directly set t to any of its instances, regardless of the recommendation decision. The key idea in setting this variable directly is that we force t to take on a particular instance without changing the instances of any other variables except those that are mandated by the known causal relationships in the do main. For example, assuming the treatment is a drug and that there is no placebo e ffect, we can directly set t to \"taken\" by injecting the patient with the drug with out his knowledge. In contrast, although we can set t to \"taken\" by physically forcing the patient to take the drug, this operation may not qualify as a setting of the variable if the patient's conditioned is worsened by the use of force itself.\nPearl and Verma (1991) and Spirtes et al. ( 1993 ) dis cuss the notion of directly setting or manipulating a variable, taking this concept to be primitive. Here, we formally define the notion in terms of limited un responsiveness.\nDefinition 3 (Set Decision) Given a domain de scribed by U, D, and S, consider a set of decision variables outside D, denoted (; , that contains one de cision variable x for every x E U, where x has alter natives \"set x to k \" for each possible instance k of x and \"do nothing. \" Let U' = U, D' = D U (; , and S' be an augmentation of the original domain in the sense that, ( 1) when each x E (; is set to \"do nothing\", the realizations in the augmented domain (as a function of S' and D') are the same as those in the original domain, and (2) when x = \"set x to k, \" then x as sumes tlie state k. Then, (; is said to be a collection\nof set decision variables for U with respect to U, D, and S if, for all Y \ufffd U and Z \ufffd U U D, x \ufffd z D in the original domain if and only if x \ufffdzuy D U Y6 in the augmented domain, where Y are the set decisions corresponding to the variables in Y .\nFor example, in the medical-treatment story, we have that c \ufffdt r. Thus, in the augmented domain, we must have c \ufffdt { r, i} for i to be a set decision for t. It is likely that a decision to secretly in ject the patient satisfies this condition (again, provided there is no placebo e ffect ), whereas it is unlikely that a decision\n6 In writing this expression, we are using the second gen eralization of the definition of limited unresponsiveness dis cussed in Section 2. In particular, this expression is equiv alent to the statement x f-'zuYu(U\\Y) D'.\n270 Heckerman and Shachter\nto use physical force does. Note that, in general, set decisions need only be hypothesized. They need not be implementable in practice.\nDefinition 4 (Setting a Variable) Given a deci sion variable d, we set that variable by choosing one of its alternatives. Given a chance variable x, we set that variable by choosing one of the alternatives of x other than \"do nothing. \"\nWe can now give the general defintion of a mapping variable.\nDefinition 5 (Mapping Variable) Given chance variables X and variables Y, the map\nping variable X (Y) is the chance variable that repre sents all possible mappings from Y to X as we set Y to each of its possible instances. 7\nThere are several important points to be made about mapping variables as we have now defined them. First, as in the more specific case, X is always a deterministic function of Y and X (Y) .\nSecond, additional probability assessments typically are required when introducing a mapping variable into a probabilistic model. For example, two independent assessments are needed to quantify the relationship be tween r and t in the medical-treatment story; whereas three independent assessments are required for the node t ( r ) . In general, many additional assessments are required. If X has b instances and Y has a in stances, then X(Y) has as many as ba instances. In real-world domains, however, reasonable assertions of independence decrease the number of required assess ments. In some cases, no additional assessments are necessary (see, e.g., Heckerman et al. 1994 ). Third, although we may not be able to observe a map ping variable directly, we may be able to learn some thing about it. For example, we can model the decision to continue or quit smoking using the decision vari able s ( smoke) , the chance variable l ( lung cancer?) , and the mapping variable l ( s) . Although we cannot observe l(s) , we can imagine a test that measures the susceptibility of someone's lung tissue to lung cancer in the presence of tobacco smoke. Given the result of such a test, we can update our probability distribution over l(s) .\nFourth, we have the following theorem and corollaries.\nTheorem 3 (Mapping Variable) Given a decision problem described by U and D, variables X\ufffd U, and\n7There are some technical details involved with the def inition of a mapping variable when particular instances of Y are not possible or not possible for particular in stances of D. Although all of the results given here are true in general, we omit these special cases for simplicity in presentation.\nvariable sets W, Y, and Z that are all subsets ofUUD, X(W) ,WzuY D if and only if X(W U Y) ,Wz D.\nProof: X (W U Y) represents all possible mappings from W U Y to X. By the definition of a mapping variable, X(WUY) ,Wz D if and only if X(W) ,WzuY DUYu, where Yu = Y n U is the set of chance variables in Y. Likewise, by the definition of a set decision, X(W) ,Wzuy DUYu if and only if X(W) ,WzuY D.D\nCorollary 4 (Mapping Variable) Given a deci sion problem described by U and D, variables X \ufffd U, and Y\ufffd U U D, X ,Wy D if and only if X(Y) ,W D.\nFor example, in the medical treatment story, we have c ,Wt r and c(t) ,W r. Roughly speaking, Corollary 4 says that X is unresponsive to D in states limited by Y if and only if the way X depends on Y does not depend on D. This equivalence provides us with an alternative set of conditions for cause.\nCorollary 5 (Cause) Given a decision problem de scribed by U and D, and a chance variable x E U, the variables C \ufffd D U U \\ { x} are causes for x with re spect to D if C is a minimal set of variables such that x (C) ,W D.\nWe can think of x (C)-where Care causes for x-as a causal mechanism that relates C and x. For example,\nsuppose chance variables i and o represent the volt age input and output, respectively, of an inverter in a logic circuit. Given a decision d to which i responds, we can assert that { i} is a cause for o. In this exam ple, the mapping variable o( i) , represents the mapping from the inverter's inputs to its outputs. That is, this mapping variable represents the state of the inverter itself.\nDefinition 6 (Causal Mechanism) Given a deci sion problem described by U and D and a chance vari able x E U that is responsive to D, a causal mech anism for x with respect to D is a mapping variable x (C) where C are causes for x with respect to D.\nThus, we have the following consequence of Corol lary 4.\nCorollary 6 (Causal Mechanism) If x (C) is a causal mechanism for x with respect to D, then x (C) is unresponsive to D.\n4.2 Canonical Form Influence Diagrams\nWe can now define what it means for an influence di agram to be in canonical form.\nDefinition 7 (Canonical Form) An influence dia gram for a decision problem described by U and D is said to be in canonical form if (1) all chance nodes that\nA Definition and Graphical Representation for Causality 271\n(a) (b)\nFigure 1: (a ) An influence diagram for the medical treatment story. (b ) A corresponding influence dia gram in canonical form.\nare responsive to D are descendants of one or more de cision nodes and (2) all chance nodes that are descen dants of one or more decision nodes are deterministic nodes.\nAn immediate consequence of this definition is that any chance node that is not a descendant of decision node must be unresponsive to D.\nWe can construct an influence diagram in canonical form for a given problem by including in the influence diagram a causal mechanism for every variable that is responsive to the decisions. In doing so, we can make every responsive variable a deterministic function of a set of its causes and the unresponsive causal mech anism. For example, consider the medical-treatment story as depicted in the influence diagram of Figure la. The variables t and care responsive tor, but their cor responding nodes are not deterministic. Consequently, this influence diagram is not in canonical form. To construct a canonical form influence diagram, we in troduce the mapping variables t (r) and c(t), as shown in Figure lb. The responsive variables are now deter ministic; and the mapping variables are unresponsive to the decision. This example illustrates an important point: Causal mechanisms may be probabilistically de pendent. We return to this issue in Section 4.3.\nIn general, we can construct an influence diagram in canonical form for the decision problem U and D as follows.\nAlgorithm 1 (Canonical Form)\n1. Add a node to the diagram corresponding to each variable in U U D\n2. Order the variables x1, .. . , Xn in U so that the variables unresponsive to D come first\n3. For each variable x; E U that is unresponsive to D,\n(a) Add a causal-mechanism chance node x; ( C;) to the diagram, where C; \ufffd D U {x1, ... , x;_I}\n(b) Make x; a deterministic node with parents C; and x;(C;)\n4. A ssess dependencies among the variables that are unresponsive to D\nThis algorithm is well defined. In particular, it is al ways possible to find a C; satisfying the condition in step 3a, because x; \ufffd D D by Property 3. Also, the structure of the of the constructed influence diagram is valid. Namely, by Corollary 6, all causal mechanisms added in step 3 are unresponsive to D. Thus, suppose we identify the relevance arcs and de terministic nodes by using a variable ordering where the nodes in D are followed by the unresponsive nodes (including the causal mechanisms ), which are in turn followed by the responsive nodes in the order specified at step 2. Then, (1 ) we would add no arcs from D to the unresponsive nodes by Theorem 1 (and the algo rithm adds none ) ; (2 ) we would add arcs among the unresponsive nodes as described in step 4; and (3 ) for every responsive variable x;, we would make x; a de terministic node (as described in step 3b ) by definition of a mapping variable.\nFurthermore, the structure that results from Algo rithm 1 will be in canonical form. In particular, be cause there are no arcs from D to the unresponsive nodes, only responsive variables can be descendants of D. In addition, by Theorem 2, we know that every responsive node is a descendant of D, and (by con struction ) a deterministic node. To illustrate the algorithm, consider the medical treatment story as depicted by the influence diagram in Figure 2a where the variable g (genotype?) is rep resented explicitly. To construct an influence diagram in canonical form for this problem, we first add the variables { r, g, t , c} to the diagram and choose the or dering (g , t , c) . Both t and c are responsive to D = { r }, and have causes r and t , respectively. Consequently, we add causal mechanisms t ( r ) and c(t) to the new diagram, and make t a deterministic function of rand t ( r) and c a deterministic function of t and c( t ) . Fi nally, we assess the dependencies among the unrespon sive variables {g, t (r) , c(t)}, adding arcs from g to t (r) and c(t) under the assumption that the causal mech anisms are conditionally independent given g . The resulting canonical form influence diagram is shown in Figure 2b.\nFrom our construction, it follows that every responsive variable x; has at least one set of causes explicitly en coded in the diagram ( C;). That is, a canonical form\n272 Heckerman and Shachter\n(a) (b)\nFigure 2: (a ) Another influence diagram for the medical-treatment story. (b ) A corresponding influ ence diagram in canonical form.\ninfluence diagram constructed as in Algorithm 1 ac curately represents a set of causes for every variable having a nonempty set of causes. In this sense, we find canonical form to be an adequate representation of cause.\nCanonical form is a generalization of Howard Canon ical Form, which was developed by Howard ( 1990) to facilitate the computation of value of information.\n4.3 Pearl's Causal Theory\nThere is a close relationship between the canoni cal form influence diagram and Pearl's causal theory (Pearl and Verma, 1991; Pearl, 1995). In fact, as we now demonstrate, a causal theory is a special case of canonical form.8\nPearl takes causation to be a primitive notion, and de fines a causal model for variables U to be a directed acyclic graph where each node corresponds to a vari able in U and each nonroot node is caused by its par ents. Each variable in his analysis plays a dual role of chance and decision variable. In particular, a vari able may be observed or directly set to a particular instance. As mentioned, Pearl takes the concept of directly setting a variable to be a primitive.\nGiven a causal model for U, Pearl goes on to define a causal theory for U. Here, we express his definition in the language of influence diagrams. Let M(U) be a causal model for U. Let Pa(x) denote the parents of x in M(U), which by definition are causes for x. A causal theory for U based on M(U), which we denote T(U), is an influence diagram described as follows. For each variable x; E U, i = 1, . . . , n, T(U) contains a corresponding chance variable x; , a set decision i; for\n8We note that Pearl's causal theory and the pseudo indeterministic system of Spirtes et al. (1993} are very similar, and many of the remarks in this section apply to the latter representation as well.\nX;, and a chance variable f;, which Pearl calls a distur bance variable. Furthermore, in the influence diagram T(U), only the chance nodes x; have parents. In par ticular, each x; is a deterministic function of Pa(x;) , i; , and Ei, where (1 ) if i; = k then x; = k, and (2 ) if i; =\"do nothing\" then x = f;[Pa (x;) , E;] for some deterministic function J;. Note that, in a causal the ory, disturbance variables are mutually independent by definition.\nNow, in our framework, suppose we have a set of chance variables U and a corresponding collection of set decisions 0 for U with respect to U. In addi tion, suppose that, for all x;, Pa(x;.) U {i;.} is a set of causes for x; with respect to 0. When we con struct an influence diagram in canonical form as de scribed in Algorithm 1 using an ordering consistent with the causal model M ( U) , we can obtain an influ ence diagram where each variable x; is a determinis tic function of i;, Pa(x; ) , and the causal mechanism x; (Pa (x;) , i;). Given the definition of a set decision, we can simplify each such relationship by writing x; as a deterministic function of i;, Pa( x;) , and the variable x; (Pa (x;) ) , where x;(Pa(x;)) represents the possible mappings from Pa(x;) to x; when i; is set to \"do noth ing.\" If we identify each mapping variable x; (Pa (x;) ) with Pearl's disturbance variable f;, then we obtain an influence diagram identical to the causal theory T(U), with the exception that the mapping variables in this influence diagram may be dependent.9\nThe fact that disturbance variables must be indepen dent in a causal theory does not necessarily limit the expressiveness of a causal theory. Such dependencies often disappear when hidden common causes are in troduced. Furthermore, the assumption that causal mechanisms are independent has the convenient con sequence that the a causal model for U can be inter preted as a Bayesian network in the traditional sense (Spirtes et al., 1993; Pearl, 1995). That is, if variables X and Y are d-separated by Z in the causal model, then X and Y are conditionally independent given Z according to the causal theory.\nNonetheless, the fact that we can use canonical form to represent causes locally-that is, we represent causes only when they are relevant to the decisions at hand makes canonical form a more efficient representation than the causal theory. For example, to represent the relationships in Figure 2b using a causal theory, we would introduce causal-mechanism variables t( r, g) and c ( t, g). Assuming r, g, t and c are binary variables,\n9 At first glance, there appears to be another difference between the two representations. Namely, the disturbance variables in T(U) are assumed to be merely independent of the set decisions 0; whereas, in the canonical form influ ence diagram, the mapping variables are also unresponsive to the set decisions. A careful reading of Pearl's work, how ever, suggests that the disturbance variables must in fact be unresponsive to the set decisions.\nA Definition and Graphical Representation for Causality 273\nbot h m apping v ari ables in the c aus al t heory wo uld h ave 16 inst ances. In contr ast, bot h m apping v ari ables in F ig ure 2b h ave only fo ur inst ances. Conse quently, t he nodes g , t(r, g) and c(t, g) in the c aus al-t heory rep resent ation re quire 3 1 prob abilities in tot al, whereas the nodes g, c(s) , and v(d) in the c anonic al- form rep resent ation re quire only 13 prob abilities in tot al.\n5 Conclusions and Future Work\nWe have presented a precise definition o f c ause and e ffect in terms o f t he more fund ament al notion o f un responsiveness. Our definition dep arts from t he tr adi tion al view o f c aus ation in th at o ur c aus al assertions are m ade rel ative to a set o f decisions. As a conse quence, o ur definition allows for models where only some dependencies h ave a c aus al expl an ation. We have s hown how t hese properties c an m ake t he represen t ation and m anip ul ation o f c aus al rel ations hips more efficient.\nIn addition, we h ave ex amined t he gr aphic al encod ing o f c aus ation. We h ave s hown how the ordin ary infl uence di agr am is in ade quate as a gr ap hic al repre sent ation o f c ause, b ut t hat t he c anonic al form infl u ence di agr am is alw ays an acc ur ate l ang uage for c aus al dependence. Also, we h ave described t he rel ations hip between Pe arl's c aus al t heory and c anonic al form in fluence di agr ams.\nAn import ant aspect o f c aus ality t hat we have b arely to uc hed upon in t his p aper is t he notion o f time . For ex ample, wh at i f o ur altern atives consists o f reactive plans, where observ ations are interspersed wit h ac tions ? More gener ally, wh at h appens w hen system v ari ables ch ange in time ? We will explore these iss ues and others in a se quel to this p aper.\nAcknowledgments\nWe t hank Jack Breese, Tom Ch avez, Max Chicker ing, Eric Horvitz, Ron How ard, Christopher Meek, Jude a Pe arl, Mark Peot, Glenn S hafer, Peter Spirtes, P atrick S uppes, and anonymo us reviewers for use ful comments.\nReferences\n[Dr uzdzel and Simon, 1993 ] Dr uzdzel, M. and Simon, H . ( 1993 ) . C aus ality in B ayesi an belie f networks. In Proceedings of Ninth Conference on Uncertainty in Artificial Intelligence, Was hington, DC, p ages 3 -1 1. Morg an Kaufm ann.\n[Heckerm an, 1995) Heckerm an, D. (1995). A B ayesi an appro ach for le arning c aus al networks. In t his pro ceedings.\n[Heckerm an et al., 1994 ) Heckerm an, D., Breese, J., and Rommelse, K. (1994 ). Se quenti al tro ubleshoot ing under uncert ainty. In Proceedings of Fifth Inter national Workshop on Principles of Diagnosis, New P altz, N Y, p ages 1 2 1-13 0.\n[Heckerm an and S hac hter, 1 994 ) Heckerm an, D . and Sh achter, R. ( 1994 ). A decision-b ased view o f c aus ality. In Proceedings of Tenth Conference on Uncertainty in Artificial Intelligence, Se attle, W A,\np ages 3 02 -3 10. Morg an Kaufm ann.\n[How ard, 1990) How ard, R. ( 1990). From infl uence to relev ance to knowledge. In Oliver , R . and Smith, J . , editors, Influence Diagrams, Belief Nets, and Deci sion Analysis, ch apter 1. Wiley and Sons, New York .\n[How ard and Matheson, 1981) How ard, R. and Mat h eson, J. (1981). In fluence di agr ams. In How ard, R . and Matheson, J ., editors, Readings on the Prin ciples and Applications of Decision Analysis, vol ume I I, p ages 72 1-762. Str ategic Decisions Gro up, Menlo P ark, C A.\n[L auritzen, 1982 ) L auritzen, S. (1982 ). Lectures on Contingency Tables. University o f A alborg Press, A alborg, Denm ark.\n[Lewis, 1978) Lewis, D. ( 1978 ) . Co unter fact ual depen dence and time's arrow. Nous, p ages 4 55-4 76.\n[Pe arl, 1988) Pe arl, J . (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Infer ence. Morg an Kaufm ann, S an Mateo, C A .\n[Pe arl, 1995) Pe arl, J. ( 1995). C aus al di agr ams for em piric al rese arch. Biometrika, to appe ar.\n[Pe arl and Verm a, 1991) Pe arl, J. and Verm a, T. (1991 ) . A t heory o f in ferred c aus ation. In Allen, J., F ikes, R., and S andew all, E., editors, Knowl edge Representation and Reasoning: Proceedings of the Second International Conference, p ages 4 4 1- 4 52. Morg an Kaufm ann, New York.\n[R ubin, 1978) R ubin , D. ( 1978). B ayesi an in ference for c aus al e ffects: T he role o f r andomiz ation. Annals of Statistics, 6:3 4 -58.\n[S av age, 1954 ) S av age, L. ( 1954 ). The Foundations of Statistics. Dover, New York.\n[Spirtes et al ., 1993 ) Spirtes, P., Glymo ur, C., and Sc heines, R. ( 1993 ) . Causation, Prediction, and Search. Springer -Verl ag, New York."}], "references": [{"title": "Heckerm an and S hac hter", "author": ["Heckerm an", "R. Sh achter"], "venue": "In Proceedings of Tenth Conference on Uncertainty in Artificial Intelligence, Se attle, W A, p ages", "citeRegEx": "an et al\\.,? \\Q1994\\E", "shortCiteRegEx": "an et al\\.", "year": 1994}, {"title": "B ayesi an in ference for c aus al e ffects: T he role", "author": ["R ubin", "D. 1978) R ubin"], "venue": null, "citeRegEx": "ubin and ubin,? \\Q1978\\E", "shortCiteRegEx": "ubin and ubin", "year": 1978}], "referenceMentions": [], "year": 2011, "abstractText": "We present a precise definition of ca use and e ffect in terms of a f undamental notion called unresponsiveness. Our definition is based on Savage's (1954 ) form ulation of decision the\u00ad ory and departs from the traditional view of ca usation in that o ur ca usal assertions are made relative to a set of decisions. An im\u00ad portant conseq uence of this depart ure is that we can reason abo ut ca use locally, not re\u00ad q uiring a ca usal explanation for every depen\u00ad dency. S uch local reasoning can be beneficial beca use it may not be necessary to determine whether a partic ular dependency is ca usal to make a decision. Also in this paper, we ex\u00ad amine the graphical encoding of ca usal rela\u00ad tionships. We show that infl uence diagrams in canonical form are an acc urate and effi\u00ad cient representation of ca usal relationships. In addition, we establish a correspondence between canonical form and Pearl's ca usal theory.", "creator": "pdftk 1.41 - www.pdftk.com"}}}