{"id": "1303.5722", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2013", "title": "Time-Dependent Utility and Action Under Uncertainty", "abstract": "townsfolk We discuss representing pasarell and reasoning with 60.72 knowledge about trepang the demens time - mungin dependent spectate utility of an agent ' s actions. Time - dependent utility froglets plays a crucial bellyaching role in decreased the jojohnson interaction slana between tippins computation and aquatics action landsteiner under 42.20 bounded hoketsu resources. We alshehhi present a semantics seghers for israelism time - barrand dependent jackfield utility ap2 and describe precipices the journey use savovic of time - fintor dependent information seaside in 50.08 decision zahf contexts. scoured We illustrate manzer our discussion with examples granja of haggart time - yankel pressured reasoning jennifer in kerrs Protos, a system constructed 516 to jutkiewicz explore ub-6 the cablecast ideal pre-1993 control of braathens inference by reasoners cootehill with ejogo limit abilities.", "histories": [["v1", "Wed, 20 Mar 2013 15:31:01 GMT  (263kb)", "http://arxiv.org/abs/1303.5722v1", "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)"]], "COMMENTS": "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["eric j horvitz", "geoffrey rutledge"], "accepted": false, "id": "1303.5722"}, "pdf": {"name": "1303.5722.pdf", "metadata": {"source": "CRF", "title": "Time-Dependent Utility and Action Under Uncertainty", "authors": ["Eric Horvitz", "Geoffrey Rutledge"], "emails": [], "sections": [{"heading": null, "text": "1 INTRODUCTION\nDecision-theoretic methods have been considered inap plicable for general problem solving because they re quire agents to possess a utility function that provides a preference ordering over outcomes of action, and to have access to a probability distribution over outcomes associated with each decision (Simon et al., 1987). We have investigated methods for maximizing utility in reasoning systems, given limitations in computational abilities and information. In particular, we have ex plored the problem of computing probability distribu tions under resource constraints. To a lesser extent, we have studied the assessment and custom-tailoring of utility models for time-dependent action.\nPerforming inference to determine a probability distri bution can delay an agent's action. Inference-related delays can lead to losses stemming from competition for limited resources, decay of physiological states, and problems with coordination among independent deci sion makers. Endowing an agent with the ability to trade off the accuracy or precision of an analysis for more timely responses can increase the expected value of that agent's behavior. Growing interest and re cent work by several investigators have addressed such tradeoffs in reasoning systems (Doyle, 1988; Horvitz,\n1988; Boddy and Dean, 1989; Russell and Wefald, 1989; Breese and Horvitz, 1990).\nWe constructed the Protos system to experiment with the use of metareasoning procedures to control infer ence approximation methods (Horvitz et al., 1989a). Protos determines the length of time it should dwell on an inference problem before taking action in the world. Protos iteratively computes a myopic estimate of the expected value of computation (EVC) by bal ancing the cost of delay with the benefits expected from additional refinement of the probabilities used in a decision problem. The system makes use of informa tion about the convergence of approximate results to exact answers, and about the time-dependent change of the utility of outcomes.\nWe discuss several aspects of our work on the con sideration of time-dependent utility of outcomes. We review background on the Protos system, describe the semantics and assessment procedures for time dependent utility, and discuss the custom-tailoring of default time-dependent utility models given observa tions. Finally, we describe the operation of Protos by presenting examples of the system's behavior.\n2 A LIMITED REASONER\nDetermining the expected value of alternate actions under uncertainty requires the assignment of belief, p(HJE,\ufffd), to one or more relevant hypotheses, H, given observations, E, and background information, \ufffd- Inference approximation algorithms produce partial results in the form of bounds or second-order probabil ity distributions on relevant probabilities. Let us refer to relevant probabilities as rj;. If we are forced to act immediately, we should take an action D that max imizes our expected utility, given the mean of p(rj;), < p(rj;) > (Howard, 1970). The utility of this action is equal to the utility of the decision we would make had belief in q, been a point probability at the mean of p(rj;). That is,\narg maxu(D, p(rj;)) = arg maxu(D, <p(r/;)>) D D\n152 Horvitz and Rutledge\nObservations\nValue-of \u00b7computation metareasoner\nInference base\nProblem-specific decision model\nFigure 1: Protos' four components include (1) a metar easoner that considers the benefits of continuing to compute, (2) an inference base containing probabilistic inference procedures, (3) belief networks representing domain domain; and ( 4) a problem-specific decision model. Inference and time-dependent utility depend on observations.\nAdditional computation can tighten a second-order distribution. However, the utility of outcomes can di minish with time. Thus, there is a tradeoff between the benefits of making a decision based on a more pre cise result and the costs associated with delay. An EVC analysis compares the expected utility of instan taneous action with the expected utility of action that might be taken following future computation, includ ing the costs of that computation.\nAn exact EVC analysis can consume a significant por tion of the total computational cost of solving an in ference problem. Our investigation on the control of belief-network inference has focused on the use of tractable EVC approximations. Approximate EVC analyses include single-step or myopic analyses. In my opic analyses, the EVC is computed under the assump tion that an agent will take an action in the world after reasoning for a predetermined increment of time; we undertake a myopic analysis to determine if additional analysis is more valuable than immediate action. One approach to computing the expected utility delaying action is to consider the set of second-order distribu tions expected with additional computation. For each feasible future distribution, we consider the value of the best action, given that distribution, and weight that utility by the probability of the future distribu tion.\nProtos makes use of myopic EVC analyses. Protos has four major components, pictured schematically in Figure 1: (1) a metareasoner; (2) an inference base containing inference procedures; (3) a domain-specific knowledge base in the form of belief networks; and ( 4) a problem-specific decision model. At run time,\na decision problem containing alternate actions, out comes, and utilities is passed to Protos. Given a de cision problem, Protos initiates an iterative cycle of reasoning and metareasoning. Object-level inference is interleaved with metareasoning about the value of continuing to perform additional inference.\nAt the start of each cycle, Protos computes the EVC associated with continuing object-level computation for an additional increment of time. If the metarea soner indicates that the EVC associated with the next increment of reasoning is zero or negative computation ceases and the system takes an action indicated by the mean of the second-order probability distribution. De pending on the computational hardware, the structure of the time-dependent utility model, and the expected refinement of the second-order probability distribution by an inference algorithm, Protos may (1) take an im mediate reflex action, (2) dictate a best action after some partial inference, or (3) take an action it proves to be dominant. Decision dominance can be proved before inference is completed with the use of a proba bility bounding algorithm. A decision dominates oth ers when a single action is indicated for the range of probabilities in the interval bordered by an upper and lower bound on the probability.\nWe have experimented with a tractable myopic ap proximation named EVC/BC (for EVC-bounds cate goricaD to control probabilistic bounding. With this form of EVC, we compute the value of tightening categorical upper and lower bounds on a probabil ity. EVC/BC hinges on interpreting upper and lower bounds as a second-order probability distribution. The measure is based on a least-commitment interpretation of bounds as a uniform distribution between the upper and lower bounds, with a mean at the midpoint of the bounds interval. The small amount of time required for the EVC/BC analysis is included in the EVC anal ysis itself. Details about the nature, limitations, and use of EVC/BC are described in (Horvitz, 1990).\nTime-Dependent Utility and Action Under Uncertainty 153\n3 TIME-DEPENDENT UTILITY\nLet us consider the use of Protos to solve time pressured medical problems. We have worked to repre sent in Protos the cost of delaying treatment as a func tion of the time a patient has remained in an untreated acute pathophysiological state. Physicians delivering emergency medical care often rely on knowledge about the cost of delay in treating a patient.\n3.1 Semantics and Representation of Time-Dependency\nIn answer to a query for assistance Protos propa gates observations about a patient's symptomatology through a belief network. The system deliberates about whether to make a treatment recommendation immediately, based on a partial analysis, or to defer its action and to continue inference, given its knowledge about the costs of delay.\nWe represent time-dependent action by considering a continuum of decisions, each defined by initiating an action at a progressively later time, and by assessing the change in utility of the outcome as a function of this time. We use A ;H j, t to refer to an action, A;, taken at time t when state Hj is true. We define t in terms of an initial time, t0, the time a physiological challenge begins. We define the utility of u(A;H j, t) at different times t, with an acute-challenge lottery. To assess the cost of delaying a treatment, we ask a deci sion maker to consider a time-pressured problem that he might face in a decision context. Next, we imagine that there is a treatment that can rid him instantly of the acute affliction with probability 1 -p. Unfortu nately, with probability p, the treatment will kill him, immediately and painlessly. We assume that, if a pa tient wins this lottery, he will continue his life as if the acute incident had not occurred; that is, he faces his preincident future life lottery. To assess the utility, u(A ;Hj, t), at progressively later times t for action, we ask a decision maker for the probability p of instant, painless death that would make him indifferent to ac cepting the uncertain outcome of being treated for an acute illness at time t or having a 1- p chance of con tinuing his life as if the acute incident facing him had never occurred. We take the difference in the probabil ities of death for action at time t and at a later time t' as the loss in utility. We can measure the cost of delay in terms of micromorts. A micromort is a 10-6 chance of immediate, painless death. Alternatively we can assign dollar values to the risks incurred with delay. We can use the worth-numeraire model introduced by Howard (Howard, 1980) to convert small probabilities of death to dollars in terms of dollars per micromort.\nBeyond assessing utilities for each moment of action, we can model the utility of action at progressively later times with functions that encode a micromort flux for each outcome. The micromort flux is the number of\nL------:o--L--\ufffd--=---__;;:::j U(A:fll.to) o f p* p(H\ufffd 1\np(H\ufffdEi.\ufffd) =?\nFigure 3: A graphical representation of the utility of two actions under uncertainty. The lines indicate the utilities of action A1 and action A2 as a function of the probability of hypothesis H1. The lines cross at a threshold probability of hypothesis H1 called p*.\nmicromorts we incur with each second of delay. We experimented with parametric utility equations and found several to be useful for summarizing the time dependency of alternate outcomes. Two functions we used to model losses with time, are the linear and ex ponential forms,\nu(A;Hj, t) = u(A;Hj,to)e-k.t\nu(A;Hj, t) = u(A;Hj,to)-cbt where u(A;Hj,t) 2:0 where ka and Cb are parameter constants derived through fitting a series of micromort assessments to a functional form or are assessed directly. Our language for assessing and representing mathematical models of time-dependence allows decision makers to encode lower bounds on utility over time, and to make state ments about the chaining of sequences of functional forms.\n3.2 Utility of Action in Time-Pressured Contexts\nGiven time-dependent utilities, we can compute the expected value of different actions, A;, in terms of the likelihood of alternative outcomes, Hj. The expected utility (eu) of taking action A; at timet is\nn\neu(A;, t) _L p(Hj JE,\ufffd)u(A;Hi, t) j=l\nConsider the simple case of a binary time-dependent decision problem. We have two states of the world (e.g., diseases) H1 and H2 and two best actions (treat ments) A1 and A2 to address each state. As an exam ple, the states can be the presence and absence of a disease, and the ideal actions can be treating and not treating for the disease. Under uncertainty, we must consider the utilities of four outcomes: u(A2H2, t), u(A1H2,t), u(A1H1,t), and u(A2H1,t). If H1 and H2\n154 Horvitz and Rutledge\neu(A1, t)\neu(A2, t)\np(H1jE, \ufffd) ( u(A1 H1, t) - u(A1H2, t)) +u(A1H2, t) p(HtiE, 0 ( ( u(A2H1, t)- u(A2H2, t)) +u(A2H2,t)\nThe expected utilities of actions A1 and A2, as a func tion of the probability of H1, are graphed in Figure 3. Note that the equations specify the expected utility of two action as lines intersecting at a threshold probabil ity of H1, denoted p\u2022. As we increase the probability of p(Ht) from zero to 1, the decision with the great est expected utility shifts, at p\u2022, from A1 to A2. If we must act immediately, we take an action dictated by the mean of the second-order distribution: We take action At if the mean of the second-order distribution over p(Ht iE, \ufffd) is greater than p\u2022. Otherwise it is best to take action A2.\nA computational agent rarely is forced to act imme diately. An agent can pause to continue inference, or to reflect about the costs and benefits of delaying an action to compute a better decision. The dynamics of reasoning about belief and action under bounded resources is highlighted in Figure 4. The figure shows how the utility of outcome A1 H1, t might diminish with delay. The dashed line shows the expected utility of taking At in the context of H1 at an initial time, i0\u2022 The adjacent solid line indicates the diminished expected utility of taking the action at a later time t, given the truth of H1. Note that, as the utility of taking action A1 falls, the decision threshold, p\u2022, in creases.\nIn a time-pressured computational setting the utility of one or more outcomes decay with delay. At the same time, inferential processes may be underway to refine bounds or a second-order distribution over prob abilities of interest. Figure 4 shows the concurrent tightening of upper and lower bounds by a bounding algorithm. As the utility lines pivot or sweep down at rates dictated by the decay functions for each out come approximate inference continues to tighten the bounds, yielding a time-dependent dynamics of belief and action.\n3.3 Run-Time Modification of Criticality\nMost of the work on Protos has relied on the use of files of utilities assessed for prototypical situations. The utility information is represented in tuples which contain the utility of immediate action, and time de pendent decay, indexed by A;HJ pairs. However, we also have explored the construction of models of time dependent utility. With the modeling approach, we assess utilities that represent preferences for canoni cal situations and apply a mathematical model to cus tomize \"average case\" utilities and time-dependencies to a specific decision maker and situation. To handle time-pressured medical decisions, we elicit from an ex pert decision maker-in our case, an emergency-room physician1-functions that modify the micromort flux of relevant outcomes, in response to arguments of dis crete and real-valued patient vital signs. We experi mented with functions that provide time-dependency parameters as a function of the patient's age, heart rate, blood pressure, and partial pressure of oxygen in the blood (Pa02). In practice, Protos makes use of default time-dependent utility models if no vital signs are observed. Given the observation of vital signs, and the availability of information about the specific class of decision problem, the initial utility and time dependence are customized.\nOur work on customizing time-dependent utility through constructing models of criticality parallels work in the medical decision analysis community on tools for assisting physicians to induce the utility func tions of patients by identifying key features of their personalities (McNeil et a!., 1982; Jimison, 1990). Our experimentation with deterministic functions for mod ifying utility models is a modest initial approach to customizing default time-dependent models. In the general case, modeling the utility of decision makers, such as patients receiving time-critical therapy, is a problem of diagnosis under uncertainty.\n10ne of the authors (G.R.) has served as the source of emergency-medicine expertise.\n'\"'\" l\u2022l\"''l\u2022rollllrlol, '\nTime-Dependent Utility and Action Under Uncertainty 155\nU!rlrltl '\"' rlrl'\" \"' 1\u20221>' rl I \u2022\u202211< <!ron\n..\n\u2022\u2022\n\"' '\ufffd-;\ufffd\ufffd\ufffd\"\ufffd\ufffd\ufffd--\ufffd.\ufffd.-.\ufffd\ufffd\ufffd \u00b7\u00b7 Tl\u2022(--)\n(a) (b)\nFigure 5: Time-dependent inference and ideal action. (a) Protos displays the convergence of the upper and lower bounds (ub, lb) on a probability of interest and the time-dependent decision threshold (p'). The vertical line indicates the time for action. (b) The time-dependent utilities for four possible outcomes.\n4 PROTOS IN ACTION\nWe now examine the behavior of Protos in solving several simplified time-dependent decision problems in medicine. In the examples we determine the ideal time to perform inference with the bounded-conditioning approximation strategy (Horvitz et a!., 1989b), given time-dependent changes in the utility of outcomes.\nBounded conditioning is based on the method of con ditioning (Pearl, 1988). The method works by de composing a belief-network inference problem into a set of simpler, singly connected belief-networks and solving these subproblems in order of their contri bution to upper and lower bounds on a probability of interest. The more subproblems that are solved, the tighter the bounds. We shall examine decisions based on inference with Dxnet and Alarm, multiply connected belief networks that were assessed for rea soning about acute medical problems (Beinlich et al., 1989; Rutledge et a!., 1989) 2 We note that several approximation algorithms and exact algorithms (such as the clique-tree method of Lauritzen and Spiegel halter (Lauritzen and Spiegelhalter, 1988)) can solve inference problems with these networks faster than bounded conditioning can perform a complete anal ysis. However, the incremental and well-characterized convergence of bounds by bounded conditioning gives us the opportunity to explore fundamental interactions between time-dependent belief and utility, and more generally, to develop principles for optimizing the value of actions taken by an agent with limited inferential abilities. Principles of utility-directed control promise to be most valuable for controlling probabilistic infer ence in larger belief networks, such as the evolving QMR-DT network for internal medicine (Shwe et al., 1990).\n2 Alarm is a 37 node belief network; DxNet has 81 nodes.\nFigure 6: Graphical analysis of action. The util ity (crossing solid lines) of treating for hypothesis H1 (Util(A1)) and for H2 (Util(A2)) as a function of the probability of H1. Broken lines indicates the utilities of acting at t0\u2022 The vertical line (p) displays the value of the exact probability, computed after the decision to take action A2 was made.\n4.1 Case Analyses\nFigure 5(a) displays the time-dependent decision threshold, p\u2022 and the convergence of the upper and lower bounds (ub,lb) on a probability computed by bounded-conditioning with the Alarm network. As sume we are employing inference to determine the probability of a life-threatening respiratory pathophys iology (H1), requiring dangerous ventilation therapy, versus a minor acute respiratory reaction that resolves in most cases with minor treatment. We assume that we shall not gather additional information; we shall base our action only on information already collected. A vertical line through the bounds in Figure 5( a) in dicates Protos' decision to halt inference after 20 sec onds. At this time, the EVC becomes nonpositive. Figure 5(b) displays the time-dependent utilities of four outcomes, constructed as the product of actions and states of the world: We treat (A!) or do not treat (A2) the patient with an invasive treatment, and the patient either has (H1) or does not have the severe respiratory problem (H2). The time-dependent p' is a function of the utilities, which were assessed from an expert. In this case, the utility of outcome A1H1 ,t the utility of acting to treat the patient for the severe respiratory problem-decays significantly with delay.\nFigure 6 displays a graph of the utility of actions A1 and A2 at the time action was recommended, as a function of the probability of H1. The broken line, adjacent to the solid utility lines, indicates the util ity of A1 at to, allowing us to inspect the effect that delay has had on the value of the time-dependent out come. The graph displays the upper and lower bounds (ub, lb) at halting time, the mean value between these bounds, and the decision threshold p' at the time Pro tos recommended action A2. The graph also displays the final point probability of H1, computed after the\n156 Horvitz and Rutledge\nthe entire inference problem is solved. The value of the point probability indicates that an instantaneous complete analysis would have recommended the same action. This is not always the case.\nTo demonstrate the sensitivity of Protos' analysis to changes in time-dependent utilities, we consider the same decision problem with a smaller micromort flux for the utility of outcome, A1H1,t. Figure 7(a) displays the convergence of bounds on belief and the trajectory of the decision threshold for the revised problem. The reduced time-dependence of utilities of the outcome are displayed in Figure 7(b). With the revised utility model, which represents a less critical situation, Protos now reasons for 40 seconds before making a recommen dation not to treat for H1. The EVC/BC remains pos itive until the upper bound passes beneath p*, proving the dominance of A2. Figure 7(c) displays graphs of the utilities and bounds at the time action was taken.\nLet us now examine Protos' performance on a car diac decision problem with a focus on the use of de fault and customized utility models. Consider the case where Protos is challenged with recommending action for a patient who suddenly demonstrates extremely low blood pressure and tachycardia (an extremely fast\nheart rate). Assume the problem has been narrowed to two mutually exclusive syndromes: congestive heart failure (H!) and hypovolemia (H2). Hypovolemia is a dangerous state of decreased blood volume caused, for example, by dehydration or bleeding. Congestive heart failure (CHF) is a serious condition in which the pumping ability of the heart is weakened; like hypo volemia, it causes low blood pressure and poor oxy genation of tissues. Although hypovolemia and CHF share salient symptomatology, the treatments for these pathophysiological states conflict with each other. The treatment for hypovolemia (A2) is to give the patient fluids to restore them to a normal level. In contrast, the primary treatment for CHF (AI) is to reduce the quantity of liquids in the body with a diuretic. Er roneously treating a patient who has CHF with fluid replacement therapy, or treating a patient who has hy povolemia with diuretic therapy, is life-threatening.\nIn Protos' default time-dependent utility model for the average case situation, the cost of delaying the treat ment of CHF is described by an exponential decay con stant that is ten times larger than the constant used to characterize the cost of delay in treating hypov olemia. Protos computes the probability of CHF by propagating observations in the Dxnet belief network. Figure S(a) shows a trace of the update of the probabil ity of CHF. Here, Protos is considering a new finding that a patient's pulmonary capillary wedge pressure is normal. (Protos was previously informed that the pa tient displayed low stroke volume and had low central venous pressure.) The vertical line indicates Protos' decision to halt in 115 seconds. At this point, the sys tem recommends that the patient should be treated for CHF. The dominance of this decision is proved when the lower bound crosses the decision threshold p*.\nFor this decision problem the micromort flux assoc iated with delaying treatment for CIIF is represented as a function of the patient's blood pressure. Let us lower the blood pressure and reevaluate the case. In response to a significant drop in blood pressure, Pro tos increases the exponential decay of the value for the outcome of treating for CHF, when CHF is in deed present. In this case, the decay of u(A1H1 ,t) is increased from c\u00b70011 to e- oost Figure S(b) shows the same probabilistic analysis with the use of the re vised time-dependent utility model. Protos now rec ommends that the patient should be treated for CHF after only 30 seconds of computation. In the more crit ical case, action is indicated before a decision threshold is reached because the EVC becomes nonpositive be fore a probability bound crosses the decision threshold.\n4.2 Discussion\nWe have made several observations about Protos' be havior. We have found that, in many cases, a utility directed analysis of probabilistic inference dictates that actions should be taken after a small fraction of\n(\u2022) (b)\nFigure 8: (a) Bounds convergence and decision thresh old for decision dilemma involving treatment for CHF (AI) versus for hypovolemia (A2). (b) Same decision problem with increased decay of the outcome of treat ing for CHF when CHF is present.\nan analysis has been performed. Thus, even approxi mation methods with relatively slow convergence can be more valuable than faster exact algorithms. Two salient examples of this phenomena are displayed in Figure 9. In such cases the ideal decision is determined in the first few seconds of an analysis. More generally, we have found that decisions about the ideal length of time to deliberate and the ideal action to take are sen sitive to the details of the time-dependent utilities of outcomes, the information about the convergence of an approximation strategy, and the trajectory of partial results generated by approximate inference.\nWe have observed behaviors that highlight the com plexity of the interplay between time-dependent utility and time-consuming inferential processes. Some of the behaviors are explained by the limitations associated with the use of a myopic measure of EVC. We found that dependencies between time-dependent utility and inferential processes can make computation time and recommended actions sensitive to small changes in a time-dependent utility model. In some cases small changes in the time-dependencies in a utility model change the ideal recommended action a We found that increasing the time-dependent decay of the utility of an outcome can increase the duration of reflection. In these cases the trajectory of converging bounds sur rounds and \"keeps step\" with an increasing or decreas mg p*. We observed situations where an agent apply ing a myopic EVC estimate may be in the unlucky situation of continuing, for several steps, to observe a positive EVC, yet see its expected utility continue to diminish with delay. We identified cases where the EVC/BC returns to a positive value after it has been zero or negative. Such nonmonotonicity in the EVC motivated us to implement lookahcad analyses that\n. 3Related problems with an optimal decision changing With delay for analysis have been identified previously m the context of decision analysis (McNutt and Pauker, 1987).\nTime-Dependent Utility and Action Under Uncertainty 157\n(\u2022) (b)\nFigure 9: (a) Bounds convergence and decision threshold in the Alarm network for treating possible left-ventricular failure. (b) Bounds convergence and decision threshold in reasoning within the Dxnet be lief network to support a decision about treating for a pulmonary embolism.\nconsider two or more future steps of computation. We are experimenting with more advanced lookahead tech niques. More generally, we are pursuing the develop ment of methods to monitor and modify behavioral patterns that have roots in the myopic EVC evalua tion, and for identifying cases where the results of an analysis are sensitive to small fluctuations in the tra jectory of time-dependent utilities or probabilities.\nBefore concluding, we stress that we have addressed the assignment of belief and utilities by limited agents; we have not discussed the automated construction of decision models. In the current version of Protos, pre constructed decision problems are passed to the sys tem, in reaction to salient observations. We foresee that ongoing work on procedures for constructing de cision models (Wellman, 1988; Breese, 1990; Hecker man and Horvitz, 1990) will foster the development of more comprehensive agents that can build as well as solve decision problems under bounded resources.\n5 SUMMARY\nWe described the assessment and use of time dependent utility in limited computational agents that are charged with taking ideal action in time-critical contexts. Analyses with Protos have demonstrated that the duration of computational analysis and the ideal decisions to make in the world can be sensitive to the time-dependent utilities of relevant outcomes. We discussed the generalization of lottery-based as sessment techniques to mathematical models which represent the decay of utility of outcomes with delay. After describing the problem of customizing the time dependency of default utility models in response to ob servations, we presented examples of Protos' behavior on time-pressured medical decision problems. Finally, we discussed some of Protos' behaviors and described\n158 Horvitz and Rutledge\nongoing work on the development of nonmyopic infer ence monitoring and control procedures.\nAcknowledgments\nThis work was supported by NASA under Grant NCC220-51, by the NSF under Grant IRI-8703710, and by the Palo Alto Laboratory of the Rockwell International Science Center.\nReferences\nBeinlich, I., Suermondt, H., Chavez, R., and Cooper, G. (1989). The ALARM monitoring system: A case study with two probabilistic inference tech niques for belief networks. In Proceedings of the Second European Conference on Artificial In telligence in Medicine, London. Springer Verlag, Berlin.\nBoddy, M. and Dean, T. (1989). Solving timedependent planning problems. In Proceedings of the Eleventh IJCAI. AAAI/International Joint Conferences on Artificial Intelligence.\nBreese, J. ( 1990). Construction of belief and decision networks. Technical Report Technical Memoran dum 30, Rockwell International Science Center, Palo Alto, California.\nBreese, J. and Horvitz, E. (1990). Ideal reformulation of belief networks. In Proceedings of Sixth Con ference on Uncertainty in Artificial Intelligence, Cambridge, MA, pages 64-72.\nDoyle, J. ( 1988). Artificial intelligence and ratio nal self-government. Technical Report CS-88-124, Carnegie-Mellon University.\nHeckerman, D. and Horvitz, E. (1990). Problem for mulation as the reduction of a decision problem. In Proceedings of Sixth Conference on Uncertainty in Artificial Intelligence, Cambridge, MA.\nHorvitz, E. (1988). Reasoning under varying and uncertain resource constraints. In Proceedings AAAI-88 Seventh National Conference on Arti ficial Intelligence, Minneapolis, MN, pages 111- 116. Morgan Kaufmann, San Mateo, CA.\nHorvitz, E. (1990). Computation and Action Under Bounded Resources. PhD thesis, Stanford U ni versity.\nHorvitz, E., Cooper, G., and Heckerman, D. (1989a). Reflection and action under scarce resources: Theoretical principles and empirical study. In Proceedings of the Eleventh IJCAI, pages 1121- 1127. International Joint Conference on Artificial Intelligence.\nHorvitz, E., Suermondt, H., and Cooper, G. (1989b). Bounded conditioning: Flexible inference for de cisions under scarce resources. In Proceedings of\nF ifth Workshop on Uncertainty in Artificial Intel ligence, Windsor, ON, pages 182-193.\nHoward, R. (1970). Decision analysis: Perspectives on inference, decision, and experimentation. Pro ceedings of the IEEE, 58:632-643.\nHoward, R. (1980). On making life and death de cisions. In Howard, R. and Matheson, J., edi tors, Readings on the Principles and Applications of Decision Analysis, volume II, pages 483-506. Strategic Decisions Group, Menlo Park, CA.\nJimison, H. (1990). A Representation for Gaining In sight Into Clinical Decision Models. PhD thesis, Stanford University.\nLauritzen, S. and Spiegelhalter, D. (1988). Local com putations with probabilities on graphical struc tures and their application to expert systems. J. Royal Statistical Society B, 50:157-224.\nMcNeil, B. J., Pauker, S. G., Sox, H. C., and Tver sky, A. (1982). On the elicitation of preferences for alternative therapies. New England Journal of Medicine, 306:1259-62.\nMcNutt, R. and Pauker, S. (1987). Competing rates of risk in a patient with subarachnoid hemorrhage and myocardial infarction: Its now or never. Med ical Decision Making, 7( 4):250-259.\nPearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Mor gan Kaufmann, San Mateo, CA.\nRussell, S. and Wefald, E. H. (1989). Principles of metareasoning. In Brachman, R. J ., Levesque, H. J ., and Reiter, R., editors, Proceedings of the First International Conference on Princi ples of Knowledge Representation and Reasoning, Toronto. Morgan Kaufman.\nRutledge, G., Thomsen, G., Beinlich, I., Farr, B., Kahn, M., Sheiner, L., and Fagan, L. (1989). Ventplan: An architecture for combining quali tative and quantitative computation. In Proceed ings of the Thirteenth SCAMC, Washington, DC. IEEE Computer Society Press, Los Angeles, CA.\nShwe, M., Middleton, B., Heckerman, D., Henrion, M., Horvitz, E., Lehmann, H., and Cooper, G. (1990). A foundation for normative decision making in in ternal medicine: A probabilistic reformulation of QMR. Technical Report KSL-90-09, Knowledge Systems Laboratory, Stanford University.\nSimon, H., Dantzig, G., Hogarth, R., Plott, C., Raiffa, H., Shelling, T., Shepsle, K., Thaler, R., Tversky, A., and Winter, S. (1987). Decision making and problem solving. Interfaces, 17:11-31.\nWellman, M. (1988). Formulation of Tradeoffs in Planning Under Uncertainty. PhD thesis, Mas sachusetts Institute of Technology, Cambridge, MA."}], "references": [{"title": "The ALARM monitoring system: A case study with two probabilistic inference tech\u00ad niques for belief networks", "author": ["I. Beinlich", "H. Suermondt", "R. Chavez", "G. Cooper"], "venue": "In Proceedings of the Second European Conference on Artificial In\u00ad", "citeRegEx": "Beinlich et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Beinlich et al\\.", "year": 1989}, {"title": "Solving timedependent planning problems", "author": ["M. Boddy", "T. Dean"], "venue": "In Proceedings of the Eleventh IJCAI. AAAI/International Joint Conferences on Artificial Intelligence", "citeRegEx": "Boddy and Dean,? \\Q1989\\E", "shortCiteRegEx": "Boddy and Dean", "year": 1989}, {"title": "Construction of belief and decision networks", "author": ["J. Breese"], "venue": "Technical Report Technical Memoran\u00ad dum 30,", "citeRegEx": "Breese,? \\Q1990\\E", "shortCiteRegEx": "Breese", "year": 1990}, {"title": "Ideal reformulation of belief networks", "author": ["J. Breese", "E. Horvitz"], "venue": "In Proceedings of Sixth Con\u00ad ference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Breese and Horvitz,? \\Q1990\\E", "shortCiteRegEx": "Breese and Horvitz", "year": 1990}, {"title": "Artificial intelligence and ratio\u00ad nal self-government", "author": ["J. Doyle"], "venue": "Technical Report CS-88-124,", "citeRegEx": "Doyle,? \\Q1988\\E", "shortCiteRegEx": "Doyle", "year": 1988}, {"title": "Problem for\u00ad mulation as the reduction of a decision problem", "author": ["D. Heckerman", "E. Horvitz"], "venue": "In Proceedings of Sixth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Heckerman and Horvitz,? \\Q1990\\E", "shortCiteRegEx": "Heckerman and Horvitz", "year": 1990}, {"title": "Reasoning under varying and uncertain resource constraints", "author": ["E. Horvitz"], "venue": "Seventh National Conference on Arti\u00ad ficial Intelligence,", "citeRegEx": "Horvitz,? \\Q1988\\E", "shortCiteRegEx": "Horvitz", "year": 1988}, {"title": "Computation and Action Under Bounded Resources", "author": ["E. Horvitz"], "venue": "PhD thesis, Stanford U ni\u00ad versity", "citeRegEx": "Horvitz,? \\Q1990\\E", "shortCiteRegEx": "Horvitz", "year": 1990}, {"title": "Reflection and action under scarce resources: Theoretical principles and empirical study", "author": ["E. Horvitz", "G. Cooper", "D. Heckerman"], "venue": "In Proceedings of the Eleventh IJCAI,", "citeRegEx": "Horvitz et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Horvitz et al\\.", "year": 1989}, {"title": "Bounded conditioning: Flexible inference for de\u00ad cisions under scarce resources", "author": ["E. Horvitz", "H. Suermondt", "G. Cooper"], "venue": null, "citeRegEx": "Horvitz et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Horvitz et al\\.", "year": 1989}, {"title": "Decision analysis: Perspectives on inference, decision, and experimentation", "author": ["R. Howard"], "venue": "Pro\u00ad ceedings of the IEEE,", "citeRegEx": "Howard,? \\Q1970\\E", "shortCiteRegEx": "Howard", "year": 1970}, {"title": "On making life and death de\u00ad cisions", "author": ["R. Howard"], "venue": "Readings on the Principles and Applications of Decision Analysis,", "citeRegEx": "Howard,? \\Q1980\\E", "shortCiteRegEx": "Howard", "year": 1980}, {"title": "A Representation for Gaining In\u00ad sight Into Clinical Decision Models", "author": ["H. Jimison"], "venue": "PhD thesis,", "citeRegEx": "Jimison,? \\Q1990\\E", "shortCiteRegEx": "Jimison", "year": 1990}, {"title": "Local com\u00ad putations with probabilities on graphical struc\u00ad tures and their application to expert systems", "author": ["S. Lauritzen", "D. Spiegelhalter"], "venue": "J. Royal Statistical Society B,", "citeRegEx": "Lauritzen and Spiegelhalter,? \\Q1988\\E", "shortCiteRegEx": "Lauritzen and Spiegelhalter", "year": 1988}, {"title": "On the elicitation of preferences for alternative therapies", "author": ["B.J. McNeil", "S.G. Pauker", "H.C. Sox", "A. Tver\u00ad sky"], "venue": null, "citeRegEx": "McNeil et al\\.,? \\Q1982\\E", "shortCiteRegEx": "McNeil et al\\.", "year": 1982}, {"title": "Competing rates of risk in a patient with subarachnoid hemorrhage and myocardial infarction: Its now or never", "author": ["R. McNutt", "S. Pauker"], "venue": "Med\u00ad ical Decision Making,", "citeRegEx": "McNutt and Pauker,? \\Q1987\\E", "shortCiteRegEx": "McNutt and Pauker", "year": 1987}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Mor\u00ad", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1988\\E", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Principles of metareasoning", "author": ["S. Russell", "E.H. Wefald"], "venue": null, "citeRegEx": "Russell and Wefald,? \\Q1989\\E", "shortCiteRegEx": "Russell and Wefald", "year": 1989}, {"title": "Ventplan: An architecture for combining quali\u00ad tative and quantitative computation", "author": ["G. Rutledge", "G. Thomsen", "I. Beinlich", "B. Farr", "M. Kahn", "L. Sheiner", "L. Fagan"], "venue": "In Proceed\u00ad ings of the Thirteenth SCAMC,", "citeRegEx": "Rutledge et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Rutledge et al\\.", "year": 1989}, {"title": "A foundation for normative decision making in in\u00ad ternal medicine: A probabilistic reformulation of QMR", "author": ["M. Shwe", "B. Middleton", "D. Heckerman", "M. Henrion", "E. Horvitz", "H. Lehmann", "G. Cooper"], "venue": "Technical Report KSL-90-09,", "citeRegEx": "Shwe et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Shwe et al\\.", "year": 1990}, {"title": "Decision making and problem solving", "author": ["H. Simon", "G. Dantzig", "R. Hogarth", "C. Plott", "H. Raiffa", "T. Shelling", "K. Shepsle", "R. Thaler", "A. Tversky", "S. Winter"], "venue": null, "citeRegEx": "Simon et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Simon et al\\.", "year": 1987}, {"title": "Formulation of Tradeoffs in Planning Under Uncertainty", "author": ["M. Wellman"], "venue": "PhD thesis, Mas\u00ad sachusetts Institute of Technology,", "citeRegEx": "Wellman,? \\Q1988\\E", "shortCiteRegEx": "Wellman", "year": 1988}], "referenceMentions": [{"referenceID": 20, "context": "have access to a probability distribution over outcomes associated with each decision (Simon et al., 1987).", "startOffset": 86, "endOffset": 106}, {"referenceID": 10, "context": "If we are forced to act immediately, we should take an action D that max\u00ad imizes our expected utility, given the mean of p(rj;), < p(rj;) > (Howard, 1970).", "startOffset": 140, "endOffset": 154}, {"referenceID": 7, "context": "Details about the nature, limitations, and use of EVC/BC are described in (Horvitz, 1990).", "startOffset": 74, "endOffset": 89}, {"referenceID": 11, "context": "We can use the worth-numeraire model introduced by Howard (Howard, 1980) to convert small probabilities of death to dollars in terms of dollars per micromort.", "startOffset": 58, "endOffset": 72}, {"referenceID": 12, "context": "Our work on customizing time-dependent utility through constructing models of criticality parallels work in the medical decision analysis community on tools for assisting physicians to induce the utility func\u00ad tions of patients by identifying key features of their personalities (McNeil et a!., 1982; Jimison, 1990).", "startOffset": 279, "endOffset": 315}, {"referenceID": 16, "context": "Bounded conditioning is based on the method of con\u00ad ditioning (Pearl, 1988).", "startOffset": 62, "endOffset": 75}, {"referenceID": 0, "context": "We shall examine decisions based on inference with Dxnet and Alarm, multiply connected belief networks that were assessed for rea\u00ad soning about acute medical problems (Beinlich et al., 1989; Rutledge et a!., 1989) 2 We note that several approximation algorithms and exact algorithms (such as the clique-tree method of Lauritzen and Spiegel\u00ad halter (Lauritzen and Spiegelhalter, 1988)) can solve inference problems with these networks faster than bounded conditioning can perform a complete anal\u00ad ysis.", "startOffset": 167, "endOffset": 213}, {"referenceID": 13, "context": ", 1989) 2 We note that several approximation algorithms and exact algorithms (such as the clique-tree method of Lauritzen and Spiegel\u00ad halter (Lauritzen and Spiegelhalter, 1988)) can solve inference problems with these networks faster than bounded conditioning can perform a complete anal\u00ad ysis.", "startOffset": 142, "endOffset": 177}, {"referenceID": 19, "context": "Principles of utility-directed control promise to be most valuable for controlling probabilistic infer\u00ad ence in larger belief networks, such as the evolving QMR-DT network for internal medicine (Shwe et al., 1990).", "startOffset": 194, "endOffset": 213}, {"referenceID": 15, "context": "m the context of decision analysis (McNutt and Pauker, 1987).", "startOffset": 35, "endOffset": 60}, {"referenceID": 21, "context": "We foresee that ongoing work on procedures for constructing de\u00ad cision models (Wellman, 1988; Breese, 1990; Hecker\u00ad man and Horvitz, 1990) will foster the development of more comprehensive agents that can build as well as solve decision problems under bounded resources.", "startOffset": 78, "endOffset": 138}, {"referenceID": 2, "context": "We foresee that ongoing work on procedures for constructing de\u00ad cision models (Wellman, 1988; Breese, 1990; Hecker\u00ad man and Horvitz, 1990) will foster the development of more comprehensive agents that can build as well as solve decision problems under bounded resources.", "startOffset": 78, "endOffset": 138}], "year": 2011, "abstractText": "We discuss representing and reasoning with knowledge about the time-dependent util\u00ad ity of an agent's actions. Time-dependent utility plays a crucial role in the interac\u00ad tion between computation and action under bounded resources. We present a semantics for time-dependent utility and describe the use of time-dependent information in deci\u00ad sion contexts. We illustrate our discussion with examples of time-pressured reasoning in Protos, a system constructed to explore the ideal control of inference by reasoners with limited abilities.", "creator": "pdftk 1.41 - www.pdftk.com"}}}