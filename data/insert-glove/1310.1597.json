{"id": "1310.1597", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Oct-2013", "title": "Cross-lingual Pseudo-Projected Expectation Regularization for Weakly Supervised Learning", "abstract": "We consider leadon a re-chartered multilingual anastasiades weakly supervised rodrick learning sof scenario where darvall knowledge from jihn annotated corpora in a maru resource - mckiernan rich language is transferred blackhouse via cantonese bitext to guide kansakar the learning q\u0101sem\u0101b\u0101d in other poroso languages. Past approaches project 25-run labels across bitext 1988/1989 and steine use bfsb them hoatzin as features shogunal or gold labels directivity for cirque training. durango We propose a daqiao new segen method that agrast projects ibson model atl\u00e1ntico expectations rothschilds rather pacheco than palatine labels, which iwanami facilities bobet transfer blach of stilling model uncertainty across oriel language hubiera boundaries. hiding We encode m67 expectations as wharncliffe constraints payed and sagitta train a discriminative natos CRF zeliff model yevgenyevich using wanga Generalized swayamvaram Expectation Criteria (pla\u00e7a Mann expectantly and everette McCallum, 109.57 2010 ). mhlanga Evaluated on standard kaiser-frazer Chinese - whitelocke English off-seasons and osnabr\u00fcck German - alucitidae English NER datasets, our 06:00 method demonstrates F1 scores hiromitsu of 64% bhrigu and progressio 60% cleadon when no labeled trebonius data is used. marinovi\u0107 Attaining bksh the niekro same riceland accuracy civiletti with supervised dierdre CRFs requires earmarks 12k and 1. augusti 5k gecker labeled martinus sentences. Furthermore, when swaminatha combined tzvika with fetzer labeled examples, 97.26 our grall method yields voyagers significant improvements over lithos state - afl-cio of - chaly the - art supervised methods, stegodon achieving janeway best reported cloer numbers aspatria to mohtar date on 13-23 Chinese OntoNotes 1979-1981 and German CoNLL - 03 andrianov datasets.", "histories": [["v1", "Sun, 6 Oct 2013 16:34:30 GMT  (108kb,D)", "http://arxiv.org/abs/1310.1597v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["mengqiu wang", "christopher d manning"], "accepted": true, "id": "1310.1597"}, "pdf": {"name": "1310.1597.pdf", "metadata": {"source": "CRF", "title": "Cross-lingual Pseudo-Projected Expectation Regularization for Weakly Supervised Learning", "authors": ["Mengqiu Wang", "Christopher D. Manning"], "emails": ["mengqiu@cs.stanford.edu", "manning@cs.stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "Supervised statistical learning methods have enjoyed great popularity in Natural Language Processing (NLP) over the past decade. The success of supervised methods depends heavily upon the availability of large amounts of annotated training data. Manual curation of annotated corpora is a costly and time consuming process. To date, most annotated resources resides within the English language, which\nhinders the adoption of supervised learning methods in many multilingual environments.\nTo minimize the need for annotation, significant progress has been made in developing unsupervised and semi-supervised approaches to NLP (Collins and Singer 1999; Klein 2005; Liang 2005; Smith 2006; Goldberg 2010; inter alia) . More recent paradigms for semi-supervised learning allow modelers to directly encode knowledge about the task and the domain as constraints to guide learning (Chang et al., 2007; Mann and McCallum, 2010; Ganchev et al., 2010). However, in a multilingual setting, coming up with effective constraints require extensive knowledge of the foreign1 language.\nBilingual parallel text (bitext) lends itself as a medium to transfer knowledge from a resource-rich language to a foreign languages. Yarowsky and Ngai (2001) project labels produced by an English tagger to the foreign side of bitext, then use the projected labels to learn a HMM model. More recent work applied the projection-based approach to more language-pairs, and further improved performance through the use of type-level constraints from tag dictionary and feature-rich generative or discriminative models (Das and Petrov, 2011; Ta\u0308ckstro\u0308m et al., 2013).\nIn our work, we propose a new project-based method that differs in two important ways. First, we never explicitly project the labels. Instead, we project expectations over the labels. This pseudo-\n1For experimental purposes, we designate English as the resource-rich language, and other languages of interest as \u201cforeign\u201d. In our experiments, we simulate the resource-poor scenario using Chinese and German, even though in reality these two languages are quite rich in resources.\nar X\niv :1\n31 0.\n15 97\nv1 [\ncs .C\nL ]\n6 O\nct 2\n01 3\nprojection acts as a soft constraint over the labels, which allows us to transfer more information and uncertainty across language boundaries. Secondly, we encode the expectations as constraints and train a model by minimizing divergence between model expectations and projected expectations in a Generalized Expectation (GE) Criteria (Mann and McCallum, 2010) framework.\nWe evaluate our approach on Named Entity Recognition (NER) tasks for English-Chinese and English-German language pairs on standard public datasets. We report results in two settings: a weakly supervised setting where no labeled data or a small amount of labeled data is available, and a semisupervised settings where labeled data is available, but we can gain predictive power by learning from unlabeled bitext."}, {"heading": "2 Related Work", "text": "Most semi-supervised learning approaches embody the principle of learning from constraints. There are two broad categories of constraints: multi-view constraints, and external knowledge constraints.\nExamples of methods that explore multi-view constraints include self-training (Yarowsky, 1995; McClosky et al., 2006),2 co-training (Blum and Mitchell, 1998; Sindhwani et al., 2005), multiview learning (Ando and Zhang, 2005; Carlson et al., 2010), and discriminative and generative model combination (Suzuki and Isozaki, 2008; Druck and McCallum, 2010).\nAn early example of using knowledge as constraints in weakly-supervised learning is the work by Collins and Singer (1999). They showed that the addition of a small set of \u201cseed\u201d rules greatly improve a co-training style unsupervised tagger. Chang et al. (2007) proposed a constraint-driven learning (CODL) framework where constraints are used to guide the selection of best self-labeled examples to be included as additional training data in an iterative EM-style procedure. The kind of constraints used in applications such as NER are the ones like \u201cthe words CA, Australia, NY are LOCATION\u201d (Chang et al., 2007). Notice the similarity of this particu-\n2A multi-view interpretation of self-training is that the selftagged additional data offers new views to learners trained on existing labeled data.\nlar constraint to the kinds of features one would expect to see in a discriminative model such as MaxEnt. The difference is that instead of learning the validity (or weight) of this feature from labeled examples \u2014 since we do not have them \u2014 we can constrain the model using our knowledge of the domain. Druck et al. (2009) also demonstrated that in an active learning setting where annotation budget is limited, it is more efficient to label features than examples. Other sources of knowledge include lexicons and gazetteers (Druck et al., 2007; Chang et al., 2007).\nWhile it is straight-forward to see how resources such as a list of city names can give a lot of mileage in recognizing locations, we are also exposed to the danger of over-committing to hard constraints. For example, it becomes problematic with city names that are ambiguous, such as Augusta, Georgia.3 To soften these constraints, Mann and McCallum (2010) proposed the Generalized Expectation (GE) Criteria framework, which encodes constraints as a regularization term over some score function that measures the divergence between the model\u2019s expectation and the target expectation. The connection between GE and CODL is analogous to the relationship between hard (Viterbi) EM and soft EM, as illustrated by Samdani et al. (2012).\nAnother closely related work is the Posterior Regularization (PR) framework by Ganchev et al. (2010). In fact, as Bellare et al. (2009) have shown, in a discriminative model these two methods optimize exactly the same objective.4 The two differ in optimization details: PR uses a EM algorithm to approximate the gradients which avoids the expensive computation of a covariance matrix between features and constraints, whereas GE directly calculates the gradient. However, later results (Druck, 2011) have shown that using the Expectation Semiring techniques of Li and Eisner (2009), one can compute the exact gradients of GE in a Conditional Random Fields (CRF) (Lafferty et al., 2001) at costs\n3This is a city in the state of Georgia in USA, famous for its golf courses. It is ambiguous since both Augusta and Georgia can also be used as person names.\n4The different terminology employed by GE and PR may be confusing to discerning readers, but the \u201cexpectation\u201d in the context of GE means the same thing as \u201cmarginal posterior\u201d as in PR.\nno greater than computing the gradients of ordinary CRF. And empirically, GE tends to perform more accurately than PR (Bellare et al., 2009; Druck, 2011).\nObtaining appropriate knowledge resources for constructing constraints remain as a bottleneck in applying GE and PR to new languages. However, a number of past work recognizes parallel bitext as a rich source of linguistic constraints, naturally captured in the translations. As a result, bitext has been effectively utilized for unsupervised multilingual grammar induction (Alshawi et al., 2000; Snyder et al., 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al., 2009).\nA number of recent work also explored bilingual constraints in the context of simultaneous bilingual tagging, and showed that enforcing agreements between language pairs give superior results than monolingual tagging (Burkett et al., 2010; Che et al., 2013; Wang et al., 2013). They also demonstrated a uptraining (Petrov et al., 2010) setting where taginduced bitext can be used as additional monolingual training data to improve monolingual taggers. A major drawback of this approach is that it requires a readily-trained tagging models in each languages, which makes a weakly supervised setting infeasible. Another intricacy of this approach is that it only works when the two models have comparable strength, since mutual agreements are enforced between them.\nProjection-based methods can be very effective in weakly-supervised scenarios, as demonstrated by Yarowsky and Ngai (2001), and Xi and Hwa (2005). One problem with projected labels is that they are often too noisy to be directly used as training signals. To mitigate this problem, Das and Petrov (2011) designed a label propagation method to automatically induce a tag lexicon for the foreign language to smooth the projected labels. Fossum and Abney (2005) filter out projection noise by combining projections from from multiple source languages. However, this approach is not always viable since it relies on having parallel bitext from multiple source languages. Li et al. (2012) proposed the use of crowd-sourced Wiktionary as additional resources for inducing tag lexicons. More recently, Ta\u0308ckstro\u0308m et al. (2013) combined token-level and type-level constraints to constrain legitimate label sequences and and recalibrate the probability distri-\nbution in a CRF. The tag dictionary used for POS tagging are analogous to the gazetteers and name lexicons used for NER by Chang et al. (2007).\nOur work is also closely related to Ganchev et al. (2009). They used a two-step projection method similar to Das and Petrov (2011) for dependency parsing. Instead of using the projected linguistic structures as ground truth (Yarowsky and Ngai, 2001), or as features in a generative model (Das and Petrov, 2011), they used them as constraints in a PR framework. Our work differs by projecting expectations rather than Viterbi one-best labels. We also choose the GE framework over PR. Experiments in Bellare et al. (2009) and Druck (2011) suggest that in a discriminative model (like ours), GE is more accurate than PR."}, {"heading": "3 Approach", "text": "Given bitext between English and a foreign language, our goal is to learn a CRF model in the foreign language from little or no labeled data. Our method performs Cross-Lingual Pseudo-Projection Expectation Regularization (CLiPPER).\nFigure 1 illustrates the high-level workflow. For every aligned sentence pair in the bitext, we first compute the posterior marginal at each word position on the English side using a pre-trained English CRF tagger; then for each aligned English word, we project its posterior marginal as expectations to the aligned word position on the foreign side.\nWe would like to learn a CRF model in the foreign language that has similar expectations as the projected expectations from English. To this end, we adopt the Generalized Expectation (GE) Criteria framework introduced by Mann and McCallum (2010). In the remainder of this section, we follow the notation used in (Druck, 2011) to explain our approach."}, {"heading": "3.1 CLiPPER", "text": "The general idea of GE is that we can express our preferences over models through constraint functions. A desired model should satisfy the imposed constraints by matching the expectations on these constraint functions with some target expectations (attained by external knowledge like lexicons or in our case transferred knowledge from English). We\ndefine a constraint function \u03c6i,lj for each word position i and output label assignment lj as a label identity indicator:\n\u03c6i,lj (y) = { 1 if lj = yi and Ai 6= \u2205 0 otherwise\nThe set {l1, \u00b7 \u00b7 \u00b7 , lm} denotes all possible label assignment for each yi, and m is number of label values. Ai is the set of English words aligned to Chinese word i. The condition Ai 6= \u2205 specifies that the constraint function applies only to Chinese word positions that have at least one aligned English word. Each \u03c6i,lj (y) can be treated as a Bernoulli random variable, and we concatenate the set of all \u03c6i,lj into a random vector \u03c6(y), where \u03c6k = \u03c6i,lj if k = i \u2217m+ j. We drop the (y) in \u03c6 for simplicity.\nThe target expectation over \u03c6i,lj , denoted as \u03c6\u0303i,lj , is the expectation of assigning label lj to English word Ai5 under the English conditional probability model.\nThe expectation over \u03c6 under a conditional probability model P (y|x;\u03b8) is denoted as EP (y|x;\u03b8)[\u03c6], and simplified as E\u03b8[\u03c6] whenever it is unambiguous.\nThe conditional probability model P (y|x;\u03b8) in our case is defined as a standard linear-chain CRF:6\nP (y|x;\u03b8) = 1 Z(x;\u03b8) exp ( n\u2211 i \u03b8f(x, yi, yi\u22121) ) 5An English word aligned to foreign word at position i. When multiple English words are aligned to the same foreign word, we average the expectations.\n6We simplify notation by dropping the L2 regularizer in the CRF definition, but apply it in our experiments.\nwhere f is a set of feature functions; \u03b8 are the matching parameters to learn; n = |x|.\nThe objective function to maximize in a standard CRF is the log probability over a collection of labeled documents:\nLCRF (\u03b8) = a\u2032\u2211 a=1 logP (y\u2217a|xa;\u03b8) (1)\na\u2032 is the number of labeled sentences. y\u2217 is an observed label sequence.\nThe objective function to maximize in GE is defined as the sum over all unlabeled examples (foreign side of bitext), over some cost function S between between the model expectation (E\u03b8[\u03c6]) and the target expectation (\u03c6\u0303) over \u03c6.\nWe choose S to be the negative L22 squared error, 7\ndefined as:\nLGE(\u03b8) = n\u2032\u2211 b=1 S ( EP (y|xb;\u03b8)[\u03c6(yb)], \u03c6\u0303(yb )\n= b\u2032\u2211\nb=1\n\u2212\u2016\u03c6\u0303(yb)\u2212 E\u03b8[\u03c6(yb)]\u201622 (2)\nb\u2032 is the total number of unlabeled bitext sentence pairs.\nWhen both labeled and bitext training data are available, the joint objective is the sum of Eqn. 1 and 2. Each is computed over the labeled training data and foreign half in the bitext, respectively.\n7In general, other loss functions such as KL-divergence can also be used for S. We found L22 to work well in practice.\nWe can optimize this joint objective by computing the gradients and use a gradient-based optimization method such as L-BFGS. Gradients of LCRF decomposes down to the gradients over each labeled training example (x,y\u2217), computed as:\n\u2202\n\u2202\u03b8 (logP (y\u2217a|xa;\u03b8) = E\u0303[\u03b8]\u2212 E[\u03b8]\nwhere E\u0303[\u03b8] and E[\u03b8] are the empirical and expected feature counts, respectively.\nComputing the gradient of LGE decomposes down to the gradients of S(EP (y|xb;\u03b8[\u03c6]) for each unlabeled foreign sentence x and the constraints over this example \u03c6 . The gradients can be calculated as:\n\u2202\n\u2202\u03b8 S(E\u03b8[\u03c6]) = \u2212\n\u2202\n\u2202\u03b8\n( \u03c6\u0303\u2212 E\u03b8[\u03c6] )T ( \u03c6\u0303\u2212 E\u03b8[\u03c6] ) = 2 ( \u03c6\u0303\u2212 E\u03b8[\u03c6] )T ( \u2202 \u2202\u03b8 E\u03b8[\u03c6] )\nWe redefine the penalty vector u = 2 ( \u03c6\u0303\u2212 E\u03b8[\u03c6] ) to be u. \u2202\u2202\u03b8E\u03b8[\u03c6] is a matrix where each column contains the gradients for a particular model feature \u03b8 with respect to all constraint functions \u03c6. It can be computed as:\n\u2202\n\u2202\u03b8 E\u03b8[\u03c6] = \u2211 y \u03c6(y) \u2202 \u2202\u03b8 P (y|x;\u03b8)\n= \u2211 y \u03c6(y) \u2202 \u2202\u03b8 ( 1 Z(x;\u03b8) exp(\u03b8T f(x,y)) )\n= \u2211 y \u03c6(y)\n( 1\nZ(x;\u03b8)\n( \u2202\n\u2202\u03b8 exp(\u03b8T f(x,y))\n)\n+ exp(\u03b8T f(x,y))\n( \u2202\n\u2202\u03b8\n1\nZ(x;\u03b8)\n))\n= \u2211 y \u03c6(y) ( P (y|x;\u03b8)f(x,y)T\n\u2212 P (y|x;\u03b8) \u2211 y\u2032 P (y\u2032|x;\u03b8)f(x,y\u2032)T )\n= \u2211 y P (y|x;\u03b8) \u2211 y \u03c6(y)f(x,y)T\n\u2212 (\u2211\ny\nP (y|x;\u03b8)\u03c6(y) )(\u2211\ny\nP (y|x;\u03b8)f(x,y)T )\n= COVP (y|x;\u03b8) (\u03c6(y), f(x,y)) (3) = E\u03b8[\u03c6f T ]\u2212 E\u03b8[\u03c6]E\u03b8[fT ] (4)\nEqn. 3 gives the intuition of how optimization works in GE. In each iteration of L-BFGS, the model parameters are updated according to their covariance with the constraint features, scaled by the difference between current expectation and target expectation. The term E\u03b8[\u03c6fT ] in Eqn. 4 can be computed using a dynamic programming (DP) algorithm, but solving it directly requires us to store a matrix of the same dimension as fT in each step of the DP. We can reduce the complexity by using the following trick:\n\u2202\n\u2202\u03b8 S(E\u03b8[\u03c6]) = u\nT\n( \u2202\n\u2202\u03b8 E\u03b8[\u03c6] ) =uT ( E\u03b8[\u03c6f T ]\u2212 E\u03b8[\u03c6]E\u03b8[fT ] )\n=E\u03b8[u T\u03c6fT ]\u2212 E\u03b8[uT\u03c6]E\u03b8[fT ] =E\u03b8[\u03c6 \u2032fT ]\u2212 E\u03b8[\u03c6\u2032]E\u03b8[fT ] (5)\n\u03c6\u2032 = uT\u03c6\nNow in Eqn. 5, E\u03b8[\u03c6\u2032] becomes a scalar value; and to compute the termE\u03b8[\u03c6\u2032fT ], we only need to store a vector in each step of the following DP algorithm (Druck, 2011, 93):\nE\u03b8[\u03c6 \u2032fT ] = n\u2211 i=1 \u2211 yi \u2211 yi+1 {[ n\u2211 j=1 \u2211 yj P (yi, yi+1, yj |x)\n\u00b7 \u03c6(yj) ] \u00b7 f(yi, yi+1,x)T }\nThe bracketed term can be broken down to two parts:\nn\u2211 j=1 \u2211 yj P (yi, yi+1, yj |x)\u03c6(yj)\n= i\u2211\nj=1 \u2211 yj P (yi, yi+1, yj |x)\u03c6(yj)\n+ n\u2211\nj=i+1 \u2211 yj P (yi, yi+1, yj |x)\u03c6(yj)\n= \u03b1(yi, yi+1, i) + \u03b2(yi, yi+1, i)\n\u03b1(y0, y1, 0) \u2261 P (y0, y1|x)\u03c6(y0) \u03b1(yi, yi+1, i) \u2261 P (yi, yi+1|x)\u03c6(yi)+\nP (yi+1|yi,x) \u2211 yi\u22121 \u03b1(yi\u22121, yi, i\u2212 1)\n\u03b2(yn\u22121, yn, n\u2212 1) \u2261 P (yn\u22121, yn|x)\u03c6(yn) \u03b2(yi, yi+1, i) \u2261 P (yi, yi+1|x)\u03c6(yi+1)+\nP (yi|yi+1,x) \u2211 yi+2 \u03b2(yi+1, yi+2, i+ 1)\nThe resulting algorithm has complexity O(nm2), which is the same as the standard forward-backward inference algorithm for CRF."}, {"heading": "3.2 Hard vs. Soft Projection", "text": "Projecting expectations instead of one-best label assignments from English to foreign language can be thought of as a soft version of the method described in (Das and Petrov, 2011) and (Ganchev et al., 2009). Soft projection has its advantage: when the English model is not certain about its predictions, we do not have to commit to the current best prediction. The foreign model has more freedom to form its own belief since any marginal distribution it produces would deviates from a flat distribution by just about the same amount. In general, preserving uncertainties till later is a strategy that has benefited many NLP tasks (Finkel et al., 2006). Hard projection can also be treated as a special case in our framework. We can simply recalibrate posterior marginal of English by assigning probability mass 1 to the most likely outcome, and zero everything else out, effectively taking the argmax of\nthe marginal at each word position. We refer to\nthis version of expectation as the \u201chard\u201d expectation. In the hard projection setting, GE training resembles a \u201cproject-then-train\u201d style semi-supervised CRF training scheme (Yarowsky and Ngai, 2001; Ta\u0308ckstro\u0308m et al., 2013). In such a training scheme, we project the one-best predictions of English CRF to the foreign side through word alignments, then include the newly \u201ctagged\u201d foreign data as additional training data to a standard CRF in the foreign language. The difference between GE training and this scheme is that they optimize different objectives: CRF optimizes maximum conditional likelihood of the observed label sequence, whereas GE minimizes squared error between model\u2019s expectation and \u201chard\u201d expectation based on the observed label sequence. We compare the hard and soft variants of GE with the project-then-train style CRF training in our experiments and report results in Section 4.2."}, {"heading": "4 Experiments", "text": "We conduct experiments on Chinese and German NER. We evaluate CLiPPER in two learning settings: weakly supervised and semi-supervised. In the weakly supervised setting, we simulate the condition of having no labeled training data, and evaluate the model learned from bitext alone. We then vary the amount of labeled data available to the model, and examine the model\u2019s learning curve. In the semi-supervised setting, we assume our model has access to the full labeled data; our goal is to improve performance of the supervised method by learning from additional bitext."}, {"heading": "4.1 Dataset and Setup", "text": "We used the latest version of Stanford NER Toolkit8 as our base CRF model in all experiments. Features for English, Chinese and German CRFs are documented extensively in (Che et al., 2013) and (Faruqui and Pado\u0301, 2010) and omitted here for brevity. It it worth noting that the current Stanford NER models include recent improvements from semi-supervise learning approaches that induces distributional similarity features from large word clusters. These models represent the current state-ofthe-art in supervised methods, and serve as a very\n8http://www-nlp.stanford.edu/ner\nstrong baseline. For Chinese NER experiments, we follow the same setup as Che et al. (2013) to evaluate on the latest OntoNotes (v4.0) corpus (Hovy et al., 2006).9 A total of 8,249 sentences from the parallel Chinese and English Penn Treebank portion 10 are reserved for evaluation. Odd-numbered documents are used as development set, and even-numbered documents are held out as blind test set. The rest of OntoNotes annotated with NER tags are used to train the English and Chinese CRF base taggers. There are about 16k and 39k labeled sentences for Chinese and English training, respectively. The English CRF tagger trained on this training corpus gives F1 score of 81.68% on the OntoNotes test set. Four entities types (PERSON, LOCATION, ORGANIZATION and GPE) are used with a BO tagging scheme. The English-Chinese bitext comes from the Foreign Broadcast Information Service corpus (FBIS).11 It is first sentence aligned using the Champollion Tool Kit,12 then word aligned with the BerkeleyAligner.13\nFor German NER experiments, we evaluate using the standard CoNLL-03 NER corpus (Sang and Meulder, 2003). The labeled training set has 12k and 15k sentences. We used the de-en portion of the News Commentary14 data from WMT13 as bitext. The English CRF tagger trained on CoNLL-03 English training corpus gives F1 score of 90.4% on the CoNLL-03 test set.\nWe report standard entity-level precision (P), recall (R) and F1 score given by CONLLEVAL script on both the development and test sets. Statistical significance tests are done using a paired bootstrap resampling method with 1000 iterations, averaged over 5 runs. We compare against three recently approaches that were introduced in Section 2. They are: semi-supervised learning method using factored bilingual models with Gibbs sampling (Wang et al., 2013); bilingual NER using Integer Linear Programming (ILP) with bilingual constraints, by (Che et al., 2013); and constraint-driven bilingual-reranking ap-\n9LDC catalogue No.: LDC2011T03 10File numbers: chtb 0001-0325, ectb 1001-1078 11LDC catalogue No.: LDC2003E14 12champollion.sourceforge.net 13code.google.com/p/berkeleyaligner 14http://www.statmt.org/wmt13/\ntraining-parallel-nc-v8.tgz\nproach (Burkett et al., 2010). The code from (Che et al., 2013) and (Wang et al., 2013) are publicly available,15. Code from (Burkett et al., 2010) is obtained through personal communications.16\nSince the objective function in Eqn. 2 is nonconvex, we adopted the early stopping training scheme from (Turian et al., 2010) as the following: after each iteration in L-BFGS training, the model is evaluated against the development set; the training procedure is terminated if no improvements have been made in 20 iterations."}, {"heading": "4.2 Weakly Supervised Results", "text": "The top four figures in Figure 2 show results of weakly supervised learning experiments. Quite remarkably, on Chinese test set, our proposed method (CLiPPER) achieves a F1 score of 64.4% with 80k bitext, when no labeled training data is used. In contrast, the supervised CRF baseline would require as much as 12k labeled sentences to attain the same accuracy. Results on the German test set is less striking. With no labeled data and 40k of bitext, CLiPPER performs at F1 of 60.0%, the equivalent of using 1.5k labeled examples in the supervised setting. When combined with 1k labeled examples, performance of CLiPPER reaches 69%, a gain of over 5% absolute over supervised CRF. We also notice that supervised CRF model learns much faster in German than Chinese. This result is not too surprising, since it is well recognized that Chinese NER is more challenging than German or English due to the lack of orthographical features, such as word capitalization. Chinese NER relies more on lexicalized features, and therefore needs more labeled data to achieve good coverage. The results also suggest that CLiPPER seems to be very effective at transferring lexical knowledge from English to Chinese.\nThe bottom two figures in Figure 2 compares soft GE projection with hard GE projection and the \u201cproject-then-train\u201d style CRF training scheme (cf. Section 3.2). We observe that both soft and hard GE projection significantly outperform the \u201cprojectthen-train\u201d style training scheme. The difference is especially pronounced on the Chinese results when\n15https://github.com/stanfordnlp/CoreNLP 16Due to technical difficulties, we are unable to replicate Burkett et al. (2010) experiments on German NER, therefore only Chinese results are reported.\nfewer labeled examples are available. Soft projection gives better accuracy than hard projection when no labeled data is available, and also has a faster learning rate."}, {"heading": "4.3 Semi-supervised Results", "text": "In the semi-supervised experiments, we let the CRF model use the full set of labeled examples in addition to the unlabeled bitext. Table 1 shows results on the development dataset for Chinese and German using 10-80k bitext. We see that with merely 10k additional bitext, CLiPPER is able to improve significantly over state-of-the-art CRF baselines by as much as 1.5% F1 on both Chinese and German. With more unlabeled data, we notice a tradeoff between precision and recall on Chinese. The final F1 score on Chinese at 80k level is only marginally better than 10k. On the other hand, we observe a modest but steady improvement on German as we add more unlabeled bitext, up until 40k sentences. We select the best configurations on development set (80k for Chinese and 40k for German) to evaluate on test set.\nResults on the test set are shown in Table 2. All semi-supervised baselines are tested with the same number of unlabeled bitext as CLiPPER in each language. The \u201cproject-then-train\u201d semi-supervised training scheme severely hurts performance on Chinese, but gives a small improvement on German. Moreover, on Chinese it learns to achieve high precision but at a significant loss in recall. On German its behavior is the opposite. Such drastic and erratic imbalance suggest that this method is not robust or reliable. The other three semi-supervised\nbaselines (row 3-5) all show improvements over the CRF baseline, consistent with their reported results. CLIPPERs gives the best results on both Chinese and German, yielding statistically significant improvements over all baselines except for CWD13 on German. The hard projection version of CLiPPER also gives sizable gain over CRF. However, in comparison, CLIPPERs is superior.\nThe improvements of CLIPPERs over CRF on Chinese test set is over 2.8% in absolute F1. The improvement over CRF on German is almost a percent. To our knowledge, these are the best reported numbers on the OntoNotes Chinese and CoNLL-03 German datasets."}, {"heading": "4.4 Efficiency", "text": "Another advantage of our proposed approach is efficiency. Because we eliminated the previous multistage \u201cproject-then-train\u201d paradigm, but instead integrating the semi-supervised and supervised objective into one joint objective, we are able to attain significant speed improvements. Table 3 shows the training time required to produce models that give\nresults in Table 2."}, {"heading": "5 Error Analysis and Discussion", "text": "Figure 3 gives two examples of CLiPPER in action. Both examples have a named entity that immediately proceeds the word \u201c\u7eaa\u5ff5\u7891\u201d (monument) in the Chinese sentence. In Figure 3a, the word \u201c\u9ad8 \u5c97\u201d has literal meaning of a hillock located at a high position, which also happens to be the name of a former vice president of China. Without having previously observed this word as a person name in the labeled training data, the CRF model does not have enough evidence to believe that this is a PERSON, instead of LOCATION. But the aligned words in English (\u201cGao Gang\u201d) are clearly part of a person name as they were preceded by a title (\u201cVice President\u201d). The English model has high expectation that the aligned Chinese word of \u201dGao Gang\u201d is also a PERSON. Therefore, projecting the English expec-\ntations to Chinese provides a strong clue to help disambiguating this word. Figure 3b gives another example: the word \u201c\u9ec4\u6cb3\u201d(Huang He, the Yellow River of China) can be confused with a person name since \u201c\u9ec4\u201d(Huang or Hwang) is also a common Chinese last name.17. Again, knowing the translation in English, which has the indicative word \u201cRiver\u201d in it, helps disambiguation."}, {"heading": "6 Conclusion", "text": "We introduced a domain and language independent semi-supervised method for training discriminative models by projecting expectations across bitext. Experiments on Chinese and German NER show that our method, learned over bitext alone, can rival performance of supervised models trained with thousands of labeled examples. Furthermore, applying our method in a setting where all labeled examples are available also shows improvements over state-ofthe-art supervised methods. Our experiments also showed that soft expectation projection is more favorable to hard projection. This technique can be generalized to all sequence labeling tasks, and can be extended to include more complex constraints. For future work, we plan to apply this method to more language pairs and examine the formal properties of the model.\n17In fact, a people search of the name \u9ec4\u6cb3 on the Chinese equivalent of Facebook (www.renren.com) returns over 13,000 matches."}], "references": [{"title": "Head-transducer models for speech translation and their automatic acquisition from bilingual data", "author": ["Hiyan Alshawi", "Srinivas Bangalore", "Shona Douglas."], "venue": "Machine Translation, 15.", "citeRegEx": "Alshawi et al\\.,? 2000", "shortCiteRegEx": "Alshawi et al\\.", "year": 2000}, {"title": "A highperformance semi-supervised learning method for text chunking", "author": ["Rie Kubota Ando", "Tong Zhang."], "venue": "Proceedings of ACL.", "citeRegEx": "Ando and Zhang.,? 2005", "shortCiteRegEx": "Ando and Zhang.", "year": 2005}, {"title": "Alternating projections for learning with expectation constraints", "author": ["Kedar Bellare", "Gregory Druck", "Andrew McCallum."], "venue": "Proceedings of UAI.", "citeRegEx": "Bellare et al\\.,? 2009", "shortCiteRegEx": "Bellare et al\\.", "year": 2009}, {"title": "Combining labeled and unlabeled data with co-training", "author": ["Avrim Blum", "Tom Mitchell."], "venue": "Proceedings of COLT.", "citeRegEx": "Blum and Mitchell.,? 1998", "shortCiteRegEx": "Blum and Mitchell.", "year": 1998}, {"title": "Two languages are better than one (for syntactic parsing)", "author": ["David Burkett", "Dan Klein."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Burkett and Klein.,? 2008", "shortCiteRegEx": "Burkett and Klein.", "year": 2008}, {"title": "Learning better monolingual models with unannotated bilingual text", "author": ["David Burkett", "Slav Petrov", "John Blitzer", "Dan Klein."], "venue": "Proceedings of CoNLL.", "citeRegEx": "Burkett et al\\.,? 2010", "shortCiteRegEx": "Burkett et al\\.", "year": 2010}, {"title": "Coupled semi-supervised learning for information extraction", "author": ["Andrew Carlson", "Justin Betteridge", "Richard C. Wang", "Estevam R. Hruschka Jr.", "Tom M. Mitchell."], "venue": "Proceedings of WSDM.", "citeRegEx": "Carlson et al\\.,? 2010", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "Guiding semi-supervision with constraintdriven learning", "author": ["Ming-Wei Chang", "Lev Ratinov", "Dan Roth."], "venue": "Proceedings of ACL.", "citeRegEx": "Chang et al\\.,? 2007", "shortCiteRegEx": "Chang et al\\.", "year": 2007}, {"title": "Named entity recognition with bilingual constraints", "author": ["Wanxiang Che", "Mengqiu Wang", "Christopher D. Manning."], "venue": "Proceedings of NAACL.", "citeRegEx": "Che et al\\.,? 2013", "shortCiteRegEx": "Che et al\\.", "year": 2013}, {"title": "Unsupervised models for named entity classification", "author": ["Michael Collins", "Yoram Singer."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Collins and Singer.,? 1999", "shortCiteRegEx": "Collins and Singer.", "year": 1999}, {"title": "Unsupervised partof-speech tagging with bilingual graph-based projections", "author": ["Dipanjan Das", "Slav Petrov."], "venue": "Proceedings of ACL.", "citeRegEx": "Das and Petrov.,? 2011", "shortCiteRegEx": "Das and Petrov.", "year": 2011}, {"title": "Highperformance semi-supervised learning using discriminatively constrained generative models", "author": ["Gregory Druck", "Andrew McCallum."], "venue": "Proceedings of ICML.", "citeRegEx": "Druck and McCallum.,? 2010", "shortCiteRegEx": "Druck and McCallum.", "year": 2010}, {"title": "Leveraging existing resources using generalized expectation criteria", "author": ["Gregory Druck", "Gideon Mann", "Andrew McCallum."], "venue": "Proceedings of NIPS Workshop on Learning Problem Design.", "citeRegEx": "Druck et al\\.,? 2007", "shortCiteRegEx": "Druck et al\\.", "year": 2007}, {"title": "Active learning by labeling features", "author": ["Gregory Druck", "Burr Settles", "Andrew McCallum."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Druck et al\\.,? 2009", "shortCiteRegEx": "Druck et al\\.", "year": 2009}, {"title": "Generalized Expectation Criteria for Lightly Supervised Learning", "author": ["Gregory Druck."], "venue": "Ph.D. thesis, University of Massachusetts Amherst.", "citeRegEx": "Druck.,? 2011", "shortCiteRegEx": "Druck.", "year": 2011}, {"title": "Training and evaluating a German named entity recognizer with semantic generalization", "author": ["Manaal Faruqui", "Sebastian Pad\u00f3."], "venue": "Proceedings of KONVENS.", "citeRegEx": "Faruqui and Pad\u00f3.,? 2010", "shortCiteRegEx": "Faruqui and Pad\u00f3.", "year": 2010}, {"title": "Solving the problem of cascading errors: Approximate bayesian inference for linguistic annotation pipelines", "author": ["Jenny Rose Finkel", "Christopher D. Manning", "Andrew Y. Ng."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Finkel et al\\.,? 2006", "shortCiteRegEx": "Finkel et al\\.", "year": 2006}, {"title": "Automatically inducing a part-of-speech tagger by projecting from multiple source languages across aligned corpora", "author": ["Victoria Fossum", "Steven Abney."], "venue": "Proceedings of IJCNLP.", "citeRegEx": "Fossum and Abney.,? 2005", "shortCiteRegEx": "Fossum and Abney.", "year": 2005}, {"title": "Dependency grammar induction via bitext projection constraints", "author": ["Kuzman Ganchev", "Jennifer Gillenwater", "Ben Taskar."], "venue": "Proceedings of ACL.", "citeRegEx": "Ganchev et al\\.,? 2009", "shortCiteRegEx": "Ganchev et al\\.", "year": 2009}, {"title": "Posterior regularization for structured latent variable models", "author": ["Kuzman Ganchev", "Jo ao Gra\u00e7a", "Jennifer Gillenwater", "Ben Taskar."], "venue": "JMLR, 10:2001\u20132049.", "citeRegEx": "Ganchev et al\\.,? 2010", "shortCiteRegEx": "Ganchev et al\\.", "year": 2010}, {"title": "New Directions in Semisupervised Learning", "author": ["Andrew B. Goldberg."], "venue": "Ph.D. thesis, University of Wisconsin-Madison.", "citeRegEx": "Goldberg.,? 2010", "shortCiteRegEx": "Goldberg.", "year": 2010}, {"title": "OntoNotes: the 90% solution", "author": ["Eduard Hovy", "Mitchell Marcus", "Martha Palmer", "Lance Ramshaw", "Ralph Weischedel."], "venue": "Proceedings of NAACL-HLT.", "citeRegEx": "Hovy et al\\.,? 2006", "shortCiteRegEx": "Hovy et al\\.", "year": 2006}, {"title": "The Unsupervised Learning of Natural Language Structure", "author": ["Dan Klein."], "venue": "Ph.D. thesis, Stanford University.", "citeRegEx": "Klein.,? 2005", "shortCiteRegEx": "Klein.", "year": 2005}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John D. Lafferty", "Andrew McCallum", "Fernando C.N. Pereira."], "venue": "Proceedings of ICML.", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "First- and second-order expectation semirings with applications to minimumrisk training on translation forests", "author": ["Zhifei Li", "Jason Eisner."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Li and Eisner.,? 2009", "shortCiteRegEx": "Li and Eisner.", "year": 2009}, {"title": "Wiki-ly supervised part-of-speech tagging", "author": ["Shen Li", "Jo ao Gra\u00e7a", "Ben Taskar."], "venue": "Proceedings of EMNLP-CoNLL.", "citeRegEx": "Li et al\\.,? 2012", "shortCiteRegEx": "Li et al\\.", "year": 2012}, {"title": "Semi-supervised learning for natural language", "author": ["Percy Liang."], "venue": "Master\u2019s thesis, Massachusetts Institute of Technology.", "citeRegEx": "Liang.,? 2005", "shortCiteRegEx": "Liang.", "year": 2005}, {"title": "Generalized expectation criteria for semi-supervised learning with weakly labeled data", "author": ["Gideon Mann", "Andrew McCallum."], "venue": "JMLR, 11:955\u2013984.", "citeRegEx": "Mann and McCallum.,? 2010", "shortCiteRegEx": "Mann and McCallum.", "year": 2010}, {"title": "Effective self-training for parsing", "author": ["David McClosky", "Eugene Charniak", "Mark Johnson."], "venue": "Proceedings of NAACL-HLT.", "citeRegEx": "McClosky et al\\.,? 2006", "shortCiteRegEx": "McClosky et al\\.", "year": 2006}, {"title": "Multilingual part-ofspeech tagging: Two unsupervised approaches", "author": ["Tahira Naseem", "Benjamin Snyder", "Jacob Eisenstein", "Regina Barzilay."], "venue": "JAIR, 36:1076\u20139757.", "citeRegEx": "Naseem et al\\.,? 2009", "shortCiteRegEx": "Naseem et al\\.", "year": 2009}, {"title": "Uptraining for accurate deterministic question parsing", "author": ["Slav Petrov", "Pi-Chuan Chang", "Michael Ringgaard", "Hiyan Alshawi."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Petrov et al\\.,? 2010", "shortCiteRegEx": "Petrov et al\\.", "year": 2010}, {"title": "Unified expectation maximization", "author": ["Rajhans Samdani", "Ming-Wei Chang", "Dan Roth."], "venue": "Proceedings of NAACL.", "citeRegEx": "Samdani et al\\.,? 2012", "shortCiteRegEx": "Samdani et al\\.", "year": 2012}, {"title": "Introduction to the CoNLL-2003 shared task: languageindependent named entity recognition", "author": ["Erik F. Tjong Kim Sang", "Fien De Meulder."], "venue": "Proceedings of CoNLL.", "citeRegEx": "Sang and Meulder.,? 2003", "shortCiteRegEx": "Sang and Meulder.", "year": 2003}, {"title": "A co-regularization approach to semisupervised learning with multiple views", "author": ["Vikas Sindhwani", "Partha Niyogi", "Mikhail Belkin."], "venue": "Proceedings of ICML Workshop on Learning with Multiple Views, International Conference on Machine Learn-", "citeRegEx": "Sindhwani et al\\.,? 2005", "shortCiteRegEx": "Sindhwani et al\\.", "year": 2005}, {"title": "Novel Estimation Methods for Unsupervised Discovery of Latent Structure in Natural Language Text", "author": ["Noah A. Smith."], "venue": "Ph.D. thesis, Johns Hopkins University.", "citeRegEx": "Smith.,? 2006", "shortCiteRegEx": "Smith.", "year": 2006}, {"title": "Unsupervised multilingual grammar induction", "author": ["Benjamin Snyder", "Tahira Naseem", "Regina Barzilay."], "venue": "Proceedings of ACL.", "citeRegEx": "Snyder et al\\.,? 2009", "shortCiteRegEx": "Snyder et al\\.", "year": 2009}, {"title": "Semi-supervised sequential labeling and segmentation using giga-word scale unlabeled data", "author": ["Jun Suzuki", "Hideki Isozaki."], "venue": "Proceedings of ACL.", "citeRegEx": "Suzuki and Isozaki.,? 2008", "shortCiteRegEx": "Suzuki and Isozaki.", "year": 2008}, {"title": "Token and type constraints for cross-lingual part-of-speech tagging", "author": ["Oscar T\u00e4ckstr\u00f6m", "Dipanjan Das", "Slav Petrov", "Ryan McDonald", "Joakim Nivre."], "venue": "Proceedings of ACL.", "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? 2013", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2013}, {"title": "Word representations: A simple and general method for semi-supervised learning", "author": ["Joseph Turian", "Lev Ratinov", "Yoshua Bengio."], "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL).", "citeRegEx": "Turian et al\\.,? 2010", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "Effective bilingual constraints for semisupervised learning of named entity recognizers", "author": ["Mengqiu Wang", "Wanxiang Che", "Christopher D. Manning."], "venue": "Proceedings of AAAI.", "citeRegEx": "Wang et al\\.,? 2013", "shortCiteRegEx": "Wang et al\\.", "year": 2013}, {"title": "A backoff model for bootstrapping resources for non-english languages", "author": ["Chenhai Xi", "Rebecca Hwa."], "venue": "Proceedings of HLT-EMNLP.", "citeRegEx": "Xi and Hwa.,? 2005", "shortCiteRegEx": "Xi and Hwa.", "year": 2005}, {"title": "Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora", "author": ["David Yarowsky", "Grace Ngai."], "venue": "Proceedings of NAACL.", "citeRegEx": "Yarowsky and Ngai.,? 2001", "shortCiteRegEx": "Yarowsky and Ngai.", "year": 2001}, {"title": "Unsupervised word sense disambiguation rivaling supervised methods", "author": ["David Yarowsky."], "venue": "Proceedings of ACL.", "citeRegEx": "Yarowsky.,? 1995", "shortCiteRegEx": "Yarowsky.", "year": 1995}], "referenceMentions": [{"referenceID": 27, "context": "We encode expectations as constraints and train a discriminative CRF model using Generalized Expectation Criteria (Mann and McCallum, 2010).", "startOffset": 114, "endOffset": 139}, {"referenceID": 7, "context": "More recent paradigms for semi-supervised learning allow modelers to directly encode knowledge about the task and the domain as constraints to guide learning (Chang et al., 2007; Mann and McCallum, 2010; Ganchev et al., 2010).", "startOffset": 158, "endOffset": 225}, {"referenceID": 27, "context": "More recent paradigms for semi-supervised learning allow modelers to directly encode knowledge about the task and the domain as constraints to guide learning (Chang et al., 2007; Mann and McCallum, 2010; Ganchev et al., 2010).", "startOffset": 158, "endOffset": 225}, {"referenceID": 19, "context": "More recent paradigms for semi-supervised learning allow modelers to directly encode knowledge about the task and the domain as constraints to guide learning (Chang et al., 2007; Mann and McCallum, 2010; Ganchev et al., 2010).", "startOffset": 158, "endOffset": 225}, {"referenceID": 10, "context": "More recent work applied the projection-based approach to more language-pairs, and further improved performance through the use of type-level constraints from tag dictionary and feature-rich generative or discriminative models (Das and Petrov, 2011; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 227, "endOffset": 273}, {"referenceID": 37, "context": "More recent work applied the projection-based approach to more language-pairs, and further improved performance through the use of type-level constraints from tag dictionary and feature-rich generative or discriminative models (Das and Petrov, 2011; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 227, "endOffset": 273}, {"referenceID": 7, "context": "More recent paradigms for semi-supervised learning allow modelers to directly encode knowledge about the task and the domain as constraints to guide learning (Chang et al., 2007; Mann and McCallum, 2010; Ganchev et al., 2010). However, in a multilingual setting, coming up with effective constraints require extensive knowledge of the foreign1 language. Bilingual parallel text (bitext) lends itself as a medium to transfer knowledge from a resource-rich language to a foreign languages. Yarowsky and Ngai (2001) project labels produced by an English tagger to the foreign side of bitext, then use the projected labels to learn a HMM model.", "startOffset": 159, "endOffset": 513}, {"referenceID": 27, "context": "Secondly, we encode the expectations as constraints and train a model by minimizing divergence between model expectations and projected expectations in a Generalized Expectation (GE) Criteria (Mann and McCallum, 2010) framework.", "startOffset": 192, "endOffset": 217}, {"referenceID": 42, "context": "Examples of methods that explore multi-view constraints include self-training (Yarowsky, 1995; McClosky et al., 2006),2 co-training (Blum and Mitchell, 1998; Sindhwani et al.", "startOffset": 78, "endOffset": 117}, {"referenceID": 28, "context": "Examples of methods that explore multi-view constraints include self-training (Yarowsky, 1995; McClosky et al., 2006),2 co-training (Blum and Mitchell, 1998; Sindhwani et al.", "startOffset": 78, "endOffset": 117}, {"referenceID": 3, "context": ", 2006),2 co-training (Blum and Mitchell, 1998; Sindhwani et al., 2005), multiview learning (Ando and Zhang, 2005; Carlson et al.", "startOffset": 22, "endOffset": 71}, {"referenceID": 33, "context": ", 2006),2 co-training (Blum and Mitchell, 1998; Sindhwani et al., 2005), multiview learning (Ando and Zhang, 2005; Carlson et al.", "startOffset": 22, "endOffset": 71}, {"referenceID": 1, "context": ", 2005), multiview learning (Ando and Zhang, 2005; Carlson et al., 2010), and discriminative and generative model combination (Suzuki and Isozaki, 2008; Druck and McCallum, 2010).", "startOffset": 28, "endOffset": 72}, {"referenceID": 6, "context": ", 2005), multiview learning (Ando and Zhang, 2005; Carlson et al., 2010), and discriminative and generative model combination (Suzuki and Isozaki, 2008; Druck and McCallum, 2010).", "startOffset": 28, "endOffset": 72}, {"referenceID": 36, "context": ", 2010), and discriminative and generative model combination (Suzuki and Isozaki, 2008; Druck and McCallum, 2010).", "startOffset": 61, "endOffset": 113}, {"referenceID": 11, "context": ", 2010), and discriminative and generative model combination (Suzuki and Isozaki, 2008; Druck and McCallum, 2010).", "startOffset": 61, "endOffset": 113}, {"referenceID": 7, "context": "The kind of constraints used in applications such as NER are the ones like \u201cthe words CA, Australia, NY are LOCATION\u201d (Chang et al., 2007).", "startOffset": 118, "endOffset": 138}, {"referenceID": 8, "context": "An early example of using knowledge as constraints in weakly-supervised learning is the work by Collins and Singer (1999). They showed that the addition of a small set of \u201cseed\u201d rules greatly improve a co-training style unsupervised tagger.", "startOffset": 96, "endOffset": 122}, {"referenceID": 7, "context": "Chang et al. (2007) proposed a constraint-driven learning (CODL) framework where constraints are used to guide the selection of best self-labeled examples to be included as additional training data in an iterative EM-style procedure.", "startOffset": 0, "endOffset": 20}, {"referenceID": 12, "context": "Other sources of knowledge include lexicons and gazetteers (Druck et al., 2007; Chang et al., 2007).", "startOffset": 59, "endOffset": 99}, {"referenceID": 7, "context": "Other sources of knowledge include lexicons and gazetteers (Druck et al., 2007; Chang et al., 2007).", "startOffset": 59, "endOffset": 99}, {"referenceID": 11, "context": "Druck et al. (2009) also demonstrated that in an active learning setting where annotation budget is limited, it is more efficient to label features than examples.", "startOffset": 0, "endOffset": 20}, {"referenceID": 27, "context": "3 To soften these constraints, Mann and McCallum (2010) proposed the Generalized Expectation (GE) Criteria framework, which encodes constraints as a regularization term over some score function that measures the divergence between the model\u2019s expectation and the target expectation.", "startOffset": 31, "endOffset": 56}, {"referenceID": 27, "context": "3 To soften these constraints, Mann and McCallum (2010) proposed the Generalized Expectation (GE) Criteria framework, which encodes constraints as a regularization term over some score function that measures the divergence between the model\u2019s expectation and the target expectation. The connection between GE and CODL is analogous to the relationship between hard (Viterbi) EM and soft EM, as illustrated by Samdani et al. (2012).", "startOffset": 31, "endOffset": 430}, {"referenceID": 14, "context": "However, later results (Druck, 2011) have shown that using the Expectation Semiring techniques of Li and Eisner (2009), one can compute the exact gradients of GE in a Conditional Random Fields (CRF) (Lafferty et al.", "startOffset": 23, "endOffset": 36}, {"referenceID": 23, "context": "However, later results (Druck, 2011) have shown that using the Expectation Semiring techniques of Li and Eisner (2009), one can compute the exact gradients of GE in a Conditional Random Fields (CRF) (Lafferty et al., 2001) at costs", "startOffset": 199, "endOffset": 222}, {"referenceID": 16, "context": "Another closely related work is the Posterior Regularization (PR) framework by Ganchev et al. (2010). In fact, as Bellare et al.", "startOffset": 79, "endOffset": 101}, {"referenceID": 2, "context": "In fact, as Bellare et al. (2009) have shown, in a discriminative model these two methods optimize exactly the same objective.", "startOffset": 12, "endOffset": 34}, {"referenceID": 2, "context": "In fact, as Bellare et al. (2009) have shown, in a discriminative model these two methods optimize exactly the same objective.4 The two differ in optimization details: PR uses a EM algorithm to approximate the gradients which avoids the expensive computation of a covariance matrix between features and constraints, whereas GE directly calculates the gradient. However, later results (Druck, 2011) have shown that using the Expectation Semiring techniques of Li and Eisner (2009), one can compute the exact gradients of GE in a Conditional Random Fields (CRF) (Lafferty et al.", "startOffset": 12, "endOffset": 480}, {"referenceID": 2, "context": "And empirically, GE tends to perform more accurately than PR (Bellare et al., 2009; Druck, 2011).", "startOffset": 61, "endOffset": 96}, {"referenceID": 14, "context": "And empirically, GE tends to perform more accurately than PR (Bellare et al., 2009; Druck, 2011).", "startOffset": 61, "endOffset": 96}, {"referenceID": 0, "context": "As a result, bitext has been effectively utilized for unsupervised multilingual grammar induction (Alshawi et al., 2000; Snyder et al., 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al.", "startOffset": 98, "endOffset": 141}, {"referenceID": 35, "context": "As a result, bitext has been effectively utilized for unsupervised multilingual grammar induction (Alshawi et al., 2000; Snyder et al., 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al.", "startOffset": 98, "endOffset": 141}, {"referenceID": 4, "context": ", 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al.", "startOffset": 17, "endOffset": 42}, {"referenceID": 29, "context": ", 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al., 2009).", "startOffset": 66, "endOffset": 87}, {"referenceID": 5, "context": "A number of recent work also explored bilingual constraints in the context of simultaneous bilingual tagging, and showed that enforcing agreements between language pairs give superior results than monolingual tagging (Burkett et al., 2010; Che et al., 2013; Wang et al., 2013).", "startOffset": 217, "endOffset": 276}, {"referenceID": 8, "context": "A number of recent work also explored bilingual constraints in the context of simultaneous bilingual tagging, and showed that enforcing agreements between language pairs give superior results than monolingual tagging (Burkett et al., 2010; Che et al., 2013; Wang et al., 2013).", "startOffset": 217, "endOffset": 276}, {"referenceID": 39, "context": "A number of recent work also explored bilingual constraints in the context of simultaneous bilingual tagging, and showed that enforcing agreements between language pairs give superior results than monolingual tagging (Burkett et al., 2010; Che et al., 2013; Wang et al., 2013).", "startOffset": 217, "endOffset": 276}, {"referenceID": 30, "context": "They also demonstrated a uptraining (Petrov et al., 2010) setting where taginduced bitext can be used as additional monolingual training data to improve monolingual taggers.", "startOffset": 36, "endOffset": 57}, {"referenceID": 0, "context": "As a result, bitext has been effectively utilized for unsupervised multilingual grammar induction (Alshawi et al., 2000; Snyder et al., 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al., 2009). A number of recent work also explored bilingual constraints in the context of simultaneous bilingual tagging, and showed that enforcing agreements between language pairs give superior results than monolingual tagging (Burkett et al., 2010; Che et al., 2013; Wang et al., 2013). They also demonstrated a uptraining (Petrov et al., 2010) setting where taginduced bitext can be used as additional monolingual training data to improve monolingual taggers. A major drawback of this approach is that it requires a readily-trained tagging models in each languages, which makes a weakly supervised setting infeasible. Another intricacy of this approach is that it only works when the two models have comparable strength, since mutual agreements are enforced between them. Projection-based methods can be very effective in weakly-supervised scenarios, as demonstrated by Yarowsky and Ngai (2001), and Xi and Hwa (2005).", "startOffset": 99, "endOffset": 1110}, {"referenceID": 0, "context": "As a result, bitext has been effectively utilized for unsupervised multilingual grammar induction (Alshawi et al., 2000; Snyder et al., 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al., 2009). A number of recent work also explored bilingual constraints in the context of simultaneous bilingual tagging, and showed that enforcing agreements between language pairs give superior results than monolingual tagging (Burkett et al., 2010; Che et al., 2013; Wang et al., 2013). They also demonstrated a uptraining (Petrov et al., 2010) setting where taginduced bitext can be used as additional monolingual training data to improve monolingual taggers. A major drawback of this approach is that it requires a readily-trained tagging models in each languages, which makes a weakly supervised setting infeasible. Another intricacy of this approach is that it only works when the two models have comparable strength, since mutual agreements are enforced between them. Projection-based methods can be very effective in weakly-supervised scenarios, as demonstrated by Yarowsky and Ngai (2001), and Xi and Hwa (2005). One problem with projected labels is that they are often too noisy to be directly used as training signals.", "startOffset": 99, "endOffset": 1133}, {"referenceID": 0, "context": "As a result, bitext has been effectively utilized for unsupervised multilingual grammar induction (Alshawi et al., 2000; Snyder et al., 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al., 2009). A number of recent work also explored bilingual constraints in the context of simultaneous bilingual tagging, and showed that enforcing agreements between language pairs give superior results than monolingual tagging (Burkett et al., 2010; Che et al., 2013; Wang et al., 2013). They also demonstrated a uptraining (Petrov et al., 2010) setting where taginduced bitext can be used as additional monolingual training data to improve monolingual taggers. A major drawback of this approach is that it requires a readily-trained tagging models in each languages, which makes a weakly supervised setting infeasible. Another intricacy of this approach is that it only works when the two models have comparable strength, since mutual agreements are enforced between them. Projection-based methods can be very effective in weakly-supervised scenarios, as demonstrated by Yarowsky and Ngai (2001), and Xi and Hwa (2005). One problem with projected labels is that they are often too noisy to be directly used as training signals. To mitigate this problem, Das and Petrov (2011) designed a label propagation method to automatically induce a tag lexicon for the foreign language to smooth the projected labels.", "startOffset": 99, "endOffset": 1290}, {"referenceID": 0, "context": "As a result, bitext has been effectively utilized for unsupervised multilingual grammar induction (Alshawi et al., 2000; Snyder et al., 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al., 2009). A number of recent work also explored bilingual constraints in the context of simultaneous bilingual tagging, and showed that enforcing agreements between language pairs give superior results than monolingual tagging (Burkett et al., 2010; Che et al., 2013; Wang et al., 2013). They also demonstrated a uptraining (Petrov et al., 2010) setting where taginduced bitext can be used as additional monolingual training data to improve monolingual taggers. A major drawback of this approach is that it requires a readily-trained tagging models in each languages, which makes a weakly supervised setting infeasible. Another intricacy of this approach is that it only works when the two models have comparable strength, since mutual agreements are enforced between them. Projection-based methods can be very effective in weakly-supervised scenarios, as demonstrated by Yarowsky and Ngai (2001), and Xi and Hwa (2005). One problem with projected labels is that they are often too noisy to be directly used as training signals. To mitigate this problem, Das and Petrov (2011) designed a label propagation method to automatically induce a tag lexicon for the foreign language to smooth the projected labels. Fossum and Abney (2005) filter out projection noise by combining projections from from multiple source languages.", "startOffset": 99, "endOffset": 1445}, {"referenceID": 0, "context": "As a result, bitext has been effectively utilized for unsupervised multilingual grammar induction (Alshawi et al., 2000; Snyder et al., 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al., 2009). A number of recent work also explored bilingual constraints in the context of simultaneous bilingual tagging, and showed that enforcing agreements between language pairs give superior results than monolingual tagging (Burkett et al., 2010; Che et al., 2013; Wang et al., 2013). They also demonstrated a uptraining (Petrov et al., 2010) setting where taginduced bitext can be used as additional monolingual training data to improve monolingual taggers. A major drawback of this approach is that it requires a readily-trained tagging models in each languages, which makes a weakly supervised setting infeasible. Another intricacy of this approach is that it only works when the two models have comparable strength, since mutual agreements are enforced between them. Projection-based methods can be very effective in weakly-supervised scenarios, as demonstrated by Yarowsky and Ngai (2001), and Xi and Hwa (2005). One problem with projected labels is that they are often too noisy to be directly used as training signals. To mitigate this problem, Das and Petrov (2011) designed a label propagation method to automatically induce a tag lexicon for the foreign language to smooth the projected labels. Fossum and Abney (2005) filter out projection noise by combining projections from from multiple source languages. However, this approach is not always viable since it relies on having parallel bitext from multiple source languages. Li et al. (2012) proposed the use of crowd-sourced Wiktionary as additional resources for inducing tag lexicons.", "startOffset": 99, "endOffset": 1670}, {"referenceID": 0, "context": "As a result, bitext has been effectively utilized for unsupervised multilingual grammar induction (Alshawi et al., 2000; Snyder et al., 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al., 2009). A number of recent work also explored bilingual constraints in the context of simultaneous bilingual tagging, and showed that enforcing agreements between language pairs give superior results than monolingual tagging (Burkett et al., 2010; Che et al., 2013; Wang et al., 2013). They also demonstrated a uptraining (Petrov et al., 2010) setting where taginduced bitext can be used as additional monolingual training data to improve monolingual taggers. A major drawback of this approach is that it requires a readily-trained tagging models in each languages, which makes a weakly supervised setting infeasible. Another intricacy of this approach is that it only works when the two models have comparable strength, since mutual agreements are enforced between them. Projection-based methods can be very effective in weakly-supervised scenarios, as demonstrated by Yarowsky and Ngai (2001), and Xi and Hwa (2005). One problem with projected labels is that they are often too noisy to be directly used as training signals. To mitigate this problem, Das and Petrov (2011) designed a label propagation method to automatically induce a tag lexicon for the foreign language to smooth the projected labels. Fossum and Abney (2005) filter out projection noise by combining projections from from multiple source languages. However, this approach is not always viable since it relies on having parallel bitext from multiple source languages. Li et al. (2012) proposed the use of crowd-sourced Wiktionary as additional resources for inducing tag lexicons. More recently, T\u00e4ckstr\u00f6m et al. (2013) combined token-level and type-level constraints to constrain legitimate label sequences and and recalibrate the probability distribution in a CRF.", "startOffset": 99, "endOffset": 1805}, {"referenceID": 0, "context": "As a result, bitext has been effectively utilized for unsupervised multilingual grammar induction (Alshawi et al., 2000; Snyder et al., 2009), parsing (Burkett and Klein, 2008), and sequence labeling (Naseem et al., 2009). A number of recent work also explored bilingual constraints in the context of simultaneous bilingual tagging, and showed that enforcing agreements between language pairs give superior results than monolingual tagging (Burkett et al., 2010; Che et al., 2013; Wang et al., 2013). They also demonstrated a uptraining (Petrov et al., 2010) setting where taginduced bitext can be used as additional monolingual training data to improve monolingual taggers. A major drawback of this approach is that it requires a readily-trained tagging models in each languages, which makes a weakly supervised setting infeasible. Another intricacy of this approach is that it only works when the two models have comparable strength, since mutual agreements are enforced between them. Projection-based methods can be very effective in weakly-supervised scenarios, as demonstrated by Yarowsky and Ngai (2001), and Xi and Hwa (2005). One problem with projected labels is that they are often too noisy to be directly used as training signals. To mitigate this problem, Das and Petrov (2011) designed a label propagation method to automatically induce a tag lexicon for the foreign language to smooth the projected labels. Fossum and Abney (2005) filter out projection noise by combining projections from from multiple source languages. However, this approach is not always viable since it relies on having parallel bitext from multiple source languages. Li et al. (2012) proposed the use of crowd-sourced Wiktionary as additional resources for inducing tag lexicons. More recently, T\u00e4ckstr\u00f6m et al. (2013) combined token-level and type-level constraints to constrain legitimate label sequences and and recalibrate the probability distribution in a CRF. The tag dictionary used for POS tagging are analogous to the gazetteers and name lexicons used for NER by Chang et al. (2007).", "startOffset": 99, "endOffset": 2078}, {"referenceID": 41, "context": "Instead of using the projected linguistic structures as ground truth (Yarowsky and Ngai, 2001), or as features in a generative model (Das and Petrov, 2011), they used them as constraints in a PR framework.", "startOffset": 69, "endOffset": 94}, {"referenceID": 10, "context": "Instead of using the projected linguistic structures as ground truth (Yarowsky and Ngai, 2001), or as features in a generative model (Das and Petrov, 2011), they used them as constraints in a PR framework.", "startOffset": 133, "endOffset": 155}, {"referenceID": 15, "context": "Our work is also closely related to Ganchev et al. (2009). They used a two-step projection method similar to Das and Petrov (2011) for dependency parsing.", "startOffset": 36, "endOffset": 58}, {"referenceID": 9, "context": "They used a two-step projection method similar to Das and Petrov (2011) for dependency parsing.", "startOffset": 50, "endOffset": 72}, {"referenceID": 2, "context": "Experiments in Bellare et al. (2009) and Druck (2011) suggest that in a discriminative model (like ours), GE is more accurate than PR.", "startOffset": 15, "endOffset": 37}, {"referenceID": 2, "context": "Experiments in Bellare et al. (2009) and Druck (2011) suggest that in a discriminative model (like ours), GE is more accurate than PR.", "startOffset": 15, "endOffset": 54}, {"referenceID": 14, "context": "In the remainder of this section, we follow the notation used in (Druck, 2011) to explain our approach.", "startOffset": 65, "endOffset": 78}, {"referenceID": 26, "context": "To this end, we adopt the Generalized Expectation (GE) Criteria framework introduced by Mann and McCallum (2010). In the remainder of this section, we follow the notation used in (Druck, 2011) to explain our approach.", "startOffset": 88, "endOffset": 113}, {"referenceID": 10, "context": "Projecting expectations instead of one-best label assignments from English to foreign language can be thought of as a soft version of the method described in (Das and Petrov, 2011) and (Ganchev et al.", "startOffset": 158, "endOffset": 180}, {"referenceID": 18, "context": "Projecting expectations instead of one-best label assignments from English to foreign language can be thought of as a soft version of the method described in (Das and Petrov, 2011) and (Ganchev et al., 2009).", "startOffset": 185, "endOffset": 207}, {"referenceID": 16, "context": "In general, preserving uncertainties till later is a strategy that has benefited many NLP tasks (Finkel et al., 2006).", "startOffset": 96, "endOffset": 117}, {"referenceID": 41, "context": "In the hard projection setting, GE training resembles a \u201cproject-then-train\u201d style semi-supervised CRF training scheme (Yarowsky and Ngai, 2001; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 119, "endOffset": 168}, {"referenceID": 37, "context": "In the hard projection setting, GE training resembles a \u201cproject-then-train\u201d style semi-supervised CRF training scheme (Yarowsky and Ngai, 2001; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 119, "endOffset": 168}, {"referenceID": 8, "context": "Features for English, Chinese and German CRFs are documented extensively in (Che et al., 2013) and (Faruqui and Pad\u00f3, 2010) and omitted here for brevity.", "startOffset": 76, "endOffset": 94}, {"referenceID": 15, "context": ", 2013) and (Faruqui and Pad\u00f3, 2010) and omitted here for brevity.", "startOffset": 12, "endOffset": 36}, {"referenceID": 21, "context": "0) corpus (Hovy et al., 2006).", "startOffset": 10, "endOffset": 29}, {"referenceID": 8, "context": "For Chinese NER experiments, we follow the same setup as Che et al. (2013) to evaluate on the latest OntoNotes (v4.", "startOffset": 57, "endOffset": 75}, {"referenceID": 32, "context": "For German NER experiments, we evaluate using the standard CoNLL-03 NER corpus (Sang and Meulder, 2003).", "startOffset": 79, "endOffset": 103}, {"referenceID": 39, "context": "They are: semi-supervised learning method using factored bilingual models with Gibbs sampling (Wang et al., 2013); bilingual NER using Integer Linear Programming (ILP) with bilingual constraints, by (Che et al.", "startOffset": 94, "endOffset": 113}, {"referenceID": 8, "context": ", 2013); bilingual NER using Integer Linear Programming (ILP) with bilingual constraints, by (Che et al., 2013); and constraint-driven bilingual-reranking ap-", "startOffset": 93, "endOffset": 111}, {"referenceID": 5, "context": "tgz proach (Burkett et al., 2010).", "startOffset": 11, "endOffset": 33}, {"referenceID": 8, "context": "The code from (Che et al., 2013) and (Wang et al.", "startOffset": 14, "endOffset": 32}, {"referenceID": 39, "context": ", 2013) and (Wang et al., 2013) are publicly available,15.", "startOffset": 12, "endOffset": 31}, {"referenceID": 5, "context": "Code from (Burkett et al., 2010) is obtained through personal communications.", "startOffset": 10, "endOffset": 32}, {"referenceID": 38, "context": "2 is nonconvex, we adopted the early stopping training scheme from (Turian et al., 2010) as the following: after each iteration in L-BFGS training, the model is evaluated against the development set; the training procedure is terminated if no improvements have been made in 20 iterations.", "startOffset": 67, "endOffset": 88}, {"referenceID": 5, "context": "com/stanfordnlp/CoreNLP Due to technical difficulties, we are unable to replicate Burkett et al. (2010) experiments on German NER, therefore only Chinese results are reported.", "startOffset": 82, "endOffset": 104}, {"referenceID": 39, "context": "WCD13 is (Wang et al., 2013), CWD13 is (Che et al.", "startOffset": 9, "endOffset": 28}, {"referenceID": 8, "context": ", 2013), CWD13 is (Che et al., 2013), and BPBK10 is (Burkett et al.", "startOffset": 18, "endOffset": 36}, {"referenceID": 5, "context": ", 2013), and BPBK10 is (Burkett et al., 2010).", "startOffset": 23, "endOffset": 45}], "year": 2013, "abstractText": "We consider a multilingual weakly supervised learning scenario where knowledge from annotated corpora in a resource-rich language is transferred via bitext to guide the learning in other languages. Past approaches project labels across bitext and use them as features or gold labels for training. We propose a new method that projects model expectations rather than labels, which facilities transfer of model uncertainty across language boundaries. We encode expectations as constraints and train a discriminative CRF model using Generalized Expectation Criteria (Mann and McCallum, 2010). Evaluated on standard Chinese-English and German-English NER datasets, our method demonstrates F1 scores of 64% and 60% when no labeled data is used. Attaining the same accuracy with supervised CRFs requires 12k and 1.5k labeled sentences. Furthermore, when combined with labeled examples, our method yields significant improvements over state-of-the-art supervised methods, achieving best reported numbers to date on Chinese OntoNotes and German CoNLL-03 datasets.", "creator": "TeX"}}}