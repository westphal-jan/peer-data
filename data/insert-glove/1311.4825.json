{"id": "1311.4825", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2013", "title": "Gaussian Process Optimization with Mutual Information", "abstract": "In thackley this paper, altenmarkt we analyze a toronto-based generic algorithm scheme snowiest for oresme sequential global stratis optimization abaza using Gaussian processes. benzaiten The binaca upper bounds bahadurpur we derive frazee on the nikel cumulative nlp regret for this gravelle generic kul\u00fcb\u00fc algorithm improve nuclease by an brzezinski exponential factor terrano the previously known bounds kapaa for hador algorithms canyon like sartorial GP - scornfully UCB. mikl\u00f3s We veiller also ihrc introduce one-fifth the novel Gaussian glavas Process 62-50 Mutual 1960-1964 Information 96.40 algorithm (GP - MI ), dietzel which significantly improves heiwa further these wilsons upper ki-moon bounds for the ksetra cumulative regret. centros We lysosomal confirm the efficiency lapangan of 87-87 this time-space algorithm 14s on mccraney synthetic and e-health real duhaime tasks against bunkie the acid-base natural competitor, GP - kroy UCB, 55-12 and jehad also the heusinger Expected Improvement heuristic.", "histories": [["v1", "Tue, 19 Nov 2013 18:29:19 GMT  (888kb,D)", "https://arxiv.org/abs/1311.4825v1", null], ["v2", "Tue, 20 May 2014 18:25:19 GMT  (888kb,D)", "http://arxiv.org/abs/1311.4825v2", "Proceedings of The 31st International Conference on Machine Learning (ICML 2014)"], ["v3", "Mon, 8 Jun 2015 13:27:19 GMT  (889kb,D)", "http://arxiv.org/abs/1311.4825v3", "Proceedings of The 31st International Conference on Machine Learning (ICML 2014)"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["emile contal", "vianney perchet", "nicolas vayatis"], "accepted": true, "id": "1311.4825"}, "pdf": {"name": "1311.4825.pdf", "metadata": {"source": "CRF", "title": "Gaussian Process Optimization with Mutual Information", "authors": ["Emile Contal", "Vianney Perchet", "Nicolas Vayatis"], "emails": [], "sections": [{"heading": null, "text": "Preprint for the 31st International Conference on Machine Learning (ICML 2014)\nar X\niv :1\n31 1.\n48 25\nv3 [\nst at\n.M L\nErratum After the publication of our article, we found an error in the proof of Lemma 1 which invalidates the main theorem. It appears that the information given to the algorithm is not sufficient for the main theorem to hold true. The theoretical guarantees would remain valid in a setting where the algorithm observes the instantaneous regret instead of noisy samples of the unknown function. We describe in this page the mistake and its consequences.\nLet f : X \u2192 R be the unknown function to be optimized, which is a sample from a Gaussian process. Let\u2019s fix x?, x1, . . . , xT \u2208 X and the observations yt = f(xt)+ t where the noise variables t are independent Gaussian noise N (0, \u03c32). We define the instantaneous regret rt = f(x?)\u2212 f(xt) and,\nMT = T\u2211 t=1 \u00b4 rt \u2212 Errt | y1, . . . , yt\u22121s \u00af .\nIn Lemma 1, we claimed that MT is a Gaussian martingale with respect to YT = y1, . . . , yT . Even if Mt \u2212 Mt\u22121 is a centered Gaussian conditioned on YT\u22121, it is wrong to say that MT is a martingale since it is not measurable with respect to YT .\nIn order to fix Lemma 1, it is possible to modify MT and use its natural filtration FT = {rt}t\u2264T instead of YT ,\nMT = T\u2211 t=1 \u00b4 rt \u2212 Errt | Ft\u22121s \u00af .\nThen MT is a Gaussian martingale with respect to FT . Now to adapt the algorithm for this new quantity it needs to observe rt instead of yt to be able to compute both the posterior expectation and variance for all x in X :\n\u00b5t(x) = Erf(x) | Ft\u22121s and \u03c32t (x) = Var <rf(x) | Ft\u22121s .\nWe remark that the experiments performed in this article are remarkably good in spite of Lemma 1 being unproved. After having discovered the mistake we were able to build scenarios were the GP-MI algorithm is overconfident and misses the optimum of f , and therefore incurs a linear cumulative regret."}, {"heading": "1 Introduction", "text": "Stochastic optimization problems are encountered in numerous real world domains including engineering design Wang & Shan [2007], finance Ziemba & Vickson [2006], natural sciences Floudas & Pardalos [2000], or in machine learning for selecting models by tuning the parameters of learning algorithms Snoek et al. [2012]. We aim at finding the input of a given system which optimizes the output (or reward). In this view, an iterative procedure uses the previously acquired measures to choose the next query predicted to be the most useful. The goal is to maximize the sum of the rewards received at each iteration, that is to minimize the cumulative regret by balancing exploration (gathering information by favoring locations with high uncertainty) and exploitation (focusing on the optimum by favoring locations with high predicted reward). This optimization task becomes challenging when the dimension of the search space is high and the evaluations are noisy and expensive. Efficient algorithms have been studied to tackle this challenge such as multiarmed bandit Auer et al. [2002], Kleinberg [2004], Bubeck et al. [2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP Rasmussen & Williams [2006]. Our main contribution is twofold: we propose a generic algorithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret. The theoretical analysis has a direct impact on strategies built with the GP-UCB algorithm Srinivas et al. [2012] such as Krause & Ong [2011], Desautels et al. [2012], Contal et al. [2013]. We suggest an alternative policy which achieves an exponential speed up with respect to the cumulative regret. We also introduce a novel algorithm, the Gaussian Process Mutual Information algorithm (GP-MI), which improves furthermore upper bounds for the cumulative regret from O( a\nT (log T )d+1) for GP-UCB, the current state of the art, to the spectacular O( a\n(log T )d+1), where T is the number of iterations, d is the dimension of the input space and the kernel function is Gaussian. The remainder of this article is organized as follows. We first introduce the setup and notations. We define the GP-MI algorithm in Section 2. Main results on the cumulative regret bounds are presented in Section 3. We then provide technical details in Section 4. We finally confirm the performances of GP-MI on real and synthetic tasks compared to the state of the art of GP optimization and some heuristics used in practice.\n2 Gaussian process optimization and the GP-MI algorithm"}, {"heading": "2.1 Sequential optimization and cumulative regret", "text": "Let f : X \u2192 R, where X \u2282 Rd is a compact and convex set, be the unknown function modeling the system we want to be optimized. We consider the problem of finding the\nmaximum of f denoted by: f(x?) = max\nx\u2208X f(x) ,\nvia successive queries x1, x2, . . . \u2208 X . At iteration T +1, the choice of the next query xT+1 depends on the previous noisy observations, YT = {y1, . . . , yT } at locations XT = {x1, . . . , xT } where yt = f(xt) + t for all t \u2264 T , and the noise variables 1, . . . , T are independently distributed as a Gaussian random variable N (0, \u03c32) with zero mean and variance \u03c32. The efficiency of a policy and its ability to address the exploration/exploitation trade-off is measured via the cumulative regret RT , defined as the sum of the instantaneous regret rt, the gaps between the value of the maximum and the values at the sample locations,\nrt = f(x ?)\u2212 f(xt) for t \u2264 T\nand RT = T\u2211 t=1 f(x?)\u2212 f(xt) .\nOur aim is to obtain upper bounds on the cumulative regret RT with high probability."}, {"heading": "2.2 The Gaussian process framework", "text": "Prior assumption on f . In order to control the smoothness of the underlying function, we assume that f is sampled from a Gaussian process GP(m, k) with mean function m : X \u2192 R and kernel function k : X \u00d7 X \u2192 R+. We formalize in this manner the prior assumption that high local variations of f have low probability. The prior mean function is considered without loss of generality to be zero, as the kernel k can completely define the GP Rasmussen & Williams [2006]. We consider the normalized and dimensionless framework introduced by Srinivas et al. [2010] where the variance is assumed to be bounded, that is k(x, x) \u2264 1 for all x \u2208 X .\nBayesian inference. At iteration T + 1, given the previously observed noisy values YT at locations XT , we use Bayesian inference to compute the current posterior distribution Rasmussen & Williams [2006], which is a GP of mean \u00b5T+1 and variance \u03c32T+1 given at any x \u2208 X by,\n\u00b5T+1(x) = kT (x) >C\u22121T YT (1) and \u03c32T+1(x) = k(x, x)\u2212 kT (x)>C\u22121T kT (x) , (2)\nwhere kT (x) = [k(xt, x)]xt\u2208XT is the vector of covariances between x and the query points at time T , and CT = KT +\u03c32I with KT = [k(xt, xt\u2032)]xt,xt\u2032\u2208XT the kernel matrix, \u03c32 is the variance of the noise and I stands for the identity matrix. The Bayesian inference is illustrated on Figure 1 in a sample problem in dimension one, where the posteriors are based on four observations of a Gaussian Process with squared exponential kernel. The height of the gray area represents two posterior standard deviations at each point.\nAlgorithm 1 GP-MI p\u03b30 \u2190 0 for t = 1, 2, . . . do\nCompute \u00b5t and \u03c32t // Bayesian inference (Eq. 1, 2) \u03c6t(x)\u2190 ? \u03b1 \u02c6 b \u03c32t (x) + p\u03b3t\u22121 \u2212 a p\u03b3t\u22121 \u02d9\n// Definition of \u03c6t(x) for all x \u2208 X xt \u2190 argmaxx\u2208X \u00b5t(x) + \u03c6t(x) // Selection of the next query location p\u03b3t \u2190 p\u03b3t\u22121 + \u03c32t (xt) // Update p\u03b3t Sample xt and observe yt // Query\nend for"}, {"heading": "2.3 The Gaussian Process Mutual Information algorithm", "text": "A novel algorithm. The Gaussian Process Mutual Information algorithm (GP-MI) is presented as Algorithm 1. The key statement is the choice of the query, xt = argmaxx\u2208X \u00b5t(x) + \u03c6t(x). The exploitation ability of the procedure is driven by \u00b5t, while the exploration is governed by \u03c6t : X \u2192 R, which is an increasing function of \u03c32t (x). The novelty in the GP-MI algorithm is that \u03c6t is empirically controlled by the amount of exploration that has been already done, that is, the more the algorithm has gathered information on f , the more it will focus on the optimum. In the GP-UCB algorithm from Srinivas et al. [2012] the exploration coefficient is aO(log t) and therefore tends to infinity. The parameter \u03b1 in Algorithm 1 governs the trade-off between precision and confidence, as shown in Theorem 2. The efficiency of the algorithm is robust to the choice of its value. We confirm empirically this property and provide further discussion on the calibration of \u03b1 in Section 5.\nAlgorithm 2 Generic Optimization Scheme (\u03c6t) for t = 1, 2, . . . do\nCompute \u00b5t and \u03c6t xt \u2190 argmaxx\u2208X \u00b5t(x) + \u03c6t(x) Sample xt and observe yt\nend for\nMutual information. The quantity p\u03b3T controlling the exploration in our algorithm forms a lower bound on the information acquired on f by the query points XT . The information on f is formally defined by IT (XT ), the mutual information between f and the noisy observations YT at XT , hence the name of the GP-MI algorithm. For a Gaussian process distribution IT (XT ) = 12 log det(I + \u03c3\n\u22122KT ) where KT is the kernel matrix [k(xi, xj)]xi,xj\u2208XT . We refer to Cover & Thomas [1991] for further reading on mutual information. We denote by \u03b3T = maxXT\u2282X :|XT |=T IT (XT ) the maximum mutual information obtainable by a sequence of T query points. In the case of Gaussian processes with bounded variance, the following inequality is satisfied (Lemma 5.4 in Srinivas et al. [2012]):\np\u03b3T = T\u2211 t=1 \u03c32t (xt) \u2264 C1\u03b3T (3)\nwhere C1 = 2log(1+\u03c3\u22122) and \u03c3 2 is the noise variance. The upper bounds on the cumulative regret we derive in the next section depend mainly on this key quantity."}, {"heading": "3 Main Results", "text": ""}, {"heading": "3.1 Generic Optimization Scheme", "text": "We first consider the generic optimization scheme defined in Algorithm 2, where we let \u03c6t as a generic function viewed as a parameter of the algorithm. We only require \u03c6t to be measurable with respect to Yt\u22121, the observations available at iteration t\u2212 1. The theoretical analysis of Algorithm 2 can be used as a plug-in theorem for existing algorithms. For example the GP-UCB algorithm with parameter \u03b2t = O(log t) is obtained with \u03c6t(x) = a\n\u03b2t\u03c32t (x). A generic analysis of Algorithm 2 leads to the following upper bounds on the cumulative regret with high probability.\nTheorem 1 (Regret bounds for the generic algorithm). For all \u03b4 > 0 and T > 0, the regret RT incurred by Algorithm 2 on f distributed as a GP perturbed by independent Gaussian noise with variance \u03c32 satisfies the following bound with high probability, with C1 = 2log(1+\u03c3\u22122) and \u03b1 = log 2 \u03b4 :\nPr\n\u00ab RT \u2264 T\u2211 t=1 p\u03c6t(xt)\u2212 \u03c6t(x?)q + 4 a \u03b1(C1\u03b3T + 1) + ? \u03b1 2 \u2211T t=1 \u03c3 2 t (x ?)? C1\u03b3T + 1 ff \u2265 1\u2212\u03b4 .\nThe proof of Theorem 1, relies on concentration guarantees for Gaussian processes (see Section 4.1). Theorem 1 provides an intermediate result used for the calibration of \u03c6t to face the exploration/exploitation trade-off. For example by choosing \u03c6t(x) =? \u03b1 2 \u03c3 2 t (x) (where the dimensional constant is hidden), Algorithm 2 becomes a variant\nof the GP-UCB algorithm where in particular the exploration parameter ? \u03b2t is fixed to ? \u03b1 2 instead of being an increasing function of t. The upper bounds on the cumulative regret with this definition of \u03c6t are of the form RT = O(\u03b3T ), as stated in Corollary 1. We then also consider the case where the kernel k of the Gaussian process is under the form of a squared exponential (RBF) kernel, k(x1, x2) = exp \u00b4 \u2212 \u2016x1\u2212x2\u2016 2\n2l2\n\u00af\n, for all x1, x2 \u2208 X and length scale l \u2208 R. In this setting, the maximum mutual information \u03b3T satisfies the upper bound \u03b3T = Op(log T )d+1q, where d is the dimension of the input space Srinivas et al. [2012]. Corollary 1. Consider the Algorithm 2 where we set \u03c6t(x) = ? \u03b1 2 \u03c3 2 t (x). Under the assumptions of Theorem 1, we have that the cumulative regret for Algorithm 2 satisfies the following upper bounds with high probability:\n\u2022 For f sampled from a GP with general kernel: RT = O(\u03b3T ).\n\u2022 For f sampled from a GP with RBF kernel: RT = Op(log T )d+1q.\nTo prove Corollary 1 we apply Theorem 1 with the given definition of \u03c6t and then Equation 3, which leads to Pr rRT \u2264 ? \u03b1 2 C1\u03b3T + 4 a\n\u03b1(C1\u03b3T + 1)s \u2265 1 \u2212 \u03b4. The previously known upper bounds on the cumulative regret for the GP-UCB algorithm are of the form RT = Op ? T\u03b2T \u03b3T q where \u03b2T = Op log T\u03b4 q. The improvement of the generic Algorithm 2 with \u03c6t(x) = ? \u03b1 2 \u03c3 2 t (x) over the GP-UCB algorithm with respect to the cumulative regret is then exponential in the case of Gaussian processes with RBF kernel. For f sampled from a GP with linear kernel, corresponding to f(x) = wTx with w \u223c N (0, I), we obtain RT = Opd log T q. We remark that the GP assumption with linear kernel is more restrictive than the linear bandit framework, as it implies a Gaussian prior over the linear coefficients w. Hence there is no contradiction with the lower bounds stated for linear bandit like those of Dani et al. [2008]. We refer to Srinivas et al. [2012] for the analysis of \u03b3T with other kernels widely used in practice.\n3.2 Regret bounds for the GP-MI algorithm We present here the main result of the paper, the upper bound on the cumulative regret for the GP-MI algorithm.\nTheorem 2 (Regret bounds for the GP-MI algorithm). For all \u03b4 > 0 and T > 1, the regret RT incurred by Algorithm 1 on f distributed as a GP perturbed by independent Gaussian noise with variance \u03c32 satisfies the following bound with high probability, with C1= 2log(1+\u03c3\u22122) and \u03b1=log 2 \u03b4 :\nPr \u201d RT \u2264 5 a \u03b1C1\u03b3T + 4 ? \u03b1 \u0131 \u2265 1\u2212 \u03b4 .\nThe proof for Theorem 2 is provided in Section 4.2, where we analyze the properties of the exploration functions \u03c6t. Corollary 2 describes the case with RBF kernel for the GP-MI algorithm.\nCorollary 2 (RBF kernels). The cumulative regret RT incurred by Algorithm 1 on f sampled from a GP with RBF kernel satisfies with high probability,\nRT = O \u00b4 (log T ) d+1 2 \u00af .\nThe GP-MI algorithm significantly improves the upper bounds for the cumulative regret over the GP-UCB algorithm and the alternative policy of Corollary 1."}, {"heading": "4 Theoretical analysis", "text": "In this section, we provide the proofs for Theorem 1 and Theorem 2. The approach presented here to study the cumulative regret incurred by Gaussian process optimization strategies is general and can be used further for other algorithms."}, {"heading": "4.1 Analysis of the general algorithm", "text": "The theoretical analysis of Theorem 1 uses a similar approach to the Azuma-Hoeffding inequality adapted for Gaussian processes. Let rt = f(x?)\u2212 f(xt) for all t \u2264 T . We define MT , which is shown later to be a martingale with respect to YT\u22121,\nMT = T\u2211 t=1 \u00b4 rt \u2212 p\u00b5t(x?)\u2212 \u00b5t(xt)q \u00af , (4)\nfor T \u2265 1 and M0 = 0. Let Yt be defined as the martingale difference sequence with respect to MT , that is the difference between the instantaneous regret and the gap between the posterior mean for the optimum and the one for the point queried,\nYt =Mt \u2212Mt\u22121 = rt \u2212 p\u00b5t(x?)\u2212 \u00b5t(xt)q for t \u2265 1 .\nLemma 1. The sequence MT is a martingale with respect to YT\u22121 and for all t \u2264 T , given Yt\u22121, the random variable Yt is distributed as a Gaussian N (0, `2t ) with zero mean and variance `2t , where:\n`2t = \u03c3 2 t (x ?) + \u03c32t (xt)\u2212 2k(x?, xt) . (5)\nProof. From the GP assumption, we know that given Yt\u22121, the distribution of f(x) is Gaussian N p\u00b5t(x), \u03c32t (x)q for all x \u2208 X , and rt is a projection of a Gaussian random vector, that is rt is distributed as a Gaussian N p\u00b5t(x?) \u2212 \u00b5t(xt), `2t q and Yt is distributed as GaussianN (0, `2t ), with `2t = \u03c32t (x?) + \u03c32t (xt)\u2212 2k(x?, xt), hence MT is a Gaussian martingale.\nWe now give a concentration result for MT using inequalities for self-normalized martingales.\nLemma 2. For all \u03b4 > 0 and T > 1, the martingaleMT normalized by the predictable quadratic variation \u2211T t=1 ` 2 t satisfies the following concentration inequality with \u03b1 = log 2\u03b4 and y = 8(C1\u03b3T + 1):\nPr\n\u00ab\nMT \u2264 a 2\u03b1y +\nc\n2\u03b1\ny T\u2211 t=1 \u03c32t (x ?) ff \u2265 1\u2212 \u03b4 .\nProof. Let y = 8(C1\u03b3T +1). We introduce the notation Pr>[A] for Pr[A\u2227 \u2211T t=1 ` 2 t >\ny] and Pr\u2264[A] for Pr[A\u2227 \u2211T t=1 ` 2 t \u2264 y]. Given thatMt is a Gaussian martingale, using\nTheorem 4.2 and Remark 4.2 from Bercu & Touati [2008] with \u3008M\u3009T = \u2211T t=1 ` 2 t and a = 0 and b = 1 we obtain for all x > 0:\nPr>\n\u201d MT\u2211T t=1 ` 2 t > x \u0131 < exp \u00b4 \u2212x2y2 \u00af .\nWith x = b\n2\u03b1 y where \u03b1 = log 2 \u03b4 , we have:\nPr>\n\u201d\nMT > b 2\u03b1 y \u2211T t=1 ` 2 t \u0131 < \u03b42 .\nBy definition of `t in Eq. 5 and with k(x?, xt) \u2265 0, we have for all t \u2265 1 that `2t \u2264 \u03c32t (xt) + \u03c3 2 t (x ?). Using Equation 3 we have p\u03b3T \u2264 y8 , we finally get:\nPr>\n\u201d MT > ? 2\u03b1y 8 + b 2\u03b1 y \u2211T t=1 \u03c3 2 t (x ?) \u0131 < \u03b42 . (6)\nNow, using Theorem 4.1 and Remark 4.2 from Bercu & Touati [2008] the following inequality is satisfied for all x > 0:\nPr\u2264 rMT > xs < exp \u00b4 \u2212x22y \u00af .\nWith x = ? 2\u03b1y we have:\nPr\u2264 rMT > ? 2\u03b1ys < \u03b42 . (7)\nCombining Equations 6 and 7 leads to,\nPr\n\u00ab\nMT > a 2\u03b1y +\nc\n2\u03b1\ny T\u2211 t=1 \u03c32t (x ?) ff < \u03b4 ,\nproving Lemma 2.\nThe following lemma concludes the proof of Theorem 1 using the previous concentration result and the properties of the generic Algorithm 2.\nLemma 3. The cumulative regret for Algorithm 2 on f sampled from a GP satisfies the following bound for all \u03b4 > 0 and \u03b1 and y defined in Lemma 2:\nPr\n\u00ab RT \u2264 T\u2211 t=1 p\u03c6t(xt)\u2212 \u03c6t(x?)q + a 2\u03b1y + c 2\u03b1 y T\u2211 t=1 \u03c32t (x ?) ff \u2265 1\u2212 \u03b4 .\nProof. By construction of the generic Algorithm 2, we have xt = argmaxx\u2208X \u00b5t(x)+ \u03c6t(x), which guarantees for all t \u2265 1 that \u00b5t(x?)\u2212\u00b5t(xt) \u2264 \u03c6t(xt)\u2212\u03c6t(x?). Replacing MT by its definition in Eq. 4 and using the previous property in Lemma 2 proves Lemma 3.\n4.2 Analysis of the GP-MI algorithm In order to bound the cumulative regret for the GP-MI algorithm, we focus on an alternative definition of the exploration functions \u03c6t where the last term is modified inductively so as to simplify the sum \u2211T t=1 \u03c6t(xt) for all T > 0. Being a constant term for a fixed t > 0, Algorithm 1 remains unchanged. Let \u03c6t be defined as,\n\u03c6t(x) = b \u03b1(\u03c32t (x) + p\u03b3t\u22121)\u2212 t\u22121\u2211 i=1 \u03c6i(xi) ,\nwhere xt is the point selected by Algorithm 1 at iteration t. We have for all T > 1,\nT\u2211 t=1 \u03c6t(xt) = a \u03b1p\u03b3T \u2212 T\u22121\u2211 t=1 \u03c6t(xt) + T\u22121\u2211 t=1 \u03c6t(xt) = a \u03b1p\u03b3T . (8)\nWe can now derive upper bounds for \u2211T t=1 p\u03c6t(xt) \u2212 \u03c6t(x?)q which will be plugged in Theorem 1 in order to cancel out the terms involving x?. In this manner we can calibrate sharply the exploration/exploitation trade-off by optimizing the remaining terms.\nLemma 4. For the GP-MI algorithm, the exploration term in the equation of Theorem 1 satisfies the following inequality:\nT\u2211 t=1 p\u03c6t(xt)\u2212 \u03c6t(x?)q \u2264 a \u03b1p\u03b3T \u2212 ? \u03b1 2 \u2211T t=1 \u03c3 2 t (x ?) a p\u03b3T + 1 .\nProof. Using our alternative definition of \u03c6t which gives the equality stated in Equation 8, we know that,\nT\u2211 t=1 p\u03c6t(xt)\u2212 \u03c6t(x?)q = ? \u03b1 \u02dc a p\u03b3T + T\u2211 t=1 \u00b4 a p\u03b3t\u22121 \u2212 b p\u03b3t\u22121 + \u03c32t (x?) \u00af \u00b8 . By concavity of the square root, we have for all a \u2265 \u2212b that ? a+ b\u2212?a \u2264 b\n2 ? a . Introducing the notations at = p\u03b3t\u22121 + \u03c32t (x\n?) and bt = \u2212\u03c32t (x?), we obtain, T\u2211 t=1 p\u03c6t(xt)\u2212 \u03c6t(x?)q \u2264 a \u03b1p\u03b3T + ? \u03b1 2 T\u2211 t=1 bt? at .\nMoreover, with 0 \u2264 \u03c32t (x) \u2264 1 for all x \u2208 X , we have at \u2264 p\u03b3T + 1 and bt \u2264 0 for all t \u2264 T which gives,\nT\u2211 t=1 bt? at \u2264 \u2212 \u2211T t=1 \u03c3 2 t (x ?) a p\u03b3T + 1 ,\nleading to the inequality of Lemma 4.\nThe following lemma combines the results from Theorem 1 and Lemma 4 to derive upper bounds on the cumulative regret for the GP-MI algorithm with high probability.\nLemma 5. The cumulative regret for Algorithm 1 on f sampled from a GP satisfies the following bound for all \u03b4 > 0 and \u03b1 defined in Lemma 2,\nPr \u201d RT \u2264 5 a \u03b1C1\u03b3T + 4 ? \u03b1 \u0131 \u2265 1\u2212 \u03b4 .\nProof. Considering Theorem 1 in the case of the GP-MI algorithm and bounding\u2211T t=1 p\u03c6t(xt) \u2212 \u03c6t(x?)q with Lemma 4, we obtain the following bound on the cumulative regret incurred by GP-MI:\nPr [ RT \u2264 a \u03b1p\u03b3T \u2212 ? \u03b1\n2\n\u2211T t=1 \u03c3 2 t (x\n?) a\np\u03b3T + 1 + 4\na\n\u03b1(C1\u03b3T + 1) +\n? \u03b1\n2\n\u2211T t=1 \u03c3 2 t (x\n?)? C1\u03b3T + 1 ] \u2265 1\u2212 \u03b4 ,\nwhich simplifies to the inequality of Lemma 5 using Equation 3, and thus proves Theorem 2."}, {"heading": "5 Practical considerations and experiments", "text": ""}, {"heading": "5.1 Numerical experiments", "text": "Protocol. We compare the empirical performances of our algorithm against the stateof-the-art of GP optimization, the GP-UCB algorithm Srinivas et al. [2012], and a commonly used heuristic, the Expected Improvement (EI) algorithm with GP Jones et al. [1998]. The tasks used for assessment come from two real applications and five synthetic problems described here. For all data sets and algorithms the learners were initialized with a random subset of 10 observations {(xi, yi)}i\u226410. When the prior distribution of the underlying function was not known, the Bayesian inference was made using a squared exponential kernel. We first picked the half of the data set to estimate the hyper-parameters of the kernel via cross validation in this subset. In this way, each algorithm was running with the same prior information. The value of the parameter \u03b4 for the GP-MI and the GP-UCB algorithms was fixed to \u03b4 = 10\u22126 for all these experimental tasks. Modifying this value by several orders of magnitude is insignificant with respect to the empirical mean cumulative regret incurred by the algorithms, as discussed in Section 5.2. The results are provided in Figure 3. The curves show the evolution of the average regret RTT in term of iteration T . We report the mean value with the confidence interval over a hundred experiments.\nDescription of the data sets. We describe briefly all the data sets used for assessment.\n\u2022 Generated GP. The generated Gaussian process functions are random GPs drawn from an isotropic Mate\u0301rn kernel in dimension 2 and 4, with the kernel bandwidth set to 1 for dimension 2, and 16 for dimension 4. The Mate\u0301rn parameter was set to \u03bd = 3 and the noise standard deviation to 1% of the signal standard deviation.\n(a) Gaussian mixture (b) Himmelblau\nthe VOLNA code Dutykh et al. [2011] with the simplified geometry of a conical island sitting on a flat surface in front of a sloping beach. In the study of Stefanakis et al. [2013] the setup was controlled by five physical parameters and the aim was to find with confidence and with the least number of simulations the parameters leading to the maximum run-up amplification.\n\u2022 Mackey-Glass function. The Mackey-Glass delay-differential equation is a chaotic system in dimension 6, but without noise. It models real feedback systems and is used in physiological domains such as hematology, cardiology, neurology, and psychiatry. The highly chaotic behavior of this function makes it an exceptionally difficult optimization problem. It has been used as a benchmark for example by Flake & Lawrence [2002].\nEmpirical comparison of the algorithms. Figure 3 compares the empirical mean average regret RTT for the three algorithms. On the easy optimization assessments like the Branin data set (Fig. 3(e)) the three strategies behave in a comparable manner, but the GP-UCB algorithm incurs a larger cumulative regret. For more difficult assessments the GP-UCB algorithm performs poorly and our algorithm always surpasses the EI heuristic. The improvement of the GP-MI algorithm against the two competitors is the most significant for exceptionally challenging optimization tasks as illustrated in Figures 3(a) to 3(d) and 3(h), where the underlying functions present several local optima. The ability of our algorithm to deal with the exploration/exploitation trade-off is emphasized by these experimental results as its average regret decreases directly after the first iterations, avoiding unwanted exploration like GP-UCB on Figures 3(a) to 3(d), or getting stuck in some local optimum like EI on Figures 3(c), 3(g) and 3(h). We further mention that the GP-MI algorithm is empirically robust against the number of dimensions of the data set (Fig. 3(b), 3(g), 3(h))."}, {"heading": "5.2 Practical aspects", "text": "Calibration of \u03b1. The value of the parameter \u03b1 is chosen following Theorem 2 as \u03b1 = log 2\u03b4 with 0 < \u03b4 < 1 being a confidence parameter. The guarantees we prove in Section 4.2 on the cumulative regret for the GP-MI algorithm holds with probability at least 1 \u2212 \u03b4. With \u03b1 increasing linearly for \u03b4 decreasing exponentially toward 0, the algorithm is robust to the choice of \u03b4. We present on Figure 4 the small impact of \u03b4 on the average regret for four different values selected on a wide range.\nNumerical Complexity. Even if the numerical cost of GP-MI is insignificant in practice compared to the cost of the evaluation of f , the complexity of the sequential Bayesian update Osborne [2010] is O(T 2) and might be prohibitive for large T . One can reduce drastically the computational time by means of Lazy Variance Calculation Desautels et al. [2012], built on the fact that \u03c32T (x) always decreases for increasing T and for all x \u2208 X . We further mention that approximated inference algorithms such as the EP approximation and MCMC sampling Kuss et al. [2005] can be used as an alternative if the computational time is a restrictive factor."}, {"heading": "6 Conclusion", "text": "We introduced the GP-MI algorithm for GP optimization and prove upper bounds on its cumulative regret which improve exponentially the state-of-the-art in common settings. The theoretical analysis was presented in a generic framework in order to expand its impact to other similar algorithms. The experiments we performed on real and synthetic assessments confirmed empirically the efficiency of our algorithm against both the theoretical state-of-the-art of GP optimization, the GP-UCB algorithm, and the commonly used EI heuristic."}, {"heading": "Acknowledgements", "text": "The authors would like to thank David Buffoni and Raphae\u0308l Bonaque for fruitful discussions. The authors also thank the anonymous reviewers of the 31st International Conference on Machine Learning for their detailed feedback."}], "references": [{"title": "Bandit view on noisy optimization. In Optimization for Machine Learning, pp. 431\u2013454", "author": ["Audibert", "J-Y", "S. Bubeck", "R. Munos"], "venue": null, "citeRegEx": "Audibert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Audibert et al\\.", "year": 2011}, {"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine Learning,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Exponential inequalities for self-normalized martingales with applications", "author": ["B. Bercu", "A. Touati"], "venue": "The Annals of Applied Probability,", "citeRegEx": "Bercu and Touati,? \\Q2008\\E", "shortCiteRegEx": "Bercu and Touati", "year": 2008}, {"title": "Upperconfidence-bound algorithms for active learning in multi-armed bandits", "author": ["A. Carpentier", "A. Lazaric", "M. Ghavamzadeh", "R. Munos", "P. Auer"], "venue": "In Proceedings of the International Conference on Algorithmic Learning Theory,", "citeRegEx": "Carpentier et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Carpentier et al\\.", "year": 2011}, {"title": "Near-optimal batch mode active learning and adaptive submodular optimization", "author": ["Y. Chen", "A. Krause"], "venue": "In Proceedings of the International Conference on Machine Learning. icml.cc / Omnipress,", "citeRegEx": "Chen and Krause,? \\Q2013\\E", "shortCiteRegEx": "Chen and Krause", "year": 2013}, {"title": "Parallel Gaussian process optimization with upper confidence bound and pure exploration", "author": ["E. Contal", "D. Buffoni", "A. Robicquet", "N. Vayatis"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Contal et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Contal et al\\.", "year": 2013}, {"title": "Stochastic linear optimization under bandit feedback", "author": ["V. Dani", "T.P. Hayes", "S.M. Kakade"], "venue": "In Proceedings of the 21st Annual Conference on Learning Theory, pp", "citeRegEx": "Dani et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Dani et al\\.", "year": 2008}, {"title": "Exponential regret bounds for Gaussian process bandits with deterministic observations", "author": ["N. de Freitas", "A.J. Smola", "M. Zoghi"], "venue": "In Proceedings of the 29th International Conference on Machine Learning. icml.cc / Omnipress,", "citeRegEx": "Freitas et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Freitas et al\\.", "year": 2012}, {"title": "Parallelizing exploration-exploitation tradeoffs with Gaussian process bandit optimization", "author": ["T. Desautels", "A. Krause", "J.W. Burdick"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "Desautels et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Desautels et al\\.", "year": 2012}, {"title": "The VOLNA code for the numerical modelling of tsunami waves: generation, propagation and inundation", "author": ["D. Dutykh", "R Poncet", "F. Dias"], "venue": "European Journal of Mechanics B/Fluids,", "citeRegEx": "Dutykh et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dutykh et al\\.", "year": 2011}, {"title": "Efficient SVM regression training with SMO", "author": ["G.W. Flake", "S. Lawrence"], "venue": "Machine Learning,", "citeRegEx": "Flake and Lawrence,? \\Q2002\\E", "shortCiteRegEx": "Flake and Lawrence", "year": 2002}, {"title": "Optimization in Computational Chemistry and Molecular Biology: Local and Global Approaches", "author": ["C.A. Floudas", "P.M. Pardalos"], "venue": "Nonconvex Optimization and Its Applications. Springer,", "citeRegEx": "Floudas and Pardalos,? \\Q2000\\E", "shortCiteRegEx": "Floudas and Pardalos", "year": 2000}, {"title": "Regret bounds for Gaussian process bandit problems", "author": ["S. Grunewalder", "Audibert", "J-Y", "M. Opper", "J. Shawe-Taylor"], "venue": "In Proceedings of the International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Grunewalder et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Grunewalder et al\\.", "year": 2010}, {"title": "The 2010 Mw 7.8 Mentawai earthquake: Very shallow source of a rare tsunami earthquake determined from tsunami field survey and near-field GPS data", "author": ["E.M. Hill", "J.C. Borrero", "Z. Huang", "Q. Qiu", "P. Banerjee", "D.H. Natawidjaja", "P. Elosegui", "H.M. Fritz", "B.W. Suwargadi", "I.R. Pranantyo", "L. Li", "K.A. Macpherson", "V. Skanavis", "C.E. Synolakis", "K. Sieh"], "venue": "J. Geophys. Res.,", "citeRegEx": "Hill et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2012}, {"title": "Efficient global optimization of expensive black-box functions", "author": ["D.R. Jones", "M. Schonlau", "W.J. Welch"], "venue": "Journal of Global Optimization,", "citeRegEx": "Jones et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Jones et al\\.", "year": 1998}, {"title": "Nearly tight bounds for the continuum-armed bandit problem", "author": ["R. Kleinberg"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Kleinberg,? \\Q2004\\E", "shortCiteRegEx": "Kleinberg", "year": 2004}, {"title": "Contextual Gaussian process bandit optimization", "author": ["A. Krause", "C.S. Ong"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Krause and Ong,? \\Q2011\\E", "shortCiteRegEx": "Krause and Ong", "year": 2011}, {"title": "Approximate inference for robust Gaussian process regression", "author": ["M. Kuss", "T. Pfingsten", "L. Csat\u00f3", "C.E. Rasmussen"], "venue": "Max Planck Inst. Biological Cybern., Tubingen, GermanyTech. Rep,", "citeRegEx": "Kuss et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Kuss et al\\.", "year": 2005}, {"title": "Bayesian approach to global optimization. Mathematics and its applications", "author": ["J. Mockus"], "venue": "Kluwer Academic,", "citeRegEx": "Mockus,? \\Q1989\\E", "shortCiteRegEx": "Mockus", "year": 1989}, {"title": "Bayesian Gaussian processes for sequential prediction, optimisation and quadrature", "author": ["Osborne", "Michael"], "venue": "PhD thesis, Oxford University New College,", "citeRegEx": "Osborne and Michael.,? \\Q2010\\E", "shortCiteRegEx": "Osborne and Michael.", "year": 2010}, {"title": "Gaussian Processes for Machine Learning", "author": ["C.E. Rasmussen", "C. Williams"], "venue": null, "citeRegEx": "Rasmussen and Williams,? \\Q2006\\E", "shortCiteRegEx": "Rasmussen and Williams", "year": 2006}, {"title": "Practical bayesian optimization of machine learning algorithms", "author": ["J. Snoek", "H. Larochelle", "R.P. Adams"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Snoek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Snoek et al\\.", "year": 2012}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["N. Srinivas", "A. Krause", "S. Kakade", "M. Seeger"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Srinivas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srinivas et al\\.", "year": 2010}, {"title": "Information-theoretic regret bounds for Gaussian process optimization in the bandit setting", "author": ["N. Srinivas", "A. Krause", "S. Kakade", "M. Seeger"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Srinivas et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Srinivas et al\\.", "year": 2012}, {"title": "Long-wave runup on a plane beach behind a conical island", "author": ["T.S. Stefanakis", "F. Dias", "N. Vayatis", "S. Guillas"], "venue": "In Proceedings of the World Conference on Earthquake Engineering,", "citeRegEx": "Stefanakis et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Stefanakis et al\\.", "year": 2012}, {"title": "Can small islands protect nearby coasts from tsunamis ? An active experimental design approach", "author": ["T.S. Stefanakis", "E. Contal", "N. Vayatis", "F. Dias", "C.E. Synolakis"], "venue": "arXiv preprint arXiv:1305.7385,", "citeRegEx": "Stefanakis et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Stefanakis et al\\.", "year": 2013}, {"title": "Review of metamodeling techniques in support of engineering design optimization", "author": ["G. Wang", "S. Shan"], "venue": "Journal of Mechanical Design,", "citeRegEx": "Wang and Shan,? \\Q2007\\E", "shortCiteRegEx": "Wang and Shan", "year": 2007}, {"title": "Stochastic optimization models in finance", "author": ["W.T. Ziemba", "R.G. Vickson"], "venue": "World Scientific Singapore,", "citeRegEx": "Ziemba and Vickson,? \\Q2006\\E", "shortCiteRegEx": "Ziemba and Vickson", "year": 2006}], "referenceMentions": [{"referenceID": 12, "context": "1 Introduction Stochastic optimization problems are encountered in numerous real world domains including engineering design Wang & Shan [2007], finance Ziemba & Vickson [2006], natural sciences Floudas & Pardalos [2000], or in machine learning for selecting models by tuning the parameters of learning algorithms Snoek et al. [2012]. We aim at finding the input of a given system which optimizes the output (or reward).", "startOffset": 313, "endOffset": 333}, {"referenceID": 0, "context": "Efficient algorithms have been studied to tackle this challenge such as multiarmed bandit Auer et al. [2002], Kleinberg [2004], Bubeck et al.", "startOffset": 90, "endOffset": 109}, {"referenceID": 0, "context": "Efficient algorithms have been studied to tackle this challenge such as multiarmed bandit Auer et al. [2002], Kleinberg [2004], Bubeck et al.", "startOffset": 90, "endOffset": 127}, {"referenceID": 0, "context": "Efficient algorithms have been studied to tackle this challenge such as multiarmed bandit Auer et al. [2002], Kleinberg [2004], Bubeck et al. [2011], Audibert et al.", "startOffset": 90, "endOffset": 149}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al.", "startOffset": 8, "endOffset": 31}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al.", "startOffset": 8, "endOffset": 73}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al.", "startOffset": 8, "endOffset": 95}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al.", "startOffset": 8, "endOffset": 134}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al.", "startOffset": 8, "endOffset": 161}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al.", "startOffset": 8, "endOffset": 185}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f .", "startOffset": 8, "endOffset": 211}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP Rasmussen & Williams [2006]. Our main contribution is twofold: we propose a generic algorithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret.", "startOffset": 8, "endOffset": 592}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP Rasmussen & Williams [2006]. Our main contribution is twofold: we propose a generic algorithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret. The theoretical analysis has a direct impact on strategies built with the GP-UCB algorithm Srinivas et al. [2012] such as Krause & Ong [2011], Desautels et al.", "startOffset": 8, "endOffset": 871}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP Rasmussen & Williams [2006]. Our main contribution is twofold: we propose a generic algorithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret. The theoretical analysis has a direct impact on strategies built with the GP-UCB algorithm Srinivas et al. [2012] such as Krause & Ong [2011], Desautels et al.", "startOffset": 8, "endOffset": 899}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP Rasmussen & Williams [2006]. Our main contribution is twofold: we propose a generic algorithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret. The theoretical analysis has a direct impact on strategies built with the GP-UCB algorithm Srinivas et al. [2012] such as Krause & Ong [2011], Desautels et al. [2012], Contal et al.", "startOffset": 8, "endOffset": 924}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP Rasmussen & Williams [2006]. Our main contribution is twofold: we propose a generic algorithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret. The theoretical analysis has a direct impact on strategies built with the GP-UCB algorithm Srinivas et al. [2012] such as Krause & Ong [2011], Desautels et al. [2012], Contal et al. [2013]. We suggest an alternative policy which achieves an exponential speed up with respect to the cumulative regret.", "startOffset": 8, "endOffset": 946}, {"referenceID": 22, "context": "We consider the normalized and dimensionless framework introduced by Srinivas et al. [2010] where the variance is assumed to be bounded, that is k(x, x) \u2264 1 for all x \u2208 X .", "startOffset": 69, "endOffset": 92}, {"referenceID": 22, "context": "We consider the normalized and dimensionless framework introduced by Srinivas et al. [2010] where the variance is assumed to be bounded, that is k(x, x) \u2264 1 for all x \u2208 X . Bayesian inference. At iteration T + 1, given the previously observed noisy values YT at locations XT , we use Bayesian inference to compute the current posterior distribution Rasmussen & Williams [2006], which is a GP of mean \u03bcT+1 and variance \u03c3 T+1 given at any x \u2208 X by, \u03bcT+1(x) = kT (x) >C\u22121 T YT (1) and \u03c3 T+1(x) = k(x, x)\u2212 kT (x)>C\u22121 T kT (x) , (2) where kT (x) = [k(xt, x)]xt\u2208XT is the vector of covariances between x and the query points at time T , and CT = KT +\u03c3I with KT = [k(xt, xt\u2032)]xt,xt\u2032\u2208XT the kernel matrix, \u03c3 is the variance of the noise and I stands for the identity matrix.", "startOffset": 69, "endOffset": 377}, {"referenceID": 22, "context": "In the GP-UCB algorithm from Srinivas et al. [2012] the exploration coefficient is aO(log t) and therefore tends to infinity.", "startOffset": 29, "endOffset": 52}, {"referenceID": 22, "context": "4 in Srinivas et al. [2012]):", "startOffset": 5, "endOffset": 28}, {"referenceID": 21, "context": "In this setting, the maximum mutual information \u03b3T satisfies the upper bound \u03b3T = Op(log T )q, where d is the dimension of the input space Srinivas et al. [2012]. Corollary 1.", "startOffset": 139, "endOffset": 162}, {"referenceID": 6, "context": "Hence there is no contradiction with the lower bounds stated for linear bandit like those of Dani et al. [2008]. We refer to Srinivas et al.", "startOffset": 93, "endOffset": 112}, {"referenceID": 6, "context": "Hence there is no contradiction with the lower bounds stated for linear bandit like those of Dani et al. [2008]. We refer to Srinivas et al. [2012] for the analysis of \u03b3T with other kernels widely used in practice.", "startOffset": 93, "endOffset": 148}, {"referenceID": 21, "context": "We compare the empirical performances of our algorithm against the stateof-the-art of GP optimization, the GP-UCB algorithm Srinivas et al. [2012], and a commonly used heuristic, the Expected Improvement (EI) algorithm with GP Jones et al.", "startOffset": 124, "endOffset": 147}, {"referenceID": 14, "context": "[2012], and a commonly used heuristic, the Expected Improvement (EI) algorithm with GP Jones et al. [1998]. The tasks used for assessment come from two real applications and five synthetic problems described here.", "startOffset": 87, "endOffset": 107}, {"referenceID": 21, "context": "This benchmark is one of the two synthetic functions used by Srinivas et al. [2012] to evaluate the empirical performances of the GP-UCB algorithm.", "startOffset": 61, "endOffset": 84}, {"referenceID": 21, "context": "This benchmark is one of the two synthetic functions used by Srinivas et al. [2012] to evaluate the empirical performances of the GP-UCB algorithm. No noise has been added to the original signal in this experimental task. \u2022 Goldstein-Price. The Goldstein & Price function is an other benchmark function for global optimization, with a single global optimum but several local optima in the 2-D square [\u22122, 2]\u00d7 [\u22122, 2]. This is the second synthetic benchmark used by Srinivas et al. [2012]. Like in the previous challenge, no noise has been added to the original signal.", "startOffset": 61, "endOffset": 488}, {"referenceID": 13, "context": "Recent post-tsunami survey data as well as the numerical simulations of Hill et al. [2012] have shown that in some cases the run-up, which is the maximum vertical extent of wave climbing on a beach, in areas which were supposed to be protected by small islands in the vicinity of coast, was significantly higher than in neighboring locations.", "startOffset": 72, "endOffset": 91}, {"referenceID": 13, "context": "Recent post-tsunami survey data as well as the numerical simulations of Hill et al. [2012] have shown that in some cases the run-up, which is the maximum vertical extent of wave climbing on a beach, in areas which were supposed to be protected by small islands in the vicinity of coast, was significantly higher than in neighboring locations. Motivated by these observations Stefanakis et al. [2012] investigated this phenomenon by employing numerical simulations using", "startOffset": 72, "endOffset": 400}, {"referenceID": 9, "context": "the VOLNA code Dutykh et al. [2011] with the simplified geometry of a conical island sitting on a flat surface in front of a sloping beach.", "startOffset": 15, "endOffset": 36}, {"referenceID": 9, "context": "the VOLNA code Dutykh et al. [2011] with the simplified geometry of a conical island sitting on a flat surface in front of a sloping beach. In the study of Stefanakis et al. [2013] the setup was controlled by five physical parameters and the aim was to find with confidence and with the least number of simulations the parameters leading to the maximum run-up amplification.", "startOffset": 15, "endOffset": 181}, {"referenceID": 9, "context": "the VOLNA code Dutykh et al. [2011] with the simplified geometry of a conical island sitting on a flat surface in front of a sloping beach. In the study of Stefanakis et al. [2013] the setup was controlled by five physical parameters and the aim was to find with confidence and with the least number of simulations the parameters leading to the maximum run-up amplification. \u2022 Mackey-Glass function. The Mackey-Glass delay-differential equation is a chaotic system in dimension 6, but without noise. It models real feedback systems and is used in physiological domains such as hematology, cardiology, neurology, and psychiatry. The highly chaotic behavior of this function makes it an exceptionally difficult optimization problem. It has been used as a benchmark for example by Flake & Lawrence [2002].", "startOffset": 15, "endOffset": 802}, {"referenceID": 8, "context": "One can reduce drastically the computational time by means of Lazy Variance Calculation Desautels et al. [2012], built on the fact that \u03c3 T (x) always decreases for increasing T and for all x \u2208 X .", "startOffset": 88, "endOffset": 112}, {"referenceID": 8, "context": "One can reduce drastically the computational time by means of Lazy Variance Calculation Desautels et al. [2012], built on the fact that \u03c3 T (x) always decreases for increasing T and for all x \u2208 X . We further mention that approximated inference algorithms such as the EP approximation and MCMC sampling Kuss et al. [2005] can be used as an alternative if the computational time is a restrictive factor.", "startOffset": 88, "endOffset": 322}], "year": 2015, "abstractText": "In this paper, we analyze a generic algorithm scheme for sequential global optimization using Gaussian processes. The upper bounds we derive on the cumulative regret for this generic algorithm improve by an exponential factor the previously known bounds for algorithms like GP-UCB. We also introduce the novel Gaussian Process Mutual Information algorithm (GP-MI), which significantly improves further these upper bounds for the cumulative regret. We confirm the efficiency of this algorithm on synthetic and real tasks against the natural competitor, GP-UCB, and also the Expected Improvement heuristic. Preprint for the 31st International Conference on Machine Learning (ICML 2014) 1 ar X iv :1 31 1. 48 25 v3 [ st at .M L ] 8 J un 2 01 5 Erratum After the publication of our article, we found an error in the proof of Lemma 1 which invalidates the main theorem. It appears that the information given to the algorithm is not sufficient for the main theorem to hold true. The theoretical guarantees would remain valid in a setting where the algorithm observes the instantaneous regret instead of noisy samples of the unknown function. We describe in this page the mistake and its consequences. Let f : X \u2192 R be the unknown function to be optimized, which is a sample from a Gaussian process. Let\u2019s fix x, x1, . . . , xT \u2208 X and the observations yt = f(xt)+ t where the noise variables t are independent Gaussian noise N (0, \u03c3). We define the instantaneous regret rt = f(x?)\u2212 f(xt) and, MT = T \u2211", "creator": "LaTeX with hyperref package"}}}