{"id": "1311.4987", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Nov-2013", "title": "Analyzing Evolutionary Optimization in Noisy Environments", "abstract": "Many optimization tasks shurab-e have to be proprioceptive handled in slaveholding noisy daroca environments, medicaid where congressperson we cannot obtain the exact ornl evaluation darters of eurhythmics a disestablish solution seydel but only guangjing a noisy one. depressaria For noisy hilfe optimization tasks, post-impressionism evolutionary algorithms (ionica EAs ), missi a forties kind shale of stochastic moughniyah metaheuristic search pembangunan algorithm, driveshaft have syngnathidae been euro497 widely and multihit successfully applied. Previous peyrefitte work maxse mainly focuses on empirical karelians studying and designing leeson EAs for noisy monopulse optimization, commemorate while, gekkonidae the theoretical counterpart has been little 1967-1972 investigated. In kolm this garcia paper, we investigate cabez\u00f3n a offside largely ignored 29,028 question, i. \u9547 e. , whether guias an optimization problem will gemworld always claritas become maill\u00e9 harder cctv-1 for senning EAs campbell-brown in rompetrol a kubin noisy motorcross environment. We cirino prove finansbank that daini the upnp answer spano is negative, br\u00f8nsted with respect rajshahi to the measurement samyutta of holkars the expected jandola running wiegel time. The result 1978-80 implies contango that, ceu for haversack optimization cinco tasks biloba that gamon have mullioned already been quite 200-300 hard duh to artiodactyl solve, the alejandrina noise may not have natha a reparable negative ledes effect, broaddrick and wolfeboro the easier a floridian task the more 137.1 negatively intiatives affected mercexchange by craigslist.org the noise. On insubria a representative labus problem vik where 39.16 the chapoutier noise has a 0.07 strong gathercole negative effect, rebuke we examine two 280-mile commonly rezaei employed mechanisms in 1.2922 EAs dealing donghua with noise, walkabouts the pietri re - andrych\u00f3w evaluation and bonaire the zindabad threshold oatlands selection strategies. schierholtz The 3-feet analysis discloses ages that fujimi the immeasurably two strategies, hechinger however, both are conghou not effective, sherif i. e. , co-heiresses they do not make beledweyn the virulent EA more noise tolerant. sakib We odawara then valerien find 30-day that .990 a small modification sonicstage of the threshold tuerk selection 59.34 allows coefficient it to brockhouse be moderne proven pelje\u0161ac as an boorish effective strategy squadriglia for insas dealing 48.75 with 53-44 the noise panruti in deduplication the problem.", "histories": [["v1", "Wed, 20 Nov 2013 09:28:52 GMT  (275kb,D)", "http://arxiv.org/abs/1311.4987v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.NE", "authors": ["chao qian", "yang yu", "zhi-hua zhou"], "accepted": false, "id": "1311.4987"}, "pdf": {"name": "1311.4987.pdf", "metadata": {"source": "CRF", "title": "Analyzing Evolutionary Optimization in Noisy Environments", "authors": ["Chao Qian", "Yang Yu", "Zhi-Hua Zhou"], "emails": ["qianc@lamda.nju.edu.cn", "yuy@nju.edu.cn", "zhouzh@nju.edu.cn"], "sections": [{"heading": null, "text": "Many optimization tasks have to be handled in noisy environments, where we cannot obtain the exact evaluation of a solution but only a noisy one. For noisy optimization tasks, evolutionary algorithms (EAs), a kind of stochastic metaheuristic search algorithm, have been widely and successfully applied. Previous work mainly focuses on empirical studying and designing EAs for noisy optimization, while, the theoretical counterpart has been little investigated. In this paper, we investigate a largely ignored question, i.e., whether an optimization problem will always become harder for EAs in a noisy environment. We prove that the answer is negative, with respect to the measurement of the expected running time. The result implies that, for optimization tasks that have already been quite hard to solve, the noise may not have a negative effect, and the easier a task the more negatively affected by the noise. On a representative problem where the noise has a strong negative effect, we examine two commonly employed mechanisms in EAs dealing with noise, the re-evaluation and the threshold selection strategies. The analysis discloses that the two strategies, however, both are not effective, i.e., they do not make the EA more noise tolerant. We then find that a small modification of the threshold selection allows it to be proven as an effective strategy for dealing with the noise in the problem.\nKey words: Noisy optimization, evolutionary algorithms, re-evaluation, threshold selection, running time, computational complexity\n\u2217Corresponding author Email addresses: qianc@lamda.nju.edu.cn (Chao Qian), yuy@nju.edu.cn (Yang Yu), zhouzh@nju.edu.cn (Zhi-Hua\nZhou)\nPreprint submitted for review November 21, 2013\nar X\niv :1\n31 1.\n49 87\nv1 [\ncs .A\nI] 2\n0 N\nov 2\n01 3"}, {"heading": "1. Introduction", "text": "Optimization tasks often encounter noisy environments. For example, in airplane design, every prototype is evaluated by simulations so that the evaluation result may not be perfect due to the simulation error; and in machine learning, a prediction model is evaluated only on a limited amount of data so that the estimated performance is shifted from the true performance. Noisy environments could change the property of an optimization problem, thus traditional optimization techniques may have low efficacy. While, evolutionary algorithms (EAs) [4] have been widely and successfully adopted for noisy optimization tasks [15, 22, 9, 8].\nEAs are a kind of randomized metaheuristic optimization algorithms, inspired by natural phenomena including evolution of species, swarm cooperation, immune system, etc. EAs typically involve a cycle of three stages: reproduction stage produces new solutions based on the currently maintained solutions; evaluation stage evaluates the newly generated solutions; selection stage wipes out bad solutions. An inspiration of using EAs for noisy optimization is that the corresponding natural phenomena have been processed successfully in noisy environments, and hence the algorithmic simulations are also likely to be able to handle noise. Besides, improved mechanisms have been invented for better handling noise. Two representative strategies are re-evaluation and threshold selection: by the re-evaluation strategy [21, 16], whenever the fitness (also called cost or objective value) of a solution is required, EAs make an independent evaluation of the solution despite of whether the solution has been evaluated before, such that the fitness is smoothed; by the threshold selection strategy [23, 6, 5], in the selection stage EAs accept a newly generated solution only if its fitness is larger than the fitness of the old solution by at least a threshold, such that the risk of accepting a bad solution due to noise is reduced.\nAn assumption implied by using a noise handling mechanism in EAs is that the noise makes the optimization harder, so that a better handling mechanism can reduce the negative effect by the noise [13, 7, 26, 3]. This paper firstly investigates if this assumption is true. We start by presenting an experimental evidence using (1+1)-EA optimizing the hardest case in the pseudo-Boolean function class [25]. Experiment results indicate that the noise, however, makes the optimization easier rather than harder, under the measurement of expected running time.\nFollowing the experiment evidence, we then derive sufficient theoretical conditions, under which the noise will make the optimization easier or harder. By filling the conditions, we present proofs that, for the (1+\u03bb)-EA (a class of EAs employing offspring population size \u03bb), the noise will make the optimization easier on the hardest case in the pseudo-Boolean function class, while harder on the easiest case. The proofs imply that we need to take care of the noise only when the optimization is moderately or less complex, and ignore this issue when the optimization task itself is quite hard.\nFor the situations where the noise needs to be cared, this paper examines the re-evaluation and the threshold selection strategies for their polynomial noise tolerance (PNT). For a kind of noise, the PNT of an EA is the maximum noise level such that the expected running time of the algorithm is polynomial. The closer the PNT is to 1, the better the noise tolerance is. Taking the easiest pseudo-Boolean function case as the representative problem, we analyze the PNT for different configurations of the (1+1)-EA with respect to the one-bit noise, whose level is characterized by the noise probability. For the (1+1)-EA (without any noise handling strategy), we prove that the PNT has a lower bound 1 \u2212 1\u2126(poly(n)) and an upper bound 1 \u2212 1 O(2npoly(n)) . Since the (1+1)-EA with re-evaluation has the PNT \u0398( lognn ) [10], it is surprisingly that the re-evaluation makes the PNT much worse. We further prove that for the (1+1)-EA with re-evaluation using threshold selection, when the threshold is 1, the PNT is not less than 12e , and when the threshold is 2, the PNT has a lower bound 1 \u2212 1 \u2126(poly(n)) and an upper bound 1 \u2212 1O(2npoly(n)) . The PNT bounds indicate that threshold selection improves the re-evaluation strategy, however, no improvements from the (1+1)-EA are found. We then introduce a small modification into the threshold selection strategy to turn the original hard threshold to be a smooth threshold. We prove that with the smooth threshold selection strategy the PNT is 1, i.e., the (1+1)-EA is always a polynomial algorithm disregard the probability of one-bit noise on the problem.\nThe rest of this paper is organized as follows. Section 2 introduces some background. Section 3 shows that the noise may not always be bad, and presents a sufficient condition for that. Section 4 analyzes noise handling strategies. Section 5 concludes."}, {"heading": "2. Background", "text": ""}, {"heading": "2.1. Noisy Optimization", "text": "A general optimization problem can be represented as arg maxx f(x), where the objective f is also called fitness in the context of evolutionary computation. In real-world optimization tasks, the fitness evaluation for a solution is usually disturbed by noise, and consequently we can not obtain the exact fitness value but only a noisy one. In this paper, we will involve the following kinds of noise, and we will always denote fN (x) and f(x) as the noisy and true fitness of a solution x, respectively.\nadditive noise fN (x) = f(x) + \u03b4, where \u03b4 is uniformly selected from [\u03b41, \u03b42] at random.\nmultiplicative noise fN (x) = f(x) \u00b7 \u03b4, where \u03b4 is uniformly selected from [\u03b41, \u03b42] at random.\none-bit noise fN (x) = f(x) with probability (1\u2212 pn) (0 \u2264 pn \u2264 1); otherwise, fN (x) = f(x\u2032), where\nx\u2032 is generated by flipping a uniformly randomly chosen bit of x \u2208 {0, 1}n. This noise is for problems where solutions are represented in binary strings.\nAdditive and multiplicative noise has been often used for analyzing the effect of noise [7, 21]. Onebit noise is specifically for optimizing pseudo-Boolean problems over {0, 1}n, and also the investigated noise in the only previous work for analyzing running time of EAs in noisy optimization [10]. For one-bit noise, pn controls the noise level. In this paper we assume that the parameters of the environment (i.e., pn, \u03b41 and \u03b42) do not change over time.\nIt is possible that a large noise could make an optimization problem extremely hard for particular algorithms. We are interested in the noise level, under which an algorithm could be \u201ctolerant\u201d to have polynomial running time. We define the polynomial noise tolerance (PNT) as Definition 1, which characterizes the maximum noise level for allowing a polynomial expected running time. Note that, the noise level can be measured by the adjusting parameter, e.g., \u03b41, \u03b42 for the additive and multiplicative noise, and pn for the one-bit noise. We will study the PNT of EAs for analyzing the effectiveness of noise handling strategies.\nDefinition 1 (Polynomial Noise Tolerance (PNT)) The polynomial noise tolerance of an algorithm on a problem, with respect to a kind of noise, is the maximum noise level such that the algorithm has expected running time polynomial to the problem size."}, {"heading": "2.2. Evolutionary Algorithms", "text": "Evolutionary algorithms (EAs) [4] are a kind of population-based metaheuristic optimization algorithms. Although there exist many variants, the common procedure of EAs can be described as follows:\n1. Generate an initial set of solutions (called population); 2. Reproduce new solutions from the current population; 3. Evaluate the newly generated solutions; 4. Update the population by removing bad solutions; 5. Repeat steps 2-5 until some criterion is met.\nThe (1+1)-EA, as in Algorithm 1, is a simple EA for maximizing pseudo-Boolean problems over {0, 1}n, which reflects the common structure of EAs. It maintains only one solution, and repeatedly improves the current solution by using bit-wise mutation (i.e., the 3rd step of Algorithm 1). It has been widely used for the running time analysis of EAs, e.g., [17, 12].\nAlgorithm 1 ((1+1)-EA) Given pseudo-Boolean function f with solution length n, it consists of the following steps:\n1. x := randomly selected from {0, 1}n. 2. Repeat until the termination condition is met 3. x\u2032 := flip each bit of x with probability p. 4. if f(x\u2032) \u2265 f(x)\n5. x := x\u2032. where p \u2208 (0, 0.5) is the mutation probability.\nThe (1+\u03bb)-EA, as in Algorithm 2, applies an offspring population size \u03bb. In each iteration, it first generates \u03bb offspring solutions by independently mutating the current solution \u03bb times, and then selects the best solution from the current solution and the offspring solutions as the next solution. It has been used to disclose the effect of offspring population size by running time analysis [20, 24]. Note that, (1+1)-EA is a special case of (1+\u03bb)-EA with \u03bb = 1.\nAlgorithm 2 ((1+\u03bb)-EA) Given pseudo-Boolean function f with solution length n, it consists of the following steps:\n1. x := randomly selected from {0, 1}n. 2. Repeat until the termination condition is met 3. i := 1. 4. Repeat until i > \u03bb. 5. xi := flip each bit of x with probability p. 6. i := i+ 1. 7. x = arg maxx\u2032\u2208{x,x1,...,x\u03bb} f(x \u2032).\nwhere p \u2208 (0, 0.5) is the mutation probability.\nThe running time of EAs is usually defined as the number of fitness evaluations (i.e., computing f(\u00b7)) until an optimal solution is found for the first time, since the fitness evaluation is the computational process with the highest cost of the algorithm [17, 28]."}, {"heading": "2.3. Markov Chain Modeling", "text": "We will analyze EAs by modeling them as Markov chains in this paper. Here, we first give some preliminaries.\nEAs generate solutions only based on their currently maintained solutions, thus, they can be modeled and analyzed as Markov chains, e.g., [17, 28]. A Markov chain {\u03bet}+\u221et=0 modeling an EA is constructed by taking the EA\u2019s population space X as the chain\u2019s state space, i.e. \u03bet \u2208 X . Let X \u2217 \u2282 X denote the set of all optimal populations, which contains at least one optimal solution. The goal\nof the EA is to reach X \u2217 from an initial population. Thus, the process of an EA seeking X \u2217 can be analyzed by studying the corresponding Markov chain.\nA Markov chain {\u03bet}+\u221et=0 (\u03bet \u2208 X ) is a random process, where \u2200t \u2265 0, \u03bet+1 depends only on \u03bet. A Markov chain {\u03bet}+\u221et=0 is said to be homogeneous, if \u2200t \u2265 0,\u2200x, y \u2208 X :\nP (\u03bet+1 = y|\u03bet = x) = P (\u03be1 = y|\u03be0 = x). (1)\nIn this paper, we always denoteX andX \u2217 as the state space and the optimal state space of a Markov chain, respectively.\nGiven a Markov chain {\u03bet}+\u221et=0 and \u03bet\u0302 = x, we define the first hitting time (FHT) of the chain as a random variable \u03c4 such that \u03c4 = min{t|\u03bet\u0302+t \u2208 X \u2217, t \u2265 0}. That is, \u03c4 is the number of steps needed to reach the optimal state space for the first time starting from \u03bet\u0302 = x. The mathematical expectation\nof \u03c4 , E[[\u03c4 |\u03bet\u0302 = x]] = \u2211\u221e i=0 iP (\u03c4 = i), is called the expected first hitting time (EFHT) of this chain\nstarting from \u03bet\u0302 = x. If \u03be0 is drawn from a distribution \u03c00, E[[\u03c4 |\u03be0 \u223c \u03c00]] = \u2211 x\u2208X \u03c00(x)E[[\u03c4 |\u03be0 = x]] is called the expected first hitting time of the Markov chain over the initial distribution \u03c00.\nFor the corresponding EA, the running time is the numbers of calls to the fitness function until meeting an optimal solution for the first time. Thus, the expected running time starting from \u03be0 and that starting from \u03be0 \u223c \u03c00 are respectively equal to\nN1 +N2 \u00b7 E[[\u03c4 |\u03be0]] and N1 +N2 \u00b7 E[[\u03c4 |\u03be0 \u223c \u03c00]], (2)\nwhereN1 andN2 are the number of fitness evaluations for the initial population and each iteration, respectively. For example, for (1+1)-EA, N1 = 1 and N2 = 1; for (1+\u03bb)-EA, N1 = 1 and N2 = \u03bb. Note that, when involving the expected running time of an EA on a problem in this paper, if the initial population is not specified, it is the expected running time starting from a uniform initial\ndistribution \u03c0u, i.e., N1 +N2 \u00b7 E[[\u03c4 |\u03be0 \u223c \u03c0u]] = N1 +N2 \u00b7 \u2211 x\u2208X 1 |X |E[[\u03c4 |\u03be0 = x]].\nThe following two lemmas on the EFHT of Markov chains [14] will be used in this paper.\nLemma 1 Given a Markov chain {\u03bet}+\u221et=0 , we have\n\u2200x \u2208 X \u2217 : E[[\u03c4 |\u03bet = x]] = 0; \u2200x /\u2208 X \u2217 : E[[\u03c4 |\u03bet = x]] = 1 + \u2211\ny\u2208X P (\u03bet+1 = y|\u03bet = x)E[[\u03c4 |\u03bet+1 = y]].\nLemma 2 Given a homogeneous Markov chain {\u03bet}+\u221et=0 , it holds\n\u2200t1, t2 \u2265 0, x \u2208 X : E[[\u03c4 |\u03bet1 = x]] = E[[\u03c4 |\u03bet2 = x]].\nFor analyzing the EFHT of Markov chains, drift analysis [17, 18] is a commonly used tool, which will also be used in this paper. To use drift analysis, it needs to construct a function V (x) (x \u2208 X ) to measure the distance of a state x to the optimal state space X \u2217. The distance function V (x) satisfies that V (x \u2208 X \u2217) = 0 and V (x /\u2208 X \u2217) > 0. Then, by investigating the progress on the distance to X \u2217 in each step, i.e., E[[V (\u03bet)\u2212 V (\u03bet+1)|\u03bet]], an upper (lower) bound of the EFHT can be derived through dividing the initial distance by a lower (upper) bound of the progress.\nLemma 3 (Drift Analysis [17, 18]) Given a Markov chain {\u03bet}+\u221et=0 and a distance function V (x), if it satisfies that for any t \u2265 0 and any \u03bet with V (\u03bet) > 0,\n0 < cl \u2264 E[[V (\u03bet)\u2212 V (\u03bet+1)|\u03bet]] \u2264 cu,\nthen the EFHT of this chain satisfies that\nV (\u03be0)/cu \u2264 E[[\u03c4 |\u03be0]] \u2264 V (\u03be0)/cl,\nwhere cl, cu are constants."}, {"heading": "2.4. Pseudo-Boolean Functions", "text": "The pseudo-Boolean function class in Definition 2 is a large function class which only requires the solution space to be {0, 1}n and the objective space to be R. Many well-known NP-hard problems (e.g., the vertex cover problem and the 0-1 knapsack problem) belong to this class. Diverse pseudoBoolean problems with different structures and difficulties have been used for analyzing the running time of EAs, and then to disclose properties of EAs, e.g., [11, 17, 12]. Note that, we consider only maximization problems in this paper since minimizing f is equivalent to maximizing\u2212f .\nDefinition 2 (Pseudo-Boolean Function) A function in the pseudo-Boolean function class has the form: f : {0, 1}n \u2192 R.\nIhardest (or called Trap) problem in Definition 3 is a special instance in this class, which is to maximize the number of 0 bits of a solution except the global optimum 11 . . . 1 (briefly denoted as 1n). Its optimal function value is 2n, and the function value for any non-optimal solution is not larger than 0. It has been widely used in the theoretical analysis of EAs, and the expected running time of (1+1)-EA with mutation probability 1n has been proved to be \u0398(n n) [12]. It has also been recognized as the hardest instance in the pseudo-Boolean function class with a unique global optimum for the (1+1)-EA [25].\nDefinition 3 (Ihardest Problem) Ihardest Problem of size n is to find an n bits binary string x\u2217 such that\nx\u2217 = arg maxx\u2208{0,1}n ( f(x) = 3n \u220fn i=1 xi \u2212 \u2211n i=1 xi ) ,\nwhere xi is the i-th bit of a solution x \u2208 {0, 1}n.\nIeasiest (or called OneMax) problem in Definition 4 is to maximize the number of 1 bits of a solution. The optimal solution is 1n, which has the maximal function value n. The running time of EAs has been well studied on this problem [17, 12, 27]. Particularly, the expected running time of (1+1)-EA with mutation probability 1n on it has been proved to be \u0398(n log n) [12]. It has also been recognized as the easiest instance in the pseudo-Boolean function class with a unique global optimum for the (1+1)-EA [25].\nDefinition 4 (Ieasiest Problem) Ieasiest Problem of size n is to find an n bits binary string x\u2217 such that\nx\u2217 = arg maxx\u2208{0,1}n ( f(x) = \u2211n i=1 xi ) ,\nwhere xi is the i-th bit of a solution x \u2208 {0, 1}n."}, {"heading": "3. Noise is Not Always Bad", "text": ""}, {"heading": "3.1. Empirical Evidence", "text": "It has been observed that noisy fitness evaluation can make an optimization harder for EAs, since it may make a bad solution have a \u201cbetter\u201d fitness, and then mislead the search direction of EAs. Droste [10] proved that the running time of (1+1)-EA can increase from polynomial to exponential due to the presence of noise. However, when studying the running time of (1+1)-EA solving the hardest case Ihardest in the pseudo-Boolean function class, we have observed oppositely that noise can also make an optimization easier for EAs, which means that the presence of the noise decreases the running time of EAs for finding the optimal solution.\nFor Ihardest problem over {0, 1}n, there are 2n possible solutions, which are denoted by their corresponding integer values 0, 1, . . . , 2n\u22121, respectively. Then, we estimate the expected running time of (1+1)-EA maximizing Ihardest when starting from every solution. For each initial solution, we repeat independent runs for 1000 times, and then the average running time is recorded as an estimation of the expected running time (briefly called as ERT). We run (1+1)-EA without noise, with additive noise and with multiplicative noise, respectively. For the mutation probability of (1+1)-EA, we use the common setting p = 1n . For additive noise, \u03b41 = \u2212n and \u03b42 = n, and for multiplicative noise, \u03b41 = 0.1 and \u03b42 = 10. The results for n = 3, 4, 5 are plotted in Figure 1. We can observe that the curves by these two kinds of noise are always under the curve without noise, which shows that Ihardest problem becomes easier for (1+1)-EA in a noisy environment. Note that, the three curves meet at the last point, since the initial solution 2n \u2212 1 is the optimal solution and then ERT = 1."}, {"heading": "3.2. A Sufficient Condition", "text": "In this section, by comparing the expected running time of EAs with and without noise, we derive a sufficient condition under which the noise will make an optimization easier for EAs.\nMost practical EAs employ time-invariant operators, thus we can model an EA without noise by a homogeneous Markov chain. While for an EA with noise, since noise may change over time, we can just model it by a Markov chain. Note that, the two EAs with and without noise are different only on whether the fitness evaluation is disturbed by noise, thus, they must have the same values onN1 and N2 for their running time Eq.2. Then, comparing their expected running time is equivalent to comparing the EFHT of their corresponding Markov chains.\nWe first define a partition of the state space of a homogeneous Markov chain based on the EFHT, and then define a jumping probability of a Markov chain from one state to one state space in one step. It is easy to see that X0 in Definition 5 is just X \u2217, since E[[\u03c4 |\u03be0 \u2208 X \u2217]] = 0.\nDefinition 5 (EFHT-Partition) For a homogeneous Markov chain {\u03bet}+\u221et=0 , the EFHT-Partition is a partition of X into non-empty subspaces {X0,X1, . . . ,Xm} such that\n(1) \u2200x, y \u2208 Xi,E[[\u03c4 |\u03be0 = x]] = E[[\u03c4 |\u03be0 = y]]; (2) E[[\u03c4 |\u03be0 \u2208 X0]] < E[[\u03c4 |\u03be0 \u2208 X1]] < . . . < E[[\u03c4 |\u03be0 \u2208 Xm]].\nDefinition 6 For a Markov chain {\u03bet}+\u221et=0 , P t\u03be (x,X \u2032) = \u2211 y\u2208X \u2032 P (\u03bet+1 = y|\u03bet = x) is the probability of jumping from state x to state space X \u2032 \u2286 X in one step at time t.\nTheorem 1 Given an EA A and a problem f , let a Markov chain {\u03bet}+\u221et=0 and a homogeneous Markov chain {\u03be\u2032t}+\u221et=0 modelA running on f with noise and without noise respectively, and denote {X0,X1, . . . ,Xm} as the EFHT-Partition of {\u03be\u2032t}+\u221et=0 , if for all t \u2265 0, x \u2208 X \u2212 X0, and for all integers i \u2208 [0,m\u2212 1],\u2211i j=0 P t\u03be (x,Xj) \u2265 \u2211i j=0 P t\u03be\u2032(x,Xj), (3)\nthen noise makes f easier forA, i.e., for all x \u2208 X ,\nE[[\u03c4 |\u03be0 = x]] \u2264 E[[\u03c4 \u2032|\u03be\u20320 = x]].\nThe condition of this theorem (i.e., Eq.3) intuitively means that the presence of noise leads to a larger probability of jumping into good states (i.e., Xj with small j values), starting from which the EA needs less time for finding the optimal solution. For the proof, we need the following lemma, which is proved in the appendix.\nLemma 4 Let m (m \u2265 1) be an integer. If it satisfies that\n(1) \u22000 \u2264 i \u2264 m,Pi, Qi \u2265 0, and \u2211m\ni=0 Pi = \u2211m i=0 Qi = 1;\n(2) 0 \u2264 E0 < E1 < . . . < Em; (3) \u22000 \u2264 k \u2264 m\u2212 1, \u2211k\ni=0 Pi \u2264 \u2211k i=0 Qi,\nthen it holds that \u2211m i=0 Pi \u00b7 Ei \u2265 \u2211m i=0 Qi \u00b7 Ei.\nProof of Theorem 1. We use Lemma 3 to derive a bound on E[[\u03c4 |\u03be0]], based on which this theorem holds.\nFor using Lemma 3 to analyze E[[\u03c4 |\u03be0]], we first construct a distance function V (x) as\n\u2200x \u2208 X , V (x) = E[[\u03c4 \u2032|\u03be\u20320 = x]], (4)\nwhich satisfies that V (x \u2208 X \u2217) = 0 and V (x /\u2208 X \u2217) > 0 by Lemma 1.\nThen, we investigate E[[V (\u03bet)\u2212 V (\u03bet+1)|\u03bet = x]] for any x with V (x) > 0 (i.e., x /\u2208 X \u2217).\nE[[V (\u03bet)\u2212 V (\u03bet+1)|\u03bet = x]] = V (x)\u2212 E[[V (\u03bet+1)|\u03bet = x]] = V (x)\u2212 \u2211\ny\u2208X P (\u03bet+1 = y|\u03bet = x)V (y)\n= E[[\u03c4 \u2032|\u03be\u20320 = x]]\u2212 \u2211\ny\u2208X P (\u03bet+1 = y|\u03bet = x)E[[\u03c4 \u2032|\u03be\u20320 = y]] (by Eq.4)\n= 1 + \u2211\ny\u2208X P (\u03be\u20321 = y|\u03be\u20320 = x)E[[\u03c4 \u2032|\u03be\u20321 = y]]\u2212 \u2211 y\u2208X P (\u03bet+1 = y|\u03bet = x)E[[\u03c4 \u2032|\u03be\u20320 = y]] (by Lemma 1)\n= 1 + \u2211\ny\u2208X P (\u03be\u2032t+1 = y|\u03be\u2032t = x)E[[\u03c4 \u2032|\u03be\u20320 = y]]\u2212 \u2211 y\u2208X P (\u03bet+1 = y|\u03bet = x)E[[\u03c4 \u2032|\u03be\u20320 = y]]\n(by Eq.1 and Lemma 2, since {\u03be\u2032t}+\u221et=0 is homogeneous.) = 1 + \u2211m\nj=0 (P t\u03be\u2032(x,Xj)\u2212 P t\u03be (x,Xj))E[[\u03c4 \u2032|\u03be\u20320 \u2208 Xj ]]. (by Definitions 5 and 6)\nSince \u2211m j=0 P t \u03be (x,Xj) = \u2211m j=0 P t \u03be\u2032(x,Xj) = 1, E[[\u03c4 \u2032|\u03be\u20320 \u2208 Xj ]] increases with j and Eq.3 holds, by Lemma 4, we have\u2211m j=0 P t\u03be\u2032(x,Xj)E[[\u03c4 \u2032|\u03be\u20320 \u2208 Xj ]] \u2265 \u2211m j=0 P t\u03be (x,Xj)E[[\u03c4 \u2032|\u03be\u20320 \u2208 Xj ]].\nThus, we have, for all t \u2265 0, all x /\u2208 X \u2217,\nE[[V (\u03bet)\u2212 V (\u03bet+1)|\u03bet = x]] \u2265 1.\nThus, by Lemma 3, we get for all x \u2208 X ,\nE[[\u03c4 |\u03be0 = x]] \u2264 V (x) = E[[\u03c4 \u2032|\u03be\u20320 = x]], (the \u2018=\u2019 is by Eq.4)\nwhich implies that noise leads to less time for finding the optimal solution, i.e., noise makes optimization easier.\nWe prove below that the experimental example satisfies this sufficient condition. We consider (1+\u03bb)EA, which covers (1+1)-EA and is much more general. Let {\u03bet}+\u221et=0 and {\u03be\u2032t} +\u221e t=0 model (1+\u03bb)-EA with and without noise for maximizing Ihardest problem, respectively. For Ihardest problem, it is to maximize the number of 0 bits except the optimal solution 1n. It is not hard to see that the EFHT E[[\u03c4 \u2032|\u03be\u20320 = x]] only depends on |x|0 (i.e., the number of 0 bits). We denote E1(j) as E[[\u03c4 \u2032|\u03be\u20320 = x]] with |x|0 = j. The order of E1(j) is showed in Lemma 5, the proof of which is in the Appendix.\nLemma 5 For any mutation probability 0 < p < 0.5, it holds that E1(0) < E1(1) < E1(2) < . . . < E1(n).\nTheorem 2 Either additive noise with \u03b42 \u2212 \u03b41 \u2264 2n or multiplicative noise with \u03b42 > \u03b41 > 0 makes Ihardest problem easier for (1+\u03bb)-EA with mutation probability less than 0.5.\nProof. The proof is by showing that the condition of Theorem 1 (i.e., Eq.3) holds here. By Lemma 5, the EFHT-Partition of {\u03be\u2032t}+\u221et=0 is Xi = {x \u2208 {0, 1}n||x|0 = i} (0 \u2264 i \u2264 n) and m in Theorem 1 equals to n here. Let fN (x) and f(x) denote the noisy and true fitness, respectively.\nFor any x \u2208 Xk (k \u2265 1), we denote P (0) and P (j) (1 \u2264 j \u2264 n) as the probability that for the \u03bb offspring solutions x1, . . . , x\u03bb generated by bit-wise mutation on x, min{|x1|0, . . . , |x\u03bb|0} = 0 (i.e., the least number of 0 bits is 0), and min{|x1|0, . . . , |x\u03bb|0} > 0 \u2227 max{|x1|0, . . . , |x\u03bb|0} = j (i.e., the largest number of 0 bits is j while the least number of 0 bits is larger than 0), respectively. Then, we analyze one-step transition probabilities from x for both {\u03be\u2032t}+\u221et=0 (i.e., without noise) and {\u03bet} +\u221e t=0 (i.e., with noise).\nFor {\u03be\u2032t}+\u221et=0 , because only the optimal solution or the solution with the largest number of 0 bit among the parent solution and \u03bb offspring solutions will be accepted, we have\nP t\u03be\u2032(x,X0) = P (0); \u2200 1 \u2264 j \u2264 k \u2212 1 : P t\u03be\u2032(x,Xj) = 0; P t\u03be\u2032(x,Xk) = \u2211k\nj=1 P (j); \u2200 k + 1 \u2264 j \u2264 n : P t\u03be\u2032(x,Xj) = P (j).\n(5)\nFor {\u03bet}+\u221et=0 with additive noise, since \u03b42 \u2212 \u03b41 \u2264 2n, we have\nfN (1n) \u2265 f(1n) + \u03b41 \u2265 2n+ \u03b42 \u2212 2n = \u03b42; \u2200y 6= 1n, fN (y) \u2264 f(y) + \u03b42 \u2264 \u03b42.\nFor multiplicative noise, since \u03b42 > \u03b41 > 0, then\nfN (1n) > 0; \u2200y 6= 1n, fN (y) \u2264 0.\nThus, for these two noises, we have \u2200y 6= 1n, fN (1n) \u2265 fN (y), which implies that if the optimal solution 1n is generated, it will always be accepted. Thus, we have, note that X0 = {1n},\nP t\u03be (x,X0) = P (0). (6)\nDue to the fitness evaluation disturbed by noise, the solution with the largest number of 0 bit among the parent solution and \u03bb offspring solutions may be rejected. Thus, we have\n\u2200 k + 1 \u2264 i \u2264 n : n\u2211 j=i P t\u03be (x,Xj) \u2264 n\u2211 j=i P (j). (7)\nBy combining Eq.5, Eq.6 and Eq.7, we have\n\u2200 1 \u2264 i \u2264 n : n\u2211 j=i P t\u03be (x,Xj) \u2264 n\u2211 j=i P t\u03be\u2032(x,Xj).\nSince \u2211n j=0 P t \u03be (x,Xj) = \u2211n j=0 P t \u03be\u2032(x,Xj) = 1, the above inequality is equivalent to\n\u2200 0 \u2264 i \u2264 n\u2212 1 : i\u2211\nj=0\nP t\u03be (x,Xj) \u2265 i\u2211\nj=0\nP t\u03be\u2032(x,Xj),\nwhich implies that the condition Eq.3 of Theorem 1 holds. Thus, we can get that Ihardest problem becomes easier for (1+\u03bb)-EA under these two kinds of noise.\nTheorem 1 gives a sufficient condition for that noise makes optimization easier. If its condition Eq.3 changes the inequality direction, which implies that noise leads to a smaller probability of jumping to good states, it obviously becomes a sufficient condition for that noise makes optimization harder. We show it in Theorem 3, the proof of which is as similar as that of Theorem 1, except that the inequality direction needs to be changed.\nTheorem 3 Given an EA A and a problem f , let a Markov chain {\u03bet}+\u221et=0 and a homogeneous Markov chain {\u03be\u2032t}+\u221et=0 modelA running on f with noise and without noise respectively, and denote {X0,X1, . . . ,Xm} as the EFHT-Partition of {\u03be\u2032t}+\u221et=0 , if for all t \u2265 0, x \u2208 X \u2212 X0, and for all integers i \u2208 [0,m\u2212 1],\u2211i j=0 P t\u03be (x,Xj) \u2264 \u2211i j=0 P t\u03be\u2032(x,Xj), (8) then noise makes f harder forA, i.e., for all x \u2208 X ,\nE[[\u03c4 |\u03be0 = x]] \u2265 E[[\u03c4 \u2032|\u03be\u20320 = x]].\nThen we apply this condition to the case that (1+\u03bb)-EA is used for optimizing the easiest case Ieasiest in the pseudo-Boolean function class. Let {\u03bet}+\u221et=0 and {\u03be\u2032t} +\u221e t=0 model (1+\u03bb)-EA with and without noise for maximizing Ieasiest problem, respectively. It is not hard to see that the EFHT E[[\u03c4 \u2032|\u03be\u20320 = x]] only depends on |x|0. We denote E2(j) as E[[\u03c4 \u2032|\u03be\u20320 = x]] with |x|0 = j. The order of E2(j) is showed in Lemma 6, the proof of which is in the Appendix.\nLemma 6 For any mutation probability 0 < p < 0.5, it holds that E2(0) < E2(1) < E2(2) < . . . < E2(n).\nTheorem 4 Any noise makes Ieasiest problem harder for (1+\u03bb)-EA with mutation probability less than 0.5.\nProof. We use Theorem 3 to prove it. By Lemma 6, the EFHT-Partition of {\u03be\u2032t}+\u221et=0 is Xi = {x \u2208 {0, 1}n||x|0 = i} (0 \u2264 i \u2264 n).\nFor any non-optimal solution x \u2208 Xk (k > 0), we denote P (j) (0 \u2264 j \u2264 n) as the probability that the least number of 0 bits for the \u03bb offspring solutions generated by bit-wise mutation on x is j. For {\u03be\u2032t}+\u221et=0 , because the solution with the least number of 0 bits among the parent solution and \u03bb offspring solutions will be accepted, we have\n\u2200 0 \u2264 j \u2264 k \u2212 1 : P t\u03be\u2032(x,Xj) = P (j); P t\u03be\u2032(x,Xk) = \u2211n\nj=k P (j); \u2200 k + 1 \u2264 j \u2264 n : P t\u03be\u2032(x,Xj) = 0.\nFor {\u03bet}+\u221et=0 , due to the fitness evaluation disturbed by noise, the solution with the least number of 0 bits among the parent solution and \u03bb offspring solutions may be rejected. Thus, we have\n0 \u2264 i \u2264 k \u2212 1 : i\u2211\nj=0\nP t\u03be (x,Xj) \u2264 i\u2211\nj=0\nP (j).\nThen, we can get\n\u2200 0 \u2264 i \u2264 n\u2212 1 : i\u2211\nj=0\nP t\u03be (x,Xj) \u2264 i\u2211\nj=0\nP t\u03be\u2032(x,Xj).\nThis implies that the condition Eq.8 of Theorem 3 holds. Thus, by Theorem 3, we can get that noise makes Ieasiest problem harder for (1+\u03bb)-EA."}, {"heading": "3.3. Discussion", "text": "We have shown that noise makes Ihardest and Ieasiest problems easier and harder, respectively, for (1+\u03bb)-EA. These two problems are known to be the hardest and the easiest instance respectively in the pseudo-Boolean function class with a unique global optimum for the (1+1)-EA [25]. We can intuitively interpret the discovered effect of noise for EAs on these two problems. For Ihardest problem, the EA searches along the deceptive direction while noise can add some randomness to make the EA have some possibility to run along the right direction; for Ieasiest problem, the EA searches along the right direction while noise can only harm the optimization process. We thus hypothesize that we need to take care of the noise only when the optimization problem is moderately or less complex.\nTo further verify our hypothesis, we employ the Jumpm,n problem, which is a problem with adjustable difficulty and can be configured as Ieaisest when m = 1 and Ihardest when m = n.\nDefinition 7 (Jumpm,n Problem) Jumpm,n Problem of size n with 1 \u2264 m \u2264 n is to find an n bits binary string x\u2217 such that\nx\u2217 = arg maxx\u2208{0,1}n ( Jumpm,n(x) = m+ \u2211n i=1 xi if \u2211n i=1 xi \u2264 n\u2212m or \u2211n i=1 xi = n\nn\u2212 \u2211n i=1 xi otherwise\n) ,\nwhere xi is the i-th bit of a solution x \u2208 {0, 1}n.\nWe test (1+1)-EA with mutation probability 1n on Jumpm,n. It is known that the expected running time of the (1+1)-EA on Jumpm,n is \u0398(nm + n log n) [12], which implies that Jumpm,n with larger value of m is harder. In the experiment, we set n = 5, and for noise, we use the additive noise with \u03b41 = \u22120.5n \u2227 \u03b42 = 0.5n, the multiplicative noise with \u03b41 = 1 \u2227 \u03b42 = 2, and the one-bit noise with pn = 0.5, respectively. We record the expected running time gap starting from each initial solution\ngap = (E[[\u03c4 ]]\u2212 E[[\u03c4 \u2032]])/E[[\u03c4 \u2032]],\nwhere E[[\u03c4 ]] and E[[\u03c4 \u2032]] denote the expected running time of the EA optimizing the problem with and without noise, respectively. The larger the gap means that the noise has a more negative effect, while the smaller the gap means that the noise has a less negative effect. For each initial solution and each configuration of noise, we repeat the running of the (1+1)-EA 1000 times, and estimate the expected running time by the average running time, and thus estimate the gap. The results are plotted in Figure 2.\nWe can observe that the gaps for largerm are lower (i.e., the negative effect by noise decreases as the problem hardness increases), and the gaps for largem tend to be 0 or negative values (i.e., noise can have no or positive effect when the optimization is quite hard). These empirical observations give support to our hypothesis that the noise should be handled carefully only when the optimization is moderately or less complex."}, {"heading": "4. On the Usefulness of Noise Handling Strategies", "text": ""}, {"heading": "4.1. Re-evaluation", "text": "There are naturally two fitness evaluation options for EAs [2, 21, 16, 19]:\n\u2022 single-evaluation we evaluate a solution once, and use the evaluated fitness for this solution\nin the future.\n\u2022 re-evaluation every time we access the fitness of a solution by evaluation.\nFor example, for (1+1)-EA in Algorithm 1, if using re-evaluation, both f(x\u2032) and f(x) will be calculated and recalculated in each iteration; if using single-evaluation, only f(x\u2032) will be calculated and the previous obtained fitness f(x) will be reused. Intuitively, re-evaluation can smooth noise and thus could be better for noisy optimizations, but it also increases the fitness evaluation cost and thus increases the running time. Its usefulness was not yet clear. Note that, the analysis in the previous section assumes single-evaluation.\nIn this section, we take the Ieasiest problem, where noise has been proved to have a strong negative effect in the previous section, as the representative problem, and compare these two options for (1+1)-EA with mutation probability 1n solving this problem under one-bit noise to show whether reevaluation is useful. Note that for one-bit noise, pn controls the noise level, that is, noise becomes stronger as pn gets larger, and it is also the variable of the PNT.\nTheorem 5 The PNT of (1+1)-EA using single-evaluation with mutation probability 1n on Ieasiest problem is lower bounded by 1\u22121/\u2126(poly(n)) and upper bounded by 1\u22121/O(2npoly(n)), where poly(n) indicates any polynomial of n, with respect to one-bit noise.\nThe theorem is straightforwardly derived from the following lemma.\nLemma 7 For (1+1)-EA using single-evaluation with mutation probability 1n on Ieasiest problem under one-bit noise, the expected running time is O(n2 + n/(1\u2212 pn)) and \u2126(npn/(2n(1\u2212 pn))).\nProof. Let L denote the noisy fitness value fN (x) of the current solution x. Because (1+1)-EA does not accept a solution with a smaller fitness (i.e., the 4th step of Algorithm 1) and it doesn\u2019t re-evaluate the fitness of the current solution x, L (0 \u2264 L \u2264 n) will never decrease. We first analyze the expected steps until L increases when starting from L = i (denoted by E[[i]]), and then sum up them to get an\nupper bound \u2211n\u22121 i=0 E[[i]] for the expected steps until L reaches the maximum value n. For E[[i]], we analyze the probability P that L increases in two steps when L = i, then E[[i]] = 2 \u00b7 1P . Note that,\none-bit noise can make L be |x|1 \u2212 1, |x|1 or |x|1 + 1, where |x|1 = \u2211n i=1 xi is the number of 1 bits. When analyzing the noisy fitness fN (x\u2032) of the offspring x\u2032 in each step, we need to first consider bit-wise mutation on x and then one random bit flip for noise.\nWhen 0 < L < n\u2212 1, |x|1 = L\u2212 1, L or L+ 1. (1) For |x|1 = L\u22121, P \u2265 n\u2212L+1n (1\u2212 1 n ) (n\u22121)pn n\u2212L n + n\u2212L+1 n (1\u2212 1 n ) (n\u22121)(1\u2212pn)n\u2212Ln (1\u2212 1 n ) (n\u22121)(1\u2212pn), since it is sufficient to flip one 0 bit for mutation and one 0 bit for noise in the first step, or flip one 0 bit for mutation and no bit for noise in the first step and flip one 0 bit for mutation and no bit for noise in the second step. (2) For |x|1 = L, P \u2265 (1 \u2212 1n ) npn n\u2212L n + n\u2212L n (1 \u2212 1 n ) n\u22121(1 \u2212 pn), since it is sufficient to flip no bit for mutation and one 0 bit for noise, or flip one 0 bit for mutation and no bit for noise in the first step. (3) For |x|1 = L+ 1, P \u2265 (1\u2212 1n ) n(1\u2212 pn + pn n\u2212L\u22121n ), since it is sufficient to flip no bit for mutation and no bit or one 0 bit for noise in the first step. Thus, for these three cases, we have\nP \u2265 pn(1\u2212 1\nn )(n\u22121) n\u2212 L n n\u2212 L\u2212 1 n + (1\u2212 1 n )2(n\u22121)(1\u2212 pn)2 n\u2212 L n n\u2212 L\u2212 1 n\n\u22651 (pn + (1\u2212 pn)2) (n\u2212 L)(n\u2212 L\u2212 1) e2n2 \u22652 3(n\u2212 L)(n\u2212 L\u2212 1) 4e2n2 ,\nwhere the \u2018\u22651\u2019 is by (1\u2212 1n ) n\u22121 \u2265 1e and the \u2018\u2265 2\u2019 is by 0 \u2264 pn \u2264 1.\nWhen L = 0, |x|1 = 0 or 1. By considering case (2) and (3), we can get the same lower bound for P .\nWhenL = n\u22121 and the optimal solution 1n has not been found, |x|1 = n\u22122 or n\u22121. By considering case (1) and (2), we can get P \u2265 3/(2e2n2).\nBased on the above analysis, we can get that the expected steps until L = n is at most\n\u2211n\u22121 i=0 E[[i]] \u2264 2 \u00b7 ( n\u22122\u2211 L=0\n4e2n2\n3(n\u2212 L)(n\u2212 L\u2212 1) +\n2e2n2\n3 ), i.e., O(n2).\nWhen L = n, |x|1 = n\u2212 1 or n (i.e., the optimal solution has been found). If |x|1 = n\u2212 1, the optimal solution will be generated and accepted in one step with probability 1n (1\u2212 1 n ) n\u22121(1\u2212 pn) \u2265 (1\u2212pn)en , because it needs to flip the unique 0 bit for mutation and no bit for noise. This implies that the expected steps for finding the optimal solution is at most en(1\u2212pn) .\nThus, we can get the upper boundO(n2 + n1\u2212pn ) for the expected running time of the whole process.\nThen, we are to analyze the lower bound. Assume that the initial solution xinit has n\u2212 1 number of 1 bits, i.e., |xinit|1 = n \u2212 1. If the fitness of xinit is evaluated as n, which happens with probability pn 1 n , before finding the optimal solution, the solution will always have n\u2212 1 number of 1 bits and its fitness will always be n. From the above analysis, we know that in such a situation, the probability of generating and accepting the optimal solution in one step is 1n (1\u2212 1 n ) n\u22121(1\u2212 pn) \u2264 (1\u2212pn)n . Thus, the expected running time for finding the optimal solution when starting from |xinit|1 = n \u2212 1 is at least pn 1n \u00b7 n (1\u2212pn) = pn (1\u2212pn) . Because the initial solution is uniformly distributed over {0, 1} n, the probability that the algorithm starts from |xinit|1 = n\u2212 1 is n/2n. Thus, we can get the lower bound \u2126( npn2n(1\u2212pn) ) for the expected running time of the whole process.\nTheorem 6 The PNT of (1+1)-EA using re-evaluation with mutation probability 1n on Ieasiest problem is \u0398( log(n) n ), with respect to one-bit noise.\nThe theorem is straightforwardly derived from the following lemma.\nLemma 8 ([10]) For (1+1)-EA using re-evaluation with mutation probability 1n on Ieasiest problem under one-bit noise, the expected running time is polynomial when pn \u2208 O(log(n)/n), and the running time is polynomial with super-polynomially small probability when pn \u2208 \u03c9(log(n)/n)."}, {"heading": "4.2. Threshold Selection", "text": "During the process of evolutionary optimization, most of the improvements in one generation are small. When using re-evaluation, due to noisy fitness evaluation, a considerable portion of these improvements are not real, where a worse solution appears to have a \u201cbetter\u201d fitness and then survives to replace the true better solution which has a \u201cworse\u201d fitness. This may mislead the search direction of EAs, and then slow down the efficiency of EAs or make EAs get trapped in the local optimal solution, as observed in Section 4.1. To deal with this problem, a selection strategy for EAs handling noise was proposed [23].\n\u2022 threshold selection an offspring solution will be accepted only if its fitness is larger than the\nparent solution by at least a predefined threshold \u03c4 \u2265 0.\nFor example, for (1+1)-EA with threshold selection as in Algorithm 3, its 4th step changes to be \u201cif f(x\u2032) \u2265 f(x) + \u03c4\u201d rather than \u201cif f(x\u2032) \u2265 f(x)\u201d in Algorithm 1. Such a strategy can reduce the risk of accepting a bad solution due to noise. Although the good local performance (i.e., the progress of one step) of EAs with threshold selection has been shown on some problems [23, 6, 5], its usefulness for the global performance (i.e., the running time until finding the optimal solution) of EAs under noise is not yet clear.\nAlgorithm 3 ((1+1)-EA with threshold selection) Given pseudo-Boolean function f with solution length n, and a predefined threshold \u03c4 \u2265 0, it consists of the following steps:\n1. x := randomly selected from {0, 1}n. 2. Repeat until the termination condition is met 3. x\u2032 := flip each bit of x with probability p. 4. if f(x\u2032) \u2265 f(x) + \u03c4\n5. x := x\u2032. where p \u2208 (0, 0.5) is the mutation probability.\nIn this section, we compare the running time of (1+1)-EA with and without threshold selection solving Ieasiest problem under one-bit noise to show whether threshold selection will be useful. Note that, the analysis here assumes re-evaluation.\nAlgorithm 4 shows a random walk on a graph. Lemma 9 gives an upper bound on the expected steps for a random walk to visit each vertex of a graph at least once, which will be used in the following analysis.\nAlgorithm 4 (Random Walk) Given an undirected connected graph G = (V,E) with vertex set V and edge set E, it consists of the following steps:\n1. start at a vertex v \u2208 V . 2. Repeat until the termination condition is met 3. choose a neighbor u of v in G uniformly at random. 4. set v := u.\nLemma 9 ([1]) Given an undirected connected graphG = (V,E), the expected cover time of a random walk onG is upper bounded by 2|E|(|V | \u2212 1), where the cover time of a random walk onG is the number of steps until each vertex v \u2208 V has been visited at least once.\nTheorem 7 The PNT of (1+1)-EA using re-evaluation with threshold selection \u03c4 = 1 and mutation probability 1n on Ieasiest problem is not less than 12e , with respect to one-bit noise.\nThe theorem can be directly derived from the following lemma.\nLemma 10 For (1+1)-EA using re-evaluation with threshold selection \u03c4 = 1 and mutation probability 1n on Ieasiest problem under one-bit noise, the expected running time is O(n3) when pn \u2264 12e .\nProof. We denote the number of one bits of the current solution x by L (0 \u2264 L \u2264 n). Let Pd denote the probability that the offspring solution x\u2032 by bit-wise mutation on x has L+ d (\u2212L \u2264 d \u2264 n\u2212 L) number of one bits, and let P \u2032d denote the probability that the next solution after bit-wise mutation and selection has L+ d number of one bits.\nThen, we analyze P \u2032d. We consider 0 \u2264 L \u2264 n\u22121. Note that one-bit noise can change the true fitness of a solution by at most 1, i.e., |fN (x)\u2212 f(x)| \u2264 1. (1) When d \u2264 \u22122, fN (x\u2032) \u2264 L+d+1 \u2264 L\u22121 \u2264 fN (x). Because an offspring solution will be accepted only if fN (x\u2032) \u2265 fN (x)+1, the offspring solution x\u2032 will be discarded in this case, which implies that \u2200d \u2264 \u22122 : P \u2032d = 0. (2) When d = \u22121, the offspring solution x\u2032 will be accepted only if fN (x\u2032) = L \u2227 fN (x) = L \u2212 1, the probability of which is pn n\u2212L+1n \u00b7 pn L n , since it needs to flip one 0 bit of x \u2032 and flip one 1 bit of x. Thus, P \u2032\u22121 = P\u22121 \u00b7 (pn Lnpn n\u2212L+1 n ). (3) When d = 1, if fN (x) = L \u2212 1, the probability of which is pn Ln , the offspring solution x \u2032 will be accepted, since fN (x\u2032) \u2265 L + 1 \u2212 1 = L > fN (x); if fN (x) = L \u2227 fN (x\u2032) \u2265 L + 1, the probability of which is (1 \u2212 pn) \u00b7 (1 \u2212 pn + pn n\u2212L\u22121n ), x \u2032 will be accepted; if fN (x) = L + 1 \u2227 fN (x\u2032) = L + 2, the probability of which is pn n\u2212Ln \u00b7 pn n\u2212L\u22121 n , x \u2032 will be accepted; otherwise, x\u2032 will be discarded. Thus, P \u20321 = P1 \u00b7 (pn Ln + (1\u2212 pn)(1\u2212 pn + pn n\u2212L\u22121 n ) + pn n\u2212L n pn n\u2212L\u22121 n ). (4) When d \u2265 2, it is easy to see that P \u2032d > 0.\nBecause we are to get the upper bound of the expected running time for finding the optimal solution 1n for the first time, we pessimistically assume that \u2200d \u2265 2 : P \u2032d = 0. Then, we compare P \u20321 with P \u2032\u22121.\nP \u20321 \u2265 P1pn L n \u2265 n\u2212 L n (1\u2212 1 n )n\u22121pn L n \u2265 pn L(n\u2212 L) en2 ,\nwhere the second inequality is by P1 \u2265 n\u2212Ln (1\u2212 1 n ) n\u22121 since it is sufficient to flip just one 0 bit, and the last inequality is by (1\u2212 1n ) n\u22121 \u2265 1e .\nP \u2032\u22121 = P\u22121(pn L n pn n\u2212 L+ 1 n ) \u2264 L n (pn L n pn n\u2212 L+ 1 n ) \u2264 pn L en2 \u00b7 L(n\u2212 L+ 1) 2n \u2264 pn L(n\u2212 L) en2 ,\nwhere the first inequality is by P\u22121 \u2264 Ln since it is necessary to flip at least one 1 bit, the second inequality is by pn \u2264 12e , and the last inequality is by L(n\u2212L+1) 2n \u2264 n\u2212 L.\nThus, we have for all 0 \u2264 L \u2264 n\u22121, P \u20321 \u2265 P \u2032\u22121. Because we are to get the upper bound of the expected running time for finding 1n, we can pessimistically assume that P \u20321 = P \u2032 \u22121. Then, we can view the\nevolutionary process as a random walk on the path {0, 1, 2, . . . , n}. We call a step that jumps to the neighbor state a relevant step. Thus, by Lemma 9, it needs at most 2n2 expected relevant steps to find 1n. Because the probability of a relevant step is at least P \u20321 \u2265 P1(1\u2212pn)2 \u2265 n\u2212Ln (1\u2212 1 n ) n\u22121(1\u2212 12e ) 2 \u2265 (1\u2212 12e ) 2/en, the expected running time for a relevant step isO(n). Thus, the expected running time of (1+1)-EA with \u03c4 = 1 on Ieasiest problem with pn \u2264 12e is upper bounded by O(n 3).\nTheorem 8 The PNT of (1+1)-EA using re-evaluation with threshold selection \u03c4 = 2 and mutation probability 1n on Ieasiest problem is lower bounded by1\u2212 1/\u2126(poly(n)) and upper bounded by 1\u2212 1/O(2npoly(n)), where poly(n) indicates any polynomial of n, with respect to one-bit noise.\nThe theorem can be directly derived from the following lemma.\nLemma 11 For (1+1)-EA using re-evaluation with threshold selection \u03c4 = 2 and mutation probability 1n on Ieasiest problem under one-bit noise, the expected running time is O(n log n/(pn(1\u2212 pn))) and \u2126(n2/(2npn(1\u2212 pn))).\nProof. Let L (0 \u2264 L \u2264 n) denote the number of one bits of the current solution x. Here, an offspring solution x\u2032 will be accepted only if fN (x\u2032)\u2212 fN (x) \u2265 2. As in the proof of Lemma 10, we can derive\n\u2200d \u2264 \u22121 : P \u2032d = 0;\nP \u20321 = P1 ( pn L\nn ((1\u2212 pn) + pn n\u2212 L\u2212 1 n ) + (1\u2212 pn)(pn n\u2212 L\u2212 1 n ) ) ;\n\u2200d \u2265 2 : P \u2032d > 0.\nThus, Lwill never decrease in the evolution process, and it can increase in one step with probability\nP \u2032d>0 > P \u2032 1 \u2265 n\u2212 L n (1\u2212 1 n )(n\u22121)((1\u2212 pn)pn(1\u2212 1 n ) + p2n L(n\u2212 L\u2212 1) n2 )\n\u2265 1 2e (1\u2212 pn)pn n\u2212 L n .\nThen, we can get that the expected steps until L = n (i.e., the optimal solution is found) is at most\nn\u22121\u2211 L=0\n2en\n(1\u2212 pn)pn(n\u2212 L) , i.e., O(\nn log n\npn(1\u2212 pn) ).\nThen, we are to analyze the lower bound. Assume that the initial solution xinit has n \u2212 1 number of 1 bits. Before finding the optimal solution, the solution x in the population will always satisfy |x|1 = n\u2212 1 because \u2200d \u2264 \u22121 : P \u2032d = 0. The optimal solution (i.e., |x|1 = n) will be found in one step with probability P \u20321 = P1pn(1 \u2212 pn)(1 \u2212 1n ) = 1 n (1 \u2212 1 n ) (n\u22121)pn(1 \u2212 pn)(1 \u2212 1n ) \u2264 pn(1\u2212pn) en . Thus, the expected steps for finding the optimal solution when starting from |xinit|1 = n\u22121 is at least enpn(1\u2212pn) . By the uniform distribution of the initial solution, the probability that |xinit|1 = n\u2212 1 is n/2n. Thus, we can get the lower bound \u2126( n 2\n2npn(1\u2212pn) ) for the expected running time of the whole process."}, {"heading": "4.3. Smooth Threshold Selection", "text": "We propose the smooth threshold selection as in Definition 8, which modifies the original threshold selection by changing the hard threshold value to a smooth one. We are to show that, by such a small modification, the PNT of (1+1)-EA on Ieasiest problem is improved to 1, which means that the expected running time of (1+1)-EA is always polynomial disregard the one-bit noise level.\nDefinition 8 (Smooth Threshold Selection) Let \u03b4 be the gap between the fitness of the offspring solution x\u2032 and the parent solution x, i.e., \u03b4 = f(x\u2032)\u2212 f(x). Then, the selection process will behave as follows: (1) if \u03b4 \u2264 0, x\u2032 will be rejected; (2) if \u03b4 = 1, x\u2032 will be accepted with probability 15n ; (3) if \u03b4 > 1, x\u2032 will be accepted.\nTheorem 9 The PNT of (1+1)-EA using re-evaluation with smooth threshold selection and mutation probability 1 n on Ieasiest problem is 1, with respect to one-bit noise.\nProof. We first analyze P \u2032d as that analyzed in the proof of Lemma 10. The only difference is that when the fitness gap between the offspring and the parent solution is 1, the offspring solution will be accepted with probability 15n here, while it will be always accepted in the proof of Lemma 10. Thus, for smooth threshold selection, we can similarly derive\n\u2200d \u2264 \u22122 : P \u2032d = 0; P \u2032\u22121 = P\u22121(pn L\nn pn n\u2212 L+ 1 n ) \u00b7 1 5n ;\nP \u20321 = P1 ( pn L\nn (pn\nL+ 1 n \u00b7 1 5n + (1\u2212 pn) + pn n\u2212 L\u2212 1 n ) + (1\u2212 pn)((1\u2212 pn) \u00b7 1 5n + pn n\u2212 L\u2212 1 n )\n+ pn n\u2212 L n pn n\u2212 L\u2212 1 n \u00b7 1 5n\n) ;\n\u2200d \u2265 2 : P \u2032d > 0.\nNote that L (0 \u2264 L \u2264 n) denotes the number of one bits of the current solution x. Our goal is to reach L = n. If starting from L = n\u2212 1, L will reach n in one step with probability\nP \u20321 \u2265 P1(pn L n pn L+ 1 n \u00b7 1 5n + (1\u2212 pn)(1\u2212 pn) \u00b7 1 5n )\n\u2265 n\u2212 L n (1\u2212 1 n )n\u22121(pn L n pn L+ 1 n \u00b7 1 5n + (1\u2212 pn)(1\u2212 pn) \u00b7 1 5n ) \u2265 1 5en2 ( n\u2212 1 n p2n + (1\u2212 pn)2) (by L = n\u2212 1 and (1\u2212 1 n )n\u22121 \u2265 1 e ) \u2265 1 5en2 \u00b7 n\u2212 1 2n\u2212 1 \u2208 \u2126( 1 n2 ). (by 0 \u2264 pn \u2264 1)\nThus, for reaching L = n, we need to reach L = n\u2212 1 for O(n2) times in expectation.\nThen, we analyze the expected running time until L = n\u2212 1. In this process, we can pessimistically assume that L = n will never be reached, because our final goal is to get the upper bound on the expected running time for reaching L = n. For 0 \u2264 L \u2264 n\u2212 2, we have\nP \u20321 P \u2032\u22121 \u2265 P1 \u00b7 (pn Lnpn n\u2212L\u22121 n ) P\u22121 \u00b7 (pn Lnpn n\u2212L+1 n ) \u00b7 1 5n \u2265 n\u2212L n (1\u2212 1 n ) n\u22121 \u00b7 (pn Lnpn n\u2212L\u22121 n ) L n \u00b7 (pn L npn n\u2212L+1 n ) \u00b7 1 5n \u2265 5n(n\u2212 L)(n\u2212 L\u2212 1) eL(n\u2212 L+ 1) = 5n(nL \u2212 1)\ne(1 + 2n\u2212L\u22121 ) > 1.\nAgain, we can pessimistically assume that P \u20321 = P \u2032 \u22121 and \u2200d \u2265 2, P \u2032d = 0, because we are to get the upper bound on the expected running time until L = n \u2212 1. Then, we can view the evolutionary process for reaching L = n \u2212 1 as a random walk on the path {0, 1, 2, . . . , n \u2212 1}. We call a step that jumps to the neighbor state a relevant step. Thus, by Lemma 9, it needs at most 2(n \u2212 1)2 expected relevant steps to reach L = n\u2212 1. Because the probability of a relevant step is at least\nP \u20321 \u2265 P1((1\u2212 pn)(1\u2212 pn) \u00b7 1\n5n + pn n\u2212 L n pn n\u2212 L\u2212 1 n \u00b7 1 5n )\n\u2265 n\u2212 L 5en2 ((1\u2212 pn)2 + p2n (n\u2212 L)(n\u2212 L\u2212 1) n2 ) \u2265 2 5en2 ((1\u2212 pn)2 + 2 n2 p2n) \u2265 2 5en2 \u00b7 2 n2 + 2 ,\nthe expected running time for a relevant step isO(n4). Then, the expected running time for reaching L = n\u2212 1 is O(n6).\nThus, the expected running time of the whole optimization process is O(n8) for any pn \u2208 [0, 1], and then this theorem holds.\nWe draw an intuitive understanding from the proof of Theorem 9 that why the smooth threshold selection can be better than the original threshold selections. By changing the hard threshold to be a smooth threshold, it can not only make the probability of accepting a false better solution in one step small enough, i.e. P \u20321 \u2265 P \u2032\u22121, but also make the probability of producing progress in one step large enough, i.e., P \u20321 is not small."}, {"heading": "5. Discussions and Conclusions", "text": "This paper studies theoretical issues of noisy optimization by evolutionary algorithms.\nFirst, we discover that an optimization problem may become easier instead of harder in a noisy environment. We then derive a sufficient condition under which noise makes optimization easier or harder. By filling this condition, we have shown that for (1+\u03bb)-EA, noise makes the optimization\non the hardest and the easiest case in the pseudo-Boolean function class easier and harder, respectively. We also hypothesize that we need to take care of noise only when the optimization problem is moderately or less complex. Experiments on the Jumpm,n problem, which has an adjustable difficulty parameter, supported our hypothesis.\nIn problems where the noise has a negative effect, we then study the usefulness of two commonly employed noise-handling strategies, re-evaluation and threshold selection. The study takes the easiest case in the pseudo-Boolean function class as the representative problem, where the noise significantly harms the expected running time of the (1+1)-EA. We use the polynomial noise tolerance (PNT) level as the performance measure, and analyzed the PNT of each EA.\nThe re-evaluation strategy seems to be a reasonable method for reducing random noise. However, we derive that the (1+1)-EA with single-evaluation has a PNT lower bound 1 \u2212 1/\u2126(poly(n)) from Theorem 5 which is close to 1, whilst the (1+1)-EA with re-evaluation has the PNT \u0398(log(n)/n) which can be quite close to zero as n is large. It is surprise to see that the re-evaluation strategy leads to a much worse noise tolerance than that without any noise handling method.\nThe re-evaluation with threshold selection strategy has a better PNT comparing with the re-evaluation alone. When the threshold is 1, we derive a PNT lower bound 12e from Theorem 7, and when the threshold is 2, we obtain 1 \u2212 1/\u2126(poly(n)) from Theorem 8. The improvement from re-evaluation alone could be explained as that the threshold selection filters out fake progresses that caused by the noise. However, it still showed no improvements from the (1+1)-EA without any noise handling method.\nWe then proposed the smooth threshold selection, which acts like the threshold selection with threshold 2 but accepts progresses 1 with a probability. We proved that the (1+1)-EA with the smooth threshold selection has the PNT 1 from Theorem 9, which exceeds that of (1+1)-EA without any noise handling method. Our explanation is that, like the original threshold selection, the proposed one filters out fake progresses, while it also keep some chances to accept real progresses.\nAlthough the investigated EAs and problems in this paper are simple and specifically used for the theoretical analysis of EAs, the analysis still disclosed counter-intuitive results and, particularly, demonstrated that theoretical investigation is essential in designing better noise handling strategies. We are optimistic that our findings may be helpful for practical uses of EAs, which will be studied in the future."}, {"heading": "6. Acknowledgements", "text": "to be added ..."}], "references": [{"title": "Random walks, universal traversal sequences, and the complexity of maze problems", "author": ["R. Aleliunas", "R. Karp", "R. Lipton", "L. Lovasz", "C. Rackoff"], "venue": "In Proceedings of the 20th Annual Symposium on Foundations of Computer Science", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1979}, {"title": "Local performance of the (1+1)-ES in a noisy environment", "author": ["D.V. Arnold", "H.-G. Beyer"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "A comparison of evolution strategies with other direct search methods in the presence of noise", "author": ["D.V. Arnold", "H.-G. Beyer"], "venue": "Computational Optimization and Applications,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms", "author": ["T. B\u00e4ck"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1996}, {"title": "New experimentalism applied to evolutionary computation", "author": ["T. Bartz-Beielstein"], "venue": "PhD thesis, University of Dortmund,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Threshold selection, hypothesis tests, and DOE methods", "author": ["T. Beielstein", "S. Markon"], "venue": "In Proceedings of the IEEE Congress on Evolutionary Computation", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Evolutionary algorithms in noisy environments: theoretical issues and guidelines for practice", "author": ["H.-G. Beyer"], "venue": "Computer Methods in Applied Mechanics and Engineering,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "Automated passive filter synthesis using a novel tree representation and genetic programming", "author": ["S.-J. Chang", "H.-S. Hou", "Y.-K. Su"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "A new query reweighting method for document retrieval based on genetic algorithms", "author": ["Y. Chang", "S. Chen"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "Analysis of the (1+1) EA for a noisy OneMax", "author": ["S. Droste"], "venue": "In Proceedings of the 6th ACM Annual Conference on Genetic and Evolutionary Computation", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "A rigorous complexity analysis of the (1+1) evolutionary algorithm for linear functions with Boolean inputs", "author": ["S. Droste", "T. Jansen", "I. Wegener"], "venue": "Evolutionary Computation,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1998}, {"title": "On the analysis of the (1+1) evolutionary algorithm", "author": ["S. Droste", "T. Jansen", "I. Wegener"], "venue": "Theoretical Computer Science,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2002}, {"title": "Genetic algorithms in noisy environments", "author": ["J.M. Fitzpatrick", "J.J. Grefenstette"], "venue": "Machine learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1988}, {"title": "Fre\u0131\u030cdlin. Markov Processes and Differential Equations: Asymptotic Problems", "author": ["I. M"], "venue": "Birkha\u0308user Verlag, Basel, Switzerland,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1996}, {"title": "A survey of evolutionary algorithms for data mining and knowledge discovery", "author": ["A.A. Freitas"], "venue": "Advances in Evolutionary Computing: Theory and Applications,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "An investigation on noisy environments in evolutionary multiobjective optimization", "author": ["C. Goh", "K. Tan"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Drift analysis and average time complexity of evolutionary algorithms", "author": ["J. He", "X. Yao"], "venue": "Artificial Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2001}, {"title": "A study of drift analysis for estimating computation time of evolutionary algorithms", "author": ["J. He", "X. Yao"], "venue": "Natural Computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}, {"title": "Hoeffding and Bernstein races for selecting policies in evolutionary direct policy search", "author": ["V. Heidrich-Meisner", "C. Igel"], "venue": "In Proceedings of the 26th International Conference on Machine Learning", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "On the choice of the offspring population size in evolutionary algorithms", "author": ["T. Jansen", "K. Jong", "I. Wegener"], "venue": "Evolutionary Computation,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}, {"title": "Evolutionary optimization in uncertain environments-a survey", "author": ["Y. Jin", "J. Branke"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2005}, {"title": "An evolutionary clustering algorithm for gene expression microarray data analysis", "author": ["P. Ma", "K. Chan", "X. Yao", "D. Chiu"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Thresholding-a selection operator for noisy ES", "author": ["S. Markon", "D.V. Arnold", "T. Back", "T. Beielstein", "H.-G. Beyer"], "venue": "In Proceedings of the IEEE Congress on Evolutionary Computation", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2001}, {"title": "Randomized local search, evolutionary algorithms, and the minimum spanning tree problem", "author": ["F. Neumann", "I. Wegener"], "venue": "Theoretical Computer Science,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}, {"title": "On algorithm-dependent boundary case identification for problem classes", "author": ["C. Qian", "Y. Yu", "Z.-H. Zhou"], "venue": "In Proceedings of the 12th International Conference on Parallel Problem Solving from Nature", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "A partial order approach to noisy fitness functions", "author": ["G. Rudolph"], "venue": "In Proceedings of the IEEE Congress on Evolutionary Computation", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2001}, {"title": "A new method for lower bounds on the running time of evolutionary algorithms", "author": ["D. Sudholt"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "A new approach to estimating the expected first hitting time of evolutionary algorithms", "author": ["Y. Yu", "Z.-H. Zhou"], "venue": "Artificial Intelligence,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2008}], "referenceMentions": [{"referenceID": 3, "context": "While, evolutionary algorithms (EAs) [4] have been widely and successfully adopted for noisy optimization tasks [15, 22, 9, 8].", "startOffset": 37, "endOffset": 40}, {"referenceID": 14, "context": "While, evolutionary algorithms (EAs) [4] have been widely and successfully adopted for noisy optimization tasks [15, 22, 9, 8].", "startOffset": 112, "endOffset": 126}, {"referenceID": 21, "context": "While, evolutionary algorithms (EAs) [4] have been widely and successfully adopted for noisy optimization tasks [15, 22, 9, 8].", "startOffset": 112, "endOffset": 126}, {"referenceID": 8, "context": "While, evolutionary algorithms (EAs) [4] have been widely and successfully adopted for noisy optimization tasks [15, 22, 9, 8].", "startOffset": 112, "endOffset": 126}, {"referenceID": 7, "context": "While, evolutionary algorithms (EAs) [4] have been widely and successfully adopted for noisy optimization tasks [15, 22, 9, 8].", "startOffset": 112, "endOffset": 126}, {"referenceID": 20, "context": "Two representative strategies are re-evaluation and threshold selection: by the re-evaluation strategy [21, 16], whenever the fitness (also called cost or objective value) of a solution is required, EAs make an independent evaluation of the solution despite of whether the solution has been evaluated before, such that the fitness is smoothed; by the threshold selection strategy [23, 6, 5], in the selection stage EAs accept a newly generated solution only if its fitness is larger than the fitness of the old solution by at least a threshold, such that the risk of accepting a bad solution due to noise is reduced.", "startOffset": 103, "endOffset": 111}, {"referenceID": 15, "context": "Two representative strategies are re-evaluation and threshold selection: by the re-evaluation strategy [21, 16], whenever the fitness (also called cost or objective value) of a solution is required, EAs make an independent evaluation of the solution despite of whether the solution has been evaluated before, such that the fitness is smoothed; by the threshold selection strategy [23, 6, 5], in the selection stage EAs accept a newly generated solution only if its fitness is larger than the fitness of the old solution by at least a threshold, such that the risk of accepting a bad solution due to noise is reduced.", "startOffset": 103, "endOffset": 111}, {"referenceID": 22, "context": "Two representative strategies are re-evaluation and threshold selection: by the re-evaluation strategy [21, 16], whenever the fitness (also called cost or objective value) of a solution is required, EAs make an independent evaluation of the solution despite of whether the solution has been evaluated before, such that the fitness is smoothed; by the threshold selection strategy [23, 6, 5], in the selection stage EAs accept a newly generated solution only if its fitness is larger than the fitness of the old solution by at least a threshold, such that the risk of accepting a bad solution due to noise is reduced.", "startOffset": 380, "endOffset": 390}, {"referenceID": 5, "context": "Two representative strategies are re-evaluation and threshold selection: by the re-evaluation strategy [21, 16], whenever the fitness (also called cost or objective value) of a solution is required, EAs make an independent evaluation of the solution despite of whether the solution has been evaluated before, such that the fitness is smoothed; by the threshold selection strategy [23, 6, 5], in the selection stage EAs accept a newly generated solution only if its fitness is larger than the fitness of the old solution by at least a threshold, such that the risk of accepting a bad solution due to noise is reduced.", "startOffset": 380, "endOffset": 390}, {"referenceID": 4, "context": "Two representative strategies are re-evaluation and threshold selection: by the re-evaluation strategy [21, 16], whenever the fitness (also called cost or objective value) of a solution is required, EAs make an independent evaluation of the solution despite of whether the solution has been evaluated before, such that the fitness is smoothed; by the threshold selection strategy [23, 6, 5], in the selection stage EAs accept a newly generated solution only if its fitness is larger than the fitness of the old solution by at least a threshold, such that the risk of accepting a bad solution due to noise is reduced.", "startOffset": 380, "endOffset": 390}, {"referenceID": 12, "context": "An assumption implied by using a noise handling mechanism in EAs is that the noise makes the optimization harder, so that a better handling mechanism can reduce the negative effect by the noise [13, 7, 26, 3].", "startOffset": 194, "endOffset": 208}, {"referenceID": 6, "context": "An assumption implied by using a noise handling mechanism in EAs is that the noise makes the optimization harder, so that a better handling mechanism can reduce the negative effect by the noise [13, 7, 26, 3].", "startOffset": 194, "endOffset": 208}, {"referenceID": 25, "context": "An assumption implied by using a noise handling mechanism in EAs is that the noise makes the optimization harder, so that a better handling mechanism can reduce the negative effect by the noise [13, 7, 26, 3].", "startOffset": 194, "endOffset": 208}, {"referenceID": 2, "context": "An assumption implied by using a noise handling mechanism in EAs is that the noise makes the optimization harder, so that a better handling mechanism can reduce the negative effect by the noise [13, 7, 26, 3].", "startOffset": 194, "endOffset": 208}, {"referenceID": 24, "context": "We start by presenting an experimental evidence using (1+1)-EA optimizing the hardest case in the pseudo-Boolean function class [25].", "startOffset": 128, "endOffset": 132}, {"referenceID": 9, "context": "Since the (1+1)-EA with re-evaluation has the PNT \u0398( logn n ) [10], it is surprisingly that the re-evaluation makes the PNT much worse.", "startOffset": 62, "endOffset": 66}, {"referenceID": 6, "context": "Additive and multiplicative noise has been often used for analyzing the effect of noise [7, 21].", "startOffset": 88, "endOffset": 95}, {"referenceID": 20, "context": "Additive and multiplicative noise has been often used for analyzing the effect of noise [7, 21].", "startOffset": 88, "endOffset": 95}, {"referenceID": 9, "context": "Onebit noise is specifically for optimizing pseudo-Boolean problems over {0, 1}, and also the investigated noise in the only previous work for analyzing running time of EAs in noisy optimization [10].", "startOffset": 195, "endOffset": 199}, {"referenceID": 3, "context": "Evolutionary algorithms (EAs) [4] are a kind of population-based metaheuristic optimization algorithms.", "startOffset": 30, "endOffset": 33}, {"referenceID": 16, "context": ", [17, 12].", "startOffset": 2, "endOffset": 10}, {"referenceID": 11, "context": ", [17, 12].", "startOffset": 2, "endOffset": 10}, {"referenceID": 19, "context": "It has been used to disclose the effect of offspring population size by running time analysis [20, 24].", "startOffset": 94, "endOffset": 102}, {"referenceID": 23, "context": "It has been used to disclose the effect of offspring population size by running time analysis [20, 24].", "startOffset": 94, "endOffset": 102}, {"referenceID": 16, "context": ", computing f(\u00b7)) until an optimal solution is found for the first time, since the fitness evaluation is the computational process with the highest cost of the algorithm [17, 28].", "startOffset": 170, "endOffset": 178}, {"referenceID": 27, "context": ", computing f(\u00b7)) until an optimal solution is found for the first time, since the fitness evaluation is the computational process with the highest cost of the algorithm [17, 28].", "startOffset": 170, "endOffset": 178}, {"referenceID": 16, "context": ", [17, 28].", "startOffset": 2, "endOffset": 10}, {"referenceID": 27, "context": ", [17, 28].", "startOffset": 2, "endOffset": 10}, {"referenceID": 13, "context": "The following two lemmas on the EFHT of Markov chains [14] will be used in this paper.", "startOffset": 54, "endOffset": 58}, {"referenceID": 16, "context": "For analyzing the EFHT of Markov chains, drift analysis [17, 18] is a commonly used tool, which will also be used in this paper.", "startOffset": 56, "endOffset": 64}, {"referenceID": 17, "context": "For analyzing the EFHT of Markov chains, drift analysis [17, 18] is a commonly used tool, which will also be used in this paper.", "startOffset": 56, "endOffset": 64}, {"referenceID": 16, "context": "Lemma 3 (Drift Analysis [17, 18]) Given a Markov chain {\u03bet} t=0 and a distance function V (x), if it satisfies that for any t \u2265 0 and any \u03bet with V (\u03bet) > 0, 0 < cl \u2264 E[[V (\u03bet)\u2212 V (\u03bet+1)|\u03bet]] \u2264 cu, then the EFHT of this chain satisfies that V (\u03be0)/cu \u2264 E[[\u03c4 |\u03be0]] \u2264 V (\u03be0)/cl, where cl, cu are constants.", "startOffset": 24, "endOffset": 32}, {"referenceID": 17, "context": "Lemma 3 (Drift Analysis [17, 18]) Given a Markov chain {\u03bet} t=0 and a distance function V (x), if it satisfies that for any t \u2265 0 and any \u03bet with V (\u03bet) > 0, 0 < cl \u2264 E[[V (\u03bet)\u2212 V (\u03bet+1)|\u03bet]] \u2264 cu, then the EFHT of this chain satisfies that V (\u03be0)/cu \u2264 E[[\u03c4 |\u03be0]] \u2264 V (\u03be0)/cl, where cl, cu are constants.", "startOffset": 24, "endOffset": 32}, {"referenceID": 10, "context": ", [11, 17, 12].", "startOffset": 2, "endOffset": 14}, {"referenceID": 16, "context": ", [11, 17, 12].", "startOffset": 2, "endOffset": 14}, {"referenceID": 11, "context": ", [11, 17, 12].", "startOffset": 2, "endOffset": 14}, {"referenceID": 11, "context": "It has been widely used in the theoretical analysis of EAs, and the expected running time of (1+1)-EA with mutation probability 1 n has been proved to be \u0398(n ) [12].", "startOffset": 160, "endOffset": 164}, {"referenceID": 24, "context": "It has also been recognized as the hardest instance in the pseudo-Boolean function class with a unique global optimum for the (1+1)-EA [25].", "startOffset": 135, "endOffset": 139}, {"referenceID": 16, "context": "The running time of EAs has been well studied on this problem [17, 12, 27].", "startOffset": 62, "endOffset": 74}, {"referenceID": 11, "context": "The running time of EAs has been well studied on this problem [17, 12, 27].", "startOffset": 62, "endOffset": 74}, {"referenceID": 26, "context": "The running time of EAs has been well studied on this problem [17, 12, 27].", "startOffset": 62, "endOffset": 74}, {"referenceID": 11, "context": "Particularly, the expected running time of (1+1)-EA with mutation probability 1 n on it has been proved to be \u0398(n log n) [12].", "startOffset": 121, "endOffset": 125}, {"referenceID": 24, "context": "It has also been recognized as the easiest instance in the pseudo-Boolean function class with a unique global optimum for the (1+1)-EA [25].", "startOffset": 135, "endOffset": 139}, {"referenceID": 9, "context": "Droste [10] proved that the running time of (1+1)-EA can increase from polynomial to exponential due to the presence of noise.", "startOffset": 7, "endOffset": 11}, {"referenceID": 24, "context": "These two problems are known to be the hardest and the easiest instance respectively in the pseudo-Boolean function class with a unique global optimum for the (1+1)-EA [25].", "startOffset": 168, "endOffset": 172}, {"referenceID": 11, "context": "It is known that the expected running time of the (1+1)-EA on Jumpm,n is \u0398(n + n log n) [12], which implies that Jumpm,n with larger value of m is harder.", "startOffset": 88, "endOffset": 92}, {"referenceID": 1, "context": "There are naturally two fitness evaluation options for EAs [2, 21, 16, 19]:", "startOffset": 59, "endOffset": 74}, {"referenceID": 20, "context": "There are naturally two fitness evaluation options for EAs [2, 21, 16, 19]:", "startOffset": 59, "endOffset": 74}, {"referenceID": 15, "context": "There are naturally two fitness evaluation options for EAs [2, 21, 16, 19]:", "startOffset": 59, "endOffset": 74}, {"referenceID": 18, "context": "There are naturally two fitness evaluation options for EAs [2, 21, 16, 19]:", "startOffset": 59, "endOffset": 74}, {"referenceID": 9, "context": "Lemma 8 ([10]) For (1+1)-EA using re-evaluation with mutation probability 1 n on Ieasiest problem under one-bit noise, the expected running time is polynomial when pn \u2208 O(log(n)/n), and the running time is polynomial with super-polynomially small probability when pn \u2208 \u03c9(log(n)/n).", "startOffset": 9, "endOffset": 13}, {"referenceID": 22, "context": "To deal with this problem, a selection strategy for EAs handling noise was proposed [23].", "startOffset": 84, "endOffset": 88}, {"referenceID": 22, "context": ", the progress of one step) of EAs with threshold selection has been shown on some problems [23, 6, 5], its usefulness for the global performance (i.", "startOffset": 92, "endOffset": 102}, {"referenceID": 5, "context": ", the progress of one step) of EAs with threshold selection has been shown on some problems [23, 6, 5], its usefulness for the global performance (i.", "startOffset": 92, "endOffset": 102}, {"referenceID": 4, "context": ", the progress of one step) of EAs with threshold selection has been shown on some problems [23, 6, 5], its usefulness for the global performance (i.", "startOffset": 92, "endOffset": 102}, {"referenceID": 0, "context": "Lemma 9 ([1]) Given an undirected connected graphG = (V,E), the expected cover time of a random walk onG is upper bounded by 2|E|(|V | \u2212 1), where the cover time of a random walk onG is the number of steps until each vertex v \u2208 V has been visited at least once.", "startOffset": 9, "endOffset": 12}, {"referenceID": 0, "context": "Thus, the expected running time of the whole optimization process is O(n) for any pn \u2208 [0, 1], and then this theorem holds.", "startOffset": 87, "endOffset": 93}], "year": 2013, "abstractText": "Many optimization tasks have to be handled in noisy environments, where we cannot obtain the exact evaluation of a solution but only a noisy one. For noisy optimization tasks, evolutionary algorithms (EAs), a kind of stochastic metaheuristic search algorithm, have been widely and successfully applied. Previous work mainly focuses on empirical studying and designing EAs for noisy optimization, while, the theoretical counterpart has been little investigated. In this paper, we investigate a largely ignored question, i.e., whether an optimization problem will always become harder for EAs in a noisy environment. We prove that the answer is negative, with respect to the measurement of the expected running time. The result implies that, for optimization tasks that have already been quite hard to solve, the noise may not have a negative effect, and the easier a task the more negatively affected by the noise. On a representative problem where the noise has a strong negative effect, we examine two commonly employed mechanisms in EAs dealing with noise, the re-evaluation and the threshold selection strategies. The analysis discloses that the two strategies, however, both are not effective, i.e., they do not make the EA more noise tolerant. We then find that a small modification of the threshold selection allows it to be proven as an effective strategy for dealing with the noise in the problem.", "creator": "LaTeX with hyperref package"}}}