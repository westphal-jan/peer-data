{"id": "1312.1530", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Dec-2013", "title": "Bandit Online Optimization Over the Permutahedron", "abstract": "The gangapur permutahedron eurotower is the portentously convex aniline polytope with coffers vertex announces set griffith consisting blott of 95.35 the billings vectors $ (\\ cosmogenic pi (komano 1 ), \\ 13.51 dots, \\ iesus pi (delaware n) ) $ jossey-bass for tunmore all papyrus permutations (allisons bijections) $ \\ ex-us pi $ fons over $ \\ {ibushi 1, \\ http://www.uscourts.gov dots, outlast n \\} $. outskated We clewis study 80.4 a netherlanders bandit playfully game in spatula which, shankland at himeji each 15:21 step $ 124.76 t $, phala an adversary kan\u014d chooses barkero a rohmat hidden weight jabloteh weight tarkhan vector $ howls s_t $, pricey a rollercoasters player 3.528 chooses a auxin vertex $ \\ protrudes pi_t $ fushe of algemeen the unwed permutahedron and suffers fencer an observed grange loss supaul of $ \\ presov sum_ {canaan i = hovers 1} ^ blackcurrant n \\ quade pi (29.30 i) holobyte s_t (lashoff i) $.", "histories": [["v1", "Thu, 5 Dec 2013 13:00:23 GMT  (14kb)", "https://arxiv.org/abs/1312.1530v1", null], ["v2", "Sun, 6 Jul 2014 12:47:36 GMT  (25kb)", "http://arxiv.org/abs/1312.1530v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["nir ailon", "kohei hatano", "eiji takimoto"], "accepted": false, "id": "1312.1530"}, "pdf": {"name": "1312.1530.pdf", "metadata": {"source": "CRF", "title": "Bandit Online Optimization Over the Permutahedron", "authors": ["Nir Ailon", "Kohei Hatano", "Eiji Takimoto"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n31 2.\n15 30\nv2 [\ncs .L\nG ]\n6 J\ni=1 \u03c0t(i)st(i). We study the problem in two regimes. In the first regime, st is a point in the polytope dual to the permutahedron. Algorithm CombBand of Cesa-Bianchi et al (2009) guarantees a regret of O(n \u221a T log n) after T steps. Unfortunately, CombBand requires at each step an n-by-n matrix permanent computation, a #P -hard problem. Approximating the permanent is possible in the impractical running time of O(n10), with an additional heavy inverse-polynomial dependence on the sought accuracy. We provide an algorithm of slightly worse regret O(n3/2 \u221a T ) but with more realistic time complexity O(n3) per step. The technical contribution is a bound on the variance of the Plackett-Luce noisy sorting process\u2019s \u2018pseudo loss\u2019, obtained by establishing positive semi-definiteness of a family of 3-by-3 matrices of rational functions in exponents of 3 parameters.\nIn the second regime, st is in the hypercube. For this case we present and analyze an algorithm based on Bubeck et al.\u2019s (2012) OSMD approach with a novel projection and decomposition technique for the permutahedron. The algorithm is efficient and achieves a regret of O(n \u221a T ), but for a more restricted space of possible loss vectors."}, {"heading": "1 Introduction", "text": "Consider a game in which, at each step, a player plays a permutation of some ground set V = {1, . . . , n}, and then suffers (and observes) a loss. We model the loss as a sum over the items of some latent quality of the item, weighted by its position in the permutation. The game is repeated, and the items\u2019 quality can adversarially change over time. The game models many scenarios in which the player is an online system (say, a search/recommendation engine) presenting a ranked list of items (results/products) to a stream of users. A user\u2019s experience\nis positive if she perceives the quality of the top items on the list as higher than those at the bottom. The goal of the system is to create a total positive experience for its users.\nThere is a myriad of methods for modelling ranking loss functions in the literature, especially (but not exclusively) for information retrieval. Our choice allows us to study the problem in the framework of online combinatorial optimization in the bandit setting, and to obtain highly nontrivial results improving on state of the art in either run time or regret bounds. More formally, we study online linear optimization over the the n-permutahedron action set, defined as the convex closure of all vectors in Rn consisting of n distinct coordinates taking values in [n] := {1, . . . , n} (permutations). At each step t = 1, . . . , T , the player outputs an action \u03c0t and suffers a loss \u03c0 \u2032 tst = \u2211n i=1 \u03c0t(i)st(i) , where st \u2208 Rn is the vector of \u201citem qualities\u201d chosen by some adversary who knows the player\u2019s strategy but doesn\u2019t control their random coins. The performance of the player is the difference between their total loss and that of the optimal static player, who plays the best (in hindsight) single permutation \u03c0\u2217 throughout. This difference is known as regret. Note that, given s1, . . . , sT , \u03c0\n\u2217 can be computed by sorting the coordinates of\n\u2211T t=1 st in decreasing order. This is aligned with our\npractical requirement that items with higher quality should be placed first, and those with lower quality should be last."}, {"heading": "2 Results, Techniques and Contribution", "text": "Our first of two results, stated as Theorem 1, is for the setting in which at each step the loss is uniformly bounded (by 1 for simplicity) in absolute value for all possible permutations. Equivalently, the vectors st belong to the polytope that is dual to the permutahedron. Our algorithm, BanditRank, plays permutations from a distribution known as the Plackett-Luce model (see [12]) which is widely used in statistics and econometrics (see eg [3]). It uses an inverse covariance matrix of the distribution in order to obtain an unbiased loss vector estimator, which is a standard technique [6]. The main technical difficulty (Lemma 2) is in bounding second moment properties of Plackett-Luce, by establishing positive semidefiniteness of a certain family of 3 by 3 matrices. The lemma is interesting in its own right as a tool for studying distributions over permutations. The expected regret of our algorithm is O(n3/2 \u221a T ) for T steps, with running time of O(n3) per time step. This result should be compared to CombBand of [6], where a framework for playing bandit games over combinatorially structured sets was developed. Their techniques extend that of [7]. In each step, it draws a permutation from a distribution that assigns to each permutation \u03c0 a probability of e\u03b7 \u2211t \u03c4=1 \u03c0\n\u2032 s\u0303\u03c4 , where s\u0303t is a pseudo-loss vector at time t, an unbiased estimator of the loss vector st. Their algorithm guarantees a regret of O(n \u221a T logn), which is better than ours by a factor of \u0398( \u221a\nn/ logn). However, its computational requirements are much worse. In order to draw permutations, they need to compute nonnegative n by n matrix permanents. Unfortunately, nonnegative permanent computation is #P -hard, as shown by [14]. On the other hand, a\ngroundbreaking result of [11] presents a polynomial time approximation scheme for permanent, which runs in time O(n10) for fixed accuracy. To make things worse, the dependence in the accuracy is inverse polynomial, implying that, even if we could perform arbitrarily accurate floating point operations, the total running time would be super linear in T , because a regret dependence of \u221a T over T steps requires accuracy inverse polynomial in T . (Our algorithm does not suffer from this problem.) From a practical point of view, the runtime dependence of CombBand in both n and T is infeasible for even modest cases. For example, our algorithm can handle online ranking of n = 100 items in an order of few millions of operations per game iteration. In contrast, approximating the permanent of a 100-by-100 positive matrix is utterly impractical.\nWe note that independently of our work, Hazan et al. [9] have improved the state-of-the-art general purpose algorithm for linear bandit optimization, implying an algorithm with regret O(n \u221a T ) for our problem, but with worse running time O\u0303(n4).1\nIn our second result in Section 5 we further restrict st to have \u21131 norm of 1/n. (Note that this restriction is contained in |\u03c0\u2032tst| \u2264 1 by Ho\u0308lder). We present and analyze an algorithm OSMDRank based on the bandit algorithm OSMD of [5] with projection and decomposition techniques over the permutahedron ([15, 13]). The projection is defined in terms of the binary relative entropy divergence. The restriction allows us to obtain an expected regret bound of O(n \u221a T ) (a \u221a logn improvement over CombBand). The running time is O(n2+ n\u03c4(n)), where \u03c4(n) is the time complexity for some numerical procedure, which is O(n2) in a fixed precision machine.\nWe note previous work on playing the permutahedron online optimization game in the full information case, namely, when st is known for each t. As far as we know, Helmbold et al. [10] were the first to study a more general version of this problem, where the action set is the vertex set of the Birkhoff-von-Neumann polytope (doubly-stochastic matrices). Suehiro et al. [13] studied the problem by casting it as a submodularly constrained optimization problem, giving near optimal regret bounds, and more recently Ailon [1] both provided optimal regret bounds with improved running time and established tight regret lower bounds."}, {"heading": "3 Definitions and Problem Statement", "text": "Let V be a ground set of n items. For simplicity, we identify V with [n] := {1, . . . n}. Let Sn denote the set of n! permutations over V , namely bijections over [n]. By convention, we think of \u03c0(v) for v \u2208 V as the position of v \u2208 V in the ranking, where we think of lower numbered positions as more favorable. For distinct u, v \u2208 V , we say that u \u227a\u03c0 v if \u03c0(u) < \u03c0(v) (in words: u beats v). We use [u, v]\u03c0 as shorthand for the indicator function of the predicate u \u227a\u03c0 v.\n1The running time is a product of O\u0303(n3) number of Markov chain steps required for drawing a random point from a convex set under a log-concave distribution, and O(n logn) time to test whether a point lies in the permutahedron. By O\u0303 we hide poly-logarithmic factors.\nThe convex closure of Sn is known as the permutahedron polytope. It will be more convenient for us to consider a translated version of the permutahedron, centered around the origin. More precisely, for \u03c0 \u2208 Sn we let \u03c0\u0302 denote\n\u03c0\u0302 := (\u03c0(1)\u2212 (n+ 1)/2, \u03c0(2)\u2212 (n+ 1)/2, . . . , \u03c0(n)\u2212 (n+ 1)/2) .\nIt will be convenient to define a symmetrized version of the permutation set S\u0302n := {\u03c0\u0302 : \u03c0 \u2208 Sn}. The symmetrized n-permutahedron, denoted P\u0302n is the convex closure of S\u0302n. Symmetrization allows us to work with a polytope that is centered around the origin. Generalization our result to standard (un-symmetrized) permutations is a simple technicality that will be explained below. The notation u \u227a\u03c0\u0302 v and [u, v]\u03c0\u0302 is defined as for \u03c0 \u2208 Sn in an obvious manner.\nAt each step t = 1, . . . , T , an adversary chooses and hides a nonnegative vector st \u2208 Rn \u2261 RV , which assigns an elementwise quality measure st(v) for any v \u2208 V . The player-algorithm chooses a permutation \u03c0\u0302t \u2208 S\u0302n, possibly random, and suffers an instantaneous loss\n\u2113t := \u03c0\u0302 \u2032 tst =\n\u2211 v\u2208V \u03c0\u0302t(v)st(v) . (3.1)\nThe total loss Lt is defined as \u2211T t=1 \u2113t. We will work with the notion of regret, defined as the difference Lt \u2212 L\u2217t , where L\u2217T = min\u03c0\u0302\u2208S\u0302n \u2211T t=1 \u03c0\u0302 \u2032st. We let \u03c0\u0302\u2217 denote any minimizer achieving L\u2217T in the RHS.\nFor any \u03c0\u0302 \u2208 S\u0302n and s \u2208 Rn, the dot-product \u03c0\u0302\u2032s can be decomposed over pairs: \u03c0\u0302\u2032s = 12 \u2211\nu6=v[u, v]\u03c0(s(v) \u2212 s(u)). This makes the symmetrized permutahedron easier to work with. Nevertheless, our results also apply to the non-symmetrized permutahedron as well, as we shall see below.\nThroughout, the notation \u2211\nu6=v means summation over distinct, ordered pairs of elements u, v \u2208 V , and\u2211u<v means summation over distinct, unordered pairs.2 The uniform distribution over S\u0302n will be denoted Un.\nThe smallest eigenvalue of a PSD matrix A is denoted \u03bbmin(A). The norm \u2016\u00b7\u20162 will denote spectral norm (Euclidean norm for a vector). To avoid notation such as C,C\u2032, C\u2032\u2032, C1 for universal constants, the expression C will denote a \u201cgeneral positive constant\u201d that may change its value as necessary. For example, we may write C = 3C + 5.\n4 Algorithm BanditRank and its Guarantee\nFor this section, we will assume that the instantaneous losses are uniformly bounded by 1, in absolute value: For all t and \u03c0\u0302 \u2208 S\u0302n, |\u03c0\u0302\u2032st| \u2264 1. Equivalently, using geometric language, the loss vectors belong to a polytope which is dual to the permutahedron.\nNow consider Algorithm 1. It maintains, at each time step t, a weight vector wt \u2208 Rn. At each time step, it draws a random permutation \u03c0\u0302t from a mixture\n2We will only use expressions of the form \u2211\nu<v f(u, v) for symmetric functions satisfying f(u, v) = f(v, u).\nDt of the uniform distribution over S\u0302n and a distribution PLn(w) which we define shortly. The distribution mixture is determined by a parameter \u03b3. The algorithm then plays the permutation \u03c0\u0302t and thereby suffers the instantaneous loss defined in (3.1). The weights are consequently updated by adding an unbiased estimator s\u0303t of st (computed using the pseudo-inverse covariance matrix corresponding to Dt), multiplied by another parameter \u03b7 > 0.\nThe Plackett-Luce Random Sorting Procedure: The distribution PLn(w) over S\u0302n, parametrized by w \u2208 Rn, is defined by the following procedure. To choose the first (most preferred) item, the procedure draws a random item, assigning probability proportional to ew(u) for each u \u2208 V . It then removes this item from the pool of available items, and iteratively continues to choose the second item, then third and so on. As claimed in the introduction, this random permutation model is well studied in statistics. An important well known property of the distribution is that it can be equivalently defined as a Random Utility Model (RUM) [12, 16]: To draw a permutation, add a random iid noise variable following the Gumbel distribution to each weight, and then sort the items of V in decreasing value of noisy-weights.3 The RUM characterization implies, in particular, that for any two disjoint pairs of element (u, v) and (u\u2032, v\u2032), the events u \u227a\u03c0 v and u\u2032 \u227a\u03c0 v\u2032 are statistically independent if \u03c0 is drawn from PLn(w), for any w. This fact will be used later. We are finally ready to state our main result, bounding the expected regret of the algorithm.\nTheorem 1. If algorithm BanditRank (Algorithm 1) is executed with parameters \u03b3 = O(n3/2/ \u221a T ) and \u03b7 = O(\u03b3/n), then the expected regret (with respect to the game defined by the symmetrized permutahedron) is at most O(n3/2 \u221a T ). The running time of each iteration is O(n3). Additionally, there exists an algorithm with the same expected regret bound and running time with respect to the standard permutahedron (assuming the vectors st uniformly satisfy |\u03c0\u2032st| \u2264 1, \u2200\u03c0 \u2208 Sn.)\nThe proof uses a standard technique used e.g. in Cesa-Bianchi et al.\u2019s CombBand [6], which is itself an adaptation of Auer et al.\u2019s Exp3 [2] from the finite case to the structured combinatorial case. The distribution from which the actions \u03c0\u0302t are drawn in the algorithm differ from the distribution used in CombBand, and give rise to the technical difficulty of variance estimation, resolved in Lemma 2.\nProof. Let Tn denote the set of tournaments over [n]. More precisely, an element A \u2208 Tn is a subset of [n]\u00d7 [n] with either (u, v) \u2208 A or (v, u) \u2208 A (but not both) for all u < v. We extend our previous notation so that u \u227aA v is equivalent to the predicate (u, v) \u2208 A.\n3The Gumbel distribution, also known as doubly-exponential, has a cdf of e\u2212e \u2212x .\nAlgorithm 1 Algorithm BanditRank(n, \u03b7, \u03b3, T ) (assuming |\u03c0\u0302\u2032st| \u2264 1 for all t and \u03c0\u0302 \u2208 S\u0302n) 1: given: ground set size n, positive parameters \u03b7, \u03b3 (\u03b3 \u2264 1), time horizon T 2: set w0(u) = 0 for all u \u2208 V = [n] 3: for t = 1..T do 4: let distribution Dt over S\u0302n denote a mixture of Un (with probability \u03b3)\nand PLn(wt\u22121) (with probability 1\u2212 \u03b3) 5: draw and output \u03c0\u0302t \u223c Dt 6: observe and suffer loss \u2113t (= \u03c0\u0302 \u2032 tst) 7: s\u0303t = \u2113tP + t \u03c0\u0302t where Pt = E\u03c3\u0302\u223cDt [\u03c3\u0302\u03c3\u0302\n\u2032] 8: set wt = wt\u22121 + \u03b7s\u0303 9: end for\nFor any pair \u03c0\u0302 \u2208 S\u0302n and w \u2208 Rn, p(\u03c0\u0302|w) denotes the probability assigned to \u03c0\u0302 \u2208 S\u0302n by PLn(w). Slightly abusing notation, we define the following shorthand:\np(u \u227a v|w) := \u2211 \u03c0\u0302:u\u227a\u03c0\u0302v p(\u03c0|w) = e\nw(u)\new(u) + ew(v)\np(u \u227a v \u227a z|w) := \u2211 \u03c0\u0302:u\u227a\u03c0\u0302v\u227a\u03c0\u0302z p(\u03c0\u0302|w) = e\nw(u)+w(v)\n(ew(u) + ew(v) + ew(z))(ew(v) + ew(z)) .\nThe last two right hand sides are easily derived from the definition of the distribution PLn(w), see also e.g. [12]. We also define the following abbreviations:\np(u \u227a vz |w) := p(u \u227a v \u227a z|w) + p(u \u227a z \u227a v|w) = ew(u)\new(u) + ew(v) + ew(z)\n(4.1)\np(uv \u227a z|w) := p(u \u227a v \u227a z|w) + p(v \u227a u \u227a z|w)\n= ew(u)+w(v)\new(u) + ew(v) + ew(z)\n(\n1\new(v) + ew(z) +\n1\new(u) + ew(z)\n)\n(4.2)\nWe will also need to define a distribution over the set of tournaments Tn. The distribution, BT Ln(w) is parametrized by a weight vector w \u2208 Rn. Drawing A \u223c BT Ln(w) is done by independently setting, for all u < v in V ,\n(u, v) \u2208 A with probability p(u \u227a v|w) = e w(u)\new(u) + ew(v)\n(v, u) \u2208 A with probability p(v \u227a u|w) = e w(v)\new(u) + ew(v) .\n(Note that the distribution is equivalently defined as the product distribution, over all u < v in V , of the Bradley-Terry-Luce pairwise preference model, hence\nthe name BT Ln. We refer to [12] for definition and history of the BradleyTerry-Luce model.)\nFor A \u2208 Tn, we denote by p\u0303(A|w) the probability \u220f u\u227aAv p(u \u227a v|w) of drawing A from BT Ln(w). The proof of the theorem proceeds roughly as the main result upper bounding the expected regret of CombBand in [6]. The following technical lemma is required in anticipation of a major hurdle (inequality (4.5). We believe the inequality is interesting in its own right as a probabilistic statement on permutation and tournament distributions.\nLemma 2. Let s, w \u2208 Rn. Let \u03c0\u0302 \u223c PLn(w) and A \u223c BT Ln(w) be drawn independently. Define X1 = \u2211\nu,v: u\u227a\u03c0\u0302v(s(v)\u2212s(u)) = \u03c0\u0302 \u2032s, X2 = \u2211 u,v: u\u227aAv(s(v)\u2212 s(u)). Then E[X22 ] \u2264 E[X21 ].\n(Note that clearly, E[X2] = E[X1], so the lemma in fact upper bounds the variance of X2 by that of X1.) The proof of the lemma is deferred to Section 4.1.\nContinuing the proof of Theorem 1, we let q(\u03c0|w) denote the probability of drawing \u03c0 from the mixture of the uniform distribution (with probability \u03b3) and PLn(w) (with probability (1 \u2212 \u03b3). Similarly to above, q(u \u227a v|w) denotes \u2211\n\u03c0\u0302:u\u227a\u03c0\u0302v q(\u03c0\u0302|w). By these definitions,\nq(\u03c0\u0302|w) = (1\u2212 \u03b3)p(\u03c0\u0302|w) + \u03b3 n!\nq(u \u227a v|w) = (1\u2212 \u03b3)p(u \u227a v|w) + \u03b3 2 . (4.3)\nThe analysis proceeds by defining a potential function: Wt(u, v) := e 1 2\u03b7(wt(u)\u2212wt(v))+ e 1 2 \u03b7(wt(v)\u2212wt(u)). The quanatity of interest will be E [ \u2211\nu<v\n\u2211 t log Wt(u,v)\nWt\u22121(u,v)\n]\n,\nwhere the expectation is taken over all random coins used by the algorithm throughout T steps. This quantity will be bounded from above and from below, giving rise to a bound on the expected total loss, expressed using the optimal static loss. On the one hand,\n\u2211\nu<v\nlog Wt(u, v)\nWt\u22121(u, v) =\n\u2211\nu<v\nlog\n(\ne 1 2 (wt(u)\u2212wt(v))\nWt\u22121(u, v) +\ne 1 2 (wt(v)\u2212wt(u))\nWt\u22121(u, v)\n)\n= \u2211\nu<v\nlog\n(\ne 1 2 (wt\u22121(u)\u2212wt\u22121(v))e 1 2\u03b7(s\u0303t(u)\u2212s\u0303t(v))\nWt\u22121(u, v) +\ne 1 2 (wt(v)\u2212wt(u))e 1 2\u03b7(s\u0303t(v)\u2212s\u0303t(u))\nWt\u22121(u, v)\n)\n= \u2211\nu<v\nlog ( p(u \u227a v|wt\u22121)e 1 2\u03b7(s\u0303t(u)\u2212s\u0303t(v)) + p(v \u227a u|wt\u22121)e 1 2 \u03b7(s\u0303t(v)\u2212s\u0303t(u)) )\n= log\n(\n\u2211\nA\u2208Tn p\u0303(A|wt\u22121)e\n1 2 \u03b7 \u2211 u\u227aAv\n(s\u0303t(u)\u2212s\u0303t(v)) )\n.\nWe will now assume that \u03b7 is small enough so that for all A \u2208 Tn and for all t,\n\u03b7\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2211 (u,v)\u2208A (s\u0303t(u)\u2212 s\u0303t(v)) \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2264 1 . (4.4)\n(This will be shortly enforced.) Using ex \u2264 1 + x+ x2 \u2200x \u2208 [\u22121/2, 1/2],\n\u2211\nu,v\nlog Wt(u, v)\nWt\u22121(u, v) \u2264 log\n[\n\u2211\nA\u2208Tn p\u0303(A|wt\u22121)\n(\n1 + \u03b7\n2\n\u2211\nu\u227aAv (s\u0303t(u)\u2212 s\u0303t(v))\n+ \u03b72\n4\n(\n\u2211\nu\u227aAv (s\u0303t(u)\u2212 s\u0303t(v))\n)2 \n\n\n\n= log\n\n1 + \u03b7\n2 EA\u223cBT Ln(wt\u22121)\n\n\n\u2211\nu\u227aAv (s\u0303t(u)\u2212 s\u0303t(v)) +\n\u03b72\n4\n(\n\u2211\nu\u227aAv (s\u0303t(u)\u2212 s\u0303t(v))\n)2 \n\n\n\n\u2264 log\n\n1 + \u03b7\n2 E\u03c0\u0302\u223cPLn(wt\u22121)\n\n\n\u2211\nu\u227a\u03c0\u0302v (s\u0303t(u)\u2212 s\u0303t(v)) +\n\u03b72\n4\n(\n\u2211\nu\u227a\u03c0\u0302v (s\u0303t(u)\u2212 s\u0303t(v))\n)2 \n\n\n .\n(4.5)\nwhere we used Lemma 2 in the last inequality (together with the fact that the marginal probability of the event \u201cu \u227aY v\u201d is identical for both Y \u223c PLn(wt\u22121) and Y \u223c BT Ln(wt\u22121)). Henceforth, for any \u03c0\u0302 \u2208 S\u0302, we let \u2113\u0303t(\u03c0\u0302) := \u03c0\u0302\u2032s\u0303t = \u2211\nu\u227a\u03c0\u0302v(s\u0303(v)\u2212 s\u0303(u)). Using 4.3 and the fact that log(1+x) \u2264 x for all x, we get\n\u2211\nu<v\nlog Wt(u, v)\nWt\u22121(u, v)\n\u2264 \u03b7 2 \u2211\nu6=v\nq(u \u227a v|wt\u22121)\u2212 \u03b32 1\u2212 \u03b3 (s\u0303t(u)\u2212 s\u0303t(v)) + \u03b72 4 \u2211\n\u03c0\u0302\u2208S\u0302n\nq(\u03c0|wt\u22121)\u2212 \u03b3n! 1\u2212 \u03b3 \u2113\u0303t(\u03c0\u0302) 2\n\u2264 \u2212\u03b7 2(1\u2212 \u03b3) \u2211\n\u03c0\u0302\u2208S\u0302n\nqt(\u03c0\u0302|wt\u22121)\u2113\u0303t(\u03c0\u0302) + \u03b72\n4(1\u2212 \u03b3) \u2211\n\u03c0\u0302\u2208S\u0302n\nqt(\u03c0\u0302|wt\u22121)\u2113\u0303t(\u03c0\u0302)2 .\nWe now note that (1) \u2211 \u03c0\u0302\u2208S\u0302 qt(\u03c0\u0302|wt\u22121)\u2113\u0303t = \u2113t (following the properties of matrix pseudo-inverse in Line 7 in Algorithm 1), and (2) \u2211\n\u03c0\u0302\u2208S\u0302n qt(\u03c0\u0302|wt\u22121)\u2113\u0303t(\u03c0) 2] \u2264\nn (see top of page 31 together with Lemma 15 in [6]). Applying these inequalities, and then taking expectations over the algorithm\u2019s randomness and summing for t = 1, . . . , T , we get\nT \u2211\nt=1\nE\n[\n\u2211\nu,v\nlog Wt(u, v)\nWt\u22121(u, v)\n]\n\u2264 \u2212 \u03b7 2(1\u2212 \u03b3)E[LT ] +\n\u03b72\n8(1\u2212 \u03b3)nT .\nOn the other hand,\nT \u2211\nt=1\nE\n[\n\u2211\nu,v\nlog Wt(u, v)\nWt\u22121(u, v)\n]\n\u2265 \u2211\nu,v\nE\n[ log ( [u, v]\u03c0\u2217e 1 2 (wT (u)\u2212wT (v)) + [v, u]\u03c0\u2217e 1 2 (wT (u)\u2212wT (v))) )] \u2212 \u2211\nu,v\nlog 2\n= 1\n2\n\u2211\nu,v\n(E [[u, v]\u03c0\u2217(wT (u)\u2212 wT (v)) + [v, u]\u03c0\u2217(wT (u)\u2212 wT (v))])\u2212 ( n\n2\n)\nlog 2\n= \u03b7\n2\n\u2211\nu,v\n(\nE\n[\n[u, v]\u03c0\u2217 \u2211\nt\n(s\u0303t(u)\u2212 s\u0303t(v)) + [v, u]\u03c0\u2217 \u2211\nt\n(s\u0303t(u)\u2212 s\u0303t(v)) ]) \u2212 ( n\n2\n)\nlog 2\n= \u03b7\n2\n\u2211\nu,v\n(\n[u, v]\u03c0\u2217 \u2211\nt\n(st(u)\u2212 st(v)) + [v, u]\u03c0\u2217 \u2211\nt\n(st(u)\u2212 st(v)) ) \u2212 ( n\n2\n)\nlog 2\n= \u2212\u03b7 2 L\u2217T \u2212\n(\nn\n2\n)\nlog 2 ,\nwhere L\u2217T is the total loss of a player who chooses the best permutatation \u03c0\u0302 \u2217 \u2208 S\u0302n in hindsight. Combining, we obtain \u03b7 2(1\u2212\u03b3)E[Lt] \u2264 \u03b7 2L \u2217 T+ n2 2 log 2+ \u03b72 4(1\u2212\u03b3)nT . Multiplying both sides by 2(1\u2212 \u03b3)/\u03b7 yields\nE[LT ] \u2264 L\u2217T + \u03b3|L\u2217T |+ n2 log 2\n\u03b7 +\n\u03b7 2 nT . (4.6)\nWe shall now work to impose (4.4).\nmax t max A\u2208T (V )\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2211 (u,v)\u2208A (s\u0303t(u)\u2212 s\u0303t(v)) \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2264 max t \u221a \u2211 v\u2208V s\u0303t(v)2\n\u221a \u221a \u221a \u221a \u221a (n\u22121)/2 \u2211\ni=\u2212(n\u22121)/2 i2 \u2264 Cmax t \u2016s\u0303t\u20162n3/2 ,\nwhere the left inequality is Cauchy-Schwartz. We now note that \u2016s\u0303t\u20162 \u2264 |\u2113t|\u2016P+t \u20162\u2016\u03c0\u0302t\u20162. Clearly \u2016\u03c0\u0302\u20162 is bounded above by Cn3/2. Also \u2016P+t \u20162 equals 1/\u03bbmin(Pt). By Weyl\u2019s inequality \u03bbmin(Pt) \u2265 \u03b3\u03bbmin(E\u03c4\u0302\u223cUn [\u03c4\u0302 \u03c4\u0302 \u2032]). It is an exercise to check that \u03bbmin(E\u03c4\u0302\u223cUn [\u03c4\u0302 \u03c4\u0302\n\u2032]) \u2265 Cn2. We conclude (also recalling that |\u2113t| \u2264 1) that maxt \u2016s\u0303t\u20162 \u2264 C/(n1/2\u03b3). Combining, we shall satisfy (4.7) by imposing \u03b7 \u2264 \u03b3/(Cn). Plugging in (4.6), we get\nE[LT (Alg)] \u2264 L\u2217T + \u03b3|L\u2217T |+ Cn3\n\u03b3 + C\u03b3T . (4.7)\nChoosing \u03b3 = \u221a Cn3\nT gives E[LT (Alg)] \u2264 L\u2217T + Cn 3/2 \u221a T |L\u2217T |+ n3/2 \u221a T .\nThis concludes the required result for the symmetrized case, because |L\u2217T | \u2264 T . For the standard permutahedron, we notice that for any \u03c0 \u2208 Sn and its symmetrized counterpart \u03c0\u0302 \u2208 S\u0302n, and any vector s \u2208 Rn, \u03c0\u2032s \u2212 \u03c0\u0302\u2032s =\nn\u22121 2 \u2211 v\u2208V s(v) =: f(s). Equivalently, we can write \u03c0 \u2032s = (\u03c0\u0302\u2032, 1)(s; f(s)), where (\u00b7, a) appends the scalar a to the right of a row vector and (\u00b7; a) appends to the bottom of a column vector. Algorithm 1 can be easily adjusted to work with action set S\u0302n \u00d7 {1}. For the proof, we keep the same potential function. The technical part of the proof is lower bounding the smallest eigenvalue of the expectation of \u03c4\u0302 \u03c4\u0302 \u2032, where \u03c4\u0302 is now drawn from the uniform distribution on S\u0302n \u00d7 {1}. We omit these simple details for lack of space."}, {"heading": "4.1 Proof of Lemma 2", "text": "The expression E[X21 ] can be written as\nE[X21 ] = \u2211 u6=v p(u \u227a v|w)((s(v) \u2212 s(u))2\n+ \u2211 |{u,v,u\u2032,v\u2032}|=4 p(u \u227a v \u2227 u\u2032 \u227a v\u2032|w) (s(v) \u2212 s(u))(s(v\u2032)\u2212 s(u\u2032)) + \u2211\nu6=v,u\u2032 6=v\u2032\n|{u,v,u\u2032,v\u2032}|=3\np(u \u227a v \u2227 u\u2032 \u227a v\u2032|w) (s(v) \u2212 s(u))(s(v\u2032)\u2212 s(u\u2032)) , (4.8)\nwhere p(u \u227a v \u2227 u\u2032 \u227a v\u2032|w) is the probability that both u \u227a\u03c0\u0302 v and u\u2032 \u227a\u03c0\u0302 v\u2032 with \u03c0\u0302 \u223c PLn(w). Similarly,\nE[X22 ] = \u2211 u6=v p(u, v|w)((s(v) \u2212 s(u))2\n+ \u2211 |{u,v,u\u2032,v\u2032}|=4 p(u \u227a v|w)p(u\u2032 \u227a v\u2032|w) (s(v) \u2212 s(u))(s(v\u2032)\u2212 s(u\u2032)) + \u2211\nu6=v,u\u2032 6=v\u2032\n|{u,v,u\u2032,v\u2032}|=3\np(u \u227a v|w)p(u\u2032 \u227a v\u2032|w) (s(v) \u2212 s(u))(s(v\u2032)\u2212 s(u\u2032)) .\n(4.9)\nSince Plackett-Luce is a random utility model (see [12]), it is clear that whenever a pair of pairs u 6= v, u\u2032 6= v\u2032 satisfies |{u, v, u\u2032, v\u2032}| = 4, p(u \u227a v \u2227 u\u2032 \u227a v\u2032|w) = p(u \u227a v|w)p(u\u2032 \u227a v\u2032|w). Hence, it suffices to prove that the third summand in the RHS of (4.9) is upper bounded by the third summand in the RHS of (4.8). But now notice the following identity:\n\u2211\nu6=v,u\u2032 6=v\u2032\n|{u,v,u\u2032,v\u2032}|=3\n\u2261 \u2211\n\u2206\u2286V |\u2206|=3\n\u2211\nu6=v,u\u2032 6=v\u2032\nu,v,u\u2032,v\u2032\u2208\u2206 |{u,v,u\u2032,v\u2032}|=3\n.\nThis last sum rearrangement implies that it suffices to prove that for any \u2206 of\ncardinality 3,\nF2(\u2206) := \u2211\nu6=v,u\u2032 6=v\u2032\nu,v,u\u2032 ,v\u2032\u2208\u2206\n|{u,v,u\u2032,v\u2032}|=3\np(u, v|w)p(u\u2032, v\u2032|w) (s(v) \u2212 s(u))(s(v\u2032)\u2212 s(u\u2032))\n\u2264 \u2211\nu6=v,u\u2032 6=v\u2032\nu,v,u\u2032,v\u2032\u2208\u2206\n||{u,v,u\u2032,v\u2032}|=3\np(u, v \u2227 u\u2032, v\u2032|w) (s(v) \u2212 s(u))(s(v\u2032)\u2212 s(u\u2032)) =: F1(\u2206) .\nIf we now denote \u2206 = {a, b, c}, then both F1(\u2206) and F2(\u2206) are quadratic forms in s(a), s(b), s(c) (for fixed w). It hence suffices to prove that H(\u2206) := F1(\u2206)\u2212F2(\u2206) is a positive semi-definite form in s(\u2206) := (s(a), s(b), s(c))\u2032. We now write\nH(\u2206) = s(\u2206)\u2032\n\n\nHaa 1 2Hab 1 2Hac 1 2Hab Hbb 1 2Hbc 1 2Hac 1 2Hbc Hcc\n\n s(\u2206) .\nThe matrix is singular, because clearly H(\u2206) = F1(\u2206) = F2(\u2206) = 0 whenever s(a) = s(b) = s(c). To prove positive semi-definiteness, by Sylvester\u2019s criterion it hence suffices to show that the diagonal element Haa \u2265 0 and that the principal 2-by-2 minor determinant HaaHbb \u2212 14H2ab \u2265 0. Using the definitions, together with the properties of PLn(w), a technical (but quite tedious) algebraic derivation (see Appendix A for details) gives\nHaa = 4es(a)+s(b)+s(c)\n(es(a) + es(b))(es(a) + es(c))(es(a) + es(b) + es(c)) . (4.10)\nSimilarly, by symmetry, Hbb = 4es(a)+s(b)+s(c)\n(es(b)+es(a))(es(b)+es(c))(es(a)+es(b)+es(c)) . From a\nsimilar (yet more tedious) technical algebraic calculation which we omit, one gets: (see Appendix A for details):\nHab = \u22128es(a)+s(b)+2s(c)\n(es(a) + es(b))(es(a) + es(c))(es(b) + es(c))(es(a) + es(b) + es(c)) . (4.11)\nOne now verifies, using (4.10)-(4.11), the identity\nHaaHbb\u2212 1\n4 H2ab =\n16e2s(a)+2s(b)+2s(c)\n(es(a) + es(b))2(es(a) + es(c))(es(b) + es(c))(es(a) + es(b) + es(c))2 .\nIt remains to notice, trivially, that Haa \u2265 0 and HaaHbb \u2212 14H2ab \u2265 0 for all possible values of s(a), s(b), s(c). The proof of the lemma is concluded."}, {"heading": "5 Bandit Algorithm based on Projection and", "text": "Decomposition\nIn this section, we propose another bandit algorithm OSMDRank, described in Algorithm 2. We will be working under the more restricted assumption that\nAlgorithm 2 Algorithm OSMDRank(n, \u03b7, \u03b3, T ) (assuming \u2016st\u20161 \u2264 1 and \u03c0\u0302t \u2208 Q\u0302n for all t )\n1: given: ground set size n, positive parameters \u03b7, \u03b3 (\u03b3 \u2264 1), time horizon T 2: let x1 = 0 \u2208 Q\u0302n. (Note that x1 = argmina\u2208Q\u0302n F (a)) 3: for t = 1, . . . , T do 4: let x\u0303t = (1\u2212 \u03b3)xt (Note that a\u0303t \u2208 Q\u0302n since the origin 0 and xt are in Q\u0302n and x\u0303t is a convex combination of them). 5: output \u03c0t = Decomposition(x\u0303t) (i.e., choose \u03c0t so that E[\u03c0t] = x\u0303t) and\nsuffer loss \u2113t (= \u03c0 \u2032 tst)\n6: let distribution Dt over [\u22121, 1]ndenote a mixture of the uniform distribution over the canonical basis with random sign (with probability \u03b3) and a Radmacher distribution over {\u22121, 1}n with parameter (1 + xt,i)/2 for each i = 1, . . . , n (with probability 1\u2212 \u03b3) 7: estimate the loss vector s\u0303t = \u2113tP + t \u03c0t, where Pt = E\u03c3\u223cDt [\u03c3\u03c3\n\u2032] 8: let xt+ 12 = \u2207F\n\u2217(F (xt)\u2212 \u03b7s\u0303t) 9: let xt+1 = Projection(xt+ 12 ) (that is, xt+1 = minx\u2208Q\u0302n DF (x, xt+ 12 ))\n10: end for\nsup \u2016st\u20161 \u2264 1 and sup \u2016\u03c0\u0302t\u2016\u221e \u2264 1. This in particular implies that |\u03c0\u0302\u2032tst| \u2264 1, as before. But now we shall achieve a better expected regret of O(n \u221a T ).\nWe prefer, for reasons clarified shortly, to require that the actions \u03c0\u0302t are vertices of the rescaling Q\u0302n := 2 n\u22121 P\u0302n \u2208 [\u22121, 1]n of the symmetrized permutahedron. That is, sup \u2016\u03c0\u0302t\u2016\u221e \u2264 1 (and sup \u2016st\u20161 \u2264 1). This will allow us to work with the following standard regularizer F : [\u22121, 1]n \u2192 R+: F (x) = 12 \u2211n i=1 ((1 + x) ln(1 + x) + (1 \u2212 x) ln(1 \u2212 x)). The regularizer F (x) is the key to the OSMD (Online Stochastic Mirror Descent) algorithm of Bubeck et al. [5], on which our algorithm is based. OSMD is a bandit algorithm over the hypercube domain [\u22121, 1]n and a variant of Follow the Regularized Leader (FTRL, e.g., [8]) for linear loss functions. To apply this algorithm, we need a new projection and decomposition technique for the polytope Q\u0302n, as well as a slightly modified perturbation step in line 4 of Algorithm 2. Our algorithm OSMDRank has the following two procedures:\n1. Projection: Given a point xt \u2208 [\u22121, 1]n, return argminyt\u2208Q\u0302n \u2206F (yt, xt), where \u2206F is the Bregman divergence defined wr.t. F , i.e., \u2206F (y, x) = F (y)\u2212 F (x)\u2212\u2207F (x)\u2032(y \u2212 x) (also known as binary relative entropy).4\n2. Decomposition: Given yt \u2208 Q\u0302n from the the projection step, output a random vertex \u03c0\u0302t of Q\u0302n such that E[\u03c0\u0302t] = yt.\nThe decomposition can be done using the technique of [15], which runs in O(n logn) time. (To be precise, the method there was defined for the standard\n4Note that the binary relative entropy is different from the relative entropy, where the relative entropy is defined as Rel(p, q) =\n\u2211n i=1 pi ln pi qi for probability distributions p and q\nover [n].\npermutahedron; The adjustments for the symmetrized version are trivial.) For notational purposes, we define f := \u2207F , and notice that f(x)i = 12 ln 1+xi1\u2212xi , and its inverse function f\u22121 is given by f\u22121(y)i = eyi\u22121 eyi+1 . Our projection procedure is presented in Algorithm 3.\nLemma 3. (i) Given q \u2208 [\u22121, 1]n, Algorithm 3 outputs the projection of q onto Q\u0302n, with respect to the regularizer F . (ii) The time complexity of the algorithm is O(n\u03c4(n) + n2), where \u03c4(n) is the time complexity to perform step 4.\nskecth. Our projection algorithm is an extension of that in [13] and our proof follows a similar argument in [13]. For simplicity, we assume that elements in q are sorted in descending order, i.e., q1 \u2265 q2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 qn. This can be achieved in time O(n log n) by sorting q. Then, it can be shown that projection preserves the order in q by using Lemma 1 in [13]. That is, the projection p of q satisfies p1 \u2265 p2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 pn. So, if the conditions 2n\u22121 \u2211i j=1 pj \u2264 \u2211i j=1( n+1 2 \u2212 j), for i = 1, . . . , n\u2212 1, are satisfied, then other inequality constraints are satisfied as well since for any S \u2282 [n] such that |S| = i, \u2211j\u2208S pj \u2264 \u2211i j=1 pj . Therefore, relevant constraints for projection onto Q\u0302n are only linearly many. By following a similar argument in [13], we can show that the output p indeed satisfies the KKT optimality conditions for projection, which completes the proof of the first statement. Finally, the algorithm terminates in time O(n\u03c4(n)+ n2) since the number of iteration is at most n and each iteration takes O(n + \u03c4(n)) time, which completes the second statement of the lemma.\nNote that with respect to other regularizers (e.g. relative entropy or Euclidean norm squared), a different projection scheme is possible in time O(n2) (see [15, 13] for the details). It is an open question whether an O(n2) algorithm can be devised with respect to the binary relative entropy we need here. In our case, we need to solve a numerical optimization problem by, say, binary search. Note that the time \u03c4(n) is reasonably small: In fact, we can perform the binary search over the domain [\u22121, 1] for each dimension i. Therefore, if the precision is a fixed constant, the binary search ends in time O(n) for each dimension. In that case, \u03c4(n) is O(n2). We are ready to present our main result for this section.\nTheorem 4. For \u03b7 = O(n \u221a 1/T ) and \u03b3 = O( \u221a 1/T ), Algorithm OSMDRank has expected regret O(n \u221a T ) and running time O(n2 + n\u03c4(n)) per step, where \u03c4(n) is the time for a numerical optimization step depending on n. Additionally, there exists an algorithm with the same expected regret bound and running time with respect to the standard permutahedron (assuming \u2016st\u20161 \u2264 1/n).\nsketch. The algorithm OSMDRank is a modification of OSMD for the hypercube [\u22121, 1]n obtained by adding (1) a projection step and (2) a decomposition step. Standard techniques show that adding the projection step does not increase the expected regret bound (see, e.g., chapters 5 and 7 on OMD and OSMD of Bubeck\u2019s lecture notes [4]). The key facts are: (i) A variant of Theorem 2 of [5] (regret bound of OSMD) holds for OSMD with Projection, (ii) E[\u03c0t] = (1\u2212\u03b3)xt,\nAlgorithm 3 Projection onto Q\u0302n 1: given (q1, . . . , qn) \u2208 [\u22121, 1]n satisfying q1 \u2265 q2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 qn. (This assumption\nholds by renaming the indices, and reverting to their original names at the end).\n2: set i0 = 0 3: for k = 1, . . . , n do 4: for each i = ik\u22121 + 1, . . . , n, set \u03b4ki = min\u03b4\u2208R \u03b4 subject to:\n\u2211i j=ik\u22121+1 f\u22121(f(qj)\u2212 \u03b4) \u2264 2n\u22121 \u2211i j=ik\u22121+1 ( n+1 2 \u2212 j ) .\n5: ik = argmaxi:ik\u22121<i\u2264n \u03b4 k i . In case of multiple minimizers, choose largest as ik. 6: set pj = f\n\u22121(f(qj)\u2212 \u03b4kik) for j = ik\u22121 + 1, . . . , ik 7: if ik = n, then break 8: end for 9: return (p1, . . . , pn) \u2032\nand (iii) The estimated loss is the same one used in OSMD for the hypercube [\u22121, 1]n . Once these three conditions are satisfied, we can prove a regret bound of OSMDRank by following the proof of Theorem 5 in Bubeck et al. [5]. In addition, the running time of OSMD per trial is O(n) [5]. Combining Lemma 3 for the projection and the analysis of the decomposition from [15], the proof of the first statement is concluded. The statement related to the standard permutahedron holds based on the affine transformation between the standard permutahedron and Q\u0302n."}, {"heading": "6 Future Work", "text": "The main open question is whether there is an algorithm of expected regret O(n \u221a T ) and time O(n3) in the setting of Section 4. Another interesting line of research is to study other ranking polytopes. For example, given any strictly monotonically increasing function f : R 7\u2192 R we can consider as an action set fn(Sn), defined as f n(Sn) := {(f(\u03c0(1)), f(\u03c0(2)), . . . , f(\u03c0(n))) : \u03c0 \u2208 Sn}."}, {"heading": "Acknowledgments", "text": "Ailon acknowledges the generous support of a Marie Curie Reintegration Grant PIRG07-GA-2010-268403, an Israel Science Foundation (ISF) grant 127/133 and a Jacobs Technion-Cornell Innovation Institute (JTCII) grant."}, {"heading": "A Derivations in proof of Lemma 2", "text": "By definition, and then by applying the properties of the distribution PLn(w),\nHaa = [p(a \u227a b \u2227 a \u227a c|w) + p(b \u227a a \u2227 c \u227a a|w) \u2212 p(b \u227a a \u2227 a \u227a c|w)\u2212 p(c \u227a a \u2227 a \u227a b|w)] \u2212 [p(a \u227a b|w)p(a \u227a c|w) + p(b \u227a a|w)p(c \u227a a|w)\u2212 p(a \u227a b|w)p(c \u227a a|w)\n\u2212p(a \u227a c|w)p(b \u227a a|w)] (A.1)\np(a \u227a b \u2227 a \u227a c|w) = e s(a)\nes(a) + es(b) + es(c) (A.2)\np(b \u227a a \u2227 c \u227a a|w) = e s(b) es(a) + es(b) + es(c) es(c) es(a) + es(c) +\nes(c) es(a) + es(b) + es(c) es(b) es(a) + es(b)\n(A.3)\np(b \u227a a \u2227 a \u227a c|w) = e s(b) es(a) + es(b) + es(c) es(a) es(a) + es(c) (A.4) p(c \u227a a \u2227 a \u227a b|w) = e s(c)\nes(a) + es(b) + es(c) es(a) es(a) + es(b) (A.5)\nPlugging (A.2)-(A.5) in (A.1) and simplifying results in (4.10). One now verifies:\nHab = [p(a \u227a c \u2227 b \u227a c|w) + p(c \u227a a \u2227 c \u227a b|w)\u2212 3p(a \u227a c \u2227 c \u227a b|w)\u2212 3p(b \u227a c \u2227 c \u227a a|w)] \u2212 [\u2212p(a \u227a b|w)p(a \u227a c|w) \u2212 p(b \u227a a|w)p(c \u227a a|w) + p(a \u227a b|w)p(c \u227a a|w)\n+ p(a \u227a b|w)p(a \u227a c|w) + p(a \u227a b|w)p(b \u227a c|w) + p(b \u227a a|w)p(c \u227a b|w) \u2212 p(b \u227a a|w)p(b \u227a c|w) \u2212 p(a \u227a b|w)p(c \u227a b|w) + p(a \u227a b|w)p(b \u227a c|w) +p(b \u227a a|w)p(c \u227a b|w) \u2212 p(b \u227a a|w)p(b \u227a c|w) \u2212 p(a \u227a b|w)p(c \u227a b|w) \u2212p(a \u227a c|w)p(b \u227a c|w) \u2212 p(c \u227a a|w)p(c \u227a b|w) + p(a \u227a c|w)p(c \u227a b|w)\n+p(c \u227a a|w)p(b \u227a c|w)]\nAgain using identities (A.2)-(A.5) and simplifying, gives (4.11)"}], "references": [{"title": "Improved Bounds for Online Learning Over the Permutahedron and Other Ranking Polytopes", "author": ["Nir Ailon"], "venue": "In AISTATS,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Yoav Freund", "Robert E. Schapire"], "venue": "SIAM J. Comput.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Assessing the potential demand for electric cars", "author": ["S Beggs", "S Cardell", "J Hausman"], "venue": "Journal of Econometrics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1981}, {"title": "Introduction to Online Optimization", "author": ["S\u00e9bastien Bubeck"], "venue": "http://www.princeton.edu/~bubeck/BubeckLectureNotes.pdf,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Towards Minimax Policies for Online Linear Optimization with Bandit Feedback", "author": ["S\u00e9bastien Bubeck", "Nicol\u00f2 Cesa-Bianchi", "Sham M. Kakade"], "venue": "In Proceedings of 25th Annual Conference on Learning Theory (COLT", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Combinatorial bandits", "author": ["Nicol\u00f2 Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "The price of bandit information for online optimization", "author": ["Varsha Dani", "Thomas P. Hayes", "Sham Kakade"], "venue": "In NIPS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "The convex optimization approach to regret minimization", "author": ["Elad Hazan"], "venue": "Optimization for Machine Learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Volumetric spanners and their applications to machine learning", "author": ["Elad Hazan", "Zohar Shay Karnin", "Raghu Mehka"], "venue": "CoRR, abs/1312.6214,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Learning Permutations with Exponential Weights", "author": ["David P. Helmbold", "Manfred K. Warmuth"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "A polynomial-time approximation algorithm for the permanent of a matrix with nonnegative entries", "author": ["Mark Jerrum", "Alistair Sinclair", "Eric Vigoda"], "venue": "J. ACM,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Analyzing and Modeling Rank Data", "author": ["John I. Marden"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1995}, {"title": "Online Prediction under Submodular Constraints", "author": ["Daiki Suehiro", "Kohei Hatano", "Shuji Kijima", "Eiji Takimoto", "Kiyohito Nagano"], "venue": "In Proceedings of 23th Annual Conference on Algorithmic Learning Theory (ALT", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "The complexity of computing the permanent", "author": ["Leslie G. Valiant"], "venue": "Theor. Comput. Sci.,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1979}, {"title": "Online Linear Optimization over Permutations", "author": ["Shota Yasutake", "Kohei Hatano", "Shuji Kijima", "Eiji Takimoto", "Masayuki Takeda"], "venue": "In Proceedings of the 22nd International Symposium on Algorithms and Computation (ISAAC", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "The relationship between Luce\u2019s choice axiom, Thurstone\u2019s theory of comparative judgment, and the double exponential distribution", "author": ["J. Yellott"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1977}], "referenceMentions": [{"referenceID": 11, "context": "Our algorithm, BanditRank, plays permutations from a distribution known as the Plackett-Luce model (see [12]) which is widely used in statistics and econometrics (see eg [3]).", "startOffset": 104, "endOffset": 108}, {"referenceID": 2, "context": "Our algorithm, BanditRank, plays permutations from a distribution known as the Plackett-Luce model (see [12]) which is widely used in statistics and econometrics (see eg [3]).", "startOffset": 170, "endOffset": 173}, {"referenceID": 5, "context": "It uses an inverse covariance matrix of the distribution in order to obtain an unbiased loss vector estimator, which is a standard technique [6].", "startOffset": 141, "endOffset": 144}, {"referenceID": 5, "context": "This result should be compared to CombBand of [6], where a framework for playing bandit games over combinatorially structured sets was developed.", "startOffset": 46, "endOffset": 49}, {"referenceID": 6, "context": "Their techniques extend that of [7].", "startOffset": 32, "endOffset": 35}, {"referenceID": 13, "context": "Unfortunately, nonnegative permanent computation is #P -hard, as shown by [14].", "startOffset": 74, "endOffset": 78}, {"referenceID": 10, "context": "groundbreaking result of [11] presents a polynomial time approximation scheme for permanent, which runs in time O(n) for fixed accuracy.", "startOffset": 25, "endOffset": 29}, {"referenceID": 8, "context": "[9] have improved the state-of-the-art general purpose algorithm for linear bandit optimization, implying an algorithm with regret O(n \u221a T ) for our problem, but with worse running time \u00d5(n).", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "We present and analyze an algorithm OSMDRank based on the bandit algorithm OSMD of [5] with projection and decomposition techniques over the permutahedron ([15, 13]).", "startOffset": 83, "endOffset": 86}, {"referenceID": 14, "context": "We present and analyze an algorithm OSMDRank based on the bandit algorithm OSMD of [5] with projection and decomposition techniques over the permutahedron ([15, 13]).", "startOffset": 156, "endOffset": 164}, {"referenceID": 12, "context": "We present and analyze an algorithm OSMDRank based on the bandit algorithm OSMD of [5] with projection and decomposition techniques over the permutahedron ([15, 13]).", "startOffset": 156, "endOffset": 164}, {"referenceID": 9, "context": "[10] were the first to study a more general version of this problem, where the action set is the vertex set of the Birkhoff-von-Neumann polytope (doubly-stochastic matrices).", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] studied the problem by casting it as a submodularly constrained optimization problem, giving near optimal regret bounds, and more recently Ailon [1] both provided optimal regret bounds with improved running time and established tight regret lower bounds.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[13] studied the problem by casting it as a submodularly constrained optimization problem, giving near optimal regret bounds, and more recently Ailon [1] both provided optimal regret bounds with improved running time and established tight regret lower bounds.", "startOffset": 150, "endOffset": 153}, {"referenceID": 11, "context": "An important well known property of the distribution is that it can be equivalently defined as a Random Utility Model (RUM) [12, 16]: To draw a permutation, add a random iid noise variable following the Gumbel distribution to each weight, and then sort the items of V in decreasing value of noisy-weights.", "startOffset": 124, "endOffset": 132}, {"referenceID": 15, "context": "An important well known property of the distribution is that it can be equivalently defined as a Random Utility Model (RUM) [12, 16]: To draw a permutation, add a random iid noise variable following the Gumbel distribution to each weight, and then sort the items of V in decreasing value of noisy-weights.", "startOffset": 124, "endOffset": 132}, {"referenceID": 5, "context": "\u2019s CombBand [6], which is itself an adaptation of Auer et al.", "startOffset": 12, "endOffset": 15}, {"referenceID": 1, "context": "\u2019s Exp3 [2] from the finite case to the structured combinatorial case.", "startOffset": 8, "endOffset": 11}, {"referenceID": 11, "context": "[12].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "We refer to [12] for definition and history of the BradleyTerry-Luce model.", "startOffset": 12, "endOffset": 16}, {"referenceID": 5, "context": "The proof of the theorem proceeds roughly as the main result upper bounding the expected regret of CombBand in [6].", "startOffset": 111, "endOffset": 114}, {"referenceID": 5, "context": "We now note that (1) \u2211 \u03c0\u0302\u2208\u015c qt(\u03c0\u0302|wt\u22121)l\u0303t = lt (following the properties of matrix pseudo-inverse in Line 7 in Algorithm 1), and (2) \u2211 \u03c0\u0302\u2208\u015cn qt(\u03c0\u0302|wt\u22121)l\u0303t(\u03c0) ] \u2264 n (see top of page 31 together with Lemma 15 in [6]).", "startOffset": 212, "endOffset": 215}, {"referenceID": 11, "context": "9) Since Plackett-Luce is a random utility model (see [12]), it is clear that whenever a pair of pairs u 6= v, u\u2032 6= v\u2032 satisfies |{u, v, u\u2032, v\u2032}| = 4, p(u \u227a v \u2227 u\u2032 \u227a v\u2032|w) = p(u \u227a v|w)p(u\u2032 \u227a v\u2032|w).", "startOffset": 54, "endOffset": 58}, {"referenceID": 4, "context": "[5], on which our algorithm is based.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": ", [8]) for linear loss functions.", "startOffset": 2, "endOffset": 5}, {"referenceID": 14, "context": "The decomposition can be done using the technique of [15], which runs in O(n logn) time.", "startOffset": 53, "endOffset": 57}, {"referenceID": 12, "context": "Our projection algorithm is an extension of that in [13] and our proof follows a similar argument in [13].", "startOffset": 52, "endOffset": 56}, {"referenceID": 12, "context": "Our projection algorithm is an extension of that in [13] and our proof follows a similar argument in [13].", "startOffset": 101, "endOffset": 105}, {"referenceID": 12, "context": "Then, it can be shown that projection preserves the order in q by using Lemma 1 in [13].", "startOffset": 83, "endOffset": 87}, {"referenceID": 12, "context": "By following a similar argument in [13], we can show that the output p indeed satisfies the KKT optimality conditions for projection, which completes the proof of the first statement.", "startOffset": 35, "endOffset": 39}, {"referenceID": 14, "context": "relative entropy or Euclidean norm squared), a different projection scheme is possible in time O(n) (see [15, 13] for the details).", "startOffset": 105, "endOffset": 113}, {"referenceID": 12, "context": "relative entropy or Euclidean norm squared), a different projection scheme is possible in time O(n) (see [15, 13] for the details).", "startOffset": 105, "endOffset": 113}, {"referenceID": 3, "context": ", chapters 5 and 7 on OMD and OSMD of Bubeck\u2019s lecture notes [4]).", "startOffset": 61, "endOffset": 64}, {"referenceID": 4, "context": "The key facts are: (i) A variant of Theorem 2 of [5] (regret bound of OSMD) holds for OSMD with Projection, (ii) E[\u03c0t] = (1\u2212\u03b3)xt, 13", "startOffset": 49, "endOffset": 52}], "year": 2014, "abstractText": "The permutahedron is the convex polytope with vertex set consisting of the vectors (\u03c0(1), . . . , \u03c0(n)) for all permutations (bijections) \u03c0 over {1, . . . , n}. We study a bandit game in which, at each step t, an adversary chooses a hidden weight weight vector st, a player chooses a vertex \u03c0t of the permutahedron and suffers an observed instantaneous loss of \u2211n i=1 \u03c0t(i)st(i). We study the problem in two regimes. In the first regime, st is a point in the polytope dual to the permutahedron. Algorithm CombBand of Cesa-Bianchi et al (2009) guarantees a regret of O(n \u221a T log n) after T steps. Unfortunately, CombBand requires at each step an n-by-n matrix permanent computation, a #P -hard problem. Approximating the permanent is possible in the impractical running time of O(n), with an additional heavy inverse-polynomial dependence on the sought accuracy. We provide an algorithm of slightly worse regret O(n \u221a T ) but with more realistic time complexity O(n) per step. The technical contribution is a bound on the variance of the Plackett-Luce noisy sorting process\u2019s \u2018pseudo loss\u2019, obtained by establishing positive semi-definiteness of a family of 3-by-3 matrices of rational functions in exponents of 3 parameters. In the second regime, st is in the hypercube. For this case we present and analyze an algorithm based on Bubeck et al.\u2019s (2012) OSMD approach with a novel projection and decomposition technique for the permutahedron. The algorithm is efficient and achieves a regret of O(n \u221a T ), but for a more restricted space of possible loss vectors.", "creator": "LaTeX with hyperref package"}}}