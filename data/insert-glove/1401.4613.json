{"id": "1401.4613", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2014", "title": "Local Consistency and SAT-Solvers", "abstract": "Local karlan consistency oliveri techniques timothee such as k - consistency are heritability a key bandoneon component of dansby specialised solvers for capitalized constraint magyars satisfaction problems. In folkl this paper we show that 39.56 the bachata power iwuchukwu of using tecoma k - papakura consistency alpuri techniques on a varni constraint satisfaction melati problem lichtenegger is 1.70 precisely meats captured iso/tc by hala using endorsers a particular borhani inference rule, which we call sirak negative - ejidos hyper - jizi resolution, 340 on the 90-year standard mccartt direct corell encoding of glaucescens the problem into Boolean woofers clauses. sandelman We 800,000 also injuring show tannic that 893-8811 current clause - learning fmqb SAT - solvers hayler will manabi discover jayasurya in expected dmp polynomial saladillo time red-fronted any bsl inconsistency that waveguides can bowers be deduced from a mahavir given set unchristian of keetoowah clauses using negative - hyper - resolvents of a fixed rubidium size. We freidrich combine these two refiles results to whammo show timofeev that, routan without beta-carotene being explicitly designed to yodo do aqualad so, current moshtarak clause - commendably learning blomefield SAT - mccoury solvers goal efficiently overstocking simulate hoven k - single-season consistency seersucker techniques, ottri for lehan all fixed values 12.55 of governement k. 106.96 We sayn then give some pharmacare experimental results to show premixed that 9,240 this sinfonica feature anglia allows papunya clause - learning headlong SAT - galija solvers 70-6 to wampler efficiently solve certain flender families dabanovic of constraint problems which kott are stoda challenging for conventional hd3 constraint - wildey programming \u0163ara solvers.", "histories": [["v1", "Sat, 18 Jan 2014 21:39:00 GMT  (441kb)", "http://arxiv.org/abs/1401.4613v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LO", "authors": ["peter jeavons", "justyna petke"], "accepted": false, "id": "1401.4613"}, "pdf": {"name": "1401.4613.pdf", "metadata": {"source": "CRF", "title": "Local Consistency and SAT-Solvers", "authors": ["Peter Jeavons", "Justyna Petke"], "emails": ["Peter.Jeavons@cs.ox.ac.uk", "Justyna.Petke@cs.ox.ac.uk"], "sections": [{"heading": "1. Introduction", "text": "One of the oldest and most central ideas in constraint programming, going right back to Montanari\u2019s original paper in 1974, is the idea of using local consistency techniques to prune the search space (Bessie\u0300re, 2006). The idea of arc-consistency was introduced by Mackworth (1977), and generalised to k-consistency by Freuder (1978). Modern constraint solvers generally employ specialised propagators to prune the domains of variables to achieve some form of generalised arc-consistency, but typically do not attempt to enforce higher levels of consistency, such as path-consistency.\nBy contrast, the software tools developed to solve propositional satisfiability problems, known as SAT-solvers, generally use logical inference techniques, such as unit propagation and clause-learning, to prune the search space.\nOne of the most surprising empirical findings of the last few years has been the remarkably good performance of general SAT-solvers in solving constraint satisfaction problems. To apply such tools to a constraint satisfaction problem one first has to translate the instance into a set of clauses using some form of Boolean encoding (Tamura, Taga, Kitagawa, & Banbara, 2009; Walsh, 2000). Such encoding techniques tend to obscure the structure of the original problem, and may introduce a very large number of Boolean variables and clauses to encode quite easily-stated constraints. Nevertheless, in quite a few cases, such approaches have out-performed more traditional constraint-solving tools (van Dongen, Lecoutre, & Roussel, 2008, 2009; Petke & Jeavons, 2009).\nc\u00a92012 AI Access Foundation. All rights reserved.\nIn this paper we draw on a number of recent analytical approaches to try to account for the good performance of general SAT-solvers on many forms of constraint problems. Building on the results of Atserias, Bulatov, and Dalmau (2007), Atserias and Dalmau (2008), and Hwang and Mitchell (2005), we show that the power of using k-consistency techniques in a constraint problem is precisely captured by using a single inference rule in a standard Boolean encoding of that problem. We refer to this inference rule as negativehyper-resolution, and show that any conclusions deduced by enforcing k-consistency can be deduced by a sequence of negative-hyper-resolution inferences involving Boolean clauses in the original instance and negative-hyper-resolvents with at most k literals. Furthermore, by using the approach of Atserias, Fichte, and Thurley (2011), and Pipatsrisawat and Darwiche (2009), we show that current clause-learning SAT-solvers will mimic the effect of such deductions in polynomial expected time, even with a random branching strategy. Hence we show that, although they are not explicitly designed to do so, running a clause-learning SAT-solver on a straightforward encoding of a constraint problem efficiently simulates the effects of enforcing k-consistency for all values of k."}, {"heading": "2. Preliminaries", "text": "In this section we give some background and definitions that will be used throughout the rest of the paper.\n2.1 Constraint Satisfaction Problems and k-Consistency\nDefinition 1 An instance of the Constraint Satisfaction Problem (CSP) is specified by a triple (V,D,C), where\n\u2022 V is a finite set of variables;\n\u2022 D = {Dv | v \u2208 V } where each set Dv is the set of possible values for the variable v, called the domain of v;\n\u2022 C is a finite set of constraints. Each constraint in C is a pair (Ri, Si) where\n\u2013 Si is an ordered list of mi variables, called the constraint scope;\n\u2013 Ri is a relation over D of arity mi, called the constraint relation.\nGiven any CSP instance (V,D,C), a partial assignment is a mapping f from some subset W of V to \u22c3 Dv such that f(v) \u2208 Dv for all v \u2208 W . A partial assignment satisfies the constraints of the instance if, for all (R, (v1, v2, . . . , vm)) \u2208 C such that vj \u2208 W for j = 1, 2, . . . ,m, we have (f(v1), f(v2) . . . , f(vm)) \u2208 R. A partial assignment that satisfies the constraints of an instance is called a partial solution1 to that instance. The set of variables on which a partial assignment f is defined is called the domain of f , and denoted Dom(f). A partial solution g extends a partial solution f if Dom(g) \u2287 Dom(f) and g(v) = f(v) for all v \u2208 Dom(f). A partial solution with domain V is called a solution.\nOne way to derive new information about a CSP instance, which may help to determine whether or not it has a solution, is to use some form of constraint propagation to enforce\n1. Note that not all partial solutions extend to solutions.\nsome level of local consistency (Bessie\u0300re, 2006). For example, it is possible to use the notion of k-consistency, defined below. We note that there are several different but equivalent ways to define and enforce k-consistency described in the literature (Bessie\u0300re, 2006; Cooper, 1989; Freuder, 1978). Our presentation follows that of Atserias et al. (2007), which is inspired by the notion of existential k-pebble games introduced by Kolaitis and Vardi (2000).\nDefinition 2 (Atserias et al., 2007) For any CSP instance P , the k-consistency closure of P is the set H of partial assignments which is obtained by the following algorithm:\n1. Let H be the collection of all partial solutions f of P with |Dom(f)| \u2264 k + 1;\n2. For every f \u2208 H with |Dom(f)| \u2264 k and every variable v of P , if there is no g \u2208 H such that g extends f and v \u2208 Dom(g), then remove f and all its extensions from H;\n3. Repeat step 2 until H is unchanged.\nNote that computing the k-consistency closure according to this definition corresponds precisely to enforcing strong (k+1)-consistency according to the definitions given by Bessie\u0300re (2006), Cooper (1989), and Freuder (1978).\nThroughout this paper, we shall assume that the domain of possible values for each variable in a CSP instance is finite. It is straightforward to show that for any fixed k, and any fixed maximum domain size, the k-consistency closure of an instance P can be computed in polynomial time (Atserias et al., 2007; Cooper, 1989).\nNote that any solution to P must extend some element of the k-consistency closure of P . Hence, if the k-consistency closure of P is empty, for some k, then P has no solutions. The converse is not true in general, but it holds for certain special cases, such as the class of instances whose structure has tree-width bounded by k (Atserias et al., 2007), or the class of instances whose constraint relations are \u201c0/1/all\u201d relations, as defined in Cooper, Cohen, and Jeavons (1994), or \u201cconnected row-convex\u201d relations, as defined in Deville, Barette, and Hentenryck (1997). For these special kinds of instances it is possible to determine in polynomial time whether or not a solution exists simply by computing the k-consistency closure, for an appropriate choice of k. Moreover, if a solution exists, then it can be constructed in polynomial time by selecting each variable in turn, assigning each possible value, re-computing the k-consistency closure, and retaining an assignment that gives a non-empty result.\nThe following result gives a useful condition for determining whether the k-consistency closure of a CSP instance is empty.\nLemma 1 (Kolaitis & Vardi, 2000) The k-consistency closure of a CSP instance P is non-empty if and only if there exists a non-empty family H of partial solutions to P such that:\n1. If f \u2208 H, then |Dom(f)| \u2264 k + 1;\n2. If f \u2208 H and f extends g, then g \u2208 H;\n3. If f \u2208 H, |Dom(f)| \u2264 k, and v /\u2208 Dom(f) is a variable of P , then there is some g \u2208 H such that g extends f and v \u2208 Dom(g).\nA set of partial solutions H satisfying the conditions described in Lemma 1 is sometimes called a strategy for the instance P (Barto & Kozik, 2009; Kolaitis & Vardi, 2000)."}, {"heading": "2.2 Encoding a CSP Instance as a Propositional Formula", "text": "One possible approach to solving a CSP instance is to encode it as a propositional formula over a suitable set of Boolean variables, and then use a program to decide the satisfiability of that formula. Many such programs, known as SAT-solvers, are now available and can often efficiently handle problems with thousands, or sometimes even millions, of Boolean variables (Zhang & Malik, 2002).\nSeveral different ways of encoding a CSP instance as a propositional formula have been proposed (Prestwich, 2009; Tamura et al., 2009; Walsh, 2000).\nHere we consider one common family of encodings, known as sparse encodings (this term was introduced in Hoos, 1999). For any CSP instance P = (V,D,C), a sparse encoding introduces a set of Boolean variables of the form xvi for each v \u2208 V and each i \u2208 Dv. The Boolean variable xvi is assigned True if and only if the original variable v is assigned the value i. We will say that a partial assignment f falsifies a clause C if C consists entirely of literals of the form \u00acxvf(v), for variables v \u2208 Dom(f). Otherwise, we will say that a partial assignment f satisfies a clause C.\nExample 1 Let P be a CSP instance such that V = {u, v, w}, Du = Dv = {0, 1}, Dw = {0, 1, 2} and C contains a single ternary constraint with scope (u, v, w) specifying that u \u2264 v < w. A sparse encoding of P will introduce seven Boolean variables:\nxu0, xu1, xv0, xv1, xw0, xw1, xw2.\nSparse encodings usually contain certain clauses known as at-least-one and at-most-one clauses, to ensure that each variable v is assigned a value, say i, and that no other value, j 6= i, is assigned to v. The at-least-one clauses are of the form \u2228 i\u2208Dv xvi for each variable v. The at-most-one clauses can be represented as a set of binary clauses \u00acxvi \u2228\u00acxvj for all i, j \u2208 Dv with i 6= j.\nExample 2 In the case of the CSP instance from Example 1 the at-least-one clauses are:\nxu0 \u2228 xu1, xv0 \u2228 xv1, xw0 \u2228 xw1 \u2228 xw2\nThe at-most-one clauses are:\n\u00acxu0 \u2228 \u00acxu1, \u00acxv0 \u2228 \u00acxv1, \u00acxw0 \u2228 \u00acxw1, \u00acxw0 \u2228 \u00acxw2, \u00acxw1 \u2228 \u00acxw2\nThe various different sparse encodings differ in the way they encode the constraints of a CSP instance. Two methods are most commonly used. The first one encodes the disallowed variable assignments - the so-called conflicts or no-goods. The direct encoding (Prestwich, 2009), for instance, generates a clause \u2228 v\u2208S \u00acxvf(v) for each partial assignment f that does not satisfy the constraint (R,S) \u2208 C. Using the direct encoding, the ternary constraint from Example 1 would be encoded by the following clauses:\n\u00acxu0 \u2228 \u00acxv0 \u2228 \u00acxw0, \u00acxu0 \u2228 \u00acxv1 \u2228 \u00acxw0, \u00acxu0 \u2228 \u00acxv1 \u2228 \u00acxw1, \u00acxu1 \u2228 \u00acxv0 \u2228 \u00acxw0,\n\u00acxu1 \u2228 \u00acxv0 \u2228 \u00acxw1, \u00acxu1 \u2228 \u00acxv0 \u2228 \u00acxw2, \u00acxu1 \u2228 \u00acxv1 \u2228 \u00acxw0, \u00acxu1 \u2228 \u00acxv1 \u2228 \u00acxw1.\nAnother way of translating constraints into clauses is to encode the allowed variable assignments - the so-called supports. This has been used as the basis for an encoding of binary CSP instances, known as the support encoding (Gent, 2002), defined as follows. For each pair of variables v, w in the scope of some constraint, and each value i \u2208 Dv, the support encoding will contain the clause \u00acxvi \u2228 \u2228 j\u2208A xwj , where A \u2286 Dw is the set of values for the variable w which are compatible with the assignment v = i, according to the constraint.\nNote that the support encoding is defined for binary CSP instances only. However, some non-binary constraints can be decomposed into binary ones without introducing any new variables. For instance, the ternary constraint from Example 1 can be decomposed into two binary constraints specifying that u \u2264 v and v < w. Using the support encoding, these binary constraints would then be represented by the following clauses:\n\u00acxu0 \u2228 xv0 \u2228 xv1, \u00acxu1 \u2228 xv1, \u00acxv0 \u2228 xu0, \u00acxv1 \u2228 xu0 \u2228 xu1, \u00acxv0 \u2228 xw1 \u2228 xw2, \u00acxv1 \u2228 xw2, \u00acxw0, \u00acxw1 \u2228 xv0, \u00acxw2 \u2228 xv0 \u2228 xv1."}, {"heading": "2.3 Inference Rules", "text": "Given any set of clauses we can often deduce further clauses by applying certain inference rules. For example, if we have two clauses of the form C1\u2228x and C2\u2228\u00acx, for some (possibly empty) clauses C1, C2, and some variable x, then we can deduce the clause C1 \u2228 C2. This form of inference is known as propositional resolution; the resultant clause is called the resolvent (Robinson, 1965).\nIn the next section, we shall establish a close connection between the k-consistency algorithm and a form of inference called negative-hyper-resolution (Bu\u0308ning & Lettmann, 1999), which we define as follows:\nDefinition 3 If we have a collection of clauses of the form Ci \u2228 \u00acxi, for i = 1, 2, . . . , r, and a clause C0 \u2228 x1 \u2228 x2 \u2228 \u00b7 \u00b7 \u00b7 \u2228 xr, where each xi is a Boolean variable, and C0 and each Ci is a (possibly empty) disjunction of negative literals, then we can deduce the clause C0 \u2228 C1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 Cr.\nWe call this form of inference negative-hyper-resolution and the resultant clause C0 \u2228 C1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 Cr the negative-hyper-resolvent.\nIn the case where C0 is empty, the negative-hyper-resolution rule is equivalent to the nogood resolution rule described by Hwang and Mitchell (2005) as well as the H5-k rule introduced by de Kleer (1989) and the nogood recording scheme described by Schiex and Verfaillie (1993).\nNote that the inference obtained by negative-hyper-resolution can also be obtained by a sequence of standard resolution steps. However, the reason for introducing negative-hyperresolution is that it allows us to deduce the clauses we need in a single step without needing to introduce intermediate clauses (which may contain up to r \u2212 1 more literals than the\nnegative-hyper-resolvent). By restricting the size of the clauses we use in this way we are able to obtain better performance bounds for SAT-solvers in the results below.\nExample 3 Assume we have a collection of clauses of the form Ci\u2228\u00acxi, for i = 1, 2, . . . , r, and a clause C0 \u2228 x1 \u2228 x2 \u2228 \u00b7 \u00b7 \u00b7 \u2228 xr, as specified in Definition 3, where each Ci = C0. The negative-hyper-resolvent of this set of clauses is C0.\nThe clause C0 can also be obtained by a sequence of standard resolution steps, as follows. First resolve C0 \u2228 x1 \u2228 x2 \u2228 \u00b7 \u00b7 \u00b7 \u2228 xr with C0 \u2228\u00acxr to obtain C0 \u2228 x1 \u2228 x2 \u2228 \u00b7 \u00b7 \u00b7 \u2228 xr\u22121. Then resolve this with the next clause, C0 \u2228 \u00acxr\u22121, and so on for the other clauses, until finally we obtain C0. However, in this case the intermediate clause C0\u2228x1\u2228x2\u2228\u00b7 \u00b7 \u00b7\u2228xr\u22121 contains r \u2212 1 more literals than the negative-hyper-resolvent.\nExample 4 Note that the no-good clauses in the direct encoding of a binary CSP instance can each be obtained by a single negative-hyper-resolution step from an appropriate support clause in the support encoding together with an appropriate collection of at-most-one clauses. Let A \u2286 Dw be the set of values for the variable w which are compatible with the assignment v = i, then the support encoding will contain the clause C = \u00acxvi \u2228 \u2228 j\u2208A xwj. If there are any values k \u2208 Dw which are incompatible with the assignment v = i, then we can form the negative-hyper-resolvent of C with the at-most-one clauses \u00acxwk \u2228 \u00acxwj for each j \u2208 A, to obtain the corresponding no-good clause, \u00acxvi \u2228 \u00acxwk.\nA negative-hyper-resolution derivation of a clause C from a set of initial clauses \u03a6 is a sequence of clauses C1, C2, . . . , Cm, where Cm = C and each Ci follows by the negativehyper-resolution rule from some collection of clauses, each of which is either contained in \u03a6 or else occurs earlier in the sequence. The width of this derivation is defined to be the maximum size of any of the clauses Ci. If Cm is the empty clause, then we say that the derivation is a negative-hyper-resolution refutation of \u03a6.\n3. k-Consistency and Negative-Hyper-Resolution\nIt has been pointed out by many authors that enforcing local consistency is a form of inference on relations analogous to the use of the resolution rule on clauses (Bacchus, 2007; Bessie\u0300re, 2006; Hwang & Mitchell, 2005; Rish & Dechter, 2000). The precise strength of the standard resolution inference rule on the direct encoding of a CSP instance was considered in the work of Walsh (2000), where it was shown that unit resolution (where one of the clauses being resolved consists of a single literal), corresponds to enforcing a weak form of local consistency known as forward checking. Hwang and Mitchell (2005) pointed out that the standard resolution rule with no restriction on clause length is able to simulate all the inferences made by a k-consistency algorithm. Atserias and Dalmau (2008) showed that the standard resolution rule restricted to clauses with at most k literals, known as the kresolution rule, can be characterised in terms of the Boolean existential (k+1)-pebble game. It follows that on CSP instances with Boolean domains this form of inference corresponds to enforcing k-consistency. An alternative proof that k-resolution achieves k-consistency for instances with Boolean domains is given in the book by Hooker (2006, Thm. 3.22).\nHere we extend these results a little, to show that for CSP instances with arbitrary finite domains, applying the negative-hyper-resolution rule on the direct encoding to obtain\nclauses with at most k literals corresponds precisely to enforcing k-consistency. A similar relationship was stated in the work of de Kleer (1989), but a complete proof was not given.\nNote that the bound, k, that we impose on the size of the negative-hyper-resolvents, is independent of the domain size. In other words, using this inference rule we only need to consider inferred clauses of size at most k, even though we make use of clauses in the encoding whose size is equal to the domain size, which may be arbitrarily large.\nTheorem 1 The k-consistency closure of a CSP instance P is empty if and only if its direct encoding as a set of clauses has a negative-hyper-resolution refutation of width at most k.\nThe proof is broken down into two lemmas inspired by Lemmas 2 and 3 in the work of Atserias and Dalmau (2008).\nLemma 2 Let P be a CSP instance, and let \u03a6 be its direct encoding as a set of clauses. If \u03a6 has no negative-hyper-resolution refutation of width k or less, then the k-consistency closure of P is non-empty.\nProof. Let V be the set of variables of P , where each v \u2208 V has domain Dv, and let X = {xvi | v \u2208 V, i \u2208 Dv} be the corresponding set of Boolean variables in \u03a6. Let \u0393 be the set of all clauses having a negative-hyper-resolution derivation from \u03a6 of width at most k. By the definition of negative-hyper-resolution, every non-empty clause in \u0393 consists entirely of negative literals.\nNow let H be the set of all partial assignments for P with domain size at most k + 1 that do not falsify any clause in \u03a6 \u222a \u0393 under the direct encoding.\nConsider any element f \u2208 H. By the definition of H, f does not falsify any clause of \u03a6, so by the definition of the direct encoding, every element of H is a partial solution to P . Furthermore, if f extends g, then g is also an element of H, because g makes fewer assignments than f and hence cannot falsify any additional clauses to f .\nIf \u03a6 has no negative-hyper-resolution refutation of width at most k, then \u0393 does not contain the empty clause, so H contains (at least) the partial solution with empty domain, and hence H is not empty.\nNow let f be any element of H with |Dom(f)| \u2264 k and let v be any variable of P that is not in Dom(f). For any partial assignment g that extends f and has Dom(g) = Dom(f) \u222a {v} we have that either g \u2208 H or else there exists a clause in \u03a6 \u222a \u0393 that is falsified by g. Since g is a partial assignment, any clause C in \u03a6 \u222a \u0393 that is falsified by g, must consist entirely of negative literals. Hence the literals of C must either be of the form \u00acxwf(w) for some w \u2208 Dom(f), or else \u00acxvg(v). Moreover, any such clause must contain the literal \u00acxvg(v), or else it would already be falsified by f .\nAssume, for contradiction, that H does not contain any assignment g that extends f and has Dom(g) = Dom(f)\u222a {v}. In that case, we have that, for each i \u2208 Dv, \u03a6\u222a\u0393 contains a clause Ci consisting of negative literals of the form \u00acxwf(w) for some w \u2208 Dom(f), together with the literal \u00acxvi. Now consider the clause, C, which is the negative-hyper-resolvent of these clauses Ci and the at-least-one clause \u2228 i\u2208Dv xvi. The clause C consists entirely of negative literals of the form \u00acxwf(w) for some w \u2208 Dom(f), so it has width at most |Dom(f)| \u2264 k, and hence is an element of \u0393. However C is falsified by f , which contradicts the choice of f . Hence we have shown that for all f \u2208 H with |Dom(f)| \u2264 k, and for\nall variables v such that v 6\u2208 Dom(f), there is some g \u2208 H such that g extends f and v \u2208 Dom(g).\nWe have shown that H satisfies all the conditions required by Lemma 1, so we conclude that the k-consistency closure of P is non-empty. 2\nLemma 3 Let P be a CSP instance, and let \u03a6 be its direct encoding as a set of clauses. If the k-consistency closure of P is non-empty, then \u03a6 has no negative-hyper-resolution refutation of width k or less.\nProof. Let V be the set of variables of P , where each v \u2208 V has domain Dv, and let X = {xvi | v \u2208 V, i \u2208 Dv} be the corresponding set of Boolean variables in \u03a6.\nBy Lemma 1, if the k-consistency closure of P is non-empty, then there exists a nonempty set H of partial solutions to P which satisfies the three properties described in Lemma 1.\nNow consider any negative-hyper-resolution derivation \u0393 from \u03a6 of width at most k. We show by induction on the length of this derivation that the elements of H do not falsify any clause in the derivation. First we note that the elements of H are partial solutions, so they satisfy all the constraints of P , and hence do not falsify any clause of \u03a6. This establishes the base case. Assume, for induction, that all clauses in the derivation earlier than some clause C are not falsified by any element of H.\nNote that, apart from the at-least-one clauses, all clauses in \u03a6 and \u0393 consist entirely of negative literals. Hence we may assume, without loss of generality, that C is the negativehyper-resolvent of a set of clauses \u2206 = {Ci \u2228 \u00acxvi | i \u2208 Dv} and the at-least-one clause\u2228\ni\u2208Dv xvi, for some fixed variable v.\nIf f \u2208 H falsifies C, then the literals of C must all be of the form \u00acxwf(w), for some w \u2208 Dom(f). Since the width of the derivation is at most k, C contains at most k literals, and hence we may assume that |Dom(f)| \u2264 k. But then, by the choice of H, there must exist some extension g of f in H such that v \u2208 Dom(g). Any such g will falsify some clause in \u2206, which contradicts our inductive hypothesis. Hence no f \u2208 H falsifies C, and, in particular, C cannot be empty.\nIt follows that no negative-hyper-resolution derivation of width at most k can contain the empty clause. 2\nNote that the proof of Theorem 1 applies to any sparse encoding that contains the at-least-one clauses for each variable, and where all other clauses are purely negative. We will call such an encoding a negative sparse encoding. As well as the direct encoding, other negative sparse encodings exist. For example, we may use negative clauses that involve only a subset of the variables in the scope of some constraints (to forbid tuples where all possible extensions to the complete scope are disallowed by the constraint). Another example of a negative sparse encoding is a well-known variant of the direct encoding in which the at-most-one clauses are omitted.\nCorollary 1 The k-consistency closure of a CSP instance P is empty if and only if any negative sparse encoding of P has a negative-hyper-resolution refutation of width at most k."}, {"heading": "4. Negative-Hyper-Resolution and SAT-Solvers", "text": "In this section we adapt the machinery from Atserias et al. (2011), and Pipatsrisawat and Darwiche (2009) to show that for any fixed k, the existence of a negative-hyper-resolution refutation of width k is likely to be discovered by a SAT-solver in polynomial-time using standard clause learning and restart techniques, even with a totally random branching strategy.\nNote that previous results about the power of clause-learning SAT-solvers have generally assumed an optimal branching strategy (Beame, Kautz, & Sabharwal, 2004; Pipatsrisawat & Darwiche, 2009) - they have shown what solvers are potentially capable of doing, rather than what they are likely to achieve in practice. An important exception is the paper by Atserias et al. (2011), which gives an analysis of likely behaviour, but relies on the existence of a standard resolution proof of bounded width. Here we show that the results of Atserias et al. can be extended to hyper-resolution proofs, which can be shorter and narrower than their associated standard resolution proofs.\nWe will make use of the following terminology from Atserias et al. (2011). For a clause C, a Boolean variable x, and a truth value a \u2208 {0, 1}, the restriction of C by the assignment x = a, denoted C|x=a, is defined to be the constant 1, if the assignment satisfies the clause, or else the clause obtained by deleting from C any literals involving the variable x. For any sequence of assignments S of the form (x1 = a1, x2 = a2, . . . , xr = ar) we write C|S to denote the result of computing the restriction of C by each assignment in turn. If C|S is empty, then we say that the assignments in S falsify the clause C. For a set of clauses \u2206, we write \u2206|S to denote the set {C|S | C \u2208 \u2206} \\ {1}.\nMost current SAT-solvers operate in the following way (Atserias et al., 2011; Pipatsrisawat & Darwiche, 2009). They maintain a database of clauses \u2206 and a current state S, which is a partial assignment of truth values to the Boolean variables in the clauses of \u2206. A high-level description of the algorithms used to update the clause database and the state, derived from the description given in Atserias et al., is shown in Algorithm 1 (a similar framework, using slightly different terminology, is given in Pipatsrisawat & Darwiche, 2009).\nNow consider a run of the algorithm shown in Algorithm 1, started with the initial database \u2206, and the empty state S0, until it either halts or discovers a conflict (i.e., \u2205 \u2208 \u2206|S). Such a run is called a complete round started with \u2206, and we represent it by the sequence of states S0, . . . , Sm, that the algorithm maintains. Note that each state Si extends the state Si\u22121 by a single assignment to a Boolean variable, which may be either a decision assignment or an implied assignment.\nMore generally, a round is an initial segment S0, S1, . . . , Sr of a complete round started with \u2206, up to a state Sr such that either \u2206|Sr contains the empty clause, or \u2206|Sr does not contain any unit clause. For any clause C, we say that a round S0, S1, . . . , Sr satisfies C if C|Sr = 1, and we say that the round falsifies C if C|Sr is empty.\nIf S0, S1, . . . , Sr is a round started with \u2206, and \u2206|Sr contains the empty clause, then the algorithm either reports unsatisfiability or learns a new clause: such a round is called conclusive. If a round is not conclusive we call it inconclusive 2. Note that if S0, S1, . . . , Sr is an inconclusive round started with \u2206, then \u2206|Sr does not contain the empty clause,\n2. Note that a complete round that assigns all variables and reports satisfiability is called inconclusive.\nand does not contain any unit clauses. Hence, for any clause C \u2208 \u2206, if Sr falsifies all the literals of C except one, then it must satisfy the remaining literal, and hence satisfy C. This property of clauses is captured by the following definition.\nDefinition 4 (Atserias et al., 2011) Let \u2206 be a set of clauses, C a non-empty clause, and l a literal of C. We say that \u2206 absorbs C at l if every inconclusive round started with \u2206 that falsifies C \\ {l} satisfies C.\nIf \u2206 absorbs C at each literal l in C, then we simply say that \u2206 absorbs C.\nNote that a closely related notion is introduced by Pipatsrisawat and Darwiche (2009) for clauses that are not absorbed by a set of clauses \u2206; they are referred to as 1-empowering with respect to \u2206. (The exact relationship between 1-empowering and absorption is discussed in Atserias et al., 2011.)\nWe will now explore the relationship between absorption and negative-hyper-resolution.\nExample 5 Let \u2206 be the direct encoding of a CSP instance P = (V,D,C), where V = {u, v, w}, Du = Dv = Dw = {1, 2} and C contains two binary constraints: one forbids the assignment of the value 1 to u and v simultaneously, and the other forbids the simultaneous assignment of the value 2 to u and 1 to w. Let C also contain a ternary constraint that forbids the assignment of the value 2 to all three variables simultaneously.\n\u2206 = { xu1 \u2228 xu2, xv1 \u2228 xv2, xw1 \u2228 xw2, \u00acxu1 \u2228 \u00acxu2, \u00acxv1 \u2228 \u00acxv2, \u00acxw1 \u2228 \u00acxw2,\n\u00acxu1 \u2228 \u00acxv1, \u00acxu2 \u2228 \u00acxw1, \u00acxu2 \u2228 \u00acxv2 \u2228 \u00acxw2 }.\nThe clause \u00acxv1 \u2228 \u00acxw1 is not contained in \u2206, but can be obtained by negative-hyperresolution from the clauses xu1 \u2228 xu2,\u00acxu1 \u2228 \u00acxv1,\u00acxu2 \u2228 \u00acxw1.\nThis clause is absorbed by \u2206, since every inconclusive round that sets xv1 = true must set xw1 = false by unit propagation, and every inconclusive round that sets xw1 = true must set xv1 = false also by unit propagation.\nExample 5 indicates that clauses that can be obtained by negative hyper-resolution from a set of clauses \u2206 are sometimes absorbed by \u2206. The next result clarifies when this situation holds.\nLemma 4 Any negative-hyper-resolvent of a set of disjoint clauses is absorbed by that set of clauses.\nProof. Let C be the negative-hyper-resolvent of a set of clauses \u2206 = {Ci \u2228 \u00acxi | i = 1, 2, . . . , r} and a clause C \u2032 = C0 \u2228 x1 \u2228 x2 \u2228 \u00b7 \u00b7 \u00b7 \u2228 xr, where each Ci is a (possibly empty) disjunction of negative literals, for 0 \u2264 i \u2264 r. Then C = C0 \u2228C1 \u2228 \u00b7 \u00b7 \u00b7 \u2228Cr by Definition 3. By Definition 4, we must show that \u2206 \u222a C \u2032 absorbs C at each of its literals. Assume all but one of the literals of C are falsified. Since the set of clauses \u2206 \u222a C \u2032 are assumed to be disjoint, the remaining literal l must belong to exactly one of the clauses in this set. There are two cases to consider.\n1. If l belongs to the clause C \u2032, then all clauses in \u2206 have all but one literals falsified, so the remaining literal \u00acxi in each of these clauses is set to true, by unit propagation. Hence all literals in C \u2032 are falsified, except for l, so l is set to true, by unit propagation.\n2. If l belongs to one of the clauses Ci \u2228\u00acxi, then all of the remaining clauses in \u2206 have all but one literals falsified, so the corresponding literals \u00acxj are set to true, by unit propagation. Hence all literals in C \u2032 are falsified, except for xi, so xi is set to true, by unit propagation. But now all literals in Ci \u2228 \u00acxi are falsified, except for l, so l is set to true by unit propagation.\n2\nThe next example shows that the negative-hyper-resolvent of a set of clauses that is not disjoint will not necessarily be absorbed by those clauses.\nExample 6 Recall the set of clauses \u2206 given in Example 5, which is the direct encoding of a CSP instance with three variables {u, v, w}, each with domain {1, 2}.\nThe clause \u00acxu2 \u2228 \u00acxv2 is not contained in \u2206, but can be obtained by negative-hyperresolution from the clauses xw1 \u2228 xw2,\u00acxu2 \u2228 \u00acxv2 \u2228 \u00acxw2,\u00acxu2 \u2228 \u00acxw1.\nThis clause is not absorbed by \u2206, since an inconclusive round that sets xv2 = true will not necessarily ensure that xu2 = false by unit propagation.\nThe basic approach we shall use to establish our main results below is to show that any clauses that can be obtained by bounded width negative-hyper-resolution from a given set of clauses, but are not immediately absorbed (such as the one in Example 6) are likely to become absorbed quite quickly because of the additional clauses that are added by the process of clause learning. Hence a clause-learning SAT-solver is likely to fairly rapidly absorb all of the clauses that can be derived from its original database of clauses by negativehyper-resolution. In particular, if the empty clause can be derived by negative-hyperresolution, then the solver will fairly rapidly absorb some literal and its complement, and hence report unsatisfiability (see the proof of Theorem 2 for details).\nThe following key properties of absorption are established by Atserias et al. (2011).\nLemma 5 (Atserias et al., 2011) Let \u2206 and \u2206\u2032 be sets of clauses, and let C and C \u2032 be non-empty clauses.\n1. If C belongs to \u2206, then \u2206 absorbs C;\n2. If C \u2286 C \u2032 and \u2206 absorbs C, then \u2206 absorbs C \u2032;\n3. If \u2206 \u2286 \u2206\u2032 and \u2206 absorbs C, then \u2206\u2032 absorbs C.\nTo allow further analysis, we need to make some assumptions about the learning scheme, the restart policy and the branching strategy used by our SAT-solver.\nThe learning scheme is a rule that creates and adds a new clause to the database whenever there is a conflict. Such a clause is called a conflict clause, and each of its literals is falsified by some assignment in the current state. If a literal is falsified by the i-th decision assignment, or some later implied assignment before the (i+1)-th decision assignment, it is said to be falsified at level i. If a conflict clause contains exactly one literal that is falsified at the maximum possible level, it is called an asserting clause (Pipatsrisawat & Darwiche, 2009; Zhang, Madigan, Moskewicz, & Malik, 2001).\nAssumption 1 The learning scheme chooses an asserting clause.\nAlgorithm 1 Framework for a typical clause-learning SAT-solver\nInput: \u2206 : set of clauses; S : partial assignment of truth values to variables.\n1. while \u2206|S 6= \u2205 do 2. if \u2205 \u2208 \u2206|S then Conflict 3. if S contains no decision assignments then 4. print \u201cUNSATISFIABLE\u201d and halt 5. else 6. apply the learning scheme to add a new clause to \u2206 7. if restart policy says restart then 8. set S = \u2205 9. else 10. select most recent conflict-causing unreversed decision assignment in S 11. reverse this decision, and remove all later assignments from S 12. end if 13. end if 14. else if {l} \u2208 \u2206|S for some literal l then Unit Propagation 15. add to S the implied assignment x = a which satisfies l 16. else Decision 17. apply the branching strategy to choose a decision assignment x = a 18. add this decision assignment to S 19. end if 20. end while 21. print \u201cSATISFIABLE\u201d and output S\nMost learning schemes in current use satisfy this assumption (Pipatsrisawat & Darwiche, 2009; Zhang et al., 2001), including the learning schemes called \u201c1UIP\u201d and \u201cDecision\u201d (Zhang et al., 2001).\nWe make no particular assumption about the restart policy. However, our main result is phrased in terms of a bound on the expected number of restarts. If the algorithm restarts after r conflicts, our bound on the expected number of restarts can simply be multiplied by r to get a bound on the expected number of conflicts. This means that the results will be strongest if the algorithm restarts immediately after each conflict. In that case, r = 1 and our bound will also bound the expected number of conflicts. Existing SATsolvers typically do not employ such an aggressive restart policy, but we note the remark in the work of Pipatsrisawat and Darwiche (2009, p.666) that \u201cthere has been a clear trend towards more and more frequent restarts for modern SAT solvers\u201d.\nThe branching strategy determines which decision assignment is chosen after an inconclusive round that is not complete. In most current SAT solvers the strategy is based on some heuristic measure of variable activity, which is related to the occurrence of a variable in conflict clauses (Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001). However, to simplify the probabilistic analysis, we will make the following assumption.\nAssumption 2 The branching strategy chooses a variable uniformly at random amongst the unassigned variables, and assigns it the value TRUE.\nAs noted by Atserias et al. (2011), the same analysis we give below can also be applied to any other branching strategy that randomly chooses between making a heuristic-based decision or a randomly-based decision. More precisely, if we allow, say, c > 1 rounds of nonrandom decisions between random ones, then the number of required restarts and conflicts would appear multiplied by a factor of c.\nAn algorithm that behaves according to the description in Algorithm 1, and satisfies the assumptions above, will be called a standard randomised SAT-solver.\nTheorem 2 If a set of non-empty clauses \u2206 over n Boolean variables has a negativehyper-resolution refutation of width k and length m, then the expected number of restarts required by a standard randomised SAT-solver to discover that \u2206 is unsatisfiable is less than mnk2 (n k ) .\nProof. Let C1, C2, . . . , Cm be a negative-hyper-resolution refutation of width k from \u2206, where Cm is the first occurrence of the empty clause. Since each clause in \u2206 is non-empty, Cm must be derived by negative-hyper-resolution from some collection of negative literals \u00acx1,\u00acx2, . . .\u00acxd and a purely positive clause x1 \u2228 x2 \u2228 \u00b7 \u00b7 \u00b7 \u2228 xd \u2208 \u2206.\nNow consider a standard randomised SAT-solver started with database \u2206. Once all of the unit clauses \u00acxi are absorbed by the current database, then, by Definition 4, any further inconclusive round of the algorithm must assign all variables xi false, and hence falsify the clause x1\u2228x2\u2228 \u00b7 \u00b7 \u00b7xd. Since this happens even when no decision assignments are made, the SAT-solver will report unsatisfiability.\nIt only remains to bound the expected number of restarts required until each clause Ci is absorbed, for 1 \u2264 i < m. Let each Ci be the negative-hyper-resolvent of clauses Ci1, Ci2, . . . , Cir, each of the form C \u2032 ij\u2228\u00acxj , together with a clause Ci0 = C0\u2228x1\u2228x2\u2228\u00b7 \u00b7 \u00b7\u2228xr from \u2206, where C0 is a (possibly empty) disjunction of negative literals. Assume also that each clause Cij is absorbed by \u2206 for j = 0, 1, . . . , r.\nIf \u2206 absorbs Ci, then no further learning or restarts are needed, so assume now that \u2206 does not absorb Ci. By Definition 4, this means that there exists some literal l and some inconclusive round R started with \u2206 that falsifies Ci \\ {l} and does not satisfy Ci. Note that R must leave the literal l unassigned, because one assignment would satisfy Ci and the other would falsify C0 and each C \u2032 ij , and hence force all of the literals \u00acxj used in the negative-hyper-resolution step to be satisfied, because each Cij is absorbed by \u2206, so Ci0 would be falsified, contradicting the fact that R is inconclusive.\nHence, if the branching strategy chooses to falsify the literals Ci \\ {l} whenever it has a choice, it will construct an inconclusive round R\u2032 where l is unassigned (since all the decision assignments in R\u2032 are also assigned the same values in R, any implied assignments in R\u2032 must also be assigned the same values3 in R, but we have shown that R leaves l unassigned). If the branching strategy then chooses to falsify the remaining literal l of Ci, then the algorithm would construct a conclusive round R\u2032\u2032 where Ci0 is falsified, and all\n3. See Lemmas 5, 8 and 10 in the work of Atserias et al. (2011) for a more formal statement and proof of this assertion.\ndecision assignments falsify literals in Ci. Hence, by Assumption 1, the algorithm would then learn some asserting clause C \u2032 and add it to \u2206 to obtain a new set \u2206\u2032.\nSince C \u2032 is an asserting clause, it contains exactly one literal, l\u2032, that is falsified at the highest level in R\u2032\u2032. Hence, any inconclusive round R started with \u2206\u2032 that falsifies Ci \\ {l} will falsify all but one literal of C \u2032, and hence force the remaining literal l\u2032 to be satisfied, by unit propagation. If this new implied assignment for l\u2032 propagates to force l to be true, then R satisfies Ci, and hence \u2206\n\u2032 absorbs Ci at l. If not, then the branching strategy can once again choose to falsify the remaining literal l of Ci, which will cause a new asserting clause to be learned and added to \u2206. Since each new asserting clause forces a new literal to be satisfied after falsifying Ci \\ {l} this process can be repeated fewer than n times before it is certain that \u2206\u2032 absorbs Ci at l.\nNow consider any sequence of k random branching choices. If the first k \u2212 1 of these each falsify a literal of Ci \\ {l}, and the final choice falsifies l, then we have shown that the associated round will reach a conflict, and add an asserting clause to \u2206. With a random branching strategy, as described in Assumption 2, the probability that this happens is at least the probability that the first k \u2212 1 random choices consist of a fixed set of variables (in some order), and the final choice is the variable associated with l. The number of random choices that fall in a fixed set follows the hypergeometric distribution, so the overall probability of this is 1\n( nk\u22121) 1\n(n\u2212k+1) = 1/(k (n k ) ).\nTo obtain an upper bound on the expected number of restarts, consider the worst case where we require n asserting clauses to be added to absorb each clause Ci at each of its k literals l. Since we require only an upper bound, we will treat each round as an independent trial with success probability p = 1/(k (n k ) ), and consider the worst case where we have to achieve (m \u2212 1)nk successes to ensure that Ci for 1 \u2264 i < m is absorbed. In this case the total number of restarts will follow a negative binomial distribution, with expected value (m\u2212 1)nk/p. Hence in all cases the expected number of restarts is less than mnk2 (n k ) . 2\nA tighter bound on the number of restarts can be obtained if we focus on the Decision learning scheme (Atserias et al., 2011; Zhang et al., 2001), as the next result indicates.\nTheorem 3 If a set of non-empty clauses \u2206 over n Boolean variables has a negative-hyperresolution refutation of width k and length m, then the expected number of restarts required by a standard randomised SAT-solver using the Decision learning scheme to discover that \u2206 is unsatisfiable is less than m (n k ) .\nProof. The proof is similar to the proof of Theorem 2, except that the Decision learning scheme has the additional feature that the literals in the chosen conflict clause falsify a subset of the current decision assignments. Hence in the situation we consider, where the decision assignments all falsify literals of some clause Ci, this learning scheme will learn a subset of Ci, and hence immediately absorb Ci, by Lemma 5 (1,2). Hence the maximum number of learnt clauses required is reduced from (m\u22121)nk to (m\u22121), and the probability is increased from 1/(k (n k ) ) to 1/ (n k ) , giving the tighter bound. 2\nNote that a similar argument shows that the standard deviation of the number of restarts is less than the standard deviation of a negative binomial distribution with parameters m\nand 1/ (n k ) , which is less than \u221a m (n k ) . Hence, by Chebyshev\u2019s inequality (one-tailed version), the probability that a standard randomised SAT-solver using the decision learning scheme will discover that \u2206 is unsatisfiable after (m + \u221a m) (n k ) restarts is greater than 1/2.\n5. k-Consistency and SAT-Solvers\nBy combining Theorem 1 and Theorem 3 we obtain the following result linking k-consistency and SAT-solvers.\nTheorem 4 If the k-consistency closure of a CSP instance P is empty, then the expected number of restarts required by a standard randomised SAT-solver using the Decision learning scheme to discover that the direct encoding of P is unsatisfiable is O(n2kd2k), where n is the number of variables in P and d is the maximum domain size.\nProof. The length m of a negative-hyper-resolution refutation of width k is bounded by the number of possible no-goods of length at most k for P , which is \u2211k i=1 d i (n i ) . Hence,\nby Theorem 1 and Theorem 3 we obtain a bound of (\u2211k i=1 d i (n i )) (nd k ) , which is O(n2kd2k). 2\nHence a standard randomised SAT-solver with a suitable learning strategy will decide the satisfiability of any CSP instance with tree-width k with O(n2kd2k) expected restarts, even when it is set to restart immediately after each conflict. In particular, the satisfiability of any tree-structured binary CSP instance (i.e., with tree-width 1) will be decided by such a solver with at most O(n2d2) expected conflicts, which is comparable with the growth rate of an optimal arc-consistency algorithm for binary constraints. Note that this result cannot be obtained directly from the work of Atserias et al. (2011), because the direct encoding of an instance with tree-width k is a set of clauses whose tree-width may be as high as dk.\nMoreover, a standard randomised SAT-solver will decide the satisfiability of any CSP instance, with any structure, within the same polynomial bounds, if the constraint relations satisfy certain algebraic properties that ensure bounded width (Barto & Kozik, 2009). Examples of such constraint types include the \u201c0/1/all\u201d relations, defined by Cooper et al. (1994), and the \u201cconnected row-convex\u201d relations, defined by Deville et al. (1997), which can both be decided by 2-consistency.\nIt was shown by Gent (2002) that the support encoding of a binary CSP instance can be made arc-consistent (that is, 1-consistent) by applying unit propagation alone. Hence, a standard SAT-solver will mimic the effect of enforcing arc-consistency on such an encoding before making any decisions or restarts. By combining Theorem 4 with the observation in Example 4 that the direct encoding can be obtained from the support encoding by negativehyper-resolution, we obtain the following corollary concerning the support encoding for all higher levels of consistency.\nCorollary 2 For any k \u2265 2, if the k-consistency closure of a binary CSP instance P is empty, then the expected number of restarts required by a standard randomised SATsolver using the Decision learning scheme to discover that the support encoding of P is unsatisfiable is O(n2kd2k), where n is the number of variables in P and d is the maximum domain size.\nThe CSP literature describes many variations on the notion of consistency. In this paper we have considered k-consistency only. We note that our results can be generalised to some other types of consistency such as singleton arc-consistency (Bessie\u0300re, 2006). The extension to singleton arc-consistency follows from the recent discovery that if a family of CSP instances is solvable by enforcing singleton arc-consistency, then the instances have bounded width (Chen, Dalmau, & Gru\u00dfien, 2011). In other words, all such instances can be solved by enforcing k-consistency, for some fixed k. Hence, by Theorem 4, they will be solved in polynomial expected time by a standard randomised SAT-solver."}, {"heading": "6. Experimental Results", "text": "The polynomial upper bounds we obtain in this paper are not asymptotic, they apply for all values of n,m and k. However, they are very conservative, and are likely to be met very easily in practice.\nTo investigate how an existing SAT-solver actually performs, we measured the runtime of the MiniSAT solver (Ee\u0301n & So\u0308rensson, 2003), version 2.2.0, on a family of CSP instances that can be decided by a fixed level of consistency. For comparison, we also ran our experiments on two state-of-the-art constraint solvers: we used Minion (Gent, Jefferson, & Miguel, 2006), version 0.12, and the G12 finite domain solver (Nethercote et al., 2007), version 1.4.\nTo match the simplified assumptions of our analysis more closely, we ran a further set of experiments on a core version of MiniSAT in order to get a solver that uses only unit propagation and conflict-directed learning with restarts. We also modified the solver to follow the random branching strategy described above. Our solver does not delete any learnt clauses and uses an extreme restart policy that makes it restart whenever it encounters a conflict. It uses the same learning scheme as MiniSAT. We refer to this modified solver as simple-MiniSAT.\nAs the characteristic feature of the instances tested is their relatively low tree-width, we also used the Toulbar2 solver (Sanchez et al., 2008). This solver implements the BTD (Backtracking with Tree-Decomposition) technique which has been shown to be efficient in practice, in contrast to earlier methods that had been proposed to attempt to exploit tree-decompositions of the input problem (Je\u0301gou & Terrioux, 2003). As the problem of finding a tree-decomposition of minimal width (i.e., the tree-width) is NP-hard, the BTD technique uses some approximations (described in Je\u0301gou & Terrioux, 2003). We note here that Toulbar2 is designed for solving optimization problems, namely weighted CSPs, or WCSPs. In a WCSP instance, certain partial assignments have an associated cost. However, the Toulbar2 solver can be used to solve standard CSPs by simply setting all costs to 0.\nFor all of the results, the times given are elapsed times on a Lenovo 3000 N200 laptop with an Intel Core 2 Duo processor running at 1.66GHz with 2GB of RAM. Each generated instance was run five times and the mean times and mean number of restarts are shown4.\nExample 7 We consider a family of instances specified by two parameters, w and d. They have ((d\u22121)\u2217w+2)\u2217w variables arranged in groups of size w, each with domain {0, ..., d\u22121}.\n4. MiniSAT and simple-MiniSAT were run with different seeds for each of the five runs of an instance. Instances marked with * were run once only. The runtime of simple-MiniSAT on those instances exceeded 6 hours. Moreover, Toulbar2 was run with parameter B = 1 which enables BTD.\nWe impose a constraint of arity 2w on each pair of successive groups, requiring that the sum of the values assigned to the first of these two groups should be strictly smaller than the sum of the values assigned to the second. This ensures that the instances generated are unsatisfiable. An instance with w = 2 and d = 2 is shown diagrammatically and defined using the specification language MiniZinc (Nethercote et al., 2007) in Figure 1 (a) and (b) respectively5. A similar format is used for Toulbar2 6 and the same instance encoded in this format is shown in Figure 1 (c) (note that each hard constraint has cost 0).\nThe structure of the instances described in Example 7 has a simple tree-decomposition as a path of nodes, with each node corresponding to a constraint scope. Hence the tree-width of these instances is 2w \u2212 1 and they can be shown to be unsatisfiable by enforcing (2w \u2212 1)- consistency (Atserias et al., 2007). However, these instances cannot be solved efficiently using standard propagation algorithms which only prune individual domain values.\nThe structure of the direct encoding of these instances also has a tree-decomposition with each node corresponding to a constraint scope in the original CSP instance. However, because the direct encoding introduces d Boolean variables to represent each variable in the\n5. In order to run an instance on a CP solver one must usually use a translator to convert the original model. The MiniZinc distribution provides an mzn2fzn translator while for Minion one can use Tailor (available at http://www.cs.st-andrews.ac.uk/\u223candrea/tailor/). 6. A cp2wcsp translator and a description of the cp and wcsp formats is available at http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/SoftCSP.\noriginal instance, the tree-width of the encoded SAT instances is larger by approximately a factor of d; it is in fact 2wd\u2212 1 (see Figure 2).\nTable 1 shows the runtimes of simple-MiniSAT and the original MiniSAT solver on this family of instances, along with times for the two state-of-the-art CP solvers and the WCSP solver Toulbar2. By far the best solver for this set of instances is Toulbar2, which is explicitly designed to exploit low tree-width by constructing a tree-decomposition. For the class of instances we are considering, the widths of the tree-decompositions found by Toulbar2 matched the tree-widths of the instances tested (i.e., 2w \u2212 1).\nHowever, we also note that MiniSAT is remarkably effective in solving these chains of inequalities, compared to Minion and G12, even though the use of MiniSAT requires encoding each instance into a large number of clauses with a much larger tree-width than the original. Although our simplified version of the MiniSAT solver takes a little longer than the current highly optimised version, it still performs very well on these instances in comparison with the conventional CP solvers. Moreover, the number of restarts (and hence the number of conflicts) appears to grow only polynomially with the size of the instance (see Figure 3). In all cases the actual number of restarts is much lower than the polynomial upper bound on the expected number of restarts given in Theorem 4.\nOur best theoretical upper bounds on the expected run-time were obtained for the Decision learning scheme (Theorem 4), but the standard version of MiniSAT uses the 1UIP learning scheme with conflict clause minimization. To allow a direct comparison with these theoretical upper bounds, we implemented the Decision scheme in simpleMiniSAT. As the 1UIP learning scheme has generally been found to be more efficient in practice (Zhang et al., 2001), we switched off conflict clause minimization in simpleMiniSAT in order to compare the two standard learning schemes and ran a further set of experiments. We counted the number of restarts for these two modified solvers on instances of the form described in Example 7 - see Table 2.\nAlthough the performance of simple-MiniSAT with the Decision learning scheme and the 1UIP scheme are significantly worse than the performance of the original simpleMiniSAT solver, only about twice as many restarts were required for each instance. Hence, our theoretical upper bounds are still easily met for both of these standard learning schemes."}, {"heading": "7. Conclusions", "text": "We have shown that the notion of k-consistency can be precisely captured by a single inference rule on the direct encoding of a CSP instance, restricted to deriving only clauses with at most k literals. We used this to show that a clause-learning SAT-solver with a purely random branching strategy will simulate the effect of enforcing k-consistency in expected polynomial time, for all fixed k. This is sufficient to ensure that such solvers are able to solve certain problem families much more efficiently than conventional CP solvers relying on GAC-propagation.\nIn principle clause-learning SAT-solvers can also do much more. It is known that, with an appropriate branching strategy and restart policy, they are able to p-simulate general resolution (Beame et al., 2004; Pipatsrisawat & Darwiche, 2009), and general resolution proofs can be exponentially shorter than the negative-hyper-resolution proofs we have considered here (Hwang & Mitchell, 2005). In practice, it seems that current clause-learning SAT-solvers with highly-tuned learning schemes, branching strategies and restart policies are often able to exploit structure in the Boolean encoding of a CSP instance even more effectively than local consistency techniques. Hence considerable work remains to be done in understanding the relevant features of instances which they are able to exploit, in order to predict their effectiveness in solving different kinds of CSP instances."}, {"heading": "Acknowledgments", "text": "We would like to thank Albert Atserias and Marc Thurley for comments on the conference version of this paper, as well as the anonymous referees. The provision of an EPSRC Doctoral Training Award to Justyna Petke is also gratefully acknowledged.\nA preliminary version of this paper appeared in Proceedings of the 16th International Conference on Principles and Practice of Constraint Programming - CP2010."}], "references": [{"title": "On the power of k-consistency", "author": ["A. Atserias", "A.A. Bulatov", "V. Dalmau"], "venue": "In International Colloquium on Automata, Languages and Programming -", "citeRegEx": "Atserias et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Atserias et al\\.", "year": 2007}, {"title": "A combinatorial characterization of resolution width", "author": ["A. Atserias", "V. Dalmau"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Atserias and Dalmau,? \\Q2008\\E", "shortCiteRegEx": "Atserias and Dalmau", "year": 2008}, {"title": "Clause-learning algorithms with many restarts and bounded-width resolution", "author": ["A. Atserias", "J.K. Fichte", "M. Thurley"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Atserias et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Atserias et al\\.", "year": 2011}, {"title": "GAC via unit propagation", "author": ["F. Bacchus"], "venue": "Principles and Practice of Constraint Programming - CP\u201907, pp. 133\u2013147.", "citeRegEx": "Bacchus,? 2007", "shortCiteRegEx": "Bacchus", "year": 2007}, {"title": "Constraint satisfaction problems of bounded width", "author": ["L. Barto", "M. Kozik"], "venue": "In Symposium on Foundations of Computer Science -", "citeRegEx": "Barto and Kozik,? \\Q2009\\E", "shortCiteRegEx": "Barto and Kozik", "year": 2009}, {"title": "Towards understanding and harnessing the potential of clause learning", "author": ["P. Beame", "H.A. Kautz", "A. Sabharwal"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Beame et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Beame et al\\.", "year": 2004}, {"title": "Constraint propagation", "author": ["C. Bessi\u00e8re"], "venue": "Rossi, F., van Beek, P., & Walsh, T. (Eds.), Handbook of Constraint Programming, chap. 3. Elsevier.", "citeRegEx": "Bessi\u00e8re,? 2006", "shortCiteRegEx": "Bessi\u00e8re", "year": 2006}, {"title": "Propositional logic: deduction and algorithms. Cambridge tracts in theoretical computer science", "author": ["H. B\u00fcning", "T. Lettmann"], "venue": null, "citeRegEx": "B\u00fcning and Lettmann,? \\Q1999\\E", "shortCiteRegEx": "B\u00fcning and Lettmann", "year": 1999}, {"title": "Arc consistency and friends", "author": ["H. Chen", "V. Dalmau", "B. Gru\u00dfien"], "venue": "Computing Research Repository - CoRR,", "citeRegEx": "Chen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2011}, {"title": "An optimal k-consistency algorithm", "author": ["M.C. Cooper"], "venue": "Artificial Intelligence, 41 (1), 89\u201395.", "citeRegEx": "Cooper,? 1989", "shortCiteRegEx": "Cooper", "year": 1989}, {"title": "Characterising tractable constraints", "author": ["M.C. Cooper", "D.A. Cohen", "P. Jeavons"], "venue": "Artificial Intelligence,", "citeRegEx": "Cooper et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Cooper et al\\.", "year": 1994}, {"title": "A comparison of ATMS and CSP techniques", "author": ["J. de Kleer"], "venue": "In International Joint Conference on Artificial Intelligence -", "citeRegEx": "Kleer,? \\Q1989\\E", "shortCiteRegEx": "Kleer", "year": 1989}, {"title": "Constraint satisfaction over connected row convex constraints", "author": ["Y. Deville", "O. Barette", "P.V. Hentenryck"], "venue": "In International Joint Conference on Artificial Intelligence", "citeRegEx": "Deville et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Deville et al\\.", "year": 1997}, {"title": "An extensible SAT-solver", "author": ["N. E\u00e9n", "N. S\u00f6rensson"], "venue": "In Theory and Applications of Satisfiability Testing -", "citeRegEx": "E\u00e9n and S\u00f6rensson,? \\Q2003\\E", "shortCiteRegEx": "E\u00e9n and S\u00f6rensson", "year": 2003}, {"title": "Synthesizing constraint expressions", "author": ["E.C. Freuder"], "venue": "Communications of the ACM, 21 (11), 958\u2013966.", "citeRegEx": "Freuder,? 1978", "shortCiteRegEx": "Freuder", "year": 1978}, {"title": "Arc consistency in SAT", "author": ["I.P. Gent"], "venue": "European Conference on Artificial Intelligence - ECAI\u201902, pp. 121\u2013125.", "citeRegEx": "Gent,? 2002", "shortCiteRegEx": "Gent", "year": 2002}, {"title": "Minion: A fast scalable constraint solver", "author": ["I.P. Gent", "C. Jefferson", "I. Miguel"], "venue": "In European Conference on Artificial Intelligence -", "citeRegEx": "Gent et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Gent et al\\.", "year": 2006}, {"title": "Integrated Methods for Optimization (International Series in Operations Research & Management Science)", "author": ["J.N. Hooker"], "venue": "Springer-Verlag New York, Inc., Secaucus, NJ, USA.", "citeRegEx": "Hooker,? 2006", "shortCiteRegEx": "Hooker", "year": 2006}, {"title": "SAT-encodings, search space structure, and local search performance", "author": ["H.H. Hoos"], "venue": "International Joint Conference on Artificial Intelligence - IJCAI\u201999, pp. 296\u2013303.", "citeRegEx": "Hoos,? 1999", "shortCiteRegEx": "Hoos", "year": 1999}, {"title": "2-way vs. d-way branching for CSP", "author": ["J. Hwang", "D.G. Mitchell"], "venue": "In Principles and Practice of Constraint Programming -", "citeRegEx": "Hwang and Mitchell,? \\Q2005\\E", "shortCiteRegEx": "Hwang and Mitchell", "year": 2005}, {"title": "Hybrid backtracking bounded by tree-decomposition of constraint networks", "author": ["P. J\u00e9gou", "C. Terrioux"], "venue": "Artificial Intelligence,", "citeRegEx": "J\u00e9gou and Terrioux,? \\Q2003\\E", "shortCiteRegEx": "J\u00e9gou and Terrioux", "year": 2003}, {"title": "A game-theoretic approach to constraint satisfaction", "author": ["P.G. Kolaitis", "M.Y. Vardi"], "venue": "In Conference on Artificial Intelligence", "citeRegEx": "Kolaitis and Vardi,? \\Q2000\\E", "shortCiteRegEx": "Kolaitis and Vardi", "year": 2000}, {"title": "Consistency in networks of relations", "author": ["A.K. Mackworth"], "venue": "Artificial Intelligence, 8 (1), 99\u2013118.", "citeRegEx": "Mackworth,? 1977", "shortCiteRegEx": "Mackworth", "year": 1977}, {"title": "Networks of constraints: Fundamental properties and applications to picture processing", "author": ["U. Montanari"], "venue": "Information Sciences, 7, 95\u2013132.", "citeRegEx": "Montanari,? 1974", "shortCiteRegEx": "Montanari", "year": 1974}, {"title": "Chaff: Engineering an efficient SAT solver", "author": ["M.W. Moskewicz", "C.F. Madigan", "Y. Zhao", "L. Zhang", "S. Malik"], "venue": "In Design Automation Conference -", "citeRegEx": "Moskewicz et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Moskewicz et al\\.", "year": 2001}, {"title": "MiniZinc: Towards a standard CP modelling language", "author": ["N. Nethercote", "P.J. Stuckey", "R. Becket", "S. Brand", "G.J. Duck", "G. Tack"], "venue": "In Principles and Practice of Constraint Programming -", "citeRegEx": "Nethercote et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nethercote et al\\.", "year": 2007}, {"title": "Tractable benchmarks for constraint programming", "author": ["J. Petke", "P. Jeavons"], "venue": "Technical Report RR-09-07,", "citeRegEx": "Petke and Jeavons,? \\Q2009\\E", "shortCiteRegEx": "Petke and Jeavons", "year": 2009}, {"title": "On the power of clause-learning SAT solvers with restarts", "author": ["K. Pipatsrisawat", "A. Darwiche"], "venue": "In Principles and Practice of Constraint Programming -", "citeRegEx": "Pipatsrisawat and Darwiche,? \\Q2009\\E", "shortCiteRegEx": "Pipatsrisawat and Darwiche", "year": 2009}, {"title": "CNF encodings", "author": ["S.D. Prestwich"], "venue": "Biere, A., Heule, M., van Maaren, H., & Walsh, T. (Eds.), Handbook of Satisfiability, pp. 75\u201397. IOS Press.", "citeRegEx": "Prestwich,? 2009", "shortCiteRegEx": "Prestwich", "year": 2009}, {"title": "Resolution versus search: Two strategies for SAT", "author": ["I. Rish", "R. Dechter"], "venue": "Journal of Automated Reasoning,", "citeRegEx": "Rish and Dechter,? \\Q2000\\E", "shortCiteRegEx": "Rish and Dechter", "year": 2000}, {"title": "A machine-oriented logic based on the resolution principle", "author": ["J.A. Robinson"], "venue": "Journal of the ACM, 12 (1), 23\u201341.", "citeRegEx": "Robinson,? 1965", "shortCiteRegEx": "Robinson", "year": 1965}, {"title": "Max-CSP competition 2008: Toulbar2 solver description", "author": ["M. Sanchez", "S. Bouveret", "S. de Givry", "F. Heras", "P. J\u00e9gou", "J. Larrosa", "S. Ndiaye", "E. Rollon", "T. Schiex", "C. Terrioux", "G. Verfaillie", "M. Zytnicki"], "venue": "In Proceedings of the Third International CSP Solver Competition", "citeRegEx": "Sanchez et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sanchez et al\\.", "year": 2008}, {"title": "Nogood recording for static and dynamic constraint satisfaction problems", "author": ["T. Schiex", "G. Verfaillie"], "venue": "In International Conference on Tools with Artificial Intelligence - ICTAI\u201993,", "citeRegEx": "Schiex and Verfaillie,? \\Q1993\\E", "shortCiteRegEx": "Schiex and Verfaillie", "year": 1993}, {"title": "Compiling finite linear CSP", "author": ["N. Tamura", "A. Taga", "S. Kitagawa", "M. Banbara"], "venue": "into SAT. Constraints,", "citeRegEx": "Tamura et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Tamura et al\\.", "year": 2009}, {"title": "3rd international CSP solver competition. Instances and results available at http://www.cril.univ-artois.fr/CPAI08", "author": ["M. van Dongen", "C. Lecoutre", "O. Roussel"], "venue": null, "citeRegEx": "Dongen et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Dongen et al\\.", "year": 2008}, {"title": "4th international CSP solver competition. Instances and results available at http://www.cril.univ-artois.fr/CPAI09", "author": ["M. van Dongen", "C. Lecoutre", "O. Roussel"], "venue": null, "citeRegEx": "Dongen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dongen et al\\.", "year": 2009}, {"title": "SAT v CSP", "author": ["T. Walsh"], "venue": "Principles and Practice of Constraint Programming CP\u201900, pp. 441\u2013456.", "citeRegEx": "Walsh,? 2000", "shortCiteRegEx": "Walsh", "year": 2000}, {"title": "Efficient conflict driven learning in Boolean satisfiability solver", "author": ["L. Zhang", "C.F. Madigan", "M.W. Moskewicz", "S. Malik"], "venue": "In International Conference on ComputerAided Design -", "citeRegEx": "Zhang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2001}, {"title": "The quest for efficient Boolean satisfiability solvers", "author": ["L. Zhang", "S. Malik"], "venue": "In Computer Aided Verification -", "citeRegEx": "Zhang and Malik,? \\Q2002\\E", "shortCiteRegEx": "Zhang and Malik", "year": 2002}], "referenceMentions": [{"referenceID": 6, "context": "One of the oldest and most central ideas in constraint programming, going right back to Montanari\u2019s original paper in 1974, is the idea of using local consistency techniques to prune the search space (Bessi\u00e8re, 2006).", "startOffset": 200, "endOffset": 216}, {"referenceID": 6, "context": "One of the oldest and most central ideas in constraint programming, going right back to Montanari\u2019s original paper in 1974, is the idea of using local consistency techniques to prune the search space (Bessi\u00e8re, 2006). The idea of arc-consistency was introduced by Mackworth (1977), and generalised to k-consistency by Freuder (1978).", "startOffset": 201, "endOffset": 281}, {"referenceID": 6, "context": "One of the oldest and most central ideas in constraint programming, going right back to Montanari\u2019s original paper in 1974, is the idea of using local consistency techniques to prune the search space (Bessi\u00e8re, 2006). The idea of arc-consistency was introduced by Mackworth (1977), and generalised to k-consistency by Freuder (1978). Modern constraint solvers generally employ specialised propagators to prune the domains of variables to achieve some form of generalised arc-consistency, but typically do not attempt to enforce higher levels of consistency, such as path-consistency.", "startOffset": 201, "endOffset": 333}, {"referenceID": 36, "context": "To apply such tools to a constraint satisfaction problem one first has to translate the instance into a set of clauses using some form of Boolean encoding (Tamura, Taga, Kitagawa, & Banbara, 2009; Walsh, 2000).", "startOffset": 155, "endOffset": 209}, {"referenceID": 1, "context": "Building on the results of Atserias, Bulatov, and Dalmau (2007), Atserias and Dalmau (2008), and Hwang and Mitchell (2005), we show that the power of using k-consistency techniques in a constraint problem is precisely captured by using a single inference rule in a standard Boolean encoding of that problem.", "startOffset": 65, "endOffset": 92}, {"referenceID": 1, "context": "Building on the results of Atserias, Bulatov, and Dalmau (2007), Atserias and Dalmau (2008), and Hwang and Mitchell (2005), we show that the power of using k-consistency techniques in a constraint problem is precisely captured by using a single inference rule in a standard Boolean encoding of that problem.", "startOffset": 65, "endOffset": 123}, {"referenceID": 1, "context": "Building on the results of Atserias, Bulatov, and Dalmau (2007), Atserias and Dalmau (2008), and Hwang and Mitchell (2005), we show that the power of using k-consistency techniques in a constraint problem is precisely captured by using a single inference rule in a standard Boolean encoding of that problem. We refer to this inference rule as negativehyper-resolution, and show that any conclusions deduced by enforcing k-consistency can be deduced by a sequence of negative-hyper-resolution inferences involving Boolean clauses in the original instance and negative-hyper-resolvents with at most k literals. Furthermore, by using the approach of Atserias, Fichte, and Thurley (2011), and Pipatsrisawat and Darwiche (2009), we show that current clause-learning SAT-solvers will mimic the effect of such deductions in polynomial expected time, even with a random branching strategy.", "startOffset": 65, "endOffset": 684}, {"referenceID": 1, "context": "Building on the results of Atserias, Bulatov, and Dalmau (2007), Atserias and Dalmau (2008), and Hwang and Mitchell (2005), we show that the power of using k-consistency techniques in a constraint problem is precisely captured by using a single inference rule in a standard Boolean encoding of that problem. We refer to this inference rule as negativehyper-resolution, and show that any conclusions deduced by enforcing k-consistency can be deduced by a sequence of negative-hyper-resolution inferences involving Boolean clauses in the original instance and negative-hyper-resolvents with at most k literals. Furthermore, by using the approach of Atserias, Fichte, and Thurley (2011), and Pipatsrisawat and Darwiche (2009), we show that current clause-learning SAT-solvers will mimic the effect of such deductions in polynomial expected time, even with a random branching strategy.", "startOffset": 65, "endOffset": 723}, {"referenceID": 6, "context": "some level of local consistency (Bessi\u00e8re, 2006).", "startOffset": 32, "endOffset": 48}, {"referenceID": 6, "context": "We note that there are several different but equivalent ways to define and enforce k-consistency described in the literature (Bessi\u00e8re, 2006; Cooper, 1989; Freuder, 1978).", "startOffset": 125, "endOffset": 170}, {"referenceID": 9, "context": "We note that there are several different but equivalent ways to define and enforce k-consistency described in the literature (Bessi\u00e8re, 2006; Cooper, 1989; Freuder, 1978).", "startOffset": 125, "endOffset": 170}, {"referenceID": 14, "context": "We note that there are several different but equivalent ways to define and enforce k-consistency described in the literature (Bessi\u00e8re, 2006; Cooper, 1989; Freuder, 1978).", "startOffset": 125, "endOffset": 170}, {"referenceID": 0, "context": "Our presentation follows that of Atserias et al. (2007), which is inspired by the notion of existential k-pebble games introduced by Kolaitis and Vardi (2000).", "startOffset": 33, "endOffset": 56}, {"referenceID": 0, "context": "Our presentation follows that of Atserias et al. (2007), which is inspired by the notion of existential k-pebble games introduced by Kolaitis and Vardi (2000).", "startOffset": 33, "endOffset": 159}, {"referenceID": 0, "context": "Definition 2 (Atserias et al., 2007) For any CSP instance P , the k-consistency closure of P is the set H of partial assignments which is obtained by the following algorithm:", "startOffset": 13, "endOffset": 36}, {"referenceID": 0, "context": "It is straightforward to show that for any fixed k, and any fixed maximum domain size, the k-consistency closure of an instance P can be computed in polynomial time (Atserias et al., 2007; Cooper, 1989).", "startOffset": 165, "endOffset": 202}, {"referenceID": 9, "context": "It is straightforward to show that for any fixed k, and any fixed maximum domain size, the k-consistency closure of an instance P can be computed in polynomial time (Atserias et al., 2007; Cooper, 1989).", "startOffset": 165, "endOffset": 202}, {"referenceID": 0, "context": "The converse is not true in general, but it holds for certain special cases, such as the class of instances whose structure has tree-width bounded by k (Atserias et al., 2007), or the class of instances whose constraint relations are \u201c0/1/all\u201d relations, as defined in Cooper, Cohen, and Jeavons (1994), or \u201cconnected row-convex\u201d relations, as defined in Deville, Barette, and Hentenryck (1997).", "startOffset": 152, "endOffset": 175}, {"referenceID": 4, "context": "Note that computing the k-consistency closure according to this definition corresponds precisely to enforcing strong (k+1)-consistency according to the definitions given by Bessi\u00e8re (2006), Cooper (1989), and Freuder (1978).", "startOffset": 173, "endOffset": 189}, {"referenceID": 4, "context": "Note that computing the k-consistency closure according to this definition corresponds precisely to enforcing strong (k+1)-consistency according to the definitions given by Bessi\u00e8re (2006), Cooper (1989), and Freuder (1978).", "startOffset": 173, "endOffset": 204}, {"referenceID": 4, "context": "Note that computing the k-consistency closure according to this definition corresponds precisely to enforcing strong (k+1)-consistency according to the definitions given by Bessi\u00e8re (2006), Cooper (1989), and Freuder (1978). Throughout this paper, we shall assume that the domain of possible values for each variable in a CSP instance is finite.", "startOffset": 173, "endOffset": 224}, {"referenceID": 0, "context": "It is straightforward to show that for any fixed k, and any fixed maximum domain size, the k-consistency closure of an instance P can be computed in polynomial time (Atserias et al., 2007; Cooper, 1989). Note that any solution to P must extend some element of the k-consistency closure of P . Hence, if the k-consistency closure of P is empty, for some k, then P has no solutions. The converse is not true in general, but it holds for certain special cases, such as the class of instances whose structure has tree-width bounded by k (Atserias et al., 2007), or the class of instances whose constraint relations are \u201c0/1/all\u201d relations, as defined in Cooper, Cohen, and Jeavons (1994), or \u201cconnected row-convex\u201d relations, as defined in Deville, Barette, and Hentenryck (1997).", "startOffset": 166, "endOffset": 684}, {"referenceID": 0, "context": "It is straightforward to show that for any fixed k, and any fixed maximum domain size, the k-consistency closure of an instance P can be computed in polynomial time (Atserias et al., 2007; Cooper, 1989). Note that any solution to P must extend some element of the k-consistency closure of P . Hence, if the k-consistency closure of P is empty, for some k, then P has no solutions. The converse is not true in general, but it holds for certain special cases, such as the class of instances whose structure has tree-width bounded by k (Atserias et al., 2007), or the class of instances whose constraint relations are \u201c0/1/all\u201d relations, as defined in Cooper, Cohen, and Jeavons (1994), or \u201cconnected row-convex\u201d relations, as defined in Deville, Barette, and Hentenryck (1997). For these special kinds of instances it is possible to determine in polynomial time whether or not a solution exists simply by computing the k-consistency closure, for an appropriate choice of k.", "startOffset": 166, "endOffset": 776}, {"referenceID": 28, "context": "Several different ways of encoding a CSP instance as a propositional formula have been proposed (Prestwich, 2009; Tamura et al., 2009; Walsh, 2000).", "startOffset": 96, "endOffset": 147}, {"referenceID": 33, "context": "Several different ways of encoding a CSP instance as a propositional formula have been proposed (Prestwich, 2009; Tamura et al., 2009; Walsh, 2000).", "startOffset": 96, "endOffset": 147}, {"referenceID": 36, "context": "Several different ways of encoding a CSP instance as a propositional formula have been proposed (Prestwich, 2009; Tamura et al., 2009; Walsh, 2000).", "startOffset": 96, "endOffset": 147}, {"referenceID": 28, "context": "The direct encoding (Prestwich, 2009), for instance, generates a clause \u2228 v\u2208S \u00acxvf(v) for each partial assignment f that does not satisfy the constraint (R,S) \u2208 C.", "startOffset": 20, "endOffset": 37}, {"referenceID": 15, "context": "This has been used as the basis for an encoding of binary CSP instances, known as the support encoding (Gent, 2002), defined as follows.", "startOffset": 103, "endOffset": 115}, {"referenceID": 30, "context": "This form of inference is known as propositional resolution; the resultant clause is called the resolvent (Robinson, 1965).", "startOffset": 106, "endOffset": 122}, {"referenceID": 18, "context": "In the case where C0 is empty, the negative-hyper-resolution rule is equivalent to the nogood resolution rule described by Hwang and Mitchell (2005) as well as the H5-k rule introduced by de Kleer (1989) and the nogood recording scheme described by Schiex and Verfaillie (1993).", "startOffset": 123, "endOffset": 149}, {"referenceID": 11, "context": "In the case where C0 is empty, the negative-hyper-resolution rule is equivalent to the nogood resolution rule described by Hwang and Mitchell (2005) as well as the H5-k rule introduced by de Kleer (1989) and the nogood recording scheme described by Schiex and Verfaillie (1993).", "startOffset": 191, "endOffset": 204}, {"referenceID": 11, "context": "In the case where C0 is empty, the negative-hyper-resolution rule is equivalent to the nogood resolution rule described by Hwang and Mitchell (2005) as well as the H5-k rule introduced by de Kleer (1989) and the nogood recording scheme described by Schiex and Verfaillie (1993). Note that the inference obtained by negative-hyper-resolution can also be obtained by a sequence of standard resolution steps.", "startOffset": 191, "endOffset": 278}, {"referenceID": 3, "context": "It has been pointed out by many authors that enforcing local consistency is a form of inference on relations analogous to the use of the resolution rule on clauses (Bacchus, 2007; Bessi\u00e8re, 2006; Hwang & Mitchell, 2005; Rish & Dechter, 2000).", "startOffset": 164, "endOffset": 241}, {"referenceID": 6, "context": "It has been pointed out by many authors that enforcing local consistency is a form of inference on relations analogous to the use of the resolution rule on clauses (Bacchus, 2007; Bessi\u00e8re, 2006; Hwang & Mitchell, 2005; Rish & Dechter, 2000).", "startOffset": 164, "endOffset": 241}, {"referenceID": 2, "context": "It has been pointed out by many authors that enforcing local consistency is a form of inference on relations analogous to the use of the resolution rule on clauses (Bacchus, 2007; Bessi\u00e8re, 2006; Hwang & Mitchell, 2005; Rish & Dechter, 2000). The precise strength of the standard resolution inference rule on the direct encoding of a CSP instance was considered in the work of Walsh (2000), where it was shown that unit resolution (where one of the clauses being resolved consists of a single literal), corresponds to enforcing a weak form of local consistency known as forward checking.", "startOffset": 165, "endOffset": 390}, {"referenceID": 2, "context": "It has been pointed out by many authors that enforcing local consistency is a form of inference on relations analogous to the use of the resolution rule on clauses (Bacchus, 2007; Bessi\u00e8re, 2006; Hwang & Mitchell, 2005; Rish & Dechter, 2000). The precise strength of the standard resolution inference rule on the direct encoding of a CSP instance was considered in the work of Walsh (2000), where it was shown that unit resolution (where one of the clauses being resolved consists of a single literal), corresponds to enforcing a weak form of local consistency known as forward checking. Hwang and Mitchell (2005) pointed out that the standard resolution rule with no restriction on clause length is able to simulate all the inferences made by a k-consistency algorithm.", "startOffset": 165, "endOffset": 614}, {"referenceID": 1, "context": "Atserias and Dalmau (2008) showed that the standard resolution rule restricted to clauses with at most k literals, known as the kresolution rule, can be characterised in terms of the Boolean existential (k+1)-pebble game.", "startOffset": 0, "endOffset": 27}, {"referenceID": 11, "context": "A similar relationship was stated in the work of de Kleer (1989), but a complete proof was not given.", "startOffset": 52, "endOffset": 65}, {"referenceID": 1, "context": "The proof is broken down into two lemmas inspired by Lemmas 2 and 3 in the work of Atserias and Dalmau (2008).", "startOffset": 83, "endOffset": 110}, {"referenceID": 2, "context": "Most current SAT-solvers operate in the following way (Atserias et al., 2011; Pipatsrisawat & Darwiche, 2009).", "startOffset": 54, "endOffset": 109}, {"referenceID": 0, "context": "In this section we adapt the machinery from Atserias et al. (2011), and Pipatsrisawat and Darwiche (2009) to show that for any fixed k, the existence of a negative-hyper-resolution refutation of width k is likely to be discovered by a SAT-solver in polynomial-time using standard clause learning and restart techniques, even with a totally random branching strategy.", "startOffset": 44, "endOffset": 67}, {"referenceID": 0, "context": "In this section we adapt the machinery from Atserias et al. (2011), and Pipatsrisawat and Darwiche (2009) to show that for any fixed k, the existence of a negative-hyper-resolution refutation of width k is likely to be discovered by a SAT-solver in polynomial-time using standard clause learning and restart techniques, even with a totally random branching strategy.", "startOffset": 44, "endOffset": 106}, {"referenceID": 0, "context": "In this section we adapt the machinery from Atserias et al. (2011), and Pipatsrisawat and Darwiche (2009) to show that for any fixed k, the existence of a negative-hyper-resolution refutation of width k is likely to be discovered by a SAT-solver in polynomial-time using standard clause learning and restart techniques, even with a totally random branching strategy. Note that previous results about the power of clause-learning SAT-solvers have generally assumed an optimal branching strategy (Beame, Kautz, & Sabharwal, 2004; Pipatsrisawat & Darwiche, 2009) - they have shown what solvers are potentially capable of doing, rather than what they are likely to achieve in practice. An important exception is the paper by Atserias et al. (2011), which gives an analysis of likely behaviour, but relies on the existence of a standard resolution proof of bounded width.", "startOffset": 44, "endOffset": 744}, {"referenceID": 0, "context": "In this section we adapt the machinery from Atserias et al. (2011), and Pipatsrisawat and Darwiche (2009) to show that for any fixed k, the existence of a negative-hyper-resolution refutation of width k is likely to be discovered by a SAT-solver in polynomial-time using standard clause learning and restart techniques, even with a totally random branching strategy. Note that previous results about the power of clause-learning SAT-solvers have generally assumed an optimal branching strategy (Beame, Kautz, & Sabharwal, 2004; Pipatsrisawat & Darwiche, 2009) - they have shown what solvers are potentially capable of doing, rather than what they are likely to achieve in practice. An important exception is the paper by Atserias et al. (2011), which gives an analysis of likely behaviour, but relies on the existence of a standard resolution proof of bounded width. Here we show that the results of Atserias et al. can be extended to hyper-resolution proofs, which can be shorter and narrower than their associated standard resolution proofs. We will make use of the following terminology from Atserias et al. (2011). For a clause C, a Boolean variable x, and a truth value a \u2208 {0, 1}, the restriction of C by the assignment x = a, denoted C|x=a, is defined to be the constant 1, if the assignment satisfies the clause, or else the clause obtained by deleting from C any literals involving the variable x.", "startOffset": 44, "endOffset": 1118}, {"referenceID": 2, "context": "Definition 4 (Atserias et al., 2011) Let \u2206 be a set of clauses, C a non-empty clause, and l a literal of C.", "startOffset": 13, "endOffset": 36}, {"referenceID": 25, "context": "Note that a closely related notion is introduced by Pipatsrisawat and Darwiche (2009) for clauses that are not absorbed by a set of clauses \u2206; they are referred to as 1-empowering with respect to \u2206.", "startOffset": 52, "endOffset": 86}, {"referenceID": 0, "context": "The following key properties of absorption are established by Atserias et al. (2011).", "startOffset": 62, "endOffset": 85}, {"referenceID": 2, "context": "Lemma 5 (Atserias et al., 2011) Let \u2206 and \u2206\u2032 be sets of clauses, and let C and C \u2032 be non-empty clauses.", "startOffset": 8, "endOffset": 31}, {"referenceID": 37, "context": "Most learning schemes in current use satisfy this assumption (Pipatsrisawat & Darwiche, 2009; Zhang et al., 2001), including the learning schemes called \u201c1UIP\u201d and \u201cDecision\u201d (Zhang et al.", "startOffset": 61, "endOffset": 113}, {"referenceID": 37, "context": ", 2001), including the learning schemes called \u201c1UIP\u201d and \u201cDecision\u201d (Zhang et al., 2001).", "startOffset": 69, "endOffset": 89}, {"referenceID": 0, "context": "As noted by Atserias et al. (2011), the same analysis we give below can also be applied to any other branching strategy that randomly chooses between making a heuristic-based decision or a randomly-based decision.", "startOffset": 12, "endOffset": 35}, {"referenceID": 0, "context": "See Lemmas 5, 8 and 10 in the work of Atserias et al. (2011) for a more formal statement and proof of this assertion.", "startOffset": 38, "endOffset": 61}, {"referenceID": 2, "context": "A tighter bound on the number of restarts can be obtained if we focus on the Decision learning scheme (Atserias et al., 2011; Zhang et al., 2001), as the next result indicates.", "startOffset": 102, "endOffset": 145}, {"referenceID": 37, "context": "A tighter bound on the number of restarts can be obtained if we focus on the Decision learning scheme (Atserias et al., 2011; Zhang et al., 2001), as the next result indicates.", "startOffset": 102, "endOffset": 145}, {"referenceID": 0, "context": "Note that this result cannot be obtained directly from the work of Atserias et al. (2011), because the direct encoding of an instance with tree-width k is a set of clauses whose tree-width may be as high as dk.", "startOffset": 67, "endOffset": 90}, {"referenceID": 0, "context": "Note that this result cannot be obtained directly from the work of Atserias et al. (2011), because the direct encoding of an instance with tree-width k is a set of clauses whose tree-width may be as high as dk. Moreover, a standard randomised SAT-solver will decide the satisfiability of any CSP instance, with any structure, within the same polynomial bounds, if the constraint relations satisfy certain algebraic properties that ensure bounded width (Barto & Kozik, 2009). Examples of such constraint types include the \u201c0/1/all\u201d relations, defined by Cooper et al. (1994), and the \u201cconnected row-convex\u201d relations, defined by Deville et al.", "startOffset": 67, "endOffset": 574}, {"referenceID": 0, "context": "Note that this result cannot be obtained directly from the work of Atserias et al. (2011), because the direct encoding of an instance with tree-width k is a set of clauses whose tree-width may be as high as dk. Moreover, a standard randomised SAT-solver will decide the satisfiability of any CSP instance, with any structure, within the same polynomial bounds, if the constraint relations satisfy certain algebraic properties that ensure bounded width (Barto & Kozik, 2009). Examples of such constraint types include the \u201c0/1/all\u201d relations, defined by Cooper et al. (1994), and the \u201cconnected row-convex\u201d relations, defined by Deville et al. (1997), which can both be decided by 2-consistency.", "startOffset": 67, "endOffset": 650}, {"referenceID": 0, "context": "Note that this result cannot be obtained directly from the work of Atserias et al. (2011), because the direct encoding of an instance with tree-width k is a set of clauses whose tree-width may be as high as dk. Moreover, a standard randomised SAT-solver will decide the satisfiability of any CSP instance, with any structure, within the same polynomial bounds, if the constraint relations satisfy certain algebraic properties that ensure bounded width (Barto & Kozik, 2009). Examples of such constraint types include the \u201c0/1/all\u201d relations, defined by Cooper et al. (1994), and the \u201cconnected row-convex\u201d relations, defined by Deville et al. (1997), which can both be decided by 2-consistency. It was shown by Gent (2002) that the support encoding of a binary CSP instance can be made arc-consistent (that is, 1-consistent) by applying unit propagation alone.", "startOffset": 67, "endOffset": 723}, {"referenceID": 6, "context": "We note that our results can be generalised to some other types of consistency such as singleton arc-consistency (Bessi\u00e8re, 2006).", "startOffset": 113, "endOffset": 129}, {"referenceID": 25, "context": "12, and the G12 finite domain solver (Nethercote et al., 2007), version 1.", "startOffset": 37, "endOffset": 62}, {"referenceID": 31, "context": "As the characteristic feature of the instances tested is their relatively low tree-width, we also used the Toulbar2 solver (Sanchez et al., 2008).", "startOffset": 123, "endOffset": 145}, {"referenceID": 25, "context": "An instance with w = 2 and d = 2 is shown diagrammatically and defined using the specification language MiniZinc (Nethercote et al., 2007) in Figure 1 (a) and (b) respectively5.", "startOffset": 113, "endOffset": 138}, {"referenceID": 0, "context": "Hence the tree-width of these instances is 2w \u2212 1 and they can be shown to be unsatisfiable by enforcing (2w \u2212 1)consistency (Atserias et al., 2007).", "startOffset": 125, "endOffset": 148}, {"referenceID": 37, "context": "As the 1UIP learning scheme has generally been found to be more efficient in practice (Zhang et al., 2001), we switched off conflict clause minimization in simpleMiniSAT in order to compare the two standard learning schemes and ran a further set of experiments.", "startOffset": 86, "endOffset": 106}, {"referenceID": 5, "context": "It is known that, with an appropriate branching strategy and restart policy, they are able to p-simulate general resolution (Beame et al., 2004; Pipatsrisawat & Darwiche, 2009), and general resolution proofs can be exponentially shorter than the negative-hyper-resolution proofs we have considered here (Hwang & Mitchell, 2005).", "startOffset": 124, "endOffset": 176}], "year": 2012, "abstractText": "Local consistency techniques such as k-consistency are a key component of specialised solvers for constraint satisfaction problems. In this paper we show that the power of using k-consistency techniques on a constraint satisfaction problem is precisely captured by using a particular inference rule, which we call negative-hyper-resolution, on the standard direct encoding of the problem into Boolean clauses. We also show that current clauselearning SAT-solvers will discover in expected polynomial time any inconsistency that can be deduced from a given set of clauses using negative-hyper-resolvents of a fixed size. We combine these two results to show that, without being explicitly designed to do so, current clause-learning SAT-solvers efficiently simulate k-consistency techniques, for all fixed values of k. We then give some experimental results to show that this feature allows clause-learning SAT-solvers to efficiently solve certain families of constraint problems which are challenging for conventional constraint-programming solvers.", "creator": "TeX"}}}