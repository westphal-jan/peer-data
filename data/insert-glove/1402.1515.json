{"id": "1402.1515", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2014", "title": "Dictionary Learning over Distributed Models", "abstract": "marcellino In ex-member this paper, mantiqueira we astvatsatsin consider holc learning dictionary marginally models over a stiffens network of griped agents, ihlen where natiq each agent is only bc5 in charge of a portion of the mica\u00ebla dictionary elements. This taxies formulation is relevant in port-city big parler data 15-season scenarios tech where multiple large battistone dictionary reacquainted models andreasberg may innocent be shmuger spread dijkstal over marcomannic different spatial locations seyid and innovative it is diapason not adolescentes feasible to 4.9375 aggregate all dictionaries aeroport in fifo one location aromanians due antolini to nasim communication and lovo privacy considerations. We 76101-1870 first theismann show that up/down the dual function of 5-ounce the contro inference problem is an ellin aggregation datacenters of individual elv cost audiocassette functions status associated bartko with gittens different agents, art\u00far which farndale can then kericho be minimized efficiently moray by means chumphon of diffusion louis-san strategies. compagnoni The ekland collaborative ibarrola inference step generates the kimo dual variables that trooops are 10-10 used m\u00e9d\u00e9e by chobanian the roache agents to update dishforth their kulturbund dictionaries 2002is without the 9.96 need to share these dictionaries or even arispe the sackett coefficient qanbar models for the training data. This parklife is a powerful property that rosewall leads nitschke to deng a neuroanatomical remarkably efficient recedes distributed ulrike procedure 6650 for learning dictionaries vantu over bersham large networks.", "histories": [["v1", "Thu, 6 Feb 2014 22:19:19 GMT  (2771kb,D)", "https://arxiv.org/abs/1402.1515v1", "16 pages, 7 figures. Submitted for publication"], ["v2", "Sun, 7 Dec 2014 05:40:44 GMT  (752kb,D)", "http://arxiv.org/abs/1402.1515v2", "16 pages, 8 figures. To appear in IEEE Transactions on Signal Processing"]], "COMMENTS": "16 pages, 7 figures. Submitted for publication", "reviews": [], "SUBJECTS": "cs.LG cs.DC", "authors": ["jianshu chen", "zaid j towfic", "ali h sayed"], "accepted": false, "id": "1402.1515"}, "pdf": {"name": "1402.1515.pdf", "metadata": {"source": "CRF", "title": "Dictionary Learning over Distributed Models", "authors": ["Jianshu Chen"], "emails": ["pubs-permissions@ieee.org.", "cjs09@ucla.edu.", "ztowfic@ucla.edu."], "sections": [{"heading": null, "text": "Index Terms\u2014Dictionary learning, distributed model, diffusion strategies, dual decomposition, conjugate functions, image denoising, novel document detection, topic modeling, bi-clustering.\nI. INTRODUCTION AND RELATED WORK Dictionary learning is a useful procedure by which dependencies among input features can be represented in terms of suitable bases [2]\u2013[11]. It has found applications in many machine learning and inference tasks including image denoising [5], [6], dimensionality-reduction [7], [8], bi-clustering [9], feature-extraction and classification [10], and novel document detection [11]. Dictionary learning usually alternates between two steps: (i) an inference (sparse coding) step and (ii) a dictionary update step. The first step finds a sparse representation for the input data using the existing dictionary by solving, for example, a regularized regression problem, while the second step usually employs a gradient descent iteration to update the dictionary entries.\nWith the increasing complexity of various learning tasks, it is not uncommon for the size of the learning dictionaries to be demanding in terms of memory and computing requirements. It is therefore important to study scenarios where the dictionary is not necessarily available in a single central location but its components are possibly spread out over multiple locations.\nCopyright (c) 2014 IEEE. Personal use of this material is permitted. However, permission to use this material for any other purposes must be obtained from the IEEE by sending a request to pubs-permissions@ieee.org.\nThis work was supported in part by NSF grants CCF-1011918 and ECCS1407712. A short and preliminary version of this work appears in the conference publication [1].\nJ. Chen is with Microsoft Research, Redmond, WA, 98052. Email: cjs09@ucla.edu.\nZaid J. Towfic is with MIT Lincoln Laboratory, Lexington, MA. Email: ztowfic@ucla.edu.\nA. H. Sayed is with the Department of Electrical Engineering, University of California, Los Angeles, CA 90095. Email: sayed@ee.ucla.edu. This work was completed while J. Chen and Z. J. Towfic were PhD students at UCLA.\nThis is particularly true in Big Data scenarios where large dictionary components may already be available at separate locations and it is not feasible to aggregate all dictionaries in one location due to communication and privacy considerations. This observation motivates us to examine how to learn a dictionary model that is stored over a network of agents, where each agent is in charge of only a portion of the dictionary elements. Compared with other works, the problem we solve in this article is how to learn a distributed dictionary model, which is, for example, different from the useful work in [12] where it is assumed instead that each agent maintains the entire dictionary model.\nIn this paper, we first formulate a general dictionary learning problem, where the residual error function and the regularization function can assume different forms in different applications. As we shall explain, this form turns out not to be directly amenable to distributed implementations. However, when the regularization is strongly convex, we will show that the problem has a dual function that can be solved in a distributed manner using diffusion strategies [13]\u2013[16]. In this solution, the agents will not need to share their (private) dictionary elements but only the dual variable. Useful consensus strategies [17]\u2013[20] can also be used for the same purpose. However, since it has been shown that diffusion strategies have enhanced stability and learning abilities over consensus strategies [21]\u2013[23], we will continue our presentation by focusing on diffusion strategies.\nWe will test our proposed algorithm on two important applications of dictionary learning: (i) novel document detection [11], [24], [25], and (ii) bi-clustering on microarray data [9]. A third application related to image denoising is considered in [1]. In the novel document detection problem [11], [24], [25], each learner receives documents associated with certain topics, and wishes to determine if an incoming document is associated with a topic that has already been observed in previous data. This application is useful, for example, in finance when a company wishes to mine news streams for factors that may impact stock prices. Another example is the mining of social media streams for topics that may be unfavorable to a company. In these applications, our algorithm is able to perform distributed non-negative matrix factorization tasks, with the residual metric chosen as the Huber loss function [26], and is able to achieve a high area under the receiver operating characteristic (ROC) curve. In the bi-clustering experiment, our algorithm is used to learn relations between genes and types of cancer. From the learned dictionary, the patients are subsequently clustered into groups corresponding to different manifestations of cancer. We show that our algorithm can obtain similar clustering results to those in [9], which relies instead on a batched (centralized) implementation.\nThe paper is organized as follows. In Section II, we intro-\nar X\niv :1\n40 2.\n15 15\nv2 [\ncs .L\nG ]\n7 D\nec 2\n01 4\n2\nduce the dictionary learning problem over distributed models. In Section III, using the concepts of conjugate function and dual decomposition, we transform the original dictionary learning problem into a form that is amenable to distributed optimization. In Section IV, we test our proposed algorithm on two applications. In Section V we conclude the exposition."}, {"heading": "II. PROBLEM FORMULATION", "text": ""}, {"heading": "A. General Dictionary Learning Problem", "text": "We seek to solve the following general form of a global dictionary learning problem over a network of N agents connected by a topology:\nmin W\nE [ f(xt \u2212Wyot ) + hy(yot ) ] + hW (W ) (1)\ns.t. W \u2208 W (2) where E[\u00b7] denotes the expectation operator, xt is the M \u00d7 1 input data vector at time t (we use boldface letters to represent random quantities), yot is a K\u00d71 coding vector defined further ahead as the solution to (7), and W is an M \u00d7K dictionary matrix. Moreover, the q-th column of W , denoted by [W ]:,q , is called the q-th dictionary element (or atom), f(u) in (1) denotes a differentiable convex loss function for the residual error, hy(y) and hW (W ) are convex (but not necessarily differentiable) regularization terms on y and W , respectively, andW denotes the convex constraint set on W . Depending on the application problem of interest, there are different choices for f(u), hy(y), hW (W ) and W . Table I lists some typical tasks and the corresponding choices for these functions. In regular dictionary learning [6], the constraint set W is\nW = {W : \u2016[W ]:,q\u20162 \u2264 1, \u2200q} (3) and in applications of nonnegative matrix factorization [6] and novel document detection (topic modeling) [11], it is\nW = {W : \u2016[W ]:,q\u20162 \u2264 1, W 0, \u2200q} (4) where the notation W 0 means each entry of the matrix W is nonnegative. We note that if there is a constraint on y, it can\nbe absorbed into the regularization factor hy(y), by including an indicator function of the constraint into this regularization term. For example, if y is required to satisfy y \u2208 Y = {y : 0 y 1}, where 1 denotes the all-one vector, we can modify the original regularization hy(y) by adding an additional indicator function:\nhy(y)\u2190 hy(y) + IY(y) (5) where the indicator function IY(y) for Y is defined as\nIY(y) , { 0, if 0 y 1 +\u221e, otherwise (6)\nThe vector yot in (1) is the solution to the following general inference problem for each input data sample xt at time t for a given W (the regular font for xt and yot denotes realizations for the random quantities xt and yot ):\nyot , arg min y [f(xt \u2212Wy) + hy(y)] (7)\nNote that dictionary learning consists of two steps: the inference step (sparse coding) for xt at each time t in (7), and the dictionary update step (learning) in (1)\u2013(2)."}, {"heading": "B. Dictionary Learning over Networked Agents", "text": "Let the matrix W and the vector y be partitioned in the following block forms:\nW = [ W1 \u00b7 \u00b7 \u00b7 WN ] , y = col{y1, . . . , yN} (8)\nwhere Wk is an M \u00d7Nk sub-dictionary matrix and yk is an Nk\u00d7 1 sub-vector. Note that the sizes of the sub-dictionaries add up to the total size of the dictionary, K, i.e.,\nN1 + \u00b7 \u00b7 \u00b7+NN = K (9) Furthermore, we assume the regularization terms hy(y) and hW (W ) admit the following decompositions:\nhy(y) = N\u2211 k=1 hyk(yk), hW (W ) = N\u2211 k=1 hWk(Wk) (10)\n3 W1\nW2 W3\nW4\nW5\nW6\nWk\nNk\nNI\nyo1,t\nyo2,t\nyo3,t\nyo4,t\nyo5,t\nyo6,t\nyok,t\n{xt}\nFig. 1. The data sample xt at time t is available to a subset NI of agents in the network (e.g., agents 3 and 6 in the figure), and each agent k is in charge of one sub-dictionary, Wk , and the corresponding optimal sub-vector of coefficients estimated at time t, yok,t. Each agent k can only exchange information with its immediate neighbors (e.g., agents 5, 2 and 6 in the figure and k itself). We use Nk to denote the set of neighbors of agent k.\nThen, the objective function of the inference step (7) can be written as\nQ(W, y;xt) , f ( xt \u2212 N\u2211 k=1 Wkyk ) + N\u2211 k=1 hyk(yk) (11)\nWe observe from (11) that the sub-dictionary matrices {Wk} are linearly combined to represent the input data xt. By minimizing Q(W, y;xt) over y, the first term in (11) helps ensure that the representation error for xt is small. The second term in (11), which usually involves a combination of `1 and `2 measures, as indicated in Table I, helps ensure that each of the resulting combination coefficients {yk} is sparse and small. We will make the following assumption regarding hyk(yk) throughout the paper\nAssumption 1 (Strongly convex regularization). The regularization terms hyk(yk) are assumed to be strongly convex for k = 1, . . . , N .\nThis assumption will allow us to develop a fully distributed strategy that enables the sub-dictionaries {Wk} and the corresponding coefficients {yk} to be stored and learned in a distributed manner over the network; each agent k will infer its own yk and update its own sub-dictionary Wk with limited interaction with its neighboring agents. Requiring {hyk(yk)} to be strongly convex is not restrictive since we can always add a small `2 regularization term to make it strongly convex. For example, in Table I, we add an `2 term to `1 regularization so that the resulting hyk(yk) ends up amounting to elastic net regularization, in the manner advanced in [7].\nFigure 1 shows the assumed configuration of the knowledge and data distribution over the network. The sub-dictionaries {Wk} can be interpreted as the \u201cwisdom\u201d that is distributed over the network, and which we wish to combine in a distributed manner to form a greater \u201cintelligence\u201d for interpreting the data xt. Observe that we are allowing xt to be observed by only a subset, NI , of the agents. By having the dictionary distributed over the agents, we would then like to develop a procedure that enables these networked agents to\n\u22122 0 2 0\n1\n2\n3\n4\n5\nF u\nn c ti\no n\nV a lu\ne\nQu adrati c Loss\nu \u22122 0 2\n0\n1\n2\n3\n4\n5\nu\nF u\nn c ti\no n\nV a lu\ne\n\u21131 Loss\n\u22122 0 2 0\n1\n2\n3\n4\n5\nu\nF u\nn c ti\no n\nV a lu\ne\nH uber Loss (\u03b7 = 1)\n\u22122 0 2 0\n1\n2\n3\n4\n5\ny\nF u\nn c ti\no n\nV a lu\ne\nE l as ti c N et (\u03b3 = 1, \u03b4 = 1)\n1 2 u2 |u|\nL(u) \u03b3 |y | + \u03b4 2 y2\nFig. 2. Illustration of the loss functions, and the elastic net regularization.\nfind the global solutions to both the inference problem (7) and the learning problem (1)\u2013(2) with interactions that are limited to their neighborhoods."}, {"heading": "C. Relation to Prior Work", "text": "1) Model Distributed vs. Data Distributed: The problem we are solving in this paper is different from the useful work [12], [27] on distributed dictionary learning and from the traditional distributed learning setting [13], [14], [16], [28], where it is assumed that the entire dictionary W is maintained by each agent or that individual data samples generated by the same distribution, denoted by xk,t, are observed by the agents at each time t. That is, these previous works study data distributed formulations. What we are studying in this paper is to find a distributed solution where each agent is only in charge of a portion of the dictionary (Wk for each agent k) and where the incoming data, xt, is observed by only a subset of the agents. This scenario corresponds to a model distributed (or dictionary-distributed) formulation. A different formulation is also considered in [29] in the context of distributed deep neural network (DNN) models over computer networks. In these models, each computer is in charge of a portion of neurons in the DNN, and the computing nodes exchange their private activation signals. As we will see further ahead, our distributed model requires exchanging neither the private combination coefficients {yk} nor the sub-dictionaries {Wk}.\nThe distributed-model setting we are studying is important in practice because agents tend to be limited in their memory and computing power and they may not be able to store large dictionaries locally. Even if the agents were powerful enough, different agents may still have access to different databases and different sources of information. Rather than aggregate the information in the form of large dictionaries at every single location, it is often more advantageous to keep the\n4 information distributed due to costs in exchanging large dataset and dictionary models, and also due to privacy considerations where agents may not be in favor of sharing their private information.\n2) Distributed Basis Pursuit: Other useful related works appear in the studies [30]\u2013[32] on distributed basis pursuit, which also rely on dual decomposition arguments. However, there are some key differences in problem formulation, generality, and technique, as explained in [33]. For example, the works [30]\u2013[32] do not deal with dictionary learning problems and focus instead on the solution of special cases of the inference problem (7). Specifically, the problem formulations in [30]\u2013[32] focus on determining sparse solutions to (underdetermined) linear systems of equations, which can be interpreted as corresponding to scenarios where the dictionaries are static and not learned from data. In comparison, in this article, we show how the inference and learning problems (7) and (1)\u2013(2) can be jointly integrated into a common framework. Furthermore, our proposed distributed dictionary learning strategy is an online algorithm, which updates the dictionaries sequentially in response to streaming data. We also only require the data sample xt to be available to a subset of the agents (e.g., one agent) while it is assumed in [30]\u2013[32] that all agents have access to the same data xt.\nFor instance, one of the problems studied in [30] is the following inference problem (compare with (7)):\nyot , arg min y N\u2211 k=1 [ \u03b3\u2016yk\u20161 + \u03b4 2 \u2016yk\u201622 ] (12a)\ns.t. N\u2211 k=1 Wkyk = xt (12b)\nThis formulation can be recast as a special case of (7) by selecting:\nhyk(yk) = \u03b3\u2016yk\u20161 + \u03b4\n2 \u2016yk\u201622 (13a)\nf(xt \u2212Wy) = IB ( xt \u2212 N\u2211 k=1 Wkyk ) (13b)\nwhere IB(\u00b7) is the indicator function defined by:\nIB(u) = { 0, u \u2208 B \u221e, u /\u2208 B (14)\nwhere B , {0M} is a set consisting of the zero vector in RM . Equality constraints of the form (12b), or a residual function of the form (13b), are generally problematic for problems that require both learning and inference since modeling and measurement errors usually seep into the data and the {Wk} may not be able to represent the xt accurately with a precise equality as in (12b). To handle the modeling error, the work [31] considered instead:\nyot , arg min y N\u2211 k=1 [ \u03b3\u2016yk\u20161 + \u03b4 2 \u2016yk\u201622 ] (15a)\ns.t. \u2225\u2225\u2225 N\u2211 k=1 Wkyk \u2212 xt \u2225\u2225\u2225 2 \u2264 \u03c3 (15b)\nfor some \u03c3 \u2265 0, which again can be viewed as a special case of problem (7) for the same hyk(\u00b7) from (13a) and with the indicator function in (13b) replaced by IC(u) relative to the set\nC , { u \u2208 RM\u00d71 : \u2016u\u20162 \u2264 \u03c3 } (16)\nAn alternative problem formulation that removes the indicator functions is considered in [31], [34], namely,\nyot , arg min y\n[ 1\n2 \u2016xt \u2212Wy\u20162 + \u03b3\u2016y\u20161\n] (17)\nHere, we now have hy(y) = \u03b3\u2016y\u20161 and f(u) = 12\u2016u\u20162. However, for problem (17), the dictionary elements as well as the entries of xt, were partitioned in [31], [34] by rows across the network as opposed to our column-wise partitioning in (8):\nW = [UT1 , . . . , U T N ] T (18)\nIn this case, it is straightforward to rewrite problem (17) in the form\nyot , arg min y N\u2211 k=1 [ 1 2 \u2016xk,t \u2212 Uky\u20162 + \u03b3 N \u2016y\u20161 ] (19)\nwhich is naturally in a \u201csum-of-costs\u201d form; such forms are directly amenable to distributed optimization and do not require transformations \u2014 see (20) further ahead. However, the more challenging problem where the matrix W is partitioned column-wise as in (8), which leads to the \u201ccost-of-sum\u201d form showed earlier in (11), was not examined in [31], [34].\nIn summary, we will solve the more challenging problem of joint inference and dictionary learning (instead of inference alone under static dictionaries) under the column-wise partitioning of W (rather than row-wise partitioning) and general penalty functions f(\u00b7) and {hyk(\u00b7)} (instead of the special indicator choices in (14) and (16))."}, {"heading": "III. LEARNING OVER DISTRIBUTED MODELS", "text": ""}, {"heading": "A. \u201cCost-of-Sum\u201d vs. \u201cSum-of-Costs\u201d", "text": "We thus start by observing that the cost function (11) is a regularized \u201ccost-of-sum\u201d; it consists of two terms: the first term has a sum of quantities associated with different agents appearing as an argument for the function f(\u00b7) and the second term is a collection of separable regularization terms {hyk(yk)}. This formulation is different from the classical \u201csum-of-costs\u201d problem, which usually seeks to minimize a global cost function, Jglob(w), that is expressed as the aggregate sum of individual costs {Jk(w)}, say, as:\nJglob(w) = N\u2211 k=1 Jk(w) (20)\nThe \u201csum-of-costs\u201d problem (20) is amenable to distributed implementations [13]\u2013[21]. In comparison, minimizing the regularized \u201ccost-of-sum\u201d problem in (11) directly would require knowledge of all sub-dictionaries {Wk} and coefficients {yk}. Therefore, this formulation is not directly amenable to the distributed techniques from [13]\u2013[21]. In [35], the authors proposed a useful consensus-based primal-dual perturbation\n5 method to solve a similar constrained \u201ccost-of-sum\u201d problem for smart grid control. In their method, an averaging consensus step was used to compute the sum inside the cost. We follow a different route and arrive at a more efficient distributed strategy by transforming the original optimization problem into a dual problem that has the same form as (20) \u2014 see (30a)\u2013(30b) further ahead, and which can then be solved efficiently by means of diffusion strategies. There will be no need to exchange any information among the agents beyond the dual variable, or to employ a separate consensus step to evaluate the sum inside the cost in order to update their own sub-dictionaries.\nB. Inference over Distributed Models: A Dual Formulation To begin with, we first transform the minimization of (11) into the following equivalent optimization problem by introducing a splitting variable z:\nmin {yk},z f(xt \u2212 z) + N\u2211 k=1 hyk(yk) (21a)\ns.t. z = N\u2211 k=1 Wkyk (21b)\nNote that the above problem is convex over both {yk} and z since the objective is convex and the equality constraint is linear. Problem (21a)\u2013(21b) is a convex optimization problem with linear constraints so that strong duality holds [36, p.514], meaning that the optimal solution to (21a)\u2013(21b) can be found by solving its corresponding dual problem (see (22) below) and then recovering the optimal primal variables {yk} and z (to be discussed in Sec. III-E):\nmax \u03bd g(\u03bd;xt) (22)\nwhere g(\u03bd;xt) is the dual function associated with the optimization problem (21a)\u2013(21b), and is defined as follows. First, the Lagrangian L({yk}, z, \u03bd;xt) over the primal variables {yk} and z is given by\nL({yk}, z, \u03bd;xt)\n= f(xt \u2212 z) + \u03bdT z + N\u2211 k=1 [ hyk(yk)\u2212 \u03bdTWkyk ] (23)\nThen, the dual function g(\u03bd;xt) can be expressed as:\ng(\u03bd;xt)\n, inf {yk},z\nL({yk}, z, \u03bd;xt)\n= inf z\n[ f(xt\u2212z)+\u03bdT z ] + N\u2211 k=1 inf yk [ hyk(yk)\u2212\u03bdTWkyk ] (24)\n(a) = inf\nu\n[ f(u)\u2212\u03bdTu+\u03bdTxt ] + N\u2211 k=1 inf yk [ hyk(yk)\u2212\u03bdTWkyk ] = \u2212sup\nu\n[ \u03bdTu\u2212f(u) ] +\u03bdTxt\u2212 N\u2211 k=1 sup yk [ \u03bdTWkyk\u2212hyk(yk) ] = \u2212f?(\u03bd) + \u03bdTxt \u2212\nN\u2211 k=1 h?yk(W T k \u03bd) (25)\n\u03bd \u2208 Vf \u2229 Vhy1 \u2229 \u00b7 \u00b7 \u00b7 \u2229 VhyN where in step (a) we introduced u , xt \u2212 z, and f?(\u00b7) and h?yk(\u00b7) are the conjugate functions of f(\u00b7) and hyk(\u00b7), respectively, with the corresponding domains denoted by Vf and Vhyk , respectively. We note that the conjugate function (or Legendre-Fenchel transform [37, p.37]), r?(\u03bd), for a function r(x) is defined as [38, pp.90-95]:\nr?(\u03bd) , sup x\n[ \u03bdTx\u2212 r(x) ] , \u03bd \u2208 Vr (26)\nwhere the domain Vr is defined as the set of \u03bd where the above supremum is finite. The conjugate function r?(\u03bd) and its domain Vr are convex regardless of whether r(x) is convex or not [36, p.530] [38, p.91]. In particular, it holds that Vr = RM if r(x) is strongly convex [37, p.82]. Now since hyk(\u00b7) is assumed in Assumption 1 to be strongly convex, its domain Vhyk is the entire R\nM . If f(u) happens to be strongly convex (rather than only convex, e.g., if f(u) = 12\u2016u\u201622), then Vf would also be RM , otherwise it is a convex subset of RM . Therefore, the dual function in (25) becomes\ng(\u03bd;xt) = \u2212f?(\u03bd) + \u03bdTxt \u2212 N\u2211 k=1 h?yk(W T k \u03bd), \u03bd \u2208 Vf (27)\nNow, maximizing g(\u03bd;xt) is equivalent to minimizing \u2212g(\u03bd;xt) so that the dual problem (22) is equivalent to\nmin \u03bd \u2212 g(\u03bd;xt) = f?(\u03bd)\u2212 \u03bdTxt + N\u2211 k=1 h?yk(W T k \u03bd) (28a)\ns.t. \u03bd \u2208 Vf (28b) Note that the objective function in the above optimization problem is an aggregation of (i) individual costs associated with sub-dictionaries at different agents (last term in (28a)), (ii) a term associated with the data sample xt (second term in (28a)), and (iii) a term that is the conjugate function of the residual cost (first term in (28a)). In contrast to (11), the cost function in (28a) is now in a form that is amenable to distributed processing. In particular, diffusion strategies [14], [21], [39], consensus strategies [17]\u2013[20], or ADMM strategies [30], [31], [33], [40]\u2013[42] can now be applied to obtain the optimal dual variable \u03bdot in a distributed manner at the various agents.\nTo arrive at the distributed solution, we proceed as follows. We denote the set of agents that observe the data sample xt by NI . Motivated by (28a), with each agent k, we associate the local cost function:\nJk(\u03bd;xt) ,\n{ \u2212\u03bdT xt|NI | + 1 N f ?(\u03bd)+h?yk(W T k \u03bd), k \u2208 NI\n1 N f ?(\u03bd)+h?yk(W T k \u03bd), k /\u2208 NI\n(29)\nwhere |NI | denotes the cardinality of NI . Then, the optimization problem (28a)\u2013(28b) can be rewritten as\nmin \u03bd N\u2211 k=1 Jk(\u03bd;xt) (30a)\ns.t. \u03bd \u2208 Vf (30b) In Sections III-C and III-D, we will first discuss the solution of (30a)\u2013(30b) for the optimal dual variable, \u03bdot , in a distributed\n6 manner. And then in Sec. III-E, we will reveal how to recover the optimal primal variables yok,t and z o t from \u03bd o t .\nC. Inference over Distributed Models: Diffusion Strategies\nNote that the new equivalent form (30a) is an aggregation of individual costs associated with different agents; each cost Jk(\u03bd;xt) only requires knowledge of Wk. Consider first the case in which f(u) is strongly convex. Then, it holds that Vf = RM and problem (30a)\u2013(30b) becomes an unconstrained optimization problem of the same general form as problems studied in [15], [16]. Therefore, we can directly apply the diffusion strategies developed in these works to solve (30a)\u2013 (30b) in a fully distributed manner. The adapt-then-combine (ATC) implementation of the diffusion algorithm then takes the following form:\n\u03c8k,i = \u03bdk,i\u22121 \u2212 \u00b5 \u00b7 \u2207\u03bdJk(\u03bdk,i\u22121;xt) (31a) \u03bdk,i = \u2211 `\u2208Nk a`k\u03c8`,i (31b)\nwhere \u03bdk,i denotes the estimate of the optimal \u03bdot at agent k at iteration i (we will use i to denote the i-th iteration of the inference, and use t to denote the t-th data sample), \u03c8k,i is an intermediate variable, Nk denotes the neighborhood of agent k, \u00b5 is the step-size parameter chosen to be a small positive number, and a`k is the combination coefficient that agent k assigns to the information received from agent ` and it satisfies\u2211 `\u2208Nk a`k = 1, a`k > 0 if ` \u2208 Nk, a`k = 0 if ` /\u2208 Nk (32)\nLet A denote the N\u00d7N matrix that collects a`k as its (`, k)-th entry. Then, it is shown in [16] that as long as the matrix A is doubly-stochastic (i.e., satisfies A1 = AT1 = 1) and \u00b5 is selected such that\n0 < \u00b5 < min 1\u2264k\u2264N\n1\n\u03c3k (33)\nwhere \u03c3k is the Lipschitz constant1 of the gradient of Jk(\u03bd;xt):\n\u2016\u2207\u03bdJk(\u03bd1;xt)\u2212\u2207\u03bdJk(\u03bd2;xt)\u2016 \u2264 \u03c3k \u00b7 \u2016\u03bd1 \u2212 \u03bd2\u2016 (34) then algorithm (31a)\u2013(31b) converges to a fixed point that is O(\u00b52) away from the optimal solution of (30a) in squared Euclidean distance. We remark that a doubly-stochastic matrix is one that satisfies A1 = AT1 = 1.\nConsider now the case in which the constraint set Vf is not equal to RM but is still known to all agents. This is a reasonable requirement. In general, we need to solve the supremum in (26) with r(x) = f(x) to derive the expression for f?(\u03bd) and determine the set Vf that makes the supremum in (26) finite. Fortunately, this step can be pursued in closedform for many typical choices of f(u). We list in Table II the results that will be used in Sec. IV; part of these results are derived in Appendix A and the rest is from [38, pp.90-95].\n1 If Jk(\u03bd;xt) is twice-differentiable, then the Lipschitz gradient condition (34) is equivalent to requiring an upper bound on the Hessian of Jk(\u03bd;xt), i.e., 0 \u2264 \u22072\u03bdJk(\u03bd;xt) \u2264 \u03c3kIM .\nUsually, Vf for these typical choices of f(u) are simple sets whose projection operators2 can be found in closed-form \u2014 see also [43]. For example, the projection operator onto the set\nVf = {\u03bd : \u2016\u03bd\u2016\u221e \u2264 1} = {\u03bd : \u22121 \u03bd 1} (35) that is listed in the third row of Table II is given by\n[\u03a0Vf (\u03bd)]m =  1 if \u03bdm > 1\n\u03bdm if \u2212 1 \u2264 \u03bdm \u2264 1 \u22121 if \u03bdm < \u22121\n(36)\nwhere [x]m denotes the m-th entry of the vector x and \u03bdm denotes the m-th entry of the vector \u03bd. Once the constraint set Vf is found, it can be enforced either by incorporating local projections onto Vf into the combination step (31b) at each agent [44] or by using the penalized diffusion method [45]. For example, the projection-based strategy replaces (31a)\u2013(31b) by:\n\u03c8k,i = \u03bdk,i\u22121 \u2212 \u00b5 \u00b7 \u2207\u03bdJk(\u03bdk,i\u22121;xt) (37a)\n\u03bdk,i = \u03a0Vf [\u2211 `\u2208Nk a`k\u03c8`,i ] (37b)\nwhere \u03a0Vf [\u00b7] is the projection operator onto Vf .\nD. Inference over Distributed Models: ADMM Strategies\nAn alternative approach to solving the dual inference problem (30a)\u2013(30b) is the distributed alternating direction multiplier method (ADMM) [30], [31], [40], [41], [46]. Depending on the configuration of the network, there are different variations of distributed ADMM strategies. For example, the method proposed in [40] relies on a set of bridge nodes for the distributed interactions among agents, and the method in [30], [31] uses a graph coloring approach to partition the agents in the network into different groups, and lets the optimization process alternate between different groups with one group of agents engaged at a time. In [41] and [46], the authors developed ADMM strategies that adopt Jacobian style updates with all agents engaged in the computation concurrently. Below, we describe the Jacobian-ADMM strategies from [46, p.356] and briefly compare them with the diffusion strategies.\nThe Jacobian-ADMM strategy solves (30a)\u2013(30b) by first transforming it into the following equivalent optimization problem:\nmin \u03bd N\u2211 k=1 [ Jk(\u03bdk;xt) + IVf (\u03bdk) ] (38a)\ns.t. \u03bdk = \u03bd`, ` \u2208 Nk\\{k}, k = 1, . . . , N (38b) where the cost function is decoupled among different {\u03bdk} and the constraints are coupled through neighborhoods. Then, the following recursion is used to solve (38a)\u2013(38b):\n\u03bdk,i = arg min \u03bdk N\u2211 k=1 {[ Jk(\u03bdk;xt) + IVf (\u03bdk) ] 2The projection operator onto the set Vf is defined as \u03a0Vf (\u03bd) ,\narg min x\u2208Vf\n\u2016x\u2212 \u03bd\u20162.\n7\nTABLE II CONJUGATE FUNCTIONS USED IN THIS PAPER FOR DIFFERENT TASKS\nTasks f(u) f?(\u03bd) Vf zot hyk (yk) h?yk (W T k \u03bd) Vhyk y o k,t\nSparse SVD 1 2 \u2016u\u201622\n1 2 \u2016\u03bd\u201622 RM xt \u2212 \u03bdot \u03b3\u2016yk\u20161 + \u03b4 2 \u2016yk\u201622 S \u03b3\u03b4\n( WTk \u03bd\n\u03b4\n) b RM T \u03b3\n\u03b4\n( WTk \u03bd o t\n\u03b4\n) a\nBi-Clustering 1 2 \u2016u\u201622\n1 2 \u2016\u03bd\u201622 RM xt \u2212 \u03bdot \u03b3\u2016yk\u20161 + \u03b4 2 \u2016yk\u201622 S \u03b3\u03b4\n( WTk \u03bd\n\u03b4\n) RM T \u03b3\n\u03b4\n( WTk \u03bd o t\n\u03b4 ) Nonnegative Matrix 1\n2 \u2016u\u201622\n1 2 \u2016\u03bd\u201622 RM xt \u2212 \u03bdot \u03b3\u2016yk\u20161,+ + \u03b4 2 \u2016yk\u201622 S + \u03b3 \u03b4\n( WTk \u03bd\n\u03b4\n) d RM T +\u03b3\n\u03b4\n( WTk \u03bd o t\n\u03b4\n) c\nFactorization M\u2211 m=1 L(um) \u03b7 2 \u2016\u03bd\u201622 {\u03bd : \u2016\u03bd\u2016\u221e \u2264 1} \u03b3\u2016yk\u20161,+ + \u03b4 2 \u2016yk\u201622 S + \u03b3 \u03b4 ( WTk \u03bd \u03b4 ) RM T +\u03b3 \u03b4 ( WTk \u03bd o t \u03b4 ) a T\u03bb(x) denotes the entry-wise soft-thresholding operator on the vector x: [T\u03bb(x)]n , (|[x]n| \u2212 \u03bb)+sgn([x]n), where (x)+ = max(x, 0). b S \u03b3\n\u03b4 (x) is the function defined by S \u03b3 \u03b4 (x) , \u2212 \u03b4 2 \u00b7 \u2225\u2225T \u03b3 \u03b4 (x) \u2225\u22252 2 \u2212 \u03b3 \u00b7 \u2225\u2225T \u03b3 \u03b4 (x) \u2225\u2225 1 + \u03b4 \u00b7 xT T \u03b3 \u03b4\n(x) for x \u2208 RM . c T +\u03bb (x) denotes the entry-wise one-side soft-thresholding operator on the vector x: [T + \u03bb (x)]n , ([x]n \u2212 \u03bb)+. d S+\u03b3 \u03b4 (x) is defined by S+\u03b3 \u03b4 (x) , \u2212 \u03b4 2 \u00b7 \u2225\u2225T +\u03b3 \u03b4 (x) \u2225\u22252 2 \u2212 \u03b3 \u00b7 \u2225\u2225T +\u03b3 \u03b4 (x) \u2225\u2225 1 + \u03b4 \u00b7 xT T +\u03b3 \u03b4 (x) for x \u2208 RM . e The functions T\u03bb(x), T +\u03bb (x), S \u03b3\u03b4 (x), and S + \u03b3 \u03b4 (x) for the case of a scalar argument x are illustrated in Fig. 3.\n+ N\u2211 `=1 bk` [ \u03bbTk`,i\u22121(\u03bd`,i\u22121\u2212\u03bdk)+\u2016\u03bd`,i\u22121\u2212\u03bdk\u201622 ]} (39a)\n\u03bbk`,i=\u03bbk`,i\u22121 + \u00b5 bk` \u00b7 (\u03bdk,i \u2212 \u03bd`,i) (39b)\nwhere bk` is the (k, `)-th entry of the adjacency matrix B = [bk`] of the network, which is defined as:\nbk` = 1 if ` \u2208 Nk\\{k}, bk` = 0 otherwise (40)\nFrom recursion (39a)\u2013(39b), we observe that ADMM requires solving a separate optimization problem (arg min) for each ADMM step. This optimization problem generally requires an iterative algorithm to solve when it cannot be solved in closed-form, which adds a third time scale to the algorithm, as explained in [33] in the context of dictionary learning. This situation is illustrated in Fig. 4. The need for a third time-scale usually translates into requiring faster processing at the agents\nTime Scales\nADMM solution involves three time-scales:\nbetween data arrivals, which can be a hindrance for adaptation in real-time."}, {"heading": "E. Recovery of the Primal Variables", "text": "Returning to the diffusion solution (31a)\u2013(31b) or (37a)\u2013 (37a), once the optimal dual variable \u03bdot has been estimated by the various agents, the optimal primal variables yok,t and z o t can now be recovered uniquely if f(u) and {hyk(yk)} are strongly convex. In this case, the infimums in (24) can be attained and become minima. As a result, optimal primal variables can be recovered via\nzot = arg min z\n{ f(xt \u2212 z) + (\u03bdot )T z } (a) = xt \u2212 arg max\nu\n[ (\u03bdot ) Tu\u2212 f(u) ]\n(41)\nyok,t = arg min yk\n{ hyk(yk)\u2212(\u03bdot )TWkyk }\n8 = arg max yk [ (WTk \u03bd o t ) T yk \u2212 hyk(yk) ] (42)\nwhere step (a) performs the variable substitution u = xt \u2212 z. By (41)\u2013(42), we obtain the optimal solutions of (21a)\u2013 (21b) (and also of the original inference problem (7)) after first solving the dual problem (22). For many typical choices of f(\u00b7) and hyk(\u00b7), the solutions of (41)\u2013(42) can be expressed in closed form in terms of \u03bdot . In Table II, we list the results that will be used later in Sec. IV with the derivation given in Appendix A.\nThe strong convexity of f(u) and {hyk(yk)} is needed if we want to uniquely recover zot and {yok,t} from the dual problem (22). As we will show further ahead in (56), the quantities {yok,t} are always needed in the dictionary update. For this reason, we assumed in Assumption 1 that the {hyk(yk)} are strongly convex, which can always be satisfied by means of elastic net regularization as explained earlier. On the other hand, depending on the application, the recovery of zot is not always needed and neither is the strong convexity of f(u) (in these cases, it is sufficient to assume that f(u)) is convex). For example, as explained in [1], the image denoising application requires recovery of zot as the final reconstructed image. On the other hand, the novel document detection application discussed further ahead does not require recovery of zot but the maximum value of the dual function, g(\u03bd;xt), which, by strong duality, is equal to the minimum value of the cost function (21a) and that of (7)."}, {"heading": "F. Choice of Residual and Regularization Functions", "text": "In Tables I\u2013II, we list several typical choices for the residual function, f(u), and the regularization functions, {hyk(yk)}. In general, a careful choice of f(u) and {hyk(yk)} can make the dual cost (28a) better conditioned than in the primal cost (21a). Recall that the primal cost (21a) may not be differentiable due to the choice of hyk(yk) (e.g., the elastic net). However, if f(u) is chosen to be strictly convex with Lipschitz gradients and the {hyk(yk)} are chosen to be strongly convex (not necessarily differentiable), then the conjugate function f?(\u00b7) will be a differentiable strongly convex function with Lipschitz gradient and the {h?yk(\u00b7)} will be differentiable convex functions with Lipschitz gradients [37, pp.79\u201384]. Adding f?(\u00b7) and {h?yk(\u00b7)} together in (28a) essentially transforms a non-differentiable primal cost (21a) into a differentiable strongly convex dual cost (28a) with Lipschitz gradients. As a result, the algorithms that optimize the dual problem (28a)\u2013(28b) can generally enjoy a fast (geometric) convergence rate [16], [22], [47]."}, {"heading": "G. Distributed Dictionary Updates", "text": "Now that we have shown how the inference task (7) can be solved in a distributed manner, we move on to explain how the local sub-dictionaries Wk can be updated through the solution of the stochastic optimization problem (1)\u2013(2), which is rewritten as:\nmin W EQ(W,yot ;xt) + N\u2211 k=1 hWk(Wk) (43a)\ns.t. Wk \u2208 Wk, k = 1, . . . , N (43b)\nwhere the loss function Q(W,yot ;xt) is given in (11), y o t , col{yo1,t, . . . ,yoN,t}, the decomposition for hW (W ) from (10) is used, and we assume the constraint set W can be decomposed into a set of constraints {Wk} on the individual sub-dictionaries Wk; this condition usually holds for typical dictionary learning applications \u2014 see Table I. Problem (43a)\u2013(43b) can also be written as the following unconstrained optimization problem by introducing indicator functions for the sets {Wk}:\nmin W EQ(W,yot ;xt)+ N\u2211 k=1 [ hWk(Wk) + IWk(Wk) ] (44)\nNote that the cost function in (44) consists of two parts, where the first term is differentiable3 with respect to W while the second term, if it exists, is non-differentiable but usually consists of simple components \u2014 see Table I. A typical approach to optimizing cost functions of this type is the proximal gradient method [43], [48]\u2013[50], which applies gradient descent to the first differentiable part followed by a proximal operator to the second non-differentiable part. This method is known to converge faster than applying the subgradient descent method to both parts. However, the proximal gradient methods in [43], [48]\u2013[50] are developed for deterministic optimization, where the exact form of the objective function is known. In constrast, our objective function in (44) assumes a stochastic form and is unknown beforehand because the statistical distribution of the data {xt} is not known. Therefore, our strategy is to apply the proximal gradient method to the cost function in (44) and remove the expectation operator to obtain an instantaneous approximation to the true gradient; this is the approach typically used in adaptation [21], [22], [51] and stochastic approximation [52]:\nWk,t=prox\u00b5w\u00b7(hWk+IWk ) { Wk,t\u22121\u2212\u00b5w\u2207WkQ(Wt\u22121, yot ;xt) } (45)\nRecursion (45) is effective as long as the proximal operator of hWk(Wk) + IWk(Wk) can be solved easily in closedform. When this is not possible but the proximal operators of hWk(\u00b7) and IWk(\u00b7) are simple, it is preferable to apply a stochastic gradient descent step, followed by the proximal operator of hWk(\u00b7), and then the proximal operator of IWk(\u00b7) (equivalent to \u03a0Wk(\u00b7) [43], which is the projection onto Wk) in an incremental manner [53], thus leading to the following recursion:\nWk,t=\u03a0Wk { prox\u00b5w\u00b7hWk ( Wk,t\u22121\u2212\u00b5w\u2207WkQ(Wt\u22121, yot ;xt) )} (46)\nwhere Wt\u22121 , [W1,t\u22121, \u00b7 \u00b7 \u00b7 ,WN,t\u22121], and prox\u00b5w\u00b7hWk (\u00b7) denotes the proximal operator of \u00b5w \u00b7hWk(Wk). The expression for the gradient \u00b5w\u2207WkQ(Wt\u22121, yot ;xt) will be given further ahead in (53)\u2013(56). We recall that the proximal operator of a vector function h(u) is defined as [43, p.6]:\nproxh(x) , arg min u\n( h(u) + 1\n2 \u2016u\u2212 x\u201622\n) (47)\n3Note from (11) that Q(\u00b7) depends on W via f(\u00b7), which is assumed to be differentiable.\n9 Algorithm 1 Model-distributed diffusion strategy for dictionary learning (Main algorithm)\nInitialization: The sub-dictionaries {Wk} are randomly initialized and then projected onto either the constraint (3) or (4), depending on the task in Tab. I. for each input data sample xt do\nCompute \u03bdot by iterating (31a)-(31b) until convergence: \u03bdot \u2248 \u03bdk,i. That is: \u03c8k,i = \u03bdk,i\u22121 \u2212 \u00b5 \u00b7 \u2207\u03bdJk(\u03bdk,i\u22121;xt) \u03bdk,i = \u03a0Vf\n{ \u2211 `\u2208Nk a`k\u03c8`,i }\nwith initialization {\u03bdk,0 = 0, k = 1, . . . , N}. for each agent k do\nCompute coefficient yok,t using Table II or (42):\nyok,t = arg max yk\n[ (WTk \u03bd o t ) T yk \u2212 hyk (yk) ] Adjust dictionary element Wk,t using (56):\nWk,t = \u03a0Wk { prox\u00b5w\u00b7hWk ( Wk,t\u22121 + \u00b5w\u03bd o t (y o k,t) T )} end for\nend for\nFor a matrix function h(U), the proximal operator assumes the same form as (47) except that the Euclidean norm in (47) is replaced by the Frobenius norm. The proximal operator for \u00b5w \u00b7hWk(Wk) = \u00b5w\u03b2 \u00b7|||Wk|||1 used in the bi-clustering task in Table I is the entry-wise soft-thresholding function [43, p.191]:\nprox\u00b5w\u00b7hWk (\u00b7) = prox\u00b5w\u03b2\u00b7|||Wk|||(\u00b7) = T\u00b5w\u00b7\u03b2(\u00b7) (48) and the proximal operator for hWk(Wk) = 0 for other cases in Table I is the identity mapping: prox0(x) = x. With regards to the projection operator used in (46), we provide some examples of interest for the current work. If the constraint set Wk is of the form:\nWk = {Wk : \u2016[Wk]:,q\u20162 \u2264 1} (49) then the projection operator \u03a0Wk(\u00b7) is given by [43], [44]:\n[\u03a0Wk(X)]:,n =\n{ [X]:,n, \u2016[X]:,n\u20162 \u2264 1\n[X]:,n \u2016[X]:,n\u20162 , \u2016[X]:,n\u20162 > 1\n(50)\nOn the other hand, if the constraint set Wk is of the form: Wk = {Wk : \u2016[Wk]:,q\u20162 \u2264 1, W 0} (51)\nthen the projection operator \u03a0Wk(\u00b7) becomes\n[\u03a0Wk(X)]:,n =  ( [X]:,n ) + , \u2016 ( [X]:,n ) + \u20162 \u2264 1( [X]:,n ) +\n\u2016 ( [X]:,n ) + \u20162 , \u2016\n( [X]:,n ) + \u20162 > 1 (52)\nwhere (x)+ = max(x, 0), i.e., it replaces all the negative entries of a vector x with zeros.\nNow, we return to derive the expression for the gradient \u2207WkQ(Wt\u22121, yot ;xt) in (46). By (11), we have\n\u2207WkQ(Wt\u22121, yot ;xt)=\u2212f \u2032u ( xt\u2212 N\u2211 k=1 Wk,t\u22121y o k,t ) (yok,t) T (53)\nwhere f \u2032u(u) denotes the gradient of f(u) with respect to the residual u. On the face of it, expression (53) requires global knowledge by agent k of all sub-dictionaries {Wk} across the network, which goes against the desired objective of arriving at a distributed implementation. However, we can develop a distributed algorithm by exploiting the structure of the problem as follows. Note from (23) that the optimal inference result should satisfy:{\n0 = \u2207zL({yok,t}, zot , \u03bdot ;xt) 0 = \u2207\u03bdL({yok,t}, zot , \u03bdot ;xt) \u21d4  0 = \u2212f \u2032u(xt\u2212zot )+\u03bdot zot =\nN\u2211 k=1 Wk,t\u22121y o k,t\n(54)\nwhich leads to 0 = \u2212f \u2032u ( xt \u2212 N\u2211 k=1 Wk,t\u22121y o k,t ) + \u03bdot\n\u21d4 \u03bdot = f \u2032u ( xt \u2212 N\u2211 k=1 Wk,t\u22121y o k,t ) (55)\nIn other words, we find that the optimal dual variable \u03bdot is equal to the desired gradient vector. Substituting (55) into (53), the dictionary learning update (46) becomes\nWk,t = \u03a0Wk { prox\u00b5w\u00b7hWk ( Wk,t\u22121 + \u00b5w\u03bd o t (y o k,t) T )} (56)\nwhich is now in a fully-distributed form. At each agent k, the above \u03bdot can be replaced by the estimate \u03bdk,i after a sufficient number of inference iterations (large enough i). We note that the dictionary learning update (56) has the following important interpretation. Let\nuot , xt \u2212 N\u2211 k=1 Wk,t\u22121y o k,t (57)\nwhich is the optimal prediction residual error using the entire existing dictionary set {Wk,t\u22121}Nk=1. Observe from (55) that \u03bdot is the gradient of the residual function f(u) at the optimal uot . The update term for dictionary element k in (56) is effectively the correlation between \u03bdot , the gradient of the residual function f(uot ), and the coefficient y o k,t (the activation) at agent k. In the special case of f(u) = 12\u2016u\u201622, expression (55) implies that\n\u03bdot = u o t = xt \u2212 N\u2211 k=1 Wk,t\u22121y o k,t (58)\nIn this case, \u03bdot has the interpretation of being equal to the optimal prediction residual error, uot , using the entire existing dictionary set {Wk,t\u22121}Nk=1. Then, the update term for dictionary element k in (56) becomes the correlation between the optimal prediction error \u03bdot = u o t and the coefficient y o k,t at agent k. Furthermore, recursion (56) reveals that, for each input data sample xt, after the dual variable \u03bdot is obtained at each agent, there is no need to exchange any additional information among agents in order to update their own subdictionaries; the dual variable \u03bdot already provides sufficient information to carry out the update. The fully distributed algorithm for dictionary learning is listed in Algorithm 1 and is also illustrated in Fig. 5.\n10\nIV. IMPORTANT SPECIAL CASES AND EXPERIMENTS\nIn this section, we apply the dictionary learning algorithm to two problems involving novel document/topic detection and bi-clustering. A third application to image denoising is considered in [1], [33].4 In our experiments below, we will use the diffusion strategy (31a)\u2013(31b) or (37a)\u2013(37b) to solve the dual inference problem (28a)\u2013(28b)."}, {"heading": "A. Tuning of the parameters", "text": "In the following experiments, it is necessary to select properly the step-size \u00b5 for the diffusion algorithm (31a)\u2013 (31b) to ensure that the estimate for \u03bdot converges sufficiently close to it after a reasonable number of iterations. Table III lists the step-size conditions that guarantee the convergence of the diffusion algorithm for different applications, which are derived from the general condition (33). Note that as long as the agents know the regularization parameter \u03b4 and the maximum number, Nmax, of dictionary atoms that are allowed at each agent, the agents can select the step-size in a distributed manner.\nFor the convenience of the experiments in this section and only to get an idea about how many iterations are typically needed for the inference step, we choose a data sample x from the training dataset, and use a non-distributed optimization package such as CVX [54] to compute the optimal solution yo , col{yo1, . . . , yoN} and its respective dual variable \u03bdo as the ground truth for the inference problem (21a)\u2013(21b). We plot the signal-to-noise measures \u2016yo\u20162/\u2016yi \u2212 yo\u20162 and \u2016\u03bdo\u20162/\u2016\u03bdk,i \u2212 \u03bdo\u20162 against the iteration number i in Fig. 6. The value \u03bdk,i is obtained from the distributed algorithm (see (31b) or (37b)) at each iteration i and yi , col{y1,i, . . . , yN,i} is calculated at each iteration according to:\nyk,i = arg max yk\n[ (WTk \u03bdk,i) T yk \u2212 hyk(yk) ]\n(59)\n4The software code for the experiments in this manuscript is available online at http://www.ee.ucla.edu/asl\nObserve from Fig. 6 that in order to achieve satisfactory SNR values (e.g., 40-50dB) for both y and \u03bd, the required number of diffusion iterations is about 500. Also note that the primal variable y generally reaches a high SNR value before the dual variable \u03bd, but both are required to be found with reasonable accuracy for the dictionary update step (see (56)). Furthermore, although the number of iterations by diffusion seems to be large for solving the inference problem, the actual wall-clock time it takes is short because of the relatively low complexity per step.\nWe further note that there was no restriction imposed on the size of the network. In our experiments, network consists of N = 196 nodes in the image denoising example [1] and employs from N = 10 to N = 80 nodes in the novel document detection example. In the bi-clustering example, the network size, N , is three because of the application setup and the nature of the data from [9], where the rank of the data matrix is low so that three dictionary atoms are sufficient to represent the data."}, {"heading": "B. Novel Document Detection via Dictionary Learning", "text": "In the novel document detection application [11], [24], [25], a stream of documents arrives in blocks at the network, and the task is to detect which of the documents in the incoming batch are associated with topics that have not been observed previously, and to incorporate the new block of data into the knowledge database to detect new topics/documents in future incoming batches. We refer to each such step as a \u201ctime-step\u201d and we use xst to denote the tth data sample in the sth timestep, where 1 \u2264 t \u2264 Ts with Ts being the number of samples in the sth time-step (Ts = 1000 for all s in this example), and 1 \u2264 s \u2264 8 since our dataset only contains enough data for eight time-steps. We simulate our dictionary learning\n11\nalgorithm using the Huber cost function as the residual metric. We compare our algorithm performance to that proposed in [11] under the same setup proposed there. The data is from the TDT2 dataset, which contains news documents associated with their dominant topics collected over the first 27 weeks of 1998. The data is compiled into a term frequency-inverse document frequency (TF-IDF) matrix X \u2208 RM\u00d7T , where M = 19527 and T = 9394. The documents have been processed so that only the most frequent 30 topics (and documents associated with them) are preserved. In this experiment, we allow all agents in the network to observe the incoming data. The key observation is that if a document belongs to a topic that has been observed previously, then it is expected that the objective value of the optimization problem (21a)\u2013(21b) will be \u201csmall\u201d since the document should be well modeled by the available dictionary. On the other hand, when the objective value is \u201clarge,\u201d then this is an indication that the document is not well modeled by the available dictionary.\nIn this application, we let f(u) = \u2211M m=1 L(um), where L(um) is chosen to be the scalar Huber function defined in Table I. We choose Huber loss for the following reasons. The work [11] points out that some of the coefficients of the representation error u = xt \u2212Wy in text documents contain large, impulsive values. For this reason, the work [11] adopts the `1 loss f(u) = \u2016u\u20161 because this loss grows only linearly for large u and is less sensitive to large outliers. However, `1 loss is not differentiable and has a conjugate function of zero with domain Vf = {\u03bd : \u2016\u03bd\u2016\u221e \u2264 1}. In comparison, the Huber loss, while preserving the linear growth for large u, is smooth and has Lipschitz gradients, which gives a quadratic conjugate function (see Tab. II and Sec. III-F) that naturally regularizes the dual cost (28a) to make it strongly convex. In this way, we end up with a better conditioned optimization problem, which allows first-order methods (e.g., diffusion) to achieve relatively fast convergence and satisfactory performance on the dual inference problem (28a)\u2013(28b). The setup is the same as in [11],5 except that we start with only ten dictionary atoms, and add ten additional atoms after each time-step. We simulate the last line of the non-negative matrix factorization setup in Table I. We compare our algorithm to the one proposed in [11], which simulates the setup where f(u) = \u2016u\u20161, hy(y) = \u2016y\u20161, and Wk = {w : \u2016w\u20161 \u2264 1}. Therefore, the choice of the penalty function f(u) is also slightly different, as we use Huber loss while [11] uses `1 loss.\nFor the simulation of the diffusion algorithm, the data are normalized so that \u2016xst\u20162 = 1. In contrast, when testing on the centralized ADMM-based algorithm from [11], the data are normalized so that \u2016xst\u20161 = 1 in keeping with the proposed simulation setup there. The constraint set for W for the diffusion-based algorithm is {W : \u2016[W ]:,q\u20162 \u2264 1, W 0}, while the constraint set for the ADMM-based algorithm from [11] is {W : \u2016[W ]:,q\u20161 \u2264 1, W 0}. We choose \u03b3 = 0.05 and \u03b4 = 0.1. For the initialization of the dictionary for the ADMM algorithm from [11], we let the algorithm iterate between the sparse coding step and the dictionary learning\n5We would like to thank S. P. Kasiviswanathan for kindly sharing his MATLAB code through e-mail communication in order to reproduce the simulation in [11], including the ordered data.\nstep 35 times. The diffusion algorithm runs through the data once. We choose \u03b7 = 0.2 for the connection point between the quadratic part and the linear part of the Huber loss function. Both the fully connected and distributed algorithms utilize a learning step-size of \u00b5w(s) = 1/s, where s is the current timestep for learning of the dictionary. For the inference, the fully connected algorithm utilizes \u00b5FC = 0.5, while the distributed algorithm uses \u00b5 = 0.05. The fully connected algorithm performs 100 iterations for the inference, while the distributed algorithm utilizes 1000 iterations for the inference. Samples 1-1000 are used for the initialization of the dictionary. Novel documents are only introduced at the first (samples 1001- 2000), second (2001-3000), fifth (5001-6000), sixth (6001- 7000), and eighth (8001-9000) time-steps. For this reason, we only execute the novel document detection part of the algorithm at those time-steps, and present the ROC curves for those time-steps. We run our algorithm using the fully connected case, where A = 1N 11\nT and the distributed case where the probability that two nodes are connected is 0.5, and the combination matrix is the Metropolis rule.\nTo obtain the distributed algorithm, we note from (29) that\nJk(\u03bd;x s t ) ,\n1\nN (f?(\u03bd)\u2212 \u03bdTxst )+h?yk(wTk \u03bd) (60)\nwhere we are using wk instead of Wk because each agent k is in charge of one atom of the dictionary (i.e., the k-th column of W ). Since we now use f(u) = \u2211M m=1 L(um) and hyk(yk) = \u03b3\u2016y\u20161,+ + \u03b42\u2016y\u201622 (according to the last row of Table I), we obtain that f?(\u03bd) = \u03b72\u2016\u03bd\u201622, Vf = {\u03bd : \u2016\u03bd\u2016\u221e \u2264 1}, and h?yk(wTk \u03bd) = S + \u03b3 \u03b4 ( wTk \u03bd \u03b4 ) according to Table II. A straightforward calculation then shows that\n\u2207\u03bdf?(\u03bd) = \u03b7 \u00b7 \u03bd, \u2207\u03bdh?yk(wTk \u03bd) = 1\n\u03b4 T +\u03b3 (wTk \u03bd)wk (61)\nSubstituting (61) into the gradient of (60), we obtain:\n\u2207\u03bdJk(\u03bd;xt) = 1\nN (\u03b7 \u00b7 \u03bd \u2212 xt)+\n1 \u03b4 T +\u03b3 (wTk \u03bd)wk (62)\nwhere we let NI = N and all agents in the network have access to xst . By substituting (62) into the inference part of Alg. 1, we immediately obtain the inference part of Alg. 2. For the learning portion of the algorithm, we need to compute yok,t at node k once \u03bd o t has been estimated. With our choices of f(u) and h(yk), we observe from Table II that yok,t may be obtained as yok,t = T +\u03b3 \u03b4 ( wTk \u03bd o t \u03b4 ) = 1\u03b4T +\u03b3 ( wTk \u03bd o t ) (as listed in Alg. 2). Now, using the fact that hwk(wk) = 0 (see Table I), we have that the update rule for wk from Alg. 1 becomes\nwk,t = \u03a0Wk { wk,t\u22121+\u00b5w\u03bd o t y o k,t } (63)\nwhere Wk = {w : \u2016w\u20162 \u2264 1, w 0} (see Table I). When recursion (63) finishes going through the data samples in the s-th time-step, the most up-to-date dictionary is denoted by W s = [ws1 \u00b7 \u00b7 \u00b7wsN ].\nIn this example, we do not need to recover zot in (41), but we only need to recover the cost value for representing a test data sample \u03bet using dictionary W s learned up to the s-th\n12\ntime-step:\nmin {yk}\n[ f ( \u03bet \u2212\nN\u2211 k=1 wskyk ) + N\u2211 k=1 hyk(yk) ] (64)\nwhere we use \u03bet to differentiate it from the training data sample xst . Interestingly, since strong duality holds for this example, based on the argument from (21a) to (28a), the above minimum primal cost (64) is equal to the maximum value of its associated dual cost:\nmax \u03bd\ng(\u03bd, \u03bet) = g(\u03bd o t , \u03bet) = \u2212 N\u2211 k=1 Jk(\u03bd o t , \u03bet) (65)\nwhere the first equality follows from the fact that \u03bdot is the optimizer of the dual problem. Therefore, we can obtain the minimum primal cost (64) by computing the maximum dual cost (65), which can be done in many ways with one of them being the diffusion strategy. In order to obtain a scaled multiple of (65), we setup the following scalar optimization problem:\nmin g N\u2211 k=1 Vk(g) (66)\nwhere\nVk(g) , 1\n2 (Jk(\u03bd\no t , \u03bet) + g) 2 (67)\nfrom which we can obtain the following scalar diffusion algorithm [16]:\u03c6k(i) = gk(i\u2212 1)\u2212 \u00b5g(Jk(\u03bd o t , \u03bet) + gk(i\u2212 1))\ngk(i) = \u2211 `\u2208Nk a`k\u03c6`(i) (68)\nAfter sufficient iterations, recursion (68) approximates the minimizer of (66), which is got = \u2212 1N \u2211N k=1 Jk(\u03bd o t , \u03bet). Comparing got to (65), we note that there is an additional positive scaling factor, 1/N , in got . However, it does not affect the result since it can be absorbed into the threshold parameter:\n\u2212 N\u2211 k=1 Jk(\u03bd o t , \u03bet) H1 \u2277 H0 \u03c7\u2032 \u21d4 got H1 \u2277 H0 \u03c7 , \u03c7\u2032 N (69)\nwhere H1 and H0 denote the hypotheses of \u201cthe document is novel\u201d and \u201cthe document is not novel\u201d, respectively. In other words, using a threshold \u03c7\u2032 for the original cost (65), is equivalent to using the threshold \u03c7 = \u03c7\u2032/N for got .\nThe final algorithm is listed in Alg. 2. Each node in the network is responsible for a single dictionary atom. The sparse coding stages of the centralized ADMM-based algorithm from [11] utilize 35 iterations, and the number of iterations of the dictionary update steps are capped at 10 for all iterations other than the initialization step, which are the default setup in the code of [11]. We observe that the performance of the centralized ADMM-based algorithm reproduced in this manuscript is competitive with that in [11], even though the initial dictionary size is chosen to be ten, as opposed to 200 atoms (as was done in the experiment in [11]). Furthermore, for our algorithm, since we are simulating a network of N - agents on a single machine, we expect the computation time to be N times as much as that in [11] in order to have a\nAlgorithm 2 Model-distributed diffusion strategy for distributed novel document detection (Huber Loss Residual).\nInitialization: The sub-dictionaries {Wk} are randomly initialized and then projected onto (4) using (52). for each time step s = 1, 2, . . . , 8 do\nDictionary Learning: for each training sample xst from time-step s, (t = 1, . . . , Ts) do\nEach node k repeats until convergence:{ \u03c8k,i=\u03bdk,i\u22121\u2212\u00b5N (\u03b7\u03bdk,i\u22121\u2212x s t)\u2212 \u00b5 \u03b4 T +\u03b3 (wTk,t\u22121\u03bdk,i\u22121)wk,t\u22121\n\u03bdk,i=\u03a0\u03bd\u2208[\u22121,1] {\u2211 `\u2208Nk a`k\u03c8`,i } with initialization {\u03bdk,0 = 0, k = 1, . . . , N}. where the above projection is carried out according to (36). Set \u03bdot = \u03bdk,i. Compute yok,t = 1 \u03b4 T +\u03b3 (wTk,t\u22121\u03bdot ). Update the dictionary using:\nwk,t = \u03a0\u2016w\u20162\u22641 { \u03a0w 0 { wk,t\u22121+\u00b5w(s)\u03bd o t y o k,t }} end for Let wsk denote the most up-to-date sub-dictionary at agent k. Novel Document Detection: for each test data sample \u03bet, each node k do\nRepeat until convergence:{ \u03c8k,i=\u03bdk,i\u22121\u2212\u00b5N (\u03b7\u03bdk,i\u22121\u2212\u03bet)\u2212 \u00b5 \u03b4 T +\u03b3 ( (wsk) T \u03bdk,i\u22121 ) wsk\n\u03bdk,i = \u03a0\u03bd\u2208[\u22121,1] {\u2211 `\u2208Nk a`k\u03c8`,i } Set \u03bdot = \u03bdk,i. Perform diffusion strategy to optimize (66) until convergence:{\n\u03c6k(i) = gk(i\u2212 1)\u2212 \u00b5g(Jk(\u03bdot , \u03bet) + gk(i\u2212 1)) gk(i) = \u2211 `\u2208Nk a`k\u03c6`(i)\nwhere Jk(\u03bd, \u00b7) is defined in (60). Set got = gk,i. if got > \u03c7 then\ndeclare document as novel. else\ndeclare document as not novel. end if\nend for Add nodes to network (expand the dictionary)\nend for\nfair comparison. This is because the gradient descent steps and the combination steps in (31a)\u2013(31b) should be finished concurrently in an actual N -agent network, while our singlemachine simulation can only perform them sequentially. For this reason, we choose the setup for our algorithm (such as the number of inference iterations) to be about N times of that in [11] to ensure a fair comparison.6\nThe performance of the algorithms is illustrated in Fig. 7. We observe that the Huber loss function improves performance relative to the `1 function. The area under each ROC curve is listed in Table IV. Since the different algorithms were initialized with different dictionaries, it may be possible for the sparsely-connected diffusion strategy to slightly outperform\n6When applying the centralized gradient descent to the dual inference problem (30a)\u2013(30b) with 1000 iterations at a single machine, we found that the entire learning time over one time-step (1000 samples) is approximately the same as that of the ADMM-based method from [11] using the same MATLAB implementation for the time benchmark.\n13\n0 1 0\n1\nProbabi l i ty of Fal se Alarm\nP ro\nb a b il\nit y\no f\nD e te\nc ti\no n s=1\n0 1 0\n1\nPr obabi l i ty of Fal se Alarm P\nr o b a b il\nit y\no f\nD e te\nc ti\no n s=2\n0 1 0\n1\nProbabi l i ty of Fal se Alarm\nP ro\nb a b il\nit y\no f\nD e te\nc ti\no n s=5\nthe fully-connected diffusion strategy. We observe this effect in Table IV, where the sparsely-connected network outperforms the fully-connected network by 0.01 (area under ROC curve)."}, {"heading": "C. Biclustering via Sparse Singular-Value-Decomposition", "text": "Consider next the cancer data matrix X \u2208 RM\u00d7T from [9], where M = 56 and T = 12, 625. Each row of X contains the genetic information for each of 56 patients. Each patient belongs to one of four cancer categories: Normal, Carcinoid, Colon, and SmallCell. The algorithm is unaware of the true category (label) of any patient, but wants to cluster patients into groups with different cancer types using the genetic information. The problem was formulated in [18] as a biclustering task (see also Tables I\u2013II) that factorizes X as\nX \u2248 N\u2211 k=1 wky T k (70)\nwith both wk \u2208 RM\u00d71 and yk \u2208 RT\u00d71 being sparse.\nIn Alg. 3, we list the algorithm from [9], which alternates between two sparse coding steps to obtain y and w, respectively. Observe that the algorithm is a batch algorithm, in that\nAlgorithm 3 Simplified algorithm from [9] for biclustering. for each k do\nApply standard SVD to X = woldsoldyTold. Repeat until convergence:\n1) Set y\u0303 = T\u03bb(XTwold), and ynew = y\u0303/\u2016y\u0303\u20162. 2) Set w\u0303 = T\u03b2(Xynew), and wnew = w\u0303/\u2016y\u0303\u20162. 3) Set wold = wnew.\nSet wk = wnew, sk = wTnewXynew, and yk = skynew. Set X = X \u2212 wkyTk .\nend for\nAlgorithm 4 Model-distributed diffusion strategy for online biclustering.\nInitialization: The sub-dictionaries {Wk} are randomly initialized and then projected onto (3) using (50). for each input data sample xt, each node k do\nRepeat until convergence: \u03c8k,i=\u03bdk,i\u22121\u2212\u00b5\u03bd 1N (\u03bdk,i\u22121 \u2212 xt)\u2212 \u00b5\u03bd \u03b4 T\u03b3(wTk,t\u22121\u03bdk,i\u22121)wk,t\u22121\n\u03bdk,i = \u2211 `\u2208Nk a`k\u03c8`,i\nwith initialization {\u03bdk,0 = 0, k = 1, . . . , N}. Set \u03bdok = \u03bdk,i. Compute y o k = 1 \u03b4 T\u03b3(wTk,t\u22121\u03bdo). Update the dictionary using:\nwk,t = \u03a0\u2016w\u2016\u22641 { T\u03b2 ( wk,t\u22121+\u00b5w\u03bd o ky oT k )} end for\nit utilizes the entire data set at each iteration. In addition, the algorithm works by computing the best sparse rank-1 approximation for the matrix X \u2248 w1yT1 , then computes the best rank-1 approximation for X \u2212 w1yT1 \u2248 w2yT2 , and so on. In contrast, our proposed Alg. 1, when specialized to the bi-clustering application (see Alg. 4), runs through the data in an online manner and obtains the {wk} simultaneously.\nWe choose N = 3 to be consistent with the setup in [9], where each node is responsible for a single dictionary atom. We set \u03b3 = 0.5 and \u03b2 = 0.01. Since the number of nodes is small, we simulate the fully connected case where the combination matrix A = 1N 1N1 T N (i.e., each node is effectively averaging the estimate of \u03c8k,i). We run Alg. 3 until \u2016wnew \u2212 wold\u2016\u221e < 1 \u00d7 10\u221210. We run our algorithm\u2019s sparse coding for a total of 2000 iterations. We choose \u00b5\u03bd = 0.01, \u00b5w = 5 \u00d7 10\u22123, and \u03b4 = 0.01. In Fig. 8, we plot, in the same manner as [9], the clustering results of Algorithms 3\u20134. This is an unsupervised learning task, meaning that, during the learning process, the algorithms are unaware of the ground truth of the cancer categories of each patient. Still, the algorithms are required to cluster patients into different groups according to their underlying genetic information, hoping that patients of similar genetic information will be clustered together. After the clustering is done, we add colors to different markers according to the ground truth (label) to visualize and evaluate the result of the clustering. The clustering will be more successful if (i) markers of the same color are clustered together, and (ii) markers of different colors are well separated. We observe that both algorithms, without the use of the cancer labels, can successfully cluster the data\n14\ninto 4 distinct clusters according to the genetic information, with each cluster corresponding to a different type of cancer. The advantage of the diffusion strategy is that it only requires each node to observe each data sample (each column of X) once (not batched) and obtain {w1, w2, w3} simultaneously. Note that in this example an additional data collection process is required to gather all the w1, w2, and w3 to generate the final bi-clustering plots in Fig. 8. This is because we need to use ([w1]m, [w2]m, [w3]m) to represent the genetic profile of each patient m. This step is usually less demanding than learning the {wk}, especially in large-scale genetic data analysis. The agents may choose to report the obtained results periodically. Nevertheless, the computation-intensive learning process in biclustering is still distributed over the network, where the agents learn different {wk} in an online and simultaneous manner."}, {"heading": "V. CONCLUSION", "text": "In this paper, we studied the online dictionary learning problem over distributed models, where each agent is in charge of a portion of the dictionary atoms and the agents collaborate to represent the data. Using the concepts of conjugate function and dual decomposition, we transform the original learning problem into a form that is amenable to distributed optimization, which is then solved by means of a diffusion strategy. The collaborative inference step generates dual variables that are used by the agents to update their dictionary atoms without the need to share their dictionaries or even the coefficient models for the training data. The proposed algorithm is tested over two typical tasks of dictionary learning, namely, novel document detection and bi-clustering. The results demonstrate that our proposed algorithm can solve the dictionary learning tasks effectively in a distributed and online manner.\nIn relation to the convergence behavior, we remark that the general learning problem (1)\u2013(2) is not jointly convex with respect to both W and y. This fact explains why convergence guarantees towards a global minimum, when it exists, are generally not available in the literature. A common technique for solving such coupled optimization problems is to alternate between the minimization over one variable while keeping the other variable fixed. In this article, we followed a similar construction albeit one that operates in an online and distributed manner. For the inference problem (7), we applied the diffusion strategy, which has already been shown in prior studies [16] to converge within O(\u00b52) to the optimal inference solution. For the dictionary update step, we used a proximal projection step. Simulation results in this article and by other authors have indicated that such alternating optimization solutions tend to perform well in practice."}, {"heading": "APPENDIX A DERIVATION OF SOME TYPICAL CONJUGATE FUNCTIONS", "text": "In this appendix, we derive the conjugate functions listed in Table II. The conjugate functions for 12\u2016u\u201622, and their corresponding domains can be found in [38, pp.90-94]. The conjugate function for the scalar Huber loss L(um) can be found in [55] as L?(\u03bdm) = 12\u03bd 2 m with |\u03bdm| \u2264 1. Therefore, by the \u201csums of independent functions\u201d property7 in [38, p.95], the conjugate function of \u2211M m=1 L(um) is:\nM\u2211 m=1 L?(\u03bdm) = M\u2211 m=1 1 2 \u03bd2m = 1 2 \u2016\u03bd\u201622, (71)\nwhere the domain is given by\n|\u03bdm| \u2264 1, m = 1, . . . ,M \u21d4 \u2016\u03bd\u2016\u221e \u2264 1 (72) Next, we derive the conjugate functions for the elastic net regularization term hyk(yk) = \u03b3\u2016yk\u20161 + \u03b42\u2016yk\u201622. By the definition of conjugate functions in (26), we have\nh?yk(W T k \u03bd) = sup\nyk\n[ (WTk \u03bd) T yk \u2212 hyk(yk) ]\n7If f(x1, . . . , xN ) = f1(x1) + \u00b7 \u00b7 \u00b7 fN (xN ), then the conjugate function for f(x1, . . . , xN ) is given by f?(\u03bd1, . . . , \u03bdN ) = f?1 (\u03bd1) + \u00b7 \u00b7 \u00b7 + f?N (\u03bdN ), where f ? 1 (\u03bd1), . . . , f ? N (\u03bdN ) are the conjugate functions for f1(x1), . . . , fN (xN ), respectively.\n15\n= \u2212 inf yk\n[ hyk(yk)\u2212 (WTk \u03bd)T yk ] = \u2212 inf\nyk\n[ \u03b3\u2016yk\u20161+ \u03b4\n2 \u2016yk\u201622\u2212(WTk \u03bd)T yk\n] (73)\n= \u2212\u03b4 \u00b7inf yk\n[ \u03b3\n\u03b4 \u2016yk\u20161+\n1\n2 \u2225\u2225\u2225yk\u2212 1 \u03b4 WTk \u03bd \u2225\u2225\u22252 2 ] + 1\n2\u03b4 \u2016WTk \u03bd\u201622 (74)\nwhere the last step completes the square. Note from (47) that the optimal yk that minimizes the term inside the bracket of (74) can be expressed as the proximal operator of (\u03b3/\u03b4)\u2016yk\u20161, which is known to be given by the entry-wise soft-thresholding operator [43, p.188] [56]:\nyok,t = arg min yk\n[ \u03b3\n\u03b4 \u2016yk\u20161 +\n1\n2 \u2225\u2225\u2225yk\u2212 1 \u03b4 WTk \u03bd \u2225\u2225\u22252 2 ] = prox \u03b3\n\u03b4 \u2016\u00b7\u20161\n( WTk \u03bd\n\u03b4\n) = T \u03b3\n\u03b4\n( WTk \u03bd\n\u03b4\n) (75)\nwhere [T\u03bb(x)]n , (|[x]n| \u2212 \u03bb)+sgn([x]n) and (x)+ = max(x, 0). Substituting (75) into (73), we obtain\nh?yk(W T k \u03bd) = S \u03b3\u03b4\n( WTk \u03bd\n\u03b4\n) (76)\nwhere\nS \u03b3 \u03b4\n(x) , \u2212\u03b3 \u00b7 \u2225\u2225T \u03b3 \u03b4 (x) \u2225\u2225 1 \u2212 \u03b4\n2\n\u2225\u2225T \u03b3 \u03b4 (x) \u2225\u22252 2 +\u03b4 \u00b7 xTT \u03b3 \u03b4 (x) (77)\nFinally, we derive the conjugate function for the nonnegative elastic net regularization function hyk(yk) = \u03b3\u2016yk\u20161,+ + \u03b4 2\u2016yk\u201622. Following the same line of argument from (73)\u2013(74), we get\nh?yk(W T k \u03bd) = \u2212 inf\nyk\n[ \u03b3\u2016yk\u20161,++ \u03b4\n2 \u2016yk\u201622\u2212(WTk \u03bd)Tyk\n] (78a)\n= \u2212\u03b4 \u00b7inf yk\n[ \u03b3\n\u03b4 \u2016yk\u20161,++\n1\n2 \u2225\u2225\u2225yk\u2212 1 \u03b4 WTk \u03bd \u2225\u2225\u22252 2 ] + 1\n2\u03b4 \u2016WTk \u03bd\u201622 (78b)\nBy (47), the optimal yok,t that minimizes the term inside the bracket of (78b) is given by\nyok,t = arg min yk\n[ \u03b3\n\u03b4 \u2016yk\u20161,+ +\n1\n2 \u2225\u2225\u2225yk\u2212 1 \u03b4 WTk \u03bd \u2225\u2225\u22252 2 ] (79)\nApplying an argument similar to the one used in [50], we can express the optimal yok,t in (79) as\nyok,t = T +\u03b3 \u03b4\n( WTk \u03bd\n\u03b4\n) (80)\nwhere [T +\u03bb (x)]n , ([x]n \u2212 \u03bb)+. Substituting (80) into (78a):\nh?yk(W T k \u03bd) = S+\u03b3\n\u03b4\n( WTk \u03bd\n\u03b4\n) (81)\nwhere\nS+\u03b3 \u03b4\n(x) , \u2212\u03b3 \u00b7 \u2225\u2225T +\u03b3 \u03b4 (x) \u2225\u2225 1,+ \u2212 \u03b4 2 \u2225\u2225T +\u03b3 \u03b4 (x) \u2225\u22252 2 +\u03b4 \u00b7 xTT +\u03b3 \u03b4 (x)\n= \u2212\u03b3 \u00b7 \u2225\u2225T +\u03b3 \u03b4 (x) \u2225\u2225 1 \u2212 \u03b4 2 \u2225\u2225T +\u03b3 \u03b4 (x) \u2225\u22252 2 +\u03b4 \u00b7xTT +\u03b3 \u03b4 (x) (82)\nwhere the last step uses the fact that the output of T +\u03b3 (\u00b7) is always nonnegative so that \u2016T +\u03b3\n\u03b4 (x) \u20161,+ = \u2016T +\u03b3 \u03b4 (x) \u20161."}], "references": [{"title": "Online dictionary learning over distributed models", "author": ["J. Chen", "Z.J. Towfic", "A.H. Sayed"], "venue": "Proc. IEEE ICASSP, Florence, Italy, May 2014, pp. 3874\u20133878.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation", "author": ["M. Aharon", "M. Elad", "A. Bruckstein"], "venue": "IEEE Trans. Signal Process., vol. 54, no. 11, pp. 4311\u20134322, Nov. 2006.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "PETRELS: Parallel subspace estimation and tracking by recursive least squares from partial observations", "author": ["Y. Chi", "Y. Eldar", "R. Calderbank"], "venue": "IEEE Trans. Signal Process., vol. 61, no. 23, pp. 5947\u20135959, Dec. 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Dictionary learning", "author": ["I. Tosic", "P. Frossard"], "venue": "IEEE Signal Processing Magazine, vol. 28, no. 2, pp. 27\u201338, Mar. 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Image denoising via sparse and redundant representations over learned dictionaries", "author": ["M. Elad", "M. Aharon"], "venue": "IEEE Trans. Image Process., vol. 15, no. 12, pp. 3736\u20133745, Dec. 2006.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Online learning for matrix factorization and sparse coding", "author": ["J. Mairal", "F. Bach", "J. Ponce", "G. Sapiro"], "venue": "The Journal of Machine Learning Research, vol. 11, pp. 19\u201360, Mar. 2010.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Sparse principal component analysis", "author": ["H. Zou", "T. Hastie", "R. Tibshirani"], "venue": "Journal of Computational and Graphical Statistics, vol. 15, no. 2, pp. 265\u2013286, Jan. 2006.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Sparse principal component analysis via regularized low rank matrix approximation", "author": ["H. Shen", "J.Z. Huang"], "venue": "Journal of Multivariate Analysis, vol. 99, no. 6, pp. 1015\u20131034, Jul. 2008.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Biclustering via sparse singular value decomposition", "author": ["M. Lee", "H. Shen", "J.Z. Huang", "J.S. Marron"], "venue": "Biometrics, vol. 66, no. 4, pp. 1087\u20131095, Dec. 2010.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Supervised dictionary learning", "author": ["J. Mairal", "F. Bach", "J. Ponce", "G. Sapiro", "A. Zisserman"], "venue": "Proc. NIPS, Lake Tahoe, Nevada, Dec. 2008, pp. 1033\u20131040.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Online `1-dictionary learning with application to novel document detection", "author": ["S.P. Kasiviswanathan", "H. Wang", "A. Banerjee", "P. Melville"], "venue": "Proc. NIPS, Lake Tahoe, Nevada, Dec. 2012, pp. 2267\u20132275.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning a common dictionary over a sensor network", "author": ["P. Chainais", "C. Richard"], "venue": "Proc. IEEE CAMSAP, St. Martin, French West Indies, Dec. 2013, pp. 133\u2013136.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Diffusion LMS strategies for distributed estimation", "author": ["F.S. Cattivelli", "A.H. Sayed"], "venue": "IEEE Trans. Signal Process., vol. 58, no. 3, pp. 1035\u20131048, Mar. 2010.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Diffusion strategies for adaptation and learning over networks", "author": ["A.H. Sayed", "S.-Y. Tu", "J. Chen", "X. Zhao", "Z.J. Towfic"], "venue": "IEEE Signal Process. Mag., vol. 30, no. 3, pp. 155\u2013171, May 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "On the limiting behavior of distributed optimization strategies", "author": ["J. Chen", "A.H. Sayed"], "venue": "Proc. Allerton Conf., Monticello, IL, Oct. 2012, pp. 1535\u20131542.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Distributed Pareto optimization via diffusion adaptation", "author": ["J. Chen", "A.H. Sayed"], "venue": "IEEE J. Sel. Topics Signal Process., vol. 7, no. 2, pp. 205\u2013 220, Apr. 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed parameter estimation in sensor networks: Nonlinear observation models and imperfect communication", "author": ["S. Kar", "J.M.F. Moura", "K. Ramanan"], "venue": "IEEE Trans. Inf. Theory, vol. 58, no. 6, pp. 3575\u20133605, Jun. 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Distributed random projection algorithm for convex optimization", "author": ["S. Lee", "A. Nedic"], "venue": "IEEE Journal Sel. Topics Signal Process., vol. 7, no. 2, pp. 221\u2013229, Apr. 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Parallel and Distributed Computation: Numerical Methods", "author": ["D.P. Bertsekas", "J.N. Tsitsiklis"], "venue": "Athena Scientific,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1997}, {"title": "Distributed asynchronous deterministic and stochastic gradient optimization algorithms", "author": ["J.N. Tsitsiklis", "D.P. Bertsekas", "M. Athans"], "venue": "IEEE Trans. Autom. Control, vol. 31, no. 9, pp. 803\u2013812, 1986.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1986}, {"title": "Adaptive networks", "author": ["A.H. Sayed"], "venue": "Proc. IEEE, vol. 102, no. 4, pp. 460\u2013497, Apr. 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Adaptation, learning, and optimization over networks", "author": ["A.H. Sayed"], "venue": "Foundations and Trends in Machine Learning, vol. 7, issue 4\u20135, NOW Publishers, Jul. 2014.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Diffusion strategies outperform consensus strategies for distributed estimation over adaptive networks", "author": ["S.-Y. Tu", "A.H. Sayed"], "venue": "IEEE Trans. Signal Process., vol. 60, no. 12, pp. 6217\u20136234, Dec. 2012.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Sensing trending topics in twitter", "author": ["L.M. Aiello", "G. Petkos", "C. Martin", "D. Corney", "S. Papadopoulos", "R. Skraba", "A. Goker", "I. Kompatsiaris", "A. Jaimes"], "venue": "IEEE Trans. Multimedia, vol. 15, no. 6, pp. 1268\u2013 1282, Oct. 2013.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Discovering emerging topics in social streams via link-anomaly detection", "author": ["T. Takahashi", "R. Tomioka", "K. Yamanishi"], "venue": "IEEE Trans. Knowl. Data Eng., vol. 26, no. 1, pp. 120\u2013130, Jan. 2014. 16", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Robust estimation of a location parameter", "author": ["P.J. Huber"], "venue": "The Annals of Mathematical Statistics, vol. 35, no. 1, pp. 73\u2013101, Mar. 1964.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1964}, {"title": "Distributed dictionary learning over a sensor network", "author": ["P. Chainais", "C. Richard"], "venue": "arXiv:1304.3568, Apr. 2013.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Adaptive robust distributed learning in diffusion sensor networks", "author": ["S. Chouvardas", "K. Slavakis", "S. Theodoridis"], "venue": "IEEE Trans. Signal Process., vol. 59, no. 10, pp. 4692\u20134707, Oct. 2011.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Large scale distributed deep networks", "author": ["J. Dean", "G.S. Corrado", "R. Monga", "K. Chen", "M. Devin", "Q.V. Le", "M.Z. Mao", "M. Ranzato", "A. Senior", "P. Tucker", "K. Yang", "A.Y. Ng"], "venue": "Proc. NIPS, Lake Tahoe, NV, Dec. 2012, pp. 1\u20139.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "Distributed basis pursuit", "author": ["J. Mota", "J. Xavier", "P. Aguiar", "M. P\u00fcschel"], "venue": "IEEE Trans. Signal Process., vol. 60, no. 4, pp. 1942\u20131956, Apr. 2012.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1942}, {"title": "D-ADMM: A communication-efficient distributed algorithm for separable optimization", "author": ["J. Mota", "J. Xavier", "P. Aguiar", "M. P\u00fcschel"], "venue": "IEEE Trans. Signal Process., vol. 61, no. 10, pp. 2718\u20132723, May 2013.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "On the convergence of decentralized gradient descent", "author": ["K. Yuan", "Q. Ling", "W. Yin"], "venue": "to appear in SIAM Journal on Optimization, [also avaiable as arXiv:1310.7063], 2014.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Dictionary learning over large distributed models via dual-ADMM strategies", "author": ["Z.J. Towfic", "J. Chen", "A.H. Sayed"], "venue": "Proc. IEEE MLSP, Reims, France, Sep. 2014, pp. 1\u20136.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Distributed sparse linear regression", "author": ["G. Mateos", "J.A. Bazerque", "G.B. Giannakis"], "venue": "IEEE Trans. Signal Process., vol. 58, no. 10, pp. 5262\u20135276, 2010.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Distributed constrained optimization by consensus-based primal-dual perturbation method", "author": ["T.-H. Chang", "A. Nedic", "A. Scaglione"], "venue": "available as arXiv:1304.5590, Apr. 2013.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Diffusion adaptation strategies for distributed optimization and learning over networks", "author": ["J. Chen", "A.H. Sayed"], "venue": "IEEE Trans. Signal Process., vol. 60, no. 8, pp. 4289\u20134305, Aug. 2012.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2012}, {"title": "Consensus in ad hoc WSNs with noisy links\u2014Part I: Distributed estimation of deterministic signals", "author": ["I.D. Schizas", "A. Ribeiro", "G.B. Giannakis"], "venue": "IEEE Trans. Signal Process., vol. 56, no. 1, pp. 350\u2013364, 2008.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2008}, {"title": "Distributed in-network channel decoding", "author": ["H. Zhu", "G. Giannakis", "A. Cano"], "venue": "IEEE Trans. Signal Process., vol. 57, no. 10, pp. 3970\u20133983, Oct. 2009.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2009}, {"title": "A multi-block alternating direction method with parallel splitting for decentralized consensus optimization", "author": ["Q. Ling", "M. Tao", "W. Yin", "X. Yuan"], "venue": "EURASIP J. Wireless Commun. Netw., vol. 338, no. 1, pp. 1\u201312, Nov. 2012.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2012}, {"title": "Proximal algorithms", "author": ["N. Parikh", "S. Boyd"], "venue": "Foundations and Trends in Optimization, vol. 1, no. 3, pp. 123\u2013231, 2013.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2013}, {"title": "Adaptive learning in a world of projections", "author": ["S. Theodoridis", "K. Slavakis", "I. Yamada"], "venue": "IEEE Signal Process. Mag., vol. 28, no. 1, pp. 97\u2013123, Jan. 2011.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2011}, {"title": "Adaptive penalty-based distributed stochastic convex optimization", "author": ["Z.J. Towfic", "A.H. Sayed"], "venue": "IEEE Trans. Signal Process., vol. 62, no. 15, pp. 3924\u20133938, Aug. 2014.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2014}, {"title": "Distributed detection and estimation in wireless sensor networks", "author": ["S. Barbarossa", "S. Sardellitti", "P. Di Lorenzo"], "venue": "Academic Press Library in Signal Processing, vol. 2, R. Chellapa and S. Theodoridis, editors, pp. 329\u2013408, Elsevier, 2014.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "Introduction to Optimization, Optimization", "author": ["B. Polyak"], "venue": "Software, NY,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 1987}, {"title": "A bound optimization approach to wavelet-based image deconvolution", "author": ["M. Figueiredo", "R.D. Nowak"], "venue": "Proc. IEEE ICIP, Genoa, Italy, Sep. 2005, vol. 2, pp. 779\u2013782.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2005}, {"title": "Majorization\u2013minimization algorithms for wavelet-based image restoration", "author": ["M.A.T. Figueiredo", "J.M. Bioucas-Dias", "R.D. Nowak"], "venue": "IEEE Trans. Image Process.,, vol. 16, no. 12, pp. 2980\u20132991, Nov. 2007.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2007}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM Journal on Imaging Sciences, vol. 2, no. 1, pp. 183\u2013202, 2009.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2009}, {"title": "Stochastic Approximation and Recursive Algorithms and Applications", "author": ["H.J. Kushner", "G. Yin"], "venue": null, "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2003}, {"title": "Incremental gradient, subgradient, and proximal methods for convex optimization: A survey", "author": ["D.P. Bertsekas"], "venue": "LIDS Technical Report, MIT, 2010.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2010}, {"title": "CVX: Matlab software for disciplined convex programming, version 2.0 beta", "author": ["M. Grant", "S. Boyd"], "venue": "http://cvxr.com/cvx, Sept. 2013.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2013}, {"title": "Practical methods for convex multi-view reconstruction", "author": ["C. Zach", "M. Pollefeys"], "venue": "Proc. ECCV, pp. 354\u2013367. Heraklion, Greece, Sep. 2010.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2010}, {"title": "De-noising by soft-thresholding", "author": ["D.L. Donoho"], "venue": "IEEE Trans. Inf. Theory, vol. 41, no. 3, pp. 613\u2013627, May 1995.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 1995}], "referenceMentions": [{"referenceID": 1, "context": "INTRODUCTION AND RELATED WORK Dictionary learning is a useful procedure by which dependencies among input features can be represented in terms of suitable bases [2]\u2013[11].", "startOffset": 161, "endOffset": 164}, {"referenceID": 10, "context": "INTRODUCTION AND RELATED WORK Dictionary learning is a useful procedure by which dependencies among input features can be represented in terms of suitable bases [2]\u2013[11].", "startOffset": 165, "endOffset": 169}, {"referenceID": 4, "context": "It has found applications in many machine learning and inference tasks including image denoising [5], [6], dimensionality-reduction [7], [8], bi-clustering [9], feature-extraction and classification [10], and novel document detection [11].", "startOffset": 97, "endOffset": 100}, {"referenceID": 5, "context": "It has found applications in many machine learning and inference tasks including image denoising [5], [6], dimensionality-reduction [7], [8], bi-clustering [9], feature-extraction and classification [10], and novel document detection [11].", "startOffset": 102, "endOffset": 105}, {"referenceID": 6, "context": "It has found applications in many machine learning and inference tasks including image denoising [5], [6], dimensionality-reduction [7], [8], bi-clustering [9], feature-extraction and classification [10], and novel document detection [11].", "startOffset": 132, "endOffset": 135}, {"referenceID": 7, "context": "It has found applications in many machine learning and inference tasks including image denoising [5], [6], dimensionality-reduction [7], [8], bi-clustering [9], feature-extraction and classification [10], and novel document detection [11].", "startOffset": 137, "endOffset": 140}, {"referenceID": 8, "context": "It has found applications in many machine learning and inference tasks including image denoising [5], [6], dimensionality-reduction [7], [8], bi-clustering [9], feature-extraction and classification [10], and novel document detection [11].", "startOffset": 156, "endOffset": 159}, {"referenceID": 9, "context": "It has found applications in many machine learning and inference tasks including image denoising [5], [6], dimensionality-reduction [7], [8], bi-clustering [9], feature-extraction and classification [10], and novel document detection [11].", "startOffset": 199, "endOffset": 203}, {"referenceID": 10, "context": "It has found applications in many machine learning and inference tasks including image denoising [5], [6], dimensionality-reduction [7], [8], bi-clustering [9], feature-extraction and classification [10], and novel document detection [11].", "startOffset": 234, "endOffset": 238}, {"referenceID": 0, "context": "A short and preliminary version of this work appears in the conference publication [1].", "startOffset": 83, "endOffset": 86}, {"referenceID": 11, "context": "Compared with other works, the problem we solve in this article is how to learn a distributed dictionary model, which is, for example, different from the useful work in [12] where it is assumed instead that each agent maintains the entire dictionary model.", "startOffset": 169, "endOffset": 173}, {"referenceID": 12, "context": "However, when the regularization is strongly convex, we will show that the problem has a dual function that can be solved in a distributed manner using diffusion strategies [13]\u2013[16].", "startOffset": 173, "endOffset": 177}, {"referenceID": 15, "context": "However, when the regularization is strongly convex, we will show that the problem has a dual function that can be solved in a distributed manner using diffusion strategies [13]\u2013[16].", "startOffset": 178, "endOffset": 182}, {"referenceID": 16, "context": "Useful consensus strategies [17]\u2013[20] can also be used for the same purpose.", "startOffset": 28, "endOffset": 32}, {"referenceID": 19, "context": "Useful consensus strategies [17]\u2013[20] can also be used for the same purpose.", "startOffset": 33, "endOffset": 37}, {"referenceID": 20, "context": "However, since it has been shown that diffusion strategies have enhanced stability and learning abilities over consensus strategies [21]\u2013[23], we will continue our presentation by focusing on diffusion strategies.", "startOffset": 132, "endOffset": 136}, {"referenceID": 22, "context": "However, since it has been shown that diffusion strategies have enhanced stability and learning abilities over consensus strategies [21]\u2013[23], we will continue our presentation by focusing on diffusion strategies.", "startOffset": 137, "endOffset": 141}, {"referenceID": 10, "context": "We will test our proposed algorithm on two important applications of dictionary learning: (i) novel document detection [11], [24], [25], and (ii) bi-clustering on microarray data [9].", "startOffset": 119, "endOffset": 123}, {"referenceID": 23, "context": "We will test our proposed algorithm on two important applications of dictionary learning: (i) novel document detection [11], [24], [25], and (ii) bi-clustering on microarray data [9].", "startOffset": 125, "endOffset": 129}, {"referenceID": 24, "context": "We will test our proposed algorithm on two important applications of dictionary learning: (i) novel document detection [11], [24], [25], and (ii) bi-clustering on microarray data [9].", "startOffset": 131, "endOffset": 135}, {"referenceID": 8, "context": "We will test our proposed algorithm on two important applications of dictionary learning: (i) novel document detection [11], [24], [25], and (ii) bi-clustering on microarray data [9].", "startOffset": 179, "endOffset": 182}, {"referenceID": 0, "context": "A third application related to image denoising is considered in [1].", "startOffset": 64, "endOffset": 67}, {"referenceID": 10, "context": "In the novel document detection problem [11], [24], [25], each learner receives documents associated with certain topics, and wishes to determine if an incoming document is associated with a topic that has already been observed in previous data.", "startOffset": 40, "endOffset": 44}, {"referenceID": 23, "context": "In the novel document detection problem [11], [24], [25], each learner receives documents associated with certain topics, and wishes to determine if an incoming document is associated with a topic that has already been observed in previous data.", "startOffset": 46, "endOffset": 50}, {"referenceID": 24, "context": "In the novel document detection problem [11], [24], [25], each learner receives documents associated with certain topics, and wishes to determine if an incoming document is associated with a topic that has already been observed in previous data.", "startOffset": 52, "endOffset": 56}, {"referenceID": 25, "context": "In these applications, our algorithm is able to perform distributed non-negative matrix factorization tasks, with the residual metric chosen as the Huber loss function [26], and is able to achieve a high area under the receiver operating characteristic (ROC) curve.", "startOffset": 168, "endOffset": 172}, {"referenceID": 8, "context": "We show that our algorithm can obtain similar clustering results to those in [9], which relies instead on a batched (centralized) implementation.", "startOffset": 77, "endOffset": 80}, {"referenceID": 5, "context": "In regular dictionary learning [6], the constraint set W is W = {W : \u2016[W ]:,q\u20162 \u2264 1, \u2200q} (3)", "startOffset": 31, "endOffset": 34}, {"referenceID": 5, "context": "and in applications of nonnegative matrix factorization [6] and novel document detection (topic modeling) [11], it is", "startOffset": 56, "endOffset": 59}, {"referenceID": 10, "context": "and in applications of nonnegative matrix factorization [6] and novel document detection (topic modeling) [11], it is", "startOffset": 106, "endOffset": 110}, {"referenceID": 6, "context": "For example, in Table I, we add an `2 term to `1 regularization so that the resulting hyk(yk) ends up amounting to elastic net regularization, in the manner advanced in [7].", "startOffset": 169, "endOffset": 172}, {"referenceID": 11, "context": "Data Distributed: The problem we are solving in this paper is different from the useful work [12], [27] on distributed dictionary learning and from the traditional distributed learning setting [13], [14], [16], [28], where it is assumed that the entire dictionary W is maintained by each agent or that individual data samples generated by the same distribution, denoted by xk,t, are observed by the agents at each time t.", "startOffset": 93, "endOffset": 97}, {"referenceID": 26, "context": "Data Distributed: The problem we are solving in this paper is different from the useful work [12], [27] on distributed dictionary learning and from the traditional distributed learning setting [13], [14], [16], [28], where it is assumed that the entire dictionary W is maintained by each agent or that individual data samples generated by the same distribution, denoted by xk,t, are observed by the agents at each time t.", "startOffset": 99, "endOffset": 103}, {"referenceID": 12, "context": "Data Distributed: The problem we are solving in this paper is different from the useful work [12], [27] on distributed dictionary learning and from the traditional distributed learning setting [13], [14], [16], [28], where it is assumed that the entire dictionary W is maintained by each agent or that individual data samples generated by the same distribution, denoted by xk,t, are observed by the agents at each time t.", "startOffset": 193, "endOffset": 197}, {"referenceID": 13, "context": "Data Distributed: The problem we are solving in this paper is different from the useful work [12], [27] on distributed dictionary learning and from the traditional distributed learning setting [13], [14], [16], [28], where it is assumed that the entire dictionary W is maintained by each agent or that individual data samples generated by the same distribution, denoted by xk,t, are observed by the agents at each time t.", "startOffset": 199, "endOffset": 203}, {"referenceID": 15, "context": "Data Distributed: The problem we are solving in this paper is different from the useful work [12], [27] on distributed dictionary learning and from the traditional distributed learning setting [13], [14], [16], [28], where it is assumed that the entire dictionary W is maintained by each agent or that individual data samples generated by the same distribution, denoted by xk,t, are observed by the agents at each time t.", "startOffset": 205, "endOffset": 209}, {"referenceID": 27, "context": "Data Distributed: The problem we are solving in this paper is different from the useful work [12], [27] on distributed dictionary learning and from the traditional distributed learning setting [13], [14], [16], [28], where it is assumed that the entire dictionary W is maintained by each agent or that individual data samples generated by the same distribution, denoted by xk,t, are observed by the agents at each time t.", "startOffset": 211, "endOffset": 215}, {"referenceID": 28, "context": "A different formulation is also considered in [29] in the context of distributed deep neural network (DNN) models over computer networks.", "startOffset": 46, "endOffset": 50}, {"referenceID": 29, "context": "2) Distributed Basis Pursuit: Other useful related works appear in the studies [30]\u2013[32] on distributed basis pursuit, which also rely on dual decomposition arguments.", "startOffset": 79, "endOffset": 83}, {"referenceID": 31, "context": "2) Distributed Basis Pursuit: Other useful related works appear in the studies [30]\u2013[32] on distributed basis pursuit, which also rely on dual decomposition arguments.", "startOffset": 84, "endOffset": 88}, {"referenceID": 32, "context": "However, there are some key differences in problem formulation, generality, and technique, as explained in [33].", "startOffset": 107, "endOffset": 111}, {"referenceID": 29, "context": "For example, the works [30]\u2013[32] do not deal with dictionary learning problems and focus instead on the solution of special cases of the inference problem (7).", "startOffset": 23, "endOffset": 27}, {"referenceID": 31, "context": "For example, the works [30]\u2013[32] do not deal with dictionary learning problems and focus instead on the solution of special cases of the inference problem (7).", "startOffset": 28, "endOffset": 32}, {"referenceID": 29, "context": "Specifically, the problem formulations in [30]\u2013[32] focus on determining sparse solutions to (underdetermined) linear systems of equations, which can be interpreted as corresponding to scenarios where the dictionaries are static and not learned from data.", "startOffset": 42, "endOffset": 46}, {"referenceID": 31, "context": "Specifically, the problem formulations in [30]\u2013[32] focus on determining sparse solutions to (underdetermined) linear systems of equations, which can be interpreted as corresponding to scenarios where the dictionaries are static and not learned from data.", "startOffset": 47, "endOffset": 51}, {"referenceID": 29, "context": ", one agent) while it is assumed in [30]\u2013[32] that all agents have access to the same data xt.", "startOffset": 36, "endOffset": 40}, {"referenceID": 31, "context": ", one agent) while it is assumed in [30]\u2013[32] that all agents have access to the same data xt.", "startOffset": 41, "endOffset": 45}, {"referenceID": 29, "context": "For instance, one of the problems studied in [30] is the following inference problem (compare with (7)):", "startOffset": 45, "endOffset": 49}, {"referenceID": 30, "context": "To handle the modeling error, the work [31] considered instead:", "startOffset": 39, "endOffset": 43}, {"referenceID": 30, "context": "An alternative problem formulation that removes the indicator functions is considered in [31], [34], namely,", "startOffset": 89, "endOffset": 93}, {"referenceID": 33, "context": "An alternative problem formulation that removes the indicator functions is considered in [31], [34], namely,", "startOffset": 95, "endOffset": 99}, {"referenceID": 30, "context": "However, for problem (17), the dictionary elements as well as the entries of xt, were partitioned in [31], [34] by rows across the network as opposed to our column-wise partitioning in (8):", "startOffset": 101, "endOffset": 105}, {"referenceID": 33, "context": "However, for problem (17), the dictionary elements as well as the entries of xt, were partitioned in [31], [34] by rows across the network as opposed to our column-wise partitioning in (8):", "startOffset": 107, "endOffset": 111}, {"referenceID": 30, "context": "However, the more challenging problem where the matrix W is partitioned column-wise as in (8), which leads to the \u201ccost-of-sum\u201d form showed earlier in (11), was not examined in [31], [34].", "startOffset": 177, "endOffset": 181}, {"referenceID": 33, "context": "However, the more challenging problem where the matrix W is partitioned column-wise as in (8), which leads to the \u201ccost-of-sum\u201d form showed earlier in (11), was not examined in [31], [34].", "startOffset": 183, "endOffset": 187}, {"referenceID": 12, "context": "The \u201csum-of-costs\u201d problem (20) is amenable to distributed implementations [13]\u2013[21].", "startOffset": 75, "endOffset": 79}, {"referenceID": 20, "context": "The \u201csum-of-costs\u201d problem (20) is amenable to distributed implementations [13]\u2013[21].", "startOffset": 80, "endOffset": 84}, {"referenceID": 12, "context": "Therefore, this formulation is not directly amenable to the distributed techniques from [13]\u2013[21].", "startOffset": 88, "endOffset": 92}, {"referenceID": 20, "context": "Therefore, this formulation is not directly amenable to the distributed techniques from [13]\u2013[21].", "startOffset": 93, "endOffset": 97}, {"referenceID": 34, "context": "In [35], the authors proposed a useful consensus-based primal-dual perturbation", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "In particular, diffusion strategies [14], [21], [39], consensus strategies [17]\u2013[20], or ADMM strategies [30], [31], [33], [40]\u2013[42] can now be applied to obtain the optimal dual variable \u03bd t in a distributed manner at the various agents.", "startOffset": 36, "endOffset": 40}, {"referenceID": 20, "context": "In particular, diffusion strategies [14], [21], [39], consensus strategies [17]\u2013[20], or ADMM strategies [30], [31], [33], [40]\u2013[42] can now be applied to obtain the optimal dual variable \u03bd t in a distributed manner at the various agents.", "startOffset": 42, "endOffset": 46}, {"referenceID": 35, "context": "In particular, diffusion strategies [14], [21], [39], consensus strategies [17]\u2013[20], or ADMM strategies [30], [31], [33], [40]\u2013[42] can now be applied to obtain the optimal dual variable \u03bd t in a distributed manner at the various agents.", "startOffset": 48, "endOffset": 52}, {"referenceID": 16, "context": "In particular, diffusion strategies [14], [21], [39], consensus strategies [17]\u2013[20], or ADMM strategies [30], [31], [33], [40]\u2013[42] can now be applied to obtain the optimal dual variable \u03bd t in a distributed manner at the various agents.", "startOffset": 75, "endOffset": 79}, {"referenceID": 19, "context": "In particular, diffusion strategies [14], [21], [39], consensus strategies [17]\u2013[20], or ADMM strategies [30], [31], [33], [40]\u2013[42] can now be applied to obtain the optimal dual variable \u03bd t in a distributed manner at the various agents.", "startOffset": 80, "endOffset": 84}, {"referenceID": 29, "context": "In particular, diffusion strategies [14], [21], [39], consensus strategies [17]\u2013[20], or ADMM strategies [30], [31], [33], [40]\u2013[42] can now be applied to obtain the optimal dual variable \u03bd t in a distributed manner at the various agents.", "startOffset": 105, "endOffset": 109}, {"referenceID": 30, "context": "In particular, diffusion strategies [14], [21], [39], consensus strategies [17]\u2013[20], or ADMM strategies [30], [31], [33], [40]\u2013[42] can now be applied to obtain the optimal dual variable \u03bd t in a distributed manner at the various agents.", "startOffset": 111, "endOffset": 115}, {"referenceID": 32, "context": "In particular, diffusion strategies [14], [21], [39], consensus strategies [17]\u2013[20], or ADMM strategies [30], [31], [33], [40]\u2013[42] can now be applied to obtain the optimal dual variable \u03bd t in a distributed manner at the various agents.", "startOffset": 117, "endOffset": 121}, {"referenceID": 36, "context": "In particular, diffusion strategies [14], [21], [39], consensus strategies [17]\u2013[20], or ADMM strategies [30], [31], [33], [40]\u2013[42] can now be applied to obtain the optimal dual variable \u03bd t in a distributed manner at the various agents.", "startOffset": 123, "endOffset": 127}, {"referenceID": 38, "context": "In particular, diffusion strategies [14], [21], [39], consensus strategies [17]\u2013[20], or ADMM strategies [30], [31], [33], [40]\u2013[42] can now be applied to obtain the optimal dual variable \u03bd t in a distributed manner at the various agents.", "startOffset": 128, "endOffset": 132}, {"referenceID": 14, "context": "Then, it holds that Vf = R and problem (30a)\u2013(30b) becomes an unconstrained optimization problem of the same general form as problems studied in [15], [16].", "startOffset": 145, "endOffset": 149}, {"referenceID": 15, "context": "Then, it holds that Vf = R and problem (30a)\u2013(30b) becomes an unconstrained optimization problem of the same general form as problems studied in [15], [16].", "startOffset": 151, "endOffset": 155}, {"referenceID": 15, "context": "Then, it is shown in [16] that as long as the matrix A is doubly-stochastic (i.", "startOffset": 21, "endOffset": 25}, {"referenceID": 39, "context": "Usually, Vf for these typical choices of f(u) are simple sets whose projection operators2 can be found in closed-form \u2014 see also [43].", "startOffset": 129, "endOffset": 133}, {"referenceID": 40, "context": "Once the constraint set Vf is found, it can be enforced either by incorporating local projections onto Vf into the combination step (31b) at each agent [44] or by using the penalized diffusion method [45].", "startOffset": 152, "endOffset": 156}, {"referenceID": 41, "context": "Once the constraint set Vf is found, it can be enforced either by incorporating local projections onto Vf into the combination step (31b) at each agent [44] or by using the penalized diffusion method [45].", "startOffset": 200, "endOffset": 204}, {"referenceID": 29, "context": "Inference over Distributed Models: ADMM Strategies An alternative approach to solving the dual inference problem (30a)\u2013(30b) is the distributed alternating direction multiplier method (ADMM) [30], [31], [40], [41], [46].", "startOffset": 191, "endOffset": 195}, {"referenceID": 30, "context": "Inference over Distributed Models: ADMM Strategies An alternative approach to solving the dual inference problem (30a)\u2013(30b) is the distributed alternating direction multiplier method (ADMM) [30], [31], [40], [41], [46].", "startOffset": 197, "endOffset": 201}, {"referenceID": 36, "context": "Inference over Distributed Models: ADMM Strategies An alternative approach to solving the dual inference problem (30a)\u2013(30b) is the distributed alternating direction multiplier method (ADMM) [30], [31], [40], [41], [46].", "startOffset": 203, "endOffset": 207}, {"referenceID": 37, "context": "Inference over Distributed Models: ADMM Strategies An alternative approach to solving the dual inference problem (30a)\u2013(30b) is the distributed alternating direction multiplier method (ADMM) [30], [31], [40], [41], [46].", "startOffset": 209, "endOffset": 213}, {"referenceID": 42, "context": "Inference over Distributed Models: ADMM Strategies An alternative approach to solving the dual inference problem (30a)\u2013(30b) is the distributed alternating direction multiplier method (ADMM) [30], [31], [40], [41], [46].", "startOffset": 215, "endOffset": 219}, {"referenceID": 36, "context": "For example, the method proposed in [40] relies on a set of bridge nodes for the distributed interactions among agents, and the method in [30], [31] uses a graph coloring approach to partition the agents in the network into different groups, and lets the optimization process alternate between different groups with one group of agents engaged at a time.", "startOffset": 36, "endOffset": 40}, {"referenceID": 29, "context": "For example, the method proposed in [40] relies on a set of bridge nodes for the distributed interactions among agents, and the method in [30], [31] uses a graph coloring approach to partition the agents in the network into different groups, and lets the optimization process alternate between different groups with one group of agents engaged at a time.", "startOffset": 138, "endOffset": 142}, {"referenceID": 30, "context": "For example, the method proposed in [40] relies on a set of bridge nodes for the distributed interactions among agents, and the method in [30], [31] uses a graph coloring approach to partition the agents in the network into different groups, and lets the optimization process alternate between different groups with one group of agents engaged at a time.", "startOffset": 144, "endOffset": 148}, {"referenceID": 37, "context": "In [41] and [46], the authors developed ADMM strategies that adopt Jacobian style updates with all agents engaged in the computation concurrently.", "startOffset": 3, "endOffset": 7}, {"referenceID": 42, "context": "In [41] and [46], the authors developed ADMM strategies that adopt Jacobian style updates with all agents engaged in the computation concurrently.", "startOffset": 12, "endOffset": 16}, {"referenceID": 32, "context": "This optimization problem generally requires an iterative algorithm to solve when it cannot be solved in closed-form, which adds a third time scale to the algorithm, as explained in [33] in the context of dictionary learning.", "startOffset": 182, "endOffset": 186}, {"referenceID": 0, "context": "For example, as explained in [1], the image denoising application requires recovery of z t as the final reconstructed image.", "startOffset": 29, "endOffset": 32}, {"referenceID": 15, "context": "As a result, the algorithms that optimize the dual problem (28a)\u2013(28b) can generally enjoy a fast (geometric) convergence rate [16], [22], [47].", "startOffset": 127, "endOffset": 131}, {"referenceID": 21, "context": "As a result, the algorithms that optimize the dual problem (28a)\u2013(28b) can generally enjoy a fast (geometric) convergence rate [16], [22], [47].", "startOffset": 133, "endOffset": 137}, {"referenceID": 43, "context": "As a result, the algorithms that optimize the dual problem (28a)\u2013(28b) can generally enjoy a fast (geometric) convergence rate [16], [22], [47].", "startOffset": 139, "endOffset": 143}, {"referenceID": 39, "context": "A typical approach to optimizing cost functions of this type is the proximal gradient method [43], [48]\u2013[50], which applies gradient descent to the first differentiable part followed by a proximal operator to the second non-differentiable part.", "startOffset": 93, "endOffset": 97}, {"referenceID": 44, "context": "A typical approach to optimizing cost functions of this type is the proximal gradient method [43], [48]\u2013[50], which applies gradient descent to the first differentiable part followed by a proximal operator to the second non-differentiable part.", "startOffset": 99, "endOffset": 103}, {"referenceID": 46, "context": "A typical approach to optimizing cost functions of this type is the proximal gradient method [43], [48]\u2013[50], which applies gradient descent to the first differentiable part followed by a proximal operator to the second non-differentiable part.", "startOffset": 104, "endOffset": 108}, {"referenceID": 39, "context": "However, the proximal gradient methods in [43], [48]\u2013[50] are developed for deterministic optimization, where the exact form of the objective function is known.", "startOffset": 42, "endOffset": 46}, {"referenceID": 44, "context": "However, the proximal gradient methods in [43], [48]\u2013[50] are developed for deterministic optimization, where the exact form of the objective function is known.", "startOffset": 48, "endOffset": 52}, {"referenceID": 46, "context": "However, the proximal gradient methods in [43], [48]\u2013[50] are developed for deterministic optimization, where the exact form of the objective function is known.", "startOffset": 53, "endOffset": 57}, {"referenceID": 20, "context": "Therefore, our strategy is to apply the proximal gradient method to the cost function in (44) and remove the expectation operator to obtain an instantaneous approximation to the true gradient; this is the approach typically used in adaptation [21], [22], [51] and stochastic approximation [52]:", "startOffset": 243, "endOffset": 247}, {"referenceID": 21, "context": "Therefore, our strategy is to apply the proximal gradient method to the cost function in (44) and remove the expectation operator to obtain an instantaneous approximation to the true gradient; this is the approach typically used in adaptation [21], [22], [51] and stochastic approximation [52]:", "startOffset": 249, "endOffset": 253}, {"referenceID": 47, "context": "Therefore, our strategy is to apply the proximal gradient method to the cost function in (44) and remove the expectation operator to obtain an instantaneous approximation to the true gradient; this is the approach typically used in adaptation [21], [22], [51] and stochastic approximation [52]:", "startOffset": 289, "endOffset": 293}, {"referenceID": 39, "context": "When this is not possible but the proximal operators of hWk(\u00b7) and IWk(\u00b7) are simple, it is preferable to apply a stochastic gradient descent step, followed by the proximal operator of hWk(\u00b7), and then the proximal operator of IWk(\u00b7) (equivalent to \u03a0Wk(\u00b7) [43], which is the projection onto Wk) in an incremental manner [53], thus leading to the following recursion:", "startOffset": 256, "endOffset": 260}, {"referenceID": 48, "context": "When this is not possible but the proximal operators of hWk(\u00b7) and IWk(\u00b7) are simple, it is preferable to apply a stochastic gradient descent step, followed by the proximal operator of hWk(\u00b7), and then the proximal operator of IWk(\u00b7) (equivalent to \u03a0Wk(\u00b7) [43], which is the projection onto Wk) in an incremental manner [53], thus leading to the following recursion:", "startOffset": 320, "endOffset": 324}, {"referenceID": 39, "context": "then the projection operator \u03a0Wk(\u00b7) is given by [43], [44]:", "startOffset": 48, "endOffset": 52}, {"referenceID": 40, "context": "then the projection operator \u03a0Wk(\u00b7) is given by [43], [44]:", "startOffset": 54, "endOffset": 58}, {"referenceID": 0, "context": "A third application to image denoising is considered in [1], [33].", "startOffset": 56, "endOffset": 59}, {"referenceID": 32, "context": "A third application to image denoising is considered in [1], [33].", "startOffset": 61, "endOffset": 65}, {"referenceID": 49, "context": "For the convenience of the experiments in this section and only to get an idea about how many iterations are typically needed for the inference step, we choose a data sample x from the training dataset, and use a non-distributed optimization package such as CVX [54] to compute the optimal solution y , col{yo 1, .", "startOffset": 262, "endOffset": 266}, {"referenceID": 0, "context": "In our experiments, network consists of N = 196 nodes in the image denoising example [1] and employs from N = 10 to N = 80 nodes in the novel document detection example.", "startOffset": 85, "endOffset": 88}, {"referenceID": 8, "context": "In the bi-clustering example, the network size, N , is three because of the application setup and the nature of the data from [9], where the rank of the data matrix is low so that three dictionary atoms are sufficient to represent the data.", "startOffset": 126, "endOffset": 129}, {"referenceID": 10, "context": "Novel Document Detection via Dictionary Learning In the novel document detection application [11], [24], [25], a stream of documents arrives in blocks at the network, and the task is to detect which of the documents in the incoming batch are associated with topics that have not been observed previously, and to incorporate the new block of data into the knowledge database to detect new topics/documents in future incoming batches.", "startOffset": 93, "endOffset": 97}, {"referenceID": 23, "context": "Novel Document Detection via Dictionary Learning In the novel document detection application [11], [24], [25], a stream of documents arrives in blocks at the network, and the task is to detect which of the documents in the incoming batch are associated with topics that have not been observed previously, and to incorporate the new block of data into the knowledge database to detect new topics/documents in future incoming batches.", "startOffset": 99, "endOffset": 103}, {"referenceID": 24, "context": "Novel Document Detection via Dictionary Learning In the novel document detection application [11], [24], [25], a stream of documents arrives in blocks at the network, and the task is to detect which of the documents in the incoming batch are associated with topics that have not been observed previously, and to incorporate the new block of data into the knowledge database to detect new topics/documents in future incoming batches.", "startOffset": 105, "endOffset": 109}, {"referenceID": 10, "context": "We compare our algorithm performance to that proposed in [11] under the same setup proposed there.", "startOffset": 57, "endOffset": 61}, {"referenceID": 10, "context": "The work [11] points out that some of the coefficients of the representation error u = xt \u2212Wy in text documents contain large, impulsive values.", "startOffset": 9, "endOffset": 13}, {"referenceID": 10, "context": "For this reason, the work [11] adopts the `1 loss f(u) = \u2016u\u20161 because this loss grows only linearly for large u and is less sensitive to large outliers.", "startOffset": 26, "endOffset": 30}, {"referenceID": 10, "context": "The setup is the same as in [11],5 except that we start with only ten dictionary atoms, and add ten additional atoms after each time-step.", "startOffset": 28, "endOffset": 32}, {"referenceID": 10, "context": "We compare our algorithm to the one proposed in [11], which simulates the setup where f(u) = \u2016u\u20161, hy(y) = \u2016y\u20161, and Wk = {w : \u2016w\u20161 \u2264 1}.", "startOffset": 48, "endOffset": 52}, {"referenceID": 10, "context": "Therefore, the choice of the penalty function f(u) is also slightly different, as we use Huber loss while [11] uses `1 loss.", "startOffset": 106, "endOffset": 110}, {"referenceID": 10, "context": "In contrast, when testing on the centralized ADMM-based algorithm from [11], the data are normalized so that \u2016xt\u20161 = 1 in keeping with the proposed simulation setup there.", "startOffset": 71, "endOffset": 75}, {"referenceID": 10, "context": "The constraint set for W for the diffusion-based algorithm is {W : \u2016[W ]:,q\u20162 \u2264 1, W 0}, while the constraint set for the ADMM-based algorithm from [11] is {W : \u2016[W ]:,q\u20161 \u2264 1, W 0}.", "startOffset": 148, "endOffset": 152}, {"referenceID": 10, "context": "For the initialization of the dictionary for the ADMM algorithm from [11], we let the algorithm iterate between the sparse coding step and the dictionary learning", "startOffset": 69, "endOffset": 73}, {"referenceID": 10, "context": "Kasiviswanathan for kindly sharing his MATLAB code through e-mail communication in order to reproduce the simulation in [11], including the ordered data.", "startOffset": 120, "endOffset": 124}, {"referenceID": 15, "context": "from which we can obtain the following scalar diffusion algorithm [16]: \uf8f2\uf8f3\u03c6k(i) = gk(i\u2212 1)\u2212 \u03bcg(Jk(\u03bd o t , \u03bet) + gk(i\u2212 1)) gk(i) = \u2211", "startOffset": 66, "endOffset": 70}, {"referenceID": 10, "context": "The sparse coding stages of the centralized ADMM-based algorithm from [11] utilize 35 iterations, and the number of iterations of the dictionary update steps are capped at 10 for all iterations other than the initialization step, which are the default setup in the code of [11].", "startOffset": 70, "endOffset": 74}, {"referenceID": 10, "context": "The sparse coding stages of the centralized ADMM-based algorithm from [11] utilize 35 iterations, and the number of iterations of the dictionary update steps are capped at 10 for all iterations other than the initialization step, which are the default setup in the code of [11].", "startOffset": 273, "endOffset": 277}, {"referenceID": 10, "context": "We observe that the performance of the centralized ADMM-based algorithm reproduced in this manuscript is competitive with that in [11], even though the initial dictionary size is chosen to be ten, as opposed to 200 atoms (as was done in the experiment in [11]).", "startOffset": 130, "endOffset": 134}, {"referenceID": 10, "context": "We observe that the performance of the centralized ADMM-based algorithm reproduced in this manuscript is competitive with that in [11], even though the initial dictionary size is chosen to be ten, as opposed to 200 atoms (as was done in the experiment in [11]).", "startOffset": 255, "endOffset": 259}, {"referenceID": 10, "context": "Furthermore, for our algorithm, since we are simulating a network of N agents on a single machine, we expect the computation time to be N times as much as that in [11] in order to have a Algorithm 2 Model-distributed diffusion strategy for distributed novel document detection (Huber Loss Residual).", "startOffset": 163, "endOffset": 167}, {"referenceID": 10, "context": "For this reason, we choose the setup for our algorithm (such as the number of inference iterations) to be about N times of that in [11] to ensure a fair comparison.", "startOffset": 131, "endOffset": 135}, {"referenceID": 10, "context": "6When applying the centralized gradient descent to the dual inference problem (30a)\u2013(30b) with 1000 iterations at a single machine, we found that the entire learning time over one time-step (1000 samples) is approximately the same as that of the ADMM-based method from [11] using the same MATLAB implementation for the time benchmark.", "startOffset": 269, "endOffset": 273}, {"referenceID": 10, "context": "l1-ADMM [11]", "startOffset": 8, "endOffset": 12}, {"referenceID": 10, "context": "Time Step ADMM [11] Diffusion (Fully Connected) Diffusion 1 0.", "startOffset": 15, "endOffset": 19}, {"referenceID": 8, "context": "Biclustering via Sparse Singular-Value-Decomposition Consider next the cancer data matrix X \u2208 RM\u00d7T from [9], where M = 56 and T = 12, 625.", "startOffset": 104, "endOffset": 107}, {"referenceID": 17, "context": "The problem was formulated in [18] as a biclustering task (see also Tables I\u2013II) that factorizes X as", "startOffset": 30, "endOffset": 34}, {"referenceID": 8, "context": "3, we list the algorithm from [9], which alternates between two sparse coding steps to obtain y and w, respectively.", "startOffset": 30, "endOffset": 33}, {"referenceID": 8, "context": "Observe that the algorithm is a batch algorithm, in that Algorithm 3 Simplified algorithm from [9] for biclustering.", "startOffset": 95, "endOffset": 98}, {"referenceID": 8, "context": "We choose N = 3 to be consistent with the setup in [9], where each node is responsible for a single dictionary atom.", "startOffset": 51, "endOffset": 54}, {"referenceID": 8, "context": "8, we plot, in the same manner as [9], the clustering results of Algorithms 3\u20134.", "startOffset": 34, "endOffset": 37}, {"referenceID": 15, "context": "For the inference problem (7), we applied the diffusion strategy, which has already been shown in prior studies [16] to converge within O(\u03bc) to the optimal inference solution.", "startOffset": 112, "endOffset": 116}, {"referenceID": 50, "context": "The conjugate function for the scalar Huber loss L(um) can be found in [55] as L(\u03bdm) = 12\u03bd 2 m with |\u03bdm| \u2264 1.", "startOffset": 71, "endOffset": 75}, {"referenceID": 51, "context": "188] [56]:", "startOffset": 5, "endOffset": 9}, {"referenceID": 46, "context": "Applying an argument similar to the one used in [50], we can express the optimal y k,t in (79) as", "startOffset": 48, "endOffset": 52}], "year": 2014, "abstractText": "In this paper, we consider learning dictionary models over a network of agents, where each agent is only in charge of a portion of the dictionary elements. This formulation is relevant in Big Data scenarios where large dictionary models may be spread over different spatial locations and it is not feasible to aggregate all dictionaries in one location due to communication and privacy considerations. We first show that the dual function of the inference problem is an aggregation of individual cost functions associated with different agents, which can then be minimized efficiently by means of diffusion strategies. The collaborative inference step generates dual variables that are used by the agents to update their dictionaries without the need to share these dictionaries or even the coefficient models for the training data. This is a powerful property that leads to an effective distributed procedure for learning dictionaries over large networks (e.g., hundreds of agents in our experiments). Furthermore, the proposed learning strategy operates in an online manner and is able to respond to streaming data, where each data sample is presented to the network once.", "creator": "LaTeX with hyperref package"}}}