{"id": "1402.4157", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Feb-2014", "title": "Conservative collision prediction and avoidance for stochastic trajectories in continuous time and space", "abstract": "mitrofanov Existing work in please multi - rotan agent yinchuan collision prediction and avoidance typically assumes discrete - time 68.2 trajectories with paec Gaussian tritos uncertainty or that tyana are dehz completely aristegui deterministic. vinje We ardennes propose an approach reborn that allows 471 detection 49.93 of collisions lc&dr even interrelatedness between continuous, stochastic trajectories deionized with the popoff only restriction auman that mamun means pashtuns and 107.12 covariances lcbo can be computed. To putting this rosaline end, lou\u00ffs we scrumhalf employ probabilistic bounds interacting to pfanner derive abderrahmane criterion margaery functions whose negative patres sign pyh\u00e4j\u00e4rvi provably oram is indicative i.o.c. of takaaki probable teshome collisions. r.f. For criterion functions that hamisah are orthophytum Lipschitz, p\u0113rkonkrusts an 7:05 algorithm is taguba provided non-perishable to rapidly rifampicin find negative values debeck or couvreur prove uhk their absence. We propose an 94.68 iterative chelan policy - search approach batha that hautes avoids prior file discretisations and yields shinki collision - free trajectories coxswain with xanterra adjustably leszczy\u0144ski high tosti certainty. We test our seining method outthink with both 1987-1988 fixed - overreached priority ergotamine and sanoussi auction - beauchief based protocols superkombat for hoshiyar coordinating the willowy iterative planning process. Results cordillera are 80-day provided in metroliners collision - netegrity avoidance ip-based simulations hathi of feedback controlled castellan plants.", "histories": [["v1", "Mon, 17 Feb 2014 21:46:26 GMT  (376kb,D)", "https://arxiv.org/abs/1402.4157v1", "This preprint is an extended version of a conference paper that is to appear in \\textit{Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2014)}"], ["v2", "Mon, 12 May 2014 15:38:42 GMT  (383kb,D)", "http://arxiv.org/abs/1402.4157v2", "This preprint is an extended version of a conference paper that is to appear in \\textit{Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2014)}"]], "COMMENTS": "This preprint is an extended version of a conference paper that is to appear in \\textit{Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2014)}", "reviews": [], "SUBJECTS": "cs.AI cs.MA cs.RO", "authors": ["jan-peter calliess", "michael osborne", "stephen roberts"], "accepted": false, "id": "1402.4157"}, "pdf": {"name": "1402.4157.pdf", "metadata": {"source": "CRF", "title": "Conservative collision prediction and avoidance for stochastic trajectories in continuous time and space", "authors": ["Jan-P. Calliess", "Michael Osborne", "Stephen Roberts"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Due to their practical importance, multi-agent collision avoidance and control have been extensively studied across different communities including AI, robotics and control. Considering continuous stochastic trajectories, reflecting each agent\u2019s uncertainty about its neighbours\u2019 time-indexed locations in an environment space, we exploit a distribution-independent bound on collision probabilities to develop a conservative collision-prediction module. It avoids\n\u2217The authours gratefully acknowledge funds via EPSRC EP/I011587.\nar X\niv :1\n40 2.\n41 57\nv2 [\ncs .A\nI] 1\ntemporal discretisation by stating collision-prediction as a one-dimensional optimization problem. If mean and standard deviation are computable Lipschitz functions of time, one can derive Lipschitz constants that allow us to guarantee collision prediction success with low computational effort. This is often the case, for instance, when dynamic knowledge of the involved trajectories is available (e.g. maximum velocities or even the stochastic differential equations).\nTo avoid collisions detected by the prediction module, we let an agent re-plan repeatedly until no more collisions occur with a definable probability. Here, replanning refers to modifying a control signal (influencing the basin of attraction and equilibrium point of the agent\u2019s stochastic dynamics) so as to bound the collision probability while seeking low plan execution cost in expectation. To keep the exposition concrete, we focus our descriptions on an example scenario where the plans correspond to sequences of setpoints of a feedback controller regulating an agent\u2019s noisy state trajectory. However, one can apply our method in the context of more general policy search problems.\nIn order to foster low social cost across the entire agent collective, we compare two different coordination mechanisms. Firstly, we consider a simple fixedpriority scheme [11], and secondly, we modify an auction-based coordination protocol [7] to work in our continuous setting. In contrast to pre-existing work in auction-style multi-agent planning (e.g. [7,16]) and multi-agent collision avoidance (e.g. [1, 2, 15]), we avoid a priori discretizations of space and time. Instead, we recast the coordination problem as one of incremental open-loop policy search. That is, as a succession of continuous optimisation or root-finding problems that can be efficiently and reliably solved by modern optimisation and root-finding techniques (e.g. [13, 23]).\nWhile our current experiments were conducted with linear stochastic differential equation (SDE) models with state-independent noise (yielding Gaussian processes), our method is also applicable to any situation where mean and covariances can be evaluated. This encompasses non-linear, non-Gaussian cases that may have state-dependent uncertainties (cf. [12]).\nThis preprint is an extended and improved version of a conference paper that appeared in Proc. of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2014) [6]."}, {"heading": "1.1 Related Work", "text": "Multi-agent trajectory planning and task allocation methods have been related to auction mechanisms by identifying locations in state space with atomic goods to be auctioned in a sequence of repeated coordination rounds (e.g. [7, 16, 26]). Unfortunately, even in finite domains the coordination is known to be intractable \u2013 for instance the sequential allocation problem is known to be NP-hard in the number of goods and agents [14, 22]. Furthermore, collision avoidance corresponds to non-convex interactions.\nThis renders the coordination problem inapplicable to standard optimization techniques that rely on convexity of the joint state space. In recent years, several works have investigated the use of mixed-integer programming techniques for\nsingle- and multi-agent model-predictive control with collision avoidance both in deterministic and stochastic settings [7, 19]. To connect the problem to preexisting mixed-integer optimization tools these works had to limit the models to dynamics governed by linear, time-discrete difference equations with stateindependent state noise. The resulting plans were finite sequences of control inputs that could be chosen freely from a convex set. The controls gained from optimization are open-loop \u2013 to obtain closed-loop policies the optimization problems have to be successively re-solved on-line in a receding horizon fashion. However, computational effort may prohibit such an approach in multi-agent systems with rapidly evolving states.\nFurthermore, prior time-discretisation comes with a natural trade-off. On the one hand, one would desire a high temporal resolution in order to limit the chance of missing a collision predictably occurring between consecutive time steps. On the other hand, communication restrictions, as well as poor scalability of mixed-integer programming techniques in the dimensionality of the input vectors, impose severe restrictions on this resolution. To address this tradeoff, [10] proposed to interpolate between the optimized time steps in order to detect collisions occurring between the discrete time-steps. Whenever a collision was detected they proposed to augment the temporal resolution by the timestep of the detected collision thereby growing the state-vectors incrementally as needed. A detected conflict, at time t, is then resolved by solving a new mixed-integer linear programme over an augmented state space, now including the state at t. This approach can result in a succession of solution attempts of optimization problems of increasing complexity, but can nonetheless prove relatively computationally efficient. Unfortunately, their method is limited to linear, deterministic state-dynamics.\nAnother thread of works relies on dividing space into polytopes [1,17], while still others [8,9,15,21] adopt a potential field. In not accommodating uncertainty and stochasticity, these approaches are forced to be overly conservative in order to prevent collisions in real systems.\nIn contrast to all these works, we will consider a different scenario. Our exposition focuses on the assumption that each agent is regulated by influencing its continuous stochastic dynamics. For instance, we might have a given feedback controller with which one can interact by providing a sequence of setpoints constituting the agent\u2019s plan. While this restricts the choice of control action, it also simplifies computation as the feedback law is fixed. The controller can generate a continuous, state-dependent control signal based on a discrete number of control decisions, embodied by the setpoints. Moreover, it renders our method applicable in settings where the agents\u2019 plants are controlled by standard offthe-shelf controllers (such as the omnipresent PID-controllers) rather than by more sophisticated customized ones. Instead of imposing discreteness, we make the often more realistic assumption that agents follow continuous time-state trajectories within a given continuous time interval. Unlike most work [1,21,25,27] in this field, we allow for stochastic dynamics, where each agent cannot be certain about the location of its team-members. This is crucial for many real-world multi-agent systems. The uncertainties are modelled as state-noise which can re-\nflect physical disturbances or merely model inaccuracies. While our exposition\u2019s focus is on stochastic differential equations, our approach is generally applicable in all contexts where the first two moments of the predicted trajectories can be evaluated for all time-steps. As noted above, this paper is an extended version of work that has been published in the proceedings of AAMAS\u201914 [6] and an earlier stage of this work was presented at an ICML [5] workshop."}, {"heading": "2 Predictive Probabilistic Collision Detection with", "text": "Criterion Functions\nTask. Our aim is to design a collision-detection module that can decide whether a set of (predictive) stochastic trajectories is collision-free (in the sense defined below). The module we will derive is guaranteed to make this decision correctly, based on knowledge of the first and second order moments of the trajectories alone. In particular, no assumptions are made about the family of stochastic processes the trajectories belong to. As the required collision probabilities will generally have to be expressed as non-analytic integrals, we will content ourselves with a fast, conservative approach. That is, we are willing to tolerate a non-zero false-alarm-rate as long as decisions can be made rapidly and with zero false-negative rate. Of course, for certain distributions and plant shapes, one may derive closed-form solutions for the collision probability that may be less conservative and hence, lead to faster termination and shorter paths. In such cases, our derivations can serve as a template for the construction of criterion functions on the basis of the tighter probabilistic bounds.\nProblem Formalization. Formally, a collision between two objects (or agents) a, r at time t \u2208 I := [t0, tf ] \u2282 R can be described by the event\nCa,r(t) = {(xa(t), xr(t))| \u2016xa(t)\u2212 xr(t)\u20162 \u2264 \u039ba+\u039br 2 }. Here, \u039b a,\u039br denote the objects\u2019 diameters, and xa, xr : I \u2192 RD are two (possibly uncertain) trajectories in a common, D-dimensional interaction space.\nIn a stochastic setting, we desire to bound the collision probability below a threshold \u03b4 \u2208 (0, 1) at any given time in I. We loosely say that the trajectories are collision-free if Pr[Ca,r(t)] < \u03b4, \u2200t \u2208 I.\nApproach. For conservative collision detection between two agents\u2019 stochastic trajectories xa, xr, we construct a criterion function \u03b3a,r : I \u2192 R (eq. as per Eq. 2 below). A conservative criterion function has the property \u03b3a,r(t) > 0 \u21d2 Pr[Ca,r(t)] < \u03b4a. That is, a collision between the trajectories with probability above \u03b4 can be ruled-out if \u03b3a,r attains only positive values. If one could evaluate the function t 7\u2192 Pr[Ca,r(t)], an ideal criterion function would be\n\u03b3a,rideal(t) := \u03b4 \u2212 Pr[C a,r(t)]. (1)\nIt is ideal in the sense that \u03b3a,rideal(t) > 0 \u21d4 Pr[Ca,r(t)] < \u03b4. However, in most cases, evaluating the criterion function in closed form will not be feasible. Therefore, we adopt a conservative approach: That is, we determine a\ncriterion function \u03b3a,r(t) such that provably, we have \u03b3a,r(t) \u2264 \u03b3a,rideal(t),\u2200t, including the possibility of false-alarms. That is, it is possible that for some times t, \u03b3a,r(t) \u2264 0, in spite of \u03b3a,rideal(t) > 0.\nUtilising the conservative criterion functions for collision-prediction, we assume a collision occurs unless mint\u2208I \u03b3\na,r(t) > 0,\u2200r 6= a. If the trajectories\u2019 means and standard deviations are Lipschitz functions of time then one can often show that \u03b3a,r is Lipschitz as well. In such cases negative values of \u03b3a,r can be found or ruled out rapidly, as will be discussed in Sec. 2.1. In situations where a Lipschitz constant is unavailable or hard to determine, we can base our detection on the output of a global minimization method such as DIRECT [13]."}, {"heading": "2.1 Finding negative function values of Lipschitz functions", "text": "Let t0, tf \u2208 R, t0 \u2264 tf , I := [t0, tf ] \u2282 R. Assume we are given a Lipschitz continuous target function f : I \u2192 R with Lipschitz constant L \u2265 0. That is, \u2200S \u2282 I \u2203LS \u2264 L\u2200x, x\u2032 \u2208 S : |f(x)\u2212 f(x\u2032)| \u2264 LS |x\u2212 x\u2032|. Let t0 < t1 < t2 < ... < tN < tf and define GN = (t0, . . . , tN+1) to be the sample grid of size N + 2 \u2265 2 consisting of the inputs at which we choose to evaluate the target f .\nOur goal is to prove or disprove the existence of a negative function value of target f ."}, {"heading": "2.1.1 A naive algorithm", "text": "As a first, naive method, Alg. 1 leverages Lipschitz continuity to answer the question of positivity correctly after a finite number of function evaluations.\nThe algorithm evaluates the function values on a finite grid assuming a uniform constant Lipschitz number L. The grid is iteratively refined until either a negative function value is found or, the Lipschitz continuity of function \u03b3 allows us to infer that no negative function values can exist. The latter is the case whenever mint\u2208GN \u03b3(t) > L\u2206 where GN = (t0, ..., tN+1) is the grid of function input (time) samples, \u2206 = |ti+1 \u2212 ti| (i = 0, ..., N \u2212 1) and L > 0 a Lipschitz number of the function \u03b3 : (t0, tf )\u2192 R which is to be evaluated.\nThe claim is established by the following Lemma:\nLemma 2.1. Let \u03b3 : [t0, tf ] \u2282 R \u2192 R be a Lipschitz function with Lipschitz number L > 0. Furthermore, let GN = (t0, t1, . . . , tN+1) be an equidistant grid with \u2206 = |ti+1 \u2212 ti| (i = 0, ..., N \u2212 1).\nWe have, \u03b3(t) > 0,\u2200t \u2208 (t0, tf ) if \u2200t \u2208 GN : \u03b3(t) > L\u2206.\nProof. Since L is a Lipschitz constant of \u03b3 we have |\u03b3(t)\u2212\u03b3(t\u2032)| \u2264 L|t\u2212t\u2032|,\u2200t, t\u2032 \u2208 (t0, tf ). Now, let t\n\u2217 \u2208 (t0, tf ) and ti, ti+1 \u2208 GN such that t\u2217 \u2208 [ti, ti+1]. Consistent with the premise of the implication we aim to show, we assume \u03b3(ti), \u03b3(ti+1) > L\u2206 and, without loss of generality, we assume \u03b3(ti) \u2264 \u03b3(ti+1). Let \u03b4 := |ti \u2212 t\u2217|. Since ti \u2264 t\u2217 \u2264 ti+1 we have 0 \u2264 \u2206 \u2212 \u03b4. Finally, 0 < L\u2206 < |\u03b3(ti)| implies \u03b3(t\u2217) \u2265 \u03b3(ti) \u2212 |\u03b3(ti) \u2212 \u03b3(t\u2217)| \u2265 \u03b3(ti) \u2212 L|ti \u2212 t\u2217| > L\u2206\u2212 L\u03b4 = L(\u2206\u2212 \u03b4) \u2265 0.\ninput : Domain boundaries t0, tf \u2208 R, function \u03b3 : (t0, tf )\u2192 R, Lipschitz constant L > 0. output: Flag flag indicating presence of a non-positive function value (flag = 1 indicates existence of a non-positive function value; flag =0 indicates it has been ruled out that a negative function value can exist). Variable criticalTime contains the time of a non-positive function value if such exists (criticalTime = t0 \u2212 1, iff \u03b3((t0, tf )) \u2282 R+).\nflag\u2190 \u22121; criticalTime\u2190 t0 \u2212 1; TimeGrid\u2190 {t0, tf}; r \u2190 \u22121; repeat\nr \u2190 r + 1; \u2206\u2190 tf\u2212t02r ; N \u2190 (tf \u2212 t0)/\u2206; TimeGrid\u2190 \u222aNi=0{t0 + i\u2206}; minVal\u2190 mint\u2208TimeGrid \u03b3(t); if minVal \u2264 0 then\nflag\u2190 1; criticalTime\u2190 arg mint\u2208TimeGrid \u03b3(t); else if minVal > L \u2206 then\nflag\u2190 0;\nuntil flag = 1 OR flag = 0;\nAlgorithm 1: Naive algorithm deciding whether a Lipschitz continuous function \u03b3 has a non-positive value on a compact domain. Note, if minVal > L \u2206 the function is guaranteed to map into the positive reals exclusively.\nAppart from a termination criterion, the lemma establishes that larger Lipschitz numbers will generally cause longer run-times of the algorithm as finer resolutions \u2206t will be required to ensure non-negativity of the function under investigation."}, {"heading": "2.1.2 An improved adaptive algorithm", "text": "Next, we will present an improved version of the algorithm provided above. We can define two functions, ceiling uN and floor lN , such that (i) they bound the target \u2200t \u2208 I : lN (t) \u2264 \u03b3(t) \u2264 uN (t), and (ii) the bounds get tighter for denser grids. In particular, one can show that lN , uN\nN\u2192\u221e\u2212\u2192 f uniformly if GN converges to a dense subset of [a, b]. Define \u03belN := arg minx\u2208I lN (x). It has been shown that \u03belN = min N\u22121 i=1 ti+1+ti 2 \u2212 \u03b3(ti+1)\u2212\u03b3(ti) 2L and lN (\u03be l N ) = mini \u03b3(ti+1)+\u03b3(ti) 2 \u2212 L ti+1\u2212ti 2 (see [13,23]). It is trivial to refine this to take localised Lipschitz constants into account: \u03belN = mini \u03b3(ti+1)+\u03b3(ti) 2 \u2212 LJi ti+1\u2212ti\n2 where LJi is a Lipschitz number valid on interval Ji = (ti, ti+1).\nThis suggests the following algorithm: We refine the grid GN to grid GN+1, by including \u03belN , f(\u03be l N ) as a new sample. This process is repeated until either of the following stopping conditions are met: (i) a negative function value of \u03b3 is discovered (f(\u03belN ) < 0), or (ii) lN (\u03be l N ) \u2265 0 (in which case we are guaranteed that no negative function values can exist). For pseudo-code refer to Alg. 2. An example run is depicted in Fig. 1. Note, without our stopping criteria, our algorithm degenerates to Shubert\u2019s minimization method [23]. The stopping criteria are important to save computation, especially in the absence of negative function values."}, {"heading": "2.2 Deriving collision criterion functions", "text": "This subsection is dedicated to the derivation of a (Lipschitz) criterion function. In lieu to the approach of [7, 20], the idea is to define hyper-cuboids Ha, Hr sufficently large to contain a large enough proportion of each agent\u2019s probability mass to ensure that no collision occurs (with sufficient confidence) as long as the\ninput : Domain boundaries t0, tf \u2208 R, function \u03b3 : (t0, tf )\u2192 R, Lipschitz constant L > 0. output: Flag flag indicating presence of a non-positive function value (flag = 1 indicates existence of a non-positive function value; flag =0 indicates it has been ruled out that a negative function value can exist). Variable criticalTime contains the time of a non-positive function value if such exists (criticalTime = t0 \u2212 1, iff \u03b3((t0, tf )) \u2282 R+).\nflag\u2190 \u22121; criticalTime\u2190 t0 \u2212 1; GN \u2190 {t0, tf}; N = 0; repeat\n\u03bel \u2190 minNi=1 ti+1+ti 2 \u2212 \u03b3(ti+1)\u2212\u03b3(ti) 2L ; lN (\u03be l N )\u2190 min N i=1 \u03b3(ti+1)+\u03b3(ti) 2 \u2212 L ti+1\u2212ti 2 ; minVal\u2190 \u03b3(\u03bel); if minVal \u2264 0 then\nflag\u2190 1; criticalTime\u2190 \u03bel; else if lN (\u03be l N ) > 0 then\nflag\u2190 0; else\nN \u2190 N + 1; GN \u2190 GN \u222a {\u03bel}; end\nuntil flag = 1 OR flag = 0;\nAlgorithm 2: Adaptive algorithm based on Shubert\u2019s method to prove whether a Lipschitz continuous function \u03b3 has a non-positive value on a compact domain. Note, if lN (\u03be l N ) > 0 the function is guaranteed to map into the positive reals exclusively.\ncuboids do not overlap. We then define the criterion function so as to negative values whenever the hyper-cuboids do overlap.\nFor ease of notation, we omit the time index t. For instance, in this subsection, xa now denotes random variable xa(t) rather than the stochastic trajectory.\nThe next thing we will do is to derive sufficient conditions for absence of collisions, i.e. for Pr[Ca,r] < \u03b4.\nTo this end, we make an intermediate step: For each agent q \u2208 {a, r} we define an open hyper-cuboid Hq centred around mean \u00b5q = \u3008xq(t)\u3009. As a Ddimensional hyper-cuboid, Hq is completely determined by its centre point \u00b5q and its edge lengths lq1, ..., l q D. Let O\nq denote the event that xq /\u2208 Hq and P q := Pr[Oq]. We derive a simple disjunctive constraint on the component distances of the means under which we can guarantee that the collision probability is not greater than the probability of at least one object being outside its hyper-cuboid. This is the case if the hypercuboids do not overlap. That is, their max-norm distance is at least \u039ba,r := \u039b a+\u039br\n2 . Before engaging in a formal discussion we need to establish a preparatory\nfact:\nLemma 2.2. Let \u00b5qj denote the jth component of object q\u2019s mean and r q j = 1 2 l q j . Furthermore, let Fa,r := Ca,r be the event that no collision occurs and Ba,r := Ha \u00d7 Hr the event that xa \u2208 Ha and xr \u2208 Hr. Assume the component-wise distance between the hyper-cuboids Ha, Hr is at least \u039ba,r, which is expressed by the following disjunctive constraint:\n\u2203j \u2208 {1, ..., D} : \u2223\u2223\u00b5aj \u2212 \u00b5rj\u2223\u2223 > \u039ba,r + raj + rrj .\nThen, we have : Ba,r \u2282 Fa,r.\nProof. Since \u2016x\u2016\u221e \u2264 \u2016x\u20162 ,\u2200x we have F\u221e := {(xa, xr)| \u2016xa \u2212 xr\u2016\u221e > \u039ba,r} \u2282 {(xa, xr)| \u2016xa \u2212 xr\u20162 > \u039ba,r} = Fa,r. It remains to be shown that Ba,r \u2282 F\u221e: Let (xa, xr) \u2208 Ba,r = Ha \u00d7 Ha. Thus, \u2200j \u2208 {1, ..., D}, q \u2208 {a, r} :\n\u2223\u2223xqj \u2212 \u00b5qj \u2223\u2223 \u2264 rqj . For contradiction, assume (xa, xr) /\u2208 F\u221e. Then, |xai \u2212 xri | \u2264 \u039ba,r for all i \u2208 {1, ..., D}.\nHence, |\u00b5ai \u2212 \u00b5ri | = |\u00b5ai \u2212 xai + xai \u2212 xri + xri \u2212 \u00b5ri | \u2264 |\u00b5ai \u2212 xai | + |xai \u2212 xri | + |xri \u2212 \u00b5ri | \u2264 rai + \u039ba,r + rri ,\u2200i \u2208 {1, ..., D} which contradicts our disjunctive constraint in the premise of the lemma. q.e.d.\nTheorem 2.3. Let \u00b5qj denote the jth component of object q\u2019s mean and r q j = 1 2 l q j . Assume, x\na, xr are random variables with means \u00b5a = \u3008xa\u3009, \u00b5r = \u3008xr\u3009, respectively. The max-norm distance between hypercuboids Ha, Hr is at least \u039ba,r > 0 (i.e. the hypercuboids do not overlap), which is expressed by the following disjunctive constraint:\n\u2203j \u2208 {1, ..., D} : \u2223\u2223\u00b5aj \u2212 \u00b5rj\u2223\u2223 > \u039ba,r + raj + rrj .\nThen, we have :\nPr[Ca,r] \u2264 P a + P r \u2212 P r P a \u2264 P a + P r\nwhere P q = Pr[xq /\u2208 Hq], (q \u2208 {a, r}).\nProof. As in Lem. 2.2, let Fa,r := Ca,r be the event that no collision occurs and let Ba,r := Ha \u00d7Hr. We have Pr[Ca,r] \u2264 1\u2212 Pr[Ca,r] = 1\u2212 Pr[Fa,r]. By Lem. 2.2 we have Ba,r \u2282 Fa,r and thus, 1\u2212 Pr[Fa,r] \u2264 1\u2212 Pr[Ba,r] = Pr[Ba,r]. Now, Pr[Ba,r] = Pr[xa /\u2208 Ha \u2228 xr /\u2208 Hr] = P a + P r \u2212 P a P r \u2264 P a + P r. q.e.d.\nOne way to define a criterion function is as follows:\n\u03b3a,r(t; %(t)) := max i=1,...,D {|\u00b5ai (t)\u2212 \u00b5ri(t)| \u2212 \u039ba,r \u2212 rai (t)\u2212 rri (t)} (2)\nwhere % = (ra1 , . . . , r a D, r r 1, . . . , r r D) is the parameter vector of radii. (For notational convenience, we will often omit explicit mention of parameter % in the function argument.)\nFor more than two agents, agent a\u2032s overall criterion function is \u0393a(t) := minr\u2208A\\{a} \u03b3\na,r(t). Thm. 2.3 tells us that the collision probability is bounded from above by the desired threshold \u03b4 if \u03b3a,r(t) > 0, provided we chose the radii raj , r r j (j = 1, ..., D) such that P a, P r \u2264 \u03b42 . Let q \u2208 {a, r}. Probability theory provides several distribution-independent bounds relating the radii of a (possibly partly unbounded) hypercuboid to the probability of not falling into it. That is, these are bounds of the form\nP q \u2264 \u03b2(rq1 , ..., r q D; \u0398)\nwhere \u03b2 is a continuous function that decreases monotonically with increasing radii and \u0398 represents additional information. In the case of Chebyshev-type bounds information about the first two moments are folded in, i.e. \u0398 = (\u00b5q, Cq) where Cq(t) \u2208 RD\u00d7D is the variance (-covariance) matrix. We then solve for radii that fulfil the inequality \u03b42 \u2265 \u03b2(r q 1 , ..., r q D; \u0398) while simultaneously ensuring collision avoidance with the desired probability. Inspecting Eq. 2, it becomes clear that, in order to maximally diminish conservatism of the criterion function, it would be ideal to choose the radii in % such that % = argmax%\u03b3 a,r(t; %) = argmaxra1 ,...,raDrr1,...,rrD maxi=1,...,D{|\u00b5 a i \u2212 \u00b5ri |\u2212 \u039ba,r\u2212rai\u2212rri} subject to the constraints \u03b42 \u2265 \u03b2(r q 1 , ..., r q D; \u0398), (q \u2208 {a, r}). Solving this constrained optimisation problem can often be done in closed form. In the context where \u03b2 is derived from a Chebyshev-type bound, we propose to set as many radii as large as possible (in order to decrease (\u03b2 to satisfy the constraints) while setting the radii rai , r r i as small as possible without violating the constraint (where i is some dimension). That is, we define the radii as follows: Set rqj := \u221e,\u2200j 6= i. The remaining unknown variable, r q i , then is defined as the solution to the equation \u03b42 = \u03b2(r q 1 , ..., r q D; \u0398). The resulting criterion function, denoted by \u03b3a,ri , we obtain with this procedure of course depends on the arbitrary choice of dimension i. Therefore, we obtain a less conservative criterion function by repeating this process for each dimension i and then constructing a new criterion function as the point-wise maximum: \u03b3a,r(t) := maxi \u03b3 a,r i (t).\nA concrete example of this procedure is provided below."}, {"heading": "2.2.1 Example constructions of distribution-independent criterion functions", "text": "We can use the above derivation as a template for generating criterion functions. Consider the following concrete example. Combining union bound and the\nstandard (one-dim.) Chebyshev bound yields P q = Pr[xq /\u2208 Hq] \u2264 \u2211D j=1 Cqjj rqj r q j =: \u03b2(rq1 , . . . , r q D;C q). Setting every radius, except rqi , to infinitely large values and \u03b2 equal to \u03b42 yields \u03b4 2 = Cqii rqi r q i , i.e. rqi = \u221a 2Cqii \u03b4 . (Note, this a correction of the radius provided in the conference version of this paper.) Finally, inserting these radii ( for q = a, r) into Eq. 2 yields our first collision criterion function:\n\u03b3a,r(t) := |\u00b5ai (t)\u2212 \u00b5ri(t)| \u2212 \u039ba,r \u2212 \u221a 2Caii(t) \u03b4 \u2212 \u221a 2Crii(t)\n\u03b4 . Of course, this argument can be made for any choice of dimension i. Hence,\na less conservative, yet valid, choice is\n\u03b3a,r(t) := max i=1,...,D\n|\u00b5ai (t)\u2212 \u00b5ri(t)| \u2212 \u039ba,r \u2212 \u221a 2Caii(t) \u03b4 \u2212 \u221a 2Crii(t) \u03b4 . (3)\nNotice, this function has the desirable property of being Lipschitz continuous, provided the mean \u00b5qi : I \u2192 R and standard deviation functions \u03c3qii = \u221a Cqii : I \u2192 R+ are. In particular, it is easy to show L(\u03b3a,r) \u2264 maxi=1,...,D L(\u00b5 a i ) + L(\u00b5 r i) + \u221a 2 \u03b4 ( L(\u03c3aii) + L(\u03c3 r ii) ) where, as before, L(f) denotes a Lipschitz constant of function f . For the special case of two dimensions, we can derive a less conservative alternative criterion function based on a tighter two-dimensional Chebyshevtype bound [28]:\nTheorem 2.4 (Alternative collision criterion function). Let spatial dimensionality be D = 2. Choosing\nrqi (t) := \u221a 1 2\u03b4a \u221a Cqii(t) + \u221a Cqii(t)C q jj(t)(C q ii(t)C q jj(t)\u2212(C q ij(t)) 2)\nCqjj(t)\n(q \u2208 {a, r}, i \u2208 {1, 2}, j \u2208 {1, 2} \u2212 {i}) in Eq. 2 yields a valid distributionindependend criterion function. That is, \u03b3a,r(t) > 0\u21d2 Pr[Ca,r(t)] < \u03b4a.\nA proof sketch and a Lipschitz constant (for non-zero uncertainty) are provided in the appendix. Note, the Lipschitz constant we have derived therein becomes infinite in the limit of vanishing variance. In that case, the presence of negative criterion values can be tested based on the sign of the minimum of the criterion function. This can be found employing a global optimiser. Future work will investigate, in how far Hoelder continuity instead of Lipschitz continuity can be leveraged to yield a similar algorithm as the one provided in Sec. 2.1.2."}, {"heading": "2.2.2 Multi-agent case.", "text": "Let a \u2208 A, A\u2032 \u2282 A such that a /\u2208 A\u2032 a subset of agents. We define the event that a collides with at least one of the agents in A\u2019 at time t as Ca,A \u2032 (t) :=\n{(xa(t), xr(t))|\u2203r \u2208 A\u2032 : \u2016xa(t)\u2212 xr(t)\u20162 \u2264 \u039b} = \u22c3 r\u2208A\u2032 C a,r. By union bound, Pr[Ca,A \u2032 (t)] \u2264 \u2211 r\u2208A\u2032 Pr[C a,r(t)].\nTheorem 2.5 (Multi-Agent Criterion). Let \u03b3a,r be valid criterion functions defined w.r.t. collision bound \u03b4a. We define multi-agent collision criterion function \u0393a,A \u2032 (t) := minr\u2208A\u2032 \u03b3 a,r(t). If \u0393a,A \u2032 (t) > 0 then the collision probability with A\u2019 is bounded below \u03b4a|A\u2032|. That is, Pr[Ca,A\u2032(t)] < \u03b4a|A\u2032|.\nProof. Let a \u2208 A, A\u2032 \u2282 A such that a /\u2208 A\u2032 a subset of agents. We define the event that a collides with at least one of the agents in A\u2019 at time t as Ca,A\n\u2032 (t) := {(xa(t), xr(t))|\u2203r \u2208 A\u2032 : \u2016xa(t)\u2212 xr(t)\u20162 \u2264 \u2206} = \u22c3 r\u2208A\u2032 C\na,r. We have established that if \u2200r \u2208 A\u2032 : \u03b3a,r(t) > 0 then Pr[Ca,r(t)] < \u03b4a,\u2200r \u2208 A\u2032. Now, let \u0393a,A \u2032 < \u03b4a. Hence,\u2200r \u2208 A\u2032 : \u03b3a,r(t) > 0. Thus, \u2200r \u2208 A\u2032 :\nPr[Ca,r(t)] < \u03b4a) Therefore, \u2211\nr\u2208A\u2032 Pr[C a,r(t)] \u2264 |A\u2032| \u03b4a. By union bound,\nPr[Ca,A \u2032 (t)] \u2264 \u2211 r\u2208A\u2032 Pr[C a,r(t)]. Consequently, we have Pr[Ca,A \u2032 (t)] \u2264 |A\u2032| \u03b4a. q.e.d.\nMoreover, \u0393a,A \u2032\nis Lipschitz if the constituent functions \u03b3a,r are (see Appendix B).\nOur distribution-independent collision criterion functions have the virtue that they work for all distributions \u2013 not only the omnipresent Gaussian. Unfortunately, distribution-independence is gained at the price of conservativeness ( ref. to Fig. 2). In our experiments in Sec. 4, the collision criterion function as per Thm. B.3 is utilized as an integral component of our collision avoidance mechanisms. The results suggest that the conservativeness of our detection module does not entail prohibitively high-false-alarm rates for the distributionindependent approach to be considered impractical. That said, whenever distributional knowledge can be converted into a criterion function. One could then\nuse our derivations as a template to generate refined criterion functions using Eq. 2 with adjusted radii ri,rj , reflecting the distribution at hand."}, {"heading": "3 Collision Avoidance", "text": "In this section we outline the core ideas of our proposed approach to multi-agent collision avoidance. After specifying the agent\u2019s dynamics and formalizing the notion of a single-agent plan, we define the multi-agent planning task. Then we describe how conflicts, picked-up by our collision prediction method, can be resolved. In Sec. 3.1 we describe the two coordination approaches we consider utilizing to generate conflict-free plans.\nI) Model (example). We assume the system contains a set A of agents indexed by a \u2208 {1, ..., |A |}. Each agent a\u2019s associated plant has a probabilistic state trajectory following stochastic controlled D-dimensional state dynamics (we consider the case D = 2) in the continuous interval of (future) time I = (t0, tf ]. We desire to ask agents to adjust their policies to avoid collisions. Each policy gives rise to a stochastic belief over the trajectory resulting from executing the policy. For our method to work, all we require is that the trajectory\u2019s mean function m : I \u2192 RD and covariance matrix function \u03a3 : I \u2192 RD\u00d7D are evaluable for all times t \u2208 I.\nA prominent class for which closed-form moments can be easily derived are linear stochastic differential equations (SDE s). For instance, we consider the SDE\ndxa(t) = K ( \u03bea(t)\u2212 xa(t) ) dt+B dW (4)\nwhere K,B \u2208 RD\u00d7D are matrices xa : I \u2192 RD is the state trajectory and W is a vector-valued Wiener process. Here, u(xa; \u03bea) := K(\u03bea \u2212 xa) could be interpreted as the control policy of a linear feedback-controller parametrised by \u03bea. It regulates the state to track a desired trajectory \u03bea(t) = \u03b6a0\u03c7{0}(t) +\u2211Ha i=1 \u03b6 a i \u03c7\u03c4ai (t) where \u03c7\u03c4i : R\u2192 {0, 1} denotes the indicator function of the halfopen interval \u03c4ai = (t a i\u22121, t a i ] \u2282 [0, T a] and each \u03b6ai \u2208 RD is a setpoint. If K is positive definite the agent\u2019s state trajectory is determined by setpoint sequence pa = (tai , \u03b6 a i ) Ha\ni=0 (aside from the random disturbances) which we will refer to as the agent\u2019s plan. For example, plan pa := ( (t0, x a 0), (tf , x a f ) )\ncould be used to regulate agent a\u2019s start state xa0 to a given goal state x a f between times t0 and tf . For simplicity, we assume the agents are always initialized with plans of this form before coordination commences.\nOne may interpret a setpoint as some way to alter the stochastic trajectory. Below, we will determine setpoints that modify a stochastic trajectory to reduce collision probability while maintaining low expected cost. From the vantage point of policy search, \u03bea is agent a\u2019s policy parameter that has to be adjusted to avoid collisions.\nII) Task. Each agent a desires to find a sequence of setpoints (pa) such that (i) it moves from its start state xa0 to its goal state x a f along a low-cost trajectory and (ii) such that along the trajectory its plant (with diameter \u2206)\ndoes not collide with any other agents\u2019 plant in state space with at least a given probability 1\u2212 \u03b4 \u2208 (0, 1).\nIII) Collision resolution. An agent seeks to avoid collisions by adding new setpoints to its plan until the collision probability of the resulting state trajectory drops below threshold \u03b4. For choosing these new setpoints we consider two methods WAIT and FREE. In the first method the agents insert a timesetpoint pair (t, xa0) into the previous plan p\na. Since this aims to cause the agent to wait at its start location xa0 we will call the method WAIT. It is possible that multiple such insertions are necessary until collisions are avoided. Of course, if a higher-priority agent decides to traverse through xa0, this method is too rigid to resolve a conflict. In the second method the agent optimizes for the time and location of the new setpoint. Let pa\u2191(t,s) be the plan updated by insertion of time-setpoint pair (t, s) \u2208 I \u00d7 RD. We propose to choose the candidate setpoint (t, s) that minimizes a function being a weighted sum of the expected cost entailed by executing updated plan pa\u2191(t,s) and a hinge-loss collision penalty cacoll(p a \u2191(t,s)) := \u03bb max{0,\u2212mint \u0393\na(t)}. Here, \u0393a is computed based on the assumption we were to execute pa\u2191(t,s) and \u03bb >> 0 determines the extent to which collisions are penalized. Since the new setpoint can be chosen freely in time and state-space we refer to the method as FREE."}, {"heading": "3.1 Coordination", "text": "We will now consider how to integrate our collision detection and avoidance methods into a coordination framework that determines who needs to avoid whom and at what stage of the coordination process. Such decisions are known to significantly impact the social cost (i.e. the sum of all agents\u2019 individual costs) of the agent collective.\nFixed-priorities (FP). As a baseline method for coordination we consider a basic fixed-priority method (e.g. [3,11]). Here, each agent has a unique ranking (or priority) according to its index a (i.e. agent 1 has highest priority, agent |A| lowest). When all higher-ranking agents are done planning, agent a is informed of their planned trajectories which it has to avoid with a probability greater than 1 \u2212 \u03b4. This can be done by repeatedly invoking for collision detection and resolution methods described above until no further collision with higherranking agents are found.\nLazy Auction Protocol (AUC). While the FP method is simple and fast the rigidity of the fixed ranking can lead to sub-optimal social cost and coordination success. Furthermore, its sequential nature does not take advantage of possible parallelization a distributed method could. To alleviate this we propose to revert the ranking flexibly on a case-by-case basis. In particular, the agents are allowed to compete for the right to gain passage (e.g. across a region where a collision was detected) by submitting bids in the course of an auction. The structure of the approach is outlined in Alg. 3.\nAssume an agent a detects a collision at a particular time step tcoll and\ninput : Agents a \u2208 A, cost functions ca, dynamics, initial start and goal states, initial plans p1, ..., p|A| . output: collision-free plans p1, ..., p|A|.\nrepeat for a \u2208 A do\n[ flag a, Ca, tcoll]\u2190 CollDetect a(a,A\u2212 {a}) if flaga = 1 then\nwinner\u2190 Auction(Ca \u222a {a}, tcoll) foreach r \u2208 (Ca \u222a {a})\u2212 {winner} do\npr \u2190 Avoidr((Ca \u222a {a})\u2212 {r}, tcoll) Broadcastr (pr)\nend\nend\nend\nuntil \u2200a \u2208 A : flaga = 0; Algorithm 3: Lazy auction coordination method (AUC) (written in a sequentialized form). Collisions are resolved by choosing new setpoints to enforce collision avoidance. Ca: set of agents detected to be in conflict with agent a. flaga: collision detection flag (=0, iff no collision detected). tcoll: earliest time where a collision was detected. Avoid: collision resolution method updating the plan by a single new setpoint according to WAIT or FREE.\ninvites the set of agents Ca = {r|\u03b3a,r(tcoll) \u2264 0} to join an auction to decide who needs to avoid whom. In particular, the auction determines a winner who is not required to alter his plan. The losing agents need to insert a new setpoint into their respective plans designed to avoid all other agents in Ca while keeping the plan cost function low.\nThe idea is to design the auction rules as a heuristic method to minimize the social cost of the ensuing solution. To this end, we define the bids such that their magnitude is proportional to a heuristic magnitude of the expected regret for losing and not gaining passage. That is agent a submits a bid ba = la \u2212 sa. Magnitude la is defined as a\u2019s anticipated cost caplan(p a \u2191(t,s)) for the event that the agent will not secure \u201cthe right of passage\u201d and has to create a new setpoint (t, s) (according to (III)) tailored to avoid all other agents engaged in the current auction. On the other hand, sa := caplan(p\na) is the cost of the unchanged plan pa. If there is a tie among multiple agents the agent with the lowest index among the highest bidders wins.\nAcknowledging that swinner+ \u2211\na6=winner l a is an estimated social cost (based\non current beliefs of trajectories) after the auction, we see that the winner determination rule greedily attempts to minimize social cost: bwinner \u2265 br \u21d4 \u2200r : sr + \u2211 a6=r l a \u2265 swinner + \u2211 a6=winner l a."}, {"heading": "4 Simulations", "text": "As a first test, we simulated three simple multi-agent scenarios, EXP1, EXP2 and EXP3. Each agent\u2019s dynamics were an instantiation of an SDE of the form of Eq. 4. We set \u03b4 to achieve collision avoidance with certainty greater than 95%. Collision prediction was based on the improved criterion function as per Thm. B.3. During collision resolution with the FREE method each agent a assessed a candidate plan pa according to cost function caplan(p\na) = w1 c a traj(p a) + w2 c a miss(p a) + w3 c a coll(p\na). Here catraj is a heuristic to penalize expected control energy or path length; in the second summand, camiss(p\na) =\u2225\u2225\u2225xa(tf )\u2212 xaf\u2225\u2225\u22252 penalizes expected deviation from the goal state; the third term cacoll(p\na) penalizes collisions (cf. III ). The weights are design parameters which we set to w1 = 10, w2 = 10 3 and w3 = 10 6, emphasizing avoidance of mission failure and collisions. Note, if our method was to be deployed in a receding horizon fashion, the parameters could also be adapted online using standard learning techniques such as no-regret algorithms [18,24].\nEXP1. Collision resolution was done with the WAIT method to update\nplans. Draws from the SDEs with the initial plans of the agents are depicted in Fig. 3 (left). The curves represent 20 noisy trajectories of agents 1 (red) and 2 (blue). Each curve is a draw from the stochastic differential dynamics obtained by simulating the execution of the given initial plan. The trajectories were simulated with the Euler-Maruyama method for a time interval of I = [0s, 2s]. The spread of the families of curves is due to the random disturbances each agent\u2019s controller had to compensate for during runtime.\nAgent 1 desired to control the state from start state x10 = (5, 10) to goal x1f = (5, 5). Agent 2 desired to move from start state x 2 0 = (5, 0) via intermediate goal x2f1 = (5, 7) (at 1s) to final goal state x 2 f2\n= (0, 7). While the agents meet their goals under the initial plans, their execution would imply a high probability of colliding around state (5, 6) (cf. Fig. 3 (left), Tab. 1). Coordination with fixed priorities (1 (red) > 2 (blue)) yields conflict-free plans (Fig. 3 (centre)). However, agent 2 is forced to wait too long at its start location to be able to reach intermediate waypoint x2f,1 in time and therefore, decides to move directly to its second goal. This could spawn high social cost due to missing one of the designated goals (Tab. 1 ). By contrast, the auction method is flexible enough to reverse the ranking at the detected collision point causing agent 1 to wait instead of 2 (Fig. 3 (right)). Thereby, agent 2 is able to reach both of its goal states in time. This success is reflected by low social cost (see Tab. 1).\nEXP2. The setup was analogous to EXP1 but with three agents and different start and goal states as depicted in Fig. 4. Furthermore, collisions were avoided with the FREE method with 10 random initializations of the local optimizer. Coordination of plans with fixed priorities (1 (red) > 2 (blue) > 3 (green) ) caused 2 to avoid agent 1 by moving to the left. Consequently, 3 now had to temporarily leave its start and goal state to get out of the way (see Fig. 4 (centre) ). With two agents moving to avoid collisions social cost was relatively\nhigh (see Tab. 1). During coordination with the auction-based method agent 2 first chose to avoid agent 1 (as in the FP method). However, losing the auction to agent 3 at a later stage of coordination, agent 2 decided to finally circumvent 1 by arcing to the right instead of to the left. This allowed 3 to stay in place (see Tab. 1).\nEXP3. Next, we conducted a sequence of experiments for varying numbers of agents ranging from |A| = 1, .., 7. In each experiment all agents\u2019 start locations were placed on a circle. Their respective goals were placed on the opposite ends of the circle. The eigenvalues of the feedback gain matrices of each agent were drawn at random from a uniform distribution on the range [2,7]. An example situation for an experiment with 5 agents is depicted in Fig. 5. Collision avoidance was achieved.\nNote, that despite this setting being close to worst case (i.e. almost all agents try to traverse a common, narrow corridor) the coordination overhead is moderate (see Fig. 6, right). Also, all collisions were successfully avoided (see Fig. 6, left)."}, {"heading": "5 Conclusions", "text": "This work considered multi-agent planning under stochastic uncertainty and non-convex chance-constraints for collision avoidance. In contrast to pre-existing work, we did not need to rely on prior space or time-discretisation. This was achieved by deriving criterion functions with the property that the collision probability is guaranteed to be below a freely definable threshold \u03b4 \u2208 (0, 1) if the criterion function attains no negative values. Thereby, stochastic collision detection is reduced to deciding whether such negative values exist. For Lipschitz criterion functions, we provided an algorithm for making this decision rapidly. We described a general procedure for deriving criterion functions and presented two such functions based on Chebyshev-type bounds. The advantage of using Chebyshev inequalities is their independence of the underlying distribution. Therefore, our approach is applicable to any stochastic state noise model for which the first two moments can be computed at arbitrary time steps. In particular, this would apply to models with state-dependent uncertainty and non-convex chance constraints which, to the best to our knowledge, have not been successfully approached in the multi-agent control literature. Nonetheless, future work could build on our results and derive less conservative criterion functions by using more problem-specific probabilistic inequalities. For instance, in simple cases such as additive Gaussian noise, tighter bounds can be given [4] and used in Eq. 2.\nTo enforce collision avoidance, our method modified the agent\u2019s plans until no collisions could be detected. To coordinate the detection and avoidance efforts of the agents, we employed an auction-based as well as a fixed-priority method.\nOur experiments are a first indication that our approach can succeed in\nfinding collision-free plans with high-certainty with the number of required coordination rounds scaling mildly in the number of agents. While in its present form, the coordination mechanism does not come with a termination guarantee, in none of our simulations have we encountered an infinite loop. For graph routing, [7] provides a termination guarantee of the lazy auction approach under mild assumptions. Current work considers if their analysis can be extended to our continuous setting. Moreover, if required, our approach can be combined with a simple stopping criterion that terminates the coordination attempt when a computational budget is expended or an infinite loop is detected.\nThe computation time within each coordination round depends heavily on the time required for finding a new setpoint and for collision detection. This involves minimizing (t, s) 7\u2192 caplan(pa\u2191(t,s)) and c a coll, respectively. The worstcase complexity depends on the choice of cost functions, their domains and the chosen optimizer. Fortunately, we can draw on a plethora of highly advanced global optimisation methods (eg [13, 23]) guaranteeing rapid optimization success. In terms of execution time, we can expect considerable alleviations from implementation in a compiled language. Furthermore, the collision detection and avoidance methods are based on global optimization and thus, would be highly amenable to parallel processing \u2013 this could especially benefit the auction approach.\nWhile our exposition was focussed on the task of defining setpoints of feedbackcontrolled agents, the developed methods can be readily applied to other policy search settings, where the first two moments of the probabilistic beliefs over the trajectories (that would result from applying the found policies) can be computed."}, {"heading": "A Derivations of the covariance and mean of the", "text": "feedback-controlled agents as deployed in the trajectory planning experiments\nWe will now solve the mean and covariance for the dynamics given by the ItoSDE describing the dynamics of the feedback controlled agents considered in the experiments of this paper. Our aim is to obtain closed-form solutions avoiding the need to approximate any integrals. This ameliorates the computational burden of our method since mean and covariance matrix functions need to be evaluated frequently in the course of collision detection and resolution.\nTheorem A.1. For all t \u2208 [t0, T ] let \u03be(t), x(t) \u2208 RD, A = diag(a1, ..., aD),K = diag(k1, ..., kD), B = diag( \u221a \u03bd1, ..., \u221a \u03bdD) and let x(t0) be a normally distributed random vector. The solution to the SDE dx = (Ax\u2212K(x\u2212 \u03be))dt + B dW is a Gaussian process with vector-valued mean function \u00b5 : [t0, T ]\u2192 RD and matrixvalued covariance function C : [t0, T ]\n2 \u2192 RD\u00d7D. Here the mean components are\n\u00b5j(t) = e (kj\u2212aj)(t0\u2212t) \u3008xj(t0)\u3009+ \u222b t t0 kj e (kj\u2212aj)(t\u0303\u2212t)\u03bej(t\u0303)dt\u0303\nand the covariance matrix function is C(s, t) = diag(cov11(s, t), ..., covDD(s, t)) where\ncovjj(s, t) = e (aj\u2212kj)(t+s\u22122t0)(\u3008x2j (t0)\u3009 \u2212 \u3008xj(t0)\u30092)\n+ \u03bdj\n2(kj \u2212 aj) [e(aj\u2212kj)|t\u2212s| \u2212 e(kj\u2212aj)(2t0\u2212(s+t))].\nProof. Let qj := kj \u2212 aj . Owing to the diagonal form of A,K and B and the independence of the output dimensions of the vector-valued Wiener process, the given SDE decomposes into a system of D indpendent 1-dimensional SDEs dxj = (\u2212qjxj+kj\u03bej)dt+ \u221a \u03bdjdWj (j = 1, ..., D) which can be treated separately.\nFor ease of notation we omit the subscripts yielding an SDE of the form: dx = (\u2212qx + k\u03be)dt + \u221a \u03bd dW . To solve each of these SDEs we introduce the substitution y := xeqt. With Ito\u2019s product rule we find\ndy = x deqt + eqt dx+ dx deqt\n= \u03bekeqt dt+ \u221a \u03bdeqtdW\nwhere the last equality follows from substitution of the SDE for dx and utilization the formal rules dt dW = 0, (dt)2 = 0.\nThis SDE is solved by y(t) = y(t0) + \u222b t t0 k\u03be(t\u0303)eqt\u0303dt\u0303+ \u222b t t0 eqt\u0303 \u221a \u03bddW (t\u0303) where\nthe last integral is to be interpreted as an Ito integral. Re-substitution yields\nx(t) = x(t0)e q(t0\u2212t) + \u222b t t0 k eq(t\u0303\u2212t)\u03be(t\u0303)dt\u0303+ \u222b t t0 eq(t\u0303\u2212t) \u221a \u03bddW (t\u0303).\nRandom variables x(t) (t \u2208 [t0, T ]) are given as affine transformations of a Wiener process. Since the Wiener process is Gaussian, the solution is clearly a Gaussian process as long as x(t0) is a normally distributed random variable.\nFor notational convenience we define\nJt := \u222b t t0 k eq(t\u0303\u2212t)\u03be(t\u0303) dt\u0303,\n\u2126t := \u222b t t0 eq(t\u0303\u2212t) \u221a \u03bd dW (t\u0303)\nand ct := x(t0)e q(t0\u2212t).\nTherefore, we can write\nx(t) = ct + Jt + \u2126t.\nIt remains to find the first and second moments. Owing to the linearity of the expectation and, since the expectation of the Ito integral of a non-anticipating integrand is zero, the mean function is:\n\u00b5(t) = \u3008x(t)\u3009 = \u3008ct\u3009+ \u3008Jt\u3009+ \u3008\u2126t\u3009 = \u3008x(t0)\u3009ek(t0\u2212t) + Jt.\nNow, we calculate the second moment:\ncov(s, t) = \u3008x(s)x(t)\u3009 \u2212 \u00b5(s)\u00b5(t)\nwhere\n\u3008x(s)x(t)\u3009 = \u3008(cs + Js + \u2126s)(ct + Jt + \u2126t)\u3009 = \u3008csct\u3009+ \u3008csJt\u3009+ \u3008cs\u2126t\u3009+ ...+ \u3008\u2126s\u2126t\u3009.\nOnce again leveraging that the expectation of an Ito integral with non-anticipating integrand is zero, the cross-terms \u3008cq\u2126r\u3009, \u3008Jq\u2126r\u3009 (q, r \u2208 {s, t}) vanish. Hence, we obtain\n\u3008x(s)x(t)\u3009 = \u3008csct\u3009+ \u3008csJt\u3009+ \u3008ctJs\u3009+ JtJs + \u3008\u2126s\u2126t\u3009 = \u3008csct\u3009+ Jt\u3008cs\u3009+ Js\u3008ct\u3009+ JtJs + \u3008\u2126s\u2126t\u3009 = \u00b5(s)\u00b5(t) + \u3008csct\u3009 \u2212 \u3008cs\u3009\u3008ct\u3009+ \u3008\u2126s\u2126t\u3009.\nHence,\ncov(s, t) = \u3008csct\u3009 \u2212 \u3008cs\u3009\u3008ct\u3009+ \u3008\u2126s\u2126t\u3009 = e\u2212q(t+s\u22122t0)(\u3008x2(t0)\u3009 \u2212 \u3008x(t0)\u30092) + \u3008\u2126s\u2126t\u3009\nIt is well-known that for non-anticipating f, g interval I we have \u3008 \u222b I f(t)dW (t) \u222b I g(t)dW (t)\u3009 = \u222b I f(t)g(t)dt.\nApplying this fact as well as leveraging the independent increments property of the Wiener process yields:\n\u3008\u2126s\u2126t\u3009 = \u03bd\neq(s+t) \u222b min{t,s} t0 e2qt\u0303dt\u0303\n= \u03bd\n2qeq(s+t) [e2kmin{t,s} \u2212 e2qt0 ]\n= \u03bd\n2q [eq(2 min{t,s}\u2212(s+t) \u2212 eq(2t0\u2212(s+t))]\n= \u03bd\n2q [e\u2212q|t\u2212s| \u2212 eq(2t0\u2212(s+t))]\nNotice, that when altering the plan and hence, \u03be, the integral\nJt,j := \u222b t t0 kj e (kj\u2212aj)(t\u0303\u2212t)\u03bej(t\u0303)dt\u0303\nhas to be computed. For general forms of allowable \u03be we would have to rely on numerical approximation methods. Since repeated calculations of solutions need to be done in the course of coordination we will want to alleviate the computational burden thereof as much as possible. This motivated our restriction to plans that give rise to step functions for which we can show that Jt is closed-form.\nLemma A.2. Let t \u2265 t0, t, t0 \u2208 [0, T a]. Given plan pa = ( (tai , \u03b6 a i ) )Ha i=0 where each \u03b6ai = (\u03b6 a i,j) D j=1. Let i = arg maxi{ti \u2264 t0}, i = arg mini{ti \u2265 t} and I := {i \u2208 {1, ...,Ha}|i < i \u2264 i}. Furthermore, let \u03beaj denote the jth component of step-function setpoint signal \u03bea. We have\u222b t\nt0\nkj e qj(t\u0303\u2212t)\u03beaj (t\u0303)dt\u0303\n= \u2211 i\u2208I kj qj \u03b6ai,j(e qj(min{ti,t}\u2212t) \u2212 eqj(max{ti\u22121,t0}\u2212t)).\nProof. Remember, \u03c4ai = (t a i\u22121, t a i ] \u2282 [0, T a]. We have\u222b t\nt0\nkj exp(qj(t\u0303\u2212 t))\u03beaj (t\u0303)dt\u0303\n= \u222b t t0 kj exp(qj(t\u0303\u2212 t)) Ha\u2211 i=1 \u03b6ai,j\u03c7\u03c4ai (t\u0303)dt\u0303\n= \u2211 i\u2208I \u222b min{t,ti} max{t0,ti\u22121} kj exp(qj(t\u0303\u2212 t))\u03b6ai,jdt\u0303\nCalculation of the anti-derivate and substitution of the integration bounds yields the desired result.\nWe immediately get the following corollary\nCorollary A.3. Let a \u2208 A be an agent with controlled plant dynamics\ndxa = (Axa \u2212K(xa \u2212 \u03bea))dt+B dW\nwhere for all t \u2208 [t0, T ]: \u03bea(t), xa(t) \u2208 RD, A = diag(a1, ..., aD), K = diag(k1, ..., kD), B = diag( \u221a \u03bd1, ..., \u221a \u03bdD). Let x a(t0) be a normally\ndistributed random vector. Assume a\u2019s plan is pa = ( (tai , \u03b6 a i ) )Ha 0=1 where each \u03b6ai = (\u03b6 a i,j) D j=1. Let t \u2265 t0, i = arg maxi{ti \u2264 t0}, i = arg mini{ti \u2265 t} and I := {i \u2208 {1, ...,Ha}|i < i \u2264 i}. Furthermore, let \u03beaj denote the jth component of step-function reference signal \u03bea.\nThe solution to agent a\u2019s SDE is a Gaussian process with vector-valued mean function \u00b5 : [t0, T ] \u2192 RD and matrix-valued covariance function C : [t0, T ]2 \u2192 RD\u00d7D. Here the mean components are\n\u00b5j(t) = e kj(t0\u2212t) \u3008xj(t0)\u3009 + \u2211 i\u2208I kj kj \u2212 aj \u03b6ai,j(e (kj\u2212aj)(min{ti,t}\u2212t) \u2212 e(kj\u2212aj)(max{ti\u22121,t0}\u2212t))\nand the covariance matrix function is C(s, t) = diag(cov11(s, t), ..., covDD(s, t)) where\ncovjj(s, t) = e (aj\u2212kj)(t+s\u22122t0)(\u3008x2j (t0)\u3009 \u2212 \u3008xj(t0)\u30092)\n+ \u03bdj\n2(kj \u2212 aj) [e(aj\u2212kj)|t\u2212s| \u2212 e(kj\u2212aj)(2t0\u2212(s+t))]."}, {"heading": "B Deriving Lipschitz numbers", "text": "So far, we have established how knowledge of the Lipschitz number of a Lipschitz function can be utilized to exclude the presence of any negative function values on a compact domain based on a finite number of function evaluations. To employ this insight in the context of collision detection we will have to know a Lipschitz number L of the criterion functions \u03b3a,r.\nWe may consider two cases:\n\u2022 We have a belief quantified as a distribution over the smallest Lipschitz constant L\u2032. Let the cumulative distribution function of this belief be denoted by F : R \u2192 [0, 1]. That is, F (x) = Pr[L\u2032 < x]. If we desire a guaranteed success of collision detection of at least \u03b4 \u2208 (0, 1) we invoke Alg.1 with a Lipschitz number L \u2265 min{x \u2208 R|F (x) \u2265 \u03b4} to detect nonpositive values of \u03b3a,r.\n\u2022 If we do not have such a belief function or desire complete certainty in collision detection success it may be possible to derive a Lipschitz number for the \u03b3a,r based on the mean and covariance functions of the agent\u2019s stochastic trajectories. In turn, these may be derived from the agents\u2019 SDEs. How this can be accomplished is the subject of the remainder of this section.\nB.1 Lipschitz arithmetic\nIn preparation of the derivations of Lipschitz numbers, we need to establish a few basic properties of Lipschitz continuous functions. As a convention, L\u03c6 will always denote the Lipschitz constant of a Lipschitz continuous function \u03c6.\nLemma B.1 (Lipschitz arithmetic). Let, I, J \u2282 R+. Let f : R\u2192 R be Lipschitz on I with Lipschitz number LI(f) and g : R\u2192 R be Lipschitz on J with Lipschitz number LJ(g). We have:\n1. Mapping t 7\u2192 |f(t)| is Lipschitz on I with constant LI(f).\n2. If g is Lipschitz on all of J = f(I) the concatenation g \u25e6 f : t 7\u2192 g(f(t)) is Lipschitz on I with Lipschitz constant LI(g \u25e6 f) \u2264 LJ(g)LI(f).\n3. Let r \u2208 R. r f : x 7\u2192 r f(x) is Lipschitz on I having a Lipschitz constant LI(r f) = |r|LI(f).\n4. f + g : t 7\u2192 f(t) + g(t) has Lipschitz number at most LI(f) + LJ(g).\n5. Let mf = supt\u2208I f(t) and mg = supt\u2208I g(t). Product function f \u00b7 g : x 7\u2192 f(x) g(x) has a Lipschitz number on I which is at most (mf LJ(g) + mg LI(f)).\n6. Let h(t) = max{f(t), g(t)},\u2200t \u2208 I\u2229J . We have LI\u2229J(h) = max{LI(f), LJ(g)}.\n7. Let b := inft\u2208I |f(t)| > 0 and let \u03c6(t) = 1f(t) ,\u2200t \u2208 I. Then LI(\u03c6) \u2264 b\u22122 LI(f) on I.\n8. f cont. differentiable on I \u21d2 LI(f) = supt\u2208I |f\u0307(t)|.\n9. Let c \u2208 R, f(t) = c,\u2200t \u2208 I. Then LI(f) = 0.\n10. LI(f 2) \u2264 2 s(f)LI(f).\n11. f cont. differentiable \u21d2 \u2200q \u2208 Q : LI(fq) = |q| sup\u03c4\u2208I |fq\u22121(\u03c4) f\u0307(\u03c4)|.\nProof. 1) We show |f | has the same Lipschitz number as f . Let t, t\u2032 \u2208 I arbitrary. We enter a case differentiation:\n1st case: f(t), f(t\u2032) \u2265 0. Hence, \u2223\u2223|f(t)| \u2212 |f(t\u2032)|\u2223\u2223 = \u2223\u2223f(t)\u2212 f(t\u2032)\u2223\u2223 f Lipschitz\u2264 LI(f)|t\u2212 t\u2032|.\n2nd case: f(t) \u2265 0, f(t\u2032) \u2264 0. Note, |y| = \u2212y, iff y \u2264 0. Hence, \u2223\u2223|f(t)| \u2212 |f(t\u2032)|\u2223\u2223 \u2264 \u2223\u2223|f(t)| + |f(t\u2032)|\u2223\u2223 = \u2223\u2223|f(t)| \u2212 f(t\u2032)\u2223\u2223 = \u2223\u2223f(t)\u2212 f(t\u2032)\u2223\u2223 \u2264 LI(f) |t\u2212 t\u2032|. 3rd case: f(t) \u2264 0, f(t\u2032) \u2265 0. Completely analogous to 2nd case.\n4th case: f(t), f(t\u2032) \u2264 0.\u2223\u2223|f(t)| \u2212 |f(t\u2032)|\u2223\u2223 = \u2223\u2223f(t\u2032)\u2212 f(t)\u2223\u2223 = \u2223\u2223f(t)\u2212 f(t\u2032)\u2223\u2223 f Lipschitz\u2264 LI(f)|t\u2212 t\u2032|. 2) For arbitrary t, t\u2032 \u2208 I we have:\u2223\u2223g(f(t)) \u2212 g(f(t\u2032))|\u2223\u2223 \u2264 LJ(g) |f(t) \u2212 f(t\u2032)| \u2264 LJ(g)LI(f) |t \u2212 t\u2032| where the\ntwo inequalities are due to the Lipschitz properties of g and f , respectively.\n3) For arbitrary t, t\u2032 \u2208 I, r \u2208 R we have:\u2223\u2223r f(t)\u2212 r f(t\u2032)|\u2223\u2223 = |r| |f(t)\u2212 f(t\u2032)| \u2264 |r|LI(f) |t\u2212 t\u2032|. 4) For arbitrary t, t\u2032 \u2208 I, r \u2208 R we have:\u2223\u2223g(t) + f(t)\u2212 (g(t\u2032) + f(t\u2032))|\u2223\u2223 = \u2223\u2223g(t)\u2212 g(t\u2032) + f(t)\u2212 f(t\u2032)|\u2223\u2223 \u2264 \u2223\u2223g(t)\u2212 g(t\u2032)\u2223\u2223+\u2223\u2223f(t)\u2212 f(t\u2032)|\u2223\u2223 \u2264 (LJ(g) + LI(f)) |t\u2212 t\u2032|. 5) Let t, t\u2032 \u2208 I, d := f(t)\u2212 f(t\u2032).\u2223\u2223g(t)f(t)\u2212 g(t\u2032)f(t\u2032)\u2223\u2223 = \u2223\u2223g(t)(f(t\u2032) + d)\u2212 g(t\u2032)f(t\u2032)\u2223\u2223 = \u2223\u2223(g(t)\u2212 g(t\u2032))f(t\u2032) +\ng(t)d \u2223\u2223 \u2264 \u2223\u2223g(t)\u2212g(t\u2032)\u2223\u2223|f(t\u2032)|+\u2223\u2223g(t)\u2223\u2223 |d| \u2264 LI(g)|t\u2212t\u2032||f(t\u2032)|+\u2223\u2223g(t)\u2223\u2223LI(f)|t\u2212t\u2032| \u2264\nLI(g)|t\u2212t\u2032| supt\u2032\u2208I{|f(t\u2032)|}+supt\u2208I{ \u2223\u2223g(t)\u2223\u2223}LI(f)|t\u2212t\u2032|= (LI(g) supt\u2032\u2208I{|f(t\u2032)|}+\nsupt\u2208I{ \u2223\u2223g(t)\u2223\u2223}LI(f))|t\u2212 t\u2032|.\n6) Proof in \u201d\u2018 Nick Weaver, Lipschitz algebras\u201d\u2019. 7) Let t, t\u2032 \u2208 I. \u2223\u2223 1 f(t)\u2212 1 f(t\u2032) \u2223\u2223= \u2223\u2223 f(t\u2032)f(t\u2032)f(t)\u2212 f(t)f(t\u2032)f(t) \u2223\u2223= \u2223\u2223f(t\u2032)\u2212f(t)\u2223\u2223\u2223\u2223f(t\u2032)\u2223\u2223\u2223\u2223f(t)\u2223\u2223 \u2264 LI(f)|t\u2212t\u2032|inft\u2208I |f(t)| . 8) Define ` := supt\u2208I |f\u0307(t)| = LI(f). In two steps, we show that ` is the smallest Lipschitz constant. Firstly, we show that it is a Lipschitz constant: Let t, t\u2032 \u2208 I, t < t\u2032. Due to the mean value theorem \u2203\u03be \u2208 [t, t\u2032] \u2282 I : |f(t)\u2212f(t \u2032)|\n|t\u2212t\u2032| = |f\u0307(\u03be)| \u2264 `. Secondly, we show that ` is the smallest Lipschitz constant: Let \u00af\u0300 be another Lipschitz constant such that \u00af\u0300\u2264 `. Since I is compact and f\u0307 is continuous there is some \u03be \u2208 I such that f\u0307(\u03be) = `. Pick any sequence (tk) \u221e k=1 such that tk\nk\u2192\u221e\u2212\u2192 \u03be. \u2200k : tk \u2208 I and \u00af\u0300 is a Lipschitz constant on I. Hence, \u00af\u0300\u2265 |f(tk)\u2212f(\u03be)||tk\u2212\u03be|\nk\u2192\u221e\u2212\u2192 |f\u0307(\u03be)| = `. Thus, \u00af\u0300= `.\n9) Immediate consequence of 8).\n10) L(f2) = L(f f) \u2264 s(f)L(f) +L(f)s(f) where the last inequality follows from property 5).\n11) L(fq) 8) = sup\u03c4\u2208I | dd tf q(\u03c4)| = |q| sup\u03c4\u2208I |fq\u22121(\u03c4) f\u0307(\u03c4)|.\nNotice, that several of the inequalities in the Lemma are not tight (Eg. Ineq. (5), (10) ). Therefore, it may sometimes be better not to apply it if instead one is able to determine the Lipschitz constant directly to yield a lower Lipschitz number.\nLemma B.2. For 0 < a < b let J \u2282 R+ be the domain interval of square root function \u221a \u00b7 : J \u2192 R+, t 7\u2192 \u221a t such that inf J = a and sup J = b. We have LJ( \u221a \u00b7) \u2264 1\n2 \u221a a\nwhere LJ( \u221a \u00b7) denotes the Lipschitz constant of the square root\nfunction on J .\nProof. Applying Lem. B.1 and leveraging differentiability of the square root function reduces the problem of determining a Lipschitz constant to finding supt\u2208J | d \u221a \u00b7 dt (t)| = supt\u2208J | 1 2 \u221a t |. Since d 2 dt2 \u221a \u00b7 = \u2212 1 4 \u221a \u00b73 attains only negative values on J \u2282 R+ we know that the first derivative d \u221a \u00b7 dt = 1 2 \u221a \u00b7 is strictly monotonously decreasing. Thus, supt\u2208J | d \u221a \u00b7 dt (t)| = d \u221a \u00b7 dt (inf J) = 1 2 \u221a inf J =\n1 2 \u221a a .\nB.2 An alternative collision-criterion function and the derivation of its Lipschitz number\nTheorem B.3 (Alternative collision criterion function). Let spatial dimensionality D = 2. Let \u03b4a \u2208 (0, 1) denote the maximum upper bound on instantaneous collision probability at time t agent a \u2208 A is allowed to tolerate. Let \u00b5a(t) \u2208 RD be the mean of trajectory xa and Caij(t) be the spatial between dimensions i and j at time t. For i \u2208 {1, 2}, j \u2208 {1, 2} \u2212 {i} let\nrai (t) := \u221a 1 2\u03b4a \u221a Caii(t) + \u221a Caii(t)C a jj(t)(C a ii(t)C a jj(t)\u2212(Caij(t))2)\nCajj(t) .\nLet a, r be two agents\u2019 plants whose radii sum to \u039ba,r with state trajectories xa, xr, respectively. Define\nba,rj (t, t \u2032) := raj (t) + r r j(t \u2032) + \u039ba,r.\nThe function\n\u03b3a,r(t) := max j\u2208{1,...,D} {|\u00b5aj (t)\u2212 \u00b5rj(t)| \u2212 b a,r j (t, t)}\nis a valid criterion function. That is, \u03b3a,r(t) > 0\u21d2 Pr[Ca,r(t)] < \u03b4a.\nProof. (Sketch) Let t \u2208 I be an arbitrary but fixed time. It is straight-forward to adapt the proof of Thm. 2 in [20] to our case showing that Pr[Ca,r(t)] < \u03b4a if |\u00b5aj (t) \u2212 \u00b5rj(t, t\u2032)| \u2212 bj(t, t\u2032) > 0 for at least one j \u2208 {1, . . . , D}. Hence, {t \u2208 I|\u03b3a,r(t, t) > 0} \u2282 {t \u2208 I|Pr[Ca,r(t)] < \u03b4a}.\nDefinition B.4. For future reference we define s : f 7\u2192 supt\u2208I |f(t)| and \u03b9 : f 7\u2192 inft\u2208I |f(t)| on the space of continuous functions on interval I.\nTheorem B.5. Let D = 2 be the dimensionality of state space. For any agent a let \u00b5aj : I = [t0, tf ] \u2192 R denote the jth component of a\u2019s mean function and Caij(t) the covariance of agent a\u2019s trajectory between dimension j and i at time t.\nFor q \u2208 {a, r} and all i, j \u2208 {1, . . . , D} assume the \u00b5qj , C q ij are Lipschitz on\nI with Lipschitz numbers L(\u00b5qj ) and Lipschitz numbers L(C q ij), respectively.\nLet \u03b3a,r denote the collision criterion function between agents a and r as defined in Thm. B.3.\nThen \u03b3a,r is Lipschitz on I with Lipschitz constant\nL(\u03b3a,r) \u2264 max j\u2208{1,...,D} {L(\u00b5aj \u2212 \u00b5rj) + L(b a,r j )}\n\u2264 max j\u2208{1,...,D} {L(\u00b5aj ) + L(\u00b5rj) + L(b a,r j )}\nwhere \u03b3a,r, ba,r, \u03b1a,r are defined as in Def. B.3 and \u2200i \u2208 {1, 2}, j \u2208 {1, 2} \u2212 {i} \u2200q \u2208 {a, r} we have:\n1. L(ba,rj ) \u2264 12 ( L(\u03b1aj ) + L(\u03b1 r j) ) ,\n2. L(\u03b1qi ) \u2264 \u221a 1 2\u03b4q 1 \u03b9(gi) L(gi)\nwhere gi(t) := C q ii(t) + \u221a (Cqii) 2 \u2212 Cqii ( Cqij )2 Cqjj and\nwhere (i)L(gi) \u2264 L(Cqii)+QL ( (Cqii) 2 ) +Qs( ( Cqij )2 )L ( Cqii Cqjj ) +QL( ( Cqij )2 )s ( Cqii Cqjj ) , and\n(ii)L(gi) \u2264 L(Cqii)+QL ( (Cqii) 2 ) +Qs(Cqii)L (( Cqij )2 Cqjj ) +QL ( Cqii ) s (( Cqij )2 Cqjj ) .\nHere, Q = inft\u2208I ( (Cqii(t)) 2 \u2212 Cqii(t) ( Cqij(t) )2 Cqjj(t) ) = inft\u2208I(gi \u2212 Cqii)2(t).\n3. also, L(\u03b1qj ) \u2264 12\u221aaL ( Cqjj Cqii ) s(\u03b1qi )+s (\u221a Cqjj Cqii ) L(\u03b1q1), where a = inft\u2208I Cqjj(t) Cqjj(t) ,\n4. L ( Cqii Cqjj ) \u2264 L(Cqjj)\u03b9(C q jj) \u22122s(Cqii)+s( 1 Cqjj\n)L(Cqii) if \u03b9(Cjj) = inft\u2208I |Cjj(t)| > 0,\n5. and similarly, L ( (Cqij) 2\nCqjj\n) \u2264 L(Cqjj)\u03b9(C q jj) \u22122s((Cqij)\n2) + s( 1 Cqjj )L((Cqij) 2) if\n\u03b9(Cqjj) = inft\u2208I |C q jj(t)| > 0.\n6. \u2200i, j \u2208 {1, 2} : L ( (Cqij) 2 ) \u2264 2 s(Cqij)L ( Cqij ) .\nProof. The equalities follow from successively applying Lem. B.1 to the definitions of the parts of the criterion function given in Thm. B.3. In our derivations we will note which of the properties of the Lemma we utilized as a superscript above the inequality sign. We have\nL(\u03b3a,r) def. = L(maxj\u2208{1,...,D}{|\u00b5aj \u2212 \u00b5rj | \u2212 b a,r j }) (6) = maxj\u2208{1,...,D} L(|\u00b5aj \u2212 \u00b5rj | \u2212 b a,r j ) \u2264 maxj\u2208{1,...,D} L(|\u00b5aj \u2212 \u00b5rj |) + L(b a,r j ) (1,3,4)\n\u2264 maxj\u2208{1,...,D} L(\u00b5aj ) + L(\u00b5rj) + L(b a,r j ).\nProof of Ineq. 1): By definition, L(ba,rj ) = L( 1 2 (\u03b1 a j (t) + \u03b1 r j(t \u2032)) + \u2206a,r)\n(3,4)\n\u2264 12 (L((\u03b1 a j ) + L(\u03b1 r j)) + L(\u2206 a,r) (9) = 12 (L((\u03b1 a j ) + L(\u03b1 r j)).\nFurthermore, to prove the remaining inequalities, assume q \u2208 {a, r}.\nProof of Ineq. 2): Let g(t) := Cqii(t)+ \u221a (Cqii) 2 \u2212 Cqii ( Cqij )2 Cqjj . Then, L(\u03b1q1) (3) =\u221a\n2 \u03b4a L(\n\u221a g) \u2264 \u221a 2 \u03b4q 1 2\u03b9(g)L(g)\nwhere the last inequality follows from Lem. B.2 and Lem. B.1.(2) as before.\nFurthermore, L(g) (4) \u2264 L(Cqii) + L( \u221a (Cqii) 2 \u2212 Cqii ( Cqij )2 Cqjj )\n= L(Cqii) + L (\u221a (Cqii) 2 \u2212 Cqii ( Cqij )2 Cqjj ) = L(Cqii) + QL ( (Cqii) 2 \u2212 Cqii ( Cqij )2 Cqjj ) where according to Lem. B.2, Q =\n\u03b9 (\n(Cqii) 2\u2212Cqii\n( Cqij )2 Cqjj ) . Hence, L(g) \u2264 L(Cqii) +QL ( (Cqii) 2 ) +QL ( Cqii ( Cqij )2 Cqjj ) .\nProof of Ineq. 3): We have L(\u03b1qj (t)) def = L( \u221a Cqjj Cqii \u03b1qi )\n(5) \u2264 s( \u221a\nCqjj Cqii )L(\u03b1qi ) + L( \u221a Cqjj Cqii )s(\u03b1qi )\n(2) \u2264 s( \u221a\nCq22 Cqii )L(\u03b1qi ) + LJ( \u221a \u00b7)L(C q jj Cqii )s(\u03b1qi ) where J = Cqjj Cqii (I). Inequality 2) now\nfollows from applying Lem. B.2.\nFrom here we can make two alternative derivations: i) L(g) \u2264 L(Cq11)+QL ( (Cq11) 2 ) +Qs( ( Cq12 )2 )L ( Cq11 Cq22 ) +QL( ( Cq12 )2 )s ( Cq11 Cq22 ) . Alternatively, one can obtain:\nii) L(g) \u2264 L(Cq11)+QL ( (Cq11) 2 ) +Qs(Cq11)L (( Cq12 )2 Cq22 ) +QL ( Cq11 ) s (( Cq12 )2 Cq22 ) .\nProof of Ineq. 4): L ( Cqii Cqjj ) = L ( Cqii 1 Cqjj ) (5) \u2264 L ( 1 Cqjj ) s ( Cqii ) +L ( Cqii ) s ( 1 Cqjj )\n(7) \u2264 b\u22122 L ( Cqjj ) s ( Cqii ) + L ( Cqii ) s (\n1 Cqjj\n) where b \u2208 R+ chosen such that\nCqjj(I) \u2229 [\u2212b, b] = \u2205 (we assume such a b exists). A valid choice certainly is b := inft\u2208I |Cqjj(t)|.\nProof of Ineq. 5): Completely, analogous to proof of 4).\nProof of Ineq. 6): Consequence of Lem. B.1.(10).\nThe theorem provides a recipe to find a Lipschitz bound for the collision criterion function given known Lipschitz numbers of the trajectories\u2019 means and spatial covariance mappings.\nHowever, since most equalities are not tight one should attempt to determine Lipschitz numbers directly wherever possible rather than using the inequalities provided in Lem. B.1. For instance, if one can determine the best Lipschitz number for L ( (Cqij) 2 )\ndirectly (e.g. by utilizing Lem B.1.11) this would normally yield a better Lipschitz constant than obtained by expanding into 2 s(Cqij)L ( Cqij )\ndue to application of Lem. B.1.6. Examining the terms in the inequalities we notice the occurrence of suprema\nof covariances s(Cij) or inverted covariances of the form s( 1 Cii\n). The latter requires non-vanishing uncertainty in our model. Furthermore, note, the need to evaluate know the extrema is not to burdensome as they can be rapidly found by pre-existing Lipschitz optimizers which are highly efficient. However, in many cases the optima are known a priori. For instance, if one knows that the uncertainty monotonously increases over time we have e.g. s(Cqij) = C q ij(inf I) and s( 1 Cqij ) = Cqij(sup I). Alternatively, the covariances may allow for an analytic closed-form solution of the extremum which may be analytically derived before run-time.\nWe will revisit these issues in Sec. B.3 where we examine a concrete application of the theorem to a multi-agent control scenario.\nB.3 A Lipschitz number for the criterion function of our feedback-controlled agents\nLet a \u2208 A be an agent with controlled plant dynamics given by the Ito-SDE\ndxa = K(\u03bea \u2212 xa)dt+B dW.\nHere xa(t) \u2208 RD denotes the agent a\u2032s state (e.g. location), \u03bea(t) \u2208 RD is the agent\u2019s setpoint signal at time t \u2208 I = [t0, tf ]. Furthermore, K = diag(k1, ..., kD) > 0 is the controller\u2019s gain matrix and B = diag( \u221a \u03bd1, ..., \u221a \u03bdD) reflects the magnitude of the uncertainties (disturbances). Let uncertain start state xa(t0) be a normally distributed random vector. Assume a\u2019s plan is\npa = ( (tai , \u03b6 a i ) )Ha 0=1 where each \u03b6ai = (\u03b6 a i,j) D j=1. Let t \u2265 t0, i = arg maxi{ti \u2264 t0},\ni = arg mini{ti \u2265 t} and I := {i \u2208 {1, ...,Ha}|i < i \u2264 i}. Furthermore, let \u03beaj denote the jth component of step-function reference signal \u03bea.\nFor ease of notation we will drop the agent superscripts throughout the remainder of this subsection. The solution to agent a\u2019s SDE is a Gaussian process with vector-valued mean function \u00b5a : [t0, tf ]\u2192 RD and matrix-valued covariance function Ca : [t0, tf ]\n2 \u2192 RD\u00d7D. By applying Ito-calculus to the suitable expectations of the SDE we can show that we have\n\u00b5aj (t) = e kaj (t0\u2212t) \u3008xaj (t0)\u3009+ kaj e\u2212k a j t \u222b t t0 ek a j t\u0303\u03beaj (t\u0303)dt\u0303.\nThe covariance matrix function is (s, t) 7\u2192 diag(cova11(s, t), ..., covaDD(s, t)) where\ncovajj(s, t) = e \u2212kaj (t+s\u22122t0)(\u3008 ( xaj (t0) )2\u3009 \u2212 \u3008xaj (t0)\u30092) +\n\u03bdaj 2kaj [e\u2212k a j |t\u2212s| \u2212 ek a j (2t0\u2212(s+t))].\nUsing the notation of Thm. B.5 we have Cajj(t) = cov a jj(t, t)\n= e\u2212k a j 2(t\u2212t0)(\u3008 ( xaj (t0) )2\u3009 \u2212 \u3008xaj (t0)\u30092) + \u03bdaj2kaj [1\u2212 ekaj 2(t0\u2212t)] = e\u2212k a j 2(t\u2212t0) ( Cajj(t0)\u2212\n\u03bdaj 2kaj\n) +\n\u03bdaj 2kaj .\nwhere Cajj(t0) is assumed to be a known quantification of the initial state uncertainty.\nNext we will derive Lipschitz constants for the the component means and covariances which is necessary to derive a Lipschitz number for the collision criterion function.\nFirstly, we consider the mean function. Defining va(t) := ek a j (t0\u2212t) \u3008xaj (t0)\u3009,\nwa(t) := kaj e \u2212kaj t and q\u0307a(t) := ek a j t\u03beaj (t) we we can restate the component mean function maj as \u00b5aj (t) = v a j (t) + w a j (t) q a j (t).\nLeveraging Lem. B.1 we see that L ( \u00b5aj ) \u2264 L(vaj ) + s(waj )L(qaj ) + s(qaj )L(waj ) (5) \u2264 s(v\u0307aj ) + s(waj ) s(q\u0307aj ) + s(qaj ) s(waj ) (6)\nwhere as before s(f) = supt\u2208I |f(t)| for any function f . Evaluation of the suprema depends on the setpoint signal \u03be and on the kj . For instance, choosing a constant setpoint \u03be and kj > 0 would yield:\n\u2022 s(v\u0307aj ) = supt\u2208[t0,tf ] | \u2212 k a j \u3008xaj (t0)\u3009ek\na j t0e\u2212k a j t| = |kj\u3008xaj (t0)\u3009| where the last\nequality holds since e\u2212k a j t decreases monotonically,\n\u2022 s(waj ) = supt\u2208[t0,tf ] |k a j e \u2212kaj t| = |kaj |e\u2212k a j t0 ,\n\u2022 s(q\u0307aj ) = supt\u2208[t0,tf ] |\u03be a j e kaj t| = |\u03beaj | ek a j tf ,\n\u2022 s(qaj ) = supt\u2208[t0,tf ] | \u222b t t0 ek a j t\u0303\u03beaj dt\u0303| = | \u03beaj kaj [ek a j tf \u2212 ek a j t0 ]|. Here we leveraged\nthe monotonicity of the exponential function.\nNext, we derive Lipschitz constants for the covariances:\nNote the cross-covariances are zero Caij(t) = 0,\u2200t, i 6= j. Fortunately, the diagonal of the covariance matrix function are also continuously differentiable. In particular, we have C\u0307ajj(t) = \u2212kaj 2e\u2212k a j 2(t\u2212t0) ( Cajj(t0) \u2212 \u03bdaj 2kaj ) . We can once again utilize Lem. B.1 yielding a Lipschitz bound\nL(Cajj) \u2264 s ( C\u0307ajj )\n\u2264 sup t\u2208[t0,tf ]\n|kaj 2 ( Cajj(t0)\u2212\n\u03bdaj 2kaj\n) |e\u2212k a j 2(t\u2212t0)\n= |kaj 2 ( Cajj(t0)\u2212\n\u03bdaj 2kaj\n) |.\nwhere the last equality follows from the fact that t 7\u2192 exp(\u2212kj2(t \u2212 t0)) is monotonically decreasing.\nIn summary, we have found\nL(Cajj) \u2264 |kaj 2 ( Cajj(t0)\u2212\n\u03bdaj 2kaj\n) |, (7)\nL(Ca12) = L(C a 21) = 0, (8)\nL(\u00b5aj ) \u2264 s(v\u0307aj ) + s(waj )s(q\u0307aj ) + s(qaj )s(waj ), (9)\n=|kaj \u3008xaj (t0)\u3009|+ |kaj ||\u03beaj | ek a j (tf\u2212t0) + |\u03beaj [ek a j (tf\u2212t0) \u2212 1]|. (10)\nNext, we combine our estimates of the mean and covariances with Lem. B.1 and Thm. B.5 to derive a Lipschitz number for the criterion function defined in Thm. B.3. Let q \u2208 {a, r}. Since L(Cq12) = 0 we have gi(t) :=\nCqii(t) + \u221a (Cqii) 2 \u2212 Cqii ( Cqij )2 Cqjj = 2Cqii(t). By Thm. B.5.2, this implies L(\u03b1 q i ) \u2264\u221a\n1 2\u03b4q 1 \u03b9(gi)\nL(gi) = \u221a 1 2\u03b4q 1 \u03b9(2Cqii) L(2Cqii) = \u221a 1 2\u03b4q 1 \u03b9(Cqii) L(Cqii) where the last equal-\nity is due to Lem. B.1.3 and due to the fact that inft |r f(t)| = |r| inft |f(t)| for all constants r, functions f . Next, we determine \u03b9(Cqii). By inspecting its derivative, we notice that Cqii is strictly monotonously increasing iff C q ii(t0)\u2212 vqi 2kqi < 0 and monotonously decreasing otherwise. Also, Cqii does not attain negative values implying Cqii =\n\u2223\u2223Cqii\u2223\u2223. Hence, \u03b9(Cqii) = inf{|C q ii(I)|} = inf{C q ii(I)}\n= C q ii(t0), if C q ii(t0) < vqi 2kqi ;\nCqii(tf ), if C q ii(t0) \u2265 vqi 2kqi ; Now, we have all the necessary ingredients\nto utilize Thm. B.5 in order to wrap-up:\nL(\u03b3a,r) \u2264 maxj{L(\u00b5aj ) + L(\u00b5rj) + L(b a,r j )}\n\u2264 maxj{L(\u00b5aj ) + L(\u00b5rj) + 12L(\u03b1 a j ) + 1 2L(\u03b1 r j)} \u2264 maxj { |kaj\u00b5aj (t0)| + |kaj ||\u03beaj |ek a j (tf\u2212t0) + |\u03beaj [ek a j (tf\u2212t0) \u2212 1]| + |krj\u00b5rj(t0)| + |krj ||\u03berj |ek r j (tf\u2212t0)+|\u03berj [ek r j (tf\u2212t0)\u22121]|+ 12 \u221a 1 2\u03b4a 1 \u03b9(Cajj) L(Cajj)+ 1 2 \u221a 1 2\u03b4r 1 \u03b9(Crjj) L(Crjj) } .\nWe can see that this Lipschitz number might adopt large values in certain parts of the domain. Therefore, it might be helpful to recompute the Lipschitz numbers adaptively for different parts of the domain."}, {"heading": "C Utilising priors encoding belief over change", "text": "of sign of a criterion function\nDetection of collisions is based on excluding the possibility of negative criterion function values. However, as these functions are non-convex any numerical procedure executed on a digital computer has to achieve this with only a finite number of function evaluations. Given this, what is our confidence in not having missed a negative criterion function value?\nThus far, we have proposed using a knowledge (i.e. a prior) about a Lipschitz number of the criterion function to rule out collisions in continuous time based on a finite number of samples. In addition to the Lipschitz-based method presented above, we will now consider an alternative method that assumes a prior belief about the anticipated change of sign of a criterion function.\nBefore commencing it will prove helpful to introduce the notion of a sign change point (SCP). An SCP is a time step which is the border between two changes in sign of a function. More precisely, time t is an SCP of function f if there exist open intervals I \u2032 := (t\u2032, t) and I \u2032\u2032 := (t, t\u2032\u2032) such that sgn(f(\u03c4 \u2032)) 6= sgn(f(\u03c4 \u2032\u2032)),\u2200\u03c4 \u2032 \u2208 I \u2032, \u03c4 \u2032\u2032 \u2208 I \u2032\u2032.\nTo give an example, consider the function\n\u03c6 : t 7\u2192 \u2212t \u03c7R\u2212(t) + 0\u03c7[0,1](t) + (t\u2212 1)\u03c7R>1(t).\nAs before, \u03c7S denotes the indicator function of set S. Function \u03c6 has exactly two SCPs \u2013 at t = 0 and t = 1.\nResuming with our discussion, assume we are given f(t0), ..., f(tk) on a lattice of times (0 = t0 < ... < tk = T ). If f(ti) \u2264 0 for some ti we will want to conservatively assume a collision has occurred. On the other hand, if all evaluations are positive we desire to specify our confidence that all intermittent unobserved values are. This is the case if no SCPs occur. The presence of an odd number of SCPs between two time steps ti, ti+1 is detectable by checking sgn(f(ti)) 6= sgn(f(ti+1)). In fact, if the total number n of SCPs in [0, T ] is\nodd we will detect a change of sign. By contrast, if an even number of SCPs occur we have sgn(f(ti)) = sgn(f(ti+1)) and hence, will be oblivious of negative function values in the interval (ti, ti+1).\nNow, assume we are given a distribution Q : N \u2192 [0, 1] representing our belief over the number of occurring SCPs. By the law of total probability, our belief that we will miss the existence of a collision is\u2211\nn\u22082N Pn,kQ[n] (11)\nwhere Pn,k denotes the probability of missing the existence of a collision during collision detection given that n SCPs occur in the interior of the lattice.\nIn preparation of the next theorem we need the following result:\nLemma C.1 (Improved bound). Given a set S = {s1, ..., sn} of n \u2208 2N objects let P be the number of ways the set can be partitioned into pairs, i.e. P = |{{P1, ...,Pn/2}|\u2200i 6= j : Pi \u2229 Pj = \u2205, \u22c3 iPi = {s1, ..., sn},\u2200i\u2203q 6= r : Pi = {sq, sr}}|. We have P \u2264 ( n(n\u22121)/2\nn/2\n) .\nProof. We can create (n2 \u2212 n)/2 = n(n\u2212 1)/2 distinct sets of the form {sq, sr} of cardinality two. That is, |T | = n(n \u2212 1)/2 where T = {{si, sj}|i 6= j, i, j = 1, ..., n}.\nTo generate a partition {P1, ...,Pn/2} we need to select a subset of T containing n/2 two-element sets. Conservatively (not taking into account that not every n/2 -element subset is an actual partition), this could be done in at most( n(n\u22121)/2\nn/2\n) ways. Hence P \u2264 ( n(n\u22121)/2\nn/2\n) .\nTheorem C.2. Assume we are given n \u2208 2N0 SCPs s1, ..., sn whose locations are drawn independently from an identical distribution (drawn i.i.d.). Furthermore, we are given a grid of test points 0 = t0 < t1 < ... < tk = T where the intermediate times are chosen such that \u2200i \u2208 {1, ..., n}, j \u2208 {1, ..., k} : Pr[si \u2208 (tj\u22121, tj)] = 1/k. The probability of missing the existence of a collision by looking for non-positive elements in the sample f(t0), ..., f(tk) is:\nPn,k \u2264 P\u221a kn \u2264\n( n(n\u22121)/2\nn/2 ) \u221a kn\nwhere P is a function of n (but not of k) as defined in Lemma C.1. In particular, we have limk\u2192\u221e Pn,k = 0.\nProof. We define the sample space \u2126 := {(b1, ..., bn) \u2208 {1, ..., k}n} where each bi \u2208 {1, ..., k} denotes the index of the time interval (\u201cbin\u201d) (tbi\u22121 , tbi ] the ith SCP si falls into (i = 1, ..., n). Due to the assumption that the assignment of SCP to bin is i.i.d., each sample has equal probability and we can compute Pn,k as a Laplace probability. That is, Pn,k = |G| |\u2126| where G is the set of events\ndescribing that no bin contains an odd number of SCPs (because if at least one does contain an odd number we detect the presence of a collision).\nObviously, |\u2126| = kn. On the other hand, G = {(v1, ..., vk)| \u2211k j=1 vj = n, \u2200j \u2208 {1, ..., k} : vj \u2208 {0, ..., n}\u22292N0} where vj \u2208 {0, ..., n} denotes the number of SCPs falling into bin j \u2208 {1, ..., k}. We will find an upper bound on G\u2032s cardinality by constructing a finite set H for whose cardinality one can easily establish \u221a k n P as an upper bound. We show that one can define an injective function \u03c8 : G \u2192 H. The latter establishes that |G| \u2264 |H|. Thus, |G||\u2126| \u2264 |H| |\u2126| \u2264 P\u221a k n which will hence conclude the proof. We generate H by invoking a two-stage process (where in each stage it is easy to enumerate all possible elements that are generated). In the first stage, we partition the SCPs into n/2 pairs (which we always can since we assumed n to be even). In the second stage, we assign these pairs to the bins in which the pairs are merged into joint sets of SCPs. Therefore, H = {(M1, ...,Mk)|M1 \u2282 {s1, ..., sn}, ...,Mk \u2282 {s1, ..., sn}, |M1|, ..., |Mk| \u2208 2N0, |M1|+ ...+ |Mk| = n,H =\u22c3 iMi}.\nLet P be the number of ways in which one can partition the n SCPs into n/2 (unordered) pairs i.e. P = |{{P1, ...,Pn/2}|\u2200i 6= j : Pi \u2229Pj = \u2205, \u22c3 iPi = {s1, ..., sn},\u2200i\u2203q 6= r : Pi = {sq, sr}}|. (Cf. Lem. C.1 for a bound). In the second stage, the pairs are distributed among the k bins (intervals) (which can be done in B = kn/2 ways) before the sets within each bin are merged. The number of different paths the process can take to generate an element in H is P (number of partitions into pairs) multiplied with B (number of ways the pairs constituting the partition can then be distributed into the bins).\nBy construction, each final assignment (subsets of SCPs to bins) generated by the two-stage process is an element of H. Conversely, let (M1, ...,Mk) \u2208 H then it is easy to verify it could be generated by the two-stage process (however, there may be multiple paths in the process generating the same element of H). Hence, |H| \u2264 P B.\nWe finalize our considerations by defining the function \u03c8 : G\u2192 H, (v1, ..., vn) 7\u2192 (M1, ...,Mk) where M1 := {s1, ..., sv1} and for i > 1: Mi := {s1+wi , ..., svi+wi} where wi = \u2211 j<i vj . It is easy to see that \u03c8 maps different (v1, ..., vn) \u2208 G to different (M1, ...,Mk) \u2208 H. Hence, \u03c8 is injective. Since both H and G are finite this implies |G| \u2264 |H|. Wrapping up, |G||\u2126| \u2264 |H| |\u2126| \u2264 PB kn \u2264 Pkn/2 kn\n= P kn/2\nLem.C.1 \u2264 ( n(n\u22121)/2 n/2 )\u221a kn .\nIn conjunction with Eq. 11, Thm. C.2 can provides a recipe how to do collision detection based on a finite number of criterion function samples such that our confidence in not having overlooked an existing collision is above a certain threshold \u03b8. To this end we require a prior Q over the number of SCPs. Let N be a random variable quantifying the number of occurring SCPs and let M denote the event that we would not detect the existence of an SCP.\nBy the law of total probability we have Pr[M |k] = \u2211 n\u2208N0 Pr[M |N = n, k]Q[N = n] (12)\n= \u2211 n\u22082N0 Pr[M |N = n, k]Q[N = n] (13)\n= \u2211 n\u22082N0 Pn,kQ[N = n] (14)\nwhere the last equality follows from Pr[M |N = n, k] = 0, (n \u2208 2N\u2212 1), k \u2265 1. Given a threshold \u03b8 \u2208 (0, 1) we can then utilize Thm. C.2 to choose a lattice resolution k such that\nPr[M |k] ! < \u03b8.\nTo illustrate this we provide to simple examples:\nExample C.3 (Finite-support prior). As a simplistic example, assume we desire to detect a collision between two agents a, r with plans containing two setpoints each (stabilizing their start and goal state each) and with linear dynamics. We know that at their start and goal locations, no collisions occur. Given this our belief over the number n of SCPs may be Q[N = 0] = 0.5 Q[N = 1] = .1, Q[N = 2] = .4. Furthermore, in the given time interval [0,T] we assume a flat prior distribution giving rise to an equidistant lattice 0 = t0 < t1 < ... < tk = T of samples during collision detection. That is, ti+1 \u2212 ti = T/k for some k. Our collision detection method now inspects our criterion function values \u0393a,r(t0), ...,\u0393\na,r(tk). If all values are positive we assume no collision has occurred. How large should we set k in order to ensure that our confidence in this assertion is at least \u03b8 \u2208 (0, 1)? By Thm. C.2, we know that the probability of having missed a collision with this simple method is less than 0.4\u221a\nk2 . Therefore,\nwe need to set k such that 1\u2212 0.4\u221a k2 \u2265 \u03b8 which is equivalent to setting the number k of criterion function evaluations to k \u2265 0.41\u2212\u03b8 ."}], "references": [], "referenceMentions": [], "year": 2014, "abstractText": "Existing work in multi-agent collision prediction and avoid-<lb>ance typically assumes discrete-time trajectories with Gaus-<lb>sian uncertainty or that are completely deterministic. We pro-<lb>pose an approach that allows detection of collisions even be-<lb>tween continuous, stochastic trajectories with the only restric-<lb>tion that means and covariances can be computed. To this<lb>end, we employ probabilistic bounds to derive criterion func-<lb>tions whose negative sign provably is indicative of probable<lb>collisions. For criterion functions that are Lipschitz, an al-<lb>gorithm is provided to rapidly find negative values or prove<lb>their absence. We propose an iterative policy-search approach<lb>that avoids prior discretisations and, upon termination, yields<lb>collision-free trajectories with adjustably high certainty. We<lb>test our method with both fixed-priority and auction-based<lb>protocols for coordinating the iterative planning process. Re-<lb>sults are provided in collision-avoidance simulations of feedback<lb>controlled plants.", "creator": "LaTeX with hyperref package"}}}