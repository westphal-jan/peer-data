{"id": "1406.1305", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2014", "title": "Faster Rates for the Frank-Wolfe Method over Strongly-Convex Sets", "abstract": "The space-saving Frank - mcglory Wolfe method (lewellen a. k. a. brico conditional onterrio gradient algorithm) for mangeliidae smooth optimization sung-hyun has regained maish much labor-intensive interest compressibility in recent years ballinrobe in hijo the 58.72 context eurozone of large scammon scale fouth optimization and machine creamery learning. karaki A key undercurrents advantage siddiqul of mutineers the method is umbrage that it declare avoids projections - 35.53 the suroyo computational gorden bottleneck biobehavioral in many applications - piruz replacing it by lance-corporal a gasque linear optimization step. anastacio Despite this chongryon advantage, the convergence injectable rates of the FW method bhichai fall rockport behind disruptors standard k.b. gradient methods mylius for rungrawee most figural settings of interest. turnagain It prelinger is willhite an heryanto active cumplir line 15.81 of research to derive faster prydz FW algorithms kibira for various shadoe settings timothy of eisenhart convex zavarzin optimization.", "histories": [["v1", "Thu, 5 Jun 2014 09:25:22 GMT  (59kb,D)", "https://arxiv.org/abs/1406.1305v1", null], ["v2", "Fri, 14 Aug 2015 18:15:14 GMT  (69kb,D)", "http://arxiv.org/abs/1406.1305v2", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG", "authors": ["dan garber", "elad hazan"], "accepted": true, "id": "1406.1305"}, "pdf": {"name": "1406.1305.pdf", "metadata": {"source": "META", "title": "Faster Rates for the Frank-Wolfe Method over Strongly-Convex Sets", "authors": ["Dan Garber", "Elad Hazan"], "emails": ["DANGAR@TX.TECHNION.AC.IL", "EHAZAN@CS.PRINCETON.EDU"], "sections": [{"heading": null, "text": "In this paper we consider the special case of optimization over strongly convex sets, for which we prove that the vanila FW method converges at a rate of 1t2 . This gives a quadratic improvement in convergence rate compared to the general case, in which convergence is of the order 1t , and known to be tight. We show that various balls induced by `p norms, Schatten norms and group norms are strongly convex on one hand and on the other hand, linear optimization over these sets is straightforward and admits a closed-form solution. We further show how several previous fastrate results for the FW method follow easily from our analysis."}, {"heading": "1. Introduction", "text": "The Frank-Wolfe method, originally introduced by Frank and Wolfe in the 1950\u2019s (Frank & Wolfe, 1956), is a first order method for the minimization of a smooth convex function over a convex set. Its main advantage in largescale problems is that it is a first-order and projection-free method - i.e. the algorithm proceeds by iteratively solving a linear optimization problem and remaining inside the feasi-\nble domain. For matrix completion problems, metric learning, sparse PCA, structural SVM and other large-scale machine learning problems, this feature enabled the derivation of algorithms that are practical on one hand and come with provable convergence rates on the other (Jaggi & Sulovsky\u0301, 2010; Lacoste-Julien et al., 2013; Dud\u0131\u0301k et al., 2012; Harchaoui et al., 2012; Hazan & Kale, 2012; Shalev-Shwartz et al., 2011; Laue, 2012).\nDespite its empirical success, the main drawback of the method is its relatively slow convergence rate in comparison to optimal first order methods. The convergence rate of the method is on the order of 1/t where t is the number of iterations, and this is known to be tight. In contrast, Nesterov\u2019s accelerated gradient descent method gives a rate of 1/t2 for general convex smooth problems and a rate e\u2212\u0398(t) is known for smooth and strongly convex problems. The following question arises: are there projectionfree methods with convergence rates matching that of projected gradient-descent and its extensions?\nMotivated by this question, in this work we advance the line of research for faster convergence rates of projection free methods. We prove that in case both the objective function and the feasible set are strongly convex (in fact a slightly weaker assumption than strong convexity of the objective is required), the vanilla Frank-Wolfe method converges at an accelerated rate of 1/t2. The improved convergence rate is independent of the dimension. This is also the first convergence result for the FW that we are aware of that achieves a rate that is between the standard 1/t rate and a linear rate. We further show how the analysis used to prove the latter result enables to easily derive previous fast convergence rates for the FW method.\nWe motivate the study of optimization over strongly convex sets by demonstrating that various norms that serve as popular regularizes in machine learning problems, including `p norms, matrix Schatten norms and matrix group norms, give rise to strongly convex sets. We further show that indeed linear optimization over these sets is straightforward to implement and admits a closed-form solution. Hence the\nar X\niv :1\n40 6.\n13 05\nv2 [\nm at\nh. O\nC ]\n1 4\nA ug\n2 01\nFW method is appealing for solving optimization problems with such constraints, such as regularized linear regression."}, {"heading": "1.1. Related Work", "text": "The Frank-Wolfe method dates back to the original work of Frank and Wolfe (Frank & Wolfe, 1956) which presented an algorithm for minimizing a quadratic function over a polytope using only linear optimization steps over the feasible set. Recent results by Clarkson (Clarkson, 2008), Hazan (Hazan, 2008) and Jaggi (Jaggi, 2013) extend the method to smooth convex optimization over the simplex, spectrahedron and arbitrary convex and compact sets respectively.\nIt was shown in numerous works that the convergence rate of the method is on the order of 1/t and that it could not be improved in general, even if the objective function is strongly convex for instance, as shown in (Clarkson, 2008; Hazan, 2008; Jaggi, 2013), even though it is known that in this case, the projected gradient method achieves an exponentially fast convergence rate.\nOver the past years, several results tried to improve the convergence rate of the Frank-Wolfe method under various assumptions. Gue\u0301Lat and Marcotte (Gue\u0301Lat & Marcotte, 1986) showed that in case the objective function is strongly convex and the feasible set is a polytope, then in case the optimal solution is located in the interior of the set, the FW method converges exponentially fast. A similar result was presented in the work of Beck and Teboulle (Beck & Teboulle, 2004) who considered a specific problem they refer to a the convex feasibility problem over an arbitrary convex set. They also obtained a linear convergence rate under the assumption that an optimal solution that is far enough from the boundary of the set exists.\nRecently, Garber and Hazan (Garber & Hazan, 2013a) gave the first natural linearly-converging FW variant without any restricting assumptions on the location of the optimum. They showed that a variant of the Frank Wolfe method with the addition of away steps converges exponentially fast in case the objective function is strongly convex and the feasible set is a polytope. In follow-up work, Jaggi and Lacoste-Julien (Lacoste-Julien & Jaggi, 2013) gave a refined analysis of an algorithm presented in (Gue\u0301Lat & Marcotte, 1986) which also uses away steps and showed that it also converges exponentially fast in the same setting as the Garber-Hazan result. Also relevant in this context is the work of Ahipasaoglu, Sun and Todd (Ahipasaoglu et al., 2008) who showed that in the specific case of minimizing a smooth and strongly convex function over the unit simplex, a variant of the Frank-Wolfe method that also uses away steps converges with a linear rate.\nIn a different line of work, Migdalas and recently Lan\n(Migdalas, 1994; Lan, 2013) considered the Frank-Wolfe algorithm with a stronger optimization oracle that is able to solve quadratic problems over the feasible domain. They show that in case the objective function is strongly convex then exponentially fast convergence is attainable. However, in most settings of interest, an implementation of such a non-linear oracle is computationally much more expensive than the linear oracle, and the key benefit of the FrankWolfe method is lost.\nIn the specific case that the feasible set is strongly convex, an assumption also made in this paper, Levitin and Polyak showed in their classical work (Levitin & Polyak, 1966) that under the restrictive assumption that the norm of the gradient of the objective function is lower bounded by a constant everywhere in the feasible set, the FW method converges with an exponential rate. The same result appeared in following works by Demyanov and Rubinov (Demyanov & Rubinov, 1970) and Dunn (Dunn, 1979), both also requiring that the magnitude of the gradients is lower bounded by a constant everywhere in the feasible set. As we later show, the lower bound requirement on the gradients is in a sense much stronger than requiring that the objective function is strongly convex. Under our assumption however, which is slightly weaker than strong convexity of the objective, the gradient may become arbitrarily small on the feasible set.\nWe summarize previous convergence rate results for the standard FW method in Table 1.1."}, {"heading": "2. Preliminaries", "text": ""}, {"heading": "2.1. Smoothness and Strong Convexity", "text": "For the following definitions let E be a finite vector space and \u2016 \u00b7 \u2016, \u2016 \u00b7 \u2016\u2217 be a pair of dual norms over E. Definition 1 (smooth function). We say that a function f : E \u2192 R is \u03b2 smooth over a convex set K \u2282 E with respect to \u2016 \u00b7 \u2016 if for all x, y \u2208 K it holds that\nf(y) \u2264 f(x) +\u2207f(x) \u00b7 (y \u2212 x) + \u03b2 2 \u2016x\u2212 y\u20162.\nDefinition 2 (strongly convex function). We say that a function f : E \u2192 R is \u03b1-strongly convex over a convex set K \u2282 E with respect to \u2016 \u00b7 \u2016 if it satisfies the following two equivalent conditions\n1. \u2200x, y \u2208 K :\nf(y) \u2265 f(x) +\u2207f(x) \u00b7 (y \u2212 x) + \u03b1 2 \u2016x\u2212 y\u20162.\n2. \u2200x, y \u2208 K, \u03b3 \u2208 [0, 1] :\nf(\u03b3x+ (1\u2212 \u03b3)y) \u2264 \u03b3f(x) + (1\u2212 \u03b3)f(y)\n\u2212 \u03b1 2 \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u20162.\nThe above definition (part 1) combined with first order optimality conditions imply that for a \u03b1-strongly convex function f , if x\u2217 = arg minx\u2208K f(x), then for any x \u2208 K\nf(x)\u2212 f(x\u2217) \u2265 \u03b1 2 \u2016x\u2212 x\u2217\u20162. (1)\nEq. (1) further implies that the magnitude of the gradient of f at point x, \u2016\u2207f(x)\u2016\u2217 is at least of the order of the square-root of the approximation error at x, f(x)\u2212 f(x\u2217). This follows since\u221a\n2 \u03b1 (f(x)\u2212 f(x\u2217)) \u00b7 \u2016\u2207f(x)\u2016\u2217 \u2265 \u2016x\u2212 x\u2217\u2016 \u00b7 \u2016\u2207f(x)\u2016\u2217\n\u2265 (x\u2212 x\u2217) \u00b7 \u2207f(x) \u2265 f(x)\u2212 f(x\u2217),\nwhere the first inequality follows from (1), the second from Holder\u2019s inequality and the third from convexity of f . Thus we have that at any point x \u2208 K it holds that\n\u2016\u2207f(x)\u2016\u2217 \u2265 \u221a \u03b1 2 \u00b7 \u221a f(x)\u2212 f(x\u2217). (2)\nWe will show that this property, that is in fact weaker than strong convexity, combined with an additional property of the convex set that we define next, allows to obtain the faster rates 1.\nDefinition 3 (strongly convex set). We say that a convex set K \u2282 E is \u03b1-strongly convex with respect to \u2016 \u00b7 \u2016 if for any x, y \u2208 K, any \u03b3 \u2208 [0, 1] and any vector z \u2208 E such that \u2016z\u2016 = 1, it holds that\n\u03b3x+ (1\u2212 \u03b3)y + \u03b3(1\u2212 \u03b3)\u03b1 2 \u2016x\u2212 y\u20162z \u2208 K.\nThat is, K contains a ball of of radius \u03b3(1\u2212 \u03b3)\u03b12 \u2016x\u2212 y\u2016 2 induced by the norm \u2016 \u00b7 \u2016 centered at \u03b3x+ (1\u2212 \u03b3)y. 1In this work we assume that the convex set K is fulldimensional. In case this assumption does not hold, e.g. if the convex set is the unit simplex, then Eq. (2) holds even if we replace \u2207f(x) with PS(K)[\u2207f(x)] where PS(K) denotes the projection operator onto the smallest subspace that contains K."}, {"heading": "2.2. The Frank-Wolfe Algorithm", "text": "The Frank-Wolfe algorithm, also known as the conditional gradient algorithm, is an algorithm for the minimization of a convex function f : E \u2192 R which is assumed to be \u03b2f -smooth with respect to a norm \u2016 \u00b7 \u2016, over a convex and compact set K \u2282 E. The algorithm implicitly assumes that the convex set K is given in terms of a linear optimization oracle OK : E \u2192 K which given a linear objective c \u2208 E returns a point x = OK(c) \u2208 K such that x \u2208 arg miny\u2208K y \u00b7 c. The algorithm is given below. The algorithm proceeds in iterations, taking on each iteration t the new iterate xt+1 to be a convex combination between the previous feasible iterate xt and a feasible point that minimizes the dot product with the gradient direction at xt, which is generated by invoking the oracle OK with the input vector \u2207f(xt). There are various ways to set the parameter that controls the convex combination \u03b7t in order to guarantee convergence of the method. The option that we choose here is the optimization of \u03b7t via a simple line search rule, which is straightforward and computationally cheap to implement.\nAlgorithm 1 Frank-Wolfe Algorithm 1: Let x0 be an arbitrary point in K. 2: for t = 0, 1, ... do 3: pt \u2190 OK(\u2207f(xt)). 4: \u03b7t \u2190 arg min\u03b7\u2208[0,1] \u03b7(pt \u2212 xt) \u00b7 \u2207f(xt) +\n\u03b72 \u03b2f 2 \u2016pt \u2212 xt\u2016 2. 5: xt+1 \u2190 xt + \u03b7t(pt \u2212 xt). 6: end for\nThe following theorem states the well-known convergence rate of the Frank-Wolfe algorithm for smooth convex minimization over a compact and convex set, without any further assumptions. A proof is given in the appendix for completeness though similar proofs could also be found in (Levitin & Polyak, 1966; Jaggi, 2013).\nTheorem 1. Let x\u2217 \u2208 arg minx\u2208K f(x) and denote DK = maxx,y\u2208K \u2016x\u2212 y\u2016 (the diameter of the set with respect to\n\u2016 \u00b7 \u2016). For every t \u2265 1 the iterate xt of Algorithm 1 satisfies\nf(xt)\u2212 f(x\u2217) \u2264 8\u03b2fD\n2 K\nt = O\n( 1\nt\n) ."}, {"heading": "2.3. Our Results", "text": "In this work, we consider the case in which the function to optimize f is not only \u03b2f -smooth with respect to \u2016 \u00b7 \u2016 but also \u03b1f -strongly convex with respect to \u2016 \u00b7 \u2016 (we relax this assumption a bit in subsection 4.3). We further assume that the feasible set K is \u03b1K-strongly convex with respect to \u2016 \u00b7 \u2016. Under these two additional assumptions alone we prove the following theorem.\nTheorem 2. Let x\u2217 = arg minx\u2208K f(x) and let M =\u221a \u03b1f\u03b1K\n8 \u221a 2\u03b2f . Denote DK = maxx,y\u2208K \u2016x\u2212 y\u2016. For every\nt \u2265 1 the iterate xt of Algorithm 1 satisfies\nf(xt)\u2212 f(x\u2217) \u2264 max{ 92\u03b2fD 2 K, 18M \u22122} (t+ 2)2 = O\n( 1\nt2\n) ."}, {"heading": "3. Proof of Theorem 2", "text": "We denote the approximation error of the iterate xt produced by the algorithm by ht. That is ht = f(xt)\u2212 f(x\u2217) where x\u2217 = arg minx\u2208K f(x).\nTo better illustrate our results, we first shortly revisit the proof technique of Theorem 1. The main observation to be made is the following:\nht+1 = f(xt + \u03b7t(pt \u2212 xt))\u2212 f(x\u2217) \u2264 ht + \u03b7t(pt \u2212 xt) \u00b7 \u2207f(xt) + \u03b72t \u03b2f\n2 \u2016pt \u2212 xt\u20162 \u2264\nht + \u03b7t(x \u2217 \u2212 xt) \u00b7 \u2207f(xt) + \u03b72t \u03b2f 2 \u2016pt \u2212 xt\u20162 \u2264 (1\u2212 \u03b7t)ht + \u03b72t \u03b2f\n2 \u2016pt \u2212 xt\u20162, (3)\nwhere the the first inequality follows from the smoothness of f , the second from the optimality of pt and the third from convexity of f . Choosing \u03b7t to be roughly 1/t yields the convergence rate of 1/t stated in Theorem 1. This rate cannot be improved in general since while the so-called duality gap (xt \u2212 pt) \u00b7 \u2207f(xt) could be arbitrarily small (as small as (xt \u2212 x\u2217) \u00b7 \u2207f(xt)), the quantity \u2016pt \u2212 xt\u2016 may remain as large as the diameter of the set. Note that in case f is strongly-convex, then according to Eq. (1) it holds that xt converges to x\u2217 and thus according to Eq. (3) it suffices to solve the inner linear optimization problem in Algorithm 1 on the intersection of K and a small ball centered at xt. As a result the quantity \u2016pt \u2212 xt\u20162 will be proportional to the approximation error at time t, and a linear convergence rate will be attained. However in general, under the linear oracle assumption, we have no way to solve the linear\noptimization problem over the intersection of K and a ball without greatly increasing the number of calls to the linear oracle, which is the most expensive step in many settings.\nIn case the feasible set K is strongly convex, then the main observation to be made is that while the quantity \u2016pt \u2212 xt\u2016 may still be much larger than \u2016x\u2217 \u2212 xt\u2016 (the distance to the optimum), in this case, the duality gap must also be large, which results in faster convergence. This observation is illustrated in Figure 1 and given formally in Lemma 1.\nLemma 1. On any iteration t of Algorithm 1 it holds that\nht+1 \u2264 ht \u00b7max{ 1 2 , 1\u2212 \u03b1K\u2016\u2207f(xt)\u2016\u2217 8\u03b2f }.\nProof. By the optimality of the point pt we have that\n(pt \u2212 xt) \u00b7 \u2207f(xt) \u2264 (x\u2217 \u2212 xt) \u00b7 \u2207f(xt) \u2264 f(x\u2217)\u2212 f(xt) = \u2212ht, (4)\nwhere the second inequality follows from convexity of f . Denote ct = 12 (xt + pt) and wt \u2208 arg minw\u2208E,\u2016w\u2016\u22641 w \u00b7 \u2207f(xt). Note that from Holder\u2019s inequality we have that wt \u00b7\u2207f(xt) = \u2212\u2016\u2207f(xt)\u2016\u2217. Using the strong convexity of the setK we have that the point p\u0303t = ct+ \u03b1K8 \u2016xt \u2212 pt\u2016\n2wt is in K. Again using the optimality of pt we have that\n(pt \u2212 xt) \u00b7 \u2207f(xt) \u2264 (p\u0303t \u2212 xt) \u00b7 \u2207f(xt)\n= 1\n2 (pt \u2212 xt) \u00b7 \u2207f(xt) +\n\u03b1K\u2016xt \u2212 pt\u20162\n8 wt \u00b7 \u2207f(xt)\n\u2264 \u22121 2 ht \u2212\n\u03b1K\u2016xt \u2212 pt\u20162\n8 \u2016\u2207f(xt)\u2016\u2217, (5)\nwhere the last inequality follows from Eq. (4).\nWe now analyze the decrease in the approximation error\nht+1. By smoothness of f we have\nf(xt+1) \u2264 f(xt) + \u03b7t(pt \u2212 xt) \u00b7 \u2207f(xt)\n+ \u03b2f 2 \u03b72t \u2016pt \u2212 xt\u20162.\nSubtracting f(x\u2217) from both sides we have\nht+1 \u2264 ht + \u03b7t(pt \u2212 xt) \u00b7 \u2207f(xt) + \u03b2f 2 \u03b72t \u2016pt \u2212 xt\u20162.\n(6)\nPlugging Eq. (5) we have\nht+1 \u2264 ht (\n1\u2212 \u03b7t 2\n) \u2212 \u03b7t \u03b1K\u2016xt \u2212 pt\u20162\n8 \u2016\u2207f(xt)\u2016\u2217\n+ \u03b2f 2 \u03b72t \u2016pt \u2212 xt\u20162\n= ht\n( 1\u2212 \u03b7t\n2 ) + \u2016xt \u2212 pt\u20162\n2\n( \u03b72t \u03b2f \u2212 \u03b7t\n\u03b1K\u2016\u2207f(xt)\u2016\u2217 4\n) .\nIn case \u03b1K\u2016\u2207f(xt)\u2016\u22174 \u2265 \u03b2f , by the optimal choice of \u03b7t in Algorithm 1, we can set \u03b7t = 1 and get\nht+1 \u2264 ht 2 .\nOtherwise, we can set \u03b7t = \u03b1K\u2016\u2207f(xt)\u2016\u2217\n4\u03b2f and get\nht+1 \u2264 ht (\n1\u2212 \u03b1K\u2016\u2207f(xt)\u2016\u2217 8\u03b2f\n) .\nNote that Lemma 1 only relies on the strong convexity of the set K and did not assume anything regrading f beyond convexity and smoothness. In particular it does not require f to be strongly convex.\nWe can now prove Theorem 2.\nProof. Let M = \u221a \u03b1f\u03b1K\n8 \u221a 2\u03b2f and C =\nmax{ 92\u03b2fD 2 K, 18M \u22122}. We prove by induction that for all t \u2265 1, ht \u2264 C(t+2)2 .\nSince we assume that the objective function f satisfies Eq. (2), we have from Lemma 1 that on any iteration t,\nht+1 \u2264 ht \u00b7max{ 1\n2 , 1\u2212\n\u03b1K \u221a \u03b1f\n8 \u221a\n2\u03b2f\n\u221a ht}\n= ht \u00b7max{ 1\n2 , 1\u2212Mh1/2t }. (7)\nFor the base case t = 1 we need to prove that h1 = f(x1)\u2212 f(x\u2217) \u2264 C/4. By \u03b2f smoothness of f we have\nf(x1)\u2212 f(x\u2217) = f(x0 + \u03b70(p0 \u2212 x0))\u2212 f(x\u2217)\n\u2264 h0 + \u03b70(p0 \u2212 x0) \u00b7 \u2207f(x0) + \u03b2f\u03b7\n2 0\n2 D2K\n\u2264 h0(1\u2212 \u03b70) + \u03b2f\u03b7\n2 0\n2 D2K,\nwhere the last inequality follows from convexity of f . By the optimal choice of \u03b70 we can in particular set \u03b70 = 1 which gives h1 \u2264 \u03b2f2 D 2 K \u2264 C/9.\nAssume now that the induction holds for time t \u2265 1, that is ht \u2264 C(t+2)2 .\nIf the result of the max operation in Eq. (7) is the first argument, that is 1/2, we have that\nht+1 \u2264 ht 2 \u2264 C 2(t+ 2)2 =\nC (t+ 3)2 \u00b7 (t+ 3)\n2\n2(t+ 2)2\n\u2264 C (t+ 3)2 . (8)\nwhere the last inequality holds for any t \u2265 1.\nWe now turn to the case in which the result of the max operation in Eq. (7) is the second argument. We consider two cases.\nIf ht \u2264 C2(t+2)2 then as in Eq. (8) it holds for any t \u2265 1 that\nht+1 \u2264 ht \u2264 C 2(t+ 2)2 \u2264 C (t+ 3)2 ,\nwhere the first inequality follows from Eq. (7).\nOtherwise, ht > C2(t+2)2 . By Eq. (7) and the induction assumption we have ht+1 \u2264 ht ( 1\u2212Mh1/2t )\n< C\n(t+ 2)2\n( 1\u2212M \u221a C\n2\n1\nt+ 2\n)\n= C (t+ 3)2 \u00b7 (t+ 3)\n2\n(t+ 2)2\n( 1\u2212M \u221a C\n2\n1\nt+ 2\n)\n= C (t+ 3)2 \u00b7 (t+ 2)\n2 + 2t+ 5\n(t+ 2)2\n( 1\u2212M \u221a C\n2\n1\nt+ 2\n)\n< C\n(t+ 3)2\n( 1 + 3(t+ 2)\n(t+ 2)2\n)( 1\u2212M \u221a C\n2\n1\nt+ 2\n)\n= C\n(t+ 3)2\n( 1 + 3\nt+ 2\n)( 1\u2212M \u221a C\n2\n1\nt+ 2\n) .\nThus for C \u2265 18M2 we have that\nht+1 \u2264 C\n(t+ 3)2\n( 1 + 3\nt+ 2\n)( 1\u2212 3\nt+ 2 ) < C\n(t+ 3)2 ."}, {"heading": "4. Derivation of Previous Fast Rates Results and Extensions", "text": ""}, {"heading": "4.1. Deriving the Linear Rate of Polayk & Levitin", "text": "Polyak & Levitin considered in (Levitin & Polyak, 1966) the case in which the feasible set is strongly convex, the objective function is smooth and there exists a constant g > 0 such that\n\u2200x \u2208 K : \u2016\u2207f(x)\u2016\u2217 \u2265 g. (9)\nThey showed that under the lower-bounded gradient assumption, Algorithm 1 converges with a linear rate, that is e\u2212\u0398(t). Clearly by plugging Eq. (9) into Lemma 1 we have that on each iteration t\nht+1 \u2264 ht \u00b7max{ 1 2 , 1\u2212 \u03b1kg 8\u03b2f }.\nwhich results in the same exponentially fast convergence rate as in (Levitin & Polyak, 1966) and following works such as (Demyanov & Rubinov, 1970; Dunn, 1979)."}, {"heading": "4.2. Deriving a Linear Rate for Arbitrary Convex Sets in case x\u2217 is in the Interior of the Set", "text": "Assume now that the feasible setK is convex but not necessarily strongly convex. We assume that the objective function f is smooth, convex, satisfies Eq. (2) with some constant \u03b1f and admits a minimizer (not necessarily unique) x\u2217 that lies in the interior of K, i.e. there exists a parameter r > 0 such that the ball of radius r with respect to norm \u2016 \u00b7 \u2016 centered at x\u2217 is fully contained in K 2. Gue\u0301Lat and Marcotte (Gue\u0301Lat & Marcotte, 1986) showed the under the above conditions, the Frank-Wolfe algorithm converges with a linear rate. We now show how a slight modification in the proof of Lemma 1 yields this linear convergence result.\nLet wt be as in the proof of Lemma 1, that is wt \u2208 arg minw\u2208E,\u2016w\u2016\u22641 w \u00b7 \u2207f(xt). Instead of defining the\n2We assume here thatK is full-dimensional. In any other case, we can assume instead that the intersection of the ball centered at x\u2217 with the smallest subspace containing K is fully contained in K. In this case we also need to replace the gradient \u2207f(x) with its projection onto this subspace, see also footnote 1.\npoint p\u0303t as in the proof of Lemma 1 we define it to be p\u0303t = x\n\u2217 + rwt. Because of our assumption on the location of x\u2217, it holds that p\u0303t \u2208 K. We thus have that\n(p\u0303t \u2212 xt) \u00b7 \u2207f(xt) = (x\u2217t \u2212 xt) \u00b7 \u2207f(xt) + rwt \u00b7 \u2207f(xt) \u2264 \u2212r\u2016\u2207f(xt)\u2016\u2217.\nPlugging this into Eq. (6) we have\nht+1 \u2264 ht \u2212 \u03b7tr\u2016\u2207f(xt)\u2016\u2217 + \u03b2f\u03b7\n2 tD 2 K 2\n\u2264 ht \u2212 \u03b7tr \u221a \u03b1f 2 \u221a ht + \u03b2f\u03b7 2 tD 2 K 2 .\nwhere DK denotes the diameter of K with respect to norm \u2016 \u00b7 \u2016 and the second inequality follows from Eq. (2). By the optimal choice of \u03b7t, we can set \u03b7t = r \u221a \u03b1f \u221a ht\u221a\n2\u03b2fD2K and get\nht+1 \u2264 ht \u2212 r2\u03b1f\n4\u03b2fD2K ht,\nwhich results in a linear convergence result."}, {"heading": "4.3. Relaxing the Strong Convexity of f", "text": "So far we have considered the case in which the objective function f is strongly convex. Notice however that our main instrument for proving the accelerated convergence rate, i.e. Lemma 1, did not rely directly on strong convexity of f , but on the magnitude of the gradient, \u2016\u2207f(xt)\u2016\u2217. We have seen in Eq. (2) that indeed if f is strongly convex than the gradient is at least of the order of \u221a ht. We now show that there exists functions which are not strongly convex but still satisfy Eq. (2) and hence our results apply also for them.\nConsider the function\nf(x) = 1\n2 \u2016Ax\u2212 b\u201622.\nwhere x \u2208 Rn, A \u2208 Rm\u00d7n, b \u2208 Rm. Assume that m < n and all rows of A are linearly independent. In this case the optimization problem minx\u2208K f(x) is the problem of finding a point in K that best satisfies an under-determined linear system in terms of the mean square error. An application of the Frank-Wolfe method to this problem was studied in (Beck & Teboulle, 2004). Under these assumptions, the function f is smooth and convex but not strongly convex since the Hessian matrix given by A>A is not positive definite (note however that the matrix AA> is positive definite).\nThe gradient of f is given by\n\u2207f(x) = A>(Ax\u2212 b).\nThus we have that\n\u2016\u2207f(x)\u201622 = [A>(Ax\u2212 b)]>[A>(Ax\u2212 b)] \u2265 \u03bbmin(AA>)\u2016Ax\u2212 b\u201622\n\u2265 2\u03bbmin(AA>) (1\n2 \u2016Ax\u2212 b\u201622\n\u2212 1 2 \u2016Ax\u2217 \u2212 b\u201622\n) ,\nwhere \u03bbmin(AA>) denotes the smallest eigenvalue of AA>. Since AA> is positive definite, \u03bbmin(AA>) > 0 and it follows that f satisfies Eq. (2).\nCombining the result of this subsection with the previous one yields the linear convergence rate of the Frank-Wolfe method applied to the convex feasibility problem studied in (Beck & Teboulle, 2004)."}, {"heading": "5. Examples of Strongly Convex Sets", "text": "In this section we explore convex sets for which Theorem 2 is applicable. That is, convex sets which on one hand are strongly convex, and on the other, admit a simple and efficient implementation of a linear optimization oracle. We show that various norms that give rise to natural regularization functions in machine learning, induce convex sets that fit both of the above requirements. A summary of our findings is given in Table 5. We note that in all cases in which the norm parameter p is smaller than 2 (or one of the parameters s, p in case of group norms), we are not aware of a practical algorithm for computing the projection."}, {"heading": "5.1. Partial Characterization of Strongly Convex Sets", "text": "The following lemma is taken from (Journe\u0301e et al., 2010) (Theorem 12).\nLemma 2. Let E be a finite vector space and let f : E\u2192 R be non-negative, \u03b1-strongly convex and \u03b2-smooth. Then the set K = {x | f(x) \u2264 r} is \u03b1\u221a\n2\u03b2r -strongly convex.\nThis lemma for instance shows that the Euclidean ball of radius r is 1/r-strongly convex (by applying the lemma with f = \u2016x\u201622).\nThe following lemma will be useful to prove that convex sets that are induced by certain norms, which do not correspond to a smooth function as in the previous lemma, are strongly convex. The proof is given in the appendix.\nLemma 3. Let E be a finite vector space, let \u2016\u00b7\u2016 be a norm over E and assume that the function f(x) = \u2016x\u20162 is \u03b1strongly convex over E with respect to the norm \u2016\u00b7\u2016. Then for any r > 0, the set B\u2016\u00b7\u2016(r) = {x \u2208 E | \u2016x\u2016 \u2264 r} is \u03b12r - strongly convex with respect to \u2016 \u00b7 \u2016.\n5.2. `p Balls for p \u2208 (1, 2]\nGiven a parameter p \u2265 1, consider the `p ball of radius r,\nBp(r) = {x \u2208 Rn | \u2016x\u2016p \u2264 r}.\nThe following lemma is proved in (Shwartz, 2007).\nLemma 4. Fix p \u2208 (1, 2]. The function 12\u2016x\u2016 2 p is (p \u2212 1)- strongly convex w.r.t. the norm \u2016\u00b7\u2016p.\nThe following corollary is a consequence of combining Lemma 4 and Lemma 3. The proof is given in the appendix\nCorollary 1. Fix p \u2208 (1, 2]. The set Bp(r) is p\u22121r -strongly convex with respect to the norm \u2016 \u00b7 \u2016p and (p\u22121)n 1 2 \u2212 1 p\nr - strongly convex with respect to the norm \u2016 \u00b7 \u20162.\nThe following lemma establishes that linear optimization over Bp(r) admits a simple closed-form solution that can be computed in time that is linear in the number of nonzeros in the linear objective. The proof is given in the appendix.\nLemma 5. Fix p \u2208 (1, 2], r > 0 and a linear objective c \u2208 Rn. Let x \u2208 Rn such that xi = \u2212 r\u2016c\u2016q\u22121q sgn(ci)|ci| q\u22121 where q satisfies: 1/q + 1/p = 1, and sgn(\u00b7) is the sign function. Then x = arg miny\u2208Bp(r) y \u00b7 c\n5.3. Schatten `p Balls for p \u2208 (1, 2]\nGiven a matrix X \u2208 Rm\u00d7n we denote by \u03c3(X) the vector of singular values of X in descending order, that is \u03c3(X)1 \u2265 \u03c3(X)2 \u2265 ...\u03c3(X)min(m,n). The Schatten `p norm is given by\n\u2016X\u2016S(p) = \u2016\u03c3(X)\u2016p = min(m,n)\u2211 i=1 \u03c3(X)pi 1/p . Consider the Schatten `p ball of radius r,\nBS(p)(r) = {X \u2208 Rm\u00d7n | \u2016X\u2016S(p) \u2264 r}.\nThe following lemma is taken from (Kakade et al., 2012).\nLemma 6. Fix p \u2208 (1, 2]. The function 12\u2016X\u2016 2 S(p) is (p \u2212 1)-strongly convex w.r.t. the norm \u2016\u00b7\u2016S(p).\nThe proof of the following corollary follows the exact same lines as the proof of Corollary 1 by using Lemma 6 instead of Lemma 4.\nCorollary 2. Fix p \u2208 (1, 2]. The set BS(p)(r) is p\u22121 r -strongly convex with respect to the norm \u2016 \u00b7 \u2016S(p) and (p\u22121) min(m,n) 1 2 \u2212 1 p\nr -strongly convex with respect to the frobenius norm \u2016 \u00b7 \u2016F .\nThe following lemma establishes that linear optimization over BS(p)(r) admits a simple closed-form solution given the singular value decomposition of the linear objective. The proof is given in the appendix.\nLemma 7. Fix p \u2208 (1, 2], r > 0 and a linear objective C \u2208 Rm\u00d7n. Let C = U\u03a3V > be the singular value decomposition of C. Let \u03c3 be a vector such that \u03c3i = \u2212 r \u2016\u03c3(C)\u2016q\u22121q \u03c3(C)q\u22121i where q satisfies: 1/q+ 1/p = 1. Finally, let X = UDiag(\u03c3)V > where Diag(\u03c3) is an m\u00d7 n diagonal matrix with the vector \u03c3 as the main diagonal. Then X = arg minY \u2208BS(p)(r) Y \u2022 C, where \u2022 denotes the standard inner product for matrices.\n5.4. Group `s,p Balls for s, p \u2208 (1, 2]\nGiven a matrix X \u2208 Rm\u00d7n denote by Xi \u2208 Rn the ith row of X . That is X = (X1, X2, ..., Xm)>.\nThe `s,p norm of X is given by,\n\u2016X\u2016s,p = \u2016(\u2016X1\u2016s, \u2016X2\u2016s, ..., \u2016Xm\u2016s)\u2016p.\nWe define the `s,p ball as follows:\nBs,p(r) = {X \u2208 Rm\u00d7n | \u2016X\u2016s,p \u2264 r}.\nThe proof of the following lemma is given in the appendix.\nLemma 8. Let s, p \u2208 (1, 2]. The set Bs,p(r) is (s\u22121)(p\u22121)(s+p\u22122)r - strongly convex with respect to the norm \u2016 \u00b7 \u2016s,p and n 1 s\u2212 1 2m 1 p\u2212 1 2\n(s\u22121)(p\u22121) (s+p\u22122)r -strongly convex with respect to the\nfrobenius norm \u2016 \u00b7 \u2016F .\nThe following lemma establishes that linear optimization over Bs,p(r) admits a simple closed-form solution that can be computed in time that is linear in the number of nonzeros in the linear objective. The proof is given in the appendix.\nLemma 9. Fix s, p \u2208 (1, 2], r > 0 and a linear objective C \u2208 Rm\u00d7n. Let X \u2208 Rm\u00d7n be such that Xi,j = \u2212 r\u2016C\u2016q\u22121z,q \u2016Ci\u2016z\u2212qz sgn(Ci,j)|Ci,j | z\u22121 where z satisfies: 1/s+ 1/z = 1, q satisfies: 1/p+ 1/q = 1 and Ci denotes the ith row of C. Then X = arg minY \u2208Bs,p(r) Y \u2022C, where \u2022 denotes the standard inner product for matrices."}, {"heading": "6. Conclusions and Open Problems", "text": "In this paper we proved that the Frank-Wolfe algorithm converges at an accelerated rate of O(1/t2) for smooth and strongly-convex optimization over strongly-convex sets, beating the known tight convergence rate of the method for general smooth and convex optimization. This is one of the very few known results that achieve such an improvement in convergence rate under natural and standard assumptions (i.e. strong convexity etc.). We have further demonstrated that various regularization functions in machine learning give rise to strongly convex sets. We have also demonstrated how previous fast convergence rate results follow easily from our analysis.\nThe following questions naturally arise.\nIt is known that in case the objective function is both smooth and strongly convex, projection/prox-based methods achieve a convergence rate of O(log(1/ )). Is it possible to achieve such a rate for the FW method in case the convex set is strongly convex?\nWe have shown that it is possible to obtain faster rates for optimization over balls induced by norms that give rise to strongly convex functions. Is it possible to obtain faster rates for balls induced by norms that do not give rise to strongly convex functions (but rather to smooth functions)? e.g. is it possible to obtain faster rates for `p balls for p > 2.\nFinally, the most intriguing question is to give a linear optimization oracle-based method that enjoys the same convergence rate, at least in terms of the approximation error, as optimal projection/prox-based gradient methods, in any regime (including non-smooth problems). A progress in this direction was made recently by Garber and Hazan (Garber & Hazan, 2013b) who showed that in case the feasible set is a polytope, a variant of the FW-method obtains the same rates as the projected (sub)gradient descent method."}, {"heading": "Acknowledgments", "text": "The research leading to these results has received funding from the European Unions Seventh Framework Programme (FP7/2007-2013) under grant agreement n\u25e6 336078 \u2013 ERCSUBLRN."}, {"heading": "A. Proof of Theorem 1", "text": "Proof. Fix an iteration t. By the \u03b2f -smoothness of f we have that\nht+1 = f(xt + \u03b7t(pt \u2212 xt))\u2212 f(x\u2217) \u2264 f(xt)\u2212 f(x\u2217) + \u03b7t(pt \u2212 xt) \u00b7 \u2207f(xt)\n+ \u03b72t \u03b2f\n2 \u2016pt \u2212 xt\u20162\n\u2264 ht \u2212 \u03b7tht + \u03b72t \u03b2fD 2 K\n2 , (10)\nwhere the last inequality follows from convexity of f . Notice that by the optimal choice of \u03b7t in Algorithm 1, it holds in particular that ht+1 \u2264 ht (by setting \u03b7t = 0 in Eq. (10)).\nFix C = 8\u03b2fD2K. We now prove by induction on t that ht \u2264 Ct .\nFor the base case t = 1 we notice that by the optimal choice of \u03b70 in Algorithm 1 we can in particular set \u03b70 = 1 and thus it follows from Eq. (10) that h1 \u2264 \u03b2fD 2 K\n2 < C as needed.\nAssume now that the induction holds for t \u2265 1. That is ht \u2264 Ct . We consider two cases.\nIf ht \u2264 C2t then we have\nht+1 \u2264 ht \u2264 C\n2t =\nC t+ 1 \u00b7 t+ 1 2t \u2264 C t+ 1 ,\nwhere the last inequality holds for any t \u2265 1.\nOtherwise it holds that ht > C2t . Using Eq. (10) again we have\nht+1 \u2264 ht \u2212 \u03b7tht + \u03b72t \u03b2fD 2 K\n2 .\nBy the optimal choice of \u03b7t in Algorithm 1 we can set \u03b7t = ht \u03b2fD2K and get\nht+1 \u2264 ht \u2212 1\n2\u03b2fD2K h2t <\nC t \u2212 C\n2\n8\u03b2fD2Kt 2\n= C\nt+ 1\n( t+ 1\nt \u2212 C(t+ 1)\n8\u03b2fD2Kt 2 ) < C\nt+ 1\n( 1 + 1\nt \u2212 Ct\n8\u03b2fD2Kt 2\n) .\nThus for C \u2265 8\u03b2fD2K we have that ht+1 \u2264 Ct+1 ."}, {"heading": "B. Proofs of Lemmas and Corollaries from", "text": "Section 5\nB.1. Proof of Lemma 3\nProof. It suffices to show that given x, y \u2208 E such that f(x) \u2264 r2, f(y) \u2264 r2, a scalar \u03b3 \u2208 [0, 1] and z \u2208 E such\nthat \u2016z\u2016 \u2264 \u03b14r\u03b3(1\u2212\u03b3)\u2016x\u2212 y\u2016 2, it holds that, f(\u03b3x+ (1\u2212 \u03b3)y + z) \u2264 r2.\nBy the definition of f and the triangle inequality for \u2016 \u00b7 \u2016 we have\nf(\u03b3x+ (1\u2212 \u03b3)y + z) = \u2016\u03b3x+ (1\u2212 \u03b3)y + z\u20162 \u2264 (\u2016\u03b3x+ (1\u2212 \u03b3)y\u2016+ \u2016z\u2016)2 =(\u221a\nf(\u03b3x+ (1\u2212 \u03b3)y) + \u2016z\u2016 )2 . (11)\nSince f is \u03b1 strongly convex with respect to \u2016 \u00b7 \u2016 we have that\nf(\u03b3x+ (1\u2212 \u03b3)y) \u2264 \u03b3f(x) + (1\u2212 \u03b3)f(y)\u2212 \u03b1 2 \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u20162 \u2264 r2 \u2212 \u03b1 2 \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u20162.\nThe function g(t) = \u221a t is concave, meaning \u221a a\u2212 b = g(a\u2212 b) \u2264 g(a)\u2212 g\u2032(a) \u00b7 b = \u221a a\u2212 b\n2 \u221a a . Thus,\n\u221a f(\u03b3x+ (1\u2212 \u03b3)y) \u2264 \u221a r2 \u2212 \u03b1\n2 \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u20162\n\u2264 r \u2212 \u03b1\u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u2016 2\n4r .\nPlugging back in Eq. (11) we have\nf(\u03b3x+ (1\u2212 \u03b3)y + z) \u2264( r \u2212 \u03b1\u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u2016 2\n4r + \u2016z\u2016\n)2 .\nBy our assumption on \u2016z\u2016 we have\nf(\u03b3x+ (1\u2212 \u03b3)y + z) \u2264 ( r \u2212 \u03b1\u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u2016 2\n4r\n+ \u03b1\n4r \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u20162 )2 = r2.\nB.2. Proof of Corollary 1\nProof. The strong convexity of the set w.r.t. \u2016 \u00b7 \u2016p is an immediate consequence of Lemma 3.\nSince Bp(r) is \u03b1 = (p \u2212 1)/r strongly convex w.r.t. the norm \u2016 \u00b7\u2016p, we have that given x, y \u2208 Bp(r), \u03b3 \u2208 [0, 1] and z \u2208 Rn such that \u2016z\u2016p \u2264 1 it holds that\n\u03b3x+ (1\u2212 \u03b3)y + \u03b1 2 \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u20162pz \u2208 Bp(r).\nFor any p \u2208 (1, 2] and vector v \u2208 Rn it holds that\n\u2016v\u20162 \u2264 \u2016v\u2016p \u2264 n 1 p\u2212 1 2 \u2016v\u20162. (12)\nGiven a vector z\u2032 \u2208 Rn such that \u2016z\u2032\u2016F \u2264 1 we have that\n\u2016\u03b1 2 \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u201622z\u2032\u2016p = \u03b1\n2 \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u201622\u2016z\u2032\u2016p.\nUsing Eq. (12) we have\n\u2016\u03b1 2 \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u201622z\u2032\u2016p \u2264 \u03b1 2 \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u20162pn 1 p\u2212 1 2 \u2016z\u2032\u20162 \u2264 \u03b1n 1 p\u2212 1 2\n2 \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u20162p.\nHence, Bp(r) is \u03b1n 1 2\u2212 1 p = (p\u22121)n\n1 2 \u2212 1 p\nr -strongly convex with respect to \u2016 \u00b7 \u20162.\nB.3. Proof of Lemma 5\nProof. Since \u2016\u00b7\u2016p and \u2016\u00b7\u2016q are dual norms, we have using Holder\u2019s inequality that for all x \u2208 Bp(r),\nx \u00b7 c \u2265 \u2212\u2016x\u2016p\u2016c\u2016q \u2265 \u2212r\u2016c\u2016q.\nThus choosing xi = \u2212 r\u2016c\u2016q\u22121q sgn(ci)|ci| q\u22121 we have that\nx \u00b7 c = \u2212 n\u2211 i=1 r \u2016c\u2016q\u22121q sgn(ci)|ci|q\u22121 \u00b7 ci\n= \u2212 n\u2211 i=1 r \u2016c\u2016q\u22121q |ci|q = \u2212 r \u2016c\u2016q\u22121q \u2016c\u2016qq = \u2212r\u2016c\u2016q.\nMoreover,\n\u2016x\u2016pp = rp( \u2016c\u2016q\u22121q )p n\u2211 i=1 ( |ci|q\u22121 )p .\nSince p = q/(q \u2212 1) we have that\n\u2016x\u2016pp = rp\n\u2016c\u2016qq n\u2211 i=1 |ci|q = rp.\nThus we have that x \u2208 Bp(r).\nB.4. Proof of Lemma 7\nProof. Since \u2016\u00b7\u2016S(p) and \u2016\u00b7\u2016S(q) are dual norms we from Holder\u2019s inequality that for all X \u2208 BS(p)(r),\nX \u2022 C \u2265 \u2212\u2016X\u2016S(p)\u2016C\u2016S(q) \u2265 \u2212r\u2016C\u2016S(q) = r\u2016\u03c3(C)\u2016q.\nBy our choice of X we have that\nX \u2022 C = Tr(X>C) = Tr(V Diag(\u03c3)>U>U\u03a3V >) = Tr(V Diag(\u03c3)>\u03a3V >) = Tr(V >V Diag(\u03c3)>\u03a3) = Tr(Diag(\u03c3)>\u03a3)\n= min(m,n)\u2211 i=1 \u2212 r \u2016\u03c3(C)\u2016q\u22121q \u03c3(C)q\u22121i \u00b7 \u03c3(C)i\n= \u2212 r \u2016\u03c3(C)\u2016q\u22121q min(m,n)\u2211 i=1 \u03c3(C)qi = \u2212r\u2016\u03c3(C)\u2016q.\nMoreover,\n\u2016X\u2016pS(p) = \u2016\u03c3(X)\u2016 p p = rp( \u2016\u03c3(C)\u2016q\u22121q )p n\u2211 i=1 ( \u03c3(C)q\u22121i )p .\nSince p = q/(q \u2212 1) we have that\n\u2016X\u2016pS(p) = rp\n\u2016\u03c3(C)\u2016qq n\u2211 i=1 |\u03c3(C)i|q = rp.\nThus we have that X \u2208 BS(p)(r).\nB.5. Proof of Lemma 8\nThe following lemma will be of use in the proof. Lemma 10. for any matrix A \u2208 Rm\u00d7n and s, p \u2208 (1, 2] it holds that\n\u2016A\u2016F \u2264 \u2016A\u2016s,p \u2264 n 1 s\u2212 1 2m 1 p\u2212 1 2 \u2016A\u2016F .\nProof. For any vector v \u2208 Rn and p \u2208 (1, 2] it holds that\n\u2016v\u20162 \u2264 \u2016v\u2016p \u2264 n 1 p\u2212 1 2 \u2016v\u20162. (13)\nDenote by Ai the ith row of A. For any i \u2208 [m] and p \u2208 (1, 2] it holds that\n\u2016Ai\u20162 \u2264 \u2016Ai\u2016p \u2264 n 1 p\u2212 1 2 \u2016Ai\u20162. (14)\nNote that by definition \u2016 \u00b7 \u2016F \u2261 \u2016 \u00b7 \u20162,2. Applying Eq. (13) and (14) we have,\n\u2016A\u2016F = \u2016A\u20162,2 = \u2016(\u2016A1\u20162, \u2016A2\u20162, ..., \u2016Am\u20162)\u20162 \u2264 \u2016(\u2016A1\u2016s, \u2016A2\u2016s, ..., \u2016Am\u2016s)\u2016p \u2264 n 1s\u2212 12m 1 p\u2212 1 2 \u2016(\u2016A1\u20162, \u2016A2\u20162, ..., \u2016Am\u20162)\u20162\n= n 1 s\u2212 1 2m 1 p\u2212 1 2 \u2016A\u2016F .\nWe can now prove Lemma 8.\nProof. Let z, q be such that 1/z+1/s = 1 and 1/q+1/p = 1. Note that z, q \u2208 [2,\u221e). The norm \u2016 \u00b7 \u2016z,q is the dual norm to \u2016 \u00b7 \u2016s,p (see (Kakade et al., 2012) for instance).\nAccording to Lemma 4, the functions \u2016x\u20162s and \u2016x\u20162p are \u03b1s = 2(s \u2212 1)-strongly convex w.r.t. \u2016 \u00b7 \u2016p and \u03b1p = 2(p \u2212 1)-strongly convex w.r.t. \u2016 \u00b7 \u2016q respectively. Hence by the strong convexity / smoothness duality (see Theorem 3 in (Kakade et al., 2012)) we have that the functions \u2016x\u20162z and \u2016x\u20162q are \u03b1\u22121s -smooth w.r.t. \u2016 \u00b7 \u2016z and \u03b1\u22121p -smooth w.r.t. \u2016 \u00b7 \u2016q respectively.\nBy Theorem 13 in (Kakade et al., 2012) we have that the function \u2016X\u20162z,q is (\u03b1\u22121p +\u03b1\u22121s )-smooth with respect to the norm \u2016\u00b7\u2016z,q . Again using the strong convexity / smoothness duality we have that \u2016X\u20162s,p is ( \u03b1\u22121p + \u03b1 \u22121 s )\u22121 = \u03b1p\u03b1s \u03b1p+\u03b1s strongly convex with respect to the norm \u2016 \u00b7 \u2016s,p. The first part of the lemma now follows from applying Lemma 3.\nSince Bs,p(r) is \u03b1 = (s\u22121)(p\u22121)(s+p\u22122)r strongly convex w.r.t. the norm \u2016\u00b7\u2016s,p, we have that givenX,Y \u2208 Bs,p(r), \u03b3 \u2208 [0, 1] and Z \u2208 Rm\u00d7n such that \u2016Z\u2016s,p \u2264 1 it holds that\n\u03b3X + (1\u2212 \u03b3)Y + \u03b1 2 \u03b3(1\u2212 \u03b3)\u2016X \u2212 Y \u20162s,pZ \u2208 Bs,p(r).\nGiven a matrix Z \u2032 \u2208 Rm\u00d7n such that \u2016Z \u2032\u2016F \u2264 1 we have that\n\u2016\u03b1 2 \u03b3(1\u2212 \u03b3)\u2016X \u2212 Y \u20162FZ \u2032\u2016s,p = \u03b1\n2 \u03b3(1\u2212 \u03b3)\u2016x\u2212 y\u20162F \u2016Z \u2032\u2016s,p.\nUsing Lemma 10 we have\n\u2016\u03b1 2 \u03b3(1\u2212 \u03b3)\u2016X \u2212 Y \u20162FZ \u2032\u2016s,p \u2264 \u03b1 2 \u03b3(1\u2212 \u03b3)\u2016X \u2212 Y \u20162s,pn 1 s\u2212 1 2m 1 p\u2212 1 2 \u2016Z \u2032\u2016F \u2264 \u03b1n 1 s\u2212 1 2m 1 p\u2212 1 2\n2 \u03b3(1\u2212 \u03b3)\u2016X \u2212 Y \u20162s,p.\nHence, Bs,p(r) is \u03b1n 1 s\u2212 1 2m 1 p\u2212 1 2 = n 1 s\u2212 1 2m 1 p\u2212 1 2\n(s\u22121)(p\u22121) (s+p\u22122)r strongly convex with respect\nto \u2016 \u00b7 \u2016F .\nB.6. Proof of Lemma 9\nProof. Since by choice of z, q it holds that \u2016 \u00b7 \u2016s,p, \u2016 \u00b7 \u2016z,q are dual norms, we have by Holder\u2019s inequality that\nX \u2022 C \u2265 \u2212\u2016X\u2016s,p\u2016C\u2016z,q \u2265 \u2212r\u2016C\u2016z,q.\nThus, choosing\nXi,j = \u2212 r\n\u2016C\u2016q\u22121z,q \u2016Ci\u2016z\u2212qz sgn(Ci,j)|Ci,j |z\u22121,\nwe have that X \u2022 C = \u2211\ni\u2208[m],j\u2208[n]\nXi,jCi,j =\n\u2211 i\u2208[m],j\u2208[n] \u2212 r \u2016C\u2016q\u22121z,q \u2016Ci\u2016z\u2212qz sgn(Ci,j)|Ci,j |z\u22121 \u00b7 Ci,j =\n\u2211 i\u2208[m],j\u2208[n] \u2212 r \u2016C\u2016q\u22121z,q \u2016Ci\u2016z\u2212qz |Ci,j |z =\n\u2211 i\u2208[m] \u2212 r \u2016C\u2016q\u22121z,q \u2016Ci\u2016z\u2212qz \u2211 j\u2208[n] |Ci,j |z =\n\u2211 i\u2208[m] \u2212 r \u2016C\u2016q\u22121z,q \u2016Ci\u2016z\u2212qz \u2016Ci\u2016zz = \u2211 i\u2208[m] \u2212 r \u2016C\u2016q\u22121z,q \u2016Ci\u2016qz = \u2212 r \u2016C\u2016q\u22121z,q \u2211 i\u2208[m] \u2016Ci\u2016qz = \u2212 r \u2016C\u2016q\u22121z,q \u2016C\u2016qz,q = \u2212r\u2016C\u2016z,q.\nMoreover, for all i \u2208 [m] it holds that\n\u2016Xi\u2016ss = n\u2211 j=1 |Xi,j |s = rs \u2016C\u2016s(q\u22121)z,q \u2016Ci\u2016s(z\u2212q)z n\u2211 i=j |Ci,j |s(z\u22121).\nSince s = z/(z \u2212 1) we have\n\u2016Xi\u2016ss = rs\n\u2016C\u2016s(q\u22121)z,q \u2016Ci\u2016s(z\u2212q)z \u2016Ci\u2016zz = \u2016Ci\u2016sq\u2212z(s\u22121)z \u2016C\u2016s(q\u22121)z,q rs\nUsing z = s/(s\u2212 1) we have that\n\u2016Xi\u2016ss = \u2016Ci\u2016s(q\u22121)z \u2016C\u2016s(q\u22121)z,q rs.\nThus,\n\u2016Xi\u2016s = ( \u2016Ci\u2016z \u2016C\u2016z,q )q\u22121 r.\nFinally, we have that\n\u2016X\u2016ps,p = \u2211 i\u2208[m] \u2016Xi\u2016ps = \u2211 i\u2208[m] ( \u2016Ci\u2016z \u2016C\u2016z,q )p(q\u22121) rp =\n\u2211 i\u2208[m] ( \u2016Ci\u2016z \u2016C\u2016z,q )q rp = rp \u2016C\u2016qz,q \u2211 i\u2208[m] \u2016Ci\u2016qz = rp.\nThus, X \u2208 Bs,p(r)."}], "references": [{"title": "Linear convergence of a modified frank-wolfe algorithm for computing minimum-volume enclosing ellipsoids", "author": ["References Ahipasaoglu", "S. Damla", "Sun", "Peng", "Todd", "Michael J"], "venue": "Optimization Methods and Software,", "citeRegEx": "Ahipasaoglu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ahipasaoglu et al\\.", "year": 2008}, {"title": "A conditional gradient method with linear rate of convergence for solving convex linear systems", "author": ["Beck", "Amir", "Teboulle", "Marc"], "venue": "Math. Meth. of OR,", "citeRegEx": "Beck et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Beck et al\\.", "year": 2004}, {"title": "Coresets, sparse greedy approximation, and the frank-wolfe algorithm", "author": ["Clarkson", "Kenneth L"], "venue": "In Proceedings of the Nineteenth Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "Clarkson and L.,? \\Q2008\\E", "shortCiteRegEx": "Clarkson and L.", "year": 2008}, {"title": "Approximate methods in optimization problems", "author": ["Demyanov", "Vladimir F", "Rubinov", "Aleksandr M"], "venue": null, "citeRegEx": "Demyanov et al\\.,? \\Q1970\\E", "shortCiteRegEx": "Demyanov et al\\.", "year": 1970}, {"title": "Lifted coordinate descent for learning with trace-norm regularization", "author": ["Dud\u0131\u0301k", "Miroslav", "Harchaoui", "Za\u0131\u0308d", "Malick", "J\u00e9r\u00f4me"], "venue": "Journal of Machine Learning Research Proceedings Track,", "citeRegEx": "Dud\u0131\u0301k et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dud\u0131\u0301k et al\\.", "year": 2012}, {"title": "Rates of Convergence for Conditional Gradient Algorithms Near Singular and Nonsingular Extremals", "author": ["Dunn", "Joseph C"], "venue": "SIAM Journal on Control and Optimization,", "citeRegEx": "Dunn and C.,? \\Q1979\\E", "shortCiteRegEx": "Dunn and C.", "year": 1979}, {"title": "An algorithm for quadratic programming", "author": ["M. Frank", "P. Wolfe"], "venue": "Naval Research Logistics Quarterly,", "citeRegEx": "Frank and Wolfe,? \\Q1956\\E", "shortCiteRegEx": "Frank and Wolfe", "year": 1956}, {"title": "Playing non-linear games with linear oracles", "author": ["Garber", "Dan", "Hazan", "Elad"], "venue": "In 54th Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "Garber et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Garber et al\\.", "year": 2013}, {"title": "A linearly convergent conditional gradient algorithm with applications to online and stochastic optimization", "author": ["Garber", "Dan", "Hazan", "Elad"], "venue": "CoRR, abs/1301.4666,", "citeRegEx": "Garber et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Garber et al\\.", "year": 2013}, {"title": "Some comments on Wolfe\u2019s \u2018away step", "author": ["Gu\u00e9Lat", "Jacques", "Marcotte", "Patrice"], "venue": "Mathematical Programming,", "citeRegEx": "Gu\u00e9Lat et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Gu\u00e9Lat et al\\.", "year": 1986}, {"title": "Large-scale image classification with trace-norm regularization", "author": ["Harchaoui", "Za\u0131\u0308d", "Douze", "Matthijs", "Paulin", "Mattis", "Dud\u0131\u0301k", "Miroslav", "Malick", "J\u00e9r\u00f4me"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Harchaoui et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Harchaoui et al\\.", "year": 2012}, {"title": "Sparse approximate solutions to semidefinite programs", "author": ["Hazan", "Elad"], "venue": "In 8th Latin American Theoretical Informatics Symposium, LATIN,", "citeRegEx": "Hazan and Elad.,? \\Q2008\\E", "shortCiteRegEx": "Hazan and Elad.", "year": 2008}, {"title": "Projection-free online learning", "author": ["Hazan", "Elad", "Kale", "Satyen"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "Hazan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2012}, {"title": "Revisiting frank-wolfe: Projection-free sparse convex optimization", "author": ["Jaggi", "Martin"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "Jaggi and Martin.,? \\Q2013\\E", "shortCiteRegEx": "Jaggi and Martin.", "year": 2013}, {"title": "A simple algorithm for nuclear norm regularized problems", "author": ["Jaggi", "Martin", "Sulovsk\u00fd", "Marek"], "venue": "In Proceedings of the 27th International Conference on Machine Learning,", "citeRegEx": "Jaggi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jaggi et al\\.", "year": 2010}, {"title": "Generalized power method for sparse principal component analysis", "author": ["Journ\u00e9e", "Michel", "Nesterov", "Yurii", "Richt\u00e1rik", "Peter", "Sepulchre", "Rodolphe"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Journ\u00e9e et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Journ\u00e9e et al\\.", "year": 2010}, {"title": "Regularization techniques for learning with matrices", "author": ["Kakade", "Sham M", "Shalev-Shwartz", "Shai", "Tewari", "Ambuj"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Kakade et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kakade et al\\.", "year": 2012}, {"title": "An affine invariant linear convergence analysis for frank-wolfe algorithms", "author": ["Lacoste-Julien", "Simon", "Jaggi", "Martin"], "venue": "CoRR, abs/1312.7864,", "citeRegEx": "Lacoste.Julien et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lacoste.Julien et al\\.", "year": 2013}, {"title": "Block-coordinate frank-wolfe optimization for structural svms", "author": ["Lacoste-Julien", "Simon", "Jaggi", "Martin", "Schmidt", "Mark W", "Pletscher", "Patrick"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "Lacoste.Julien et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lacoste.Julien et al\\.", "year": 2013}, {"title": "The complexity of large-scale convex programming under a linear optimization oracle", "author": ["Lan", "Guanghui"], "venue": "CoRR, abs/1309.5550,", "citeRegEx": "Lan and Guanghui.,? \\Q2013\\E", "shortCiteRegEx": "Lan and Guanghui.", "year": 2013}, {"title": "A hybrid algorithm for convex semidefinite optimization", "author": ["Laue", "S\u00f6ren"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "Laue and S\u00f6ren.,? \\Q2012\\E", "shortCiteRegEx": "Laue and S\u00f6ren.", "year": 2012}, {"title": "Constrained minimization methods", "author": ["Levitin", "Evgeny S", "Polyak", "Boris T"], "venue": "USSR Computational mathematics and mathematical physics,", "citeRegEx": "Levitin et al\\.,? \\Q1966\\E", "shortCiteRegEx": "Levitin et al\\.", "year": 1966}, {"title": "A regularization of the frankwolfe method and unification of certain nonlinear programming methods", "author": ["Migdalas", "Athanasios"], "venue": "Mathematical Programming,", "citeRegEx": "Migdalas and Athanasios.,? \\Q1994\\E", "shortCiteRegEx": "Migdalas and Athanasios.", "year": 1994}, {"title": "Large-scale convex minimization with a low-rank constraint", "author": ["Shalev-Shwartz", "Shai", "Gonen", "Alon", "Shamir", "Ohad"], "venue": "In Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 17, "context": "For matrix completion problems, metric learning, sparse PCA, structural SVM and other large-scale machine learning problems, this feature enabled the derivation of algorithms that are practical on one hand and come with provable convergence rates on the other (Jaggi & Sulovsk\u00fd, 2010; Lacoste-Julien et al., 2013; Dud\u0131\u0301k et al., 2012; Harchaoui et al., 2012; Hazan & Kale, 2012; Shalev-Shwartz et al., 2011; Laue, 2012).", "startOffset": 260, "endOffset": 419}, {"referenceID": 4, "context": "For matrix completion problems, metric learning, sparse PCA, structural SVM and other large-scale machine learning problems, this feature enabled the derivation of algorithms that are practical on one hand and come with provable convergence rates on the other (Jaggi & Sulovsk\u00fd, 2010; Lacoste-Julien et al., 2013; Dud\u0131\u0301k et al., 2012; Harchaoui et al., 2012; Hazan & Kale, 2012; Shalev-Shwartz et al., 2011; Laue, 2012).", "startOffset": 260, "endOffset": 419}, {"referenceID": 10, "context": "For matrix completion problems, metric learning, sparse PCA, structural SVM and other large-scale machine learning problems, this feature enabled the derivation of algorithms that are practical on one hand and come with provable convergence rates on the other (Jaggi & Sulovsk\u00fd, 2010; Lacoste-Julien et al., 2013; Dud\u0131\u0301k et al., 2012; Harchaoui et al., 2012; Hazan & Kale, 2012; Shalev-Shwartz et al., 2011; Laue, 2012).", "startOffset": 260, "endOffset": 419}, {"referenceID": 23, "context": "For matrix completion problems, metric learning, sparse PCA, structural SVM and other large-scale machine learning problems, this feature enabled the derivation of algorithms that are practical on one hand and come with provable convergence rates on the other (Jaggi & Sulovsk\u00fd, 2010; Lacoste-Julien et al., 2013; Dud\u0131\u0301k et al., 2012; Harchaoui et al., 2012; Hazan & Kale, 2012; Shalev-Shwartz et al., 2011; Laue, 2012).", "startOffset": 260, "endOffset": 419}, {"referenceID": 0, "context": "Also relevant in this context is the work of Ahipasaoglu, Sun and Todd (Ahipasaoglu et al., 2008) who showed that in the specific case of minimizing a smooth and strongly convex function over the unit simplex, a variant of the Frank-Wolfe method that also uses away steps converges with a linear rate.", "startOffset": 71, "endOffset": 97}, {"referenceID": 15, "context": "The following lemma is taken from (Journ\u00e9e et al., 2010) (Theorem 12).", "startOffset": 34, "endOffset": 56}, {"referenceID": 16, "context": "The following lemma is taken from (Kakade et al., 2012).", "startOffset": 34, "endOffset": 55}], "year": 2015, "abstractText": "The Frank-Wolfe method (a.k.a. conditional gradient algorithm) for smooth optimization has regained much interest in recent years in the context of large scale optimization and machine learning. A key advantage of the method is that it avoids projections the computational bottleneck in many applications replacing it by a linear optimization step. Despite this advantage, the known convergence rates of the FW method fall behind standard first order methods for most settings of interest. It is an active line of research to derive faster linear optimization-based algorithms for various settings of convex optimization. In this paper we consider the special case of optimization over strongly convex sets, for which we prove that the vanila FW method converges at a rate of 1 t2 . This gives a quadratic improvement in convergence rate compared to the general case, in which convergence is of the order 1t , and known to be tight. We show that various balls induced by `p norms, Schatten norms and group norms are strongly convex on one hand and on the other hand, linear optimization over these sets is straightforward and admits a closed-form solution. We further show how several previous fastrate results for the FW method follow easily from our analysis.", "creator": "LaTeX with hyperref package"}}}