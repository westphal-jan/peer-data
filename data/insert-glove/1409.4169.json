{"id": "1409.4169", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Sep-2014", "title": "An Algorithm Based on Empirical Methods, for Text-to-Tuneful-Speech Synthesis of Sanskrit Verse", "abstract": "tupolevs The naacp rendering urbanspoon of Sanskrit 26,875 poetry balassa from text to speech 4,411 is usd a problem 89.37 that has not been camouflage solved bacteriocins before. One reason may be usao the cavers complications multicity in the afrotropics language itself. al-aziz We ragab present cuckney unique algorithms bacardi based leadout on extensive empirical 104.30 analysis, to synthesize 2,994 speech \u0430 from detoxifying a sanjeev given text burdi input of Sanskrit verses. urz\u0119d\u00f3w Using quicken a pre - morainic recorded audio unauthorized units database bastad which tavakkoli is itself authoritatively tremendously reduced remodelers in edenderry size compared kowalski to collegehumor the (318) colossal size that sodomites would saarbruecken otherwise be bar-lev required, the engi algorithms work on producing the mingli best livgren possible, tunefully rendered chanting avoided of the agrega given 1115 verse. meiggs His would geldard enable 24.30 the visually mulo impaired and g\u00e9n\u00e9raux those ansolabehere with self-hatred reading tutuola disabilities to easily 2:52 access the devyn contents manfully of Sanskrit verses shtayyeh otherwise available eyelid only dovber in writing.", "histories": [["v1", "Mon, 15 Sep 2014 08:05:36 GMT  (227kb)", "http://arxiv.org/abs/1409.4169v1", "International Journal of Computer Science and Network Security, Vol.10, No. 1, January 2010"]], "COMMENTS": "International Journal of Computer Science and Network Security, Vol.10, No. 1, January 2010", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["rama n", "meenakshi lakshmanan"], "accepted": false, "id": "1409.4169"}, "pdf": {"name": "1409.4169.pdf", "metadata": {"source": "CRF", "title": "An Algorithm Based on Empirical Methods, for Text-to-Tuneful- Speech Synthesis of Sanskrit Verse", "authors": ["Rama N", "Meenakshi Lakshmanan"], "emails": [], "sections": [{"heading": null, "text": "Manuscript received January 5, 2010 Manuscript revised January 20, 2010\nAn Algorithm Based on Empirical Methods, for Text-to-TunefulSpeech Synthesis of Sanskrit Verse\nRama N.\u2020 and Meenakshi Lakshmanan\u2020\u2020\n\u2020Department of Computer Science, Presidency College, Chennai, India\n\u2020\u2020Department of Computer Science, Meenakshi College for Women, Chennai, India and\nResearch Scholar, Mother Teresa Women\u2019s University, Kodaikanal, India\nSummary The rendering of Sanskrit poetry from text to speech is a problem that has not been solved before. One reason may be the complications in the language itself. We present unique algorithms based on extensive empirical analysis, to synthesize speech from a given text input of Sanskrit verses. Using a prerecorded audio units database which is itself tremendously reduced in size compared to the colossal size that would otherwise be required, the algorithms work on producing the best possible, tunefully rendered chanting of the given verse. His would enable the visually impaired and those with reading disabilities to easily access the contents of Sanskrit verses otherwise available only in writing. Key words: Sanskrit, verse, text-to-speech, musical tones, speech synthesis, sandhi, metre."}, {"heading": "1. Introduction", "text": "Speech synthesis systems have proved to be extremely useful in improving the lives of the visually impaired and those with reading disabilities across the globe. However, such systems that cater to western language are not applicable in the Indian context, because of the huge difference in the structure and pronunciation schemes of Indian languages. Work has been done to bring Indian vernaculars to the people through speech synthesis [3, 16, 18], but there is a dearth of such work in the context of Sanskrit. Even a cursory glance at randomly chosen works in the Sanskrit literature would reveal that poetry hugely dominates the literature. The volume of the extant literature is vast and the contents profound, with topics ranging from grammar to spirituality, from medicine to geography. Listening to verses being chanted and committing them to memory has been a traditional practice. Similar is the case with chanting them tunefully. Obviously, rather good familiarity with the Sanskrit script is required to read the verses, and that too continuously,\nwith reasonable speed and with a tune. Thus, the visually impaired and those with reading disabilities would find themselves at a serious disadvantage, as would those who do not know how to read Sanskrit but would like to know or memorize verses. Further, in today\u2019s fast-moving world in which time is at a premium, a piece of software that reads out any desired Sanskrit poetical text would be welcome. We propose a comprehensive method based on empirical analysis, to convert Sanskrit poetical text to speech. This method is new, effective and produces output that is tuneful."}, {"heading": "2. The Problem", "text": "The most important qualities of a speech synthesis system are naturalness and intelligibility. Naturalness describes how closely the output sounds like human speech, while intelligibility is the ease with which the output is understood [7]. The most popular and simplest method of speech synthesizing is the concatenative method. Formant synthesis, the other major speech synthesis method, would inevitably compromise on naturalness of the voice output [5, 9, 12, 14]. We deal with only the concatenative method in this work. Sanskrit is a highly phonetic language, which adheres completely to the \u201cwhat you see is what you hear\u201d rule. Further, it is highly structured with stringent rules in its phonemic and morphological levels, but lends itself to extreme versatile in the higher syntactic, semantic and pragmatic levels. As such, the limit for framing new compound words in Sanskrit is only the poet\u2019s imagination and linguistic skill. This fact coupled with the complications posed by sandhi-s and case-inflectional forms or vibhakti-s, ensures that the standard method of text-to-speech synthesis, viz. creating a voice database of words in the dictionary and concatenating these stored audio files while parsing the verse, is well nigh impossible\nto apply in the case of Sanskrit, in spite of the highly phonetic nature of the language. Secondly, creating just the pronounced individual letters as audio files and then concatenating them while parsing the verse, would render a rather poorly pronounced verse, and in fact an incorrectly pronounced one. Consider the sample verse,\nvande gur\u016b\u1e47\u0101\u1e41 cara\u1e47\u0101ravinde sandar\u015bitassv\u0101tmasukh\u0101vabodhe | janasya ye j\u0101\u1e45galik\u0101yam\u0101ne sa\u1e41s\u0101rah\u0101l\u0101halamoha\u015b\u0101ntyai ||\nThe large compound word, sandar\u015bitassv\u0101tmasukh\u0101vabodhe\nis actually sandar\u015bita\u1e25 + sv\u0101tmasukh\u0101vabodhe to which a sandhi rule has been applied. There is no way one could have stored a priori, this entire compound word created on the fly by the poet. Similarly, the word janasya comes from the word jana\u1e25 which would be found in a dictionary, unlike janasya. The reason is that the sixth out of eight case-endings has been applied to the root word jana\u1e25 meaning \u201cpeople\u201d, resulting in janasya meaning \u201cof people\u201d. There are 24 such case-inflectional forms in total for every noun, and nine or eighteen for verbs in each of six tenses and four moods. Considering that the count of nouns and verbs is in the thousands, the storing and retrieval of audio snippets of all such case-inflectional forms would be prohibitive in terms of space and time for creation and retrieval. Pronouncing the verse letter by letter would give \u201cv + a + n + d + e\u201d, etc., which is incorrect pronunciation. Even if the unit of pronunciation be considered as a consonant with its succeeding vowel alone, it is insufficient, for \u201cva\u201d would be pronounced correctly, but there would be a problem again with streaming the \u201cn\u201d separately, for it would result in weird pronunciation. It is thus clear that none of the methods of speech synthesis outlined above would be effective in the case of Sanskrit text-to-speech processing. We present algorithms to make the output intelligible and constituting a correct reading of the verse with pauses as per the caesura data and also tunefully."}, {"heading": "3. The Precursor to this Work", "text": "Euphonic conjunctions or sandhi-s in Sanskrit are points between adjacent words or sub-words at which letters coalesce and transform. The application of sandhi is compulsory in Sanskrit verse, though the rules are not as stringent in the prose. A novel computational approach to sandhi processing based on building sandhi-s rather than splitting them, was developed by the authors [10]. This was done in accordance with the grammatical rules laid down by the ancient Sanskrit grammarian-genius P\u0101\u1e47ini in\nhis magnum opus, the A\u1e63\u1e6d\u0101dhy\u0101y\u012b and forms a comprehensive sandhi-building engine. An example of sandhi is: nama\u1e25 + \u015biv\u0101ya = nama\u015b\u015biv\u0101ya. The visarga letter (\u1e25) gets transformed because of the presence of the letter \u015b after it, into \u015b. This is an example of consecutive application of a visarga sandhi rule and the \u015bcutva sandhi rule [10]. Though the original words nama\u1e25 and \u015biv\u0101ya are independent words and are per se correct as they are, the rules of verse demand that the sandhi at their junction be applied and the transformation done as shown. This becomes relevant in the context of speech synthesis, because after the application of the sandhi rule, the two words become one compound word and, as a result of the doubling of the letter \u015b, is read with a stress on the letter. Secondly, verses in Sanskrit are classified into metres according to the number and type of syllables in the four quarters of the verse. Algorithms to efficiently parse and classify verses into more than 700 metres and to gather information about the caesura or points in the verse where a pause must be introduced while reading the verse, were developed by the authors [11]. Verses of different metres are read in different tempos, with pauses at different caesura and with different tunes. Hence the information provided by the metrical classification algorithm already developed by the authors to handle input verses in both Sanskrit Unicode and as E-text in the Latin character set, is an important input for this work."}, {"heading": "4. Text Pre-processing", "text": "4.1 Unicode Representation of Sanskrit Text\nThe Unicode (UTF-8) standard is what has been adopted universally for the purpose of encoding Indian language texts into digital format. The Unicode Consortium has assigned the Unicode hexadecimal range 0900 - 097F for Sanskrit characters. All characters including the diacritical characters used to represent Sanskrit letters in E-texts are found dispersed across the Basic Latin (0000-007F), Latin-1 Supplement (0080-00FF), Latin Extended-A (0100-017F) and Latin Extended Additional (1E00 \u2013 1EFF) Unicode ranges. The Latin character set has been employed in this paper to represent Sanskrit letters as E-text. The text given in the form of E-text using the Unicode Latin character set, is taken as input for processing. Unicode Sanskrit font is also accepted as input, but is converted to the Latin character form before processing begins, as already presented by the authors in [11].\n4.2 Sandhi Correction\nThe following sandhi rules are specifically relevant because the transformation wrought by them have a bearing on the pronunciation of the word. 1. For the letter combination \u201chn\u201d, such as in the word\n\u201cvahni\u201d, the normal pronunciation is actually \u201cnh\u201d, i.e. as \u201cvanhi\u201d. Thus, when the combination \u201chn\u201d is encountered in a word, it is replaced by \u201cnh\u201d.\n2. Sandhi rules with respect to the anusv\u0101ra are applied. For example, the word \u201csa\u1e41ny\u0101sa\u201d, split as \u201csa\u1e41+ny\u0101sa\u201d is normally not pronounced this way. Instead, it is pronounced as \u201csanny\u0101sa\u201d, the transformation being governed by a sandhi category called the parasavarna sandhi.\n3. Sandhi rules involving the transformation of the visarga. The example \u201cnama\u1e25 + \u015biv\u0101ya\u201d discussed earlier in Section 3 is a typical one.\n4. Sandhi rules for the jihv\u0101m\u016bliya (the aspirate sound produced near the base of the tongue while pronouncing the visarga that is followed by \u2018k\u2019 or \u2018kh\u2019) and the upadhm\u0101n\u012bya (the sound of \u2018f\u2019 while pronouncing the visarga that is followed by \u2018p\u2019 or \u2018ph\u2019) have to be applied for correct pronunciation. At the text pre-processing stage, such visarga-s are replaced appropriately by \u2018z\u2019 for the jihv\u0101m\u016bl\u012bya and by \u2018f\u2019 for the upadhm\u0101n\u012bya.\nThe algorithm in [10] serves to effect these corrections on the given verse.\n4.3 Identifying the Syllabic Units of the Verse\nThe text being processed has to be divided into singlesyllabic units at the pre-processing stage, in such a way that each of the units is pronounceable. This is riddled with problems and cannot be handled like European languages [1, 2, 4, 6, 8], as already discussed in Section 2 above. We refer to such pronounceable units as just \u2018units\u2019. A unit can have a maximum of three components:\n1. Vowel component 2. Pre-vowel component 3. Post-vowel component\nThe vowel component is central and indispensable to the unit. A unit would have the vowel component and optionally one or more of the other two components. Further, the pre-vowel and post-vowel components may consist of one or more characters. For our purposes, we use the categorization of the Sanskrit alphabet given in Table 1.\nThe following empirically determined cases constitute all the possibilities that arise while parsing a verse: 1. We parse the verse starting from the end of the last\nunit identified, until we encounter the first vowel. As we do so, we include all the letters on the way in the unit.\n2. If a consonant is encountered and it happens to be from the first or third columns of the Consonants category shown in Table 1, then we have to examine the following letter to see if it is an \u2018h\u2019. If it is, then the two letters together constitute a consonant belonging to the second or fourth rows of the Consonants category. This is important in order to correctly determine the next letter while parsing.\n3. If the vowel encountered = \u2018a\u2019 and is followed by \u2018i\u2019 or \u2018u\u2019, then the vowel is really \u2018ai\u2019 or \u2018au\u2019 respectively.\n4. If a visarga or anusv\u0101ra follows the vowel of the unit, then it is included in the unit and the unit is closed.\n5. If the vowel is followed by a consonant that is in turn followed by a vowel, then the unit is closed with the vowel itself. Eg: In the word \u201cgur\u016b\u1e47\u0101\u1e41\u201d, first \u2018g\u2019 is taken, and then the vowel \u2018u\u2019 is encountered. Now since the vowel of the unit is followed by a consonant (\u2018r\u2019) and then a vowel (\u2018\u016b\u2019), the unit is closed as \u201cgu\u201d. The next unit will begin with the \u2018r\u2019.\n6. If the vowel is followed by a consonant and then by a non-vowel, then the consonant is also included in the unit and the unit closes with that. Eg: In the word \u201cvande\u201d, after parsing upto \u201cva\u201d, it is found that the vowel \u2018a\u2019 of the unit is followed by a consonant (\u2018n\u2019)\nthat is in turn followed by a non-vowel (\u2018d\u2019). Hence, the unit includes \u2018n\u2019 also and is closed as \u201cvan\u201d.\n7. If the vowel is followed by the letter \u2018r\u2019, followed by a non-vowel and again a non-vowel (and any number of such non-vowels), then the unit is taken to include the letter \u2018r\u2019 and the non-vowel following it. Eg: In the word \u201ck\u0101rtsnya\u1e41\u201d, after \u201cka\u201d is parsed, we encounter \u2018r\u2019 followed by a non-vowel (\u2018t\u2019) and again a nonvowel (\u2018s\u2019). Thus, the unit is taken as \u201ck\u0101rt\u201d. Indeed, the word is pronounced as k\u0101rt-snya\u1e41.\n8. If the vowel is followed by \u2018r\u2019, then a non-vowel and then a vowel, then the unit is closed with the \u2018r\u2019. Eg: In the word \u201ck\u0101rya\u1e41\u201d, \u201ck\u0101\u201d is parsed, and after the following \u2018r\u2019, we have a non-vowel (\u2018y\u2019) and then a vowel (\u2018a\u2019). Hence the unit is closed as \u201ck\u0101r\u201d. The way the word is pronounced in Sanskrit is k\u0101r-ya\u1e41, and hence this is valid.\nExceptions to Rule 6: a. Whenever the vowel is followed by the consonant\npairs \u201cj\u00f1\u201d or \u201ck\u1e63\u201d then the unit is closed with the vowel itself. Eg: In the word \u201caj\u00f1\u0101\u201d, the pronunciation is a-j\u00f1\u0101 and not aj-\u00f1\u0101 as Rule 6 would have it.\nb. In cases where the consonant pairs \u201cpr\u201d or \u201cbr\u201d or \u201ckr\u201d or the consonant \u2018h\u2019 follow a short vowel, the unit is closed with the vowel itself. Eg: The word \u201csapriya\u1e25\u201d is to be pronounced sa-priya\u1e25 and not as sap-riya\u1e25 as would be required by Rule 6.\nWe propose the following parsing algorithm that parses a given verse, handles all the above cases including the exceptions and recognizes the units in the verse. Algorithm SplitVerseIntoUnits //strVerse is a string variable that contains the entire verse. //strVerse(i) denotes its i-th character. //strUnit is a string variable storing the unit being //processed. It is initialized to the empty string. i = 0; while i < strVerse.length() do\nwhile strVerse(i) is not a vowel do //parse till 1st vowel append strVerse(i) to strUnit; i = i + 1; end while if k = \u2018a\u2019 and (k1 = \u2018i\u2019 or k1 = \u2018u\u2019) then\nappend k1 to strUnit; i = i + 1;\nend if k = strVerse(i); //the first vowel in the unit k1 = strVerse(i+1); if k1 is a consonant\nif (k1 = \u2018k\u2019 or k1 = \u2018g\u2019 or k1 = \u2018c\u2019 or k1 = \u2018j\u2019 or k1 = \u2018\u1e6d\u2019 or k1 = \u2018\u1e0d\u2019 or k1 = \u2018t\u2019 or k1 = \u2018d\u2019 or k1 = \u2018p\u2019 or k1 = \u2018b\u2019) and strVerse(i+2) = \u2018h\u2019 then\ni = i + 1;\nend if end if k2 = strVerse(i+2); if k2 is a consonant\nif (k2 = \u2018k\u2019 or k2 = \u2018g\u2019 or k2 = \u2018c\u2019 or k2 = \u2018j\u2019 or k2 = \u2018\u1e6d\u2019 or k2 = \u2018\u1e0d\u2019 or k2 = \u2018t\u2019 or k2 = \u2018d\u2019 or k2 = \u2018p\u2019 or k2 = \u2018b\u2019) and strVerse(i+3) = \u2018h\u2019 then\ni = i + 1; end if\nend if k3 = strVerse(i+3); append k to strUnit; if k1 is visarga or k1 is anusv\u0101ra then\nappend k1 to strUnit; close strUnit and initialize to empty string to hold the next unit;\nelse if k1 is a consonant if k2 is a vowel then\nclose strUnit and initialize to empty string to hold the next unit;\nelse if (k2=\u2018j\u2019and k3=\u2018\u00f1\u2019) or (k2=\u2018k\u2019 and k3=\u2018\u1e63\u2019) then close strUnit and initialize to empty string to hold the next unit; else if (k is a short vowel) and (k2k3 = \u201cpr\u201d or k2k3 = \u201cbr\u201d or k2k3 = \u201ckr\u201d or k2 = \u2018h\u2019) then\nclose strUnit and initialize to empty string to hold the next unit;\nelse //k2 not vowel, above exceptions do not hold append k1 to strUnit; close strUnit and initialize to empty string to hold the next unit;\nend if else if k1 is \u2018r\u2019 and k2 is not a vowel\nif k3 is not a vowel then append k1 to strUnit; append k2 to strUnit; close strUnit and initialize to empty string to hold the next unit; else //k3 is a vowel append k1 to strUnit; close strUnit and initialize to empty string to hold the next unit;\nend if end if i = i + 1;\nend while end Algorithm"}, {"heading": "5. The Audio Units Database", "text": "Determining the units to be recorded as audio files and stored in a database is a non-trivial task, as is clear from the discussions in Sections 2 and 4 above. The possible number of such recordable units is huge. There are a total\nof 34 letters in the consonants, semi-vowel, sibilant and aspirate categories, and 13 vowels. As such, for the units with one consonant and one vowel, we would have possible 34 x 13 = 442 recordable units, which seems feasible. But for units having two consonants, a vowel and a consonant, there are theoretically 34 * 13 * 34 * 34 = 510, 952 recordable units possible! The number of cases with more than two consonants in close succession would obviously be much greater. Thus, we see that there is a combinatorial explosion of the number of required recordable units in this scheme. This problem was surmounted by extensively analyzing the words present in a comprehensive Sanskrit dictionary [13]. Pronounceable units were gathered through this exercise, and the total number of units for practical use was thus substantially reduced. Further, the glyphs of the Sanskrit 2003 font were also studied and some possible units were eliminated as unpronounceable. This font was particularly chosen because it provides a plethora of composite glyphs as well. In this manner, the number of readable units was significantly reduced to yield a database size of just approximately 2000 recorded unit clips. The recording of each unit was done in the same vocal pitch. However, the length of intoning of the sound was varied according as whether the unit being intoned has a long (guru) vowel or a short (laghu) one. All long vowels are guru and all short vowels are laghu. The exception is that laghu vowels become guru if they are 1. followed by double consonants (this being optional in\nthe case of pr, br, kr and h) 2. followed by anusv\u0101ra or visarga All laghu units were recorded in one time unit, and all guru ones, in two. For example, in the sample verse given in Section 2 above, the word \u201cvande\u201d has two units, \u201cvan\u201d and \u201cde\u201d, which are respectively of the laghu and guru kinds. As such, \u201cvan\u201d was recorded in one time unit (2 seconds) and \u201cde\u201d in two time units (4 seconds). The reason for using 2 and 4 seconds rather than perhaps 1 and 2 seconds, is that a units have different number of letters in them and yet have to be intoned in the same time span. For example, the units k\u0101 and k\u0101rt are both guru units, and hence must each be intoned in two time units. However, it would clearly take a little longer to pronounce the whole of k\u0101rt than it would to pronounce k\u0101. Hence, the k\u0101 would have to elongated and recorded. It is to provide for this that the longer time spans of 2 and 4 seconds were fixed and followed during the recording process. The purpose of assigning the duration of an audio clip based on whether the unit being pronounced is laghu or guru, is to help make the synthesized chanting of the verse follow a beat. This factor is important in order to achieve\nnear-human reproduction of verse-chanting. The beat to be followed for a verse would vary according to the metre and associated caesura of the verse [11]."}, {"heading": "6. The Musical Component of the Speech", "text": "Synthesizer\nIndian music is similar to its Western counterpart in the context of the theory of notes and octaves. There are a total of 12 notes in each octave, with the notes separated by a few frequencies. The basic notes bear the names sa, ri (soft), ri, ga (soft), ga, ma, ma (sharp), pa, dha (soft), dha, ni (soft), ni. These 12 notes repeat themselves in higher and higher levels of frequencies, and thus are octaves formed. To make the chanting of the verse tuneful, it is necessary to introduce these musical notes. The fundamental idea is that slight changes made to the frequency of the recorded audio unit file, results in a change of the musical note at which the unit is heard when played. The changes have necessarily to be slight, for otherwise it is found that the very texture of the voice changes with vast changes in frequency.\nLet u1, u2, \u2026 un be the n units constituting the given verse. Now the two variables associated with each such unit are the syllable intoned and the pitch of the sound. We will assume that the same octave is maintained throughout. Let pi denote the pitch at which ui should be intoned in order for the verse to be chanted tunefully. Thus, the final output for the ith unit is a function f of ui and pi. Thus, the final\nspeech output is not just \u2211 but \u2211 , where summation here stands for concatenation. The pitch levels p1, p2, \u2026 pn for the n syllables of a verse\u2019s quarter, were fixed for the categories of metres enumerated and stored in the database created for the earlier work on metre classification outlined in Section 3 [11]. Here, n may vary from 1 to 26 for equal-quarter-metres, as well as metres for with half-equal as also unequal quarters. The values of pi were fixed according to the general scheme presented in Table 2. By tradition, the note pa is considered as the middle note and therefore assigned the value 0. We create an array p[] containing the pi values for each category of metres from 1 to 26 syllables per quarter and also for the half-equal and unequal metres. Consider the two examples depicted in Tables 3 and 4."}, {"heading": "7. The Algorithm for Text-to-Tuneful-Speech", "text": "Initially, the verse is parsed by the metre classification algorithm and converted to its binary representation with laghu syllables taking the value 0 and guru syllables taking the value 1 [11]. For the sample verse given in Section 2 above, Table 5 depicts the binary representation thus obtained. However, this may not match with the binary representation of individual units in the current context. Table 6 depicts the scenario generated by the consideration of individual units. The reason for this discrepancy seen between Tables 5 and 6, is that in the current context depicted by Table 6, we are considering units as individual entities and independently categorizing them as laghu and guru. However, in the case of Table 5, we are considering each syllable in conjunction with the following one and making corrections to the laghu-guru status. For instance, \u201cvan\u201d has a short vowel and is hence valued at 0 in Table 6. However, the full context of \u201cvan\u201d is \u201cvande\u201d, and so the double consonant \u201cnd\u201d after the vowel \u2018a\u2019 forces the syllable \u201cvan\u201d to be considered as guru and not laghu (as discussed in Section 5). Hence it is valued at 1 in Table 5.\nNow since we assign 1 unit of time to a laghu syllable and 2 units to a guru one, we adopt the following notation. Let vi be the actual value of unit ui (as per Table 5 and used for metre identification). We denote by TE, the expected total units of time to chant the quarter of the verse under consideration, and by TA, the actual total units of time to chant the concerned quarter. Therefore, we have\nTE = \u2211 \u00a01 TA = \u2211 \u00a01 Clearly, TA \u2264 TE, because short syllables in the units may be converted to long if factors regarding the adjacent unit are taken into consideration. However, long syllables are never converted to short.\nWe present a general algorithm to adjust the beat of the chant, the chanting being achieved by concatenating the pre-recorded unit audio clips. One solution to making sure the beat is maintained, is to insert single units of silence when a unit is being intoned as laghu instead of guru. However, since a period of silence cannot be introduced in the middle of a word, in such cases, the syllabic unit being considered can be stretched to cover one more time unit. Algorithm ConcatenateUnits nTotalUnits = n; if TA < TE then\nk = 1; while k <= nTotalUnits do\nif tk < vk then if k is the end of a word then\ninsert 1 time unit of silence at position k+1; else\nstretch the kth audio unit; end if nTotalUnits = nTotalUnits + 1;\nend if end while\nend if n = nTotalUnits; concatenate f(u1, p1), f(u2, p2) \u2026 f(un, pn); append 1 time unit of silence at caesura of the metre; end Algorithm"}, {"heading": "8. The Overall Synthesis Algorithm", "text": "We now present the overall algorithm incorporating all factors discussed above. Algorithm VerseTextToTunefulSpeechSynthesizer Step 1: Parse the verse and identify its metre, caesura and retrieve the stored pitch array values; Step 2: Apply sandhi rules to correct the specific cases where the pronunciation would change; Step 3: Call Algorithm SplitVerseIntoUnits, to identify the pronounceable units in the verse; Step 4: Retrieve the appropriate audio file for each unit from a file collection; Step 5: Call Algorithm ConcatenateUnits, to adjust the beat of the chanting and also to apply the note (pitch) variations to make the chanting tuneful; Step 6: Play the concatenated file; end Algorithm\nThe audio unit files were stored as .wav files and the concatenation was done by streaming them consecutively into a target .wav file. It was found that the function f (ui, pi) used to change the frequency and hence the musical tone of the audio file may be realized both through the free APIs provided with the versatile open source software\nAudacity [15] and through the Microsoft DirectX SDK [17]. Clearly, the accuracy of the output is dependent on the tone and time duration of the recorded audio units. As such, during testing, changes to these audio unit files in terms of the intoning pitch and more importantly the time for which individual units were recorded, had to be made. This drastically improved the output quality."}, {"heading": "9. Conclusions", "text": "Text-to-speech synthesis of Sanskrit verse is a hitherto unsolved problem. The fact is that such synthesis is problem-ridden owing to the numerous complexities inherent in the Sanskrit language in general and versification in particular. This work presents a beguilingly simple, yet comprehensive and effective solution based on the concatenative method of text-tospeech synthesis. The novel method presented here does not suffer from any performance bottlenecks. This work utilizes earlier work by the authors on metrical classification of Sanskrit verses and on the P\u0101\u1e47inian method of sandhi processing, and builds a Text-to-speech synthesizer for Sanskrit Verse. Empirical methods of analysis were used to create algorithms for splitting the verse into bits of pronounceable text and to significantly reduce the audio corpora required for the algorithm to function reasonably well. Furthermore, since Sanskrit verses are always tunefully chanted rather than uttered in a prosaic way, this solution incorporates a unique musical element too, and achieves a tuneful rendering of verses of various metres through manipulation of the frequency of the sound at appropriate places. The work would be of tremendous use to those with visual impairments or reading disabilities, who would want to listen to and even memorize Sanskrit verses from any text they wish."}], "references": [{"title": "Preselection of candidate units in a unit selectionbased text-to-speech synthesis system", "author": ["Alistair Conkie", "Mark Beutnagel", "Ann Syrdal", "Philip Brown"], "venue": "Proceedings of ICSLP,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Unit selection in a concatenative speech synthesis system", "author": ["Andrew Hunt", "Alan Black"], "venue": "Proceedings of ICASSP'96,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1996}, {"title": "Sparsha: A Comprehensive Indian Language Toolset for the Blind", "author": ["Anirban Lahiri", "Satya Jyoti Chattopadhyay", "Anupam Basu"], "venue": "Proceedings of the 7th international ACM SIGACCESS conference on Computers and accessibility,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Statistical modeling for unit selection in speech synthesis", "author": ["Cyril Allauzen", "Mehryar Mohri", "Michael Riley"], "venue": "Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Unit selection using k-nearest neighbor search for concatenative speech synthesis", "author": ["Hideyuki Mizuno", "Satoshi Takahashi"], "venue": "Proceedings of the 3rd International Universal Communication Symposium,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "From Text to Speech: The MITalk", "author": ["Jonathan Allen", "M. Sharon Hunnicutt", "Dennis Klatt"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1987}, {"title": "Rapid unit selection from a large speech corpus for concatenative speech synthesis", "author": ["Mark Beutnagel", "Mehryar Mohri", "Michael Riley"], "venue": "Proceedings of Eurospeech,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1999}, {"title": "Speech synthesis for phonetic and phonological models, Thomas A", "author": ["Mattingly", "Ignatius G"], "venue": "Sebeok (Ed.), Current Trends in Linguistics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1974}, {"title": "A New Computational Schema for Euphonic Conjunctions in Sanskrit Processing", "author": ["Rama N", "Meenakshi Lakshmanan"], "venue": "IJCSI International Journal of Computer Science Issues,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "A Computational Algorithm for Metrical Classification of Verse, submitted to IJCSI International", "author": ["Rama N", "Meenakshi Lakshmanan"], "venue": "Journal of Computer Science Issues,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "An articulatory synthesizer for perceptual research", "author": ["P. Rubin", "T. Baer", "Mermelstein P"], "venue": "Journal of the Acoustical Society of America,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1981}, {"title": "Practical Sanskrit-English Dictionary, Motilal Banarsidass Publishers Pvt", "author": ["Vaman Shivram Apte"], "venue": "Ltd., Delhi,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}], "referenceMentions": [{"referenceID": 2, "context": "Work has been done to bring Indian vernaculars to the people through speech synthesis [3, 16, 18], but there is a dearth of such work in the context of Sanskrit.", "startOffset": 86, "endOffset": 97}, {"referenceID": 5, "context": "Naturalness describes how closely the output sounds like human speech, while intelligibility is the ease with which the output is understood [7].", "startOffset": 141, "endOffset": 144}, {"referenceID": 7, "context": "Formant synthesis, the other major speech synthesis method, would inevitably compromise on naturalness of the voice output [5, 9, 12, 14].", "startOffset": 123, "endOffset": 137}, {"referenceID": 10, "context": "Formant synthesis, the other major speech synthesis method, would inevitably compromise on naturalness of the voice output [5, 9, 12, 14].", "startOffset": 123, "endOffset": 137}, {"referenceID": 8, "context": "A novel computational approach to sandhi processing based on building sandhi-s rather than splitting them, was developed by the authors [10].", "startOffset": 136, "endOffset": 140}, {"referenceID": 8, "context": "This is an example of consecutive application of a visarga sandhi rule and the \u015bcutva sandhi rule [10].", "startOffset": 98, "endOffset": 102}, {"referenceID": 9, "context": "Algorithms to efficiently parse and classify verses into more than 700 metres and to gather information about the caesura or points in the verse where a pause must be introduced while reading the verse, were developed by the authors [11].", "startOffset": 233, "endOffset": 237}, {"referenceID": 9, "context": "Unicode Sanskrit font is also accepted as input, but is converted to the Latin character form before processing begins, as already presented by the authors in [11].", "startOffset": 159, "endOffset": 163}, {"referenceID": 8, "context": "The algorithm in [10] serves to effect these corrections on the given verse.", "startOffset": 17, "endOffset": 21}, {"referenceID": 0, "context": "This is riddled with problems and cannot be handled like European languages [1, 2, 4, 6, 8], as already discussed in Section 2 above.", "startOffset": 76, "endOffset": 91}, {"referenceID": 1, "context": "This is riddled with problems and cannot be handled like European languages [1, 2, 4, 6, 8], as already discussed in Section 2 above.", "startOffset": 76, "endOffset": 91}, {"referenceID": 3, "context": "This is riddled with problems and cannot be handled like European languages [1, 2, 4, 6, 8], as already discussed in Section 2 above.", "startOffset": 76, "endOffset": 91}, {"referenceID": 4, "context": "This is riddled with problems and cannot be handled like European languages [1, 2, 4, 6, 8], as already discussed in Section 2 above.", "startOffset": 76, "endOffset": 91}, {"referenceID": 6, "context": "This is riddled with problems and cannot be handled like European languages [1, 2, 4, 6, 8], as already discussed in Section 2 above.", "startOffset": 76, "endOffset": 91}, {"referenceID": 11, "context": "This problem was surmounted by extensively analyzing the words present in a comprehensive Sanskrit dictionary [13].", "startOffset": 110, "endOffset": 114}, {"referenceID": 9, "context": "The beat to be followed for a verse would vary according to the metre and associated caesura of the verse [11].", "startOffset": 106, "endOffset": 110}, {"referenceID": 9, "context": "pn for the n syllables of a verse\u2019s quarter, were fixed for the categories of metres enumerated and stored in the database created for the earlier work on metre classification outlined in Section 3 [11].", "startOffset": 198, "endOffset": 202}, {"referenceID": 9, "context": "Initially, the verse is parsed by the metre classification algorithm and converted to its binary representation with laghu syllables taking the value 0 and guru syllables taking the value 1 [11].", "startOffset": 190, "endOffset": 194}], "year": 2010, "abstractText": "The rendering of Sanskrit poetry from text to speech is a problem that has not been solved before. One reason may be the complications in the language itself. We present unique algorithms based on extensive empirical analysis, to synthesize speech from a given text input of Sanskrit verses. Using a prerecorded audio units database which is itself tremendously reduced in size compared to the colossal size that would otherwise be required, the algorithms work on producing the best possible, tunefully rendered chanting of the given verse. His would enable the visually impaired and those with reading disabilities to easily access the contents of Sanskrit verses otherwise available only in writing.", "creator": "PScript5.dll Version 5.2.2"}}}