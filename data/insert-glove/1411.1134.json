{"id": "1411.1134", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2014", "title": "Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems", "abstract": "retch The Burer - dotel Monteiro euro326 decomposition ($ X = Y Y ^ gaffney T $) bhanpura with companys stochastic gradient koobface descent \u00f8stfold is fortuna commonly shobashobane employed dorridge to pandemrix speed lanning up vil\u00e1 and coldstone scale brealey up o'connell matrix gerosa problems including 76.99 matrix completion, duvivier subspace flag-raising tracking, maslyukov and grobler SDP geopark relaxation. Although tillers it steamers is 98.05 widely used abgal in dolphin practice, there exist dirani no moberg known global semiautomatics convergence zetter results prosperous for lebrock this method. In this farabee paper, flycatching we ilyas prove morrisroe that, under 167.5 broad sampling 27-point conditions, 118.26 a misplays first - order rank - 1 26b stochastic gradient dogma descent (nazlat SGD) mehanna matrix wristy recovery scheme konstanty converges 32-6 globally confcommercio from saenz a psycho random sokolovsky starting 21sec point at a $ eucla O (\\ jokinen epsilon ^ {- 1} mitchum n \\ log n) $ kinkladze rate with dejun constant probability. tantrum We demonstrate our method saddam experimentally.", "histories": [["v1", "Wed, 5 Nov 2014 03:05:43 GMT  (48kb)", "https://arxiv.org/abs/1411.1134v1", null], ["v2", "Thu, 6 Nov 2014 03:10:29 GMT  (48kb)", "http://arxiv.org/abs/1411.1134v2", null], ["v3", "Tue, 10 Feb 2015 20:19:28 GMT  (67kb)", "http://arxiv.org/abs/1411.1134v3", null]], "reviews": [], "SUBJECTS": "cs.LG math.OC stat.ML", "authors": ["christopher de sa", "christopher r\u00e9", "kunle olukotun"], "accepted": true, "id": "1411.1134"}, "pdf": {"name": "1411.1134.pdf", "metadata": {"source": "CRF", "title": "Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems", "authors": ["Christopher De Sa", "Kunle Olukotun"], "emails": ["cdesa@stanford.edu,", "kunle@stanford.edu,", "chrismre@stanford.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n41 1.\n11 34\nv3 [\ncs .L\nG ]\n1 0"}, {"heading": "1 Introduction", "text": "We analyze an algorithm to solve the stochastic optimization problem\nminimize E\n[\n\u2225 \u2225 \u2225A\u0303\u2212X \u2225 \u2225 \u2225 2\nF\n]\nsubject to X \u2208 Rn\u00d7n, rank (X) \u2264 p,X 0, (1)\nwhere p is an integer and A\u0303 is a symmetric matrix drawn from some distribution with bounded covariance. The solution to this problem is the matrix formed by zeroing out all but the largest p eigenvalues of the matrix E[A\u0303]. This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].\nSometimes, (1) arises under conditions in which the samples A\u0303 are sparse, but the matrix X would be too large to store and operate on efficiently; a standard heuristic to use in this case is a low-rank factorization [9]. The idea is to substitute X = Y Y T and solve the problem\nminimize E\n[\n\u2225 \u2225 \u2225A\u0303\u2212 Y Y T \u2225 \u2225 \u2225 2\nF\n]\nsubject to Y \u2208 Rn\u00d7p. (2)\nBy construction, if we set X = Y Y T , then X \u2208 Rn\u00d7n, rank (X) \u2264 p, and X 0; this allows us to drop these constraints. Instead of having to store the matrix X (of size n2), we only need to store the matrix Y (of size np).\nIn practice, many people use stochastic gradient descent (SGD) to solve (2). Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36]. However, standard stochastic gradient descent on (2) does not converge globally, in the sense that there will always be some initial values for which the norm of the iterate will diverge (see Appendix A).\nPeople have attempted to compensate for this with sophisticated methods like geodesic step rules [27] and manifold projections [1]; however, even these methods cannot guarantee global convergence. Motivated by this, we describe Alecton, an algorithm for solving (2), and analyze its convergence. Alecton is an SGDlike algorithm that has a simple update rule with a step size that is a simple function of the norm of the iterate Yk. We show that Alecton converges globally. We make the following contributions:\n\u2022 We establish the convergence rate to a global optimum of Alecton using a random initialization; in contrast, prior analyses [11, 25] have required more expensive initialization methods, such as the singular value decomposition of an empirical average of the data.\n\u2022 In contrast to previous work that uses bounds on the magnitude of the noise [21], our analysis depends only on the variance of the samples. As a result, we are able to be robust to different noise models, and we apply our technique to these problems, which did not previously have global convergence rates:\n\u2013 matrix completion, in which we observe entries of A one at a time [25, 28] (Section 4.1),\n\u2013 phase retrieval, in which we observe tr(uTAv) for randomly selected u, v [11, 13] (Section 4.3), and\n\u2013 subspace tracking, in which A is a projection matrix and we observe random entries of a random vector in its column space [6] (Section 4.4).\nOur result is also robust to different noise models.\n\u2022 We describe a martingale-based analysis technique that is novel in the space of non-convex optimization. We are able to generalize this technique to some simple regularized problems, and we are optimistic that it has more applications."}, {"heading": "1.1 Related Work", "text": "Much related work exists in the space of solving low-rank factorized optimization problems. Foundational work in this space was done by Burer and Monteiro [9, 10], who analyzed the low-rank factorization of general semidefinite programs. Their results focus on the classification of the local minima of such problems, and on conditions under which no non-global minima exist. They do not analyze the convergence rate of SGD.\nAnother general analysis in Journe\u0301e et al. [27] exhibits a second-order algorithm that converges to a local solution. Their results use manifold optimization techniques to optimize over the manifold of lowrank matrices. These approaches have attempted to correct for falling off the manifold using Riemannian retractions [27], geodesic steps [6], or projections back onto the manifold. General non-convex manifold optimization techniques [1] tell us that first-order methods, such as SGD, will converge to a fixed point, but they provide no convergence rate to the global optimum. Our algorithm only involves a simple rescaling, and we are able to provide global convergence results.\nOur work follows others who have studied individual problems that we consider. Jain et al. [25] study matrix completion and provides a convergence rate for an exact recovery algorithm, alternating minimization. Cande\u0300s et al. [11] provide a similar result for phase retrieval. In contrast to these results, which require expensive SVD-like operations to initialize, our results allow random initialization. Our provided convergence rates apply to additional problems and SGD algorithms that are used in practice (but are not covered\nby previous analysis). However, our convergence rates are slower in their respective settings. This is likely unavoidable in our setting, as we show that our convergence rate is optimal in this more general setting (see Appendix E).\nA related class of algorithms that are similar to Alecton is stochastic power iteration [3]. These algorithms reconsider (1) as an eigenvalue problem, and uses the familiar power iteration algorithm, adapted to a stochastic setting. Stochastic power iteration has been applied to a wide variety of problems [3, 26]. Oja [31] show convergence of this algorithm, but provides no rate. Arora et al. [4] analyze this problem, and state that \u201cobtaining a theoretical understanding of the stochastic power method, or of how the step size should be set, has proved elusive.\u201d Our paper addresses this by providing a method for selecting the step size, although our analysis shows convergence for any sufficiently small step size.\nShamir [35] provide exponential-rate local convergence results for a stochastic power iteration algorithm for PCA. As they note, it can be used in practice to improve the accuracy of an estimate returned by another, globally-convergent algorithm such as Alecton.\nAlso recently, Balsubramani et al. [5] and Hardt and Price [21] provide a global convergence rate for the stochastic power iteration algorithm. Our result only depends on the variance of the samples, while both their results require absolute bounds on the magnitude of the noise. This allows us to analyze a different class of noise models, which enables us to do matrix completion, phase retrieval, and subspace tracking in the same model."}, {"heading": "2 Algorithmic Derivation", "text": "We focus on the low-rank factorized stochastic optimization problem (2). We can rewrite the objective as\nE\n[ f\u0303(Y ) ] , with sampled objective function\nf\u0303(Y ) = tr ( Y Y TY Y T ) \u2212 2tr ( Y A\u0303Y T ) + \u2225 \u2225 \u2225A\u0303 \u2225 \u2225 \u2225 2\nF .\nIn the analysis that follows, we let A = E [ A\u0303 ]\n, and let its eigenvalues be \u03bb1 \u2265 \u03bb2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03bbn with corresponding orthonormal eigenvectors u1, u2, . . . , un (such a decomposition is guaranteed since A is symmetric). The standard stochastic gradient descent update rule for this problem is, for some step size \u03b1k,\nYk+1 = Yk \u2212 \u03b1k\u2207f\u0303k(Y )\n= Yk \u2212 4\u03b1k ( YkY T k Yk \u2212 A\u0303kYk ) ,\nwhere A\u0303k is the sample we use at timestep k. The low-rank factorization introduces symmetry into the problem. If we let\nOp = { U \u2208 Rp\u00d7p | UTU = Ip }\ndenote the set of orthogonal matrices in Rp\u00d7p, then f\u0303(Y ) = f\u0303(Y U) for any U \u2208 Op. Previous work has used manifold optimization techniques to solve such symmetric problems [27]. Absil et al. [1] state that stochastic gradient descent on a manifold has the general form\nxk+1 = xk \u2212 \u03b1kG\u22121xk \u2207f\u0303k(xk),\nwhere Gx is the matrix such that for all u and v,\nuTGxv = \u3008u, v\u3009x,\nwhere the right side of this equation denotes the Riemannian metric [15] of the manifold at x. For (2), the manifold in question is M = Rn\u00d7p/Op, which is the quotient manifold of Rn\u00d7p under the orthogonal group action. According to Absil et al. [1], this manifold has induced Riemannian metric\n\u3008U, V \u3009Y = tr ( UY TY V T ) . (3)\nFor Alecton, we are free to pick any Riemannian metric and step size. Inspired by (3), we pick a new step size parameter \u03b7, and let \u03b1k = 1 4\u03b7 and set\n\u3008U, V \u3009Y = tr ( U(I + \u03b7Y TY )V T ) .\nWith this, the SGD update rule becomes\nYk+1 = Yk \u2212 \u03b7 ( YkY T k Yk \u2212 A\u0303kYk ) ( I + \u03b7Y Tk Yk )\u22121\n= ( Yk ( I + \u03b7Y Tk Yk ) \u2212 \u03b7 ( YkY T k Yk \u2212 A\u0303kYk )) ( I + \u03b7Y Tk Yk )\u22121\n= (\nI + \u03b7A\u0303k\n)\nYk ( I + \u03b7Y Tk Yk )\u22121 .\nFor p = 1, choosing a Riemannian metric to use with SGD results in the same algorithm as choosing an SGD step size that depends on the iterate Yk. The same update rule would result if we substituted\n\u03b1k = 1\n4 \u03b7 (\n1 + \u03b7Y TY )\u22121\ninto the standard SGD update formula. We can think of this as the manifold results giving us intuition on how to set our step size.\nThe reason why selecting this particular step size/metric is useful in practice is that we can run the simpler update rule\nY\u0304k+1 = ( I + \u03b7A\u0303k ) Y\u0304k. (4)\nIf Y\u03040 = Y0, the iteration will satisfy the property that the column space of Yk will always be equal to the column space of Y\u0304k, (since C(XY ) = C(X) for any invertible matrix Y ). That is, if we just care about computing the column space of Yk, we can do it using the much simpler update rule (4). Intuitively, we have transformed an optimization problem operating in the whole space Rn to one operating on the Grassmannian; one benefit of Alecton is that we don\u2019t have to work on the actual Grassmannian, but get some of the same benefits from a rescaling of the Yk space. In this specific case, the Alecton update rule is akin to stochastic power iteration, since it involves a repeated multiplication by the sample; this would not hold for optimization on other manifolds.\nWe can use (4) to compute the column space (or \u201cangular component\u201d) of the solution, before then recovering the rest of the solution (the \u201cradial component\u201d) using averaging. Doing this corresponds to Algorithm 1, Alecton. Notice that, unlike most iterative algorithms for matrix recovery, Alecton does not require any special initialization phase and can be initialized randomly.\nAnalysis Analyzing this algorithm is challenging, as the low-rank decomposition also introduces symmetrical families of fixed points. Not all these points are globally optimal: in fact, a fixed point will occur whenever\nY Y T = \u2211\ni\u2208C \u03bbiuiu\nT i\nAlgorithm 1 Alecton: Solve stochastic matrix problem Require: \u03b7 \u2208 R, K \u2208 N, L \u2208 N, and a sampling distribution A\n\u22b2 Angular component (eigenvector) estimation phase Select Y0 uniformly in Rn\u00d7m s.t. Y T0 Y0 = I . for k = 0 to K \u2212 1 do\nSelect A\u0303k uniformly and independently at random from the sampling distribution A. Yk+1 \u2190 Yk + \u03b7A\u0303kYk\nend for Y\u0302 \u2190 YK ( Y TKYK )\u2212 1 2 \u22b2 Radial component (eigenvalue) estimation phase R0 \u2190 0 for l = 0 to L\u2212 1 do\nSelect A\u0303l uniformly and independently at random from the sampling distribution A. Rl+1 \u2190 Rl + Y\u0302 T A\u0303lY\u0302\nend for R\u0304 \u2190 RL/L return y\u0302R\u0304 1 2\nfor any set C of size less than p. One consequence of the non-optimal fixed points is that the standard proof of SGD\u2019s convergence, in which we choose a Lyapunov function and show that this function\u2019s expectation decreases with time, cannot work. This is because, if such a Lyapunov function were to exist, it would show that no matter where we initialize the iteration, convergence to a global optimum will still occur rapidly; this cannot be possible due to the presence of the non-optimal fixed points. Thus, a standard statement of global convergence, that convergence occurs uniformly regardless of initial condition, cannot hold.\nWe therefore use martingale-based methods to show convergence. Specifically, our attack involves defining a process xk with respect to the natural filtration Fk of the iteration, such that xk is a supermartingale, that is E [xk+1|Fk] \u2264 xk. We then use the optional stopping theorem [17] to bound both the probability and rate of convergence of xk, from which we derive convergence of the original algorithm. We describe this analysis in the next section."}, {"heading": "3 Convergence Analysis", "text": "First, we need a way to define convergence for the angular phase. For most problems, we want C(Yk) to be as close as possible to the span of u1, u2, . . . , up. However, for some cases, this is not what we want. For example, consider the case where p = 1 but \u03bb1 = \u03bb2. In this case, the algorithm could not recover u1, since it is indistinguishable from u2. Instead, it is reasonable to expect C(Yk) to converge to the span of u1 and u2.\nTo handle this case, we instead want to measure convergence to the subspace spanned by some number, q \u2265 p, of the algebraically largest eigenvectors (in most cases, q = p). For a particular q, let U be the projection matrix onto the subspace spanned by u1, u2, . . . , uq , and define \u2206, the eigengap, as \u2206 = \u03bbq \u2212 \u03bbq+1. We now let \u01eb > 0 be an arbitrary error term, and define an angular success condition for Alecton.\nDefinition 1. When running the angular phase of Alecton, we say that success has occurred at timestep k if and only if for all z \u2208 Rp,\n\u2016UYkz\u20162\n\u2016Ykz\u20162 \u2265 1\u2212 \u01eb.\nThis condition requires that all members of the column space of Yk are close to the desired subspace. We say that success has occurred by time t if success has occurred for some timestep k < t. Otherwise, we say the algorithm has failed, and we let Ft denote this failure event.\nTo prove convergence, we need to put some restrictions on the problem. Our theorem requires the following three conditions.\nCondition 1 (Alecton Variance). A sampling distribution A with expected value A satisfies the Alecton Variance Condition (AVC) with parameters (\u03c3a, \u03c3r) if and only if for any y \u2208 R and for any symmetric matrix W 0 that commutes with A, if A\u0303 is sampled from A, the following bounds hold:\nE\n[ yT A\u0303TWA\u0303y ]\n\u2264 \u03c32atr (W ) \u2016y\u20162\nand\nE\n[\n( yT A\u0303y )2\n]\n\u2264 \u03c32r \u2016y\u20164 .\nIn Section 4, we show several models that satisfy AVC.\nCondition 2 (Alecton Rank). An instance of Alecton satisfies the Alecton Rank Condition if either p = 1 (rank-1 recovery), or each sample A\u0303 from A is rank-1 (rank-1 sampling).\nMost of the noise models we analyze have rank-1 samples, and so satisfy the rank condition.\nCondition 3 (Alecton Step Size). Define \u03b3 as\n\u03b3 = 2n\u03c32ap 2(p+ \u01eb)\n\u2206\u01eb \u03b7.\nThis represents a constant step size parameter that is independent of problem scaling. An instance of Alecton satisfies the Alecton Step Size Condition if and only if \u03b3 \u2264 1.\nNote that the step size condition is only an upper bound on the step size. This means that, even if we do not know the problem parameters exactly, we can still choose a feasible step size as long as we can bound them. (However, smaller step sizes imply slower convergence, so it is a good idea to choose \u03b7 as large as possible.)\nWe will now define a useful function, then state our main theorem that bounds the probability of failure.\nDefinition 2. For some p, let R \u2208 Rp\u00d7p be a random matrix the entries of which are independent standard normal random variables. Define function Zp as\nZp(\u03b3) = 2 ( 1\u2212E [ \u2223 \u2223I + \u03b3p\u22121(RTR)\u22121 \u2223 \u2223 \u22121]) .\nTheorem 1. Assume that we run an instance of Alecton that satisfies the variance, rank, and step size conditions. Then for any t, the probability that the angular phase will have failed up to time t is\nP (Ft) \u2264 Zp(\u03b3) + 4n\u03c32ap 2(p+ \u01eb)\n\u22062\u03b3\u01ebt log\n(\nnp2\n\u03b3q\u01eb\n)\n. (5)\nAlso, in the radial phase, for any constant \u03c8 it holds that\nP\n(\n\u2225 \u2225 \u2225R\u0304\u2212 Y\u0302 TAY\u0302 \u2225 \u2225 \u2225 2\nF \u2265 \u03c8\n)\n\u2264 p 2\u03c32r L\u03c8 .\nIn particular, if \u03c3a\u2206\u22121 does not vary with n, this theorem implies convergence of the angular phase with constant probability after O(\u01eb\u22121np3 log n) iterations and in the same amount of time. Note that since we do not reuse samples in Alecton, our rates do not differentiate between sampling and computational complexity, unlike many other algorithms (see Appendix B). We also do not consider numerical error or overflow: periodically re-normalizing the iterate may be necessary to prevent these in an implementation of Alecton.\nSince the upper bound expression uses Zp, which is obscure, we plot it here (Figure 1). We also can make a more precise statement about the failure rate for p = 1.\nLemma 1. For the case of rank-1 recovery,\nZ1(\u03b3) = \u221a 2\u03c0\u03b3 exp (\u03b3\n2\n)\nerfc\n( \u221a\n\u03b3\n2\n)\n\u2264 \u221a 2\u03c0\u03b3."}, {"heading": "3.1 Martingale Technique", "text": "A proof for Theorem 1 and full formal definitions will appear in Appendix C of this document, but since the method is nonstandard for non-convex optimization (although it has been used in Shamir [34] to show convergence for convex problems), we will outline it here. First, we define a failure event fk at each timestep, that occurs if the iterate gets \u201ctoo close\u201d to the unstable fixed points. Next, we define a sequence \u03c4k, where\n\u03c4k =\n\u2223 \u2223Y Tk UYk \u2223 \u2223\n\u2223 \u2223Y Tk (\u03b3n \u22121p\u22122qI + (1\u2212 \u03b3n\u22121p\u22122q)U)Yk \u2223 \u2223\n(where |X| denotes the determinant of X); the intuition here is that \u03c4k is close to 1 if and only if success occurs, and close to 0 when failure occurs. We show that, if neither success nor failure occurs at time k,\nE [\u03c4k+1|Fk] \u2265 \u03c4k (1 +R (1\u2212 \u03c4k)) (6)\nfor some constant R; here, Fk denotes the filtration at time k, which contains all the events that have occurred up to time k [17]. If we let T denote the first time at which either success or failure occurs, then this implies that \u03c4k is a submartingale for k < T . We use the optional stopping Theorem [17] (here we state a discrete-time version).\nDefinition 3 (Stopping Time). A random variable T is a stopping time with respect to a filtration Fk if and only if {T \u2264 k} \u2208 Fk for all k. That is, we can tell whether T \u2264 k using only events that have occurred up to time k.\nTheorem 2 (Optional Stopping Theorem). If xk is a martingale (or submartingale) with respect to a filtration Fk, and T is a stopping time with respect to the same filtration, then xk\u2227T is also a martingale (resp. submartingale) with respect to the same filtration, where k \u2227 T denotes the minimum of k and T . In particular, for bounded submartingales, this implies that E [x0] \u2264 E [xT ].\nHere, T is a stopping time since it depends only on events occurring before timestep T . Applying this to the submartingale \u03c4k results in\nE [\u03c40] \u2264 E [\u03c4T ] = E [\u03c4T |FT ]P (fT ) +E [\u03c4T |\u00acFT ] (1\u2212 P (fT ))\n\u2264 \u03b4P (fT ) + (1\u2212 P (fT )).\nThis isolates the probability of the failure event occurring. Next, subtracting 1 from both sides of (6) and taking the logarithm results in\nE [log (1\u2212 \u03c4k+1)|Fk] \u2264 log(1\u2212 \u03c4k) + log (1\u2212R\u03c4k) \u2264 log(1\u2212 \u03c4k)\u2212R\u03b4.\nSo, if we let Wk = log(1\u2212 \u03c4k) +R\u03b4k, then Wk is a supermartingale. We again apply the optional stopping theorem to produce E [W0] \u2265 E [WT ] = E [log(1\u2212 \u03c4T )] +R\u03b4E [T ] . This isolates the expected value of the stopping time. Finally, we notice that success occurs before time t if T \u2264 t and fT does not occur. By the union bound, this implies that\nPfailure \u2264 P (fT ) + P (T \u2264 t) ,\nand by Markov\u2019s inequality, Pfailure \u2264 P (fT ) + t\u22121E [T ] .\nSubstituting the isolated values for P (fT ) and E [T ] produces the expression above in (5).\nThe radial part of the theorem follows from an application of Chebychev\u2019s inequality to the average of L samples of y\u0302T A\u0303y\u0302 \u2014 we do not devote any discussion to it since averages are already well understood."}, {"heading": "4 Application Examples", "text": ""}, {"heading": "4.1 Entrywise Sampling", "text": "One sampling distribution that arises in many applications (most importantly, matrix completion [12]) is entrywise sampling. This occurs when the samples are independently chosen from the entries of A. Specifically,\nA\u0303 = n2eie T i Aeje T j ,\nwhere i and j are each independently drawn from 1, . . . , n. It is standard for these types of problems to introduce a matrix coherence bound [25].\nDefinition 4. A matrix A \u2208 Rn\u00d7n is incoherent with parameter \u00b5 if and only if for every unit eigenvector ui of the matrix, and for all standard basis vectors ej ,\n\u2223 \u2223eTj ui \u2223 \u2223 \u2264 \u00b5n\u2212 12 .\nUnder an incoherence assumption, we can provide a bound on the second moment of A\u0303, which is all that we need to apply Theorem 1 to this problem.\nLemma 2. If A is incoherent with parameter \u00b5, and A\u0303 is sampled uniformly from the entries of A, then the distribution of A\u0303 satisfies the Alecton variance condition with parameters \u03c32a = \u00b5\n4 \u2016A\u20162F and \u03c32r = \u00b54tr (A)2.\nFor problems in which the matrix A is of constant rank, and its eigenvalues do not vary with n, neither \u2016A\u2016F nor tr (A) will vary with n. In this case, \u03c32a, \u03c32r , and \u2206 will be constants, and the O(\u01eb\u22121n log n) bound on convergence time will hold."}, {"heading": "4.2 Rectangular Entrywise Sampling", "text": "Entrywise sampling also commonly appear in rectangular matrix recovery problems. In these cases, we are trying to solve something like\nminimize \u2016M \u2212X\u20162F subject to X \u2208 Rm\u00d7n, rank (X) \u2264 p.\nTo solve this problem using Alecton, we first convert it into a symmetric matrix problem by constructing the block matrix\nA =\n[\n0 M MT 0\n]\n;\nit is known that recovering the dominant eigenvectors of A is equivalent to recovering the dominant singular vectors of M .\nEntrywise sampling on M corresponds to choosing a random i \u2208 1, . . . ,m and j \u2208 1, . . . , n, and then sampling A\u0303 as\nA\u0303 = mnMij(eie T m+j + em+je T i ).\nIn the case where we can bound the entries of M (this is natural for recommender systems), we can prove the following.\nLemma 3. If M \u2208 Rm\u00d7n satisfies the entry bound\nM2ij \u2264 \u03bem\u22121n\u22121 \u2016M\u20162F\nfor all i and j, then the rectangular entrywise sampling distribution on M satisfies the Alecton variance condition with parameters\n\u03c32a = \u03c3 2 r = 2\u03be \u2016M\u20162F .\nAs above, for problems in which the singular values of M do not vary with problem size, our big-O convergence time bound will still hold."}, {"heading": "4.3 Trace Sampling", "text": "Another common sampling distribution arises from the matrix sensing problem [25]. In this problem, we are given the value of vTAw for unit vectors v and w selected uniformly at random. (This problem has been handled for the more general complex case in [11] using Wirtinger flow.) Using a trace sample, we can construct an unbiased sample\nA\u0303 = n2vvTAwwT .\nThis lets us bound the variance as follows.\nLemma 4. If n > 50, and v and w are sampled uniformly from the unit sphere in Rn, then for any positive semidefinite matrix A, if we let A\u0303 = n2vvTAwwT , then the distribution of A\u0303 satisfies the Alecton variance condition with parameters \u03c32a = 16 \u2016A\u20162F and \u03c32r = 16tr (A) 2.\nAs above, for problems in which the eigenvalues of A do not vary with problem size, our big-O convergence time bound will still hold.\nIn some cases of the trace sampling problem, instead of being given samples of the form uTAv, we know uTAu. In this case, we need to use two independent samples uT1 Au1 and u T 2 Au2, and let u \u221d u1 + u2 and v \u221d u1 \u2212 u2 be two unit vectors which we will use in the above sampling scheme. Notice that since u1 and u2 are independent and uniformly distributed, u and v will also be independent and uniformly distributed (by the spherical symmetry of the underlying distribution). Furthermore, we can compute\nuTAv = (u1 + u2) TA(u1 \u2212 u2) = uT1 Au1 \u2212 uT2 Au2.\nThis allows us to use our above trace sampling scheme even with samples of the form uTAu."}, {"heading": "4.4 Subspace Sampling", "text": "Our analysis can handle more complicated sampling schemes. Consider the following distribution, which arises in subspace tracking [6]. Our matrix A is a rank-r projection matrix, and each sample consists of some randomly-selected entries from a randomly-selected vector in its column space. Specifically, we are given Qv and Rv, where v is some vector selected uniformly at random from C(A), and Q and R are independent random diagonal projection matrices with expected value mn\u22121I . Using this, we can construct the distribution\nA\u0303 = rn2m\u22122QvvTR.\nThis distribution is unbiased since E [ qvvT ]\n= A. When bounding its second moment, we run into the same coherence problem as we did in the entrywise case, which motivates us to introduce a coherence constraint for subspaces.\nDefinition 5. A subspace of Rn of dimension q with associated projection matrix U is incoherent with parameter \u00b5 if and only if for all standard basis vectors ei,\n\u2016Uei\u20162 \u2264 \u00b5rn\u22121.\nUsing this, we can prove the following facts about the second moment of this distribution.\nLemma 5. The subspace sampling distribution, when sampled from a subspace that is incoherent with parameter \u00b5, satisfies the Alecton variance condition with parameters\n\u03c32a = \u03c3 2 r = r 2(1 + \u00b5rm\u22121)2.\nIn many cases of subspace sampling, we are given just some entries of v at each timestep (as opposed to two separate random sets of entries associated with Q and R). That is, we are given a random diagonal projection matrix S, and the product Sv. We can use this to construct a sample of the above form by randomly splitting the given entries among Q and R in such a way that Q = QS and R = RS, and Q and R are independent. We can then construct an unbiased sample as\nA\u0303 = rn2m\u22122QSvvTSR,\nwhich uses only the entries of v that we are given."}, {"heading": "4.5 Noisy Sampling", "text": "Since our analysis depends only on a variance bound, it is straightforward to handle the case in which the values of our samples themselves are noisy. Using the additive property of the variance for independent random variables, we can show that additive noise only increases the variance of the sampling distribution by a constant amount proportional to the variance of the noise. Similarly, using the multiplicative property of the variance for independent random variables, multiplicative noise only multiplies the variance of the sampling distribution by a constant factor proportional to the variance of the noise. In either case, we can show that the noisy sampling distribution satisfies AVC."}, {"heading": "4.6 Extension to Higher Ranks", "text": "It is possible to use multiple iterations of the rank-1 version of Alecton to recover additional eigenvalue/eigenvector pairs of the data matrix A one-at-a-time. This is a standard technique for using power iteration algorithms to recover multiple eigenvalues. Sometimes, this may be preferable to using a single higher-rank invocation of Alecton (for example, we may not know a priori how many eigenvectors we want). We outline this technique as Algorithm 2. This strategy allows us to recover the largest p eigenvectors of A using p executions\nAlgorithm 2 Alecton One-at-a-time Require: A sampling distribution A\nA1 \u2192 A for i = 1 to p do\n\u22b2 Run rank-1 Alecton to produce output yi. yi \u2192 Alectonp=1(Ai) Generate sampling distribution Ai+1 such that, if A\u0303\u2032 is sampled from Ai+1 and A\u0303 is sampled from Ai, E [ A\u0303\u2032 ] = E [ A\u0303 ]\n\u2212 yiyTi . end for return\n\u2211p i=1 yiy T i\nof Alecton. If the eigenvalues of the matrix are independent of n and p, we will be able to accomplish this in O(\u01eb\u22121pn log n) total steps."}, {"heading": "5 Experiments", "text": "We experimentally verify our main claim, that Alecton does converge quickly for practical datasets. All experiments were run on a machine with a single twelve-core socket (Intel Xeon E5-2697, 2.70GHz), and 256 GB of shared memory. All were written in C++, excepting the Netflix Prize problem experiment, which was written in Julia. No data was collected for the radial phase of Alecton, since the performance of averaging is already well understood.\nThe first experiments were run on randomly-generated rank-10 data matrices A \u2208 Rn\u00d7n. Each was generated by selecting a random orthogonal matrix U \u2208 Rn\u00d7n, then independently selecting a diagonal matrix \u039b with 10 positive nonzero eigenvalues, and constructing A = U\u039bU \u2032. Figure 2(a) illustrates the convergence of Alecton with p = q = 1 using three sampling distributions on datasets with n = 104. We ran Alecton starting from five random initial values; the different plotted trajectories illustrate how convergence time can depend on the initial value.\nFigure 2(b) illustrates the performance of Alecton (p = q = 1 again) on a larger dataset with n = 106 as the step size parameter \u03b7 is varied. As we would expect, a smaller value of \u03b7 yields slower, but more\naccurate convergence. Also notice that the smaller the value of \u03b7, the more the initial value seems to affect convergence time.\nFigure 3 demonstrates convergence results on real data from the Netflix Prize problem. This problem involves recovering a matrix with 480,189 columns and 17,770 rows from a training dataset containing 110,198,805 revealed entries. We used the rectangular entrywise distribution described above, then ran Alecton with \u03b7 = 10\u221212 and p = q = 1 for ten million iterations to recover the most significant singular vector. Next, we used Algorithm 2 to recover additional singular vectors of the matrix, up to a maximum of p = 12. The absolute runtime and RMS errors after the recovery of each subsequent eigenvector are plotted in Figure 3. This plot illustrates that the runtime of the one-at-a-time algorithm does not increase disastrously as the number of recovered eigenvectors expands."}, {"heading": "5.1 Discussion", "text": "The Hogwild! algorithm [30] is a parallel, lock-free version of stochastic gradient descent that has been shown to perform similarly to sequential SGD on convex problems, while allowing for a good parallel speedup. It is an open question whether a Hogwild! version of Alecton for non-convex problems converges with a good rate, but we are optimistic that it will."}, {"heading": "6 Conclusion", "text": "This paper exhibited Alecton, a stochastic gradient descent algorithm applied to a non-convex low-rank factorized problem; it is similar to the algorithms used in practice to solve a wide variety of problems. We prove that Alecton converges globally, and provide a rate of convergence. We do not require any special initialization step but rather initialize randomly. Furthermore, our result depends only on the variance of the samples, and therefore holds under broad sampling conditions that include both matrix completion and matrix sensing, and is also able to take noisy samples into account. We show these results using a martingale-based technique that is novel in the space of non-convex optimization, and we are optimistic that this technique can be applied to other problems in the future."}, {"heading": "A Negative Results", "text": "Divergence Example Here, we observe what happens when we choose a constant step size for stochastic gradient descent for quartic objective functions. Consider the simple optimization problem of minimizing\nf(x) = 1\n4 x4.\nThis function will have gradient descent update rule\nxk+1 = xk \u2212 \u03b1kx3k = ( 1\u2212 \u03b1kx2k ) xk.\nWe now prove that, for any reasonable step size rule chosen independently of xk, there is some initial condition such that this iteration diverges to infinity.\nProposition 1. Assume that we iterate using the above rule, for some choice of \u03b1k that is not superexponentially decreasing; that is, for some C > 1 and some \u03b1 > 0, \u03b1k \u2265 \u03b1C\u22122k for all k. Then, if x20 \u2265 \u03b1\u22121(C + 1), for all k\nx2k > \u03b1 \u22121C2k(C + 1).\nProof. We will prove this by induction. The base case follows directly from the assumption, while under the inductive case, if the proposition is true for k, then\n\u03b1kx 2 k \u2265 \u03b1C\u22122k\u03b1\u22121C2k(C + 1) = C + 1.\nTherefore, x2k+1 = ( \u03b1kx 2 k \u2212 1 )2 x2k\n\u2265 C2x2k \u2265 C2\u03b1\u22121C2k(C + 1) = \u03b1\u22121C2(k+1)(C + 1).\nThis proves the statement.\nThis proof shows that, for some choice of x0, xk will diverge to infinity exponentially quickly. Furthermore, no reasonable choice of \u03b1k will be able to halt this increase for all initial conditions. We can see the effect of this in stochastic gradient descent as well, where there is always some probability that, due to an unfortunate series of gradient steps, we will enter the zone in which divergence occurs. On the other hand, if we chose step size \u03b1k = \u03b3kx \u22122 k , for some 0 < \u03b3k < 2, then\nxk+1 = (1\u2212 \u03b3k)xk,\nwhich converges for all starting values of xk. This simple example is what motivates us to take \u2016Yk\u2016 into account when choosing the step size for Alecton.\nGlobal Convergence Counterexample We now exhibit a particular problem for which SGD on a lowrank factorization doesn\u2019t converge to the global optimum for a particular starting point. Let matrix A \u2208 R 2\u00d72 be the diagonal matrix with diagonal entries 4 and 1. Further, let\u2019s assume that we are trying to minimize the expected value of the decomposed rank-1 objective function\nf\u0303(y) = \u2225 \u2225 \u2225A\u0303\u2212 yyT \u2225 \u2225 \u2225\nF = \u2016y\u20164 \u2212 2yT A\u0303y +\n\u2225 \u2225 \u2225A\u0303 \u2225 \u2225 \u2225 2\nF .\nIf our stochastic samples satisfy A\u0303 = A (i.e. we use a perfect sampler), then the SGD update rule is\nyk+1 = yk \u2212 \u03b1k\u2207f\u0303(yk) = yk \u2212 4\u03b1k ( yk \u2016yk\u20162 \u2212Ayk ) .\nNow, we know that e1 is the most significant eigenvector of A, and that y = 2e1 is the global solution to the problem. However,\neT1 yk+1 = e T 1 yk \u2212 4\u03b1k\n( eT1 yk \u2016yk\u20162 \u2212 eT1 Ayk )\n= ( 1\u2212 4\u03b1k ( \u2016yk\u20162 \u2212 4 )) eT1 yk\n. This implies that if eT1 y0 = 0, then e T 1 yk = 0 for all k, which means that convergence to the global optimum cannot occur. This illustrates that global convergence does not occur for all manifold optimization problems using a low-rank factorization and for all starting points.\nConstraints Counterexample We might think that our results can be generalized to give O(n log n) convergence of low-rank factorized problems with arbitrary constraints. Here, we show that this will not work for all problems by encoding an NP-complete problem as a constrained low-rank optimization problem.\nFor any graph with node set N and edge set E, the MAXCUT problem on the graph requires us to solve\nminimize \u2211\n(i,j)\u2208E yiyj subject to yi \u2208 {\u22121, 1}.\nAlgorithm Sampling Scheme Complexity\nSampling Computational\nAlecton Any O(\u01eb\u22121p3n log n)\nSVD Various o(pn) O(n3)\nSpectral Matrix Completion [28] Elementwise o(pn) O(p2n log n)\nPhaseLift [13] Phase Retrieval o(n) O(\u01eb\u22121n3)\nAlternating Minimization [41] Phase Retrieval o(n log(\u01eb\u22121)) O(n2 log2(\u01eb\u22121))\nWirtinger Flow [11] Phase Retrieval o(n log2 n) O(pn log(\u01eb\u22121))\nEquivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22]\nminimize yTAy subject to yi \u2208 {\u22121, 1}.\nWe relax this problem to minimize yTAy subject to \u22121 \u2264 yi \u2264 1.\nSince the diagonal of A is zero, if we fix all but one of the entries of y, the objective function will have an affine dependence on that entry. In particular, this means that a global minimum of the problem must occur on the boundary where yi \u2208 {\u22121, 1}, which implies that this problem has the same global solution as the original MAXCUT problem. Furthermore, for sufficiently large values of \u03c3, the problem\nminimize \u2016y\u20164 + 2\u03c3yTAy + \u03c32 \u2016A\u20162F subject to \u22121 \u2264 yi \u2264 1\nwill also have the same solution. But, this problem is in the same form as a low-rank factorization of\nminimize \u2016X + \u03c3A\u20162F subject to Xii \u2264 1,X 0, rank (X) = 1\nwhere X = yyT . Since MAXCUT is NP-complete, it can\u2019t possibly be the case that SGD applied to this low-rank factorized problem converges quickly to the global optimum, because that would imply an efficient solution to this NP-complete problem. This suggests that care will be needed when analyzing problems with constraints, in order to exclude these sorts of cases."}, {"heading": "B Comparison with Other Methods", "text": "There are several other algorithms that solve similar matrix recover problems in the literature. In Table B, we list some other algorithms, and their convergence rates, in terms of both number of samples required (sampling complexity) and number of iterations performed (computational complexity). For this table, the data is assumed to be of dimension n, and the rank (where applicable) is assumed to be p. (In order to save space, factors of log log \u01eb\u22121 have been omitted from some formulas.)"}, {"heading": "C Proofs of Main Results", "text": "In this appendix, we provide rigorous definitions and detail the proof outlined in Section 3.1.\nC.1 Definitions\nFleming and Harrington [17] provide the following definitions of filtration and martingale. We state the definitions adapted to the discrete-time case.\nDefinition 6 (Filtration). Given a measurable probability space (\u2126,F), a filtration is a sequence of sub-\u03c3algebras {Ft} for t \u2265 0, such that for all s \u2264 t,\nFs \u2282 Ft.\nThat is, if an event A is in Fs, and t \u2265 s, then A is also in Ft. This definition encodes the monotonic increase in available information over time.\nDefinition 7 (Martingale). Let {Xt} be a stochastic process and {Ft} be a filtration over the same probability space. Then X is called a martingale with respect to the filtration if for every t, Xt is Ft-measurable, and E [Xt+1|Ft] = Xt. (7) We call X a submartingale if the same conditions hold, except (7) is replaced with\nE [Xt+1|Ft] \u2265 Xt.\nWe call X a supermartingale if the same conditions hold, except (7) is replaced with\nE [Xt+1|Ft] \u2264 Xt.\nC.2 Preliminaries\nIn addition to the quantities used in the statement of Theorem 1, we let\nW = \u03b3n\u22121p\u22122qI + (1\u2212 \u03b3n\u22121p\u22122q)U,\nand define sequences \u03c4k and \u03c6k as\n\u03c4k =\n\u2223 \u2223Y Tk UYk \u2223 \u2223 \u2223 \u2223Y Tk WYk \u2223 \u2223 ,\nand \u03c6k = tr ( I \u2212 Y Tk UYk ( Y Tk WYk )\u22121) .\nThis agrees with the definition of \u03c4k stated in the body of the paper. Using this sequence, we define the failure event fk as the event that occurs when\n\u03c4k \u2264 1\n2 . (8)\nWe recall that we defined the success event at time k as the event that, for all z \u2208 Rp,\n\u2016UYkz\u20162\n\u2016Ykz\u20162 \u2265 1\u2212 \u01eb.\nFinally, we define T , the stopping time, to be the first time at which either the success event or the failure event occurs.\nNow, we state some lemmas we will need in the following proofs. We defer proofs of the lemmas themselves to Appendix D. First, we state a lemma about quadratic rational functions that we will need in the next section.\nLemma 6 (Quadratic rational lower bound). For any a, b, c, and d in R, if 1+by+cy2 > 0 and 1+ay+dy2 \u2265 0 for all y, then for all x \u2208 R,\n1 + ax+ dx2 1 + bx+ cx2 \u2265 1 + (a\u2212 b)x\u2212 cx2.\nNext, a lemma about the expected initial value of \u03c4 :\nLemma 7. If we initialize Y0 uniformly as in the Alecton algorithm, then\nE [\u03c40] \u2265 1\u2212 1\n2 Zp(\u03b3).\nNext, a lemmas that bounds a determinant expression.\nLemma 8. For any B \u2208 Rn\u00d7n, Y \u2208 Rn\u00d7m, and any symmetric positive-semidefinite Z \u2208 Rn\u00d7n, if either B is rank-1 or m = 1, then\n\u2223 \u2223Y T (I +B)TZ(I +B)Y \u2223 \u2223\n\u2265 \u2223 \u2223Y TZY \u2223 \u2223 ( tr ( Y (Y TZY )\u22121Y TZB ) + 1 )2\nand \u2223\n\u2223Y T (I +B)TZ(I +B)Y \u2223 \u2223\n\u2264 \u2223 \u2223Y TZY \u2223 \u2223\n(\n1 + 2tr ( Y (Y TZY )\u22121Y TZB )\n+ tr ( Y (Y TZY )\u22121Y TBTZB )\n)\n.\nNext, a lemma that bounds \u03c4 in the case that the success condition does not occur.\nLemma 9. If we run Alecton, and at timestep k, the success condition does not hold, then\n\u03c4k \u2264 1\u2212 \u03b3n\u22121p\u22122q\u01eb.\nFinally, a lemma that relates \u03c6 and \u03c4 .\nLemma 10. Using the definitions above, for all k,\n\u03c6k \u2265 1\u2212 \u03c4k.\nC.3 Main Proofs\nWe now proceed to prove Theorem 1 in six steps, as outlined in Section 3.1.\n\u2022 First, we prove Lemma 11, the dominant mass bound lemma, which bounds E [\u03c4k+1|Fk] from below by a quadratic function of the step size \u03b7.\n\u2022 We use this to prove Lemma 12, which establishes the result stated in (6).\n\u2022 We use the optional stopping theorem to prove Lemma 13, which bounds the probability of a failure event occurring before success.\n\u2022 We use the optional stopping theorem again to prove Lemma 14, which bounds the expected time until either a failure or success event occurs.\n\u2022 We use Markov\u2019s inequality and the union bound to bound the angular failure probability of Theorem 1.\n\u2022 Finally, we prove the radial phase result stated in Theorem 1.\nLemma 11 (Dominant Mass Bound). If we run Alecton under the conditions of Theorem 1, then for any k,\nE [\u03c4k+1|Fk] \u2265 \u03c4k ( 1 + 2\u03b7 ( \u2206\u2212 \u03b7\u03c32a\u03b3\u22121np2 ) (1\u2212 \u03c4k)\n\u2212 \u03b72\u03c32ap(q + 1) ) .\nProof. From the definition of \u03c4 , at the next timestep we will have\n\u03c4k+1 =\n\u2223 \u2223Y Tk+1UYk+1 \u2223 \u2223 \u2223 \u2223Y Tk+1WYk+1 \u2223 \u2223\n=\n\u2223 \u2223 \u2223 \u2223 Y Tk ( I + \u03b7A\u0303k )T U ( I + \u03b7A\u0303k ) Yk \u2223 \u2223 \u2223 \u2223\n\u2223 \u2223 \u2223 \u2223 Y Tk ( I + \u03b7A\u0303k )T W ( I + \u03b7A\u0303k ) Yk \u2223 \u2223 \u2223 \u2223\n.\nNow, since our instance of Alecton satisfies the rank condition, either A\u0303k is rank-1 or p = 1. Therefore, we can apply Lemma 8 to these determinant quantities. In order to produce a lower bound on \u03c4k+1, we will apply lower bound to the numerator and the upper bound to the denominator. If we let Bk = Yk(Y Tk UYk)\n\u22121Y Tk , and Ck = Yk(Y Tk WYk) \u22121Y Tk , then this results in\n\u03c4k+1 \u2265 \u2223 \u2223Y Tk UYk \u2223 \u2223 \u2223\n\u2223Y Tk WYk \u2223 \u2223\n\u00b7\n( 1 + \u03b7tr (\nBkUA\u0303k\n))2\n1 + 2\u03b7tr (\nCkWA\u0303k\n) + \u03b72tr (\nCkA\u0303 T kWA\u0303k\n) .\nNext, we apply Lemma 6, which results in\n\u03c4k+1 \u2265 \u03c4k ( 1 + 2\u03b7 ( tr ( BkUA\u0303k ) \u2212 tr ( CkWA\u0303k ))\n\u2212 \u03b72tr (\nCkA\u0303 T kWA\u0303k\n))\n\u2265 \u03c4k ( 1 + 2\u03b7Rk + \u03b7 2Qk ) ,\nfor sequences Rk and Qk. Now, we investigate the expected values of these sequences. First, since the estimator has E [\nA\u0303k\n\u2223 \u2223 \u2223 Fk ] = A, the expected value of Rk is\nE [Rk|Fk] = tr (BkUA)\u2212 tr (CkWA) = tr ((Bk \u2212 Ck)UA)\n\u2212 \u03b3n\u22121p\u22122qtr (Ck(I \u2212 U)A) .\nNow, since U commutes with A, we will have that\nUA \u03bbqU,\nand similarly (I \u2212 U)A \u03bbq+1(I \u2212 U).\nApplying this results in\nE [Rk|Fk] \u2265 tr (BkUA)\u2212 tr (CkWA) = \u03bbqtr ((Bk \u2212Ck)U)\n\u2212 \u03bbq+1\u03b3n\u22121p\u22122qtr (Ck(I \u2212 U)) .\nNow, we first notice that\ntr ((Bk \u2212 Ck)U) = tr ( I \u2212 YkUY Tk (Y Tk WYk)\u22121 )\n= \u03c6k.\nWe also notice that\n\u03b3n\u22121p\u22122qtr (Ck(I \u2212 U)) = tr (Ck(W \u2212 U)) = tr (\nI \u2212 YkUY Tk (Y Tk WYk)\u22121 )\n= \u03c6k.\nIt therefore follows that\nE [Rk|Fk] \u2265 (\u03bbq \u2212 \u03bbq+1)\u03c6k = \u2206\u03c6k.\nNext, the expected value of Qk is\nE [Qk|Fk] = tr ( CkE [ A\u0303TkWA\u0303k ]) .\nSince our instance of Alecton satisfies the variance condition, and W commutes with A,\nE [Qk|Fk] \u2264 \u03c32atr (W ) tr (Ck) .\nWe notice that\ntr (Ck) = tr ( Ck ( W + (1\u2212 \u03b3n\u22121p\u22122q)(I \u2212 U) ))\n= p+ (1\u2212 \u03b3n\u22121p\u22122q)tr (Ck(I \u2212 U)) \u2264 p+ tr (Ck(I \u2212 U)) .\nBy the logic above,\ntr (Ck) \u2264 p+ \u03b3\u22121np2q\u22121\u03c6k.\nAlso,\ntr (W ) = tr ( \u03b3n\u22121p\u22122qI + (1\u2212 \u03b3n\u22121p\u22122q)U )\n= \u03b3p\u22122q + q \u2212 \u03b3n\u22121p\u22122q2\n\u2265 q + 1\nand therefore, since tr (W ) \u2264 q + 1,\nE [Qk|Fk] \u2264 \u03c32a(q + 1) ( p+ \u03b3\u22121np2q\u22121\u03c6k ) .\nSubstituting these in results in\nE [\u03c4k+1|Fk] \u2265 \u03c4k ( 1 + 2\u03b7\u2206\u03c6k \u2212 \u03b72 ( \u03c32ap(q + 1) + \u03c3 2 a\u03b3 \u22121np2(q + 1)q\u22121\u03c6k ))\n= \u03c4k ( 1 + \u03b7 ( 2\u2206 \u2212 \u03b7\u03c32a\u03b3\u22121np2(q + 1)q\u22121 ) \u03c6k \u2212 \u03b72\u03c32ap(q + 1) ) \u2265 \u03c4k ( 1 + 2\u03b7 ( \u2206\u2212 \u03b7\u03c32a\u03b3\u22121np2 ) \u03c6k \u2212 \u03b72\u03c32ap(q + 1) ) .\nFinally, since for our chosen value of \u03b3,\n\u2206 > \u03b7\u03c32a\u03b3 \u22121np2,\nwe can apply Lemma 10, which produces\nE [\u03c4k+1|Fk] \u2265 \u03c4k ( 1 + 2\u03b7 ( \u2206\u2212 \u03b7\u03c32a\u03b3\u22121np2 ) (1\u2212 \u03c4k)\n\u2212 \u03b72\u03c32ap(q + 1) ) .\nThis is the desired expression.\nLemma 12. If we run Alecton under the conditions of Theorem 1, then for any time k at which neither the success event nor the failure event occur,\nE [\u03c4k+1|Fk] \u2265 \u03c4k (1 + \u03b7\u2206(1\u2212 \u03c4k)) .\nProof. From the result of Lemma 11,\nE [\u03c4k+1|Fk] \u2265 \u03c4k ( 1 + 2\u03b7 ( \u2206\u2212 \u03b7\u03c32a\u03b3\u22121np2 ) (1\u2212 \u03c4k)\u2212 \u03b72\u03c32ap(q + 1) )\n= \u03c4k ( 1 + \u03b7\u2206(1 \u2212 \u03c4k) + \u03b7 ( \u2206\u2212 2\u03b7\u03c32a\u03b3\u22121np2 ) (1\u2212 \u03c4k)\u2212 \u03b72\u03c32ap(q + 1) ) = \u03c4k (1 + \u03b7\u2206(1\u2212 \u03c4k) + \u03b7Sk, )\nfor sequence Sk. Now, it can be easily verified that we chose \u03b3 such that\n\u2206 \u2265 2\u03b7\u03c32a\u03b3\u22121np2,\nand so it follows that, by Lemma 9,\nSk = ( \u2206\u2212 2\u03b7\u03c32a\u03b3\u22121np2 ) (1\u2212 \u03c4k)\u2212 \u03b7\u03c32ap(q + 1) \u2265 (\n\u2206\u2212 2\u03b7\u03c32a\u03b3\u22121np2 ) \u03b3n\u22121p\u22122q\u01eb\u2212 \u03b7\u03c32ap(q + 1) = \u2206\u03b3n\u22121p\u22122q\u01eb\u2212 2\u03b7\u03c32aq\u01eb\u2212 \u03b7\u03c32ap(q + 1) \u2265 \u2206\u03b3n\u22121p\u22122q\u01eb\u2212 2\u03b7\u03c32aq(p+ \u01eb).\nIf we substitute the value of \u03b3,\n\u03b3 = 2n\u03c32ap 2(p+ \u01eb)\n\u2206\u01eb \u03b7.\nthen we arrive at Sk \u2265 0.\nSubstituting this in to our original expression produces\nE [\u03c4k+1|Fk] \u2265 \u03c4k (1 + \u03b7\u2206(1\u2212 \u03c4k)) ,\nas desired.\nLemma 13 (Failure Probability Bound). If we run Alecton under the conditions of Theorem 1, then the probability that the failure event will occur before the success event is\nP (fT ) \u2264 Zp(\u03b3).\nProof. To prove this, we use the stopping time T , which we defined as the first time at which either the success event or failure event occurs. First, if k < T , it follows that neither success nor failure have occurred yet, so we can apply Lemma 12, which results in\nE [\u03c4k+1|Fk] \u2265 \u03c4k (1 + \u03b7\u2206(1\u2212 \u03c4k)) .\nTherefore \u03c4k is a supermartingale for k < T . So, we can apply the optional stopping theorem, which produces E [\u03c40] \u2264 E [\u03c4T ] . So, by the law of total expectation,\nE [\u03c40] \u2264 E [\u03c4T |fT ]P (fT ) +E [\u03c4T |\u00acfT ]P (\u00acfT ) ,\nwhere fT is the failure event at time T . Applying the definition of the failure event from (8),\nE [\u03c40] \u2264 1\n2 P (fT ) + 1\n( 1\u2212 P (fT ) ) .\nTherefore, solving for P (fT ),\nP (fT ) \u2264 2 (1\u2212E [\u03c40]) .\nNow applying Lemma 7,\nP (fT ) \u2264 2 ( 1\u2212 ( 1\u2212 1 2 Zp(\u03b3) )) = Zp(\u03b3),\nas desired.\nLemma 14 (Stopping Time Expectation). If we run Alecton under the conditions of Theorem 1, then the expected value of the stopping time T will be\nE [T ] \u2264 4n\u03c3 2 ap 2(p+ \u01eb)\n\u22062\u03b3\u01eb log\n(\nnp2\n\u03b3q\u01eb\n)\n.\nProof. First, as above if k < T , we can apply Lemma 12, which results in\nE [\u03c4k+1|Fk] \u2265 \u03c4k (1 + \u03b7\u2206(1\u2212 \u03c4k)) = \u03c4k + \u03b7\u2206\u03c4k (1\u2212 \u03c4k) ,\nand so E [1\u2212 \u03c4k+1|Fk] \u2264 (1\u2212 \u03c4k) (1\u2212 \u03b7\u2206\u03c4k) .\nNow, if k < T , then since failure hasn\u2019t occurred yet, \u03c4k > 12 . So,\nE [1\u2212 \u03c4k+1|Fk] \u2264 (1\u2212 \u03c4k) ( 1\u2212 1 2 \u03b7\u2206 ) .\nNow, since the logarithm function is concave, by Jensen\u2019s inequality we have\nE [log (1\u2212 \u03c4k+1)|Fk] \u2264 logE [1\u2212 \u03c4k+1|Fk] ,\nand thus by transitivity,\nE [log (1\u2212 \u03c4k+1)|Fk] \u2264 log(1\u2212 \u03c4k) + log ( 1\u2212 1 2 \u03b7\u2206 )\n\u2264 log(1\u2212 \u03c4k)\u2212 1\n2 \u03b7\u2206.\nNow, we define a new process \u03c8k as\n\u03c8k = log(1\u2212 \u03c4k) + 1\n2 \u03b7\u2206k.\nUsing this definition, for k < T ,\nE [\u03c8k+1|Fk] = E [log(1\u2212 \u03c4k+1)|Fk] + 1\n2 \u03b7\u2206(k + 1)\n\u2264 log(1\u2212 \u03c4k)\u2212 1\n2 \u03b7\u2206+\n1 2 \u03b7\u2206(k + 1)\n= log(1\u2212 \u03c4k) + 1\n2 \u03b7\u2206k\n= \u03c8k,\nso \u03c8k is a supermartingale for k < T . We can therefore apply the optional stopping theorem, which states that E [log(1\u2212 \u03c40)] = E [\u03c80] \u2265 E [\u03c8T ] . Since 1\u2212 \u03c40 < 1, it follows that log(1\u2212 \u03c40) < 0. Therefore,\n0 \u2265 E [\u03c8T ] = E [log(1\u2212 \u03c4T )] + 1\n2 \u03b7\u2206E [T ] .\nApplying Lemma 9, 1\u2212 \u03c4T \u2265 \u03b3n\u22121p\u22122q\u01eb,\nand so\n0 \u2265 log(\u03b3n\u22121p\u22122q\u01eb) + 1 2 \u03b7\u2206E [T ] .\nSolving for the expected value of the stopping time,\nE [T ] \u2264 2 \u03b7\u2206\u03b4 log\n(\nnp2\n\u03b3q\u01eb\n)\n.\nFinally, substituting \u03b7 in terms of \u03b3 results in\nE [T ] \u2264 4n\u03c3 2 ap 2(p+ \u01eb)\n\u22062\u03b3\u01eb log\n(\nnp2\n\u03b3q\u01eb\n)\n,\nas desired.\nFinally, we prove Theorem 1.\nProof of angular part of Theorem 1. First, we notice that the total failure event up to time t can be written as\nFt = fT \u222a {T > t} .\nThat is, total failure up to time t occurs if either failure happens before success (event fT ), or neither success nor failure happen before t. By the union bound,\nFt \u2264 P (fT ) + P (T > t) .\nApplying Markov\u2019s inequality,\nP (Ft) \u2264 P (fT ) + 1\nt E [T ] .\nFinally, applying Lemmas 13 and 14 produces\nP (Ft) \u2264 Zp(\u03b3) + 4n\u03c32ap 2(p+ \u01eb)\n\u22062\u03b3\u01ebt log\n(\nnp2\n\u03b3q\u01eb\n)\n.\nThis is the desired expression.\nProof of radial part of Theorem 1. Recall that in Alecton, R\u0304 is defined as\nR\u0304 = 1\nL\nL\u22121 \u2211\nl=0\nY\u0302 T A\u0303lY\u0302 .\nNow, computing the expected distance to the mean,\nE\n[\n\u2225 \u2225 \u2225R\u0304\u2212 Y\u0302 TAY\u0302 \u2225 \u2225 \u2225 2\nF\n]\n= E\n\n\n\u2225 \u2225 \u2225 \u2225 \u2225 1 L L\u22121 \u2211\nl=0\nY\u0302 T A\u0303lY\u0302 \u2212 Y\u0302 TAY\u0302 \u2225 \u2225 \u2225 \u2225\n\u2225\n2\nF\n\n\n= E\n\n\n\u2225 \u2225 \u2225 \u2225 \u2225 1 L L\u22121 \u2211\nl=0\nY\u0302 T (A\u0303l \u2212A)Y\u0302 \u2225 \u2225 \u2225 \u2225\n\u2225\n2\nF\n\n\n= 1\nL2 E\n[ L\u22121 \u2211\nk=0\nL\u22121 \u2211\nl=0\ntr\n( Y\u0302 T (A\u0303k \u2212A)T Y\u0302 Y\u0302 T (A\u0303l \u2212A)Y\u0302 )\n]\nSince E [ A\u0303 ]\n= A, and the A\u0303l are independently sampled, the summand here will be zero unless k = l.\nTherefore,\nE\n[\n\u2225 \u2225 \u2225R\u0304\u2212 Y\u0302 TAY\u0302 \u2225 \u2225 \u2225 2\nF\n]\n= 1\nL2\nL\u22121 \u2211\nl=0\nE\n[\ntr\n( Y\u0302 T (A\u0303l \u2212A)T Y\u0302 Y\u0302 T (A\u0303l \u2212A)Y\u0302 )]\n= 1\nL E\n[\ntr\n( Y\u0302 T (A\u0303\u2212A)T Y\u0302 Y\u0302 T (A\u0303\u2212A)Y\u0302 )]\n\u2264 1 L E [ tr ( Y\u0302 T A\u0303T Y\u0302 Y\u0302 T A\u0303Y\u0302 )] .\nApplying the Alecton variance condition, and recalling that tr ( Y\u0302 Y\u0302 T ) = p, results in\nE\n[\n\u2225 \u2225 \u2225 R\u0304\u2212 Y\u0302 TAY\u0302 \u2225 \u2225 \u2225 2\nF\n]\n\u2264 p 2\u03c32r L .\nWe can now apply Markov\u2019s inequality to this expression. This results in, for any constant \u03c8 > 0,\nP (\u2225 \u2225 \u2225R\u0304\u2212 Y\u0302 TAY\u0302 \u2225 \u2225 \u2225 2 F \u2265 \u03c8 ) \u2264 p 2\u03c32r L\u03c8 ,\nwhich is the desired result."}, {"heading": "D Proofs of Lemmas", "text": "First, we prove the lemmas used above to demonstrate the general result.\nProof of quadratic rational lower bound lemma (Lemma 6). Expanding the product results in (\n1+bx+cx2 ) ( 1+(2a\u2212b)x\u2212cx2 ) =1+((2a\u2212b)+b)x+(c\u2212c+(2a\u2212b)b)x2+((2a\u2212b)c\u2212bc)x3\u2212c2x4\n= 1 + 2ax+ (2ab\u2212 b2)x2 + 2(a\u2212 b)cx3 \u2212 c2x4 = 1 + 2ax+ a2x2 \u2212 (a2 \u2212 2ab+ b2)x2 + 2(a\u2212 b)cx3 \u2212 c2x4 = 1 + 2ax+ a2x2 \u2212 x2 ( (a\u2212 b)2 \u2212 2(a\u2212 b)cx+ c2x2 )\n= (1 + ax)2 \u2212 x2((a\u2212 b)\u2212 cx)2 \u2264 (1 + ax)2.\nDividing both sides by 1 + bx+ cx2 (which we can do since this is assumed to be positive) reconstructs the desired identity.\nProof of Lemma 7. We first note that, by the symmetry of the multivariate Gaussian distribution, initializing Y0 uniformly at random such that Y T0 Y0 = I is equivalent to initializing the entries of Y0 as independent standard normal random variables, for the purposes of computing \u03c40. Under this initialization strategy, E [\u03c40] is\nE [\u03c40] = E\n[ \u2223\n\u2223Y T0 UY0 \u2223 \u2223 \u2223 \u2223Y T0 WY0 \u2223 \u2223\n]\n= E\n[ \u2223\n\u2223Y T0 UY0 \u2223 \u2223\n\u2223 \u2223\u03b3n\u22121p\u22122qY T0 (I \u2212 U)Y0 + Y T0 UY0 \u2223 \u2223\n]\n.\nNow, let X \u2208 Rq\u00d7p be the component of Y0 that is in the column space of U , and let Z \u2208 R(n\u2212q)\u00d7p be the component of Y0 in the null space of U . Then,\nE [\u03c40] = E\n[ \u2223\n\u2223XTX \u2223 \u2223\n|\u03b3n\u22121p\u22122qZTZ +XTX|\n]\n.\nSince X and Z are selected orthogonally from a Gaussian random matrix, they must be independent, so we can take their expected values independently. Taking the expected value first with respect to Z , we notice\nthat |V |\u22121 is a convex function in V , and so by Jensen\u2019s inequality,\nE [\u03c40] \u2265 E [\n\u2223 \u2223XTX \u2223 \u2223\n|\u03b3n\u22121p\u22122qE [ZTZ] +XTX|\n]\n\u2265 E [\n\u2223 \u2223XTX \u2223 \u2223\n|\u03b3n\u22121p\u22122q(n\u2212 q)I +XTX|\n]\n\u2265 E [\n\u2223 \u2223XTX \u2223 \u2223\n|\u03b3p\u22122qI +XTX|\n]\n= E [ \u2223 \u2223I + \u03b3p\u22122q(XTX)\u22121 \u2223 \u2223 \u22121] .\nNow, let V \u2208 Rq\u00d7p be a random full-rank projection matrix, selected independently of X. Then,\nE [ V V T ] = p\nq I,\nand so\nE [\u03c40] \u2265 E [ \u2223 \u2223 \u2223I + \u03b3p\u22121E [ XTV V TX \u2223 \u2223X ]\u22121\u2223 \u2223 \u2223 \u22121 ] .\nApplying Jensen\u2019s inequality again,\nE [\u03c40] \u2265 E [ E [ \u2223 \u2223 \u2223I + \u03b3p\u22121 ( XTV V TX )\u22121\u2223 \u2223 \u2223 \u22121 \u2223 \u2223 \u2223\n\u2223\nX\n]]\n.\nand by the law of total expectation,\nE [\u03c40] \u2265 E [ \u2223 \u2223 \u2223I + \u03b3p\u22121 ( XTV V TX )\u22121\u2223 \u2223 \u2223 \u22121] .\nNow, since V and X were sampled independently, it follows that V TX is sampled as a standard normal random matrix in Rp\u00d7p. If we call this matrix R, then\nE [\u03c40] \u2265 E [ \u2223 \u2223 \u2223 I + \u03b3p\u22121 ( RTR )\u22121\u2223 \u2223 \u2223 \u22121 ]\n= 1\u2212 1 2 Zp(\u03b3),\nas desired.\nLemma 15. For any B \u2208 Rn\u00d7n, any Y \u2208 Rn\u00d7m, and any symmetric positive- semidefinite Z \u2208 Rn\u00d7n, if either B is rank-1 or m = 1, then\n\u2223 \u2223Y T (I +B)TZ(I +B)Y \u2223 \u2223\n= \u2223 \u2223Y TZY \u2223 \u2223\n(\n( tr ( Y (Y TZY )\u22121Y TZB ) + 1 )2\n+ tr ( Y (Y TZY )\u22121Y TBTZB )\n\u2212 tr ( ZY (Y TZY )\u22121Y TZBY (Y TZY )\u22121Y TBT )\n)\n.\nProof. We will prove this separately for each case. First, if m = 1, then Y is a vector, and the desired expression simplifies to\nY T (I +B)TZ(I +B)Y\n= Y TZY ( (Y TZY )\u22121Y TZBY + 1 )2\n+ tr ( Y TBTZBY ) \u2212 (Y TZY )\u22121(Y TZBY )2.\nStraightforward evaluation indicates that this expression holds in this case. Next, we consider the case where B is rank-1. In this case, we can rewrite it as B = uvT for vectors u and v, such that uTZu = 1. Then,\n\u2223 \u2223Y T (I +B)TZ(I +B)Y \u2223 \u2223\n= \u2223 \u2223Y T (I + uvT )TZ(I + uvT )Y \u2223 \u2223\n= \u2223 \u2223Y TZY + 2Y TZuvTY + Y T vvTY \u2223 \u2223\nIf we define M = Y TZY and W = [ Y TZu Y T v ] ,\nthen\n\u2223 \u2223Y T (I +B)TZ(I +B)Y \u2223 \u2223\n=\n\u2223 \u2223 \u2223 \u2223 M +W [ 0 1 1 1 ] W T \u2223 \u2223 \u2223 \u2223 .\nApplying the matrix determinant lemma, and recalling that\n[\n0 1 1 1\n]\u22121 = [\n\u22121 1 1 0\n]\nand \u2223\n\u2223 \u2223 \u2223 0 1 1 1\n\u2223 \u2223 \u2223 \u2223 = \u22121,\nwe produce\n\u2212 detM\u22121 \u2223 \u2223Y T (I +B)TZ(I +B)Y \u2223 \u2223\n= \u2212 \u2223 \u2223 \u2223\n\u2223\n[\n\u22121 1 1 0\n]\n+W TM\u22121W\n\u2223 \u2223 \u2223 \u2223\n=\n\u2223 \u2223 \u2223 \u2223 uTZYM\u22121Y TZu\u2212 1 vTYM\u22121Y TZu+ 1 vTYM\u22121Y TZu+ 1 vTYM\u22121Y T v \u2223 \u2223 \u2223 \u2223\n= ( uTZYM\u22121Y TZu\u2212 1 ) ( vTYM\u22121Y T v )\n\u2212 ( vTYM\u22121Y TZu+ 1 )2\n= uTZYM\u22121Y TZuvTYM\u22121Y T v\n\u2212 vTYM\u22121Y T vuTZu \u2212 ( vTYM\u22121Y TZu+ 1 )2 .\nRewriting this in terms of the matrix B = uvT ,\n\u2212 detM\u22121 \u2223 \u2223Y T (I +B)TZ(I +B)Y \u2223 \u2223\n= tr ( ZYM\u22121Y TZBYM\u22121Y TBT )\n\u2212 tr ( YM\u22121Y TBTZB )\n\u2212 ( tr ( YM\u22121Y TZB ) + 1 )2 .\nSubstitution produces the desired result.\nProof of Lemma 8. First, for the lower bound, we notice that\nZY (Y TZY )\u22121Y TZ Z,\nsince the interior of the left expression is a projection matrix. This lets us conclude that\ntr ( Y (Y TZY )\u22121Y TBTZB )\n\u2265 tr ( ZY (Y TZY )\u22121Y TZBY (Y TZY )\u22121Y TBT ) .\nAppling this to the result of Lemma 15 produces the desired lower bound. For the upper bound, recall that, by the Cauchy-Schwarz inequality, for any rank-1 matrix A,\ntr (A)2 \u2264 tr ( ATA ) .\nSince B is rank-1, it follows that\ntr ( Y (Y TZY )\u22121Y TZB )\n\u2264 tr ( ZY (Y TZY )\u22121Y TZBY (Y TZY )\u22121Y TBT ) .\nAppling this to the result of Lemma 15 produces the desired upper bound.\nLemma 16. For any symmetric matrix 0 X I ,\ntr (I \u2212X) \u2265 1\u2212 |X| .\nProof. If x1, x2, . . . , xp are the eigenvalues of x, then this statement is equivalent to\n(\np \u2211\ni=1\n(1\u2212 xi) ) \u2212 ( 1\u2212 p \u220f\ni=1\nxi\n)\n> 0.\nIf we let f(X) denote this expression, then\n\u2202f \u2202xj = \u22121 + 1 xj\np \u220f\ni=1\nxi \u2264 0.\nIt follows that the minimum of f is attained at X = I . However, when X = I , f(X) = 0, and so f > 0, which proves the lemma.\nProof of Lemma 10. From the definition of \u03c6k, if we let Z2 = ( Y Tk WYk )\u22121\nfor Z positive semidefinite, then\n\u03c6k = tr ( I \u2212 Y Tk UTUYk ( Y Tk WYk )\u22121)\n= tr ( I \u2212 ZY Tk UTUYkZ ) .\nSince 0 ZY Tk UTUYkZ I , we can apply Lemma 16, which produces\n\u03c6k \u2265 1\u2212 \u2223 \u2223ZY Tk U TUYkZ \u2223 \u2223\n= 1\u2212 \u2223 \u2223Y Tk U TUYk \u2223 \u2223 \u2223\n\u2223Y Tk WYk \u2223 \u2223\n= 1\u2212 \u03c4k,\nwhich is the desired expression.\nProof of Lemma 9. Since the success event does not occur, it follows that there exists a z \u2208 Rp such that\n\u2016UYkz\u20162\n\u2016Ykz\u20162 \u2264 1\u2212 \u01eb.\nIf we let Y\u0302k = Yk ( Y Tk Yk )\u2212 1 2 ,\nand define z\u0302 as the unit vector such that z\u0302 \u221d (\nY Tk Yk )\n1 2 z,\nthen we can rewrite this as \u2225\n\u2225 \u2225 UY\u0302kz\u0302\n\u2225 \u2225 \u2225 2 \u2264 1\u2212 \u01eb.\nIt follows that Y\u0302 Tk UY\u0302k has an eigenvalues less than 1\u2212 \u01eb. Now, expanding \u03c4k,\n\u03c4k =\n\u2223 \u2223Y Tk UYk \u2223 \u2223 \u2223 \u2223Y Tk WYk \u2223 \u2223\n=\n\u2223 \u2223 \u2223 Y\u0302 Tk UY\u0302k \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 Y\u0302 Tk WY\u0302k \u2223 \u2223 \u2223\n=\n\u2223 \u2223 \u2223 \u2223 (1\u2212 \u03b3n\u22121p\u22122q)I + \u03b3n\u22121p\u22122q ( Y\u0302 Tk UY\u0302k )\u22121 \u2223 \u2223 \u2223 \u2223\n\u22121\nSince this is a matrix that has eigenvalues between 0 and 1, it follows that its determinant is less than each of its eigenvalues. From the analysis above, we can bound one of the eigenvalues of this matrix. Doing this results in\n\u03c4k \u2264 ( (1\u2212 \u03b3n\u22121p\u22122q) + \u03b3n\u22121p\u22122q (1\u2212 \u01eb)\u22121 )\u22121\n= 1\u2212 \u01eb\n\u03b3n\u22121p\u22122q + (1\u2212 \u03b3n\u22121p\u22122q)(1 \u2212 \u01eb)\n= 1\u2212 \u03b3n \u22121p\u22122q\u01eb \u03b3n\u22121p\u22122q + (1\u2212 \u03b3n\u22121p\u22122q)(1\u2212 \u01eb) \u2264 1\u2212 \u03b3n\u22121p\u22122q\u01eb,\nas desired.\nLemma 17. Let x be a standard normal random variable, and a \u2208 R a constant. Then\nE\n[\na2\nx2 + a2\n]\n= exp\n(\na2\n2\n)\n\u221a\n\u03c0a2\n2 erfc\n( \u221a\na2\n2\n)\n.\nProof. By the definition of expected value, since x is normally distributed,\nE\n[\na2\nx2 + a2\n]\n=\n\u222b \u221e\n\u2212\u221e\n(\na2\nx2 + a2\n)(\n1\u221a 2\u03c0 exp\n(\n\u2212x 2\n2\n))\ndx.\nIf we let F denote the fourier transform, then\nF [\na\nx2 + a2\n] = \u221a 2\u03c0 exp (\u2212a |\u03c9|) .\nFurthermore, since the Gaussian functions are eigenfunctions of the Fourier transform, we know that\nF [ 1\u221a 2\u03c0 exp ( \u2212x 2 2 )] = 1\u221a 2\u03c0 exp ( \u2212\u03c9 2 2 ) .\nAnd so, by Parseval\u2019s theorem,\nE\n[\n1\nx2 + 1\n]\n= a\n\u222b \u221e\n\u2212\u221e F [\na\nx2 + a2\n] F [ 1\u221a 2\u03c0 exp ( \u2212x 2 2 )] d\u03c9\n= a\n\u222b \u221e\n\u2212\u221e\n\u221a 2\u03c0 exp (\u2212a |\u03c9|) (\n1\u221a 2\u03c0 exp\n(\n\u2212\u03c9 2\n2\n))\nd\u03c9\n= a\n\u222b \u221e\n0 exp\n(\n\u2212a\u03c9 \u2212 \u03c9 2\n2\n)\nd\u03c9\n= a exp\n(\na2\n2\n) \u222b \u221e\n0 exp\n(\n\u2212a 2 2 \u2212 a\u03c9 \u2212 \u03c9 2 2\n)\nd\u03c9.\nLetting u = \u03c9+a\u221a 2\nand d\u03c9 = \u221a 2du, so\nE\n[\n1\nx2 + 1\n]\n= a exp\n(\na2\n2\n)\u222b \u221e\na \u221a\n2\nexp ( \u2212u2 ) \u221a 2du\n= exp\n(\na2\n2\n)\n\u221a\n\u03c0a2\n2 erfc\n( \u221a\na2\n2\n)\n,\nas desired.\nProof of Lemma 1. We start by stating the definition of Z1(\u03b3). For some Gaussian random matrix R \u2208 R 1\u00d71,\nZ1(\u03b3) = 2 ( 1\u2212E [ \u2223 \u2223I + \u03b3(RTR)\u22121 \u2223 \u2223 \u22121]) .\nSince R is a scalar, this reduces to\nZ1(\u03b3) = 2 ( 1\u2212E [ ( 1 + \u03b3R\u22122 )\u22121])\n= E\n[\n2\n(\n1\u2212 1 1 + \u03b3R\u22122\n)]\n= E\n[ 2 \u03b3R\u22122\n1 + \u03b3R\u22122\n]\n= 2E\n[(\n\u03b3\nR2 + \u03b3\n)]\n.\nApplying Lemma 17,\nZ1(\u03b3) = 2 exp (\u03b3\n2\n)\n\u221a\n\u03c0\u03b3\n2 erfc\n( \u221a\n\u03b3\n2\n)\n= \u221a 2\u03c0\u03b3 exp (\u03b3\n2\n)\nerfc\n( \u221a\n\u03b3\n2\n)\n.\nThis is the desired expression. Furthermore, since for all x,\nerfc (\u221a x ) \u2264 exp (x) ,\nwe can also produce the desired upper bound on Z1,\nZ1 \u2264 \u221a 2\u03c0\u03b3.\nD.1 Proofs of Alecton Variance Condition Lemmas\nNext, we prove the Alecton Variance Conditions lemmas for the distributions mentioned in the body of the paper.\nD.1.1 Entrywise Sampling\nTo analyze the entrywise sampling case, we need some lemmas that makes the incoherence condition more accessible.\nLemma 18. If matrix A is symmetric and incoherent with parameter \u00b5, and B is a symmetric matrix that commutes with A, then B is incoherent with parameter \u00b5.\nProof. Since A and B commute, they must have the same eigenvectors. Therefore, the set of eigenvectors that shows that A is incoherent with parameter \u00b5 will also show that B has the same property.\nLemma 19. If matrix A is symmetric and incoherent with parameter \u00b5, and ei is a standard basis element, then\neTi Aei \u2264 \u00b52\nn tr (A) .\nProof. Let u1, u2, . . . , un be the eigenvectors guaranteed by the incoherence of A, and let \u03bb1, . . . , \u03bbn be the corresponding eigenvalues. Then,\neTi Aei = e T i\n\n\nn \u2211\nj=1\nuj\u03bbju T j\n\n ei\n=\nn \u2211\nj=1\nuj\u03bbj(e T i uj) 2.\nApplying the definition of incoherence,\neTi Aei \u2264 n \u2211\nj=1\nuj\u03bbj\n(\n\u00b5\u221a n\n)2\n= \u00b52\nn tr (A) ,\nas desired.\nProof of the \u03c3a bound part of Lemma 2. We recall that the entrywise samples are of the form\nA\u0303 = n2uuTAvvT ,\nwhere u and v are independently, uniformly chosen standard basis elements. We further recall that E [ uuT ]\n= E [ vvT ] = n\u22121I . Now, evaluating the desired quantity,\nE\n[ yT A\u0303TWA\u0303y ] = n4E [ yT vvTAuuTWuuTAvvT y ] .\nSince W commutes with A, by Lemmas 18 and 19, uTWu \u2264 \u00b52n\u22121tr (W ). Therefore,\nE\n[ yT A\u0303TWA\u0303y ] \u2264 \u00b52n3tr (W )E [ yTvvTAuuTAvvT y ]\n= \u00b52n2tr (W )E [ yTvvTA2vvT y ] .\nSince A2 commutes with A, the same logic shows that vTA2v \u2264 \u00b52n\u22121tr ( A2 ) , and so,\nE\n[ yT A\u0303TWA\u0303y ] \u2264 \u00b54ntr (W ) tr ( A2 ) E [ yT vvT y ]\n= \u00b54tr (W ) \u2016A\u20162F \u2016y\u2016 2 .\nSo it suffices to choose \u03c32a = \u00b5 4 \u2016A\u20162F , as desired.\nProof of the \u03c3r bound part of Lemma 2. Evaluating the desired quantity,\nE\n[\n( yT A\u0303y )2\n]\n= n4E [ ( yTuuTAvvT y )2 ]\n= n4E [ (uT y)2(vT y)2(uTAv)2 ] .\nBy the CauchySchwarz inequality,\n(uTAv)2 \u2264 (uTAu)(vTAv),\nand by Lemma 19, uTAu \u2264 \u00b52n\u22121tr (A), and so\n(uTAv)2 \u2264 \u00b54n\u22122tr (A)2 .\nTherefore,\nE\n[\n( yT A\u0303y )2\n]\n\u2264 \u00b54n2tr (A)2 E [ (uT y)2(vT y)2 ]\n= \u00b54tr (A)2 \u2016y\u20164 .\nSo it suffices to choose \u03c32r = \u00b5 4 tr (A)2, as desired.\nD.1.2 Rectangular Entrywise Sampling\nProof of Lemma 3. We recall that the rectangular entrywise samples are of the form\nA\u0303 = mnMij(eie T m+j + em+je T i ),\nwhere i \u2208 1, . . . ,m and j \u2208 1, . . . , n are chosen uniformly and independently. Now, for any y and z in R m+n,\nE\n[ (zT A\u0303y)2 ] = m2n2E [\nM2ij(z T (eie T m+j + em+je T i )y)\n2 ]\n.\nApplying the entry bound,\nE\n[ (zT A\u0303y)2 ]\n\u2264 \u03bemn \u2016M\u20162F E [ (zT eie T m+jy + z T em+je T i y) 2 ] .\nNow, since (x+ y)2 \u2264 2(x2 + y2), if we let P be the projection matrix onto the first m basis vectors, then E [\neie T i\n] = m\u22121P and E [\nem+je T m+j\n]\n= n\u22121(I \u2212 P ), and so,\nE\n[ (zT A\u0303y)2 ]\n\u2264 2\u03bemn \u2016M\u20162F E [ (zT ei) 2(eTm+jy) 2 + (zT em+j) 2(eTi y) 2 ] = 2\u03be \u2016M\u20162F ( \u2016Pz\u20162 \u2016(I \u2212 P )y\u20162 + \u2016(I \u2212 P )z\u20162 \u2016Py\u20162 )\n\u2264 2\u03be \u2016M\u20162F \u2016y\u2016 2 \u2016z\u20162 .\nSince this is true for any y and z, it is true in particular for z being an eigenvector of A. Therefore, it suffices to pick \u03c32a = 2\u03be \u2016M\u20162F . Similarly, it is true in particular for z = y, and therefore it suffices to pick \u03c32r = 2\u03be \u2016M\u20162F . This proves the lemma.\nD.1.3 Trace Sampling\nIn order to prove our second moment lemma for the trace sampling case, we must first derive some lemmas about the way this distribution behaves.\nLemma 20 (Sphere Component Fourth Moment). If n > 50, and v \u2208 Rn is sampled uniformly from the unit sphere, then for any unit vector y \u2208 Rn,\nE\n[\n( yT v )4 ] \u2264 4 n2 .\nProof. Let x be sampled from the standard normal distribution in Rn. Then, by radial symmetry,\nE\n[\n( yTv )4 ] = E\n[\n( yTx )4\n\u2016x\u20164\n]\n.\nIf we let u denote yTx, and z denote the components of x orthogonal to y, then \u2016x\u20162 = u2 + \u2016z\u20162. Furthermore, by the properties of the normal distribution, u and z are independent. Therefore,\nE\n[\n( yT v )4 ] = E\n[\nu4 ( u2 + \u2016z\u20162 )\u22122\n]\n\u2264 E [ u4 ( \u2016z\u20162 )\u22122 ]\n= E [ u4 ] E\n[ \u2016z\u2016\u22124 ] .\nNow, E [ u4 ] is the fourth moment of the normal distribution, which is known to be 3. Furthermore,\nE\n[ \u2016z\u2016\u22124 ]\nis the second moment of an inverse-chi-squared distribution with parameter n \u2212 1, which is also a known result. Substituting these in,\nE\n[\n( yT v )4 ] \u2264 3 ( (n\u2212 3)\u22122 + 2 (n\u2212 3)\u22122 (n\u2212 5)\u22121 )\n= 3 (n\u2212 3)\u22122 ( 1 + 2 (n\u2212 5)\u22121 ) .\nThis quantity has the asymptotic properties we want. In particular, applying the constraint that n > 50,\nE\n[\n( yT v )4 ] \u2264 4 n2 .\nThis is the desired result.\nLemma 21 (Sphere Component Fourth Moment Matrix). If n > 50, and v \u2208 Rn is sampled uniformly from the unit sphere, then for any positive semidefinite matrix W ,\nE [ vvTWvvT ] 4n\u22122tr (W ) I.\nProof. Let\nW =\nn \u2211\ni=1\n\u03bbiwiw T i\nbe the eigendecomposition of W . Then for any unit vector z,\nzTE [ vvTWvvT ] z = E\n[\nzT vvT\n(\nn \u2211\ni=1\n\u03bbiwiw T i\n)\nvvT z\n]\n= n \u2211\ni=1\n\u03bbiE [ ( zT v )2 ( wTi v )2 ] .\nBy the Cauchy-Schwarz inequality applied to the expectation,\nE\n[\n( zT v )2 ( wTi v )2 ] \u2264 \u221a E [ (zT v)4 ] E [ ( wTi v )2 ]\n= E [ (zT v)4 ] .\nBy Lemma 20, E [ (zT v)4 ] \u2264 4n\u22122, and so\nzTE [ vvTWvvT ] z \u2264 n \u2211\ni=1\n\u03bbi(4n \u22122) = 4n\u22122tr (W ) .\nSince this is true for any unit vector z, by the definition of the positive semidefinite relation,\nE [ vvTWvvT ] 4n\u22122tr (W ) I,\nas desired.\nNow, we prove the AVC lemma for this distribution.\nProof of \u03c3a bound part of Lemma 4. Evaluating the expression we want to bound,\nE\n[ yT A\u0303TWA\u0303y ] = n4E [ yT vvTAuuTWuuTAvvT y ] .\nApplying Lemma 21,\nE\n[ yT A\u0303TWA\u0303y ] \u2264 n4E [ yT vvTA ( 4n\u22122tr (W ) I ) AvvT y ]\n= 4n2tr (W )E [ yT vvTA2vvT y ] .\nAgain applying Lemma 21,\nE\n[ yT A\u0303TWA\u0303y ] \u2264 4n2tr (W ) yT ( 4n\u22122tr ( A2 ) I ) y\n= 16 \u2016A\u20162F tr (W ) \u2016y\u2016 2 .\nSo it suffices to pick \u03c32a = 16 \u2016A\u20162F , as desired.\nProof of \u03c3r bound part of Lemma 4. Evaluating the expression we want to bound,\nE\n[\n( yA\u0303y )2\n]\n= n4E [ ( yvvTAwwT y )2 ]\n= n4E [ tr ( AvvT yyT vvTAwwT yyTwwT )]\n= n4tr ( AE [ vvT yyT vvT ] AE [ wwT yyTwwT ]) .\nApplying Lemma 21 to this results in\nE\n[\n( yA\u0303y )2\n]\n\u2264 n4tr ( A ( 4n\u22122tr ( yyT ) I ) A ( 4n\u22122tr ( yyT ) I ))\n= 16 \u2016A\u20162F \u2016y\u2016 4 .\nSo it suffices to pick \u03c32r = 16 \u2016A\u20162F , as desired.\nD.1.4 Subspace Sampling\nRecall that, in subspace sampling, our samples are of the form\nA\u0303 = rn2m\u22122QvvTR,\nwhere Q and R are independent projection matrices that select m entries uniformly at random, and v is uniformly and independently selected from the column space of A. Using this, we first prove some lemmas, then prove our bounds.\nLemma 22. If Q is a projection matrix that projects onto a subspace spanned by m random standard basis vectors, and v is a member of a subspace that is incoherent with parameter \u00b5, then for any vector x,\n(xTQv)2 \u2264 (\u00b5mr +m2)n\u22122 \u2016x\u20162 \u2016v\u20162 ."}, {"heading": "As a corollary, for any symmetric matrix W 0,", "text": "vTQWQv \u2264 (\u00b5mr +m2)n\u22122tr (W ) \u2016v\u20162 .\nProof. Let \u03bbi be 1 in the event that ei is in the column space of Q, and 0 otherwise. Then an eigendecomposition of Q is\nQ =\nn \u2211\ni=1\n\u03bbieie T i .\nTherefore,\n(xTQv)2 =\n(\nn \u2211\ni=1\n\u03bbix T eie T i v\n)2\n=\nn \u2211\ni=1\nn \u2211\nj=1\n\u03bbi\u03bbjxixjvivj .\nTaking the expected value, and noting that \u03bbi and \u03bbj are independent, and have expected value E [\u03bbi] = mn\u22121,\nE [ (xTQv)2 ] = m2n\u22122 n \u2211\ni=1\nn \u2211\nj=1\nxixjvivj\n+mn\u22121(1\u2212mn\u22121) n \u2211\ni=1\nx2i v 2 i .\nSince v is part of a subspace that is incoherent,\nE [ (xTQv)2 ] \u2264 m2n\u22122 n \u2211\ni=1\nn \u2211\nj=1\nxixjvivj\n+ \u00b5mrn\u22122(1\u2212mn\u22121) \u2016v\u20162 n \u2211\ni=1\nx2i\n= m2n\u22122(xT v)2\n+ \u00b5mrn\u22122 \u2016x\u20162 \u2016v\u20162\n\u2264 (\u00b5mr +m2)n\u22122 \u2016x\u20162 \u2016v\u20162 ,\nas desired.\nProof of \u03c3a bound part of Lemma 5. Evaluating the expression we want to bound,\nE\n[ yT A\u0303TWA\u0303y ]\n= r2n4m\u22124E [ yTRvvTQWQvvTRy ] = r2n4m\u22124E [ E [ vTRyyTRv ] E [ vTQWQv ]] .\nApplying Lemma 22,\nE\n[ yT A\u0303TWA\u0303y ] \u2264 r2m\u22124(\u00b5mr +m2)2tr (W ) \u2016y\u20162\n= r2(1 + \u00b5rm\u22121)2tr (W ) \u2016y\u20162 .\nSo, we can choose \u03c32a = r 2(1 + \u00b5rm\u22121)2, as desired.\nProof of \u03c3r bound part of Lemma 5. Evaluating the expression we want to bound,\nE\n[ (yT A\u0303y)2 ] = r2n4m\u22124E [ (yTQvvTRy)2 ]\n= r2n4m\u22124E [ E [ (yTQv)2 ] E [ (yTRv)2 ]] .\nApplying Lemma 22,\nE\n[ (yT A\u0303y)2 ] \u2264 r2m\u22124(\u00b5mr +m2)2 \u2016y\u20164\n= r2(1 + \u00b5rm\u22121)2 \u2016y\u20164 .\nSo, we can choose \u03c32r = r 2(1 + \u00b5rm\u22121)2, as desired."}, {"heading": "E Lower Bound on Alecton Rate", "text": "In this section, we prove a rough lower bound on the rate of convergence of an Alecton-like algorithm for bounded sampling distributions. Specifically, we analyze the case where, rather than choosing a constant \u03b7, we allow the step size to vary at each timestep. Our result shows that we can\u2019t hope for a better step size rule that improves the convergence rate of Alecton to, for example, a linear rate.\nTo show this lower bound, we assume we run Alecton with p = 1 for some sampling distribution such that for all \u03b7 and all y, for some constant C ,\n\u2225 \u2225 \u2225y + \u03b7A\u0303y \u2225 \u2225 \u2225 \u2264 (1 + \u03b7C) \u2016y\u2016 .\nFurther assume that for some eigenvector u (with eigenvalue \u03bb \u2265 0) that is not global solution, the sample variance in the direction of u satisfies\nE\n[ A\u0303TuuT A\u0303 ] \u2265 \u03c32I.\nWe now define \u03c1k to be\n\u03c1k = (uTYk) 2\n\u2016Yk\u20162 .\nThis quantity measures the error of the iterate at timestep k in the direction of u. We will show that the expected value of \u03c1k can only decrease with at best a \u2126 ( 1 K+1 ) rate.\nFirst, we require a lemma.\nLemma 23. For any a \u2265 0, b \u2265 0, and 0 \u2264 x \u2264 1,\na(1\u2212 x)2 + bx2 \u2265 ab a+ b .\nProof. Expanding the left side,\na(1\u2212 x)2 + bx2 = a\u2212 2ax+ (a+ b)x2\n= a\u2212 a 2\na+ b +\na2\na+ b \u2212 2ax+ (a+ b)x2\n= ab\na+ b + (a\u2212 (a+ b)x)2 a+ b\n\u2265 ab a+ b ,\nas desired.\nTheorem 3. Under the above conditions, regardless of how we choose the step size in the Alecton algorithm, even if we are able to choose a different step size each iteration, the expected error will still satisfy\nE [\u03c1K ] \u2265 \u03c32\n\u03c32n+ C2K .\nProof. Using the Alecton update rule with a time-varying step size \u03b7k,\n\u03c1k+1 = (uTYk) 2\n\u2016Yk\u20162\n= (uTYk + \u03b7ku T A\u0303kYk) 2\n\u2225 \u2225 \u2225 Yk + \u03b7kA\u0303kYk \u2225 \u2225 \u2225 2\n\u2265 (u TYk + \u03b7ku T A\u0303kYk) 2\n(1 + \u03b7kC)2 \u2016Yk\u20162 .\nTaking the expected value,\nE [\u03c1k+1] \u2265 E [ (uTYk + \u03b7ku T A\u0303kYk) 2\n(1 + \u03b7kC)2 \u2016Yk\u20162\n]\n\u2265 E [ (1 + 2\u03b7k\u03bb)(u TYk) 2 + \u03b72k\u03c3 2Y Tk Yk (1 + \u03b7kC)2 \u2016Yk\u20162 ]\n= 1 + 2\u03b7k\u03bb\n(1 + \u03b7kC)2 E [\u03c1k] +\n\u03b72k\u03c3 2\n(1 + \u03b7kC)2\n\u2265 1 (1 + \u03b7kC)2 E [\u03c1k] + \u03b72k\u03c3 2 (1 + \u03b7kC)2\nNow, if we define \u03b6k as\n\u03b6k = \u03b7kC\n1 + \u03b7kC ,\nthen E [\u03c1k+1] \u2265 (1\u2212 \u03b6k)2E [\u03c1k] + \u03b62k\u03c32C\u22122.\nApplying Lemma 23,\nE [\u03c1k+1] \u2265 \u03c32C\u22122E [\u03c1k]\nE [\u03c1k] + \u03c32C\u22122 .\nTaking the inverse, 1\nE [\u03c1k+1] \u2264 1 E [\u03c1k] +\nC2 \u03c32 .\nTherefore, summing across steps, 1\nE [\u03c1K ] \u2264 1 E [\u03c10] +\nC2K\n\u03c32 .\nSince, by symmetry, E [\u03c10] = n\u22121, we have\n1 E [\u03c1K ] \u2264 n+ C\n2K\n\u03c32 .\nand taking the inverse again produces\nE [\u03c1K ] \u2265 \u03c32\n\u03c32n+ C2K ,\nwhich is the desired expression."}, {"heading": "F Handling Constraints", "text": "Alecton can easily be adapted to solve the problem of finding a low-rank approximation to a matrix under a spectahedral constraint. That is, we want to solve the problem\nminimize \u2016A\u2212X\u20162F subject to X \u2208 RN\u00d7N , tr (X) = 1,\nrank (X) \u2264 1,X 0.\nThis is equivalent to the decomposed problem\nminimize \u2016y\u20164 \u2212 2yTAy + \u2016A\u20162F subject to y \u2208 RN , \u2016y\u20162 = 1,\nwhich is itself equivalent to: minimize 1\u2212 2yTAy + \u2016A\u20162F subject to y \u2208 RN , \u2016y\u20162 = 1.\nThis will have a minimum when y = u1. We can therefore solve the problem using only the angular phase of Alecton, which recovers the vector u1. The same convergence analysis described above still applies.\nFor an example of a constrained problem that Alecton cannot handle, because it is NP-hard, see the elliptope-constrained MAXCUT embedding in Appendix A. This shows that constrained problems can\u2019t be solved efficiently by SGD algorithms in all cases."}, {"heading": "G Towards a Linear Rate", "text": "In this section, we consider a special case of the matrix recovery problem: one in which the samples we are given would allow us to exactly recover A. That is, for some linear operator \u2126 : Rn\u00d7n \u2192 Rs, we are given the value of \u2126(A) as an input, and we know that the unique solution of the optimization problem\nminimize \u2016\u2126(X \u2212A)\u20162 subject to X \u2208 Rn\u00d7n, rank (X) \u2264 p,X 0\nis X = A. Performing a rank-p quadratic substitution on this problem results in:\nminimize \u2225 \u2225\u2126(Y Y T \u2212A) \u2225 \u2225 2 subject to Y \u2208 Rn\u00d7p\nThe specific case we will be looking at is where the operator \u2126 satisfies the p-RIP constraint.\nDefinition 8 (Restricted isometry property). A linear operator \u2126 : Rn\u00d7n \u2192 Rs satisfies p-RIP with constant \u03b4 if for all X \u2208 Rn\u00d7n of rank at most p,\n(1\u2212 \u03b4) \u2016X\u20162F \u2264 \u2016\u2126(X)\u2016 2 \u2264 (1 + \u03b4) \u2016X\u20162F .\nThis definition encodes the notion that \u2126 preserves the norm of low-rank matrices under its transformation. We can prove a simple lemma that extends this to the inner product.\nLemma 24. If \u2126 is (p+ q)-RIP with parameter \u03b4, then for any symmetric matrices X and Y of rank at most p and q respectively,\n\u2126(X)T\u2126(Y ) \u2265 tr (XY )\u2212 \u03b4 \u2016X\u2016F \u2016Y \u2016F\nProof. For any a \u2208 R, since \u2126 is linear,\ntr (\u2126(X)\u2126(Y )) = 1\n4a\n( \u2016\u2126(X) + a\u2126(Y )\u20162 \u2212 \u2016\u2126(X)\u2212 a\u2126(Y )\u20162 )\n= 1\n4a\n( \u2016\u2126(X + aY )\u20162 \u2212 \u2016\u2126(X \u2212 aY )\u20162 ) .\nSince rank (X \u2212 aY ) \u2264 rank (X) + rank (Y ) \u2264 p + q, we can apply our RIP inequalities, which produces\ntr (\u2126(X)\u2126(Y )) \u2265 1 4a ( (1\u2212 \u03b4) \u2016X + aY \u2016 2F \u2212 (1 + \u03b4) \u2016X \u2212 aY \u2016 2F )\n\u2265 1 4a ( \u22122\u03b4 \u2016X\u2016 2F + 4atr (XY )\u2212 2\u03b4a2 \u2016Y \u2016 2F ) = tr (XY )\u2212 \u03b4\u2016X\u2016 2 F + a\n2 \u2016Y \u2016 2F 2a .\nSubstituting a = \u2016X\u2016F\u2016Y \u2016 F results in\ntr (\u2126(X)\u2126(Y )) \u2265 tr (XY )\u2212 \u03b4 \u2016X\u2016F \u2016Y \u2016F ,\nas desired.\nFinally, we prove our main theorem that shows that the quadratically transformed objective function is strongly convex in a ball about the solution.\nTheorem 4. If we define f(Y ) as the objective function of the above optimization problem, that is for Y \u2208 Rn\u00d7p and A \u2208 Rn\u00d7n symmetric of rank no greater than p,\nf(Y ) = \u2225 \u2225\u2126(Y Y T \u2212A) \u2225 \u2225 2 ,\nand \u2126 is 3p-RIP with parameter \u03b4, then for all Y , if we let \u03bbp denote the smallest positive eigenvalue of A then\n\u22072V f(Y ) 2 ( (1\u2212 \u03b4)\u03bbp \u2212 (3 + \u03b4) \u2225 \u2225Y Y T \u2212A \u2225 \u2225\nF\n)\nI.\nProof. The directional derivative of f along some direction V will be, by the product rule,\n\u2207V f(Y ) = 2\u2126(Y Y T \u2212A)T\u2126(Y V T + V Y T ).\nThe second derivative along this same direction will be\n\u22072V f(Y ) = 4\u2126(Y Y T \u2212A)T\u2126(V V T ) + 2\u2126(Y V T + V Y T )T\u2126(Y V T + V Y T ) = 4\u2126(Y Y T \u2212A)T\u2126(V V T ) + 2 \u2225 \u2225\u2126(Y V T + V Y T ) \u2225 \u2225 2 .\nTo this, we can apply the definition of RIP, and the corollary lemma, which results in\n\u22072V f(Y ) \u2265 4tr ( (Y Y T \u2212A)(UUT ) ) \u2212 4\u03b4 \u2225 \u2225Y Y T \u2212A \u2225 \u2225 F \u2225 \u2225UUT \u2225 \u2225 F + 2(1\u2212 \u03b4) \u2225 \u2225Y UT + UY T \u2225 \u2225 2 F .\nBy Cauchy-Schwarz,\n\u22072V f(Y ) \u2265 \u22124 \u2225 \u2225Y Y T \u2212A \u2225 \u2225 F tr ( UUT ) \u2212 4\u03b4 \u2225 \u2225Y Y T \u2212A \u2225 \u2225 F tr ( UUT ) + 2(1\u2212 \u03b4)\u03bbmin(Y TY )tr ( UUT )\n= 2 ( (1\u2212 \u03b4)\u03bbmin(Y TY )\u2212 2(1 + \u03b4) \u2225 \u2225Y Y T \u2212A \u2225 \u2225 F ) tr ( UUT ) .\nNow, since at the optimum, \u03bbmin(Y TY ) = \u03bbp, it follows that for general Y ,\n\u03bbmin(Y TY ) \u2265 \u03bbp \u2212\n\u2225 \u2225Y Y T \u2212A \u2225 \u2225\nF .\nSubstituting this in to the previous expression,\n\u22072V f(Y ) \u2265 2 ( (1\u2212 \u03b4)(\u03bbp \u2212 \u2225 \u2225Y Y T \u2212A \u2225 \u2225 F )\u2212 2(1 + \u03b4) \u2225 \u2225Y Y T \u2212A \u2225 \u2225 F ) tr ( UUT )\n= 2 ( (1\u2212 \u03b4)\u03bbp \u2212 (3 + \u03b4) \u2225 \u2225Y Y T \u2212A \u2225 \u2225 F ) \u2016U\u2016 2F .\nSince this is true for an arbitrary direction vector U , it follows that\n\u22072V f(Y ) 2 ( (1\u2212 \u03b4)\u03bbp \u2212 (3 + \u03b4) \u2225 \u2225Y Y T \u2212A \u2225 \u2225\nF\n)\nI,\nwhich is the desired result.\nThis theorem shows that there is a region of size O(1) (i.e. not dependent on n) within which the above problem is strongly convex. So, if we start within this region, any standard convex descent method will converge at a linear rate. In particular, coordinate descent will do so. Therefore, we can imagine doing the following:\n\u2022 First, use Alecton to, with high probability, recover an estimate Y that for which \u2225 \u2225Y Y T \u2212A \u2225 \u2225\nF is\nsufficiently small for the objective function to be strongly convex with some probability. This will only require O(n log n) steps of the angular phase of the algorithm per iteration of Alecton, as stated in the main body of the paper. We will need p iterations of the algorithm to recover a rank-p estimate, so a total O(np log n) iterations will be required.\n\u2022 Use a descent method, such as coordinate descent, to recover additional precision of the estimate. This method is necessarily more heavyweight than an SGD scheme (see Section E for the reason why an SGD scheme cannot achieve a linear rate), but it will converge monotonically at a linear rate to the exact solution matrix A.\nThis hybrid method is in some sense a best-of-both worlds approach. We use fast SGD steps when we can afford to, and then switch to slower coordinate descent steps when we need additional precision.\nSecondary Literature\n[11] Emmanuel Cande\u0300s, Xiaodong Li, and Mahdi Soltanolkotabi. Phase retrieval via wirtinger flow: Theory and algorithms. arXiv preprint arXiv:1407.1065, 2014.\n[13] EmmanuelJ. Cande\u0300s and Xiaodong Li. Solving quadratic equations via phaselift when there are about as many equations as unknowns. FoCM, 14(5):1017\u20131026, 2014.\n[28] R.H. Keshavan, A. Montanari, and Sewoong Oh. Matrix completion from a few entries. Information Theory, IEEE Transactions on, 56(6):2980\u20132998, June 2010.\n[41] Praneeth Netrapalli, Prateek Jain, and Sujay Sanghavi. Phase retrieval using alternating minimization. In Advances in Neural Information Processing Systems 26, pages 2796\u20132804. 2013."}], "references": [{"title": "Optimization Algorithms on Matrix Manifolds", "author": ["P.-A. Absil", "R. Mahony", "R. Sepulchre"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "A reliable effective terascale linear learning system", "author": ["Alekh Agarwal", "Olivier Chapelle", "Miroslav Dud\u0131\u0301k", "John Langford"], "venue": "CoRR, abs/1110.4198,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Stochastic optimization for pca and pls", "author": ["R. Arora", "A. Cotter", "K. Livescu", "N. Srebro"], "venue": "In Communication, Control, and Computing (Allerton),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Stochastic optimization of pca with capped msg", "author": ["Raman Arora", "Andy Cotter", "Nati Srebro"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "The fast convergence of incremental pca", "author": ["Akshay Balsubramani", "Sanjoy Dasgupta", "Yoav Freund"], "venue": "In NIPS,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Online identification and tracking of subspaces from highly incomplete information", "author": ["Laura Balzano", "Robert Nowak", "Benjamin Recht"], "venue": "In Communication, Control, and Computing (Allerton),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Large-scale machine learning with stochastic gradient descent", "author": ["Lon Bottou"], "venue": "In Proceedings of COMP- STAT\u20192010,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "The tradeoffs of large scale learning", "author": ["Lon Bottou", "Olivier Bousquet"], "venue": "In IN: ADVANCES IN NEU- RAL INFORMATION PROCESSING SYSTEMS", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization", "author": ["Samuel Burer", "Renato DC Monteiro"], "venue": "Mathematical Programming,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2003}, {"title": "Local minima and convergence in low-rank semidefinite programming", "author": ["Samuel Burer", "Renato DC Monteiro"], "venue": "Mathematical Programming,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Phase retrieval via wirtinger flow: Theory and algorithms", "author": ["Emmanuel Cand\u00e8s", "Xiaodong Li", "Mahdi Soltanolkotabi"], "venue": "arXiv preprint arXiv:1407.1065,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Exact matrix completion via convex optimization", "author": ["Emmanuel J. Cand\u00e8s", "Benjamin Recht"], "venue": "FoCM, 9(6):717\u2013772,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Solving quadratic equations via phaselift when there are about as many equations as unknowns. FoCM", "author": ["EmmanuelJ. Cand\u00e8s", "Xiaodong Li"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Matrix completion via an alternating direction method", "author": ["Caihua Chen", "Bingsheng He", "Xiaoming Yuan"], "venue": "IMAJNA,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Counting processes and survival analysis", "author": ["Thomas R Fleming", "David P Harrington"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1991}, {"title": "Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming", "author": ["Michel X. Goemans", "David P. Williamson"], "venue": "J. ACM,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1995}, {"title": "Wtf: The who to follow service at twitter", "author": ["Pankaj Gupta", "Ashish Goel", "Jimmy Lin", "Aneesh Sharma", "Dong Wang", "Reza Zadeh"], "venue": "WWW \u201913,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "The noisy power method: A meta algorithm with applications", "author": ["Moritz Hardt", "Eric Price"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Design and performance of parallel and distributed approximation algorithms for maxcut", "author": ["Steven Homer", "Marcus Peinado"], "venue": "J. Parallel Distrib. Comput.,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1997}, {"title": "Solving ptychography with a convex relaxation", "author": ["R. Horstmeyer", "R.Y. Chen", "X. Ou", "B. Ames", "J.A. Tropp", "C. Yang"], "venue": "ArXiv e-prints,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Accelerated gradient methods for stochastic optimization and online learning", "author": ["Chonghai Hu", "James T. Kwok", "Weike Pan"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2009}, {"title": "Low-rank matrix completion using alternating minimization", "author": ["Prateek Jain", "Praneeth Netrapalli", "Sujay Sanghavi"], "venue": "In Proceedings of the Forty-fifth Annual ACM STOC,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Robust stochastic principal component analysis", "author": ["Raman Arora John Goes", "Teng Zhang", "Gilad Lerman"], "venue": "In Proceedings of the 17th International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Low-rank optimization on the cone of positive semidefinite matrices", "author": ["M. Journ\u00e9e", "F. Bach", "P.-A. Absil", "R. Sepulchre"], "venue": "SIAM J. on Optimization,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "Matrix completion from a few entries", "author": ["R.H. Keshavan", "A. Montanari", "Sewoong Oh"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Low-rank optimization with trace norm penalty", "author": ["Bamdev Mishra", "Gilles Meyer", "Francis Bach", "Rodolphe Sepulchre"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "Hogwild: A lock-free approach to parallelizing stochastic gradient descent", "author": ["Feng Niu", "Benjamin Recht", "Christopher R\u00e9", "Stephen J. Wright"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2011}, {"title": "On stochastic approximation of the eigenvectors and eigenvalues of the expectation of a random matrix", "author": ["Erkki Oja"], "venue": "Journal of Mathematical Analysis and Applications,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1985}, {"title": "Summingbird: A framework for integrating batch and online mapreduce computations", "author": ["Sam Ritchie"], "venue": "In Proceedings of the VLDB Endowment,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}, {"title": "Parallel stochastic gradient algorithms for large-scale matrix completion", "author": ["Benjamin Recht", "Christopher R\u00e9"], "venue": "Mathematical Programming Computation,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2013}, {"title": "Making gradient descent optimal for strongly convex stochastic optimization", "author": ["Ohad Shamir"], "venue": "CoRR, abs/1109.5647,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "A stochastic PCA algorithm with an exponential convergence rate", "author": ["Ohad Shamir"], "venue": "CoRR, abs/1409.2848,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2014}, {"title": "Distributed matrix completion", "author": ["Christina Teflioudi", "Faraz Makari", "Rainer Gemulla"], "venue": "IEEE 13th ICDM,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2013}], "referenceMentions": [{"referenceID": 8, "context": "edu Departments of Electrical Engineering and Computer Science Stanford University, Stanford, CA 94309 February 11, 2015 Abstract Stochastic gradient descent (SGD) on a low-rank factorization [9] is commonly employed to speed up matrix problems including matrix completion, subspace tracking, and SDP relaxation.", "startOffset": 192, "endOffset": 195}, {"referenceID": 13, "context": "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].", "startOffset": 149, "endOffset": 161}, {"referenceID": 22, "context": "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].", "startOffset": 149, "endOffset": 161}, {"referenceID": 33, "context": "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].", "startOffset": 149, "endOffset": 161}, {"referenceID": 5, "context": "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].", "startOffset": 209, "endOffset": 212}, {"referenceID": 2, "context": "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].", "startOffset": 243, "endOffset": 246}, {"referenceID": 9, "context": "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].", "startOffset": 261, "endOffset": 277}, {"referenceID": 20, "context": "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].", "startOffset": 261, "endOffset": 277}, {"referenceID": 24, "context": "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].", "startOffset": 261, "endOffset": 277}, {"referenceID": 26, "context": "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].", "startOffset": 261, "endOffset": 277}, {"referenceID": 17, "context": "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].", "startOffset": 306, "endOffset": 314}, {"referenceID": 29, "context": "This problem, or problems that can be transformed to this problem, appears in a variety of machine learning applications including matrix completion [14, 25, 36], general data analysis [37], subspace tracking [6], principle component analysis [3], optimization [10, 23, 27, 29], and recommendation systems [20, 32].", "startOffset": 306, "endOffset": 314}, {"referenceID": 8, "context": "Sometimes, (1) arises under conditions in which the samples \u00c3 are sparse, but the matrix X would be too large to store and operate on efficiently; a standard heuristic to use in this case is a low-rank factorization [9].", "startOffset": 216, "endOffset": 219}, {"referenceID": 1, "context": "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].", "startOffset": 63, "endOffset": 92}, {"referenceID": 6, "context": "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].", "startOffset": 63, "endOffset": 92}, {"referenceID": 7, "context": "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].", "startOffset": 63, "endOffset": 92}, {"referenceID": 14, "context": "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].", "startOffset": 63, "endOffset": 92}, {"referenceID": 21, "context": "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].", "startOffset": 63, "endOffset": 92}, {"referenceID": 27, "context": "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].", "startOffset": 63, "endOffset": 92}, {"referenceID": 30, "context": "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].", "startOffset": 63, "endOffset": 92}, {"referenceID": 33, "context": "Efficient SGD implementations can scale to very large datasets [2, 7, 8, 16, 24, 30, 33, 36].", "startOffset": 63, "endOffset": 92}, {"referenceID": 24, "context": "People have attempted to compensate for this with sophisticated methods like geodesic step rules [27] and manifold projections [1]; however, even these methods cannot guarantee global convergence.", "startOffset": 97, "endOffset": 101}, {"referenceID": 0, "context": "People have attempted to compensate for this with sophisticated methods like geodesic step rules [27] and manifold projections [1]; however, even these methods cannot guarantee global convergence.", "startOffset": 127, "endOffset": 130}, {"referenceID": 10, "context": "We make the following contributions: \u2022 We establish the convergence rate to a global optimum of Alecton using a random initialization; in contrast, prior analyses [11, 25] have required more expensive initialization methods, such as the singular value decomposition of an empirical average of the data.", "startOffset": 163, "endOffset": 171}, {"referenceID": 22, "context": "We make the following contributions: \u2022 We establish the convergence rate to a global optimum of Alecton using a random initialization; in contrast, prior analyses [11, 25] have required more expensive initialization methods, such as the singular value decomposition of an empirical average of the data.", "startOffset": 163, "endOffset": 171}, {"referenceID": 18, "context": "\u2022 In contrast to previous work that uses bounds on the magnitude of the noise [21], our analysis depends only on the variance of the samples.", "startOffset": 78, "endOffset": 82}, {"referenceID": 22, "context": "As a result, we are able to be robust to different noise models, and we apply our technique to these problems, which did not previously have global convergence rates: \u2013 matrix completion, in which we observe entries of A one at a time [25, 28] (Section 4.", "startOffset": 235, "endOffset": 243}, {"referenceID": 25, "context": "As a result, we are able to be robust to different noise models, and we apply our technique to these problems, which did not previously have global convergence rates: \u2013 matrix completion, in which we observe entries of A one at a time [25, 28] (Section 4.", "startOffset": 235, "endOffset": 243}, {"referenceID": 10, "context": "1), \u2013 phase retrieval, in which we observe tr(uAv) for randomly selected u, v [11, 13] (Section 4.", "startOffset": 78, "endOffset": 86}, {"referenceID": 12, "context": "1), \u2013 phase retrieval, in which we observe tr(uAv) for randomly selected u, v [11, 13] (Section 4.", "startOffset": 78, "endOffset": 86}, {"referenceID": 5, "context": "3), and \u2013 subspace tracking, in which A is a projection matrix and we observe random entries of a random vector in its column space [6] (Section 4.", "startOffset": 132, "endOffset": 135}, {"referenceID": 8, "context": "Foundational work in this space was done by Burer and Monteiro [9, 10], who analyzed the low-rank factorization of general semidefinite programs.", "startOffset": 63, "endOffset": 70}, {"referenceID": 9, "context": "Foundational work in this space was done by Burer and Monteiro [9, 10], who analyzed the low-rank factorization of general semidefinite programs.", "startOffset": 63, "endOffset": 70}, {"referenceID": 24, "context": "[27] exhibits a second-order algorithm that converges to a local solution.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "These approaches have attempted to correct for falling off the manifold using Riemannian retractions [27], geodesic steps [6], or projections back onto the manifold.", "startOffset": 101, "endOffset": 105}, {"referenceID": 5, "context": "These approaches have attempted to correct for falling off the manifold using Riemannian retractions [27], geodesic steps [6], or projections back onto the manifold.", "startOffset": 122, "endOffset": 125}, {"referenceID": 0, "context": "General non-convex manifold optimization techniques [1] tell us that first-order methods, such as SGD, will converge to a fixed point, but they provide no convergence rate to the global optimum.", "startOffset": 52, "endOffset": 55}, {"referenceID": 22, "context": "[25] study matrix completion and provides a convergence rate for an exact recovery algorithm, alternating minimization.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] provide a similar result for phase retrieval.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "A related class of algorithms that are similar to Alecton is stochastic power iteration [3].", "startOffset": 88, "endOffset": 91}, {"referenceID": 2, "context": "Stochastic power iteration has been applied to a wide variety of problems [3, 26].", "startOffset": 74, "endOffset": 81}, {"referenceID": 23, "context": "Stochastic power iteration has been applied to a wide variety of problems [3, 26].", "startOffset": 74, "endOffset": 81}, {"referenceID": 28, "context": "Oja [31] show convergence of this algorithm, but provides no rate.", "startOffset": 4, "endOffset": 8}, {"referenceID": 3, "context": "[4] analyze this problem, and state that \u201cobtaining a theoretical understanding of the stochastic power method, or of how the step size should be set, has proved elusive.", "startOffset": 0, "endOffset": 3}, {"referenceID": 32, "context": "Shamir [35] provide exponential-rate local convergence results for a stochastic power iteration algorithm for PCA.", "startOffset": 7, "endOffset": 11}, {"referenceID": 4, "context": "[5] and Hardt and Price [21] provide a global convergence rate for the stochastic power iteration algorithm.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[5] and Hardt and Price [21] provide a global convergence rate for the stochastic power iteration algorithm.", "startOffset": 24, "endOffset": 28}, {"referenceID": 24, "context": "Previous work has used manifold optimization techniques to solve such symmetric problems [27].", "startOffset": 89, "endOffset": 93}, {"referenceID": 0, "context": "[1] state that stochastic gradient descent on a manifold has the general form xk+1 = xk \u2212 \u03b1kG xk \u2207f\u0303k(xk), where Gx is the matrix such that for all u and v, uGxv = \u3008u, v\u3009x, 3", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1], this manifold has induced Riemannian metric \u3008U, V \u3009Y = tr ( UY Y V T ) .", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "We then use the optional stopping theorem [17] to bound both the probability and rate of convergence of xk, from which we derive convergence of the original algorithm.", "startOffset": 42, "endOffset": 46}, {"referenceID": 31, "context": "1 Martingale Technique A proof for Theorem 1 and full formal definitions will appear in Appendix C of this document, but since the method is nonstandard for non-convex optimization (although it has been used in Shamir [34] to show convergence for convex problems), we will outline it here.", "startOffset": 218, "endOffset": 222}, {"referenceID": 15, "context": "We show that, if neither success nor failure occurs at time k, E [\u03c4k+1|Fk] \u2265 \u03c4k (1 +R (1\u2212 \u03c4k)) (6) for some constant R; here, Fk denotes the filtration at time k, which contains all the events that have occurred up to time k [17].", "startOffset": 225, "endOffset": 229}, {"referenceID": 15, "context": "We use the optional stopping Theorem [17] (here we state a discrete-time version).", "startOffset": 37, "endOffset": 41}, {"referenceID": 11, "context": "1 Entrywise Sampling One sampling distribution that arises in many applications (most importantly, matrix completion [12]) is entrywise sampling.", "startOffset": 117, "endOffset": 121}, {"referenceID": 22, "context": "It is standard for these types of problems to introduce a matrix coherence bound [25].", "startOffset": 81, "endOffset": 85}, {"referenceID": 22, "context": "3 Trace Sampling Another common sampling distribution arises from the matrix sensing problem [25].", "startOffset": 93, "endOffset": 97}, {"referenceID": 10, "context": "(This problem has been handled for the more general complex case in [11] using Wirtinger flow.", "startOffset": 68, "endOffset": 72}, {"referenceID": 5, "context": "Consider the following distribution, which arises in subspace tracking [6].", "startOffset": 71, "endOffset": 74}, {"referenceID": 27, "context": "1 Discussion The Hogwild! algorithm [30] is a parallel, lock-free version of stochastic gradient descent that has been shown to perform similarly to sequential SGD on convex problems, while allowing for a good parallel speedup.", "startOffset": 36, "endOffset": 40}, {"referenceID": 0, "context": "References [1] P.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] Alekh Agarwal, Olivier Chapelle, Miroslav Dud\u0131\u0301k, and John Langford.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] R.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Raman Arora, Andy Cotter, and Nati Srebro.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Akshay Balsubramani, Sanjoy Dasgupta, and Yoav Freund.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Laura Balzano, Robert Nowak, and Benjamin Recht.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Lon Bottou.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Lon Bottou and Olivier Bousquet.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] Samuel Burer and Renato DC Monteiro.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Samuel Burer and Renato DC Monteiro.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] Emmanuel Cand\u00e8s, Xiaodong Li, and Mahdi Soltanolkotabi.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] Emmanuel J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] EmmanuelJ.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] Caihua Chen, Bingsheng He, and Xiaoming Yuan.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] John Duchi, Elad Hazan, and Yoram Singer.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] Thomas R Fleming and David P Harrington.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[19] Michel X.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[20] Pankaj Gupta, Ashish Goel, Jimmy Lin, Aneesh Sharma, Dong Wang, and Reza Zadeh.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[21] Moritz Hardt and Eric Price.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[22] Steven Homer and Marcus Peinado.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[23] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[24] Chonghai Hu, James T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[25] Prateek Jain, Praneeth Netrapalli, and Sujay Sanghavi.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[26] Raman Arora John Goes, Teng Zhang and Gilad Lerman.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[27] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[28] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[29] Bamdev Mishra, Gilles Meyer, Francis Bach, and Rodolphe Sepulchre.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[30] Feng Niu, Benjamin Recht, Christopher R\u00e9, and Stephen J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[31] Erkki Oja.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[32] Ian O\u2019Connell Jimmy Lin Oscar Boykin, Sam Ritchie.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[33] Benjamin Recht and Christopher R\u00e9.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[34] Ohad Shamir.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[35] Ohad Shamir.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[36] Christina Teflioudi, Faraz Makari, and Rainer Gemulla.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "Algorithm Sampling Scheme Complexity Sampling Computational Alecton Any O(\u01eb\u22121p3n log n) SVD Various o(pn) O(n3) Spectral Matrix Completion [28] Elementwise o(pn) O(p2n log n) PhaseLift [13] Phase Retrieval o(n) O(\u01eb\u22121n3) Alternating Minimization [41] Phase Retrieval o(n log(\u01eb\u22121)) O(n2 log2(\u01eb\u22121)) Wirtinger Flow [11] Phase Retrieval o(n log n) O(pn log(\u01eb\u22121)) Equivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22] minimize yAy subject to yi \u2208 {\u22121, 1}.", "startOffset": 139, "endOffset": 143}, {"referenceID": 12, "context": "Algorithm Sampling Scheme Complexity Sampling Computational Alecton Any O(\u01eb\u22121p3n log n) SVD Various o(pn) O(n3) Spectral Matrix Completion [28] Elementwise o(pn) O(p2n log n) PhaseLift [13] Phase Retrieval o(n) O(\u01eb\u22121n3) Alternating Minimization [41] Phase Retrieval o(n log(\u01eb\u22121)) O(n2 log2(\u01eb\u22121)) Wirtinger Flow [11] Phase Retrieval o(n log n) O(pn log(\u01eb\u22121)) Equivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22] minimize yAy subject to yi \u2208 {\u22121, 1}.", "startOffset": 185, "endOffset": 189}, {"referenceID": 10, "context": "Algorithm Sampling Scheme Complexity Sampling Computational Alecton Any O(\u01eb\u22121p3n log n) SVD Various o(pn) O(n3) Spectral Matrix Completion [28] Elementwise o(pn) O(p2n log n) PhaseLift [13] Phase Retrieval o(n) O(\u01eb\u22121n3) Alternating Minimization [41] Phase Retrieval o(n log(\u01eb\u22121)) O(n2 log2(\u01eb\u22121)) Wirtinger Flow [11] Phase Retrieval o(n log n) O(pn log(\u01eb\u22121)) Equivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22] minimize yAy subject to yi \u2208 {\u22121, 1}.", "startOffset": 311, "endOffset": 315}, {"referenceID": 16, "context": "Algorithm Sampling Scheme Complexity Sampling Computational Alecton Any O(\u01eb\u22121p3n log n) SVD Various o(pn) O(n3) Spectral Matrix Completion [28] Elementwise o(pn) O(p2n log n) PhaseLift [13] Phase Retrieval o(n) O(\u01eb\u22121n3) Alternating Minimization [41] Phase Retrieval o(n log(\u01eb\u22121)) O(n2 log2(\u01eb\u22121)) Wirtinger Flow [11] Phase Retrieval o(n log n) O(pn log(\u01eb\u22121)) Equivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22] minimize yAy subject to yi \u2208 {\u22121, 1}.", "startOffset": 463, "endOffset": 471}, {"referenceID": 19, "context": "Algorithm Sampling Scheme Complexity Sampling Computational Alecton Any O(\u01eb\u22121p3n log n) SVD Various o(pn) O(n3) Spectral Matrix Completion [28] Elementwise o(pn) O(p2n log n) PhaseLift [13] Phase Retrieval o(n) O(\u01eb\u22121n3) Alternating Minimization [41] Phase Retrieval o(n log(\u01eb\u22121)) O(n2 log2(\u01eb\u22121)) Wirtinger Flow [11] Phase Retrieval o(n log n) O(pn log(\u01eb\u22121)) Equivalently, if we let A denote the edge-matrix of the graph, we can represent this as a matrix problem [19, 22] minimize yAy subject to yi \u2208 {\u22121, 1}.", "startOffset": 463, "endOffset": 471}, {"referenceID": 15, "context": "1 Definitions Fleming and Harrington [17] provide the following definitions of filtration and martingale.", "startOffset": 37, "endOffset": 41}, {"referenceID": 0, "context": "\u2223 M +W [ 0 1 1 1 ]", "startOffset": 7, "endOffset": 18}, {"referenceID": 0, "context": "\u2223 M +W [ 0 1 1 1 ]", "startOffset": 7, "endOffset": 18}, {"referenceID": 0, "context": "\u2223 M +W [ 0 1 1 1 ]", "startOffset": 7, "endOffset": 18}, {"referenceID": 0, "context": "[ 0 1 1 1 ]\u22121 = [ \u22121 1 1 0 ]", "startOffset": 0, "endOffset": 11}, {"referenceID": 0, "context": "[ 0 1 1 1 ]\u22121 = [ \u22121 1 1 0 ]", "startOffset": 0, "endOffset": 11}, {"referenceID": 0, "context": "[ 0 1 1 1 ]\u22121 = [ \u22121 1 1 0 ]", "startOffset": 0, "endOffset": 11}, {"referenceID": 10, "context": "Secondary Literature [11] Emmanuel Cand\u00e8s, Xiaodong Li, and Mahdi Soltanolkotabi.", "startOffset": 21, "endOffset": 25}, {"referenceID": 12, "context": "[13] EmmanuelJ.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[28] R.", "startOffset": 0, "endOffset": 4}], "year": 2014, "abstractText": "Abstract Stochastic gradient descent (SGD) on a low-rank factorization [9] is commonly employed to speed up matrix problems including matrix completion, subspace tracking, and SDP relaxation. In this paper, we exhibit a step size scheme for SGD on a low-rank least-squares problem, and we prove that, under broad sampling conditions, our method converges globally from a random starting point within O(\u01ebn logn) steps with constant probability for constant-rank problems. Our modification of SGD relates it to stochastic power iteration. We also show experiments to illustrate the runtime and convergence of the algorithm.", "creator": "gnuplot 4.6 patchlevel 4"}}}