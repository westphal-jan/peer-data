{"id": "1411.1316", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2014", "title": "Rapid Skill Capture in a First-Person Shooter", "abstract": "friburgo Various texans aspects pasted of kristallnacht computer game criswell design, borukhova including dolling adaptive 70-man elements of aronne game levels, characteristics of ' bot ' galdos behavior, and player headley matching 313.222.2738 in 3-3-1 multiplayer 87-page games, would zhangsun ideally be easy sensitive to humps a player ' cajoled s skill level. gem\u00e4ldegalerie Yet, bianka while johnnetta difficulty and polemics player przedb\u00f3rz learning kawthaung have g\u00e4vle been novial explored objectified in the context earmarked of dinosaurios games, there has been little donelli work terblanche analyzing lemaitre skill per se, and how dunand it reinet pertains interco to a batiste player ' s input. To this eldin end, 45-16 we dzia\u0142dowo present concierge a data set of 476 game logs \u00e5str\u00f6m from over iplex 40 karolyn players of 102-story a first - hae person shooter maslow game (Red Eclipse) mayra as a 11.21 basis japs of dingdang a k\u00fcnzelsau case study. reformatting We bau then wkys analyze different prester metrics mobin of skill northumbrian and show kidspost that a-point some confrerie of montcada these chalonnaise can be predicted partridges using 49.55 only a joelle few codice seconds of unfixed keyboard andalusite and mouse knr input. We argue displacements that the askvoll techniques wyomissing used eardley here are 14,000-seat useful manilov for machold adapting games migration to match flyleaf players ' skill 2,481 levels rapidly, kalimantan perhaps petry more 22.48 rapidly than solutions snubbing based competencia on performance averaging 2:18 such self-criticism as TrueSkill.", "histories": [["v1", "Wed, 5 Nov 2014 16:41:12 GMT  (1242kb)", "https://arxiv.org/abs/1411.1316v1", "16 pages, 28 figures, journal paper submission"], ["v2", "Thu, 6 Nov 2014 13:04:25 GMT  (1437kb)", "http://arxiv.org/abs/1411.1316v2", "16 pages, 28 figures, journal paper submission"]], "COMMENTS": "16 pages, 28 figures, journal paper submission", "reviews": [], "SUBJECTS": "cs.HC cs.LG", "authors": ["david buckley", "ke chen", "joshua knowles"], "accepted": false, "id": "1411.1316"}, "pdf": {"name": "1411.1316.pdf", "metadata": {"source": "CRF", "title": "Rapid Skill Capture in a First-Person Shooter", "authors": ["David Buckley", "Ke Chen", "Joshua Knowles"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n41 1.\n13 16\nv2 [\ncs .H\nC ]\n6 N\nov 2\n01 4\nIndex Terms\u2014First-person shooter, player modeling, skill capture, skill metrics, skill prediction.\nI. INTRODUCTION\nSKILL is an important component of any recreational orcompetitive activity. Not only does it contribute to the result, the relationship between skill and difficulty of the activity affects the experience of those taking part. Players in a game, for instance, often have as little fun beating novices as they do being dominated by highly accomplished players.\nIn our research, skill is a property of a player, defined in terms of their average performance. This discounts notions of \u2018skillful\u2019 behavior other than those that aid in winning the game. The definition used here falls in line with existing skill metrics [1], [2], and allows skill to be explicitly measured.\nIf a player\u2019s skill were known before they played, their opponents could be selected in a way that would optimize their experience of the game. In competitive games, this is known as matchmaking, and is widely used in online gaming. Single player games, on the other hand, use Dynamic Difficulty Adjustment (DDA) [3], [4], where the game\u2019s difficulty is changed according to the player\u2019s progress. Left 4 Dead\u2019s AI director is an example of this in action [5].\nUnfortunately, there is currently no quick and accurate way of measuring a player\u2019s skill. Bayesian methods, such as TrueSkill [2], require several games before converging, depending on the number of players, and DDA relies on heuristic methods which are not necessarily representative of a player\u2019s skill [3]. In a domain where a single bad experience can be enough to alienate someone, two or three games can\nThis work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.\nThis work was supported by the Engineering and Physical Research Council [EP/I028099/1].\nD. Buckley, K. Chen and J. Knowles are with the School of Computer Science, University of Manchester, Manchester M13 9PL, U.K. (e-mail: david.buckley@cs.man.ac.uk; ke.chen@manchester.ac.uk; j.knowles@manchester.ac.uk).\nbe too many, so we seek to reduce this to a single game or less.\nWhereas a player\u2019s performance may depend on several factors, including their opponents, their input, e.g. mouse and key presses, is consistent over several games. It is intuitive to assume that a skilled player will interact with the controls differently to a novice [6]. Instead of relying on performance as a metric for each player, we therefore consider using their input.\nTowards this goal, we have performed a systematic study based on Red Eclipse, a first-person shooter game (FPS). Game logs were automatically recorded during the study, storing input events, some game events and a few common measures of performance. In order to understand these measures, we present a thorough analysis of them and the features extracted from the input events. Building on the success of random forests in previous work [7], we then predict the player\u2019s skill with reasonable accuracy from only 10 seconds of data (see Fig. 28).\nOur main contributions can be summarized as follows: 1) a complete data set of games containing player input and results, 2) an investigation of the data set, validating a number of skill metrics and exploring their connection to input, and 3) a model capable of predicting a player\u2019s skill from less than a single game.\nThe rest of this paper is organized as follows. After a review of previous work in Section II, the data set is described in depth in Section III. We use the techniques presented in Section IV to analyze different skill measures and player behavior in Sections V and VI. We finally present the skill prediction in Section VII, discuss the implications of this research in Section VIII, and present our concluding remarks in Section IX."}, {"heading": "II. PREVIOUS WORK", "text": "We define skill as the average level of performance over a set of games. A value of skill only holds meaning for a particular set and for a particular averaging technique. This definition does not consider concept drift or learning, and assumes skill is averaged over a reasonable length of time.\nThe definition of skill used here is distinct from the term ability defined by Parker and Fleishman [8]: \u201cAbility refers to a more general, stable trait of the individual which may facilitate performance in a variety of tasks. . . . The term skill is more specific: it is task oriented.\u201d\nPerformance is the value assigned to a person after a particular task has been completed. This value, or measure, is defined by a metric, where different metrics may yield different performance measures for the same task and the choice of metric used affects the rankings of players within a\ngame. The connection between skill and performance has been illustrated in Fig. 1, and is similar to the connection Chomsky draws between competence and performance [9].\nWe differentiate between a skill metric, which is calculated by averaging performance over time, and skill prediction, the process of predicting a skill metric using less information than that required by the metric. Thus, while the prediction may share the same unit as the metric, it is not guaranteed to produce the same ranking. Although both are considered methods of skill capture, this research assumes that a skill metric always has higher validity than a prediction."}, {"heading": "A. Performance and Skill Metrics", "text": "There are numerous ways to measure performance of a task, and each video game has its own common metrics that are used by developers or its community. StarCraft and Counter-Strike, for instance, use win-loss metrics to determine the winner, whereas players of each game use actions-per-minute and killto-death ratio respectively to compare themselves. These can, and often are, averaged to provide players with skill metrics.\nA common problem with metrics is \u2018inflation\u2019, where players change their gameplay to manipulate their performance (and consequently their skill measure), contrary to how the developers intended them to play. Combining and adjusting different metrics is done in order to encourage desired behavior [10]. The WN6 algorithm used for World of Tanks, for example, takes a variety of metrics and combines them using weightings and a series of mathematical operations to produce a single skill metric [11].\nTrueSkill, unlike the simple metrics previously mentioned, averages performance using Bayesian updating [2]. The model, which is based on the Elo rating [1], actually represents a belief in a player\u2019s skill, which can be reduced to produce a skill metric. The model uses rank as its performance metric, and can therefore cope with multiple teams of varying player sizes. The main criticisms of TrueSkill are its time to convergence, which can take several games to find a confident representation, and that values cannot be compared across different leagues [12]."}, {"heading": "B. Skill Prediction", "text": "Skill metrics have the distinct disadvantage that performance measures must be taken over a set period of time in order to determine an average. Users of the TrueSkill\nalgorithm, for instance, need to play anywhere between 3 and 100 games, depending on the number of players in each game. Skill prediction techniques seek to determine an individual\u2019s skill in significantly less time.\nKenneth Regan et al. extend a chess end-game performance metric [13] to complete chess games [14]. Using the assumption that computers can play better than humans, a player\u2019s move is compared with those of a computer to produce a prediction of the player\u2019s performance. The authors then use Bayesian averaging over several moves in order to produce a skill prediction.\nThe task of skill prediction is not limited to games, and also extends to domains such as teleoperations [15] and Human Computer Interaction (HCI) [16], [17]. The work in HCI takes advantage of a user\u2019s mouse input to predict their skill for a specific task and the system as a whole. Several useful features of the mouse are highlighted in this work, and were used for our own research. However, this work in HCI focuses on a predefined task with specific instructions that the users can learn very quickly. This contrasts with the task used in our own experiments, which is more analogous to \u2018system skill\u2019.\nWithin the domain of video games, there have been a few attempts at skill prediction, using a variety of techniques, including physiological monitoring, recording game events, and logging player input from the hardware. The first of these, monitoring physiological responses, explored skill in a fighting game [18]. The researchers distinguished between players of different skill using the performance metric \u2018success rate\u2019 when inputting commands. However, while the work provides a foundation for further research, there was a very small number of participants and little analysis of the differences between player types. Moreover, physiological data collection can be intrusive, potentially distancing players from immersion, thus changing how they play.\nAn alternative to physiological data is using information about the game and high-level game events. This sort of data is easy to collect, and useful for other methods of prediction [19]. Mahlmann et al. consider this data for predicting completion time in Tomb Raider: Underworld [20], a reasonable metric of performance for single-player games. The main focus of the paper was not on player skill, however, and the results of prediction were inconclusive.\nFinally, the most closely related research was done in the real-time strategy (RTS) game StarCraft II [21]. In this work, Tetske et al. successfully predict a player\u2019s skill level using \u2018actions\u2019, the interactions between the player and the interface, from a substantial data set. Rather than predicting a skill metric, however, the model is trained to predict the league or group of each player, making the assumption that these categories accurately indicate skill. The research also makes no use of hardware input events, which along with skill metrics, are explored in depth in our own research."}, {"heading": "III. DATA SET", "text": "To our knowledge, there does not exist a publicly available data set that specifically concerns \u2018player input\u2019: the players\u2019 input to a game through the means of hardware, e.g. a mouse\nor keyboard. This paper therefore presents a substantial data set of game logs recorded from many different players of an FPS.\nDesigned for balance and representation of different player types, the data, and how it was collected is described here. The data set, scripts for manipulating it and further information can be found on our website1."}, {"heading": "A. Red Eclipse", "text": "The test-bed for this experiment was an open-source firstperson shooter, Red Eclipse2, which is a fully-customizable, fast-paced action game that includes many common game mechanics from the FPS genre. A screenshot of the game can be seen in Fig. 2.\nWhile Red Eclipse strives to emulate traditional game mechanics, it also provides a \u2018parkour\u2019 system, which is not present in most first-person shooters. The system allows players greater freedom in moving around their environment, but adds a further level of complexity. Many players tried to use this feature, but very few used it consistently.\nThe data collected from the games were limited to logging the inputs of the player and some information about the game. A timestamped log file was constructed for each game, recording the game\u2019s settings and a selection of events, including keyboard and mouse events and some game features such as kill and damage events.\nRed Eclipse allows users to modify the game settings in order to customize their experience. This includes the type of game they play (the game mode), the arena in which they play (the map), and the difficulty of simulated enemies (bots).\nThe game mode was set to deathmatch, in which players compete to kill each other for the most points. This limited the complexity of rules and tactics used, and meant players were not dependent on the skill of their teammates. Each game was also set to three minutes; considered long enough for players to become immersed, but short enough to meet our goal of short-term skill capture.\nEight different maps were chosen in order to represent a range of playing environments. Some maps were more difficult\n1http://www.cs.man.ac.uk/\u223cbuckled8/shortterm.html 2http://www.redeclipse.net\nfor players, whereas others were harder for the bots. Six ranges of bot difficulty were used (40\u201350 to 90\u2013100) defining the minimum and maximum difficulty. From a given range, inclusive of the two limits, the engine randomly selects an integer for each bot which defines its skill for that game."}, {"heading": "B. The Log File", "text": "Although the structure of the log file was designed independently, inspiration was drawn from similar research being done at the time [22]. Each log file has a set of metadata that describes the game and a variable-length list of events. The log files, originally text-based, have been published as JSON objects. This is for flexibility and human-readability.\nEach game comes with information that describes its settings. The list of metadata can be found in Table I along with a brief description. The Client Number is set by Red Eclipse when connecting to an online game, but is always 0 in this data set. Although the bot difficulties had a larger range, they were restricted to 40 and 100 in this experiment, as difficulties lower than 40 were considered minimally different.\nTwo types of events were extracted from the game: input events and game events. Input events were further separated into key presses, mouse button presses and mouse motion. Keyboard and mouse button events contain a key identifier, the final state of the button and the action the button caused in the game. Mouse motion events have an x and y value (the number of pixels the mouse was moved), and were triggered roughly once every three milliseconds while the mouse was in motion.\nThe second category of events is a simplified summary of game events. These events, generated by the game, only concern events that happen to the player; in other words, interactions between bots is not considered. The events were chosen with the consideration of skill as a focus of the experiment."}, {"heading": "C. Data Collection", "text": "The data set was compiled from an in-house experiment. This level of control gave both consistency and reliability to the data set. It also allowed the experimenters to ensure the data set remained balanced throughout.\nAlthough the terms participant and player can be used interchangeably, we have attempted to attribute participant to the context of the experiment, and player to the context of the game.\nThe overall format for the experiment is presented in Fig. 3. Each participant started by completed a demographic questionnaire at the start. They were then presented with a written tutorial and given as much time as they needed to read through it. This included a summary of general firstperson shooter mechanics and more specific details about Red Eclipse. Participants were allowed to ask questions at any point through the experiment or refer back to the tutorial, but the experimenter did not provide information voluntarily.\nThe main part of the experiment was split into \u2018sessions\u2019, where a single session consists of a pair of games and a respective set of questionnaires, as in Fig. 3. A participant\nTABLE I THE META DATA FOR EACH GAME.\nName Description Example\nGame ID A unique identifier for the game. 127\nPlayer ID A unique identifier for the current player. 26\nClient Number The number assigned to the player by the game. 0\nGame Number From the set of games played by one player, the position this game appears (starting from 0). 5\nMap Name The name of the map that was selected for this game. wet\nBot Min Each bot\u2019s difficulty is chosen randomly from between Bot Min and Bot Max. Possible values range from 0 to 101.\n60\nBot Max 70\nConnect time The time the user connected to the game (ms). 1\nDisconnect time The time the game ended (ms). 185010\nScoreboard The final scoreboard for the game, including number of points and kills for each player (given by their client number). 0: \u2019points\u2019: 8, \u2019kills\u2019: 3 ...\nDate & time The date the game was played and the time it started. 2013-02-26, 14:40:54\nconsent demographic tutorial game A likert A game B likert B 4-AFC\nSESSION\nFig. 3. The overall format of the experiment.\nwas allowed to complete as many sessions as they wanted. After each game, the participant answered questions about their experience, and at the end of each session, the participant would compare the two experiences. The questionnaires are described in the next section.\nAll participants used the same keyboard and mouse, and a headset was provided to wear at their discretion. The researcher was present in the room throughout the experiment to guide participants through the process and answer any questions. On three occasions, the researcher had to intervene to ensure participants followed procedure. For each of these games, there is roughly an 18s gap of missing game data. These games are highlighted on the website.\nFinally, it is worth noting that the data, while only spanning a few weeks, is separated by several months. After the initial study [7], a further period of data collection was held in order to improve on existing problems with the data set. In particular, the second period was designed to correct imbalances of content, increase the overall number of games, and increase the number of games per player. From all 45 participants, 14 took part exclusively in the first period, 11 in the second and 20 took part in both periods."}, {"heading": "D. Questionnaires", "text": "There were three different questionnaires used in total throughout the experiment: a demographic questionnaire, an experience-based questionnaire using the Likert scale [23], and an experience-based questionnaire using 4 Alternative Forced Choice (4-AFC) [24].\nThe demographic questionnaire was presented to participants before they started. This questionnaire gleaned information such as age, gender and, most notably, two self-reported\nmeasures of skill. The first measure, how many hours the participant plays per week, is a common question in research [25], [26]. The second, the number of first-person shooters played, was conceived in order to discount the effect of other genres, and account for the player\u2019s entire gaming experience, rather than playing habits. These questions were designed to be objective and avoid self-assessment, which players are notoriously poor at [27].\nThe two experience-based questionnaires used the same questions in two different forms. The first was Likert, to allow the participant to rate each game separately, and the second 4-AFC, comparing the last two games. There are advantages and disadvantages to each method, which are discussed more thoroughly in [28]. Each of these questionnaires had four questions concerning the fun, the frustration, the challenge and the player\u2019s impression of the map. The first three questions have been used previously with some degree of success [19], [29]. In our research, the Likert questionnaire was worded as follows:\n\u2022 How much would you want to keep playing the game? \u2022 How frustrating did you find the game? \u2022 How challenging did you find the game? \u2022 How lost did you feel while playing the map?\nThe first question, regarding fun, was chosen to allow players to question their current state of feeling, rather than remembering how they felt during the game. This was to mitigate the effects of memory on self-reported affect [30]."}, {"heading": "E. Data Distribution", "text": "The complete data set consists of 476 games from 45 participants. The range of number of games played varied from 4 to 22, and has been visualized in Fig. 4.\nAs player skill was the main focus of this research, some effort went towards ensuring balance. This was validated using the number of FPSs played (f ), which was found to be a better indicator of the two self-reported measures. Even though there was an overall imbalance of players according to this metric, the distribution of the original population was unknown, and the range of different skills was considered acceptable.\nThe map and bot difficulties were selected independently and uniformly at random, adjusted by the experimenter to ensure players did not have a biased experience of the game. The distribution of maps over players is also represented in Fig. 4, while the maps and bot difficulties played for each skill group is shown in Fig. 5 and Fig. 6 respectively.\nFrom a preliminary analysis of the first period of data, average player skill leveled out near the 6th game (more detail is provided in Section V). For this study, we therefore discarded players with fewer than 8 games and ignored games played after the 16th, in order to minimize bias. This selection of data (430 games from 37 players) is highlighted in Fig. 4 and has been used throughout the rest of this paper."}, {"heading": "IV. METHODS", "text": "This section reviews the existing measures and algorithms that are used in our experiments. For our analysis of the skill metrics in Section V, we present the details of the TrueSkill\nalgorithm, and discuss some methods for evaluating similar skill metrics. Next, we introduce some techniques used to extract features from the players\u2019 input which are used in Section VI. Finally, we present the random forest algorithm used to predict skill in Section VII."}, {"heading": "A. The TrueSkill Algorithm", "text": "TrueSkill is a widely used measure of skill in commercial games, used primarily for matchmaking, and hence serves as an important benchmark for other methods presented in this paper. The algorithm assigns unitless values, \u00b5 and \u03c3, to players, which represent the algorithm\u2019s belief in the player\u2019s skill. The first value, \u00b5, is the current estimate, and \u03c3 is the confidence in that estimate. Together, the two values represent a normal distribution of skill.\nWhen two players compete, the two normal distributions can be combined to indicate the probability of a draw (the prior). After the game, the result (the likelihood), can be used to update the model\u2019s belief in both players. If a player, Alice (\u00b5a, \u03c3a), beats Bob (\u00b5b, \u03c3b), \u00b5a would increase, \u00b5b would decrease, and both values of \u03c3 would decrease according to the following formulas:\n\u00b5winner \u2190 \u00b5winner + \u03c32winner\nc \u00b7 V,\n\u00b5loser \u2190 \u00b5loser \u2212 \u03c32loser c \u00b7 V,\n\u03c32winner \u2190 \u03c32winner \u00b7 (1\u2212 \u03c32winner\nc2 \u00b7W ),\n\u03c32loser \u2190 \u03c32loser \u00b7 (1\u2212 \u03c32loser c2 \u00b7W ),\nwhere\nc2 = 2\u03b22 + \u03c32winner + \u03c3 2 loser , V = v( \u00b5winner \u2212 \u00b5loser\nc , \u03b5 c ),\nW = w( \u00b5winner \u2212 \u00b5loser\nc , \u03b5 c ).\nThe functions, v and w, dictate the update for \u00b5 and \u03c3 respectively. This only leaves \u03b5, the probability of a draw, and \u03b22, which is a player\u2019s performance variance. The more the performance of the players varies, the slower the values will update. A more thorough description of the workings of TrueSkill can be found in [31].\nThe two values \u00b5 and \u03c3 are usually combined to produce an ordinal value which can be used to rank players. A conservative estimate is usually used, and is given as \u00b5\u22123\u2217\u03c3 in this research."}, {"heading": "B. Evaluating Skill Metrics", "text": "In classification problems, it is common to evaluate the model using its testing accuracy (or error rate). There are also other measures and techniques for helping to understand the model\u2019s performance. Within regression (predicting a continuous measure), the proportion of explained variance (R2) is a common evaluation criteria. This measure and others, including relative absolute error (RAE) [20], punish offset results and those suffering from scaling effects. The values we are comparing, however, are skill measures; measures which are ultimately used for ranking players. We therefore use Spearman\u2019s rank correlation coefficient (Spearman\u2019s \u03c1) to evaluate our models. This has the added advantage that the ranking of two different skill measures can be compared. Spearman\u2019s \u03c1 is defined as the Pearson correlation coefficient [32] between two ranked variables.\nIn some instances we have multiple groups of players and need to determine whether the groups are significantly different. For this situation, where the skill metrics are nonparametric, unlike a t-test, and the measures are independent, in contrast with the Wilcoxon signed-rank test, the Mann\u2013 Whitney U test is suitable [33]. In particular, given two groups of players, we can use this test to determine whether one group is statistically more skilled than the other, given different significance levels, \u03b1."}, {"heading": "C. Complexity of Hardware Input", "text": "A reasonable hypothesis is that skilled players use controls in a more complex way than novices. We therefore use a number of techniques to measure this complexity\u2014some for compression of a sequence and others for analysis on a timeseries. These techniques are used to extract features which are then used in Sections VI and VII.\nThe first two, Lempel-Ziv-Welch (LZW) [34] and Huffman coding, can all be used for compression of data. Simple, or more predictable data, should be easier to compress, allowing these to be used to measure complexity. The first, LZW, has\nthe advantage of being simple to implement. The algorithm is as follows:\n1) Initialize a dictionary with single-character strings. 2) Find the next longest string, W , in the dictionary. 3) Replace W with the dictionary index. 4) Add (W + next character) to the dictionary. 5) Go to Step 2.\nThe second algorithm, designed by Huffman [35], constructs a Huffman tree based on probability distributions. Common characters are given smaller codes and placed towards the left of the tree. Encoding involves replacing characters with codes from the tree. If the population distribution of the characters is known, Huffman encoding is close to the theoretical minimum.\nIn addition to the compression techniques above, two measures of entropy are used: Shannon entropy and sample entropy. The first measures the amount of information in a given sequence:\nH(X) = \u2212 \u2211\ni\nP (xi) logP (xi).\nThe second measure, sample entropy, based on approximate entropy [36], is performed on continuous data and was originally designed for physiological time-series. Independent of data length, it is potentially useful in understanding the complexity of either mouse or keyboard input.\nThe final complexity measure used was a discrete Fourier transform [37]. This method reveals regularities in the data and relative strengths of periodic components. Assuming complexities vary with skill, it would be interesting to see how the frequencies of the mouse input compare between users."}, {"heading": "D. Prediction Using Random Forests", "text": "There are several techniques that could be used for predicting player skill. Previous research [21], [38] successfully used SMO (Sequential Minimal Optimization), an algorithm for support vector machines [39]. However, random forests [40] were chosen for their ability to generalize well, even with a large number of features with unknown properties. A random forest also has the added advantage of being a \u2018gray box\u2019, in that it can be used with little knowledge of its internal mechanics, but can tell us which features were the most import during training. Finally, a random forest model can be trained for each classification or regression, which can accommodate the different shapes and sizes of skill metrics.\nRandom forests are an ensemble method that train several trees on different subsets of the data. The MATLAB implementation used was an interface to the R implementation by Andy Liaw et al. [41]. Two settings are used during training this model. The first, ntree, dictates how many trees to use. This was left on its default setting of 500 for all the given experiments. The second setting, mtry, determines how many features are sampled from when a tree is split. This variable was also left on its default setting, \u230a \u221a D\u230b, where D is the total number of features."}, {"heading": "V. ANALYSIS OF SKILL METRICS", "text": "Any research in player skill requires an understanding of the metrics used, yet there is no gold standard for measuring skill. In order to better understand how we evaluate skill, this section presents an analysis of a number of skill metrics based on our data set. For reference, these skill metrics and their notations are summarized in Table II. Although not a complete analysis, this section demonstrates how skill metrics should be understood before any analysis or prediction of skill."}, {"heading": "A. Rank", "text": "The winner of any game is given by a single performance metric. For chess, this is a simple win-loss-draw state. Many games use rank (r), where r = 1 is the winner, r = 2 indicates second place, and so on. r is used in the TrueSkill algorithm, and is a descriptive win-loss value for games with multiple players or teams.\nRank is the value that defines performance for a single game. That makes it a logical metric to use. Although large differences in skill are ignored by r, it may be less easily affected by content (a win on one map will have the same value as a win on a different map). However, r is still defined by the number of players on a map, and the continuum of values is limited by it. This makes it more difficult to distinguish between two players with high performance.\nIn our research, skill is measured over the whole task and should therefore be independent of content and difficulty. However, r, as a performance metric, is dependent on both map, seen in Fig. 7, and difficulty, Fig. 8. There are two methods for averaging rank used in this paper. The first uses Bayesian updating (TrueSkill), and is discussed later. The second is obtained by taking the mean r over a player\u2019s games, producing a continuous metric, player rank (r\u0304)."}, {"heading": "B. Score", "text": "In order to work out the ranking of players, games often use an alternative performance measure. Racing games, for example, commonly use time. The primary goal of a deathmatch (the task in this experiment) is to accrue points. Points are accumulated by killing other players, with extra points\nawarded for \u2018skillful\u2019 behavior such as assisting other players. At the end of the game, each player\u2019s rank is worked out from the number of points they have: their score (s). Similar scoring systems are used in other first-person shooters.\nIt is important to note that score can only be used as a performance metric because rank is based on it. For a different game mode or genre, a different metric should be used. Team Fortress 2, for example, keeps a score for each player; however, as these values do not directly influence the result of the game, it is meaningless as a performance metric.\nThe main advantage of s over r is that s has a much larger range of values, and is therefore more descriptive. A larger value of s, for instance, may imply an easier victory. On the other hand, s, like r, is dependent on content and difficulty, as seen in Fig. 9 and Fig. 10. The maps Foundation and Ubik are worth noting when comparing the two measures. For\nFoundation, players tend to perform well using the performance metric s, but, on average, rank low. This demonstrates instances where s is inflated by content. Conversely, Ubik was a particularly hard map for players according to s. However, bots found it more difficult, resulting in higher ranks in Fig. 7.\nAs with r, a skill metric, player score (s\u0304) was produced using the mean of s over all games played by a player. The s and s\u0304 values for each player is presented in Fig. 11, illustrating the outlying values of s for individuals that are accommodated for in s\u0304. We were confident that some players had played enough games to obtain a reasonable skill metric, but the specific number of games required was unknown. Fig. 12 shows that after playing between 5 and 7 games, s\u0304 starts to stabilize. The large increase in Spearman\u2019s \u03c1 between games 7 and 8 is because some players had only played 8 games.\nUsing s\u0304, the players were separated into four bins defined in Table III. The limits of these groups were chosen so that there was a roughly equal number of participants in each group.\nThese groups have been used throughout this research as a substitute for s\u0304 where groups of skill are more appropriate. A directional Mann\u2013Whitney U test confirms that the groups are statistically different with a significance level of \u03b1 = 0.005."}, {"heading": "C. TrueSkill Estimate", "text": "TrueSkill is designed for multiplayer leagues, where a TrueSkill model for one player interacts with other TrueSkill models for other opponents. Unfortunately, participants in our experiment never played against each other, but against bots.\nIn order to account for this, a slight adaptation was made to the TrueSkill algorithm.\nFor each game, the opponents (bots) were selected randomly from a predefined range, b. As we did not know the precise difficulty of each bot, we assigned a \u00b5b and \u03c3b value to the whole range, b; in other words, every bot in range b had the same \u00b5b and \u03c3b values. To calculate final \u00b5b and \u03c3b values, the TrueSkill algorithm was run over randomly selected games, updating \u00b5b and \u03c3b with the average posteriors, \u00b5 and \u03c3 from all bots. With these final \u00b5b and \u03c3b values, the TrueSkill algorithm was run as normal to calculate player TrueSkill values \u00b5p and \u03c3p.\nTypically, a conservative estimate of skill is used for ranking: \u00b5\u2212k\u2217\u03c3. In this research, k is set to 3, i.e. T = \u00b5\u22123\u2217\u03c3. The average T (TrueSkill estimate) value for each score group over time can be seen in Fig. 13. The dotted lines indicate the T values for different bot ranges.\nTo our knowledge, the TrueSkill algorithm has not been applied to single-player content before, or to simulated multiplayer, where players compete against bots. Although Fig. 14 shows that T generally agrees with both metrics, r\u0304 and s\u0304, we do not know how valid this method is. It may also be that T values for players, some of whom played as few as 8 games, did not fully converge. In addition, s\u0304 discriminates between the higher-end players (T > 25) more effectively than T or r\u0304."}, {"heading": "D. Self-Reported Measures", "text": "Asking players about their gaming experience is common in related research [26]. It can serve to put research into context, and is very easy to collect. In commercial games, players are commonly asked to select a difficulty setting. However, players are poor estimators of their own skill [27]. This research therefore explores two objective criteria for reporting player experience, hours played (h) and FPSs played (f ).\nThe number of hours that someone plays games for may be indicative of playing behavior. It may not, however, relate well to skill. Fig. 15 illustrates how this value compares with\na performance measure, s, and a skill measure, s\u0304. In addition to the low correlation between the groups (Table IV), there is significant overlap of skill between the groups, and some players from h = 2\u20135 have a higher score than those in higher skill categories. Indeed, using a directional Mann\u2013Whitney U test with a significance level of \u03b1 = 0.025, there was not sufficient evidence to state that any group was statistically greater than its previous group. There were, however, not enough players for the pair of groups h = 5\u201310 and h = 10+ to make any conclusions.\nThe second metric, f , consists of 5 categories and attempts to take into account the user\u2019s entire gaming history and exclude time spent playing other genres of game, such as role-playing games. Again, a comparison between f and s\u0304 is shown in Fig. 16. Although more closely correlated to skill, there were a few players in the second category, f = 1 or 2, who had more experience than could be described by this measure. As done with h, a directional Mann\u2013Whitney U test\nwas performed between each adjacent measure. There were not enough players for the pair f = Never and f = 1 or 2. Between the other pairs, only f = 5\u201310 was found to be greater than its predecessor, f = 2\u20135 with a significance level of \u03b1 = 0.005."}, {"heading": "E. Community Measures", "text": "The gaming community will often use game statistics to evaluate and compare players. These are designed to give a better understanding of each player\u2019s strengths and weaknesses, but are often specific to the game genre they are used for, such as actions-per-minute in StarCraft.\nKill-to-death ratio (k), often abbreviated KDR, and accuracy (a) are two performance measures that are specific to firstperson shooters. The first, k, represents the number of kills the player made against the number of times they were killed themselves. The second, a, is the hit ratio of the player; the number of times they hit opponents versus the number of shots they fired. Player averages have been calculated for both of these values, k\u0304 and a\u0304 respectively. A third measure, average number of deaths for a player (d\u0304), has been included in Table IV for comparison.\nThe relationship between a\u0304 and s\u0304 has been visualized in Fig. 17. It can be seen from this graph that although greater skill may imply greater accuracy, there is less difference of accuracy between the more skilled players. This may imply that accuracy is an ability more quickly mastered. However, the correlation between a\u0304 and s\u0304 is too low to make concrete conclusions about their relationship for so few players.\nIn summary, the three skill metrics s\u0304, r\u0304 and T rank players very similarly. The two self-reported measures, f and h, on the other hand, were found to be insufficient for our purposes. Equally, the community-based metrics, k\u0304 and a\u0304, may describe skill given a different task, but, for this experiment, are more likely to describe play style. Given that T is only an estimate of TrueSkill, s\u0304, as the more descriptive of the three metrics, is used for the rest of this paper."}, {"heading": "VI. PLAYER INPUT FEATURE ANALYSIS", "text": "Using the methods presented in Section IV and previous work [17], 174 global features were extracted from the keyboard and mouse events of each game3. These features are grouped and analyzed in this section in order to better understand player input and how it relates to skill.\nThree different schemes, summarized in Table V, were used to group the features. By grouping these features, we can start to see how different types of player input are affected by skill. While the groups of each scheme were designed to be mutually exclusive, some features could not be categorized, so are left ungrouped, and were not used in analysis."}, {"heading": "A. Hardware: Keyboard, Mouse Movement and Clicks", "text": "The first set of groups separates features according to which input device generated the events. As one of the first obstacles to playing a game, use of the input devices is likely to contribute to skill. In addition, different types of games may have different dependencies on each of the devices.\nThe features extracted from the Keyboard events concerned the complexity of the input or the frequency with which they\n3The complete list of features and their associated groups can be found on the website.\nFig. 18. Pearson correlation coefficient for each feature to player score (s\u0304), grouped by feature group and ordered by correlation. Dotted lines indicate correlation of \u00b10.6.\nwere pressed. Some of these features were based specifically on the movement keys, which allow the player to move around. A number of mouse movement events have already been used in related HCI research [17], and these formed the basis for the Mouse features. Mouse Clicks, having been used less in the literature and far more simple in nature, had the fewest features. One set of features was created using knowledge of both mouse and keyboard and, as such, did not fall into one single category. These were ignored for this particular grouping.\nThe Pearson correlation coefficient was calculated for each feature with respect to s\u0304, chosen as a major index of skill, and presented in Fig. 18, grouped by feature group. The number of these with a strong correlation (defined here as 0.6, slightly greater than that suggested in previous work [43]) has been summarized in Fig. 19. Although Keyboard contains the most features, it was also one of the more interesting groups, as most features were correlated in some way. The Mouse group, on the other hand, correlated significantly less with skill overall. This contrasts previous work in HCI, in which mouse features played a key role [17]. Clicks were also generally uncorrelated to skill, the most interesting being the LZW complexity of a player\u2019s clicks, with a correlation of only 0.418.\nFig. 19. Number of features strongly correlated to player score (s\u0304) for each feature group."}, {"heading": "B. Type: Event Frequency, Complexity and Kinetics", "text": "The second grouping scheme is slightly less obvious, in that features are grouped according to what type of input they describe. Some features, for instance, describe the kinetic motion of the mouse, whereas others describe how complex a user\u2019s input was (according to the algorithms presented in Section IV). These groups allow us to see what types of player input are most relevant to skill. Unfortunately, there were 49 ungrouped features which did not fall into any of the three groups within this category.\nThere were a number of Complexity-based features that correlated to skill. In particular, these described how complex a player\u2019s keyboard input was. For example, the LZW complexity of the four movement keys (forward, left, right and back) correlates highly with skill (Pearson\u2019s r = 0.799). Skilled players had a higher LZW value, implying their skill is more complex according to the LZW algorithm.\nThe Kinetics group was much smaller than its counterparts. The most interesting features, corresponding to r \u2248 0.48, include the number of times the player changed the x-direction of the mouse and the average angle of change in a player\u2019s movement.\nEvent Frequency described how often a player generated events with the input devices. Several features of this group\ncorrelated well with skill, as illustrated in Fig. 19. In general, the higher a player\u2019s skill, the greater the number of presses, and the longer each key was pressed."}, {"heading": "C. Context: Free and Dependent", "text": "In an ideal scenario, data collection could be done independently of each game. By splitting the features into those that require some prior knowledge about the game (e.g. the user pressed a key that moves the player forward), and those that do not (e.g. the user pressed the \u2018w\u2019 key), we start to understand how independent the features are from the game. This category had the most balanced grouping out of each set. The Dependent group comes out on top, as seen in Fig. 19. This was expected, given that this group was allowed to know more about the game. On the other hand, features extracted from the keyboard without knowing anything about the game still contained some information about skill. The length of time any two keys were pressed at once, for instance, had a correlation to s\u0304 of 0.780.\nHaving found the strongest correlations for each of the groups, we identified 6 distinct types of correlation, which are presented in Fig. 20."}, {"heading": "D. Player Learning", "text": "The cumulative average score for each score group has been presented in Fig. 21. There is a notable increase in average performance over the first few games for groups Skilled and Expert which is less visible in the other two groups. Given that only one person had played Red Eclipse before, this is consistent with previous research that found skilled players learned faster [44].\nSelecting a feature that was particularly highly correlated with player score (the average number of keys pressed at once), we plot the cumulative average value for this over successive games in Fig. 22, again grouping by score group. In contrast to Fig. 21, there is much less variation in value over several games. This suggests the feature values extracted from the input are more stable than performance metrics."}, {"heading": "VII. SKILL PREDICTION", "text": "This section presents how a player\u2019s skill can be predicted from their input to a game. The experiments presented include predicting different classes of skill, predicting continuous skill measures and finally attempting to learn from smaller sections of gameplay. Each experiment used the random forests presented in Section IV, and used 5-fold cross-validation."}, {"heading": "A. Predicting a Skill Category", "text": "Categories of player can be used to get a general idea of how skillful players are. StarCraft, for instance, groups players into leagues, where players in the same league are generally comparable in skill [21]. The score groups introduced in Section V are therefore used to construct a classification model.\nThe average accuracy for such a model trained on the different feature groups is presented in Fig. 23. An average accuracy of 77.1% is achieved by training on Keyboard features,\nsignificantly higher than the majority class baseline of 27.4%. The confusion matrix of this model is given in Table VI, and shows that many mistakes (77.1% of all misclassifications) are in neighboring classes. The Intermediate group was, however, the most difficult to predict.\nFor some applications, it is often sufficient to be able to distinguish between two kinds of players: those who have never played before, and those who have. For this binary classification, we split the data into two groups: Novice and all others. As shown in Fig. 24, the Context-Free group achieves an accuracy of 94.9%, whereas the worst group, Mouse, performed at 86.2%."}, {"heading": "B. Predicting Skill Measures", "text": "Most metrics of skill use a continuous measure, allowing detailed comparisons between different players. A regression model would allow these continuous values to be predicted for each player, but has not been studied in the literature as thoroughly. Predicted values are represented in this research with a hat (e.g. \u02c6\u0304s is the prediction of s\u0304).\nWe constructed several models to predict s\u0304 using different feature groups, measuring the performance for each model using Spearman\u2019s \u03c1. The performances for these models are summarized in Fig. 25. The comparative baseline for this experiment is to use the player\u2019s performance, s (which can be collected after one game), as a substitute for the skill measure,\ns\u0304. s\u0304 is successfully predicted with \u03c1 = 87.4, notably higher than s, which has a correlation of only \u03c1 = 67.3.\nWe visualized the average predicted values of player score (s\u0304) and player KDR (k\u0304) for each game (\u02c6\u0304s and \u02c6\u0304k) in Fig. 26. It is clear that the two models agree with each. It also clusters the games into three groups, around \u02c6\u0304s < 19 and \u02c6\u0304s > 27. From this graph, it seems particularly difficult for the model to distinguish between the two highest skilled groups. It may be that the clusters created here related to both skill and player style [6]."}, {"heading": "C. Prediction Convergence Rate", "text": "The features used up to this point were all extracted from the entire three minutes of gameplay. However, in order to explore how soon a player\u2019s skill could be predicted, the same features were extracted from smaller segments of the game. In addition to the full 180 s segment already used, data was extracted from the first t s of the game, where several values\nof t were selected from between 1 s and 120 s. Splitting the players into two roughly equally-sized groups, Novice and Intermediate players in one group, the Skilled and Expert players in the other, we trained the model on the different segment sizes. The result of this is presented in Fig. 27 and compared to a model trained using score (s) as a feature. We performed the same test for a regression model, predicting s\u0304 for each segment of the game. The performance of this is compared to how well the current score correlates to s\u0304 in Fig. 28. Not only are the input-based models more accurate than their baselines, they start to converge in a very short time (e.g. t = 10 s)."}, {"heading": "VIII. DISCUSSION", "text": "This section will discuss the implications and limitations of each contribution in turn, and finally outline future work that this research leaves open.\nOur data set, presented in detail in Section III, is potentially useful to anyone delving into player input, particularly where\ntwo distinct input devices are required. Although our research did not offer promising results with regards to mouse input, it may be that there still exist features of mouse input that can describe a player, their style, or even their skill level. Some information about game events is also available, although limited with regards to enemies and player positions. The player experience feedback has also been left unexplored, leaving open an entirely different subject of research. The biggest limitation with this data set, one that directly affects this research, is the lack of expert players for this specific game. In the real world, expert players have more experience than those that took part in our experiment. There are also too few games per player to make adequate conclusions about learning or to explore how metrics change over time.\nTo our knowledge, skill metrics have not been analyzed in this way before. Section V therefore provides a framework and baseline for comparing skill measures in other games. We explored two player-reported metrics (f and h) and showed that they were inappropriate for analysis of skill. Finally, the Bayesian-averaged T values, while estimates, were shown to correlate well with other skill metrics. This may indicate that similar methods can be applied to single-player games to measure skill or difficulty.\nDuring our analysis of the features, we found that the keyboard was the most descriptive input device of skill. The mouse features, on the other hand, was very weakly correlated to player skill. While useful in previous research [17], it may simply be too random for use in this application4. We also showed that even though knowledge of the game was preferred when extracting features, there were features that correlated with skill which required no knowledge of the game. Using this, models based on a game-independent approach may be implemented externally to a game. On the other hand, the features extracted were limited to input features. As such, the predictive models may be limited to predicting skill at using\n4Any findings in this research are limited to the types of features extracted. There may yet be other features of mouse movement that correlate well with skill.\nthe input, or mechanical dexterity, discounting other aspects of skill.\nThere are several key differences between the prediction done in this research and that in previous work [7], [21]. The first is the prior analysis of the skill metrics, which lends more credence to the results. Secondly, we showed that skill metrics such as average score (s\u0304) could be predicted relatively accurately\u2014more so than using a performance metric. And finally, this could be achieved after only a few seconds of gameplay. Using this model, matchmaking algorithms could initialize skill values for players, and then switch to another slower, but more reliable, model after a few games.\nWe defined our task as the average skill at deathmatch over a preselected number of maps. This meant that our \u2018ground truth\u2019 was the average position of the player compared to other players, r\u0304. If the task changed, however, to a different game mode, or to a different game, the ground truth would undoubtedly change, and as such, the meanings of each of these skill measures. In addition, although each player in our data set experienced a well-balanced proportion of content, traditional games may offer more content to the player, and a player may have a preference for particular maps, skewing a metric such as s\u0304. As such, the different averaging techniques should be compared to account for differences in content.\nThe most obvious next step with this research is to show how these techniques can be applied. An obvious example, as already mentioned, is matchmaking. Would using a rapid model presented here help improve matchings over the first few games in a matchmaking system? And similarly, in singleplayer games, can a rapid model reliably select the difficulty for players, removing the need for players to learn what the developer means by \u2018normal\u2019 or \u2018hard\u2019?\nMany of the features we collected are relevant to all PCbased first-person shooters. Two possible extensions on this work are either generalizing to other games in the genre or attempting to predict skill on console devices. Difficulties may start to arise with the former when a game\u2019s pace changes. The Counter-Strike series, for example, are much slower paced than Red Eclipse, and Team Fortress 2 lets players compete as different classes, each with different styles of play. Console games, on the other hand, control player movement using analogue sticks, which may require completely different types of features."}, {"heading": "IX. CONCLUSIONS", "text": "This research has provided a strong foundation for skill capture in video games by presenting some methods for understanding metrics used. More specifically, we demonstrated that skill could be predicted reliably after only 10s of gameplay (see Fig. 28).\nThe applications for this research can be directly applied to matchmaking and DDA systems, potentially improving player satisfaction in the short-term. However, the models will need to be further refined or adapted when applied to other domains or when using different input devices. The area of research that we intend to explore next is skill capture in singleplayer games, applying the same methods presented here, and showing how they can be used to improve DDA."}], "references": [{"title": "The Rating of Chessplayers", "author": ["A. Elo"], "venue": "Past and Present. Arco,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1972}, {"title": "TrueSkill(TM): A Bayesian skill rating system", "author": ["R. Herbrich", "T. Minka", "T. Graepel"], "venue": "Advances in Neural Informat. Process. Syst., vol. 20, pp. 569\u2013576, Jan. 2007.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Extending reinforcement learning to provide dynamic game balancing", "author": ["G. Andrade", "G. Ramalho", "H. Santana", "V. Corruble"], "venue": "Proc. IJCAI Workshop Reasoning, Representation and Learning in Computer Games, Jul. 2005, pp. 7\u201312.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "Dynamic game difficulty scaling using adaptive behavior-based AI", "author": ["C.H. Tan", "K.C. Tan", "A. Tay"], "venue": "IEEE Trans. Comput. Intell. AI in Games, vol. 3, pp. 289\u2013301, 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "The AI systems of Left 4 Dead", "author": ["M. Booth"], "venue": "Keynote, Fifth Artificial Intelligence and Interactive Digital Entertainment Conference (AIIDE\u201909), Stanford, CA, Oct. 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Unsupervised modeling of player style with LDA", "author": ["J. Gow", "R. Baumgarten", "P. Cairns", "S. Colton", "P. Miller"], "venue": "IEEE Trans. Comput. Intell. AI in Games, vol. 4, no. 3, pp. 152\u2013166, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Predicting skill from gameplay input to a first-person shooter", "author": ["D. Buckley", "K. Chen", "J. Knowles"], "venue": "Proc. IEEE Conf. Comput. Intell. Games (CIG\u201913), Aug. 2013, pp. 105\u2013112.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Ability Factors and Component Performance Measures as Predictors of Complex Tracking Behavior, ser", "author": ["J.F. Parker", "E.A. Fleishman"], "venue": "Psychological monographs : general and applied. American Psychological Association,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1961}, {"title": "Aspects of the theory of syntax", "author": ["N. Chomsky"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1965}, {"title": "Predicting dominance rankings for score-based games", "author": ["S. Samothrakis", "D. Perez", "P. Rohlfshagen", "S. Lucas"], "venue": "IEEE Trans. Comput. Intell. AI in Games, 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "TrueSkill through time: Revisiting the history of chess", "author": ["P. Dangauthier", "R. Herbrich", "T. Minka", "T. Graepel"], "venue": "Advances in Neural Information Processing Systems 20. MIT Press, 2008, pp. 931\u2013938. [Online]. Available: http://research.microsoft.com/apps/pubs/default.aspx?id=74417", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Gentlemen, stop your engines!", "author": ["G.M. Haworth"], "venue": "ICGA Journal,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Skill rating by Bayesian inference", "author": ["G. Di Fatta", "G. Haworth", "K.W. Regan"], "venue": "IEEE Symp. Comput. Intell. Data Mining (CIDM\u201909), Mar. 2009, pp. 89\u201394.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Towards human-robot coordination: skill modeling and transferring via hidden markov model", "author": ["Y. Xu", "J. Yang"], "venue": "Proc. IEEE Conf. Robotics and Automation, vol. 2, May 1995, pp. 1906\u20131911.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1995}, {"title": "Dynamic detection of novice vs. skilled use without a task model", "author": ["A. Hurst", "S.E. Hudson", "J. Mankoff"], "venue": "Proc. SIGCHI Conf. Hum. Factors Comput. Syst. (CHI\u201907), ser. CHI, New York, NY, USA, 2007, pp. 271\u2013280.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Automatic detection of users\u2019 skill levels using high-frequency user interface events", "author": ["A. Ghazarian", "S. Noorhosseini"], "venue": "User Modeling and User-Adapted Interaction, vol. 20, no. 2, pp. 109\u2013146, 2010.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Fighting game skill evaluation method using surface EMG signal", "author": ["T. Taneichi", "M. Toda"], "venue": "IEEE Conf. Consumer Electronics (GCCE\u201912), Oct. 2012, pp. 106\u2013107.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Modeling player experience for content creation", "author": ["C. Pedersen", "J. Togelius", "G.N. Yannakakis"], "venue": "IEEE Trans. Comput. Intell. AI in Games, vol. 2, pp. 54\u201367, Mar. 2010.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Predicting player behavior in Tomb Raider: Underworld", "author": ["T. Mahlmann", "A. Drachen", "J. Togelius", "A. Canossa", "G.N. Yannakakis"], "venue": "Proc. IEEE Symp. Comput. Intell. Games (CIG\u201910), 2010, pp. 178\u2013185.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Player skill modeling in Starcraft II", "author": ["T. Avontuur", "P. Spronck", "M. van Zaanen"], "venue": "AAAI Conf. AI Interactive Digit. Entertainment, 2013.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Understanding users in the wild", "author": ["A. Apaolaza", "S. Harper", "C. Jay"], "venue": "Proc. International Cross-Disciplinary Conf. Web Accessibility (W4A\u201913), ser. W4A \u201913. New York, NY, USA: ACM, 2013, pp. 13:1\u2013 13:4.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "A Technique for the Measurement of Attitudes, ser", "author": ["R. Likert"], "venue": "Archives of Psychology. s.n.,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1932}, {"title": "Give me a reason to dig Minecraft and psychology of motivation", "author": ["A. Canossa", "J. Martinez", "J. Togelius"], "venue": "Proc. IEEE Conf. Comput. Intell. Games (CIG\u201913), Aug. 2013, pp. 1\u20138.  MANUSCRIPT FOR THE IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES  16", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "A gamebased corpus for analysing the interplay between game context and player experience", "author": ["N. Shaker", "S. Asteriadis", "G. Yannakakis", "K. Karpouzis"], "venue": "Affective Computing and Intelligent Interaction, ser. Lecture Notes in Computer Science, S. D.Mello, A. Graesser, B. Schuller, and J.-C. Martin, Eds. Springer Berlin Heidelberg, 2011, vol. 6975, pp. 547\u2013556.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2011}, {"title": "Unskilled and unaware of it: How difficulties in recognizing one\u2019s own incompetence lead to inflated selfassessments", "author": ["J. Kruger", "D. Dunning"], "venue": "Journal of Personality and Social Psychology, vol. 77, pp. 1121\u20131134, 1999.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1999}, {"title": "Ranking vs. preference: a comparative study of self-reporting", "author": ["G.N. Yannakakis", "J. Hallam"], "venue": "Proc. Conf. Affect. Comput. Intell. Inter. (ACII\u201911), Berlin, Heidelberg, 2011, pp. 437\u2013446.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "Dynamic difficulty adjusting strategy for a two-player video game", "author": ["V.M. lvarez Pato", "C. Delgado-Mata"], "venue": "Procedia Technology, vol. 7, no. 0, pp. 315\u2013321, 2013.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Choices, values and frames", "author": ["D. Kahneman"], "venue": "Experienced Utility and Objective Happiness: A Moment-Based Approach, D. Kahneman and A. Tversky, Eds. New York, NY: Cambridge University Press, 2000, ch. 37, pp. 673\u2013692.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2000}, {"title": "The math behind TrueSkill", "author": ["J. Mosser"], "venue": "May 2011, accessed 5-28-14.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "Note on regression and inheritance in the case of two parents", "author": ["K. Pearson"], "venue": "Proceedings of the Royal Society of London, vol. 58, no. 347- 352, pp. 240\u2013242, 1895.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1895}, {"title": "On a test of whether one of two random variables is stochastically larger than the other", "author": ["H.B. Mann", "D.R. Whitney"], "venue": "The Annals of Mathematical Statistics, vol. 18, no. 1, pp. 50\u201360, Mar. 1947.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1947}, {"title": "A technique for high-performance data compression", "author": ["T.A. Welch"], "venue": "Computer, vol. 17, no. 6, pp. 8\u201319, Jun. 1984.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1984}, {"title": "A method for the construction of minimum-redundancy  codes", "author": ["D.A. Huffman"], "venue": "Proc. IRE, vol. 40, no. 9, pp. 1098\u20131101, Sep. 1952.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1952}, {"title": "Physiological time-series analysis using approximate entropy and sample entropy", "author": ["J.S. Richman", "J.R. Moorman"], "venue": "American Journal of Physiology - Heart and Circulatory Physiology, vol. 278, no. 6, pp. H2039\u2013H2049, Jun. 2000.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2000}, {"title": "An algorithm for the machine calculation of complex Fourier series", "author": ["J.W. Cooley", "J.W. Tukey"], "venue": "Mathematics of Computation, vol. 19, no. 90, pp. 297\u2013301, 1965.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1965}, {"title": "Player modeling using self-organization in Tomb Raider: Underworld", "author": ["A. Drachen", "A. Canossa", "G.N. Yannakakis"], "venue": "Proc. IEEE Symp. Comput. Intell. Games (CIG\u201909), 2009, pp. 1\u20138.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2009}, {"title": "Sequential minimal optimization: A fast algorithm for training support vector machines", "author": ["J.C. Platt"], "venue": "Advances in Kernel Methods - Support Vector Learning, Tech. Rep., 1998.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1998}, {"title": "Random forests", "author": ["L. Breiman"], "venue": "Machine Learning, vol. 45, pp. 5\u201332, 2001.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2001}, {"title": "Classification and regression by randomForest", "author": ["A. Liaw", "M. Wiener"], "venue": "R News, vol. 2, no. 3, pp. 18\u201322, 2002. [Online]. Available: http://CRAN.R-project.org/doc/Rnews/", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2002}, {"title": "Some implementations of the boxplot", "author": ["M. Frigge", "D.C. Hoaglin", "B. Iglewicz"], "venue": "The American Statistician, vol. 43, no. 1, pp. 50\u201354, 1989.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1989}, {"title": "Statistical Power Analysis for the Behavioral Sciences", "author": ["J. Cohen"], "venue": "L. Erlbaum Associates,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1988}, {"title": "Does training novices to criteria and does rapid acquisition of skills on laparoscopic simulators have predictive validity or are we just playing video games?", "author": ["N.J. Hogle", "W.D. Widmann", "A.O. Ude", "M.A. Hardy", "D.L. Fowler"], "venue": "Journal of Surgical Education,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "The definition used here falls in line with existing skill metrics [1], [2], and allows skill to be explicitly measured.", "startOffset": 67, "endOffset": 70}, {"referenceID": 1, "context": "The definition used here falls in line with existing skill metrics [1], [2], and allows skill to be explicitly measured.", "startOffset": 72, "endOffset": 75}, {"referenceID": 2, "context": "Single player games, on the other hand, use Dynamic Difficulty Adjustment (DDA) [3], [4], where the game\u2019s difficulty is changed according to the player\u2019s progress.", "startOffset": 80, "endOffset": 83}, {"referenceID": 3, "context": "Single player games, on the other hand, use Dynamic Difficulty Adjustment (DDA) [3], [4], where the game\u2019s difficulty is changed according to the player\u2019s progress.", "startOffset": 85, "endOffset": 88}, {"referenceID": 4, "context": "Left 4 Dead\u2019s AI director is an example of this in action [5].", "startOffset": 58, "endOffset": 61}, {"referenceID": 1, "context": "Bayesian methods, such as TrueSkill [2], require several games before converging, depending on the number of players, and DDA relies on heuristic methods which are not necessarily representative of a player\u2019s skill [3].", "startOffset": 36, "endOffset": 39}, {"referenceID": 2, "context": "Bayesian methods, such as TrueSkill [2], require several games before converging, depending on the number of players, and DDA relies on heuristic methods which are not necessarily representative of a player\u2019s skill [3].", "startOffset": 215, "endOffset": 218}, {"referenceID": 5, "context": "It is intuitive to assume that a skilled player will interact with the controls differently to a novice [6].", "startOffset": 104, "endOffset": 107}, {"referenceID": 6, "context": "Building on the success of random forests in previous work [7], we then predict the player\u2019s skill with reasonable accuracy from only 10 seconds of data (see Fig.", "startOffset": 59, "endOffset": 62}, {"referenceID": 7, "context": "The definition of skill used here is distinct from the term ability defined by Parker and Fleishman [8]: \u201cAbility refers to a more general, stable trait of the individual which may facilitate performance in a variety of tasks.", "startOffset": 100, "endOffset": 103}, {"referenceID": 8, "context": "1, and is similar to the connection Chomsky draws between competence and performance [9].", "startOffset": 85, "endOffset": 88}, {"referenceID": 9, "context": "Combining and adjusting different metrics is done in order to encourage desired behavior [10].", "startOffset": 89, "endOffset": 93}, {"referenceID": 1, "context": "TrueSkill, unlike the simple metrics previously mentioned, averages performance using Bayesian updating [2].", "startOffset": 104, "endOffset": 107}, {"referenceID": 0, "context": "The model, which is based on the Elo rating [1], actually represents a belief in a player\u2019s skill, which can be reduced to produce a skill metric.", "startOffset": 44, "endOffset": 47}, {"referenceID": 10, "context": "The main criticisms of TrueSkill are its time to convergence, which can take several games to find a confident representation, and that values cannot be compared across different leagues [12].", "startOffset": 187, "endOffset": 191}, {"referenceID": 11, "context": "extend a chess end-game performance metric [13] to complete chess games [14].", "startOffset": 43, "endOffset": 47}, {"referenceID": 12, "context": "extend a chess end-game performance metric [13] to complete chess games [14].", "startOffset": 72, "endOffset": 76}, {"referenceID": 13, "context": "The task of skill prediction is not limited to games, and also extends to domains such as teleoperations [15] and Human Computer Interaction (HCI) [16], [17].", "startOffset": 105, "endOffset": 109}, {"referenceID": 14, "context": "The task of skill prediction is not limited to games, and also extends to domains such as teleoperations [15] and Human Computer Interaction (HCI) [16], [17].", "startOffset": 147, "endOffset": 151}, {"referenceID": 15, "context": "The task of skill prediction is not limited to games, and also extends to domains such as teleoperations [15] and Human Computer Interaction (HCI) [16], [17].", "startOffset": 153, "endOffset": 157}, {"referenceID": 16, "context": "The first of these, monitoring physiological responses, explored skill in a fighting game [18].", "startOffset": 90, "endOffset": 94}, {"referenceID": 17, "context": "This sort of data is easy to collect, and useful for other methods of prediction [19].", "startOffset": 81, "endOffset": 85}, {"referenceID": 18, "context": "consider this data for predicting completion time in Tomb Raider: Underworld [20], a reasonable metric of performance for single-player games.", "startOffset": 77, "endOffset": 81}, {"referenceID": 19, "context": "Finally, the most closely related research was done in the real-time strategy (RTS) game StarCraft II [21].", "startOffset": 102, "endOffset": 106}, {"referenceID": 20, "context": "Although the structure of the log file was designed independently, inspiration was drawn from similar research being done at the time [22].", "startOffset": 134, "endOffset": 138}, {"referenceID": 6, "context": "After the initial study [7], a further period of data collection was held in order to improve on existing problems with the data set.", "startOffset": 24, "endOffset": 27}, {"referenceID": 21, "context": "There were three different questionnaires used in total throughout the experiment: a demographic questionnaire, an experience-based questionnaire using the Likert scale [23], and an experience-based questionnaire using 4 Alternative Forced Choice (4-AFC) [24].", "startOffset": 169, "endOffset": 173}, {"referenceID": 22, "context": "The first measure, how many hours the participant plays per week, is a common question in research [25], [26].", "startOffset": 99, "endOffset": 103}, {"referenceID": 23, "context": "The first measure, how many hours the participant plays per week, is a common question in research [25], [26].", "startOffset": 105, "endOffset": 109}, {"referenceID": 24, "context": "These questions were designed to be objective and avoid self-assessment, which players are notoriously poor at [27].", "startOffset": 111, "endOffset": 115}, {"referenceID": 25, "context": "There are advantages and disadvantages to each method, which are discussed more thoroughly in [28].", "startOffset": 94, "endOffset": 98}, {"referenceID": 17, "context": "The first three questions have been used previously with some degree of success [19], [29].", "startOffset": 80, "endOffset": 84}, {"referenceID": 26, "context": "The first three questions have been used previously with some degree of success [19], [29].", "startOffset": 86, "endOffset": 90}, {"referenceID": 27, "context": "This was to mitigate the effects of memory on self-reported affect [30].", "startOffset": 67, "endOffset": 71}, {"referenceID": 28, "context": "A more thorough description of the workings of TrueSkill can be found in [31].", "startOffset": 73, "endOffset": 77}, {"referenceID": 18, "context": "This measure and others, including relative absolute error (RAE) [20], punish offset results and those suffering from scaling effects.", "startOffset": 65, "endOffset": 69}, {"referenceID": 29, "context": "Spearman\u2019s \u03c1 is defined as the Pearson correlation coefficient [32] between two ranked variables.", "startOffset": 63, "endOffset": 67}, {"referenceID": 30, "context": "For this situation, where the skill metrics are nonparametric, unlike a t-test, and the measures are independent, in contrast with the Wilcoxon signed-rank test, the Mann\u2013 Whitney U test is suitable [33].", "startOffset": 199, "endOffset": 203}, {"referenceID": 31, "context": "The first two, Lempel-Ziv-Welch (LZW) [34] and Huffman coding, can all be used for compression of data.", "startOffset": 38, "endOffset": 42}, {"referenceID": 32, "context": "The second algorithm, designed by Huffman [35], constructs a Huffman tree based on probability distributions.", "startOffset": 42, "endOffset": 46}, {"referenceID": 33, "context": "The second measure, sample entropy, based on approximate entropy [36], is performed on continuous data and was originally designed for physiological time-series.", "startOffset": 65, "endOffset": 69}, {"referenceID": 34, "context": "The final complexity measure used was a discrete Fourier transform [37].", "startOffset": 67, "endOffset": 71}, {"referenceID": 19, "context": "Previous research [21], [38] successfully", "startOffset": 18, "endOffset": 22}, {"referenceID": 35, "context": "Previous research [21], [38] successfully", "startOffset": 24, "endOffset": 28}, {"referenceID": 36, "context": "used SMO (Sequential Minimal Optimization), an algorithm for support vector machines [39].", "startOffset": 85, "endOffset": 89}, {"referenceID": 37, "context": "However, random forests [40] were chosen for their ability to generalize well, even with a large number of features with unknown properties.", "startOffset": 24, "endOffset": 28}, {"referenceID": 38, "context": "[41].", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "This Tukey box plot [42] presents the performance metric, rank (r) and skill metric (r\u0304) for every game, grouped by the game\u2019s map.", "startOffset": 20, "endOffset": 24}, {"referenceID": 23, "context": "Asking players about their gaming experience is common in related research [26].", "startOffset": 75, "endOffset": 79}, {"referenceID": 24, "context": "However, players are poor estimators of their own skill [27].", "startOffset": 56, "endOffset": 60}, {"referenceID": 15, "context": "Using the methods presented in Section IV and previous work [17], 174 global features were extracted from the keyboard and mouse events of each game3.", "startOffset": 60, "endOffset": 64}, {"referenceID": 15, "context": "A number of mouse movement events have already been used in related HCI research [17], and these formed the basis for the Mouse features.", "startOffset": 81, "endOffset": 85}, {"referenceID": 40, "context": "6, slightly greater than that suggested in previous work [43]) has been summarized in Fig.", "startOffset": 57, "endOffset": 61}, {"referenceID": 15, "context": "This contrasts previous work in HCI, in which mouse features played a key role [17].", "startOffset": 79, "endOffset": 83}, {"referenceID": 41, "context": "Given that only one person had played Red Eclipse before, this is consistent with previous research that found skilled players learned faster [44].", "startOffset": 142, "endOffset": 146}, {"referenceID": 19, "context": "StarCraft, for instance, groups players into leagues, where players in the same league are generally comparable in skill [21].", "startOffset": 121, "endOffset": 125}, {"referenceID": 5, "context": "It may be that the clusters created here related to both skill and player style [6].", "startOffset": 80, "endOffset": 83}, {"referenceID": 15, "context": "While useful in previous research [17], it may simply be too random for use in this application4.", "startOffset": 34, "endOffset": 38}, {"referenceID": 6, "context": "There are several key differences between the prediction done in this research and that in previous work [7], [21].", "startOffset": 105, "endOffset": 108}, {"referenceID": 19, "context": "There are several key differences between the prediction done in this research and that in previous work [7], [21].", "startOffset": 110, "endOffset": 114}], "year": 2014, "abstractText": "Various aspects of computer game design, including adaptive elements of game levels, characteristics of \u2018bot\u2019 behavior, and player matching in multiplayer games, would ideally be sensitive to a player\u2019s skill level. Yet, while difficulty and player learning have been explored in the context of games, there has been little work analyzing skill per se, and how it pertains to a player\u2019s input. To this end, we present a data set of 476 game logs from over 40 players of a first-person shooter game (Red Eclipse) as a basis of a case study. We then analyze different metrics of skill and show that some of these can be predicted using only a few seconds of keyboard and mouse input. We argue that the techniques used here are useful for adapting games to match players\u2019 skill levels rapidly, perhaps more rapidly than solutions based on performance averaging such as TrueSkill.", "creator": "LaTeX with hyperref package"}}}