{"id": "1411.4925", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Nov-2014", "title": "Linguistic Descriptions for Automatic Generation of Textual Short-Term Weather Forecasts on Real Prediction Data", "abstract": "sisneros We present liberto in ferrick this paper bovell an unidade application which automatically pouzilhac generates panteleyev textual vinnaithaandi short - turnback term weather forecasts for alycia every municipality in Galicia (3.58 NW pacis Spain ), kloof using the sevin real data provided by alborz the Galician darkhan Meteorology bonking Agency (bottle MeteoGalicia ). 53-3 This foot-operated solution combines ricerca in abess an mortes innovative way naifeh computing briem with perceptions cross-examined techniques and 380 strategies for linguistic description queanbeyan of data together with gardes a ostroff natural gunnar language ba'athists generation (crankily NLG) p3p system. The closet application, named GALiWeather, negotiatons extracts 8:48 relevant polesia information redraw from weather proclamation forecast input data principate and encodes padrnos it kornat into garze intermediate pincushions descriptions alico using linguistic marabouts variables and temporal references. These descriptions h\u00e4rn\u00f6sand are bellemare later mamai translated st\u00f8rmer into miyoshi natural academic language texts by the natural hagerty language mazeppa generation system. maslarova The darryl obtained 38-hour forecast results raffray have tinling been thoroughly naja validated mangled by an mzilikazi expert meteorologist from reviles MeteoGalicia herms using isere a quality assessment methodology outpitched which 27,321 covers two wissem key siewierz dimensions syngnathidae of oto a text: the morimoto accuracy of 7.95 its ehrhard content and the valour correctness of motat its form. Following soloman this validation GALiWeather bytham will be ibla released as 20/30 a unconformities real omniscient service bracewell offering custom forecasts for a pdry wide public.", "histories": [["v1", "Tue, 18 Nov 2014 17:35:59 GMT  (6443kb,D)", "http://arxiv.org/abs/1411.4925v1", "13 pages, 20 figures, IEEE Transactions on Fuzzy Systems, 2014"]], "COMMENTS": "13 pages, 20 figures, IEEE Transactions on Fuzzy Systems, 2014", "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["a ramos-soto", "a bugar\\'in", "s barro", "j taboada"], "accepted": false, "id": "1411.4925"}, "pdf": {"name": "1411.4925.pdf", "metadata": {"source": "CRF", "title": "Linguistic Descriptions for Automatic Generation of Textual Short-Term Weather Forecasts on Real Prediction Data", "authors": ["A. Ramos-Soto"], "emails": ["alejandro.ramos@usc.es,", "alberto.bugarin.diz@usc.es,", "senen.barro@usc.es).", "juan.taboada@meteogalicia.es)."], "sections": [{"heading": null, "text": "1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\nIndex Terms\u2014linguistic descriptions of data, natural language generation, computing with perceptions, open data\nI. INTRODUCTION\nIn recent years, governments and agencies from many countries have increasingly focused efforts on improving the accessibility of their citizens to public data, i.e., all the data that public bodies in a given country produce, collect or pay for, which is widely known as the Open Data paradigm [1]. These resources, which come from many different fields of knowledge, offer a high potential for reuse in new products and services. This scenario has been described very graphically with the following statement \u201cdata is the new oil for the digital age\u201d [2].\nHowever, there is still a significant gap between the resources offered by public institutions and the necessities of their potential consumers. One reason is that the publishing bodies are usually focused on the availability of their datasets rather than on providing tools or means for accessing and processing them. This often results in extensive catalogues of heterogeneous data which have almost no direct value for the potential consumers of that data.\nBesides a lack of standardization, there is also a lack of tools and services which allow a better access and comprehension of\nA. Ramos-Soto, A. Bugar\u0131\u0301n and S. Barro are with the Research Centre on Information Technologies (CiTIUS), University of Santiago de Compostela, Spain (e-mail: alejandro.ramos@usc.es, alberto.bugarin.diz@usc.es, senen.barro@usc.es). J. Taboada is with MeteoGalicia, Santiago de Compostela, Spain (e-mail: juan.taboada@meteogalicia.es).\nThis work was supported by the Spanish Ministry for Economy and Competitiveness under grant TIN2011-29827-C02-02. It was also supported in part by the European Regional Development Fund (ERDF/FEDER) under the project CN2012/151 of the Galician Ministry of Education.\nA. Ramos-Soto is supported by the Spanish Ministry for Economy and Competitiveness (FPI Fellowship Program).\nthe raw data provided by the public institutions. An interesting and illustrative example of this kind of services can be found in meteorology, where meteorological agencies offer both raw data and also several types of information pieces (such as forecasts, reports or meteorological warnings) that are elaborated by meteorologists from these raw data.\nArtificial Intelligence provides us with tools which allow us to process and understand this massive availability of huge quantities of data. Originally, this objective has been assumed by the knowledge discovery in databases (KDD) field, but more specifically by its core stage, the data mining field [3], which assembles several tasks such as classification, association, clustering, trend analysis or summarization [4]. Summarization is of particular interest, since it abstracts data into useful information at different levels and dimensions. The abstracted information can adopt many forms, although the most common services come in the form of webbased visualization tools. However, other approaches taken by research fields such as natural language generation (NLG) or soft computing offer solutions to convert and summarize data into textual information which can be easily consumed by human users.\nThe creation of automatic textual summaries of data is a task which originally started within the NLG field. Several NLG approaches which generated summaries of data include ANA [5], which generated summaries of stock market activity; LFS [6], which generated summaries of statistical data; SUMGEN [7], which generated summaries of events in a battle simulation; TEMSIS [8], which generated summaries of environmental data; TREND [9], which generated summaries of historical weather data; and, more recently, BabyTalk [10], which generates medical reports for neonatal intensive care data. However, the most successful NLG systems for data summarization, at least in terms of public impact and usefulness, generate automatic textual weather forecasts from numerical prediction data. A few systems, such as FoG [11], MultiMeteo [12] and SUMTIME-MOUSAM [13], [14], have been used by meteorological agencies to automatically produce public weather forecasts.\nAt the same time, within the fuzzy logic and soft computing field, the paradigm of computing with words (CWW) [15], and its later evolution computing with perceptions (CWP) [16], [17], made their appearance in the 1990s. As opposed to other classical approaches, these paradigms involve a fusion of natural languages and computation with linguistic variables [16]. Although many new approaches based on CWW have emerged, one of the most promising tools is linguistic data summarization [18], [19], which employs fuzzy quantified propositions to obtain linguistic summaries involving one variable (as in \u201cMost of the dogs are brown\u201d or \u201cA few trees are tall\u201d) or more than one variable (as in\nar X\niv :1\n41 1.\n49 25\nv1 [\ncs .A\nI] 1\n8 N\nov 2\n01 4\n\u201cSome of the brown dogs are heavy\u201d or \u201cMost of the tall trees are very old\u201d). Since then, linguistic summarization from CWW has been applied in several practical cases and, with the appearance of CWP, some authors have started to refer to linguistic summaries as linguistic descriptions of data (LDD) [20], which understand linguistic summaries as a tool to describe human perceptions. For reasons of clarity, we will use in this paper the term linguistic descriptions of data. Examples of fields of application of linguistic description approaches include descriptions of the patient inflow in health centers [21], domestic electric consumption reports [22], human activity based on mobile phone accelerometers [23] or human gait quality [24]. Other approaches use more complex expressions involving relationships among different attributes (in economic data [25], in sales data [26] or the analysis of investment fund quotations [27]).\nMost of these approaches are very strongly dependent on the field of application and the users\u2019 needs of information. A more general approach which is able to construct different kinds of linguistic descriptions regardless of the application domain is still an open challenge in this field. Nevertheless, steps in this direction have been taken by providing general criteria on how to structure quantified sentences in order to obtain more complex descriptions [28] or on how to build and evaluate linguistic descriptions [29], [30], [31].\nAnother open challenge is the relationship between linguistic descriptions in CWP and NLG. Until now, both have followed separate paths, although it remains clear that both can contribute to each other in a substantial way [26].\nWith both linguistic descriptions from CWP and textual summaries from NLG as inspiration, we present in this paper GALiWeather [32], an application which automatically generates shortterm weather forecasts in the form of natural language texts for the Galician Meteorological Agency (MeteoGalicia) [33]. This solution employs in an innovative way a LDD computational method combined with a NLG system in order to solve a real life information need, as opposed to other approaches which only present test use cases and do not address the whole problem of adapting their solutions to real final user needs and demands. For this, the use of fuzzy procedures through linguistic variables and quantifiers allows the application to model imprecise concepts included in the linguistic descriptions. Furthermore, the quality of these descriptions, which are generated as natural language texts by the NLG system, has been assessed by an expert meteorologist in two key dimensions, verifying that the textual forecasts are both correct and properly expressed.\nThe next section introduces the context in which this solution has been devised. In Section III a formal description of the forecast input data and the linguistic description computational method is provided, followed by an extensive overview of the NLG system. Section IV addresses the validation process and results obtained for our application. Section V contains some insights about a methodological conceptualization of our approach and finally in Section VI we present the most relevant conclusions.\nII. SHORT-TERM WEB FORECASTS FOR GALICIA\nThe operative weather forecasting offered by the Galician (NW Spain) Meteorology Agency through its website (MeteoGalicia\n[33]) consisted until now of a global description of the shortterm meteorological trend (Fig. 1). This service has been recently improved in order to provide visitors with symbolic forecasts for each of the 315 municipalities in Galicia, thus improving its quality and allowing users to obtain more precise information about specific locations of the Galician geography.\nFigure 2 shows the current web application for consulting municipality forecasts [33], which has been graphically divided in blocks for an easier explanation. Block 1 contains a shortcut list to the seven most important municipalities in Galicia, which allows a direct access to their forecast data (the user can select a favorite municipality, which is loaded by default in posterior visits). Block 2 allows the user to search for the rest of the municipalities, which are grouped according to the Galician province they belong to. It also allows to add to the shortcut list in Block 1 the selected municipality. The short-term forecast is shown in Block 3, which offers symbolic data for wind and sky state and numeric data for temperatures for four days, including morning, afternoon and night each day. Block 4 shows the mid-term forecast for several days and includes a global comment about the weather in Galicia in general, which consequently remains the same for every municipality.\nThis increase in the quantity of available numerical-symbolic data has a main downside, which resides in the lack of natural language forecasts which describe this set of data. This issue makes forecasts harder to understand, since users need to look\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\nat every symbol and detect which phenomena are relevant and when they will occur, whereas natural language descriptions directly provide all this information. In the case of a mid-term forecast, its uncertainty allows the inclusion of a global description, which is written by a meteorologist. However, for short-term forecasts, which are much more accurate, the meteorological diversity causes that several meteorological phenomena may occur at the same time in different areas. Thus, to issue daily textual forecasts upon 315 municipalities is not feasible.\nIn order to address this issue we have developed an application which, from short-term data, generates linguistic descriptions which highlight meteorological phenomena considered important by an expert meteorologist. The style and contents of the natural language linguistic descriptions for each location are similar to the general one presented in Fig. 1.\nIII. APPLICATION DESCRIPTION\nThe solution we have devised employs numerical-symbolic forecast data and additional expert information to generate the final output textual weather forecasts in two separate tasks. The first task converts the numerical-symbolic input data into linguistic descriptions (encoded in an intermediate language). These descriptions are created through a computational method which abstracts data values into linguistic labels dealing with uncertainty and temporal references. In the second stage, a NLG system translates the intermediate codes into a natural language forecast for one of the available final output natural languages, which is ready for human consumption. A general schema of this process is shown in Fig. 3.\nA. Input weather forecast data characterization\nMeteoGalicia\u2019s database offers a dataset which covers all the 315 Galician municipalities and includes forecast data associated to several items in a four-day temporal window. This data is heterogeneous in its nature and includes values in degrees Celsius and weather symbols represented by codes. For instance, the meteorologists have characterized the sky state phenomena as 21 numerical codes (values in the interval [101,121]) and the wind phenomena as 34 numerical codes (values associated to a given intensity and direction in the interval [299,332]). These numerical codes are used to display graphical symbols in the forecast website. Figure 4 shows an example of a real short-term forecast data series.\nFormally, each municipality M has an associated forecast data series set FDM = {SSM ,WM , TMAXM , TMINM} , which includes data series for the input variables considered: sky state (SSM ), wind (WM ) and maximum (TMAXM ) and minimum\n(TMINM ) temperatures. For clarity reasons, without loss of generality, we will consider a single municipality data series in the explanations that follow (FDM = FD). Each data series element in FD is characterized in what follows: \u2022 Sky state (SS). It provides three numerical codes per day\n(morning, afternoon, night) about two meteorological variables of interest, namely cloud coverage and precipitation. From a formal point of view, SS = {ss1, . . . , ssi, . . . , ss12}, where ssi \u2208 [101, 121]\u2200ssi \u2208 SS. Each code in the interval [101, 121] has a specific sky state meaning (for example, 111 means \u201ccovered with rain\u201d). \u2022 Wind (W ). It provides three numerical codes per day about the wind intensity and direction. W = {w1, ..., wi, ..., w12}, where wi \u2208 [299, 332]\u2200wi \u2208 W . Each code in the interval [299, 332] has an associated wind direction and intensity (for instance, 317 means \u201cstrong wind from the North\u201d). \u2022 Temperature (TMAX and TMIN ). Maximum and minimum forecasted temperatures are given in degrees Celsius with a resolution of 1 degree and one value per day:\n\u2013 TMAX = {tmax1, tmax2, tmax3, tmax4}, where tmaxi \u2208 [\u221260\u25e6C, 60\u25e6C]\u2200tmaxi \u2208 TMAX . \u2013 TMIN = {tmin1, tmin2, tmin3, tmin4}, where tmini \u2208 [\u221260\u25e6C, 60\u25e6C]\u2200tmini \u2208 TMIN . For each forecast data series FD, our application obtains linguistic descriptions about seven forecast variables, namely cloud coverage, precipitation, wind, maximum and minimum temperature variation and maximum and minimum temperature climatic behavior 1. For this, we have devised a computational method divided in several linguistic description generation operators."}, {"heading": "B. First stage: Linguistic description generation method", "text": "The first stage of our application obtains a linguistic description for every variable, which consists in sets of linguistic labels and temporal references which contain the relevant information extracted from the raw data. This process, as it can be seen in Fig. 5, consists of providing each linguistic description operator with its corresponding data and expert knowledge (in the form of crisp and fuzzy partition sets and numeric categories) in order to generate the intermediate linguistic descriptions. Each operator is formally described in what follows.\n1) Cloud coverage fuzzy operators: Two different fuzzy operators are used in the linguistic description generation of the cloud coverage variable. The first one provides a chronological\n1It measures the difference between the forecasted temperatures and the temperature climatic mean, defined as the average for the previous 30 years in a given month.\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\ndescription, while the second one provides a short-term global description when the previous description is not appropriate.\n1) Chronological description fuzzy operator. \u2022 Input:\n\u2013 Sky state data series SS = {ss1, . . . , ssi, . . . , ss12}. \u2013 A temporal fuzzy linguistic partition CCT = {cct1, . . . , cctj , . . . , cctn}, where each temporal linguistic term cctj has an associated fuzzy membership function \u00b5cctj : N \u2192 [0, 1]. For our application, CCT = {BEGINNING,HALF,END} (Fig. 6). \u2013 A cloud coverage linguistic variable, defined as a set of cloud coverage categories CCL = {ccl1, . . . , cclk, . . . , cclm}. Each linguistic term cclk \u2208 CCL has an associated crisp membership function \u00b5cclk : N\u2192 {0, 1}, defined as:\n\u00b5cclk(ssi) = { 1 if ssi \u2208 cclk 0 otherwise\n(1)\nIn our application, CCL = {C,PC, V C} (\u201cclear\u201d, \u201cpartly cloudy\u201d, \u201cvery cloudy\u201d), as shown in Fig. 6. \u2022 Procedure. This operator provides the most appropriate cloud coverage linguistic term cclk for each temporal subdivision cctj . A relevance degree is calculated for each pair of cloud coverage and temporal labels and the label pairs with the highest degree are then selected (one per temporal label): \u2013 Relevance degree matrix RD, where each value RDj,k\ndetermines the importance a cloud coverage linguistic term cclk has within a temporal sub period cctj :\nRDj,k = |SS|\u2211 i=1\n\u00b5cclk(ssi) \u2217 \u00b5cctj (i) \u2013 Set of the most appropriate cloud coverage label\nfor each temporal label, ordered by the temporal partition index j: CCTL = {(cctj , cclk)|RDj,k = max(RDj)}\n\u2022 Output. A chronological cloud coverage linguistic description as an intermediate code characterized by the following concatenation:\nLDChronoCC \u2192 (cct1, cclk) . . . (cctn, cclk)\nFigure 6 shows the definitions of both linguistic variables for our application and an example of the chronological cloud coverage linguistic description process. This description\nCurrent day Tomorrow 2 days after 3 days after\nss1 ss2 ss3 ss4 ss5 ss6 ss7 ss8 ss9 ss10 ss11 ss12SS =\nC PC VCCCL =\nCCT =\nLDChronoCC (BEGINNING, PC) (HALF, VC) (END, C)\nC PC VC\nBEG.\nHALF\nEND\n1 3.1 0.14\n0.29 1.72 3.43\n3 0 1.24\nRD =\n1 2 3 4 5 6 7 8 9 10 11 12 0\n0.2\n0.4\n0.6\n0.8\n1 BEGINNING HALF END\nFu lfi\nllm en\nt de\ngr ee\nMeteorological value index\n2) Precipitation episode extractor operator: This operator extracts precipitation episodes from the sky state values. These periods are classified according to the kind of precipitations detected: \u2022 Input:\n\u2013 Sky state data series SS = {ss1, . . . , ssi, . . . , ss12}. \u2013 A precipitation linguistic variable, defined as a set of\nprecipitation categories PV = {pv1, . . . , pvj , . . . , pvn}, where each linguistic term pvj has an associated crisp\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\nmembership function \u00b5pvj : N \u2192 {0, 1}, where \u00b5pvj is defined identically as \u00b5cclk in expression (1).\n\u2022 Procedure. This operator extracts an ordered set of precipitation episodes PE = {pe1, . . . , pek, . . . , pem}, where each episode is characterized as pek = {START,END, LABELS}. The algorithm in Fig. 8 describes how the precipitation operator extracts the relevant episodes from SS: \u2022 Output. A precipitation linguistic description for each precipitation episode pek as an intermediate code characterized by the following concatenation of terms:\nLDPrecipitationk \u2192 STARTk ENDk LABELSk\nIn this case, PL = {I, P, SN, ST,H} (\u201cintermittent\u201d,\u201cpersistent\u201d,\u201csnow\u201d,\u201cstorm\u201d,\u201chail\u201d) is defined for precipitation (although \u201cintermittent\u201d and \u201cpersistent\u201d are not explicitly included in the final natural language forecasts, as required by the meteorologists). Figure 9 shows the definition of PL and provides a graphical example of the precipitation linguistic description generation process.\n3) Wind operator: It follows a similar strategy to the precipitation operator, although in this case it does not convert the original values into labels.\n\u2022 Input: \u2013 Wind data series W = {w1, . . . , wi, . . . , w12}. \u2013 A numeric interval AW = [awa, awb]|AW \u2282 [299, 332]\n(as indicated in Section III-A), which specifies the relevant wind values to be extracted by the operator. In our application, AW = [317, 332]. This interval corresponds to strong and very strong winds, which are the only relevant wind conditions to be included in the descriptions according to the meteorologists.\n\u2022 Procedure. This operator extracts an ordered set of wind episodes WE = {we1, . . . , wek, . . . , wem}, where each episode is characterized as wek = {STARTk, ENDk, SYMBOLSk}. The algorithm in Fig. 10 describes how the wind operator extracts the relevant episodes from W . \u2022 Output. A wind linguistic description for each wind episode wej as an intermediate code characterized by the following concatenation: LDWindk \u2192 STARTk ENDk SYMBOLSk. For example, if there is a period of strong wind within W , we could obtain a linguistic description such as \u201cSTART=2 END=4 LABELS=322,322,322\u201d, meaning \u201cfrom tonight (i = 2) until tomorrow afternoon (i = 4) there will be strong wind from the southwest (wi = 322)\u201d.\n4) Temperature operator: This operator generates a linguistic description which reflects the temperature trend for the 4-day period and also obtains information about the climatic behavior\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\nof the forecasted temperatures. Thus, four variables are considered: maximum and minimum temperature variations and maximum and minimum climatic behavior. \u2022 Input:\n\u2013 Maximum temperature data series TMAX = {tmax1, tmax2, tmax3, tmax4}. \u2013 Minimum temperature data series TMIN = {tmin1, tmin2, tmin3, tmin4}. \u2013 A temperature variation linguistic variable, defined as TV = {tv1, . . . , tvj , . . . , tvn}, where each linguistic term tvj \u2208 TV has an associated crisp membership function \u00b5tvj : R \u2192 {0, 1}. In our application, TV = {ED,ND,MD,SD,WC, SI,MI,NI,EI} (\u201cextreme decrease\u201d, \u201cnotable decrease\u201d, \u201cmoderate decrease\u201d, \u201cslight decrease\u201d, \u201cwithout changes\u201d, \u201cslight increase\u201d, ..., \u201cextreme increase\u201d). \u2013 A temperature climatic behavior linguistic variable, defined as TC = {tc1, . . . , tcj , . . . , tcn}, where each linguistic term tcj \u2208 TC has an associated crisp membership function \u00b5tcj : R \u2192 {0, 1}. In our case, TC = {V L,L,N,H, V H} (\u201cvery low\u201d, \u201clow\u201d, \u201cnormal\u201d, \u201chigh\u201d, \u201cvery high\u201d).\n\u2022 Procedure. This operator provides the linguistic terms with the highest membership degree from TV and TC for the four temperature variables considered:\n\u2013 Temperature variation: for maxima TMAXV = tvj |\u00b5tvj (tmax|TMAX| \u2212 tmax1) = 1, and minima TMINV = tvj |\u00b5tvj (tmin|TMIN | \u2212 tmin1) = 1. \u2013 Temperature climatic behavior: for maxima TMAXC =\ntcj |\u00b5tcj ( |TMAX|\u2211 i=1 tmaxi |TMAX| ) = 1, and minima TMINC =\ntcj |\u00b5tcj ( |TMIN |\u2211 i=1 tmini |TMIN | ) = 1.\n\u2022 Output. A temperature linguistic description as an intermediate code characterized by the following term concatenation:\nLDTemperature \u2192 TMINC TMAXC TMINV\nTMAXV\nThe definition of TV and a graphical example of the temperature operator are shown in Figure 11. As for TC, its associated crisp membership functions \u00b5tcj are not shown in this example, since they vary for each municipality."}, {"heading": "C. Second stage: Natural language generation", "text": "The natural language generation (NLG) stage of this application consists of a domain-specific system which, following standard NLG techniques, has also been divided into different modules for each variable, so that changes in one of them do not affect the rest of the system. From a global perspective, each of these modules receives the intermediate linguistic description generated by their corresponding operator, parses it and generates the final textual forecast for its associated variable.\nIf we delve deeper into the natural language generation stage structure, the complexity of the final natural language descriptions is a factor which has determined the design and implementation approach we have followed. This includes evaluation criteria applicable to linguistic descriptions [29] such as the description length, but also NLG systems design methodologies as in [35] and [36].\nThus, since the quantity of information in the descriptions is variable and the diversity of situations for each variable to be included ranges from simple to more complex, we have adopted two different NLG solutions. On one hand, we have defined templates in structured text files which contain generic natural language sentences for the simpler variables (cloud coverage, temperatures and wind). On the other hand, we have designed and implemented the generation of natural language sentences for precipitation inspired by standard NLG methodologies [35], [36].\n1) Template-based NLG approach: This approach has been devised as a solution for variables whose corresponding natural language sentences have rather static structure and length, such as temperatures or cloud coverage. For example, a textual forecast for temperatures usually includes information about variation of maxima and minima and their climate behavior, and the only elements that differ from one forecast to another are the labels assigned to the variations and the behavior, whereas the syntactic structure and length of the forecasts remain the same.\nIn this context, structured text files, such as XML, allow to model and build templates of natural language sentences, where static text can be mixed with other elements, such as variables or optional texts within a sentence. We have taken advantage of this flexibility by designing templates for temperature, cloud coverage and wind variables. These templates are included in a document which also\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\ncontains natural language label sets for variables, time expressions or other kind of language-dependent text resources. Figure 12 shows parts of a template document (in this case for English language), whose structure (Fig. 13) is comprised of the following elements: \u2022 Variable templates, which include the generic natural lan-\nguage forecast structures for several variables, such as cloud coverage or temperature. \u2022 Label sets, which contain the natural language vocabulary and expressions used to fill in the variable elements. They are the natural language equivalent to the crisp and fuzzy partition sets used in the linguistic description extraction stage. For example, in Fig. 11 the temperature variation labels in TV correspond to the label identifiers in the temperature variation label set in Fig. 12.\nThe template documents for the supported languages are loaded into structured objects within the application. Once the intermediate codes for the NLG template-based variables have been obtained, each NLG module (one per meteorological variable) parses its corresponding code and executes expert rules incorporated into the implementation code, so that according to certain detectable events in the intermediate language, different cases and options can be selected. Then, the template variables are filled with the natural language labels which correspond to the linguistic labels found in the intermediate code. Finally, the NLG template structures are translated into a natural language forecast text through the concatenation of the text values of each of their elements.\n2) Precipitation NLG approach: The previous NLG approach is not suitable for variables such as precipitation, where several episodes can occur within a forecast term. This can lead to the generation of several natural language sentences which, although may reflect faithfully the meteorological data, are repetitive and tedious to read. Since the purpose of building linguistic descriptions in natural language is to provide users with textual information which should be easy to read and to understand, another NLG approach is required in order to achieve this goal.\nBased on the concepts of a NLG system architecture described in [35] and [36], we have designed and developed a NLG module for precipitation which addresses redundancy or length excess in\nthe obtained descriptions. In [36], a NLG system is depicted as a six stage task, where one subtask is performed per stage. However, some of these subtasks may be merged or might not even be necessary, depending on the NLG requirements. Consequently, we have adapted some of these subtasks for the precipitation NLG module: content determination, sentence aggregation, lexicalization and linguistic realization. Others such as document planning were not considered, since in our case the NLG complexity is aimed at a sentence level. This process is summarized in Figure 14.\nContent determination is defined in [36] as the process which decides what information should be communicated in the text. This is done by creating a set of data objects (messages) which contain the filtered and summarized data. In our method, this task is partially performed in the linguistic description stage by the precipitation operator, which extracts the relevant data from the raw data and converts it into an intermediate language. The remaining task is to convert the intermediate code into data objects, which is done by the precipitation NLG module parser. As a result, a list of precipitation episodes, whose structure is shown in Fig. 15, is created and used by the subsequent natural language generation subtasks.\nThe precipitation data object structure in Fig. 15 shows that a precipitation episode has a duration (which can range from a single instant to the whole term). Furthermore, it might have associated nuances, which are subintervals within the episode in which the precipitation can be of different nature than rain (of snow, of hail or stormy).\nThe next NLG subtask we have adopted in our approach is sentence aggregation, which consists in grouping messages into\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\nsentences. We have contemplated three different ways of aggregating the precipitation episodes: by episodes, by days and wholeterm aggregation. Consequently, we have created three different submodules which perform not only sentence aggregation, but also lexicalization and linguistic realization.\nLexicalization, which is the process of deciding which specific words and phrases should be chosen to express the concepts and relations in the messages, employs label sets defined in the NLG templates described in the previous approach.\nLinguistic realization produces a text which is syntactically, morphologically and orthographically correct. Our precipitation approach obtains three candidate natural language precipitation sentences which describe the same input meteorological data set. The final output sentence for precipitation will be the shortest of the three, since we want to ensure that the obtained natural language forecasts remain as concise and brief as possible [29].\nD. Implementation details\nThis application has been developed in the cross-platform coding language Python, with the use of libraries for mathematical and fuzzy calculations (numpy, pyfuzzy) or text pattern recognition by grammars (pyparsing). The current implementation supports both Linux and Windows systems. The initially supported languages include Spanish and Galician. English was also included for research and scientific exposure purposes.\nIV. VALIDATION AND RESULTS\nIn this section we address the validation process for GALiWeather, which consists in an exhaustive expert-based revision and quality assessment of a set of automatically generated text forecasts obtained by the application. For this, we briefly discuss the state of the art in validation methodologies for both NLG and LDD fields and, based on these approaches, we explain in detail the validation methodology we have followed and its associated results. For illustration purposes, we present beforehand three examples of linguistic descriptions from the validation set obtained with the application."}, {"heading": "A. Examples of automatic weather forecasts", "text": "Although the short-term prediction data series are limited to 32 values, the number of phenomena which must be considered and its temporal variability ensures a high richness in the obtained linguistic descriptions. As a proof of this richness, we present in\nthis section the following examples covering several meteorological situations.\nThe example shown in Fig. 16 includes real forecast data for the town of Pontevedra, issued the 9th of December by MeteoGalicia. This case shows how GALiWeather performs in common meteorological situations, where the weather changes progressively.\nThe examples shown in Fig. 17 and Fig. 18 present unusual and odd meteorological conditions, which were generated using synthetic data forecasts. These cases were created to test the application robustness under uncommon situations. Both examples include several meteorological phenomena, such as snow, storm, strong winds and temperature variations. Furthermore, each example shows a different precipitation sentence which aggregates the precipitation periods in a different way, as described in Section III-C.\nB. Validation methodology\nValidating automatic natural language generated texts is still an open challenge, even within the NLG field [37]. Several validation approaches do exist, both human and automatic, although in general, the human validation by experts is considered the most reliable [38], [39]. Consequently, the vast majority of NLG systems are validated using expert assessment, which usually implies answering questions about different aspects of the output texts. In the case of the LDD field several criteria have been proposed for evaluating and measuring the quality of the linguistic descriptions objectively [29], but they are not applicable in every approach and the information they provide is very limited compared to that of an expert, besides the fact that many LDD approaches do not reach the NLG stage and are not subject to a full validation process.\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\nMeteoGalicia\u2019s meteorologists have provided support for a human expert validation of the results, which has allowed us to refine the proposed solution in a way that ensures it works under realistic conditions and cases. For this, we have performed the following validation process:\n1) Dataset collection creation. A collection of 45 forecast datasets was created by the meteorologists. This collection includes synthetic and real forecast data, which covers common as well as unusual meteorologic scenarios, similar to the ones presented in the examples in Section IV-A. 2) Natural language forecast automatic generation. From this collection of forecast datasets, 45 automatically generated natural language forecasts were obtained. 3) Polishing stage. These 45 natural language forecasts generated by our application were evaluated by a meteorologist who assessed their quality taking into account their most relevant aspects and dimensions of interest. This initial evaluation was made to obtain preliminary conclusions and polish our approach in those aspects which needed to be improved. 4) Natural language forecast automatic generation. Once the changes to our approach were implemented, new 45 automatically generated language forecasts have been obtained from the original collection of forecast datasets. 5) Validation stage. We have requested the expert to assess the new 45 automatically generated natural language forecasts. As opposed to the results from the polishing stage, which served to identify certain issues and potential improvements, the results of this stage allow to discern if the improvements in our approach are effective and, more importantly, if our application meets the expert\u2019s requirements and is consequently prepared to be released as a public service.\nIn order to assess the quality of the automatically generated forecasts, we have provided the expert meteorologist with a questionnaire which follows the approach presented in [40]. This questionnaire covers three key dimensions about the generated weather forecasts, as shown in Fig. 19:\n\u2022 Relevance: Does the forecast include all the kind of information the expert would include? \u2022 Truthfulness: Does the included information in the forecast reflect the numeric-symbolic forecast correctly?\n\u2022 Manner: Does the forecast express the information properly? Is it well formatted?\nThese three dimensions are directly classified into two higher level categories, \u201dwhat the text implicates\u201d and \u201dwhat the text says\u201d, which altogether determine the quality of the generated forecast. More specifically, the questionnaire we propose consists of five questions which deal in more depth with the previous three dimensions: \u2022 Question 1: \u201cIndicate in which degree you identify the type of\nresults expressed as the type of results expressed by yourself: a) For sky coverage b) For precipitations c) For wind d) For temperatures\u201d. This question determines the grade in which an expert identifies the generated forecast with the ones he creates. For reasons of precision, and in order to identify more specific issues in each forecast variable, Question 1 was divided into four subquestions, one for each forecast variable. \u2022 Question 2: \u201cDo you agree with the provided descriptions? a) For sky coverage b) For precipitations c) For wind d) For temperatures\u201d. This question considers the degree of truthfulness of the generated description, this is, the degree in which the content of the forecast reflects faithfully the information within the numericsymbolic forecast data. Similar to Question 1, Question 2 is divided into four subquestions. With the ratings of Questions 1 and 2, we obtain the partial rating of the forecast related to \u201cwhat the text implicates\u201d. \u2022 Question 3: \u201cIndicate in which degree the vocabulary is used correctly\u201d. This question evaluates if the vocabulary from the meteorology domain is used properly. \u2022 Question 4: \u201cIndicate in which degree the content is correctly grouped to facilitate the comprehension of the description\u201d. This question evaluates if the information in the natural language description is properly grouped and not repetitive. \u2022 Question 5: \u201cIndicate in which degree the format of the report, including the punctuation, is the most adequate\u201d. Question 5 considers aspects related to the forecast text presentation, such as punctuation. With the ratings of Questions 3, 4 and 5 we obtain the partial rating \u201cwhat the text says\u201d.\nEach of these questions must be answered as a number in a 1-5 scale (from 1 \u201cvery negative\u201d to 5 \u201cvery positive\u201d). Thus, in order to calculate the global score for the collection of automatically generated forecasts, we follow the global aggregation schema defined in expression (2). Following this quality measure approach, the quality Q of an automatically generated natural language weather forecast Si is defined as the arithmetic mean of the two dimensions in Layer 3 (Fig. 19):\nQSi = p1+p2 2 + p3+p4+p5 3\n2 (2)\nThe terms p1 and p2 correspond to the average score of the subquestions a, b, c and d for Question 1 and Question 2, respectively. The remaining terms, p3, p4 and p5 are the scores for Questions 3, 4 and 5. As 2 shows, the average of p1 and p2 (\u201cwhat the text implicates\u201d) and the average of p3, p4 and p5 (\u201cwhat the text says\u201d) determine the quality of a forecast. Thus, the global quality score GQ for our collection of automatically generated natural language\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\nforecasts is obtained as the average of the validation cases quality score: GQ = n\u2211 i=1 QSi n , where n = 45 in our case."}, {"heading": "C. Results", "text": "One expert meteorologist answered the proposed questionnaire for the initial 45 automatically generated forecasts. Table I shows that, in general, the meteorologist\u2019s assessment about the content of the forecasts was very positive for the initial test (with an average global score (GQ) of 4.35 out of 5 and a deviation of 0.22). In this sense, the expert identified the content and language of the generated forecasts with the ones he would provide in a high degree. However, from each individual question score we could extract additional conclusions which, in general, implied that there was room for improvement, especially on Question 4 and on some variables from Question 1 and 2. This was due to several repetitive sentences produced by the NLG stage in some of the variables (especially precipitation) and to some expressions which were not appropriate for some variables.\nBased on the results obtained for the polishing stage, we have improved the NLG modules to address the issues found in our first approach and a validation test has been performed by the meteorologist with new 45 automatically generated natural language forecasts. With an average score of 4.83 out of 5 and a deviation of 0.18 (as Table II shows), the quality increase is substantial. In particular, the results in Question 1 show that the expert fully identifies the automatically generated forecasts as if they were produced manually by him. The fact that both content and language from the automatic forecasts are almost indistinguishable from those that an expert would produce are the most important among the several quality aspects which can be measured for a NLG approach. The remaining Questions also show increased scores compared to the first assessment.\nTABLE I POLISHING STAGE QUESTIONNAIRE SCORE\nQuestions Average score Standard deviation\nQ. 1 (a-d) (3.6 3.93 5 4) (0.45 0.75 0 0.57) Q. 2 (a-d) (4.04 4.44 5 4.86) (0.36 0.5 0 0.34) Q. 3 5 0 Q. 4 3.64 0.77 Q. 5 4.26 0.49 GQ 4.35 0.22\nTABLE II VALIDATION QUESTIONNAIRE SCORE\nQuestions Average score Standard deviation\nQ. 1 (a-d) (5 5 5 5) (0 0 0 0) Q. 2 (a-d) (4.97 4.53 5 5) (0.14 0.5 0 0) Q. 3 5 0 Q. 4 4.64 0.48 Q. 5 4.53 0.50 GQ 4.83 0.18"}, {"heading": "V. APPLICATION CONCEPTUALIZATION", "text": "The solution we have presented addresses a specific practical problem by solving the need for providing 315 daily short term weather forecasts, which otherwise would not be possible to produce if they were manually created by a single meteorologist. As a consequence, the NLG stage is problem-oriented and is mostly not reusable. In spite of this, we want to stress the role that linguistic descriptions of data (LDD) techniques can play as a generic toolset which can be applied to many domains and give some insights into the generic methodology we are following for this LDD approach. For example, our application includes highly configurable linguistic description operators, which allow data series of any length and linguistic variables (implemented as fuzzy or crisp membership functions) with any number of labels as input. In fact, most of the changes made to improve the application during the whole development process were made to the linguistic variable definitions used by these operators (some of which are shown in Fig. 20) rather than to the operators themselves.\nFrom our point of view, the main purpose of creating linguistic description solutions is to provide users with descriptions which make use of easily understandable familiar concepts found in natural language, imprecise and ambiguous in their nature. These concepts are usually modeled by employing some of the theoretical tools provided by the Computation With Perceptions field, such as fuzzy quantifiers, linguistic variables and others. However, the fact that these descriptions include linguistic terms neither implies they are actually expressed in natural language nor means they should be, as it occurs in NLG systems. In fact, both research fields seem rather complementary, in such a way that LDD provides tools for extracting the most relevant information in the form of (imprecise) linguistic terms, which then are used as an input to a NLG system to produce well-constructed sentences which are ready for human consumption. This is the approach we have followed in our solution, where LDD operators create input descriptions for an independent NLG system which generates natural language forecasts.\nWith a clearer view of which aspects LDD, in our opinion, should cover, we can abstract the basic elements which serve as pillars for a general LDD methodology. Many of the approaches described in the literature (e.g. those referred to in Section I) share several elements in common that can be taken into account for a flexible and reusable methodology for generating linguistic descriptions approaches:\n\u2022 Operators. Operators extract information from raw data, converting numeric measurements into structures composed of linguistic terms. Originally, linguistic descriptions were con-\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\nceived as quantified sentences, which resulted from applying fuzzy quantification models to data series. Therefore, many of the existing approaches use some kind of fuzzy quantification to obtain descriptions over one or several variables. For example, we can apply Zadeh\u2019s or other quantification models to produce a summary like \u201cMost days of the month were dry\u201d (in the case of rain data time series). However, many other operators which extract different pieces of information can be defined and implemented [29], such as: evaluation of a fuzzy label over the data series (e.g. \u201cMost of the temperatures were high in March\u201d), search of data sequences fulfilling a given fuzzy label (e.g. \u201cEnergy consumption was low between days 3 and 10\u201d), search of increasing or decreasing patterns (e.g. \u201cThere was a slight increase of valve pressure during the morning\u201d), search of pitches in the dataset or of oscillation patterns (e.g. \u201cThe system got unstable between 10:00 and 10:30\u201d), event-counting operators (e.g. \u201cThere were too many high pitches within the last hours\u201d) or summarizing operators based on temporal/spatial hierarchies (e.g. \u201cThe month was hot but the first week was cold\u201d). For instance, for our LDD approach we have created highly configurable operators for each weather variable, according to the type of information that we needed to extract. These operators can be applied straightforwardly to other variables by just replacing the partition sets for the current variables with partition sets for the new ones. \u2022 Use of temporal/spatial hierarchies. In the majority of cases, the numeric data series have an associated temporal and/or spatial component. This allows to arrange the data in hierarchies, which are usually defined by the experts in the application field. For example, in a temperature data series which covers one year, with one measurement per day, we can define a temporal hierarchy which would group the individual days in months, the months in seasons and so on. This considerably improves the exploitation of the available data, allowing to extract richer and more complex information. In our case, we have employed a time hierarchy which divides the shortterm forecast temporal window into three subperiods for cloud coverage. \u2022 Operator compositions. Operators can be considered as the core primitives or atomic logical units of a framework which generates linguistic descriptions. These units can be combined in order to build more complex descriptions, depending on the requirements of the specific linguistic description problem. Therefore, means for mixing their outputs should be taken into account as additional elements in our framework. Our LDD approach does not make use of this concept, since the linguistic descriptions we obtain for each variable are independent. \u2022 Evaluation criteria. The raw output of linguistic description approaches usually consists of several candidate descriptions which must be filtered according to some pre-defined criteria, in order to ensure the quality and truthfulness of the selected final summary. Again, every specific problem needs its own set of adapted criteria, but also some general objective and reusable evaluation criteria, such as the description length, truth or fulfillment degree, data coverage, ambiguity, etc. should be used [29]. In our case, we have employed the aggregation of fulfillment degrees of each fuzzy subperiod with respect to each cloud coverage label to obtain the best cloud\ncoverage for each subperiod. Furthermore, we have also used the length of descriptions in order to discriminate the final precipitation text forecast.\nAlthough all of these are concepts and notions taken from experience, we believe the main value of this methodology lies in the operators as the building blocks of the LDD approaches. If a collection of well-tested both in quality and usefulness operators for linguistic description of data is gathered, the viability of a generic LDD framework to create domain-specific approaches is highly ensured. In order to achieve this, we propose a feedback process which combines bottom-up and top-down approaches. On one hand, we believe that the best way to ensure the usefulness of the operators is to generalize specific solutions taken from real life problems and test them in other contexts. On the other hand, intuition-based operators can also be proposed and tested to check whether the information they produce is relevant to the experts. This loop which goes from concrete to abstract and then vice versa would help to improve in a correct direction the general LDD framework."}, {"heading": "VI. CONCLUSIONS AND FUTURE WORK", "text": "We have presented GALiWeather, an application which obtains textual short-term weather forecasts for the 315 municipalities in Galicia, using the real data provided by MeteoGalicia. As opposed to other linguistic descriptions approaches, this solution is based on an applied development in a realistic application, whose definition and structure is inspired by the linguistic descriptions research field by using both fuzzy and crisp operators which extract relevant information, and also by the natural language generation field.\nFurthermore, the automatically generated textual forecasts were thoroughly evaluated by a meteorologist in order to assess the quality of their contents and to check whether his expert knowledge was included correctly. The obtained results show that the textual forecasts fulfill the expert\u2019s requirements in a very high degree (4.83 out of 5). GALiWeather is to be released as a real service in a very near future, since the application fully meets the meteorologists\u2019 requirements. The automatic linguistic descriptions will be displayed as a new information service at MeteoGalicia\u2019s website [33].\nThe main value of GALiWeather resides in its ability to cover and support a service of high interest for a wide number of users, which can only be provided by generating descriptions of data in an automatic manner, due to the high number of textual forecasts (315 in this case) which must be obtained.\nIn a longer term we are considering other application fields in which linguistic descriptions will prove useful. Among them, we have identified linguistic descriptions on information and decision support environmental systems as a promising research line, where not only linguistic descriptions for single location data are interesting, but also descriptions which geographically aggregate data in order to provide region-wide information. This is a complex challenge which will include the description of data in both time and space dimensions. This will lead us to develop a general model which can be applied to application fields in other areas."}, {"heading": "ACKNOWLEDGMENTS", "text": "The authors would like to thank the editors and referees for their comments and suggestions, which have led to a substantial\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\nimprovement in the paper quality. We would also like to thank CITIUS and MeteoGalicia for their support and for providing personal and material means for the development of this application.\nREFERENCES\n[1] E. Comission. (2011, December) Open data. an engine for innovation, growth and transparent governance. [Online]. Available: http://www.ipex.eu/ IPEXL-WEB/dossier/document/COM20110882.do [2] N. Kroes. (2012, March) Speech/12/149 digital agenda and open data from crisis of trust to open governing. Presentation of the Action Plan of the Slovak Republic in favour of Open Democracy. [Online]. Available: http://europa.eu/rapid/press-release SPEECH-12-149 en.htm [3] U. Fayyad, G. Piatetsky-shapiro, and P. Smyth, \u201cFrom data mining to knowledge discovery in databases,\u201d AI Magazine, vol. 17, pp. 37\u201354, 1996. [4] A. Fu, \u201cData mining,\u201d Potentials, IEEE, vol. 16, no. 4, pp. 18\u201320, 1997. [5] K. Kukich, \u201cDesign and implementation of a knowledge-based report gen-\nerator,\u201d in Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics (ACL-1983), 1983, pp. 145\u2013150. [6] L. Iordanskaja, M. Kim, R. Kittredge, B. Lavoie, and A. Polgue\u0300re, \u201cGeneration of extended bilingual statistical reports,\u201d in Proceedings of the 14th International Conference on Computational Linguistics (COLING-1992), vol. 3, 1992, pp. 1019\u20131023. [7] M. T. Maybury, \u201cGenerating summaries from event data,\u201d Information Processing And Management, vol. 31, no. 5, pp. 735 \u2013 751, 1995. [8] S. Busemann and H. Horacek, \u201cGenerating air-quality reports from environmental data,\u201d in DFKI Workshop on Natural Language Generation, DFKI Document D-97-06, S. Busemann, T. Becker, and W. Finkler, Eds., 1997. [9] S. Boyd, \u201cTrend: A system for generating intelligent descriptions of timeseries data,\u201d in Proceedings of the IEEE International Conference on Intelligent Processing Systems (ICIPS-1998, 1998. [10] F. Portet, E. Reiter, A. Gatt, J. Hunter, S. Sripada, Y. Freer, and C. Sykes, \u201cAutomatic generation of textual summaries from neonatal intensive care data,\u201d Artif. Intell., vol. 173, no. 7-8, pp. 789\u2013816, May 2009. [11] E. Goldberg, N. Driedger, and R. Kittredge, \u201cUsing natural-language processing to produce weather forecasts,\u201d IEEE Expert, vol. 9, no. 2, pp. 45\u201353, 1994. [12] J. Coch, \u201cInteractive generation and knowledge administration in multimeteo,\u201d in Proceedings of the Ninth International Workshop on Natural-Language Generation (INLG-1996), 1998, pp. 300\u2013303. [13] E. Reiter, S. Sripada, J. Hunter, and I. Davy, \u201cChoosing words in computergenerated weather forecasts,\u201d Artificial Intelligence, vol. 167, pp. 137\u2013169, 2005. [14] S. Sripada, E. Reiter, and I. Davy, \u201cSumtimemousam: Configurable marine weather forecast generator,\u201d Expert Update, vol. 6, no. 3, pp. 4\u201310, 2003. [15] L. A. Zadeh, \u201cFuzzy logic = computing with words,\u201d Fuzzy Systems, IEEE Transactions on, vol. 4, no. 2, pp. 103\u2013111, 1996. [16] \u2014\u2014, \u201cFrom computing with numbers to computing with words : From manipulation of measurements to manipulation of perceptions,\u201d in Intelligent Systems and Soft Computing: Prospects, Tools and Applications. SpringerVerlag, 2000, pp. 3\u201340. [17] J. Mendel, \u201cThe perceptual computer: an architecture for computing with words,\u201d in Fuzzy Systems, 2001. The 10th IEEE International Conference on, vol. 1, 2001, pp. 35\u201338. [18] R. R. Yager, K. M. Ford, and A. J. Can\u0303as, \u201cAn approach to the linguistic summarization of data,\u201d in Uncertainty in Knowledge Bases, 3rd International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems, IPMU 90, Paris, France, July 2-6, 1990, Proceedings, ser. Lecture Notes in Computer Science, B. Bouchon-Meunier, R. R. Yager, and L. A. Zadeh, Eds., vol. 521. Springer, 1990, pp. 456\u2013468. [19] J. Kacprzyk and S. Zadrozny, \u201cLinguistic database summaries and their protoforms: towards natural language based knowledge discovery tools,\u201d Inf. Sci. Inf. Comput. Sci., vol. 173, no. 4, pp. 281\u2013304, 2005. [20] G. Trivino and M. Sugeno, \u201cTowards linguistic descriptions of phenomena,\u201d International Journal of Approximate Reasoning, vol. 54, no. 1, pp. 22 \u2013 34, January 2013. [21] R. Castillo-Ortega, N. Mar\u0131\u0301n, and D. Sa\u0301nchez, \u201cA fuzzy approach to the linguistic summarization of time series,\u201d Multiple-Valued Logic and Soft Computing, pp. 157\u2013182, 2011. [22] A. van der Heide and G. Trivino, \u201cAutomatic generated linguistic summaries of energy consumption data,\u201d in Proceedings of 9th ISDA Conference, 2009, pp. 553\u2013559. [23] D. Sanchez-Valdes, L. Eciolaza, and G. Trivino, \u201cLinguistic description of human activity based on mobile phone\u2019s accelerometers,\u201d in Ambient Assisted Living and Home Care, ser. Lecture Notes in Computer Science, J. Bravo, R. Herva\u0301s, and M. Rodr\u0131\u0301guez, Eds. Springer Berlin Heidelberg, 2012, vol. 7657, pp. 346\u2013353.\n[24] A. Alvarez-Alvarez and G. Trivino, \u201cLinguistic description of the human gait quality,\u201d Engineering Applications of Artificial Intelligence, vol. 26, no. 1, pp. 13 \u2013 23, 2013. [25] I. Kobayashi and N. Okumura, \u201cVerbalizing time-series data: With an example of stock price trends,\u201d in Proceedings IFSA/EUSFLAT Conf., 2009, pp. 234\u2013 239. [26] J. Kacprzyk, \u201cComputing with words is an implementable paradigm: Fuzzy queries, linguistic data summaries, and natural-language generation,\u201d IEEE Trans. Fuzzy Systems, pp. 451\u2013472, 2010. [27] J. Kacprzyk and A. Wilbik, \u201cUsing fuzzy linguistic summaries for the comparison of time series: an application to the analysis of investment fund quotations,\u201d in Proceedings IFSA/EUSFLAT Conf. 2009, 2009, pp. 1321\u20131326. [28] J. Kacprzyk and S. Zadrozny, \u201cLinguistic data summarization: A high scalability through the use of natural language?\u201d Scalable Fuzzy Algorithms for Data Management and Analysis: Methods and Design, pp. 214\u2013237, 2010. [29] F. D\u0131\u0301az-Hermida, A. Ramos-Soto, and A. Bugar\u0131\u0301n, \u201cOn the role of fuzzy quantified statements in linguistic summarization,\u201d in Proceedings of 11th International Conference on. Intelligent Systems Design and Applications (ISDA), 2011, pp. 166\u2013171. [30] R. Castillo-Ortega, N. Mar\u0131\u0301n, D. Sa\u0301nchez, and A. Tettamanzi, \u201cQuality assessment in linguistic summaries of data,\u201d in Advances in Computational Intelligence, ser. Communications in Computer and Information Science, S. Greco, B. Bouchon-Meunier, G. Coletti, M. Fedrizzi, B. Matarazzo, and R. Yager, Eds. Springer Berlin Heidelberg, 2012, vol. 298, pp. 285\u2013294. [31] C. Menendez and G. Trivino, \u201cSelection of the best suitable sentences in linguistic descriptions of data,\u201d in Advances in Computational Intelligence, ser. Communications in Computer and Information Science, S. Greco, B. BouchonMeunier, G. Coletti, M. Fedrizzi, B. Matarazzo, and R. Yager, Eds. Springer Berlin Heidelberg, 2012, vol. 298, pp. 295\u2013304. [32] GALiWeather reference website. [Online]. Available: http://citius.usc.es/ transferencia/demostradores-tecnoloxicos/GALiWeather [33] MeteoGalicia website. [Online]. Available: www.meteogalicia.es [34] L. A. Zadeh, \u201cA computational theory of dispositions,\u201d International Journal\nof Intelligent Systems, vol. 2, no. 1, pp. 39\u201363, 1987. [35] E. Reiter and R. Dale, Building Natural Language Generation Systems.\nCambridge University Press, 2000. [36] \u2014\u2014, \u201cBuilding applied natural language generation systems,\u201d Journal of\nNatural-Language Engineering, no. 3, pp. 57\u201387, 1997. [37] E. Reiter, \u201cTask-based evaluation of nlg systems: control vs real-world\ncontext,\u201d in Proceedings of the UCNLG+Eval: Language Generation and Evaluation Workshop, ser. UCNLG+EVAL \u201911, 2011, pp. 28\u201332. [38] A. Belz and E. Reiter, \u201cComparing automatic and human evaluation of nlg systems,\u201d in In Proc. EACL\u201906, 2006, pp. 313\u2013320. [39] R. Sambaraju, E. Reiter, R. Logie, A. McKinlay, C. McVittie, A. Gatt, and C. Sykes, \u201cWhat is in a text and what does it do: qualitative evaluations of an nlg system \u2013 the bt-nurse \u2013 using content analysis and discourse analysis,\u201d in Proceedings of the 13th European Workshop on Natural Language Generation, ser. ENLG \u201911. Association for Computational Linguistics, 2011, pp. 22\u201331. [40] L. Eciolaza, M. Pereira-Farin\u0303a, and G. Trivino, \u201cAutomatic linguistic reporting in driving simulation environments,\u201d Applied Soft Computing, vol. 13, no. 9, pp. 3956 \u2013 3967, 2013.\nAlejandro Ramos received the M.S.c. degree in computer science from the University of Santiago de Compostela (USC), Spain, in 2011. He is currently a Ph.D. student at its Research Centre on Information Technologies (CiTIUS). His research interests include Linguistic Descriptions of Data and Natural Language Generation.\nAlberto J. Bugar\u0131\u0301n received the Ph.D. degree in physics from the University of Santiago de Compostela (USC), Spain, in 1994. He is currently a Full Professor at its Research Centre on Information Technologies (CiTIUS). His research interests mainly focus on Linguistic Data Description of Data using Natural Language Generation, Machine Learning techniques for fuzzy knowledge bases discovery and Fuzzy Temporal knowledge representation and reasoning. On these and related topics and their applications he has published more than 150 scientific refereed papers and participated in more than 40 R+D projects and\ncontracts.\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.\nSene\u0301n Barro received the Ph.D. in physics with distinction from the University of Santiago de Compostela (USC), Spain, in 1988. He is Professor in the area of Computer Science and Artificial Intelligence. He was head of the Computer and Electronic Department of the University of Santiago de Compostela from 1993 to 2002, and the rector of this university from 2002 to 2010. Since May 2008 he is the president of RedEmprendia, which is made of 24 European and Latin American universities, focused on transfer on R&D, innovation and entrepreneurship. He founded the USC Intelligent Systems Group, which he\nalso directs, and which currently has more than 40 members and is one of the first Artificial Intelligence groups in Spain. He has been editor or author of seven books and author of more than 200 scientific articles. He has also been member of organizing, scientific and publishing committees of international conferences and journals.\nJuan Taboada received the Ph.D. Degree in physics from the University of Santiago de Compostela (USC), Spain, in 1999, after a two-year stage in the University of Paris VI. He currently leads the operational weather forecast department in MeteoGalicia, the Galician (NW Spain) Meteorological Agency. His research areas include climate variability and change, and seasonal and weather forecasting.\n1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information."}], "references": [{"title": "December) Open data. an engine for innovation, growth and transparent governance", "author": ["E. Comission"], "venue": "http://www.ipex.eu/", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "March) Speech/12/149 digital agenda and open data from crisis of trust to open governing. Presentation of the Action Plan of the Slovak Republic in favour of Open Democracy", "author": ["N. Kroes"], "venue": "en.htm", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "From data mining to knowledge discovery in databases", "author": ["U. Fayyad", "G. Piatetsky-shapiro", "P. Smyth"], "venue": "AI Magazine, vol. 17, pp. 37\u201354, 1996.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "Data mining", "author": ["A. Fu"], "venue": "Potentials, IEEE, vol. 16, no. 4, pp. 18\u201320, 1997.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1997}, {"title": "Design and implementation of a knowledge-based report generator", "author": ["K. Kukich"], "venue": "Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics (ACL-1983), 1983, pp. 145\u2013150.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1983}, {"title": "Generation of extended bilingual statistical reports", "author": ["L. Iordanskaja", "M. Kim", "R. Kittredge", "B. Lavoie", "A. Polgu\u00e8re"], "venue": "Proceedings of the 14th International Conference on Computational Linguistics (COLING-1992), vol. 3, 1992, pp. 1019\u20131023.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1992}, {"title": "Generating summaries from event data", "author": ["M.T. Maybury"], "venue": "Information Processing And Management, vol. 31, no. 5, pp. 735 \u2013 751, 1995.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1995}, {"title": "Generating air-quality reports from environmental data", "author": ["S. Busemann", "H. Horacek"], "venue": "DFKI Workshop on Natural Language Generation, DFKI Document D-97-06, S. Busemann, T. Becker, and W. Finkler, Eds., 1997.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1997}, {"title": "Trend: A system for generating intelligent descriptions of timeseries data", "author": ["S. Boyd"], "venue": "Proceedings of the IEEE International Conference on Intelligent Processing Systems (ICIPS-1998, 1998.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "Automatic generation of textual summaries from neonatal intensive care data", "author": ["F. Portet", "E. Reiter", "A. Gatt", "J. Hunter", "S. Sripada", "Y. Freer", "C. Sykes"], "venue": "Artif. Intell., vol. 173, no. 7-8, pp. 789\u2013816, May 2009.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Using natural-language processing to produce weather forecasts", "author": ["E. Goldberg", "N. Driedger", "R. Kittredge"], "venue": "IEEE Expert, vol. 9, no. 2, pp. 45\u201353, 1994.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1994}, {"title": "Interactive generation and knowledge administration in multimeteo", "author": ["J. Coch"], "venue": "Proceedings of the Ninth International Workshop on Natural-Language Generation (INLG-1996), 1998, pp. 300\u2013303.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1996}, {"title": "Choosing words in computergenerated weather forecasts", "author": ["E. Reiter", "S. Sripada", "J. Hunter", "I. Davy"], "venue": "Artificial Intelligence, vol. 167, pp. 137\u2013169, 2005.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "Sumtimemousam: Configurable marine weather forecast generator", "author": ["S. Sripada", "E. Reiter", "I. Davy"], "venue": "Expert Update, vol. 6, no. 3, pp. 4\u201310, 2003.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "Fuzzy logic = computing with words", "author": ["L.A. Zadeh"], "venue": "Fuzzy Systems, IEEE Transactions on, vol. 4, no. 2, pp. 103\u2013111, 1996.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1996}, {"title": "From computing with numbers to computing with words : From manipulation of measurements to manipulation of perceptions", "author": ["\u2014\u2014"], "venue": "Intelligent Systems and Soft Computing: Prospects, Tools and Applications. Springer- Verlag, 2000, pp. 3\u201340.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2000}, {"title": "The perceptual computer: an architecture for computing with words", "author": ["J. Mendel"], "venue": "Fuzzy Systems, 2001. The 10th IEEE International Conference on, vol. 1, 2001, pp. 35\u201338.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2001}, {"title": "An approach to the linguistic summarization of data", "author": ["R.R. Yager", "K.M. Ford", "A.J. Ca\u00f1as"], "venue": "Uncertainty in Knowledge Bases, 3rd International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems, IPMU 90, Paris, France, July 2-6, 1990, Proceedings, ser. Lecture Notes in Computer Science, B. Bouchon-Meunier, R. R. Yager, and L. A. Zadeh, Eds., vol. 521. Springer, 1990, pp. 456\u2013468.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1990}, {"title": "Linguistic database summaries and their protoforms: towards natural language based knowledge discovery tools", "author": ["J. Kacprzyk", "S. Zadrozny"], "venue": "Inf. Sci. Inf. Comput. Sci., vol. 173, no. 4, pp. 281\u2013304, 2005.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2005}, {"title": "Towards linguistic descriptions of phenomena", "author": ["G. Trivino", "M. Sugeno"], "venue": "International Journal of Approximate Reasoning, vol. 54, no. 1, pp. 22 \u2013 34, January 2013.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "A fuzzy approach to the linguistic summarization of time series", "author": ["R. Castillo-Ortega", "N. Mar\u0131\u0301n", "D. S\u00e1nchez"], "venue": "Multiple-Valued Logic and Soft Computing, pp. 157\u2013182, 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic generated linguistic summaries of energy consumption data", "author": ["A. van der Heide", "G. Trivino"], "venue": "Proceedings of 9th ISDA Conference, 2009, pp. 553\u2013559.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Linguistic description of human activity based on mobile phone\u2019s accelerometers", "author": ["D. Sanchez-Valdes", "L. Eciolaza", "G. Trivino"], "venue": "Ambient Assisted Living and Home Care, ser. Lecture Notes in Computer Science, J. Bravo, R. Herv\u00e1s, and M. Rodr\u0131\u0301guez, Eds. Springer Berlin Heidelberg, 2012, vol. 7657, pp. 346\u2013353.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Linguistic description of the human gait quality", "author": ["A. Alvarez-Alvarez", "G. Trivino"], "venue": "Engineering Applications of Artificial Intelligence, vol. 26, no. 1, pp. 13 \u2013 23, 2013.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Verbalizing time-series data: With an example of stock price trends", "author": ["I. Kobayashi", "N. Okumura"], "venue": "Proceedings IFSA/EUSFLAT Conf., 2009, pp. 234\u2013 239.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Computing with words is an implementable paradigm: Fuzzy queries, linguistic data summaries, and natural-language generation", "author": ["J. Kacprzyk"], "venue": "IEEE Trans. Fuzzy Systems, pp. 451\u2013472, 2010.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "Using fuzzy linguistic summaries for the comparison of time series: an application to the analysis of investment fund quotations", "author": ["J. Kacprzyk", "A. Wilbik"], "venue": "Proceedings IFSA/EUSFLAT Conf. 2009, 2009, pp. 1321\u20131326.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2009}, {"title": "Linguistic data summarization: A high scalability through the use of natural language?", "author": ["J. Kacprzyk", "S. Zadrozny"], "venue": "Scalable Fuzzy Algorithms for Data Management and Analysis: Methods and Design,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "On the role of fuzzy quantified statements in linguistic summarization", "author": ["F. D\u0131\u0301az-Hermida", "A. Ramos-Soto", "A. Bugar\u0131\u0301n"], "venue": "Proceedings of 11th International Conference on. Intelligent Systems Design and Applications (ISDA), 2011, pp. 166\u2013171.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Quality assessment in linguistic summaries of data", "author": ["R. Castillo-Ortega", "N. Mar\u0131\u0301n", "D. S\u00e1nchez", "A. Tettamanzi"], "venue": "Advances in Computational Intelligence, ser. Communications in Computer and Information Science, S. Greco, B. Bouchon-Meunier, G. Coletti, M. Fedrizzi, B. Matarazzo, and R. Yager, Eds. Springer Berlin Heidelberg, 2012, vol. 298, pp. 285\u2013294.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "Selection of the best suitable sentences in linguistic descriptions of data", "author": ["C. Menendez", "G. Trivino"], "venue": "Advances in Computational Intelligence, ser. Communications in Computer and Information Science, S. Greco, B. Bouchon- Meunier, G. Coletti, M. Fedrizzi, B. Matarazzo, and R. Yager, Eds. Springer Berlin Heidelberg, 2012, vol. 298, pp. 295\u2013304.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2012}, {"title": "A computational theory of dispositions", "author": ["L.A. Zadeh"], "venue": "International Journal of Intelligent Systems, vol. 2, no. 1, pp. 39\u201363, 1987.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1987}, {"title": "Building Natural Language Generation Systems", "author": ["E. Reiter", "R. Dale"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2000}, {"title": "Building applied natural language generation systems", "author": ["\u2014\u2014"], "venue": "Journal of Natural-Language Engineering, no. 3, pp. 57\u201387, 1997.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1997}, {"title": "Task-based evaluation of nlg systems: control vs real-world context", "author": ["E. Reiter"], "venue": "Proceedings of the UCNLG+Eval: Language Generation and Evaluation Workshop, ser. UCNLG+EVAL \u201911, 2011, pp. 28\u201332.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2011}, {"title": "Comparing automatic and human evaluation of nlg systems", "author": ["A. Belz", "E. Reiter"], "venue": "In Proc. EACL\u201906, 2006, pp. 313\u2013320.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2006}, {"title": "What is in a text and what does it do: qualitative evaluations of an nlg system \u2013 the bt-nurse \u2013 using content analysis and discourse analysis", "author": ["R. Sambaraju", "E. Reiter", "R. Logie", "A. McKinlay", "C. McVittie", "A. Gatt", "C. Sykes"], "venue": "Proceedings of the 13th European Workshop on Natural Language Generation, ser. ENLG \u201911. Association for Computational Linguistics, 2011, pp. 22\u201331.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": ", all the data that public bodies in a given country produce, collect or pay for, which is widely known as the Open Data paradigm [1].", "startOffset": 130, "endOffset": 133}, {"referenceID": 1, "context": "This scenario has been described very graphically with the following statement \u201cdata is the new oil for the digital age\u201d [2].", "startOffset": 121, "endOffset": 124}, {"referenceID": 2, "context": "Originally, this objective has been assumed by the knowledge discovery in databases (KDD) field, but more specifically by its core stage, the data mining field [3], which assembles several tasks such as classification, association, clustering, trend analysis or summarization [4].", "startOffset": 160, "endOffset": 163}, {"referenceID": 3, "context": "Originally, this objective has been assumed by the knowledge discovery in databases (KDD) field, but more specifically by its core stage, the data mining field [3], which assembles several tasks such as classification, association, clustering, trend analysis or summarization [4].", "startOffset": 276, "endOffset": 279}, {"referenceID": 4, "context": "Several NLG approaches which generated summaries of data include ANA [5], which generated summaries of stock market activity; LFS [6], which generated summaries of statistical data; SUMGEN [7], which generated summaries of events in a battle simulation; TEMSIS [8], which generated summaries of environmental data; TREND [9], which generated summaries of historical weather data; and, more recently, BabyTalk [10], which generates medical reports for neonatal intensive care data.", "startOffset": 69, "endOffset": 72}, {"referenceID": 5, "context": "Several NLG approaches which generated summaries of data include ANA [5], which generated summaries of stock market activity; LFS [6], which generated summaries of statistical data; SUMGEN [7], which generated summaries of events in a battle simulation; TEMSIS [8], which generated summaries of environmental data; TREND [9], which generated summaries of historical weather data; and, more recently, BabyTalk [10], which generates medical reports for neonatal intensive care data.", "startOffset": 130, "endOffset": 133}, {"referenceID": 6, "context": "Several NLG approaches which generated summaries of data include ANA [5], which generated summaries of stock market activity; LFS [6], which generated summaries of statistical data; SUMGEN [7], which generated summaries of events in a battle simulation; TEMSIS [8], which generated summaries of environmental data; TREND [9], which generated summaries of historical weather data; and, more recently, BabyTalk [10], which generates medical reports for neonatal intensive care data.", "startOffset": 189, "endOffset": 192}, {"referenceID": 7, "context": "Several NLG approaches which generated summaries of data include ANA [5], which generated summaries of stock market activity; LFS [6], which generated summaries of statistical data; SUMGEN [7], which generated summaries of events in a battle simulation; TEMSIS [8], which generated summaries of environmental data; TREND [9], which generated summaries of historical weather data; and, more recently, BabyTalk [10], which generates medical reports for neonatal intensive care data.", "startOffset": 261, "endOffset": 264}, {"referenceID": 8, "context": "Several NLG approaches which generated summaries of data include ANA [5], which generated summaries of stock market activity; LFS [6], which generated summaries of statistical data; SUMGEN [7], which generated summaries of events in a battle simulation; TEMSIS [8], which generated summaries of environmental data; TREND [9], which generated summaries of historical weather data; and, more recently, BabyTalk [10], which generates medical reports for neonatal intensive care data.", "startOffset": 321, "endOffset": 324}, {"referenceID": 9, "context": "Several NLG approaches which generated summaries of data include ANA [5], which generated summaries of stock market activity; LFS [6], which generated summaries of statistical data; SUMGEN [7], which generated summaries of events in a battle simulation; TEMSIS [8], which generated summaries of environmental data; TREND [9], which generated summaries of historical weather data; and, more recently, BabyTalk [10], which generates medical reports for neonatal intensive care data.", "startOffset": 409, "endOffset": 413}, {"referenceID": 10, "context": "A few systems, such as FoG [11], MultiMeteo [12] and SUMTIME-MOUSAM [13], [14], have been used by meteorological agencies to automatically produce public weather forecasts.", "startOffset": 27, "endOffset": 31}, {"referenceID": 11, "context": "A few systems, such as FoG [11], MultiMeteo [12] and SUMTIME-MOUSAM [13], [14], have been used by meteorological agencies to automatically produce public weather forecasts.", "startOffset": 44, "endOffset": 48}, {"referenceID": 12, "context": "A few systems, such as FoG [11], MultiMeteo [12] and SUMTIME-MOUSAM [13], [14], have been used by meteorological agencies to automatically produce public weather forecasts.", "startOffset": 68, "endOffset": 72}, {"referenceID": 13, "context": "A few systems, such as FoG [11], MultiMeteo [12] and SUMTIME-MOUSAM [13], [14], have been used by meteorological agencies to automatically produce public weather forecasts.", "startOffset": 74, "endOffset": 78}, {"referenceID": 14, "context": "At the same time, within the fuzzy logic and soft computing field, the paradigm of computing with words (CWW) [15], and its later evolution computing with perceptions (CWP) [16], [17], made their appearance in the 1990s.", "startOffset": 110, "endOffset": 114}, {"referenceID": 15, "context": "At the same time, within the fuzzy logic and soft computing field, the paradigm of computing with words (CWW) [15], and its later evolution computing with perceptions (CWP) [16], [17], made their appearance in the 1990s.", "startOffset": 173, "endOffset": 177}, {"referenceID": 16, "context": "At the same time, within the fuzzy logic and soft computing field, the paradigm of computing with words (CWW) [15], and its later evolution computing with perceptions (CWP) [16], [17], made their appearance in the 1990s.", "startOffset": 179, "endOffset": 183}, {"referenceID": 15, "context": "As opposed to other classical approaches, these paradigms involve a fusion of natural languages and computation with linguistic variables [16].", "startOffset": 138, "endOffset": 142}, {"referenceID": 17, "context": "Although many new approaches based on CWW have emerged, one of the most promising tools is linguistic data summarization [18], [19], which employs fuzzy quantified propositions to obtain linguistic summaries involving one variable (as in \u201cMost of the dogs are brown\u201d or \u201cA few trees are tall\u201d) or more than one variable (as in ar X iv :1 41 1.", "startOffset": 121, "endOffset": 125}, {"referenceID": 18, "context": "Although many new approaches based on CWW have emerged, one of the most promising tools is linguistic data summarization [18], [19], which employs fuzzy quantified propositions to obtain linguistic summaries involving one variable (as in \u201cMost of the dogs are brown\u201d or \u201cA few trees are tall\u201d) or more than one variable (as in ar X iv :1 41 1.", "startOffset": 127, "endOffset": 131}, {"referenceID": 19, "context": "Since then, linguistic summarization from CWW has been applied in several practical cases and, with the appearance of CWP, some authors have started to refer to linguistic summaries as linguistic descriptions of data (LDD) [20], which understand linguistic summaries as a tool to describe human perceptions.", "startOffset": 223, "endOffset": 227}, {"referenceID": 20, "context": "Examples of fields of application of linguistic description approaches include descriptions of the patient inflow in health centers [21], domestic electric consumption reports [22], human activity based on mobile phone accelerometers [23] or human gait quality [24].", "startOffset": 132, "endOffset": 136}, {"referenceID": 21, "context": "Examples of fields of application of linguistic description approaches include descriptions of the patient inflow in health centers [21], domestic electric consumption reports [22], human activity based on mobile phone accelerometers [23] or human gait quality [24].", "startOffset": 176, "endOffset": 180}, {"referenceID": 22, "context": "Examples of fields of application of linguistic description approaches include descriptions of the patient inflow in health centers [21], domestic electric consumption reports [22], human activity based on mobile phone accelerometers [23] or human gait quality [24].", "startOffset": 234, "endOffset": 238}, {"referenceID": 23, "context": "Examples of fields of application of linguistic description approaches include descriptions of the patient inflow in health centers [21], domestic electric consumption reports [22], human activity based on mobile phone accelerometers [23] or human gait quality [24].", "startOffset": 261, "endOffset": 265}, {"referenceID": 24, "context": "Other approaches use more complex expressions involving relationships among different attributes (in economic data [25], in sales data [26] or the analysis of investment fund quotations [27]).", "startOffset": 115, "endOffset": 119}, {"referenceID": 25, "context": "Other approaches use more complex expressions involving relationships among different attributes (in economic data [25], in sales data [26] or the analysis of investment fund quotations [27]).", "startOffset": 135, "endOffset": 139}, {"referenceID": 26, "context": "Other approaches use more complex expressions involving relationships among different attributes (in economic data [25], in sales data [26] or the analysis of investment fund quotations [27]).", "startOffset": 186, "endOffset": 190}, {"referenceID": 27, "context": "Nevertheless, steps in this direction have been taken by providing general criteria on how to structure quantified sentences in order to obtain more complex descriptions [28] or on how to build and evaluate linguistic descriptions [29], [30], [31].", "startOffset": 170, "endOffset": 174}, {"referenceID": 28, "context": "Nevertheless, steps in this direction have been taken by providing general criteria on how to structure quantified sentences in order to obtain more complex descriptions [28] or on how to build and evaluate linguistic descriptions [29], [30], [31].", "startOffset": 231, "endOffset": 235}, {"referenceID": 29, "context": "Nevertheless, steps in this direction have been taken by providing general criteria on how to structure quantified sentences in order to obtain more complex descriptions [28] or on how to build and evaluate linguistic descriptions [29], [30], [31].", "startOffset": 237, "endOffset": 241}, {"referenceID": 30, "context": "Nevertheless, steps in this direction have been taken by providing general criteria on how to structure quantified sentences in order to obtain more complex descriptions [28] or on how to build and evaluate linguistic descriptions [29], [30], [31].", "startOffset": 243, "endOffset": 247}, {"referenceID": 25, "context": "Until now, both have followed separate paths, although it remains clear that both can contribute to each other in a substantial way [26].", "startOffset": 132, "endOffset": 136}, {"referenceID": 0, "context": ", cctn}, where each temporal linguistic term cctj has an associated fuzzy membership function \u03bccctj : N \u2192 [0, 1].", "startOffset": 106, "endOffset": 112}, {"referenceID": 0, "context": ", ccqn}, where each linguistic term ccqj has an associated fuzzy quantifier \u03bcccqj : [0, 1] \u2192 [0, 1].", "startOffset": 84, "endOffset": 90}, {"referenceID": 0, "context": ", ccqn}, where each linguistic term ccqj has an associated fuzzy quantifier \u03bcccqj : [0, 1] \u2192 [0, 1].", "startOffset": 93, "endOffset": 99}, {"referenceID": 31, "context": "This operator quantifies the occurrence of the different cloud coverage categories cclk using Zadeh\u2019s quantification model [34]:", "startOffset": 123, "endOffset": 127}, {"referenceID": 28, "context": "This includes evaluation criteria applicable to linguistic descriptions [29] such as the description length, but also NLG systems design methodologies as in [35] and [36].", "startOffset": 72, "endOffset": 76}, {"referenceID": 32, "context": "This includes evaluation criteria applicable to linguistic descriptions [29] such as the description length, but also NLG systems design methodologies as in [35] and [36].", "startOffset": 157, "endOffset": 161}, {"referenceID": 33, "context": "This includes evaluation criteria applicable to linguistic descriptions [29] such as the description length, but also NLG systems design methodologies as in [35] and [36].", "startOffset": 166, "endOffset": 170}, {"referenceID": 32, "context": "On the other hand, we have designed and implemented the generation of natural language sentences for precipitation inspired by standard NLG methodologies [35], [36].", "startOffset": 154, "endOffset": 158}, {"referenceID": 33, "context": "On the other hand, we have designed and implemented the generation of natural language sentences for precipitation inspired by standard NLG methodologies [35], [36].", "startOffset": 160, "endOffset": 164}, {"referenceID": 32, "context": "Based on the concepts of a NLG system architecture described in [35] and [36], we have designed and developed a NLG module for precipitation which addresses redundancy or length excess in Precipitation Episode NLG Generator Precipitation Day NLG Generator Precipitation Term NLG Generator", "startOffset": 64, "endOffset": 68}, {"referenceID": 33, "context": "Based on the concepts of a NLG system architecture described in [35] and [36], we have designed and developed a NLG module for precipitation which addresses redundancy or length excess in Precipitation Episode NLG Generator Precipitation Day NLG Generator Precipitation Term NLG Generator", "startOffset": 73, "endOffset": 77}, {"referenceID": 33, "context": "In [36], a NLG system is depicted as a six stage task, where one subtask is performed per stage.", "startOffset": 3, "endOffset": 7}, {"referenceID": 33, "context": "Content determination is defined in [36] as the process which decides what information should be communicated in the text.", "startOffset": 36, "endOffset": 40}, {"referenceID": 28, "context": "The final output sentence for precipitation will be the shortest of the three, since we want to ensure that the obtained natural language forecasts remain as concise and brief as possible [29].", "startOffset": 188, "endOffset": 192}, {"referenceID": 34, "context": "Validating automatic natural language generated texts is still an open challenge, even within the NLG field [37].", "startOffset": 108, "endOffset": 112}, {"referenceID": 35, "context": "Several validation approaches do exist, both human and automatic, although in general, the human validation by experts is considered the most reliable [38], [39].", "startOffset": 151, "endOffset": 155}, {"referenceID": 36, "context": "Several validation approaches do exist, both human and automatic, although in general, the human validation by experts is considered the most reliable [38], [39].", "startOffset": 157, "endOffset": 161}, {"referenceID": 28, "context": "In the case of the LDD field several criteria have been proposed for evaluating and measuring the quality of the linguistic descriptions objectively [29], but they are not applicable in every approach and the information they provide is very limited compared to that of an expert, besides the fact that many LDD approaches do not reach the NLG stage and are not subject to a full validation process.", "startOffset": 149, "endOffset": 153}, {"referenceID": 28, "context": "However, many other operators which extract different pieces of information can be defined and implemented [29], such as: evaluation of a fuzzy label over the data series (e.", "startOffset": 107, "endOffset": 111}, {"referenceID": 28, "context": "should be used [29].", "startOffset": 15, "endOffset": 19}], "year": 2014, "abstractText": "1063-6706 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information. Abstract\u2014We present in this paper an application which automatically generates textual short-term weather forecasts for every municipality in Galicia (NW Spain), using the real data provided by the Galician Meteorology Agency (MeteoGalicia). This solution combines in an innovative way computing with perceptions techniques and strategies for linguistic description of data together with a natural language generation (NLG) system. The application, named GALiWeather, extracts relevant information from weather forecast input data and encodes it into intermediate descriptions using linguistic variables and temporal references. These descriptions are later translated into natural language texts by the natural language generation system. The obtained forecast results have been thoroughly validated by an expert meteorologist from MeteoGalicia using a quality assessment methodology which covers two key dimensions of a text: the accuracy of its content and the correctness of its form. Following this validation GALiWeather will be released as a real service offering custom forecasts for a wide public.", "creator": "LaTeX with hyperref package"}}}