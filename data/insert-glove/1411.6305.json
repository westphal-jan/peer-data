{"id": "1411.6305", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Nov-2014", "title": "Revenue Optimization in Posted-Price Auctions with Strategic Buyers", "abstract": "suti We study revenue optimization learning paymah algorithms thembinkosi for posted - siebengebirge price monteagle auctions manufacturers with mobi strategic kuensel buyers. We analyze a very persuaders broad rhizomatous family of monotone regret minimization shido algorithms ghazipur for villan this problem, danielyan which atlacatl includes conceding the epa previously macv best known luntz algorithm, vestnik and fichtel show maureen that no dirhams algorithm badrinath in that 98.7 family admits a strategic regret more referencing favorable family.com than $ \\ Omega (\\ ronan sqrt {clotheslined T} ) $. r\u00e9seau We 12-14 then introduce schwann a new algorithm macaranga that jamili achieves bisher a strategic lodish regret differing from bacevich the 2,374 lower mousepox bound only waitressing by saturay a factor in $ O (\\ repellent log T) $, an gobbler exponential anzhi improvement 29,200 upon the previous menning best 19.02 algorithm. 1308 Our new cos\u00ec algorithm miloud admits tyrving a disembowel natural losey analysis and simpler proofs, and hartono the ideas behind sub-committees its design are aksaray general. andsnes We also faletti report the 100.43 results coomera of empirical galitzine evaluations comparing arrhenius our algorithm alsagoff with julies the humps previous perim state delimitations of the attachments art arkestra and karada show a molano consistent exponential afro-guyanese improvement 5:49 in northest several locke different counterpropaganda scenarios.", "histories": [["v1", "Sun, 23 Nov 2014 21:58:29 GMT  (179kb,D)", "http://arxiv.org/abs/1411.6305v1", "At NIPS 2014"]], "COMMENTS": "At NIPS 2014", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mehryar mohri", "andres mu\\~noz medina"], "accepted": false, "id": "1411.6305"}, "pdf": {"name": "1411.6305.pdf", "metadata": {"source": "CRF", "title": "Revenue Optimization in Posted-Price Auctions with Strategic Buyers", "authors": ["Mehryar Mohri", "Andres Mu\u00f1oz"], "emails": ["mohri@cims.nyu.edu", "munoz@cims.nyu.edu"], "sections": [{"heading": null, "text": "\u221a T ). We then introduce a new algorithm that achieves a strategic regret\ndiffering from the lower bound only by a factor in O(log T ), an exponential improvement upon the previous best algorithm. Our new algorithm admits a natural analysis and simpler proofs, and the ideas behind its design are general. We also report the results of empirical evaluations comparing our algorithm with the previous state of the art and show a consistent exponential improvement in several different scenarios."}, {"heading": "1 Introduction", "text": "Auctions have long been an active area of research in Economics and Game Theory [Vickrey, 2012, Milgrom and Weber, 1982, Ostrovsky and Schwarz, 2011]. In the past decade, however, the advent of online advertisement has prompted a more algorithmic study of auctions, including the design of learning algorithms for revenue maximization for generalized second-price auctions or second-price auctions with reserve [Cesa-Bianchi et al., 2013, Mohri and Mun\u0303oz Medina, 2014, He et al., 2013].\nThese studies have been largely motivated by the widespread use of AdExchanges and the vast amount of historical data thereby collected \u2013 AdExchanges are advertisement selling platforms using second-price auctions with reserve price to allocate advertisement space. Thus far, the learning algorithms proposed for revenue maximization in these auctions critically rely on the assumption that the bids, that is, the outcomes of auctions, are drawn i.i.d. according to some unknown distribution. However, this assumption may not hold in practice. In particular, with the knowledge that a revenue optimization algorithm is being used, an advertiser could seek to mislead the publisher by under-bidding. In fact, consistent empirical evidence of strategic behavior by advertisers has been found by Edelman and Ostrovsky [2007]. This motivates the analysis presented in this paper of the interactions between sellers and strategic buyers, that is, buyers that may act non-truthfully with the goal of maximizing their surplus.\nThe scenario we consider is that of posted-price auctions, which, albeit simpler than other mechanisms, in fact matches a common situation in AdExchanges where many auctions admit a single bidder. In this setting, second-price auctions with reserve are equivalent to posted-price auctions: a seller sets a reserve price for a good and the buyer decides whether or not to accept it (that is to bid higher than the reserve price). In order to capture the buyer\u2019s strategic behavior, we will analyze an online scenario: at each time t, a price pt is offered by the seller and the buyer must decide to either accept it or leave it. This scenario can be modeled as a two-player repeated non-zero sum game with\nar X\niv :1\n41 1.\n63 05\nv1 [\ncs .L\nG ]\n2 3\nN ov\nincomplete information, where the seller\u2019s objective is to maximize his revenue, while the advertiser seeks to maximize her surplus as described in more detail in Section 2.\nThe literature on non-zero sum games is very rich [Nachbar, 1997, 2001, Morris, 1994], but much of the work in that area has focused on characterizing different types of equilibria, which is not directly relevant to the algorithmic questions arising here. Furthermore, the problem we consider admits a particular structure that can be exploited to design efficient revenue optimization algorithms.\nFrom the seller\u2019s perspective, this game can also be viewed as a bandit problem [Kuleshov and Precup, 2010, Robbins, 1985] since only the revenue (or reward) for the prices offered is accessible to the seller. Kleinberg and Leighton [2003] precisely studied this continuous bandit setting under the assumption of an oblivious buyer, that is, one that does not exploit the seller\u2019s behavior (more precisely, the authors assume that at each round the seller interacts with a different buyer). The authors presented a tight regret bound of \u0398(log log T ) for the scenario of a buyer holding a fixed valuation and a regret bound of O(T 2 3 ) when facing an adversarial buyer by using an elegant reduction to a discrete bandit problem. However, as argued by Amin et al. [2013], when dealing with a strategic buyer, the usual definition of regret is no longer meaningful. Indeed, consider the following example: let the valuation of the buyer be given by v \u2208 [0, 1] and assume that an algorithm with sublinear regret such as Exp3 [Auer et al., 2002b] or UCB [Auer et al., 2002a] is used for T rounds by the seller. A possible strategy for the buyer, knowing the seller\u2019s algorithm, would be to accept prices only if they are smaller than some small value , certain that the seller would eventually learn to offer only prices less than . If v, the buyer would considerably boost her surplus while, in theory, the seller would have not incurred a large regret since in hindsight, the best fixed strategy would have been to offer price for all rounds. This, however is clearly not optimal for the seller. The stronger notion of policy regret introduced by Arora et al. [2012] has been shown to be the appropriate one for the analysis of bandit problems with adaptive adversaries. However, for the example just described, a sublinear policy regret can be similarly achieved. Thus, this notion of regret is also not the pertinent one for the study of our scenario.\nWe will adopt instead the definition of strategic-regret, which was introduced by Amin et al. [2013] precisely for the study of this problem. This notion of regret also matches the concept of learning loss introduced by [Agrawal, 1995] when facing an oblivious adversary. Using this definition, Amin et al. [2013] presented both upper and lower bounds for the regret of a seller facing a strategic buyer and showed that the buyer\u2019s surplus must be discounted over time in order to be able to achieve sublinear regret (see Section 2). However, the gap between the upper and lower bounds they presented is in O( \u221a T ). In the following, we analyze a very broad family of monotone regret minimization algorithms for this problem (Section 3), which includes the algorithm of Amin et al. [2013], and show that no algorithm in that family admits a strategic regret more favorable than \u2126( \u221a T ). Next, we introduce a nearly-optimal algorithm that achieves a strategic regret differing from the lower bound at most by a factor in O(log T ) (Section 4). This represents an exponential improvement upon the existing best algorithm for this setting. Our new algorithm admits a natural analysis and simpler proofs. A key idea behind its design is a method deterring the buyer from lying, that is rejecting prices below her valuation."}, {"heading": "2 Setup", "text": "We consider the following game played by a buyer and a seller. A good, such as an advertisement space, is repeatedly offered for sale by the seller to the buyer over T rounds. The buyer holds a private valuation v \u2208 [0, 1] for that good. At each round t = 1, . . . , T , a price pt is offered by the seller and a decision at \u2208 {0, 1} is made by the buyer. at takes value 1 when the buyer accepts to buy at that price, 0 otherwise. We will say that a buyer lies whenever at = 0 while pt < v. At the beginning of the game, the algorithm A used by the seller to set prices is announced to the buyer. Thus, the buyer plays strategically against this algorithm. The knowledge of A is a standard assumption in mechanism design and also matches the practice in AdExchanges.\nFor any \u03b3 \u2208 (0, 1), define the discounted surplus of the buyer as follows:\nSur(A, v) = T\u2211 t=1 \u03b3t\u22121at(v \u2212 pt). (1)\nThe value of the discount factor \u03b3 indicates the strength of the preference of the buyer for current surpluses versus future ones. The performance of a seller\u2019s algorithm is measured by the notion of strategic-regret [Amin et al., 2013] defined as follows:\nReg(A, v) = Tv \u2212 T\u2211 t=1 atpt. (2)\nThe buyer\u2019s objective is to maximize his discounted surplus, while the seller seeks to minimize his regret. Note that, in view of the discounting factor \u03b3, the buyer is not fully adversarial. The problem consists of designing algorithms achieving sublinear strategic regret (that is a regret in o(T )).\nThe motivation behind the definition of strategic-regret is straightforward: a seller, with access to the buyer\u2019s valuation, can set a fixed price for the good close to this value. The buyer, having no control on the prices offered, has no option but to accept this price in order to optimize his utility. The revenue per round of the seller is therefore v\u2212 . Since there is no scenario where higher revenue can be achieved, this is a natural setting to compare the performance of our algorithm.\nTo gain more intuition about the problem, let us examine some of the complications arising when dealing with a strategic buyer. Suppose the seller attempts to learn the buyer\u2019s valuation v by performing a binary search. This would be a natural algorithm when facing a truthful buyer. However, in view of the buyer\u2019s knowledge of the algorithm, for \u03b3 0, it is in her best interest to lie on the initial rounds, thereby quickly, in fact exponentially, decreasing the price offered by the seller. The seller would then incur an \u2126(T ) regret. A binary search approach is therefore \u201ctoo aggressive\u201d. Indeed, an untruthful buyer can manipulate the seller into offering prices less than v/2 by lying about her value even just once! This discussion suggests following a more conservative approach. In the next section, we discuss a natural family of conservative algorithms for this problem."}, {"heading": "3 Monotone algorithms", "text": "The following conservative pricing strategy was introduced by Amin et al. [2013]. Let p1 = 1 and \u03b2 < 1. If price pt is rejected at round t, the lower price pt+1 = \u03b2pt is offered at the next round. If at any time price pt is accepted, then this price is offered for all the remaining rounds. We will denote this algorithm by monotone. The motivation behind its design is clear: for a suitable choice of \u03b2, the seller can slowly decrease the prices offered, thereby pressing the buyer to reject many prices (which is not convenient for her) before obtaining a favorable price. The authors present an O(T\u03b3 \u221a T ) regret bound for this algorithm, with T\u03b3 = 1/(1\u2212 \u03b3). A more careful analysis shows\nthat this bound can be further tightened to O( \u221a T\u03b3T + \u221a T ) when the discount factor \u03b3 is known to the seller.\nDespite its sublinear regret, the monotone algorithm remains sub-optimal for certain choices of \u03b3. Indeed, consider a scenario with \u03b3 1. For this setting, the buyer would no longer have an incentive to lie, thus, an algorithm such as binary search would achieve logarithmic regret, while the regret achieved by the monotone algorithm is only guaranteed to be in O( \u221a T ).\nOne may argue that the monotone algorithm is too specific since it admits a single parameter \u03b2 and that perhaps a more complex algorithm with the same monotonic idea could achieve a more favorable regret. Let us therefore analyze a generic monotone algorithmAm defined by Algorithm 1. Definition 1. For any buyer\u2019s valuation v \u2208 [0, 1], define the acceptance time \u03ba\u2217 = \u03ba\u2217(v) as the first time a price offered by the seller using algorithm Am is accepted. Proposition 1. For any decreasing sequence of prices (pt)Tt=1, there exists a truthful buyer with valuation v0 such that algorithm Am suffers regret of at least\nReg(Am, v0) \u2265 1\n4\n\u221a T \u2212 \u221a T .\nProof. By definition of the regret, we have Reg(Am, v) = v\u03ba\u2217 + (T \u2212 \u03ba\u2217)(v \u2212 p\u03ba\u2217). We can consider two cases: \u03ba\u2217(v0) > \u221a T for some v0 \u2208 [1/2, 1] and \u03ba\u2217(v) \u2264 \u221a T for every v \u2208 [1/2, 1].\nIn the former case, we have Reg(Am, v0) \u2265 v0 \u221a T \u2265 12 \u221a T , which implies the statement of the proposition. Thus, we can assume the latter condition.\nAlgorithm 1 Family of monotone algorithms. Let p1 = 1 and pt \u2264 pt\u22121 for t = 2, . . . T . t\u2190 1 p\u2190 pt Offer price p while (Buyer rejects p) and (t < T ) do\nt\u2190 t+ 1 p\u2190 pt Offer price p\nend while while (t < T ) do\nt\u2190 t+ 1 Offer price p\nend while\nAlgorithm 2 Definition of Ar . n = the root of T (T ) while Offered prices less than T do\nOffer price pn if Accepted then\nn = r(n) else\nOffer price pn for r rounds n = l(n)\nend if end while\nLet v be uniformly distributed over [ 12 , 1]. In view of Lemma 4 (see Appendix 8.1), we have\nE[v\u03ba\u2217] + E[(T \u2212 \u03ba\u2217)(v \u2212 p\u03ba\u2217)] \u2265 1\n2 E[\u03ba\u2217] + (T \u2212\n\u221a T )E[(v \u2212 p\u03ba\u2217)] \u2265 1\n2 E[\u03ba\u2217] +\nT \u2212 \u221a T 32E[\u03ba\u2217] .\nThe right-hand side is minimized for E[\u03ba\u2217] = \u221a T\u2212 \u221a T\n4 . Plugging in this value yields\nE[Reg(Am, v)] \u2265 \u221a T\u2212 \u221a T 4 , which implies the existence of v0 with Reg(Am, v0) \u2265 \u221a T\u2212 \u221a T 4 .\nWe have thus shown that any monotone algorithmAm suffers a regret of at least \u2126( \u221a T ), even when facing a truthful buyer. A tighter lower bound can be given under a mild condition on the prices offered.\nDefinition 2. A sequence (pt)Tt=1 is said to be convex if it verifies pt \u2212 pt+1 \u2265 pt+1 \u2212 pt+2 for t = 1, . . . , T \u2212 2.\nAn instance of a convex sequence is given by the prices offered by the monotone algorithm. A seller offering prices forming a decreasing convex sequence seeks to control the number of lies of the buyer by slowly reducing prices. The following proposition gives a lower bound on the regret of any algorithm in this family.\nProposition 2. Let (pt)Tt=1 be a decreasing convex sequence of prices. There exists a valuation v0 for the buyer such that the regret of the monotone algorithm defined by these prices is \u2126( \u221a TC\u03b3 +\u221a\nT ), where C\u03b3 = \u03b32(1\u2212\u03b3) .\nThe full proof of this proposition is given in Appendix 8.1. The proposition shows that when the discount factor \u03b3 is known, the monotone algorithm is in fact asymptotically optimal in its class.\nThe results just presented suggest that the dependency on T cannot be improved by any monotone algorithm. In some sense, this family of algorithms is \u201ctoo conservative\u201d. Thus, to achieve a more favorable regret guarantee, an entirely different algorithmic idea must be introduced. In the next section, we describe a new algorithm that achieves a substantially more advantageous strategic regret by combining the fast convergence properties of a binary search-type algorithm (in a truthful setting) with a method penalizing untruthful behaviors of the buyer."}, {"heading": "4 A nearly optimal algorithm", "text": "Let A be an algorithm for revenue optimization used against a truthful buyer. Denote by T (T ) the tree associated to A after T rounds. That is, T (T ) is a full tree of height T with nodes n \u2208 T (T ) labeled with the prices pn offered by A. The right and left children of n are denoted by r(n) and l(n) respectively. The price offered when pn is accepted by the buyer is the label of r(n) while the price offered by A if pn is rejected is the label of l(n). Finally, we will denote the left and right subtrees rooted at node n by L (n) and R(n) respectively. Figure 1 depicts the tree generated by an algorithm proposed by Kleinberg and Leighton [2003], which we will describe later.\nSince the buyer holds a fixed valuation, we will consider algorithms that increase prices only after a price is accepted and decrease it only after a rejection. This is formalized in the following definition. Definition 3. An algorithm A is said to be consistent if maxn\u2032\u2208L (n) pn\u2032 \u2264 pn \u2264 minn\u2032\u2208R(n) pn\u2032 for any node n \u2208 T (T ).\nFor any consistent algorithm A, we define a modified algorithm Ar, parametrized by an integer r \u2265 1, designed to face strategic buyers. Algorithm Ar offers the same prices as A, but it is defined with the following modification: when a price is rejected by the buyer, the seller offers the same price for r rounds. The pseudocode of Ar is given in Algorithm 2. The motivation behind the modified algorithm is given by the following simple observation: a strategic buyer will lie only if she is certain that rejecting a price will boost her surplus in the future. By forcing the buyer to reject a price for several rounds, the seller ensures that the future discounted surplus will be negligible, thereby coercing the buyer to be truthful.\nWe proceed to formally analyze algorithm Ar. In particular, we will quantify the effect of the parameter r on the choice of the buyer\u2019s strategy. To do so, a measure of the spread of the prices offered by Ar is needed. Definition 4. For any node n \u2208 T (T ) define the right increment of n as \u03b4rn := pr(n)\u2212pn. Similarly, define its left increment to be \u03b4ln := maxn\u2032\u2208L (n) pn \u2212 pn\u2032 .\nThe prices offered by Ar define a path in T (T ). For each node in this path, we can define time t(n) to be the number of rounds needed for this node to be reached by Ar. Note that, since r may be greater than 1, the path chosen by Ar might not necessarily reach the leaves of T (T ). Finally, let S : n 7\u2192 S(n) be the function representing the surplus obtained by the buyer when playing an optimal strategy against Ar after node n is reached. Lemma 1. The function S satisfies the following recursive relation:\nS(n) = max(\u03b3t(n)\u22121(v \u2212 pn) + S(r(n)),S(l(n))). (3)\nProof. Define a weighted tree T \u2032(T ) \u2282 T (T ) of nodes reachable by algorithm Ar. We assign weights to the edges in the following way: if an edge on T \u2032(T ) is of the form (n, r(n)), its weight is set to be \u03b3t(n)\u22121(v \u2212 pn), otherwise, it is set to 0. It is easy to see that the function S evaluates the weight of the longest path from node n to the leafs of T \u2032(T ). It thus follows from elementary graph algorithms that equation (3) holds.\nThe previous lemma immediately gives us necessary conditions for a buyer to reject a price. Proposition 3. For any reachable node n, if price pn is rejected by the buyer, then the following inequality holds:\nv \u2212 pn < \u03b3r\n(1\u2212 \u03b3)(1\u2212 \u03b3r) (\u03b4ln + \u03b3\u03b4 r n).\nProof. A direct implication of Lemma 1 is that price pn will be rejected by the buyer if and only if\n\u03b3t(n)\u22121(v \u2212 pn) + S(r(n)) < S(l(n)). (4)\nHowever, by definition, the buyer\u2019s surplus obtained by following any path in R(n) is bounded above by S(r(n)). In particular, this is true for the path which rejects pr(n) and accepts every price afterwards. The surplus of this path is given by \u2211T t=t(n)+r+1 \u03b3\nt\u22121(v \u2212 p\u0302t) where (p\u0302t)Tt=t(n)+r+1 are the prices the seller would offer if price pr(n) were rejected. Furthermore, since algorithm Ar is consistent, we must have p\u0302t \u2264 pr(n) = pn + \u03b4rn. Therefore, S(r(n)) can be bounded as follows:\nS(r(n)) \u2265 T\u2211\nt=t(n)+r+1\n\u03b3t\u22121(v \u2212 pn \u2212 \u03b4rn) = \u03b3t(n)+r \u2212 \u03b3T\n1\u2212 \u03b3 (v \u2212 pn \u2212 \u03b4rn). (5)\nWe proceed to upper bound S(l(n)). Since pn \u2212 p\u2032n \u2264 \u03b4ln for all n\u2032 \u2208 L (n), v \u2212 pn\u2032 \u2264 v \u2212 pn + \u03b4ln and\nS(l(n)) \u2264 T\u2211\nt=tn+r\n\u03b3t\u22121(v \u2212 pn + \u03b4ln) = \u03b3t(n)+r\u22121 \u2212 \u03b3T\n1\u2212 \u03b3 (v \u2212 pn + \u03b4ln). (6)\nCombining inequalities (4), (5) and (6) we conclude that\n\u03b3t(n)\u22121(v \u2212 pn) + \u03b3t(n)+r \u2212 \u03b3T\n1\u2212 \u03b3 (v \u2212 pn \u2212 \u03b4rn) \u2264\n\u03b3t(n)+r\u22121 \u2212 \u03b3T\n1\u2212 \u03b3 (v \u2212 pn + \u03b4ln)\n\u21d2 (v \u2212 pn) ( 1 + \u03b3r+1 \u2212 \u03b3r\n1\u2212 \u03b3\n) \u2264 \u03b3 r\u03b4ln + \u03b3 r+1\u03b4rn \u2212 \u03b3T\u2212t(n)+1(\u03b4rn + \u03b4ln)\n1\u2212 \u03b3\n\u21d2 (v \u2212 pn)(1\u2212 \u03b3r) \u2264 \u03b3r(\u03b4ln + \u03b3\u03b4 r n)\n1\u2212 \u03b3 .\nRearranging the terms in the above inequality yields the desired result.\nLet us consider the following instantiation of algorithm A introduced in [Kleinberg and Leighton, 2003]. The algorithm keeps track of a feasible interval [a, b] initialized to [0, 1] and an increment parameter initialized to 1/2. The algorithm works in phases. Within each phase, it offers prices a + , a + 2 , . . . until a price is rejected. If price a + k is rejected, then a new phase starts with the feasible interval set to [a+ (k\u2212 1) , a+ k ] and the increment parameter set to 2. This process continues until b \u2212 a < 1/T at which point the last phase starts and price a is offered for the remaining rounds. It is not hard to see that the number of phases needed by the algorithm is less than dlog2 log2 T e+1. A more surprising fact is that this algorithm has been shown to achieve regret O(log log T ) when the seller faces a truthful buyer. We will show that the modification Ar of this algorithm admits a particularly favorable regret bound. We will call this algorithm PFSr (penalized fast search algorithm). Proposition 4. For any value of v \u2208 [0, 1] and any \u03b3 \u2208 (0, 1), the regret of algorithm PFSr admits the following upper bound:\nReg(PFSr, v) \u2264 (vr + 1)(dlog2 log2 T e+ 1) + (1 + \u03b3)\u03b3rT\n2(1\u2212 \u03b3)(1\u2212 \u03b3r) . (7)\nNote that for r = 1 and \u03b3 \u2192 0 the upper bound coincides with that of [Kleinberg and Leighton, 2003].\nProof. Algorithm PFSr can accumulate regret in two ways: the price offered pn is rejected, in which case the regret is v, or the price is accepted and its regret is v \u2212 pn. Let K = dlog2 log2 T e + 1 be the number of phases run by algorithm PFSr. Since at most K different prices are rejected by the buyer (one rejection per phase) and each price must be rejected for r rounds, the cumulative regret of all rejections is upper bounded by vKr.\nThe second type of regret can also be bounded straightforwardly. For any phase i, let i and [ai, bi] denote the corresponding search parameter and feasible interval respectively. If v \u2208 [ai, bi], the regret accrued in the case where the buyer accepts a price in this interval is bounded by bi\u2212ai = \u221a i. If, on the other hand v \u2265 bi, then it readily follows that v \u2212 pn < v \u2212 bi + \u221a i for all prices pn offered in phase i. Therefore, the regret obtained in acceptance rounds is bounded by K\u2211 i=1 Ni ( (v \u2212 bi)1v>bi + \u221a i ) \u2264 K\u2211 i=1 (v \u2212 bi)1v>biNi +K,\nwhere Ni \u2264 1\u221a i denotes the number of prices offered during the i-th round.\nFinally, notice that, in view of the algorithm\u2019s definition, every bi corresponds to a rejected price. Thus, by Proposition 3, there exist nodes ni (not necessarily distinct) such that pni = bi and\nv \u2212 bi = v \u2212 pni \u2264 \u03b3r\n(1\u2212 \u03b3)(1\u2212 \u03b3r) (\u03b4lni + \u03b3\u03b4 r ni).\nIt is immediate that \u03b4rn \u2264 1/2 and \u03b4ln \u2264 1/2 for any node n, thus, we can write K\u2211 i=1 (v \u2212 bi)1v>biNi \u2264 \u03b3r(1 + \u03b3) 2(1\u2212 \u03b3)(1\u2212 \u03b3r) K\u2211 i=1 Ni \u2264 \u03b3r(1 + \u03b3) 2(1\u2212 \u03b3)(1\u2212 \u03b3r) T.\nThe last inequality holds since at most T prices are offered by our algorithm. Combining the bounds for both regret types yields the result.\nWhen an upper bound on the discount factor \u03b3 is known to the seller, he can leverage this information and optimize upper bound (7) with respect to the parameter r.\nTheorem 1. Let 1/2 < \u03b3 < \u03b30 < 1 and r\u2217 = \u2308 argminr\u22651 r + \u03b3r0T\n(1\u2212\u03b30)(1\u2212\u03b3r0 )\n\u2309 . For any v \u2208 [0, 1],\nif T > 4, the regret of PFSr\u2217 satisfies\nReg(PFSr\u2217 , v) \u2264 (2v\u03b30T\u03b30 log cT + 1 + v)(log2 log2 T + 1) + 4T\u03b30 ,\nwhere c = 4 log 2.\nThe proof of this theorem is fairly technical and is deferred to the Appendix. The theorem helps us define conditions under which logarithmic regret can be achieved. Indeed, if \u03b30 = e\u22121/ log T = O(1\u2212 1log T ), using the inequality e \u2212x \u2264 1\u2212 x+ x2/2 valid for all x > 0 we obtain\n1 1\u2212 \u03b30 \u2264 log\n2 T\n2 log T \u2212 1 \u2264 log T.\nIt then follows from Theorem 1 that\nReg(PFSr\u2217 , v) \u2264 (2v log T log cT + 1 + v)(log2 log2 T + 1) + 4 log T.\nLet us compare the regret bound given by Theorem 1 with the one given by Amin et al. [2013]. The above discussion shows that for certain values of \u03b3, an exponentially better regret can be achieved by our algorithm. It can be argued that the knowledge of an upper bound on \u03b3 is required, whereas this is not needed for the monotone algorithm. However, if \u03b3 > 1 \u2212 1/ \u221a T , the regret bound on monotone is super-linear, and therefore uninformative. Thus, in order to properly compare both algorithms, we may assume that \u03b3 < 1 \u2212 1/ \u221a T in which case, by Theorem 1, the regret of our algorithm is O( \u221a T log T ) whereas only linear regret can be guaranteed by the monotone\nalgorithm. Even under the more favorable bound of O( \u221a T\u03b3T + \u221a T ), for any \u03b1 < 1 and \u03b3 < 1 \u2212 1/T\u03b1, the monotone algorithm will achieve regret O(T \u03b1+12 ) while a strictly better regret O(T\u03b1 log T log log T ) is attained by ours."}, {"heading": "5 Lower bound", "text": "The following lower bounds have been derived in previous work. Theorem 2 ([Amin et al., 2013]). Let \u03b3 > 0 be fixed. For any algorithm A, there exists a valuation v for the buyer such that Reg(A, v) \u2265 112T\u03b3 .\nThis theorem is in fact given for the stochastic setting where the buyer\u2019s valuation is a random variable taken from some fixed distribution D. However, the proof of the theorem selects D to be a point mass, therefore reducing the scenario to a fixed priced setting. Theorem 3 ( [Kleinberg and Leighton, 2003]). Given any algorithm A to be played against a truthful buyer, there exists a value v \u2208 [0, 1] such that Reg(A, v) \u2265 C log log T for some universal constant C.\nCombining these results leads immediately to the following. Corollary 1. Given any algorithm A, there exists a buyer\u2019s valuation v \u2208 [0, 1] such that Reg(A, v) \u2265 max ( 1 12T\u03b3 , C log log T ) , for a universal constant C.\nWe now compare the upper bounds given in the previous section with the bound of Corollary 1. For \u03b3 > 1/2, we have Reg(PFSr, v) = O(T\u03b3 log T log log T ). On the other hand, for \u03b3 \u2264 1/2, we may choose r = 1, in which case, by Proposition 4, Reg(PFSr, v) = O(log log T ). Thus, the upper and lower bounds match up to an O(log T ) factor."}, {"heading": "6 Empirical results", "text": "In this section, we present the result of simulations comparing the monotone algorithm and our algorithm PFSr. The experiments were carried out as follows: given a buyer\u2019s valuation v, a discrete set of false valuations v\u0302 were selected out of the set {.03, .06, . . . , v}. Both algorithms were run against a buyer making the seller believe her valuation is v\u0302 instead of v. The value of v\u0302 achieving the best utility for the buyer was chosen and the regret for both algorithms is reported in Figure 2.\nWe considered two sets of experiments. First, the value of parameter \u03b3 was left unknown to both algorithms and the value of r was set to log(T ). This choice is motivated by the discussion following Theorem 1 since, for large values of T , we can expect to achieve logarithmic regret. The first two plots (from left to right) in Figure 2 depict these results. The apparent stationarity in the regret of PFSr is just a consequence of the scale of the plots as the regret is in fact growing as log(T ). For the second set of experiments, we allowed access to the parameter \u03b3 to both algorithms. The value of r was chosen optimally based on the results of Theorem 1 and the parameter \u03b2 of monotone was set to 1 \u2212 1/ \u221a TT\u03b3 to ensure regret in O( \u221a TT\u03b3 + \u221a T ). It is worth noting that even though our algorithm was designed under the assumption of some knowledge about the value of \u03b3, the experimental results show that an exponentially better performance over the monotone algorithm is still attainable and in fact the performances of the optimized and unoptimized versions of our algorithm are comparable. A more comprehensive series of experiments is presented in Appendix 9."}, {"heading": "7 Conclusion", "text": "We presented a detailed analysis of revenue optimization algorithms against strategic buyers. In doing so, we reduced the gap between upper and lower bounds on strategic regret to a logarithmic factor. Furthermore, the algorithm we presented is simple to analyze and reduces to the truthful scenario in the limit of \u03b3 \u2192 0, an important property that previous algorithms did not admit. We believe that our analysis helps gain a deeper understanding of this problem and that it can serve as a tool for studying more complex scenarios such as that of strategic behavior in repeated second-price auctions, VCG auctions and general market strategies."}, {"heading": "Acknowledgments", "text": "We thank Kareem Amin, Afshin Rostamizadeh and Umar Syed for several discussions about the topic of this paper. This work was partly funded by the NSF award IIS-1117591."}, {"heading": "8 Appendix", "text": "Lemma 2. The function g : \u03b3 7\u2192 log 1 \u03b3\n1\u2212\u03b3 is decreasing over the interval (0, 1).\nProof. This can be straightforwardly established:\ng\u2032(\u03b3) = \u2212 1\u2212\u03b3\u03b3 + log 1 \u03b3\n(1\u2212 \u03b3)2 = \u03b3 log\n( 1\u2212 [ 1\u2212 1\u03b3 ]) \u2212 (1\u2212 \u03b3)\n\u03b3(1\u2212 \u03b3)2 < (1\u2212 \u03b3)\u2212 (1\u2212 \u03b3) \u03b3(1\u2212 \u03b3)2 = 0,\nusing the inequality log(1\u2212 x) < \u2212x valid for all x < 0.\nLemma 3. Let a \u2265 0 and let g : D \u2282 R \u2192 [a,\u221e) be a decreasing and differentiable function. Then, the function F : R\u2192 R defined by\nF (\u03b3) = g(\u03b3)\u2212 \u221a g(\u03b3)2 \u2212 b\nis increasing for all values of b \u2208 [0, a].\nProof. We will show that F \u2032(\u03b3) \u2265 0 for all \u03b3 \u2208 D. Since F \u2032 = g\u2032[1 \u2212 g(g2 \u2212 b)\u22121/2] and g\u2032 \u2264 0 by hypothesis, the previous statement is equivalent to showing that \u221a g2 \u2212 b \u2264 g which is trivially verified since b \u2265 0.\nTheorem 1. Let 1/2 < \u03b3 < \u03b30 < 1 and r\u2217 = \u2308 argminr\u22651 r + \u03b3r0T\n(1\u2212\u03b30)(1\u2212\u03b3r0 )\n\u2309 . For any v \u2208 [0, 1],\nif T > 4, the regret of PFSr\u2217 satisfies\nReg(PFSr\u2217 , v) \u2264 (2v\u03b30T\u03b30 log cT + 1 + v)(log2 log2 T + 1) + 4T\u03b30 ,\nwhere c = 4 log 2.\nProof. It is not hard to verify that the function r 7\u2192 r + \u03b3 r 0T\n(1\u2212\u03b30)(1\u2212\u03b3r0 ) is convex and approaches\ninfinity as r \u2192 \u221e. Thus, it admits a minimizer r\u0304\u2217 whose explicit expression can be found by solving the following equation\n0 = d\ndr\n( r +\n\u03b3r0T\n(1\u2212 \u03b30)(1\u2212 \u03b3r0)\n) = 1 +\n\u03b3r0T log \u03b30 (1\u2212 \u03b30)(1\u2212 \u03b3r0)2 .\nSolving the corresponding second-degree equation yields\n\u03b3r\u0304 \u2217 0 = 2 + T log(1/\u03b30)1\u2212\u03b30 \u2212\n\u221a( 2 + T log(1/\u03b30)1\u2212\u03b30 )2 \u2212 4\n2 =: F (\u03b30).\nBy Lemmas 2 and 3, the function F thereby defined is increasing. Therefore, \u03b3r\u0304 \u2217\n0 \u2264 lim\u03b30\u21921 F (\u03b30) and\n\u03b3r\u0304 \u2217 0 \u2264 2 + T \u2212 \u221a (2 + T )2 \u2212 4 2 = 4 2(2 + T + \u221a (2 + T )2 \u2212 4) \u2264 2 T . (8)\nBy the same argument, we must have \u03b3r\u0304 \u2217\n0 \u2265 F (1/2), that is\n\u03b3r\u0304 \u2217 0 \u2265 F (1/2) = 2 + 2T log 2\u2212 \u221a (2 + 2T log 2)2 \u2212 4 2\n= 4 2(2 + 2T log 2 + \u221a (2 + 2T log 2)2 \u2212 4)\n\u2265 2 4 + 4T log 2 \u2265 1 4T log 2 .\nThus,\nr\u2217 = dr\u0304\u2217e \u2264 log(1/F (1/2)) log(1/\u03b30) + 1 \u2264 log(4T log 2) log 1/\u03b30 + 1. (9)\nCombining inequalities (8) and (9) with (7) gives Reg(PFSr\u2217 , v) \u2264 ( v log(4T log 2)\nlog 1/\u03b30 + 1 + v\n) (dlog2 log2 T e+ 1) +\n(1 + \u03b30)T\n(1\u2212 \u03b30)(T \u2212 2) \u2264 (2v\u03b30T\u03b30 log(cT ) + 1 + v)(dlog2 log2 T e+ 1) + 4T\u03b30 ,\nusing the inequality log( 1\u03b3 ) \u2265 1\u2212\u03b3 2\u03b3 valid for all \u03b3 \u2208 (1/2, 1)."}, {"heading": "8.1 Lower bound for monotone algorithms", "text": "Lemma 4. Let (pt)Tt=1 be a decreasing sequence of prices. Assume that the seller faces a truthful buyer. Then, if v is sampled uniformly at random in the interval [ 12 , 1], the following inequality holds:\nE[\u03ba\u2217] \u2265 1 32E[v \u2212 p\u03ba\u2217 ] .\nProof. Since the buyer is truthful, \u03ba\u2217(v) = \u03ba if and only if v \u2208 [p\u03ba, p\u03ba\u22121]. Thus, we can write\nE[v \u2212 p\u03ba\u2217 ] = \u03bamax\u2211 \u03ba=2 E [ 1v\u2208[p\u03ba,p\u03ba\u22121](v \u2212 p\u03ba) ] = \u03bamax\u2211 \u03ba=2 \u222b p\u03ba\u22121 p\u03ba (v \u2212 p\u03ba) dv = \u03bamax\u2211 \u03ba=2 (p\u03ba\u22121 \u2212 p\u03ba)2 2 ,\nwhere \u03bamax = \u03ba\u2217( 12 ). Thus, by the Cauchy-Schwarz inequality, we can write\nE [ \u03ba\u2217\u2211 \u03ba=2 p\u03ba\u22121 \u2212 p\u03ba ] \u2264 E  \u221a\u221a\u221a\u221a\u03ba\u2217 \u03ba\u2217\u2211 \u03ba=2 (p\u03ba\u22121 \u2212 p\u03ba)2  \u2264 E\n\u221a\u221a\u221a\u221a\u03ba\u2217 \u03bamax\u2211 \u03ba=2 (p\u03ba\u22121 \u2212 p\u03ba)2  = E [\u221a 2\u03ba\u2217E[v \u2212 p\u03ba\u2217 ]\n] \u2264 \u221a E[\u03ba\u2217] \u221a\n2E[v \u2212 p\u2217\u03ba],\nwhere the last step holds by Jensen\u2019s inequality. In view of that, since v > p\u03ba\u2217 , it follows that:\n3 4 = E[v] \u2265 E[p\u03ba\u2217 ] = E [ \u03ba\u2217\u2211 \u03ba=2 p\u03ba \u2212 p\u03ba\u22121 ] + p1 \u2265 \u2212 \u221a E[\u03ba\u2217] \u221a 2E[v \u2212 p\u03ba\u2217 ] + 1.\nSolving for E[\u03ba\u2217] concludes the proof.\nThe following lemma characterizes the value of \u03ba\u2217 when facing a strategic buyer.\nLemma 5. For any v \u2208 [0, 1], \u03ba\u2217 satisfies v \u2212 p\u03ba\u2217 \u2265 C\u03ba \u2217 \u03b3 (p\u03ba\u2217 \u2212 p\u03ba\u2217+1) with C\u03ba \u2217 \u03b3 = \u03b3\u2212\u03b3T\u2212\u03ba\n\u2217+1\n1\u2212\u03b3 . Furthermore, when \u03ba\u2217 \u2264 1+ \u221a T\u03b3T and T \u2265 T\u03b3 + 2 log(2/\u03b3)log(1/\u03b3) , C \u03ba\u2217\n\u03b3 can be replaced by the universal constant C\u03b3 = \u03b32(1\u2212\u03b3) .\nProof. Since an optimal strategy is played by the buyer, the surplus obtained by accepting a price at time \u03ba\u2217 must be greater than the corresponding surplus obtained when accepting the first price at time \u03ba\u2217 + 1. It thus follows that:\nT\u2211 t=\u03ba\u2217 \u03b3t\u22121(v \u2212 p\u03ba\u2217) \u2265 T\u2211 t=\u03ba\u2217+1 \u03b3t\u22121(v \u2212 p\u03ba\u2217+1)\n\u21d2 \u03b3\u03ba \u2217\u22121(v \u2212 p\u03ba\u2217) \u2265 T\u2211 t=\u03ba\u2217+1 \u03b3t\u22121(p\u03ba\u2217 \u2212 p\u03ba\u2217+1) = \u03b3\u03ba \u2217 \u2212 \u03b3T 1\u2212 \u03b3 (p\u03ba\u2217 \u2212 p\u03ba\u2217+1).\nDividing both sides of the inequality by \u03b3\u03ba \u2217\u22121 yields the first statement of the lemma. Let us verify the second statement. A straightforward calculation shows that the conditions on T imply T \u2212 \u221a TT\u03b3 \u2265 log(2/\u03b3)log(1/\u03b3) , therefore\nC\u03ba \u2217 \u03b3 \u2265 \u03b3 \u2212 \u03b3T\u2212\n\u221a T\u03b3T\n1\u2212 \u03b3 \u2265 \u03b3 \u2212 \u03b3\nlog(2/\u03b3) log(1/\u03b3)\n1\u2212 \u03b3 = \u03b3 \u2212 \u03b32 1\u2212 \u03b3 = \u03b3 2(1\u2212 \u03b3) .\nProposition 5. For any convex decreasing sequence (pt)Tt=1, if T \u2265 T\u03b3 + 2 log(2/\u03b3) log(1/\u03b3) , then there exists a valuation v0 \u2208 [ 12 , 1] for the buyer such that\nReg(Am, v0) \u2265 max 1 8 \u221a T \u2212 \u221a T , \u221a\u221a\u221a\u221aC\u03b3(T \u2212\u221aT\u03b3T)(1 2 \u2212 \u221a C\u03b3 T ) = \u2126(\u221aT +\u221aC\u03b3T ). Proof. In view of Proposition 1, we only need to verify that there exists v0 \u2208 [ 12 , 1] such that\nReg(Am, v0) \u2265 \u221a\u221a\u221a\u221aC\u03b3(T \u2212\u221aT\u03b3T)(1 2 \u2212 \u221a C\u03b3 T ) .\nLet \u03bamin = \u03ba\u2217(1), and \u03bamax = \u03ba\u2217( 12 ). If \u03bamin > 1 + \u221a T\u03b3T , then Reg(Am, 1) \u2265 1 + \u221a T\u03b3T , from which the statement of the proposition can be derived straightforwardly. Thus, in the following we will only consider the case \u03bamin \u2264 1+ \u221a T\u03b3T . Since, by definition, the inequality 12 \u2265 p\u03bamax holds, we can write 1\n2 \u2265 p\u03bamax = \u03bamax\u2211 \u03ba=\u03bamin+1 (p\u03ba \u2212 p\u03ba\u22121) + p\u03bamin \u2265 \u03bamax(p\u03bamin+1 \u2212 p\u03bamin) + p\u03bamin ,\nwhere the last inequality holds by the convexity of the sequence and the fact that p\u03bamin \u2212 p\u03bamin\u22121 \u2264 0. The inequality is equivalent to p\u03bamin \u2212 p\u03bamin+1 \u2265 p\u03bamin\u2212 1 2 \u03bamax . Furthermore, by Lemma 5, we have\nmax v\u2208[ 12 ,1] Reg(Am, v) \u2265 max (\u03bamax, (T \u2212 \u03bamin)(p\u03bamin \u2212 p\u03bamin+1))\n\u2265 max ( \u03bamax, C\u03b3\n(T \u2212 \u03bamin)(p\u03bamin \u2212 12 ) \u03bamax\n) .\nThe right-hand side is minimized for \u03bamax = \u221a C\u03b3(T \u2212 \u03bamin)(p\u03bamin \u2212 12 ). Thus, there exists a valuation v0 for which the following inequality holds:\nReg(Am, v0) \u2265 \u221a C\u03b3(T \u2212 \u03bamin) ( p\u03bamin \u2212 1\n2\n) \u2265 \u221a C\u03b3 ( T \u2212 \u221a T\u03b3T )( p\u03bamin \u2212 1\n2\n) .\nFurthermore, we can assume that p\u03bamin \u2265 1 \u2212 \u221a C\u03b3 T otherwise Reg(Am, 1) \u2265 (T \u2212 1) \u221a C\u03b3/T , which is easily seen to imply the desired lower bound. Thus, there exists a valuation v0 such that\nReg(Am, v0) \u2265 \u221a\u221a\u221a\u221aC\u03b3(T \u2212\u221aT\u03b3T)(1 2 \u2212 \u221a C\u03b3 T ) ,\nwhich concludes the proof."}, {"heading": "9 Simulations", "text": "Here, we present the results of more extensive simulations for PFSr and the monotone algorithm. Again, we consider two different scenarios. Figure 3 shows the experimental results for an agnostic scenario where the value of the parameter \u03b3 remains unknown to both algorithms and where the parameter r of PFSr is set to log(T ). The results reported in Figure 4 correspond to the second scenario where the discounting factor \u03b3 is known to the algorithms and where the parameter \u03b2 for the monotone algorithm is set to 1\u22121/ \u221a TT\u03b3 . The scale on the plots is logarithmic in the number of rounds and in the regret."}], "references": [{"title": "The continuum-armed bandit problem", "author": ["R. Agrawal"], "venue": "SIAM journal on control and optimization,", "citeRegEx": "Agrawal.,? \\Q1926\\E", "shortCiteRegEx": "Agrawal.", "year": 1926}, {"title": "Learning prices for repeated auctions with strategic buyers", "author": ["K. Amin", "A. Rostamizadeh", "U. Syed"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Amin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Amin et al\\.", "year": 2013}, {"title": "Online bandit learning against an adaptive adversary: from regret to policy regret", "author": ["R. Arora", "O. Dekel", "A. Tewari"], "venue": "In Proceedings of ICML,", "citeRegEx": "Arora et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Arora et al\\.", "year": 2012}, {"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine Learning,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R.E. Schapire"], "venue": "SIAM J. Comput.,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Regret minimization for reserve prices in second-price auctions", "author": ["N. Cesa-Bianchi", "C. Gentile", "Y. Mansour"], "venue": "In Proceedings of SODA,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2013}, {"title": "Strategic bidder behavior in sponsored search auctions", "author": ["B. Edelman", "M. Ostrovsky"], "venue": "Decision Support Systems,", "citeRegEx": "Edelman and Ostrovsky.,? \\Q2007\\E", "shortCiteRegEx": "Edelman and Ostrovsky.", "year": 2007}, {"title": "A game-theoretic machine learning approach for revenue maximization in sponsored search", "author": ["D. He", "W. Chen", "L. Wang", "T. Liu"], "venue": "In Proceedings of IJCAI,", "citeRegEx": "He et al\\.,? \\Q2013\\E", "shortCiteRegEx": "He et al\\.", "year": 2013}, {"title": "The value of knowing a demand curve: Bounds on regret for online posted-price auctions", "author": ["R.D. Kleinberg", "F.T. Leighton"], "venue": "In Proceedings of FOCS,", "citeRegEx": "Kleinberg and Leighton.,? \\Q2003\\E", "shortCiteRegEx": "Kleinberg and Leighton.", "year": 2003}, {"title": "Algorithms for the multi-armed bandit problem", "author": ["V. Kuleshov", "D. Precup"], "venue": "Journal of Machine Learning,", "citeRegEx": "Kuleshov and Precup.,? \\Q2010\\E", "shortCiteRegEx": "Kuleshov and Precup.", "year": 2010}, {"title": "A theory of auctions and competitive bidding", "author": ["P. Milgrom", "R. Weber"], "venue": "Econometrica: Journal of the Econometric Society,", "citeRegEx": "Milgrom and Weber.,? \\Q1982\\E", "shortCiteRegEx": "Milgrom and Weber.", "year": 1982}, {"title": "Learning theory and algorithms for revenue optimization in second-price auctions with reserve", "author": ["M. Mohri", "A. Mu\u00f1oz Medina"], "venue": "In Proceedings of ICML,", "citeRegEx": "Mohri and Medina.,? \\Q2014\\E", "shortCiteRegEx": "Mohri and Medina.", "year": 2014}, {"title": "Non-zero-sum games. In Introduction to Game Theory, pages 115\u2013147", "author": ["P. Morris"], "venue": null, "citeRegEx": "Morris.,? \\Q1994\\E", "shortCiteRegEx": "Morris.", "year": 1994}, {"title": "Bayesian learning in repeated games of incomplete information", "author": ["J. Nachbar"], "venue": "Social Choice and Welfare,", "citeRegEx": "Nachbar.,? \\Q2001\\E", "shortCiteRegEx": "Nachbar.", "year": 2001}, {"title": "Prediction, optimization, and learning in repeated games", "author": ["J.H. Nachbar"], "venue": "Econometrica: Journal of the Econometric Society,", "citeRegEx": "Nachbar.,? \\Q1997\\E", "shortCiteRegEx": "Nachbar.", "year": 1997}, {"title": "Reserve prices in internet advertising auctions: A field experiment", "author": ["M. Ostrovsky", "M. Schwarz"], "venue": "In Proceedings of EC,", "citeRegEx": "Ostrovsky and Schwarz.,? \\Q2011\\E", "shortCiteRegEx": "Ostrovsky and Schwarz.", "year": 2011}, {"title": "Some aspects of the sequential design of experiments", "author": ["H. Robbins"], "venue": "In Herbert Robbins Selected Papers,", "citeRegEx": "Robbins.,? \\Q1985\\E", "shortCiteRegEx": "Robbins.", "year": 1985}, {"title": "Counterspeculation, auctions, and competitive sealed tenders", "author": ["W. Vickrey"], "venue": "The Journal of finance,", "citeRegEx": "Vickrey.,? \\Q2012\\E", "shortCiteRegEx": "Vickrey.", "year": 2012}], "referenceMentions": [{"referenceID": 5, "context": "In the past decade, however, the advent of online advertisement has prompted a more algorithmic study of auctions, including the design of learning algorithms for revenue maximization for generalized second-price auctions or second-price auctions with reserve [Cesa-Bianchi et al., 2013, Mohri and Mu\u00f1oz Medina, 2014, He et al., 2013]. These studies have been largely motivated by the widespread use of AdExchanges and the vast amount of historical data thereby collected \u2013 AdExchanges are advertisement selling platforms using second-price auctions with reserve price to allocate advertisement space. Thus far, the learning algorithms proposed for revenue maximization in these auctions critically rely on the assumption that the bids, that is, the outcomes of auctions, are drawn i.i.d. according to some unknown distribution. However, this assumption may not hold in practice. In particular, with the knowledge that a revenue optimization algorithm is being used, an advertiser could seek to mislead the publisher by under-bidding. In fact, consistent empirical evidence of strategic behavior by advertisers has been found by Edelman and Ostrovsky [2007]. This motivates the analysis presented in this paper of the interactions between sellers and strategic buyers, that is, buyers that may act non-truthfully with the goal of maximizing their surplus.", "startOffset": 261, "endOffset": 1158}, {"referenceID": 3, "context": "Kleinberg and Leighton [2003] precisely studied this continuous bandit setting under the assumption of an oblivious buyer, that is, one that does not exploit the seller\u2019s behavior (more precisely, the authors assume that at each round the seller interacts with a different buyer).", "startOffset": 0, "endOffset": 30}, {"referenceID": 0, "context": "However, as argued by Amin et al. [2013], when dealing with a strategic buyer, the usual definition of regret is no longer meaningful.", "startOffset": 22, "endOffset": 41}, {"referenceID": 0, "context": "However, as argued by Amin et al. [2013], when dealing with a strategic buyer, the usual definition of regret is no longer meaningful. Indeed, consider the following example: let the valuation of the buyer be given by v \u2208 [0, 1] and assume that an algorithm with sublinear regret such as Exp3 [Auer et al., 2002b] or UCB [Auer et al., 2002a] is used for T rounds by the seller. A possible strategy for the buyer, knowing the seller\u2019s algorithm, would be to accept prices only if they are smaller than some small value , certain that the seller would eventually learn to offer only prices less than . If v, the buyer would considerably boost her surplus while, in theory, the seller would have not incurred a large regret since in hindsight, the best fixed strategy would have been to offer price for all rounds. This, however is clearly not optimal for the seller. The stronger notion of policy regret introduced by Arora et al. [2012] has been shown to be the appropriate one for the analysis of bandit problems with adaptive adversaries.", "startOffset": 22, "endOffset": 936}, {"referenceID": 0, "context": "However, as argued by Amin et al. [2013], when dealing with a strategic buyer, the usual definition of regret is no longer meaningful. Indeed, consider the following example: let the valuation of the buyer be given by v \u2208 [0, 1] and assume that an algorithm with sublinear regret such as Exp3 [Auer et al., 2002b] or UCB [Auer et al., 2002a] is used for T rounds by the seller. A possible strategy for the buyer, knowing the seller\u2019s algorithm, would be to accept prices only if they are smaller than some small value , certain that the seller would eventually learn to offer only prices less than . If v, the buyer would considerably boost her surplus while, in theory, the seller would have not incurred a large regret since in hindsight, the best fixed strategy would have been to offer price for all rounds. This, however is clearly not optimal for the seller. The stronger notion of policy regret introduced by Arora et al. [2012] has been shown to be the appropriate one for the analysis of bandit problems with adaptive adversaries. However, for the example just described, a sublinear policy regret can be similarly achieved. Thus, this notion of regret is also not the pertinent one for the study of our scenario. We will adopt instead the definition of strategic-regret, which was introduced by Amin et al. [2013] precisely for the study of this problem.", "startOffset": 22, "endOffset": 1324}, {"referenceID": 0, "context": "This notion of regret also matches the concept of learning loss introduced by [Agrawal, 1995] when facing an oblivious adversary. Using this definition, Amin et al. [2013] presented both upper and lower bounds for the regret of a seller facing a strategic buyer and showed that the buyer\u2019s surplus must be discounted over time in order to be able to achieve sublinear regret (see Section 2).", "startOffset": 79, "endOffset": 172}, {"referenceID": 0, "context": "This notion of regret also matches the concept of learning loss introduced by [Agrawal, 1995] when facing an oblivious adversary. Using this definition, Amin et al. [2013] presented both upper and lower bounds for the regret of a seller facing a strategic buyer and showed that the buyer\u2019s surplus must be discounted over time in order to be able to achieve sublinear regret (see Section 2). However, the gap between the upper and lower bounds they presented is in O( \u221a T ). In the following, we analyze a very broad family of monotone regret minimization algorithms for this problem (Section 3), which includes the algorithm of Amin et al. [2013], and show that no algorithm in that family admits a strategic regret more favorable than \u03a9( \u221a T ).", "startOffset": 79, "endOffset": 648}, {"referenceID": 1, "context": "The performance of a seller\u2019s algorithm is measured by the notion of strategic-regret [Amin et al., 2013] defined as follows:", "startOffset": 86, "endOffset": 105}, {"referenceID": 1, "context": "3 Monotone algorithms The following conservative pricing strategy was introduced by Amin et al. [2013]. Let p1 = 1 and \u03b2 < 1.", "startOffset": 84, "endOffset": 103}, {"referenceID": 8, "context": "Figure 1 depicts the tree generated by an algorithm proposed by Kleinberg and Leighton [2003], which we will describe later.", "startOffset": 64, "endOffset": 94}, {"referenceID": 8, "context": "(a) (b) Figure 1: (a) Tree T (3) associated to the algorithm proposed in [Kleinberg and Leighton, 2003].", "startOffset": 73, "endOffset": 103}, {"referenceID": 8, "context": "Let us consider the following instantiation of algorithm A introduced in [Kleinberg and Leighton, 2003].", "startOffset": 73, "endOffset": 103}, {"referenceID": 8, "context": "Note that for r = 1 and \u03b3 \u2192 0 the upper bound coincides with that of [Kleinberg and Leighton, 2003].", "startOffset": 69, "endOffset": 99}, {"referenceID": 1, "context": "Let us compare the regret bound given by Theorem 1 with the one given by Amin et al. [2013]. The above discussion shows that for certain values of \u03b3, an exponentially better regret can be achieved by our algorithm.", "startOffset": 73, "endOffset": 92}, {"referenceID": 1, "context": "Theorem 2 ([Amin et al., 2013]).", "startOffset": 11, "endOffset": 30}, {"referenceID": 8, "context": "Theorem 3 ( [Kleinberg and Leighton, 2003]).", "startOffset": 12, "endOffset": 42}], "year": 2014, "abstractText": "We study revenue optimization learning algorithms for posted-price auctions with strategic buyers. We analyze a very broad family of monotone regret minimization algorithms for this problem, which includes the previously best known algorithm, and show that no algorithm in that family admits a strategic regret more favorable than \u03a9( \u221a T ). We then introduce a new algorithm that achieves a strategic regret differing from the lower bound only by a factor in O(log T ), an exponential improvement upon the previous best algorithm. Our new algorithm admits a natural analysis and simpler proofs, and the ideas behind its design are general. We also report the results of empirical evaluations comparing our algorithm with the previous state of the art and show a consistent exponential improvement in several different scenarios.", "creator": "LaTeX with hyperref package"}}}