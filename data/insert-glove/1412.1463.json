{"id": "1412.1463", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Dec-2014", "title": "On the String Kernel Pre-Image Problem with Applications in Drug Discovery", "abstract": "wallenbergs The pre - image problem has hirshson to be solved kghm during inference peering by volstagg most kiew structured zizka output langille predictors. For string 270th kernels, 1905-06 this problem khaldi corresponds off-shoot to sayadaw finding the inn string associated to a given 118.91 input. footfall An endonym algorithm pervomaiskoye capable ortmayer of vran\u010di\u0107 solving avtotor or finding good bibliographical approximations cundieff to this phoca problem would have many applications snuggling in morrolan computational biology 17.69 and saheba other consecutive fields. 0954 This work bandaranaike uses a recent bangers result verdad on laurifolia combinatorial luddites optimization simplifications of islamshahr linear expansions predictors based on persuaded string kernels to servan-schreiber develop, for wherefores the yamane pre - umehara image, a low complexity upper bound valid barraud for many string 25.93 kernels. This hemorrhoid upper bound dapo is bogislaw used with success rodulf in 491 a subtribe branch and ffa bound 1.4876 searching algorithm. rumored Applications and subtyping results in unregulated the carriles discovery of balotelli druggable wizened peptides are consolini presented and recorrido discussed.", "histories": [["v1", "Wed, 3 Dec 2014 20:33:57 GMT  (14kb)", "https://arxiv.org/abs/1412.1463v1", "Peer-reviewed and accepted for presentation at Machine Learning in Computational Biology 2014, Montr\\'{e}al, Qu\\'{e}bec, Canada"], ["v2", "Thu, 4 Dec 2014 02:51:56 GMT  (12kb)", "http://arxiv.org/abs/1412.1463v2", "Peer-reviewed and accepted for presentation at Machine Learning in Computational Biology 2014, Montr\\'eal, Qu\\'ebec, Canada"]], "COMMENTS": "Peer-reviewed and accepted for presentation at Machine Learning in Computational Biology 2014, Montr\\'{e}al, Qu\\'{e}bec, Canada", "reviews": [], "SUBJECTS": "cs.LG cs.CE", "authors": ["s\\'ebastien gigu\\`ere", "am\\'elie rolland", "fran\\c{c}ois laviolette", "mario marchand"], "accepted": false, "id": "1412.1463"}, "pdf": {"name": "1412.1463.pdf", "metadata": {"source": "CRF", "title": "On the String Kernel Pre-Image Problem with Applications in Drug Discovery", "authors": ["S\u00e9bastien Gigu\u00e8re", "Am\u00e9lie Rolland", "Fran\u00e7ois Laviolette", "Mario Marchand"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n41 2.\n14 63\nv2 [\ncs .L\nG ]\n4 D\nec 2"}, {"heading": "1 Introduction", "text": "This work focuses on the challenges of using regression learning algorithms in the design of highly active peptides. Let A be the set of all amino acids and A\u2217 be the set of all possible peptides. Throughout this paper we will assume that we have a dataset S = {(x1, e1), . . . , (xm, em)} \u2208 A\u2217 \u00d7R where xi is the amino acid sequence of the i-th peptide in S and ei is its bioactivity (which could be its binding affinity to some target protein, its antimicrobial activity, or some other desirable activity for peptides). The regression approach consists of learning a predictor h from the training dataset S. Let h(x) be the estimated bioactivity of x according to the predictor h. There are many ways to represent such a predictor but this work focuses on string kernel based predictors. Many learning algorithm, such as the Support Vector Regression, Ridge Regression, and Gaussian Processes, produce predictors h whose output h(x), on input x, is given by\nh(x) =\nm \u2211\ni=1\n\u03b1iK(xi,x) , (1)\nwhere \u03b1i is the weight on the i-th training example, K(xi,x) = \u3008\u03c6(x),\u03c6(x\u2032)\u3009 is a string kernel, \u3008\u00b7, \u00b7\u3009 denotes the inner product between feature vectors, and \u03c6 is the feature map associated to K . The weight vector \u03b1 = (\u03b11, \u03b12, .., \u03b1m) is obtained by minimizing the learning algorithm objective function.\nFor the discovery of peptide inhibitors and peptides that could act as drug precursors, we are interested in finding the peptide xh maximizing the predicted bioactivity:\nx h = arg max\nx\u2208A\u2217 h(x) . (2)\nThe complexity of this combinatorial problem will obviously depend on the string kernel used to learn h. For few kernels like the Hamming kernel, solving Equation (2) is trivial [1]. However, this kernel is not well suited for peptides [2]. On another hand, the Generic String (GS) kernel [2] is well suited for peptides. It is defined as follows:\nGS(x,x\u2032, k, \u03c3p, \u03c3c) def =\nk \u2211\nl=1\n|x|\u2212l \u2211\ni=0\n|x\u2032|\u2212l \u2211\nj=0\nexp ( \u2212(i\u2212j)2\n2\u03c32p\n)\nexp\n(\n\u2212\u2016\u03c8l(xi+1,..,xi+l)\u2212\u03c8 l(x\u2032j+1,..,x \u2032 j+l )\u20162\n2\u03c32c\n)\n, (3)\n1Corresponding author: amelie.rolland.1@ulaval.ca Peer-reviewed and accepted for presentation at Machine Learning in Computational Biology 2014, Montre\u0301al, Que\u0301bec, Canada.\nwhere k controls the length of compared k-mers, \u03c8k : Ak \u2192 Rdk encodes the physico-chemical properties of k-mers by mapping each of the k amino acids to a real valued vector containing d properties, \u03c3c controls the penalty incurred when the physico-chemical properties of two k-mers differ, and \u03c3p controls the penalty incurred when two k-mers are not sharing the same position in their respective peptides. Depending on the chosen hyper-parameters, this kernel can be specialized to eight known kernels [2], namely the Hamming kernel, the Blended Spectrum [3], the Radial Basis Function (RBF), the Oligo [4], and the Weighted degree [5]. Since the proposed approach uses the GS kernel it is also valid for all of these kernels.\nIt was recently shown [6] that when K is the Generic String (GS) kernel, and when we restrict peptides to be of length l, the peptide xh \u2208 Al can be found in polynomial time for any predictor h in the form of Equation (1). Their approach maps the combinatorial problem to a directed acyclic graph (DAG) that is basically a de Bruijn graph with weights on the arcs. Then, they show that finding the longest (weighted) path in this graph is equivalent to finding xh \u2208 Al. Finally, the longest path can be found in polynomial time by dynamic programming since the graph is acyclic.\nHowever, with the GS kernel, given two peptides x and x\u2032 of the same length, the Euclidean norms of their feature vectors \u03c6(x) and \u03c6(x\u2032) can differ substantially, i.e. we can have \u221a K(x,x) \u226b \u221a\nK(x\u2032,x\u2032). Let us first show, with a simple example, why this can be problematic. We will then show how to avoid this problem through kernel normalization. Such normalization does not have any computational impact in the learning phase of the regression algorithm. It does however impact substantially the prediction phase, leading to a harder combinatorial problem.\nHence, let us consider the strings \u201cAAAAA\u201d and \u201cABCDE\u201d and the Spectrum kernel [7] (also known as the n-gram kernel) with k-mers of size two. The string \u201cAAAAA\u201d has a norm of \u221a 16 = 4, while \u201cABCDE\u201d has a norm of\u221a\n1 + 1 + 1 + 1 = 2. Hence the Spectrum kernel is sensitive to k-mers repetitions in the string. Note that this problem is shared by many other string kernels. In the case of the GS kernel, it is possible to avoid this problem by fixing the hyper-parameter \u03c3p to 0, which forces a constant norm, i.e. K(x,x) = c for all x \u2208 Al. However, K(x,x) will vary whenever \u03c3p > 0, as it is the case for the Blended Spectrum and the Oligo kernels, for example. A consequence of a non-constant norm is that h(x) will heavily depend on the norm of \u03c6(x). Hence, xh will be more likely a peptide having a feature vector with a large norm, i.e., a peptide having many repetitions. This is generally an undesired bias. It is easy to overcome this problem by normalizing kernel values, in that case the output function becomes\nh\u22c6(x) = m \u2211\ni=1\n\u03b1i K(xi,x) \u221a\nK(xi,xi)K(x,x) =\n1 \u221a\nK(x,x)\nm \u2211\ni=1\n\u03b2iK(xi,x) (4)\nwhere \u03b2i = \u03b1i\u221a K(xi,xi) . In that case we are now interested in finding\nx h\u22c6 = arg max\nx\u2208A\u2217\n1 \u221a\nK(x,x)\nm \u2211\ni=1\n\u03b2iK(xi,x) . (5)\nThis optimization problem is also a pre-image problem, but written in a slightly different form. We conjecture that solving Equation (5) is NP-Hard when K is the GS kernel. Given the similarity between the problems of Equation (2) and Equation (5), the difference in their computational complexity is unexpected.\nIn the next section, we will present a low complexity upper bound on Equation (4) that makes it a good candidate for a branch and bound search to solve Equation (5)."}, {"heading": "2 Method", "text": "Since the number of peptides grows exponentially with its length, it becomes impossible to evaluate all solutions for large peptides, we propose a branch and bound scheme to guide this search. A branch and bound algorithm starts by dividing the search space into disjoint subspaces. For example, one subspace could be all peptides ending with the string \u201cDE\u201d. For a maximization problem, an upper bound on the best achievable solution is computed for each of these subspaces. Then, the subspace with the highest upper bound is further divided into smaller subspaces. Finally, the search stops when a subspace can no longer be divided (a leaf is reached in the search tree), or when the upper bound value is lower than the value of an already achieved solution (i.e., an already reached leaf in the search tree). A branch and bound approach can thus avoid exploring a large part of the search space.\nAlgorithm 1 gives the specifics of the branch and bound algorithm applied to our case. The search algorithm alternates between a greedy phase and a branch and bound phase. The greedy phase is important to ensure that leaves of the search tree are quickly visited. This allows good but sub-optimal solutions to be returned by the algorithm if the allowed computational time expires. Whenever a node is visited, the bound is computed for all its children and they\nare added to the priority queue accordingly. This greedy process is repeated until a leaf is reached. Then, the node with the largest bound is visited and the greedy process starts again. At all time, the best solution found so far is kept and the search stops when the bound of the node on top of the priority queue is smaller than the value of the best solution.\nAlgorithm 1 Branch and bound search for maximal string of length l Q : empty priority queue ordering bounds in descending order\nbest node \u2190 Node(empty string, 0) for all s \u2208 Ak do \u22b2 Add all k-mer in Q\nQ.push(Node(s, F (s, l))) end for while current node \u2190 Q.pop() & current node.bound > best node.bound do \u22b2 Get maximal node in Q\nwhile |current node.string| < l & current node.bound > best node.bound do best child \u2190 Node(empty-string, 0) for all a \u2208 A do \u22b2 Evaluate all children of node\ns\u2032 \u2190 Concatenate(a, current node.string) if F (s\u2032, l) > best node.bound then\nif F (s\u2032, l) > best child.bound then best child \u2190 Node(s\u2032, F (s\u2032, l)) \u22b2 Update best child end if Q.push(Node(s\u2032, F (s\u2032, l))) \u22b2 Add child to Q end if end for current node \u2190 best child Q.remove(best child) \u22b2 Remove best child from Q if it was added\nend while if |current node.string| = l & current node.bound > best node.bound then\nbest node \u2190 current node \u22b2 Update best node end if\nend while\nreturn best node.string, best node.bound \u22b2 Return string and maximal bioactivity\nLet Al\u2212p \u00d7{x\u20321, . . . , x\u2032p} be the set of all possible strings of length l that end with x\u20321, . . . , x\u2032p, in other words, Al\u2212p \u00d7 {x\u20321, . . . , x\u2032p} is a set of strings having their last p characters fixed. Our goal is to have a function F that upper bounds h\u22c6 for every Al\u2212p \u00d7 {x\u20321, . . . , x\u2032p}. In other words:\nF (x\u2032, l) \u2265 max x\u2208Al\u2212p\u00d7{x\u2032\n1 ,...,x\u2032p}\n1 \u221a\nK(x,x)\nm \u2211\ni=1\n\u03b2iK(xi,x) . (6)\nTo do so, let F (x\u2032, l) def = 1\u221a\nf(x\u2032,l) g(x\u2032, l), where\nf(x\u2032, l) \u2264 min x\u2208Al\u2212p\u00d7{x\u2032\n1 ,...,x\u2032p}\nK(x,x) and g(x\u2032, l) \u2265 max x\u2208Al\u2212p\u00d7{x\u2032\n1 ,...,x\u2032p}\nm \u2211\ni=1\n\u03b2iK(xi,x) (7)\nare, respectively, a lower and an upper bound.\nWhen K is the GS kernel with hyper-parameters k , \u03c3p and \u03c3c, the lower bound f can be obtained as follows:\nfk,\u03c3p,\u03c3c (x \u2032, l) def = GS(x\u2032,x\u2032, k, \u03c3p, \u03c3c) + 2XX \u2032(x\u2032, l, k, \u03c3p, \u03c3c) +XX(x \u2032, l, k, \u03c3p, \u03c3c) , (8)\nwhere\nXX \u2032(x\u2032, l, k, \u03c3p, \u03c3c) def =\nk \u2211\np=1\nl\u2212|x\u2032| \u2211\ni=1\nmin x\u2208Ap\n|x\u2032| \u2211\nj=1\nexp ( \u2212(i\u2212j)2\n2\u03c32p\n)\nexp\n(\n\u2212\u2016\u03c8l(x1,..,xp)\u2212\u03c8 l(x\u2032j ,..,x \u2032 j+p)\u2016 2\n2\u03c32c\n)\n, (9)\nXX(x\u2032, l, k, \u03c3p, \u03c3c) def =\nk \u2211\np=1\nl\u2212|x\u2032| \u2211\ni=1\nl\u2212|x\u2032| \u2211\nj=1\nexp ( \u2212(i\u2212(l\u2212|x\u2032|+j))2\n2\u03c32p\n) exp ( \u2212(D(i,j)2+...+D(i+p,j+p)2\n2\u03c32c\n)\n(10)\nand\nD(i, j) =\n{\n0 if i = j,\nmax a,a\u2032\u2208A\n\u03c8(a, a\u2032) otherwise.\nNote that the lower bound f is not attained since it under-estimates the value of the string x \u2208 Al\u2212p \u00d7 {x\u20321, . . . , x\u2032p} minimizing K(x,x).\nFor g(x\u2032, l), note that \u2211m\ni=1 \u03b2iK(xi,x) is what [6] proposed to maximize. Their approach uses a dynamic programming table to compute the longest path in a graph. It is relatively easy to modify their algorithm to return the table instead of the longest path. In that way, given a string with suffix x\u2032, it is possible to determine in constant time, by accessing the dynamic programming table, the prefix from Al\u2212p maximizing \u2211mi=1 \u03b2iK(xi,x). The computation of g is thus very efficient, the algorithm of [6] only needs to be done once before the branch and bound search, then g(x\u2032, l) can be computed in constant time for any x\u2032. Finally, g is the least upper bound (or suprema) since there is always a string x \u2208 Al\u2212p \u00d7 {x\u20321, . . . , x\u2032p} with g(x, l) = \u2211m i=1 \u03b2iK(xi,x). In other words, there are no tighter bound."}, {"heading": "3 Results and Discussion", "text": "We followed the protocol suggested by [6] and, as a proof of concept, we used the same dataset they used: 101 cationic antimicrobial pentadecapeptides (CAMPs) from the synthetic antibiotic peptides database [8]. Peptide antibacterial activities are expressed as the logarithm of bactericidal potency. As in [6], we used kernel ridge regression as the learning algorithm. Except when stated otherwise, all hyper-parameters for the GS kernel (k, \u03c3c, \u03c3p) and the kernel ridge regression (\u03bb) were chosen by standard cross-validation. We learned two predictors of antimicrobial potency, one uses unnormalized kernel values (thus, the same predictor used in [6]), the other was trained using normalized kernel values. We refer to these predictors respectively as h and h\u22c6.\nThe method presented in [6] was used to identify the peptide xh \u2208 A15 of maximal predicted bioactivity according to h and the branch and bound was used to identify xh\u22c6 \u2208 A15, the peptide maximizing h\u22c6. Both approaches found the same peptide, which is \u201cWWKWWKRLRRLFLLV\u201d.\nNote that both methods are able to output more than one sequence. The method of [6] uses a k-longest path algorithm to obtain the k peptides of maximal bioactivity. It is also possible for the branch and bound by stopping the search only when the bound on top of the priority queue is lower than the k-th peptide found. These peptides can be used, for example, for motif generation, for multiple peptide synthesis or in combinatorial chemistry. To highlight the differences between the methods, they were used to list the top 1000 peptides and the lists were compared: 70.5% of the 1000 peptides were found by both methods. Then, the Pearson correlation coefficient (PCC) was computed between the rank of the 679 peptides present in both lists: a PCC of 0.56 was obtained. Hence, the ranking of peptides found by h and by h\u22c6 differ significantly.\nThe overlap in the lists is attributed to the value of \u03c3p that was chosen during cross-validation for h. As explained earlier, when \u03c3p is 0, the unnormalized predictor h will not suffer from differences in the norm of \u03c6(x). In the case of antimicrobial peptides, \u03c3p = 0.8 was found to be the optimal value for h. This suggests that the method of [6] offers some resistance to variation in norm when \u03c3p is small. Indeed, for small \u03c3p, all examples have about the same norm.\nTo further highlight the difference between the methods, we intentionally fixed \u03c3p to infinity and cross-validated all other parameters for h and h\u22c6 and compared the best peptides found. Situations were \u03c3p would have to be set to infinity are not at all unlikely. For example, cyclic peptides have no N-terminus and no C-terminus. For that reason, there is no origin from which we can express the positions of k-mers in these peptides. The method of [6] found the peptide \u201cFKKIFKKIFKKIFKF\u201d using the predictor h and the branch and bound approach found the peptide \u201cWKKIFKKIWKFRVFK\u201d using the predictorh\u22c6. The peptide identified by h shares almost no similarity with peptides of the training set and is basically composed of repetition of the k-mer \u201cFKK\u201d. In contrast, the peptide identified by h\u22c6 shares many substructures with the most bioactive peptides of the training set. This tends to point out that in situation where example norms vary a lot, h clearly favors examples having a large norm. However, this bias is unjustified and is not related to a biological reality."}, {"heading": "4 Conclusion", "text": "We proposed a bound for maximizing the inference function of kernel methods that uses normalized string kernels. Moreover, the bound is also valid for solving the pre-image of a variety of string kernels. Empirical results show that the method proposed by [6] can suffer from a dominance of the norm for certain strings, a problem which is present\nwith many string kernels. In these situations, the proposed method was shown to overcome this problem. Tighter bounds should take advantage of the proposed framework and allow the discovery of novel peptide inhibitors. Finally, applications for drugs based on cyclic peptides and other structured output applications are expected."}, {"heading": "Acknowledgments", "text": "The authors would like to thank Prudencio Tossu for his help in the experimentations. Computations were performed on the Colosse supercomputer at Universite\u0301 Laval (resource allocation project: avt-710-aa), under the auspices of Calcul Que\u0301bec and Compute Canada. AR is recipient of a Master\u2019s Scholarship from the Fonds de recherche du Que\u0301bec - Nature et technologies (FRQNT). This work was supported by the FRQNT (FL & MM; 2013-PR-166708)."}], "references": [{"title": "Risk bounds and learning algorithms for the regression approach to structured output prediction", "author": ["S\u00e9bastien Gigu\u00e8re", "Fran\u00e7ois Laviolette", "Mario Marchand", "Khadidja Sylla"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Learning a peptide-protein binding affinity predictor with kernel ridge regression", "author": ["S\u00e9bastien Gigu\u00e8re", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Drouin", "Jacques Corbeil"], "venue": "BMC Bioinformatics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Kernel methods for pattern analysis", "author": ["John Shawe-Taylor", "Nello Cristianini"], "venue": "Cambridge university press,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Oligo kernels for datamining on biological sequences: A case study on prokaryotic translation initiation sites", "author": ["P. Meinicke", "M. Tech", "B. Morgenstern", "R. Merkl"], "venue": "BMC Bioinformatics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Accurate Splice Site Detection for Caenorhabditis elegans", "author": ["Gunnar R\u00e4tsch", "S\u00f6ren Sonnenburg"], "venue": "Kernel Methods in Computational Biology,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Machine learning assisted design of highly active peptides for drug discovery", "author": ["S\u00e9bastien Gigu\u00e8re", "Fran\u00e7ois Laviolette", "Mario Marchand", "Denise Tremblay", "Sylvain Moineau", "\u00c9ric Biron", "Jacques Corbeil"], "venue": "Under review, Submitted to MLCB,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "The spectrum kernel: A string kernel for svm protein classification", "author": ["Christina S Leslie", "Eleazar Eskin", "William Stafford Noble"], "venue": "In Pacific symposium on biocomputing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Synthetic antibiotic peptides database", "author": ["David Wade", "Jukka Englund"], "venue": "Protein and peptide letters,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "For few kernels like the Hamming kernel, solving Equation (2) is trivial [1].", "startOffset": 73, "endOffset": 76}, {"referenceID": 1, "context": "However, this kernel is not well suited for peptides [2].", "startOffset": 53, "endOffset": 56}, {"referenceID": 1, "context": "On another hand, the Generic String (GS) kernel [2] is well suited for peptides.", "startOffset": 48, "endOffset": 51}, {"referenceID": 1, "context": "Depending on the chosen hyper-parameters, this kernel can be specialized to eight known kernels [2], namely the Hamming kernel, the Blended Spectrum [3], the Radial Basis Function (RBF), the Oligo [4], and the Weighted degree [5].", "startOffset": 96, "endOffset": 99}, {"referenceID": 2, "context": "Depending on the chosen hyper-parameters, this kernel can be specialized to eight known kernels [2], namely the Hamming kernel, the Blended Spectrum [3], the Radial Basis Function (RBF), the Oligo [4], and the Weighted degree [5].", "startOffset": 149, "endOffset": 152}, {"referenceID": 3, "context": "Depending on the chosen hyper-parameters, this kernel can be specialized to eight known kernels [2], namely the Hamming kernel, the Blended Spectrum [3], the Radial Basis Function (RBF), the Oligo [4], and the Weighted degree [5].", "startOffset": 197, "endOffset": 200}, {"referenceID": 4, "context": "Depending on the chosen hyper-parameters, this kernel can be specialized to eight known kernels [2], namely the Hamming kernel, the Blended Spectrum [3], the Radial Basis Function (RBF), the Oligo [4], and the Weighted degree [5].", "startOffset": 226, "endOffset": 229}, {"referenceID": 5, "context": "It was recently shown [6] that when K is the Generic String (GS) kernel, and when we restrict peptides to be of length l, the peptide x \u2208 Al can be found in polynomial time for any predictor h in the form of Equation (1).", "startOffset": 22, "endOffset": 25}, {"referenceID": 6, "context": "Hence, let us consider the strings \u201cAAAAA\u201d and \u201cABCDE\u201d and the Spectrum kernel [7] (also known as the n-gram kernel) with k-mers of size two.", "startOffset": 79, "endOffset": 82}, {"referenceID": 5, "context": "For g(x, l), note that \u2211m i=1 \u03b2iK(xi,x) is what [6] proposed to maximize.", "startOffset": 48, "endOffset": 51}, {"referenceID": 5, "context": "The computation of g is thus very efficient, the algorithm of [6] only needs to be done once before the branch and bound search, then g(x, l) can be computed in constant time for any x.", "startOffset": 62, "endOffset": 65}, {"referenceID": 5, "context": "3 Results and Discussion We followed the protocol suggested by [6] and, as a proof of concept, we used the same dataset they used: 101 cationic antimicrobial pentadecapeptides (CAMPs) from the synthetic antibiotic peptides database [8].", "startOffset": 63, "endOffset": 66}, {"referenceID": 7, "context": "3 Results and Discussion We followed the protocol suggested by [6] and, as a proof of concept, we used the same dataset they used: 101 cationic antimicrobial pentadecapeptides (CAMPs) from the synthetic antibiotic peptides database [8].", "startOffset": 232, "endOffset": 235}, {"referenceID": 5, "context": "As in [6], we used kernel ridge regression as the learning algorithm.", "startOffset": 6, "endOffset": 9}, {"referenceID": 5, "context": "We learned two predictors of antimicrobial potency, one uses unnormalized kernel values (thus, the same predictor used in [6]), the other was trained using normalized kernel values.", "startOffset": 122, "endOffset": 125}, {"referenceID": 5, "context": "The method presented in [6] was used to identify the peptide x \u2208 A15 of maximal predicted bioactivity according to h and the branch and bound was used to identify x\u22c6 \u2208 A15, the peptide maximizing h\u22c6.", "startOffset": 24, "endOffset": 27}, {"referenceID": 5, "context": "The method of [6] uses a k-longest path algorithm to obtain the k peptides of maximal bioactivity.", "startOffset": 14, "endOffset": 17}, {"referenceID": 5, "context": "This suggests that the method of [6] offers some resistance to variation in norm when \u03c3p is small.", "startOffset": 33, "endOffset": 36}, {"referenceID": 5, "context": "The method of [6] found the peptide \u201cFKKIFKKIFKKIFKF\u201d using the predictor h and the branch and bound approach found the peptide \u201cWKKIFKKIWKFRVFK\u201d using the predictorh\u22c6.", "startOffset": 14, "endOffset": 17}, {"referenceID": 5, "context": "Empirical results show that the method proposed by [6] can suffer from a dominance of the norm for certain strings, a problem which is present", "startOffset": 51, "endOffset": 54}], "year": 2014, "abstractText": "The pre-image problem has to be solved during inference by most structured output predictors. For string kernels, this problem corresponds to finding the string associated to a given input. An algorithm capable of solving or finding good approximations to this problem would have many applications in computational biology and other fields. This work uses a recent result on combinatorial optimization of linear predictors based on string kernels to develop, for the pre-image, a low complexity upper bound valid for many string kernels. This upper bound is used with success in a branch and bound searching algorithm. Applications and results in the discovery of druggable peptides are presented and discussed.", "creator": "LaTeX with hyperref package"}}}