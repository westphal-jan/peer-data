{"id": "1412.3352", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Dec-2014", "title": "Web image annotation by diffusion maps manifold learning algorithm", "abstract": "gcvo Automatic 018 image fourplay annotation is menthol one of automat the puniet most ont. challenging herck problems expresscard in machine altmark vision areas. The goal of this occur task tolai is 93.30 to jukeboxes predict number of keywords 1.003 automatically miskolc for images milliliter captured 12-8 in screen real ayloffe data. bong Many methods are kreh based e4 on shinnosuke visual rahan features in order collaborated to wetangula calculate similarities banjoist between ergezen image treme samples. But oogie the computation saltzburg cost 905 of these approaches is very centum high. hibiki These randomization methods collaris require uninsured many training mahallas samples xbl to traeder be paints stored in mod\u00e8le memory. motonari To 6k lessen moggridge this ukrainians burden, a number of leyendecker techniques have been mcdonnell-douglas developed nivola to heuliez reduce the crescendoing number of features in a dataset. Manifold learning u-turn is palmata a popular goffman approach haake to nonlinear dimensionality reduction. 3tablespoons In this statins paper, quelimane we investigate Diffusion non-scheduled maps yochelson manifold hunger learning 39.48 method pl\u00e1stica for web image auto - annotation task. Diffusion maps manifold learning therocephalian method is used to trainmaster reduce the bushy dimension of hipwell some three-movement visual nojima features. bassham Extensive experiments warley and analysis hd3 on preamplifiers NUS - WIDE - LITE kittikachorn web fischman image dataset responsibilites with gimbal different visual relaunched features antireligious show executor how this manifold judo learning schuberth dimensionality reduction method carl can be edomite applied effectively to macaskill image 1350s annotation.", "histories": [["v1", "Mon, 8 Dec 2014 10:38:28 GMT  (333kb)", "http://arxiv.org/abs/1412.3352v1", "11 pages, 8 figures"]], "COMMENTS": "11 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.CV cs.IR cs.LG", "authors": ["neda pourali"], "accepted": false, "id": "1412.3352"}, "pdf": {"name": "1412.3352.pdf", "metadata": {"source": "CRF", "title": "WEB IMAGE ANNOTATION BY DIFFUSION MAPS MANIFOLD LEARNING ALGORITHM", "authors": ["Neda Pourali"], "emails": [], "sections": [{"heading": null, "text": "DOI:10.5121/ijfcst.2014.4606 59\noriginal Euclidian distance as the similarity measure in the input feature space can be approximated by the Hamming distance. The training costs of these methods, however, are basically expensive. Another popular problem with high dimensional data is known as the \u201ccurse of dimensionality\u201d. So we need some methods to reduce the dimension of feature vectors. Manifold learning is an emerging and promising approach in non-parametric dimension reduction. A manifold is a topological space that is locally Euclidean, i.e. around every point, there is a neighborhood that is topologically the same as the open unit ball in . An Earth is a good example of a manifold. Locally, at each point on the surface of the Earth, we have a 3-D coordinate system: two for location and one for the altitude. Globally, it is a 2-D sphere that is embedded in a 3-D space [13]. Manifolds offer a powerful framework for dimensionality reduction problem. The key idea of dimensionality reduction is to find low dimensional structure that is embedded in a higher dimensional space. Occam's razor has been used to support dimensionality reduction. The main idea of Occam\u2019s razor is to select the simplest model from a set of equal models to explain a given phenomenon. Moreover, if the data are indeed generated according to a manifold, then a manifold based learning can be optimal [13]. In recent studies, Manifold learning algorithms have been used for many applications. Nathan Mekuz [14] worked on Local Linear Embedding (LLE) method for face recognition problem. Raducanu [15] represented Supervised Laplacian Eigenmaps (S-LEM) in order to enhance accuracy of classification task on some face datasets. Carlotta Orsenigo [16] proposed manifold learning methods for cancer microarray data classification. Abdenour Hadid [17] worked on demographic classification from face videos using manifold learning. Yahong Han [18] proposed manifold learning application for image classification on out of sample data. Xianming Liu [19] worked on cross-media manifold learning for image retrieval and annotation task. In this paper, we investigate an advanced manifold learning method for image auto-annotation task. Local Tangent Space Alignment is used to reduce the dimension of some visual features. After reducing the dimension of feature vectors, new features are used for our multi-label classifier. We compare these methods with some other dimensionality reduction methods. The rest of this paper is organized as follows: Section 2 introduces dimensionality reduction and Section 3 explains Diffusion maps manifold learning method and Diffusion maps algorithm is used to solve the curse of dimensionality problem of KNN classifier. Section 4 introduces experimental setup and experimental results. At the end of this paper, we make a conclusion in Section 5."}, {"heading": "2. DIMENSIONALITY REDUCTION", "text": "The problem of nonlinear dimensionality reduction method can be defined as follows. Assume we have dataset representation in a nD matrix X consisting of n datavectores ( \u2208{1, 2, \u2026 , n}) with dimensionality D. Assume that this dataset has intrinsic dimensionality of d (where d < D, and often we have d \u226a D ). Intrinsic dimensionality means that the points in dataset X are lying on or near a manifold with dimensionality of d that is embedded in the D-dimensional space. Dimensionality reduction problems map the dataset X with dimensionality D into a dataset Y with dimensionality d while retaining the geometry of the data as much as possible. Neither the geometry of the data manifold, nor the intrinsic dimensionality d of the dataset X are known. So, dimensionality reduction is a problem that can only be solved by assuming certain properties of the data. Throughout the paper, datapoint is denoted by , where is the \u2019th row of the D-\ndimensional data matrix X. The low-dimensional of is denoted by , where is the \u2019th row of the d-dimensional data matrix Y. [20]. Figure (1) shows taxonomy of techniques for dimensionality reduction. The main distinction between techniques for dimensionality reduction is the distinction between linear and nonlinear techniques. Linear techniques assume that the data lie on or near a linear sub-space of the highdimensional space. Nonlinear techniques for dimensionality reduction do not rely on the linearity assumption as a result of which more complex embedding of the data in the high-dimensional space can be identified. In section 3 we discuss Diffusion maps nonlinear dimensionality reduction."}, {"heading": "3. DIFFUSION MAPS MANIFOLD LEARNING DIMENSIONALITY REDUCTION", "text": "The diffusion maps (DM) algorithm [21, 22] originates from the dynamical systems. Maaten [20] introduced LEM as follows. Diffusion maps techniques are based on a Markov random walk on the graph of the data.when the random walk for a number of time steps occurs, a measure for the proximity of the datapoints is obtained. By using this measure, the diffusion distance an define. In the low-dimensional representation of the data, the pairwise diffusion distances are kept as well as possible. In the diffusion maps, first the graph of the data is constructed. The weights of the edges in this constructed graph are computed using the Gaussian kernel function, leading to a matrix W with the following entries\n=\n\u0255 (1)\nwhere \u0255 indicates the variance of the Gaussian. Afterwards, the normalization process of the matrix W is performed in a way that its rows add up to 1. In this way, a matrix ( ) is constructed with entries\n( ) = \u2211\n(2) Since diffusion maps techniques originate from dynamical systems, the resulting matrix ( ) is regarded a Markov matrix that defines the forward transition probability matrix of a dynamical process. So, the matrix ( ) shows the probability of a transition from one datapoint to another datapoint in one time step. The forward probability matrix for t time steps ( ) can given by ( ( )) . By using the random walk forward probabilities ( ), the diffusion distance is computed by\n( )( , )= \u2211 ( ( ) ( ))\n( ) (3)\nIn the equation (3) , ( ) is for attributing more weights to parts of the graph with the high density. It is can defined by ( ) =\u2211 , where is the degree of node omputed by\n= \u2211 . From Equation (3), it can be concluded that pairs of data points with a high forward transition probability have a small diffusion distance. The main idea behind the diffusion distance is that it is based on many paths in the graph. This makes the diffusion distance more robust to noise than the geodesic distance. In the low-dimensional representation of the data Y , diffusion maps attempt to keep the diffusion distances. It can be shown by spectral theory on the random walk that the low-dimensional representation Y that retains the diffusion distances is constructed by the d nontrivial principal eigenvectors of the eigen problem\n( ) = (4) Because the graph is fully connected, the largest eigenvalue is minor (viz. \u03bb = 1), its eigenvector\nis thus discarded. So The low-dimensional representation Y is given by the next d principal eigenvectors. In the low dimensional representation Y, the eigenvectors can normalized by their corresponding eigenvalues. Therefore, the low-dimensional data representation Y is given by\nY={\u03bb , \u03bb , . . . \u03bb } (5)"}, {"heading": "3.1. Diffusion maps on Synthetic Data", "text": "In order to examine the performance of algorithms, we first evaluate algorithms for dimensionality reduction task only. We test on two different standard datasets:"}, {"heading": "3.1.1. Swiss Roll Example", "text": "A randomly sampled plane is rolled up into a spiral. A good nonlinear dimensionality reduction technique should unroll this example into a plane. If the number of nearest neighbors is set to large, the embedding will across folds. This dataset was proposed by Tannenbaum [24]. Figure (2) shows this dataset with N=2000 data points."}, {"heading": "2.1.2. Punctured Sphere Example", "text": "The bottom \u00be of a sphere is sampled non-uniformly. The sampling is densest along the top rim and sparsest on the bottom of the sphere. The 2D projection should display concentric circles. The user can control the height of the sphere. This dataset was written by Saul [25]. Figure (3) shows this dataset with N=2000 data points."}, {"heading": "3.1.3. Dimensionality reduction results on two datasets", "text": "We tested DM method on two datasets that explained before. Figure (4) and Figure (5) show the embedding results of this method. We set Sigma={1, 4, 10} in both datasets. The performance of DM on Sigma=10 is the best in both datasets."}, {"heading": "4. EXPERIMENT WITH REAL DATA", "text": ""}, {"heading": "4.1. Feature Vectors", "text": "For evaluating of our manifold learning methods, we tested on three features as follows:"}, {"heading": "4.1.1. 73-D edge direction histogram:", "text": "Edge direction histogram encrypts the distribution of the directions of edges. Edge direction histogram has a total of 73 bins, in which the first 72 bins are the count of edges with directions quantized at five degrees interval, and the last bin is the count of number of pixels that do not contribute to an edge. To pay back for different image sizes, they normalized the entries in histogram as follows:\niH =\n\u23a9 \u23aa \u23a8\n\u23aa \u23a7 ( ) , [0,..., 71]\ne\nH i if i M \n( ) , 72H i if i M\n (6)\nwhere ( )H i is the count of bin i in the edge direction histogram; Me is the total number of edge points that detected in the sub-block of an image; and M is the total number of pixels in the sub-block. It uses Canny filter to detect edge points and Sobel operator to compute the direction by the gradient of each edge point [23]."}, {"heading": "4.1.2. 144-D color auto-correlogram (HSV):", "text": "The color auto-correlogram was proposed to describe the color distributions and the spatial correlation of pairs of colors together. The histogram has three dimensions. The first two dimensions of it are the colors of any pixel pair and the third dimension is their spatial distance. Let I show the entire set of image pixels and ( )c iI represent the subset of pixels with color ( )c i , then the color auto-correlogram is defined as:\n1 ( ) 2 2 ( ) 1 2 ( ) , [P P ]P c i c i k ij P I P I I P dr r      \n where , {1, 2,..., }i j K , {1, 2,..., }d L and 1 2p p is the distance between 1p and 2p pixels. Color auto-correlogram reduces the dimension from 2( )O N d to O(N )d because it only captures the spatial correlation between identical colors. They quantize the HSV color components into 36 bins and set the distance metric to four odd intervals of {1,3,5,7}d  .So the color autocorrelogram has a dimension of144(36 4) [23]."}, {"heading": "4.1.3. 225-D block-wise color moments (LAB):", "text": "The first (mean), the second (variance) and the third order (skew- ness) color moments are efficient and effective in representing the color distributions of images. The first three moments are defined as:\n1\n1 N i ij\nj f N      1\n2 2\n1\n1( ( ) ) N\ni ij i j f N       1\n3 3\n1\n1( ( ) ) N\ni ij i j s f N       where ijf is the value of the i \u2019th color component of the image pixel j , and N is the total number of pixels in the image. Color moments offer a very dence representation of image content as compared to other color features. Using of three color moments as described above, only nine components (three color moments, each with three color components) will be used. Due to this density, it may not have good discrimination power. for NUS_WIDE dataset, they extract the block-wise color moments over 5\u00d75 fixed grid partitions, giving rise to a block-wise color moments with a dimension of 225 [23]."}, {"heading": "4.2. Dataset", "text": "We performed experiment on NUS-WIDE-LITE dataset that represented by Tat-Seng Chua [23]. This is a large web image dataset downloaded from Flickr. All dataset samples are supervised and labeled with 81 concepts and it has about 2 labels per image. NUS-WIDE-LITE dataset includes a set of 55615 images and their associated tag randomly selected from the full NUS-WIDE dataset. Its cover the full 81 concepts from NUS-WIDE. We prune images with less than five labels and then we work on subdataset. We randomly divide the images into training and testing subset. Half of them are used as training data and the rest are used for testing data. We represent each image as three feature vectors."}, {"heading": "4.3. Annotation Method and Evaluation Protocol", "text": "Since our interest was in the performance of image annotation, we simply use K nearest neighbour method. The system output the most frequent labels in the k retrieved neighbours. For NUS-WIDE-LITE dataset, we tested k={4, 8,16, 32} nearest neighbour and d={10, 20, 30, 40, 50} dimensions for dimensionality reduction methods. For evaluating of annotation, we follow the methodology of previous work that Hideki Nakayama [26] proposed it. The system annotates test image with 5 words for each. These words are then compared with the ground truth. To facilitate a quantitative comparison, we use publicly available feature files in the experiment. We test on three features: 1) 225-D block-wise color moments, 2) 144-D color auto-correlogram, 3) 73-D edge direction histogram. These features are provided by the authors of [23]. By using the manifold learning algorithms, we decrease the dimensions of these three feature vectors to d={10, 20, 30, 40, 50} dimensions."}, {"heading": "4.4. Experimental Results", "text": "We report the results for the NUS-WIDE-LITE dataset. In this dataset, the dimension of visual features is too large for k nearest neighbourhood method. So we decrease the dimensions of these three feature vectors to d={10, 20, 30, 40, 50} dimensions. First the dimensionality reduction time for each of four methods is summarized in Table (1). Target dimensionality is set to d=30, and we use a 5-core Intel 2.30 GHz system for computation. We compare the performance of DM method with three other dimensionality reduction algorithms; PCA, LLE and LEM. The dimensionality reduction time of PCA is the lowest between all methods and the dimensionality reduction time of DM is the highest between all methods. Next we summarized the results for image annotation task. We give a comparison of the annotation accuracy (Average Precision) with k=8 in KNN method. Average Precision is originally used in information retrieval systems to evaluate the document ranking performance for query retrieval [27]. In our comparison, DM exhibit superior performance, and achieve comparable and better performance than the other three algorithms. Because we tested on three features, we show our experimental result of each feature separately. The first feature is 73-D edge direction histogram. The results for annotation with this feature are summarized in Figure (6). On 73-D edge direction histogram, the performance of PCA of is the lowest between all methods. The DM achieves the best performance. The results of LLE and LEM are moderate. The second feature is 144-D color auto-correlogram (HSV). The results for annotation with 144-D color auto-correlogram (HSV) feature are summarized in Figure (7). The third feature is 225-D block-wise color moments (LAB). The DM achieves the best performance. The results for annotation with 225-D block-wise color moments (LAB) feature are summarized in Figure (8). In our comparison on three features, 225-D block-wise color moments (LAB) exhibit superior performance on different dimensions."}, {"heading": "5. CONCLUSION", "text": "In this article, we investigated and compared a manifold learning dimensionality reduction algorithm (DM) for image annotation task. Obtaining powerful small algorithms in a scalable manner is an important issue in implementing large-scale image annotation systems. Linear methods like PCA enable training in linear time and are suitable for this purpose. Overall, we can balance the trade-off between computation efficiency and annotation accuracy by selecting the dimensions of feature vectors. We can obtain a small-dimension latent subspace reflecting the semantic distance of instances. We used DM method for this goal and we achieve the best performance in value of Average precision. Our future work could be extended to other compression formats and the other advanced manifold learning algorithms."}], "references": [{"title": "Object recognition as machine translation: Learning a lexicon for a fixed image vocabulary", "author": ["P.Duygulu", "K.Barnard", "N. de Freitas", "D. Forsyth"], "venue": "In Proc. ECCV,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Multiple Bernoulli relevance models for image and video annotation", "author": ["S.Feng", "R. Manmatha", "V. Lavrenko"], "venue": "In proc. IEEE CVPR,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "A model for learning the semantics of pictures", "author": ["V.Larvenko", "R. Manmatha", "J. Jeon"], "venue": "In proc. NIPS", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Image annotation via graph learning", "author": ["J.Liu", "M. Li", "Q. Liu", "H. Lu", "S. Ma"], "venue": "Pattern Recognition,42(2),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "An adaptive graph model for automatic image annotation", "author": ["J.Liu", "M. Li", "W.-Y. Ma", "Q. Liu", "H. Lu"], "venue": "In proc. ACM MIR,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Modeling annotated data", "author": ["D.M. Blei", "M.I. Jordan"], "venue": "In Proc. ACM SIGIR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "PLSA-based image auto-annotation: constraining the latent space", "author": ["F.Monay", "D. Gatica-Perez"], "venue": "In Proc. ACM multimedia", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Supervised learning of semantic classes for image annotation and retrieval", "author": ["G.Carneiro", "A.B. Chan", "P.J. Moreno", "N. Vasconcelos"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Tagprop: Discriminative metric learning in nearest neighbor models for image auto-annotation", "author": ["M.Guillaumin", "T. Mensink", "J. Verbeek", "C. Schmid"], "venue": "In Proc. IEEE ICCV,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Subspace manifold learning with sample weights", "author": ["Nathan Mekuz", "Christian Bauckhage", "John K. Tsotsos"], "venue": "Image and Vision Computing", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "A comparative study of nonlinear manifold learning methods for cancer microarray data classification", "author": ["Carlotta Orsenigo", "Carlo Vercellis"], "venue": "Expert Systems with Applications 40,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Cross-media manifold learning for image retrieval and annotation", "author": ["Xianming Liu", "Rongrong Ji", "Hongxun Yao", "Pengfei Xu", "Xiaoshuai Sun", "Tianqiang Liu"], "venue": "Proceedings of the 1st ACM international conference on Multimedia information retrieval,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Dimensionality Reduction: A Comparative Review", "author": ["L.J.P. van der Maaten", "E.O. Postma", "H.J. van den Herik"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": "Incremental nonlinear dimensionality reduction by manifold learning", "author": ["M.H. Law", "A.K. Jain"], "venue": "IEEE Transactions of Pattern Analysis and Machine Intelligence,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "On spectral clustering: Analysis and an algorithm", "author": ["A.Ng", "M. Jordan", "Y. Weiss"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2001}, {"title": "NUS-WIDE: a real-word web image database from National University of Sangapore", "author": ["T.-S. Chua", "J. Tang", "R. Hong", "H. Li", "Z. Luo", "Y. -T. Zheng"], "venue": "In proc. ACM CIVR", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "A Global Geometric Framework for Nonlinear Dimensionality Reduction", "author": ["Joshua B. Tenenbaum", "Vin de Silva", "John C. Langford"], "venue": "Science", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2000}, {"title": "Think Globally, Fit Locally: Unsupervised Learning of Low Dimensional Manifolds", "author": ["Lawrence K. Saul", "Sam T. Roweis"], "venue": "Journal of Machine Learning Research", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2003}, {"title": "Evaluation of dimensionality reduction methods for image auto-annotation", "author": ["H.Nakayama", "T. Harada", "Y. Kuniyoshi"], "venue": "British Machine Vision Association,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "ML-KNN: A lazy learning approach to multi-label learning", "author": ["Min-Ling Zhang", "Zhi-Hue Zhou"], "venue": "Pattern Recognition", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Many approaches have been proposed to solve the image annotation problem, including classification-based [1, 2], region-based [3, 4, 5], graph-based [6, 7], topic model [8, 9], and generative image patch modelling [10] techniques.", "startOffset": 126, "endOffset": 135}, {"referenceID": 1, "context": "Many approaches have been proposed to solve the image annotation problem, including classification-based [1, 2], region-based [3, 4, 5], graph-based [6, 7], topic model [8, 9], and generative image patch modelling [10] techniques.", "startOffset": 126, "endOffset": 135}, {"referenceID": 2, "context": "Many approaches have been proposed to solve the image annotation problem, including classification-based [1, 2], region-based [3, 4, 5], graph-based [6, 7], topic model [8, 9], and generative image patch modelling [10] techniques.", "startOffset": 126, "endOffset": 135}, {"referenceID": 3, "context": "Many approaches have been proposed to solve the image annotation problem, including classification-based [1, 2], region-based [3, 4, 5], graph-based [6, 7], topic model [8, 9], and generative image patch modelling [10] techniques.", "startOffset": 149, "endOffset": 155}, {"referenceID": 4, "context": "Many approaches have been proposed to solve the image annotation problem, including classification-based [1, 2], region-based [3, 4, 5], graph-based [6, 7], topic model [8, 9], and generative image patch modelling [10] techniques.", "startOffset": 149, "endOffset": 155}, {"referenceID": 5, "context": "Many approaches have been proposed to solve the image annotation problem, including classification-based [1, 2], region-based [3, 4, 5], graph-based [6, 7], topic model [8, 9], and generative image patch modelling [10] techniques.", "startOffset": 169, "endOffset": 175}, {"referenceID": 6, "context": "Many approaches have been proposed to solve the image annotation problem, including classification-based [1, 2], region-based [3, 4, 5], graph-based [6, 7], topic model [8, 9], and generative image patch modelling [10] techniques.", "startOffset": 169, "endOffset": 175}, {"referenceID": 7, "context": "Many approaches have been proposed to solve the image annotation problem, including classification-based [1, 2], region-based [3, 4, 5], graph-based [6, 7], topic model [8, 9], and generative image patch modelling [10] techniques.", "startOffset": 214, "endOffset": 218}, {"referenceID": 8, "context": "For example Guillaumin [12] worked on 37,000 dimensional data.", "startOffset": 23, "endOffset": 27}, {"referenceID": 9, "context": "Nathan Mekuz [14] worked on Local Linear Embedding (LLE) method for face recognition problem.", "startOffset": 13, "endOffset": 17}, {"referenceID": 10, "context": "Carlotta Orsenigo [16] proposed manifold learning methods for cancer microarray data classification.", "startOffset": 18, "endOffset": 22}, {"referenceID": 11, "context": "Xianming Liu [19] worked on cross-media manifold learning for image retrieval and annotation task.", "startOffset": 13, "endOffset": 17}, {"referenceID": 12, "context": "[20].", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Taxonomy of dimensionality reduction techniques [20].", "startOffset": 48, "endOffset": 52}, {"referenceID": 13, "context": "DIFFUSION MAPS MANIFOLD LEARNING DIMENSIONALITY REDUCTION The diffusion maps (DM) algorithm [21, 22] originates from the dynamical systems.", "startOffset": 92, "endOffset": 100}, {"referenceID": 14, "context": "DIFFUSION MAPS MANIFOLD LEARNING DIMENSIONALITY REDUCTION The diffusion maps (DM) algorithm [21, 22] originates from the dynamical systems.", "startOffset": 92, "endOffset": 100}, {"referenceID": 12, "context": "Maaten [20] introduced LEM as follows.", "startOffset": 7, "endOffset": 11}, {"referenceID": 16, "context": "This dataset was proposed by Tannenbaum [24].", "startOffset": 40, "endOffset": 44}, {"referenceID": 17, "context": "This dataset was written by Saul [25].", "startOffset": 33, "endOffset": 37}, {"referenceID": 15, "context": "It uses Canny filter to detect edge points and Sobel operator to compute the direction by the gradient of each edge point [23].", "startOffset": 122, "endOffset": 126}, {"referenceID": 15, "context": "So the color autocorrelogram has a dimension of144(36 4) \uf0b4 [23].", "startOffset": 59, "endOffset": 63}, {"referenceID": 15, "context": "for NUS_WIDE dataset, they extract the block-wise color moments over 5\u00d75 fixed grid partitions, giving rise to a block-wise color moments with a dimension of 225 [23].", "startOffset": 162, "endOffset": 166}, {"referenceID": 15, "context": "Dataset We performed experiment on NUS-WIDE-LITE dataset that represented by Tat-Seng Chua [23].", "startOffset": 91, "endOffset": 95}, {"referenceID": 18, "context": "For evaluating of annotation, we follow the methodology of previous work that Hideki Nakayama [26] proposed it.", "startOffset": 94, "endOffset": 98}, {"referenceID": 15, "context": "These features are provided by the authors of [23].", "startOffset": 46, "endOffset": 50}, {"referenceID": 19, "context": "Average Precision is originally used in information retrieval systems to evaluate the document ranking performance for query retrieval [27].", "startOffset": 135, "endOffset": 139}], "year": 2014, "abstractText": "Automatic image annotation is one of the most challenging problems in machine vision areas. The goal of this task is to predict number of keywords automatically for images captured in real data. Many methods are based on visual features in order to calculate similarities between image samples. But the computation cost of these approaches is very high. These methods require many training samples to be stored in memory. To lessen this burden, a number of techniques have been developed to reduce the number of features in a dataset. Manifold learning is a popular approach to nonlinear dimensionality reduction. In this paper, we investigate Diffusion maps manifold learning method for web image auto-annotation task. Diffusion maps manifold learning method is used to reduce the dimension of some visual features. Extensive experiments and analysis on NUS-WIDE-LITE web image dataset with different visual features show how this manifold learning dimensionality reduction method can be applied effectively to image annotation.", "creator": null}}}