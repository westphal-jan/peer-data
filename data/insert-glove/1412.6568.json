{"id": "1412.6568", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2014", "title": "Improving zero-shot learning by mitigating the hubness problem", "abstract": "The zero - penumbra shot paradigm exploits numididae vector - based word hosiery representations chauffeured extracted wenbo from text corpora trehalose with videogame unsupervised murba methods comsec to learn general mapping functions noriyasu from xugong other rajatarangini feature filumena spaces wet-nurse onto word second-team space, shangdong where goodbar the ignachenko words associated to the nearest colleague neighbours mariaan of the trifonov mapped kovil vectors al-rayyan are messuziere used as their linguistic labels. We datar show that the daulatpur neighbourhoods of dunvant the erdo\u011fan mapped elements postplatyptilia are strongly ricordi polluted by wyl hubs, stuber vectors that cafi tend wizzard to be f\u00e9nelon near a 12-km high fhm proportion of kurds items, pushing their correct labels down the cliffsides neighbour list. lukis After heteropsis illustrating the payg problem empirically, we propose a narozhilenko simple reile method zhenhai to correct virage it nssa by 2-to-4 taking then-upcoming the proximity distribution aborigines of garmsar potential neighbours colwich across many mapped 36.2 vectors 230-foot into account. We white-sided show marrons that gumps this correction leads jhenidah to ageorges consistent crumpled improvements hkr in goetzmann realistic zero - shot 126.70 experiments 173.5 in thestor the cross - feige lingual, image cosi labeling edmunds.com and perciform image rosmah retrieval floresta domains.", "histories": [["v1", "Sat, 20 Dec 2014 01:03:46 GMT  (1038kb,D)", "https://arxiv.org/abs/1412.6568v1", null], ["v2", "Tue, 10 Mar 2015 14:15:13 GMT  (1039kb,D)", "http://arxiv.org/abs/1412.6568v2", null], ["v3", "Wed, 15 Apr 2015 13:10:07 GMT  (1039kb,D)", "http://arxiv.org/abs/1412.6568v3", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["georgiana dinu", "angeliki lazaridou", "marco baroni"], "accepted": true, "id": "1412.6568"}, "pdf": {"name": "1412.6568.pdf", "metadata": {"source": "CRF", "title": "IMPROVING ZERO-SHOT LEARNING BY MITIGATING THE HUBNESS PROBLEM", "authors": ["Georgiana Dinu", "Angeliki Lazaridou", "Marco Baroni"], "emails": ["georgiana.dinu@unitn.it", "angeliki.lazaridou@unitn.it", "marco.baroni@unitn.it"], "sections": [{"heading": "1 INTRODUCTION", "text": "Extensive research in computational linguistics and neural language modeling has shown that contextual co-occurrence patterns of words in corpora can be effectively exploited to learn high-quality vector-based representations of their meaning in an unsupervised manner (Collobert et al., 2011; Clark, 2015; Turney & Pantel, 2010). This has in turn led to the development of the so-called zeroshot learning paradigm as a way to address the manual annotation bottleneck in domains where other vector-based representations (e.g., images or brain signals) must be associated to word labels (Palatucci et al., 2009). The idea is to use the limited training data available to learn a general mapping function from vectors in the domain of interest to word vectors, and then apply the induced function to map vectors representing new entities (that were not seen in training) onto word space, retrieving the nearest neighbour words as their labels. This approach has originally been tested in neural decoding (Mitchell et al., 2008; Palatucci et al., 2009), where the task consists in learning a regression function from fMRI activation vectors to word representations, and then applying it to the brain signal of a concept outside the training set, in order to \u201cread the mind\u201d of subjects. In computer vision, zero-shot mapping of image vectors onto word space has been applied to the task of retrieving words to label images of objects outside the training inventory (Frome et al., 2013; Socher et al., 2013), as well as using the inverse language-to-vision mapping for image retrieval (Lazaridou et al., 2014a). Finally, the same approach has been applied in a multilingual context, using translation pair vectors to learn a cross-language mapping, that is then exploited to translate new words (Mikolov et al., 2013b).\nZero-shot learning is a very promising and general technique to reduce manual supervision. However, while all experiments above report very encouraging results, performance is generally quite low in absolute terms. For example, the system of Frome et al. (2013) returns the correct image label as top hit in less than 1% of cases in all zero-shot experiments (see their Table 2). Performance is always above chance, but clearly not of practical utility.\nIn this paper, we study one specific problem affecting the quality of zero-shot labeling, following up on an observation that we made, qualitatively, in our experiments: The neighbourhoods surrounding mapped vectors contain many items that are \u201cuniversal\u201d neighbours, that is, they are neighbours of a large number of different mapped vectors. The presence of such vectors, known as hubs, is an intrinsic problem of high-dimensional spaces (Radovanovic\u0301 et al., 2010b). Hubness has already\nar X\niv :1\n41 2.\n65 68\nv3 [\ncs .C\nL ]\n1 5\nA pr\n2 01\n5\nbeen shown to be an issue for word-based vectors (Radovanovic\u0301 et al., 2010a).1 However, as we show in Section 2, the problem is much more severe for neighbourhoods of vectors that are mapped onto a high-dimensional space from elsewhere through a regression algorithm. We leave a theoretical understanding of why hubness affects regression-based mappings to further work. Our current contributions are to demonstrate the hubness problem in the zero-shot setup, to present a simple and efficient method to get rid of it by adjusting the similarity matrix after mapping, and to show how this brings consistent performance improvements across different tasks. While one could address the problem by directly designing hubness-repellent mapping functions, we find our post-processing solution more attractive as it allows us to use very simple and general least-squares regression methods to train and perform the mapping.\nWe use use the term pivots to stand for a set of vectors we retrieve neighbours for (these comprise at least, in our setting, the zero-shot-mapped vectors) and targets for the subspace of vectors we retrieve the neighbours from (often, corresponding to the whole space of interest). Then, we can phrase our proposal as follows. Standard nearest neighbour queries rank the targets independently for each pivot. A single target is allowed to be the nearest neighbour, or among the top k nearest neighbours, of a large proportion of pivots: and this is exactly what happens empirically (the hubness problem). We can greatly mitigate the problem by taking the global distribution of targets across pivots into account. In particular, we use the very straightforward and effective strategy of inverting the query: we convert the similarity scores of a target with all pivots to the corresponding ranks, and then retrieve the nearest neighbours of a pivot based on such ranks, instead of the original similarity scores. We will empirically show that with this method high-hubness targets are down-ranked for many pivots, and will kept as neighbours only when semantically appropriate."}, {"heading": "2 HUBNESS IN ZERO-SHOT MAPPING", "text": "The Zero-shot setup In zero-shot learning, training data consist of vector representations in the source domain (e.g., source language for translation, image vectors for image annotation) paired with language labels (the target domain): Dtr = {(xi, yi)}mi=1, where xi \u2208 Ru and yi \u2208 Ttr, a vocabulary containing training labels. At test time, the task is to label vectors which have a novel label: Dts = {(xi, yi)}ni=1, yi \u2208 Tts, with Tts \u2229 Ttr = \u2205. This is possible because labels y have vector representations y \u2208 Rv .2 Training is cast as a multivariate regression problem, learning a function which maps the source domain vectors to their corresponding target (linguistic-space) vectors. A straightforward and performant choice (Lazaridou et al., 2014a; Mikolov et al., 2013b) is to assume the mapping function is a linear map W, and use a l2-regularized least-squares error objective:\nW\u0302 = arg min W\u2208Rv\u00d7u\n||XW \u2212Y||F + \u03bb||W|| (1)\nwhere X and Y are matrices obtained through the concatenation of train source vectors and the target vectors of the corresponding labels.\nOnce the linear function has been estimated, any source vector x \u2208 Ru can be mapped into the target domain through xTW.\nTarget space label retrieval Given a source element x \u2208 S and its vector x, the standard way to retrieve a target space label (T ) is by returning the nearest neighbour (according to some similarity measure) of mapped x from the set of vector representations of T . Following common practice, we use the cosine as our similarity measure.\nWe denote by Rankx,T (y) the rank of an element y \u2208 T w.r.t. its similarity to x and assuming a query space T . More precisely, this is the position of y in the (decreasingly) sorted list of similarities: [cos(x, yi)|yi \u2208 T ]. This is an integer from 1 to |T | (assuming distinct cosine values). Under this notation, the standard nearest neighbour of x is given by:\nNN1(x, T ) = arg min y\u2208T Rankx,T (y) (2)\n1Radovanovic\u0301 et al. (2010a) propose a supervised hubness-reducing method for document vectors that is not extensible to the zero-shot scenario, as it assumes a binary relevance classification setup.\n2We use x and x to stand for a label and its corresponding vector.\nWe will use NNk(x, T ) to stand for the set of k-nearest neighbours in T , omitting the T argument for brevity.\nHubness We can measure how hubby an item y \u2208 T is with respect to a set of pivot vectors P (where T is the search space) by counting the number of times it occurs in the k-nearest neighbour lists of elements in P :\nNk,P (y) = |{y \u2208 NNk(x, T )|x \u2208 P}| (3)\nAn item with a large Nk value (we will omit the set subscript when it is clear from the context) occurs in the NNk set of many elements and is therefore a hub.\nHubness has been shown to be an intrinsic problem of high-dimensional spaces: as we increase the dimensionality of the space, a number of elements, which are, by all means, not similar to all other items, become hubs. As a results nearest neighbour queries return the hubs at top 1, harming accuracy. It is known that the problem of hubness is related to concentration, the tendency of pairwise similarities between elements in a set to converge to a constant as the dimensionality of the space increases (Radovanovic\u0301 et al., 2010b). Radovanovic\u0301 et al. (2010a) show that this also holds for cosine similarity (which is used almost exclusively in linguistic applications): the expectation of pairwise similarities becomes constant and the standard deviation converges to 0. This, in turn, is known to cause an increase in hubness.\nOriginal vs. mapped vectors In previous work we have (qualitatively) observed a tendency of the hubness problem to become worse when we query a target space in which some elements have been mapped from a different source space. In order to investigate this more closely, we compare the properties of mapped elements versus original ones. We consider word translation as an application and use 300-dimensional vectors of English words as source and vectors of Italian words as target. We have, in total, vocabularies of 200,000 English and Italian words, which we denote S and T . We use a set of 5,000 translation pairs as training data and learn a linear map.\nWe then pick a random test set Ts of 1,500 English words that have not been seen in training and map them to Italian using the learned training function (full details in Section 3.1 below). We compute the hubness of all elements in T using the test set items as pivots, and considering all 200, 000 items in the target space as potential neighbours (as any of them could be the right translation of a test word). In the first setting (original), we use target space items: for the test instance car \u2192 auto, we use the true Italian auto vector. In the second and third settings (mapped) we use the mapped vectors (our predicted translation vector of car into Italian), mapped through a matrix learned without and with regularization, respectively. Figure 1 plots the distribution of the N20,Ts(y) scores in these three settings.\nAs the plots show, the hubness problem is indeed greatly exacerbated. When using the original Ts elements, target space hubs reach a N20 level of at most 11, meaning they occur in the NN20 sets of 11 test elements. On the other hand, when using mapped elements the maximum N20 values are above 40 (note that the x axes are on different scales in the plots!). Moreover, regularization does not significantly mitigate hubness, suggesting that it is not just a matter of overfitting, such that the mapping function projects everything near vectors it sees during training."}, {"heading": "3 A GLOBALLY CORRECTED NEIGHBOUR RETRIEVAL METHOD", "text": "One way to correct for the increase in hubness caused by mapping is to compute hubness scores for all target space elements. Then, given a test set item, we re-rank its nearest neighbours by downplaying the importance of elements that have a high hubness score. Methods for this have been proposed and evaluated, for example, by Radovanovic\u0301 et al. (2010a) and Tomasev et al. (2011a). We adopt a much simpler approach (similar in spirit to Tomasev et al., 2011b, but greatly simplified), which takes advantage of the fact that we almost always have access not to just 1 test instance, but more vectors in the source domain (these do not need to be labeled instances). We map these additional pivot elements and conjecture that we can use the topology of the subspace where the mapped pivot set lives to correct nearest neighbour retrieval. We consider first the most straightforward way to achieve this effect. A hub is an element which appears in many NNk lists because it has high similarity with many items. A simple way to correct for this is to normalize the vector of similarities of each target item to the mapped pivots to length 1, prior to performing NN queries. This way, a vector with very high similarities to many pivots will be penalized. We denote this method NNnrm.\nWe propose a second corrected measure, which does not re-weight the similarity scores, but ranks target elements using NN statistics for the entire mapped pivot set. Instead of the nearest neighbour retrieval method in Equation (2), we use a following globally-corrected (GC) approach, that could be straightforwardly implemented as:\nGC1(x, T ) = arg min y\u2208T Ranky,P (x) (4)\nTo put it simply, this method reverses the querying: instead of returning the nearest neighbour of pivot x as a solution, it returns the target element y which has x ranked highest. Intuitively, a hub may still occur in the NN lists of some elements, but only if not better alternatives are present. The formulation of GC in Equation (4) can however lead to many tied ranks: For example, we want to translate car, but both Italian auto and macchina have car as their second nearest neighbour (so both rank 2) and no Italian word has car as first neighbour (no rank 1 value). We use the cosine scores to break ties, therefore car will be translated with auto if the latter has a higher cosine with the mapped car vector, with macchina otherwise. Note that when only one source vector is available, the GC method becomes equivalent to a standard NN query. As the cosine is smaller than 1 and ranks larger or equal to 1, the following equation implements GC with cosine-based tie breaking:\nGC1(x, T ) = arg min y\u2208T\n(Ranky,P (x)\u2212 cos(x, y)) (5)"}, {"heading": "3.1 ENGLISH TO ITALIAN WORD TRANSLATION", "text": "We first test our methods on bilingual lexicon induction. As the amount of parallel data is limited, there has been a lot of work on acquiring translation dictionaries by using vector-space methods on monolingual corpora, together with a small seed lexicon (Haghighi et al., 2008; Klementiev et al., 2012; Koehn & Knight, 2002; Rapp, 1999). One of the most straightforward and effective methods is to represent words as high-dimensional vectors that encode co-occurrence only with the words in the seed lexicon and are therefore comparable cross-lingually (Klementiev et al., 2012; Rapp, 1999). However, this method is limited to vector spaces that use words as context features, and does not extend to vector-based word representations relying on other kinds of dimensions, such as those neural language models that have recently been shown to greatly outperform context-word-based representations (Baroni et al., 2014). The zero-shot approach, that induces a function from one space to the other based on paired seed element vectors, and then applies it to new data, works irrespective of the choice of vector representation. This method has been shown to be effective for bilingual lexicon construction by Mikolov et al. (2013b), with Dinu & Baroni (2014) reporting overall better performance than with the seed-word-dimension method. We set up a similar evaluation on the task of finding Italian translations of English words.\nWord representations The cbow method introduced by Mikolov et al. (2013a) induces vectorbased word representations by trying to predict a target word from the words surrounding it within a neural network architecture. We use the word2vec toolkit3 to learn 300-dimensional representations of 200,000 words with cbow. We consider a context window of 5 words to either side of the target, we set the sub-sampling option to 1e-05 and estimate the probability of a target word with the negative sampling method, drawing 10 samples from the noise distribution (Mikolov et al., 2013a). We use 2.8 billion tokens as input (ukWaC + Wikipedia + BNC) for English and the 1.6 billion itWaC tokens for Italian.4\nTraining and testing Both train and test translation pairs are extracted from a dictionary built from Europarl, available at http://opus.lingfil.uu.se/ (Europarl, en-it) (Tiedemann, 2012). We use 1,500 English words split into 5 frequency bins as test set (300 randomly chosen in each bin). The bins are defined in terms of rank in the (frequency-sorted) lexicon: [1-5K], [5K-20K], [20K-50K], [50K-100K] and [100K-200K]. The bilingual lexicon acquisition literature generally tests on very frequent words only. Translating medium or low frequency words is however both more challenging and useful. We also sample the training translation pairs by frequency, using the top 1K, 5K, 10K and 20K most frequent translation pairs from our dictionary (by English frequency), while making sure there is no overlap with test elements.\nFor each test element we query the entire (200,000) target space and report translation accuracies. An English word may occur with more than one Italian translation (1.2 on average in the entire data): in evaluation, an instance is considered correct if any of these is predicted. We test the standard method (regular NN querying) as well as the two corrected methods: NNnrm and GC. As previously discussed, the latter benefit from more mapped data, in addition to an individual test instance, to be used as pivots. In addition to the 1,500 test elements, we report performance when mapping other 20,000 randomly chosen English words (their Italian translations are not needed). We actually observed improvements also when using solely the 1,500 mapped test elements as pivots, but increasing the size with arbitrary additional data (that can simply be sampled from the source space without any need for supervision) helps performance.\nResults Results are given in Figure 2. We report results without regularization as well as with the regularization parameter \u03bb estimated by generalized cross-validation (GCV) (Hastie et al., 2009, p. 244). Both corrected methods achieve significant improvements over standard NN, ranging from 7% to 14%. For the standard method, the performance decreases as the training data size increases beyond 5K, probably due to the noise added by lower-frequency words. The corrected measures are robust against this effect: adding more training data does not help, but it does not harm them either. Regularization does not improve, and actually hampers the standard method, whereas it benefits the corrected measures when using a small amount of training data (1K), and does not affect performance otherwise. The results by frequency bin show that most of the improvements are brought about for the all-important medium- and low-frequency words. Although not directly comparable, the absolute numbers we obtain are in the range of those reported by Mikolov et al. (2013b), whose test data correspond, in terms of frequency, to those in our first 2 bins. Furthermore, we observe, similarly to them, that the accuracy scores underestimate the actual performance, as many translations are in fact correct but not present in our gold dictionary.\nThe elements with the largest hub score are shown in Figure 3 (left). As can be seen, they tend to be \u201cgarbage\u201d low-frequency words. However, in any realistic setting such low-frequency terms should not be filtered out, as good translations might also have low frequency. As pointed out by Radovanovic\u0301 et al. (2010b), hubness correlates with proximity to the test-set mean vector (the average of all test vectors). Hubness level is plotted against cosine-to-mean in Figure 3 (right).\nTable 1 presents some cases where wrong translation are \u201ccorrected\u201d by the GC measure. The latter consistently pushes high-hubness elements down the neighbour lists. For example, 11/09/2002, that was originally returned as the translation of backwardness, can be found in the N20 list of 110 English words. With the corrected method, the right translation, arretratezza, is obtained. 11/09/2002 is returned as the translation, this time, of only two other English pivot words: orthodoxies and ku-\n3https://code.google.com/p/word2vec/ 4Corpus sources: http://wacky.sslmit.unibo.it, http://en.wikipedia.org, http://\nwww.natcorp.ox.ac.uk\nmaratunga. The hubs we correct for are not only garbage ones, such as 11/09/2002, but also more standard words such as dio (god) or violentatori (rapists), also shown in Table 1.5"}, {"heading": "3.2 ZERO-SHOT IMAGE LABELING AND RETRIEVING", "text": "In this section we test our proposed method in a cross-modal setting, mapping images to word labels and vice-versa.\nExperimental setting We use the data set of Lazaridou et al. (2014b) containing 5,000 word labels, each associated to 100 ImageNet pictures (Deng et al., 2009). Word representations are extracted from Wikipedia with word2vec in skip-gram mode. Images are represented by 4096- dimensional vectors extracted using the Caffe toolkit (Jia et al., 2014) together with the pre-trained convolutional neural network of Krizhevsky et al. (2012). We use a random 4/1 train/test split.\nResults We consider both the usual image labeling setting (Vision\u2192Language) and the image retrieval setting (Language\u2192Vision). For the Vision\u2192Language task, we use as pivot set the 100K test images (1,000 labels x 100 images/label) and an additional randomly chosen 100K images. The search space is the entire label set of 5,000 words. For Language\u2192Vision, we use as pivot set the entire word list (5,000) and the target set is the entire set of images (500,000). The objects depicted in the images form a set of 5,000 distinct elements, therefore, for the word cat, for example, returning any of the 100 cat images is correct. Chance accuracy in both settings is thus at 1/5,000. Table 2 reports accuracy scores.6 We observe that, differently from the translation case, correcting by normalizing the cosine scores of the elements in the target domain (NNnrm) leads to poorer results than no correction. On the other hand, the GC method is consistent across domains, and it improves significantly on the standard NN method in both settings. Note that, while there are differences between the setups, Frome et al. (2013) report accuracy results below 1% in all their zero-shot experiments, including those with chance levels comparable to ours.\nIn order to investigate the hubness of the corrected solution, we plot similar figures as in Section 2, computing the N20 distribution of the target space elements w.r.t the pivots in the test set.7 Figure 4 shows this distribution 1) for the vectors of the gold word labels in language space, 2) the corresponding Vision\u2192Language mapped test vectors, as well as 3) N20 values computed using GC correction.8 Similarly to the translation case, the maximum hubness values increase significantly from the original target space vectors to the mapped items. When adjusting the rank with the GC method, hubness decreases to a level that is now below that of the original items. We observe\n5Prompted by a reviewer, we also performed preliminary experiments with a margin-based ranking objective similar to the one in WSABIE Weston et al. (2011) and DeViSE Frome et al. (2013) which is typically reported to outperform the l2 objective in Equation 1 (Socher et al. (2014)). Given a pair of training items (xi,yi) and the corresponding prediction y\u0302i = Wxi, the error is given by: \u2211k j=1,j 6=i max{0, \u03b3+dist(y\u0302i,yi)\u2212dist(y\u0302i,yj)}, where dist is a distance measure, which we take to be inverse cosine, and \u03b3 and k are the margin and the number of negative examples, respectively. We tune \u03b3-the margin and k-the number of negative samples on a held-out set containing 25% of the training data. We estimate W using stochastic gradient descent where per-parameter learning rates are tuned with Adagrad Duchi et al. (2011). Results on the En\u2192It task are at 38.4 (NN) and further improved to 40.6 (GC retrieval), confirming that GC is not limited to least-squares error estimation settings.\n6The non-regularized objective led to very low results in both directions and for all methods, and we omit these results.\n7In order to facilitate these computations, we use \u201caggregated\u201d visual vectors corresponding to each word label (e.g., we obtain a single cat vector in image space by averaging the vectors of 100 cat pictures).\n8We abuse notation here, asN20 is defined as in Equation 3 for 1) and 2) and as |{y \u2208 GCk(x, T )|x \u2208 P \u2032}| for 3).\nthe same trend in the Language\u2192Vision direction (as well as in the translation experiments in the previous section), the specifics of which we however leave out for brevity."}, {"heading": "4 CONCLUSION", "text": "In this paper we have shown that the basic setup in zero-shot experiments (use multivariate linear regression with a regularized least-squares error objective to learn a mapping across representational vectors spaces) is negatively affected by strong hubness effects. We proposed a simple way to correct for this by replacing the traditional nearest neighbour queries with globally adjusted ones. The method only requires the availability of more, unlabeled source space data, in addition to the test instances. While more advanced ways for learning the mapping could be employed (e.g., incorporating hubness avoidance strategies into non-linear functions or different learning objectives), we have shown that consistent improvements can be obtained, in very different domains, already with our query-time correction of the basic learning setup, which is a popular and attractive one, given its simplicity, generality and high performance. In future work we plan to investigate whether the hubness effect carries through to other setups: For example, to what extent different kinds of word representations and other learning objectives are affected by it. This empirical work should pose a solid basis for a better theoretical understanding of the causes of hubness increase in cross-space mapping."}, {"heading": "5 ACKNOWLEDGMENTS", "text": "This work was supported by the ERC 2011 Starting Independent Research Grant n. 283554 (COMPOSES)."}], "references": [{"title": "Don\u2019t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors", "author": ["Baroni", "Marco", "Dinu", "Georgiana", "Kruszewski", "Germ\u00e1n"], "venue": "In Proceedings of ACL,", "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Vector space models of lexical meaning", "author": ["Clark", "Stephen"], "venue": "Handbook of Contemporary Semantics,", "citeRegEx": "Clark and Stephen.,? \\Q2015\\E", "shortCiteRegEx": "Clark and Stephen.", "year": 2015}, {"title": "Natural language processing (almost) from scratch", "author": ["Collobert", "Ronan", "Weston", "Jason", "Bottou", "L\u00e9on", "Karlen", "Michael", "Kavukcuoglu", "Koray", "Kuksa", "Pavel"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Deng", "Jia", "Dong", "Wei", "Socher", "Richard", "Li", "Lia-Ji", "Fei-Fei"], "venue": "In Proceedings of CVPR,", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "How to make words with vectors: Phrase generation in distributional semantics", "author": ["Dinu", "Georgiana", "Baroni", "Marco"], "venue": "In Proceedings of ACL,", "citeRegEx": "Dinu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dinu et al\\.", "year": 2014}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["Duchi", "John", "Hazan", "Elad", "Singer", "Yoram"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "DeViSE: A deep visual-semantic embedding model", "author": ["Frome", "Andrea", "Corrado", "Greg", "Shlens", "Jon", "Bengio", "Samy", "Dean", "Jeff", "Ranzato", "Marc\u2019Aurelio", "Mikolov", "Tomas"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Frome et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Frome et al\\.", "year": 2013}, {"title": "Learning bilingual lexicons from monolingual corpora", "author": ["Haghighi", "Aria", "Liang", "Percy", "Berg-Kirkpatrick", "Taylor", "Klein", "Dan"], "venue": "In Proceedings of ACL,", "citeRegEx": "Haghighi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Haghighi et al\\.", "year": 2008}, {"title": "The Elements of Statistical Learning, 2nd edition", "author": ["Hastie", "Trevor", "Tibshirani", "Robert", "Friedman", "Jerome"], "venue": null, "citeRegEx": "Hastie et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hastie et al\\.", "year": 2009}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Jia", "Yangqing", "Shelhamer", "Evan", "Donahue", "Jeff", "Karayev", "Sergey", "Long", "Jonathan", "Girshick", "Ross", "Guadarrama", "Sergio", "Darrell", "Trevor"], "venue": "In Proceedings of the ACM International Conference on Multimedia, MM", "citeRegEx": "Jia et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2014}, {"title": "Toward statistical machine translation without parallel corpora", "author": ["Klementiev", "Alexandre", "Irvine", "Ann", "Callison-Burch", "Chris", "Yarowsky", "David"], "venue": "In Proceedings of EACL,", "citeRegEx": "Klementiev et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Klementiev et al\\.", "year": 2012}, {"title": "Learning a translation lexicon from monolingual corpora", "author": ["Koehn", "Philipp", "Knight", "Kevin"], "venue": "Proceedings of ACL Workshop on Unsupervised Lexical Acquisition,", "citeRegEx": "Koehn et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2002}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Is this a wampimuk? cross-modal mapping between distributional semantics and the visual world", "author": ["Lazaridou", "Angeliki", "Bruni", "Elia", "Baroni", "Marco"], "venue": "In Proceedings of ACL,", "citeRegEx": "Lazaridou et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lazaridou et al\\.", "year": 2014}, {"title": "Combining language and vision with a multimodal skip-gram model", "author": ["Lazaridou", "Angeliki", "Pham", "The Nghia", "Baroni", "Marco"], "venue": "In NIPS workshop on Learning Semantics,", "citeRegEx": "Lazaridou et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lazaridou et al\\.", "year": 2014}, {"title": "Efficient estimation of word representations in vector space", "author": ["Mikolov", "Tomas", "Chen", "Kai", "Corrado", "Greg", "Dean", "Jeffrey"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Exploiting similarities among languages for Machine Translation", "author": ["Mikolov", "Tomas", "Le", "Quoc", "Sutskever", "Ilya"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Predicting human brain activity associated with the meanings of nouns", "author": ["Mitchell", "Tom", "Shinkareva", "Svetlana", "Carlson", "Andrew", "Chang", "Kai-Min", "Malave", "Vincente", "Mason", "Robert", "Just", "Marcel"], "venue": "Science, 320:1191\u20131195,", "citeRegEx": "Mitchell et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2008}, {"title": "Zero-shot learning with semantic output codes", "author": ["Palatucci", "Mark", "Pomerleau", "Dean", "Hinton", "Geoffrey E", "Mitchell", "Tom M"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Palatucci et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Palatucci et al\\.", "year": 2009}, {"title": "On the existence of obstinate results in vector space models", "author": ["Radovanovi\u0107", "Milos", "Nanopoulos", "Alexandros", "Ivanovi\u0107", "Mirjana"], "venue": "In Proceedings of SIGIR,", "citeRegEx": "Radovanovi\u0107 et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Radovanovi\u0107 et al\\.", "year": 2010}, {"title": "Hubs in space: Popular nearest neighbors in high-dimensional data", "author": ["Radovanovi\u0107", "Milo\u0161", "Nanopoulos", "Alexandros", "Ivanovi\u0107", "Mirjana"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Radovanovi\u0107 et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Radovanovi\u0107 et al\\.", "year": 2010}, {"title": "Automatic identification of word translations from unrelated english and german corpora", "author": ["Rapp", "Reinhard"], "venue": "In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics,", "citeRegEx": "Rapp and Reinhard.,? \\Q1999\\E", "shortCiteRegEx": "Rapp and Reinhard.", "year": 1999}, {"title": "Zero-shot learning through cross-modal transfer", "author": ["Socher", "Richard", "Ganjoo", "Milind", "Manning", "Christopher", "Ng", "Andrew"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Grounded compositional semantics for finding and describing images with sentences", "author": ["Socher", "Richard", "Le", "Quoc", "Manning", "Christopher", "Ng", "Andrew"], "venue": "Transactions of the Association for Computational Linguistics,", "citeRegEx": "Socher et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2014}, {"title": "Parallel data, tools and interfaces in opus", "author": ["Tiedemann", "J\u00f6rg"], "venue": "In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC\u201912),", "citeRegEx": "Tiedemann and J\u00f6rg.,? \\Q2012\\E", "shortCiteRegEx": "Tiedemann and J\u00f6rg.", "year": 2012}, {"title": "The influence of hubness on nearest-neighbor methods in object recognition", "author": ["Tomasev", "Nenad", "Brehar", "Raluca", "Mladenic", "Dunja", "Nedevschi", "Sergiu"], "venue": "Intelligent Computer Communication and Processing (ICCP),", "citeRegEx": "Tomasev et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tomasev et al\\.", "year": 2011}, {"title": "A probabilistic approach to nearest-neighbor classification: naive hubness bayesian knn", "author": ["Tomasev", "Nenad", "Radovanovic", "Milos", "Mladenic", "Dunja", "Ivanovic", "Mirjana"], "venue": "In CIKM,", "citeRegEx": "Tomasev et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tomasev et al\\.", "year": 2011}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["Turney", "Peter", "Pantel", "Patrick"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Turney et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turney et al\\.", "year": 2010}, {"title": "Wsabie: Scaling up to large vocabulary image annotation", "author": ["Weston", "Jason", "Bengio", "Samy", "Usunier", "Nicolas"], "venue": "In Proceedings of IJCAI,", "citeRegEx": "Weston et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 2, "context": "Extensive research in computational linguistics and neural language modeling has shown that contextual co-occurrence patterns of words in corpora can be effectively exploited to learn high-quality vector-based representations of their meaning in an unsupervised manner (Collobert et al., 2011; Clark, 2015; Turney & Pantel, 2010).", "startOffset": 269, "endOffset": 329}, {"referenceID": 18, "context": ", images or brain signals) must be associated to word labels (Palatucci et al., 2009).", "startOffset": 61, "endOffset": 85}, {"referenceID": 17, "context": "This approach has originally been tested in neural decoding (Mitchell et al., 2008; Palatucci et al., 2009), where the task consists in learning a regression function from fMRI activation vectors to word representations, and then applying it to the brain signal of a concept outside the training set, in order to \u201cread the mind\u201d of subjects.", "startOffset": 60, "endOffset": 107}, {"referenceID": 18, "context": "This approach has originally been tested in neural decoding (Mitchell et al., 2008; Palatucci et al., 2009), where the task consists in learning a regression function from fMRI activation vectors to word representations, and then applying it to the brain signal of a concept outside the training set, in order to \u201cread the mind\u201d of subjects.", "startOffset": 60, "endOffset": 107}, {"referenceID": 6, "context": "In computer vision, zero-shot mapping of image vectors onto word space has been applied to the task of retrieving words to label images of objects outside the training inventory (Frome et al., 2013; Socher et al., 2013), as well as using the inverse language-to-vision mapping for image retrieval (Lazaridou et al.", "startOffset": 178, "endOffset": 219}, {"referenceID": 22, "context": "In computer vision, zero-shot mapping of image vectors onto word space has been applied to the task of retrieving words to label images of objects outside the training inventory (Frome et al., 2013; Socher et al., 2013), as well as using the inverse language-to-vision mapping for image retrieval (Lazaridou et al.", "startOffset": 178, "endOffset": 219}, {"referenceID": 6, "context": "For example, the system of Frome et al. (2013) returns the correct image label as top hit in less than 1% of cases in all zero-shot experiments (see their Table 2).", "startOffset": 27, "endOffset": 47}, {"referenceID": 19, "context": "It is known that the problem of hubness is related to concentration, the tendency of pairwise similarities between elements in a set to converge to a constant as the dimensionality of the space increases (Radovanovi\u0107 et al., 2010b). Radovanovi\u0107 et al. (2010a) show that this also holds for cosine similarity (which is used almost exclusively in linguistic applications): the expectation of pairwise similarities becomes constant and the standard deviation converges to 0.", "startOffset": 205, "endOffset": 260}, {"referenceID": 19, "context": "Methods for this have been proposed and evaluated, for example, by Radovanovi\u0107 et al. (2010a) and Tomasev et al.", "startOffset": 67, "endOffset": 94}, {"referenceID": 19, "context": "Methods for this have been proposed and evaluated, for example, by Radovanovi\u0107 et al. (2010a) and Tomasev et al. (2011a). We adopt a much simpler approach (similar in spirit to Tomasev et al.", "startOffset": 67, "endOffset": 121}, {"referenceID": 7, "context": "As the amount of parallel data is limited, there has been a lot of work on acquiring translation dictionaries by using vector-space methods on monolingual corpora, together with a small seed lexicon (Haghighi et al., 2008; Klementiev et al., 2012; Koehn & Knight, 2002; Rapp, 1999).", "startOffset": 199, "endOffset": 281}, {"referenceID": 10, "context": "As the amount of parallel data is limited, there has been a lot of work on acquiring translation dictionaries by using vector-space methods on monolingual corpora, together with a small seed lexicon (Haghighi et al., 2008; Klementiev et al., 2012; Koehn & Knight, 2002; Rapp, 1999).", "startOffset": 199, "endOffset": 281}, {"referenceID": 10, "context": "One of the most straightforward and effective methods is to represent words as high-dimensional vectors that encode co-occurrence only with the words in the seed lexicon and are therefore comparable cross-lingually (Klementiev et al., 2012; Rapp, 1999).", "startOffset": 215, "endOffset": 252}, {"referenceID": 0, "context": "However, this method is limited to vector spaces that use words as context features, and does not extend to vector-based word representations relying on other kinds of dimensions, such as those neural language models that have recently been shown to greatly outperform context-word-based representations (Baroni et al., 2014).", "startOffset": 304, "endOffset": 325}, {"referenceID": 0, "context": "However, this method is limited to vector spaces that use words as context features, and does not extend to vector-based word representations relying on other kinds of dimensions, such as those neural language models that have recently been shown to greatly outperform context-word-based representations (Baroni et al., 2014). The zero-shot approach, that induces a function from one space to the other based on paired seed element vectors, and then applies it to new data, works irrespective of the choice of vector representation. This method has been shown to be effective for bilingual lexicon construction by Mikolov et al. (2013b), with Dinu & Baroni (2014) reporting overall better performance than with the seed-word-dimension method.", "startOffset": 305, "endOffset": 637}, {"referenceID": 0, "context": "However, this method is limited to vector spaces that use words as context features, and does not extend to vector-based word representations relying on other kinds of dimensions, such as those neural language models that have recently been shown to greatly outperform context-word-based representations (Baroni et al., 2014). The zero-shot approach, that induces a function from one space to the other based on paired seed element vectors, and then applies it to new data, works irrespective of the choice of vector representation. This method has been shown to be effective for bilingual lexicon construction by Mikolov et al. (2013b), with Dinu & Baroni (2014) reporting overall better performance than with the seed-word-dimension method.", "startOffset": 305, "endOffset": 664}, {"referenceID": 15, "context": "Word representations The cbow method introduced by Mikolov et al. (2013a) induces vectorbased word representations by trying to predict a target word from the words surrounding it within a neural network architecture.", "startOffset": 51, "endOffset": 74}, {"referenceID": 8, "context": "We report results without regularization as well as with the regularization parameter \u03bb estimated by generalized cross-validation (GCV) (Hastie et al., 2009, p. 244). Both corrected methods achieve significant improvements over standard NN, ranging from 7% to 14%. For the standard method, the performance decreases as the training data size increases beyond 5K, probably due to the noise added by lower-frequency words. The corrected measures are robust against this effect: adding more training data does not help, but it does not harm them either. Regularization does not improve, and actually hampers the standard method, whereas it benefits the corrected measures when using a small amount of training data (1K), and does not affect performance otherwise. The results by frequency bin show that most of the improvements are brought about for the all-important medium- and low-frequency words. Although not directly comparable, the absolute numbers we obtain are in the range of those reported by Mikolov et al. (2013b), whose test data correspond, in terms of frequency, to those in our first 2 bins.", "startOffset": 137, "endOffset": 1024}, {"referenceID": 19, "context": "As pointed out by Radovanovi\u0107 et al. (2010b), hubness correlates with proximity to the test-set mean vector (the average of all test vectors).", "startOffset": 18, "endOffset": 45}, {"referenceID": 3, "context": "(2014b) containing 5,000 word labels, each associated to 100 ImageNet pictures (Deng et al., 2009).", "startOffset": 79, "endOffset": 98}, {"referenceID": 9, "context": "Images are represented by 4096dimensional vectors extracted using the Caffe toolkit (Jia et al., 2014) together with the pre-trained convolutional neural network of Krizhevsky et al.", "startOffset": 84, "endOffset": 102}, {"referenceID": 10, "context": "Experimental setting We use the data set of Lazaridou et al. (2014b) containing 5,000 word labels, each associated to 100 ImageNet pictures (Deng et al.", "startOffset": 44, "endOffset": 69}, {"referenceID": 3, "context": "(2014b) containing 5,000 word labels, each associated to 100 ImageNet pictures (Deng et al., 2009). Word representations are extracted from Wikipedia with word2vec in skip-gram mode. Images are represented by 4096dimensional vectors extracted using the Caffe toolkit (Jia et al., 2014) together with the pre-trained convolutional neural network of Krizhevsky et al. (2012). We use a random 4/1 train/test split.", "startOffset": 80, "endOffset": 373}, {"referenceID": 6, "context": "Note that, while there are differences between the setups, Frome et al. (2013) report accuracy results below 1% in all their zero-shot experiments, including those with chance levels comparable to ours.", "startOffset": 59, "endOffset": 79}, {"referenceID": 24, "context": "Prompted by a reviewer, we also performed preliminary experiments with a margin-based ranking objective similar to the one in WSABIE Weston et al. (2011) and DeViSE Frome et al.", "startOffset": 133, "endOffset": 154}, {"referenceID": 5, "context": "(2011) and DeViSE Frome et al. (2013) which is typically reported to outperform the l2 objective in Equation 1 (Socher et al.", "startOffset": 18, "endOffset": 38}, {"referenceID": 5, "context": "(2011) and DeViSE Frome et al. (2013) which is typically reported to outperform the l2 objective in Equation 1 (Socher et al. (2014)).", "startOffset": 18, "endOffset": 133}, {"referenceID": 5, "context": "We estimate W using stochastic gradient descent where per-parameter learning rates are tuned with Adagrad Duchi et al. (2011). Results on the En\u2192It task are at 38.", "startOffset": 106, "endOffset": 126}], "year": 2015, "abstractText": "The zero-shot paradigm exploits vector-based word representations extracted from text corpora with unsupervised methods to learn general mapping functions from other feature spaces onto word space, where the words associated to the nearest neighbours of the mapped vectors are used as their linguistic labels. We show that the neighbourhoods of the mapped elements are strongly polluted by hubs, vectors that tend to be near a high proportion of items, pushing their correct labels down the neighbour list. After illustrating the problem empirically, we propose a simple method to correct it by taking the proximity distribution of potential neighbours across many mapped vectors into account. We show that this correction leads to consistent improvements in realistic zero-shot experiments in the cross-lingual, image labeling and image retrieval domains.", "creator": "LaTeX with hyperref package"}}}