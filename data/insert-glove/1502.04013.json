{"id": "1502.04013", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Feb-2015", "title": "Deep Neural Programs for Adaptive Control in Cyber-Physical Systems", "abstract": "rouille We angi introduce Deep Neural Programs (DNP ), amfleet a leros novel cabet programming chilmanov paradigm for kalajian writing adaptive readington controllers for cy - bannock ber - physical ghauri systems (74.64 CPS ). DNP 250,000-dollar replace cantalejo if 462,350 and while serwotka statements, sweatt whose 2,995 discontinuity thawing is sociologist responsible sackhoff for marzook undecidability 9min in CPS secta analysis, 143.4 intractability in ifn CPS jakopin design, sphingidae and frailness in CPS shiran implementation, antarctique with their coudersport smooth, neural neumeyer nif and walton-le-dale nwhile counterparts. sa'ar This not lume only arsanov makes pervomaiskaya CPS analysis earmarked decidable charlene and CPS dorwin design kuptsov tractable, schaffter but also wehle allows macropus to corpsmen write evaporated robust 276.5 and samui adaptive sinead CPS code. litsea In DNP 529,000 the pre-stressed connection between the bhadrak sigmoidal feldberg guards of hypogeum the nif graceful and galusha nwhile statements kunnen has decarlo to finder be 56-yard given icbn as a re-strengthened Gaussian Bayesian spynie network, bernie which musayev reflects 212 the partial knowledge, the CPS odni program has limbed about its environment. consolata To am\u00e1lia the wekesa best of our knowledge, transmitting DNP are the first holloway approach rousay linking aboutraika neural figard networks to programs, in a way inhalable that rind makes explicit tope the meaning of verissimo the network. handwashing In order to overcoat prove zamparini and validate the zinjibar usefulness iguana of DNP, we use them to pronostica write and learn an adaptive miwok CPS resorts controller lucus for the 40-80 parallel parking ferch of the Pioneer kuj\u014d rovers available 111.16 in gollum our kral CPS 2,569 lab.", "histories": [["v1", "Fri, 13 Feb 2015 14:50:22 GMT  (1215kb,D)", "http://arxiv.org/abs/1502.04013v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.RO", "authors": ["konstantin selyunin", "denise ratasich", "ezio bartocci", "radu grosu"], "accepted": false, "id": "1502.04013"}, "pdf": {"name": "1502.04013.pdf", "metadata": {"source": "CRF", "title": "Deep Neural Programs for Adaptive Control in Cyber-Physical Systems", "authors": ["K. Selyunin", "D. Ratasich", "E. Bartocci", "R. Grosu"], "emails": ["konstantin.selyunin@tuwien.ac.at", "denise.ratasich@tuwien.ac.at", "ezio.bartocci@tuwien.ac.at", "radu.grosu@tuwien.ac.at"], "sections": [{"heading": null, "text": "Keywords Cyber-Physical Systems, Adaptive Control, Car Parking, Deep Neural Programs, Gaussian Bayesian Networks."}, {"heading": "1. INTRODUCTION", "text": "Recent advances in sensing, actuation, communication, and computation technologies, as well as innovations in their integration within increasingly smaller, interconnected devices, has lead to the emergence of a new and fascinating class of systems, the so-called cyber-physical systems (CPS). Examples of CPS include smart grids, smart factories, smart transportation, and smart health-care [4].\nSimilarly to living organisms, CPS operate in an uncertain, continuously evolving ecosystem, where they compete for a limited supply of resources. For survival, CPS need to continuously adapt, such that, they react in real time and optimal fashion, with regard to an overall survival metric,\ntheir partial knowledge, and their bounded sensing, actuation, communication and computation capabilities.\nIn order to equip CPS with such exceptional features, various researchers have started to wonder weather our current CPS analysis, design and implementation techniques are still adequate. Going back to Parnas, Chaudhuri and Lezama identified in a series of intriguing papers [6,7,25], the if-thenelse construct as the main culprit for program frailness. In a simple decision of the form if (x > a), the predicate x>a acts like a step function (see Figure 1), with infinite plateaus to the left and to the right of the discontinuity point x= a. In a typical mid-size program, the nesting of thousands of if-then-else conditions leads to a highly nonlinear program, consisting of a large number of plateaus separated by discontinuous jumps. This has important implications.\nFrom a CPS-analysis point of view, predicates of the form f(x)>a, where f(x) is a nonlinear analytic function, are a disaster. They render CPS analysis undecidable. Intuitively, in order to separate all points on one side of the curve f(x) = a, from all on the other side, one needs to forever decrease the size of a grid, in all the rectangles that are crossed by the curve. Such a process does never terminate, except for linear functions where computation is still prohibitive. For this reason, a series of papers, of Fraenzle, Ratschan, Wang, Gao and Clarke [11, 12, 27, 32], proposed the use of an indifference region \u03b4 (see Figure 1), and rewrite the predicates in the form f(x)\u2212a> \u03b4. This approach not only makes program analysis (wrt. reals) decidable, and computable in polynomial time, but it also aligns it with the finite computational precision available in today\u2019s computers.\nFrom a CPS-design point of view, where one is interested to find the values of a for which an optimization criterion is satisfied, predicates of the form f(x)>a are a nightmare. They render CPS optimization intractable. Intuitively, a gradientdescent method searching for a local minimum, gets stuck in plateaus, where a small perturbation to the left or to the right, still keeps the search on the same plateau. In order to alleviate this problem, Chaudhuri and Lezama [6] proposed to smoothen the steps, by passing a Gaussian input distribution through the CPS. This can be thought of as corresponding to the sensing and actuation noise. The parameters of this distribution control the position of the resulting sigmoidal curve (see Figure 1), and its steepness, that is, the width of the above indifference region \u03b4. The authors however, stopped short of proposing a new programming\nar X\niv :1\n50 2.\n04 01\n3v 1\n[ cs\n.A I]\n1 3\nFe b\n20 15\nparadigm, and the step-like functions in the programs to be optimized, posed considerable challenges in the analysis, as they cut the Gaussians in very undesirable ways.\nFrom a CPS-implementation point of view, conditional statements of the form if (f(x) > a) are also a disaster. They render CPS frail and nonadaptive. In other words, a small change in the environment or the program itself, may lead to catastrophic consequences, as the CPS is not able to adapt. In the AI community, where steps are called hard neurons and sigmoid curves are called soft neurons, adaptation and robustness is achieved by learning a particular form of Bayesian networks with soft-neuron distributions, called neural networks. Such networks, and in particular deep neural networks, have recently achieved amazing performance, for example in the recognition of sophisticated patterns [8, 10]. This technology looks so promising that major companies such as Google and Amazon are actively recruiting experts in this area. However, the neural-networks learned are still met with considerable opposition, as it is very difficult, if not impossible, to humanly understand them.\nHaving identified the if-then-else programming construct as the major source of trouble in the analysis, design and implementation of CPS, the following important question still remains: Is there a simple, humanly understandable way to develop robust and adaptive CPS? It is our belief, that such a way not only exists, but it is also amazingly simple!\nFirst, as program skeletons express domain knowledge and developer intuition, they are here to stay. However, one needs to replace hard neurons with their soft counterparts. We call such program statements neural if-then-else statements, or nif-then-else for short. They represent probabilistic, probit distributions, and the decision to choose the left or the right branch is sampled from their associated Gaussian distributions. As a consequence, a program with nif statements represents not only one, but a very large (up to the computational precision) set of correct executions.\nSecond, the partial knowledge of such a program is encoded as a Bayesian network, expressing the conditional dependencies among the Gaussian distributions occurring within the nif statements. These dependencies may be given, learned through a preliminary phase and continuously improved during deployment, or inferred through optimization techniques. In this case, learning and optimization are considerably simplified, as the program is by definition smooth. The depth and the branching structure of these Bayesian networks reflect the sequential and parallel nesting within the program, which is an essential asset in program understanding.\nFor example, a parallel algorithm for pattern recognition,\nmay possess a quad-tree Bayesian structure, hierarchically reflecting the neighbourhood relation among subimages. The depth of the network is determined by the height of the tree. Similarly, a purely sequential program, representing successive decisions, will have a very linear Bayesian structure, whose depth is determined by the number of decisions.\nIn order to validate our new paradigm, we use the parking example from [5]. The goal of this example was to automatically learn the parameters of a program skeleton, intuitively expressing the control as follows: Go backwards up to a point a1, turn up to an angle b1, go backwards up to a2, turn again up to b2 and finally go backwards up to a3. Since this program uses classical if statements, it is not adaptive, and a small perturbation such as a slippery environment, may lead to an accident. We therefore rewrite the program with nif statements, and learn the conditional Gaussian network associated with the predicates within these statements. Using its sensors, the control program is now able to detect the actual stopping or turning points, and to adequately sample its next targets. Although this program is written once and for all, it is able to adapt to a varying environment.\nThe main contributions of the work presented in this paper can be therefore briefly summarized as follows:\n1. We propose a new programming paradigm for the development of smooth and adaptive CPS in which:\n\u2022 Troublesome ifs are replaced by neural ifs, thus improving analysis, design and implementation,\n\u2022 Partial knowledge is encoded within a learned Bayesian network, with Gaussian distributions.\n2. We demonstrate the versatility of this programming paradigm on a parking example using Pioneer rovers. The associated youtube videos are available at [2].\nGiven obvious space limitations, we do not address CPSanalysis and CPS-design (optimization) in this paper. They will be the subject of a series of follow up papers.\nThe rest of the paper is organized as follows. In Section 2 we introduce Bayesian inference, Bayesian networks, and Gaussian and Probit distributions. In Section 3 we introduce our programming paradigm. In Section 4 we discuss how to learn the Gaussian Bayesian network. In Section 5 we discuss our implementation platform and the associated results. In Section 6 we discuss related work. Finally in Section 7 we give our concluding remarks and directions for future work."}, {"heading": "2. BACKGROUND", "text": "The main tool for logical inference is the Modus-Ponens rule: Assuming that proposition A is true, and that from the truth of A one can infer the truth of proposition B, one can conclude that propositions A and B are both true. Formally:\nA \u2227 (A\u2192 B) = A \u2227B = B \u2227 (B \u2192 A)\nIn probability theory, the uncertainty in the truth of a proposition (also called an event) is expressed as a probability, and implication between propositions is expressed as a conditional probability. This leads to a probabilistic extension of Modus-Ponens, known as the Bayes\u2019 rule. Formally:\nP (A) P (B | A) = P (A \u2227B) = P (B) P (A | B)\nThis rule, consistent with logic, is the main mechanism for probabilistic inference [28]. It allows to reason in both forward, or causal way, and backwards, or diagnostic way. For example if B is causally implied by A, then the left term in the above equation denotes a causal relation, and the right term, a diagnostic relation. Equating the two, allows one to use causal information (or observed events), for diagnostic inference. In real-world systems, causal relations are usually chained and can form sophisticated structures.\nBayesian Networks. A probabilistic system is completely characterized by the joint probability distribution of all of its (possibly noisy) components. However, the size of this distribution typically explodes, and its use becomes intractable. In such cases, the Bayes\u2019 rule, allows to successively decompose the joint distribution according to the conditional dependences among its random variables (RV). These are both discrete or continuous variables, which associate to each value (or infinitesimal interval) in their range, the rate of its occurrence. Networks of conditional dependencies among random variables are known as Bayesian networks (BN), and they have a very succinct representation.\nSyntactically, a BN is a direct acyclic graph G = (V,E), where each vertex vi \u2208 V represents a random variable Xi and each edge eij \u2208 E represents a conditional dependence of the variable Xj on the variable Xi. To avoid the complications induced by the use of the joint probability distribution (or density), each variable Xi is associated with a conditional probability distribution (CPD) that takes into account dependencies only between the variable and its direct parents [20, 28]. Such a compact representation keeps information about the system in a distributed manner and makes reasoning tractable even for large number of variables.\nAlthough in many interesting applications the variables of a BN have discrete distributions (e.g. in fault detection, a device might have only a finite number of diagnosable errors, caused by a finite set of faults), in many other applications, continuous random variables naturally describe the entities of interest. For instance, in our parallel parking running example, a Pioneer rover starting from an initial location, needs to execute a sequence of motion primitives (e.g. driving or turning forward or backward with fixed speed for a particular distance Xi or angle Xj), which will result in parking the rover in a dedicated parking spot.\nGaussian Distributions. Any real measurement of a physical quantity is affected by noise. Hence, the distances and the angles occurring in our parking example are naturally expressed as continuous RVs. In this paper we assume that variables have Normal, also called, Gaussian distributions (GD). These distributions naturally occur from the mixing of several (possibly unobservable) RVs, and they have mathematical properties making them very attractive.\nAn univariate Gaussian distribution (UGD) is denoted by N (\u00b5, \u03c32) and it is characterized by two parameters: The mean \u00b5 and the variance \u03c32. In our example, the desired distance in the first motion is associated with \u00b5, which is perturbed by noise with variance \u03c32. The Gaussian proba-\nbility density of a RV X with values x is defined as follows:\npdf\u00b5,\u03c32(x) = 1\u221a 2\u03c0\u03c3 exp\n( \u2212 (x\u2212 \u00b5) 2\n2\u03c32\n) . (1)\nParallel parking includes a sequence of motion primitives that are mutually dependent. To express these dependencies we use a multivariate Gaussian Distribution (MGD) [15], which generalizes the Gaussian distribution to multiple dimensions. For a n-dimensional vector of random variables X the probability density function is characterized by a ndimensional mean vector \u00b5 and a symmetric positive definite covariance matrix \u03a3. To express the probability density of a multivariate Gaussian distribution we use the inverse of covariance matrix, called precision matrix T = \u03a3\u22121, which will be helpful later during the learning phase. The probability density then can be written as follows [24]:\npdf\u00b5,\u03c32(x) = 1\n(2\u03c0)n/2(det(T\u22121))1/2 exp\n( \u22121\n2 \u22062(x)\n) , (2)\nwhere \u22062(x) = (x\u2212 \u00b5)TT(x\u2212 \u00b5).\nA Gaussian BN (GBN) is a BN where random variables X associated to each node in the network have associated a Gaussian distribution, conditional on their parents Xi.\nProbit Distributions. In order to smoothen the decisions in a program, we need to choose a function without plateaus and discontinuities. Since we operate with Gaussian random variables, the natural candidate is their cumulative distribution function (CDF). This is an S -shaped function or a sigmoid (see Figure 2), whose steepness is defined by \u03c32, where erf denotes the error function:\ncdf\u00b5,\u03c32(x) = 1\n2\n( 1 + erf ( x\u2212 \u00b5 \u03c3 \u221a 2 )) , (3)\nFor a particular value x ofX, the function cdf\u00b5,\u03c32(x) returns the probability that a random sample from the distribution N (\u00b5, \u03c32) will belong to the interval (\u2212\u221e, x].\nSince the sensors and actuators of the Pioneer rover are noisy, the trajectories it follows are each time different from the optimal one (assuming that such difference is tolerated by the parking configuration), even if the optimal trajectory of the parking example is known. To be adaptive we use a combined approach: we incorporate probabilistic control structures in the program (introduced in the Section 3) and sample commands from a GBN, whose parameters were learned experimentally. To detect changes in the environment and get more accurate position estimates, data from various sensors are combined with a sensor fusion algorithm."}, {"heading": "3. NEURAL CODE", "text": "Traditional inequality relations (e.g. >, \u2265, \u2264, <) define a sharp (or firm) boundary on the satisfaction of a condition, which represents a step function (see Fig 1). Using firm decisions in a program operating on Normal RVs, cuts distributions in halves, leaving unnormalized and invalid PDFs (see Figure 3: The upper right plot shows the approximation of the PDF after passing a Normal RV through a traditional conditional statement). Hence, to keep a proper PDF after passing a Normal RV through an if or a loop statement one needs to perform a re-normalization of the PDF.\nIn order to avoid re-shaping of probability density each time after a variable is passed through a condition, we introduce a special type of control structure called neural if, or nif for short. The name is coined to express the key novelty of our approach: We propose to use a smooth conditionals cdf\u00b5,\u03c32(x) instead of firm ones (see Figure 1). A nif statement operates on an inequality relation and a variance \u03c32, and decides which branch should be taken: nif(x # y,\u03c32), where # can be replaced with (>, \u2265, \u2264 or <) and \u03c32 represents the uncertainty of making a decision. For the case when \u03c32 \u2192 0 (no uncertainty) we require the nif statement to behave as a traditional if statement.\nThe evaluation of the nif() statement is explained on hand of the following example, where x, a \u2208 R and \u03c32 \u2208 R+.\nnif( x >= a, \u03c32) S1 else S2\nThe evaluation is done in two steps: (i) Find an R interval I representing the confidence of making the decision; (ii) Check if a sample from the GD N (0, \u03c32) belongs to I.\nSince the input RV has a GD, and a GD is used to evaluate the condition, the result is a product of two GDs, which is also a GD scaled by some constant factor k. To find I in (i), we estimate the difference diff(x,a) between x and a. For the general case nif(x # a,\u03c32), with arbitrary #, the difference diff(x,a) is defined as below, where represents the smallest real number on a computer.\ndiff(x,a) =  x - a\u2212 if # is >, x - a if # is \u2265, a - x\u2212 if # is <, a - x if # is \u2264 .\nInformally, our confidence is characterized by the difference: The larger diff(x,a) is, the larger is the probability of executing S1. The probability to execute S1 is given by cdf0,\u03c32(diff(x,a)) and is used to obtain the interval [q1; q2] by calculating two symmetric quantiles q1 and q2 such that:\u222b q2\nq1\npdf0,\u03c32(x)dx = cdf0,\u03c32(diff(x,a)). (4)\nIn the second step a random sample from the distribution N (0, \u03c32) is checked to belong to the interval [q1; q2]. If it is within the interval, S1 is executed, otherwise S2. At this point the probability value to execute S1 is influenced by the variance \u03c32 (see Figure 2). Hence, the dependence is twofold: diff(x,a) shows how confident we are in making a decision, and \u03c32 characterizes the uncertainty.\nFor the case \u03c32 \u2192 0 the nif statement is equivalent to the if statement. For infinitesimal \u03c32 the PDF is expressed as a Dirac function \u03b4(x), which has the following properties:\n(i) \u03b4(x) = +\u221e if x = 0 else 0 (ii) \u222b\u221e \u2212\u221e \u03b4(x) dx = 1.\nThe Dirac function essentially concentrates all the PD in a single point x= 0. In this case the cdf0,\u03c32\u21920(x) becomes a step function (see Figure 1). We consider two cases, as follows: (i) diff(x,a)\u2265 0 and (ii) diff(x,a)< 0. In the first case the probability of executing S1 is equal to 1, hence the\ninterval is (\u2212\u221e; +\u221e) and includes every possible sample; for the second case the probability of taking S1 is 0, hence the interval is empty and cannot contain any sample. An if statement is an nif statement without uncertainty.\nLet us illustrate the concept on a concrete example. Suppose that in the current execution x = 0 and a = 1. Figure 2 illustrates how decisions are made if \u03c32 is: 0.42, \u03c0, 42. Since diff(x,a) = 1, the probability of executing S1 is defined by cdf0,\u03c32(1) and for the above cases is equal to 0.994, 0.714 and 0.599 respectively. The intervals for the above cases are as follows: [-1.095;1.095], [-1.890; 1.890] and [-3.357; 3.357]. In the second step we sample from the distributions with the corresponding \u03c32 (N (0, 0.42), N (0, \u03c0) and N (0, 42)) and check whether the value lies within the intervals.\nSo far we were concerned with single samples x \u223c N (\u00b5, \u03c32). Figure 3 illustrates what happens to the distributions: The differences of passing a GD RV x \u223c N (0, 0.1) through the statements if(x >= 0.15) and nif(x >= 0.15, 0.1). Using our approach the GD is not cut in undesirable ways, and it maintains its GD form after passing the nif statement.\nWe can introduce now the confidence-uncertainty trade-off to loops. The neural while statement, or nwhile for short, is an extension of a traditional while statement which incorporates uncertainty. The statement nwhile( x # a, \u03c32){P1} takes an inequality relation and variance \u03c32 and executes the program P1 according to the following rule: (1) Compute diff(x # a) and obtain quantiles q1 and q2 according to the Equation 4; (2) Check if a random sample x \u223c N (0, \u03c32) is within the interval [q1; q2]; (3) If the sample belongs to the interval, execute P1 and go to step (1), else exit.\nSince the nif and nwhile statements subsume the behavior\nof traditional if and while statements (the case \u03c32 \u2192 0), we use them to define an imperative language with probabilistic control structures. Binary operators bop (such as addition multiplication), unary operators uop (negation), and constants c are used to form expressions E. A program P is a statement S or combination of statements.\nE ::= xi | c | bop(E1, E2) | uop(E1) S ::= skip | xi := E | S1;S2 | nif( xi # c, \u03c32 ) S1 else S2 |\nnwhile( xi # c, \u03c3 2){ S1 }\nIn order to define the denotational semantics for the nif and\nthe nwhile statements, we use check(xi, c, \u03c3 2,#), a function which: (1) Computes the difference diff(xi, c), (2) Finds quantiles q1 and q2 (Equation 4), and (3) Checks if a sample x \u223c N (0, \u03c32) belongs to the interval [q1; q2]. If it does, it returns value 1, otherwise it returns value 0. The denotational semantics of neural programs is then defined as follows:\nJskipK(x) = x\nJxi := E K(x) = x[JEK(x) 7\u2192 xi]\nJ S1;S2 K(x) = JS2K(JS1K(x))\nJnif( xi # c, \u03c32) S1 else S2K(x) = Jcheck(xi, a, \u03c32,#)K(x)JS1K(x) + J\u00accheck(xi, a, \u03c32,#)K(x)JS2K(x)\nJnwhile( xi # c, \u03c32){ S1 }K(x) = xJ\u00accheck(xi, a, \u03c32,# )K(x) + Jcheck(xi, a, \u03c32,# )K(x)Jnwhile( xi # c, \u03c32){ S1 }K(JS1Kx)\nWe are now ready to write the control-program skeleton for the parallel parking task of our Pioneer rover, as a sequence of nwhile statements, as shown in Listing 1. Each nwhile corresponds to executing one motion primitive of the informal description in Section 1. The functions moving() and getPose() are output and input statements, which for simplicity, were omitted from the denotational semantics.\nListing 1: Parallel parking program skeleton nwhile(currentDistance < targetLocation1 , sigma1){\nmoving (); currentDistance = getPose (); }\nupdateTargetLocations (); nwhile(currentAngle < targetLocation2 , sigma2){\nturning (); currentAngle = getAngle (); }\nupdateTargetLocations (); nwhile(currentDistance < targetLocation3 , sigma3){\nmoving (); currentDistance = getPose (); }\nupdateTargetLocations (); nwhile(currentAngle < targetLocation4 , sigma4){\nturning (); currentAngle = getAngle (); }\nupdateTargetLocations (); nwhile(currentDistance < targetLocation5 , sigma5){\nmoving (); currentDistance = getPose (); }\nThe versatility of this approach is that the program skeleton is written only once and comprises infinite number of controllers. The question we need to answer next is:\nWhat are the distances and turning angles for each action and how uncertain are we about each of them?\nTo find the unknown parameters from Listing 1, namely the target locations targetLocations and variances sigmas, we use the learning procedure described in Section 4."}, {"heading": "4. BAYESIAN-NETWORK LEARNING", "text": "Parking can be seen as a sequence of moves and turns, where each action depends on the previous one. For example, the turning angle typically depends on the previously driven distance. Due to sensor noise and imprecision, inertia and friction forces, and also many possible ways to perform a parking task starting from one initial location, we assume that the dependence between actions is probabilistic, and in particular, the RVs are distributed according to Gaussian distributions (GD). We represent the dependencies between actions as the GBN in Figure 4, where li or \u03b1j denotes a distance or a turning angle of the corresponding action and bij is a conditional dependence between consecutive actions.\nIn order to learn the conditional probability distributions of the GBN in Figure 4, and to fill in the targetLocations and the sigmas in Listing 1, we record trajectories of the successful parkings done by a human expert. Figure 5 shows example trajectories used during the learning phase.\nWe than use the fact that any GBN can be converted to an MGD [24] in our learning routine. Learning the parameters of the GBN can be divided into three steps:\n1. Convert the GBN to the corresponding MGD,\n2. Update the precision matrix T of the MGD, 3. Extract \u03c32s and conditional dependences from T.\n1. Conversion step. To construct MGD we need to obtain the mean vector \u00b5 and the precision matrix T. The mean vector \u00b5 comprises the means of all the variables from the GBN. To find the symbolic form of the precision matrix, we\nuse the recursive notation in [16], where the value of the coefficients bi, will be learned in the update step below.\nTi+1 = Ti + bi+1b T i+1 \u03c32i+1 \u2212bi+1 \u03c32i+1\n\u2212b T i+1\n\u03c32i+1\n1 \u03c32i+1  (5) In order to apply Equation 5 we define an ordering starting with the initial node l1. Its precision matrix is equal to:\nT1 = 1\n\u03c321 .\nThe vector bi comprises dependence coefficients for node i on all its immediate parents it in the ordering. For example, the dependence vector for node \u03b12 in the Figure 4 equals to:\nb4 =  00 b43  After applying the Equation 5 to each node in the GBN, we obtain the precision matrix T7, shown in Figure 12. Since each action in the parking task depends only on the previous one (for example, in Figure 4 the turning angle depends on the previously driven distance only), we can generalize the precision matrix for the arbitrary number of moves. For a GBN with k moves, all non-zero elements of the precision matrix T \u2208 Rk;k can be found according to the Equation 6, where T(r, c) is a c-th element in a r-th row of the precision matrix with indices started from one.\nT(i, i\u2212 1) = \u2212 bi(i\u22121) \u03c32i ,\nT(i, i) = 1 \u03c32i + b2(i+1)i \u03c32i+1 ,\nT(i, i+ 1) = \u2212 b(i+1)i \u03c32i+1 ,\n(6)\n2. Update step. Once we derived the symbolic form of the precision matrix (T7 in our example), we use the training set, in order to learn the actual values of its parameters, as described in the algorithm from [24]. Each training example x(i) corresponds to a vector of lengths and turning angles for a successful parking task. The total number of examples in the training set is M . The procedure allows us to learn iteratively and adjust the prior belief by updating the values of the mean \u00b5 and covariance matrix \u03b2 of the prior, where v is a size of a training set for the prior belief, and \u03b1 = v \u2212 1.\n\u03b2 = v(\u03b1\u2212 n+ 1)\nv + 1 T\u22121, (7)\nThe updated mean value \u00b5\u2217 incorporates prior value of the mean \u00b5 and the mean value of the new training examples x.\nx =\n\u2211M i=1 x (i)\nM\n\u00b5\u2217 = v\u00b5+Mx\nv +M\n(8)\nThe size of the training set v\u2217 is updated to its new value:\nv\u2217 = v +M (9)\nThe updated covariance matrix \u03b2\u2217 combines the prior matrix \u03b2 with the covariance matrix of the training set s:\ns = M\u2211 i=1 ( x(i) \u2212 x )( x(i) \u2212 x )T \u03b2\u2217 =\u03b2 + s+ rm\nv +M\n( x(i) \u2212 x )( x(i) \u2212 x )T (10)\nFinally, the new value of the matrix \u03b2 is used to calculate the covariance matrix (T\u2217)\u22121, where \u03b1\u2217 = \u03b1+M .\n(T\u2217) \u22121 = v\u2217 + 1\nv\u2217(\u03b1\u2217 \u2212 n+ 1)\u03b2 \u2217 (11)\n3. Extraction step. The new parameters of the GBN can now be retrieved from the updated mean vector \u00b5\u2217 and from (T\u2217)\u22121. If new traces are available at hand, one can update the distributions by recomputing \u00b5\u2217 and (T\u2217)\u22121 using Equations 8-11. We depict the whole process in Figure 6: Unknown parameters from the program skeleton are learned from successful traces and these dependencies are used during the execution phase to sample the commands."}, {"heading": "5. EXPERIMENTAL RESULTS", "text": "We performed our experiments on a Pioneer P3AT-SH mobile rover from Adept MobileRobots [1] (see Figure 7). The rover uses the Carma Devkit from SECO [21] as a main computational unit. The comprised Tegra 3 ARM CPU runs the Robot Operating System (ROS) on top of Ubuntu 12.04."}, {"heading": "5.1 Structure of the Parking System", "text": "The parking system can be separated into several building blocks (see Figure 8). The block Rover Interface senses and controls the rover, that is, it establishes an interface to the hardware. The block Sensor Fusion takes the sensor values from the Rover Interface block, and provides the estimated pose of the rover to the high-level controller Engine. The Engine uses the GBN block to update the motion commands\nT7 =  1 \u03c321 + b221 \u03c322\n\u2212 b21 \u03c322\n0 0 0 0 0\n\u2212 b21 \u03c322\n1 \u03c322 + b232 \u03c323\n\u2212 b32 \u03c323\n0 0 0 0\n0 \u2212 b32 \u03c323\n1 \u03c323 + b243 \u03c324\n\u2212 b43 \u03c324\n0 0 0\n0 0 \u2212 b43 \u03c324\n1 \u03c324 + b254 \u03c325\n\u2212 b54 \u03c325\n0 0\n0 0 0 \u2212 b54 \u03c325\n1 \u03c325 + b265 \u03c326\n\u2212 b65 \u03c326\n0\n0 0 0 0 \u2212 b65 \u03c326\n1 \u03c326 + b276 \u03c327 \u2212 b76 \u03c327\n0 0 0 0 0 \u2212 b76 \u03c327\n1 \u03c327\n (12)\nbased on the estimated pose. Furthermore, the Engine maps the (higher level) motion commands to velocity commands needed by the Rover Interface to control the rover.\n5.1.1 The Gaussian Bayesian Network Block The goal of the GBN block in Figure 8, is to generate motion commands for the Engine to execute. A motion command corresponds to a driving distance or a turning angle.\nDuring the learning phase, the distributions of the random variables (RVs) in the Gaussian Bayesian network (GBN) in Figure 4 are collected in a CSV file of following format:\nmotionType , motionDirect ion ,mean , var iance , dependenceCoe f f i c i en t\nParsing the CSV file initializes the GBN that will be used\nfor sampling the motion commands. Before starting the run we obtain the initial command vector from the distributions learned. The distribution of the first move l1 is independent from any other move and has the form N (\u00b51, \u03c321). Starting from the second move \u03b11, each motion depends on the previous one: For motion number n, the distribution has the form N (\u00b5n\u2212 bn,n\u22121 \u2217 xsampledn\u22121 , \u03c32n). The initial command vector is obtained by sampling from l1, and each subsequent command vector is obtained by taking into account the previous sample, when sampling from its own distribution.\nAs the rover and its environment are uncertain (e.g., sensors are disturbed by noise) we use the pose provided by the sensor fusion unit to update the motion commands. Hence the motion commands are constantly adapted to take into account the actual driven distance (which could be different from the planned one due to the aforementioned uncertainty of the CPS). This allows us to incorporate the results of the sensor fusion algorithm in the updated commands.\n5.1.2 The Engine Block During the run we execute a motion command according to the semantics of the nwhile loop. In particular, the estimated pose is passed from the Sensor Fusion block to the Engine and compared with the target location, specified as a point on a 2-D plane. Since the rover is affected by noise its path can deviate and never come to the target location. To be able to detect and overcome this problem we estimate the scalar product of two vectors: The first one is the initial target location, and the second one is the current target location. This product is monotonely decreasing and becomes negative after passing the goal even on a deviating path. In an nwhile statement we monitor the distance (or angle) and detect if we should process the next command.\nTo obtain the current state of the rover (its pose), and send velocity commands, we start two separate threads: (i) Receive the pose and (ii) Send the velocity command. The motion command (containing desired driving distance or turning angle) is converted to a suitable velocity or steering command respectively, for the Rover Interface. After each executed command, we resample the pose in order to take into account actual driving distance in subsequent moves.\n5.1.3 The Rover Interface Block The block Rover Interface implements the drivers for sensors and actuators. The wheel velocities are measured by encoders, already supplied within the Pioneer rover. A built-in\nmicrocontroller reads the encoders and sends their value to the Carma Devkit. Additionally the rover is equipped with an inertial measurement unit (IMU) including an accelerometer, measuring the linear acceleration, and a gyroscope, measuring the angular velocity of the rover. The Raspberry Pi mounted on top of the rover samples the accelerometer and gyroscope, and forwards the raw IMU measurements to the Carma Devkit. The rover is controlled according to the incoming velocity commands containing desired linear velocity into forward direction (x-translation) and the desired angular velocity (z-rotation). The desired translation and rotation is converted to the individual wheel velocities, which are sent to and applied by the built-in microcontroller.\n5.1.4 The Sensor Fusion Block Parking is often performed by applying predefined rules [22] or following a specific trajectory [22]. So typically an autonomously parking car stops at a specific position beside a parking space and then turns and moves for a fixed time, angle or distance. The car has to stop, move and turn exactly as designated to park successfully. The car has to be aware of its current pose, that is, position and heading, otherwise parking will most likely fail (whatsoever controller is used). However, the current pose is observed by sensors, which suffer from uncertainty. Measurements are distorted by noise, e.g., caused by fluctuations of the elements of the electrical circuit of the sensors. The environment may be unpredictable, e.g., the car may slip over water or ice when parking. To overcome such problems sensor fusion techniques are applied, i.e., several sensors are combined to estimate a more accurate state. A common method is state estimation (also called filtering) [23,30].\nIn this application, an unscented Kalman filter (UKF) [31] is used. This filter combines the measurements listed in Table 1 with a suitable model describing the relations from the measured variables to the pose of the car.\nThe belief state maintained by the UKF, e.g., the current linear velocity, will be continuously updated: (i) By predicting the state, and (ii) By updating the prediction with measurements. For example, the linear velocity will be predicted by the current belief of acceleration and the time elapsed since the previous estimation. Next, the measurements from accelerometer and wheel encoders are used to update the predicted velocity. Because the wheel encoders are much more accurate than the acceleration sensor (see variance in Table 1), the measurements from the wheel encoders will be trusted more (for simplicity one can think of weighting and averaging the measurements, where the particular weight corresponds to the reciprocal variance of the sensor). However, by using more than one sensor, the unscented Kalman filter reduces the error of estimated and actual velocity."}, {"heading": "5.2 Integration into ROS", "text": "ROS [26] is a meta-operating system that provides common functionality for robotic tasks including process communication, package management, and hardware abstraction. A basic building block of a system in ROS is a so-called node, that performs computation and exchanges information with other entities. Nodes communicate with each other subscribing for or publishing messages to specific topics. So all the nodes subscribed to a particular topic A, will receive messages from nodes publishing to this topic A.\nSince the application is implemented in ROS we use the utility roslaunch to start the required ROS nodes (as shown in Figure 9) corresponding to the blocks given in Section 5.1.\nRover Interface: The node RosAria is used to control the velocity of the rover and provide the values of the wheel encoders for the sensor fusion node. The ROS nodes imu3000 and kxtf9 running on the Raspberry Pi provide data from acceleromenter and gyroscope.\nSensor Fusion: sf_filter node reads sensor values, implements the sensor fusion algorithm and provides the estimated pose of the rover.\nGBN and Engine: pioneer_driver is a node implementing resampling of commands based on the actual driven distance and constantly providing the required velocity commands to the RosAria node (see Figure 9)."}, {"heading": "5.3 Results", "text": "After the learning phase, we obtain the parameters of the GBN that we use in the program skeleton (Table. 2). Since we track the position using the data from the sensor fusion and each movement has the experimentally learned uncertainty, we are resistive to the perturbation of the actual driving distances and angles. If in the current distance of the robot deviates from the planned one, the commands, resampled from the GBN will try compensate the deviation with the dependencies obtained from the learning phase."}, {"heading": "6. RELATED WORK", "text": "Although probabilistic programs (PP), Gaussian Bayesian networks (GBN) and neural networks were considered before, to the best of our knowledge, the development of smooth control statements, related within a GBN ontology is new. The ontology represents the knowledge of the PP about both its environment and its own control logic.\nProbabilistic programs are represented by different languages and frameworks [9, 13, 14]. The authors in [14] differentiate probabilistic programs from \u201ctraditional\u201d ones, by the ability to sample at random from the distribution and condition the values of variables via observation. Although they consider both discrete and continuous probability distributions, and transformation of Bayesian Networks and Discrete Time Markov Chains to probabilistic programs, they do not mention probabilistic control structures linked in GBN.\nIn [6], the authors adapted the signal and image processing technique called Gaussian smoothing (GS), for program optimization. Using GS, a program could be approximated by a smooth mathematical function, which is in fact a convolution of a denotational semantics of a program with a Gaussian function. This approximation is used to facilitate optimization for solving the parameter synthesis problem. In [7] this idea was developed further and soundness and robustness for smooth interpretation of programs was defined. In both papers the authors do not consider any means for eliminating the re-normalization step of the probability density function when a variable is passed through a conditional branch in the current execution trace. Moreover, they stop short of proposing new, smooth control statements.\nLearning Bayesian Networks comprises different tasks and problem formulations: i) Learning the structure of the network, ii) Learning the conditional probabilities for the given structure and iii) Performing querying-inference for a given Bayesian Network [24]. In [16] the authors introduce a unified method for both discrete and continuous domains to learn the parameters of Bayesian Network, using a combination of prior knowledge and statistical data.\nVarious formulations of a mobile parking problem were extensively studied for robots with different architectures [17\u2013 19, 22, 29]. For instance, in [22] the authors use a custom spatial configuration of the ultrasonic sensors and binaural method to perceive the environment and park the robot using predefined rules. In [19] the authors approximate the trajectory for the parking task with a polynomial curve, that the robot could follow with the constraints satisfied, and used fuzzy controller to minimize the difference between specified trajectory and actual path.\nIn order to govern a physical process (e.g., parking a car), the controller must be aware of the internal state of the process (e.g., the position of the car). Sensors measure the outputs of a process, whereof the state can be estimated. However, the measurements are distorted by noise and the environment may be unpredictable. State estimators [3, 23, 30] and in particular Kalman filters [30, 31] are commonly used methods to increase the confidence of the state estimate evaluated out of raw sensor measurements."}, {"heading": "7. CONCLUSION", "text": "In this paper we introduced deep neural programs (DNP), a new formalism for writing robust and adaptive cyberphysical-system (CPS) controllers. Key to this formalism is: (i) The use of smooth Probit distributions in conditional and loop statements, instead of their classic stepwise counterparts, and (2) The use of a Gaussian Bayesian network, for capturing the dependencies among the Probit distributions within the conditional and loop statements in the DPN.\nWe validated the usefulness of DPNs by developing, once and for all, a parallel parking CPS-controller, which is able to adapt to unforeseen environmental situations, such as a slippery ground, or noisy actuators. No classic program has such ability: One would have to encode all this unforeseen situations, which would lead to an unintelligible code.\nIn future work, we plan to explore the advantages of DPNs in the analysis, as well as, in the design (optimization) of CPS controllers. The nice mathematical properties of DPNs make them an ideal formalism for these tasks."}, {"heading": "8. REFERENCES", "text": "[1] Adept MobileRobots(2013). Pioneer 3-AT.\nhttp://www.mobilerobots.com/ResearchRobots/ P3AT.aspx (Accessed 24.08.2014).\n[2] Parking Videos. http://youtu.be/xNOj ARSEYs?list=PLP5Gx6r7gK2cxjKv0K2V5fBedovfo8 3y (Accessed 12.10.2014).\n[3] M. Arulampalam, S. Maskell, N. Gordon, and T. Clapp. A Tutorial on Particle Filters for Online Nonlinear/Non-Gaussian Bayesian Tracking. IEEE Transactions on Signal Processing, 50(2):174\u2013188, 2002.\n[4] M. Broy and E. Geisberger. Cyber-physical systems, driving force for innovation in mobility, health, energy and production. Acatech: The National Academy Of Science and Engineering, 2012.\n[5] S. Chaudhuri and A. Solar-Lezama. Smooth Interpretation: Presentation Slides. http://people.csail.mit.edu/asolar/Talks/ PLDI2010Final.pptx (Accessed 14.06.2014).\n[6] S. Chaudhuri and A. Solar-Lezama. Smooth interpretation. In PLDI, pages 279\u2013291, 2010.\n[7] S. Chaudhuri and A. Solar-Lezama. Smoothing a program soundly and robustly. In CAV, pages 277\u2013292, 2011.\n[8] D. Ciresan, U. Meier, and J. Schmidhuber. Multi-column deep neural networks for image classification. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 3642\u20133649, June 2012.\n[9] A. Dekhtyar and V. Subrahmanian. Hybrid Probabilistic Programs . The Journal of Logic Programming, 43(3):187 \u2013 250, 2000.\n[10] D. Erhan, Y. Bengio, A. Courville, P.-A. Manzagol, P. Vincent, and S. Bengio. Why does unsupervised pre-training help deep learning? J. Mach. Learn. Res., 11:625\u2013660, Mar. 2010.\n[11] M. Fraenzle. Analysis of hybrid systems: An ounce of realism can save an infinity of states. In Computer\nScience Logic, volume 1683 of Lecture Notes in Computer Science, pages 126\u2013139. Springer Berlin Heidelberg, 1999.\n[12] S. Gao, S. Kong, W. Chen, and E. M. Clarke. Delta-complete analysis for bounded reachability of hybrid systems. CoRR, abs/1404.7171, 2014.\n[13] W. R. Gilks, A. Thomas, and D. J. Spiegelhalter. A Language and Program for Complex Bayesian Modelling. Journal of the Royal Statistical Society. Series D (The Statistician), 43(1):pp. 169\u2013177, 1994.\n[14] A. D. Gordon, T. A. Henzinger, A. V. Nori, and S. K. Rajamani. Probabilistic Programming. In International Conference on Software Engineering (ICSE Future of Software Engineering). IEEE, May 2014.\n[15] G. Grimmett and D. Stirzaker. Probability and random processes. Oxford science publications. Clarendon Press, 1985.\n[16] D. Heckerman and D. Geiger. Learning bayesian networks: A unification for discrete and gaussian domains. In UAI, pages 274\u2013284, 1995.\n[17] M.-A. Ibarra-Manzano, J.-H. De-Anda-Cuellar, C.-A. Perez-Ramirez, O.-I. Vera-Almanza, F.-J. Mendoza-Galindo, M.-A. Carbajal-Guillen, and D.-L. Almanza-Ojeda. Intelligent algorithm for parallel self-parking assist of a mobile robot. In Electronics, Robotics and Automotive Mechanics Conference (CERMA), 2012 IEEE Ninth, pages 37\u201341, Nov 2012.\n[18] K. Jiang and L. Seneviratne. A sensor guided autonomous parking system for nonholonomic mobile robots. In Robotics and Automation, 1999. Proceedings. 1999 IEEE International Conference on, volume 1, pages 311\u2013316 vol.1, 1999.\n[19] M. Khoshnejad and K. Demirli. Autonomous parallel parking of a car-like mobile robot by a neuro-fuzzy behavior-based controller. In Fuzzy Information Processing Society, 2005. NAFIPS 2005. Annual Meeting of the North American, pages 814\u2013819, June 2005.\n[20] D. Koller and N. Friedman. Probabilistic Graphical Models: Principles and Techniques - Adaptive Computation and Machine Learning. The MIT Press, 2009.\n[21] M. A. Lee. CUDA on ARM: Tegra3 Based Low-Power GPU Compute Node, 2013. Poster presented at GPU Technical Conference, 2013.\n[22] T. Li, Y.-C. Yeh, J.-D. Wu, M.-Y. Hsiao, and C.-Y. Chen. Multifunctional Intelligent Autonomous Parking Controllers for Carlike Mobile Robots. Industrial Electronics, IEEE Transactions on, 57(5):1687\u20131700, May 2010.\n[23] H. Mitchell. Multi-Sensor Data Fusion - An Introduction. Springer, Berlin, Heidelberg, New York, 2007.\n[24] R. E. Neapolitan. Learning Bayesian Networks. Prentice-Hall, Inc., Upper Saddle River, NJ, USA, 2003.\n[25] D. L. Parnas. Software aspects of strategic defense systems. Commun. ACM, 28(12):1326\u20131335, Dec. 1985.\n[26] M. Quigley, K. Conley, B. Gerkey, J. Faust, T. B. Foote, J. Leibs, R. Wheeler, and A. Y. Ng. ROS: an\nopen-source robot operating system. In ICRA Workshop on Open Source Software, 2009.\n[27] S. Ratschan and Z. She. Constraints for continuous reachability in the verification of hybrid systems. In J. Calmet, T. Ida, and D. Wang, editors, Artificial Intelligence and Symbolic Computation, volume 4120 of Lecture Notes in Computer Science, pages 196\u2013210. Springer Berlin Heidelberg, 2006.\n[28] S. Russell and P. Norvig. Artificial Intelligence: A Modern Approach. Prentice-Hall, 3rd edition, 2010.\n[29] N. Scicluna, E. Gatt, O. Casha, I. Grech, and J. Micallef. Fpga-based autonomous parking of a car-like robot using fuzzy logic control. In Electronics, Circuits and Systems (ICECS), 2012 19th IEEE International Conference on, pages 229\u2013232, Dec 2012.\n[30] S. Thrun, W. Burgard, and D. Fox. Probabilistic Robotics. MIT Press, Cambridge, 2006.\n[31] E. Wan and R. Van der Merwe. The Unscented Kalman Filter for Nonlinear Estimation. In Adaptive Systems for Signal Processing, Communications, and Control Symposium 2000. AS-SPCC. The IEEE 2000, pages 153\u2013158, 2000.\n[32] Q. Wang, P. Zuliani, S. Kong, S. Gao, and E. M. Clarke. Sreach: Combining statistical tests and bounded model checking for nonlinear hybrid systems with parametric uncertainty. CoRR, abs/1404.7206, 2014."}], "references": [{"title": "A Tutorial on Particle Filters for Online Nonlinear/Non-Gaussian Bayesian Tracking", "author": ["M. Arulampalam", "S. Maskell", "N. Gordon", "T. Clapp"], "venue": "IEEE Transactions on Signal Processing, 50(2):174\u2013188", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Cyber-physical systems", "author": ["M. Broy", "E. Geisberger"], "venue": "driving force for innovation in mobility, health, energy and production. Acatech: The National Academy Of Science and Engineering", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Smooth Interpretation: Presentation Slides", "author": ["S. Chaudhuri", "A. Solar-Lezama"], "venue": "http://people.csail.mit.edu/asolar/Talks/ PLDI2010Final.pptx ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Smooth interpretation", "author": ["S. Chaudhuri", "A. Solar-Lezama"], "venue": "PLDI, pages 279\u2013291", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Smoothing a program soundly and robustly", "author": ["S. Chaudhuri", "A. Solar-Lezama"], "venue": "CAV, pages 277\u2013292", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Multi-column deep neural networks for image classification", "author": ["D. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Hybrid Probabilistic Programs", "author": ["A. Dekhtyar", "V. Subrahmanian"], "venue": "The Journal of Logic Programming, 43(3):187 \u2013 250", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2000}, {"title": "Why does unsupervised pre-training help deep learning", "author": ["D. Erhan", "Y. Bengio", "A. Courville", "P.-A. Manzagol", "P. Vincent", "S. Bengio"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Analysis of hybrid systems: An ounce of realism can save an infinity of states", "author": ["M. Fraenzle"], "venue": "Computer  Science Logic, volume 1683 of Lecture Notes in Computer Science, pages 126\u2013139. Springer Berlin Heidelberg", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}, {"title": "Delta-complete analysis for bounded reachability of hybrid systems", "author": ["S. Gao", "S. Kong", "W. Chen", "E.M. Clarke"], "venue": "CoRR, abs/1404.7171", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "A Language and Program for Complex Bayesian Modelling", "author": ["W.R. Gilks", "A. Thomas", "D.J. Spiegelhalter"], "venue": "Journal of the Royal Statistical Society. Series D (The Statistician), 43(1):pp. 169\u2013177", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1994}, {"title": "Probabilistic Programming", "author": ["A.D. Gordon", "T.A. Henzinger", "A.V. Nori", "S.K. Rajamani"], "venue": "In International Conference on Software Engineering (ICSE Future of Software Engineering)", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Probability and random processes", "author": ["G. Grimmett", "D. Stirzaker"], "venue": "Oxford science publications. Clarendon Press", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1985}, {"title": "Learning bayesian networks: A unification for discrete and gaussian domains", "author": ["D. Heckerman", "D. Geiger"], "venue": "UAI, pages 274\u2013284", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1995}, {"title": "Intelligent algorithm for parallel self-parking assist of a mobile robot", "author": ["M.-A. Ibarra-Manzano", "J.-H. De-Anda-Cuellar", "C.-A. Perez-Ramirez", "O.-I. Vera-Almanza", "F.-J. Mendoza-Galindo", "M.-A. Carbajal-Guillen", "D.-L. Almanza-Ojeda"], "venue": "In Electronics, Robotics and Automotive Mechanics Conference (CERMA),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "A sensor guided autonomous parking system for nonholonomic mobile robots", "author": ["K. Jiang", "L. Seneviratne"], "venue": "Robotics and Automation, 1999. Proceedings. 1999 IEEE International Conference on, volume 1, pages 311\u2013316 vol.1", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "Autonomous parallel parking of a car-like mobile robot by a neuro-fuzzy behavior-based controller", "author": ["M. Khoshnejad", "K. Demirli"], "venue": "Fuzzy Information Processing Society", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2005}, {"title": "Probabilistic Graphical Models: Principles and Techniques - Adaptive Computation and Machine Learning", "author": ["D. Koller", "N. Friedman"], "venue": "The MIT Press", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "CUDA on ARM: Tegra3 Based Low-Power GPU Compute Node", "author": ["M.A. Lee"], "venue": "2013. Poster presented at GPU Technical Conference", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Multifunctional Intelligent Autonomous Parking Controllers for Carlike Mobile Robots", "author": ["T. Li", "Y.-C. Yeh", "J.-D. Wu", "M.-Y. Hsiao", "C.-Y. Chen"], "venue": "Industrial Electronics, IEEE Transactions on,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Multi-Sensor Data Fusion - An Introduction", "author": ["H. Mitchell"], "venue": "Springer, Berlin, Heidelberg, New York", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning Bayesian Networks", "author": ["R.E. Neapolitan"], "venue": "Prentice-Hall, Inc., Upper Saddle River, NJ, USA", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "Software aspects of strategic defense systems", "author": ["D.L. Parnas"], "venue": "Commun. ACM,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1985}, {"title": "ROS: an  open-source robot operating system", "author": ["M. Quigley", "K. Conley", "B. Gerkey", "J. Faust", "T.B. Foote", "J. Leibs", "R. Wheeler", "A.Y. Ng"], "venue": "ICRA Workshop on Open Source Software", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Constraints for continuous reachability in the verification of hybrid systems", "author": ["S. Ratschan", "Z. She"], "venue": "J. Calmet, T. Ida, and D. Wang, editors, Artificial Intelligence and Symbolic Computation, volume 4120 of Lecture Notes in Computer Science, pages 196\u2013210. Springer Berlin Heidelberg", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2006}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["S. Russell", "P. Norvig"], "venue": "Prentice-Hall, 3rd edition", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Fpga-based autonomous parking of a car-like robot using fuzzy logic control", "author": ["N. Scicluna", "E. Gatt", "O. Casha", "I. Grech", "J. Micallef"], "venue": "In Electronics, Circuits and Systems (ICECS),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Probabilistic Robotics", "author": ["S. Thrun", "W. Burgard", "D. Fox"], "venue": "MIT Press, Cambridge", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2006}, {"title": "The Unscented Kalman Filter for Nonlinear Estimation", "author": ["E. Wan", "R. Van der Merwe"], "venue": "In Adaptive Systems for Signal Processing, Communications, and Control Symposium", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2000}, {"title": "Sreach: Combining statistical tests and bounded model checking for nonlinear hybrid systems with parametric uncertainty", "author": ["Q. Wang", "P. Zuliani", "S. Kong", "S. Gao", "E.M. Clarke"], "venue": "CoRR, abs/1404.7206", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 1, "context": "Examples of CPS include smart grids, smart factories, smart transportation, and smart health-care [4].", "startOffset": 98, "endOffset": 101}, {"referenceID": 3, "context": "Going back to Parnas, Chaudhuri and Lezama identified in a series of intriguing papers [6,7,25], the if-thenelse construct as the main culprit for program frailness.", "startOffset": 87, "endOffset": 95}, {"referenceID": 4, "context": "Going back to Parnas, Chaudhuri and Lezama identified in a series of intriguing papers [6,7,25], the if-thenelse construct as the main culprit for program frailness.", "startOffset": 87, "endOffset": 95}, {"referenceID": 22, "context": "Going back to Parnas, Chaudhuri and Lezama identified in a series of intriguing papers [6,7,25], the if-thenelse construct as the main culprit for program frailness.", "startOffset": 87, "endOffset": 95}, {"referenceID": 8, "context": "For this reason, a series of papers, of Fraenzle, Ratschan, Wang, Gao and Clarke [11, 12, 27, 32], proposed the use of an indifference region \u03b4 (see Figure 1), and rewrite the predicates in the form f(x)\u2212a> \u03b4.", "startOffset": 81, "endOffset": 97}, {"referenceID": 9, "context": "For this reason, a series of papers, of Fraenzle, Ratschan, Wang, Gao and Clarke [11, 12, 27, 32], proposed the use of an indifference region \u03b4 (see Figure 1), and rewrite the predicates in the form f(x)\u2212a> \u03b4.", "startOffset": 81, "endOffset": 97}, {"referenceID": 24, "context": "For this reason, a series of papers, of Fraenzle, Ratschan, Wang, Gao and Clarke [11, 12, 27, 32], proposed the use of an indifference region \u03b4 (see Figure 1), and rewrite the predicates in the form f(x)\u2212a> \u03b4.", "startOffset": 81, "endOffset": 97}, {"referenceID": 29, "context": "For this reason, a series of papers, of Fraenzle, Ratschan, Wang, Gao and Clarke [11, 12, 27, 32], proposed the use of an indifference region \u03b4 (see Figure 1), and rewrite the predicates in the form f(x)\u2212a> \u03b4.", "startOffset": 81, "endOffset": 97}, {"referenceID": 3, "context": "In order to alleviate this problem, Chaudhuri and Lezama [6] proposed to smoothen the steps, by passing a Gaussian input distribution through the CPS.", "startOffset": 57, "endOffset": 60}, {"referenceID": 5, "context": "Such networks, and in particular deep neural networks, have recently achieved amazing performance, for example in the recognition of sophisticated patterns [8, 10].", "startOffset": 156, "endOffset": 163}, {"referenceID": 7, "context": "Such networks, and in particular deep neural networks, have recently achieved amazing performance, for example in the recognition of sophisticated patterns [8, 10].", "startOffset": 156, "endOffset": 163}, {"referenceID": 2, "context": "In order to validate our new paradigm, we use the parking example from [5].", "startOffset": 71, "endOffset": 74}, {"referenceID": 25, "context": "This rule, consistent with logic, is the main mechanism for probabilistic inference [28].", "startOffset": 84, "endOffset": 88}, {"referenceID": 17, "context": "To avoid the complications induced by the use of the joint probability distribution (or density), each variable Xi is associated with a conditional probability distribution (CPD) that takes into account dependencies only between the variable and its direct parents [20, 28].", "startOffset": 265, "endOffset": 273}, {"referenceID": 25, "context": "To avoid the complications induced by the use of the joint probability distribution (or density), each variable Xi is associated with a conditional probability distribution (CPD) that takes into account dependencies only between the variable and its direct parents [20, 28].", "startOffset": 265, "endOffset": 273}, {"referenceID": 12, "context": "To express these dependencies we use a multivariate Gaussian Distribution (MGD) [15], which generalizes the Gaussian distribution to multiple dimensions.", "startOffset": 80, "endOffset": 84}, {"referenceID": 21, "context": "The probability density then can be written as follows [24]:", "startOffset": 55, "endOffset": 59}, {"referenceID": 21, "context": "We than use the fact that any GBN can be converted to an MGD [24] in our learning routine.", "startOffset": 61, "endOffset": 65}, {"referenceID": 13, "context": "use the recursive notation in [16], where the value of the coefficients bi, will be learned in the update step below.", "startOffset": 30, "endOffset": 34}, {"referenceID": 21, "context": "Once we derived the symbolic form of the precision matrix (T7 in our example), we use the training set, in order to learn the actual values of its parameters, as described in the algorithm from [24].", "startOffset": 194, "endOffset": 198}, {"referenceID": 18, "context": "The rover uses the Carma Devkit from SECO [21] as a main computational unit.", "startOffset": 42, "endOffset": 46}, {"referenceID": 19, "context": "4 The Sensor Fusion Block Parking is often performed by applying predefined rules [22] or following a specific trajectory [22].", "startOffset": 82, "endOffset": 86}, {"referenceID": 19, "context": "4 The Sensor Fusion Block Parking is often performed by applying predefined rules [22] or following a specific trajectory [22].", "startOffset": 122, "endOffset": 126}, {"referenceID": 20, "context": "A common method is state estimation (also called filtering) [23,30].", "startOffset": 60, "endOffset": 67}, {"referenceID": 27, "context": "A common method is state estimation (also called filtering) [23,30].", "startOffset": 60, "endOffset": 67}, {"referenceID": 28, "context": "In this application, an unscented Kalman filter (UKF) [31] is used.", "startOffset": 54, "endOffset": 58}, {"referenceID": 23, "context": "2 Integration into ROS ROS [26] is a meta-operating system that provides common functionality for robotic tasks including process communication, package management, and hardware abstraction.", "startOffset": 27, "endOffset": 31}, {"referenceID": 6, "context": "Probabilistic programs are represented by different languages and frameworks [9, 13, 14].", "startOffset": 77, "endOffset": 88}, {"referenceID": 10, "context": "Probabilistic programs are represented by different languages and frameworks [9, 13, 14].", "startOffset": 77, "endOffset": 88}, {"referenceID": 11, "context": "Probabilistic programs are represented by different languages and frameworks [9, 13, 14].", "startOffset": 77, "endOffset": 88}, {"referenceID": 11, "context": "The authors in [14] differentiate probabilistic programs from \u201ctraditional\u201d ones, by the ability to sample at random from the distribution and condition the values of variables via observation.", "startOffset": 15, "endOffset": 19}, {"referenceID": 3, "context": "In [6], the authors adapted the signal and image processing technique called Gaussian smoothing (GS), for program optimization.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "In [7] this idea was developed further and soundness and robustness for smooth interpretation of programs was defined.", "startOffset": 3, "endOffset": 6}, {"referenceID": 21, "context": "Learning Bayesian Networks comprises different tasks and problem formulations: i) Learning the structure of the network, ii) Learning the conditional probabilities for the given structure and iii) Performing querying-inference for a given Bayesian Network [24].", "startOffset": 256, "endOffset": 260}, {"referenceID": 13, "context": "In [16] the authors introduce a unified method for both discrete and continuous domains to learn the parameters of Bayesian Network, using a combination of prior knowledge and statistical data.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "Various formulations of a mobile parking problem were extensively studied for robots with different architectures [17\u2013 19, 22, 29].", "startOffset": 114, "endOffset": 130}, {"referenceID": 19, "context": "Various formulations of a mobile parking problem were extensively studied for robots with different architectures [17\u2013 19, 22, 29].", "startOffset": 114, "endOffset": 130}, {"referenceID": 26, "context": "Various formulations of a mobile parking problem were extensively studied for robots with different architectures [17\u2013 19, 22, 29].", "startOffset": 114, "endOffset": 130}, {"referenceID": 19, "context": "For instance, in [22] the authors use a custom spatial configuration of the ultrasonic sensors and binaural method to perceive the environment and park the robot using predefined rules.", "startOffset": 17, "endOffset": 21}, {"referenceID": 16, "context": "In [19] the authors approximate the trajectory for the parking task with a polynomial curve, that the robot could follow with the constraints satisfied, and used fuzzy controller to minimize the difference between specified trajectory and actual path.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "State estimators [3, 23, 30] and in particular Kalman filters [30, 31] are commonly used methods to increase the confidence of the state estimate evaluated out of raw sensor measurements.", "startOffset": 17, "endOffset": 28}, {"referenceID": 20, "context": "State estimators [3, 23, 30] and in particular Kalman filters [30, 31] are commonly used methods to increase the confidence of the state estimate evaluated out of raw sensor measurements.", "startOffset": 17, "endOffset": 28}, {"referenceID": 27, "context": "State estimators [3, 23, 30] and in particular Kalman filters [30, 31] are commonly used methods to increase the confidence of the state estimate evaluated out of raw sensor measurements.", "startOffset": 17, "endOffset": 28}, {"referenceID": 27, "context": "State estimators [3, 23, 30] and in particular Kalman filters [30, 31] are commonly used methods to increase the confidence of the state estimate evaluated out of raw sensor measurements.", "startOffset": 62, "endOffset": 70}, {"referenceID": 28, "context": "State estimators [3, 23, 30] and in particular Kalman filters [30, 31] are commonly used methods to increase the confidence of the state estimate evaluated out of raw sensor measurements.", "startOffset": 62, "endOffset": 70}], "year": 2015, "abstractText": "We introduce Deep Neural Programs (DNP), a novel programming paradigm for writing adaptive controllers for cyber-physical systems (CPS). DNP replace if and while statements, whose discontinuity is responsible for undecidability in CPS analysis, intractability in CPS design, and frailness in CPS implementation, with their smooth, neural nif and nwhile counterparts. This not only makes CPS analysis decidable and CPS design tractable, but also allows to write robust and adaptive CPS code. In DNP the connection between the sigmoidal guards of the nif and nwhile statements has to be given as a Gaussian Bayesian network, which reflects the partial knowledge, the CPS program has about its environment. To the best of our knowledge, DNP are the first approach linking neural networks to programs, in a way that makes explicit the meaning of the network. In order to prove and validate the usefulness of DNP, we use them to write and learn an adaptive CPS controller for the parallel parking of the Pioneer rovers available in our CPS lab.", "creator": "LaTeX with hyperref package"}}}