{"id": "1502.04042", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Feb-2015", "title": "Abstract Learning via Demodulation in a Deep Neural Network", "abstract": "beloeil Inspired by bioterror the non-obvious brain, zubrin deep assel neural shabbat networks (DNN) are hankin thought chuska to cutaia learn haledon abstract representations influenza-like through their petumenos hierarchical architecture. However, at present, how bronzeville this wharington happens haeju is not well understood. inconspicua Here, titoist we demonstrate tnsm that hankerson DNN uomini learn abstract 97.72 representations by a yata process korolenko of demodulation. dapper We metro-north introduce a biased festhalle sigmoid activation pre-conquest function kobold and use blackhearts it to butlerian show that DNN latched learn childeric and liberale perform better athulathmudali when optimized bullseye for layin demodulation. Our findings constitute the investigate first limonene unambiguous galuh evidence that DNN perform pinega abstract latins learning cityliner in pirgs practical use. Our grapico findings may khaan also explain abstract kick-start learning cross-country in conks the venetians human luceno brain.", "histories": [["v1", "Fri, 13 Feb 2015 16:09:41 GMT  (90kb)", "http://arxiv.org/abs/1502.04042v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["andrew j r simpson"], "accepted": false, "id": "1502.04042"}, "pdf": {"name": "1502.04042.pdf", "metadata": {"source": "CRF", "title": "Abstract Learning via Demodulation in a Deep Neural Network", "authors": ["Andrew J.R. Simpson"], "emails": ["Andrew.Simpson@Surrey.ac.uk"], "sections": [{"heading": null, "text": "Abstract Learning via Demodulation in a Deep Neural Network\nAndrew J.R. Simpson #1\n# Centre for vision, speech and signal processing (CVSSP), University of Surrey,\nGuildford, Surrey, UK 1 Andrew.Simpson@Surrey.ac.uk\nAbstract\u2014Inspired by the brain, deep neural networks (DNN) are thought to learn abstract representations through their hierarchical architecture. However, at present, how this happens is not well understood. Here, we demonstrate that DNN learn abstract representations by a process of demodulation. We introduce a biased sigmoid activation function and use it to show that DNN learn and perform better when optimized for demodulation. Our findings constitute the first unambiguous evidence that DNN perform abstract learning in practical use. Our findings may also explain abstract learning in the human brain.\nIndex terms\u2014Deep learning, abstract representation, neural\nnetworks, demodulation.\nI. INTRODUCTION\nDeep neural networks (DNN) are state of the art for many machine learning problems [1], [2], [3], [4], [5], [6]. The architecture of deep neural networks is inspired by the hierarchical structure of the brain [7]. Deep neural networks feature a hierarchical, layer-wise arrangement of nonlinear activation functions (neurons) fed by inputs scaled by linear weights (synapses). Since the brain is adept at abstraction, it is anticipated that deep neural architecture might somehow capture abstract representations. However, it is not presently known how (or even if) abstract learning occurs in a DNN.\nOne possible way to engineer the process of abstraction is known as demodulation. Consider a 1 kHz sinusoidal carrier signal that is multiplied with a 10 Hz sinusoidal modulation signal. This shapes the envelope of the carrier signal into a representation of the modulation signal, and this allows the slower modulation signal to pass through a band-pass circuit that would not otherwise support the low frequency information. In this case, the abstract information (i.e., about the 1 kHz carrier) is that the carrier is modulated at 10 Hz. Recovery of the modulation signal is achieved via a nonlinear demodulation operation.\nIn this paper, we take a sampling theory perspective [8] and we interpret the nonlinear activation function of the DNN as a demodulation device within the context of the well-known MNIST [4] hand-written character classification problem (example image in Fig. 1).\nWe consider the archetypal sigmoid activation function [ = 1/(1 + exp(\u2212 ]. In order for the sigmoid to act as a demodulator, the input data must be asymmetrical. Taking the example of the sinusoidal carrier signal multiplied with the sinusoidal modulator, if the sinusoids are centred within the sigmoid there will be exactly zero demodulation because the demodulation energy exactly cancels out. However, if the sigmoid is biased, then the energy does not cancel out. Thus, only asymmetrical signals may be demodulated by this method.\nThe sigmoidal activation function comprises a zero-centred sigmoid which is mapped to the range [0, 1]. As a result, demodulation is not symmetrical. We added a bias term (\u03b2) to the sigmoid to illustrate this;\n= ( (1) We set x to be a discrete sampled signal comprising the pair\nof carrier/modulator multiplied sinusoids as described above, where the modulator frequency was \u03c9. Computing y for different values of \u03b2, we used the Fourier transform (of y) to compute a modulation energy power spectrum, H, with N bins. From this power spectrum we computed a ratio of the power of the demodulated signal to the average power in the FFT as follows;\n= ( \u2211\n(2)\nWhere g is the overall measure of demodulation utility and where \u03c9 is the modulation frequency in question. This ratio is unscaled. However, real networks have noise floors, so we include a subtractive logarithmic term to represent the loss in overall power capable of relating the overall modulation power to the \u2018overall noise floor\u2019 (meaning that an infinitely large ratio at an infinitely small energy is not useful). We extend Eq. 2 as follows;\n= ( \u2211\n\u2212 log10 ( $ \u2211 %& $ &' (\n) (3)\nwhere \u03b1 represents an arbitrary scalar on the subtractive term and \u03ba raises the order of the term (i.e., to account for more\ncomplex network related effects). We set \u03b1 to 1.8x10-13 and \u03ba was set to 12 in order to provide some punitive drop-off within the range in question.\nThis allows us to visualize the point at which the gains in ratio are overcome by the losses in overall gain. Fig. 2a plots the resulting functions of \u03b2 for Eq. 2 (grey line) and Eq. 3 (superposed blue line). At zero bias (\u03b2 = 0) there is no demodulation power. At negative bias (\u03b2 < 0) there is very little demodulation power but at positive bias the demodulation ratio is asymptotic by around \u03b2 = 6 and this is then pulled back by the overall gain term (Eq. 3). Hence, the optimal value of \u03b2 is around 6 (depending on the strength of the subtractive overall gain term).\nWe applied the same activation function (Eq. 1) to a typical feed-forward DNN, which we used to solve the well-known problem of hand-written character recognition on the MNIST dataset [4]. We evaluated both learning and overall performance of the network as a function of \u03b2. This allowed us to assess whether demodulation was a factor in DNN learning, and hence allowed us to assess the question of abstract learning in a quantitative way.\nII. METHOD\nWe chose the well-known computer vision problem of hand-written character classification using the MNIST dataset [3], [1], [4]. For the input layer we unpacked the images of 28x28 pixels into vectors of length 784. An example digit is given in Fig. 1. Pixel intensities were normalized to zero mean.\nUsing the biased sigmoid activation function, we built a fully connected network of size 784x784x10 units, with a 10- unit softmax output layer, corresponding to the 10-way digit classification problem. Separate instances of the model were independently trained at various values of \u03b2, using stochastic gradient descent (SGD). However, each individual instance of the model was trained from the exact same random seed. This means that the weights of the network were always initialized to the same (random) values and that the same (randomly chosen) paths were taken during SGD. Hence, changes in performance can be attributed to the different values of \u03b2.\nWe trained the various instances of the model on the 60,000 training examples from the MNIST dataset [4]. Each iteration of SGD consisted of a complete sweep of the entire training data set. The resulting models were tested on the 10,000 separate test examples at various (full-sweep) iteration points. Models were trained without dropout.\nIII. RESULTS\nFig. 2b plots classification error as a function of \u03b2, applied to classifying the separate test data (10,000 examples), after one iteration of training (SGD). The shape of the function matches well the demodulation (Eq. 3) function of Fig. 2a and the two functions are highly correlated (r = -0.74, P < 0.001, Spearman). The classification error function shows the same asymmetrical shape and minima around \u03b2 = 6. This demonstrates that demodulation, and hence abstraction, plays a role in the learning and performance of the model.\nFig. 2c plots classification error as a function of iteration number for \u03b2 = 0 (representing a traditional sigmoidal activation function) and \u03b2 = 6. The biased model (\u03b2 = 6) learns more rapidly and performs around 80% better. Both functions appear to have converged, so it would not appear that the difference in results can be attributed to different learning rates. Indeed, it appears that the difference in performance is sufficiently fundamental that extra training would not be able to account for the difference. These results confirm that demodulation, and hence abstraction, plays a key role in learning and performance.\nIV. DISCUSSION\nWe have set out some simple theory describing how DNN might perform abstract learning through demodulation. We have also introduced a biased sigmoidal activation function and we have characterized the demodulation of this function in both idealized and practical demonstrations. The optimum bias of the practical DNN example matched the theoretical optimum bias for demodulation and provided greatly improved performance in the model. These results provide the first unambiguous evidence that DNN learn abstract representations through demodulation.\nIn this context, the alternate nonlinear activation functions (abs, tanh, rectified linear unit - ReLU, etc [6]) may be understood as demodulators with different properties. It has been observed that models employing the ReLU function outperform sigmoid activated models [6] in ways that are similar to the results in Fig. 2c. However, it has also been observed that such models require far greater degrees of regularization (such as dropout [6]), which the biased sigmoid activation function does not appear to require. Assuming that demodulation performance is the reason for the improved performance in both cases, the difference in terms of need for regularization is likely due to the high order distortion generated by the abrupt nonlinearity (of the ReLU) and its increased potential for aliasing [8]. Thus, the low-order (smooth) nonlinearity of the biased sigmoid may prove to learn as fast as the ReLU but require less regularization. Future work might characterize the various activation functions in terms of their properties and trade-off of both demodulation performance versus distortion/aliasing, overfitting and regularization requirements.\nWe have noted that the unbiased sigmoid is, in the idealized case, incapable of performing abstraction by demodulation. Thus, it might be asked: how do these deep networks succeed at all with the unbiased sigmoid? The likely answer to this question is that real data are almost never symmetrical, and hence some small degree of bias would be sufficient to provide abstract learning (e.g., at the level shown in this paper). Indeed, the data employed here is decidedly asymmetrical (even after zero-mean normalization). Thus, it may be generally concluded that traditional sigmoid-activated networks are only capable of abstract learning when the data is asymmetrical. It is also evident that this class of demodulator is inherently sensitive to the polarity of the data, and it may be that some data is more informative in one direction than the other.\nMore generally, given that the DNN takes its inspiration from the brain, it is interesting to note that the bias scheme described here is not necessary in order for the equivalent\nbrain network to perform abstract learning because the sigmoid activated neurons of the brain are not signed or zeromean operated [7]. Hence, it would appear that the brain is ideally suited to perform abstract learning via demodulation.\nV. CONCLUSION\nIn this paper we have provided evidence that deep neural networks perform abstract learning through a process of demodulation that is sensitive to asymmetry in the data. We have introduced a biased sigmoid activation function that is capable of improved learning and performance. We have shown that the optimum bias point in a practical model matches well that of the idealized demodulation example and that the optimally biased model is fundamentally superior to the traditional sigmoid activated model. These results have broad implications for how deep neural networks are interpreted, designed and understood. Furthermore, our findings may provide insight into the exceptional abstract learning capabilities of the human brain.\nACKNOWLEDGMENT\nAJRS was supported by grant EP/L027119/1 from the UK Engineering and Physical Sciences Research Council (EPSRC).\nREFERENCES [1] Hinton G. E., Osindero S., Teh Y. (2006). \u201cA fast learning algorithm\nfor deep belief nets\u201d, Neural Computation 18: 1527\u20131554. [2] BengioY (2009) Learning deep architectures for AI, Foundations and\nTrends in Machine Learning 2:1\u2013127. [3] LeCun Y., Bottou L., Bengio Y., Haffner P. (1998) Gradient-based\nlearning applied to document recognition. Proc. IEEE 86: 2278\u20132324. [4] Ciresan, C. D., Meier U., Gambardella L. M., Schmidhuber J. (2010)\n\u201cDeep big simple neural nets excel on handwritten digit recognition\u201d, Neural Computation 22: 3207\u20133220. [5] Hinton G. E., Srivastava N., Krizhevsky A., Sutskever I., Salakhutdinov R. (2012) \u201cImproving neural networks by preventing co-adaptation of feature detectors,\u201d The Computing Research Repository (CoRR), abs/1207.0580. [6] Dahl G. E., Sainath T. N., Hinton G. E. (2013) \u201cImproving deep neural networks for LVCSR using rectified linear units and dropout\u201d, in Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), pp. 8609-8613. [7] Dayan P, Abbott LF (2001) Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems (MIT Press, Cambridge, Massachusetts, 2001). [8] Simpson AJR (2015) Over-Sampling in a Deep Neural Network, arxiv.org abs/1502.03648\n."}], "references": [{"title": "A fast learning algorithm for deep belief nets", "author": ["E. Hinton G", "S. Osindero", "Y. Teh"], "venue": "Neural Computation", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proc. IEEE", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1998}, {"title": "Deep big simple neural nets excel on handwritten digit recognition", "author": ["Ciresan C. D", "U. Meier", "M. Gambardella L", "J. Schmidhuber"], "venue": "Neural Computation", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors,", "author": ["E. Hinton G", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "The Computing Research Repository (CoRR),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Improving deep neural networks for LVCSR using rectified linear units and dropout", "author": ["E. Dahl G", "N. Sainath T", "E. Hinton G"], "venue": "in Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems", "author": ["P Dayan", "LF Abbott"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "Over-Sampling in a Deep Neural Network, arxiv.org abs/1502.03648", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Deep neural networks (DNN) are state of the art for many machine learning problems [1], [2], [3], [4], [5], [6].", "startOffset": 83, "endOffset": 86}, {"referenceID": 1, "context": "Deep neural networks (DNN) are state of the art for many machine learning problems [1], [2], [3], [4], [5], [6].", "startOffset": 93, "endOffset": 96}, {"referenceID": 2, "context": "Deep neural networks (DNN) are state of the art for many machine learning problems [1], [2], [3], [4], [5], [6].", "startOffset": 98, "endOffset": 101}, {"referenceID": 3, "context": "Deep neural networks (DNN) are state of the art for many machine learning problems [1], [2], [3], [4], [5], [6].", "startOffset": 103, "endOffset": 106}, {"referenceID": 4, "context": "Deep neural networks (DNN) are state of the art for many machine learning problems [1], [2], [3], [4], [5], [6].", "startOffset": 108, "endOffset": 111}, {"referenceID": 5, "context": "The architecture of deep neural networks is inspired by the hierarchical structure of the brain [7].", "startOffset": 96, "endOffset": 99}, {"referenceID": 6, "context": "In this paper, we take a sampling theory perspective [8] and we interpret the nonlinear activation function of the DNN as a demodulation device within the context of the well-known MNIST [4] hand-written character classification problem (example image in Fig.", "startOffset": 53, "endOffset": 56}, {"referenceID": 2, "context": "In this paper, we take a sampling theory perspective [8] and we interpret the nonlinear activation function of the DNN as a demodulation device within the context of the well-known MNIST [4] hand-written character classification problem (example image in Fig.", "startOffset": 187, "endOffset": 190}, {"referenceID": 0, "context": "The sigmoidal activation function comprises a zero-centred sigmoid which is mapped to the range [0, 1].", "startOffset": 96, "endOffset": 102}, {"referenceID": 2, "context": "1) to a typical feed-forward DNN, which we used to solve the well-known problem of hand-written character recognition on the MNIST dataset [4].", "startOffset": 139, "endOffset": 142}, {"referenceID": 1, "context": "We chose the well-known computer vision problem of hand-written character classification using the MNIST dataset [3], [1], [4].", "startOffset": 113, "endOffset": 116}, {"referenceID": 0, "context": "We chose the well-known computer vision problem of hand-written character classification using the MNIST dataset [3], [1], [4].", "startOffset": 118, "endOffset": 121}, {"referenceID": 2, "context": "We chose the well-known computer vision problem of hand-written character classification using the MNIST dataset [3], [1], [4].", "startOffset": 123, "endOffset": 126}, {"referenceID": 2, "context": "We trained the various instances of the model on the 60,000 training examples from the MNIST dataset [4].", "startOffset": 101, "endOffset": 104}, {"referenceID": 4, "context": "In this context, the alternate nonlinear activation functions (abs, tanh, rectified linear unit - ReLU, etc [6]) may be understood as demodulators with different properties.", "startOffset": 108, "endOffset": 111}, {"referenceID": 4, "context": "It has been observed that models employing the ReLU function outperform sigmoid activated models [6] in ways that are similar to the results in Fig.", "startOffset": 97, "endOffset": 100}, {"referenceID": 4, "context": "However, it has also been observed that such models require far greater degrees of regularization (such as dropout [6]), which the biased sigmoid activation function does not appear to require.", "startOffset": 115, "endOffset": 118}, {"referenceID": 6, "context": "Assuming that demodulation performance is the reason for the improved performance in both cases, the difference in terms of need for regularization is likely due to the high order distortion generated by the abrupt nonlinearity (of the ReLU) and its increased potential for aliasing [8].", "startOffset": 283, "endOffset": 286}, {"referenceID": 5, "context": "More generally, given that the DNN takes its inspiration from the brain, it is interesting to note that the bias scheme described here is not necessary in order for the equivalent brain network to perform abstract learning because the sigmoid activated neurons of the brain are not signed or zeromean operated [7].", "startOffset": 310, "endOffset": 313}], "year": 2015, "abstractText": "Learning via Demodulation in a Deep Neural Network Andrew J.R. Simpson #1 # Centre for vision, speech and signal processing (CVSSP), University of Surrey, Guildford, Surrey, UK 1 Andrew.Simpson@Surrey.ac.uk Abstract\u2014Inspired by the brain, deep neural networks (DNN) are thought to learn abstract representations through their hierarchical architecture. However, at present, how this happens is not well understood. Here, we demonstrate that DNN learn abstract representations by a process of demodulation. We introduce a biased sigmoid activation function and use it to show that DNN learn and perform better when optimized for demodulation. Our findings constitute the first unambiguous evidence that DNN perform abstract learning in practical use. Our findings may also explain abstract learning in the human brain.Inspired by the brain, deep neural networks (DNN) are thought to learn abstract representations through their hierarchical architecture. However, at present, how this happens is not well understood. Here, we demonstrate that DNN learn abstract representations by a process of demodulation. We introduce a biased sigmoid activation function and use it to show that DNN learn and perform better when optimized for demodulation. Our findings constitute the first unambiguous evidence that DNN perform abstract learning in practical use. Our findings may also explain abstract learning in the human brain.", "creator": "PDFCreator Version 1.7.1"}}}