{"id": "1502.05556", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Feb-2015", "title": "Just Sort It! A Simple and Effective Approach to Active Preference Learning", "abstract": "From goodsell sporting puncturing events bravada to escena sociological wobbled surveys, ranking maketh from pairwise comparisons grayness is a tool of walsin choice celexa for neuve many wakering applications. abels When celeketic certain dibelius pairs of herut items are farmworker difficult silicates to viswanath compare, outcomes can professionnel be noisy, ramsar and it is necessary to piatco develop robust strategies. sayyid In candar this yu\u00e8 work, 38.44 we show how gribble a simple koopmans active sampling background-color scheme that tesman uses mensajes a standard black pre-1950 box heinze sorting stickel algorithm enables the nepi efficient recovery kulesa of the akhtyrka ranking, achieving headquarters low bullet error with sparse xen samples. 109.68 Both in stone theory reamonn and keher practice, this active coton strategy performs rums systematically be4 better richet than tres selecting comparisons euphronios at random. As lietz a detour, archdioceses we show lean a ordains link gridded between brichambaut Rank 2xlp Centrality, myrrha a recently uscnote proposed algorithm 9.55 for rank 59.04 aggregation, -99 and the ML concei\u00e7\u00e3o estimator biazon for the bazalgette Bradley - u-1 Terry poked model. expeditionary This nkvd enables ddot us to develop a new, provably convergent iterative omd algorithm for computing brecheen the ancom ML optimism estimate.", "histories": [["v1", "Thu, 19 Feb 2015 12:50:13 GMT  (68kb,D)", "https://arxiv.org/abs/1502.05556v1", null], ["v2", "Thu, 15 Jun 2017 15:19:38 GMT  (293kb,D)", "http://arxiv.org/abs/1502.05556v2", "Accepted at ICML 2017"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["lucas maystre", "matthias grossglauser"], "accepted": true, "id": "1502.05556"}, "pdf": {"name": "1502.05556.pdf", "metadata": {"source": "CRF", "title": "Just Sort It! A Simple and Effective Approach to Active Preference Learning", "authors": ["Lucas Maystre", "Matthias Grossglauser"], "emails": ["lucas.maystre@epfl.ch", "matthias.grossglauser@epfl.ch"], "sections": [{"heading": "1 Introduction", "text": "The problem of recovering a ranking over n items from noisy outcomes of pairwise comparisons has attracted, in the last century, much research interest, driven by applications in sports [Elo, 1978], social sciences [Thurstone, 1927, Salganik and Levy, 2015] and\u2014more recently\u2014recommender systems [Houlsby et al., 2012]. Whereas pairwise comparison models and related inference algorithms have been extensively studied, the issue of which pairwise comparisons to sample, also known as active learning, has received significantly less attention. To understand the potential benefits of adaptively selecting samples, consider the case where comparison outcomes are noiseless, i.e., consistent with a linear order on a set of n items. If pairs of items are selected at random, it is necessary to collect \u2126(n2) comparisons to recover the ranking [Alon et al., 1994]. In contrast, by using an efficient sorting algorithm, O(n log n) adaptively chosen comparisons are sufficient. In this work, we demonstrate that sorting algorithms can also be helpful in the noisy setting, where some comparison outcomes are inconsistent with the ranking: despite errors, sorting algorithms tend to select informative samples. We focus on the Bradley\u2013Terry (BT) model, a widely-used probabilistic model of comparison outcomes. In this model, each item is\n\u2217School of Computer and Communication Sciences, EPFL, Switzerland.\nar X\niv :1\n50 2.\n05 55\n6v 2\n[ st\nat .M\nL ]\n1 5\nJu n\n20 17\nassociated with a parameter on the real line, and the probability of observing an incorrect outcome decreases as the distance between the items\u2019 parameters increases.\nFirst, we study the output of a single execution of Quicksort when comparison outcomes are generated from a BT model, under the assumption that the distance between adjacent parameters is (stochastically) uniform across the ranking. We measure the quality of a ranking estimate by its displacement with respect to the ground truth, i.e., the sum of rank differences. We show that Quicksort\u2019s output is a good approximation to the ground-truth ranking: no method comparing every pair of items at most once can do better (up to constant factors). Furthermore, we show that by aggregating O(log5 n) independent runs of Quicksort, it is possible to recover the exact rank for all but a vanishing fraction of the items. These theoretical results suggest that adaptive sampling is able to bring a substantial acceleration to the learning process.\nSecond, we propose a practical active-learning (AL) strategy that consists of repeatedly sorting the items. We evaluate our sorting-based method on three datasets and compare it to existing AL methods. We observe that all the strategies that we consider lead to better ranking estimates noticeably faster than random sampling. However, most strategies are challenging to operate and computationally expensive, thus hindering wider adoption [Schein and Ungar, 2007]. In this regard, sorting-based AL stands out, as a) it is computationally-speaking as inexpensive as random sampling, b) it is trivial to implement, and c) it requires no tuning of hyperparameters."}, {"heading": "1.1 Preliminaries and Notation", "text": "We consider n items that are represented by consecutive integers [n] = {1, . . . , n}. Without loss of generality, we assume that the items are ranked by increasing preference1, i.e., i < j means that j is (in expectation) preferred to i. When j is preferred to i as a result of a pairwise comparison, we denote the observation by i \u227a j. If i < j, we say that i \u227a j is a consistent outcome and j \u227a i an inconsistent (incorrect) outcome. In most of the paper, pairwise comparison outcomes follow a Bradley\u2013Terry model with parameters \u03b8 = [ \u03b81 \u00b7 \u00b7 \u00b7 \u03b8n ] \u2208 Rn, denoted BT(\u03b8). The parameters \u03b81 < \u00b7 \u00b7 \u00b7 < \u03b8n represent the utilities of items 1, . . . , n, and the probability of observing the outcome i \u227a j is\np(i \u227a j | \u03b8) = 1 1 + exp[\u2212(\u03b8j \u2212 \u03b8i)] .\nThe probability of observing an inconsistent comparison decreases with the distance between the items. This captures the intuitive notion that some pairs of items are easy to compare and some are more difficult [Zermelo, 1928, Bradley and Terry, 1952].\nA ranking \u03c3 is a function that maps an item to its rank, i.e., \u03c3(i) = rank of item i. The (ground-truth) identity ranking is denoted by id, i.e. id(i) = i. To measure the quality of a ranking \u03c3 with respect to the ground-truth, we consider the displacement\n\u2206(\u03c3) = n\u2211 i=1 |\u03c3(i)\u2212 i|,\n1 This convention greatly simplifies the notation throughout the paper, but differs from that used in most of the preference learning literature. In our paper, the item with rank 1 is the worst.\nalso known as Spearman\u2019s footrule distance. Another metric widely used in practice is the Kendall\u2013Tau distance, defined as K(\u03c3) = \u2211 i<j 1 {\u03c3(i) > \u03c3(j)}. Both metrics are equivalent up to a factor of two2, such that bounds on \u2206(\u03c3) also hold for K(\u03c3) up to constant factors.\nFinally, we say that an event A holds with high probability if P [A]\u2192 1 as n\u2192\u221e. For a random variable X and a sequence of numbers an, we say that X = O(an) with high probability if P [|X| \u2264 can]\u2192 1 as n\u2192\u221e for some constant c that does not depend on n.\nOutline of the paper. We begin by briefly reviewing related literature in Section 2. Next, in Section 3, we study the displacement of Quicksort\u2019s output under noisy comparisons. In Section 4, we empirically evaluate several AL strategies on three datasets. Finally, we conclude in Section 5."}, {"heading": "2 Related Work", "text": "Passive setting. Recently, there have been a number of results on the sample complexity of the BT model, based on the assumption that all pairs of items are chosen before any comparison outcome is revealed [Negahban et al., 2012, Hajek et al., 2014, Rajkumar and Agarwal, 2014, Vojnovic and Yun, 2016]. In general, these results reveal that choosing pairs of items uniformly at random is essentially optimal. Furthermore, they suggest that the ranking induced by the BT model cannot be recovered with less than \u2126(n2) comparisons. Our work shows that by adaptively selecting pairs based on observed outcomes, we observe substantial gains.\nActive preference learning. AL approaches for learning a ranking based on noisy comparison outcomes have been studied under various assumptions. Braverman and Mossel [2008] examine a model where outcomes of pairwise comparisons are flipped with a small, constant probability. Ailon [2012] considers an adversarial setting (comparison outcomes can be arbitrary) and investigates AL in the context of finding a ranking that minimizes the number of inconsistent outcomes, also known as the minimum feedback-arc set problem on tournaments (MFAST). These theoretical studies imply, in their respective settings, that O(n logk n) comparison outcomes are enough to recover a near-optimal ranking. Jamieson and Nowak [2011] propose an efficient active-ranking algorithm that is applicable if items can be embedded in Rd (e.g., using d features) and assuming that admissible rankings satisfy some geometric constraints. Wang et al. [2014] study a collaborative preference-learning problem and show that a variant of uncertainty sampling (a well-known AL strategy) works well for their problem. In this work, we assume that we do not have access to item features and that comparison outcomes follow a single BT model.\nBayesian methods. From a practical standpoint, Bayesian methods provide an effective way to select informative samples [MacKay, 1992]. However, they can be difficult to scale if the number of items is large. Work on Bayesian active preference learning includes Chu\n2\u2206(\u03c3)/2 \u2264 K(\u03c3) \u2264 \u2206(\u03c3) [Diaconis and Graham, 1977].\nAlgorithm 1 Quicksort Require: set of items V 1: if |V | < 2 then return list(V ) . Terminating case. 2: L\u2190 \u2205, R\u2190 \u2205 3: p\u2190 element of V selected uniformly at random 4: for i \u2208 V \\ {p} do 5: if i \u227a p then . Pairwise comparison. 6: L\u2190 L \u222a {i} 7: else 8: R\u2190 R \u222a {i} 9: end if 10: end for 11: return Quicksort(L) \u00b7 p \u00b7Quicksort(R)\nand Ghahramani [2005], Houlsby et al. [2012], Salimans et al. [2012] and Chen et al. [2013]. We compare our AL strategy to these methods in Section 4.\nMulti-armed bandit. The dueling bandit problem [Yue et al., 2009] is somewhat related to our work. In this problem, the goal is to identify the best item based on noisy comparison outcomes, using as few adaptively chosen samples as possible. Two recent papers also extend the problem to that of recovering the entire ranking (instead of only the top element). The work of Sz\u00f6r\u00e9nyi et al. [2015] is the closest to ours, as it also uses the BT model. One of their results is similar to our Theorem 2: They show that a quasi-linear number of comparisons is sufficient to recover the true ranking, under some conditions on \u03b8. Heckel et al. [2016] investigate a non-parametric model and develop some theoretical guarantees. In contrast to these works, our paper studies practical comparison budgets: we give theoretical guarantees for the output obtained from a single call to Quicksort, and in our experiments we never exceed \u2248 10 calls.\nQuicksort. The Quicksort algorithm [Hoare, 1962] is one of the most widely studied sorting procedures. Quicksort has been shown to produce useful rankings beyond classic sorting problems. For example, Ailon et al. [2008] show that Quicksort produces (in expectation) a 3-approximation to the MFAST problem. Quicksort combined with BT comparison outcomes has also been proposed as a probabilistic ranking model [Ailon, 2008]. We take advantage of some of the properties of this ranking model in order to derive the theoretical results of Section 3."}, {"heading": "3 Theoretical Results", "text": "In this section, we begin by studying the behavior and output of Quicksort under inconsistent comparison outcomes, without any assumptions on the noise generating process. Then, starting in Section 3.1, we focus on comparison outcomes generated by the BT model. Most full proofs are deferred to Appendix A.\nQuicksort (Algorithm 1) is best described as a recursive procedure. At each step of the recursion, a pivot item p is chosen uniformly at random (line 3). Then, during the\npartition operation (lines 4\u201310), every other item is compared to p and added to the set L or R, depending on the outcome. If all comparison outcomes are consistent, it is well-known that Quicksort terminates after sampling O(n log n) comparisons with high probability. What happens if we drop the consistency assumption? The following two lemmas state that these key properties remain valid, no matter which (and how many) comparison outcomes are inconsistent.\nLemma 1. Quicksort always terminates and samples each of the n(n\u22121)/2 possible comparisons at most once.\nProof. The proof is identical to the consistent setting. Consider the state of L and R at the end of a partition operation. Because |L|+ |R| = |V | \u2212 1, the recursive calls are made on sets of items of strictly decreasing cardinality, and the algorithm terminates after a finite number of steps. Furthermore, suppose that Quicksort samples an outcome for the pair (i, j). Then either i or j is the pivot in a partition operation. In either case, the pivot is not included in the recursive calls, which ensures that (i, j) cannot be compared again.\nLemma 2. Quicksort samples O(n log n) comparisons w.h.p.\nProof (sketch). We follow a standard analysis of Quicksort [see, e.g., Dubhashi and Panconesi, 2009, Section 3.3.3]. With high probability, we choose a \u201cgood\u201d pivot (i.e., one that results in a balanced partition) a constant fraction of the time. In this case, the depth of the call tree is O(log n). As there are at most n comparisons at each level of the call tree, we conclude that Quicksort uses O(n log n) comparisons in total. With respect to the standard proof, we need some additional work to formalize the notion of \u201cgood\u201d pivot to the setting where comparison outcomes are not consistent with a linear order.\nLemma 2 complements Theorem 3 in Ailon and Mohri [2010], which states that Quicksort samples O(n log n) in expectation. These results might suggest that all properties of Quicksort carry over to the noisy setting. This is not the case. For example, although Quicksort uses approximately 2n lnn comparisons on average in the noiseless setting [Sedgewick and Wayne, 2011], this number can be distinctly different with inconsistent comparison outcomes3.\nQuicksort (and efficient sorting algorithms in general) infer most pairs of items\u2019 relative position by transitivity and thus rely heavily on the consistency of comparison outcomes. In the noisy case, it is therefore important to precisely understand the effect of an inconsistent outcome on the output of the algorithm; this effect extends beyond the pair of items whose comparison outcome was inconsistent. For this purpose, the next Lemma bounds the displacement of Quicksort\u2019s output as a function of the inconsistent outcomes.\nLemma 3. Let E be the set of pairs sampled by Quicksort and whose outcome is inconsistent with id. Let \u03c3 be the output. Then,\n\u2206(\u03c3) \u2264 2 \u2211\n(i,j)\u2208E\n|i\u2212 j|\n3E.g., if comparison outcomes are uniformly random, all items are \u201cgood\u201d pivots w.h.p., and the average number of comparisons will be closer to n log2 n on average, for large n.\nProof (sketch). Consider the first partition operation, with pivot p, resulting in partitions L and R. Denote the errors made during this partition operation by E1. We can show that the displacement is bounded by\n\u2206(\u03c3) \u2264 \u2206L(\u03c3) + \u2206R(\u03c3) + 2 \u2211\n(i,j)\u2208E1\n|i\u2212 j|,\nwhere \u2206L(\u03c3) and \u2206R(\u03c3) represent the displacement of the ordering induced by \u03c3 on L and R, respectively. In other words, the total displacement can be decomposed into a term that represents the \u201clocal\u201d displacement due to the partition operation and into two terms that account for errors in the recursive calls. We obtain the desired result by recursively bounding \u2206L(\u03c3) and \u2206R(\u03c3).\nInformally, Lemma 3 states that the displacement can be bounded by a sum of \u201clocal shifts\u201d due to the inconsistent outcomes and that the price to pay for any information inferred by transitivity is bounded by a factor two. Lemma 3 is a crucial component of our subsequent analysis of BT noise, and we believe that it can be useful in order to investigate Quicksort under a wide variety of other noise generating processes."}, {"heading": "3.1 Displacement in the Poisson Model", "text": "From here on, we assume that comparison outcomes are generated from BT(\u03b8). Clearly, any results on the displacement of a ranking estimated from samples of a BT model will depend on \u03b8; it is easy to construct a model instance for which it is arbitrarily hard to recover the ranking, by choosing parameters sufficiently close to each other. Our approach is as follows. We postulate a family of distributions over \u03b8, and we give bounds on the displacement that hold with high probability.\nWe suppose that comparison outcomes are (in expectation) uniformly noisy across the ranking : i.e., comparing two elements at the bottom is (a priori) as difficult as comparing two elements at the top or in the middle. This means that the probability distribution over parameters \u03b81, . . . , \u03b8n results in (random) distances |\u03b8i+k \u2212 \u03b8i| that depend only on k. One such distribution arises if the parameters are drawn from a Poisson point process of rate \u03bb. That is,\ni.i.d. x1, . . . , xn\u22121 \u223c Exp(\u03bb), \u03b8i = i\u22121\u2211 k=1 xk. (1)\nThe average distance between two items separated by k positions in the ordering is E [\u03b8i+k \u2212 \u03b8i] = k/\u03bb. Although the distance between adjacent items is constant in expectation, we allow some parameters to be arbitrarily close4. The parameter \u03bb controls the expected level of noise; a large \u03bb is likely to result in a larger number of inconsistent outcomes. Although the precise choice of this Poisson model is driven by tractability concerns, in Section 3.2 we argue that it is essentially equivalent to choosing the parameters independently and uniformly at random in the interval [0, (n+ 1)/\u03bb], when \u03bb is fixed and n is large. We are now ready to state our main result.\n4 In particular, the expected minimum distance between two items (i.e., the min of n exponential r.v.s) decreases as (n\u03bb)\u22121 as n increases.\nTheorem 1. Let \u03b8 be sampled from a Poisson point process of rate \u03bb. Let \u03c3 be the output of Quicksort using comparison outcomes sampled from BT(\u03b8). Then, w.h.p.,\n\u2206(\u03c3) = O(\u03bb2n), (2) max i |\u03c3(i)\u2212 i| = O(\u03bb log n). (3)\nProof (sketch). Let zij be the indicator random variable of the event \u201cthe comparison between i and j results in an error\u201d, and let dij = |\u03b8i \u2212 \u03b8j|. The distance dij is a sum of |i\u2212 j| exponential random variables, i.e., dij \u223c Gamma(|i\u2212 j|, \u03bb), and we can show that\nE [zij] = E\n[ 1\n1 + exp(dij)\n] \u2264 E [exp(\u2212dij)] = (1 + 1/\u03bb)\u2212|i\u2212j|.\nUsing Lemma 3 and the fact that every pair of items is compared at most once, we find\nE [\u2206] \u2264 2 \u2211 i<j |i\u2212 j|E [zij] \u2264 2n \u221e\u2211 k=0 k(1 + 1/\u03bb)\u2212k = 2n\u03bb(\u03bb+ 1).\nThe random variables {zij} are not unconditionally independent (they are independent when conditioned on \u03b8) but, with some more work, we can show that Var [\u2206] = O(n). By using a Chebyshev bound, (2) follows.\nIn order to prove (3), we take advantage of a theorem due to Ailon [2008] which states that\nP [\u03c3(i) < \u03c3(j) | \u03b8] = p(i \u227a j | \u03b8),\neven if i and j were not directly compared with each other. We use a Chernoff bound on dij to show that the relative order between any two items separated by at least O(\u03bb log n) positions is correct with high probability. The second part of the claim follows easily.\nNote that any method that compares each pair of items at most once results in a ranking estimate \u03c4 with displacement \u2206(\u03c4) = \u2126(n) with high probability: As there is only a single (possibly inconsistent) comparison outcome between each pair of adjacent items, it is likely that a constant fraction of the items will be ranked incorrectly, resulting in a displacement that grows linearly in n. Hence, our bound on \u2206(\u03c3) shows that Quicksort is order-optimal (in n).\nIn light of Theorem 1, a natural question to ask is as follows. How many comparisons are needed in order to find the correct ranking? Clearly, finding the exact ranking is difficult: in fact, \u2126(n) comparison outcomes are necessary to discriminate the closest pair of items reliably (see Appendix B). As such, we will focus on finding a ranking that matches the ground truth everywhere, except at a vanishing fraction of the items.\nMultiple runs of Quicksort likely produce different outputs, because of the noisy comparison outcomes and because the algorithm itself is randomized (the pivot selection is random). By aggregating m independent outputs of Quicksort, is it possible to produce a better ranking estimate? Similarly to Sz\u00f6r\u00e9nyi et al. [2015], we combine the m outputs \u03c31, . . . , \u03c3m into an aggregate ranking \u03c3\u0302 using Copeland\u2019s method. The method assigns, to each item, a score that corresponds to the number of items that it beats in a majority of the rankings, and it then ranks the items by increasing score [Copeland, 1951]. We call the procedure Multisort and describe it in Algorithm 2.\nAlgorithm 2 Multisort Require: set of items V , number of iterations m 1: S \u2190 \u2205 2: for k = 1, . . . ,m do 3: \u03c3 \u2190 Quicksort(V ) 4: S \u2190 S \u222a {\u03c3} 5: end for 6: return Copeland aggregation of S\nTheorem 2. Let \u03b8 be sampled from a Poisson point process of rate \u03bb. Let \u03c3\u0302 be the output of Multisort using m = O(\u03bb2 log5 n) and comparison outcomes sampled from BT(\u03b8). Then, w.h.p.,\n\u2206(\u03c3\u0302) = o(\u03bbn).\nProof (sketch). We use results on the order statistics of the distances x1, . . . , xn\u22121 between successive items, as defined in (1), to partition the items into two disjoint subsets B and G. The set B contains a vanishing (1/ log2 n)-fraction of \u201cbad\u201d items that are difficult to order. The set G is such that the smallest distance dij from any item i \u2208 G to any other item j \u2208 [n] is bounded from below by c/(\u03bb log2 n). We can show that with m = O(\u03bb2 log5 n), for any i \u2208 G and j \u2208 [n] we have i < j \u21d0\u21d2 \u03c3(i) < \u03c3(j) in a majority of the Quicksort outputs (with high probability). This implies that \u03c3\u0302(i) = i for all i \u2208 G with high probability. Using (3) for items in B, we have\n\u2206(\u03c3\u0302) = |B| \u00b7O(\u03bb log n) = O(\u03bbn/ log n)\nwith high probability.\nTheorem 2 states that all but a vanishing fraction of items are correctly ranked using O(\u03bb2n log6 n) comparisons. This result should be compared to the \u2126(n2) comparisons needed if samples are selected uniformly at random.\nEmpirical validation. In Figure 1, we illustrate the results of Theorems 1 and 2 by running simulations for increasing n and different values of \u03bb. The bound on \u2206(\u03c3) is tight in n, but the dependence on \u03bb appears to be linear rather than quadratic. The bound on maxi|\u03c3(i)\u2212i| appears to be tight in n and \u03bb. Finally, we compare the Copeland aggregation of m outputs of Quicksort with the ranking induced by the maximum-likelihood (ML) estimate, inferred from the outcomes of all the pairwise comparisons sampled by them runs. Although the ranking induced by the ML estimate does not benefit from the guarantees of Theorem 2, it performs better in practice. We will make use of this observation in Section 4."}, {"heading": "3.2 Independent Uniformly-Distributed Parameters", "text": "A different (perhaps more natural) assumption on the parameters \u03b8 is to consider that they are drawn independently and uniformly at random over some interval. That is,\ni.i.d. \u03b8\u03041, . . . , \u03b8\u0304n \u223c U(0, (n+ 1)/\u03bb),\nwith \u03b81, . . . , \u03b8n the order statistics of \u03b8\u0304, i.e., the random variables arranged in increasing order. From some elementary results on the joint distribution of order statistics [see, e.g., Arnold et al., 2008], we see that\n|\u03b8i+k \u2212 \u03b8i| \u223c (n+ 1)/\u03bb \u00b7 Beta(k, n\u2212 k + 1),\ni.e., a Beta random variable rescaled between 0 and (n + 1)/\u03bb. Letting fk,n(x) be the probability density of |\u03b8i+k \u2212 \u03b8i|, we have, for any fixed k and \u03bb,\nfk,n(x) \u221d xk\u22121 [ 1\u2212 \u03bbx\nn+ 1\n]n\u2212k n\u2192\u221e\u2212\u2212\u2212\u2192 xk\u22121e\u2212\u03bbx.\nWe recognize the functional form of the density of a Gamma(k, \u03bb) distribution. Hence, the Poisson model and the i.i.d. uniform model are essentially equivalent for fixed \u03bb and large n, and we can expect the results developed in Section 3.1 to hold under this distribution as well."}, {"heading": "4 Experimental Results", "text": "In practice, the comparison budget for estimating a ranking from noisy data might typically be larger than that for a single call to Quicksort, and it might not exactly match the number of comparisons required to run a given number of calls to Quicksort to completion. Building upon the observations made at the end of Section 3.1, we suggest the following practical active-learning strategy: for a budget of c pairwise comparisons, run the sorting procedure repeatedly until the budget is depleted (the last call might have to be truncated). Then, retain only the set of c comparison pairs and their outcomes and discard the rankings produced by the sorting procedure. The final ranking estimate is then induced from the ML estimate over the set of c comparison outcomes.\nIn this section, we demonstrate the effectiveness of this sampling strategy on synthetic and real-world data. In particular, we show that it is comparable to existing AL strategies at a minuscule fraction of the computational cost."}, {"heading": "4.1 Competing Sampling Strategies", "text": "To assess the relative merits of our sorting-based strategy, we consider three strategies that we believe are representative of the state of the art in active preference learning.\nUncertainty sampling. Developed in the context of classification tasks, this popular active-learning heuristic suggests to greedily sample the point that lies closest to the decision boundary [Settles, 2012]. In the context of a ranking task, this corresponds to sampling the pair of items whose relative order is most uncertain. After t observations, given an estimate of model parameters \u03b8t, the strategy selects the (t+1)-st pair uniformly at random in\narg min i 6=j\n|\u03b8ti \u2212 \u03b8tj|.\nThis set can be computed in time O(n log n) by sorting the parameters. The parameters themselves need to be estimated, e.g., using (penalized) ML inference that in practice can be the dominating cost.\nBayesian methods. If we have access to a full posterior distribution qt(\u03b8) instead of a point estimate \u03b8t, we can take advantage of the extra information on the uncertainty of the parameters to improve the selection strategy. A principled approach to AL consists of sampling the point that maximizes the expected information gain [MacKay, 1992]. That is, the pair of items at iteration t+ 1 is selected in\narg max i 6=j\nH(qt)\u2212 E [ H(qt+1) ] , (4)\nwhere H(\u00b7) denotes the entropy function. A conceptually similar but slightly different selection strategy is given by Chen et al. [2013]. Letting qij be the marginal distribution of (\u03b8i, \u03b8j), the pair is selected in\narg max i 6=j\nE [ KL(qt+1ij \u2016qtij) ] , (5)\nwhere KL(\u00b7) denotes the Kullback\u2013Leibler divergence. Computing the exact posterior is not analytically tractable for the BT model, but a Gaussian approximation can be found in time O(n3). Criteria (4) and (5) can be computed in constant time for each pair of items. The dominating cost is again that of estimating \u03b8 (or, in this case, q(\u03b8)).\nIn addition to these existing AL strategies, we also include in our experiments a variation of our sorting-based strategy that uses Mergesort instead of Quicksort. In the noiseless setting, Mergesort is known to use on average \u2248 39 % fewer comparisons than Quicksort per run [Knuth, 1998], but it does not benefit from the theoretical guarantees developed in Section 3."}, {"heading": "4.2 Running Time", "text": "In this section, we briefly discuss the running time of the methods. We implement ML and Bayesian approximate inference algorithms for the BT model as a Python library5. For\n5See: http://lucas.maystre.ch/choix.\nML inference, we find that the fastest running time is achieved by a truncated Newton algorithm (even for large n). For approximate Bayesian inference, we use a variant of the expectation-propagation algorithm outlined by Chu and Ghahramani [2005]. All experiments are performed on a server with a 12-core Xeon X5670 processor running at 2.93 GHz. Numerical computations take advantage of the Intel Math Kernel Library.\nWe illustrate the running time of AL strategies as follows. For n \u2208 {102, 103, 104}, we generate outcomes for n comparisons pairs chosen uniformly at random among n items. For each strategy, we then measure the time it takes to select the (n+1)-st pair of items adaptively. The results are presented in Table 1. Note that these numbers are intended to be considered as orders of magnitude, rather than exact values, as they depend on the particular combination of software and hardware that we use. The running time of the Bayesian AL strategies exceed 10 hours for n = 104 and the calls were stopped ahead of completion. Our sorting-based methods, like random sampling, are the only AL strategies whose running time is constant for increasing n (and for increasing c). In fact, their running time is negligible in comparison to the other strategies, including uncertainty sampling."}, {"heading": "4.3 Empirical Evaluation", "text": "We now investigate three datasets and measure the displacement of rankings estimated from adaptively-chosen samples, as a function of the budget c. Note that in order to use uncertainty sampling and Bayesian methods, it is necessary to choose a regularization strength or prior variance in the inference step. Different values can result in drastically different outcomes (in particular for uncertainty sampling) and, in practice, choosing a good value can be a significant challenge6. In the following, we report results for the values that worked best a posteriori.\nSynthetic dataset. We generate n i.i.d. parameters \u03b81, . . . , \u03b8n uniformly in [0, (n+1)/\u03bb] and draw samples from BT(\u03b8). The ground-truth ranking is the one induced by the parameters. Figure 2 presents results for n = 200 and \u03bb = 5 (plots for different values\n6Observe that our sorting-based approach is entirely parameter-free and is therefore not affected by this issue.\nof \u03bb are presented in Appendix C, and are qualitatively similar). In comparison to random sampling, AL is very effective and results in significantly better ranking estimates for any given number of comparisons. The two Bayesian methods, though being the most computationally expensive, perform the best for all values of c, but are nearly indistinguishable from uncertainty sampling. The two sorting-based strategies perform similarly (with a small edge for Mergesort). They are slightly worse than the Bayesian methods but are still able to reap most of the benefits of active learning.\nSushi dataset. Next, we consider a dataset of Sushi preferences [Kamishima and Akaho, 2009]. In this dataset, 5000 respondents give a strict ordering over 10 different types of sushi. These 10 sushi are chosen among a larger set of n = 100 items. To suit our purposes, we decompose each 10-way partial ranking into pairwise comparisons, resulting in 225 000 comparison outcomes. We use all comparisons to fit a BT model that induces a ground-truth ranking7.\nThe comparisons are dense, and there is at least one comparison outcome for almost all pairs. When an outcome for pair (i, j) is requested, we sample uniformly at random over all outcomes observed for this pair. In the rare case where no outcome is available, we return i \u227a j with probability 1/2. This enables us to compare sampling strategies in a realistic setting, where the assumptions of the BT model do not necessarily hold anymore.\nResults are shown in Figure 3 (left). Once again, active learning performs noticeably better than random sampling. On this real-world dataset, the performance of our sortingbased strategies is indistinguishable from that of the Bayesian methods, after completing one entire call to the sorting procedure (slightly less than 1000 comparisons). This result should be interpreted in light of the time needed to select all 104 pairs: a fraction of a\n7 The BT-induced ranking is almost the same as that obtained using the Copeland score. The results are very similar if the Copeland aggregation is used as ground truth.\nsecond for sorting-based strategies, and several hours for the Bayesian methods. Finally, we observe that the performance of uncertainty sampling progressively degrades as c increases. A detailed analysis reveals that uncertainty sampling increasingly focuses on a small set of hard-to-discriminate pairs, symptomatic of a well-known issue [Settles, 2012].\nGIFGIF dataset. GIFGIF8 is a project of the MIT Media Lab that aims at explaining the emotions communicated by a collection of animated GIF images. Users of the website are shown a prompt with two images and a question, \u201cWhich better expresses x?\u201d where x is one of 17 emotions. The users can click on either image, or use a third option, neither. To date, over three million comparison outcomes have been collected. For the purpose of our experiment, we restrict ourselves to a single emotion, happiness ; and we ignore outcomes that resulted in neither. We consider 106 887 comparison outcomes over n = 6120 items\u2014a significant increase in scale compared to the Sushi dataset.\nAs the data, despite a relatively large number of comparisons, remains sparse (less than 20 comparisons per item on average), we proceed as follows. We fit a BT model by using all the available comparisons and use the induced ranking as ground truth. We then generate new, synthetic comparison outcomes from the BT model. In this sense, the experiment enables us to compare sampling strategies by using a large BT model with realistic parameters. The large number of items makes uncertainty sampling and the two Bayesian methods prohibitively expensive. We try a simplified, computationally less expensive version of uncertainty sampling where, at every iteration, each item is compared to its two closest neighbors, but this heuristic fails spectacularly: The resulting displacement is over 5\u00d7 larger than random sampling for c = 106, and is therefore not reported here (see Appendix C).\nFigure 3 (right) compares the displacement of random sampling to that of the two sorting-based sampling strategies for increasing c. The adaptive sampling approaches\n8See http://www.gif.gf/. Data available at http://lucas.maystre.ch/gifgif-data.\nperform systematically better. After 106 comparisons, the displacement of random sampling is 14 % and 23 % larger than that of Quicksort and Mergesort, respectively. Conversely, in order to reach any target displacement, Mergesort requires approximately 2\u00d7 fewer comparisons than random sampling."}, {"heading": "5 Conclusion", "text": "In this work, we demonstrate that active learning can substantively speed up the task of learning a ranking from noisy comparisons gains\u2014both in theory and in practice. With the advent of large-scale crowdsourced ranking surveys, exemplified by GIFGIF and wiki surveys [Salganik and Levy, 2015], there is a clear need for practical AL strategies. However, existing methods are complex and computationally expensive to operate even for a reasonable number of items (a few thousands). We show that a deceptively simple idea\u2014 repeatedly sorting the items\u2014is able to bring in all the benefits of active learning, is trivial to implement, and is computationally no more expensive that random sampling. Therefore, we believe that our method can be broadly useful for machine-learning practitioners interested in ranking problems.\nAcknowledgments. We thank Holly Cogliati-Bauereis, Ksenia Konyushkova, Brunella Spinelli and anonymous reviewers for careful proofreading and helpful comments."}, {"heading": "A Proofs", "text": "Section A.1 contains the proofs of Lemmas 2 and 3. Section A.2 presents the proof for our result on the displacement of the output of a single call to Quicksort (Theorem 1), and Section A.3 that of our result on the displacement of the Copeland aggregation of multiple outputs.\nA.1 Lemmas 2 and 3\nWe start by briefly presenting a result from graph theory that will be useful in the proof of Lemma 2. A tournament is a directed graph obtained by assigning a direction to every edge of a complete graph. The score sequence of a tournament is defined as the nondecreasing sequence of the vertices\u2019 outdegrees. The following proposition is due to Landau [1953].\nProposition 1. Let (s1, . . . , sn) with 0 \u2264 s1 \u2264 \u00b7 \u00b7 \u00b7 \u2264 sn be the score sequence of a tournament on n vertices. Then,\nk \u2212 1 2 \u2264 sk \u2264 n+ k \u2212 2 2 \u2200 k \u2208 [n].\nWe use a tournament on n vertices to represent the outcome of a comparison between each pair of items. In particular, we represent the outcome i \u227a j by an edge (i, j). In this case, the outdegree of a vertex i corresponds to the number of items which \u201cwon\u201d in a\ncomparison against i. Note that the comparison outcomes do not need to be transitive, i.e., the tournament can contain cycles.\nThe proof of Lemma 2 is adapted from standard results on Quicksort, see, e.g., Dubhashi and Panconesi [2009, Section 3.3.3]. These results are based on the fact that it is likely that the random choice of pivot leads to a well-balanced partition into subsets L and R. In our setting, the comparison outcomes do not need to be consistent with an ordering of the items, therefore we cannot use the standard argument based on the pivot\u2019s rank. Instead, we use the tournament representation of the comparison outcomes and analyze the pivot\u2019s out-degree (using Proposition 1) to ensure that the partition is balanced often enough.\nProof of Lemma 2. We show that the maximum call depth of Quicksort is at most d48 log ne with high probability. The statement follows by noticing that at most n comparisons are used at each level of the call tree.\nBy Lemma 1, Quicksort samples a comparison outcome for each pair of items at most once. Therefore, we can represent these (a priori unobserved) pairwise outcomes as a tournament T = ([n], A). At each step of the recursion, we select a pivot p uniformly at random in the set V (line 3), and compare it to the rest of the items in the set (line 5). Let TV denote the subgraph of T induced by V . Given that the comparison outcomes follow from the edges of the tournament, L is equal to the set of incoming neighbors of p in TV . (Correspondingly, R is equal to the set of the outgoing neighbors.) Hence, the outdegree of p in TV determines how balanced the partition is. The probability that the outdegree of p lies in the middle half of the score sequence is 1/2, and if it does, Proposition 1 tells us that\n|V | \u2212 7 8 \u2264 outdeg(p) \u2264 7|V | \u2212 5 8 .\nIn this case, at the end of the partition |L| and |R| are of size at most 7|V |/8, and in at most log8/7(n) \u2264 8 log n such partitions we get to a subset of size one and match the terminating case. Even though we do not select the pivot in the middle half every time, it is unlikely that more than c \u00b7 8 log n recursions are needed (for some small constant c) to select the pivot in the middle range at least 8 log n times. Let zd i.i.d \u223c Bern(1/2) be the indicator variable for the event \u201cthe pivot is selected in the middle half at level of recursion d\u201d. Using a Chernoff bound, we have\nP d48 logne\u2211 d=1 zd \u2264 8 log n  \u2264 1 n2 ,\ni.e., the depth of a leaf in the call tree is at most d48 log ne with probability at least 1\u2212 1/n2. As there are at most n leaves in the tree, the maximum depth is bounded by the same value with probability at least 1\u2212 1/n.\nIn order to prove Lemma 3, we introduce some additional notation. For any \u03c3 \u2208 Sn and V \u2286 [n], let \u03c3V : V \u2192 {1, . . . , |V |} be the ordering induced by \u03c3 on V . We generalize the definition of displacement as\n\u2206V (\u03c3, \u03c4) = \u2211 i\u2208V |\u03c3V (i)\u2212 \u03c4V (i)|.\nFor conciseness, we use the shorthand \u2206V (\u03c3) . = \u2206V (\u03c3, id), where id is the identity permutation.\nProof of Lemma 3. Denote by V the collection of working sets that were used as input to one of the recursive calls to Quicksort. For V \u2208 V , let EV be the set of pairs sampled by Quicksort to partition V and which results in an error. Note that EV \u2229 EV \u2032 = \u2205 for V 6= V \u2032, and that \u22c3 V EV = E. We will show that for all V \u2208 V ,\n\u2206V (\u03c3) \u2264 \u2206L(\u03c3) + \u2206R(\u03c3) + 2 \u2211\n(i,j)\u2208EV\n|i\u2212 j|, (6)\nwhere L and R are the two sets obtained at the end of the partition operation. The lemma follows by taking V = [n] and recursively bounding \u2206L(\u03c3) and \u2206R(\u03c3).\nConsider the partition operation on V , with pivot p, resulting in partitions L and R. Let \u03c3\u0303 be the ordering on V that a) ranks L at the bottom, p in the middle and R at the top, and b) matches the identity permutation on L and R, i.e., \u2206L(\u03c3\u0303) = \u2206R(\u03c3\u0303) = 0. In a sense, \u03c3\u0303 is the ordering that would be obtained if there were no further errors in the remaining recursive calls. Using the triangle inequality, we have that\n\u2206V (\u03c3) \u2264 \u2206V (\u03c3, \u03c3\u0303) + \u2206V (\u03c3\u0303). (7)\nBy definition of \u03c3\u0303, we have that\n\u2206V (\u03c3, \u03c3\u0303) = \u2206L(\u03c3, \u03c3\u0303) + \u2206R(\u03c3, \u03c3\u0303) = \u2206L(\u03c3) + \u2206R(\u03c3), (8)\nwhere the first equality follows from a), and the second follows from b). Finally, we bound \u2206V (\u03c3\u0303). Let E\u2212V = {(p, i) \u2208 EV : i < p}, and similarly E + V = {(p, i) \u2208 EV : i > p}. Without loss of generality, we can assume that V consists of consecutive integers, and that \u03ba .= |E\u2212V | \u2264 |E + V |. We proceed as follows: starting from the ranking idV , we progressively incorporate errors into the ranking, ending with \u03c3\u0303 once all errors have been treated. To understand the impact of each error on \u2206V (\u03c3\u0303), we look at errors in the following specific sequence.\n1. At steps t = 1, . . . , \u03ba, we consider the t-th \u201csmallest\u201d errors in E\u2212V and E + V . That is,\nwe process (p, i) \u2208 E\u2212V and (p, i\u2032) \u2208 E + V such that |p \u2212 i| and |p \u2212 i\u2032|, respectively, are smallest among errors not yet treated.\n2. At steps t = \u03ba+ 1, . . . , |E+V |, we process the remaining errors in E + V , once again in\nincreasing order of distance to p.\nFigure 4 illustrates the state of the ranking at different steps on a concrete example. We start with the first case, i.e., t \u2264 \u03ba. The effect of the errors (p, i) and (p, i\u2032) on \u2206V (\u03c3\u0303) is as follows.\n\u2022 All items j < i and j > i\u2032 are not affected by the two errors: their position remains the same.\n\u2022 The position of the pivot p remains the same, as the two errors balance out.\n\u2022 Item i is shifted by |p\u2212 i|+ 1 positions to the right, just right of p. Similary, item i\u2032 is shifted by |p\u2212 i\u2032|+ 1 positions to the left, just left of p.\n\u2022 The |p\u2212 i| \u2212 1 items that are between p (excluded) and i are shifted by 1 position to the left. Similarly, the |p\u2212 i\u2032| \u2212 1 items that are between p and i\u2032 are shifted by 1 position to the right.\nHence, the two errors contribute 2(|p \u2212 i| + |p \u2212 i\u2032|) towards \u2206V (\u03c3\u0303). Now consider the second case, when t > \u03ba. The effect of an error (p, i) is as follows.\n\u2022 All items j > i and all the items on the left of p are not affected by the error: their position remains the same.\n\u2022 The (at most) |p \u2212 i| items that are between p (included) and i are shifted by 1 position to the right.\n\u2022 Item i is shifted by at most |p\u2212 i| positions to the left, just left of p.\nAs a result, the error contributes at most 2|p \u2212 i| to the displacement. Adding up the contributions of all the errors, it follows that\n\u2206V (\u03c3\u0303) \u2264 2 \u2211\n(i,j)\u2208EV\n|i\u2212 j|. (9)\nCombining (8) and (9) using (7) we obtain (6), which concludes the proof.\nA.2 Theorem 1\nFrom now on, we focus on parameters drawn from a Poisson process of rate \u03bb, as described in (1) in the main text. We consider a worst-case scenario and assume that Quicksort samples a comparison outcome for every pair of items. Let zij be the indicator random variable of the event \u201cthe comparison between i and j resulted in an error\u201d. By Lemma 3, we have\n\u2206(\u03c3) \u2264 2 \u2211 i<j |i\u2212 j|zij (10)\nIn the following, we will bound some of the statistical properties of the random variables {zij}. We start with a lemma that bounds their mean.\nLemma 4. For any 1 \u2264 i < j \u2264 n,\nE [zij] \u2264 ( \u03bb\n\u03bb+ 1\n)j\u2212i .\nProof. Let dij = \u03b8i \u2212 \u03b8j be the (random) distance between items i and j. This distance is a sum of k = j \u2212 i independent exponential random variables, and therefore dij \u223c Gamma(k, \u03bb). The comparison outcome is generated as per the BT model; conditioned on the distance dij , the random variable zij is a Bernoulli trial with probability [1+exp(dij)]\u22121. Therefore, we have that\nE [zij] \u2264 E [exp(\u2212dij)] = ( \u03bb\n\u03bb+ 1\n)k\nNext, we bound their covariance. Note that the random variables {zij} are in general not unconditionally independent. They become independent only when conditioned on \u03b8.\nLemma 5. For any 1 \u2264 i < j \u2264 n and any 1 \u2264 u < v \u2264 n, let A = {i .. j\u22121} and B = {u .. v\u22121}.\nCov [zij, zuv] \u2264  0 if A \u2229B = \u2205,( \u03bb \u03bb+ 1 )j\u2212i if A = B,( \u03bb+ 1\n\u03bb+ 2\n)j\u2212i+v\u2212u otherwise.\nProof. If A and B are disjoint, the distances dij and duv are independent random variables. Conditioned on the distances, the comparison outcomes are independent Bernoulli trials, and we conclude that zij and zuv are independent. In the two remaining cases, we bound E [zijzuv] \u2265 Cov [zij, zuv]. If A = B, then zij = zuv and we have\nE [zijzuv] = E [ z2ij ] = E [zij]\nand we apply Lemma 4. Finally, if A and B are neither equivalent nor disjoint, the two comparison outcomes are independent Bernoulli trials conditioned on the distances dij and duv, but the distances are not independent. Consider the case where i < u < j < v. Even though dij and duv are dependent, the distances diu, duj, djv are independent Gamma random variables of rate \u03bb and shape u\u2212 i, j \u2212 u and v \u2212 j, respectively, and\nE [zijzuv] \u2264 E [exp{\u2212(diu + duj)\u2212 (duj + djv)}]\n=\n( \u03bb\n\u03bb+ 1\n)u\u2212i( \u03bb\n\u03bb+ 2\n)j\u2212u( \u03bb\n\u03bb+ 1\n)v\u2212j \u2264 ( \u03bb+ 1\n\u03bb+ 2 )j\u2212i+v\u2212u The other cases are treated analogously.\nLemmas 4 and 5 will be useful in proving the first part of Theorem 1. For the second part, we need a result from Ailon [2008], which characterizes the pairwise marginals of the distribution over rankings induced by Quicksort with comparisons sampled from a BT model.\nTheorem 3 (Ailon, 2008, Theorem 4.1). Let \u03c3 be the output of Quicksort using comparison outcomes sampled from BT(\u03b8). Then, for any i, j \u2208 [n],\nP [\u03c3(i) < \u03c3(j) | \u03b8] = p(i \u227a j | \u03b8)\nNote that the result is non-trivial as i and j might not have been directly compared to each other: their relative position might have been deduced by transitivity from other comparison outcomes. We are now ready to prove Theorem 1.\nProof of Theorem 1. We begin with the first part of the theorem, which bounds the displacement \u2206(\u03c3). For clarity of exposition, we use the notation zi\u2192k instead of zij if j = i+ k. Using (10) and Lemma 4, we can bound the expected displacement as\nE [\u2206] \u2264 n\u22121\u2211 i=1 n\u2212i\u2211 k=1 2kE [zi\u2192k] \u2264 n \u221e\u2211 k=1 2k ( \u03bb \u03bb+ 1 )k = 2n\u03bb(\u03bb+ 1).\nIn a similar way, using Lemma 5, we can bound the variance of the displacement as\nVar [\u2206] \u2264 n\u22121\u2211 i=1 n\u2212i\u2211 k=1 4k2Var [zi\u2192k] + 2 n\u22121\u2211 i=1 n\u2212i\u2211 k=1 2k i+k\u2211 u=i+1 n\u2212u\u2211 `=1 2`Cov [zi\u2192k, zu\u2192`]\n\u2264 n \u221e\u2211 k=1 4k2 ( \u03bb \u03bb+ 1 )k + 2n \u221e\u2211 k=1 2k2 ( \u03bb+ 1 \u03bb+ 2 )k \u00b7 \u221e\u2211 `=1 2` ( \u03bb+ 1 \u03bb+ 2 )` \u2264 1500n(\u03bb5 + 1).\nCombining the bounds for the mean and the variance with Chebyshev\u2019s inequality, we have that\nP [ \u2206(\u03c3) \u2265 50n(\u03bb2 + 1) ] \u2264 \u03bb/n,\nwhich concludes the proof of the first part of the claim. The second part of the theorem bounds the maximum displacement for any single item. We start by showing that with high probability, there is no pair of items separated by at least O(\u03bb log n) positions that is \u201cflipped\u201d in the output of Quicksort. Let i and j be two items such that i < j and let k = |i\u2212 j|. Then dij \u223c Gamma(k, \u03bb), and using a Chernoff bound we obtain\nP [dij \u2264 k/(e\u03bb)] \u2264 exp(\u2212k/e).\nIf k \u2265 3(\u03bb+ 1)e log n, we find that\nP [dij \u2264 k/(e\u03bb)] \u2264 P [dij \u2264 3 log n] \u2264 n\u22123. (11)\nUsing the fact that the pairwise marginals of Quicksort match the pairwise comparison outcome probabilities (Theorem 3), we find\nP [\u03c3(j) < \u03c3(i)] = p(j \u227a i) \u2264 exp(\u22123 log n) = n\u22123. (12)\nCombining (11) and (12), and using a union bound over the ( n k ) pairs, we see that with probability 1\u2212 1/n there is no pairs of items (i, j) separated by at least 3(\u03bb+ 1)e log n position with i < j but \u03c3(j) < \u03c3(i). Finally, suppose that there is an i such |\u03c3(i)\u2212 i| = k. Without loss of generality, we can assume that i < \u03c3(i). This means that there are k items larger than i that are on the left of i in \u03c3. In particular, there is an item j > i such that |i\u2212 j| \u2265 k and \u03c3(j) < \u03c3(i). This concludes the proof.\nA.3 Theorem 2\nIn order to prove Theorem 2, we first need a basic result on the order statistics of exponential random variables. Let x1, . . . , xn, be i.i.d. exponential random variables of rate \u03bb. Let x(1), . . . , x(n) be their order statistics, i.e., the random variables arranged in increasing order. Then,\nx(i) = i\u2211\nj=1\n1\nn\u2212 j + 1 yj, (13)\nwhere y1, . . . , yn are i.i.d. exponential random variables of rate \u03bb [see, e.g., Arnold et al., 2008, Section 4.6].\nProof of Theorem 2. We consider the order statistics of the n\u22121 i.i.d. exponential random variables x1, . . . , xn\u22121 which define the distances between neighboring items. Let n\u0302 = dn/ log2 ne, and denote by B \u2282 [n] the set of items at both ends of x(1), . . . , x(n\u0302\u22121). These \u201cbad\u201d items are close to their nearest neighbor, and we simply invoke Theorem 1 to claim that each of these items is shifted by at most O(\u03bb log n) positions with high probability. Consider now the \u201cgood\u201d items, i.e., those in G = [n] \\ B. Using (13) and for n large enough,\nP [ x(n\u0302) \u2264 1/(e\u03bb log2 n) ] \u2264 P [ n\u0302\u2211 j=1 yj/n \u2264 1/(e\u03bb log2 n) ] \u2264 exp(\u2212n\u0302/e) \u2264 1/n.\nThe second-to-last inequality follows from a Chernoff bound similar to that used in the proof of Theorem 1. Therefore, with high probability all items in G are at distance larger than c/(\u03bb log2 n) from their nearest neighbor.\nWe will now show that after m = O(\u03bb2 log5 n) runs of Quicksort, \u03c3\u0302(i) = i with high probability for all i \u2208 G. Let i \u2208 G, j \u2208 [n] be a pair of items, and without loss of generality assume that i < j. Let tk be the indicator random variable for the event \u201c\u03c3(i) < \u03c3(j) in the k-th run of Quicksort\u201d, and let p = P [tk = 1]. Then, using Theorem 3,\np\u2212 1 2 = p(i \u227a j)\u2212 1 2 = 1\u2212 exp(\u2212dij) 2[1 + exp(\u2212dij)] \u2265 1\u2212 exp[\u22121/(e\u03bb log 2 n)] 4 \u2265 1 8e\u03bb log2 n\nwith high probability. In the last inequality, we used the fact that 1 \u2212 e\u2212x \u2265 x/2 for x \u2208 [0, 1]. The random variables t1, . . . , tm are independent Bernoulli trials, and using a Chernoff bound we obtain\nP [\u03c3\u0302(j) < \u03c3\u0302(i)] = P [ m\u2211 k=1 tk \u2264 n/2 ] \u2264 exp[\u22122m(p\u2212 1/2)2] \u2264 exp [ \u2212 m 32e2\u03bb2 log4 n ] .\nWith m = 96e2\u03bb2 log5 n, we have P [\u03c3\u0302(j) < \u03c3\u0302(i)] \u2264 n\u22123, and using a union bound we see that with probability 1 \u2212 1/n we have \u03c3\u0302(i) = i for all i \u2208 G. Therefore, the total displacement is\n\u2206(\u03c3\u0302) = \u2211 i\u2208B |\u03c3\u0302(i)\u2212 i| \u2264 |B| \u00b7 3(\u03bb+ 1)e log n = O(\u03bbn/ log n).\nThis concludes the proof."}, {"heading": "B Discriminating the Closest Items", "text": "The distance between the two closest items is dmin = mini|\u03b8i+i \u2212 \u03b8i| = mini xi, i.e., the minimum of n \u2212 1 independent exponential random variables of rate \u03bb. Therefore, dmin \u223c Exp((n\u2212 1)\u03bb), and for n \u2265 2 with probability at least 1\u2212 e\u22121/2 \u2248 0.39 we have dmin \u2264 (\u03bbn)\u22121. Suppose that we compare the two closest items m times, and let zi be the indicator random variable for the event \u201cthe outcome of the i-th comparison is incorrect\u201d. Assuming that dmin \u2264 (\u03bbn)\u22121 and that \u03bbn \u2265 1/2,\nP [zi = 0] \u2264 1 1 + exp[\u22121/(\u03bbn)] \u2264 1 2\u2212 1/(\u03bbn) = 1 2 \u00b7 ( 1 + 1 2\u03bbn\u2212 1 ) \u2264 1 2 exp [ 1 2\u03bbn\u2212 1 ] ,\nwhere we used the inequality ex \u2265 1 + x twice. Given the m comparison outcomes, we use a majority vote to decide the relative order of the two items. The probability of making the correct decision is\nP [ m\u2211 i=1 zi \u2264 m/2 ] \u2264 m/2\u2211 k=1 ( m k ) P [zi = 0] m \u2264 exp [\nm\n2\u03bbn\u2212 1\n] \u00b7 2\u2212m m/2\u2211 k=1 ( m k ) = 1\n2 exp\n[ m\n2\u03bbn\u2212 1\n] .\nTherefore, if m = o(\u03bbn) the probability of making a mistake is bounded from below by a positive constant."}, {"heading": "C Additional Figures", "text": "In this section, we present a few additional figures that complement the ones presented in Section 4 of the main text.\nFigure 5 presents the results on the GIFGIF dataset including a variant of uncertainty sampling. This variant samples, at each iteration, n\u2212 1 comparisons consisting of adjacent pairs in the ranking \u03b8\u0302. This strategy performs surprisingly poorly.\nFigure 6 presents results on synthetic datasets with n = 200 and \u03bb \u2208 {1, 2, 5, 10}. For the reader\u2019s convenience, we plot every graph on both a linear and a logarithmic scale. Unsurprisingly, the gains of adaptive sampling are greater when the noise is smaller."}], "references": [{"title": "Reconciling Real Scores with Binary Comparisons: A Unified Logistic Model for Ranking", "author": ["N. Ailon"], "venue": "In Advances in Neural Information Processing Systems 21,", "citeRegEx": "Ailon.,? \\Q2008\\E", "shortCiteRegEx": "Ailon.", "year": 2008}, {"title": "An Active Learning Algorithm for Ranking from Pairwise Preferences with an Almost Optimal Query Complexity", "author": ["N. Ailon"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Ailon.,? \\Q2012\\E", "shortCiteRegEx": "Ailon.", "year": 2012}, {"title": "Preference-based learning to rank", "author": ["N. Ailon", "M. Mohri"], "venue": "Machine Learning,", "citeRegEx": "Ailon and Mohri.,? \\Q2010\\E", "shortCiteRegEx": "Ailon and Mohri.", "year": 2010}, {"title": "Aggregating Inconsistent Information: Ranking and Clustering", "author": ["N. Ailon", "M. Charikar", "A. Newman"], "venue": "Journal of the ACM,", "citeRegEx": "Ailon et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ailon et al\\.", "year": 2008}, {"title": "Linear Extensions of a Random Partial Order", "author": ["N. Alon", "B. Bollob\u00e1s", "G. Brightwell", "S. Janson"], "venue": "The Annals of Applied Probability,", "citeRegEx": "Alon et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Alon et al\\.", "year": 1994}, {"title": "Rank Analysis of Incomplete Block Designs: I", "author": ["R.A. Bradley", "M.E. Terry"], "venue": "The Method of Paired Comparisons. Biometrika,", "citeRegEx": "Bradley and Terry.,? \\Q1952\\E", "shortCiteRegEx": "Bradley and Terry.", "year": 1952}, {"title": "Noisy sorting without resampling", "author": ["M. Braverman", "E. Mossel"], "venue": "In Proceedings of SODA\u201908,", "citeRegEx": "Braverman and Mossel.,? \\Q2008\\E", "shortCiteRegEx": "Braverman and Mossel.", "year": 2008}, {"title": "Pairwise Ranking Aggregation in a Crowdsourced Setting", "author": ["X. Chen", "P.N. Bennett", "K. Collins-Thompson", "E. Horvitz"], "venue": "In Proceedings of WSDM\u201913,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Extensions of Gaussian Processes for Ranking: Semisupervised and Active Learning", "author": ["W. Chu", "Z. Ghahramani"], "venue": "In Proceedings of the NIPS 2005 Workshop on Learning", "citeRegEx": "Chu and Ghahramani.,? \\Q2005\\E", "shortCiteRegEx": "Chu and Ghahramani.", "year": 2005}, {"title": "A \u2018reasonable\u2019 social welfare function", "author": ["A.H. Copeland"], "venue": null, "citeRegEx": "Copeland.,? \\Q1951\\E", "shortCiteRegEx": "Copeland.", "year": 1951}, {"title": "Spearman\u2019s Footrule as a Measure of Disarray", "author": ["P. Diaconis", "R.L. Graham"], "venue": "Journal of the Royal Statistical Society, Series B,", "citeRegEx": "Diaconis and Graham.,? \\Q1977\\E", "shortCiteRegEx": "Diaconis and Graham.", "year": 1977}, {"title": "Concentration of Measure for the Analysis of Randomized Algorithms", "author": ["D.P. Dubhashi", "A. Panconesi"], "venue": null, "citeRegEx": "Dubhashi and Panconesi.,? \\Q2009\\E", "shortCiteRegEx": "Dubhashi and Panconesi.", "year": 2009}, {"title": "The Rating Of Chess Players", "author": ["A. Elo"], "venue": "Past & Present. Arco,", "citeRegEx": "Elo.,? \\Q1978\\E", "shortCiteRegEx": "Elo.", "year": 1978}, {"title": "Minimax-optimal Inference from Partial Rankings", "author": ["B. Hajek", "S. Oh", "J. Xu"], "venue": "In Advances in Neural Information Processing Systems 27,", "citeRegEx": "Hajek et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hajek et al\\.", "year": 2014}, {"title": "Active Ranking from Pairwise Comparisons and when Parametric Assumptions Don\u2019t Help", "author": ["R. Heckel", "N.B. Shah", "K. Ramchandran", "M.J. Wainwright"], "venue": null, "citeRegEx": "Heckel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Heckel et al\\.", "year": 2016}, {"title": "Hern\u00e1ndez-lobato. Collaborative Gaussian Processes for Preference Learning", "author": ["N. Houlsby", "F. Husz\u00e1r", "Z. Ghahramani", "J. M"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Houlsby et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Houlsby et al\\.", "year": 2012}, {"title": "Active Ranking using Pairwise Comparisons", "author": ["K. Jamieson", "R. Nowak"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Jamieson and Nowak.,? \\Q2011\\E", "shortCiteRegEx": "Jamieson and Nowak.", "year": 2011}, {"title": "Efficient Clustering for Orders", "author": ["T. Kamishima", "S. Akaho"], "venue": "In Mining Complex Data,", "citeRegEx": "Kamishima and Akaho.,? \\Q2009\\E", "shortCiteRegEx": "Kamishima and Akaho.", "year": 2009}, {"title": "The art of computer programming: sorting and searching, volume 3. AddisonWesley", "author": ["D.E. Knuth"], "venue": "2nd edition,", "citeRegEx": "Knuth.,? \\Q1998\\E", "shortCiteRegEx": "Knuth.", "year": 1998}, {"title": "On Dominance Relations and the Structure of Animal Societies: III The Condition for a Score Structure", "author": ["H.G. Landau"], "venue": "Bulletin of Mathematical Biophysics,", "citeRegEx": "Landau.,? \\Q1953\\E", "shortCiteRegEx": "Landau.", "year": 1953}, {"title": "Bayesian Methods for Adaptive Models", "author": ["D.J.C. MacKay"], "venue": "PhD thesis, California Institute of Technology,", "citeRegEx": "MacKay.,? \\Q1992\\E", "shortCiteRegEx": "MacKay.", "year": 1992}, {"title": "Iterative Ranking from Pair-wise Comparisons", "author": ["S. Negahban", "S. Oh", "D. Shah"], "venue": "In Advances in Neural Information Processing Systems 25,", "citeRegEx": "Negahban et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Negahban et al\\.", "year": 2012}, {"title": "A Statistical Convergence Perspective of Algorithms for Rank Aggregation from Pairwise Data", "author": ["A. Rajkumar", "S. Agarwal"], "venue": "In Proceedings of ICML 2014, Beijing,", "citeRegEx": "Rajkumar and Agarwal.,? \\Q2014\\E", "shortCiteRegEx": "Rajkumar and Agarwal.", "year": 2014}, {"title": "Wiki Surveys: Open and Quantifiable Social Data Collection", "author": ["M.J. Salganik", "K.E.C. Levy"], "venue": "PLOS ONE,", "citeRegEx": "Salganik and Levy.,? \\Q2015\\E", "shortCiteRegEx": "Salganik and Levy.", "year": 2015}, {"title": "Collaborative Learning of Preference Rankings", "author": ["T. Salimans", "U. Paquet", "T. Graepel"], "venue": "In Proceedings of RecSys\u201912,", "citeRegEx": "Salimans et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Salimans et al\\.", "year": 2012}, {"title": "Active learning for logistic regression: an evaluation", "author": ["A.I. Schein", "L.H. Ungar"], "venue": "Machine Learning,", "citeRegEx": "Schein and Ungar.,? \\Q2007\\E", "shortCiteRegEx": "Schein and Ungar.", "year": 2007}, {"title": "Online Rank Elicitation for Plackett\u2013Luce: A Dueling Bandits Approach", "author": ["B. Sz\u00f6r\u00e9nyi", "R. Busa-Fekete", "A. Paul", "E. H\u00fcllermeier"], "venue": "In Advances in Neural Information Processing Systems 28,", "citeRegEx": "Sz\u00f6r\u00e9nyi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sz\u00f6r\u00e9nyi et al\\.", "year": 2015}, {"title": "A Law of Comparative Judgment", "author": ["L. Thurstone"], "venue": "Psychological Review,", "citeRegEx": "Thurstone.,? \\Q1927\\E", "shortCiteRegEx": "Thurstone.", "year": 1927}, {"title": "Parameter Estimation for Generalized Thurstone Choice Models", "author": ["M. Vojnovic", "S. Yun"], "venue": "In Proceedings of ICML 2016,", "citeRegEx": "Vojnovic and Yun.,? \\Q2016\\E", "shortCiteRegEx": "Vojnovic and Yun.", "year": 2016}, {"title": "Active Collaborative Permutation Learning", "author": ["J. Wang", "N. Srebro", "J. Evans"], "venue": "In Proceedings of KDD\u201914,", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "The k-armed dueling bandits problem", "author": ["Y. Yue", "J. Broder", "R. Kleinberg", "T. Joachims"], "venue": "In Proceedings of COLT", "citeRegEx": "Yue et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yue et al\\.", "year": 2009}, {"title": "Die Berechnung der Turnier-Ergebnisse als ein Maximumproblem der Wahrscheinlichkeitsrechnung", "author": ["E. Zermelo"], "venue": "Mathematische Zeitschrift,", "citeRegEx": "Zermelo.,? \\Q1928\\E", "shortCiteRegEx": "Zermelo.", "year": 1928}], "referenceMentions": [{"referenceID": 12, "context": "The problem of recovering a ranking over n items from noisy outcomes of pairwise comparisons has attracted, in the last century, much research interest, driven by applications in sports [Elo, 1978], social sciences [Thurstone, 1927, Salganik and Levy, 2015] and\u2014more recently\u2014recommender systems [Houlsby et al.", "startOffset": 186, "endOffset": 197}, {"referenceID": 15, "context": "The problem of recovering a ranking over n items from noisy outcomes of pairwise comparisons has attracted, in the last century, much research interest, driven by applications in sports [Elo, 1978], social sciences [Thurstone, 1927, Salganik and Levy, 2015] and\u2014more recently\u2014recommender systems [Houlsby et al., 2012].", "startOffset": 296, "endOffset": 318}, {"referenceID": 4, "context": "If pairs of items are selected at random, it is necessary to collect \u03a9(n) comparisons to recover the ranking [Alon et al., 1994].", "startOffset": 109, "endOffset": 128}, {"referenceID": 25, "context": "However, most strategies are challenging to operate and computationally expensive, thus hindering wider adoption [Schein and Ungar, 2007].", "startOffset": 113, "endOffset": 137}, {"referenceID": 4, "context": "Braverman and Mossel [2008] examine a model where outcomes of pairwise comparisons are flipped with a small, constant probability.", "startOffset": 0, "endOffset": 28}, {"referenceID": 0, "context": "Ailon [2012] considers an adversarial setting (comparison outcomes can be arbitrary) and investigates AL in the context of finding a ranking that minimizes the number of inconsistent outcomes, also known as the minimum feedback-arc set problem on tournaments (MFAST).", "startOffset": 0, "endOffset": 13}, {"referenceID": 0, "context": "Ailon [2012] considers an adversarial setting (comparison outcomes can be arbitrary) and investigates AL in the context of finding a ranking that minimizes the number of inconsistent outcomes, also known as the minimum feedback-arc set problem on tournaments (MFAST). These theoretical studies imply, in their respective settings, that O(n log n) comparison outcomes are enough to recover a near-optimal ranking. Jamieson and Nowak [2011] propose an efficient active-ranking algorithm that is applicable if items can be embedded in R (e.", "startOffset": 0, "endOffset": 439}, {"referenceID": 0, "context": "Ailon [2012] considers an adversarial setting (comparison outcomes can be arbitrary) and investigates AL in the context of finding a ranking that minimizes the number of inconsistent outcomes, also known as the minimum feedback-arc set problem on tournaments (MFAST). These theoretical studies imply, in their respective settings, that O(n log n) comparison outcomes are enough to recover a near-optimal ranking. Jamieson and Nowak [2011] propose an efficient active-ranking algorithm that is applicable if items can be embedded in R (e.g., using d features) and assuming that admissible rankings satisfy some geometric constraints. Wang et al. [2014] study a collaborative preference-learning problem and show that a variant of uncertainty sampling (a well-known AL strategy) works well for their problem.", "startOffset": 0, "endOffset": 652}, {"referenceID": 20, "context": "From a practical standpoint, Bayesian methods provide an effective way to select informative samples [MacKay, 1992].", "startOffset": 101, "endOffset": 115}, {"referenceID": 10, "context": "Work on Bayesian active preference learning includes Chu 2\u2206(\u03c3)/2 \u2264 K(\u03c3) \u2264 \u2206(\u03c3) [Diaconis and Graham, 1977].", "startOffset": 79, "endOffset": 106}, {"referenceID": 14, "context": "and Ghahramani [2005], Houlsby et al. [2012], Salimans et al.", "startOffset": 23, "endOffset": 45}, {"referenceID": 14, "context": "and Ghahramani [2005], Houlsby et al. [2012], Salimans et al. [2012] and Chen et al.", "startOffset": 23, "endOffset": 69}, {"referenceID": 7, "context": "[2012] and Chen et al. [2013]. We compare our AL strategy to these methods in Section 4.", "startOffset": 11, "endOffset": 30}, {"referenceID": 30, "context": "The dueling bandit problem [Yue et al., 2009] is somewhat related to our work.", "startOffset": 27, "endOffset": 45}, {"referenceID": 25, "context": "The work of Sz\u00f6r\u00e9nyi et al. [2015] is the closest to ours, as it also uses the BT model.", "startOffset": 12, "endOffset": 35}, {"referenceID": 14, "context": "Heckel et al. [2016] investigate a non-parametric model and develop some theoretical guarantees.", "startOffset": 0, "endOffset": 21}, {"referenceID": 0, "context": "Quicksort combined with BT comparison outcomes has also been proposed as a probabilistic ranking model [Ailon, 2008].", "startOffset": 103, "endOffset": 116}, {"referenceID": 0, "context": "For example, Ailon et al. [2008] show that Quicksort produces (in expectation) a 3-approximation to the MFAST problem.", "startOffset": 13, "endOffset": 33}, {"referenceID": 0, "context": "Lemma 2 complements Theorem 3 in Ailon and Mohri [2010], which states that Quicksort samples O(n log n) in expectation.", "startOffset": 33, "endOffset": 56}, {"referenceID": 9, "context": "The method assigns, to each item, a score that corresponds to the number of items that it beats in a majority of the rankings, and it then ranks the items by increasing score [Copeland, 1951].", "startOffset": 175, "endOffset": 191}, {"referenceID": 0, "context": "In order to prove (3), we take advantage of a theorem due to Ailon [2008] which states that P [\u03c3(i) < \u03c3(j) | \u03b8] = p(i \u227a j | \u03b8), even if i and j were not directly compared with each other.", "startOffset": 61, "endOffset": 74}, {"referenceID": 0, "context": "In order to prove (3), we take advantage of a theorem due to Ailon [2008] which states that P [\u03c3(i) < \u03c3(j) | \u03b8] = p(i \u227a j | \u03b8), even if i and j were not directly compared with each other. We use a Chernoff bound on dij to show that the relative order between any two items separated by at least O(\u03bb log n) positions is correct with high probability. The second part of the claim follows easily. Note that any method that compares each pair of items at most once results in a ranking estimate \u03c4 with displacement \u2206(\u03c4) = \u03a9(n) with high probability: As there is only a single (possibly inconsistent) comparison outcome between each pair of adjacent items, it is likely that a constant fraction of the items will be ranked incorrectly, resulting in a displacement that grows linearly in n. Hence, our bound on \u2206(\u03c3) shows that Quicksort is order-optimal (in n). In light of Theorem 1, a natural question to ask is as follows. How many comparisons are needed in order to find the correct ranking? Clearly, finding the exact ranking is difficult: in fact, \u03a9(n) comparison outcomes are necessary to discriminate the closest pair of items reliably (see Appendix B). As such, we will focus on finding a ranking that matches the ground truth everywhere, except at a vanishing fraction of the items. Multiple runs of Quicksort likely produce different outputs, because of the noisy comparison outcomes and because the algorithm itself is randomized (the pivot selection is random). By aggregating m independent outputs of Quicksort, is it possible to produce a better ranking estimate? Similarly to Sz\u00f6r\u00e9nyi et al. [2015], we combine the m outputs \u03c31, .", "startOffset": 61, "endOffset": 1610}, {"referenceID": 20, "context": "A principled approach to AL consists of sampling the point that maximizes the expected information gain [MacKay, 1992].", "startOffset": 104, "endOffset": 118}, {"referenceID": 7, "context": "A conceptually similar but slightly different selection strategy is given by Chen et al. [2013]. Letting qij be the marginal distribution of (\u03b8i, \u03b8j), the pair is selected in", "startOffset": 77, "endOffset": 96}, {"referenceID": 18, "context": "In the noiseless setting, Mergesort is known to use on average \u2248 39 % fewer comparisons than Quicksort per run [Knuth, 1998], but it does not benefit from the theoretical guarantees developed in Section 3.", "startOffset": 111, "endOffset": 124}, {"referenceID": 8, "context": "For approximate Bayesian inference, we use a variant of the expectation-propagation algorithm outlined by Chu and Ghahramani [2005]. All experiments are performed on a server with a 12-core Xeon X5670 processor running at 2.", "startOffset": 106, "endOffset": 132}, {"referenceID": 17, "context": "Next, we consider a dataset of Sushi preferences [Kamishima and Akaho, 2009].", "startOffset": 49, "endOffset": 76}, {"referenceID": 23, "context": "With the advent of large-scale crowdsourced ranking surveys, exemplified by GIFGIF and wiki surveys [Salganik and Levy, 2015], there is a clear need for practical AL strategies.", "startOffset": 100, "endOffset": 125}, {"referenceID": 19, "context": "The following proposition is due to Landau [1953].", "startOffset": 36, "endOffset": 50}, {"referenceID": 0, "context": "For the second part, we need a result from Ailon [2008], which characterizes the pairwise marginals of the distribution over rankings induced by Quicksort with comparisons sampled from a BT model.", "startOffset": 43, "endOffset": 56}], "year": 2017, "abstractText": "We address the problem of learning a ranking by using adaptively chosen pairwise comparisons. Our goal is to recover the ranking accurately but to sample the comparisons sparingly. If all comparison outcomes are consistent with the ranking, the optimal solution is to use an efficient sorting algorithm, such as Quicksort. But how do sorting algorithms behave if some comparison outcomes are inconsistent with the ranking? We give favorable guarantees for Quicksort for the popular Bradley\u2013Terry model, under natural assumptions on the parameters. Furthermore, we empirically demonstrate that sorting algorithms lead to a very simple and effective active learning strategy: repeatedly sort the items. This strategy performs as well as state-of-the-art methods (and much better than random sampling) at a minuscule fraction of the computational cost.", "creator": "LaTeX with hyperref package"}}}