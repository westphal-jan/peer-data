{"id": "1503.02009", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Mar-2015", "title": "Towards an intelligent VNS heuristic for the k-labelled spanning forest problem", "abstract": "homopolar In kleemann a al-jazari currently ongoing project, we 1,885 investigate drinker a new kulis possibility incrimination for solving shaddad the k - ucmj labelled spanning forest (roughing kLSF) trabajadores problem by an intelligent Variable Neighbourhood Search (73.67 Int - VNS) metaheuristic. dewa In 65.46 the 140 kLSF tenryu problem egt we rabinow are whirly given an compromise undirected four-masted input graph G maddow and beppe an integer positive value larco k, and shahnaz the aim brisebois is to find hydrobiology a ferg spanning forest euro950 of taglines G having bundespost the j.r minimum venkataramana number thunderbolts of jaha connected retainers components and the 1.544 upper bound k on the 90.73 number of 3-iron labels taida to studbook use. The problem is related fmb to rupununi the linquan minimum re-examination labelling hoja spanning tree (MLST) 37-36 problem, anele whose goal wagenfeld is ernestina to papastathopoulos get the spanning tree tindale of the input graph skinwalkers with becaue the minimum number of vunivalu labels, schisgal and leogang has several applications voluntas in 12-seat the hawksmoor real siamo world, where one aims to saxon ensure xiangxi connectivity christlichen by yaumati means 4,380 of homogeneous k3 connections. bortle The ruma Int - bolometric VNS metaheuristic pyxis that stuff we balai propose bilonick for emulated the itkin kLSF amphiphilic problem 11,200 is 86.13 derived blossomed from sighting the 13.67 promising intelligent gestalt VNS strategy hippies recently spuds proposed pof for the MLST problem, 66-day and integrates maindy the nris basic VNS for uxmal the aeds kLSF problem with other hydrographical complementary approaches from tausug machine u.s.military learning, statistics cheerleaders and dzmitry experimental barnes-jewish algorithmics, ruixiang in order to produce philhealth high - quality 0-for-19 performance roughriders and to timeform completely automate the resulting vester\u00e5len strategy.", "histories": [["v1", "Thu, 5 Mar 2015 14:10:19 GMT  (26kb)", "http://arxiv.org/abs/1503.02009v1", "2 pages, Fifteenth International Conference on Computer Aided Systems Theory (EUROCAST 2015), Las Palmas de Gran Canaria, Spain"]], "COMMENTS": "2 pages, Fifteenth International Conference on Computer Aided Systems Theory (EUROCAST 2015), Las Palmas de Gran Canaria, Spain", "reviews": [], "SUBJECTS": "cs.OH cs.AI", "authors": ["sergio consoli", "jos\\`e", "r\\`es moreno p\\`erez", "nenad mladenovic"], "accepted": false, "id": "1503.02009"}, "pdf": {"name": "1503.02009.pdf", "metadata": {"source": "CRF", "title": "Towards an intelligent VNS heuristic for the k-labelled spanning forest problem", "authors": ["Sergio Consoli", "Jos\u00e9 Andr\u00e9s Moreno P\u00e9rez", "Nenad Mladenovi\u0107"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n50 3.\n02 00\n9v 1\n[ cs\n.O H\n] 5\nM ar\n2 01\n5\nTowards an intelligent VNS heuristic for the\nk-labelled spanning forest problem\nSergio Consoli1, Jose\u0301 Andre\u0301s Moreno Pe\u0301rez2, and Nenad Mladenovic\u03013"}, {"heading": "1 ISTC/STLab, National Research Council (CNR), Catania, Italy", "text": ""}, {"heading": "2 Department of Computing Engineering, Universidad de La Laguna, Tenerife, Spain", "text": ""}, {"heading": "3 School of Computing & Mathematics, Brunel University, London, United Kingdom", "text": "{sergio.consoli@jrc.it,jamoreno@ull.es,nenad.mladenovic@brunel.ac.uk}\nIn a currently ongoing project, we investigate a new possibility for solving the k -labelled spanning forest (kLSF) problem by an intelligent Variable Neighbourhood Search (Int-VNS) metaheuristic. In the kLSF problem we are given an undirected input graph G = (V,E, L) where V is the set of nodes, E the set of edges, that are labelled on the set L of labels, and an integer positive value k\u0304, and the aim is to find a spanning forest G\u2217 = (V,E\u2217, L\u2217) of the input graph having the minimum number of connected components, i.e. min|Comp(G\u2217)|, and the upper bound k\u0304 on the number of labels to use, |L\u2217| \u2264 k\u0304. The problem is related to the minimum labelling spanning tree (MLST) problem [1], whose goal is to get the spanning tree of the input graph with the minimum number of labels, and has several applications in the real-world, where one aims to ensure connectivity by means of homogeneous connections. The kLSF problem was recently introduced in [2] along with the proof of its NP-hardness; therefore any practical solution approach requires heuristics [2, 3]. In particular our aim is to present an intelligent VNS which is aimed to achieve further improvements for the kLSF problem. This approach is derived from the promising strategy recently proposed in [4] for the MLST problem, and integrates the basic VNS for the kLSF problem in [3] with other complementary approaches from machine learning, statistics and experimental algorithmics, in order to produce high-quality performance and to completely automate the resulting strategy.\nThe first extension that we introduce is a local search mechanism that is inserted at top of the basic VNS. The resulting local search method is referred to as Complementary Variable Neighbourhood Search (Co-VNS) [4]. Given a labelled graph G = (V,E, L) with n vertices, m edges, and \u2113 labels, CoVNS replaces iteratively each incumbent solution L\u2217 = (l1, l2, ..., l\u2113), where, \u2200i = 1, . . . , |L|, li = 1 if label i \u2208 L\n\u2217, li = 0 otherwise, with another solution selected from the complementary space of L\u2217, referred to as Cospace, defined as the set of all the labels that are not contained in L\u2217, that is L\u2206L\u2217. The iterative process of extraction of a new solution from the complementary space of the current solution helps to escape the algorithm from possible traps in local minima, since the complementary solution lies in a very different zone of the search space with respect to the incumbent solution. Successively, the basic VNS [3] is applied in order to improve the resulting solution. At the starting point of VNS, it is required to define a suitable neighbourhood structure of size qmax. The simplest and most common choice is a structure in which the neigh-"}, {"heading": "2 Consoli et al.", "text": "bourhoods have increasing cardinality: |N1(\u00b7)| < |N2(\u00b7)| < ... < |Nqmax(\u00b7)|. In order to impose a neighbourhood structure on the solution space S, comprising all possible solutions, we define the distance between any two such solutions L1, L2 \u2208 S, as the Hamming distance: \u03c1(L1, L2) = |L1\u2206L2| = \u2211\u2113 i=1 \u03bbi, where \u03bbi = 1 if label i is included in one of the solutions but not in the other, and 0 otherwise, \u2200i = 1, ..., \u2113. In order to construct the neighbourhood of a solution L\u2217, the algorithm first proceeds with the deletion of labels from L\u2217. In other words, given a solution L\u2217, its qth neighbourhood, Nq(C), consists of all the different sets obtained from L\u2217 by removing q labels, where q \u2190 1, 2, ..., qmax. In order to seek further improvements and to automate on-line the search process, Co-VNS has been modified by including a probability-based local search with a self-tuning parameters setting, resulting in the intelligent VNS metaheuristic that we propose.\nThe probability-based local search is obtained by introducing a probabilistic choice on the next label to be added into incomplete solutions. By allowing worse components to be added to incomplete solutions, this probabilistic constructive heuristic produces a further increase on the diversification of the optimization process. The construction criterion is as follows. The procedure starts from an initial solution and iteratively selects at random a candidate move. If this move leads to a solution having a better objective function value than the current solution, then this move is accepted unconditionally; otherwise the move is accepted with a probability that depends on the deterioration,\u2206, of the objective function value. This construction criterion takes inspiration from Simulated Annealing: the acceptance probability of a worse component into a partial solution is evaluated according to the Boltzmann function exp(\u2212\u2206/T ), where the parameter T , referred to as temperature, controls the dynamics of the function. Initially the value of T is large, so allowing many worse moves to be accepted, and is gradually reduced by the following geometric cooling law: Tj+1 = \u03b1 \u00b7 Tj, where T0 = |BestL| and \u03b1 = 1/|BestL| \u2208 [0, 1], with BestL being the current best solution and |BestL| its number of labels. This cooling schedule does not requires any intervention from the user regarding the setting of its parameters, as it is guided automatically by the best solution BestL. Therefore the whole process is able to react in response to the search algorithm\u2019s behavior and to adapt its setting on-line according to the instance of the problem under evaluation.\nThe achieved optimization strategy seems to be highly promising for the kLSF problem. Ongoing investigation will consist in a statistical comparison of the resulting strategy against the best kLSF algorithms in the literature, in order to quantify and qualify the improvements obtained by the proposed Int-VNS."}], "references": [{"title": "The minimum labelling spanning trees", "author": ["R.S. Chang", "S.J. Leu"], "venue": "Inf Proc Let", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1997}, {"title": "The k-labeled spanning forest problem", "author": ["R. Cerulli", "A. Fink", "M. Gentili", "A. Raiconi"], "venue": "Procedia - Social and Behavioral Sciences", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Variable neighbourhood search for the k-labelled spanning forest problem. ENDM", "author": ["S. Consoli", "J.A. Moreno-P\u00e9rez"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Intelligent variable neighbourhood search for the minimum labelling spanning tree problem", "author": ["S. Consoli", "J.A. Moreno-P\u00e9rez", "N. Mladenovi\u0107"], "venue": "ENDM", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "The problem is related to the minimum labelling spanning tree (MLST) problem [1], whose goal is to get the spanning tree of the input graph with the minimum number of labels, and has several applications in the real-world, where one aims to ensure connectivity by means of homogeneous connections.", "startOffset": 77, "endOffset": 80}, {"referenceID": 1, "context": "The kLSF problem was recently introduced in [2] along with the proof of its NP-hardness; therefore any practical solution approach requires heuristics [2, 3].", "startOffset": 44, "endOffset": 47}, {"referenceID": 1, "context": "The kLSF problem was recently introduced in [2] along with the proof of its NP-hardness; therefore any practical solution approach requires heuristics [2, 3].", "startOffset": 151, "endOffset": 157}, {"referenceID": 2, "context": "The kLSF problem was recently introduced in [2] along with the proof of its NP-hardness; therefore any practical solution approach requires heuristics [2, 3].", "startOffset": 151, "endOffset": 157}, {"referenceID": 3, "context": "This approach is derived from the promising strategy recently proposed in [4] for the MLST problem, and integrates the basic VNS for the kLSF problem in [3] with other complementary approaches from machine learning, statistics and experimental algorithmics, in order to produce high-quality performance and to completely automate the resulting strategy.", "startOffset": 74, "endOffset": 77}, {"referenceID": 2, "context": "This approach is derived from the promising strategy recently proposed in [4] for the MLST problem, and integrates the basic VNS for the kLSF problem in [3] with other complementary approaches from machine learning, statistics and experimental algorithmics, in order to produce high-quality performance and to completely automate the resulting strategy.", "startOffset": 153, "endOffset": 156}, {"referenceID": 3, "context": "The resulting local search method is referred to as Complementary Variable Neighbourhood Search (Co-VNS) [4].", "startOffset": 105, "endOffset": 108}, {"referenceID": 2, "context": "Successively, the basic VNS [3] is applied in order to improve the resulting solution.", "startOffset": 28, "endOffset": 31}, {"referenceID": 0, "context": "Initially the value of T is large, so allowing many worse moves to be accepted, and is gradually reduced by the following geometric cooling law: Tj+1 = \u03b1 \u00b7 Tj, where T0 = |BestL| and \u03b1 = 1/|BestL| \u2208 [0, 1], with BestL being the current best solution and |BestL| its number of labels.", "startOffset": 199, "endOffset": 205}], "year": 2017, "abstractText": null, "creator": "LaTeX with hyperref package"}}}