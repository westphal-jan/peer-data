{"id": "1503.07477", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Mar-2015", "title": "A Survey of Classification Techniques in the Area of Big Data", "abstract": "crossrail Big Data staybridge concern liezi large - tiremakers volume, growing data sets linguist that are purevideo complex ruban and cockling have toolmaking multiple markiewicz autonomous warga sources. lezion Earlier chumbawamba technologies perc were adbullah not sompo able to lamperti handle storage and meents processing of huge 620,000 data bebi thus Big Data vernor concept iwr comes into heathlands existence. mictlan This bagni is a tedious i-85 job noades for strakka users nuisance unstructured professedly data. forklift So, zinc there calimlim should asphyxiating be cso some mechanism which fycc classify unstructured leonian data krishan into organized form which overanalyzed helps user convincingly to busters easily shurik access required marcha data. Classification techniques over marschalk big rigaud transactional pi\u0105tnica database extra-biblical provide required data knbr to the users from large datasets wotan more dreamcatcher simple way. rokkasho There are two main classification techniques, prejudge supervised mi-28 and 72.28 unsupervised. In this evz paper jasna we hinton focused on to petrography study forbert of bouris different supervised classification techniques. gianturco Further .321 this paper shows a advantages and dandies limitations.", "histories": [["v1", "Wed, 25 Mar 2015 17:56:19 GMT  (377kb)", "http://arxiv.org/abs/1503.07477v1", "7 pages, 3 figures, 2 tables in IJAFRC, Vol.1, Issue 11, November 2014, ISSN: 2348-4853"]], "COMMENTS": "7 pages, 3 figures, 2 tables in IJAFRC, Vol.1, Issue 11, November 2014, ISSN: 2348-4853", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["praful koturwar", "sheetal girase", "debajyoti mukhopadhyay"], "accepted": false, "id": "1503.07477"}, "pdf": {"name": "1503.07477.pdf", "metadata": {"source": "CRF", "title": "A Survey of Classification Techniques in the Area of Big Data", "authors": [], "emails": ["prafulkoturwar@gmail.com,", "girase.sheetal@gmail.com,", "debajyoti.mukhopadhyay@gmail.com"], "sections": [{"heading": null, "text": "A Survey of Classification Techniques in the Area of Big\nData. 1PrafulKoturwar, 2SheetalGirase, 3Debajyoti Mukhopadhyay\n1Reseach Scholar, Department of Information Technology\n2Assistance Professor,Department of Information Technology\n3Head, Department of Information Technology\nMaharashtra Institute of Technology Pune 411038, India\nprafulkoturwar@gmail.com, girase.sheetal@gmail.com, debajyoti.mukhopadhyay@gmail.com\nA B S T R A C T\nBig Data concern large-volume, growing data sets that are complex and have multiple autonomous sources. Earlier technologies were not able to handle storage and processing of huge data thus Big Data concept comes into existence. This is a tedious job for users to identify accurate data from huge unstructured data. So, there should be some mechanism which classify unstructured data into organized form which helps user to easily access required data. Classification techniques over big transactional database provide required data to the users from large datasets more simple way. There are two main classification techniques, supervised and unsupervised. In this paper we focused on to study of different supervised classification techniques. Further this paper shows application of each technique and their advantages and limitations.\nIndex Terms: Big Data, Supervised Classification, Decision Tree, Support Vector Machine\nI. INTRODUCTION\nBig Data is unstructured data that exceeds the processing complexity of conventional database systems. The data is too big, moves too fast, or doesn\u2019t fit the rule restricting behavior of our database architectures. This information comes from multiple, distinct, independent sources with complex and evolving relationships in a Big Data which is keep on growing day by day. There are three main challenges in Big Data which are data accessing and arithmetic computing procedures, semantics and domain knowledge for different Big Data applications and the difficulties raised by Big Data volumes, distributed data distribution and by complex and dynamic characteristics. Big data framework is divided into three tiers as shown in figure 1, to handle the above challenges [1].\nTier I which is data accessing and computing focus on data accessing and arithmetic computing procedures. Because large amount of information are stored at different locations which are growing rapidly day by day, hence for computing distributed large-scale of information we have to consider effective computing platform like Hadoop.\nData privacy and domain knowledge is the Tier II which focuses on semantics and domain knowledge for different Big Data applications [9]. In social network, users are linked with each other that shares their knowledge which are represented by user communities, leaders in each group and social influence modelling and so on, therefore for understanding their semantics and application knowledge is important for both low-level data access and for high-level mining algorithm designs.\nTier III which is Big Data mining algorithm focus on difficulties raised by Big Data volumes, distributed data distribution and by complex and dynamic characteristics. There are three stages in Tier III, as shown in Figure 2, (a) Sparse, heterogeneous, uncertain, incomplete and multisource data are pre-processed by data fusion techniques; (b) Complex and dynamic data are mined after pre-processing; (c) The global knowledge obtained by local learning and model fusion is tested and relevant information is feedback to the preprocessing stage [1].\nBig Data is now part of every sector and function of the global economy [7]. Big Data a collection of datasets is so large and complex that is beyond the ability of typical database software tools to capture, store, manage and process the data within a tolerable elapsed time. A typical domain like stock market data are constantly generating a large quantity of information such as bids, buys and puts, in every single seconds [2]. This information impact on different factors such as domestic and international news, government reports and natural disasters and so on, hence it is nearly impossible to have required and appropriate information to user over such a complex and voluminous data so it is crucial that such a data should be classified appropriately and presented to the user for his convenience and ease of access.\nClassification technique is used to solve the above challenges which classify the big data according to the format of the data that must be processed, the type of analysis to be applied, the processing techniques at work, and the data sources for the data that the target system is required to acquire, load, process, analyze and store [4]. Many classification techniques are used based on applications selected. Before actual classification begins, required information is extracted from large amount of data and then classification is\ntechniques as shown in Figure 3, are also known as predictive or directed classification. In this method set of possible class is known in advanced. Unsupervised classification techniques are also known as descriptive or undirected. In this method set of possible class is unknown, after classification we can assign name to that class.\nIn supervised classification Decision Tree (DT) and Support Vector Machine (SVM) are well known classifier and used widely. Decision Tree is a hierarchical model that recursively does the separation of the input space into class regions. It consists of decision nodes and leaves. Learning algorithm for the Decision Tree is greedy, it finds the best attribute to split the data. Repeat this until it cannot be separated any more. The main aim of DT is to find out the smallest tree that would make the data after split as pure as possible. Support Vector Machine is a supervised method that analyzes data and recognizes patterns which is used for classification. Given a training set and the data needs to be classified into two classes, a SVM classifier builds a model that assigns the data into one of the categories. Extraction of huge training set is modelled as a multi-dimensional classification problem with one class for each action and its aim is to assign a class label to a given action or activity.\nRest of this paper is organized as follows: In Section 2 briefly describe the Overview of Classification over Big Data, Section 3 does Comparative study. Conclusion and Future scope is discussed in the last section."}, {"heading": "2. OVERVIEW OF CLASSIFICATION", "text": "Classification is one of the data mining technique that classifies unstructured data into the structured class and groups and it helps to user for knowledge discovery and future plan [3]. Classification provides intelligent decision making. There are two phases in classification, first is learning process phase in which a huge training data sets are supplied and analysis takes place then rules and patterns are created. Then the execution of second phase start that is evaluation or test of data sets and archives the accuracy of a classification patterns. This section briefly describes the supervised classification methods such as Decision Tree and Support Vector Machine."}, {"heading": "2.1 SUPERVISED METHODS", "text": "Problems which involve classification are considered to be instances of a branch of machine learning called as \u201csupervised learning\u201d [5]. In this, the machine is given a \u201ctraining set\u201d of correctly classified instances of data in the first stage, and then the algorithm devised from this \u201clearning\u201d is used for the next stage of prediction. The converse of this is \u201cunsupervised learning\u201d, which involves classifying data into categories based on some similarity of input parameters in the data.\nSupervised Data Mining techniques are appropriate when we have a specific target value, so we can predict about our data [8]. The targets can have two or more possible outcomes, or even be a continuous numeric value. To use these methods, we ideally have a subset of training data (observations and measurement) sets for which this target value is already known. Training data includes both the input and desired results.\nof multiple attributes or features. Each record is tagged with a class label. For some examples the correct results (target) are known and are given in input to the model during the learning process. The construction of a proper training validation and test set is crucial. These methods are usually fast and accurate.\nThe objective of classification is to analyze huge data and to develop an accurate description or model for each organized class using the feature present in the data. We use that training data to build a model of what a typical data set looks like when it has one of the various target values. We then apply that model to data for which that target value is currently unknown. The algorithm identifies the \u201cnew\u201d data points that match the model of each target value. This model is used to classify test data for which the class descriptions are not known."}, {"heading": "1. Decision Tree (DT)", "text": "Decision Tree is ideal to use as the filter to handle the large amount of data. DT is a basic way of classification can have satisfactory efficiency and accuracy of those datasets. Decision Tree algorithm is good at tuning between precision which can be trained very fast and provide sound results on those classification data [2].\nBig Data are now rapidly expanding in all domains with the fast development of networking and increase in the data storage and collection capacity. The instances are divided into a set of discrete valued set of properties, known as various features of the data. For example, classifying a received email as \u201cspam\u201d or \u201cnot spam\u201d could be based on analyzing characteristics of the email such as origin IP address, the number of emails received from the same origin, the subject line, the email address itself, the content of the body of the email, etc. All these features will contribute to a final value which will allow the algorithm to classify the email. It is logical that the more number of examples of spam and non-spam emails the Machine Learning system goes through, the better will be its prediction for the next unknown email.\nDecision Tree learning is reasonably fast and accurate. The approach is to learn on large data sets is to parallelize the process of learning by utilizing Decision Trees. It is straightforward to reduce a Decision Tree to rules. The strategy follow here is to break a large data set into n partitions then learn a DT on each of the n partitions in parallel. A DT become bigger on each of n processors independently. After that they must be combined in such a way that the Decision Tree remains individual tree, for this approach Decision Tree can used Meta-learning. Meta-learning is the process by which learners become aware of and increasingly in control of habits of perception, inquiry, learning, and growth.\nNow other aspect of creating final DT is pruning the tree which removes the nodes that do not provides accuracy in classification results in reduced size tree. Pruning is likely to be very important for large training set which will produce large trees. There are a number of methods to prune a Decision Tree. In C4.5 an approach called pessimistic pruning is quite fast and has been shown to provide trees that perform adequately.\nBig Data challenges are growing day by day, traditional Decision Tree algorithms have multiple limitations. First, building a Decision Tree is a very time consuming when the available dataset is extremely huge.\nalgorithms, the strategy of data distribution should be optimized so that required data for building one node is localized and meanwhile the communication cost is minimized.\nTo overcome these limitations, distributed C4.5 algorithm with MapReduce computing model is used. When available dataset is extremely huge then C4.5 algorithm performs well in short time and it is robust in nature as well as simple to understand [10]."}, {"heading": "2. Support Vector Machine (SVM)", "text": "Machine Learning has ability to enable the computer to learn that uses algorithm and techniques which perform different tasks and activities to provide efficient learning. Our main problem is that how can we represent complex data and how to exclude bogus data. Support Vector Machine is a Machine Learning tool used for classification that is based on Supervised Learning which classifies points to one of two disjoint half-spaces. It uses nonlinear mapping to convert the original data into higher dimension. Its objective is to construct a function which will correctly predict the class to which the new point belongs and the old points belong. In the era of Big Data, the main reason behind maximum margin or separation because if we use a decision boundary to classify, it may end up nearer to one set of datasets compared to others. This happens only if data is structured or linear but mostly we find data is unstructured/nonlinear and dataset is inseparable then SVM kernels are used.\nTraditional Classification approaches perform weakly when working directly because of huge amount of data but Support Vector Machine can avoid the problems of representing this much data. Support Vector Machine is the most promising technique and approach as compared to others classification approaches. Support Vector Machine balance proper and accurate huge amount of data and compromise between classifier complexity and error can be controlled explicitly. Another benefit of SVMs is that one can design and use a SVM kernel for a particular problem that could be applied directly to the data without the need for a feature extraction process. It is particularly important problems, where huge amount of structured data is lost by the feature extraction process.\nSupport Vector Machine (SVM) is the classification technique which used to process on large training data. The Big and complex data can be left to the SVM since the result of SVM will be greatly influenced when there is too much noise in the datasets. SVM provides with an optimized algorithm to solve the problem of over fitting. SVM is an effective classification model is useful to handle those complex data. SVM can make use of certain kernels to reveal efficiently in quantum form the largest eigenvalues and corresponding eigenvectors of the training data overlap (kernel) and covariance matrices [2].\nSVM have high training performance and low generalization error which pointed out the potential problems of SVMs when the training set is noisy and imbalanced. The SVM is not that much scalable on large data sets because it take time for multiple scanning of data sets hence it is too expensive to perform. To overcome this problem, Clustering-Based SVM (CB-SVM) comes into picture for scalability and reliability of SVM classification [6]. Clustering-Based SVM (CB-SVM) is the SVM technique that is designed for handling large data sets which applies on hierarchical micro-clustering algorithm that scans the entire data set only once to provide the high quality of samples. CB-SVM is scalable if and only if the efficiency of training maximizing the performance of SVMs.\nIn this we have done comparative study of Decision Tree and Support Vector Machine, supervised classification techniques, based on predictive accuracy, fitting speed, prediction speed, memory usage and area under curve is shown in Table 1. Further Table 2 shows advantages, limitations and applications of both techniques.\nTable1: Comparison between DT and SVM\nModel DT SVM\nPredictive Accuracy Low High\nFitting Speed Fast Medium\nPrediction Speed Fast *\nMemory Usage Low *\nEasy to Interpret Yes *\nHandles Categorical\nPredictors\nYes No\nArea Under the Curve (AUC) More Less\n* SVM prediction speed and memory usage are good if there are few support vectors, but can be poor if there are many support vectors. When we use a kernel function, it can be difficult to interpret how SVM classifies data; through the default linear scheme is easy to interpret."}, {"heading": "IV. CONCLUSION", "text": "In this report, we saw the different supervised classification techniques on the era of Big Data. Both techniques is better suited than the other for different applications. We also stated a table showing the advantages and disadvantages of the different classification techniques. These techniques can be used to organize all kinds of user needs. Each technique has a different accuracy, speed and predictors. The study indicates that the classification accuracy of SVM algorithm was better than DT algorithm which also gives better classification datasets than DT algorithm.\n[1] Xindong Wu, Xingquan Zhu, Gong-Qing Wu, and Wei Ding, \u201cData Mining with Big Data,\u201d\nTransactions On Knowledge And Data Engineering, Vol. 26, No. 1. 1041-4347/14 January 2014, IEEE.\n[2] Dingxian Wang, Xiao Liu, Mengdi Wang, \u201cA DT-SVM Strategy for Stock Futures Prediction with Big\nData,\u201d16th International Conference on Computational Science and Engineering 978-0-76955096- 1/13, 2013, IEEE\n[3] G. Kesavaraj, Dr. S. Sukumaran, \u201cA Study on Classification Techniques in Data Mining,\u201d 4th ICCCNT\n\u2013 Tiruchengode, India, 31661, July 4 - 6, 2013, IEEE.\n[4] Shan Suthaharan, \u201cBig Data Classification: Problems and Challenges in Network Intrusion\nPrediction with Machine Learning,\u201d Department of Computer Science, University of North Carolina at Greensboro, Greensboro, NC 27402, USA, 2012.\n[5] S. B. Kotsiantis, \u201cSupervised machine learning: A review of classification techniques,\u201d Informatica\n31, 249-268, 2007.\n[6] Hwanjo Yu,Jiong Yang, Jiawei Han, \u201cClassifying Large Data Sets Using SVMs with Hierarchical\nClusters,\u201d SIGKDD \u201903 Washington, DC, USA, 1581137370/ 03/0008, 2003, ACM.\n[7] YongjunPiao, Hyun Woo Park, Cheng Hao Jin, Keun Ho Ryu, \u201cEnsemble Method for Classification\nof High-Dimensional Data,\u201d 978-1-4799-3919-0/14, 20 14 , IEEE.\n[8] VitthalYenkar, Prof.MahipBartere, \u201cReview on Data M ining with Big Data,\u201d International Journal\nof Computer Science and Mobile Computing, Vol.3 Iss ue.4, pg. 97-102, April- 2014.\n[9] Mohammed GH. AL Zamil, \u201cThe Application of Semantic Big Data,\u201d - based Classification on\nInternational Conference on Information and Communi cation Systems (ICICS) 978-1-4799-3023 4 /14, 2014, IEEE.\n[10] Wei Dai, Wei Ji, \u201cA MapReduce Implementation of C4. 5 Decision Tree Algorithm,\u201d International\nJournal of Database Theory and Application, SERSC, 2014."}], "references": [{"title": "Data Mining with Big Data", "author": ["Xindong Wu", "Xingquan Zhu", "Gong-Qing Wu", "Wei Ding"], "venue": "Transactions On Knowledge And Data Engineering, Vol. 26, No. 1. 1041-4347/14 January 2014, IEEE.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "A DT-SVM Strategy for Stock Futures Prediction with Big Data,\u201d16th", "author": ["Dingxian Wang", "Xiao Liu", "Mengdi Wang"], "venue": "International Conference on Computational Science and Engineering", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "A Study on Classification Techniques in Data Mining", "author": ["G. Kesavaraj", "Dr. S. Sukumaran"], "venue": "4th ICCCNT \u2013 Tiruchengode, India, 31661, July 4 - 6, 2013, IEEE.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Big Data Classification: Problems and Challenges in Network Intrusion Prediction with Machine Learning", "author": ["Shan Suthaharan"], "venue": "Department of Computer Science, University of North Carolina at Greensboro, Greensboro, NC 27402, USA, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Supervised machine learning: A review of classification techniques", "author": ["S.B. Kotsiantis"], "venue": "Informatica 31, 249-268, 2007.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Classifying Large Data Sets Using SVMs with Hierarchical Clusters", "author": ["Hwanjo Yu", "Jiong Yang", "Jiawei Han"], "venue": "SIGKDD \u201903 Washington, DC, USA, 1581137370/ 03/0008, 2003, ACM.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Ensemble Method for Classification of High-Dimensional Data", "author": ["YongjunPiao", "Hyun Woo Park", "Cheng Hao Jin", "Keun Ho Ryu"], "venue": "978-1-4799-3919-0/14, 20  14 , IEEE.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 0}, {"title": "Review on Data M ining with Big Data", "author": ["VitthalYenkar", "Prof.MahipBartere"], "venue": "International Journal of Computer Science and Mobile Computing, Vol.3 Iss ue.4, pg. 97-102, April- 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "The Application of Semantic  Big Data", "author": ["Mohammed GH. AL Zamil"], "venue": " - based Classification on International Conference on Information and Communi cation Systems (ICICS) 978-1-4799-3023 4 /14, 2014, IEEE.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "A MapReduce Implementation of C4. 5 Decision Tree Algorithm", "author": ["Wei Dai", "Wei Ji"], "venue": "International Journal of Database Theory and Application, SERSC, 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Big data framework is divided into three tiers as shown in figure 1, to handle the above challenges [1].", "startOffset": 100, "endOffset": 103}, {"referenceID": 8, "context": "Data privacy and domain knowledge is the Tier II which focuses on semantics and domain knowledge for different Big Data applications [9].", "startOffset": 133, "endOffset": 136}, {"referenceID": 0, "context": "There are three stages in Tier III, as shown in Figure 2, (a) Sparse, heterogeneous, uncertain, incomplete and multisource data are pre-processed by data fusion techniques; (b) Complex and dynamic data are mined after pre-processing; (c) The global knowledge obtained by local learning and model fusion is tested and relevant information is feedback to the preprocessing stage [1].", "startOffset": 377, "endOffset": 380}, {"referenceID": 6, "context": "Big Data is now part of every sector and function of the global economy [7].", "startOffset": 72, "endOffset": 75}, {"referenceID": 1, "context": "A typical domain like stock market data are constantly generating a large quantity of information such as bids, buys and puts, in every single seconds [2].", "startOffset": 151, "endOffset": 154}, {"referenceID": 3, "context": "Classification technique is used to solve the above challenges which classify the big data according to the format of the data that must be processed, the type of analysis to be applied, the processing techniques at work, and the data sources for the data that the target system is required to acquire, load, process, analyze and store [4].", "startOffset": 336, "endOffset": 339}, {"referenceID": 2, "context": "Classification is one of the data mining technique that classifies unstructured data into the structured class and groups and it helps to user for knowledge discovery and future plan [3].", "startOffset": 183, "endOffset": 186}, {"referenceID": 4, "context": "Problems which involve classification are considered to be instances of a branch of machine learning called as \u201csupervised learning\u201d [5].", "startOffset": 133, "endOffset": 136}, {"referenceID": 7, "context": "Supervised Data Mining techniques are appropriate when we have a specific target value, so we can predict about our data [8].", "startOffset": 121, "endOffset": 124}, {"referenceID": 1, "context": "Decision Tree algorithm is good at tuning between precision which can be trained very fast and provide sound results on those classification data [2].", "startOffset": 146, "endOffset": 149}, {"referenceID": 9, "context": "5 algorithm performs well in short time and it is robust in nature as well as simple to understand [10].", "startOffset": 99, "endOffset": 103}, {"referenceID": 1, "context": "SVM can make use of certain kernels to reveal efficiently in quantum form the largest eigenvalues and corresponding eigenvectors of the training data overlap (kernel) and covariance matrices [2].", "startOffset": 191, "endOffset": 194}, {"referenceID": 5, "context": "To overcome this problem, Clustering-Based SVM (CB-SVM) comes into picture for scalability and reliability of SVM classification [6].", "startOffset": 129, "endOffset": 132}], "year": 2015, "abstractText": "Big Data concern large-volume, growing data sets that are complex and have multiple autonomous sources. Earlier technologies were not able to handle storage and processing of huge data thus Big Data concept comes into existence. This is a tedious job for users to identify accurate data from huge unstructured data. So, there should be some mechanism which classify unstructured data into organized form which helps user to easily access required data. Classification techniques over big transactional database provide required data to the users from large datasets more simple way. There are two main classification techniques, supervised and unsupervised. In this paper we focused on to study of different supervised classification techniques. Further this paper shows application of each technique and their advantages and limitations.", "creator": "Microsoft\u00ae Word 2013"}}}