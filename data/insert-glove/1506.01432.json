{"id": "1506.01432", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2015", "title": "Encoding Markov Logic Networks in Possibilistic Logic", "abstract": "thunor Markov logic uses weighted hukam formulas to kuranyi compactly somersby encode gunthardt a probability distribution over possible cussac worlds. Despite market-based the colombiana use p-36 of logical wallace formulas, Markov aklan logic networks (rhinoceroses MLNs) can be difficult to fireplug interpret, renationalisation due trevi to the schelde often tamp counter - mi-5 intuitive stresa meaning of re8 their mykelti weights. 6:42 To address this issue, meadowlark we propose a method to bond construct a aristeion possibilistic merkezi logic neuroses theory triplanes that exactly delinking captures what can fumarole be skamlova derived from malakpet a 1,468 given MLN using maximum castmate a opbf posteriori (450-megahertz MAP) inference. Unfortunately, treader the size of this built-in theory is 25.3 exponential 31-11 in prenzlau general. We kamijo therefore smedes also propose anthonius two methods godfrain which renaldo can 3rd-4th derive surfperch compact pimas theories that habit still katumbi capture MAP inference, quigley but ocho only for shoemaker specific rivest types of miyun evidence. These signing theories '69 can mdd be paterna used, valerian among ejf others, masjed to make dunkin explicit the pavlysh hidden petroluem assumptions 1842 underlying p7 an charming MLN ducktales or to qalinle explain the predictions it bulvar makes.", "histories": [["v1", "Wed, 3 Jun 2015 23:20:28 GMT  (26kb)", "https://arxiv.org/abs/1506.01432v1", null], ["v2", "Mon, 8 Jun 2015 19:58:03 GMT  (27kb)", "http://arxiv.org/abs/1506.01432v2", "Extended version of a paper appearing in UAI 2015"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ondrej kuzelka", "jesse davis", "steven schockaert"], "accepted": false, "id": "1506.01432"}, "pdf": {"name": "1506.01432.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n50 6.\n01 43\n2v 2\n[ cs\n.A I]\n8 J\nun 2\nMarkov logic uses weighted formulas to compactly encode a probability distribution over possible worlds. Despite the use of logical formulas, Markov logic networks (MLNs) can be difficult to interpret, due to the often counter-intuitive meaning of their weights. To address this issue, we propose a method to construct a possibilistic logic theory that exactly captures what can be derived from a given MLN using maximum a posteriori (MAP) inference. Unfortunately, the size of this theory is exponential in general. We therefore also propose two methods which can derive compact theories that still capture MAP inference, but only for specific types of evidence. These theories can be used, among others, to make explicit the hidden assumptions underlying an MLN or to explain the predictions it makes."}, {"heading": "1 INTRODUCTION", "text": "Markov logic [22] and possibilistic logic [9] are two popular logics for modelling uncertain beliefs. Both logics share a number of important characteristics. At the syntactic level, formulas correspond to pairs (\u03b1, \u03bb), consisting of a classical formula \u03b1 and a certainty weight \u03bb, while at the semantic level, sets of these formulas induce a mapping from possible worlds to [0, 1], encoding the relative plausibility of each possible world.\nDespite their close similarities, however, Markov logic and possibilistic logic have been developed in different communities and for different purposes: Markov logic has mainly been studied in a machine learning context whereas possibilistic logic has been studied as a knowledge representation language. This reflects the complementary strengths and weaknesses of these logics. On the one hand, the qualitative nature of possibilistic logic makes it challenging to use for learning; although a few interesting approaches for\nlearning possibilistic logic theories from data have been explored (e.g. [24]), their impact on applications to date has been limited. On the other hand, the intuitive meaning of Markov logic theories is often difficult to grasp, which limits the potential of Markov logic for knowledge representation. The main culprit is that the meaning of a theory can often not be understood by looking at the individual formulas in isolation. This issue, among others, has been highlighted in [26], where coherence measures are proposed that evaluate to what extent the formulation of a Markov logic theory is misleading.\nExample 1. Consider the following Markov logic formulas:\n+\u221e : antarctic-bird(X) \u2192 bird(X)\n10 : bird(X) \u2192 flies(X)\n5 : antarctic-bird(X) \u2192 \u00acflies(X)\nWhile the last formula might appear to suggest that antarctic birds cannot fly, in combination with the other two formulas, it merely states that antarctic birds are less likely to fly than birds in general.\nPossibilistic logic is based on a purely qualitative, comparative model of uncertainty: while a Markov logic theory compactly encodes a probability distribution over the set of possible worlds, a possibilistic logic theory merely encodes a ranking of these possible worlds. Even though a probability distribution offers a much richer uncertainty model, many applications of Markov logic are based on MAP inference, which only relies on the ranking induced by the probability distribution.\nIn this paper, we first show how to construct a possibilistic logic theory \u0398, given a Markov logic theory M, such that the conclusions that we can infer from \u0398 are exactly those conclusions that we can obtain from M using MAP inference. Our construction can be seen as the syntactic counterpart of the probability-possibility transformation from [10]. In principle, it allows us to combine the best of both worlds, using M for making predictions while using \u0398 for elucidating the knowledge that is captured by M (e.g. to verify\nthat the theory M is sensible). However, the size of \u0398 can be exponential in the size of M, which is unsurprising given that the computational complexity of MAP inference is higher than the complexity of inference in possibilistic logic. To overcome this problem, we begin by studying ground (i.e. propositional) theories and propose two novel approaches for transforming a ground MLN into a compact ground possibilistic logic theory that still correctly captures MAP inference, but only for specific types of evidence (e.g. sets of at most k literals). Then we lift one of these approaches such that it can transform a first-order MLN into a first-order possibilistic logic theory. Finally, we present several examples that illustrate how the transformation process can be used to help identify unintended consequences of a given MLN, and more generally, to better understand its behaviour.\nThe remainder of the paper is structured as follows. In the next section, we provide some background on Markov logic and possibilistic logic. In Section 3, we analyse the relation between MAP inference in ground Markov logic networks and possibilistic logic inference, introducing in particular two methods for deriving compact theories. Section 4 then discusses how we can exploit the symmetries in the case of an ungrounded Markov logic network, while Section 5 provides some illustrative examples. Finally, we provide an overview of related work in Section 6.\nDue to space limitations, some of the proofs have been omitted from this paper. These proofs can be found in an online appendix.1"}, {"heading": "2 BACKGROUND", "text": ""}, {"heading": "2.1 MARKOV LOGIC", "text": "A Markov logic network (MLN) [22] is a set of pairs (F,wF ), whereF is a formula in first-order logic and wF is a real number, intuitively reflecting a penalty that is applied to possible worlds (i.e. logical interpretations) that violate F . In examples, we will also use the notation wF : F to denote the formula (F,wF ). An MLN serves as a template for constructing a propositional Markov network. In particular, given a set of constants C, an MLN M induces the following probability distribution on possible worlds \u03c9:\npM(\u03c9) = 1\nZ exp\n  \u2211\n(F,wF )\u2208M\nwFnF (\u03c9)\n  , (1)\nwhere nF (x) is the number of true groundings of F in the possible world \u03c9, and Z is a normalization constant to ensure that pM can be interpreted as a probability distribution. Sometimes, formulas (F,wF ) are considered where wF = +\u221e, to represent hard constraints. In such cases,\n1http://arxiv.org/abs/1506.01432\nwe define pM(\u03c9) = 0 for all possible worlds that do not satisfy all of the hard constraints, and only formulas with a real-valued weight are considered in (1) for the possible worlds that do. Note that a Markov logic network can be seen as a weighted set of propositional formulas, which are obtained by grounding the formulas in M w.r.t. the set of constants C in the usual way. In the particular case that all formulas in M are already grounded, M corresponds to a theory in penalty logic [13].\nOne common inference task in MLNs is full MAP inference. In this setting, given a set of ground literals (the evidence) the goal is to compute the most probable configuration of all unobserved variables (the queries). Two standard approaches for performing MAP inference in MLNs are to employ a strategy based on MaxWalkSAT [22] or to use a cutting plane based strategy [23, 18]. Given a set of ground formulas E, we write max(M, E) for the set of most probable worlds of the MLN that satisfy E. For each \u03c9 \u2208 max(M, E),\n\u2211 (F,wF )\u2208M\nwFnF (\u03c9) evaluates to the same value, which we will refer to as sat(M, E). We define the penalty pen(M, E) of E as follows:\npen(M, E) = sat(M, \u2205)\u2212 sat(M, E)\nWe will sometimes identify possible worlds with the set of literals they make true, writing pen(M, \u03c9). We will also write pen(M, \u03b1), with \u03b1 a ground formula, as a shorthand for pen(M, {\u03b1}). We will consider the following inference relation, which has been considered among others in [13]:\n(M, E) \u22a2MAP \u03b1 iff \u2200\u03c9 \u2208 max(M, E) : \u03c9 |= \u03b1 (2)\nwith M an MLN, \u03b1 a ground formula andE a set of ground formulas. It can be shown that checking (M, E) \u22a2MAP \u03b1 for a ground network M is \u2206P2 -complete 2 [4]."}, {"heading": "2.2 POSSIBILISTIC LOGIC", "text": "A possibility distribution in a universe \u2126 is a mapping \u03c0 from \u2126 to [0, 1], encoding our knowledge about the possible values that a given variable X can take; throughout this paper, we will assume that all universes are finite. For each x \u2208 \u2126, \u03c0(x) is called the possibility degree of x. By convention, in a state of complete ignorance, we have \u03c0(x) = 1 for all x \u2208 \u2126; conversely, if X = x0 is known, we have \u03c0(x0) = 1 and \u03c0(x) = 0 for x 6= x0. Possibility theory [27, 12] is based on the possibility measure \u03a0 and dual necessity measure N , induced by a possibility distribution \u03c0 as follows (A \u2286 \u2126):\n\u03a0(A) = max a\u2208A \u03c0(a)\nN(A) = 1\u2212\u03a0(\u2126 \\A)\n2The complexity class \u2206P2 contains those decision problems that can be solved in polynomial time on a deterministic Turing machine with access to an NP oracle.\nIntuitively, \u03a0(A) is the degree to which available evidence is compatible with the view that X belongs to A, whereas N(A) is the degree to which available evidence implies that X belongs to A, i.e. the degree to which it is certain that X belongs to A.\nA theory in possibilistic logic [9] is a set of formulas of the form (\u03b1, \u03bb), where \u03b1 is a propositional formula and \u03bb \u2208 [0, 1] is a certainty weight. A possibility distribution \u03c0 satisfies (\u03b1, \u03bb) iff N(J\u03b1K) \u2265 \u03bb, with N the necessity measure induced by \u03c0 and J\u03b1K the set of propositional models of \u03b1. We say that a possibilistic logic theory \u0398 entails (\u03b1, \u03bb), written \u0398 |= (\u03b1, \u03bb), if every possibility distribution which satisfies all the formulas in \u0398 also satisfies (\u03b1, \u03bb). A possibility distribution \u03c01 is called less specific than a possibility distribution \u03c02 if \u03c01(\u03c9) \u2265 \u03c02(\u03c9) for every \u03c9. It can be shown that the set of models of \u0398 always has a least element w.r.t. the minimal specificity ordering, which is called the least specific model \u03c0\u2217 of \u0398. It is easy to see that \u0398 |= (\u03b1, \u03bb) iff \u03c0\u2217 satisfies (\u03b1, \u03bb).\nEven though the semantics of possibilistic logic is defined at the propositional level, we will also use first-order formulas such as (p(X) \u2192 q(X,Y ), \u03bb) throughout the paper. As in Markov logic, we will interpret these formulas as abbreviations for a set of propositional formulas, obtained using grounding in the usual way. In particular, we will always assume that first-order formulas are defined w.r.t. a finite set of constants.\nThe \u03bb-cut \u0398\u03bb of a possibilistic logic theory \u0398 is defined as follows:\n\u0398\u03bb = {\u03b1 | (\u03b1, \u00b5) \u2208 \u0398, \u00b5 \u2265 \u03bb}\nIt can be shown that \u0398 |= (\u03b1, \u03bb) iff \u0398\u03bb |= \u03b1, which means that inference in possibilistic logic can straightforwardly be implemented using a SAT solver.\nAn inconsistency-tolerant inference relation \u22a2poss for possibilistic logic can be defined as follows:\n\u0398 \u22a2poss \u03b1 iff \u0398con(\u0398) |= \u03b1\nwhere the consistency level con(\u0398) of \u0398 is the lowest certainty level \u03bb for which \u0398\u03bb is satisfiable (among the certainty levels that occur in \u0398). Note that all formulas with a certainty level below con(\u0398) are ignored, even if they are unrelated to any inconsistency in \u0398. This observation is known as the drowning effect.\nWe will write (\u0398, E) \u22a2poss \u03b1, with E a set of propositional formulas, as an abbreviation for \u0398\u222a {(e, 1) | e \u2208 E} \u22a2poss \u03b1. Despite its conceptual simplicity, \u22a2poss has many desirable properties. Among others, it is closely related to AGM belief revision [8] and default reasoning [2]. It can be shown that checking \u0398 \u22a2poss (\u03b1, \u03bb) is a \u0398P2 complete problem3 [17]. In this paper, \u22a2poss will allow us to capture the non-monotonicity of MAP inference.\n3The complexity class \u0398P2 contains those decision problems\nExample 2. Let \u0398 consist of the following formulas:\n(penguin(X) \u2192 bird(X), 1)\n(penguin(X) \u2192 \u00acflies(X), 1)\n(bird(X) \u2192 flies(X), 0.5)\nThen we find:\n(\u0398, {bird(tweety)}) \u22a2poss flies(tweety)\n(\u0398, {bird(tweety), penguin(tweety)}) \u22a2poss \u00acflies(tweety)\nIn general, \u22a2poss allows us to model rules with exceptions, by ensuring that rules about specific contexts have a higher certainty weight than rules about general contexts."}, {"heading": "3 ENCODING GROUND NETWORKS", "text": "Throughout this section, we will assume thatM is a ground MLN in which all the weights are strictly positive. This can always be guaranteed for ground MLNs by replacing formulas (\u03b1, \u03bb) with \u03bb < 0 by (\u00ac\u03b1,\u2212\u03bb), and by discarding any formula whose weight is 0. For a subset X \u2286 M, we write X\u2217 for the set of corresponding classical formulas, e.g. for X = {(F1, w1), ..., (Fn, wn)} we have X\u2217 = {F1, ..., Fn}. In particular, M\u2217 are the classical formulas appearing in the MLN M.\nThe following transformation constructs a possibilistic logic theory that is in some sense equivalent to a given MLN. It is inspired by the probability-possiblity transformation from [10].\nTransformation 1. We define the possibilistic logic theory \u0398M corresponding to an MLN M as follows:\n{( \u2228 X\u2217, \u03c6(\u00ac \u2228 X\u2217)) |X \u2286 M, \u03c6(\u00ac \u2228 X\u2217) > 0} (3)\nwhere for a propositional formula \u03b1:\n\u03c6(\u03b1) =\n{ K+pen(M,\u03b1)\nL if \u03b1 satisfies the hard constraints\n1 otherwise\nand the constants K and L are chosen such that 0 = \u03c6(\u22a4) \u2264 \u03c6(\u03b1) < 1 for every \u03b1 that satisfies the hard constraints (i.e. the formulas with weight +\u221e).\nIn the following we will use the notations \u03c6(\u03c9) for a possible world \u03c9 and \u03c6(E) for a set of formulas E, defined entirely analogously. Throughout the paper we will also write (\u2212K < x < L\u2212K):\n\u03bbx = K + x\nL\nThe correctness of Transformation 1 follows from the next proposition, which is easy to show.\nthat can be solved in polynomial time on a deterministic Turing machine, by making at most a logaritmic number of calls to an NP oracle.\nProposition 1. Let M be a ground MLN and \u0398M the corresponding possibilistic logic theory. Let \u03c0 be the least specific model of \u0398M. It holds that:\n\u03c0(\u03c9) = 1\u2212 \u03c6(\u03c9)\nCorollary 1. Let M be a ground MLN and \u0398M the corresponding possibilistic logic theory. It holds that for \u03bb < 1:\n\u0398M |= (\u03b1, \u03bb) iff pen(M,\u00ac\u03b1) \u2265 \u03bbL\u2212K\nand\n\u0398M |= (\u03b1, 1) iff pen(M,\u00ac\u03b1) = +\u221e\nCorollary 2. Let M be a ground MLN and \u0398M the corresponding possibilistic logic theory. For pM the probability distribution induced by M and \u03c0 the least specific model of \u0398M, it holds that\npM(\u03c91) > pM(\u03c92) iff \u03c0(\u03c91) > \u03c0(\u03c92)\nfor all possible worlds \u03c91 and \u03c92. In particular, it follows that for every propositional formula \u03b1 and every set of propositional formulas E:\n(M, E) \u22a2MAP \u03b1 iff (\u0398, E) \u22a2poss \u03b1 (4)\nExample 3. Consider the MLN M containing the following formulas:\n5 : a \u2192 x 5 : a \u2192 y 10 : a \u2227 b \u2192 \u00acy\nThen \u0398M contains the following formulas:\n\u03bb5 : a \u2192 x \u03bb5 : a \u2192 y\n\u03bb10 : a \u2227 b \u2192 \u00acy \u03bb10 : a \u2192 x \u2228 y\n\u03bb15 : a \u2227 b \u2192 x \u2228 \u00acy\nIt can be verified that:\n(\u0398M, {a}) \u22a2poss x \u2227 y (\u0398M, {a, b}) \u22a2poss x \u2227 \u00acy\nAn important drawback of the transformation to possibilistic logic is that the number of formulas in \u0398M is exponential in |M|. This makes the transformation inefficient, and moreover limits the interpretability of the possibilistic logic theory. In general, the exponential size of \u0398M cannot be avoided if we want (4) to hold for any E and \u03b1. However, more compact theories can be found if we focus on specific types of evidence. Sections 3.1 and 3.2 introduce two practical methods to accomplish this."}, {"heading": "3.1 SELECTIVELY AVOIDING DROWNING", "text": "In many applications, we are only interested in particular types of evidence sets E. For example, we may only\nbe interested in evidence sets that contain at most k literals, or in evidence sets that only contain positive literals. In such cases, we can often derive a more compact possibilistic logic theory \u0398E as follows. Let E be the set of evidence sets that we wish to consider, where each E \u2208 E is a set of ground formulas. Given E \u2208 E we write SE for the set of all minimal subsets {F1, ..., Fl} of M\u2217E = {F |F \u2208 M \u2217, pen(M,\u00acF ) < pen(M, E)} s.t.\npen(M, \u2227\nE \u2227 \u00acF1 \u2227 ... \u2227 \u00acFl) > pen(M, E) (5)\nThe following transformation constructs a possibilistic logic theory that correctly captures MAP inference for evidence sets in E . The basic intuition is that we want to weaken the formulas in M\u2217 just enough to ensure that the resulting certainty level prevents them from drowning when the evidence E becomes available.\nTransformation 2. Given a ground MLN M and a set of evidence sets E , we define the possibilistic logic theory \u0398EM as follows:\n{(F1, \u03c6(\u00acF1)) |F1 \u2208 M \u2217} (6)\n\u222a {(\u00ac \u2227 E \u2228 \u2228 Z, \u03c6( \u2227 E \u2227 \u00ac \u2227\nZ)) |Z \u2208 SE , (7)\nE \u2208 E} \u222a {(\u00ac \u2227 E, \u03c6( \u2227 E)) |E \u2208 E} (8)\nIf M is clear from the context, we will omit the subscript in \u0398EM. The formulas in (6) are the direct counterpart of the MLN. Intuitively, there are two reasons why these formulas are not sufficient. First, due to the drowning effect, formulas F such that pen(M,\u00acF ) < pen(M, E) will be ignored under the evidenceE. In such cases we should look at minimal ways to weaken these formulas such that the certainty level of the resulting formula is sufficient to avoid drowning under the evidence E. This is accomplished by adding the formulas in (7). Second, as \u0398E contains less information than \u0398M, we need to ensure that the consistency level for \u0398E is never lower than the consistency level for \u0398M, given an evidence set E \u2208 E . To this end, \u0398E includes the formulas in (8). The following example illustrates why these formulas are needed.\nExample 4. Consider the following MLN M:\n3 : u 2 : a 10 : (a \u2228 b) \u2227 (u \u2228 v) \u2192 \u00acx\n2 : b 1 : v\nand let E = {{x}}, i.e. the only evidence set in which we are interested is {x}. It holds that\nSE = {{a, u}, {b, u}, {a, v}, {b, v}} (9)\nand \u0398E = \u0398 \u222a\u03a8 \u222a \u0393, where:\n\u0398 = {(u, \u03bb3), (a, \u03bb2), ((a \u2228 b) \u2227 (u \u2228 v) \u2192 \u00acx, \u03bb10),\n(b, \u03bb2), (v, \u03bb1)}\n\u03a8 = {(a \u2228 u \u2228 \u00acx, \u03bb6), (b \u2228 u \u2228 \u00acx, \u03bb6),\n(a \u2228 v \u2228 \u00acx, \u03bb5), (b \u2228 v \u2228 \u00acx, \u03bb5)\n\u0393 = {(\u00acx, \u03bb4)}\nIt is easy to verify that (\u0398 \u222a \u03a8, {x}) \u22a2poss u whereas (M, {x}) 6\u22a2MAP u and (\u0398 \u222a\u03a8 \u222a \u0393, {x}) 6\u22a2poss u.\nWe now prove the correctness of Transformation 2.\nProposition 2. For any formula \u03b1 and any evidence set E \u2208 E , it holds that (\u0398M, E) \u22a2poss \u03b1 iff (\u0398E , E) \u22a2poss \u03b1.\nProof. Let us introduce the following notation:\n\u03bbE = con(\u0398M \u222a {(e, 1) | e \u2208 E})\n\u03bbEE = con(\u0398 E \u222a {(e, 1) | e \u2208 E})\nA = (\u0398M \u222a {(e, 1) | e \u2208 E})\u03bbE\nAE = (\u0398E \u222a {(e, 1) | e \u2208 E})\u03bbE E\nWe need to show that A is equivalent to AE , for anyE \u2208 E .\nBy Corollary 1, we know that every formula (\u03b1, \u03bb) in \u0398EM is entailed by \u0398M, hence \u03bb E E \u2264 \u03bbE . Since \u03bbE is the smallest certainty level from \u0398M which is strictly higher than \u03c6(E), it follows that AE contains every formula which appears in \u0398E with a weight that is strictly higher than \u03c6(E). Moreover, since \u0398E by construction contains (\u00ac \u2227 E, \u03c6( \u2227 E)), we find that AE can only contain such formulas:\nAE = E \u222a {\u03b1 | (\u03b1, \u03bb) \u2208 \u0398E , \u03bb > \u03c6(E)} (10)\nIt follows that A |= AE .\nLet G1 \u2228 ... \u2228 Gs be a formula from A. From Corollary 1 we know that:\npen(M,\u00acG1 \u2227 ... \u2227 \u00acGs) > pen(M, E)\nand a fortiori\npen(M, E \u2227 \u00acG1 \u2227 ... \u2227 \u00acGs) > pen(M, E)\nThis means that for any formula G1 \u2228 ... \u2228Gs in A, either pen(M,\u00acGi) > pen(M, E) for some i or SE contains a subset {H1, ..., Hr} of {G1, ..., Gs}. Then \u0398E contains either Gi or the formula \u00acE \u2228 H1... \u2228 Hr with a weight which is strictly higher than \u03c6(E) and thus either Gi or \u00acE \u2228 H1... \u2228 Hr belongs to AE . In both cases we find AE |= G1 \u2228 ... \u2228Gs. We conclude AE |= A.\nAn alternative, which would make the approach in this section closer to the standard encoding in (1), is to define S \u2032E as the set of minimal subsets {F1, ..., Fl} of M\u2217E such that\npen(M,\u00acF1 \u2227 ... \u2227 \u00acFl) > pen(M, E) (11)\nand then replace the formulas in (7) by\n{( \u2228 Z, \u03c6(\u00ac \u2227\nZ)) |Z \u2208 S \u2032E} (12)\nThe advantage of (7), however, is that we can expect many of the sets in SE to be singletons. To see why this is\nthe case, first note that for each world \u03c9 in max(M, E), the set of formulas Y \u2286 M\u2217 satisfied by \u03c9 is such that pen(M,\u00ac \u2228 (M\u2217 \\ Y)) is minimal among all sets Y \u2032 \u2286 M\u2217 for which E \u2227 \u2227 Y \u2032 is consistent. Let us write ConsE(M) for the set of all these maximally consistent subsets of M\u2217. Note that max(M, E) = J \u2228 { \u2227 Y |Y \u2208 ConsE(M)}K.\nLemma 1. For a set of formulas {F1, ..., Fl} \u2286 M\u2217 it holds that pen(M, E \u2227 \u00acF1 \u2227 ... \u2227 \u00acFl) > pen(M, E) iff {F1, ..., Fl} \u2229 Y 6= \u2205 for every Y in ConsE(M).\nCorollary 3. Let ConsE(M) = {Y1, ...,Ys}. It holds that SE consists of the subset-minimal elements of {{y1, ..., ys} | y1 \u2208 Y1 \u2229M\u2217E , ..., ys \u2208 Ys \u2229M \u2217 E}.\nExample 5. Consider again the MLN M from Example 4 and let E = {x}. It holds that ConsE(M) = {Y1,Y2}, where\nY1 = {(a \u2228 b) \u2227 (u \u2228 v) \u2192 \u00acx, a, b}\nY2 = {(a \u2228 b) \u2227 (u \u2228 v) \u2192 \u00acx, u, v}\nM\u2217E = {a, b, u, v}\nFrom Corollary 3,it follows that SE is given by (9).\nIn practice, ConsE(M) will often contain a single element, in which case all the elements of SE will be singletons."}, {"heading": "3.2 MAP INFERENCE AS DEFAULT REASONING", "text": "A large number of approaches has been proposed for reasoning with a set of default rules of the form \u201cif \u03b1 then typically \u03b2\u201d [15, 19, 14]. At the core, each of the proposed semantics corresponds to the intuition that a set of default rules imposes a preference order on possible worlds, where \u201cif \u03b1 then \u03b2\u201d means that \u03b2 is true in the most preferred models of \u03b1. The approaches from [15] and [19] can be elegantly captured in possibilistic logic [2], by interpreting the default rule as the constraint \u03a0(\u03b1\u2227\u03b2) > \u03a0(\u03b1\u2227\u00ac\u03b2). In Markov logic, the same constraint on the ordering of possible worlds can be expressed by imposing the constraint (M, \u03b1) \u22a2MAP \u03b2. In other words, we can view the MAP consequences of an MLN as a set of default rules, and encode these default rules in possibilistic logic. The following transformation is based on this idea.\nTransformation 3. Given a ground MLN M and a positive integer k, we construct a possibilistic logic theory \u0398kM as follows:\n\u2022 For each hard rule F from M, add (F, 1) to \u0398kM.\n\u2022 For each set of literals E such that 0 \u2264 |E| \u2264 k, let X = {x | (M, E) \u22a2MAP x} be the set of literals that are true in all the most plausible models of E. Unless there is a literal y \u2208 E such that \u2227 (E \\ {y}) \u22a2MAP y,\nadd (\u2227 E \u2192 \u2227 X,\u03bbE )\nto \u0398kM, where \u03bbE = \u03c6( \u2227\nE). If pen(M, E) > pen(M, \u2205), add also\n(\u00ac( \u2227 E \u2227 \u2227\nX), \u03bb\u2032E) (13)\nwhere \u03bb\u2032E is the certainty level just below \u03bbE in \u0398 k M, i.e. \u03bbE\u2032 = max{\u03bbF |\u03bbF < \u03bbE , |F | \u2264 k}.\nIf M is clear from the context, we will omit the subscript in \u0398kM. The possibilistic encoding of default rules used in Transformation 3 is similar in spirit to the method from [2], which is based on the Z-ranking from [19]. However, because pM already provides us with a model of the default rules, we can directly encode default rules in possibilistic logic, without having to rely on the Z-ranking. Also note that although the method is described in terms of an MLN, it can be used for encoding any ranking on possible worlds (assuming a finite set of atoms).\nAs illustrated in the following example, (13) is needed to avoid deriving too much, serving a similar purpose to (8) in the approach from Section 3.1.\nExample 6. Consider the following MLN M:\n2 : \u00aca \u2228 b 2 : a \u2228 b 1 : a \u2228 \u00acb\nThen \u03981 = \u0398 \u222a\u03a8, where\n\u0398 = {(\u22a4 \u2192 a \u2227 b, \u03bb0), (\u00aca \u2192 b, \u03bb1), (\u00acb \u2192 \u22a4, \u03bb2)}\n\u03a8 = {(b, \u03bb1), (a \u2228 \u00acb, \u03bb0)}\nWe find (\u0398, {\u00acb}) \u22a2poss a while (M, {\u00acb}) 6\u22a2MAP a. Accordingly, we have (\u0398 \u222a\u03a8, {\u00acb}) 6\u22a2poss a.\nTransformations 2 and 3 have complementary strengths. For example, Transformation 2 may lead to more compact theories for relatively simple MLNs, e.g. if for most of the considered evidence sets, there is a unique set of formulas from the MLN that characterizes the most probable models of the evidence (cf. Lemma 1). On the other hand, Transformation 3 may lead to substantially more compact theories in cases where the number of formulas is large relative to the number of atoms.\nWe now show the correctness of Transformation 3.\nProposition 3. Let M be an MLN, k a positive integer and \u0398k the proposed possibilistic logic encoding of M. Furthermore, let E and C be sets of literals such that |E|+ |C| \u2264 k+ 1. It holds that (M, E) \u22a2MAP \u2228 C if and only if\n(\u0398k, E) \u22a2poss \u2228 C.\nBefore we prove Proposition 3, we present a number of lemmas. In the lemmas and proofs below, M will always be an MLN, \u0398k will be the corresponding possibilistic logic theory and k will be the maximum size of the evidence sets considered in the translation.\nLemma 2. If E is a set of literals, |E| \u2264 k, \u03bb = \u03c6(E) and (M, E) \u22a2MAP x then\n{(\u2227 E\u2032 \u2192 \u2227 X ) \u2208 \u0398k\u03bb s.t. |E \u2032| \u2264 |E| } \u22a2 \u2227 E \u2192 x\nLemma 3. If \u03c6(\u03c9) \u2264 \u03bb then \u03c9 is a model of \u0398k\u03bb.\nProof. If there were a formula F = ( \u2227 E) \u2192 ( \u2227 X) in \u0398k\u03bb that was not satisfied by \u03c9, then its body would have to be true in \u03c9 but then necessarily\n\u03bb \u2264 \u03c6(E) \u2264 \u03c6(\u03c9) \u2264 \u03bb.\nThe first inequality follows from the fact that, by the construction of \u0398k, if the certainty weight of F is at least \u03bb then it must be the case that \u03c6(E) \u2265 \u03bb. The second inequality follows from the fact that \u03c9 was assumed to be a model of \u2227 E. It follows that:\npen(M, \u03c9) = pen(M, E).\nHowever, this would mean that \u03c9 is also a most probable world of (M, E), but then \u03c9 |= F by construction of \u0398k. If there were an unsatisfied formula F = \u00ac ( \u2227 E \u2227 \u2227 X) in \u0398k\u03bb then by construction we would have \u03c6(E \u222aX) > \u03bb. However, from \u03c9 |= \u2227 E \u2227 \u2227 X we find \u03c6(E \u222a X) \u2264 \u03c6(\u03c9) \u2264 \u03bb, a contradiction.\nSince all formulas in \u0398k are of the two considered types, it follows that all formulas from \u0398k whose certainty weight is at least \u03bb must be satisfied in \u03c9.\nLemma 4. If (M, E) \u22a2MAP (y1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 ym) then\n(i) for any i, either (M, E \u222a {\u00acyi}) \u22a2MAP (y1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 yi\u22121 \u2228 yi+1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 ym) or (M, E) \u22a2MAP yi,\n(ii) there exist a j and a set {y\u20321, . . . , y \u2032 m\u2032} \u2286\n{y1, . . . , ym} \\ {yj} such that (M, E \u222a {\u00acy\u20321, . . . ,\u00acy \u2032 m\u2032}) \u22a2MAP yj .\nLemma 5. If |C| + |E| \u2264 k + 1, and \u03bb = \u03c6(E) then \u0398k\u03bb \u222aE \u22a2 \u2228 C if and only if (M, E) \u22a2MAP \u2228 C.\nWe now turn to the proof of Proposition 3.\nProof of Proposition 3. Let E be an evidence set such that |E| \u2264 k and let \u03bb = \u03c6(E). Given Lemma 5, it is sufficient to show that con(\u0398k, E) = \u03bb. It follows from Lemma 3 that con(\u0398k, E) \u2264 \u03bb. Let X = {x | (M, E) \u22a2MAP x} be the set of literals which can be derived from (M, E) using MAP inference. By construction, \u0398k contains a formula \u00ac( \u2227 E \u2227 \u2227 X) with a certainty weight which is just below \u03bb. Specifically, for \u03bb\u2032 < \u03bb we either have \u0398k\u03bb = \u0398 k \u03bb\u2032 or\n\u0398k\u03bb\u2032 |= \u00ac \u2227 E, from which we find con(\u0398k, E) = \u03bb.\nIt is of interest to remove any formulas in \u0398k that are redundant, among others because this is likely to make the theory easier to interpret. Although we can use possibilistic logic inference to identify redundant formulas, in some cases we can avoid adding the redundant formulas altogether. For example, in the transformation procedure, we do not add any rules for E if it holds that E \\ {y} \u22a2MAP y for some y \u2208 E. This pruning rule is the counterpart of the cautious monotonicity property, which is well-known in the context of default reasoning [15]. Any ranking on possible worlds also satisfies the stronger rational monotonicity property, which translated to our setting states that when (M, E \\ {y}) \u22a2MAP x and (M, E \\ {y}) 6\u22a2MAP \u00acy it holds that (M, E) \u22a2MAP x. Accordingly, when processing the evidence set E in the transformation procedure, instead of ( \u2227 E \u2192 \u2227 X,\u03bbE) it is sufficient to add the following rule:\n( \u2227 E \u2192 \u2227\n(X \\X0), \u03bbE)\nwhere\nX0 = {x |E \\ {y} \u22a2MAP x and E \\ {y} 6\u22a2MAP \u00acy}\nThe correctness of this pruning step follows from the following proposition.\nProposition 4. Let x and y be literals. If |E| < k, (M, E) \u22a2MAP x and (M, E) 6\u22a2MAP \u00acy then:\n\u0398k \\ {F} |= (\u2227 E \u2227 y \u2192 x, \u03bbE\u222a{y} )\nwhere F is the formula in \u0398k corresponding to the evidence set E \u222a {y}, i.e.:\nF = \u2227 (E \u222a {y}) \u2192 \u2227\n{x | (M, E \u222a {y}) \u22a2MAP x}\nProof. If (M, E) \u22a2MAP x and (M, E) 6\u22a2MAP \u00acy then (M, E \u222a {y}) \u22a2MAP x and pen(M, E) = pen(M, E \u222a {y}) = pen(M, E \u222a {x, y}). Therefore using Lemma 2, we find that \u0398k\u03bbE\u222a{y} \u22a2 \u2227 E \u2192 x. From Lemma 2, it\nfurthermore follows that \u2227 E \u2192 x can be derived from rules with antecedents of length at most |E|. In particular, we find that \u2227 E \u2192 x can be derived without using the formula \u2227 E \u2227 y \u2192 \u2227 X .\nFinally, note that formulas of the form (13) can be omitted when \u03bb\u2032E = \u03bb(E\\{y}) for some y \u2208 E. Indeed, in such a case we find from pen(M, E \\ {y}) < pen(M, E) that (M, E \\ {y}) \u22a2MAP \u00acy, hence (13) will be entailed by a formula of the form (\u2227 (E \\ {y}) \u2192 \u2227 X,\u03bbE\\{y} ) in \u0398k."}, {"heading": "4 ENCODING NON-GROUND NETWORKS", "text": "We now provide the counterpart to the construction from Section 3.2 for non-ground MLNs. The first-order nature\nof MLNs often leads to distributions with many symmetries which can be exploited by lifted inference methods [20]. We can similarly exploit these symmetries for constructing more compact possibilistic logic theories from MLNs.\nFor convenience, in the possibilistic logic theories, we will use typed formulas. For instance, when we have the formula \u03b1 = owns(person : X, thing : Y ) and the set of constants of the type person is {alice, bob} and the set of constants of the type thing is {car} then \u03b1 corresponds to the ground formulas owns(alice, car) and owns(bob, car). In cases where there is only one type, we will not write it explicitly.\nTwo typed formulas F1 and F2 are said to be isomorphic when there is a type-respecting substitution \u03b8 of the variables of F1 such that F1\u03b8 \u2261 F2 (where \u2261 denotes equivalence of logical formulas). Two MLNs M1 and M2 are said to be isomorphic, denoted by M1 \u2248 M2, if there is a bijection i from formulas of M1 to formulas of M2 such that for i(F,w) = (F \u2032, w\u2032) it holds that w = w\u2032 and the formulas F and F \u2032 are isomorphic. When j is a permutation of a subset of constants from M then j(M) denotes the MLN obtained by replacing any constant c from the subset by its image j(c).\nGiven a non-ground MLN M, we can first identify sets of constants which are interchangeable, where a set of constants Ct is said to be interchangeable if j(M) \u2248 M for any permutation j of the constants in Ct. Note that to check whether a set of constants Ct is interchangeable, it is sufficient to check that j(M) \u2248 M for those permutations which swap just two constants from Ct. For every maximal set Ct of interchangeable constants, we introduce a new type t. For a constant c, we write \u03c4(c) to denote its type. When F is a ground formula, variabilize(F ) denotes the following formula:\n\u2227 {Vc 6= Vd | c, d \u2208 const(F ), \u03c4(c) = \u03c4(d)} \u2192 F \u2032\nwhere const(F ) is the set of constants appearing in F and F \u2032 is obtained from F by replacing all constants c by a new variable Vc of type \u03c4(c).\nTransformation 4. Given an MLN M and a positive integer k, we construct a possibilistic logic theory \u0398kM as follows:\n\u2022 For each hard rule F from M, add (F, 1) to \u0398kM.\n\u2022 For each set of literals E such that 0 \u2264 |E| \u2264 k, let X = {x | (M, E) \u22a2MAP x}. For all x \u2208 X , unless there is a literal y \u2208 E such that (M, E\\{y}) \u22a2MAP y and unless \u0398kM already contains a formula isomorphic to variabilize ( \u2227 E \u2192 x), add\n( variabilize (\u2227 E \u2192 x ) , \u03bbE )\nto \u0398kM. If pen(M, E) > pen(M, \u2205) and \u0398 k M does not already contain a formula isomorphic to variabilize (\u00ac ( \u2227 E \u2227 \u2227 X)), add also\n( variabilize ( \u00ac (\u2227 E \u2227 \u2227 X ))\n, \u03bb\u2032E\n) (14)\nwhere \u03bb\u2032E is the certainty level just below \u03bbE in \u0398 k M.\nAs before, we will usually omit the subscript in \u0398kM. We can show that after grounding, \u0398k is equivalent to the theory that would be obtained by first grounding the MLN and then applying the method from Section 3.2. The correctness proof is provided in the online appendix.\nOur implementation4 of Transformation 4 relies on an efficient implementation of inference in possibilistic logic and Markov logic, efficient generation of non-redundant candidate evidence sets and efficient filtering of isomorphic formulas. For MAP inference in MLNs, we used a cuttingplane inference algorithm based on a SAT-based optimization. For inference in possibilistic logic, we also used cutting-plane inference in order to avoid having to ground the whole theory. To find the ground rules that need to be added by the cutting-plane method, we used a modified querying system from [16]. For solving and optimizing the resulting ground programs, we used the SAT4J library [3].\nNote that to check whether \u0398k\u03bb \u22a2 F , where F is a (not necessarily ground) clause, it is sufficient to find one (typerespecting) grounding \u03b8 of F , and check whether \u0398k\u03bb \u222a {\u00ac(F\u03b8)} is inconsistent. In this way, we can check whether a rule is implied by \u0398k without grounding the whole theory because, as for MLNs, inference in non-ground possibilistic logic theories can be carried out by cutting-plane inference methods.\nWe implemented the transformation as a modification of the standard best-first search (BFS) algorithm which constructs incrementally larger candidate evidence sets, checks their MAP consequences and adds the respective rules to the possibilistic logic theory being constructed. Like the standard BFS algorithm it uses a hash-table based data structure closed, in which already processed evidence sets are stored. In order to avoid having to check isomorphism with every evidence set in closed, each time a new evidence set is considered, the stored evidence sets are enriched by fingerprints which contain some invariants, guaranteeing that no two variabilized evidence sets with different fingerprints are isomorphic. In this way, we can efficiently check for a given evidence set E whether there is a previously generated evidence set E\u2032 such that variabilize(E) and variabilize(E\u2032) are isomorphic.\nAs a final remark, we note that for the non-ground transformation, it may be preferable to replace any\n4The implementation can be downloaded from: https://github.com/supertweety/mln2poss.\nrule (variabilize (\u00ac ( \u2227 E \u2227 \u2227 X)) , \u03bb\u2032E) by the rule\n(variabilize (\u00ac \u2227 E) , \u03bb\u2032E). The reason is that the former rules may often become too long in the non-ground case. On the other hand, for the ground transformation, the advantage of the longer rules is that they will often be the same for different sets E, which, in effect, means a smaller number of rules in the possibilistic logic theory. The correctness of this alternative to Transformation 4 is also shown in the online appendix."}, {"heading": "5 ILLUSTRATIVE EXAMPLES", "text": "The first example is a variation on a classical problem from non-monotonic reasoning. Here, we want to express that birds generally fly, but heavy antarctic birds do not fly, unless they have a jet pack. The MLN which we will convert into possibilistic logic contains the following rules: 10 : bird(X) \u2192 flies(X), 1 : antarctic(X) \u2192 \u00acflies(X), 10 : heavy(X) \u2192 \u00acflies(X), 100 : hasJetPack(X) \u2192 flies(X). When presented with this MLN, Transformation 4 produces the following possibilistic logic theory.\n(\u00acantarctic(X) \u2228 \u00acflies(X), \u03bb0)\n(\u00acbird(X) \u2228 flies(X), \u03bb0)\n(\u00acheavy(X) \u2228 \u00acflies(X), \u03bb0)\n(flies(X) \u2228 \u00achasJetPack(X), \u03bb0)\n(\u00acbird(X) \u2228 flies(X) \u2228 hasJetPack(X), \u03bb1)\n(\u00acheavy(X) \u2228 antarctic(X) \u2228 \u00acflies(X), \u03bb1)\n(\u00acbird(X) \u2228 \u00acheavy(X), \u03bb1)\n(\u00acantarctic(X) \u2228 \u00acheavy(X) \u2228 \u00acflies(X), \u03bb10)\n(flies(X) \u2228 \u00achasJetPack(X) \u2228 bird(X), \u03bb11)\n(\u00acbird(X) \u2228 flies(X) \u2228 \u00achasJetPack(X), \u03bb100)\nLet us consider the evidence set E = {bird(tweety), heavy(tweety)}. Then the levels \u03bb0 and \u03bb1 drown because of the inconsistency with the rule (\u00acbird(X) \u2228 \u00acheavy(X), \u03bb1) which was produced as one of the rules (14). We can see from the rest of the possibilistic logic theory that unless we add either antarctic(tweety) or hasJetPack(tweety), we cannot say anything about whether tweety flies or not. It can be verified that the same is true also for the respective MLN.\nThe second example consists of formulas from a classical MLN about smokers. There are three predicates in this MLN: a binary predicate f(A,B) denoting that A and B are friends, and two unary predicates s(A) and c(A) denoting that A smokes and that A has cancer, respectively. The MLN contains the following hard rules: \u00acf(A,B) \u2228 f(B,A) and \u00acf(A,A). In addition, we have two soft rules. The first soft rule 10: \u00acs(A)\u2228\u00acf(A,B)\u2228 s(B) states that if A and B are friends and A smokes then B is more likely to smoke too. The second rule 10: \u00acs(A) \u2228 c(A) states that smoking increases the likelihood of cancer. The following possi-\nbilistic logic theory was obtained using Transformation 4 with k = 4.\n(s(B) \u2228 \u00acf(A,B) \u2228 \u00acs(A) \u2228 \u00acalldiff(A,B), \u03bb0)\n(\u00acs(A) \u2228 c(A), \u03bb0)\n(\u00acf(C,B) \u2228 \u00acf(A,B) \u2228 s(A) \u2228 s(C)\n\u2228\u00acalldiff(A,B,C) \u2228 \u00acs(B), \u03bb10)\n(\u00acf(C,B) \u2228 \u00acs(A) \u2228 \u00acf(A,C) \u2228 s(C)\n\u2228\u00acalldiff(A,B,C) \u2228 \u00acs(B), \u03bb10)\n(\u00acs(A) \u2228 \u00acf(C,A) \u2228 s(C) \u2228 c(B)\n\u2228\u00acalldiff(A,B,C) \u2228 \u00acs(B), \u03bb10)\n(\u00acs(A) \u2228 c(A) \u2228 c(B) \u2228 \u00acs(B) \u2228 \u00acalldiff(A,B), \u03bb10)\n(s(B) \u2228 \u00acf(A,B) \u2228 \u00acs(A) \u2228 c(A) \u2228 \u00acalldiff(A,B), \u03bb10)\n(\u00acf(A,B) \u2228 f(B,A), 1)\n(\u00acf(A,A), 1)\nAt the lowest level \u03bb0 we find the counterparts of the soft rules from the MLN, whereas at level 1 we find the hard rules. At the intermediate level we intuitively find weakened rules from the MLN. For instance, the rule (\u00acs(A) \u2228 c(A)\u2228c(B)\u2228\u00acs(B)\u2228\u00acalldiff(A,B), \u03bb1) can be interpreted as: if A and B smoke then at least one of them has cancer. It is quite natural that this rule has higher certainty weight than the rule: if A smokes then A has cancer.\nA final, more elaborate example is provided in the online appendix."}, {"heading": "6 RELATED WORK", "text": "One line of related work focuses on extracting a comprehensible model from another learned model that is difficult or impossible to interpret. A seminal work in this area is the TREPAN [5] algorithm. Given a trained neural network and a data set, TREPAN learns a decision tree to mimic the predictions of the neural network. In addition to producing interpretable output, this algorithm was shown to learn accurate models that faithfully mimicked the neural network\u2019s predictions. More recent research has focused on approximating complex ensemble classifiers with a single model. For example, Popovic et al. [21] proposed a method for learning a single decision tree that mimics the predictions of a random forest.\nWhile, to the best of our knowledge, this is the first paper that studies the relation between Markov logic and possibilistic logic, the links between possibility theory and probability theory have been widely studied. For example, [10] has proposed a probability-possibility transformation based on the view that a possibility measure corresponds to a particular family of probability measures. Dempster-Shafer evidence theory [25] has also been used to provide a probabilistic interpretation to possibility degrees. In particular, a possibility distribution can be interpreted as the contour\nfunction of a mass assignment; see [11] for details. In [13] it is shown how the probability distribution induced by a penalty logic theory corresponds to the contour function of a mass assignment, which suggests that it is indeed natural to interpret this probability distribution as a possibility distribution. Several other links between possibility theory and probability theory have been discussed in [6].\nIn this paper, we have mainly focused on MAP inference. An interesting question is whether it would be possible to construct a (possibilistic) logic base that captures the set of accepted beliefs encoded by a probability distribution, where A is accepted if P (A) > P (\u00acA). Unfortunately, the results in [7] show that this is only possible for the limited class of so-called big-stepped probability distributions. In practice, this means that we would have to define a partition of the set of possible worlds, such that the probability distribution over the partition classes is big-stepped, and only capture the beliefs that are encoded by the latter, less informative, probability distribution. A similar approach was taken in [1] to learn default rules from data."}, {"heading": "7 CONCLUSIONS", "text": "This paper has focused on how a Markov logic network M can be encoded in possibilistic logic. We started from the observation that it is always possible to construct a possibilistic logic theory \u0398M that is equivalent to M, in the sense that the probability distribution induced by M is isomorphic to the possibility distribution induced by \u0398M. As a result, applying possibilistic logic inference to \u0398M yields the same conclusions as applying MAP inference to M. Although the size of \u0398M is exponential in the number of formulas in M, we have shown how more compact theories can be obtained in cases where we can put restrictions on the types of evidence that need to be considered (e.g. small sets of literals).\nOur main motivation has been to use possibilistic logic as a way to make explicit the assumptions encoded in a given MLN. Among others, the possibilistic logic theory could be used to generate explanations for predictions made by the MLN, to gain insight into the data from which the MLN was learned, or to identify errors in the structure or weights of the MLN. Taking this last idea one step further, our aim for future work is to study methods for repairing a given MLN, based on the mistakes that have thus been identified."}, {"heading": "Acknowledgements", "text": "We would like to thank the anonymous reviewers for their helpful comments. This work has been supported by a grant from the Leverhulme Trust (RPG-2014-164). JD is partially supported by the Research Fund KU Leuven (OT/11/051), EU FP7 Marie Curie Career Integration Grant (#294068) and FWO-Vlaanderen(G.0356.12)."}, {"heading": "A PROOFS", "text": "Proof of Proposition 1. Let X = {(F,w) \u2208 M : \u03c9 6|= F} be the set of rules from the MLN not satisfied in \u03c9. By construction, the possibilistic logic theory \u0398 contains the rule ( \u2228 X\u2217, \u03bb) where \u03bb = \u03c6(\u00ac \u2228 X\u2217) = K+pen(M,\u00ac \u2228 X\u2217)\nL =\nK+pen(M,\u03c9) L\n. As a result, \u03c9 6|= \u0398\u03bb. On the other hand, \u03c9 |= \u0398\u03bb\u2032 for any \u03bb\u2032 > \u03bb. Indeed, for ( \u2228 Y \u2217, \u03bb\u2032) \u2208 \u0398 and \u03bb\u2032 > \u03bb, we have by construction that Y \u2217 6\u2286 X\u2217, i.e. Y \u2217 contains a formula \u03b1 which is not in X\u2217. By definition of X , this means \u03c9 |= \u03b1, and thus in particular \u03c9 |= \u2228 Y \u2217. Since \u03c0 was assumed to be the least specific model of \u0398, it holds that \u03c0(\u03c9) = 1\u2212max(\u03b1i,\u03bbi){\u03bbi|\u03c9 6|= \u03b1i}. Hence we can conclude \u03c0(\u03c9) = 1\u2212 \u03c6(\u03c9).\nProof of Lemma 2. The lemma can be proved by induction on |E|. The base case |E| = 0 is obvious. Let us assume that the lemma holds for |E| = n < k. If E does not contain any literal y such that (M, E \\ {y}) \u22a2MAP y then \u0398k\u03bb contains a formula \u2227 E \u2192 \u2227 X with x \u2208 X and the lemma clearly holds. Otherwise, if there is a literal y \u2208 E such that (M, E \\ {y}) \u22a2MAP y then we must also have (M, E \\ {y}) \u22a2MAP x. Moreover \u03c6(E) = \u03c6(E \\ {y}) = \u03bb in this case. By induction we find that the formula\n\u2227 (E \\ {y}) \u2192 x can be derived from{\n( \u2227 E\u2032 \u2192 \u2227 X) \u2208 \u0398k\u03bb s.t. |E \u2032| \u2264 |E| } .\nProof of Lemma 1. We have that {F1, ..., Fl} \u2229 Y 6= \u2205 for every Y \u2208 ConsE(M) iff \u2228 { \u2227 Y |Y \u2208 ConsE(M)} \u2227 \u00acF1 \u2227 ... \u2227 \u00acFl is inconsistent. This in turn means that the most plausible world of E\u2227\u00acF1\u2227...\u2227\u00acFl cannot be among the most plausible worlds ofE, and thus pen(M, E\u2227\u00acF1\u2227 ... \u2227 \u00acFl) > pen(M, E).\nProof of Lemma 4. (i) Let \u2126 be the set of most probable worlds of (M, E), let \u2126\u2032i be the set of most probable worlds of (M, E \u222a {\u00acyi}) and let \u2126\u2032\u2032i be the set of most probable worlds of (M, E) in which yi is false. In general \u2126\u2032i 6= \u2126 \u2032\u2032 i . Either (M, E) \u22a2MAP (y1 \u2227 \u00b7 \u00b7 \u00b7 \u2227 yk) or at least one of \u2126\u2032\u2032i must be nonempty. Let \u2126\u2032\u2032i\u2217 be such a nonempty set. It must hold (M, E\u222a{\u00acyi\u2217}) \u22a2MAP (y1\u2228\u00b7 \u00b7 \u00b7\u2228yi\u2217\u22121\u2228yi\u2217+1\u2228\u00b7 \u00b7 \u00b7\u2228 yk) because, in this case, \u2126\u2032i\u2217 = \u2126 \u2032\u2032 i\u2217 \u2286 \u2126. (ii) The second part of the lemma follows from repeated application of the first part.\nProof of Lemma 5. (\u21d2) It follows from Lemma 3 that any most probable model of E is a model of \u0398k\u03bb \u222a E, hence if \u0398k\u03bb \u222aE \u22a2 \u2228 C then (M, E) \u22a2MAP \u2228 C.\n(\u21d0) If (M, E) \u22a2MAP (c1 \u2228 \u00b7 \u00b7 \u00b7 \u2228 cm), then by Lemma 4 we have (M, E \u222a C\u2032) \u22a2MAP cj for some j \u2208 {1, ...,m} and C\u2032 \u2286 {\u00acc1, . . . ,\u00accj\u22121,\u00accj+1, . . . ,\u00accm}. Since |E| + |C\u2032| \u2264 k, by Lemma 2 we have\u0398k\u03bb \u22a2 \u00ac ( \u2227 E)\u2228\u00ac ( \u2227 C\u2032)\u2228\ncj and therefore \u0398k\u03bb \u222a E \u22a2 \u2228 C.\nCorrectness of Transformation 4\nIn the following lemmas, M will be an MLN, k will be an integer, \u03a5kM will be the ground possibilistic logic encoding given by Transformation 3 in which, for convenience, we replace any rule ( \u2227 E \u2192 \u2227 X,\u03bbE) by a set of rules\n( \u2227 E \u2192 x, \u03bbE) where x \u2208 X . \u0398kM will be the non-ground possibilistic logic encoding given by Transformation 4. Recall that \u0398kM is given together with a set of constants, typed according to their interchangeability. The ground possibilistic logic theory obtained by grounding \u0398kM using this set of typed constants will be denoted by \u0398\u0302kM. Lemma 6. Let \u03b1 = ( \u2227 E \u2192 x, \u03bbE) be a rule. Then \u03b1 \u2208 \u03a5kM if and only if \u03b1 \u2208 \u0398\u0302 k M.\nProof. (\u21d2) If \u03b1 \u2208 \u03a5kM then a rule isomorphic to (variabilize ( \u2227 E \u2192 x) , \u03bbE) must be contained in \u0398kM but then \u03b1 must be among the groundings of that rule and therefore also be in \u0398\u0302kM.\n(\u21d0) If \u03b1 \u2208 \u0398\u0302kM then \u0398 k M must contain a\nrule (variabilize ( \u2227 E\u2032 \u2192 x\u2032) , \u03bbE) isomorphic to\n(variabilize ( \u2227 E \u2192 x) , \u03bbE) such that (M, E\u2032) \u22a2MAP x\u2032 and such that there is no literal y\u2032 \u2208 E\u2032 satisfying (M, E\u2032 \\ {y\u2032}) \u22a2MAP y\u2032. It follows from the fact that constants of the same type are interchangeable that then also (M, E) \u22a2MAP x and that there is no literal y \u2208 E satisfying (M, E \\ {y}) \u22a2MAP y. From this it immediately follows that \u03b1 \u2208 \u03a5kM. Lemma 7. Let \u03b1 = (\u00ac ( \u2227 E \u2227 \u2227 X) , \u03bb\u2032E) be a rule. Then \u03b1 \u2208 \u03a5kM if and only if \u03b1 \u2208 \u0398\u0302 k M.\nProof. The proof of this lemma is very similar to the proof of Lemma 6.\n(\u21d2) If \u03b1 \u2208 \u03a5kM then a rule isomorphic to (variabilize ( \u2227 E \u2227 \u2227 X) , \u03bb\u2032E) must be contained in \u0398 k M but then \u03b1 must be among the groundings of that rule and therefore also be in \u0398\u0302kM.\n(\u21d0) If \u03b1 \u2208 \u0398\u0302kM then \u0398 k M must contain a rule\n(variabilize ( \u2227 E\u2032 \u2227 \u2227 X \u2032) , \u03bb\u2032E) isomorphic to\n(variabilize ( \u2227 E \u2227 \u2227 x) , \u03bb\u2032E) such that (M, E \u2032) \u22a2MAP x \u2032 for all x\u2032 \u2208 X \u2032. It follows from the fact that constants of the same type are interchangeable that then also (M, E) \u22a2MAP x for all x \u2208 X , from which it immediately follows that \u03b1 \u2208 \u03a5kM.\nProposition 5. Given an MLN M and an integer k, the possibilistic logic theories obtained by Transformation 3 and by grounding the possibilistic logic theory obtained by Transformation 4 are equivalent.\nProof. The proof follows from Lemma 6 and Lemma 7.\nCorrectness of the alternative to Transformation 4\nWe show the correctness of the alternative transformation, in which we replace rules of the form\n( variabilize ( \u00ac (\u2227 E \u2227 \u2227 X ))\n, \u03bb\u2032E\n)\nby the rule (\nvariabilize ( \u00ac \u2227 E ) , \u03bb\u2032E )\nThe correctness of this alternative transformation can be shown as follows. Let \u0398k be the possibilistic logic theory obtained by Transformation 4 and let \u03a6k be the possibilistic logic theory obtained by the alternative transformation. It holds that \u00ac \u2227 E |= \u00ac( \u2227 E \u2227 \u2227 X) and consequently also variabilize(\u00ac \u2227 E) |= variabilize(\u00ac( \u2227 E\u2227 \u2227\nX)). Therefore if \u0398k\u03bb \u222a F is inconsistent then \u03a6 k \u03bb \u222a F must be inconsistent as well. Moreover, since \u03bb\u2032E < \u03c6(E), we can show (using arguments analogical to those used in the proof of Proposition 3) that this alternative transformation also satisfies the properties stated for Transformation 4 in Proposition 5."}, {"heading": "B ADDITIONAL EXAMPLE", "text": "In this section we illustrate Transformation 4 on a larger MLN trained for predicting categories of computer science papers5, which is shown in Table 1. This MLN contains rules for predicting categories of papers from categories of other papers which refer to them (rules 2-3) or from categories of papers written by the same author (rule 3). In addition it contains rules giving prior probabilities of the individual probabilities and a hard rule specifying that every paper has at most one category (for simplicity).\nWe applied Transformation 4 on this MLN which resulted in a possibilistic logic theory with 200 rules6. Table 2 displays a subset of the rules in the resulting theory, which are interesting for illustrating some properties of the MLN and which are not immediately obvious from the MLN itself. Notice that we represent, apart from the formulas of the form (14), we present formuals in the implication form to make the interpretation easier.\nRule \u03b1 is one of the rules enforcing drowning. Rule \u03b2 states that in absence of other evidence, the category of any paper\n5We obtained the structure of the MLN from the Tuffy web http://i.stanford.edu/hazy/tuffy/download/.\n6There are two modes for filtering redundant rules in the possibilistic logic theory in our implementation. The more aggressive filtering iteratively removes rules which are entailed by other rules in the theory (with the same or greater certainty weights) whereas the less aggressive filtering only iteratively removes the rules which are entailed by subset of the rules from the theory which are all shorter or equally long. The latter filtering results in slightly more interpretable results. In the experiments reported here, we have used the less aggressive filtering.\nis assumed to be AI. Rule \u03b3 cannot intuitively be justified and is probably an unintended consequence of the MLN. It states that if V 1 wrote a paper which is not from the category AI, then V 1 did not write any other paper. This rule is not harmful when the MLN is used for the purpose of predicting categories but it indicates that the MLN would not be suitable for predicting authorship (which is not really surprising given that the MLN was not trained for this task). The rules \u03b4 and \u03b7 are representatives of rules which capture the prior distribution of the categories (note that there are more rules of this kind which we do not show here). Rule \u03b6 is similar to \u03b3. The rules \u03b9, \u03ba, \u03bb, \u00b5, \u03bd and \u03be state that if one paper refers to another paper then they typically have the same category. Such rules actually give evidence of meaningfulness of the MLN for prediction of categories."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "Markov logic uses weighted formulas to com-<lb>pactly encode a probability distribution over pos-<lb>sible worlds. Despite the use of logical formu-<lb>las, Markov logic networks (MLNs) can be diffi-<lb>cult to interpret, due to the often counter-intuitive<lb>meaning of their weights. To address this issue,<lb>we propose a method to construct a possibilis-<lb>tic logic theory that exactly captures what can<lb>be derived from a given MLN using maximum<lb>a posteriori (MAP) inference. Unfortunately, the<lb>size of this theory is exponential in general. We<lb>therefore also propose two methods which can<lb>derive compact theories that still capture MAP<lb>inference, but only for specific types of evidence.<lb>These theories can be used, among others, to<lb>make explicit the hidden assumptions underlying<lb>an MLN or to explain the predictions it makes.", "creator": "LaTeX with hyperref package"}}}