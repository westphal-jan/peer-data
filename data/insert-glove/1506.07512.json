{"id": "1506.07512", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2015", "title": "Un-regularizing: approximate proximal point and faster stochastic algorithms for empirical risk minimization", "abstract": "We tippingpoint develop a mosheim family of \u0161timac accelerated neufville stochastic algorithms taimyr that shrikant minimize khwa sums chou of convex aburto functions. yakir Our campy algorithms \u00e8s improve reductively upon ca1 the fastest skunks running loku time norio for aislabie empirical risk voulgarakis minimization (ERM ), immunosuppressed and in deadeye particular linear least - vreeswijk squares baring-gould regression, across a aranjuez wide boroondara range lotfian of problem bray@globe.com settings. To andrianov achieve this, we worsfold establish orender a framework based trentin on the classical sinker proximal roshan point enraging algorithm. ferments Namely, koji\u0107 we makeweight provide several sanderstead algorithms mogh that plessix reduce the 161.7 minimization eslate of a strongly bergner convex function to raja approximate minimizations nahariya of porte-coch\u00e8re regularizations ponsot of 132kg the 1859 function. mostaghim Using sir these cifuentes results, we accelerate wakan recent frelimo fast breivik stochastic algorithms johanssen in a black - box fashion. Empirically, we abankwah demonstrate 1.145 that the 1,260 resulting algorithms haun exhibit senter notions torroja of stability that are advantageous superamerica in swum practice. Both in alcoholics theory and in practice, the ncbi provided euro29 algorithms reap napolitan the computational rivi\u00e8re-des-prairies benefits 46.41 of 101.70 adding a voluntarism large strongly wagenaar convex regularization cupressus term, without incurring viles a corresponding bias 15:33 to ramlan the now-classic original problem.", "histories": [["v1", "Wed, 24 Jun 2015 19:53:45 GMT  (60kb,D)", "http://arxiv.org/abs/1506.07512v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.DS cs.LG", "authors": ["roy frostig", "rong ge 0001", "sham kakade", "aaron sidford"], "accepted": true, "id": "1506.07512"}, "pdf": {"name": "1506.07512.pdf", "metadata": {"source": "CRF", "title": "Un-regularizing: approximate proximal point and faster stochastic algorithms for empirical risk minimization", "authors": ["Roy Frostig", "Rong Ge", "Sham M. Kakade", "Aaron Sidford"], "emails": ["rf@cs.stanford.edu,", "rongge@microsoft.com,", "skakade@microsoft.com,", "sidford@mit.edu."], "sections": [{"heading": null, "text": "To achieve this, we establish a framework based on the classical proximal point algorithm. Namely, we provide several algorithms that reduce the minimization of a strongly convex function to approximate minimizations of regularizations of the function. Using these results, we accelerate recent fast stochastic algorithms in a black-box fashion.\nEmpirically, we demonstrate that the resulting algorithms exhibit notions of stability that are advantageous in practice. Both in theory and in practice, the provided algorithms reap the computational benefits of adding a large strongly convex regularization term, without incurring a corresponding bias to the original problem."}, {"heading": "1 Introduction", "text": "A general optimization problem central to machine learning is that of empirical risk minimization (ERM): finding a predictor or regressor that minimizes a sum of loss functions defined by a data sample. We focus in part on the problem of empirical risk minimization of linear predictors: given a set of n data points ai, . . . , an \u2208 Rd and convex loss functions \u03c6i : R\u2192 R for i = 1, . . . , n, solve\nmin x\u2208Rn\nF (x), where F (x) def = n\u2211 i=1 \u03c6i(a T i x). (1)\nThis problem underlies supervised learning (e.g. the training of logistic regressors when \u03c6i(z) = log(1 + e\u2212zbi), or their regularized form when \u03c6i(z) = log(1 + e \u2212zbi) + \u03b32n\u2016x\u2016 2 2 for a scalar \u03b3 > 0) and captures the widely-studied problem of linear least-squares regression when \u03c6i(z) = 1 2(z\u2212 bi)\n2. Over the past five years, problems such as (1) have received increased attention, with a recent burst of activity in the design of fast randomized algorithms. Iterative methods that randomly\n\u2217This is an extended and updated version of our conference paper that appeared in Proceedings of the 32nd\nInternational Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP Volume 37. Email: rf@cs.stanford.edu, rongge@microsoft.com, skakade@microsoft.com, sidford@mit.edu.\nar X\niv :1\n50 6.\n07 51\n2v 1\n[ st\nat .M\nL ]\n2 4\nsample the \u03c6i have been shown to outperform standard first-order methods under mild assumptions (Bottou and Bousquet, 2008; Johnson and Zhang, 2013; Xiao and Zhang, 2014; Defazio et al., 2014; Shalev-Shwartz and Zhang, 2014).\nDespite the breadth of these recent results, their running time guarantees when solving the ERM problem (1) are sub-optimal in terms of their dependence on a natural notion of the problem\u2019s condition number (See Section 1.1). This dependence can, however, significantly impact their guarantees on running time. High-dimensional problems encountered in practice are often poorly conditioned. In large-scale machine learning applications, the condition number of the ERM problem (1) captures notions of data complexity arising from variable correlation in high dimensions and is hence prone to be very large.\nMore specifically, among the recent randomized algorithms, each one either:\n1. Solves the ERM problem (1), under an assumption of strong convexity, with convergence that depends linearly on the problem\u2019s condition number (Johnson and Zhang, 2013; Defazio et al., 2014).\n2. Solves only an explicitly regularized ERM problem, minx{F (x) + \u03bbr(x)} where the regularizer r is a known 1-strongly convex function and \u03bb must be strictly positive, even when F is itself strongly convex. One such result is due to Shalev-Shwartz and Zhang (2014) and is the first to achieve acceleration for this problem, i.e. dependence only on the square root of the regularized problem\u2019s condition number, which scales inversely with \u03bb. Hence, taking small \u03bb to solve the ERM problem (where \u03bb = 0 in effect) is not a viable option.\nIn this paper we show how to bridge this gap via black-box reductions. Namely, we develop algorithms to solve the ERM problem (1) \u2013 under a standard assumption of strong convexity \u2013 through repeated, approximate minimizations of the regularized ERM problem minx{F (x) + \u03bbr(x)} for fairly large \u03bb. Instantiating our framework with known randomized algorithms that solve the regularized ERM problem, we achieve accelerated running time guarantees for solving the original ERM problem.\nThe key to our reductions are approximate variants of the classical proximal point algorithm (PPA) (Rockafellar, 1976; Parikh and Boyd, 2014). We show how both PPA and the inner minimization procedure can then be accelerated and our analysis gives precise approximation requirements for either option. Furthermore, we show further practical improvements when the inner minimizer operates by a dual ascent method. In total, this provides at least three different algorithms for achieving an improved accelerated running time for solving the ERM problem (1) under the standard assumption of strongly convex F and smooth \u03c6i. (Table 1 summarizes our improvements in comparison to existing minimization procedures.)\nPerhaps the strongest and most general theoretical reduction we provide in this paper is encompassed by the following theorem which we prove in Section 3.\nTheorem 1.1 (Accelerated Approximate Proximal Point Algorithm). Let f : Rn \u2192 R be a \u00b5strongly convex function and suppose that, for all x0 \u2208 Rn, c > 0, \u03bb > 0, we can compute a point xc (possibly random) such that\nEf(xc)\u2212min x\n{ f(x) + \u03bb\n2 \u2016x\u2212 x0\u201622 } \u2264 1 c [ f(x0)\u2212min x { f(x) + \u03bb 2 \u2016x\u2212 x0\u201622 }]\nin time Tc. Then given any x0, c > 0, \u03bb \u2265 2\u00b5, we can compute x1 such that\nEf(x1)\u2212min x f(x) \u2264 1 c\n[ f(x0)\u2212min\nx f(x) ] in time O ( T 4( 2\u03bb+\u00b5\n\u00b5 )3/2\n\u221a d\u03bb/\u00b5e log c ) .\nThis theorem essentially states that we can use a linearly convergent algorithm for minimizing f(x) + \u03bb\u2016x\u2212 x0\u201622 in order to minimize f , while incurring a multiplicative overhead of only O( \u221a d\u03bb/\u00b5epolylog(\u03bb/\u00b5)). Applying this theorem to previous state-of-the-art algorithms improves both the running time for solving (1), as well as the following more general ERM problem:\nmin x\u2208Rd n\u2211 i=1 \u03c8i(x), where \u03c8i : Rd \u2192 R. (2)\nProblem (2) is fundamental in the theory of convex optimization and covers ERM problems for multiclass and structured prediction.\nThere are a variety of additional extensions to the ERM problem to which some of our analysis easily applies. For instance, we could work in more general normed spaces, allow non-uniform smoothness of the \u03c6, add an explicit regularizer, etc. However, to simplify exposition and comparison to related work, we focus on (1) and make clear the extensions to (2) in Section 3. These cases capture the core of the arguments presented and illustrate the generality of this approach.\nSeveral of the algorithmic tools and analysis techniques in this paper are similar in principle to (and sometimes appear indirectly in) work scattered throughout the machine learning and optimization literature \u2013 from classical treatments of error-tolerant PPA (Rockafellar, 1976; Guler, 1992) to the effective proximal term used by Accelerated Proximal SDCA Shalev-Shwartz and Zhang (2014) in enabling its acceleration.\nBy analyzing these as separate tools, and by bookkeeping the error requirements that they impose, we are able to assemble them into algorithms with improved guarantees. We believe that the presentation of Accelerated APPA (Algorithm 2) arising from this view simplifies, and clarifies in terms of broader convex optimization theory, the \u201couter loop\u201d steps employed by Accelerated Proximal SDCA. More generally, we hope that disentangling the relevant algorithmic components into this general reduction framework will lead to further applications both in theory and in practice."}, {"heading": "1.1 Formal setup", "text": "We consider the ERM problem (1) in the following common setting:\nAssumption 1.2 (Regularity). Each loss function \u03c6i is L-smooth, i.e. for all x, y \u2208 R,\n\u03c6(y) \u2264 \u03c6(x) + \u03c6\u2032(x)(y \u2212 x) + L 2 (y \u2212 x)2,\nand the sum F is \u00b5-strongly convex, i.e. for all x, y \u2208 Rd,\nF (x) \u2265 F (x) +\u2207F (x)T(y \u2212 x) + \u00b5 2 \u2016y \u2212 x\u201622.\nWe let R def = maxi \u2016ai\u20162 and let A \u2208 Rn\u00d7d be the matrix whose i\u2019th row is aTi . We refer to\n\u03ba def = dLR2/\u00b5e\nas the condition number of (1). Although many algorithms are designed for special cases of the ERM objective F where there is some known, exploitable structure to the problem, our aim is to study the most general case subject to Assumption 1.2. To standardize the comparison among algorithms, we consider the following generic model of interaction with F :\nAssumption 1.3 (Computational model). For any i \u2208 [n] and x \u2208 Rd, we consider two primitive operations:\n\u2022 For b \u2208 R, compute the gradient of x 7\u2192 \u03c6i(aTi x\u2212 b).\n\u2022 For b \u2208 R, c \u2208 Rd, minimize \u03c6i(aTi x) + b\u2016x\u2212 c\u201622.\nWe refer to these operations, as well as to the evaluation of \u03c6i(a T i x), as single accesses to \u03c6i, and assume that these operations can be performed in O(d) time.\nNotation Denote [n] def = {1, . . . , n}. Denote the optimal value of a convex function by fopt = minx f(x), and, when f is clear from context, let x opt denote a minimizer. A point x\u2032 is an\n-approximate minimizer of f if f(x\u2032) \u2212 fopt \u2264 . The Fenchel dual of a convex function f : Rk \u2192 R is f\u2217 : Rk \u2192 R defined by f\u2217(y) = supx\u2208Rk{\u3008y, x\u3009 \u2212 f(x)}. We use O\u0303(\u00b7) to hide factors polylogarithmic in n, L, \u00b5, \u03bb, and R, i.e. O\u0303(f) = O(fpolylog(n,L, \u00b5, \u03bb,R)).\nRegularization and duality Throughout the paper we let F : Rd \u2192 R denote a \u00b5-strongly convex function. For certain results presented, F must in particular be the ERM problem (1), while other statements hold more generally. We make it clear on a case-by-case basis when F must have the ERM structure as in (1).\nBeginning in Section 1.3 and throughout the remainder of the paper, we frequently consider the function fs,\u03bb(x), defined for all x, s \u2208 Rd and \u03bb > 0 by\nfs,\u03bb(x) def = F (x) + \u03bb2\u2016x\u2212 s\u2016 2 2 (3)\nIn such context, we let xopts,\u03bb def = argminx fs,\u03bb(x) and we call\n\u03ba\u03bb def = dLR2/\u03bbe\nthe regularized condition number. When F is indeed the ERM objective (1), certain algorithms for minimizing fs,\u03bb operate in the regularized ERM dual. Namely, they proceed by decreasing the negative dual objective gs,\u03bb : Rn \u2192 R, given by\ngs,\u03bb(y) def = G(y) +\n1\n2\u03bb \u2016ATy\u201622 \u2212 sTATy, (4)\nwhere G(y) def = \u2211n\ni=1 \u03c6 \u2217 i (yi). Similar to the above, we let y opt s,\u03bb def = argminy gs,\u03bb(y).\nTo make corresponding primal progress, dual-based algorithms make use of the dual-to-primal mapping, given by\nx\u0302s,\u03bb(y) def = s\u2212 1\u03bbA Ty, (5)\nand the primal-to-dual mapping, given entrywise by\n[y\u0302(x)]i def =\n[ \u2202\u03c6i(z)\n\u2202z ]\u2223\u2223\u2223\u2223 z=aTi x\n(6)\nfor i = 1, . . . , n. (See Appendix B for a derivation of these facts and further properties of the dual.)"}, {"heading": "1.2 Running times and related work", "text": "In Table 1 we compare our results with the running time of both classical and recent algorithms for solving the ERM problem (1) and linear least-squares regression. Here we briefly explain these running times and related work.\nEmpirical risk minimization In the context of the ERM problem, GD refers to canonical gradient descent on F , Accel. GD is Nesterov\u2019s accelerated gradient decent (Nesterov, 1983, 2004), SVRG is the stochastic variance-reduced gradient of Johnson and Zhang (2013), SAG is the stochastic average gradient of Roux et al. (2012) and Defazio et al. (2014), SDCA is the stochastic dual coordinate ascent of Shalev-Shwartz and Zhang (2013), AP-SDCA is the Accelerated Proximal SDCA of Shalev-Shwartz and Zhang (2014) and APCG is the accelerated coordinate algorithm of Lin et al. (2014). The latter three algorithms are more restrictive in that they only solve the explicitly regularized problem F + \u03bbr, even if F is itself strongly convex (such algorithms run in time inversely proportional to \u03bb).\nThe running times of the algorithms are presented based on the setting considered in this paper, i.e. under Assumptions 1.2 and 1.3. Many of the algorithms can be applied in more general settings\n(e.g. even if the function F is not strongly convex) and have different convergence guarantees in those cases. The running times are characterized by four parameters: d is the data dimension, n is the number of samples, \u03ba = dLR2/\u00b5e is the condition number (for F + \u03bbr minimizers, the condition number \u03ba\u03bb = dLR2/\u03bbe is used) and 0/ is the ratio between the initial and desired accuracy. Running times are stated per O\u0303-notation; factors that depend polylogarithmically on n, \u03ba, and \u03ba\u03bb are ignored.\nLinear least-squares regression For the linear least-squares regression problem, there is greater variety in the algorithms that apply. For comparison, Table 1 includes Moore-Penrose pseudoinversion \u2013 computed via naive matrix multiplication and inversion routines, as well as by their asymptotically fastest counterparts \u2013 in order to compute a closed-form solution via the standard normal equations. The table also lists algorithms based on the randomized Kaczmarz method (Strohmer and Vershynin, 2009; Needell et al., 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al., 2013; Cohen et al., 2015). Some Kaczmarz-based methods only apply to the more restrictive problem of solving a consistent system (finding x satisfying Ax = b) rather than minimize the squared loss \u2016Ax\u2212 b\u201622. The running times depend on the same four parameters n, d, \u03ba, 0/ as before, except for computing the closed-form pseudoinverse, which for simplicity we consider \u201cexact,\u201d independent of initial and target errors 0/ .\nApproximate proximal point The key to our improved running times is a suite of approximate proximal point algorithms that we propose and analyze. We remark that notions of error-tolerance in the typical proximal point algorithm \u2013 for both its plain and accelerated variants \u2013 have been defined and studied in prior work (Rockafellar, 1976; Guler, 1992). However, these mainly consider the cumulative absolute error of iterates produced by inner minimizers, assuming that such a sequence is somehow produced. Since essentially any procedure of interest begins at some initial point \u2013 and has runtime that depends on the relative error ratio between its start and end \u2013 such a view does not yield fully concrete algorithms, nor does it yield end-to-end runtime upper bounds such as those presented in this paper.\nAdditional related work There is an immense body of literature on proximal point methods and alternating direction method of multipliers (ADMM) that are relevant to the approach in this paper; see Boyd et al. (2011); Parikh and Boyd (2014) for modern surveys. We also note that the independent work of Lin et al. (2015) contains results similar to some of those in this paper."}, {"heading": "1.3 Main results", "text": "All formal results in this paper are obtained through a framework that we develop for iteratively applying and accelerating various minimization algorithms. When instantiated with recentlydeveloped fast minimizers we obtain, under Assumptions 1.2 and 1.3, algorithms guaranteed to solve the ERM problem in time O\u0303(nd \u221a \u03ba log(1/ )).\nOur framework stems from a critical insight of the classical proximal point algorithm (PPA) or proximal iteration: to minimize F (or more generally, any convex function) it suffices to iteratively minimize\nfs,\u03bb(x) def = F (x) + \u03bb2\u2016x\u2212 s\u2016 2 2\nfor \u03bb > 0 and proper choice of center s \u2208 Rd. PPA iteratively applies the update\nx(t+1) \u2190 argmin x fx(t),\u03bb(x)\nand converges to the minimizer of F . The minimization in the update is known as the proximal operator (Parikh and Boyd, 2014), and we refer to it in the sequel as the inner minimization problem.\nIn this paper we provide three distinct approximate proximal point algorithms, i.e. algorithms that do not require full inner minimization. Each enables the use of existing fast algorithm as its inner minimizer, in turn yielding several ways to obtain our improved ERM running time:\n\u2022 In Section 2 we develop a basic approximate proximal point algorithm (APPA). The algorithm is essentially PPA with a relaxed requirement of inner minimization by only a fixed multiplicative constant in each iteration. Instantiating this algorithm with an accelerated, regularized ERM solver \u2013 such as APCG (Lin et al., 2014) \u2013 as its inner minimizer yields the improved accelerated running time for the ERM problem (1).\n\u2022 In Section 3 we develop Accelerated APPA. Instantiating this algorithm with SVRG (Johnson and Zhang, 2013) as its inner minimizer yields the improved accelerated running time for both the ERM problem (1) as well as the general ERM problem (2).\n\u2022 In Section 4 we develop Dual APPA: an algorithm whose approximate inner minimizers operate on the dual fs,\u03bb, with warm starts between iterations. Dual APPA enables several inner minimizers that are a priori incompatible with APPA. Instantiating this algorithm with an accelerate, regularized ERM solver \u2013 such as APCG (Lin et al., 2014) \u2013 as its inner minimizer yields the improved accelerated running time for the ERM problem (1).\nEach of the three algorithms exhibits a slight advantage over the others in different regimes. APPA has by far the simplest and most straightforward analysis, and applies directly to any \u00b5strongly convex function F (not only F given by (1)). Accelerated APPA is more complicated, but in many regimes is a more efficient reduction than APPA; it too applies to any \u00b5-strongly convex function F and in turn proves Theorem 1.1.\nOur third algorithm, Dual APPA, is the least general in terms of the assumptions on which it relies. It is the only reduction we develop that requires the ERM structure of F . However, this algorithm is a natural choice in conjunction with inner minimizers that operate on a popular dual objective. In Section 5 we demonstrate moreover that this algorithm has properties that make it desirable in practice."}, {"heading": "1.4 Paper organization", "text": "The remainder of this paper is organized as follows. In Section 2, Section 3, and Section 4 we state and analyze the approximate proximal point algorithms described above. In Section 5 we discuss practical concerns and cover numerical experiments involving Dual APPA and related stochastic algorithms. In Appendix A we prove general technical lemmas used throughout the paper and in Appendix B we provide a derivation of regularized ERM duality and related technical lemmas."}, {"heading": "2 Approximate proximal point algorithm (APPA)", "text": "In this section we describe our approximate proximal point algorithm (APPA). This algorithm is perhaps the simplest, both in its description and in its analysis, in comparison to the others described in this paper. This section also introduces technical machinery that is used throughout the sequel.\nWe first present our formal abstraction of inner minimizers (Section 2.1), then we present our algorithm (Section 2.2), and finally we step through its analysis (Section 2.3)."}, {"heading": "2.1 Approximate primal oracles", "text": "To design APPA, we first quantify the error that can be tolerated of an inner minimizer, while accounting for the computational cost of ensuring such error. The abstraction we use is the following notion of inner approximation:\nDefinition 2.1. An algorithm P is a primal (c, \u03bb)-oracle if, given x \u2208 Rd, it outputs P(x) that is a ([fx,\u03bb(x)\u2212 foptx,\u03bb ]/c)-approximate minimizer of fx,\u03bb in time TP . 1\nIn other words, a primal oracle is an algorithm initialized at x that reduces the error of fx,\u03bb by a 1/c fraction, in time that depends on \u03bb, and c, and regularity properties of F . Typical iterative first-order algorithms, such as those in Table 1, yield primal (c, \u03bb)-oracles with runtimes TP that scale inversely in \u03bb or \u221a \u03bb, and logarithmically in c. For instance:\nTheorem 2.2 (SVRG as a primal oracle). SVRG (Johnson and Zhang, 2013) is a primal (c, \u03bb)oracle with runtime complexity TP = O(ndmin{\u03ba, \u03ba\u03bb} log c) for both the ERM problem (1) and the general ERM problem (2).\nTheorem 2.3 (APCG as an accelerated primal oracle). Using APCG (Lin et al., 2014) we can obtain a primal (c, \u03bb)-oracle with runtime complexity TP = O\u0303(nd \u221a \u03ba\u03bb log c) for the ERM problem (1). 2\nProof. Corollary B.3 implies that, given a primal point x, we can obtain, in O(nd) time, a corresponding dual point y such that the duality gap fx,\u03bb(x) + gx,\u03bb(y) (and thus the dual error) is at most O(poly(\u03ba\u03bb)) times the primal error. Lemma B.1 implies that decreasing the dual error by a factor O(poly(\u03ba\u03bb)c) decreases the induced primal error by c. Therefore, applying APCG to the dual and performing the primal and dual mappings yield the theorem."}, {"heading": "2.2 Algorithm", "text": "Our Approximate Proximal Point Algorithm (APPA) is given by the following Algorithm 1.\n1When the oracle is a randomized algorithm, we require that expected error is the same, i.e. that the solution be -approximate in expectation.\n2AP-SDCA could likely also serve as a primal oracle with the same guarantees. However, the results in ShalevShwartz and Zhang (2014) are stated assuming initial primal and dual variables are zero. It is not directly clear how one can provide a generic relative decrease in error from this specific initial primal-dual pair.\nAlgorithm 1 Approximate PPA (APPA)\ninput x(0) \u2208 Rd, \u03bb > 0 input primal (2(\u03bb+\u00b5)\u00b5 , \u03bb)-oracle P\nfor t = 1, . . . , T do x(t) \u2190 P(x(t\u22121))\nend for output x(T )\nThe central goal of this section is to prove the following lemma, which guarantees a geometric convergence rate for the iterates produced in this manner\nLemma 2.4 (Contraction in APPA). For any c\u2032 \u2208 (0, 1), x \u2208 Rd, and possibly randomized primal (\u03bb+\u00b5c\u2032\u00b5 , \u03bb)-oracle P (possibly randomized) we have\nE[F (P(x))]\u2212 F opt \u2264 \u03bb+ c \u2032\u00b5\n\u03bb+ \u00b5\n( F (x)\u2212 F opt ) . (7)\nThis lemma immediately implies the following running-time bounds for APPA.\nTheorem 2.5 (Un-regularizing in APPA). Given a primal (2(\u00b5+\u03bb)\u00b5 , \u03bb)-oracle P, Algorithm 1 minimizes the general ERM problem (2) to within accuracy in time O(TPd\u03bb/\u00b5e log( 0/ )).3\nCombining Theorem 2.5 and Theorem 2.3 immediately yields our desired running time for solving (1).\nCorollary 2.6. Instantiating Algorithm 1 with the Theorem 2.3 as the primal oracle and taking \u03bb = \u00b5 yields the running time of O\u0303(nd \u221a \u03ba log( 0/ )) for solving (1)."}, {"heading": "2.3 Analysis", "text": "This section gives a proof of Lemma 2.4. Throughout, no assumption is made on F aside from \u00b5-strong convexity. Namely, we need not have F be smooth or at all differentiable.\nFirst, we consider the effect of an exact inner minimizer. Namely, we prove the following lemma relating the minimum of the inner problem fs,\u03bb to F opt.\nLemma 2.7 (Relationship between minima). For all s \u2208 Rd and \u03bb \u2265 0\nfopts,\u03bb \u2212 F opt \u2264 \u03bb\n\u00b5+ \u03bb\n( F (s)\u2212 F opt ) .\nProof. Let xopt = argminx F (x) and for all \u03b1 \u2208 [0, 1] let x\u03b1 = (1 \u2212 \u03b1)s + \u03b1xopt. The \u00b5-strong convexity of F implies that, for all \u03b1 \u2208 [0, 1],\nF (x\u03b1) \u2264 (1\u2212 \u03b1)F (s) + \u03b1F (xopt)\u2212 \u03b1(1\u2212 \u03b1)\u00b5\n2 \u2016s\u2212 xopt\u201622.\nConsequently, by the definition of fopts,\u03bb ,\nfopts,\u03bb \u2264 F (x\u03b1) + \u03bb\n2 \u2016x\u03b1 \u2212 s\u201622 \u2264 (1\u2212 \u03b1)F (s) + \u03b1F (xopt)\u2212 \u03b1(1\u2212 \u03b1)\u00b5 2 \u2016s\u2212 xopt\u201622 + \u03bb\u03b12 2 \u2016s\u2212 xopt\u201622\nChoosing \u03b1 = \u00b5\u00b5+\u03bb yields the result.\n3When the oracle is a randomized algorithm, the expected accuracy is at most .\nThis immediately implies contraction for the exact PPA, as it implies that in every iteration of PPA the error in F decreases by a multiplicative \u03bb/(\u03bb+ \u00b5). Using this we prove Lemma 2.4.\nProof of Lemma 2.4. Let x\u2032 = P (x). By definition of primal oracle P we have\nfx,\u03bb(x \u2032)\u2212 foptx,\u03bb \u2264\nc\u2032\u00b5\n\u03bb+ \u00b5\n( fx,\u03bb(x)\u2212 foptx,\u03bb ) .\nCombining this and Lemma 2.7 we have\nfx,\u03bb(x \u2032)\u2212 F opt \u2264 c\n\u2032\u00b5\n\u03bb+ \u00b5\n( fx,\u03bb(x)\u2212 foptx,\u03bb ) + \u03bb\n\u00b5+ \u03bb\n( F (x)\u2212 F opt ) Using that clearly for all z we have F (z) \u2264 fx,\u03bb(z) we see that F (x\u2032) \u2264 fx,\u03bb(x\u2032) and F opt \u2264 foptx,\u03bb . Combining with the fact that fx,\u03bb(x) = F (x) yields the result."}, {"heading": "3 Accelerated APPA", "text": "In this section we show how generically accelerate the APPA algorithm of Section 2. Accelerated APPA (Algorithm 2) uses inner minimizers more efficiently, but requires a smaller minimization factor when compared to APPA. The algorithm and its analysis immediately prove Theorem 1.1 and in turn yield another means by which we achieve the accelerated running time guarantees for solving (1).\nWe first present the algorithm and state its running time guarantees (Section 3.1), then prove the guarantees as part of analysis (Section 3.2)."}, {"heading": "3.1 Algorithm", "text": "Our accelerated APPA algorithm is given by Algorithm 2. In every iteration it still makes a single call to a primal oracle, but rather than requiring a fixed constant minimization the minimization factor depends polynomial on the ratio of \u03bb and \u00b5.\nAlgorithm 2 Accelerated APPA input x(0) \u2208 Rd, \u00b5 > 0, \u03bb > 2\u00b5 input primal (4\u03c13/2, \u03bb)-oracle P, where \u03c1 = \u00b5+2\u03bb\u00b5\nDefine \u03b6 = 2\u00b5 + 1 \u03bb v(0) \u2190 x(0) for t = 0, . . . , T \u2212 1 do y(t) \u2190 ( 1\n1+\u03c1\u22121/2\n) x(t) + ( \u03c1\u22121/2\n1+\u03c1\u22121/2\n) v(t)\nx(t+1) \u2190 P(y(t)) g(t) \u2190 \u03bb(y(t) \u2212 x(t+1)) v(t+1) \u2190 (1\u2212 \u03c1\u22121/2)v(t) + \u03c1\u22121/2 [ y(t) \u2212 \u03b6g(t) ] end for\noutput x(T )\nThe central goal is to prove the following theorem regarding the running time of APPA.\nTheorem 3.1 (Un-regularizing in Accelerated APPA). Given a primal (4(2\u03bb+\u00b5\u00b5 ) 3/2, \u03bb)-oracle P for \u03bb \u2265 2\u00b5, Algorithm 2 minimizes the general ERM problem (2) to within accuracy in time O(TP \u221a d\u03bb/\u00b5e log( 0/ )).\nThis theorem is essentially a restatement of Theorem 1.1 and by instantiating it with Theorem 2.2 we obtain the following.\nCorollary 3.2. Instantiating Theorem 3.1 with SVRG (Johnson and Zhang, 2013) as the primal oracle and taking \u03bb = 2\u00b5 + LR2 yields the running time bound O\u0303(nd \u221a \u03ba log( 0/ )) for the general ERM problem (2)."}, {"heading": "3.2 Analysis", "text": "Here we establish the convergence rate of Algorithm 2, Accelerated APPA, and prove Theorem 3.1. Note that as in Section 2 the results in this section use nothing about the structure of F other than strong convexity and thus they apply to the general ERM problem (2).\nWe remark that aspects of the proofs in this section bear resemblance to the analysis in ShalevShwartz and Zhang (2014), which achieves similar results in a more specialized setting.\nOur proof is split into the following parts.\n\u2022 In Lemma 3.3 we show that applying a primal oracle to the inner minimization problem gives us a quadratic lower bound on F (x).\n\u2022 In Lemma 3.4 we use this lower bound to construct a series of lower bounds for the main objective function f , and accelerate the APPA algorithm, comprising the bulk of the analysis.\n\u2022 In Lemma 3.5 we show that the requirements of Lemma 3.4 can be met by using a primal oracle that decreases the error by a constant factor.\n\u2022 In Lemma 3.6 we analyze the initial error requirements of Lemma 3.4.\nThe proof of Theorem 3.1 follows immediately from these lemmas.\nLemma 3.3. For x0 \u2208 Rn and > 0 suppose that x+ is an -approximate solution to fx0,\u03bb. Then for \u00b5\u2032 def = \u00b5/2, g def = \u03bb(x0 \u2212 x+), and all x \u2208 Rn we have\nF (x) \u2265 F (x+)\u2212 1 2\u00b5\u2032 \u2016g\u20162 + \u00b5\n\u2032\n2 \u2225\u2225\u2225\u2225x\u2212 (x0 \u2212 ( 1\u00b5\u2032 + 1\u03bb ) g )\u2225\u2225\u2225\u22252 2 \u2212 \u03bb+ 2\u00b5 \u2032 \u00b5\u2032 .\nNote that as \u00b5\u2032 = \u00b5/2 we are only losing a factor of 2 in the strong convexity parameter for our lower bound. This allows us to account for errors without sacrificing in our ultimate asymptotic convergence rates.\nProof. Since F is \u00b5-strongly convex clearly fx0,\u03bb is \u00b5+ \u03bb strongly convex, by Lemma A.1\nfx0,\u03bb(x)\u2212 fx0,\u03bb(x opt x0,\u03bb ) \u2265 \u00b5+ \u03bb 2 \u2016x\u2212 xopt\u201622. (8)\nBy Cauchy-Schwartz and Young\u2019s Inequality we know that\n\u03bb+ \u00b5\u2032\n2 \u2016x\u2212 x+\u201622 \u2264\n\u03bb+ \u00b5\u2032\n2\n( \u2016x\u2212 xoptx0,\u03bb\u2016 2 2 + \u2016x opt x0,\u03bb \u2212 x+\u201622 ) + \u00b5\u2032 2 \u2016x\u2212 xoptx0,\u03bb\u2016 2 2 + (\u03bb+ \u00b5\u2032)2 2\u00b5\u2032 \u2016xoptx0,\u03bb \u2212 x +\u201622,\nwhich implies\n\u00b5+ \u03bb\n2 \u2016x\u2212 xoptx0,\u03bb\u2016 2 2 \u2265\n\u03bb+ \u00b5\u2032\n2 \u2016x\u2212 x+\u201622 \u2212\n\u03bb+ \u00b5\u2032\n\u00b5\u2032 \u00b7 \u03bb+ \u00b5 2 \u2016xoptx0,\u03bb \u2212 x +\u201622.\nOn the other hand, since fx0,\u03bb(x +) \u2264 fx0,\u03bb(x opt x0,\u03bb )+ by assumption we have \u03bb+\u00b52 \u2016x +\u2212xopt\u201622 \u2264\nand therefore\nfx0,\u03bb(x)\u2212 fx0,\u03bb(x+) \u2265 fx0,\u03bb(x)\u2212 fx0,\u03bb(x opt x0,\u03bb )\u2212 \u2265 \u00b5+ \u03bb 2 \u2016x\u2212 xoptx0,\u03bb\u2016 2 2 \u2212\n\u2265 \u03bb+ \u00b5 \u2032\n2 \u2016x\u2212 x+\u201622 \u2212\n\u03bb+ \u00b5\u2032\n\u00b5\u2032 \u00b7 \u03bb+ \u00b5 2 \u2016xoptx0,\u03bb \u2212 x +\u201622 \u2212\n\u2265 \u03bb+ \u00b5 \u2032\n2 \u2016x\u2212 x+\u201622 \u2212\n\u03bb+ 2\u00b5\u2032\n\u00b5\u2032 .\nNow since\n\u2016x\u2212 x+\u201622 = \u2016x\u2212 x0 + 1\n\u03bb g\u201622 = \u2016x\u2212 x0\u20162 +\n2 \u03bb \u3008g, x\u2212 x0\u3009+ 1 \u03bb2 \u2016g\u201622,\nand using the fact that fx0,\u03bb(x) = F (x) + \u03bb 2\u2016x\u2212 x0\u2016 2 2, we have\nF (x) \u2265F (x+) + [ 1\n\u03bb +\n\u00b5\u2032\n2\u03bb2\n] \u2016g\u201622 + ( 1 + \u00b5\u2032\n\u03bb\n) \u3008g, x\u2212 x0\u3009+ \u00b5\u2032\n2 \u2016x\u2212 x0\u20162 \u2212\n\u03bb+ 2\u00b5\u2032\n\u00b5\u2032 .\nThe right hand side of the above equation is a quadratic function. Looking at its gradient with respect to x we see that it obtains its minimum when x = x0\u2212 ( 1\u00b5\u2032 + 1 \u03bb)g and has a minimum value of F (x+)\u2212 12\u00b5\u2032 \u2016g\u2016 2 2 \u2212 \u03bb+2\u00b5\u2032 \u00b5\u2032 .\nLemma 3.4. Suppose that in each iteration t we have \u03c8t def = \u03c8optt +\n\u00b5\u2032 2 \u2016x\u2212 v (t)\u201622 such that F (x) \u2265\n\u03c8t(x) for all x. Let \u03c1 def = \u00b5 \u2032+\u03bb \u00b5\u2032 for \u03bb \u2265 3\u00b5 \u2032, and let\n\u2022 y(t) def= (\n1 1+\u03c1\u22121/2\n) x(t) + ( \u03c1\u22121/2\n1+\u03c1\u22121/2\n) v(t),\n\u2022 E[fy(t),\u03bb(x(t+1))]\u2212 f opt y(t),\u03bb \u2264 \u03c1\n\u22123/2\n4 (F (x (t))\u2212 \u03c8optt ),\n\u2022 g(t) def= \u03bb(y(t) \u2212 x(t+1)),\n\u2022 v(t+1) def= (1\u2212 \u03c1\u22121/2)v(t) + \u03c1\u22121/2 [ y(t) \u2212 ( 1 \u00b5\u2032 + 1 \u03bb ) g(t) ] .\nWe have\nE[F (x(t))\u2212 \u03c8optt ] \u2264\n( 1\u2212 \u03c1 \u22121/2\n2\n)t (F (x0)\u2212 \u03c8opt0 ).\nProof. Regardless of how y(t) is chosen we know by Lemma 3.3 that for \u03b3 = 1 + \u00b5 \u2032\n\u03bb and all x \u2208 R n\nF (x) \u2265 F (x(t+1))\u2212 1 2\u00b5\u2032 \u2016g(t)\u201622+\n\u00b5\u2032\n2 \u2225\u2225\u2225\u2225x\u2212 (y(t) \u2212 \u03b3\u00b5\u2032 g(t) )\u2225\u2225\u2225\u22252\n2\n\u2212 \u03bb+ 2\u00b5 \u2032\n\u00b5\u2032\n( fy(t),\u03bb(x (t+1))\u2212 fopt y(t),\u03bb ) . (9)\nThus, for \u03b2 = 1\u2212 \u03c1\u22121/2 we can let\n\u03c8t+1(x) def = \u03b2\u03c8t(x) + (1\u2212 \u03b2) [ F (x(t+1))\u2212 1\n2\u00b5\u2032 \u2016g(t)\u201622 +\n\u00b5\u2032 2 \u2016x\u2212\n( y(t) \u2212 \u03b3 \u00b5\u2032 g(t) ) \u201622\n\u2212 \u03bb+ 2\u00b5 \u2032\n\u00b5\u2032 (fy(t),\u03bb(x\n(t+1))\u2212 fopt y(t),\u03bb ) ] = \u03b2 [ \u03c8optt + \u00b5\u2032\n2 \u2016x\u2212 v(t)\u201622\n] + (1\u2212 \u03b2) [ F (x(t+1))\u2212 1\n2\u00b5\u2032 \u2016g(t)\u201622 +\n\u00b5\u2032 2 \u2016x\u2212\n( y(t) \u2212 \u03b3 \u00b5\u2032 g(t) ) \u201622\n\u2212 \u03bb+ 2\u00b5 \u2032\n\u00b5\u2032 (fy(t),\u03bb(x\n(t+1))\u2212 fopt y(t),\u03bb ) ] = \u03c8optt+1 + \u00b5\u2032\n2 \u2016x\u2212 v(t+1)\u201622.\nwhere in the last line we used Lemma A.3. Again, by Lemma A.3 we know that \u03c8optt+1 = \u03b2\u03c8t + (1\u2212 \u03b2) ( F (x(t+1))\u2212 1\n2\u00b5\u2032 \u2016g(t)\u201622 \u2212\n\u03bb+ 2\u00b5\u2032\n\u00b5\u2032 (fy(t),\u03bb(x\n(t+1))\u2212 fopt y(t),\u03bb ) ) + \u03b2(1\u2212 \u03b2)\u00b5 \u2032\n2 \u2016v(t) \u2212\n( y(t) \u2212 \u03b3 \u00b5\u2032 g(t) ) \u201622\n\u2265 \u03b2\u03c8t + (1\u2212 \u03b2)F (x(t+1))\u2212 (1\u2212 \u03b2)2\n2\u00b5\u2032 \u2016g(t)\u201622 + \u03b2(1\u2212 \u03b2)\u03b3\n\u2329 g(t), v(t) \u2212 y(t) \u232a \u2212 (1\u2212 \u03b2)(\u03bb+ 2\u00b5 \u2032)\n\u00b5\u2032 (fy(t),\u03bb(x\n(t+1))\u2212 fopt y(t),\u03bb ).\nIn the second step we used the following fact:\n\u22121\u2212 \u03b2 2\u00b5\u2032 + \u03b2(1\u2212 \u03b2)\u00b5 \u2032 2 \u00b7 \u03b3 2 \u00b5\u2032 = 1\u2212 \u03b2 2\u00b5\u2032 (\u22121 + \u03b2\u03b32) \u2265 \u2212(1\u2212 \u03b2) 2 2\u00b5\u2032 .\nFurthermore, expanding the term \u00b52\u2016(x\u2212 y (t)) + \u03b3\u00b5g (t)\u201622 and instantiating x with x(t) in (9) yields\nF (x(t+1)) \u2264 F (x(t))\u2212 1 \u03bb \u2016g(t)\u201622 + \u03b3\n\u2329 g(t), y(t) \u2212 x(t) \u232a + \u03bb+ 2\u00b5\u2032\n\u00b5\u2032 (fy(t),\u03bb(x\n(t+1))\u2212 fopt y(t),\u03bb ).\nConsequently we know\nF (x(t+1))\u2212 \u03c8optt+1 \u2264 \u03b2[f(x (t))\u2212 \u03c8optt ] +\n[ (1\u2212 \u03b2)2\n2\u00b5\u2032 \u2212 \u03b2 \u03bb\n] \u2016g(t)\u201622 + \u03b3\u03b2 \u2329 g(t), y(t) \u2212 x(t) \u2212 (1\u2212 \u03b2)(v(t) \u2212 y(t)) \u232a + (\u03bb+ 2\u00b5\u2032)\n\u00b5\u2032 (fy(t),\u03bb(x\n(t+1))\u2212 fopt y(t),\u03bb )\nNote that we have chosen y(t) so that the inner product term equals 0, and we choose \u03b2 = 1\u2212\u03c1\u22121/2 \u2265 1 2 which ensures\n(1\u2212 \u03b2)2\n2\u00b5\u2032 \u2212 \u03b2 \u03bb \u2264 1 2(\u00b5\u2032 + \u03bb) \u2212 1 2\u03bb \u2264 0.\nAlso, by assumption we know E[fy(t),\u03bb(x(t+1))\u2212 f opt y(t),\u03bb ] \u2264 \u03c1\n\u22123/2\n4 (f(x (t))\u2212 \u03c8optt ), which implies\nE[F (x(t+1))\u2212 \u03c8optt+1] \u2264\n( \u03b2 + (\u03bb+ 2\u00b5\u2032)\n\u00b5\u2032 \u00b7 \u03c1 \u22123/2 4 ) (F (x(t))\u2212 \u03c8optt ) \u2264 (1\u2212 \u03c1\u22121/2/2)(F (x(t))\u2212 \u03c8 opt t ).\nIn the final step we are using the fact that \u03bb+2\u00b5 \u2032\n\u00b5\u2032 \u2264 2\u03c1 and \u03c1 \u2265 1.\nLemma 3.5. Under the setting of Lemma 3.4, we have fy(t),\u03bb(x (t)) \u2212 fopt y(t),\u03bb \u2264 F (x(t)) \u2212 \u03c8optt . In particular, in order to achieve E[fy(t),\u03bb(x(t+1))] \u2264 \u03c1\u22123/2 8 (F (x (t))\u2212\u03c8optt ) we only need an oracle that shrinks the function error by a factor of \u03c1 \u22123/2\n8 (in expectation).\nProof. We know\nfy(t),\u03bb(x (t))\u2212 f(x(t)) = \u03bb\n2 \u2016x(t) \u2212 y(t)\u201622 =\n\u03bb 2 \u00b7 \u03c1\n\u22121\n(1 + \u03c1\u22121/2)2 \u2016x(t) \u2212 v(t)\u201622.\nWe will try to show the lower bound fopt y(t),\u03bb is larger than \u03c8optt by the same amount. This is because for all x we have\nfy(t),\u03bb(x) = F (x) + \u03bb\n2 \u2016x\u2212 y(t)\u201622 \u2265 \u03c8 opt t +\n\u00b5\u2032 2 \u2016x\u2212 v(t)\u201622 + \u03bb 2 \u2016x\u2212 y(t)\u201622.\nThe right hand side is a quadratic function, whose optimal point is at x = \u00b5 \u2032v(t)+\u03bby(t)\n\u00b5\u2032+\u03bb and whose optimal value is equal to\n\u03c8optt + \u03bb\n2\n( \u00b5\u2032\n\u00b5\u2032 + \u03bb\n)2 \u2016v(t)\u2212y(t)\u201622+ \u00b5\u2032\n2\n( \u03bb\n\u00b5+ \u03bb\n)2 \u2016v(t)\u2212y(t)\u201622 = \u03c8 opt t + \u00b5\u2032\u03bb\n2(\u00b5\u2032 + \u03bb) \u00b7 1 (1 + \u03c1\u22121/2)2 \u2016x(t)\u2212v(t)\u201622.\nBy definition of \u03c1\u22121, we know \u00b5 \u2032\u03bb\n2(\u00b5\u2032+\u03bb) \u00b7 1 (1+\u03c1\u22121/2)2 \u2016x(t)\u2212v(t)\u201622 is exactly equal to \u03bb2 \u00b7\n\u03c1\u22121\n(1+\u03c1\u22121/2)2 \u2016x(t)\u2212\nv(t)\u201622, therefore fy(t),\u03bb(x(t))\u2212 f opt y(t),\u03bb \u2264 F (x(t))\u2212 \u03c8optt .\nRemark In the next lemma we show that moving to the regularized problem has the same effect on the primal function value and the lower bound. This is a result of the choice of \u03b2 in the proof of Lemma 3.4. However, this does not mean that the choice of \u03b2 is very fragile. We can choose any \u03b2\u2032 that is between the current \u03b2 and 1; the effect on this lemma will be that the increase in primal function becomes smaller than the increase in the lower bound (so the lemma continues to hold).\nLemma 3.6. Let \u03c8opt0 = F (x (0)) \u2212 \u03bb+2\u00b5\n\u2032\n\u00b5\u2032 (F (x (0)) \u2212 fopt), and v(0) = x(0), then \u03c80 def = \u03c8opt0 +\n\u00b5\u2032\n2 \u2016x \u2212 v0\u2016 2 is a valid lower bound for F . In particular when \u03bb = LR2 then F (x(0)) \u2212 \u03c8opt0 \u2264\n2\u03ba(F (x(0))\u2212 fopt).\nProof. This lemma is a direct corollary of Lemma 3.3 with x+ = x(0)."}, {"heading": "4 Dual APPA", "text": "In this section we develop Dual APPA (Algorithm 3), a natural approximate proximal point algorithm that operates entirely in the regularized ERM dual. Our focus here is on theoretical properties of Dual APPA; Section 5 later explores aspects of Dual APPA more in practice.\nWe first present an abstraction for dual-based inner minimizers (Section 4.1), then present the algorithm (Section 4.2), and finally step through its runtime analysis (Section 4.3)."}, {"heading": "4.1 Approximate dual oracles", "text": "Our primary goal in this section is to quantify how much objective function progress an algorithm needs to make in the dual problem, gs,\u03bb (See Section 1.1) in order to ensure primal progress at a rate similar to that in APPA (Algorithm 1).\nHere, similar to Section 2.1, we formally define our requirements for an approximate dual-based inner dual minimize. In particular, we use the following notion of dual oracle.\nDefinition 4.1. An algorithm D is a dual (c, \u03bb)-oracle if, given s \u2208 Rd and y \u2208 Rn, it outputs D(s, y) that is a ([gs,\u03bb(y)\u2212 gopts,\u03bb ]/c)-approximate minimizer of gs,\u03bb in time TD. 4\nDual based algorithms for regularized ERM and variants of coordinate descent typically can be used as such a dual oracle. In particular we note that APCG is such a dual oracle.\nTheorem 4.2 (APCG as a dual oracle). APCG (Lin et al., 2014) is a dual (c, \u03bb)-oracle with runtime complexity TD = O\u0303(nd \u221a \u03ba\u03bb log c). 5"}, {"heading": "4.2 Algorithm", "text": "Our dual APPA is given by the following Algorithm 3.\nAlgorithm 3 Dual APPA input x(0) \u2208 Rd, \u03bb > 0 input dual (\u03c3, \u03bb)-oracle D (see Theorem 4.3 for \u03c3) y(0) \u2190 y\u0302(x(0)) for t = 1, . . . , T do y(t) \u2190 D(x(t\u22121), y(t\u22121)) x(t) \u2190 x\u0302x(t\u22121),\u03bb(y(t))\nend for output x(T )\nDual APPA (Algorithm 3) repeatedly queries a dual oracle while producing primal iterates via the dual-to-primal mapping (5) along the way. We show that it obtains the following running time bound:\nTheorem 4.3 (Un-regularizing in Dual APPA). Given a dual (\u03c3, \u03bb)-oracle D, where\n\u03c3 \u2265 80n2\u03ba2\u03bb max{\u03ba, \u03ba\u03bb}d\u03bb/\u00b5e\nAlgorithm 3 minimizes the ERM problem (1) to within accuracy in time O\u0303(TDd\u03bb/\u00b5e log( 0/ )).6\nCombining Theorem 4.3 and Theorem 4.2 immediately yields another way to achieve our desired running time for solving (1).\n4As in the primal oracle definition, when the oracle is a randomized algorithm, we require that its output be an expected -approximate solution.\n5As in Theorem 2.3, AP-SDCA could likely also serve as a dual oracle with the same guarantees, provided it is modified to allow for the more general primal-dual initialization.\n6As in Theorem 2.5, when the oracle is a randomized algorithm, the expected accuracy is at most .\nCorollary 4.4. Instantiating Theorem 4.3 with Theorem 4.2 as the dual oracle and taking \u03bb = \u00b5 yields the running time bound O\u0303(nd \u221a \u03ba log( 0/ )).\nWhile both this result and the results in Section 2 show that APCG can be used to achieve our fastest running times for solving (1), note that the algorithms they suggest are in fact different. In every invocation of APCG in Algorithm 1, we need to explicitly compute both the primal-to-dual and dual-to-primal mappings (in O(nd) time). However, here we only need to compute the primalto-dual mapping once upfront, in order to initialize the algorithm. Every subsequent invocation of APCG then only requires a single dual-to-primal mapping computation, which can often be streamlined. From a practical viewpoint, this can be seen as a natural \u201cwarm start\u201d scheme for the dual-based inner minimizer."}, {"heading": "4.3 Analysis", "text": "Here we proves Theorem 4.3. We begin by bounding the error of the dual regularized ERM problem when the center of regularization changes. This characterizes the initial error at the beginning of each Dual APPA iteration.\nLemma 4.5 (Dual error after re-centering.). For all y \u2208 Rn, x \u2208 Rd, and x\u2032 = x\u0302x(y) we have\ngx\u2032,\u03bb(y)\u2212 goptx\u2032,\u03bb \u2264 2(gx,\u03bb(y)\u2212 g opt x,\u03bb) + 4n\u03ba\n[ F (x\u2032)\u2212 F opt + F (x)\u2212 F opt ] In other words, the dual error gs,\u03bb(y)\u2212 gopts,\u03bb is bounded across a re-centering step by multiples\nof previous sub-optimality measurements (namely, dual error and gradient norm).\nProof. By the definition of gx,\u03bb and x \u2032 we have, for all z,\ngx\u2032,\u03bb(z) = G(z) + 1 2\u03bb \u2016ATz\u20162 \u2212 x\u2032TATz = gx,\u03bb(z)\u2212 (x\u2032 \u2212 x)>ATz = gx,\u03bb(z) + 1 \u03bb yTAATz .\nFurthermore, since g is 1L -strongly convex we can invoke Lemma A.2 obtaining\ngx\u2032,\u03bb(y)\u2212 goptx\u2032,\u03bb \u2264 2 [ gx,\u03bb(y)\u2212 goptx\u2032,\u03bb ] + L \u2225\u2225\u2225\u2225 1\u03bbAATy \u2225\u2225\u2225\u22252 2 .\nSince each row of A has `2 norm at most R we know that \u2016Az\u201622 \u2264 nR2\u2016z\u201622 and we know that by definition ATy = \u03bb(x\u2212 x\u2032). Combining these yields\ngx\u2032,\u03bb(y)\u2212 goptx\u2032,\u03bb \u2264 2 [ gx,\u03bb(y)\u2212 goptx\u2032,\u03bb ] + nLR2\u2016x\u2212 x\u2032\u201622.\nFinally, since F is \u00b5-strongly convex, by Lemma A.1, we have\n1 2 \u2016x\u2212 x\u2032\u201622 \u2264 \u2016x\u2032 \u2212 xopt\u201622 + \u2016x\u2212 xopt\u201622 \u2264 2 \u00b5\n[ F (x\u2032)\u2212 F opt + F (x)\u2212 F opt ] .\nCombining and recalling the definition of \u03ba yields the result.\nThe following lemma establishes the rate of convergence of the primal iterates {x(t)} produced over the course of Dual APPA, and in turn implies Theorem 4.3.\nLemma 4.6 (Convergence rate of Dual APPA). Let c\u2032 \u2208 (0, 1) be arbitrary and suppose that \u03c3 \u2265 (40/c\u2032)n2\u03ba2\u03bb max{\u03ba, \u03ba\u03bb}d\u03bb/\u00b5e in Dual APPA (Algorithm 3). Then in every iteration t \u2265 1 of Dual APPA (Algorithm 3) the following invariants hold:\nF (x(t\u22121))\u2212 F opt \u2264 ( \u03bb+ c\u2032\u00b5\n\u03bb+ \u00b5\n)t\u22121 ( F (x(0))\u2212 F opt ) , and (10)\ngx(t\u22121),\u03bb(y (t))\u2212 gopt x(t\u22121),\u03bb \u2264 ( \u03bb+ c\u2032\u00b5\n\u03bb+ \u00b5\n)t\u22121 ( F (x(0))\u2212 F opt ) . (11)\nProof. For notational convenience we let r def = (\u03bb+c \u2032\u00b5 \u03bb+\u00b5 ), gt def = gx(t),\u03bb, ft def = fx(t),\u03bb, and t def = F (x(t))\u2212 F opt for all t \u2265 0. Thus, we wish to show that t\u22121 \u2264 rt\u22121 0 (equivalent to (11)) and we wish to show that gt\u22121(y\n(t))\u2212 goptt\u22121 \u2264 rt\u22121 0 (equivalent to (10)) for all t \u2265 1. By definition of a dual oracle we have, for all t \u2265 1,\ngt\u22121(y (t))\u2212 goptt\u22121 \u2264\n1\n\u03c3\n[ gt\u22121(yt\u22121)\u2212 goptt\u22121 ] , (12)\nby Lemma B.1 we have, for all t \u2265 1,\nft\u22121(x (t))\u2212 foptt\u22121 \u2264 2n 2\u03ba2\u03bb [ gt\u22121(y (t))\u2212 goptt\u22121 ] , (13)\nby Lemma 4.5 we know\ngt(y (t))\u2212 goptt \u2264 2 [ gt\u22121(y (t))\u2212 goptt ] + 4n\u03ba( t + t\u22121), (14)\nand by Lemma 2.7 we know that for all t \u2265 1\nfoptt\u22121 \u2212 F opt \u2264 \u03bb\n\u00b5+ \u03bb t\u22121 (15)\nFurthermore, by Corollary B.3, the definition of y(0), and the facts that f0(x (0)) = F (x(0)) and ft(z) \u2265 F (z) we have\ng0(y (0))\u2212 gopt0 \u2264 2\u03ba\u03bb ( f0(x (0))\u2212 fopt0 ) \u2264 2\u03ba\u03bb ( F (x(0))\u2212 F opt ) = 2\u03ba\u03bb 0 (16)\nWe show that combining these and applying strong induction on t yields the desired result. We begin with our base cases. When t = 1 the invariant (11) holds immediately by definition. Furthermore, when t = 1 we see that the invariant (10) holds, since \u03c3 \u2265 2\u03ba\u03bb and\ng0(y (1))\u2212 gopt0 \u2264\n1 \u03c3 (g0(y (0))\u2212 gopt0 ) \u2264 2\u03ba\u03bb \u03c3\n( f0(x (0))\u2212 fopt0 ) \u2264 2\u03ba\u03bb\n\u03c3 0, (17)\nwere we used (12) and (16) respectively. Finally we show that invariant (11) holds for t = 2:\nF (x(1))\u2212 F opt \u2264 f0(x(1))\u2212 fopt0 + f opt 0 \u2212 F opt (Since F (z) \u2264 ft(z) for all t, z)\n\u2264 2n2\u03ba2\u03bb(g0(y(1))\u2212 g opt 0 ) +\n\u03bb\n\u00b5+ \u03bb 0 (Equations (13) and (15)) \u2264 (\n4n2\u03ba3\u03bb \u03c3 + \u03bb \u00b5+ \u03bb\n) 0 (Equation (17))\n\u2264 r 0 (Since \u03c3 \u2265 4n\u03ba3\u03bb/(c\u2032\u03bb/(\u00b5+ \u03bb)))\nNow consider t \u2265 3 for the second invariant (11). We show this holds assuming the invariants hold for all smaller t.\nF (x(t\u22121))\u2212 F opt \u2264 ft\u22122(x(t\u22121))\u2212 foptt\u22122 + f opt t\u22122 \u2212 F opt (Since F (z) \u2264 ft(z) for all t, z)\n\u2264 2n2\u03ba2\u03bb(gt\u22122(yt\u22121)\u2212 g opt t\u22122) +\n\u03bb\n\u00b5+ \u03bb t\u22122 (Equations (13) and (15))\n\u2264 2n2\u03ba2\u03bb \u03c3 ( gt\u22122(yt\u22122)\u2212 goptt\u22122 ) + \u03bb \u00b5+ \u03bb t\u22122 (Equation (12))\nFurthermore,\ngt\u22122(yt\u22122)\u2212 goptt\u22122 \u2264 2(gt\u22123(yt\u22122)\u2212 g opt t\u22123) + 4n\u03ba [ t\u22122 + t\u22123] (Equation (17)) \u2264 ( 2rt\u22122 + 4n\u03ba(rt\u22121 + rt\u22122) ) 0 (Inductive hypothesis)\n\u2264 10n\u03bart\u22121 0 (r \u2264 1 and \u03ba \u2265 1)\nSince \u03c3 \u2265 20n2\u03ba2\u03bb\u03ba/(c\u2032\u03bb/(\u00b5+ \u03bb)) combining yields that\n2n2\u03ba2\u03bb \u03c3 ( gt\u22122(yt\u22122)\u2212 goptt\u22122 ) \u2264 c \u2032\u00b5 \u00b5+ \u03bb rt\u22121 0\nand the result follows by the inductive hypothesis on t\u22122. Finally we show that invariant (10) holds for any t \u2265 2 given that it holds for all smaller t and invariant (11) holds for that t and all smaller t.\ngt\u22121(y (t))\u2212 goptt\u22121 \u2264\n1 \u03c3 (gt\u22121(yt\u22121)\u2212 goptt\u22121) (Definition dual oracle.)\n\u2264 1 \u03c3\n[ 2(gx(t\u22122)(yt\u22121)\u2212 g opt x(t\u22122) ) + 4n\u03ba [ t\u22121 + t\u22122] ] (Equation (14))\n\u2264 1 \u03c3\n[ 2rt\u22121 + 4n\u03ba [ rt + rt\u22121 ]] 0 (Inductive hypothesis)\n\u2264 rt\u22121 0 (\u03c3 \u2265 8n\u03ba)\nThe result then follows by induction."}, {"heading": "5 Implementation", "text": "In the following two subsections, respectively, we discuss implementation details and report on an empirical evaluation of the APPA framework."}, {"heading": "5.1 Practical concerns", "text": "While theoretical convergence rates lay out a broad-view comparison of the algorithms in the literature, we briefly remark on some of the finer-grained differences between algorithms, which inform their implementation or empirical behavior. To match the terminology used for SVRG in Johnson and Zhang (2013), we refer to a \u201cstage\u201d as a single step of APPA, i.e. the time spent executing the inner minimization of fx(t),\u03bb or gx(t),\u03bb (as in (3) and (4)).\nRe-centering overhead of Dual APPA vs. SVRG At the end of every one of its stages, SVRG pauses to compute an exact gradient by a complete pass over the dataset (costing \u0398(nd) time during which n gradients are computed). Although an amortized runtime analysis hides this cost, this operation cannot be carried out in-step with the iterative updates of the previous stage, since the exact gradient is computed at a point that is only selected at the stage\u2019s end.\nMeanwhile, if each stage in Dual APPA is initialized with a valid primal-dual pair for the inner problem, Dual APPA can update the current primal point together with every dual coordinate update, in time O(d), i.e. with negligible increase in the overhead of the update. When doing so, the corresponding data row remains fresh in cache and, unlike SVRG, no additional gradient need be computed.\nMoreover, initializing each stage with a valid such primal-dual pair can be done in only O(d) time. At the end of a stage where s was the center point, Dual APPA holds a primal-dual pair (x, y) where x = x\u0302s(y). The next stage is centered at x and the dual variables initialized at y, so it remains to set up a corresponding primal point x\u2032 = x\u0302x(y) = x \u2212 1\u03bbA\nTy. This can be done by computing x\u2032 \u2190 2x\u2212 s, since we know that x\u2212 s = \u2212 1\u03bbA Ty.\nDecreasing \u03bb APPA and Dual APPA enjoy the nice property that, as long as the inner problems are solved with enough accuracy, the algorithm does not diverge even for large choice of \u03bb. In practice this allows us to start with a large \u03bb and make faster inner minimizations. If we heuristically observe that the function error is not decreasing rapidly enough, we can switch to a smaller \u03bb. Figure 3 (Section 5.2) demonstrates this empirically. This contrasts with algorithm parameters such as step size choices in stochastic optimizers (that may still appear in inner minimization). Such parameters are typically more sensitive, and can suddenly lead to divergence when taken too large, making them less amenable to mid-run parameter tuning.\nStable update steps When used as inner minimizers, dual coordinate-wise methods such as SDCA typically provide a convenient framework in which to derive parameter updates with datadependent step sizes, or sometimes enables closed-form updates altogether (i.e. optimal solutions to each single-coordinate maximization sub-problem). For example, when Dual APPA is used together with SDCA to solve a problem of least-squares or ridge regression, the locally optimal SDCA updates can be performed efficiently in closed form. This decreases the number of algorithmic parameters requiring tuning, improves the overall the stability of the end-to-end optimizer and, in turn, makes it easier to use out of the box."}, {"heading": "5.2 Empirical analysis", "text": "We experiment with Dual APPA in comparison with SDCA, SVRG, and SGD on several binary classification tasks.\nBeyond general benchmarking, the experiments also demonstrate the advantages of the unordinary \u201cbias-variance tradeoff\u201d presented by approximate proximal iteration: the vanishing proximal term empirically provides advantages of regularization (added strong convexity, lower variance) at a bias cost that is less severe than with typical `2 regularization. Even if some amount of `2 shrinkage is desired, Dual APPA can place yet higher weight on its `2 term, enjoy improved speed and stability, and after a few stages achieve roughly the desired bias.\nDatasets In this section we show results for three binary classification tasks, derived from MNIST,7 CIFAR-10,8 and Protein:9 in MNIST we classify the digits {1, 2, 4, 5, 7} vs. the rest, and in CIFAR we classify the animal categories vs. the automotive ones. MNIST and CIFAR are taken under non-linear feature transformations that increase the problem scale significantly: we normalize the rows by scaling the data matrix by the inverse average `2 row norm. We then take take n/5 random Fourier features per the randomized scheme of Rahimi and Recht (2007). This yields 12K features for MNIST (60K training examples, 10K test) and 10K for CIFAR (50K training examples, 10K test). Meanwhile, Protein is a standard pre-featurized benchmark (75 features, \u223c117K training examples, \u223c30K test) that we preprocess minimally by row normalization and an appended affine feature, and whose train/test split we obtain by randomly holding out 20% of the original labeled data.\nAlgorithms Each algorithm is parameterized by a scalar value \u03bb analogous to the \u03bb used in proximal iteration: \u03bb is the step size for SVRG, \u03bbt\u22121/2 is the decaying step size for SGD, and \u03bb 2\u2016x\u2016 2 2 is the ridge penalty for SDCA. (See Johnson and Zhang (2013) for a comparison of SVRG to a more thoroughly tuned SGD under different decay schemes.) We use Dual APPA (Algorithm 3) with SDCA as the inner minimizer. For the algorithms with a notion of a stage \u2013 i.e. Dual APPA\u2019s time spent invoking the inner minimizer, SVRG\u2019s period between computing exact gradients \u2013 we set the stage size equal to the dataset size for simplicity.10 SVRG is given an advantage in that we choose not to count its gradient computations when it computes the exact gradient between stages. All algorithms are initialized at x = 0. Each algorithm was run under \u03bb = 10i for i = \u22128,\u22127, . . . , 8, and plots report the trial that best minimized the original ERM objective.\nConvergence and bias The proximal term in APPA introduces a vanishing bias for the problem (towards the initial point of x = 0) that provides a speedup by adding strong convexity to the problem. We investigate a natural baseline: for the purpose of minimizing the original ERM problem, how does APPA compare to solving one instance of a regularized ERM problem (using a single run of its inner optimizer)? In other words, to what extent does re-centering the regularizer over time help in solving the un-regularized problem? Intuitively, even if SDCA is run to convergence, some of the minimization is of the regularization term rather than the ERM term, hence one cannot weigh the regularization too heavily. Meanwhile, APPA can enjoy more ample strong convexity by placing a larger weight on its `2 term. This advantage is evident for MNIST and CIFAR in Figures 1 and 2: recalling that \u03bb is the same strong convexity added both by APPA and by SDCA, we see that APPA takes \u03bb at least an order of magnitude larger than SDCA does, to achieve faster and more stable convergence towards an ultimately lower final value.\nFigure 1 also shows dashed lines corresponding to the ERM performance of the least-squares fit and of fully-optimized ridge regression, using \u03bb as that of the best APPA and SDCA runs. These appear in the legend as \u201cls(\u03bb).\u201d They indicate lower bounds on the ERM value attainable by any algorithm that minimizes the corresponding regularized ERM objective. Lastly, test set classification accuracy demonstrates the extent to which a shrinkage bias is statistically desirable.\n7http://yann.lecun.com/exdb/mnist/ 8http://www.cs.toronto.edu/\u223ckriz/cifar.html 9http://osmot.cs.cornell.edu/kddcup/datasets.html\n10Such a choice is justified by the observation that doubling the stage size does not have noticeable effect on the results discussed.\nIn the MNIST and CIFAR holdout, we want only the small bias taken explicitly by SDCA (and effectively achieved by APPA). In the Protein holdout, we want no bias at all (again effectively achieved by APPA).\nParameter sensitivity By solving only regularized ERM inner problems, SDCA and APPA enjoy a stable response to poor specification of the biasing parameter \u03bb. Figure 3 plots the algorithms\u2019 final value after 20 stages, against different choices of \u03bb. Overestimating the step size in SGD or SVRG incurs a sharp transition into a regime of divergence. Meanwhile, APPA and SDCA always converge, with solution quality degrading more smoothly. APPA then exhibits an even better degradation as it overcomes an overaggressive biasing by the 20th stage."}, {"heading": "Acknowledgments", "text": "Part of this work took place while RF and AS were at Microsoft Research, New England, and another part while AS was visiting the Simons Institute for the Theory of Computing, UC Berkeley. This work was partially supported by NSF awards 0843915 and 1111109, NSF Graduate Research Fellowship (grant no. 1122374)."}, {"heading": "A Technical lemmas", "text": "In this section we provide several stand-alone technical lemmas we use throughout the paper. First we provide Lemma A.1 some common inequalities regarding smooth or strongly convex functions, then Lemma A.2 which shows the effect of adding a linear term to a convex function, and then Lemma A.3 a small technical lemma regarding convex combinations of quadratic functions.\nLemma A.1 (Standard bounds for smooth, strongly convex functions). Let f : Rk \u2192 R be differentiable function that obtains its minimal value at xopt.\nIf f is L-smooth then for all x \u2208 Rk\n1\n2L \u2016\u2207f(x)\u201622 \u2264 f(x)\u2212 f(xopt) \u2264\nL 2 \u2016x\u2212 xopt\u201622 .\nIf f is \u00b5-strongly convex the for all x \u2208 Rk\n\u00b5 2 \u2016x\u2212 xopt\u201622 \u2264 f(x)\u2212 f(xopt) \u2264 1 2\u00b5 \u2016\u2207f(x)\u201622 .\nProof. Apply the definition of smoothness and strong convexity at the points x and xopt and minimize the resulting quadratic form.\nLemma A.2. Let f : Rn \u2192 R be a \u00b5-strongly convex function and for all a, x \u2208 Rn let fa(x) = f(x) + a>x. Then\nfa(x)\u2212 fopta \u2264 2(f(x)\u2212 fopt) + 1\n\u00b5 \u2016a\u201622\nProof. 11 Let xopt = argminx f(x). Since f is \u00b5-strongly convex by Lemma A.1 we have f(x) \u2265 f(xopt) + \u00b52\u2016x\u2212 x opt\u201622 for all x. Consequently, for all x\nfopta \u2265 f(x) + a>x \u2265 f(xopt) + \u00b5 2 \u2016x\u2212 xopt\u201622 + a>x \u2265 fa(xopt) + a>(x\u2212 xopt) + \u00b5 2 \u2016x\u2212 xopt\u201622\n11Note we could have also proved this by appealing to the gradient of f and Lemma A.1, however the proof here holds even if f is not differentiable.\nMinimizing with respect to x yields that fopta \u2265 fa(xopt) \u2212 12\u00b5\u2016a\u2016 2 2. Consequently, by Cauchy Schwarz, and Young\u2019s Inequality we have\nfa(x)\u2212 fopta \u2264 f(x)\u2212 fopt + a>(x\u2212 xopt) + 1\n2\u00b5 \u2016a\u201622 (18)\n\u2264 f(x)\u2212 fopt + 1 2\u00b5 \u2016a\u201622 + \u00b5 2 \u2016x\u2212 xopt\u201622 + 1 2\u00b5 \u2016a\u201622 (19)\nApplying A.1 again yields the result.\nLemma A.3. Suppose that for all x we have\nf1(x) def = \u03c81 +\n\u00b5 2 \u2016x\u2212 v1\u201622 and f2(x) = \u03c82 + \u00b5 2 \u2016x\u2212 v2\u201622\nthen \u03b1f1(x) + (1\u2212 \u03b1)f2(x) = \u03c8\u03b1 + \u00b5\n2 \u2016x\u2212 v\u03b1\u201622\nwhere v\u03b1 = \u03b1v1 + (1\u2212 \u03b1)v2 and \u03c8\u03b1 = \u03b1\u03c81 + (1\u2212 \u03b1)\u03c82 + \u00b5\n2 \u03b1(1\u2212 \u03b1)\u2016v1 \u2212 v2\u201622\nProof. Setting the gradient of \u03b1f1(x) + (1\u2212 \u03b1)f2(x) to 0 we know that v\u03b1 must satisfy\n\u03b1\u00b5 (v\u03b1 \u2212 v1) + (1\u2212 \u03b1)\u00b5 (v\u03b1 \u2212 v2) = 0\nand thus v\u03b1 = \u03b1v1 + (1\u2212 \u03b1)v2. Finally,\n\u03c8\u03b1 = \u03b1 [ \u03c81 + \u00b5\n2 \u2016v\u03b1 \u2212 v1\u201622\n] + (1\u2212 \u03b1) [ \u03c82 + \u00b5\n2 \u2016v\u03b1 \u2212 v2\u201622 ] = \u03b1\u03c81 + (1\u2212 \u03b1)\u03c82 + \u00b5\n2\n[ \u03b1(1\u2212 \u03b1)2\u2016v2 \u2212 v1\u201622 + (1\u2212 \u03b1)\u03b12\u2016v2 \u2212 v1\u201622 ] = \u03b1\u03c81 + (1\u2212 \u03b1)\u03c82 + \u00b5\n2 \u03b1(1\u2212 \u03b1)\u2016v1 \u2212 v2\u201622."}, {"heading": "B Regularized ERM duality", "text": "In this section we derive the dual (4) to the problem of computing proximal operator for the ERM objective (3) (Section B.1) and prove several bounds on primal and dual errors (Section B.2). Throughout this section we assume F is given by the ERM problem (1) and we make extensive use of the notation and assumptions in Section 1.1.\nB.1 Dual derivation\nWe can rewrite the primal problem, minx fs,\u03bb(x), as\nmin x\u2208Rd,z\u2208Rn\n\u2211n i=1 \u03c6i(zi) + \u03bb 2\u2016x\u2212 s\u2016 2 2\nsubject to zi = a T i x, for i = 1, . . . , n\n.\nBy convex duality, this is equivalent to\nmin x,{zi} max y\u2208Rn n\u2211 i=1 \u03c6i(zi) + \u03bb 2 \u2016x\u2212 s\u201622 + yT(Ax\u2212 z) = maxy minx,{zi} n\u2211 i=1 \u03c6i(zi) + \u03bb 2 \u2016x\u2212 s\u201622 + yT(Ax\u2212 z)\nSince min zi {\u03c6i(zi)\u2212 yizi} = \u2212max zi {yizi \u2212 \u03c6i(zi)} = \u2212\u03c6\u2217i (yi)\nand\nmin x\n{ \u03bb\n2 \u2016x\u2212 s\u201622 + yTAx\n} = yTAs+ min\nx\n{ \u03bb\n2 \u2016x\u2212 s\u201622 + yTA(x\u2212 s)\n} = yTAs\u2212 1\n2\u03bb \u2016ATy\u201622,\nit follows that the optimization problem is in turn equivalent to\n\u2212min y n\u2211 i=1 \u03c6\u2217i (yi) + 1 2\u03bb \u2016ATy\u201622 \u2212 sTATy.\nThis negated problem is precisely the dual formulation. The first problem is a Lagrangian saddle-point problem, where the Lagrangian is defined as\nL(x, y, z) = n\u2211 i=1 \u03c6i(zi) + \u03bb 2 \u2016x\u2212 s\u201622 + yT(Ax\u2212 z).\nThe dual-to-primal mapping (5) and primal-to-dual mapping (6) are implied by the KKT conditions under L, and can be derived by solving for x, y, and z in the system \u2207L(x, y, z) = 0.\nThe duality gap in this context is defined as\ngaps,\u03bb(x, y) def = fs,\u03bb(x) + gs,\u03bb(y). (20)\nStrong duality dictates that gaps,\u03bb(x, y) \u2265 0 for all x \u2208 Rd, y \u2208 Rn, with equality attained when x is primal-optimal and y is dual-optimal.\nB.2 Error bounds\nLemma B.1 (Dual error bounds primal error). For all s \u2208 Rd, y \u2208 Rn, and \u03bb > 0 we have\nfs,\u03bb(x\u0302s,\u03bb(y))\u2212 fopts,\u03bb \u2264 2(n\u03ba\u03bb) 2(gs,\u03bb(y)\u2212 gopts,\u03bb).\nProof. Because F is nR2L smooth, fs,\u03bb is nR 2L+ \u03bb smooth. Consequently, for all x \u2208 Rd we have\nfs,\u03bb(x)\u2212 fopts,\u03bb \u2264 nR2L+ \u03bb\n2 \u2016x\u2212 xopts,\u03bb\u2016 2 2\nSince we know that xopts,\u03bb = s\u2212 1 \u03bbA Tyopts,\u03bb and \u2016A Tz\u201622 \u2264 nR2\u2016z\u201622 for all z \u2208 Rn we have\nfs,\u03bb(x\u0302x,\u03bb(y))\u2212 fs,\u03bb(xopts,\u03bb ) \u2264 nR2L+ \u03bb 2 \u2016s\u2212 1 \u03bb ATy \u2212 (s\u2212 1 \u03bb ATyopts,\u03bb )\u2016 2 2\n= nR2L+ \u03bb\n2\u03bb2 \u2016y \u2212 yopts,\u03bb \u2016 2 AAT\n\u2264 nR 2(nR2L+ \u03bb)\n2\u03bb2 \u2016y \u2212 yopts,\u03bb \u2016 2 2. (21)\nFinally, since each \u03c6\u2217i is 1/L-strongly convex, G is 1/L-strongly convex and hence so is gs,\u03bb. Therefore by Lemma A.1 we have\n1\n2L \u2016y \u2212 yopts,\u03bb \u2016 2 2 \u2264 gs,\u03bb(y)\u2212 gs,\u03bb(y opt s,\u03bb ). (22)\nSubstituting (22) in (21) and recalling that \u03ba\u03bb \u2265 1 yields the result.\nLemma B.2 (Gap for primal-dual pairs). For all s, x \u2208 Rd and \u03bb > 0 we have\ngaps,\u03bb(x, y\u0302(x)) = 1\n2\u03bb \u2016\u2207F (x)\u201622 +\n\u03bb 2 \u2016x\u2212 s\u201622. (23)\nProof. To prove the first identity (23), let y\u0302 = y\u0302(x) for brevity. Recall that\ny\u0302i = \u03c6 \u2032 i(a T i x) \u2208 argmax yi {xTaiyi \u2212 \u03c6\u2217i (yi)} (24)\nby definition, and hence xTaiy\u0302i \u2212 \u03c6\u2217i (y\u0302i) = \u03c6i(aTi x). Observe that\ngaps,\u03bb(x, y\u0302) = n\u2211 i=1 ( \u03c6i(a T i x) + \u03c6 \u2217 i (y\u0302i) ) \u2212 xTATy\u0302 + 12\u03bb\u2016A Ty\u0302\u20162 + \u03bb2\u2016x\u2212 s\u2016 2\n= n\u2211 i=1 \u03c6i(aTi x) + \u03c6\u2217i (y\u0302i)\u2212 xTaiy\u0302i\ufe38 \ufe37\ufe37 \ufe38 =0 (by (24)) + 12\u03bb\u2016ATy\u0302\u20162 + \u03bb2\u2016x\u2212 s\u20162 = 12\u03bb\u2016A Ty\u0302\u20162 + \u03bb2\u2016x\u2212 s\u2016 2\n= 12\u03bb\u2016 n\u2211 i=1 ai\u03c6 \u2032 i(a T i x)\u20162 + \u03bb2\u2016x\u2212 s\u2016 2 = 12\u03bb\u2016\u2207F (x)\u2016 2 + \u03bb2\u2016x\u2212 s\u2016 2.\nCorollary B.3 (Initial dual error). For all s, x \u2208 Rd and \u03bb > 0 we have\ngx,\u03bb(y\u0302(x))\u2212 goptx,\u03bb \u2264 2\u03ba\u03bb ( fx,\u03bb(x)\u2212 foptx,\u03bb ) Proof. By Lemma B.2 we have\ngapx,\u03bb(x, y\u0302(x)) = 1\n2\u03bb \u2016\u2207F (x)\u201622 +\n\u03bb 2 \u2016x\u2212 x\u201622 = 1 2\u03bb \u2016\u2207F (x)\u201622\nNow clearly \u2207F (x) = \u2207fx,\u03bb(x). Furthermore, since fx,\u03bb(x) is (nLR2 + \u03bb)-smooth by Lemma A.1 we have \u2016\u2207fx,\u03bb(x)\u2016 \u2264 2(nLR2 + \u03bb)(fx,\u03bb(x)\u2212 foptx,\u03bb ). Consequently,\ngx,\u03bb(y\u0302(x))\u2212 goptx,\u03bb \u2264 gapx,\u03bb(x, y\u0302(x)) \u2264 2(nLR2 + \u03bb)\n2\u03bb\n( fx,\u03bb(x)\u2212 foptx,\u03bb ) .\nRecalling the definition of \u03ba\u03bb and the fact that 1 \u2264 \u03ba\u03bb yields the result."}], "references": [{"title": "The tradeoffs of large scale learning", "author": ["L. Bottou", "O. Bousquet"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Bottou and Bousquet.,? \\Q2008\\E", "shortCiteRegEx": "Bottou and Bousquet.", "year": 2008}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Boyd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2011}, {"title": "Uniform sampling for matrix approximation", "author": ["M.B. Cohen", "Y.T. Lee", "C. Musco", "R. Peng", "A. Sidford"], "venue": "In Innovations in Theoretical Computer Science (ITCS),", "citeRegEx": "Cohen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 2015}, {"title": "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives", "author": ["A. Defazio", "F. Bach", "S. Lacoste-Julien"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Defazio et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Defazio et al\\.", "year": 2014}, {"title": "New proximal point algorithms for convex minimization", "author": ["O. Guler"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Guler.,? \\Q1992\\E", "shortCiteRegEx": "Guler.", "year": 1992}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["R. Johnson", "T. Zhang"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Johnson and Zhang.,? \\Q2013\\E", "shortCiteRegEx": "Johnson and Zhang.", "year": 2013}, {"title": "Efficient accelerated coordinate descent methods and faster algorithms for solving linear systems", "author": ["Y.T. Lee", "A. Sidford"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "Lee and Sidford.,? \\Q2013\\E", "shortCiteRegEx": "Lee and Sidford.", "year": 2013}, {"title": "Iterative row sampling", "author": ["M. Li", "G.L. Miller", "R. Peng"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "Li et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "A universal catalyst for first-order optimization", "author": ["H. Lin", "J. Mairal", "Z. Harchaoui"], "venue": null, "citeRegEx": "Lin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2015}, {"title": "An accelerated proximal coordinate gradient method", "author": ["Q. Lin", "Z. Lu", "L. Xiao"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Lin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "Stochastic gradient descent, weighted sampling, and the randomized kaczmarz algorithm", "author": ["D. Needell", "N. Srebro", "R. Ward"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Needell et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Needell et al\\.", "year": 2014}, {"title": "OSNAP: Faster numerical linear algebra algorithms via sparser subspace embeddings", "author": ["J. Nelson", "H.L. Nguyen"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "Nelson and Nguyen.,? \\Q2013\\E", "shortCiteRegEx": "Nelson and Nguyen.", "year": 2013}, {"title": "A method of solving a convex programming problem with convergence rate O(1/k2)", "author": ["Y. Nesterov"], "venue": "Soviet Mathematics Doklady,", "citeRegEx": "Nesterov.,? \\Q1983\\E", "shortCiteRegEx": "Nesterov.", "year": 1983}, {"title": "Introductory Lectures on Convex Optimization: A Basic Course", "author": ["Y. Nesterov"], "venue": null, "citeRegEx": "Nesterov.,? \\Q2004\\E", "shortCiteRegEx": "Nesterov.", "year": 2004}, {"title": "Random features for large-scale kernel machines", "author": ["A. Rahimi", "B. Recht"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Rahimi and Recht.,? \\Q2007\\E", "shortCiteRegEx": "Rahimi and Recht.", "year": 2007}, {"title": "Monotone operators and the proximal point algorithm", "author": ["R.T. Rockafellar"], "venue": "SIAM Journal on Control and Optimization,", "citeRegEx": "Rockafellar.,? \\Q1976\\E", "shortCiteRegEx": "Rockafellar.", "year": 1976}, {"title": "A stochastic gradient method with an exponential convergence rate for finite training sets", "author": ["N.L. Roux", "M. Schmidt", "F. Bach"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Roux et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Roux et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "sample the \u03c6i have been shown to outperform standard first-order methods under mild assumptions (Bottou and Bousquet, 2008; Johnson and Zhang, 2013; Xiao and Zhang, 2014; Defazio et al., 2014; Shalev-Shwartz and Zhang, 2014).", "startOffset": 96, "endOffset": 224}, {"referenceID": 5, "context": "sample the \u03c6i have been shown to outperform standard first-order methods under mild assumptions (Bottou and Bousquet, 2008; Johnson and Zhang, 2013; Xiao and Zhang, 2014; Defazio et al., 2014; Shalev-Shwartz and Zhang, 2014).", "startOffset": 96, "endOffset": 224}, {"referenceID": 3, "context": "sample the \u03c6i have been shown to outperform standard first-order methods under mild assumptions (Bottou and Bousquet, 2008; Johnson and Zhang, 2013; Xiao and Zhang, 2014; Defazio et al., 2014; Shalev-Shwartz and Zhang, 2014).", "startOffset": 96, "endOffset": 224}, {"referenceID": 5, "context": "Solves the ERM problem (1), under an assumption of strong convexity, with convergence that depends linearly on the problem\u2019s condition number (Johnson and Zhang, 2013; Defazio et al., 2014).", "startOffset": 142, "endOffset": 189}, {"referenceID": 3, "context": "Solves the ERM problem (1), under an assumption of strong convexity, with convergence that depends linearly on the problem\u2019s condition number (Johnson and Zhang, 2013; Defazio et al., 2014).", "startOffset": 142, "endOffset": 189}, {"referenceID": 15, "context": "The key to our reductions are approximate variants of the classical proximal point algorithm (PPA) (Rockafellar, 1976; Parikh and Boyd, 2014).", "startOffset": 99, "endOffset": 141}, {"referenceID": 15, "context": "Several of the algorithmic tools and analysis techniques in this paper are similar in principle to (and sometimes appear indirectly in) work scattered throughout the machine learning and optimization literature \u2013 from classical treatments of error-tolerant PPA (Rockafellar, 1976; Guler, 1992) to the effective proximal term used by Accelerated Proximal SDCA Shalev-Shwartz and Zhang (2014) in enabling its acceleration.", "startOffset": 261, "endOffset": 293}, {"referenceID": 4, "context": "Several of the algorithmic tools and analysis techniques in this paper are similar in principle to (and sometimes appear indirectly in) work scattered throughout the machine learning and optimization literature \u2013 from classical treatments of error-tolerant PPA (Rockafellar, 1976; Guler, 1992) to the effective proximal term used by Accelerated Proximal SDCA Shalev-Shwartz and Zhang (2014) in enabling its acceleration.", "startOffset": 261, "endOffset": 293}, {"referenceID": 4, "context": "Several of the algorithmic tools and analysis techniques in this paper are similar in principle to (and sometimes appear indirectly in) work scattered throughout the machine learning and optimization literature \u2013 from classical treatments of error-tolerant PPA (Rockafellar, 1976; Guler, 1992) to the effective proximal term used by Accelerated Proximal SDCA Shalev-Shwartz and Zhang (2014) in enabling its acceleration.", "startOffset": 281, "endOffset": 391}, {"referenceID": 4, "context": "GD is Nesterov\u2019s accelerated gradient decent (Nesterov, 1983, 2004), SVRG is the stochastic variance-reduced gradient of Johnson and Zhang (2013), SAG is the stochastic average gradient of Roux et al.", "startOffset": 121, "endOffset": 146}, {"referenceID": 4, "context": "GD is Nesterov\u2019s accelerated gradient decent (Nesterov, 1983, 2004), SVRG is the stochastic variance-reduced gradient of Johnson and Zhang (2013), SAG is the stochastic average gradient of Roux et al. (2012) and Defazio et al.", "startOffset": 121, "endOffset": 208}, {"referenceID": 3, "context": "(2012) and Defazio et al. (2014), SDCA is the stochastic dual coordinate ascent of Shalev-Shwartz and Zhang (2013), AP-SDCA is the Accelerated Proximal SDCA of Shalev-Shwartz and Zhang (2014) and APCG is the accelerated coordinate algorithm of Lin et al.", "startOffset": 11, "endOffset": 33}, {"referenceID": 3, "context": "(2012) and Defazio et al. (2014), SDCA is the stochastic dual coordinate ascent of Shalev-Shwartz and Zhang (2013), AP-SDCA is the Accelerated Proximal SDCA of Shalev-Shwartz and Zhang (2014) and APCG is the accelerated coordinate algorithm of Lin et al.", "startOffset": 11, "endOffset": 115}, {"referenceID": 3, "context": "(2012) and Defazio et al. (2014), SDCA is the stochastic dual coordinate ascent of Shalev-Shwartz and Zhang (2013), AP-SDCA is the Accelerated Proximal SDCA of Shalev-Shwartz and Zhang (2014) and APCG is the accelerated coordinate algorithm of Lin et al.", "startOffset": 11, "endOffset": 192}, {"referenceID": 3, "context": "(2012) and Defazio et al. (2014), SDCA is the stochastic dual coordinate ascent of Shalev-Shwartz and Zhang (2013), AP-SDCA is the Accelerated Proximal SDCA of Shalev-Shwartz and Zhang (2014) and APCG is the accelerated coordinate algorithm of Lin et al. (2014). The latter three algorithms are more restrictive in that they only solve the explicitly regularized problem F + \u03bbr, even if F is itself strongly convex (such algorithms run in time inversely proportional to \u03bb).", "startOffset": 11, "endOffset": 262}, {"referenceID": 10, "context": "The table also lists algorithms based on the randomized Kaczmarz method (Strohmer and Vershynin, 2009; Needell et al., 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al.", "startOffset": 72, "endOffset": 124}, {"referenceID": 6, "context": ", 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al.", "startOffset": 38, "endOffset": 61}, {"referenceID": 11, "context": ", 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al., 2013; Cohen et al., 2015).", "startOffset": 137, "endOffset": 199}, {"referenceID": 7, "context": ", 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al., 2013; Cohen et al., 2015).", "startOffset": 137, "endOffset": 199}, {"referenceID": 2, "context": ", 2014) and their accelerated variant (Lee and Sidford, 2013), as well as algorithms based on subspace embedding (OSNAP) or row sampling (Nelson and Nguyen, 2013; Li et al., 2013; Cohen et al., 2015).", "startOffset": 137, "endOffset": 199}, {"referenceID": 15, "context": "We remark that notions of error-tolerance in the typical proximal point algorithm \u2013 for both its plain and accelerated variants \u2013 have been defined and studied in prior work (Rockafellar, 1976; Guler, 1992).", "startOffset": 174, "endOffset": 206}, {"referenceID": 4, "context": "We remark that notions of error-tolerance in the typical proximal point algorithm \u2013 for both its plain and accelerated variants \u2013 have been defined and studied in prior work (Rockafellar, 1976; Guler, 1992).", "startOffset": 174, "endOffset": 206}, {"referenceID": 1, "context": "Additional related work There is an immense body of literature on proximal point methods and alternating direction method of multipliers (ADMM) that are relevant to the approach in this paper; see Boyd et al. (2011); Parikh and Boyd (2014) for modern surveys.", "startOffset": 197, "endOffset": 216}, {"referenceID": 1, "context": "Additional related work There is an immense body of literature on proximal point methods and alternating direction method of multipliers (ADMM) that are relevant to the approach in this paper; see Boyd et al. (2011); Parikh and Boyd (2014) for modern surveys.", "startOffset": 197, "endOffset": 240}, {"referenceID": 1, "context": "Additional related work There is an immense body of literature on proximal point methods and alternating direction method of multipliers (ADMM) that are relevant to the approach in this paper; see Boyd et al. (2011); Parikh and Boyd (2014) for modern surveys. We also note that the independent work of Lin et al. (2015) contains results similar to some of those in this paper.", "startOffset": 197, "endOffset": 320}, {"referenceID": 9, "context": "Instantiating this algorithm with an accelerated, regularized ERM solver \u2013 such as APCG (Lin et al., 2014) \u2013 as its inner minimizer yields the improved accelerated running time for the ERM problem (1).", "startOffset": 88, "endOffset": 106}, {"referenceID": 5, "context": "Instantiating this algorithm with SVRG (Johnson and Zhang, 2013) as its inner minimizer yields the improved accelerated running time for both the ERM problem (1) as well as the general ERM problem (2).", "startOffset": 39, "endOffset": 64}, {"referenceID": 9, "context": "Instantiating this algorithm with an accelerate, regularized ERM solver \u2013 such as APCG (Lin et al., 2014) \u2013 as its inner minimizer yields the improved accelerated running time for the ERM problem (1).", "startOffset": 87, "endOffset": 105}, {"referenceID": 5, "context": "SVRG (Johnson and Zhang, 2013) is a primal (c, \u03bb)oracle with runtime complexity TP = O(ndmin{\u03ba, \u03ba\u03bb} log c) for both the ERM problem (1) and the general ERM problem (2).", "startOffset": 5, "endOffset": 30}, {"referenceID": 9, "context": "Using APCG (Lin et al., 2014) we can obtain a primal (c, \u03bb)-oracle with runtime complexity TP = \u00d5(nd \u221a \u03ba\u03bb log c) for the ERM problem (1).", "startOffset": 11, "endOffset": 29}, {"referenceID": 5, "context": "1 with SVRG (Johnson and Zhang, 2013) as the primal oracle and taking \u03bb = 2\u03bc + LR2 yields the running time bound \u00d5(nd \u221a \u03ba log( 0/ )) for the general ERM problem (2).", "startOffset": 12, "endOffset": 37}, {"referenceID": 9, "context": "APCG (Lin et al., 2014) is a dual (c, \u03bb)-oracle with runtime complexity TD = \u00d5(nd \u221a \u03ba\u03bb log c).", "startOffset": 5, "endOffset": 23}, {"referenceID": 5, "context": "To match the terminology used for SVRG in Johnson and Zhang (2013), we refer to a \u201cstage\u201d as a single step of APPA, i.", "startOffset": 42, "endOffset": 67}, {"referenceID": 14, "context": "We then take take n/5 random Fourier features per the randomized scheme of Rahimi and Recht (2007). This yields 12K features for MNIST (60K training examples, 10K test) and 10K for CIFAR (50K training examples, 10K test).", "startOffset": 75, "endOffset": 99}, {"referenceID": 5, "context": "(See Johnson and Zhang (2013) for a comparison of SVRG to a more thoroughly tuned SGD under different decay schemes.", "startOffset": 5, "endOffset": 30}], "year": 2015, "abstractText": "We develop a family of accelerated stochastic algorithms that minimize sums of convex functions. Our algorithms improve upon the fastest running time for empirical risk minimization (ERM), and in particular linear least-squares regression, across a wide range of problem settings. To achieve this, we establish a framework based on the classical proximal point algorithm. Namely, we provide several algorithms that reduce the minimization of a strongly convex function to approximate minimizations of regularizations of the function. Using these results, we accelerate recent fast stochastic algorithms in a black-box fashion. Empirically, we demonstrate that the resulting algorithms exhibit notions of stability that are advantageous in practice. Both in theory and in practice, the provided algorithms reap the computational benefits of adding a large strongly convex regularization term, without incurring a corresponding bias to the original problem.", "creator": "LaTeX with hyperref package"}}}