{"id": "1509.03389", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2015", "title": "Multi-Attribute Proportional Representation", "abstract": "laurien We consider \u0142aziska the tarbiat following problem in which blockbusting a given number of items has to be fulfils chosen from miyauchi a predefined offspin set. terran Each peruses item is chibale described 350-bed by a 81st vector of attributes hipped and seldon for each attribute there 89.6 is a desired distribution that garhbeta the isms selected castmate set should 232.6 have. We qohab-e look anti-racism for a khoka set pahk that 7,655 fits faeroes as chidsey much tbr as possible whinney the subcompact desired distributions m\u00e9lodies on cavin all alsobrook attributes. snotty Examples lipari of knock-offs applications include choosing members 65.73 of a qvale representative liberte committee, remissions where candidates are murrumbidgee described by attributes such as sex, age 1958-60 and unsealing profession, and 15.97 where bazookas we caressed look for sbragia a committee quantick that 83-run for each attribute padano offers a biel certain representation, xijiang i. e. , a hogmo single wagenfeld committee brueghel that seipp contains a 677 certain igorot number bashmet of young codewords and old people, 42.39 certain number of scriptwriter men okla.-based and 64.54 women, certain n.b.a. number of dhul people sucessful with kraszewski different professions, etc. complaint With struzan a single lokasenna attribute duncanville the nymphaeum problem parachuters collapses to eria the sempron apportionment edgerton problem for party - 3pt list proportional side-wheeler representation strahovski systems (nababan in such leukine case the mohmed value canol of the balch single majus attribute would pieters be slimes a political saudades affiliation of pancrate a candidate ). We 551 study the werling properties of the associated dayz subset 180-degree selection fedayeen rules, tv18 as shish well as stagnate their tresckow computation complexity.", "histories": [["v1", "Fri, 11 Sep 2015 05:01:17 GMT  (188kb)", "http://arxiv.org/abs/1509.03389v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DS cs.GT", "authors": ["j\u00e9r\u00f4me lang", "piotr krzysztof skowron"], "accepted": true, "id": "1509.03389"}, "pdf": {"name": "1509.03389.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n50 9.\n03 38\n9v 1\n[ cs\n.A I]\n1 1\nSe p\n20 15"}, {"heading": "1 Introduction", "text": "A research department has to choose k members for a recruiting committee. A selected committee should be gender balanced, ideally containing 50% of male and 50% of female. Additionally, a committee should represent different research areas in certain proportions: ideally it should contain 55% of researchers specializing in area A, 25% of experts in area B, and 20% in area C. Another requirement is that the committee should contain 30% junior and 70% senior researchers, and finally, the repartition between local and external members should be kept in proportions 30% to 70 %. The pool of possible members is the following:\nName Sex Group Age Affiliation Ann F A J L Bob M A J E\nCharlie M A S L Donna F B S E Ernest M A S L George M A S E Helena F B S E John M B J E\nKevin M C J E Laura F C J L\nIn the given example, if the department wants to select k = 3 members, then it is easy to see that there exists no such committee that would ideally satisfy all the criteria. Nevertheless, some committees are better than others: intuitively we feel the sex ratio should be either equal to 2:1 or to 1:2, the area ratio should be equal to 2:1:0, the age ratio to 1:2, and the affiliation ratio to 1:2. Such relaxed criteria can be achieved by selecting Ann, Donna, and George. Now, let us consider the above example for the case when k = 4. In such case, the ideal sex ratio should be equal to 2:2, the research area ratio to 2:1:1, the age ratio to 1:3, and the\naffiliation ratio to 1:3. It can be proved, however, that for k = 4 there exists no committee satisfying such relaxed criteria. Intuitively, in such case the best committee is either {Ann, Charlie, Donna, George}, with two externals instead of three, or {Charles, Donna, George, Kevin}, with males being over-represented.\nIn this paper we formalize the intuition given in the above example and define what it means for a committee to be optimal. When looking for an appropriate definition we follow an axiomatic approach. First, we notice that our model generalizes the apportionment problem for proportional representation [2]. The central question of the apportionment problem is how to distribute parliament seats between political parties, given the numbers of votes casted for each party. Indeed, we can consider our multi-attribute problem, with the single attribute being a political affiliation of a candidate, and the desired distributions being the proportions of votes casted for different parties. In such case we can see that selecting a committee in our multi-attribute proportional representation system boils down to selecting a parliament according to some apportionment method.\nThere is a variety of apportionment methods studied in the literature [1]. In this paper we do not review these methods in detail (we refer the reader to the survey of Balinski and Young [2]), but we rather focus on a specific set of their properties that have been analyzed, namely non-reversal, exactness and respect of quota, population monotonicity, and house monotonicity. We define the analogs of these properties for the multi-attribute domain, and analyze our definition of an optimal committee for a multi-attribute domain with respect to these properties.\nTo emphasize the analogy between our model and the apportionment methods, we should provide some discussion on where the desired proportions for attributes come from. Typically, but not always, they come from votes. For instance, each voter might give her preferred value for each attribute, and the ideal proportions coincide with the observed frequencies. For instance, out of 20 voters, 10 would have voted for a male and 10 for a female, 13 for a young person and 7 for a senior one, etc. It is worth mentioning that the voters might cast approval ballots, that is for each attribute they might define a set of approved values rather than pointing out the single most preferred one. On the other hand, sometimes, instead of votes, there are \u201cglobal\u201d preferences on the composition of the committee, expressed directly by the group, imposed by law, or by other constraints that should be respected as much as possible independently of voter preferences.\nThe multi-attribute case, however, is also substantially different from the single-attribute one. In particular, multi-attribute proportional representation systems exhibit computational problems that do not appear in the single-attribute setting. Indeed, in the second part of our paper we show that finding an optimal committee is often NP-hard. However, we show that this challenge can be addressed by designing efficient approximation and fixed-parameter tractable algorithms.\nAfter positioning our work with respect to related areas in Section 2, we present our model in Section 3. In Sections 4 and 5 we discuss relevant properties of methods for multi-attribute fair representation. In Section 6 we show that, although the computational of optimal committees is generally NP-hard, there exist good approximation and fixed-parameter tractable algorithms for finding them. In Section 7 we point to further research issues."}, {"heading": "2 Related work", "text": "Our model is related to three distinct research areas:\nVoting on multi-attribute domains (see the work of Lang and Xia [13] for a survey). There, the aim is to output a single winning combination of attributes (e.g., in multiple referenda, a combination of binary values). Our model in case when k = 1 can be viewed as a voting problem on a constrained multi-attribute domain (constrained because not all combinations are feasible).\nMultiwinner (or committee) elections. In particular, our model is related to the problem of finding a fully proportional representation [6, 18]. There, the voters vote directly for candidates and do not consider attributes that characterize them. Thus, in this literature, the term \u201cproportional representation\u201d has a different meaning: these methods are \u2018representative\u2019 because each voter feels represented by some member of the elected committee. The computational aspects of full proportional and its extensions have raised a lot of\nattention lately [21, 3, 7, 24, 17]. Our study of the properties of multi-attribute proportional representation is close in spirit to the work of Elkind et al. [10], who gives a normative study of multiwinner election rules. Budgeted social choice [16] is technically close to committee elections, but it has a different motivation: the aim is to make a collective choice about a set of objects to be consumed by the group (perhaps, subject to some constraints) rather than about the set of candidates to represent voters.\nApportionment for party-list representation systems (see the work of Balinski and Young [2] for a survey). As we already pointed out, the apportionment methods correspond to the restriction of our model to a single attribute (albeit with a different motivation). While voting on multi-attribute domains and multiwinner elections have lead to significant research effort in computational social choice, this is less the case for partylist representation systems. Ding and Lin [8] studied a game-theoretic model for a party-list proportional representation system under specific assumptions, and show that computing the Nash equilibria of the game is hard. Also related is the computation of bi-apportionment (assignment of seats to parties within regions), investigated in a few recent papers [22, 23, 14].\nConstrained approval voting (CAP) [4, 20] is probably the closest work to our setting (MAPR). In CAP there are also multiple attributes, candidates are represented by tuples of attribute values, there is a target composition of the committee and we try to find a committee close to this target. However, there are also substantial differences between MAPR and CAP. First, in CAP, the target composition of the committee, exogenously defined, consists of a target number of seats for each combination of attributes (called a cell), that is, for each ~z \u2208 D1\u00d7 . . .\u00d7Dp, we have a value s(~z); while in MAPR we have a smaller input consisting of a target number for each value of each attribute. Note that the input in CAP is exponentially large in the number of attributes, which makes it infeasible in practice as soon as this number exceeds a few units (probably CAP was designed only for very small numbers of attributes, such as 2 or 3). Second, in CAP, the selection criterion of an optimal committee is made in two consecutive steps: first a set of admissible committees is defined, and the choice between these admissible committees is made by using approval ballots, and the chosen committee is the admissible committee maximizing the sum, over all voters, of the number of candidates approved (there is no loss function to minimize as in MAPR). A simple translation of CAP into an integer linear programming problem is given in [20, 25]."}, {"heading": "3 The model", "text": "Let X = {X1, . . . , Xp} be a set of p attributes, each with a finite domain Di = {x1i , . . . , x qi i }. We say that Xi is binary if |Di| = 2. We let D = D1 \u00d7 . . . \u00d7 Dp. Let C = {c1, . . . , cm} be a set of candidates, also referred to as the candidate database. Each candidate ci is represented as a vector of attribute values (X1(ci), . . . , Xp(ci)) \u2208 D.1\nFor each i \u2264 p, by \u03c0i we denote a target distribution \u03c0i = (\u03c01i , . . . , \u03c0 qi i ) with \u2211qi i=1 \u03c0 j i = 1. We set \u03c0 = (\u03c01, . . . , \u03c0p). Typically, n voters have casted a ballot expressing their preferred value on every attribute Xi, and \u03c0 j i is the fraction of voters who have x j i as their preferred value for Xi, but the results presented in the paper are independent from where the values \u03c0ji come from (see the discussion in the Introduction). The goal is to select a committee2 of k \u2208 {1, . . . ,m} candidates (or items) such that the distribution of attribute values is as close as possible to \u03c0. Formally, let Sk(C) denote the set of all subsets of C of cardinality k. Given A \u2208 Sk(C), the representation vector for A is defined as r(A) = (r1(A), . . . , rp(A)), where ri(A) = (r j i (A)|1 \u2264 j \u2264 qi) for each i = 1, . . . , p, and r j i (A) = |{c\u2208A:Xi(c)=x j i }| k .\nDefinition 1 A committee A \u2208 Sk(C) is perfect for \u03c0 if ri(A) = \u03c0i for all i.\n1By writing Xj(ci), we slightly abuse notation, that is, we consider Xj both as an attribute name and as a function that maps any candidate to an attribute value; this will not lead to any ambiguity.\n2We will stick to the terminology \u201ccommittee\u201d although the meaning of subsets of candidates has sometimes nothing to do with the election of a committee.\nThus, a perfect committee matches exactly the target distribution. Clearly, there is no perfect committee if for some i, j, \u03c0ji is not an integer multiplicity of 1 k . In some of our results we will focus on target distributions such that for each i, j the value k\u03c0ji is an integer. We will refer to such target distributions as to natural distributions.\nWe define metrics measuring how well a committee fits a target distribution, called loss functions.\nDefinition 2 A loss function f maps \u03c0 and r to f(\u03c0, r(A)) \u2208 R, and satisfies f(\u03c0, r(A)) = 0 if and only if \u03c0 = r.\nThere are a number of loss functions that can be considered. As often, the most classical loss functions use Lp norms, with the most classical examples of L1, L2, and L\u221e. We focus on two representative Lp norms, L1, and L\u221e, but we believe that other choices are also justified and may lead to interesting variants of our model. Consequently, we consider the following loss functions:\n\u2022 \u2016 \u00b7 \u20161 : \u2016\u03c0, r(A)\u20161 = \u2211 i,j |r j i (A)\u2212 \u03c0 j i |.\n\u2022 \u2016 \u00b7 \u20161,max : \u2016\u03c0, r(A)\u20161,max = \u2211 imaxj |r j i (A) \u2212 \u03c0 j i |.\n\u2022 \u2016 \u00b7 \u2016max : \u2016\u03c0, r(A)\u2016max = maxi,j |\u03c0 j i \u2212 r j i (A)|.\nNow, we are ready to formally define the central problem addressed in the paper.\nDefinition 3 (OPTIMALREPRESENTATION) Given X , C, \u03c0, k, and a loss function f , find a committee A \u2208 Sk(C) minimizing f(\u03c0, r(A)).\nExample 1 For the example of the Introduction, we have X = {sex, group, age, affiliation}, D = {F,M}\u00d7 {A,B,C}\u00d7{J, S}\u00d7{L,E}, and X1(Ann) = F , X1(Bob) = M etc. {Charlie,Donna,George,Kevin} is optimal for \u2016 \u00b7 \u20161, with \u2016\u03c0, r(A)\u20161 = 0.5+ 0.1+ 0.1+ 0.1 = 0.8, and for \u2016 \u00b7 \u20161,max, with \u2016\u03c0, r(A)\u20161,max = 0.4, but not for \u2016 \u00b7 \u2016max. {Ann,Charlie,Donna,George} is optimal for \u2016 \u00b7 \u2016max, with \u2016\u03c0, r(A)\u2016max = max(0, 0.2, 0.05, 0.2) = 0.2, but not for the other criteria."}, {"heading": "4 The single-attribute case", "text": "In this section we focus on the single-attribute case (p = 1). Without loss of generality, let us assume that the single attribute be party affiliation. Further, let us for a moment assume that for each value xj1 there are at least k candidates with value xj1 (this is typically the case in party-list elections). Then finding the optimal committee comes down to apportionment problem for party-list elections, where a fractional distribution \u03c01 has to be \u201crounded up\u201d to an integer-valued distribution r1 such that \u2211 j r j 1 = k.\nThere are two main families of apportionment methods: largest remainders and highest average methods [2]. We shall not discuss highest average methods here, because they are weakly relevant to our model. For largest remainders methods, a quota q is computed as a function of the number of seats k and the number of voters n. The number of votes for party i is ni = n.\u03c0i. The most common choice of a quota is the Hare quota, defined as nk ; the method based on the Hare quota is called the Hamilton method.\n3 Our aim is to generalize the Hamilton method to multiattribute domains.\nDefinition 4 (The largest remainder method.) The largest remainder method with quota q is defined as follows:\n\u2022 for all i, s\u2217i = ni q is the ideal number of seats for party i.\n\u2022 each party i receives si = \u230as\u2217i \u230b seats; let ti = si \u2212 s \u2217 i (called the remainder).\n3Other common choices are the Droop quota 1 + n 1+k , the Hagenbach-Bischoff quota n 1+k and the Imperiali quota n 2+k .\n\u2022 the remaining k \u2212 \u2211 i si seats are given to the k \u2212 \u2211 i si parties with the highest remainders ti.\nBelow we show that the largest remainder methods select a distribution (k1, . . . , kq) minimizing maxi=1,...,p(s \u2217 i \u2212 ki), which in the case of Hamilton comes down to minimizing maxi=1,...,p( ni q \u2212 ki). After defining \u03c0i1 = ni n for all i, we obtain the result that explains that our problem, with any of the three variants of loss functions, generalizes the Hamilton apportionment method.\nProposition 1 When p = 1 and assuming there are at least k items for each attribute, optimal subsets for \u2016 \u00b7 \u20161, \u2016 \u00b7 \u20161,max and \u2016 \u00b7 \u2016max coincide, and correspond to the subsets given by the Hamilton apportionment method.\nProof. Note that \u2016 \u00b7 \u20161,max and \u2016 \u00b7 \u2016max are equivalent for p = 1. Recall that s\u2217j denotes the target number of seats for party j. Let A be a committee of size k and let Rj(A) = k rj(A) be the number of members of A that belong to party j. Since |Rj(A) \u2212 s\u2217j | = k|r\nj(A) \u2212 \u03c0j |, we need to show that the following three assertions are equivalent:\n1. A minimizes \u2211 j |R j(A) \u2212 s\u2217j |.\n2. A minimizes maxj |Rj(A) \u2212 s\u2217j |.\n3. A is a Hamilton committee.\nWe first show 1 \u21d2 3. Assume A is not a Hamilton committee: then there exists an attribute value (party) that receives strictly more or strictly less seats than it would receive according to the Hamilton method. Naturally, there must also exist an attribute that receives strictly less or strictly more seats, respectively. Formally, this means that there are two attribute values (parties), say 1 and 2, such that the target number of seats for parties 1 and 2 are s\u22171 = p + \u03b11 and s \u2217 2 = q + \u03b12, with p, q integers and 1 > \u03b12 > \u03b11 \u2265 0, and such that either R1(A) \u2265 p + 1 and R2(A) \u2264 q. We have \u2211\nj |R j(A) \u2212 \u03c0j | =\n\u2211\nj 6=1,2 |R j(A) \u2212 s\u2217j | + |R 1(A) \u2212 s\u22171| +\n|R2(A) \u2212 s\u22172| \u2265 \u2211 j 6=1,2 |R j(A) \u2212 s\u2217j | + (1 \u2212 \u03b11) + \u03b12. Consider the committee A \u2032 obtained from A by giving one less seat to 1 and one more to 2.\n\u2022 If R1(A) > p + 1 then \u2211 j |R j(A) \u2212 s\u2217j | \u2212 \u2211 j |R j(A\u2032) \u2212 s\u2217j | = |R 1(A) \u2212 s\u22171| \u2212 |R 1(A\u2032) \u2212 s\u22171| +\n|R2(A)\u2212 s\u22172| \u2212 |R 2(A\u2032)\u2212 s\u22172| \u2265 1 + (1\u2212 \u03b12)\u2212 \u03b12 > 0.\n\u2022 If R2(A) < q then similarly, \u2211 j |R j(A)\u2212 s\u2217j | \u2212 \u2211 j |R j(A\u2032)\u2212 s\u2217j | > 0.\n\u2022 IfR1(A) = p+1 andR2(A) = q then we have \u2211 j |R j(A)\u2212s\u2217j | = \u2211 j 6=1,2 |R j(A)\u2212s\u2217j |+(1\u2212\u03b11)+\u03b12\nand \u2211 j |R j(A\u2032)\u2212s\u2217j | = \u2211 j 6=1,2 |R j(A\u2032)\u2212s\u2217j |+(1\u2212\u03b12)+\u03b11, hence \u2211 j |R j(A)\u2212s\u2217j |\u2212 \u2211 j |R j(A\u2032)\u2212 s\u2217j | = 2(\u03b12 \u2212 \u03b11) > 0.\nIn all three cases, A does not minimize \u2211 j |R j(A) \u2212 s\u2217j | and is therefore not an optimal committee for\n\u2016 \u00b7 \u20161, \u2211.\nWe now show 2 \u21d2 3. Call a party i lucky if Ri(A) > s\u2217i and unlucky if R i(A) < s\u2217i . Then we\nhave maxi |Ri(A) \u2212 s\u2217i | = max(0,max{R i(A) \u2212 s\u2217i |i lucky},max{s \u2217 i \u2212 R i(A)|i unlucky}). Let, without loss of generality, 1 be the lucky party with the highest value (if there are several such parties, we take arbitrary one of them) Ri(A) \u2212 s\u2217i and 2 be the unlucky party with the highest value s \u2217 i \u2212 R\ni(A). Assume A is not a Hamilton committee: then 2 had a higher remainder than 1 before 1 got her last seat, that is, R2(A) \u2212 s\u22172 > (R 1(A) \u2212 1) \u2212 s\u22171. Let A \u2032 be the committee A\u2032 obtained from A by giving one less seat to 1 and one more to 2: then either A\u2032 is a Hamilton committee, or it is not, and in this case we repeat the operation until we get a Hamilton committee A\u2217. Because maxj |Rj(A\u2217)\u2212 s\u2217j | < maxj |R\nj(A)\u2212 s\u2217j |, A is not an optimal committee for \u2016 \u00b7 \u2016max.\nIt remains to be shown that if A is a Hamilton committee then if is both optimal for \u2016\u00b7\u20161,max and \u2016\u00b7\u2016max. If there is a unique Hamilton-optimal committee then this follows immediately from 1 \u21d2 3 and 2 \u21d2 3. Assume there are several Hamilton-optimal committees A1, . . . , Aq . Then there are q parties, w.l.o.g.,\n1, . . . q, with equal remainders \u03b1 \u2208 [0, 1), that is, s\u22171 = p1 + \u03b1, . . . , s \u2217 q = pq + \u03b1, and the Hamilton-optimal committees differ only in the choice if those of these q parties to give they give an extra seat. We easily check that for any two A,A\u2032 of these committees we have \u2016A\u20161,max = \u2016A\u2032\u20161,max and \u2016A\u2016max = \u2016A\u2032\u2016max. \u2737\nTherefore, our model can be seen as a generalization of the Hamilton apportionment method to more than attribute. Note that our model can easily extend other largest remainder methods, and our results would be easily adapted. Interestingly, when p \u2265 2, our three criteria no longer coincide. However, for binary domains, \u2016 \u00b7 \u20161 and \u2016 \u00b7 \u20161,max coincide, since \u2211 j=1,2 |r j i (A)\u2212 \u03c0 j i | = 2maxj=1,2 |r j i (A)\u2212 \u03c0 j i |.\nProposition 2\n1. For each p \u2265 3 and binary domains, optimal subsets for \u2016 \u00b7 \u20161 and \u2016 \u00b7 \u2016max may be disjoint, even for k = 2.\n2. For each p \u2265 3, optimal subsets for \u2016 \u00b7 \u2016max and \u2016 \u00b7 \u20161,max can be disjoint.\n3. For each p \u2265 2, if at least one attribute has 4 values, then optimal subsets for \u2016 \u00b7 \u20161 and \u2016 \u00b7 \u20161,max can be disjoint.\n4. For p = 2 and binary domains, optimal subsets for \u2016 \u00b7 \u20161 and \u2016 \u00b7 \u2016max may differ.\nProof. We prove point 1 for p = 3 (the proof extends easily to p > 3 by adding attributes on which all items, and the target, agree). We have four candidates: two (A and B) with attribute vectors (x21, x 1 2, x 1 3), and two (C and D) with (x11, x 2 2, x 2 3). The target distribution is \u03c0 1 i = 0 and \u03c0 2 i = 1 for i \u2208 {1, 2, 3}. The \u2016 \u00b7\u2016max-optimal committees are {A,C}, {A,D}, {B,C} and {B,D}. The \u2016 \u00b7 \u20161-optimal committee is {C,D}. For Point 2: because optimal subsets for \u2016 \u00b7 \u20161 and \u2016 \u00b7 \u20161,max coincide for binary domains, Point 1 implies that optimal subsets for \u2016 \u00b7 \u2016max and \u2016 \u00b7 \u20161,max can be disjoint. The counterexample extends easily to nonbinary domains.\nFor Point 3: Let there be two attributes X1 with values x11, x 2 1, x 3 1, x 4 1 and X2 with values x 1 2, x 2 2; four\ncandidates: A with value vector (x11, x 2 2), B with value vector (x 2 1, x 2 2), C with value vector (x 3 1, x 1 2), and D with value vector (x41, x 1 2); k = 2; and \u03c0 = (0.5, 0.5, 0, 0) for X1 and (0.9, 0.1) for X2. The optimal committees for \u2016 \u00b7 \u20161 are all pairs except {C,D} (with loss 1.8) while the optimal committee for \u2016 \u00b7 \u20161,max is {C,D} (with loss 0.6). Next, we show that \u2016 \u00b7 \u2016max and \u2016 \u00b7 \u20161,max can be disjoint. The counterexample extends easily to more attributes and more values.\nFor Point 4, let k = 2, three candidates A, B and C with value vectors (x11, x 1 2), (x 1 1, x 1 2) and (x 2 1, x 2 2);\nand \u03c011 = 1, \u03c0 2 1 = 0, \u03c0 1 2 = 0, and \u03c0 2 2 = 1. {A,B}, {A,C} and {B,C} are all \u2016 \u00b7 \u20161-optimal, but only {A,C} and {B,C} are \u2016 \u00b7 \u2016max-optimal. \u2737\nThese negative results come from the constraints imposed by the candidate database, which prevent the selection on the different attributes to be done independently. In the example of the proof of point 1, for instance, since all items with the value x12 for X2 have value x 1 3 for X3, selecting q items with X2 = x 1 2 implies selecting q items with X3 = x13. However, if the database is sufficiently diverse so that no such constraints exist, the optimization can be done separately on each attribute. This is captured by the following notion.\nDefinition 5 A candidate database C satisfy the Full Supply (FS) property with respect to k if for any ~x \u2208 D there are at least k candidates in C associated with value vector ~x.\nThe candidate database of Example 1 does not satisfy FS, even for k = 1, because there is not a single candidate with group C and age S. If we ignore attributes group and affiliation, then we are left with 2 (resp., 3, 2, 3) candidates with value vector FJ (resp. MJ , FS, MS): the reduced database satisfies FS for k \u2208 {1, 2}.\nProposition 3 Let (X,C, k) be an optimal committee selection problem. If C satisfies FS w.r.t. k, then the following statements are equivalent:\n\u2022 A is an optimal committee for \u2016 \u00b7 \u20161\n\u2022 A is an optimal committee for \u2016 \u00b7 \u20161,max\n\u2022 for any attribute Xi, A is a Hamilton committee for the single-attribute problem ({Xi}, D\u2193Xi , \u03c0i, k), where D\u2193Xi is the projection of D on {Xi}.\nMoreover, any \u2016 \u00b7\u20161 (and \u2016 \u00b7\u20161,max) optimal committee is optimal for \u2016 \u00b7\u2016max. (The converse does not always hold.)\nProof. For each attribute Xi and value x j i \u2208 Di, let R j i be the number of seats with value x j i given by the Hamilton method for the single-attribute problem ({Xi}, D\u2193Xi , \u03c0i, k). For all j = 1, . . . , k, let ti(j) = min{l | R 1 i + . . . + R l\u22121 i < j and R 1 i + . . . + R l i \u2265 j}. Then take as item cj any item in the database with value vector (xt1(j)1 , . . . , x tp(j) p ), and remove it from the database; the full supply assumption guarantees that it will always be possible to find such an item. Let A = {c1, . . . , ck}; it is easy to check that A is an optimal committee for \u2016 \u00b7 \u20161 and for \u2016 \u00b7 \u20161,max. \u2737\nTo illustrate the constructive proof, consider 2 attributes X1 with 3 values x11, x 2 1, x 3 1, and X2 with 2 values\nx12, x 2 2; k = 4; and R 1 1 = 2, R 2 1 = 0, R 3 1 = 2, R 1 2 = 3, R 2 2 = 1. Then t1(1) = t1(2) = 1, t1(3) = t1(4) = 3, t2(1) = t2(2) = t2(3) = 1, t2(4) = 2, which leads to choose c1 with value vector (x11, x 1 2), c2 with vector (x11, x 1 2), c3 with vector (x 3 1, x 1 2), and c4 with vector (x 3 1, x 2 2)."}, {"heading": "5 Properties of multi-attribute proportional representation", "text": "Several properties of apportionment methods have been studied, starting with Balinski and Young [1]. We omit their definition in the single-attribute case and directly give their generalizations to our more general model. Let A be any optimal committee for some criterion given \u03c0, C and k. We recall that Rji (A) = k r j i (A) denotes the number of elements of A with the attribute Xi equal to x j i .\n\u2022 Non-reversal: for any attribute Xi, and attribute values x j i , x\nj\u2032 i , if \u03c0 j i > \u03c0 j\u2032 i then r j i (A) \u2265 r j\u2032 i (A).\n\u2022 Exactness and respect of quota: for all i, either Rji = \u230ak\u03c0 j i \u230b or R j i = \u2308k\u03c0 j i \u2309.\n\u2022 Population monotonicity (with respect to Xi): consider \u03c0 and \u03c1 such that (a) \u03c0 j i > \u03c1 j i , (b) for all\nj\u2032, j\u2032\u2032 6= j, \u03c0 j\u2032\u2032 i\n\u03c0j \u2032\ni\n= \u03c1j\n\u2032\u2032\ni\n\u03c1j \u2032\ni\n, and (c) for all i\u2032 6= i and all j, \u03c1ji\u2032 = \u03c0 j i\u2032 . Then there is an optimal committee B\nfor \u03c1 such that rji (A) \u2265 r j i (B).\n\u2022 House monotonicity: let B be an optimal committee for \u03c0, C and k\u2032 > k. Then for all i, j, rji (B) \u2265 rji (A). 4\nIn the single-attribute case, it is known for long that the Hamilton method satisfies all these properties except house monotonicity (this failure of house monotonicity is better known under the name Alabama paradox).\nWe start by noticing that if a property fails to be satisfied in the single-attribute case, a fortiori it is not satisfied in the multi-attribute case. As a consequence, house monotonicity is not satisfied, even under the FS assumption. We now consider the other properties.\n4Some other properties, such as consistency, seem more difficult to generalize to the multi-attribute case. Also, properties that deal with strategy proofness issues, such as resistance to party merging or party splitting, are less relevant in our setting than for political elections and we omit them.\nProposition 4 Under the full supply assumption, non-reversal, exactness and respect of quota, and population monotonicity are all satisfied, for any of our loss functions. In the general case, non-reversal, exactness and respect of quota are not satisfied. If Xi is a binary variable, and for \u2016 \u00b7 \u20161, population monotonicity with respect to Xi is satisfied; however it is not satisfied in the general case.\nProof. Under FS, the result easily comes from Proposition 3 and the fact that the property holds in the single-attribute case.\nIn the general case, we give counterexamples. For exactness and respect of quota, we have two binary attributes, and two items a, b with value vectors (x21, x 2 2) and (x 1 1, x 1 2), k = 1, \u03c0 defined as \u03c0 1 1 = 0, \u03c0 2 1 = 1, \u03c012 = 1, \u03c0 2 2 = 0. The optimal committee is either {a} or {b}, and does not respect quota even though all values k\u03c0ji are integers. For non-reversal we have two binary attributes and six items: a, b, c, each with vector (x11, x 1 2) and d, e, f , each with vector (x21, x 2 2). We have a target distribution \u03c0 defined as follows: \u03c0 1 1 = 0.35, \u03c0 2 1 = 0.65, \u03c0 1 2 = 1, \u03c022 = 0. We set k = 3. The optimal committees for \u2016 \u00b7 \u20161 and \u2016 \u00b7 \u20161,max are {a, b, c} and all triples made up from two items out of {a, b, c} and one out of {d, e, f}. The optimal committees for \u2016 \u00b7 \u2016max are all triples made up from two items out of {a, b, c} and one out of {d, e, f}. In all cases, for all optimal committees A we have r11(A) > r 2 1(A) although \u03c0 1 1 < \u03c0 2 1 .\nNow, we prove that population monotonicity holds for binary domains and for \u2016 \u00b7 \u20161. Consider a binary attribute Xi, with Di = {x0i , x 1 i }.\nAssume that \u03c10i > \u03c0 0 i (and \u03c1 0 i > \u03c0 0 i ), and that for all i \u2032 6= i we have \u03c1i\u2032 = \u03c0i\u2032 . Let A be an optimal committee for \u03c0 and, for the sake of contradiction, assume that for all optimal committees B for \u03c1 we have r0i (B) < r 0 i (A). Let B be such a committee. The proof is a case by case study, with six cases to be considered: (C1) r0i (B) \u2264 \u03c0 0 i < \u03c1 0 i \u2264 r 0 i (A); (C2) \u03c0 0 i \u2264 r 0 i (B) \u2264 \u03c1 0 i \u2264 r 0 i (A); (C3) \u03c0 0 i < \u03c10i \u2264 r 0 i (B) < r 0 i (A); (C4) r 0 i (B) \u2264 \u03c0 0 i \u2264 r 0 i (A) \u2264 \u03c1 0 i ; (C5) \u03c0 0 i \u2264 r 0 i (B) < r 0 i (A) \u2264 \u03c1 0 i ; and (C6) r0i (B) < r 0 i (A) \u2264 \u03c0 0 i < \u03c1 0 i .\n\u2022 Case 1: r0i (B) \u2264 \u03c0 0 i < \u03c1 0 i \u2264 r 0 i (A). In this case we have r 1 i (B) \u2265 \u03c0 1 i > \u03c1 1 i \u2265 r 1 i (A) and the\nfollowing holds:\n\u2016r(B)\u2212 \u03c0\u20161 = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c0 j i\u2032 |+ (\u03c0 0 i \u2212 r 0 i (B)) + (r 1 i (B)\u2212 \u03c0 1 i ) (1)\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c1 j i\u2032 |+ (\u03c1 0 i \u2212 r 0 i (B)) + (r 1 i (B)\u2212 \u03c1 1 i )\n+\u03c00i \u2212 \u03c0 1 i \u2212 \u03c1 0 i + \u03c1 1 i (2)\n= \u2016r(B) \u2212 \u03c1\u20161 + 2(\u03c0 0 i \u2212 \u03c1 0 i ) (3) < \u2016r(A) \u2212 \u03c1\u20161 + 2(\u03c0 0 i \u2212 \u03c1 0 i ) (4) = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (r 0 i (A) \u2212 \u03c1 0 i ) + (\u03c1 1 i \u2212 r 1 i (A)) + 2(\u03c0 0 i \u2212 \u03c1 0 i ) (5)\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (r 0 i (A) \u2212 \u03c0 0 i ) + (\u03c0 1 i \u2212 r 1 i (A))\n+\u03c00i \u2212 \u03c0 1 i \u2212 \u03c1 0 i + \u03c1 1 i + 2(\u03c0 0 i \u2212 \u03c1 0 i ) (6)\n= \u2016r(A) \u2212 \u03c0\u20161 + 4(\u03c0 0 i \u2212 \u03c1 0 i ) (7) \u2264 \u2016r(A) \u2212 \u03c0\u20161 (8)\n(4) comes from the fact that A is not optimal for \u03c1. Since, there is one strong inequality in the sequence, we imply that A is not optimal for \u03c0, a contradiction.\n\u2022 Case 2: \u03c00i \u2264 r 0 i (B) \u2264 \u03c1 0 i \u2264 r 0 i (A).\n\u2016r(B)\u2212 \u03c0\u20161 = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c0 j i\u2032 |+ (r 0 i (B)\u2212 \u03c0 0 i ) + (\u03c0 1 i \u2212 r 1 i (B))\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c1 j i\u2032 |+ (\u03c1 0 i \u2212 r 0 i (B)) + (r 1 i (B)\u2212 \u03c1 1 i )\n+2r0i (B)\u2212 \u03c0 0 i \u2212 \u03c1 0 i \u2212 2r 1 i (B) + \u03c0 1 i + \u03c1 1 i\n= \u2016r(B) \u2212 \u03c1\u20161 + 4r 0 i (B)\u2212 2\u03c0 0 i \u2212 2\u03c1 0 i < \u2016r(A) \u2212 \u03c1\u20161 + 4r 0 i (B)\u2212 2\u03c0 0 i \u2212 2\u03c1 0 i = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (r 0 i (A) \u2212 \u03c1 0 i ) + (\u03c1 1 i \u2212 r 1 i (A)) + 4r 0 i (B)\u2212 2\u03c0 0 i \u2212 2\u03c1 0 i\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (r 0 i (A) \u2212 \u03c0 0 i ) + (\u03c0 1 i \u2212 r 1 i (A))\n+\u03c00i \u2212 \u03c1 0 i \u2212 \u03c0 1 i + \u03c1 1 i + 4r 0 i (B) \u2212 2\u03c0 0 i \u2212 2\u03c1 0 i\n= \u2016r(A) \u2212 \u03c0\u20161 + 4r 0 i (B)\u2212 4\u03c1 0 i \u2264 \u2016r(A) \u2212 \u03c0\u20161\nAgain we obtain a contradiction.\n\u2022 Case 3: \u03c00i < \u03c1 0 i \u2264 r 0 i (B) < r 0 i (A).\n\u2016r(B)\u2212 \u03c0\u20161 = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c0 j i\u2032 |+ (r 0 i (B)\u2212 \u03c0 0 i ) + (\u03c0 1 i \u2212 r 1 i (B))\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c1 j i\u2032 |+ (r 0 i (B) \u2212 \u03c1 0 i ) + (\u03c1 1 i \u2212 r 1 i (B))\n\u2212\u03c00i + \u03c1 0 i + \u03c0 1 i \u2212 \u03c1 1 i\n= \u2016r(B) \u2212 \u03c1\u20161 \u2212 2\u03c0 0 i + 2\u03c1 0 i < \u2016r(A) \u2212 \u03c1\u20161 \u2212 2\u03c0 0 i + 2\u03c1 0 i = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (r 0 i (A) \u2212 \u03c1 0 i ) + (\u03c1 1 i \u2212 r 1 i (A))\u2212 2\u03c0 0 i + 2\u03c1 0 i\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (r 0 i (A) \u2212 \u03c0 0 i ) + (\u03c0 1 i \u2212 r 1 i (A))\n+\u03c00i \u2212 \u03c1 0 i \u2212 \u03c0 1 i + \u03c1 1 i \u2212 2\u03c0 0 i + 2\u03c1 0 i\n= \u2016r(A) \u2212 \u03c0\u20161\n\u2022 Case 4: r0i (B) \u2264 \u03c0 0 i \u2264 r 0 i (A) \u2264 \u03c1 0 i .\n\u2016r(B)\u2212 \u03c0\u20161 = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c0 j i\u2032 |+ (\u03c0 0 i \u2212 r 0 i (B)) + (r 1 i (B)\u2212 \u03c0 1 i )\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c1 j i\u2032 |+ (\u03c1 0 i \u2212 r 0 i (B)) + (r 1 i (B)\u2212 \u03c1 1 i )\n\u03c00i \u2212 \u03c1 0 i \u2212 \u03c0 1 i + \u03c1 1 i\n= \u2016r(B) \u2212 \u03c1\u20161 + 2\u03c0 0 i \u2212 2\u03c1 0 i < \u2016r(A) \u2212 \u03c1\u20161 + 2\u03c0 0 i \u2212 2\u03c1 0 i = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (\u03c1 0 i \u2212 r 0 i (A)) + (r 1 i (A)\u2212 \u03c1 1 i ) + 2\u03c0 0 i \u2212 2\u03c1 0 i\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (r 0 i (A) \u2212 \u03c0 0 i ) + (\u03c0 1 i \u2212 r 1 i (A))\n\u22122r0i (A) + 2r 1 i (A) + \u03c0 0 i + \u03c1 0 i \u2212 \u03c0 1 i \u2212 \u03c1 1 i + 2\u03c0 0 i \u2212 2\u03c1 0 i\n= \u2016r(A) \u2212 \u03c0\u20161 \u2212 4r 0 i (A) + 4\u03c0 0 i \u2264 \u2016r(A) \u2212 \u03c0\u20161\n\u2022 Case 5: \u03c00i \u2264 r 0 i (B) < r 0 i (A) \u2264 \u03c1 0 i .\n\u2016r(B)\u2212 \u03c0\u20161 = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c0 j i\u2032 |+ (r 0 i (B)\u2212 \u03c0 0 i ) + (\u03c0 1 i \u2212 r 1 i (B))\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c1 j i\u2032 |+ (\u03c1 0 i \u2212 r 0 i (B)) + (r 1 i (B)\u2212 \u03c1 1 i )\n+2r0i (B)\u2212 2r 1 i (B)\u2212 \u03c0 0 i \u2212 \u03c1 0 i + \u03c0 1 i + \u03c1 1 i\n= \u2016r(B) \u2212 \u03c1\u20161 + 4r 0 i (B)\u2212 2\u03c0 0 i \u2212 2\u03c1 0 i < \u2016r(A) \u2212 \u03c1\u20161 + 4r 0 i (B)\u2212 2\u03c0 0 i \u2212 2\u03c1 0 i = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (\u03c1 0 i \u2212 r 0 i (A)) + (r 1 i (A)\u2212 \u03c1 1 i ) + 4r 0 i (B)\u2212 2\u03c0 0 i \u2212 2\u03c1 0 i\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (r 0 i (A) \u2212 \u03c0 0 i ) + (\u03c0 1 i \u2212 r 1 i (A))\n+4r0i (B)\u2212 2r 0 i (A) + 2r 1 i (A) + \u03c0 0 i + \u03c1 0 i \u2212 \u03c0 1 i \u2212 \u03c1 1 i \u2212 2\u03c0 0 i \u2212 2\u03c1 0 i\n= \u2016r(A) \u2212 \u03c0\u20161 + 4r 0 i (B)\u2212 4r 0 i (A) \u2264 \u2016r(A) \u2212 \u03c0\u20161\n\u2022 Case 6: r0i (B) < r 0 i (A) \u2264 \u03c0 0 i < \u03c1 0 i .\n\u2016r(B)\u2212 \u03c0\u20161 = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c0 j i\u2032 |+ (\u03c0 0 i \u2212 r 0 i (B)) + (r 1 i (B)\u2212 \u03c0 1 i )\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(B)\u2212 \u03c1 j i\u2032 |+ (\u03c1 0 i \u2212 r 0 i (B)) + (r 1 i (B)\u2212 \u03c1 1 i )\n+\u03c00i \u2212 \u03c1 0 i \u2212 \u03c0 1 i + \u03c1 1 i\n= \u2016r(B) \u2212 \u03c1\u20161 + 2\u03c0 0 i \u2212 2\u03c1 0 i < \u2016r(A) \u2212 \u03c1\u20161 + 2\u03c0 0 i \u2212 2\u03c1 0 i = \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (\u03c1 0 i \u2212 r 0 i (A)) + (r 1 i (A)\u2212 \u03c1 1 i ) + 2\u03c0 0 i \u2212 2\u03c1 0 i\n= \u2211\ni\u2032 6=i\n\u2211 j |r j i\u2032(A) \u2212 \u03c1 j i\u2032 |+ (\u03c0 0 i \u2212 r 0 i (A)) + (r 1 i (A) \u2212 \u03c0 1 i )\n\u2212\u03c00i + \u03c1 0 i + \u03c0 1 i \u2212 \u03c1 1 i + 2\u03c0 0 i \u2212 2\u03c1 0 i\n= \u2016r(A) \u2212 \u03c0\u20161\nFinally, we give an example showing that population monotonicity does not hold in the general case for \u2016 \u00b7\u20161. First, we describe the set of attributes. We have one distinguished attribute X1 with 5 possible values x11, x21, x 3 1, x 4 1, and x 5 1 and 64 groups of binary attributes, indexed with the pairs of integers i, j \u2208 {1, 2, 3, 4}. These groups of attributes are denoted as X(1,1), X(1,2), . . .X(1,8), X(2,1), . . .X(8,8). Each group contains some large number \u03bb of indistinguishable attributes, each having the same set of possible values {x12, x 2 2}. We have 16 alternatives A1, A2, . . . , A8, and B1, B2, . . . B8, and our goal is to select a subset of k = 8 of them.\nWe start with describing these alternatives on binary attributes: each alternative Ai has the value x12 on all attributes X(i,\u00b7) and the value x22 on all the remaining ones; each alternative Bi has the value x 1 2 on all attributes X(\u00b7,i) and the value x22 on all the remaining ones. For the binary attributes we set the target probabilities to \u03c012 = 1/8 and \u03c0 2 2 = 7/8. Due to this construction, we see that the only two subsets that perfectly agree with target distributions on each of binary attributes are A = {A1, A2, . . . , A8} and B = {B1, B2, . . . , B8}. Indeed, every subset S includingAi andBj , would have r(S) \u2265 1/4 at least for one group of attributes X(i,j). Since \u03bb is large, we infer that, independently what happens on the distinguished attribute X1, the only possible winning committee is either A = {A1, A2, . . . , A8} or B = {B1, B2, . . . , B8}.\nNext, let us describe what happens on the attribute X1. The vector \u3008r j i (A)\u3009 is equal to \u3008r j i (A)\u3009 = (1/2, 0, 1/2, 0, 0). For the committee B, we have \u3008rji (B)\u3009 = (1/4, 1/4, 1/4, 1/8, 1/8), and the vector of target distributions for X1 is equal \u03c01 = (0, 0, 3/8 + \u01eb, 5/8 \u2212 \u01eb, 0). We can see that \u2016r(A) \u2212 \u03c0\u20161 = 1/2+1/8\u2212\u01eb+5/8\u2212\u01eb = 1.25\u22122\u01eb. Since, \u2016r(B)\u2212\u03c0\u20161 = 1/4+1/4+1/8+\u01eb+4/8\u2212\u01eb+1/8 = 1.25, we get that A is a winning committee. However, if we modify the target fractions so that \u03c11 = (1/4, 0, 9/32 + \u01eb1, 15/32 \u2212 \u01eb2, 0), we will get \u2016r(A) \u2212 \u03c1\u20161 = 1/4 + 7/32 \u2212 \u01eb1 + 15/32 \u2212 \u01eb2 = 30/32 \u2212 \u01eb1 \u2212 \u01eb2 and \u2016r(B) \u2212 \u03c1\u20161 = 1/4 + 1/32 + \u01eb1 + 11/32\u2212 \u01eb2 + 1/8 = 24/32 + \u01eb1 \u2212 \u01eb2, thus, B is winning according to \u03c1. However, B has lower representation of x11 than A, and \u03c1 was obtained from \u03c0, by increasing the fraction of \u03c011 . This completes the proof.\n\u2737\nOther properties, specific to multi-attribute proportional representation, could also be considered, for instance by adapting properties studied by Elkind et al. [10]. One such property is candidate monotonicity (if we add more candidates to the database, the new committee must be at least as good as the old one). We leave this for further research."}, {"heading": "6 Computing Optimal Committees", "text": "In this section we now investigate the computation complexity of optimal committees. We start with observing that the problem of deciding whether there is a perfect committee for a given instance is NP-complete.\nProposition 5 Given set of attributes X , a set of candidates C, a vector of target distributions \u03c0, an integer k, deciding whether there is a perfect committee is NP-complete.\nProof. Membership is straightforward. Hardness follows by reduction from the NP-complete problem EXACT COVER WITH 3-SETS, or X3C [12]. Let I = \u3008X,S\u3009 with X = {x1, . . . , x3k} and S = {S1, . . . , Sn}\nwith |Si| = 3 for each i. I is a positive instance of X3C iff there is a collection S \u2032 \u2286 S with |S \u2032| = k and \u222a{S|S \u2208 S \u2032} = X . Define the following instance of PERFECT COMMITTEE: let X1, . . . , X3k be 3k binary attributes, and let C consist of m candidates c1, . . . , cm with Xi(cj) = 1 if xi \u2208 Sj and Xi(cj) = 0 if xi /\u2208 Sj . Finally, for each i, \u03c0i(0) = k\u22121k and \u03c0i(1) = 1 k . We want a committee of size k. A = {ci1 , . . . , cik} is perfect for \u03c0 if for each Xi, there is exactly one j \u2208 {1, . . . , k} such that Xi(cij ) = 1, which is equivalent to saying that for each xi, there is exactly one Sj \u2208 {Si1 , . . . , Sik} such that xi \u2208 Sj . Thus, there is a perfect committee for \u03c0 and C if and only if I is a positive instance. \u2737\nThis simple result implies that the decision problem associated with finding an optimal committee (is there a committee whose loss is less than \u03b8?) is NP-hard for all loss functions. However, if the number of attributes p is fixed, the problem is solvable in polynomial time.\nProposition 6 Let p be a constant integer. Given set of p attributes X , a set of candidates C, a vector of target distributions \u03c0, an integer k, deciding whether there is a perfect committee is solvable in polynomial time.\nProof. Let q = maxi qi. Each candidate can be viewed as a vector of values indexed with the attributes; there are qp such possible vectors. Since the size of the input is at least q, the number of distinct candidates is bounded by the polynomial function of the size of the input. The rest of the proof is the same as the proof of Theorem 4. \u2737"}, {"heading": "6.1 Approximating optimal committees", "text": "A natural approach to alleviate the NP-hardness of the problem is to analyze whether it can be well approximated. Before proceeding to presentation of our approximation algorithms, the core technical contribution of this paper, we define the notion of approximability used in our analysis.\nDefinition 6 An algorithm A is an \u03b1-additive-approximation algorithm for OPTIMALREPRESENTATION if for each instance I of OPTIMALREPRESENTATION it holds that |f(\u03c0, r(A)) \u2212 f(\u03c0, r(A\u2217))| \u2264 \u03b1, where A is the committee returned by A for I , and A\u2217 an optimal committee.\nIt is easy to observe that for binary domains it holds that \u2016\u03c0, r(A)\u20161 = 2\u2016\u03c0, r(A)\u20161,max. This implies that for binary domains, an \u03b1-additive-approximation algorithm for \u2016 \u00b7 \u20161 is an \u03b12 -additive-approximation algorithm for \u2016 \u00b7 \u20161,max.\nIn this paper we mostly present computational results for binary domains. However, this assumption is not as restrictive as it may seem\u2014every instance of the OPTIMALREPRESENTATION problem can be transformed to a new instance with binary domains in the following way:\n\u2022 Xnew = {Xij | i = 1, . . . , p, j = 1, . . . , |Di|}.\n\u2022 Cnew = {c \u2032 l | l = 1, . . . ,m}.\n\u2022 \u03c0new = (\u03c0i,j | 1 \u2264 i \u2264 p, 1 \u2264 j \u2264 |Di|), where for all i = 1, . . . ,m, j = 1, . . . , p and j = 1, . . . , |Di|, \u03c00i,j = \u03c0 j i and \u03c0 1 i,j = 1\u2212 \u03c0 j i .\nThe following lemma shows how to obtain approximation guarantees for arbitrary domains having guarantees for the problem transformed to binary domains.\nLemma 1 For a given committee A and target distribution \u03c0, let Anew and \u03c0new denote the committee and target distributions obtained as above. The following holds:\n1. \u2016\u03c0new, r(Anew)\u20161 = 2\u2016\u03c0, r(A)\u20161.\n2. 1 \u2264 \u2016\u03c0new,r(Anew)\u20161,max\u2016\u03c0,r(A)\u20161,max \u2264 maxi |Di|.\n3. max(\u03c0new, r(Anew)) = max(\u03c0, r(A)).\nProof. We prove the first equality\u2014the proof for the other two is similar.\n\u2016\u03c0, r(A)\u20161 = \u2211\ni,j\n|rji (A)\u2212 \u03c0 j i | =\n\u2211\ni,j\n\u2223 \u2223 \u2223 \u2223 \u2223 |{c \u2208 A : Xi(c) = x j i}| k \u2212 \u03c0ji \u2223 \u2223 \u2223 \u2223 \u2223\n= \u2211\ni,j\n\u2223 \u2223 \u2223 \u2223 |{c \u2208 Anew : Xi,j(c) = 1}|\nk \u2212 \u03c01i,j\n\u2223 \u2223 \u2223 \u2223\n= 1\n2\n\u2211\ni,j\n(\u2223\n\u2223 \u2223 \u2223\n|{c \u2208 Anew : Xi,j(c) = 1}|\nk \u2212 \u03c01i,j\n\u2223 \u2223 \u2223 \u2223 + \u2223 \u2223 \u2223 \u2223 |{c \u2208 Anew : Xi,j(c) = 0}|\nk \u2212 \u03c00i,j\n\u2223 \u2223 \u2223 \u2223 )\n= 1\n2\n\u2211\ni,j\n\u2211\n\u2113\u2208{0,1}\n|r\u2113i,j(A)\u2212 \u03c0 \u2113 i,j | =\n1 2 \u2016\u03c0new, r(Anew)\u20161.\n\u2737\nLemma 1 has interesting implications\u2014first shows that the transformed instance has the has the same perfect committees as the original instance; then it shows how to obtain additive approximation guarantees for arbitrary domains having guarantees for the problem restricted to binary domains, for different loss functions."}, {"heading": "6.2 Approximation algorithms", "text": "In this section we show an approximation algorithm for the OPTIMALREPRESENTATION problem. The algorithm is given in Figure 1 and is parameterized by an integer value \u2113. It starts with a random collection of k samples and, in each step, it looks whether it is possible to replace some \u2113 items from the current solution with some other \u2113 items to obtain a better solution. The algorithm continues until it cannot find any pair of sets of \u2113 items that improves the current solution. As we show now, the approximation guarantees depend on the value of the parameter \u2113.\nTheorem 1 For binary domains natural distributions, and for the \u2016 \u00b7 \u20161 loss function, the local search algorithm defined on Figure 1 with \u2113 = 1 is a |X |-additive-approximation algorithm for OPTIMALREPRESENTATION.\nProof. Let A\u2217 denote an optimal solution for a given instance I of the problem of finding a perfect committee. Let A \u2208 Sk(C) denote the set returned by the local search algorithm from Figure 1. From the condition in the \u201cwhile\u201d loop, we know that there exist no c \u2208 C and a \u2208 A such that \u2016\u03c0, r(A)\u20161 > \u2016\u03c0, r((A\\{a})\u222a{c})\u20161.\nNow, let Xex \u2286 X denote the set of all attributes for which A achieves exact match with \u03c0, that is, such that for each Xi \u2208 Xex, we have that r1i (A) = \u03c0 1 i and r 2 i (A) = \u03c0 2 i .\nLet us consider the procedure consisting in taking the items from A \\ A\u2217 and, one by one, replace them with arbitrary items from A\u2217 \\ A. This procedure, in |A \\ A\u2217| steps, transforms A into an optimal solution A\u2217. We now estimate the total gain g induced by this procedure. For each item a \u2208 A \\A\u2217, by a\u2032 \u2208 A\u2217 \\ A we denote the item which was taken to replace a in the procedure. For each attribute Xi \u2208 X we define the gain gi(a, a\u2032) of replacing a by a\u2032 as:\ngi(a, a \u2032) =\n\u2211\nj\u2208{1,2}\n(\n|rji (A)\u2212 \u03c0 j i | \u2212 |r j i (A \\ {a} \u222a {a \u2032})\u2212 \u03c0ji | ) .\nWe now extend this definition to sets of k candidates:\ngi(B,B \u2032) =\n\u2211\nj\u2208{1,2}\n(\n|rji (A)\u2212 \u03c0 j i | \u2212 |r j i ((A \\ B) \u222a B \u2032)\u2212 \u03c0ji | ) .\nIf Xi \u2208 Xex, then ri(A) = \u03c0i, and so the replacement cannot improve the quality of the solution relatively to Xi, hence\n\u2211\ni\u2208Xex\ngi(A \\A \u2217, A\u2217 \\A) \u2264 0. (1)\nNote that gi(a, a\u2032) \u2208 {\u2212 2k , 0, 2 k}. Moreover, for each attribute Xi /\u2208 Xex there are two possible cases:\n1. rji (A) > \u03c0 j i and each exchange of candidate that results in a negative gain increases r j i (A).\n2. rji (A) < \u03c0 j i and each exchange that results in a negative gain decreases r j i (A).\nIntuitively, 1. and 2. mean that for attributes outside of Xex, the negative gains cumulate. Formally, for each X /\u2208 Xex:\ngi(A \\A \u2217, A\u2217 \\A) \u2264\n\u2211\na\u2208A\\A\u2217\ngi(a, a \u2032). (2)\nFrom the condition in the \u201cwhile\u201d loop, we have that for each a \u2208 A \\A\u2217: \u2211 i gi(a, a \u2032) \u2264 0, and so:\n\u2211\ni\n\u2211\na\u2208A\\A\u2217\ngi(a, a \u2032) \u2264 0. (3)\nWe now give the following sequence of inequalities:\ng = \u2211\ni\ngi(A \\A \u2217, A\u2217 \\A)\n= \u2211\ni\u2208Xex\ngi(A \\A \u2217, A\u2217 \\A) +\n\u2211\ni/\u2208Xex\ngi(A \\A \u2217, A\u2217 \\A)\n\u2264 \u2211\ni/\u2208Xex\ngi(A \\A \u2217, A\u2217 \\A) \u2264\n\u2211\ni/\u2208Xex\n\u2211\na\u2208A\\A\u2217\ngi(a, a \u2032)\n\u2264 \u2212 \u2211\ni\u2208Xex\n\u2211\na\u2208A\\A\u2217\ngi(a, a \u2032)\n\u2264 |Xex| \u00b7 k \u00b7 2\nk = 2|Xex|. (4)\nFinally, for each attribute Xi \u2208 Xex the loss relative to Xi, i.e., |r0i \u2212 \u03c0 0|+ |r1i \u2212 \u03c0 1|, is at most 2. Thus, we get g \u2264 2(|X | \u2212 |Xex|), which leads to g \u2264 |X |. \u2737\nIs the bound |X | from Theorem 1 a good result? One way to interpret this result is to observe that a solution that for half of the attributes gives exact match, and for other half is arbitrarily bad, is an |X |- approximate solution. We do not know whether the bound |X | is reached, but we now show that a lower bound on the error made by the algorithm with \u2113 = 1 is 23 |X |.\nExample 2 Consider 3p binary attributes X1, . . . , X3p, 4\u2113 candidates C = {a1, . . . , a2\u2113, b1, . . . , b2\u2113}, and let k = 2\u2113. For each i \u2264 p, we have: for j \u2264 \u2113,Xi(aj) = 1 and Xi(bj) = 1; for j > \u2113,Xi(aj) = 0 and Xi(bj) = 0. For each i such that p < i \u2264 2p we have: for j \u2264 \u2113,Xi(aj) = 1 and Xi(bj) = 0; for j > \u2113,Xi(aj) = 0 and Xi(bj) = 1. For i > 2p we have: for each j,Xi(aj) = 1 and Xi(bj) = 0. Finally, for i \u2264 2p let \u03c00i = \u03c0 1 i = 1 2 , and for i > 2p let \u03c0 0 i = 1\u2212\u03c0 1 i = 1. It can be easily checked that B = {b1, . . . , b2\u2113} is a perfect committee. Now, A = {a1, . . . , a2\u2113} is locally optimal. To check this, we consider two cases: in the first case, where (r \u2264 \u2113 and q \u2264 \u2113) or (r > \u2113 and q > \u2113), replacing ar with bq does not change the distance to the target distribution on each of the first p attributes, increases the distance on each of the next p attributes and decreases the distance on each of the last p attributes. For the second case, where (r \u2264 \u2113 and q > \u2113) or (r > \u2113; q \u2264 \u2113), the line of reasoning is similar. Finally, \u2016\u03c0, r(A)\u20161 = 2p = 23 |X |.\nA better approximation bound can be obtained with \u2113 = 2:\nLemma 2 Consider n buckets X1, . . . , Xn, such that in the i-th bucket Xi there are xi white balls and yi black balls. Let A denote the number of pairs of balls such that both balls in the pair belong to the same bucket and are of different color. Let us consider the procedure in which one iteratively selects a bucket and takes out two balls with different colors from the selected bucket. The procedure ends after B steps, when no further steps are possible (in each bucket, either there are no balls anymore, or all balls have the same color). It holds that A \u2265 B 2\nn .\nProof. Without loss of generality let us assume that for each i: xi \u2264 yi. Thus, B = \u2211 i xi and\nA = \u2211 i xiyi \u2264 \u2211 i x 2 i . The inequality \u2211 i x 2 i \u2265\n( \u2211\ni xi)\n2\nn follows from Jensen\u2019s inequality applied to the quadratic function. \u2737\nLemma 3 Let xi, yi, Ai, 1 \u2264 i \u2264 n, be real values satisfying the following constraints:\n1. xi \u2265 Ai\n2n\u22122(i\u22121) , for each 1 \u2264 i \u2264 n,\n2. Ai \u2265 Ai\u22121 \u2212 2xi\u22121, for each 2 \u2264 i \u2264 n,\n3. yi \u2265 xi\n2n\u22122(i\u22121)\u22121 , for each 1 \u2264 i \u2264 n.\nThen:\nn \u2211\ni=1\nyi \u2265 |A1| lnn\n4n .\nProof. We can view the set of above inequalities 1, 2, 3 as a linear program with (3n \u2212 1) variables (all xi and yi for 1 \u2264 i \u2264 n and Ai for 2 \u2264 i \u2264 q; we treat A1 as a constant) and (3n \u2212 1) constraints. Thus, we know that \u2211\ni yi achieves the minimum when each from the above constraints is satisfied with equality.\nWe show by induction that the values xi = A1 2n and Ai = 2n\u22122(i\u22121) 2n A1 constitute the solution to the set of equalities that is derived by taking constraints 1, and 2, and treating them as equalities. We can show that\nby induction: It is easy to see that the base step, for i = 1, holds:\nx1 = A1\n2n\u2212 2(i\u2212 1) =\n|A1|\n2n ,\nA1 \u2265 2n\u2212 2(1\u2212 1)\n2n A1.\nLet us assume that from the equalities 1 and 2 taken for i < j, it follows that xi = A12n and Ai = 2n\u22122(i\u22121) 2n A1, for i < j. We will show that from equalities 1 and 2 for i = j it follows that xj = A12n andAj = 2n\u22122(j\u22121) 2n A1:\nxj = Aj\n2n\u2212 2(j \u2212 1) =\n1 2n\u2212 2(j \u2212 1) \u00b7 2n\u2212 2(j \u2212 1) 2n A1 = |A1| 2n ,\nAj = Aj\u22121 \u2212 2xj\u22121 = 2n\u2212 2((j \u2212 1)\u2212 1)\n2n A1 \u2212 2\n|A1|\n2n =\n2n\u2212 2(j \u2212 1)\n2n A1.\nFrom constraint 3, treated as equality, we get:\nyi = xi\n2n\u2212 2(i\u2212 1)\u2212 1 =\n|A1|\n2n(2n\u2212 2(i\u2212 1)\u2212 1) .\nThus, we infer that \u2211n i=1 yi is minimized when yi = |A1| 2n(2n\u22122(i\u22121)\u22121) . We recall that Hn denotes the n-th harmonic number (Hn = \u2211n i=1 1 n ), and that ln(n+ 1) < Hn \u2264 1 + ln(n). As a result we get:\nn \u2211\ni=1\nyi \u2265 A1 2n\nn \u2211\ni=1\n1\n(2n\u2212 2(i\u2212 1)\u2212 1) \u2265 A1 2n\nn \u2211\ni=1\n1\n2n\u2212 2(i\u2212 1) (5)\n= A1 4n\nn \u2211\ni=1\n1\n(n\u2212 i+ 1)) = A1 4n Hn \u2265 A1 lnn 4n . (6)\n\u2737\nTheorem 2 For binary domains (|Di| = 2, for each 1 \u2264 i \u2264 p), natural distributions, and for \u2016 \u00b7 \u20161 loss function, the local search algorithm from Figure 1 with \u2113 = 2 is a ln(k/2)2 ln(k/2)\u22121 ( |X |+ 6|X|k ) -additiveapproximation algorithm for OPTIMALREPRESENTATION.\nProof. In this proof we use similar idea to the proof of Theorem 1, but the proof is technically more involved. As before, byA\u2217 andA we denote the optimal solution and the solution returned by the local search algorithm, respectively. Similarly to the previous proof, by Xex \u2282 X we denote the set of all attributes for which A achieves exact match with \u03c0, i.e.,\nXex = { Xi \u2208 X : r 1 i (A) = \u03c0 1 i } .\nWe also define the set Xaex \u2282 X of all attributes for which A achieves almost exact match with \u03c0, i.e.,\nXaex =\n{\nXi \u2208 X : |r 1 i (A)\u2212 \u03c0 1 i | \u2264\n1\nk\n}\n.\nLet qf = |A\\A\u2217| 2 and q = \u230aqf\u230b. Let us rename the items from A \\ A \u2217 so that A \\ A\u2217 = {a1, a2, . . . , a2qf }, and the items from A\u2217 \\ A, so that A\u2217 \\ A = {a\u20321, a \u2032 2, . . . , a \u2032 2qf\n}. Hereinafter, we follow a convention in which the elements from A\u2217 \\ A are marked with primes. Renaming of the items that we described above, allows us to the define the following sequence of pairs (a1, a\u20321), . . . , (a2qf , a \u2032 2qf ) in which each element from A \\A\u2217 is paired with (assigned to) exactly one element from A\u2217 \\A. For each pair (aj , a\u2032j) and for each attribute Xi we consider what happens if we replace ai in A \\A\n\u2217 with a\u2032i. One of three scenarios can happen, after such replacement:\n1. The value r0i (A) can increase by 1 k (in such case r 1 i (A) decreases by 1 k ), which we denote by\nXi(aj \u2194 a \u2032 j) = 1,\n2. The value r0i (A) can decrease by 1 k (in such case r 1 i (A) increases by 1 k ), which we denote by\nXi(aj \u2194 a \u2032 j) = \u22121, or\n3. The value r0i (A) can remain unchanged (in such case r 1 i (A) also remains unchanged), which we denote\nby Xi(aj \u2194 a\u2032j) = 0.\nWe follow a procedure which, in q consecutive steps, replaces pairs of items from A \\A\u2217, with the pairs of items from A\u2217 \\ A. A pair (ai, aj) is always replaced with (a\u2032i, a \u2032 j). In other words, when looking for a pair from A\u2217 \\A to replace (ai, aj) we follow the assignment rule induced by renaming, as described above. The way in which we create pairs within A \\ A\u2217 for replacement (the way how (ai, aj) is selected in each of q consecutive steps) will be described later. After this whole procedure A can differ from A\u2217 with at most one element, hence, having distance to the optimal distribution at most equal to |X | 2k . Let us define the sequence of sets A\u03041, A\u03042, . . . , A\u0304q in the following way: we define A\u03041 = A \\ A\u2217, and we define A\u0304j+1 as A\u0304j after removing the pair from A \\A\u2217 that was used in replacement in the j-th step of our procedure.\nAs before, for each B \u2286 A \\ A\u2217 and B\u2032 \u2286 A\u2217 \\ A, and for each attribute Xi \u2208 X we define the gain gi(B,B \u2032):\ngi(B,B \u2032) =\n\u2211\nj\u2208{1,2}\n(\n|rji (A)\u2212 \u03c0 j i | \u2212 |r j i ((A \\B) \u222aB \u2032)\u2212 \u03c0ji | ) .\nSimilarly as in the proof of Theorem 1, we observe that for Xi /\u2208 Xaex the negative gains cumulate: i.e., that for each sequences of disjoint sets B1, B2, . . . , Bs and B\u20321, B \u2032 2, . . . , B \u2032 s such that for every 1 \u2264 j \u2264 s, Bj \u2286 A \\A \u2217, B\u2032j \u2286 A \u2217 \\A, and |Bj | = |B\u2032j | \u2264 2 we have that:\ngi( \u22c3\nj\nBj , \u22c3\nj\nB\u2032j) \u2264 \u2211\nj\ngi(Bj , B \u2032 j). (7)\nWhy is this the case? If Xi /\u2208 Xaex, then the distance between A and the target distribution on attribute Xi is at least equal to 2 \u00b7 2k . In other words: |r 0 i (A) \u2212 \u03c0 0 i | \u2265 2 k and |r 1 i (A) \u2212 \u03c0 1 i | \u2265 2 k . Without loss of generality let us assume that r0i (A) \u2212 \u03c0 0 i \u2265 2 k . Since each set Bj and each set B \u2032 j has at most two elements, replacing Bj with B\u2032j can change the distance between A and the target distribution, for each attribute, by at most 2k . Consequently, if gi(Bj , B \u2032 j) is negative, then it means that replacingBj with B \u2032 j makes the difference r0i (A)\u2212\u03c0 0 i even greater. Thus, each such replacement with the negative gain g causes A to move further from the target distribution by the value g. Naturally, each replacement with the positive gain g causes A to move closer to the target distribution by at most g. Consequently, after the sequence of replacement \u222ajBj \u2194 B\u2032j the distance on the attribute Xi cannot improve by more than \u2211 j gi(Bj , B \u2032 j).\nIn contrast to the proof of Theorem 1, we note that here we require that Xi /\u2208 Xaex instead of Xi /\u2208 Xex\u2014 the above observation is not valid if Xi \u2208 Xaex even if Xi /\u2208 Xex.5\nNext, for each A\u0304j , and each attribute Xi \u2208 Xex, we define a set Wj of annihilating pairs as:\nWj(Xi) = { ((ax, Xi), (ay, Xi)) : ax \u2208 A\u0304j ; ay \u2208 A\u0304j ;x < y;Xi(ax \u2194 a \u2032 x) = \u2212Xi(ay \u2194 a \u2032 y) } .\n5 Consider an example in which \u03c01i = 1 k and r1i (A) = 2 k . Let us consider sets B = {b1, b2}, B\u2032 = {b\u20321, b \u2032 2}, C = {c1, c2}, C \u2032 =\n{c\u20321, c \u2032 2} such that: Xi(c1) = Xi(c2) = Xi(b \u2032 1) = Xi(b \u2032 2) = d 1 i , and Xi(c \u2032 1) = Xi(c \u2032 2) = Xi(b1) = Xi(b2) = d 2 i , Thus, we have that:\n\u2022 Replacing B with B\u2032 results with r1i (A) = 4 k . \u2022 Replacing C with C\u2032 results with r1i (A) = 0. \u2022 Replacing B \u222aC with B\u2032 \u222a C\u2032 results with r1i (A) = 2 k .\nWe can repeat this reasoning for r2i (A), thus having, gi(B,B \u2032) = \u2212 4 k , gi(C,C\u2032) = 0 and gi(B \u222a C,B\u2032 \u222a C\u2032) = 0.\n(a1, X4), (a4, X4) ) , ( (a1, X7), (a3, X7) ) }.\nIntuitively, if ((ax, Xi), (ay, Xi)) \u2208 Wj , then both replacing ax with a\u2032x and replacing ay with a \u2032 y move the original set A (i.e., the set before any of the replacements) further from the target distribution for the attribute Xi, but replacing {ax, ay} with {a\u2032x, a \u2032 y} does not change the distance of A from the target distribution for the attribute Xi. For each j, we set Wj = \u222ai\u2208XexWj(Xi). Let us denote by P the number of annihilated pairs of candidates considered in the process of replacing items from A \\ A\u2217 with items from A\u2217 \\ A. Formally, P is the size of the maximal subset W \u2286 W1 composed of disjoint annihilating pairs, i.e., for each i \u2264 p, for each ax, and for each ay, if ((ax, Xi), (ay , Xi)) \u2208 P then there exists no b 6= ay such that ((ax, Xi), (b,Xi)) \u2208 P or ((b,Xi), (ax, Xi)) \u2208 P . From Lemma 2, after defining each bucket Xi as containing xi white balls and yi black balls, where xi (respectively, yi) is the number of candidates aj \u2208 A\u03041 with the value Xi(aj \u2194 a\u2032j) equal to 1 (respectively, -1), it follows that W1 \u2265 P 2\n|Xex| . The concept of annihilating pairs is explained on\nexample in Table 1. We are now ready to describe the way in which we select pairs from A \\ A\u2217 in our procedure. In each step j, the pair (aj,1, aj,2) from A \\ A\u2217 is selected in the following way. For each item a let sj,1(a) be the number of pairs p in Wj such that p = ((a, \u00b7), (\u00b7, \u00b7)) or p = ((\u00b7, \u00b7), (a, \u00b7)), let aj,1 be such that sj,1(aj) = maxa\u2208A\u0304j sj,1(a), and let sj,1 = sj,1(aj). Next, for each item b let sj,2(b) be the number of pairs p inWj such that p = ((aj,1, \u00b7), (b, \u00b7)) or p = ((b, \u00b7), (aj,1, \u00b7)), let aj,2 be such that sj,2(b) = maxb\u2208A\u0304j sj,2(b), and let sj,2 = sj,2(aj,2).\nLet us consider the procedure described above on the example from Table 1. The item a1 belongs to 8 pairs in W1 (a1 belongs to 2 pairs for attribute X1, X2, and X3, and to one pair for attributes X4 and X7), thus: s1,1(a1) = 8. Moreover, s1,1(a2) = 5, s1,1(a3) = 6, and s1,1(a4) = 7. Consequently, a1 will be the item that will replaced with a\u20321 in the first step: aj,1 = a1 and sj,1 = 8. Further, s1,2(a2) = 2 (there are two annihilating pairs including a1 and a2, i.e.,: ( (a1, X1), (a2, X1) ) and ( (a1, X2), (a2, X2) )\n); similarly: s1,2(a3) = 3, and s1,2(a4) = 3. Thus, an arbitrary of the two items, a3 and a4, say a3, will be the second item that will be replaced with a\u20323 in the first step. In the second step only two items, a2 and a4, are left, so both will be replaced with a\u20322 and a \u2032 4 in the second step. Nevertheless, let us illustrate our definitions also in the second step of the replacement procedure. The set A\u03042 consists of two remaining items: a2 and a4. We have W2 = { ( (a2, X2), (a4, X2) ) , ( (a2, X3), (a4, X3) )\n}. Naturally, s2,1(a2) = s2,1(a4) = s2,2(a2) = s2,2(a4) = 2.\nWe want now to derive bounds on the values sj,1 and sj,2. The following inequalities hold:\n1. sj,1 \u2265 2|Wj |\n2qf\u22122(j\u22121) for each 1 \u2264 j \u2264 q.\nWj contains pairs of items belonging to A\u0304j . A\u03041 has 2qf items, and A\u0304j+1 is obtained from A\u0304j by\nremoving two items. Consequently, A\u0304j has 2qf \u2212 2(j \u2212 1) items, and thus, Wj contains pairs of 2qf \u2212 2(j \u2212 1) different items. From the pigeonhole principle it follows that there exists an item that belongs to at least 2|Wj |2qf\u22122(j\u22121) pairs. Naturally, we also get the weaker constraint: sj,1 \u2265 |Wj | 2qf\u22122(j\u22121) .\n2. |Wj | \u2265 |Wj\u22121| \u2212 2sj\u22121,1 for each 2 \u2264 j \u2264 q.\nEach item in Wj\u22121 belongs to at most sj\u22121,1 pairs (this follows from the definition of sj\u22121,1). Wj contains all pairs that Wj\u22121 contained, except for the pairs involving aj\u22121,1, aj\u22122,2 (to obtain A\u0304j , we removed these two items from A\u0304j\u22121). Consequently, Wj is obtained from Wj\u22121 by removing at most 2sj\u22121,1 pairs of items.\n3. sj,2 \u2265 sj,1\n2qf\u22122(j\u22121)\u22121 for each 1 \u2264 j \u2264 q.\nIn Wj , there are sj,1 pairs of items involving aj,1. As we noted before, Wj contains pairs of 2qf \u2212 2(j \u2212 1) different items. Thus, in Wj , aj,1 is paired with at most 2qf \u2212 2(j \u2212 1)\u2212 1 items. From the pigeonhole principle it follows that aj,1 must be paired with some item at least\nsj,1 2qf\u22122(j\u22121)\u22121 times.\nFrom Lemma 3 we get that:\nq \u2211\nj=1\nsj,2 \u2265 |W1| ln q\n4q . (8)\nBefore we proceed further let us make three observations regarding annihilating pairs. First, we note that for each Xi \u2208 Xex, and each ax and ay , if the value gi({ax, ay}, {a\u2032x, a \u2032 y}) is different from (gi(ax, a \u2032 x) + gi(ay, a \u2032 y)) than it is greater from (gi(ax, a \u2032 x) + gi(ay, a \u2032 y)) by 4 k . We also note that gi({ax, ay}, {a \u2032 x, a \u2032 y}) is greater than (gi(ax, a\u2032x) + gi(ay, a \u2032 y)) if and only if the changes Xi(ax \u2194 a \u2032 x) and Xi(ay \u2194 a \u2032 y) annihilate (this is illustrated in Figure 2). Further, we recall that the value sj,2 counts all attributes for which aj,1 and aj,2 constitute an annihilating pair. Thus, for each 1 \u2264 j \u2264 q::\n\u2211\ni\u2208Xex\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}) =\n\u2211\ni\u2208Xex\n(\ngi(aj,1, a \u2032 j,1) + gi(aj,2, a \u2032 j,2)\n) + sj,2 4\nk (9)\nOur second observation is similar in spirit to the first one. We note that for each Xi \u2208 Xex:\ngi(A \\A \u2217, A\u2217 \\A)\u2212\n\u2211\na\u2208A\\A\u2217\ngi(a, a \u2032) = the number of pairs that annihilated for Xi \u00d7\n4 k .\nThe above equality is illustrated in Figure 3. As a consequence, we get that:\n\u2211\nXi\u2208Xex\n(\ngi(A \\A \u2217, A\u2217 \\A)\u2212\n\u2211\na\u2208A\\A\u2217\ngi(a, a \u2032) ) = the number of pairs that annihilated \u00d7 4\nk .\nWe recall that after the replacement procedure A can differ from A\u2217 with at most one element, hence, having distance to the optimal distribution at most equal to |X | 2k . Thus:\n\u2211\nXi\u2208Xex\n(\ngi(A \\A \u2217, A\u2217 \\A)\u2212\nq \u2211\nj=1\n(\ngi(aj,1, a \u2032 j,1) + gi(aj,2, a \u2032 j,2)\n)\n) \u2264 P \u00b7 4\nk + |X |\n2 k . (10)\nOur third observation says that:\n\u2211\nXi\u2208Xaex\\Xex\ngi(A \\A \u2217, A\u2217 \\A)\u2212\n\u2211\nXi\u2208Xaex\\Xex\nq \u2211\nj=1\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}) \u2264 |Xaex \\Xex| . (11)\nWhere does Inequality 11 come from? Let us use the geometric interpretation, like the one from Figure 3. Let us consider an Xi, Xi \u2208 Xaex. For Xi, A lies in a distance of 2k on the left or on the right from the target distribution. Without loss of generality, let us assume it lies on the right. Now, if gi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}) < 0 then replacing (aj,1, aj,2) with (a \u2032 j,1, a \u2032 j,2) moves the current solution right. If gi({aj,1, aj,2}, {a\u2032j,1, a \u2032 j,2}) = 2 k , then replacing (aj,1, aj,2) with (a \u2032 j,1, a \u2032 j,2) moves the current solution by 2k on left. If gi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}) = 0, then replacing (aj,1, aj,2) with (a \u2032 j,1, a \u2032 j,2) either does not move the solution or moves it by 4k on left. Let us define yi = gi(A\\A\u2217, A\u2217 \\A)\u2212 \u2211q j=1 gi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}). If the solution moves q times to the right, then the total gain \u2212 \u2211q\nj=1 gi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}) will be maximized, achieving q 4 k . In\nsuch case however, the value gi(A \\A\u2217, A\u2217 \\A) will be equal to \u2212q 4k , and thus the value yi will be equal to 0. After some consideration, the reader will see that the value yi is maximized if the current solution moves q 2 times right and q 2 times left, each time by the value of 4 k . This way, the moves to the right induce the total gain of q2 \u00b7 4 k , the moves to the left induce the zero gain, but as a consequence, the current solution for Xi does not change (gi(A \\ A\u2217, A\u2217 \\ A) = 0). Thus, for each Xi \u2208 Xaex, yi is upper bounded by q 2 \u00b7 4 k \u2264 1, which proves Inequality 11.\nWe can further proceed with the proof by observing that from the condition in the \u201cwhile\u201d loop we get that for each 1 \u2264 j \u2264 q:\n0 \u2265 \u2211\ni\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2})\n\u2265 \u2211\ni\u2208Xex\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}) +\n\u2211\ni/\u2208Xex\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2})\nFrom Equality 9:\n\u2265 \u2211\ni\u2208Xex\n(\ngi(aj,1, a \u2032 j,1) + gi(aj,2, a \u2032 j,2)\n) + sj,2 4\nk +\n\u2211\ni/\u2208Xex\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}).\nThus, we get:\n\u2212 \u2211\ni\u2208Xex\n(\ngi(aj,1, a \u2032 j,1) + gi(aj,2, a \u2032 j,2)\n) \u2212 4\nk s2j > +\n\u2211\ni/\u2208Xex\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}). (12)\nNext, we give the following sequence of inequalities:\ng = \u2211\ni\ngi(A \\A \u2217, A\u2217 \\A)\n= \u2211\nXi\u2208Xex\ngi(A \\A \u2217, A\u2217 \\A) +\n\u2211\nXi\u2208Xaex\\Xex\ngi(A \\A \u2217, A\u2217 \\A) +\n\u2211\nXi /\u2208Xaex\ngi(A \\A \u2217, A\u2217 \\A)\nFrom Inequality 7, for all i /\u2208 Xaex, we have gi(A \\ A\u2217, A\u2217 \\ A) \u2264 \u2211 a\u2208A\\A\u2217 gi(a, a \u2032). Since the set\nA \\ A\u2217 and \u22c3q j=1{aj,1, aj,2} can differ by at most one item (which induces distance 2|X| k to the optimal solution), we have that\n\u2211\nXi /\u2208Xaex\ngi(A \\A \u2217, A\u2217 \\A) \u2264\n\u2211\nXi /\u2208Xaex\nq \u2211\nj=1\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}) +\n2|X |\nk .\nAnd, as a consequence:\ng \u2264 \u2211\nXi\u2208Xex\ngi(A \\A \u2217, A\u2217 \\A) +\n\u2211\nXi\u2208Xaex\\Xex\ngi(A \\A \u2217, A\u2217 \\A)\n+ \u2211\nXi /\u2208Xaex\nq \u2211\nj=1\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}) +\n2|X |\nk\n\u2264 \u2211\nXi\u2208Xex\ngi(A \\A \u2217, A\u2217 \\A) +\n\u2211\nXi\u2208Xaex\\Xex\ngi(A \\A \u2217, A\u2217 \\A)\n+ \u2211\nXi /\u2208Xex\nq \u2211\nj=1\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2})\u2212\n\u2211\nXi\u2208Xaex\\Xex\nq \u2211\nj=1\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}) +\n2|X |\nk .\nFrom Inequality 11 we get:\ng \u2264 \u2211\nXi\u2208Xex\ngi(A \\A \u2217, A\u2217 \\A) +\n\u2211\nXi /\u2208Xex\nq \u2211\nj=1\ngi({aj,1, aj,2}, {a \u2032 j,1, a \u2032 j,2}) +\n2|X |\nk + |Xaex \\Xex| .\nFrom Inequality 12:\ng \u2264 2|X |\nk + |Xaex \\Xex|+\n\u2211\nXi\u2208Xex\ngi(A \\A \u2217, A\u2217 \\A)\u2212\n\u2211\nXi\u2208Xex\nq \u2211\nj=1\n(\ngi(aj,1, a \u2032 j,1) + gi(aj,2, a \u2032 j,2)\n) \u2212 4\nk\n\u2211\nj\nsj,2.\nFrom Inequality 8:\ng \u2264 2|X |\nk + |Xaex \\Xex| \u2212\n|W1| ln q 4q \u00b7 4 k + \u2211\ni\u2208Xex\n\ngi(A \\A \u2217, A\u2217 \\A)\u2212\nq \u2211\nj=1\n(\ngi(aj,1, a \u2032 j,1) + gi(aj,2, a \u2032 j,2)\n)\n\n\nFrom Inequality 10:\ng \u2264 4|X |\nk + |Xaex \\Xex| \u2212\n|W1| ln q\nkq + P\n4 k .\nAs we noted before, from Lemma 2, we have that W1 \u2265 P 2\n|Xex| . Thus:\ng \u2264 4|X |\nk + |Xaex \\Xex|+\n4\nk\n(\nP \u2212 P 2 ln q\n4|Xex|q\n)\n.\nSince q \u2264 k2 , and since the function ln x x is decreasing for x \u2265 1:\ng \u2264 4|X |\nk + |Xaex \\Xex|+\n4\nk\n(\nP \u2212 P 2 ln(k/2)\n2|Xex|k\n)\nThe function f(P ) = P \u2212 P 2 ln(k/2) 2|Xex|k takes its maximum for P = |Xex|kln(k/2) . Thus:\ng \u2264 4|X |\nk + |Xaex \\Xex|+\n4 k \u00b7 |Xex|k 2 ln(k/2) = 4|X | k + |Xaex \\Xex|+ 2|Xex| ln(k/2) .\nSince our local-search algorithm for \u2113 = 2 also tries to perform local swaps on single items, we can repeat the analysis from the proof of Theorem 1. Thus, using Inequality 4 from there, we get that g \u2264 2|Xex|, and as a consequence: (\n1 2 \u2212 1 ln(k/2)\n)\ng \u2264 |Xex| \u2212 2|Xex| ln(k/2) .\nFor each attribute Xi \u2208 X \\Xaex the distance from A and the target distribution is bounded by 2. For Xi \u2208 Xaex this distance is bounded by 2k . Thus, we get that g \u2264 2(|X |\u2212 |Xex| \u2212 |Xaex \\Xex|) + |X | 2 k , and so:\ng +\n(\n1 2 \u2212\n1\nln(k/2)\n)\ng + 1\n2 g \u2264\n4|X |\nk + |Xaex \\Xex|+\n2|Xex|\nln(k/2)\n+ |Xex| \u2212 2Xex|\nln(k/2)\n+ (|X | \u2212 |Xex| \u2212 |Xaex \\Xex|) + |X | 2\nk\n= |X |+ 6|X |\nk\nFinally, we get:\ng \u2264 ln(k/2)\n2 ln(k/2)\u2212 1\n(\n|X |+ 6|X |\nk\n)\n.\nWhich proves the thesis. \u2737\nSince a brute-force algorithm can be used to compute an optimal solution for small values of k, Theorem 2 implies that for every \u01eb > 0 we can achieve an additive approximation of 12 (|X |+ \u01eb), that is we can guarantee that the solution returned by our algorithm will be at least 4 times better than a solution that is arbitrarily\nbad on each attribute. A natural open question is whether the local search algorithm achieves even better approximation guarantees for larger values of \u2113.\nOne may argue that the restriction to normal target distributions is a strong one. However, for a given vector of target distributions \u03c0, we can easily find a vector \u03c0N of target normal distributions such that \u2016\u03c0, \u03c0N\u20161 \u2264 2X k . Thus, the results from Theorems 1 and 2 can be modified by providing approximation ratio worse by an additive value of 2Xk but valid for arbitrary target distributions. Again, since an optimal solution can easily be computed for small values of k, we can get arbitrarily close to the approximation guarantees given by Theorems 1 and 2, even for non-normal target distributions.\nBelow we show a lower bound of 2X7 for the approximation ratio of the local search algorithm from Figure 1 with \u2113 = 2.\nExample 3 Consider 5p binary attributes X1, . . . , X5p, 6\u2113 and the set of distinct candidates C = {a1, . . . , a\u2113, a \u2032 1, . . . , a \u2032 \u2113, b1, . . . , b\u2113, b \u2032 1, . . . , b \u2032 \u2113, c1, . . . , c\u2113, c \u2032 1, . . . , c \u2032 \u2113} (in our database there exists a large number p of copies of each candidate from C). For each i, we have:\nX1 X2 X3 X4 X5 X6 X7\nai 1 0 1 1 0 0 1 a\u2032i 0 1 0 0 1 1 1 bi 0 0 0 0 0 0 0 b\u2032i 0 0 1 1 1 1 0 ci 1 1 1 1 0 0 0 c\u2032i 1 1 0 0 1 1 0\nWe note that for each candidate the value of the attribute X3 is the same as of X4 and the value of the attribute X5 is the same as of X6. For i \u2208 {1, 2, 3, 4, 5, 6} let \u03c00i = \u03c0 1 i = 1 2 , and let \u03c0 0 7 = 1\u2212 \u03c0 1 i = 1.\nLet k = 4p. It can be easily checked that the set consisting of p copies of candidates bi, b\u2032i, ci, c \u2032 i is a perfect committee. On the other hand, the set A consisting of 2p copies of candidates ai and a\u2032i is locally optimal. Indeed, replacing candidate ai or a\u2032i with bi or b \u2032 i moves the solution closer to the target distribution on X7, but the further from the target distribution on X1 or X2. The same situation happens if we replace candidates ai or a\u2032i with ci or c \u2032 i. If we replace two a-candidates with the pair consisting of one b-candidate (bi or b\u2032i) and one c-candidate (ci or c \u2032 i), then such replacement will move the solution closer by 4 k to the target distribution on X7, but will move the solution further by 2k on two attributes from {X3, X4, X5, X6}. Finally, \u2016\u03c0, r(A)\u20161 = 2p = 27 |X |."}, {"heading": "6.3 Parameterized Complexity", "text": "In this section, we study the parameterized complexity of the problem of finding a perfect committee. We are specifically interested whether for some natural parameters there exist fixed parameter tractable (FPT) algorithms. We recall that the problem is FPT for a parameter P if its each instance I can be solved in time O(f(P ) \u00b7 poly(|I|)).\nFrom the point of view of parameterized complexity, FPT is seen as the class of easy problems. There is also a whole hierarchy of hardness classes, FPT \u2286 W [1] \u2286 W [2] \u2286 \u00b7 \u00b7 \u00b7 (for details, we point the reader to appropriate overviews [9, 19, 11].\nObviously, the problem admits an FPT algorithm for the parameter m. Now, we present a negative result for parameter k (committee size) and a positive result for the parameter p (number of attributes).\nTheorem 3 The problem of deciding whether there exists a perfect committee is W[1]-hard for the parameter k, even for binary domains.\nProof. By reduction from the W[1]-complete PERFECTCODE problem [5]. Let I be an instance of PERFECTCODE that consists of a graph G = (V,E) and a positive integer k. We ask whether there exists\nV \u2032 \u2286 V such that each vertex in V is adjacent to exactly one vertex from V \u2032 (by convention, a vertex is adjacent to itself). From I we construct the following instance I \u2032 of the perfect committee problem. For each v \u2208 V there is a binary attribute Xv and a candidate cv. For each u, v \u2208 V , Xv(cu) = 1 if and only if u and v are adjacent in G. We look for a committee of size k. For each v, \u03c01v = 1 \u2212 \u03c0 0 v = 1 k . It is easy to see that perfect codes in I correspond to perfect committees in I \u2032. \u2737\nTheorem 4 For binary domains, there is an FPT algorithm for the perfect committee problem for parameter p.\nProof. Each item can be viewed as a vector of values indexed with the attributes; there are 2p such possible vectors: v1, . . . , v2p . For each vi, let ai denote the number of items that correspond to vi. Consider the following integer linear program, in which each variable bi is the number of candidates corresponding to vi in a perfect committee.\nminimize 2p \u2211\ni=1\nbi\nsubject to:\n(a) : bi \u2265 0 1 \u2264 i \u2264 2 p (b) : bi \u2264 ai 1 \u2264 i \u2264 2p\n(c) : 2p \u2211\ni=1\nbi = k\n(d) : \u2211\ni:vi[j]=1\nbi = \u03c0 1 i 1 \u2264 j \u2264 p\nThis linear program has 2p variables, thus, by the result of Lenstra [15, Section 5] it can be solved in FPT time for parameter p. This completes the proof. \u2737\nExample 4 Let p = 2, k = 5, and let the candidate database C consists of 4 candidates with value vector v1 = (0, 0), 2 with value vector v2 = (1, 0), 2 candidates with value vector v3 = (0, 1) and 2 candidates with value vector v4 = (1, 1). Let \u03c0 = ((0.2, 0.8), (0.6, 0.4)). The integer linear program is\nminimize b1 + b2 + b3 + b4 subject to:\n(a) : bi \u2265 0 1 \u2264 i \u2264 4\n(b) : b1 \u2264 4; b2 \u2264 2; b3 \u2264 2; b4 \u2264 2\n(c) : b1 + b2 + b3 + b4 = 5\n(d) : b1 + b3 = 1; b1 + b2 = 3\nand a solution is (b1 = 1, b2 = 2, b3 = 0, b4 = 2): a perfect committee is obtained by taking one candidate with value vector (0, 0), two candidates with value vector (1, 0), and two with value vector (1, 1).\nNow, consider the database C\u2032 consists of 5 candidates with value vector v1 = (0, 0), 2 with value vector v2 = (1, 0), 2 candidates with value vector v3 = (0, 1) and 1 candidate with value vector v4 = (1, 1). Let \u03c0 = ((0.2, 0.8), (0.6, 0.4)): then the corresponding constraints are inconsistent and there is no perfect committee.\nWe conclude this Section by a short discussion. Finding an optimal committee is likely to be difficult if the candidate database C is large, and the number of attributes not small. Assume |C| is large compared to\nthe size of the domain \u220fp\ni=1 |Di|, that each attribute value appears often enough in C and that there is no strong correlation between attributes in C: then, the larger |C|, the more likely C satisfies Full Supply, in which case finding an optimal committee is easy. The really difficult cases are when |C| is not significantly larger than the domain, or when C shows a high correlation between attributes."}, {"heading": "7 Conclusion", "text": "We have defined, and studied, multi-attribute generalizations of a well-known apportionment method (Hamilton), albeit with motivations that go far beyond party-list elections (such as the selection of a common set of items). We have shown positive and negative results concerning the properties satisfied by these generalizations and their computation, but a lot remains to be done. Note that other largest remainder apportionment methods can be generalized in a similar way, but it is unclear how largest-average methods can be generalized."}], "references": [{"title": "Criteria for proportional representation", "author": ["M. Balinski", "P. Young"], "venue": "Operations Research, 27(1):80\u201395", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1979}, {"title": "Fair Representation : Meeting the Ideal of One Man One Vote", "author": ["M. Balinski", "P. Young"], "venue": "Brookings Institution Press, seconde edition", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "On the computation of fully proportional representation", "author": ["N. Betzler", "A. Slinko", "J. Uhlmann"], "venue": "JAIR", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Computer-assisted constrained approval voting", "author": ["S.J. Brams"], "venue": "Interfaces, 20(5):67\u201380", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1990}, {"title": "Perfect code is W[1]-complete", "author": ["M. Cesati"], "venue": "Information Processing Letters, 81(3):163\u2013168", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Representative deliberations and representative decisions: Proportional representation and the Borda rule", "author": ["B. Chamberlin", "P. Courant"], "venue": "American Political Science Review, 77(3):718\u2013733", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1983}, {"title": "Bounded single-peaked width and proportional representation", "author": ["D. Cornaz", "L. Galand", "O. Spanjaard"], "venue": "ECAI, pages 270\u2013275", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "On computing optimal strategies in open list proportional representation: The two parties case", "author": ["N. Ding", "F. Lin"], "venue": "Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July 27 -31, 2014, Qu\u00e9bec City, Qu\u00e9bec, Canada., pages 1419\u20131425", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Parameterized Complexity", "author": ["R. Downey", "M. Fellows"], "venue": "Springer-Verlag", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1999}, {"title": "Properties of multiwinner voting rules", "author": ["E. Elkind", "P. Faliszewski", "P. Skowron", "A. Slinko"], "venue": "Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Parameterized Complexity Theory", "author": ["J. Flum", "M. Grohe"], "venue": "Springer-Verlag", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Computers and Intractability: A Guide to the Theory of NP-Completeness", "author": ["M. Garey", "D. Johnson"], "venue": "W. H. Freeman and Company", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1979}, {"title": "Voting over multiattribute domains", "author": ["J. Lang", "L. Xia"], "venue": "F. Brandt, V. Conitzer, U. Endriss, J. Lang, and A. Procaccia, editors, Handbook of Computational Social Choice, chapter 9. Cambridge University Press", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Bidimensional allocation of seats via zero-one matrices with given line sums", "author": ["I. Lari", "F. Ricca", "A. Scozzari"], "venue": "Annals OR, 215(1):165\u2013181", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Integer programming with a fixed number of variables", "author": ["H.W. Lenstra"], "venue": "Mathematics of Operations Research, 8(4):538\u2013548", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1983}, {"title": "Budgeted social choice: From consensus to personalized decision making", "author": ["T. Lu", "C. Boutilier"], "venue": "Proceedings of the 22nd International Joint Conference on Artificial Intelligence ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Multiwinner social choice with incomplete preferences", "author": ["T. Lu", "C. Boutilier"], "venue": "IJCAI", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Fully proportional representation", "author": ["B.L. Monroe"], "venue": "American Political Science Review, 89:925\u2013940", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1995}, {"title": "Invitation to Fixed-Parameter Algorithms", "author": ["R. Niedermeier"], "venue": "Oxford University Press", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "Use of linear programming for constrained approval voting", "author": ["R. Potthoff"], "venue": "Interfaces, 20(5):79\u201380", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1990}, {"title": "On the complexity of achieving proportional representation", "author": ["A. Procaccia", "J. Rosenschein", "A. Zohar"], "venue": "Social Choice and Welfare, 30(3):353\u2013362", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "Network flow methods for electoral systems", "author": ["F. Pukelsheim", "F. Ricca", "B. Simeone", "A. Scozzari", "P. Serafini"], "venue": "Networks, 59(1):73\u201388", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Parametric maximum flow methods for minimax approximation of target quotas in biproportional apportionment", "author": ["P. Serafini", "B. Simeone"], "venue": "Networks, 59(2):191\u2013208", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Achieving fully proportional representation: Approximability result", "author": ["P. Skowron", "P. Faliszewski", "A. Slinko"], "venue": "Artificial Intelligence, 222:67\u2013103", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Computer-assisted constrained approval voting", "author": ["A. Straszak", "M. Libura", "J. Sikorski", "D. Wagner"], "venue": "Group Decision and Negotiation, 2(4):375\u2013385", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1993}], "referenceMentions": [{"referenceID": 1, "context": "First, we notice that our model generalizes the apportionment problem for proportional representation [2].", "startOffset": 102, "endOffset": 105}, {"referenceID": 0, "context": "There is a variety of apportionment methods studied in the literature [1].", "startOffset": 70, "endOffset": 73}, {"referenceID": 1, "context": "In this paper we do not review these methods in detail (we refer the reader to the survey of Balinski and Young [2]), but we rather focus on a specific set of their properties that have been analyzed, namely non-reversal, exactness and respect of quota, population monotonicity, and house monotonicity.", "startOffset": 112, "endOffset": 115}, {"referenceID": 12, "context": "2 Related work Our model is related to three distinct research areas: Voting on multi-attribute domains (see the work of Lang and Xia [13] for a survey).", "startOffset": 134, "endOffset": 138}, {"referenceID": 5, "context": "In particular, our model is related to the problem of finding a fully proportional representation [6, 18].", "startOffset": 98, "endOffset": 105}, {"referenceID": 17, "context": "In particular, our model is related to the problem of finding a fully proportional representation [6, 18].", "startOffset": 98, "endOffset": 105}, {"referenceID": 20, "context": "attention lately [21, 3, 7, 24, 17].", "startOffset": 17, "endOffset": 35}, {"referenceID": 2, "context": "attention lately [21, 3, 7, 24, 17].", "startOffset": 17, "endOffset": 35}, {"referenceID": 6, "context": "attention lately [21, 3, 7, 24, 17].", "startOffset": 17, "endOffset": 35}, {"referenceID": 23, "context": "attention lately [21, 3, 7, 24, 17].", "startOffset": 17, "endOffset": 35}, {"referenceID": 16, "context": "attention lately [21, 3, 7, 24, 17].", "startOffset": 17, "endOffset": 35}, {"referenceID": 9, "context": "[10], who gives a normative study of multiwinner election rules.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Budgeted social choice [16] is technically close to committee elections, but it has a different motivation: the aim is to make a collective choice about a set of objects to be consumed by the group (perhaps, subject to some constraints) rather than about the set of candidates to represent voters.", "startOffset": 23, "endOffset": 27}, {"referenceID": 1, "context": "Apportionment for party-list representation systems (see the work of Balinski and Young [2] for a survey).", "startOffset": 88, "endOffset": 91}, {"referenceID": 7, "context": "Ding and Lin [8] studied a game-theoretic model for a party-list proportional representation system under specific assumptions, and show that computing the Nash equilibria of the game is hard.", "startOffset": 13, "endOffset": 16}, {"referenceID": 21, "context": "Also related is the computation of bi-apportionment (assignment of seats to parties within regions), investigated in a few recent papers [22, 23, 14].", "startOffset": 137, "endOffset": 149}, {"referenceID": 22, "context": "Also related is the computation of bi-apportionment (assignment of seats to parties within regions), investigated in a few recent papers [22, 23, 14].", "startOffset": 137, "endOffset": 149}, {"referenceID": 13, "context": "Also related is the computation of bi-apportionment (assignment of seats to parties within regions), investigated in a few recent papers [22, 23, 14].", "startOffset": 137, "endOffset": 149}, {"referenceID": 3, "context": "Constrained approval voting (CAP) [4, 20] is probably the closest work to our setting (MAPR).", "startOffset": 34, "endOffset": 41}, {"referenceID": 19, "context": "Constrained approval voting (CAP) [4, 20] is probably the closest work to our setting (MAPR).", "startOffset": 34, "endOffset": 41}, {"referenceID": 19, "context": "A simple translation of CAP into an integer linear programming problem is given in [20, 25].", "startOffset": 83, "endOffset": 91}, {"referenceID": 24, "context": "A simple translation of CAP into an integer linear programming problem is given in [20, 25].", "startOffset": 83, "endOffset": 91}, {"referenceID": 1, "context": "There are two main families of apportionment methods: largest remainders and highest average methods [2].", "startOffset": 101, "endOffset": 104}, {"referenceID": 0, "context": "5 Properties of multi-attribute proportional representation Several properties of apportionment methods have been studied, starting with Balinski and Young [1].", "startOffset": 156, "endOffset": 159}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Hardness follows by reduction from the NP-complete problem EXACT COVER WITH 3-SETS, or X3C [12].", "startOffset": 91, "endOffset": 95}, {"referenceID": 0, "context": "There is also a whole hierarchy of hardness classes, FPT \u2286 W [1] \u2286 W [2] \u2286 \u00b7 \u00b7 \u00b7 (for details, we point the reader to appropriate overviews [9, 19, 11].", "startOffset": 61, "endOffset": 64}, {"referenceID": 1, "context": "There is also a whole hierarchy of hardness classes, FPT \u2286 W [1] \u2286 W [2] \u2286 \u00b7 \u00b7 \u00b7 (for details, we point the reader to appropriate overviews [9, 19, 11].", "startOffset": 69, "endOffset": 72}, {"referenceID": 8, "context": "There is also a whole hierarchy of hardness classes, FPT \u2286 W [1] \u2286 W [2] \u2286 \u00b7 \u00b7 \u00b7 (for details, we point the reader to appropriate overviews [9, 19, 11].", "startOffset": 140, "endOffset": 151}, {"referenceID": 18, "context": "There is also a whole hierarchy of hardness classes, FPT \u2286 W [1] \u2286 W [2] \u2286 \u00b7 \u00b7 \u00b7 (for details, we point the reader to appropriate overviews [9, 19, 11].", "startOffset": 140, "endOffset": 151}, {"referenceID": 10, "context": "There is also a whole hierarchy of hardness classes, FPT \u2286 W [1] \u2286 W [2] \u2286 \u00b7 \u00b7 \u00b7 (for details, we point the reader to appropriate overviews [9, 19, 11].", "startOffset": 140, "endOffset": 151}, {"referenceID": 0, "context": "Theorem 3 The problem of deciding whether there exists a perfect committee is W[1]-hard for the parameter k, even for binary domains.", "startOffset": 79, "endOffset": 82}, {"referenceID": 0, "context": "By reduction from the W[1]-complete PERFECTCODE problem [5].", "startOffset": 23, "endOffset": 26}, {"referenceID": 4, "context": "By reduction from the W[1]-complete PERFECTCODE problem [5].", "startOffset": 56, "endOffset": 59}], "year": 2015, "abstractText": "We consider the following problem in which a given number of items has to be chosen from a predefined set. Each item is described by a vector of attributes and for each attribute there is a desired distribution that the selected set should have. We look for a set that fits as much as possible the desired distributions on all attributes. Examples of applications include choosing members of a representative committee, where candidates are described by attributes such as sex, age and profession, and where we look for a committee that for each attribute offers a certain representation, i.e., a single committee that contains a certain number of young and old people, certain number of men and women, certain number of people with different professions, etc. With a single attribute the problem collapses to the apportionment problem for partylist proportional representation systems (in such case the value of the single attribute would be a political affiliation of a candidate). We study the properties of the associated subset selection rules, as well as their computation complexity.", "creator": "LaTeX with hyperref package"}}}