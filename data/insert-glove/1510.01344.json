{"id": "1510.01344", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Oct-2015", "title": "Within-Brain Classification for Brain Tumor Segmentation", "abstract": "Purpose: 4-97 In this paper, willigis we esq. investigate a framework for interactive brain tumor segmentation which, blanton@globe.com at cyclops its jaf core, spygate treats peik the 8-gilberto problem joppa of dealu interactive cookridge brain account tumor segmentation kalpana as stombergas a chabi machine shealy learning problem.", "histories": [["v1", "Mon, 5 Oct 2015 20:32:04 GMT  (478kb,D)", "http://arxiv.org/abs/1510.01344v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["mohammad havaei", "hugo larochelle", "philippe poulin", "pierre-marc jodoin"], "accepted": false, "id": "1510.01344"}, "pdf": {"name": "1510.01344.pdf", "metadata": {"source": "CRF", "title": "Within-Brain Classification for Brain Tumor Segmentation", "authors": ["Mohammad Havaei", "Hugo Larochelle", "Philippe Poulin", "Pierre-Marc Jodoin"], "emails": ["mohammad.havaei@gmail.com", "hugo.larochelle@usherbrooke.ca", "philippe.Poulin2@usherbrooke.ca", "pierre-marc.jodoin@usherbrooke.ca"], "sections": [{"heading": null, "text": "Methods: This method has an advantage over typical machine learning methods for this task where generalization is made across brains. The problem with these methods is that they need to deal with intensity bias correction and other MRI-specific noise. In this paper, we avoid these issues by approaching the problem as one of within brain generalization. Specifically, we propose a semi-automatic method that segments a brain tumor by training and generalizing within that brain only, based on some minimum user interaction.\nConclusion: We investigate how adding spatial feature coordinates (i.e. i, j, k) to the intensity features can significantly improve the performance of different classification methods such as SVM, kNN and random forests. This would only be possible within an interactive framework. We also investigate the use of a more appropriate kernel and the adaptation of hyper-parameters specifically for each brain.\n\u2217mohammad.havaei@gmail.com \u2020hugo.larochelle@usherbrooke.ca \u2021philippe.Poulin2@usherbrooke.ca \u00a7pierre-marc.jodoin@usherbrooke.ca\nar X\niv :1\n51 0.\n01 34\n4v 1\n[ cs\nResults: As a result of these experiments, we obtain an interactive method whose results reported on the MICCAI-BRATS 2013 dataset are the second most accurate compared to published methods, while using significantly less memory and processing power than most stateof-the-art methods."}, {"heading": "1 Introduction", "text": "Brain tumor segmentation is primarily used for diagnosis, patient monitoring, treatment planning, neurosurgery planning and radiotherapy planning. The task of brain tumor segmentation is to locate the tumor and delineate different sub-regions of the tumor, namely edema, non-enhanced, and enhanced regions (see Fig. 1). A standard way to diagnose a brain tumor is by using magnetic resonance imaging (MRI), for which many different modalities can be used. The most frequent MRI modalities used for brain tumor segmentation are Flair, T1-weighted (also referred to as T1), T2- weighted (also referred to as T2) and T1-weighted contrast-enhanced (gadolinium-DTPA) which we refer to as T1C. These different modalities are often used jointly as they provide complementary information for locating tumors.\nUnfortunately, tumors (especially glioblastomas and metastases) can appear almost anywhere in the brain. They have no prior shape, and often have poorly defined edges. Also, they visually present themselves in grayscales that are present in healthy tissues as well. As a consequence, brain tumor segmentation in practice is still done manually. Manual segmentation is not only time consuming and tedious, it is also subject to variations between observers and also within the same observer [18].\nMany methods have been proposed to facilitate the tumor segmentation process. Among them, automatic methods, which rely on machine learning, are very popular and in some cases very efficient [2]. These methods are trained on a number of subjects and generalize on data which might be gathered from different MRI scanners. Because there is no intensity standardization among MRI scanners, this makes generalization difficult for automatic methods. In an\n2\nattempt to overcome these difficulties, a lot of prepossessing steps are made which can be time consuming. Also, to improve generalization, these methods often compute high dimensional feature vectors [18] which add to the processing time and take up a lot of memory.\nIn this paper, we consider the specific problem of segmenting an imaged brain into 4 classes: edema, non-enhancing tumor, enhancing tumor and healthy tissue (see Fig. 1). Note that the non-enhancing tumor sometimes includes necrotic tissue. Our approach is halfway between automatic and semi-automatic methods. While machine learning methods train on a pre-selected set of brains and then generalize to testing brains, our method implements a \u201csingle brain\u201d supervised learning method. The user roughly selects brain voxels associated to each class and then these voxels are used as training data. The method then generalizes by labeling non-selected voxels.\nThe main characteristics of our method are as follows:\n\u2022 Since it treats each brain as a separate dataset, it is immune to the multi-MRI disadvantages mentioned above.\n\u2022 Although it uses only 6 simple features, it produces highly accurate results.\n\u2022 The segmentation process for a 240 \u00d7 240 \u00d7 168 brain takes approximately 10 seconds for our fastest method which is much faster than most state-of-the-art methods which can take up to 100 minutes.\n\u2022 The method is extremely memory efficient (50 Mb vs. >2 Gb for other methods)\nIn this paper, we first evaluate the performance of a k nearest neighbor classifier (kNN) within this framework. Then, we extend this framework and thoroughly evaluate its potential through comparing the use of several classifiers, including support vector machines (SVM), random forests and boosted decision trees. Second, we propose better distance metrics to be used by SVM classifier in the context of this approach. We also investigate the importance of performing hyper-parameter selection individually for each brain, as opposed to using generic hyper-parameters for every brain. Thanks to this investigation, we were able to significantly improve the resulting brain\nsegmentation system and achieve a competitive performance compared to the methods submitted to the brain tumor segmentation challenge (BRATSURL [5]) online evaluation benchmark."}, {"heading": "2 Related Work", "text": "Brain tumor segmentation methods can be divided into automatic methods and semi-automatic (interactive) methods. Semi-automatic methods are those relying on user interaction. Most of these methods use either deformable models or classification methods to perform segmentation (see Bauer et al [2] for a survey).\nFor automatic methods, machine learning classification techniques are a tool of choice for designing such systems, as they can easily integrate different MRI modalities as well as other features. After integrating different intensity and texture features, these methods decide to which class each voxel belongs to.\nFor instance, Festa et al. [14] used a series of intensity and texture based features to make a feature space of over 300 dimensions, on which a random forest classifier was trained. Tustison et al. and Reza et al. also used random forests [14]. Tustison et al. constructed a multi-dimensional feature space by incorporating first order neighborhood statistical images, GMM and Markov Random Field (MRF) posteriors, and template differences. [12] performed binary segmentation (tumor vs. non-tumor) using T1, T2, T1C in an SVM framework followed by a variation of conditional random fields to account for neighborhood relationships. [1] used a kernel SVM for multiclass segmentation of brain tumors, where a CRF is used to regularize the results.\nSchmidt et al [18] compared the combination of many different feature sets, such as binary mask, average intensity, left to right symmetry. Luts et al [13] also compared different feature selection methods such as Fisher discriminant analysis, Kruskal wallis, relief-f and ARD for LS-SVM.\nBecause automatic methods train on multiple brains, these methods are vulnerable to the variations in the MRI data. These variations come from the fact that MR images are generated by different machines and each have their own unique noise and intensity level. To overcome this difficulty, most of these methods rely on a large number of features, which requires a lot of memory and computation time.\nAs for semi-automatic methods, deformable models are often employed.\nThese algorithms are usually initialized by a user drawing a contour around the tumor. Following an energy minimization criterion, the contour shrinks down towards the borders of the tumor [10, 21]. Hamamci et al [7] used a socalled CA-based method on T1 weighted images to produce a probability map for the tumor, based on seeds provided by the user. This probability map is later used in a level set framework. Later, they extend their method to accept multi-modal MRI inputs namely T1C and Flair. For a two class segmentation (tumor, edema) this method takes 1 minute for user interaction and 10-20 minutes for segmentation depending on the size of the tumor [6]. There exists a line of research focusing on how to efficiently initialize the active contour and thus remove user interaction. In this context, the location of the tumor is roughly determined by some other method and deformable models are used as post-processing for refinement. Ho et al [8] use the difference between T1 and T1C together with a Gaussian mixture model (GMM) to get a probability map of the tumor, which is used in a level-set model to initialize the contour. Prastawa et al [17] used voxel registration with an atlas as a way to get a probability map for abnormalities. An active contour is then initialized using this probability map and iterates until the change in posterior probability is below a certain threshold.\nAlthough deformable models have been popular in medical image analysis, they have some significant disadvantages. Because these methods rely on image gradients, they are likely to fail when the object of interest does not have well defined borders. The contour may get attracted by strong gradients from surrounding objects. Incorporating different features into the model is also non-trivial. Finally, without a GPU implementation, these methods can be extremely slow.\nThere has been research on ensembling results from multiple methods applied to brain tumor segmentation. Huo et al [9] used three segmentation methods: fuzzy connectedness, GrowCut and voxel classification using SVM to generate candidate segmentations for each voxel. Confidance-based averaging (CMA) was used to make the ensemble.\nAlthough our method is a semi-automatic method, it shares with automatic methods the use of a machine learning classification algorithm, ran on a feature representation of voxels and improved by a spatial dependency model. The main difference is that generalization is performed within each brain, based on the training data provided by the user\u2019s interaction. This simplified generalization problem allows us to use a very simple feature space, yielding an interactive segmentation method that is fast and effective. [20]\nused a similar, semi-automatic, kNN classification method, applied to proton density, T1 and T2 modalities. [3] also proposed a semi-automatic segmentation method that uses instead Quadratic Discriminative Aanalysis to perform multi-class segmentation. However, they did not use the \u3008i, j, k\u3009 voxel positions as features (see Section 3.2.1) nor did they deal with label spatial dependency modeling (see Section 3.4.1), which we found to play a crucial role in obtaining competitive performances."}, {"heading": "3 Investigating Within-Brain Generalization", "text": "Within-brain generalization treats the segmentation of each brain as its own machine learning experiment, in which a classifier is trained (on user-labeled voxels) and used to generalize to new observations (voxels not labeled by the user).\nThis approach is motivated by the observation that, with current computers and for relatively small data sets with small feature spaces, a machine learning experiment (including hyper-parameter selection) can actually be performed within a very short delay, even for more sophisticated algorithms that require more than simply storing the data (as in kNN). Moreover, segmenting only within a given brain removes the challenging problem of generalizing across brain imaging acquisition conditions.\nIn what follows, we describe the details of our approach and enumerate the different variations we explored in this direction.\nFigure 2 shows our method in a nutshell. We explain these steps in Section 3."}, {"heading": "3.1 Feature representation and manual selection", "text": "The first step of our method is to collect voxel label data for a given brain image to segment. This is done by the user who roughly selects a subset of voxels associated with each class, through a graphical interface. The number of strokes required for obtaining the training data depends on the number of tumors in a given brain. However, usually one or two strokes per-class is enough. We will note as B a binary mask such that Bv \u2208 {0, 1} indicates whether a voxel v has been manually selected (i.e. labeled) or not. T will then be the class-selection mask where Tv \u2208 {edema, non-enhancing tumor, enhancing tumor, healthy} is the class label associated with the voxel v by the user.\nWe must also decide on a feature representation for the different voxels. Each brain image I is assumed to come with 3 MRI modalities (T1C, T2, Flair), such that I is a tensor where each voxel v in I is a 3D vector containing the grayscale values of the modalities. This is represented by I1v , I 2 v , I 3 v . By converting each voxel v to an N-dimensional feature representation Fv, it will be possible to train a classifier to predict the voxel label Tv, for every voxel, from its feature representation. We propose a simple 6 dimensional feature represeentation, which consists of the MRI modality gray scales and the 3d position of voxel v: Fv = (I 1 v , I 2 v , I 3 v , i, j, k). These features are normalized between zero and one. At this point, from each labeled voxel, we can thus generate a training pair (Fv, Tv) and construct a training set D that we shall use to classify the non-selected voxels using a classifier."}, {"heading": "3.2 Voxel classifiers", "text": "Having built the training set through manual interaction, the next step is to train a classifier and generalize the segmentation to non-selected voxels. We investigate the use of different machine learning algorithms to produce a classifier. While we could, theoretically, consider any existing algorithm, it is natural to prefer algorithms that are known to be robust and fairly \u201dblack box\u201d in their use. For instance, we do not want the user (typically a doctor or a neuro-scientist) to have to manually tune hyper-parameters for each brain, with trial and error. So we chose algorithms that are known to be easily tuned or for which default values of their hyper-parameters tend to work well. These algorithms have also shown to be successful for automatic\nbrain tumor segmentation [18, 14]."}, {"heading": "3.2.1 K-Nearest Neighbors (kNN)", "text": "To start, k nearest neighbor (kNN), one of the simplest classifiers, is considered. For every voxel v, kNN finds among the training data D, the set of k nearest neighbors (Nv) based on Fv. LetNv = ((Fv1 , Tv1), (Fv2 , Tv2), ..., (Fvk , Tvk)) where Fvi is the i\nth closest training point of Fv. The kNN classification rule assigns a class label to some voxel v following this equation\nTv = arg max c\n1\nk \u2211 (Fvi ,Tvi )\u2208Nv \u03b4(Tvi , c) (1)\nwhere c is a class label and \u03b4(a, b) returns 1 when a = b and 0 otherwise. Note that this formulation can be seen as using a posterior class probability:\np(Tv = c|Fv) = 1\nk \u2211 (Fvi ,Tvi )\u2208Nv \u03b4(Tvi , c) (2)\nwhich states that the probability of an observation Fv of being in class c is given by the proportion of nearest neighbors assigned to that class. This probabilistic formulation of the classifier will be reused for the unary terms of a CRF, described in Section 3.4.1."}, {"heading": "3.2.2 Support Vector Machine", "text": "The support vector machine (SVM) [4] is probably the most frequently used classifier. This is in part due to the existence of many freely available, mature and easy-to-use implementations. In its parametric form, it is a linear classifier that attempts to classify data points by maximizing the margin between the decision boundaries of the different classes and their closest points.\nOf higher interest in our setting is the kernelized version of SVM [11]. A choice for the kernel that often proves successful is the radial basis function (RBF) kernel:\nK(Fj, Fv) = exp(-\u03b3 \u2016 Fj \u2212 Fv \u201622). (3)\nwhere \u03b3 is a hyper-parameter. Also, a slack variable C is used to relax the constraints in the SVM optimization problem [11]. The resulting classifier effectively takes the form of a template matcher, that compares a given input\nwith all training examples, each voting for their class with a weight related to their similarity with the input (as modeled by the kernel). In this sense, it is similar to the kNN classifier, though the former often outperforms the later in practice.\nIt is also possible to obtain a posterior class probability p(Tv = c|Fv) from the SVM. This is done by training the parameters of an additional sigmoid function of the form\nP (Tv = c|Fv) = 1\n1 + exp (Af(Fv, c) +B) (4)\nwhere f(Fv, c) is the unthresholded output of the SVM and A,B are the parameters to be estimated [16]. Here again, the posterior probability function will be used later on, for the CRF unary term."}, {"heading": "3.2.3 Ensemble of Decision Trees", "text": "Another popular approach to classification are ensembles of decision trees. Each decision tree is trained by recursively partitioning the feature space, according to some heuristic that favors a good separation of classes. Once a criterion for stopping the tree growth is reached, a conditional class distribution is then computed at each leaf, based on the training data falling into the corresponding partition. Specifically, the class distribution p(Tv = c|Fv) is set as\nP (Tv = c|Fv) = Nc N\n(5)\nwhere Nc is the relative frequency of examples belonging to class c of the partition in which Fv falls and N is the total number of examples.\nThe performance of a single decision tree is often disappointing. However, by constructing an ensemble of such trees, a competitive classification performance is achievable. There are different approaches to combining decision trees into an ensemble. The two most popular algorithms for ensembles of decision trees are random forests and Adaboost [15]. We considered these two algorithms for our experiments."}, {"heading": "3.3 Distance Metric/Kernel", "text": "The performances of the SVM classifier often depends on the choice of metric or kernel used to compare data points. Thus, it is generally beneficial to\nadapt this choice to each individual problem. For example, the conventional RBF kernel puts equal weight to each dimension of the feature space. However, in our within-brain framework, the spatial coordinate features \u3008i, j, k\u3009 and the modality features actually play different roles. Intuitively, one role of the spatial coordinates is to avoid that a user-labeled voxel starts influencing the prediction made at a voxel far away from it, e.g. to avoid false positives in faraway regions. The modality features, are thus mostly informative within the vicinity of a user-labeled voxel.\nTherefore, we might want to weight the modality and spatial features differently, within the RBF kernel of the SVM. To maintain positive-semidefiniteness of the kernel, we simply opt for using two different values of \u03b3 for MRI modality intensities and the spatial features:\nK(Fj, Fv) = exp( \u2212\u03b31 \u2016 Fj,{1:N} \u2212 Fv,{1:N} \u201622 (6) \u2212\u03b32 \u2016 Fj,{N+1:N+3} \u2212 Fv,{N+1:N+3} \u201622).\nThis kernel is also equivalent to the product of two RBF kernels, each defined on the subspace of modalities and of spatial coordinates, and each having their own hyper-parameters. The hyper-parameters required by this approach are \u03b31 and \u03b32."}, {"heading": "3.4 Importance of Within-Brain Hyper-Parameter Se-", "text": "lection\nWhen training a classifier, hyper-parameter values must be specified. One approach which is commonly implemented [14] is to choose hyper-parameters by cross-validation in a grid search approach on a subset of brains and fix the selected set of hyper-parameters for the rest of the brains. We hypothesize given the variations in MRI data, using a fixed set of hyper-parameters for generalization is not optimal. An alternative way is to perform hyperparameter selection individually for each brain, in order to adapt to the specificity of each case. We measure the potential gains of this approach in our experiments when selecting the hyper-parameters for the SVM, namely the slack variable C and the coefficient \u03b3. A detailed discussion of this experiment is presented in section 4.2.4."}, {"heading": "3.4.1 Conditional Random Fields (CRF)", "text": "As mentioned earlier, segmentation accuracy can easily be improved by leveraging a model of the 3D spatial regularity of labels. One way of enforcing spacial regularity is to define a joint (conditional) distribution over the labels of all voxels in the brain that expresses the expected dependencies between neighboring voxels. Conditional Random Fields (CRF) provide a convenient formalism for that. CRFs model directly the posterior probabilities of the labels given the features P (T |F ) directly, alleviating the need to model the distribution over the feature vectors F and allowing us to construct rich conditionals P (T |F ).\nFormally speaking, we use the following form for P (T |F ):\nP (T |F ) = 1 Z \u220f v \u03c6(Fv, Tv)\u03c6(Tv, Fv, Tr, Fr) where r \u2208 \u03b7v (7)\nwhere Z is a normalization term, \u03c6 are clique potential functions and \u03b7v is the set of voxels surrounding v.\nSegmenting a brain requires that we find the labeling T with highest probability P (T |F ). This leads to an optimization problem of the form T = arg maxT \u220f v \u03c6(Fv, Tv)\u03c6(Tv, Tr) or, equivalently,\nT = arg min T\u2208T \u2211 v\n( V (Fv, Tv) +\n\u2211 r\u2208\u03b7v I(Tv, Fv, Tr, Fr)\n) . (8)\nwhere we set the equivalence V (Fv, Tv) = \u2212 log \u03c6(Fv, Tv) and I(Tv, Fv, Tr, Fr) = \u2212 log \u03c6(Tv, Fv, Tr, Fr).\nIn our case, we model the unary terms V (Fv, Tv) by taking the negative log of the posterior distribution\nV (Fv, Tv) = \u2212log(P (Tv|Fv) (9)\nspecified in Eq.(2), (4) or (5). As for the pairwise term, we set it to be I(Tv, Fv, Tr, Fr) = \u03bb(1\u2212 \u03b4(Tv, Tr)) exp ( \u2212\u2016Fv \u2212 Fr\u2016\n\u03c32\n) . (10)\nThe choice of these unary and pairwise terms allows us to perform the optimization of Equation 8 using the graphcut algorithm.\nWe refer to the segmentation methods using this label dependency model as kNN-CRF, SVM-CRF, and DT-CRF, depending on the unary term used."}, {"heading": "4 Experiments", "text": ""}, {"heading": "4.1 Experimental Setup", "text": "All our experiments were conducted on real patient data obtained from the brain tumor segmentation challenge dataset (Farahani et al [5]) as part of the MICCAI conference. This dataset contains 30 patient subjects (20 high grade and 10 low grade tumors) for training and 10 (all high grade tumors) for testing. For each subject there exist 4 modalities which are co-aligned together, namely: T1, T1C, T2 and Flair . In our experiments, we used T1C, T2 and Flair only. We do not use T1 as it is not very descriptive and using it did not improve the overall performance of the model. For each brain, the user is asked to manually label voxels in only two 2D slices for each class. The choice of slices depend on the size and spread of the tumor. Considering the fact that the user can choose slices from any view (i.e. axial, sagittal and coronal), the tumor coverage is sufficient and the results are not very sensitive to the slices chosen for labeling. On average, only 0.4% of the voxels containing pathology and 0.03% of the voxels corresponding to healthy tissue were manually selected, thus providing minimal labeled data to the algorithm. To make operations faster, we disregard all the voxels outside of the skull and consider them as healthy.\nThe quantitative results for each method was obtained from the BRATS online evaluation system, which provides Dice, Specificity and Sensitivity as measures of performance. These measures are defined as follows:\nDice(P, T ) = |P1 \u2227 T1|\n(|P1|+|T1|)/2 ,\nSensitivity(P, T ) = |P1 \u2227 T1| |T1| , Specificity(P, T ) = |P0 \u2227 T0| |T0| ,\nwhere P represents the model predictions and T represents the ground truth labels. We also note as T1 and T0 the subset of voxels predicted as positives and negatives for the tumor region in question. Similarly for P1 and P0 [14].\nWe report these measures for the test subjects over the three categories considered by the BRATS evaluation (i.e. complete, core, enhanced). The\ncomplete category is the union of classes containing un-healthy tissue. i.e. {l|l \u2208 [necrosis, edema, enhancing]}), the core category are classes containing tumor core i.e. {l|l \u2208 [necrosis, enhancing]} and the enhancing category is the enhancing tumor class. i.e. {l|l \u2208 [enhancing]}. The online evaluation system also provides a ranking for every method submitted for evaluation. This includes methods from the 2013 BRATS challenge published in [14] as well as anonymized unpublished methods for which no reference is available. The methods in each table presented in this section are ordered according to the ranking provided by the online evaluation system.\nPlease note that we could not use the BRATS 2014 dataset due problems with both the system performing the evaluation and the quality of the labeled data. For these reasons the old BRATS 2014 dataset has been removed from the official website and, at the time of submitting this manuscript, the BRATS website still showed: \u201cFinal data for BRATS 2014 to be released soon\u201d For these reasons, we decided to focus on the BRATS 2013 data. Also, this article does not contain any studies with human participants performed by any of the authors."}, {"heading": "4.2 Results and Discussion", "text": "In this section, we report experimental results obtained with the machine learning methods presented in Section 3.2. This includes linear SVM (LSVM), kernel SVM with rbf kernel (KSVM), our proposed product kernel SVM (PKSVM), kNN, decision trees trained with Ada-Boost (ADT), and random forests (RDT). All these methods have been explored with and without the CRF. The CRF parameters \u03b1 and \u03b2 were set for each method, by crossvalidation on 6 brains on the training set. We also investigate the extent to which adding spatial features \u3008i, j, k\u3009 helps improving the performance. This is noted by adding a \u201c\u2217\u201d next to the method\u2019s name."}, {"heading": "4.2.1 KNN", "text": "The results for the kNN related experiments are presented in Table 1. We first made an experiment without including the \u3008i, j, k\u3009 position features in the feature vector as presented by [20]. Since his method uses neither the spatial coordinate features nor the CRF regularization, it performs significantly worse than other kNN related experiments. While adding the spatial coordinates to this method improves the result by a significant margin, the\nbest performance is achieved when we use both spatial coordinates and a CRF regularization."}, {"heading": "4.2.2 SVM", "text": "The results for the SVM-related experiments are presented in Table 2. Results confirm that using spatial coordinate features (shown with \u201d*\u201d) and using the CRF model (shown with \u201d-CRF\u201d) improve the performance of both a linear SVM (LSVM) and an RBF kernel SVM (KSVM). It is also quite clear from this experiment that the non-linearity of the kernel SVM is crucial, as it significantly outperforms the linear SVM (LSVM).\nAs for the PKSVM method which stands for the RBF product kernel SVM presented in Section 3.3 (c.f. Eq.(7)) it clearly improved the KernelSVM and Kernel-SVM+CRF results. This underlines the relative importance of the spatial coordinate features \u3008i, j, k\u3009 versus the input T1, T2 and Flair modalities."}, {"heading": "4.2.3 Decision trees", "text": "For these experiments, we fixed the number of decision trees for AdaBoost (ADT) and random forests (RDT) to 100 and the leaf size to 1. For AdaBoost, decision stumps were used. The quantitative results are shown in Table 3. While adding spatial features are beneficial for both random forests and AdaBoost, using the CRF model is mostly beneficial except for random forest without spatial coordinates. However, the segmentation systems relying on decision trees tend to be worse than using kNN or SVM methods."}, {"heading": "4.2.4 Robustness of hyper-parameter selection", "text": "In our method when using the SVM as the classifier, the hyper-parameters (regularization constant C and kernel hyper-parameters \u03b3, \u03b31 and \u03b32) were always cross-validated for each brain individually, using an automated grid search. On the other hand, for automatic methods, a fixed set of hyperparameters is used for generalization. Given the variation of the MRI data and tumor types, we hypothesize that using a fixed set of hyper-parameters will degrade the performance quite significantly.\nTo evaluate the importance of performing per-brain model selection, we conducted an experiment where we used a fixed configuration of hyperparameters for all subjects. For this experiment, we considered our top two segmentation methods, PKSVM-CRF* and KSVM-CRF*. The values of the hyper-parameters were chosen by taking the hyper-parameter value most frequently selected by these methods, across all the brains. The idea was to pick values that are most likely to work well in general. For the KSVM-CRF*, C was set to 1 and \u03b3 to 5 and for the PKSVM-CRF*, C was set to 1, \u03b31 to 100 and \u03b32 to 10.\nThe results (Table 4) show a decrease in performance if fixed hyperparameters are used for all brains. We also performed this experiment on the BRATS training data (not shown here) and the performance decreased even more. This was not unexpected, since the training data is more varied and actually consists of both high grade tumors and low grade tumors, while the test data only contains high grade tumors.\nWhile it appears the tuning of the SVM\u2019s hyper-parameter to each brain is beneficial, we tested the extent to which small changes to the optimal hyperparameters would affect the performance. This is meant to simulate the fact that cross-validation might not always find the same hyper-parameters between variations on the manually labeled voxels. In order to measure how resilient our method is to slight hyper-parametric shifts, we ran another experiment to measure the sensitivity of our model. We did so by randomly selecting 20 brains from the BRATS training data, trained an SVM whose hyper-parameters have been obtained from cross validation. We then added noise to the hyper-parameters and measured the effect on the resulting segmentation. The noise corresponded to Gaussian noise, whose standard deviation was set to a certain percentage of the hyper-parameters\u2019 values. Figure 3 shows the resulting Dice measure for different noise level. As one can see, even with a noise level corresponding to a corruption of 25% of the hyper-\nparameter values, the end result is still close to the one obtained without any noise.\nFinally, the importance of optimizing the hyper-parameters was found to be less crucial for the other methods. For kNN, we evaluated the effect of using different values of k, with k = 3 consistently producing higher performance. The same type of experiment was performed to measure the effect of using different number of trees and leaf size in ADT and RDT. For these methods, setting the number of decision trees to 100 and leaf size to 1 always worked well."}, {"heading": "4.2.5 Speed-up procedure", "text": "Every segmentation method presented in this paper uses manually-selected voxels as their input. However, these selected voxels often carry out similar information. That is especially true for neighboring voxels whose \u3008i, j, k\u3009 position is almost the same, and whose T1,T2, Flair values are likely to be identical. Thus, in order to speed-up the segmentation procedure, one can randomly down-sample the training data. To have an overall idea to what extent we can down-sample the data without hurting too much the overall precision, we conducted an experiment where we divide the training points into healthy and non-healthy subsets and subsample them separately. This is done as to maintain a balance between the size of the healthy class with respect to other classes. The outcome of this process is a smaller training set but with roughly the same proportion of healthy points and non-healthy points. Figure 4 shows the result of this experiment. The curves were obtained by averaging the results of 20 randomly selected brains from BRATS training data. The horizontal axes in Figure 4 shows the number of training points in the subsampled training set. As shown in Figure 4(a), with maximum number of training points (i.e 3000) we get an average Dice measure of 0.72 and by considering 1000 training points the average Dice measure barely drops to 0.71, while the processing time decreases by 60%. Thus, all experiments submitted to the BRATS website were done with this subsampling measure."}, {"heading": "5 Conclusion", "text": ""}, {"heading": "5.1 Putting it all together", "text": "We finally present how our top performing methods compare with other state-of-the-art methods. The BRATS official website provides a ranking system for this purpose. However, because the BRATS organizers have recently made all methods anonymous, a complete comparison is not possible. For that reason, we rank our method based on the MICCAI-BRATS 2013 challenge results for which references to the methods were available. This is shown in table 5 1. As one can see, PKSVM-CRF* and KSVM-CRF*\n1Please note that the results mentioned in Table 5 are from methods competing in the BRATS 2013 challenge for which a static table is provided [https://www.virtualskeleton.ch/BRATS/StaticResults2013]. Since then, other methods\nare ranked second and third respectively, closely behind Tustison et al. and kNN-CRF* is ranked 6th in this table. Using the spatial features \u3008i, j, k\u3009, and CRF post-processing is vital to produce highly accurate results. Many methods in this table (like that of Tustison et al. Reza et al. and Festa et al. ) use random forests with a large number of features. In our case, random forests did not perform as well as the SVM or kNN methods. This might be due to the low dimensionality of our feature space. Recently Subbanna et al [19] published competitive results on the BRATS 2013 dataset, reporting Dice measures of 0.86, 0.86, 0.77 for Complete, Core and Enhancing tumor regions. Since they do not report Specificity and Sensitivity measures, a completely fair comparison with that method is not possible. However, as mentioned in [19], their method takes 70 minutes to process a subject, which is significantly slower than our method.\nFigure 5 shows a visualisation of segmentation results, for different variations of our SVM method. This illustrates the contribution of adding spatial features, using a CRF and using our improved kernel function, in improving the general performance of the SVM approach.\nhave been added to the score board but for which no reference is available."}, {"heading": "5.2 Processing time and memory usage", "text": "A key advantage of our proposed method is in having a very small processing time and memory usage, while maintaining high accuracy. Due to the low dimensionality of our feature space, it only takes up, on average, 50 MB of RAM to store the feature space of a brain. This is very small compared to state-of-the-art methods, whose memory footprint of the feature space is on the order of GB\u2019s. For example, Festa et al. use a feature space of 300 dimensions for their random forest approach which would take up to 2.7GB\u2019s. Tustison et al. Reza et al. and Meier et al. also take a similar approach using random forests [14]. These methods rely on a high number of texture features which are computationally time consuming and memory wise expensive.\nApart from the feature space, our proposed methods have different speed and memory footprint. We can make a comparison in accuracy, speed and memory usage as presented in Table 6. The processing time was measured on an 8-core processor and includes both training and testing. The time required by graphcut inference is the same for all methods and involves only\nan additional 8 seconds. As shown in Table 6, PKSVM-CRF* has the highest accuracy but requires a higher processing time (35 seconds) and memory usage (7.7 MB), on top of the 50 MB required to store the feature space. On the other hand, KSVM-CRF* and kNN-CRF* are closer to real time implementations with negligeable memory consumption. This allows the expert to interact in real-time with the software. That being said, all methods presented in Table 6 are significantly faster than state-of-the-art methods. For example, Tustison\u2019s method takes around 30 minutes to process a brain as mentioned in Menze et al [14].\nIn this paper we evaluated the capability of within brain generalization using a variety of classifiers. We showed that the SVM reached the best performances, thanks in part to a kernel function specifically adapted to our feature space. Most interestingly, we also showed that adopting a fixed hyperparameter configuration for all brains actually decreases the performance of the SVM. A better strategy was to also perform hyper-parameter selection\nfor each brain individually, in order to adapt to the specificities of each brain, further motivating our within brain generalization framework."}, {"heading": "6 Conflict of Interest", "text": "The authors declare that they have no conflict of interest."}, {"heading": "7 Ethical approval", "text": "All procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards.\nThis article does not contain any studies with human participants performed by any of the authors."}], "references": [{"title": "Fully automatic segmentation of brain tumor images using support vector machine classification in combination with hierarchical conditional random field regularization. In: Medical Image Computing and Computer-Assisted Intervention", "author": ["S Bauer", "L Nolte", "M Reyes"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "A survey of mri-based medical image analysis for brain tumor studies. Physics in medicine and biology", "author": ["S Bauer", "R Wiest", "L Nolte", "M Reyes"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Probabilistic segmentation of brain tumors based on multi-modality magnetic resonance images", "author": ["H Cai", "R Verma", "Y Ou", "S Lee", "E Melhem", "C Davatzikos"], "venue": "Biomedical Imaging: From Nano to Macro,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Multimodal Brain Tumor Segmentation", "author": ["K Farahani", "B Menze", "M Reyes"], "venue": "(BRATS", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Multimodal brain tumor segmentation using the tumor-cut method on the brats dataset", "author": ["A Hamamci", "G Unal"], "venue": "Proc Workshod on Brain Tumor Segmentation,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Tumorcut: Segmentation of brain tumors on contrast enhanced mr images for radiosurgery applications", "author": ["A Hamamci", "N Kucuk", "K Karaman", "K Engin", "G Unal"], "venue": "IEEE Transactions on Medical Imaging", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Level-set evolution with region competition: automatic 3-d segmentation of brain tumors", "author": ["S Ho", "E Bullitt", "G Gerig"], "venue": "Proc. Int. Conf. Pattern Recognition,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}, {"title": "Ensemble segmentation for gbm brain tumors on mr images using confidence-based averaging", "author": ["J Huo", "K Okada", "EM van Rikxoort", "HJ Kim", "JR Alger", "WB Pope", "JG Goldin", "MS Brown"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Segmentation and quantification of brain tumor", "author": ["C Jiang", "X Zhang", "W Huang", "C Meinel"], "venue": "Virtual Environments, Human-Computer Interfaces and Measurement Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "Kernel methods in computer vision. Foundations and Trends in Computer Graphics and Vision", "author": ["CH Lampert"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Segmenting brain tumors using pseudo\u2013conditional random fields. In: Medical Image Computing and Computer-Assisted Intervention", "author": ["C Lee", "S Wang", "A Murtha", "M Brown", "R Greiner"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "A combined mri and mrsi based multiclass system for brain tumour recognition using ls-svms with class probabilities and feature selection", "author": ["J Luts", "A Heerschap", "J Suykens", "SV Huffel"], "venue": "Artificial Intelligence in Medicine", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "The multimodal brain tumor image segmentation benchmark (brats)", "author": ["B Menze", "M Reyes", "KV Leemput"], "venue": "IEEE Trans on Medical Imaging (accepted)", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Machine learning: a probabilistic perspective", "author": ["K Murphy"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. In: Advances in large margin classifiers, Citeseer", "author": ["J Platt"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1999}, {"title": "Robust estimation for brain tumor segmentation. In: Medical Image Computing and Computer- Assisted Intervention-MICCAI", "author": ["M Prastawa", "E Bullitt", "S Ho", "G Gerig"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2003}, {"title": "Segmenting brain tumors using alignment-based features", "author": ["M Schmidt", "I Levner", "R Greiner", "A Murtha", "A Bistritz"], "venue": "In: Int. Conf on Machine Learning and Applications,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}, {"title": "Iterative multilevel mrf leveraging context and voxel information for brain tumour segmentation in mri", "author": ["N Subbanna", "D Precup", "T Arbel"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Comparison of supervised mri segmentation methods for tumor volume determination during therapy. Magnetic resonance imaging", "author": ["M Vaidyanathan", "L Clarke", "R Velthuizen", "S Phuphanich", "A Bensaid", "L Hall", "J Bezdek", "H Greenberg", "A Trotti", "M Silbiger"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1995}, {"title": "Fluid vector flow and applications in brain tumor segmentation", "author": ["T Wang", "I Cheng", "A Basu"], "venue": "IEEE Trans Biomedical Eng", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}], "referenceMentions": [{"referenceID": 16, "context": "Manual segmentation is not only time consuming and tedious, it is also subject to variations between observers and also within the same observer [18].", "startOffset": 145, "endOffset": 149}, {"referenceID": 1, "context": "Among them, automatic methods, which rely on machine learning, are very popular and in some cases very efficient [2].", "startOffset": 113, "endOffset": 116}, {"referenceID": 16, "context": "Also, to improve generalization, these methods often compute high dimensional feature vectors [18] which add to the processing time and take up a lot of memory.", "startOffset": 94, "endOffset": 98}, {"referenceID": 3, "context": "segmentation system and achieve a competitive performance compared to the methods submitted to the brain tumor segmentation challenge (BRATSURL [5]) online evaluation benchmark.", "startOffset": 144, "endOffset": 147}, {"referenceID": 1, "context": "Most of these methods use either deformable models or classification methods to perform segmentation (see Bauer et al [2] for a survey).", "startOffset": 118, "endOffset": 121}, {"referenceID": 12, "context": "[14] used a series of intensity and texture based features to make a feature space of over 300 dimensions, on which a random forest classifier was trained.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "also used random forests [14].", "startOffset": 25, "endOffset": 29}, {"referenceID": 10, "context": "[12] performed binary segmentation (tumor vs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1] used a kernel SVM for multiclass segmentation of brain tumors, where a CRF is used to regularize the results.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "Schmidt et al [18] compared the combination of many different feature sets, such as binary mask, average intensity, left to right symmetry.", "startOffset": 14, "endOffset": 18}, {"referenceID": 11, "context": "Luts et al [13] also compared different feature selection methods such as Fisher discriminant analysis, Kruskal wallis, relief-f and ARD for LS-SVM.", "startOffset": 11, "endOffset": 15}, {"referenceID": 8, "context": "Following an energy minimization criterion, the contour shrinks down towards the borders of the tumor [10, 21].", "startOffset": 102, "endOffset": 110}, {"referenceID": 19, "context": "Following an energy minimization criterion, the contour shrinks down towards the borders of the tumor [10, 21].", "startOffset": 102, "endOffset": 110}, {"referenceID": 5, "context": "Hamamci et al [7] used a socalled CA-based method on T1 weighted images to produce a probability map for the tumor, based on seeds provided by the user.", "startOffset": 14, "endOffset": 17}, {"referenceID": 4, "context": "For a two class segmentation (tumor, edema) this method takes 1 minute for user interaction and 10-20 minutes for segmentation depending on the size of the tumor [6].", "startOffset": 162, "endOffset": 165}, {"referenceID": 6, "context": "Ho et al [8] use the difference between T1 and T1C together with a Gaussian mixture model (GMM) to get a probability map of the tumor, which is used in a level-set model to initialize the contour.", "startOffset": 9, "endOffset": 12}, {"referenceID": 15, "context": "Prastawa et al [17] used voxel registration with an atlas as a way to get a probability map for abnormalities.", "startOffset": 15, "endOffset": 19}, {"referenceID": 7, "context": "Huo et al [9] used three segmentation methods: fuzzy connectedness, GrowCut and voxel classification using SVM to generate candidate segmentations for each voxel.", "startOffset": 10, "endOffset": 13}, {"referenceID": 18, "context": "[20]", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[3] also proposed a semi-automatic segmentation method that uses instead Quadratic Discriminative Aanalysis to perform multi-class segmentation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "brain tumor segmentation [18, 14].", "startOffset": 25, "endOffset": 33}, {"referenceID": 12, "context": "brain tumor segmentation [18, 14].", "startOffset": 25, "endOffset": 33}, {"referenceID": 9, "context": "Of higher interest in our setting is the kernelized version of SVM [11].", "startOffset": 67, "endOffset": 71}, {"referenceID": 9, "context": "Also, a slack variable C is used to relax the constraints in the SVM optimization problem [11].", "startOffset": 90, "endOffset": 94}, {"referenceID": 14, "context": "where f(Fv, c) is the unthresholded output of the SVM and A,B are the parameters to be estimated [16].", "startOffset": 97, "endOffset": 101}, {"referenceID": 13, "context": "The two most popular algorithms for ensembles of decision trees are random forests and Adaboost [15].", "startOffset": 96, "endOffset": 100}, {"referenceID": 12, "context": "One approach which is commonly implemented [14] is to choose hyper-parameters by cross-validation in a grid search approach on a subset of brains and fix the selected set of hyper-parameters for the rest of the brains.", "startOffset": 43, "endOffset": 47}, {"referenceID": 3, "context": "All our experiments were conducted on real patient data obtained from the brain tumor segmentation challenge dataset (Farahani et al [5]) as part of the MICCAI conference.", "startOffset": 133, "endOffset": 136}, {"referenceID": 12, "context": "Similarly for P1 and P0 [14].", "startOffset": 24, "endOffset": 28}, {"referenceID": 12, "context": "This includes methods from the 2013 BRATS challenge published in [14] as well as anonymized unpublished methods for which no reference is available.", "startOffset": 65, "endOffset": 69}, {"referenceID": 18, "context": "We first made an experiment without including the \u3008i, j, k\u3009 position features in the feature vector as presented by [20].", "startOffset": 116, "endOffset": 120}, {"referenceID": 17, "context": "Recently Subbanna et al [19] published competitive results on the BRATS 2013 dataset, reporting Dice measures of 0.", "startOffset": 24, "endOffset": 28}, {"referenceID": 17, "context": "However, as mentioned in [19], their method takes 70 minutes to process a subject, which is significantly slower than our method.", "startOffset": 25, "endOffset": 29}, {"referenceID": 12, "context": "also take a similar approach using random forests [14].", "startOffset": 50, "endOffset": 54}, {"referenceID": 12, "context": "For example, Tustison\u2019s method takes around 30 minutes to process a brain as mentioned in Menze et al [14].", "startOffset": 102, "endOffset": 106}], "year": 2015, "abstractText": "Purpose: In this paper, we investigate a framework for interactive brain tumor segmentation which, at its core, treats the problem of interactive brain tumor segmentation as a machine learning problem. Methods: This method has an advantage over typical machine learning methods for this task where generalization is made across brains. The problem with these methods is that they need to deal with intensity bias correction and other MRI-specific noise. In this paper, we avoid these issues by approaching the problem as one of within brain generalization. Specifically, we propose a semi-automatic method that segments a brain tumor by training and generalizing within that brain only, based on some minimum user interaction. Conclusion: We investigate how adding spatial feature coordinates (i.e. i, j, k) to the intensity features can significantly improve the performance of different classification methods such as SVM, kNN and random forests. This would only be possible within an interactive framework. We also investigate the use of a more appropriate kernel and the adaptation of hyper-parameters specifically for each brain. \u2217mohammad.havaei@gmail.com \u2020hugo.larochelle@usherbrooke.ca \u2021philippe.Poulin2@usherbrooke.ca \u00a7pierre-marc.jodoin@usherbrooke.ca 1 ar X iv :1 51 0. 01 34 4v 1 [ cs .C V ] 5 O ct 2 01 5 Results: As a result of these experiments, we obtain an interactive method whose results reported on the MICCAI-BRATS 2013 dataset are the second most accurate compared to published methods, while using significantly less memory and processing power than most stateof-the-art methods.", "creator": "LaTeX with hyperref package"}}}