{"id": "1510.08108", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Oct-2015", "title": "Online Learning with Gaussian Payoffs and Side Observations", "abstract": "peddling We consider a wesson sequential kakul learning spa-francorchamps problem nafta with quandary Gaussian noctule payoffs tsuboi and ekwe side information: radun after tweedmouth selecting an gads action $ i $, the learner receives information about the pamper payoff of inductees every action $ j $ arnberger in the vickerson form of celebic Gaussian magnanimously observations whose 1506 mean is oligomeric the same as 6-minute the anasuya mean nagasaki payoff, archbishops but the variance protrude depends mass\u00e9 on low-life the smokey pair $ (i, bolshoye j) $ (parsecs and 104.2 may gasquet be dondero infinite ). The setup spot-kick allows aarts a schabort more refined \u014dmura information neiss transfer from edbrooke one action manueline to puhakka another than 1.4094 previous partial monitoring distillation setups, including l'\u00e9dition the four-string recently ktul introduced graph - cahora structured vinten feedback afact case. 5:5 For idioma the missed first kiaran time in bussi the belgian literature, we crivello provide non - asymptotic popularising problem - tappet dependent lower bounds on the regret of any algorithm, maccari which comedically recover heilige existing mouse-deer asymptotic sickens problem - dependent niota lower millennialism bounds replant and inning finite - mesotitsch time minors minimax pro-rata lower bounds available in hgvs the literature. We soft-tissue also ameche provide jakati algorithms coquelin that isumi achieve stompin the wilrijk problem - dependent mo'nique lower bound (\u0627\u0628\u0646 up to some shoeprints universal guibord constant cartoony factor) or the raconteur minimax 30-game lower bounds (zbanic up oakington to duque logarithmic portals factors ).", "histories": [["v1", "Tue, 27 Oct 2015 21:59:33 GMT  (40kb)", "http://arxiv.org/abs/1510.08108v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["yifan wu", "andr\u00e1s gy\u00f6rgy", "csaba szepesv\u00e1ri"], "accepted": true, "id": "1510.08108"}, "pdf": {"name": "1510.08108.pdf", "metadata": {"source": "CRF", "title": "Online Learning with Gaussian Payoffs and Side Observations", "authors": ["Yifan Wu", "Csaba Szepesv\u00e1ri"], "emails": ["ywu12@ualberta.ca", "szepesva@ualberta.ca", "a.gyorgy@imperial.ac.uk"], "sections": [{"heading": null, "text": "ar X\niv :1\n51 0.\n08 10\n8v 1\n[ st\nat .M\nL ]\n2 7"}, {"heading": "1 Introduction", "text": "Online learning in stochastic environments is a sequential decision problem where in each time step a learner chooses an action from a given finite set, observes some random feedback and receives a random payoff. Several feedback models have been considered in the literature: The simplest is the full information case where the learner observes the payoff of all possible actions at the end of every round. A popular setup is the case of bandit feedback, where the learner only observes its own payoff and receives no information about the payoff of other actions [1]. Recently, several papers considered a more refined setup, called graph-structured feedback, that interpolates between the full-information and the bandit case: here the feedback structure is described by a (directed) graph, and choosing an action reveals the payoff of all actions that are connected to the selected one, including the chosen action itself. This problem, motivated for example by social networks, has been studied extensively in both the adversarial [2, 3, 4, 5] and the stochastic cases [6, 7]. However, most algorithms presented heavily depend on the self-observability assumption (that is, that the payoff of the selected action can be observed). Removing this self-loop assumption leads to the so-called partial monitoring case [5]. In the absolutely general partial monitoring setup the learner receives some general feedback that depends on its choice (and the environment), with some arbitrary (but known) dependence [8, 9]. While the partial monitoring setup covers all other problems, its analysis has concentrated on the finite case where both the set of actions and the set of feedback signals are finite [8, 9], which is in contrast to the standard full information and bandit settings where the feedback is typically assumed to be real-valued. The only exception to this case is the work of [5], which considers graph-structured feedback without the self-loop assumption.\nIn this paper we consider a generalization of the graph-structured feedback model that can also be viewed as a general partial monitoring model with real-valued feedback. We assume that selecting an action i the learner can observe a random variable Xij for each action j whose mean is the same as the payoff of j, but its variance \u03c32ij depends on the pair (i, j). For simplicity, throughout the paper\nwe assume that all the payoffs and the Xij are Gaussian. While in the graph-structured feedback case one either has observation on an action or not, but the observation always gives the same amount of information, our model is more refined: Depending on the value of \u03c3ij , the information can be of different quality. For example, if \u03c32ij = \u221e, trying action i gives no information about action j. In general, for any \u03c32ij < \u221e, the value of the information depends on the time horizon T of the problem: when \u03c32ij is large relative to 1/ \u221a T (and the payoff differences of the actions) essentially no information is received, while a small variance results in useful observations.\nAfter defining the problem formally in Section 2, we provide non-asymptotic problem-dependent lower bounds in Section 3, which depend on the distribution of the observations through their mean payoffs and variances. To our knowledge, these are the first such bounds presented for any stochastic partial monitoring problem beyond the full-information setting: previous work either presented asymptotic problem-dependent lower bounds (e.g., [10, 7]), or finite-time minimax bounds (e.g., [9, 3, 5]). Our bounds can recover all previous bounds up to some universal constant factors not depending on the problem. In Section 4, we present two algorithms with finite-time performance guarantees for the case of graph-structured feedback without the self-observability assumption. While due to their complicated forms it is hard to compare our finite-time upper and lower bounds, we show that our first algorithm achieves the asymptotic problem-dependent lower bound up to problem-independent multiplicative factors. Regarding the minimax regret, the hardness (\u0398\u0303(T 1/2) or \u0398\u0303(T 2/3) regret) of partial monitoring problems is characterized by their global/local observability property [9] or, in case of the graph-structured feedback model, by their strong/weak observability property [5]. In the same section we present another algorithm that achieves the minimax regret (up to logarithmic factors) under both strong and weak observability, and achieves an O(log3/2 T ) problem-dependent regret. Earlier results for the stochastic graph-structured feedback problems [6, 7] provided only asymptotic problem-dependent lower bounds and performance bounds that did not match the asymptotic lower bounds or the minimax rate up to constant factors. Finally, we draw conclusions and consider some interesting future directions in Section 5. Due to space constraints, all proofs are deferred to the appendix."}, {"heading": "2 Problem Formulation", "text": "Formally, we consider an online learning problem with Gaussian payoffs and side observations: Suppose a learner has to choose from K actions in every round. When choosing an action, the learner receives a random payoff and also some side observations corresponding to other actions. More precisely, each action i \u2208 [K] = {1, . . . ,K} is associated with some parameter \u03b8i, and the payoff Yt,i to action i in round t is normally distributed random variable with mean \u03b8i and variance \u03c32ii, while the learner observes a K-dimensional Gaussian random vector Xt,i whose jth coordinate is a normal random variable with mean \u03b8j and variance \u03c32ij (we assume \u03c3ij \u2265 0) and the coordinates of Xt,i are independent of each other. We assume the following: (i) the random variables (Xt, Yt)t are independent for all t; (ii) the parameter vector \u03b8 is unknown to the learner but it knows the variance matrix \u03a3 = (\u03c32ij)i,j\u2208[K] in advance; (iii) \u03b8 \u2208 [0, D]K for some D > 0 ; (iv) mini\u2208[K] \u03c3ij \u2264 \u03c3 < \u221e for all j \u2208 [K], that is, the expected payoff of each action can be observed.\nThe goal of the learner is to maximize its payoff or, in other words, minimize the expected regret\nRT = T max i\u2208[K]\n\u03b8i \u2212 T\u2211\nt=1\nE [Yt,it ]\nwhere it is the action selected by the learner in round t.\nNote that the problem encompasses several common feedback models considered in online learning (modulo the Gaussian assumption), and makes it possible to examine more delicate observation structures:\nFull information: \u03c3ij = \u03c3j < \u221e for all i, j \u2208 [K]. Bandit: \u03c3ii < \u221e and \u03c3ij = \u221e for all i 6= j \u2208 [K]. Partial monitoring with feedback graphs [5]: Each action i \u2208 [K] is associated with an observa-\ntion set Si \u2282 [K] such that \u03c3ij = \u03c3j if j \u2208 Si and \u03c3ij = \u221e otherwise.\nWe will call the uniform variance version of these problems when all the finite \u03c3ij are equal to some \u03c3 \u2265 0. Some interesting features of the problem can be seen when considering the generalized full information case , when all entries of \u03a3 are finite. In this case, the greedy algorithm, which estimates the payoff of each action by the average of the corresponding observed samples and selects the one with the highest average, achieves at most a constant regret for any time horizon T .1 On the other hand, the constant can be quite large: in particular, when the variance of some observations are large relative to the gaps dj = maxi \u03b8i \u2212 \u03b8j , the situation is rather similar to a partial monitoring setup for a smaller, finite time horizon. In this paper we are going to analyze this problem and present algorithms and lower bounds that are able to \u201cinterpolate\u201d between these cases and capture the characteristics of the different regimes."}, {"heading": "2.1 Notation", "text": "Let CNT = {c \u2208 NK : ci \u2265 0 , \u2211\ni\u2208[K] ci = T } and N(T ) \u2208 CT denote the number of plays over all actions taken by some algorithm in T rounds. Also let CRT = {c \u2208 RK : ci \u2265 0 , \u2211 i\u2208[K] ci = T }. We will consider environments with different expected payoff vectors \u03b8 \u2208 \u0398, but the variance matrix \u03a3 will be fixed. Therefore, an environment can be specified by \u03b8; oftentimes, we will explicitly denote the dependence of different quantities on \u03b8: The probability and expectation functionals under environment \u03b8 will be denoted by Pr (\u00b7; \u03b8) and E [\u00b7; \u03b8], respectively. Furthermore, let ij(\u03b8) be the jth best action (ties are broken arbitrarily, i.e., \u03b8i1 \u2265 \u03b8i2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03b8iK ) and define di(\u03b8) = \u03b8i1(\u03b8)\u2212\u03b8i for any i \u2208 [K]. Then the expected regret under environment \u03b8 is RT (\u03b8) = \u2211 i\u2208[K] E [Ni(T ); \u03b8] di(\u03b8). For any action i \u2208 [K], let Si = {j \u2208 [K] : \u03c3ij < \u221e} denote the set of actions whose parameter \u03b8j is observable by choosing action i. Throughout the paper, log denotes the natural logarithm and \u2206n denotes the n-dimensional simplex for any positive integer n."}, {"heading": "3 Lower Bounds", "text": "The aim of this section is to derive generic, problem-dependent lower bounds to the regret, which are also able to provide minimax lower bounds. The hardness in deriving such bounds is that for any fixed \u03b8 and \u03a3, the dumb algorithm that always selects i1(\u03b8) achieves zero regret (the regret of this algorithm is linear for any \u03b8\u2032 with i1(\u03b8) 6= i1(\u03b8\u2032)), so in general it is not possible to give a lower bound for a single instance. When deriving asymptotic lower bounds, this is circumvented by only considering consistent algorithms whose regret is sub-polynomial for any problem [10]. However, this asymptotic notion of consistency is not applicable to finite-horizon problems. Therefore, following [11], for any problem we create a family of related problems (by perturbing the mean payoffs) such that if the regret of an algorithm is \u201ctoo small\u201d in one of the problems than it will be \u201clarge\u201d in another one.\nAs a warm-up, and to show the reader what form of a lower bound can be expected, first we present an asymptotic lower bound for the uniform-variance version of the problem of partial monitoring with feedback graphs. The result presented below is an easy consequence of [10], hence its proof is omitted. An algorithm is said to be consistent if sup\u03b8\u2208\u0398RT (\u03b8) = o(T\n\u03b3) for every \u03b3 > 0. Now assume for simplicity that there is a unique optimal action in environment \u03b8, that is, \u03b8i1(\u03b8) > \u03b8i for all i 6= i1 and let\nC\u03b8 =   c \u2208 [0,\u221e) K : \u2211\ni:j\u2208Si ci \u2265\n2\u03c32\nd2j (\u03b8) \u2200j 6= i1(\u03b8) ,\n\u2211\ni:i1(\u03b8)\u2208Si ci \u2265\n2\u03c32\nd2i2(\u03b8)(\u03b8)\n   .\nThen, for any consistent algorithm and for any \u03b8 with \u03b8i1(\u03b8) > \u03b8i2(\u03b8),\nlim inf T\u2192\u221e\nRT (\u03b8)\nlogT \u2265 inf c\u2208C\u03b8 \u3008c, d(\u03b8)\u3009 . (1)\nNote that the right hand side of (1) is 0 for any generalized full information problem (recall that the expected regret is bounded by a constant for such problems), but it is a finite positive number\n1To see this, notice that the error of identifying the optimal action decays exponentially with the number of rounds.\nfor other problems. Similar bounds have been provided in [6, 7] for graph-structured feedback with self-observability (under non-Gaussian assumptions on the payoffs). In the following we derive finite time lower bounds that are also able to replicate this result."}, {"heading": "3.1 A General Finite Time Lower Bound", "text": "First we derive a general lower bound. For any \u03b8, \u03b8\u2032 \u2208 \u0398 and q \u2208 \u2206|CNT |, define f(\u03b8, q, \u03b8\u2032) as\nf(\u03b8, q, \u03b8\u2032) = inf q\u2032\u2208\u2206|CNT |\n\u2211\na\u2208CNT\nq\u2032(a) \u3008a, d(\u03b8\u2032)\u3009\ns.t. \u2211\na\u2208CNT\nq(a) log q(a)\nq\u2032(a) \u2264\n\u2211\ni\u2208[K]\n Ii(\u03b8, \u03b8\u2032) \u2211\na\u2208CNT\nq(a)ai\n\n ,\nwhere Ii(\u03b8, \u03b8\u2032) is the KL-divergence between Xt,i(\u03b8) and Xt,i(\u03b8\u2032), given by Ii(\u03b8, \u03b8\u2032) = KL(Xt,i(\u03b8);Xt,i(\u03b8 \u2032)) = \u2211K\nj=1(\u03b8j \u2212 \u03b8\u2032j)2/2\u03c32ij . Clearly, f(\u03b8, q, \u03b8\u2032) is a lower bound on RT (\u03b8\u2032) for any algorithm for which the distribution of N(T ) is q. The intuition behind the allowed values of q\u2032 is that we want q\u2032 to be as similar to q as the environments \u03b8 and \u03b8\u2032 look like for the algorithm (through the feedback (Xt,it)t). Now define\ng(\u03b8, c) = inf q\u2208\u2206|CNT | sup \u03b8\u2032\u2208\u0398\nf(\u03b8, q, \u03b8\u2032), such that \u2211\na\u2208CNT\nq(a)a = c.\ng(\u03b8, c) is a lower bound of the worst-case regret of any algorithm with E [N(T ); \u03b8] = c. Finally, for any x > 0, define\nb(\u03b8, x) = inf c\u2208C\u03b8,x\n\u3008c, d(\u03b8)\u3009 where C\u03b8,x = {c \u2208 CRT ; g(\u03b8, c) \u2264 x}.\nHere C\u03b8,B contains all the value of E [N(T ); \u03b8] that can be achieved by some algorithm whose lower bound g on the worst-case regret is smaller than x. These definitions give rise to the following theorem:\nTheorem 1. Given any B > 0, for any algorithm such that sup\u03b8\u2032\u2208\u0398 RT (\u03b8) \u2264 B, we have, for any environment \u03b8 \u2208 \u0398, RT (\u03b8) \u2265 b(\u03b8,B). Remark 2. If B is picked as the minimax value of the problem given the observation structure \u03a3, the theorem states that for any minimax optimal algorithm the expected regret for a certain \u03b8 is lower bounded by b(\u03b8,B)."}, {"heading": "3.2 A Relaxed Lower Bound", "text": "Now we introduce a relaxed but more interpretable version of the finite-time lower bound of Theorem 1, which can be shown to match the asymptotic lower bound (1). The idea of deriving the lower bound is the following: instead of ensuring that the algorithm performs well in the most adversarial environment \u03b8\u2032, we consider a set of \u201cbad\u201d environments and make sure that the algorithm performs well on them, where each \u201cbad\u201d environment \u03b8\u2032 is the most adversarial one by only perturbing one coordinate \u03b8i of \u03b8.\nHowever, in order to get meaningful finite-time lower bounds, we need to perturb \u03b8 more carefully than in the case of asymptotic lower bounds. The reason for this is that for any sub-optimal action i, if \u03b8i is very close to \u03b8i1(\u03b8), then E [Ni(T ); \u03b8] is not necessarily small for a good algorithm for \u03b8. If it is small, one can increase \u03b8i to obtain an environment \u03b8\u2032 where i is the best action and the algorithm performs bad; otherwise, when E [Ni(T ); \u03b8] is large, we need to decrease \u03b8i to make the algorithm perform badly in \u03b8\u2032. Moreover, when perturbing \u03b8i to be better than \u03b8i1(\u03b8), we cannot make \u03b8 \u2032 i\u2212\u03b8i1(\u03b8) arbitrarily small as in asymptotic lower-bound arguments, because when \u03b8\u2032i \u2212 \u03b8i1(\u03b8) is small, large E [ Ni1(\u03b8); \u03b8\n\u2032] and not necessarily large E [Ni(T ); \u03b8\u2032] may lead to low finite-time regret in \u03b8\u2032. In the following we make this argument precise to obtain an interpretable lower bound."}, {"heading": "3.2.1 Formulation", "text": "We start with defining a subset of CRT that contains the set of \u201creasonable\u201d values for E [N(T ); \u03b8]. For any \u03b8 \u2208 \u0398 and B > 0, let\nC\u2032\u03b8,B =\n  c \u2208 C R T : K\u2211\nj=1\ncj \u03c32ji \u2265 mi(\u03b8,B) , \u2200i \u2208 [K]\n \n\nwhere mi, the minimum sample size required to distinguish between \u03b8i and its worstcase perturbation, is defined as follows: For i 6= i1, if \u03b8i1 = D, then mi(\u03b8,B) = 0. Otherwise let\nmi,+(\u03b8,B) = max \u01eb\u2208(di(\u03b8),D\u2212\u03b8i]\n1 \u01eb2 log T (\u01eb\u2212 di(\u03b8)) 8B ,\nmi,\u2212(\u03b8,B) = max \u01eb\u2208(0,\u03b8i]\n1 \u01eb2 log T (\u01eb+ di(\u03b8)) 8B ,\nand let \u01ebi,+ and \u01ebi,\u2212 denote the value of \u01eb achieving the maximum in mi,+ and mi,\u2212, respectively. Then, define\nmi(\u03b8,B) = { mi,+(\u03b8,B) if di(\u03b8) \u2265 4B/T ; min {mi,+(\u03b8,B),mi,\u2212(\u03b8,B)} if di(\u03b8) < 4B/T .\nFor i = i1, then mi1(\u03b8,B) = 0 if \u03b8i2(\u03b8) = 0, else the definitions for i 6= i1 change by replacing di(\u03b8) with di2(\u03b8)(\u03b8) (and switching the + and \u2212 indices): let\nmi1(\u03b8),\u2212(\u03b8,B) = max \u01eb\u2208(di2(\u03b8)(\u03b8),\u03b8i1(\u03b8)]\n1 \u01eb2 log T (\u01eb\u2212 di2(\u03b8)(\u03b8)) 8B ,\nmi1(\u03b8),+(\u03b8,B) = max \u01eb\u2208(0,D\u2212\u03b8i1(\u03b8)]\n1 \u01eb2 log T (\u01eb+ di2(\u03b8)(\u03b8)) 8B\nwhere \u01ebi1(\u03b8),\u2212 and \u01ebi1(\u03b8),+ are the maximizers for \u01eb in the above expressions. Then, define\nmi1(\u03b8)(\u03b8,B) = { mi1(\u03b8),\u2212(\u03b8,B) if di2(\u03b8)(\u03b8) \u2265 4B/T ; min { mi1(\u03b8),+(\u03b8,B),mi1(\u03b8),\u2212(\u03b8,B) } if di2(\u03b8)(\u03b8) < 4B/T .\nNote that \u01ebi,+ and \u01ebi,\u2212 can be expressed in closed form using the Lambert WR \u2192 R function satisfying W (x)eW (x) = x: for any i 6= i1(\u03b8),\n\u01ebi,+ = min { D \u2212 \u03b8i , 8 \u221a eB\nT e W\n(\ndi(\u03b8)T 16 \u221a eB\n)\n+ di(\u03b8)\n} , (2)\n\u01ebi,\u2212 = min { \u03b8i , 8 \u221a eB\nT e W\n(\n\u2212 di(\u03b8)T 16 \u221a eB\n) \u2212 di(\u03b8) } ,\nand similar results hold for i = i1, as well.\nNow we can give the main result of this section, a simplified version of Theorem 1:\nCorollary 3. Given B > 0, for any algorithm such that sup\u03bb\u2208\u0398 RT (\u03bb) \u2264 B, we have, for any environment \u03b8 \u2208 \u0398, RT (\u03b8) \u2265 b\u2032(\u03b8,B) = minc\u2208C\u2032\n\u03b8,B \u3008c, d(\u03b8)\u3009.\nNext we compare this bound to existing lower bounds.\n3.2.2 Comparison to the Asymptotic Lower Bound of (1)\nNow we will show that our finite time lower bound in Corollary 3 matches the asymptotic lower bound in (1) up to some constants.\nPick B = \u03b1T \u03b2 for some \u03b1 > 0 and 0 < \u03b2 < 1. For simplicity, we only consider \u03b8 which is \u201caway from\u201d the boundary of \u0398 (so that the minimum in (2) is not achieved on the boundary) and has a unique optimal action. Then, for i 6= i1(\u03b8), it is easy to show that \u01ebi,+ = di(\u03b8)2W (di(\u03b8)T 1\u2212\u03b2/(16\u03b1\u221ae)) +\ndi(\u03b8) by (2) and mi(\u03b8,B) = 1\u01eb2i,+ log T (\u01ebi,+\u2212di(\u03b8)) 8B for large enough T . Then, using the fact that log x \u2212 log log x \u2264 W (x) \u2264 log x for x \u2265 e, it follows that limT\u2192\u221e mi(\u03b8,B)/ logT = (1 \u2212 \u03b2)/d2i (\u03b8), and similarly we can show that limT\u2192\u221e mi1(\u03b8)(\u03b8,B)/ log T = (1\u2212\u03b2)/d2i2(\u03b8)(\u03b8). Thus, C\u2032\u03b8,B \u2192 (1\u2212\u03b2) log T2 C\u03b8 , under the assumptions of (1), as T \u2192 \u221e. This implies that Corollary 3 matches the asymptotic lower bound of (1) up to a factor of (1\u2212 \u03b2)/2."}, {"heading": "3.2.3 Comparison to Minimax Bounds", "text": "Now we will show that our \u03b8-dependent finite-time lower bound reproduces the minimax regret bounds of [2] and [5], except for the generalized full information case.\nThe minimax bounds depend on the following notion of observability: An action i is strongly observable if either i \u2208 Si or [K] \\ {i} \u2282 {j : i \u2208 Sj}. i is weakly observable if it is not strongly observable but there exists j such that i \u2208 Sj (note that we already assumed the latter condition for all i). Let W(\u03a3) be the set of all weakly observable actions. \u03a3 is said to be strongly observable if W(\u03a3) = \u2205. \u03a3 is weakly observable if W(\u03a3) 6= \u2205. Next we will define two key qualities introduced by [2] and [5] that characterize the hardness of a problem instance with feedback structure \u03a3: A set A \u2282 [K] is called an independent set if for any i \u2208 A, Si \u2229 A \u2282 {i}. The independence number \u03ba(\u03a3) is defined as the cardinality of the largest independent set. For any pair of subsets A,A\u2032 \u2282 [K], A is said to be dominatingA\u2032 if for any j \u2208 A\u2032 there exists i \u2208 A such that j \u2208 Si. The weak domination number \u03c1(\u03a3) is defined as the cardinality of the smallest set that dominates W(\u03a3). Corollary 4. Assume that \u03c3ij = \u221e for some i, j \u2208 [K], that is, we are not in the generalized full information case. Then,\n(i) if \u03a3 is strongly observable, with B = \u03b1\u03c3 \u221a \u03ba(\u03a3)T for some \u03b1 > 0, we have\nsup\u03b8\u2208\u0398 b \u2032(\u03b8,B) \u2265 \u03c3\n\u221a \u03ba(\u03a3)T\n64e\u03b1 for T \u2265 64e2\u03b12\u03c32\u03ba(\u03a3)3/D2.\n(ii) If \u03a3 is weakly observable, with B = \u03b1(\u03c1(\u03a3)D)1/3(\u03c3T )2/3 log\u22122/3 K for some \u03b1 > 0, we\nhave sup\u03b8\u2208\u0398 b \u2032(\u03b8,B) \u2265 (\u03c1(\u03a3)D) 1/3(\u03c3T )2/3 log\u22122/3 K 51200e2\u03b12 .\nRemark 5. In Corollary 4, picking \u03b1 = 1 8 \u221a e for strongly observable \u03a3 and \u03b1 = 173 for weakly observable \u03a3 gives formal minimax lower bounds: (i) If \u03a3 is strongly observable, for any algorithm we have sup\u03b8\u2208\u0398RT (\u03b8) \u2265 \u03c3 \u221a \u03ba(\u03a3)T 8 \u221a e\nfor T \u2265 e\u03c32\u03ba(\u03a3)3/D2. (ii) If \u03a3 is weakly observable, for any algorithm we have sup\u03b8\u2208\u0398RT (\u03b8) \u2265 (\u03c1(\u03a3)D) 1/3(\u03c3T )2/3 73 log2/3 K ."}, {"heading": "4 Algorithms", "text": "In this section we present two algorithms and their finite-time analysis for the uniform variance version of our problem (where \u03c3ij is either \u03c3 or \u221e). The upper bound for the first algorithm matches the asymptotic lower bound in (1) up to constants. The second algorithm achieves the minimax lower bounds of Corollary 4 up to logarithmic factors, as well as O(log3/2 T ) problem-dependent regret. In the problem-dependent upper bounds of both algorithms, we assume that the optimal action is unique, that is, di2(\u03b8)(\u03b8) > 0."}, {"heading": "4.1 An Asymptotically Optimal Algorithm", "text": "Let c(\u03b8) = argminc\u2208C\u03b8 \u3008c, d(\u03b8)\u3009; note that increasing ci1(\u03b8)(\u03b8) does not change the value of \u3008c, d(\u03b8)\u3009 (since di1(\u03b8)(\u03b8) = 0), so we take the minimum value of ci1(\u03b8)(\u03b8) in this definition. Let ni(t) = \u2211t\u22121 s=1 I {i \u2208 Sis} be the number of observations for action i before round t and \u03b8\u0302i,t be the\nempirical estimate of \u03b8i based on the first ni(t) observations. Let Ni(t) = \u2211t\u22121\ns=1 I {is = i} be the number of plays for action i before round t. Note that this definition of Ni(t) is different from that in the previous sections since it excludes the round t.\nOur first algorithm is presented in Algorithm 1. The main idea, coming from [12], is that by forcing exploration over all actions the solution c(\u03b8) of the linear program can be well approximated while\nAlgorithm 1 1: Inputs: \u03a3, \u03b2(n), \u03b1. 2: For t = 1, ...,K , observe each action i at least once by playing it such that t \u2208 Sit . 3: Set exploration count ne(K + 1) = 0. 4: for t = K + 1,K + 2, ... do 5: if N(t)4\u03b1 log t \u2208 C\u03b8\u0302t then 6: Play it = i1(\u03b8\u0302t). 7: Set ne(t+ 1) = ne(t). 8: else 9: if mini\u2208[K] ni(t) < \u03b2(ne(t))/K then 10: Play it such that argmini\u2208[K] ni(t) \u2208 Sit . 11: else 12: Play it such that Ni(t) < ci(\u03b8\u0302t)4\u03b1 log t. 13: end if 14: Set ne(t+ 1) = ne(t) + 1. 15: end if 16: end for\npaying a constant price. This solves the main difficulty that, without getting enough observations on each action, we may not have good enough estimates for d(\u03b8) and c(\u03b8). One advantage of our algorithm compared to that of [12] is that we use a sublinear exploration schedule \u03b2(n) instead of a constant rate \u03b2(n) = \u03b2n. This resolves the problem that, to achieve asymptotically optimal performance, some parameter of the algorithm needs to be chosen according to dmin(\u03b8) as in [12]. The expected regret of Algorithm 1 is upper bounded as follows:\nTheorem 6. For any \u03b8 \u2208 \u0398, \u01eb > 0, \u03b1 > 2 and any non-decreasing \u03b2(n) that satisfies 0 \u2264 \u03b2(n) \u2264 n/2 and \u03b2(m+ n) \u2264 \u03b2(m) + \u03b2(n) for m,n \u2208 N,\nRT (\u03b8) \u2264 ( 2K + 2 + 4K\n\u03b1\u2212 2\n) dmax(\u03b8) + 4Kdmax(\u03b8) T\u2211\ns=0\nexp ( \u2212\u03b2(s)\u01eb 2\n2K\u03c32\n)\n+ 2dmax(\u03b8)\u03b2\n 4\u03b1 logT \u2211\ni\u2208[K] ci(\u03b8, \u01eb) +K\n + 4\u03b1 logT \u2211\ni\u2208[K] ci(\u03b8, \u01eb)di(\u03b8) .\nwhere ci(\u03b8, \u01eb) = sup{ci(\u03b8\u2032) : |\u03b8\u2032j \u2212 \u03b8j | \u2264 \u01eb \u2200j \u2208 [K]}.\nFurther specifying \u03b2(n) and using the continuity of c(\u03b8) around \u03b8, it immediately follows that Algorithm 1 achieves asymptotically optimal performance:\nCorollary 7. Suppose the conditions of Theorem 6 hold. Assume, furthermore, that \u03b2(n) satisfies \u03b2(n) = o(n) and \u2211\u221e s=0 exp ( \u2212\u03b2(s)\u01eb 2 2K\u03c32 ) < \u221e for any \u01eb > 0, then for any \u03b8 such that c(\u03b8) is unique,\nlim sup T\u2192\u221e RT (\u03b8)/ logT \u2264 4\u03b1 inf c\u2208C(\u03b8) \u3008c, d(\u03b8)\u3009 .\nNote that any \u03b2(n) = anb with a \u2208 (0, 12 ], b \u2208 (0, 1) satisfies the requirements in Theorem 6 and Corollary 7. Also note that the algorithms presented in [6, 7] do not achieve this asymptotic bound."}, {"heading": "4.2 A Minimax Optimal Algorithm", "text": "For any A,A\u2032 \u2282 [K], define c(A,A\u2032) = argmaxc\u2208\u2206|A| mini\u2208A\u2032 \u2211\nj:i\u2208Sj cj (ties are broken arbitrarily) and m(A,A\u2032) = mini\u2208A\u2032 \u2211 j:i\u2208Sj cj(A,A\n\u2032). For any A \u2282 [K] and |A| \u2265 2, define AS = {i \u2208 A : \u2203j \u2208 A, i \u2208 Sj} and AW = A\u2212AS . Furthermore, let gi,r(\u03b4) = \u03c3 \u221a 2 log(8K2r3/\u03b4)\nni(r)\nwhere ni(r) = \u2211r\u22121\ns=1 ir,i and \u03b8\u0302i,r be the empirical estimate of \u03b8i based on first ni(r) observations (i.e., the average of the samples).\nAlgorithm 2 1: Inputs: \u03a3, \u03b4. 2: Set t1 = 0, A1 = [K]. 3: for r = 1, 2, ... do 4: Let \u03b1r = min1\u2264s\u2264r,AWs 6=\u2205 m([K] , A W s ) and \u03b3(r) = (\u03c3\u03b1rtr/D)\n2/3. ( Define \u03b1r = 1 if AWs = \u2205 for all 1 \u2264 s \u2264 r.)\n5: if AWr 6= \u2205 and mini\u2208AWr ni(r) < mini\u2208ASr ni(r) and mini\u2208AWr ni(r) < \u03b3(r) then 6: Set cr = c([K] , AWr ). 7: else 8: Set cr = c(Ar , ASr ). 9: end if\n10: Play ir = \u2308cr \u00b7 \u2016cr\u20160\u2309. 11: tr+1 \u2190 tr + \u2016ir\u20161. 12: Ar+1 \u2190 {i \u2208 Ar : \u03b8\u0302i,r+1 + gi,r+1(\u03b4) \u2265 maxj\u2208Ar \u03b8\u0302j,r+1 \u2212 gj,r+1(\u03b4)}. 13: if |Ar+1| = 1 then 14: Play the only action in the remaining rounds. 15: end if 16: end for\nOur second algorithm, presented in Algorithm 2, follows a successive elimination process: it explores all possibly optimal actions (called \u201cgood actions\u201d later) based on some confidence intervals until only one action remains. While doing exploration, it first tries to explore the good actions by only using good ones. However, due to weak observability, some good actions might have to be explored by the actions that are eliminated. To control this exploration-exploitation trade off, we use a sublinear function \u03b3 to control the exploration of weakly observable actions. In the following we present high-probability bounds on the performance of the algorithm, so, with a slight abuse of notation, RT (\u03b8) will denote the regret without expectation in the rest of this section. Theorem 8. For any \u03b4 \u2208 (0, 1) and any \u03b8 \u2208 \u0398,\nRT (\u03b8) \u2264 (\u03c1(\u03a3)D)1/3(\u03c3T )2/3 \u00b7 7 \u221a 6 log(2KT/\u03b4) + 125\u03c32K3/D + 13K3D\nwith probability at least 1\u2212 \u03b4 if \u03a3 is weakly observable, while\nRT (\u03b8) \u2264 2KD + 80\u03c3 \u221a \u03ba(\u03a3)T \u00b7 6 logK log 2KT\n\u03b4\nwith probability at least 1\u2212 \u03b4 if \u03a3 is strongly observable. Theorem 9 (Problem-dependent upper bound). For any \u03b4 \u2208 (0, 1) and any \u03b8 \u2208 \u0398 such that the optimal action is unique, with probability at least 1\u2212 \u03b4,\nRT (\u03b8) \u2264 1603\u03c1(\u03a3)D\u03c32\nd2min(\u03b8)\n( log 2KT\n\u03b4\n)3/2 + 14K3D + 125\u03c32K3\nD\n+ 15 ( \u03c1(\u03a3)D\u03c32\n)1/3 ( 125\u03c32\nD2 + 10\n) K2 ( log 2KT\n\u03b4\n)1/2 .\nRemark 10. Picking \u03b4 = 1/T gives an O ( log3/2 T ) upper bound on the expected regret.\nRemark 11. Note that Algortihm 2 is similar to the UCB-LP algorithm of [7], which admits a better problem-dependent upper bound (although does not achieve it with optimal problem-dependent constants), but it does not achieve the minimax bound even under strong observability."}, {"heading": "5 Conclusions and Open Problems", "text": "We considered a novel partial-monitoring setup with Gaussian side observations, which generalizes the recently introduced setting of graph-structured feedback, allowing finer quantification of the observed information from one action to another. We provided non-asymptotic problem-dependent\nlower bounds that imply existing asymptotic problem-dependent and non-asymptotic minimax lower bounds (up to some constant factors) beyond the full information case. We also provided an algorithm that achieves the asymptotic problem-dependent lower bound (up to some universal constants) and another algorithm that achieves the minimax bounds under both weak and strong observability.\nHowever, we think this is just the beginning. For example, we currently have no algorithm that achieves both the problem dependent and the minimax lower bounds at the same time. Also, our upper bounds only correspond to the graph-structured feedback case. It is of great interest to go beyond the weak/strong observability in characterizing the harness of the problem, and provide algorithms that can adapt to any correspondence between the mean payoffs an the variances (the hardness is that one needs to identify suboptimal actions with good information/cost trade-off)."}, {"heading": "Acknowledgments", "text": "This work was supported by the Alberta Innovates Technology Futures through the Alberta Ingenuity Centre for Machine Learning (AICML) and NSERC. During this work, A. Gyo\u0308rgy was with the Department of Computing Science, University of Alberta."}, {"heading": "A Proofs for Section 3", "text": "A.1 Proof of Theorem 1\nLet \u03c6\u03b8,\u03c3 denote the density function of a K-dimensional Gaussian random variable with mean vector \u03b8 and independent components wehere the variance of the ith coordinate is \u03c32i , and define LT =\u2211T\nt=1 log \u03c6\u03b8,\u03c3it (Xt,it )\n\u03c6\u03b8\u2032,\u03c3it (Xt,it )\nwhere it is the choice of the algorithm in round t. Let q, q\u2032 \u2208 \u2206|C N T | denote\nthe joint distribution over the number of plays for each action under environment \u03b8 and \u03b8\u2032 \u2208 \u0398, respectively, that is, q(a) = Pr (N(T ) = a; \u03b8) and q\u2032(a) = Pr (N(T ) = a; \u03b8\u2032) for each a \u2208 CNT . For any a \u2208 CNT , applying a standard change of measure equality (see, e.g., [13, Lemma 15]), we obtain\nq\u2032(a) = Pr (N(T ) = a; \u03b8\u2032) = E [I {N(T ) = a} exp(\u2212LT ); \u03b8] = E [I {N(T ) = a}E [exp(\u2212LT )|N(T ) = a; \u03b8] ; \u03b8] \u2265 E [I {N(T ) = a} exp (E [\u2212LT |N(T ) = a; \u03b8]) ; \u03b8] = Pr (N(T ) = a; \u03b8) exp (E [\u2212LT |N(T ) = a; \u03b8]) = q(a) exp (E [\u2212LT |N(T ) = a; \u03b8]) .\nThus E [LT |N(T ) = a; \u03b8] \u2265 log q(a)q\u2032(a) and so \u2211 i\u2208[K] E [Ni(T ); \u03b8] Ii(\u03b8, \u03b8 \u2032) = E [LT ; \u03b8]\n= \u2211\na\u2208CNT\nPr (N(T ) = a; \u03b8)E [LT |N(T ) = a; \u03b8] \u2265 \u2211\na\u2208CNT\nq(a) log q(a)\nq\u2032(a) ,\nwhere E [Ni(T ); \u03b8] = \u2211\na\u2208CNT q(a)ai. Therefore, according to the definition of f(\u03b8, q, \u03b8 \u2032), we\nhave f(\u03b8, q, \u03b8\u2032) \u2264 \u2211a\u2208CNT q \u2032(a) \u3008a, d(\u03b8\u2032)\u3009 = RT (\u03b8\u2032) for any \u03b8\u2032 \u2208 \u0398. Then sup\u03b8\u2032\u2208\u0398 f(\u03b8, q, \u03b8\u2032) \u2264\nsup\u03b8\u2032\u2208\u0398 RT (\u03b8 \u2032) \u2264 B must hold. Since E [N(T ); \u03b8] = \u2211a\u2208CNT q(a)a we have g(\u03b8,E [N(T ); \u03b8]) \u2264 sup\u03b8\u2032\u2208\u0398 f(\u03b8, q, \u03b8 \u2032) \u2264 B. Thus E [N(T ); \u03b8] \u2208 C\u03b8,B and so RT (\u03b8) \u2265 b(\u03b8,B), which concludes the proof of Theorem 1.\nA.2 Proof of Corollary 3\nWe start the proof with two technical lemmas on the Lambert W function.\nLemma 12. Let a, b > 0 with ab < 1 and f(x) = 1x2 log ((x+ a)b) for x > 0. Then f(x) \u2264 f(x\u2217) for all x > 0 where\nx\u2217 =\n\u221a e\nb e W\n(\n\u2212 ab 2 \u221a e\n)\n\u2212 a .\nLemma 13. Let a, b > 0 and f(x) = 1x2 log ((x \u2212 a)b) for x > a. Then f(x) \u2264 f(x\u2217) for all x > a where\nx\u2217 =\n\u221a e\nb e W\n(\nab 2 \u221a e\n)\n+ a .\nProof of Lemma 13.\nf \u2032(x) = x\u22123\nx\u2212 a (x\u2212 2(x\u2212 a) log ((x\u2212 a)b)) .\nLet g(y) = y + a\u2212 2y log by defined on y > 0. g\u2032(y) = \u22122 log yb\u2212 1\nSo g(y) is increasing when 0 < y < 1 b \u221a e and decreasing when y > 1 b \u221a e .\nSince limy\u21920 g(y) = a > 0 and limy\u2192+\u221e g(y) = \u2212\u221e we know that there exists a unique y\u2217 > 0 such that g(y\u2217) = 0, g(y) > 0 for 0 < y < y\u2217 and g(y) < 0 for y > y\u2217. It can be verified that y\u2217 = x\u2217 \u2212 a = \u221a e b e W ( ab 2 \u221a e )\nsatisfies g(y\u2217) = 0. Therefore f \u2032(x) > 0 when a < x < x\u2217 and f \u2032(x) < 0 when x > x\u2217. Since f(x) is continuous when x > a we have proved that f(x) \u2264 f(x\u2217) for all x > a.\nProof of Corollary 3. To prove the corollary, it suffices to show b\u2032(\u03b8,B) \u2264 b(\u03b8,B). Define C\u2032\u03b8,B = { c \u2208 CRT : \u2211K j=1\ncj \u03c32ji\n\u2265 mi(\u03b8,B) , \u2200i \u2208 [K] }\n. We will prove C\u03b8,B \u2282 C\u2032\u03b8,B by showing that if c \u2208 CRT satisfies g(\u03b8, c) \u2264 B then c \u2208 C\u2032\u03b8,B .\nFor c \u2208 CRT , if g(\u03b8, c) \u2264 B, then there exists q \u2208 \u2206|C N T | such that sup\u03b8\u2032\u2208\u0398 f(\u03b8, q, \u03b8 \u2032) \u2264 B and\u2211\na\u2208CNT q(a)a = c. We will next derive K constraints on c to show that c \u2208 C\u2032\u03b8,B by picking\ndifferent \u03b8\u2032s. Before proceeding with the proof, we introduce the following technical lemma:\nLemma 14. For any A \u2282 CNT and q, q\u2032 \u2208 \u2206|C N T |, if q(A) \u2265 1/2 then \u2211\na\u2208CNT\nq(a) log q(a) q\u2032(a) \u2265 1 2 log 1 4q\u2032(A) ,\nwhere q\u2032(A) = \u2211\na\u2208A q \u2032(a).\nProof. Let Ac = CNT \u2212A. By the log-sum inequality we have \u2211\na\u2208CNT\nq(a) log q(a) q\u2032(a) \u2265 KL(q(A), q\u2032(A)) , (3)\nwhere for x, y \u2208 [0, 1], KL(x, y) = x log(x/y) + (1 \u2212 x) log((1 \u2212 x)/(1 \u2212 y)) denotes the binary KL-divergence. Now for such x, y, since x log x + (1 \u2212 x) log(1 \u2212 x) is minimized for x = 1/2, we have\nKL(x, y) \u2265 log 1 2 + x log 1 y + (1\u2212 x) log( 1 1\u2212 y ) \u2265 log 1 2 + 1 2 log 1 y = 1 2 log 1 4y .\nCombining with (3) proves the lemma.\nNow we continue the proof of Corollary 3. First consider i 6= i1(\u03b8). If \u2211\na:ai\u2264T/2 q(a) \u2265 1/2, construct \u03b8(i,+) by replacing \u03b8i with \u03b8i + \u01ebi,+. Then f(\u03b8, q, \u03b8(i,+)) \u2264 B holds, so there exists q\u2032 \u2208 \u2206|CNT | such that \u2211a\u2208CNT q \u2032(a) \u2329 a, d(\u03b8(i,+)) \u232a \u2264 B and \u2211 a\u2208CNT q(a) log q(a)q\u2032(a) \u2264 \u2211 j\u2208[K] cjIj(\u03b8, \u03b8 (i,+)). Applying Lemma 14 with A = {a : ai \u2264 T/2} gives \u2211\nj\u2208[K] cjIj(\u03b8, \u03b8\n(i,+)) \u2265 1 2 log 1 4q\u2032(A) ,\nwhere\nq\u2032(A) = \u2211\na\u2208CNT\nI\n \n \u2211\nj 6=i aj \u2265 T/2\n   q \u2032(a) \u2264 2 T \u2211\na\u2208CNT\nq\u2032(a) \u2211\nj 6=i aj\n= 2 T (\u01ebi,+ \u2212 di(\u03b8)) \u2211\na\u2208CNT\nq\u2032(a) \u2211\nj 6=i aj(\u01ebi,+ \u2212 di(\u03b8))\n\u2264 2 T (\u01ebi,+ \u2212 di(\u03b8))\n\u2211\na\u2208CNT\nq\u2032(a) \u2329 a, d(\u03b8(i,+)) \u232a\n\u2264 2B T (\u01ebi,+ \u2212 di(\u03b8)) .\nSince Ij(\u03b8, \u03b8(i,+)) = \u01eb2i,+/2\u03c3 2 ji, we get\n\u2211\nj\u2208[K]\ncj \u03c32ji \u2265 1 \u01eb2i,+ log T (\u01ebi,+ \u2212 di(\u03b8)) 8B . (4)\nIf \u2211\na:ai\u2264T/2 q(a) < 1/2 and di(\u03b8) \u2265 4B/T , then\nf(\u03b8, q, \u03b8) = \u2211\na\u2208CNT\nq(a) \u3008a, d(\u03b8)\u3009 \u2265 \u2211\na\u2208CNT\nq(a)aidi(\u03b8)\n\u2265 di(\u03b8) \u2211\na\u2208CNT\nI {ai \u2265 T/2} q(a)ai\n\u2265 4B T T 2\n\u2211\na\u2208CNT\nI {ai \u2265 T/2} q(a) > B ,\nwhich contradicts the fact that sup\u03b8\u2032\u2208\u0398 f(\u03b8, q, \u03b8 \u2032) \u2264 B. If \u2211\na:ai\u2264T/2 q(a) < 1/2 and di(\u03b8) < 4B/T , construct \u03b8 (i,\u2212) by replacing \u03b8i with \u03b8i \u2212 \u01ebi,\u2212. Then\nthere exists q\u2032 \u2208 \u2206|CNT | such that \u2211a\u2208CNT q \u2032(a) \u2329 a, d(\u03b8(i,\u2212)) \u232a \u2264 B and \u2211a\u2208CNT q(a) log q(a) q\u2032(a) \u2264\u2211\nj\u2208[K] cjIj(\u03b8, \u03b8 (i,\u2212)). Applying Lemma 14 with A = {a : ai > T/2} gives\n\u2211\nj\u2208[K] cjIj(\u03b8, \u03b8\n(i,\u2212)) \u2265 1 2 log 1 4q\u2032(A) ,\nwhere q\u2032(A) = \u2211\na\u2208CNT\nI {ai > T/2} q\u2032(a) \u2264 2\nT\n\u2211\na\u2208CNT\naiq \u2032(a) \u2264 2\nT (\u01ebi,\u2212 + di(\u03b8))\n\u2211\na\u2208CNT\nq\u2032(a)ai(\u01ebi,\u2212 + di(\u03b8))\n\u2264 2 T (\u01ebi,\u2212 + di(\u03b8))\n\u2211\na\u2208CNT\nq\u2032(a) \u2329 a, d(\u03b8(i,\u2212)) \u232a \u2264 2B\nT (\u01ebi,\u2212 + di(\u03b8)) .\nUsing Ij(\u03b8, \u03b8(i,\u2212)) = \u01eb2i,\u2212/2\u03c3 2 ji gives\n\u2211\nj\u2208[K]\ncj \u03c32ji \u2265 1 \u01eb2i,\u2212 log T (\u01ebi,\u2212 + di(\u03b8)) 8B . (5)\nNow consider i = i1(\u03b8). If \u2211\na:ai\u2265T/2 q(a) \u2265 1/2, construct \u03b8(i1,\u2212) by replacing \u03b8i with \u03b8i \u2212 \u01ebi,\u2212. Then there exists q\u2032 \u2208 \u2206|CNT | such that \u2211a\u2208CNT q \u2032(a) \u2329 a, d(\u03b8(i,\u2212)) \u232a \u2264 B and \u2211a\u2208CNT q(a) log q(a) q\u2032(a) \u2264\u2211\nj\u2208[K] cjIj(\u03b8, \u03b8 (i,\u2212)). Applying Lemma 14 with A = {a : ai \u2265 T/2} and\nq\u2032(A) = \u2211\na\u2208CNT\nI {ai \u2265 T/2} q\u2032(a) \u2264 2 T (\u01ebi,\u2212 \u2212 di2(\u03b8)(\u03b8)) \u2211\na\u2208CNT\nq\u2032(a)ai(\u01ebi,\u2212 \u2212 di2(\u03b8)(\u03b8)) \u2264 2B\nT (\u01ebi,\u2212 \u2212 di2(\u03b8)(\u03b8))\ngives\n\u2211\nj\u2208[K]\ncj \u03c32ji \u2265 1 \u01eb2i,\u2212\nlog T (\u01ebi,\u2212 \u2212 di2(\u03b8)(\u03b8))\n8B . (6)\nIf \u2211\na:ai\u2265T/2 q(a) < 1/2 and di2(\u03b8)(\u03b8) \u2265 4B/T , then\nf(\u03b8, q, \u03b8) = \u2211\na\u2208CNT\nq(a) \u3008a, d(\u03b8)\u3009 \u2265 \u2211\na\u2208CNT\nq(a)di2(\u03b8) \u2211\nj 6=i aj \u2265 di2(\u03b8)\n\u2211\na\u2208CNT\nI    \u2211\nj 6=i aj > T/2\n   q(a) \u2211\nj 6=i aj\n> 4B\nT\nT\n2\n\u2211\na\u2208CNT\nI    \u2211\nj 6=i aj > T/2\n   q(a) \u2265 B ,\nwhich contradicts the fact that sup\u03b8\u2032\u2208\u0398 f(\u03b8, q, \u03b8 \u2032) \u2264 B. If \u2211\na:ai\u2265T/2 q(a) < 1/2 and di2(\u03b8)(\u03b8) < 4B/T , construct \u03b8 (i,+) by replacing \u03b8i with\n\u03b8i + \u01ebi,+. Then there exists q\u2032 \u2208 \u2206|C N T | such that \u2211\na\u2208CNT q\u2032(a)\n\u2329 a, d(\u03b8(i,+)) \u232a \u2264 B and\n\u2211 a\u2208CNT q(a) log q(a) q\u2032(a) \u2264 \u2211 j\u2208[K] cjIj(\u03b8, \u03b8\n(i,+)). Applying Lemma 14 with A = {a : ai < T/2} and\nq\u2032(A) = \u2211\na\u2208CNT\nI\n \n \u2211\nj 6=i aj > T/2\n   q \u2032(a) \u2264 2 T \u2211\na\u2208CNT\nq\u2032(a) \u2211\nj 6=i aj\n= 2\nT (\u01ebi,+ + di2(\u03b8)(\u03b8))\n\u2211\na\u2208CNT\nq\u2032(a) \u2211\nj 6=i aj(\u01ebi,+ + di2(\u03b8)) \u2264\n2B\nT (\u01ebi,+ + di2(\u03b8))\ngives\n\u2211\nj\u2208[K]\ncj \u03c32ji \u2265 1 \u01eb2i,+ log T (\u01ebi,+ + di2(\u03b8)) 8B . (7)\nCombining (4) (5) (6) (7) gives c \u2208 C\u2032\u03b8,B, which concludes the proof.\nA.3 Proof of Corollary 4\nProof of Corollary 4. Define \u01eb = 8eBT . First consider the case that \u03a3 is strongly observable. If the maximum independence number \u03ba(\u03a3) \u2265 2, there exists an independent set A\u03ba \u2282 [K] such that |A\u03ba| = \u03ba(\u03a3). We construct \u03b8 as follows: Let \u03b8i1 = D/2 for some i1 \u2208 A\u03ba and \u03b8i = D/2\u2212 \u01eb for i \u2208 A\u03ba \\ {i1}. For the remaining i /\u2208 A\u03ba, let \u03b8i = 0. Note that each i in A\u03ba must be self observable since otherwise it is a weakly observable action. Also in A\u03ba i can be observed only by itself according to the definition of independent sets.\nThen we will lower bound b\u2032(\u03b8,B). According to our choice of \u01eb, we have\n8 \u221a eB\nT e W\n(\n\u01ebT 16 \u221a eB\n)\n+ \u01eb = 2\u01eb .\nTherefore, for i = i1 we have \u01ebi,\u2212 = 2\u01eb and \u01ebi,+ = 2\u01eb for i \u2208 A\u03ba \\ {i1}. Thus for any i \u2208 A\u03ba,\nmi(\u03b8,B) = 1\n4\u01eb2 log\nT \u01eb 8B = 1 4\u01eb2 .\nRecall that we defined C\u2032\u03b8,B = { c \u2208 CRT : \u2211 j:i\u2208Sj cj \u2265 \u03c32mi(\u03b8,B) , \u2200i \u2208 [K] } and b\u2032(\u03b8,B) = infc\u2208C\u2032\u03b8,B \u3008c, d(\u03b8)\u3009. For any c \u2208 C\u2032\u03b8,B , let a = \u2211\ni/\u2208A\u03ba ci. Then we have for any i \u2208 A\u03ba,\u2211 j:i\u2208Sj cj \u2264 a+ ci and thus ci \u2265 \u03c32mi(\u03b8,B)\u2212a = \u03c32\n4\u01eb2 \u2212a. Since di(\u03b8) = \u01eb for all i \u2208 A\u03ba \\{i1} and di(\u03b8) = D/2 for all i /\u2208 A\u03ba, we get\n\u3008c, d(\u03b8)\u3009 = \u2211\ni\u2208A\u03ba\\{i1} ci\u01eb +\naD\n2 \u2265 (\u03ba(\u03a3)\u2212 1)\n( \u03c32\n4\u01eb2 \u2212 a\n) \u01eb+ aD\n2\n\u2265 \u03ba(\u03a3) 2\n( \u03c32\n4\u01eb2 \u2212 a\n) \u01eb + aD\n2 =\n\u03ba(\u03a3)\u03c32\n8\u01eb + D \u2212 \u03ba(\u03a3)\u01eb 2 a\n\u2265 \u03ba(\u03a3)\u03c3 2\n8\u01eb (8)\nif \u03ba(\u03a3)\u01eb < D. Applying our particular choice of \u01eb and B, we get the conclusion that for T \u2265 64e2\u03b12\u03c32\u03ba(\u03a3)3\nD2 , b \u2032(\u03b8,B) \u2265 \u03c3\n\u221a \u03ba(\u03a3)T\n64e\u03b1 .\nIf \u03ba(\u03a3) = 1, since we exclude the full information case, there always exists a pair of actions i1 and i2 such that i2 /\u2208 Si1 (here i1 6= i2 is not necessary). We construct \u03b8 by setting \u03b8i1 = D/2 and \u03b8i = D/2 \u2212 \u01eb for all i 6= i1. Then mi(\u03b8,B) = 14\u01eb2 holds for all i \u2208 [K]. For any c \u2208 C\u2032\u03b8,B , let a =\n\u2211 i6=i1 ci, then \u2211 j:i2\u2208Sj cj \u2264 a. Hence a \u2265 \u03c32mi2(\u03b8,B) = \u03c32 4\u01eb2 and\n\u3008c, d(\u03b8)\u3009 = a\u01eb \u2265 \u03c3 2\n4\u01eb >\n\u03ba(\u03a3)\u03c32\n8\u01eb . (9)\nCombining (8) and (9) gives the first part of Corollary 4.\nNow we turn to the case that \u03a3 is weakly observable. The idea of constructing the worst \u03b8 comes from the proof of Theorem 7 in [5] which based on the following graph-theoretic lemma:\nLemma 15 (Restated from Lemma 8 in [5]). Let G = (V,E) be a directed graph with K vertices and let W \u2282 V be a subset of vertices with domination number \u03c1. Then there exists an independent set U \u2282 W with the property that |U | \u2265 \u03c150 logK and any vertex of G dominates at most logK vertices of U .\nLet W(\u03a3) \u2282 [K] be the set of all weakly observable actions. By Lemma 15 we know that there exists an independent set A\u03c1 \u2282 W(\u03a3) such that |A\u03c1| \u2265 \u03c1(\u03a3)50 logK and for any i \u2208 [K], |Si \u2229 U | \u2264 logK .\nIf \u03c1(\u03a3) \u2265 100 logK such that |A\u03c1| \u2265 2, we can construct \u03b8 as follows: Let \u03b8i1 = D/2 for some i1 \u2208 A\u03c1 and \u03b8i = D/2\u2212 \u01eb for i \u2208 A\u03c1 \\{i1}. For the remaining i /\u2208 A\u03c1, let \u03b8i = 0. Note that actions in A\u03c1 cannot be observed by any action inside A\u03c1. For any c \u2208 C\u2032\u03b8,B , let a = \u2211 i/\u2208A\u03c1 ci. Since for\nany i, |Si \u2229 U | \u2264 logK , we have \u2211 i\u2208A\u03c1 \u2211 j:i\u2208Sj cj \u2264 a logK and\na logK \u2265 |A\u03c1| min i\u2208A\u03c1\n\u2211\nj:i\u2208Sj cj \u2265 |A\u03c1| min i\u2208A\u03c1 \u03c32mi(\u03b8,B) \u2265\n\u03c1(\u03a3)\u03c32\n200 logK\u01eb2 .\nTherefore,\n\u3008c, d(\u03b8)\u3009 \u2265 aD 2 \u2265 \u03c1(\u03a3)\u03c3 2D 200\u01eb2 log2 K =\n(\u03c1(\u03a3)D)1/3(\u03c3T )2/3 log\u22122/3 K\n12800e2\u03b12 . (10)\nIf \u03c1(\u03a3) < 100 logK , then we pick a weakly observable action as i2. There must be another action i1 such that i2 /\u2208 Si1 due to the definition of weakly observable actions. Then we set \u03b8 as \u03b8i1 = D/2, \u03b8i2 = D/2 \u2212 \u01eb and \u03b8i = 0 for the remaining actions. So for any c \u2208 C\u2032\u03b8,B , let a = \u2211 i6=i1,i2 ci \u2265 \u03c32mi2(\u03b8,B). Then\n\u3008c, d(\u03b8)\u3009 \u2265 aD 2 \u2265 \u03c3 2mi2(\u03b8,B)D 2 = D\u03c32 8\u01eb2 = D1/3(\u03c3T )2/3 512e2\u03b12 \u00b7 log 4/3 K \u03c1(\u03a3)2/3\n\u2265 (\u03c1(\u03a3)D) 1/3(\u03c3T )2/3 log\u22122/3 K\n51200e2\u03b12 . (11)\nIn the last step we used the fact that K \u2265 3 for any weakly observable \u03a3. Combining (10) and (11) gives the second part of Corollary 4."}, {"heading": "B Proofs for Section 4.1", "text": "B.1 Proof of Theorem 6\nProof of Theorem 6. Define events\nUt = { \u2200i \u2208 [K] , |\u03b8\u0302i,t \u2212 \u03b8i| \u2264 \u221a 2\u03b1\u03c32 log t\nni(t)\n} ,\nVt = { \u2200i \u2208 [K] , |\u03b8\u0302i,t \u2212 \u03b8i| \u2264 \u01eb } ,\nWt =\n{ N(t)\n4\u03b1 log t \u2208 C(\u03b8\u0302t)\n} ,\nYt = { min i\u2208[K] ni(t) < \u03b2(ne(t))/K }\nand U ct , V c t , W c t , Y c t be their complements.\nRT (\u03b8) =\nT\u2211\nt=1\nE [dit(\u03b8)] \u2264 Kdmax(\u03b8) + n\u2211\nt=K+1\nE [dit(\u03b8)]\n= Kdmax(\u03b8) +\nT\u2211\nt=K+1\nE [dit(\u03b8) (I {U ct }+ I {Ut,Wt}+ I {Ut,W ct , Yt}\n+I {Ut,W ct , Y ct , V ct }+ I {Ut,W ct , Y ct , Vt})] . (12)\nThen we will upper bound each quantity in (12) separately.\nBy Hoeffding\u2019s inequality, we have\nPr ( |\u03b8\u0302i,t \u2212 \u03b8i| > \u221a 2\u03b1\u03c32 log t\nni(t)\n) \u2264 2t1\u2212\u03b1 ,\nwhere we use a union bound over all possible ni(t). Then \u2211n\nt=K+1 E [dit(\u03b8)I {U ct }] can be bounded by T\u2211\nt=K+1\nE [dit(\u03b8)I {U ct }] \u2264 dmax(\u03b8) T\u2211\nt=K+1\nPr(U ct ) \u2264 dmax(\u03b8) T\u2211\nt=K+1\n2Kt1\u2212\u03b1 \u2264 2Kdmax(\u03b8) \u03b1\u2212 2 .\n(13)\nNext consider \u2211T\nt=K+1 E [dit(\u03b8)I {Ut,Wt}]. If Ut and Wt hold, first we have\nni1(\u03b8\u0302t) \u2265 8\u03b1\u03c32 log t\nd2 i1(\u03b8\u0302t)\n(\u03b8\u0302t) ,\nand\n\u03b8\u0302i1(\u03b8\u0302t),t \u2212 \u03b8i1(\u03b8\u0302t) \u2264 \u221a 2\u03b1\u03c32 log t\nni1(\u03b8\u0302t)(t) \u2264\ndi1(\u03b8\u0302t)(\u03b8\u0302t)\n2 \u2264 di(\u03b8\u0302t) 2 (14)\nfor any i 6= i1(\u03b8\u0302t). Similarly, for i 6= i1(\u03b8\u0302t) we have\n\u03b8i \u2212 \u03b8\u0302i,t \u2264 \u221a 2\u03b1\u03c32 log t\nni(t) \u2264 di(\u03b8\u0302t) 2 . (15)\nCombining (14) and (15) gives \u03b8i \u2264 \u03b8i1(\u03b8\u0302t) for any i 6= i1(\u03b8\u0302t), which means i1(\u03b8\u0302t) = i1(\u03b8), hence T\u2211\nt=K+1\nE [dit(\u03b8)I {Ut,Wt}] = 0 . (16)\nConsider the next term in (12),\nT\u2211\nt=K+1\nE [dit(\u03b8)I {Ut,W ct , Yt}] \u2264 dmax(\u03b8)E [ T\u2211\nt=K+1\nI {Ut,W ct , Yt} ] . (17)\nTo upper bound (17), we will first prove:\nProposition 16.\nT\u2211\nt=K+1\nI {W ct , Yt} \u2264 1 + \u03b2 ( T\u2211\nt=K+1\nI {W ct } ) . (18)\nProof of (18). According to the algorithm we have ne(t) = \u2211t\u22121\ns=K+1 I {W cs } for t > K , we then proceed by the following proposition: Proposition 17. For K < t1 < t2, if \u2211t2\u22121\ns=t1 I {W cs , Ys} \u2265 K , then mini\u2208[K] ni(t2) \u2265\nmini\u2208[K] ni(t1) + 1.\nProof of Proposition 17. If for such t1 and t2, mini\u2208[K] ni(t2) = mini\u2208[K] ni(t1), then there must exist j such that nj(t1) = nj(t2) and nj(s) = mini\u2208[K] ni(s) for all t1 \u2264 s \u2264 t2. Since\u2211t2\u22121\ns=t1 I {W cs , Ys} \u2265 K , there exist K instants t1 \u2264 s1 < s2 < ... < sK \u2264 t2 \u2212 1 such that{\nW csk , Ysk }\nhappens for 1 \u2264 k \u2264 K . According to the algorithm, for each sk, there exists j\u2032 6= j such that j\u2032 \u2208 Sisk and nj\u2032(sk) = nj(sk) = mini\u2208[K] ni(sk). Note that each action appears at most once as such j\u2032 for 1 \u2264 k \u2264 K since nj\u2032(sk + 1) = nj\u2032 (sk) + 1, but there are only K \u2212 1 actions other than j, which means such j cannot exist. Hence mini\u2208[K] ni(t2) \u2265 mini\u2208[K] ni(t1) + 1 is proved.\nNow we define\nt\u2032 = max {K + 1 \u2264 t \u2264 T : W ct , Yt} . If such t\u2032 does not exist, then (18) must hold. If such t\u2032 exists, by Proposition 17,\nmin i\u2208[K]\nni(t \u2032) \u2265 min\ni\u2208[K] ni(K + 1) +  1 K t\u2032\u22121\u2211\nt=K+1\nI {W ct , Yt}  \u2265 1 K t\u2032\u22121\u2211\nt=K+1\nI {W ct , Yt} .\nTherefore,\nT\u2211\nt=K+1\nI {W ct , Yt} = 1 + t\u2032\u22121\u2211\nt=K+1\nI {W ct , Yt} \u2264 1 +K min i\u2208[K] ni(t \u2032) < 1 + \u03b2(ne(t \u2032))\n\u2264 1 + \u03b2(ne(T )) \u2264 1 + \u03b2 ( T\u2211\nt=K+1\nI {W ct } )\ngives (18).\nNow continue with (17)\nT\u2211\nt=K+1\nI {Ut,W ct , Yt} \u2264 T\u2211\nt=K+1\nI {W ct , Yt} \u2264 1 + \u03b2 ( T\u2211\nt=K+1\nI {W ct } )\n\u2264 1 + \u03b2 ( T\u2211\nt=K+1\nI {U ct }+ I {Ut,W ct , Yt}+ I {Ut,W ct , Y ct , V ct }+ I {Ut,W ct , Y ct , Vt} )\n\u2264 1 + 1 2\nT\u2211\nt=K+1\n(I {U ct }+ I {Ut,W ct , Yt}+ I {Ut,W ct , Y ct , V ct }) + \u03b2 (I {Ut,W ct , Y ct , Vt}) .\nThus we have\nT\u2211\nt=K+1\nI {Ut,W ct , Yt}\n\u2264 2 + T\u2211\nt=K+1\nI {U ct }+ T\u2211\nt=K+1\nI {Ut,W ct , Y ct , V ct }+ 2\u03b2 ( n\u2211\nt=K+1\nI {Ut,W ct , Y ct , Vt} ) ,\nand\nT\u2211\nt=K+1\nE [dit(\u03b8)I {Ut,W ct , Yt}] \u2264 dmax(\u03b8)E [ T\u2211\nt=K+1\nI {Ut,W ct , Yt} ]\n\u2264 2dmax(\u03b8) + 2Kdmax(\u03b8) \u03b1\u2212 2 + dmax(\u03b8) T\u2211\nt=K+1\nE [I {Ut,W ct , Y ct , V ct }]\n+ 2dmax(\u03b8)E\n[ \u03b2 ( n\u2211\nt=K+1\nI {Ut,W ct , Y ct , Vt} )]\n(19)\nby applying (13). To bound \u2211T\nt=K+1 E [I {Ut,W ct , Y ct , V ct }], we first introduce two lemmas from [14] (Lemma 2.1 and 2.2):\nLemma 18. Let {Zt}t\u2208N+ be a sequence of independent random variables from N (0, \u03c32). Define Ft the \u03c3-algebra generated by {Zs}s\u2264t and the filtration F = (Ft)t\u2208N+ . Consider r, n0 \u2208 N+ and T \u2265 n0. Define Yt = \u2211t\u22121 s=n0\nBsZs where Bt \u2208 {0, 1} is an Ft\u22121-measurable random variable. Further define n(t) =\n\u2211t\u22121 s=n0\nBs and \u03c6 an F -stopping time which satisfies either n(\u03c6) \u2265 r or \u03c6 = T + 1.\nThen we have\nPr (|Y\u03c6| > n(\u03c6)\u01eb, \u03c6 \u2264 T ) \u2264 2 exp ( \u2212 r\u01eb 2\n2\u03c32\n) .\nLemma 19. Define Ft the \u03c3-algebra generated by {Xi,s}s\u2208[t],i\u2208[K]. Let \u039b \u2282 [1, T ] \u2229 N be a set of (random) time instants. Assume there exists a sequence of (random) sets {\u039bs}0\u2264s\u2264T such that (i) \u039b \u2282 \u222a0\u2264s\u2264T\u039bs, (ii) for all 0 \u2264 s \u2264 T , |\u039bs| \u2264 1, (iii) for all 0 \u2264 s \u2264 T , if t \u2208 \u039bs then ni(t) \u2265 \u03b2(s)/K , and (iv) the event {t \u2208 \u039bs} is Ft measurable. Then for any \u01eb > 0 and i \u2208 [K]:\nE\n[ T\u2211\nt=1\nI { t \u2208 \u039b, |\u03b8\u0302i,t \u2212 \u03b8i| > \u01eb }] \u2264 T\u2211\ns=0\n2 exp ( \u2212\u03b2(s)\u01eb 2\n2K\u03c32\n) .\nProof of Lemma 19. We adapt the proof of Lemma 2.2 from [14]. For 0 \u2264 s \u2264 T , define \u03c6s = t if \u039bs = {t} or \u03c6s = T + 1 if \u039bs = \u2205. Then\nE\n[ T\u2211\nt=1\nI { t \u2208 \u039b, |\u03b8\u0302i,t \u2212 \u03b8i| > \u01eb }] \u2264 E [ T\u2211\ns=0\nI { \u03c6s \u2264 T, |\u03b8\u0302i,\u03c6s \u2212 \u03b8i| > \u01eb\n}]\n=\nT\u2211\ns=0\nPr ( \u03c6s \u2264 T, |\u03b8\u0302i,\u03c6s \u2212 \u03b8i| > \u01eb ) . (20)\nSince \u03c6s can be viewed as an F -stopping time and satisfies either ni(\u03c6s) \u2265 \u2308\u03b2(s)/K\u2309 or \u03c6s = T + 1, if \u2308\u03b2(s)/K\u2309 \u2265 1 then applying Lemma 18 gives\nPr ( \u03c6s \u2264 T, |\u03b8\u0302i,\u03c6s \u2212 \u03b8i| > \u01eb ) \u2264 2 exp ( \u2212\u2308\u03b2(s)/K\u2309\u01eb 2\n2\u03c32\n) \u2264 2 exp ( \u2212\u03b2(s)\u01eb 2\n2K\u03c32\n) .\nIf \u2308\u03b2(s)/K\u2309 = 0 then Pr ( \u03c6s \u2264 T, |\u03b8\u0302i,\u03c6s \u2212 \u03b8i| > \u01eb ) < 2 = 2 exp ( \u2212\u03b2(s)\u01eb 2\n2K\u03c32\n) still holds. Now\nproceeding from (20) we can get the result of Lemma 19.\nNow we define \u039b = {t : K + 1 \u2264 t \u2264 T, Ut,W ct , Y ct }, and \u039bs = {t : K + 1 \u2264 t \u2264 T, Ut,W c t , ne(t) = s,mini\u2208[K] ni(t) \u2265 \u03b2(s)/K}. It can be verified that \u039bs satisfies the conditions in Lemma 19: (i) If t \u2208 \u039b then there must be some 0 \u2264 s \u2264 T such that ne(t) = s and thus t \u2208 \u039bs. (ii) If t \u2208 \u039bs then for t\u2032 > t, ne(t\u2032) \u2265 ne(t+1) = ne(t)+1 = s+1, so t\u2032 /\u2208 \u039bs. Condition (iii) and (iv) are also satisfied from the definition of \u039bs.\nThen T\u2211\nt=K+1\nE [I {Ut,W ct , Y ct , V ct }] = T\u2211\nt=K+1\nE [I {t \u2208 \u039b, V ct }]\n\u2264 K\u2211\ni=1\nT\u2211\nt=K+1\nE [ I { t \u2208 \u039b, |\u03b8\u0302i,t \u2212 \u03b8i| > \u01eb }] \u2264 2K T\u2211\ns=0\nexp ( \u2212\u03b2(s)\u01eb 2\n2K\u03c32\n) . (21)\nFinally we will upper bound \u2211n\nt=K+1 dit(\u03b8)I {Ut,W ct , Y ct , Vt}.\nRecall that in the algorithm, if W ct and Y c t happens, some it satisfying Ni(t) < ci(\u03b8\u0302t)4\u03b1 log t is played. Such it must exist because otherwise Ni(t) 4\u03b1 log t \u2265 ci(\u03b8\u0302t)4\u03b1 log t holds for any i \u2208 [K] and\nthus Wt = { N(t) 4\u03b1 log t \u2208 C(\u03b8\u0302t) } happens, which causes contradiction.\nDefine\n\u0398(\u03b8, \u01eb) = {\u03bb \u2208 \u0398 : \u2200i \u2208 [K] , |\u03bbi \u2212 \u03b8i| \u2264 \u01eb} , and\nci(\u03b8, \u01eb) = sup \u03bb\u2208\u0398(\u03b8,\u01eb) ci(\u03bb) .\nLet Ti be the maximum t \u2264 T such that it = i and I {Ut,W ct , Y ct , Vt} = 1. Then\nNi(Ti) =\nTi\u22121\u2211\ns=1\nI {is = i} \u2264 ci(\u03b8\u0302Ti)4\u03b1 logTi \u2264 ci(\u03b8, \u01eb)4\u03b1 logT .\nThus T\u2211\nt=K+1\nI {it = i, Ut,W ct , Y ct , Vt} \u2264 ci(\u03b8, \u01eb)4\u03b1 logT + 1 .\nSo we have T\u2211\nt=K+1\ndit(\u03b8)I {Ut,W ct , Y ct , Vt} \u2264 4\u03b1 logT \u2211\ni\u2208[K] ci(\u03b8, \u01eb)di(\u03b8) +\n\u2211\ni\u2208[K] di(\u03b8) , (22)\nand T\u2211\nt=K+1\nI {Ut,W ct , Y ct , Vt} \u2264 4\u03b1 logT \u2211\ni\u2208[K] ci(\u03b8, \u01eb) +K . (23)\nNow plugging (23) (21) into (19) and plugging (13) (16) (19) (21) (22) into (12) we get\nRT (\u03b8) \u2264 ( 2K + 2 + 4K\n\u03b1\u2212 2\n) dmax(\u03b8) + 4Kdmax(\u03b8) T\u2211\ns=0\nexp ( \u2212\u03b2(s)\u01eb 2\n2K\u03c32\n)\n+ 2dmax(\u03b8)\u03b2\n 4\u03b1 logT \u2211\ni\u2208[K] ci(\u03b8, \u01eb) +K\n + 4\u03b1 logT \u2211\ni\u2208[K] ci(\u03b8, \u01eb)di(\u03b8) ."}, {"heading": "C Proofs for Section 4.2", "text": "C.1 Proof of Theorem 8\nProof of Theorem 8. For every r > 0, define the events\nUr = { \u2200i \u2208 [K] , |\u03b8\u0302i,r \u2212 \u03b8i| \u2264 gi,r(\u03b4) } .\nThen, by Hoeffding\u2019s inequality and union bound, we have\nPr(\u2200r \u2265 2, Ur) \u2265 1\u2212 \u03b4 .\nNext we will upper bound the regret based on the fact that Ur holds for all r \u2265 2. Define rT = max{r : tt < T, |Ar| \u2265 2}, the event\nVr = { AWr 6= \u2205, min\ni\u2208AWr ni(r) < min{min i\u2208ASr ni(r), \u03b3(r)}\n}\nand its complement V cr . Then consider the regret:\nRT (\u03b8) \u2264 rT\u2211\nr=1\nI {Vr} \u3008ir, d(\u03b8)\u3009 + rT\u2211\nr=1\nI {V cr } \u3008ir, d(\u03b8)\u3009\n\u2264 rT\u2211\nr=1\nI {Vr} \u2016ir\u20161 D + rT\u2211\nr=1\nI {V cr } \u2016ir\u20161 maxi\u2208Ar di(\u03b8) . (24)\nWe upper bound the two terms in (24) separately. Before proceeding, we introduce the following proposition which lower bounds ni(r) for i \u2208 AWr . Proposition 20. For any i, r such that i \u2208 AWr ,\nni(r) \u2265 \u03b1r\u22121 2\nr\u22121\u2211\ns=1\nI {Vs} \u2016is\u20161 \u2212 (\u03b2r \u2212 1)K , (25)\nwhere \u03b2r = \u2223\u2223\u2223 \u22c3 1\u2264s\u2264r A W s \u2223\u2223\u2223.\nProof of Proposition 20. The proof is done by induction. Let Wr denote the event that for any 1 \u2264 s \u2264 r and any i \u2208 AWs , (25) holds. W1 holds because AW1 = \u2205. Now we assume Wr holds and consider Wr+1.\nIf AWr+1 = \u2205, then Wr+1 holds. If AWr+1 6= \u2205, for i \u2208 AWr+1, consider ni(r + 1) in different cases: If i \u2208 AWr , then ni(r) \u2265 \u03b1r\u221212 \u2211r\u22121\ns=1 I {Vs} \u2016is\u20161 \u2212 (\u03b2r \u2212 1)K . Recall that \u03b1r = min1\u2264s\u2264r,AWs 6=\u2205 m([K] , A W s ). So we have\nni(r + 1) \u2265 ni(r) + I {Vr} \u2016cr\u20160 \u03b1r \u2265 \u03b1r 2\nr\u2211\ns=1\nI {Vs} \u2016is\u20161 \u2212 (\u03b2r+1 \u2212 1)K ,\nwhere we use the fact that \u03b1r is non-increasing, \u03b2r is non-decreasing as well as\n\u2016ir\u20161 = \u2016\u2308cr \u00b7 \u2016cr\u20160\u2309\u20161 \u2264 \u2016cr\u20160 + \u2016cr\u20160 \u00b7 \u2016cr\u20161 = 2 \u2016cr\u20160 . (26)\nIf i /\u2208 AWr , then i \u2208 ASs for all 1 \u2264 s \u2264 r and thus \u03b2r+1 \u2265 \u03b2r + 1. Let r\u2032 = max{s \u2264 r : Vs}. If such r\u2032 does not exist, then\nni(r + 1) \u2265 0 \u2265 \u03b1r 2\nr\u2211\ns=1\nI {Vs} \u2016is\u20161 \u2212 (\u03b2r+1 \u2212 1)K .\nIf such r\u2032 exists\nni(r + 1) \u2265 ni(r\u2032) > min j\u2208AW\nr\u2032 nj(r\n\u2032) \u2265 \u03b1r\u2032\u22121 2\nr\u2032\u22121\u2211\ns=1\nI {Vs} \u2016is\u20161 \u2212 (\u03b2r\u2032 \u2212 1)K\n\u2265 \u03b1r 2\nr\u2211\ns=1\nI {Vs} \u2016is\u20161 \u2212 \u03b1r 2 \u2016ir\u2032\u20161 \u2212 (\u03b2r\u2032 \u2212 1)K \u2265 \u03b1r 2\nr\u2211\ns=1\nI {Vs} \u2016is\u20161 \u2212 \u03b2r\u2032K\n\u2265 \u03b1r 2\nr\u2211\ns=1\nI {Vs} \u2016is\u20161 \u2212 (\u03b2r+1 \u2212 1)K ,\nwhere the facts \u03b1r \u2264 1, \u2016ir\u2032\u20161 \u2264 2K and \u03b2r\u2032 \u2264 \u03b2r+1 \u2212 1 are used. Now we have proved that Wr+1 holds based on the assumption of Wr, hence Wr holds for any r, which gives the result of Proposition 20.\nBased on Proposition 20, \u2211r\ns=1 I {Vs} \u2016is\u20161 can be upper bounded by the following fact:\nProposition 21. For any r \u2265 1, \u2211rs=1 I {Vs} \u2016is\u20161 \u2264 2\u03b3(r)+2K\u03b2r \u03b1r .\nProof of Proposition 21. Let r\u2032 = max{s \u2264 r : Vs}. Then\n\u03b3(r\u2032) > min i\u2208AW\nr\u2032 ni(r\n\u2032) \u2265 \u03b1r\u2032\u22121 2\nr\u2032\u22121\u2211\ns=1\nI {Vs} \u2016is\u20161 \u2212 (\u03b2r\u2032 \u2212 1)K .\nHence r\u2211\ns=1\nI {Vs} \u2016is\u20161 \u2264 r\u2032\u22121\u2211\ns=1\nI {Vs} \u2016is\u20161 + \u2016ir\u2032\u20161 \u2264 2\u03b3(r\u2032) + 2K(\u03b2r\u2032 \u2212 1)\n\u03b1r\u2032 + 2K\n\u2264 2\u03b3(r \u2032) + 2K\u03b2r\u2032\n\u03b1r\u2032 .\nSince \u03b1r is non-increasing, \u03b2r is non-decreasing and \u03b3(r)/\u03b1r = \u03b1 \u22121/3 r (\u03c3tr/D)\n2/3 is nondecreasing, we have \u2211r s=1 I {Vs} \u2016is\u20161 \u2264 2\u03b3(r)+2K\u03b2r \u03b1r .\nNow we are ready to upper bound the first term in (24): rT\u2211\nr=1\nI {Vr} \u2016ir\u20161 D \u2264 2\u03b3(rT ) + 2K\u03b2rT \u03b1rT D = 2\u03b1\u22121/3rT D 1/3(\u03c3T )2/3 + 2KD \u03b2rT \u03b1rT . (27)\nNext consider the second term in (24): \u2211rT\nr=1 I {V cr } \u2016ir\u20161 maxi\u2208Ar di(\u03b8). Given Ur holds for all r we know that i1(\u03b8) is never eliminated. Then for any i \u2208 Ar , we have |\u03b8\u0302i,r \u2212 \u03b8i| \u2264 gi,r(\u03b4) and \u03b8\u0302i,r + gi,r(\u03b4) \u2265 \u03b8\u0302i1(\u03b8) \u2212 gi1(\u03b8),r(\u03b4). Therefore,\ndi(\u03b8) \u2264 min { D, 2gi,r(\u03b4) + 2gi1(\u03b8),r(\u03b4) } \u2264 min { D, 4\u03c3 \u221a 6 log 2KT\n\u03b4 ( min i\u2208Ar ni(r) )\u22121/2} .\nSo rT\u2211\nr=1\nI {V cr } \u2016ir\u20161 maxi\u2208Ar di(\u03b8) \u2264 rT\u2211\nr=1\nI {V cr } \u2016ir\u20161 min { D,C(min\ni\u2208Ar ni(r))\n\u22121/2 }\n, (28)\nwhere C = 4\u03c3 \u221a 6 log 2KT\u03b4 .\nThe next step is to lower bound mini\u2208Ar ni(r) when V c r happens. Define \u03b7min = minA\u2208[K],|A|\u22652 m(A,A S). For i \u2208 ASr ,\nni(r) \u2265 r\u22121\u2211\ns=1\nI {V cs } \u2016cs\u20160 m(As, ASs ) \u2265 \u03b7min 2\nr\u22121\u2211\ns=1\nI {V cs } \u2016is\u20161 . (29)\nFor i \u2208 AWr , since V cr happens and AWr 6= \u2205, we have\nni(r) \u2265 min{min i\u2208ASr ni(r), \u03b3(r)} \u2265 min { \u03b7min 2 r\u22121\u2211\ns=1\nI {V cs } \u2016is\u20161 , \u03b3(r) } .\nBy Proposition 21,\n\u03b7min 2\nr\u22121\u2211\ns=1\nI {V cs } \u2016is\u20161 \u2265 1\n2K\n( tr \u2212 r\u2211\ns=1\nI {Vs} \u2016is\u20161\n) \u2265 1\n2K\n( tr \u2212\n2\u03b3(r) + 2K\u03b2r \u03b1r\n)\n= 1\n2K\n( tr \u2212 2\u03b1\u22121/3r ( \u03c3tr D )2/3 \u2212 2K\u03b2r/\u03b1r )\n\u2265 1 2K tr \u2212 ( \u03c3tr D )2/3 \u2212K2 ,\nwhere we used \u03b1r, \u03b7min \u2265 1/K and \u03b2r \u2264 K .\nFor tr \u2265 125\u03c3 2 D2 K 3 + 10K3, we have 45 tr \u2265 4K ( \u03c3tr D )2/3 and 15 tr \u2265 2K3, so\n\u03b7min 2\nr\u22121\u2211\ns=1\nI {V cs } \u2016is\u20161 \u2265 1\n2K tr \u2212 ( \u03c3tr D )2/3 \u2212K2\n\u2265 2 ( \u03c3tr D )2/3 +K2 \u2212 ( \u03c3tr D )2/3 \u2212K2\n= ( \u03c3tr D )2/3 \u2265 ( \u03c3\u03b1rtr D )2/3 = \u03b3(r) .\nSo we have proved that for any r \u2264 rT such that tr \u2265 T0 = 125\u03c3 2 D2 K 3 + 10K3 and V cr happens, mini\u2208Ar ni(r) \u2265 \u03b3(r) \u2265 (\u03c3\u03b1rT tr/D)2/3. Therefore, following (28) gives rT\u2211\nr=1\nI {V cr } \u2016ir\u20161 maxi\u2208Ar di(\u03b8)\n\u2264 rT\u2211\nr=1\nI {V cr } \u2016ir\u20161 min { D,C(min\ni\u2208Ar ni(r))\n\u22121/2 }\n\u2264 \u2211\nr\u22651:tr<T0 \u2016ir\u20161 D +\n\u2211\nr\u2264rT :tr\u2265T0 \u2016ir\u20161 C\n(\u03c3\u03b1rT D )\u22121/3 t\u22121/3r\n\u2264 (T0 + 2K)D + C (\u03c3\u03b1rT\nD\n)\u22121/3 \u2211\nr\u2264rT :tr\u2265T0 (tr+1 \u2212 tr)(tr+1 \u2212 2K)\u22121/3\n\u2264 (T0 + 2K)D + C (\u03c3\u03b1rT\nD\n)\u22121/3 \u222b trT +1\nT0\n(x\u2212 2K)\u22121/3dx\n\u2264 (T0 + 2K)D + C (\u03c3\u03b1rT\nD )\u22121/3 \u222b trT T0\u22122K x\u22121/3dx\n\u2264 (T0 + 2K)D + 3 2 C (\u03c3\u03b1rT D )\u22121/3 T 2/3\n= 125\u03c32K3\nD + (10K3 + 2K)D + \u03b1\u22121/3rT D\n1/3(\u03c3T )2/3 \u00b7 6 \u221a 6 log 2KT\n\u03b4 . (30)\nNow plugging (27) and (30) into (24) gives\nRT (\u03b8) \u2264 \u03b1\u22121/3rT D1/3(\u03c3T )2/3 \u00b7 7 \u221a 6 log 2KT\n\u03b4 +\n125\u03c32K3\nD + 13K3D .\nIf \u03a3 is strongly observable, then AWr is always empty and V c r always happens. According to (24) (28) and (29) we have\nRT (\u03b8) \u2264 rT\u2211\nr=1\n\u2016ir\u20161 maxi\u2208Ar di(\u03b8)\n\u2264 rT\u2211\nr=1\n(tr+1 \u2212 tr)min { D,C (\u03b7min 2 )\u22121/2 t\u22121/2r }\n\u2264 2KD+ C (\u03b7min\n2 )\u22121/2 \u222b trT 0 x\u22121/2dx\n\u2264 2KD+ 8\u03c3 \u221a T\n\u03b7min \u00b7 12 log 2KT \u03b4 .\nTo finish the proof, it suffices to show that 1\u03b1rT \u2264 \u03c1(\u03a3) and 1\u03b7min \u2264 \u03ba(\u03a3)50 logK , which is based on the following fact:\nProposition 22. For any A,A\u2032 \u2282 [K] Let \u03c1LP(A,A\u2032) denote the minimum fractional cover number from A to A\u2032, that is\n\u03c1LP(A,A \u2032) = min\nb\u2208[0,\u221e)A\n\u2211 i\u2208A bi\ns.t. \u2211\ni:j\u2208Si bi \u2265 1 \u2200j \u2208 A\u2032 .\nThen m(A,A\u2032) = 1\u03c1LP(A,A\u2032) .\nProof of Proposition 22. Recall that\nm(A,A\u2032) = max c\u2208\u2206A min i\u2208A\u2032\n\u2211\nj:i\u2208Sj cj\n= max c\u2208\u2206A,a\na s.t. \u2211\ni:j\u2208Si ci \u2265 a \u2200j \u2208 A\u2032 .\nLet b = c/a, then\nm(A,A\u2032) = max b\u2208[0,\u221e)A,a\na s.t. \u2211\ni:j\u2208Si bi \u2265 1 \u2200j \u2208 A\u2032 and\n\u2211 i\u2208A bi = 1 a\n= max b\u2208[0,\u221e)A 1\u2211 i\u2208A bi\ns.t. \u2211\ni:j\u2208Si bi \u2265 1 \u2200j \u2208 A\u2032\n= 1\n\u03c1LP(A,A\u2032) .\nTo lower bound \u03b1rT , let \u03c1(A,A \u2032) be the integer version of \u03c1LP(A,A\u2032) by restricting b \u2208 NA. Then we have \u03c1(\u03a3) = \u03c1([K] ,W(\u03a3)) and\n\u03b1rT \u2265 m([K] ,W(\u03a3)) = 1 \u03c1LP([K] ,W(\u03a3)) \u2265 1 \u03c1(\u03a3) ,\nwhere we used the fact that AWr \u2282 W(\u03a3) for any r \u2264 rT . To lower bound \u03b7min, we use\n\u03b7min = min A\u2208[K],|A|\u22652 m(A,AS) = min A\u2208[K],|A|\u22652 m(A,A) = 1\nmaxA\u2208[K],|A|\u22652 \u03c1LP(A,A)\n(AS = A for strongly observable \u03a3), thus\nmax A\u2208[K],|A|\u22652 \u03c1(A,A) \u2265 1 \u03b7min .\nFor any A \u2208 [K] , |A| \u2265 2, let \u03a3A be the subgraph of \u03a3 on A. We apply Lemma 15 on \u03a3A with the subset W = A. Then the lemma states that A contains an independent set U of size at least \u03c1(A,A) 50 log |A| . Since an independent set of \u03a3A is also an independent set of \u03a3, for each subset A there exists an independent set of \u03a3 with size at least \u03c1(A,A)50 log |A| . So the independence number\n\u03ba(\u03a3) \u2265 max A\u2208[K],|A|\u22652\n\u03c1(A,A) 50 log |A| \u2265 1 50 logK max A\u2208[K],|A|\u22652 \u03c1(A,A) \u2265 1 \u03b7min50 logK ,\nwhich indicates 1\u03b7min \u2264 \u03ba(\u03a3)50 logK .\nC.2 Proof of Theorem 9\nProof of Theorem 9. Similarly to the proof of Theorem 9, we define high probability events\nUr = { \u2200i \u2208 [K] , |\u03b8\u0302i,r \u2212 \u03b8i| \u2264 gi,r(\u03b4) } .\nand upper bound the regret based on the fact that for all r \u2265 2, Ur holds. The rest of the proof will be based on upper bounding the number of round before all sub-optimal actions are eliminated.\nDefine rT = max{r : tt < T, |Ar| \u2265 2}, event\nVr = { AWr 6= \u2205, min\ni\u2208AWr ni(r) < min{min i\u2208ASr ni(r), \u03b3(r)}\n}\nand V cr be its complement.\nFor any r \u2264 rT and any i \u2208 Ar, i 6= i1(\u03b8), we have 2gi,r(\u03b4) + 2gi1(\u03b8),r(\u03b4) \u2265 di(\u03b8) \u2265 dmin(\u03b8), where dmin(\u03b8) denotes di2(\u03b8)(\u03b8). From gi,r(\u03b4) = \u03c3 \u221a 2 log(8K2r3/\u03b4) ni(r) we get\ndmin(\u03b8) \u2264 2\u03c3 \u221a 2 log(8K2r3/\u03b4) ( 1\u221a ni(r) + 1\u221a ni1(\u03b8)(r) ) \u2264 Cr ( min i\u2208Ar ni(r) )\u22121/2 ,\nwhere Cr = 4\u03c3 \u221a 6 log 2Kr\u03b4 , and thus\nmin i\u2208Ar\nni(r) \u2264 C2r\nd2min(\u03b8) . (31)\nThen consider the regret:\nRT (\u03b8) \u2264 rT\u2211\nr=1\nI {Vr} \u3008ir, d(\u03b8)\u3009+ rT\u2211\nr=1\nI {V cr } \u3008ir, d(\u03b8)\u3009\n\u2264 rV\u2211\nr=1\nI {Vr} \u2016ir\u20161 dmax(\u03b8) + rW\u2211\nr=1\nI {V cr } \u2016ir\u20161 maxi\u2208Ar di(\u03b8) . (32)\nwhere rV = max{r \u2264 rT : Vr} and rW = max{r \u2264 rT : V cr }. Since mini\u2208AWrV ni(rV ) < mini\u2208ASrV ni(rV ) we have\nmin i\u2208ArV ni(rV ) = min i\u2208AWrV\nni(rV ) \u2265 1\n2\u03c1(\u03a3)\nrV \u22121\u2211\ns=1\nI {Vs} \u2016is\u20161 \u2212K2\nby applying Proposition 20. Then we can upper bound the first term in (32) by rV\u2211\nr=1\nI {Vr} \u2016ir\u20161 \u2264 2\u03c1(\u03a3)C2rV d2min(\u03b8) + 2\u03c1(\u03a3)K2 + 2K . (33)\nRegarding the second term in (32), recall that for any r \u2264 rT such that tr \u2265 T0 = 125\u03c3 2 D2 K 3+10K3 and V cr happens, mini\u2208Ar ni(r) \u2265 \u03b3(r) \u2265 (\u03c3\u03b1rT tr/D)2/3 \u2265 ( \u03c3tr \u03c1(\u03a3)D )2/3 . Using the fact that maxi\u2208Ar di(\u03b8) \u2264 min { dmax(\u03b8), Cr (mini\u2208Ar ni(r)) \u22121/2 } gives\nrW\u2211\nr=1\nI {V cr } \u2016ir\u20161 maxi\u2208Ar di(\u03b8)\n\u2264 rW\u2211\nr=1\nI {V cr } \u2016ir\u20161 min { dmax(\u03b8), Cr(min\ni\u2208Ar ni(r))\n\u22121/2 }\n\u2264 \u2211\nr\u22651:tr<T0 \u2016ir\u20161 dmax(\u03b8) +\n\u2211\nr\u2264rW :tr\u2265T0 \u2016ir\u20161 CrW\n( \u03c3\n\u03c1(\u03a3)D\n)\u22121/3 t\u22121/3r\n\u2264 (T0 + 2K)dmax(\u03b8) + CrW ( \u03c3\n\u03c1(\u03a3)D\n)\u22121/3 \u2211\nr\u2264rW :tr\u2265T0 (tr+1 \u2212 tr)(tr+1 \u2212 2K)\u22121/3\n\u2264 (T0 + 2K)dmax(\u03b8) + CrW ( \u03c3\n\u03c1(\u03a3)D\n)\u22121/3 \u222b trW +1\nT0\n(x\u2212 2K)\u22121/3dx\n\u2264 (T0 + 2K)dmax(\u03b8) + CrW ( \u03c3\n\u03c1(\u03a3)D )\u22121/3 \u222b trW T0\u22122K x\u22121/3dx\n\u2264 (T0 + 2K)dmax(\u03b8) + 3\n2 CrW\n( \u03c3\n\u03c1(\u03a3)D\n)\u22121/3 t2/3rW . (34)\nNow we upper bound trW . If trW \u2265 T0 then C2rW\nd2min(\u03b8) \u2265 mini\u2208ArW ni(rW ) \u2265 ( \u03c3trW \u03c1(\u03a3)D )2/3 . Hence\nt2/3rW \u2264 ( \u03c3\n\u03c1(\u03a3)D )\u22122/3 C2rW d2min(\u03b8) + T 2/3 0 . (35)\nCombining (32) (33) (34) and (35) with CrW \u2264 CrT gives\nRT (\u03b8) \u2264 1603\u03c1(\u03a3)D\u03c32\nd2min(\u03b8)\n( log\n2KrT \u03b4\n)3/2 + 14K3D + 125\u03c32K3\nD\n+ 15 ( \u03c1(\u03a3)D\u03c32\n)1/3 ( 125\u03c32\nD2 + 10\n) K2 ( log\n2KrT \u03b4\n)1/2 . (36)\nApplying rT \u2264 T gives the result of Theorem 9. Note that using rT \u2264 T here is only for simplicity, actually rT can be upper bounded by some constant by more careful analysis. This is because, according to Proposition 21, \u2211rT s=1 I {Vs} \u2016is\u20161 =\nO ( t 2/3 rT ) , and trW = O ( (log trT ) 3/2 ) , we have\ntrT \u2264 trW + rT\u2211\ns=1\nI {Vs} \u2016is\u20161 = O ( t2/3rT ) +O ( (log trT ) 3/2 ) ,\nwhich mean trT must be upper bounded by some constant independent with T ."}], "references": [{"title": "Regret analysis of stochastic and nonstochastic multi-armed bandit problems", "author": ["S. Bubeck", "N. Cesa-Bianchi"], "venue": "Foundations and Trends in Machine Learning, 5(1):1\u2013122,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "From bandits to experts: on the value of side-observations", "author": ["S. Mannor", "O. Shamir"], "venue": "Advances in Neural Information Processing Systems 24 (NIPS), pages 684\u2013692,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Online learning with feedback graphs: beyond bandits", "author": ["Noga Alon", "Nicol\u00f2 Cesa-Bianchi", "Ofer Dekel", "Tomer Koren"], "venue": "In Proceedings of The 28th Conference on Learning Theory (COLT),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Leveraging side observations in stochastic bandits", "author": ["St\u00e9phane Caron", "Branislav Kveton", "Marc Lelarge", "Smriti Bhagat"], "venue": "In Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Stochastic bandits with side observations on networks", "author": ["Swapna Buccapatnam", "Atilla Eryilmaz", "Ness B. Shroff"], "venue": "SIGMETRICS Perform. Eval. Rev.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Prediction, Learning, and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": "Cambridge University Press, Cambridge,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Partial monitoring \u2013 classification, regret bounds, and algorithms", "author": ["G. Bart\u00f3k", "D. Foster", "D. P\u00e1l", "A. Rakhlin", "Cs. Szepesv\u00e1ri"], "venue": "Mathematics of Operations Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Asymptotically efficient adaptive choice of control laws incontrolled markov chains", "author": ["Todd L Graves", "Tze Leung Lai"], "venue": "SIAM Journal on Control and Optimization,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1997}, {"title": "Toward minimax off-policy value estimation", "author": ["Lihong Li", "R\u00e9mi Munos", "Csaba Szepesv\u00e1ri"], "venue": "In Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Lipschitz bandits: Regret lower bounds and optimal algorithms", "author": ["Stefan Magureanu", "Richard Combes", "Alexandre Proutiere"], "venue": "In Proceedings of The 27th Conference on Learning Theory (COLT),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "On the complexity of best arm identification in multi-armed bandit models", "author": ["E. Kaufmann", "O. Capp\u00e9", "A. Garivier"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "A popular setup is the case of bandit feedback, where the learner only observes its own payoff and receives no information about the payoff of other actions [1].", "startOffset": 157, "endOffset": 160}, {"referenceID": 1, "context": "This problem, motivated for example by social networks, has been studied extensively in both the adversarial [2, 3, 4, 5] and the stochastic cases [6, 7].", "startOffset": 109, "endOffset": 121}, {"referenceID": 2, "context": "This problem, motivated for example by social networks, has been studied extensively in both the adversarial [2, 3, 4, 5] and the stochastic cases [6, 7].", "startOffset": 109, "endOffset": 121}, {"referenceID": 3, "context": "This problem, motivated for example by social networks, has been studied extensively in both the adversarial [2, 3, 4, 5] and the stochastic cases [6, 7].", "startOffset": 147, "endOffset": 153}, {"referenceID": 4, "context": "This problem, motivated for example by social networks, has been studied extensively in both the adversarial [2, 3, 4, 5] and the stochastic cases [6, 7].", "startOffset": 147, "endOffset": 153}, {"referenceID": 2, "context": "Removing this self-loop assumption leads to the so-called partial monitoring case [5].", "startOffset": 82, "endOffset": 85}, {"referenceID": 5, "context": "In the absolutely general partial monitoring setup the learner receives some general feedback that depends on its choice (and the environment), with some arbitrary (but known) dependence [8, 9].", "startOffset": 187, "endOffset": 193}, {"referenceID": 6, "context": "In the absolutely general partial monitoring setup the learner receives some general feedback that depends on its choice (and the environment), with some arbitrary (but known) dependence [8, 9].", "startOffset": 187, "endOffset": 193}, {"referenceID": 5, "context": "While the partial monitoring setup covers all other problems, its analysis has concentrated on the finite case where both the set of actions and the set of feedback signals are finite [8, 9], which is in contrast to the standard full information and bandit settings where the feedback is typically assumed to be real-valued.", "startOffset": 184, "endOffset": 190}, {"referenceID": 6, "context": "While the partial monitoring setup covers all other problems, its analysis has concentrated on the finite case where both the set of actions and the set of feedback signals are finite [8, 9], which is in contrast to the standard full information and bandit settings where the feedback is typically assumed to be real-valued.", "startOffset": 184, "endOffset": 190}, {"referenceID": 2, "context": "The only exception to this case is the work of [5], which considers graph-structured feedback without the self-loop assumption.", "startOffset": 47, "endOffset": 50}, {"referenceID": 7, "context": ", [10, 7]), or finite-time minimax bounds (e.", "startOffset": 2, "endOffset": 9}, {"referenceID": 4, "context": ", [10, 7]), or finite-time minimax bounds (e.", "startOffset": 2, "endOffset": 9}, {"referenceID": 6, "context": ", [9, 3, 5]).", "startOffset": 2, "endOffset": 11}, {"referenceID": 2, "context": ", [9, 3, 5]).", "startOffset": 2, "endOffset": 11}, {"referenceID": 6, "context": "Regarding the minimax regret, the hardness (\u0398\u0303(T ) or \u0398\u0303(T ) regret) of partial monitoring problems is characterized by their global/local observability property [9] or, in case of the graph-structured feedback model, by their strong/weak observability property [5].", "startOffset": 162, "endOffset": 165}, {"referenceID": 2, "context": "Regarding the minimax regret, the hardness (\u0398\u0303(T ) or \u0398\u0303(T ) regret) of partial monitoring problems is characterized by their global/local observability property [9] or, in case of the graph-structured feedback model, by their strong/weak observability property [5].", "startOffset": 262, "endOffset": 265}, {"referenceID": 3, "context": "Earlier results for the stochastic graph-structured feedback problems [6, 7] provided only asymptotic problem-dependent lower bounds and performance bounds that did not match the asymptotic lower bounds or the minimax rate up to constant factors.", "startOffset": 70, "endOffset": 76}, {"referenceID": 4, "context": "Earlier results for the stochastic graph-structured feedback problems [6, 7] provided only asymptotic problem-dependent lower bounds and performance bounds that did not match the asymptotic lower bounds or the minimax rate up to constant factors.", "startOffset": 70, "endOffset": 76}, {"referenceID": 2, "context": "Partial monitoring with feedback graphs [5]: Each action i \u2208 [K] is associated with an observation set Si \u2282 [K] such that \u03c3ij = \u03c3j if j \u2208 Si and \u03c3ij = \u221e otherwise.", "startOffset": 40, "endOffset": 43}, {"referenceID": 7, "context": "When deriving asymptotic lower bounds, this is circumvented by only considering consistent algorithms whose regret is sub-polynomial for any problem [10].", "startOffset": 149, "endOffset": 153}, {"referenceID": 8, "context": "Therefore, following [11], for any problem we create a family of related problems (by perturbing the mean payoffs) such that if the regret of an algorithm is \u201ctoo small\u201d in one of the problems than it will be \u201clarge\u201d in another one.", "startOffset": 21, "endOffset": 25}, {"referenceID": 7, "context": "The result presented below is an easy consequence of [10], hence its proof is omitted.", "startOffset": 53, "endOffset": 57}, {"referenceID": 3, "context": "Similar bounds have been provided in [6, 7] for graph-structured feedback with self-observability (under non-Gaussian assumptions on the payoffs).", "startOffset": 37, "endOffset": 43}, {"referenceID": 4, "context": "Similar bounds have been provided in [6, 7] for graph-structured feedback with self-observability (under non-Gaussian assumptions on the payoffs).", "startOffset": 37, "endOffset": 43}, {"referenceID": 1, "context": "3 Comparison to Minimax Bounds Now we will show that our \u03b8-dependent finite-time lower bound reproduces the minimax regret bounds of [2] and [5], except for the generalized full information case.", "startOffset": 133, "endOffset": 136}, {"referenceID": 2, "context": "3 Comparison to Minimax Bounds Now we will show that our \u03b8-dependent finite-time lower bound reproduces the minimax regret bounds of [2] and [5], except for the generalized full information case.", "startOffset": 141, "endOffset": 144}, {"referenceID": 1, "context": "Next we will define two key qualities introduced by [2] and [5] that characterize the hardness of a problem instance with feedback structure \u03a3: A set A \u2282 [K] is called an independent set if for any i \u2208 A, Si \u2229 A \u2282 {i}.", "startOffset": 52, "endOffset": 55}, {"referenceID": 2, "context": "Next we will define two key qualities introduced by [2] and [5] that characterize the hardness of a problem instance with feedback structure \u03a3: A set A \u2282 [K] is called an independent set if for any i \u2208 A, Si \u2229 A \u2282 {i}.", "startOffset": 60, "endOffset": 63}, {"referenceID": 9, "context": "The main idea, coming from [12], is that by forcing exploration over all actions the solution c(\u03b8) of the linear program can be well approximated while", "startOffset": 27, "endOffset": 31}, {"referenceID": 9, "context": "One advantage of our algorithm compared to that of [12] is that we use a sublinear exploration schedule \u03b2(n) instead of a constant rate \u03b2(n) = \u03b2n.", "startOffset": 51, "endOffset": 55}, {"referenceID": 9, "context": "This resolves the problem that, to achieve asymptotically optimal performance, some parameter of the algorithm needs to be chosen according to dmin(\u03b8) as in [12].", "startOffset": 157, "endOffset": 161}, {"referenceID": 3, "context": "Also note that the algorithms presented in [6, 7] do not achieve this asymptotic bound.", "startOffset": 43, "endOffset": 49}, {"referenceID": 4, "context": "Also note that the algorithms presented in [6, 7] do not achieve this asymptotic bound.", "startOffset": 43, "endOffset": 49}, {"referenceID": 4, "context": "Note that Algortihm 2 is similar to the UCB-LP algorithm of [7], which admits a better problem-dependent upper bound (although does not achieve it with optimal problem-dependent constants), but it does not achieve the minimax bound even under strong observability.", "startOffset": 60, "endOffset": 63}, {"referenceID": 0, "context": "References [1] S.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[5] Noga Alon, Nicol\u00f2 Cesa-Bianchi, Ofer Dekel, and Tomer Koren.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[6] St\u00e9phane Caron, Branislav Kveton, Marc Lelarge, and Smriti Bhagat.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[7] Swapna Buccapatnam, Atilla Eryilmaz, and Ness B.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[8] N.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[9] G.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[10] Todd L Graves and Tze Leung Lai.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[11] Lihong Li, R\u00e9mi Munos, and Csaba Szepesv\u00e1ri.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[12] Stefan Magureanu, Richard Combes, and Alexandre Proutiere.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[13] E.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "where for x, y \u2208 [0, 1], KL(x, y) = x log(x/y) + (1 \u2212 x) log((1 \u2212 x)/(1 \u2212 y)) denotes the binary KL-divergence.", "startOffset": 17, "endOffset": 23}, {"referenceID": 2, "context": "The idea of constructing the worst \u03b8 comes from the proof of Theorem 7 in [5] which based on the following graph-theoretic lemma: Lemma 15 (Restated from Lemma 8 in [5]).", "startOffset": 74, "endOffset": 77}, {"referenceID": 2, "context": "The idea of constructing the worst \u03b8 comes from the proof of Theorem 7 in [5] which based on the following graph-theoretic lemma: Lemma 15 (Restated from Lemma 8 in [5]).", "startOffset": 165, "endOffset": 168}], "year": 2015, "abstractText": "We consider a sequential learning problem with Gaussian payoffs and side information: after selecting an action i, the learner receives information about the payoff of every action j in the form of Gaussian observations whose mean is the same as the mean payoff, but the variance depends on the pair (i, j) (and may be infinite). The setup allows a more refined information transfer from one action to another than previous partial monitoring setups, including the recently introduced graph-structured feedback case. For the first time in the literature, we provide non-asymptotic problem-dependent lower bounds on the regret of any algorithm, which recover existing asymptotic problem-dependent lower bounds and finitetime minimax lower bounds available in the literature. We also provide algorithms that achieve the problem-dependent lower bound (up to some universal constant factor) or the minimax lower bounds (up to logarithmic factors).", "creator": "LaTeX with hyperref package"}}}