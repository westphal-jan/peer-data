{"id": "1511.05706", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Nov-2015", "title": "Efficient Output Kernel Learning for Multiple Tasks", "abstract": "hondas The paradigm of 2,368 multi - giuffrida task learning sideroxylon is that treasury one kazuyoshi can achieve better succi generalization by learning tasks jointly and aiquile thus maldacena exploiting the umberger similarity parmley between the vi\u00f1ales tasks 3600 rather party-led than learning them 76-51 independently of each khasru other. procreating While previously qrm the relationship nantie between anarcho-punk tasks had to fundamentally be 117.98 user - defined in the left-back form \u0142\u00f3dzki of moguls an ayumu output langenlonsheim kernel, 16:13 recent approaches latveria jointly adelson learn seasonally the rossy tasks vlaams and ous the output sinig kernel. As gokal the ellyn output kernel is latifi a midtown positive lipis semidefinite matrix, the resulting brentford optimization problems semi-deserts are not 1.085 scalable in cubbins the number mini-buses of tasks as abolhassan an eigendecomposition officiis is couse required in brunetto each locates step. \\ conscienceless mbox {Using} kottak the 1.92-meter theory four-barrel of positive authenticator semidefinite kernels 1995-6 we 467th show in this ville paper bough that for a kadidal certain p.o.d. class d'estaing of regularizers on the thil output kernel, the constraint cassandre of gabi being pairings positive semidefinite home.html can chac\u00f3n be dropped as heteromyidae it bruguiere is automatically satisfied for the ----------- relaxed godai problem. vasilieva This enoggera leads inns to kimia an missillier unconstrained dual re-structuring problem which can voina be atsayev solved mungan efficiently. vgp Experiments on several thereunto multi - saraswats task heusner and multi - class data sets illustrate the sarayu efficacy extensor of jump-start our hurrah approach in terms of shivalik computational anglia efficiency watchung as well bridgeman as generalization performance.", "histories": [["v1", "Wed, 18 Nov 2015 09:37:54 GMT  (1613kb,D)", "http://arxiv.org/abs/1511.05706v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["pratik jawanpuria", "maksim lapin", "matthias hein 0001", "bernt schiele"], "accepted": true, "id": "1511.05706"}, "pdf": {"name": "1511.05706.pdf", "metadata": {"source": "CRF", "title": "Efficient Output Kernel Learning for Multiple Tasks", "authors": ["Pratik Jawanpuria", "Maksim Lapin", "Bernt Schiele"], "emails": [], "sections": [{"heading": null, "text": "The paradigm of multi-task learning is that one can achieve better generalization by learning tasks jointly and thus exploiting the similarity between the tasks rather than learning them independently of each other. While previously the relationship between tasks had to be user-defined in the form of an output kernel, recent approaches jointly learn the tasks and the output kernel. As the output kernel is a positive semidefinite matrix, the resulting optimization problems are not scalable in the number of tasks as an eigendecomposition is required in each step. Using the theory of positive semidefinite kernels we show in this paper that for a certain class of regularizers on the output kernel, the constraint of being positive semidefinite can be dropped as it is automatically satisfied for the relaxed problem. This leads to an unconstrained dual problem which can be solved efficiently. Experiments on several multi-task and multi-class data sets illustrate the efficacy of our approach in terms of computational efficiency as well as generalization performance."}, {"heading": "1 Introduction", "text": "Multi-task learning (MTL) advocates sharing relevant information among several related tasks during the training stage. The advantage of MTL over learning tasks independently has been shown theoretically as well as empirically [1, 2, 3, 4, 5, 6, 7].\nThe focus of this paper is the question how the task relationships can be inferred from the data. It has been noted that naively grouping all the tasks together may be detrimental [8, 9, 10, 11]. In particular, outlier tasks may lead to worse performance. Hence, clustered multi-task learning algorithms [10, 12] aim to learn groups of closely related tasks. The information is then shared only within these clusters of tasks. This corresponds to learning the task covariance matrix, which we denote as the output kernel in this paper. Most of these approaches lead to non-convex problems.\nIn this work, we focus on the problem of directly learning the output kernel in the multi-task learning framework. The multi-task kernel on input and output is assumed to be decoupled as the product of a scalar kernel and the output kernel, which is a positive semidefinite matrix [1, 13, 14, 15]. In classical multi-task learning algorithms [1, 16], the degree of relatedness between distinct tasks is set to a constant and is optimized as a hyperparameter. However, constant similarity between tasks is a strong assumption and is unlikely to hold in practice. Thus recent approaches have tackled the problem of directly learning the output kernel. [17] solves a multi-task formulation in the framework of vector-valued reproducing kernel Hilbert spaces involving squared loss where they penalize the Frobenius norm of the output kernel as a regularizer. They formulate an invex optimization problem that they solve optimally. In comparison, [18] recently proposed an efficient barrier method to optimize a generic convex output kernel learning formulation. On the other hand, [9] proposes a convex formulation to learn low rank output kernel matrix by enforcing a trace constraint. The above approaches [9, 17, 18] solve the resulting optimization problem via alternate minimization between task parameters and the output kernel. Each step of the alternate minimization requires an eigen-\nar X\niv :1\n51 1.\n05 70\n6v 1\n[ st\nat .M\nL ]\n1 8\nN ov\n2 01\nvalue decomposition of a matrix having as size the number of tasks and a problem corresponding to learning all tasks independently.\nIn this paper we study a similar formulation as [17]. However, we allow arbitrary convex loss functions and employ general p-norms for p \u2208 (1, 2] (including the Frobenius norm) as regularizer for the output kernel. Our problem is jointly convex over the task parameters and the output kernel. Small p leads to sparse output kernels which allows for an easier interpretation of the learned task relationships in the output kernel. Under certain conditions on p we show that one can drop the constraint that the output kernel should be positive definite as it is automatically satisfied for the unconstrained problem. This significantly simplifies the optimization and our result could also be of interest in other areas where one optimizes over the cone of positive definite matrices. The resulting unconstrained dual problem is amenable to efficient optimization methods such as stochastic dual coordinate ascent [19], which scale well to large data sets. Overall we do not require any eigenvalue decomposition operation at any stage of our algorithm and no alternate minimization is necessary, leading to a highly efficient methodology. Furthermore, we show that this trick not only applies to p-norms but also applies to a large class of regularizers for which we provide a characterization.\nOur contributions are as follows: (a) we propose a generic p-norm regularized output kernel matrix learning formulation, which can be extended to a large class of regularizers; (b) we show that the constraint on the output kernel to be positive definite can be dropped as it is automatically satisfied, leading to an unconstrained dual problem; (c) we propose an efficient stochastic dual coordinate ascent based method for solving the dual formulation; (d) we empirically demonstrate the superiority of our approach in terms of generalization performance as well as significant reduction in training time compared to other methods learning the output kernel.\nThe paper is organized as follows. We introduce our formulation in Section 2. Our main technical result is discussed in Section 3. The proposed optimization algorithm is described in Section 4. In Section 5, we report the empirical results."}, {"heading": "2 The Output Kernel Learning Formulation", "text": "We first introduce the setting considered in this paper. We denote the number of tasks by T . We assume that all tasks have a common input space X and a common positive definite kernel function k : X \u00d7 X \u2192 R. We denote by \u03c8(\u00b7) the feature map and by Hk the reproducing kernel Hilbert space (RKHS) [20] associated with k. The training data is (xi, yi, ti)ni=1, where xi \u2208 X , ti is the task the i-th instance belongs to and yi is the corresponding label. Moreover, we have a positive definite matrix \u0398 \u2208 ST+ on the set of tasks {1, . . . , T}, where ST+ is the set of T \u00d7 T symmetric and positive semidefinite (p.s.d.) matrices.\nIf one arranges the predictions of all tasks in a vector one can see multi-task learning as learning a vector-valued function in a RKHS [see 1, 13, 14, 15, 18, and references therein]. However, in this paper we use the one-to-one correspondence between real-valued and matrix-valued kernels, see [21], in order to limit the technical overhead. In this framework we define the joint kernel of input space and the set of tasks M : (X \u00d7 {1, . . . , T})\u00d7 (X \u00d7 {1, . . . , T})\u2192 R as\nM ( (x, s), (z, t) ) = k(x, z)\u0398(s, t), (1)\nWe denote the corresponding RKHS of functions on X \u00d7 {1, . . . , T} as HM and by \u2016\u00b7\u2016HM the corresponding norm. We formulate the output kernel learning problem for multiple tasks as\nmin \u0398\u2208ST+ ,F\u2208HM C n\u2211 i=1 L ( yi, F (xi, ti) ) + 1 2 \u2016F\u20162HM + \u03bbV (\u0398) (2)\nwhere L : R \u00d7 R \u2192 R is the convex loss function (convex in the second argument), V (\u0398) is a convex regularizer penalizing the complexity of the output kernel \u0398 and \u03bb \u2208 R+ is the regularization parameter. Note that \u2016F\u20162HM implicitly depends also on \u0398. In the following we show that (2) can be reformulated into a jointly convex problem in the parameters of the prediction function and the output kernel \u0398. In order to see this we first need the following representer theorem for fixed output kernel \u0398.\nLemma 1 The optimal solution F \u2217 \u2208 HM of the optimization problem\nmin F\u2208HM C n\u2211 i=1 L ( yi, F (xi, ti) ) + 1 2 \u2016F\u20162HM (3)\nadmits a representation of the form\nF \u2217(x, t) = T\u2211 s=1 n\u2211 i=1 \u03b3isM ( (xi, s), (x, t) ) = T\u2211 s=1 n\u2211 i=1 \u03b3isk(xi, x)\u0398(s, t),\nwhere F \u2217(x, t) is the prediction for instance x belonging to task t and \u03b3 \u2208 Rn\u00d7T .\nProof: The proof is analogous to the standard representer theorem [20]. We denote by U = Span(M((xi, s), (\u00b7, \u00b7)) | i = 1, . . . , n, s = 1, . . . , T ) the subspace in HM spanned by the training data. This induces the orthogonal decomposition of HM = U \u2295 U\u22a5, where U\u22a5 is the orthogonal subpace of U . Every function F \u2208 HM can correspondingly decomposed into F = F \u2016 + F\u22a5, where F \u2016 \u2208 U and F\u22a5 \u2208 U\u22a5. Then \u2016F\u20162HM = \u2225\u2225F \u2016\u2225\u22252 HM + \u2225\u2225F\u22a5\u2225\u22252 HM . As\nF (xi, ti) = \u3008F,M((xi, ti), (\u00b7, \u00b7))\u3009 = \u2329 F \u2016,M((xi, ti), (\u00b7, \u00b7)) \u232a = F \u2016(xi, ti). (4)\nAs the loss only depends on F \u2016 and we minimize the objective by having \u2225\u2225F\u22a5\u2225\u2225\nHM = 0. This\nyields the result.\nWith the explicit form of the prediction function one can rewrite the main problem (2) as\nmin \u0398\u2208ST+ ,\u03b3\u2208Rn\u00d7T C n\u2211 i=1 L ( yi, T\u2211 s=1 n\u2211 j=1 \u03b3jskji\u0398s ti ) + 1 2 T\u2211 r,s=1 n\u2211 i,j=1 \u03b3ir\u03b3jskij\u0398rs + \u03bbV (\u0398), (5)\nwhere \u0398rs = \u0398(r, s) and kij = k(xi, xj). Unfortunately, problem (5) is not jointly convex in \u0398 and \u03b3 due to the product in the second term. A similar problem has been analyzed in [17]. They could show that for the squared loss and V (\u0398) = \u2016\u0398\u20162F the corresponding optimization problem is invex and directly optimize it. For an invex function every stationary point is globally optimal [22].\nWe follow a different path which leads to a formulation similar to the one of [2] used for learning an input mapping (see also [9]). Our formulation for the output kernel learning problem is jointly convex in the task kernel \u0398 and the task parameters. We present a derivation for the general RKHS Hk, analogous to the linear case presented in [2, 9]. We use the following variable transformation,\n\u03b2it = T\u2211 s=1 \u0398ts\u03b3is, i = 1, . . . , n, s = 1, . . . , T, resp. \u03b3is = T\u2211 t=1 ( \u0398\u22121 ) st \u03b2it.\nIn the last expression \u0398\u22121 has to be understood as the pseudo-inverse if \u0398 is not invertible. Note that this causes no problems as in case \u0398 is not invertible, we can without loss of generality restrict \u03b3 in (5) to the range of \u0398. The transformation leads to our final problem formulation, where the prediction function F and its squared norm \u2016F\u20162HM can be written as\nF (x, t) = n\u2211 i=1 \u03b2itk(xi, x), \u2016F\u20162HM = T\u2211 r,s=1 n\u2211 i,j=1 ( \u0398\u22121 ) sr \u03b2is\u03b2jrk(xi, xj). (6)\nThis can be seen as follows\n\u2016F\u20162HM = T\u2211\nr,s=1 n\u2211 i,j=1 \u03b3ir\u03b3jsk(xi, xj)\u0398rs (7)\n= T\u2211 t,u=1 T\u2211 r,s=1 n\u2211 i,j=1 \u03b2it\u03b2ju ( \u0398\u22121 ) tr ( \u0398\u22121 ) us k(xi, xj)\u0398rs (8)\n= T\u2211 t,u=1 n\u2211 i,j=1 ( \u0398\u22121 ) tu \u03b2it\u03b2juk(xi, xj). (9)\nWe get our final primal optimization problem\nmin \u0398\u2208ST+ ,\u03b2\u2208Rn\u00d7T C n\u2211 i=1 L ( yi, n\u2211 j=1 \u03b2jtikji ) + 1 2 T\u2211 r,s=1 n\u2211 i,j=1 ( \u0398\u22121 ) sr \u03b2is\u03b2jrkij + \u03bbV (\u0398) (10)\nBefore we analyze the convexity of this problem, we want to illustrate the connection to the formulations in [9, 17]. With the task weight vectors wt = \u2211n j=1 \u03b2jt\u03c8(xj) \u2208 Hk we get predictions as F (x, t) = \u3008wt, \u03c8(x)\u3009 and one can rewrite\n\u2016F\u20162HM = T\u2211\nr,s=1 n\u2211 i,j=1 ( \u0398\u22121 ) sr \u03b2is\u03b2jrk(xi, xj) = T\u2211 r,s=1 ( \u0398\u22121 ) sr \u3008ws, wt\u3009 .\nThis identity is known for vector-valued RKHS, see [15] and references therein. When \u0398 is \u03ba times the identity matrix, then \u2016F\u20162HM = \u2211T t=1 \u2016wt\u20162 \u03ba and thus (2) is learning the tasks independently. As mentioned before the convexity of the expression of \u2016F\u20162HM is crucial for the convexity of the full problem (10). The following result has been shown in [2] (see also [9]).\nLemma 2 Let R(\u0398) denote the range of \u0398 \u2208 ST+ and let \u0398\u2020 be the pseudoinverse. The extended function f : ST+ \u00d7 Rn\u00d7T \u2192 R \u222a {\u221e} defined as\nf(\u0398, \u03b2) =\n{\u2211T r,s=1 \u2211n i,j=1 ( \u0398\u2020 ) sr \u03b2is\u03b2jrk(xi, xj), if \u03b2i\u00b7 \u2208 R(\u0398),\u2200 i = 1, . . . , n,\n\u221e else . ,\nis jointly convex. Proof: It has been shown in [2] and [23][p. 223] that \u2329 x,A\u2020x \u232a is jointly convex on ST+ \u00d7 R(A), where R(A) is the range of A and A\u2020 is the pseudoinverse of A \u2208 ST+. As L := (k(xi, xj))ni,j=1 is positive semi-definite we can compute the eigendecomposition as\nLij = n\u2211 l=1 \u03bbluliulj ,\nwhere \u03bbl \u2265 0, l = 1, . . . , n are the eigenvalues and ul \u2208 Rn the eigenvectors. Using this we get\nT\u2211 r,s=1 n\u2211 i,j=1 ( \u0398\u22121 ) sr \u03b2is\u03b2jrk(xi, xj) = n\u2211 l=1 \u03bbl T\u2211 r,s=1 ( n\u2211 i=1 \u03b2isuli )( n\u2211 j=1 \u03b2jrulj )( \u0398\u22121 ) rs\n(11)\nand thus we can write the function f as a positive combination of convex functions, where the arguments are composed with linear mappings which preserves convexity [24].\nThe formulation in (10) is similar to [9, 17, 18]. [9] uses the constraint Trace(\u0398) \u2264 1 instead of a regularizer V (\u0398) enforcing low rank of the output kernel. On the other hand, [17] employs squared Frobenius norm for V (\u0398) with squared loss function. [18] proposed an efficient algorithm for convex V (\u0398). Instead we think that sparsity of \u0398 is better to avoid the emergence of spurious relations between tasks and also leads to output kernels which are easier to interpret. Thus we propose to use the following regularization functional for the output kernel \u0398:\nV (\u0398) = T\u2211 t,t\u2032=1 |\u0398tt\u2032 |p = \u2016\u0398\u2016pp ,\nfor p \u2208 [1, 2]. Several approaches [9, 17, 18] employ alternate minimization scheme, involving costly eigendecompositions of T \u00d7T matrix per iteration (as \u0398 \u2208 ST+). In the next section we show that for a certain set of values of p one can derive an unconstrained dual optimization problem which thus avoids the explicit minimization over the ST+ cone. The resulting unconstrained dual problem can then be easily optimized by stochastic coordinate ascent. Having explicit expressions of the primal variables \u0398 and \u03b2 in terms of the dual variables allows us to get back to the original problem.\n3 Unconstrained Dual Problem Avoiding Optimization over ST+\nThe primal formulation (10) is a convex multi-task output kernel learning problem. The next lemma derives the Fenchel dual function of (10). This still involves the optimization over the primal variable \u0398 \u2208 ST+. A main contribution of this paper is to show that this optimization problem over the ST+ cone can be solved with an analytical solution for a certain class of regularizers V (\u0398). In the following we denote by \u03b1r := {\u03b1i | ti = r} the dual variables corresponding to task r and by Krs the kernel matrix (k(xi, xj) | ti = r, tj = s) corresponding to the dual variables of tasks r and s.\nLemma 3 Let L\u2217i be the conjugate function of the loss Li : R\u2192 R, u 7\u2192 L(yi, u), then\nq : Rn \u2192 R, q(\u03b1) = \u2212C n\u2211 i=1 L\u2217i ( \u2212 \u03b1i C ) \u2212 \u03bb max \u0398\u2208ST+ ( 1 2\u03bb T\u2211 r,s=1 \u0398rs \u3008\u03b1r,Krs\u03b1s\u3009 \u2212 V (\u0398) ) (12)\nis the dual function of (10), where \u03b1 \u2208 Rn are the dual variables. The primal variable \u03b2 \u2208 Rn\u00d7T in (10) and the prediction function F can be expressed in terms of \u0398 and \u03b1 as \u03b2is = \u03b1i\u0398sti and F (x, s) = \u2211n j=1 \u03b1j\u0398stjk(xj , x) respectively, where tj is the task of the j-th training example.\nProof: We derive the Fenchel dual function of (10). For this purpose we introduce auxiliary variables z \u2208 Rn which satisfy the constraint\nzi = n\u2211 j=1 \u03b2jtik(xj , xi) = F (xi, ti).\nThe Lagrangian L of the resulting problem (10) is given as:\nL(\u03b2,\u0398, z, \u03b1) = C n\u2211 i=1 L(yi, zi) + 1 2 T\u2211 r,s=1 n\u2211 i,j=1 ( \u0398\u22121 ) sr \u03b2is\u03b2jrk(xi, xj) (13)\n+ n\u2211 i=1 \u03b1i ( zi \u2212 n\u2211 j=1 \u03b2jtik(xj , xi) ) + iST+ (\u0398) + \u03bbV (\u0398).\nwhere iC is the indicator function of the set C. The dual function q is defined as\nq(\u03b1) = min \u03b2\u2208Rn\u00d7T ,\u0398\u2208ST+ , z\u2208Rn L(\u03b2,\u0398, z, \u03b1). (14)\nUsing the definition of the conjugate function [24], we get\nmin zi\u2208R C L(yi, zi) + \u03b1izi = C min zi\u2208R L(yi, zi) + \u03b1i C zi = \u2212C max zi\u2208R ( \u2212 \u03b1i C zi \u2212 L(yi, zi) ) (15)\n= \u2212C L\u2217i ( \u2212 \u03b1i C ) , (16)\nwhere L\u2217i is the conjugate function of Li : z \u2192 L(yi, z). Moreover, we compute the minimizer with respect to \u03b2, via\n\u2202\n\u2202\u03b2lu\n(1 2 T\u2211 r,s=1 n\u2211 i,j=1 ( \u0398\u22121 ) sr \u03b2is\u03b2jrk(xi, xj)\u2212 n\u2211 i=1 \u03b1i ( n\u2211 j=1 \u03b2jtik(xj , xi) )\n(17)\n= T\u2211 r=1 n\u2211 j=1 \u03b2jr(\u0398 \u22121)urk(xl, xj)\u2212 n\u2211 i=1 \u03b1i\u03b4utik(xl, xi),\nwhere \u03b4 is the Kronecker symbol, that is \u03b4uti = {\n1 if u = ti, 0 else . Solving for the global minimizer\n\u03b2\u2217 yields \u03b2\u2217jr = \u03b1j\u0398rtj . (18)\nPlugging \u03b2\u2217 back into the above expressions yields\nT\u2211 r,s=1 n\u2211 i,j=1 ( \u0398\u22121 ) sr \u03b2is\u03b2jrk(xi, xj) = T\u2211 r,s=1 n\u2211 i,j=1 ( \u0398\u22121 ) sr \u0398sti\u0398rtj\u03b1i\u03b1jk(xi, xj)\n= n\u2211 i,j=1 \u0398titj\u03b1i\u03b1jk(xi, xj), (19)\nn\u2211 i,j=1 \u03b1i\u03b2jtik(xj , xi) = n\u2211 i,j=1 \u03b1i\u03b1j\u0398tjtik(xj , xi), (20)\nIntroducing \u03b1r = (\u03b1i)ti=r, Krs = ( k(xi, xj) ) ti=r,tj=s\nand gathering the terms corresponding to the individual tasks we get\nn\u2211 i,j=1 \u03b1i\u03b1j\u0398tjtik(xj , xi) = T\u2211 r,s=1 \u3008\u03b1r,Krs\u03b1s\u3009 .\nPlugging all the expressions back into (14), we get the dual function as\nq(\u03b1) = \u2212C L\u2217ti(\u2212 \u03b1ti C ) + min \u0398\u2208ST+ \u03bbV (\u0398)\u2212 1 2 T\u2211 r,s=1 \u0398rs \u3008\u03b1r,Krs\u03b1s\u3009 (21)\n= \u2212C L\u2217ti(\u2212 \u03b1ti C ) + \u03bb min \u0398\u2208ST+ V (\u0398)\u2212 \u3008\u03c1,\u0398\u3009 (22) = \u2212C L\u2217ti(\u2212 \u03b1ti C )\u2212 \u03bb max \u0398\u2208ST+ \u3008\u03c1,\u0398\u3009 \u2212 V (\u0398) (23)\nwhere we have introduced in the second step \u03c1 \u2208 RT\u00d7T with\n\u03c1rs = 1\n2\u03bb \u3008\u03b1r,Krs\u03b1s\u3009 , r, s = 1, . . . , T.\nNote that \u03c1 is a Gram matrix and thus positive semidefinite. The expression for the prediction function is obtained by plugging (18) into (6).\nWe now focus on the remaining maximization problem in the dual function in (12)\nmax \u0398\u2208ST+\n1\n2\u03bb T\u2211 r,s=1 \u0398rs \u3008\u03b1r,Krs\u03b1s\u3009 \u2212 V (\u0398). (24)\nThis is a semidefinite program which is computationally expensive to solve and thus prohibits to scale the output kernel learning problem to a large number of tasks. However, we show in the following that this problem has an analytical solution for a subset of the regularizers V (\u0398) = 1 2 \u2211T r,s=1 |\u0398rs|p for p \u2265 1. For better readability we defer a more general result towards the end of the section. The basic idea is to relax the constraint on \u0398 \u2208 RT\u00d7T in (24) so that it is equivalent to the computation of the conjugate V \u2217 of V . If the maximizer of the relaxed problem is positive semi-definite, one has found the solution of the original problem.\nTheorem 4 Let k \u2208 N and p = 2k2k\u22121 , then with \u03c1rs = 1 2\u03bb \u3008\u03b1 r,Krs\u03b1 s\u3009 we have\nmax \u0398\u2208ST+ T\u2211 r,s=1 \u0398rs\u03c1rs \u2212 1 2 T\u2211 r,s=1 |\u0398rs|p = 1 4k \u2212 2 (2k \u2212 1 2k\u03bb )2k T\u2211 r,s=1 \u3008\u03b1r,Krs\u03b1s\u30092k , (25)\nand the maximizer is given by the positive semi-definite matrix \u0398\u2217rs = (2k \u2212 1\n2k\u03bb\n)2k\u22121 \u3008\u03b1r,Krs\u03b1s\u30092k\u22121 , r, s = 1, . . . , T. (26)\nProof: We relax the constraints and solve\nmax \u0398\u2208RT\u00d7T\n1\n2\u03bb T\u2211 r,s=1 \u0398rs \u3008\u03b1r,Krs\u03b1s\u3009 \u2212 1 2 T\u2211 r,s=1 |\u0398rs|p.\nNote that the problem is separable and thus we can solve for each component separately,\nmax \u0398rs\u2208R\n1\n2\u03bb \u0398rs \u3008\u03b1r,Krs\u03b1s\u3009 \u2212\n1 2 |\u0398rs|p.\nThe optimality condition for \u0398\u2217rs becomes with \u03c1rs = 1 2\u03bb \u3008\u03b1 r,Krs\u03b1 s\u3009,\n0 = \u03c1rs \u2212 p\n2 sign(\u0398\u2217rs)|\u0398\u2217rs|p\u22121 =\u21d2 \u0398\u2217rs = (2 p ) 1 p\u22121 sign(\u03c1rs)|\u03c1rs| 1 p\u22121 .\nThe solution of the relaxed problem is the solution of the original constrained problem, if we can show that the corresponding maximizer is positive semidefinite. Note that \u03c1rs = 12\u03bb \u3008\u03b1 r,Krs\u03b1 s\u3009 is\na positive semidefinite (p.s.d.) matrix as it is a Gram matrix. The factor (\n2 p\n) 1 p\u22121\nis positive and thus\nthe resulting matrix is p.s.d. if sign(\u03c1rs)|\u03c1rs| 1 p\u22121 is p.s.d.\nIt has been shown [25], that the elementwise power Alrs of a positive semidefinite matrix A is positive definite for all A \u2208 ST+ and T \u2208 N if and only if l is a positive integer. Note that we have an elementwise integer power of \u0398 if 1p\u22121 is an odd positive integer (the case of an even integer is ruled out by Theorem 5), that is 1p\u22121 = 2k \u2212 1 for k \u2208 N as in this case we have\n\u0398\u2217rs = (2 p )2k\u22121 sign(\u03c1rs)|\u03c1rs|2k\u22121 = (2 p )2k\u22121 \u03c12k\u22121rs = (2k \u2212 1 2k\u03bb )2k\u22121 \u3008\u03b1r,Krs\u03b1s\u30092k\u22121 .\nWe get the admissible values of p as p = 2k2k\u22121 , k \u2208 N (resp. 2k = p p\u22121 ). We compute the optimal objective value as\nT\u2211 r,s=1 \u03c12krs ((2 p )2k\u22121 \u2212 1 2 (2 p )2k) = (p\u2212 1)1 2 (2 p )2k T\u2211 r,s=1 \u03c12krs = 1 4k \u2212 2 (2k \u2212 1 k )2k T\u2211 r,s=1 \u03c12krs\n(27)\n= 1\n4k \u2212 2 (2k \u2212 1 2\u03bb k )2k T\u2211 r,s=1 \u3008\u03b1r,Krs\u03b1s\u30092k (28)\nPlugging the result of the previous theorem into the dual function of Lemma 3 we get for k \u2208 N and p = 2k2k\u22121 with V (\u0398) = \u2016\u0398\u2016 p p the following unconstrained dual of our main problem (10):\nmax \u03b1\u2208Rn \u2212C n\u2211 i=1 L\u2217i ( \u2212 \u03b1i C ) \u2212 \u03bb 4k \u2212 2 (2k \u2212 1 2k\u03bb )2k T\u2211 r,s=1 \u3008\u03b1r,Krs\u03b1s\u30092k . (29)\nNote that by doing the variable transformation \u03bai := \u03b1iC we effectively have only one hyperparameter in (29). This allows us to cross-validate more efficiently. The range of admissible values for p in Theorem 4 lies in the interval (1, 2], where we get for k = 1 the value p = 2 and as k \u2192\u221e we have p\u2192 1. The regularizer for p = 2 together with the squared loss has been considered in the primal in [17, 18]. Our analytical expression of the dual is novel and allows us to employ stochastic dual coordinate ascent to solve the involved primal optimization problem. Please also note that by optimizing the dual, we have access to the duality gap and thus a well-defined stopping criterion. This is in contrast to the alternating scheme of [17, 18] for the primal problem which involves costly matrix operations. Our runtime experiments show that our solver for (29) outperforms the solvers of [17, 18]. Finally, note that even for suboptimal dual variables \u03b1, the corresponding \u0398 matrix in (26) is positive semidefinite. Thus we always get a feasible set of primal variables.\nTable 1: Examples of regularizers V (\u0398) together with their generating function \u03c6 and the explicit form of \u0398\u2217 in terms of the dual variables, \u03c1rs = 12\u03bb \u3008\u03b1 r,Krs\u03b1 s\u3009. The optimal value of (24) is given in terms of \u03c6 as max\n\u0398\u2208RT\u00d7T\n\u3008\u03c1,\u0398\u3009 \u2212 V (\u0398) =\n\u2211T\nr,s=1 \u03c6(\u03c1rs).\n\u03c6(z) V (\u0398) \u0398\u2217rs\nz2k 2k , k \u2208 N 2k\u22121 2k T\u2211 r,s=1 |\u0398rs| 2k 2k\u22121 \u03c12k\u22121rs ez = \u2211\u221e k=0 zk k!  T\u2211 r,s=1 \u0398rs log(\u0398rs)\u2212\u0398rs if \u0398rs > 0\u2200r, s\n\u221e else . e\u03c1rs\ncosh(z)\u2212 1 = \u2211\u221e k=1 z2k (2k)! T\u2211 r,s=1 ( \u0398rs arcsinh(\u0398rs)\u2212 \u221a 1 + \u03982rs ) + T 2 arcsinh(\u03c1rs)\nCharacterizing the set of convex regularizers V which allow an analytic expression for the dual function The previous theorem raises the question for which class of convex, separable regularizers we can get an analytical expression of the dual function by explicitly solving the optimization problem (24) over the positive semidefinite cone. A key element in the proof of the previous theorem is the characterization of functions f : R \u2192 R which when applied elementwise f(A) = (f(aij)) T i,j=1 to a positive semidefinite matrix A \u2208 ST+ result in a p.s.d. matrix, that is f(A) \u2208 ST+. This set of functions has been characterized by Hiai [26].\nTheorem 5 ([26]) Let f : R \u2192 R and A \u2208 ST+. We denote by f(A) = (f(aij))Ti,j=1 the elementwise application of f to A. It holds \u2200T \u2265 2, A \u2208 ST+ =\u21d2 f(A) \u2208 ST+ if and only if f is analytic and f(x) = \u2211\u221e k=0 akx k with ak \u2265 0 for all k \u2265 0.\nNote that in the previous theorem the condition on f is only necessary when we require the implication to hold for all T . If T is fixed, the set of functions is larger and includes even (large) fractional powers, see [25]. We use the stronger formulation as we want that the result holds without any restriction on the number of tasks T . Theorem 5 is the key element used in our following characterization of separable regularizers of \u0398 which allow an analytical expression of the dual function.\nTheorem 6 Let \u03c6 : R \u2192 R be analytic on R and given as \u03c6(z) = \u2211\u221e k=0 ak k+1z\nk+1 where ak \u2265 0 \u2200k \u2265 0. If \u03c6 is convex, then, V (\u0398) := \u2211T r,s=1 \u03c6 \u2217(\u0398rs), is a convex function V : RT\u00d7T \u2192 R and\nmax \u0398\u2208RT\u00d7T\n\u3008\u03c1,\u0398\u3009 \u2212 V (\u0398) = V \u2217(\u03c1) = T\u2211\nr,s=1\n\u03c6 ( \u03c1rs ) , (30)\nwhere the global maximizer fulfills \u0398\u2217 \u2208 ST+ if \u03c1 \u2208 ST+ and \u0398\u2217rs = \u2211\u221e k=0 ak\u03c1 k rs.\nProof: Note that \u03c6 is analytic on R and thus infinitely differentiable on R. As \u03c6 is additionally convex, it is a proper, lower semi-continuous convex function and thus (\u03c6\u2217)\u2217 = \u03c6 [27, Corollary 1.3.6]. As \u03c6\u2217 is convex, V is a convex function and using (\u03c6\u2217)\u2217 = \u03c6 we get\nmax \u0398\u2208RT\u00d7T\n\u3008\u03c1,\u0398\u3009 \u2212 V (\u0398) = V \u2217(\u03c1) = T\u2211\nr,s=1\n\u03c6(\u03c1rs). (31)\nFinally, we show that the global maximizer has the given form. Note that as \u03c6 is a proper, lower semi-continuous convex function it holds [27, Corollary 1.4.4]\n\u0398rs \u2208 \u2202\u03c6\u2217(\u03c1rs) \u21d0\u21d2 \u03c1rs \u2208 \u2202\u03c6(\u0398rs).\nNote that the maximizer \u0398\u2217rs of problem (31) fulfills \u03c1rs \u2208 \u2202\u03c6\u2217 \u2202\u0398rs (\u0398\u2217rs) and thus \u0398 \u2217 rs = \u2202\u03c6 \u2202\u03c1rs\n(\u03c1rs), where we have used that \u03c6 is infinitely differentiable. These conditions allow us to express the maximizer of (30) in terms of \u2202\u03c6. As \u03c6 is continuously differentiable, we get\n\u0398\u2217rs = \u2202\u03c6\n\u2202\u03c1rs (\u03c1rs) = \u221e\u2211 k=0 ak\u03c1 k rs.\nNote that the series has infinite convergence radius and ak \u2265 0 for all k and thus it is of the form provided in Theorem 5. Thus \u0398\u2217 \u2208 ST+ if \u03c1 \u2208 ST+. Table 1 summarizes e.g. of functions \u03c6, the corresponding V (\u0398) and the maximizer \u0398\u2217 in (30).\nExamples\n\u2022 First we recover the results of Theorem 4. We use \u03c6(x) = 12kx 2k for k \u2208 N, which is\nconvex. We compute\n\u03c6\u2217(y) = sup x\u2208R xy \u2212 \u03c6(x) = sup x\u2208R xy \u2212 1 2k x2k = 2k \u2212 1 2k |y| 2k 2k\u22121 ,\nwhere we have used x\u2217 = |y| 1 2k\u22121 sign(y). We recover\nV (\u0398) = T\u2211 r,s=1 \u03c6\u2217(\u0398rs) = 2k \u2212 1 2k T\u2211 r,s=1 \u0398 2k 2k\u22121 rs ,\nwhich with p = 2k2k\u22121 yields up to a positive factor the family of regularizers employed in Theorem 4 together with\n\u0398\u2217rs = \u03c1 2k\u22121 rs \u2022 In the second example we use \u03c6(x) = ex = \u2211\u221e k=0 xk\nk! , which is convex and the series has infinite convergence radius The conjugate \u03c6\u2217 is given as\n\u03c6\u2217(y) = sup x\u2208R xy \u2212 ex = { y log(y)\u2212 y if y > 0 \u221e else.\nso that the regularizer is given by,\nV (\u0398) = T\u2211 r,s=1 \u03c6\u2217(\u0398rs) =\n{\u2211T r,s=1 \u0398rs log(\u0398rs)\u2212\u0398rs if \u0398rs > 0 \u2200r, s = 1, . . . , T\n\u221e else . .\nThis can be seen as a generalized KL-divergence between \u0398 and \u03980, where \u03980 \u2208 ST+ is the matrix of all ones\nV (\u0398) = T\u2211 r,s=1 \u03c6\u2217(\u0398rs) =  \u2211T r,s=1 \u0398rs log ( \u0398rs( \u03980 ) rs ) \u2212\u0398rs + ( \u03980 ) rs if \u0398rs > 0 \u2200r, s \u221e else . .\nNote that adding the constant term \u2211T r,s=1 ( \u03980 ) rs\ndoes not change the optimization problem (10). The corresponding \u0398\u2217 is given by\n\u0398\u2217rs = \u221e\u2211 k=0 \u03c1krs k! = e\u03c1rs .\n\u2022 Next we consider \u03c6(x) = cosh(x) \u2212 1 = \u2211\u221e k=1 x2k\n(2k)! which is obviously convex and the series has infinite convergence radius (ex is majorant). The conjugate \u03c6\u2217 can be computed as \u03c6\u2217(y) = sup\nx\u2208R xy\u2212cosh(x)+1 = y arcsinh(y)\u2212\n\u221a 1 + y2+1 = y log(y+ \u221a y2 + 1)\u2212 \u221a 1 + y2+1.\nso that the regularizer is given by\nV (\u0398) = T\u2211 r,s=1 \u03c6\u2217(\u0398rs) = T\u2211 r,s=1 ( \u0398rs arcsinh(\u0398rs)\u2212 \u221a 1 + \u03982rs + 1 ) .\nThe corresponding \u0398\u2217 is given by \u0398\u2217rs = arcsinh(\u03c1rs) = log ( \u03c1rs + \u221a \u03c12rs + 1 ) .\nThis regularizer is interpolating between a squared norm and a variant of 1-norm. One has\nlim y\u21920\n\u03c6\u2217(y) = y2\n2 , lim y\u2192\u221e \u03c6\u2217(y) = |y|(log(2|y|)\u2212 1) + 1.\nAlgorithm 1 Fast MTL-SDCA Input: Gram matrix K, label vector y, regularization parameter and relative duality gap parameter Output: \u03b1 (\u0398 is computed from \u03b1 using our result in 26) Initialize \u03b1 = \u03b1(0)\nrepeat Let {i1, . . . , in} be a random permutation of {1, . . . , n} for j = 1, . . . , n do\nSolve for \u2206 in (32) corresponding to \u03b1ij \u03b1ij \u2190 \u03b1ij + \u2206\nend for until Relative duality gap is below"}, {"heading": "4 Optimization Algorithm", "text": "The dual problem (29) can be efficiently solved via decomposition based methods like stochastic dual coordinate ascent algorithm (SDCA) [19]. SDCA enjoys low computational complexity per iteration and has been shown to scale effortlessly to large scale optimization problems.\nOur algorithm for learning the output kernel matrix and task parameters is summarized in Algorithm 1. At each step of the iteration we optimize the dual objective over a randomly chosen \u03b1i variable. Let ti = r be the task corresponding to \u03b1i. We apply the update \u03b1i \u2190 \u03b1i + \u2206. The optimization problem of solving (29) with respect to \u2206 is as follows:\nmin \u2206\u2208R\nL\u2217i ( (\u2212\u03b1i \u2212\u2206)/C ) + \u03b7 ( (a\u22062 + 2brr\u2206 + crr) 2k + 2 \u2211 s6=r (brs\u2206 + crs) 2k + \u2211 s,z 6=r c2ksz ) , (32)\nwhere a = kii, brs = \u2211 j:tj=s kij\u03b1j \u2200s, csz = \u3008\u03b1s,Ksz\u03b1z\u3009 \u2200s, z and \u03b7 = \u03bbC(4k\u22122) ( 2k\u22121 2k\u03bb )2k . This one-dimensional convex optimization problem is solved efficiently via Newton method. The complexity of the proposed algorithm is O(T ) per iteration . The proposed algorithm can also be employed for learning output kernels regularized by generic V (\u0398), discussed in the previous section. Special case p = 2(k = 1): For certain loss functions such as the hinge loss, the squared loss, etc., L\u2217ti ( \u2212 \u03b1ti+\u2206C ) yields a linear or a quadratic expression in \u2206. In such cases problem (32) reduces to finding the roots of a cubic equation, which has a closed form expression. Hence, our algorithm is highly efficient with the above loss functions when \u0398 is regularized by the squared Frobenius norm."}, {"heading": "5 Empirical Results", "text": "In this section, we present our results on benchmark data sets comparing our algorithm with existing approaches in terms of generalization accuracy as well as computational efficiency. In Section 5.1, we discuss generalization results in multi-task setting. We evaluate the performance of our algorithm against several recent multi-task methods that employ clustering, low-dimensional projection of input feature space or output kernel learning. Section 5.2 discusses multi-class experiment results. Single task learning (STL) is a common baseline in both these experiments, and it employs hinge loss and -SVR loss functions for classification and regression problems respectively. Finally, in Section 5.3, we discuss the results on the computational efficiency of our algorithm."}, {"heading": "5.1 Multi-Task Data Sets", "text": "We begin with the generalization results in multi-task setups. The data sets are as follows: Sarcos: A multi-task regression data set. The aim is to predict 7 degrees of freedom of a robotic arm [28]. Parkinson: A multi-task regression data set [29] where one needs to predict the Parkinson\u2019s disease symptom score for 42 patients. Yale: A face recognition data set from the Yale face base with 28 binary classification tasks [30]. Landmine: A data set containing binary classification problems from 19 different landmines [30]. MHC-I: A bioinformatics data set having 10 binary classification tasks [12].\nLetter: A data set containing handwritten letters from several writers and having 9 binary classification tasks [31].\nTable 2 presents the data set statistics. We compare the following algorithms: MTL [16]: A classical multi-task learning baseline. They define the \u0398 matrix as: \u0398(t, t\u2032) = 1\u00b5+\u03b4tt\u2032 , where \u00b5 > 0 is a hyper-parameter and \u03b4tt\u2032 = 1 if t = t\u2032 else \u03b4tt\u2032 = 0. The hyper-parameter \u00b5 is cross-validated. CMTL [12]: A clustered multi-task learning algorithm. Tasks within a cluster are assumed to be close to a mean vector. It requires the number of task clusters as a hyper-parameter. MTFL [11]: Learns the input kernel and the output kernel matrix as a linear combination of base kernel matrices. GMTL [10]: A clustered multi-task feature learning approach. Tasks within a cluster are assumed to share a low dimensional feature subspace [2]. Hence, it effectively learns both the input kernel as well as the output kernel. MTRL [9]: A multi-task relationship learning approach. It learns a low rank output kernel matrix by enforcing a trace constraint on it. FMTLp: Our proposed multi-task learning formulation (29). We consider three different values for the p-norm: p = 2 (k = 1), p = 4/3 (k = 2) and p = 8/7 (k = 4). Hinge and -SVR loss functions were used for classification and regression problems respectively.\nWe follow the experimental protocol1 described in [11]. Three-fold cross validation was performed for parameter selection. Linear kernel was employed for all data sets. Also, note that GMTL [10] and MTFL [11] enjoy the advantage of both input and output kernel learning. Hence, their generalization results are not directly comparable to our method, which focuses solely on learning the output kernel matrix.\nTable 3 reports the performance of the algorithms averaged over ten random train-test splits. The proposed FMTLp attains the best generalization accuracy in general. It outperforms the baseline MTL as well as MTRL and CMTL, which solely learns the output kernel matrix. Moreover, it achieves an overall better performance than GMTL and MTFL. The FMTLp=4/3,8/7 give comparable generalization to p = 2 case, with the additional benefit of learning sparser and more interpretable output kernel matrix (see Figure 1).\n1The performance of STL, MTL, CMTL and MTFL are reported from [11]."}, {"heading": "5.2 Multi-Class Data Sets", "text": "The multi-class setup is cast as T one-vs-all binary classification tasks, corresponding to T classes. In this section we experimented with two loss functions: a) FMTLp-H \u2013 the hinge loss employed in SVMs, and b) FMTLp-S \u2013 the squared loss employed in OKL [17]. In these experiments, we also compare our results with MTL-SDCA, a state-of-the-art multi-task feature learning method [32]. In addition, we report results from our KL-divergence regularized formulation with squared loss (denoted by FMTLkl ).\nHandwritten Digit Recognition: We consider the following two data sets and follow the experimental protocol detailed in [10]. USPS: A handwritten digit data sets with 10 classes [33]. We process the images using PCA and reduce the dimensionality to 87. This retains almost 87% of variance. MNIST: Another handwritten digit data set with 10 classes [34]. PCA is employed to reduce the dimensionality to 64.\nWe use 1000, 500 and 500 examples for training, validation and test respectively. Table 4 reports the average accuracy achieved by various methods on both data sets over 5 splits. Our approach FMTLp-H obtains better accuracy than GMTL, MTRL and MTL-SDCA [32] on both data sets.\nMIT Indoor67 Experiments: We also report results on the MIT Indoor67 benchmark [35] which covers 67 indoor scene categories with over 100 images per class. We use the train/test split (80/20 images per class) provided by the authors. FMTLp-S achieved the accuracy of 73.1%, 73.1% and 73.3% with p = 2, 4/3 and 8/7 respectively. Our KL-divergence regularized approach FMTLkl obtained 73.1%. Note that these are better than the ones reported in [36] (70.1%) and [35] (68.24%).\nSUN397 Experiments: SUN397 [37] is a challenging scene classification benchmark [35] with 397 scene classes and more than 100 images per class. We use m = 5, 50 images per class for training, 50 images per class for testing and report the average accuracy over the 10 standard splits. We employed the CNN features extracted with the convolutional neural network (CNN) provided by [35] using Places 205 database. We resized the images directly to 227 \u00d7 227 pixels, which is the\nTable 5: Mean accuracy and the standard deviation over ten train-test splits on SUN397.\nm STL MTL MTL-SDCA FMTLp-H FMTLp-S FMTLklp = 2 p = 4/3 p = 8/7 p = 2 p = 4/3 p = 8/7\n5 40.5\u00b10.9 42.0\u00b11.4 41.2\u00b11.3 41.5\u00b11.1 41.6\u00b11.3 41.6\u00b11.2 44.1\u00b11.3 44.1\u00b11.1 44.0\u00b11.2 44.1\u00b11.3 50 55.0\u00b10.4 57.0\u00b10.2 54.8\u00b10.3 55.1\u00b10.2 55.6\u00b10.3 55.1\u00b10.3 58.6\u00b10.1 58.5\u00b10.1 58.6\u00b10.2 58.4\u00b10.1\n50 100 150 200 250 300 350\n50\n100\n150\n200\n250\n300\n350\n50 100 150 200 250 300 350\n50\n100\n150\n200\n250\n300\n350\n50 100 150 200 250 300 350\n50\n100\n150\n200\n250\n300\n350\n(p = 2) (p = 4/3) (p = 8/7)\nFigure 2: Plots of matrices log(1 + |\u0398|) (rescaled to [0,1] and diagonal entries removed since they reflect high similarity of a task with itself, which is obvious) computed by our solver FMTLp-S for the SUN397 data set for different p-norms, with cross-validated hyper-parameter values. The hierarchical block structure indicated by the red squares corresponds to the groups of classes available in SUN397, e.g., the top 3 super-classes are indoor, outdoor-natural, and outdoor-man-made, which in turn contain subgroups of classes. Note that this information was not used in experiments. We can observe that the learned \u0398 matrix at p = 2 depicts much more spurious task relationships than the one at p = 8/7. Thus, our sparsifying regularizer improves interpretability. Best viewed in color.\nsize of the receptive field of that network. The parameters were set by 2-fold cross-validation. The results are tabulated in Table 5.\nFigure 2 offers a qualitative assessment of the proposed method by showing the output kernel matrices \u0398 computed by our formulation FMTLp-S for various p-norms. We can observe that the \u0398 matrix becomes sparser as the p-norm decreases from 2 towards one. Enforcing sparsity helps to detect the hierarchical structure of the tasks (see caption for more details)."}, {"heading": "5.3 Scaling Experiment", "text": "We compare the runtime of our solver for FMTL2-S with the OKL solver of [17] and the ConvexOKL solver of [18] on several data sets. All the three methods solve the same optimization problem. Figure 3a shows the result of the scaling experiment where we vary the number of tasks (classes). The parameters employed are the ones obtained via cross-validation. Note that both OKL and ConvexOKL algorithms do not have a well defined stopping criterion whereas our approach can easily compute the relative duality gap (set as 10\u22123). We terminate them when they reach the primal objective value achieved by FMTL2-S . Our optimization approach is 7 times and 4.3 times faster than the alternate minimization based OKL and ConvexOKL, respectively, when the number of tasks is maximal. The generic FMTLp=4/3,8/7 are also considerably faster than OKL and ConvexOKL.\nFigure 3b compares the average runtime of our FMTLp-S with OKL and ConvexOKL on the crossvalidated range of hyper-parameter values. The hyper-parameter value chosen by cross-validation for SUN397 and MIT Indoor67 data sets was around 105. FMTLp-S outperform them on both MIT Indoor67 and SUN397 data sets. Figure 4 shows the same comparison on MNIST and USPS data sets."}, {"heading": "6 Conclusion", "text": "We proposed a novel formulation for learning the positive semi-definite output kernel matrix for multiple tasks. Our main technical contribution is our analysis of a certain class of regularizers on the output kernel matrix where one may drop the positive semi-definite constraint from the optimization problem, but still solve the problem optimally. This leads to a dual formulation that can be efficiently solved using stochastic dual coordinate ascent algorithm. Results on benchmark multi-task and multi-class data sets demonstrates the effectiveness of the proposed multi-task algorithm in terms of runtime as well as generalization accuracy.\nAcknowledgments. P.J. and M.H. acknowledge the support by the Cluster of Excellence (MMCI)."}], "references": [{"title": "Learning multiple tasks with kernel methods", "author": ["T. Evgeniou", "C.A. Micchelli", "M. Pontil"], "venue": "JMLR, 6:615\u2013637,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "Convex multi-task feature learning", "author": ["A. Argyriou", "T. Evgeniou", "M. Pontil"], "venue": "ML, 73:243\u2013272,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Taking advantage of sparsity in multi-task learning", "author": ["K. Lounici", "M. Pontil", "A.B. Tsybakov", "S. van de Geer"], "venue": "In COLT,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "A dirty model for multi-task learning", "author": ["A. Jalali", "P. Ravikumar", "S. Sanghavi", "C. Ruan"], "venue": "NIPS,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Multi-task multiple kernel learning", "author": ["P. Jawanpuria", "J.S. Nath"], "venue": "SDM,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Sparse coding for multitask and transfer learning", "author": ["A. Maurer", "M. Pontil", "B. Romera-paredes"], "venue": "ICML,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Generalized hierarchical kernel learning", "author": ["P. Jawanpuria", "J.S. Nath", "G. Ramakrishnan"], "venue": "JMLR, 16:617\u2013 652,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Multitask learning", "author": ["R. Caruana"], "venue": "ML, 28:41\u201375,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1997}, {"title": "A convex formulation for learning task relationships in multi-task learning", "author": ["Y. Zhang", "D.Y. Yeung"], "venue": "UAI,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning with whom to share in multi-task feature learning", "author": ["Z. Kang", "K. Grauman", "F. Sha"], "venue": "ICML,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "A convex feature learning formulation for latent task structure discovery", "author": ["P. Jawanpuria", "J.S. Nath"], "venue": "ICML,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Clustered multi-task learning: A convex formulation", "author": ["L. Jacob", "F. Bach", "J.P. Vert"], "venue": "NIPS,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Kernels for multitask learning", "author": ["C.A. Micchelli", "M. Pontil"], "venue": "NIPS,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "Universal multi-task kernels", "author": ["A. Caponnetto", "C.A. Micchelli", "M. Pontil", "Y. Ying"], "venue": "JMLR, 9:1615\u2013 1646,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Kernels for vector-valued functions: a review", "author": ["M.A. \u00c1lvarez", "L. Rosasco", "N.D. Lawrence"], "venue": "Foundations and Trends in Machine Learning, 4:195\u2013266,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Regularized multi\u2013task learning", "author": ["T. Evgeniou", "M. Pontil"], "venue": "KDD,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "Learning output kernels with block coordinate descent", "author": ["F. Dinuzzo", "C.S. Ong", "P. Gehler", "G. Pillonetto"], "venue": "ICML,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Convex learning of multiple tasks and their structure", "author": ["C. Ciliberto", "Y. Mroueh", "T. Poggio", "L. Rosasco"], "venue": "ICML,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Stochastic dual coordinate ascent methods for regularized loss", "author": ["S. Shalev-Shwartz", "T. Zhang"], "venue": "JMLR, 14(1):567\u2013599,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning with Kernels", "author": ["B. Sch\u00f6lkopf", "A. Smola"], "venue": "MIT Press,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2002}, {"title": "Kernels, associated structures and generalizations", "author": ["M. Hein", "O. Bousquet"], "venue": "Technical Report TR-127, Max Planck Institute for Biological Cybernetics,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "What is invexity ? J", "author": ["A. Ben-Israel", "B. Mond"], "venue": "Austral. Math. Soc. Ser. B, 28:1\u20139,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1986}, {"title": "Convex Optimization and Euclidean Distance Geometry", "author": ["J. Dattorro"], "venue": "Meboo Publishing,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Convex Optimization", "author": ["S. Boyd", "L. Vandenberghe"], "venue": "Cambridge University Press,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2004}, {"title": "The theory of infinitely divisible matrices and kernels", "author": ["R.A. Horn"], "venue": "Trans. Amer. Math. Soc., 136:269\u2013286,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1969}, {"title": "Monotonicity for entrywise functions of matrices", "author": ["F. Hiai"], "venue": "Linear Algebra and its Applications, 431(8):1125 \u2013 1146,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Fundamentals of convex analysis", "author": ["J.-B. Hiriart-Urruty", "C. Lemar\u00e9chal"], "venue": "Springer,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2001}, {"title": "Semi-supervised multi-task regression", "author": ["Y. Zhang", "D.Y. Yeung"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2009}, {"title": "Learning multiple tasks with a sparse matrix-normal penalty", "author": ["Y. Zhang", "J. Schneider"], "venue": "NIPS,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2010}, {"title": "An accelerated gradient method for trace norm minimization", "author": ["S. Ji", "J. Ye"], "venue": "ICML,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Scalable multitask representation learning for scene classification", "author": ["M. Lapin", "B. Schiele", "M. Hein"], "venue": "CVPR,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "A database for handwritten text recognition research", "author": ["J.J. Hull"], "venue": "IEEE PAMI, 16:550\u2013554,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1994}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, 86(11):2278\u20132324,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1998}, {"title": "Learning deep features for scene recognition using places database", "author": ["B. Zhou", "A. Lapedriza", "J. Xiao", "A. Torralba", "A. Oliva"], "venue": "NIPS,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "Convolutional network features for scene recognition", "author": ["M. Koskela", "J. Laaksonen"], "venue": "Proceedings of the ACM International Conference on Multimedia,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2014}, {"title": "SUN database: Large-scale scene recognition from abbey to zoo", "author": ["J. Xiao", "J. Hays", "K.A. Ehinger", "A. Oliva", "A. Torralba"], "venue": "CVPR,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "The advantage of MTL over learning tasks independently has been shown theoretically as well as empirically [1, 2, 3, 4, 5, 6, 7].", "startOffset": 107, "endOffset": 128}, {"referenceID": 1, "context": "The advantage of MTL over learning tasks independently has been shown theoretically as well as empirically [1, 2, 3, 4, 5, 6, 7].", "startOffset": 107, "endOffset": 128}, {"referenceID": 2, "context": "The advantage of MTL over learning tasks independently has been shown theoretically as well as empirically [1, 2, 3, 4, 5, 6, 7].", "startOffset": 107, "endOffset": 128}, {"referenceID": 3, "context": "The advantage of MTL over learning tasks independently has been shown theoretically as well as empirically [1, 2, 3, 4, 5, 6, 7].", "startOffset": 107, "endOffset": 128}, {"referenceID": 4, "context": "The advantage of MTL over learning tasks independently has been shown theoretically as well as empirically [1, 2, 3, 4, 5, 6, 7].", "startOffset": 107, "endOffset": 128}, {"referenceID": 5, "context": "The advantage of MTL over learning tasks independently has been shown theoretically as well as empirically [1, 2, 3, 4, 5, 6, 7].", "startOffset": 107, "endOffset": 128}, {"referenceID": 6, "context": "The advantage of MTL over learning tasks independently has been shown theoretically as well as empirically [1, 2, 3, 4, 5, 6, 7].", "startOffset": 107, "endOffset": 128}, {"referenceID": 7, "context": "It has been noted that naively grouping all the tasks together may be detrimental [8, 9, 10, 11].", "startOffset": 82, "endOffset": 96}, {"referenceID": 8, "context": "It has been noted that naively grouping all the tasks together may be detrimental [8, 9, 10, 11].", "startOffset": 82, "endOffset": 96}, {"referenceID": 9, "context": "It has been noted that naively grouping all the tasks together may be detrimental [8, 9, 10, 11].", "startOffset": 82, "endOffset": 96}, {"referenceID": 10, "context": "It has been noted that naively grouping all the tasks together may be detrimental [8, 9, 10, 11].", "startOffset": 82, "endOffset": 96}, {"referenceID": 9, "context": "Hence, clustered multi-task learning algorithms [10, 12] aim to learn groups of closely related tasks.", "startOffset": 48, "endOffset": 56}, {"referenceID": 11, "context": "Hence, clustered multi-task learning algorithms [10, 12] aim to learn groups of closely related tasks.", "startOffset": 48, "endOffset": 56}, {"referenceID": 0, "context": "The multi-task kernel on input and output is assumed to be decoupled as the product of a scalar kernel and the output kernel, which is a positive semidefinite matrix [1, 13, 14, 15].", "startOffset": 166, "endOffset": 181}, {"referenceID": 12, "context": "The multi-task kernel on input and output is assumed to be decoupled as the product of a scalar kernel and the output kernel, which is a positive semidefinite matrix [1, 13, 14, 15].", "startOffset": 166, "endOffset": 181}, {"referenceID": 13, "context": "The multi-task kernel on input and output is assumed to be decoupled as the product of a scalar kernel and the output kernel, which is a positive semidefinite matrix [1, 13, 14, 15].", "startOffset": 166, "endOffset": 181}, {"referenceID": 14, "context": "The multi-task kernel on input and output is assumed to be decoupled as the product of a scalar kernel and the output kernel, which is a positive semidefinite matrix [1, 13, 14, 15].", "startOffset": 166, "endOffset": 181}, {"referenceID": 0, "context": "In classical multi-task learning algorithms [1, 16], the degree of relatedness between distinct tasks is set to a constant and is optimized as a hyperparameter.", "startOffset": 44, "endOffset": 51}, {"referenceID": 15, "context": "In classical multi-task learning algorithms [1, 16], the degree of relatedness between distinct tasks is set to a constant and is optimized as a hyperparameter.", "startOffset": 44, "endOffset": 51}, {"referenceID": 16, "context": "[17] solves a multi-task formulation in the framework of vector-valued reproducing kernel Hilbert spaces involving squared loss where they penalize the Frobenius norm of the output kernel as a regularizer.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "In comparison, [18] recently proposed an efficient barrier method to optimize a generic convex output kernel learning formulation.", "startOffset": 15, "endOffset": 19}, {"referenceID": 8, "context": "On the other hand, [9] proposes a convex formulation to learn low rank output kernel matrix by enforcing a trace constraint.", "startOffset": 19, "endOffset": 22}, {"referenceID": 8, "context": "The above approaches [9, 17, 18] solve the resulting optimization problem via alternate minimization between task parameters and the output kernel.", "startOffset": 21, "endOffset": 32}, {"referenceID": 16, "context": "The above approaches [9, 17, 18] solve the resulting optimization problem via alternate minimization between task parameters and the output kernel.", "startOffset": 21, "endOffset": 32}, {"referenceID": 17, "context": "The above approaches [9, 17, 18] solve the resulting optimization problem via alternate minimization between task parameters and the output kernel.", "startOffset": 21, "endOffset": 32}, {"referenceID": 16, "context": "In this paper we study a similar formulation as [17].", "startOffset": 48, "endOffset": 52}, {"referenceID": 18, "context": "The resulting unconstrained dual problem is amenable to efficient optimization methods such as stochastic dual coordinate ascent [19], which scale well to large data sets.", "startOffset": 129, "endOffset": 133}, {"referenceID": 19, "context": "We denote by \u03c8(\u00b7) the feature map and by Hk the reproducing kernel Hilbert space (RKHS) [20] associated with k.", "startOffset": 88, "endOffset": 92}, {"referenceID": 20, "context": "However, in this paper we use the one-to-one correspondence between real-valued and matrix-valued kernels, see [21], in order to limit the technical overhead.", "startOffset": 111, "endOffset": 115}, {"referenceID": 19, "context": "Proof: The proof is analogous to the standard representer theorem [20].", "startOffset": 66, "endOffset": 70}, {"referenceID": 16, "context": "A similar problem has been analyzed in [17].", "startOffset": 39, "endOffset": 43}, {"referenceID": 21, "context": "For an invex function every stationary point is globally optimal [22].", "startOffset": 65, "endOffset": 69}, {"referenceID": 1, "context": "We follow a different path which leads to a formulation similar to the one of [2] used for learning an input mapping (see also [9]).", "startOffset": 78, "endOffset": 81}, {"referenceID": 8, "context": "We follow a different path which leads to a formulation similar to the one of [2] used for learning an input mapping (see also [9]).", "startOffset": 127, "endOffset": 130}, {"referenceID": 1, "context": "We present a derivation for the general RKHS Hk, analogous to the linear case presented in [2, 9].", "startOffset": 91, "endOffset": 97}, {"referenceID": 8, "context": "We present a derivation for the general RKHS Hk, analogous to the linear case presented in [2, 9].", "startOffset": 91, "endOffset": 97}, {"referenceID": 8, "context": "i,j=1 ( \u0398\u22121 ) sr \u03b2is\u03b2jrkij + \u03bbV (\u0398) (10) Before we analyze the convexity of this problem, we want to illustrate the connection to the formulations in [9, 17].", "startOffset": 150, "endOffset": 157}, {"referenceID": 16, "context": "i,j=1 ( \u0398\u22121 ) sr \u03b2is\u03b2jrkij + \u03bbV (\u0398) (10) Before we analyze the convexity of this problem, we want to illustrate the connection to the formulations in [9, 17].", "startOffset": 150, "endOffset": 157}, {"referenceID": 14, "context": "This identity is known for vector-valued RKHS, see [15] and references therein.", "startOffset": 51, "endOffset": 55}, {"referenceID": 1, "context": "The following result has been shown in [2] (see also [9]).", "startOffset": 39, "endOffset": 42}, {"referenceID": 8, "context": "The following result has been shown in [2] (see also [9]).", "startOffset": 53, "endOffset": 56}, {"referenceID": 1, "context": "Proof: It has been shown in [2] and [23][p.", "startOffset": 28, "endOffset": 31}, {"referenceID": 22, "context": "Proof: It has been shown in [2] and [23][p.", "startOffset": 36, "endOffset": 40}, {"referenceID": 23, "context": "and thus we can write the function f as a positive combination of convex functions, where the arguments are composed with linear mappings which preserves convexity [24].", "startOffset": 164, "endOffset": 168}, {"referenceID": 8, "context": "The formulation in (10) is similar to [9, 17, 18].", "startOffset": 38, "endOffset": 49}, {"referenceID": 16, "context": "The formulation in (10) is similar to [9, 17, 18].", "startOffset": 38, "endOffset": 49}, {"referenceID": 17, "context": "The formulation in (10) is similar to [9, 17, 18].", "startOffset": 38, "endOffset": 49}, {"referenceID": 8, "context": "[9] uses the constraint Trace(\u0398) \u2264 1 instead of a regularizer V (\u0398) enforcing low rank of the output kernel.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "On the other hand, [17] employs squared Frobenius norm for V (\u0398) with squared loss function.", "startOffset": 19, "endOffset": 23}, {"referenceID": 17, "context": "[18] proposed an efficient algorithm for convex V (\u0398).", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "V (\u0398) = T \u2211 t,t\u2032=1 |\u0398tt\u2032 | = \u2016\u0398\u2016pp , for p \u2208 [1, 2].", "startOffset": 45, "endOffset": 51}, {"referenceID": 1, "context": "V (\u0398) = T \u2211 t,t\u2032=1 |\u0398tt\u2032 | = \u2016\u0398\u2016pp , for p \u2208 [1, 2].", "startOffset": 45, "endOffset": 51}, {"referenceID": 8, "context": "Several approaches [9, 17, 18] employ alternate minimization scheme, involving costly eigendecompositions of T \u00d7T matrix per iteration (as \u0398 \u2208 S +).", "startOffset": 19, "endOffset": 30}, {"referenceID": 16, "context": "Several approaches [9, 17, 18] employ alternate minimization scheme, involving costly eigendecompositions of T \u00d7T matrix per iteration (as \u0398 \u2208 S +).", "startOffset": 19, "endOffset": 30}, {"referenceID": 17, "context": "Several approaches [9, 17, 18] employ alternate minimization scheme, involving costly eigendecompositions of T \u00d7T matrix per iteration (as \u0398 \u2208 S +).", "startOffset": 19, "endOffset": 30}, {"referenceID": 23, "context": "(14) Using the definition of the conjugate function [24], we get min zi\u2208R C L(yi, zi) + \u03b1izi = C min zi\u2208R L(yi, zi) + \u03b1i C zi = \u2212C max zi\u2208R ( \u2212 \u03b1i C zi \u2212 L(yi, zi) ) (15) = \u2212C Li ( \u2212 \u03b1i C ) , (16) where Li is the conjugate function of Li : z \u2192 L(yi, z).", "startOffset": 52, "endOffset": 56}, {"referenceID": 24, "context": "It has been shown [25], that the elementwise power Ars of a positive semidefinite matrix A is positive definite for all A \u2208 S + and T \u2208 N if and only if l is a positive integer.", "startOffset": 18, "endOffset": 22}, {"referenceID": 16, "context": "The regularizer for p = 2 together with the squared loss has been considered in the primal in [17, 18].", "startOffset": 94, "endOffset": 102}, {"referenceID": 17, "context": "The regularizer for p = 2 together with the squared loss has been considered in the primal in [17, 18].", "startOffset": 94, "endOffset": 102}, {"referenceID": 16, "context": "This is in contrast to the alternating scheme of [17, 18] for the primal problem which involves costly matrix operations.", "startOffset": 49, "endOffset": 57}, {"referenceID": 17, "context": "This is in contrast to the alternating scheme of [17, 18] for the primal problem which involves costly matrix operations.", "startOffset": 49, "endOffset": 57}, {"referenceID": 16, "context": "Our runtime experiments show that our solver for (29) outperforms the solvers of [17, 18].", "startOffset": 81, "endOffset": 89}, {"referenceID": 17, "context": "Our runtime experiments show that our solver for (29) outperforms the solvers of [17, 18].", "startOffset": 81, "endOffset": 89}, {"referenceID": 25, "context": "This set of functions has been characterized by Hiai [26].", "startOffset": 53, "endOffset": 57}, {"referenceID": 25, "context": "Theorem 5 ([26]) Let f : R \u2192 R and A \u2208 S +.", "startOffset": 11, "endOffset": 15}, {"referenceID": 24, "context": "If T is fixed, the set of functions is larger and includes even (large) fractional powers, see [25].", "startOffset": 95, "endOffset": 99}, {"referenceID": 18, "context": "4 Optimization Algorithm The dual problem (29) can be efficiently solved via decomposition based methods like stochastic dual coordinate ascent algorithm (SDCA) [19].", "startOffset": 161, "endOffset": 165}, {"referenceID": 27, "context": "The aim is to predict 7 degrees of freedom of a robotic arm [28].", "startOffset": 60, "endOffset": 64}, {"referenceID": 28, "context": "Yale: A face recognition data set from the Yale face base with 28 binary classification tasks [30].", "startOffset": 94, "endOffset": 98}, {"referenceID": 28, "context": "Landmine: A data set containing binary classification problems from 19 different landmines [30].", "startOffset": 91, "endOffset": 95}, {"referenceID": 11, "context": "MHC-I: A bioinformatics data set having 10 binary classification tasks [12].", "startOffset": 71, "endOffset": 75}, {"referenceID": 29, "context": "Letter: A data set containing handwritten letters from several writers and having 9 binary classification tasks [31].", "startOffset": 112, "endOffset": 116}, {"referenceID": 15, "context": "We compare the following algorithms: MTL [16]: A classical multi-task learning baseline.", "startOffset": 41, "endOffset": 45}, {"referenceID": 11, "context": "CMTL [12]: A clustered multi-task learning algorithm.", "startOffset": 5, "endOffset": 9}, {"referenceID": 10, "context": "MTFL [11]: Learns the input kernel and the output kernel matrix as a linear combination of base kernel matrices.", "startOffset": 5, "endOffset": 9}, {"referenceID": 9, "context": "GMTL [10]: A clustered multi-task feature learning approach.", "startOffset": 5, "endOffset": 9}, {"referenceID": 1, "context": "Tasks within a cluster are assumed to share a low dimensional feature subspace [2].", "startOffset": 79, "endOffset": 82}, {"referenceID": 8, "context": "MTRL [9]: A multi-task relationship learning approach.", "startOffset": 5, "endOffset": 8}, {"referenceID": 10, "context": "We follow the experimental protocol1 described in [11].", "startOffset": 50, "endOffset": 54}, {"referenceID": 9, "context": "Also, note that GMTL [10] and MTFL [11] enjoy the advantage of both input and output kernel learning.", "startOffset": 21, "endOffset": 25}, {"referenceID": 10, "context": "Also, note that GMTL [10] and MTFL [11] enjoy the advantage of both input and output kernel learning.", "startOffset": 35, "endOffset": 39}, {"referenceID": 10, "context": "The performance of STL, MTL, CMTL and MTFL are reported from [11].", "startOffset": 61, "endOffset": 65}, {"referenceID": 0, "context": "(p = 2) (p = 4/3) (p = 8/7) Figure 1: Plots of |\u0398| matrices (rescaled to [0,1] and averaged over ten splits) computed by our solver FMTLp for the Landmine data set for different p-norms, with cross-validated hyper-parameter values.", "startOffset": 73, "endOffset": 78}, {"referenceID": 16, "context": "In this section we experimented with two loss functions: a) FMTLp-H \u2013 the hinge loss employed in SVMs, and b) FMTLp-S \u2013 the squared loss employed in OKL [17].", "startOffset": 153, "endOffset": 157}, {"referenceID": 30, "context": "In these experiments, we also compare our results with MTL-SDCA, a state-of-the-art multi-task feature learning method [32].", "startOffset": 119, "endOffset": 123}, {"referenceID": 9, "context": "Handwritten Digit Recognition: We consider the following two data sets and follow the experimental protocol detailed in [10].", "startOffset": 120, "endOffset": 124}, {"referenceID": 31, "context": "USPS: A handwritten digit data sets with 10 classes [33].", "startOffset": 52, "endOffset": 56}, {"referenceID": 32, "context": "MNIST: Another handwritten digit data set with 10 classes [34].", "startOffset": 58, "endOffset": 62}, {"referenceID": 30, "context": "Our approach FMTLp-H obtains better accuracy than GMTL, MTRL and MTL-SDCA [32] on both data sets.", "startOffset": 74, "endOffset": 78}, {"referenceID": 33, "context": "MIT Indoor67 Experiments: We also report results on the MIT Indoor67 benchmark [35] which covers 67 indoor scene categories with over 100 images per class.", "startOffset": 79, "endOffset": 83}, {"referenceID": 34, "context": "Note that these are better than the ones reported in [36] (70.", "startOffset": 53, "endOffset": 57}, {"referenceID": 33, "context": "1%) and [35] (68.", "startOffset": 8, "endOffset": 12}, {"referenceID": 35, "context": "SUN397 Experiments: SUN397 [37] is a challenging scene classification benchmark [35] with 397 scene classes and more than 100 images per class.", "startOffset": 27, "endOffset": 31}, {"referenceID": 33, "context": "SUN397 Experiments: SUN397 [37] is a challenging scene classification benchmark [35] with 397 scene classes and more than 100 images per class.", "startOffset": 80, "endOffset": 84}, {"referenceID": 33, "context": "We employed the CNN features extracted with the convolutional neural network (CNN) provided by [35] using Places 205 database.", "startOffset": 95, "endOffset": 99}, {"referenceID": 0, "context": "(p = 2) (p = 4/3) (p = 8/7) Figure 2: Plots of matrices log(1 + |\u0398|) (rescaled to [0,1] and diagonal entries removed since they reflect high similarity of a task with itself, which is obvious) computed by our solver FMTLp-S for the SUN397 data set for different p-norms, with cross-validated hyper-parameter values.", "startOffset": 82, "endOffset": 87}, {"referenceID": 16, "context": "Our approach FMTL2-S is 7 times faster that OKL [17] and 4.", "startOffset": 48, "endOffset": 52}, {"referenceID": 17, "context": "3 times faster than ConvexOKL [18] when the number of tasks is maximum.", "startOffset": 30, "endOffset": 34}], "year": 2015, "abstractText": "The paradigm of multi-task learning is that one can achieve better generalization by learning tasks jointly and thus exploiting the similarity between the tasks rather than learning them independently of each other. While previously the relationship between tasks had to be user-defined in the form of an output kernel, recent approaches jointly learn the tasks and the output kernel. As the output kernel is a positive semidefinite matrix, the resulting optimization problems are not scalable in the number of tasks as an eigendecomposition is required in each step. Using the theory of positive semidefinite kernels we show in this paper that for a certain class of regularizers on the output kernel, the constraint of being positive semidefinite can be dropped as it is automatically satisfied for the relaxed problem. This leads to an unconstrained dual problem which can be solved efficiently. Experiments on several multi-task and multi-class data sets illustrate the efficacy of our approach in terms of computational efficiency as well as generalization performance.", "creator": "LaTeX with hyperref package"}}}