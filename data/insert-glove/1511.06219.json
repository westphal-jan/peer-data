{"id": "1511.06219", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Knowledge Base Population using Semantic Label Propagation", "abstract": "tutting A crucial -105 aspect of nydam a knowledge base bromance population idents system that extracts buz\u0103u new facts from 263.3 text corpora, is the schermerhorn generation of patinoire training data woggle for its relation gorby extractors. re-align In this paper, we gimmicky present 15,500 a framerate method cachin that maximizes 99.59 the kamui effectiveness of newly 17.45 trained 27.72 relation extractors barroca at a minimal annotation cost. Manual labeling badran can depressurize be significantly chandeliered reduced flared by Distant kovel Supervision, 76.51 which ramamurthy is a teera method openwave to top-twenty construct training data telepaths automatically mckneely by socinian aligning yumashev a large sandaled text goneva corpus bundesanstalt with penalizing an existing vatatzes knowledge votron base characterizes of symmocidae known h\u1ea3o facts. For raou example, single-cylinder all neerwinden sentences mentioning elia both ' Barack banishes Obama ' and ' cityview US ' may suppositories serve schnider as thienthong positive training instances for the alderete relation born_in (robl subject, incapacity object ). 55-million However, wraiths distant supervision ufd typically results kastor in talwar a highly 3.8-mile noisy training set: many 48-16 training sentences handicapper do lecithin not really vaishnavism express the bastn\u00e4site intended sellier relation. We krajina propose to basemen combine distant rakeysh supervision bograd with minimal 35.01 manual supervision berndtson in unhappy a technique caissons called bernocchi feature labeling, to willis eliminate noise tchoukball from objetivo the fourth-category large retinas and kendall noisy 21-man initial training near-sighted set, correspondence resulting cillian in 62kg a significant increase of precision. We limosa further iturra improve on this approach pannick by introducing caymanian the Semantic boota Label blurriness Propagation compatriotic method, s\u00edlvio which uses teems the karmin similarity between low - dimensional representations of earthier candidate matsys training goligoski instances, hawkes to controller extend the training service set in oedipus order d\u0119bnica to physio increase spp recall kc-130j while maintaining kobylin high precision. regione Our haitong proposed 793 strategy iambic for generating training ratey data elizabeth is studied and warrendale evaluated on an established vartanian test collection gamtoos designed aliker for jesup knowledge poisoned base njit population tasks. The webjet experimental results insurgencies show 61-21 that the Semantic Label Propagation dunsky strategy leads to substantial 199.2 performance gains hesitant when compared to existing 50.2 approaches, narcy while requiring half-page an 57.29 almost brorson negligible telepresence manual saro-wiwa annotation effort.", "histories": [["v1", "Thu, 19 Nov 2015 15:51:31 GMT  (938kb,D)", "http://arxiv.org/abs/1511.06219v1", "Submitted to Knowledge Based Systems, special issue on Knowledge Bases for Natural Language Processing"], ["v2", "Thu, 3 Mar 2016 11:52:14 GMT  (613kb,D)", "http://arxiv.org/abs/1511.06219v2", "Submitted to Knowledge Based Systems, special issue on Knowledge Bases for Natural Language Processing"]], "COMMENTS": "Submitted to Knowledge Based Systems, special issue on Knowledge Bases for Natural Language Processing", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["lucas sterckx", "thomas demeester", "johannes deleu", "chris develder"], "accepted": false, "id": "1511.06219"}, "pdf": {"name": "1511.06219.pdf", "metadata": {"source": "CRF", "title": "Knowledge Base Population using Semantic Label Propagation", "authors": ["Lucas Sterckx", "Thomas Demeester", "Johannes Deleu", "Chris Develder"], "emails": ["lucas.sterckx@intec.ugent.be"], "sections": [{"heading": null, "text": "A crucial aspect of a knowledge base population system that extracts new facts from text corpora, is the generation of training data for its relation extractors. In this paper, we present a method that maximizes the effectiveness of newly trained relation extractors at a minimal annotation cost. Manual labeling can be significantly reduced by Distant Supervision, which is a method to construct training data automatically by aligning a large text corpus with an existing knowledge base of known facts. For example, all sentences mentioning both \u2018Barack Obama\u2019 and \u2018US\u2019 may serve as positive training instances for the relation born in(subject,object). However, distant supervision typically results in a highly noisy training set: many training sentences do not really express the intended relation. We propose to combine distant supervision with minimal manual supervision in a technique called feature labeling, to eliminate noise from the large and noisy initial training set, resulting in a significant increase of precision. We further improve on this approach by introducing the Semantic Label Propagation method, which uses the similarity between low-dimensional representations of candidate training instances, to extend the training set in order to increase recall while maintaining high precision. Our proposed strategy for generating training data is studied and evaluated on an established test collection designed for knowledge base population tasks. The experimental results show that the Semantic Label Propagation strategy leads to substantial performance gains when compared to existing approaches, while requiring an almost negligible manual annotation effort.\nKeywords: Relation Extraction, Knowledge Base Population, Distant Supervision, Active Learning, Semi-supervised learning\n\u2217Corresponding author Email address: lucas.sterckx@intec.ugent.be (Lucas Sterckx)\nPreprint submitted to Knowledge Based Systems September 25, 2017\nar X\niv :1\n51 1.\n06 21\n9v 1\n[ cs\n.C L\n] 1\n9 N\nov 2\n01 5"}, {"heading": "1. Introduction", "text": "In recent years we have seen significant advances in the creation of large-scale Knowledge Bases (KBs), databases containing millions of facts about persons, organizations, events, products, etc. Examples include Wikipedia-based KBs (e.g., YAGO [1], DBpedia [2], and Freebase [3]), KBs generated from Web documents (e.g., NELL [4], PROSPERA[5]), or open information extraction approaches (e.g., TextRunner [6], PRISMATIC [7]). Besides academic projects, several commercial projects were initiated by major corporations like Microsoft (Satori1), Google (Knowledge Graph [8]), Facebook2, Walmart [9] and others. This is driven by a wide variety of applications for which KBs are increasingly found to be essential, e.g., digital assistants, or for enhancing search engine results with semantic search information.\nBecause KBs are often manually constructed, they tend to be incomplete. For example, 78.5% of persons in Freebase have no known nationality [10]. To complete a KB, we need a Knowledge Base Population (KBP) system that extracts information from various sources, of which a large fraction comprises unstructured written text items [8]. A vital component of a KBP system is a relation extractor to populate a target field of the KB with facts extracted from natural language. Relation extraction (RE) is the task of assigning a semantic relationship between (pairs of) entities in text. There are two categories of RE systems: (i) closed-schema IE systems extract relations from a fixed schema or for a closed set of relations, while (ii) open domain IE systems extract relations defined by arbitrary phrases between arguments. We focus on the completion of KBs with a fixed schema, i.e., closed IE systems.\nEffective approaches for closed schema RE apply some form of supervised or semi-supervised learning [11, 12, 13, 14, 15, 16] and generally follow three steps: (i) sentences expressing relations are transformed to a data representation, e.g., features are constructed to be used in feature-based methods, (ii) a binary or multi-class classifier is trained from positive and negative instances, and (iii) the model is then applied to new or unseen instances.\nSupervised systems are limited by the availability of expensive training data. To counter this problem, the technique of iterative bootstrapping has been proposed [17, 18], in which an initial seed set of known facts is used to learn patterns, which in turn are used to learn new facts and incrementally extend the training set. These bootstrapping approaches suffer from semantic drift and are highly dependent on the initial seed set.\n1https://blogs.bing.com/search/2013/03/21/understand-your-world-with-bing 2http://www.insidefacebook.com/2013/01/14/\nWhen an existing KB is available, a much larger set of known facts can be used to bootstrap training data, a procedure known as Distant Supervision (DS). DS automatically labels its own training data by heuristically aligning facts from a KB with an unlabeled corpus. The KB, written as D, can be seen as a collection of relational tables r(e1, e2), in which r \u2208 R (R is the set of relation labels), and < e1, e2 > is a pair of entities that are known to have relation r. The corpus is written as C.\nThe intuition underlying DS is that any sentence in C which mentions the same pair of entities (e1 and e2), expresses a particular relationship r\u0302 between them, which most likely corresponds to the known fact from the KB, r\u0302(e1, e2) = r(e1, e2), and thus forms a positive training example for an extractor of relation r. DS has been successfully applied in many relation extraction tasks [19, 20] as it allows for the creation of large training sets with little or no human effort.\nEqually apparent from the above intuition, however, is the danger of finding incorrect examples for the intended relation. The heuristic of accepting each co-occurrence of the entity pair < e1, e2 > as a positive training item because of the KB entry r(e1, e2), is known to generate noisy training data or false positives [21], i.e., two entities co-occurring in text are not guaranteed to express the same relation as the field in the KB they were generated from. The same goes for the generation of negative examples: training data consisting of facts missing from the KB are not guaranteed to be false since a KB in practice is highly incomplete. An illustration of DS generating noisy training data is shown in Figure 1.\nSeveral strategies have been proposed to reduce this noise. The most prominent is that of latent variable models of the distantly supervised data that make the assumption that a known fact is expressed at least once in the corpus [21, 22, 23]. These methods are cumbersome to train and are sensitive to initialization parameters of the model.\nAn active research direction is the combination of DS with partial supervision, as was proposed in several recent works which differ in the way this supervision is chosen and included. Some focus on active learning, selecting training instances to be labeled according to an uncertainty criterion [24, 19], while others focus on annotations of surface patterns and define rules or guidelines in a semi-supervised learning setting [25]. Existing methods for fusion of distant and partial supervision require thousands of annotations and hours of manual labor for minor improvements. In this work we start from a distantly supervised training set and show that, using minimal supervision, we can reduce noise in the training data and boost extraction performance. We will demonstrate how only a couple of minutes of annotation time per relation suffices to strongly reduce noise, and obtain significant improvements in precision and recall of the extracted relations.\nWe define the following research questions:\nRQ 1. How can we add supervision most effectively to reduce noise and optimize relation extractors?\nRQ 2. Can we combine semi-supervised learning and dimension reduction techniques to further enhance the quality of the training data and obtain state-of-the-art results using minimal manual supervision?\nWith the following contributions, we provide answers to these research questions:\n1. In answer to RQ 1, we demonstrate the effectiveness and efficiency of filtering training data based on\nhigh-precision trigger patterns. These are obtained by training initial weak classifiers and manually labeling a small amount of features chosen according to an active learning criterion.\n2. We tackle RQ 2 by proposing a semi-supervised learning technique that allows extending an initial\nset of high-quality training instances with weakly supervised candidate training items by measuring their similarity in a low-dimensional semantic vector space. This technique is called Semantic Label Propagation.\n3. We evaluate our methodology on test data from the English Slot Filling (ESF) task of the Knowledge\nBase Population at the 2014 Text Analysis Conference. We compare different methods by using them in an existing KBP system. Our relation extractors attain state-of-the-art effectiveness (a micro averaged F1 value of 36%) while relying on a very low manual annotation cost (i.e., 5 minutes per relation).\nIn Section 2 we give an overview of existing supervised and semi-supervised RE methods and highlight their remaining shortcomings. Section 3 describes our proposed methodology, with some details on the DS\nstarting point (Section 3.1), the manual feature annotation approach (Section 3.2), and the introduction of the semantic label propagation method (Section 3.3). The experimental results are given in Section 4, followed by some conclusions in Section 5."}, {"heading": "2. Related Work", "text": "The key idea of our proposed approach is to combine distant supervision with a minimal amount of supervision, i.e., requiring as few (feature) annotations as possible. Thus, our work is to be framed in the context of supervised and semi-supervised relation extraction (RE), and related to approaches designed to minimize the annotation cost, e.g., active learning. Furthermore, we use compact vector representations carrying semantics, i.e., so-called word embeddings. Below, we therefore briefly summarize related work in the areas of (i) supervised RE, (ii) semi-supervised RE, (iii) active learning, and (iv) word embeddings."}, {"heading": "2.1. Supervised Relation Extraction", "text": "Supervised RE methods rely on training data in the form of sentences tagged with a label indicating the presence or absence of the considered relation. There are three broad classes of supervised RE: (i) feature based methods, (ii) kernel based methods, and (iii) convolutional neural nets.\nFeature based methods [14, 26] extract a rich list of structural, lexical, syntactic and semantic features to represent the given relation mentions. These features are cues for the decision whether the relation is present or not. Afterwards a classifier is trained on positive and negative examples. In contrast, kernel based methods [27, 28, 16] represent each relation mention as an object such as an augmented token sequences or a parse tree, and use a carefully designed kernel function, e.g., subsequence kernel or a convolution tree kernel, to calculate their similarity with test patterns. These objects are usually augmented with extra features such as semantic information. With the recent success of deep neural networks in NLP, Convolutional Neural Networks (CNNs) have emerged as effective relation extractors [29, 30]. CNNs avoid the need for preprocessing and feature design by transforming tokens into dense vectors using embeddings of words. Lexical and sentence-level features are extracted using deep neural nets. Finally, the features are fed into a soft-max classifier to predict the relationship between two marked nouns.\nSupervised approaches all share the need for training data, which is expensive to obtain. Two common methods have emerged for the generation of large quantities of training data, and both require an initial set of known instances. When this number is initially small, the technique of bootstrapping is used. When a very\nlarge number of instances is available from an existing knowledge base, distant supervision is the preferred technique. Both are briefly discussed below."}, {"heading": "2.1.1. Bootstrapping models for Relation Extraction", "text": "When a limited set of labeled instances is available, bootstrapping methods have proven to be effective methods to generate high-precision relation patterns [17, 18, 31, 32]. The objective of bootstrapping is to expand an initial \u2018seed\u2019 set of instances with new relationship instances. Documents are scanned for entities from the seed instances and linguistic patterns connecting them are extracted. Patterns are then ranked according to coverage (recall) and low error rate (precision). Using the top scoring patterns, new seed instances are extracted and the cycle is repeated.\nAn important step in bootstrapping methods is the calculation of similarity between new patterns and the ones in the seed set. This measure decides whether a new pattern is relation oriented or not, based on the existing set. Systems use measures based on exact matches [31], cosine-similarity [17] or kernels [32]. A fundamental problem of these methods is semantic drift [33, 34]: bootstrapping, after several iterations, deviates from the semantics of the seed relationship and extracts unrelated instances which in turn generate faulty patterns. This phenomenon gets worse with the number of iterations of the bootstrapping process.\nRecently, Batista et al. [35] proposed the use of word embeddings for capturing semantic similarity between patterns. Contexts are modeled using linear combinations of the word embeddings and similarity is measured in the resulting space. This approach has shown to reduce semantic drift compared to previous similarity measures."}, {"heading": "2.1.2. Distant Supervision", "text": "Distant Supervision (DS) was first proposed in [36], where labeled data was generated by aligning instances from the Yeast Protein Database into research articles to train an extractor. This approach was later applied for training of relation extractors between entities in [10].\nAutomatically gathering training data with DS is governed by the assumption that all sentences containing both entities engaged in a reference instance of a particular relation, represent that relation. Many methods have been proposed to reduce the noise in training sets from DS. In a series of works the labels of DS data are seen as latent variables. Riedel et al. [21] relaxed the strong all sentences-assumption and relaxed it to an at-least-one-sentence-assumption, creating a Multi-Instance learner. Hoffman et al. [37] modified this model by allowing entity pairs to express multiple relations, resulting in a Multi-Instance Multi-Label\nsetting (MIML-RE). Surdeanu et al. [23] further extended this approach and included a secondary classifier, which jointly modeled all the sentences in texts and all labels in knowledge bases for a given entity pair.\nOther methods apply heuristics [38], model the training data as a generative process [39, 40] or use a low-rank representation of the feature-label matrix to exploit the underlying semantic correlated information."}, {"heading": "2.2. Semi-supervised Relation Extraction", "text": "Semi-supervised Learning is situated between supervised and unsupervised learning. In addition to unlabeled data, algorithms are provided with some supervised information. The training data comprises labeled instances Xl = (x1 . . . xl) for which labels Yl = (y1 . . . yl) are provided, and typically a large set of unlabeled ones Xu = (x1 . . . xu).\nSemi-supervised techniques have been applied to RE on several occasions. Chen et al. [41] apply Label Propagation by representing labeled and unlabeled examples as nodes and their similarities as the weights of edges in a graph. In the classification process, the labels of unlabeled examples are then propagated from the labeled to unlabeled instances according to similarity. Experimental results demonstrate that this graph-based algorithm can outperform SVM in terms of F1 when very few labeled examples are available. Sun et al. [15] show that several different cluster-based features trained on large corpora can improve the RE effectiveness.\nZhang et al. [42] compare DS and complete supervision as training resources but do not attempt to fuse them. They observe that distant supervision systems are often recall gated: to improve distant supervision quality, large input collections are needed. They also report modest improvements by adding crowd-sourced yes/no votes to the training instances. Training instances were selected ad random as labeling using active learning criteria did not affect performance significantly.\nAngeli et al. [24] show that providing a relatively small number of mention-level annotations can improve the accuracy of MIML-RE. They introduce an active learning criterion for the selection of instances incorporating both the uncertainty and the representativeness, and show that the choice of criterion is important. The MIML-RE model of Surdeanu et al. [23] marginally outperforms the Mintz++ baseline using solely distant supervision, initialization of the latent variables using labeled data is needed for larger improvements. For this, a total of 10, 000 instances were labeled having a 3% increase on the micro-F1 .\nGuided Distant Supervision, proposed by Pershina et al. [25], incorporates labeled patterns and trigger words to guide MIML-RE during training. They make use of a labeled dataset from TAC KBP to extract training guidelines, which are intended to generalize across many examples.\nThe top performing KBP ESF system [43, 44] used DS and the manual labeling of 100, 000 features. After initial DS, features are manually labeled and only pairs associated with labeled features are used as positive examples. This approach has proven to be very effective but further investigation is needed to reduce the amount of feature labeling. Here, we show how we can reduce this effort while maintaining high precision."}, {"heading": "2.3. Active Learning and Feature Labeling", "text": "Active learning is used to reduce the amount of supervision required for effective learning. The most popular form of active learning is based on iteratively requiring manual labels for the most informative instances, an approach called uncertainty sampling. In relation extraction, typical approaches include queryby-committee [24, 45] and cluster-based sampling [46]. While the focus in RE has been on labeling relation instances, alternative methods have been proposed in other tasks in which features (e.g., patterns, or the occurrence of terms) are labeled as opposed to instances [47, 48], resulting in a higher performance for less supervision.\nGetting positive examples for certain relations can be hard, especially when training data is weakly supervised. Standard uncertainty sampling is ineffective in this case: it is likely that a feature or instance has a low certainty score because it does not carry much discriminative information about the classes. Assigning labels to the most certain features has much greater impact on the classifier and can remove the principle sources of noise. This approach has been coined as Feature Certainty[48], and we show that this approach is especially effective in DS for features which generalize across many training instances."}, {"heading": "2.4. Distributional Semantics", "text": "The Distributional Hypothesis [49] states that words that tend to occur in similar contexts are likely to have similar meanings. Representations of words as dense vectors (as opposed to the standard one-hot vectors), called word embeddings, exploit this hypothesis and are trained from large amounts of unlabeled data on predicting their context. Representations for words will be similar to those of related words, allowing the model to generalize better to unseen events. The resulting vector space is also called a vector model of meaning [50]. Common methods for generating very dense, short vectors use dimensionality reduction techniques (e.g., singular value decomposition) or neural nets to create so-called word embeddings. Word embeddings have proven to be beneficial for many Natural Language Processing tasks including POStagging, machine translation and semantic role labeling. Common unsupervised word embedding algorithms\ninclude Word2Vec [51] and GloVe [52]. These models are inspired by neural networks and are trained using stochastic gradient training.\nWhile much research has been directed at ways of constructing distributional representations of individual words, for example co-occurrence based representations and word embeddings, there has been far less consensus regarding the representation of larger constructions such as phrases and sentences from these representations. Blacoe et al. [53] show that, for short phrases, a simple composition like addition or multiplication of the distributional word representations is competitive with more complex supervised models such as recursive neural networks (RNNs)."}, {"heading": "3. Labeling Strategy for Noise Reduction", "text": "In this section we introduce our strategy to combine distantly supervised training data with minimal amounts of supervision. Shortly stated, we designed our labeling strategy such as to minimize the amount of false positive instances or noise while maintaining the diversity of relation expressions generated by DS.\nWe perform a highly selective form of noise reduction starting from a fully distantly supervised relation extractor, described in Section 3.1, and use the feature weights of this initial extractor to guide manual supervision in the feature space. Various questions arise from this. When do we over-constrain the original training set generated by distant supervision? What is the trade-of between the application of distant supervision with highly diverse labeled instances, and the constraining approach of labeling features, with a highly accurate yet restricted set of training data? This is discussed in detail in Sections 3.2 and 3.3.\nMore concretely, our approach is depicted in Figure 2, and comprises the following steps:\n(1) An existing KB is used to generate distantly supervised training instances by matching its facts with\nsentences from a large text corpus. We discuss the characteristics of this weakly labeled training set as well as the features extracted from each sentence (see Section 3.1).\n(2) An initial relation extractor is trained using the noisy training data generated in step (1).\n(3) Confident positive features learned by this initial classifier are presented to an annotator with knowl-\nedge of the semantics of the relation and labeled as true positive or false positive. Feature confidence is quantified with an active learning criterion.\n(4) The collection of training instances is filtered according to the labeled features and a second classifier\nis trained. This framework, in which we combine supervision and DS, is explained in Section 3.2.\n(5) In a semi-supervised step, the filtered distantly supervised training data is added to training data by\npropagating labels from labeled features to distantly supervised instances based on similarity in a semantic vector space of reduced dimension. The technique is presented in 3.3 as Semantic Label Propagation.\n(6) A final relation extractor is trained from the augmented training set. We evaluate and discuss results\nof the proposed techniques in Section 4."}, {"heading": "3.1. Distantly Supervised Training Data", "text": "The English Gigaword corpus [54] is used as unlabeled text collection to generate relation mentions. The corpus consists of 1.8 million news articles published between January 1987 and June 2007. Articles are first preprocessed using different components of the Stanford CoreNLP toolkit [55], including sentence segmentation, tokenizing, POS-tagging, Named Entity Recognition, and clustering noun phrases which refer to the same entity.\nAs KB we use a snapshot of Freebase (now Wikidata) from May 2013. The relation schema of Freebase is mapped to that used for evaluation, the NIST TAC KBP ESF Task, which defines 41 relations, including 25 relations with a person as subject entity and 16 with organizations as subject. 26 relations require objects or fillers that are themselves entities (e.g., Scranton as place of birth of Joe Biden), whereas others require string-values (e.g., profession (Senator, Teacher, . . . ), cause of death (Cancer, Car Accident,. . . )).\nWe perform weak Entity Linking between Freebase Entities and textual mentions using simple string matching. We reduce the effect of faulty entity links by removing the most frequently occurring entities from the training data (e.g., John Smith, Robert Johnson . . . ).\nFor each generated pair of mentions, we compute various lexical, syntactic and semantic features. Table 1 shows an overview of all the features applied for the relation classification. We use these features in a binary Logistic Regression classifier. Features are illustrated for an example relation-instance <Ray Young, General Motors> and the sentence \u201cRay Young, the chief financial officer of General Motors, said GM could not bail out Delphi\u201d.\nFor each relation Ri, we generate a set of (noisy) positive examples denoted as R+i and defined as\nR+i = { (m1,m2) | Ri(e1, e2) \u2227 EL(e1,m1) \u2227 EL(e2,m2) }\nwith e1 and e2 being subject and object entities from the KB and EL(e1,m1) being the entity e1 linked to mention m1 in the text. As in previous work [56, 37], we impose the constraint that both entity mentions (m1,m2) \u2208 R+i are contained in the same sentence. To generate negative examples for each relation, we sample instances from co-occurring entities for which the relation is not present in the KB.\nWe measured the amount of noise, i.e., false positives, in the training set of positive DS instances, by manually verifying 2,000 randomly chosen instances each for a selection of relations. Table 2 shows the fraction of noise for these relations, which strongly varies among relations, ranging from 12% to 99%."}, {"heading": "3.2. Labeling High Confidence Shortest Dependency Paths", "text": "This section describes the manual feature labeling step that allows transforming a full DS training set\ninto a strongly reduced yet highly accurate training set, based on manual feature labeling.\nIn this step, we focus on a particular kind of feature, i.e., a relation\u2019s Shortests Dependency Path (SDP). Dependency paths have empirically been proven to be very informative for relation extraction, their capability in capturing a lot of information is evidenced by a systematic comparison in effectiveness of different kernel methods [57] or as features in feature-based systems [14]. This was originally proposed by Bunescu et al. [16] who claimed that the relation expressed by a sentence is often captured in the shortest path connecting the entities in the dependency graph. Figure 3 shows an example of an SDP for a sentence expressing a relation between a person and a city of residence.\nAs shown earlier in Table 2, the fraction of false positive items among all weakly supervised instances can be very large. Labeling features based on the standard active learning approach of uncertainty sampling\nis ineffective in our case since it is likely that a feature or instance has a low certainty score simply because not much discriminative information about the classes is carried. Annotating many such instances would be a waste of effort. Assigning labels to the most certain features has much greater impact on the classifier and can remove the principal sources of noise. This approach is called Feature Certainty Sampling [48]. It is intuitively an attractive method, as the goal is to reduce the most influential sources of noise as fast as possible. For example for the relation founded by there are many persons that founded the company which are also top members, leading to instances that we wish to remove when cleaning up the training data for the relation founded by.\nSDPs offer all the information needed to assess the relationship validity of the training instances, are easily labeled, and generalize over a considerable fraction of the training set as opposed to many of the feature-unigrams which remain ambiguous in many cases. We implement the feature certainty idea by ranking SDP features according to the odds that they correspond to valid relation instances. This corresponds to ranking by the following quantity, which we call the considered SDP\u2019s confidence\nConfidence(SDP ) = P (SDP |+) P (SDP |\u2212) . (1)\nThe confidence can be estimated for each feature from the original distant supervision training set, based on their (smoothed) occurrence frequencies among the positive and negative instances, as the parameters of a\nNaive Bayes classifier.\nAll dependency paths are ranked from most to least confident and the top-k are assigned to a human annotator to select the true positive SDPs. The annotator is asked to select only the patterns which unambiguously express the relation. That is, a pattern is accepted only if the annotator judges it a sufficient condition for that relation. The annotator is provided with several complete sentences containing the dependency path to this cause. When the SDP does not include any verbs, e.g., when entities are both part of the same Noun Phrase like \u201cMicrosoft CEO Bill Gates\u201d, all words between the subject and object are included and the complete path is added to the filter set. We limit the time of annotation to a minimal effort of 5 minutes for each relation. On average annotators were able to label around 250 SDPs per relation this way. The ease of annotating SDPs becomes apparent when comparing with annotating random relation instances, which they managed to do at a rate of only 100 in the same period of time.\nThe motivation behind limiting the annotation time per relation to only a few hundred patterns comes from the following analysis. First of all, a small subset of all different patterns are responsible for the majority of relation instances in the DS training set. In fact, the sparsity of Distantly Supervised training data becomes apparent when extracting all SDPs for each fact in the KB in one pass over the corpus. Figure 4a shows the approximately Zipfian distribution of the frequency of the dependency paths generated by DS in the positively labeled training set for several example relations. The abscis shows the rank of dependency paths for various relations, sorted from most to least frequent, normalized by the total number of paths for the respective relations (to allow visualization on the same graph). In line with our goal of getting a highly accurate training set with the largest sources of noise filtered away at a low annotation cost, we need to focus on capturing those top most frequent patterns. Secondly, we noticed that beyond the first few hundred most confident SDPs, which take around 5 minutes to annotate, further true positives tend to occur less frequently. Annotating many more SDPs would only marginally increase the diversity in the training set, at a rapidly increasing annotation cost. Figure 4b illustrates the occurrence of true positive patterns for decreasing confidence scores. For several example relations, the figure shows the true positive patterns as markers on the confidence distribution of the 1, 000 most confident SDPs.\nFinally, using the manually selected set of SDPs, the complete training set is filtered by enforcing that one of these SDPs be present in the feature set of the instance. We include all mention pairs associated with that feature as positive examples of the considered relation. The classifier trained on the resulting training set is intuitively of high precision but doesn\u2019t generalize well to unseen phrase constructions. Note that the classifier is quite different from a regular pattern based relation extractor. Although all training instances\nsatisfy at least one of the accepted SDPs, the classifier itself is trained on a set of features including, but not restricted to, these SDPs (see Table 1). Still, most of the benefits of DS are lost by having the selection of training instances governed by a limited set of patterns.\nThe fourth column of Table 2 lists the fraction of training data remaining after filtering out all patterns apart from those classified as indicative of the relation at hand. The amount of training data remaining after this filtering step strongly depends on the specific relation, varying from less than 1% to more than half of the original training set. Yet on the whole, the filtering results in a strong reduction of the purely DS-based training data, often removing much more than the actual fraction of noise (column 2). For example, for the relation per:employee or member of, there is a fraction of only 12.2% false positives, whereas the manual filtering leads to discarding 83.5% of the DS instances.\nThe strategy described in the previous paragraphs is related to the guidelines strategy from Pershina et al. [25] (without the MIML model) in labeling features, but it differs in some essential aspects. Instead of needing a fully annotated corpus to do so, we rank and label features entirely based on distant supervision.\nLabeling features based on a fully labeled set ignores the variety of DS and risks being biased towards the smaller set of labeled instances. Also, no selection criteria were applied when choosing which features to label, making the process even more efficient."}, {"heading": "3.3. Noise Reduction using Semantic Label Propagation", "text": "If we strictly follow the approach proposed in Section 3.2 and only retain DS training instances that satisfy an accepted SDP, an important advantage of DS is lost, namely its potential of reaching high recall. If we limit the feature annotation effort, we risk losing highly valuable SDPs. To counteract this effect, we introduce a second (re)labeling stage, adopting a semi-supervised learning (SSL) strategy to expand the training set. This is done by again adding some instances from the set of previously discarded DS instances with SDPs not matching any of the manually labeled patterns. We rely on the basic SSL approach of selftraining by propagating labels from known instances to the nearest neighboring unlabeled instances. This algorithm requires a method of determining the distance between labeled and unlabeled instances. Dangers of self-training include the failure to expand beyond the initial training data or the introduction of errors into the labeled data. In order to avoid an overly strong focus on the filtered training data, we use low-dimensional vector representations of words, also called word embeddings.\nWord embeddings allow for a relaxed semantic matching between the labeled seed patterns and the remaining weakly labeled patterns. As shown by Sterckx et al. [46], representing small phrases by summing\neach individual word\u2019s embedding leads to semantic representations of small phrases that are meaningful for the goal of relation extraction.\nWe represent each relation instance by a single vector by averaging the embeddings of the words in the\ndependency path. For example, consider the sentence:\nVincent Willem van Gogh was born in Groot-Zundert\nwhich has the following SDP,\nPER appos\u2190\u2212\u2212\u2212\u2212 born prep\u2212\u2212\u2212\u2192 in pobj\u2212\u2212\u2212\u2192 LOC.\nIts low-dimensional representation ~C is hence generated as\n~C = E(\u201cborn\u201d) + E(\u201cin\u201d)\n2 ,\nwith E(x) the word embedding of word x. The similarity between a labeled pattern ~Ct and a weakly labeled pattern ~CDS is then measured using cosine similarity between the vector representations.\nSim(~Ct, ~CDS) = ~Ct. ~CDS\n|~Ct|.|~CDS | In the special case that no verbs exist between two entities, all the words between the two entities are used to build the representations for the context vector.\nUsing these low-dimensional continuous representations of patterns, we can calculate similarities between longer, less frequently occurring patterns in the training data and the patterns from the initial seed set which are the most frequently occurring ones. We can now increase recall by adding similar but less frequent patterns.\nMore specifically, we calculate the similarity of the average vector of the labeled patterns (as in the Rocchio classifier type of self-training) with each of the remaining patterns in the DS set and put a threshold on the similarity of patterns to be added to the final training data. We call this technique Semantic Label Propagation. This process is visualized in Figure 5."}, {"heading": "4. Experimental Results", "text": ""}, {"heading": "4.1. Testing Methodology", "text": "We evaluate the relation extractors in the context of an existing Knowledge Base Population system [58, 59] using the NIST TAC KBP English Slot Filling (ESF) Evaluation from 2012 to 2014. We choose for this evaluation because of the diversity and difficulty of entities in the queries.\nIn the end-to-end ESF framework, the input to the system is a given entity (the \u2018query\u2019), a set of relations, and a set of articles. The output is a set of slot fills, where each slot fill is a triple consisting of two entities (including the query entity) and a relation (from among the given relations) predicted to hold among these entities."}, {"heading": "4.2. Knowledge Base Population System", "text": "Systems participating in the TAC KBP ESF need to handle each task of filling missing slots in a KB. Participants are only provided with one surface-text occurrence of each query entity in a large collection of text provided by the organizers. This means that an information retrieval component is needed to provide the relation extractor with sentences containing candidate answers. Our system performs query expansion using Freebase aliases and Wikipedia pages. Each document containing one of the aliases is parsed and named entities are automatically detected. Persons, organizations, and locations are recognized, and locations are further categorized as cities, states, or countries. Non-entity fillers like titles or charges are tagged using lists and table-lookups. For further details of the KBP system we refer to [58, 59]."}, {"heading": "4.3. Pattern-based Restriction vs. Similarity-based Extension", "text": "As seen from Table 2, applying the manually annotated features as described in Section 3.2 often leads to a drastic reduction of training instances, compared to the original weakly labeled training set. Using similarity metrics described in Section 3.3, we again add weakly supervised training data to the filtered data.\nAn important question is therefore, whether there exists an optimal combination of both effects. Intuitively, one would expect a high-precision-low-recall effect in the extreme case of adding no similar patterns, and a low-precision-high-recall effect when adding all weakly labeled patterns, both leading to a suboptimal F1 measure, whereas adding a limited amount of similar patterns may increase recall without harming precision too much. In this section, we investigate for various relations, how the quality of the training set depends on the fraction of top similar patterns to extend it with.\nIn our experimental setup, we start from the training set that only contains the Nfiltered instances that match the manually labeled patterns, gradually adding weakly labeled data, and each time training binary classifiers on the corresponding training set. We chose to let the additional data grow exponentially, which allows studying the effect of adding few extra instances initially, but extending towards the full weakly supervised training set of size NDS in a limited number of cases. More specifically, in K experiments of\nadding additional instances, the intermediate training set size Nk at step k is given by\nApart from studying the addition of varying amounts of similar patterns, in this section we also investigate the influence of the type of similarity measure used. In Section 3.2 we suggested the use of word embeddings, but is there a difference between different types of embeddings? Would embeddings work better than traditional dimension reduction techniques? And would such techniques indeed perform better than the original one-hot vector representations? These questions can be answered by considering several similarity measures. As a classical baseline, we represent SDPs using the average one-hot or Bag-Of-Words (BOW) representations of the words contained in the SDPs. We also transform the set of one-hot representations using Singular Value Decomposition (SVD) [60] fitted on the complete trainingset. For representations using the summed average of word embeddings described in Section 3.3, we use two sets of pre-trained Word2Vec embeddings1 (trained on news text) and GloVe embeddings2 (trained on Wikipedia text).\nFigure 7 shows the effect of adding different amounts of weakly labeled data, for different values of k as in eq. 2 (with K = 10 steps) and for similarity measures based on the different types of representations\n1https://code.google.com/p/word2vec/ 2http://nlp.stanford.edu/projects/glove/\ndescribed above. Six frequently occurring relations were selected such that they give an idea of the various forms of behavior that we observed during our investigation of all extracted relations. The chosen effectiveness measure is the optimal F1 value of classification on a development set, consisting of training data from 2012 and 2013. In the next Section we evaluate on a held-out test set, which consists of queries from the 2014 TAC ESF task, whereby the optimal value of k and type of dimension reduction is selected based on the development set. Also shown are standard deviations on these optimal F1 -values, obtained by resampling different positive and negative instances for training the classifier.\nSeveral insights can be gained from Fig. 7. We observe that the effect of expanding the initial training set is strongly dependent on the specific relation and the quality of the initial training data. In many cases training data filtered using highly confident SDPs (k = 0) generates a better relation extractor than pure DS (k = K). This holds for all shown relations, except for the age relation. We have to be aware that wrongly annotating an important pattern, or by chance missing any in the top most confident ones, can strongly reduce recall when only using the accepted SDPs. Adding even a small amount of similar patterns may hence result in a steep increase in effectiveness, such as for k = 1 in the age and country of headquarters relations. When relaxing the filtering (for increasing k) by adding unlabeled data, the optimal F1 tends to increase until a certain point, and then again drops towards the behavior of a fully DS training set, because the quality or similarity of the added training data declines and too many false positives are re-introduced. The threshold on the amount of added DS instances is thus an important parameter to tune on a development set. For part of the relations there is an optimal amount of added unlabeled data, whereas other relations show no clear optimum and fluctuate between distant and filtered classifiers\u2019 values. The use of word embeddings often leads to an improved maximum F1 -value with respect to the BOW-representations or SVD-based dimension reduction. This is for example very clear for the charges, city of headquarters, or cities of residence relations, with a slight preference of the GloVe embeddings with respect to Word2Vec for this application. However, we also noticed that word embeddings are not always better than the BOW or SVD based representations. For example, the highest optimal F1 for the age relation is reached with the BOW model."}, {"heading": "4.4. End-to-End Knowledge Base Population Results", "text": "This section presents the results of training binary relation classifiers according to our new strategy for each of the 41 relations of the TAC KBP schema. We tuned hyperparameters on data of the 2012 and 2013 tracks and now test on the last edition of the ESF track of 2014.\nNext to the thresholds of choosing the amount of unlabeled data added as discussed previously, other\nparameters include regularization and the ratio between positive and negative instances, which appeared to be an important parameter influencing the confidence of an optimal F1 -value greatly. We use the official TAC KBP evaluation script which calculates the micro-average of all classifications. All methods are evaluated with provenances (the character-offsets in the documents which contain the justification for extraction of the relation) ignored, so as not to penalize any system for finding a new provenance not validated in the official evaluation key. A listing of precision, recall and F1 for the top 20 most frequently occurring relations in the test set is shown in Table 4.\nNext to traditional distant supervision (also known as Mintz++[26], indicated as \u2018Distant Supervision\u2019 in Table 4), we compare our new semi-supervised approach (\u2018Semantic Label Propagation\u2019) to a fully supervised classifier trained by manually labeling 50, 000 instances chosen uniformly among the different relations and according to uncertainty sampling criteria (\u2018Fully Supervised\u2019), and to the classifiers obtained by purely filtering on manually labeled patterns (\u2018Pattern Filtered\u2019). We also use the fully supervised classifiers in a traditional self-training scheme, classifying distantly supervised instances in the complete feature space and adding confident instances to the training set (\u2018Self-Training (Instances)\u2019). The amount of supervision needed for these classifiers required far more annotation effort than the feature certainty sampling of Semantic Label Propagation.\nThe official F1 value of 36.4% attained using Semantic Label Propagation is equivalent with the second best entry out of eighteen submissions to the 2014 ESF track [19]. A relation extractor is but a part of a KBP system and is influenced by each of the other modules (e.g., recognition and disambiguation of named entities), which makes comparison with other systems is hard. This is the case for the absolute values of\nTable 4, but still, it demonstrates the overall quality of our relation extractors. Especially, our system relying on very limited annotations has a competitive place among systems that rely on many hours of manual feature engineering [43]. Comparing the results for Semantic Label Propagation with the other approaches shows that the proposed method combining a small labeling effort based on feature certainty, with the Semantic Label Propagation technique, outperforms the DS method, semi-supervision using instance labeling, and full supervision methods. This is also confirmed in Fig. 8, which shows the trade-off between the precision and recall averaged over all TAC KBP relations for the different methods described above, using the TAC KBP evaluation script, by varying the thresholds on classification.\nTa bl\ne 4:\nR es\nul ts\nfo rF\nre qu\nen tR\nel at\nio ns\nan d\nof fic\nia lT\nA C\n-s co\nre r\nD is\nta nt\nSu pe\nrv is\nio n\n(M in\ntz ++\n) SD\nP Fi\nlte re\nd Fu\nlly Su\npe rv\nis ed\nSe lf-\nTr ai\nni ng\n(I ns\nta nc\nes )\nSe m\nan tic\nL ab\nel Pr\nop ag\nat io n R el at io n P R F 1 P R F 1 P R F 1 P R F 1 P R F 1 tit le 22 .3 58 .8 32 .3 36 .1 39 .1 37 .6 28 .0 61 .1 32 .8 36 .5 43 .2 39 .6 43 .5 48 .5 43 .5\nto p\nm em\nbe rs\nem pl\noy ee\ns 50\n.6 63\n.4 56\n.3 51\n.3 63\n.4 47\n.3 62\n.6 53\n.9 59\n.7 56\n.3 63\n.4 59\n.7 63\n.5 62\n.5 63\n.0\nem pl\noy ee\nor m\nem be\nr of\n31 .4\n34 .0\n32 .7\n33 .8\n51 .0\n40 .6\n23 .5\n45 .7\n28 .8\n32 .2\n40 .4\n35 .8\n36 .0\n51 .0\n36 .1\nag e\n71 .6\n72 .5\n72 .0\n75 .6\n70 .0\n72 .7\n68 .0\n62 .5\n64 .9\n76 .0\n73 .6\n70 .0\n71 .7\n82 .5\n75 .0\nor ig\nin 10\n0. 0\n23 .0\n37 .5\n28 .5\n80 .0\n42 .1\n29 .4\n66 .6\n40 .8\n27 .5\n73 .3\n40 .0\n31 .7\n86 .6\n46 .4\nco un\ntr ie\ns of\nre si\nde nc\ne 10\n0. 0\n23 .0\n37 .5\n22 .4\n84 .6\n35 .4\n61 .1\n57 .6\n36 .6\n50 .0\n38 .4\n43 .4\n35 .2\n46 .1\n40 .0\nch ar\nge s\n45 .0\n52 .9\n48 .6\n40 .9\n52 .9\n46 .1\n70 .4\n44 .1\n53 .0\n47 .6\n58 .8\n52 .6\n44 .3\n68 .1\n53 .4\nci tie\ns of\nre si\nde nc\ne 22\n.9 45\n.8 30\n.5 31\n.5 25\n.0 27\n.9 36\n.3 11\n.2 62\n.5 19\n.1 16\n.6 22\n.8 34\n.4 41\n.6 37\n.7\nca us\ne of\nde at\nh 30\n.7 36\n.3 33\n.3 29\n.4 45\n.4 35\n.7 28\n.3 31\n.8 29\n.6 37\n.5 27\n.2 31\n.5 33\n.3 45\n.4 38\n.4\nsp ou\nse 50\n.0 45\n.4 47\n.6 50\n.0 45\n.4 47\n.6 75\n.0 27\n.2 39\n.9 35\n.7 45\n.4 40\n.0 71\n.4 45\n.4 55\n.5\nci ty\nof de\nat h\n10 0.\n0 16\n.6 28\n.5 14\n.2 16\n.6 15\n.3 5.\n21 10\n0. 0\n9. 91\n20 .0\n16 .6\n18 .1\n20 .0\n33 .3\n25 .0\nco un\ntr y\nof he\nad qu\nar te\nrs 22\n.7 41\n.6 29\n.4 62\n.5 41\n.6 50\n.0 10\n0. 0\n50 .0\n25 .0\n33 .3\n25 .0\n40 .0\n10 0.\n0 33\n.3 50\n.0\nda te\nof de\nat h\n66 .6\n50 .0\n57 .1\n66 .6\n50 .0\n57 .1\n50 .0\n25 .0\n33 .0\n66 .6\n50 .0\n57 .1\n66 .6\n50 .0\n57 .1\n(p er\n:) pa\nre nt\ns 37\n.0 50\n.0 42\n.5 42\n.1 40\n.0 41\n.0 37\n.5 15\n.0 21\n.3 34\n.6 45\n.0 39\n.1 40\n.9 45\n.0 42\n.8\n(o rg\n:) al\nte rn\nat e\nna m\nes 20\n.0 28\n.5 23\n.5 18\n.7 85\n.7 30\n.7 20\n.0 28\n.5 23\n.5 16\n.2 85\n.7 27\n.2 19\n.3 85\n.7 31\n.5\nst at\nes or\npr ov\nin ce\ns of\nre si\nde nc\ne 50\n.0 55\n.5 52\n.6 50\n.0 44\n.4 47\n.0 53\n.5 44\n.4 48\n.5 45\n.4 55\n.5 50\n.0 50\n.0 44\n.4 47\n.0\nfo un\nde d\nby 53\n.8 43\n.7 48\n.2 80\n.0 50\n.0 61\n.5 75\n.0 37\n.5 50\n.0 62\n.5 62\n.5 62\n.5 81\n.8 56\n.2 66\n.6\nch ild\nre n\n21 .4\n27 .2\n24 .0\n35 .7\n45 .4\n40 .0\n50 .0\n9. 2\n15 .3\n27 .2\n27 .2\n27 .2\n38 .4\n45 .4\n41 .6\nci ty\nof he\nad qu\nar te\nrs 42\n.8 10\n0. 0\n60 .0\n46 .1\n66 .6\n54 .5\n36 .3\n88 .8\n51 .6\n46 .6\n77 .7\n58 .3\n71 .4\n55 .5\n62 .5\nsi bl\nin gs\n10 0.\n0 28\n.5 44\n.4 10\n0. 0\n28 .5\n44 .4\n10 0.\n0 14\n.2 25\n.0 66\n.6 28\n.5 40\n.0 10\n0. 0\n28 .5\n44 .4\n(o rg\n:) pa\nre nt\ns 33\n.3 33\n.3 33\n.3 33\n.3 66\n.6 44\n.4 50\n.0 33\n.3 33\n.3 33\n.3 33\n.3 40\n.0 41\n.6 50\n.0 45\n.4\nO ffi\nci al\nTA C\nSc or\ner (M\nic ro\n-F 1\n) 29\n.3 28\n.1 28\n.7 35\n.5 33\n.7 34\n.7 22\n.7 26\n.0 24\n.3 37\n.5 29\n.4 33\n.0 36\n.9 35\n.9 36\n.4"}, {"heading": "5. Conclusions", "text": "The overall aim of our proposed strategy in building relation extractors in a closed IE setting (i.e., to extract a priori specified relations) is to maximize their performance using minimal (human) annotation effort. The key ideas that help us achieve that are: (i) distant supervision (DS): use known relation instances from a knowledge base to automatically generate training data, (ii) feature annotation: rather than labeling instances, annotate features (e.g., text patterns expressing a relationship), selected by means of an active learning criterion, and (iii) semantic feature space representation: use compact semantic vector spaces to detect additional, semantically related patterns that do not occur in the thus far selected training data, leaving useful patterns undetected otherwise.\nThus, we address the problem of noisy training data obtained through DS by expanding the key idea of automatically filtering of the training data to increase precision (see [46]). Specifically, to improve recall,\nwe introduce the semi-supervised Semantic Label Propagation method, that allows to relax the pattern-based filtering of the DS training data by again including weakly supervised items that are sufficiently \u201csimilar\u201d to highly confident instances. We found that a dimension reduction by a simple linear combination of the word embeddings contributing to the relation pattern are effective representations to propagate labels from supervised to weakly supervised instances. Tuning a threshold parameter for similarity creates an improved training set for relation extraction.\nThe main contributions of this paper to the domain of closed relation extraction, are the novel methodology of filtering an initial DS training set, where we motivated and demonstrated the effectiveness of an almost negligible manual annotation effort, and the Semantic Label Propagation model for again expanding the filtered set in order to increase diversity in the training data.\nWe evaluated our classifiers on the knowledge base population task of TAC KBP and show the competi-\ntiveness with respect to established methods that rely on a much heavier annotation cost."}], "references": [{"title": "Yago: a core of semantic knowledge", "author": ["F.M. Suchanek", "G. Kasneci", "G. Weikum"], "venue": "in: Proceedings of the 16th international conference on World Wide Web, ACM", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Dbpedia-a crystallization point for the web of data", "author": ["C. Bizer", "J. Lehmann", "G. Kobilarov", "S. Auer", "C. Becker", "R. Cyganiak", "S. Hellmann"], "venue": "Web Semantics: science, services and agents on the world wide web 7 (3) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["K. Bollacker", "C. Evans", "P. Paritosh", "T. Sturge", "J. Taylor"], "venue": "in: Proceedings of the 2008 ACM SIGMOD international conference on Management of data, ACM", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "J", "author": ["T. Mitchell", "W. Cohen", "E. Hruschka", "P.P. Talukdar", "J. Betteridge", "A. Carlson", "B. Dalvi Mishra", "M. Gardner", "B. Kisiel"], "venue": "Krishnamurthy, et al., Never-ending learning, in: AAAI, AAAI Press", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Scalable knowledge harvesting with high precision and high recall", "author": ["N. Nakashole", "M. Theobald", "G. Weikum"], "venue": "in: Proceedings of the fourth ACM international conference on Web search and data mining, ACM", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Textrunner: open information extraction on the web", "author": ["A. Yates", "M. Cafarella", "M. Banko", "O. Etzioni", "M. Broadhead", "S. Soderland"], "venue": "in: Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations, Association for Computational Linguistics", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Prismatic: Inducing knowledge from a large scale lexicalized relation resource", "author": ["J. Fan", "D. Ferrucci", "D. Gondek", "A. Kalyanpur"], "venue": "in: Proceedings of the NAACL HLT 2010 first international workshop on formalisms and methodology for learning by reading, Association for Computational Linguistics", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Knowledge vault: A web-scale approach to probabilistic knowledge fusion", "author": ["X. Dong", "E. Gabrilovich", "G. Heitz", "W. Horn", "N. Lao", "K. Murphy", "T. Strohmann", "S. Sun", "W. Zhang"], "venue": "in: Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "D", "author": ["B. Min", "R. Grishman", "L. Wan", "C. Wang"], "venue": "Gondek, Distant supervision for relation extraction with an incomplete knowledge base., in: HLT-NAACL", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "A novel use of statistical parsing to extract information from text", "author": ["S. Miller", "H. Fox", "L. Ramshaw", "R. Weischedel"], "venue": "in: Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference, Association for Computational Linguistics", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2000}, {"title": "Combining lexical", "author": ["N. Kambhatla"], "venue": "syntactic, and semantic features with maximum entropy models for extracting relations, in: Proceedings of the ACL 2004 on Interactive poster and demonstration sessions, Association for Computational Linguistics", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2004}, {"title": "Automatic information extraction", "author": ["E. Boschee", "R. Weischedel", "A. Zamanian"], "venue": "in: Proceedings of the 2005 International Conference on Intelligence Analysis, McLean, VA, Citeseer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "C", "author": ["J. Jiang"], "venue": "Zhai, A systematic exploration of the feature space for relation extraction., in: HLT- NAACL", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Semi-supervised relation extraction with large-scale word clustering", "author": ["A. Sun", "R. Grishman", "S. Sekine"], "venue": "in: Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, Association for Computational Linguistics", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "A shortest path dependency kernel for relation extraction", "author": ["R.C. Bunescu", "R.J. Mooney"], "venue": "in: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, Association for Computational Linguistics", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Snowball: Extracting relations from large plain-text collections", "author": ["E. Agichtein", "L. Gravano"], "venue": "in: Proceedings of the fifth ACM conference on Digital libraries, ACM", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2000}, {"title": "Spied: Stanford pattern-based information extraction and diagnostics, Proceedings of the ACL 2014 Workshop on Interactive Language Learning, Visualization, and Interfaces (ACL-ILLVI)", "author": ["S. Gupta", "C.D. Manning"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Overview of the english slot filling track at the tac2014 knowledge base population evaluation", "author": ["M. Surdeanu", "H. Ji"], "venue": "Proc. Text Analysis Conference ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Incremental knowledge base construction using deepdive", "author": ["J. Shin", "S. Wu", "F. Wang", "C. De Sa", "C. Zhang", "C. R\u00e9"], "venue": "Proceedings of the VLDB Endowment 8 (11) ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Modeling relations and their mentions without labeled text", "author": ["S. Riedel", "L. Yao", "A. McCallum"], "venue": "in: Machine Learning and Knowledge Discovery in Databases, Springer Berlin Heidelberg", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations", "author": ["R. Hoffmann", "C. Zhang", "X. Ling", "L. Zettlemoyer", "D.S. Weld"], "venue": "in: Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, Association for Computational Linguistics", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Multi-instance multi-label learning for relation extraction", "author": ["M. Surdeanu", "J. Tibshirani", "R. Nallapati", "C.D. Manning"], "venue": "in: Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, Association for Computational Linguistics", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Combining distant and partial supervision for relation extraction", "author": ["G. Angeli", "J. Tibshirani", "J.Y. Wu", "C.D. Manning"], "venue": "in: Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "R", "author": ["M. Pershina", "B. Min", "W. Xu"], "venue": "Grishman, Infusion of labeled data into distant supervision for relation extraction", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["M. Mintz", "S. Bills", "R. Snow", "D. Jurafsky"], "venue": "in: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, Association for Computational Linguistics", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Kernel methods for relation extraction", "author": ["D. Zelenko", "C. Aone", "A. Richardella"], "venue": "in: Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume 10, EMNLP \u201902, Association for Computational Linguistics, Stroudsburg, PA, USA", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2002}, {"title": "Dependency tree kernels for relation extraction", "author": ["A. Culotta", "J. Sorensen"], "venue": "in: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, Association for Computational Linguistics", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2004}, {"title": "Relation classification via convolutional deep neural network", "author": ["D. Zeng", "K. Liu", "S. Lai", "G. Zhou", "J. Zhao"], "venue": "in: Proceedings of COLING", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "Extracting patterns and relations from the world wide web., Technical Report 1999-65, Stanford InfoLab, previous number = SIDL-WP-1999-0119", "author": ["S. Brin"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1999}, {"title": "Construction of semantic bootstrapping models for relation extraction", "author": ["C. Zhang", "W. Xu", "Z. Ma", "S. Gao", "Q. Li", "J. Guo"], "venue": "Knowledge-Based Systems 83 ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Graph-based analysis of semantic drift in espressolike bootstrapping algorithms", "author": ["M. Komachi", "T. Kudo", "M. Shimbo", "Y. Matsumoto"], "venue": "in: Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP \u201908, Association for Computational Linguistics, Stroudsburg, PA, USA", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2008}, {"title": "Minimising semantic drift with mutual exclusion bootstrapping", "author": ["J.R. Curran", "T. Murphy", "B. Scholz"], "venue": "Proceedings of the Conference of the Pacific Association for Computational Linguistics ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2007}, {"title": "Semi-supervised bootstrapping of relationship extractors with distributional semantics", "author": ["D.S. Batista", "B. Martins", "M.J. Silva"], "venue": "in: Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Lisbon, Portugal", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "J", "author": ["M. Craven"], "venue": "Kumlien, et al., Constructing biological knowledge bases by extracting information from text sources., in: ISMB, Vol. 1999", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1999}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations, Proc", "author": ["R. Hoffmann", "C. Zhang", "X. Ling"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2002}, {"title": "O", "author": ["A. Intxaurrondo", "M. Surdeanu"], "venue": "L. de Lacalle, E. Agirre, Removing noisy mentions for distant supervision, Procesamiento del lenguaje natural 51 ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}, {"title": "Pattern learning for relation extraction with a hierarchical topic model", "author": ["E. Alfonseca", "K. Filippova", "J.-Y. Delort", "G. Garrido"], "venue": "in: Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2, Association for Computational Linguistics", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2012}, {"title": "Reducing wrong labels in distant supervision for relation extraction", "author": ["S. Takamatsu", "I. Sato", "H. Nakagawa"], "venue": "in: Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, Association for Computational Linguistics", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2012}, {"title": "Relation extraction using label propagation based semi-supervised learning", "author": ["J. Chen", "D. Ji", "C.L. Tan", "Z. Niu"], "venue": "in: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, Association for Computational Linguistics", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2006}, {"title": "Big data versus the crowd: Looking for relationships in all the right places", "author": ["C. Zhang", "F. Niu", "C. R\u00e9", "J. Shavlik"], "venue": "in: Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, Association for Computational Linguistics", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2012}, {"title": "Deepdive: A data management system for automatic knowledge base construction", "author": ["C. Zhang"], "venue": "Ph.D. thesis, UW-Madison ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2015}, {"title": "Query by committee", "author": ["H.S. Seung", "M. Opper", "H. Sompolinsky"], "venue": "in: Proceedings of the fifth annual workshop on Computational learning theory, ACM", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1992}, {"title": "Using active learning and semantic clustering for noise reduction in distant supervision", "author": ["L. Sterckx", "T. Demeester", "J. Deleu", "C. Develder"], "venue": "in: 4e Workshop on Automated Base Construction at NIPS2014 ", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "Active learning by labeling features", "author": ["G. Druck", "B. Settles", "A. McCallum"], "venue": "in: Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, Association for Computational Linguistics", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2009}, {"title": "A unified approach to active dual supervision for labeling features and examples", "author": ["J. Attenberg", "P. Melville", "F. Provost"], "venue": "in: In European conference on Machine learning and knowledge discovery in databases", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2010}, {"title": "Distributional structure", "author": ["Z. Harris"], "venue": "Word 10 (23) ", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1954}, {"title": "Glove: Global vectors for word representation", "author": ["J. Pennington", "R. Socher", "C.D. Manning"], "venue": "in: Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2014}, {"title": "A comparison of vector-based representations for semantic composition", "author": ["W. Blacoe", "M. Lapata"], "venue": "in: Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, Association for Computational Linguistics, Jeju Island, Korea", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2012}, {"title": "The stanford corenlp natural language processing toolkit", "author": ["C.D. Manning", "M. Surdeanu", "J. Bauer", "J. Finkel", "S.J. Bethard", "D. McClosky"], "venue": "in: Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2014}, {"title": "D", "author": ["M. Mintz", "S. Bills", "R. Snow"], "venue": "Jurafsky, Distant supervision for relation extraction without labeled data (August) ", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2009}, {"title": "Comparing information extraction pattern models", "author": ["M. Stevenson", "M.A. Greenwood"], "venue": "in: Proceedings of the Workshop on Information Extraction Beyond The Document, Association for Computational Linguistics", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2006}, {"title": "Ghent University-IBCN participation in TAC-KBP 2014 slot filling and cold start tasks", "author": ["M. Feys", "L. Sterckx", "L. Mertens", "J. Deleu", "T. Demeester", "C. Develder"], "venue": "in: 7th Text Analysis Conference, Proceedings", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2014}, {"title": "Ghent University-IBCN participation in TAC-KBP 2015 cold start task", "author": ["L. Sterckx", "J. Deleu", "T. Demeester", "C. Develder"], "venue": "in: 8th Text Analysis Conference, Proceedings (To Appear)", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2015}, {"title": "Indexing by latent semantic analysis", "author": ["S.C. Deerwester", "S.T. Dumais", "T.K. Landauer", "G.W. Furnas", "R.A. Harshman"], "venue": "JAsIs 41 (6) ", "citeRegEx": "60", "shortCiteRegEx": null, "year": 1990}], "referenceMentions": [{"referenceID": 0, "context": ", YAGO [1], DBpedia [2], and Freebase [3]), KBs generated from Web documents (e.", "startOffset": 7, "endOffset": 10}, {"referenceID": 1, "context": ", YAGO [1], DBpedia [2], and Freebase [3]), KBs generated from Web documents (e.", "startOffset": 20, "endOffset": 23}, {"referenceID": 2, "context": ", YAGO [1], DBpedia [2], and Freebase [3]), KBs generated from Web documents (e.", "startOffset": 38, "endOffset": 41}, {"referenceID": 3, "context": ", NELL [4], PROSPERA[5]), or open information extraction approaches (e.", "startOffset": 7, "endOffset": 10}, {"referenceID": 4, "context": ", NELL [4], PROSPERA[5]), or open information extraction approaches (e.", "startOffset": 20, "endOffset": 23}, {"referenceID": 5, "context": ", TextRunner [6], PRISMATIC [7]).", "startOffset": 13, "endOffset": 16}, {"referenceID": 6, "context": ", TextRunner [6], PRISMATIC [7]).", "startOffset": 28, "endOffset": 31}, {"referenceID": 7, "context": "Besides academic projects, several commercial projects were initiated by major corporations like Microsoft (Satori1), Google (Knowledge Graph [8]), Facebook2, Walmart [9] and others.", "startOffset": 142, "endOffset": 145}, {"referenceID": 8, "context": "5% of persons in Freebase have no known nationality [10].", "startOffset": 52, "endOffset": 56}, {"referenceID": 7, "context": "To complete a KB, we need a Knowledge Base Population (KBP) system that extracts information from various sources, of which a large fraction comprises unstructured written text items [8].", "startOffset": 183, "endOffset": 186}, {"referenceID": 9, "context": "Effective approaches for closed schema RE apply some form of supervised or semi-supervised learning [11, 12, 13, 14, 15, 16] and generally follow three steps: (i) sentences expressing relations are transformed to a data representation, e.", "startOffset": 100, "endOffset": 124}, {"referenceID": 10, "context": "Effective approaches for closed schema RE apply some form of supervised or semi-supervised learning [11, 12, 13, 14, 15, 16] and generally follow three steps: (i) sentences expressing relations are transformed to a data representation, e.", "startOffset": 100, "endOffset": 124}, {"referenceID": 11, "context": "Effective approaches for closed schema RE apply some form of supervised or semi-supervised learning [11, 12, 13, 14, 15, 16] and generally follow three steps: (i) sentences expressing relations are transformed to a data representation, e.", "startOffset": 100, "endOffset": 124}, {"referenceID": 12, "context": "Effective approaches for closed schema RE apply some form of supervised or semi-supervised learning [11, 12, 13, 14, 15, 16] and generally follow three steps: (i) sentences expressing relations are transformed to a data representation, e.", "startOffset": 100, "endOffset": 124}, {"referenceID": 13, "context": "Effective approaches for closed schema RE apply some form of supervised or semi-supervised learning [11, 12, 13, 14, 15, 16] and generally follow three steps: (i) sentences expressing relations are transformed to a data representation, e.", "startOffset": 100, "endOffset": 124}, {"referenceID": 14, "context": "Effective approaches for closed schema RE apply some form of supervised or semi-supervised learning [11, 12, 13, 14, 15, 16] and generally follow three steps: (i) sentences expressing relations are transformed to a data representation, e.", "startOffset": 100, "endOffset": 124}, {"referenceID": 15, "context": "To counter this problem, the technique of iterative bootstrapping has been proposed [17, 18], in which an initial seed set of known facts is used to learn patterns, which in turn are used to learn new facts and incrementally extend the training set.", "startOffset": 84, "endOffset": 92}, {"referenceID": 16, "context": "To counter this problem, the technique of iterative bootstrapping has been proposed [17, 18], in which an initial seed set of known facts is used to learn patterns, which in turn are used to learn new facts and incrementally extend the training set.", "startOffset": 84, "endOffset": 92}, {"referenceID": 17, "context": "DS has been successfully applied in many relation extraction tasks [19, 20] as it allows for the creation of large training sets with little or no human effort.", "startOffset": 67, "endOffset": 75}, {"referenceID": 18, "context": "DS has been successfully applied in many relation extraction tasks [19, 20] as it allows for the creation of large training sets with little or no human effort.", "startOffset": 67, "endOffset": 75}, {"referenceID": 19, "context": "The heuristic of accepting each co-occurrence of the entity pair < e1, e2 > as a positive training item because of the KB entry r(e1, e2), is known to generate noisy training data or false positives [21], i.", "startOffset": 199, "endOffset": 203}, {"referenceID": 19, "context": "The most prominent is that of latent variable models of the distantly supervised data that make the assumption that a known fact is expressed at least once in the corpus [21, 22, 23].", "startOffset": 170, "endOffset": 182}, {"referenceID": 20, "context": "The most prominent is that of latent variable models of the distantly supervised data that make the assumption that a known fact is expressed at least once in the corpus [21, 22, 23].", "startOffset": 170, "endOffset": 182}, {"referenceID": 21, "context": "The most prominent is that of latent variable models of the distantly supervised data that make the assumption that a known fact is expressed at least once in the corpus [21, 22, 23].", "startOffset": 170, "endOffset": 182}, {"referenceID": 22, "context": "Some focus on active learning, selecting training instances to be labeled according to an uncertainty criterion [24, 19], while others focus on annotations of surface patterns and define rules or guidelines in a semi-supervised learning setting [25].", "startOffset": 112, "endOffset": 120}, {"referenceID": 17, "context": "Some focus on active learning, selecting training instances to be labeled according to an uncertainty criterion [24, 19], while others focus on annotations of surface patterns and define rules or guidelines in a semi-supervised learning setting [25].", "startOffset": 112, "endOffset": 120}, {"referenceID": 23, "context": "Some focus on active learning, selecting training instances to be labeled according to an uncertainty criterion [24, 19], while others focus on annotations of surface patterns and define rules or guidelines in a semi-supervised learning setting [25].", "startOffset": 245, "endOffset": 249}, {"referenceID": 12, "context": "Feature based methods [14, 26] extract a rich list of structural, lexical, syntactic and semantic features to represent the given relation mentions.", "startOffset": 22, "endOffset": 30}, {"referenceID": 24, "context": "Feature based methods [14, 26] extract a rich list of structural, lexical, syntactic and semantic features to represent the given relation mentions.", "startOffset": 22, "endOffset": 30}, {"referenceID": 25, "context": "In contrast, kernel based methods [27, 28, 16] represent each relation mention as an object such as an augmented token sequences or a parse tree, and use a carefully designed kernel function, e.", "startOffset": 34, "endOffset": 46}, {"referenceID": 26, "context": "In contrast, kernel based methods [27, 28, 16] represent each relation mention as an object such as an augmented token sequences or a parse tree, and use a carefully designed kernel function, e.", "startOffset": 34, "endOffset": 46}, {"referenceID": 14, "context": "In contrast, kernel based methods [27, 28, 16] represent each relation mention as an object such as an augmented token sequences or a parse tree, and use a carefully designed kernel function, e.", "startOffset": 34, "endOffset": 46}, {"referenceID": 27, "context": "With the recent success of deep neural networks in NLP, Convolutional Neural Networks (CNNs) have emerged as effective relation extractors [29, 30].", "startOffset": 139, "endOffset": 147}, {"referenceID": 15, "context": "Bootstrapping models for Relation Extraction When a limited set of labeled instances is available, bootstrapping methods have proven to be effective methods to generate high-precision relation patterns [17, 18, 31, 32].", "startOffset": 202, "endOffset": 218}, {"referenceID": 16, "context": "Bootstrapping models for Relation Extraction When a limited set of labeled instances is available, bootstrapping methods have proven to be effective methods to generate high-precision relation patterns [17, 18, 31, 32].", "startOffset": 202, "endOffset": 218}, {"referenceID": 28, "context": "Bootstrapping models for Relation Extraction When a limited set of labeled instances is available, bootstrapping methods have proven to be effective methods to generate high-precision relation patterns [17, 18, 31, 32].", "startOffset": 202, "endOffset": 218}, {"referenceID": 29, "context": "Bootstrapping models for Relation Extraction When a limited set of labeled instances is available, bootstrapping methods have proven to be effective methods to generate high-precision relation patterns [17, 18, 31, 32].", "startOffset": 202, "endOffset": 218}, {"referenceID": 28, "context": "Systems use measures based on exact matches [31], cosine-similarity [17] or kernels [32].", "startOffset": 44, "endOffset": 48}, {"referenceID": 15, "context": "Systems use measures based on exact matches [31], cosine-similarity [17] or kernels [32].", "startOffset": 68, "endOffset": 72}, {"referenceID": 29, "context": "Systems use measures based on exact matches [31], cosine-similarity [17] or kernels [32].", "startOffset": 84, "endOffset": 88}, {"referenceID": 30, "context": "A fundamental problem of these methods is semantic drift [33, 34]: bootstrapping, after several iterations, deviates from the semantics of the seed relationship and extracts unrelated instances which in turn generate faulty patterns.", "startOffset": 57, "endOffset": 65}, {"referenceID": 31, "context": "A fundamental problem of these methods is semantic drift [33, 34]: bootstrapping, after several iterations, deviates from the semantics of the seed relationship and extracts unrelated instances which in turn generate faulty patterns.", "startOffset": 57, "endOffset": 65}, {"referenceID": 32, "context": "[35] proposed the use of word embeddings for capturing semantic similarity between patterns.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "Distant Supervision Distant Supervision (DS) was first proposed in [36], where labeled data was generated by aligning instances from the Yeast Protein Database into research articles to train an extractor.", "startOffset": 67, "endOffset": 71}, {"referenceID": 8, "context": "This approach was later applied for training of relation extractors between entities in [10].", "startOffset": 88, "endOffset": 92}, {"referenceID": 19, "context": "[21] relaxed the strong all sentences-assumption and relaxed it to an at-least-one-sentence-assumption, creating a Multi-Instance learner.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[37] modified this model by allowing entity pairs to express multiple relations, resulting in a Multi-Instance Multi-Label", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[23] further extended this approach and included a secondary classifier, which jointly modeled all the sentences in texts and all labels in knowledge bases for a given entity pair.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "Other methods apply heuristics [38], model the training data as a generative process [39, 40] or use a low-rank representation of the feature-label matrix to exploit the underlying semantic correlated information.", "startOffset": 31, "endOffset": 35}, {"referenceID": 36, "context": "Other methods apply heuristics [38], model the training data as a generative process [39, 40] or use a low-rank representation of the feature-label matrix to exploit the underlying semantic correlated information.", "startOffset": 85, "endOffset": 93}, {"referenceID": 37, "context": "Other methods apply heuristics [38], model the training data as a generative process [39, 40] or use a low-rank representation of the feature-label matrix to exploit the underlying semantic correlated information.", "startOffset": 85, "endOffset": 93}, {"referenceID": 38, "context": "[41] apply Label Propagation by representing labeled and unlabeled examples as nodes and their similarities as the weights of edges in a graph.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15] show that several different cluster-based features trained on large corpora can improve the RE effectiveness.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[42] compare DS and complete supervision as training resources but do not attempt to fuse them.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[24] show that providing a relatively small number of mention-level annotations can improve the accuracy of MIML-RE.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[23] marginally outperforms the Mintz++ baseline using solely distant supervision, initialization of the latent variables using labeled data is needed for larger improvements.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[25], incorporates labeled patterns and trigger words to guide MIML-RE during training.", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": "The top performing KBP ESF system [43, 44] used DS and the manual labeling of 100, 000 features.", "startOffset": 34, "endOffset": 42}, {"referenceID": 22, "context": "In relation extraction, typical approaches include queryby-committee [24, 45] and cluster-based sampling [46].", "startOffset": 69, "endOffset": 77}, {"referenceID": 41, "context": "In relation extraction, typical approaches include queryby-committee [24, 45] and cluster-based sampling [46].", "startOffset": 69, "endOffset": 77}, {"referenceID": 42, "context": "In relation extraction, typical approaches include queryby-committee [24, 45] and cluster-based sampling [46].", "startOffset": 105, "endOffset": 109}, {"referenceID": 43, "context": ", patterns, or the occurrence of terms) are labeled as opposed to instances [47, 48], resulting in a higher performance for less supervision.", "startOffset": 76, "endOffset": 84}, {"referenceID": 44, "context": ", patterns, or the occurrence of terms) are labeled as opposed to instances [47, 48], resulting in a higher performance for less supervision.", "startOffset": 76, "endOffset": 84}, {"referenceID": 44, "context": "This approach has been coined as Feature Certainty[48], and we show that this approach is especially effective in DS for features which generalize across many training instances.", "startOffset": 50, "endOffset": 54}, {"referenceID": 45, "context": "Distributional Semantics The Distributional Hypothesis [49] states that words that tend to occur in similar contexts are likely to have similar meanings.", "startOffset": 55, "endOffset": 59}, {"referenceID": 46, "context": "include Word2Vec [51] and GloVe [52].", "startOffset": 32, "endOffset": 36}, {"referenceID": 47, "context": "[53] show that, for short phrases, a simple composition like addition or multiplication of the distributional word representations is competitive with more complex supervised models such as recursive neural networks (RNNs).", "startOffset": 0, "endOffset": 4}, {"referenceID": 48, "context": "Articles are first preprocessed using different components of the Stanford CoreNLP toolkit [55], including sentence segmentation, tokenizing, POS-tagging, Named Entity Recognition, and clustering noun phrases which refer to the same entity.", "startOffset": 91, "endOffset": 95}, {"referenceID": 49, "context": "As in previous work [56, 37], we impose the constraint that both entity mentions (m1,m2) \u2208 R i are contained in the same sentence.", "startOffset": 20, "endOffset": 28}, {"referenceID": 34, "context": "As in previous work [56, 37], we impose the constraint that both entity mentions (m1,m2) \u2208 R i are contained in the same sentence.", "startOffset": 20, "endOffset": 28}, {"referenceID": 50, "context": "Dependency paths have empirically been proven to be very informative for relation extraction, their capability in capturing a lot of information is evidenced by a systematic comparison in effectiveness of different kernel methods [57] or as features in feature-based systems [14].", "startOffset": 230, "endOffset": 234}, {"referenceID": 12, "context": "Dependency paths have empirically been proven to be very informative for relation extraction, their capability in capturing a lot of information is evidenced by a systematic comparison in effectiveness of different kernel methods [57] or as features in feature-based systems [14].", "startOffset": 275, "endOffset": 279}, {"referenceID": 14, "context": "[16] who claimed that the relation expressed by a sentence is often captured in the shortest path connecting the entities in the dependency graph.", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": "This approach is called Feature Certainty Sampling [48].", "startOffset": 51, "endOffset": 55}, {"referenceID": 23, "context": "[25] (without the MIML model) in labeling features, but it differs in some essential aspects.", "startOffset": 0, "endOffset": 4}, {"referenceID": 42, "context": "[46], representing small phrases by summing", "startOffset": 0, "endOffset": 4}, {"referenceID": 51, "context": "Testing Methodology We evaluate the relation extractors in the context of an existing Knowledge Base Population system [58, 59] using the NIST TAC KBP English Slot Filling (ESF) Evaluation from 2012 to 2014.", "startOffset": 119, "endOffset": 127}, {"referenceID": 52, "context": "Testing Methodology We evaluate the relation extractors in the context of an existing Knowledge Base Population system [58, 59] using the NIST TAC KBP English Slot Filling (ESF) Evaluation from 2012 to 2014.", "startOffset": 119, "endOffset": 127}, {"referenceID": 51, "context": "For further details of the KBP system we refer to [58, 59].", "startOffset": 50, "endOffset": 58}, {"referenceID": 52, "context": "For further details of the KBP system we refer to [58, 59].", "startOffset": 50, "endOffset": 58}, {"referenceID": 53, "context": "We also transform the set of one-hot representations using Singular Value Decomposition (SVD) [60] fitted on the complete trainingset.", "startOffset": 94, "endOffset": 98}, {"referenceID": 24, "context": "Next to traditional distant supervision (also known as Mintz++[26], indicated as \u2018Distant Supervision\u2019 in Table 4), we compare our new semi-supervised approach (\u2018Semantic Label Propagation\u2019) to a fully supervised classifier trained by manually labeling 50, 000 instances chosen uniformly among the different relations and according to uncertainty sampling criteria (\u2018Fully Supervised\u2019), and to the classifiers obtained by purely filtering on manually labeled patterns (\u2018Pattern Filtered\u2019).", "startOffset": 62, "endOffset": 66}, {"referenceID": 17, "context": "4% attained using Semantic Label Propagation is equivalent with the second best entry out of eighteen submissions to the 2014 ESF track [19].", "startOffset": 136, "endOffset": 140}, {"referenceID": 42, "context": "Thus, we address the problem of noisy training data obtained through DS by expanding the key idea of automatically filtering of the training data to increase precision (see [46]).", "startOffset": 173, "endOffset": 177}], "year": 2017, "abstractText": "A crucial aspect of a knowledge base population system that extracts new facts from text corpora, is the generation of training data for its relation extractors. In this paper, we present a method that maximizes the effectiveness of newly trained relation extractors at a minimal annotation cost. Manual labeling can be significantly reduced by Distant Supervision, which is a method to construct training data automatically by aligning a large text corpus with an existing knowledge base of known facts. For example, all sentences mentioning both \u2018Barack Obama\u2019 and \u2018US\u2019 may serve as positive training instances for the relation born in(subject,object). However, distant supervision typically results in a highly noisy training set: many training sentences do not really express the intended relation. We propose to combine distant supervision with minimal manual supervision in a technique called feature labeling, to eliminate noise from the large and noisy initial training set, resulting in a significant increase of precision. We further improve on this approach by introducing the Semantic Label Propagation method, which uses the similarity between low-dimensional representations of candidate training instances, to extend the training set in order to increase recall while maintaining high precision. Our proposed strategy for generating training data is studied and evaluated on an established test collection designed for knowledge base population tasks. The experimental results show that the Semantic Label Propagation strategy leads to substantial performance gains when compared to existing approaches, while requiring an almost negligible manual annotation effort.", "creator": "LaTeX with hyperref package"}}}