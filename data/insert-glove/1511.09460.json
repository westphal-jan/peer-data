{"id": "1511.09460", "review": {"conference": "aaai", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Nov-2015", "title": "Ask, and shall you receive?: Understanding Desire Fulfillment in Natural Language Text", "abstract": "goossen The disincorporation ability to comprehend siyabonga wishes or tunnelling desires benbecula and their day-night fulfillment boukrouh is fitzpatricks important to biloxi Natural Language dalkia Understanding. This \uffe5 paper introduces bocholt the task capano of identifying brassicaceae if ablaut a ampico desire berenices expressed by a subject wbns in brodeur a 3.8-million given short piece of text was adic fulfilled. sleith@ajc.com We micro-organism propose various unstructured 176.4 and structured models senanayake that snifter capture fulfillment cues such as the sarovar subject ' silbering s pescara emotional 19.90 state and actions. cotman Our experiments with two initiator different datasets autobahnen demonstrate \u00f6stra the gerentes importance so-yeon of ifas understanding the callide narrative 148.00 and waag discourse aeroput structure to address this coriolanus task.", "histories": [["v1", "Mon, 30 Nov 2015 20:37:03 GMT  (817kb,D)", "http://arxiv.org/abs/1511.09460v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["snigdha chaturvedi", "dan goldwasser", "hal daume iii"], "accepted": true, "id": "1511.09460"}, "pdf": {"name": "1511.09460.pdf", "metadata": {"source": "CRF", "title": "Ask, and shall you receive?: Understanding Desire Fulfillment in Natural Language Text", "authors": ["Snigdha Chaturvedi", "Dan Goldwasser", "Hal Daum\u00e9 III"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Understanding expressions of desire is a fundamental aspect of understanding intentional human-behavior. The strong connection between desires and the ability to plan and execute appropriate actions was studied extensively in contexts of rational agent behavior [16], and modeling human dialog interactions [19].\nIn this paper we recognize the significant role that expressions of desire play in natural language understanding. Such expressions can be used to provide rationale for character behaviors when analyzing narrative text [18, 10], extract information about human wishes [17], explain positive and negative sentiment in reviews, and support automatic curation of community forums by identifying unresolved issues raised by users.\nWe follow the intuition that at the heart of the applications mentioned above is the ability to recognize whether the expressed desire was fulfilled or not, and suggest a novel reading comprehension task: Given text,\ndenoted as Desire-expression (e.g., \u201cBefore Lenin died, he said he wished to be buried beside his mother.\u201d) containing a desire (\u201cbe buried beside his mother\u201d) by the Desire-subject (\u201che\u201d), and the subsequent text (denoted Evidence fragments or simply Evidences) appearing after the Desire-expression in the paragraph, we predict if the Desire-subject was successful in fulfilling their desire. Fig. 1 illustrates our setting.\nSimilar to many other natural language understanding tasks [8, 28, 2], performance is evaluated using prediction accuracy. However, unlike tasks such as text categorization or sentiment classification which rely on lexical information, understanding desire fulfillment requires complex inferences connecting expression of desire, actions affecting the Desire-subject, and the extent to which these actions contribute to fulfilling the subject\u2019s goals. For example, in Fig. 1 the action of \u2018preserving\u2019 Lenin\u2019s body led to non-fulfillment of his desire.\nWe address these complexities by representing the narrative flow of Evidence fragments, and assessing if the events (and emotional states) mentioned in this flow con-\nar X\niv :1\n51 1.\n09 46\n0v 1\n[ cs\n.A I]\n3 0\nN ov\ntribute to (or provide indication of) fulfilling the desire expressed in the preceding Desire-expression. Following previous work on narrative representation [4], we track the events and states associated with the narrative\u2019s central character (the Desire-subject).\nWhile this representation captures important properties required by the desire-fulfillment prediction task, such as the actions taken by the Desire-subject, it does not provide us with an indication about the outcome of these actions. Recent attempts to support supervised learning of such detailed narrative structures by annotating data [11], result in highly complex structures even for restricted domains. Instead we model this information by associating a state, indicating if the outcome of an action (or the mention of an emotional state) provides evidence for making progress towards achieving the desired goal. We model the transitions between states as a latent sequence model, and use it to predict if the value of the final latent state in this sequence is indicative of a positive or negative prediction for our task.\nWe demonstrate the strength of our approach by comparing it against two strong baselines. First, we demonstrate the importance of analyzing the complete text by comparing with a textual-entailment based model that analyzes individual Evidence fragments independently. We then compare our latent structured model, which incorporates the narrative structure with an unstructured model, and show improvements in prediction performance. Our key contributions are: \u2022 We introduce the problem of understanding desire ful-\nfillment, annotate and release two datasets for further research on this problem. \u2022 We present a latent structured model for this task, incorporating the narrative structure of the text, and propose relevant features that incorporate world knowledge. \u2022 Empirically demonstrate that such a model outperforms competitive baselines."}, {"heading": "1.1 Problem Setting", "text": "Our problem consists of instances of short texts (called Desire-expressions), which were collected in a manner so that each consists of an indication of a desire (characterized using a Desire-verb) by a Desire-subject(s). The Desire-verb is identified by the following verb phrases: \u2018wanted to\u2019, \u2018wished to\u2019 or \u2018hoped to\u2019 1. The three Desireverbs were identified using lexical matches while the 1We chose to use these three phrases for data collection. However, one can include other expressions of desire if needed. We plan to include\nDesire-subject(s) was marked manually. Each Desireexpression is followed by five or fewer pieces of Evidence fragments (or simply Evidences). The Desireexpression and the Evidences (in order) consist of individual sentences that appeared contiguously in a paragraph. We address the binary classification task of predicting the Desire Fulfillment status, i.e. whether the indicated desire was fulfilled in the text, given the Evidences and the Desire-expression with Desire-verb and Subject identified. Fig. 1 shows an example of the problem."}, {"heading": "2 Inference Models for Understanding Desire Fulfillment in Narrative Text", "text": "In this section we present three textual inference approaches, each following different assumptions when approaching the desire-fulfillment task, thus allowing a principled discussion about which aspects of the narrative text should be modeled.\nOur first approach assumes the indication of desire fulfillment will be contained in a single Evidence fragment. We test this assumption by adapting the well-known Textual Entailment task to our settings, by generating entailment candidates from Desire-expression and Evidence fragments.\nOur second approach assumes the decision depends on the Evidence text as a whole, rather than on a single Evidence fragment. We test this assumption by representing relevant information extracted from the entire Evidence text. This representation (depicted in Fig. 3) connects the central character in the narrative, the Desiresubject, with their actions and emotional states exhibited in the Evidence text. This representation is then used for feature extraction when training a binary classifier for the desire-fulfillment task.\nOur final model provides a stronger structure for the actions and emotional states expressed in the Evidence text. The model treats individual Evidence fragments as parts of a plan carried out by the Desire-subject to achieve the desired goal, and makes judgments about the contribution of each step towards achieving the desired goal.\nthat in future work."}, {"heading": "2.1 Textual Entailment (TE) Model", "text": "Recognizing Textual Entailment (RTE) is the task of recognizing the existence of an entailment relationship between two text fragments [8]. From this perspective, a textual entailment based method might be a natural way to address the desire fulfillment task. RTE systems often rely on aligning the entities appearing in the text fragments. Hence we reduce the desire fulfillment task into several RTE instances consisting of text-hypothesis pairs, by pairing the Desire-expression (hypothesis) with each of the Evidence fragments (text) in that example. However, we \u201cnormalized\u201d the Desire-expression, so that it would be directly applicable for the RTE task. For example, the Desire-expression, \u201cOne day Jerry wanted to paint his barn.\u201d, gets converted to \u201cJerry painted his barn.\u201d. This process followed several steps: \u2022 If the Desire-subject is pronominal, replace it with\nthe appropriate named entity when possible (we used the Stanford CoreNLP coreference resolution system) [23]. \u2022 Ignore the content of the Desire-expression appearing before the Desire-subject. \u2022 Remove the clause containing the Desire-verb (\u2018wanted to\u2019, \u2018wished to\u2019 etc.), and convert the succeeding verb to its past tense. The desire was considered \u2018fulfilled\u2019 if the RTE model predicted entailment for at least one of the texthypothesis pairs of the example. E.g., the model could infer that the normalized Desire-expression example mentioned above, would be entailed by the following Evidence fragment- \u201cIt took Jerry six days to paint his barn that way.\u201d and hence it would conclude that the desire was fulfilled. Table 1 shows the performance of BIUTEE [30, 21], an RTE system, on the two datasets (see Sec. 4) used in our experiments2. Our results show that the RTE Model performs better with normalization. We use this model (with normalization) as a baseline in Sec. 5.\n2We also tested the TE model by using the default setting, optimized for the RTE task, however it performed very poorly."}, {"heading": "2.2 Unstructured Model", "text": "The Textual Entailment model described above assumes that the Desire-expression would be entailed by one of the individual Evidences. This assumption might not hold in all cases. Firstly, the indication of desire fulfillment (or its negation) can be subtle and expressed using indirect cues. More commonly, multiple Evidence fragments can collectively provide the cues needed to identify desire fulfillment. This suggests a need to treat the entire text as a whole when identifying cues about desire fulfillment.\nWe begin by identifying the Desire-subject and the desire expressed (using \u2018focal-word\u2019 described in Sec. 3) in the Desire-expression. Thereafter, we design several semantic features to model coreferent mentions of the Desire-subject, actions taken (and respective semanticroles of the Desire-subject), and emotional state of the Desire-subject in the Evidences. We enhance this representation using several knowledge resources identifying word connotations [15] and relations. Fig. 3 presents a visual representation of this process and Sec. 3 presents further details.\nBased on these features, extracted from the collection of all Evidences instead of individual Evidence fragments, we train supervised binary classifiers (Unstructured models)."}, {"heading": "2.3 Latent Structure Narrative Model (LSNM)", "text": "The Unstructured Model described above captures nuanced indications of desire-fulfillment, by associating the Desire-subject with actions, events and mental states. However, it ignores the narrative structure as it fails to model the \u2018flow of events\u2019 depicted in the transition between the Evidences.\nOur principal hypothesis is that the input text presents a story. The events in the story describe the evolving attempts of the story\u2019s main character (the Desire-subject) to fulfill its desire. Therefore, it is essential to understand\nthe flow of the story to make better judgments about its outcome.\nWe propose to model the evolution of the narrative using latent variables. We associate a latent state (denoted hj), with each Evidence fragment (denoted ej). The latent states take discrete values (out of H possible values, where H is a parameter to the model), which abstractly represent various degrees of optimism or pessimism with respect to fulfillment, f of the desire expressed in the Desire-expression, d. These latent states are arranged sequentially, in the order of occurrence of the corresponding Evidence fragments, and hence capture the evolution of the story (see Fig. 2).\nThe linear process assumed by our model can be summarized as: The model starts by predicting the latent state, h0, based on the first Evidence, e0. Thereafter, depending on the current latent state, and the content of the following Evidence fragment, the model transitions to another latent state. This process is repeated until all the Evidence fragments are associated with a latent state. We formulate the transition between narrative states as sequence prediction. We associate a set of Content features with each latent state, and Evolution features with the transitions between states.\nNote that the desire fulfillment status, f , is viewed as an outcome of this inference process and is modeled as the last step of this chain using a discriminative classifier which makes its prediction based on the final latent state and a Structure-independent feature set, \u03c6(d). This feature set can be handcrafted to include information that could not be modeled by the latent states, such as longrange dependencies, and other cumulative features based on the Desire-expression, d, and the Evidence fragments, ejs.\nWe quantify these predictions using a linear model which depends on the various features, \u03c6, and corresponding weights, w. Using the Viterbi algorithm we can compute the score associated with the optimal state sequence, for a given input story as:\nscore = max h [w \u00b7 \u03c6(e, d, f,h)] (1)"}, {"heading": "2.3.1 Learning and Inference", "text": "During training, we maximize the cumulative scores of all data instances using an iterative process (Alg. 1). Each iteration of this algorithm consists of two steps. In the first step, for every instance, it uses Viterbi algorithm (and weights from previous iteration, wt\u22121) to find the highest scoring latent state sequence, h, that agrees with the provided label (the fulfillment state), f . In the following step, it uses the state sequence determined above\nAlgorithm 1 Training algorithm for LSNM 1: Input: Labeled set {(d, e, f)i \u2200i \u2208 {1 . . . D}}; and T : number of iterations\nto get refined weights for the tth iteration, wt, using structured perceptron [7]. The algorithm is similar to an EM algorithm with \u2018hard\u2019 assignments albeit with a different objective. While testing, we use the learned weights and Viterbi decoding to compute the fulfillment state and the best scoring state sequence. Our approach is related to latent structured perceptron though we only use the last state (and structure-independent features) for prediction."}, {"heading": "3 Features", "text": "We now describe our features and how they are used by the models. Table 2 defines our features and Fig. 3 describes their extraction for an example. They capture different semantic aspects of the desire-expression and evidences, such as entities, their actions and connotations, and their emotive states using lexical resources like Connotation Lexicon [15], WordNet and our lexicon of conforming and dissenting phrases. Before extracting features, we pre-processed the text 3 and extracted all adjectives and verbs (with their negation statuses and connotations) associated with the Desire-subject using\n3We obtained pos tags, dependency parses, and resolved co-references using Stanford CoreNLP [23].\ndependency-parsing based rules. 1. Entailment (F1): This feature simply incorporates the output of the Textual Entailment model. 2. Discourse (F2-F3): These features aim to identify indications of obstacles or progress of desire fulfillment in the Desire-expression itself, based on discourse connectives. E.g. \u2018so\u2019 (underlined) in the Desire-expression in Fig. 4 indicates progress of desire fulfillment. 3. Focal words (F4-F8): These features identify the word(s) most closely related to the desire, and look for their presence in the Evidences. We define a focal word as the clausal complement of the Desire-verb (\u2018wanted to\u2019, \u2018hoped to\u2019, \u2018wished to\u2019). If the clausal complement is a verb, the focal word is its past tense form. e.g., the focal word in the Desire expression in Fig. 4 is \u2018helped\u2019. A focal word is not simply the verb following the Desireverb: e.g. in the Desire-expression in Fig. 1, the causal complement of \u2018wished\u2019 is \u2018buried\u2019. We then define features counting occurrences of the identified focal words and their WordNet synonyms and antonyms in each of the Evidences. 4. Desire-subject mentions (F9): This feature looks for mentions of Desire-subject in the Evidences assuming that a lack of mentions of the Subject might indicate absence of instances of their taking actions needed to fulfill the desire.\n5. Emotional State (F10-F11): Signals about the fulfillment status could also emanate from the emotional state of the Subject. A happy or content Desire-subject can be indicative of a fulfilled desire (e.g. in Evidence e3 in Fig. 4), and vice versa. We quantify the emotional state of the Subject(s) using connotations of the adjectives modifying their mentions. 6. Action features (F12-F15): These features analyze the intended action and the actions taken by various entities. We first identify the intended action - the verb immediately following the Desire-verb in the Desire Expression. e.g., in Fig. 4 the intended action is to \u2018help\u2019. Thereafter, we design features that capture the connotative agreement between the intended action and the actions taken by the Desire-subject(s) in the Evidences. We also include features that describe connotations of actions (verbs) affecting the Desire-subject(s). E.g. in e1 of Fig. 4, the action by the Desire-subject (marked in blue), \u2018offered\u2019, is in connotative agreement with the intended action, \u2018help\u2019 (both have positive connotations according to [15]). Also, the actions affecting the subject (\u2018thanked\u2019, \u2018gifted\u2019) have positive connotations indicating desire fulfillment. 7. Sustenance Features (F16-F17): LSNM uses a chain of latent states to abstractly represent the content of the Evidences with respect to Desire fulfillment Status. At any point in the chain, the model has an expectation of\nthe fulfillment status. The sustenance features indicate if the expectation should intensify, remain the same or be reversed by the incoming Evidence fragment. This is achieved by designing features indicating if the Evidence fragment starts with a \u2018conforming\u2019 or a \u2018dissenting\u2019 phrase. E.g. e3 in Fig. 4 starts with a conforming phrase, \u2018Overall\u2019, indicating that the fulfillment status expectation (positive in e2) should not change. Table 3 presents some examples of the two categories. These phrases were chosen using various discourse senses mentioned in [27]. The complete list is available on the first author\u2019s webpage."}, {"heading": "3.1 Unstructured Models", "text": "For the unstructured models, we directly used the Entailment and Discourse features (F1 to F3 in Table 2). For features F4 to F15, we summed their values across all Evidences of an instance. This ensured a constant size of the feature set in spite of variable number of Evidence fragments per instance."}, {"heading": "3.2 Latent Structure Narrative Model", "text": "Our Structured model requires three types of features: (a) Content features that help the model assign latent states to Evidence fragments based on their content, (b) Evolution features that help in modeling the evolution of the story expressed by the Evidence fragments (c) Structure Independent features used while making the final prediction. Content features: These features depend on the latent state of the model, hj , and the content of the corresponding Evidence, ej (expressed using features F4 to F15 in Table 2).\n1. \u03c6(hj , ej) = \u03b1 if the current state is hj ; 0 otherwise where \u03b1 \u2208 F4 to F15 Evolution features: These features depend on the current and previous latent states, hj and hj\u22121 and/or the current Evidence fragment, ej :\n1. \u03c6(hj\u22121, hj) = 1 if previous state is hj\u22121 and current state is hj ; 0 otherwise. 2. \u03c6(hj\u22121, hj , ej) = \u03b1 if previous state is hj\u22121, current state is hj ; 0 otherwise where \u03b1 \u2208 F16 and F17\n3. \u03c6(h0) = 1 if start state is h0; 0 otherwise. Structure Independent features \u03c6(d): This feature set is exactly same as that used by the Unstructured models."}, {"heading": "4 Datasets", "text": "We have used two real-world datasets for our experiments: MCTest and SimpleWiki consisting of 174 and 1004 manually annotated instances respectively. Both the datasets (available on the first author\u2019s webpage) were collected and annotated in a similar fashion.\nCollection and annotation: The MCTest data originated from the Machine Comprehension Test dataset [28] which contained of a set of 660 stories and associated questions. The vocabulary and concepts are limited to the extent that the stories would be understandable by 7 year olds. We discard the questions and only consider the free text of the stories.\nThe SimpleWiki dataset was created from the textual content of an October, 2014 4 dump of the Simple English Wikipedia. We discarded all lists, tables and titles in the wiki pages. We chose Simple English Wikipedia instead of Wikipedia articles to limit the complexity of the vocabulary and world knowledge required to comprehend the content thus making the task simpler and manageable.\nThe Desire-subject(s) and the Desire Fulfillment Status were manually annotated on CrowdFlower 5. Each instance was annotated by 3 or more annotators as determined by CrowdFlower using expected annotation accuracy. Annotators were also required to demonstrate proficiency on an initial set of 5 test instances. To avoid annotator fatigue, each annotator was presented only 3 instances per session. The mean CrowdFlower confidence (inter-annotator agreement weighted by their trust scores) of the annotations was 0.92.\nTraining and Test Sets: The SimpleWiki and MCTest data consisted of about 1000 and 175 instances, 20% of which was held-out as test sets. In the test sets of SimpleWiki and MCTest, 28% and 56% of the data belonged to the positive (desire fulfilled) class respectively."}, {"heading": "5 Empiricial Evaluation", "text": "For evaluation, we compared test set performances using F1 score of the positive (desire fulfilled) class. We also included a simple Logistic Regression baseline based on Bag-of-Words (BoW) features. Table 4 reports the performances of these models. For training the unstructured model, we experimented with different algorithms\n4http://dumps.wikimedia.org/simplewiki/ 5http://www.crowdflower.com/\nand show the results for the best two models: LR (Logistic Regression) and DT (Decision Trees). We report median performance values over 100 random restarts of our model since its performance depends on the initialization of the weights. Also, our model requires the number of latent states,H , as input which was set to be 2 and 15 for the MCTest and SimpleWiki datasets respectively using cross-validation. The difference in optimal H values (and F1 scores) for the two datasets could be attributed to the difference in complexity of the language and concepts used in them. The MCTest dataset consists of children stories, focusing on simple concepts and goals (e.g., \u2018wanting to go skating\u2019) and their fulfillment is indicated explicitly, in simple and focused language (e.g., They went to the skating rink together.). On the other hand, SimpleWiki describes real-life desires (e.g., \u2018wanting to conquer a country\u2019), which require sophisticated planning over multiple steps, which may provide only indirect indication of the desire fulfillment status. This added complexity resulted in a harder classification problem, and increased the complexity of inference over several latent states.\nThe table shows that LSNM outperforms the unstructured models indicating the benefit of modeling narrative structure. Also, the unstructured models perform better than the TE model emphasizing the need for simultaneous analysis all of the Evidence text. We obtained similar results during cross validation. For instance, the TE, unstructured models (best) and LSNM yielded F1 scores of 56.9, 67.9 and 70.2 respectively on the MCTest data. This shows that modeling the narrative presented by the Evidences results in better prediction of the desire fulfillment status."}, {"heading": "6 Related Work", "text": "Expressions of desires and wishes have attracted psycholinguists [29] and linguists [1] alike. [17] detect wishes from text. Analyzing desires adds a new dimension to more general tasks like opinion mining [26] where the manufacturers and advertisers want to discover users\u2019 desires or needs from online reviews etc. Another use-case would be in resolving issues for community forum users. For instance, the number of posts in Massive Open Online Courses forums often overwhelm the instructional staff [6]. Identifying posts containing unresolved issues can help focus the efforts of the instructional staff.\nOur problem is related to Machine Comprehension [28]. However, unlike most systems, designed for understanding large textual collections (macroreading) [12, 3, 13], this work focuses on Micro-reading, understanding short pieces of text. [2] also address micro-reading but with a different goal \u2013 answering domain-specific questions about entities in a paragraph.\nOur task is also related to Recognizing Textual Entailment (RTE) [8, 9]. However, we show that solving it additionally requires modeling the narrative structure of the text.\nThere have been several attempts at modeling narrative structures which include narrative schemas [5, 4], plot units [20] and Story Intention Graphs [11]. Previous work has also studied connotations and word effects on narrative modeling [15, 18]. Our approach is closely related to these methods. While focusing on a specific classification task, our structured model and features, share similar motivation.\nThe AI task of recognizing plans of characters in a narrative viewing them as intentional agents [25, 32, 22] is also relevant. However, the focused nature of our task lets us employ latent variables to model the transitions between expectations and plans.\nLatent structured models have been used previously for solving various problems in computer vision and NLP [31, 33, 14] though their problem settings and goals are different."}, {"heading": "7 Conclusion", "text": "In this paper we have addressed the novel task of analyzing small pieces of text containing expression of a desire to identify if the desire was fulfilled in the given text. For solving this problem, we adopt three approaches\nbased on different assumptions. We first use a textual entailment model to analyze small fragments of texts independently. Our second approach, an unstructured model, assumes that it is not sufficient to analyze different pieces of text independently. Instead, the complete text should be analyzed as a whole to identify desire fulfillment. Our third approach, a structured model, is based on the hypothesis that identifying desire fulfillment requires an understanding of the narrative structure and models the same using latent variables. We compare performances of these models on two different datasets that we have annotated and release. Our experiments establish the need to incorporate the narrative structure of the storyline offered by the text to better understand desire fulfillment."}], "references": [{"title": "Acquisition of desires before beliefs: A computational investigation", "author": ["L. Barak", "A. Fazly", "S. Stevenson"], "venue": "Proceedings of CoNLL-2013,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Modeling biological processes for reading comprehension", "author": ["J. Berant", "V. Srikumar", "P.-C. Chen", "A. Vander Linden", "B. Harding", "B. Huang", "P. Clark", "C.D. Manning"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Toward an architecture for neverending language learning", "author": ["A. Carlson", "J. Betteridge", "B. Kisiel", "B. Settles", "E.R.H. Jr.", "T.M. Mitchell"], "venue": "In Proceedings of the Twenty- Fourth AAAI Conference on Artificial Intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Unsupervised learning of narrative event chains", "author": ["N. Chambers", "D. Jurafsky"], "venue": "In Proceedings of the 46th annual meeting of the Association for Computational Linguistics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Unsupervised learning of narrative schemas and their participants", "author": ["N. Chambers", "D. Jurafsky"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Predicting instructor\u2019s intervention in mooc forums. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1501\u20131511", "author": ["S. Chaturvedi", "D. Goldwasser", "H. Daum\u00e9 III"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron  algorithms", "author": ["M. Collins"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Recognizing textual entailment: Rational, evaluation and approaches", "author": ["I. Dagan", "B. Dolan", "B. Magnini", "D. Roth"], "venue": "Natural Language Engineering,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "The PASCAL recognising textual entailment challenge", "author": ["I. Dagan", "O. Glickman", "B. Magnini"], "venue": "In Machine Learning Challenges. Lecture Notes in Computer Science,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "Detecting story analogies from annotations of time, action and agency", "author": ["D.K. Elson"], "venue": "In Proceedings of the LREC 2012 Workshop on Computational Models of Narrative,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Dramabank: Annotating agency in narrative discourse", "author": ["D.K. Elson"], "venue": "In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC-2012),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Machine reading", "author": ["O. Etzioni", "M. Banko", "M.J. Cafarella"], "venue": "In Proceedings, The Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Identifying relations for open information extraction", "author": ["A. Fader", "S. Soderland", "O. Etzioni"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "A discriminatively trained, multiscale, deformable part model", "author": ["P.F. Felzenszwalb", "D.A. McAllester", "D. Ramanan"], "venue": "In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Connotation lexicon: A dash of sentiment beneath the surface meaning", "author": ["S. Feng", "J.S. Kang", "P. Kuznetsova", "Y. Choi"], "venue": "In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics (Volume", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "The belief-desire-intention model of agency", "author": ["M. Georgeff", "B. Pell", "M. Pollack", "M. Tambe", "M. Wooldridge"], "venue": "In Intelligent Agents V: Agents Theories, Architectures, and Languages,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1999}, {"title": "May all your wishes come true: A study of wishes and how to recognize them", "author": ["A.B. Goldberg", "N. Fillmore", "D. Andrzejewski", "Z. Xu", "B. Gibson", "X. Zhu"], "venue": "In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Automatically producing plot unit representations for narrative text", "author": ["A. Goyal", "E. Riloff", "H. Daum\u00e9 III"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Attention, intentions, and the structure of discourse", "author": ["B.J. Grosz", "C.L. Sidner"], "venue": "Computational linguistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1986}, {"title": "Plot units and narrative summarization", "author": ["W.G. Lehnert"], "venue": "Cognitive Science,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1981}, {"title": "The excitement open platform for textual inferences", "author": ["B. Magnini", "R. Zanoli", "I. Dagan", "K. Eichler", "G. Neumann", "T. Noh", "S. Pad\u00f3", "A. Stern", "O. Levy"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Computational Modeling of Narrative", "author": ["I. Mani"], "venue": "Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["C.D. Manning", "M. Surdeanu", "J. Bauer", "J. Finkel", "S.J. Bethard", "D. McClosky"], "venue": "In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Wordnet: A lexical database for english", "author": ["G.A. Miller"], "venue": "Commun. ACM,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1995}, {"title": "Understanding goal-based stories through model finding and planning", "author": ["E.T. Mueller"], "venue": "Intelligent Narrative Technologies: Papers from the AAAI Fall Symposium,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "Opinion mining and sentiment analysis", "author": ["B. Pang", "L. Lee"], "venue": "Foundations and Trends in Information Retrieval,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2007}, {"title": "The penn discourse tree-bank 2.0 annotation manual", "author": ["R. Prasad", "E. Miltsakaki", "N. Dinesh", "A. Lee", "A. Joshi", "L. Robaldo", "B. Webber"], "venue": "Technical report,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2007}, {"title": "Mctest: A challenge dataset for the open-domain machine comprehension of text", "author": ["M. Richardson", "C.J.C. Burges", "E. Renshaw"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "The acquisition of mental verbs: A systematic investigation of the first reference to mental", "author": ["M. Shatz", "H.M. Wellman", "S. Silber"], "venue": "state. Cognition,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1983}, {"title": "BIUTEE: A modular open-source system for recognizing textual entailment. In The 50th Annual Meeting of the Association for Computational Linguistics", "author": ["A. Stern", "I. Dagan"], "venue": "Proceedings of the System Demonstrations,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Discovering finegrained sentiment with latent variable structured prediction models", "author": ["O. T\u00e4ckstr\u00f6m", "R. McDonald"], "venue": "In Proceedings of the 33rd European Conference on Advances in Information Retrieval,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "Understanding Goal-based Stories", "author": ["R. Wilensky"], "venue": "PhD thesis,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1978}, {"title": "Multi-level structured models for document-level sentiment classification", "author": ["A. Yessenalina", "Y. Yue", "C. Cardie"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2010}], "referenceMentions": [{"referenceID": 15, "context": "in contexts of rational agent behavior [16], and modeling human dialog interactions [19].", "startOffset": 39, "endOffset": 43}, {"referenceID": 18, "context": "in contexts of rational agent behavior [16], and modeling human dialog interactions [19].", "startOffset": 84, "endOffset": 88}, {"referenceID": 17, "context": "Such expressions can be used to provide rationale for character behaviors when analyzing narrative text [18, 10], extract information about human", "startOffset": 104, "endOffset": 112}, {"referenceID": 9, "context": "Such expressions can be used to provide rationale for character behaviors when analyzing narrative text [18, 10], extract information about human", "startOffset": 104, "endOffset": 112}, {"referenceID": 16, "context": "wishes [17], explain positive and negative sentiment in reviews, and support automatic curation of community forums by identifying unresolved issues raised by users.", "startOffset": 7, "endOffset": 11}, {"referenceID": 7, "context": "Similar to many other natural language understanding tasks [8, 28, 2], performance is evaluated using predic-", "startOffset": 59, "endOffset": 69}, {"referenceID": 27, "context": "Similar to many other natural language understanding tasks [8, 28, 2], performance is evaluated using predic-", "startOffset": 59, "endOffset": 69}, {"referenceID": 1, "context": "Similar to many other natural language understanding tasks [8, 28, 2], performance is evaluated using predic-", "startOffset": 59, "endOffset": 69}, {"referenceID": 3, "context": "Following previous work on narrative representation [4], we track the events and states associated with the narrative\u2019s central character (the Desire-subject).", "startOffset": 52, "endOffset": 55}, {"referenceID": 10, "context": "Recent attempts to support supervised learning of such detailed narrative structures by annotating data [11], result in highly complex structures even for restricted domains.", "startOffset": 104, "endOffset": 108}, {"referenceID": 7, "context": "Recognizing Textual Entailment (RTE) is the task of recognizing the existence of an entailment relationship between two text fragments [8].", "startOffset": 135, "endOffset": 138}, {"referenceID": 22, "context": "\u2022 If the Desire-subject is pronominal, replace it with the appropriate named entity when possible (we used the Stanford CoreNLP coreference resolution system) [23].", "startOffset": 159, "endOffset": 163}, {"referenceID": 29, "context": "Table 1 shows the performance of BIUTEE [30, 21], an RTE system, on the two datasets (see Sec.", "startOffset": 40, "endOffset": 48}, {"referenceID": 20, "context": "Table 1 shows the performance of BIUTEE [30, 21], an RTE system, on the two datasets (see Sec.", "startOffset": 40, "endOffset": 48}, {"referenceID": 14, "context": "We enhance this representation using several knowledge resources identifying word connotations [15] and relations.", "startOffset": 95, "endOffset": 99}, {"referenceID": 6, "context": "to get refined weights for the t iteration, wt, using structured perceptron [7].", "startOffset": 76, "endOffset": 79}, {"referenceID": 14, "context": "tions, and their emotive states using lexical resources like Connotation Lexicon [15], WordNet and our lexicon of conforming and dissenting phrases.", "startOffset": 81, "endOffset": 85}, {"referenceID": 22, "context": "3We obtained pos tags, dependency parses, and resolved co-references using Stanford CoreNLP [23].", "startOffset": 92, "endOffset": 96}, {"referenceID": 29, "context": "Entailment F1 TEPrediction: Binary prediction of the Textual Entailment model [30].", "startOffset": 78, "endOffset": 82}, {"referenceID": 23, "context": "Focal Word F4, F5, F6 focal count, focal syn and focal ant count: Count of occurrences of the focal word(s), their WordNet [24] synonyms and antonyms (respectively) in the Evidence.", "startOffset": 123, "endOffset": 127}, {"referenceID": 14, "context": "in blue), \u2018offered\u2019, is in connotative agreement with the intended action, \u2018help\u2019 (both have positive connotations according to [15]).", "startOffset": 128, "endOffset": 132}, {"referenceID": 26, "context": "These phrases were chosen using various discourse senses mentioned in [27].", "startOffset": 70, "endOffset": 74}, {"referenceID": 27, "context": "Collection and annotation: The MCTest data originated from the Machine Comprehension Test dataset [28] which contained of a set of 660 stories and", "startOffset": 98, "endOffset": 102}, {"referenceID": 28, "context": "Expressions of desires and wishes have attracted psycholinguists [29] and linguists [1] alike.", "startOffset": 65, "endOffset": 69}, {"referenceID": 0, "context": "Expressions of desires and wishes have attracted psycholinguists [29] and linguists [1] alike.", "startOffset": 84, "endOffset": 87}, {"referenceID": 16, "context": "[17] detect wishes from text.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "Analyzing desires adds a new dimension to more general tasks like opinion mining [26] where the manufacturers and advertisers want to discover users\u2019 desires or needs from online reviews etc.", "startOffset": 81, "endOffset": 85}, {"referenceID": 5, "context": "For instance, the number of posts in Massive Open Online Courses forums often overwhelm the instructional staff [6].", "startOffset": 112, "endOffset": 115}, {"referenceID": 27, "context": "Our problem is related to Machine Comprehension [28].", "startOffset": 48, "endOffset": 52}, {"referenceID": 11, "context": "However, unlike most systems, designed for understanding large textual collections (macroreading) [12, 3, 13], this work focuses on Micro-reading, understanding short pieces of text.", "startOffset": 98, "endOffset": 109}, {"referenceID": 2, "context": "However, unlike most systems, designed for understanding large textual collections (macroreading) [12, 3, 13], this work focuses on Micro-reading, understanding short pieces of text.", "startOffset": 98, "endOffset": 109}, {"referenceID": 12, "context": "However, unlike most systems, designed for understanding large textual collections (macroreading) [12, 3, 13], this work focuses on Micro-reading, understanding short pieces of text.", "startOffset": 98, "endOffset": 109}, {"referenceID": 1, "context": "[2] also address micro-reading but with a different goal \u2013 answering domain-specific questions about entities in a paragraph.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Our task is also related to Recognizing Textual Entailment (RTE) [8, 9].", "startOffset": 65, "endOffset": 71}, {"referenceID": 8, "context": "Our task is also related to Recognizing Textual Entailment (RTE) [8, 9].", "startOffset": 65, "endOffset": 71}, {"referenceID": 4, "context": "There have been several attempts at modeling narrative structures which include narrative schemas [5, 4], plot units [20] and Story Intention Graphs [11].", "startOffset": 98, "endOffset": 104}, {"referenceID": 3, "context": "There have been several attempts at modeling narrative structures which include narrative schemas [5, 4], plot units [20] and Story Intention Graphs [11].", "startOffset": 98, "endOffset": 104}, {"referenceID": 19, "context": "There have been several attempts at modeling narrative structures which include narrative schemas [5, 4], plot units [20] and Story Intention Graphs [11].", "startOffset": 117, "endOffset": 121}, {"referenceID": 10, "context": "There have been several attempts at modeling narrative structures which include narrative schemas [5, 4], plot units [20] and Story Intention Graphs [11].", "startOffset": 149, "endOffset": 153}, {"referenceID": 14, "context": "Previous work has also studied connotations and word effects on narrative modeling [15, 18].", "startOffset": 83, "endOffset": 91}, {"referenceID": 17, "context": "Previous work has also studied connotations and word effects on narrative modeling [15, 18].", "startOffset": 83, "endOffset": 91}, {"referenceID": 24, "context": "The AI task of recognizing plans of characters in a narrative viewing them as intentional agents [25, 32, 22] is also relevant.", "startOffset": 97, "endOffset": 109}, {"referenceID": 31, "context": "The AI task of recognizing plans of characters in a narrative viewing them as intentional agents [25, 32, 22] is also relevant.", "startOffset": 97, "endOffset": 109}, {"referenceID": 21, "context": "The AI task of recognizing plans of characters in a narrative viewing them as intentional agents [25, 32, 22] is also relevant.", "startOffset": 97, "endOffset": 109}, {"referenceID": 30, "context": "Latent structured models have been used previously for solving various problems in computer vision and NLP [31, 33, 14] though their problem settings and goals are different.", "startOffset": 107, "endOffset": 119}, {"referenceID": 32, "context": "Latent structured models have been used previously for solving various problems in computer vision and NLP [31, 33, 14] though their problem settings and goals are different.", "startOffset": 107, "endOffset": 119}, {"referenceID": 13, "context": "Latent structured models have been used previously for solving various problems in computer vision and NLP [31, 33, 14] though their problem settings and goals are different.", "startOffset": 107, "endOffset": 119}], "year": 2015, "abstractText": "The ability to comprehend desires and their fulfillment is important to Natural Language Understanding. This paper introduces the task of identifying if a desire expressed by a subject in a given short piece of text was fulfilled. We propose various unstructured and structured models that capture fulfillment cues such as the subject\u2019s emotional state and actions. Our experiments with two different datasets demonstrate the importance of understanding the narrative and discourse structure to address this task.", "creator": "LaTeX with hyperref package"}}}