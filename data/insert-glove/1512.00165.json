{"id": "1512.00165", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2015", "title": "Learning Using 1-Local Membership Queries", "abstract": "Classic sirenia machine learning re-incarnation algorithms self-absorbed learn kma from labelled examples. place-based For example, to design toray a machine .374 translation 030 system, mateer a verapaz typical sidewalls training set all-starr will s\u00f3c consist 66.6 of English commodores sentences 2455 and thyrsus their benmont translation. There is warhurst a sod stronger eron model, in dobrynska which the algorithm can smarties also query for 17:27 labels palopo of delvin\u00eb new allari examples nsic it creates. E. paraxylene g, in foregoing the translation abruptness task, concertaci\u00f3n the anchor/reporter algorithm gillie can create therapsids a draven new serei English lacalamita sentence, and \u00e4mter request trading its translation diverged from nationally-ranked the user during training. This tabon combination lishan of piguet examples weaste and vehz queries novopharm has smilodon been widely soleimani studied. chitta Yet, cyrille despite tijd many theoretical results, housewarming query 107-103 algorithms goldsbury are almost never used. One 164th of polidor the hashagen main manganiello causes for this deontic is camanche a qiqihar report (klatch Baum bregaglia and sphynx Lang, 1992) on sleone very disappointing 90.06 empirical performance sissy of a query algorithm. These poor denarii results were mainly attributed to numurkah the low-sulfur fact pertinax that the algorithm carwardine queried for labels pesters of sawatch examples that wmf are edu artificial, and blaes impossible congregation to interpret by humans.", "histories": [["v1", "Tue, 1 Dec 2015 07:40:49 GMT  (648kb,D)", "http://arxiv.org/abs/1512.00165v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["galit bary"], "accepted": false, "id": "1512.00165"}, "pdf": {"name": "1512.00165.pdf", "metadata": {"source": "CRF", "title": "Learning Using Local Membership Queries", "authors": ["Galit Bary", "Shai Shalev-Shwartz", "Amit Daniely", "Alon Gonen", "Nir Rosenfled", "Yoav Wald", "Yossi Arjevani", "Nomi Vinokurov"], "emails": [], "sections": [{"heading": null, "text": "Learning Using Local Membership Queries\nGalit Bary\nSubmitted in partial fulfillment of the requirements of the degree of Master of Science\nUnder the supervision of\nProf. Shai Shalev-Shwartz\nAmit Daniely\nSeptember 2015\nRachel and Selim Benin School of Computer Science and Engineering\nThe Hebrew University of Jerusalem Israel\nar X\niv :1\n51 2.\n00 16\n5v 1\n[ cs\n.L G\n] 1\nD ec\n2 01\n5\nAbstract\nClassic machine learning algorithms learn from labelled examples. For example, to design a machine translation system, a typical training set will consist of English sentences and their translation to French. There is a stronger model, in which the algorithm can also query for labels of new examples it creates. E.g, in the translation task, the algorithm can create a new English sentence, and request its translation from the user during training. This combination of examples and queries, that resembles human learning patterns, has been widely studied. Yet, despite many theoretical results, query algorithms are almost never used. One of the main causes for this is a report (Baum and Lang, 1992) on very disappointing empirical performance of a query algorithm. These poor results were mainly attributed to the fact that the algorithm queried for labels of examples that are artificial, and impossible to interpret by humans.\nIn this work we study a new model of local membership queries (Awasthi et al., 2012), which tries to resolve the problem of artificial queries. In this model, the algorithm is only allowed to query the labels of examples which are close to examples from the training set. E.g., in translation, the algorithm can change individual words in a sentence it has already seen, and then ask for the translation. In this model, the examples queried by the algorithm will be close to natural examples and hence, hopefully, will not appear as artificial or random. In this work we focus on 1-local membership queries (i.e., queries of distance 1 from an example in the training sample). We show that 1-local membership queries are already stronger than the standard learning model. We also present an experiment on a well known NLP task of sentiment analysis. In this experiment, the users were asked to provide, in a way that resembles 1-local queries, more information than merely indicating the label. We present results that illustrate that this extra information is beneficial in practice."}, {"heading": "Acknowledgments", "text": "I would like to thank my advisor Prof. Shai Shalev-Shwartz for having me on his outstanding team and for his support and inspiration. I would also like to thank Amit Daniely, for his guidance and mentorship. His extensive knowledge and patience were invaluable. It has been a privilege to work with him.\nTo Alon Gonen, Nir Rosenfled, Yoav Wald, Yossi Arjevani, Nomi Vinokurov and Avishai Wagner for their remarkable friendship and counsel. To the NLP lab and especially Effi Levi for all his assistance in the empirical work and to my officemates Zahi Ajami and Dikla Cohn for their wonderful companionship.\nI would like to thank my parents for all the love and support throughout the years, and to the Weisberg family for their help, especially Susan for her editorial comments. Last but not least, I would like to thank my husband Dov for his enduring support that is expressed on so many levels \u2013 encouraging me during difficult times, editing my drafts and providing home cooked meals.\nContents"}, {"heading": "1 Introduction 6", "text": ""}, {"heading": "2 Previous Work 8", "text": ""}, {"heading": "2.1 PAC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8", "text": "2.2 Membership Queries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2.3 Baum and Lang . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.4 Local Membership Queries . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2.5 Other Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11"}, {"heading": "3 Setting 12", "text": "3.1 The PAC Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.2 (Local) Membership Queries Model . . . . . . . . . . . . . . . . . . . . . . . 12"}, {"heading": "4 Learning DNFs with Evident Examples Using 1-local MQ 13", "text": "4.1 Definitions and Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 4.2 Upper Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 4.3 A Lower Bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20"}, {"heading": "5 Experiments 23", "text": "5.1 Is the additional data useful? . . . . . . . . . . . . . . . . . . . . . . . . . . 23 5.2 Experimental setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n5.2.1 Sentiment Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 5.2.2 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 5.2.3 Pre-processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 5.2.4 Language Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 5.2.5 Scoring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 5.2.6 The algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 5.3.1 Precision and Recall . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 5.3.2 Over-fitting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 5.4 Comparing to other Feature Selection Methods . . . . . . . . . . . . . . . . 29\n6 Conclusion and Future Work 31"}, {"heading": "1 Introduction", "text": "How do humans learn? Say we look at the process of a child learning how to recognize a cat. We can focus on two types of input. The first type of input is when a child\u2019s parent points at a cat and states \u201cLook, a cat!\u201d. The second type of input is an answer to the child\u2019s frequent question \u201cWhat is that?\u201d, which the child may pose when seeing a cat, but also when seeing a dog, a mouse, a rabbit, or any other small animal.\nThese two types of input were the basis for the learning model originally suggested in the celebrated paper \u201cA theory of the learnable\u201d (Valiant, 1984). In Valiant\u2019s learning model, the learning algorithm has access to two sources of information - EXAMPLES and ORACLE. The learning algorithm can call EXAMPLES to receive an example with its label (sampled from the \u201cnature\u201d). Additionally, the learning algorithm can use ORACLE, which provides the label of any example presented to it. With these two input types, we can look at two models of learning: learning using only calls for EXAMPLES, and learning using calls for both EXAMPLES and ORACLE. The first is the standard Probably Approximately Correct (PAC) model. The second is the so called PAC+MQ (Membership Queries) model. There has been a lot of theoretical work searching for the limits of the additional strength of membership queries. The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2).\nDespite that the MQ model seems much stronger, both intuitively and formally, it is rarely used in practice. This is commonly believed to result from the fact that in many cases it is not easy to implement MQ algorithms, that can create new and artificial examples to be labeled as part of the training phase. This problem of labeling artificial examples was highlighted by the experiment of Baum and Lang (1992). Baum and Lang implemented a membership query algorithm proposed by Baum (1991) for learning halfspaces . Their algorithm had very poor results, which was attributed to the fact that the algorithm created artificial and unnatural examples, which resulted in a noisy labeling. We elaborate on this experiment and criticize its conclusions in section 2.\nA suggested solution to the problem of unnatural examples was proposed by Awasthi et al. (2012). They suggested a mid-way model of learning with queries, but only restricted ones. The queries that their model allows the algorithm to ask are only local queries, i.e., queries that are close in some sense to examples from the sample set. Hopefully, examples which are similar to natural examples will also appear to be natural, or at least close to natural, and in any case will be far from appearing random or artificial. In their work, Awasti et al. started to investigate the power and the limitations of this model of local queries. They proved positive results on learning sparse polynomials with Oplogpnqqlocal queries under what they defined as locally smooth distributions1, which in some sense generalize the uniform and product distributions. They also proposed an algorithm that learns DNF formulas under the uniform distribution in quasi-polynomial time using only Oplogpnqq-local queries.\nThe exciting ideas of Awasthi et al. (2012) leave many directions for future work. One issue is that their analysis holds for a restricted family of distributions. While these results\n1locally \u03b1-smooth distributions can be defined as the class of distributions for which the logarithm of the density function is logp\u03b1q-Lipschitz with respect to the Hamming distance.\nprovide evidence of the excessive power of local queries, the distributional assumptions are rather strong.\nOur work follows Awasthi et al., and is focused on 1-local queries, which are the closest to the original PAC model. We formulate an arguably natural distributional assumption, and present an algorithm that uses 1-local membership queries to learn DNF formulas under this assumption. We also provide a matching lower bound: Namely, we prove that learning DNFs under our assumption is hard without the use of queries, assuming that learning decision trees is hard. This is the first example of a natural problem in which 1-local queries are stronger than the vanilla PAC model (it complements the work of Awasthi et al. who showed a similar result for a highly artificial problem).\nFinally, we provide some empirical evidence that using local queries can be helpful in practice, and importantly, that the implementation of the queries is easy, straightforward, and can be acquired by crowdsourcing without the use of an expert. We present a method for using local queries to perform a user-induced feature selection process, and present results of this protocol on the task of sentiment analysis of tweets. Our results show that by acquiring a more expressive data set, using (a variant of) 1-local queries, we can achieve better results with fewer examples. Based on the fact that a smaller data set is sufficient, we gain twice: we need less manpower for the labeling process and less computing power for the training process. We note that similar experiments also present encouraging results along this line (Raghavan and Allan, 2007; Raghavan et al., 2005; Settles, 2011; Druck et al., 2009). This supplies more evidence that such query-based methods can be useful in practice."}, {"heading": "2 Previous Work", "text": ""}, {"heading": "2.1 PAC", "text": "Valiant\u2019s Probably Approximately Correct (PAC) model of learning (Valiant, 1984) formulates the problem of learning a concept from examples. Examples are chosen according to a fixed but unknown and arbitrary distribution on the instance space. The learner\u2019s task is to find a prediction rule. The requirement is that with high probability, the prediction rule will be correct on all but a small fraction of the instances.\nA few positive results are known in this model - i.e., concept classes that have been proven to be PAC-learnable. Maybe the most significant example is the class of halfspaces. More examples include relatively weak classes such as DNFs and CNFs with constantly many terms (Valiant, 1984), and rank k decision trees (Ehrenfeucht and Haussler, 1989) for a constant k.\nDespite these positive results, most PAC learning problems are probably intractable. In fact, beyond the results mentioned above, almost no positive results are known. Furthermore, several negative results are known. For example, learning automatons, logarithmic depth circuits, and intersections of polynomially many halfspaces are all intractable, assuming the security of various cryptographic schemes (Kearns and Valiant, 1994; Klivans et al., 2006). In (Daniely et al., 2014; Daniely and Shalev-Shwatz, 2014; Daniely et al., 2013), it is shown that learning DNF formulas, and learning intersections of \u03c9plogpnqq halfspaces are intractable under the assumption that refuting random k-SAT is hard."}, {"heading": "2.2 Membership Queries", "text": "The PAC model is a \u201cpassive\u201d model in which the learner receives a random data set of examples and their labels and then outputs a classifier. A stronger version would be an active model in which the learner gathers information about the world by asking questions and receiving responses. Several types of active models have been proposed: the Membership Query Synthesis, Stream-Based Selective Sampling, and Pool-Based Sampling (Settles, 2010). Our work is in the area of the \u201cMembership Queries\u201d (MQ) model which was presented in (Valiant, 1984). In this model the learner is allowed to query for the label of any particular example that it chooses (even examples that are not in the given sample).\nThis model has been shown to be stronger in several scenarios. Some examples of concept classes that have been proven to be PAC-learnable only if membership queries are available include: The class of Deterministic Finite Automatons (Angluin, 1987), the class of k-term DNF for k \u201c logpnqlogplogpnqq (Blum and Rudich, 1992), the class of decision trees and k-almost monotone-DNF formulas (Bshouty, 1995), the class of intersections of k-halfspaces (Baum, 1991) and the class of DNF formulas under the uniform distribution (Jackson, 1994). The last of these results was built upon Freund\u2019s boosting algorithm (Freund, 1995) and the Fourier-based technique for learning using membership queries due to (Kushilevitz and Mansour, 1993).\nIt should be noted that there are cases in which the additional strength of MQ does not help. E.g., in the case of learning DNF and CNF formulas (Angluin and Kharitonov, 1995), and in the case of distribution free agnostic learning (although in the distribution-specific agnostic setting membership queries do increase the power of the learner) (Feldman, 2009)."}, {"heading": "2.3 Baum and Lang", "text": "As discussed above, there has been widespread and significant theoretical work in the PAC + MQ model. On the other hand, almost no practical work on implementing these ideas has been done. A well-known exception is the work of Baum and Lang (1992). They applied a variation of the MQ algorithm for learning a linear classifier proposed in Baum (1991). This algorithm uses the idea that given two examples, one positive and one negative, and a query oracle, it is possible to find an approximately accurate separating halfspace by using a binary search on the line between the positive and negative examples. Their experiment attempts to evaluate this idea in practice. The task that they chose is the task of binary digit classification. The algorithm would receive two examples, one positive and one negative (say, an image of the digit 4 and an image of the digit 7) and would return the weights of the halfspace. The generalization error of the halfspace would then be tested on other examples from the data. The query technique they used in the experiment is different than in the original algorithm: \u201cA direct implementation of this algorithm would repeatedly flash images on the screen during the binary search and would require the test subject to type in the correct label for each image. Because this process seemed likely to be error prone, we instead provided an interface that permitted the test subject to scan through the input space using the mouse and then click on an image that seemed to lie right at the edge of recognizability\u201d (from Baum and Lang (1992)).\nFor an example of what the users saw on the screen see figure 1.\nThey compared the performance of their algorithm to five other variants, three classic PAC (sample based) algorithms: Backpropogation, Perceptron and simplex, and two baselines: the first returns the perpendicular bisection of the line segments connecting the two examples, and the second returns a randomly oriented hyperplane through the midpoint of the line. The query learning algorithm uses the additional information obtained from the users as described above, while the three PAC algorithms use additional examples drawn from the data set. All three PAC algorithms outperformed the query-based algorithm. More surprisingly, even the baseline of choosing the perpendicular bisection line had significantly better results than the halfspace created by the query algorithm. The only method that\nwas worse than the query based method was the random bisector method. They suggest that the reason for the poor results is that the question the users had to answer, to find the boundary pattern, lay outside the range of the human competence.\nThis work led many to the conclusion that membership queries are not useful in practice (Settles (2010); Balcan et al. (2006); Dasgupta (2004) and more). We argue that there are several problems with this conclusion. First and foremost, the task that the users were asked to perform (scanning through images and finding the boundary between digits) is not an intuitive task, and it is very easy to think of other variants for queries which would be more suitable. It is therefore not surprising that the labeling turned out to be noisy considering the nature of the question at hand. Second, their algorithm did not use the PAC abilities; it used queries but did not use the additional option to sample extra points for the data."}, {"heading": "2.4 Local Membership Queries", "text": "Several suggestions have been made of ways to solve the problem of the algorithm\u2019s generation of unnatural examples. The most common one was to drop the whole framework of membership queries and focus on the other types of active learning: stream-based and pool-based. The idea is to filter existing examples taken from a large unlabeled data set drawn from the distribution rather than creating artificial examples. Another suggestion is to give the human annotator the option of answering \u201cI don\u2019t know\u201d, or to be tolerant of some incorrect answers. The theoretical framework is the model of an incomplete membership oracle in which the answers to a random subset of the queries may be missing. This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ. (Angluin et al. (1997); Blum et al. (1995); Sloan and Tura\u0301n (1994); Bisht et al. (2008)).\nThe third method is to restrict the examples that the learning algorithm can query to examples that are similar to examples drawn from the distribution. This is formalized in the work of Awasthi et al. (2012). They present the concept of learning using only local membership queries. This framework deals with the problem raised by (Baum and Lang, 1992). By questioning about examples which are close to examples from the distribution we escape the problem of generating random or non-classifiable examples.\nThe work of Awasthi et al. focused on the n-dimensional boolean hyper-cube X \u201c t\u00b41, 1un and on Oplogpnqq-local queries, i.e., the learning algorithm is given the option to query the label of any point for which there exists a point in the training sample with hamming distance lower than Oplogpnqq. The model they suggested is a mid-way model between the PAC model (0-local queries) and the PAC + MQ model (n-local queries). Their main result is that t-sparse polynomials are learnable under locally smooth distributions using O plogpnq ` logptqq-local queries. Another interesting result that they presented is that the class of DNF formulas is learnable under the uniform distribution in quasi-polynomial time (nOplog lognq) using Oplogpnqq-local queries. They also presented some results regarding the strength of local MQ. They proved that under standard cryptographic assumptions, using pr ` 1q-local queries is more powerful than using r-local queries (for every 1 \u010f r \u010f n \u00b4 1). They also showed that local queries do not always help. They showed that if a concept class is agnostically learnable under the uniform distribution using k-local queries\n(for constant k) then it is also agnostically learnable (under the uniform distribution) in the PAC model."}, {"heading": "2.5 Other Related Work", "text": "In section 5, we give some experimental evidence that the use of extra information from the user is helpful. There have been other works along the same line. Druck et al. (2009) propose a pool-based active learning approach in which the user provides labels for input features, rather than instances. The users are asked to provide a \u201clabel\u201d for input features, where a labeled input feature denotes that a particular feature is highly indicative of a particular label. Following that, Settles (2011) presented an active learning annotation interface, in which the users label instances and features simultaneously. At any point in time, an instance and a list of features for each label is presented on the screen. The user can choose to either label the instance, choose a feature from the list as being indicative, or add a new feature of his or her choice. Another similar work is of Raghavan and Allan (2007) and Raghavan et al. (2005). They studied the problem of tandem learning where they combine uncertainty sampling for instances along with co-occurrence-based interactive feature selection. All the above experiments were conducted on the text domain and the features were always unigrams. The experiments presented encouraging results of using the human annotators, either by reaching better results, or by showing that the excessive use of annotators can reduce the size of the data set, and sometimes both."}, {"heading": "3 Setting", "text": ""}, {"heading": "3.1 The PAC Model", "text": "Our framework is an extension of the PAC (Probably Approximately Correct) model of learning. Before introducing it, we will briefly review PAC learning. We will only consider binary classification where the instance space is X \u201c Xn \u201c t\u00b41, 1un and the label space is Y \u201c t0, 1u. A learning problem is defined by a hypothesis class H \u0102 t0, 1uX . We assume that the learner receives a training set\nS \u201c tpx1, h\u2039px1qq, px2, h\u2039px2qq, . . . , pxm, h\u2039pxmqqu P pX \u02c6 Yqm\nwhere the xi\u2019s are sampled i.i.d. from some unknown distribution D on X and h\u2039 : X \u00d1 Y is some unknown hypothesis. We will focus on the so-called realizable case where h\u2039 is assumed to be in H. The learner returns (a description of) a hypothesis h\u0302 : X \u00d1 Y. The goal is to approximate h\u2039, namely to find h\u0302 : X \u00d1 Y with loss as small as possible, where the loss is defined as LD,h\u2039ph\u0302q \u201c Px\u201eD \u00b4 h\u0302pxq \u2030 h\u2039pxq \u00af . We will require our algorithms to return a hypothesis with loss \u0103 in time that is polynomial in n and 1 . Concretely,\nDefinition 1 (Learning algorithm) We say that a learning algorithm A PAC learns H if\n\u2022 There exists a function mA pn, q \u010f poly ` n, 1 \u02d8 , such that for every distribution D over X , every h\u2039 P H and every \u0105 0, if A is given a training sequence\nS \u201c tpx1, h\u2039px1qq, px2, h\u2039px2qq, . . . , pxm, h\u2039pxmqqu\nwhere the xi\u2019s are sampled i.i.d. from D and m \u011b mApn, q, then with probability of at least 34 (over the choice of S) 2, the output h\u0302 of A satisfies LD,h\u2039ph\u0302q \u0103 .\n\u2022 Given a training set of size m\n\u2013 A runs in time polypm,nq. \u2013 The hypothesis returned by A can be evaluated in time polypm,nq.\nDefinition 2 (PAC learnability) We say that a hypothesis class H is PAC learnable if there exists a PAC learning algorithm for this class."}, {"heading": "3.2 (Local) Membership Queries Model", "text": "Learning with membership queries is an extension of the PAC model in which the learning algorithm is allowed to query the labels of specific examples in the domain set. A membership query is a call to an ORACLE which receives as input some x P X and returns h\u2039pxq. This is called a \u201cmembership query\u201d because the ORACLE returns 1 if x is in the set of examples positively labeled by h\u2039.\n2The success probability can be amplified to 1\u00b4 \u03b4 by repetition.\nDefinition 3 (Membership-Query Learning Algorithm) We say that a learning algorithm A learns H with membership queries if\n\u2022 There exists a function mA pn, q \u010f poly ` n, 1 \u02d8 , such that for every distribution D over X , every h\u2039 P H and every \u0105 0, if A is given access to membership queries, and a training sequence\nS \u201c tpx1, h\u2039px1qq, px2, h\u2039px2qq, . . . , pxm, h\u2039pxmqqu\nwhere the xi\u2019s are sampled i.i.d. from D and m \u011b mApn, q, then with probability of at least 34 (over the choice of S), the output h\u0302 of A satisfies LD,h\u2039ph\u0302q \u0103 .\n\u2022 Given a training set of size m\n\u2013 A asks at most polypm,nq membership queries. \u2013 A runs in time polypm,nq. \u2013 The hypothesis returned by A can be evaluated in time polypm,nq.\nOur work will deal with a specific type of membership queries, ones that are in some way close to examples that are already in the sample. Concretely, we say that a membership query x P X is q-local if there exists a training example x1 whose Hamming distance3 from x is at most q.\nDefinition 4 (Local-Query Learning Algorithm) We say that a learning algorithm A learns H with q-local membership queries if A learns H with membership queries that are all q-local.\nDefinition 5 We say that a hypothesis class H is q-LQ learnable if there exists a q-Localquery learning algorithm for this class.\nLearning Under a Specific Family of Distributions\nIn the classic PAC model discussed above, the learning algorithm needs to be probablyapproximately correct for any distribution D on X and any hypothesis h\u2039 P H. In this work we will have guarantees with respect to more restricted families. We will say that A learns H w.r.t a family D of pairs pD, hq of distributions on X and hypotheses in H if the following holds: The algorithm A satisfies the requirements of a learning algorithm whenever the pair D and h in the definition of a learning algorithm belongs to D . Similar considerations apply also to the notion of learning with (local) membership queries."}, {"heading": "4 Learning DNFs with Evident Examples Using 1-local MQ", "text": ""}, {"heading": "4.1 Definitions and Notations", "text": "Definition 6 (Disjunction Normal Form Formula) A DNF term is a conjunction of literals. A DNF formula is a disjunction of DNF terms.\n3We only consider the instance space t\u00b41, 1un, so the hamming distance is natural. However, the definition can be extended to other metrics.\nEach DNF formula over n variables naturally induces a function h : t\u00b41, 1un \u00d1 t0, 1u (when we standardly identify t0, 1u with \u201cTrue\u201d and \u201cFalse\u201d). We denote by hF the function induced by the DNF formula F .\nRemark 1 We will look at succinctly described hypotheses (e.g., a DNF with a small number of terms) and on small, but non-negligible probabilities. For simplicity, we will take the convention that small is at most n2 and non negligible is at least 1\nn3 . All of our results\ncan be easily generalized to the case where \u201csmall\u201d and \u201cnon-negligible\u201d are defined as \u010f nc1 and \u011b 1nc2 for any constants c1, c2 \u0105 0.\nDefinition 7 Denote by HDNF the hypothesis class of all functions that can be realized by a DNF with a small number of terms. That is\nHDNF \u201c thF : F is a DNF formula with at most n2 termsu\nIntuitively, when evaluating a DNF formula on a given example, we check a few conditions (corresponding to the formula\u2019s terms), and deem the example positive if one of the conditions holds. We will consider the case that for each of these conditions, there is some chance to see a \u201cprototype example\u201d. Namely, an example that satisfies only this condition in a strong (or evident) way.\nDefinition 8 Let F \u201c T1 _ T2 _ . . . _ Td be a DNF formula. An example x P t\u00b41, 1un satisfies a term Ti (with respect to the formula F ) evidently if :\n\u2022 It satisfies Ti. (In particular, hF pxq \u201c 1)\n\u2022 It does not satisfy any other term Tk (for k \u2030 i) from F.\n\u2022 No coordinate change will turn Ti False and another term Tk True. Concretely, if for j P rns we denote x\u2018j \u201c px1, . . . , xj\u00b41,\u00b4xj , xj`1, . . . , xnq, then for every coordinate j P rns, if x\u2018j satisfies F (i.e. if hF px\u2018jq \u201c 1) then x\u2018j satisfies Ti and only Ti.\nThe first distributional assumption that we consider is that each positive example satisfies one term evidently.\nDefinition 9 A pair pD, h\u2039q of a distribution D over t\u00b41, 1un and h\u2039 : t\u00b41, 1un \u00d1 t0, 1u is realized by a small DNF with evident examples if there exists a DNF formula F \u201c T1_T2_ . . ._Td over t\u00b41, 1un with d \u010f n2 such that h\u2039 \u201c hF and additionally, every positive example x P t\u00b41, 1un with Dpxq \u0105 0 satisfies one of F \u2019s terms evidently.\nOne of the assumptions in our definition is that the target function can be realized by a DNF formula for which every example satisfies at most one term. For a function that is realized by a decision tree this always holds. So, in a sense, our assumption holds for functions that can be realized by a \u201cstable\u201d decision tree.\nThe above definition makes a strong assumption, namely that every positive example is an evidence for one term. The next definition relaxes that assumption and only assumes that for every term there is a non-negligible probability to see an evident example.\nDefinition 10 A pair pD, h\u2039q of a distribution D over t\u00b41, 1un and h\u2039 : t\u00b41, 1un \u00d1 t0, 1u is weakly realized by a small DNF with evident examples if there exists a DNF formula F \u201c T1 _ T2 _ . . . _ Td over t\u00b41, 1un with d \u010f n2 such that h\u2039 \u201c hF and for every term Ti there is a non-negligible\n4 probability to see an example that satisfies this term evidently.\nFor example, our assumption holds for every distribution D, provided that h\u2039 can be realized by a DNF formulas in which any pair of different terms contains two opposite literals."}, {"heading": "4.2 Upper Bounds", "text": "We will now present two learning algorithms that use 1-LQ, and prove that each of these algorithms learn the class HDNF with respect to the families of distributions defined above. Both algorithms use the following claim that follows directly from definition 8\nClaim 1 Let F \u201c T1 _ T2 _ . . . _ Td be a DNF formula over t\u00b41, 1un. Then for every x P t\u00b41, 1un that satisfies a term Ti evidently (with respect to F ), for every j P rns it holds that:\nhF px\u2018jq \u201c 1 \u00f0\u00f1 the term Ti does not contain the variable xj\nAlgorithm 1 Create a DNF formula Input: S P pt\u00b41, 1un \u02c6 t0, 1uqm Output: A DNF formula H\nstart with an empty DNF formula H for all px, yq P S do\nif y \u201c 1 then define T \u201c x1 ^ x1 ^ x2 ^ x2 ^ . . .^ xn ^ xn for 1 \u010f j \u010f n do\nquery x\u2018j (to get h\u2039px\u2018jq) if h\u2039px\u2018jq \u201c 1 then\nremove xj and xj from T if h\u2039px\u2018jq \u201c 0 then\nif xj \u201c 1 then remove xj from T if xj \u201c 0 then remove xj from T\nH \u201c H _ T return H\nTheorem 1 The hypothesis class HDNF is 1-LQ learnable with respect to distributions that are realized by a DNF with evident examples.\n4Recall that non-negligible is at least 1 n3\nProof We will prove that algorithm 1 learns HDNF with 1-local membership queries. First, it is easy to see that this algorithm is efficient: For a training set of size m the algorithm asks for at most n \u00a8m 1-local membership queries, and runs in time Opnmq. Likewise, the hypothesis that the algorithm returns is a DNF formula with at most m terms and every term is of size at most n, therefore it can be evaluated in time polynomial in mn.\nNow, let D be a distribution on t\u00b41, 1un and h\u2039 : t\u00b41, 1un \u00d1 t0, 1u be a hypothesis such that the pair pD, h\u2039q is realized by a small DNF with evident examples. Let F \u201c T1 _ T2 _ . . . _ Td be that small DNF formula, (in particular h\u2039 \u201c hF and d \u010f n2). For \u0105 0 we take a sample S \u201c tpxi, h\u2039pxiqumi\u201c1 where txiumi\u201c1 are sampled i.i.d from D and m \u201c 2n2 log 2n2 \u011b 2d log 2d .\nLet H be the DNF formula returned by the algorithm after running on S, and let h\u0302 be the function induced by H. We will prove that with probability of at least 3/4 (over the choice of the examples) LD,h\u2039ph\u0302q \u0103 4 .\nFrom the assumption on the distribution we get that every instance x that satisfies the formula (in our case every x such that px, 1q P S), satisfies exactly one term T . For every one of these positive instances from S, we will show that we add that exact term to H. For every such x we start with a full term (containing all the possible literals) and then for every j P rns, at iteration j:\n\u2022 if h\u2039pxq \u201c h\u2039px\u2018jq \u201c 1 we know from claim 1 that the variable xj cannot appear in T - so we remove it and its negation from the current term.\n\u2022 if h\u2039pxq \u201c 1 and h\u2039px\u2018jq \u201c 0 we know that either xj or xj appears in T and we remove the one that cannot appear in T according to the value of xj .\nAfter n iterations we get exactly T - the term that x satisfies evidently. Therefore - H will contain every term from F for which there was an instance x in S that satisfies it - other then that H will contain no other terms. In other words,\nP x\u201eD\nrh\u2039pxq \u201c 0^ h\u0302pxq \u201c 1s \u201c 0\nand we get that\nLD,h\u2039ph\u0302q \u201c P x\u201eD rh\u2039pxq \u2030 h\u0302pxqs \u201c P x\u201eD rh\u2039pxq \u201c 1^ h\u0302pxq \u201c 0s\nDenote by pi the probability to sample x (from D) that will satisfy Ti, and let Ai be the event that S did not contain any x which satisfies Ti. Then\nP x\u201eD rh\u2039pxq \u201c 1^ h\u0302pxq \u201c 0s \u201c P x\u201eD rDi P rds such that x satisfies Ti ^ h\u0302pxq \u201c 0s\n\u010f d \u00ff\ni\u201c1 P x\u201eD rx satisfies Ti ^ h\u0302pxq \u201c 0s \u201c\nd \u00ff i\u201c1 pi \u00a8 1Ai\nNotice that since pi is the probability to sample x we get that P S\u201eDm rAis \u201c p1\u00b4 piqm\nNow if we look at the expectation we get\nE S\u201eDm rLD,h\u2039ph\u0302qs \u010f E S\u201eDm\nr d \u00ff\ni\u201c1 pi \u00a8 1Ais\n\u201c d \u00ff\ni\u201c1 pi E S\u201eDm r1Ais\n\u201c d \u00ff\ni\u201c1 pi P S\u201eDm rAis\n\u201c d \u00ff\ni\u201c1 pip1\u00b4 piqm\n\u201c \u00ff\ni|pi\u0103 2d\npip1\u00b4 piqm ` \u00ff\ni|pi\u011b 2d\npip1\u00b4 piqm\n\u010f \u00ff\ni|pi\u0103 2d\n2d `\n\u00ff\ni|pi\u011b 2d\np1\u00b4 piqm\n\u010f d \u00a8 2d `\n\u00ff\ni|pi\u011b 2d\ne\u00b4mpi\n\u010f 2 ` d \u00a8 e\u00b4m 2d\nSince m \u011b 2d log 2d we get ErLD,h\u2039ph\u0302qs \u0103 and using Markov\u2019s inequality we obtain\nP S\u201eDm\nrLD,h\u2039ph\u0302qs \u011b 4 s \u010f ErLD,h\u2039ph\u0302qs 4 \u0103 1 4\nAlgorithm 2 Create a DNF formula with checking and deleting false terms Input: S1, S2 \u010e pt\u00b41, 1un \u02c6 t\u00b41, 1uqm Output: a DNF formula H\nstart with an empty DNF formula H for all px, yq P S1 do\nif y \u201c 1 then define T \u201c x1 ^ x1 ^ x2 ^ x2 ^ . . .^ xn ^ xn for 1 \u010f j \u010f n do\nquery x\u2018j (to get h\u2039px\u2018jq) if h\u2039px\u2018jq \u201c 1 then\nremove xj and xj from T if h\u2039px\u2018jq \u201c 0 then\nif xj \u201c 1 then remove xj from T if xj \u201c 0 then remove xj from T\nH \u201c H _ T for all T in H do\nfor all px, yq P S2 do if T pxq \u201c 1 but y \u201c 0 then\nremove T from H return H\nTheorem 2 The hypothesis class HDNF is 1-LQ learnable with respect to distributions that are weakly realized by a DNF with evident examples.\nProof We will prove that algorithm 2 learns HDNF with 1-local membership queries. In this case we will have two sample sets - S1 of size m1 which will be used as before - to build the terms of H, and S2 of size m2 - a separate set to check the terms that were built. Again, it is easy to see that this algorithm is efficient. For training sets S1 of size m1 and S2 of size m2 the algorithm asks for at most n \u00a8m1 1-local membership queries. The running time of the first loop is Opnm1q and in that loop we add at most m1 terms to H so the running time of the second loop is Opm1m2q. All in all the running time is polynomial in pm1,m2, nq. Also, the hypothesis that the algorithm returns is a DNF formula with at most m1 terms and every term is of size at most n, therefore it can be evaluated at time polynomial in m1n.\nNow, let D be a distribution on t\u00b41, 1un and h\u2039 : t\u00b41, 1un \u00d1 t0, 1u be a hypothesis such that the pair pD, h\u2039q is realized by a small DNF with evident examples. Let F \u201c T1 _ T2 _ . . ._ Td be that small DNF formula, (in particular h\u2039 \u201c hF and d \u010f n2). Denote by H \u201c T\u03021 _ T\u03022 _ . . . _ T\u0302k the DNF formula algorithm 2 returns. Following the same argument from the last proof, a term Ti will be added to H in the first loop if S1 contains an example that satisfies Ti evidently. We will define m1 so that with high probability for every term Ti there will be px, 1q P S1 such that x satisfies Ti evidently. Denote by si the probability to sample x (from D) that satisfies Ti evidently, and let\ns \u201c mintsiudi\u201c1. Since for every term the probability to see an evident example is nonnegligible, s \u011b n\u00b43. For every i, the probability of not seeing an example in S1 that satisfies Ti evidently is\np1\u00b4 siqm \u010f p1\u00b4 sqm \u010f e\u00b4sm \u010f e\u00b4 m n3\nIf we set m1 to be n 3 logp8n2q \u011b n3 logp8dq we get that the probability of not seeing an example that satisfies Ti evidently (when sampling S1 from Dm1) is less than 18d and from the union bound we get that the probability that the sample will contain an evident example for every term is at least 78 . Therefore with probability of at least 7 8 we will add every Ti to H in the first loop. In the second loop, when we remove terms from H, we only remove terms which contradicts one of the examples in S2. Since all of the examples in the sample set are labeled by F , we will never remove a term that is a part of F Therefore with probability of at least 78 H will contain all of F \u2019s terms. Formally,\nP S1\u201eDm1 r P x\u201eD rh\u2039pxq \u201c 1^ h\u0302pxq \u201c 0s \u201c 0s \u011b 7 8\nNote that we are not done, as the algorithm might create a wrong term (when using a \u201dnon-evident\u201d example). For this reason we add the second loop. We use the sample S2 to test every term T\u0302i that was added to H in the first loop. If we see an example x such that T\u0302ipxq \u201c 1 but h\u2039pxq \u201c 0 we remove T\u0302i and continue to the next term. Now denote by pi the probability to sample x (from D) that will satisfy T\u0302i, and by Ai the event that T\u0302i is a wrong term (not from F) but the \u201dchecking\u201d step did not discover that. Then\nP x\u201eD rh\u0302pxq \u201c 1^ h\u2039pxq \u201c 0s \u201c P x\u201eD rDi P rks such that x satisfies T\u0302i ^ h\u2039pxq \u201c 0s\n\u010f k \u00ff\ni\u201c1 P\nx\u201eD rx satisfies T\u0302i ^ h\u2039pxq \u201c 0s\n\u201c k \u00ff\ni\u201c1 pi \u00a8 1Ai\nNote that since Ai is the event that there wasn\u2019t any example in S2 which satisfied T\u0302i (otherwise the checking step would discover that T\u0302i is wrong) this is the same situation as in the proof of theorem 1, so\nP S2\u201eDm2\nrAis \u201c p1\u00b4 piqm2\nBy the same analysis of the former proof, we get that if the size of S2 is \u011b 2k log 2k then\nP S2\u201eDm2 r P x\u201eD rh\u2039pxq \u201c 0^ h\u0302pxq \u201c 1s \u011b 4 s \u010f 1 4\nFinally we notice that k \u010f m1, because for each example in S1 the algorithm adds at most one term to H. So we can set m1 as above and m2 \u201c 2m1 log 2m1 and if we run algorithm\n2 on S1 and S2 we get that with probability of at least 1\u00b4 p14 ` 1 8q \u201c 3 4 \u00b4 1 8 over sampling"}, {"heading": "S1 and S2", "text": "LD,h\u2039ph\u0302q \u201c P x\u201eD\nrh\u2039pxq \u2030 h\u0302pxqs\n\u201c P x\u201eD rh\u2039pxq \u201c 1^ h\u0302pxq \u201c 0s ` P x\u201eD rh\u2039pxq \u201c 0^ h\u0302pxq \u201c 1s \u010f 0` 4 \u201c 4"}, {"heading": "4.3 A Lower Bound", "text": "In this section we provide evidence that the use of queries in our upper bounds is crucial. We will show that the problem of learning poly-sized decision trees can be reduced to the problem of learning DNFs w.r.t. distributions that are realized by a small DNF with evident examples. As learning decision trees is widely believed to be intractable (in fact, even learning the much smaller class of logpnq-juntas is conjectured to be hard), this reduction serves as an indication that the problems we considered are hard without membership queries.\nDefinition 11 A decision tree over t\u00b41, 1un is a binary tree with labels chosen from x1, . . . , xn on the internal nodes, and labels from t0, 1u on the leaves. Each internal node\u2019s left branch is viewed as the \u00b41 branch; the right branch is the 1 branch. Each decision tree over n variables induces a function h : t\u00b41, 1un \u00d1 t0, 1u in the following way: For a decision tree T , a vector a P t\u00b41, 1un defines a path in the tree from the root to a specific leaf by choosing ai\u2019s branch at each node xi and the value that the function hT returns on a is defined to be the label of the leaf at the end of this path.\nDefinition 12 Denote by HDT the hypothesis class of all functions that can be realized by a decision tree with a small number of leaves. That is\nHDT \u201c thT : T is a DT with at most n2 leavesu\nTheorem 3 PAC learning the hypothesis class HDNF w.r.t distributions that are realized by a small DNF with evident examples is as hard as PAC learning HDT.\nThe proof will follow from the following claim:\nClaim 2 There exists a mapping (a reduction) \u03d5 : t\u00b41, 1un \u00d1 t\u00b41, 1u2n, that can be evaluated in polypnq time so that for every decision tree T over t\u00b41, 1un there exists a DNF formula F over t\u00b41, 1u2n such that the following holds:\n1. The number of terms in F is upper bounded by the number of leaves in T\n2. hT \u201c hF \u02dd \u03d5\n3. @x such that hT pxq \u201c 1 , \u03d5pxq satisfies some term in F evidently.\nProof We will denote t\u00b41, 1un by Xn and t\u00b41, 1u2n by X2n. Define \u03d5 as follows:\n@x \u201c px1, x2, . . . , xnq P Xn \u03d5px1, x2, . . . , xnq \u201c px1, x1, x2, x2, . . . , xn, xnq\nNow, for every tree T , we will build the desired DNF formula F as follows: First we build F 1 - a DNF formula over t\u00b41, 1un . Every leaf labeled \u20191\u2019 in T will define the following termtake the path from the root to that leaf and form the logical AND of the literals describing the path. F 1 will be a disjunction of these terms. Now, for every term T in F 1 we will define a term \u03c6pT q over X2n in the following way: Let PT \u201c ti P rns : xi appear in Tu and NT \u201c ti P rns : xi appear in Tu. So\nT \u201c \u013e\njPPT\nxj \u013e\njPNT\nxj\nDefine\n\u03c6pT q \u201c \u013e\njPPT\nx2j\u00b41 \u013e\njPPT\nx2j \u013e\njPNT\nx2j\u00b41 \u013e\njPNT\nx2j\nFinally, define F to be the DNF formula over X2n by\nF \u201c \u0142\nTPF 1 \u03c6pT q\nWe will now prove that \u03d5 and F satisfy the required conditions. First, \u03d5 can be evaluated in linear time in n. Second, it is easy to see that hT \u201c hF \u02dd\u03d5, and as every term in F matches one of T \u2019s leaves, the number of terms in F cannot exceed the number of leaves in T . It is left to show that the third requirement holds. Let there be an x such that hT pxq \u201c 1, then x is matched to one and only one path from T \u2019s root to a leaf labeled \u20191\u2019. From the construction of F , x satisfies one and only one term in F 1 because every term is matched to exactly one path from T \u2019s root to a leaf labeled 1. Regarding the last requirement - that no coordinate change will make one term from F False and another one True - we made sure this will not happen by \u201cdoubling\u201d each variable. By this construction, in order to change a term from False to True at least two coordinate must change their value.\nProof [of theorem 3] Suppose we have an efficient algorithm A that PAC learns HDNF with respect to distributions that are realized by DNF with evident examples. Using the reduction from claim 2 we will build an efficient algorithm B that will PAC learn HDT. For every training set with examples from Xn:\nS \u201c tpx1, h\u2039px1qq, px2, h\u2039px2qq, . . . , pxm, h\u2039pxmqqu P pXn \u02c6 t0, 1uqm\nwe define a matching training set with examples from X2n, using \u03d5 from the above claim:\nS\u0303 :\u201c tp\u03d5px1q, h\u2039px1qq, p\u03d5px2qq, h\u2039px2qq, . . . , p\u03d5pxmq, h\u2039pxmqqu P pX2n \u02c6 t0, 1uqm\nThe algorithm B will work as follows: Given a training set S, B will construct S\u0303 \u201c \u03d5pSq and then run A with input S\u0303. Let h\u0302 be the output of A when running on S\u0303, B will return h\u0302 \u02dd \u03d5. Since \u03d5 can be evaluated in polypnq time and A is efficient, we get that B is also efficient.\nWe will prove that algorithm B is a learning algorithm for the class HDT. Since A is a learning algorithm for the class HDNF with respect to distributions that are realized by a small DNF with evident examples, there exists a function mA pn, q \u010f poly ` n, 1 \u02d8\n, such that for every pD, h\u2039q that is realized by a small DNF with evident examples and every \u0105 0, if A is given a training sequence\nS \u201c tpx1, h\u2039px1qq, px2, h\u2039px2qq, . . . , pxm, h\u2039pxmqqu\nwhere the xi\u2019s are sampled i.i.d. from D and m \u011b mApn, q, then with probability of at least 34 (over the choice of S), the output h\u0302 of A satisfies LD,h\u2039ph\u0302q \u010f .\nLet D be a distribution on Xn and let hT be a hypothesis that can be realized by a small DT. Define a distribution D\u0303 on X2n by,\n\u02dcpDqpzq \u201c #\nDpxq if Dx P Xn such that z \u201c \u03d5pxq 0 otherwise\nSince \u03d5 is one-to-one, D\u0303 is well defined and is a valid distribution on X2n. Now, as hT is realized by a small DT, then from the conditions that \u03d5 satisfies we get that there exists a DNF formula F such that hT \u201c hF \u02dd \u03d5 and the pair pD\u0303, hF q is realized by a small DNF with evident examples. Now for every \u0105 0 we take a sample S \u201c tpx1, hT px1qq, px2, hT px2qq, . . . , pxm, hT pxmqqu with m \u201c mAp2n, q and obtain that with probability of at least 34 it holds that\nLD,hT pBpSqq \u201c LD,hT ph\u0302 \u02dd \u03d5q \u201c P\nx\u201eD rhT pxq \u2030 h\u0302 \u02dd \u03d5pxqs\n\u201c P x\u201eD rhF \u02dd \u03d5pxq \u2030 h\u0302 \u02dd \u03d5pxqs \u201c P z\u201eD\u0303 rhF pzq \u2030 h\u0302pzqs \u201c LD\u0303,hF ph\u0302q \u201c LD\u0303,hF pApS\u0303qq \u0103\nSo B is indeed a learning algorithm for the class HDT"}, {"heading": "5 Experiments", "text": "Membership queries are a mean by which we can use human knowledge for improving performance in learning tasks. Human beings have a very rich knowledge and understanding of many problems that the ML community works on. They can provide much more information than merely the category of the object or an answer to a \u201cyes\u201d or \u201cno\u201d question. This knowledge is often basic, and can be acquired without the use of an expert (e.g., using crowd-sourcing). In this section we will present empirical results of an algorithm which takes advantage of this extensive knowledge in order to perform smart feature selection.\nIn standard supervised classification tasks the user is only asked to give the label of each example. What we did in this task, is to ask for additional information. Specifically, we faced a situation where we had a large number of features, and that these features had an interpretation that is easily understood. For every example in the sample set, we asked the user for its label and in addition, we asked which features indicate that this instance is labeled as such. After we finished iterating over the entire sample, we used the information on the relevant features to narrow down the feature space. Concretely, we trained linear classifiers only on the features that were chosen to be indicative by the users.\nArguably, this algorithm gathers additional information in a manner that is similar to using 1-local membership queries. 1-local query tests whether changing the value of a single feature changes the label. This can be seen as asking whether this feature is relevant to the prediction or not. In the algorithm presented here, we ask for the relevant features in a broader way. Namely, we explicitly ask which words are relevant to the corresponding label."}, {"heading": "5.1 Is the additional data useful?", "text": "When humans make decisions, it is often by very complex thought processes and we do not know whether we can access specific considerations that were used in the decision making process. The first goal of this experiment is to show that at least for some tasks, important parts of this thought process are easily accessible. I.e., that the annotators\u2019 knowledge can be retrieved by asking simple questions. The second goal is to show that using this extra knowledge can help significantly decrease the number of tagged examples that are required.\nWe will formulate the above goals using the notion of error decomposition. Let h\u0302 be the classifier returned by the algorithm. We decompose LDph\u0302q as a sum of the approximation error (the error of the best linear classifier) and the estimation error (the difference between LDph\u0302q and the approximation error):\nLDphSq \u201c app ` est where app \u201c min hPH LDphq and est \u201c LDphSq \u00b4min hPH LDphq\nThe approximation error app measures how good is the class of linear classifiers that we restrict ourselves to. In other words, since the class is linear, how informative are the features we use. The estimation error measures to which extent the algorithm overfits the data.\nWe can now formulate the above goals into claims on the approximation and estimation error. By applying the user induced feature selection mentioned above we can only increase the approximation error, as we reduce the hypothesis class to a smaller one. We will want\nto show that the feature space chosen by the users is still expressive enough, so that the increase in the approximation error will be minor. In addition, we will show that the feature selection is effective in the sense that the estimation error decreases significantly."}, {"heading": "5.2 Experimental setup", "text": ""}, {"heading": "5.2.1 Sentiment Analysis", "text": "Sentiment analysis (SA) is the Natural Language Processing task of identifying the attitude of a given text (usually whether it is positive, neutral or negative). This task has been studied in the NLP community for many years at different scale levels. It started off from being a document level classification task (Pang and Lee, 2004), and then the focus shifted to handling the sentence level (Hu and Liu, 2004; Kim and Hovy, 2004). The newest focus is sentiment analysis of Microblog data like Twitter. Working with these informal text genres, on which users post their opnions, emotions, and recations about practically everything, presents new challenges for natural language processing beyond those encountered when working with more traditional text genres such as news-wire or product reviews. Indeed, classical approaches to Sentiment Analysis (Pang and Lee, 2008) are not directly applicable to tweets. While most of them focus on relatively large texts, e.g. movie or product reviews, tweets are very short and fine-grained. Nevertheless, the great prominence of Social Media during the last few years encouraged a focus on the sentiment detection over a microblogging domain. There has been a lot of recent work on sentiment analysis of twitter data. Some examples are (Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Barbosa and Feng, 2010).\nWe chose this task to demonstrate our method since each example (tweet) is constructed from a limited number of features (words), making each of these features very important for classification. Therefore, it seems that information supplied by users, can be useful in focusing our attention on the important features. Secondly, if in fact the two claims above hold, it will enable us to use a smaller data set, which is very important for this kind of tasks, since SA (and many more NLP tasks) require a large labeled data set which is often costly.\n5.2.2 Dataset\nWe worked with the data set from SemEval (Nakov et al., 2013), a shared task for Sentiment Analysis of Tweets . This dataset is constructed of 13,140 (8,439 train+development and 4,701 test, see Table 1) tweets which were collected over a one-year period spanning from January 2012 to January 2013. The tweets were labeled using the crowd sourcing tool Amazon Mechanical Turk and the labels were filtered to get rid of spammers.\nFor each sentence (tweet), the users were asked to indicate the overall sentiment of the sentence - positive, negative or neutral 5 and also to mark all the subjective (positive or negative) words/phrases in the sentence6. The learning task that we worked on is classifying the sentiment of the entire sentence. Although we only want to predict the sentiment of the tweet, we use these two labellings to get one \u201cricher\u201d labelled data-set. I.e., each instance in our training set holds additional information to its sentiment - which words/phrases in the sentence indicate a positive or negative sentiment."}, {"heading": "5.2.3 Pre-processing", "text": "Beside simple text, tweets may contain URL addresses, references to other Twitter users (appear as @\u0103username\u0105) or content tags (also called hashtags) assigned by the tweeter (# \u0103tag\u0105). During preprocessing, we performed the following standard manipulations:\n\u2022 Words were switched to lower case and punctuation marks were removed (apart from a fixed set of smileys)\n\u2022 Every hyperlink was replaced by the meta-word URL\n\u2022 Every word starting with @, i.e. a username in twitter syntax, was replaced by the meta-word USR.\n\u2022 The hashtag sign 1#1 was removed from every tag to get a simple word. For example #perfect was changed to perfect."}, {"heading": "5.2.4 Language Model", "text": "We used the simple bag-of-words language models of n-grams (in our case unigrams, bigrams and trigrams). I.e., each tweet is represented as a sparse vector in t0, 1ud, where d is the size of the dictionary and the i\u2019th coordinate equals 1 if and only if the i\u2019th word in the dictionary appears in the tweet. We performed a standard cut-off of rare n-grams 7."}, {"heading": "5.2.5 Scoring", "text": "The results were evaluated on averaged F1 scores. This scoring function is used in the SemEval shared task, and overall a very common scoring function for NLP tasks. The F1 score is the harmonic mean of Precision and Recall. Every label has it\u2019s F1 score. For the positive label, the Precision is the number of tweets that were correctly labeled as positive divided by the total number of tweets that were labeled as positive:\nPPOS \u201c TP\nTP ` FP 5The original labeling had 4 classes-[objective, positive, negative, or neutral] but since the turkers tended to mix up between the objective and neutral, the two classes were combined in the final task. 6This labelling procedure was originally intended to be used for two separate tasks. The first is, when given a tweet containing a marked instance of a word or a phrase, to identify the sentiment of that instance (i.e., whether the word is negative or positive). The second is identifying the sentiment of the whole tweet (without using the marked words).\n7without performing this cutoff, the results for the non-query variant are much worse\nThe Recall of the positive label is the number of tweets that were correctly labeled as positive divided by the total number of positive tweets in the data:\nRPOS \u201c TP\nTP ` FN\nThe positive label F1-score is computed as follows:\nFPOS \u201c 2 PPOS \u00a8RPOS PPOS `RPOS\nThe negative label F1-score FNEG is computed similarly. The final score that the results are evaluated on is the average of the above two:\nF1 \u201c 1 2 pFPOS ` FNEGq"}, {"heading": "5.2.6 The algorithm", "text": "We compare two variants for the feature space: using the entire feature space (after cutting off the rare n-grams), and using the \u201dquery acquired\u201d feature space which contains only features that were selected by the users as positive or negative for some example. Information about the data and the number of features is given in table 2.\nWe used a simple Naive Bayes classifier, with a small smoothing parameter. We also checked other classification algorithms- random forests, logistic regression, and multiclass SVM, (with } \u00a8 }1-regularization and } \u00a8 }2-regularization), but the results of the Naive Bayes predictor were the highest for both feature spaces."}, {"heading": "5.3 Results", "text": "The results that we will present are the results of the unigram model. The test scores of the other language models (unigram+bigrams and unigram+bigram+trigram) are almost identical for both feature spaces, and the training scores gets higher with the model complexity, as expected. Since our training set only contains approximately 8000 instances, we chose to present the results of the simplest model, so that the number of features would be comparable to the number of instances.\nThe results of both variants are presented in figure 2. As can be seen by the test scores, our algorithm outperforms the other variant which does not uses the additional information. The difference in test performance is approximately constant across different training sizes. Getting back to our claims - regarding the approximation error, by looking at the final training scores (using the larger training set possible), it can seen that both variants are\nalmost identical in all of the measurements. This fact indicates that we did not increase the approximation error. Regarding the improvement of estimation error, this can be seen clearly by looking at the gap between the test scores and the train scores. The gap in the query acquired model is smaller than the gap in the other model."}, {"heading": "5.3.1 Precision and Recall", "text": "Additional interesting properties can be seen in the precision and recall graphs (figure 3). For example, by looking at the results for positive samples (a & b) we can see that the improvement in the results from using the query model is almost only due to the improvement in the precision scores. If we only use 10% of the data, the query model reaches 0.77 test precision, while the non-query model only reaches 0.71 test precision score\neven when using the whole data set. Another interesting property that can be seen is that when a small training set is used, the difference in the test scores between the query and non-query methods is about twice as large as the difference when the largest possible training set is used."}, {"heading": "5.3.2 Over-fitting", "text": "When using the naive bayes algorithm, we estimate Ppf |cq for every feature f and every label c. This term measures how much the appearance of f contributes to the fact that c is the correct label 8 . Using those terms, we can sort the features by an order which conveys their informativeness. Since our features are words (or bigrams or trgrams), we can get some interesting insights by looking at the most informative features that each variant uses. If we only look at the top of the list (the top 20), the chosen features by both variants are almost identical. But, if we look a bit further we see how the algorithm which uses the entire feature space, chooses some significant features which clearly over-fit the training data. Some example are : \u201dnick\u201d, \u201dlloyd\u201d, and \u201djustin\u201d in the unigram model, \u201dsaturday\n8by the naive assumption that all of the features are independent given the label, this information is actually the only information we use in order to build the classifier\nkitchen\u201d, \u201dghost rider\u201d, \u201dray lewis\u201d in the bigram model and \u201drugby world cup\u201d in the trigram model.\nThis over-fitting will obviously decrease as we increase the training size (and practically by checking the most informative features at different training sizes, the smaller the sample is, the more easy it is to find over-fitting features like the above). But as already stated, generally in Natural Language Processing it is much harder to acquire a large labeled data set. Therefore a method that avoids or significantly decrease this kind of over-fitting will be of high value."}, {"heading": "5.4 Comparing to other Feature Selection Methods", "text": "A question that can be raised is whether the improvement in the results is just an effect of the feature selection itself, or that the fact that the features were selected by a query process is the important part. In order to answer this, we compared our algorithm to using other automatic feature selection techniques. We checked two feature selection methods - filter and backward elimination. For each training set, the number of features that the method was instructed to select was the same as the number of features chosen by the users on that set. The results are presented in figure 4. The training scores of the automatic feature selection techniques are much lower than the training score of using the entire feature space (and much more similar to those of our method already for small training sets). This fact is reasonable, as we use a much smaller hypothesis class. If we look at the test scores it can be seen that using other feature selection techniques does improve the test score a little when compared to no feature selection at all, but still lies well under the score of our query acquired features method.\nAnother feature selection method that we compared our results to was using a SVM classifier with } \u00a8 }1-regularization, which is known to induce sparsity. Here again, using our query acquired feature set outperforms in all of the measurements."}, {"heading": "6 Conclusion and Future Work", "text": "We have presented both theoretical and empirical evidence that local-membership queries are useful and beneficial. In the theoretical setup we have shown that even 1-local queries are stronger than the vanilla PAC model in an arguably natural problem. In the empirical setup we have demonstrated that by getting additional information from the users, significantly better results can be achieved. Moreover, the data in the experiment was created using crowdsourcing, and by asking very simple questions. This shows that getting extra knowledge can be an easy task.\nToday, the use of the MQ model in practice is almost non-existent. Even the more popular models of active learning, pool-based or stream-based, are fairly rare. E.g., in a recent survey of annotation projects for natural language processing tasks, only 20% of the respondents stated they had ever decided to use active learning (Tomanek and Olsson, 2009). It seems that there is plenty of room for incorporating more profound human knowledge to the field of machine learning, especially since today this knowledge can be collected quite easily.\nMore concrete directions for future work include: developing, implementing and analyzing more algorithms that use (local) membership queries and investigating the strength and limitations of the general Op1q-local queries model. Some examples of open questions: Is the use of 2-local queries stronger than the use of 1-local queries on a natural environment? What are the limitations of a model that uses Op1q-local queries with comparison to the model of (Awasthi et al., 2012) that uses logpnq-local queries?"}], "references": [{"title": "Learning regular sets from queries and counterexamples", "author": ["D. Angluin"], "venue": "Information and computation,", "citeRegEx": "Angluin,? \\Q1987\\E", "shortCiteRegEx": "Angluin", "year": 1987}, {"title": "When won t membership queries help", "author": ["D. Angluin", "M. Kharitonov"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Angluin and Kharitonov,? \\Q1995\\E", "shortCiteRegEx": "Angluin and Kharitonov", "year": 1995}, {"title": "Malicious omissions and errors in answers to membership queries", "author": ["D. Angluin", "M. Kri\u0137is", "R.H. Sloan", "G. Tur\u00e1n"], "venue": "Machine Learning,", "citeRegEx": "Angluin et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Angluin et al\\.", "year": 1997}, {"title": "Randomly fallible teachers: Learning monotone dnf with an incomplete membership oracle", "author": ["D. Angluin", "D.K. Slonim"], "venue": "Machine Learning,", "citeRegEx": "Angluin and Slonim,? \\Q1994\\E", "shortCiteRegEx": "Angluin and Slonim", "year": 1994}, {"title": "Learning using local membership queries. arXiv preprint arXiv:1211.0996", "author": ["P. Awasthi", "V. Feldman", "V. Kanade"], "venue": null, "citeRegEx": "Awasthi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Awasthi et al\\.", "year": 2012}, {"title": "Agnostic active learning", "author": ["Balcan", "M.-F", "A. Beygelzimer", "J. Langford"], "venue": "In Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "Balcan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2006}, {"title": "Robust sentiment detection on twitter from biased and noisy data", "author": ["L. Barbosa", "J. Feng"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,", "citeRegEx": "Barbosa and Feng,? \\Q2010\\E", "shortCiteRegEx": "Barbosa and Feng", "year": 2010}, {"title": "Neural net algorithms that learn in polynomial time from examples and queries", "author": ["E.B. Baum"], "venue": "Neural Networks, IEEE Transactions", "citeRegEx": "Baum,? \\Q1991\\E", "shortCiteRegEx": "Baum", "year": 1991}, {"title": "Query learning can work poorly when a human oracle is used", "author": ["E.B. Baum", "K. Lang"], "venue": "In International Joint Conference on Neural Networks,", "citeRegEx": "Baum and Lang,? \\Q1992\\E", "shortCiteRegEx": "Baum and Lang", "year": 1992}, {"title": "Learning with errors in answers to membership queries", "author": ["L. Bisht", "N.H. Bshouty", "L. Khoury"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Bisht et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bisht et al\\.", "year": 2008}, {"title": "Learning with unreliable boundary queries", "author": ["A. Blum", "P. Chalasani", "S.A. Goldman", "D.K. Slonim"], "venue": "In Proceedings of the eighth annual conference on Computational learning theory,", "citeRegEx": "Blum et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Blum et al\\.", "year": 1995}, {"title": "Fast learning of k-term dnf formulas with queries", "author": ["A. Blum", "S. Rudich"], "venue": "In Proceedings of the twenty-fourth annual ACM symposium on Theory of computing,", "citeRegEx": "Blum and Rudich,? \\Q1992\\E", "shortCiteRegEx": "Blum and Rudich", "year": 1992}, {"title": "Exact learning boolean functions via the monotone theory", "author": ["N.H. Bshouty"], "venue": "Information and Computation,", "citeRegEx": "Bshouty,? \\Q1995\\E", "shortCiteRegEx": "Bshouty", "year": 1995}, {"title": "More data speeds up training time in learning halfspaces over sparse vectors", "author": ["A. Daniely", "N. Linial", "S. Shalev-Shwartz"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Daniely et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Daniely et al\\.", "year": 2013}, {"title": "From average case complexity to improper learning complexity", "author": ["A. Daniely", "N. Linial", "S. Shalev-Shwartz"], "venue": "In Proceedings of the 46th Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Daniely et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Daniely et al\\.", "year": 2014}, {"title": "Complexity theoretic limitations on learning dnf\u2019s", "author": ["A. Daniely", "S. Shalev-Shwatz"], "venue": "arXiv preprint arXiv:1404.3378", "citeRegEx": "Daniely and Shalev.Shwatz,? \\Q2014\\E", "shortCiteRegEx": "Daniely and Shalev.Shwatz", "year": 2014}, {"title": "Analysis of a greedy active learning strategy", "author": ["S. Dasgupta"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Dasgupta,? \\Q2004\\E", "shortCiteRegEx": "Dasgupta", "year": 2004}, {"title": "Enhanced sentiment learning using twitter hashtags and smileys", "author": ["D. Davidov", "O. Tsur", "A. Rappoport"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,", "citeRegEx": "Davidov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Davidov et al\\.", "year": 2010}, {"title": "Active learning by labeling features", "author": ["G. Druck", "B. Settles", "A. McCallum"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume", "citeRegEx": "Druck et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Druck et al\\.", "year": 2009}, {"title": "Learning decision trees from random examples", "author": ["A. Ehrenfeucht", "D. Haussler"], "venue": "Information and Computation,", "citeRegEx": "Ehrenfeucht and Haussler,? \\Q1989\\E", "shortCiteRegEx": "Ehrenfeucht and Haussler", "year": 1989}, {"title": "On the power of membership queries in agnostic learning", "author": ["V. Feldman"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Feldman,? \\Q2009\\E", "shortCiteRegEx": "Feldman", "year": 2009}, {"title": "Boosting a weak learning algorithm by majority", "author": ["Y. Freund"], "venue": "Information and computation,", "citeRegEx": "Freund,? \\Q1995\\E", "shortCiteRegEx": "Freund", "year": 1995}, {"title": "Mining and summarizing customer reviews", "author": ["M. Hu", "B. Liu"], "venue": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Hu and Liu,? \\Q2004\\E", "shortCiteRegEx": "Hu and Liu", "year": 2004}, {"title": "An efficient membership-query algorithm for learning dnf with respect to the uniform distribution", "author": ["J. Jackson"], "venue": "In Foundations of Computer Science,", "citeRegEx": "Jackson,? \\Q1994\\E", "shortCiteRegEx": "Jackson", "year": 1994}, {"title": "Cryptographic limitations on learning boolean formulae and finite automata", "author": ["M. Kearns", "L. Valiant"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Kearns and Valiant,? \\Q1994\\E", "shortCiteRegEx": "Kearns and Valiant", "year": 1994}, {"title": "Determining the sentiment of opinions", "author": ["Kim", "S.-M", "E. Hovy"], "venue": "In Proceedings of the 20th international conference on Computational Linguistics,", "citeRegEx": "Kim et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2004}, {"title": "Cryptographic hardness for learning intersections of halfspaces", "author": ["A.R. Klivans", "A Sherstov"], "venue": "In Foundations of Computer Science,", "citeRegEx": "Klivans and Sherstov,? \\Q2006\\E", "shortCiteRegEx": "Klivans and Sherstov", "year": 2006}, {"title": "Twitter sentiment analysis: The good the bad and the omg! Icwsm, 11:538\u2013541", "author": ["E. Kouloumpis", "T. Wilson", "J. Moore"], "venue": null, "citeRegEx": "Kouloumpis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kouloumpis et al\\.", "year": 2011}, {"title": "Learning decision trees using the fourier spectrum", "author": ["E. Kushilevitz", "Y. Mansour"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Kushilevitz and Mansour,? \\Q1993\\E", "shortCiteRegEx": "Kushilevitz and Mansour", "year": 1993}, {"title": "Semeval-2013 task 2: Sentiment analysis in twitter", "author": ["P. Nakov", "Z. Kozareva", "A. Ritter", "S. Rosenthal", "V. Stoyanov", "T. Wilson"], "venue": null, "citeRegEx": "Nakov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2013}, {"title": "Twitter as a corpus for sentiment analysis and opinion mining", "author": ["A. Pak", "P. Paroubek"], "venue": "In LREC,", "citeRegEx": "Pak and Paroubek,? \\Q2010\\E", "shortCiteRegEx": "Pak and Paroubek", "year": 2010}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["B. Pang", "L. Lee"], "venue": "In Proceedings of the 42nd annual meeting on Association for Computational Linguistics,", "citeRegEx": "Pang and Lee,? \\Q2004\\E", "shortCiteRegEx": "Pang and Lee", "year": 2004}, {"title": "Opinion mining and sentiment analysis", "author": ["B. Pang", "L. Lee"], "venue": "Foundations and trends in information retrieval,", "citeRegEx": "Pang and Lee,? \\Q2008\\E", "shortCiteRegEx": "Pang and Lee", "year": 2008}, {"title": "An interactive algorithm for asking and incorporating feature feedback into support vector machines", "author": ["H. Raghavan", "J. Allan"], "venue": "In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Raghavan and Allan,? \\Q2007\\E", "shortCiteRegEx": "Raghavan and Allan", "year": 2007}, {"title": "Interactive feature selection", "author": ["H. Raghavan", "O. Madani", "R. Jones"], "venue": "In IJCAI,", "citeRegEx": "Raghavan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Raghavan et al\\.", "year": 2005}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "University of Wisconsin,", "citeRegEx": "Settles,? \\Q2010\\E", "shortCiteRegEx": "Settles", "year": 2010}, {"title": "Closing the loop: Fast, interactive semi-supervised annotation with queries on features and instances", "author": ["B. Settles"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Settles,? \\Q2011\\E", "shortCiteRegEx": "Settles", "year": 2011}, {"title": "Learning with queries but incomplete information", "author": ["R.H. Sloan", "G. Tur\u00e1n"], "venue": "In Proceedings of the seventh annual conference on Computational learning theory,", "citeRegEx": "Sloan and Tur\u00e1n,? \\Q1994\\E", "shortCiteRegEx": "Sloan and Tur\u00e1n", "year": 1994}, {"title": "A web survey on the use of active learning to support annotation of text data", "author": ["K. Tomanek", "F. Olsson"], "venue": "In Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing,", "citeRegEx": "Tomanek and Olsson,? \\Q2009\\E", "shortCiteRegEx": "Tomanek and Olsson", "year": 2009}, {"title": "A theory of the learnable", "author": ["L.G. Valiant"], "venue": "Communications of the ACM,", "citeRegEx": "Valiant,? \\Q1984\\E", "shortCiteRegEx": "Valiant", "year": 1984}], "referenceMentions": [{"referenceID": 8, "context": "One of the main causes for this is a report (Baum and Lang, 1992) on very disappointing empirical performance of a query algorithm.", "startOffset": 44, "endOffset": 65}, {"referenceID": 4, "context": "In this work we study a new model of local membership queries (Awasthi et al., 2012), which tries to resolve the problem of artificial queries.", "startOffset": 62, "endOffset": 84}, {"referenceID": 39, "context": "These two types of input were the basis for the learning model originally suggested in the celebrated paper \u201cA theory of the learnable\u201d (Valiant, 1984).", "startOffset": 136, "endOffset": 151}, {"referenceID": 0, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2).", "startOffset": 122, "endOffset": 190}, {"referenceID": 11, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2).", "startOffset": 122, "endOffset": 190}, {"referenceID": 12, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2).", "startOffset": 122, "endOffset": 190}, {"referenceID": 23, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2).", "startOffset": 122, "endOffset": 190}, {"referenceID": 0, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2). Despite that the MQ model seems much stronger, both intuitively and formally, it is rarely used in practice. This is commonly believed to result from the fact that in many cases it is not easy to implement MQ algorithms, that can create new and artificial examples to be labeled as part of the training phase. This problem of labeling artificial examples was highlighted by the experiment of Baum and Lang (1992). Baum and Lang implemented a membership query algorithm proposed by Baum (1991) for learning halfspaces .", "startOffset": 123, "endOffset": 620}, {"referenceID": 0, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2). Despite that the MQ model seems much stronger, both intuitively and formally, it is rarely used in practice. This is commonly believed to result from the fact that in many cases it is not easy to implement MQ algorithms, that can create new and artificial examples to be labeled as part of the training phase. This problem of labeling artificial examples was highlighted by the experiment of Baum and Lang (1992). Baum and Lang implemented a membership query algorithm proposed by Baum (1991) for learning halfspaces .", "startOffset": 123, "endOffset": 700}, {"referenceID": 0, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2). Despite that the MQ model seems much stronger, both intuitively and formally, it is rarely used in practice. This is commonly believed to result from the fact that in many cases it is not easy to implement MQ algorithms, that can create new and artificial examples to be labeled as part of the training phase. This problem of labeling artificial examples was highlighted by the experiment of Baum and Lang (1992). Baum and Lang implemented a membership query algorithm proposed by Baum (1991) for learning halfspaces . Their algorithm had very poor results, which was attributed to the fact that the algorithm created artificial and unnatural examples, which resulted in a noisy labeling. We elaborate on this experiment and criticize its conclusions in section 2. A suggested solution to the problem of unnatural examples was proposed by Awasthi et al. (2012). They suggested a mid-way model of learning with queries, but only restricted ones.", "startOffset": 123, "endOffset": 1068}, {"referenceID": 0, "context": "The use of membership queries in addition to examples was proven to be stronger than the standard PAC model in many cases (Angluin, 1987; Blum and Rudich, 1992; Bshouty, 1995; Jackson, 1994)(see section 2). Despite that the MQ model seems much stronger, both intuitively and formally, it is rarely used in practice. This is commonly believed to result from the fact that in many cases it is not easy to implement MQ algorithms, that can create new and artificial examples to be labeled as part of the training phase. This problem of labeling artificial examples was highlighted by the experiment of Baum and Lang (1992). Baum and Lang implemented a membership query algorithm proposed by Baum (1991) for learning halfspaces . Their algorithm had very poor results, which was attributed to the fact that the algorithm created artificial and unnatural examples, which resulted in a noisy labeling. We elaborate on this experiment and criticize its conclusions in section 2. A suggested solution to the problem of unnatural examples was proposed by Awasthi et al. (2012). They suggested a mid-way model of learning with queries, but only restricted ones. The queries that their model allows the algorithm to ask are only local queries, i.e., queries that are close in some sense to examples from the sample set. Hopefully, examples which are similar to natural examples will also appear to be natural, or at least close to natural, and in any case will be far from appearing random or artificial. In their work, Awasti et al. started to investigate the power and the limitations of this model of local queries. They proved positive results on learning sparse polynomials with Oplogpnqqlocal queries under what they defined as locally smooth distributions1, which in some sense generalize the uniform and product distributions. They also proposed an algorithm that learns DNF formulas under the uniform distribution in quasi-polynomial time using only Oplogpnqq-local queries. The exciting ideas of Awasthi et al. (2012) leave many directions for future work.", "startOffset": 123, "endOffset": 2017}, {"referenceID": 33, "context": "We note that similar experiments also present encouraging results along this line (Raghavan and Allan, 2007; Raghavan et al., 2005; Settles, 2011; Druck et al., 2009).", "startOffset": 82, "endOffset": 166}, {"referenceID": 34, "context": "We note that similar experiments also present encouraging results along this line (Raghavan and Allan, 2007; Raghavan et al., 2005; Settles, 2011; Druck et al., 2009).", "startOffset": 82, "endOffset": 166}, {"referenceID": 36, "context": "We note that similar experiments also present encouraging results along this line (Raghavan and Allan, 2007; Raghavan et al., 2005; Settles, 2011; Druck et al., 2009).", "startOffset": 82, "endOffset": 166}, {"referenceID": 18, "context": "We note that similar experiments also present encouraging results along this line (Raghavan and Allan, 2007; Raghavan et al., 2005; Settles, 2011; Druck et al., 2009).", "startOffset": 82, "endOffset": 166}, {"referenceID": 39, "context": "1 PAC Valiant\u2019s Probably Approximately Correct (PAC) model of learning (Valiant, 1984) formulates the problem of learning a concept from examples.", "startOffset": 71, "endOffset": 86}, {"referenceID": 39, "context": "More examples include relatively weak classes such as DNFs and CNFs with constantly many terms (Valiant, 1984), and rank k decision trees (Ehrenfeucht and Haussler, 1989) for a constant k.", "startOffset": 95, "endOffset": 110}, {"referenceID": 19, "context": "More examples include relatively weak classes such as DNFs and CNFs with constantly many terms (Valiant, 1984), and rank k decision trees (Ehrenfeucht and Haussler, 1989) for a constant k.", "startOffset": 138, "endOffset": 170}, {"referenceID": 24, "context": "For example, learning automatons, logarithmic depth circuits, and intersections of polynomially many halfspaces are all intractable, assuming the security of various cryptographic schemes (Kearns and Valiant, 1994; Klivans et al., 2006).", "startOffset": 188, "endOffset": 236}, {"referenceID": 14, "context": "In (Daniely et al., 2014; Daniely and Shalev-Shwatz, 2014; Daniely et al., 2013), it is shown that learning DNF formulas, and learning intersections of \u03c9plogpnqq halfspaces are intractable under the assumption that refuting random k-SAT is hard.", "startOffset": 3, "endOffset": 80}, {"referenceID": 15, "context": "In (Daniely et al., 2014; Daniely and Shalev-Shwatz, 2014; Daniely et al., 2013), it is shown that learning DNF formulas, and learning intersections of \u03c9plogpnqq halfspaces are intractable under the assumption that refuting random k-SAT is hard.", "startOffset": 3, "endOffset": 80}, {"referenceID": 13, "context": "In (Daniely et al., 2014; Daniely and Shalev-Shwatz, 2014; Daniely et al., 2013), it is shown that learning DNF formulas, and learning intersections of \u03c9plogpnqq halfspaces are intractable under the assumption that refuting random k-SAT is hard.", "startOffset": 3, "endOffset": 80}, {"referenceID": 35, "context": "Several types of active models have been proposed: the Membership Query Synthesis, Stream-Based Selective Sampling, and Pool-Based Sampling (Settles, 2010).", "startOffset": 140, "endOffset": 155}, {"referenceID": 39, "context": "Our work is in the area of the \u201cMembership Queries\u201d (MQ) model which was presented in (Valiant, 1984).", "startOffset": 86, "endOffset": 101}, {"referenceID": 0, "context": "Some examples of concept classes that have been proven to be PAC-learnable only if membership queries are available include: The class of Deterministic Finite Automatons (Angluin, 1987), the class of k-term DNF for k \u201c logpnq logplogpnqq (Blum and Rudich, 1992), the class of decision trees and k-almost monotone-DNF formulas (Bshouty, 1995), the class of intersections of k-halfspaces (Baum, 1991) and the class of DNF formulas under the uniform distribution (Jackson, 1994).", "startOffset": 170, "endOffset": 185}, {"referenceID": 11, "context": "Some examples of concept classes that have been proven to be PAC-learnable only if membership queries are available include: The class of Deterministic Finite Automatons (Angluin, 1987), the class of k-term DNF for k \u201c logpnq logplogpnqq (Blum and Rudich, 1992), the class of decision trees and k-almost monotone-DNF formulas (Bshouty, 1995), the class of intersections of k-halfspaces (Baum, 1991) and the class of DNF formulas under the uniform distribution (Jackson, 1994).", "startOffset": 238, "endOffset": 261}, {"referenceID": 12, "context": "Some examples of concept classes that have been proven to be PAC-learnable only if membership queries are available include: The class of Deterministic Finite Automatons (Angluin, 1987), the class of k-term DNF for k \u201c logpnq logplogpnqq (Blum and Rudich, 1992), the class of decision trees and k-almost monotone-DNF formulas (Bshouty, 1995), the class of intersections of k-halfspaces (Baum, 1991) and the class of DNF formulas under the uniform distribution (Jackson, 1994).", "startOffset": 326, "endOffset": 341}, {"referenceID": 7, "context": "Some examples of concept classes that have been proven to be PAC-learnable only if membership queries are available include: The class of Deterministic Finite Automatons (Angluin, 1987), the class of k-term DNF for k \u201c logpnq logplogpnqq (Blum and Rudich, 1992), the class of decision trees and k-almost monotone-DNF formulas (Bshouty, 1995), the class of intersections of k-halfspaces (Baum, 1991) and the class of DNF formulas under the uniform distribution (Jackson, 1994).", "startOffset": 386, "endOffset": 398}, {"referenceID": 23, "context": "Some examples of concept classes that have been proven to be PAC-learnable only if membership queries are available include: The class of Deterministic Finite Automatons (Angluin, 1987), the class of k-term DNF for k \u201c logpnq logplogpnqq (Blum and Rudich, 1992), the class of decision trees and k-almost monotone-DNF formulas (Bshouty, 1995), the class of intersections of k-halfspaces (Baum, 1991) and the class of DNF formulas under the uniform distribution (Jackson, 1994).", "startOffset": 460, "endOffset": 475}, {"referenceID": 21, "context": "The last of these results was built upon Freund\u2019s boosting algorithm (Freund, 1995) and the Fourier-based technique for learning using membership queries due to (Kushilevitz and Mansour, 1993).", "startOffset": 69, "endOffset": 83}, {"referenceID": 28, "context": "The last of these results was built upon Freund\u2019s boosting algorithm (Freund, 1995) and the Fourier-based technique for learning using membership queries due to (Kushilevitz and Mansour, 1993).", "startOffset": 161, "endOffset": 192}, {"referenceID": 1, "context": ", in the case of learning DNF and CNF formulas (Angluin and Kharitonov, 1995), and in the case of distribution free agnostic learning (although in the distribution-specific agnostic setting membership queries do increase the power of the learner) (Feldman, 2009).", "startOffset": 47, "endOffset": 77}, {"referenceID": 20, "context": ", in the case of learning DNF and CNF formulas (Angluin and Kharitonov, 1995), and in the case of distribution free agnostic learning (although in the distribution-specific agnostic setting membership queries do increase the power of the learner) (Feldman, 2009).", "startOffset": 247, "endOffset": 262}, {"referenceID": 7, "context": "A well-known exception is the work of Baum and Lang (1992). They applied a variation of the MQ algorithm for learning a linear classifier proposed in Baum (1991).", "startOffset": 38, "endOffset": 59}, {"referenceID": 7, "context": "A well-known exception is the work of Baum and Lang (1992). They applied a variation of the MQ algorithm for learning a linear classifier proposed in Baum (1991). This algorithm uses the idea that given two examples, one positive and one negative, and a query oracle, it is possible to find an approximately accurate separating halfspace by using a binary search on the line between the positive and negative examples.", "startOffset": 38, "endOffset": 162}, {"referenceID": 7, "context": "A well-known exception is the work of Baum and Lang (1992). They applied a variation of the MQ algorithm for learning a linear classifier proposed in Baum (1991). This algorithm uses the idea that given two examples, one positive and one negative, and a query oracle, it is possible to find an approximately accurate separating halfspace by using a binary search on the line between the positive and negative examples. Their experiment attempts to evaluate this idea in practice. The task that they chose is the task of binary digit classification. The algorithm would receive two examples, one positive and one negative (say, an image of the digit 4 and an image of the digit 7) and would return the weights of the halfspace. The generalization error of the halfspace would then be tested on other examples from the data. The query technique they used in the experiment is different than in the original algorithm: \u201cA direct implementation of this algorithm would repeatedly flash images on the screen during the binary search and would require the test subject to type in the correct label for each image. Because this process seemed likely to be error prone, we instead provided an interface that permitted the test subject to scan through the input space using the mouse and then click on an image that seemed to lie right at the edge of recognizability\u201d (from Baum and Lang (1992)).", "startOffset": 38, "endOffset": 1386}, {"referenceID": 8, "context": "Figure 1: An example taken from (Baum and Lang, 1992): the images the user saw on the screen for the digits 5 and 7", "startOffset": 32, "endOffset": 53}, {"referenceID": 33, "context": "This work led many to the conclusion that membership queries are not useful in practice (Settles (2010); Balcan et al.", "startOffset": 89, "endOffset": 104}, {"referenceID": 5, "context": "This work led many to the conclusion that membership queries are not useful in practice (Settles (2010); Balcan et al. (2006); Dasgupta (2004) and more).", "startOffset": 105, "endOffset": 126}, {"referenceID": 5, "context": "This work led many to the conclusion that membership queries are not useful in practice (Settles (2010); Balcan et al. (2006); Dasgupta (2004) and more).", "startOffset": 105, "endOffset": 143}, {"referenceID": 8, "context": "This framework deals with the problem raised by (Baum and Lang, 1992).", "startOffset": 48, "endOffset": 69}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ.", "startOffset": 35, "endOffset": 61}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ. (Angluin et al. (1997); Blum et al.", "startOffset": 35, "endOffset": 149}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ. (Angluin et al. (1997); Blum et al. (1995); Sloan and Tur\u00e1n (1994); Bisht et al.", "startOffset": 35, "endOffset": 169}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ. (Angluin et al. (1997); Blum et al. (1995); Sloan and Tur\u00e1n (1994); Bisht et al.", "startOffset": 35, "endOffset": 193}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ. (Angluin et al. (1997); Blum et al. (1995); Sloan and Tur\u00e1n (1994); Bisht et al. (2008)).", "startOffset": 35, "endOffset": 214}, {"referenceID": 0, "context": "This notion was first presented in Angluin and Slonim (1994), and then followed by the notion of limited MQ and malicious MQ. (Angluin et al. (1997); Blum et al. (1995); Sloan and Tur\u00e1n (1994); Bisht et al. (2008)). The third method is to restrict the examples that the learning algorithm can query to examples that are similar to examples drawn from the distribution. This is formalized in the work of Awasthi et al. (2012). They present the concept of learning using only local membership queries.", "startOffset": 35, "endOffset": 425}, {"referenceID": 18, "context": "Druck et al. (2009) propose a pool-based active learning approach in which the user provides labels for input features, rather than instances.", "startOffset": 0, "endOffset": 20}, {"referenceID": 18, "context": "Druck et al. (2009) propose a pool-based active learning approach in which the user provides labels for input features, rather than instances. The users are asked to provide a \u201clabel\u201d for input features, where a labeled input feature denotes that a particular feature is highly indicative of a particular label. Following that, Settles (2011) presented an active learning annotation interface, in which the users label instances and features simultaneously.", "startOffset": 0, "endOffset": 343}, {"referenceID": 18, "context": "Druck et al. (2009) propose a pool-based active learning approach in which the user provides labels for input features, rather than instances. The users are asked to provide a \u201clabel\u201d for input features, where a labeled input feature denotes that a particular feature is highly indicative of a particular label. Following that, Settles (2011) presented an active learning annotation interface, in which the users label instances and features simultaneously. At any point in time, an instance and a list of features for each label is presented on the screen. The user can choose to either label the instance, choose a feature from the list as being indicative, or add a new feature of his or her choice. Another similar work is of Raghavan and Allan (2007) and Raghavan et al.", "startOffset": 0, "endOffset": 756}, {"referenceID": 18, "context": "Druck et al. (2009) propose a pool-based active learning approach in which the user provides labels for input features, rather than instances. The users are asked to provide a \u201clabel\u201d for input features, where a labeled input feature denotes that a particular feature is highly indicative of a particular label. Following that, Settles (2011) presented an active learning annotation interface, in which the users label instances and features simultaneously. At any point in time, an instance and a list of features for each label is presented on the screen. The user can choose to either label the instance, choose a feature from the list as being indicative, or add a new feature of his or her choice. Another similar work is of Raghavan and Allan (2007) and Raghavan et al. (2005). They studied the problem of tandem learning where they combine uncertainty sampling for instances along with co-occurrence-based interactive feature selection.", "startOffset": 0, "endOffset": 783}, {"referenceID": 31, "context": "It started off from being a document level classification task (Pang and Lee, 2004), and then the focus shifted to handling the sentence level (Hu and Liu, 2004; Kim and Hovy, 2004).", "startOffset": 63, "endOffset": 83}, {"referenceID": 22, "context": "It started off from being a document level classification task (Pang and Lee, 2004), and then the focus shifted to handling the sentence level (Hu and Liu, 2004; Kim and Hovy, 2004).", "startOffset": 143, "endOffset": 181}, {"referenceID": 32, "context": "Indeed, classical approaches to Sentiment Analysis (Pang and Lee, 2008) are not directly applicable to tweets.", "startOffset": 51, "endOffset": 71}, {"referenceID": 30, "context": "Some examples are (Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Barbosa and Feng, 2010).", "startOffset": 18, "endOffset": 113}, {"referenceID": 27, "context": "Some examples are (Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Barbosa and Feng, 2010).", "startOffset": 18, "endOffset": 113}, {"referenceID": 17, "context": "Some examples are (Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Barbosa and Feng, 2010).", "startOffset": 18, "endOffset": 113}, {"referenceID": 6, "context": "Some examples are (Pak and Paroubek, 2010; Kouloumpis et al., 2011; Davidov et al., 2010; Barbosa and Feng, 2010).", "startOffset": 18, "endOffset": 113}, {"referenceID": 29, "context": "We worked with the data set from SemEval (Nakov et al., 2013), a shared task for Sentiment Analysis of Tweets .", "startOffset": 41, "endOffset": 61}, {"referenceID": 38, "context": ", in a recent survey of annotation projects for natural language processing tasks, only 20% of the respondents stated they had ever decided to use active learning (Tomanek and Olsson, 2009).", "startOffset": 163, "endOffset": 189}, {"referenceID": 4, "context": "Some examples of open questions: Is the use of 2-local queries stronger than the use of 1-local queries on a natural environment? What are the limitations of a model that uses Op1q-local queries with comparison to the model of (Awasthi et al., 2012) that uses logpnq-local queries?", "startOffset": 227, "endOffset": 249}], "year": 2015, "abstractText": "Classic machine learning algorithms learn from labelled examples. For example, to design a machine translation system, a typical training set will consist of English sentences and their translation to French. There is a stronger model, in which the algorithm can also query for labels of new examples it creates. E.g, in the translation task, the algorithm can create a new English sentence, and request its translation from the user during training. This combination of examples and queries, that resembles human learning patterns, has been widely studied. Yet, despite many theoretical results, query algorithms are almost never used. One of the main causes for this is a report (Baum and Lang, 1992) on very disappointing empirical performance of a query algorithm. These poor results were mainly attributed to the fact that the algorithm queried for labels of examples that are artificial, and impossible to interpret by humans. In this work we study a new model of local membership queries (Awasthi et al., 2012), which tries to resolve the problem of artificial queries. In this model, the algorithm is only allowed to query the labels of examples which are close to examples from the training set. E.g., in translation, the algorithm can change individual words in a sentence it has already seen, and then ask for the translation. In this model, the examples queried by the algorithm will be close to natural examples and hence, hopefully, will not appear as artificial or random. In this work we focus on 1-local membership queries (i.e., queries of distance 1 from an example in the training sample). We show that 1-local membership queries are already stronger than the standard learning model. We also present an experiment on a well known NLP task of sentiment analysis. In this experiment, the users were asked to provide, in a way that resembles 1-local queries, more information than merely indicating the label. We present results that illustrate that this extra information is beneficial in practice.", "creator": "LaTeX with hyperref package"}}}