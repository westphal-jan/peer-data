{"id": "1601.03785", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2016", "title": "A Method for Image Reduction Based on a Generalization of Ordered Weighted Averaging Functions", "abstract": "intifadas In this familial paper m101 we ansumane propose jutras a 22b special grl type of batuta aggregation function openweight which shribman generalizes sita the notion range of Ordered treetop Weighted Averaging coldspring Function - elevation OWA. The searching resulting beira functions heirlooms are called Dynamic Ordered Weighted Averaging Functions - - - DYOWAs. lampposts This ramanna generalization kiwifruit will be developed in hakuna such aureo way that the splines weight vectors oscorp are tughril variables depending kamilewicz on the kinesiology input 4:08 vector. tejaji Particularly, this driverless operators generalize trichophyton the nubar aggregation functions: Minimum, i-58 Maximum, Arithmetic wilcher Mean, Median, wahnfried etc, postumus which are extensively pataphysics used in image vyomesh processing. In indelicato this overcharge field 58-game of research 3-of-11 two problems are considered: kazziha The inoperable determination dazu of bettiah methods to reduce images and the anhalt-bernburg construction of revesz techniques supercool which provide kushtia noise harkening reduction. The satiating operators porla described here are 59.82 able gamma-rays to derusha be guzzles used quaaludes in mohammadpur both overeaters cases. 11km In rkk terms bahal of image nerul reduction mushake we urmila apply i-86 the organophosphorus methodology provided by terril Patermain ribald et gattuso al. We killilea use the maglio noise misuse reduction operators obtained kazmi here to omni treat the images krrish obtained luchian in the first part of the paper, harborfront thus rm7 obtaining hamilton-wentworth images hesse-darmstadt with house-building better quality.", "histories": [["v1", "Fri, 15 Jan 2016 00:13:33 GMT  (1070kb,D)", "http://arxiv.org/abs/1601.03785v1", "32 pages, 19 figures"]], "COMMENTS": "32 pages, 19 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["a diego s farias", "valdigleis s costa", "luiz ranyer a lopes", "benjam\\'in bedregal", "regivan santiago"], "accepted": false, "id": "1601.03785"}, "pdf": {"name": "1601.03785.pdf", "metadata": {"source": "CRF", "title": "A Method for Image Reduction Based on a Generalization of Ordered Weighted Averaging Functions\u2217", "authors": ["A. Diego S. Farias", "Valdigleis S. Costa", "Luiz Ranyer A. Lopes", "Benjam\u0131\u0301n Bedregal", "Regivan H. N. Santiago"], "emails": ["nio.diego@ufersa.edu.br", "valdigleis@ppgsc.ufrn.br", "ranyer.lopes@gmail.com", "bedregal@dimap.ufrn.br", "regivan@dimap.ufrn.br"], "sections": [{"heading": null, "text": "In this paper we propose a special type of aggregation function which generalizes the notion of Ordered Weighted Averaging Function - OWA. The resulting functions are called Dynamic Ordered Weighted Averaging Functions \u2014 DYOWAs. This generalization will be developed in such way that the weight vectors are variables depending on the input vector. Particularly, this operators generalize the aggregation functions: Minimum, Maximum, Arithmetic Mean, Median etc, which are extensively used in image processing. In this field of research two problems are considered: The determination of methods to reduce images and the\n\u2217Preprint submitted to IEEE Transactions on Fuzzy Systems. \u2020Federal University of Semi-Arid - UFERSA, Pau dos Ferros, RN, Brazil, 59.900-000, antonio.diego@ufersa.edu.br \u2021DIMAp, valdigleis@ppgsc.ufrn.br \u00a7DIMAp, ranyer.lopes@gmail.com \u00b6DIMAp, bedregal@dimap.ufrn.br \u2016Dimap, regivan@dimap.ufrn.br \u2217\u2217DIMAP: Department of Informatics and Applied Mathematics, Federal University of Rio Grande do Norte \u2014 UFRN, Natal, RN, Brazil, 59.072-970\nar X\niv :1\n60 1.\n03 78\n5v 1\nconstruction of techniques which provide noise reduction. The operators described here are able to be used in both cases. In terms of image reduction we apply the methodology provided in [1]. We use the noise reduction operators obtained here to treat the images obtained in the first part of the paper, thus obtaining images with better quality.\nKeywords: Aggregation functions, OWA functions, Image reduction, Noise reduction."}, {"heading": "1 Introduction", "text": "Image processing has great applicability in several areas. In medicine, for example, they can be applied to: Identify tumors [2]; support techniques in advancing dental treatments [3], etc. Such images are not always obtained with a suitable quality, and to detect the desired information, various methods have been developed in order to eliminate most of the noise contained in these images.\nAnother problem addressed in image processing is the decrease of resolution, usu-\nally aiming the reduction of memory consumption required for its storage [4].\nThere are several techniques for image reduction in the literature, more recently Paternain et. al. [1] constructed reduction operators using weighted averaging aggregation functions. The proposed method consists of: (1) To reduce a given image by using a reduction operator; (2) To build a new image from the reduced one, and (3) To analyze the quality of the last image by using the measures PSNR and MSIM [4].\nIn this work we introduce a class of aggregation functions called: Dynamic Ordered Weighted Averaging Function - (DYOWA). They generalize the OWA function introduced by Yager [5] and in particular the operators: Arithmetic Mean, Median, Maximum, Minimum and cOWA. We provide a range of their properties such as: idempotence, symmetry and homogeneity as well two methods 1: (1) for image reduction 1These methods were implemented by using Java 1.8.0 31 software in a 64 bits MS Windows machine.\nand (2) for noise treatment.\nThis paper is structured in the following way: SECTION 2 provides some basics of Aggregation Functions Theory. SECTION 3 introduces Dynamic Ordered Weighted Averaging functions, shows some examples and properties, and introduces a particular DY OWA function, called H, which will be fundamental for this work. In SECTION 4 we provide an application of DY OWA\u2019s to image reduction and in SECTION 5, we show that DY OWA functions are able to treat images with noise, aiming to improve the reduction method used in SECTION 4. Finally, section SECTION 6 gives the final remarks of this work."}, {"heading": "2 Aggregation Functions", "text": "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13]. In this section we introduce them together with examples and properties. We also present a special family of aggregation functions called Ordered Weighted Averaging - OWA and show some of its features."}, {"heading": "2.1 Definition and Examples", "text": "Aggregation functions associate each entry x with n arguments in the closed interval [0, 1] an output value also in the interval [0, 1]; formally we have:\nDefinition 1. An n-ary aggregation function is a mapping f : [0, 1]n \u2192 [0, 1], which associates each n-dimensional vector x to a single value f(x) in the interval [0, 1] such that:\n1. f(0, ..., 0) = 0 and f(1, ..., 1) = 1;\n2. If x \u2264 y, i.e., xi \u2264 yi, for all i = 1, 2, ..., n, then f(x) \u2264 f(y).\nExample 1.\n(a) Arithmetic Mean: Arith(x) = 1\nn (x1 + x2...+ xn)\n(b) Minimum: Min(x) = min{x1, x2, ..., xn};\n(c) Maximum: Max(x) = max{x1, x2, ..., xn};\n(d) Harmonic mean: fn(x) = n\n1 x1 + 1x2 + \u00b7 \u00b7 \u00b7+ 1 xn\n;\nFrom now on we will use the short term \u201caggregation\u201d instead of \u201cn-ary aggrega-\ntion function\u201d.\nAggregations can be divided into four distinct classes: Averaging, Conjunctive, Disjunctive and Mixed. Since this paper focus on averaging aggregations, we will define only this class. A wider approach in aggregation can be found in [15, 14, 16, 17].\nDefinition 2. An aggregation is called Averaging, if for all x \u2208 [0, 1]n we have:\nMin(x) \u2264 f(x) \u2264Max(x)\nExample 2. The Arithmetic Mean, the Maximum and the Minimum are averaging aggregation functions."}, {"heading": "2.2 Special Types Aggregation Functions", "text": "An aggregation function f :\n(1) is Idempotent if, and only if, f(x, ..., x) = x for all x \u2208 [0, 1].\n(2) is Homogeneous of order k if, and only if, for all \u03bb \u2208 [0, 1] and x \u2208 [0, 1]n,\nf(\u03bbx1, \u03bbx2, ..., \u03bbxn) = \u03bb kf(x1, x2, ..., xn). When f is homogeneous of order 1 we simply say that f is homogeneous.\n(3) is Shift-invariant if, and only if, f(x1+r, x2+r, .., xn+r) = f(x1, x2, .., xn)+\nr, for all r \u2208 [\u22121, 1], x \u2208 [0, 1]n such that (x1 + r, x2 + r, ..., xn + r) \u2208 [0, 1]n and f(x1, x2, ..., xn) + r \u2208 [0, 1].\n(4) is Monotonic if, and only if, x \u2264 y implies f(x) \u2264 f(y).\n(5) is Strictly Monotone if, and only if, f(x) < f(y) whenever x < y, i.e. x \u2264 y\nand x 6= y.\n(6) has a Neutral Element e \u2208 [0, 1], if for all t \u2208 [0, 1] at any coordinate input\nvector x, it has to be:\nf(e, ..., e, t, e, ..., e) = t, and\n(7) f is Symmetric if, and only if, its value is not changed under the permutations\nof the coordinates of x, i.e, we have:\nf(x1, x2, ..., xn) = f(xp(1) , xp(2) , \u00b7 \u00b7 \u00b7 , xp(n))\nFor all x and any permutation P : {1, 2, ..., n} \u2192 {1, 2, ..., n}.\n(8) An Absorbing Element (Annihilator) of an aggregation function f , is an ele-\nment a \u2208 [0, 1] such that:\nf(x1, x2, ..., xi\u22121, a, xi+1, ..., xn) = a\n(9) A Zero Divisor of an aggregation function is an element a \u2208 ]0, 1[, such that,\nthere is some vector x with xj > 0, for all 1 \u2264 j \u2264 n, and f(x1, ..., xj\u22121, a, xj+1, .., xn) = 0.\n(10) A One Divisor of an aggregation function f is an element a \u2208 ]0, 1[ such that,\nthere is some vector x with xj < 1, for all 1 \u2264 j \u2264 n, and f(x1, ..., xj\u22121, a, xj+1, .., xn) = 1.\n(11) If N : [0, 1]\u2192 [0, 1] is a strong negation2 and f : [0, 1]n \u2192 [0, 1] is an aggrega-\ntion function, then the dual aggregation function of f is:\nfd(x1, x2, ..., xn) = N(f(N(x1), N(x2), ..., N(xn)))\nwhich is also an aggregation function.\nExample 3.\n(i) The functions: Arith,Min andMax are examples of idempotent, homogeneous,\nshift-invariant, monotonic and symmetric functions.\n(ii) Min and Max have 0 and 1 elements as annihilator, respectively, but Arith\ndoes not have annihiladors.\n(iii) Min, Max and Arith do not have zero divisors and one divisors.\n(iv) The dual of Max with respect to negation N(x) = 1\u2212 x is the Min function."}, {"heading": "2.3 Ordered Weighted Averaging Function - OWA", "text": "In the field of aggregation functions there is a very important subclass in which the elements are parametric; they are called: Ordered Weighted Averaging or simply OWA [5].\nAn OWA is an aggregation function which associates weights to all components xi of an input vector x. To achieve that observe the following definition. 2A strong negation is an antitonic function N : [0, 1] \u2192 [0, 1] such that N(N(\u03b1)) = \u03b1 for all \u03b1 \u2208 [0, 1].\nDefinition 3. Let be an input vector x = (x1, x2, . . . , xn) \u2208 [0, 1]n and a vector of weights w = (w1, . . . , wn), such that n\u2211 i=1 wi = 1. Assuming the permutation:\nSort(x) = (xp(1), xp(2), . . . , xp(n))\nsuch that xp(i) \u2265 xp(i+1), i.e., xp(1) \u2265 xp(2) \u2265 . . . \u2265 xp(n), the Ordered Weighted Averaging (OWA) Function with respect to w, is the functionOWAw : [0, 1]n \u2192 [0, 1] such that:\nOWAw(x) = n\u2211 i=1 wi \u00b7 xp(i)\nIn what follows we remove w from OWAw(x). The main properties of such func-\ntions are:\n(a) For any vector of weights w, the function OWA(x) is idempotent and mono-\ntonic. Moreover, OWA(x) is strictly increasing if all weights w are positive;\n(b) The dual of a OWAw is denoted by (OWA)d, with the vector of weights dually\nordered, i.e. (OWAw)d = OWAwd , where wd = (wp(n), wp(n\u22121), ..., wp(1)).\n(c) OWA are continuous, symmetric and shift-invariant functions;\n(d) They do not have neutral or absorption elements, except in the special case of\nfunctions OWA of Max and Min.\n2.3.1 Examples of special functions OWA\n1. If all weight vector components are equal to 1n , then OWA(x) = Arith((x).\n2. If w = (1, 0, 0, ..., 0), then OWA(x) = Max(x).\n3. If w = (0, 0, 0, ..., 1), then OWA(x) = Min(x).\n4. if wi = 0, for all i, with the exception of a k-th member, i.e, wk = 1, then this\nOWA is called static and OWAw(x) = xk\n5. Given a vector x and its ordered permutation Sort(x) = (x(1), . . . , x(n)), the\nMedian function\nMed(x) =  1 2 (x(k) + x(k+1)), if n = 2k\nx(k+1), if n = 2k + 1\nis an OWA function in which the vector of weights is defined by:\n\u2022 If n is odd, then wi = 0 for all i 6= dn2 e and wdn/2e = 1. \u2022 If n is even, then wi = 0 for all i 6= dn+12 e and i 6= b n+1 2 c, and wdn/2e =\nwbn/2c = 1 2 .\nExample 4. The n-dimensional cOWA function [18] is the OWA operator, with weighted vector defined by:\n\u2022 If n is even, then wj = 2(2j\u22121)n2 , for 1 \u2264 j \u2264 n 2 , and wn/2+i = wn/2\u2212i+1, for\n1 \u2264 i \u2264 n2 .\n\u2022 If n is odd, then wj = 2(2j\u22121)n2 , for 1 \u2264 j \u2264 n\u22121 2 , wn/2+i = wn/2\u2212i+1, for\n1 \u2264 i \u2264 n2 , and w(n+1)/2 = 1\u2212 2 (n\u22121)/2\u2211 j=1 wi.\nThe OWA functions are defined in terms of a predetermined vector of weights. In the next section we propose the generalization of the concept of OWA in order to relax the vector of weights. To achieve that we replace the vector of weights by a family of functions. The resulting functions are called Dynamic Ordered Weighted Avegaring Functions or in short: DYOWAs."}, {"heading": "3 Dynamic Ordered Weighted Avegaring Functions -", "text": "DY OWA\nBefore defining the notion of DY OWA functions, we need to establish the notion of weight-function.\nDefinition 4. A finite family of functions \u0393 = {fi : [0, 1]n \u2192 [0, 1] | 1 \u2264 i \u2264 n} such that: n\u2211 i=1 fi(x) = 1. is called family of weight-function (FWF).\nA Dynamic Ordered Weighted Averaging Function or simply DYOWA associ-\nated to a FWF \u0393 is a function of the form:\nDY OWA\u0393(x) = n\u2211 i=1 fi(x) \u00b7 xi\nBelow we show some examples ofDY OWA operators with their respective weight-\nfunctions.\nExample 5. Let be \u0393 = {fi(x) = 1n | 1 \u2264 i \u2264 n}. TheDY OWA operator associated to \u0393, DY OWA\u0393(x), is Arith(x).\nExample 6. The function Minimum can be obtained from \u0393 = {fi | 1 \u2264 i \u2264 n}, where f1(x) = f2(x) = \u00b7 \u00b7 \u00b7 = fn\u22121(x) = 0 and fn(x) = 1, for all x \u2208 [0, 1]n.\nExample 7. Similarly, the function Maximum is also of type DY OWA with \u0393 dually defined.\nExample 8. For any vector of weights w = (w1, w2, ..., wn), A function OWAw(x) is a DY OWA in which the weight-functions are given by: fi(x) = wp(i), where p : {1, 2, \u00b7 \u00b7 \u00b7 , n} \u2212\u2192 {1, 2, \u00b7 \u00b7 \u00b7 , n} is the permutation, such that p(i) = j with xi = x(j). For example: If w = (0.3, 0.4, 0.3), then for x = (0.1, 1.0, 0.9) we have x1 = x(3), x2 = x(1) and x3 = x(2). Thus, f1(x) = 0.3, f2(x) = 0.3, f3(x) = 0.4, and DY OWA(x) = 0.3 \u00b7 0.1 + 0.3 \u00b7 1.0 + 0.4 \u00b7 0.9 = 0.69\nRemark 1. Example 8 shows that the functionsOWA, introduced by Yager, are special cases of DY OWA functions. There are, however, some DY OWA functions which are not OWA.\nExample 9. Let \u0393 = {sin(x) \u00b7 y, 1\u2212 sin(x) \u00b7 y}. The respective DY OWA function is DY OWA(x, y) = (sin(x) \u00b7 y) \u00b7x+ (1\u2212 sin(x) \u00b7 y) \u00b7 y, which is not an OWA function.\n3.1 Properties of DY OWA Functions\nThe next theorem characterizes the DY OWA functions which are also aggregations.\nTheorem 1. Let \u0393 = {f1, \u00b7 \u00b7 \u00b7 , fn} be a FWF. ADY OWA\u0393 is an aggregation function if, and only if, it is monotonic.\nProof. Obviously, ifDY OWA\u0393 is an aggregation, then it is monotonic function. Conversely, if DY OWA\u0393 is monotonic, then for it to become an aggregation, enough to show that\nDY OWA\u0393(0, ..., 0) = 0 e DY OWA\u0393(1, ..., 1) = 1,\nthis follows from the definition of DY OWA.\nCorollary 1. A DY OWA is an aggregation function if, and only if, it is an a aggregation of type averaging.\nProof. For all x = (x1, ..., xn) have to\nMin(x) \u2264 xi \u2264Max(x), \u2200i = 1, 2, ..., n.\nSo, n\u2211 i=1 fi(x) \u00b7Min(x) \u2264 n\u2211 i=1 fi(x) \u00b7 xi \u2264 n\u2211 i=1 fi(x) \u00b7Max(x), but as n\u2211 i=1 fi(x) = 1, it follows that\nMin(x) \u2264 n\u2211 i=1 fi(x) \u00b7 xi \u2264Max(x)\nCorollary 2. All functions of the type DY OWA presented in examples 4, 5, 6, 7 and 8 are averaging aggregation functions.\nProof. Just see that those functions are monotonic.\nProposition 1. For every \u0393, DY OWA\u0393 is idempotent.\nProof. If x = (x, ..., x) with t \u2208 [0, 1], then:\nDY OWA\u0393(x) = n\u2211 i=1 fi(x) \u00b7 x = x \u00b7 n\u2211 i=1 fi(x) = x\nThis property is important because it tells us that every DY OWA is idempotent,\nregardless it is an aggregation or not.\nProposition 2. If \u0393 is invariant under translations, i.e, fi(x1 +\u03bb, x2 +\u03bb, ..., xn+\u03bb) = fi(x1, x2, ..., xn) for any x \u2208 [0, 1]n, for i \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , n} and \u03bb \u2208 [\u22121, 1], then DY OWA\u0393 is shift-invariant.\nProof. Let x = (x1, ..., xn) \u2208 [0, 1]n and \u03bb \u2208 [\u22121, 1] such that (x1+\u03bb, x2+\u03bb, ..., xn+ \u03bb) \u2208 [0, 1]n. then,\nDY OWA\u0393 (x1 + \u03bb, ..., xn + \u03bb) =\n=\nn\u2211 i=1 fi(x1 + \u03bb, ..., xn + \u03bb) \u00b7 (xi + \u03bb)\n=\nn\u2211 i=1 fi(x1 + \u03bb, ..., xn + \u03bb) \u00b7 xi\n+ n\u2211 i=1 fi(x1 + \u03bb, ..., xn + \u03bb) \u00b7 \u03bb\n=\nn\u2211 i=1 fi(x1, ..., xn) \u00b7 xi + \u03bb\n= DY OWA\u0393(x1, ..., xn) + \u03bb\nProposition 3. If \u0393 is homogeneous of order k (i.e., if fi is homogeneus of order k, for each fi \u2208 \u0393), then DY OWA\u0393(x) is homogeneous of order k + 1.\nProof. Of course that, if \u03bb = 0, then DY OWA\u0393(\u03bbx1, ..., \u03bbxn) = \u03bbf(x1, ..., xn). Now, to \u03bb 6= 0 we have:\nDY OWA\u0393(\u03bbx1, ..., \u03bbxn) = n\u2211 i=1 fi(\u03bbx1, ..., \u03bbxn) \u00b7 \u03bbxi\n= \u03bb \u00b7 n\u2211 i=1 \u03bbkfi(x1, ..., xn)xi = \u03bbk+1 \u00b7DY OWA\u0393(x1, ..., xn)\nExample 10. Let \u0393 be defined by\nfi(x1, ..., xn) =  1 n , if x1 = ... = xn = 0 xi n\u2211\nj=1 xj\n, otherwise\nThen,\nDY OWA\u0393(x) =  0, if x1, ..., xn = 0 n\u2211 i=1 x2i\nn\u2211 i=1 xi , otherwise\nThisDY OWA\u0393 is idempotent, homogeneous and shift-invariant. However,DY OWA\u0393 is not monotonic, sinceDY OWA\u0393(0.5, 0.2, 0.1) = 0.375 andDY OWA\u0393(0.5, 0.22, 0.2) = 0.368.\nThe next definition provides a special FWF, which will be used to build aDY OWA\nwhose properties are very important for this paper.\nDefinition 5. Consider the family \u0393 of functions\nfi(x) =  1 n , if x = (x, ..., x) 1 n\u22121 1\u2212 |xi\u2212Med(x)|n\u2211 j=1 |xj\u2212Med(x)|  , otherwise\nThen, \u0393 is a FWF, i.e. n\u2211 i=1 fi(x) = 1, for all x \u2208 [0, 1]n. Let H be the associated DY OWA. The computation of H can be performed using the following expressions:\nH(x) =  x, if x = (x, ..., x) 1 n\u22121 n\u2211 i=1 xi \u2212 xi|xi\u2212Med(x)|n\u2211 j=1 |xj\u2212Med(x)|\n , otherwise Example 11. Let be n = 3. So, for x = (0.1, 0.3, 0) we have\nf1(x) = 0.5, f2(x) = 0.167, f3(x) = 0.333 and H(x) = 0.08.\nProposition 4. The weight-functions defined in Definition 5 are such that: fi(x1 + \u03bb, ..., xn + \u03bb) = fi(x1, x2, ..., xn) and fi(\u03bbx1, ..., \u03bbxn) = fi(x1, ..., xn), for any 1 \u2264 i \u2264 n.\nProof. Writing x\u2032 = (x1+\u03bb, ..., xn+\u03bb), then f(x1+\u03bb, ..., xn+\u03bb) = (f1(x\u2032), ..., fn(x\u2032)). Clearly, Med(x\u2032) = Med(x) + \u03bb. Thus, for x 6= (x, ..., x) we have:\nfi(x \u2032) = 1n\u22121 1\u2212 |xi+\u03bb\u2212Med(x\u2032)|n\u2211 j=1 |xj+\u03bb\u2212Med(x\u2032)|  = 1n\u22121\n1\u2212 |xi+\u03bb\u2212(Med(x)+\u03bb)|n\u2211 j=1 |xj+\u03bb\u2212(Med(x)+\u03bb)|  = 1n\u22121\n1\u2212 |xi\u2212Med(x)|n\u2211 j=1 |xj\u2212Med(x)|  = fi(x).\nTherefore, f(x\u2032) = (f1(x\u2032), ..., fn(x\u2032)) = (f1(x), ..., fn(x)). The case in which x = (x, ..., x) is immediate.\nTo check the second property, make x\u2032\u2032 = (\u03bbx1, ..., \u03bbxn), note that Med(x\u2032\u2032) =\n\u03bbmed(x) and for x 6= (x, ..., x)\nfi(x \u2032\u2032) = 1n\u22121 1\u2212 |\u03bbxi\u2212Med(\u03bbx)|n\u2211 j=1 |\u03bbxj\u2212Med(\u03bbx)|  = 1n\u22121\n1\u2212 |\u03bbxi\u2212\u03bbMed(x)|n\u2211 j=1 |\u03bbxj\u2212\u03bbMed(x)|  = 1n\u22121 1\u2212 |\u03bb|\u00b7|xi\u2212Med(x)| |\u03bb|\u00b7\nn\u2211 j=1 |xj\u2212Med(x)|  = 1n\u22121\n1\u2212 |xi\u2212Med(x)|n\u2211 j=1 |xj\u2212Med(x)|  = fi(x)\nTherefore, f(x\u2032\u2032) = (f1(x\u2032\u2032), ..., fn(x\u2032\u2032)) = (f1(x), ..., fn(x)) = f(x). The case in which x = (x, ..., x) is also immediately\nCorollary 3. H is shift-invariant and homogeneous.\nProof. Straightforward for propositions 2 and 3.\nThe function H is of great importance to this work, since this function, as well as some DY OWA\u2019s already mentioned will provide us tools able: (1) To reduce the size of images and (2) To deal with noise reduction.\nNow, we present some other properties of function H."}, {"heading": "3.2 Properties of H", "text": "In addition to idempotency, homogeneity and shift-invariance H has the following proprerties.\nProposition 5. H has no neutral element.\nProof. Suppose H has a neutral element e, find the vector of weight for x = (e, ..., e, x, e, ..., e). Note that if n \u2265 3, then Med(x) = e and therefore,\nfi(x) = 1\nn\u22121 1\u2212 |xi\u2212Med(x)|n\u2211 j=1 |xj\u2212Med(x)|  = 1n\u22121\n1\u2212 |xi\u2212e|n\u2211 j=1 |xj\u2212e|  = 1n\u22121 ( 1\u2212 |xi\u2212e||x\u2212e| )\ntherefore,\nfi(x) =  1 n\u22121 , if xi = e 0, if xi = x , to n \u2265 3\ni.e.,\nf(x) = (\n1 n\u22121 , ..., 1 n\u22121 , 0, 1 n\u22121 , ..., 1 n\u22121 ) and\nH(x) = (n\u2212 1) \u00b7 e n\u2212 1 = e\nBut since e is a neutral element of H, H(x) = x. Absurd, since we can always take x 6= e.\nFor n = 2, we have Med(x) = x+ e\n2 , where x = (x, e) or x = (e, x). In both\ncases it is not difficult to show that f(x) = (0.5, 0.5) and H(x) = x+ e\n2 . Thus, taking\nx 6= e, again we have H(x, e) 6= x.\nProposition 6. H has no absorbing elements.\nProof. To n = 2, we have H(x) = x1 + x2\n2 , which has no absorbing elements. Now\nfor n \u2265 3 we have to x = (a, 0, ..., 0) with Med(x) = 0 therefore,\nf1(x) = 1\nn\u2212 1\n( 1\u2212 a\na\n) = 0 and fi = 1\nn\u2212 1 ,\u2200i = 2, ..., n.\ntherefore,\nH(a, 0, ..., 0) = 0 \u00b7 a+ 1 n\u2212 1 \u00b7 0 + ...+ 1 n\u2212 1 \u00b7 0 = a\u21d2 a = 0,\nbut to x = (a, 1, ..., 1) we have to Med(x) = 1. Furthermore,\nf1(x) = 1\nn\u2212 1\n( 1\u2212 1\u2212 a 1 \u2212 a ) = 0\nand\nfi = 1\nn\u2212 1 para i = 2, 3, ..., n.\ntherefore,\nH(a, 1, ..., 1) = 0 \u00b7 a+ 1 n\u2212 1 \u00b7 1 + ...+ 1 n\u2212 1 \u00b7 1 = a\u21d2 a = 1.\nWith this we prove that H does note have annihiladors.\nProposition 7. H has no zero divisors.\nProof. Let a \u2208 ]0, 1[ and consider x = (a, x2, ..., xn) \u2208 ]0, 1]n. In order to have H(x) = n\u2211 i=1 fi(x) \u00b7 xi = 0 we have fi(x) \u00b7 xi = 0 for all i = 1, 2, ..., n. But as a 6= 0 and we can always take x2, x3, ..., xn also different from zero, then for each i = 1, 2, ..., n there remains only the possibility of terms:\nfi(x) = 0 para i = 1, 2, ..., n.\nThis is absurd, for fi(x) \u2208 [0, 1] e n\u2211 i=1 fi(x) = 1. like this, H has no zero divisors.\nProposition 8. H does not have one divisors\nProof. Just to see that a \u2208 ]0, 1[, we have to H(a, 0, ..., 0) = f1(x).a \u2264 a < 1.\nProposition 9. H is symmetric.\nProof. Let P : {1, 2, ..., n} \u2192 {1, 2, ..., n} be a permutation. So we can easily see that Med(xP (1), xP (2), ..., xP (n)) = Med(x1, x2, ..., xn) for all x = (x1, x2, ..., xn) \u2208\n[0, 1]n. We also have to n\u2211 i=1 |xP (i)\u2212Med(xP (1), xP (2), ..., xP (n))| = n\u2211 i=1 |xi\u2212Med(x)|. Thus, it suffices to consider the case where (xP (1), xP (2), ..., xP (n)) 6= (x, x, ..., x). But (xP (1), xP (2), ..., xP (n)) 6= (x, x, ..., x) we have to:\nH (xP (1), xP (2), ..., xP (n)) =\n= 1n\u22121 n\u2211 i=1 xP (i) \u2212 xP (i)|xP (i)\u2212Med(xP (1),...,xP (n))|n\u2211 j=1 |xP (i)\u2212Med(xP (1),...,xP (n))|  = n\u2211 i=1 xP (i)\nn\u22121 \u2212 1 n\u22121 \u00b7 n\u2211 i=1 xP (i)|xP (i)\u2212Med(x1,...,xn)| n\u2211\nj=1 |xP (i)\u2212Med(x1,...,xn)|\n=\nn\u2211 i=1 xi\nn\u22121 \u2212 1 n\u22121 \u00b7 n\u2211 i=1 xP (i)|xP (i)\u2212Med(x1,...,xn)| n\u2211\nj=1 |xi\u2212Med(x1,...,xn)|\n=\nn\u2211 i=1 xi\nn\u22121 \u2212 1 n\u22121 \u00b7 n\u2211 i=1 xi|xi\u2212Med(x1,...,xn)| n\u2211\nj=1 |xi\u2212Med(x1,...,xn)|\n= H(x1, ..., xn).\nTherefore, H satisfies the following properties:\n\u2022 Idempotence\n\u2022 Homogeneity\n\u2022 Shift-invariance\n\u2022 Symmetry.\n\u2022 H has no neutral element\n\u2022 H has no absorbing elements\n\u2022 H has no zero divisors\n\u2022 H does not have one divisors\nRemark 2. Unfortunately we do not prove here the monotonicity of H, due to its complexity, but we suspect that it is true. This demonstration will be relegated to a future work.\nThe next two sections show the suitability of DY OWA. They will provide appli-\ncations for image and noise reduction."}, {"heading": "4 DY OWA\u2019s as images reduction tools", "text": "In this part of our work we use the functions DY OWA studied in Examples 4, 5, 6, 7 and 8, and definition 5 to build image reduction operators, the resulting images will be compared with the reduced image obtained from the operator function H.\nAn image is a matrix m \u00d7 n, M = A(i, j), where each A(i, j) represents a pixel. In essence, a reduction operator reduces a given image m\u00d7n to another m\u2032\u00d7n\u2032, such that m\u2032 < m and n\u2032 < n. For example,\n 0.1 0.2 0 0.5 0.3 0.3 0.2 0.8 1 0.5 0.6 0.4\n0 0.3 0.5 0.7\n 7\u2212\u2192  0.1 0 1 0.6 \nIn Grayscale images the value of pixels belong to the set [0, 255], which can be\nnormalized by dividing them by 255, so that we can think of pixels as values in the range [0, 1].\nThere are several possible ways to reduce a given image, as shown in the following\nexample:\nExample 12. The image\nM =  0.8 0.7 0.2 1 0.5 0.5 0.6 0.2 0.3 0.1 1 0 0 0 0.6 0.4 0.9 1\n0.1 0.2 0.3 0.4 0.5 0.6\n ,\ncan be reduced to another 2\u00d7 3 by partitioning M in blocks 2\u00d7 2:\nM =   0.8 0.7 0.6 0.2   0.2 1 0.3 0.1   0.5 0.5 1 0   0 0\n0.1 0.2\n  0.6 0.4\n0.3 0.4\n  0.9 1\n0.5 0.6\n  ,\nand applying to each block, for example, the function f(x, y, z, w) = Max(x, y, z, w): We obtain, the image:\nM\u2217 =  0.8 1 1 0.2 0.6 1  Applying g(x, y, z, w) = Min(x, y, z, w) we would obtain:\nM\u2217\u2217 =  0.2 0.1 0 0 0.2 0.5  In fact, if we apply any other function, we get a new image (usually different from\nthe previous one), but what is the best?\nOne possible answer to this question involves a method called magnification or extension (see [19, 20, 21]), which is a method which magnifies the reduced image to another with the same size of the original one. The magnified image is then compared with the original input image.\nExample 13. From M\u2217 and M\u2217\u2217, we get images 4 \u00d7 6, M \u2032 and M \u2032\u2032, simply cloning each pixel , [ x ] 7\u2212\u2192  x x x x \nWe obtain, new images\nM1 =  0.8 0.8 1 1 1 1 0.8 0.8 1 1 1 1 0.2 0.2 0.6 0.6 1 1\n0.2 0.2 0.6 0.6 1 1  and\nM2 =  0.2 0.2 0.1 0.1 0 0 0.2 0.2 0.1 0.1 0 0 0 0 0.2 0.2 0.5 0.5\n0 0 0.2 0.2 0.5 0.5  Since M1 e M2 have the same size as the original image M , we can now measure what is the best reduction. This can be done by comparing the initial image M with each of the resulting images, M1 and M2. But, how do we compare?\nOne of the possibilities to compare the images M1 and M2 with the original image\nM is to use the mensure PSNR [4], calculated as follows:\nPSNR(I,K) = 10 \u00b7 log10 (\nMAX2I MSE(I,K)\n) ,\nwhere I = I(i, j) andK = K(i, j) are two images,MSE(I,K) = 1nm m\u2211 i=1 n\u2211 j=1 [I(i, j)\u2212 K(i, j)]n and MAXI is the maximum possible pixel value of pixel. Observe that the closer the image the smaller the value of MSE and the larger the value of PSNR 3.\nIn what follows, we use DY OWA operators: H, cOWA,Median and Arith to\nreduce size of images in grayscale. We apply the following method:\nMethod 1\n1. Reduce the input images using the H, cOWA, Arithmetic Mean and Median; 3In particular, if the input image are equal, then the MSE value is zero and the PSNR will be infinity.\n2. Magnify the reduced image to the size of the original image using the method\ndescribed in example 13;\n3. Compare the last image with the original one using the measure PSNR.\nRemark 3. This general method can be applied to any kind of image. In this work we applied it to the 10 images in grayscale of size 512\u00d7 512 (Figure 2) 4.\nIn the tables I and II we present the PSNR values between the input images and the output provided by Method 1. Table 1 provides results for operators using blocks 2\u00d72 and Table II for blocks 4\u00d7 4.\nAccording to PSNR, Arith provided the higher quality image. However, the reduction operators generated by H and cOWA provide us quite similar images to those given by Arith.\nObserve that although the Method 1 is very simple, it introduces noise in the resulting image. In what follows we show that the operator H is suitable to filter images with noise. This is done by using H to define the weights which are used in the process of convolution. This new process will, then, be used to provide a better comparison in the Method 1. 4In this paper we made two reductions: using 2\u00d7 2 blocks and 4\u00d7 4 blocks."}, {"heading": "5 DY OWA\u2019s as Tools of Noise Reduction", "text": "In this section we show that the DY OWA operators studied in section III can be used to deal with images containing noise.\nThe methodology employed here consists to analyze the previous images with Gaussian noise \u03c3 = 10% and 15%; apply a filter built upon the operators H, cOWA and Arith based on convolution method (See [4]), and compare the resulting images with the original one using PSNR.\nTables III and IV demonstrate the power of H on images with noise. All listed operators improved significantly the quality of the image with noise. However, H exceeded all other analyzed.\nFigure 4 shows an example of a image with Gaussian noise \u03c3 = 15% and the\nFigure 5 the output image after applying the filter of convolution using H.\nThe reader can see in tables III and IV that H proved to be an excellent operator\nfor noise reduction.\nIn what follows, we modify the Method 1 in order to provide a better magnified\nimage to be compare with the original one.\nMethod 1\u2019\n1. Reduce the input images using the H, cOWA, Arithmetic Mean and Median;\nSince the output of convolution using H is closer to the original input image, the\ntables V and VI show that the process of reduction using H is more efficient."}, {"heading": "6 Final Remarks", "text": "In this paper we propose a generalized form of Ordered Weighted Averaging function, called Dynamic Ordered Weighted Averaging function or simply DYOWA. This functions are defined by weights, which are obtained dynamically from of each input vector x \u2208 [0, 1]n. We demonstrate, among other results, that OWA functions are instances of DY OWAs, and, hence, functions like: Arithmetic Mean, Median, Maximum, Minimum and cOWA are also examples of DY OWA.\nIn the second part of this work we present a particular DY OWA, called of H, and show that it is idempotent, symmetric, homogeneous, shift-invariant, and moreover, it has no zero divisors and one divisors, and also does not have neutral elements. Since aggregation functions which satisfy these properties are extensively used in image processing, we tested its usefulness to: (1) reduce the size of images and (2) deal with noise in images.\nIn terms of image reduction, Method 1 showed a weakness, since it adds noise during the process of magnification. However, the treatment of noise with function H improved the magnification step providing an evidence that the function H is more efficient to perform the image reduction process."}], "references": [{"title": "R", "author": ["D. Paternain", "J. Fernandeza", "H. Bustince"], "venue": "Mesiar ,G. Beliakov, Construction of image reduction operators using averaging aggregation functions, Fuzzy Sets and Systems 261 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Brain Tumor MRI Image Segmentation and Detection in Image Processing", "author": ["R.P. Joseph", "C.S. Singh", "M. Manikandan"], "venue": "International Journal of Research and Tecnology, vol 3 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "ISEF Based Identification of RCT/Filling in 30  Dental Caries of Decayed Tooth", "author": ["A.J. Solanki", "K.R. Jain", "N.P. Desai"], "venue": "International Journal of Image Processing (IJIP), vol 7 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Digital Image Processing", "author": ["R.C. Gonzales", "R.E. Woods"], "venue": "third edition, Pearson", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Ordered weighted averaging aggregation operators in multicriteria decision making", "author": ["R.R. Yager"], "venue": "IEEE Trans. Syst. ManCybern. 18 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1988}, {"title": "On the use of aggregation operations in information fusion processes", "author": ["D. Dubois", "H. Prade"], "venue": "Fuzzy Sets Syst. 142 ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2004}, {"title": "Fuzzy Multiple Attribute Decision Making: Methods and Applications", "author": ["S.-J. Chen", "C.-L. Hwang"], "venue": "Springer, Berlin, Heidelberg", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1992}, {"title": "Type - 1 OWA operators for aggregating uncertain information with uncertain weight sinduced by type -2 linguistic quantifiers", "author": ["S. -M. Zhou", "F. Chiclana", "R.I. John", "J.M. Garibaldi"], "venue": "Fuzzy Sets Syst", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Using a web personal evaluation tool \u2014 PET for lexicographic multi-criteria service selection", "author": ["R.R. Yager", "G. Gumrah", "M. Reformat"], "venue": "Knowl. - Based Syst. 24 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "E", "author": ["D. Paternain", "A. Jurio", "E. Barrenechea", "H. Bustince", "B.C. Bedregal"], "venue": "Szmidt: An alternative to fuzzy methods in decision-making problems. Expert Syst. Appl. 39(9): 7729-7735 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "R", "author": ["H. Bustince", "M. Galar", "B.C. Bedregal", "A. Koles\u00e1rov\u00e1"], "venue": "Mesiar: A New Approach to Interval-Valued Choquet Integrals and the Problem of Ordering in Interval-Valued Fuzzy Set Applications. IEEE T. Fuzzy Systems 21(6): 1150-1162 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Image reduction using means on discrete product lattices", "author": ["G. Beliakov", "H. Bustince", "D. Paternain"], "venue": "IEEETrans. ImageProcess. 21 ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Aggregation method for motor drive systems", "author": ["X. Liang", "W. Xu"], "venue": "Eletric Power System Research 117 ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "H", "author": ["D. Dubois"], "venue": "Prade (Eds.), Fundamental sof Fuzzy Sets, Kluwer Academic Publishers, Dordrecht", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2000}, {"title": "Aggregation functions: a guide for practitioners", "author": ["G. Beliakov", "A. Pradera", "T. Calvo"], "venue": "Stud. Fuzziness Soft Comput. 221", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2007}, {"title": "Aggregation Functions", "author": ["M. Grabisch", "E. Pap", "J.L. Marichal", "R. Mesiar"], "venue": "University Press Cambridge", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Fuzzy Implications", "author": ["M. Baczy\u0144nski", "B. Jayaram"], "venue": "Springer, Berlin", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "Centered OWA operators", "author": ["R.R. Yager"], "venue": "Soft Comput. 11 ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Image magnification using interval information", "author": ["A. Jurio", "M. Pagola", "R. Mesiar", "G. Beliakov", "H. Bustince"], "venue": "IEEE Trans. Image Process. 20 ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Image Super-Revolution Via Sparse Representation", "author": ["J. Yang", "J. Wright", "T.S. Huang", "Y. Ma"], "venue": "IEEE Trans on Image Processing, v. 19, n. 11 ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Image Super-Revolution as Sparse Representation of Raw Image Patches", "author": ["J. Yang", "J. Wright", "T.S. Huang", "Y. Ma"], "venue": "Computer Vision and Pattern Recoginition, 2008. CVPR 2008. IEEE Conference, IEEE", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "In terms of image reduction we apply the methodology provided in [1].", "startOffset": 65, "endOffset": 68}, {"referenceID": 1, "context": "In medicine, for example, they can be applied to: Identify tumors [2]; support techniques in advancing dental treatments [3], etc.", "startOffset": 66, "endOffset": 69}, {"referenceID": 2, "context": "In medicine, for example, they can be applied to: Identify tumors [2]; support techniques in advancing dental treatments [3], etc.", "startOffset": 121, "endOffset": 124}, {"referenceID": 3, "context": "Another problem addressed in image processing is the decrease of resolution, usually aiming the reduction of memory consumption required for its storage [4].", "startOffset": 153, "endOffset": 156}, {"referenceID": 0, "context": "[1] constructed reduction operators using weighted averaging aggregation functions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "The proposed method consists of: (1) To reduce a given image by using a reduction operator; (2) To build a new image from the reduced one, and (3) To analyze the quality of the last image by using the measures PSNR and MSIM [4].", "startOffset": 224, "endOffset": 227}, {"referenceID": 4, "context": "They generalize the OWA function introduced by Yager [5] and in particular the operators: Arithmetic Mean, Median, Maximum, Minimum and cOWA.", "startOffset": 53, "endOffset": 56}, {"referenceID": 5, "context": "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].", "startOffset": 109, "endOffset": 112}, {"referenceID": 8, "context": "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].", "startOffset": 130, "endOffset": 147}, {"referenceID": 7, "context": "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].", "startOffset": 130, "endOffset": 147}, {"referenceID": 6, "context": "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].", "startOffset": 130, "endOffset": 147}, {"referenceID": 10, "context": "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].", "startOffset": 130, "endOffset": 147}, {"referenceID": 9, "context": "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].", "startOffset": 130, "endOffset": 147}, {"referenceID": 0, "context": "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].", "startOffset": 166, "endOffset": 176}, {"referenceID": 1, "context": "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].", "startOffset": 166, "endOffset": 176}, {"referenceID": 11, "context": "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].", "startOffset": 166, "endOffset": 176}, {"referenceID": 12, "context": "Aggregation functions are important mathematical tools for applications in several fields: Information fuzzy [6]; Decision making [9, 8, 7, 11, 10]; Image processing [1, 2, 12] and Engineering [13].", "startOffset": 193, "endOffset": 197}, {"referenceID": 0, "context": "1 Definition and Examples Aggregation functions associate each entry x with n arguments in the closed interval [0, 1] an output value also in the interval [0, 1]; formally we have: Definition 1.", "startOffset": 111, "endOffset": 117}, {"referenceID": 0, "context": "1 Definition and Examples Aggregation functions associate each entry x with n arguments in the closed interval [0, 1] an output value also in the interval [0, 1]; formally we have: Definition 1.", "startOffset": 155, "endOffset": 161}, {"referenceID": 0, "context": "An n-ary aggregation function is a mapping f : [0, 1] \u2192 [0, 1], which associates each n-dimensional vector x to a single value f(x) in the interval [0, 1] such that: 1.", "startOffset": 47, "endOffset": 53}, {"referenceID": 0, "context": "An n-ary aggregation function is a mapping f : [0, 1] \u2192 [0, 1], which associates each n-dimensional vector x to a single value f(x) in the interval [0, 1] such that: 1.", "startOffset": 56, "endOffset": 62}, {"referenceID": 0, "context": "An n-ary aggregation function is a mapping f : [0, 1] \u2192 [0, 1], which associates each n-dimensional vector x to a single value f(x) in the interval [0, 1] such that: 1.", "startOffset": 148, "endOffset": 154}, {"referenceID": 14, "context": "A wider approach in aggregation can be found in [15, 14, 16, 17].", "startOffset": 48, "endOffset": 64}, {"referenceID": 13, "context": "A wider approach in aggregation can be found in [15, 14, 16, 17].", "startOffset": 48, "endOffset": 64}, {"referenceID": 15, "context": "A wider approach in aggregation can be found in [15, 14, 16, 17].", "startOffset": 48, "endOffset": 64}, {"referenceID": 16, "context": "A wider approach in aggregation can be found in [15, 14, 16, 17].", "startOffset": 48, "endOffset": 64}, {"referenceID": 0, "context": "An aggregation is called Averaging, if for all x \u2208 [0, 1] we have:", "startOffset": 51, "endOffset": 57}, {"referenceID": 0, "context": ", x) = x for all x \u2208 [0, 1].", "startOffset": 21, "endOffset": 27}, {"referenceID": 0, "context": "(2) is Homogeneous of order k if, and only if, for all \u03bb \u2208 [0, 1] and x \u2208 [0, 1], f(\u03bbx1, \u03bbx2, .", "startOffset": 59, "endOffset": 65}, {"referenceID": 0, "context": "(2) is Homogeneous of order k if, and only if, for all \u03bb \u2208 [0, 1] and x \u2208 [0, 1], f(\u03bbx1, \u03bbx2, .", "startOffset": 74, "endOffset": 80}, {"referenceID": 0, "context": ", xn)+ r, for all r \u2208 [\u22121, 1], x \u2208 [0, 1] such that (x1 + r, x2 + r, .", "startOffset": 35, "endOffset": 41}, {"referenceID": 0, "context": ", xn + r) \u2208 [0, 1] and f(x1, x2, .", "startOffset": 12, "endOffset": 18}, {"referenceID": 0, "context": ", xn) + r \u2208 [0, 1].", "startOffset": 12, "endOffset": 18}, {"referenceID": 0, "context": "(6) has a Neutral Element e \u2208 [0, 1], if for all t \u2208 [0, 1] at any coordinate input vector x, it has to be:", "startOffset": 30, "endOffset": 36}, {"referenceID": 0, "context": "(6) has a Neutral Element e \u2208 [0, 1], if for all t \u2208 [0, 1] at any coordinate input vector x, it has to be:", "startOffset": 53, "endOffset": 59}, {"referenceID": 0, "context": "(8) An Absorbing Element (Annihilator) of an aggregation function f , is an element a \u2208 [0, 1] such that:", "startOffset": 88, "endOffset": 94}, {"referenceID": 0, "context": "(11) If N : [0, 1]\u2192 [0, 1] is a strong negation2 and f : [0, 1] \u2192 [0, 1] is an aggregation function, then the dual aggregation function of f is:", "startOffset": 12, "endOffset": 18}, {"referenceID": 0, "context": "(11) If N : [0, 1]\u2192 [0, 1] is a strong negation2 and f : [0, 1] \u2192 [0, 1] is an aggregation function, then the dual aggregation function of f is:", "startOffset": 20, "endOffset": 26}, {"referenceID": 0, "context": "(11) If N : [0, 1]\u2192 [0, 1] is a strong negation2 and f : [0, 1] \u2192 [0, 1] is an aggregation function, then the dual aggregation function of f is:", "startOffset": 57, "endOffset": 63}, {"referenceID": 0, "context": "(11) If N : [0, 1]\u2192 [0, 1] is a strong negation2 and f : [0, 1] \u2192 [0, 1] is an aggregation function, then the dual aggregation function of f is:", "startOffset": 66, "endOffset": 72}, {"referenceID": 4, "context": "3 Ordered Weighted Averaging Function - OWA In the field of aggregation functions there is a very important subclass in which the elements are parametric; they are called: Ordered Weighted Averaging or simply OWA [5].", "startOffset": 213, "endOffset": 216}, {"referenceID": 0, "context": "2A strong negation is an antitonic function N : [0, 1] \u2192 [0, 1] such that N(N(\u03b1)) = \u03b1 for all \u03b1 \u2208 [0, 1].", "startOffset": 48, "endOffset": 54}, {"referenceID": 0, "context": "2A strong negation is an antitonic function N : [0, 1] \u2192 [0, 1] such that N(N(\u03b1)) = \u03b1 for all \u03b1 \u2208 [0, 1].", "startOffset": 57, "endOffset": 63}, {"referenceID": 0, "context": "2A strong negation is an antitonic function N : [0, 1] \u2192 [0, 1] such that N(N(\u03b1)) = \u03b1 for all \u03b1 \u2208 [0, 1].", "startOffset": 98, "endOffset": 104}, {"referenceID": 0, "context": ", xn) \u2208 [0, 1] and a vector of weights w = (w1, .", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": "\u2265 xp(n), the Ordered Weighted Averaging (OWA) Function with respect to w, is the functionOWAw : [0, 1] \u2192 [0, 1] such that: OWAw(x) = n \u2211", "startOffset": 96, "endOffset": 102}, {"referenceID": 0, "context": "\u2265 xp(n), the Ordered Weighted Averaging (OWA) Function with respect to w, is the functionOWAw : [0, 1] \u2192 [0, 1] such that: OWAw(x) = n \u2211", "startOffset": 105, "endOffset": 111}, {"referenceID": 17, "context": "The n-dimensional cOWA function [18] is the OWA operator, with weighted vector defined by: \u2022 If n is even, then wj = 2(2j\u22121) n2 , for 1 \u2264 j \u2264 n 2 , and wn/2+i = wn/2\u2212i+1, for 1 \u2264 i \u2264 n2 .", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "A finite family of functions \u0393 = {fi : [0, 1] \u2192 [0, 1] | 1 \u2264 i \u2264 n} such that: n \u2211", "startOffset": 39, "endOffset": 45}, {"referenceID": 0, "context": "A finite family of functions \u0393 = {fi : [0, 1] \u2192 [0, 1] | 1 \u2264 i \u2264 n} such that: n \u2211", "startOffset": 48, "endOffset": 54}, {"referenceID": 0, "context": "The function Minimum can be obtained from \u0393 = {fi | 1 \u2264 i \u2264 n}, where f1(x) = f2(x) = \u00b7 \u00b7 \u00b7 = fn\u22121(x) = 0 and fn(x) = 1, for all x \u2208 [0, 1].", "startOffset": 133, "endOffset": 139}, {"referenceID": 0, "context": ", x) with t \u2208 [0, 1], then:", "startOffset": 14, "endOffset": 20}, {"referenceID": 0, "context": ", xn) for any x \u2208 [0, 1], for i \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , n} and \u03bb \u2208 [\u22121, 1], then DY OWA\u0393 is shift-invariant.", "startOffset": 18, "endOffset": 24}, {"referenceID": 0, "context": ", xn) \u2208 [0, 1] and \u03bb \u2208 [\u22121, 1] such that (x1+\u03bb, x2+\u03bb, .", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": ", xn+ \u03bb) \u2208 [0, 1].", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "n \u2211 i=1 fi(x) = 1, for all x \u2208 [0, 1].", "startOffset": 31, "endOffset": 37}, {"referenceID": 0, "context": "This is absurd, for fi(x) \u2208 [0, 1] e n \u2211 i=1 fi(x) = 1.", "startOffset": 28, "endOffset": 34}, {"referenceID": 0, "context": ", xn) \u2208 [0, 1].", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": "normalized by dividing them by 255, so that we can think of pixels as values in the range [0, 1].", "startOffset": 90, "endOffset": 96}, {"referenceID": 18, "context": "In fact, if we apply any other function, we get a new image (usually different from the previous one), but what is the best? One possible answer to this question involves a method called magnification or extension (see [19, 20, 21]), which is a method which magnifies the reduced image to another with the same size of the original one.", "startOffset": 219, "endOffset": 231}, {"referenceID": 19, "context": "In fact, if we apply any other function, we get a new image (usually different from the previous one), but what is the best? One possible answer to this question involves a method called magnification or extension (see [19, 20, 21]), which is a method which magnifies the reduced image to another with the same size of the original one.", "startOffset": 219, "endOffset": 231}, {"referenceID": 20, "context": "In fact, if we apply any other function, we get a new image (usually different from the previous one), but what is the best? One possible answer to this question involves a method called magnification or extension (see [19, 20, 21]), which is a method which magnifies the reduced image to another with the same size of the original one.", "startOffset": 219, "endOffset": 231}, {"referenceID": 3, "context": "But, how do we compare? One of the possibilities to compare the images M1 and M2 with the original image M is to use the mensure PSNR [4], calculated as follows:", "startOffset": 134, "endOffset": 137}, {"referenceID": 3, "context": "The methodology employed here consists to analyze the previous images with Gaussian noise \u03c3 = 10% and 15%; apply a filter built upon the operators H, cOWA and Arith based on convolution method (See [4]), and compare the resulting images with the original one using PSNR.", "startOffset": 198, "endOffset": 201}, {"referenceID": 0, "context": "This functions are defined by weights, which are obtained dynamically from of each input vector x \u2208 [0, 1].", "startOffset": 100, "endOffset": 106}], "year": 2016, "abstractText": "In this paper we propose a special type of aggregation function which generalizes the notion of Ordered Weighted Averaging Function OWA. The resulting functions are called Dynamic Ordered Weighted Averaging Functions \u2014 DYOWAs. This generalization will be developed in such way that the weight vectors are variables depending on the input vector. Particularly, this operators generalize the aggregation functions: Minimum, Maximum, Arithmetic Mean, Median etc, which are extensively used in image processing. In this field of research two problems are considered: The determination of methods to reduce images and the \u2217Preprint submitted to IEEE Transactions on Fuzzy Systems. \u2020Federal University of Semi-Arid UFERSA, Pau dos Ferros, RN, Brazil, 59.900-000, antonio.diego@ufersa.edu.br \u2021DIMAp, valdigleis@ppgsc.ufrn.br \u00a7DIMAp, ranyer.lopes@gmail.com \u00b6DIMAp, bedregal@dimap.ufrn.br \u2016Dimap, regivan@dimap.ufrn.br \u2217\u2217DIMAP: Department of Informatics and Applied Mathematics, Federal University of Rio Grande do Norte \u2014 UFRN, Natal, RN, Brazil, 59.072-970 1 ar X iv :1 60 1. 03 78 5v 1 [ cs .A I] 1 5 Ja n 20 16 construction of techniques which provide noise reduction. The operators described here are able to be used in both cases. In terms of image reduction we apply the methodology provided in [1]. We use the noise reduction operators obtained here to treat the images obtained in the first part of the paper, thus obtaining images with better quality.", "creator": "LaTeX with hyperref package"}}}