{"id": "1603.03181", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Mar-2016", "title": "Inferring Fine-grained Details on User Activities and Home Location from Social Media: Detecting Drinking-While-Tweeting Patterns in Communities", "abstract": "Nearly (907) all younus previous work on geo - telramund locating mentawai latent (908) states sterols and doyal activities http://www.nara.gov from social media bezirksliga confounds general 62-year discussions leonberg about activities, self - ssdi reports kokonoe of users overeating participating cret in those ruettiger activities at times niedenthal in the past cagers or future, haam and monds self - reports made contesti at the immediate willet time 43.93 and place the activity sasol occurs. synopses Activities, wlaf such ornskoldsvik as alcohol kukly consumption, kroyts may occur masango at different places malipiero and types of places, apaseo and salang it heathens is important not 97.09 only cl\u00e1udio to fantail detect hand-hewn the hannawald local regions where 22.04 these activities occur, but also to analyze caller the degree of participation mmc in them sevel by suzuya local corini residents. pekarek In .0210 this mi\u0119dzyrzecz paper, frsa we develop new machine learning spearmen based methods kulasekera for prize-winning fine - unia grained limbs localization of ladybird activities ensnarled and home rapu locations snarling from huntsville-decatur Twitter 197 data. kyunghee We commotes apply coriolan these methods to lindland discover and muromets compare kulik alcohol consumption patterns cilia in 6.08 a large langwarrin urban area, New York City, adab and a more suburban douglassville and vidyarthi rural area, furthering Monroe County. We approvable find positive wcf correlations between podia the rate undies of itsukushima alcohol consumption torneio reported improbability among cablinasian a 3.58 community ' hurme s swiger Twitter iwpr users and perilously the prakrits density of barrel alcohol peddars outlets, demonstrating that the triviality degree of 2,703 correlation varies kladanj significantly mambwe between urban and haskel suburban manise areas. nscaa While dukuzov our low-tech experiments leghaei are air-strikes focused bookplate on tray alcohol walpack use, vladimirescu our methods moated for mushu locating fresh-faced homes and distinguishing temporally - rastus specific sepi self - reports are applicable to m21 a ritika broad loyally range of romm behaviors and cutoffs latent wadada states.", "histories": [["v1", "Thu, 10 Mar 2016 08:32:34 GMT  (7173kb,D)", "http://arxiv.org/abs/1603.03181v1", "12 pages, 7 figures, 4-page poster version accepted at ICWSM 2016, alcohol dataset and keywords available in: cs.rochester.edu/u/nhossain/icwsm-16-data.zip"]], "COMMENTS": "12 pages, 7 figures, 4-page poster version accepted at ICWSM 2016, alcohol dataset and keywords available in: cs.rochester.edu/u/nhossain/icwsm-16-data.zip", "reviews": [], "SUBJECTS": "cs.AI cs.SI", "authors": ["nabil hossain", "tianran hu", "roghayeh feizi", "ann marie white", "jiebo luo", "henry kautz"], "accepted": false, "id": "1603.03181"}, "pdf": {"name": "1603.03181.pdf", "metadata": {"source": "CRF", "title": "Inferring Fine-grained Details on User Activities and Home Location from Social Media: Detecting Drinking-While-Tweeting Patterns in Communities", "authors": ["Nabil Hossain", "Tianran Hu", "Roghayeh Feizi", "Ann Marie White", "Jiebo Luo", "Henry Kautz"], "emails": ["nhossain@cs.rochester.edu", "thu@cs.rochester.edu", "White@urmc.rochester.edu", "jluo@cs.rochester.edu", "kautz@cs.rochester.edu"], "sections": [{"heading": "Introduction", "text": "Analysis of Twitter has become a widespread approach for geo-spatial studies of human behavior, such as alcohol consumption (Kershaw, Rowe, and Stacey 2014; Culotta 2013) and exercise (Young 2010), and human latent states, such as sickness (Paul and Dredze 2011; Sadilek, Kautz, and Silenzio 2012a; Sadilek et al. 2013) and depression (Dos Reis and Culotta 2015; Nambisan et al. 2015; Tsugawa et al. 2015). However, nearly all prior work, with the notable exception of (Lamb, Paul, and Dredze 2013), does not attempt to distinguish mere mentions of activities or states from self-reports of activity. Moreover, no attempt has been made to distinguish reports about future or past activities and in-the-moment reports that provide finer details when geo-tagged tweets are used to map specific locations of activities. Further insights into the geo-location of activities can be obtained by inferring the home locations of the subjects involved. Home location helps analyze the number of members of a community engaging in an activity, the kinds of places where the activity occurs (e.g., home, commercial establishment, public place, etc.), and the distance people\ntravel from home to participate in it. Prior research has used simple heuristics for predicting a social media user\u2019s home location, such as the place from which the user most frequently tweets, or the most common last location of the day for the user\u2019s posts (Pontes et al. 2012a; Pontes et al. 2012b; Cho, Myers, and Leskovec 2011; Scellato et al. 2011). But such heuristics are inaccurate for a large percentage of users, e.g., in cases when users frequently visit multiple places.\nWe apply machine learning techniques on Twitter content to identify in-the-moment reports of user behaviors and to accurately predict users\u2019 home locations within 100 meters. Using these tools, we develop new methods for a task of critical interest in public health: discovering patterns of alcohol use in urban and suburban settings. Such methods can help us better understand the occurrence, frequency, and settings of alcohol consumption, a health-risk behavior, and can lead to actionable information in prevention and public health.\nExcessive alcohol use has a tremendous negative impact on health and communities. Drinking directly results in about 75,000 deaths annually in the US, making it the nation\u2019s third leading cause of preventable death (Centers for Disease Control and Prevention and others 2004). Previous research (Kuntsche et al. 2005; Naimi et al. 2003) shows that social factors play an important role in developing drinking patterns over time. While social media such as Twitter is both ubiquitous and publicly available, little research has investigated the relationship between virtual social contexts and the alcohol referencing or alcohol-linked behaviors found there in various real-world community settings.\nIn this paper, we aim to predict where Twitter users are when they report on drinking. We report on several stages of work to accomplish this research objective. First, we collected geo-tagged tweets from urban, suburban, and rural areas of New York State. Using human computation, we created a training set that captures important details such as whether the tweet mentions drinking alcohol, the user drinking, or the user drinking at the time of tweeting. We created a hierarchy of three support vector machine (SVM) classifiers (Burges 1998) to distinguish tweets up to these fine details. Each of these SVMs achieves an F-score above 83% and is used to classify tweets from New York City and from Monroe County, a predominantly suburban area in upstate New York containing one medium-sized city (Rochester), in order to develop methods that can perform in \u201cbig city\u201d as\nar X\niv :1\n60 3.\n03 18\n1v 1\n[ cs\n.A I]\n1 0\nM ar\n2 01\n6\nwell as \u201csmall city\u201d contexts of social media use. We also performed fine-grained home location inference of Twitter users to generate community descriptions, such as to calculate the proportion of \u201csocial media drinkers\u201d drinking at home, and to analyze how far people travel from home to drink-and-tweet. Existing home inference methods either rely on continuous and expensive GPS data, covering a small number of users, or suffer from poor accuracy. We trained an SVM classifier to predict home location for active users (users with as little as 5 geo-tagged tweets) within 100 by 100 meter grids. Considering the sparse and noisy nature of Twitter data that poses serious challenges in pinpointing where people live, our classifier achieves a high accuracy of 70%, covering 71% active users in New York City. We also investigated ways to balance granularity and coverage. Prior work on home location has been limited to localizing at the city level; ours is the first to achieve block-level accuracy."}, {"heading": "Related Work", "text": ""}, {"heading": "Latent States & Activities from Social Media", "text": "Most prior work on using Twitter data about users\u2019 online behavior has estimated aggregate disease trends in a large geographic area, typically at the level of a state or a large city. Researchers have examined influenza tracking (Culotta 2010; Achrekar et al. 2012; Sadilek and Kautz 2013; Broniatowski and Dredze 2013; Brennan, Sadilek, and Kautz 2013), mental health and depression (Golder and Macy 2011; De Choudhury et al. 2013), as well as general public health across a broad range of diseases (Brownstein, Freifeld, and Madoff 2009; Paul and Dredze 2011). Some researchers have begun modeling health and contagion across individuals (Ugander et al. 2012; White and Horvitz 2008; De Choudhury et al. 2013). For example, (Sadilek, Kautz, and Silenzio 2012b) showed that Twitter users who exhibit symptoms of influenza can be accurately detected using a language model based on word trigrams. A detailed epidemiological model can be subsequently built by following the interactions between sick and healthy individuals in a population, where physical encounters are estimated by spatio-temporal collocated tweets. nEmesis (Sadilek et al. 2013) scored restaurants in New York City by the number of Twitter users who posted status updates from a restaurant and within the next several days posted self-reports of symptoms of food poisoning. Our hierarchical classifiers use the same kind of word-trigram features at each level.\nLittle prior work has attempted to distinguish true in-themoment self-reports on Twitter from more general discussion of a condition or activity. A notable exception is (Lamb, Paul, and Dredze 2013), which explored language models that could distinguish discussion of the flu from self-reports. This work enriched the set of n-gram language features by including manually-specified sets of words, features for hashtags and retweets, and various syntactic patterns. For separating general discussion from reports of some particular person being sick, n-grams were most important, followed by the manually-specified word classes. For separating reports of the user being sick from reports of others being sick, n-grams were again most important, by the hash-\ntag/retweet features. The overall success of n-grams supports our n-gram based approach for latent activity detection. The authors did not use hierarchical classifiers or attempt to distinguish in-the-moment-reports from those about the past or future."}, {"heading": "Alcohol Consumption", "text": "Despite the huge public health costs exacted by alcohol use, commercial interests and individuals, for example, teens (Moreno et al. 2009; Egan and Moreno 2011) do post about alcohol and drinking in social media. Alcohol-related posts are seen as credible reports by teens and thus posts can influence perceived social norms, a factor linked to the uptake of drinking behaviors (Litt and Stock 2011).\nIn the case of alcohol use, social context certainly matters. For instance, survey research shows that having close friends that drink heightens alcohol use and perceptions about alcohol use in teen life, in general (Jackson et al. 2014; Polonec, Major, and Atwood 2006). Peer alcohol consumption behavior of one\u2019s social network, particularly those of relatives and friends (not immediate neighbors and coworkers), is a risk factor for alcohol use, specially among adolescents (Rosenquist et al. 2010; Ali and Dwyer 2010).\nWhen the geography of one\u2019s daily life creates proximity to alcohol (i.e., greater spatial/temporal availability of on-premise or off-premise alcohol outlets, etc.), a welldocumented risk factor for alcohol use and its array of related adverse public health consequences emerges (Campbell et al. 2009; Weitzman et al. 2003; Holmes et al. 2014; Scribner et al. 1999; Scribner et al. 2008; Livingston 2008a; Livingston 2008b; Livingston 2011; Kypri et al. 2008; Chen, Grube, and Gruenewald 2010; Scribner, MacKinnon, and Dwyer 1994; Zhu, Gorman, and Horel 2004; Britt et al. 2005; Liang and Chikritzhs 2011). Modifying proximity is often explored as a public health policy means to reduce alcohol use, for instance, in neighborhoods (Sparks, Jernigan, and Mosher 2011). However, the association between neighborhood alcohol outlet density and percentage of alcohol consumers may be more complex due to variation in travel patterns and neighborhood styles, and mediated by proximity to one\u2019s home (e.g., within one-mile) (Schonlau et al. 2008).\nSocial media is a new ubiquitous source of real-time community and individual public-health related behaviors. When seeking to apply social media to detect the social media ecology of health behaviors such as alcohol use, it is important to identify not only whether but where (the settings in which) the mentions or posts are occurring. As both geo-physical and virtual access to rapidly diffused messages about alcohol and its use may heighten risky drinking and related behaviors, methods are needed to permit the study of these potentially interacting influences. Such methods can reveal different risk patterns associated with different locations not prior known, and help inform more localized or targeted intervention strategy development. For instance, as social network structures are observable in social media, and as \u201cneighbor\u201d attributes can influence drinking behavior among online friends or followers, studying network influence in social media settings like Twitter may illuminate drinking\nrisk patterns not previously known. However, current methods for examining these influences are very limited. Methods for detecting problematic alcohol use in communities are typically opportunity or survey based (e.g., driver check-points, community surveys, ED admissions, or health care-based screenings), not often scalable to population levels due to resource restrictions. Research on how to vivify a community\u2019s raft of social media posts to detect its alcohol use patterns is only now starting to emerge. For instance, (Tamersoy, De Choudhury, and Chau 2015) distinguished long-term versus short-term drinking/smoking abstinence from the social media site Reddit. These researchers were able to use linguistic features from content posted, and social interaction features derived from users\u2019 network structure through the application of supervised learning. In this paper, we propose new automated methods for identifying both whether and where self-reports of drinking are occurring among Twitter users in two major metropolitan regions of New York State."}, {"heading": "Home Location Detection", "text": "With the knowledge of home locations, we can gain a better insight to human mobility patterns, as well as lifestyle in general. In (Scellato et al. 2011; Cho, Myers, and Leskovec 2011; Scellato, Noulas, and Mascolo 2011), home location is the key origin to calculate the distance that people travel and to estimate the distance between social network users in a pairwise fashion. Home location has also been used to model individuals\u2019 living conditions and lifestyles (Sadilek and Kautz 2013). We organize the discussion of related work on home location prediction by the type of data used.\nLanguage content There has been much prior work on using language features in non-geotagged social media posts to predict the home locations of users at a coarse grain, at the level of a city or state. In (Mahmud, Nichols, and Drews 2012), linguistic features and place names from tweets were used to create a classifier that infers home locations at city, state and time zone levels in the top 100 most populated US cities with accuracies of 58%, 66%, and 78% respectively. This suggests that language models are not good for fined-grained home localization (in our case, within 100 meters). Similar results, accurate at most to several kilometers, appear in (Pontes et al. 2012a). In (Cheng, Caverlee, and Lee 2010), the authors used a content-based method to detect Twitter users\u2019 home cities, placing 51% of active users within 100 miles of their actual home locations.\nGeo-tagged Data Others developed \u201csingle-attribute\u201d models based on different social network features, for example, taking the value of users\u2019 \u201cEmployment\u201d as their home cities in Google+, or using geo-tags in FourSquare, Google+, and Twitter posts to predict the city.Geo-tagged Foursquare data was used in (Pontes et al. 2012b) to infer home cities within 50 kilometers with 78% of user coverage. A dataset containing the traces of 2 million mobile phone users from a European country was used in (Cho, Myers, and Leskovec 2011) to estimate home locations based on the places with most check-ins. The paper reported that by\nmanual checking, the most check-ins method achieved 85% accuracy when the area was divided into 25 by 25 km cells.\nOther researchers used simple heuristics to select the home location from the set of locations in a user\u2019s geotagged posts. The most popular heuristics are to assume that the location with the most check-ins is home (Scellato et al. 2011), or to assume that the common last location of the day from which one tweets is home (Sadilek and Kautz 2013). The accuracy and coverage of such heuristic approaches was not reported. We discovered that these prior methods individually suffered from low accuracy and/or coverage. For example, the most check-ins approach performs poorly when a user visits several places with similar frequencies.\nWearable GPS and Diary Data GPS and diary data make home detection more precise and easier because they are more dense and continuous than social network location data, but they are more expensive to obtain, resulting in low population coverage when used in locating homes. In (Krumm 2007), a device recorded location coordinates every several seconds when the car was moving on 172 subjects\u2019 vehicles. The subjects reported the ground truth of their homes. The authors then used 4 heuristic algorithms to compute the coordinates of each subject\u2019s home, and found that the best one was \u201clast destination of a day\u201d. The median distance error of their best algorithm was 60.7 meters. In (Hoh et al. 2006), the researchers performed agglomerative clustering on the GPS traces of users until the clusters reached an average size of 100 meters. Next they manually eliminated clusters with no recorded points between 4PM and midnight and those falling outside the residential areas.\nSemantically labeling places is another important topic related to home location detection. In (Sadilek and Krumm 2012), the authors used GPS data from 307 people and 396 vehicles, then divided the world into 400 by 400 meter grids, and assigned each GPS reading to the nearest cell. They found that the top 10 frequently visited locations can usually be semantically labeled as \u201chome\u201d, \u201cwork\u201d, \u201cfavorite restaurant\u201d and so on. Other researchers (Krumm and Rouhana 2013) performed experiments using two diary datasets \u2014 American Time Use Survey and the Puget Sound Regional Council Household Activity Survey \u2014 where each location had a semantic label such as \u201chome\u201d or \u201cschool\u201d. They extracted several features of a location and trained place classifiers using machine learning, reporting a classification accuracy above 90% on locations labeled as \u201chome\u201d."}, {"heading": "Alcohol Usage Detection", "text": "We now describe our methods for detecting geo-temporal alcohol consumption via Twitter. We discuss the data preparation steps, the hierarchical classification approach, the strategies we employed to reduce classifier overfitting and the results."}, {"heading": "Ground Truth", "text": "We collected geo-tagged tweets from urban, suburban and rural areas in New York State from July 2013 to July 2014. Similar to the approach used in (Paul and Dredze 2011), we began the process of creating a training dataset by first\nfiltering tweets if they included a mention of alcohol, defined by the inclusion of any one of several drinking-related keywords (e.g., \u201cdrunk\u201d, \u201cbeer\u201d, \u201cparty\u201d) and their variants. The word set was reviewed and modified with local community member input from our social media analytic advisory group, the Big Data Docents.\nWe were interested in labeling each tweet that passed this filter by applying a hierarchy of three yes/no feature questions, as follows:\nQ1: Does the tweet make any reference to drinking alcoholic beverages?\nQ2: if so, is the tweet about the tweeter him or herself drinking alcoholic beverages?\nQ3: if so, is it likely that the tweet was sent at the time and place the tweeter was drinking alcoholic beverages?\nWe labeled this Alcohol dataset1 using the Amazon Mechanical Turk2. Given a tweet, a turker was asked Q1, and only if the turker answered \u201cyes\u201d, then he/she was asked Q2, and so on. Each question was passed to three Turkers and the answer choices were \u201cyes\u201d, \u201cno\u201dand \u201cnot sure\u201d. Tweets that didn\u2019t receive consensus in turker ratings ( (yes/no) agreement among less than two turkers) were discarded from the dataset. The remaining tweets were labeled \u20181\u2019 if two or more turkers answered \u201cyes\u201d, otherwise they were labeled \u20180\u2019 for each feature question. Since for each tweet the questions were asked hierarchically, the approach resulted in a smaller ground truth for deeper questions, as Table 1 shows.\n1dataset and keywords available in: cs.rochester.edu/ u/nhossain/icwsm-16-data.zip\n2http://www.mturk.com"}, {"heading": "Dataset Pre-processing", "text": "Tweet texts are usually conversational texts, noisy and unstructured, making it difficult to create a good feature set using them. We performed several pre-processing techniques to reduce lexical variation in tweets. These include converting hyperlinks to \u201c#url\u201d, mentions to \u201c#mention\u201d, emoticons to positive and negative emoticon features, using hashtags as distinct features, and truncating three or more consecutive occurrences of a character in a word to two consecutive occurrences (e.g. \u201cdruuuuuuunk\u201d\u2192 \u201cdruunk\u201d). Using the pre-processed tweets and their labels, we created separate trigram linguistic feature sets for the three questions. In order to reduce overfitting, we only kept the top N mostfrequent features, where N = 25% of the size of the training set size for the corresponding question."}, {"heading": "Training", "text": "For each of the three questions, we trained a linear support vector machine (SVM) to predict the answer. As shown in Figure 1, these SVMs are hierarchical (Koller and Sahami 1997). For example, the data for SVM-2 (SVM for question Q2) include only the tweets labeled by SVM-1 as \u201cyes\u201d and for which consensus was reached by turkers for Q2. This restricts the dataset distribution as we go down the hierarchy. Compared to a single flattened multi-class classifier, hierarchical classifiers are easier to optimize, and because they\nhave a restricted feature set, we can build more complex models without overfitting. This way of classifying tweets is also more intuitive and suits our purposes. In other words, SVM-1 will be specialized to filter drinking-related tweets, while SVM-3 assumes that the input tweet is about drinking and particularly the tweeter drinking, and decides whether the tweeter was drinking when he/she posted the tweet.\nFor each SVM, we used 80% of the labeled data for training and the remaining 20% for testing. We applied 5 fold cross validation to reduce overfitting and used the F-score for model selection. The F-score, ranging between 0 and 1, is the harmonic mean of precision and recall, and the higher the score the lower the classification error."}, {"heading": "Results", "text": "The results in Table 1 show high precision and recall for each question. They also suggest that the more detailed the question becomes, the harder it gets for the classifier to predict correctly. This is not unexpected because intuitively we expect Q3 to be a harder question to answer compared to Q1. More importantly, our hierarchical classification approach shrinks the training data as we go down to deeper questions, most likely making it difficult for the classifiers down the hierarchy to learn from the smaller data. However, we believe that this approach is better than a multi-class SVM approach which, although would use the full training data to answer each question, does not have the advantage of restricting the data distribution to focus on the question. For example, Table 2 shows that SVM-1 mainly uses features related to alcoholic drinks to determine whether the tweet is related to drinking alcoholic beverages. SVM-2 distinguishes self-reports of drinking from general drinking discussion by using pronouns and implicit references to drinking, as Table 3 suggests. Table 4 shows that, having known that the tweet is related to the user drinking alcohol, SVM-\n3 identifies drinking in-the-moment using temporal features (e.g., \u201changover\u201d, \u201clast night\u201d, \u201cnow\u201d) and features related to the urge to drink (e.g., \u201cneed\u201d, \u201cwant\u201d)."}, {"heading": "Home Location Prediction", "text": "Existing home inference methods suffer from either low coverage (GPS & diary data) or coarse granularity and low accuracy (language models and prior work on geo-tagged data), making them inadequate for problems that require both high coverage and fine granularity. Our more sophisticated machine learning based algorithm combines a number of different features describing each user\u2019s daily trajectories as determined from geo-tagged tweets, thus predicting users\u2019 home locations from sparse tweets with high accuracy and coverage. We now describe our method for home location prediction of Twitter users, the creation of a labeled training data, the feature set, our results, and we evaluate our system."}, {"heading": "Dataset & Pre-Processing", "text": "We collected geo-tagged tweets sent from the greater New York City area during July 2012 and from the Bay Area during 06/01/2013 - 08/31/2013. A typical geo-tagged tweet contains the ID of the poster, the exact coordinates from where the tweet was sent, time stamp, and the text content. Due to the inherent noise in the geo-tags, we split the areas into 100 by 100 meter grids and treat the center of each grid as the target of home detection. Each tweet is assigned to its closest grid, and every time a user\u2019s tweet appears in a grid we say the user has a check-in in this grid. Similar to previous work (Song et al. 2010; Smith et al. 2014; Lin, Hsu, and Lee 2012), we only focus on users who have sent at least 5 geo-tagged tweets, and we call them active users. Also following these studies, we take each user\u2019s hourly traces (only one location for each hour in our sampling duration) instead of using every single check-in. Thus, if a user appears in several unique grids in an hour, we\ntake the grid with the highest number of check-ins as the user\u2019s location for the hour (ties are broken by random selection). If a user\u2019s location is not observed in an hour, the location for that hour is set to \u201cNull\u201d. Typically, the hourly traces TU of a user U form a sparse vector, for example, TU = [Null, Li, Null, ..., Lj ], and the size of TU is the number of hours in the sampling period. We provide a snapshot of our dataset in Table 5."}, {"heading": "Ground Truth", "text": "Obtaining fine-grained ground truth is challenging because it involves identifying a Twitter user\u2019s home from several locations the user checked-in without being told by the user. Some researchers relied on information from user profiles (Pontes et al. 2012a; Pontes et al. 2012b; Mahmud, Nichols, and Drews 2012), others manually inspected the detection results (Cho, Myers, and Leskovec 2011). However, the location information in user profiles is coarse (at city level), while manual inspection is not scalable. Reading a tweet that says \u201cEnjoying the beautiful conference room view!\u201d, a human can tell that it was sent from a workplace. Tweets such as \u201cfinally home!\u201d or \u201chome sweet home\u201d are most likely sent from home. Thus, we relied on tweet content and human intelligence to build the ground truth for home location.\nWe asked faithful Twitter users what they would like to post when at home. Based on their answers, we selected a set of 50 keywords (e.g., \u201chome\u201d, \u201cbath\u201d, \u201csofa\u201d, \u201cTV\u201d, \u201csleep\u201d, etc.) and their variants which are likely to be mentioned in tweets sent from home. Next, we filtered tweets that contained at least one of these keywords. Then, we relied on Amazon Mechanical Turk to find the tweets sent from home. Each turker was given a questionnaire containing 5 tweets to answer. For each tweet we asked: \u201cis this tweet sent from home?\u201d, and the options were \u201cyes\u201d, \u201cno\u201d and \u201cnot sure\u201d. Each questionnaire was answered by three unique turkers. We only retained the tweets which, all three turkers believed, were sent from home."}, {"heading": "Features Based on Human Mobility", "text": "Previous work using linguistic features from tweet content (Mahmud, Nichols, and Drews 2012; Cheng, Caverlee, and Lee 2010) did not achieve good accuracy in granular settings, and even in course-grained conditions these methods required over a few hundred tweets per user to obtain reasonable accuracy. Our goal is to predict homes for users with as little as 5 tweets to increase coverage. Therefore, instead of using linguistic features, we extract features that capture temporal and spatial properties of homes. Although some of these features alone (e.g. check-in frequency, PageRank\nscore) can be used as reasonable baseline methods to detect homes, we show that combining features appropriately using a machine learning method brings significant gain in both accuracy and coverage. We now discuss how we obtain these features from a user\u2019s hourly traces and how they capture inherent properties of home.\nCheck-in Rate As we discussed earlier, taking the location of most check-ins as home is a popular method. Throughout the paper, we refer to this method and the corresponding feature as \u201cMost Check-in\u201d. Although checkin based methods for home detection work well on GPS data (Krumm 2007), they perform much worse on Twitter data. This is because GPS devices keep recording locations every few seconds whereas the frequency of a user\u2019s geotagged tweets are low and largely vary based on the type of user. The location with most check-ins definitely is important to a user, but that does not necessarily mean it is the home.\nFor user U , we define the margin between two locations of check-ins A and B as PA \u2212 PB , where PA and PB are percentages of U \u2019s check-ins at A and B respectively. Figure 2 shows that for a user, the lower the margin between the most check-in location and the second most check-in location, the less effective is the Most Check-in feature as an accurate predictor of home. For instance, the accuracy is 70% only when this margin is 50 or higher. Figure 3 shows that only a small number of users have large margins between most check-in and second most check-in locations (e.g., only about 20% of the users have margins above 70, which means that home detection accuracy for these users using Most Check-in method is about 80%, according to Figure 2). These explain why the Most Check-in method performs poorly in fine-grained settings \u2014 for example, as\nthe grid with most check-in shrinks from 1 by 1 kilometer block to many 100 by 100 meter grids, the most check-in percentage spreads over many of these smaller grids, lowering the margin between the new most check-in location and the new second most check-in location. To circumvent this problem, we extract 3 features for each location L checkedin by a Twitter user U :\n\u2022 the percentage of check-ins of U at location L \u2022 the margin between L and those of its immediate higher\nand lower most check-in locations\nCheck-in Frequency During Late Night Intuitively, the places people check-in at late night are probably their homes. For example, (Sadilek and Kautz 2013) estimated a person\u2019s home by taking the mean of a two-dimensional Gaussian fitted to the person\u2019s check-ins between 1AM and 6AM. This method potentially alleviates the biases caused by other frequently visited places during daytime. Thus, for each location visited by a user, we take the check-in percentage of that location computed over a restricted time period of 12AM - 7AM as a feature, which we define as the late night feature of that location.\nLast Destination of a Day According to research using GPS data (Krumm 2007), the last destination of a person on a day (no later than 3AM) is most likely the home, highlighting that people\u2019s daily movements end at their homes. Based on this assumption we extract a mobility feature, which we call the last destination feature. For each location visited by a user, we count the number of times the location had been the last destination of the day, and we add this count to our feature set.\nLast Destination with Inactive Late Night Since \u201clast destination\u201d might suffer from check-ins sent from nonhome places (e.g., when the night was spent outside), we add to our feature set a variant of last destination. We only\nconsider tweets sent on the days when people were inactive during late night (12AM - 7AM). We exclude the days with active late night and, for each place visited by the user, we count the number of times the place had been the last destination in the remaining days.\nThe original check-in feature has limitations in obtaining a broader coverage in detecting homes. The above three features introduce extra human behaviour information to the simple check-in feature and help reduce this limitation.\nTemporal Features According to (Krumm 2007), the probability of being at home varies over time. For each place checked-in by a user, we compute the check-in percentages in that place at each hour of the day over the sampling period, and we add these 24 values (which sum to 100%) to our feature set. These time related features help us capture the property of home in terms of temporal patterns.\nSpatial Features Home is a crucial start/end point of many of our movements. Thus, for each place we add 2 more features \u2014 weighted PageRank (Xing and Ghorbani 2004) and Reversed PageRank scores \u2014 to model how importantly a place behaves as an origin and a destination. To apply PageRank, we first transfer a Twitter user\u2019s trace into a directed graph called the movement graph, in which the vertices are the locations visited by the user and a directed edge from vertex Li to Lj represents that location Lj is visited directly from Li. To quantify the certainty and importance of transitions between locations, we assign a weight to each edge. The weight should be proportional to the number of times a transition appears in the user\u2019s trace, and inversely proportional to the number of idle hours during the transition. Thus, assuming that T is the set of hourly traces of a user over the sampling period, the weight w(Li,Lj) is the ratio of the total number of transitions from Li to Lj in T to the total number of idle hours during all these transitions.\nAfter constructing a user\u2019s movement graph, we apply PageRank to calculate, for each visited location, the importance of that location as a destination. To study the importance of that location as an origin, we calculate the Reversed PageRank score by reversing each edge direction in the movement graph (edge weights remain unchanged), and then applying weighted PageRank. The PageRank and Reversed PageRank scores describe the spatial characteristics of movements."}, {"heading": "SVM Training and Home Location Evaluation", "text": "Training We trained a linear SVM classifier using all these features to capture important feature combinations that better distinguish homes. Each training datapoint is a tweet identified uniquely by user ID and location ID, labeled \u201chome\u201d or \u201cnot home\u201d, having 32 feature values calculated from the user\u2019s hourly traces. For each Twitter user, the classifier outputs a score for all the places the user checked-in from. If the place with the highest score exceeds a threshold, it is marked as the user\u2019s home. Otherwise, the user\u2019s home is marked \u201cunknown\u201d, which decreases our home detection coverage. Table 6 shows the most significant SVM features.\nAccuracy vs. Coverage To guarantee the practicality of our home detection method, we need to balance granularity and coverage. Because of the natural trade-off between granularity and detection accuracy, we fix the granularity to 100 by 100 meter grid and explore the relationship between accuracy and coverage. The accuracy can be adjusted by varying the threshold, which also affects coverage.\nFigure 4 shows how our methods compare with three other single-feature based methods in terms of accuracy and coverage. The tuning parameter for PageRank (and Reversed PageRank) scores was the extent to which the highest PageRank Score was larger than the second highest one, and for Most Check-ins it was the check-ins count. Homes were not predicted using Most Check-ins when the most check-in count was less than 3. At every accuracy level, our method covers more homes than other methods, suggesting that a combined model significantly increases coverage over single-feature based models. Particularly, when we set the accuracy of each method to 70% (which we think is acceptable for urban computing), our classifier obtains 71% and\n76% coverage in NYC and Bay Area respectively, significantly higher than those achieved using individual features.\nGranularity Since we performed home detection to 100 by 100 meter grids, the resolution of this grid-based method is around 70 meters ( \u221a 2 \u2217 100/2 \u2248 70 m). We explore how resolution affects our method\u2019s accuracy by setting coverage at 80% and varying the resolution from 100 meters to 1000 meters. Figure 5 shows that increasing the resolution increase the accuracy although the rate of increase of accuracy slows down and peaks at around 80%. Compared to previous work (Pontes et al. 2012a), our method provides higher resolution with similar accuracy ( 80%)."}, {"heading": "Analysis of Alcohol Consumption via Twitter", "text": "In this section, we discuss the results obtained by applying our SVMs on geo-tagged tweets from New York City (dataset range: 11/19/2012 - 03/31/2013) and from Monroe County in upstate New York (dataset range: 07/03/2014 - 04/27/2015). We specifically chose these datasets to study alcohol consumption in urban (NYC) vs suburban (Monroe) settings. We analyze drinking at home vs. away from home, and we investigate the relationship between the density of tweets sent from different regions while intoxicated and the density of alcohol outlets in those regions. The following terms will be used throughout this section:\n\u2022 drinking-mention: SVM-1 predicts \u201cyes\u201d \u2022 user-drinking: SVM-2 predicts \u201cyes\u201d \u2022 user-drinking-now: SVM-3 predicts \u201cyes\u201d\nWe ran the set of NYC and Monroe tweets in the order shown in Figure 1. The results in Table 7 show that for each drinking-related question, NYC has a higher proportion of tweets marked positive compared to the corresponding proportion in Monroe County. One possible explanation is that a crowded city such as NYC with highly dense alcohol outlets and many people socializing is likely to have a higher rate of drinking happening at a time compared to a suburban\narea such as Monroe county with low population and alcohol outlet density.\nFigure 6 shows the zoomed geographic distributions3 of user-drinking-now tweets via normalized heat maps. These maps were constructed by splitting the geographic area for each dataset into 100 by 100 meter grids, then computing the proportion of tweets in each grid that were user-drinkingnow (excluding grids that had less than 5 user-drinking-now tweets), and using these values as the degree of \u201cheat\u201d. That is, the grids with \u201cmore heat\u201d are those where the proportion of in-the-moment drinking tweets compared to the total geotagged tweets are much higher. We believe that such grids are regions of unusual drinking activities.\nWe also computed the alcohol outlet densities4 for the grids and then calculated the correlation between the alcohol outlet density and the density of user-drinking-now tweets. As Table 7 shows, the density of user-drinking-now tweets in both our datasets exhibit positive correlations with alcohol outlet density, with p-values less than 1%. Although correlation does not necessarily imply causation, these results agree with several prior work (Campbell et al. 2009; Sparks, Jernigan, and Mosher 2011; Weitzman et al. 2003; Scribner et al. 2008; Kypri et al. 2008; Chen, Grube, and Gruenewald 2010) which claim that alcohol outlet density influences drinking."}, {"heading": "Location-based Analysis", "text": "The ability to detect homes and locations where userdrinking-now tweets are generated enables us to compare drinking going on at home vs. not at home. For this purpose, we only used homes predicted with at least 90% accuracy which resulted in some loss of coverage (see Figure 4). We filtered all Twitter users with homes in our datasets and extracted all the user-drinking-now tweets posted by these users. For these tweets, we plotted the histogram of distance from home, shown in Figure 7. We see that NYC has a larger proportion of user-drinking-now tweets posted from home (within 100 meters from home) whereas in Monroe County a higher proportion of these tweets generated at driving distance (more than 1000 meters from home)."}, {"heading": "Discussion and Future Work", "text": "We proposed a machine learning based model for detecting latent activities and user states via Twitter to such fine details\n3obtained using CartoDB \u2014 http://cartodb.com/ 4obtained from NYS LAMP \u2014 lamp.sla.ny.gov/\nthat have not been distinguished yet. The model not only distinguishes people discussing an activity vs. discussing themselves performing the activity, but also determines whether they are performing it at-the-moment vs. past/future. We showed the strength of our model by applying it to the detection of alcohol consumption as an example application. Coupled with our other contribution of home location prediction, the model allows us to study Twitter users\u2019 drinking behavior from several community or ecological viewpoints built from the fine-grained location information extracted.\nModels that permit the fine-grained study of alcohol consumption in social media can reveal important real-time information about users and the influences they have on each other. We can begin to evaluate the merits of these data for public health research. Such analyses can teach us who is and isn\u2019t referencing alcohol on Twitter, and in what settings, to evaluate the degree of self-reporting biases, and also help to create a tool for improving a community\u2019s health, given social networks can become a resource to spread positive health behaviour. For instance, the peer social network \u201cAlcoholics Anonymous\u201d5 is designed to develop social network connections to encourage abstinence among the members and establish helpful ties.\n5http://www.aa.org/\nAlthough we apply home localization to describe a geographical community portrait of drinking referencing patterns among its social media users, since people spend a large portion of their time at home, our model enables a wide range of applications that were previously impractical. For instance, we can analyze human mobility patterns; we can study the relationship between demographics, neighborhood structure and health conditions in different zip codes, thus understanding many aspects of urban life and environments. Research in these areas and alcohol consumption is mainly based on surveys and census, which are costly and often incur a delay that hamper real-time analysis and response. Our results demonstrate that tweets can provide powerful and fine-grained cues of activities going on in cities.\nWhile Twitter use is ubiquitous, its users are not a representative sample of the general population; it is known to include more young and minority users (Smith 2011). Bias, however, is a problem in any sampling method. For example, surveys under-represent the segment of the population that is unwilling to respond to surveys, such as undocumented immigrants. Statistics estimated from Twitter (or any other source) can be adjusted to account for known biases by weighting data appropriately. While addressing Twitter\u2019s bias is beyond the scope of this paper, our methods can permit further work in this area by locating users in communities with fine-grained detail, meaning more fine-grained demographic data becomes available for linkage. We also note that the average sampling rate of US Census in each state is about 3% (U.S. Census Bureau 2011), which is similar to the percentage of users we covered out of all the Twitter users.\nOur future work will perform a comprehensive study of alcohol consumption in social media around features such as user demographics, settings people go to drink-and-tweet (e.g., friends\u2019 house, stadium, park), etc. We can explore the social network of drinkers to find out how social interactions and peer pressure in social media influence the tendency to reference drinking. Another interesting study is to compare the rate of in-flow and out-flow of drinkers in adjacent neighborhoods. All these analyses will help us understand\nthe merits of these methods for analyzing drinking behavior, via social media, at a large-scale with very little cost, which can lead to new ways of reducing alcohol consumption, a global public health concern. Finally, our models are broadly applicable to various latent activities and make way for future work in many other domains."}, {"heading": "Acknowledgements", "text": "Research reported in this publication was supported by the National Institute of General Medical Sciences of the National Institutes of Health under award number R01GM108337, the National Science Foundation under Grant No. 1319378 and the Intel ISTCPC. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH and the NSF. The authors thank members of the Big Data Docents, our community collaborative research board, for their guidance in this scientific work."}], "references": [{"title": "Twitter improves seasonal influenza prediction", "author": ["Achrekar"], "venue": "Fifth Annual International Conference on Health Informatics", "citeRegEx": "Achrekar,? \\Q2012\\E", "shortCiteRegEx": "Achrekar", "year": 2012}, {"title": "D", "author": ["M.M. Ali", "Dwyer"], "venue": "S.", "citeRegEx": "Ali and Dwyer 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Towards understanding global spread of disease from everyday interpersonal interactions", "author": ["Sadilek Brennan", "S. Kautz 2013] Brennan", "A. Sadilek", "H. Kautz"], "venue": "In Twenty-Third International Conference on Artificial Intelligence (IJCAI)", "citeRegEx": "Brennan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Brennan et al\\.", "year": 2013}, {"title": "A", "author": ["H.R. Britt", "B.P. Carlin", "T.L. Toomey", "Wagenaar"], "venue": "C.", "citeRegEx": "Britt et al. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "and Dredze", "author": ["D.A. Broniatowski"], "venue": "M.", "citeRegEx": "Broniatowski and Dredze 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "L", "author": ["J.S. Brownstein", "B.S. Freifeld", "Madoff"], "venue": "C.", "citeRegEx": "Brownstein. Freifeld. and Madoff 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "C", "author": ["Burges"], "venue": "J.", "citeRegEx": "Burges 1998", "shortCiteRegEx": null, "year": 1998}, {"title": "J", "author": ["C.A. Campbell", "R.A. Hahn", "R. Elder", "R. Brewer", "S. Chattopadhyay", "J. Fielding", "T.S. Naimi", "T. Toomey", "B. Lawrence", "Middleton"], "venue": "C.; et al.", "citeRegEx": "Campbell et al. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "2004", "author": ["Centers for Disease Control", "Prevention", "others"], "venue": "Alcohol-attributable deaths and years of potential life lost\u2013united states,", "citeRegEx": "Centers for Disease Control and Prevention and others 2004", "shortCiteRegEx": null, "year": 2001}, {"title": "P", "author": ["M.-J. Chen", "J.W. Grube", "Gruenewald"], "venue": "J.", "citeRegEx": "Chen. Grube. and Gruenewald 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "You are where you tweet: a content-based approach to geo-locating twitter users", "author": ["Caverlee Cheng", "Z. Lee 2010] Cheng", "J. Caverlee", "K. Lee"], "venue": "In Proceedings of the 19th ACM International Conference on Information and Knowledge Management,", "citeRegEx": "Cheng et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cheng et al\\.", "year": 2010}, {"title": "S", "author": ["Cho, E.", "Myers"], "venue": "A.; and Leskovec, J.", "citeRegEx": "Cho. Myers. and Leskovec 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Predicting depression via social media", "author": ["De Choudhury"], "venue": "AAAI Conference on Weblogs and Social Media", "citeRegEx": "Choudhury,? \\Q2013\\E", "shortCiteRegEx": "Choudhury", "year": 2013}, {"title": "and Culotta", "author": ["V.L. Dos Reis"], "venue": "A.", "citeRegEx": "Dos Reis and Culotta 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "M", "author": ["K.G. Egan", "Moreno"], "venue": "A.", "citeRegEx": "Egan and Moreno 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "and Macy", "author": ["S. Golder"], "venue": "M.", "citeRegEx": "Golder and Macy 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Enhancing security and privacy in traffic-monitoring systems", "author": ["Hoh"], "venue": "Pervasive Computing,", "citeRegEx": "Hoh,? \\Q2006\\E", "shortCiteRegEx": "Hoh", "year": 2006}, {"title": "P", "author": ["J. Holmes", "Y. Guo", "R. Maheswaran", "J. Nicholls", "Meier"], "venue": "S.; and Brennan, A.", "citeRegEx": "Holmes et al. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards tracking and analysing regional alcohol consumption patterns in the uk through the use of social media", "author": ["Rowe Kershaw", "D. Stacey 2014] Kershaw", "M. Rowe", "P. Stacey"], "venue": "In Proceedings of the 2014 ACM conference on Web science,", "citeRegEx": "Kershaw et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kershaw et al\\.", "year": 2014}, {"title": "and Sahami", "author": ["D. Koller"], "venue": "M.", "citeRegEx": "Koller and Sahami 1997", "shortCiteRegEx": null, "year": 1997}, {"title": "and Rouhana", "author": ["J. Krumm"], "venue": "D.", "citeRegEx": "Krumm and Rouhana 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Why do young people drink? a review of drinking motives. Clinical psychology review 25(7):841\u2013861", "author": ["Kuntsche"], "venue": null, "citeRegEx": "Kuntsche,? \\Q2005\\E", "shortCiteRegEx": "Kuntsche", "year": 2005}, {"title": "G", "author": ["K. Kypri", "M.L. Bell", "Hay"], "venue": "C.; and Baxter, J.", "citeRegEx": "Kypri et al. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "M", "author": ["Lamb, A.", "Paul"], "venue": "J.; and Dredze, M.", "citeRegEx": "Lamb. Paul. and Dredze 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "and Chikritzhs", "author": ["W. Liang"], "venue": "T.", "citeRegEx": "Liang and Chikritzhs 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Z", "author": ["M. Lin", "W.-J. Hsu", "Lee"], "venue": "Q.", "citeRegEx": "Lin. Hsu. and Lee 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "M", "author": ["D.M. Litt", "Stock"], "venue": "L.", "citeRegEx": "Litt and Stock 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Alcohol outlet density and assault: a spatial analysis", "author": ["M. Livingston 2008a] Livingston"], "venue": "Addiction", "citeRegEx": "Livingston,? \\Q2008\\E", "shortCiteRegEx": "Livingston", "year": 2008}, {"title": "A longitudinal analysis of alcohol outlet density and assault. Alcoholism: Clinical and Experimental Research 32(6):1074\u20131079", "author": ["M. Livingston 2008b] Livingston"], "venue": null, "citeRegEx": "Livingston,? \\Q2008\\E", "shortCiteRegEx": "Livingston", "year": 2008}, {"title": "Where is this tweet from? inferring home locations of twitter", "author": ["Nichols Mahmud", "J. Drews 2012] Mahmud", "J. Nichols", "C. Drews"], "venue": null, "citeRegEx": "Mahmud et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mahmud et al\\.", "year": 2012}, {"title": "D", "author": ["M.A. Moreno", "M.R. Parks", "F.J. Zimmerman", "T.E. Brito", "Christakis"], "venue": "A.", "citeRegEx": "Moreno et al. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "J", "author": ["T.S. Naimi", "R.D. Brewer", "A. Mokdad", "C. Denny", "M.K. Serdula", "Marks"], "venue": "S.", "citeRegEx": "Naimi et al. 2003", "shortCiteRegEx": null, "year": 2003}, {"title": "T", "author": ["P. Nambisan", "Z. Luo", "A. Kapoor", "Patrick"], "venue": "B.; Cisler, R.; et al.", "citeRegEx": "Nambisan et al. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "and Dredze", "author": ["M.J. Paul"], "venue": "M.", "citeRegEx": "Paul and Dredze 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "L", "author": ["L.D. Polonec", "A.M. Major", "Atwood"], "venue": "E.", "citeRegEx": "Polonec. Major. and Atwood 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "Beware of what you share: Inferring home location in social networks", "author": ["Pontes"], "venue": "In Data Mining Workshops (ICDMW),", "citeRegEx": "Pontes,? \\Q2012\\E", "shortCiteRegEx": "Pontes", "year": 2012}, {"title": "We know where you live: Privacy characterization of foursquare behavior", "author": ["Pontes"], "venue": "In UbiComp,", "citeRegEx": "Pontes,? \\Q2012\\E", "shortCiteRegEx": "Pontes", "year": 2012}, {"title": "N", "author": ["J.N. Rosenquist", "J. Murabito", "J.H. Fowler", "Christakis"], "venue": "A.", "citeRegEx": "Rosenquist et al. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "and Kautz", "author": ["A. Sadilek"], "venue": "H.", "citeRegEx": "Sadilek and Kautz 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "and Krumm", "author": ["A. Sadilek"], "venue": "J.", "citeRegEx": "Sadilek and Krumm 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "nemesis: Which restaurants should you avoid today", "author": ["Sadilek"], "venue": "In First AAAI Conference on Human Computation and Crowdsourcing", "citeRegEx": "Sadilek,? \\Q2013\\E", "shortCiteRegEx": "Sadilek", "year": 2013}, {"title": "Modeling spread of disease from social interactions", "author": ["Kautz Sadilek", "A. Silenzio 2012a] Sadilek", "H.A. Kautz", "V. Silenzio"], "venue": null, "citeRegEx": "Sadilek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sadilek et al\\.", "year": 2012}, {"title": "Predicting disease transmission from geotagged micro-blog data", "author": ["Kautz Sadilek", "A. Silenzio 2012b] Sadilek", "H.A. Kautz", "V. Silenzio"], "venue": null, "citeRegEx": "Sadilek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sadilek et al\\.", "year": 2012}, {"title": "Socio-spatial properties of online locationbased social networks. ICWSM 11:329\u2013336", "author": ["Scellato"], "venue": null, "citeRegEx": "Scellato,? \\Q2011\\E", "shortCiteRegEx": "Scellato", "year": 2011}, {"title": "Exploiting place features in link prediction on location-based social networks", "author": ["Noulas Scellato", "S. Mascolo 2011] Scellato", "A. Noulas", "C. Mascolo"], "venue": "In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Scellato et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Scellato et al\\.", "year": 2011}, {"title": "D", "author": ["M. Schonlau", "R. Scribner", "T.A. Farley", "K.P. Theall", "R.N. Bluthenthal", "M. Scott", "Cohen"], "venue": "A.", "citeRegEx": "Schonlau et al. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "S", "author": ["R. Scribner", "D. Cohen", "S. Kaplan", "Allen"], "venue": "H.", "citeRegEx": "Scribner et al. 1999", "shortCiteRegEx": null, "year": 1999}, {"title": "L", "author": ["R. Scribner", "K. Mason", "K. Theall", "N. Simonsen", "S.K. Schneider", "Towvim"], "venue": "G.; and DeJong, W.", "citeRegEx": "Scribner et al. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "J", "author": ["R.A. Scribner", "D.P. MacKinnon", "Dwyer"], "venue": "H.", "citeRegEx": "Scribner. MacKinnon. and Dwyer 1994", "shortCiteRegEx": null, "year": 1994}, {"title": "A refined limit on the predictability of human mobility", "author": ["Smith"], "venue": "In Pervasive Computing,", "citeRegEx": "Smith,? \\Q2014\\E", "shortCiteRegEx": "Smith", "year": 2014}, {"title": "A", "author": ["Smith"], "venue": "2011. Twitter update", "citeRegEx": "Smith 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Limits of predictability in human mobility", "author": ["Song"], "venue": "Science", "citeRegEx": "Song,? \\Q2010\\E", "shortCiteRegEx": "Song", "year": 2010}, {"title": "J", "author": ["M. Sparks", "D.H. Jernigan", "Mosher"], "venue": "F.", "citeRegEx": "Sparks. Jernigan. and Mosher 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Characterizing smoking and drinking abstinence from social media", "author": ["M. De Choudhury", "D.H. Chau"], "venue": "In Proceedings of the 26th ACM Conference on Hypertext", "citeRegEx": "A. et al\\.,? \\Q2015\\E", "shortCiteRegEx": "A. et al\\.", "year": 2015}, {"title": "Recognizing depression from twitter activity", "author": ["Tsugawa"], "venue": "In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems,", "citeRegEx": "Tsugawa,? \\Q2015\\E", "shortCiteRegEx": "Tsugawa", "year": 2015}, {"title": "Structural diversity in social contagion", "author": ["Ugander"], "venue": "Proceedings of the National Academy of Sciences", "citeRegEx": "Ugander,? \\Q2012\\E", "shortCiteRegEx": "Ugander", "year": 2012}, {"title": "M", "author": ["E.R. Weitzman", "A. Folkman", "Folkman"], "venue": "K. L.; and Wechsler, H.", "citeRegEx": "Weitzman et al. 2003", "shortCiteRegEx": null, "year": 2003}, {"title": "and Horvitz", "author": ["R. White"], "venue": "E.", "citeRegEx": "White and Horvitz 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "A", "author": ["W. Xing", "Ghorbani"], "venue": "2004. Weighted pagerank algorithm. In Communication Networks and Services Research,", "citeRegEx": "Xing and Ghorbani 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "M", "author": ["Young"], "venue": "M.", "citeRegEx": "Young 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "D", "author": ["Zhu, L.", "Gorman"], "venue": "M.; and Horel, S.", "citeRegEx": "Zhu. Gorman. and Horel 2004", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [], "year": 2016, "abstractText": "Nearly all previous work on geo-locating latent states and activities from social media confounds general discussions about activities, self-reports of users participating in those activities at times in the past or future, and self-reports made at the immediate time and place the activity occurs. Activities, such as alcohol consumption, may occur at different places and types of places, and it is important not only to detect the local regions where these activities occur, but also to analyze the degree of participation in them by local residents. In this paper, we develop new machine learning based methods for fine-grained localization of activities and home locations from Twitter data. We apply these methods to discover and compare alcohol consumption patterns in a large urban area, New York City, and a more suburban and rural area, Monroe County. We find positive correlations between the rate of alcohol consumption reported among a community\u2019s Twitter users and the density of alcohol outlets, demonstrating that the degree of correlation varies significantly between urban and suburban areas. While our experiments are focused on alcohol use, our methods for locating homes and distinguishing temporally-specific self-reports are applicable to a broad range of behaviors and latent states.", "creator": "LaTeX with hyperref package"}}}