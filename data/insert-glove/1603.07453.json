{"id": "1603.07453", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Mar-2016", "title": "An Expressive Probabilistic Temporal Logic", "abstract": "poole This paper trawler argues ophthalmoscope that masher a combined abdulwahid treatment 59.56 of kadhafi probabilities, time skywalks and 10:25 actions is xenograft essential for an hrw appropriate domain logical account stepping-stone of cyst the notion 200-megawatt of probability; and, proto-slavic based byakuya on godwit this lifeblood intuition, describes an swedish-language expressive probabilistic inducements temporal viacheslav logic berryessa for bufete reasoning about actions praphan with abendzeitung uncertain slaidburn outcomes. pegg The logic insignificance is modal and six-pointed higher - basketballers order: channelsurfer modalities ucpb annotated natanyahu by actions are udo used to tejo express pasturing possibility lovegren and necessity of jenson propositions greinke in the next states resulting from the actions, and 27-yarder a higher - order function 9,250 is needed to unsortable express the gaddang probability transcriptionally operator. edgett The yanzhi proposed logic is seger shown sceptical to be an addy adequate cooperators extension wuthnow of kallan classical mathematical probability cofiroute theory, and mucianus its mesoscale expressiveness is jacobson illustrated analytical through dobrinja the pigtails formalization 388,000 of the Monty Hall problem.", "histories": [["v1", "Thu, 24 Mar 2016 07:00:33 GMT  (40kb)", "http://arxiv.org/abs/1603.07453v1", null], ["v2", "Sun, 8 Oct 2017 02:02:49 GMT  (40kb)", "http://arxiv.org/abs/1603.07453v2", null]], "reviews": [], "SUBJECTS": "cs.LO cs.AI", "authors": ["bruno woltzenlogel paleo"], "accepted": false, "id": "1603.07453"}, "pdf": {"name": "1603.07453.pdf", "metadata": {"source": "CRF", "title": "An Expressive Probabilistic Temporal Logic", "authors": ["Bruno Woltzenlogel Paleo"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n60 3.\n07 45\n3v 1\n[ cs\n.L O\n] 2\n4 M\nThis paper argues that a combined treatment of probabilities, time and actions is essential for an appropriate logical account of the notion of probability; and, based on this intuition, describes an expressive probabilistic temporal logic for reasoning about actions with uncertain outcomes. The logic is modal and higher-order : modalities annotated by actions are used to express possibility and necessity of propositions in the next states resulting from the actions, and a higher-order function is needed to express the probability operator. The proposed logic is shown to be an adequate extension of classical mathematical probability theory, and its expressiveness is illustrated through the formalization of the Monty Hall problem.\nKeywords: Higher-Order Modal Logics, Probability Theory"}, {"heading": "1 Introduction", "text": "In order to reason about probabilistic knowledge, we must reason about time and actions as well. When we say, for example, that \u201cthe probability of \u2018heads\u2019 after a coin toss is 50% and that of \u2018tails\u2019 is 50%\u201d, we implicitly assume that there is an action (in this example, tossing a coin) which can bring the world to different states in the next moment in time. The uncertainty lies in the state transition: the world may end up in a state where the coin shows heads or in a state where it shows tails.\nDespite the evident dependence of our informal notion of probability on the notions of action and time, the formal mathematical languages that we use to talk about probabilities rarely support mentioning action and time explicitly. Kolmogorov\u2019s probability theory, for example, merely defines probability as the measure function in a measure space with total measure 1 [9]. The task of modeling time-dependent actions and their possible outcomes in terms of events in a probabilistic space remains informal. While this informality is not problematic in the simplest situations (e.g. when we are interested in the possible outcomes of a single action, or when multiple actions are independent of each other), slightly more complex situations may already lead to confusion and difficulty. A famous example is the Monty Hall problem [10].\nAnother inconvenience of dealing with probabilities just in terms of a measure space is that its set-theoretic language (where events are represented as\nsubsets of the sample space) is rather limited. There are obvious parallels between, for instance, set intersection and conjunction or set union and disjunction, which allow us to represent propositional probabilistic knowledge easily (e.g. the event of a randomly picked coin showing heads and the same coin being made of silver can be represented as the intersection of the event of showing heads with the event of being made of silver). However, it is not clear how this analogy could be extended to more expressive logics with quantifiers.\nThe main contribution of this paper, addressing the above mentioned issues, is the development of the syntax (in Section 2) and the semantics (in Section 3) of an expressive probabilistic temporal logic (PTL) for reasoning about actions with uncertain outcomes. PTL is an adequate extension of classical probability theory (as demonstrated in Section 4), and its greater expressiveness allows us to reason explicitly about event independence (as discussed in Section 5.1) and to avoid typical ambiguities of natural language discourse about probabilities (as shown in Section 5.2). This capacity of PTL to avoid ambiguities related to outcomes and events is one of its main conceptual novelties in comparison to related work (cf. Section 8). PTL\u2019s convenience and expressive power are illustrated through the formalization of the Monty Hall problem (in Section 7)."}, {"heading": "2 Syntax", "text": "The aim of PTL\u2019s language is to be sufficiently expressive to capture typical probabilistic statements, conveniently similar to natural language, and yet more precise than natural language in cases when the latter is ambiguous. Intuitively, probability is an inherently higher-order function, since it takes a proposition (representing an event) as an argument. Therefore, if a probabilistic logical language is to include a probability operator in the syntactic level, it is only natural that it should be a higher-order language. Furthermore, because thinking probabilistically involves numerical computation and reasoning about states and actions, it is convenient to have a typed language, with distinct basic types for numbers, states and actions. The types used here are mostly the well-known simple types, but a list type constructor is included as well, in order to allow the representation of temporal sequences of actions and propositions.\nDefinition 2.1 Types are freely generated from the set of basic types {\u03b2, \u03b9, \u03b7, \u00b5}, the right-associative function type constructor \u2192 and the list type constructor list. \u00b5 is the type for states, \u03b2 is the type for booleans, \u03b9 is the type for objects and \u03b7 is the type for real numbers. The set of all types is denoted T . The type of (local) propositions o is defined to be an abbreviation for \u00b5 \u2192 \u03b2 and the type of actions \u03b1 is defined to be an abbreviation for \u00b5 \u2192 list[\u00b5].\nRemark 2.2 The definition of o ensures that the truth of a proposition depends on states. The definition of \u03b1 follows the intuition that an action can be seen as a function that maps a state to a list of possible next states.\nAs shown in Definition 2.3, PTL contains, besides the usual logical symbols, also symbols for arithmetical functions and relations, the hybrid logic symbols for explicitly referring to states, list constructors and functions, and a prob-\nability operator. As modal operators (\u2737 and \u2738) implicitly bind states, they have a more fundamental role, which reminds that of the \u03bb binder. Therefore, they are treated separately in Definition 2.4.\nDefinition 2.3 For every type \u03c4 , S\u03c4 is a countably infinite set of uninterpreted symbols of type \u03c4 . The set of arithmetic function symbols SAF is the set {0\u03b7, 1\u03b7,+\u03b7\u2192\u03b7\u2192\u03b7, \u2217\u03b7\u2192\u03b7\u2192\u03b7}. The set of arithmetic relation symbols SAR is {=\u03b7\u2192\u03b7\u2192o, <\u03b7\u2192\u03b7\u2192o}. The set of propositional logical symbols SL is {\u22a4o,\u22a5o,\u2228o\u2192o\u2192o,\u2227o\u2192o\u2192o,\u2192o\u2192o\u2192o,\u2194o\u2192o\u2192o,\u00aco\u2192o}. The set of hybrid logical symbols SH is {@\u00b5\u2192o\u2192o, in\u00b5\u2192o}. The set of quantifiers SQ is \u22c3\n\u03c4\u2208T {\u2200(\u03c4\u2192o)\u2192o, \u2203(\u03c4\u2192o)\u2192o,=o\u2192o\u2192o}. The symbol nil \u03c4 has type list[\u03c4 ], ::\u03c4 has type \u03c4 \u2192 list[\u03c4 ] \u2192 list[\u03c4 ], \u2208\u03c4 has type \u03c4 \u2192 list[\u03c4 ] \u2192 o and the length operator |.|\u03c4 has type list[\u03c4 ] \u2192 \u00b5. The probability operator P has type list[\u03b1] \u2192 o \u2192 \u03b7. The set of all symbols S is defined as S\u03c4 \u222a SAF \u222a SAR \u222a SL \u222a SH \u222a SQ \u222a \u22c3 \u03c4\u2208T {nil \u03c4 , ::\u03c4 , |.|\u03c4 ,\u2208\u03c4} \u222a {P}.\nExpressions are constructed as in the lambda calculus, using the symbols from S, application, abstraction and modalities.\nDefinition 2.4 Expressions are constructed according to the following rules:\n\u2022 if s\u03c4 \u2208 S, then s\u03c4 is an expression of type \u03c4 . \u2022 if t1 is an expression of type \u03c4 \u2192 \u03c4 \u2032 and t2 is an expression of type \u03c4 , then\n(t1 t2) is an expression of type \u03c4 \u2032.\n\u2022 if x\u03c4 \u2208 S\u03c4 and t is an expression of type \u03c4 \u2032, then \u03bbx\u03c4 .t is an expression of\ntype \u03c4 \u2192 \u03c4 \u2032.\n\u2022 if \u03d5 is an expression of type o, p is an expression of type \u03b7 and a is an expression of type \u03b1, then \u2738pa\u03d5 are \u2737a\u03d5 expressions of type o.\nFormulas are expressions of type o. Actions are expressions of type \u03b1. The set of expressions of type \u03c4 is denoted E\u03c4 . L = \u22c3 \u03c4\u2208T E\u03c4 .\nRemark 2.5 Types are omitted when they can be inferred from the context. The usual parenthesis conventions are followed. Numerals are occasionally written in decimal notation. Infix notation is employed as usual for logical connectives, arithmetical functions and relations and the list constructor ::. Binding notation is used for quantifiers. Additionally, the following notation conventions and abbreviations are used:\n\u2022 \u2738a\u03d5 \u2261 \u2203x\u03b7.\u2738 x a\u03d5\n\u2022 Pl(\u03d5) \u2261 ((P l) \u03d5)\n\u2022 \u2200x : G. H(x) \u2261 \u2200x. G(x) \u2192 H(x)\n\u2022 \u2203x : G. H(x) \u2261 \u2203x. G(x) \u2227H(x)\n\u2022 \u2200x\u03c4 \u2208 \u2113list[\u03c4 ]. H(x) \u2261 \u2200x. (x \u2208 \u2113) \u2192 H(x)\n\u2022 \u2203x\u03c4 \u2208 \u2113list[\u03c4 ]. H(x) \u2261 \u2203x. (x \u2208 \u2113) \u2227H(x)\n\u2022 Pa::l(\u03d5 :: L) \u2261 Pa::l(\u03d5) \u2227 Pl(L) (with Pnil(nil) \u2261 \u22a4)\nProbabilities appear in the logical language in two ways: firstly, as annotations on the diamond modal operator, in order to indicate how probable the corresponding state transition is; and secondly, through the higher-order probability function P , which takes a list of actions and a proposition as arguments and returns the probability that the proposition will hold after the execution of the listed actions.\nExample 2.6 The following are some simple examples of probabilistic statements and their corresponding formalizations in PTL:\n(i) Tossing a coin has a transition with probability 0.5 to a state where the coin shows heads: \u2200x : Coin .\u27380.5toss(x)heads(x)\n(ii) The probability of a coin showing heads after it is tossed is 0.5:\n\u2200x : Coin .Ptoss(x)::nil(heads(x)) = 0.5\n(iii) The probability of a coin showing heads twice after it is tossed twice is less than 0.5: \u2200x : Coin .Pt(x)::t(x)::nil(h(x) :: h(x) :: nil) < 0.5 , where t = toss and h = heads .\n(iv) After a coin is tossed it is necessarily either heads or tails:\n\u2200x : Coin .\u2737toss(x)(heads(x) \u2228 tails(x))\n(v) After a coin is tossed it is possibly tails: \u2200x : Coin .\u2738toss(x)(tails(x))"}, {"heading": "3 Semantics", "text": "For each type \u03c4 , we need a domain D\u03c4 of elements on which expressions of type \u03c4 are interpreted. For numerical expressions, we assume the domain to be a real closed field. For booleans, we assume the set with the usual two truth values. For function types, we require all functions to be present in the type\u2019s domain. This effectively results in a standard higher-order semantics. For Henkin semantics, it would suffice to drop this last condition.\nDefinition 3.1 A domain D\u03c4 for a type \u03c4 is a non-empty set such that D\u03c4 \u2032\u2192\u03c4 is the set of all functions from D\u03c4 \u2032 to D\u03c4 (for every \u03c4\n\u2032 and \u03c4), Do = {T,F}, D\u03b7 = R and Dlist[\u03c4 ] is the set of all lists of elements from D\u03c4 .\nAs in the most common modal logics [3], we use frames as the foundation for the modal aspects of the semantics. A frame is essentially a set of states and a relation for the transitions between states. What is different here is that transitions are labeled by actions and by probabilities, and the transition relation and actions must be mutually consistent.\nDefinition 3.2 A probabilistic labeled frame is a triple (W,R, P ) such that W is a non-empty set of states, R \u2286 W \u00d7W \u00d7D\u03b1 satisfying the condition that if (w,w\u2032, \u2113) \u2208 R then (w,w\u2032\u2032, \u2113) \u2208 R for every w\u2032\u2032 \u2208 \u2113(w), and P : R \u2192 [0, 1] is a probability function satisfying the condition that for all w \u2208 W and for all\n\u2113 \u2208 D\u03b1 such that there exists w \u2032 \u2208 W with (w,w\u2032, \u2113) \u2208 R,\n\u2211\nw\u2032 | (w,w\u2032,\u2113)\u2208R\nP ((w,w\u2032, \u2113)) = 1\nRemark 3.3 The relationR in definition 3.2 may be cyclic. This is convenient, for instance, when specifying Markov chains.\nA model extends a frame with an interpretation function that assigns denotations to expressions. The denotation of an expression may generally vary with the state. In such cases, we say that the interpretation is flexible; otherwise, it is rigid [6]. In the examples considered in this paper, boolean expressions and probabilistic expressions are always flexibly interpreted, whereas other expressions are always rigidly interpreted.\nDefinition 3.4 A model is a tuple (W,R, P, {D\u03c4}\u03c4\u2208T , I) where (W,R, P ) is a probabilistic labelled frame, {D\u03c4}\u03c4\u2208T is a domain, W = D\u00b5 and I is an interpretation function that maps states and expressions of any type \u03c4 to elements in D\u03c4 . It is assumed that any interpretation I maps arithmetic symbols, list constructors and functions, and logical constants to their usual fixed denotations. Therefore (as usual, non-exhaustively):\n\u2022 Iw(A \u2227B) = T iff Iw(A) = T and Iw(B) = T\n\u2022 Iw(A \u2228B) = T iff Iw(A) = T or Iw(B) = T\n\u2022 Iw(A \u2192 B) = T iff Iw(A) = F or Iw(B) = T\n\u2022 Iw(\u00acA) = T iff Iw(A) = F\n\u2022 Iw(\u2200x\u03c4 .\u03d5) = T iff Iw[x 7\u2192 e](\u03d5) = T for every e \u2208 D\u03c4\n\u2022 Iw(\u2203x\u03c4 .\u03d5) = T iff Iw[x 7\u2192 e](\u03d5) = T for some e \u2208 D\u03c4\n\u2022 Iw((t1 t2)) = (Iw(t1) Iw(t2))\n\u2022 Iw(\u03bbx\u03c4 .t) is the function taking an element e \u2208 D\u03c4 and returning Iw[x 7\u2192 e](t).\n\u2022 Iw(in(s)) = T iff w = Iw(s)\n\u2022 Iw(@s\u03d5) = T iff IIw(s)(\u03d5) = T\nwhere Iw[x 7\u2192 e](x) = e and Iw[x 7\u2192 e](t) = I[t] for any t distinct from x.\nFurthermore, and most importantly, the interpretations of expressions formed with modal and probabilistic operators are defined as follows:\n\u2022 Iw(\u2737a\u03d5) = T iff Iw\u2032(\u03d5) = T for every w\u2032 such that (w,w\u2032, Iw(a)) \u2208 R\n\u2022 Iw(\u2738 p a\u03d5) = T iff P ((w,w \u2032, Iw(a))) = Iw(p) and Iw\u2032(\u03d5) = T for some w\u2032 such that (w,w\u2032, Iw(a)) \u2208 R\n\u2022 Iw(Pnil(\u03d5)) =\n{\n1, if Iw(\u03d5) = T\n0, if Iw(\u03d5) = F\n\u2022 Iw(Pa::l(\u03d5)) = \u2211\nw\u2032|(w,w\u2032 ,Iw(a))\u2208R\nP ((w,w\u2032, Iw(a))).Iw\u2032(Pl(\u03d5))\nIn the probabilistic logic PTL, validity and satisfaction of a formula by a model are standard non-probabilistic notions, as defined below. The logic handles probabilities explicitly in its language; not at the semantic level.\nDefinition 3.5 A formula \u03d5 is satisfied in a model M \u2261 (W,R, P, {D\u03c4}\u03c4\u2208T , I) in a state w, denoted M,w \u03d5 iff Iw(\u03d5) = T. A formula \u03d5 is globally satisfied in a model M , denoted M \u03d5 iff M,w \u03d5 for all w \u2208 W . A formula \u03d5 is valid, denoted \u03d5 iffM \u03d5 for every model M . A set of formulas T entails a formula \u03d5, denoted T \u03d5, iff M \u03d5 for every model M such that M \u2227\nG\u2208T G."}, {"heading": "4 Adequacy", "text": "This section shows how the usual mathematical presentation of probability theory, as recalled in Definition 4.4, can be considered a special case of the probabilistic logic presented here. This is done by showing (in Theorem 4.5) how to translate probability spaces into models and the usual set-theoretic language for probabilistic events into PTL\u2019s language.\nDefinition 4.1 Set expressions over a set \u2126 are expressions freely generated from singleton subsets of \u2126 and operators for complementation ( ), union (\u222a) and intersection (\u2229).\nRemark 4.2 As usual, by abuse of notation, set expressions and the sets they denote are not explicitly distinguished.\nExample 4.3 If \u2126 = {w1, w2} then the following are examples of set expressions: {w1}, {w2}, {w2} (denoting the set {w1}), {w1} \u222a {w2} (denoting the set {w1, w2}), {w1} \u2229 {w2} (denoting the empty set), . . .\nDefinition 4.4 A probability space is a triple (\u2126,\u03a3, Q) where \u2126 is the sample space (whose elements are outcomes), \u03a3 is a \u03c3-algebra on \u2126 (i.e. a collection of subsets of \u2126 (events) closed under complementation, countable union and countable intersection) and Q : \u03a3 \u2192 [0, 1] is a probability function satisfying Kolmogorov\u2019s axioms:\n(i) Q(E) \u2265 0, for all E \u2208 \u03a3\n(ii) Q(\u2126) = 1\n(iii) For any countable collection C of mutually disjoint events\nQ( \u22c3\nE\u2208C\nE) = \u2211\nE\u2208C\nQ(E)\nTheorem 4.5 For every probability space (\u2126,\u03a3, Q), there is a model M and a language translation function g from set expressions over \u2126 to formulas such that Q(E) = p iff M,w Pa(g(E)) = p, for some w and some a.\nProof. Let W be {w} \u222a \u2126. For each wk \u2208 \u2126, let Fk be a distinct atomic proposition. Let I be any interpretation such that Iwi(Fj) = T iff i = j. Let R be {(w,wk, Iw(a))|wk \u2208 \u2126}. Let the probabilistic transition function be defined such that P ((w,wk , Iw(a))) = Q({wk}). Since \u2126 = \u22c3 k{wk}, all {wk}\nare mutually disjoint and Q(\u2126) = 1, the condition (from Definition 3.2) that\n\u2211\nwk | (w,wk,Iw(a))\u2208R\nP ((w,wk, Iw(a))) = 1\nholds. Finally let M be the model (W,R, P, {D\u03c4}\u03c4\u2208T , I). The translation function g is defined recursively:\ng(E) =\n\n   \n   \nFk, if E = {wk} g(E\u2032) \u2228 g(E\u2032\u2032), if E = E\u2032 \u222aE\u2032\u2032 g(E\u2032) \u2227 g(E\u2032\u2032), if E = E\u2032 \u2229E\u2032\u2032 \u00acg(E\u2032), if E = E\u2032\nNow the fact that Q(E) = p iff M,w Pa(g(E)) = p must be proven. First notice that, by Definition 3.5, M,w Pa(g(E)) = p iff Iw(Pa(g(E)) = p), and by Definition 3.4, Iw(Pa(g(E)) = p) iff\n\u2211\nw\u2032 | (w,w\u2032,Iw(a))\u2208R\nP ((w,w\u2032, Iw(a))).Iw\u2032 (Pnil(g(E))) = p\nBy Definition 3.4 again and the definition of R, the summation above can be simplified, resulting in the following equation:\n\u2211\nw\u2032|w\u2032\u2208\u2126 and Iw\u2032 (g(E))=T}\nP ((w,w\u2032, Iw(a))) = p\nFurthermore, unfolding the definition of P , the equation above reduces to:\n\u2211\nw\u2032|w\u2032\u2208\u2126 and Iw\u2032 (g(E))=T}\nQ({w\u2032}) = p\nTherefore, it suffices to prove that the equation above holds iff Q(E) = p, or equivalently, that:\n\u2211\nw\u2032|w\u2032\u2208\u2126 and Iw\u2032 (g(E))=T}\nQ({w\u2032}) = Q(E)\nBy Kolmogorov\u2019s third axiom, Q(E) = \u2211 w\u2032\u2208E Q({w \u2032}. Hence, letting X be the following set: {x|x \u2208 \u2126 and Ix(g(E)) = T}\nA sufficient condition for the equation above to hold is that X = E. This is proven below by induction on the structure of E:\n\u2022 Base case (E = {wk}): then g(Ek) = Fk and, by definition of I, Ix(Fk) = T iff x = wk.\n\u2022 Induction cases:\n\u00b7 (E = E\u2032): then g(E) = \u00acg(E\u2032) and hence:\nX = {x|x \u2208 \u2126 and not Ix(g(E \u2032)) = T}\nLet Y = {x|x \u2208 \u2126 and Ix(g(E \u2032)) = T}\nBy induction hypothesis, Y = E\u2032. Therefore, X = \u2126 \\ Y = \u2126 \\ E\u2032 = E. \u00b7 (E = E\u2032 \u2229 E\u2032\u2032): then g(E) = g(E\u2032) \u2227 g(E\u2032\u2032) and hence:\nX = {x|x \u2208 \u2126 and Ix(g(E \u2032) \u2227 g(E\u2032\u2032)) = T}\nand so:\nX = {x|x \u2208 \u2126 and Ix(g(E \u2032)) = T and Ix(g(E \u2032\u2032)) = T}\nLet: Y = {x|x \u2208 \u2126 and Ix(g(E \u2032)) = T}\nZ = {x|x \u2208 \u2126 and Ix(g(E \u2032\u2032)) = T}\nBy induction hypothesis, Y = E\u2032 and Z = E\u2032\u2032. Therefore, X = Y \u2229 Z = E\u2032 \u2229 E\u2032\u2032 = E. \u00b7 (E = E\u2032 \u222a E\u2032\u2032): this case is analogous to the case above. \u2737\nInformally, the idea of the proof of Theorem 4.5 is to translate a probability space into a model with a distinguished initial state and a future state for each possible outcome in the space. Any set expression (specifying an event) has a corresponding logical formula. The correspondence is as expected: union corresponds to disjunction, intersection to conjunction and complementation to negation. The translation is adequate in the sense that the probability of an event in the space is equal to the probability of the corresponding formula in the model."}, {"heading": "5 Expressiveness", "text": "A corollary of Theorem 4.5 is that the probabilistic logic PTL is more expressive than classical probability theory, in two distinct informal senses. The first one is syntactical: whereas the usual language of classical probability theory (which relies on set expressions) can naturally express formulas containing propositional connectives such as negation, conjunction and disjunction (through the inverse of the translation function g defined in the proof of the theorem), there are formulas in PTL\u2019s language (e.g. formulas containing quantifiers or nested probability operators) which have no (natural) counterpart in the language of classical probability theory. The second one is semantical: the proof of Theorem 4.5 shows that probability spaces correspond to models with a very simple frame; it would be inconvenient to express models with more complex frames in terms of probability spaces, because the frame structure would have to be flattened."}, {"heading": "5.1 Independence", "text": "Shortcomings and limitations of probability spaces for knowledge representation become apparent in situations where a sequence of independent actions is performed over time. Suppose that a fair coin is tossed twice. Representing this as a probability space requires a sample space with four outcomes {h1h2, h1t2, t1h2, t1t2}. Saying that, for instance, P ({h1h2}) = P (H1 \u2229H2) = P (H1)P (H2) = 0.25 (where H1 = {h1t2, h1h2} and H2 = {h1h2, t1h2}) requires the assumption of independence for the tosses. Two events E1 and E2 are often defined to be independent if and only if P (H1 \u2229H2) = P (H1)P (H2). But this definition is epistemologically unsatisfactory. How do we actually come to know that H1 and H2 are independent? According to this definition, we must know P (H1 \u2229 H2) in advance. But that is precisely what, in practice, we do not know and would like to compute (based on our knowledge of P (H1) and P (H2))! We can easily get trapped in circular reasoning, trying to justify, for instance, our claim that P (H1 \u2229 H2) = 0.25 by saying that H1 and H2 are independent and then trying to justify that they are independent by saying that P (H1 \u2229 H2) = 0.25. Of course, we tend to escape from such cases of fallacious circular reasoning by simply assuming that the events are independent. However, the assumption is tacit. Classical probability theory provides no way to represent knowledge of the independence and any reason that we might have for justifying the assumption of independence of the events remains at an informal level, external to the representation.\nIn the PTL, on the other hand, the possibility to represent independence comes naturally and for free. For instance, when the axiom \u2200x : Coin.\u27380.5t(x).H(x) \u2227 \u2738 0.5 t(x)T (x) is assumed, it follows from the semantics of the logic that it holds in any state of the model. And since the axiom states the equal probabilities for heads and tails in a way that does not depend on anything except the action of the toss itself, it is clear that tossing a coin at a state s has no effect on tossing the coin at another state s\u2032. Therefore, the two tosses must be independent, and consequently it follows that:\n\u2200x : Coin.\u27380.5t(x).H(x) \u2227\u2738 0.5 t(x)T (x) Pt(x)::t(x)::nil(H(x) :: H(x) :: nil) = 0.25\nAlso dependence can be easily represented. For example, consider a magical coin cm that behaves as a fair coin in an initial state, but when tossed in any other state always gives the opposite result of the previous toss. This may be represented by the following axioms:\n\u2022 @s\u2738 0.5 t(cm) .H(cm) \u2227\u2738 0.5 t(cm) T (cm) \u2022 T (cm) \u2192 \u2738 1 t(cm) .H(cm) \u2022 H(cm) \u2192 \u2738 1 t(cm) .T (cm)\n\u2022 \u2737\u00acin(s) (no state is a predecessor of s)\nThe inadequacy of classical probability theory\u2019s usual definition of independence can be further illustrated in a situation where we have to randomly get an object from a bag with four objects: a black sphere, a white sphere, a black cube\nand a white cube. For simplicity, we assume tacitly that we put the object back in the bag after the action. This can be represented by the following axioms: A1: S(sb)\u2227B(sb); A2: S(sw)\u2227W (sw); A3: C(cb)\u2227B(cb); A4: C(cw)\u2227W (cw); A5: Bag = sb :: sw :: cb :: cw :: nil; and A6: \u2200x \u2208 Bag .\u2738 1/|Bag| a G(x).\nIt then follows, by the semantics, that:\nA1,A2,A3,A4,A5,A6 \u2200x \u2208 Bag .Pa(S(x) \u2227B(x)) = Pa(S(x)).Pa(B(x))\nNevertheless, we should not be willing to conclude from this result, as classical probability theory does, that the event of getting a spherical object and the event of getting a black object are independent. It is merely coincidental that Pa(S(x)\u2227B(x)) = Pa(S(x)).Pa(B(x)). If the bag had an additional black tetrahedral, for instance, the two sides of this equation would not be equal anymore. In the formalization above, it is evident that both events are correlated, because they consist of outcomes from a single action.\nA simple formal theory Tindep of (in)dependence of actions could provide the following definition for independence of an action a from an action b:\n\u2022 Independent(a, b) \u2261 (\u2200s.@s((\u2200\u03d5.\u2200p.Pa(\u03d5) = p \u2192 \u2737b(Pa(\u03d5) = p)))\nIt follows from the semantics that Tindep entails the following shortcut theorem:\n\u2227\n1\u2264i<j\u2264n\nIndependent(ai, aj) \u2192 Pa1::...::an::nil(E1 :: . . . :: En :: nil) = Pa1(E1) . . .Pan (En)\nThe notion of independence defined in Tindep is non-circular. We may, from the logical specification of a system in the PTL\u2019s language, explicitly reason about the actions of the system, conclude that some of them are mutually independent and use the general theorem above as a shortcut for computing probabilities of sequences of actions. This is arguably more satisfactory than the teleological definition of independence from classical probability theory, which depends on the very shortcut theorem that we would have liked to derive.\nIt is not an aim of this paper to discuss Tindep or other theories of independence in detail. Tindep is just a (very simple) example showing that PTL is expressive enough to allow explicit reasoning about concepts that are very relevant in a probabilistic context."}, {"heading": "5.2 Disambiguation", "text": "Informal statements about probabilities are sometimes imprecise and ambiguous. Their intended meanings are not always clear. If a person A tried to describe to a person B the random effects of an action a, her description might include a sentence such as: \u201cthe probability of \u03d5 after a is p\u201d. The most straightforward and literal logical meaning for this sentence would be Pa(\u03d5) = p. However, it is often the case that the meaning intended by A is actually \u2738pa\u03d5. B must guess, from the context of the conversation and the common knowledge, which of the two alternatives is actually meant.\nA formula such as \u2738pa\u03d5 provides fine-grained information about one particular state transition that is made possible by the action, whereas Pa(\u03d5) = p\nprovides coarse-grained aggregated information about transitions to all states where \u03d5 holds. The aggregated information is incomplete, because it doesn\u2019t say how many such states there are and it doesn\u2019t specify the transition probability to each of these states.\nThe power to disambiguate is an interesting qualitative criterium to estimate the usefulness of a formal language. The formal probabilistic logical language proposed here is expressive enough to precisely disambiguate between \u2738 and P , which are subtly but importantly different in meaning, even though they are often expressed indistinguishably in natural language. It is important to note that neither \u2738pa\u03d5 \u2192 Pa(\u03d5) = p nor Pa(\u03d5) = p \u2192 \u2738 p a\u03d5 is valid. Understanding the difference between \u2738pa\u03d5 and Pa(\u03d5) = p is crucial for a correct use of PTL. Furthermore, the difference in the meanings of \u2738 and P is essential to a semantics for probabilities that is compatible with our intuition about probabilities. Therefore, any sufficiently rich probabilistic logic should strive to distinguish between these important notions. PTL does so explicitly and syntactically.\nRemark 5.1 In natural language dialogues, B tends to cope with the ambiguity by subconsciously attempting to presuppose that \u03d5 fully specifies a single outcome of a, in which case A means \u2738pa\u03d5. If this presupposition is incompatible with pre-existing knowledge or even with knowledge acquired later during the dialogue, the presupposition is canceled and the meaning falls back to Pa(\u03d5) = p. Fully understanding the dynamics of presuppositions is an open linguistic challenge, and probabilities bring yet another dimension of complexity to this difficult problem.\nExample 5.2 Consider the following statement:\n\u2022 \u201cthe probability of picking number n (for 1 \u2264 n \u2264 6) is 1/6\u201d\nUpon hearing this sentence, we tend to presuppose that there are six outcomes (i.e. \u2738 1/6 pickPicked(n)). However, if we are later told that:\n\u2022 \u201cthe number is picked by throwing a 12-faced fair dice where each n (for 1 \u2264 n \u2264 6) occurs in two distinct faces.\u201d\nwe are forced to cancel our presupposition and revise our logical interpretation of the previous sentence."}, {"heading": "6 Implementation and Automation", "text": "A preliminary implementation of PTL in Coq is available in https://github.com/Paradoxika/ProbLogic. It follows the embedding methodology used in [1,2], which is based on a higher-order and typed version of the standard translation of modal logics into predicate logic, with three important differences. Firstly, whereas in the standard translation the accessibility relation is a primitive constant, in the embedding of PTL it is derived from the primitive notion of action. Secondly, the higher-order modal logics used in [1] were rigid, while PTL includes a flexible probability function P (which is simulated by a flexible predicate in the implementation). Finally,\nin contrast to the logics from [1], PTL requires numerical reasoning. It is this last point that makes the embedding of PTL significantly harder than previous embeddings and justifies its preliminary status. The current implementation still does not provide convenient modal tactics (as those described in [2]) and numerical reasoning is done with Coq\u2019s standard QArith library for rationals (instead of real-closed fields). Decidability (of the satisfiability, validity and entailment problems) is indeed, of course, hopeless for the proposed higherorder logic. But even for logics with undecidability issues, automated theorem provers are occasionaly sufficiently efficient for practical applications [1]. It is also important to note that, even if arithmetical expressions (of type \u03b7) are restricted to be ground (i.e. by forbidding quantifiers of type (\u03b7 \u2192 o) \u2192 o), PTL thus restricted would still be expressive enough to formalize all the examples shown in this paper. In this restricted logic, the only automation of arithmetic needed is simplification/computation of arithmetic expressions and reduction of ground simplified arithmetic propositions to \u22a4 or \u22a5. With the recent progress in SMT-solving and automated theorem proving modulo arithmetic (even with quantifiers), it is reasonable to hope that automated provers will soon be able to cope with PTL problems. In the meanwhile, the current implementation in Coq has already proven to be sufficient for a fully interactive formalization of the Monty Hall problem, as described in the next section."}, {"heading": "7 The Monty Hall Problem", "text": "PTL is used here in the formalization of vos Savant\u2019s famous Monty Hall problem [10], whose description is reproduced below:\nSuppose you\u2019re on a game show, and you\u2019re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No."}, {"heading": "1, and the host, who knows what\u2019s behind the doors, opens another door, say", "text": "No. 3, which has a goat. He then says to you, \u2018Do you want to pick door No. 2?\u2019 Is it to your advantage to switch your choice?\nThis probabilistic puzzle is seemingly paradoxical, because people very often make mistakes when they reason informally about the problem, as they tend to wrongly compute the probabilities. Therefore, despite its apparent simplicity, this problem is an interesting benchmark for evaluating formal probabilistic logics. A good probabilistic logic should allow a sufficiently natural and unambiguous formal representation of the problem and should entail correct probability values. From the player\u2019s point of view, the Monty Hall problem can be formalized in PTL by the following axioms:\n\u2022 Axiom 1: \u201cyou\u2019re given the choice of three doors\u201d: D = d1 :: d2 :: d3 :: nil\n\u2022 Axiom 2: \u201cbehind one door is a car\u201d: \u2203d \u2208 D.C(d)\n\u2022 Axiom 3: \u201cbehind the others, goats\u201d: \u2200d \u2208 D.\u00acC(d) \u2194 G(d)\n\u2022 Axiom 4: \u201cyou pick a door, say No. 1, and the host, who knows what\u2019s\nbehind the doors, opens another door, say No. 3, which has a goat.\u201d:\n\u2203sc.((@s0\u2738h\u2738p(d1)\u2738oin(sc)) \u2227@sc(O(d3) \u2227G(d3)))\nA more literal reading of Axiom 4 would be that \u201cthere exists a state (the current state), reachable from the initial state by the sequence of actions in which the host hides the car (h), the player picks the first door (p(d1)), and the host opens a door (o), where the third door is open and has a goat.\u201d. It is fair to say that the axioms shown above capture the intended meanings of their corresponding informal natural language sentences. As desired, the axioms are reasonably similar to the corresponding sentences, although there are interesting differences worth discussing, particularly in relation to Axiom 4. Firstly, it illustrates the need for the hybrid logic operators @ and in in situations where it is important to declare local conditions, which hold only in a single given state. Secondly, it shows the convenience of having a versatile approach to actions. The pick (p) action, for instance, takes the picked door as an argument whereas the open (o) action takes no argument. This allows us to express that, from the point of view of the player, the action of picking a door is an action of the player and he can choose which door to pick, while opening a door is an action performed by the host, with uncertain outcomes to the player. The opening of the third door is represented as a random event of the action, through the proposition O(d3). These subtle differences between Axiom 4 and its corresponding sentence in the informal description of the problem are evidence that, as expected from a formal language, PTL offers a higher degree of precision than what we are used to in natural language.\nThere are many assumptions that are not explicitly mentioned in the description of the problem. But they must be formalized as well. We list below only some of them. Other axioms (e.g. stating what remains unchanged when actions are excuted) can be see in the Coq formalization discussed in Section 6.\n\u2022 Axiom 5: Each door has equal probability of having the car after the hide\n(h) action: \u2200d \u2208 D.\u2738 1/|D| h C(d)\n\u2022 Axiom 6: The pick (p) action marks the picked door: \u2200d \u2208 D.\u27381p(d)P (d)\n\u2022 Axiom 7: The host opens a door containing a goat with uniform probability among the doors that are neither picked nor contain a car:\n\u2200d c .\u2200d p .(C(dc) \u2192 P (dp) \u2192 \u2200d \u2208 ((D \u2212 dc)\u2212 dp).\u27381/|((D\u2212d c)\u2212dp)| o O(d))\n\u2022 Axiom 8: When the player does the switch (s) action, the newly picked door is different from the previously picked door and from the open door:\n\u2200d o .\u2200d p .(O(do) \u2192 P (dp) \u2192 \u2203d.(d 6= do \u2227 d 6= dp \u2227 \u27381sP (d)))\n\u2022 Axiom 9: When the player does the no switch (s\u0304) action, the newly picked door is the same as the previously picked door: \u2200d.(P (d) \u2192 \u27381s\u0304P (d)))\n\u2022 Axiom 10: A state is a victorious state if and only if the car is behind the picked door: V \u2194 (\u2203d.C(d) \u2227 P (d))\nThe next step is the formalization of (the intended meaning of) the question (\u201cDo you want to pick door No. 2? Is it to your advantage to switch your choice?\u201d) as a conjecture. However, this is significantly less straightforward than the formalization of the axioms. A naive and literal reading of the question could result in the following tentative conjecture:\nPs(V ) > Ps\u0304(V )\nBut the formula above is only satisfied in models where the probability of victory by switching is greater than the probability of victory by not switching in all states, whereas the question is interested in a few states only, namely those reachable by a given sequence of actions (i.e. hiding, picking, opening and re-picking). Taking this into account, an apparently plausible alternative formalization could be:\n@s0\u2737h\u2737p(d1)\u2737o(Ps(V ) > Ps\u0304(V ))\nBut this is trivially false in any model M that satisfies the axioms above, because the action hide has a successor state s1 (where the car was hidden behind the first door) such that:\nM @s1\u2737p(d1)\u2737o(Ps(V ) < Ps\u0304(V ))\nYet another possible attempt would be to formalize the conjecture as:\n\u2200s.\u03d5(s) \u2192 @sPs(V ) > Ps\u0304(V )\nwhere s is the current state when the question is asked and \u03d5(s) is a formula specifying whether s is a posible current state (i.e. consistent with the player\u2019s observations). However, for a similar reason, this formula is also false in any model M that satisfies the axioms: there is a possible current state s\u2217, where Is\u2217(Ps(V )) = 0 and Is\u2217(Ps\u0304(V )) = 1. In fact, it is easy to see that, in any possible current state s, Is\u2217(Ps\u0304(V )) and Is\u2217(Ps(V )) are always either 0 and 1, because the action of switching has always only one possible outcome.\nAs evidenced by the failed conjectures above, there is a structural gap between the natural language question and the correct formalization of its intended meaning, and therein lies a potential reason (though probably not the only one) why people tend to have difficulties to reason about the Monty Hall problem. As it is posed, the question induces the player to think in terms of probabilistic outcomes of the action of switching or not switching in the current state. In contrast, the correct thinking requires the player to hypothetically backtrack to the initial state and formulate the conjecture as follows:\n\u2022 Conjecture: @s0(Ph::p(d1)::o::s::nil(V ) > Ph::p(d1)::o::s\u0304::nil(V ))\nIn any model satisfying the axioms (including the omitted axioms), Is0(Ph::p(d1)::o::s::nil(V )) = 2/3 and Is0 (Ph::p(d1)::o::s\u0304::nil(V )) = 1/3. Therefore, the conjecture is a theorem 1 .\n1 An interactive proof of this theorem using the embedding of PTL in Coq is freely available"}, {"heading": "8 Related Work", "text": "Many probabilistic logics are surveyed in [5]. Among those logics, most depart from classical logic by adopting a probabilistic notion of validity and entailment. PTL, on the other hand, remains strictly classical in this respect. The probabilistic modal logics described in Sections 4.1 and 4.2 of [5] are probably the most similar to PTL. However, they are propositional, lack the probabilistic diamond operator, and are atemporal.\nProbabilistic logics that incorporate time include PCTL [8,4], which extends CTL by replacing the existential and universal path quantifiers by a probabilistic operator. PCTL is an excellent logic for model checking Markov chains. However, its lack of a probabilistic diamond operator makes it susceptible to the issues discussed in Section 5.2, thereby limiting its use beyond model checking. They also lack an explicit handling of actions, which is necessary for a convenient formalization of the Monty Hall problem and other examples discussed here. On the other hand, PCTL\u2019s temporal modalities (which include, for instance, the until operator) are more sophisticated than PTL\u2019s temporal modalities (which can only make statements about the next moment in time). PTL\u2019s parsimony is intentional: it includes only the minimal set of temporal modalities needed to capture the desired notion of probability. Nevertheless, in practical applications where other temporal modalities are needed, they could be easily added to PTL as well."}, {"heading": "9 Conclusion and Future Work", "text": "The large number of available probabilistic logics indicates that conciliating logic and probability is a non-trivial task. The expressive probabilistic temporal logic PTL described here provides a novel alternative approach, based on the simple intuition that the notion of probability can only be fully grasped in combination with the notions of action and time. The complex interaction of time, action and probability naturally leads to a modal and higher-order logic. PTL is adequate with respect to classical probability theory, of which it can be considered an extension (as shown in Section 4, where a correspondence between events and formulas has been established in detail). PTL\u2019s convenient expressive power allowed a natural formalization of the famous Monty Hall problem. One of the main insights in the development of PTL came with the discovery of the need for both a higher-order probability function and a probabilistic diamond operator, as discussed in Section 5.2. Besides the higher order, the satisfaction of this need is a distinguishing feature of PTL.\nIn the near future, the implementation of PTL in Coq needs to be made more user-friendly, through the implementation of tactics that automate and hide technical details for users. On the philosophical side, it would be interesting to extend PTL with past temporal modalities, since we often need to\nin the online repository of the implementation discussed in Section 6. For the sake of simplicity, this formalization of the Monty Hall problem does not concern itself with specifying in which states each action is allowed or disallowed. But this could also be done.\nreason about actions that have happened in the past but whose outcomes we have not yet observed, and to define conditional probabilities, in order to explore the question about the relationship between probabilities of conditionals (e.g. P (A \u2192 B)) and conditional probabilities (e.g. P (B|A)) [7] from PTL\u2019s perspective."}], "references": [{"title": "Automating g\u00f6del\u2019s ontological proof of god\u2019s existence with higher-order automated theorem provers", "author": ["C. Benzm\u00fcller", "B.W. Paleo"], "venue": "in: ECAI 2014 - 21st European Conference on Artificial Intelligence,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Interacting with modal logics in the coq proof assistant, in: Computer Science - Theory and Applications - 10th International Computer Science Symposium in Russia, CSR 2015, Listvyanka, Russia", "author": ["C. Benzm\u00fcller", "B.W. Paleo"], "venue": "July 13-17,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Modal Logic", "author": ["P. Blackburn", "M. de Rijke", "Y. Venema"], "venue": "Cambridge University Press, New York, NY, USA, 2001.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2001}, {"title": "The satisfiability problem for probabilistic CTL", "author": ["T. Br\u00e1zdil", "V. Forejt", "J. Kret\u0301\u0131nsk\u00fd", "A. Kucera"], "venue": "in: Proceedings of the Twenty-Third Annual IEEE Symposium on Logic in Computer Science,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Types, Tableaus, and G\u00f6del\u2019s God", "author": ["M. Fitting"], "venue": "Kluwer Academic Publishers, 2002.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "The Conditional Construal of Conditional Probability", "author": ["A. Hajek"], "venue": "Ph.D. thesis, Princeton (1993). URL http://philosophy.anu.edu.au/sites/default/files/The%20Conditional%20Construal%20of%20Conditional%20Probabili", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1993}, {"title": "A logic for reasoning about time and reliability", "author": ["H. Hansson", "B. Jonsson"], "venue": "Formal Aspects of Computing", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1994}, {"title": "Grundbegriffe der Wahrscheinlichkeitsrechnung", "author": ["A. Kolmogorov"], "venue": "1933.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1933}], "referenceMentions": [{"referenceID": 7, "context": "Kolmogorov\u2019s probability theory, for example, merely defines probability as the measure function in a measure space with total measure 1 [9].", "startOffset": 137, "endOffset": 140}, {"referenceID": 2, "context": "As in the most common modal logics [3], we use frames as the foundation for the modal aspects of the semantics.", "startOffset": 35, "endOffset": 38}, {"referenceID": 0, "context": "2 A probabilistic labeled frame is a triple (W,R, P ) such that W is a non-empty set of states, R \u2286 W \u00d7W \u00d7D\u03b1 satisfying the condition that if (w,w, l) \u2208 R then (w,w, l) \u2208 R for every w \u2208 l(w), and P : R \u2192 [0, 1] is a probability function satisfying the condition that for all w \u2208 W and for all", "startOffset": 205, "endOffset": 211}, {"referenceID": 4, "context": "In such cases, we say that the interpretation is flexible; otherwise, it is rigid [6].", "startOffset": 82, "endOffset": 85}, {"referenceID": 0, "context": "a collection of subsets of \u03a9 (events) closed under complementation, countable union and countable intersection) and Q : \u03a3 \u2192 [0, 1] is a probability function satisfying Kolmogorov\u2019s axioms: (i) Q(E) \u2265 0, for all E \u2208 \u03a3 (ii) Q(\u03a9) = 1 (iii) For any countable collection C of mutually disjoint events", "startOffset": 124, "endOffset": 130}, {"referenceID": 0, "context": "It follows the embedding methodology used in [1,2], which is based on a higher-order and typed version of the standard translation of modal logics into predicate logic, with three important differences.", "startOffset": 45, "endOffset": 50}, {"referenceID": 1, "context": "It follows the embedding methodology used in [1,2], which is based on a higher-order and typed version of the standard translation of modal logics into predicate logic, with three important differences.", "startOffset": 45, "endOffset": 50}, {"referenceID": 0, "context": "Secondly, the higher-order modal logics used in [1] were rigid, while PTL includes a flexible probability function P (which is simulated by a flexible predicate in the implementation).", "startOffset": 48, "endOffset": 51}, {"referenceID": 0, "context": "in contrast to the logics from [1], PTL requires numerical reasoning.", "startOffset": 31, "endOffset": 34}, {"referenceID": 1, "context": "The current implementation still does not provide convenient modal tactics (as those described in [2]) and numerical reasoning is done with Coq\u2019s standard QArith library for rationals (instead of real-closed fields).", "startOffset": 98, "endOffset": 101}, {"referenceID": 0, "context": "But even for logics with undecidability issues, automated theorem provers are occasionaly sufficiently efficient for practical applications [1].", "startOffset": 140, "endOffset": 143}, {"referenceID": 6, "context": "Probabilistic logics that incorporate time include PCTL [8,4], which extends CTL by replacing the existential and universal path quantifiers by a probabilistic operator.", "startOffset": 56, "endOffset": 61}, {"referenceID": 3, "context": "Probabilistic logics that incorporate time include PCTL [8,4], which extends CTL by replacing the existential and universal path quantifiers by a probabilistic operator.", "startOffset": 56, "endOffset": 61}, {"referenceID": 5, "context": "P (B|A)) [7] from PTL\u2019s perspective.", "startOffset": 9, "endOffset": 12}], "year": 2016, "abstractText": "This paper argues that a combined treatment of probabilities, time and actions is essential for an appropriate logical account of the notion of probability; and, based on this intuition, describes an expressive probabilistic temporal logic for reasoning about actions with uncertain outcomes. The logic is modal and higher-order : modalities annotated by actions are used to express possibility and necessity of propositions in the next states resulting from the actions, and a higher-order function is needed to express the probability operator. The proposed logic is shown to be an adequate extension of classical mathematical probability theory, and its expressiveness is illustrated through the formalization of the Monty Hall problem.", "creator": "LaTeX with hyperref package"}}}