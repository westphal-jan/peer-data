{"id": "1604.02133", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Apr-2016", "title": "Revising Incompletely Specified Convex Probabilistic Belief Bases", "abstract": "putzer We propose sedimentology a plantaginaceae method for an agent operacija to run-around revise its incomplete probabilistic beliefs thmey when shapovalyants a new kacar piece nashaat of propositional information is glut observed. donaghue In ingles this work, an sarkies agent ' matchplay s beliefs are represented quadratus by evaristti a kevlar set of vize probabilistic formulae - - villagr\u00e1n a 55.85 belief base. jianlin The method comus involves determining a selanne representative one-up set grimston of ' 3,000-meter boundary ' wolfberries probability distributions consistent huskey with kropf the dagestani current 1986-1994 belief jaar base, revising each of these probability yec distributions and tippah then translating jaro the revised information into a new belief tuberosa base. We frend use a 5.6-magnitude version saut of plantations Lewis fauria Imaging stuy as charlottesville the revision operation. vice-president The correctness of the shuowen approach is coor proved. The expressivity of the belief prev\u00e9 bases now-e under 3,855 consideration meherrin are rather 76-62 restricted, but has tampi some applications. We unilateralism also discuss ranil methods of zaghawa belief beranbaum base grey-crowned revision 109-106 employing dalbar the 50-billion notion grazioli of agordon optimum griff entropy, jarad and incursion point out chanters some of the hashemian benefits christmastime and extremists difficulties in biffi those francesc methods. hardrada Both the atebank boundary http://www.bop.gov distribution backscattering method demeans and pyromania the optimum ppv entropy mi-5 method are peau reasonable, yet aravali yield yigong different floppy results.", "histories": [["v1", "Thu, 7 Apr 2016 19:41:35 GMT  (25kb,D)", "http://arxiv.org/abs/1604.02133v1", "Presented at the Sixteenth International Workshop on Non-Monotonic Reasoning, 22-24 April 2016, Cape Town, South Africa. 9.25 pages"]], "COMMENTS": "Presented at the Sixteenth International Workshop on Non-Monotonic Reasoning, 22-24 April 2016, Cape Town, South Africa. 9.25 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["gavin rens", "thomas meyer", "giovanni casini"], "accepted": false, "id": "1604.02133"}, "pdf": {"name": "1604.02133.pdf", "metadata": {"source": "CRF", "title": "Revising Incompletely Specified Convex Probabilistic Belief Bases", "authors": ["Gavin Rens", "Thomas Meyer", "Giovanni Casini"], "emails": ["gavinrens@gmail.com", "tmeyer@cs.uct.ac.za", "giovanni.casini@uni.lu"], "sections": [{"heading": null, "text": "Suppose an agent represents its probabilistic knowledge with a set of statements; every statement says something about the probability of some features the agent is aware of. Ideally, the agent would want to have enough information to, at least, identify one probability distribution over all the situations (worlds) it deems possible. However, if the agent could not gather sufficient data or if it was not told or given sufficient information, it would not be able to pinpoint exactly one probability distribution. An agent with this sort of ignorance, can be thought of as having beliefs compatible with a set of distributions. Now, this agent might need to revise its beliefs when new (non-probabilistic) information is received, even though the agent\u2019s beliefs do not characterize a particular probability distribution over its current possible worlds.\nSeveral researchers argue that using a single probability distribution requires the agent to make unrealistically precise uncertainty distinctions (Grove and Halpern, 1998; Voorbraak, 1999; Yue and Liu, 2008).1 \u201cOne widelyused approach to dealing with this has been to consider\n\u2217Centre for Artificial Intelligence Research Copyright c\u00a9 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\n1See also the references in these cited papers concerning criticisms against traditional probability theory.\nsets of probability measures as a way of modeling uncertainty,\u201d (Grove and Halpern, 1998). However, simply applying standard probabilistic conditioning to each of the measures/distributions in the set individually and then combining the results is also not recommended. The framework presented in this paper proposes two ways to go from one \u2018probabilistically incomplete\u2019 belief base to another when new information is acquired.\nBoth belief revision methods presented, essentially follow this process: From the original belief base, determine a relatively small set of belief states / probability distributions \u2018compatible\u2019 with the belief base which is, in a sense, representative of the belief base. (We shall use the terms belief state, probability distribution, probability function and distribution interchangeably). Then revise every belief state in this representative set. Finally, induce a new, revised belief base from the revised representative set.\nWe shall present two approaches to determine the representative set of belief states from the current belief base: (i) The approach we focus on involves finding belief states which, in a sense, are at the boundaries of the constraints implied by the belief base. These \u2018boundary belief states\u2019 can be thought of as drawing the outline of the convex space of beliefs. This outline is then revised to form a new outline shape, which can be translated into a new belief base. (ii) As a possible alternative approach, the representative set is a single belief state which can be imagined to be at the center of the outline of the first approach. This \u2018central\u2019 belief state is found by determining the one in the space of beliefs which is least biased or most entropic in terms of information theory (Jaynes, 1978; Cover and Thomas, 1991).\nFor approach (i) \u2013 where the canonical set is the set of boundary belief states \u2013 we shall prove that the revised canonical set characterizes the set of all belief states which would have resulted from revising all (including interior) belief states compatible with the original belief base.\nThe relevant background theory and notations are now introduced.\nWe shall work with classical propositional logic. Let P be the finite set of atomic propositional variables (atoms, for short). Formally, a world is a unique assignment of truth values to all the atoms in P . There are thus 2n conceivable worlds. An agent may consider some non-empty subset W\nar X\niv :1\n60 4.\n02 13\n3v 1\n[ cs\n.A I]\n7 A\npr 2\n01 6\nof the conceivable worlds called the possible worlds. Often, in the exposition of this paper, a world will be referred to by its truth vector. For instance, if the vocabulary is placed in order \u3008q, r\u3009 and w3 \u00acq \u2227 r, then w3 may be referred to as 01.2 Let L be all propositional formulae which can be formed from P and the logical connectives \u2227 and \u00ac, with > abbreviating tautology and \u22a5 abbreviating contradiction.\nLet \u03b2 be a sentence in L. [\u03b2] denotes the set of \u03b2-worlds, that is, the elements ofW satisfying \u03b2. The worlds satisfying all sentences in a set of sentences K are denoted by [K].\nWe define the probabilistic language Lprob = {(\u03b1) ./ x | \u03b1 \u2208 L, ./\u2208 {\u2264,=,\u2265}, x \u2208 [0, 1]}. Sentences with strict inequalities (<,>) are excluded from the language for now. Such sentences are more challenging to deal with and their inclusion is left for future work. We propose a belief base (BB) to be a consistent (logically satisfiable) subset ofLprob . A BB specifies an agent\u2019s knowledge.\nThe basic semantic element of an agent\u2019s beliefs is a probability distribution or a belief state\nb = {(w1, p1), (w2, p2), . . . , (wn, pn)},\nwhere pi is the probability that wi is the actual world in which the agent is. \u2211 (w,p)\u2208b p = 1. We may also use c to refer to a belief state. For parsimony, let b = \u3008p1, . . . , pn\u3009 be the probabilities that belief state b assigns to w1, . . . , wn where \u3008w1, w2, w3, w4\u3009 = \u300811, 10, 01, 00\u3009, and \u3008w1, w2, . . . , w8\u3009= \u3008111, 110, . . . , 000\u3009. Let \u03a0 be the set of all belief states over W . b(\u03b1) abbreviates \u2211 w\u2208W,w \u03b1 b(w). b satisfies formula (\u03b1) ./ x (denoted b (\u03b1) ./ x) iff b(\u03b1) ./ x. If B is a set of formulae, then b satisfies B (denoted b B) iff \u2200\u03b3 \u2208 B, b \u03b3. If B and B\u2032 are sets of formulae, then B entailsB\u2032 (denotedB |= B\u2032) iff for all b \u2208 \u03a0, b B\u2032 whenever b B. If B |= {\u03b3} then we simply write B |= \u03b3. B is logically equivalent to B\u2032 (denoted B \u2261 B\u2032) iff B |= B\u2032 and B\u2032 |= B.\nInstead of an agent\u2019s beliefs being represented by a single belief state, a BB B represents a set of belief-states: Let \u03a0B := {b \u2208 \u03a0 | b B}. A BB B is satisfiable (consistent) iff \u03a0B 6= \u2205.\nThe technique of Lewis imaging for the revision of belief states, requires a notion of distance between worlds to be defined. We use a pseudo-distance measure between worlds, as defined by Lehmann, Magidor, and Schlechta (2001) and adopted by Chhogyal et al. (2014).\nWe add a \u2018faithfulness\u2019 condition, which we feel is lacking from the definition of Lehmann, Magidor, and Schlechta (2001): without this condition, a pseudo-distance measure would allow all worlds to have zero distance between them. Boutilier (1998) mentions this condition, and we use his terminology: \u201cfaithfulness\u201d. Definition 1. A pseudo-distance function d : W \u00d7W \u2192 Z satisfies the following four conditions: for all worlds w,w\u2032, w\u2032\u2032 \u2208W ,\n1. d(w,w\u2032) \u2265 0 (Non-negativity) 2w \u03b1 is read \u2018w is a model for/satisfies \u03b1\u2019.\n2. d(w,w) = 0 (Identity) 3. d(w,w\u2032) = d(w\u2032, w) (Symmetry)"}, {"heading": "4. d(w,w\u2032)+d(w\u2032, w\u2032\u2032) \u2265 d(w,w\u2032\u2032) (Triangular Inequality)", "text": "5. if w 6= w\u2032, then d(w,w\u2032) > 0 (Faithfulness)\nPresently, the foundation theory, or paradigm, for studying belief change operations is commonly known as AGM theory (Alchourro\u0301n, Ga\u0308rdenfors, and Makinson, 1985; Ga\u0308rdenfors, 1988). Typically, belief change (in a static world) can be categorized as expansion, revision or contraction, and is performed on a belief set, the set of sentences K closed under logical consequence. Expansion (denoted +) is the logical consequences of K \u222a {\u03b1}, where \u03b1 is new information and K is the current belief set. Contraction of \u03b1 is the removal of some sentences until \u03b1 cannot be inferred from K. It is the reduction of beliefs. Revision is when \u03b1 is (possibly) inconsistent with K and K is (minimally) modified so that the new K remains consistent and entails \u03b1. In this view, when the new information is consistent with the original beliefs, expansion and revision are equivalent.\nThe next section presents a generalized imaging method for revising probabilistic belief states. Then we describe the application of generalized imaging in our main contribution; revising boundary belief states instead of all belief states. The subsequent section explain another approaches of revising our belief bases, which prepares us for discussions in the rest of the paper. The latter method finds a single representative belief state through maximum entropy inference. Both the boundary belief state method and the maximum entropy method are reasonable, yet yield different results \u2013 a seeming paradox is thus uncovered. Then future possible directions of research are discussed. We end with a section on the related work and the concluding section.\nGeneralized Imaging It is not yet universally agreed what revision means in a probabilistic setting. One school of thought says that probabilistic expansion is equivalent to Bayesian conditioning. This is evidenced by Bayesian conditioning (BC) being defined only when b(\u03b1) 6= 0, thus making BC expansion equivalent to BC revision. In other words, one could define expansion (restricted revision) to be\nb BC \u03b1 = {(w, p) | w \u2208W,p = b(w | \u03b1), b(\u03b1) 6= 0}.\nTo accommodate cases where b(\u03b1) = 0, that is, where \u03b1 contradicts the agent\u2019s current beliefs and its beliefs need to be revised in the stronger sense, we shall make use of imaging. Imaging was introduced by Lewis (1976) as a means of revising a probability function. It has also been discussed in the work of, for instance, Ga\u0308rdenfors (1988); Dubois and Prade (1993); Chhogyal et al. (2014); Rens and Meyer (2015). Informally, Lewis\u2019s original solution for accommodating contradicting evidence \u03b1 is to move the probability of each world to its closest, \u03b1-world. Lewis made the strong assumption that every world has a unique closest \u03b1-world. More general versions of imaging allows worlds to have several, equally proximate, closest worlds.\nGa\u0308rdenfors (1988) calls one of his generalizations of Lewis\u2019s imaging general imaging. Our method is also a generalization. We thus refer to his as Ga\u0308rdenfors\u2019s general imaging and to our method as generalized imaging to distinguish them. It should be noted that all three these imaging methods are general revision methods and can be used in place of Bayesian conditioning for expansion. \u201cThus imaging is a more general method of describing belief changes than conditionalization,\u201d (Ga\u0308rdenfors, 1988, p. 112).\nLet Min(\u03b1,w, d) be the set of \u03b1-worlds closest to w with respect to pseudo-distance d. Formally,\nMin(\u03b1,w, d) :=\n{w\u2032 \u2208 [\u03b1] | \u2200w\u2032\u2032 \u2208 [\u03b1], d(w\u2032, w) \u2264 d(w\u2032\u2032, w)},\nwhere d(\u00b7) is some pseudo-distance measure between worlds (e.g., Hamming or Dalal distance). Example 1. Let the vocabulary be {q, r, s}. Let \u03b1 be (q \u2227 r) \u2228 (q \u2227 \u00acr \u2227 s). Suppose d is Hamming distance. Then\nMin((q \u2227 r) \u2228 (q \u2227 \u00acr \u2227 s), 111, d) = {111} Min((q \u2227 r) \u2228 (q \u2227 \u00acr \u2227 s), 110, d) = {110} Min((q \u2227 r) \u2228 (q \u2227 \u00acr \u2227 s), 101, d) = {101} Min((q \u2227 r) \u2228 (q \u2227 \u00acr \u2227 s), 100, d) = {110, 101} Min((q \u2227 r) \u2228 (q \u2227 \u00acr \u2227 s), 011, d) = {111} Min((q \u2227 r) \u2228 (q \u2227 \u00acr \u2227 s), 010, d) = {110} Min((q \u2227 r) \u2228 (q \u2227 \u00acr \u2227 s), 001, d) = {101} Min((q \u2227 r) \u2228 (q \u2227 \u00acr \u2227 s), 000, d) = {110, 101}\nDefinition 2 (GI). Then generalized imaging (denoted GI) is defined as\nb GI \u03b1 := {(w, p) | w \u2208W,p = 0 if w 6\u2208 [\u03b1], else p = \u2211 w\u2032\u2208W\nw\u2208Min(\u03b1,w\u2032,d)\nb(w\u2032)/|Min(\u03b1,w\u2032, d)|}.\nIn words, b GI \u03b1 is the new belief state produced by taking the generalized image of b with respect to \u03b1. Notice how the probability mass of non-\u03b1-worlds is shifted to their closest \u03b1-worlds. If a non-\u03b1-world w\u00d7 with probability p has n closest \u03b1-worlds (equally distant), then each of these closest \u03b1-worlds gets p/n mass from w\u00d7.\nWe define b\u25e6\u03b1 := b \u25e6 \u03b1 so that we can write b\u25e6\u03b1(w), where \u25e6 is a revision operator. Example 2. Continuing on Example 1: Let b = \u30080, 0.1, 0, 0.2, 0, 0.3, 0, 0.4\u3009.\n(q \u2227 r) \u2228 (q \u2227 \u00acr \u2227 s) is abbreviated as \u03b1. bGI\u03b1 (111) = \u2211\nw\u2032\u2208W 111\u2208Min(\u03b1,w\u2032,d)\nb(w\u2032)/|Min(\u03b1,w\u2032, d)|\n= b(111)/|Min(\u03b1, 111, d)| + b(011)/|Min(\u03b1, 011, d)| = 0/1 + 0/1 = 0.\nbGI\u03b1 (110) = \u2211\nw\u2032\u2208W 110\u2208Min(\u03b1,w\u2032,d)\nb(w\u2032)/|Min(\u03b1,w\u2032, d)|\n= b(110)/|Min(\u03b1, 110, d)| + b(100)/|Min(\u03b1, 100, d)| +\nb(010)/|Min(\u03b1, 010, d)| + b(000)/|Min(\u03b1, 000, d)| = 0.1/1 + 0.2/2 + 0.3/1 + 0.4/2 = 0.7.\nbGI\u03b1 (101) = \u2211\nw\u2032\u2208W 101\u2208Min(\u03b1,w\u2032,d)\nb(w\u2032)/|Min(\u03b1,w\u2032, d)|\n= b(101)/|Min(\u03b1, 101, d)| + b(100)/|Min(\u03b1, 100, d)| + b(001)/|Min(\u03b1, 001, d)| + b(000)/|Min(\u03b1, 000, d)| = 0/1 + 0.2/2 + 0/1 + 0.4/2 = 0.3.\nAnd bGI\u03b1 (100) = b GI \u03b1 (011) = b GI \u03b1 (010) = b GI \u03b1 (001) =\nbGI\u03b1 (000) = 0.\nRevision via GI and boundary belief states Perhaps the most obvious way to revise a given belief base (BB) B is to revise every individual belief state in \u03a0B and then induce a new BB from the set of revised belief states. Formally, given observation \u03b1, first determine a new belief state b\u03b1 for every b \u2208 \u03a0B via the defined revision operation:\n\u03a0B \u03b1 = {b\u03b1 \u2208 \u03a0 | b\u03b1 = b GI \u03b1, b \u2208 \u03a0B}.\nIf there is more than only a single belief state in \u03a0B , then \u03a0B contains an infinite number of belief states. Then how can one compute \u03a0B \u03b1\n? And how would one subsequently determine B\u03b1 from \u03a0B \u03b1\n? In the rest of this section we shall present a finite method\nof determining \u03a0B \u03b1\n. What makes this method possible is the insight that \u03a0B can be represented by a finite set of \u2018boundary\u2019 belief states \u2013 those belief states which, in a sense, represent the limits or the convex hull of \u03a0B . We shall prove that the set of revised boundary belief states defines \u03a0B \u03b1\n. Inducing B\u03b1 from \u03a0B \u03b1\nis then relatively easy, as will be seen.\nLet W perm be every permutation on the ordering of worlds in W . For instance, if W = {w1, w2, w3, w4}, then W perm = {\u3008w1, w2, w3, w4\u3009, \u3008w1, w2, w4, w3\u3009, \u3008w1, w3, w2, w4\u3009, . . ., \u3008w4, w3, w2, w1\u3009}. Given an ordering W# \u2208 W perm , let W#(i) be the i-th element of W#; for instance, \u3008w4, w3, w2, w1\u3009(2) = w3. Suppose we are given a BB B. We now define a function which, given a permutation of worlds, returns a belief state where worlds earlier in the ordering are assigned maximal probabilities according to the boundary values enforced by B.\nDefinition 3. MaxASAP(B,W#) is the b \u2208 \u03a0B such that for i = 1, . . . , |W |, \u2200b\u2032 \u2208 \u03a0B , if b\u2032 6= b, then\u2211i j=1 b(W #(j)) \u2265 \u2211i k=1 b \u2032(W#(k)).\nExample 3. Suppose the vocabulary is {q, r} and B1 = {(q) \u2265 0.6}. Then, for instance, MaxASAP(B1, \u300801, 00, 11, 10\u3009) = {(01, 0.4), (00, 0), (11, 0.6), (10, 0)} = {(11, 0.6), (10, 0), (01, 0.4), (00, 0)}. Definition 4. We define the boundary belief states of BB B as the set\n\u03a0Bbnd := {b \u2208 \u03a0B | W# \u2208W perm , b = MaxASAP(B,W#)}\nNote that |\u03a0Bbnd | \u2264 |W perm |.\nExample 4. Suppose the vocabulary is {q, r} and B1 = {(q) \u2265 0.6}. Then\n\u03a0B1bnd = {{(11, 1.0), (10, 0.0), (01, 0.0), (00, 0.0)}, {(11, 0.0), (10, 1.0), (01, 0.0), (00, 0.0)}, {(11, 0.6), (10, 0.0), (01, 0.4), (00, 0.0)}, {(11, 0.6), (10, 0.0), (01, 0.0), (00, 0.4)}, {(11, 0.0), (10, 0.6), (01, 0.4), (00, 0.0)}, {(11, 0.0), (10, 0.6), (01, 0.0), (00, 0.4)}}.\nNext, the revision operation is applied to every belief state in \u03a0Bbnd . Let (\u03a0 B bnd) GI \u03b1 := {b\u2032 \u2208 \u03a0 | b\u2032 = bGI\u03b1 , b \u2208 \u03a0Bbnd}.\nExample 5. Suppose the vocabulary is {q, r} and B1 = {(q) \u2265 0.6}. Let \u03b1 be (q \u2227 \u00acr) \u2228 (\u00acq \u2227 r). Then\n(\u03a0B1bnd) GI \u03b1 = {{(11, 0.0), (10, 0.5), (01, 0.5), (00, 0.0)},\n{(11, 0.0), (10, 1.0), (01, 0.0), (00, 0.0)}, {(11, 0.0), (10, 0.3), (01, 0.7), (00, 0.0)}, {(11, 0.0), (10, 0.6), (01, 0.4), (00, 0.0)}, {(11, 0.0), (10, 0.8), (01, 0.2), (00, 0.0)}}.\n(Two revision operations produce {(11, 0), (10, 0.5), (01, 0.5), (00, 0)}.)\nTo induce the new BBB\u03b1bnd from (\u03a0 B bnd) GI \u03b1 , the following procedure is executed. For every possible world, the procedure adds a sentence enforcing the upper (resp., lower) probability limit of the world, with respect to all the revised boundary belief states. Trivial limits are excepted.\nFor every w \u2208 W , (\u03c6w) \u2264 y \u2208 B\u03b1, where y = maxb\u2208(\u03a0Bbnd )GI\u03b1 b(w), except when y = 1, and (\u03c6w) \u2265 y \u2208 B\u03b1, where y = minb\u2208(\u03a0Bbnd )GI\u03b1 b(w), except when y = 0.\nThe intention is that the procedure specifies B\u03b1 to represent the upper and lower probability envelopes of the set of revised boundary belief states \u2013 B\u03b1 thus defines the entire revised belief state space (cf. Theorem 1).\nExample 6. Continuing Example 5, using the translation procedure just above, we see that B\u03b11bnd = {(\u03c611) \u2264 0, (\u03c610) \u2265 0.3, (\u03c601) \u2264 0.7, (\u03c600) \u2264 0.0}.\nNote that if we let B\u2032 = {((q \u2227 \u00acr) \u2228 (\u00acq \u2227 r)) = 1, (q \u2227 \u00acr) \u2265 0.3}, then \u03a0B\u2032 = \u03a0B\u03b11bnd . Example 7. Suppose the vocabulary is {q, r} and B2 = {(\u00acq \u2227 \u00acr) = 0.1}. Let \u03b1 be \u00acq. Then\n\u03a0B2bnd = {{(11, 0.9), (10, 0), (01, 0), (00, 0.1)}, {(11, 0), (10, 0.9), (01, 0), (00, 0.1)}, {(11, 0), (10, 0), (01, 0.9), (00, 0.1)}},\n(\u03a0B2bnd) GI \u03b1 = {{(11, 0), (10, 0), (01, 0.9), (00, 0.1)},\n{(11, 0), (10, 0), (01, 0), (00, 1)}} and\nB\u03b12bnd = {(\u03c611) \u2264 0, (\u03c610) \u2264 0, (\u03c601) \u2264 0.9, (\u03c600) \u2265 0.1}.\nNote that if we letB\u2032 = {(\u00acq) = 1, (\u00acq\u2227r) \u2264 0.9}, then \u03a0B \u2032 = \u03a0B \u03b1 2bnd .\nLet WMin(\u03b1,d) be a partition of W such that {wi1, . . . , wini} is a block in WMin(\u03b1,d) iff |Min(\u03b1,wi1, d)| = \u00b7 \u00b7 \u00b7 = |Min(\u03b1,wini, d)|. Denote an element of block {wi1, . . . , wini} as wi, and the block of which wi is an element as [wi]. Let i = |Min(\u03b1,wi, d)|, in other words, the superscript in wi indicates the size of Min(\u03b1,wi, d). Let m := maxw\u2208W |Min(\u03b1,w, d)|. Observation 1. Let \u03b41, \u03b42, . . . , \u03b4m be positive integers such that i < j iff \u03b4i < \u03b4j . Let \u03bd1, \u03bd2, . . . , \u03bdm be values in [0, 1] such that \u2211m k=1 \u03bdk = 1. Associate with every \u03bdi a maximum value it is allowed to take: most(\u03bdi). For every \u03bdi, we define the assignment value\nav(\u03bdi) :=\n{ most(\u03bdi) if \u2211i k=1 \u2264 1\n1\u2212 \u2211i\u22121 k=1 otherwise\nDetermine first av(\u03bd1), then av(\u03bd2) and so on. Then\nav(\u03bd1) \u03b41 + \u00b7 \u00b7 \u00b7+ av(\u03bdm) \u03b4m > \u03bd\u20321 \u03b41 + \u00b7 \u00b7 \u00b7+ \u03bd \u2032 m \u03b4m\nwhenever \u03bd\u2032i 6= av(\u03bdi) for some i. For instance, let \u03b41 = 1, \u03b42 = 2, \u03b43 = 3, \u03b44 = 4. Let most(\u03bd1) = 0.5, most(\u03bd2) = 0.3, most(\u03bd3) = 0.2, most(\u03bd4) = 0.3. Then av(\u03bd1) = 0.5, av(\u03bd2) = 0.3, av(\u03bd3) = 0.2, av(\u03bd4) = 0 and\n0.5\n1 +\n0.3\n2 +\n0.2\n3 +\n0 4 = 0.716.\nBut 0.49\n1 +\n0.3\n2 +\n0.2\n3 +\n0.01\n4 = 0.709.\nAnd 0.5\n1 +\n0.29\n2 +\n0.2\n3 +\n0.01\n4 = 0.714.\nLemma 1 essentially says that the belief state in \u03a0B which causes a revised belief state to have a maximal value at world w (w.r.t. all belief states in \u03a0B), will be in \u03a0Bbnd . Lemma 1. For all w \u2208 W , arg maxbX\u2208\u03a0B \u2211 w\u2032\u2208W\nw\u2208Min(\u03b1,w\u2032,d) bX(w\n\u2032)/|Min(\u03b1,w\u2032, d)| is\nin \u03a0Bbnd .\nProof. Note that\u2211 w\u2032\u2208W\nw\u2208Min(\u03b1,w\u2032,d)\nb(w\u2032)/|Min(\u03b1,w\u2032, d)|\ncan be written in the form\u2211 w\u2032\u2208[w1]\nw\u2208Min(\u03b1,w\u2032,d) b(w\u2032)\n1 + \u00b7 \u00b7 \u00b7+\n\u2211 w\u2032\u2208[wm]\nw\u2208Min(\u03b1,w\u2032,d) b(w\u2032)\nm .\nObserve that there must be a W# \u2208 W perm such that W# = \u3008w11, . . . , w1n1, . . . , wm1 , . . . , wmnm\u3009. Then by the\ndefinition of the set of boundary belief states (Def. 4), MaxASAP(B,W#) will assign maximal probability mass to [w1] = {w11, . . . , w1n1}, then to [w2] = {w21, . . . , wmn2} and so on.\nThat is, by Observation 1, for some bx \u2208 \u03a0Bbnd , bx(w) = maxbX\u2208\u03a0B \u2211 w\u2032\u2208W\nw\u2208Min(\u03b1,w\u2032,d) bX(w\n\u2032)/|Min(\u03b1,w\u2032, d)|\nfor all w \u2208 W . Therefore, arg maxbX\u2208\u03a0B \u2211 w\u2032\u2208W\nw\u2208Min(\u03b1,w\u2032,d) bX(w\n\u2032)/|Min(\u03b1,w\u2032, d)| is\nin \u03a0Bbnd .\nLet xw := maxb\u2208\u03a0Bbnd b(w) X w := maxb\u2208\u03a0B b(w)\nyw := maxb\u2208(\u03a0Bbnd )GI\u03b1 b(w) Y w := maxb\u2208(\u03a0B)GI\u03b1 b(w)\nxw := minb\u2208\u03a0Bbnd b(w) X w := minb\u2208\u03a0B b(w)\nyw := minb\u2208(\u03a0Bbnd )GI\u03b1 b(w) Y w := minb\u2208(\u03a0B)GI\u03b1 b(w)\nLemma 2 states that for every world, the upper/lower probability of the world with respect to \u03a0Bbnd is equal to the upper/lower probability of the world with respect to \u03a0B . The proof requires Observation 1 and Lemma 1.\nLemma 2. For all w \u2208W , yw = Y w and yw = Y w.\nProof. Note that if w 6\u2208 [\u03b1], then yw = Y w = 0 and yw = Y w = 0.\nWe now consider the cases where w \u2208 [\u03b1].\nyw = Y w\niff max\nb\u2208(\u03a0Bbnd ) b(w) = max b\u2208(\u03a0B) b(w)\niff\nmax bx\u2208\u03a0Bbnd\n\u2211 w\u2032\u2208W\nw\u2208Min(\u03b1,w\u2032,d)\nbx(w \u2032)/|Min(\u03b1,w\u2032, d)|\n= max bX\u2208\u03a0B\n\u2211 w\u2032\u2208W\nw\u2208Min(\u03b1,w\u2032,d)\nbX(w \u2032)/|Min(\u03b1,w\u2032, d)|\nif bx(w) = bX(w), where\nbx(w) := max bx\u2208\u03a0Bbnd\n\u2211 w\u2032\u2208W\nw\u2208Min(\u03b1,w\u2032,d)\nbx(w \u2032)/|Min(\u03b1,w\u2032, d)|\nand\nbX(w) := max bX\u2208\u03a0B\n\u2211 w\u2032\u2208W\nw\u2208Min(\u03b1,w\u2032,d)\nbX(w \u2032)/|Min(\u03b1,w\u2032, d)|.\nNote that \u2211 w\u2032\u2208W\nw\u2208Min(\u03b1,w\u2032,d)\nb(w\u2032)/|Min(\u03b1,w\u2032, d)|\ncan be written in the form\u2211 w\u2032\u2208[w1]\nw\u2208Min(\u03b1,w\u2032,d) b(w\u2032)\n1 + \u00b7 \u00b7 \u00b7+\n\u2211 w\u2032\u2208[wm]\nw\u2208Min(\u03b1,w\u2032,d) b(w\u2032)\nm .\nThen by Observation 1, bX(w) is in \u03a0Bbnd . And also by Lemma 1, the belief state in \u03a0Bbnd identified by bX(w) must be the one which maximizes\u2211\nw\u2032\u2208W w\u2208Min(\u03b1,w\u2032,d)\nbx(w \u2032)/|Min(\u03b1,w\u2032, d)|,\nwhere bx \u2208 \u03a0Bbnd . That is, bx = bX . With a symmetrical argument, it can be shown that yw = Y w.\nIn intuitive language, the following theorem says that the BB determined through the method of revising boundary belief states captures exactly the same beliefs and ignorance as the belief states in \u03a0B which have been revised. This correspondence relies on the fact that the upper and lower probability envelopes of \u03a0B can be induce from \u03a0Bbnd , which is what Lemma 2 states.\nTheorem 1. Let (\u03a0B)GI\u03b1 := {bGI\u03b1 \u2208 \u03a0 | b \u2208 \u03a0B}. Let B\u03b1bnd be the BB induced from (\u03a0Bbnd) GI \u03b1 . Then \u03a0 B\u03b1bnd = (\u03a0B)GI\u03b1 .\nProof. We show that \u2200b\u2032\u2208\u03a0, b\u2032\u2208\u03a0B\u03b1bnd \u21d0\u21d2 b\u2032\u2208(\u03a0B)GI\u03b1 . (\u21d2) b\u2032 \u2208 \u03a0B\u03b1bnd implies \u2200w \u2208 W , yw \u2264 b\u2032(w) \u2264 yw (by definition of B\u03b1bnd ). Lemma 2 states that for all w \u2208W , yw = Y w and yw = Y w. Hence, \u2200w \u2208 W , Y w \u2264 b\u2032(w) \u2264 Y w\nTherefore, b\u2032(w) \u2208 (\u03a0B)GI\u03b1 . (\u21d0) b\u2032(w) \u2208 (\u03a0B)GI\u03b1 implies \u2200w \u2208 W , Y\nw \u2264 b\u2032(w) \u2264 Y w\n. Hence, by Lemma 2, \u2200w \u2208 W , yw \u2264 b\u2032(w) \u2264 yw. Therefore, by definition of B\u03b1bnd , b \u2032\u2208\u03a0B\u03b1bnd ."}, {"heading": "Revising via a Representative Belief State", "text": "Another approach to the revision of a belief base (BB) is to determine a representative of \u03a0B (call it brep), change the representative belief state via the the defined revision operation and then induce a new BB from the revised representative belief state. Selecting a representative probability function from a family of such functions is not new (Goldszmidt, Morris, and Pearl, 1990; Paris, 1994, e.g.). More formally, given observation \u03b1, first determine brep \u2208 \u03a0B , then compute its revision b\u03b1rep , and finally induce B\n\u03b1 from b\u03b1rep . We shall represent \u03a0B (and thus B) by the single \u2018least biased\u2019 belief state, that is, the belief state in \u03a0B with highest entropy:\nDefinition 5 (Shannon Entropy). H(b) := \u2212 \u2211 w\u2208W b(w) ln b(w),\nwhere b is a belief state.\nDefinition 6 (Maximum Entropy). Traditionally, given some set of distributions \u03a0, the most entropic distribution in \u03a0 is defined as\nbH := arg max b\u2208\u03a0 H(b).\nSuppose B2 = {(\u00acq \u2227 \u00acr) = 0.1}. Then the belief state b \u2208 \u03a0B2 satisfying the constraints posed by B2 for which H(b) is maximized is brep = bH = \u30080.3, 0.3, 0.3, 0.1\u3009.\nThe above distribution can be found directly by applying the principle of maximum entropy: The true belief state is estimated to be the one consistent with known constraints, but is otherwise as unbiased as possible, or \u201cGiven no other knowledge, assume that everything is as random as possible. That is, the probabilities are distributed as uniformly as possible consistent with the available information,\u201d (Poole and Mackworth, 2010). Obviously world 00 must be assigned probability 0.1. And the remaining 0.9 probability mass should be uniformly spread across the other three worlds.\nApplying GI to brep on evidence \u00acq results in b\u00acqrep = \u30080, 0, 0.6, 0.4\u3009. Example 8. Suppose the vocabulary is {q, r}, B1 = {(q) \u2265 0.6} and \u03b1 is (q \u2227 \u00acr) \u2228 (\u00acq \u2227 r). Then brep = arg maxb\u2208\u03a0B1 H(b) = \u30080.3, 0.3, 0.2, 0.2\u3009. Applying GI to brep on \u03b1 results in b\u03b1rep = \u30080, 0.61, 0.39, 0\u3009. b\u03b1rep can be translated intoB\u03b11rep as {(q\u2227\u00acr) = 0.61, (\u00acq\u2227r) = 0.39}.\nStill using \u03b1 = (q \u2227 \u00acr) \u2228 (\u00acq \u2227 r), notice that \u03a0B\n\u03b1 1rep 6= \u03a0B\u03b11bnd . But how different areB\u03b11rep = {(q\u2227\u00acr) = 0.61, (\u00acq \u2227 r) = 0.39} and B\u03b11bnd = {(q \u2227 r) \u2264 0, (q\u2227\u00acr) \u2265 0.3, (\u00acq\u2227 r) \u2264 0.7, (\u00acq\u2227\u00acr) \u2264 0.0}? Perhaps one should ask, how different B\u03b11rep is from the representative of B\u03b11bnd : The least biased belief state satisfying B \u03b1 1bnd is \u30080, 0.5, 0.5, 0\u3009. That is, How different are \u30080, 0.61, 0.39, 0\u3009 and \u30080, 0.5, 0.5, 0\u3009?\nIn the case of B2, we could compare B \u00acq 2bnd = {(\u03c611) \u2264 0, (\u03c610) \u2264 0, (\u03c601) \u2264 0.9, (\u03c600) \u2265 0.1} with b\u00acqrep = \u30080, 0, 0.6, 0.4\u3009. Or if we take the least biased belief state satisfying B\u00acq2bnd , we can compare \u30080, 0, 0.5, 0.5\u3009 with \u30080, 0, 0.6, 0.4\u3009.\nIt has been extensively argued (Jaynes, 1978; Shore and Johnson, 1980; Paris and Vencovsk, 1997) that maximum entropy is a reasonable inference mechanism, if not the most reasonable one (w.r.t. probability constraints). And in the sense that the boundary belief states method requires no compression / information loss, it also seems like a very reasonable inference mechanism for revising BBs as defined here. Resolving this misalignment in the results of the two methods is an obvious task for future research."}, {"heading": "Future Directions", "text": "Some important aspects still missing from our framework are the representation of conditional probabilistic information such as is done in the work of Kern-Isberner, and the association of information with its level of entrenchment. On the latter point, when one talks about probabilities or likelihoods, if one were to take a frequentist perspective, information observed more (less) often should become more\n(less) entrenched. Or, without considering observation frequencies, an agent could be designed to have, say, one or two sets of deeply entrenched background knowledge (e.g., domain constraints) which does not change or is more immune to change than \u2018regular\u2019 knowledge.\nGiven that we have found that the belief base resulting from revising via the boundary-belief-states approach differs from the belief base resulting from revising via the representative-belief-state approach, the question arises, When is it appropriate to use a representative belief state defined as the most entropic belief state of a given set \u03a0B? This is an important question, especially due to the popularity of employing the Maximum Entropy principle in cases of undespecified probabilistic knowledge (Jaynes, 1978; Goldszmidt, Morris, and Pearl, 1990; Hunter, 1991; Voorbraak, 1999; Kern-Isberner, 2001; Kern-Isberner and Rdder, 2004) and the principle\u2019s well-behavedness (Shore and Johnson, 1980; Paris, 1994; Kern-Isberner, 1998).\nKatsuno and Mendelzon (1991) modified the eight AGM belief revision postulates (Alchourro\u0301n, Ga\u0308rdenfors, and Makinson, 1985) to the following six (written in the notation of this paper), where \u2217 is some revision operator.3\n\u2022 B\u03b1\u2217 |= (\u03b1) = 1. \u2022 IfB\u222a{(\u03b1) = 1} is satisfiable, thenB\u03b1\u2217 \u2261 B\u222a{(\u03b1) = 1}. \u2022 If (\u03b1) = 1 is satisfiable, then B\u03b1\u2217 is also satisfiable. \u2022 If \u03b1 \u2261 \u03b2, then B\u03b1\u2217 \u2261 B \u03b2 \u2217 . \u2022 B\u03b1\u2217 \u222a {(\u03b2) = 1} |= B \u03b1\u2227\u03b2 \u2217 . \u2022 If B\u03b1\u2217 \u222a {(\u03b2) = 1} is satisfiable, then B \u03b1\u2227\u03b2 \u2217 |= B\u03b1\u2217 \u222a\n{(\u03b2) = 1}. Testing the various revision operations against these postulates is left for a sequel paper.\nAn extended version of maximum entropy is minimum cross-entropy (MCE) (Kullback, 1968; Csisza\u0301r, 1975):\nDefinition 7 (Minimum Cross-Entropy). The \u2018directed divergence\u2019 of distribution c from distribution b is defined as\nR(c, b) := \u2211 w\u2208W c(w) ln c(w) b(w) .\nR(c, b) is undefined when b(w) = 0 while c(w) > 0; when c(w) = 0, R(c, b) = 0, because limx\u21920 ln(x) = 0. Given new evidence \u03c6 \u2208 Lprob , the distribution c satisfying \u03c6 diverging least from current belief state b is\narg min c\u2208\u03a0,c \u03c6 R(c, b).\nDefinition 8 (MCI). Then MCE inference (denoted (MCI)) is defined as\nbMCI \u03b1 := arg min b\u2032\u2208\u03a0,b\u2032 (\u03b1)=1\nR(b\u2032, b).\nIn the following example, we interpret revision as MCE inference.\n3In these postulates, it is sometimes necessary to write an observation \u03b1 as a BB, i.e., as {(\u03b1) = 1} \u2013 in the present framework, observations are regarded as certain.\nExample 9. Suppose the vocabulary is {q, r} and B1 = {(q) \u2265 0.6}. Let \u03b1 be (q \u2227 \u00acr) \u2228 (\u00acq \u2227 r). Then\n\u03a0B1bnd = {{(11, 1.0), (10, 0.0), (01, 0.0), (00, 0.0)}, {(11, 0.0), (10, 1.0), (01, 0.0), (00, 0.0)}, {(11, 0.6), (10, 0.0), (01, 0.4), (00, 0.0)}, {(11, 0.6), (10, 0.0), (01, 0.0), (00, 0.4)}, {(11, 0.0), (10, 0.6), (01, 0.4), (00, 0.0)}, {(11, 0.0), (10, 0.6), (01, 0.0), (00, 0.4)}},\n(\u03a0B1bnd) MCI \u03b1 = {{(11, 0), (10, 0), (01, 1), (00, 0)},\n{(11, 0), (10, 1), (01, 0), (00, 0)}, {(11, 0), (10, 0.6), (01, 0.4), (00, 0)}} and\nB\u03b11bnd = {(\u03c611) \u2264 0, (\u03c600) \u2264 0}. Note that if we let B\u2032 = {((q \u2227 \u00acr) \u2228 (\u00acq \u2227 r)) = 1}, then \u03a0B \u2032 = \u03a0B \u03b1 1bnd .\nRecall from Example 6 that B\u2032 included (q \u2227 \u00acr) \u2265 0.3. Hence, in this particular case, combining the boundary belief states approach with MCI results in a less informative revised belief base than when GI is used. The reason for the loss of information might be due to R(\u00b7, {(11, 1.0), (10, 0.0), (01, 0.0), (00, 0.0)}) and R(\u00b7, {(11, 0.6), (10, 0.0), (01, 0.0), (00, 0.4)}) being undefined: Recall that R(c, b) is undefined when b(w) = 0 while c(w) > 0. But then there is no belief state c for which c \u03b1 and R(\u00b7) is defined (with these two belief states as arguments). Hence, there are no revised counterparts of these two belief states in (\u03a0B1bnd) MCI \u03b1 . We would like to analyse MCI more within this framework. In particular, in the future, we would like to determine whether a statement like Theorem 1 holds for MCI too.\nIn MCE inference, b-consistency of evidence \u03c6 is defined as: There exists a belief state c such that c \u03c6 and c is totally continuous with respect to b (i.e., b(w) = 0 implies c(w) = 0). MCE is undefined when the evidence is not bconsistent. This is analogous to Bayesian conditioning being undefined for b(\u03b1) = 0. Obviously, this is a limitation of MCE because some belief states may not be considered as candidate revised belief states. Admittedly, we have not searched the literature on this topic due to it being out of the present scope.\nAs far as we know, imaging for belief change has never been applied to (conditional) probabilistic evidence. Due to issues with many revision methods required to be consistent with prior beliefs, and imaging not having this limitation, it might be worthwhile investigating.\nThe translation from the set of belief states back to a belief base is a mapping from every belief state to a probability formula. The size of the belief base is thus in the order of |W perm |, where |W | is already exponential in the size of P , the set of atoms. As we saw in several examples in this paper, the new belief base often has a more concise equivalent counterpart. It would be useful to find a way to consistently determine more concise belief bases than our present approach does.\nThe computational complexity of the process to revise a belief base is at least exponential. This work focused on theoretical issues. If the framework presented here is ever used in practice, computations will have to be optimized.\nThe following example illustrates how one might deal with strict inequalities.\nExample 10. Suppose the vocabulary is {q, r} and B3 = {(q) > 0.6}. Let \u03b1 be (q \u2227 \u00acr) \u2228 (\u00acq \u2227 r). Let be a real number which tends to 0. Then \u03a0B3bnd =\n{{(11, 1.0), (10, 0.0), (01, 0.0), (00, 0.0)}, {(11, 0.0), (10, 1.0), (01, 0.0), (00, 0.0)}, {(11, 0.6 + ), (10, 0.0), (01, 0.4\u2212 ), (00, 0.0)}, {(11, 0.6 + ), (10, 0.0), (01, 0.0), (00, 0.4\u2212 )}, {(11, 0.0), (10, 0.6 + ), (01, 0.4\u2212 ), (00, 0.0)}, {(11, 0.0), (10, 0.6 + ), (01, 0.0), (00, 0.4\u2212 )}},\n(\u03a0B3bnd) GI \u03b1 =\n{{(11, 0.0), (10, 0.5), (01, 0.5), (00, 0.0)}, {(11, 0.0), (10, 1.0), (01, 0.0), (00, 0.0)}, {(11, 0.0), (10, 0.3 + ), (01, 0.7\u2212 ), (00, 0.0)}, {(11, 0.0), (10, 0.6 + ), (01, 0.4\u2212 ), (00, 0.0)}, {(11, 0.0), (10, 0.8 + ), (01, 0.2\u2212 ), (00, 0.0)} and\nB\u03b13bnd = {(\u03c611) \u2264 0, (\u03c610) \u2265 0.3 + , (\u03c601) \u2264 0.7 \u2212 , (\u03c600) \u2264 0.0}.\nNote that if we let B\u2032 = {((q \u2227 \u00acr) \u2228 (\u00acq \u2227 r)) = 1, (q \u2227 \u00acr) > 0.3}, then \u03a0B\u2032 = \u03a0B\u03b13bnd .\nIt has been suggested by one of the reviewers that GI could be an affine map (i.t.o. geometry), thus allowing the proof of Theorem 1 to refer to existing results in the study of affine maps to significantly simplify the proof. The authors are not familiar with affine maps and thus leave investigation of the suggestion to other researchers."}, {"heading": "Related Work", "text": "Voorbraak (1999) proposed the partial probability theory (PTT), which allows probability assignments to be partially determined, and where there is a distinction between probabilistic information based on (i) hard background evidence and (ii) some assumptions. He does not explicitly define the \u201cconstraint language\u201d, however, from his examples and discussions, one can infer that he has something like the language LPTT in mind: it contains all formulae which can be formed with sentences in our Lprob in combination with connectives \u00ac,\u2227 and \u2228. A \u201cbelief state\u201d in PTT is defined as the quadruple \u3008\u2126,B,A, C\u3009, where \u2126 is a sample space, B \u2282 LPTT is a sets of probability constraints,A \u2282 LPTT is a sets of assumptions and C \u2286W \u201crepresents specific information concerning the case at hand\u201d (an observation or evidence).4 Our epistemic state can be expressed as a restricted PTT \u201cbelief state\u201d by letting \u2126 = W , B = B, A = \u2205 and\n4Voorbraak (1999)\u2019s \u201cbelief state\u201d would rather be called and epistemic state or knowledge structure in our language.\nC = {w \u2208 W | w \u03b1}, where B is a belief base and \u03b1 is an observation in our notation.\nVoorbraak (1999) mentions that he will only consider conditioning where the evidence does not contradict the current beliefs. He defines the set of belief states corresponding to the conditionalized PPT \u201cbelief state\u201d as {b(\u00b7 | C) \u2208 \u03a0 | b \u2208 \u03a0B\u222aA, b(C) > 0}. In our notation, this corresponds to {(b BC \u03b1) \u2208 \u03a0 | b \u2208 \u03a0B , b(\u03b1) > 0}, where \u03b1 corresponds to C.\nVoorbraak (1999) proposes constraining as an alternative to conditioning: Let \u03c6 \u2208 Lprob be a probability constraint. In our notation, constraining \u03a0B on \u03c6 produces \u03a0B\u222a{\u03c6}.\nNote that expanding a belief set reduces the number of models (worlds) and expanding a PPT \u201dbelief state\u201d with extra constraints also reduces the number of models (belief states / probability functions).\nIn the context of belief sets, it is possible to obtain any belief state from the ignorant belief state by a series of expansions. In PPT, constraining, but not conditioning, has the analogous property. This is one of the main reasons we prefer to constraining and not conditioning to be the probabilistic version of expansion. (Voorbraak, 1999, p. 4)\nBut Voorbraak does not address the issue that C and \u03c6 are different kinds of observations, so constraining, as defined here, cannot be an alternative to conditioning. C cannot be used directly for constraining and \u03c6 cannot be used directly for conditioning.\nW.l.o.g., we can assume C is represented by \u03b1. If we take b GI \u03b1 to be an expansion operation whenever b(\u03b1) > 0, then one might ask, Is it possible to obtain any belief base B\u2032 from the ignorant belief baseB = \u2205 by a series of expansions, using our approach? The answer is, No. For instance, there is no observation or series of observations which can change B = {} into B\u2032 = {(q) \u2265 0.6}. But if we were to allow sentences (constraints) in Lprob to be observations, then we could obtain any B\u2032 from the ignorant B.\nGrove and Halpern (1998) investigate what \u201cupdate\u201d (incorporation of an observation with current beliefs, such that the observation does not contradict the beliefs) means in a framework where beliefs are represented by a set of belief states. They state that the main purpose of their paper is to illustrate how different the set-of-distributions framework can be, \u201ctechnically\u201d, from the standard single-distribution framework. They propose six postulates characterizing what properties an update function should have. They say that some of the postulates are obvious, some arguable and one probably too strong. Out of seven (families of) update functions only the one based on conditioning (Updcond(\u00b7)) and the one based on constraining (Updconstrain(\u00b7)) satisfy all six postulates, where Updcond(\u03a0\nB , \u03b1) := {(b BC \u03b1) \u2208 \u03a0 | b \u2208 \u03a0B , b(\u03b1) > 0} and where they interpret Voorbraak\u2019s (1999) constraining as Updconstrain(\u03a0\nB , \u03b1) := {b \u2208 \u03a0B | b(\u03b1) = 1}. Grove and Halpern (1998) do not investigate the case when an observation must be incorporated while it is (possibly) inconsistent with the old beliefs (i.e., revision).\nKern-Isberner (2001) develops a new perspective of probabilistic belief change. Based on the ideas of Alchourro\u0301n,\nGa\u0308rdenfors, and Makinson (1985) and Katsuno and Mendelzon (1991) (KM), the operations of revision and update, respectively, are investigated within a probabilistic framework. She employs as basic knowledge structure a belief base (b,R), where b is a probability distribution (belief state) of background knowledge and R is a set of probabilistic conditionals of the form A B[x] meaning \u2018The probability of B, given A, is x. A universal inference operation \u2013 based on the techniques of optimum entropy \u2013 is introduced as an \u201cadequate and powerful method to realize probabilistic belief change\u201d.\nBy having a belief state available in the belief base, minimum cross-entropy can be used. The intention is then that an agent with belief base (b, T ) should always reason w.r.t. belief state bT := arg minc\u2208\u03a0,c T R(c, b). Kern-Isberner (2001) then defines the probabilistic belief revision of (b,R) by evidence S as (b,R \u222a S). And the probabilistic belief update of (b,R) by evidence S is defined as (bR,S).5 She distinguishes between revision as a knowledge adding process, and updating as a change-recording process. KernIsberner (2001) sets up comparisons of maximum crossentropy belief change with AGM revision and KM update. Cases where, for update, new information R is inconsistent with the prior distribution b, or, for revision, is inconsistent with b or the context R, are not dealt with (Kern-Isberner, 2001, p. 399, 400).\nHaving a belief state available for modification when new evidence is to be adopted is quite convenient. As Voorbraak (1999) argues, however, an agent\u2019s ignorance can hardly be represented in an epistemic state where a single belief state must always be chosen.\nThe reader may also refer to a later paper (Kern-Isberner, 2008) in which many of the results of the work just reviewed are generalized to belief bases of the form (\u03a8,R), where \u03a8 denotes a general epistemic state. In that paper, she considers two instantiations of \u03a8, namely as a probability distribution and as an ordinal conditional function (first introduced by Spohn (1988)).\nYue and Liu (2008) propose a probabilistic revision operation for imprecise probabilistic beliefs in the framework of Probabilistic Logic Programming (PLP). New evidence may be a probabilistic (conditional) formula and needs not be consistent with the original beliefs. Revision via imaging (e.g., GI) also overcomes this consistency issue.\nEssentially, their probabilistic epistemic states \u03a8 are induced from a PLP program which is a set of formulae, each formula having the form (\u03c8 | \u03c6)[l, u], meaning that the probability of the conditional (\u03c8 | \u03c6) lies in the interval [l, u].\nThe operator they propose has the characteristic that if an epistemic state \u03a8 represents a single probability distribution, revising collapses to Jeffrey\u2019s rule and Bayesian conditioning.\nThey mention that it is required that the models (distributions) of \u03a8 is a convex set. There might thus be an opportunity to employ their revision operation on a representative set of boundary distributions as proposed in this paper.\n5This is a very simplified version of what she presents. Please refer to the paper for details."}, {"heading": "Conclusion", "text": "In this paper, we propose an approach how to generate a new probabilistic belief base from an old one, given a new piece of non-probabilistic information, where a belief base is a finite set of sentences, each sentence stating the likelihood of a proposition about the world. In this framework, an agent\u2019s belief base represents the set of belief states compatible with the sentences in it. In this sense, the agent is able to represent its knowledge and ignorance about the true state of the world.\nWe used a version of the so-called imaging approach to implement the revision operation.\nTwo methods were proposed: revising a finite set of \u2018boundary belief states\u2019 and revising a least biased belief state. We focussed on the former and showed that the latter gives different results.\nThere were two main contribution of this paper. The first was to prove that the set of belief states satisfying Bnew is exactly those belief states satisfying the original belief base, revised. The second was to uncover an interesting conflict in the results of the two belief base revision methods. It is worth further understanding the reasons behind such a difference, as such an investigation could give more insight about the mechanisms behind the two methods and indicate possible pros and cons of each."}, {"heading": "Acknowledgements", "text": "The work of Giovanni Casini has been supported by the Fonds National de la Recherche, Luxembourg, and cofunded by the Marie Curie Actions of the European Commission (FP7-COFUND) (AFR/9181001)."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": null, "creator": "LaTeX with hyperref package"}}}