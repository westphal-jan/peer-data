{"id": "1604.03519", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Apr-2016", "title": "Going Deeper with Contextual CNN for Hyperspectral Image Classification", "abstract": "In filmacion this paper, \u0111\u00e1 we describe a novel deep convolutional neural pinget networks (chinese-english CNN) based approach called contextual wgc-bridgestone deep rut CNN that rom\u00e1n can soundscape jointly d'ampezzo exploit spatial leola and kivi spectral features 40-watt for heao hyperspectral image classification. The kijang contextual deep CNN younesi first concurrently applies pasture multiple barrak 3 - ibp dimensional local martyrology convolutional loria filters with different arzamas-16 sizes jointly exploiting spatial richetti and gainax spectral dje features of a decontaminating hyperspectral retraced image. visva-bharati The initial ammonia spatial 2,586 and spectral equivocation feature maps obtained hyperplastic from applying keiner the variable geopolitical size order-in-council convolutional filters 6.67 are then akuila combined wohlen together to pianura form a truk joint lochiel spatio - spectral samaki feature moldejazz map. affectees The micro joint 1570 feature 3,948 map vitascope representing rich 18.62 spectral marmur and spatial luganda properties ahuntsic of the hyperspectral image tractive is tasers then fed urdaneta through fully 1.4671 convolutional layers that eventually 5.44 predict pereverzeva the cseries corresponding label jailbreaking of reksten each pixel vector. bassinger The devora proposed approach is tested on the pinball Indian Pines loadout data underreporting and 1,139 performance comparison nummer shows k\u00e1n enhanced nobis classification sherie performance theotokis of chania the remixes proposed approach over sol-fa the skeeters current state of the norambuena art.", "histories": [["v1", "Tue, 12 Apr 2016 18:44:34 GMT  (255kb)", "http://arxiv.org/abs/1604.03519v1", null], ["v2", "Fri, 21 Oct 2016 19:39:52 GMT  (440kb)", "http://arxiv.org/abs/1604.03519v2", null], ["v3", "Tue, 9 May 2017 14:21:21 GMT  (917kb,D)", "http://arxiv.org/abs/1604.03519v3", "14 pages"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["hyungtae lee", "heesung kwon"], "accepted": false, "id": "1604.03519"}, "pdf": {"name": "1604.03519.pdf", "metadata": {"source": "CRF", "title": "CONTEXTUAL DEEP CNN BASED HYPERSPECTRAL CLASSIFICATION", "authors": ["Hyungtae Lee", "Heesung Kwon"], "emails": [], "sections": [{"heading": null, "text": "networks (CNN) based approach called contextual deep CNN that can jointly exploit spatial and spectral features for hyperspectral image classification. The contextual deep CNN first concurrently applies multiple 3-dimensional local convolutional filters with different sizes jointly exploiting spatial and spectral features of a hyperspectral image. The initial spatial and spectral feature maps obtained from applying the variable size convolutional filters are then combined together to form a joint spatio-spectral feature map. The joint feature map representing rich spectral and spatial properties of the hyperspectral image is then fed through fully convolutional layers that eventually predict the corresponding label of each pixel vector. The proposed approach is tested on the Indian Pines data and performance comparison shows enhanced classification performance of the proposed approach over the current state of the art.\nIndex Terms\u2014 contextual deep CNN, joint spectral\nand spatial exploitation, hyperspectral classification"}, {"heading": "1. INTRODUCTION", "text": "Recently, deep convolutional neural networks (CNN) [1,2] have been extensively used for a wide range of visual perception tasks, such as object detection, action/activity recognition, etc. Behind the remarkable success of deep CNN on image/video analytics are its unique capabilities of extracting underlying nonlinear structures of image data as well as discerning the categories of semantic data contents by jointly optimizing parameters of the convolutional and fully connected classification layers together.\nLately, there have been increasing efforts to use deep learning based approaches for hyperspectral image classification [3,4]. In [3], stacked autoencoders (SAE) are used to learn deep features of hyperspectral signatures in an unsupervised fashion followed by logistic regression used to classify extracted deep features into their appropriate material categories. Both a representative spectral pixel vector and the corresponding spatial vector obtained from applying principle component analysis (PCA) to\nhyperspectral data over the spectral dimension are acquired separately from a local region and then jointly used as an input to the SAE. In [4], individual spectral pixel vectors are independently fed through simple CNN in which local convolutional filters are applied to the spectral vectors extracting local spectral features. Convolutional feature maps generated after max pooling are then used as the input to the fully connected classification stage for material classification.\nAs can be seen in [3,4], the current state of the art approaches for deep learning based hyperspectral classification fall short of fully exploiting spectral and spatial information together. The two different types of information, spectral and spatial, are more or less acquired separately from pre-processing and then processed together for feature extraction and classification in [3]. [4] also failed to jointly process the spectral and spatial information together by only using individual spectral pixel vectors as input to the CNN.\nIn this paper, inspired by [5], we propose a novel deep learning based approach called contextual deep CNN that uses fully convolutional layers to better exploit spectral and spatial information from hyperspectral data together. At the initial stage of the proposed deep CNN, multiple 3- dimensional local convolutional filters with different sizes are simultaneously scanned through local regions of hyperspectral images generating initial spatial and spectral feature maps. The initial spatial and spectral feature maps are then combined together to form a joint spatio-spectral feature map, which contains rich spatio-spectral characteristics of hyperspectral pixel vectors. The joint feature map is in turn used as input to subsequent fully convolutional layers that finally predict the labels of the corresponding hyperspectral pixel vectors.\nThe main contributions of this paper are as follows:\n1. We present a novel deep CNN architecture called\ncontextual deep CNN that can jointly optimize the spectral and spatial information of hyperspectral images together. 2. The proposed work is one of the first attempts to\nsuccessfully use a very deep fully convolutional neural network for hyperspectral classification."}, {"heading": "2. CONTEXTUAL DEEP CNN", "text": "2.1 The Proposed CNN Network\nWe propose a fully convolutional network (FCN) with 9 convolutional layers for hyperspectral image classification, as shown in Fig. 1. FCN can take as input hyperspectral images of arbitrary size and produce the output with the same size as the input. This means that the network does not need any further post-processing that resizes the output to have the same dimension as the input image for hyperspectral image classification. Fig. 1 illustrates the proposed network architecture. Note that the height and width of all data blobs in the architecture are the same and only their depth changes. No dimension reduction is performed throughout the FCN processing.\nThe first convolutional layer applied to the input hyperspectral image uses an inception module [5] that locally convolves the input image with two convolutional filters with different sizes (1x1xB and 3x3xB where B is the number of spectral bands). The 3x3xB filters are used to exploit local spatial correlations of the input image while the 1x1xB filters are used to address spectral correlations. The output of the first convolutional layer, the two convolutional feature maps, as shown in Fig. 1, are combined together to form a joint feature map used as input to the subsequent convolutional layers. To prevent local spatial information of the input hyperspectral image from spilling over, we do not use convolutional filters, whose size is larger than 3x3xB in the first convolutional layer.\nThe subsequent convolutional layers use 1x1xB filters\nto extract nonlinear features from the joint spatio-spectral feature map. We use two modules from the residual learning approach [6], which demonstrated to ease the training of\ndeep network. The residual learning is to learn layers with reference to the layer inputs using the following formula:\n,}){,( xWxFy i  (1)\nwhere x and y are the input and output vectors of the layers considered. The function F is the residual mapping of convolution filters Wi to be learned. The operation F+x is the element-wise addition of F and x that the size of F and x should be the same. In the proposed architecture, the residual mapping uses two convolutional layers. ReLU (Rectified Linear Unit) makes the first layer in the module to be nonlinear.\nThe 7 th and 8 th convolutional layers have dropout in training, which reduces overfitting by preventing multiple adaptation of training data simultaneously (referred as \u201ccomplex co-adaptations\u201d). The layer combination in the last three convolutional layers is the same as the fully connected layers of Alexnet [1]. ReLU functions follow the inception module, the 2 nd , 3 rd , and 5 th convolutional layers, and two residual learning modules. The output of the first two convolutional layers is normalized by LRN (Local Response Normalization).\n2.2 Learning\nWe randomly sample a certain number of pixels from the hyperspectral image for training and use the rest to evaluate the performance of the proposed network. For each training pixel, we crop surrounding 3x3 neighboring pixels for learning convolutional filters. The proposed network contains 133376 parameters, which are learned from several hundreds of training pixels. To avoid overfitting, we augment the number of training samples four times by mirroring the training samples across the horizontal, vertical, and diagonal axis."}, {"heading": "3. EXPERIMENTAL RESULTS", "text": "The hyperspectral classification performance of the proposed network is evaluated on Indian Pines dataset, which consists of 145x145 and 220 spectral reflectance bands in the 0.4- to 2.45-\u03bcm region of the visible and near infrared spectrum with a spatial resolution of 20m. Indian Pines dataset has 16 classes but we only use 8 classes with a relatively large number of samples. We compare the performance with Hu et al. [4] using a different architecture of deep CNN. For a fair comparison, we randomly select 200 samples for each class and use them as training samples. The rest is used for testing the proposed network. Selected classes and the numbers of training and test samples are listed in Table 1. Since the proposed network is built as the FCN, any hyperspectral image with arbitrary size can be learned and tested.\nTable 2 shows the performance comparison between the proposed network and the baselines. As baselines, we use a\nSVM classifier with RBF kernel and the different architecture of deep CNN in [4]. The proposed network provided improved performance over both the baselines. The ground truth map of the Indian Pines dataset and the classification map obtained by the proposed network are shown in Fig. 2."}, {"heading": "4. CONCLUSIONS", "text": "A fully convolutional neural network that can jointly exploit local spatio-spectral characteristics of hyperspectral images has been proposed. The proposed CNN architecture uses a total of 9 convolutional layers, which are effectively trained using a relatively small number of training samples without overfitting. The proposed network provided enhanced classification performance over the current state of the art using different deep CNN architectures."}, {"heading": "5. REFERENCES", "text": "[1] A. Krizhevsky, I. Sutskever, and G. E. Hinton, \u201cImageNet Classification with deep convolutional neural networks,\u201d NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada\n[2] Deep learning related papers published in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2014-15, European Conference on Computer Vision (ECCV) 2014, International Conference on Computer Vision (ICCV) 2015.\n[3] Y. Chen, Z. Lin, G. Wang, and Y. Gu, \u201cDeep Learning-Based Classification of Hyperspectral Data,\u201d IEEE Journal of Selected topics in applied earth observations and remote sensing, vol 7, No. 6, June 2014.\n[4] W. Hu, Y. Huang, W. Li, F. Zhang, and H. Li, \u201c Deep Convolutional Neural Networks for Hyperspectral Image Classifications,\u201d Journal of Sensors, Vol. 2015, Article ID 258619.\n[5] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke and A. Rabinovich, \u201cGoing Deeper with Convolutions,\u201d CVPR 2015.\n[6] K. He, X. Zhang, S. Ren and J. Sun, \u201cDeep Residual Learning for Image Recognition,\u201d arXiv:1512.03385v1."}], "references": [{"title": "ImageNet Classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Deep Learning-Based Classification of Hyperspectral Data", "author": ["Y. Chen", "Z. Lin", "G. Wang", "Y. Gu"], "venue": "IEEE Journal of Selected topics in applied earth observations and remote sensing, vol 7, No. 6, June 2014.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep Convolutional Neural Networks for Hyperspectral Image Classifications", "author": ["W. Hu", "Y. Huang", "W. Li", "F. Zhang", "H. Li"], "venue": "Journal of Sensors, Vol. 2015, Article ID 258619.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Going Deeper with Convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CVPR 2015.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep Residual Learning for Image Recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv:1512.03385v1.  Figure 2. RGB composition maps of groundtruth (left) of Indian Pines dataset and classification results (right) of the proposed network for the dataset. The legend is listed below the figure.  Corn-notill Corn-mintill Grass-pasture Hay-windrowed Soybean-notill Soybean-mintill Soybean-clean Woods", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1512}], "referenceMentions": [{"referenceID": 0, "context": "Recently, deep convolutional neural networks (CNN) [1,2] have been extensively used for a wide range of visual perception tasks, such as object detection, action/activity recognition, etc.", "startOffset": 51, "endOffset": 56}, {"referenceID": 1, "context": "Lately, there have been increasing efforts to use deep learning based approaches for hyperspectral image classification [3,4].", "startOffset": 120, "endOffset": 125}, {"referenceID": 2, "context": "Lately, there have been increasing efforts to use deep learning based approaches for hyperspectral image classification [3,4].", "startOffset": 120, "endOffset": 125}, {"referenceID": 1, "context": "In [3], stacked autoencoders (SAE) are used to learn deep features of hyperspectral signatures in an unsupervised fashion followed by logistic regression used to classify extracted deep features into their appropriate material categories.", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "In [4], individual spectral pixel vectors are independently fed through simple CNN in which local convolutional filters are applied to the spectral vectors extracting local spectral features.", "startOffset": 3, "endOffset": 6}, {"referenceID": 1, "context": "As can be seen in [3,4], the current state of the art approaches for deep learning based hyperspectral classification fall short of fully exploiting spectral and spatial information together.", "startOffset": 18, "endOffset": 23}, {"referenceID": 2, "context": "As can be seen in [3,4], the current state of the art approaches for deep learning based hyperspectral classification fall short of fully exploiting spectral and spatial information together.", "startOffset": 18, "endOffset": 23}, {"referenceID": 1, "context": "The two different types of information, spectral and spatial, are more or less acquired separately from pre-processing and then processed together for feature extraction and classification in [3].", "startOffset": 192, "endOffset": 195}, {"referenceID": 2, "context": "[4] also failed to jointly process the spectral and spatial information together by only using individual spectral pixel vectors as input to the CNN.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "In this paper, inspired by [5], we propose a novel deep learning based approach called contextual deep CNN that uses fully convolutional layers to better exploit spectral and spatial information from hyperspectral data together.", "startOffset": 27, "endOffset": 30}, {"referenceID": 3, "context": "The first convolutional layer applied to the input hyperspectral image uses an inception module [5] that locally convolves the input image with two convolutional filters with different sizes (1x1xB and 3x3xB where B is the number of spectral bands).", "startOffset": 96, "endOffset": 99}, {"referenceID": 4, "context": "We use two modules from the residual learning approach [6], which demonstrated to ease the training of deep network.", "startOffset": 55, "endOffset": 58}, {"referenceID": 0, "context": "The layer combination in the last three convolutional layers is the same as the fully connected layers of Alexnet [1].", "startOffset": 114, "endOffset": 117}, {"referenceID": 2, "context": "[4] using a different architecture of deep CNN.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "As baselines, we use a SVM classifier with RBF kernel and the different architecture of deep CNN in [4].", "startOffset": 100, "endOffset": 103}, {"referenceID": 2, "context": "[4] 90.", "startOffset": 0, "endOffset": 3}], "year": 2016, "abstractText": "In this paper, we describe a novel deep convolutional neural networks (CNN) based approach called contextual deep CNN that can jointly exploit spatial and spectral features for hyperspectral image classification. The contextual deep CNN first concurrently applies multiple 3-dimensional local convolutional filters with different sizes jointly exploiting spatial and spectral features of a hyperspectral image. The initial spatial and spectral feature maps obtained from applying the variable size convolutional filters are then combined together to form a joint spatio-spectral feature map. The joint feature map representing rich spectral and spatial properties of the hyperspectral image is then fed through fully convolutional layers that eventually predict the corresponding label of each pixel vector. The proposed approach is tested on the Indian Pines data and performance comparison shows enhanced classification performance of the proposed approach over the current state of the art.", "creator": "Microsoft\u00ae Word 2010"}}}