{"id": "1605.05134", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2016", "title": "A Semi-automatic Method for Efficient Detection of Stories on Social Media", "abstract": "doubters Twitter has become nawanagar one of the multipage main sources of news flavonol for setlist many pnh people. pithily As constan\u0163a real - world outrage events shehabi and 793,000 emergencies unfold, chhean Twitter kraprayoon is abuzz with hundreds delaunay of administrator thousands of wenyuan stories pti about the events. impalas Some gack of wgi these stories caecum are harmless, while penclawdd others could koshi potentially goldring be loudness life - saving or sources of flp malicious 40.04 rumors. somtow Thus, herdsman it ephod is critically important to inter-party be able to second-team efficiently then-largest track brookshaw stories fabri that marlena spread composting on elkton Twitter 408,000 during these nestucca events. krone In this thal\u00eda paper, we present computus a cooder novel 73.36 semi - opi automatic bachand tool that rufinus enables users truncata to -40 efficiently cause-and-effect identify berlinger and track stories alluvial about real - tiancheng world events ndash on Twitter. We kbr ran a stolte user study pedroia with kemas 25 aysgarth participants, 3-40 demonstrating that compared to saula more caballos conventional methods, our tool can increase the galuppi speed and launders the accuracy pharmacies with atomium which fattest users can 37.95 track stories about aids-related real - hymenoptera world beginners events.", "histories": [["v1", "Tue, 17 May 2016 12:33:24 GMT  (107kb,D)", "http://arxiv.org/abs/1605.05134v1", "ICWSM'16, May 17-20, Cologne, Germany. In Proceedings of the 10th International AAAI Conference on Weblogs and Social Media (ICWSM 2016). Cologne, Germany"]], "COMMENTS": "ICWSM'16, May 17-20, Cologne, Germany. In Proceedings of the 10th International AAAI Conference on Weblogs and Social Media (ICWSM 2016). Cologne, Germany", "reviews": [], "SUBJECTS": "cs.SI cs.CL cs.IR", "authors": ["soroush vosoughi", "deb roy"], "accepted": false, "id": "1605.05134"}, "pdf": {"name": "1605.05134.pdf", "metadata": {"source": "CRF", "title": "A Semi-automatic Method for Efficient Detection of Stories on Social Media", "authors": ["Soroush Vosoughi", "Deb Roy"], "emails": ["soroush@mit.edu,", "dkroy@media.mit.edu"], "sections": [{"heading": "Introduction", "text": "In recent years, Twitter, a social media platform with hundreds of millions of users, has become a major source of news for people (Stassen 2010). This is especially true for breaking-news about real-world events (Kwak et al. 2010). The 2011 Japanese earthquake, the 2013 Boston marathon bombings, and the 2015 Paris shootings are just three examples of an event where Twitter played major role in the dissemination of information. However, given the great volume of tweets generated during these events, it becomes extremely difficult to make sense of all the information that is being shared. In this paper, we present a semi-automatic tool that combines state-of-the-art natural language processing and clustering algorithms in a novel way, enabling users to efficiently and accurately identify and track stories that spread on Twitter about particular events. The output of our system can also be used by rumor verification systems to substantiate the veracity of rumors on Twitter (Vosoughi 2015).\nA lot of the messages that are posted on Twitter about events are not directly related to any stories about the event itself. For instance, a tweet talking about how scared someone is about an event, does not contain useful information about the event itself. Tweets that are related to a story usually contain assertions. Therefore, our method focused on\nCopyright c\u00a9 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nfirst identifying assertions about events. These assertions could be anything from eye-witness testimony, to false rumors, or reports from the media or law enforcement agencies."}, {"heading": "What is an Assertion?", "text": "An assertion is an utterance that commits the speaker to the truth of the expressed proposition. For example, the tweet, \u201dthere is a third bomber on the roof\u201d contains an assertion, while the tweet, \u201dI hate reporters!\u201d does not (it contains an expression). It has been shown than more than half of tweets about events do not contain assertions (Vosoughi and Roy 2016). Thus, by filtering all non-assertions tweets, we can drastically reduce the number of tweets that need to be analysed for story detection."}, {"heading": "System Overview", "text": "An overview of the system can be seen in Figure 1. In the figure, the modules that are fully automatic are shown in blue while the modules requiring manual input are shown in green. Currently, the system only works on Twitter, though we plan to expand it to cover other publicly available social media platforms, such as Reddit.\nThe first module in the system is a standard boolean query search, specified by the user. The purpose of this query is to limit the scope of the data that is being analysed to one event. This query can be about anything but works best if it is about a well-defined event. For example, in this figure, the query is Boston AND Bombing, which picks out tweets about the 2013 Boston marathon bombings. These tweets are next passed to the \u201cautomatic\u201d parts of the system, an Assertion Detector module and a Hierarchical Clustering module.\nRaw tweets about an event feed directly into the assertion detector, which automatically filters the tweets for only those containing assertions (tweets not containing assertions are discarded at this stage). These tweets are then clustered\nar X\niv :1\n60 5.\n05 13\n4v 1\n[ cs\n.S I]\n1 7\nM ay\n2 01\n6\nin a hierarchical manner, based on the their semantic similarity. In theory, these clusters should mostly contain tweets that are making similar assertions. The hierarchical clusters (and their contents, including the text and the meta-data of the tweets they contain) are passed to the user-facing, interactive exploration tool. The exploration tool can be used to identify, investigate, and track stories, that are spreading about an event on Twitter."}, {"heading": "Detecting Assertions in Tweets", "text": "Assertions are a class of speech-acts. In order to detect assertions in tweets, a speech-act classifier is needed. We manually annotated 7, 000 tweets about several different realworld events. We labelled these tweets as either containing assertions or not. Of the 7, 000 tweets, 3, 290 (47%) of those tweets containing assertions and the rest containing one of the other speech-acts. These tweets were used to train a state-of-the-art supervised Twitter speech-act classifier, developed by Vosoughi et al. (Vosoughi and Roy 2016).\nSince, we were interested in only detecting assertions, we turned the speech-act classifier to a binary assertion classifier (by collapsing all the non-assertion classes into one class). We evaluated the classifier using 20-fold cross validation, with the F-score for classifying assertions being .86. The performance of this classifier is better illustrated by its ROC curve in Figure 2."}, {"heading": "Hierarchical Clustering of Tweets", "text": "The next part in the automatic processing pipeline is the hierarchical clustering of semantically similar tweets, in order to group together tweets making similar assertions. The output of hierarchical clustering can best be described as a dendrogram.At the lowest level of the dendrogram, all tweets belong to their own clusters. At the very root of the tree is a single cluster, containing all the tweets. Users can explore the clusters at any level. A partition lower in the tree (further from the root) would yield more clusters, with each cluster containing fewer number of tweets. Conversely, a partition higher in the tree would yield less clusters, with each containing greater number of tweets. Depending on the event, there could be thousands of clusters at different levels. It will be up to the users to decide how to best cut-off and explore\nthe clusters. For example, if the event in question is a very local event, meaning that there are not many tweets about the event, then perhaps a partition higher in the tree would be more useful and vice-versa.\nHierarchical clustering of text documents is a well-studied problem. However, as was the case with speech-act classification, the noisy, unconventional and most importantly short nature of the language used on Twitter, greatly reduce the performance of conventional hierarchical document clustering methods. Thus, we developed a novel hierarchical clustering method for Twitter, using very recent advances in Twitter natural language processing techniques.\nIn the next sections, we will describe a conventional hierarchical clustering method, followed by our novel method. Both methods were implemented so that the performance of our novel method could be benchmarked."}, {"heading": "Conventional Method", "text": "Generally speaking, there are two strategies for hierarchical clustering:\n\u2022 Agglomerative: This is a \u201dbottom up\u201d approach; each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.\n\u2022 Divisive: This is a \u201dtop down\u201d approach; all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.\nThe complexity of agglomerative clustering is polynomial at O(n3), while the complexity of divisive clustering is exponential at O(2n). Given the potentially large number tweets about an event, we decided to use Hierarchical Agglomerative Clustering (HAC), given its lower complexity.\nTo do any sort of clustering of documents (such as tweets), a similarity function is needed, to measure the similarity between different documents and decide which clusters to merge or divide. A standard metric used to measure similarity between text documents is TF-IDF combined with cosine similarity. TF-IDF is a method of converting text into numbers so that it can be represented meaningfully by a vector. TF-IDF is the product of two statistics, TF or Term Frequency and IDF or Inverse Document Frequency. Using TFIDF, a vector for each document is derived. The set of documents in our collection is then viewed as a set of vectors in a vector space with each term having its own axis. Similarity between two documents is measured using cosine similarity. With this similarity function, we can hierarchically cluster tweets using HAC."}, {"heading": "Novel Method", "text": "TF-IDF, combined with cosine similarity is usually a good method of measuring similarity between documents. However, tweets are short (140 characters), irregular text whose topic-level information can be hardly expressed by TF-IDF representations. An alternative method, is to use a similarity metric that is adapted to this platform.\nTwitter Paraphrase Identification We implemented the Twitter paraphrase identification method proposed recently by Asli Eyecioglu and Bill Keller (Eyecioglu and Keller\n2015) (winners of SemEval-2015 in this category) to measure similarity between pairs of tweets. This method is for identifying Twitter paraphrase pairs, where paraphrase identification is defined as \u201dthe task of deciding whether two given text fragments have the same meaning\u201d. This method takes a pair of tweets and makes a binary judgement on whether these two tweets are paraphrases. For example, the tweets, \u201dAmber alert gave me a damn heart attack\u201d and \u201dThat Amber alert scared the crap out of me\u201d are a paraphrase pair, while the tweets \u201dMy phone is annoying me with these amber alert\u201d, and \u201dAm I the only one who dont get Amber alert\u201d are not a paraphrase pair.\nWe used a dataset called the Twitter Paraphrase Corpus (TPC) (Xu et al. 2014) for training and testing our model. The dataset contains 18K tweet pairs 1K test data, with 35% those pairs being paraphrases, and 65% non-paraphrases. We trained an linear SVM classifier using the features proposed in that paper. These features are based on overlap of word level and character level n-grams. To begin, the text in each tweet is cleaned and represented as a set of tokens, where a token can be a character or word unigram or bigram. The overlap features are then created using set operations: size of the union of the tokens, size of the intersection of the tokens, and the size of the set of tokens.\nOf all the combinations of overlap features, the following six features were shown to be the most informative: union of word unigrams, union of character bigrams, intersection of word unigrams, intersection of character bigrams, sizes of tweet 1 and tweet 2. The linear SVM trained on these features achieved an F-score of .67%. Other than the great performance, this method is very fitted to our use-case since both feature extraction and classification are extremely fast. Given that sometimes the number of tweets about a particular event could be in the millions, this is extremely important.\nAll possible pairs of tweets that make it past our assertion detector (which is ( N 2 ) pairs, N being the number of tweets containing assertions), are passed through this binary classifier, to be classified as paraphrases or not. The results are used to create an undirected graph, with each of the N tweets being represented as a node, and edges between nodes representing paraphrase pairs. This graph is used to construct hierarchical clusters of tweets.\nClustering using Community Detection Given this undirected graph of tweets, we can use efficient community detection methods, to detect communities, or \u201dclusters\u201d of tweets with similar meaning assertions.\nWe used a method called the, Louvain (De Meo et al. 2011) for this purpose. The Louvain method is a simple and efficient method for community detection in very large networks. It uses a greedy optimization method that runs in time O(n log n), outperforming other community detection methods in terms of computation time, while performing on par, if not better, than other methods when it comes to the accuracy and quality of the extracted communities (Aynaud et al. 2013). It is however the speed of this method which is its main advantage, as it takes only two minutes to analyze a typical network of 2 million nodes. This is very important\nfor applications requiring real-time clustering, such as ours. Also, crucial for our task, the Louvain method generates hierarchical structures.\nThe idea behind the method is the greedy optimization of the modularity of the graph. Modularity is defined as a value between \u22121 and 1 that measures the density of links inside communities compared to the links between communities. The method consists of two steps. First, the method looks for \u201dsmall\u201d communities by optimizing modularity locally. Second, it aggregates nodes belonging to the same community and builds a new network whose nodes are the communities. These steps are repeated iteratively until a maximum of modularity is attained and a hierarchy of communities is produced (De Meo et al. 2011). These hierarchical communities are analogous to the hierarchical clusters generated by HAC, in that these communities contain similar assertions."}, {"heading": "Experiments", "text": "Analysis 1 Since our system is semi-automatic, the evaluation is based on user-centric criteria: the accuracy and the speed with which users can identify assertions about a particular event on Twitter. To do this, we used snopes.com to identify several rumors (a rumor is an unverified assertion) that had spread on Twitter for three different events: the 2013 Boston marathon bombings (10 rumors), the 2011 Japanese earthquake (6 rumors), and the 2015 Charlie Hebdo shooting in Paris (5 rumors). We manually collected between 150 to 500 English-language tweets for each rumor. For each event, we also mixed in several hundred random tweets about the event, not related to any of the rumors (in order to mimic a real-world situation where there is a mixture of tweets containing rumors and tweets that do not). In total there were 9,825 tweets across all three events (6,825 about one of the 21 rumors, and 3,000 random tweets about one of the three events).\nWe asked a group of twenty five undergraduates to identify the rumors for each of the events. We divided the subjects into five groups. The first group used a version of our tool that only applied HAC to the data (without any assertion filtering), the second group\u2019s tool applied assertion detection (AD) and HAC to the data (this was an earlier version of our tool (Vosoughi and Roy 2015)), the third group\u2019s tool applied the Louvain clustering method (without assertion filtering), the fourth group\u2019s tool applied AD and Louvain clustering to the data. The fifth group was the control group, their tool did not process the data at all, it put all the tweets (including non-assertions) into one giant cluster. Note that when using any of the hierarchical clustering algorithms, the users were allowed to explore the fully hierarchy. The tool did not decide on the number of clusters (i.e. where to cut the tree).\nThe subjects did not know beforehand how many rumors, if any, the dataset contained. Each person worked independently and was allowed five minutes per event. The time limit was set for two reasons. First, the limit was set in order to mimic a real-time emergency situation, for which our tool is designed. Second, given the relatively small size of the rumor dataset used for this experiment, given enough time, most subjects would be able to correctly identify all or most\nof the rumors using any of the tools, therefore a time-limit was needed to better differentiate between the different versions of the tool.\nAfter the five minutes had passed, we asked them to list the rumors they had identified. For each of the five groups, we averaged the percentage of rumors in our list that they had correctly identified. Figure 3 shows the mean, and the standard deviation of each of the five groups. There was a statistically significant difference between groups as determined by one-way ANOVA (F (4, 20) = 11.283, p < .001). There are three interesting conclusions that one can draw from these results. First, the groups using all versions of our tool outperformed the control group significantly, with the best performing group outperforming the control group by 76%. Second, Louvain based clustering outperformed HAC, both when combine with assertion filtering (by 9%) and when not (by 15%). Second, assertion filtering improved the performance of both Louvain (by 16%) and HAC clustering (by 21%). The best performing tool was the one that combined assertion filtering with Louvain based clustering. Using that tool, the subjects were able to correctly identify 81% of the rumors in five minutes. Though, somewhat simple, this experiment highlights the advantages of our tool, compared to other more conventional methods.\nAnalysis 2 Next, we quantitatively measured the quality of the clusters that are produced by HAC and Louvain clustering methods. For this analysis, we used the same dataset as the first analysis, except we did not mix in random tweets, thus we had a total of 6,825 tweets about 21 different rumors, across 3 events. We ran HAC and Louvain on the dataset and cut the generated trees so that there would be 21 clusters (same as the number of rumors). We then used the adjusted RAND index (Rand 1971) and adjusted mutual information score (Vinh, Epps, and Bailey 2010)\u2013both measures that score the similarity between two data clusterings\u2013 two compare the 21 ground-truth rumor clusters to the clusters produced by HAC and Louvain. Table 1 shows the results. The results are quantitative confirmation that the Louvain is superior to HAC."}, {"heading": "Conclusions", "text": "In this paper, we presented a semi-automatic tool that can be used to efficiently identify stories about real-world events on\nTwitter. This is an important problem since Twitter and other social media platforms have become one of the main sources of news for many people. Given a user-specified query about an event, our tool automatically detects and clusters assertions about that event on Twitter. The system uses a Twitter speech-act classifier, in conjunction with a novel hierarchical clustering method for tweets. Instead of relying on traditional hierarchical methods which perform poorly on tweets, our method works by first creating a similarity graph of tweets (using recent advances in Twitter NLP tools) and then applying a very fast community detection algorithm on the graph. The system is not only faster, but it also provides higher quality clusters (less noisy and more coherent), making it easier for users to quickly sort through thousands of tweets."}], "references": [{"title": "Multilevel local optimization of modularity. Graph Partitioning 315\u2013345", "author": ["Aynaud"], "venue": null, "citeRegEx": "Aynaud,? \\Q2013\\E", "shortCiteRegEx": "Aynaud", "year": 2013}, {"title": "Generalized louvain method for community detection in large networks", "author": ["De Meo"], "venue": "In proceedings of ISDA", "citeRegEx": "Meo,? \\Q2011\\E", "shortCiteRegEx": "Meo", "year": 2011}, {"title": "Asobek: Twitter paraphrase identification with simple overlap features and svms", "author": ["Eyecioglu", "A. Keller 2015] Eyecioglu", "B. Keller"], "venue": "In SemEval", "citeRegEx": "Eyecioglu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Eyecioglu et al\\.", "year": 2015}, {"title": "What is twitter, a social network or a news media", "author": ["Kwak"], "venue": "In proceedings of WWW", "citeRegEx": "Kwak,? \\Q2010\\E", "shortCiteRegEx": "Kwak", "year": 2010}, {"title": "Objective criteria for the evaluation of clustering methods", "author": ["W.M. Rand 1971] Rand"], "venue": "Journal of the American Statistical association", "citeRegEx": "Rand,? \\Q1971\\E", "shortCiteRegEx": "Rand", "year": 1971}, {"title": "Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance", "author": ["Epps Vinh", "N.X. Bailey 2010] Vinh", "J. Epps", "J. Bailey"], "venue": "The Journal of Machine Learning Research", "citeRegEx": "Vinh et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Vinh et al\\.", "year": 2010}, {"title": "A human-machine collaborative system for identifying rumors on twitter", "author": ["Vosoughi", "S. Roy 2015] Vosoughi", "D. Roy"], "venue": "In proceedings of ICDMW", "citeRegEx": "Vosoughi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vosoughi et al\\.", "year": 2015}, {"title": "Tweet acts: A speech act classifier for twitter", "author": ["Vosoughi", "S. Roy 2016] Vosoughi", "D. Roy"], "venue": "In proceedings of the 10th ICWSM", "citeRegEx": "Vosoughi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vosoughi et al\\.", "year": 2016}, {"title": "Extracting lexically divergent paraphrases from twitter. Transactions of the Association for Computational Linguistics 2:435\u2013448", "author": ["Xu"], "venue": null, "citeRegEx": "Xu,? \\Q2014\\E", "shortCiteRegEx": "Xu", "year": 2014}], "referenceMentions": [{"referenceID": 4, "context": "We then used the adjusted RAND index (Rand 1971) and adjusted mutual information score (Vinh, Epps, and Bailey 2010)\u2013both measures that score the similarity between two data clusterings\u2013 two compare the 21 ground-truth rumor clusters to the clusters produced by HAC and Louvain.", "startOffset": 37, "endOffset": 48}], "year": 2016, "abstractText": "Twitter has become one of the main sources of news for many people. As real-world events and emergencies unfold, Twitter is abuzz with hundreds of thousands of stories about the events. Some of these stories are harmless, while others could potentially be lifesaving or sources of malicious rumors. Thus, it is critically important to be able to efficiently track stories that spread on Twitter during these events. In this paper, we present a novel semi-automatic tool that enables users to efficiently identify and track stories about real-world events on Twitter. We ran a user study with 25 participants, demonstrating that compared to more conventional methods, our tool can increase the speed and the accuracy with which users can track stories about real-", "creator": "LaTeX with hyperref package"}}}