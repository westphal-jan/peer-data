{"id": "1605.08412", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2016", "title": "CITlab ARGUS for historical handwritten documents", "abstract": "We diksha describe CITlab ' iberico s mcilwain recognition yiddish system tormented for 12-string the HTRtS competition attached to the 48.41 13. International Conference thekla on 46.14 Document vautier Analysis and Recognition, 3,248 ICDAR completely 2015. The martyring task comprises the 98-93 recognition wakkanai of historical handwritten dissatisfied documents. bescot The foliosa core algorithms of our codice system are tariffs based on rreef multi - fakhrildeen dimensional 3oh recurrent outgrown neural networks (MDRNN) rikka and connectionist hormizd temporal classification (nithsdale CTC ). pinga The minoru software heitmann modules batre behind shames that as kemppinen well as izo the basic 15:52 utility technologies bracket are derain essentially 50.1 powered kepner by lansley PLANET ' anthologie s s\u0142owacki ARGUS piarist framework coolidge for intelligent text recognition doted and image cordon processing.", "histories": [["v1", "Thu, 26 May 2016 19:19:43 GMT  (12kb)", "http://arxiv.org/abs/1605.08412v1", "Description of CITlab's System for the HTRtS 2015 Task : Handwritten Text Recognition on the tranScriptorium Dataset"]], "COMMENTS": "Description of CITlab's System for the HTRtS 2015 Task : Handwritten Text Recognition on the tranScriptorium Dataset", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.NE", "authors": ["gundram leifert", "tobias strau{\\ss}", "tobias gr\\\"uning", "roger labahn"], "accepted": false, "id": "1605.08412"}, "pdf": {"name": "1605.08412.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Gundram Leifert", "Tobias Strau\u00df", "Tobias Gr\u00fcning", "Roger Labahn"], "emails": ["roger.labahn}@uni-rostock.de"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 5.\n08 41\n2v 1\n[ cs\n.C V\n] 2\n6 M\nay 2\n01 6\nCITlab ARGUS for historical\nhandwritten documents Description of CITlab\u2019s System for the HTRtS 2015 Task :\nHandwritten Text Recognition on the tranScriptorium Dataset\nGundram Leifert Tobias Strau\u00df Tobias Gr\u00fcning\nRoger Labahn \u2217\nApril 15, 2015\nWe describe CITlab\u2019s recognition system for the HTRtS competition attached to the 13. International Conference on Document Analysis and Recognition, ICDAR 2015. The task comprises the recognition of historical handwritten documents. The core algorithms of our system are based on multi-dimensional recurrent neural networks (MDRNN) and connectionist temporal classification (CTC). The software modules behind that as well as the basic utility technologies are essentially powered by PLANET\u2019s ARGUS framework for intelligent text recognition and image processing.\nWe describe CITlab\u2019s recognition system for the HTRtS competition attached to the 13. International Conference on Document Analysis and Recognition, ICDAR 2015. The task comprises the recognition of historical handwritten documents. The core algorithms of our system are based on multidimensional recurrent neural networks (MDRNN) and connectionist temporal classification (CTC). The software modules behind that as well as the basic utility technologies are essentially powered by PLANET\u2019s ARGUS framework for intelligent text recognition and image processing.\nKeywords \u2014 MDRNN, LSTM, CTC, handwriting recognition, neural network"}, {"heading": "1 Introduction", "text": "The International Conference on Document Analysis and Recognition, ICDAR 20151, hosts a variety of competitions in that area. Among others, the Handwritten Text Recog-\n\u2217corresponding author; CITlab, Institute of Mathematics, University of Rostock, Germany {gundram.leifert, tobias.strauss, tobias.gruening, roger.labahn}@uni-rostock.de 1http://2015.icdar.org\ncause we expected CITlab\u2019s handwriting recognition software to be able to successfully deal with the respective task.\nHTRtS2 comprises a task of word recognition for segmented historical documents, see [SRTV14] for all further details. These data consist of page images taken from the Bentham collection, a well-known transScriptorium project dataset.\nOur neural networks have basically been used previously in the international handwriting competition OpenHaRT 2013 attached to the ICDAR 2013 conference, see [LLS13]. Moreover, with a system very similar to the one presented here, the CITlab team also took part in ICFHR\u2019s ANWRESH-2014 competition on historical data tables, see [LGSL14] for the according system description.\nAffiliated with the Institute of Mathematics at the University of Rostock, CITlab3 hosts joint projects of the Mathematical Optimization Group and PLANET intelligent systems GmbH4, a small/medium enterprise focusing on computational intelligence technology and applications. The work presented here is part of a common text recognition project 2014 \u2013 2016 and is extensively based upon PLANET\u2019s ARGUS software modules and the respective framework for development, testing and training."}, {"heading": "2 Short Description", "text": "Remark 1. This short description is intended for the HTRtS-2015 organizers\u2019 information. Here we also explain the abbreviations used in the web form when submitting CITlab ARGUS\u2019s recognition result files.\nPlease cite this now as: private communication, extended version to be published after ICDAR 2015.\nThis draft is preliminary in the sense that it will be further extended to a full paper version. It will be published after the ICDAR 2015 conference when the official final evaluation results are public."}, {"heading": "2.1 Overview", "text": "Altogether, CITlab submits the recognition / transcription results generated by 14 moderately different systems. While they all mainly rely on our traditional, recurrent neural network based recognition engine ARGUS, the 14 variations arise from combining 2 training schemes, trn-1 / trn-2, with 7 decoding schemes, dec-BP / dec-CE / dec-DM and\n2http://transcriptorium.eu/~htrcontest 3http://www.citlab.uni-rostock.de 4http://www.planet.de\ndering of the respective labels, also reflect both increasing complexity of the schemes, and expected improved quality for the handwritten text recognition task."}, {"heading": "2.2 Basic Scheme", "text": "For the general approach, we may briefly refer to previous CITlab system descriptions [LLS13, LGSL14, SGLL14] because the overall scheme has essentially not been changed."}, {"heading": "2.3 Preprocessing", "text": "We worked on line polygon images, see 2.4.1 for further explanation of the data. Firstly it were applied certain standard preprocessing routines, i.e.\n\u2022 image normalization: contrast, size; \u2022 writing normalization: line bends, line slope, script slant.\nThen, images were further unified by CITlab\u2019s proprietary writing normalization, thus ensuring a fixed 96px image height with the writing\u2019s main body part appropriately placed into and stretched to cover the essential central part of the line image. These were finally the input images for the subsequent processing with Recurrent Neural Networks (RNN)."}, {"heading": "2.3.1 Recurrent Neural Network", "text": "The resulting line images were fed into the engine\u2019s first core component which we call a Sequence Processing Recurrent Neural Network (SPRNN). Note that we processed entire line images with no further segmentation.\nThe SPRNN\u2019s output then consists of a certain number of vectors. This number is related to the line length because every vector contains information about a particular image position. More precisely, the entries are understood as to estimate the probabilities of every alphabet character at the position under consideration. Hence, the vector lengths all equal the alphabet size, and putting all vectors together leads to the so-called confidence matrix. This is the intrinsic recognition result which will subsequently be used for the decoding.\nNote further that, for HTRtS-2015, we worked with the alphabet containing\n\u2022 all digits, lowercase and uppercase letters of the standard latin alphabet \u2022 special characters /&\u00a3\u00a7+-\\_.,:;!?\u2019\"=[]() and \u2423, whereby different types of quotation\nmarks and hyphens were mapped to one of the respective symbols.\nFinally, the above alphabet is augmented by an artificial, non-character symbol, which we denote by NaC. In particular, it may be used to detect character boundaries because, generally speaking, our SPRNNs emit high NaC confidences in uncertain situations.\nCITlab only participates in the Restricted Track of HTRtS-2015, i.e. for training and testing our systems, we exclusively used data provided within the contest:"}, {"heading": "2.4.1 Training Data", "text": "trn-1 consists of all 1stBatch line polygons, i.e. images of 10 491 line polygons from 433\npages.\ntrn-2 incorporates trn-1 and all 2ndBatch page images: additional 313 pages, for which\nthe line polygons where not available. Using proprietary CITlab tools we extracted 3 968 more line polygons, s.t. altogether, trn-2 finally contained 14 479 training samples.\nNote in particular, that from the data provided in HTRtS-2015, we did not use the line images itself because those covered more distortions between adjacent text lines."}, {"heading": "2.4.2 Network Training", "text": "In both training schemes, various networks have been trained similarly: The number of training epochs slightly varied between 50 and 60, and the decrease of the learning rates was chosen correspondingly. Moreover, different tries differ in certain hyper-parameters (number of neurons, subsampling rate) and random choices of the initial values for weights that were then optimized by gradient descent procedures.\nOut of a larger number of tries, finally 10 networks have been chosen by monitoring the training success on a validation data set which, due to the lack of separate data, was selected from the available training data, see 2.4.1. Note that the same approach has been used for ranking the 10 final nets in order to choose the best and certain committees, see 2.5 for details."}, {"heading": "2.5 Decoding Schemes", "text": "2.5.1 Dec-BP: Best Path decoding\nFor decoding the confidence matrix, one starts with the sequence of the most confident character per matrix vector. But in order to get a proper character string over the given alphabet, then two basic transformations have to be applied:\n1. Replace repeated occurrences of the same character by just one! 2. Delete all NaC symbols!\nserves for distinguishing between proper character repetition vs. just repeatedly seeing the same character while traversing the line image.\nNote also that these operations are commonly applied in all decoding schemes! Thus in the following, we know how to proceed from a character sequence from (or path through) the confidence matrix to a valid string interpretation as a required recognition result.\n2.5.2 Dec-CE: CITlab Expression decoding\nThe details of this decoding developed at CITlab will be presented in upcoming publications. Basically it tries to find the most confident string subject to additional restrictions on the internal structure of valid result strings. In HTRtS-2015, the decoded string should be build from expressions which, e.g., look like usual words, have punctuation marks attached to word expressions, have sentences beginning with capital letters . . . But note particularly, that this decoding scheme only considers expression syntax \u2013 it does not yet incorporate a dictionary!\n2.5.3 Dec-DM: Dictionary Model decoding\nAt this next stage, we include a rather simple language model into the decoding scheme: We try to find the most confident string transcription which belongs to a dictionary. Moreover, besides the string confidences from the recognition result itself, also word frequencies are taken into consideration. For HTRtS-2015, the dictionary with word frequencies was extracted from the available training data.\n2.5.4 Dec-E<n>: n Experts Committee decoding\nThe above Dec-DM scheme is further extended by simultaneously processing the network output of n different SPRNNs. These were choosen by descending recognition quality on the validation dataset, see 2.4.2. For coming to the committee decision, we followed the algorithm proposed in [Fis97]. In HTRtS-2015, we submitted four systems with this decoding scheme type, namely for n \u2208 {2, 3, 4, 5}."}, {"heading": "Acknowledgement", "text": "First of all, the CITlab team really wishes to express its great gratitude to our long-term technology & development partner PLANET intelligent systems GmbH (Raben Steinfeld, Germany) for the extremely valuable, ongoing support in every aspect of this work. Participating in HTRtS-2015 would not have been possible without that! In particular, we continued using PLANET\u2019s software world which was developed and essentially improved in various common CITlab\u2013PLANET projects over previous years.\nwhom we especially thank for ongoing very helpful discussions and his continuous development support.\nBeing part of our current research & development collaboration project, this work was funded by grant no. KF2622304SS3 (Kooperationsprojekt) in Zentrales Innovationsprogramm Mittelstand (ZIM) by Bundesrepublik Deutschland (BMWi).\nFinally, we are indebted to the HTRtS organizers from the PRHLT group at UPV \u2013 in particular Joan Andreu S\u00e1nchez \u2013 for setting up this evaluation and the contest as well as the entire tranScriptorium project for providing all the data."}], "references": [{"title": "A post-processing system to yield reduced word error rates: Recognizer output voting error reduction (rover)", "author": ["J.G. Fiscus"], "venue": "In IEEE Workshop on Automatic Speech Recognition and Understanding,", "citeRegEx": "Fiscus.,? \\Q1997\\E", "shortCiteRegEx": "Fiscus.", "year": 1997}, {"title": "CITlab ARGUS for historical data tables: Description of CITlab\u2019s system for the ANWRESH-2014 Word Recognition task", "author": ["Gundram Leifert", "Tobias Gr\u00fcning", "Tobias Strau\u00df", "Roger Labahn"], "venue": "Technical Report 2014/1,", "citeRegEx": "Leifert et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Leifert et al\\.", "year": 2014}, {"title": "CITlab ARGUS for arabic handwriting: Description of CITlab\u2019s system for the OpenHaRT 2013 Document Image Recognition task", "author": ["Gundram Leifert", "Roger Labahn", "Tobias Strau\u00df"], "venue": "In Proceedings of the NIST 2013 OpenHaRT Workshop [Online],", "citeRegEx": "Leifert et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Leifert et al\\.", "year": 2013}, {"title": "CITlab ARGUS for historical handwritten documents: Description of CITlab\u2019s system for the HTRtS 2014 Handwritten Text Recognition task", "author": ["Tobias Strau\u00df", "Tobias Gr\u00fcning", "Gundram Leifert", "Roger Labahn"], "venue": "Technical Report", "citeRegEx": "Strau\u00df et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Strau\u00df et al\\.", "year": 2014}, {"title": "ICFHR2014 Competition on Handwritten Text Recognition on tranScriptorium Datasets (HTRtS)", "author": ["Joan Andreu S\u00e1nchez", "Ver\u00f3nica Romero", "Alejandro H. Toselli", "Enrique Vidal"], "venue": "In Proceedings of the International Conference on Frontiers in Handwriting Recognition", "citeRegEx": "S\u00e1nchez et al\\.,? \\Q2014\\E", "shortCiteRegEx": "S\u00e1nchez et al\\.", "year": 2014}], "referenceMentions": [], "year": 2016, "abstractText": "We describe CITlab\u2019s recognition system for the HTRtS competition attached to the 13. International Conference on Document Analysis and Recognition, ICDAR 2015. The task comprises the recognition of historical handwritten documents. The core algorithms of our system are based on multi-dimensional recurrent neural networks (MDRNN) and connectionist temporal classification (CTC). The software modules behind that as well as the basic utility technologies are essentially powered by PLANET\u2019s ARGUS framework for intelligent text recognition and image processing.", "creator": "LaTeX with hyperref package"}}}