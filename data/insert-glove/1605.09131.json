{"id": "1605.09131", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-May-2016", "title": "Classification under Streaming Emerging New Classes: A Solution using Completely Random Trees", "abstract": "shazand This l'olympia paper investigates draga\u0161 an irukandji important problem in 40-nation stream jacarandas mining, thieu i. e. , classification orecchiette under streaming zamana emerging hamidiyeh new classes huemul or lothians SENC. The wudi common bellshill approach iriarte is herrlich to miesian treat it nastiest as 11 a varahamihira classification problem patasse and solve it using either a supervised heathfield learner or dalek a semi - lovecraftian supervised learner. We propose an nasstrom alternative approach by using witchdoctors unsupervised practitioners learning dbms as delaurentis the basis to lathom solve this problem. claustrum The SENC maintainer problem can urb be decomposed vi\u1ec7t into percolating three sub bazoum problems: detecting emerging candleholder new classes, kruif classifying for known classes, half-acre and updating 3,164 models roboticist to applicative enable classification of instances of ener the new 59.2 class and detection qni of sittings more 100-1 emerging outfalls new demilitarisation classes. The proposed nullifies method aleksandar employs xochimilco completely larionov random hatuey trees which pressurised have kalt been oceanside shown to roginsky work 76.6 well in demagogue unsupervised learning wipeouts and 0-21 supervised exciton learning n. independently in the doucet literature. bargate This is the photorefractive first economides time, as guoyuan far as cannelton we mantids know, hoeksema that subterfuge completely random issy-les-moulineaux trees are \u00f6vp used roskot as huntsmen a single common chocoholics core to solve serrizuela all mouthfeel three sub 5-series problems: unsupervised october/november learning, geldrop supervised learning spyware and petrolul model update settle in noam data black-naped streams. schafer We hdac1 show that the proposed dramatico unsupervised - incriminating learning - focused method often tauck achieves bowmanville significantly pasquel better chimene outcomes than existing mbewe classification - overbook focused 802,000 methods.", "histories": [["v1", "Mon, 30 May 2016 07:57:41 GMT  (5516kb)", "http://arxiv.org/abs/1605.09131v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["xin mu", "kai ming ting", "zhi-hua zhou"], "accepted": false, "id": "1605.09131"}, "pdf": {"name": "1605.09131.pdf", "metadata": {"source": "CRF", "title": "Classification under Streaming Emerging New Classes: A Solution using Completely Random Trees", "authors": ["Xin Mu", "Kai Ming Ting", "Zhi-Hua Zhou"], "emails": ["zhouzh@nju.edu.cn"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 5.\n09 13\n1v 1\n[ cs\n.L G\nThis paper investigates an important problem in stream mining, i.e., classification under streaming emerging new classes or SENC. The common approach is to treat it as a classification problem and solve it using either a supervised learner or a semi-supervised learner. We propose an alternative approach by using unsupervised learning as the basis to solve this problem. The SENC problem can be decomposed into three sub problems: detecting emerging new classes, classifying for known classes, and updating models to enable classification of instances of the new class and detection of more emerging new classes. The proposed method employs completely random trees which have been shown to work well in unsupervised learning and supervised learning independently in the literature. This is the first time, as far as we know, that completely random trees are used as a single common core to solve all three sub problems: unsupervised learning, supervised learning and model update in data streams. We show that the proposed unsupervised-learningfocused method often achieves significantly better outcomes than existing classification-focused methods. Key words: Data stream, Emerging new class, Ensemble method, Completely Random Trees\nThis paper investigates an important problem in data streams, i.e., classification under streaming emerging new class or SENC. In many real-world data mining problems, the environment is open\n\u2217Corresponding author. Email: zhouzh@nju.edu.cn\nPreprint submitted for review May 31, 2016\nand changes gradually. In the streaming classification problem, some new classes are likely to emerge as the environment changes. The predictive accuracy of a previously trained classifier will be severely degraded if it is used to classify instances of a previously unseen class in the data stream. Ideally, we would like instances of a new class to be detected as soon as they emerge in the data stream; and only instances which are likely to belong to known classes are passed to the classifier to predict their classes.\nIt is assumed that true class labels are not available throughout the entire process, except a training set of known classes which is used to train a classifier (and a detector for new classes) at the beginning of the data stream. After the deployment of the classifier (and the detector), any future updates of the models must rely on the unlabelled instances as they appear in the data stream. Note that this assumption does not prevent the proposed method from using true class labels when they are available. It sets the hardest condition in the SENC problem.\nAn illustrative example is provided in Figure 1 which shows a news image classifier system making predictions in a data stream. Assume that a classifier about news content is built in early 2014, which starts with two classes (money and airplane); then some new classes (football and phone) emerge in two later periods in the data stream. The system must have the ability to detect those new classes and update itself timely in order to maintain the predictive accuracy.\nConceptually, the SENC problem can be decomposed into three sub problems: detecting emerging new classes, classifying known classes, and updating models to enable classification of instances of the new classes and detection of more emerging new classes. For every test instance in a data stream, the detector acts as a filter to determine whether it is likely to belong to a known class.\nIf it is, the instance is passed on to the classifier to produce a class prediction. Otherwise, the instance is declared a new class and placed in a buffer which stores candidates of previously unseen class. When the candidates have reached the buffer size, they are used to update both the classifier and the detector. The process repeats in the data stream after the models are updated.\nThe overall aim of the task is to maintain high classification accuracy continuously in a data stream. Thus, the challenges in the SENC problem are to detect emerging new classes and classify instances of known classes with high accuracy, and to perform model update efficiently in data streams. In order to maintain the model complexity to a reasonable size, model components related to currently inactive classes must be eliminated from the current model.\nWe show that these challenges can be met by using completely random trees, and the proposed method often achieves significantly better outcomes than existing more complicated methods. The proposed method has the following distinguishing features:\n\u2022 The proposed method employs an unsupervised learning method as the basis to solve the\nSENC problem, and has a single common core which acts as distinct unsupervised learner and supervised learner. In contrast, most existing methods treat this problem as a classification problem and employ a supervised or semi-supervised learning approach [MP03, DYZ14] to solve it.\n\u2022 The method explicitly differentiates anomalies of known classes from instances of emerging\nnew classes using an unsupervised learning anomaly detection approach.\n\u2022 The model is updated without the initial training set because the proposed method does not\nneed to train new models for every future model updated. In contrast, most existing methods must keep this training set in order to train new models (e.g., LACU-SVM [DYZ14].)\nNote that most of the existing methods mentioned above are designed to solve part of the SENC problem only. Details are provided in Section 2.\nOur main contribution is the proposal to shift the focus of treating SENC as a classification problem to one based on unsupervised anomaly detection problem. In other words, the focus is shifted from the second sub problem to the first sub problem which is more critical in solving the\nentire problem. This shift brings about an integrated approach to solve all three sub problems in SENC. No such solution exists in the current classification-focused approaches, as far as we know.\nThe rest of this paper is organized as follows: Section 1 describes the intuition of the proposed algorithm. Section 2 reviews the related work. Section 4 and 5 describe related definitions and the details of the proposed algorithm. We report the experimental results in Section 6. The conclusion is provided in the last section."}, {"heading": "1. The intuition", "text": ""}, {"heading": "1.1. Detecting emerging new classes", "text": "The intuition is that anomalies of known classes are at the fringes of the data cloud of known classes, and instances of any emerging new classes are far from the known classes. To detect emerging new classes, we propose to treat instances of any new class as \u201coutlying\u201d anomalies which are significantly different from both instances and anomalies of the known classes.\nThe anomaly detector for the SENC problem must be able to differentiate between these two types of anomalies. The assumption is that anomalies of the known classes are more \u201cnormal\u201d than the \u201coutlying\u201d anomalies. This is a reasonable assumption in this context because only instances of the known classes are available to train the anomaly detector.\nAn anomaly detector often categorises the feature space into two types of regions: anomaly and normal. Following the above idea, we propose to further subdivide each anomaly region into two sub regions: \u201coutlying\u201d anomaly sub region and anomaly sub region: (1) The instances in anomaly sub region is closer to the region of normal instances than instances from emerging new classes as the anomalies and normal instances are generated from the same distribution. (2) \u201cOutlying\u201d anomaly sub region is further away from the normal region and anomaly sub region. A test instance is regarded as belonging to an emerging new class if it falls in the \u201coutlying\u201d anomaly sub region.\nFigure 2 illustrates the normal and anomaly regions constructed by an anomaly detector. The anomaly region is further partitioned into two sub regions. The sub region outside the anomaly sub region is the \u201coutlying\u201d anomaly sub region.\nThe construction of \u201coutlying\u201d anomaly sub regions assumes that anomaly regions can be identified. We show in Section 4.2 that this can be easily achieved using a threshold of the anomaly scores provided by an anomaly detector to categorise all regions into two types: anomaly and normal."}, {"heading": "1.2. Classification and efficient model update", "text": "If we treat the second sub problem, i.e., classification, as having no relation to the first sub problem for detecting emerging new classes, then any classifier can be applied. However, in order to facilitate efficient model update that enables classification of newly detected class and detection of more emerging new classes in data streams, we suggest an integrated approach which has a single common core for both the detection and classification tasks.\nAn unsupervised learner iForest[LTZ08], which induces completely random trees, has enabled us to implement the integrated approach with ease. This is because previous works [FWYM03, LTF05] have shown that, ensemble of completely random trees [Zho12, Chap.3.5], as an extreme case of variable-random trees [LTYZ08], can be successfully applied as a powerful classifier. We use exactly the same completely random trees, generated for the purpose of anomaly detection, for classification. This can be easily achieved by simply recording the class labels (provided in the training set) in each leaf. This is the only additional step that needs to be done in the training process to produce an ensemble of completely random trees that will act as both an unsupervised\nlearner (to detect emerging new classes) and an supervised learner (to classify known classes) in data streams.\nAs the single core for both tasks is completely random trees only, they can be updated easily when a sufficient number of instances of emerging new classes have been detected. The single core also facilitates to maintain the model complexity in a reasonable size by using effective model retiring mechanism and growing mechanism in the model update process.\nIn a nutshell, we introduce a simple and unique method to solve the SENC problem and show that the proposed method can detect emerging new classes and classify known classes with high accuracy, and perform model update efficiently in data streams. Our empirical evaluation shows that it often performs significantly better than existing more complex methods."}, {"heading": "2. Related work", "text": "The SENC problem has the following challenges:\n1. In the extreme case, no true labels except in the initial training set, i.e, true labels are not\navailable after the model deployment.\n2. A prediction must be made immediately for each incoming instance in the stream.\n3. Store no data permanently from the data stream.\n4. Fast model update.\nNote that, as far as we know, there is no an algorithm that using one single core to conquer the whole SENC challenges. We review the related work with respect to these challenges as following.\nClass-incremental learning (C-IL) [ZC02] is a branch of incremental learning which modifies a previously trained classifier to deal with emerging new classes. It has been found to be useful in various applications, e.g., detecting bots [CRT11], face recognition [HAY+07] and video concept detection[YYH07]. C-IL problems includes open set recognition[SdRRSB13], Learning with Augmented Class (LAC)[DYZ14]. All of these works are in the batch mode setting. The SENC problem is a C-IL problem in the data stream context.\nIn addition, many existing methods treat the SENC problem as a classification problem. This is the reason why they have employed supervised learning or semi-supervised learning approaches. Moreover, most of these studies assume that instances of an emerging new class are identified by some other mechanism and focuses on methods to train and incorporate classifiers which can classify new classes incrementally with previously trained classifiers[DYZ14, KOC13]. As a result, no existing methods in C-IL meet the four challenges mentioned above.\nLearning with Augmented Class (LAC) [DYZ14] is a new effort for C-IL and addresses a research gap, i.e., to produce a detector for emerging new classes. Utilising unlabelled instances through semi-supervised learning, LACU-SVM [DYZ14] modifies a previously trained classifier to identify emerging new classes. Assuming the set of unlabelled instances containing sufficient instances of an emerging new class, a trained LACU-SVM can then assign a test instance to either one of the known classes or emerging new class. While it solves the first and second sub problems, it is a batch-mode method that requires to store all training data. Thus, it is not suitable in data streams and does not meet the four challenges.\nThe aim of novel class detection is to identify new data which are not previously seen by a machine learning system during training. This is the first sub problem of SENC. An example of this work in Bioinformatics [SdC04] employs an one-class SVM approach to detect novel classes. It is interesting to note that this approach does not make a distinction between novel class detection and anomaly detection (or outlier detection) [CBK09], which is the identification of items, events or observations which do not conform to an expected pattern in a data set in batch mode. It thus also does not meet the four SENC challenges in data streams.\nThe goal of change point detection is to detect changes in the generating distributions of the timeseries. Many works have been conducted to tackle this problem [BN96] which include parametric methods [DDD05] and non-parametric methods [BD93]. This problem is equivalent to the first sub problem in SENC, without addressing the classification and model update issues. Yet, others have focused on classification in data streams [BHP+09, JA03, KM07], without addressing the emerging new classes problem.\nAnother related work, ECSMiner, [MGK+11] tackles the novel class detection and classification problems by introducing time constraints for delayed classification. ECSMiner assumes that true labels of new emerging class can be obtained after some time delay; otherwise, models cannot be\nupdated. In contrast, our proposed method assumes that no labels are available for the entire duration of a data stream.\nThe SENC problem can be solved by treating the first two sub problems independently by using existing methods, i.e., a new class detector and a known classes classifier. To detect emerging new class, existing anomaly detectors (such as LOF [BKNS00], iForest [LTZ08] and one-class SVM [MP03]) can be employed; and multi-class SVM [CL11]) can be used as an the classifier for known classes. In addition, existing supervised or semi-supervised batch classification methods can be adapted to solve the SENC problem, e.g., One-vs-rest SVM [RK04] and LACU-SVM [DYZ14].\nHowever, all these algorithms do not solve the SENC problem satisfactorily. Table 1 summarizes the ability of these algorithms and the proposed SENCForest to meet the four challenges.\nDetails about those algorithms implemented and the proposed SENCForest are provided in following sections.\nSENCForest is the only one which can meet all four challenges. Only ECSMiner, among existing algorithms, can meet Challenge #3. Note that all existing algorithms assume that true labels are made available after the model deployment at some points in time\u2014unable to meet Challenge #1."}, {"heading": "3. Terminology Definition", "text": "Before introducing the detail of our proposed algorithm, we will give the formal definitions of many important concepts used in this paper.\nDefinition 3.1 Classification under Streaming Emerging new Class (SENC) problem: Given a training data set D = {(xi, yi)} L i=1, where xi \u2208 R d is a training instance and yi \u2208 Y = {1, 2, . . . ,K} is the associated class label. A streaming data S = {(x\u2032t, y \u2032 t)} \u221e t=1, where x \u2032 \u2208 Rd, y\u2032 \u2208 Y \u2032 = {1, 2, . . . ,K,K +1, . . . ,M} with M > K. The goal of learning with the SENC problem is to learn a model f with D initially; then f is used as a detector for emerging new class and a classifier for known class. f is updated timely such that it maintains accurate predictions for known and emerging new classes on streaming data S.\nThe SENC problem can have different variations. The hardest condition is when true class labels are not available throughout the entire process, except that the initial training set of known classes is used to train a classifier (and a detector for new classes) at the beginning of the data stream. A relaxation of this condition produces easier SENC problems. For example, true class labels are available at some intervals in streaming data S. In this paper, we show that the proposed method can deal with the hardest condition (in Section 5.2) as well as some easier conditions (in Section 5.3).\nDefinition 3.2 Scores for test instances: Model f yields a score for a test instance x, which determines x as belonging to either a known class or an emerging new class (i.e., an \u201coutlying\u201d anomaly.)\nDefinition 3.3 Known Class Region and Anomaly Region: Based on the score from f , the feature space is divided into two types of regions : (a) known class regions K which have score \u2265 \u03c4\u0302 , (b) anomaly regions A which have score < \u03c4\u0302 , where \u03c4\u0302 is a threshold.\nDefinition 3.4 Anomalies of Known Classes: Let O = {x1, . . . , xn} be the training instances in an anomaly region A. The center of O is defined as c = 1 n \u2211 x\u2208O x. Let e \u2208 O be the farthest instance from c. A ball B centered at c with radius r = dist(c, e) is an anomaly sub region. Instances which fall into anomaly sub regions are Anomalies of Known Classes.\nDefinition 3.5 Instances of an emerging new class are \u201coutlying\u201d anomalies: Q = A\\B."}, {"heading": "4. The Proposed Algorithm", "text": "In this section, we propose an efficient algorithm to deal with the SENC problem named SENCForest which is composed of SENCTrees and assigns each instance, as it appears in a data stream, a class label: Emerging New Class or one of the known classes. Instead of treating it as a classification problem, we formulate it as a new class detection problem and solve it using an unsupervised anomaly detector as the basis to build SENCForest which will finally act as both unsupervised learner and supervised learner.\nWe provide an overview of the procedure in section 4.1. The pertinent details in the procedure are then provided in the following three sections."}, {"heading": "4.1. SENCForest: An Overview", "text": "SENCForest has four major steps:\n1. Train a detector for emerging new classes. Given the initial training set of known classes D, an unsupervised anomaly detector SENCForest is trained, ignoring the class information, as follows:\n1. Build an iForest [LTZ08].\n2. Determine the path length[LTZ08] threshold \u03c4\u0302 .\n3. Within each region A, construct ball B which covers all training instances which fall into\nthis region. The area of the ball B is anomaly sub region A. Any test instances which fall into B are regarded as anomalies of known classes; those that fall outside B are regarded as instances from an emerging new class.\nThe path length is introduced in iForest[LTZ08], which can be regard as an anomaly score for determining known class region and anomaly region(like Definition 3.3). After training the detector of SENCForest, model SENCForest can yields a new class score for a test instance x through aggregating results of each tree in SENCForest. Detail of iForest will be described in the following section.\nFigure 3 illustrates the regions constructed by an iTree which has axis-parallel boundaries, and the additional subdivision employs a ball to partition each anomaly region into two sub regions. The anomaly sub region outside the ball is the \u201coutlying\u201d anomaly sub region.\n2. Using known class information to build a classifier from a detector. Once the above new class detector is constructed, class distributions based on known class labels are recorded in each K or B region. Each region with class distribution acts as a classifier that outputs the majority class as the classification result for a test instance which fall into the region.\nThe training set is discarded once the training process is completed.\n3. Deployment in data stream. SENCForest is now ready to be deployed in a data stream, and it is assumed that no true class labels are available for model updated throughout the entire data stream. An instance in the data stream is given a class prediction by SENCForest if it falls into K or B region; otherwise, it is identified as an instance from an emerging new class and placed in a buffer of size s.\n4. Model update. The model update process in SENCForest is simple. It begins when the buffer is full. Using instances from the buffer, the same tree growing process is then applied to each leaf of every existing tree until the stopping criterion is satisfied. The rest of the model update process follows the same steps from 1.2 onwards, as described above. Note that the update largely involves newly grown subtrees, i.e., replacing leaf nodes which have the number of instances more than a set limit after taking new instances from the buffer into consideration. Thus, the whole process can be completed quickly. To maintain model size, mechanisms to retire SENCForest are also employed in the model update process.\nSection 4.2 describes the pertinent details of training SENCForest as both unsupervised detector and supervised learner. Deploying SENCForest and model update in data streams are provided in Section 4.3 and Section 4.4, respectively."}, {"heading": "4.2. SENCForest: Training process", "text": "The training procedure to build an SENCForest with both detection and classification functions is detailed in Algorithms 1 and 2. These are the combined step to build iForest[LTZ08] and to produce a classifier from a detector. The trees are then used to determine the path length threshold and to construct \u201coutlying\u201d anomaly regions described following respectively. Note that the procedure is the same as in building iForest, except in line 2 of Algorithm 2. As the trees constructed are not exactly iTrees, we name the trees with the new classification capability, SENCTrees.\nBuild an iForest. The unsupervised anomaly detector iForest [LTZ08] is an ensemble of Isolation Tree (iTrees). \u201cIsolation\u201d is a unique concept in anomaly detection, as each iTree is built to isolate every instance from the rest of the instances in the training set. The idea is based on the fact that since anomalies are \u2018few\u2019 and \u2018different\u2019, they are more susceptible to isolation than normal instances. Hence, an anomaly can be isolated using fewer partitions in an iTree than a normal instance.\nLiu et. al. [LTZ08] show that iTrees can be created using a completely random process to achieve the required isolation. Given a random subsample of size \u03c8, a partition is produced by randomly selecting an attribute and its cut-point between the minimum and maximum values in the subsample. To produce an iTree, the partitioning process is repeated recursively until every instance in the subsample is isolated. An iForest is an ensemble of z iTrees, each generated using a subsample randomly selected from the given training set.\nIn the testing process, an instance having a short path length, which is the number of edges it traversed from the root node to a leaf node of an iTree, is more like to be an anomaly. The average path length from all iTrees is used as the anomaly score for each test instance.\nFor both instances of emerging new class and anomalies of known classes, iForest will produce short path lengths because they all are individually \u2018few\u2019 and \u2018different\u2019 from the known classes.\nIn order words, they are all in the regions with short path length in iTrees. We called this type of region, anomaly region A to differentiate them from normal region K which have long path length.\nIn order to detect emerging new class, we first need to determine a path length threshold to differentiate A from K. Then, build a sub region B in each A region which covers all training instances in the region. As these instances are from known classes, they are anomalies of known classes. These two processes are described in the following paragraph.\nDetermine the path length threshold. As each region in iTree has its own path length, and anomaly regions A are expected to have shorter path length than that from normal regions K, we employ the following method to determine the path length threshold to separate these two types of regions.\nWe produce a list L which orders all path lengths representing all regions in an iTree in ascending order. A threshold \u03c4 in this list yields two sub-lists Ll and Lr. To find the best threshold, we use the following criterion which minimises the difference in standard deviations \u03c3(.):\n\u03c4\u0302 = argmin \u03c4\n|\u03c3(Lr)\u2212 \u03c3(Ll)|\nThe threshold \u03c4\u0302 is used to differentiate anomaly regions A from normal regions K, where the former has low path length and the latter has long path length.\nUsing a tree, Figure 4 shows an example of cumulative distribution for list L and its SDdiff (= |\u03c3(Lr)\u2212 \u03c3(Ll)|) curve. Note that the minimum SDdiff point separates into two clear regions: anomaly and normal regions.\nNote that (i) because threshold \u03c4\u0302 is determined automatically, no additional parameter is introduced; and (ii) this process does not require training data.\nConstruct \u201coutlying\u201d anomaly sub regions. After \u03c4\u0302 is determined, a ball B is constructed using all training instances in every region A of a tree, according to Definitions 3.4 and 3.5.\nWhen balls B have been built for all A regions in every SENCTree, the SENCForest has the first function as an unsupervised detector and is ready to detect instances of emerging new classes.\nA test instance which falls into A but outside B is an \u201coutlying\u201d anomaly, i.e., an instance of an emerging new class.\nProduce a classifier from a detector To incorporate the second function of being a classifier into SENCForest, all we have to do is to record class distribution F [j] in each region from K and B using the training subsample, where F [j] denotes the number of class j instances in a region. Note that this is the only step class labels are required.\nOnce the above training steps are completed, SENCForest is ready to be deployed to a data stream.\nAlgorithm 1 Build SENCForest Input: D - input data, z - number of trees, \u03c8 - subsample size. Output: SENCForest\n1: initialize: SENCForest \u2190 {} 2: for i = 1, . . . , z do 3: Xi \u2190 sample(D,\u03c8) 4: SENCForest \u2190 SENCForest \u222a SENCTree(Xi) 5: end for"}, {"heading": "4.3. Deployment in data stream", "text": "Given a test instance x, SENCForest(x) produces a class label y \u2208 {b1, . . . , bm, NewClass}, where m is the number of known classes thus far and NewClass is the label given for an emerging new\nAlgorithm 2 SENCTree Input: X - input data, MinSize - minimum internal node size Output: SENCTree\n1: if |X| < MinSize then 2: return LeafNode{|X|, F [\u00b7], c, r}, as defined in Section 4.2.\n3: else 4: let Q be a list of attributes in X 5: randomly select an attribute q \u2208 Q 6: randomly select a split point p from max and min values of attribute q in X 7: XL \u2190 filter(X, q \u2264 p) 8: XR \u2190 filter(X, q > p) 9: return inNode{Left \u2190 SENCTree(XL),\n10: Right \u2190 SENCTree(XR), 11: SplittAtt \u2190 q, 12: SplittValue \u2190 p },\n13: end if\nclass. Note that though SENCForest can detect instances of any number of emerging new classes, they are grouped into one new class for the purpose of model update. We will focus on model update on one new class in one period (but multiple new classes could emerge in different periods of a data stream) for the rest of the paper. We discuss the issue of model update for multiple new classes in Section 5.4.\nAlgorithm 3 describes the testing process during the deployment of SENCForest in a data stream.\nIn line 3 of Algorithm 3, SENCForest(x) outputs the majority class among all classes produced from z trees. A tree outputs NewClass if test instance x falls into an A region but outside the B region; otherwise, it outputs the majority of class from\nargmax j\u2208{b1,...,bm} F [j]\nwhere F [j] is the class frequency for class j recorded in the region (K or B) into which x falls.\nIf SENCForest(x) outputs NewClass, x is placed in buffer B which stores the candidates of the previously unseen class (line 5). When the number of candidates has reached the buffer size, the\ncandidates are used to update both the classifier and the detector (line 7). Once these updates are completed, the buffer is reset and the new model is ready for the next test instance in the data stream.\nAlgorithm 3 Deploying SENCForest in data stream Input: SENCForest, B - buffer of size s Output: y - class label for each x in a data stream\n1: while not end of data stream do 2: for each x do 3: y \u2190 SENCForest(x) 4: if y = NewClass then 5: B \u2190 B \u222a {x} 6: if |B| \u2265 s then 7: Update (SENCForest, B) 8: B \u2190 NULL 9: m\u2190 m+ 1\n10: end if\n11: end if 12: Output y \u2208 {b1, . . . , bm, NewClass}. 13: end for\n14: end while"}, {"heading": "4.4. Model Update", "text": ""}, {"heading": "4.4.1. Growing Mechanism", "text": "There are two growing mechanisms: one for growing a subtree in an SENCTree, and the other for the growing multiple SENCForests.\nGrowing a subtree in an SENCTree . Updating SENCForest with buffer B is a simple process of updating each leaf node in every tree using \u03c8 instances, randomly selected from B. This is depicted in Algorithm 4. The update at each node (line 10) involves either a replacement with a newly grown subtree or a simple update of the class frequency to include the new class bm+1.\nAlgorithm 4 Update SENCForest Input: SENCForest - existing model, B - input data Output: a new model of SENCForest\n1: initialize: All instances in B are assigned a new class bm+1 2: for i = 1, ..., z do 3: B\u2032 \u2190 sample(B, \u03c8) 4: Tree \u2190 SENCForest.Tree[i] 5: for j = 1, ...,Tree.LeafNodeNumber do 6: X \u2032 \u2190 instances of B\u2032 which fall into Tree.LeafNodej 7: if |X \u2032| > 0 then 8: X \u2190 Pseudo instances from Tree.LeafNodej 9: X \u2032 \u2190 X \u2032 \u222aX\n10: Tree.LeafNodej \u2190 SENCTree(X \u2032) 11: end if\n12: end for 13: recalculate \u03c4\u0302 for Tree 14: SENCForest.Tree[i] \u2190 Tree\n15: end for\nIf there are some instances which fall into a leaf node, a subtree needs to be grown as follows. As the previous training set is not stored, pseudo instances are generated for the leaf node which have the same attribute-values as centre c. The number of pseudo instances for each class j is as recorded in F [j]. The combined set of pseudo instances X and X \u2032 (i.e., the subset of B\u2032 which falls into the same leaf node) is used as input to SENCTree (line 10). An example procedure is depicted in Figure 5. In the top left figure, we assume that some emerging new class instances (green triangle) fell into node 1 (there are three instances fell into in training process) in an SENCTree. Then the combined set consists of pseudo instances and instances of the emerging new class. A new subTree is built by using the combined set. Finally, in the bottom left figure, node 1 is replaced with this new subTree. Every leaf node goes through the same process.\nNote that the update process retains the original tree structure, and all pseudo instances in a leaf node will still be placed into a single leaf node of the newly grown subtree. Thus, the predictions for the known classes are not altered in the model update process.\nOnce each tree has completed the model update, \u03c4\u0302 is recalculated as described in Section 4.2.\nGrowing multiple SENCForests. When the number of classes in a SENCForest reaches \u03c1, its SENCTrees will stop growing for any emerging new class. A new SENCForest is grown instead for the next \u03c1 emerging new classes. This user-defined parameter is set based on the memory space available.\n4.4.2. Prediction using Multiple SENCForests\nIn a model with multiple SENCForests, the final prediction is resolved as follows. For a given x, SENCForest i yields prediction yi and probability\npi = Number of SENCTrees predicting yi\nTotal number of SENCTrees\nThe final prediction is NewClass only if all SENCForests predict x as belonging to NewClass. Otherwise, the final prediction is the known class which has the highest pi. This procedure is given in Algorithm 5.\nAlgorithm 5 Final Prediction from E SENCForests Input: x - an instance in the data stream Output: y\u0131 - class label for x\n1: for i = 1, ..., E do 2: \u3008yi, pi\u3009 \u2190 SENCForesti(x) 3: end for 4: if \u2200i yi = NewClass then 5: \u0131 \u2190 1\n6: else 7: L\u2190 {i \u2208 {1, . . . , E} | yi 6= NewClass} 8: \u0131\u2190 argmaxi\u2208L pi 9: end if\n10: Output y\u0131"}, {"heading": "4.4.3. Retiring Mechanism", "text": "A mechanism to retire SENCForest is required as the data stream progresses. A SENCForest is retired under the following scenarios:\n1. When a SENCForest is not used for predicting known classes for a certain period of time, it\nis eliminated for any future predictions. In other words, a SENCForest outputs \u201cNewClass\u201d for a long time, this SENCForest will be retired\n2. In the event that the number of SENCForests has reached the preset limit \u03c1 and no SENC-\nForest can be retired based on (1), then the least used SENCForest in the last period is chosen to retire.\nThe number of known class predictions is recorded for each SENCForest in data stream. The one which has made the minimum number of predictions for known classes is identified to be the least used SENCForest."}, {"heading": "5. Experiment", "text": "This section reports the empirical evaluation we have conducted to assess the performance of SENCForest in comparison with several state-of-the-art methods."}, {"heading": "5.1. Experimental Setup", "text": "Data Stream: To simulate emerging new classes in a data stream, we assume that an initial training set with two known classes are available to train the initial models. When the trained\nmodels are deployed at the beginning of a data stream, instances of the two known classes and an emerging new class appear in the first period of the data stream with uniform distribution. It is assumed that the method employed will update its models sometime within the first period. In the second period, instances of the three classes seen in the first period and another emerging new class appear with uniform distribution. Instances appear one at a time, and the deployed method is expected to make a prediction for each instance before processing the next, i.e., each instance is predicted as belonging to either an emerging new class or one of the known classes thus far.\nNo true class labels for all instances are available throughout the entire data stream.1 Model update is based on the instances of the emerging new class identified at the time the model update is triggered.\nFigures 6 and 7 show example data streams using the KDDCUP 99 data set and the MNIST data set. The class composition in the two distinct periods in the data stream are described as follows:\n1This is a more stringent condition than previous studies (e.g., [MGK+11]) which assume that true labels are\navailable for model update, after some time delay.\nIn the first period, all instances of the emerging new class identified by a method is placed in a buffer B of size s. When the buffer is full (marked as t1), the method updates its model before processing the next instance. Note that t1 differs for different methods as their detection rates for the new class are different, as shown in Figures 6(b) and 6(c) for iForest+SVM and SENCForest (so as in Figures 7(b) and 7(c).) The buffer is reset to be empty when the model of a method has been updated. Note that after the model is updated, the new class in t0 - t1 becomes a known class b3 of the updated model in t1 - t2, as shown in the table above.\nSimilarly, in the second period between t2 and t4, t3 is the time when the buffer is full and the model of a method is updated for the second time. The new class in t2 - t3 becomes a known class b4 of the updated model in t3 - t4.\nFigure 8 shows the information of the evolving SENCForest at three different times in the data stream on two data sets.\nEvaluation measures: To evaluate the predictive accuracy of algorithms in the SENC problem, we introduce EN Accuracy in a fixed window size. Let N be the total number of instances in a window; An be the total number of emerging class instances identified correctly; and Ao be the\ntotal number of known class instances classified correctly,\nEN Accuracy = An +Ao\nN\nFigures 6(a) and 7(a) show examples of EN Accuracy results of three methods in a data stream.\nTo evaluate the accuracy of new class detection, we compute F-measure in t0 - t1 and t2 - t3 to measure the detection performance in these two durations. This measure produces a combined effect of precision (P) and recall (R) of the detection performance. F-measure = 1 if a detector identifies all instances of emerging new class with no false positives.\nF-measure = 2 \u2217 P \u2217R\nP +R\nThe cumulative numbers of instances of the true and predicted new class are also plotted in four consecutive durations. In t1-t4, it shows that both methods make some false positives resulting in more instances predicted as belonging to the new class than it actually has. The F-measures achieved by each detection method in t0-t1 and t2-t3 are shown in Figures 6(b) & 6(c) and Figures 7(b) & 7(c). In this example, SENCForest performs better than iForest+SVM because it has better F-measure, fewer false positives and higher EN Accuracy.\nIn the experiments reported in Section 5.2, the difference in performance between two methods is considered to be significance on paired t-tests at 95% significance level in our paper\nContenders: The complete list of the methods used for new class detection, classification and model update methods is shown in Table 2. As some of these methods can act as a new class detector only, a state-of-the-art classifier, i.e., multi-class SVM [CL11], is employed to classify instances of known classes. Note that three types of information, additional to that was provided to SENCForest, are required for other methods. First, true labels must be provided at each model update. Otherwise, no models could be updated. ECSMiner assumes that true labels are given at the end of a fixed interval (Tl) in order to update model. Other existing methods requires all instances in B must be given the true labels. Second, LACU-SVM needs to have additional unlabelled data before training at each model update. Third, the initial training set must be stored and incorporated at each model update. SENCForest is the only method which does not require (i) true labels during the entire data stream after training, (ii) to store the initial training set, and (iii) unlabelled training set.\nA brief description of each of the methods used in the experiment is given as follows:\n1. LOF or Local Outlier Factor [BKNS00] is a density-based anomaly detector which employs\nk-nearest neighbour procedure to estimate density.\n2. One-class SVM [SPST+01] is a state-of-the-art outlier detector [MP03] which learns from\nnormal instances only. It computes a binary function to capture regions in input space where the probability density lives.\n3. One-vs-rest SVM is a scheme for multi-class classification [RK04] where a two-class SVM\nfk(\u00b7) is built for each class. In the original One-vs-rest SVM, a test instance x is predicted as belonging to class k if fk(\u00b7) produces the highest confidence. To adapt One-vs-rest SVM to predict the emerging new class, the classifier produces a classification prediction only if maxk fk(x) > 0; otherwise x is predicted as belonging to the emerging new class.\n4. LACU-SVM [DYZ14] is a semi-supervised learner which modifies a previously trained\nmodel by considering the structure presented in the unlabelled data so that the misclassification risks among the known classes as well as between the new and the known classes are minimized simultaneously. It produces a classifier which predicts one of the known classes or the new class. This method also trains k binary classifiers fk(\u00b7) for each known class. Like\nOne-vs-rest SVM, LACU-SVM makes a prediction for the known class if maxk fk(x) > 0; otherwise x is predicted as belonging to the emerging new class.\n5. ECSMiner [MGK+11] is an algorithm for novel class detection and classification. It em-\nploys the clusters identified by k-means to detect novel classes: instances which are not within the boundaries of any clusters are treated as novel class candidates and placed in a buffer, then a new measure is defined to decide whether they are emerging new classes. K nearest neighbor is used as the classifier to make predictions for instances of known classes. Model update can only occurs if true labels are available within some fixed duration.\n6. iForest [LTZ08] is an unsupervised anomaly detector which builds a model to isolate each\ntraining instance from the rest of the training set.\nIn the experiments, all methods were executed in the MATLAB environment. The following implementations are used: SVM in the LIBSVM package [CL11]; LACU-SVM and iForest were the codes as released by the corresponding authors; and LOF is in the outlier detection toolbox.2 The ECSMiner code is completed based on the authors\u2019 paper [MGK+11]. We set the max size of each tree to 300, which avoids to the worst case that growing infinitely by random partition. The parameter settings used for these algorithms are provided in Table 5 in Appendix A.\nData sets: Five data sets are used to assess the performance of all methods , including Synthetic, KDDCup 993, Forest Cover4, MHAR and MNIST5. For KDDCup 99 data set, we use the four largest classes, i.e., normal, neptune, smurf and back. For Forest Cover data set, we use 10 attributes, and all binary attributes are removed. A description for Synthetic and MHAR data sets are provided in Appendix B. A summary of the data characteristics is provided in Table 3.\nSimulation: In the following experiment, each data set is used to simulate a data stream over ten trials. In each trial, the initial training set has two classes, and the emerging new class in each period is a class different from the known classes. These classes are randomly selected from the available classes. The instances in the initial training set and the data sequence in the data\n2https://goker.wordpress.com/2011/12/30/outlier-detection-toolbox-in-matlab/ 3http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html 4https://kdd.ics.uci.edu/databases/covertype/covertype.data.html 5http://cis.jhu.edu/ sachin/digit/digit.html\nstream are randomly selected from the given data set, but following uniform class distribution. For all real-world data sets, the data size of the initial training set D is 500 per class; the buffer size |B| = 250; and the total number of instances which have appeared in the data stream at the end of the first period at t2 is 1000; and the second period (t2 - t4) has a total of 1500 instances. As we can afford to generate more data in the synthetic data set, D, B, and the data size at each period are double to examine the effect of larger data sizes. The average result of ten trials is reported.\nThe following sections will give related evaluation results. Section 5.2 describes the empirical evaluation under the condition that no true labels are available after the data stream has started. Section 5.3 reports results under the long streams situation. Section 5.4 describes using SENCForest under the condition that emerging multiple new classes in a period."}, {"heading": "5.2. Empirical results", "text": "The results for the five data sets are shown in Figure 9.\nIn terms of new class detection, SENCForest produced the highest F-measure in all data sets. Recall that SENCForest+SVM uses SENCForest only for new class detection; thus both SENCForest and SENCForest+SVM have the same F-measure performance.\nThe closest contenders are LACU-SVM and 1R-SVM, each had the second or third highest Fmeasure in three data sets. SENCForest was significantly better than all contenders, except in MNIST (wrt LACU-SVM) and Forest Cover (wrt ECSMiner).\nIn terms of EN Accuracy, SENCForest and SENCForest+SVM produced the highest performance in all data sets. This result shows that (i) the accurate detection of emerging new class leads directly to high classification accuracy; and (ii) SENCForest as a classifier is competitive to SVM. LACU-SVM was the closest contender which had the second highest accuracy in three data sets. Beside SENCForest+SVM, SENCForest performed significantly better than the other contenders in three data sets. The two exceptions are wrt to LACU-SVM (in MNIST and Synthetic) and 1R-SVM (in Synthetic).\nAn analysis is provided below:\n\u2022 LOF and one-class SVM: the poor detection performance of these two methods wrt to\niForest is likely to be due to the parameter search, i.e., a search for a wider range of values may improve their performance. However, such search is a computationally expensive process, and this makes them unsuitable for data stream applications.\n\u2022 iForest performed worse than SENCForest in all data sets, and the differences were sig-\nnificance in four data sets. This shows that an unsupervised anomaly detector can be successfully used in the SENC problem if anomaly regions are reshaped (as described in Sections 4.2) to detect emerging new classes.\n\u2022 While One-vs-rest SVM performed reasonably well in classification, it is not a good choice\nfor detection of emerging new classes, in comparison with SENCForest.\n\u2022 LACU-SVM is the only method which requires additional unlabelled instances in training\nthe initial model and in every model update. While obtaining unlabelled instances may not be a problem in real applications, it is important to note that its detection performance is highly depended on the existence of a new class in the set of unlabelled instances. Insufficient instances of the new class will severely limit LACU-SVM\u2019s ability to detect the new class. In the experiment, LACU-SVM was provided a set of unlabelled instances in t0, t1 and t3, in addition to those instances in the initial training set and the buffer, in order to update its model. This additional data set was not available to all other methods. Despite this additional training information, LACU-SVM still performed significantly worse than SENCForest in four data sets in terms of F-measure.\n\u2022 ECSMiner is the only algorithm which was provided with true labels in order to train a\nnew classifier in each fixed interval, which occurs more often than at each model update, over the entire data stream. Despite this advantage, it still performed significantly worse than SENCForest in four out of five data sets in both measures.6\n\u2022 The result of None+SVM clearly shows that not using a detector is not an option in the\nSENC problem.\n\u2022 SENCForest is the best choice detector and a competitive classifier in the SENC problem.\n6ECSMiner [MGK+11] had employed the KDD CUP 99 and Forest Cover datasets in their evaluation. Our ECSMiner results are compatible with theirs in these two datasets. However, ECSMiner performed poorly in the other three datasets.\nWhile it is possible that a more sophisticated classifier may yield a higher accuracy in classifying known classes, it often comes at a high computational cost in an extensive parameter search.\n\u2022 While using SVM, in addition to SENCForest, could potentially produce a better accuracy\nthan that from SENCForest alone, this comes with a computational cost which is usually too expensive in the data streams context. Note that to achieve the performance of SENCForest+SVM presented in Figure 9, it needs to store all instances thus far, which is impossible in data streams. In contrast, SENCForest achieves comparable result as SENCForest+SVM without the need to store any data.\n5.3. SENCForest in long data streams\nThe aims of this section are to examine the ability of SENCForest to (i) maintain good performance using limited memory in long data streams; and (ii) make use of true class labels when they are available.\nWe simulate a long data stream using the MNIST data set. This stream has twelve emerging new classes7. The initial training data set has 2 classes, and every subsequent period has 1000 instances from one emerging new class and two known classes. The maximum number of classes which can be handled by each SENCForest is set to 3. Other settings are the same as used in the last section. In addition, true class labels are assumed to be available in Q percentage of instances in the buffer before a model update. SENCForest with Q = 0%, 50% and 100% are compared with LACU-SVM in the experiment. Recall that, as in the previous experiment, LACU-SVM is given 100% true labels at each model update and an additional set of unlabelled instances; and ECSMiner is also provided with 100% true labels at each model update.\nFigure 11 shows the average number of leaves of each SENCForest at the start of each time period. Note that a new SENCForest was produced at periods 2, 5, 8, 11, and the first two SENCForests, A and B, were retired at periods 8 and 11, respectively. Table 4 shows the further\n7Classes are reused in the simulation when they are no more in use in the current period. Because this simulation needs a number of classes, that is why only the MNIST dataset, out of the five datasets, can be used in the long stream simulation.\ninformation about SENCForests(Q = 0%) at the start of each time period. The first three rows provide the overall information; and the last three lines show the detailed information of the only evolving SENCForest at each time period, e.g., periods 2, 3, 4 for SENCForestB , periods 5, 6, 7 for SENCForestC and so on. Note that the number of leaves in anomaly regions may decrease as SENCForest grows. This happens when instances of new classes fall into few leaves only.\nThe number of SENCForests is maintained at a preset memory limit through retiring not-in-use SENCForests. Note that the model size is constrained within the set limit of three SENCForests which allows the proposed method to deal with infinite data streams. In contrast, LACU-SVM continues to demand larger and larger memory size to accommodate larger training set size as the stream progresses.\nThe result in Figure 10 (a) shows that SENCForest with Q = 0% maintains good predictive accuracy over the long stream. SENCForest is able to make use of true class labels to improve its performance along the stream. The extent of the improvement increases as Q increases. In contrast, the predictive accuracy of ECSMiner and LACU-SVM continued to decrease as the stream progressed.\nAs a result, as shown in Figure 10(b), its training time continued to grow as the stream progressed. ECSMiner has the least model update time, because k-nearest neighbor is as base learner, which only spends time in building the clusters in buffer. But, that means it needs to save the cluster summary of each cluster into memory."}, {"heading": "5.4. Multiple new classes in a period", "text": "The emergence of multiple new classes in a period is a challenge in the SENC problem. Although SENCForest is designed to deal with one emerging new class in each period, it can still perform well by treating these emerging classes in a period as a single new class. Figure 12 shows that SENCForest performs as well when every period has two emerging new classes. In this stream, there are three periods; each period has 2000 instances and 4 classes (i.e., two emerging new classes and two known classes).\nIn the event that it is important to identify each class in each period, a clustering algorithm[Agg13] can be used to achieve this aim before proceeding to do the model update."}, {"heading": "6. Conclusions and future work", "text": "This paper contributes to decompose the SENC problem into three sub problems and posits that the ability to tackle the first sub problem of detecting emerging new classes effectively is crucial\nfor the whole problem. The difficulty of the SENC problem is highlighted by the inability of existing methods to solve it satisfactorily.\nWe show that the unsupervised-anomaly-detection-focused approach, coupled with an integrated method using completely random trees, provides a complete solution for the entire SENC problem. The current classification-focused approach has failed to provide one thus far.\nThe strength of SENCForest is its ability to detect new class with high accuracy. The use of an unsupervised anomaly detector, incorporated with the new ability to differentiate between anomalies of known classes and instances of new classes, underlines the source of the strength. Existing supervised and semi-supervised methods are unable to achieve the same level of detection accuracy because the focus was on the second sub problem: classification, rather than the first sub problem: emerging new class detection.\nThe fact that the unsupervised learner consists of completely random trees facilitate the use of a common core which can be converted to an effective classifier with ease. The common core also makes model updates in data streams to be a simple model adjustment, rather than training a completely new model as in most existing methods. Like in previous work, we show that the completely random trees are a classifier competitive to state-of-the-art classifiers, especially in the data stream context which demands fast model update and classification time.\nOur empirical evaluation shows that SENCForest outperforms eight existing methods, despite the fact that it was not given the true class labels in the entire data stream; and other methods were given the true class labels at each model update. In addition, it works effectively in long stream with emerging new classes under the limited memory environment. No existing methods have the capability to work under the same condition, as far as we know.\nIn the future, we plan to improve the proposed method to deal with concept drift and to differentiate two or more emerging new classes before model updates. From a broader perspective, the proposed method is the first implementation of the unsupervised-anomaly-detection-focused approach to the SENC problem. We intend to explore other implementations of the same approach."}, {"heading": "7. appendices", "text": ""}, {"heading": "7.1. Parameter settings", "text": "The parameter settings of all algorithms used in the experiments are provided in Table 5. A 10-fold cross-validation on the training set is used in the parameter search to determine the final settings for all SVM algorithms. The parameter search for LOF is as described in [DYZ14]. ECSMiner employs K-means and K is set to 5 in the experiment."}, {"heading": "7.2. Descriptions of data sets", "text": "Synthetic: We simulate a data stream using a two dimensional synthetic data set as shown below. It contains 20,000 instances and has four overlapping Gaussian distribution. The first two\n0 5 10 15\n0\n5\n10\n15\n20\nX\nY\ninitial known classes are marked with purple. In the first period, instances of class blue emerge as the first new class. In the second period, instances of class red emerge as the second new class.\nMHAR: This data set [AGO+12] is collected from 30 volunteers wearing a smart phone on the waist and performing 6 activities (walking, upstairs, downstairs, standing, sitting, laying). The embedded 3D-accelerometer and 3D-gyroscope of a Samsung Galaxy S2 smart phone were used to collect data at a constant rate of 50 Hz. This data set has 6 classes, 10299 instances and 561 attributes."}], "references": [{"title": "A survey of stream clustering algorithms. In Data Clustering: Algorithms and Applications, pages 231\u2013258", "author": ["Charu C. Aggarwal"], "venue": null, "citeRegEx": "Aggarwal.,? \\Q2013\\E", "shortCiteRegEx": "Aggarwal.", "year": 2013}, {"title": "Human activity recognition on smartphones using a multiclass hardwarefriendly support vector machine", "author": ["Davide Anguita", "Alessandro Ghio", "Luca Oneto", "Xavier Parra", "Jorge Luis ReyesOrtiz"], "venue": "In Proceedings of the 4th International Workshop on Ambient Assisted Living and Home Care,", "citeRegEx": "Anguita et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Anguita et al\\.", "year": 2012}, {"title": "Nonparametric methods in change point problems", "author": ["E Brodsky", "Boris S Darkhovsky"], "venue": null, "citeRegEx": "Brodsky and Darkhovsky.,? \\Q1993\\E", "shortCiteRegEx": "Brodsky and Darkhovsky.", "year": 1993}, {"title": "New ensemble methods for evolving data streams", "author": ["Albert Bifet", "Geoffrey Holmes", "Bernhard Pfahringer", "Richard Kirkby", "Ricard Gavald\u00e0"], "venue": "In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Bifet et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bifet et al\\.", "year": 2009}, {"title": "LOF: identifying density-based local outliers", "author": ["Markus M. Breunig", "Hans-Peter Kriegel", "Raymond T. Ng", "J\u00f6rg Sander"], "venue": "In Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "Breunig et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Breunig et al\\.", "year": 2000}, {"title": "Detection of abrupt changes", "author": ["Mich\u00e8le Basseville", "Igor V. Nikiforov"], "venue": "Theory and application. Automatica,", "citeRegEx": "Basseville and Nikiforov.,? \\Q1996\\E", "shortCiteRegEx": "Basseville and Nikiforov.", "year": 1996}, {"title": "Anomaly detection: A survey", "author": ["Varun Chandola", "Arindam Banerjee", "Vipin Kumar"], "venue": "ACM Computing Surveys (CSUR),", "citeRegEx": "Chandola et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chandola et al\\.", "year": 2009}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Trans. Intelligent Systems and Technology,", "citeRegEx": "Chang and Lin.,? \\Q2011\\E", "shortCiteRegEx": "Chang and Lin.", "year": 2011}, {"title": "Detecting bots via incremental LS-SVM learning with dynamic feature adaptation", "author": ["Feilong Chen", "Supranamaya Ranjan", "Pang-Ning Tan"], "venue": "In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Chen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2011}, {"title": "An online kernel change detection algorithm", "author": ["Fr\u00e9d\u00e9ric Desobry", "Manuel Davy", "Christian Doncarli"], "venue": "IEEE Trans. Signal Processing,", "citeRegEx": "Desobry et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Desobry et al\\.", "year": 2005}, {"title": "Learning with augmented class by exploiting unlabeled data", "author": ["Qing Da", "Yang Yu", "Zhi-Hua Zhou"], "venue": "In Proceedings of the 28th AAAI Conference on Artificial Intelligence,", "citeRegEx": "Da et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Da et al\\.", "year": 2014}, {"title": "Is random model better? on its accuracy and efficiency", "author": ["Wei Fan", "Haixun Wang", "Philip S. Yu", "Sheng Ma"], "venue": "In Proceedings of the 3rd IEEE International Conference on Data Mining,", "citeRegEx": "Fan et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2003}, {"title": "Incremental learning of boosted face detector", "author": ["Chang Huang", "Haizhou Ai", "Takayoshi Yamashita", "Shihong Lao", "Masato Kawade"], "venue": "In Proceedings of the 11th IEEE Conference on Computer Vision,", "citeRegEx": "Huang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2007}, {"title": "Dynamic weighted majority: An ensemble method for drifting concepts", "author": ["J Zico Kolter", "Marcus A Maloof"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Kolter and Maloof.,? \\Q2007\\E", "shortCiteRegEx": "Kolter and Maloof.", "year": 2007}, {"title": "From n to n+ 1: Multiclass transfer incremental learning", "author": ["Ilja Kuzborskij", "Francesco Orabona", "Barbara Caputo"], "venue": "In Proceedings of the 26th IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Kuzborskij et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kuzborskij et al\\.", "year": 2013}, {"title": "Maximizing tree diversity by building complete-random decision trees", "author": ["Fei Tony Liu", "Kai Ming Ting", "Wei Fan"], "venue": "In Proceedings of the 9th Pacific-Asia Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Liu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2005}, {"title": "Spectrum of variablerandom trees", "author": ["Fei Tony Liu", "Kai Ming Ting", "Yang Yu", "Zhi-Hua Zhou"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Liu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2008}, {"title": "Isolation forest", "author": ["Fei Tony Liu", "Kai Ming Ting", "Zhi-Hua Zhou"], "venue": "In Proceedings of the 8th IEEE International Conference on Data Mining,", "citeRegEx": "Liu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2008}, {"title": "Classification and novel class detection in concept-drifting data streams under time constraints", "author": ["M.M. Masud", "Jing Gao", "L. Khan", "Jiawei Han", "Bhavani Thuraisingham"], "venue": "IEEE Trans. Knowledge and Data Engineering,", "citeRegEx": "Masud et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Masud et al\\.", "year": 2011}, {"title": "Time-series novelty detection using one-class support vector machines", "author": ["J. Ma", "S. Perkins"], "venue": "In Proceedings of the International Joint Conference on Neural Networks,", "citeRegEx": "Ma and Perkins.,? \\Q2003\\E", "shortCiteRegEx": "Ma and Perkins.", "year": 2003}, {"title": "In defense of one-vs-all classification", "author": ["Ryan M. Rifkin", "Aldebaro Klautau"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Rifkin and Klautau.,? \\Q2004\\E", "shortCiteRegEx": "Rifkin and Klautau.", "year": 2004}, {"title": "Svms for novel class detection in bioinformatics", "author": ["Eduardo J. Spinosa"], "venue": "In III Brazilian Workshop on Bioinformatics,", "citeRegEx": "Spinosa and Carvalho.,? \\Q2004\\E", "shortCiteRegEx": "Spinosa and Carvalho.", "year": 2004}, {"title": "Toward open set recognition", "author": ["Walter J Scheirer", "Anderson de Rezende Rocha", "Archana Sapkota", "Terrance E Boult"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence,", "citeRegEx": "Scheirer et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Scheirer et al\\.", "year": 2013}, {"title": "Estimating the support of a high-dimensional distribution", "author": ["Bernhard Sch\u00f6lkopf", "John C. Platt", "John C. Shawe-Taylor", "Alex J. Smola", "Robert C. Williamson"], "venue": "Neural Computation,", "citeRegEx": "Sch\u00f6lkopf et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Sch\u00f6lkopf et al\\.", "year": 2001}, {"title": "Cross-domain video concept detection using adaptive svms", "author": ["Jun Yang", "Rong Yan", "Alexander G Hauptmann"], "venue": "In Proceedings of the 15th international conference on Multimedia,", "citeRegEx": "Yang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2007}, {"title": "Hybrid decision tree", "author": ["Zhi-Hua Zhou", "Zhao-Qian Chen"], "venue": "Knowledge-based systems,", "citeRegEx": "Zhou and Chen.,? \\Q2002\\E", "shortCiteRegEx": "Zhou and Chen.", "year": 2002}, {"title": "Ensemble methods: foundations and algorithms", "author": ["Zhi-Hua Zhou"], "venue": null, "citeRegEx": "Zhou.,? \\Q2012\\E", "shortCiteRegEx": "Zhou.", "year": 2012}], "referenceMentions": [], "year": 2016, "abstractText": "This paper investigates an important problem in stream mining, i.e., classification under streaming emerging new classes or SENC. The common approach is to treat it as a classification problem and solve it using either a supervised learner or a semi-supervised learner. We propose an alternative approach by using unsupervised learning as the basis to solve this problem. The SENC problem can be decomposed into three sub problems: detecting emerging new classes, classifying for known classes, and updating models to enable classification of instances of the new class and detection of more emerging new classes. The proposed method employs completely random trees which have been shown to work well in unsupervised learning and supervised learning independently in the literature. This is the first time, as far as we know, that completely random trees are used as a single common core to solve all three sub problems: unsupervised learning, supervised learning and model update in data streams. We show that the proposed unsupervised-learningfocused method often achieves significantly better outcomes than existing classification-focused methods.", "creator": "LaTeX with hyperref package"}}}