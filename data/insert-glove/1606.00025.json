{"id": "1606.00025", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2016", "title": "Implementing a Reverse Dictionary, based on word definitions, using a Node-Graph Architecture", "abstract": "straightness In ihenacho this paper, infinitude we 68.66 outline an schemmel approach to shinkichi build poppea graph based dobara reverse dictionaries using bachus word renewables definitions. donkey A j.f. reverse lebe dictionary sabhnani takes a phrase as uvas an input and uttam outputs hinomaru a list of words semantically agustinus similar talmudist to that binner phrase, csm and mauresmo is a cob\u00e1n solution to the Tip of pajic the presumably Tongue problem. We use tickle a distance improta based jacome similarity invid measure, computed myden on atraco the garib graph, firuz to assess the sandile similarity romm between 64-63 a zakopane word and the input liberalized phrase. remarries We compare second-innings the origen performance of our approach with the Onelook 1-9 Reverse Dictionary climaxes and fergison a chandeliers distributional wendigo semantics method based bled on word2vec, holmwood and show that genevieve our approach skagit is tamblyn much arthurian better thorir than freyer the 40.88 distributional semantics boutiette method, watene and kaifu as bays good as Onelook ' s.", "histories": [["v1", "Tue, 31 May 2016 20:09:59 GMT  (277kb,D)", "https://arxiv.org/abs/1606.00025v1", "9 pages, 4 figures, 4 tables, submitted towards *SEM and EMNLP"], ["v2", "Fri, 15 Jul 2016 22:57:17 GMT  (562kb,D)", "http://arxiv.org/abs/1606.00025v2", "Added a new section titled 'Recommendations'. Polished multiple arguments. 10 pages, 4 figures, 4 tables, submitted at EMNLP and COLING"], ["v3", "Tue, 19 Jul 2016 08:55:35 GMT  (562kb,D)", "http://arxiv.org/abs/1606.00025v3", "Added a new section titled 'Recommendations'. Polished multiple arguments. 10 pages, 4 figures, 4 tables, submitted at EMNLP and COLING. Correction of abstract"], ["v4", "Mon, 26 Sep 2016 13:48:31 GMT  (294kb,D)", "http://arxiv.org/abs/1606.00025v4", "Accepted for publication at COLING, 2016. Minor changes. 10 pages, 4 figures, 4 tables"], ["v5", "Sat, 17 Dec 2016 22:36:15 GMT  (294kb,D)", "http://arxiv.org/abs/1606.00025v5", "Included publication information"]], "COMMENTS": "9 pages, 4 figures, 4 tables, submitted towards *SEM and EMNLP", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sushrut thorat", "varad choudhari"], "accepted": false, "id": "1606.00025"}, "pdf": {"name": "1606.00025.pdf", "metadata": {"source": "CRF", "title": "Implementing a Reverse Dictionary, based on word definitions, using a Node-Graph Architecture", "authors": ["Sushrut Thorat", "Varad Choudhari"], "emails": ["sushrut.thorat94@gmail.com", "varad.choudhari@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "A forward dictionary (FD) maps words to their definitions. A reverse dictionary (RD) (Sierra, 2000), also known as an inverse dictionary, or searchby-concept dictionary (Calvo et al., 2016), maps phrases to single words that approximate the meaning of those phrases. In the Oxford Learner\u2019s Dictionary2, one definition of \u2018brother\u2019 is \u2018a boy or man who has the same mother and father as another person\u2019. A reverse dictionary will map not only this phrase to \u2018brother\u2019, but also phrases such as \u2018son of\n1In the proceedings of the 26th International Conference on Computational Linguistics (COLING 2016), pages 2797-2806. The test data and a demo code can be found at: https://github.com/novelmartis/RD16demo\n2Accessed: February, 2016\nmy parents\u2019. A reverse dictionary is primarily a solution to the Tip of the Tongue problem (Schwartz and Metcalfe, 2011) which regularly plagues people when they want to articulate their thoughts. It can also be used in the treatment of word selection anomic aphasia (Rohrer et al., 2008), a neurological disorder in which patients can identify objects and understand semantic properties, but cannot name the object or produce one word to describe the concept.\nPopular languages let us create a multitude of phrases from a finite number of words. A static database of all possible phrases is unbound, if not infinite (Ziff, 1974). We need to dynamically compute the output word(s) from the input phrase. To map a phrase to a word, we have to compute the meanings of the phrase and the word (Fromkin et al., 2011). The principle of compositionality states that the meaning of an expression is composed of the meaning of its parts and the way they are combined structurally. The most basic parts, words, can be defined in terms of word definitions, references to objects, or lexical relations and hierarchies. Computing the meaning of a phrase requires constructing the constituent tree and recognising the relationship between the constituents, which is a complex, open problem.\nCompositional Distributional Semantic Models have been used towards computing the meaning of a phrase, with partial success (Baroni, 2013; Erk, 2012). Recurrent neural networks show promise in learning continuous phrase representations. They are used towards syntactic parsing beyond discrete categories such as NP and VP, in an attempt to capture phrasal semantics (Socher et al., 2010). A\nar X\niv :1\n60 6.\n00 02\n5v 5\n[ cs\n.C L\n] 1\n7 D\nec 2\nrecent work has used neural language embedding models (RNNs with LSTMs) to understand phrases by embedding dictionaries (Hill et al., 2015). But it doesn\u2019t perform exceptionally better than the existing reverse dictionaries (OneLook, etc.)\nIf we are to ignore the ordering of words in a phrase, the performance of such a system would not be maximal. But we could then work just with wellstudied lexical relations. Research into building reverse dictionaries has mainly focused on lexical relations than the structural or contextual combination of words. The attempts in defining a similarity measure between words have been summarised in (Mihalcea et al., 2006). An attempt towards situational understanding and contextual selection of words can be seen in (Granger, 1982). The creation of WordNet (Miller, 1995) boosted the use of lexical relations and hierarchies, as in (Dutoit and Nugues, 2002; El-Kahlout and Oflazer, 2004; Shaw et al., 2013; Me\u0301ndez et al., 2013; Calvo et al., 2016). Most of these approaches extract input words from the input phrase and expand their search through lexical relations and hierarchies, towards a similarity measure between the phrase and the words. (Zock and Schwab, 2008) take inspiration from human word synthesis and implement a user-guided search to the desired word. All these approaches have achieved partial success, but the problem stays unsolved.\nWe explore the possibility of using word definitions towards establishing semantic similarity between words and phrases. Definitions are dense sources of semantic information about words (which makes it difficult to extract information from them without using exact syntactic structures such as constituent trees), and in our approach, we employ them exclusively. We assume that the significance of the meaning of a word to a definition is proportional to its frequency throughout the definitions in the FD. We extract the meaning from the content words (Fromkin et al., 2011) contained in the phrase. We split the input phrase into these component input words, implement a graph-search through related words (relation through definition), and use a distance-based similarity measure to compute words which represent the meaning of the input phrase. A graph encodes the word relations in its connectivity matrix, on which the similarity measures are computed. We detail our approach next."}, {"heading": "2 System Description", "text": "The block diagram of the operation of the RD is depicted in Fig. 1. We now discuss the concept of the reverse map, central to the structure of our graph, and the process of obtaining the connectivity matrix underlying our graph."}, {"heading": "2.1 The Reverse Map", "text": "In a forward map, words branch out to the words that are contained in their definitions. In a reverse map, words branch out to the words whose definitions they are contained in. An example of a reverse map3 is shown in Fig. 2.\nIf the input phrase is a definition, a search depth of one (branching out from the words of the input phrase to the definitions they are contained in) of the reverse map will lead to the required word. A search depth beyond one provides us with semantic information about words whose definitions encompass or relate to concepts that encompass or relate to\n3Based on the definitions from the Oxford Learner\u2019s Dictionary.\nthe input words, and so on. Increasing search depth obscures the relationship between words, which is the basis for the definition of our similarity measure. A reverse map suggests semantic convergence in a shallow search, although the convergence might occur on multiple words, which is acceptable as they might be semantically-similar. Intuitively, a forward search seems to \u2018fragment\u2019 the meaning of the input word, and is expected to perform worse than the reverse search in defining word relationships in our approach."}, {"heading": "2.2 Connectivity Matrix of the Reverse Map", "text": "The steps in the construction of the connectivity matrix, based on the reverse map, are as follows. Our inputs are a forward dictionary, a list of functional words, and a lemmatizer. We process the forward dictionary to retain content words in their base form. We then construct the forward-linked list, transform it into a back-linked list, and then construct the backlinked connectivity matrix. Similarly, we can also construct the forward-linked connectivity matrix."}, {"heading": "2.2.1 Processing the Forward Dictionary", "text": "A forward dictionary (FD) can be viewed as a two-dimensional list. The rows in the first column contain the words, and the rows in the second column contain the corresponding definitions. We reduce all words in column one to their lemmas, their base forms4. We then delete all the functional words5 (Fromkin et al., 2011), and the corresponding definitions in column two. For our purposes, we pool all the definitions of a particular word into a single cell, parse them through the lemmatizers and delete all the functional words within them. We term the resulting list the forward-linked list. We now generate the back-linked list."}, {"heading": "2.2.2 The Back-linked list", "text": "We number the words in column one of the forward-linked list in the alphabetical order (wordid). We substitute all the words in column two by their word-ids. The back-linked list is generated by\n4Using the pattern lemmatizer (Smedt and Daelemans, 2012) and wordnet morphy (Bird et al., 2009).\n5The functional words were obtained from Higgins, 2014: http://myweb.tiscali.co.uk/wordscape/museum/funcword.html\nthe following algorithm:\nfor i in [1, length(Fs)] do : for j in Fs(i, 2) do : Bs(j, 2).append(i)\nwhere Fs is the forward-linked list, and Bs is the back-linked list. We created a list which points a word to the words whose definitions it lies in."}, {"heading": "2.2.3 The Back-Linked Matrix", "text": "We now generate the matrix which represents the connections (weights) between the nodes (words, in this case). The back-linked matrix (BLM) is generated by the following algorithm:\nfor i in [1, length(Fs)] do : for j in Bs(i, 2) do : BLM(j, i) = 1 BLM(i, i) = 0\nWe will see in section 3 that many words in a dictionary do not appear in any definition, and so cannot contact all words in the wordlist through the reverse map. But we would like to obtain the similarity measure between any two words in the wordlist. As a simple measure in ensuring complete connectivity, we build a mixed back-linked matrix (mBLM) which has forward-linked connections for words that do not have sufficient back-linked connections. The mBLM is generated by the following algorithm:\nmBLM = BLM; l = length(BLM) for i in [1, l] do :\nS = zeros(l, 1);S(i, 1) = 1; S = BLMp \u2297 S if S 6= ones(l, 1) then do :\nmBLM(:, i) = mBLM(:, i) + BLM(i, :)T\nfor j in mBLM(:, i) do : if j > 0 then do : j = 1\nmBLM(i, i) = 0\nwhere6 S is a dummy variable (denoting the states of the nodes - introduced as such in section 2.3), and p is a parameter which corresponds to the maximal depth of search required to compute the connectivity of the graph (which corresponds to the maximum non-redundant search through the graph, which is mentioned in section 3). We will assess in section 4 the change in performance by the inclusion of the said forward links.\n6A(:,i) denotes the ith column of A. AT denotes the transpose of A."}, {"heading": "2.3 The Node-Graph Architecture", "text": "The connections between the nodes in our graph are given by the BLM. Each word is represented by a node. Each node has two states {0, 1}. They respond to incoming signals, by processing their state and passing the signal to downstream nodes. If S is the state of the population of nodes, n denotes the number of time steps to be taken, Iin denotes the input signals to the nodes, Iext denotes the external bias signals to the nodes, and Iout denotes the output signals from the nodes, then the dynamics of the states of the nodes are computed by the algorithm:\nt = 0\nwhile t \u2264 n do : Iout = S\nIin = BLM\u2297 Iout + Iext for i in [1, length(BLM)] do :\nif Iin(i) \u2265 1 then do : S(i) = 1 if Iin(i) == 0 then do : S(i) = 0\nt = t+ 1\nWe create a graph for each input word (we obtain these from the input phrase by parsing it through the same operations as the definitions), and turn the input currents to their corresponding word-ids in their corresponding sheets to 1 (at t = 0 using the Iext bias term). Then we let the graphs evolve with increasing t. We are, in effect, expanding the tree of words to be able to effectively implement the similarity measure. n also represents the depth of the search. We term the evolution of S until the step n a n-layered search."}, {"heading": "2.4 The Similarity Measure", "text": "We use a distance-based measure of similarity. We define the distance dY,X from a word X to another word Y as the depth of search required to evolve a state with only SX = 1, to the first state with SY = 1. Note that dY,X 6= dX,Y .\nWe calculate the frequencies of appearances, {\u03bdZ} throughout definitions, for all words {Z} in the wordlist.\nWe define the similarity measure EW,P of a word W to an input phrase P containing the input words\n{Pi} as: EW,P = \u2211 i (\u03bdPi \u00d7 dW,Pi) \u22121\u2211\ni \u03bd \u22121 Pi\nWe weighted the inverse of the distances between the words with the inverse of the frequencies of the input words. So, the similarity measure includes a measure of \u2018semantic importance\u2019 of each input word in the input phrase. We calculate the similarity measure of each word to the input phrase, and output the words in the decreasing order of similarity. As every word is connected to every other word in the reverse map given apt search depth, the similarity measure becomes important in finding relevant output. Our similarity measure states, the smaller the distances from the input words, the more similar is the word to the input phrase. Minimal distances ensure that the semantic similarity remains meaningful."}, {"heading": "2.5 System Summary", "text": "The user inputs a phrase. Input (content) words are extracted from the phrase. Graphs are generated for each input word, and in each graph, the node corresponding to the input word is activated. The graphs are evolved to the maximum non-redundant search depth (see section 3). The similarity measure, to the input phrase, is computed for every word in the lexicon, and the words are ranked according to their similarity measures, leading to the output."}, {"heading": "3 Graph exploration", "text": "We construct BLMs and mBLMs based on the processed7 Oxford 3000 wordlist8, and a BLM for the entire WordNet (Miller, 1995) lexicon (WL). We use the Oxford Learner\u2019s dictionary (OLD), MerriamWebster dictionary9 (MW), and WordNet (WN) as forward dictionaries for the Oxford 3000 wordlist, and WordNet for the WordNet lexicon (WL). We also build a BLM and a mBLM by pooling definitions (Fusion BLM) from the three forward dictionaries, for the 3k wordlist, to check the effect of using multiple dictionaries on performance.\n7Words which appeared in Oxford Learner\u2019s dictionary definitions, but were not part of the wordlist, were added to the wordlist for consistency. The modified wordlist contains 3107 words, and is referred to as 3k, in this paper.\n8http://www.oxfordlearnersdictionaries.com/about/oxford3000 9Accessed: February, 2016\nBefore we move on to analyse the performances, let\u2019s look deeper into the connectivity matrices we generated. All the BLMs and mBLMs are sparse10. We use the compressed sparse row format from SciPy (Jones et al., 2001) to store and process our matrices.\nIn the 3k wordlist case, the number of connections in the Fusion BLM is greater than the BLMs built with individual FDs. In Fig. 3(a), we see that there are 190 words which cannot connect to the entire graph through the Fusion BLM. So, we build a mBLM, as proposed in section 2.2.3, and ensure complete connectivity of the graph, as seen in Fig. 3(b). As all words can connect to all other words in 9 steps at the most, a search depth greater than 9 would be redundant when we use the Fusion BLM. The maximum non-redundant search depths for the individual BLMs are as follows: 11 (OLD), 9 (WN), and 11 (MW).\n10Sparsity (proportion of 0\u2019s in the matrices): 0.99 (3k Fusion BLM), and 0.99 (WordNet lexicon BLM)\nThe maximum required search depth for the WordNet lexicon BLM is 19. 53, 711 words out of 82, 603 do not map to any word in the reverse map. Those words are infrequent in the language and are not used to define other words. Fig. 4(b) depicts the distribution of the number of back-linked connections from the words in the reverse map for the 80k WL BLM (\u00b5 = 7.81, \u03c3 = 62.86, max = 6163), as compared to the distribution for the 3k WN BLM (\u00b5 = 18.10, \u03c3 = 36.14, max = 615) in Fig. 4(a). The huge number of backward-linked connections for some words in 80k WL BLM would confound the accuracy of the similarity measures, and a drop in performance is expected."}, {"heading": "4 Performance Analysis", "text": "The only available online reverse dictionary is the Onelook Reverse Dictionary (Beeferman, 2003), with which we will compare our algorithm\u2019s performance. Onelook is a commercial application, and its architecture is proprietary. We know that it indexes 1061 dictionaries and resources such as Wikipedia and WordNet. The lexicon of Onelook is much bigger than 3k. In the performance comparison, we state the performance with (termed as \u2018corr\u2019) and without adapting the outputs to the 3k lexicon.\nWe also compare our approach with a distributional semantics method, based on word2vec which represents words as vectors in a linear structure that allows analogical reasoning. In that vector space, the vector \u2018king + woman - man\u2019 will have a high similarity with the vector for \u2018queen\u2019 (Mikolov et al., 2013a; Mikolov et al., 2013b). We average the vector representations of input words, and search word vectors most similar to the resulting vector (cosine similarity). This is an established method of building phrase representations from word representations (Mitchell and Lapata, 2010). The performance of such an approach11 is shown in Table. 1 (as W2V)."}, {"heading": "4.1 Performance Test", "text": "The reverse dictionary outputs multiple candidate words. We introduced users to the concept of the reverse dictionary and asked them to generate phrases\n11Based on the implementation of word2vec by Daniel Rodriguez at https://github.com/danielfrg/word2vec, trained on a corpus with 15.8million words, and a vocabulary of 98k.\nthey would use to get to a given word, if they would have forgotten the word but retained the concept. 25 such users generated 179 phrases, a sample of which is presented in Table. 2. The performance is gauged by the ranks of the words in the outputs of their usergenerated phrases12.\nWe also test all the approaches on one-line definitions for the 179 words, obtained from the Macmillian Dictionary13."}, {"heading": "4.2 Performance results", "text": "Example runs of the RD, using the 3k Fusion mBLM, are presented in Fig. 5. The distributions of ranks, for the various BLMs/mBLMs (whichever has greater % of ranks under 100 for each case), word2vec, and Onelook, are stated in Table. 1. Onelook did not provide any outputs for 18 phrases out of the 179 user-generated phrases, and 72 out\n12An input phrase can have multiple semantically similar words. Analysing the semantic quality of each output would be the ideal test. This could be done using a function of the sum of the ranks of each output weighted with their distances (in a high-dimensional semantic space such as word2vec) from the target word. However, previous approaches have used just the rank of the target word (which is nevertheless a good indicator of performance), and here we do the same.\n13Accessed: May, 2016\nof the 179 definitions from the Macmillan dictionary. Instead of considering these as failures, we factor out these phrases while evaluating Onelook. The performance of all approaches is significantly better than chance, as seen through the comparison of performance with \u2018Chance\u2019 which represents the expected values of performance for random rank assignments to the target words14 (considering the 3k lexicon). The cases of interest are highlighted in the table.\n14The expected value of the accuracy @k, over random rank assignments, is given by: \u2211Pr\nn=0 n Pr\n. Pr Cnkn(N\u2212k)Pr\u2212n\nNPr = k N , where Pr\nis the number of test phrases, and N is the size of the lexicon.\nAll the 3k cases using a BLM/mBLM have a higher performance than the 3k Fusion forwardlinked matrix (FLM). Fusion of the individual 3k BLMs yields better performance. The 3k Fusion BLM performs at least as well as Onelook. The use of mBLMs is fruitful as they increase the performance in some cases. The performance does not change much across search depth as seen in Table. 3, suggesting that our approach works well even at a shallow search. Deeper search is required only when a phrase is semantically vague or non-specific, and markedly different from dictionary definitions. Both our approach and Onelook outperform the W2V approach. We conclude that our approach works well with a 3k wordlist. Although the ranks\u2019 median and variance are indicative of the performance (hit rate, and robustness), they are marred by the accuracies, so we do not use them in our inferences.\nHowever, the performance drops significantly when the entire processed WordNet lexicon (WL, 80k) is the FD. The words that lie in the definitions of other words are a small subset of the WL wordlist. As seen in Fig. 4, there are 163 words in the WL wordlist which map to more than 500 words in the\nreverse map. Therefore, the distances of multiple words to the input words are similar, obscuring the semantic content of the similarity measure. This is a potential limitation of our approach, for which there is no trivial fix.\nWe also assessed the performance of the Fusion mBLM on the 200 test phrases used in (Hill et al., 2015). The size of their lexicon is 66k. We cannot upscale the outputs of our 3k cases to 66k, so a direct fair comparison with their results is not possible. However, we can downscale the outputs of Onelook (on the 200 phrases) to 3k and compare with it, thus providing an indirect comparison with the approach used by Hill et al. The @1/10/100 accuracies of the Fusion mBLM are .16/.39/.62. But 33 target words do not lie in the 3k lexicon. The accuracies excluding the corresponding phrases are .19/.46/.74. The @1/10/100 accuracies of the Onelook (scaled to 3k) are .08/.21/.30. But 101 phrases do not return any outputs. The accuracies excluding those phrases are .16/.42/.61. The accuracies of Onelook and the RNN approaches in Hill et al. are equivalent. We thus conclude that the performance of our approach is at least as good as the RNN approaches, on a 3k lexicon."}, {"heading": "5 Recommendations", "text": "The graph structure opens up a semantic dimension by letting us mutate the level of significance a word has in a definition, through the connectivity matrix. We can introduce this information in the similarity measure by scaling the weights of the connections between the words with distances equal to one. The definitions provided in the dictionary cannot populate the new dimension. One could consider the use of semantic rules, or lexical relations, or user feedback. Such a learning algorithm could use further exploration.\nThere are multiple points in our approach which could use either improvement or emphasis. We use multiple graphs for calculating the similarity measure. This is done because we do not want the distance of a word from an input word to be a function of all the input words. Using Spiking Neural Networks (Ghosh-Dastidar and Adeli, 2009), we could implement the similarity measure using a single graph by frequency tagging the distances from\neach input word, although it isn\u2019t clear how much advantage it would confer in terms of performance.\nA matrix of pair-wise distances between all words could be used to evaluate the similarity measures, instead of evolving a graph. Such a matrix won\u2019t be sparse, and in the case of a 80k lexicon would be 50 gigabytes in size (compared to 10megabytes in CSR sparse format for the BLM), making it impractical to deploy the algorithm on mobile devices. Execution time and memory requirement are not a problem for our approach. Our approach is an easy and computationally cheap method of implementing semantic search with a graph, which performs at least as well as the Onelook reverse dictionary.\nThere is significant drop in performance when the WordNet 80k lexicon is used (the mBLM doesn\u2019t help). The use of multiple forward dictionaries might boost the performance, as in the case of Fusion mBLM, but as mentioned in section , the branching factor of the graph is too high, obscuring the similarity measure. Although this might make the approach impractical, it does serve as a new baseline. A simple approach like ours can rival the performance of sophisticated algorithms used by Onelook and (Hill et al., 2015), suggesting that the information being retrieved by those algorithms is pretty basic. This calls for methods which could significantly outperform a simple approach like ours, towards encoding phrasal semantics.\nDealing with multi-word expressions isn\u2019t straightforward in our approach. We separate all words in the input phrase towards implementing our similarity measure. Detecting multi-word expressions would require recursive parsing of the phrase, something which is more suited to recurrent neural network-based approaches (Hill et al., 2015). This isn\u2019t a major concern for our task though, as the input phrase is supposed to be a simple description of the concept in mind, in which case the user is more likely to input \u2018to die\u2019 than \u2018kick the bucket\u2019. Multi-word expressions are also rarely used to define words or other multi-word expressions. So, they could be treated as one node with no back-linked connections but with multiple forward-linked connections (the definition of that expression), and thus be encompassed in our approach as outputs, but not as inputs (which we do in the 80k WordNet case)."}, {"heading": "6 Concluding Remarks", "text": "We reported the construction of a reverse dictionary based on a node-graph architecture, which derives its semantic information exclusively from dictionary definitions. The approach works at least as well as the Onelook reverse dictionary and a RNN-based approach described in (Hill et al., 2015), on a lexical size of 3k words, but the performance deteriorates, to below Onelook\u2019s, when scaled to a lexicon with 80k words. The performance still stays significant (as compared to the \u2018Chance\u2019), and greater than a forward map approach. Furthermore, this approach can be generalised to any language given an appropriate forward dictionary, lemmatizer, and a list of functional words.\nRecent distributional approaches use vector representations for word meaning, derived through similarities gauged by the occurrences and cooccurrences of words in a large corpus (Erk, 2012). The performance of one of these approaches, known as word2vec (Mikolov et al., 2013a; Mikolov et al., 2013b), on our test is poor, as seen in Table. 1 (under \u2018W2V\u2019). The performance suggests that phrasal semantics doesn\u2019t necessarily follow a linear additive structure. Indeed, researchers have been trying to find other mathematical structures and approaches which would be suitable for phrasal semantics (Baroni and Zamparelli, 2010; Socher et al., 2011), but with partial success and on specific types of phrases.\nA class of Artificial Neural Networks (ANNs), called Recurrent Neural Networks (RNNs) are being used for tasks such as machine translation (Cho et al., 2014) and generating natural image captions (Karpathy and Fei-Fei, 2015), among others (Zhang and Zong, 2015). These \u2018deep\u2019 networks are not trained on, or to obtain, discrete syntactic categories such as NP and VP. Instead they are provided with just the inputs and expected outputs (task-dependent) while training. The learning paradigm generates features (often incomprehensible in terms of classical linguistics) on its own to effectively implement the given task15, which seems to be better than using predetermined features. (Hill et al., 2015) use such a network to implement a re-\n15\u201cThe Unreasonable Effectiveness of Recurrent Neural Networks\u201d by Andrej Karpathy - http://karpathy.github.io/2015/05/21/rnneffectiveness/\nverse dictionary, and it performs at least as well as Onelook. Although the performance is noteworthy, the fact that a simple approach like ours can rival it suggests that the RNN-based approaches require further research before doing for reverse dictionaries (and phrasal semantics, in general) what Convolutional Neural Networks (CNNs) did for visual object classification (Chatfield et al., 2014).\nIt seems that the focus on constituent trees and the structural combination of words cannot be compromised upon. RNNs might be the way forward, in this regard, as they could develop properties encompassing and surpassing those classical linguistic features."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "In this paper, we outline an approach to build<lb>graph-based reverse dictionaries using word<lb>definitions. A reverse dictionary takes a<lb>phrase as an input and outputs a list of words<lb>semantically similar to that phrase. It is a so-<lb>lution to the Tip-of-the-Tongue problem. We<lb>use a distance-based similarity measure, com-<lb>puted on a graph, to assess the similarity be-<lb>tween a word and the input phrase. We com-<lb>pare the performance of our approach with the<lb>Onelook Reverse Dictionary and a distribu-<lb>tional semantics method based on word2vec,<lb>and show that our approach is much better<lb>than the distributional semantics method, and<lb>as good as Onelook, on a 3k lexicon. This sim-<lb>ple approach sets a new performance baseline<lb>for reverse dictionaries.1", "creator": "LaTeX with hyperref package"}}}