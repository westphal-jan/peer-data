{"id": "1606.01323", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jun-2016", "title": "Improving Coreference Resolution by Learning Entity-Level Distributed Representations", "abstract": "A devorah long - endit standing varazze challenge in ragers coreference auguries resolution turmus has arango been pendennis the kharafi incorporation of entity - 127.8 level demoing information - special-edition features consisting defined zuleika over proxim clusters of mentions adventurer instead of roby mention 27.42 pairs. turion We present a 178 neural network based coreference system 1972-1977 that cargolux produces high - dimensional 3002 vector delegitimize representations shakier for press-conference pairs of evensen coreference lomma clusters. soldados Using these antiquarian representations, our system kich learns miscommunication when vassilev combining clusters 183.6 is desirable. We tolentino train 39.34 the 58,800 system simonini with a synclavier learning to search sangstha algorithm that 466,000 teaches wentworthville it which 12-car local decisions (cluster merges) 86.22 will lead to fhernandez a showcourts high - scoring megastores final coreference partition. salterton The system bredow substantially athanasian outperforms the 1960s-1980s current u.n.-negotiated state - of - the - art previews on the kraals English and Chinese appalling portions antm of ricupero the saboteurs CoNLL greenlee 2012 40.23 Shared 2.795 Task dataset guyart despite using musquodoboit few hand - engineered ghazaly features.", "histories": [["v1", "Sat, 4 Jun 2016 04:08:45 GMT  (744kb,D)", "https://arxiv.org/abs/1606.01323v1", "Accepted for publication at the Association for Computational Linguistics (ACL), 2016"], ["v2", "Wed, 8 Jun 2016 21:11:13 GMT  (255kb,D)", "http://arxiv.org/abs/1606.01323v2", "Accepted for publication at the Association for Computational Linguistics (ACL), 2016"]], "COMMENTS": "Accepted for publication at the Association for Computational Linguistics (ACL), 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kevin clark", "christopher d manning"], "accepted": true, "id": "1606.01323"}, "pdf": {"name": "1606.01323.pdf", "metadata": {"source": "CRF", "title": "Improving Coreference Resolution by Learning Entity-Level Distributed Representations", "authors": ["Kevin Clark", "Christopher D. Manning"], "emails": ["kevclark@cs.stanford.edu", "manning@cs.stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "Coreference resolution, the task of identifying which mentions in a text refer to the same realworld entity, is fundamentally a clustering problem. However, many recent state-of-the-art coreference systems operate solely by linking pairs of mentions together (Durrett and Klein, 2013; Martschat and Strube, 2015; Wiseman et al., 2015).\nAn alternative approach is to use agglomerative clustering, treating each mention as a singleton cluster at the outset and then repeatedly merging clusters of mentions deemed to be referring to the same entity. Such systems can take advantage of entity-level information, i.e., features between clusters of mentions instead of between just two mentions. As an example for why this is useful, it is clear that the clusters {Bill Clinton} and\n{Clinton, she} are not referring to the same entity, but it is ambiguous whether the pair of mentions Bill Clinton and Clinton are coreferent.\nPrevious work has incorporated entity-level information through features that capture hard constraints like having gender or number agreement between clusters (Raghunathan et al., 2010; Durrett et al., 2013). In this work, we instead train a deep neural network to build distributed representations of pairs of coreference clusters. This captures entity-level information with a large number of learned, continuous features instead of a small number of hand-crafted categorical ones.\nUsing the cluster-pair representations, our network learns when combining two coreference clusters is desirable. At test time it builds up coreference clusters incrementally, starting with each mention in its own cluster and then merging a pair of clusters each step. It makes these decisions with a novel easy-first cluster-ranking procedure that combines the strengths of cluster-ranking (Rahman and Ng, 2011) and easy-first (Stoyanov and Eisner, 2012) coreference algorithms.\nTraining incremental coreference systems is challenging because the coreference decisions facing a model depend on previous decisions it has already made. We address this by using a learning-to-search algorithm inspired by SEARN (Daume\u0301 III et al., 2009) to train our neural network. This approach allows the model to learn which action (a cluster merge) available from the current state (a partially completed coreference clustering) will eventually lead to a high-scoring coreference partition.\nOur system uses little manual feature engineering, which means it is easily extended to multiple languages. We evaluate our system on the English and Chinese portions of the CoNLL 2012 Shared Task dataset. The cluster-ranking model significantly outperforms a mention-ranking model that\nar X\niv :1\n60 6.\n01 32\n3v 2\n[ cs\n.C L\n] 8\nJ un\n2 01\n6\ndoes not use entity-level information. We also show that using an easy-first strategy improves the performance of the cluster-ranking model. Our final system achieves CoNLL F1 scores of 65.29 for English and 63.66 for Chinese, substantially outperforming other state-of-the-art systems.1"}, {"heading": "2 System Architecture", "text": "Our cluster-ranking model is a single neural network that learns which coreference cluster merges are desirable. However, it is helpful to think of the network as being composed of distinct subnetworks. The mention-pair encoder produces distributed representations for pairs of mentions by passing relevant features through a feedforward neural network. The cluster-pair encoder produces distributed representations for pairs of clusters by applying a pooling operation over the representations of relevant mention pairs, i.e., pairs where one mention is in each cluster. The clusterranking model then scores pairs of clusters by passing their representations through a single neural network layer.\nWe also train a mention-ranking model that scores pairs of mentions by passing their representations through a single neural network layer. Its parameters are used to initialize the clusterranking model, and the scores it produces are used to prune which candidate cluster merges the cluster-ranking model considers, allowing the cluster-ranking model to run much faster. The system architecture is summarized in Figure 1."}, {"heading": "3 Building Representations", "text": "In this section, we describe the neural networks producing distributed representations of pairs of\n1Code and trained models are available at https:// github.com/clarkkev/deep-coref.\nmentions and pairs of coreference clusters. We assume that a set of mentions has already been extracted from each document using a method such as the one in Raghunathan et al. (2010)."}, {"heading": "3.1 Mention-Pair Encoder", "text": "Given a mention m and candidate antecedent a, the mention-pair encoder produces a distributed representation of the pair rm(a,m) \u2208 Rd with a feedforward neural network, which is shown in Figure 2. The candidate antecedent may be any mention that occurs before m in the document or NA, indicating that m has no antecedent. We also experimented with models based on Long Short-Term Memory recurrent neural networks (Hochreiter and Schmidhuber, 1997), but found these to perform slightly worse when used in an end-to-end coreference system due to heavy overfitting to the training data.\nInput Layer. For each mention, the model extracts various words and groups of words that are fed into the neural network. Each word is represented by a vector wi \u2208 Rdw . Each group of words is represented by the average of the vectors of each word in the group. For each mention and pair of mentions, a small number of binary features and distance features are also extracted. Distances and mention lengths are binned into one of the buckets [0, 1, 2, 3, 4, 5-7, 8-15, 16-31, 32-63, 64+] and then encoded in a one-hot vector in addition to being included as continuous features. The full set of features is as follows:\nEmbedding Features: Word embeddings of the head word, dependency parent, first word, last word, two preceding words, and two following words of the mention. Averaged word embeddings of the five preceding words, five following\nwords, all words in the mention, all words in the mention\u2019s sentence, and all words in the mention\u2019s document.\nAdditional Mention Features: The type of the mention (pronoun, nominal, proper, or list), the mention\u2019s position (index of the mention divided by the number of mentions in the document), whether the mentions is contained in another mention, and the length of the mention in words.\nDocument Genre: The genre of the mention\u2019s document (broadcast news, newswire, web data, etc.).\nDistance Features: The distance between the mentions in sentences, the distance between the mentions in intervening mentions, and whether the mentions overlap.\nSpeaker Features: Whether the mentions have the same speaker and whether one mention is the other mention\u2019s speaker as determined by string matching rules from Raghunathan et al. (2010).\nString Matching Features: Head match, exact string match, and partial string match.\nThe vectors for all of these features are concatenated to produce an I-dimensional vector h0, the input to the neural network. If a = NA, the features defined over mention pairs are not included. For this case, we train a separate network with an identical architecture to the pair network except for the input layer to produce anaphoricity scores.\nOur set of hand-engineered features is much smaller than the dozens of complex features typically used in coreference systems. However, we found these features were crucial for getting good model performance. See Section 6.1 for a feature ablation study.\nHidden Layers. The input gets passed through three hidden layers of rectified linear (ReLU) units (Nair and Hinton, 2010). Each unit in a hidden layer is fully connected to the previous layer:\nhi(a,m) = max(0,Wihi\u22121(a,m) + bi)\nwhere W1 is a M1 \u00d7 I weight matrix, W2 is a M2 \u00d7M1 matrix, and W3 is a d\u00d7M2 matrix.\nThe output of the last hidden layer is the vector representation for the mention pair: rm(a,m) = h3(a,m)."}, {"heading": "3.2 Cluster-Pair Encoder", "text": "Given two clusters of mentions ci = {mi1,mi2, ...,mi|ci|} and cj = {m j 1,m j 2, ...,m j |cj |}, the cluster-pair encoder produces a distributed representation rc(ci, cj) \u2208 R2d. The architecture of the encoder is summarized in Figure 3.\nThe cluster-pair encoder first combines the information contained in the matrix of mention-pair representations Rm(ci, cj) = [rm(m i 1,m j 1), rm(m i 1,m j 2), ..., rm(m i |ci|,m j |cj |)] to produce rc(ci, cj). This is done by applying a pooling operation. In particular it concatenates the results of max-pooling and average-pooling, which we found to be slightly more effective than using either one alone:\nrc(ci, cj)k = { max {Rm(ci, cj)k,\u00b7} for 0 \u2264 k < d avg {Rm(ci, cj)k\u2212d,\u00b7} for d \u2264 k < 2d"}, {"heading": "4 Mention-Ranking Model", "text": "Rather than training a cluster-ranking model from scratch, we first train a mention-ranking model that assigns each mention its highest scoring candidate antecedent. There are two key advantages of doing this. First, it serves as pretraining for the cluster-ranking model; in particular the mentionranking model learns effective weights for the mention-pair encoder. Second, the scores produced by the mention-ranking model are used to provide a measure of which coreference decisions are easy (allowing for an easy-first clustering strategy) and which decisions are clearly wrong (these decisions can be pruned away, significantly reducing the search space of the cluster-ranking model).\nThe mention-ranking model assigns a score sm(a,m) to a mention m and candidate an-\ntecedent a representing their compatibility for coreference. This is produced by applying a single fully connected layer of size one to the representation rm(a,m) produced by the mention-pair encoder:\nsm(a,m) = Wmrm(a,m) + bm\nwhere Wm is a 1\u00d7 d weight matrix. At test time, the mention-ranking model links each mention with its highest scoring candidate antecedent.\nTraining Objective. We train the mentionranking model with the slack-rescaled maxmargin training objective from Wiseman et al. (2015), which encourages separation between the highest scoring true and false antecedents of the current mention. Suppose the training set consists of N mentions m1,m2, ...,mN . Let A(mi) denote the set of candidate antecedents of a mention mi (i.e., mentions preceding mi and NA), and T (mi) denote the set of true antecedents of mi (i.e., mentions preceding mi that are coreferent with it or {NA} if mi has no antecedent). Let t\u0302i be the highest scoring true antecedent of mention mi:\nt\u0302i = argmax t\u2208T (mi) sm(t,mi)\nThen the loss is given by N\u2211 i=1 max a\u2208A(mi) \u2206(a,mi)(1 + sm(a,mi)\u2212 sm(t\u0302i,mi))\nwhere \u2206(a,mi) is the mistake-specific cost function\n\u2206(a,mi) =  \u03b1FN if a = NA \u2227 T (mi) 6= {NA} \u03b1FA if a 6= NA \u2227 T (mi) = {NA} \u03b1WL if a 6= NA \u2227 a /\u2208 T (mi) 0 if a \u2208 T (mi)\nfor \u201cfalse new,\u201d \u201cfalse anaphoric,\u201d \u201cwrong link,\u201d and correct coreference decisions. The different error penalties allow the system to be tuned for coreference evaluation metrics by biasing it towards making more or fewer coreference links.\nFinding Effective Error Penalties. We fix \u03b1WL = 1.0 and search for \u03b1FA and \u03b1FN out of {0.1, 0.2, ..., 1.5} with a variant of grid search. Each new trial uses the unexplored set of hyperparameters that has the closest Manhattan\ndistance to the best setting found so far on the dev set. We stopped the search when all immediate neighbors (within 0.1 distance) of the best setting had been explored. We found (\u03b1FN, \u03b1FA, \u03b1WL) = (0.8, 0.4, 1.0) to be best for English and (\u03b1FN, \u03b1FA, \u03b1WL) = (0.7, 0.4, 1.0) to be best for Chinese on the CoNLL 2012 data. We attribute our smaller false new cost from the one used by Wiseman et al. (they set \u03b1FN = 1.2) to using more precise mention detection, which results in fewer links to NA.\nTraining Details. We initialized our word embeddings with 50 dimensional ones produced by word2vec (Mikolov et al., 2013) on the Gigaword corpus for English and 64 dimensional ones provided by Polyglot (Al-Rfou et al., 2013) for Chinese. Averaged word embeddings were held fixed during training while the embeddings used for single words were updated. We set our hidden layer sizes to M1 = 1000,M2 = d = 500 and minimized the training objective using RMSProp (Hinton and Tieleman, 2012). To regularize the network, we applied L2 regularization to the model weights and dropout (Hinton et al., 2012) with a rate of 0.5 on the word embeddings and the output of each hidden layer.\nPretraining. As in Wiseman et al. (2015), we found that pretraining is crucial for the mentionranking model\u2019s success. We pretrained the network in two stages, minimizing the following objectives from Clark and Manning (2015):\nAll-Pairs Classification \u2212 N\u2211 i=1 [ \u2211 t\u2208T (mi) log p(t,mi) + \u2211 f\u2208F(mi) log(1\u2212 p(f,mi))]\nTop-Pairs Classification \u2212 N\u2211 i=1 [ max t\u2208T (mi) log p(t,mi) + min f\u2208F(mi) log(1\u2212 p(f,mi))]\nWhereF(mi) is the set of false antecedents formi and p(a,mi) = sigmoid(s(a,mi)). The top-pairs objective is a middle ground between the all-pairs classification and mention ranking objectives: it only processes high-scoring mentions, but is probabilistic rather than max-margin. We first pretrained the network with all-pairs classification for 150 epochs and then with top-pairs classification for 50 epochs. See Section 6.1 for experiments on the two-stage pretraining."}, {"heading": "5 Cluster-Ranking Model", "text": "Although a strong coreference system on its own, the mention-ranking model has the disadvantage of only considering local information between pairs of mentions, so it cannot consolidate information at the entity-level. We address this problem by training a cluster-ranking model that scores pairs of clusters instead of pairs of mentions.\nGiven two clusters of mentions ci and cj , the cluster-ranking model produces a score sc(ci, cj) representing their compatibility for coreference. This is produced by applying a single fully connected layer of size one to the representation rc(ci, cj) produced by the cluster-pair encoder:\nsc(ci, cj) = Wcrc(ci, cj) + bc\nwhere Wc is a 1 \u00d7 2d weight matrix. Our cluster-ranking approach also uses a measure of anaphoricity, or how likely it is for a mention m to have an antecedent. This is defined as\nsNA(m) = WNArm(NA,m) + bNA\nwhere WNA is a 1\u00d7 d matrix."}, {"heading": "5.1 Cluster-Ranking Policy Network", "text": "At test time, the cluster ranker iterates through every mention in the document, merging the current mention\u2019s cluster with a preceding one or performing no action. We view this procedure as a sequential decision process where at each step the algorithm observes the current state x and performs some action u.\nSpecifically, we define a state x = (C,m) to consist of C = {c1, c2, ...}, the set of existing coreference clusters, and m, the current mention being considered. At a start state, each cluster in C contains a single mention. Let cm \u2208 C be the cluster containing m and A(m) be a set of candidate antecedents for m: mentions occurring previously in the document. Then the available actions U(x) from x are\n\u2022 MERGE[cm, c], where c is a cluster containing a mention in A(m). This combines cm and c into a single coreference cluster.\n\u2022 PASS. This leaves the clustering unchanged.\nAfter determining the new clustering C \u2032 based on the existing clustering C and action u, we consider another mention m\u2032 to get the next state x\u2032 = (C \u2032,m\u2032).\nUsing the scoring functions sc and sNA, we define a policy network \u03c0 that assigns a probability distribution over U(x) as follows:\n\u03c0(MERGE[cm, c]|x) \u221d esc(cm,c)\n\u03c0(PASS|x) \u221d esNA(m)\nDuring inference, \u03c0 is executed by taking the highest-scoring (most probable) action at each step."}, {"heading": "5.2 Easy-First Cluster Ranking", "text": "The last detail needed is the ordering in which to consider mentions. Cluster-ranking models in prior work order the mentions according to their positions in the document, processing them leftto-right (Rahman and Ng, 2011; Ma et al., 2014). However, we instead sort the mentions in descending order by their highest scoring candidate coreference link according to the mention-ranking model. This causes inference to occur in an easyfirst fashion where hard decisions are delayed until more information is available. Easy-first orderings have been shown to improve the performance of other incremental coreference strategies (Raghunathan et al., 2010; Stoyanov and Eisner, 2012) because they reduce the problem of errors compounding as the algorithm runs.\nWe also find it beneficial to prune the set of candidate antecedents A(m) for each mention m. Rather than using all previously occurring mentions as candidate antecedents, we only include high-scoring ones, which greatly reduces the size of the search space. This allows for much faster learning and inference; we are able to remove over 95% of candidate actions with no decrease in the model\u2019s performance. For both of these two preprocessing steps, we use s(a,m) \u2212 s(NA,m) as the score of a coreference link between a and m."}, {"heading": "5.3 Deep Learning to Search", "text": "We face a sequential prediction problem where future observations (visited states) depend on previous actions. This is challenging because it violates the common i.i.d. assumption made in machine learning. Learning-to-search algorithms are effective for this sort of problem, and have been applied successfully to coreference resolution (Daume\u0301 III and Marcu, 2005; Clark and Manning, 2015) as well as other structured prediction tasks in natural language processing (Daume\u0301 III et al., 2014;\nAlgorithm 1 Deep Learning to Search for i = 1 to num epochs do\nInitialize the current training set \u0393 = \u2205 for each example (x, y) \u2208 D do\nRun the policy \u03c0 to completion from start state x to obtain a trajectory of states {x1, x2, ..., xn} for each state xi in the trajectory do\nfor each possible action u \u2208 U(xi) do Execute u on xi and then run the reference policy \u03c0ref until reaching an end state e Assign u a cost by computing the loss on the end state: l(u) = L(e, y) end for Add the state xi and associated costs l to \u0393\nend for end for Update \u03c0 with gradient descent, minimizing \u2211 (x,l)\u2208\u0393 \u2211 u\u2208U(x) \u03c0(u|x)l(u)\nend for\nChang et al., 2015a).\nWe train the cluster-ranking model using a learning-to-search algorithm inspired by SEARN (Daume\u0301 III et al., 2009), which is described in Algorithm 1. The algorithm takes as input a dataset D of start states x (in our case documents with each mention in its own singleton coreference cluster) and structured labels y (in our case gold coreference clusters). Its goal is to train the policy \u03c0 so when it executes from x, reaching a final state e, the resulting loss L(e, y) is small. We use the negative of the B3 coreference metric for this loss (Bagga and Baldwin, 1998). Although our system evaluation also includes the MUC (Vilain et al., 1995) and CEAF\u03c64 (Luo, 2005) metrics, we do not incorporate them into the loss because MUC has the flaw of treating all errors equally and CEAF\u03c64 is slow to compute.\nFor each example (x, y) \u2208 D, the algorithm obtains a trajectory of states x1, x2, ..., xn visited by the current policy by running it to completion (i.e., repeatedly taking the highest scoring action until reaching an end state) from the start state x. This exposes the model to states at train time similar to the ones it will face at test time, allowing it to learn how to cope with mistakes.\nGiven a state x in a trajectory, the algorithm then assigns a cost l(u) to each action u \u2208 U(x) by executing the action, \u201crolling out\u201d from the resulting state with a reference policy \u03c0ref until reaching an end state e, and computing the resulting loss L(e, y). This rolling out procedure allows the model to learn how a local action will affect the final score, which cannot be otherwise computed because coreference evaluation metrics do not de-\ncompose over cluster merges. The policy network is then trained to minimize the risk associated with taking each action: \u2211 u\u2208U(x) \u03c0(u|x)l(u).\nReference policies typically refer to the gold labels to find actions that are likely to be beneficial. Our reference policy \u03c0ref takes the action that increases the B3 score the most each step, breaking ties randomly. It is generally recommended to use a stochastic mixture of the reference policy and the current learned policy during rollouts when the reference policy is not optimal (Chang et al., 2015b). However, we find only using the reference policy (which is close to optimal) to be much more efficient because it does not require neural network computations and is deterministic, which means the costs of actions can be cached.\nTraining details. We update \u03c0 using RMSProp and apply dropout with a rate of 0.5 to the input layer. For most experiments, we initialize the mention-pair encoder component of the clusterranking model with the learned weights from the mention-ranking model, which we find to greatly improve performance (see Section 6.2).\nRuntime. The full cluster-ranking system runs end-to-end in slightly under 1 second per document on the English test set when using a GPU (including scoring all pairs of mentions with the mention-ranking model for search-space pruning). This means the bottleneck for the overall system is the syntactic parsing required for mention detection (about 4 seconds per document on the English test set)."}, {"heading": "6 Experiments and Results", "text": "Experimental Setup. We run experiments on the English and Chinese portions of the CoNLL 2012 Shared Task data (Pradhan et al., 2012). The models are evaluated using three of the most popular coreference metrics: MUC, B3, and Entity-based CEAF (CEAF\u03c64). We generally report the average F1 score (CoNLL F1) of the three, which is common practice in coreference evaluation. We used the most recent version of the CoNLL scorer (version 8.01), which implements the original definitions of the metrics.\nMention Detection. Our experiments were run using system-produced predicted mentions. We used the rule-based mention detection algorithm from Raghunathan et al. (2010), which first extracts pronouns and maximal NP projections as candidate mentions and then filters this set with rules that remove spurious mentions such as numeric entities and pleonastic it pronouns."}, {"heading": "6.1 Mention-Ranking Model Experiments", "text": "Feature Ablations. We performed a feature ablation study to determine the importance of the hand-engineered features included in our model. The results are shown in Table 1. We find the small number of non-embedding features substantially improves model performance, especially the distance and string matching features. This is unsurprising, as the additional features are not easily captured by word embeddings and historically such features have been very important in coreference resolvers (Bengtson and Roth, 2008).\nThe Importance of Pretraining. We evaluate the benefit of the two-step pretraining for the\nmention-ranking model and report results in Table 2. Consistent with Wiseman et al. (2015), we find pretraining to greatly improve the model\u2019s accuracy. We note in particular that the model benefits from using both pretraining steps from Section 4, which more smoothly transitions the model from a mention-pair classification objective that is easy to optimize to a max-margin objective better suited for a ranking task."}, {"heading": "6.2 Cluster-Ranking Model Experiments", "text": "We evaluate the importance of three key details of the cluster ranker: initializing it with the mentionranking model\u2019s weights, using an easy-first ordering of mentions, and using learning to search. The results are shown in Table 3.\nPretrained Weights. We compare initializing the cluster-ranking model randomly with initializing it with the weights learned by the mentionranking model. Using pretrained weights greatly improves performance. We believe the clusterranking model has difficulty learning effective weights from scratch due to noise in the signal coming from cluster-level decisions (an overall bad cluster merge may still involve a few cor-\nrect pairwise links) and the smaller amount of data used to train the cluster-ranking model (many possible actions are pruned away during preprocessing). We believe the score would be even lower without search-space pruning, which stops the model from considering many bad actions.\nEasy-First Cluster Ranking. We compare the effectiveness of easy-first cluster-ranking with the commonly used left-to-right approach. Using a left-to-right strategy simply requires changing the preprocessing step ordering the mentions so mentions are sorted by their position in the document instead of their highest scoring coreference link according to the mention-ranking model. We find the easy-first approach slightly outperforms using a left-to-right ordering of mentions. We believe this is because delaying hard decisions until later reduces the problem of early mistakes causing later decisions to be made incorrectly.\nLearning to Search. We also compare learning to search with the simpler approach of training the model on a trajectory of gold coreference decisions (i.e., training on a fixed cost-sensitive classification dataset). Using this approach significantly decreases performance. We attribute this to the model not learning how to deal with mistakes when it only sees correct decisions during training."}, {"heading": "6.3 Capturing Semantic Similarity", "text": "Using semantic information to improve coreference accuracy has had mixed in results in previous research, and has been called an \u201cuphill battle\u201d in coreference resolution (Durrett and Klein, 2013). However, word embeddings are well known for being effective at capturing semantic relatedness, and we show here that neural network coreference models can take advantage of this.\nPerhaps the case where semantic similarity is most important is in linking nominals with no head match (e.g., \u201cthe nation\u201d and \u201cthe country\u201d). We compare the performance of our neural network model with our earlier statistical system (Clark and Manning, 2015) at classifying mention pairs of this type as being coreferent or not. The neural network shows substantial improvement (18.9 F1 vs. 10.7 F1) on this task compared to the more modest improvement it gets at classifying any pair of mentions as coreferent (68.7 F1 vs. 66.1 F1). Some example wins are shown in Table 4. These types of coreference links are quite rare in the CoNLL data (about 1.2% of the positive coref-\nerence links in the test set), so the improvement does not significantly contribute to the final system\u2019s score, but it does suggest progress on this difficult type of coreference problem."}, {"heading": "6.4 Final System Performance", "text": "In Table 5 we compare the results of our system with state-of-the-art approaches for English and Chinese. Our mention-ranking model surpasses all previous systems. We attribute its improvement over the neural mention ranker from Wiseman et al. (2015) to our model using a deeper neural network, pretrained word embeddings, and more sophisticated pretraining.\nThe cluster-ranking model improves results further across both languages and all evaluation metrics, demonstrating the utility of incorporating entity-level information. The improvement is largest in CEAF\u03c64 , which is encouraging because CEAF\u03c64 is the most recently proposed metric, designed to correct flaws in the other two (Luo, 2005). We believe entity-level information is particularly useful for preventing bad merges between large clusters (see Figure 4 for an example). However, it is worth noting that in practice the much more complicated cluster-ranking model brings only fairly modest gains in performance."}, {"heading": "7 Related Work", "text": "There has been extensive work on machine learning approaches to coreference resolution (Soon et al., 2001; Ng and Cardie, 2002), with mentionranking models being particularly popular (Denis and Baldridge, 2007; Durrett and Klein, 2013; Martschat and Strube, 2015).\nWe train a neural mention-ranking model inspired by Wiseman et al. (2015) as a starting point, but then use it to pretrain a cluster-ranking model that benefits from entity-level information. Wise-\nman et al. (2016) extend their mention-ranking model by incorporating entity-level information produced by a recurrent neural network running over the candidate antecedent-cluster. However, this is an augmentation to a mention-ranking model, and not fundamentally a clustering model as our cluster ranker is.\nEntity-level information has also been incorporated in coreference systems using joint inference (McCallum and Wellner, 2003; Poon and Domingos, 2008; Haghighi and Klein, 2010) and systems that build up coreference clusters incrementally (Luo et al., 2004; Yang et al., 2008; Raghunathan et al., 2010). We take the latter approach, and in particular combine the cluster-ranking (Rahman and Ng, 2011; Ma et al., 2014) and easy-first (Stoyanov and Eisner, 2012; Clark and Manning, 2015) clustering strategies. These prior systems all express entity-level information in the form of hand-engineered features and constraints instead of entity-level distributed representations that are learned from data.\nWe train our system using a learning-to-search algorithm similar to SEARN (Daume\u0301 III et al., 2009). Learning-to-search style algorithms have been employed to train coreference resolvers on trajectories of decisions similar to those that would\nbe seen at test-time by Daume\u0301 et al. (2005), Ma et al. (2014), and Clark and Manning (2015). Other works use structured perceptron models for the same purpose (Stoyanov and Eisner, 2012; Fernandes et al., 2012; Bjo\u0308rkelund and Kuhn, 2014)."}, {"heading": "8 Conclusion", "text": "We have presented a coreference system that captures entity-level information with distributed representations of coreference cluster pairs. These learned, dense, high-dimensional feature vectors provide our cluster-ranking coreference model with a strong ability to distinguish beneficial cluster merges from harmful ones. The model is trained with a learning-to-search algorithm that allows it to learn how local decisions will affect the final coreference score. We evaluate our system on the English and Chinese portions of the CoNLL 2012 Shared Task and report a substantial improvement over the current state-of-the-art."}, {"heading": "Acknowledgments", "text": "We thank Will Hamilton, Jon Gauthier, and the anonymous reviewers for their thoughtful comments and suggestions. This work was supported by NSF Award IIS-1514268."}], "references": [{"title": "Polyglot: Distributed word representations for multilingual NLP", "author": ["Al-Rfou et al.2013] Rami Al-Rfou", "Bryan Perozzi", "Steven Skiena"], "venue": "Conference on Natural Language Learning (CoNLL),", "citeRegEx": "Al.Rfou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Al.Rfou et al\\.", "year": 2013}, {"title": "Algorithms for scoring coreference chains", "author": ["Bagga", "Baldwin1998] Amit Bagga", "Breck Baldwin"], "venue": "In The First International Conference on Language Resources and Evaluation Workshop on Linguistics Coreference,", "citeRegEx": "Bagga et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Bagga et al\\.", "year": 1998}, {"title": "Understanding the value of features for coreference resolution", "author": ["Bengtson", "Roth2008] Eric Bengtson", "Dan Roth"], "venue": "In Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Bengtson et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bengtson et al\\.", "year": 2008}, {"title": "Learning structured perceptrons for coreference resolution with latent antecedents and non-local features", "author": ["Bj\u00f6rkelund", "Kuhn2014] Anders Bj\u00f6rkelund", "Jonas Kuhn"], "venue": "In Association of Computational Linguistics (ACL),", "citeRegEx": "Bj\u00f6rkelund et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bj\u00f6rkelund et al\\.", "year": 2014}, {"title": "Learning to search for dependencies. arXiv preprint arXiv:1503.05615", "author": ["Chang et al.2015a] Kai-Wei Chang", "He He", "Hal Daum\u00e9 III", "John Langford"], "venue": null, "citeRegEx": "Chang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2015}, {"title": "Learning to search better than your teacher", "author": ["Chang et al.2015b] Kai-Wei Chang", "Akshay Krishnamurthy", "Alekh Agarwal", "Hal Daum\u00e9 III", "John Langford"], "venue": "In International Conference on Machine Learning (ICML)", "citeRegEx": "Chang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2015}, {"title": "Combining the best of two worlds: A hybrid approach to multilingual coreference resolution", "author": ["Chen", "Ng2012] Chen Chen", "Vincent Ng"], "venue": "In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Con-", "citeRegEx": "Chen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2012}, {"title": "Entity-centric coreference resolution with model stacking", "author": ["Clark", "Manning2015] Kevin Clark", "Christopher D. Manning"], "venue": null, "citeRegEx": "Clark et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2015}, {"title": "A large-scale exploration of effective global features for a joint entity detection and tracking model", "author": ["III Daum\u00e9", "III Marcu2005] Hal Daum\u00e9", "Marcu. Daniel"], "venue": "In Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Daum\u00e9 et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Daum\u00e9 et al\\.", "year": 2005}, {"title": "Search-based structured prediction", "author": ["John Langford", "Daniel Marcu"], "venue": "Machine Learning,", "citeRegEx": "III et al\\.,? \\Q2009\\E", "shortCiteRegEx": "III et al\\.", "year": 2009}, {"title": "Efficient programmable learning to search. arXiv preprint arXiv:1406.1837", "author": ["John Langford", "Stephane Ross"], "venue": null, "citeRegEx": "III et al\\.,? \\Q2014\\E", "shortCiteRegEx": "III et al\\.", "year": 2014}, {"title": "A ranking approach to pronoun resolution", "author": ["Denis", "Baldridge2007] Pascal Denis", "Jason Baldridge"], "venue": "In International Joint Conferences on Artificial Intelligence (IJCAI),", "citeRegEx": "Denis et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Denis et al\\.", "year": 2007}, {"title": "Easy victories and uphill battles in coreference resolution", "author": ["Durrett", "Klein2013] Greg Durrett", "Dan Klein"], "venue": "In Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Durrett et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Durrett et al\\.", "year": 2013}, {"title": "Decentralized entitylevel modeling for coreference resolution", "author": ["Durrett et al.2013] Greg Durrett", "David Leo Wright Hall", "Dan Klein"], "venue": "In Association for Computational Linguistics (ACL),", "citeRegEx": "Durrett et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Durrett et al\\.", "year": 2013}, {"title": "Latent structure perceptron with feature induction for unrestricted coreference resolution", "author": ["C\u0131\u0301cero Nogueira Dos Santos", "Ruy Luiz Milidi\u00fa"], "venue": "In Proceedings of the Joint Conference on Empirical", "citeRegEx": "Fernandes et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Fernandes et al\\.", "year": 2012}, {"title": "Coreference resolution in a modular, entity-centered model. In Human Language Technology and North American Association for Computational Linguistics (HLT-NAACL), pages", "author": ["Haghighi", "Klein2010] Aria Haghighi", "Dan Klein"], "venue": null, "citeRegEx": "Haghighi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Haghighi et al\\.", "year": 2010}, {"title": "Lecture 6.5-RmsProp: Divide the gradient by a running average of its recent magnitude", "author": ["Hinton", "Tieleman2012] Geoffrey Hinton", "Tijmen Tieleman"], "venue": "COURSERA: Neural Networks for Machine Learning,", "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580", "author": ["Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "A mention-synchronous coreference resolution algorithm based on the Bell tree", "author": ["Luo et al.2004] Xiaoqiang Luo", "Abe Ittycheriah", "Hongyan Jing", "Nanda Kambhatla", "Salim Roukos"], "venue": null, "citeRegEx": "Luo et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Luo et al\\.", "year": 2004}, {"title": "On coreference resolution performance metrics", "author": ["Xiaoqiang Luo"], "venue": "Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Luo.,? \\Q2005\\E", "shortCiteRegEx": "Luo.", "year": 2005}, {"title": "Prune-andscore: Learning for greedy coreference resolution", "author": ["Ma et al.2014] Chao Ma", "Janardhan Rao Doppa", "J Walker Orr", "Prashanth Mannem", "Xiaoli Fern", "Tom Dietterich", "Prasad Tadepalli"], "venue": null, "citeRegEx": "Ma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2014}, {"title": "Latent structures for coreference resolution. Transactions of the Association for Computational Linguistics (TACL), 3:405\u2013418", "author": ["Martschat", "Strube2015] Sebastian Martschat", "Michael Strube"], "venue": null, "citeRegEx": "Martschat et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Martschat et al\\.", "year": 2015}, {"title": "Toward conditional models of identity uncertainty with application to proper noun coreference", "author": ["McCallum", "Wellner2003] Andrew McCallum", "Ben Wellner"], "venue": "In Proceedings of the IJCAI Workshop on Information Integration on the Web", "citeRegEx": "McCallum et al\\.,? \\Q2003\\E", "shortCiteRegEx": "McCallum et al\\.", "year": 2003}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["Nair", "Hinton2010] Vinod Nair", "Geoffrey E. Hinton"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Nair et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Nair et al\\.", "year": 2010}, {"title": "Improving machine learning approaches to coreference resolution", "author": ["Ng", "Cardie2002] Vincent Ng", "Claire Cardie"], "venue": "In Association of Computational Linguistics (ACL),", "citeRegEx": "Ng et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Ng et al\\.", "year": 2002}, {"title": "A joint framework for coreference resolution and mention head detection", "author": ["Peng et al.2015] Haoruo Peng", "Kai-Wei Chang", "Dan Roth"], "venue": "Conference on Natural Language Learning (CoNLL),", "citeRegEx": "Peng et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Peng et al\\.", "year": 2015}, {"title": "Joint unsupervised coreference resolution with markov logic", "author": ["Poon", "Domingos2008] Hoifung Poon", "Pedro Domingos"], "venue": "In Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Poon et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Poon et al\\.", "year": 2008}, {"title": "Conll-2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes", "author": ["Alessandro Moschitti", "Nianwen Xue", "Olga Uryupina", "Yuchen Zhang"], "venue": "In Proceedings of the Joint Conference on Empirical", "citeRegEx": "Pradhan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2012}, {"title": "A multi-pass sieve for coreference resolution", "author": ["Heeyoung Lee", "Sudarshan Rangarajan", "Nathanael Chambers", "Mihai Surdeanu", "Dan Jurafsky", "Christopher Manning"], "venue": null, "citeRegEx": "Raghunathan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Raghunathan et al\\.", "year": 2010}, {"title": "Narrowing the modeling gap: a clusterranking approach to coreference resolution", "author": ["Rahman", "Ng2011] Altaf Rahman", "Vincent Ng"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Rahman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rahman et al\\.", "year": 2011}, {"title": "A machine learning approach to coreference resolution of noun phrases", "author": ["Soon et al.2001] Wee Meng Soon", "Hwee Tou Ng", "Daniel Chung Yong Lim"], "venue": null, "citeRegEx": "Soon et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Soon et al\\.", "year": 2001}, {"title": "Easy-first coreference resolution", "author": ["Stoyanov", "Eisner2012] Veselin Stoyanov", "Jason Eisner"], "venue": "In International Conference on Computational Linguistics (COLING),", "citeRegEx": "Stoyanov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Stoyanov et al\\.", "year": 2012}, {"title": "A model-theoretic coreference scoring scheme", "author": ["Vilain et al.1995] Marc Vilain", "John Burger", "John Aberdeen", "Dennis Connolly", "Lynette Hirschman"], "venue": "In Proceedings of the 6th conference on Message understanding,", "citeRegEx": "Vilain et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Vilain et al\\.", "year": 1995}, {"title": "Learning anaphoricity and antecedent ranking features for coreference resolution", "author": ["Wiseman et al.2015] Sam Wiseman", "Alexander M. Rush", "Stuart M. Shieber", "Jason Weston"], "venue": "In Association of Computational Linguistics (ACL),", "citeRegEx": "Wiseman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wiseman et al\\.", "year": 2015}, {"title": "Learning global features for coreference resolution. In Human Language Technology and North American Association for Computational Linguistics (HLT-NAACL)", "author": ["Wiseman et al.2016] Sam Wiseman", "Alexander M. Rush", "Stuart M. Shieber"], "venue": null, "citeRegEx": "Wiseman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wiseman et al\\.", "year": 2016}, {"title": "An entity-mention model for coreference resolution with inductive logic programming", "author": ["Yang et al.2008] Xiaofeng Yang", "Jian Su", "Jun Lang", "Chew Lim Tan", "Ting Liu", "Sheng Li"], "venue": "In Association of Computational Linguistics (ACL),", "citeRegEx": "Yang et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 35, "context": "However, many recent state-of-the-art coreference systems operate solely by linking pairs of mentions together (Durrett and Klein, 2013; Martschat and Strube, 2015; Wiseman et al., 2015).", "startOffset": 111, "endOffset": 186}, {"referenceID": 30, "context": "Previous work has incorporated entity-level information through features that capture hard constraints like having gender or number agreement between clusters (Raghunathan et al., 2010; Durrett et al., 2013).", "startOffset": 159, "endOffset": 207}, {"referenceID": 12, "context": "Previous work has incorporated entity-level information through features that capture hard constraints like having gender or number agreement between clusters (Raghunathan et al., 2010; Durrett et al., 2013).", "startOffset": 159, "endOffset": 207}, {"referenceID": 30, "context": "We assume that a set of mentions has already been extracted from each document using a method such as the one in Raghunathan et al. (2010).", "startOffset": 113, "endOffset": 139}, {"referenceID": 30, "context": "Speaker Features: Whether the mentions have the same speaker and whether one mention is the other mention\u2019s speaker as determined by string matching rules from Raghunathan et al. (2010).", "startOffset": 160, "endOffset": 186}, {"referenceID": 35, "context": "We train the mentionranking model with the slack-rescaled maxmargin training objective from Wiseman et al. (2015), which encourages separation between the highest scoring true and false antecedents of the current mention.", "startOffset": 92, "endOffset": 114}, {"referenceID": 24, "context": "We initialized our word embeddings with 50 dimensional ones produced by word2vec (Mikolov et al., 2013) on the Gigaword corpus for English and 64 dimensional ones provided by Polyglot (Al-Rfou et al.", "startOffset": 81, "endOffset": 103}, {"referenceID": 0, "context": ", 2013) on the Gigaword corpus for English and 64 dimensional ones provided by Polyglot (Al-Rfou et al., 2013) for Chinese.", "startOffset": 88, "endOffset": 110}, {"referenceID": 16, "context": "To regularize the network, we applied L2 regularization to the model weights and dropout (Hinton et al., 2012) with a rate of 0.", "startOffset": 89, "endOffset": 110}, {"referenceID": 35, "context": "As in Wiseman et al. (2015), we found that pretraining is crucial for the mentionranking model\u2019s success.", "startOffset": 6, "endOffset": 28}, {"referenceID": 35, "context": "As in Wiseman et al. (2015), we found that pretraining is crucial for the mentionranking model\u2019s success. We pretrained the network in two stages, minimizing the following objectives from Clark and Manning (2015):", "startOffset": 6, "endOffset": 213}, {"referenceID": 21, "context": "Cluster-ranking models in prior work order the mentions according to their positions in the document, processing them leftto-right (Rahman and Ng, 2011; Ma et al., 2014).", "startOffset": 131, "endOffset": 169}, {"referenceID": 30, "context": "Easy-first orderings have been shown to improve the performance of other incremental coreference strategies (Raghunathan et al., 2010; Stoyanov and Eisner, 2012) because they reduce the problem of errors compounding as the algorithm runs.", "startOffset": 108, "endOffset": 161}, {"referenceID": 34, "context": "Although our system evaluation also includes the MUC (Vilain et al., 1995) and CEAF\u03c64 (Luo, 2005) metrics, we do not incorporate them into the loss because MUC has the flaw of treating all errors equally and CEAF\u03c64 is slow to compute.", "startOffset": 53, "endOffset": 74}, {"referenceID": 20, "context": ", 1995) and CEAF\u03c64 (Luo, 2005) metrics, we do not incorporate them into the loss because MUC has the flaw of treating all errors equally and CEAF\u03c64 is slow to compute.", "startOffset": 19, "endOffset": 30}, {"referenceID": 29, "context": "We run experiments on the English and Chinese portions of the CoNLL 2012 Shared Task data (Pradhan et al., 2012).", "startOffset": 90, "endOffset": 112}, {"referenceID": 30, "context": "We used the rule-based mention detection algorithm from Raghunathan et al. (2010), which first extracts pronouns and maximal NP projections as candidate mentions and then filters this set with rules that remove spurious mentions such as numeric entities and pleonastic it pronouns.", "startOffset": 56, "endOffset": 82}, {"referenceID": 35, "context": "Consistent with Wiseman et al. (2015), we find pretraining to greatly improve the model\u2019s accuracy.", "startOffset": 16, "endOffset": 38}, {"referenceID": 35, "context": "We attribute its improvement over the neural mention ranker from Wiseman et al. (2015) to our model using a deeper neural network, pretrained word embeddings, and more sophisticated pretraining.", "startOffset": 65, "endOffset": 87}, {"referenceID": 20, "context": "The improvement is largest in CEAF\u03c64 , which is encouraging because CEAF\u03c64 is the most recently proposed metric, designed to correct flaws in the other two (Luo, 2005).", "startOffset": 156, "endOffset": 167}, {"referenceID": 32, "context": "There has been extensive work on machine learning approaches to coreference resolution (Soon et al., 2001; Ng and Cardie, 2002), with mentionranking models being particularly popular (Denis and Baldridge, 2007; Durrett and Klein, 2013; Martschat and Strube, 2015).", "startOffset": 87, "endOffset": 127}, {"referenceID": 35, "context": "We train a neural mention-ranking model inspired by Wiseman et al. (2015) as a starting point, but then use it to pretrain a cluster-ranking model that benefits from entity-level information.", "startOffset": 52, "endOffset": 74}, {"referenceID": 27, "context": "02 Peng et al. (2015) \u2013 \u2013 72.", "startOffset": 3, "endOffset": 22}, {"referenceID": 27, "context": "02 Peng et al. (2015) \u2013 \u2013 72.22 \u2013 \u2013 60.50 \u2013 \u2013 56.37 63.03 Wiseman et al. (2015) 76.", "startOffset": 3, "endOffset": 80}, {"referenceID": 27, "context": "02 Peng et al. (2015) \u2013 \u2013 72.22 \u2013 \u2013 60.50 \u2013 \u2013 56.37 63.03 Wiseman et al. (2015) 76.23 69.31 72.60 66.07 55.83 60.52 59.41 54.88 57.05 63.39 Wiseman et al. (2016) 77.", "startOffset": 3, "endOffset": 162}, {"referenceID": 19, "context": "Entity-level information has also been incorporated in coreference systems using joint inference (McCallum and Wellner, 2003; Poon and Domingos, 2008; Haghighi and Klein, 2010) and systems that build up coreference clusters incrementally (Luo et al., 2004; Yang et al., 2008; Raghunathan et al., 2010).", "startOffset": 238, "endOffset": 301}, {"referenceID": 37, "context": "Entity-level information has also been incorporated in coreference systems using joint inference (McCallum and Wellner, 2003; Poon and Domingos, 2008; Haghighi and Klein, 2010) and systems that build up coreference clusters incrementally (Luo et al., 2004; Yang et al., 2008; Raghunathan et al., 2010).", "startOffset": 238, "endOffset": 301}, {"referenceID": 30, "context": "Entity-level information has also been incorporated in coreference systems using joint inference (McCallum and Wellner, 2003; Poon and Domingos, 2008; Haghighi and Klein, 2010) and systems that build up coreference clusters incrementally (Luo et al., 2004; Yang et al., 2008; Raghunathan et al., 2010).", "startOffset": 238, "endOffset": 301}, {"referenceID": 21, "context": "We take the latter approach, and in particular combine the cluster-ranking (Rahman and Ng, 2011; Ma et al., 2014) and easy-first (Stoyanov and Eisner, 2012; Clark and Manning, 2015) clustering strategies.", "startOffset": 75, "endOffset": 113}, {"referenceID": 14, "context": "Other works use structured perceptron models for the same purpose (Stoyanov and Eisner, 2012; Fernandes et al., 2012; Bj\u00f6rkelund and Kuhn, 2014).", "startOffset": 66, "endOffset": 144}, {"referenceID": 8, "context": "Learning-to-search style algorithms have been employed to train coreference resolvers on trajectories of decisions similar to those that would be seen at test-time by Daum\u00e9 et al. (2005), Ma et al.", "startOffset": 167, "endOffset": 187}, {"referenceID": 8, "context": "Learning-to-search style algorithms have been employed to train coreference resolvers on trajectories of decisions similar to those that would be seen at test-time by Daum\u00e9 et al. (2005), Ma et al. (2014), and Clark and Manning (2015).", "startOffset": 167, "endOffset": 205}, {"referenceID": 8, "context": "Learning-to-search style algorithms have been employed to train coreference resolvers on trajectories of decisions similar to those that would be seen at test-time by Daum\u00e9 et al. (2005), Ma et al. (2014), and Clark and Manning (2015). Other works use structured perceptron models for the same purpose (Stoyanov and Eisner, 2012; Fernandes et al.", "startOffset": 167, "endOffset": 235}], "year": 2016, "abstractText": "A long-standing challenge in coreference resolution has been the incorporation of entity-level information \u2013 features defined over clusters of mentions instead of mention pairs. We present a neural network based coreference system that produces high-dimensional vector representations for pairs of coreference clusters. Using these representations, our system learns when combining clusters is desirable. We train the system with a learning-to-search algorithm that teaches it which local decisions (cluster merges) will lead to a high-scoring final coreference partition. The system substantially outperforms the current state-of-the-art on the English and Chinese portions of the CoNLL 2012 Shared Task dataset despite using few hand-engineered features.", "creator": "LaTeX with hyperref package"}}}