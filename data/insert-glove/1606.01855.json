{"id": "1606.01855", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2016", "title": "Bayesian Poisson Tucker Decomposition for Learning the Structure of International Relations", "abstract": "We introduce tentacle Bayesian Poisson zahri Tucker decomposition (BPTD) euro422 for directeur modeling country - - bahati country interaction laridae event data. superdome These magistrates data minneriya consist konak of interaction 200,000-a events whithorn of the ragovoy form \" country $ clivill\u00e9s i $ took wheezer action $ afro-latin a $ hena toward kelsang country $ sumerpur j $ at dingguo time $ t $. \" BPTD discovers baba overlapping charlyne country - - hunnewell community higgin memberships, ardrey including tribromide the number of latent slink communities. caracter In placket addition, it discovers directed santoso community - - longanecker community stoclet interaction visby networks that mov are 311.9 specific mullion to \" cirri topics \" glucosides of action brodiaea types mausi and sinkerball temporal \" ailette regimes. \" asvat We dystrichothorax show that poincar\u00e9 BPTD wia yields fatherland an milagrosa efficient MCMC 18-17 inference algorithm scorpii and achieves radulov better annectens predictive gehry performance than related martlet models. neola We gossec also demonstrate oar that 40-a it sandwiched discovers interpretable latent structure animatrix that agrees lutnick with systema our initially knowledge bourriaud of international epicenters relations.", "histories": [["v1", "Mon, 6 Jun 2016 18:34:56 GMT  (460kb,D)", "http://arxiv.org/abs/1606.01855v1", "To appear in Proceedings of the 33rd International Conference on Machine Learning (ICML 2016)"]], "COMMENTS": "To appear in Proceedings of the 33rd International Conference on Machine Learning (ICML 2016)", "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.LG cs.SI stat.AP", "authors": ["aaron schein", "mingyuan zhou", "david m blei", "hanna m wallach"], "accepted": true, "id": "1606.01855"}, "pdf": {"name": "1606.01855.pdf", "metadata": {"source": "META", "title": "Bayesian Poisson Tucker Decomposition for Learning the Structure of International Relations", "authors": ["Aaron Schein", "Mingyuan Zhou", "David M. Blei", "Hanna Wallach"], "emails": ["ASCHEIN@CS.UMASS.EDU", "MINGYUAN.ZHOU@MCCOMBS.UTEXAS.EDU", "DAVID.BLEI@COLUMBIA.EDU", "WALLACH@MICROSOFT.COM"], "sections": [{"heading": "1. Introduction", "text": "Like their inhabitants, countries interact with one another: they consult, negotiate, trade, threaten, and fight. These interactions are seldom uncoordinated. Rather, they are connected by a fabric of overlapping communities, such as security coalitions, treaties, trade cartels, and military alliances. For example, OPEC coordinates the petroleum export policies of its thirteen member countries, LAIA fosters trade among Latin American countries, and NATO guarantees collective defense against attacks by external parties.\nProceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\nA single country can belong to multiple communities, reflecting its different identities. For example, Venezuela\u2014 an oil-producing country and a Latin American country\u2014is a member of both OPEC and LAIA. When Venezuela interacts with other countries, it sometimes does so as an OPEC member and sometimes does so as a LAIA member.\nCountries engage in both within-community and betweencommunity interactions. For example, when acting as an OPEC member, Venezuela consults with other OPEC countries, but trades with non-OPEC, oil-importing countries. Moreover, although Venezuela engages in betweencommunity interactions when trading as an OPEC member, it engages in within-community interactions when trading as a LAIA member. To understand or predict how countries interact, we must account for their community memberships and how those memberships influence their actions.\nIn this paper, we take a new approach to learning overlapping communities from interaction events of the form \u201ccountry i took action a toward country j at time t.\u201d A data set of such interaction events can be represented as either 1) a set of event tokens, 2) a tensor of event type counts, or 3) a series of weighted multinetworks. Models that use the token representation naturally yield efficient inference algorithms, models that use the tensor representation exhibit good predictive performance, and models that use the network representation learn latent structure that aligns with well-known concepts such as communities. Previous models of interaction event data have each used a subset of these representations. Our approach\u2014Bayesian Poisson Tucker decomposition (BPTD)\u2014takes advantage of all three. ar X\niv :1\n60 6.\n01 85\n5v 1\n[ st\nat .M\nL ]\nBPTD builds on the classic Tucker decomposition (Tucker, 1964) to factorize a tensor of event type counts into three factor matrices and a four-dimensional core tensor (section 2). The factor matrices embed countries into communities, action types into \u201ctopics,\u201d and time steps into \u201cregimes.\u201d The core tensor interacts communities, topics, and regimes. The country\u2013community factors enable BPTD to learn overlapping community memberships, while the core tensor enables it to learn directed community\u2013community interaction networks specific to topics of action types and temporal regimes. Figure 1 illustrates this structure. BPTD leads to an efficient MCMC inference algorithm (section 4) and achieves better predictive performance than related models (section 6). Finally, BPTD discovers interpretable latent structure that agrees with our knowledge of international relations (section 7)."}, {"heading": "2. Bayesian Poisson Tucker Decomposition", "text": "We can represent a data set of interaction events as a set of N event tokens, where a single token en = (i\na\u2212\u2192j, t) indicates that sender country i \u2208 [V ] took action a \u2208 [A] toward receiver country j \u2208 [V ] during time step t \u2208 [T ]. Alternatively, we can aggregate these event tokens into a four-dimensional tensor Y , where element y(t)\ni a\u2212\u2192j is a count\nof the number of events of type (i a\u2212\u2192j, t). This tensor will be sparse because most event types never actually occur in practice. Finally, we can equivalently view this count tensor as a series of T weighted multinetwork snapshots, where the weight on edge i a\u2212\u2192j in the tth snapshot is y(t)\ni a\u2212\u2192j .\nBPTD models each element of count tensor Y as\ny (t)\ni a\u2212\u2192j \u223c Po ( C\u2211 c=1 \u03b8ic C\u2211 d=1 \u03b8jd K\u2211 k=1 \u03c6ak R\u2211 r=1 \u03c8tr \u03bb (r) c k\u2212\u2192d ) , (1)\nwhere \u03b8ic, \u03b8jd, \u03c6ak, \u03c8tr, and \u03bb (r)\nc k\u2212\u2192d\nare positive real num-\nbers. Factors \u03b8ic and \u03b8jd capture the rates at which countries i and j participate in communities c and d, respectively; factor \u03c6ak captures the strength of association between action a and topic k; and \u03c8tr captures how well regime r explains the events in time step t. We can collectively view the V \u00d7 C country\u2013community factors as a latent factor matrix \u0398, where the ith row represents country i\u2019s community memberships. Similarly, we can view the A\u00d7K action\u2013topic factors and the T\u00d7R time-step\u2013regime factors as latent factor matrices \u03a6 and \u03a8, respectively. Factor \u03bb(r)\nc k\u2212\u2192d\ncaptures the rate at which community c takes ac-\ntions associated with topic k toward community d during regime r. The C \u00d7 C \u00d7 K \u00d7 R such factors form a core tensor \u039b that interacts communities, topics, and regimes.\nThe country\u2013community factors are gamma-distributed,\n\u03b8ic \u223c \u0393(\u03b1i, \u03b2i) , (2)\nwhere the shape and rate parameters \u03b1i and \u03b2i are specific to country i. We place an uninformative gamma prior over these shape and rate parameters: \u03b1i, \u03b2i \u223c \u0393( 0, 0). This hierarchical prior enables BPTD to express heterogeneity in the countries\u2019 rates of activity. For example, we expect that the US will engage in more interactions than Burundi.\nThe action\u2013topic and time-step\u2013regime factors are also gamma-distributed; however, we assume that these factors are drawn directly from an uninformative gamma prior,\n\u03c6ak, \u03c8tr \u223c \u0393( 0, 0) . (3)\nBecause BPTD learns a single embedding of countries into communities, it preserves the traditional network-based notion of community membership. Any sender\u2013receiver asymmetry is captured by the core tensor \u039b, which we can\nview as a compression of count tensor Y . By allowing on-diagonal elements, which we denote by \u03bb(r)\nc k and off-\ndiagonal elements to be non-zero, the core tensor can represent both within- and between-community interactions.\nThe elements of the core tensor are gamma-distributed,\n\u03bb (r)\nc k \u223c \u0393 ( \u03b7 c \u03b7 \u2194 c \u03bdk\u03c1r, \u03b4 ) (4)\n\u03bb (r) c k\u2212\u2192d \u223c \u0393(\u03b7\u2194c \u03b7\u2194d \u03bdk\u03c1r, \u03b4) c 6= d. (5)\nEach community c \u2208 [C] has two positive weights \u03b7 c and \u03b7\u2194c that capture its rates of within- and betweencommunity interaction, respectively. Each topic k \u2208 [K] has a positive weight \u03bdk, while each regime r \u2208 [R] has a positive weight \u03c1r. We place an uninformative prior over the within-community interaction rates and gamma shrinkage priors over the other weights: \u03b7 c \u223c \u0393( 0, 0), \u03b7\u2194c \u223c \u0393(\u03b30 /C, \u03b6), \u03bdk \u223c \u0393(\u03b30 /K, \u03b6), and \u03c1r \u223c \u0393(\u03b30 /R, \u03b6). These priors bias BPTD toward learning latent structure that is sparse. Finally, we assume that \u03b4 and \u03b6 are drawn from an uninformative gamma prior: \u03b4, \u03b6 \u223c \u0393( 0, 0).\nAs K \u2192 \u221e, the topic weights and their corresponding action\u2013topic factors constitute a drawGK = \u2211\u221e k=1 \u03bdk 1\u03c6k from a gamma process (Ferguson, 1973). Similarly, as R \u2192 \u221e, the regime weights and their corresponding time-step\u2013regime factors constitute a draw GR =\u2211\u221e r=1 \u03c1r 1\u03c8r from another gamma process. As C \u2192 \u221e, the within- and between-community interaction weights and their corresponding country\u2013community factors constitute a draw GC = \u2211\u221e c=1 \u03b7 \u2194 c 1\u03b8c from a marked gamma process (Kingman, 1972). The mark associated with atom \u03b8c = (\u03b81c, . . . , \u03b8Vc) is \u03b7 c . We can view the elements of the core tensor and their corresponding factors as a draw G = \u2211\u221e c=1 \u2211\u221e d=1 \u2211\u221e k=1 \u2211\u221e r=1 \u03bb (r)\nc k\u2212\u2192d\n1\u03b8c,\u03b8d,\u03c6k,\u03c8r from a\ngamma process, provided that the expected sum of the core tensor elements is finite. This multirelational gamma process extends the relational gamma process of Zhou (2015).\nProposition 1: In the limit as C,K,R \u2192\u221e, the expected sum of the core tensor elements is finite and equal to\nE  \u221e\u2211 c=1 \u221e\u2211 k=1 \u221e\u2211 r=1 \u03bb(r) c k + \u2211 d6=c \u03bb (r) c k\u2212\u2192d  = 1 \u03b4 ( \u03b330 \u03b63 + \u03b340 \u03b64 ) .\nWe prove this proposition in the supplementary material."}, {"heading": "3. Connections to Previous Work", "text": "Poisson CP decomposition: DuBois & Smyth (2010) developed a model that assigns each event token (ignoring time steps) to one of Q latent classes, where each class q \u2208 [Q] is characterized by three categorical distributions\u2014\u03b8\u2192q\nover senders, \u03b8\u2190q over receivers, and \u03c6q over actions\u2014i.e.,\nP (en=(i a\u2212\u2192j, t) | zn=q) = \u03b8\u2192iq \u03b8\u2190jq \u03c6aq. (6)\nThis model is closely related to the Poisson-based model of Schein et al. (2015), which explicitly uses the canonical polyadic (CP) tensor decomposition (Harshman, 1970) to factorize count tensor Y into four latent factor matrices. These factor matrices jointly embed senders, receivers, action types, and time steps into a Q-dimensional space,\ny (t)\ni a\u2212\u2192j \u223c Po ( Q\u2211 q=1 \u03b8\u2192iq \u03b8 \u2190 jq \u03c6aq \u03c8tq ) , (7)\nwhere \u03b8\u2192iq , \u03b8 \u2190 jq , \u03c6aq , and \u03c8tq are positive real numbers.\nSchein et al.\u2019s model generalizes Bayesian Poisson matrix factorization (Cemgil, 2009; Gopalan et al., 2014; 2015; Zhou & Carin, 2015) and non-Bayesian Poisson CP decomposition (Chi & Kolda, 2012; Welling & Weber, 2001).\nAlthough Schein et al.\u2019s model is expressed in terms of a tensor of event type counts, the relationship between the multinomial and Poisson distributions (Kingman, 1972) means that we can also express it in terms of a set of event tokens. This yields an equation that is similar to equation 6,\nP (en=(i a\u2212\u2192j, t) | zn=q) \u221d \u03b8\u2192iq \u03b8\u2190jq \u03c6aq \u03c8tq. (8)\nConversely, DuBois & Smyth\u2019s model can be expressed as a CP tensor decomposition. This equivalence is analogous to the relationship between Poisson matrix factorization and latent Dirichlet allocation (Blei et al., 2003).\nWe can make Schein et al.\u2019s model nonparametric by adding a per-class positive weight \u03bbq \u223c \u0393(\u03b30Q , \u03b6), i.e.,\ny (t)\ni a\u2212\u2192j \u223c Po ( Q\u2211 q=1 \u03b8\u2192iq \u03b8 \u2190 jq \u03c6aq \u03c8tq \u03bbq ) . (9)\nAs Q \u2192 \u221e the per-class weights and their corresponding latent factors constitute a draw from a gamma process.\nAdding this per-class weight reveals that CP decomposition is a special case of Tucker decomposition where the cardinalities of the latent dimensions are equal and the offdiagonal elements of the core tensor are zero. DuBois & Smyth\u2019s and Schein et al.\u2019s models are therefore highly constrained special cases of BPTD that cannot capture dimension-specific structure, such as communities of countries or topics of action types. These models require each latent class to jointly summarize information about senders, receivers, action types, and time steps. This requirement conflates communities of countries and topics of action types, thus forcing each class to capture potentially redundant information. Moreover, by definition, CP decomposition models cannot express between-community interactions and cannot express sender\u2013receiver asymmetry without learning completely separate latent factor matrices for\nsenders and receivers. These limitations make it hard to interpret these models as learning community memberships.\nInfinite relational models: The infinite relational model (IRM) of Kemp et al. (2006) also learns latent structure specific to each dimension of an M -dimensional tensor; however, unlike BPTD, the elements of this tensor are binary, indicating the presence or absence of the corresponding event type. The IRM therefore uses a Bernoulli likelihood. Schmidt & M\u00f8rup (2013) extended the IRM to model a tensor of event counts by replacing the Bernoulli likelihood with a Poisson likelihood (and gamma priors):\ny (t)\ni a\u2212\u2192j \u223c Po\n( \u03bb (zt)\nzi za\u2212\u2192zj\n) , (10)\nwhere zi, zj \u2208 [C] are the respective community assignments of countries i and j, za \u2208 [K] is the topic assignment of action a, and zt \u2208 [R] is the regime assignment of time step t. This model, which we refer to as the gamma\u2013Poisson IRM (GPIRM), allocates M -dimensional event types to M -dimensional latent classes\u2014e.g., it allocates all tokens of type (i a\u2212\u2192j, t) to class (zi za\u2212\u2192zj , zt).\nThe GPIRM is a special case of BPTD where the rows of the latent factor matrices are constrained to be \u201cone-hot\u201d binary vectors\u2014i.e., \u03b8ic = 1(zi = c), \u03b8jd = 1(zj = d), \u03c6ak=1(za=k), and \u03c8tr=1(zt=r). With this constraint, the Poisson rates in equations 1 and 10 are equal. Unlike BPTD, the GPIRM is a single-membership model. In addition, it cannot express heterogeneity in rates of activity of the countries, action types, and time steps. The latter limitation can be remedied by letting \u03b8izi , \u03b8jzj , \u03c6aza , and \u03c8tzt be positive real numbers. We refer to this variant of the GPIRM as the degree-corrected GPIRM (DCGPIRM).\nStochastic block models: The IRM itself generalizes the stochastic block model (SBM) of Nowicki & Snijders (2001), which learns latent structure from binary networks. Although the SBM was originally specified using a Bernoulli likelihood, Karrer & Newman (2011) introduced an alternative specification that uses the Poisson likelihood:\nyi\u2212\u2192j \u223c Po ( C\u2211 c=1 \u03b8ic C\u2211 d=1 \u03b8jd \u03bbc\u2212\u2192d ) , (11)\nwhere \u03b8ic = 1(zi = c), \u03b8j = 1(zj = d), and \u03bbc\u2212\u2192d is a positive real number. Like the IRM and the GPIRM, the SBM is a single-membership model and cannot express heterogeneity in the countries\u2019 rates of activity. Airoldi et al. (2008) addressed the former limitation by letting \u03b8ic \u2208 [0, 1] such that \u2211C c=1 \u03b8ic = 1. Meanwhile, Karrer & Newman (2011) addressed the latter limitation by allowing both \u03b8izi and \u03b8jzj to be positive real numbers, much like the DCGPIRM. Ball et al. (2011) simultaneously addressed both limitations by letting \u03b8ic, \u03b8jd \u2265 0, but constrained \u03bbc\u2212\u2192d = \u03bbd\u2212\u2192c. Finally, Zhou (2015) extended\nBall et al.\u2019s model to be nonparametric and introduced the Poisson\u2013Bernoulli distribution to link binary data to the Poisson likelihood in a principled fashion. In this model, the elements of the core matrix and their corresponding factors constitute a draw from a relational gamma process.\nNon-Poisson Tucker decomposition: Researchers sometimes refer to the Poisson rate in equation 11 as being \u201cbilinear\u201d because it can equivalently be written as \u03b8j \u039b\u03b8 > i . Nickel et al. (2012) introduced RESCAL\u2014 a non-probabilistic bilinear model for binary data that achieves state-of-the-art performance at relation extraction. Nickel et al. (2015) then introduced several extensions for extracting relations of different types. Bilinear models, such as RESCAL and its extensions, are all special cases (albeit non-probabilistic ones) of Tucker decomposition.\nHoff (2015) recently developed a Gaussian-based Tucker decomposition model and multilinear tensor regression model (Hoff, 2014) for analyzing interaction event data.\nFinally, there are many other Tucker decomposition methods (Kolda & Bader, 2009). Although these include nonparametric (Xu et al., 2012) and nonnegative variants (Kim & Choi, 20007; M\u00f8rup et al., 2008; Cichocki et al., 2009), BPTD is the first such model to use a Poisson likelihood."}, {"heading": "4. Posterior Inference", "text": "Given an observed count tensor Y , inference in BPTD involves \u201cinverting\u201d the generative process to obtain the posterior distribution over the parameters conditioned on Y and hyperparameters 0 and \u03b30. The posterior distribution is analytically intractable; however, we can approximate it using a set of posterior samples. We draw these samples using Gibbs sampling, repeatedly resampling the value of each parameter from its conditional posterior given Y , 0, \u03b30, and the current values of the other parameters. We express each parameter\u2019s conditional posterior in a closed form using gamma\u2013Poisson conjugacy and the auxiliary variable techniques of Zhou & Carin (2012). We provide the conditional posteriors in the supplementary material.\nThe conditional posteriors depend on Y via a set of \u201clatent sources\u201d (Cemgil, 2009) or subcounts. Because of the Poisson additivity theorem (Kingman, 1972), each latent source y(tr)\nic ak\u2212\u2192jd\nis a Poisson-distributed random variable:\ny (tr)\nic ak\u2212\u2192jd\n\u223c Po ( \u03b8ic \u03b8jd \u03c6ak \u03c8tr \u03bb (r)\nc k\u2212\u2192d\n) (12)\ny (t)\ni a\u2212\u2192j = C\u2211 c=1 D\u2211 d=1 K\u2211 k=1 R\u2211 r=1 y (tr) ic ak\u2212\u2192jd . (13)\nTogether, equations 12 and 13 are equivalent to equation 1. In practice, we can equivalently view each latent source in\nterms of the token representation described in section 2,\ny (tr)\nic ak\u2212\u2192jd\n= N\u2211 n=1 1(en=(i a\u2212\u2192j, t))1(zn=(c k\u2212\u2192d, r)), (14)\nwhere each token\u2019s class assignment zn is an auxiliary latent variable. Using this representation, computing the latent sources (given the current values of the model parameters) simply involves allocating event tokens to classes, much like the inference algorithm for DuBois & Smyth\u2019s model, and aggregating them using equation 14. The conditional posterior for each token\u2019s class assignment is\nP (zn=(c k\u2212\u2192d, r) | en=(i a\u2212\u2192j, t),Y , 0, \u03b30, . . .)\n\u221d \u03b8ic \u03b8jd \u03c6ak \u03c8tr \u03bb(r) c k\u2212\u2192d . (15)\nComputation is dominated by the normalizing constant\nZ (t)\ni a\u2212\u2192j = C\u2211 c=1 C\u2211 d=1 K\u2211 k=1 R\u2211 r=1 \u03b8ic \u03b8jd \u03c6ak \u03c8tr \u03bb (r) c k\u2212\u2192d . (16)\nComputing this normalizing constant na\u0131\u0308vely involves O(C \u00d7 C \u00d7 K \u00d7 R) operations; however, because each latent class (c k\u2212\u2192d, r) is composed of four separate dimensions, we can improve efficiency. We instead compute\nZ (t)\ni a\u2212\u2192j = C\u2211 c=1 \u03b8ic C\u2211 d=1 \u03b8jd K\u2211 k=1 \u03b8ak R\u2211 r=1 \u03c8tr \u03bb (r) c k\u2212\u2192d , (17)\nwhich involves O(C + C +K +R) operations.\nCompositional allocation using equations 15 and 17 improves computational efficiency significantly over na\u0131\u0308ve non-compositional allocation using equations 15 and 16. In practice, we setC,K, andR to large values to approximate the nonparametric interpretation of BPTD. If, for example, C = 50, K = 10, and R = 5, computing the normalizing constant for equation 15 using equation 16 requires 2,753 times the number of operations implied by equation 17.\nProposition 2: For an M -dimensional core tensor with D1 \u00d7 . . .\u00d7DM elements, computing the normalizing constant using non-compositional allocation requires 1 \u2264 \u03c0 < \u221e times the number of operations required to compute it using compositional allocation. When D1 = . . .=DM =1, \u03c0=1. As Dm, Dm\u2032 \u2192\u221e for any m and m\u2032 6=m, \u03c0 \u2192\u221e.\nWe prove this proposition in the supplementary material.\nBPTD and other Poisson-based models yield allocation inference algorithms that take advantage of the inherent sparsity of the data and scale with the number of event tokens. In contrast, non-Poisson tensor decomposition models (including Hoff\u2019s model) lead to algorithms that scale with the size of the count tensor. Allocation-based inference in BPTD is especially efficient because it compositionally allocates each M -dimensional event token to an\nM -dimensional latent class. Figure 2 illustrates this process. CP decomposition models, such as those of DuBois & Smyth (2010) and Schein et al. (2015), only permit noncompositional allocation. For example, while BPTD allocates each token en = (i\na\u2212\u2192j, t) to a four-dimensional latent class (c k\u2212\u2192d, r), Schein et al.\u2019s model allocates en to a one-dimensional latent class q that cannot be decomposed. Therefore, whenQ=C\u00d7C\u00d7K\u00d7R, BPTD yields a faster allocation inference algorithm than Schein et al.\u2019s model."}, {"heading": "5. Country\u2013Country Interaction Event Data", "text": "Our data come from the Integrated Crisis Early Warning System (ICEWS) of Boschee et al. and the Global Database of Events, Language, and Tone (GDELT) of Leetaru & Schrodt (2013). ICEWS and GDELT both use the Conflict and Mediation Event Observations (CAMEO) hierarchy (Gerner et al.) for senders, receivers, and actions.\nThe top-level CAMEO coding for senders and receivers is their country affiliation, while lower levels in the hierarchy incorporate more specific attributes like their sectors (e.g., government or civilian) and their religious or ethnic affiliations. When studying international relations using CAMEO-coded event data, researchers usually consider only the senders\u2019 and receivers\u2019 countries. There are 249 countries represented in ICEWS, which include nonuniversally recognized states, such as Occupied Palestinian Territory, and former states, such as Former Yugoslav Republic of Macedonia; there are 233 countries in GDELT.\nThe top level for actions, which we use in our analyses, consists of twenty action classes, roughly ranked according to their overall sentiment. For example, the most negative is 20\u2014Use Unconventional Mass Violence. CAMEO further divides these actions into the QuadClass scheme: Verbal Cooperation (actions 2\u20135), Material Cooperation (actions 6\u20137), Verbal Conflict (actions 8\u201316), and Material Conflict (16\u201320). The first action (1\u2014Make Statement) is neutral."}, {"heading": "6. Predictive Analysis", "text": "Baseline models: We compared BPTD\u2019s predictive performance to that of three baseline models, described in section 3: 1) GPIRM, 2) DCGPIRM, and 3) the Bayesian Poisson tensor factorization (BPTF) model of Schein et al. (2015). All three models use a Poisson likelihood and have the same two hyperparameters as BPTD\u2014i.e., 0 and \u03b30. We set 0 to 0.1, as recommended by Gelman (2006), and we set \u03b30 so that (\u03b30 /C) 2 (\u03b30 /K) (\u03b30 /R) = 0.01. This parameterization encourages the elements of the core tensor \u039b to be sparse. We implemented an MCMC inference algorithm for each model. We provide the full generative process for all three models in the supplementary material.\nGPIRM and DCGPIRM are both Tucker decomposition models and thus allocate events to four-dimensional latent classes. The cardinalities of these latent dimensions are the same as BPTD\u2019s\u2014i.e., C, K, and R. In contrast, BPTF is a CP decomposition model and thus allocates events to one-dimensional latent classes. We set the cardinality of this dimension so that the total number of latent factors in BPTF\u2019s likelihood was equal to the total number of latent factors in BPTD\u2019s likelihood\u2014i.e., Q = d (V\u00d7C)+(A\u00d7K)+(T\u00d7R)+(C\n2\u00d7K\u00d7R) V+V+A+T+1 e. We chose not\nto let BPTF and BPTD use the same number of latent classes\u2014i.e., to set Q = C2 \u00d7 K \u00d7 R. BPTF does not permit non-compositional allocation, so MCMC inference becomes very slow for even moderate values of C, K, and R. CP decomposition models also tend to overfit when Q is large (Zhao et al., 2015). Throughout our predictive experiments, we let C= 20, K= 6, and R= 3. These values were well-supported by the data, as we explain in section 7.\nExperimental setup: We constructed twelve different observed tensors\u2014six from ICEWS and six from GDELT. Five of the six tensors for each source (ICEWS or GDELT) correspond to one-year time spans with monthly time steps, starting with 2004 and ending with 2008; the sixth corresponds to a five-year time span with monthly time steps, spanning 1995\u20132000. We divided each tensor Y into a training tensor Y train = Y (1), . . . ,Y (T\u22123) and a test tensor Y test = Y (T\u22122), . . . ,Y (T ). We further divided each test tensor into a held-out portion and an observed portion via a binary mask. We experimented with two different masks: one that treats the elements involving the most active fifteen countries as the held-out portion and the remaining elements as the observed portion, and one that does the opposite. The first mask enabled us to evaluate the models\u2019 reconstructions of the densest (and arguably most interesting) portion of each test tensor, while the second mask enabled us to evaluate their reconstructions of its complement. Across the entire GDELT database, for example, the elements involving the most active fifteen countries\u2014i.e., 6% of all 233 countries\u2014account for 30%\nof the event tokens. Moreover, 40% of these elements are non-zero. These non-zero elements are highly dispersed, with a variance-to-mean ratio of 220. In contrast, only 0.7% of the elements involving the other countries are nonzero. These elements have a variance-to-mean ratio of 26.\nFor each combination of the four models, twelve tensors, and two masks, we ran 5,000 iterations of MCMC inference on the training tensor. We clamped the country\u2013community factors, the action\u2013topic factors, and the core tensor and then inferred the time-step\u2013regime factors for the test tensor using its observed portion by running 1,000 iterations of MCMC inference. We saved every tenth sample after the first 500. We used each sample, along with the country\u2013 community factors, the action\u2013topic factors, and the core tensor, to compute the Poisson rate for each element in the held-out portion of the test tensor. Finally, we averaged these rates across samples and used each element\u2019s average rate to compute its probability. We combined the heldout elements\u2019 probabilities by taking their geometric mean or, equivalently, by computing their inverse perplexity. We chose this combination strategy to ensure that the models were penalized heavily for making poor predictions on the non-zero elements and were not rewarded excessively for making good predictions on the zero elements. By clamping the country\u2013community factors, the action\u2013topic factors, and the core tensor after training, our experimental setup is analogous to that used to assess collaborative filtering models\u2019 strong generalization ability (Marlin, 2004).\nResults: Figure 3 illustrates the results for each combination of the four models, twelve tensors, and two masks. The top row contains the results from the twelve experiments involving the first mask, where the elements involving the most active fifteen countries were treated as the held-out portion. BPTD outperformed the baselines significantly. BPTF\u2014itself a state-of-the-art model\u2014performed better than BPTD in only one experiment. In general, the Tucker decomposition allows BPTD to learn richer latent structure that generalizes better to held-out data. The bottom row contains the results from the experiments involving the second mask. The models\u2019 performance was closer in these experiments, probably because of the large proportion of easy-to-predict zero elements. BPTD and BPTF performed indistinguishably in these experiments, and both models outperformed the GPIRM and the DCGPIRM. The single-membership nature of the GPIRM and the DCGPIRM prevents them from expressing high levels of heterogeneity in the countries\u2019 rates of activity. When the heldout elements were highly dispersed, these models sometimes made extremely inaccurate predictions. In contrast, the mixed-membership nature of BPTD and BPTF allows them to better express heterogeneous rates of activity."}, {"heading": "7. Exploratory Analysis", "text": "We used a tensor of ICEWS events spanning 1995\u20132000, with monthly time steps, to explore the latent structure discovered by BPTD. We initially let C = 50, K = 8, and R= 3\u2014i.e., C \u00d7 C \u00d7 K \u00d7 R = 60, 000 latent classes\u2014 and used the shrinkage priors to adaptively learn the most appropriate numbers of communities, topics, and regimes. We found C = 20 communities and K = 6 topics with weights that were significantly greater than zero. We provide a plot of the community weights in the supplementary material. Although all three regimes had non-zero weights, one had a much larger weight than the other two. For comparison, Schein et al. (2015) used fifty latent classes to model the same data, while Hoff (2015) used C = 4, K=4, and R=4 to model a similar tensor from GDELT.\nTopics of action types: We show the inferred action\u2013topic factors as a heatmap in the left subplot of figure 4. We ordered the topics by their weights \u03bd1, . . . , \u03bdK , which are above the heatmap. The inferred topics correspond very closely to CAMEO\u2019s QuadClass scheme. Moving from left to right, the topics place their mass on increasingly negative actions. Topics 1 and 2 place most of their mass on Verbal Cooperation actions; topic 3 places most of its mass on Material Cooperation actions and the neutral 1\u2014Make Statement action; topic 4 places most of its mass on Verbal Conflict actions and the 1\u2014Make Statement action; and topics 5 and 6 place their mass on Material Conflict actions.\nTopic-partitioned community\u2013community networks: In the right subplot of figure 4, we visualize the inferred community structure for topic k=1 and the most active regime r. The bottom-left heatmap is the community\u2013community interaction network \u039b(r)k . The top-left heatmap depicts the rate at which each country i acts as a sender in each community c\u2014i.e., \u03b8ic \u2211V j=1 \u2211C d=1 \u03b8jd \u03bb (r)\nc k\u2212\u2192d\n. Similarly, the\nbottom-right heatmap depicts the rate at which each country acts as a receiver in each community. The top-right heatmap depicts the number of times each country i took\nan action associated with topic k toward each country j during regime r\u2014i.e., \u2211C c=1 \u2211C d=1 \u2211A a=1 \u2211T t=1 y (tr)\nic ak\u2212\u2192jd\n.\nWe grouped the countries by their strongest community memberships and ordered the communities by their withincommunity interaction weights \u03b7 1 , . . . , \u03b7\nC , from smallest to largest; the thin green lines separate the countries that are strongly associated with one community from the countries that are strongly associated with its adjacent communities.\nSome communities contain only one or two strongly associated countries. For example, community 1 contains only the US, community 6 contains only China, and community 7 contains only Russia and Belarus. These communities mostly engage in between-community interaction. Other larger communities, such as communities 9 and 15, mostly engage in within-community interaction. Most communities have a strong geographic interpretation. Moving upward from the bottom, there are communities that correspond to Eastern Europe, East Africa, South-Central Africa, Latin America, Australasia, Central Europe, Central Asia, etc. The community\u2013community interaction network summarizes the patterns in the top-right heatmap. This topic is dominated by the 4\u2013Consult action, so the network is symmetric; the more negative topics have asymmetric community\u2013community interaction networks. We therefore hypothesize that cooperation is an inherently reciprocal type of interaction. We provide visualizations for the other five topics in the supplementary material."}, {"heading": "8. Summary", "text": "We presented Bayesian Poisson Tucker decomposition (BPTD) for learning the latent structure of international relations from country\u2013country interaction events of the form \u201ccountry i took action a toward country j at time t.\u201d Unlike previous models, BPTD takes advantage of all three representations of an interaction event data set: 1) a set of event tokens, 2) a tensor of event type counts, and 3) a series of weighted multinetwork snapshots. BPTD uses a Poisson\nlikelihood, respecting the discrete nature of the data and its inherent sparsity. Moreover, BPTD yields a compositional allocation inference algorithm that is more efficient than non-compositional allocation algorithms. Because BPTD is a Tucker decomposition model, it shares parameters across latent classes. In contrast, CP decomposition models force each latent class to capture potentially redundant information. BPTD therefore \u201cdoes more with less.\u201d This efficiency is reflected in our predictive analysis: BPTD outperforms BPTF\u2014a CP decomposition model\u2014as well as two other baselines. BPTD learns interpretable latent structure that aligns with well-known concepts from the networks literature. Specifically, BPTD learns latent country\u2013 community memberships, including the number of communities, as well as directed community\u2013community interaction networks that are specific to topics of action types and temporal regimes. This structure captures the complex-\nity of country\u2013country interactions, while revealing patterns that agree with our knowledge of international relations. Finally, although we presented BPTD in the context of interaction events, BPTD is well suited to learning latent structure from other types of multidimensional count data."}, {"heading": "Acknowledgements", "text": "We thank Abigail Jacobs and Brandon Stewart for helpful discussions. This work was supported by NSF #SBE0965436, #IIS-1247664, #IIS-1320219; ONR #N0001411-1-0651; DARPA #FA8750-14-2-0009, #N66001-15-C4032; Adobe; the John Templeton Foundation; the Sloan Foundation; the UMass Amherst Center for Intelligent Information Retrieval. Any opinions, findings, conclusions, or recommendations expressed in this material are the authors\u2019 and do not necessarily reflect those of the sponsors."}], "references": [{"title": "Mixed membership stochastic blockmodels", "author": ["E.M. Airoldi", "D.M. Blei", "S.E. Feinberg", "E.P. Xing"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Airoldi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Airoldi et al\\.", "year": 2008}, {"title": "Efficient and principled method for detecting communities in networks", "author": ["B. Ball", "B. Karrer", "M.E.J. Newman"], "venue": "Physical Review E,", "citeRegEx": "Ball et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ball et al\\.", "year": 2011}, {"title": "Latent Dirichlet allocation", "author": ["D. Blei", "A. Ng", "M. Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Bayesian inference for nonnegative matrix factorisation models", "author": ["A.T. Cemgil"], "venue": "Computational Intelligence and Neuroscience,", "citeRegEx": "Cemgil,? \\Q2009\\E", "shortCiteRegEx": "Cemgil", "year": 2009}, {"title": "On tensors, sparsity, and nonnegative factorizations", "author": ["E.C. Chi", "T.G. Kolda"], "venue": "SIAM Journal on Matrix Analysis and Applications,", "citeRegEx": "Chi and Kolda,? \\Q2012\\E", "shortCiteRegEx": "Chi and Kolda", "year": 2012}, {"title": "Nonnegative Matrix and Tensor Factorizations: Applications to Exploratory Multi-Way Data Analysis and Blind Source Separation", "author": ["A. Cichocki", "R. Zdunek", "A.H. Phan", "S. i Amari"], "venue": null, "citeRegEx": "Cichocki et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Cichocki et al\\.", "year": 2009}, {"title": "Modeling relational events via latent classes", "author": ["C. DuBois", "P. Smyth"], "venue": "In Proceedings of the Sixteenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp", "citeRegEx": "DuBois and Smyth,? \\Q2010\\E", "shortCiteRegEx": "DuBois and Smyth", "year": 2010}, {"title": "A Bayesian analysis of some nonparametric problems", "author": ["T.S. Ferguson"], "venue": "The Annals of Statistics,", "citeRegEx": "Ferguson,? \\Q1973\\E", "shortCiteRegEx": "Ferguson", "year": 1973}, {"title": "Prior distributions for variance parameters in hierarchical models", "author": ["A. Gelman"], "venue": "Bayesian Analysis,", "citeRegEx": "Gelman,? \\Q2006\\E", "shortCiteRegEx": "Gelman", "year": 2006}, {"title": "Bayesian nonparametric Poisson factorization for recommendation systems", "author": ["P. Gopalan", "F.J.R. Ruiz", "R. Ranganath", "D.M. Blei"], "venue": "In Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Gopalan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gopalan et al\\.", "year": 2014}, {"title": "Scalable recommendation with Poisson factorization", "author": ["P. Gopalan", "J. Hofman", "D. Blei"], "venue": "In Proceedings of the Thirty-First Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Gopalan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gopalan et al\\.", "year": 2015}, {"title": "Foundations of the PARAFAC procedure: Models and conditions for an \u201cexplanatory\u201d multimodal factor analysis", "author": ["R. Harshman"], "venue": "UCLA Working Papers in Phonetics,", "citeRegEx": "Harshman,? \\Q1970\\E", "shortCiteRegEx": "Harshman", "year": 1970}, {"title": "Multilinear tensor regression for longitudinal relational data", "author": ["P. Hoff"], "venue": null, "citeRegEx": "Hoff,? \\Q2014\\E", "shortCiteRegEx": "Hoff", "year": 2014}, {"title": "Equivariant and scale-free Tucker decomposition models", "author": ["P. Hoff"], "venue": "Bayesian Analysis,", "citeRegEx": "Hoff,? \\Q2015\\E", "shortCiteRegEx": "Hoff", "year": 2015}, {"title": "Stochastic blockmodels and community structure in networks", "author": ["B. Karrer", "M.E.J. Newman"], "venue": "Physical Review E,", "citeRegEx": "Karrer and Newman,? \\Q2011\\E", "shortCiteRegEx": "Karrer and Newman", "year": 2011}, {"title": "Learning systems of concepts with an infinite relational model", "author": ["C. Kemp", "J.B. Tenenbaum", "T.L. Griffiths", "T. Yamada", "N. Ueda"], "venue": "In Proceedings of the Twenty-First National Conference on Artificial Intelligence,", "citeRegEx": "Kemp et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kemp et al\\.", "year": 2006}, {"title": "Nonnegative Tucker decomposition", "author": ["Kim", "Y.-D", "S. Choi"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Kim et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2000}, {"title": "Tensor decompositions and applications", "author": ["T.G. Kolda", "B.W. Bader"], "venue": "SIAM Review,", "citeRegEx": "Kolda and Bader,? \\Q2009\\E", "shortCiteRegEx": "Kolda and Bader", "year": 2009}, {"title": "GDELT: Global data on events, location, and tone, 1979\u20132012", "author": ["K. Leetaru", "P. Schrodt"], "venue": "Working paper,", "citeRegEx": "Leetaru and Schrodt,? \\Q2013\\E", "shortCiteRegEx": "Leetaru and Schrodt", "year": 2013}, {"title": "Collaborative filtering: A machine learning perspective", "author": ["B. Marlin"], "venue": "Master\u2019s thesis, University of Toronto,", "citeRegEx": "Marlin,? \\Q2004\\E", "shortCiteRegEx": "Marlin", "year": 2004}, {"title": "Algorithms for sparse nonnegative Tucker decompositions", "author": ["M. M\u00f8rup", "L.K. Hansen", "S.M. Arnfred"], "venue": "Neural Computation,", "citeRegEx": "M\u00f8rup et al\\.,? \\Q2008\\E", "shortCiteRegEx": "M\u00f8rup et al\\.", "year": 2008}, {"title": "Factorizing YAGO: Scalable machine learning for linked data", "author": ["M. Nickel", "V. Tresp", "Kriegel", "H.-P"], "venue": "In Proceedings of the Twenty-First International World Wide Web Conference,", "citeRegEx": "Nickel et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2012}, {"title": "A review of relational machine learning for knowledge graphs: From multi-relational link prediction to automated knowledge graph construction", "author": ["M. Nickel", "K. Murphy", "V. Tresp", "E. Gabrilovich"], "venue": null, "citeRegEx": "Nickel et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2015}, {"title": "Estimation and prediction for stochastic blockstructures", "author": ["K. Nowicki", "T.A.B. Snijders"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Nowicki and Snijders,? \\Q2001\\E", "shortCiteRegEx": "Nowicki and Snijders", "year": 2001}, {"title": "Nonparametric Bayesian modeling of complex networks: An introduction", "author": ["M.N. Schmidt", "M. M\u00f8rup"], "venue": "IEEE Signal Processing Magazine,", "citeRegEx": "Schmidt and M\u00f8rup,? \\Q2013\\E", "shortCiteRegEx": "Schmidt and M\u00f8rup", "year": 2013}, {"title": "The extension of factor analysis to threedimensional matrices", "author": ["L.R. Tucker"], "venue": "Contributions to Mathematical Psychology. Holt, Rinehart and Winston,", "citeRegEx": "Tucker,? \\Q1964\\E", "shortCiteRegEx": "Tucker", "year": 1964}, {"title": "Positive tensor factorization", "author": ["M. Welling", "M. Weber"], "venue": "Pattern Recognition Letters,", "citeRegEx": "Welling and Weber,? \\Q2001\\E", "shortCiteRegEx": "Welling and Weber", "year": 2001}, {"title": "Infinite Tucker decomposition: Nonparametric Bayesian models for multiway data analysis", "author": ["Z. Xu", "F. Yan", "Y. Qi"], "venue": "In Proceedings of the Twenty-Ninth International Conference on Machine Learning,", "citeRegEx": "Xu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2012}, {"title": "Bayesian CP factorization of incomplete tensors with automatic rank determination", "author": ["Q. Zhao", "L. Zhang", "A. Cichocki"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Zhao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}, {"title": "Infinite edge partition models for overlapping community detection and link prediction", "author": ["M. Zhou"], "venue": "In Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Zhou,? \\Q2015\\E", "shortCiteRegEx": "Zhou", "year": 2015}, {"title": "Augment-and-conquer negative binomial processes", "author": ["M. Zhou", "L. Carin"], "venue": "In Advances in Neural Information Processing Systems Twenty-Five,", "citeRegEx": "Zhou and Carin,? \\Q2012\\E", "shortCiteRegEx": "Zhou and Carin", "year": 2012}, {"title": "Negative binomial process count and mixture modeling", "author": ["M. Zhou", "L. Carin"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Zhou and Carin,? \\Q2015\\E", "shortCiteRegEx": "Zhou and Carin", "year": 2015}], "referenceMentions": [{"referenceID": 25, "context": "BPTD builds on the classic Tucker decomposition (Tucker, 1964) to factorize a tensor of event type counts into three factor matrices and a four-dimensional core tensor (section 2).", "startOffset": 48, "endOffset": 62}, {"referenceID": 7, "context": "As K \u2192 \u221e, the topic weights and their corresponding action\u2013topic factors constitute a drawGK = \u2211\u221e k=1 \u03bdk 1\u03c6k from a gamma process (Ferguson, 1973).", "startOffset": 130, "endOffset": 146}, {"referenceID": 29, "context": "This multirelational gamma process extends the relational gamma process of Zhou (2015). Proposition 1: In the limit as C,K,R \u2192\u221e, the expected sum of the core tensor elements is finite and equal to E \uf8ee\uf8f0 \u221e \u2211", "startOffset": 75, "endOffset": 87}, {"referenceID": 11, "context": "(2015), which explicitly uses the canonical polyadic (CP) tensor decomposition (Harshman, 1970) to factorize count tensor Y into four latent factor matrices.", "startOffset": 79, "endOffset": 95}, {"referenceID": 3, "context": "\u2019s model generalizes Bayesian Poisson matrix factorization (Cemgil, 2009; Gopalan et al., 2014; 2015; Zhou & Carin, 2015) and non-Bayesian Poisson CP decomposition (Chi & Kolda, 2012; Welling & Weber, 2001).", "startOffset": 59, "endOffset": 121}, {"referenceID": 9, "context": "\u2019s model generalizes Bayesian Poisson matrix factorization (Cemgil, 2009; Gopalan et al., 2014; 2015; Zhou & Carin, 2015) and non-Bayesian Poisson CP decomposition (Chi & Kolda, 2012; Welling & Weber, 2001).", "startOffset": 59, "endOffset": 121}, {"referenceID": 2, "context": "This equivalence is analogous to the relationship between Poisson matrix factorization and latent Dirichlet allocation (Blei et al., 2003).", "startOffset": 119, "endOffset": 138}, {"referenceID": 15, "context": "Infinite relational models: The infinite relational model (IRM) of Kemp et al. (2006) also learns latent structure specific to each dimension of an M -dimensional tensor; however, unlike BPTD, the elements of this tensor are binary, indicating the presence or absence of the corresponding event type.", "startOffset": 67, "endOffset": 86}, {"referenceID": 15, "context": "Infinite relational models: The infinite relational model (IRM) of Kemp et al. (2006) also learns latent structure specific to each dimension of an M -dimensional tensor; however, unlike BPTD, the elements of this tensor are binary, indicating the presence or absence of the corresponding event type. The IRM therefore uses a Bernoulli likelihood. Schmidt & M\u00f8rup (2013) extended the IRM to model a tensor of event counts by replacing the Bernoulli likelihood with a Poisson likelihood (and gamma priors):", "startOffset": 67, "endOffset": 371}, {"referenceID": 12, "context": "Hoff (2015) recently developed a Gaussian-based Tucker decomposition model and multilinear tensor regression model (Hoff, 2014) for analyzing interaction event data.", "startOffset": 115, "endOffset": 127}, {"referenceID": 27, "context": "Although these include nonparametric (Xu et al., 2012) and nonnegative variants (Kim & Choi, 20007; M\u00f8rup et al.", "startOffset": 37, "endOffset": 54}, {"referenceID": 20, "context": ", 2012) and nonnegative variants (Kim & Choi, 20007; M\u00f8rup et al., 2008; Cichocki et al., 2009), BPTD is the first such model to use a Poisson likelihood.", "startOffset": 33, "endOffset": 95}, {"referenceID": 5, "context": ", 2012) and nonnegative variants (Kim & Choi, 20007; M\u00f8rup et al., 2008; Cichocki et al., 2009), BPTD is the first such model to use a Poisson likelihood.", "startOffset": 33, "endOffset": 95}, {"referenceID": 0, "context": "Airoldi et al. (2008) addressed the former limitation by letting \u03b8ic \u2208 [0, 1] such that \u2211C c=1 \u03b8ic = 1.", "startOffset": 0, "endOffset": 22}, {"referenceID": 0, "context": "Airoldi et al. (2008) addressed the former limitation by letting \u03b8ic \u2208 [0, 1] such that \u2211C c=1 \u03b8ic = 1. Meanwhile, Karrer & Newman (2011) addressed the latter limitation by allowing both \u03b8izi and \u03b8jzj to be positive real numbers, much like the DCGPIRM.", "startOffset": 0, "endOffset": 138}, {"referenceID": 0, "context": "Airoldi et al. (2008) addressed the former limitation by letting \u03b8ic \u2208 [0, 1] such that \u2211C c=1 \u03b8ic = 1. Meanwhile, Karrer & Newman (2011) addressed the latter limitation by allowing both \u03b8izi and \u03b8jzj to be positive real numbers, much like the DCGPIRM. Ball et al. (2011) simultaneously addressed both limitations by letting \u03b8ic, \u03b8jd \u2265 0, but constrained \u03bbc\u2212 \u2192d = \u03bbd\u2212 \u2192c.", "startOffset": 0, "endOffset": 272}, {"referenceID": 0, "context": "Airoldi et al. (2008) addressed the former limitation by letting \u03b8ic \u2208 [0, 1] such that \u2211C c=1 \u03b8ic = 1. Meanwhile, Karrer & Newman (2011) addressed the latter limitation by allowing both \u03b8izi and \u03b8jzj to be positive real numbers, much like the DCGPIRM. Ball et al. (2011) simultaneously addressed both limitations by letting \u03b8ic, \u03b8jd \u2265 0, but constrained \u03bbc\u2212 \u2192d = \u03bbd\u2212 \u2192c. Finally, Zhou (2015) extended Ball et al.", "startOffset": 0, "endOffset": 393}, {"referenceID": 0, "context": "Airoldi et al. (2008) addressed the former limitation by letting \u03b8ic \u2208 [0, 1] such that \u2211C c=1 \u03b8ic = 1. Meanwhile, Karrer & Newman (2011) addressed the latter limitation by allowing both \u03b8izi and \u03b8jzj to be positive real numbers, much like the DCGPIRM. Ball et al. (2011) simultaneously addressed both limitations by letting \u03b8ic, \u03b8jd \u2265 0, but constrained \u03bbc\u2212 \u2192d = \u03bbd\u2212 \u2192c. Finally, Zhou (2015) extended Ball et al.\u2019s model to be nonparametric and introduced the Poisson\u2013Bernoulli distribution to link binary data to the Poisson likelihood in a principled fashion. In this model, the elements of the core matrix and their corresponding factors constitute a draw from a relational gamma process. Non-Poisson Tucker decomposition: Researchers sometimes refer to the Poisson rate in equation 11 as being \u201cbilinear\u201d because it can equivalently be written as \u03b8j \u039b\u03b8 > i . Nickel et al. (2012) introduced RESCAL\u2014 a non-probabilistic bilinear model for binary data that achieves state-of-the-art performance at relation extraction.", "startOffset": 0, "endOffset": 885}, {"referenceID": 0, "context": "Airoldi et al. (2008) addressed the former limitation by letting \u03b8ic \u2208 [0, 1] such that \u2211C c=1 \u03b8ic = 1. Meanwhile, Karrer & Newman (2011) addressed the latter limitation by allowing both \u03b8izi and \u03b8jzj to be positive real numbers, much like the DCGPIRM. Ball et al. (2011) simultaneously addressed both limitations by letting \u03b8ic, \u03b8jd \u2265 0, but constrained \u03bbc\u2212 \u2192d = \u03bbd\u2212 \u2192c. Finally, Zhou (2015) extended Ball et al.\u2019s model to be nonparametric and introduced the Poisson\u2013Bernoulli distribution to link binary data to the Poisson likelihood in a principled fashion. In this model, the elements of the core matrix and their corresponding factors constitute a draw from a relational gamma process. Non-Poisson Tucker decomposition: Researchers sometimes refer to the Poisson rate in equation 11 as being \u201cbilinear\u201d because it can equivalently be written as \u03b8j \u039b\u03b8 > i . Nickel et al. (2012) introduced RESCAL\u2014 a non-probabilistic bilinear model for binary data that achieves state-of-the-art performance at relation extraction. Nickel et al. (2015) then introduced several extensions for extracting relations of different types.", "startOffset": 0, "endOffset": 1043}, {"referenceID": 0, "context": "Airoldi et al. (2008) addressed the former limitation by letting \u03b8ic \u2208 [0, 1] such that \u2211C c=1 \u03b8ic = 1. Meanwhile, Karrer & Newman (2011) addressed the latter limitation by allowing both \u03b8izi and \u03b8jzj to be positive real numbers, much like the DCGPIRM. Ball et al. (2011) simultaneously addressed both limitations by letting \u03b8ic, \u03b8jd \u2265 0, but constrained \u03bbc\u2212 \u2192d = \u03bbd\u2212 \u2192c. Finally, Zhou (2015) extended Ball et al.\u2019s model to be nonparametric and introduced the Poisson\u2013Bernoulli distribution to link binary data to the Poisson likelihood in a principled fashion. In this model, the elements of the core matrix and their corresponding factors constitute a draw from a relational gamma process. Non-Poisson Tucker decomposition: Researchers sometimes refer to the Poisson rate in equation 11 as being \u201cbilinear\u201d because it can equivalently be written as \u03b8j \u039b\u03b8 > i . Nickel et al. (2012) introduced RESCAL\u2014 a non-probabilistic bilinear model for binary data that achieves state-of-the-art performance at relation extraction. Nickel et al. (2015) then introduced several extensions for extracting relations of different types. Bilinear models, such as RESCAL and its extensions, are all special cases (albeit non-probabilistic ones) of Tucker decomposition. Hoff (2015) recently developed a Gaussian-based Tucker decomposition model and multilinear tensor regression model (Hoff, 2014) for analyzing interaction event data.", "startOffset": 0, "endOffset": 1266}, {"referenceID": 3, "context": "The conditional posteriors depend on Y via a set of \u201clatent sources\u201d (Cemgil, 2009) or subcounts.", "startOffset": 69, "endOffset": 83}, {"referenceID": 28, "context": "We express each parameter\u2019s conditional posterior in a closed form using gamma\u2013Poisson conjugacy and the auxiliary variable techniques of Zhou & Carin (2012). We provide the conditional posteriors in the supplementary material.", "startOffset": 138, "endOffset": 158}, {"referenceID": 28, "context": "CP decomposition models also tend to overfit when Q is large (Zhao et al., 2015).", "startOffset": 61, "endOffset": 80}, {"referenceID": 19, "context": "By clamping the country\u2013community factors, the action\u2013topic factors, and the core tensor after training, our experimental setup is analogous to that used to assess collaborative filtering models\u2019 strong generalization ability (Marlin, 2004).", "startOffset": 226, "endOffset": 240}, {"referenceID": 8, "context": "1, as recommended by Gelman (2006), and we set \u03b30 so that (\u03b30 /C) 2 (\u03b30 /K) (\u03b30 /R) = 0.", "startOffset": 21, "endOffset": 35}, {"referenceID": 12, "context": "(2015) used fifty latent classes to model the same data, while Hoff (2015) used C = 4, K=4, and R=4 to model a similar tensor from GDELT.", "startOffset": 63, "endOffset": 75}], "year": 2016, "abstractText": "We introduce Bayesian Poisson Tucker decomposition (BPTD) for modeling country\u2013 country interaction event data. These data consist of interaction events of the form \u201ccountry i took action a toward country j at time t.\u201d BPTD discovers overlapping country\u2013 community memberships, including the number of latent communities. In addition, it discovers directed community\u2013community interaction networks that are specific to \u201ctopics\u201d of action types and temporal \u201cregimes.\u201d We show that BPTD yields an efficient MCMC inference algorithm and achieves better predictive performance than related models. We also demonstrate that it discovers interpretable latent structure that agrees with our knowledge of international relations.", "creator": "LaTeX with hyperref package"}}}