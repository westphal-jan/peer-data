{"id": "1606.02077", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2016", "title": "Regret Bounds for Non-decomposable Metrics with Missing Labels", "abstract": "We orby consider the j.p problem bobak of recommending 50-2 relevant worrywarts labels (kuty items) leps for a defreitas given infastructure data cisg point (157.6 user ). In 2011-2012 particular, debacle we are rinta interested catron in the grown-up practically 20-screen important setting nwong@globe.com where the evaluation is adam-ondi-ahman with aham respect tongass to non - decomposable (over regenerates labels) fadyl performance agreed metrics springett like cfto the $ patchett F_1 $ libitum measure, and macedonians the training cholily data has missing b\u00fcrgerschaft labels. talleyrand-p\u00e9rigord To percidae this umbellata end, nonkosher we propose dosari a generic dostoevsky framework that seventy-eight given a performance metric $ \\ diplomacy Psi $, can lincoln-way devise a regularized shorties objective function and s-shape a cayos threshold such garc\u00eda that gedevanishvili all the zhordania values impasses in khadziyeva the predicted score triplets vector above hartford and only above well.com the threshold are dabagh selected to be positive. wickets We 2,168 show rumphius that coagulation the entrenching regret smitrovich or fulmer generalization error in gavit the dublin/pleasanton given metric $ \\ Psi $ is 3.240 bounded loomis ultimately by estimation suburbicarian error of certain insider underlying departure parameters. stemcell In luminol particular, beukeboom we norgren derive regret bounds jsaltzman@globe.com under chandris three popular settings: suren a) raniero collaborative filtering, diomedes b) r/c multilabel ssis classification, 120.71 and illarion c) soy PU (conndot positive - pegasys unlabeled) learning. For biocontrol each of applauded the above problems, excursionists we jagla can bace obtain vadu precise non - asymptotic early-twentieth regret .455 bound tschetter which meydavud is rohinton small even dakshin when a chionodes large nerdrum fraction unifies of labels geekiness is missing. Our 210-page empirical cesarani results swithland on daicon synthetic wilford and vainshtok benchmark hlb datasets stirrers demonstrate that 16.23 by 17.29 explicitly commensurable modeling for diterpene missing powerlifting labels montmorency and agrarianism optimizing the desired performance toshizo metric, our nords algorithm colle indeed robinsonville achieves geisst significantly better performance (like $ F_1 $ hargan score) when compared stuarts to methods remittance that do not egelko model csms missing voix label information schramm carefully.", "histories": [["v1", "Tue, 7 Jun 2016 10:00:30 GMT  (124kb)", "http://arxiv.org/abs/1606.02077v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["nagarajan natarajan", "prateek jain 0002"], "accepted": true, "id": "1606.02077"}, "pdf": {"name": "1606.02077.pdf", "metadata": {"source": "CRF", "title": "Regret Bounds for Non-decomposable Metrics with Missing Labels", "authors": ["Prateek Jain", "Nagarajan Natarajan"], "emails": ["prajain@microsoft.com", "t-nanata@microsoft.com", "precision@k;"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n02 07\n7v 1\n[ cs\n.L G\n] 7\nJ un\nKeywords: Non-decomposable losses, Regret bounds, Multi-label Learning"}, {"heading": "1. Introduction", "text": "Predicting relevant labels/items for a given data point is by now a standard task with applications in several domains like recommendation systems (Koren et al., 2009), document tagging, image tagging (Prabhu and Varma, 2014), etc. Many times, like say in collaborative filtering, features for the data points might not be available and one needs to predict labels only on the basis of past labels (e.g., existing likes/dislikes for various labels/items). In presence of features, the problem is the standard multi-label classification problem.\nDesign and analysis of algorithms for such tasks should counter two fundamental challenges: a) in practical scenarios, desired performance metric for our predictions are typically complex non-decomposable functions such as F1 score or precision@k; standard metrics like Hamming loss or RMSE over the labels may not be useful, and b) any realistic system in this domain should be able to handle missing labels. Furthermore, often the location of missing labels may not be available like in the positive-unlabeled learning setting (Hsieh et al., 2015). Dealing with missing labels may necessitate imposition of certain regularization on the parameters like, say, low-rank regularization so as to exploit the correlations between labels.\nMost of the existing solutions only address one of the two aspects. For example, Koyejo et al. (2015) establish that for a large class of performance metrics, the optimal solution is to compute a score vector over all the labels and selecting all the labels whose score is greater than a constant. Their algorithm treats each label as independent to estimate class-conditional probability separately for each label. Clearly, such methods ignore available information about other labels, and hence cannot handle missing information effectively. Also, such methods do not even apply for the collaborative filtering setting. On the other hand, most of the existing collaborative filtering/matrix completion methods only focus on decomposable losses like RMSE, sum of logistic loss (Lafond, 2015; Yu et al., 2014), which are not effective in real-world systems with large number of labels (Prabhu and Varma, 2014).\nIn this work, we devise a simple and generic framework that addresses both the aforementioned issues; the framework leads to simple and efficient algorithms in several different settings and for a wide variety of performance metrics used in practice including the multilabel F -measure. Our framework is motivated by a simple observation that has been used in other contexts as well (Kot\u0142owski and Dembczy\u0144ski, 2015; Koyejo et al., 2015): for a large class of metrics \u03a8, simply thresholding the class probability vector leads to bayes-optimal estimators. Hence, the goal would be to estimate per-label class probabilities accurately. To this end, we show that by using a \u03bb-strongly proper loss along with appropriate thresholding leads to bounded regret wrt. \u03a8 (Theorem 1). Note that the threshold can be learned using cross-validation over a small fraction of the training data.\nMoreover, \u03bb-strong convexity of the loss function ensures that by minimizing a nuclearnorm regularized ERM (with risk measured by the selected loss function) wrt. a parameter matrix W \u2208 Rd\u00d7L, we can bound the regret in \u03a8 by regret in estimation of the optimal W (Theorem 1); here, d is the dimensionality of the data and is equal to number of users in case of recommender system. Hence, this result allows us to focus on estimation of W\u2217 in various different settings such as: a) one-bit matrix completion (Theorem 2), popularly used in recommender systems with only like/dislike information, b) one-bit matrix completion with PU learning (Theorem 4) applicable to recommender systems where only \u201clikes\" or positive feedback is observed, and c) general multi-label learning with missing labels (Theorem 3).\nFor one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al. (2015), respectively. For general multilabel setting, a direct application of existing results, such as (Lafond, 2015) leads to weak bounds. A main technical contribution of our work is to analyze the parameter estimation problem in this setting and provide tight regret bounds. In fact, our result strictly generalizes the result by Lafond (2015), which is for general matrix completion with exponential family noise, to the general inductive matrix completion setting (Jain and Dhillon, 2013) with exponential family noise. Hence, it should have applications beyond our framework as well. Finally, we illustrate our framework and algorithms on synthetic as well as real-world datasets. Our method exhibits significant improvement over a natural extension of the method by Koyejo et al. (2015) that optimizes \u03a8 directly but ignores label correlations, hence does not handle missing labels in a principled manner. For example, our method achieves 12% higher F1-measure on a benchmark dataset than that by Koyejo et al. (2015).\nRelated Work. We now highlight some related theoretical work in recommender systems and multi-label learning. Gao and Zhou (2013) study consistency and surrogate losses for\ntwo specific losses namely Hamming and expected (partial) ranking losses, and leave the other losses to future work. Dembczynski et al. (2012) consider expected pairwise ranking loss in multilabel learning, show that the problem decomposes into independent binary problems, and provide regret bound for the same. Yun et al. (2014) consider the learning to rank problem, where the goal is to rank the relevant labels for a given instance. They show that popular ranking losses like NDCG can be written as a generalization of certain robust binary loss functions, although they do not provide any explicit regret bounds. Existing theoretical guarantees for 1-bit matrix completion methods used in recommender systems focus solely on RMSE or 0-1 loss (Lafond, 2015; Hsieh et al., 2015)."}, {"heading": "2. Problem Setup and Background", "text": "Let xi \u2208 X \u2286 Rd denote instances and yi \u2208 {0, 1}L denote label vectors. Let Y \u2208 {0, 1}n\u00d7L denote the label matrix, with yi\u2019s as rows. In typical multi-label learning and recommender system settings a) the labeling process has some inherent uncertainty, which is usually captured by assuming a conditional distribution P(yi|xi), b) furthermore, we do not get to observe all the entries of yi, but only a small subset, say \u2126i. Formally, let \u2126 \u2282 [n] \u00d7 [L] denote a subset of indices sampled i.i.d. from a fixed distribution \u03c0 over [n] \u00d7 [L]. We consider the following sampling model for observing label matrix Y:\nYij =\n{ 1 with probability gj(xi;W \u2217)\n0 with probability 1\u2212 gj(xi;W\u2217) for (i, j) \u2208 \u2126. (1)\nwhere W\u2217 parameterizes the underlying conditional distribution P(yi|xi). Following the low-rank inductive matrix completion model (Yu et al., 2014; Zhong et al., 2015), we let W\n\u2217 \u2208 Rd\u00d7L be the parameter matrix and gj(xi;W\u2217) = g(\u3008xi,w\u2217j \u3009) where w\u2217j is the jth column of W\u2217 corresponding to the jth label, for some differentiable function g : R \u2192 [0, 1]. A popular choice of g is given by g(\u3008xi,wj\u3009) = exp(\u3008xi,wj\u3009)1+exp(\u3008xi,wj\u3009) , which corresponds to the logistic regression model. When we do not observe feature vectors x, as in the classical recommender system or matrix completion setting, the above model (1) reduces to the widely studied 1-bit matrix completion model (Cai and Zhou, 2013; Davenport et al., 2014):\nYij =\n{ 1 with probability g(W\u2217ij)\n0 with probability 1\u2212 g(W\u2217ij) for (i, j) \u2208 \u2126, (2)\nwhere W\u2217 \u2208 Rn\u00d7L is the parameter matrix that captures user-item preferences. The goal is to learn a multi-label classifier f : X n \u2192 {0, 1}n\u00d7L jointly over n instances. The training data consists of input features X \u2208 Rn\u00d7d where each row corresponds to an instance, drawn iid from some distribution PX over X , and partially observed label matrix Y using the sampling model (1) or (2), such that a performance metric of interest \u03a8 is maximized. In this work, we consider a large family of non-decomposable metrics (Koyejo et al., 2015) that constitutes linear-fractional functions of (multi-label analogues of) true positives, false positives, false negatives and true negatives defined below. Let Y\u0302 \u2208 {0, 1}n\u00d7L denote\nthe predicted labels, i.e. Y\u0302 = f(X) for some f . Define the primitives:\nT\u0302Pij(Y\u0302,Y) = [[Y\u0302ij = 1,Yij = 1]], F\u0302Pij(Y\u0302,Y) = [[Y\u0302ij = 1,Yij = 0]],\nT\u0302Nij(Y\u0302,Y) = [[Y\u0302ij = 0,Yij = 0]], F\u0302Nij(Y\u0302,Y) = [[Y\u0302ij = 0,Yij = 1]].\nFor convenience, we drop the arguments and just write T\u0302Pij to denote T\u0302Pij(Y\u0302,Y) and so on.\n1. Micro-averaged metrics. Define:\nT\u0302P(Y\u0302,Y) = 1 |\u2126| \u2211\n(i,j)\u2208\u2126\nT\u0302Pij,\nand F\u0302P(Y\u0302,Y), T\u0302N(Y\u0302,Y), F\u0302N(Y\u0302,Y) similarly. Let TP = E[T\u0302P],FP = E[F\u0302P] (and so on), where the expectation is defined wrt to the sampling distribution \u03c0 over indices [n]\u00d7 [L] as well as the joint distribution over instances and labels. Micro-averaged performance metric \u03a8 : {0, 1}n,L \u00d7 {0, 1}n,L \u2192 R+ is given by:\n\u03a8(Y\u0302,Y) = a0 + a11TP+ a01FP+ a10FN+ a00TN\nb0 + b11TP+ b01FP+ b10FN+ b00TN . (3)\nfor bounded constants a\u2019s and b\u2019s. Assume that \u03a8 is bounded, i.e. \u2203\u03b3 > 0 such that b0 + b11TP+ b01FP+ b10FN+ b00TN > \u03b3 for all Y\u0302,Y. 2. Instance-averaged metrics. Define\nT\u0302Pi(Y\u0302,Y) = 1 |\u2126i| \u2211\nj\u2208\u2126i\nT\u0302Pij.\nLet TPi = E[T\u0302Pi]. Instance-averaged performance metric \u03a8 is given by:\n\u03a8(Y\u0302,Y) = 1\nn\nn\u2211\ni=1\na0 + a11TPi + a01FPi + a10FNi + a00TNi b0 + b11TPi + b01FPi + b10FNi + b00TNi . (4)\nfor bounded constants a\u2019s and b\u2019s. Assume that \u03a8 is bounded, i.e. \u2203\u03b3 > 0 such that b0 + b11TPi + b01FPi + b10FNi + b00TNi > \u03b3 for all Y\u0302,Y, i. 3. Macro-averaged metrics. Let \u2126(j) = {i : (i, j) \u2208 \u2126}. Define:\nT\u0302Pj(Y\u0302,Y) = 1 |\u2126(j)| \u2211\ni\u2208\u2126(j)\nT\u0302Pij .\nLet TPj = E[T\u0302Pj ]. Macro-averaged performance metric \u03a8 is given by:\n\u03a8(Y\u0302,Y) = 1\nL\nL\u2211\nj=1\na0 + a11TPj + a01FPj + a10FNj + a00TNj b0 + b11TPj + b01FPj + b10FNj + b00TNj . (5)\nfor bounded constants a\u2019s and b\u2019s. Assume that \u03a8 is bounded, i.e. \u2203\u03b3 > 0 such that b0 + b11TPj + b01FPj + b10FNj + b00TNj > \u03b3 for all Y\u0302,Y, j.\nExample metrics:\n1. Instance-averaged F1 metric defined as: \u03a8F1(Y\u0302,Y) = 1 n \u2211n i=1 2TPi 2TPi+FPI+FNi . 2. Accuracy (equivalent to the Hamming loss): \u03a8Ham(Y\u0302,Y) = 1\u2212 1n \u2211n i=1 FPi + FNi.\nRemark 1. The aforementioned definitions of performance metrics naturally apply to the recommender system setting, where data is observed via the 1-bit matrix completion sampling model (2). Here, the recovery error is ultimately measured wrt to an estimated binary-valued matrix. Note that in this case, the expectations are defined wrt the sampling distribution \u03c0 and the inherent noise in 1-bit sampling P(Yij |Wij).\nLet \u03a8\u2217 denote the Bayes optimal performance, i.e. \u03a8\u2217 = maxf \u03a8(f(X),Y) (Note that \u03a8 is defined in terms of expectation with respect to the underlying distribution). Our objective can be now stated learning f\u0302 such that the \u03a8-regret, i.e. \u03a8\u2217 \u2212 \u03a8(f\u0302(X),Y), is provably bounded. Koyejo et al. (2015) showed that the Bayes optimal \u03a8\u2217 thresholds the conditional probability of each label j, i.e. P(yj|x) at a certain value \u03b4\u2217 \u2208 (0, 1), and that the value \u03b4\u2217 is shared across all the labels.1:"}, {"heading": "3. Algorithm", "text": "Our approach is based on estimating real-valued predictions and then thresholding the predictions optimally in order to maximize a given metric \u03a8. Koyejo et al. (2015) proposed a simple consistent plug-in estimator algorithm, which first computes conditional marginals P(yj|x) independently for each label j, and then estimates a threshold jointly to optimize \u03a8. While the approach is provably consistent asymptotically, it is not clear if it admits a useful regret bound; in particular, we would like to characterize the behavior in the finite samples regime. In case of the sampling model (1), the approach translates to learning columns of the parameter matrix W independently. In many cases, W exhibits some structure, such as low-rankness, reflecting correlation between labels (Yu et al., 2014; Zhong et al., 2015; Davenport et al., 2014). Statistically, capturing correlations via a low-rank structure could help improve the sample complexity for recovery, and computationally, it would help reduce space and time complexity of the learning procedure.\nOur proposed algorithm is presented in Algorithm 1. In Step 1, we solve a traceregularized minimization problem to estimate the parameter matrix W, where the function \u2113 can be any bounded loss such as the squared, the logistic or the squared Hinge loss. In particular, using the logistic loss corresponds to the maximum likelihood estimation of the sampling model (1). Yu et al. (2014) also solve essentially the same objective as (6), except for the additional bound constraint on entries of XW. The optimization problem (6) can be solved using a proximal gradient descent algorithm, with a fast proximal operator computation by storing the current solution in a low-rank form. We could also use fast non-convex procedure, by writing W = W1W T 2 , where W1 and W2 are low-rank matrices with k \u226a min(d, L) columns each, and applying alternating minimization. The real-valued estimator is given by Z = XW\u0302 in Step 2. To obtain binary-valued predictions, we solve a 1-dimensional optimization problem to compute the optimal threshold, on the training data. Note that this step can be done in |\u2126| time. 1. The definitions in (Koyejo et al., 2015) do not include general sampling distribution \u03c0, but the results\ncan be generalized in a straight-forward manner.\nRemark 2. In the 1-bit matrix completion setting, we obtain a thresholded max-likelihood estimator of W\u2217 \u2208 Rn\u00d7L using identical procedure; where we interpret X in Algorithm 1 as the identity matrix of size n.\nAlgorithm 1 Thresholded Max-Likelihood Estimator\nInput: Training data X \u2208 Rn\u00d7d, labels Y\u2126 \u2208 {0, 1}n\u00d7L observed on indices \u2126 and metric \u03a8. 1. Obtain W\u0302 by solving the trace-constrained matrix completion:\nW\u0302 = arg min W:\u2016XW\u2016\u221e\u2264\u03b3\n1 |\u2126| \u2211\n(i,j)\u2208\u2126\n\u2113(\u3008xi,wj\u3009,Yij) + \u03bb\u2016W\u2016\u2217, (6)\n2. Let Z = XW\u0302. Define the thresholding operator Y\u0302 = Thr\u03b8(Z), such that Y\u0302ij = [[Zij \u2265 \u03b8]].\n3. Return Y\u0302 = Thr \u03b8\u0302 (Z), where\n\u03b8\u0302 = argmax \u03b8 \u03a8(Thr\u03b8(Z\u2126),Y\u2126)."}, {"heading": "4. Analysis: Regret Bounds", "text": "In this Section, we first show that \u03a8-regret can be bounded with the regret of a certain loss \u2113. Then, under various sampling models pertaining to different settings such as 1-bit matrix completion, multi-label learning, and PU (positive-unlabeled) learning, we show that the \u2113regret can be bounded, via recovering the underlying parameter matrix governing P(yij|xi)."}, {"heading": "4.1 Low \u2113-regret implies low \u03a8-regret", "text": "Our first main result connects \u03a8-regret to regret with respect to a strongly proper loss function \u2113 (Agarwal, 2014). Canonical examples of strongly proper losses include the logistic loss \u2113(t, y) = log(1+exp(\u2212yt)), the exponential loss \u2113(t, y) = exp(\u2212yt) and the squared loss \u2113(t, y) = (1\u2212 yt)2. Define the \u2113-regret of Z \u2208 Rn\u00d7L as:\nReg\u2113(Z) = E[\u2113(Zij,Yij)]\u2212 min Z \u2032\u2208Rn\u00d7L E[\u2113(Z\u2032ij ,Yij)],\nwhere the expectation is wrt. draws from \u03c0 and the joint distribution over instances and labels.\nTheorem 1 (Main Result 1). Let \u03a8 be a performance metric as defined in (3) , (4) or (5). Let \u2113 be a \u03bb-strongly proper loss function. Assume the input X \u2208 Rn\u00d7L consists of iid instances sampled from marginal PX, label matrix Y \u2208 {0, 1}n\u00d7L, where yij is sampled iid from P(yij|xi), which is observed only on a subset of indices \u2126 sampled iid from a fixed distribution \u03c0. Then, the output Y\u0302 obtained by thresholding the estimate Z in Step 3 of\nAlgorithm 1 satisfies the regret bound:\n\u03a8\u2217 \u2212\u03a8(Y\u0302,Y) \u2264 C \u221a 2\n\u03bb\n\u221a Reg\u2113(Z) +O ( 1\u221a |\u2126| ) , (7)\nfor some absolute constants C and \u03bb.\nWe emphasize that the above result holds for arbitrary metric \u03a8 from the family (3), (4) or (5). Consider the RHS of (7): 1/ \u221a |\u2126| is the lower-order term, and independent of dimensionality; the first term makes the framework fairly powerful, as it can use any strongly proper loss. In the next subsection, we will provide precise instantiations of this term under various learning settings.\nProof Outline for Theorem 1. Proof technique is based on (Kot\u0142owski and Dembczy\u0144ski, 2015), where they derive similar bound in the binary classification setting. We first relate the \u03a8-regret to weighted 0-1 loss regret (Lemma 2). Then, we show there exists a thresholding Thr\u03b8\u2217(Z) \u2208 {0, 1}n\u00d7L such that its weighted loss regret is bounded by the \u2113-regret of a strongly proper loss \u2113 (Lemma 3). Finally, we argue that it suffices to estimate \u03b8\u0302 from the training data (Lemma 4). Detailed proof and associated Lemmas are available in Appendix A.1."}, {"heading": "4.2 Bounding \u2113-regret", "text": "Below, we provide the desired \u2113-regret bound under three different settings."}, {"heading": "4.2.1 Collaborative Filtering", "text": "Consider the 1-bit matrix completion sampling model in (2). Then (6) reduces to the optimization problem considered by Lafond (2015). We have the following regret bound for the estimator Z = W\u0302 obtained in Step 2 of Algorithm 1 (Note that X is just treated as identity in this setting).\nTheorem 2. Assume \u03c0 is uniform, and consider the 1-bit matrix completion sampling model (2). Let \u2113 denote a 1-Lipschitz, strongly proper loss (appearing in (7)), and Z denote the output of Step 2 of Algorithm 1. With probability at least 1\u2212 \u03b4, the following holds:\nReg\u2113(Z) \u2264\n\u221a\u221a\u221a\u221aC\u0303max ( max(n,L) rank(W\u2217) log(3/\u03b4)\n|\u2126|\n( \u03c32\u03b3 + 1 ) , \u03b32\n\u221a log(3/\u03b4)\n|\u2126|\n) ,\nwhere C\u0303, c\u03b3 , c \u2032 \u03b3 , c \u2032\u2032 \u03b3 , \u03c3\u03b3 are numerical constants, and \u03b3 = maxij |W\u2217ij |.\nNote that when |\u2126| > max(n,L), the RHS of the above bound starts converging; in particular, the second term within max is the lower-order term: \u03b3 \u2248 O (\u221a 1/nL ) . Theorem 2 can be extended to general distributions \u03c0 beyond uniform, satisfying mild assumptions. See Appendix A.2."}, {"heading": "4.2.2 Multi-label Learning", "text": "Consider the sampling model (1) with features. We have the following regret bound for the estimator Z = XW\u0302 obtained in Step 2 of Algorithm 1, under the following assumptions.\nAssumption 1. The marginal distribution over the features PX is sub-Gaussian with subGaussian norm K and covariance \u03a3 \u2208 Rd\u00d7d.\nAssumption 2. Let \u03c0k,l denote the probability of sampling the entry (k, l) \u2208 [n]\u00d7 [L];\n1. \u2203 \u00b5 \u2265 1 s.t. mink\u2208[n],l\u2208[L] \u03c0k,l \u2265 1\u00b5nL , and 2. \u2203 \u03bd \u2265 1 s.t. maxi\u2032,j\u2032 (\u2211 j \u03c0i\u2032j , \u2211 i \u03c0ij\u2032 ) \u2264 \u03bdmin(n,L) .\nTheorem 3 (Main Result 2). Assume 1, 2 and consider the sampling model (1). Also assume L \u2265 d. Let W\u0302 be the solution to the trace-norm regularized optimization problem (6) using logistic loss for \u2113, number of training data points n \u2265 C \u2032 . d, number of observations |\u2126| \u2265 L + d, and setting the regularization parameter \u03bb = 2c\u221a\n|\u2126| . Then, with probability at\nleast 1\u2212 3(n+ L)\u22121 \u2212 2(d+ L)\u22121, the following holds:\n\u2016W\u0302 \u2212 W\u2217\u20162F dL \u2264 C2\u00b5 2 d max\n( L rank(W\u2217) log(n+ L)\n|\u2126|\n( \u03c32\u03b3 + 1 ) , \u03b32\n\u00b5\n\u221a log(n + L)\n|\u2126|\n) ,\nwhere c, C \u2032, C2 are numerical constants and \u03c3\u03b3 \u2264 (1 + e\u03b3)2e\u03b3.\nA few remarks of our result in the multi-label setting are in order:\nRemark 3 (Generalization). The result in Theorem 3, and Theorem 8 in Appendix B for general exponential distributions, is a key technical contribution of this work. In particular, our analysis applies to Y arising from general exponential distributions, including Gaussian when Y is real-valued and Poisson when Y models counts. See Appendix B for more details.\nRemark 4 (Comparing (Lafond, 2015)). If we directly apply the method and the analysis of (Lafond, 2015), the resulting bounds are very weak; in fact, when n \u2265 L and |\u2126| = O(n), which is quite common in the multi-label scenario, the ensuing bound suggests that the estimator is not even consistent, even when \u03c0 is uniform. See Appendix A.3 for details.\nRemark 5 (Comparing (Koyejo et al., 2015)). The plugin-in estimator algorithm of (Koyejo et al., 2015) estimates w\u2217j for each label j independently, and learns a common threshold as in Algorithm 1. Let w\u0302j denote the estimator for label j. Then, using standard analysis we have,\n\u2016w\u0302j \u2212w\u2217j\u20162 \u2264 \u03c3 \u221a d |\u2126j | , where |\u2126j | is the number of observations per label which is O( |\u2126| L ). Thus we have the bound: \u2016W\u2217\u2212W\u0302\u20162 F\nL \u2264 \u03c3O(Ld|\u2126|). This is how our bounds behave, when W\u2217\nis indeed full rank, up to constants. When rank(W\u2217) \u226a min(d, L), we achieve much faster convergence.\nWe now give the desired \u2113-regret bound as a corollary.\nCorollary 1. Assume the conditions of Theorem 3 hold. Let \u2113 denote a 1-Lipschitz, strongly proper loss (appearing in (7)), and Z = XW\u0302 denote the output of Step 2 of Algorithm 1. With probability at least 1\u2212 \u03b4 \u2212 (d+ L)\u22121, the following holds:\nReg\u2113(Z) \u2264 \u221a\u221a\u221a\u221aC2\u00b52max ( L rank(W\u2217) log(3/\u03b4)\n|\u2126|\n( \u03c32\u03b3 + 1 ) , \u03b32\n\u00b5\n\u221a log(3/\u03b4)\n|\u2126|\n) ,\nwhere c, C \u2032, C2, \u03c3\u03b3 are defined as in Theorem 3.\nProof Outline for Theorem 3. We analyze the following general exponential noise model for Y:\nyij|xi,wj \u223c exph,G(xi,wj) := h(yij) exp ( \u3008xi,wj\u3009yij \u2212G(\u3008xi,wj\u3009) ) , (8)\nwhere h and G are the base measure and log-partition functions associated with this canonical representation. Our proof sketch is based on Lafond (2015), but requires bounding certain quantities carefully. In particular, we prove a tight bound for \u2016XT\u2207\u03a6Y(X,W\u2217)\u20162 in terms of the regularization parameter \u03bb, where \u03a6Y(X,W\n\u2217) is the MLE wrt. general exponential distribution (reduces to (6), without regularization, when yij\u2019s are from (1)), as stated below.\nLemma 1. Consider the sampling model (8). Assume (i) d \u2264 L, (ii) |\u2126| \u2265 (L+d), (iii) yij\u2019s are sampled independently given xi, and (iv) |yij \u2212G\u2032(\u3008xi,w\u2217j \u3009)| \u2264 \u03b1, for all i, j \u2208 [n]\u00d7 [L], for any n,L. Let X \u2208 Rn\u00d7d whose rows (xi\u2019s) are iid samples from PX satisfying Assumption 1. Then, with probability at least 1\u2212 (d+ L)\u22121, there exists numerical constant c such that,\n\u2225\u2225XT\u2207\u03a6Y (X,W\u2217) \u2225\u2225 2 \u2264 c . \u03b1\u221a\n|\u2126| ."}, {"heading": "4.2.3 PU Learning", "text": "In many collaborative filtering and multi-label learning tasks, only the positive entries (yij = 1) are observed. In this setting, we can use the approach of (Hsieh et al., 2015), where they consider a two-stage sampling model: sample yij using (2) for all i, j \u2208 [n] \u00d7 [L] (or using (1) when features are available), and then flip a fraction \u03c1 of the sampled 1\u2019s to 0\u2019s, resulting in Y\u0303. We would then use the unbiased estimator \u2113\u0303 of loss \u2113 in (6); \u2113\u0303 satisfies E[\u2113\u0303(Zij , Y\u0303ij)] = \u2113(Zij ,Yij), where the expectation is wrt the flipping process, parameterized by \u03c1. For the estimator Z = W\u0302 obtained thus, we have the following regret bound.\nTheorem 4. Let \u2113 denote a 1-Lipschitz, strongly proper loss (appearing in (7)). Assume \u2016W\u2217\u2016\u2217 \u2264 t. Let Z = XW\u0302, where W\u0302 is obtained by solving the unbiased estimator objective of Hsieh et al. (2015). With probability at least 1\u2212 \u03b4, there exists absolute constant C such that:\nReg\u2113(Z) \u2264 \u221a 6 \u221a log(2/\u03b4)\u221a nL(1\u2212 \u03c1) + 2C . t \u221a n+ \u221a L (1\u2212 \u03c1)nL.\nThe RHS of the bound above, when n = L, is of O( \u221a\n1 n(1\u2212\u03c1)), where (1\u2212\u03c1) is the fraction\nof observed 1\u2019s in Y\u0303 . Naturally, as \u03c1 is large, we need more samples to achieve similar rates as in the other settings.\nRemark 6. This PU learning result is particularly very useful in extreme classification setting (Bhatia et al., 2015a; Prabhu and Varma, 2014); where there are too many labels and is unrealistic to get feedback on every label, but possible to obtain a small subset of relevant labels for instances. Furthermore, the above result serves to attest to the utility of our framework."}, {"heading": "5. Experiments", "text": "We focus on multi-label datasets for experimental study. The goal is to show that the convergence happens as suggested by the theory, and that the proposed algorithm performs well on real-world datasets. To solve (6), we use an alternating minimization procedure by forming W = W1W T 2 , such that W1 \u2208 Rd\u00d7k and W2 \u2208 RL\u00d7k, where k, the rank of W, is an input parameter."}, {"heading": "5.1 Synthetic data", "text": "We generate multi-label data as follows. We fix n = 1000, L = 100 and d = 10. First, we generate X \u2208 Rn\u00d7d using samples from multi-variate Gaussian N (0, I). Then, we generate W\n\u2217 of rank 5. The label matrix Y is obtained by thresholding XW\u2217 at \u03b8\u2217 = 0, i.e. yij = sign(\u3008xi,w\u2217j \u3009). In this noise-free setting, we expect that our algorithm would recover both W\u2217 and \u03b8\u2217 accurately as it sees more and more observations. The results for maximizing micro F1 and accuracy metrics are presented in Figure 1. As the sampling ratio |\u2126| nL\nincreases, we observe that the proposed estimator achieves optimal performance in both the cases. Furthermore, even when only 10% of the observations are revealed, we observe that the proposed method achieves very high F1 as well as accuracy values, compared to learning the columns of W\u2217 independently via the plugin estimator method proposed by (Koyejo et al., 2015) (followed by learning a threshold)."}, {"heading": "5.2 Real-world data", "text": "We consider five real-world multi-label datasets widely used as benchmarks (Bhatia et al., 2015a; Yu et al., 2014).\n1. CAL500: a music dataset with 400 training and 100 test instances, L = 174, d = 68,\n2. Corel5k: an image dataset with 4500 training and 500 test instances, L = 374, d = 499,\n3. Bibtex: a text dataset with 4,880 training and 2,515 test instances, L = 159, d = 1, 836,\n4. Compphys dataset with 161 training and 40 test instances, L = 208, d = 33, 284, and\n5. Autofood dataset with 4,880 training and 2,515 test instances, L = 162, d = 1, 836.\nnL\nwas fixed to 20% for training. The rank of W was set to 0.4L for Algorithm 1. We observe that the proposed algorithm which captures label correlations performs better consistently across datasets.\nWe set the rank k of W to 0.4L for all the datasets in our method, and set |\u2126| nL\n= 20% to train the models in each method. The results are presented in Table 1. We observe that the proposed method is competitive in all the datasets, and achieves better micro-F1 and accuracy values, with a small value of rank 0.4L. We note that the label matrices of most of the datasets are very sparse (for instance, less than 8.5% of the test data are positive labels in Autofood), which explains high accuracy and low F1 values. The learned model is much more compact than that of (Koyejo et al., 2015) (k(d+L) vs dL parameters). While our bounds in theory hold for the case L \u2265 d (Theorem 3), many of the datasets considered here have d \u2265 L and yet the performance is competitive."}, {"heading": "6. Conclusions", "text": "We presented a framework for optimizing general performance metrics applicable to multilabel as well as collaborative filtering settings. Our work complements recent results in this direction: on the theoretical front, we derive strong regret bounds for practically used metrics like F -measure, and on the algorithmic front, we provide simple and efficient procedure that works well in practice."}, {"heading": "Appendix A. Proofs", "text": ""}, {"heading": "A.1 Proof of Theorem 1", "text": "Proof technique is based on (Kot\u0142owski and Dembczy\u0144ski, 2015), where they derive similar bound in the binary classification setting. We first relate the \u03a8-regret to weighted 0-1 loss regret. Define the \u03b1-weighted 0-1 loss \u2113\u03b1 : R\u00d7 R \u2192 [0, 1] as:\n\u2113\u03b1(y\u0302, y) = \u03b1[[y = 0]][[y\u0302 = 1]] + (1\u2212 \u03b1)[[y = 1]][[y\u0302 = 0]],\nLet Y\u0302 = f(X) for some function f . The \u2113\u03b1-risk of f with respect to the underlying distribution over X,Y and \u2126 is defined as:\nRisk\u03b1(Y\u0302) = E[\u2113\u03b1(Y\u0302ij ,Yij)] = \u03b1FP(Y\u0302,Y) + (1\u2212 \u03b1)FN(Y\u0302,Y).\nDefine the Bayes optimal corresponding to the above risk: f\u2217\u03b1 = argminf Risk\u03b1(f(X),Y). Let Risk\u2217\u03b1 := f \u2217 \u03b1(X). The \u2113\u03b1-regret of f is defined as:\nReg\u03b1(f(X)) := Risk\u03b1(f(X))\u2212Risk\u2217\u03b1.\nLemma 2. Let \u03a8 be a linear-fractional performance metric as defined in (3), (4) or (5). Then for \u03b1 \u2208 (0, 1) defined as:\n\u03b1 = \u03a8\u2217c2 \u2212 c1\n\u03a8\u2217c2 \u2212 c1 +\u03a8\u2217d2 \u2212 d1 , (9)\nwhere c1, d1, c2, d2 are constants that depend on \u03a8, there exists some constant C > 0 such that, for any f :\n\u03a8\u2217 \u2212\u03a8(f(X),Y) \u2264 C(Risk\u03b1(f(X))\u2212 Risk\u2217\u03b1). (10)\nLet \u2113 : {0, 1} \u00d7 R \u2192 R+ be a \u03bb-strongly proper composite loss (Reid and Williamson, 2010), such as the squared loss or the logistic. Given real-valued predictions Z \u2208 Rn\u00d7L, we now argue that there exists a thresholding Thr\u03b8\u2217(Z) \u2208 {0, 1}n\u00d7L such that Risk\u03b1(Thr\u03b8\u2217(Z),Y) is bounded by the \u2113-regret of a strongly proper loss \u2113 (where Thr operator is defined as in Step 2 of Algorithm 1).\nLemma 3. Let \u2113 be a \u03bb-strongly proper loss function, and \u03b1 be defined as in (9). Then, there exists \u03b8\u2217 s.t.\nReg\u03b1(Thr\u03b8\u2217(Z)) \u2264 \u221a 2\n\u03bb\n\u221a Reg\u2113(Z) .\nFinally, we show that estimating \u03b8\u0302 from training samples (Step 3 of Algorithm 1) is sufficient for bounding the \u03a8-regret.\nLemma 4. We have: max\n\u03b8 \u03a8(Thr\u03b8(Z),Y) \u2265 \u03a8(Thr\u03b8\u2217(Z),Y),\nand\nmax \u03b8 \u03a8(Thr\u03b8(Z\u2126),Y\u2126) \u2265 max \u03b8\n\u03a8(Thr\u03b8(Z),Y)\u2212O (\n1\u221a |\u2126|\n) .\nThe proof of the Theorem is complete by chaining the above three Lemmas.\nRemark 7. When \u03a8\u2217 is known (in the noise-free or realizable setting, \u03a8\u2217 is the maximum possible value of \u03a8), we can get a closed form for \u03b8\u2217, which is \u03b8\u2217 = \u03be(\u03b1) where \u03be is the link function corresponding to the proper loss \u2113."}, {"heading": "A.1.1 Proof of Lemma 2", "text": "Let Y\u0302 = f(X). Consider the metric \u03a8 from family (3) for the moment. Define A(Y\u0302) = a0+a11TP+a01FP+a10FN+a00TN := c1FP+d1FN+e1 and B(Y\u0302) = b0+b11TP+b01FP+ b10FN+ b00TN := c2FP + d2FN+ e2 (for constants c1, c2, d1, d2, e1, e2 suitably defined), so that \u03a8(Y\u0302,Y) = A(Y\u0302)/B(Y\u0302). Let f\u2217 denote the Bayes optimal attaining \u03a8\u2217 = A\u2217/B\u2217. We have:\n\u03a8\u2217 \u2212\u03a8(Y\u0302,Y) = \u03a8 \u2217B(Y\u0302)\u2212A(Y\u0302)\nB(Y\u0302)\n= \u03a8\u2217B(Y\u0302)\u2212A(Y\u0302)\u2212 (\u03a8\u2217B\u2217 \u2212A\u2217)\nB(Y\u0302)\n= \u03a8\u2217(B(Y\u0302)\u2212B\u2217)\u2212 (A(Y\u0302)\u2212A\u2217)\nB(Y\u0302)\n= (\u03a8\u2217c2 \u2212 c1)(FP(Y\u0302,Y)\u2212 FP(f\u2217(X),Y)) + (\u03a8\u2217d2 \u2212 d1)(FN(Y\u0302,Y)\u2212 FN(f\u2217(X),Y))\nB(Y\u0302)\n\u2264 (\u03a8 \u2217c2 \u2212 c1)(FP(Y\u0302,Y)\u2212 FP(f\u2217(X),Y)) + (\u03a8\u2217d2 \u2212 d1)(FN(Y\u0302,Y)\u2212 FN(f\u2217(X),Y))\n\u03b3\n= C ( Risk\u03b1(Y\u0302,Y)\u2212 Risk\u03b1(f\u2217(X),Y) ) .\nAssuming (\u03a8\u2217c2 \u2212 c1) \u2265 0 and (\u03a8\u2217d2 \u2212 d1) \u2265 0, the last equality follows by defining:\n\u03b1 = \u03a8\u2217c2 \u2212 c1\n\u03a8\u2217c2 \u2212 c1 +\u03a8\u2217d2 \u2212 d1 . (11)\nand C = \u03a8 \u2217c2\u2212c1+\u03a8\u2217d2\u2212d1\n\u03b3 . The statement of the lemma follows. When \u03a8 is a metric\nfrom family (4), we can apply Proposition 1 of (Koyejo et al., 2015) to see that TPi = TP, FPi = FP and so on (as the expectations are defined wrt TPij ,FPij), which yields \u03a8\n\u2217 is identical as in the micro-averaging case. So, the same regret bound applies as shown below: Define Ai = a0+a11TPi+a01FPi+a10FNi+a00TNi = c1FPi+d1FNi+ e1 and Bi similarly.\nAs before, let \u03a8\u2217 = A\u2217/B\u2217. So when \u03a8 is of the form (4),\n\u03a8\u2217 \u2212\u03a8(Y\u0302,Y) = 1 n\nn\u2211\ni=1\n\u03a8\u2217Bi(Y\u0302)\u2212Ai(Y\u0302) Bi(Y\u0302)\n= 1\nn\nn\u2211\ni=1\n\u03a8\u2217Bi(Y\u0302)\u2212Ai(Y\u0302)\u2212 (\u03a8\u2217B\u2217 \u2212A\u2217) Bi(Y\u0302)\n= 1\nn\nn\u2211\ni=1\n\u03a8\u2217(Bi(Y\u0302)\u2212B\u2217)\u2212 (Ai(Y\u0302)\u2212A\u2217) Bi(Y\u0302)\n= 1\nn\nn\u2211\ni=1\n(\u03a8\u2217c2 \u2212 c1)(FPi(Y\u0302,Y)\u2212 FP(f\u2217(X),Y)) + (\u03a8\u2217d2 \u2212 d1)(FNi(Y\u0302,Y)\u2212 FN(f\u2217(X),Y)) Bi(Y\u0302)\n= 1\nn\nn\u2211\ni=1\n(\u03a8\u2217c2 \u2212 c1)(FP(Y\u0302,Y)\u2212 FP(f\u2217(X),Y)) + (\u03a8\u2217d2 \u2212 d1)(FN(Y\u0302,Y)\u2212 FN(f\u2217(X),Y)) Bi(Y\u0302)\n\u2264 (\u03a8 \u2217c2 \u2212 c1)(FP(Y\u0302,Y)\u2212 FP(f\u2217(X),Y)) + (\u03a8\u2217d2 \u2212 d1)(FN(Y\u0302,Y)\u2212 FN(f\u2217(X),Y))\n\u03b3\n= C ( Risk\u03b1(Y\u0302,Y)\u2212 Risk\u03b1(f\u2217(X),Y) ) .\nwhich is identical to the bound for family (3). It is easy to see that (5) also admits the above bound. Therefore, relation (10) holds for all definitions of \u03a8, with the same \u03b1."}, {"heading": "A.1.2 Proof of Lemma 3", "text": "Let Y, Y\u0302 \u2208 {0, 1}n\u00d7L. Note that for any \u2113, Risk\u2113(f) is defined as:\nRisk\u2113(f) = E[\u2113(Y\u0302ij,Yij)] = EX\u223cPn X E(i,j)\u223c\u03c0EYij\u223cP(.|xi)\u2113(Y\u0302ij ,Yij),\nwhere \u03c0 denotes the sampling distribution over (i, j) pairs. Fix instance i and label j. Let \u03b7ij denote the conditional probability of label j of instance i being 1, i.e. \u03b7ij = P(Yij = 1|xi). For convenience, denote \u03b7ij simply by \u03b7. Given \u03b7 \u2208 [0, 1], and y\u0302 \u2208 {0, 1}, consider the conditional \u2113\u03b1-risk of y\u0302:\nL\u03b1(\u03b7, y\u0302) = \u03b1(1 \u2212 \u03b7)[[y\u0302 = 1]] + (1\u2212 \u03b1)\u03b7[[y\u0302 = 0]],\nand the corresponding conditional \u2113\u03b1 regret of y\u0302:\nRegL\u03b1(\u03b7, y\u0302) = L\u03b1(\u03b7, y\u0302)\u2212min y\u0302 L\u03b1(\u03b7, y\u0302),\nwhere we have: argminy\u0302 L\u03b1(\u03b7, y\u0302) = [[\u03b7 \u2212 \u03b1]]. More generally, for a loss \u2113, and a number z\u0302, we have:\nL\u2113(\u03b7, z\u0302) = \u2113(z\u0302, 1)\u03b7 + \u2113(z\u0302, 0)(1 \u2212 \u03b7),\nand\nRegL\u2113 (\u03b7, z\u0302) = L\u2113(\u03b7, z\u0302)\u2212min z\u0302 L\u2113(\u03b7, z\u0302).\nNow, observe that:\nRisk\u03b1(Y\u0302,Y) = EX\u223cPn X E(i,j)\u223c\u03c0L\u03b1(\u03b7ij , Y\u0302ij),\nand\nReg\u03b1(Y\u0302,Y) = EX\u223cPnXE(i,j)\u223c\u03c0Reg L \u03b1(\u03b7ij , Y\u0302ij),\nwhere the last equality follows from the fact that the Bayes optimal f\u2217\u03b1 of the \u2113\u03b1-risk minimizes the conditional L\u03b1(\u03b7ij , .) risk for each (i, j). Let Z = f(X) \u2208 Rn\u00d7L denote real-valued predictions obtained using some function f . Using the same arguments as by Kot\u0142owski and Dembczy\u0144ski (2015), we can show that, by setting threshold \u03b8\u2217 = \u03be(\u03b1), where \u03be is the monotonic link function corresponding to \u03bb-strongly proper loss \u2113, and \u03b1 is defined as in (9), the conditional \u2113\u03b1 regret of Y\u0302ij = [[Zij \u2265 \u03b8\u2217]] for a fixed (i, j) can be bounded as:\nRegL\u03b1(\u03b7ij , Y\u0302ij) \u2264 \u221a 2\n\u03bb\n\u221a RegL\u2113 (\u03b7ij ,Zij),\nTaking expectation wrt sampling distribution \u03c0 and the distribution over instances Pn X on both the sides of the above inequality, and applying Jensen\u2019s inequality, the statement of the Lemma follows."}, {"heading": "A.1.3 Proof of Lemma 4", "text": "The first part of the lemma is trivially true. For the second part, we can apply the same arguments as in Lemma 9 of Koyejo et al. (2014)."}, {"heading": "A.2 Proof of Theorem 2", "text": "The following theorem bounds the error of the estimator W\u0302 \u2208 Rn\u00d7L in this model, via the result by Lafond (2015).\nTheorem 5 ( Lafond (2015)). Assume \u03c0 is uniform, and consider the 1-bit matrix completion sampling model (2). Let W\u0302 be the solution to the trace-norm regularized optimization problem (6) using logistic loss for \u2113 (with input X assumed to be identity matrix of size n), number of observations |\u2126| \u2265 log(n+L)min(n,L)max(c\u2032\u03b3 log2(c\u2032\u2032\u03b3 \u221a min(n,L), 1/9), and\nsetting the regularization parameter \u03bb = 2c\u03b3 \u221a 2 log(n+L) min(n,L)|\u2126| . Then, with probability at least 1\u2212 3(n + L)\u22121, the following holds:\n\u2016W\u0302 \u2212 W\u2217\u20162F nL\n\u2264 C\u0303max ( max(n,L) rank(W\u2217) log(n+ L)\n|\u2126|\n( \u03c32\u03b3 + 1 ) , \u03b32\n\u00b5\n\u221a log(n+ L)\n|\u2126|\n) ,\nwhere C\u0303, c\u03b3 , c \u2032 \u03b3 , c \u2032\u2032 \u03b3 , \u03c3\u03b3 are numerical constants.\nThe above theorem can be extended to general distributions \u03c0 satisfying Assumption 2. See Lafond (2015) for more details. Now, we use the fact that \u2113 is 1-Lipschitz (say, by choosing logistic loss), and bound E[\u2113(W\u0302ij ,Yij) \u2212 \u2113(W\u2217ij ,Yij)] \u2264 1nL \u2211 ij |W\u0302ij \u2212 W\u2217ij|.\nObserving that \u2016W\u0302\u2212W\u2217\u20161 \u2264 \u221a nL\u2016W\u0302\u2212W\u2217\u2016F , and combining with the bound in Theorem 5, the proof is complete."}, {"heading": "A.3 Weakness of using Lafond (2015) for Multi-label Learning", "text": "In the multi-label learning model (1), one could hope to directly apply the analysis of Lafond (2015) for recovering XW\u2217 \u2208 Rn\u00d7L, and in turn, W\u2217 \u2208 Rd\u00d7L. In lieu of problem (6), we would then solve the optimization problem in Lafond (2015):\nW\u0302 = arg min W:\u2016XW\u2016\u221e\u2264\u03b3\n1 |\u2126| \u2211\n(i,j)\u2208\u2126\n\u2113(\u3008xi,wj\u3009,Yij) + \u03bb\u2016XW\u2016\u2217 (12)\nNote that the only difference is how the trace-norm regularization is performed: \u2016XW\u2016\u2217 versus our proposed \u2016W\u2016\u2217 in Algorithm 1. The following corollary of Theorem 5 provides a bound for the recovery error of W\u0302.\nCorollary 2. Assume 1, \u03c0 is uniform, and consider the sampling model (1). Let W\u0302 be the solution to the trace-norm regularized optimization problem (12) using logistic loss for \u2113, number of observations |\u2126| \u2265 log(n + L)min(n,L)max(c\u2032\u03b3 log2(c\u2032\u2032\u03b3 \u221a min(n,L), 1/9), and\nsetting the regularization parameter \u03bb = 2c\u03b3 \u221a 2 log(n+L) min(n,L)|\u2126| . Then, with probability at least 1\u2212 3(n + L)\u22121, the following holds:\n\u2016W\u0302 \u2212 W\u2217\u20162F dL \u2264 C\u0303 d max\n( max(n,L) rank(W\u2217) log(n+ L)\n|\u2126|\n( \u03c32\u03b3 + 1 ) , \u03b32\n\u00b5\n\u221a log(n+ L)\n|\u2126|\n) ,\nwhere C\u0303, c\u03b3 , c \u2032 \u03b3 , c \u2032\u2032 \u03b3 , \u03c3\u03b3 are numerical constants.\nWhen n \u2265 L and |\u2126| = O(n), which is quite common in multi-label scenario, the above bound suggests that W\u0302 from (12) is not even a consistent estimator, even when \u03c0 is uniform."}, {"heading": "A.4 Proof of Theorem 3", "text": "The statement is a corollary of the more general Theorem 8, proved in Appendix B. We can compute the constants for the logistic loss as: \u03c3\u0304\u03b3 \u2264 1 and \u03c3\u03b3 \u2265 (1+e \u03b3)2 e\u2212\u03b3 , over the domain [\u2212\u03b3, \u03b3]."}, {"heading": "A.5 Proof of Theorem 4", "text": "The following result by (Hsieh et al., 2015) gives recovery bound for the resulting estimator W\u0302, as described in the text (Section 4.2.3).\nTheorem 6 ((Hsieh et al., 2015)). With probability at least 1\u2212 2(n + L)\u22121,\n\u2016W\u0302 \u2212 W\u2217\u20162F nL\n\u2264 6 \u221a\nlog(n+ L)\u221a nL(1\u2212 \u03c1) + 2C . t\n\u221a n+ \u221a L (1\u2212 \u03c1)nL,\nwhere C is absolute constant and \u2016W\u2217\u2016\u2217 \u2264 t. The proof is complete by using the same argument for 1-Lipschitz \u2113 as in the proof of Theorem 2."}, {"heading": "Appendix B. Sampling from Exponential Distribution", "text": "We now consider the generalized matrix completion problem when the values are sampled iid from an exponential distribution parameterized by the input features x \u2208 Rd. This setting extends that of Lafond (2015). Let yij \u2208 R denote a random sample corresponding to the user i and label j, which is distributed as:\nyij|xi,wj \u223c exph,G(xi,wj) := h(yij) exp ( \u3008xi,wj\u3009yij \u2212G(\u3008xi,wj\u3009) ) . (13)\nwhere \u3008xi,wj\u3009, i = 1, 2, . . . , n and j = 1, 2, . . . , L are the canonical parameters, h and G are the base measure and log-partition functions associated with this canonical representation.\nLet W\u2217 \u2208 Rd\u00d7L denote the ground-truth parameter matrix with wj\u2019s as columns. Similarly, let Y \u2208 Rn\u00d7L (with entries yij) denote a random sample from XW\u2217. As in the standard matrix completion setting, we only observe values of Y corresponding to a set of indices \u2126 sampled iid from a fixed distribution.\nNotation. With a slight abuse, we will continue to use \u3008., .\u3009 when the arguments are matrices, instead of the trace operator, i.e. for matrices A and B of appropriate dimensions,\n\u3008A,B\u3009 := trace(ATB). Let \u2016A\u2016\u221e = maxij |Aij |, \u2016A\u2016F = \u221a\u2211 ij A 2 ij , \u2016A\u2016\u2217 denote the trace norm (sum of singular values of A), \u03c3max(A) = \u2016A\u20162 denote the operator norm (maximum singular value of A), and \u03c3min(A) denote the smallest singular value."}, {"heading": "Maximum Log-likelihood Estimator.", "text": "We consider the negative log-likelihood of the observations, given by:\n\u03a6Y (X,W) = \u2212 1 |\u2126| \u2211\n(i,j)\u2208|\u2126|\nyij\u3008xi,wj\u3009 \u2212G(\u3008xi,wj\u3009).\nConstrained ML estimator is obtained as:\nW\u0302 := arg min W:\u2016XW\u2016\u221e\u2264\u03b3\n\u03a6\u03bbY (X,W) := \u03a6Y (X,W) + \u03bb\u2016W\u2016\u2217 (14)\nAssumption 3. 1. The function G(x) is twice differentiable and strongly convex on [\u2212\u03b3, \u03b3], such that there exists constants \u03c3\u0304\u03b3 > 0 and \u03c3\u03b3 > 0 satisfying:\n\u03c32\u03b3 \u2264 G\u2032\u2032(x) \u2264 \u03c3\u03042\u03b3 ,\nfor any x \u2208 [\u2212\u03b3, \u03b3].\n2. There exists a constant \u03b4\u03b3 > 0 such that for all x \u2208 [\u2212\u03b3, \u03b3] and y \u223c exph,G(x):\nEy\u223cP(.|x)\n[ exp ( |y \u2212G\u2032(x)| \u03b4\u03b3 )] \u2264 e.\nDefinition 1. Given convex function G(x) define the Bregman divergence between two scalars x, x\u2032 \u2208 R as:\ndG(x, x \u2032) = G(x)\u2212G(x\u2032)\u2212G\u2032(x\u2032)(x\u2212 x\u2032). (15)\nRemark 8. Under Assumption 3.1, for any x, x\u2032 \u2208 [\u2212\u03b3, \u03b3], the Bregman divergence G satisfies:\n\u03c32\u03b3(x\u2212 x\u2032)2 \u2264 2dG(x, x\u2032) \u2264 \u03c3\u03042\u03b3(x\u2212 x\u2032)2. (16)\nLet Eij \u2208 Rn\u00d7L denote the indicator matrix with zeros everywhere except at (i, j) where it is 1. For (\u01ebij) |\u2126| ij=1 a Rademacher sequence independent from (\u2126, Y\u2126), define:\n\u03a3R := 1 |\u2126| \u2211\n(i,j)\u2208\u2126\n\u01ebijEij. (17)\nTheorem 7. Assume 3.1, 2.1, \u2016XW\u2217\u2016\u221e \u2264 \u03b3, \u03c3min(X) > 0 and 2\u2016XT\u2207\u03a6Y(X,W\u2217)\u20162 \u2264 \u03bb. Then, with probability at least 1\u2212 2(n+ L)\u22121, the following holds:\n\u2016W\u0302 \u2212 W\u2217\u20162F dL \u2264 C\u00b5 2n\n\u03c32min(X) . d max\n( L rank(W\u2217) ( \u03bb2\n\u03c34\u03b3\nn\n\u03c32min(X) +d\n( E\u2016\u03a3R\u20162 )2 ) , \u03b32\n\u00b5\n\u221a log(n+ L)\n|\u2126|\n) ,\nwhere C is a numerical constant and \u03a3R is defined as in (17).\nProof. The proof closely follows that of Theorem 5 of Lafond (2015). As W\u0302 is the minimizer of (14), we have: \u03a6\u03bbY (X, W\u0302)\u2212 \u03a6\u03bbY (X,W\u2217) \u2264 0 It follows that:\n\u03bb(\u2016W\u0302\u2016\u2217 \u2212 \u2016W \u2217\u2016\u2217) + 1 |\u2126| \u2211\n(i,j)\u2208\u2126\nyij\u3008xi,w\u2217j \u2212 w\u0302j\u3009+G(\u3008xi, w\u0302j\u3009)\u2212G(\u3008xi,w\u2217j \u3009) \u2264 0\nUsing the fact that the gradient matrix:\n\u2207\u03a6Y (X,W\u2217) := \u2207XW\u2217\u03a6Y (X,W\u2217) = \u2212 1 |\u2126| \u2211\n(i,j)\u2208\u2126\n( yij \u2212G\u2032(\u3008xi,w\u2217j \u3009)Eij (18)\n(where Eij are the indicator matrices defined earlier) in the above inequality, we have:\n\u03bb(\u2016W\u0302\u2016\u2217 \u2212 \u2016W\u2217\u2016\u2217) + \u2329 \u2207\u03a6Y (X,W\u2217),X(W\u2217 \u2212 W\u0302) \u232a +\n1 |\u2126| \u2211\n(i,j)\u2208\u2126\nG(\u3008xi, w\u0302j\u3009)\u2212G(\u3008xi,w\u2217j \u3009)\u2212G\u2032(\u3008xi,w\u2217j \u3009)(\u3008xi, w\u0302j \u2212w\u2217j \u3009) \u2264 0.\nUsing the definition of the divergence (15), and the fact that \u2329 \u2207\u03a6Y (X,W\u2217),X(W\u2217\u2212W\u0302) \u232a = \u2329 X T\u2207\u03a6Y (X,W\u2217),W\u2217 \u2212 W\u0302 \u232a it follows that:\nD\u2126G(XW\u0302,XW \u2217) :=\n1 |\u2126| \u2211\n(i,j)\u2208\u2126\ndG(\u3008xi, w\u0302j\u3009, \u3008xi,w\u2217j \u3009) \u2264 \u03bb(\u2016W\u2217\u2016\u2217\u2212W\u0302\u2016\u2217)\u2212 \u2329 X T\u2207\u03a6Y (X,W\u2217),W\u2217\u2212W\u0302 \u232a\nThe first term in the RHS of above inequality can be bounded first using Lemma 16-(iii) of Lafond (2015). The second term can be bounded using the trace inequality (that uses the duality between \u2016.\u2016\u2217 and \u2016.\u20162) and the assumption on \u03bb stated in the Theorem. We get:\nD\u2126G(XW\u0302,XW \u2217) \u2264 \u03bb(\u2016PW\u2217(W\u0302 \u2212 W\u2217)\u2016\u2217 +\n1 2 \u2016W\u0302 \u2212 W\u2217\u2016\u2217).\nTo bound the first term in the above equation, we can apply Lemma 16-(ii) of Lafond (2015). Lemma 5 gives a bound for the second term. Together we have:\nD\u2126G(XW\u0302,XW \u2217) \u2264 3\u03bb \u221a 2 rank(W\u2217)\u2016W\u0302 \u2212 W\u2217\u2016F . (19)\nBy strong convexity of G (Assumption 3.1), we have:\n\u22062Y(XW\u0302,XW \u2217) :=\n1 |\u2126| \u2211\n(i,j)\u2208\u2126\n(\u3008xi, w\u0302j \u2212w\u2217j \u3009)2 \u2264 2\n\u03c32\u03b3 D\u2126G(XW\u0302,XW \u2217). (20)\nNow, we will get a lower bound for\u22062Y (XW\u0302,XW \u2217). To do so, let us define \u03b2 := 8e\u03b32\n\u221a log(n+ L)/|\u2126|\nand distinguish the two following cases:\nCase 1 If E[(\u3008xi, w\u0302j \u2212w\u2217j \u3009)2] \u2264 \u03b2, where E is defined wrt the sampling distribution as in Assumption 2, then Lemma 18 of Lafond (2015) yields,\n\u2016XW\u0302 \u2212 XW\u2217\u20162F nL \u2264 \u00b5\u03b2. (21)\nCase 2 If E[(\u3008xi, w\u0302j \u2212 w\u2217j \u3009)2] > \u03b2, consider W\u0302 \u2208 C(\u03b2, 32\u00b5dL rank(W\u2217)), where C(., .) is defined as:\nC(\u03b2, r) = { W \u2208 Rd\u00d7L | \u2016W\u2217 \u2212 W\u0302\u2016\u2217 \u2264 \u221a rE[\u22062 Y (XW,XW\u2217)];E[\u22062 Y (XW,XW\u2217)] > \u03b2 } . (22)\nThen, from Lemma 19 of Lafond (2015), it holds with probability at least 1 \u2212 2(n + L)\u22121 that\n\u22062Y(XW\u0302,XW \u2217) \u2265 1\n2 E[\u22062Y(XW\u0302,XW \u2217)]\u2212 512e(E[\u2016\u03a3R\u20162)2\u00b5dL rank(W\u2217). (23)\nCombining the above inequality with (20), (19) and Lemma 18 of Lafond (2015) yields:\n\u2016XW\u0302 \u2212 XW\u2217\u20162F 2\u00b5nL \u2212 512e(E[\u2016\u03a3R\u20162)2\u00b5dL rank(W\u2217) \u2264 6\u03bb\n\u03c32\u03b3\n\u221a 2 rank(W\u2217)\u2016W\u0302 \u2212 W\u2217\u2016F .\nWe can use Lemma (6) to bound the first term from below. Applying the identity ab \u2264 (a2+ b2)/4, multiplying both sides of the inequality by 1/d, rearranging and combining with (21), the proof is complete.\nTheorem 8. Assume 1, 2, 3. Choose, n \u2265 C \u2032 . d, L \u2265 d, |\u2126| \u2265 L+ d and \u03bb = 2c\u03c3\u0304\u03b3\u221a |\u2126| . Then, with probability at least 1\u2212 3(n+ L)\u22121 \u2212 2(d+ L)\u22121, the following holds:\n\u2016W\u0302 \u2212 W\u2217\u20162F dL \u2264 C2\u00b5 2 d max\n( L rank(W\u2217) log(n+ L)\n|\u2126|\n( \u03c3\u03042\u03b3 \u03c34\u03b3 + 1 ) , \u03b32 \u00b5\n\u221a log(n+ L)\n|\u2126|\n) ,\nwhere c, C \u2032, C2 are numerical constants.\nProof. It suffices to show 2\u2016XT\u2207\u03a6(X,W\u2217)\u20162 \u2264 \u03bb for chosen \u03bb in the statement of the Theorem and a suitable bound for E\u2016\u03a3R\u20162 (the result would then follow by applying Theorem 7). The latter term can be readily bounded applying the corresponding arguments in the proof of Theorem 6 of Lafond (2015), which yields:\nE\u2016\u03a3R\u20162 \u2264 c\u2217 \u221a 2e log(n+ L)\n|\u2126|\n( \u03bd\nmin(n,L)\n) , (24)\nwhere we use the fact that \u2211L\nl=1 \u03c0k,l = \u03bd min(n,L) (by Assumption 2). where c \u2217 is a numerical\nconstant. We can apply Lemma 1 to bound \u2016XT\u2207\u03a6(X,W\u2217)\u20162, with the \u03bb chosen in the statement of the Theorem. The proof is complete noting that for the choice of n as in the statement of the Theorem, Lemma 7 implies \u03c32min(X) \u2265 Cn and that for the choice of n and L as in the statement of the Theorem, dmin(n,L) \u2264 1.\nLemma 5. Let XW,XW\u0303 \u2208 Rn\u00d7L satisfy \u2016XW\u2016\u221e \u2264 \u03b3 and \u2016XW\u0303\u2016\u221e \u2264 \u03b3. Assume: 2\u2016XT\u2207\u03a6Y(X, W\u0303)\u20162 \u2264 \u03bb, and \u03a6\u03bbY (X,W) \u2264 \u03a6\u03bbY (X, W\u0303). Then: (i) \u2016P\u22a5\nW\u0303 (W \u2212 W\u0303)\u2016\u2217 \u2264 3\u2016PW\u0303(W \u2212 W\u0303)\u2016\u2217,\n(ii) \u2016W \u2212 W\u0303\u2016\u2217 \u2264 4 \u221a\n2 rank(W\u0303)\u2016W \u2212 W\u0303\u2016F . Proof. The proof closely follows that of Lemma 17 of (Lafond, 2015). By definition, we have: \u03a6\u03bbY (X,W)\u2212 \u03a6\u03bbY (X, W\u0303) \u2264 0 or, \u03a6Y (X,W)\u2212 \u03a6Y (X, W\u0303) \u2264 \u03bb(\u2016W\u0303 \u2212 W\u2016\u2217) ."}, {"heading": "Writing W \u2208 Rd\u00d7L as W = W\u0303+P\u22a5", "text": "W\u0303 (W\u2212 W\u0303)+P W\u0303 (W\u2212 W\u0303), Lemma 16-(i) of (Lafond, 2015)\nand triangle inequality together give:\n\u2016W\u2016\u2217 \u2265 \u2016W\u0303\u2016\u2217 + \u2016P\u22a5 W\u0303 (W \u2212 W\u0303)\u2016\u2217 + \u2016PW\u0303(W \u2212 W\u0303)\u2016\u2217,\nOr, \u03a6Y (X, W\u0303)\u2212 \u03a6Y (X,W) \u2265 \u03bb(\u2016P\u22a5\nW\u0303 (W \u2212 W\u0303)\u2016\u2217 + \u2016PW\u0303(W \u2212 W\u0303)\u2016\u2217) . (25)\nNote that by convexity of \u03a6Y :\n\u03a6Y (X, W\u0303)\u2212 \u03a6Y (X,W) \u2264 \u2329 \u2207\u03a6Y (X, W\u0303),XW\u0303 \u2212 XW \u232a = \u2329 X T\u2207\u03a6Y (X, W\u0303), W\u0303 \u2212 W \u232a ,\nBy trace inequality, we have:\n\u03a6Y (X, W\u0303)\u2212 \u03a6Y (X,W) \u2264 \u2016XT\u2207\u03a6Y (X, W\u0303)\u20162\u2016W\u0303 \u2212 W\u2016\u2217 \u2264 \u03bb\n2 \u2016W\u0303 \u2212 W\u2016\u2217\nwhere the last inequality is by assumption, \u2016XT\u2207\u03a6Y (X, W\u0303)\u20162 \u2264 \u03bb/2. The last term in the above inequality can be bounded by \u03bb2 ( \u2016P\u22a5 W\u0303 (W \u2212 W\u0303)\u2016\u2217 + \u2016PW\u0303(W \u2212 W\u0303)\u2016\u2217 ) . Together with\n(25), we get the first part of the Lemma. We can now conclude the proof of part two using identical arguments as in Lemma 17 of (Lafond, 2015).\nLemma 6. Let \u03c3min(X) denote the smallest singular value of X. Then for any W, W\u0303, Then:\n\u2016XW \u2212 XW\u0303\u20162F \u2265 \u03c32min(X)\u2016W \u2212 W\u0303\u20162F .\nProof. Observe that \u2016X(W\u2212W\u0303)\u20162F = trace ( X(W\u2212W\u0303)(W\u2212W\u0303)TXT ) = trace ( (W\u2212W\u0303)(W\u2212\nW\u0303)TXTX ) \u2265 \u03c3min(XTX)trace ( (W \u2212 W\u0303)(W \u2212 W\u0303)T ) = \u03c3min(X) 2\u2016W \u2212 W\u0303\u20162F .\nLemma 7. Let X \u2208 Rn\u00d7d be a matrix with rows sampled from sub-Gaussian distribution satisfying Assumption 1. Furthermore, choose:\nn \u2265 C \u2032d .\nThen, with probability at least 1\u2212 2e\u2212d, each of the following statements is true:\n\u03c3max(X T X) \u2264 C\u0304n,\n\u03c3min(X T X) \u2265 Cn,\nwhere C \u2032, C\u0304 and C are absolute constants that depend only on the parameters K and \u03a3 of the sub-Gaussian distribution.\nProof. Using Lemma 16 of Bhatia et al. (2015b), we have for any \u03b4 > 0, with probability at least 1\u2212 \u03b4, each of the following statements hold:\n\u03c3max(X T X) \u2264 \u03c3max(\u03a3) . n+ CK \u221a dn + t \u221a n,\n\u03c3min(X T X) \u2265 \u03c3min(\u03a3) . n\u2212 CK \u221a dn\u2212 t\u221an,\nwhere t = \u221a\n1 cK log 2 \u03b4 , and cK , CK are absolute constants that depend only on the sub-\nGaussian norm K of the distribution PX . Now, choosing \u03b4 = 2e \u2212d or log(2/\u03b4) = d, we have:\nCK \u221a dn+ t \u221a n = CK \u221a dn +\n\u221a 1\ncK dn =\n\u221a dn ( CK + \u221a 1\nck\n) .\nFor ease, define C \u2032K := CK+ \u221a 1 ck . Now, choosing n \u2265 ( C\u2032K \u03c3min(\u03a3) )2 . d, and substituting above we have:\nCK \u221a dn+ t \u221a n \u2264 1\n2 \u03c3min(\u03a3) .n.\nTherefore:\n\u03c3max(X T X) \u2264 ( \u03c3max(\u03a3) + 1\n2 \u03c3min(\u03a3)\n) n,\n\u03c3min(X T X) \u2265 1\n2 \u03c3min(\u03a3) . n.\nThe proof is complete."}, {"heading": "Proof of Lemma 1", "text": "Let H denote the matrix with hij = yij \u2212G\u2032(\u3008xi,w\u2217j \u3009). Let hi denote the ith row of H. Let P\u2126(H) denote the projection of H onto the observed indices \u2126. Let \u2126i denote the observed indices in row i of Y. For a vector v, let v\u2126i denote its projection onto the observed indices \u2126i.\nFix u \u2208 Rd and v \u2208 RL. Define ai = xTi u and bi = \u3008v\u2126i ,hi\u2126i\u3009. We have:\n1\n|\u2126|u T X TP\u2126(H)v =\n1 |\u2126| n\u2211\ni=1\naibi\n= 1 |\u2126| n\u2211\ni=1\n\u2016v\u2126i\u20162 . ai bi\n\u2016v\u2126i\u20162 .\nConsider bi = \u2211\n(i,j)\u2208\u2126 vjhij . Note that hij \u2019s are sub-Gaussian random variables with subGaussian norm \u03b1. Using Lemma 5.9 of Vershynin (2010), we have bi is sub-Gaussian with norm \u2016v\u2126i\u20162\u03b1. In turn, this implies, bi\u2016v\u2126i\u20162 is sub-Gaussian with sub-Gaussian norm \u03b1. Therefore, aibi\u2016v\u2126i\u20162 is \u03b1-subexponential. Applying Proposition 5.16 of Vershynin (2010), we have, with probability at least 1\u2212 \u03b4,\n1 |\u2126| n\u2211\ni=1\n\u2016v\u2126i\u20162 . ai bi \u2016v\u2126i\u20162 \u2264 c . \u03b1|\u2126|\n(\u221a\u221a\u221a\u221a n\u2211\ni=1\n\u2016v\u2126i\u20162 \u221a log 2\n\u03b4 +max i\u2208[n] \u2016v\u2126i\u20162 log\n2\n\u03b4\n) .\nfor some absolute constant c. Noting that: \u2016v\u20162 = 1 and for any j \u2208 [L], |{i : (i, j) \u2208 \u2126}| \u2264 c\u2032.|\u2126| L , we have, with probability at least 1\u2212 \u03b4,\n1 |\u2126| n\u2211\ni=1\n\u2016v\u2126i\u20162 . ai bi \u2016v\u2126i\u20162 \u2264 c . \u03b1|\u2126| (\u221a c\u2032.|\u2126| L \u221a log 2 \u03b4 + log 2 \u03b4 ) .\nWe conclude the proof by a covering argument: Taking a union bound over \u01eb-ball of u and v, we have, with probability at least 1\u2212 (d+ L)\u22121:\n\u2225\u2225XT\u2207\u03a6Y (X,W\u2217) \u2225\u2225 2 \u2264 c . \u03b1|\u2126| (\u221a c\u2032.|\u2126| L \u221a d+ L+ d+ L ) .\nAssuming d \u2264 L and |\u2126| \u2265 (L+ d), the proof is complete."}], "references": [{"title": "Surrogate regret bounds for bipartite ranking via strongly proper losses", "author": ["Shivani Agarwal"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Agarwal.,? \\Q2014\\E", "shortCiteRegEx": "Agarwal.", "year": 2014}, {"title": "Sparse local embeddings for extreme multi-label classification", "author": ["Kush Bhatia", "Himanshu Jain", "Purushottam Kar", "Manik Varma", "Prateek Jain"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bhatia et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bhatia et al\\.", "year": 2015}, {"title": "Robust regression via hard thresholding", "author": ["Kush Bhatia", "Prateek Jain", "Purushottam Kar"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bhatia et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bhatia et al\\.", "year": 2015}, {"title": "A max-norm constrained minimization approach to 1-bit matrix completion", "author": ["Tony Cai", "Wen-Xin Zhou"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Cai and Zhou.,? \\Q2013\\E", "shortCiteRegEx": "Cai and Zhou.", "year": 2013}, {"title": "1-bit matrix completion", "author": ["Mark A Davenport", "Yaniv Plan", "Ewout van den Berg", "Mary Wootters"], "venue": "Information and Inference,", "citeRegEx": "Davenport et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Davenport et al\\.", "year": 2014}, {"title": "Consistent multilabel ranking through univariate losses", "author": ["Krzysztof Dembczynski", "Wojciech Kotlowski", "Eyke H\u00fcllermeier"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "Dembczynski et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dembczynski et al\\.", "year": 2012}, {"title": "On the consistency of multi-label learning", "author": ["Wei Gao", "Zhi-Hua Zhou"], "venue": "Artificial Intelligence,", "citeRegEx": "Gao and Zhou.,? \\Q2013\\E", "shortCiteRegEx": "Gao and Zhou.", "year": 2013}, {"title": "Pu learning for matrix completion", "author": ["Cho-jui Hsieh", "Nagarajan Natarajan", "Inderjit Dhillon"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning", "citeRegEx": "Hsieh et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hsieh et al\\.", "year": 2015}, {"title": "Provable inductive matrix completion", "author": ["Prateek Jain", "Inderjit S Dhillon"], "venue": "arXiv preprint arXiv:1306.0626,", "citeRegEx": "Jain and Dhillon.,? \\Q2013\\E", "shortCiteRegEx": "Jain and Dhillon.", "year": 2013}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Yehuda Koren", "Robert Bell", "Chris Volinsky"], "venue": null, "citeRegEx": "Koren et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Koren et al\\.", "year": 2009}, {"title": "Surrogate regret bounds for generalized classification performance metrics", "author": ["Wojciech Kot\u0142owski", "Krzysztof Dembczy\u0144ski"], "venue": "arXiv preprint arXiv:1504.07272,", "citeRegEx": "Kot\u0142owski and Dembczy\u0144ski.,? \\Q2015\\E", "shortCiteRegEx": "Kot\u0142owski and Dembczy\u0144ski.", "year": 2015}, {"title": "Consistent binary classification with generalized performance metrics", "author": ["Oluwasanmi O Koyejo", "Nagarajan Natarajan", "Pradeep K Ravikumar", "Inderjit S Dhillon"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Koyejo et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Koyejo et al\\.", "year": 2014}, {"title": "Consistent multilabel classification", "author": ["Oluwasanmi O Koyejo", "Nagarajan Natarajan", "Pradeep K Ravikumar", "Inderjit S Dhillon"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Koyejo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Koyejo et al\\.", "year": 2015}, {"title": "Low rank matrix completion with exponential family noise", "author": ["Jean Lafond"], "venue": "arXiv preprint arXiv:1502.06919,", "citeRegEx": "Lafond.,? \\Q2015\\E", "shortCiteRegEx": "Lafond.", "year": 2015}, {"title": "Fastxml: a fast, accurate and stable tree-classifier for extreme multi-label learning", "author": ["Yashoteja Prabhu", "Manik Varma"], "venue": "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Prabhu and Varma.,? \\Q2014\\E", "shortCiteRegEx": "Prabhu and Varma.", "year": 2014}, {"title": "Composite binary losses", "author": ["Mark D Reid", "Robert C Williamson"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Reid and Williamson.,? \\Q2010\\E", "shortCiteRegEx": "Reid and Williamson.", "year": 2010}, {"title": "Introduction to the non-asymptotic analysis of random matrices", "author": ["Roman Vershynin"], "venue": "arXiv preprint arXiv:1011.3027,", "citeRegEx": "Vershynin.,? \\Q2010\\E", "shortCiteRegEx": "Vershynin.", "year": 2010}, {"title": "Large-scale multilabel learning with missing labels", "author": ["Hsiang-Fu Yu", "Prateek Jain", "Purushottam Kar", "Inderjit Dhillon"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "Yu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2014}, {"title": "Ranking via robust binary classification", "author": ["Hyokun Yun", "Parameswaran Raman", "S Vishwanathan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Yun et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yun et al\\.", "year": 2014}, {"title": "Efficient matrix sensing using rank-1 gaussian measurements", "author": ["Kai Zhong", "Prateek Jain", "Inderjit S. Dhillon"], "venue": "In International Conference on Algorithmic Learning Theory (ALT),", "citeRegEx": "Zhong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhong et al\\.", "year": 2015}, {"title": "\u03bb-strongly proper composite loss (Reid and Williamson, 2010), such as the squared loss or the logistic. Given real-valued predictions Z \u2208 Rn\u00d7L, we now argue that there exists a thresholding Thr\u03b8\u2217(Z) \u2208 {0, 1}n\u00d7L such that Risk\u03b1(Thr\u03b8\u2217(Z),Y) is bounded by the l-regret of a strongly proper loss", "author": ["R \u00d7 R"], "venue": null, "citeRegEx": "\u2192,? \\Q2010\\E", "shortCiteRegEx": "\u2192", "year": 2010}, {"title": "Sampling from Exponential Distribution We now consider the generalized matrix completion problem when the values are sampled iid from an exponential distribution parameterized by the input features x \u2208 R. This setting extends that of Lafond (2015)", "author": ["Jain", "Natarajan Appendix B"], "venue": "Let yij \u2208 R", "citeRegEx": "Jain and B.,? \\Q2015\\E", "shortCiteRegEx": "Jain and B.", "year": 2015}, {"title": "The first term in the RHS of above inequality can be bounded first using Lemma", "author": ["Jain", "Natarajan"], "venue": null, "citeRegEx": "Jain and Natarajan,? \\Q2015\\E", "shortCiteRegEx": "Jain and Natarajan", "year": 2015}, {"title": "To bound the first term in the above equation, we can apply Lemma 16-(ii) of Lafond (2015). Lemma 5 gives a bound for the second term", "author": ["\u2016\u0174 \u2212 W"], "venue": null, "citeRegEx": "W.\u2217..,? \\Q2015\\E", "shortCiteRegEx": "W.\u2217..", "year": 2015}, {"title": "2015b), we have for any \u03b4 > 0, with probability at least 1\u2212 \u03b4, each of the following statements", "author": ["Bhatia"], "venue": null, "citeRegEx": "Bhatia,? \\Q2015\\E", "shortCiteRegEx": "Bhatia", "year": 2015}], "referenceMentions": [{"referenceID": 9, "context": "Introduction Predicting relevant labels/items for a given data point is by now a standard task with applications in several domains like recommendation systems (Koren et al., 2009), document tagging, image tagging (Prabhu and Varma, 2014), etc.", "startOffset": 160, "endOffset": 180}, {"referenceID": 14, "context": ", 2009), document tagging, image tagging (Prabhu and Varma, 2014), etc.", "startOffset": 41, "endOffset": 65}, {"referenceID": 7, "context": "Furthermore, often the location of missing labels may not be available like in the positive-unlabeled learning setting (Hsieh et al., 2015).", "startOffset": 119, "endOffset": 139}, {"referenceID": 13, "context": "On the other hand, most of the existing collaborative filtering/matrix completion methods only focus on decomposable losses like RMSE, sum of logistic loss (Lafond, 2015; Yu et al., 2014), which are not effective in real-world systems with large number of labels (Prabhu and Varma, 2014).", "startOffset": 156, "endOffset": 187}, {"referenceID": 17, "context": "On the other hand, most of the existing collaborative filtering/matrix completion methods only focus on decomposable losses like RMSE, sum of logistic loss (Lafond, 2015; Yu et al., 2014), which are not effective in real-world systems with large number of labels (Prabhu and Varma, 2014).", "startOffset": 156, "endOffset": 187}, {"referenceID": 14, "context": ", 2014), which are not effective in real-world systems with large number of labels (Prabhu and Varma, 2014).", "startOffset": 83, "endOffset": 107}, {"referenceID": 10, "context": "Our framework is motivated by a simple observation that has been used in other contexts as well (Kot\u0142owski and Dembczy\u0144ski, 2015; Koyejo et al., 2015): for a large class of metrics \u03a8, simply thresholding the class probability vector leads to bayes-optimal estimators.", "startOffset": 96, "endOffset": 150}, {"referenceID": 12, "context": "Our framework is motivated by a simple observation that has been used in other contexts as well (Kot\u0142owski and Dembczy\u0144ski, 2015; Koyejo et al., 2015): for a large class of metrics \u03a8, simply thresholding the class probability vector leads to bayes-optimal estimators.", "startOffset": 96, "endOffset": 150}, {"referenceID": 13, "context": "For general multilabel setting, a direct application of existing results, such as (Lafond, 2015) leads to weak bounds.", "startOffset": 82, "endOffset": 96}, {"referenceID": 8, "context": "In fact, our result strictly generalizes the result by Lafond (2015), which is for general matrix completion with exponential family noise, to the general inductive matrix completion setting (Jain and Dhillon, 2013) with exponential family noise.", "startOffset": 191, "endOffset": 215}, {"referenceID": 8, "context": "For example, Koyejo et al. (2015) establish that for a large class of performance metrics, the optimal solution is to compute a score vector over all the labels and selecting all the labels whose score is greater than a constant.", "startOffset": 13, "endOffset": 34}, {"referenceID": 8, "context": "Our framework is motivated by a simple observation that has been used in other contexts as well (Kot\u0142owski and Dembczy\u0144ski, 2015; Koyejo et al., 2015): for a large class of metrics \u03a8, simply thresholding the class probability vector leads to bayes-optimal estimators. Hence, the goal would be to estimate per-label class probabilities accurately. To this end, we show that by using a \u03bb-strongly proper loss along with appropriate thresholding leads to bounded regret wrt. \u03a8 (Theorem 1). Note that the threshold can be learned using cross-validation over a small fraction of the training data. Moreover, \u03bb-strong convexity of the loss function ensures that by minimizing a nuclearnorm regularized ERM (with risk measured by the selected loss function) wrt. a parameter matrix W \u2208 Rd\u00d7L, we can bound the regret in \u03a8 by regret in estimation of the optimal W (Theorem 1); here, d is the dimensionality of the data and is equal to number of users in case of recommender system. Hence, this result allows us to focus on estimation of W in various different settings such as: a) one-bit matrix completion (Theorem 2), popularly used in recommender systems with only like/dislike information, b) one-bit matrix completion with PU learning (Theorem 4) applicable to recommender systems where only \u201clikes\" or positive feedback is observed, and c) general multi-label learning with missing labels (Theorem 3). For one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al.", "startOffset": 97, "endOffset": 1540}, {"referenceID": 7, "context": "For one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al. (2015), respectively.", "startOffset": 145, "endOffset": 165}, {"referenceID": 7, "context": "For one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al. (2015), respectively. For general multilabel setting, a direct application of existing results, such as (Lafond, 2015) leads to weak bounds. A main technical contribution of our work is to analyze the parameter estimation problem in this setting and provide tight regret bounds. In fact, our result strictly generalizes the result by Lafond (2015), which is for general matrix completion with exponential family noise, to the general inductive matrix completion setting (Jain and Dhillon, 2013) with exponential family noise.", "startOffset": 145, "endOffset": 506}, {"referenceID": 7, "context": "For one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al. (2015), respectively. For general multilabel setting, a direct application of existing results, such as (Lafond, 2015) leads to weak bounds. A main technical contribution of our work is to analyze the parameter estimation problem in this setting and provide tight regret bounds. In fact, our result strictly generalizes the result by Lafond (2015), which is for general matrix completion with exponential family noise, to the general inductive matrix completion setting (Jain and Dhillon, 2013) with exponential family noise. Hence, it should have applications beyond our framework as well. Finally, we illustrate our framework and algorithms on synthetic as well as real-world datasets. Our method exhibits significant improvement over a natural extension of the method by Koyejo et al. (2015) that optimizes \u03a8 directly but ignores label correlations, hence does not handle missing labels in a principled manner.", "startOffset": 145, "endOffset": 953}, {"referenceID": 7, "context": "For one-bit matrix completion (and the related PU setting), we obtain our final regret bound by adapting existing results from Lafond (2015) and Hsieh et al. (2015), respectively. For general multilabel setting, a direct application of existing results, such as (Lafond, 2015) leads to weak bounds. A main technical contribution of our work is to analyze the parameter estimation problem in this setting and provide tight regret bounds. In fact, our result strictly generalizes the result by Lafond (2015), which is for general matrix completion with exponential family noise, to the general inductive matrix completion setting (Jain and Dhillon, 2013) with exponential family noise. Hence, it should have applications beyond our framework as well. Finally, we illustrate our framework and algorithms on synthetic as well as real-world datasets. Our method exhibits significant improvement over a natural extension of the method by Koyejo et al. (2015) that optimizes \u03a8 directly but ignores label correlations, hence does not handle missing labels in a principled manner. For example, our method achieves 12% higher F1-measure on a benchmark dataset than that by Koyejo et al. (2015).", "startOffset": 145, "endOffset": 1184}, {"referenceID": 6, "context": "Gao and Zhou (2013) study consistency and surrogate losses for", "startOffset": 0, "endOffset": 20}, {"referenceID": 13, "context": "Existing theoretical guarantees for 1-bit matrix completion methods used in recommender systems focus solely on RMSE or 0-1 loss (Lafond, 2015; Hsieh et al., 2015).", "startOffset": 129, "endOffset": 163}, {"referenceID": 7, "context": "Existing theoretical guarantees for 1-bit matrix completion methods used in recommender systems focus solely on RMSE or 0-1 loss (Lafond, 2015; Hsieh et al., 2015).", "startOffset": 129, "endOffset": 163}, {"referenceID": 5, "context": "Dembczynski et al. (2012) consider expected pairwise ranking loss in multilabel learning, show that the problem decomposes into independent binary problems, and provide regret bound for the same.", "startOffset": 0, "endOffset": 26}, {"referenceID": 5, "context": "Dembczynski et al. (2012) consider expected pairwise ranking loss in multilabel learning, show that the problem decomposes into independent binary problems, and provide regret bound for the same. Yun et al. (2014) consider the learning to rank problem, where the goal is to rank the relevant labels for a given instance.", "startOffset": 0, "endOffset": 214}, {"referenceID": 17, "context": "Following the low-rank inductive matrix completion model (Yu et al., 2014; Zhong et al., 2015), we let W \u2217 \u2208 Rd\u00d7L be the parameter matrix and gj(xi;W) = g(\u3008xi,w j \u3009) where w\u2217 j is the jth column of W corresponding to the jth label, for some differentiable function g : R \u2192 [0, 1].", "startOffset": 57, "endOffset": 94}, {"referenceID": 19, "context": "Following the low-rank inductive matrix completion model (Yu et al., 2014; Zhong et al., 2015), we let W \u2217 \u2208 Rd\u00d7L be the parameter matrix and gj(xi;W) = g(\u3008xi,w j \u3009) where w\u2217 j is the jth column of W corresponding to the jth label, for some differentiable function g : R \u2192 [0, 1].", "startOffset": 57, "endOffset": 94}, {"referenceID": 3, "context": "When we do not observe feature vectors x, as in the classical recommender system or matrix completion setting, the above model (1) reduces to the widely studied 1-bit matrix completion model (Cai and Zhou, 2013; Davenport et al., 2014):", "startOffset": 191, "endOffset": 235}, {"referenceID": 4, "context": "When we do not observe feature vectors x, as in the classical recommender system or matrix completion setting, the above model (1) reduces to the widely studied 1-bit matrix completion model (Cai and Zhou, 2013; Davenport et al., 2014):", "startOffset": 191, "endOffset": 235}, {"referenceID": 12, "context": "In this work, we consider a large family of non-decomposable metrics (Koyejo et al., 2015) that constitutes linear-fractional functions of (multi-label analogues of) true positives, false positives, false negatives and true negatives defined below.", "startOffset": 69, "endOffset": 90}, {"referenceID": 11, "context": "Koyejo et al. (2015) showed that the Bayes optimal \u03a8\u2217 thresholds the conditional probability of each label j, i.", "startOffset": 0, "endOffset": 21}, {"referenceID": 17, "context": "In many cases, W exhibits some structure, such as low-rankness, reflecting correlation between labels (Yu et al., 2014; Zhong et al., 2015; Davenport et al., 2014).", "startOffset": 102, "endOffset": 163}, {"referenceID": 19, "context": "In many cases, W exhibits some structure, such as low-rankness, reflecting correlation between labels (Yu et al., 2014; Zhong et al., 2015; Davenport et al., 2014).", "startOffset": 102, "endOffset": 163}, {"referenceID": 4, "context": "In many cases, W exhibits some structure, such as low-rankness, reflecting correlation between labels (Yu et al., 2014; Zhong et al., 2015; Davenport et al., 2014).", "startOffset": 102, "endOffset": 163}, {"referenceID": 10, "context": "Koyejo et al. (2015) proposed a simple consistent plug-in estimator algorithm, which first computes conditional marginals P(yj|x) independently for each label j, and then estimates a threshold jointly to optimize \u03a8.", "startOffset": 0, "endOffset": 21}, {"referenceID": 4, "context": ", 2015; Davenport et al., 2014). Statistically, capturing correlations via a low-rank structure could help improve the sample complexity for recovery, and computationally, it would help reduce space and time complexity of the learning procedure. Our proposed algorithm is presented in Algorithm 1. In Step 1, we solve a traceregularized minimization problem to estimate the parameter matrix W, where the function l can be any bounded loss such as the squared, the logistic or the squared Hinge loss. In particular, using the logistic loss corresponds to the maximum likelihood estimation of the sampling model (1). Yu et al. (2014) also solve essentially the same objective as (6), except for the additional bound constraint on entries of XW.", "startOffset": 8, "endOffset": 632}, {"referenceID": 12, "context": "The definitions in (Koyejo et al., 2015) do not include general sampling distribution \u03c0, but the results can be generalized in a straight-forward manner.", "startOffset": 19, "endOffset": 40}, {"referenceID": 0, "context": "1 Low l-regret implies low \u03a8-regret Our first main result connects \u03a8-regret to regret with respect to a strongly proper loss function l (Agarwal, 2014).", "startOffset": 136, "endOffset": 151}, {"referenceID": 10, "context": "Proof technique is based on (Kot\u0142owski and Dembczy\u0144ski, 2015), where they derive similar bound in the binary classification setting.", "startOffset": 28, "endOffset": 61}, {"referenceID": 13, "context": "Then (6) reduces to the optimization problem considered by Lafond (2015). We have the following regret bound for the estimator Z = \u0174 obtained in Step 2 of Algorithm 1 (Note that X is just treated as identity in this setting).", "startOffset": 59, "endOffset": 73}, {"referenceID": 13, "context": "Remark 4 (Comparing (Lafond, 2015)).", "startOffset": 20, "endOffset": 34}, {"referenceID": 13, "context": "If we directly apply the method and the analysis of (Lafond, 2015), the resulting bounds are very weak; in fact, when n \u2265 L and |\u03a9| = O(n), which is quite common in the multi-label scenario, the ensuing bound suggests that the estimator is not even consistent, even when \u03c0 is uniform.", "startOffset": 52, "endOffset": 66}, {"referenceID": 12, "context": "Remark 5 (Comparing (Koyejo et al., 2015)).", "startOffset": 20, "endOffset": 41}, {"referenceID": 12, "context": "The plugin-in estimator algorithm of (Koyejo et al., 2015) estimates w\u2217 j for each label j independently, and learns a common threshold as in Algorithm 1.", "startOffset": 37, "endOffset": 58}, {"referenceID": 13, "context": "Our proof sketch is based on Lafond (2015), but requires bounding certain quantities carefully.", "startOffset": 29, "endOffset": 43}, {"referenceID": 7, "context": "In this setting, we can use the approach of (Hsieh et al., 2015), where they consider a two-stage sampling model: sample yij using (2) for all i, j \u2208 [n] \u00d7 [L] (or using (1) when features are available), and then flip a fraction \u03c1 of the sampled 1\u2019s to 0\u2019s, resulting in \u1ef8.", "startOffset": 44, "endOffset": 64}, {"referenceID": 7, "context": "Let Z = X\u0174, where \u0174 is obtained by solving the unbiased estimator objective of Hsieh et al. (2015). With probability at least 1\u2212 \u03b4, there exists absolute constant C such that: Regl(Z) \u2264 \u221a 6 \u221a log(2/\u03b4) \u221a nL(1\u2212 \u03c1) + 2C .", "startOffset": 79, "endOffset": 99}, {"referenceID": 14, "context": "This PU learning result is particularly very useful in extreme classification setting (Bhatia et al., 2015a; Prabhu and Varma, 2014); where there are too many labels and is unrealistic to get feedback on every label, but possible to obtain a small subset of relevant labels for instances.", "startOffset": 86, "endOffset": 132}, {"referenceID": 12, "context": "Furthermore, even when only 10% of the observations are revealed, we observe that the proposed method achieves very high F1 as well as accuracy values, compared to learning the columns of W independently via the plugin estimator method proposed by (Koyejo et al., 2015) (followed by learning a threshold).", "startOffset": 248, "endOffset": 269}, {"referenceID": 17, "context": "2 Real-world data We consider five real-world multi-label datasets widely used as benchmarks (Bhatia et al., 2015a; Yu et al., 2014).", "startOffset": 93, "endOffset": 132}, {"referenceID": 11, "context": "Dataset Koyejo et al. (2015) Algorithm 1 Koyejo et al.", "startOffset": 8, "endOffset": 29}, {"referenceID": 11, "context": "Dataset Koyejo et al. (2015) Algorithm 1 Koyejo et al. (2015) Algorithm 1 micro F1 micro F1 Accuracy Accuracy CAL500 0.", "startOffset": 8, "endOffset": 62}, {"referenceID": 12, "context": "Table 1: Comparison of proposed algorithm and plugin-estimator method of (Koyejo et al., 2015) on multi-label micro F1 and Hamming (i.", "startOffset": 73, "endOffset": 94}, {"referenceID": 12, "context": "The learned model is much more compact than that of (Koyejo et al., 2015) (k(d+L) vs dL parameters).", "startOffset": 52, "endOffset": 73}], "year": 2016, "abstractText": "We consider the problem of recommending relevant labels (items) for a given data point (user). In particular, we are interested in the practically important setting where the evaluation is with respect to non-decomposable (over labels) performance metrics like the F1 measure, and the training data has missing labels. To this end, we propose a generic framework that given a performance metric \u03a8, can devise a regularized objective function and a threshold such that all the values in the predicted score vector above and only above the threshold are selected to be positive. We show that the regret or generalization error in the given metric \u03a8 is bounded ultimately by estimation error of certain underlying parameters. In particular, we derive regret bounds under three popular settings: a) collaborative filtering, b) multilabel classification, and c) PU (positive-unlabeled) learning. For each of the above problems, we can obtain precise non-asymptotic regret bound which is small even when a large fraction of labels is missing. Our empirical results on synthetic and benchmark datasets demonstrate that by explicitly modeling for missing labels and optimizing the desired performance metric, our algorithm indeed achieves significantly better performance (like F1 score) when compared to methods that do not model missing label information carefully.", "creator": "LaTeX with hyperref package"}}}