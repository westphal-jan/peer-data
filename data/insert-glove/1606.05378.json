{"id": "1606.05378", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2016", "title": "Simpler Context-Dependent Logical Forms via Model Projections", "abstract": "mpeg We wenna consider the discriminant task sugababes of tamandar\u00e9 learning 1992-1996 a 21,000 context - dependent mapping enlistee from rajabhat utterances to bishopsbourne denotations. With only yangliuqing denotations at training funda time, 4,550 we must bunch search over a raam combinatorially large halyburton space trimingham of badwater logical 335.5 forms, which stoneage is kwangtung even haly larger with context - dependent utterances. phedre To cope jala with florist this shamshabad challenge, we perform successive projections sard of accorded the full model amharic onto simpler lerner models minimizer that aota operate over uniprot equivalence classes of suvari logical ortigoza forms. Though therien less uusimaa expressive, cacti we herzeg-bosnia find redflex that .516 these simpler hargeisa models are much faster and dabbas can thrombolytic be fortwo surprisingly effective. gravelled Moreover, amets they chippenham can be ffrf used jsat to vaxjo bootstrap 46.7 the beseeched full moldava model. protima Finally, we collected 16.53 three new context - dependent acda semantic suef parsing lizz datasets, and arlecchino develop sarkis a buros new left - graveson to - right parser.", "histories": [["v1", "Thu, 16 Jun 2016 21:57:11 GMT  (5085kb,D)", "http://arxiv.org/abs/1606.05378v1", "10 pages, ACL 2016"]], "COMMENTS": "10 pages, ACL 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["reginald long", "panupong pasupat", "percy liang"], "accepted": true, "id": "1606.05378"}, "pdf": {"name": "1606.05378.pdf", "metadata": {"source": "CRF", "title": "Simpler Context-Dependent Logical Forms via Model Projections", "authors": ["Reginald Long", "Panupong Pasupat", "Percy Liang"], "emails": ["reggylong@cs.stanford.edu", "ppasupat@cs.stanford.edu", "pliang@cs.stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "Suppose we are only told that a piece of text (a command) in some context (state of the world) has some denotation (the effect of the command)\u2014see Figure 1 for an example. How can we build a system to learn from examples like these with no initial knowledge about what any of the words mean?\nWe start with the classic paradigm of training semantic parsers that map utterances to logical forms, which are executed to produce the denotation (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010). More recent work learns directly from denotations (Clarke et al., 2010; Liang, 2013; Berant et al., 2013; Artzi and Zettlemoyer, 2013), but in this setting, a constant struggle is to contain the exponential explosion of possible logical forms. With no initial lexicon and longer contextdependent texts, our situation is exacerbated.\nIn this paper, we propose projecting a full semantic parsing model onto simpler models over equivalence classes of logical form derivations. As illustrated in Figure 2, we consider the following sequence of models:\n\u2022 Model A: our full model that derives logical forms (e.g., in Figure 1, the last utterance maps to mix(args[1][1])) compositionally from the text so that spans of the utterance (e.g., \u201cit\u201d) align to parts of the logical form (e.g., args[1][1], which retrieves an argument from a previous logical form). This is based on standard semantic parsing (e.g., Zettlemoyer and Collins (2005)).\n\u2022 Model B: collapse all derivations with the same logical form; we map utterances to full logical forms, but without an alignment between the utterance and logical forms. This \u201cfloating\u201d approach was used in Pasupat and Liang (2015) and Wang et al. (2015).\n\u2022 Model C: further collapse all logical forms whose top-level arguments have the same denotation. In other words, we map utterances\nar X\niv :1\n60 6.\n05 37\n8v 1\n[ cs\n.C L\n] 1\n6 Ju\nn 20\n16\nModel A\nto flat logical forms (e.g., mix(beaker2)), where the arguments of the top-level predicate are objects in the world. This model is in the spirit of Yao et al. (2014) and Bordes et al. (2014), who directly predicted concrete paths in a knowledge graph for question answering.\nModel A excels at credit assignment: the latent derivation explains how parts of the logical form are triggered by parts of the utterance. The price is an unmanageably large search space, given that we do not have a seed lexicon. At the other end, Model C only considers a small set of logical forms, but the mapping from text to the correct logical form is more complex and harder to model.\nWe collected three new context-dependent semantic parsing datasets using Amazon Mechanical Turk: ALCHEMY (Figure 1), SCENE (Figure 3), and TANGRAMS (Figure 4). Along the way, we develop a new parser which processes utterances left-to-right but can construct logical forms without an explicit alignment.\nOur empirical findings are as follows: First, Model C is surprisingly effective, mostly surpassing the other two given bounded computational resources (a fixed beam size). Second, on a synthetic dataset, with infinite beam, Model A outperforms the other two models. Third, we can bootstrap up to Model A from the projected models with finite beam."}, {"heading": "2 Task", "text": "In this section, we formalize the task and describe the new datasets we created for the task."}, {"heading": "2.1 Setup", "text": "First, we will define the context-dependent semantic parsing task. Define w0 as the initial world state, which consists of a set of entities (beakers in ALCHEMY) and properties (location, color(s), and amount filled). The text x is a sequence of utterances x1, . . . , xL. For each utterance xi (e.g., \u201cmix\u201d), we have a latent logical form zi (e.g., mix(args[1][2])). Define the context ci = (w0, z1:i\u22121) to include the initial world state w0 and the history of past logical forms z1:i\u22121. Each logical form zi is executed on the context ci to produce the next state: wi = Exec(ci, zi) for each i = 1, . . . , L. Overloading notation, we write wL = Exec(w0, z), where z = (z1, . . . , zL).\nThe learning problem is: given a set of training examples {(w0,x, wL)}, learn a mapping from the text x to logical forms z = (z1, . . . , zL) that produces the correct final state (wL = Exec(w0, z))."}, {"heading": "2.2 Datasets", "text": "We created three new context-dependent datasets, ALCHEMY, SCENE, and TANGRAMS (see Table 1 for a summary), which aim to capture a diverse set of context-dependent linguistic phenomena such as ellipsis (e.g., \u201cmix\u201d in ALCHEMY), anaphora on entities (e.g., \u201che\u201d in SCENE), and anaphora on actions (e.g., \u201crepeat step 3\u201d, \u201cbring it back\u201d in TANGRAMS).\nFor each dataset, we have a set of properties and actions. In ALCHEMY, properties are color, and amount; actions are pour, drain, and mix. In SCENE, properties are hat-color and shirt-color; actions are enter, leave, move, and trade-hats. In TANGRAMS, there is one property (shape), and actions are add, remove, and swap. In addition, we include the position property (pos) in each dataset. Each example has L = 5 utterances, each denoting some transformation of the world state.\nOur datasets are unique in that they are grounded to a world state and have rich linguistic context-dependence. In the context-dependent ATIS dataset (Dahl et al., 1994) used by Zettlemoyer and Collins (2009), logical forms of utterances depend on previous logical forms, though there is no world state and the linguistic phenomena is limited to nominal references. In the map navigation dataset (Chen and Mooney, 2011), used by Artzi and Zettlemoyer (2013), utterances only reference the current world state. Vlachos and Clark (2014) released a corpus of annotated dialogues, which has interesting linguistic contextdependence, but there is no world state.\nData collection. Our strategy was to automatically generate sequences of world states and ask Amazon Mechanical Turk (AMT) workers to describe the successive transformations. Specifically, we started with a random world state w0. For each i = 1, . . . , L, we sample a valid action and argument (e.g., pour(beaker1, beaker2)). To encourage context-dependent descriptions, we upweight recently used ac-\ntions and arguments (e.g., the next action is more like to be drain(beaker2) rather than drain(beaker5)). Next, we presented an AMT worker with statesw0, . . . , wL and asked the worker to write a description in between each pair of successive states.\nIn initial experiments, we found it rather nontrivial to obtain interesting linguistic contextdependence in these micro-domains: often a context-independent utterance such as \u201cbeaker 2\u201d is just clearer and not much longer than a possibly ambiguous \u201cit\u201d. We modified the domains to encourage more context. For example, in SCENE, we removed any visual indication of absolute position and allowed people to only move next to other people. This way, workers would say \u201cto the left of the man in the red hat\u201d rather than \u201cto position 2\u201d."}, {"heading": "3 Model", "text": "We now describe Model A, our full contextdependent semantic parsing model. First, let Z denote the set of candidate logical forms (e.g., pour(color(green),color(red))). Each logical form consists of a top-level action with arguments, which are either primitive values (green, 3, etc.), or composed via selection and superlative operations. See Table 2 for a full description. One notable feature of the logical forms is the context dependency: for example, given some context (w0, z1:4), the predicate actions[2] refers to the action of z2 and args[2][1] refers to first argument of z2.1\nWe use the term anchored logical forms (a.k.a. derivations) to refer to logical forms augmented with alignments between sub-logical forms of zi and spans of the utterance xi. In the example above, color(green) might align with \u201cgreen beaker\u201d from Figure 1; see Figure 2 for another example.\n1These special predicates play the role of references in Zettlemoyer and Collins (2009). They perform contextindependent parsing and resolve references, whereas we resolve them jointly while parsing.\nLog-linear model. We place a conditional distribution over anchored logical forms zi \u2208 Z given an utterance xi and context ci = (w0, z1:i\u22121), which consists of the initial world state w0 and the history of past logical forms z1:i\u22121. We use a standard log-linear model:\np\u03b8(zi | xi, ci) \u221d exp(\u03c6(xi, ci, zi) \u00b7 \u03b8), (1)\nwhere \u03c6 is the feature mapping and \u03b8 is the parameter vector (to be learned). Chaining these distributions together, we get a distribution over a sequence of logical forms z = (z1, . . . , zL) given the whole text x:\np\u03b8(z | x, w0) = L\u220f i=1 p\u03b8(zi | xi, (w0, z1:i\u22121)). (2)\nFeatures. Our feature mapping \u03c6 consists of two types of indicators:\n1. For each derivation, we fire features based on the structure of the logical form/spans.\n2. For each span s (e.g., \u201cgreen beaker\u201d) aligned to a sub-logical form z (e.g., color(green)), we fire features on unigrams, bigrams, and trigrams inside s conjoined with various conditions of z.\nThe exact features given in Table 3, references the first two utterances of Figure 1 and the associated logical forms below:\nx1 = \u201cPour the last green beaker into beaker 2.\u201d\nz1 = pour(argmin(color(green),pos),pos(2))\nx2 = \u201cThen into the first beaker.\u201d\nz2 = actions[1](args[1][2],pos(3)).\nWe describe the notation we use for Table 3, restricting our discussion to actions that have two or fewer arguments. Our featurization scheme, however, generalizes to an arbitrary number of arguments. Given a logical form zi, let zi.a be its action and (zi.b1, zi.b2) be its arguments (e.g., color(green)). The first and second arguments are anchored over spans [s1, t1] and [s2, t2], respectively. Each argument zi.bj has a corresponding value zi.vj (e.g., beaker1), obtained by executing zi.bj on the context ci. Finally, let j, k \u2208 {1, 2} be indices of the arguments. For example, we would label the constituent parts of z1 (defined above) as follows:\n\u2022 z1.a = pour \u2022 z1.b1 = argmin(color(green),pos) \u2022 z1.v1 = beaker3 \u2022 z1.b2 = pos(2) \u2022 z1.v2 = beaker2\nDelete the second figure. Repeat.\ndelete 2\npos(2)\nactions[1](args[1])\ndelete(pos(2))\ndelete(pos(2)) actions[1](args[1][1])\nactions[1] args[1][1]\nDelete the second figure. Repeat.\ndelete 2\npos(2)\nargs[1][1]\nactions[1]\ndelete(pos(2))\ndelete(pos(2))\nactions[1] args[1][1]\nDelete the second figure. Repeat.\ndelete 2\npos(2)\nactions[1]\ndelete(pos(2))\ndelete(pos(2))\nactions[1]\nDelete the second figure. Repeat.\ndelete 2\npos(2)\ndelete(pos(2))\ndelete(pos(2))\n(1) (2) (3) (4)\nFigure 5: Suppose we have already constructed delete(pos(2)) for \u201cDelete the second figure.\u201d Continuing, we shift the utterance \u201cRepeat\u201d. Then, we build action[1] aligned to the word \u201cRepeat.\u201d followed by args[1][1], which is unaligned. Finally, we combine the two logical forms."}, {"heading": "4 Left-to-right parsing", "text": "We describe a new parser suitable for learning from denotations in the context-dependent setting. Like a shift-reduce parser, we proceed left to right, but each shift operation advances an entire utterance rather than one word. We then sit on the utterance for a while, performing a sequence of build operations, which either combine two logical forms on the stack (like the reduce operation) or generate fresh logical forms, similar to what is done in the floating parser of Pasupat and Liang (2015).\nOur parser has two desirable properties: First, proceeding left-to-right allows us to build and score logical forms zi that depend on the world statewi\u22121, which is a function of the previous logical forms. Note that wi\u22121 is a random variable in our setting, whereas it is fixed in Zettlemoyer and Collins (2009). Second, the build operation allows us the flexibility to handle ellipsis (e.g., \u201cMix.\u201d) and anaphora on full logical forms (e.g., \u201cDo it again.\u201d), where there\u2019s not a clear alignment between the words and the predicates generated.\nThe parser transitions through a sequence of hypotheses. Each hypothesis is h = (i, b, \u03c3), where i is the index of the current utterance, where b is the number of predicates constructed on utterance xi, and \u03c3 is a stack (list) of logical forms. The stack includes both the previous logical forms z1:i\u22121 and fragments of logical forms built on the current utterance. When processing a particular hypothesis, the parser can choose to perform either the shift or build operation:\nShift: The parser moves to the next utterance by incrementing the utterance index i and resetting b, which transitions a hypothesis from (i, b, \u03c3) to (i+ 1, 0, \u03c3).\nBuild: The parser creates a new logical form by combining zero or more logical forms on the stack. There are four types of build operations:\n1. Create a predicate out of thin air (e.g., args[1][1] in Figure 5). This is useful when the utterance does not explicitly reference the arguments or action. For example, in Figure 5, we are able to generate the logical form args[1][1] in the presence of ellipsis.\n2. Create a predicate anchored to some span of the utterance (e.g., actions[1] anchored to \u201cRepeat\u201d). This allows us to do credit assignment and capture which part of the utterance explains which part of the logical form.\n3. Pop z from the stack \u03c3 and push z\u2032 onto \u03c3, where z\u2032 is created by applying a rule in Table 2 to z.\n4. Pop z, z\u2032 from the stack \u03c3 and push z\u2032\u2032 onto \u03c3, where z\u2032\u2032 is created by applying a rule in Table 2 to z, z\u2032 (e.g., actions[1](args[1] [1]) by the top-level root rule).\nThe build step stops once a maximum number of predicates B have been constructed or when the top-level rule is applied.\nWe have so far described the search space over logical forms. In practice, we keep a beam of the K hypotheses with the highest score under the current log-linear model."}, {"heading": "5 Model Projections", "text": "Model A is ambitious, as it tries to learn from scratch how each word aligns to part of the logical form. For example, when Model A parses \u201cMix it\u201d, one derivation will correctly align \u201cMix\u201d\nto mix, but others will align \u201cMix\u201d to args[1] [1], \u201cMix\u201d to pos(2), and so on (Figure 2).\nAs we do not assume a seed lexicon that could map \u201cMix\u201d to mix, the set of anchored logical forms is exponentially large. For example, parsing just the first sentence of Figure 1 would generate 1,216,140 intermediate anchored logical forms.\nHow can we reduce the search space? The key is that the space of logical forms is much smaller than the space of anchored logical forms. Even though both grow exponentially, dealing directly with logical forms allows us to generate pour without the combinatorial choice over alignments. We thus define Model B over the space of these logical forms. Figure 2 shows that the two anchored logical forms, which are treated differently in Model A are collapsed in Model B. This dramatically reduces the search space; parsing the first sentence of Figure 1 generates 7,047 intermediate logical forms.\nWe can go further and notice that many compositional logical forms reduce to the same flat logical form if we evaluate all the arguments. For example, in Figure 2, mix(args[1] [1]) and mix(pos(2)) are equivalent to mix(beaker2). We define Model C to be the space of these flat logical forms which consist of a top-level action plus primitive arguments. Using Model C, parsing the first sentence of Figure 1 generates only 349 intermediate logical forms.\nNote that in the context-dependent setting, the number of flat logical forms (Model C) still increases exponentially with the number of utterances, but it is an overwhelming improvement over Model A. Furthermore, unlike other forms of relaxation, we are still generating logical forms that can express any denotation as before. The gains from Model B to Model C hinge on the fact that in our world, the number of denotations is much smaller than the number of logical forms.\nProjecting the features. While we have defined the space over logical forms for Models B and C, we still need to define a distribution over these spaces to to complete the picture. To do this, we propose projecting the features of the log-linear model (1). Define \u03a0A\u2192B to be a map from a anchored logical form zA (e.g., mix(pos(2) ) aligned to \u201cmix\u201d) to an unanchored one zB (e.g., mix(pos(2))), and define \u03a0B\u2192C to be a map from zB to the flat logical form zC (e.g., mix(beaker2)).\nWe construct a log-linear model for Model B by constructing features \u03c6(zB) (omitting the dependence on xi, ci for convenience) based on the Model A features \u03c6(zA). Specifically, \u03c6(zB) is the component-wise maximum of \u03c6(zA) over all zA that project down to zB; \u03c6(zC) is defined similarly:\n\u03c6(zB) def = max{\u03c6(zA) : \u03a0A\u2192B(zA) = zB}, (3)\n\u03c6(zC) def = max{\u03c6(zB) : \u03a0B\u2192C(zB) = zC}. (4)\nConcretely, Model B\u2019s features include indicator features over LF conditions in Table 3 conjoined with every n-gram of the entire utterance, as there is no alignment. This is similar to the model of Pasupat and Liang (2015). Note that most of the derivation conditions (F2)\u2013(F7) already depend on properties of the denotations of the arguments, so in Model C, we can directly reason over the space of flat logical forms zC (e.g., mix(beaker2)) rather than explicitly computing the max over more complex logical forms zB (e.g., mix(color(red))).\nExpressivity. In going from Model A to Model C, we gain in computational efficiency, but we lose in modeling expressivity. For example, for \u201csecond green beaker\u201d in Figure 1, instead of predicting color(green)[2], we would have to predict beaker3, which is not easily explained by the words \u201csecond green beaker\u201d using the simple features in Table 3.\nAt the same time, we found that simple features can actually simulate some logical forms. For example, color(green) can be explained by the feature that looks at the color property of beaker3. Nailing color(green)[2], however, is not easy. Surprisingly, Model C can use a conjunction of features to express superlatives (e.g., argmax(color(red),pos)) by using one feature that places more mass on selecting objects that are red and another feature that places more mass on objects that have a greater position value."}, {"heading": "6 Experiments", "text": "Our experiments aim to explore the computationexpressivity tradeoff in going from Model A to Model B to Model C. We would expect that under the computational constraint of a finite beam size, Model A will be hurt the most, but with an infinite beam, Model A should perform better.\nWe evaluate all models on accuracy, the fraction of examples that a model predicts correctly. A predicted logical form z is deemed to be correct for an example (w0,x, wL) if the predicted logical form z executes to the correct final world state wL. We also measure the oracle accuracy, which is the fraction of examples where at least one z on the beam executes to wL. All experiments train for 6 iterations using AdaGrad (Duchi et al., 2010) and L1 regularization with a coefficient of 0.001."}, {"heading": "6.1 Real data experiments", "text": "Setup. We use a beam size of 500 within each utterance, and prune to the top 5 between utterances. For the first two iterations, Models B and C train on only the first utterance of each example (L = 1). In the remaining iterations, the models train on two utterance examples. We then evaluate on examples with L = 1, . . . , 5, which tests our models ability to extrapolate to longer texts.\nAccuracy with finite beam. We compare models B and C on the three real datasets for both L = 3 and L = 5 utterances (Model A was too expensive to use). Table 4 shows that on 5 utterance examples, the flatter Model C achieves an average accuracy of 20% higher than the more compositional Model B. Similarly, the average oracle accuracy is 39% higher. This suggests that (i) the correct logical form often falls off the beam for Model B due to a larger search space, and (ii) the expressivity of Model C is sufficient in many cases.\nOn the other hand, Model B outperforms Model C on the TANGRAMS dataset. This happens for two reasons. The TANGRAMS dataset has the smallest search space, since all of the utterances refer to objects using position only. Additionally, many utterances reference logical forms that\nModel C is unable to express, such as \u201crepeat the first step\u201d, or \u201cadd it back\u201d.\nFigure 6 shows how the models perform as the number of utterances per example varies. When the search space is small (fewer number of utterances), Model B outperforms or is competitive with Model C. However, as the search space increases (tighter computational constraints), Model C does increasingly better.\nOverall, both models perform worse as L increases, since to predict the final world state wL correctly, a model essentially needs to predict an entire sequence of logical forms z1, . . . , zL, and errors cascade. Furthermore, for larger L, the utterances tend to have richer context-dependence."}, {"heading": "6.2 Artificial data experiments", "text": "Setup. Due to the large search space, running model A on real data is impractical. In order feasibly evaluate Model A, we constructed an artificial dataset. The worlds are created using the procedure described in Section 2.2. We use a simple template to generate utterances (e.g., \u201cdrain 1 from the 2 green beaker\u201d).\nTo reduce the search space for Model A, we only allow actions (e.g., drain) to align to verbs and property values (e.g., green) to align to adjectives. Using these linguistic constraints provides a slightly optimistic assessment of Model A\u2019s performance.\nWe train on a dataset of 500 training examples and evaluate on 500 test examples. We repeat this procedure for varying beam sizes, from 40 to 260. The model only uses features (F1) through (F3).\nAccuracy under infinite beam. Since Model A is more expressive, we would expect it to be more powerful when we have no computational constraints. Figure 7 shows that this is indeed the case: When the beam size is greater than 250, all models attain an oracle of 1, and Model A outperforms Model B, which performs similarly to Model C. This is because the alignments provide a powerful signal for constructing the logical forms. Without alignments, Models B and C learn noisier features, and accuracy suffers accordingly.\nBootstrapping. Model A performs the best with unconstrained computation, and Model C performs the best with constrained computation. Is there some way to bridge the two? Even though Model C has limited expressivity, it can still learn\nto associate words like \u201cgreen\u201d with their corresponding predicate green. These should be useful for Model A too.\nTo operationalize this, we first train Model C and use the parameters to initialize model A. Then we train Model A. Figure 7 shows that although Model A and C predict different logical forms, the initialization allows Model C to A to perform well in constrained beam settings. This bootstrapping works here because Model C is a projection of Model A, and thus they share the same features."}, {"heading": "6.3 Error Analysis", "text": "We randomly sampled 20 incorrect predictions on 3 utterance examples from each of the three real datasets for Model B and Model C. We categorized each prediction error into one of the following categories: (i) logical forms falling off the beam; (ii) choosing the wrong action (e.g., mapping \u201cdrain\u201d to pour); (iii) choosing the wrong argument due to misunderstanding the description (e.g., mapping \u201cthird beaker\u201d to pos(1)); (iv) choosing the wrong action or argument due to misunderstanding of context (see Figure 8); (v) noise\nin the dataset. Table 5 shows the fraction of each error category."}, {"heading": "7 Related Work and Discussion", "text": "Context-dependent semantic parsing. Utterances can depend on either linguistic context or world state context. Zettlemoyer and Collins (2009) developed a model that handles references to previous logical forms; Artzi and Zettlemoyer (2013) developed a model that handles references to the current world state. Our system considers both types of context, handling linguistic phenomena such as ellipsis and anaphora that reference both previous world states and logical forms.\nLogical form generation. Traditional semantic parsers generate logical forms by aligning each part of the logical form to the utterance (Zelle and Mooney, 1996; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2011). In general, such systems rely on a lexicon, which can be hand-engineered, extracted (Cai and Yates, 2013; Berant et al., 2013), or automatically learned from annotated logical forms (Kwiatkowski et al., 2010; Chen, 2012).\nRecent work on learning from denotations has moved away from anchored logical forms. Pasupat and Liang (2014) and Wang et al. (2015) proposed generating logical forms without alignments, similar to our Model B. Yao et al. (2014) and Bordes et al. (2014) have explored predicting paths in a knowledge graph directly, which is similar to the flat logical forms of Model C.\nRelaxation and bootstrapping. The idea of first training a simpler model in order to work up to a more complex one has been explored other contexts. In the unsupervised learning of generative models, bootstrapping can help escape local optima and provide helpful regularization (Och and Ney, 2003; Liang et al., 2009). When it is difficult to even find one logical form that reaches the denotation, one can use the relaxation technique of Steinhardt and Liang (2015).\nRecall that projecting from Model A to C creates a more computationally tractable model at the cost of expressivity. However, this is because Model C used a linear model. One might imagine that a non-linear model would be able to recuperate some of the loss of expressivity. Indeed, Neelakantan et al. (2016) use recurrent neural networks attempt to perform logical operations.\nOne could go one step further and bypass logical forms altogether, performing all the logical reasoning in a continuous space (Bowman et al., 2014; Weston et al., 2015; Guu et al., 2015; Reed and de Freitas, 2016). This certainly avoids the combinatorial explosion of logical forms in Model A, but could also present additional optimization challenges. It would be worth exploring this avenue to completely understand the computationexpressivity tradeoff.\nReproducibility\nOur code, data, and experiments are available on CodaLab at https:// worksheets.codalab.org/worksheets/ 0xad3fc9f52f514e849b282a105b1e3f02/."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for their constructive feedback. The third author is supported by a Microsoft Research Faculty Fellowship."}], "references": [{"title": "Weakly supervised learning of semantic parsers for mapping instructions to actions", "author": ["Y. Artzi", "L. Zettlemoyer."], "venue": "Transactions of the Association for Computational Linguistics (TACL), 1:49\u201362.", "citeRegEx": "Artzi and Zettlemoyer.,? 2013", "shortCiteRegEx": "Artzi and Zettlemoyer.", "year": 2013}, {"title": "Semantic parsing on Freebase from question-answer pairs", "author": ["J. Berant", "A. Chou", "R. Frostig", "P. Liang."], "venue": "Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Berant et al\\.,? 2013", "shortCiteRegEx": "Berant et al\\.", "year": 2013}, {"title": "Question answering with subgraph embeddings", "author": ["A. Bordes", "S. Chopra", "J. Weston."], "venue": "Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Bordes et al\\.,? 2014", "shortCiteRegEx": "Bordes et al\\.", "year": 2014}, {"title": "Can recursive neural tensor networks learn logical reasoning", "author": ["S.R. Bowman", "C. Potts", "C.D. Manning"], "venue": "In International Conference on Learning Representations (ICLR)", "citeRegEx": "Bowman et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bowman et al\\.", "year": 2014}, {"title": "Large-scale semantic parsing via schema matching and lexicon extension", "author": ["Q. Cai", "A. Yates."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Cai and Yates.,? 2013", "shortCiteRegEx": "Cai and Yates.", "year": 2013}, {"title": "Learning to interpret natural language navigation instructions from observations", "author": ["D.L. Chen", "R.J. Mooney."], "venue": "Association for the Advancement of Artificial Intelligence (AAAI), pages 859\u2013865.", "citeRegEx": "Chen and Mooney.,? 2011", "shortCiteRegEx": "Chen and Mooney.", "year": 2011}, {"title": "Fast online lexicon learning for grounded language acquisition", "author": ["D.L. Chen."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Chen.,? 2012", "shortCiteRegEx": "Chen.", "year": 2012}, {"title": "Driving semantic parsing from the world\u2019s response", "author": ["J. Clarke", "D. Goldwasser", "M. Chang", "D. Roth."], "venue": "Computational Natural Language Learning (CoNLL), pages 18\u201327.", "citeRegEx": "Clarke et al\\.,? 2010", "shortCiteRegEx": "Clarke et al\\.", "year": 2010}, {"title": "Expanding the scope of the ATIS task: The ATIS-3 corpus", "author": ["D.A. Dahl", "M. Bates", "M. Brown", "W. Fisher", "K. Hunicke-Smith", "D. Pallett", "C. Pao", "A. Rudnicky", "E. Shriberg."], "venue": "Workshop on Human Language Technology, pages 43\u201348.", "citeRegEx": "Dahl et al\\.,? 1994", "shortCiteRegEx": "Dahl et al\\.", "year": 1994}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer."], "venue": "Conference on Learning Theory (COLT).", "citeRegEx": "Duchi et al\\.,? 2010", "shortCiteRegEx": "Duchi et al\\.", "year": 2010}, {"title": "Traversing knowledge graphs in vector space", "author": ["K. Guu", "J. Miller", "P. Liang."], "venue": "Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Guu et al\\.,? 2015", "shortCiteRegEx": "Guu et al\\.", "year": 2015}, {"title": "Inducing probabilistic CCG grammars from logical form with higher-order unification", "author": ["T. Kwiatkowski", "L. Zettlemoyer", "S. Goldwater", "M. Steedman."], "venue": "Empirical Methods in Natural Language Processing (EMNLP), pages 1223\u20131233.", "citeRegEx": "Kwiatkowski et al\\.,? 2010", "shortCiteRegEx": "Kwiatkowski et al\\.", "year": 2010}, {"title": "Lexical generalization in CCG grammar induction for semantic parsing", "author": ["T. Kwiatkowski", "L. Zettlemoyer", "S. Goldwater", "M. Steedman."], "venue": "Empirical Methods in Natural Language Processing (EMNLP), pages 1512\u20131523.", "citeRegEx": "Kwiatkowski et al\\.,? 2011", "shortCiteRegEx": "Kwiatkowski et al\\.", "year": 2011}, {"title": "Learning semantic correspondences with less supervision", "author": ["P. Liang", "M.I. Jordan", "D. Klein."], "venue": "Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL-IJCNLP), pages 91\u201399.", "citeRegEx": "Liang et al\\.,? 2009", "shortCiteRegEx": "Liang et al\\.", "year": 2009}, {"title": "Lambda dependency-based compositional semantics", "author": ["P. Liang."], "venue": "arXiv.", "citeRegEx": "Liang.,? 2013", "shortCiteRegEx": "Liang.", "year": 2013}, {"title": "Neural programmer: Inducing latent programs with gradient descent", "author": ["A. Neelakantan", "Q.V. Le", "I. Sutskever."], "venue": "International Conference on Learning Representations (ICLR).", "citeRegEx": "Neelakantan et al\\.,? 2016", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2016}, {"title": "A systematic comparison of various statistical alignment models", "author": ["F.J. Och", "H. Ney."], "venue": "Computational Linguistics, 29:19\u201351.", "citeRegEx": "Och and Ney.,? 2003", "shortCiteRegEx": "Och and Ney.", "year": 2003}, {"title": "Zero-shot entity extraction from web pages", "author": ["P. Pasupat", "P. Liang."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Pasupat and Liang.,? 2014", "shortCiteRegEx": "Pasupat and Liang.", "year": 2014}, {"title": "Compositional semantic parsing on semi-structured tables", "author": ["P. Pasupat", "P. Liang."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Pasupat and Liang.,? 2015", "shortCiteRegEx": "Pasupat and Liang.", "year": 2015}, {"title": "Neural programmerinterpreters", "author": ["S. Reed", "N. de Freitas."], "venue": "International Conference on Learning Representations (ICLR).", "citeRegEx": "Reed and Freitas.,? 2016", "shortCiteRegEx": "Reed and Freitas.", "year": 2016}, {"title": "Learning with relaxed supervision", "author": ["J. Steinhardt", "P. Liang."], "venue": "Advances in Neural Information Processing Systems (NIPS).", "citeRegEx": "Steinhardt and Liang.,? 2015", "shortCiteRegEx": "Steinhardt and Liang.", "year": 2015}, {"title": "A new corpus and imitation learning framework for context-dependent semantic parsing", "author": ["A. Vlachos", "S. Clark."], "venue": "Transactions of the Association for Computational Linguistics (TACL), 2:547\u2013559.", "citeRegEx": "Vlachos and Clark.,? 2014", "shortCiteRegEx": "Vlachos and Clark.", "year": 2014}, {"title": "Building a semantic parser overnight", "author": ["Y. Wang", "J. Berant", "P. Liang."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Wang et al\\.,? 2015", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Towards AI-complete question answering: A set of prerequisite toy tasks", "author": ["J. Weston", "A. Bordes", "S. Chopra", "T. Mikolov."], "venue": "arXiv.", "citeRegEx": "Weston et al\\.,? 2015", "shortCiteRegEx": "Weston et al\\.", "year": 2015}, {"title": "Learning synchronous grammars for semantic parsing with lambda calculus", "author": ["Y.W. Wong", "R.J. Mooney."], "venue": "Association for Computational Linguistics (ACL), pages 960\u2013967.", "citeRegEx": "Wong and Mooney.,? 2007", "shortCiteRegEx": "Wong and Mooney.", "year": 2007}, {"title": "Freebase QA: Information extraction or semantic parsing", "author": ["X. Yao", "J. Berant", "B. Van-Durme."], "venue": "Workshop on Semantic parsing.", "citeRegEx": "Yao et al\\.,? 2014", "shortCiteRegEx": "Yao et al\\.", "year": 2014}, {"title": "Learning to parse database queries using inductive logic programming", "author": ["M. Zelle", "R.J. Mooney."], "venue": "Association for the Advancement of Artificial Intelligence (AAAI), pages 1050\u20131055.", "citeRegEx": "Zelle and Mooney.,? 1996", "shortCiteRegEx": "Zelle and Mooney.", "year": 1996}, {"title": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars", "author": ["L.S. Zettlemoyer", "M. Collins."], "venue": "Uncertainty in Artificial Intelligence (UAI), pages 658\u2013 666.", "citeRegEx": "Zettlemoyer and Collins.,? 2005", "shortCiteRegEx": "Zettlemoyer and Collins.", "year": 2005}, {"title": "Online learning of relaxed CCG grammars for parsing to logical form", "author": ["L.S. Zettlemoyer", "M. Collins."], "venue": "Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL), pages 678\u2013687.", "citeRegEx": "Zettlemoyer and Collins.,? 2007", "shortCiteRegEx": "Zettlemoyer and Collins.", "year": 2007}, {"title": "Learning context-dependent mappings from sentences to logical form", "author": ["L.S. Zettlemoyer", "M. Collins."], "venue": "Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL-IJCNLP).", "citeRegEx": "Zettlemoyer and Collins.,? 2009", "shortCiteRegEx": "Zettlemoyer and Collins.", "year": 2009}], "referenceMentions": [{"referenceID": 26, "context": "We start with the classic paradigm of training semantic parsers that map utterances to logical forms, which are executed to produce the denotation (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010).", "startOffset": 147, "endOffset": 282}, {"referenceID": 27, "context": "We start with the classic paradigm of training semantic parsers that map utterances to logical forms, which are executed to produce the denotation (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010).", "startOffset": 147, "endOffset": 282}, {"referenceID": 24, "context": "We start with the classic paradigm of training semantic parsers that map utterances to logical forms, which are executed to produce the denotation (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010).", "startOffset": 147, "endOffset": 282}, {"referenceID": 29, "context": "We start with the classic paradigm of training semantic parsers that map utterances to logical forms, which are executed to produce the denotation (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010).", "startOffset": 147, "endOffset": 282}, {"referenceID": 11, "context": "We start with the classic paradigm of training semantic parsers that map utterances to logical forms, which are executed to produce the denotation (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010).", "startOffset": 147, "endOffset": 282}, {"referenceID": 7, "context": "More recent work learns directly from denotations (Clarke et al., 2010; Liang, 2013; Berant et al., 2013; Artzi and Zettlemoyer, 2013), but in this setting, a constant struggle is to contain the exponential explosion of possible logical forms.", "startOffset": 50, "endOffset": 134}, {"referenceID": 14, "context": "More recent work learns directly from denotations (Clarke et al., 2010; Liang, 2013; Berant et al., 2013; Artzi and Zettlemoyer, 2013), but in this setting, a constant struggle is to contain the exponential explosion of possible logical forms.", "startOffset": 50, "endOffset": 134}, {"referenceID": 1, "context": "More recent work learns directly from denotations (Clarke et al., 2010; Liang, 2013; Berant et al., 2013; Artzi and Zettlemoyer, 2013), but in this setting, a constant struggle is to contain the exponential explosion of possible logical forms.", "startOffset": 50, "endOffset": 134}, {"referenceID": 0, "context": "More recent work learns directly from denotations (Clarke et al., 2010; Liang, 2013; Berant et al., 2013; Artzi and Zettlemoyer, 2013), but in this setting, a constant struggle is to contain the exponential explosion of possible logical forms.", "startOffset": 50, "endOffset": 134}, {"referenceID": 27, "context": ", Zettlemoyer and Collins (2005)).", "startOffset": 2, "endOffset": 33}, {"referenceID": 14, "context": "This \u201cfloating\u201d approach was used in Pasupat and Liang (2015) and Wang et al.", "startOffset": 49, "endOffset": 62}, {"referenceID": 14, "context": "This \u201cfloating\u201d approach was used in Pasupat and Liang (2015) and Wang et al. (2015).", "startOffset": 49, "endOffset": 85}, {"referenceID": 24, "context": "This model is in the spirit of Yao et al. (2014) and Bordes et al.", "startOffset": 31, "endOffset": 49}, {"referenceID": 2, "context": "(2014) and Bordes et al. (2014), who directly predicted concrete paths in a knowledge graph for question answering.", "startOffset": 11, "endOffset": 32}, {"referenceID": 8, "context": "In the context-dependent ATIS dataset (Dahl et al., 1994) used by Zettlemoyer and Collins (2009), logical forms of utterances depend on previous logical forms, though there is no world state and the linguistic phenomena is limited to nominal references.", "startOffset": 38, "endOffset": 57}, {"referenceID": 5, "context": "In the map navigation dataset (Chen and Mooney, 2011), used by Artzi and Zettlemoyer (2013), utterances only reference the current world state.", "startOffset": 30, "endOffset": 53}, {"referenceID": 5, "context": "In the context-dependent ATIS dataset (Dahl et al., 1994) used by Zettlemoyer and Collins (2009), logical forms of utterances depend on previous logical forms, though there is no world state and the linguistic phenomena is limited to nominal references.", "startOffset": 39, "endOffset": 97}, {"referenceID": 0, "context": "In the map navigation dataset (Chen and Mooney, 2011), used by Artzi and Zettlemoyer (2013), utterances only reference the current world state.", "startOffset": 63, "endOffset": 92}, {"referenceID": 0, "context": "In the map navigation dataset (Chen and Mooney, 2011), used by Artzi and Zettlemoyer (2013), utterances only reference the current world state. Vlachos and Clark (2014) released a corpus of annotated dialogues, which has interesting linguistic contextdependence, but there is no world state.", "startOffset": 63, "endOffset": 169}, {"referenceID": 27, "context": "These special predicates play the role of references in Zettlemoyer and Collins (2009). They perform contextindependent parsing and resolve references, whereas we resolve them jointly while parsing.", "startOffset": 56, "endOffset": 87}, {"referenceID": 14, "context": "We then sit on the utterance for a while, performing a sequence of build operations, which either combine two logical forms on the stack (like the reduce operation) or generate fresh logical forms, similar to what is done in the floating parser of Pasupat and Liang (2015).", "startOffset": 260, "endOffset": 273}, {"referenceID": 27, "context": "Note that wi\u22121 is a random variable in our setting, whereas it is fixed in Zettlemoyer and Collins (2009). Second, the build operation allows us the flexibility to handle ellipsis (e.", "startOffset": 75, "endOffset": 106}, {"referenceID": 14, "context": "This is similar to the model of Pasupat and Liang (2015). Note that most of the derivation conditions (F2)\u2013(F7) already depend on properties of the denotations of the arguments, so in Model C, we can directly reason over the space of flat logical forms zC (e.", "startOffset": 44, "endOffset": 57}, {"referenceID": 9, "context": "All experiments train for 6 iterations using AdaGrad (Duchi et al., 2010) and L1 regularization with a coefficient of 0.", "startOffset": 53, "endOffset": 73}, {"referenceID": 26, "context": "Zettlemoyer and Collins (2009) developed a model that handles references to previous logical forms; Artzi and Zettlemoyer (2013) developed a model that handles references to the current world state.", "startOffset": 0, "endOffset": 31}, {"referenceID": 0, "context": "Zettlemoyer and Collins (2009) developed a model that handles references to previous logical forms; Artzi and Zettlemoyer (2013) developed a model that handles references to the current world state.", "startOffset": 100, "endOffset": 129}, {"referenceID": 26, "context": "Traditional semantic parsers generate logical forms by aligning each part of the logical form to the utterance (Zelle and Mooney, 1996; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2011).", "startOffset": 111, "endOffset": 215}, {"referenceID": 24, "context": "Traditional semantic parsers generate logical forms by aligning each part of the logical form to the utterance (Zelle and Mooney, 1996; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2011).", "startOffset": 111, "endOffset": 215}, {"referenceID": 28, "context": "Traditional semantic parsers generate logical forms by aligning each part of the logical form to the utterance (Zelle and Mooney, 1996; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2011).", "startOffset": 111, "endOffset": 215}, {"referenceID": 12, "context": "Traditional semantic parsers generate logical forms by aligning each part of the logical form to the utterance (Zelle and Mooney, 1996; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2011).", "startOffset": 111, "endOffset": 215}, {"referenceID": 4, "context": "In general, such systems rely on a lexicon, which can be hand-engineered, extracted (Cai and Yates, 2013; Berant et al., 2013), or automatically learned from annotated logical forms (Kwiatkowski et al.", "startOffset": 84, "endOffset": 126}, {"referenceID": 1, "context": "In general, such systems rely on a lexicon, which can be hand-engineered, extracted (Cai and Yates, 2013; Berant et al., 2013), or automatically learned from annotated logical forms (Kwiatkowski et al.", "startOffset": 84, "endOffset": 126}, {"referenceID": 11, "context": ", 2013), or automatically learned from annotated logical forms (Kwiatkowski et al., 2010; Chen, 2012).", "startOffset": 63, "endOffset": 101}, {"referenceID": 6, "context": ", 2013), or automatically learned from annotated logical forms (Kwiatkowski et al., 2010; Chen, 2012).", "startOffset": 63, "endOffset": 101}, {"referenceID": 13, "context": "Pasupat and Liang (2014) and Wang et al.", "startOffset": 12, "endOffset": 25}, {"referenceID": 13, "context": "Pasupat and Liang (2014) and Wang et al. (2015) proposed generating logical forms without alignments, similar to our Model B.", "startOffset": 12, "endOffset": 48}, {"referenceID": 13, "context": "Pasupat and Liang (2014) and Wang et al. (2015) proposed generating logical forms without alignments, similar to our Model B. Yao et al. (2014) and Bordes et al.", "startOffset": 12, "endOffset": 144}, {"referenceID": 2, "context": "(2014) and Bordes et al. (2014) have explored predicting paths in a knowledge graph directly, which is similar to the flat logical forms of Model C.", "startOffset": 11, "endOffset": 32}, {"referenceID": 16, "context": "In the unsupervised learning of generative models, bootstrapping can help escape local optima and provide helpful regularization (Och and Ney, 2003; Liang et al., 2009).", "startOffset": 129, "endOffset": 168}, {"referenceID": 13, "context": "In the unsupervised learning of generative models, bootstrapping can help escape local optima and provide helpful regularization (Och and Ney, 2003; Liang et al., 2009).", "startOffset": 129, "endOffset": 168}, {"referenceID": 13, "context": "In the unsupervised learning of generative models, bootstrapping can help escape local optima and provide helpful regularization (Och and Ney, 2003; Liang et al., 2009). When it is difficult to even find one logical form that reaches the denotation, one can use the relaxation technique of Steinhardt and Liang (2015).", "startOffset": 149, "endOffset": 318}, {"referenceID": 3, "context": "One could go one step further and bypass logical forms altogether, performing all the logical reasoning in a continuous space (Bowman et al., 2014; Weston et al., 2015; Guu et al., 2015; Reed and de Freitas, 2016).", "startOffset": 126, "endOffset": 213}, {"referenceID": 23, "context": "One could go one step further and bypass logical forms altogether, performing all the logical reasoning in a continuous space (Bowman et al., 2014; Weston et al., 2015; Guu et al., 2015; Reed and de Freitas, 2016).", "startOffset": 126, "endOffset": 213}, {"referenceID": 10, "context": "One could go one step further and bypass logical forms altogether, performing all the logical reasoning in a continuous space (Bowman et al., 2014; Weston et al., 2015; Guu et al., 2015; Reed and de Freitas, 2016).", "startOffset": 126, "endOffset": 213}, {"referenceID": 13, "context": "Indeed, Neelakantan et al. (2016) use recurrent neural networks attempt to perform logical operations.", "startOffset": 8, "endOffset": 34}], "year": 2016, "abstractText": "We consider the task of learning a contextdependent mapping from utterances to denotations. With only denotations at training time, we must search over a combinatorially large space of logical forms, which is even larger with context-dependent utterances. To cope with this challenge, we perform successive projections of the full model onto simpler models that operate over equivalence classes of logical forms. Though less expressive, we find that these simpler models are much faster and can be surprisingly effective. Moreover, they can be used to bootstrap the full model. Finally, we collected three new contextdependent semantic parsing datasets, and develop a new left-to-right parser.", "creator": "TeX"}}}