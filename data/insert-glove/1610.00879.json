{"id": "1610.00879", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Oct-2016", "title": "A Computational Approach to Automatic Prediction of Drunk Texting", "abstract": "Alcohol abuse ornamented may keynoter lead yadumi to scotswood unsociable behavior such as suborbital crime, drunk summum driving, ayimba or kippax privacy leaks. We jre introduce automatic drunk - unencrypted texting prediction as ashwini the valentino task zmed of identifying whether a krill text was superheterodyne written when romaniuk under refresh the influence waiz of alcohol. piko We birgenair experiment with feminize tweets labeled abidi using hashtags as narc distant hammarskjold supervision. Our valk classifiers h\u01b0u use 22.83 a set buteyko of queuing N - gram and m2hb stylistic features yulieski to detect drunk heartfield tweets. deq Our preceeding observations newer present 91-85 the first quantitative 11.02 evidence that portoviejo text contains ceta signals that torquata can bandier be exploited nugee to greengage detect concrete drunk - anti-hero texting.", "histories": [["v1", "Tue, 4 Oct 2016 07:34:24 GMT  (109kb,D)", "http://arxiv.org/abs/1610.00879v1", "This paper was presented at ACL-IJCNLP 2015"]], "COMMENTS": "This paper was presented at ACL-IJCNLP 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["aditya joshi", "abhijit mishra", "balamurali ar", "pushpak bhattacharyya", "mark carman"], "accepted": true, "id": "1610.00879"}, "pdf": {"name": "1610.00879.pdf", "metadata": {"source": "CRF", "title": "A Computational Approach to Automatic Prediction of Drunk-Texting", "authors": ["Aditya Joshi", "Abhijit Mishra", "Balamurali AR", "Pushpak Bhattacharyya", "Mark James Carman"], "emails": ["pb}@cse.iitb.ac.in"], "sections": [{"heading": "1 Introduction", "text": "The ubiquity of communication devices has made social media highly accessible. The content on these media reflects a user\u2019s day-to-day activities. This includes content created under the influence of alcohol. In popular culture, this has been referred to as \u2018drunk-texting\u20191. In this paper, we introduce automatic \u2018drunk-texting prediction\u2019 as a computational task. Given a tweet, the goal is to automatically identify if it was written by a drunk user. We refer to tweets written under the influence of alcohol as \u2018drunk tweets\u2019, and the opposite as \u2018sober tweets\u2019.\nA key challenge is to obtain an annotated dataset. We use hashtag-based supervision so that the authors of the tweets mention if they were drunk at the time of posting a tweet. We create three datasets by using different strategies that are related to the use of hashtags. We then present SVM-based classifiers that use N-gram and stylistic features such as capitalisation, spelling errors, etc. Through our experiments, we make subtle points related to: (a) the performance of our features, (b) how our approach compares against\n1Source: http://www.urbandictionary.com\nhuman ability to detect drunk-texting, (c) most discriminative stylistic features, and (d) an error analysis that points to future work. To the best of our knowledge, this is a first study that shows the feasibility of text-based analysis for drunk-texting prediction."}, {"heading": "2 Motivation", "text": "Past studies show the relation between alcohol abuse and unsociable behaviour such as aggression (Bushman and Cooper, 1990), crime (Carpenter, 2007), suicide attempts (Merrill et al., 1992), drunk driving (Loomis and West, 1958), and risky sexual behaviour (Bryan et al., 2005). Merrill et al. (1992) state that \u201cthose responsible for assessing cases of attempted suicide should be adept at detecting alcohol misuse\u201d. Thus, a drunk-texting prediction system can be used to identify individuals susceptible to these behaviours, or for investigative purposes after an incident.\nDrunk-texting may also cause regret. Mail Goggles2 prompts a user to solve math questions before sending an email on weekend evenings. Some Android applications3 avoid drunk-texting by blocking outgoing texts at the click of a button. However, to the best of our knowledge, these tools require a user command to begin blocking. An ongoing text-based analysis will be more helpful, especially since it offers a more natural setting by monitoring stream of social media text and not explicitly seeking user input. Thus, automatic drunktexting prediction will improve systems aimed to avoid regrettable drunk-texting. To the best of our knowledge, ours is the first study that does a quantitative analysis, in terms of prediction of the drunk state by using textual clues.\nSeveral studies have studied linguistic traits associated with emotion expression and mental\n2http://gmailblog.blogspot.in/2008/10/new-in-labs-stopsending-mail-you-later.html\n3https://play.google.com/store/apps/details?id=com.oopsapp\nar X\niv :1\n61 0.\n00 87\n9v 1\n[ cs\n.C L\n] 4\nO ct\n2 01\n6\nhealth issues, suicidal nature, criminal status, etc. (Pennebaker, 1993; Pennebaker, 1997). NLP techniques have been used in the past to address social safety and mental health issues (Resnik et al., 2013)."}, {"heading": "3 Definition and Challenges", "text": "Drunk-texting prediction is the task of classifying a text as drunk or sober. For example, a tweet \u2018Feeling buzzed. Can\u2019t remember how the evening went\u2019 must be predicted as \u2018drunk\u2019, whereas, \u2018Returned from work late today, the traffic was bad\u2019 must be predicted as \u2018sober\u2019. The challenges are:\n1. More than topic categorisation: Drunktexting prediction is similar to topic categorisation (that is, classification of documents into a set of categories such as \u2018news\u2019, \u2018sports\u2019, etc.). However, Borrill et al. (1987) show that alcohol abusers have more pronounced emotions, specifically, anger. In this respect, drunk-texting prediction lies at the confluence of topic categorisation and emotion classification.\n2. Identification of labeled examples: It is difficult to obtain a set of sober tweets. The ideal label can be possibly given only by the author. For example, whether a tweet such as \u2018I am feeling lonely tonight\u2019 is a drunk tweet is ambiguous. This is similar to sarcasm expressed as an exaggeration (for example, \u2018This is the best film ever!), where the context beyond the text needs to be considered.\n3. Precision/Recall trade-off: The goal that a drunk-texting prediction system must chase depends on the application. An application that identifies potential crimes must work with high precision, since the target population to be monitored will be large. On the other hand, when being used to avoid regrettable drunk-texting, a prediction system must produce high recall in order to ensure that a drunk message does not pass through."}, {"heading": "4 Dataset Creation", "text": "We use hashtag-based supervision to create our datasets, similar to tasks like emotion classification (Purver and Battersby, 2012). The tweets are downloaded using Twitter API (https://dev.\ntwitter.com/). We remove non-Unicode characters, and eliminate tweets that contain hyperlinks4 and also tweets that are shorter than 6 words in length. Finally, hashtags used to indicate drunk or sober tweets are removed so that they provide labels, but do not act as features. The dataset is available on request. As a result, we create three datasets, each using a different strategy for sober tweets, as follows:\n1. Dataset 1 (2435 drunk, 762 sober): We collect tweets that are marked as drunk and sober, using hashtags. Tweets containing hashtags #drunk, #drank and #imdrunk are considered to be drunk tweets, while those with #notdrunk, #imnotdrunk and #sober are considered to be sober tweets.\n2. Dataset 2 (2435 drunk, 5644 sober): The drunk tweets are downloaded using drunk hashtags, as above. The list of users who created these tweets is extracted. For the negative class, we download tweets by these users, which do not contain the hashtags that correspond to drunk tweets.\n3. Dataset H (193 drunk, 317 sober): A separate dataset is created where drunk tweets are downloaded using drunk hashtags, as above. The set of sober tweets is collected using both the approaches above. The resultant is the held-out test set Dataset-H that contains no tweets in common with Datasets 1 and 2.\nThe drunk tweets for Datasets 1 and 2 are the same. Figure 1 shows a word-cloud for these drunk tweets (with stop words and forms of the word \u2018drunk\u2019 removed), created using\n4This is a rigid criterion, but we observe that tweets with hyperlinks are likely to be promotional in nature.\nWordItOut5. The size of a word indicates its frequency. In addition to topical words such as \u2018bar\u2019, \u2018bottle\u2019 and \u2018wine\u2019, the word-cloud shows sentiment words such as \u2018love\u2019 or \u2018damn\u2019, along with profane words.\nHeuristics other than these hashtags could have been used for dataset creation. For example, timestamps were a good option to account for time at which a tweet was posted. However, this could not be used because user\u2019s local times was not available, since very few users had geolocation enabled."}, {"heading": "5 Feature Design", "text": "The complete set of features is shown in Table 1. There are two sets of features: (a) N-gram features, and (b) Stylistic features. We use unigrams and bigrams as N-gram features- considering both presence and count.\nTable 1 shows the complete set of stylistic features of our prediction system. POS ratios are a set of features that record the proportion of each POS tag in the dataset (for example, the proportion of nouns/adjectives, etc.). The POS tags and named entity mentions are obtained from NLTK (Bird, 2006). Discourse connectors are identified based on a manually created list. Spelling errors are identified using a spell checker by Aby (2014). The repeated characters feature captures a situation in which a word contains a letter that is repeated three or more times, as in the case of\n5www.worditout.com\nhapppy. Since drunk-texting is often associated with emotional expression, we also incorporate a set of sentiment-based features. These features include: count/presence of emoticons and sentiment ratio. Sentiment ratio is the proportion of positive and negative words in the tweet. To determine positive and negative words, we use the sentiment lexicon in Wilson et al. (2005). To identify a more refined set of words that correspond to the two classes, we also estimated 20 topics for the dataset by estimating an LDA model (Blei et al., 2003). We then consider top 10 words per topic, for both classes. This results in 400 LDA-specific unigrams that are then used as features."}, {"heading": "6 Evaluation", "text": "Using the two sets of features, we train SVM classifiers (Chang and Lin, 2011)6. We show the five-fold cross-validation performance of our features on Datasets 1 and 2, in Section 6.1, and on Dataset H in Section 6.2. Section 6.3 presents an error analysis. Accuracy, positive/negative precision and positive/negative recall are shown as A, PP/NP and PR/NR respectively. \u2018Drunk\u2019 forms the positive class, while \u2018Sober\u2019 forms the negative class."}, {"heading": "6.1 Performance for Datasets 1 and 2", "text": "Table 2 shows the performance for five-fold crossvalidation for Datasets 1 and 2. In case of Dataset 1, we observe that N-gram features achieve an accuracy of 85.5%. We see that our stylistic features alone exhibit degraded performance, with an accuracy of 75.6%, in the case of Dataset 1. Table 3 shows top stylistic features, when trained on the two datasets. Spelling errors, POS ratios for nouns (POS NOUN)7, length and sentiment ratios appear in both lists, in addition to LDAbased unigrams. However, negative recall reduces to a mere 3.2%. This degradation implies that our features capture a subset of drunk tweets and that there are properties of drunk tweets that may be more subtle. When both N-gram and stylistic features are used, there is negligible improvement. The accuracy for Dataset 2 increases from\n6We also repeated all experiments for Na\u0131\u0308ve Bayes. They do not perform as well as SVM, and have poor recall.\n7POS ratios for nouns, adjectives and adverbs were nearly similar in drunk and sober tweets - with the maximum difference being 0.03%\n77.9% to 78.1%. Precision/Recall metrics do not change significantly either. The best accuracy of our classifier is 78.1% for all features, and 75.6% for stylistic features. This shows that text-based clues can indeed be used for drunk-texting prediction."}, {"heading": "6.2 Performance for Held-out Dataset H", "text": "Using held-out dataset H, we evaluate how our system performs in comparison to humans. Three annotators, A1-A3, mark each tweet in the Dataset H as drunk or sober. Table 4 shows a moderate agreement between our annotators (for example, it is 0.42 for A1 and A2). Table 5 compares our classifier with humans. Our human annotators perform the task with an average accuracy of 68.8%, while our classifier (with all features) trained on Dataset 2 reaches 64%. The classifier trained on Dataset 2 is better than which is trained on Dataset 1."}, {"heading": "6.3 Error Analysis", "text": "Some categories of errors that occur are:\n1. Incorrect hashtag supervision: The tweet \u2018Can\u2019t believe I lost my bag last night, literally had everything in! Thanks god the bar man found it\u2019 was marked with\u2018#Drunk\u2019. However, this tweet is not likely to be a drunk tweet, but describes a drunk episode in retrospective. Our classifier predicts it as sober.\n2. Seemingly sober tweets: Human annotators as well as our classifier could not identify whether \u2018Will you take her on a date? But really she does like you\u2019 was drunk, although the author of the tweet had marked it so. This example also highlights the difficulty of drunk-texting prediction.\n3. Pragmatic difficulty: The tweet \u2018National dress of Ireland is one\u2019s one vomit.. my family is lovely\u2019 was correctly identified by our human annotators as a drunk tweet. This tweet contains an element of humour and topic change, but our classifier could not capture it."}, {"heading": "7 Conclusion & Future Work", "text": "In this paper, we introduce automatic drunktexting prediction as the task of predicting a tweet as drunk or sober. First, we justify the need for drunk-texting prediction as means of identifying risky social behavior arising out of alcohol abuse, and the need to build tools that avoid privacy leaks due to drunk-texting. We then highlight the challenges of drunk-texting prediction: one of the challenges is selection of negative examples (sober tweets). Using hashtag-based supervision, we create three datasets annotated with drunk or sober labels. We then present SVM-based classifiers which use two sets of features: N-gram and stylistic features. Our drunk prediction system obtains a best accuracy of 78.1%. We observe that our stylistic features add negligible value to N-gram features. We use our heldout dataset to compare how our system performs against human annotators. While human annotators achieve an accuracy of 68.8%, our system reaches reasonably close and performs with a best accuracy of 64%.\nOur analysis of the task and experimental findings make a case for drunk-texting prediction as a useful and feasible NLP application."}], "references": [{"title": "Nltk: the natural language toolkit", "author": ["Steven Bird"], "venue": "In Proceedings of the COLING/ACL on Interactive presentation sessions,", "citeRegEx": "Bird.,? \\Q2006\\E", "shortCiteRegEx": "Bird.", "year": 2006}, {"title": "Latent dirichlet allocation", "author": ["Blei et al.2003] David M Blei", "Andrew Y Ng", "Michael I Jordan"], "venue": null, "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "The influence of alcohol on judgement of facial expressions of emotion", "author": ["Bernard K Rosen", "Angela B Summerfield"], "venue": "British Journal of Medical Psychology", "citeRegEx": "Borrill et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Borrill et al\\.", "year": 1987}, {"title": "Condom use among high-risk adolescents: testing the influence of alcohol use on the relationship of cognitive correlates", "author": ["Bryan et al.2005] Angela Bryan", "Courtney A Rocheleau", "Reuben N Robbins", "Kent E Hutchinson"], "venue": null, "citeRegEx": "Bryan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Bryan et al\\.", "year": 2005}, {"title": "Effects of alcohol on human aggression: An intergrative research review", "author": ["Bushman", "Cooper1990] Brad J Bushman", "Harris M Cooper"], "venue": "Psychological bulletin,", "citeRegEx": "Bushman et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Bushman et al\\.", "year": 1990}, {"title": "Heavy alcohol use and crime: Evidence from underage drunk-driving laws", "author": ["Christopher Carpenter"], "venue": "Journal of Law and Economics,", "citeRegEx": "Carpenter.,? \\Q2007\\E", "shortCiteRegEx": "Carpenter.", "year": 2007}, {"title": "Libsvm: a library for support vector machines", "author": ["Chang", "Lin2011] Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),", "citeRegEx": "Chang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2011}, {"title": "The influence of alcohol on automobile driving ability: An experimental study for the evaluation of certain medicological aspects", "author": ["Loomis", "West1958] Ted A Loomis", "TC West"], "venue": "Quarterly journal of studies on alcohol,", "citeRegEx": "Loomis et al\\.,? \\Q1958\\E", "shortCiteRegEx": "Loomis et al\\.", "year": 1958}, {"title": "Alcohol and attempted suicide", "author": ["Merrill et al.1992] John Merrill", "GABRIELLE MILKER", "John Owens", "Allister Vale"], "venue": "British journal of addiction,", "citeRegEx": "Merrill et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Merrill et al\\.", "year": 1992}, {"title": "Putting stress into words: Health, linguistic, and therapeutic implications", "author": ["James W Pennebaker"], "venue": "Behaviour research and therapy,", "citeRegEx": "Pennebaker.,? \\Q1993\\E", "shortCiteRegEx": "Pennebaker.", "year": 1993}, {"title": "Writing about emotional experiences as a therapeutic process", "author": ["James W Pennebaker"], "venue": "Psychological science,", "citeRegEx": "Pennebaker.,? \\Q1997\\E", "shortCiteRegEx": "Pennebaker.", "year": 1997}, {"title": "Experimenting with distant supervision for emotion classification", "author": ["Purver", "Battersby2012] Matthew Purver", "Stuart Battersby"], "venue": "In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Purver et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Purver et al\\.", "year": 2012}, {"title": "Using topic modeling to improve prediction of neuroticism and depression", "author": ["Resnik et al.2013] Philip Resnik", "Anderson Garron", "Rebecca Resnik"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural,", "citeRegEx": "Resnik et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Resnik et al\\.", "year": 2013}, {"title": "Recognizing contextual polarity in phrase-level sentiment analysis. In Proceedings of the conference on human language technology and empirical methods in natural language", "author": ["Janyce Wiebe", "Paul Hoffmann"], "venue": null, "citeRegEx": "Wilson et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 5, "context": "Past studies show the relation between alcohol abuse and unsociable behaviour such as aggression (Bushman and Cooper, 1990), crime (Carpenter, 2007), suicide attempts (Merrill et al.", "startOffset": 131, "endOffset": 148}, {"referenceID": 8, "context": "Past studies show the relation between alcohol abuse and unsociable behaviour such as aggression (Bushman and Cooper, 1990), crime (Carpenter, 2007), suicide attempts (Merrill et al., 1992), drunk driving (Loomis and West, 1958), and risky sexual behaviour (Bryan et al.", "startOffset": 167, "endOffset": 189}, {"referenceID": 3, "context": ", 1992), drunk driving (Loomis and West, 1958), and risky sexual behaviour (Bryan et al., 2005).", "startOffset": 75, "endOffset": 95}, {"referenceID": 3, "context": ", 1992), drunk driving (Loomis and West, 1958), and risky sexual behaviour (Bryan et al., 2005). Merrill et al. (1992) state that \u201cthose responsible for assess-", "startOffset": 76, "endOffset": 119}, {"referenceID": 9, "context": "(Pennebaker, 1993; Pennebaker, 1997).", "startOffset": 0, "endOffset": 36}, {"referenceID": 10, "context": "(Pennebaker, 1993; Pennebaker, 1997).", "startOffset": 0, "endOffset": 36}, {"referenceID": 12, "context": "NLP techniques have been used in the past to address social safety and mental health issues (Resnik et al., 2013).", "startOffset": 92, "endOffset": 113}, {"referenceID": 2, "context": "However, Borrill et al. (1987) show that alcohol abusers have more pronounced emotions, specifically, anger.", "startOffset": 9, "endOffset": 31}, {"referenceID": 0, "context": "The POS tags and named entity mentions are obtained from NLTK (Bird, 2006).", "startOffset": 62, "endOffset": 74}, {"referenceID": 0, "context": "The POS tags and named entity mentions are obtained from NLTK (Bird, 2006). Discourse connectors are identified based on a manually created list. Spelling errors are identified using a spell checker by Aby (2014). The repeated characters feature captures a situation in which a word contains a letter that is repeated three or more times, as in the case of", "startOffset": 63, "endOffset": 213}, {"referenceID": 1, "context": "To identify a more refined set of words that correspond to the two classes, we also estimated 20 topics for the dataset by estimating an LDA model (Blei et al., 2003).", "startOffset": 147, "endOffset": 166}, {"referenceID": 12, "context": "To determine positive and negative words, we use the sentiment lexicon in Wilson et al. (2005). To identify a more refined set of words that correspond to the two classes, we also estimated 20 topics for the dataset by estimating an LDA model (Blei et al.", "startOffset": 74, "endOffset": 95}], "year": 2016, "abstractText": "Alcohol abuse may lead to unsociable behavior such as crime, drunk driving, or privacy leaks. We introduce automatic drunk-texting prediction as the task of identifying whether a text was written when under the influence of alcohol. We experiment with tweets labeled using hashtags as distant supervision. Our classifiers use a set of N-gram and stylistic features to detect drunk tweets. Our observations present the first quantitative evidence that text contains signals that can be exploited to detect drunk-texting.", "creator": "LaTeX with hyperref package"}}}