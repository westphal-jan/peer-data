{"id": "1610.03090", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Oct-2016", "title": "Dynamic Metric Learning from Pairwise Comparisons", "abstract": "feuilles Recent shembe work in lehto distance metric glassmaker learning asuu has hean focused bhawanipur on learning transformations bluefields of totalfinaelf data bulldozes that eustace best sweetnorthernsaint align unusal with nonfans specified pairwise nepenthes similarity dolichopodidae and blonsky dissimilarity poynter constraints, often supplied by wladika a human 17.52 observer. The learned transformations lead rockumentary to 82.2 improved retrieval, 82-ball classification, and clustering algorithms due a.g. to ksm the mcglynn better adapted leigu distance 123rd or 1640s similarity measures. acilius Here, menconi we address the problem of hayt learning akmatbayev these transformations kgk when the underlying constraint crosscourt generation process is 1.45 nonstationary. This wences nonstationarity can gosselies be motoric due to changes volkers in either taitt the ground - truth 1911-1912 clustering used to santonio generate constraints or changes tints in oke the feature nauta subspaces in which the penngrove class 21.6 structure is apparent. We propose mafiosos Online vice-versa Convex storberget Ensemble turfgrass StrongLy dadyal Adaptive Dynamic lanxade Learning (hajiri OCELAD ), trpv1 a rootkit general adaptive, contin online kazue approach educology for learning laundresses and masaga tracking optimal metrics as they change over hpr time front-to-back that is highly microhabitat robust pronotum to encroached a cfinley variety of nonstationary behaviors in vend\u00e9en the changing unamuno metric. stander We consolidating apply the OCELAD 327-vote framework arang to heymodesti an earthforce ensemble m.c.c. of online prabal learners. Specifically, manasa we create a lumpini retro - accorded initialized composite pena objective mirror descent (COMID) 7,645 ensemble (RICE) tiwana consisting keeffe of lansingburgh a reposed set mindanao of 1,035 parallel 37.09 COMID 3.85 learners rust-colored with marie-france different mirex learning rates, chi-chi demonstrate RICE - reconcilable OCELAD replicant on augstums both real \u017ceromski and uza synthetic advisors data tabitha sets overlayed and show carmignani significant sauli performance improvements relative atrush to previously bonesteel proposed flipkens batch comfrey and online sondhi distance metric paolina learning algorithms.", "histories": [["v1", "Mon, 10 Oct 2016 20:39:25 GMT  (1870kb,D)", "http://arxiv.org/abs/1610.03090v1", "to appear Allerton 2016. arXiv admin note: substantial text overlap witharXiv:1603.03678"]], "COMMENTS": "to appear Allerton 2016. arXiv admin note: substantial text overlap witharXiv:1603.03678", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["kristjan greenewald", "stephen kelley", "alfred hero iii"], "accepted": false, "id": "1610.03090"}, "pdf": {"name": "1610.03090.pdf", "metadata": {"source": "CRF", "title": "Dynamic metric learning from pairwise comparisons", "authors": ["Kristjan Greenewald"], "emails": [], "sections": [{"heading": null, "text": "I. INTRODUCTION\nTHe effectiveness of many machine learning and datamining algorithms depends on an appropriate measure of pairwise distance between data points that accurately reflects the learning task, e.g., prediction, clustering or classification. The kNN classifier, K-means clustering, and the LaplacianSVM semi-supervised classifier are examples of such distancebased machine learning algorithms. In settings where there is clean, appropriately-scaled spherical Gaussian data, standard Euclidean distance can be utilized. However, when the data is heavy tailed, multimodal, or contaminated by outliers, observation noise, or irrelevant or replicated features, use of Euclidean inter-point distance can be problematic, leading to bias or loss of discriminative power.\nTo reduce bias and loss of discriminative power of distancebased machine learning algorithms, data-driven approaches for optimizing the distance metric have been proposed. These methodologies, generally taking the form of dimensionality reduction or data \u201cwhitening\u201d, aim to utilize the data itself to learn a transformation of the data that embeds it into a space where Euclidean distance is appropriate. Examples of such techniques include Principal Component Analysis [1], Multidimensional Scaling [2], covariance estimation [2], [1], and manifold learning [3]. Such unsupervised methods do not exploit human input on the distance metric, and they overly rely on prior assumptions, e.g., local linearity or smoothness.\nK. Greenewald and A. Hero III are with the Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA. This work was partially supported by US Army Research Office grant W911NF-15-1-0479.\nIn distance metric learning one seeks to learn transformations of the data associated with a distance metric that is well matched to a particular task specified by the user. Point labels or constraints indicating point similarity or dissimilarity are used to learn a transformation of the data such that similar points are \u201cclose\u201d to one another and dissimilar points are distant in the transformed space. Learning distance metrics in this manner allows a more precise notion of distance or similarity to be defined that is better related to the task at hand.\nMany supervised and semi-supervised distance metric learning approaches have been developed [4]. This includes online algorithms [5] with regret guarantees for situations where similarity constraints are received sequentially.\nThis paper proposes a new distance metric tracking method that is applicable to the non-stationary time varying case of distance metric drift and has provably strongly adaptive tracking performance.\nSpecifically, we suppose the underlying ground-truth (or optimal) distance metric from which constraints are generated is evolving over time, in an unknown and potentially nonstationary way. We propose a strongly adaptive, online approach to track the underlying metric as the constraints are received. We introduce a framework called Online Convex Ensemble StrongLy Adaptive Dynamic Learning (OCELAD), which at every time step evaluates the recent performance of and optimally combines the outputs of an ensemble of online learners, each operating under a different drift-rate assumption. We prove strong bounds on the dynamic regret of every subinterval, guaranteeing strong adaptivity and robustness to nonstationary metric drift such as discrete shifts, slow drift with a widely-varying drift rate, and all combinations thereof. Applying OCELAD to the problem of nonstationary metric learning, we find that it gives excellent robustness and low regret when subjected to all forms of nonstationarity."}, {"heading": "A. Related Work", "text": "Linear Discriminant Analysis (LDA) and Principal Component Analysis (PCA) are classic examples of using linear transformations for projecting data into more interpretable low dimensional spaces. Unsupervised PCA seeks to identify a set of axes that best explain the variance contained in the data. LDA takes a supervised approach, minimizing the intra-class variance and maximizing the inter-class variance given class labeled data points.\nMuch of the recent work in Distance Metric Learning has focused on learning Mahalanobis distances on the basis of pairwise similarity/dissimilarity constraints. These methods have the same goals as LDA; pairs of points labeled \u201csimilar\u201d should be close to one another while pairs labeled \u201cdissimilar\u201d\nar X\niv :1\n61 0.\n03 09\n0v 1\n[ cs\n.L G\n] 1\n0 O\nct 2\n01 6\n2 should be distant. MMC [6], a method for identifying a Mahalanobis metric for clustering with side information, uses semidefinite programming to identify a metric that maximizes the sum of distances between points labeled with different classes subject to the constraint that the sum of distances between all points with similar labels be less than some constant.\nLarge Margin Nearest Neighbor (LMNN) [7] similarly uses semidefinite programming to identify a Mahalanobis distance. In this setting, the algorithm minimizes the sum of distances between a given point and its similarly labeled neighbors while forcing differently labeled neighbors outside of its neighborhood. This method has been shown to be computationally efficient [8] and, in contrast to the similarly motivated Neighborhood Component Analysis [9], is guaranteed to converge to a globally optimal solution. Information Theoretic Metric Learning (ITML) [10] is another popular Distance Metric Learning technique. ITML minimizes the KullbackLiebler divergence between an initial guess of the matrix that parameterizes the Mahalanobis distance and a solution that satisfies a set of constraints. For surveys of the vast metric learning literature, see [4], [11], [12].\nIn a dynamic environment, it is necessary to track the changing metric at different times, computing a sequence of estimates of the metric, and to be able to compute those estimates online. Online learning [13] meets these criteria by efficiently updating the estimate every time a new data point is obtained, instead of solving an objective function formed from the entire dataset. Many online learning methods have regret guarantees, that is, the loss in performance relative to a batch method is provably small [13], [14]. In practice, however, the performance of an online learning method is strongly influenced by the learning rate, which may need to vary over time in a dynamic environment [15], [16], [17], especially one with changing drift rates.\nAdaptive online learning methods attempt to address the learning rate problem by continuously updating the learning rate as new observations become available. For learning static parameters, AdaGrad-style methods [16], [17] perform gradient descent steps with the step size adapted based on the magnitude of recent gradients. Follow the regularized leader (FTRL) type algorithms adapt the regularization to the observations [18]. Recently, a method called Strongly Adaptive Online Learning (SAOL) has been proposed for learning parameters undergoing K discrete changes when the loss function is bounded between 0 and 1. SAOL maintains several learners with different learning rates and randomly selects the best one based on recent performance [15]. Several of these adaptive methods have provable regret bounds [18], [19], [20]. These typically guarantee low total regret (i.e. regret from time 0 to time T ) at every time [18]. SAOL, on the other hand, attempts to have low static regret on every subinterval, as well as low regret overall [15]. This allows tracking of discrete changes, but not slow drift. Our work improves upon the capabilities of SAOL by allowing for unbounded loss functions, using a convex combination of the ensemble instead of simple random selection, and providing guaranteed low regret when all forms of nonstationarity occur, not just discrete\nshifts. All of these additional capabilities are shown in the results to be critical for good metric learning performance.\nThe remainder of this paper is structured as follows. In Section II we formalize the time varying distance metric tracking problem, and section III presents the basic COMID online learner and our Retro-Initialized COMID Ensemble (RICE) of learners with dyadically scaled learning rates. Section IV presents our OCELAD algorithm, a method of adaptively combining learners with different learning rates. Strongly adaptive bounds on the dynamic regret of OCELAD and RICE-OCELAD are presented in Section V, and results on both synthetic data and a text review dataset are presented in Section VI. Section VII concludes the paper."}, {"heading": "II. NONSTATIONARY METRIC LEARNING", "text": "Metric learning seeks to learn a metric that encourages data points marked as similar to be close and data points marked as different to be far apart. The time-varying Mahalanobis distance at time t is parameterized by Mt as\nd2Mt(x, z) = (x\u2212 z) TMt(x\u2212 z) (1)\nwhere Mt \u2208 Rn\u00d7n 0. Suppose a temporal sequence of similarity constraints are given, where each constraint is the triplet (xt, zt, yt), xt and zt are data points in Rn, and the label yt = +1 if the points xt, zt are similar at time t and yt = \u22121 if they are dissimilar.\nFollowing [5], we introduce the following margin based constraints:\nt|yt = 1 : d2Mt(xt, zt) \u2264 \u00b5\u2212 1; (2) t|yt = \u22121 : d2Mt(xt, zt) \u2265 \u00b5+ 1,\nwhere \u00b5 is a threshold that controls the margin between similar and dissimilar points. A diagram illustrating these constraints and their effect is shown in Figure 1. These constraints are softened by penalizing violation of the constraints with a convex loss function `. This gives a loss function\nL({Mt, \u00b5}) = 1\nT T\u2211 t=1 `(yt(\u00b5\u2212 uTt Mtut)) + \u03c1r(Mt) (3)\n= 1\nT T\u2211 t=1 ft(Mt, \u00b5),\nwhere ut = xt\u2212zt, r is the regularizer and \u03c1 the regularization parameter. Kunapuli and Shavlik [5] propose using nuclear norm regularization (r(M) = \u2016M\u2016\u2217) to encourage projection of the data onto a low dimensional subspace (feature selection/dimensionality reduction), and we have also had success with the elementwise L1 norm (r(M) = \u2016vec(M)\u20161). In what follows, we develop an adaptive online method to minimize the loss subject to nonstationary smoothness constraints on the sequence of metric estimates Mt."}, {"heading": "III. RETRO-INITIALIZED COMID ENSEMBLE (RICE)", "text": "Viewing the acquisition of new data points as stochastic realizations of the underlying distribution [5] suggests the use of composite objective stochastic mirror descent techniques\n3\n(COMID). For convenience, we set `t(Mt, \u00b5t) = `(yt(\u00b5 \u2212 uTt Mtut)).\nFor the loss (3) and learning rate \u03b7t, COMID [14] gives\nM\u0302t+1 = arg min M 0 B\u03c8(M, M\u0302t) (4)\n+ \u03b7t\u3008\u2207M `t(M\u0302t, \u00b5\u0302t),M\u2212 M\u0302t\u3009+ \u03b7t\u03c1\u2016M\u2016\u2217 \u00b5\u0302t+1 = arg min\n\u00b5\u22651 B\u03c8(\u00b5, \u00b5\u0302t) + \u03b7t\u2207\u00b5`t(M\u0302t, \u00b5\u0302t)\u2032(\u00b5\u2212 \u00b5\u0302t),\nwhere B\u03c8 is any Bregman divergence. In [5] a closedform algorithm for solving the minimization in (4) with r(M) = \u2016M\u2016\u2217 is developed for a variety of common losses and Bregman divergences, involving rank one updates and eigenvalue shrinkage.\nThe output of COMID depends strongly on the choice of \u03b7t. Critically, the optimal learning rate \u03b7t depends on the rate of change of Mt [21], and thus will need to change with time to adapt to nonstationary drift. Choosing an optimal sequence for \u03b7t is clearly not practical in an online setting with nonstationary drift, since the drift rate is changing. We thus propose to maintain an ensemble of learners with a range of \u03b7t values, whose output we will adaptively combine for optimal nonstationary performance. If the range of \u03b7t is diverse enough, one of the learners in the ensemble should have good performance on every interval. Critically, the optimal learner in the ensemble may vary widely with time, since the drift rate and hence the optimal learning rate changes in time. For example, if a large discrete change occurs, the fast learners are optimal at first, followed by increasingly slow learners as the estimate of the new value improves. In other words, the optimal approach is fast reaction followed by increasing refinement, in a manner consistent with the attractive O(1/ \u221a t) decay of the learning rate of optimal nonadaptive algorithms. Define a set I of intervals I = [tI1, tI2] such that the lengths |I| of the intervals are proportional to powers of two, i.e. |I| = I02\nj , j = 0, . . . , with an arrangement that is a dyadic partition of the temporal axis, as in [15]. The first interval of length |I| starts at t = |I| (see Figure 2), and additional intervals of length |I| exist such that the rest of time is covered.\nEvery interval I is associated with a base COMID learner that operates on that interval. Each learner (4) has a constant\nlearning rate proportional to the inverse square of the length of the interval, i.e. \u03b7t(I) = \u03b70/ \u221a |I|. Each learner (besides the coarsest) at level j (|I| = I02j) is initialized to the last estimate of the next coarsest learner (level j\u22121) (see Figure 2). This strategy is equivalent to \u201cbackdating\u201d the interval learners so as to ensure appropriate convergence has occurred before the interval of interest is reached, and is effectively a quantized square root decay of the learning rate. We call our method of forming an ensemble of COMID learners on dyadically nested intervals the Retro-Initialized COMID Ensemble, or RICE, and summarize it in Figure 2.\nAt a given time t, a set ACT(t) \u2286 I of floor(log2 t) intervals/COMID learners are active, running in parallel. Because the metric being learned is changing with time, learners designed for low regret at different scales (drift rates) will have different performance (analogous to the classical bias/variance tradeoff). In other words, there is a scale Iopt optimal at a given time.\nTo adaptively select and fuse the outputs of the ensemble, we introduce Online Convex Ensemble StrongLy Adaptive Dynamic Learning (OCELAD), a method that accepts an ensemble of black-box learners and uses recent history to select the optimal one at each time."}, {"heading": "IV. OCELAD", "text": "To maintain generality, in this section we assume the series of random loss functions of the form `t(\u03b8t) where \u03b8t is the time-varying unknown parameters. We assume that an ensemble B of online learners is provided on the dyadic interval set I, each optimized for the appropriate scale. To select the appropriate scale, we compute weights wt(I) that are updated based on the learner\u2019s recent estimated regret. The weight update we use is inspired by the multiplicative weight (MW) literature [22], modified to allow for unbounded loss functions. At each step, we rescale the observed losses so they lie between -1 and 1, allowing for maximal selection ability\n4\nand preventing negative weights.\nrt(I) = (\u2211 I wt(I)\u2211 I wt(I) `t(\u03b8t(I)) ) \u2212 `t(\u03b8t(I)) (5)\nwt+1(I) =wt(I) ( 1 + \u03b7I\nrt(I)\nmaxI\u2208ACT(t) |rt(I)|\n) , \u2200t \u2208 I.\nThese hold for all I \u2208 I, where \u03b7I = min{1/2, 1/ \u221a |I|}, Mt(I), \u00b5t(I) are the outputs at time t of the learner on interval I , and rt(I) is called the estimated regret of the learner on interval I at time t. The initial value of w(I) is \u03b7I . Essentially, this is highly weighting low loss learners and lowly weighting high loss learners.\nFor any given time t, the outputs of the learners of interval I \u2208 ACT(t) are combined to form the weighted ensemble estimate\n\u03b8\u0302t =\n\u2211 I\u2208ACT(t) wt(I)\u03b8t(I)\u2211\nI\u2208ACT(t) wt(I) (6)\nThe weighted average of the ensemble is reasonable here due to our use of a convex loss function (proven in the next section), as opposed to the possibly non-convex losses of [22], necessitating a randomized selection approach. OCELAD is summarized in Algorithm 1, and the joint RICE-OCELAD approach as applied to metric learning of {Mt, \u00b5t} is shown in Algorithm 2.\nAlgorithm 1 Online Convex Ensemble Strongly Adaptive Dynamic Learning (OCELAD)\n1: Provide dyadic ensemble of online learners B. 2: Initialize weight: w1(I). 3: for t = 1 to T do 4: Observe loss function `t(\u00b7) and update B ensemble. 5: Obtain |ACT(t)| estimates \u03b8t(I) from the B ensemble.\n6: Compute weighted ensemble average \u03b8\u0302t via (6) and set as estimate. 7: Update weights wt+1(I) via (5). 8: end for 9: Return {\u03b8\u0302t}.\nAlgorithm 2 RICE-OCELAD for Nonstationary Metric Learning\n1: Initialize weight: w1(I) 2: for t = 1 to T do 3: Obtain constraint (xt, zt, yt), compute loss function `t,c(Mt, \u00b5t). 4: Initialize new learner in RICE if needed. New learner\nat scale j > 0: initialize to the last estimate of learner at scale j \u2212 1.\n5: COMID update Mt(I), \u00b5t(I) using (4) for all active learners in RICE ensemble. 6: Compute\nM\u0302t \u2190 \u2211 I\u2208ACT(t) wt(I)Mt(I)\u2211\nI\u2208ACT(t) wt(I) \u00b5\u0302t \u2190 \u2211 I\u2208ACT(t) wt(I)\u00b5t(I)\u2211\nI\u2208ACT(t) wt(I) .\n7: for I \u2208 ACT(t) do 8: Compute estimated regret rt(I) and update weights according to (5) with \u03b8t(I) = {Mt(I), \u00b5t(I)}. 9: end for\n10: end for 11: Return {M\u0302t, \u00b5\u0302t}."}, {"heading": "V. STRONGLY ADAPTIVE DYNAMIC REGRET", "text": "The standard static regret is defined as\nRB,static(I) = \u2211 t\u2208I ft(\u03b8\u0302t)\u2212min \u03b8\u2208\u0398 \u2211 t\u2208I ft(\u03b8). (7)\nwhere ft(\u03b8t) is a loss with parameter \u03b8t. Since in our case the optimal parameter value \u03b8t is changing, the static regret of an algorithm B on an interval I is not useful. Instead, let w = {\u03b8t}t\u2208[0,T ] be an arbitrary sequence of parameters. Then, the dynamic regret of an algorithm B relative to a comparator sequence w on the interval I is defined as\nRB,w(I) = \u2211 t\u2208I ft(\u03b8\u0302t)\u2212 \u2211 t\u2208I ft(\u03b8t), (8)\nwhere \u03b8\u0302t are generated by B. This allows for a dynamically changing estimate.\n5 In [21] the authors derive dynamic regret bounds that hold over all possible sequences w such that \u2211 t\u2208I \u2016\u03b8t+1\u2212\u03b8t\u2016 \u2264 \u03b3, i.e. bounding the total amount of variation in the estimated parameter. Without this temporal regularization, minimizing the loss would cause \u03b8t to grossly overfit. In this sense, setting the comparator sequence w to the \u201cground truth sequence\u201d or \u201cbatch optimal sequence\u201d both provide meaningful intuitive bounds.\nStrongly adaptive regret bounds [15] have claimed that static regret is low on every subinterval, instead of only low in the aggregate. We use the notion of dynamic regret to introduce strongly adaptive dynamic regret bounds, proving that dynamic regret is low on every subinterval I \u2286 [0, T ] simultaneously. In a later work, we prove the following. Suppose there are a sequence of random loss functions `t(\u03b8t). The goal is to estimate a sequence \u03b8\u0302t that minimizes the dynamic regret.\nTheorem 1. Let w = {\u03b81, . . . , \u03b8T } be an arbitrary sequence of parameters and define \u03b3w(I) = \u2211 q\u2264t<s \u2016\u03b8t+1 \u2212 \u03b8t\u2016 as a function of w and an interval I = [q, s]. Choose an ensemble of learners B such that given an interval I the learner BI creates an output sequence \u03b8t(I) satisfying the dynamic regret bound\nRBI ,w(I) \u2264 C(1 + \u03b3w(I)) \u221a |I| (9)\nfor some constant C > 0. Then the strongly adaptive dynamic learner OCELADB using B as the ensemble creates an estimation sequence \u03b8\u0302t satisfying\nROCELADB,w(I) \u2264 8C(1 + \u03b3w(I)) \u221a |I|+ 40 log(s+ 1) \u221a |I|\non every interval I = [q, s] \u2286 [0, T ].\nIn a dynamic setting, bounds of this type are particularly desirable because they allow for changing drift rate and guarantee quick recovery from discrete changes. For instance, suppose K discrete switches (large parameter changes or changes in drift rate) occur at times ti satisfying 0 = t0 < t1 < \u00b7 \u00b7 \u00b7 < tK = T . Then since \u2211K i=1 \u221a |ti\u22121 \u2212 ti| \u2264 \u221a KT , this implies that the total expected dynamic regret on [0, T ] remains low (O( \u221a KT )), while simultaneously guaranteeing that an appropriate learning rate is achieved on each subinterval [ti, ti+1].\nNow, reconsider the dynamic metric learning problem of Section II. It is reasonable to assume that the transformed distance between any two points is bounded, implying \u2016M\u2016 \u2264 c\u2032 and that `t(Mt, \u00b5t) \u2264 k = `(c\u2032maxt \u2016xt\u2212 zt\u201622). Thus the loss (and the gradient) are bounded. We can then show the COMID learners in the RICE ensemble have low dynamic regret. The proof of the following result is omitted for lack of space, and derives from a result in [21].\nCorollary 1 (Dynamic Regret: Metric Learning COMID). Let the sequence M\u0302t, \u00b5\u0302t be generated by (4), and let w = {Mt}Tt=1 be an arbitrary sequence with \u2016Mt\u2016 \u2264 c. Then using \u03b7t+1 \u2264 \u03b7t gives\nRw([0, T ]) \u2264 Dmax \u03b7T+1 + 4\u03c6max \u03b7T \u03b3 + G2` 2\u03c3 T\u2211 t=1 \u03b7t (10)\nand setting \u03b7t = \u03b70/ \u221a T ,\nRw([0, T ]) (11)\n\u2264 \u221a T\n( Dmax + 4\u03c6max( \u2211 t \u2016Mt+1 \u2212Mt\u2016F ) \u03b70 + \u03b70G 2 ` 2\u03c3 ) =O ( \u221a T [ 1 +\nT\u2211 t=1 \u2016Mt+1 \u2212Mt\u2016F\n]) . (12)\nSince the COMID learners have low dynamic regret, we can use OCELAD on the RICE ensemble.\nTheorem 2 (RICE-OCELAD Strongly Adaptive Dynamic Regret). Let w = {Mt}t\u2208[0,T ] be any sequence of metrics with \u2016Mt\u2016 \u2264 c on the interval [0, T ], and define \u03b3w(I) =\u2211 t\u2208I \u2016Mt+1 \u2212 Mt\u2016. Let B be the RICE ensemble with\n\u03b7t(I) = \u03b70/ \u221a |I|. Then the RICE-OCELAD metric learning algorithm (Algorithm 2) satisfies\nROCELAD,w(I) \u2264 (13) 4 21/2 \u2212 1 C(1 + \u03b3w(I)) \u221a |I|+ 40 log(s+ 1) \u221a |I|,\nfor every subinterval I = [q, s] \u2286 [0, T ] simultaneously. C is a constant, and the expectation is with respect to the random output of the algorithm."}, {"heading": "VI. RESULTS", "text": ""}, {"heading": "A. Synthetic Data", "text": "We run our metric learning algorithms on a synthetic dataset undergoing different types of simulated metric drift. We create a synthetic 2000 point dataset with 2 independent 50-20-30% clusterings (A and B) in disjoint 3-dimensional subspaces of R25. The clusterings are formed as 3-D Gaussian blobs, and the remaining 19-dimensional subspace is filled with iid Gaussian noise.\nWe create a scenario exhibiting nonstationary drift, combining continuous drifts and shifts between the two clusterings (A and B). To simulate continuous drift, at each time step we perform a small random rotation of the dataset. The drift profile is shown in 3. For the first interval, partition A is used and the dataset is static, no drift occurs. Then, the partition is changed to B, followed by an interval of first moderate, then fast, and then moderate drift. Finally, the partition reverts back to A, followed by slow drift.\nWe generate a series of T constraints from random pairs of points in the dataset, incorporating the simulated drift, running each experiment with 3000 random trials. For each experiment conducted in this section, we evaluate performance using two metrics. We plot the K-nearest neighbor error rate, using the learned embedding at each time point, averaging over all trials. We quantify the clustering performance by plotting the empirical probability that the normalized mutual information (NMI) of the K-means clustering of the unlabeled data points in the learned embedding at each time point exceeds 0.8 (out of a possible 1). We believe clustering NMI, rather than k-NN performance, is a more realistic indicator of metric learning performance, at least in the case where finding a relevant embedding is the primary goal.\nIn our results, we consider RICE-OCELAD, SAOL with COMID [15], nonadaptive COMID [5], LMNN (batch) [7], and online ITML [10].\nFor RICE-OCELAD, we set the base interval length I0 = 1 throughout, and set \u03b70 via cross-validation in a scenario with no drift. All parameters for the other algorithms were set via cross validation, so as to err on the side of optimism in a truly online scenario. For nonadaptive COMID, we set the high learning rate using cross validation for moderate drift, and we set the low learning rate via cross validation in the case of no drift. The results are shown in Figure 3. Online ITML fails due to its bias agains low-rank solutions [10], and\nthe batch method and low learning rate COMID fail due to an inability to adapt. The high learning rate COMID does well at first, but as it is optimized for slow drift it cannot adapt to the changes in drift rate as well or recover quickly from the two partition changes. SAOL, as it is designed for mildlyvarying bounded loss functions without slow drift and does not use retro-initialized learners, completely fails in this setting (zero probability of NMI \u00bf .8 throughout). RICE-OCELAD, on the other hand, adapts well throughout the entire interval, as predicted by the theory.\n7 (a) OCELAD\n-300 -250 -200 -150 -100 -50 0\n-60\n-40\n-20\n0\n20\n40\n60\n80\n(b) PCA\nFig. 4. Metric learning for product type clustering. Book reviews blue, electronics reviews red. Original LOO k-NN error rate 15.3%. Top: First two dimensions of learned RICE-OCELAD embedding (LOO k-NN error rate 11.3%). Bottom: embedding from PCA (k-NN error 20.4%). Note improved separation of the clusters using RICE-OCELAD (cleaner border)."}, {"heading": "B. Clustering Product Reviews", "text": "As an example real data task, we consider clustering Amazon text reviews, using the Multi-Domain Sentiment Dataset [23]. We use the 11402 reviews from the Electronics and Books categories, and preprocess the data by computing word counts for each review and 2369 commonly occurring words, thus creating 11402 data points in R2369. Two possible clusterings of the reviews are considered: product category (books or electronics) and sentiment (positive: star rating 4/5 or greater, or negative: 2/5 or less).\nFigures 4 and 5 show the first two dimensions of the embeddings learned by static COMID for the category and sentiment clusterings respectively. Also shown are the 2- dimensional standard PCA embeddings, and the k-NN classification performance both before embedding and in each embeddings. As expected, metric learning is able to find embeddings with improved class separability. We emphasize\n(a) OCELAD\n-300 -250 -200 -150 -100 -50 0\n-60\n-40\n-20\n0\n20\n40\n60\n80\n(b) PCA\nFig. 5. Metric learning for sentiment clustering. Positive reviews blue, negative red. Original LOO k-NN error rate 35.7%. Top: First two dimensions of learned RICE-OCELAD embedding (LOO k-NN error rate 23.5%). Bottom: embedding from PCA (k-NN error 41.9%). Note improved separation of the clusters using RICE-OCELAD.\nthat while improvements in k-NN classification are observed, we use k-NN merely as a way to quantify the separability of the classes in the learned embeddings. In these experiments, we set the regularizer r(\u00b7) to the elementwise L1 norm to encourage sparse features.\nWe then conducted drift experiments where the clustering changes. The change happens after the metric learner for the original clustering has converged, hence the nonadaptive learning rate is effectively zero. For each change, we show the k-NN error rate in the learned RICE-OCELAD embedding as it adapts to the new clustering. Emphasizing the visualization and computational advantages of a low-dimensional embedding, we computed the k-NN error after projecting the data into the first 5 dimensions of the embedding. Also shown are the results for a learner where an oracle allows reinitialization of the metric to the identity at time zero, and the nonadaptive learner for which the learning rate is not increased. Figure 6 (left) shows the results when the clustering changes from the\n8 0 20 40 60 80 100\nTime (constraints)\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5 0.55 E m b e d d in g k -N N E rr o r R a te\nAdaptive Reinitialized Nonadaptive\n0 20 40 60 80 100\nTime (constraints)\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\nE m\nb e d d in\ng k\n-N N\nE rr\no r\nR a te\nAdaptive Reinitialized Nonadaptive\nFig. 6. Metric drift in Amazon review data. Left: Change from product type + sentiment clustering to simply product type; Right: Change from sentiment to product type clustering. The proposed OCELAD adapts to changes, tracking the clusters as they evolve. The oracle reinitialized mirror descent method (COMID) learner has higher tracking error and the nonadaptive learner (straight line) does not track the changes at all.\nfour class sentiment + type partition to the two class product type only partition, and Figure 6 (right) shows the results when the partition changes from sentiment to product type. In the first case, the similar clustering allows RICE-OCELAD to significantly outperform even the reinitialized method, and in the second remain competitive where the clusterings are unrelated."}, {"heading": "VII. CONCLUSION AND FUTURE WORK", "text": "Learning a metric on a complex dataset enables both unsupervised methods and/or a user to home in on the problem of interest while de-emphasizing extraneous information. When the problem of interest or the data distribution is nonstationary, however, the optimal metric can be time-varying. We considered the problem of tracking a nonstationary metric and presented an efficient, strongly adaptive online algorithm (OCELAD), that combines the outputs of any black box learning ensemble (such as RICE), and has strong theoretical regret guarantees. Performance of our algorithm was evaluated\nboth on synthetic and real datasets, demonstrating its ability to learn and adapt quickly in the presence of changes both in the clustering of interest and in the underlying data distribution.\nPotential directions for future work include the learning of more expressive metrics beyond the Mahalanobis metric, the incorporation of unlabeled data points in a semi-supervised learning framework [24], and the incorporation of an active learning framework to select which pairs of data points to obtain labels for at any given time [25]."}], "references": [{"title": "The elements of statistical learning: data mining, inference and prediction", "author": ["T. Hastie", "R. Tibshirani", "J. Friedman", "J. Franklin"], "venue": "The Mathematical Intelligencer, vol. 27, no. 2, pp. 83\u201385, 2005.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Nonlinear dimensionality reduction", "author": ["J.A. Lee", "M. Verleysen"], "venue": "Springer Science & Business Media,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Metric learning: A survey.", "author": ["B. Kulis"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Mirror descent for metric learning: a unified approach", "author": ["G. Kunapuli", "J. Shavlik"], "venue": "Machine Learning and Knowledge Discovery in Databases. Springer, 2012, pp. 859\u2013874.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Distance metric learning with application to clustering with side-information", "author": ["E.P. Xing", "M.I. Jordan", "S. Russell", "A.Y. Ng"], "venue": "Advances in Neural Information Processing Systems, 2002, pp. 505\u2013512.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "Distance metric learning for large margin nearest neighbor classification", "author": ["K.Q. Weinberger", "J. Blitzer", "L.K. Saul"], "venue": "Advances in Neural Information Processing System, 2005, pp. 1473\u20131480.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Fast solvers and efficient implementations for distance metric learning", "author": ["K.Q. Weinberger", "L.K. Saul"], "venue": "ICML, 2008, pp. 1160\u20131167.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Neighbourhood components analysis", "author": ["J. Goldberger", "G.E. Hinton", "S.T. Roweis", "R. Salakhutdinov"], "venue": "Advances in neural information processing systems, 2004, pp. 513\u2013520.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "Informationtheoretic metric learning", "author": ["J.V. Davis", "B. Kulis", "P. Jain", "S. Sra", "I.S. Dhillon"], "venue": "ICML, 2007, pp. 209\u2013216.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "A survey on metric learning for feature vectors and structured data", "author": ["A. Bellet", "A. Habrard", "M. Sebban"], "venue": "arXiv preprint arXiv:1306.6709, 2013.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Distance metric learning: A comprehensive survey", "author": ["L. Yang", "R. Jin"], "venue": "Michigan State Universiy, vol. 2, 2006.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Prediction, learning, and games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Composite objective mirror descent", "author": ["J.C. Duchi", "S. Shalev-Shwartz", "Y. Singer", "A. Tewari"], "venue": "COLT. Citeseer, 2010, pp. 14\u201326.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Strongly adaptive online learning", "author": ["A. Daniely", "A. Gonen", "S. Shalev-Shwartz"], "venue": "ICML, 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Adaptive bound optimization for online convex optimization", "author": ["H.B. McMahan", "M. Streeter"], "venue": "COLT, 2010.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J.C. Duchi", "E. Hazan", "Y. Singer"], "venue": "COLT, 2010.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Analysis techniques for adaptive online learning", "author": ["H.B. McMahan"], "venue": "arXiv preprint arXiv:1403.3465, 2014.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Tracking the best expert", "author": ["M. Herbster", "M.K. Warmuth"], "venue": "Machine Learning, vol. 32, no. 2, pp. 151\u2013178, 1998.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1998}, {"title": "Adaptive algorithms for online decision problems", "author": ["E. Hazan", "C. Seshadhri"], "venue": "Electronic Colloquium on Computational Complexity (ECCC), vol. 14, no. 088, 2007.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "Online convex optimization in dynamic environments", "author": ["E. Hall", "R. Willett"], "venue": "Selected Topics in Signal Processing, IEEE Journal of, vol. 9, no. 4, pp. 647\u2013662, June 2015.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "From external to internal regret", "author": ["A. Blum", "Y. Mansour"], "venue": "Learning theory. Springer, 2005, pp. 621\u2013636.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2005}, {"title": "Biographies, bollywood, boomboxes and blenders: Domain adaptation for sentiment classification", "author": ["J. Blitzer", "M. Dredze", "F. Pereira"], "venue": "ACL, vol. 7, 2007, pp. 440\u2013447.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Integrating constraints and metric learning in semi-supervised clustering", "author": ["M. Bilenko", "S. Basu", "R.J. Mooney"], "venue": "ICML, 2004, p. 11.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2004}, {"title": "Active learning", "author": ["B. Settles"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning, vol. 6, no. 1, pp. 1\u2013114, 2012.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "Examples of such techniques include Principal Component Analysis [1], Multidimensional Scaling [2], covariance estimation [2], [1], and manifold learning [3].", "startOffset": 95, "endOffset": 98}, {"referenceID": 0, "context": "Examples of such techniques include Principal Component Analysis [1], Multidimensional Scaling [2], covariance estimation [2], [1], and manifold learning [3].", "startOffset": 122, "endOffset": 125}, {"referenceID": 1, "context": "Examples of such techniques include Principal Component Analysis [1], Multidimensional Scaling [2], covariance estimation [2], [1], and manifold learning [3].", "startOffset": 154, "endOffset": 157}, {"referenceID": 2, "context": "Many supervised and semi-supervised distance metric learning approaches have been developed [4].", "startOffset": 92, "endOffset": 95}, {"referenceID": 3, "context": "This includes online algorithms [5] with regret guarantees for situations where similarity constraints are received sequentially.", "startOffset": 32, "endOffset": 35}, {"referenceID": 4, "context": "MMC [6], a method for identifying a Mahalanobis metric for clustering with side information, uses semidefinite programming to identify a metric that maximizes the sum of distances between points labeled with different classes subject to the constraint that the sum of distances between all points with similar labels be less than some constant.", "startOffset": 4, "endOffset": 7}, {"referenceID": 5, "context": "Large Margin Nearest Neighbor (LMNN) [7] similarly uses semidefinite programming to identify a Mahalanobis distance.", "startOffset": 37, "endOffset": 40}, {"referenceID": 6, "context": "This method has been shown to be computationally efficient [8] and, in contrast to the similarly motivated Neighborhood Component Analysis [9], is guaranteed to converge to a globally optimal solution.", "startOffset": 59, "endOffset": 62}, {"referenceID": 7, "context": "This method has been shown to be computationally efficient [8] and, in contrast to the similarly motivated Neighborhood Component Analysis [9], is guaranteed to converge to a globally optimal solution.", "startOffset": 139, "endOffset": 142}, {"referenceID": 8, "context": "Information Theoretic Metric Learning (ITML) [10] is another popular Distance Metric Learning technique.", "startOffset": 45, "endOffset": 49}, {"referenceID": 2, "context": "For surveys of the vast metric learning literature, see [4], [11], [12].", "startOffset": 56, "endOffset": 59}, {"referenceID": 9, "context": "For surveys of the vast metric learning literature, see [4], [11], [12].", "startOffset": 61, "endOffset": 65}, {"referenceID": 10, "context": "For surveys of the vast metric learning literature, see [4], [11], [12].", "startOffset": 67, "endOffset": 71}, {"referenceID": 11, "context": "Online learning [13] meets these criteria by efficiently updating the estimate every time a new data point is obtained, instead of solving an objective function formed from the entire dataset.", "startOffset": 16, "endOffset": 20}, {"referenceID": 11, "context": "Many online learning methods have regret guarantees, that is, the loss in performance relative to a batch method is provably small [13], [14].", "startOffset": 131, "endOffset": 135}, {"referenceID": 12, "context": "Many online learning methods have regret guarantees, that is, the loss in performance relative to a batch method is provably small [13], [14].", "startOffset": 137, "endOffset": 141}, {"referenceID": 13, "context": "In practice, however, the performance of an online learning method is strongly influenced by the learning rate, which may need to vary over time in a dynamic environment [15], [16], [17], especially one with changing drift rates.", "startOffset": 170, "endOffset": 174}, {"referenceID": 14, "context": "In practice, however, the performance of an online learning method is strongly influenced by the learning rate, which may need to vary over time in a dynamic environment [15], [16], [17], especially one with changing drift rates.", "startOffset": 176, "endOffset": 180}, {"referenceID": 15, "context": "In practice, however, the performance of an online learning method is strongly influenced by the learning rate, which may need to vary over time in a dynamic environment [15], [16], [17], especially one with changing drift rates.", "startOffset": 182, "endOffset": 186}, {"referenceID": 14, "context": "For learning static parameters, AdaGrad-style methods [16], [17] perform gradient descent steps with the step size adapted based on the magnitude of recent gradients.", "startOffset": 54, "endOffset": 58}, {"referenceID": 15, "context": "For learning static parameters, AdaGrad-style methods [16], [17] perform gradient descent steps with the step size adapted based on the magnitude of recent gradients.", "startOffset": 60, "endOffset": 64}, {"referenceID": 16, "context": "Follow the regularized leader (FTRL) type algorithms adapt the regularization to the observations [18].", "startOffset": 98, "endOffset": 102}, {"referenceID": 13, "context": "SAOL maintains several learners with different learning rates and randomly selects the best one based on recent performance [15].", "startOffset": 124, "endOffset": 128}, {"referenceID": 16, "context": "Several of these adaptive methods have provable regret bounds [18], [19], [20].", "startOffset": 62, "endOffset": 66}, {"referenceID": 17, "context": "Several of these adaptive methods have provable regret bounds [18], [19], [20].", "startOffset": 68, "endOffset": 72}, {"referenceID": 18, "context": "Several of these adaptive methods have provable regret bounds [18], [19], [20].", "startOffset": 74, "endOffset": 78}, {"referenceID": 16, "context": "regret from time 0 to time T ) at every time [18].", "startOffset": 45, "endOffset": 49}, {"referenceID": 13, "context": "SAOL, on the other hand, attempts to have low static regret on every subinterval, as well as low regret overall [15].", "startOffset": 112, "endOffset": 116}, {"referenceID": 3, "context": "Following [5], we introduce the following margin based constraints:", "startOffset": 10, "endOffset": 13}, {"referenceID": 3, "context": "Kunapuli and Shavlik [5] propose using nuclear norm regularization (r(M) = \u2016M\u2016\u2217) to encourage projection of the data onto a low dimensional subspace (feature selection/dimensionality reduction), and we have also had success with the elementwise L1 norm (r(M) = \u2016vec(M)\u20161).", "startOffset": 21, "endOffset": 24}, {"referenceID": 3, "context": "Viewing the acquisition of new data points as stochastic realizations of the underlying distribution [5] suggests the use of composite objective stochastic mirror descent techniques", "startOffset": 101, "endOffset": 104}, {"referenceID": 12, "context": "For the loss (3) and learning rate \u03b7t, COMID [14] gives", "startOffset": 45, "endOffset": 49}, {"referenceID": 3, "context": "In [5] a closedform algorithm for solving the minimization in (4) with", "startOffset": 3, "endOffset": 6}, {"referenceID": 19, "context": "Critically, the optimal learning rate \u03b7t depends on the rate of change of Mt [21], and thus will need to change with time to adapt to nonstationary drift.", "startOffset": 77, "endOffset": 81}, {"referenceID": 13, "context": ", with an arrangement that is a dyadic partition of the temporal axis, as in [15].", "startOffset": 77, "endOffset": 81}, {"referenceID": 20, "context": "The weight update we use is inspired by the multiplicative weight (MW) literature [22], modified to allow for unbounded loss functions.", "startOffset": 82, "endOffset": 86}, {"referenceID": 20, "context": "The weighted average of the ensemble is reasonable here due to our use of a convex loss function (proven in the next section), as opposed to the possibly non-convex losses of [22], necessitating a randomized selection approach.", "startOffset": 175, "endOffset": 179}, {"referenceID": 19, "context": "In [21] the authors derive dynamic regret bounds that hold over all possible sequences w such that \u2211 t\u2208I \u2016\u03b8t+1\u2212\u03b8t\u2016 \u2264 \u03b3, i.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "Strongly adaptive regret bounds [15] have claimed that static regret is low on every subinterval, instead of only low in the aggregate.", "startOffset": 32, "endOffset": 36}, {"referenceID": 19, "context": "The proof of the following result is omitted for lack of space, and derives from a result in [21].", "startOffset": 93, "endOffset": 97}, {"referenceID": 3, "context": "Metric tracking performance is computed for RICE-OCELAD (adaptive), nonadaptive COMID [5] (high learning rate), nonadaptive COMID (low learning rate), the batch solution (LMNN) [7], SAOL [15] and online ITML [10], averaged over 3000 random trials.", "startOffset": 86, "endOffset": 89}, {"referenceID": 5, "context": "Metric tracking performance is computed for RICE-OCELAD (adaptive), nonadaptive COMID [5] (high learning rate), nonadaptive COMID (low learning rate), the batch solution (LMNN) [7], SAOL [15] and online ITML [10], averaged over 3000 random trials.", "startOffset": 177, "endOffset": 180}, {"referenceID": 13, "context": "Metric tracking performance is computed for RICE-OCELAD (adaptive), nonadaptive COMID [5] (high learning rate), nonadaptive COMID (low learning rate), the batch solution (LMNN) [7], SAOL [15] and online ITML [10], averaged over 3000 random trials.", "startOffset": 187, "endOffset": 191}, {"referenceID": 8, "context": "Metric tracking performance is computed for RICE-OCELAD (adaptive), nonadaptive COMID [5] (high learning rate), nonadaptive COMID (low learning rate), the batch solution (LMNN) [7], SAOL [15] and online ITML [10], averaged over 3000 random trials.", "startOffset": 208, "endOffset": 212}, {"referenceID": 13, "context": "In our results, we consider RICE-OCELAD, SAOL with COMID [15], nonadaptive COMID [5], LMNN (batch) [7], and online ITML [10].", "startOffset": 57, "endOffset": 61}, {"referenceID": 3, "context": "In our results, we consider RICE-OCELAD, SAOL with COMID [15], nonadaptive COMID [5], LMNN (batch) [7], and online ITML [10].", "startOffset": 81, "endOffset": 84}, {"referenceID": 5, "context": "In our results, we consider RICE-OCELAD, SAOL with COMID [15], nonadaptive COMID [5], LMNN (batch) [7], and online ITML [10].", "startOffset": 99, "endOffset": 102}, {"referenceID": 8, "context": "In our results, we consider RICE-OCELAD, SAOL with COMID [15], nonadaptive COMID [5], LMNN (batch) [7], and online ITML [10].", "startOffset": 120, "endOffset": 124}, {"referenceID": 8, "context": "Online ITML fails due to its bias agains low-rank solutions [10], and the batch method and low learning rate COMID fail due to an inability to adapt.", "startOffset": 60, "endOffset": 64}, {"referenceID": 21, "context": "As an example real data task, we consider clustering Amazon text reviews, using the Multi-Domain Sentiment Dataset [23].", "startOffset": 115, "endOffset": 119}, {"referenceID": 22, "context": "Potential directions for future work include the learning of more expressive metrics beyond the Mahalanobis metric, the incorporation of unlabeled data points in a semi-supervised learning framework [24], and the incorporation of an active learning framework to select which pairs of data points to obtain labels for at any given time [25].", "startOffset": 199, "endOffset": 203}, {"referenceID": 23, "context": "Potential directions for future work include the learning of more expressive metrics beyond the Mahalanobis metric, the incorporation of unlabeled data points in a semi-supervised learning framework [24], and the incorporation of an active learning framework to select which pairs of data points to obtain labels for at any given time [25].", "startOffset": 335, "endOffset": 339}], "year": 2016, "abstractText": "Recent work in distance metric learning has focused on learning transformations of data that best align with specified pairwise similarity and dissimilarity constraints, often supplied by a human observer. The learned transformations lead to improved retrieval, classification, and clustering algorithms due to the better adapted distance or similarity measures. Here, we address the problem of learning these transformations when the underlying constraint generation process is nonstationary. This nonstationarity can be due to changes in either the groundtruth clustering used to generate constraints or changes in the feature subspaces in which the class structure is apparent. We propose Online Convex Ensemble StrongLy Adaptive Dynamic Learning (OCELAD), a general adaptive, online approach for learning and tracking optimal metrics as they change over time that is highly robust to a variety of nonstationary behaviors in the changing metric. We apply the OCELAD framework to an ensemble of online learners. Specifically, we create a retroinitialized composite objective mirror descent (COMID) ensemble (RICE) consisting of a set of parallel COMID learners with different learning rates, demonstrate RICE-OCELAD on both real and synthetic data sets and show significant performance improvements relative to previously proposed batch and online distance metric learning algorithms.", "creator": "LaTeX with hyperref package"}}}