{"id": "1610.03955", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Oct-2016", "title": "Dialogue Session Segmentation by Embedding-Enhanced TextTiling", "abstract": "In h\u00fasav\u00edk human - ramtek computer conversation systems, firecrest the 176.50 context of a user - rhodri issued utterance is martlet particularly 119,000 important because yuanxi it provides vdm useful background information choking of mammadov the aangan conversation. huna However, it is year-and-a-half unwise vrelo to 10,000.00 track all previous utterances arrogated in the paddled current treepeople session as not scissurella all of faridabad them are 61-3 equally prasanna important. In mairesse this paper, euro472 we address the problem of howlader session 259th segmentation. We parishii propose bodenstein an acworth embedding - enhanced 7,490 TextTiling approach, scientific-technical inspired by the kuysanjaq observation enthrall that 4:58 conversation utterances kuwadzana are highly bi-lingual noisy, and constitucion that word embeddings granovetter provide a bromance robust way singalila of nasteex capturing subarnarekha semantics. burdens Experimental shortall results alessi show 1989-99 that intellectually our approach \u00e4rm achieves wrd better maglev performance maar than mackenzie the 22-15 TextTiling, inamorata MMD approaches.", "histories": [["v1", "Thu, 13 Oct 2016 07:07:50 GMT  (403kb,D)", "http://arxiv.org/abs/1610.03955v1", "INTERSPEECH-16, pages 2706--2710"]], "COMMENTS": "INTERSPEECH-16, pages 2706--2710", "reviews": [], "SUBJECTS": "cs.CL cs.HC", "authors": ["yiping song", "lili mou", "rui yan", "li yi", "zinan zhu", "xiaohua hu", "ming zhang"], "accepted": false, "id": "1610.03955"}, "pdf": {"name": "1610.03955.pdf", "metadata": {"source": "CRF", "title": "Dialogue Session Segmentation by Embedding-Enhanced TextTiling", "authors": ["Yiping Song", "Lili Mou", "Rui Yan", "Li Yi", "Zinan Zhu", "Xiaohua Hu", "Ming Zhang"], "emails": ["songyiping@pku.edu.cn,", "doublepower.mou@gmail.com", "yanrui@mail.ccnu.edu.cn", "yili@mail.ccnu.edu.cn", "zzn@mail.ccnu.edu.cn", "huxiaohua@mail.ccnu.edu.cn"], "sections": [{"heading": "1. Introduction", "text": "Human-computer dialog/conversation1 is one of the most challenging problems in artificial intelligence. Given a user-issued utterance (called a query in this paper), the computer needs to provide a reply to the query. In early years, researchers have developed various domain-oriented dialogue systems, which are typically based on rules or templates [5, 6, 7]. Recently, opendomain conversation systems have attracted more and more attention in both academia and industry (e.g., XiaoBing from Microsoft and DuMi from Baidu). Due to high diversity, we can hardly design rules or templates in the open domain. Researchers have proposed information retrieval methods [8] and modern generative neural networks [9, 10] to either search for a reply from a large conversation corpus or generate a new sentence as the reply.\nIn open-domain conversations, context information (one or a few previous utterances) is particularly important to language understanding [2, 10, 11, 12]. As dialogue sentences are usually casual and short, a single utterance (e.g., \u201cThank you.\u201d in Figure 1) does not convey much meaning, but its previous utterance (\u201c. . . writing an essay\u201d) provides useful background information of the conversation. Using such context will certainly benefit the conversation system.\n1A full dialog system typically involves speech recognition, text understanding, and speech synthesis. In this paper, we focus on the text understanding stage. However, our approach is directly applicable to dialogue systems with acoustic interaction, provided that the spoken language is converted to texts by automatic speech recognition (ASR) [1, 2], or even manually text-transcribed for research purposes like [3, 4].\nHowever, tracking all previous utterances as the context is unwise. First, commercial chat-bots usually place high demands on efficiency. In a retrieval-based system, for example, performing a standard process of candidate retrieval and re-ranking for each previous utterance may well exceed the time limit (which is very short, e.g., 500ms). Second, we observe that not all sentences in the current conversation session are equally important. The sentence \u201cWant to take a walk?\u201d is irrelevant to the current context, and should not be considered when the computer synthesizes the reply. Therefore, it raises the question of session segmentation in conversation systems.\nDocument segmentation for general-purpose corpora has been widely studied in NLP. For example, Hearst [13] proposes the TextTiling approach; she measures the similarity of neighboring sentences based on bag-of-words features, and performs segmentation by thresholding. However, such approaches are not tailored to the dialogue genre and may not be suitable for conversation session segmentation.\nIn this paper, we address the problem of session segmentation for open-domain conversations. We leverage the classic TextTiling approach, but enhance it with modern embeddingbased similarity measures. Compared with traditional bag-ofwords features, embeddings map discrete words to real-valued vectors, capturing underlying meanings in a continuous vector space; hence, it is more robust for noisy conversation corpora. Further, we propose a tailored method for word embedding learning. In traditional word embedding learning, the interaction between two words in a query and a reply is weaker than that within an utterance. We propose to combine a query and its corresponding reply as a \u201cvirtual sentence,\u201d so that it provides a better way of modeling utterances between two agents.\nar X\niv :1\n61 0.\n03 95\n5v 1\n[ cs\n.C L\n] 1\n3 O\nct 2\n01 6"}, {"heading": "2. Related Work", "text": ""}, {"heading": "2.1. Dialogue Systems and Context Modeling", "text": "Human-computer dialogue systems can be roughly divided into several categories. Template- and rule-based systems are mainly designed for certain domains [5, 6, 14]. Although manually engineered templates can also be applied in the open domain like [15], but their generated sentences are subject to 7 predefined forms, and hence are highly restricted. Retrieval methods search for a candidate reply from a large conversation corpus given a user-issued utterance as a query [8]. Generative methods can synthesize new replies by statistical machine translation [16, 17] or neural networks [9].\nThe above studies do not consider context information in reply retrieval or generation. However, recent research shows that previous utterances in a conversation session are important because they capture rich background information. Sordoni et al. [12] summarize a single previous sentence as bag-of-words features, which are fed to a recurrent neural network for reply generation. Serban et al. [18] design an attention-based neural network over all previous conversation turns/rounds, but this could be inefficient if a session lasts long in real commercial applications. By contrast, our paper addresses the problem of session segmentation so as to retain near, relevant context utterances and to eliminate far, irrelevant ones.\nA similar (but different) research problem is topic tracking in conversations, e.g., [19, 20, 21, 22]. In these approaches, the goal is typically a classification problem with a few predefined conversation states/topics, and hence it can hardly be generalized to general-purpose session segmentation."}, {"heading": "2.2. Text Segmentation", "text": "An early and classic work on text segmentation is TextTiling, proposed in [13]. The idea is to measure the similarity between two successive sentences with smoothing techniques; then segmentation is accomplished by thresholding of the depth of a \u201cvalley.\u201d In the original form of TextTiling, the cosine of term frequency features is used as the similarity measure. Joty et al. [23] apply divisive clustering instead of thresholding for segmentation. Malioutov et al. [24] formalize segmentation as a graph-partitioning problem and propose a minimum cut model based on tf \u00b7idf features to segment lectures. Ye et al. [25] minimize between-segment similarity while maximizing within-segment similarity. However, the above complicated approaches are known as global methods: when we perform segmentation between two successive sentences, future context information is needed. Therefore, they are inapplicable to realtime chat-bots, where conversation utterances can be viewed as streaming data.\nIn our study, we prefer the simple yet effective TextTiling approach for open-domain dialogue session segmentation, but enhance it with modern advances of word embeddings, which are robust in capturing semantics of words. We propose a tailored algorithm for word embedding learning by combining a query and context as a \u201cvirtual document\u201d; we also propose several heuristics for similarity measuring."}, {"heading": "3. Session Segmentation Methodology", "text": ""}, {"heading": "3.1. TextTiling", "text": "We apply a TextTiling-like algorithm for session segmentation. The original TextTiling is proposed by Hearst [13]. The main idea is to measure the similarity of each adjacent sentence pair;\nthen \u201cvalleys\u201d of similarities are detected for segmentation. Concretely, the \u201cdepth of the valley\u201d is defined by the similarity differences between the peak point in each side and the current position. We may obtain some statistics of depth scores like the mean \u00b5 and standard deviation \u03c3, and perform segmentation by a cutoff threshold.\ncutoff(\u03b1) = \u00b5+ \u03b1 \u00b7 \u03c3 (1)\nwhere \u03b1 is a hyperparameter adjusting the number of segmentation boundaries; \u00b5 and \u03c3 are the average and standard deviation of depth scores, respectively.\nIn the scenario of human-computer conversations, we compute the depth solely by the similarity difference between its left peak (previous context) and the current position. This is because we cannot obtain future utterances during online conversation.\nAlthough bag-of-words features work well in the original TextTiling algorithm for general text segmentation, it is not suitable for dialogue segmentation. As argued by Hearst [13], text overlap (repetition) between neighboring sentences is a strong hint of semantic coherence, which can be well captured by term frequency or tf \u00b7idf variants. However, in human-computer conversations, sentences are usually short, noisy, highly diversified, and probably incomplete, which requires a more robust way of similarity measuring. Therefore, we enhance TextTiling with modern word embedding techniques, as will be discussed in the next part."}, {"heading": "3.2. Learning Word Embeddings", "text": "Word embeddings are distributed, real-valued vector representations of discrete words [26, 27]. Compared with one-hot representation, word embeddings are low-dimensional and dense, measuring word meanings in a continuous vector space. Studies show that the offset of two words\u2019 embeddings represents a certain relation, e.g., \u201cman\u201d \u2212 \u201cwoman\u201d \u2248 \u201cking\u201d \u2212 \u201cqueen\u201d [26]. Hence, it is suitable to use word embeddings to model short and noisy conversation utterances.\nTo train the embeddings, we adopt the word2vec approach. The idea is to map a word w and its context c to vectors (w and c). Then we estimate the probability of a word by\np(w|c) = exp(w >c)\u2211\nw\u2032 exp(w \u2032>c)\n(2)\nThe goal of word embedding learning is to maximize the average probability of all words (suppose we have T running words):\n1\nT T\u2211 t=1 log p(wt|ct) (3)\nWe used hierarchical softmax to approximate the probability. To model the context, we further adopt the continuous bagof-words (CBOW) method. The context2 is defined by the sum of neighboring words\u2019 (input) vectors in a fixed-size window (t\u2212 \u03c4 to t+ \u03c4 ) within a sentence:\nct = \u2211\nt\u2212\u03c4\u2264i\u2264t+\u03c4 i6=t\nui (4)\nNotice that the context vector u in Equation (4) and the output vector w in Equation (2) are different as suggested in [26, 27], but the details are beyond the scope of our paper.\nVirtual Sentences In a conversation corpus, successive sentences have a stronger interaction than general texts. For example, in Figure 1, the words thank and welcome are strongly correlated, but they hardly appear in the a sentence and thus a same window. Therefore, traditional within-sentence CBOW may not capture the interaction between a query and its corresponding reply.\nIn this paper, we propose the concept of virtual sentences to learn word embeddings for conversation data. We concatenate a query q and its reply r as a virtual sentence q \u2295 r. We also use all words (other than the current one) in the virtual sentence as context (Figure 2). Formally, the context ct of the word wt is given by\nct = \u2211 i\u2208q\u2295r i6=t ui (5)\nIn this way, related words across two successive utterances from different agents can have interaction during word embedding learning. As will be shown in Subsection 4.2, virtual sentences yield a higher performance for dialogue segmentation."}, {"heading": "3.3. Measuring Similarity", "text": "In this part, we introduce several heuristics of similarity measuring based on word embeddings. Notice that, we do not leverage supervised learning (e.g., full neural networks for sentence paring [28, 29]) to measure similarity, because it is costly to obtain labeled data of high quality.\nThe simplest approach, perhaps, is to sum over all word embeddings in an utterance as sentence-level features s. This heuristic is essentially the sum pooling method widely used in neural networks [30, 31, 28]. The cosine measure is used as the similarity score between two utterances S1 and S2. Let s1 and s2 be their sentence vectors; then we have\nsim(S1, S2) = cos(s1, s2) \u2261 s>1 s2\n\u2016s1\u2016 \u00b7 \u2016s2\u2016 (6)\nwhere \u2016 \u00b7 \u2016 is the `2-norm of a vector. To enhance the interaction between two successive sentences, we propose a more complicated heuristic as follows. Let wi and vj be a word in s1 and s2, respectively. (Embeddings are denoted as bold alphabets.) Suppose further that n1 and n2 are the numbers of words in S1 and S2. The similarity is given by\nsim(S1, S2) = 1\nn1 n1\u2211 i=1 maxn2j=0{cos(wi,vj)} (7)\nFor each word wi in s1, our intuition is to find the most related word in s2, given by the max{\u00b7} part; their relatedness\n2Here, the context of a word roughly refers to its previous and future words. Please do not be confused with the context of an utterance.\nis also defined by the cosine measure. Then the sentence-level similarity is obtained by the average similarity score of words in s1. This method is denoted as heuristic-max.\nAlternatively, we may substitute the max operator in Equation (7) with avg, resulting in the heuristic-avg variant, which is equivalent to the average of word-by-word cosine similarity. However, as shown in Subsection 4.2, intensive similarity averaging has a \u201cblurring\u201d effect and will lead to significant performance degradation. This also shows that our proposed heuristic-max does capture useful interaction between two successive utterances in a dialogue."}, {"heading": "4. Experiments", "text": "In this section, we evaluate our embedding-enhanced TextTiling method as well as the effect of session segmentation. In Subsection 4.1, we describe the datasets used in our experiments. Subsection 4.2 presents the segmentation accuracy of our method and baselines. In Subsection 4.3, we show that, with our session segmentation, we can improve the performance of a retrieval-based conversation system."}, {"heading": "4.1. Dataset", "text": "To evaluate the session segmentation method, we used a realworld chatting corpus from DuMi,3 a state-of-the-practice open-domain conversation system in Chinese. We sampled 200 sessions as our experimental corpus. Session segmentation was manually annotated before experiments, serving as the ground truth. The 200 sessions were randomly split by 1:1 for validation and testing. Notice that, our method does not require labeled training samples; massive data with labels of high quality are quite expensive to obtain.\nWe also leveraged an unlabeled massive dataset of conversation utterances to train our word embeddings with \u201cvirtual sentences.\u201d The dataset was crawled from the Douban forum,4 containing 3 million utterances and approximately 150,000 unique words (Chinese terms)."}, {"heading": "4.2. Segmentation Performance", "text": "We compared our full method (TextTiling with heuristic-max based on embeddings trained by virtual sentences) with several baselines:\n\u2022 Random. We randomly segmented conversation sessions. In this baseline, we were equipped with the prior probability of segmentation. \u2022 MMD. We applied the MinMax-Dotplotting (MMD) approach proposed by Ye et al. [25]. We ran the executable program provided by the authors.\n3http://xiaodu.baidu.com 4http://www.douban.com\n\u2022 TextTiling w/ tf\u00b7idf features. We implemented TextTiling ourselves according to [13].\nWe tuned the hyperparameter \u03b1 in Equation (??)on the validation set to make the number of segmentation close to that of manual annotation, and reported precision, recall, and the F-score on the test set in Table 1. As seen, our approach significantly outperforms baselines by a large margin in terms of both precision and recall. Besides, we can see that MMD obtains low performance, which is mainly because the approach cannot be easily adapted to other datasets like short sentences of conversation utterances. In summary, we achieve an F -score higher than baseline methods by more than 20%, showing the effectiveness of enhancing TextTiling with modern word embeddings.\nWe further conducted in-depth analysis of different strategies of training word-embeddings and matching heuristics in Table 2. For word embeddings, we trained them on the 3Msentence dataset with three strategies: (1) virtual-sentence context proposed in our paper; (2) within-sentence context, where all words (except the current one) within a sentence (either a query or reply) are regarded as the context; (3) window-based context, which is the original form of [26]: the context is the words in a window (previous 2 words and future 2 words in the sentence). We observe that our virtual-sentence strategy consistently outperforms the other two in all three matching heuristics. The results suggest that combining a query and a reply does provide more information in learning dialogue-specific word embeddings.\nRegarding matching heuristics, we find that in the second and third strategies of training word embeddings, the complicated heuristic-max method yields higher F -scores than simple sum pooling by 2\u20133%. However, for the virtual-sentence strategy, heuristic-max is slightly worse than the sum pooling. (The degradation is only 0.1% and not significant.) This is probably because both heuristic-max and virtual sentences emphasize the rich interaction between a query and its corresponding reply; combining them does not result in further gain.\nWe also notice that heuristic-avg is worse than other similarity measures. As this method is mathematically equivalent to the average of word-by-word similarity, it may have an undesirable blurring effect.\nTo sum up, our experiments show that both the proposed embedding learning approach and the similarity heuristic are effective for session segmentation. The embedding-enhanced TextTiling approach largely outperforms baselines."}, {"heading": "4.3. Session Segmentation in Dialogue Systems", "text": "We conducted an external experiment to show the effect of session segmentation in dialogue systems. We integrated the segmentation mechanism into a state-of-the-practice retrievalbased system and evaluated the results by manual annotation, similar to our previous work [28, 32, 33].\nConcretely, we compared our session segmentation with fixed-length context, used in [12]. That is to say, the competing method always regards two previous utterances as context. We hired three workers to annotate the results with three integer scores (0\u20132 points, indicating bad, borderline, and good replies, respectively.) We sampled 30 queries from the test set of 100 sessions. For each query, we retrieved 10 candidates and computed p@15 and nDCG scores [34] (averaged over three annotators). Provided with previous utterances as context, each worker had up to 1000 sentences to read during annotation.\nTable 3 presents the results of the dialogue system with session segmentation. As demonstrated, our method outperforms the simple fixed-context approach in terms of both metrics. We computed the inner-annotator agreement: std = 0.309; 3-discrete-class Fleiss\u2019 kappa score = 0.411, indicating moderate agreement [35].\nCase Study. We present a case study on our website: https://sites.google.com/site/sessionsegmentation/. From the case study, we see that the proposed approach is able to segment the dialogue session appropriately, so as to better utilize background information from a conversation session."}, {"heading": "5. Conclusion", "text": "In this paper, we addressed the problem of session segmentation for open-domain dialogue systems. We proposed an embedding-enhanced TextTiling approach, where we trained embeddings with the novel notion of virtual sentences; we also proposed several heuristics for similarity measure. Experimental results show that both our embedding learning and similarity measuring are effective in session segmentation, and that with our approach, we can improve the performance of a retrievalbased dialogue system."}, {"heading": "6. Acknowledgments", "text": "We thank anonymous reviewers for useful comments and Jingbo Zhu for sharing the MMD executable program. This paper is partially supported by the National Natural Science Foundation of China (NSFC Grant Nos. 61272343 and 61472006), the Doctoral Program of Higher Education of China (Grant No. 20130001110032), and the National Basic Research Program (973 Program No. 2014CB340405).\n5Out of a rigorous criterion, we regard a \u201ccorrect\u201d reply if the score is 2, and \u201cincorrect\u201d if the score is 0 or 1."}, {"heading": "7. References", "text": "[1] F. Bechet, A. Nasr, and B. Favre, \u201cAdapting dependency parsing\nto spontaneous speech for open domain spoken language understanding.\u201d in INTERSPEECH, 2014, pp. 135\u2013139.\n[2] C. Liu, P. Xu, and R. Sarikaya, \u201cDeep contextual language understanding in spoken dialogue systems,\u201d in INTERSPEECH, 2015, pp. 120\u2013124.\n[3] A. Cervone, C. Lai, S. Pareti, and P. Bell, \u201cTowards automatic detection of reported speech in dialogue using prosodic cues,\u201d in INTERSPEECH, 2015, pp. 3061\u20133065.\n[4] V. Freeman, G.-A. Levow, R. Wright, and M. Ostendorf, \u201cInvestigating the role of \u2018yeah\u2019 in stance-dense conversation,\u201d in INTERSPEECH, 2015, pp. 3076\u20133080.\n[5] G. Ferguson, J. Allen, B. Miller et al., \u201cTRAINS-95: Towards a mixed-initiative planning assistant.\u201d in AIPS, 1996, pp. 70\u201377.\n[6] A. C. Graesser, P. Chipman, B. C. Haynes, and A. Olney, \u201cAutoTutor: An intelligent tutoring system with mixed-initiative dialogue,\u201d IEEE Trans. Education, vol. 48, no. 4, pp. 612\u2013618, 2005.\n[7] G. Mesnil, X. He, L. Deng, and Y. Bengio, \u201cInvestigation of recurrent-neural-network architectures and learning methods for spoken language understanding.\u201d in INTERSPEECH, 2013, pp. 3771\u20133775.\n[8] J. Otterbacher, G. Erkan, and D. R. Radev, \u201cUsing random walks for question-focused sentence retrieval,\u201d in HLT-EMNLP, 2005, pp. 915\u2013922.\n[9] L. Shang, Z. Lu, and H. Li, \u201cNeural responding machine for shorttext conversation,\u201d in ACL-IJCNLP, 2015, pp. 1577\u20131586.\n[10] A. Sordoni, Y. Bengio, H. Vahabi, C. Lioma, J. Grue Simonsen, and J.-Y. Nie, \u201cA hierarchical recurrent encoder-decoder for generative context-aware query suggestion,\u201d in CIKM, 2015, pp. 553\u2013 562.\n[11] A. Bhargava, A. Celikyilmaz, D. Hakkani-Tur, and R. Sarikaya, \u201cEasy contextual intent prediction and slot detection,\u201d in ICASSP, 2013, pp. 8337\u20138341.\n[12] A. Sordoni, M. Galley, M. Auli, C. Brockett, Y. Ji, M. Mitchell, J.-Y. Nie, J. Gao, and B. Dolan, \u201cA neural network approach to context-sensitive generation of conversational responses,\u201d in NAACL-HLT, 2015, pp. 196\u2013205.\n[13] M. A. Hearst, \u201cTextTiling: Segmenting text into multi-paragraph subtopic passages,\u201d Computational Linguistics, vol. 23, no. 1, pp. 33\u201364, 1997.\n[14] S. Watanabe, J. R. Hershey, T. K. Marks, Y. Fujii, and Y. Koji, \u201cCost-level integration of statistical and rule-based dialog managers,\u201d in INTERSPEECH, 2014, pp. 323\u2013327.\n[15] S. Han, J. Bang, S. Ryu, and G. G. Lee, \u201cExploiting knowledge base to generate responses for natural language dialog listening agents,\u201d in SIGDIAL, 2015, pp. 129\u2013133.\n[16] C. Haas and S. Riezler, \u201cResponse-based learning for machine translation of open-domain database queries,\u201d in NAACL-HLT, 2015, pp. 1339\u20131344.\n[17] J. Tavernier, R. Cowan, and M. Vanni, \u201cHoly Moses! Leveraging existing tools and resources for entity translation,\u201d in LREC, 2008, pp. 2715\u20132719.\n[18] I. V. Serban, A. Sordoni, Y. Bengio, A. Courville, and J. Pineau, \u201cBuilding end-to-end dialogue systems using generative hierarchical neural network models,\u201d arXiv preprint arXiv:1507.04808, 2015.\n[19] S. Kim, R. E. Banchs, and H. Li, \u201cWikipedia-based kernels for dialogue topic tracking,\u201d in ICASSP, 2014, pp. 131\u2013135.\n[20] A. Celikyilmaz, D. Z. Hakkani-Tu\u0308r, and G. Tu\u0308r, \u201cApproximate inference for domain detection in spoken language understanding,\u201d in INTERSPEECH, 2011, pp. 713\u2013716.\n[21] K. Lagus and J. Kuusisto, \u201cTopic identification in natural language dialogues using neural networks,\u201d in SIGDIAL, 2002, pp. 95\u2013102.\n[22] P. A. Crook, J.-P. Robichaud, and R. Sarikaya, \u201cMulti-language hypotheses ranking and domain tracking for open domain dialogue systems,\u201d in INTERSPEECH, 2015, pp. 1810\u20131814.\n[23] S. Joty, G. Carenini, and R. T. Ng, \u201cTopic segmentation and labeling in asynchronous conversations,\u201d JAIR, no. 47, pp. 521\u2013573, 2013.\n[24] I. Malioutov and R. Barzilay, \u201cMinimum cut model for spoken lecture segmentation,\u201d in COLING-ACL, 2006, pp. 25\u201332.\n[25] N. Ye, N. Ye, J. Zhu, H. Wang, M. Y. Ma, and B. Zhang, \u201cAn improved model of dotplotting for text segmentation,\u201d J. Chinese Language and Computing, vol. 17, no. 1, pp. 27\u201340, 2007.\n[26] T. Mikolov, K. Chen, G. Corrado, and J. Dean, \u201cEfficient estimation of word representations in vector space,\u201d arXiv preprint arXiv:1301.3781, 2013.\n[27] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, \u201cDistributed representations of words and phrases and their compositionality,\u201d in NIPS, 2013, pp. 3111\u20133119.\n[28] R. Yan, Y. Song, and H. Wu, \u201cLearning to respond with deep neural networks for retrieval based human-computer conversation system,\u201d in SIGIR, 2016.\n[29] L. Mou, R. Men, G. Li, Y. Xu, L. Zhang, R. Yan, and Z. Jin, \u201cNatural language inference by tree-based convolution and heuristic matching,\u201d in ACL (2), 2016.\n[30] Y. LeCun, L. Jackel, L. Bottou, A. Brunot, C. Cortes, J. Denker, H. Drucker, I. Guyon, U. Muller, E. Sackinger, P. Simard, and V. Vapnik, \u201cComparison of learning algorithms for handwritten digit recognition,\u201d in Proc. Int\u2019l Conf. Artificial Neural Networks, 1995, pp. 53\u201360.\n[31] L. Mou, H. Peng, G. Li, Y. Xu, L. Zhang, and Z. Jin, \u201cDiscriminative neural sentence modeling by tree-based convolution,\u201d in EMNLP, 2015, pp. 2315\u20132325.\n[32] X. Li, L. Mou, R. Yan, and M. Zhang, \u201cStalemateBreaker: A proactive content-introducing approach to automatic humancomputer conversation,\u201d in IJCAI, 2016.\n[33] L. Mou, R. Yan, G. Li, L. Zhang, and Z. Jin, \u201cBackward and forward language modeling for constrained natural language generation,\u201d arXiv preprint arXiv:1512.06612, 2015.\n[34] K. Ja\u0308rvelin and J. Keka\u0308la\u0308inen, \u201cCumulated gain-based evaluation of ir techniques,\u201d ACM Trans. Information Systems, vol. 20, no. 4, pp. 422\u2013446, 2002.\n[35] J. Fleiss, \u201cMeasuring nominal scale agreement among many raters,\u201d Psychological Bulletin, vol. 76, no. 5, pp. 378\u2013382, 1971."}], "references": [{"title": "Adapting dependency parsing to spontaneous speech for open domain spoken language understanding.", "author": ["F. Bechet", "A. Nasr", "B. Favre"], "venue": "INTERSPEECH,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Deep contextual language understanding in spoken dialogue systems", "author": ["C. Liu", "P. Xu", "R. Sarikaya"], "venue": "INTERSPEECH, 2015, pp. 120\u2013124.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Towards automatic detection of reported speech in dialogue using prosodic cues", "author": ["A. Cervone", "C. Lai", "S. Pareti", "P. Bell"], "venue": "INTERSPEECH, 2015, pp. 3061\u20133065.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Investigating the role of \u2018yeah\u2019 in stance-dense conversation", "author": ["V. Freeman", "G.-A. Levow", "R. Wright", "M. Ostendorf"], "venue": "INTER- SPEECH, 2015, pp. 3076\u20133080.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "TRAINS-95: Towards a mixed-initiative planning assistant.", "author": ["G. Ferguson", "J. Allen", "B. Miller"], "venue": "AIPS,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1996}, {"title": "AutoTutor: An intelligent tutoring system with mixed-initiative dialogue", "author": ["A.C. Graesser", "P. Chipman", "B.C. Haynes", "A. Olney"], "venue": "IEEE Trans. Education, vol. 48, no. 4, pp. 612\u2013618, 2005.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding.", "author": ["G. Mesnil", "X. He", "L. Deng", "Y. Bengio"], "venue": "INTERSPEECH,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Using random walks for question-focused sentence retrieval", "author": ["J. Otterbacher", "G. Erkan", "D.R. Radev"], "venue": "HLT-EMNLP, 2005, pp. 915\u2013922.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Neural responding machine for shorttext conversation", "author": ["L. Shang", "Z. Lu", "H. Li"], "venue": "ACL-IJCNLP, 2015, pp. 1577\u20131586.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "A hierarchical recurrent encoder-decoder for generative context-aware query suggestion", "author": ["A. Sordoni", "Y. Bengio", "H. Vahabi", "C. Lioma", "J. Grue Simonsen", "J.-Y. Nie"], "venue": "CIKM, 2015, pp. 553\u2013 562.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Easy contextual intent prediction and slot detection", "author": ["A. Bhargava", "A. Celikyilmaz", "D. Hakkani-Tur", "R. Sarikaya"], "venue": "ICASSP, 2013, pp. 8337\u20138341.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["A. Sordoni", "M. Galley", "M. Auli", "C. Brockett", "Y. Ji", "M. Mitchell", "J.-Y. Nie", "J. Gao", "B. Dolan"], "venue": "NAACL-HLT, 2015, pp. 196\u2013205.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "TextTiling: Segmenting text into multi-paragraph subtopic passages", "author": ["M.A. Hearst"], "venue": "Computational Linguistics, vol. 23, no. 1, pp. 33\u201364, 1997.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1997}, {"title": "Cost-level integration of statistical and rule-based dialog managers", "author": ["S. Watanabe", "J.R. Hershey", "T.K. Marks", "Y. Fujii", "Y. Koji"], "venue": "INTERSPEECH, 2014, pp. 323\u2013327.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Exploiting knowledge base to generate responses for natural language dialog listening agents", "author": ["S. Han", "J. Bang", "S. Ryu", "G.G. Lee"], "venue": "SIGDIAL, 2015, pp. 129\u2013133.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Response-based learning for machine translation of open-domain database queries", "author": ["C. Haas", "S. Riezler"], "venue": "NAACL-HLT, 2015, pp. 1339\u20131344.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Holy Moses! Leveraging existing tools and resources for entity translation", "author": ["J. Tavernier", "R. Cowan", "M. Vanni"], "venue": "LREC, 2008, pp. 2715\u20132719.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "author": ["I.V. Serban", "A. Sordoni", "Y. Bengio", "A. Courville", "J. Pineau"], "venue": "arXiv preprint arXiv:1507.04808, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Wikipedia-based kernels for dialogue topic tracking", "author": ["S. Kim", "R.E. Banchs", "H. Li"], "venue": "ICASSP, 2014, pp. 131\u2013135.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Approximate inference for domain detection in spoken language understanding", "author": ["A. Celikyilmaz", "D.Z. Hakkani-T\u00fcr", "G. T\u00fcr"], "venue": "INTERSPEECH, 2011, pp. 713\u2013716.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Topic identification in natural language dialogues using neural networks", "author": ["K. Lagus", "J. Kuusisto"], "venue": "SIGDIAL, 2002, pp. 95\u2013102.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2002}, {"title": "Multi-language hypotheses ranking and domain tracking for open domain dialogue systems", "author": ["P.A. Crook", "J.-P. Robichaud", "R. Sarikaya"], "venue": "INTERSPEECH, 2015, pp. 1810\u20131814.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Topic segmentation and labeling in asynchronous conversations", "author": ["S. Joty", "G. Carenini", "R.T. Ng"], "venue": "JAIR, no. 47, pp. 521\u2013573, 2013.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Minimum cut model for spoken lecture segmentation", "author": ["I. Malioutov", "R. Barzilay"], "venue": "COLING-ACL, 2006, pp. 25\u201332.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2006}, {"title": "An improved model of dotplotting for text segmentation", "author": ["N. Ye", "N. Ye", "J. Zhu", "H. Wang", "M.Y. Ma", "B. Zhang"], "venue": "J. Chinese Language and Computing, vol. 17, no. 1, pp. 27\u201340, 2007.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "arXiv preprint arXiv:1301.3781, 2013.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "NIPS, 2013, pp. 3111\u20133119.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning to respond with deep neural networks for retrieval based human-computer conversation system", "author": ["R. Yan", "Y. Song", "H. Wu"], "venue": "SIGIR, 2016.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2016}, {"title": "Natural language inference by tree-based convolution and heuristic matching", "author": ["L. Mou", "R. Men", "G. Li", "Y. Xu", "L. Zhang", "R. Yan", "Z. Jin"], "venue": "ACL (2), 2016.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "Comparison of learning algorithms for handwritten digit recognition", "author": ["Y. LeCun", "L. Jackel", "L. Bottou", "A. Brunot", "C. Cortes", "J. Denker", "H. Drucker", "I. Guyon", "U. Muller", "E. Sackinger", "P. Simard", "V. Vapnik"], "venue": "Proc. Int\u2019l Conf. Artificial Neural Networks, 1995, pp. 53\u201360.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1995}, {"title": "Discriminative neural sentence modeling by tree-based convolution", "author": ["L. Mou", "H. Peng", "G. Li", "Y. Xu", "L. Zhang", "Z. Jin"], "venue": "EMNLP, 2015, pp. 2315\u20132325.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "StalemateBreaker: A proactive content-introducing approach to automatic humancomputer conversation", "author": ["X. Li", "L. Mou", "R. Yan", "M. Zhang"], "venue": "IJCAI, 2016.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2016}, {"title": "Backward and forward language modeling for constrained natural language generation", "author": ["L. Mou", "R. Yan", "G. Li", "L. Zhang", "Z. Jin"], "venue": "arXiv preprint arXiv:1512.06612, 2015.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Cumulated gain-based evaluation of ir techniques", "author": ["K. J\u00e4rvelin", "J. Kek\u00e4l\u00e4inen"], "venue": "ACM Trans. Information Systems, vol. 20, no. 4, pp. 422\u2013446, 2002.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2002}, {"title": "Measuring nominal scale agreement among many raters", "author": ["J. Fleiss"], "venue": "Psychological Bulletin, vol. 76, no. 5, pp. 378\u2013382, 1971.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1971}], "referenceMentions": [{"referenceID": 4, "context": "In early years, researchers have developed various domain-oriented dialogue systems, which are typically based on rules or templates [5, 6, 7].", "startOffset": 133, "endOffset": 142}, {"referenceID": 5, "context": "In early years, researchers have developed various domain-oriented dialogue systems, which are typically based on rules or templates [5, 6, 7].", "startOffset": 133, "endOffset": 142}, {"referenceID": 6, "context": "In early years, researchers have developed various domain-oriented dialogue systems, which are typically based on rules or templates [5, 6, 7].", "startOffset": 133, "endOffset": 142}, {"referenceID": 7, "context": "Researchers have proposed information retrieval methods [8] and modern generative neural networks [9, 10] to either search for a reply from a large conversation corpus or generate a new sentence as the reply.", "startOffset": 56, "endOffset": 59}, {"referenceID": 8, "context": "Researchers have proposed information retrieval methods [8] and modern generative neural networks [9, 10] to either search for a reply from a large conversation corpus or generate a new sentence as the reply.", "startOffset": 98, "endOffset": 105}, {"referenceID": 9, "context": "Researchers have proposed information retrieval methods [8] and modern generative neural networks [9, 10] to either search for a reply from a large conversation corpus or generate a new sentence as the reply.", "startOffset": 98, "endOffset": 105}, {"referenceID": 1, "context": "In open-domain conversations, context information (one or a few previous utterances) is particularly important to language understanding [2, 10, 11, 12].", "startOffset": 137, "endOffset": 152}, {"referenceID": 9, "context": "In open-domain conversations, context information (one or a few previous utterances) is particularly important to language understanding [2, 10, 11, 12].", "startOffset": 137, "endOffset": 152}, {"referenceID": 10, "context": "In open-domain conversations, context information (one or a few previous utterances) is particularly important to language understanding [2, 10, 11, 12].", "startOffset": 137, "endOffset": 152}, {"referenceID": 11, "context": "In open-domain conversations, context information (one or a few previous utterances) is particularly important to language understanding [2, 10, 11, 12].", "startOffset": 137, "endOffset": 152}, {"referenceID": 0, "context": "However, our approach is directly applicable to dialogue systems with acoustic interaction, provided that the spoken language is converted to texts by automatic speech recognition (ASR) [1, 2], or even manually text-transcribed for research purposes like [3, 4].", "startOffset": 186, "endOffset": 192}, {"referenceID": 1, "context": "However, our approach is directly applicable to dialogue systems with acoustic interaction, provided that the spoken language is converted to texts by automatic speech recognition (ASR) [1, 2], or even manually text-transcribed for research purposes like [3, 4].", "startOffset": 186, "endOffset": 192}, {"referenceID": 2, "context": "However, our approach is directly applicable to dialogue systems with acoustic interaction, provided that the spoken language is converted to texts by automatic speech recognition (ASR) [1, 2], or even manually text-transcribed for research purposes like [3, 4].", "startOffset": 255, "endOffset": 261}, {"referenceID": 3, "context": "However, our approach is directly applicable to dialogue systems with acoustic interaction, provided that the spoken language is converted to texts by automatic speech recognition (ASR) [1, 2], or even manually text-transcribed for research purposes like [3, 4].", "startOffset": 255, "endOffset": 261}, {"referenceID": 12, "context": "For example, Hearst [13] proposes the TextTiling approach; she measures the similarity of neighboring sentences based on bag-of-words features, and performs segmentation by thresholding.", "startOffset": 20, "endOffset": 24}, {"referenceID": 4, "context": "Template- and rule-based systems are mainly designed for certain domains [5, 6, 14].", "startOffset": 73, "endOffset": 83}, {"referenceID": 5, "context": "Template- and rule-based systems are mainly designed for certain domains [5, 6, 14].", "startOffset": 73, "endOffset": 83}, {"referenceID": 13, "context": "Template- and rule-based systems are mainly designed for certain domains [5, 6, 14].", "startOffset": 73, "endOffset": 83}, {"referenceID": 14, "context": "Although manually engineered templates can also be applied in the open domain like [15], but their generated sentences are subject to 7 predefined forms, and hence are highly restricted.", "startOffset": 83, "endOffset": 87}, {"referenceID": 7, "context": "Retrieval methods search for a candidate reply from a large conversation corpus given a user-issued utterance as a query [8].", "startOffset": 121, "endOffset": 124}, {"referenceID": 15, "context": "Generative methods can synthesize new replies by statistical machine translation [16, 17] or neural networks [9].", "startOffset": 81, "endOffset": 89}, {"referenceID": 16, "context": "Generative methods can synthesize new replies by statistical machine translation [16, 17] or neural networks [9].", "startOffset": 81, "endOffset": 89}, {"referenceID": 8, "context": "Generative methods can synthesize new replies by statistical machine translation [16, 17] or neural networks [9].", "startOffset": 109, "endOffset": 112}, {"referenceID": 11, "context": "[12] summarize a single previous sentence as bag-of-words features, which are fed to a recurrent neural network for reply generation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] design an attention-based neural network over all previous conversation turns/rounds, but this could be inefficient if a session lasts long in real commercial applications.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": ", [19, 20, 21, 22].", "startOffset": 2, "endOffset": 18}, {"referenceID": 19, "context": ", [19, 20, 21, 22].", "startOffset": 2, "endOffset": 18}, {"referenceID": 20, "context": ", [19, 20, 21, 22].", "startOffset": 2, "endOffset": 18}, {"referenceID": 21, "context": ", [19, 20, 21, 22].", "startOffset": 2, "endOffset": 18}, {"referenceID": 12, "context": "An early and classic work on text segmentation is TextTiling, proposed in [13].", "startOffset": 74, "endOffset": 78}, {"referenceID": 22, "context": "[23] apply divisive clustering instead of thresholding for segmentation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] formalize segmentation as a graph-partitioning problem and propose a minimum cut model based on tf \u00b7idf features to segment lectures.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] minimize between-segment similarity while maximizing within-segment similarity.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "The original TextTiling is proposed by Hearst [13].", "startOffset": 46, "endOffset": 50}, {"referenceID": 12, "context": "As argued by Hearst [13], text overlap (repetition) between neighboring sentences is a strong hint of semantic coherence, which can be well captured by term frequency or tf \u00b7idf variants.", "startOffset": 20, "endOffset": 24}, {"referenceID": 25, "context": "Word embeddings are distributed, real-valued vector representations of discrete words [26, 27].", "startOffset": 86, "endOffset": 94}, {"referenceID": 26, "context": "Word embeddings are distributed, real-valued vector representations of discrete words [26, 27].", "startOffset": 86, "endOffset": 94}, {"referenceID": 25, "context": ", \u201cman\u201d \u2212 \u201cwoman\u201d \u2248 \u201cking\u201d \u2212 \u201cqueen\u201d [26].", "startOffset": 37, "endOffset": 41}, {"referenceID": 25, "context": "Notice that the context vector u in Equation (4) and the output vector w in Equation (2) are different as suggested in [26, 27], but the details are beyond the scope of our paper.", "startOffset": 119, "endOffset": 127}, {"referenceID": 26, "context": "Notice that the context vector u in Equation (4) and the output vector w in Equation (2) are different as suggested in [26, 27], but the details are beyond the scope of our paper.", "startOffset": 119, "endOffset": 127}, {"referenceID": 27, "context": ", full neural networks for sentence paring [28, 29]) to measure similarity, because it is costly to obtain labeled data of high quality.", "startOffset": 43, "endOffset": 51}, {"referenceID": 28, "context": ", full neural networks for sentence paring [28, 29]) to measure similarity, because it is costly to obtain labeled data of high quality.", "startOffset": 43, "endOffset": 51}, {"referenceID": 29, "context": "This heuristic is essentially the sum pooling method widely used in neural networks [30, 31, 28].", "startOffset": 84, "endOffset": 96}, {"referenceID": 30, "context": "This heuristic is essentially the sum pooling method widely used in neural networks [30, 31, 28].", "startOffset": 84, "endOffset": 96}, {"referenceID": 27, "context": "This heuristic is essentially the sum pooling method widely used in neural networks [30, 31, 28].", "startOffset": 84, "endOffset": 96}, {"referenceID": 24, "context": "[25].", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "We implemented TextTiling ourselves according to [13].", "startOffset": 49, "endOffset": 53}, {"referenceID": 25, "context": "For word embeddings, we trained them on the 3Msentence dataset with three strategies: (1) virtual-sentence context proposed in our paper; (2) within-sentence context, where all words (except the current one) within a sentence (either a query or reply) are regarded as the context; (3) window-based context, which is the original form of [26]: the context is the words in a window (previous 2 words and future 2 words in the sentence).", "startOffset": 337, "endOffset": 341}, {"referenceID": 27, "context": "We integrated the segmentation mechanism into a state-of-the-practice retrievalbased system and evaluated the results by manual annotation, similar to our previous work [28, 32, 33].", "startOffset": 169, "endOffset": 181}, {"referenceID": 31, "context": "We integrated the segmentation mechanism into a state-of-the-practice retrievalbased system and evaluated the results by manual annotation, similar to our previous work [28, 32, 33].", "startOffset": 169, "endOffset": 181}, {"referenceID": 32, "context": "We integrated the segmentation mechanism into a state-of-the-practice retrievalbased system and evaluated the results by manual annotation, similar to our previous work [28, 32, 33].", "startOffset": 169, "endOffset": 181}, {"referenceID": 11, "context": "Concretely, we compared our session segmentation with fixed-length context, used in [12].", "startOffset": 84, "endOffset": 88}, {"referenceID": 33, "context": "For each query, we retrieved 10 candidates and computed p@1 and nDCG scores [34] (averaged over three annotators).", "startOffset": 76, "endOffset": 80}, {"referenceID": 34, "context": "411, indicating moderate agreement [35].", "startOffset": 35, "endOffset": 39}], "year": 2016, "abstractText": "In human-computer conversation systems, the context of a userissued utterance is particularly important because it provides useful background information of the conversation. However, it is unwise to track all previous utterances in the current session as not all of them are equally important. In this paper, we address the problem of session segmentation. We propose an embedding-enhanced TextTiling approach, inspired by the observation that conversation utterances are highly noisy, and that word embeddings provide a robust way of capturing semantics. Experimental results show that our approach achieves better performance than the TextTiling, MMD approaches.", "creator": "LaTeX with hyperref package"}}}