{"id": "1701.05574", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jan-2017", "title": "Harnessing Cognitive Features for Sarcasm Detection", "abstract": "In this paper, sparkler we gaulke propose a novel mechanism maybank for enriching dmelvin the qikiqtaaluk feature vector, lefse for the windstorm task of sarcasm detection, ten-hour with 1985-1986 cognitive features extracted komaki from eye - movement prohibit patterns ipratropium of guihua human easterly readers. Sarcasm orzechowski detection has dont been sayyid a buffered challenging research camphora problem, 1.5875 and opalescent its udovic importance for NLP ging applications skb such as cooperage review continent summarization, pabianice dialog corregidora systems harkrider and chng sentiment painstakingly analysis realis is well recognized. Sarcasm russia-1 can often be traced pcaob to jayalalitha incongruity re-dedicated that yann becomes kopel apparent derg as valtteri the full sentence negatives unfolds. chapuis This presence of salzenstein incongruity - chelmsley implicit or yilin explicit - affects kanai the way readers eyes madrid move do\u011fu through the hannele text. niuatoputapu We observe the chilavert difference laksanavisit in ausaid the wagonway behaviour sucessful of the rapper eye, mequon while efim reading saulny sarcastic midatlantic and indeterminates non bakeoff sarcastic metatarsal sentences. alwan Motivated fois by cucaracha his anglo-american observation, we hungriest augment traditional redash linguistic sacramento-san and mitcham stylistic features wasquehal for sarcasm passenger-only detection medarex with the cognitive features neyyattinkara obtained from stunde readers eye apoyo movement rebekah data. We perform easy-to-use statistical classification using electrons the enhanced l'essor feature set negroid so sportback obtained. The augmented quammen cognitive features improve ironton sarcasm invigorates detection by 3. 7% (subsequence in terms 3-66 of alerting F - score ), over piroozi the performance cvv of the saluting best reported vachousek system.", "histories": [["v1", "Thu, 19 Jan 2017 19:32:06 GMT  (292kb,D)", "http://arxiv.org/abs/1701.05574v1", "The 54th Annual Meeting of The Association for Computational Linguistics (ACL 2016)"]], "COMMENTS": "The 54th Annual Meeting of The Association for Computational Linguistics (ACL 2016)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["abhijit mishra", "diptesh kanojia", "seema nagar", "kuntal dey", "pushpak bhattacharyya"], "accepted": true, "id": "1701.05574"}, "pdf": {"name": "1701.05574.pdf", "metadata": {"source": "CRF", "title": "Harnessing Cognitive Features for Sarcasm Detection", "authors": ["Abhijit Mishra", "Diptesh Kanojia", "Seema Nagar", "Kuntal Dey", "Pushpak Bhattacharyya"], "emails": ["pb}@cse.iitb.ac.in", "kuntadey}@in.ibm.com"], "sections": [{"heading": "1 Introduction", "text": "Sarcasm is an intensive, indirect and complex construct that is often intended to express contempt or ridicule 1. Sarcasm, in speech, is multi-modal, involving tone, body-language and gestures along with linguistic artifacts used in speech. Sarcasm in text, on the other hand, is more restrictive when it comes to such non-linguistic modalities. This makes recognizing textual sarcasm more challenging for both humans and machines.\n1The Free Dictionary\nSarcasm detection plays an indispensable role in applications like online review summarizers, dialog systems, recommendation systems and sentiment analyzers. This makes automatic detection of sarcasm an important problem. However, it has been quite difficult to solve such a problem with traditional NLP tools and techniques. This is apparent from the results reported by the survey from Joshi et al. (2016). The following discussion brings more insights into this.\nConsider a scenario where an online reviewer gives a negative opinion about a movie through sarcasm: \u201cThis is the kind of movie you see because the theater has air conditioning\u201d. It is difficult for an automatic sentiment analyzer to assign a rating to the movie and, in the absence of any other information, such a system may not be able to comprehend that prioritizing the air-conditioning facilities of the theater over the movie experience indicates a negative sentiment towards the movie. This gives an intuition to why, for sarcasm detection, it is necessary to go beyond textual analysis.\nWe aim to address this problem by exploiting the psycholinguistic side of sarcasm detection, using cognitive features extracted with the help of eye-tracking. A motivation to consider cognitive features comes from analyzing human eyemovement trajectories that supports the conjecture: Reading sarcastic texts induces distinctive eye movement patterns, compared to literal texts. The cognitive features, derived from human eye movement patterns observed during reading, include two primary feature types:\n1. Eye movement characteristic features of readers while reading given text, comprising gaze-fixaions (i.e,longer stay of gaze on a visual object), forward and backward saccades (i.e., quick jumping of gaze between two positions of rest).\nar X\niv :1\n70 1.\n05 57\n4v 1\n[ cs\n.C L\n] 1\n9 Ja\nn 20\n17\n2. Features constructed using the statistical and deeper structural information contained in graph, created by treating words as vertices and saccades between a pair of words as edges.\nThe cognitive features, along with textual features used in best available sarcasm detectors, are used to train binary classifiers against given sarcasm labels. Our experiments show significant improvement in classification accuracy over the state of the art, by performing such augmentation.\nFeasibility of Our Approach Since our method requires gaze data from human readers to be available, the methods practicability becomes questionable. We present our views on this below.\nAvailability of Mobile Eye-trackers Availability of inexpensive embedded eye-trackers on hand-held devices has come close to reality now. This opens avenues to get eye-tracking data from inexpensive mobile devices from a huge population of online readers non-intrusively, and derive cognitive features to be used in predictive frameworks like ours. For instance, Cogisen: (http://www.sencogi.com) has a patent (ID: EP2833308-A1) on \u201ceye-tracking using inexpensive mobile web-cams\u201d.\nApplicability Scenario We believe, mobile eye-tracking modules could be a part of mobile applications built for e-commerce, online learning, gaming etc. where automatic analysis of online reviews calls for better solutions to detect linguistic nuances like sarcasm. To give an example, let\u2019s say a book gets different reviews on Amazon. Our system could watch how readers read the review using mobile eye-trackers, and thereby, decide whether the text contains sarcasm or not. Such an application can horizontally scale across the web and will help in improving automatic classification of online reviews.\nSince our approach seeks human mediation, one might be tempted to question the approach of relying upon eye-tracking, an indirect indicator, instead of directly obtaining man-made annotations. We believe, asking a large number of internet audience to annotate/give feedback on each and every sentence that they read online, following a set of annotation instructions, will be extremely intrusive and may not be responded well. Our system,\non the other hand, can be seamlessly integrated into existing applications and as the eye-tracking process runs in the background, users will not be interrupted in the middle of the reading. This, thus, offers a more natural setting where human mediation can be availed without intervention.\nGetting Users\u2019 Consent for Eye-tracking\nEye-tracking technology has already been utilized by leading mobile technology developers (like Samsung) to facilitate richer user experiences through services like Smart-scroll (where a user\u2019s eye movement determines whether a page has to be scrolled or not) and Smart-lock (where user\u2019s gaze position decides whether to lock the screen or not). The growing interest of users in using such services takes us to a promising situation where getting users\u2019 consent to record eyemovement patterns will not be difficult, though it is yet not the current state of affairs.\nDisclaimer: In this work, we focus on detecting sarcasm in non-contextual and short-text settings prevalent in product reviews and social media. Moreover, our method requires eye-tracking data to be available in the test scenario."}, {"heading": "2 Related Work", "text": "Sarcasm, in general, has been the focus of research for quite some time. In one of the pioneering works Jorgensen et al. (1984) explained how sarcasm arises when a figurative meaning is used opposite to the literal meaning of the utterance. In the word of Clark and Gerrig (1984), sarcasm processing involves canceling the indirectly negated message and replacing it with the implicated one. Giora (1995), on the other hand, define sarcasm as a mode of indirect negation that requires processing of both negated and implicated messages. Ivanko and Pexman (2003) define sarcasm as a six tuple entity consisting of a speaker, a listener, Context, Utterance, Literal Proposition and Intended Proposition and study the cognitive aspects of sarcasm processing.\nComputational linguists have previously addressed this problem using rule based and statistical techniques, that make use of : (a) Unigrams and Pragmatic features (Carvalho et al., 2009; Gonza\u0301lez-Iba\u0301nez et al., 2011; Barbieri et al., 2014; Joshi et al., 2015) (b) Stylistic patterns (Davidov et al., 2010) and patterns related to situational disparity (Riloff et al., 2013) and (c) Hastag\ninterpretations (Liebrecht et al., 2013; Maynard and Greenwood, 2014).\nMost of the previously done work on sarcasm detection uses distant supervision based techniques (ex: leveraging hashtags) and stylistic/pragmatic features (emoticons, laughter expressions such as \u201clol\u201d etc). But, detecting sarcasm in linguistically well-formed structures, in absence of explicit cues or information (like emoticons), proves to be hard using such linguistic/stylistic features alone.\nWith the advent of sophisticated eyetrackers and electro/magneto-encephalographic (EEG/MEG) devices, it has been possible to delve deep into the cognitive underpinnings of sarcasm understanding. Filik (2014), using a series of eye-tracking and EEG experiments try to show that for unfamiliar ironies, the literal interpretation would be computed first. They also show that a mismatch with context would lead to a re-interpretation of the statement, as being ironic. Camblin et al. (2007) show that in multi-sentence passages, discourse congruence has robust effects on eye movements. This also implies that disrupted processing occurs for discourse incongruent words, even though they are perfectly congruous at the sentence level. In our previous work (Mishra et al., 2016), we augment cognitive features, derived from eye-movement patterns of readers, with textual features to detect whether a human reader has realized the presence of sarcasm in text or not.\nThe recent advancements in the literature discussed above, motivate us to explore gaze-based cognition for sarcasm detection. As far as we know, our work is the first of its kind."}, {"heading": "3 Eye-tracking Database for Sarcasm Analysis", "text": "Sarcasm often emanates from incongruity (Campbell and Katz, 2012), which enforces the brain to reanalyze it (Kutas and Hillyard, 1980). This, in turn, affects the way eyes move through the text. Hence, distinctive eye-movement patterns may be observed in the case of successful processing of sarcasm in text in contrast to literal texts. This hypothesis forms the crux of our method for sarcasm detection and we validate this using our previously released freely available sarcasm dataset2 (Mishra et al., 2016) enriched with gaze\n2http://www.cfilt.iitb.ac.in/cognitive-nlp\ninformation."}, {"heading": "3.1 Document Description", "text": "The database consists of 1,000 short texts, each having 10-40 words. Out of these, 350 are sarcastic and are collected as follows: (a) 103 sentences are from two popular sarcastic quote websites3, (b) 76 sarcastic short movie reviews are manually extracted from the Amazon Movie Corpus (Pang and Lee, 2004) by two linguists. (c) 171 tweets are downloaded using the hashtag #sarcasm from Twitter. The 650 non-sarcastic texts are either downloaded from Twitter or extracted from the Amazon Movie Review corpus. The sentences do not contain words/phrases that are highly topic or culture specific. The tweets were normalized to make them linguistically well formed to avoid difficulty in interpreting social media lingo. Every sentence in our dataset carries positive or negative opinion about specific \u201caspects\u201d. For example, the sentence \u201cThe movie is extremely well cast\u201d has positive sentiment about the aspect \u201ccast\u201d.\nThe annotators were seven graduate students with science and engineering background, and possess good English proficiency. They were given a set of instructions beforehand and are advised to seek clarifications before they proceed. The instructions mention the nature of the task, annotation input method, and necessity of head movement minimization during the experiment."}, {"heading": "3.2 Task Description", "text": "The task assigned to annotators was to read sentences one at a time and label them with with binary labels indicating the polarity (i.e., positive/negative). Note that, the participants were not\n3http://www.sarcasmsociety.com, http://www.themarysue.com/funny-amazon-reviews\ninstructed to annotate whether a sentence is sarcastic or not., to rule out the Priming Effect (i.e., if sarcasm is expected beforehand, processing incongruity becomes relatively easier (Gibbs, 1986)). The setup ensures its \u201cecological validity\u201d in two ways: (1) Readers are not given any clue that they have to treat sarcasm with special attention. This is done by setting the task to polarity annotation (instead of sarcasm detection). (2) Sarcastic sentences are mixed with non sarcastic text, which does not give prior knowledge about whether the forthcoming text will be sarcastic or not.\nThe eye-tracking experiment is conducted by following the standard norms in eye-movement research (Holmqvist et al., 2011). At a time, one sentence is displayed to the reader along with the \u201caspect\u201d with respect to which the annotation has to be provided. While reading, an SR-Research Eyelink-1000 eye-tracker (monocular remote mode, sampling rate 500Hz) records several eye-movement parameters like fixations (a long stay of gaze) and saccade (quick jumping of gaze between two positions of rest) and pupil size.\nThe accuracy of polarity annotation varies between 72%-91% for sarcastic texts and 75%-91% for non-sarcastic text, showing the inherent difficulty of sentiment annotation, when sarcasm is present in the text under consideration. Annotation errors may be attributed to: (a) lack of patience/attention while reading, (b) issues related to text comprehension, and (c) confusion/indecisiveness caused due to lack of context.\nFor our analysis, we do not discard the incorrect annotations present in the database. Since our system eventually aims to involve online readers for sarcasm detection, it will be hard to segregate readers who misinterpret the text. We make a rational assumption that, for a particular text, most of the readers, from a fairly large population, will be able to identify sarcasm. Under this assumption, the eye-movement parameters, averaged across all readers in our setting, may not be significantly distorted by a few readers who would have failed to identify sarcasm. This assumption is applicable for both regular and multi-instance based classifiers explained in section 6."}, {"heading": "4 Analysis of Eye-movement Data", "text": "We observe distinct behavior during sarcasm reading, by analyzing the \u201cfixation duration on the text\u201d (also referred to as \u201cdwell time\u201d in the lit-\nerature) and \u201cscanpaths\u201d of the readers."}, {"heading": "4.1 Variation in the Average Fixation Duration per Word", "text": "Since sarcasm in text can be expected to induce cognitive load, it is reasonable to believe that it would require more processing time (Ivanko and Pexman, 2003). Hence, fixation duration normalized over total word count should usually be higher for a sarcastic text than for a non-sarcastic one. We observe this for all participants in our dataset, with the average fixation duration per word for sarcastic texts being at least 1.5 times more than that of non-sarcastic texts. To test the statistical significance, we conduct a twotailed t-test (assuming unequal variance) to compare the average fixation duration per word for sarcastic and non-sarcastic texts. The hypothesized mean difference is set to 0 and the error tolerance limit (\u03b1) is set to 0.05. The t-test analysis, presented in Table 1, shows that for all participants, a statistically significant difference exists between the average fixation duration per word for sarcasm (higher average fixation duration) and nonsarcasm (lower average fixation duration). This affirms that the presence of sarcasm affects the duration of fixation on words.\nIt is important to note that longer fixations may also be caused by other linguistic subtleties (such as difficult words, ambiguity and syntactically complex structures) causing delay in comprehension, or occulomotor control problems forcing readers to spend time adjusting eye-muscles. So, an elevated average fixation duration per word may not sufficiently indicate the presence of sarcasm. But we would also like to share that, for our"}, {"heading": "I will always cherish the", "text": "dataset, when we considered readability (Flesch readability ease-score (Flesch, 1948)), number of words in a sentence and average character per word along with the sarcasm label as the predictors of average fixation duration following a linear mixed effect model (Barr et al., 2013), sarcasm label turned out to be the most significant predictor with a maximum slope. This indicates that average fixation duration per word has a strong connection with the text being sarcastic, at least in our dataset.\nWe now analyze scanpaths to gain more insights into the sarcasm comprehension process."}, {"heading": "4.2 Analysis of Scanpaths", "text": "Scanpaths are line-graphs that contain fixations as nodes and saccades as edges; the radii of the nodes represent the fixation duration. A scanpath corresponds to a participant\u2019s eye-movement pattern while reading a particular sentence. Figure 1 presents scanpaths of three participants for the sarcastic sentence S1 and the non-sarcastic sentence S2. The x-axis of the graph represents the sequence of words a reader reads, and the y-axis represents a temporal sequence in milliseconds.\nConsider a sarcastic text containing incongruous phrases A and B. Our qualitative scanpathanalysis reveals that scanpaths with respect to sarcasm processing have two typical characteristics. Often, a long regression - a saccade that goes to a previously visited segment - is observed when a reader starts reading B after skimming through A. In a few cases, the fixation duration on A and B are significantly higher than the average fixation duration per word. In sentence S1, we see long and multiple regressions from the two incongruous phrases \u201cmisconception\u201d and \u201ccherish\u201d, and a few instances where phrases \u201calways cherish\u201d and \u201coriginal misconception\u201d are fixated longer than usual. Such eye-movement behaviors are not seen for S2.\nThough sarcasm induces distinctive scanpaths\nlike the ones depicted in Figure 1 in the observed examples, presence of such patterns is not sufficient to guarantee sarcasm; such patterns may also possibly arise from literal texts. We believe that a combination of linguistic features, readability of text and features derived from scanpaths would help discriminative machine learning models learn sarcasm better."}, {"heading": "5 Features for Sarcasm Detection", "text": "We describe the features used for sarcasm detection in Table 2. The features enlisted under lexical,implicit incongruity and explicit incongruity are borrowed from various literature (predominantly from Joshi et al. (2015)). These features are essential to separate sarcasm from other forms semantic incongruity in text (for example ambiguity arising from semantic ambiguity or from metaphors). Two additional textual features viz. readability and word count of the text are also taken under consideration. These features are used to reduce the effect of text hardness and text length on the eye-movement patterns."}, {"heading": "5.1 Simple Gaze Based Features", "text": "Readers\u2019 eye-movement behavior, characterized by fixations, forward saccades, skips and regressions, can be directly quantified by simple statistical aggregation (i.e., either computing features for individual participants and then averaging or performing a multi-instance based learning as explained in section 6). Since these eye-movement attributes relate to the cognitive process in reading (Rayner and Sereno, 1994), we consider these as features in our model. Some of these features have been reported by Mishra et al. (2016) for modeling sarcasm understandability of readers. However, as far as we know, these features are being introduced in NLP tasks like textual sarcasm detection for the first time. The values of these features are believed to increase with the increase in the degree of surprisal caused by incongruity in text (except skip count, which will decrease)."}, {"heading": "5.2 Complex Gaze Based Features", "text": "For these features, we rely on a graph structure, namely \u201csaliency graphs\u201d, derived from eye-gaze information and word sequences in the text.\nConstructing Saliency Graphs: For each reader and each sentence, we construct a \u201csaliency graph\u201d, representing the reader\u2019s atten-\ntion characteristics. A saliency graph for a sentence S for a readerR, represented asG = (V,E), is a graph with vertices (V ) and edges (E) where each vertex v \u2208 V corresponds to a word in S (may not be unique) and there exists an edge e \u2208 E between vertices v1 and v2 if R performs at least one saccade between the words corresponding to v1 and v2.\nFigure 2 shows an example of a saliency graph.A saliency graph may be weighted, but not necessarily connected, for a given text (as there may be words in the given text with no fixation on them). The \u201ccomplex\u201d gaze features derived from\nsaliency graphs are also motivated by the theory of incongruity. For instance, Edge Density of a saliency graph increases with the number of distinct saccades, which could arise from the complexity caused by presence of sarcasm. Similarly, the highest weighted degree of a graph is expected to be higher, if the node corresponds to a phrase, incongruous to some other phrase in the text."}, {"heading": "6 The Sarcasm Classifier", "text": "We interpret sarcasm detection as a binary classification problem. The training data constitutes\n994 examples created using our eye-movement database for sarcasm detection. To check the effectiveness of our feature set, we observe the performance of multiple classification techniques on our dataset through a stratified 10-fold cross validation. We also compare the classification accuracy of our system and the best available systems proposed by Riloff et al. (2013) and Joshi et al. (2015) on our dataset. Using Weka (Hall et al., 2009) and LibSVM (Chang and Lin, 2011) APIs, we implement the following classifiers:\n\u2022 Na\u0308ive Bayes classifier\n\u2022 Support Vector Machines (Cortes and Vapnik, 1995) with default hyper-paramaters\n\u2022 Multilayer Feed Forward Neural Network\n\u2022 Multi Instance Logistic Regression (MILR) (Xu and Frank, 2004)"}, {"heading": "6.1 Results", "text": "Table 3 shows the classification results considering various feature combinations for different classifiers and other systems. These are:\n\u2022 Unigram (with principal components of unigram feature vectors),\n\u2022 Sarcasm (the feature-set reported by Joshi et al. (2015) subsuming unigram features and features from other reported systems)\n\u2022 Gaze (the simple and complex cognitive features we introduce, along with readability and word count features), and\n\u2022 Gaze+Sarcasm (the complete set of features).\nFor all regular classifiers, the gaze features are averaged across participants and augmented with linguistic and sarcasm related features. For the MILR classifier, the gaze features derived from\neach participant are augmented with linguistic features and thus, a multi instance \u201cbag\u201d of features is formed for each sentence in the training data. This multi-instance dataset is given to an MILR classifier, which follows the standard multi instance assumption to derive class-labels for each bag.\nFor all the classifiers, our feature combination outperforms the baselines (considering only unigram features) as well as (Joshi et al., 2015), with the MILR classifier getting an F-score improvement of 3.7% and Kappa difference of 0.08. We also achieve an improvement of 2% over the baseline, using SVM classifier, when we employ our feature set. We also observe that the gaze features alone, also capture the differences between sarcasm and non-sarcasm classes with a highprecision but a low recall.\nTo see if the improvement obtained is statistically significant over the state-of-the art system with textual sarcasm features alone, we perform McNemar test. The output of the SVM classifier using only linguistic features used for sarcasm detection by Joshi et al. (2015) and the output of the MILR classifier with the complete set of features are compared, setting threshold \u03b1 = 0.05. There was a significant difference in the classifier\u2019s accuracy with p(two-tailed) = 0.02 with an odds-ratio of 1.43, showing that the classification accuracy improvement is unlikely to be observed by chance in 95% confidence interval."}, {"heading": "6.2 Considering Reading Time as a Cognitive Feature along with Sarcasm Features", "text": "One may argue that, considering simple measures of reading effort like \u201creading time\u201d as cognitive feature instead of the expensive eye-tracking features for sarcasm detection may be a cost-effective solution. To examine this, we repeated our experiments with \u201creading time\u201d considered as the only cognitive feature, augmented with the textual features. The F-scores of all the classifiers turn out to be close to that of the classifiers considering sarcasm feature alone and the difference in the improvement is not statistically significant (p > 0.05). One the other hand, F-scores with gaze features are superior to the F-scores when reading time is considered as a cognitive feature."}, {"heading": "6.3 How Effective are the Cognitive Features", "text": "We examine the effectiveness of cognitive features on the classification accuracy by varying the input training data size. To examine this, we create a\nstratified (keeping the class ratio constant) random train-test split of 80%:20%. We train our classifier with 100%, 90%, 80% and 70% of the training data with our whole feature set, and the feature combination from Joshi et al. (2015). The goodness of our system is demonstrated by improvements in F-score and Kappa statistics, shown in Figure 3.\nWe further analyze the importance of features by ranking the features based on (a) Chi squared test, and (b) Information Gain test, using Weka\u2019s attribute selection module. Figure 4 shows the top 20 ranked features produced by both the tests. For both the cases, we observe 16 out of top 20 features to be gaze features. Further, in each of the cases, Average Fixation Duration per Word and Largest Regression Position are seen to be the two most significant features."}, {"heading": "6.4 Example Cases", "text": "Table 4 shows a few example cases from the experiment with stratified 80%-20% train-test split.\n\u2022 Example sentence 1 is sarcastic, and requires extra-linguistic knowledge (about poor living conditions at Manchester). Hence, the sarcasm detector relying only on textual features is unable to detect the underlying incongruity. However, our system predicts the label successfully, possibly helped by the gaze features.\n\u2022 Similarly, for sentence 2, the false sense of presence of incongruity (due to phrases like \u201cHelped me\u201d and \u201cCan\u2019t stop\u201d) affects the system with only linguistic features. Our system, though, performs well in this case also.\n\u2022 Sentence 3 presents a false-negative case where it was hard for even humans to get the sarcasm. This is why our gaze features (and subsequently the complete set of features) account for erroneous prediction.\n\u2022 In sentence 4, gaze features alone falseindicate presence of incongruity, whereas the system predicts correctly when gaze and linguistic features are taken together.\nFrom these examples, it can be inferred that, only gaze features would not have sufficed to rule out the possibility of detecting other forms of incongruity that do not result in sarcasm."}, {"heading": "6.5 Error Analysis", "text": "Errors committed by our system arise from multiple factors, starting from limitations of the eyetracker hardware to errors committed by linguistic tools and resources. Also, aggregating various eye-tracking parameters to extract the cognitive features may have caused information loss in the regular classification setting."}, {"heading": "7 Conclusion", "text": "In the current work, we created a novel framework to detect sarcasm, that derives insights from human cognition, that manifests over eye movement patterns. We hypothesized that distinctive eye-movement patterns, associated with reading sarcastic text, enables improved detection of sarcasm. We augmented traditional linguistic features with cognitive features obtained from readers\u2019 eye-movement data in the form of simple gaze-based features and complex features derived from a graph structure. This extended feature-set improved the success rate of the sarcasm detector by 3.7%, over the best available system. Using cognitive features in an NLP Processing system like ours is the first proposal of its kind.\nOur general approach may be useful in other NLP sub-areas like sentiment and emotion analysis, text summarization and question answering, where considering textual clues alone does not prove to be sufficient. We propose to augment this work in future by exploring deeper graph and gaze features. We also propose to develop models for the purpose of learning complex gaze feature representation, that accounts for the power of individual eye movement patterns along with the aggregated patterns of eye movements."}, {"heading": "Acknowledgments", "text": "We thank the members of CFILT Lab, especially Jaya Jha and Meghna Singh, and the students of IIT Bombay for their help and support."}], "references": [{"title": "Modelling sarcasm in twitter, a novel approach", "author": ["Horacio Saggion", "Francesco Ronzano"], "venue": "ACL", "citeRegEx": "Barbieri et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Barbieri et al\\.", "year": 2014}, {"title": "Random effects structure for confirmatory hypothesis testing", "author": ["Barr et al.2013] Dale J Barr", "Roger Levy", "Christoph Scheepers", "Harry J Tily"], "venue": null, "citeRegEx": "Barr et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Barr et al\\.", "year": 2013}, {"title": "The interplay of discourse congruence and lexical association during sentence processing: Evidence from {ERPs} and eye tracking", "author": ["Peter C. Gordon", "Tamara Y. Swaab"], "venue": "Journal of Memory and Language,", "citeRegEx": "Camblin et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Camblin et al\\.", "year": 2007}, {"title": "Are there necessary conditions for inducing a sense of sarcastic irony? Discourse Processes, 49(6):459\u2013480", "author": ["Campbell", "Katz2012] John D Campbell", "Albert N Katz"], "venue": null, "citeRegEx": "Campbell et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Campbell et al\\.", "year": 2012}, {"title": "Clues for detecting irony in user-generated contents: oh...!! it\u2019s so easy;-)", "author": ["Lu\u0131\u0301s Sarmento", "M\u00e1rio J Silva", "Eug\u00e9nio De Oliveira"], "venue": "In Proceedings of the 1st international CIKM workshop on Topic-sentiment analy-", "citeRegEx": "Carvalho et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Carvalho et al\\.", "year": 2009}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chang", "Lin2011] Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Chang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2011}, {"title": "Semi-supervised recognition of sarcastic sentences in twitter and amazon", "author": ["Oren Tsur", "Ari Rappoport"], "venue": "In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,", "citeRegEx": "Davidov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Davidov et al\\.", "year": 2010}, {"title": "Testing theories of irony processing using eye-tracking and erps. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(3):811\u2013828", "author": ["Hartmut", "Wallington Katie", "Page Jemma Filik", "Ruth", "Leuthold"], "venue": null, "citeRegEx": "Hartmut et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hartmut et al\\.", "year": 2014}, {"title": "A new readability yardstick", "author": ["Rudolph Flesch"], "venue": "Journal of applied psychology,", "citeRegEx": "Flesch.,? \\Q1948\\E", "shortCiteRegEx": "Flesch.", "year": 1948}, {"title": "Comprehension and memory for nonliteral utterances: The problem of sarcastic indirect requests", "author": ["Raymond W. Gibbs"], "venue": "Acta Psychologica,", "citeRegEx": "Gibbs.,? \\Q1986\\E", "shortCiteRegEx": "Gibbs.", "year": 1986}, {"title": "On irony and negation", "author": ["Rachel Giora"], "venue": "Discourse processes,", "citeRegEx": "Giora.,? \\Q1995\\E", "shortCiteRegEx": "Giora.", "year": 1995}, {"title": "Identifying sarcasm in twitter: a closer look", "author": ["Smaranda Muresan", "Nina Wacholder"], "venue": "In Proceedings of the 49th Annual Meeting of the Association", "citeRegEx": "Gonz\u00e1lezIb\u00e1nez et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gonz\u00e1lezIb\u00e1nez et al\\.", "year": 2011}, {"title": "The weka data mining software: an update", "author": ["Hall et al.2009] Mark Hall", "Eibe Frank", "Geoffrey Holmes", "Bernhard Pfahringer", "Peter Reutemann", "Ian H Witten"], "venue": "ACM SIGKDD explorations newsletter,", "citeRegEx": "Hall et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "Eye tracking: A comprehensive guide to methods and measures", "author": ["Marcus Nystr\u00f6m", "Richard Andersson", "Richard Dewhurst", "Halszka Jarodzka", "Joost Van de Weijer"], "venue": null, "citeRegEx": "Holmqvist et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Holmqvist et al\\.", "year": 2011}, {"title": "Context incongruity and irony processing", "author": ["Ivanko", "Pexman2003] Stacey L Ivanko", "Penny M Pexman"], "venue": "Discourse Processes,", "citeRegEx": "Ivanko et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Ivanko et al\\.", "year": 2003}, {"title": "Test of the mention theory of irony", "author": ["George A Miller", "Dan Sperber"], "venue": "Journal of Experimental Psychology: General,", "citeRegEx": "Jorgensen et al\\.,? \\Q1984\\E", "shortCiteRegEx": "Jorgensen et al\\.", "year": 1984}, {"title": "Harnessing context incongruity for sarcasm detection", "author": ["Joshi et al.2015] Aditya Joshi", "Vinita Sharma", "Pushpak Bhattacharyya"], "venue": "Proceedings of 53rd Annual Meeting of the Association for Computational Linguistics, Beijing,", "citeRegEx": "Joshi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2015}, {"title": "Automatic sarcasm detection: A survey", "author": ["Joshi et al.2016] Aditya Joshi", "Pushpak Bhattacharyya", "Mark James Carman"], "venue": null, "citeRegEx": "Joshi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2016}, {"title": "Reading senseless sentences: Brain potentials reflect semantic incongruity", "author": ["Kutas", "Hillyard1980] Marta Kutas", "Steven A Hillyard"], "venue": null, "citeRegEx": "Kutas et al\\.,? \\Q1980\\E", "shortCiteRegEx": "Kutas et al\\.", "year": 1980}, {"title": "The perfect solution for detecting sarcasm in tweets", "author": ["Florian Kunneman", "Antal van den Bosch"], "venue": "WASSA", "citeRegEx": "Liebrecht et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liebrecht et al\\.", "year": 2013}, {"title": "Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis", "author": ["Maynard", "Greenwood2014] Diana Maynard", "Mark A Greenwood"], "venue": "In Proceedings of LREC", "citeRegEx": "Maynard et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Maynard et al\\.", "year": 2014}, {"title": "Predicting readers\u2019 sarcasm understandability by modeling gaze behavior", "author": ["Diptesh Kanojia", "Pushpak Bhattacharyya"], "venue": "In Proceedings of AAAI", "citeRegEx": "Mishra et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mishra et al\\.", "year": 2016}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["Pang", "Lee2004] Bo Pang", "Lillian Lee"], "venue": "In Proceedings of the 42nd annual meeting on Association for Computational Linguistics,", "citeRegEx": "Pang et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Pang et al\\.", "year": 2004}, {"title": "Eye movements in reading: Psycholinguistic studies", "author": ["Rayner", "Sereno1994] Keith Rayner", "Sara C Sereno"], "venue": null, "citeRegEx": "Rayner et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Rayner et al\\.", "year": 1994}, {"title": "Sarcasm as contrast between a positive sentiment and negative situation", "author": ["Riloff et al.2013] Ellen Riloff", "Ashequl Qadir", "Prafulla Surve", "Lalindra De Silva", "Nathan Gilbert", "Ruihong Huang"], "venue": null, "citeRegEx": "Riloff et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Riloff et al\\.", "year": 2013}, {"title": "Logistic regression and boosting for labeled bags of instances", "author": ["Xu", "Frank2004] Xin Xu", "Eibe Frank"], "venue": "In Advances in knowledge discovery and data mining,", "citeRegEx": "Xu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2004}], "referenceMentions": [{"referenceID": 16, "context": "This is apparent from the results reported by the survey from Joshi et al. (2016). The following discussion brings more insights into this.", "startOffset": 62, "endOffset": 82}, {"referenceID": 15, "context": "In one of the pioneering works Jorgensen et al. (1984) explained how sarcasm arises when a figurative meaning is", "startOffset": 31, "endOffset": 55}, {"referenceID": 10, "context": "Giora (1995), on the other hand, define sarcasm as a mode of indirect negation that requires processing of both negated and implicated messages.", "startOffset": 0, "endOffset": 13}, {"referenceID": 10, "context": "Giora (1995), on the other hand, define sarcasm as a mode of indirect negation that requires processing of both negated and implicated messages. Ivanko and Pexman (2003) define sarcasm as a six tuple entity consisting of a speaker,", "startOffset": 0, "endOffset": 170}, {"referenceID": 4, "context": "Computational linguists have previously addressed this problem using rule based and statistical techniques, that make use of : (a) Unigrams and Pragmatic features (Carvalho et al., 2009; Gonz\u00e1lez-Ib\u00e1nez et al., 2011; Barbieri et al., 2014; Joshi et al., 2015) (b) Stylistic patterns (Davidov et al.", "startOffset": 163, "endOffset": 259}, {"referenceID": 0, "context": "Computational linguists have previously addressed this problem using rule based and statistical techniques, that make use of : (a) Unigrams and Pragmatic features (Carvalho et al., 2009; Gonz\u00e1lez-Ib\u00e1nez et al., 2011; Barbieri et al., 2014; Joshi et al., 2015) (b) Stylistic patterns (Davidov et al.", "startOffset": 163, "endOffset": 259}, {"referenceID": 16, "context": "Computational linguists have previously addressed this problem using rule based and statistical techniques, that make use of : (a) Unigrams and Pragmatic features (Carvalho et al., 2009; Gonz\u00e1lez-Ib\u00e1nez et al., 2011; Barbieri et al., 2014; Joshi et al., 2015) (b) Stylistic patterns (Davidov et al.", "startOffset": 163, "endOffset": 259}, {"referenceID": 6, "context": ", 2015) (b) Stylistic patterns (Davidov et al., 2010) and patterns related to situational disparity (Riloff et al.", "startOffset": 31, "endOffset": 53}, {"referenceID": 24, "context": ", 2010) and patterns related to situational disparity (Riloff et al., 2013) and (c) Hastag", "startOffset": 54, "endOffset": 75}, {"referenceID": 19, "context": "interpretations (Liebrecht et al., 2013; Maynard and Greenwood, 2014).", "startOffset": 16, "endOffset": 69}, {"referenceID": 2, "context": "Camblin et al. (2007) show that in multi-sentence passages, discourse congruence has robust effects on eye movements.", "startOffset": 0, "endOffset": 22}, {"referenceID": 21, "context": "In our previous work (Mishra et al., 2016), we augment cognitive features, derived from eye-movement patterns of readers, with textual features to detect whether a human reader has realized the presence of sarcasm in text or not.", "startOffset": 21, "endOffset": 42}, {"referenceID": 21, "context": "This hypothesis forms the crux of our method for sarcasm detection and we validate this using our previously released freely available sarcasm dataset2 (Mishra et al., 2016) enriched with gaze", "startOffset": 152, "endOffset": 173}, {"referenceID": 9, "context": ", if sarcasm is expected beforehand, processing incongruity becomes relatively easier (Gibbs, 1986)).", "startOffset": 86, "endOffset": 99}, {"referenceID": 13, "context": "The eye-tracking experiment is conducted by following the standard norms in eye-movement research (Holmqvist et al., 2011).", "startOffset": 98, "endOffset": 122}, {"referenceID": 8, "context": "dataset, when we considered readability (Flesch readability ease-score (Flesch, 1948)), number of words in a sentence and average character per word along with the sarcasm label as the predictors of average fixation duration following a linear mixed effect model (Barr et al.", "startOffset": 71, "endOffset": 85}, {"referenceID": 1, "context": "dataset, when we considered readability (Flesch readability ease-score (Flesch, 1948)), number of words in a sentence and average character per word along with the sarcasm label as the predictors of average fixation duration following a linear mixed effect model (Barr et al., 2013), sarcasm label turned out to be the most significant predictor with a maximum slope.", "startOffset": 263, "endOffset": 282}, {"referenceID": 16, "context": "The features enlisted under lexical,implicit incongruity and explicit incongruity are borrowed from various literature (predominantly from Joshi et al. (2015)).", "startOffset": 139, "endOffset": 159}, {"referenceID": 21, "context": "Some of these features have been reported by Mishra et al. (2016) for modeling sarcasm understandability of readers.", "startOffset": 45, "endOffset": 66}, {"referenceID": 8, "context": "Readability (RED) Real Flesch Readability Ease (Flesch, 1948) score of the sentence Textual Number of Words (LEN) Integer Number of words in the sentence Avg.", "startOffset": 47, "endOffset": 61}, {"referenceID": 12, "context": "Using Weka (Hall et al., 2009) and LibSVM (Chang and Lin, 2011) APIs, we implement the following classifiers:", "startOffset": 11, "endOffset": 30}, {"referenceID": 21, "context": "racy of our system and the best available systems proposed by Riloff et al. (2013) and Joshi et al.", "startOffset": 62, "endOffset": 83}, {"referenceID": 15, "context": "(2013) and Joshi et al. (2015) on our dataset.", "startOffset": 11, "endOffset": 31}, {"referenceID": 16, "context": "\u2022 Sarcasm (the feature-set reported by Joshi et al. (2015) subsuming unigram features and features from other reported systems)", "startOffset": 39, "endOffset": 59}, {"referenceID": 16, "context": "For all the classifiers, our feature combination outperforms the baselines (considering only unigram features) as well as (Joshi et al., 2015), with the MILR classifier getting an F-score improvement of 3.", "startOffset": 122, "endOffset": 142}, {"referenceID": 16, "context": "tection by Joshi et al. (2015) and the output of the MILR classifier with the complete set of features are compared, setting threshold \u03b1 = 0.", "startOffset": 11, "endOffset": 31}, {"referenceID": 16, "context": "We train our classifier with 100%, 90%, 80% and 70% of the training data with our whole feature set, and the feature combination from Joshi et al. (2015). The goodness of our system is demonstrated by improvements in F-score and Kappa statistics, shown in Figure 3.", "startOffset": 134, "endOffset": 154}], "year": 2017, "abstractText": "In this paper, we propose a novel mechanism for enriching the feature vector, for the task of sarcasm detection, with cognitive features extracted from eye-movement patterns of human readers. Sarcasm detection has been a challenging research problem, and its importance for NLP applications such as review summarization, dialog systems and sentiment analysis is well recognized. Sarcasm can often be traced to incongruity that becomes apparent as the full sentence unfolds. This presence of incongruityimplicit or explicitaffects the way readers eyes move through the text. We observe the difference in the behaviour of the eye, while reading sarcastic and non sarcastic sentences. Motivated by this observation, we augment traditional linguistic and stylistic features for sarcasm detection with the cognitive features obtained from readers eye movement data. We perform statistical classification using the enhanced feature set so obtained. The augmented cognitive features improve sarcasm detection by 3.7% (in terms of Fscore), over the performance of the best reported system.", "creator": "LaTeX with hyperref package"}}}