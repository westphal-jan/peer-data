{"id": "1702.02212", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Feb-2017", "title": "MORSE: Semantic-ally Drive-n MORpheme SEgment-er", "abstract": "We psychographic present parce in this sexploitation paper a adobe novel 27.46 framework hatikvah for morpheme 1,065 segmentation which s.g. uses velichko the morpho - atum syntactic ryll regularities 777-300ers preserved einars by akhunzada word brissac representations, in addition ex-serviceman to ersberg orthographic features, to segment lobel words sybaris into suficientes morphemes. 3,486 This framework olusola is 1,181 the pyrolysis first to kurohime consider vocabulary - wide referrer syntactico - semantic sittwe information for this superpremium task. vezzosi We also analyze rotuman the schuurman deficiencies of available hesperian benchmarking datasets sardy and introduce heartwrenching our darchula own dataset 1,039 that was lymphadenitis created anti-trust on cloven the rabbitte basis of compositionality. air-to-surface We validate our algorithm across kcaa datasets and lason present heum state - of - the - gr\u00e4fin art \u00e7iller results.", "histories": [["v1", "Tue, 7 Feb 2017 21:49:13 GMT  (121kb,D)", "https://arxiv.org/abs/1702.02212v1", null], ["v2", "Sat, 11 Feb 2017 00:13:28 GMT  (121kb,D)", "http://arxiv.org/abs/1702.02212v2", null], ["v3", "Mon, 1 May 2017 12:36:34 GMT  (129kb,D)", "http://arxiv.org/abs/1702.02212v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["tarek sakakini", "suma bhat", "pramod viswanath"], "accepted": true, "id": "1702.02212"}, "pdf": {"name": "1702.02212.pdf", "metadata": {"source": "CRF", "title": "MORSE: Semantic-ally Drive-n MORpheme SEgment-er", "authors": ["Tarek Sakakini", "Suma Bhat", "Pramod Viswanath"], "emails": ["sakakini@illinois.edu", "spbhat2@illinois.edu", "pramodv@illinois.edu"], "sections": [{"heading": "1 Introduction", "text": "Morpheme segmentation is a core natural language processing (NLP) task used as an integral component in related-fields such as information retrieval (IR) (Zieman and Bleich, 1997; Kurimo et al., 2007), automatic speech recognition (ASR) (Bilmes and Kirchhoff, 2003; Kurimo et al., 2006), and machine translation (MT) (Lee, 2004; Virpioja et al., 2007). Most previous works have relied solely on orthographic features (Harris, 1970; Goldsmith, 2000; Creutz and Lagus, 2002, 2005, 2007), neglecting the underlying semantic information. This has led to an over-segmentation of words because a change of the surface form pattern is a necessary but insufficient indication of a morphological change. For example, the surface form of \u201cfreshman\u201d, hints that it should be segmented to \u201cfresh-man\u201d, although \u201cfreshman\u201d does not describe semantically the compositional meaning of \u201cfresh\u201d and \u201cman\u201d.\nTo compensate for this lack of semantic knowledge, previous works (Schone and Jurafsky,\n2000; Baroni et al., 2002; Narasimhan et al., 2015) have incorporated semantic knowledge locally by checking the semantic relatedness of possibly morphologically related pair of words. Narasimhan et al. (2015) check for semantic relatedness using cosine similarity in word representations (Mikolov et al., 2013a; Pennington et al., 2014). A limitation of such an approach is the inherent \u201csample noise\u201d in specific word representations (exacerbated in the case of rare words). Moreover, limitation to local comparison enforces modeling morphological relations via semantic relatedness, although it has been shown that difference vectors model morphological relations more accurately (Mikolov et al., 2013b). To address this issue, we introduce a new framework (MORSE), the first to bring semantics into morpheme segmentation both on a local and a vocabulary-wide level. That is, when checking for the morphological relation between two words, we not only check for the semantic relatedness of the pair at hand (local), but also check if the difference vectors of pairs showing similar orthographic change are consistent (vocabulary-wide).\nIn summary, MORSE clusters pairs of words which only vary by an affix; for example, pairs such as (\u201cquick\u201d, \u201cquickly\u201d) and (\u201chopeful\u201d, \u201chopefully\u201d) get clustered together. To verify the cluster of a specific affix from a semantic corpuswide standpoint, we check for the consistency of the difference vectors (Mikolov et al., 2013b). To evaluate it from an orthographic corpus-wide perspective, we check for the size of each cluster of an affix. To evaluate each pair in a cluster locally from a semantic standpoint, we check if a pair of words in a valid affix cluster are morphologically related by checking if its difference vector is consistent with other members in the cluster and if the words in the pair are semantically related (i.e. close in the vector space). The reason for local ar X\niv :1\n70 2.\n02 21\n2v 3\n[ cs\n.C L\n] 1\nM ay\n2 01\n7\nevaluations is exemplified by (\u201con\u201d,\u201conly\u201d) which belongs to the cluster of a valid affix (\u201cly\u201d), although they are not (obviously) morphologically related. We would expect such a pair to fail the last two local evaluation methods.\nOur proposed segmentation algorithm is evaluated using benchmarking datasets from the Morpho Challenge (MC) for multiple languages and a newly introduced dataset for English which compensates for lack of discriminating capabilities in the MC dataset. Experiments reveal that our proposed framework not only outperforms the widely used approach, but also performs better than published state-of-the-art results.\nThe central contribution of this work is a novel framework that performs morpheme segmentation resulting in new state-of-the-art results. To the best of our knowledge this is the first unsupervised approach to consider the vocabulary-wide semantic knowledge of words and their affixes in addition to relying on their surface forms. Moreover we point out the deficiencies in the MC datasets with respect to the compositionality of morphemes and introduce our own dataset free of these deficiencies."}, {"heading": "2 Related Work", "text": "Extensive work has been done in morphology learning, with tasks such as morphological analysis (Baayen et al., 1993), morphological reinflection (Cotterell et al., 2016), and morpheme segmentation. Given the less complex nature of morpheme segmentation in comparison to the other tasks, most systems developed for morpheme segmentation have been unsupervised or minimally supervised (mostly for parameter tuning).\nUnsupervised morpheme segmentation traces back to (Harris, 1970), which falls under the framework of Letter Successor Variety (LSV) which builds on the hypothesis that predictability of successor letters is high within morphemes and low otherwise. The most dominant pieces of work on unsupervised morpheme segmentation, Morfessor (Creutz and Lagus, 2002, 2005, 2007) and Linguistica (Goldsmith, 2000) adopt the Minimum Description Length (MDL) principle (Rissanen, 1998): they aim to minimize describing the lexicon of morphs as well as minimizing the description of an input corpus. Morfessor has a widely used API and has inspired a large body of following work (Kohonen et al., 2010; Gro\u0308nroos\net al., 2014).\nThe unsupervised original implementation was later adapted (Kohonen et al., 2010; Gro\u0308nroos et al., 2014) to allow for minimal supervision. Another work on minimally supervised morpheme segmentation is (Sirts and Goldwater, 2013) which relies on Adaptor Grammars (AGs) (Johnson et al., 2006). AGs learn latent tree structures over an input corpus using a nonparametric Bayesian model (Sirts and Goldwater, 2013).\n(Lafferty et al., 2001) use Conditional Random Fields (CRF) for morpheme segmentation. In this supervised method, the morpheme segmentation task is modeled as a sequence-to-sequence learning problem, whereby the sequence of labels defines the boundaries of morphemes (Ruokolainen et al., 2013, 2014). In contrast to the previously mentioned generative approaches of MDL and AG, this method takes a discriminative approach and allows for the inclusion of a larger set of features. In this approach, CRF learns a conditional probability of a segmentation given a word (Ruokolainen et al., 2013, 2014).\nAll these morpheme segmenters rely solely on orthographic features of morphemes. Semantics were initially introduced to morpheme segmenters by (Schone and Jurafsky, 2000), using LSA to generate word representations and then evaluate if two words are morphologically related based on semantic relatedness, as well as deterministic orthographic methods. Similarly, (Baroni et al., 2002) use edit distance and mutual information as metrics for semantic and orthographic validity of a morphological relation between two words. Recent work in (Narasimhan et al., 2015), inspired by the log-linear model in (Poon et al., 2009) incorporates semantic relatedness into the model via word representations. Other systems such as (U\u0308stu\u0308n and Can, 2016) rely solely on evaluating two words from a semantic standpoint by the use of a twolayer neural network.\nMORSE introduces semantic information into its morpheme segmenters via distributed word representations while also relying on orthographic features. Inspired by the work of (Soricut and Och, 2015), instead of merely evaluating semantic relatedness, we are the first to evaluate the morphological relationship via the difference vector of morphologically related words. Comparing the difference vectors of multiple pairs across the corpus following the same morphological relation, gives\nMORSE a vocabulary-wide evaluation of morphological relations learned."}, {"heading": "3 System", "text": "The key limitation of previous frameworks that rely solely on orthographic features is the resulting over-segmentation. As an example, MDLbased frameworks segment \u201csing\u201d to \u201cs-ing\u201d due to the high frequency of the morphemes: \u201cs\u201d and \u201cing\u201d. Our framework combines semantic relatedness with orthographic relatedness to eliminate such error. For the example mentioned, MORSE validates morphemes such as \u201cs\u201d and \u201cing\u201d from an orthographic perspective, yet invalidates the relation between \u201cs\u201d and \u201csing\u201d from a local and vocabulary-wide semantic perspective. Hence, MORSE will segment \u201cjumping\u201d as \u201cjump-ing\u201d, and perform no segmentations on \u201csing\u201d.\nTo bring in semantic understanding into MORSE, we rely on word representations (Mikolov et al., 2013a; Pennington et al., 2014). These word representations capture the semantics of the vocabulary through statistics over the context in which they appear. Moreover, morphosyntactic regularities have been shown over these word representations, whereby pairs of words sharing the same relationship exhibit equivalent difference vectors (Mikolov et al., 2013b). For example, it is expected in the vector space of word representations that ~wjumping \u00b4 ~wjump \u00ab ~wplaying \u00b4 ~wplay, but ~wsing \u00b4 ~ws ff ~wplaying \u00b4 ~wplay.\nAs a high level description, we first learn all possible affix transformations (morphological rules) in the language from pairs of words from an orthographic standpoint. For example, the pair (\u201cjump\u201d, \u201cjumping\u201d) corresponds to the valid affix transformation \u03c6 suffix\u00dd\u00dd\u00dd\u00d1 \u201cing\u201d (where \u03c6 represents the empty string), and the pair (\u201cslow\u201d, \u201cslogan\u201d) corresponds to the invalid rule \u201cw\u201d suffix\u00dd\u00dd\u00dd\u00d1 \u201cgan\u201d. Then we invalidate the rules, such as \u201cw\u201d suffix\u00dd\u00dd\u00dd\u00d1 \u201cgan\u201d, that do not conform to the linear relation in the vector space. We also invalidate pairs of words which, due to randomness, are orthographically related via a valid rule although they are not morphologically related, such as (\u201con\u201d, \u201conly\u201d).\nNow we formalize the objects we learn in MORSE and the scores (orthographic and semantic) used for validation. This constitutes the training stage. Finally, we formalize the inference stage, where we use these objects and scores to perform morpheme segmentation."}, {"heading": "3.1 Training Stage", "text": "Objects:\n\u2022 Rule set R made of all possible affix transformations in a language. R is populated via the following definition: Rsuffix = {aff1\nsuffix\u00dd\u00dd\u00dd\u00d1 aff2: D (w1, w2) P V2, stem(w1) = stem(w2), w1 = stem(w1) + aff1, w2 = stem(w2) + aff2}, Rprefix is defined similarly for prefixes, and R = Rsuffix Y Rprefix. An example R would be equal to {\u03c6 suffix\u00dd\u00dd\u00dd\u00d1 \u201cly\u201d, \u03c6 prefix\u00dd\u00dd\u00dd\u00d1 \u201cun\u201d, \u201cing\u201d suffix\u00dd\u00dd\u00dd\u00d1 \u201ced\u201d,. . . }.\n\u2022 Support set SSr for a rule r P R consists of all pairs of words related via r on a surface level. SSr is populated via the following definition: SSr = {(w1, w2): w1, w2 P V, w1\nr\u00dd\u00d1 w2}. An example support set of the rule \u201cing\u201d suffix\u00dd\u00dd\u00dd\u00d1 \u201ced\u201d would be {(\u201cplaying\u201d, \u201cplayed\u201d), (\u201ccrafting\u201d, \u201ccrafted\u201d),. . .}.\nScores:\n\u2022 scorer orth(r) is a vocabulary-wide orthographic confidence score for rule r P R. It reflects the validity of an affix transformation in a language from an orthographic perspective. This score is evaluated as scorer orth(r) = |SSr|. \u2022 scorer sem(r) is a vocabulary-wide seman-\ntic confidence score for rule r P R. It reflects the validity of an affix transformation in a language from a semantic perspective. This score is evaluated as: scorer sem(r) = |clusterr|/|SSr|2 where clusterr = {((w1, w2), (w3, w4)): (w1, w2), (w3, w4) P SSr, ~w1 \u00b4 ~w2 \u00ab ~w3 \u00b4 ~w4 }. We consider ~w1 \u00b4 ~w2 \u00ab ~w3 \u00b4 ~w4 if cos(~w4, ~w2 \u00b4 ~w1 ` ~w3) \u0105 0.1. \u2022 scorew sem((w1, w2) P SSr) is a vocabularywide semantic confidence score for a pair of words (w1, w2). The pair of words is related via r on an orthographic level, but the score reflects the validity of the morphological relation via r on a semantic level. This score is evaluated as: scorew sem((w1, w2) P SSr) = |{(w3, w4): (w3, w4) P SSr, ~w1 \u00b4 ~w2 \u00ab ~w3\u00b4 ~w4}|/|SSr|. In other words, it is the fraction of pairs of words in the support set that exhibit a similar linear relation as (w1, w2) in the vector space.\n\u2022 scoreloc sem((w1, w2) P SSr) is a local semantic confidence score for a pair of words (w1, w2). The pair of words is related via r on an orthographic level, but the score reflects the semantic relatedness between the pair. The score is evaluated as: scoreloc sem((w1, w2) P SSr) = cos(~w1, ~w2)."}, {"heading": "3.2 Inference Stage", "text": "In this stage we perform morpheme segmentation using the knowledge gained from the first stage. We begin with some notation: let Radd = {r : r P R, r = aff1\nr\u00dd\u00d1 aff2, aff1 = \u03c6, aff2 \u2030 \u03c6 }, Rrep = {r : r P R, r = aff1\nr\u00dd\u00d1 aff2, aff1 \u2030 \u03c6, aff2 \u2030 \u03c6 }. In other words, we divide the rules to those where an affix is added (Radd) and to those where an affix is replaced (Rrep).\nGiven a word w to segment, we search for r\u02da, the solution to the following optimization problem1. The search space is limited to the rules that include w in their support set, a fairly small search space and the corresponding computation readily tractable:\nmax r\n\u00ff\nt1\nscoret1ppw1, wq P SSrq ` \u00ff\nt2\nscoret2prq\ns. t. r P Radd scorer semprq \u0105 tr sem scorer orthprq \u0105 tr orth scorew semppw1, wq P SSrq \u0105 tw sem scoreloc semppw1, wq P SSrq \u0105 tloc sem\nWhere t1 = {w sem, loc sem}, t2 = {r sem, r orth}, and tr sem, tr orth, tw sem, tloc sem are hyperparameters of the system. Now given r\u02da = \u03c6 suffix\u00dd\u00dd\u00dd\u00d1 suf, w1 is defined as w1 r \u02da \u00dd\u00d1 w. Thus the algorithm segments w \u00d1 w1-suf. We treat prefixes similarly. Next, the algorithm iterates over w1. Figure 1 shows the segmentation process of the word \u201cunhealthy\u201d based on the sequentially retrieved r\u02da.\nThe reason we restrict our rule set to Radd in the optimization problem is to avoid rules such as \u201cer\u201d suffix\u00dd\u00dd\u00dd\u00d1 \u201cing\u201d like in (\u201cplayer\u201d, \u201cplaying\u201d) leading to false segmentations such as \u201cplaying\u201d \u00d1 \u201cplayering\u201d. Yet we cannot completely restrict our search to Radd due to rules such as \u201cy\u201d \u00d1 \u201cies\u201d in words like (\u201csky\u201d, \u201cskies\u201d). To be able to segment words such as \u201cskies\u201d, we\u2019d have to consider rules in Rrep\n1r and w uniquely identify w1, and thus the search space is defined only over r.\nbut only after searching in Radd. Thus if the first optimization problem was unfeasible, we repeat it while replacing Radd with Rrep. The program terminates when both optimization problems are infeasible."}, {"heading": "4 Experiments", "text": "We conduct a variety of experiments to assess the performance of MORSE, and compare it with prior works. First, the performance is assessed intrinsically on the task of morpheme segmentation and against the most widely used morpheme segmenter: Morfessor 2.0. We evaluate the performance across three languages of varying morphology levels: English, Turkish, Finnish, with Finnish being the richest in morphology and English being the poorest. Second, we show the inadequacies of benchmarking gold datasets for this task and describe a new dataset that we create to address the inadequacy. Third, in order to highlight the effect of including semantic information, we compare MORSE against Morfessor on a set of words which should not be segmented from a semantic perspective although orthographically they seem to be segmentable (such as \u201cfreshman\u201d).\nIn all of our experiments (unless specified otherwise), we report precision and recall (and corresponding F1 scores) with locations of morpheme boundaries being considered positives and the rest of the locations considered negatives. It should be noted that we disregard starting and ending positions of words, since they form trivial boundaries (Virpioja et al., 2011)."}, {"heading": "4.1 Setup", "text": "Both systems, Morfessor and MORSE, were trained on the same monolingual corpus: Wikipedia2 (as of September 20, 2016) to control for affecting factors within the experiment. For each language considered, the respective Wikipedia dump was preprocessed using an available code3. We use Word2Vec (Mikolov\n2https://dumps.wikimedia.org 3https://github.com/bwbaugh/\nwikipedia-extractor\net al., 2013a) to train word representations of 300 dimensions and based on a context window of size 5. Also, for computational efficiency, MORSE was limited to a vocabulary of size 1M, a restriction not enforced on Morfessor.\nMORSE\u2019s hyperparameters are tuned based on a tuning set of gold morpheme segmentations. We have publicly released the source code of a pretrained MORSE4 as described in this paper."}, {"heading": "4.2 Morpho Challenge Dataset", "text": "As our first intrinsic experiment, we consider the Morpho Challenge (MC) gold segmentations available online5. For every language, two datasets are supplied: training and development. For the purpose of our experiments, all systems use the development dataset as a test dataset, and the training dataset is used for tuning MORSE\u2019s hyperparameters. MC dataset sizes are reported in Table 1."}, {"heading": "4.3 Semantically Driven Dataset", "text": "There are a variety of weaknesses in the MC dataset, specifically related to whether the segmentation is semantically appropriate or not. We introduce a new semantically driven dataset (SD17) for morpheme segmentation along with the methodology used for creation; this new dataset is publicly available in the canonical6 and non-canonical7 versions (Cotterell and Vieira, 2016). Non-compositional segmentation: One of the key requirements of morpheme segmentation is the compositionality of the meaning of the word from the meaning of its morphemes. This requirement is violated on multiple occasions in the MC dataset. One example from Table 2 is segmenting the word \u201cbusiness\u201d into \u201cbusi-ness\u201d, which falsely assumes that \u201cbusiness\u201d means the act of being busy. Such a segmentation might be consistent with the historic origin of the word, but with\n4https://goo.gl/w4r7vP 5http://research.ics.aalto.fi/events/\nmorphochallenge2010 6https://goo.gl/MgKfG1 7https://goo.gl/0vTXVt\nradical semantic changes over time, the segmentation no longer semantically represents the compositionality of the words\u2019 components (Wijaya and Yeniterzi, 2011). Not only does such a weakness contribute to false segmentations, but it also favors segmentation methods following the MDL principle. Trivial instances: The second weakness in the MC dataset is due to abundance of trivial instances. These instances lack discriminating capability since all methods can easily predict them (Baker, 2001). These instances are comprised of genetive cases (such as teacher\u2019s) as well as hyphenated words (such as turning-point). For genetive cases, segmenting at the apostrophe leads to perfect precision and recall, and thus such instances are deemed trivial. In the case of hyphenated words, segmenting at the hyphen is a correct segmentation with a very high probability. In the MC tuning dataset, in 43 times out of 46, the hyphen was a correct indication of segmentation. Other issues exist in the Morpho Challenge dataset although less abundantly. There are instances of wrong segmentations possibly due to human error. One example of such instance is \u201cturning-point\u201d segmented to \u201cturning - point\u201d instead of \u201cturn ing - point\u201d. Another issue, which is hard to avoid, is ambiguity of segmentation boundaries. Take for example the word \u201cstrafed\u201d, the segmentations \u201cstraf-ed\u201d and \u201cstrafe-d\u201d are equally justified. In such situations, the MC dataset favors complete affixes rather than complete lemmas. This also favors MDL-based segmenters. We note that the MC dataset also provides segmentations in a canonical version such as \u201cstrafe-ed\u201d, yet for the sake of a fair comparison with Morfessor and all previously evaluated systems on the MC dataset, we consider only the former version of segmentations.\nDue to these reasons, we create a new dataset SD17 for English gold morpheme segmentations with compositionality guiding the annotations. We select 2000 words randomly from the 10K most frequent words in the English Wikipedia dump and have them annotated by two proficient English speakers. The segmentation criterion was to segment the word to the largest extent possible while preserving its compositionality from the segments. The inter-annotator agreement reached 91% on a word level. Based on post annotation discussions, annotators agreed on 99% of the words, and words not agreed on were eliminated along with words containing non-alpha characters to avoid trivial instances.\nSD17 is used to evaluate the performance of both Morfessor and MORSE. We claim that the performance on SD17 is a better indication of the performance of a morpheme segmenter. By the use of SD17 we expect to gain insights on the extent to which morpheme segmentation is a function of semantics in addition to orthography."}, {"heading": "4.4 Handling Compositionality", "text": "We have hypothesized that following the MDL principle (such as Morfessor) leads to oversegmentation. This over-segmentation happens specifically when the meaning of the word does not follow from the meaning of its morphemes. Examples include words such as \u201cred head\u201d, \u201cduck face\u201d, \u201chow ever\u201d, \u201cs ing\u201d. A subset of these words are defined by linguists as exocentric compounds (Bauer, 2008). MORSE does not suffer from this issue owing to its use of a semantic model.\nWe use a collection of 100 English words which appear to be segmentable but actually are not (example: \u201chowever\u201d). Such a collection will highlight a system\u2019s capability of distinguishing frequent letter sequences from the semantic contribution of this letter sequence in a word. We make this collection publicly available8.\n8https://goo.gl/EFbacj"}, {"heading": "5 Results", "text": "We compare MORSE with Morfessor, and place the performance alongside the state-of-the-art published results."}, {"heading": "5.1 Morpho Challenge Dataset", "text": "As demonstrated in Table 3, MORSE performs better than Mofessor on English and Turkish, and worse on Finnish. Considering English first, using MORSE instead of Morfessor, resulted in a 6% absolute increase in F1 scores. This supports our claim for the need of semantic cues in morpheme segmentation, and also validates the method used in this paper. Since English is a less systematic language in terms of the orthographic structure of words, semantic cues are of greater need, and hence a system which relies on semantic cues is expected to perform better; indeed this is the case. Similarly, MORSE performs better on Turkish with a 7% absolute margin in terms of F1 score. On the other hand, Morfessor surpasses MORSE in performance on Finnish by a large margin as well, especially in terms of recall."}, {"heading": "5.1.1 Discussion", "text": "We hypothesize that the richness of morphology in Finnish led to suboptimal performance of MORSE. This is because richness in morphology leads to word level sparsity which directly leads to: (1) Degradation of quality of word representations (2) Increased vocabulary size exacerbating the issue of limited vocabulary (recall MORSE was limited to a vocabulary of 1M). In a language with productive morphology, limiting its vocabulary results in a lower chance of finding morphologically related word pairs. This negatively im-\npacts the training stage of MORSE which relies on the availability of such pairs. In order to detect the suffix \u201cly\u201d from the word \u201ccheerfully\u201d MORSE needs to come across \u201ccheerful\u201d as well. Coming across \u201ccheerful\u201d is now a lower probability event due to high sparsity. This is not as much of an issue for Morfessor under the MDL principle, since it might detect \u201cly\u201d just by coming across multiple words ending with \u201cly\u201d even without encountering the base forms of those words. We show how the detection of rules is affected by considering the number of candidate rules detected as well as the number of candidate morphologically related word pairs detected. As shown in Table 4, the number of detected candidate rules and candidate related words decreases with the increase in morphology in a language. This confirms our hypothesis; we note that this issue can be directly attributed to the limited vocabulary size in MORSE. With the increase in processing power, and thus larger vocabulary coverage, MORSE is expected to perform better."}, {"heading": "5.2 Semantically Driven Dataset", "text": "The performance of MORSE and Morfessor on SD17 is shown in Table 5. The use of MC data (which does not adhere to the compositionality principle) to tune MORSE to be evaluated on SD17 (which does adhere to the compositionality principle) is not optimal. Thus, we evaluate MORSE on SD17 using 5-fold cross validation, where 80% of the dataset is used to tune and 20% is used to evaluate. Precision, Recall, and F1 scores are averaged and reported in Table 5 using the label MORSE-CV.\nBased on the results in Table 5, we make the following observations. Comparing MORSE-CV to MORSE reflects the fundamental difference between SD17 and MC datasets. Knowing the basis of construction of SD17 and the fundamental weaknesses in MC datasets, we attribute the performance increase to the lack of compositionality in MC dataset. Comparing MORSE-CV to Morfessor, we observe a significant jump in performance (an increase of 24%). In comparison, the increase on the MC dataset (6%) shows that the Morpho Challenge dataset underestimates the performance gap between Morfessor and MORSE due its inherent weaknesses.\nSince MORSE is equipped with the capability to retrieve full morphemes even when not present\nin full orthographically, a capability that Morfessor lacks, we evaluated both systems on the canonical version of SD17. The results are reported in Table 6. We notice that evaluating on the canonical form of SD17 gives a further edge for MORSE over Morfessor. For evaluation on the canonical version of SD17, we switch to morpheme-level evaluation instead of boundary-level as a more suitable method for Morfessor. Morpheme-level evaluation is distinguished from boundary-level evaluation in that we evaluate the detection of morphemes instead of the boundary locations in the segmented word.\nWe next compare MORSE against published state-of-the-art results9. As one can see in Table 7 MORSE significantly performs better than published state-of-the-art results, most notably (Narasimhan et al., 2015) referred to as LLSM in the Table. Comparison is also made against the top results in the latest Morpho Challenge: Morfessor S+W and Morfessor S+W+L (Kohonen et al., 2010), and Base Inference (Lignos, 2010)."}, {"heading": "5.3 Handling Compositionality", "text": "We compare the performance of MORSE and Morfessor on a set of words made up of morphemes which don\u2019t compose the meaning of the word. Since all the boundaries in this dataset are negative, to evaluate both systems (with MORSE tuned on SD17), we only report the number of segments generated. The more segments a system generates, the worse is its performance.\nWe find that MORSE generates 7 false morphemes whereas Morfessor generates 43 false morphemes. This shows MORSE\u2019s robustness to such examples through its semantic knowledge and validates our claim that Morfessor oversegments on such examples."}, {"heading": "6 Discussion", "text": "One of the benefits of MORSE against other frameworks such as MDL is its ability to identify the lemma within the segmentation. The lemma would be the last non-segmented word in the iterative process of segmentation. Hence, an advantage of our framework is its easy adaptability into a lemmatizer and even a stemmer.\nAnother key aspect which is not present in some of the competitive systems is the need for a small tuning dataset. This is a point in favor of completely unsupervised systems such as Morfessor. On the other hand, these hyperparameters could allow for flexibility. Figure 2 shows how precision and recall changes as a function of the hyperparameter selection10. As one would expect, increasing the hyperparameters, in general, leads\n9The five published state-of-the-art results are on different datasets\n10Only a subset of the hyperparameters is used for display purposes\nto a stricter search space and thus increases precision and decreases recall. Putting these results in perspective, the user of MORSE is given the capability of controlling for precision and recall based on the needs of the downstream task.\nMoreover, to check for the level of dependency of MORSE on a set of gold morpheme segmentations for tuning, we check for the variation in performance with respect to size of tuning data. For the purpose of this experiment we take an 80- 20 split of SD17 and vary the size of the tuning set. We notice that the performance (81.90% F1) reaches a steady state at 20% (\u00ab 300 gold segmentations) of the tuning data. This reflects the minimal dependency on a tuning dataset.\nRegarding the training stage, homomorphs are treated as one rule and allomorphs are treated as separate rules. For example, (\u201ctall\u201d, \u201ctaller\u201d) and (\u201cfast\u201d, \u201cfaster\u201d) are wrongly considered to have the same morphological relation, besides (\u201ccat\u201d, \u201ccats\u201d) and (\u201cbutterfly\u201d, \u201cbutterflies\u201d) are wrongly considered to have different morphological relations. The separate clustering of the different forms of a homomorph leads to the underestimation of the respective orthographic scores. Moreover, the clustering of allomorphs together would lead to the underestimation of the semantic score of the rule as well as the underestimation of the vocabulary-wide semantic score of word pairs in the support set of this rule. This does not significantly affect the performance of MORSE, since the tuned thresholds are able to distinguish between the low scores of an invalid rule and the mediocre underestimated scores of allomorphs and homomorphs.\nAs for the inference stage of MORSE, the greedy inference approach limits its performance. In other words, a wrong segmentation at the be-\nginning will propagate and result in consequent wrong segmentations. Also, MORSE\u2019s limitation to concatenative morphology decreases its efficacy on languages that include non-concatenative morphology. This opens the stage for further research on a more optimal inference stage and a more global modeling of orthographic morphological transformations."}, {"heading": "7 Conclusions and Future Work", "text": "In this paper, we have presented MORSE, a first morpheme segmenter to consider semantic structure at this scale (local and vocabulary-wide). We show its superiority over state-of-the-art algorithms using intrinsic evaluation on a variety of languages. We also pinpointed the weaknesses in current benchmarking datasets, and presented a new dataset free of these weaknesses. With a relative increase in performance reaching 24% absolute increase over Morfessor, this work proves the significance of semantic cues as well as validates a new state-of-the-art morpheme segmenter. For future work, we plan to address the limitations of MORSE: minimal supervision, greedy inference, and concatenative orthographic model. Moreover, we plan to computationally optimize the training stage for the sake of wider adoption by the community."}, {"heading": "Acknowledgements", "text": "This work is supported in part by IBM-ILLINOIS Center for Cognitive Computing Systems Research (C3SR) - a research collaboration as part of the IBM Cognitive Horizons Network."}], "references": [{"title": "The CELEX lexical database [cd-rom] Philadelphia: University of Pennsylvania", "author": ["RH Baayen", "R Piepenbrock", "H Van Rijn."], "venue": "Linguistic Data Consortium .", "citeRegEx": "Baayen et al\\.,? 1993", "shortCiteRegEx": "Baayen et al\\.", "year": 1993}, {"title": "The basics of item response theory", "author": ["Frank B Baker."], "venue": "ERIC.", "citeRegEx": "Baker.,? 2001", "shortCiteRegEx": "Baker.", "year": 2001}, {"title": "Unsupervised discovery of morphologically related words based on orthographic and semantic similarity", "author": ["Marco Baroni", "Johannes Matiasek", "Harald Trost."], "venue": "Proceedings of the ACL-02 Workshop on Morphological and Phonological Learning-", "citeRegEx": "Baroni et al\\.,? 2002", "shortCiteRegEx": "Baroni et al\\.", "year": 2002}, {"title": "Exocentric compounds", "author": ["Laurie Bauer."], "venue": "Morphology 18(1):51\u201374.", "citeRegEx": "Bauer.,? 2008", "shortCiteRegEx": "Bauer.", "year": 2008}, {"title": "Factored language models and generalized parallel backoff", "author": ["Jeff A Bilmes", "Katrin Kirchhoff."], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technol-", "citeRegEx": "Bilmes and Kirchhoff.,? 2003", "shortCiteRegEx": "Bilmes and Kirchhoff.", "year": 2003}, {"title": "The SIGMORPHON 2016 shared task\u2014 morphological reinflection", "author": ["Ryan Cotterell", "Christo Kirov", "John Sylak-Glassman", "David Yarowsky", "Jason Eisner", "Mans Hulden."], "venue": "Proceedings of the 2016 Meeting of SIGMORPHON. Association for", "citeRegEx": "Cotterell et al\\.,? 2016", "shortCiteRegEx": "Cotterell et al\\.", "year": 2016}, {"title": "A joint model of orthography and morphological segmentation", "author": ["Ryan Cotterell", "Tim Vieira."], "venue": "Proceedings of NAACL-HLT . pages 664\u2013669.", "citeRegEx": "Cotterell and Vieira.,? 2016", "shortCiteRegEx": "Cotterell and Vieira.", "year": 2016}, {"title": "Unsupervised discovery of morphemes", "author": ["Mathias Creutz", "Krista Lagus."], "venue": "Proceedings of the ACL-02 Workshop on Morphological and Phonological Learning-Volume 6. Association for Computational Linguistics, pages 21\u201330.", "citeRegEx": "Creutz and Lagus.,? 2002", "shortCiteRegEx": "Creutz and Lagus.", "year": 2002}, {"title": "Unsupervised morpheme segmentation and morphology induction from text corpora using Morfessor 1.0", "author": ["Mathias Creutz", "Krista Lagus"], "venue": "Helsinki University of Technology", "citeRegEx": "Creutz and Lagus.,? \\Q2005\\E", "shortCiteRegEx": "Creutz and Lagus.", "year": 2005}, {"title": "Unsupervised models for morpheme segmentation and morphology learning", "author": ["Mathias Creutz", "Krista Lagus."], "venue": "ACM Transactions on Speech and Language Processing (TSLP) 4(1):3.", "citeRegEx": "Creutz and Lagus.,? 2007", "shortCiteRegEx": "Creutz and Lagus.", "year": 2007}, {"title": "Linguistica: An automatic morphological analyzer", "author": ["John Goldsmith."], "venue": "Proceedings of 36th meeting of the Chicago Linguistic Society.", "citeRegEx": "Goldsmith.,? 2000", "shortCiteRegEx": "Goldsmith.", "year": 2000}, {"title": "Morfessor Flatcat: An HMM-based method for unsupervised and semisupervised learning of morphology", "author": ["Stig-Arne Gr\u00f6nroos", "Sami Virpioja", "Peter Smit", "Mikko Kurimo."], "venue": "COLING. pages 1177\u20131185.", "citeRegEx": "Gr\u00f6nroos et al\\.,? 2014", "shortCiteRegEx": "Gr\u00f6nroos et al\\.", "year": 2014}, {"title": "From phoneme to morpheme", "author": ["Zellig S Harris."], "venue": "Papers in Structural and Transformational Linguistics, Springer, pages 32\u201367.", "citeRegEx": "Harris.,? 1970", "shortCiteRegEx": "Harris.", "year": 1970}, {"title": "Adaptor grammars: A framework for specifying compositional nonparametric bayesian models", "author": ["Mark Johnson", "Thomas L Griffiths", "Sharon Goldwater."], "venue": "Advances in neural information processing systems. pages 641\u2013648.", "citeRegEx": "Johnson et al\\.,? 2006", "shortCiteRegEx": "Johnson et al\\.", "year": 2006}, {"title": "Semi-supervised learning of concatenative morphology", "author": ["Oskar Kohonen", "Sami Virpioja", "Krista Lagus."], "venue": "Proceedings of the 11th Meeting of the ACL Special Interest Group on Computational Morphology and Phonology. Association for Com-", "citeRegEx": "Kohonen et al\\.,? 2010", "shortCiteRegEx": "Kohonen et al\\.", "year": 2010}, {"title": "Unsupervised morpheme analysis evaluation by IR experiments-Morpho Challenge 2007", "author": ["Mikko Kurimo", "Mathias Creutz", "Ville T Turunen."], "venue": "CLEF (Working Notes).", "citeRegEx": "Kurimo et al\\.,? 2007", "shortCiteRegEx": "Kurimo et al\\.", "year": 2007}, {"title": "Unsupervised segmentation of words into morphemes\u2013 challenge 2005: An introduction and evaluation report", "author": ["Mikko Kurimo", "Mathias Creutz", "Matti Varjokallio", "Ebru Arisoy", "Murat Sara\u00e7lar."], "venue": "Proceedings of the PASCAL Challenge", "citeRegEx": "Kurimo et al\\.,? 2006", "shortCiteRegEx": "Kurimo et al\\.", "year": 2006}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John Lafferty", "Andrew McCallum", "Fernando Pereira."], "venue": "Proceedings of the eighteenth International Conference on Machine Learning, ICML.", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Morphological analysis for statistical machine translation", "author": ["Young-Suk Lee."], "venue": "Proceedings of HLTNAACL 2004: Short Papers. Association for Computational Linguistics, pages 57\u201360.", "citeRegEx": "Lee.,? 2004", "shortCiteRegEx": "Lee.", "year": 2004}, {"title": "Learning from unseen data", "author": ["Constantine Lignos."], "venue": "Proceedings of the Morpho Challenge 2010 Workshop. pages 35\u201338.", "citeRegEx": "Lignos.,? 2010", "shortCiteRegEx": "Lignos.", "year": 2010}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781 .", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Linguistic regularities in continuous space word representations", "author": ["Tomas Mikolov", "Wen-tau Yih", "Geoffrey Zweig."], "venue": "HLT-NAACL. volume 13, pages 746\u2013751.", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "An unsupervised method for uncovering morphological chains", "author": ["Karthik Narasimhan", "Regina Barzilay", "Tommi Jaakkola."], "venue": "Transactions of the Association for Computational Linguistics 3.", "citeRegEx": "Narasimhan et al\\.,? 2015", "shortCiteRegEx": "Narasimhan et al\\.", "year": 2015}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "EMNLP. volume 14, pages 1532\u2013 1543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Unsupervised morphological segmentation with log-linear models", "author": ["Hoifung Poon", "Colin Cherry", "Kristina Toutanova."], "venue": "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Associa-", "citeRegEx": "Poon et al\\.,? 2009", "shortCiteRegEx": "Poon et al\\.", "year": 2009}, {"title": "Stochastic complexity in statistical inquiry, volume 15", "author": ["Jorma Rissanen."], "venue": "World scientific.", "citeRegEx": "Rissanen.,? 1998", "shortCiteRegEx": "Rissanen.", "year": 1998}, {"title": "Supervised morphological segmentation in a low-resource learning setting using conditional random fields", "author": ["Teemu Ruokolainen", "Oskar Kohonen", "Sami Virpioja", "Mikko Kurimo."], "venue": "CoNLL. pages 29\u201337.", "citeRegEx": "Ruokolainen et al\\.,? 2013", "shortCiteRegEx": "Ruokolainen et al\\.", "year": 2013}, {"title": "Painless semi-supervised morphological segmentation using conditional random fields", "author": ["Teemu Ruokolainen", "Oskar Kohonen", "Sami Virpioja", "Mikko Kurimo."], "venue": "EACL. pages 84\u201389.", "citeRegEx": "Ruokolainen et al\\.,? 2014", "shortCiteRegEx": "Ruokolainen et al\\.", "year": 2014}, {"title": "Knowledge-free induction of morphology using latent semantic analysis", "author": ["Patrick Schone", "Daniel Jurafsky."], "venue": "Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational Natural", "citeRegEx": "Schone and Jurafsky.,? 2000", "shortCiteRegEx": "Schone and Jurafsky.", "year": 2000}, {"title": "Minimallysupervised morphological segmentation using adaptor grammars", "author": ["Kairit Sirts", "Sharon Goldwater."], "venue": "Transactions of the Association for Computational Linguistics 1:255\u2013266.", "citeRegEx": "Sirts and Goldwater.,? 2013", "shortCiteRegEx": "Sirts and Goldwater.", "year": 2013}, {"title": "Unsupervised morphology induction using word embeddings", "author": ["Radu Soricut", "Franz Josef Och."], "venue": "HLT-NAACL. pages 1627\u20131637.", "citeRegEx": "Soricut and Och.,? 2015", "shortCiteRegEx": "Soricut and Och.", "year": 2015}, {"title": "Unsupervised morphological segmentation using neural word embeddings", "author": ["Ahmet \u00dcst\u00fcn", "Burcu Can."], "venue": "International Conference on Statistical Language and Speech Processing. Springer, pages 43\u201353.", "citeRegEx": "\u00dcst\u00fcn and Can.,? 2016", "shortCiteRegEx": "\u00dcst\u00fcn and Can.", "year": 2016}, {"title": "Empirical comparison of evaluation methods for unsupervised learning of morphology", "author": ["Sami Virpioja", "Ville T Turunen", "Sebastian Spiegler", "Oskar Kohonen", "Mikko Kurimo."], "venue": "TAL 52(2):45\u201390.", "citeRegEx": "Virpioja et al\\.,? 2011", "shortCiteRegEx": "Virpioja et al\\.", "year": 2011}, {"title": "Morphology-aware statistical machine translation based on morphs induced in an unsupervised manner", "author": ["Sami Virpioja", "Jaakko J V\u00e4yrynen", "Mathias Creutz", "Markus Sadeniemi."], "venue": "Machine Translation Summit XI 2007:491\u2013498.", "citeRegEx": "Virpioja et al\\.,? 2007", "shortCiteRegEx": "Virpioja et al\\.", "year": 2007}, {"title": "Understanding semantic change of words over centuries", "author": ["Derry Tanti Wijaya", "Reyyan Yeniterzi."], "venue": "Proceedings of the 2011 International Workshop on DETecting and Exploiting Cultural diversiTy on the Social Web. ACM, New", "citeRegEx": "Wijaya and Yeniterzi.,? 2011", "shortCiteRegEx": "Wijaya and Yeniterzi.", "year": 2011}, {"title": "Conceptual mapping of user\u2019s queries to medical subject headings", "author": ["Yuri L Zieman", "Howard L Bleich."], "venue": "Proceedings of the AMIA Annual Fall Symposium. American Medical Informatics Association, page 519.", "citeRegEx": "Zieman and Bleich.,? 1997", "shortCiteRegEx": "Zieman and Bleich.", "year": 1997}], "referenceMentions": [{"referenceID": 35, "context": "Morpheme segmentation is a core natural language processing (NLP) task used as an integral component in related-fields such as information retrieval (IR) (Zieman and Bleich, 1997; Kurimo et al., 2007), automatic speech recognition (ASR) (Bilmes and Kirchhoff, 2003; Kurimo et al.", "startOffset": 154, "endOffset": 200}, {"referenceID": 15, "context": "Morpheme segmentation is a core natural language processing (NLP) task used as an integral component in related-fields such as information retrieval (IR) (Zieman and Bleich, 1997; Kurimo et al., 2007), automatic speech recognition (ASR) (Bilmes and Kirchhoff, 2003; Kurimo et al.", "startOffset": 154, "endOffset": 200}, {"referenceID": 4, "context": ", 2007), automatic speech recognition (ASR) (Bilmes and Kirchhoff, 2003; Kurimo et al., 2006), and machine translation (MT) (Lee, 2004; Virpioja et al.", "startOffset": 44, "endOffset": 93}, {"referenceID": 16, "context": ", 2007), automatic speech recognition (ASR) (Bilmes and Kirchhoff, 2003; Kurimo et al., 2006), and machine translation (MT) (Lee, 2004; Virpioja et al.", "startOffset": 44, "endOffset": 93}, {"referenceID": 18, "context": ", 2006), and machine translation (MT) (Lee, 2004; Virpioja et al., 2007).", "startOffset": 38, "endOffset": 72}, {"referenceID": 33, "context": ", 2006), and machine translation (MT) (Lee, 2004; Virpioja et al., 2007).", "startOffset": 38, "endOffset": 72}, {"referenceID": 12, "context": "Most previous works have relied solely on orthographic features (Harris, 1970; Goldsmith, 2000; Creutz and Lagus, 2002, 2005, 2007), neglecting the underlying semantic information.", "startOffset": 64, "endOffset": 131}, {"referenceID": 10, "context": "Most previous works have relied solely on orthographic features (Harris, 1970; Goldsmith, 2000; Creutz and Lagus, 2002, 2005, 2007), neglecting the underlying semantic information.", "startOffset": 64, "endOffset": 131}, {"referenceID": 28, "context": "To compensate for this lack of semantic knowledge, previous works (Schone and Jurafsky, 2000; Baroni et al., 2002; Narasimhan et al., 2015) have incorporated semantic knowledge locally by checking the semantic relatedness of possibly morphologically related pair of words.", "startOffset": 66, "endOffset": 139}, {"referenceID": 2, "context": "To compensate for this lack of semantic knowledge, previous works (Schone and Jurafsky, 2000; Baroni et al., 2002; Narasimhan et al., 2015) have incorporated semantic knowledge locally by checking the semantic relatedness of possibly morphologically related pair of words.", "startOffset": 66, "endOffset": 139}, {"referenceID": 22, "context": "To compensate for this lack of semantic knowledge, previous works (Schone and Jurafsky, 2000; Baroni et al., 2002; Narasimhan et al., 2015) have incorporated semantic knowledge locally by checking the semantic relatedness of possibly morphologically related pair of words.", "startOffset": 66, "endOffset": 139}, {"referenceID": 2, "context": "To compensate for this lack of semantic knowledge, previous works (Schone and Jurafsky, 2000; Baroni et al., 2002; Narasimhan et al., 2015) have incorporated semantic knowledge locally by checking the semantic relatedness of possibly morphologically related pair of words. Narasimhan et al. (2015) check for semantic relatedness using cosine similarity in word represen-", "startOffset": 94, "endOffset": 298}, {"referenceID": 20, "context": "tations (Mikolov et al., 2013a; Pennington et al., 2014).", "startOffset": 8, "endOffset": 56}, {"referenceID": 23, "context": "tations (Mikolov et al., 2013a; Pennington et al., 2014).", "startOffset": 8, "endOffset": 56}, {"referenceID": 21, "context": "modeling morphological relations via semantic relatedness, although it has been shown that difference vectors model morphological relations more accurately (Mikolov et al., 2013b).", "startOffset": 156, "endOffset": 179}, {"referenceID": 21, "context": "To verify the cluster of a specific affix from a semantic corpuswide standpoint, we check for the consistency of the difference vectors (Mikolov et al., 2013b).", "startOffset": 136, "endOffset": 159}, {"referenceID": 0, "context": "ysis (Baayen et al., 1993), morphological reinflection (Cotterell et al.", "startOffset": 5, "endOffset": 26}, {"referenceID": 5, "context": ", 1993), morphological reinflection (Cotterell et al., 2016), and morpheme segmentation.", "startOffset": 36, "endOffset": 60}, {"referenceID": 12, "context": "Unsupervised morpheme segmentation traces back to (Harris, 1970), which falls under the framework of Letter Successor Variety (LSV) which builds on the hypothesis that predictability of successor letters is high within morphemes and low otherwise.", "startOffset": 50, "endOffset": 64}, {"referenceID": 10, "context": "The most dominant pieces of work on unsupervised morpheme segmentation, Morfessor (Creutz and Lagus, 2002, 2005, 2007) and Linguistica (Goldsmith, 2000) adopt the Minimum Description Length (MDL) principle (Rissanen, 1998): they aim to minimize describing the lexicon of morphs as well as minimizing the description of an input corpus.", "startOffset": 135, "endOffset": 152}, {"referenceID": 25, "context": "The most dominant pieces of work on unsupervised morpheme segmentation, Morfessor (Creutz and Lagus, 2002, 2005, 2007) and Linguistica (Goldsmith, 2000) adopt the Minimum Description Length (MDL) principle (Rissanen, 1998): they aim to minimize describing the lexicon of morphs as well as minimizing the description of an input corpus.", "startOffset": 206, "endOffset": 222}, {"referenceID": 14, "context": "Morfessor has a widely used API and has inspired a large body of following work (Kohonen et al., 2010; Gr\u00f6nroos et al., 2014).", "startOffset": 80, "endOffset": 125}, {"referenceID": 11, "context": "Morfessor has a widely used API and has inspired a large body of following work (Kohonen et al., 2010; Gr\u00f6nroos et al., 2014).", "startOffset": 80, "endOffset": 125}, {"referenceID": 14, "context": "The unsupervised original implementation was later adapted (Kohonen et al., 2010; Gr\u00f6nroos et al., 2014) to allow for minimal supervision.", "startOffset": 59, "endOffset": 104}, {"referenceID": 11, "context": "The unsupervised original implementation was later adapted (Kohonen et al., 2010; Gr\u00f6nroos et al., 2014) to allow for minimal supervision.", "startOffset": 59, "endOffset": 104}, {"referenceID": 29, "context": "Another work on minimally supervised morpheme segmentation is (Sirts and Goldwater, 2013) which relies on Adaptor Grammars (AGs) (Johnson et al.", "startOffset": 62, "endOffset": 89}, {"referenceID": 13, "context": "Another work on minimally supervised morpheme segmentation is (Sirts and Goldwater, 2013) which relies on Adaptor Grammars (AGs) (Johnson et al., 2006).", "startOffset": 129, "endOffset": 151}, {"referenceID": 29, "context": "AGs learn latent tree structures over an input corpus using a nonparametric Bayesian model (Sirts and Goldwater, 2013).", "startOffset": 91, "endOffset": 118}, {"referenceID": 17, "context": "(Lafferty et al., 2001) use Conditional Random Fields (CRF) for morpheme segmentation.", "startOffset": 0, "endOffset": 23}, {"referenceID": 28, "context": "Semantics were initially introduced to morpheme segmenters by (Schone and Jurafsky, 2000), using LSA to generate word representations and then evaluate", "startOffset": 62, "endOffset": 89}, {"referenceID": 2, "context": "Similarly, (Baroni et al., 2002) use edit distance and mutual information as metrics for semantic and orthographic validity of a morphological relation between two words.", "startOffset": 11, "endOffset": 32}, {"referenceID": 22, "context": "Recent work in (Narasimhan et al., 2015), inspired by the log-linear model in (Poon et al.", "startOffset": 15, "endOffset": 40}, {"referenceID": 24, "context": ", 2015), inspired by the log-linear model in (Poon et al., 2009) incorporates semantic relatedness into the model via word representations.", "startOffset": 45, "endOffset": 64}, {"referenceID": 31, "context": "Other systems such as (\u00dcst\u00fcn and Can, 2016) rely solely on evaluating two words from a semantic standpoint by the use of a twolayer neural network.", "startOffset": 22, "endOffset": 43}, {"referenceID": 30, "context": "Inspired by the work of (Soricut and Och, 2015), instead of merely evaluating semantic relatedness, we are the first to evaluate the morphological relationship via the difference vector of morphologically related words.", "startOffset": 24, "endOffset": 47}, {"referenceID": 20, "context": "To bring in semantic understanding into MORSE, we rely on word representations (Mikolov et al., 2013a; Pennington et al., 2014).", "startOffset": 79, "endOffset": 127}, {"referenceID": 23, "context": "To bring in semantic understanding into MORSE, we rely on word representations (Mikolov et al., 2013a; Pennington et al., 2014).", "startOffset": 79, "endOffset": 127}, {"referenceID": 21, "context": "sharing the same relationship exhibit equivalent difference vectors (Mikolov et al., 2013b).", "startOffset": 68, "endOffset": 91}, {"referenceID": 32, "context": "It should be noted that we disregard starting and ending positions of words, since they form trivial boundaries (Virpioja et al., 2011).", "startOffset": 112, "endOffset": 135}, {"referenceID": 6, "context": "We introduce a new semantically driven dataset (SD17) for morpheme segmentation along with the methodology used for creation; this new dataset is publicly available in the canonical6 and non-canonical7 versions (Cotterell and Vieira, 2016).", "startOffset": 211, "endOffset": 239}, {"referenceID": 34, "context": "radical semantic changes over time, the segmentation no longer semantically represents the compositionality of the words\u2019 components (Wijaya and Yeniterzi, 2011).", "startOffset": 133, "endOffset": 161}, {"referenceID": 1, "context": "These instances lack discriminating capability since all methods can easily predict them (Baker, 2001).", "startOffset": 89, "endOffset": 102}, {"referenceID": 3, "context": "A subset of these words are defined by linguists as exocentric compounds (Bauer, 2008).", "startOffset": 73, "endOffset": 86}, {"referenceID": 22, "context": "As one can see in Table 7 MORSE significantly performs better than published state-of-the-art results, most notably (Narasimhan et al., 2015) referred to as LLSM in the Table.", "startOffset": 116, "endOffset": 141}, {"referenceID": 14, "context": "Comparison is also made against the top results in the latest Morpho Challenge: Morfessor S+W and Morfessor S+W+L (Kohonen et al., 2010), and Base Inference (Lignos, 2010).", "startOffset": 114, "endOffset": 136}, {"referenceID": 19, "context": ", 2010), and Base Inference (Lignos, 2010).", "startOffset": 28, "endOffset": 42}], "year": 2017, "abstractText": "In this paper we present a novel framework for morpheme segmentation which uses the morpho-syntactic regularities preserved by word representations, in addition to orthographic features, to segment words into morphemes. This framework is the first to consider vocabulary-wide syntactico-semantic information for this task. We also analyze the deficiencies of available benchmarking datasets and introduce our own dataset that was created on the basis of compositionality. We validate our algorithm across different datasets and languages and present new state-of-the-art", "creator": "LaTeX with hyperref package"}}}