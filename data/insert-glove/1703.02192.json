{"id": "1703.02192", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Mar-2017", "title": "A Gentle Introduction to Epistemic Planning: The DEL Approach", "abstract": "16:8 Epistemic landsmannschaft planning gimondi can be cropley used sabath for decision dowager making rsn in disestablish multi - peniston agent 93-79 situations orda with distributed verge knowledge and capabilities. Dynamic raigarh Epistemic bapst Logic (eur2004-gre DEL) has hamer been shown four-book to instrumentalists provide a hypponen very regenvanu natural and shekaki expressive framework for epistemic planning. In bumar this trentino-alto paper, uniates we aim zingg to vazha give reductases an accessible introduction bodenstein to DEL - mikaal based realigning epistemic 3,861 planning. The paper starts with the zo\u00e9 most miombo classical sobin framework hackie for planning, STRIPS, and paganelli then moves hickes towards governmentality epistemic planning in zakri a hoffinger number 36.29 of smaller steps, where each step bellechasse is motivated ghostlike by the caunter need seperately to be 2010-12 able worley to garbelotto model 26-19 more cited complex u.f.o. planning scenarios.", "histories": [["v1", "Tue, 7 Mar 2017 03:15:08 GMT  (31kb,D)", "http://arxiv.org/abs/1703.02192v1", "In Proceedings M4M9 2017,arXiv:1703.01736"]], "COMMENTS": "In Proceedings M4M9 2017,arXiv:1703.01736", "reviews": [], "SUBJECTS": "cs.AI cs.LO cs.MA", "authors": ["thomas bolander"], "accepted": false, "id": "1703.02192"}, "pdf": {"name": "1703.02192.pdf", "metadata": {"source": "CRF", "title": "A Gentle Introduction to Epistemic Planning: The DEL Approach", "authors": ["Sujata Ghosh", "Thomas Bolander"], "emails": ["tobo@dtu.dk"], "sections": [{"heading": null, "text": "Sujata Ghosh and R. Ramanujam: M4M9 EPTCS 243, 2017, pp. 1\u201322, doi:10.4204/EPTCS.243.1\nc\u00a9 Thomas Bolander This work is licensed under the Creative Commons Attribution License.\nA Gentle Introduction to Epistemic Planning: The DEL Approach\nThomas Bolander DTU Compute\nTechnical University of Denmark Copenhagen, Denmark\ntobo@dtu.dk\nEpistemic planning can be used for decision making in multi-agent situations with distributed knowledge and capabilities. Dynamic Epistemic Logic (DEL) has been shown to provide a very natural and expressive framework for epistemic planning. In this paper, we aim to give an accessible introduction to DEL-based epistemic planning. The paper starts with the most classical framework for planning, STRIPS, and then moves towards epistemic planning in a number of smaller steps, where each step is motivated by the need to be able to model more complex planning scenarios."}, {"heading": "1 Introduction", "text": "Automated planning is a branch of artificial intelligence concerned with computing plans (sequences of actions) leading to some desired goal. A human or robot could e.g. have the goal of picking up a parcel at the post office, and then the problem becomes to find a succesful sequence of actions achieving this. Epistemic planning is the enrichment of planning with epistemic notions, that is, knowledge and beliefs. The human or robot might have to reason about epistemic aspects such as: Do I know at which post office the parcel is? If not, who would be relevant to ask? Maybe the parcel is a birthday present for my daughter, and I want to ensure that she doesnt get to know, and have to plan my actions accordingly (make sure she doesn\u2019t see me with the parcel). The epistemic notions are usually formalised using an epistemic logic. Epistemic planning can naturally be seen as the combination of automated planning with epistemic logic, relying on ideas, concepts and solutions from both areas.\nIn general, epistemic planning considers the following problem: Given my current state of knowledge, and a desirable state of knowledge, how do I get from one to the other? It is of central importance in settings where agents need to be able to reason about their own lack of knowledge, and e.g. make plans of how to achieve the required knowledge. It is also essential in multi-agent planning, where succesful coordination and collaboration can only be expected if agents are able to reason about the knowledge, uncertainty and capabilities of the other agents.\nIn this gentle introduction to epistemic planning, the focus will be on the DEL approach: Using Dynamic Epistemic Logic (DEL) as the underlying formalism. We start with the most classical framework for planning, STRIPS, and then stepwise we expand and generalise the framework until finally reaching full multi-agent planning based on dynamic epistemic logic. Each of these steps will be based on the need to be able to formalise specific planning scenarios.\nIn Section 2 we will first introduce classical planning domains and planning tasks. Then we move to present the basics of the STRIPS planning framework in Section 3, and propositional planning in Section 4. We then slowly progress towards defining the epistemic planning framework via first defining belief states and conditional actions in Section 5, and then epistemic logic and dynamic epistemic logic in Sections 6\u20137. In Section 8 we finally define epistemic planning tasks, and study various extensions\nand generalisations in Sections 9\u201311. In Section 12 we very briefly study complexity issues of epistemic planning, and we round off with a discussion of alternative approaches to epistemic planning in Section 13."}, {"heading": "2 Classical planning domains and planning tasks", "text": "Example 1. Suppose a father has his daughter\u2019s birthday coming up, and he ordered a present for her which is now at the post office. His goal is to be able to give her the present the next day. This is a planning task (sometimes called a planning problem): He needs to compute a plan to achieve the goal. In a planning task, one is given an initial state, a set of goal states and a set of available actions. The problem is now to compute a sequence of actions (a plan) that, if executed in the initial state, will lead to one of the goal states. In the birthday present example, the initial state describes that the present is at the post office and not yet wrapped. The goal states are those in which the present is at home and wrapped (ready to be given on the next day). The available actions could be actions like going from home to the post office, going from the post office to home, picking up the present at the post office, and wrapping the present. Of course we do not need to limit ourselves to only allowing these specific actions, but could have general actions for going from a location A to a location B, general actions for picking up an object at a location, and general actions for wrapping an object that you are currently holding.\nTo allow us to reason formally about planning tasks and plans, and to allow computers and robots to compute plans, we need an appropriate formalism to describe such objects. The simplest approach is to define planning tasks in terms of state-transition systems.\nDefinition 1. [17] A (restricted) state-transition system (also called a classical planning domain or simply a state space) is \u03a3 = (S,A,\u03b3) where:\n\u2022 S is a finite or recursively enumerable set of states. \u2022 A is a finite or recursively enumerable set of actions. \u2022 \u03b3 : S\u00d7A \u21aa\u2192 S is a computable partial state-transition function.\nWhen \u03b3(s,a) is defined, a is said to be applicable in s. When \u03c0 = a1; \u00b7 \u00b7 \u00b7 ;an is a sequence of actions from A, we write \u03b3(s,\u03c0) for \u03b3(. . .\u03b3(\u03b3(\u03b3(s,a1),a2),a3), . . . ,an).1\nDefinition 2. [17] A classical planning task is a triple (\u03a3,s0,Sg) where:\n\u2022 \u03a3 = (S,A,\u03b3) is a state-transition system (a classical planning domain). \u2022 s0 \u2208 S is the initial state. \u2022 Sg \u2286 S is the set of goal states.\nA solution to a classical planning task ((S,A,\u03b3),s0,Sg) is a finite sequence of actions (a plan) \u03c0 = a1; \u00b7 \u00b7 \u00b7 ;an from A such that \u03b3(s0,\u03c0) \u2208 Sg. The length of a solution \u03c0 is the number of actions in \u03c0 . Example 2. Consider the birthday present example from Example 1. The available actions and their corresponding state transitions could be presented by the state-transitions system of Figure 1. Here we have \u03a3 = (S,A,\u03b3) with S = {s1,s2,s3,s4,s5,s6}, A = {go to post office, go home, pick up present, wrap present}, and \u03b3 is as given in the figure (e.g. \u03b3(s1,go to post office) = s2 since there is an edge labelled \u201cgo to post office\u201d from s1 to s2). Note that \u201cwrap present\u201d is only applicable after \u201cpick up present\u201d has been executed: it is necessary to get hold of the present before it can be wrapped. The\n1So \u03b3(s,\u03c0) is the result of executing the actions of \u03c0 in sequence starting in s.\nplanning task of Example 1 can then be represented as the classical planning task (\u03a3,s0,Sg) where s0 = s1 and Sg = {s5}. A solution is highlighted in Figure 1:\n\u03c0 = go to post office;pick up present;go home;wrap present.\nRepresenting planning tasks directly as state-transition systems has some important weaknesses: 1) there is no internal structure on states and actions to understand or clarify what they represent; 2) statetransition systems are normally of exponential size in the number of propositional variables required to describe the states. To exemplify the second weakness, if the planning task was to take home n parcels from the post office, the state space (state-transition system) would be of size \u2265 2n: each parcel could either be at the post office or at home. This is so even though the length of the shortest solution would only be linear in n (e.g. bring the parcels home one at a time). To address both of these weaknesses one introduces logical structures on states and actions. This is e.g. done in the planning language STRIPS to be introduced next."}, {"heading": "3 STRIPS planning", "text": "The classical language for describing states and actions in the field of automated planning is STRIPS [16]. We will here introduce STRIPS slightly informally, and the interested reader is referred to [29] for more details. The reader familiar with STRIPS planning can skip this section, but might want to briefly look at the examples.\nIn STRIPS, states are represented as sets of ground atoms of a function-free first-order language L. In the birthday present example, the initial state could e.g. be described by\ns0 = {At(Father,Home),At(Present,PostOffice), IsAgent(Father), IsLocation(Home), IsLocation(PostOffice), IsObject(Present)} (1)\nwhere At(x,y) is a predicate for expressing that object (or agent) x is at location y. The predicates IsAgent(x), IsLocation(x) and IsObject(x) are true of agents, objects and locations, respectively (alternatively, one could use a sorted first-order language and then omit these predicates). Actions are described via so-called action schemas. The actions of going from one location to another, picking up an object and wrapping an object can be expressed by the STRIPS action schemas provided in Figure 2, where predicates have names starting with upper-case letters, and variables have names starting with lowercase letters. Each action schema has a name, a precondition and an effect. Preconditions and effects\nare conjunctions of literals of the first-order language L. A ground action is achieved by instantiating all variables of an action schema with constants of L. For instance,\nACTION : Go(Father,Home,PostOffice) PRECOND : At(Father,Home)\u2227 IsAgent(Father)\u2227 IsLocation(Home)\u2227 IsLocation(PostOffice) EFFECT : At(Father,PostOffice)\u2227\u00acAt(Father,Home)\nThe precondition of a ground action describes what has to be true for the action to be applicable.2 It is easy to check that Go(Father,Home,PostOffice) is applicable in the initial state s0 defined by (1) (all precondition atoms of the action occur in s0). The effect of a ground action describes how the state is modified when the action is executed. The effect of Go(Father,Home,PostOffice) expresses that At(Father,PostOffice) becomes true, and that At(Father,Home) becomes false. Hence the result of executing Go(Father,Home,PostOffice) in s0 will be the state\ns1 = {At(Father,PostOffice),At(Present,PostOffice), IsAgent(Father), IsLocation(Home), IsLocation(PostOffice), IsObject(Present)}\nAny finite set of STRIPS action schemas A induce a state-transition system (classical planning domain) \u03a3 = (S,A\u2032,\u03b3) by:\n\u2022 S = 2P, where P is the set of ground atoms of L. \u2022 A\u2032 = {all ground instances of the action schemas in A}\n\u2022 \u03b3(s,a) =  (s\u2212{\u03d5 | \u00ac\u03d5 is a negative literal of EFFECT(a)) \u222a {\u03d5 | \u03d5 is a positive literal of EFFECT(a)} if s |= PRECOND(a)\nundefined otherwise\nThe state-transition system induced by the STRIPS schemas of Figure 2 is provided in Figure 3. The rigid atoms, those that cannot change truth-value, have been omitted. Furthermore, each constant name is abbreviated by the capital letters it contains (so for instance PostOffice is abbreviated PO). Note that\n2More formally, a ground action a is applicable in a state s if s |= PRECOND(a) where |= denotes semantical entailment on propositional logic over the set of ground atoms of L.\nthe resulting state-transition system is isomorphic to the state-transition system of Figure 1. The advantage of the current STRIPS representation over the previous pure state-transition representation is that there is now structure on states and actions. This for instance means that the current formulation is easily generalisable, e.g. we can add n\u2212 1 additional parcels to the initial state without any need to modify the underlying action schemas. The induced state-transition system would become exponentially bigger, as earlier noted, but the size of the STRIPS action schemas would stay the same (though the size of the description of the initial state would grow linearly with n).\nA STRIPS planning task on a function-free first-order language L is (A,s0,\u03d5g) where A is a set of STRIPS action schemas over L, s0 is a set of ground atoms over L and \u03d5g is a conjunction of ground literals over L called the goal formula. Any STRIPS planning task (A,s0,\u03d5g) induces a classical planning task (\u03a3,s0,Sg) by letting \u03a3 be the state-transition system induced by A and letting Sg = {s \u2208 S | s |= \u03d5g}. A solution to a STRIPS planning task is then a solution to the induced classical planning task.\nExample 3. The birthday present example can be represented as a STRIPS planning task (A,s0,\u03d5g) where A is the set of action schemas of Figure 2, s0 is defined by (1), and \u03d5g = At(Father,Home)\u2227 Has(Father,Present)\u2227Wrapped(Present). This is a STRIPS planning task on the function-free first order languageLwith binary predicate symbols At and Has, unary predicate symbols Wrapped, IsAgent, IsLocation and IsObject, and constant symbols Home, PostOffice, Father, Present. Consulting Figure 3, it is easy to show that a solution to this planning task is\n\u03c0 = Go(Father,Home,PostOffice);PickUp(Father,Present,PostOffice); Go(Father,PostOffice,Home);Wrap(Father,Present).\nIn the field of automated planning, actions are always described compactly in an action description language like STRIPS (or e.g. PDDL, ADL or SAS+). A lot of research effort goes into finding ways to automatically derive efficient heuristics from action schemas, such that solutions can be found with minimal search. If given an induced state-transition system of a set of STRIPS action schemas, finding a solution to a planning task becomes a simple graph search problem (find a path from s0 to a state in Sg). This can be done in linear time in the size of the state-transition system. However, as earlier noted, the induced state-transition system is often exponential in the size of the action schemas. Hence the complexity of computing solutions or deciding whether a solution exists (the plan existence problem) is in automated planning always measured in the size of the compact action schema representation. This is different from many formalisms in logic that consider plans or strategies and where complexity is measured in terms of the size of the state space. This is e.g. why epistemic planning based on ATEL\nin [19] can be claimed to be tractable, even though already basic propositional STRIPS planning, which is much less expressive, is intractable. For most planning domains considered in automated planning (e.g. the planning domains of the International Planning Competition, IPC), calculating the entire statetransition system is computationally infeasible, and the goal is then for the heuristics to be sufficiently efficient that only the most relevant parts of the state-transition system are explored."}, {"heading": "4 Propositional planning tasks", "text": "Even though STRIPS action schemas are formulated using first-order logic, for most purposes we can consider STRIPS as a planning formalism based on propositional logic. To see this, we first define propositional planning tasks.\nDefinition 3. A propositional planning task3 on a finite set of atomic propositions P is (A,s0,\u03d5g) where \u2022 A is a finite set of actions. Each action is a pair a = \u3008pre(a), post(a)\u3009 where pre(a) and post(a)\nare conjunctions of propositional literals over P. The element pre(a) is called the precondition of a and post(a) its postcondition.\n\u2022 s0 is the initial state, a propositional state over P (a subset of P).4\n\u2022 \u03d5g is the goal formula, a propositional formula over P. A propositional planning task (A,s0,\u03d5g) on P induces a classical planning task ((S,A,\u03b3),s0,Sg) in the expected way (compare with the classical planning task induced by a STRIPS planning task defined in Section 3):\n\u2022 S = 2P\n\u2022 \u03b3(s,a) =  (s\u2212{p | \u00acp is a negative literal of post(a)) \u222a {p | p is a positive literal of post(a)} if s |= pre(a)\nundefined otherwise\n\u2022 Sg = {s \u2208 S | s |= \u03d5g}. A solution to a propositional planning task is any solution to the induced classical planning task.\nFor any function-free first-order language L, let PL denote the set of ground atoms of L. The set PL can be thought of as the atomic propositions of a propositional language. Any quantifier-free ground formula of L is then at the same time a formula of propositional logic over PL. Any STRIPS planning task (A,s0,\u03d5g) on L induces a propositional planning task (A\u2032,s0,\u03d5g) on PL by simply letting\nA\u2032 = {\u3008Precond(a),Effect(a)\u3009 | a is a ground instance of an action schema in A}.\nIt is easy to show that the STRIPS planning task (A,s0,\u03d5g) and its induced propositional planning task (A\u2032,s0,\u03d5g) both induce the same classical planning task. They thus also have the same solutions. Note that the conventions for preconditions and effects are a bit different in propositional planning tasks than in STRIPS planning tasks. We now write precondition and effect pairs of an action a as a pair of the form \u3008pre(a), post(a)\u3009, where we have also relabelled effects as postconditions. The point of both these changes is to gradually move away from the classical conventions of STRIPS planning into the conventions of dynamic epistemic logic that we will later present a planning framework based on.\n3Called a set-theoretic planning task in [17]. 4In general, we will identify propositional states with subsets of P. A subset S \u2286 P represents the propositional state s in\nwhich the elements of S are the atomic propositions true in s.\nExample 4. The birthday present example can be represented as the propositional planning task (A,s0,\u03d5g) below. It is a simplified version of the propositional planning task induced by the STRIPS planning task of Example 3, where we have done away with the rigid atoms that are no longer necessary. In the definitions below, Agt is a set of agent names (including Father), Loc is a set of locations (including Home and PostOffice) and Obj is a set of objects (including Present).\n\u2022 A = {Go(agt, from, to) | agt \u2208 Agt & from, to \u2208 Loc}\u222a{PickUp(agt,obj, from) | agt \u2208 Agt & obj \u2208 Obj & from\u2208Loc}\u222a{Wrap(agt,obj) | agt\u2208Agt &obj\u2208Obj}where, for all agt\u2208Agt, all from, to\u2208 Loc and all obj \u2208 Obj,\n\u2013 Go(agt, from, to) = \u3008At(agt, from),At(agt, to)\u2227\u00acAt(agt, from)\u3009 \u2013 PickUp(agt,obj, from) = \u3008At(agt, from)\u2227At(obj, from)\u2227\u00acHas(agt,obj),Has(agt,obj)\u3009 \u2013 Wrap(agt,obj) = \u3008Has(agt,obj)\u2227\u00acWrapped(obj),Wrapped(obj)\u3009.\n\u2022 s0 = {At(Father,Home),At(Present,PostOffice)}.\n\u2022 \u03d5g = At(Father,Home)\u2227Has(Father,Present)\u2227Wrapped(Present).\nNote that expressions like At(agt, from) with agt\u2208Agt and from\u2208 Loc are no longer considered as ground atoms of the original first-order language L, but as atoms of propositional logic over PL. A solution to this planning task is exactly as to the original STRIPS version: \u03c0 = Go(Father,Home,PostOffice); PickUp(Father,Present,PostOffice); Go(Father,PostOffice,Home); Wrap(Father,Present).\nSince any STRIPS planning task can be propositionalised as above, it means we can now work in a simpler formalism, propositional logic, which also makes it easier to generalise the formalism to e.g. planning with partial observability, non-determinism or epistemic planning.5"}, {"heading": "5 Belief states, partial observability, and conditional actions", "text": "Consider the birthday present example formalised as the propositional planning task of Example 4. Assume now that there is not only one, but two, local post offices, and the father does not know in which one the parcel is. We can assume Loc correspondingly contains two constants, PostOffice1 and PostOffice2. To represent this modified planning task we need two changes in the underlying formalism: belief states and conditional actions. We need belief states to represent the uncertainty of the agent. A belief state in this setting is a set of propositional states, that is, a set of subsets of P (where P is the set of atomic propositions). The initial belief state of our agent is now:\ns0 = {{At(Father,Home),At(Present,PostOffice1)},{At(Father,Home),At(Present,PostOffice2)}}. (2)\nThe state s0 contains two propositional states, where the first one represents the situation where the present is in PostOffice1, and the second presents the situation where it is in PostOffice2. We define a propositional formula \u03d5 to be true in a belief state s, written s |= \u03d5 , if \u03d5 is true in all propositional states of s. Hence we have\n(1) s0 |= At(Father,Home)\n(2) s0 6|= At(Present,PostOffice1) 5In certain cases the difference between expressing a planning task in the lifted first-order STRIPS representation and its induced propositionalisation becomes essential: for some of the complexity results measured in the size of the planning tasks; for practical convenience of representation; or e.g. for learning actions/action models [30, 24]. However, for the purposes of this paper, the grounded/propositionalised representation is sufficient.\n(3) s0 6|= At(Present,PostOffice2) (4) s0 |= At(Present,PostOffice1)\u2228At(Present,PostOffice2).\nThis represents the internal perspective of the father in the belief state s0: He can verify (knows) that he is home (1) and can verify (knows) that the present is in PostOffice1 or PostOffice2 (4), but doesn\u2019t know which (2\u20133). Planning in the space of belief states rather than propositional states is called planning under partial observability (and planning on propositional states is then called planning under full observability). In the following, and in line with modal logic, we will call the elements of belief states worlds.\nTo represent the modified example we also need to allow conditional actions. The agent can attempt to pick up the present at either of the two post offices, but whether he is succesful is conditional on whether it is the correct one. Symmetric to the generalisation from representing states as subsets of P to sets of such subsets, we can generalise actions from being pairs \u3008pre(a), post(a)\u3009 to be sets of such pairs. We can then represent the attempted pickup action by:\nTryPickUp(agt,obj, from) = { \u3008At(agt, from)\u2227At(obj, from)\u2227\u00acHas(agt,obj),Has(agt,obj)\u2227\u00acAt(obj, from)\u3009, \u3008At(agt, from)\u2227\u00acAt(obj, from),>\u3009 }\n(3)\nwhere the postcondition > means that nothing changes. From now on we will, in line with the literature on dynamic epistemic logic, call pairs \u3008pre(e), post(a)\u3009 events. So a conditional action like the one above is a set of events: a set of the possible things that might happen when the action is executed. The TryPickUp action above expresses that if the agent and the object are in the same location, the object will be successfully picked up (the first event of the action), and otherwise nothing will happen (the second event of the action).\nGiven a belief state s represented as a set of worlds and an action action a represented as a set of events, we can define a generalised transition function by\n\u03b3(s,a) = {\u03b3(w,e) | w \u2208 s,e \u2208 a,w |= pre(e)}.6 (4)\nThus, e.g., where we abbreviate PostOffice1 by PO1, PostOffice2 by PO2 and Home by H:\ns1 = \u03b3(s0,Go(Father,H,PO1)) = \u03b3({{At(Father,H),At(Present,PO1)},{At(Father,H),At(Present,PO2)}},Go(Father,H,PO1)) = {{At(Father,PO1),At(Present,PO1)},{At(Father,PO1),At(Present,PO2)}}\ns2 = \u03b3(s1,TryPickUp(Father,Present,PO1)) = {{At(Father,PO1),Has(Father,Present)},{At(Father,PO1),At(Present,PO2)}}\ns3 = \u03b3(s2,Go(Father,PO1,PO2)) = {{At(Father,PO2),Has(Father,Present)},{At(Father,PO2),At(Present,PO2)}}\ns4 = \u03b3(s3,TryPickUp(Father,Present,PO2)) = {{At(Father,PO2),Has(Father,Present)}}\n6This is consistent with how the transition function is defined for conditional actions in [17], but only for actions in which the events have pairwise mutually inconsistent preconditions. If two events have mutually consistent preconditions, it means there exists states in which both are applicable. This can be interpreted in two ways. Either it represents non-determinism where only one of the events can actually take place when the action is executed. Or it represents a situation where multiple events occur in parallel. In [17], the latter interpretation is used. In this paper and in dynamic epistemic logic, the first interpretation is used.\ns5 = \u03b3(s4,Go(Father,PO2,Home)) = {{At(Father,Home),Has(Father,Present)}}\ns6 = \u03b3(s5,Wrap(Father,Present)) = {{At(Father,Home),Has(Father,Present),Wrapped(Present)}}\nNote how the belief state goes down from cardinality 2 to cardinality 1 when going from s3 to s4. At plan time, when deliberating about the possible action sequences, the father doesn\u2019t know whether he will have the present after having visited only PostOffice1, and he hence has to represent both possibilities. In s4, however, he knows, even at plan time, that he will have the present, since if he didn\u2019t get it at PostOffice1, he will be sure to get it at PostOffice2. The calculations above show that a solution to the modified planning task is\n\u03c0 = Go(Father,H,PO1);TryPickUp(Father,Present,PO1);Go(Father,PO1,PO2); TryPickUp(Father,Present,PO2);Go(Father,PO2,Home);Wrap(Father,Present).\n(5)\nThere are, unfortunately, several weaknesses in the current approach. An important weakness is that the formalism does so far not distinguish between between the kind of uncertainty the father has in s1 and the kind of uncertainty he has in s2. In s1, the father has run time uncertainty [26] about the location of the present. This means that even at execution time, when the action Go(Father,H,PO1) has been executed in the initial state, the father still does not know which of the two worlds of s1 is the actual one. In s2, however, he should only have plan time uncertainty [26]. This means that when he is deliberating about the possible action sequences and their potential outcomes, he can not tell which of the two worlds of s2 is going to be realised, but at execution time he will know. This is because attempting to pick up the present at PO1 has the side-effect of informing him whether the present is there or not. The distinction between plan time and run time uncertainty is not represented in our current formalism, since both kinds of uncertainty are modelled exactly the same: by simply having a set of worlds representing those situations that the agent cannot distinguish between (whether at plan time or at run time).\nThe simplest and most common solution to this problem in the automated planning literature (see e.g. [17, 28]) is to treat observability as a static partition on the set of possible worlds, so that certain possible worlds are always distinguishable and others never are. What becomes distinguishable at execution time is then hardcoded into this observability partition. This approach is however insufficient for our purposes. For instance, assume the present is initially located at PO2. Assume further that the father initially goes to PO1 to attempt picking it up and then goes home again. Then afterwards he will be in exactly the same world as initially, namely the world satisfying At(Father,Home)\u2227At(Present,PO2). But he will not be in the same information state: He learned that the present is not at PO1 (and therefore also learned that it must be at PO2). To be able to represent this in an appropriate way we need to take the final step into planning based on epistemic logic.7\n7In principle, in the single-agent case, we could alternatively consider modelling states as sets of sets of worlds (that is,\nelements of 22 2P\n) and actions a sets of sets of events. In a state {{w11,w21, . . . ,w n1 1 },{w 1 2,w 2 2, . . . ,w n2 2 }, . . . ,{w 1 m,w 2 m, . . . ,w nm m }},\ntwo worlds wki and w l j would then always be plan time indistinguishable, but only run time indistinguishable if i = j. This is essentially equivalent to representing states as models of single-agent epistemic logic (see next section). Since we are anyway going to generalise to multi-agent planning, we choose to move straight to epistemic logic, rather than consider this further intermediate step."}, {"heading": "6 Epistemic logic", "text": "Let P be a finite set of atomic propositions (often we will take P to be the set of ground atoms of a function-free first-order language as in the previous sections). Let A be a finite set of agents. The epistemic language on P,A, denoted LKC(P,A), is generated by the following BNF:\n\u03d5 ::=> | \u22a5 | p | \u00ac\u03d5 | \u03d5 \u2227\u03d5 | Ki\u03d5 |C\u03d5,\nwhere p \u2208 P and i \u2208A. We read Ki\u03d5 as \u201cagent i knows \u03d5\u201d and C\u03d5 as \u201cit is common knowledge that \u03d5\u201d. When P and A are clear from the context (or no assumptions about them are made), we will write LKC for LKC(P,A). LK is the language LKC without the C modality.\nDefinition 4. Let P and A be as above. An epistemic model on P,A isM= (W,(\u223ci)i\u2208A,L) where\n\u2022 The domain W is a non-empty finite set of worlds.\n\u2022 \u223ci \u2286W \u00d7W is an equivalence relation called the indistinguishability relation for agent i \u2208 A.8\n\u2022 L : W \u2192 2P is a labelling function assigning a propositional valuation (a set of propositions) to each world.\nFor Wd \u2286W , the pair (M,Wd) is called an epistemic state (or simply a state), and the worlds of Wd are called the designated worlds. A state is called global if Wd = {w} for some world w (called the actual world), and we then often write (M,w) instead of (M,{w}). We use Sgl(P,A) to denote the set of global states (or simply Sgl if P and A are clear from the context). For any state s = (M,Wd) we let Globals(s) = {(M,w) |w\u2208Wd}. A state (M,Wd) is called a local state for agent i if Wd is closed under \u223ci (that is, if w \u2208Wd and w\u223ci v implies v \u2208Wd). Given a state s = (M,Wd), the associated local state of agent i, denoted si, is (M,{v | v\u223ci w and w \u2208Wd}).\nDefinition 5. Let (M,Wd) be a state on P,A withM = (W,(\u223ci)i\u2208A,L). For i \u2208 A, p \u2208 P and \u03d5,\u03c8 \u2208 LKC(P,A), we define truth as follows:\n(M,Wd) |= \u03d5 iff (M,w) |= \u03d5 for all w \u2208Wd (M,w) |= p iff p \u2208 L(w) (M,w) |= \u00ac\u03d5 iff M,w 6|= \u03d5 (M,w) |= \u03d5 \u2227\u03c8 iff M,w |= \u03d5 andM,w |= \u03c8 (M,w) |= Ki\u03d5 iff (M,v) |= \u03d5 for all v\u223ci w (M,w) |=C\u03d5 iff (M,v) |= \u03d5 for all v\u223c\u2217 w\nwhere \u223c\u2217 is the transitive closure of \u22c3\ni\u2208A \u223ci.\nNote that a formula \u03d5 is defined to be true in a non-global state (M,Wd) iff it is true in each of the global states (M,w), w\u2208Wd , it contains. This is consistent with our previous definition of truth in belief states as truth in all worlds of that state.\nExample 5. Let P = PL, where L is the function-free first-order language of Example 3 extended with constant symbols PostOffice1 and PostOffice2 and let A = {Father}. Consider the initial state s0 defined by (2). We can represent this via an epistemic model M = (W,\u223cFather,L) on P,A with W = {w1,w2}, \u223cFather =W \u00d7W , L(w1) = {At(Father,Home),At(Present,PostOffice1)} and L(w2) =\n8We will later consider generalising to non-equivalence relations, but for now it is sufficient ot make this simplification and only consider equivalence relations.\n{At(Father,Home),At(Present,PostOffice2)}. Graphically, this epistemic model is represented as follows, using the abbreviations from earlier:\nw1 : At(Father,H),At(Present,PO1) w2 : At(Father,H),At(Present,PO2)\nFather\nHere the nodes represent the worlds and the edges represent the indistinguishability relation (reflexive edges left out). Each node is labelled by its name and the set of atomic propositions true at the world. Consider the case where initially the present is at PostOffice2. This means that the actual world is w2, and this situation can be represented by the global state s0 = (M,w2), that we graphically present as\ns0 = w1 : At(Father,H),At(Present,PO1) w2 : At(Father,H),At(Present,PO2)\nFather\nWe use for designated worlds. The planning agent, Father, does not have access to this global state, since he considers it equally possible that the present is at PO1 (w1 and w2 are indistinguishable to him). The internal initial state of the father is his associated local state sFather0 = (M,W ):\nsFather0 = w1 : At(Father,H),At(Present,PO1) w2 : At(Father,H),At(Present,PO2)\nFather\nWe have s |= At(Present,PO2) but sFather 6|= At(Present,PO2): From the outside global perspective (the perspective of an omniscient external observer) it can initially be verified that the present is at PO2, but not from the perspective of the planning agent, Father, himself.\nIn general, any belief state B = {s1, . . . ,sn} (set of propositional states) can be equivalently represented as an epistemic state ((W,\u223c,L),W ) with W = {w1, . . . ,wn}, \u223c = W \u00d7W , L(wi) = si for all i = 1, . . . ,n.\nWith epistemic models we can also capture the distinction between run time and plan time uncertainty. When the father contemplates on the possible action sequences to execute in his local state sFather, the epistemic state representing the result of executing the action sequence\nGo(Father,H,PO1);TryPickUp(Father,Present,PO1);Go(Father,PO1,H)\nwill be\ns\u2032 = w1 : At(Father,H),Has(Father,Present) w2 : At(Father,H),At(Present,PO2)\nThere is still two designated worlds: the agent do not at plan time know which one it will end up in. But they are now not indistinguishable (there is no indistinguishability edge connecting them): at run time, when the plan is executed, the agent will be able to tell whether it is in w1 or w2. In fact we have e.g. s\u2032 |= KFatherAt(Present,PO2)\u2228KFather\u00acAt(Present,PO2): In s\u2032, the father knows whether the present is at PO2 or not. More generally, let s = (M,Wd) be any local state of an agent i \u2208 A and let w1,w2 \u2208Wd . The worlds w1 and w2 are called run time indistinguishable (for agent i) if w1 \u223ci w2. Otherwise, they are plan time indistinguishable.\nThe generalisation from belief states (in the standard AI sense of sets of propositional states [29]) to epistemic states (in the sense of epistemic logic) also allows us to represent planning tasks involving multiple agents. E.g. the father might want to make sure that his daughter doesn\u2019t get to know that he has a present for her (it is supposed to be a surprise). In this case, we could reformulate the goal as\n\u03d5g = At(Father,Home)\u2227Has(Father,Present)\u2227Wrapped(Present)\u2227\u00acKDaughterHas(Father,Present). (6)"}, {"heading": "7 Dynamic epistemic logic", "text": "Generalising from propositional states to epistemic states amounted to generalise from propositional valuations to multisets of such valuations with an added indistinguishability relation for each agent. We can now apply the exact same trick to generalise from propositional actions to epistemic actions. A propositional action is an event \u3008pre(a), post(a)\u3009, so an epistemic action will be a multiset of events with an indistinguishability relation for each agent. This is exactly how epistemic actions are defined in dynamic epistemic logic (DEL) with postconditions [12]. Such structures are called event models or action models.\nDefinition 6. An action model on P,A is E = (E,(\u223ci)i\u2208A, pre, post) where \u2022 The domain E is a non-empty finite set of events. \u2022 \u223ci \u2286 E\u00d7E is an equivalence relation called the indistinguishability relation for agent i \u2208 A. \u2022 pre : E\u2192LKC(P,A) assigns a precondition to each event. \u2022 post : E\u2192LKC(P,A) assigns a postcondition to each event. For all e\u2208E, post(e) is a conjunction\nof literals over P (including the special atom >).9\nFor Ed \u2286 E, the pair (E ,Ed) is called an epistemic action (or simply an action), and the events in Ed are called the designated events. An action is called global if Ed = {e} for some event e, and we then often write (E ,e) instead of (E ,{e}). Similar to states, (E ,Ed) is called a local action for agent i when Ed is closed under \u223ci. Given an action a = (E ,Ed), the associated local action of agent i \u2208 A, denoted ai, is (E ,{ f \u2208 E | f \u223ci e for some e \u2208 Ed}).\nAny propositional action a = \u3008pre(a), post(a)\u3009 trivially induces an epistemic action (E ,{e}) with E = ({e},{(e,e)}, pre, post) where pre(e) = pre(a) and post(e) = post(a). Example 6. We can now finally, using action models, give a satisfactory formal representation of the TryPickUp action of Section 5, cf. (3):\nTryPickUp(agt,obj, from) =\ne1 : \u3008At(agt, from)\u2227At(obj, from)\u2227\u00acHas(agt,obj), Has(agt,obj)\u2227\u00acAt(obj, from)\u3009\ne2 : \u3008At(agt, from)\u2227\u00acAt(obj, from), >\u3009\n9This definition of postconditions is slightly less general than the standard definition of postconditions in DEL [12]. Normally, post(e) is a mapping from atomic propositions to formulas LKC, where post(e)(p) = \u03d5 means that p after the event e has occurred gets whatever truth value \u03d5 had before e occurred. In [12] it is shown that any action model can be equivalently represented by one in which post(e)(p)\u2208 {p,>,\u22a5} for all e\u2208 E and p\u2208 P. This action model can potentially be exponentially larger. Such simplified (but potentially larger) action models can immediately be translated into the form defined here (see [6] for details). The advantages of the conventions of this paper is to have a more clear connection to the conventions of classical planning and to simplify notation.\nWe here use the same conventions for representing action models graphically as we did for epistemic models. Note that there is no indistinguishability edge for Father: He will at run time observe whether the action is succesful (e1) or not (e2). But at plan time he does not know which one it will be, which is why both events are designated.\nThe state-transition function of DEL is called product update, and is denoted by an infix \u2297 symbol. So instead of writing \u03b3(s,a), one writes s\u2297a. Definition 7. Let a state s = (M,Wd) and an action a = (E ,Ed) be given with M = (W,(\u223ci)i\u2208A,L) and E = (E,(\u223ci)i\u2208A, pre, post). Then the product update of s with a is s\u2297a = ((W \u2032,(\u223c\u2032i)i\u2208A,L\u2032),W \u2032d) where\n\u2022 W \u2032 = {(w,e) \u2208W \u00d7E | (M,w) |= pre(e)} \u2022 \u223c\u2032i = {((w,e),(w\u2032,e\u2032)) \u2208W \u2032\u00d7W \u2032 | w\u223ci w\u2032 and e\u223ci e\u2032} \u2022 L\u2032(p) = (L(p)\u2212{p | \u00acp is a negative literal of post(e))\u222a{p | p is a positive literal of post(e)} \u2022 W \u2032d = {(w,e) \u2208W \u2032 | w \u2208Wd and e \u2208 Ed}.\nWe say that an action (E ,Ed) is applicable in a state (M,Wd) if for all w \u2208Wd there is an event e \u2208 Ed such that (M,w) |= pre(e).\nNote that this is the obvious generalisation to the epistemic setting of the state-transition function for belief states and sets of events given in (4). In particular, if s\u2032 is the epistemic state induced by a belief state s, and a\u2032 is the action model induced by a propositional action a, then s\u2032\u2297a\u2032 is the epistemic state induced by \u03b3(s,a).\nLet i \u2208 A be an agent, let (M,Wd) be a local state for i and let (E ,Ed) be a local action for i. Then (M,Wd) and (E ,Ed) represent agent i\u2019s view on a particular state and action. According to the definition above, the action (E ,Ed) is then applicable in the state (M,Wd) if, for any of the worlds agent i considers possible (any world w in Wd), the action specifies at least one applicable event that agent i considers possible (an event e in Ed with (M,w) |= pre(e)). In other words, the action is applicable from the perspective of agent i."}, {"heading": "8 Epistemic planning tasks", "text": "We now have all the necessary ingredients for defining planning tasks in epistemic planning based on DEL. We simply define these as for propositional planning tasks, except we replace propositional actions by epistemic actions, propositional states by epistemic states and propositional goal formulas by epistemic goal formulas.\nDefinition 8. An epistemic planning task on P,A is (A,s0,\u03d5g) where A is a finite set of epistemic actions on P,A, s0 is an epistemic state on P,A, and \u03d5g \u2208 LKC(P,A). We say that (A,s0,\u03d5g) is an epistemic planning task for agent i \u2208 A if s0 and all a \u2208 A are local for i. A planning task (A,s0,\u03d5g) is called global if s0 is global. Given any planning task \u03a0 = (A,s0,\u03d5g), the associated local planning task of agent i, denoted \u03a0i, is ({ai | a \u2208 A},si0,\u03d5g).10\nAn epistemic planning task (A,s0,\u03d5g) induces a classical planning task ((S,A,\u03b3),s0,Sg) in a similar manner to propositional planning tasks:\n10Given a planning task \u03a0, the planning task \u03a0i is agent i\u2019s local perspective on that planning task. E.g. if the present is at PO1, then from an outside perspective, the planning task has an initial state where only the world satisfying At(Present,PO1) is designated, but agent Father is still forced to do planning based on the planning task \u03a0Father where both the At(Present,PO1)world and the At(Present,PO2)-world are designated, since the father doesn\u2019t know which of the two is the actual initial state.\n\u2022 S = {s0\u2297a1\u2297\u00b7\u00b7 \u00b7\u2297an | n \u2208 N and a1, . . . ,an \u2208 A}\n\u2022 \u03b3(s,a) = { s\u2297a if a is applicable in s undefined otherwise\n\u2022 Sg = {s \u2208 S | s |= \u03d5g}. As for propositional planning tasks, we can then define a solution to an epistemic planning task (A,s0,\u03d5g) to be a solution to the induced classical planning task. This is equivalent to the existence of a sequence of actions a1; \u00b7 \u00b7 \u00b7 ;an from A such that each ai is applicable in s0\u2297 a1\u2297\u00b7\u00b7 \u00b7\u2297 ai\u22121 (i \u2264 n) and s0\u2297 a1\u2297 \u00b7\u00b7 \u00b7\u2297an |= \u03d5g. Example 7. Let us provide a full formalisation of the birthday present example as an epistemic planning task. The epistemic action TryPickUp was presented in Example 6. The actions Go(agt, from, to) and Wrap(agt,obj) are simply the ones induced by their propositional counterparts. The initial state is the state sFather0 of Example 5. The goal formula is \u03d5g = At(Father,Home)\u2227Has(Father,Present)\u2227 Wrapped(Present). Clearly the resulting planning task is a planning task for agent Father. We now get\ns1 = sFather0 \u2297Go(Father,H,PO1) = At(Father,PO1), At(Present,PO1)\nAt(Father,PO1), At(Present,PO2)\nFather\ns2 = s1\u2297TryPickUp(Father,Present,PO1) = At(Father,PO1), Has(Father,Present) At(Father,PO1), At(Present,PO2)\nNote that the indistinguishability link between the two worlds is being cut when going from s1 to s2, since the two events of TryPickUp are distinguishable. We further get\ns3 = s2\u2297Go(Father,PO1,PO2) = At(Father,PO2), Has(Father,Present)\nAt(Father,PO2), At(Present,PO2)\ns4 = s3\u2297TryPickUp(Father,Present,PO2) = At(Father,PO2), Has(Father,Present) At(Father,PO2), Has(Father,Present)\ns6 = s4\u2297Go(Father,PO2,H)\u2297Wrap(Father,Present) = At(Father,Home), Has(Father,Present) Wrapped(Present) At(Father,Home), Has(Father,Present) Wrapped(Present)\nSince the two worlds of s6 have identical labels, we can take the bisimulation contraction which will preserve only one of them.11 We clearly have s5 |= \u03d5g. Hence the action sequence (5) above is a solution to the epistemic planning task. We could actually replace the TryPickUp(Father,Present,PO2) action in this plan with the epistemic action induced by the original non-conditional PickUp(Father,Present,PO2) action. This is because the father will know that the present is at PO2 when he gets there (since it wasn\u2019t at PO1).\n11For a definition of bisimulation between epistemic models with multiple designated points, see [6]. For a definition of bisimulation on models of modal logic in general, and a definition of bisimulation contraction, see [4]. Bisimulation contractions are an indispensible tool in practice when working with product updates in DEL, since sequences of updates otherwise tend to produce very large model."}, {"heading": "9 Conditional epistemic planning", "text": "The plan found in the previous example, Example 7, is clearly not always optimal. If the father gets the present already at PO1, there is no need to go to PO2 as well. So in this case the father will be able to reach the goal in 4 instead of 6 steps. But the father will of course not know this until run time (after having attempted to pick up the present at PO1). A sequential plan (sequence of actions) can not capture this, since it has a fixed number of actions, independent of the action outcomes. So we need to move to conditional plans (not to be confused with conditional actions that we already have). A conditional plan for the current planning task could e.g. be formulated as the following program\nGo(Father,H,PO1);TryPickUp(Father,Present,PO1); if KFatherHas(Father,Present) then Go(Father,PO1,H);Wrap(Father,Present) else Go(Father,PO1,PO2);TryPickUp(Father,Present,PO2);Go(Father,PO2,H); Wrap(Father,Present)\nSuch programs for epistemic planning tasks are formally defined and explored in [1] (single-agent case only).12 Alternatively, such programs can be seen as abbreviations of PDL programs, e.g. the program if \u03d5 then \u03c01 else \u03c02 can be seen as shorthand for the PDL program (\u03d5?;\u03c01)\u222a(\u00ac\u03d5?;\u03c02). In [13], dynamic epistemic logic with postconditions and PDL constructs is studied (however not in a planning context). Programs like the one above are in [15] called knowledge-based programs and are there studied in an alternative logical setting. Knowledge-based programs are studied in a planning context in [23].\nAn alternative to conditional plans as programs is policies. A policy is a mapping from states into actions, that is, for each state the policy specifies the action chosen in that state (a policy is also sometimes called a strategy or a protocol, depending on the area). Since implemented planning systems often generate conditional plans via an AND-OR graph search in the state space, a policy comes as a more direct output of these algorithms than a program (e.g. one does not have to synthesise appropriate ifconditions). From now on we will only consider conditional plans as policies, not programs.\nDefinition 9. Let \u03a0 = (A,s0,\u03d5g) be a planning task and i \u2208 A be an agent. An i-policy \u03c0 for \u03a0 is a partial mapping \u03c0 : Sgl \u21aa\u2192 A from global states into actions such that\n(1) If \u03c0(s) = a then a is applicable in si.\n(2) If si = t i then \u03c0(s) = \u03c0(t).\nAn i-policy is a policy from the perspective of agent i. Condition (1) ensures that in such a policy, agent i always knows that the next action to be performed is applicable (knowledge of preconditions). Condition (2) is a uniformity condition: If two global states are indistinguishable to agent i, agent i has to make the same choice in both.\nDefinition 10. An execution of a policy \u03c0 from a global state s0 is a maximal (finite or infinite) sequence of alternating global states and actions (s0,a1,s1,a2,s2, . . .) such that for all m\u2265 0,\n(1) \u03c0(sm) = am+1, and\n(2) sm+1 \u2208 Globals(sm\u2297am+1). 12Note that the if-condition of the if-then-else construct is a K-formula expressing knowledge of the planning agent (Father). All such if-conditions are required to be K-formulas of the planning agent, as an agent can only make a choice based on what he knows. Otherwise we could simply construct a conditional plan like if At(Present,PO1) then Go(Father,Home,PO1) else Go(Father,Home,PO2). However, in this case the agent would not know how to settle the truth-value of the if-condition At(Present,PO1) in the initial state, and would hence not know whether to execute Go(Father,Home,PO1) or Go(Father,Home,PO2).\nAn execution is called successful for a global planning task \u03a0 = (A,s0,\u03d5g) if it is a finite execution (s0,a1,s1, . . . ,an,sn) such that sn |= \u03d5g.\nDefinition 11. A policy \u03c0 for a planning task \u03a0 = (A,s0,\u03d5g) is called a solution to \u03a0 if Globals(s0)\u2286 Dom(\u03c0) and for each s \u2208 Dom(\u03c0), any execution of \u03c0 from s is successful for \u03a0.13\nExample 8. In the birthday present task we can now specify distinct actions to be performed in the two distinct global states of the state s2 of Example 7 (the state after the father has attempted to pickup the present at PO1):\n\u03c0( At(Father,PO1), Has(Father,Present) At(Father,PO1), At(Present,PO2) ) = Go(Father,PO1,Home)\n\u03c0( At(Father,PO1), Has(Father,Present) At(Father,PO1), At(Present,PO2) ) = Go(Father,PO1,PO2).\nThis partial policy can easily be extended into a full solution policy to the planning task.\nExample 9. Consider extending the birthday present example with a post office employee, Employee, working at PO1. We can think of this as a new agent, so now A = {Father,Employee}. It might be possible to call the employee from home to ask whether the present is at the post office. We can assume the employee knows whether the present is at his or her post office, so the initial state would be the same as in Example 7 (sFather0 ), except there is now reflexive loops for Employee at both worlds. We can now represent a general action of an agent i calling an agent j to ask whether a formula \u03d5 is true as the following action, where i, j \u2208 A and \u03d5 \u2208 LKC:\nAsk(i, j,\u03d5) = \u3008K j\u03d5,>\u3009 \u3008K j\u00ac\u03d5,>\u3009 \u3008\u00acK j\u03d5 \u2227\u00acK j\u00ac\u03d5,>\u3009\nThe action model above corresponds to agent j giving a sincere answer to the question \u201cis \u03d5 true?\u201d. Agent j saying \u201cyes\u201d to the question is represented by the event e1, that is, it corresponds to an announcement that agent j knows \u03d5 . Event e2 corresponds to saying \u201cno\u201d, and e3 corresponds to saying \u201cI don\u2019t know\u201d. We now get\nsFather0 \u2297Ask(Father,Employee,At(Present,PO1)) = At(Father,H), At(Present,PO1)\nAt(Father,Home), At(Present,PO2)\nThis is because in w1 of sFather0 we have that KEmployeeAt(Present,PO1) holds and in w2 of s Father 0 we have KEmployee\u00acAt(Present,PO1), and the action model for Ask(Father,Employee,At(Present,PO1))\n13Note that a solution policy has to lead to successful executions for all global states in s0 (and for all global states along all possible executions of the policy). Such policies are often called strong policies, because the requirement is that they are guaranteed to succeed under alle circumstances (considered possible by the planning agent). In conditional planning, one often also considers weak solutions (weak policies) that have a possibility of succeeding, but might not always succeed. A weak solution to the birthday present task would be to go to PO1, attempt picking up the present there, go home, and then wrap the present if one has it. This plan can clearly fail if the present is at PO2. In this paper we restrict attention to strong solutions.\nis clearly seen to cut the link between worlds satisfying KEmployee\u00acAt(Present,PO1) and worlds satisfying KEmployee\u00acAt(Present,PO1) (since there are two distinguishable events with these formulas as preconditions). Hence the planning agent, Father, can conclude\ns0\u2297Ask(Father,Employee,At(Present,PO1)) |= KFatherAt(Present,PO1)\u2228KFatherAt(Present,PO2)\nand hence that he can first call to ask the post office employee whether she has the present, and then next he will know where to go."}, {"heading": "10 Public and private actions", "text": "The Ask action above is a bit simplified. It is publicly observable: the indistinguishability relation is the identity. When there is only two agents in the scenario this is acceptable, since they can only call each other, but if there were more agents present, these would probably not observe the phone call taking place. Consider adding a third agent, Employee2, working at PostOffice2. If Father calls Employee, Employee2 will not know, and might not even consider it possible that the phone call could have taken place. To model this we have to go beyond equivalence classes in epistemic models and action models, since now it becomes possible to have false beliefs, e.g. a false belief that no phone call took place (or a false belief that Father does not yet know At(Present,PO2)). In this case, we could model the private phone call of agent i to agent j asking about \u03d5 as follows:\nAsk(i, j,\u03d5) =\n\u3008K j\u03d5,>\u3009 \u3008K j\u00ac\u03d5,>\u3009 \u3008\u00acK j\u03d5 \u2227\u00acK j\u00ac\u03d5,>\u3009\n\u3008>,>\u3009\nA\u2212{i, j} A\u2212{i, j} A\u2212{i, j}\nThis models that agent i and j know the phone call takes place (and know the outcome of the phone call), but all other agents think that nothing has happened (the skip event \u3008>,>\u3009). We can even model that some subset B \u2286A of agents hear the question being asked, but not the answer (they are together with i, but cannot hear what is being said in the other end):\nAsk(i, j,\u03d5) =\n\u3008K j\u03d5,>\u3009 \u3008K j\u00ac\u03d5,>\u3009 \u3008\u00acK j\u03d5 \u2227\u00acK j\u00ac\u03d5,>\u3009\n\u3008>,>\u3009\nA\u2212{i, j}\u2212B A\u2212{i, j}\u2212B A\u2212{i, j}\u2212B\nB B\nThese examples illustrate that designing action models to represent actions under multi-agent partial observability is far from a trivial matter. Some recent papers try to propose different ways of encoding observability information into a logical language, so that the action models themselves can become simpler, more uniform, and automatically induced from the underlying observability information [5, 7, 18]. However, there are still many unsolved problems in this area.\nThe possibility of representing private actions (only observed by a subset of agents, whereas the other agents believe nothing happens) is also what allows us to model the full version of the birthday present example, where the daughter does not get to know that the father has the present. We can for instance model that only agents who are copresent (in the same location) can observe actions taking place in that location (see [10] for a discussion and treatment of copresence in an epistemic planning setting). For instance, the Wrap action could be reformulated as follows:\nWrap(agt,obj, loc) = \u3008At(agt, loc)\u2227Has(agt,obj)\u2227\u00acWrapped(obj), Wrapped(obj)\u3009\n\u3008>,>\u3009\n{i : \u00acAt(i, loc)}i\u2208A\nWe here use a new type of action model that we call an edge-conditioned action model [5]. The meaning of the label on the edge is that there is an edge for agent i here if \u00acAt(i, loc) is true (agent i is not present in the location where the present is being wrapped). Such edge-conditioned action models are a variant of generalised arrow updates [22].\nWith the wrapping action presented as above, the father will e.g. be able to figure out that if the daughter is at home (At(Daughter,Home) is true), then only the plan where he executes Wrap at the post office will lead to Wrapped(Present)\u2227\u00acKDaughterHas(Father,Present) (recall the state-transition system in Figure 2 that shows that the present can either be wrapped in the post office or at home)."}, {"heading": "11 Multi-agent planning", "text": "So far we have only considered the case of a single agent planning in the presence of other agents. The formal framework of course also allows to represent real multi-agent planning tasks. However, for true multi-agent planning a lot of additional design choices have to be made. Are the agents collaborating or competing? Are there coalitions of agents trying to achieve a joint goal, perhaps against the agents outside the coalition? Can the agents communicate and coordinate arbitrarily when coming up with a plan, and will they commit to such a joint plan? The papers [14, 8] look at implicitly coordinated plans, where agents have a joint goal but are not allowed to coordinate or negotiate in advance. All coordination should happen during plan executions as a result of announcements and observing the actions of others.\nIn the birthday present example it could e.g. be that Father calls Employee to announce the goal Has(Father,Present). Assuming Employee is altruistic and adopts this as his or her own goal, Father and Employee are now engaged in planning with implicit coordination towards the joint goal Has(Father,Present). Assume the present is at PostOffice2. Since Employee knows that Father doesn\u2019t know the location of the present, and that he cannot get the present unless he knows, she will choose to announce that the present is at PostOffice2. This is a case of implicit coordination: The father doesn\u2019t ask the employee about the location of the present, but the employee knows about the goal and can still plan to inform him, in order to allow him to plan the rest of the required actions. These ideas are explored further in [14, 8]."}, {"heading": "12 (Un)decidability and complexity", "text": "One of the most studied problems in epistemic planning based on DEL is the complexity of the plan existence problems. The plan existence problem for a class of planning tasks X is the following decision\nproblem: Given a planning task \u03a0 \u2208 X , does there exist a solution to \u03a0? So far only the complexity of deciding whether a sequential plan exists have been studied. For general epistemic planning tasks the problem is undecidable already with two agents, no common knowledge, and even without postconditions (that is, purely epistemic planning without ontic change) [2]. This has lead to a quest for finding decidable, but still reasonably expressive, fragments of epistemic planning. The first result along these lines proved that epistemic planning with propositional preconditions (that is, no epistemic formulas in the preconditions) is decidable [31]. An upper bound on complexity is in that paper shown to be (n+1)EXPTIME for planning tasks in which the goal formula has modal depth n. In [11] it is shown that when the preconditions are propositional and there are no postconditions, then the plan existence problem is PSPACE-complete (for arbitrary goal formulas). If restricting further to certain types of actions, like private and public announcements, complexity of plan existence goes further down to NP-complete [9]."}, {"heading": "13 Alternative approaches to epistemic planning", "text": "Epistemic planning based on DEL takes a semantic approach, where states are represented as semantical objects, epistemic states. It is also possible to take a syntactic approach, where states are represented as knowledge-bases, sets of formulas known to be true. Interestingly, STRIPS and propositional planning are semantic and syntactic at the same time, since in propositional logic a semantic state is just a set of formulas (a set of true atomic propositions). This means that when generalising from STRIPS or propositional planning to epistemic planning, it is not immediately obvious whether a semantic or syntactic approach would be most appropriate. Both approaches have their strength and weaknesses.\nEpistemic planning based on DEL also takes the approach of insisting on succinct action representations via action models. We argued in favour of this approach already very early in the paper by mentioning the weaknesses of attempting to represent planning tasks explicitly as state-transition systems. In fact, the state-transition systems induced by epistemic planning tasks will often be infinite, so even if choosing a state-transition system based approach, one will need a way to represent them finitely in order to be able to do planning based on them [20]. From the perspective of classical planning, the most appropriate approach to representing state-transition systems compactly seems to be representing the actions themselves in a compact way (using some kind of action models or action schemas).\nBased on the above, we can distinguish approaches to epistemic planning along two dimensions:\n\u2022 Semantic approaches versus syntactic approaches.\n\u2022 Action model based approaches versus state-transition system based approaches.\nThe approach of this paper is, as mentioned, semantic and action model based. Syntactic approaches to epistemic planning can be found in e.g. the (single-agent) PKS planner [27], the (multi-agent) planning framework of [25] and the compilation approach of [21], translating a restricted fragment of epistemic planning into classical planning. The state-transition system based approach is found in a number of papers in temporal epistemic logic, e.g. [19, 20]. In these papers, the planning domains are represented by a type of epistemic state-transition system called a concurrent epistemic game structure (CEGS). Having an explicitly represented state-transition system like a CEGS tends to make it easier to define complex notions of multi-agent plans (strategies). On the other hand, by working directly with statetransition systems, some of the important problems of epistemic planning are being silently bypassed. These problems include compact representations of the state-transition system, and efficient heuristics for avoiding to build the entire state-transition system when planning. They also include problems of how to provide a general approach to multi-agent observability and problems of concurrent composition\nof actions of multiple agents. In CEGS, transitions represent joint actions, one action per agent. The problem of how to make a parallel composition of the actions of the individual agents has to be solved before one can even build the CEGS for a given planning domain. In epistemic planning based on DEL, this problem has to be solved at the level of action models: How do we make a parallel composition of two action models in case they are not independent (e.g. two agents trying to open a door at the same time, but from opposite sides). Epistemic planning tasks can be seen as inducing e.g. forests of epistemic temporal logic [3] or CEGSs. The exact relations have not been explored yet, but providing a link between the action model based approaches and the state-transition system based approaches could be very valuable and provide a possibility of getting the best of both worlds.\nSimilarly, providing links and connections between syntactic and semantic approaches seem to be potentially very valuable. In a semantic approach, one is essentially modelling ignorance: the more ignorance, the bigger the state. In a syntactic approach, one is essentially modelling knowledge: the more knowledge, the bigger the state. Knowledge and ignorance are each others duals, and hence the semantic and the syntactic approach are also each others duals. It seems that when humans are planning, we are sometimes using a more semantic approach, and sometimes a more syntactic one, depending on the planning task at hand. It would hence also be very interesting to see whether planning frameworks could be developed that would employ or combine both approaches."}], "references": [{"title": "Conditional Epistemic Planning", "author": ["Mikkel Birkegaard Andersen", "Thomas Bolander", "Martin Holm Jensen"], "venue": "Lecture Notes in Artificial Intelligence", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Undecidability in Epistemic Planning", "author": ["Guillaume Aucher", "Thomas Bolander"], "venue": "Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Merging frameworks for interaction: DEL and ETL", "author": ["Johan van Benthem", "Jelle Gerbrandy", "Eric Pacuit"], "venue": "Proceedings of the 11th conference on Theoretical aspects of rationality and knowledge,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "M", "author": ["P. Blackburn"], "venue": "de Rijke & Y. Venema ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "Seeing is Believing: Formalising False-Belief Tasks in Dynamic Epistemic Logic", "author": ["Thomas Bolander"], "venue": "editors: Proceedings of the European Conference on Social Intelligence (ECSI-2014), CEUR Workshop Proceedings 1283,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Epistemic Planning for Single- and Multi-Agent Systems", "author": ["Thomas Bolander", "Mikkel Birkegaard Andersen"], "venue": "Journal of Applied Non-Classical Logics", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Announcements to Attentive Agents", "author": ["Thomas Bolander", "Hans van Ditmarsch", "Andreas Herzig", "Emiliano Lorini", "Pere Pardo", "Fran\u00e7ois Schwarzentruber"], "venue": "Journal of Logic, Language and Information,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Better Eager Than Lazy? How Agent Types Impact the Successfulness of Implicit Coordination", "author": ["Thomas Bolander", "Thorsten Engesser", "Robert Mattmller", "Bernhard Nebel"], "venue": "Distributed and Multi-Agent Planning", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Complexity Results in Epistemic Planning", "author": ["Thomas Bolander", "Martin Holm Jensen", "Fran\u00e7ois Schwarzentruber"], "venue": "editors: Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Continual planning and acting in dynamic multiagent environments", "author": ["Michael Brenner", "Bernhard Nebel"], "venue": "Autonomous Agents and Multi-Agent Systems", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "On the Impact of Modal Depth in Epistemic Planning", "author": ["Tristan Charrier", "Bastien Maubert", "Fran\u00e7ois Schwarzentruber"], "venue": "Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Semantic Results for Ontic and Epistemic Change", "author": ["Hans van Ditmarsch", "Barteld Kooi"], "venue": "editors: Logic and the Foundation of Game and Decision Theory (LOFT 7), Texts in Logic and Games", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Dynamic epistemic logics", "author": ["Jan van Eijck"], "venue": "Johan van Benthem on Logic and Information Dynamics,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Cooperative Epistemic Multi-Agent Planning for Implicit Coordination", "author": ["Thorsten Engesser", "Thomas Bolander", "Robert Mattmller", "Bernhard Nebel"], "venue": "Proceedings of Methods for Modalities,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2017}, {"title": "Reasoning About Knowledge", "author": ["Ronald Fagin", "Joseph Y. Halpern", "Yoram Moses", "Moshe Y. Vardi"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1995}, {"title": "STRIPS: A new approach to the application of theorem proving to problem solving", "author": ["R. Fikes", "N. Nilsson"], "venue": "Artificial Intelligence", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1971}, {"title": "Automated Planning: Theory and Practice", "author": ["Malik Ghallab", "Dana S. Nau", "Paolo Traverso"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "A poor mans epistemic logic based on propositional assignment and higher-order observation. In: Logic, Rationality and Interaction, Lecture Notes in Computer Science 9394", "author": ["Andreas Herzig", "Emiliano Lorini", "Faustine Maffre"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Tractable Multiagent Planning for Epistemic Goals", "author": ["Wiebe van der Hoek", "Michael Wooldridge"], "venue": "Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Beliefs in multiagent planning: From one agent to many", "author": ["Filippos Kominis", "Hector Geffner"], "venue": "Proc. ICAPS Workshop on Distributed and Multi-Agent Planning", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Generalized arrow update logic", "author": ["Barteld Kooi", "Bryan Renne"], "venue": "Proceedings of the 13th Conference on Theoretical Aspects of Rationality and Knowledge,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Knowledge-Based Programs as Plans: Succinctness and the Complexity of Plan Existence", "author": ["J\u00e9r\u00f4me Lang", "Bruno Zanuttini"], "venue": "TARK", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Learning STRIPS Operators from Noisy and Incomplete Observations", "author": ["Kira Mour\u00e3o", "Luke S. Zettlemoyer", "Ronald P.A. Petrick", "Mark Steedman"], "venue": "editors: Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Planning Over Multi-Agent Epistemic States: A Classical Planning Approach (Amended Version)", "author": ["Christian Muise", "Vaishak Belle", "Paolo Felli", "Sheila McIlraith", "Tim Miller", "Adrian R Pearce", "Liz Sonenberg"], "venue": "Distributed and Multi-Agent Planning (DMAP-15),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "A Knowledge-Based Approach to Planning with Incomplete Information and Sensing", "author": ["Ronald P.A. Petrick", "Fahiem Bacchus"], "venue": "editors: Proceedings of the Sixth International Conference on Artificial Intelligence Planning and Scheduling (AIPS-2002),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2002}, {"title": "PKS: Knowledge-Based Planning with Incomplete Information and Sensing", "author": ["Ronald P.A. Petrick", "Fahiem Bacchus"], "venue": "ICAPS", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2004}, {"title": "Introduction to automated planning", "author": ["Jussi Rintanen"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2006}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["Stuart Russell", "Peter Norvig"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1995}, {"title": "Efficient Learning of Action Schemas and Web-service Descriptions", "author": ["Thomas J. Walsh", "Michael L. Littman"], "venue": "Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 2,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "Multi-agent epistemic explanatory diagnosis via reasoning about actions", "author": ["Quan Yu", "Ximing Wen", "Yongmei Liu"], "venue": "Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}], "referenceMentions": [{"referenceID": 16, "context": "[17] A (restricted) state-transition system (also called a classical planning domain or simply a state space) is \u03a3 = (S,A,\u03b3) where: \u2022 S is a finite or recursively enumerable set of states.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] A classical planning task is a triple (\u03a3,s0,Sg) where: \u2022 \u03a3 = (S,A,\u03b3) is a state-transition system (a classical planning domain).", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "The classical language for describing states and actions in the field of automated planning is STRIPS [16].", "startOffset": 102, "endOffset": 106}, {"referenceID": 27, "context": "We will here introduce STRIPS slightly informally, and the interested reader is referred to [29] for more details.", "startOffset": 92, "endOffset": 96}, {"referenceID": 18, "context": "in [19] can be claimed to be tractable, even though already basic propositional STRIPS planning, which is much less expressive, is intractable.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "3Called a set-theoretic planning task in [17].", "startOffset": 41, "endOffset": 45}, {"referenceID": 28, "context": "for learning actions/action models [30, 24].", "startOffset": 35, "endOffset": 43}, {"referenceID": 22, "context": "for learning actions/action models [30, 24].", "startOffset": 35, "endOffset": 43}, {"referenceID": 16, "context": "6This is consistent with how the transition function is defined for conditional actions in [17], but only for actions in which the events have pairwise mutually inconsistent preconditions.", "startOffset": 91, "endOffset": 95}, {"referenceID": 16, "context": "In [17], the latter interpretation is used.", "startOffset": 3, "endOffset": 7}, {"referenceID": 24, "context": "In s1, the father has run time uncertainty [26] about the location of the present.", "startOffset": 43, "endOffset": 47}, {"referenceID": 24, "context": "In s2, however, he should only have plan time uncertainty [26].", "startOffset": 58, "endOffset": 62}, {"referenceID": 16, "context": "[17, 28]) is to treat observability as a static partition on the set of possible worlds, so that certain possible worlds are always distinguishable and others never are.", "startOffset": 0, "endOffset": 8}, {"referenceID": 26, "context": "[17, 28]) is to treat observability as a static partition on the set of possible worlds, so that certain possible worlds are always distinguishable and others never are.", "startOffset": 0, "endOffset": 8}, {"referenceID": 27, "context": "The generalisation from belief states (in the standard AI sense of sets of propositional states [29]) to epistemic states (in the sense of epistemic logic) also allows us to represent planning tasks involving multiple agents.", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "This is exactly how epistemic actions are defined in dynamic epistemic logic (DEL) with postconditions [12].", "startOffset": 103, "endOffset": 107}, {"referenceID": 11, "context": "9This definition of postconditions is slightly less general than the standard definition of postconditions in DEL [12].", "startOffset": 114, "endOffset": 118}, {"referenceID": 11, "context": "In [12] it is shown that any action model can be equivalently represented by one in which post(e)(p)\u2208 {p,>,\u22a5} for all e\u2208 E and p\u2208 P.", "startOffset": 3, "endOffset": 7}, {"referenceID": 5, "context": "Such simplified (but potentially larger) action models can immediately be translated into the form defined here (see [6] for details).", "startOffset": 117, "endOffset": 120}, {"referenceID": 5, "context": "11For a definition of bisimulation between epistemic models with multiple designated points, see [6].", "startOffset": 97, "endOffset": 100}, {"referenceID": 3, "context": "For a definition of bisimulation on models of modal logic in general, and a definition of bisimulation contraction, see [4].", "startOffset": 120, "endOffset": 123}, {"referenceID": 0, "context": "Such programs for epistemic planning tasks are formally defined and explored in [1] (single-agent case only).", "startOffset": 80, "endOffset": 83}, {"referenceID": 12, "context": "In [13], dynamic epistemic logic with postconditions and PDL constructs is studied (however not in a planning context).", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "Programs like the one above are in [15] called knowledge-based programs and are there studied in an alternative logical setting.", "startOffset": 35, "endOffset": 39}, {"referenceID": 21, "context": "Knowledge-based programs are studied in a planning context in [23].", "startOffset": 62, "endOffset": 66}, {"referenceID": 4, "context": "Some recent papers try to propose different ways of encoding observability information into a logical language, so that the action models themselves can become simpler, more uniform, and automatically induced from the underlying observability information [5, 7, 18].", "startOffset": 255, "endOffset": 265}, {"referenceID": 6, "context": "Some recent papers try to propose different ways of encoding observability information into a logical language, so that the action models themselves can become simpler, more uniform, and automatically induced from the underlying observability information [5, 7, 18].", "startOffset": 255, "endOffset": 265}, {"referenceID": 17, "context": "Some recent papers try to propose different ways of encoding observability information into a logical language, so that the action models themselves can become simpler, more uniform, and automatically induced from the underlying observability information [5, 7, 18].", "startOffset": 255, "endOffset": 265}, {"referenceID": 9, "context": "We can for instance model that only agents who are copresent (in the same location) can observe actions taking place in that location (see [10] for a discussion and treatment of copresence in an epistemic planning setting).", "startOffset": 139, "endOffset": 143}, {"referenceID": 4, "context": "We here use a new type of action model that we call an edge-conditioned action model [5].", "startOffset": 85, "endOffset": 88}, {"referenceID": 20, "context": "Such edge-conditioned action models are a variant of generalised arrow updates [22].", "startOffset": 79, "endOffset": 83}, {"referenceID": 13, "context": "Are the agents collaborating or competing? Are there coalitions of agents trying to achieve a joint goal, perhaps against the agents outside the coalition? Can the agents communicate and coordinate arbitrarily when coming up with a plan, and will they commit to such a joint plan? The papers [14, 8] look at implicitly coordinated plans, where agents have a joint goal but are not allowed to coordinate or negotiate in advance.", "startOffset": 292, "endOffset": 299}, {"referenceID": 7, "context": "Are the agents collaborating or competing? Are there coalitions of agents trying to achieve a joint goal, perhaps against the agents outside the coalition? Can the agents communicate and coordinate arbitrarily when coming up with a plan, and will they commit to such a joint plan? The papers [14, 8] look at implicitly coordinated plans, where agents have a joint goal but are not allowed to coordinate or negotiate in advance.", "startOffset": 292, "endOffset": 299}, {"referenceID": 13, "context": "These ideas are explored further in [14, 8].", "startOffset": 36, "endOffset": 43}, {"referenceID": 7, "context": "These ideas are explored further in [14, 8].", "startOffset": 36, "endOffset": 43}, {"referenceID": 1, "context": "For general epistemic planning tasks the problem is undecidable already with two agents, no common knowledge, and even without postconditions (that is, purely epistemic planning without ontic change) [2].", "startOffset": 200, "endOffset": 203}, {"referenceID": 29, "context": "The first result along these lines proved that epistemic planning with propositional preconditions (that is, no epistemic formulas in the preconditions) is decidable [31].", "startOffset": 166, "endOffset": 170}, {"referenceID": 10, "context": "In [11] it is shown that when the preconditions are propositional and there are no postconditions, then the plan existence problem is PSPACE-complete (for arbitrary goal formulas).", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": "If restricting further to certain types of actions, like private and public announcements, complexity of plan existence goes further down to NP-complete [9].", "startOffset": 153, "endOffset": 156}, {"referenceID": 25, "context": "the (single-agent) PKS planner [27], the (multi-agent) planning framework of [25] and the compilation approach of [21], translating a restricted fragment of epistemic planning into classical planning.", "startOffset": 31, "endOffset": 35}, {"referenceID": 23, "context": "the (single-agent) PKS planner [27], the (multi-agent) planning framework of [25] and the compilation approach of [21], translating a restricted fragment of epistemic planning into classical planning.", "startOffset": 77, "endOffset": 81}, {"referenceID": 19, "context": "the (single-agent) PKS planner [27], the (multi-agent) planning framework of [25] and the compilation approach of [21], translating a restricted fragment of epistemic planning into classical planning.", "startOffset": 114, "endOffset": 118}, {"referenceID": 18, "context": "[19, 20].", "startOffset": 0, "endOffset": 8}, {"referenceID": 2, "context": "forests of epistemic temporal logic [3] or CEGSs.", "startOffset": 36, "endOffset": 39}], "year": 2017, "abstractText": "Epistemic planning can be used for decision making in multi-agent situations with distributed knowledge and capabilities. Dynamic Epistemic Logic (DEL) has been shown to provide a very natural and expressive framework for epistemic planning. In this paper, we aim to give an accessible introduction to DEL-based epistemic planning. The paper starts with the most classical framework for planning, STRIPS, and then moves towards epistemic planning in a number of smaller steps, where each step is motivated by the need to be able to model more complex planning scenarios.", "creator": "LaTeX with hyperref package"}}}