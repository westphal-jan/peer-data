{"id": "1703.10476", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Mar-2017", "title": "Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training", "abstract": "milstein While strong scaddan progress has 13.09 been hebert made sondheimer in shoaling image montagny captioning bluteau over the isentropic last tawiah years, somebody machine bashkimi and mimico human 220-million captions are 537,000 still 32-percent quite distinct. A akhdar closer look hibs reveals that this is jan.-jun due diviner to yuan-ti the deficiencies 30-year in the 8-4 generated http://www.fema.gov word distribution, vocabulary chhattisgarh size, and strong bias in the generators time-weighted towards ayoo frequent 2nd-century captions. nister Furthermore, vaesteraas humans - - briefcase rightfully so - - 984,000 generate multiple, diverse euro409 captions, sparapet due to the inherent ambiguity in tenaris the reestablishing captioning kredell task gallie which omicron is futagoyama not considered in paya today ' lamego s ampat systems.", "histories": [["v1", "Thu, 30 Mar 2017 13:54:51 GMT  (9553kb,D)", "http://arxiv.org/abs/1703.10476v1", "16 pages"]], "COMMENTS": "16 pages", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.CL", "authors": ["rakshith shetty", "marcus rohrbach", "lisa anne hendricks", "mario fritz", "bernt schiele"], "accepted": false, "id": "1703.10476"}, "pdf": {"name": "1703.10476.pdf", "metadata": {"source": "CRF", "title": "Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training", "authors": ["Rakshith Shetty", "Marcus Rohrbach", "Lisa Anne Hendricks", "Mario Fritz", "Bernt Schiele"], "emails": [], "sections": null, "references": [], "referenceMentions": [], "year": 2017, "abstractText": "While strong progress has been made in image caption-<lb>ing over the last years, machine and human captions are<lb>still quite distinct. A closer look reveals that this is due to<lb>the deficiencies in the generated word distribution, vocabu-<lb>lary size, and strong bias in the generators towards frequent<lb>captions. Furthermore, humans \u2013 rightfully so \u2013 generate<lb>multiple, diverse captions, due to the inherent ambiguity in<lb>the captioning task which is not considered in today\u2019s sys-<lb>tems. To address these challenges, we change the training ob-<lb>jective of the caption generator from reproducing ground-<lb>truth captions to generating a set of captions that is indis-<lb>tinguishable from human generated captions. Instead of<lb>handcrafting such a learning target, we employ adversar-<lb>ial training in combination with an approximate Gumbel<lb>sampler to implicitly match the generated distribution to the<lb>human one. While our method achieves comparable perfor-<lb>mance to the state-of-the-art in terms of the correctness of<lb>the captions, we generate a set of diverse captions, that are<lb>significantly less biased and match the word statistics better<lb>in several aspects.", "creator": "LaTeX with hyperref package"}}}