{"id": "1703.10772", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Mar-2017", "title": "Joining Hands: Exploiting Monolingual Treebanks for Parsing of Code-mixing Data", "abstract": "raymond In this paper, schweder we llanymynech propose insalata efficient and hootin less resource - intensive varzi strategies finavia for parsing vesterbro of code - coppertone mixed gaddang data. southtrust These valbona strategies are diputaci\u00f3n not constrained by wbb in - geist domain piesiewicz annotations, rather they leverage 21min pre - zala existing titmus monolingual trondheimsfjord annotated damm resources for training. sudden-death We show that jumilla these fateha methods ichthyosis can spermophilus produce rxd4 significantly 54.4 better results as gunasekera compared alekos to an atakora informed pinatubo baseline. tilaka Besides, we teaser also fouth present a minotaurs data set of 49-state 450 cholo Hindi and English madoc code - georgiades mixed tweets of Hindi multilingual speakers for evaluation. cumulative The repechage data baa1 set berdimuhamedow is guhl manually marrs annotated with Universal ramberg Dependencies.", "histories": [["v1", "Fri, 31 Mar 2017 07:10:30 GMT  (28kb)", "http://arxiv.org/abs/1703.10772v1", "5 pages, EACL 2017 short paper"]], "COMMENTS": "5 pages, EACL 2017 short paper", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["irshad ahmad bhat", "riyaz ahmad bhat", "manish shrivastava", "dipti misra sharma"], "accepted": false, "id": "1703.10772"}, "pdf": {"name": "1703.10772.pdf", "metadata": {"source": "CRF", "title": "Joining Hands: Exploiting Monolingual Treebanks for Parsing of Code-mixing Data", "authors": ["Irshad Ahmad Bhat", "Riyaz Ahmad Bhat", "Manish Shrivastava"], "emails": ["irshad.bhat@iiit.ac.in", "riyaz.bhat@iiit.ac.in", "m.shrivastava@iiit.ac.in", "dipti@iiit.ac.in"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 3.\n10 77\n2v 1\n[ cs\n.C L\n] 3\n1 M\nar 2\n01 7\nless resource-intensive strategies for parsing of code-mixed data. These strategies are not constrained by in-domain annotations, rather they leverage pre-existing monolingual annotated resources for training. We show that these methods can produce significantly better results as compared to an informed baseline. Besides, we also present a data set of 450 Hindi and English code-mixed tweets of Hindi multilingual speakers for evaluation. The data set is manually annotated with Universal Dependencies."}, {"heading": "1 Introduction", "text": "Code-switching or code-mixing is a sociolinguistic phenomenon, where multilingual speakers switch back and forth between two or more common languages or language varieties in a single utterance1 . The phenomenon is mostly prevalent in spoken language and in informal settings on social media such as in news groups, blogs, chat forums etc. Computational modeling of code-mixed data, particularly from social media, is presumed to be more challenging than monolingual data due to various factors. The main contributing factors are non-adherence to a standard grammar, spelling variations and/or back-transliteration. It has been generally observed that traditional NLP techniques perform miserably when processing code-mixed language data (Solorio and Liu, 2008b; Vyas et al., 2014; C\u0327etinog\u0306lu et al., 2016).\n1For brevity, we will not differentiate between intra- and inter-sentential mixing of languages and use the terms codemixing and code-switching interchangeably throughout the paper.\nMore recently, there has been a surge in studies concerning code-mixed data from social media (Solorio and Liu, 2008a; Solorio and Liu, 2008a; Vyas et al., 2014; Sharma et al., 2016; Rudra et al., 2016; Joshi et al., 2016, and others). Besides these individual research articles, a series of shared-tasks and workshops on preprocessing and shallow syntactic analysis of code-mixed data have also been conducted at multiple venues such as Empirical Methods in NLP (EMNLP 2014 and 2016), International Conference on NLP (ICON 2015 and 2016) and Forum for Information Retrieval Evaluation (FIRE 2015 and 2016). Most of these works are an attempt to address preprocessing issues\u2013such as language identification and transliteration\u2013that any higher NLP application may face in processing such data.\nDue to paucity of annotated resources in codemixed genre, the performance of monolingual parsing models is yet to be evaluated on codemixed structures. This paper serves to fill this gap by presenting an evaluation set annotated with dependency structures. Besides, we also propose different parsing strategies that exploit nothing but the pre-existing annotated monolingual data. We show that by making trivial adaptations, monolingual parsing models can effectively parse codemixed data."}, {"heading": "2 Parsing Strategies", "text": "We explore three different parsing strategies to parse code-mixed data and evaluate their performance on a manually annotated evaluation set. These strategies are distinguished by the way they use pre-existing treebanks for parsing code-mixed data.\n\u2022 Monolingual: The monolingual method uses\ntwo separate models trained from the respective monolingual treebanks of the languages which are present in the code-mixed data. We can use the monolingual models in two different ways. Firstly, we can parse each code-mixed sentence by intelligently choosing the monolingual model based on the matrix language of the sentence.2 A clear disadvantage of this method is that the monolingual parser may not accurately parse those fragments of a sentence which belong to a language unknown to the model. Therefore, we consider this as the baseline method. Secondly, we can linearly interpolate the predictions of both monolingual models at the inference time. The interpolation weights are chosen based on the matrix language of each parsing configuration. The interpolated oracle output is defined as:\ny = argmax(\u03bbm \u2217 f(\u03c6(cm))+\n(1\u2212 \u03bbm) \u2217 f(\u03c6(cs))) (1)\nwhere f(\u00b7) is a softmax layer of our neural parsing model, \u03c6(cm) and \u03c6(cs) are the feature functions of the matrix and subordinate languages respectively and \u03bbm is the interpolation weight for the matrix language (see Section \u00a75 for more details on the parsing model).\nInstead of selecting the matrix language at sentence level, we define the matrix language individually for each parsing configuration. We define the matrix language of a configuration based on the language tags of top 2 nodes in the stack and buffer belonging to certain syntactic categories such as adposition, auxiliary, particle and verb.\n\u2022 Multilingual: In the second approach, we train a single model on a combined treebank of the\nlanguages represented in the code-mixed data. This method has a clear advantage over the baseline Monolingual method in that it would be aware of the grammars of both languages of the code-mixed data. However, it may not be able to properly connect the fragments of two languages as the model lacks evidence for such mixed structures in the augmented data. This would particularly happen if the code-mixed languages are typologically diverse.\n2In any code-mixed utterance, the matrix language defines the overall grammatical structure of an utterance, while subordinate language represents any individual words or phrases embedded in the matrix language. We use a simple countbased approach to identify the matrix and subordinate languages of a code-mixed sentence.\nMoreover, training a parsing model on augmented data with more diverse structures will worsen the structural ambiguity problem. But we can easily circumvent this problem by including token-level language tag as an additional feature in the parsing model (Ammar et al., 2016).\n\u2022 Multipass: In the Multipass method, we train two separate models like the Monolingual\nmethod. However, we apply these models on the code-mixed data differently. Unlike Monolingual method, we use both models simultaneously for each sentence and pass the input to the models twice. There are two possible ways to accomplish this. We can first parse all the fragments of each language using their respective parsing models one by one and then the root nodes of the parsed fragments would be parsed by the matrix language parsing model. Or, we can parse the subordinate language first and then parse the root of the subordinate fragments with the fragments of matrix language using the matrix language parser. In both cases, monolingual parsers would not be affected by the cross language structures. More importantly, matrix language parser in the second pass would be unaffected by the internal structure of the subordinate language fragments. But there is a caveat, we need to identify the code-mixed fragments accurately, which is a non-trivial task. In this paper, we use token-level language information to segment tweets into subordinate or matrix language fragments."}, {"heading": "3 Code-mixed Dependency Annotations", "text": "To the best of our knowledge, there is no available code-mixed data set that contains dependency annotations. There are, however, a few available code-mixed data sets that provide annotations related to language of a token, its POS and chunk tags. For an intrinsic evaluation of our parsing models on code-mixed texts, we manually annotated a data set of Hindi-English codemixed tweets with dependency structures. The code-mixed tweets were sampled from a large set of tweets of Indian language users that we crawled from Twitter using Tweepy3\u2013a Twitter API wrapper. We used a language identification system (see \u00a74) to filter Hindi-English codemixed tweets from the crawled Twitter data. Only\n3http://www.tweepy.org/\nthose tweets were selected that satisfied a minimum ratio of 30:70(%) code-mixing. From this data set, we manually selected 450 tweets for annotation. The selected tweets are thoroughly checked for code-mixing ratio. While calculating the code-mixing ratio, we do not consider borrowings from English as an instance of codemixing. For POS tagging and dependency annotation, we used Universal dependency guidelines (De Marneffe et al., 2014), while language tags are assigned based on the tagset defined in (Solorio et al., 2014; Jamatia et al., 2015). The annotations are split into testing and tuning sets for evaluation and tuning of our models. The tuning set consists of 225 tweets (3,467 tokens) with a mixing ratio of 0.54 and the testing set contains 225 tweets (3,322 tokens) with a mixing ratio of 0.53. Here mixing ratio is defined as:\n1\nn\nn\u2211\ns=1\nHs\nHs + Es (2)\nwhere n is the number of sentences in the data set,Hs and Es are the number of Hindi words and English words in sentence s respectively."}, {"heading": "4 Preprocessing", "text": "The parsing strategies that we discussed above for code-mixed texts heavily rely on language identification of individual tokens. Besides we also need normalization of non-standard word forms prevalent in code-mixed social media content and backtransliteration of Romanized Hindi words. Here we discuss both preprocessing steps in brief.\nLanguage Identification We model language identification as a classification problem where each token needs to be classified into one of the following tags: \u2018Hindi\u2019 (hi), \u2018English\u2019 (en), \u2018Acronym\u2019 (acro), \u2018Named Entity\u2019 (ne) and \u2018Universal\u2019 (univ). For this task, we use the feedforward neural network architecture of Bhat et al. (2016)4 proposed for Named Entity extraction in code mixed-data of Indian languages. We train the network with similar feature representations on the data set provided in ICON 20155 shared task on language identification. The data set contains 728 Facebook comments annotated with the five language tags noted above. We evaluated the\n4Due to space limitation we don\u2019t discuss the system architecture in detail. The interested reader can refer to the original paper for a detailed description.\n5http://ltrc.iiit.ac.in/icon2015/\npredictions of our identification system against the gold language tags in our code-mixed development set and test set. Even though the model is trained on a very small data set, its prediction accuracy is still above 96% for both the development set and the test set. The results are shown in Table 1.\nNormalization and Transliteration We model the problem of both normalization and backtransliteration of (noisy) Romanized Hindi words as a single transliteration problem. Our goal is to learn a mapping for both standard and non-standard Romanized Hindi word forms to their respective standard forms in Devanagari. For this purpose, we use the structured perceptron of Collins (Collins, 2002) which optimizes a given loss function over the entire observation sequence. For training the model, we use the transliteration pairs (87,520) from the Libindic transliteration project6 and Brahmi-Net (Kunchukuttan et al., 2015) and augmented them with noisy transliteration pairs (63,554) which are synthetically generated by dropping noninitial vowels and replacing consonants based on their phonological proximity. We use Giza++ (Och and Ney, 2003) to character align the transliteration pairs for training.\nAt inference time, our transliteration model would predict the most likely word form for each input word. However, the single-best output from the model may not always be the best option considering an overall sentential context. Contracted word forms in social media content are quite often ambiguous and can represent different standard word forms such as \u2018pt\u2019 may refer to \u2018put\u2019, \u2018pit\u2019, \u2018pat\u2019, \u2018pot\u2019 and \u2018pet\u2019. To resolve this ambiguity, we extract n-best transliterations from the transliteration model using beam-search decoding. The best word sequence is then decoded using an exact search over bn word sequences7 scored by a tri-gram language model. The language model is trained on monolingual data using IRSTLM-Toolkit (Federico et al., 2008) with Kneser-Ney smoothing. For English, we use a similar model for normalization which we trained on the noisy word forms (3,90,000) synthetically generated from the English vocabulary.\n6https://github.com/libindic/indic-trans 7 b is the size of beam-width and n is the sentence length. For each word, we extract five best transliterations or normalizations i.e., b=5."}, {"heading": "5 Experimental Setup", "text": "The parsing experiments reported in this paper are conducted using a non-linear neural network-based transition system which is similar to (Chen and Manning, 2014). The models are trained on Universal Dependency Treebanks of Hindi and English released under version 1.4 of Universal Dependencies (Nivre et al., 2016).\nParsing Models Our parsing model is based on transition-based dependency parsing paradigm (Nivre, 2008). Particularly, we use an arc-eager transition system (Nivre, 2003). The arc-eager system defines a set of configurations for a sentence w1,...,wn, where each configuration C = (S, B, A) consists of a stack S, a buffer B, and a set of dependency arcs A. For each sentence, the parser starts with an initial configuration where S = [ROOT], B = [w1,...,wn] and A = \u2205 and terminates with a configuration C if the buffer is empty and the stack contains the ROOT. The parse trees derived from transition sequences are given by A. To derive the parse tree, the arc-eager system defines four types of transitions (t): 1) Shift, 2) Left-Arc, 3) Right-Arc, and 4) Reduce.\nSimilar to (Chen and Manning, 2014), we use a non-linear neural network to predict the transitions for the parser configurations. The neural network model is the standard feed-forward neural network with a single layer of hidden units. We use 200 hidden units and RelU activation function. The output layer uses softmax function for probabilistic multi-class classification. The model is trained by minimizing cross entropy loss with an l2-regularization over the entire training data. We also use mini-batch Adagrad for optimization (Duchi et al., 2011) and apply dropout (Hinton et al., 2012).\nFrom each parser configuration, we extract features related to the top four nodes in the stack, top four nodes in the buffer and leftmost and rightmost children of the top two nodes in the stack and the leftmost child of the top node in the buffer.\nPOS Models We train POS tagging models using a similar neural network architecture as dis-\ncussed above. Unlike (Collobert et al., 2011), we do not learn separate transition parameters. Instead we include the structural features in the input layer of our model with other lexical and nonlexical units. We use second-order structural features, two words to either side of the current word, and last three characters of the current word.\nWe trained two POS tagging models: Monolingual and Multilingual. In the Monolingual approach, we divide each code-mixed sentence into contiguous fragments based on the language tags assigned by the language identifier. Words with language tags other than \u2018Hi\u2019 and \u2018En\u2019 (such as univ, ne and acro) are merged with the preceding fragment. Each fragment is then individually tagged by the monolingual POS taggers trained on their respective monolingual POS data sets. In the Multilingual approach, we train a single model on combined data sets of the languages in the codemixed data. We concatenate an additional 1x2 vector8 in the input layer of the neural network representing the language tag of the current word. Table 2 gives the POS tagging accuracies of the two models.\nWord Representations For both POS tagging and parsing models, we include the lexical features in the input layer of the Neural Network using the pre-trained word representations while for the non-lexical features, we use randomly initialized embeddings within a range of \u22120.25 to +0.25.9 We use Hindi and English monolingual corpora to learn the distributed representation of the lexical units. The English monolingual data contains around 280M sentences, while the Hindi data is comparatively smaller and contains around 40M sentences. The word representations are learned using Skip-gram model with negative sampling which is implemented in word2vec toolkit (Mikolov et al., 2013). For multilingual models, we use robust projection algorithm of Guo et al. (2015) to induce bilingual representations\n8In our experiments we fixed these to be {-0.25,0.25} for Hindi and {0.25,-0.25 } for English\n9Dimensionality of input units in POS and parsing models: 80 for words, 20 for POS tags, 2 for language tags and 20 for affixes.\nusing the monolingual embedding space of English and a bilingual lexicon of Hindi and English (\u223c63,000 entries). We extracted the bilingual lexicon from ILCI and Bojar Hi-En parallel corpora (Jha, 2010; Bojar et al., 2014)."}, {"heading": "6 Experiments and Results", "text": "We conducted multiple experiments to measure effectiveness of the proposed parsing strategies in both gold and predicted settings. In predicted settings, we use the monolingual POS taggers for all the experiments. We used the Monolingual method as the baseline for evaluating other parsing strategies. The baseline model parses each sentence in the evaluation sets by either using Hindi or English parsing model based on the matrix language of the sentence. For baseline and the Multipass methods, we use bilingual embedding space derived from matrix language embedding space (Hindi or English) to represent lexical nodes in the input layer of our parsing architecture. In the Interpolation method, we use separate monolingual embedding spaces for each model. The interpolation weights are tuned using the development set and the best results are achieved at \u03bbm ranging from 0.7 to 0.8 (see eq. 1). The results of our experiments are reported in Table 3. Table 4 shows the impact of sentential decoding for choosing the best normalized and/or back-transliterated tweets on different parsing strategies (see \u00a74).\nAll of our parsing models produce results that are at-least 10 LAS points better than our baseline parsers which otherwise provide competitive results on Hindi and English evaluation sets (Straka et al., 2016).10 Among all the parsing strategies, the Interpolated methods perform com-\n10Our results are not directly comparable to (Straka et al., 2016) due to different parsing architectures. While we use a simple greedy, projective transition system, Straka et al. (2016) use a search-based swap system.\nparatively better on both monolingual and codemixed evaluation sets. Interpolation method manipulates the parameters of both languages quite intelligently at each parsing configuration. Despite being quite accurate on code-mixed evaluation sets, the Multilingual model is less accurate in single language scenario. Also the Multilingual model performs worse for Hindi since its lexical representation is derived from English embedding space. It is at-least 2 LAS points worse than the Interpolated and the Multipass methods. However, unlike the latter methods, the Multilingual models do not have a run-time and computational overhead. In comparison to Interpolated and Multilingual methods, Multipass methods are mostly affected by the errors in language identification. Quite often these errors lead to wrong segmentation of code-mixed fragments which adversely alter their internal structure.\nDespite higher gains over the baseline models, the performance of our models is nowhere near the performance of monolingual parsers on newswire texts. This is due to inherent complexities of code-mixed social media content (Solorio and Liu, 2008b; Vyas et al., 2014; C\u0327etinog\u0306lu et al., 2016)."}, {"heading": "7 Conclusion", "text": "In this paper, we have evaluated different strategies for parsing code-mixed data that only leverage monolingual annotated data. We have shown that code-mixed texts can be efficiently parsed by the monolingual parsing models if they are intelligently manipulated. Against an informed monolingual baseline, our parsing strategies are at-least 10 LAS points better. Among different strategies that we proposed, Multilingual and Interpolation methods are two competitive methods for parsing code-mixed data.\nThe code of the parsing models is available at the GitHub repository https://github. com/irshadbhat/cm-parser, while the data can be found under the Universal Dependencies of Hindi at https://github.com/ UniversalDependencies/UD_Hindi."}], "references": [{"title": "Code mixed entity extraction in indian languages using neural networks", "author": ["Manish Shrivastava", "Riyaz Ahmad Bhat"], "venue": "In Proceedings of the Shared Task on Code Mix Entity Extraction in Indian Languages (CMEE-", "citeRegEx": "Bhat et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bhat et al\\.", "year": 2016}, {"title": "HindEnCorp Hindi-English and Hindi-only Corpus for Machine Translation", "author": ["Bojar et al.2014] Ond\u0159ej Bojar", "Vojt\u011bch Diatka", "Pavel Rychl\u00fd", "Pavel Stra\u0148\u00e1k", "V\u0131\u0301t Suchomel", "Ale\u0161 Tamchyna", "Daniel Zeman"], "venue": null, "citeRegEx": "Bojar et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bojar et al\\.", "year": 2014}, {"title": "Challenges of computational processing of code-switching", "author": ["Sarah Schulz", "Ngoc Thang Vu"], "venue": "In Proceedings of the Second Workshop on Computational Approaches to Code Switching,", "citeRegEx": "\u00c7etino\u011flu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "\u00c7etino\u011flu et al\\.", "year": 2016}, {"title": "A fast and accurate dependency parser using neural networks", "author": ["Chen", "Manning2014] Danqi Chen", "Christopher D Manning"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms", "author": ["Michael Collins"], "venue": "In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Collins.,? \\Q2002\\E", "shortCiteRegEx": "Collins.", "year": 2002}, {"title": "Natural language processing (almost) from scratch", "author": ["Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Universal stanford dependencies: A cross-linguistic typology", "author": ["Timothy Dozat", "Natalia Silveira", "Katri Haverinen", "Filip Ginter", "Joakim Nivre", "Christopher D Manning"], "venue": null, "citeRegEx": "Marneffe et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2014}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["Duchi et al.2011] John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Irstlm: an open source toolkit for handling large scale language models", "author": ["Nicola Bertoldi", "Mauro Cettolo"], "venue": "In Interspeech,", "citeRegEx": "Federico et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Federico et al\\.", "year": 2008}, {"title": "Cross-lingual dependency parsing based on distributed representations", "author": ["Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computa-", "citeRegEx": "Guo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2015}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580", "author": ["Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Part-of-speech tagging for code-mixed english-hindi twitter and facebook chat", "author": ["Bj\u00f6rn Gamb\u00e4ck", "Amitava Das"], "venue": null, "citeRegEx": "Jamatia et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jamatia et al\\.", "year": 2015}, {"title": "The TDIL program and the Indian language corpora initiative (ILCI)", "author": ["Girish Nath Jha"], "venue": "In Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC", "citeRegEx": "Jha.,? \\Q2010\\E", "shortCiteRegEx": "Jha.", "year": 2010}, {"title": "Towards sub-word level compositions for sentiment analysis of hindi-english code mixed text", "author": ["Joshi et al.2016] Aditya Joshi", "Ameya Prabhu", "Manish Shrivastava", "Vasudeva Varma"], "venue": "In Proceedings of COLING 2016,", "citeRegEx": "Joshi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2016}, {"title": "Brahmi-net: A transliteration and script conversion system for languages of the indian subcontinent", "author": ["Ratish Puduppully", "Pushpak Bhattacharyya"], "venue": null, "citeRegEx": "Kunchukuttan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kunchukuttan et al\\.", "year": 2015}, {"title": "Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Universal dependencies 1.4", "author": ["Larraitz Uria", "Gertjan van Noord", "Viktor Varga", "Veronika Vincze", "Lars Wallin", "Jing Xian Wang", "Jonathan North Washington", "Mats Wir\u00e9n", "Zden\u011bk \u017dabokrtsk\u00fd", "Amir Zeldes", "Daniel Zeman", "Hanzhi Zhu"], "venue": null, "citeRegEx": "Uria et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Uria et al\\.", "year": 2016}, {"title": "An efficient algorithm for projective dependency parsing", "author": ["Joakim Nivre"], "venue": "In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT)", "citeRegEx": "Nivre.,? \\Q2003\\E", "shortCiteRegEx": "Nivre.", "year": 2003}, {"title": "Algorithms for deterministic incremental dependency parsing", "author": ["Joakim Nivre"], "venue": "Computational Linguistics,", "citeRegEx": "Nivre.,? \\Q2008\\E", "shortCiteRegEx": "Nivre.", "year": 2008}, {"title": "Understanding language preference for expression of opinion and sentiment: What do hindi-english speakers do on twitter", "author": ["Niloy Ganguly"], "venue": null, "citeRegEx": "Ganguly.,? \\Q2016\\E", "shortCiteRegEx": "Ganguly.", "year": 2016}, {"title": "Shallow parsing pipeline - hindi-english code-mixed social media text", "author": ["Sharma et al.2016] Arnav Sharma", "Sakshi Gupta", "Raveesh Motlani", "Piyush Bansal", "Manish Shrivastava", "Radhika Mamidi", "Dipti M. Sharma"], "venue": null, "citeRegEx": "Sharma et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sharma et al\\.", "year": 2016}, {"title": "Learning to predict code-switching points", "author": ["Solorio", "Liu2008a] Thamar Solorio", "Yang Liu"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Solorio et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Solorio et al\\.", "year": 2008}, {"title": "Part-of-speech tagging for english-spanish code-switched text", "author": ["Solorio", "Liu2008b] Thamar Solorio", "Yang Liu"], "venue": null, "citeRegEx": "Solorio et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Solorio et al\\.", "year": 2008}, {"title": "Udpipe: Trainable pipeline for processing conll-u files performing tokenization, morphological analysis, pos tagging and parsing", "author": ["Straka et al.2016] Milan Straka", "Jan Hajic", "Jana Strakov\u00e1"], "venue": null, "citeRegEx": "Straka et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Straka et al\\.", "year": 2016}, {"title": "Pos tagging of english-hindi code-mixed social media content", "author": ["Vyas et al.2014] Yogarshi Vyas", "Spandana Gella", "Jatin Sharma", "Kalika Bali", "Monojit Choudhury"], "venue": "In Proceedings of the 2014 Con-", "citeRegEx": "Vyas et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Vyas et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 24, "context": "It has been generally observed that traditional NLP techniques perform miserably when processing code-mixed language data (Solorio and Liu, 2008b; Vyas et al., 2014; \u00c7etino\u011flu et al., 2016).", "startOffset": 122, "endOffset": 189}, {"referenceID": 2, "context": "It has been generally observed that traditional NLP techniques perform miserably when processing code-mixed language data (Solorio and Liu, 2008b; Vyas et al., 2014; \u00c7etino\u011flu et al., 2016).", "startOffset": 122, "endOffset": 189}, {"referenceID": 11, "context": ", 2014), while language tags are assigned based on the tagset defined in (Solorio et al., 2014; Jamatia et al., 2015).", "startOffset": 73, "endOffset": 117}, {"referenceID": 0, "context": "For this task, we use the feedforward neural network architecture of Bhat et al. (2016) proposed for Named Entity extraction in code mixed-data of Indian languages.", "startOffset": 69, "endOffset": 88}, {"referenceID": 4, "context": "For this purpose, we use the structured perceptron of Collins (Collins, 2002) which optimizes a given loss function over the entire observation sequence.", "startOffset": 62, "endOffset": 77}, {"referenceID": 14, "context": "(Kunchukuttan et al., 2015) and augmented them", "startOffset": 0, "endOffset": 27}, {"referenceID": 8, "context": "The language model is trained on monolingual data using IRSTLM-Toolkit (Federico et al., 2008) with Kneser-Ney smoothing.", "startOffset": 71, "endOffset": 94}, {"referenceID": 18, "context": "Parsing Models Our parsing model is based on transition-based dependency parsing paradigm (Nivre, 2008).", "startOffset": 90, "endOffset": 103}, {"referenceID": 17, "context": "Particularly, we use an arc-eager transition system (Nivre, 2003).", "startOffset": 52, "endOffset": 65}, {"referenceID": 7, "context": "We also use mini-batch Adagrad for optimization (Duchi et al., 2011) and apply dropout (Hinton et al.", "startOffset": 48, "endOffset": 68}, {"referenceID": 10, "context": ", 2011) and apply dropout (Hinton et al., 2012).", "startOffset": 26, "endOffset": 47}, {"referenceID": 5, "context": "Unlike (Collobert et al., 2011), we do not learn separate transition parameters.", "startOffset": 7, "endOffset": 31}, {"referenceID": 15, "context": "The word representations are learned using Skip-gram model with negative sampling which is implemented in word2vec toolkit (Mikolov et al., 2013).", "startOffset": 123, "endOffset": 145}, {"referenceID": 9, "context": "For multilingual models, we use robust projection algorithm of Guo et al. (2015) to induce bilingual representations", "startOffset": 63, "endOffset": 81}, {"referenceID": 12, "context": "We extracted the bilingual lexicon from ILCI and Bojar Hi-En parallel corpora (Jha, 2010; Bojar et al., 2014).", "startOffset": 78, "endOffset": 109}, {"referenceID": 1, "context": "We extracted the bilingual lexicon from ILCI and Bojar Hi-En parallel corpora (Jha, 2010; Bojar et al., 2014).", "startOffset": 78, "endOffset": 109}, {"referenceID": 23, "context": "All of our parsing models produce results that are at-least 10 LAS points better than our baseline parsers which otherwise provide competitive results on Hindi and English evaluation sets (Straka et al., 2016).", "startOffset": 188, "endOffset": 209}, {"referenceID": 23, "context": "Our results are not directly comparable to (Straka et al., 2016) due to different parsing architectures.", "startOffset": 43, "endOffset": 64}, {"referenceID": 23, "context": "Our results are not directly comparable to (Straka et al., 2016) due to different parsing architectures. While we use a simple greedy, projective transition system, Straka et al. (2016) use a search-based swap system.", "startOffset": 44, "endOffset": 186}], "year": 2017, "abstractText": "In this paper, we propose efficient and less resource-intensive strategies for parsing of code-mixed data. These strategies are not constrained by in-domain annotations, rather they leverage pre-existing monolingual annotated resources for training. We show that these methods can produce significantly better results as compared to an informed baseline. Besides, we also present a data set of 450 Hindi and English code-mixed tweets of Hindi multilingual speakers for evaluation. The data set is manually annotated with Universal", "creator": "LaTeX with hyperref package"}}}