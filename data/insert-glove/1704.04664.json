{"id": "1704.04664", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Apr-2017", "title": "Online Spatial Concept and Lexical Acquisition with Simultaneous Localization and Mapping", "abstract": "intensional In karega this paper, we propose reticles an online learning phytosanitary algorithm 230-million based andava on a Rao - Blackwellized www.mcdonalds.com particle lis filter 85.27 for armour spatial lambek concept lederman acquisition acad\u00e9mica and mapping. dribbles We antia have proposed mireille a dreifuss nonparametric dowels Bayesian ayeyawady spatial swank concept acquisition regenstein model (jamila SpCoA ). We bagyidaw propose medicines a bellinger novel method (SpCoSLAM) galanta integrating meidl SpCoA and dogmas FastSLAM in the theoretical mkhatshwa framework khlestov of munchausen the centeon Bayesian wallisch generative 5-a-side model. disqualifications The jaslyn proposed 97-82 method verhaeghe can kilduff simultaneously biotransformation learn place sportpaleis categories and zeljeznicar lexicons while milliner incrementally generating an environmental 19.98 map. leal Furthermore, 1933-45 the proposed method seelie has streamcast scene euro585 image bandhana features and bavo a guell language psn model added to fourcroy SpCoA. In the 2,000-member experiments, idyllwild we tested online renou learning philbert of dodgeville spatial concepts and 16-strong environmental maps in a horby novel environment of which the shyti robot did not have a map. Then, mixins we helper evaluated monhegan the results of sumas online dakota learning mademoiselle of spatial concepts lagos and lexical krafts acquisition. The ridge experimental ofgem results equiano demonstrated that encumber the 2-time robot was able hainstock to more accurately learn indiaman the untaes relationships acclamations between igcc words giannini and the stowaway place in the environmental map incrementally grueter by using gunship the sopor proposed method.", "histories": [["v1", "Sat, 15 Apr 2017 17:18:11 GMT  (700kb,D)", "http://arxiv.org/abs/1704.04664v1", "Preprint submitted to 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems. Received March 1, 2017"]], "COMMENTS": "Preprint submitted to 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems. Received March 1, 2017", "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.RO", "authors": ["akira taniguchi", "yoshinobu hagiwara", "tadahiro taniguchi", "tetsunari inamura"], "accepted": false, "id": "1704.04664"}, "pdf": {"name": "1704.04664.pdf", "metadata": {"source": "CRF", "title": "Online Spatial Concept and Lexical Acquisition with Simultaneous Localization and Mapping", "authors": ["Akira Taniguchi", "Yoshinobu Hagiwara", "Tadahiro Taniguchi", "Tetsunari Inamura"], "emails": ["@em.ci.ritsumei.ac.jp", "inamura@nii.ac.jp"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nRobots coexisting with humans and operating in various environments are required to adaptively learn and use the spatial concepts and vocabulary related to different places. However, spatial concepts are such that their target domain may be unclear compared with object concepts and may differ according to the user and environment. Therefore, it is difficult to manually design spatial concepts in advance, and it is desirable for robots to autonomously learn spatial concepts based on their own experiences.\nThe related research fields of semantic mapping and place categorization [1], [2] have attracted considerable interest in recent years. However, most of these studies have consisted of separate independent methods of semantics of places and mapping using simultaneous localization and mapping (SLAM) [3]. In addition, the semantics of places, place categories, and names of places could only be learned from pre-set values. In this paper, we propose a novel unsupervised Bayesian generative model and an online learning algorithm that can perform simultaneous learning of the spatial concepts and an environmental map from multimodal information. The proposed method can automatically and sequentially perform place categorization and learn unknown words without prior knowledge.\n*This work was partially supported by JST, CREST. 1Akira Taniguchi, Yoshinobu Hagiwara and Tadahiro Taniguchi are with Ritsumeikan University, 1-1-1 Noji-Higashi, Kusatsu, Shiga 525-8577, Japan {a.taniguchi, yhagiwara, taniguchi} @em.ci.ritsumei.ac.jp\n2Tetsunari Inamura is with National Institute of Informatics / SOKENDAI (The Graduate University for Advanced Studies), 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan inamura@nii.ac.jp\nIn this paper, we aim to develop a method that enables mobile robots to learn spatial concepts and an environmental map sequentially from interaction with an environment and human, even in an unknown environment without prior knowledge. Taniguchi et al. [4] proposed a method that integrated ambiguous speech-recognition results with the self-localization method for learning spatial concepts. In addition, Taniguchi et al. [5] proposed the nonparametric Bayesian spatial concept acquisition method (SpCoA) based on an unsupervised word-segmentation method known as latticelm [6]. On the other hand, Ishibushi et al. [7] proposed a self-localization method that exploits image features using a convolutional neural network (CNN) [8]. These methods [4], [5], [7] cannot cope with changes in the names of places and the environment because these methods use batch learning algorithms. In addition, these methods cannot learn spatial concepts from unknown environments without a map, i.e., the robot needs to have a map generated by SLAM beforehand. Therefore, in this paper, we develop an online algorithm that can sequentially learn a map, spatial concepts integrating positions, speech signals, and scene images.\nFastSLAM [9], [10] has realized an on-line algorithm for efficient self-localization and mapping using a RaoBlackwellized particle filter (RBPF) [11]. In this paper, we introduce a grid-based FastSLAM algorithm in the generative model for spatial concept acquisition. The graphical model of SpCoA has integrated spatial lexical acquisition into Monte Carlo localization (MCL), a particle-filter-based self-localization method. SpCoA can be extended naturally to SLAM. Therefore, we assume that the robot can learn vocabulary related to places and a map sequentially.\nar X\niv :1\n70 4.\n04 66\n4v 1\n[ cs\n.A I]\n1 5\nA pr\n2 01\n7\nOne of the important problems of our research is unsupervised lexical acquisition. There are research efforts on incremental spatial language acquisition through robot-torobot interaction [12], [13]. However, these studies [12], [13] did not consider lexical acquisition through human-torobot speech interactions (HRSI). For online unsupervised lexical acquisition by HRSI, it is necessary to deal with the problems of phoneme recognition errors and word segmentation of uttered sentences containing errors. SpCoA reduced phoneme recognition errors of word segmentation by using the weighted finite-state transducer (WFST)-based unsupervised word segmentation method latticelm [6]. Araki et al. [14] performed a pseudo-online algorithm using the nested Pitman\u2013Yor language model (NPYLM) [15]. However, these studies [5], [14] have reported that word segmentation of speech recognition results including errors causes over-segmentation [16]. In this paper, we will improve the accuracy of speech recognition by updating the language models sequentially.\nWe assume that the robot has not acquired any vocabulary in advance, and can recognize only phonemes or syllables. We represent the spatial area of the environment in terms of a position distribution. Furthermore, we define a spatial concept as a place category that includes place names, scene image features, and the position distributions corresponding to those names.\nThe goal of this study is to develop a robot that learns spatial concepts incrementally from multimodal information obtained while moving in the environment. The main contributions of this paper are as follows. \u2022 We propose an online algorithm based on RBPF for spa-\ntial concept acquisition. The proposed method integrates SpCoA and FastSLAM in the theoretical framework of the Bayesian generative model. \u2022 We demonstrated that a robot without a pre-existing lexicon or map can learn spatial concepts and an environmental map incrementally."}, {"heading": "II. ONLINE SPATIAL CONCEPT ACQUISITION", "text": ""}, {"heading": "A. Overview", "text": "An overview of the proposed method is shown in Fig. 1. We integrate SpCoA and FastSLAM in the theoretical framework of the Bayesian generative model. The proposed method is online spatial concept acquisition and simultaneous localization and mapping (SpCoSLAM). The proposed method can learn sequential spatial concepts for unknown environments and unsearched regions without maps. It can mutually complement the uncertainty of information by expressing the mapping, place categorization, and lexical acquisition with one Bayesian generative model. A pseudocode for the online learning is given in Algorithm 1. The procedure of SpCoSLAM for each step is described as follows. 2) \u2013 6) are performed for each particle.\n1) A robot gets WFST speech recognition results of the user\u2019s speech signals using a language model of the previous step."}, {"heading": "B. Generative model and graphical model", "text": "Figure 2 shows the graphical model for the acquisition of spatial concepts and Table I lists each variable of the graphical model. We describe the generative model as follows:\n\u03c0 \u223c DP(\u03b1) (1) Ct \u223c Mult(\u03c0) (2) \u03c6l \u223c DP(\u03b3) (3) Wl \u223c Dir(\u03b2) (4) LM \u223c p(LM | \u03bb) (5) St \u223c p(St |W, Ct, LM) (6) yt \u223c p(yt | St, AM) (7) \u03b8l \u223c Dir(\u03c7) (8) ft \u223c Mult(\u03b8Ct) (9)\n\u03a3k \u223c IW(\u03a3 | V0, \u03bd0) (10) \u00b5k \u223c N(\u00b5 | m0, (\u03a3k/\u03ba0)) (11) xt \u223c p(xt | xt\u22121, ut) (12) zt \u223c p(zt | xt,m) (13) it \u223c p(it | xt,\u00b5,\u03a3,\u03c6, Ct) (14)\nwhere DP() represents Dirichlet process, Mult() is multinomial distribution, Dir() is Dirichlet distribution, IW() is inverseWishart distribution, and N() is Gaussian distribution.\nEquation (6) approximates by using unigram rescaling [17], as shown in (15). UR \u2248 represents the approximation by unigram rescaling.\np(St |W, Ct, LM) UR \u2248 p(St | LM) \u220f Bt Mult(St,b |WCt)\u2211 c\u2032 Mult(St,b |Wc\u2032) (15)\nwhere Bt denotes the number of words in the sentence. Then, the probability distribution for (14) can be defined as follows:\np(it | xt,\u00b5,\u03a3,\u03c6, Ct)\n= N (xt | \u00b5it ,\u03a3it)Mult(it | \u03c6Ct)\u2211 it=j N (xt | \u00b5j ,\u03a3j)Mult(j | \u03c6Ct) . (16)"}, {"heading": "C. Formulation of the speech recognition and the unsupervised word segmentation", "text": "The 1-best speech recognition and the WFST speech recognition are represented as follows:\nS (1-best) t = argmax\nSt\nSR(St | yt, AM,LM) (17)\nLt \u2248 SR(Lt | yt, AM,LM) (18)\nwhere Lt denotes the speech recognition result of WFST format, which is a word graph representing the speech recognition results. The unsupervised word segmentation of WFST by latticelm [6] is represented as follows:\nSTo \u223c latticelm(STo | LTo , \u03bb). (19)\nAlgorithm 1 Online learning algorithm of SpCoSLAM 1: procedure SpCoSLAM(Xt\u22121, ut, zt, f1:t, y1:t) 2: X\u0304t = Xt = \u2205 3: L1:t = SR(L1:t | y1:t, AM,LMt\u22121) 4: for r = 1 to R do 5: x\u0301[r]t = sample motion model(ut, x [r] t\u22121)\n6: x[r]t = scan matching(zt, x\u0301 [r] t ,m [r] t\u22121) 7: for j = 1 to J do 8: xj = sample motion model(ut, x [r] t\u22121)\n9: end for 10: \u03c9[r]z = \u2211J j=1 measurement model(zt, xj ,m [r] t\u22121) 11: S[r]1:t \u223c latticelm(S1:t | L1:t, \u03bb) 12: i[r]t , C [r] t \u223c p(it, Ct | x [r] 0:t, i [r] 1:t\u22121, C [r] 1:t\u22121, S [r] 1:t, f1:t,h) 13: \u03c9[r]f = p(ft | C [r] 1:t\u22121, f1:t\u22121, \u03b1, \u03c7) 14: \u03c9[r]s = p(S [r] t |S [r] 1:t\u22121, C [r] 1:t\u22121, \u03b1, \u03b2)/p(S [r] t | S [r] 1:t\u22121, \u03b2) 15: \u03c9[r]t = \u03c9 [r] z \u00b7 \u03c9[r]f \u00b7 \u03c9 [r] s 16: m[r]t = updated occupancy grid(zt, x [r] t ,m [r] t\u22121) 17: \u0398[r]t = E[p(\u0398 | x [r] 0:t,C [r] 1:t, f1:t,h)] 18: X\u0304t = X\u0304t \u222a \u3008x[r]0:t,C [r] 1:t,m [r] t ,\u0398 [r] t , \u03c9 [r] t \u3009 19: end for 20: S\u22171:t = argmaxS[r]1:t \u2211R r=1 \u03c9 [r] t \u03b4(S1:t \u2212 S [r] 1:t) 21: LMt = argmaxLM p(LM | S\u22171:t, \u03bb) 22: for r = 1 to R do 23: draw i with probability \u221d \u03c9[i]t 24: add \u3008x[i]0:t,C [i] 1:t,m [i] t ,\u0398 [i] t , LMt\u3009 to Xt 25: end for 26: return Xt 27: end procedure"}, {"heading": "D. Online spatial concept acquisition and mapping", "text": "Here, we describe the derivation of formulas for the online algorithm. The online learning algorithm of the proposed method can be derived by introducing sequential update equations for estimating the parameters of the spatial concepts into the formulation of FastSLAM based on RBPF. The proposed method assumes grid-based FastSLAM 2.0 [9], [10] algorithm. Algorithm 1 is the online learning algorithm of SpCoSLAM. As an advantage of using a particle filter, parallel processing can be easily applied because each particle can be calculated independently.\nIn the formulation of FastSLAM, the joint posterior distribution be factorized as follows:\np(x0:t,m | u1:t, z1:t) = p(m | x0:t, z1:t)\ufe38 \ufe37\ufe37 \ufe38\nMapping\np(x0:t | u1:t, z1:t)\ufe38 \ufe37\ufe37 \ufe38 Particle filter . (20)\nThis factorization represents a decomposition into two calculations: the mapping and self-localization by RBPF.\nIn the formulation of SpCoSLAM, the joint posterior distribution can be factorized to the probability distributions of a language model LM , a map m, the set of model parameters of spatial concepts \u0398 = {W,\u00b5,\u03a3, \u03b8, \u03c6, \u03c0}, and the joint distribution of trajectory of self-position x0:t and the set of latent variables C1:t = {i1:t, C1:t, S1:t}. We describe\nthe joint posterior distribution of SpCoSLAM as follows:\np(x0:t,C1:t, LM,\u0398,m | u1:t, z1:t, y1:t, f1:t, AM,h) = p(LM | S1:t, \u03bb)p(m | x0:t, z1:t) \u00b7 p(\u0398 | x0:t,C1:t, f1:t,h) \u00b7 p(x0:t,C1:t | u1:t, z1:t, y1:t, f1:t, AM,h)\ufe38 \ufe37\ufe37 \ufe38\nParticle filter\n(21)\nwhere the set of hyperparameters is denoted as h = {\u03b1, \u03b2, \u03b3, \u03c7, \u03bb,m0, \u03ba0, V0, \u03bd0}. Note that the speech signal yt is not observed at all times. In this paper, the proposed method is equivalent to FastSLAM at the time when yt is not observed.\nThe particle filter algorithm uses sampling importance resampling (SIR). We describe the importance weight \u03c9[r]t for each particle as follows:\n\u03c9 [r] t =\np(x [r] 0:t,C [r] 1:t | u1:t, z1:t, y1:t, f1:t, AM,h) q(x [r] 0:t,C [r] 1:t | u1:t, z1:t, y1:t, f1:t, AM,h)\n= P\n[r] t Q [r] t , (22)\nwhere the particle index is r. The number of particles is R. Henceforth, equations are also calculated for each particle r, but the subscripts representing the particle index are omitted.\nWe describe the target distribution Pt as follows:\np(x0:t,C1:t | u1:t, z1:t, y1:t, f1:t, AM,h) UR \u2248 p(zt | xt,mt\u22121)p(ft | C1:t\u22121, f1:t\u22121,h) \u00b7 p(it, Ct | x0:t, i1:t\u22121, C1:t\u22121, S1:t, f1:t,h) \u00b7 p(xt | xt\u22121, ut)p(St | S1:t\u22121, y1:t, AM, \u03bb)\n\u00b7 p(St | S1:t\u22121, C1:t\u22121, \u03b1, \u03b2) p(St | S1:t\u22121, \u03b2) \u00b7 Pt\u22121. (23)\nWe describe the proposal distribution Qt as follows:\nq(x0:t,C1:t | u1:t, z1:t, y1:t, f1:t, AM,h) = q(xt,Ct | x0:t\u22121,C1:t\u22121, u1:t, z1:t, y1:t, f1:t, AM,h)\ufe38 \ufe37\ufe37 \ufe38\nqt\n\u00b7 q(x0:t\u22121,C1:t\u22121|u1:t\u22121, z1:t\u22121, y1:t\u22121, f1:t\u22121, AM,h)\ufe38 \ufe37\ufe37 \ufe38 Qt\u22121 = qtQt\u22121. (24)\nThe weight \u03c9t is represented by (22), (23), and (24) as follows:\n\u03c9t \u2248 p(zt | xt,mt\u22121)p(ft | C1:t\u22121, f1:t\u22121,h) \u00b7 p(it, Ct | x0:t, i1:t\u22121, C1:t\u22121, S1:t, f1:t,h) \u00b7 p(xt | xt\u22121, ut)p(St | S1:t\u22121, y1:t, AM, \u03bb)\n\u00b7 p(St | S1:t\u22121, C1:t\u22121, \u03b1, \u03b2) p(St | S1:t\u22121, \u03b2)qt \u00b7 Pt\u22121 Qt\u22121\ufe38 \ufe37\ufe37 \ufe38 \u03c9t\u22121 . (25)\nWe assume the proposal distribution qt at time t as follows:\nqt = p(xt | xt\u22121, zt,mt\u22121, ut) \u00b7 p(it, Ct | x0:t, i1:t\u22121, C1:t\u22121, S1:t, f1:t,h) \u00b7 p(St | S1:t\u22121, y1:t, AM, \u03bb). (26)\nThen, p(xt | xt\u22121, zt,mt\u22121, ut) is equivalent to the proposal distribution of FastSLAM 2.0.\nThe term of it and Ct is the marginal distribution regarding the set of model parameters \u0398. This distribution can be calculated by a formula equivalent to collapsed Gibbs sampling. We describe the equation for sampling it and Ct simultaneously as follows:\np(it, Ct | x0:t, i1:t\u22121, C1:t\u22121, S1:t, f1:t,h) \u221d p(S1:t | C1:t, \u03b2)p(f1:t | C1:t, \u03c7)p(x0:t | i1:t,h) \u00b7 p(it, Ct | i1:t\u22121, C1:t\u22121, \u03b1, \u03b3). (27)\nThe details of (27) are described in Section II-E. We approximate the term of St by speech recognition using the language model LMt\u22121 and unsupervised word segmentation using the WFST speech recognition results L1:t as follows:\np(St | S1:t\u22121, y1:t, AM, \u03bb) \u2248 latticelm(S1:t | L1:t, \u03bb)SR(L1:t | y1:t, AM,LMt\u22121).\n(28)\nIn the formulation of (21), it is desirable to estimate the language model LMt for each particle. However, in this case, it is necessary to perform speech recognition of the number of data times the number of particles for each teaching utterance. In order to reduce the computational cost, we use a language model LMt of a particle with the maximum weight for speech recognition of the next step.\nFinally, \u03c9t is represented as follows:\n\u03c9t \u2248 p(zt | mt\u22121, xt\u22121, ut)p(ft | C1:t\u22121, f1:t\u22121,h)\n\u00b7 p(St | S1:t\u22121, C1:t\u22121, \u03b1, \u03b2) p(St | S1:t\u22121, \u03b2) \u00b7 \u03c9t\u22121. (29)\nThis is an equation obtained by multiplying the weight \u03c9t\u22121 at a previous time with the marginal likelihoods for zt, ft, and St."}, {"heading": "E. Simultaneous sampling of indices it and Ct", "text": "The proposed method uses the Chinese restaurant process (CPR) [18], which is one of the constitution methods of the Dirichlet process (DP). We describe the distribution of Ct using the CRP representation as follows:\np(Ct = l | C1:t\u22121, \u03b1) =\n{ n (l) t\nnt+\u03b1 (n\n(l) t > 0)\n\u03b1 nt+\u03b1\n(l is new) (30)\nwhere n(l)t denotes the number of data allocated to the l-th spatial concept in all data up to the time t\u2212 1. The number of data is nt = \u2211 l\u2032 n (l\u2032) t .\nWe describe the distribution of it by the CRP representation as follows:\np(it = k | i1:t\u22121, C1:t\u22121, Ct = l, \u03b3)\n=  n (l,k) t n (l) t +\u03b3 (n (l,k) t > 0) \u03b3\nn (l) t +\u03b3\n(k is new) (31)\nwhere n(l,k)t denotes the number of data allocated to the kth position distribution in data allocated to the l-th spatial concept.\nTherefore, the joint prior distribution of it and Ct is represented as follows:\np(it = k,Ct = l | i1:t\u22121, C1:t\u22121, \u03b1, \u03b3)\n=  n (l,k) t n (l) t +\u03b3 n (l) t nt+\u03b1 (n (l,k) t > 0) \u03b3 n (l) t +\u03b3 n (l) t nt+\u03b1 (n (l) t > 0 \u2229 k is new) \u03b3\nn (l) t +\u03b3\n\u03b1 nt+\u03b1 (l and k are new)\n(32)\nThe probability of words St is represented as follows:\np(S1:t | C1:t\u22121, Ct = l, \u03b2) = \u220f Bt p(St,b = sg, S1:t\u22121 | C1:t\u22121, Ct = l, \u03b2)\n\u221d  \u220f Bt n (l,g) t +\u03b2\u2211G g\u2032=1(n (l,g\u2032) t +\u03b2) (n (l) t > 0)\n1 GBt\n(l is new) (33)\nwhere G denotes the number of types of words, i.e., the number of dimensions of the multinomial distribution of the names of places and n(l,g)t denotes the total number of words sg of the g-th dimension allocated to the l-th multinomial distribution of the names of the places in words S1:t\u22121.\nThe probability of image features ft is represented as follows:\np(f1:t | C1:t\u22121, Ct = l, \u03c7) = \u220f E p(ft,e, f1:t\u22121 | C1:t\u22121, Ct = l, \u03c7)\n\u221d  \u220f E ( n (l,e) t +\u03c7\u2211E e\u2032=1(n (l,e\u2032) t +\u03c7) )ft,e (n (l) t > 0)\n1 EFt\n(l is new) (34)\nwhere E denotes the number of dimensions of image features, n(l,e)t denotes the total number of image features of the e-th dimension allocated to the l-th multinomial distribution of image features in image features f1:t\u22121, and Ft = \u2211 E ft,e.\nThe probability of self-position xt of the robot is described as follows:\np(xt, x0:t\u22121 | i1:t\u22121, it = k,h)\n\u221d St(xt | mk, Vq(\u03bak + 1)\n\u03bak(\u03bdk \u2212 d+ 1) , \u03bdk \u2212 d+ 1)\n(35)\nwhere the function St() denotes the multivariate Student\u2019s t-distribution [19]. Then, the posterior parameters in (35) are\nrepresented as follows:\nx\u0304k = 1\nn (k) t \u2211 xj\u2208xk xj (36)\nmk = n\n(k) t x\u0304k + \u03ba0m0\nn (k) t + \u03ba0\n(37)\n\u03bak = n (k) t + \u03ba0 (38) \u03bdk = \u03bd0 + n (k) t (39)\nVq = V0 + \u2211 xj\u2208xk xjx T j + \u03ba0m0m T 0 \u2212 \u03bakmkmTk\n(40)\nwhere n(k)t and xk are the number of data and the set of position data, respectively, allocated to the position distribution of it = k in data up to the time t\u2212 1.\nFrom the above, (27) can be expressed as follows:\np(it = k,Ct = l | x0:t, i1:t\u22121, C1:t\u22121, S1:t, f1:t,h)\n\u221d  \u220f Bt n (l,g) t +\u03b2\u2211G g\u2032=1(n (l,g\u2032) t +\u03b2) \u220f E ( n (l,e) t +\u03c7\u2211E e\u2032=1(n (l,e\u2032) t +\u03c7) )ft,e \u00b7St(xt | mk, V \u22121q (\u03bak+1) \u03bak(\u03bdk\u2212d+1) , \u03bdk \u2212 d+ 1) \u00b7 n (l,k) t n (l) t +\u03b3 n (l) t nt+\u03b1 (n (l,k) t > 0)\u220f Bt n (l,g) t +\u03b2\u2211G g\u2032=1(n (l,g\u2032) t +\u03b2) \u220f E ( n (l,e) t +\u03c7\u2211E e\u2032=1(n (l,e\u2032) t +\u03c7) )ft,e \u00b7St(xt | m0, V \u22121 0 (\u03ba0+1) \u03ba0(\u03bd0\u2212d+1) , \u03bd0 \u2212 d+ 1) \u00b7 \u03b3 n (l) t +\u03b3 n (l) t nt+\u03b1 (n (l) t > 0 \u2229 k is new) 1 GBt 1 EFt \u00b7St(xt | m0, V \u22121 0 (\u03ba0+1) \u03ba0(\u03bd0\u2212d+1) , \u03bd0 \u2212 d+ 1) \u00b7 \u03b3 n (l) t +\u03b3 \u03b1 nt+\u03b1\n(l and k are new)\n(41)"}, {"heading": "III. EXPERIMENTS", "text": "We performed experiments for online learning of spatial concepts from a novel environment. In addition, we performed evaluations of place categorization and lexical acquisition related to place. We compare the performance of four methods as follows: (A) SpCoSLAM (B) Online SpCoA based on RBPF (C) Online SpCoA (D) SpCoA (Batch learning) [5]\nMethods (A), (B), and (C) performed online learning algorithms based on the CRP representation. Methods (B) and (C) did not perform the update of a language model. Method (D) performed Gibbs sampling based on a weak-limit approximation [20] of the stick-breaking process (SBP) [21], i.e., the upper limit numbers of spatial concepts and position distributions were set as L = 100 and K = 100 respectively. In the batch learning (D), we performed Gibbs sampling for 100 iterations."}, {"heading": "A. Online learning", "text": "We conducted experiments for online spatial concept acquisition in a real environment. We extended the gmapping package, implementing the grid-based FastSLAM 2.0 [9], [10] in the robot operating system (ROS). We used an open dataset (albert-b-laser-vision) containing a rosbag file in which the odometry, laser range data, and vision data were recorded. This dataset was obtained from the Robotics Data Set Repository (Radish) [22]. The authors thank Cyrill Stachniss for providing this data. We prepared a Japanese speech signal data corresponding to the movement of the robot of the above dataset because it did not include speech signal data. The number of teaching places was 10 and there were nine place names. The teaching utterances included 10 types of various phrases. The total number of utterances was 50. The employed microphone was a SHURE PG27USB. The speech recognition system uses Julius dictationkit-v4.3.1-linux (GMM-HMM decoding) [23]. The initial word dictionary of the Julius system contains 115 Japanese syllables. The unsupervised word segmentation system uses latticelm [6]. We used a deep learning framework Caffe [24] for CNNs as an image feature extractor. We used a pretrained CNN, i.e., Places205-AlexNet trained on 205 scene categories of Places Database with 2.5\u00d7106 images [25]. The map resolution was 0.05 m/grid. The number of particles was R = 30. The hyperparameters were set as follows: \u03b1 = 20, \u03b3 = 10, \u03b2 = 0.2, \u03c7 = 0.2, m0 = [0, 0]T, \u03ba0 = 0.001, V0 = diag(2, 2), and \u03bd0 = 3. The above parameters were set so that all methods in the comparison were tested under the same conditions.\nFig. 3 shows the position distributions in the environmental maps at steps 15, 30, and 50. The upper part of this figure shows an example of the image corresponding to each position distribution, the correct phoneme sequence of the name of the place, and the upper three words of the probability value estimated by the probability distribution p(St | it,\u0398t, LMt) at step t. As a result, Fig. 3 shows how the spatial concepts are acquired while sequentially mapping."}, {"heading": "B. Estimation accuracy of spatial concepts", "text": "We compare the matching rate for the estimated index Ct of the spatial concept of each teaching utterance and the classification results of correct answers by a person. In this experiment, the evaluation metric uses the normalized mutual information (NMI), which is a measure of the degree of similarity between two clustering results. The estimated index it of the position distributions is also evaluated in the same manner. In addition, we evaluate the estimated number of spatial concepts L and position distributions K by using the estimation accuracy rate (EAR). The EAR was calculated as follows:\nEAR = min(1\u2212 | nT \u2212 nE | nT , 0) (42)\nwhere nT is the correct number and nE is the estimated number.\nTable II lists the evaluation-value averages calculated using the metrics NMI and EAR at step 50. Fig. 4 shows the average of the NMI values in 10 trials by online learning. In both Ct and it, the NMI values tended to rise at the beginning. The NMI values of Ct were similar for methods (A), (B), and (C). In the NMI values for it, the proposed method (A) showed higher values than the other methods after step 30. We consider a major possible reason for the clustering results of spatial concepts. In online lexical acquisition, the word segmentation results cannot be obtained stably when training dataset is small. We consider that stable words can be obtained by further increasing the number of training steps. Fig. 5 shows the average of the number of spatial concepts and the number of position distributions in 10 trials by online learning. The average values of the estimated results of method (D) were L = 18.9, K = 13.1. True data was determined by a user based on teaching data. The experimental results show that the proposed method (A) was closer to the true data than other methods for both L and K."}, {"heading": "C. Comparison of the number of segmented words", "text": "We show whether a phoneme sequence including the name of a place is properly segmented. Fig. 6 shows the number of segmented words. The morphological segmentation (purple line) was suitably segmented into Japanese morphemes using MeCab, which is an off-the-shelf Japanese morphological analyzer that is widely used for natural language processing. The phrase segmentation (yellow line) was the number of words in the case of segmenting words only before and after the name of the place, i.e., we assume that a phrase other than the name of the place is one word. Table III presents examples of the word segmentation results of the four methods. Method (A) was similar to the phrase segmentation. On the other hand, methods (B) and (C) showed results of oversegmentation. In addition, the average value of the number of segmented words of method (D) was 391.4, i.e., it was similar to methods (B) and (C) at step 50. The results indicate that method (A) improved the problem of over-segmentation by updating the language model sequentially."}, {"heading": "D. Place recognition using a speech signal", "text": "When the robot hears a user\u2019s speech signal yt including the name of a place, the robot estimates a position x(best)t\nindicated by the uttered sentence. The user says \u201c** ni iqte.\u201d (which means \u201cGo to **.\u201d in English). The estimation of a position was calculated as follows:\nx (best) t = argmax\nxt\np(xt | yt,\u0398, AM,LM). (43)\nIn this experiment, (43) was approximated by using the speech recognition results S(1:10-best)t from 1-best to 10-best as follows:\nS (1:10-best) t \u223c SR(St | yt, AM,LM), (44) x\n(best) t = argmax\nxt\np(xt | S(1:10-best)t ,\u0398). (45)\nIt is difficult to calculate (45) for all of the possible positions. Therefore, we use the 10 position coordinates sampled for each position distribution as candidates for x(best)t . As a justification for this, we consider that positions near the mean values of position distributions become possible candidates for calculating (45). In this experiment, we decided to correct the position within the rectangular area surrounding the position coordinates taught as the same place (including 0.5 m margins to the right, left, above, and below). The place recognition rate (PRR) is calculated as follows:\nPRR = nC nU , (46)\nwhere nU denotes the number of utterances and nC denotes the number of correct positions. The number of utterances is nine.\nFig. 7 shows the average of the PRR values in 10 trials. The average value of PRR of Method (D) was 0.500. Method (A) showed the highest overall evaluation values of the online methods. The experimental results show that the robot was able to more accurately learn the relationships between words and the position in the map incrementally by using method (A)."}, {"heading": "IV. CONCLUSION", "text": "This paper discussed online learning methods of spatial concepts and an environmental map by a mobile robot. The proposed method integrated the spatial concept acquisition into SLAM by an RBPF-based approach. In the experiments, we conducted online learning in a novel environment by the robot without a pre-existing lexicon and map. The experimental results demonstrated that SpCoSLAM enhances the performance of place recognition using a speech signal\nin online learning methods. SpCoSLAM improved oversegmentation problem in lexical acquisition by updating the language model sequentially. We consider that incorporating forgetting [14] and rejuvenation [26] into SpCoSLAM could further improve estimation accuracy.\nOne of the advantages of online learning is that it can deal with changes in the environment and place names. Moreover, we consider that the spatial concepts the robot mistakenly learns can also be corrected sequentially. In this way, it is possible to acquire spatial concepts that flexibly respond to changes in the environment, which could not be done so far. We expect this work to contribute greatly to the realization of long-term spatial language interaction between people and robots. In the future, we would like to perform continuous online learning of spatial concepts in a long-term experiment and incremental transfer learning of spatial concepts to other novel environments."}], "references": [{"title": "Semantic mapping for mobile robotics tasks: A survey", "author": ["I. Kostavelis", "A. Gasteratos"], "venue": "Robotics and Autonomous Systems, vol. 66, pp. 86\u2013103, 2015.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "A review of spatial reasoning and interaction for real-world robotics", "author": ["C. Landsiedel", "V. Rieser", "M. Walter", "D. Wollherr"], "venue": "Advanced Robotics, vol. 31, no. 5, pp. 222\u2013242, 2017.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2017}, {"title": "Simultaneous estimation of self-position and word from noisy utterances and sensory information", "author": ["A. Taniguchi", "T. Taniguchi", "T. Inamura"], "venue": "13th IFAC/IFIP/IFORS/IEA Symposium on Analysis, Design, and Evaluation of Human-Machine Systems, 2016.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Spatial concept acquisition for a mobile robot that integrates self-localization and unsupervised word discovery from spoken sentences", "author": ["\u2014\u2014"], "venue": "IEEE Transactions on Cognitive and Developmental Systems, vol. 8, no. 4, pp. 285\u2013297, 2016.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2016}, {"title": "Bayesian learning of a language model from continuous speech", "author": ["G. Neubig", "M. Mimura", "T. Kawahara"], "venue": "IEICE TRANSACTIONS on Information and Systems, vol. 95, no. 2, pp. 614\u2013625, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Statistical localization exploiting convolutional neural network for an  autonomous vehicle", "author": ["S. Ishibushi", "A. Taniguchi", "T. Takano", "Y. Hagiwara", "T. Taniguchi"], "venue": "Industrial Electronics Society, IECON 2015- 41st Annual Conference of the IEEE. IEEE, 2015, pp. 1369\u20131375.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "Advances in neural information processing systems, 2012, pp. 1097\u20131105.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Improving grid-based slam with rao-blackwellized particle filters by adaptive proposals and selective resampling", "author": ["G. Grisetti", "C. Stachniss", "W. Burgard"], "venue": "IEEE International Conference on Robotics and Automation (ICRA), 2005.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "Improved techniques for grid mapping with rao-blackwellized particle filters", "author": ["\u2014\u2014"], "venue": "IEEE Transactions on Robotics, vol. 23, pp. 34\u201346, 2007.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Raoblackwellised particle filtering for dynamic bayesian networks", "author": ["A. Doucet", "N. De Freitas", "K. Murphy", "S. Russell"], "venue": "Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence. Morgan Kaufmann Publishers Inc., 2000, pp. 176\u2013183.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2000}, {"title": "Incremental grounded language learning in robot-robot interactions-examples from spatial language", "author": ["M. Spranger"], "venue": "Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob). IEEE, 2015, pp. 196\u2013201.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Lingodroids: Cross-situational learning for episodic elements", "author": ["S. Heath", "D. Ball", "J. Wiles"], "venue": "IEEE Transactions on Cognitive and Developmental Systems, vol. 8, no. 1, pp. 3\u201314, March 2016.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Online learning of concepts and words using multimodal LDA and hierarchical Pitman-Yor Language Model", "author": ["T. Araki", "T. Nakamura", "T. Nagai", "S. Nagasaka", "T. Taniguchi", "N. Iwahashi"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2012, pp. 1623\u20131630.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Bayesian unsupervised word segmentation with nested Pitman-Yor language modeling", "author": ["D. Mochihashi", "T. Yamada", "N. Ueda"], "venue": "Proceedings of ACL-IJCNLP, 2009, pp. 100\u2013108.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "A Bayesian framework for word segmentation: Exploring the effects of context", "author": ["S. Goldwater", "T.L. Griffiths", "M. Johnson"], "venue": "Cognition, vol. 112, no. 1, pp. 21\u201354, 2009.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Topic-based language models using em", "author": ["D. Gildea", "T. Hofmann"], "venue": "In Proceedings of the 6th European Conference on Speech Communication and Technology (EUROSPEECH), 1999.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1999}, {"title": "Exchangeability and related topics", "author": ["D. Aldous"], "venue": "\u00c9cole d\u2019\u00c9t\u00e9 de Probabilit\u00e9s de Saint-Flour XIII-1983, pp. 1\u2013198, 1985.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1983}, {"title": "Machine learning: a probabilistic perspective", "author": ["K.P. Murphy"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "A sticky HDP-HMM with application to speaker diarization", "author": ["E.B. Fox", "E.B. Sudderth", "M.I. Jordan", "A.S. Willsky"], "venue": "The Annals of Applied Statistics, pp. 1020\u20131056, 2011.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "A constructive definition of Dirichlet priors", "author": ["J. Sethuraman"], "venue": "Statistica Sinica, vol. 4, pp. 639\u2013650, 1994.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1994}, {"title": "The robotics data set repository (radish)", "author": ["A. Howard", "N. Roy"], "venue": "2003. [Online]. Available: http://radish.sourceforge.net/", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2003}, {"title": "Sharable software repository for Japanese large vocabulary continuous speech recognition", "author": ["T. Kawahara", "T. Kobayashi", "K. Takeda", "N. Minematsu", "K. Itou", "M. Yamamoto", "A. Yamada", "T. Utsuro", "K. Shikano"], "venue": "Fifth International Conference on Spoken Language Processing, 1998.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1998}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "arXiv preprint arXiv:1408.5093, 2014.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning deep features for scene recognition using places database", "author": ["B. Zhou", "A. Lapedriza", "J. Xiao", "A. Torralba", "A. Oliva"], "venue": "Advances in Neural Information Processing Systems 27 (NIPS), 2014, pp. 487\u2013 495.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Online inference of topics with latent dirichlet allocation.", "author": ["K.R. Canini", "L. Shi", "T.L. Griffiths"], "venue": "in AISTATS, vol", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "The related research fields of semantic mapping and place categorization [1], [2] have attracted considerable interest in recent years.", "startOffset": 73, "endOffset": 76}, {"referenceID": 1, "context": "The related research fields of semantic mapping and place categorization [1], [2] have attracted considerable interest in recent years.", "startOffset": 78, "endOffset": 81}, {"referenceID": 2, "context": "[4] proposed a method that integrated ambiguous speech-recognition results with the self-localization method for learning spatial concepts.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[5] proposed the nonparametric Bayesian spatial concept acquisition method (SpCoA) based on an unsupervised word-segmentation method known as latticelm [6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] proposed the nonparametric Bayesian spatial concept acquisition method (SpCoA) based on an unsupervised word-segmentation method known as latticelm [6].", "startOffset": 152, "endOffset": 155}, {"referenceID": 5, "context": "[7] proposed a self-localization method that exploits image features using a convolutional neural network (CNN) [8].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] proposed a self-localization method that exploits image features using a convolutional neural network (CNN) [8].", "startOffset": 112, "endOffset": 115}, {"referenceID": 2, "context": "These methods [4], [5], [7] cannot cope with changes in the names of places and the environment because these methods use batch learning algorithms.", "startOffset": 14, "endOffset": 17}, {"referenceID": 3, "context": "These methods [4], [5], [7] cannot cope with changes in the names of places and the environment because these methods use batch learning algorithms.", "startOffset": 19, "endOffset": 22}, {"referenceID": 5, "context": "These methods [4], [5], [7] cannot cope with changes in the names of places and the environment because these methods use batch learning algorithms.", "startOffset": 24, "endOffset": 27}, {"referenceID": 7, "context": "FastSLAM [9], [10] has realized an on-line algorithm for efficient self-localization and mapping using a RaoBlackwellized particle filter (RBPF) [11].", "startOffset": 9, "endOffset": 12}, {"referenceID": 8, "context": "FastSLAM [9], [10] has realized an on-line algorithm for efficient self-localization and mapping using a RaoBlackwellized particle filter (RBPF) [11].", "startOffset": 14, "endOffset": 18}, {"referenceID": 9, "context": "FastSLAM [9], [10] has realized an on-line algorithm for efficient self-localization and mapping using a RaoBlackwellized particle filter (RBPF) [11].", "startOffset": 145, "endOffset": 149}, {"referenceID": 10, "context": "There are research efforts on incremental spatial language acquisition through robot-torobot interaction [12], [13].", "startOffset": 105, "endOffset": 109}, {"referenceID": 11, "context": "There are research efforts on incremental spatial language acquisition through robot-torobot interaction [12], [13].", "startOffset": 111, "endOffset": 115}, {"referenceID": 10, "context": "However, these studies [12], [13] did not consider lexical acquisition through human-torobot speech interactions (HRSI).", "startOffset": 23, "endOffset": 27}, {"referenceID": 11, "context": "However, these studies [12], [13] did not consider lexical acquisition through human-torobot speech interactions (HRSI).", "startOffset": 29, "endOffset": 33}, {"referenceID": 4, "context": "SpCoA reduced phoneme recognition errors of word segmentation by using the weighted finite-state transducer (WFST)-based unsupervised word segmentation method latticelm [6].", "startOffset": 169, "endOffset": 172}, {"referenceID": 12, "context": "[14] performed a pseudo-online algorithm using the nested Pitman\u2013Yor language model (NPYLM) [15].", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] performed a pseudo-online algorithm using the nested Pitman\u2013Yor language model (NPYLM) [15].", "startOffset": 92, "endOffset": 96}, {"referenceID": 3, "context": "However, these studies [5], [14] have reported that word segmentation of speech recognition results including errors causes over-segmentation [16].", "startOffset": 23, "endOffset": 26}, {"referenceID": 12, "context": "However, these studies [5], [14] have reported that word segmentation of speech recognition results including errors causes over-segmentation [16].", "startOffset": 28, "endOffset": 32}, {"referenceID": 14, "context": "However, these studies [5], [14] have reported that word segmentation of speech recognition results including errors causes over-segmentation [16].", "startOffset": 142, "endOffset": 146}, {"referenceID": 4, "context": "3) The robot performs unsupervised word segmentation latticelm [6] using WFST speech recognition results.", "startOffset": 63, "endOffset": 66}, {"referenceID": 15, "context": "Equation (6) approximates by using unigram rescaling [17], as shown in (15).", "startOffset": 53, "endOffset": 57}, {"referenceID": 4, "context": "The unsupervised word segmentation of WFST by latticelm [6] is represented as follows:", "startOffset": 56, "endOffset": 59}, {"referenceID": 7, "context": "0 [9], [10] algorithm.", "startOffset": 2, "endOffset": 5}, {"referenceID": 8, "context": "0 [9], [10] algorithm.", "startOffset": 7, "endOffset": 11}, {"referenceID": 16, "context": "Simultaneous sampling of indices it and Ct The proposed method uses the Chinese restaurant process (CPR) [18], which is one of the constitution methods of the Dirichlet process (DP).", "startOffset": 105, "endOffset": 109}, {"referenceID": 17, "context": "where the function St() denotes the multivariate Student\u2019s t-distribution [19].", "startOffset": 74, "endOffset": 78}, {"referenceID": 3, "context": "We compare the performance of four methods as follows: (A) SpCoSLAM (B) Online SpCoA based on RBPF (C) Online SpCoA (D) SpCoA (Batch learning) [5] Methods (A), (B), and (C) performed online learning algorithms based on the CRP representation.", "startOffset": 143, "endOffset": 146}, {"referenceID": 18, "context": "Method (D) performed Gibbs sampling based on a weak-limit approximation [20] of the stick-breaking process (SBP) [21], i.", "startOffset": 72, "endOffset": 76}, {"referenceID": 19, "context": "Method (D) performed Gibbs sampling based on a weak-limit approximation [20] of the stick-breaking process (SBP) [21], i.", "startOffset": 113, "endOffset": 117}, {"referenceID": 7, "context": "0 [9], [10] in the robot operating system (ROS).", "startOffset": 2, "endOffset": 5}, {"referenceID": 8, "context": "0 [9], [10] in the robot operating system (ROS).", "startOffset": 7, "endOffset": 11}, {"referenceID": 20, "context": "This dataset was obtained from the Robotics Data Set Repository (Radish) [22].", "startOffset": 73, "endOffset": 77}, {"referenceID": 21, "context": "1-linux (GMM-HMM decoding) [23].", "startOffset": 27, "endOffset": 31}, {"referenceID": 4, "context": "The unsupervised word segmentation system uses latticelm [6].", "startOffset": 57, "endOffset": 60}, {"referenceID": 22, "context": "We used a deep learning framework Caffe [24] for CNNs as an image feature extractor.", "startOffset": 40, "endOffset": 44}, {"referenceID": 23, "context": "5\u00d710 images [25].", "startOffset": 12, "endOffset": 16}, {"referenceID": 3, "context": "770 (D) SpCoA [5] 0.", "startOffset": 14, "endOffset": 17}, {"referenceID": 12, "context": "We consider that incorporating forgetting [14] and rejuvenation [26] into SpCoSLAM could further improve estimation accuracy.", "startOffset": 42, "endOffset": 46}, {"referenceID": 24, "context": "We consider that incorporating forgetting [14] and rejuvenation [26] into SpCoSLAM could further improve estimation accuracy.", "startOffset": 64, "endOffset": 68}], "year": 2017, "abstractText": "In this paper, we propose an online learning algorithm based on a Rao-Blackwellized particle filter for spatial concept acquisition and mapping. We have proposed a nonparametric Bayesian spatial concept acquisition model (SpCoA). We propose a novel method (SpCoSLAM) integrating SpCoA and FastSLAM in the theoretical framework of the Bayesian generative model. The proposed method can simultaneously learn place categories and lexicons while incrementally generating an environmental map. Furthermore, the proposed method has scene image features and a language model added to SpCoA. In the experiments, we tested online learning of spatial concepts and environmental maps in a novel environment of which the robot did not have a map. Then, we evaluated the results of online learning of spatial concepts and lexical acquisition. The experimental results demonstrated that the robot was able to more accurately learn the relationships between words and the place in the environmental map incrementally by using the proposed method.", "creator": "LaTeX with hyperref package"}}}