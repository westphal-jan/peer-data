{"id": "1704.07816", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Apr-2017", "title": "Introspective Classifier Learning: Empower Generatively", "abstract": "just In nield this paper kalyanam we propose silbury introspective auctor classifier stoia learning (ICL) uotila that emphasizes uprise the importance of having priene a breadfruit discriminative classifier trease empowered labovitz with 163.2 generative capabilities. diadochi We develop exponentials a reclassification - loring by - offload synthesis algorithm to perform baumohl training nominally using uncorking a tragheim formulation stemmed highfalutin from the unskilled Bayes camm theory. spea Our crickhowell classifier wacko is mitino able caskey to internationalists iteratively: (foramen 1) chippa synthesize pseudo - \u00f6sterreichischen negative samples in the clarity synthesis step; lide and (\u015bwi\u0119tej 2) over-the-counter enhance itself by improving goal-scoring the second-round classification 165.4 in aegon the gamble reclassification diatribes step. choristers The niceville single jeeves classifier dilday learned 6.95 is deseronto at stavro the erythrocytes same time dlowe generative - - - senario being able to fricourt directly spetsnaz synthesize new crisscrossing samples within its 8-bits own lubricity discriminative huiyong model. temanggung We conduct e85 experiments on standard benchmark datasets including lanzhou MNIST, CIFAR, and yasawa SVHN pointer using state - non-involvement of - aflq the - art CNN architectures, cerci and observe improved m\u01b0\u1eddi classification rayfield results.", "histories": [["v1", "Tue, 25 Apr 2017 17:49:03 GMT  (1105kb,D)", "http://arxiv.org/abs/1704.07816v1", "11 pages, 6 figure"]], "COMMENTS": "11 pages, 6 figure", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["long jin", "justin lazarow", "zhuowen tu"], "accepted": false, "id": "1704.07816"}, "pdf": {"name": "1704.07816.pdf", "metadata": {"source": "META", "title": "Introspective Classifier Learning: Empower Generatively", "authors": ["Long Jin", "Justin Lazarow", "Zhuowen Tu"], "emails": ["ztu}@ucsd.edu"], "sections": [{"heading": "1. Introduction", "text": "In machine learning, great success has been achieved in obtaining powerful discriminative classifiers via supervised training. Other learning principles that are not fully supervised include unsupervised (Duda et al., 2000), semi-supervised (Zhu, 2005), weakly-supervised (Dietterich et al., 1997), and reinforcement (Sutton & Barto, 1998) which also point to promising directions when annotated data is limited.\nExisting classifiers, such as decision trees (Quinlan, 1996), support vector machines (Vapnik, 1995), neural networks (LeCun et al., 1989), boosting (Freund & Schapire, 1997), and random forests (Breiman, 2001), carry out training processes to either implicitly or explicitly minimize an objective function that balances the training error and regularization. Recent studies reveal that even modern classifiers like deep convolutional neural networks (Krizhevsky et al., 2012) still make mistakes that look absurd to humans (Goodfellow et al., 2014b). A common way to im-\nprove the performance is by using more data, in particular \u201chard examples\u201d, to train the classifier. Different types of approaches have been proposed in the past including bootstrapping (Mooney et al., 1993), active learning (Settles, 2010), semi-supervised learning (Zhu, 2005), and data augmentation (Krizhevsky et al., 2012). However, the approaches above utilize data samples that are either already present in the given training set, or additionally created by humans or separate algorithms.\nThe key to granting the synthesis capability to a discriminative classifier is to make it internally generative. In the past, attempts have been made to build connections between generative models and discriminative classifiers (Friedman et al., 2001; Liang & Jordan, 2008; Jebara, 2012). Many existing approaches however combine discriminative classifiers with generative models to form hybrid models (Tu et al., 2008). In (Welling et al., 2002) a self supervised boosting algorithm was proposed to train a boosting algorithm by sequentially adding features as weak classifiers on additional self-generated negative samples; the generative discriminative modeling work in (Tu, 2007) generalizes the concept that a generative model can be successfully modeled by learning a sequence of discriminative classifiers via self-generated pseudo-negatives.\nInspired by the work that learns density functions (Welling et al., 2002) and generative models (Tu, 2007) using sequentially self-generated pseudo-negative samples, as well as recent success in deep learning (LeCun et al., 1989; Hinton et al., 2006; Krizhevsky et al., 2012; Gatys et al., 2015), we propose here an algorithm that capitalizes on the endto-end learning of deep convolutional nets while making it internally generative. We specifically study how the generative aspect of our model can benefit its own discriminative training. We name our framework introspective classifier learning (ICL). There is a recent line of work to use a discriminative classifier to help with an external generator (Goodfellow et al., 2014a), which is different from our objective here. We aim at building a single model that is simultaneously discriminative and generative: being both a discriminator and a generator at the same time. ar X\niv :1\n70 4.\n07 81\n6v 1\n[ cs\n.C V\n] 2\n5 A\npr 2\n01 7"}, {"heading": "2. Significance and related work", "text": "The introspective classifier learning (ICL) framework being introduced here makes a number of contributions. (1) We introduce an end-to-end learning algorithm that is agnostic and both discriminative and generative under a single model (not a hybird one). (2) An efficient sampling procedure is developed to synthesize new data from a discriminative classifier. (3) A reclassification-by-synthesis algorithm is devised to iteratively augment negative samples and update the classifier. (4) We propose a formulation to seamlessly train a multi-class classifier on the given training set and augmented samples. We show consistent improvement over a state-of-the-art CNN classifier (ResNet (He et al., 2016a)) on CIFAR and SVHN datasets in the experiments.\nTo compare with the self-supervised boosting work (Welling et al., 2002), ICL has its advantage in: a). having a greater power for both discriminative and generative modeling beyond density estimation, b). being a direct discriminative classifier showing competitive experimental results of practical importance; c). being convolutional for automatic feature learning, and d). having a more efficient learning process. Compared with the generative model learning via discriminative classifier work (GDL) (Tu, 2007), ICL is advantageous for its: a). simplicity of having a single classifier as opposed to consisting of a sequence of boosting classifiers; b) being an effective discriminative classifier demonstrating direct improvement over state-of-the-art methods; c). greater representation power due to convolutional networks; and d). more efficient sampling process. Other methods (Gutmann & Hyva\u0308rinen, 2010; Tolstikhin et al., 2017) in which generative models are learned using discriminative classifiers share some common disadvantages as in (Welling et al., 2002; Tu, 2007).\nPrevious algorithms connecting generative modeling with discriminative classification (Friedman et al., 2001; Liang & Jordan, 2008; Tu et al., 2008; Jebara, 2012) fall in the category of hybrid models that are combinations of the two and mostly limited to specific tasks. Other directions in machine learning such as bootstrapping (Mooney et al., 1993), active learning (Settles, 2010; Beygelzimer et al., 2009), semi-supervised learning (Zhu, 2005), and data augmentation (Krizhevsky et al., 2012), try to effectively utilize the existing data whereas ICL is able to self-generate new data. Some existing work on introspective learning (Leake, 2012) has a different scope to the problem being tackled here.\nRecent efforts in adversarial learning are also very interesting and worth mentioning. The work of (Goodfellow et al., 2014b) was motivated from an observation that adding small perturbations to an image leads to classification er-\nrors that are absurd to humans; their approach is however taken by augmenting positive samples from existing input whereas ICL is able to synthesize new samples from scratch. The generative adversarial nets algorithm (GAN) (Goodfellow et al., 2014a) engages two separate models, a generator and a discriminator, with the objective of making use of the discriminator to help the generator generate faithful samples; the discriminator in GAN is not meant to perform the generic two-class/multi-class classification task; thus, some special settings for semi-supervised learning (Goodfellow et al., 2014a; Radford et al., 2015; Zhao et al., 2016; Brock et al., 2016; Salimans et al., 2016) were created since the discriminators in GAN were trained to classify between \u201creal\u201d and \u201cfake\u201d samples. ICL instead has a single model that is both generative and discriminative, and thus, an improvement to ICL\u2019s generator leads to a direct means to ameliorate its discriminator; ICL also has a direct root in the Bayes theory from the derivation. Later development alongside GAN (Radford et al., 2015; Salimans et al., 2016; Zhao et al., 2016; Brock et al., 2016) share some similar aspects to GAN, which also do not achieve the same goal as ICL does. For example, an additional \u201cnot-real\u201d class was generated in addition to the standard k classes in multi-class classification for a semisupervised learning setting in (Salimans et al., 2016). ICL instead, maintains the same parameter setting in soft-max function identical to a standard multi-class CNN classifier.\nOther generative modeling schemes such as the MiniMax entropy theory (Zhu et al., 1997), inducing features (Della Pietra et al., 1997), auto-encoder (Baldi, 2012), Wake-sleep (Hinton et al., 1995), and recent CNN based generative modeling approaches (Xie et al., 2016b;a) are not for discriminative training and do not have a single model that is both generative and discriminative."}, {"heading": "2.1. Relationship with GDL (Tu, 2007)", "text": "The generative via discriminative learning framework (GDL) (Tu, 2007) learns a generative model through a sequence of discriminative classifiers (boosting (Freund & Schapire, 1997)) using repeatedly self-generated samples, called pseudo-negatives. Figure 1 shows the basic pipeline of GDL in (Tu, 2007). The far-left panel shows a set of\npoints (in red) as input data, and the task is to learn a generative model to characterize the distribution of these points, hence an unsupervised learning task; the GDL algorithm starts from a uniform distribution as a reference distribution to generate the first batch of pseudo-negatives (shown on the top-left panel) and a discriminative classifier is then trained to separate the given input data and the pseudo-negatives; new samples that pass the learned classifiers are considered as a new set of pseudo-negatives in the next round (shown on the top-middle panel) to train a new classifier; the algorithm repeats until the pseudo-negatives are no longer distinguishable from the input data (shown on the bottom-right panel); the learned generative model is then a concatenation of a series of discriminative classifiers learned through the process.\nOur work is inspired by (Tu, 2007) but we also observe a number of areas for improvement to (Tu, 2007): (1) features in (Tu, 2007) are pre-specified manually instead of being automatically learned; (2) the sampling process is time-consuming, carried out by Markov chain Monte Carlo (MCMC) with a lengthy process to converge; (3) a series of discriminative classifiers are learned sequentially and those learned in the early stages do not get a chance to be updated later; (4) GDL was mainly for generative modeling and improvement to discriminative classification was not demonstrated in (Tu, 2007). In this paper, we pay our attention to the classification task and we focus on improving existing discriminative classification.\nTo summarize, we present a deep convolutional neural networks method that is simultaneously generative and discriminative under a single framework. We focus on the classification side and develop an effective algorithm for training. Encouraging experimental results have been attained on standard machine learning benchmark datasets."}, {"heading": "3. Method", "text": "The pipeline of ICL is shown in Figure 2, which has an immediate improvement over GDL in several aspects that have been described in the previous section. One particular gain of ICL is its representation power and efficient sampling process through backpropagation as a variational sampling strategy."}, {"heading": "3.1. Formulation", "text": "We start the discussion by introducing the basic formulation and borrow the notations from (Tu, 2007). Let x be a data sample (vector) and y \u2208 {\u22121,+1} be its label, indicating either a negative or a positive sample. In multi-class classification y \u2208 {1, ...,K}. We study binary classification first. A discriminative classifier computes p(y|x), the probability of x being positive or negative. p(y = \u22121|x) + p(y = +1|x) = 1. A generative model instead models p(y,x) = p(x|y)p(y), which cap-\ntures the underlying generation process of x for class y. In binary classification, positive samples are of primary interest. Under the Bayes rule:\np(x|y = +1) = p(y = +1|x)p(y = \u22121) p(y = \u22121|x)p(y = +1) p(x|y = \u22121),\n(1) which can be further simplified when assuming equal priors p(y = +1) = p(y = \u22121):\np(x|y = +1) = p(y = +1|x) 1\u2212 p(y = +1|x) p(x|y = \u22121). (2)\nWe make two interesting and important observations from eqn. (2): 1) p(x|y = +1) is dependent on the faithfulness of p(x|y = \u22121), and 2) a classifier C to report p(y = +1|x) can be made simultaneously generative and discriminative. However, there is a requirement: having an informative distribution for the negatives p(x|y = \u22121) such that samples drawn x \u223c p(x|y = \u22121) have good coverage to the entire space of x \u2208 <m, especially for samples that are close to the positives x \u223c p(x|y = +1), to allow the classifier to faithfully learn p(y = +1|x). There seems to exist a dilemma. In supervised learning, we are only given a set of limited amount of training data and a classifier C is only focused on the decision boundary to separate the given samples and the classification on the unseen data may not be accurate. This can be seen from the top left plot in Figure 2. This motivates us to implement the synthesis part in learning: make a learned discriminative classifier generate samples that pass its own classification and see how different these generated samples are to the given positive samples. This allows us to attain a single model that has two aspects at the same time: a generative model for the positive samples and an improved classifier for the classification.\nSuppose we are given a training set S = {(xi, yi), i = 1..n} and x \u2208 <m and y \u2208 {\u22121,+1}. One can directly train a discriminative classifier C, e.g. a boosting algorithm (Freund & Schapire, 1997) or convolutional neural networks (LeCun et al., 1989) to learn p(y = +1|x), which is always an approximation due to various reasons including insufficient training samples, generalization error, and classifier limitations. Previous attempts to improve classification by data augmentation were mostly done to increase the positive samples (Krizhevsky et al., 2012; Goodfellow et al., 2014b); we instead argue the importance of increasing negative samples to improve the classification performance. The dilemma is that S = {(xi, yi), i = 1..n} is limited to the given data. For clarity, we now use p\u2212(x) to represent p(x|y = \u22121). Our goal is to gradually learn p\u2212t (x):\np\u2212t (x) t=\u221e\u2192 p(x|y = +1) (3)\nsuch that the samples drawn x \u223c p\u2212t (x) become indistinguishable from the given positive samples. We call the\nsamples drawn from x \u223c p\u2212t (x) pseudo-negatives (defined in (Tu, 2007)). We expand S = {(xi, yi), i = 1..n} by Ste = S \u222a Stpn, where S0pn = \u2205 and for t \u2265 1\nStpn = {(xi,\u22121), i = n+ 1, ..., n+ tl}.\nStpn includes all the pseudo-negative samples selfgenerated from our model up to time t. l indicates the number of pseudo-negatives generated at each round. We define a reference distribution p\u2212r (x) = U(x), where U(x) is a Gaussian distribution (e.g. N (0.0, 0.32) independently). We carry out learning with t = 0...T to iteratively obtain\nqt(y = +1|x), qt(y = \u22121|x) (4)\nby updating classifier Ct on Ste = S \u222a Stpn. The initial classifier C0 on S0e = S reports discriminative probability q0(y = +1|x). The reason for using q is because it is an approximation to the true p due to limited samples drawn in <m. At each time t, we then compute\np\u2212t (x) = 1\nZt qt(y = +1|x) qt(y = \u22121|x) p\u2212r (x), (5)\nwhere Zt = \u222b qt(y=+1|x) qt(y=\u22121|x)p \u2212 r (x)dx. Draw new samples\nxi \u223c p\u2212t (x)\nto expand the pseudo-negative set:\nSt+1pn = S t pn \u222a {(xi,\u22121), i = n+ tl + 1, ..., n+ (t+ 1)l}. (6) We name the specific training algorithm for our introspective classifier learning (ICL) framework reclassificationby-synthesis, which is described in Algorithm 1. We adopt convolutional neural networks (CNN) classifier to build an end-to-end learning framework with an efficient sampling process (to be discussed in the next section)."}, {"heading": "3.2. Reclassification-by-synthesis", "text": "We present our reclassification-by-synthesis algorithm for ICL in this section. A schematic illustration is shown in Figure 2. A single CNN classifier is being trained progressively, which is simultaneously a discriminator and a generator. With the pseudo-negatives being gradually generated, the classification boundary gets tightened, and hence improvement to the classifier performance. The reclassification-by-synthesis method is described in Algorithm 1. The key to the algorithm includes two steps: (1) reclassification-step, and (2) synthesis-step, which will be discussed in detail below."}, {"heading": "3.2.1. RECLASSIFICATION-STEP", "text": "The reclassification-step can be viewed as training a normal classifier on the training set Ste = S \u222a Stpn where S = {(xi, yi), i = 1..n} and S0pn = \u2205. Stpn = {(xi,\u22121), i = n + 1, ..., n + tl} for t \u2265 1. We use CNN as our base classifier. When training a classifier Ct on Ste, we denote the parameters to be learned in Ct by a high-dimensional\nvector Wt = (w (0) t ,w (1) t ) which might consist of millions of parameters. w(1)t denotes the weights on the top layer combining the features \u03c6(x;w(0)t ) and w (0) t carries all the internal representations. Without loss of generality, we assume a sigmoid function for the discriminative probability\nqt(y|x;Wt) = 1/(1 + exp{\u2212yw(1)Tt \u03c6(x;w (0) t )}),\nwhere \u03c6(x;w(0)t ) defines the feature function for x. Both w\n(1) t and w (0) t can be learned by the standard stochastic gradient descent algorithm via backpropagation to minimize a cross-entropy loss with an additional term on the pseudo-negatives:\nL(Wt) = \u2212 i=1..n\u2211\n(xi,yi)\u2208S\nln qt(yi|xi;Wt)\n\u2212 i=n+1..n+tl\u2211 (xi,\u22121)\u2208Stpn ln qt(\u22121|xi;Wt). (7)\nAlgorithm 1 Outline of the reclassification-by-synthesis algorithm for discriminative classifier training.\nInput: Given a set of training data S = {(xi, yi), i = 1..n} with x \u2208 <m and y \u2208 {\u22121,+1}. Initialization: obtain a distribution the negative samples: p\u2212r (x) = U(x) and train an initial CNN binary classifier C0 on S, q0(y = +1|x). S0pn = \u2205. U(x) is a zero mean Gaussian distribution. For t=0..T 1. Update the model: p\u2212t (x) = 1Zt qt(y=+1|x) qt(y=\u22121|x)p \u2212 r (x). 2. Synthesis-step: sample l pseudo-negative samples xi \u223c p\u2212t (x), i = n+ tl+1, ..., n+(t+1)l from the current model p\u2212t (x) using a variational sampling procedure (stochastic gradient on the input). 3. Augment the pseudo-negative set with St+1pn = Stpn \u222a {(xi,\u22121), i = n+ tl + 1, ..., n+ (t+ 1)l}. 4. Reclassification-step: Update CNN classifier to Ct+1 on St+1e = S \u222a St+1pn , resulting in qt+1(y = +1|x). 5. t \u2190 t + 1 and go back to step 1 until convergence (e.g. no improvement on the validation set). End"}, {"heading": "3.2.2. SYNTHESIS-STEP", "text": "In the reclassification step, we obtain qt(y|x;Wt) which is then used to update p\u2212t (x) according to eqn. (5):\np\u2212t (x) = 1\nZt qt(y = +1|x;Wt) qt(y = \u22121|x;Wt) p\u2212r (x). (8)\nIn the synthesis-step, our goal is to draw fair samples from p\u2212t (x). In (Tu, 2007), various Markov chain Monte Carlo techniques (Liu, 2008) including Gibbs sampling and Iterated Conditional Modes (ICM) have been adopted, which are often slow. Motivated by the DeepDream code (Mordvintsev et al., 2015) and Neural Artistic Style work (Gatys et al., 2015), we update a random sample x drawn from p\u2212r (x) by increasing qt(y=+1|x;Wt) qt(y=\u22121|x;Wt) using backpropagation. Note that the partition function (normalization) Zt is a constant that is not dependent on the sample x. Let\ngt(x) = qt(y = +1|x;Wt) qt(y = \u22121|x;Wt) = exp{w(1)Tt \u03c6(x;w (0) t )},\n(9) and take its ln, which is nicely turned into the logit of qt(y = +1|x;Wt)\nln gt(x) = w (1)T t \u00b7 \u03c6(x;w (0) t ). (10)\nStarting from x drawn from p\u2212r (x), we directly increase w\n(1)T t \u03c6(x;w (0) t ) using stochastic gradient ascent on x via backpropagation, which allows us to obtain fair samples subject to eqn. (8). Gaussian noise can be added to eqn. (10) along the line of stochastic gradient Langevin dynamics (Welling & Teh, 2011).\nSampling strategies When conducting experiments, we carried out several strategies using stochastic gradient descent algorithm (SGD) including: i) early stopping for the\nsampling process after x becomes positive (or a fixed small number); ii) sampling for a fixed, large number of steps. We found early-stopping to achieve a good balance between effectiveness and efficiency, which is aligned with contrastive divergence (Carreira-Perpinan & Hinton, 2005) where a short Markov chain is simulated.\nBuilding the connection between SGD and MCMC is an active area in machine learning (Welling & Teh, 2011; Chen et al., 2014; Mandt et al., 2017). In (Welling & Teh, 2011), combining SGD and additional Gaussian noise under annealed stepsize results in a simulation to Langevin dynamics MCMC. SGD is also related to the diffusion process in MCMC (Grenander & Miller, 1994). A recent work (Mandt et al., 2017) further shows the similarity between constant SGD and MCMC, along with analysis of SGD using momentum updates. Our progressively learned discriminative classifier can be viewed as carving out the feature space on \u03c6(x), which essentially becomes a equivalent class for the positives; the volume of the equivalent class that satisfies the condition is exponentially large, as analyzed in (Wu et al., 2000). The probability landscape of positives (equivalent class) makes our SGD sampling process not particularly biased towards a small limited modes. Results in Figure 3 illustrates that large variation of the sampled/synthesized examples."}, {"heading": "3.3. Multi-class classification", "text": "One-vs-all\nIn the above section, we discussed the binary classification case. When dealing with multi-class classification problems, such as MNIST and CIFAR-10, we will need to adapt our proposed reclassification-by-synthesis scheme to the multi-class case. This can be done directly using a one-vsall strategy by training a binary classifierCi using the i\u2212th class as the positive class and then combine the rest classes into the negative class, resulting in a total of K binary classifiers. The training procedure then becomes identical to the binary classification case. If we have K classes, then the algorithm will trainK individual binary classifiers with\n< (w (0)1 t ,w (1)1 t ), ..., (w (0)K t ,w (1)K t ) > .\nThe prediction function is simply\nf(x) = argmax k\nexp{w(1)kTt \u00b7 \u03c6(x;w (0)k t )}.\nThe advantage of using the one-vs-all strategy is that the algorithm can be made nearly identical to the binary case at the price of training K different neural networks.\nSoftmax function It is also desirable to build a single CNN classifier to perform multi-class classification directly. Here we propose a new formulation to train an end-to-end multiclass classifier\ndirectly. Since we are directly dealing with K classes, the pseudo-negative data set will be slightly different and we introduce negatives for each individual class by S0pn = \u2205 and:\nStpn = {(xi,\u2212k), k = 1, ...,K, i = n+ (t\u2212 1)\u00d7 k \u00d7 l + 1, ..., n+ t\u00d7 k \u00d7 l}\nSuppose we are given a training set S = {(xi, yi), i = 1..n} and x \u2208 <m and y \u2208 {1, ..K}. We want to train a single CNN classifier with\nWt =< w (0) t ,w (1)1 t , ...,w (1)K t >\nwhere w(0)t denotes the internal feature and parameters for the single CNN, and w(1)kt denotes the top-layer weights for the k \u2212 th class. We therefore minimize an integrated objective function L(Wt) = \u2212 n\u2211 i=1 ln exp{w(1)yiTt \u00b7 \u03c6(xi;w (0) t )}\u2211K k=1 exp{w (1)kT t \u00b7 \u03c6(xi;w (0) t )}\n+ n+t\u00d7K\u00d7l\u2211 i=n+1 ln(1 + exp{w(1)|yi|Tt \u00b7 \u03c6(xi;w0t )}) (11)\nThe first term in eqn. (11) encourages a softmax loss on the original training set S and the second term in eqn. (11) encourages a good prediction on the individual pseudonegative class generated for the k \u2212 th class. Note that we now only need to build a single CNN sharing w(0)t for all the K classes. We perform direct multi-class classification where the parameter setting is identical to a standard multi-class classification in CNN whereas an additional \u201cnot-real\u201d class is created in (Salimans et al., 2016)."}, {"heading": "3.4. Analysis", "text": "We show the convergence of p\u2212t (x)\nt=\u221e\u2192 p+(x), inspired by the proof from (Tu, 2007),\nTheorem 1 KL[p+(x)||p\u2212t+1(x)] \u2264 KL[p+(x)||p \u2212 t (x)] where KL denotes the Kullback-Leibler divergence, and p(x|y = +1) \u2261 p+(x), under the assumption that classifier at t+ 1 improves over that at t.\nProof:\np\u2212t (x) = 1\nZt qt(y = +1|x) qt(y = \u22121|x) p\u2212r (x),\nand\np\u2212t+1(x) = 1\nZt+1 qt+1(y = +1|x) qt+1(y = \u22121|x) p\u2212r (x).\np\u2212t+1(x) = 1\nHt+1\nexp{w(1)Tt+1 \u03c6(x;w (0) t+1)} exp{w(1)Tt \u03c6(x;w (0) t )} p\u2212t (x)\nwhere Ht+1 = \u222b exp{w(1)Tt+1 \u03c6(x;w(0)t+1)}\nexp{w(1)Tt \u03c6(x;w (0) t )}\np\u2212t (x)dx\nKL[p+(x)||p\u2212t (x)]\u2212KL[p+(x)||p\u2212t+1(x)]\n= \u222b p+(x) ln ( 1\nHt+1\nexp{w(1)Tt+1 \u03c6(x;w (0) t+1)} exp{w(1)Tt \u03c6(x;w (0) t )} p\u2212t (x)\n) dx\n\u2212 \u222b p+(x) ln[p\u2212t (x)]dx\n= \u222b p+(x) ln 1\nHt+1 dx\n+ \u222b p+(x) ln exp{w(1)Tt+1 \u03c6(x;w (0) t+1)}\nexp{w(1)Tt \u03c6(x;w (0) t )}\ndx\n= ln 1\nHt+1 +\n\u222b p+(x) ln exp{w(1)Tt+1 \u03c6(x;w (0) t+1)}\nexp{w(1)Tt \u03c6(x;w (0) t )}\ndx \u2265 0.\nSince Ht+1 = \u222b exp{w(1)Tt+1 \u03c6(x;w(0)t+1)}\nexp{w(1)Tt \u03c6(x;w (0) t )} p\u2212t (x)dx \u2264 1 and\u222b p+(x) ln exp{w(1)Tt+1 \u03c6(x;w (0) t+1)}\nexp{w(1)Tt \u03c6(x;w (0) t )} dx \u2265 0. We assume that classifier at t + 1 improves over that at t. This shows that p\u2212t+1(x) converges to p(x|y = +1) and the convergence rate depends on the classification error at each step.\nRemark Given a training set Strain = {(xi, yi), i = 1..n} and test set Stest = {(xi, yi), i = 1..b} where yi \u2208 {\u22121,+1} and prediction function f(x) \u2208 {\u22121,+1}. Typically one computes a training error train = 1 n \u2211n i=1 1(yi 6= f(xi)) and a test error test = 1 b \u2211b i=1 1(yi 6= f(xi)). The difference between train and test, test = train + generalization(f) is largely due to the difference of the data distributions in training and testing. We pay particular attention to the negative samples, which are in a space that is often much larger than the positive sample space. For the negative training samples, we have yi = \u22121 and xi \u223c Q\u2212(x), where Q\u2212(x) is a distribution on the given negative examples in the original training set. Our reclassification-by-synthesis algorithm (Algorithm 1) essentially constructs a mixture model p\u0303(x) \u2261 1T \u2211T\u22121 t=0 p \u2212 t (x) by sequentially generating pseudo-negative samples to augment our training set. Our new distribution for augmented negative sample set thus becomes\nQ\u2212new(x) \u2261 n\nn+ T l Q\u2212(x) +\nT l\nn+ T l p\u0303(x),\nwhere p\u0303(x) encodes pseudo-negative samples that are confusing and similar to (but are not) the true positives. Often th1 \u2264 Dist(p+(x), p\u0303(x)) \u2264 th2 where th1 and th2 are two thresholds bounding the distances. Our overall algorithm thus is capable of enhancing classification by selfgenerating confusing samples to improve the robustness."}, {"heading": "4. Experiments", "text": "We conduct experiments on three standard benchmark datasets, including MNIST, CIFAR-10 and SVHN. We use MNIST as a running example to illustrate our proposed framework using a shallow CNN and show competitive results using a state-of-the-art CNN classifier, ResNet (He et al., 2016a) on CIFAR-10 and SVHN.\nIn our experiments, for the reclassification step, we use the SGD optimizer with mini-batch size of 64 (MNIST) or 128 (CIFAR-10 and SVHN) and momentum equal to 0.9; for the synthesis step, we use the Adam optimizer (Kingma & Ba, 2014) with momentum term \u03b21 equal to 0.5. All results are obtained by averaging multiple rounds."}, {"heading": "4.1. MNIST", "text": "The MNIST (LeCun & Cortes, 1998) dataset consists of 28\u00d7 28 grey images from 10 different classes (0 to 9) with 60, 000 training and 10, 000 test samples. We use a simple network, containing 4 convolutional layers, each having a 5 \u00d7 5 filter size with 64, 128, 256 and 512 channels, respectively. These convolutional layers have stride 2, and no pooling layers are used. LeakyReLU activations (Maas et al., 2013) are used after each convolutional layer. The last convolutional layer is flattened and fed into a sigmoid output (in the one-vs-all case). This network architecture is similar to the discriminator in DCGAN (Radford et al.,\n2015), but batch normalization layers are not used.\nIn the synthesis step, we use the backpropagation sampling process as discussed in Section 3.2.2. We initialize the image with random noise, fix the parameters of the network, and run multiple steps of Adam with early stopping. We also implemented alternative sampling approaches but this early stopping has a good balance between effectiveness and efficiency (see discussions in Section 3.2.2). Each time we synthesize a fixed number (e.g. 200) of pseudo-negative samples. In the reclassification step, we run SGD (for 5 epochs) on the current training data Ste, including previously generated pseudo-negatives. Our initial learning rate is 0.01 and is decreased by a factor of 10 at t = 20.\nWe show some synthesized pseudo-negatives from the MNIST dataset in Figure 3. The samples in the top row are from the original training dataset. ICL gradually synthesizes pseudo-negatives, which are increasingly faithful to the original data. Since we treat these pseudo-negatives as negative samples in our reclassification step, we set a threshold on the total number of synthesis steps to use, as determined by cross-validation. For evaluation, we compare our ICL method with the baseline CNN models. In\nthe one-vs-all case, we train one network for each class individually, therefore we have 10 classifiers in total whereas in the softmax case, we only need to train a single network.\nComparison with GDL and GAN. GDL (Tu, 2007) focuses on unsupervised learning; GAN (Goodfellow et al., 2014a) and DCGAN (Radford et al., 2015) show results for unsupervised learning and semi-supervised classification. To apply GDL and GAN to the supervised classification setting, we design an experiment to perform a two-step implementation.\nFor GDL, we ran the GDL code (Tu, 2007) and obtained the pseudo-negative samples for each individual digit; the pseudo-negatives are then used as augmented negative samples to train individual one-vs-all CNN classifiers (using an identical CNN architecture to ICL for a fair comparison), which are combined to form a multi-class classifier in the end. To compare with DCGAN (Radford et al., 2015), we follow the same procedure: each generator trained by DCGAN (Radford et al., 2015) using tensorflow implementation (Kim, 2016) was used to generate positive samples, which are then augmented to the negative set to train the individual one-vs-all CNN classifiers (also using an identical CNN architecture to ICL), which are combined to create the overall multi-class classifier. GDL+CNN achieves a test error of 0.89% and DCGAN+CNN achieves a test error of 0.86% on the MNIST dataset, whereas ICL reports an error of 0.78% using the same CNN architecture. These results are averaged over multiple rounds. As the supervised learning task was not directly specified in DCGAN (Radford et al., 2015), some care is needed to design the optimal setting to utilize the generated samples from DCGAN in the two-step approach (we may not get the best setting in the experiments). GDL (Tu, 2007) can be made into a discriminative classifier by utilizing the given negative samples first but boosting (Freund & Schapire, 1997) with manually designed features was adopted which may not reproduce competitive results as CNN classifier does.\nNevertheless, the advantage of ICL being an integrated end-to-end supervised learning single-model framework can be observed.\nAblation study. We also experiment using random noise as the synthesized pseudo-negatives in an ablation study. Table 1 lists the test errors on the MNIST dataset over multiple trials. We observe our ICL method outperforms the CNN baseline and the ICL-noise method in both one-vsall and softmax cases. The error plots of our algorithm are shown in Figure 4.\nTo better understand the effectiveness of our ICL method, we set up an experiment to see how it performs when varying the number of training examples. We vary the number of training examples across sets of size 500, 2000, 10000\nand 60000. From Figure 5, we can observe that when we have fewer training examples, our ICL model is more effective since it has the internal synthesis capability to synthesize pseudo-negatives in order to aid the training process.\nRobustness to external adversarial examples. The synthesis strategy within ICL and its generative capability provides improvement that is intrinsically more robust to confusing and challenging examples. To validate this, we compare the baseline CNN with our ICL classifier on adversarial examples generated using the \u201cfast gradient sign\u201d method from (Goodfellow et al., 2014b) for validation purposes only. This \u201cfast gradient sign\u201d method (with = 0.25) can cause a maxout network to misclassify 89.4% of adversarial examples generated from the MNIST test set (Goodfellow et al., 2014b). In our experiment, we set = 0.125. Starting with 10, 000 MNIST test examples, we first determine those which are correctly classified by the baseline CNN in order to generate adversarial examples from them. We find that 6, 876 generated adversarial examples successfully fool the baseline CNN, however, only 4, 661 of these examples can fool our ICL classifier, which is a 32.2% reduction in error against adversarial examples. Note that the improvement is achieved without using any additional training data, nor knowing a prior about how these adversarial examples are generated by the specific \u201cfast gradient sign method\u201d (Goodfellow et al., 2014b). Figure 6 shows some examples. On the contrary, of the 5, 989 adversarial examples generated from the ICL classifier side that then fooled ICL using the same method, 5, 542 of them can still fool the baseline CNN classifier. This twoway experiment shows the significantly improved robustness of ICL over the baseline CNN."}, {"heading": "4.2. CIFAR-10", "text": "The CIFAR-10 (Krizhevsky, 2009) dataset consists of 32\u00d7 32 color images. A collection of 60, 000 images is split into 50, 000 training and 10, 000 testing images. We adopt ResNet (He et al., 2016b) as our baseline model, which has been widely used. For data augmentation, we follow the standard procedure in (Lee et al., 2015; 2016; He et al., 2016b) by augmenting the dataset by zero-padding 4 pixels on each side; we also perform cropping and random flipping. In both one-vs-all and softmax cases, ICL outperforms the baseline method.\nOur proposed ICL method is orthogonal to many existing approaches which use various improvements to the network structures in order to enhance the CNN performance."}, {"heading": "4.3. SVHN", "text": "The SVHN (Netzer et al., 2011) dataset consists of color images of house numbers collected by Google Street View. We use a training set that combines its training and extra data in our experiments and leave the test data as our\n1https://github.com/ppwwyyxx/tensorpack/ tree/master/examples/ResNet\ntest set. No data augmentation has been applied. Our ICL method shows improvement to the baseline ResNet."}, {"heading": "5. Conclusion", "text": "In this paper, we have proposed introspective classifier learning (ICL), which results in a CNN classifier empowered with generative capabilities. We developed a reclassification-by-synthesis training algorithm. A new loss function to seamlessly integrate ICL in a single multiclass CNN classifier is additionally developed. We tested the algorithm on standard benchmarks and report encouraging results."}, {"heading": "6. Acknowledgement", "text": "This work is supported by NSF IIS-1618477 and a Northrop Grumman Contextual Robotics grant. We thank Saining Xie, Shuai Tang, and Sanjoy Dasgupta for helpful discussions."}], "references": [{"title": "Autoencoders, unsupervised learning, and deep architectures", "author": ["Baldi", "Pierre"], "venue": "ICML unsupervised and transfer learning,", "citeRegEx": "Baldi and Pierre.,? \\Q2012\\E", "shortCiteRegEx": "Baldi and Pierre.", "year": 2012}, {"title": "Random Forests", "author": ["Breiman", "Leo"], "venue": "Machine Learning,", "citeRegEx": "Breiman and Leo.,? \\Q2001\\E", "shortCiteRegEx": "Breiman and Leo.", "year": 2001}, {"title": "Neural photo editing with introspective adversarial networks", "author": ["Brock", "Andrew", "Lim", "Theodore", "JM Ritchie", "Weston", "Nick"], "venue": "arXiv preprint arXiv:1609.07093,", "citeRegEx": "Brock et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Brock et al\\.", "year": 2016}, {"title": "Stochastic gradient hamiltonian monte carlo", "author": ["Chen", "Tianqi", "Fox", "Emily B", "Guestrin", "Carlos"], "venue": "In ICML,", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Inducing features of random fields", "author": ["Della Pietra", "Stephen", "Vincent", "Lafferty", "John"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "Pietra et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Pietra et al\\.", "year": 1997}, {"title": "Solving the multiple instance problem with axis-parallel rectangles", "author": ["T.G. Dietterich", "R.H. Lathrop", "P.T. Lozano"], "venue": "Artificial intelligence,", "citeRegEx": "Dietterich et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Dietterich et al\\.", "year": 1997}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "J. of Comp. and Sys. Sci.,", "citeRegEx": "Freund and Schapire,? \\Q1997\\E", "shortCiteRegEx": "Freund and Schapire", "year": 1997}, {"title": "The elements of statistical learning, volume 1. Springer series in statistics", "author": ["Friedman", "Jerome", "Hastie", "Trevor", "Tibshirani", "Robert"], "venue": null, "citeRegEx": "Friedman et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 2001}, {"title": "A neural algorithm of artistic style", "author": ["Gatys", "Leon A", "Ecker", "Alexander S", "Bethge", "Matthias"], "venue": "arXiv preprint arXiv:1508.06576,", "citeRegEx": "Gatys et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gatys et al\\.", "year": 2015}, {"title": "Generative adversarial nets", "author": ["Goodfellow", "Ian", "Pouget-Abadie", "Jean", "Mirza", "Mehdi", "Xu", "Bing", "Warde-Farley", "David", "Ozair", "Sherjil", "Courville", "Aaron", "Bengio", "Yoshua"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Explaining and harnessing adversarial examples", "author": ["Goodfellow", "Ian J", "Shlens", "Jonathon", "Szegedy", "Christian"], "venue": "arXiv preprint arXiv:1412.6572,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Representations of knowledge in complex systems", "author": ["Grenander", "Ulf", "Miller", "Michael I"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "Grenander et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Grenander et al\\.", "year": 1994}, {"title": "Noise-contrastive estimation: A new estimation principle for unnormalized statistical models", "author": ["Gutmann", "Michael", "Hyv\u00e4rinen", "Aapo"], "venue": "In AISTATS,", "citeRegEx": "Gutmann et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gutmann et al\\.", "year": 2010}, {"title": "Deep residual learning for image recognition", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "In CVPR,", "citeRegEx": "He et al\\.,? \\Q2016\\E", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "Identity mappings in deep residual networks", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "He et al\\.,? \\Q2016\\E", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y.W. Teh"], "venue": "Neural computation,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "wake-sleep\u201d algorithm for unsupervised neural networks", "author": ["Hinton", "Geoffrey E", "Dayan", "Peter", "Frey", "Brendan J", "Neal", "Radford M. The"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 1995}, {"title": "Machine learning: discriminative and generative", "author": ["Jebara", "Tony"], "venue": null, "citeRegEx": "Jebara and Tony.,? \\Q2012\\E", "shortCiteRegEx": "Jebara and Tony.", "year": 2012}, {"title": "DCGAN-tensorflow. https://github.com/ carpedm20/DCGAN-tensorflow, 2016", "author": ["Kim", "Taehoon"], "venue": null, "citeRegEx": "Kim and Taehoon.,? \\Q2016\\E", "shortCiteRegEx": "Kim and Taehoon.", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik", "Ba", "Jimmy"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Learning Multiple Layers of Features from Tiny Images", "author": ["Krizhevsky", "Alex"], "venue": "CS Dept., U Toronto, Tech. Rep.,", "citeRegEx": "Krizhevsky and Alex.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky and Alex.", "year": 2009}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": "In NIPS,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Introspective learning and reasoning", "author": ["Leake", "David B"], "venue": "In Encyclopedia of the Sciences of Learning,", "citeRegEx": "Leake and B.,? \\Q2012\\E", "shortCiteRegEx": "Leake and B.", "year": 2012}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "In Neural Computation,", "citeRegEx": "LeCun et al\\.,? \\Q1989\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1989}, {"title": "Generalizing pooling functions in convolutional neural networks: Mixed, gated, and tree", "author": ["Lee", "Chen-Yu", "Gallagher", "Patrick W", "Tu", "Zhuowen"], "venue": null, "citeRegEx": "Lee et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2016}, {"title": "An asymptotic analysis of generative, discriminative, and pseudolikelihood estimators", "author": ["Liang", "Percy", "Jordan", "Michael I"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Liang et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Liang et al\\.", "year": 2008}, {"title": "Monte Carlo strategies in scientific computing", "author": ["Liu", "Jun S"], "venue": "Springer Science & Business Media,", "citeRegEx": "Liu and S.,? \\Q2008\\E", "shortCiteRegEx": "Liu and S.", "year": 2008}, {"title": "Rectifier nonlinearities improve neural network acoustic models", "author": ["Maas", "Andrew L", "Hannun", "Awni Y", "Ng", "Andrew Y"], "venue": "In ICML,", "citeRegEx": "Maas et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Maas et al\\.", "year": 2013}, {"title": "Stochastic gradient descent as approximate bayesian inference", "author": ["Mandt", "Stephan", "Hoffman", "Matthew D", "Blei", "David M"], "venue": "arXiv preprint arXiv:1704.04289,", "citeRegEx": "Mandt et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Mandt et al\\.", "year": 2017}, {"title": "Bootstrapping: A nonparametric approach to statistical inference", "author": ["Mooney", "Christopher Z", "Duval", "Robert D", "Duvall", "Robert"], "venue": "Number 94-95", "citeRegEx": "Mooney et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Mooney et al\\.", "year": 1993}, {"title": "Deepdream - a code example for visualizing neural networks", "author": ["Mordvintsev", "Alexander", "Olah", "Christopher", "Tyka", "Mike"], "venue": "Google Research,", "citeRegEx": "Mordvintsev et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mordvintsev et al\\.", "year": 2015}, {"title": "Reading Digits in Natural Images with Unsupervised Feature Learning", "author": ["Netzer", "Yuval", "Wang", "Tao", "Coates", "Adam", "Bissacco", "Alessandro", "Wu", "Bo", "Ng", "Andrew Y"], "venue": "In NIPS Workshop on Deep Learning and Unsupervised Feature Learning,", "citeRegEx": "Netzer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Netzer et al\\.", "year": 2011}, {"title": "Improved use of continuous attributes in c4.5", "author": ["J.R. Quinlan"], "venue": "J. of Art. Intell. Res.,", "citeRegEx": "Quinlan,? \\Q1996\\E", "shortCiteRegEx": "Quinlan", "year": 1996}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["Radford", "Alec", "Metz", "Luke", "Chintala", "Soumith"], "venue": "arXiv preprint arXiv:1511.06434,", "citeRegEx": "Radford et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2015}, {"title": "Improved techniques for training gans", "author": ["Salimans", "Tim", "Goodfellow", "Ian", "Zaremba", "Wojciech", "Cheung", "Vicki", "Radford", "Alec", "Chen", "Xi"], "venue": "arXiv preprint arXiv:1606.03498,", "citeRegEx": "Salimans et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Salimans et al\\.", "year": 2016}, {"title": "Active learning literature survey", "author": ["Settles", "Burr"], "venue": "University of Wisconsin, Madison,", "citeRegEx": "Settles and Burr.,? \\Q2010\\E", "shortCiteRegEx": "Settles and Burr.", "year": 2010}, {"title": "Reinforcement learning: An introduction, volume 1", "author": ["Sutton", "Richard S", "Barto", "Andrew G"], "venue": "MIT press Cambridge,", "citeRegEx": "Sutton et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1998}, {"title": "Adagan: Boosting generative models", "author": ["Tolstikhin", "Ilya", "Gelly", "Sylvain", "Bousquet", "Olivier", "SimonGabriel", "Carl-Johann", "Sch\u00f6lkopf", "Bernhard"], "venue": "arXiv preprint arXiv:1701.02386,", "citeRegEx": "Tolstikhin et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Tolstikhin et al\\.", "year": 2017}, {"title": "Learning generative models via discriminative approaches", "author": ["Tu", "Zhuowen"], "venue": "In CVPR,", "citeRegEx": "Tu and Zhuowen.,? \\Q2007\\E", "shortCiteRegEx": "Tu and Zhuowen.", "year": 2007}, {"title": "Brain anatomical structure segmentation by hybrid discriminative/generative models", "author": ["Tu", "Zhuowen", "Narr", "Katherine L", "Doll\u00e1r", "Piotr", "Dinov", "Ivo", "Thompson", "Paul M", "Toga", "Arthur W"], "venue": "Medical Imaging, IEEE Transactions on,", "citeRegEx": "Tu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Tu et al\\.", "year": 2008}, {"title": "The nature of statistical learning theory", "author": ["Vapnik", "Vladimir N"], "venue": null, "citeRegEx": "Vapnik and N.,? \\Q1995\\E", "shortCiteRegEx": "Vapnik and N.", "year": 1995}, {"title": "Bayesian learning via stochastic gradient langevin dynamics", "author": ["Welling", "Max", "Teh", "Yee W"], "venue": "In ICML,", "citeRegEx": "Welling et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Welling et al\\.", "year": 2011}, {"title": "Self supervised boosting", "author": ["Welling", "Max", "Zemel", "Richard S", "Hinton", "Geoffrey E"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Welling et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Welling et al\\.", "year": 2002}, {"title": "Equivalence of julesz ensembles and frame models", "author": ["Wu", "Ying Nian", "Zhu", "Song Chun", "Liu", "Xiuwen"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Wu et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2000}, {"title": "Cooperative training of descriptor and generator networks", "author": ["Xie", "Jianwen", "Lu", "Yang", "Zhu", "Song-Chun", "Wu", "Ying Nian"], "venue": "arXiv preprint arXiv:1609.09408,", "citeRegEx": "Xie et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Xie et al\\.", "year": 2016}, {"title": "A theory of generative convnet", "author": ["Xie", "Jianwen", "Lu", "Yang", "Zhu", "Song-Chun", "Wu", "Ying Nian"], "venue": "arXiv preprint arXiv:1602.03264,", "citeRegEx": "Xie et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Xie et al\\.", "year": 2016}, {"title": "Energybased generative adversarial network", "author": ["Zhao", "Junbo", "Mathieu", "Michael", "LeCun", "Yann"], "venue": "arXiv preprint arXiv:1609.03126,", "citeRegEx": "Zhao et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2016}, {"title": "Minimax entropy principle and its application to texture modeling", "author": ["Zhu", "Song Chun", "Wu", "Ying Nian", "Mumford", "David"], "venue": "Neural Computation,", "citeRegEx": "Zhu et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 1997}, {"title": "Semi-supervised learning literature survey", "author": ["Zhu", "Xiaojin"], "venue": "Technical Report 1530,", "citeRegEx": "Zhu and Xiaojin.,? \\Q2005\\E", "shortCiteRegEx": "Zhu and Xiaojin.", "year": 2005}], "referenceMentions": [{"referenceID": 5, "context": ", 2000), semi-supervised (Zhu, 2005), weakly-supervised (Dietterich et al., 1997), and reinforcement (Sutton & Barto, 1998) which also point to promising directions when annotated data is limited.", "startOffset": 56, "endOffset": 81}, {"referenceID": 32, "context": "Existing classifiers, such as decision trees (Quinlan, 1996), support vector machines (Vapnik, 1995), neural networks (LeCun et al.", "startOffset": 45, "endOffset": 60}, {"referenceID": 23, "context": "Existing classifiers, such as decision trees (Quinlan, 1996), support vector machines (Vapnik, 1995), neural networks (LeCun et al., 1989), boosting (Freund & Schapire, 1997), and random forests (Breiman, 2001), carry out training processes to either implicitly or explicitly minimize an objective function that balances the training error and regularization.", "startOffset": 118, "endOffset": 138}, {"referenceID": 21, "context": "Recent studies reveal that even modern classifiers like deep convolutional neural networks (Krizhevsky et al., 2012) still make mistakes that look absurd to humans (Goodfellow et al.", "startOffset": 91, "endOffset": 116}, {"referenceID": 29, "context": "Different types of approaches have been proposed in the past including bootstrapping (Mooney et al., 1993), active learning (Settles, 2010), semi-supervised learning (Zhu, 2005), and data augmentation (Krizhevsky et al.", "startOffset": 85, "endOffset": 106}, {"referenceID": 21, "context": ", 1993), active learning (Settles, 2010), semi-supervised learning (Zhu, 2005), and data augmentation (Krizhevsky et al., 2012).", "startOffset": 102, "endOffset": 127}, {"referenceID": 7, "context": "In the past, attempts have been made to build connections between generative models and discriminative classifiers (Friedman et al., 2001; Liang & Jordan, 2008; Jebara, 2012).", "startOffset": 115, "endOffset": 174}, {"referenceID": 39, "context": "Many existing approaches however combine discriminative classifiers with generative models to form hybrid models (Tu et al., 2008).", "startOffset": 113, "endOffset": 130}, {"referenceID": 42, "context": "In (Welling et al., 2002) a self supervised boosting algorithm was proposed to train a boosting algorithm by sequentially adding features as weak classifiers on additional self-generated negative samples; the generative discriminative modeling work in (Tu, 2007) generalizes the concept that a generative model can be successfully modeled by learning a sequence of discriminative classifiers via self-generated pseudo-negatives.", "startOffset": 3, "endOffset": 25}, {"referenceID": 42, "context": "Inspired by the work that learns density functions (Welling et al., 2002) and generative models (Tu, 2007) using sequentially self-generated pseudo-negative samples, as well as recent success in deep learning (LeCun et al.", "startOffset": 51, "endOffset": 73}, {"referenceID": 23, "context": ", 2002) and generative models (Tu, 2007) using sequentially self-generated pseudo-negative samples, as well as recent success in deep learning (LeCun et al., 1989; Hinton et al., 2006; Krizhevsky et al., 2012; Gatys et al., 2015), we propose here an algorithm that capitalizes on the endto-end learning of deep convolutional nets while making it internally generative.", "startOffset": 143, "endOffset": 229}, {"referenceID": 15, "context": ", 2002) and generative models (Tu, 2007) using sequentially self-generated pseudo-negative samples, as well as recent success in deep learning (LeCun et al., 1989; Hinton et al., 2006; Krizhevsky et al., 2012; Gatys et al., 2015), we propose here an algorithm that capitalizes on the endto-end learning of deep convolutional nets while making it internally generative.", "startOffset": 143, "endOffset": 229}, {"referenceID": 21, "context": ", 2002) and generative models (Tu, 2007) using sequentially self-generated pseudo-negative samples, as well as recent success in deep learning (LeCun et al., 1989; Hinton et al., 2006; Krizhevsky et al., 2012; Gatys et al., 2015), we propose here an algorithm that capitalizes on the endto-end learning of deep convolutional nets while making it internally generative.", "startOffset": 143, "endOffset": 229}, {"referenceID": 8, "context": ", 2002) and generative models (Tu, 2007) using sequentially self-generated pseudo-negative samples, as well as recent success in deep learning (LeCun et al., 1989; Hinton et al., 2006; Krizhevsky et al., 2012; Gatys et al., 2015), we propose here an algorithm that capitalizes on the endto-end learning of deep convolutional nets while making it internally generative.", "startOffset": 143, "endOffset": 229}, {"referenceID": 42, "context": "To compare with the self-supervised boosting work (Welling et al., 2002), ICL has its advantage in: a).", "startOffset": 50, "endOffset": 72}, {"referenceID": 37, "context": "Other methods (Gutmann & Hyv\u00e4rinen, 2010; Tolstikhin et al., 2017) in which generative models are learned using discriminative classifiers share some common disadvantages as in (Welling et al.", "startOffset": 14, "endOffset": 66}, {"referenceID": 42, "context": ", 2017) in which generative models are learned using discriminative classifiers share some common disadvantages as in (Welling et al., 2002; Tu, 2007).", "startOffset": 118, "endOffset": 150}, {"referenceID": 7, "context": "Previous algorithms connecting generative modeling with discriminative classification (Friedman et al., 2001; Liang & Jordan, 2008; Tu et al., 2008; Jebara, 2012) fall in the category of hybrid models that are combinations of the two and mostly limited to specific tasks.", "startOffset": 86, "endOffset": 162}, {"referenceID": 39, "context": "Previous algorithms connecting generative modeling with discriminative classification (Friedman et al., 2001; Liang & Jordan, 2008; Tu et al., 2008; Jebara, 2012) fall in the category of hybrid models that are combinations of the two and mostly limited to specific tasks.", "startOffset": 86, "endOffset": 162}, {"referenceID": 29, "context": "Other directions in machine learning such as bootstrapping (Mooney et al., 1993), active learning (Settles, 2010; Beygelzimer et al.", "startOffset": 59, "endOffset": 80}, {"referenceID": 21, "context": ", 2009), semi-supervised learning (Zhu, 2005), and data augmentation (Krizhevsky et al., 2012), try to effectively utilize the existing data whereas ICL is able to self-generate new data.", "startOffset": 69, "endOffset": 94}, {"referenceID": 33, "context": ", 2014a) engages two separate models, a generator and a discriminator, with the objective of making use of the discriminator to help the generator generate faithful samples; the discriminator in GAN is not meant to perform the generic two-class/multi-class classification task; thus, some special settings for semi-supervised learning (Goodfellow et al., 2014a; Radford et al., 2015; Zhao et al., 2016; Brock et al., 2016; Salimans et al., 2016) were created since the discriminators in GAN were trained to classify between \u201creal\u201d and \u201cfake\u201d samples.", "startOffset": 335, "endOffset": 445}, {"referenceID": 46, "context": ", 2014a) engages two separate models, a generator and a discriminator, with the objective of making use of the discriminator to help the generator generate faithful samples; the discriminator in GAN is not meant to perform the generic two-class/multi-class classification task; thus, some special settings for semi-supervised learning (Goodfellow et al., 2014a; Radford et al., 2015; Zhao et al., 2016; Brock et al., 2016; Salimans et al., 2016) were created since the discriminators in GAN were trained to classify between \u201creal\u201d and \u201cfake\u201d samples.", "startOffset": 335, "endOffset": 445}, {"referenceID": 2, "context": ", 2014a) engages two separate models, a generator and a discriminator, with the objective of making use of the discriminator to help the generator generate faithful samples; the discriminator in GAN is not meant to perform the generic two-class/multi-class classification task; thus, some special settings for semi-supervised learning (Goodfellow et al., 2014a; Radford et al., 2015; Zhao et al., 2016; Brock et al., 2016; Salimans et al., 2016) were created since the discriminators in GAN were trained to classify between \u201creal\u201d and \u201cfake\u201d samples.", "startOffset": 335, "endOffset": 445}, {"referenceID": 34, "context": ", 2014a) engages two separate models, a generator and a discriminator, with the objective of making use of the discriminator to help the generator generate faithful samples; the discriminator in GAN is not meant to perform the generic two-class/multi-class classification task; thus, some special settings for semi-supervised learning (Goodfellow et al., 2014a; Radford et al., 2015; Zhao et al., 2016; Brock et al., 2016; Salimans et al., 2016) were created since the discriminators in GAN were trained to classify between \u201creal\u201d and \u201cfake\u201d samples.", "startOffset": 335, "endOffset": 445}, {"referenceID": 33, "context": "Later development alongside GAN (Radford et al., 2015; Salimans et al., 2016; Zhao et al., 2016; Brock et al., 2016) share some similar aspects to GAN, which also do not achieve the same goal as ICL does.", "startOffset": 32, "endOffset": 116}, {"referenceID": 34, "context": "Later development alongside GAN (Radford et al., 2015; Salimans et al., 2016; Zhao et al., 2016; Brock et al., 2016) share some similar aspects to GAN, which also do not achieve the same goal as ICL does.", "startOffset": 32, "endOffset": 116}, {"referenceID": 46, "context": "Later development alongside GAN (Radford et al., 2015; Salimans et al., 2016; Zhao et al., 2016; Brock et al., 2016) share some similar aspects to GAN, which also do not achieve the same goal as ICL does.", "startOffset": 32, "endOffset": 116}, {"referenceID": 2, "context": "Later development alongside GAN (Radford et al., 2015; Salimans et al., 2016; Zhao et al., 2016; Brock et al., 2016) share some similar aspects to GAN, which also do not achieve the same goal as ICL does.", "startOffset": 32, "endOffset": 116}, {"referenceID": 34, "context": "For example, an additional \u201cnot-real\u201d class was generated in addition to the standard k classes in multi-class classification for a semisupervised learning setting in (Salimans et al., 2016).", "startOffset": 167, "endOffset": 190}, {"referenceID": 47, "context": "Other generative modeling schemes such as the MiniMax entropy theory (Zhu et al., 1997), inducing features (Della Pietra et al.", "startOffset": 69, "endOffset": 87}, {"referenceID": 16, "context": ", 1997), auto-encoder (Baldi, 2012), Wake-sleep (Hinton et al., 1995), and recent CNN based generative modeling approaches (Xie et al.", "startOffset": 48, "endOffset": 69}, {"referenceID": 23, "context": "a boosting algorithm (Freund & Schapire, 1997) or convolutional neural networks (LeCun et al., 1989) to learn p(y = +1|x), which is always an approximation due to various reasons including insufficient training samples, generalization error, and classifier limitations.", "startOffset": 80, "endOffset": 100}, {"referenceID": 21, "context": "Previous attempts to improve classification by data augmentation were mostly done to increase the positive samples (Krizhevsky et al., 2012; Goodfellow et al., 2014b); we instead argue the importance of increasing negative samples to improve the classification performance.", "startOffset": 115, "endOffset": 166}, {"referenceID": 30, "context": "Motivated by the DeepDream code (Mordvintsev et al., 2015) and Neural Artistic Style work (Gatys et al.", "startOffset": 32, "endOffset": 58}, {"referenceID": 8, "context": ", 2015) and Neural Artistic Style work (Gatys et al., 2015), we update a random sample x drawn from pr (x) by increasing qt(y=+1|x;Wt) qt(y=\u22121|x;Wt) using backpropagation.", "startOffset": 39, "endOffset": 59}, {"referenceID": 3, "context": "Building the connection between SGD and MCMC is an active area in machine learning (Welling & Teh, 2011; Chen et al., 2014; Mandt et al., 2017).", "startOffset": 83, "endOffset": 143}, {"referenceID": 28, "context": "Building the connection between SGD and MCMC is an active area in machine learning (Welling & Teh, 2011; Chen et al., 2014; Mandt et al., 2017).", "startOffset": 83, "endOffset": 143}, {"referenceID": 28, "context": "A recent work (Mandt et al., 2017) further shows the similarity between constant SGD and MCMC, along with analysis of SGD using momentum updates.", "startOffset": 14, "endOffset": 34}, {"referenceID": 43, "context": "Our progressively learned discriminative classifier can be viewed as carving out the feature space on \u03c6(x), which essentially becomes a equivalent class for the positives; the volume of the equivalent class that satisfies the condition is exponentially large, as analyzed in (Wu et al., 2000).", "startOffset": 275, "endOffset": 292}, {"referenceID": 34, "context": "We perform direct multi-class classification where the parameter setting is identical to a standard multi-class classification in CNN whereas an additional \u201cnot-real\u201d class is created in (Salimans et al., 2016).", "startOffset": 187, "endOffset": 210}, {"referenceID": 27, "context": "LeakyReLU activations (Maas et al., 2013) are used after each convolutional layer.", "startOffset": 22, "endOffset": 41}, {"referenceID": 33, "context": ", 2014a) and DCGAN (Radford et al., 2015) show results for unsupervised learning and semi-supervised classification.", "startOffset": 19, "endOffset": 41}, {"referenceID": 33, "context": "To compare with DCGAN (Radford et al., 2015), we follow the same procedure: each generator trained by DCGAN (Radford et al.", "startOffset": 22, "endOffset": 44}, {"referenceID": 33, "context": ", 2015), we follow the same procedure: each generator trained by DCGAN (Radford et al., 2015) using tensorflow implementation (Kim, 2016) was used to generate positive samples, which are then augmented to the negative set to train the individual one-vs-all CNN classifiers (also using an identical CNN architecture to ICL), which are combined to create the overall multi-class classifier.", "startOffset": 71, "endOffset": 93}, {"referenceID": 33, "context": "As the supervised learning task was not directly specified in DCGAN (Radford et al., 2015), some care is needed to design the optimal setting to utilize the generated samples from DCGAN in the two-step approach (we may not get the best setting in the experiments).", "startOffset": 68, "endOffset": 90}, {"referenceID": 31, "context": "The SVHN (Netzer et al., 2011) dataset consists of color images of house numbers collected by Google Street View.", "startOffset": 9, "endOffset": 30}], "year": 2017, "abstractText": "In this paper we propose introspective classifier learning (ICL) that emphasizes the importance of having a discriminative classifier empowered with generative capabilities. We develop a reclassification-by-synthesis algorithm to perform training using a formulation stemmed from the Bayes theory. Our classifier is able to iteratively: (1) synthesize pseudo-negative samples in the synthesis step; and (2) enhance itself by improving the classification in the reclassification step. The single classifier learned is at the same time generative \u2014 being able to directly synthesize new samples within its own discriminative model. We conduct experiments on standard benchmark datasets including MNIST, CIFAR, and SVHN using state-of-the-art CNN architectures, and observe improved classification results.", "creator": "LaTeX with hyperref package"}}}