{"id": "1705.03303", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-May-2017", "title": "The Imprecisions of Precision Measures in Process Mining", "abstract": "In willesborough process memons mining, medlyn precision measures signup are 75-billion used oberligas to iro quantify boscastle how much spanjers a heckler process baishui model capitula overapproximates the rodden behavior seen hypergraphs in an event log. Although 23.53 several measures have been proposed throughout capraia the woensdrecht years, free-trade no research annihilate has been unfavored done to carcinogen validate heavyset whether 96.22 these kairi measures once-in-a-lifetime achieve maillot the intended intros aim of quantifying over - approximation azrojan in a consistent way muddy for 22,750 all vimala models esdraelon and logs. ekblom This paper garbutt fills this jarbawi gap 206-448-8160 by grossack postulating a strepsirrhine number pequiven of axioms holdgate for licencees quantifying 55.78 precision simple consistently undulatus for any samyutta log and any model. farag Further, we salak show through counter - examples that skyship none of katsumasa the gravel existing measures consistently wita quantifies precision.", "histories": [["v1", "Wed, 3 May 2017 11:50:45 GMT  (24kb,D)", "https://arxiv.org/abs/1705.03303v1", null], ["v2", "Tue, 16 May 2017 18:44:59 GMT  (24kb,D)", "http://arxiv.org/abs/1705.03303v2", null]], "reviews": [], "SUBJECTS": "cs.DB cs.AI cs.LO cs.SE", "authors": ["niek tax", "xixi lu", "natalia sidorova", "dirk fahland", "wil m p van der aalst"], "accepted": false, "id": "1705.03303"}, "pdf": {"name": "1705.03303.pdf", "metadata": {"source": "CRF", "title": "The Imprecisions of Precision Measures in Process Mining", "authors": ["Niek Tax", "Xixi Lu", "Natalia Sidorova", "Dirk Fahland", "Wil M.P. van der Aalst"], "emails": ["n.tax@tue.nl", "x.lu@tue.nl", "n.sidorova@tue.nl", "d.fahland@tue.nl", "w.m.p.v.d.aalst@tue.nl"], "sections": [{"heading": null, "text": "In process mining, precision measures are used to quantify how much a process model overapproximates the behavior seen in an event log. Although several measures have been proposed throughout the years, no research has been done to validate whether these measures achieve the intended aim of quantifying over-approximation in a consistent way for all models and logs. This paper fills this gap by postulating a number of axioms for quantifying precision consistently for any log and any model. Further, we show through counter-examples that none of the existing measures consistently quantifies precision.\nKeywords: Process mining, Formal languages and automata, Petri nets, Design of algorithms"}, {"heading": "1. Introduction", "text": "Process mining [1] is a fast growing discipline that is focused on the analysis of events logged during the execution of a business process. Events contain information on what was done, by whom, for whom, where, when, etc. Such event data are often readily available from information systems such as ERP, CRM, or BPM systems. Process discovery, which plays a prominent role in process mining, is the task of automatically generating a process model that accurately describes a business process based on such event data. Many process discovery techniques have been developed over the last decade (e.g. [2, 3, 4, 5]), producing process models in various forms, such as Petri nets [6], process trees [7], YAWL models [8], and BPMN models [9].\nThe process model that is pursued by process discovery techniques ideally allows for all the behavior that was observed in the event log (called fitness), while at the same time it should not be too general by allowing for much more behavior than what was seen in the event log (called precision).\nA range of measures have been proposed for quantifying precision [10, 11, 12, 13, 14]. However, to the best of our knowledge, there is currently no work on verifying whether precision measures actually quantify what\n\u2217Corresponding author Email addresses: n.tax@tue.nl (Niek Tax), x.lu@tue.nl\n(Xixi Lu), n.sidorova@tue.nl (Natalia Sidorova), d.fahland@tue.nl (Dirk Fahland), w.m.p.v.d.aalst@tue.nl (Wil M.P. van der Aalst)\nthey are supposed to measure in a consistent manner. Conceptually, the precision of a process model in the context of an event log should be high when the model allows for few traces not seen in the log, and it should be low when it allows for many traces not seen in the log. In this paper we propose a set of axioms that formulate desired properties of precision measures and systematically validate whether these axioms hold for existing precision measures.\nIn Section 2 we introduce basic notation and definitions. In Section 3 we formulate axioms for precision measures. We then continue with Section 4, where we describe existing precision measures in more detail and validate the axioms for these measures. In Section 5 we describe two contexts in which we are not able to define axioms for precision. In Section 6 we conclude this paper and state several directions for future work."}, {"heading": "2. Preliminaries", "text": "In this section we introduce concepts used in later sections of this paper.\nX = {a1, a2, . . . , an} denotes a finite set. P(X) denotes the power set of X, i.e., the set of all possible subsets of X. X\u2217 denotes the set of all sequences over a set X and \u03c3 = \u3008a1, a2, . . . , an\u3009 denotes a sequence of length n, with \u3008\u3009 the empty sequence. X\\Y denotes the set of elements that are in set X but not in set Y , e.g., {a, b, c}\\{a, c}={b}. A multiset (or bag) over X is a function B : X\u2192N which we write as [aw11 , a w2 2 , . . . , a wn n ], where for 1\u2264i\u2264n we have\nPreprint submitted to Elsevier May 18, 2017\nar X\niv :1\n70 5.\n03 30\n3v 2\n[ cs\n.D B\n] 1\n6 M\nay 2\n01 7\nai\u2208X and wi\u2208N+. The set of all bags over X is denoted B(X).\nIn the context of process mining, we assume the set of all process activities \u03a3 to be given. Event logs consist of sequences of events where each event represents a process activity.\nDefinition 1 (Event, Trace, and Event Log). An event e in an event log is the occurrence of an activity e\u2208\u03a3. We call a sequence of events \u03c3\u2208\u03a3\u2217 a trace. An event log L\u2208B(\u03a3\u2217) is a finite multiset of traces.\nL=[\u3008a, b, c\u30092, \u3008b, a, c\u30093] is an example event log over process activities \u03a3={a, b, c}, consisting of 2 occurrences of trace \u3008a, b, c\u3009 and three occurrences of trace \u3008b, a, c\u3009.\nMost precision measures have been implemented for Petri nets, a process modeling formalism frequently used in the context of process mining. A Petri net is a directed bipartite graph consisting of places (depicted as circles) and transitions (depicted as rectangles), connected by arcs. A transition describes an activity, while places represent the enabling conditions of transitions. Labels of transitions indicate the type of activity that they represent. Unlabeled transitions (\u03c4-transitions) represent invisible transitions (depicted as gray rectangles), which are only used for routing purposes and are not recorded in the event log.\nDefinition 2 (Labeled Petri net). A labeled Petri net N = \u3008P,T, F, `\u3009 is a tuple where P is a finite set of places, T is a finite set of transitions such that P\u2229T=\u2205, F\u2286(P\u00d7T )\u222a(T\u00d7P) is a set of directed arcs, called the flow relation, and `:T9\u03a3 is a partial labeling function that assigns a label to a transition, or leaves it unlabeled (the \u03c4-transitions).\nWe write \u2022n and n\u2022 for the input and output nodes of n \u2208 P \u222a T (according to F). A state of a Petri net is defined by its marking m\u2208B(P) being a multiset of places. A marking is graphically denoted by putting m(p) tokens on each place p\u2208P. State changes occur through transition firings. A transition t is enabled (can fire) in a given marking m if each input place p\u2208\u2022t contains at least one token. Once t fires, one token is removed from each input place p\u2208\u2022t and one token is added to each output place p\u2032\u2208t\u2022, leading to a new marking m\u2032=m\u2212 \u2022t + t\u2022.\nA firing of a transition t leading from marking m to marking m\u2032 is denoted as step m\nt\u2212\u2192m\u2032. Steps are lifted to sequences of firing enabled transitions, written m \u03b3 \u2212\u2192m\u2032 and \u03b3\u2208T \u2217 is a firing sequence..\nA partial function f\u2208X9Y with domain dom( f ) can be lifted to sequences over X using the following recursive definition: (1) f (\u3008\u3009) = \u3008\u3009; (2) for any \u03c3\u2208X\u2217 and x \u2208 X:\nf (\u03c3 \u00b7 \u3008x\u3009) = {\nf (\u03c3) if x<dom( f ), f (\u03c3) \u00b7 \u3008 f (x)\u3009 if x\u2208dom( f ).\nDefining an initial and final markings allows to define the language accepted by a Petri net as a set of finite sequences of activities.\nDefinition 3 (Accepting Petri Net). An accepting Petri net is a triplet APN=(N,m0,MF), where N is a labeled Petri net, m0\u2208B(P) is its initial marking, and MF\u2286B(P) is its set of possible final markings. A sequence \u03c3\u2208\u03a3\u2217 is a trace of an accepting Petri net APN if there exists a firing sequence m0 \u03b3 \u2212\u2192m f such that m f\u2208MF, \u03b3\u2208T \u2217 and `(\u03b3)=\u03c3.\nThe language L(APN) is the set of all its traces, i.e., L(APN)={l(\u03b3)|\u03b3\u2208T \u2217\u2227\u2203m f \u2208MFm0 \u03b3 \u2212\u2192m f }, which can be of infinite size when APN contains loops. Even though we define language for accepting Petri nets, in theory L(M) can be defined for any process model M with formal semantics. We denote the universe of process models asM. For each M\u2208M, L(M) is defined.\nFor an event log L, L\u0303={\u03c3\u2208\u03a3\u2217|L(\u03c3)>0} is the trace set of L. For example, for log L=[\u3008a, b, c\u30092, \u3008b, a, c\u30093], L\u0303={\u3008a, b, c\u3009\u3008b, a, c\u3009}. For an event log L and a model M we say that L is fitting on model M if L\u0303\u2286L(M). Precision is related to the behavior that is allowed by a model M that was not observed in the event log L, i.e., L(M)\\L\u0303."}, {"heading": "3. Axioms for Precision Metrics", "text": "The properties that are desired for precision measures are not clearly defined in existing work, although they are often discussed informally. Van der Aalst et al. [15], describe the precision dimension as \u201cPrecision: measure determining whether the model prohibits behavior very different from the behavior seen in the event log. A model with low precision is underfitting.\u201d. Vanden Broucke et al. [13] describe precision as \u201cprecision (or: appropriateness), i.e., the model\u2019s ability to disallow unwanted behavior;\u201d. Mu\u0303noz-Gama and Carmona [12] describe it as \u201cPrecision: refers to overly general models, preferring models with minimal behavior to represent as closely as possible to the log.\u201d. Buijs et al. [16] describe precision as \u201c... precision quantifies the fraction of the behavior allowed by the model which is not seen in the event log.\u201d.\nWe consider precision to be a function prec(L,M) which quantifies which part of the language of model M is seen in event log L. Below we formalize the desired properties of function prec through axioms to consistently hold for any kind of model and any kind of log.. Note that in the examples that we will show in this paper all models M will be Petri nets, however the formulated axioms are more general and apply to any process model M\u2208M. Figure 1 visualizes two axioms using Euler diagrams.\nThe first axiom states that precision is deterministic, i.e., given a log and model always the same result is returned.\nAxiom A1. A precision measure is a function prec : B(\u03a3\u2217) \u00d7M \u2192 R, i.e., it is deterministic.\nExisting precision measures normalize R to a [0, 1]- interval.\nThe second axiom formulates the conceptual description of precision more formally: if a process model M2 allows for more behavior not seen in a log L than another model M1 does, then M2 should have a lower precision than M1 regarding L.\nAxiom A2. For models M1 and M2 and a log L, L\u0303\u2286L(M1)\u2286L(M2) =\u21d2 prec(L,M1)\u2265prec(L,M2)\nNote that A2 does allow L\u0303\u2286L(M1)\u2282L(M2) with prec(L,M1)=prec(L,M2). Ideally, since L(M1) is smaller than L(M2) we would like to see a higher precision for M1, but this requirement might be too strict. However, for a process model M with L\u0303\u2286L(M), we would like the precision of M on L to be higher than the precision of M on any flower model (i.e., a model that allows for all behavior over its activities) on log L.\nAxiom A3. For models M1 and M2 and a log L, L(M1)\u2282P(\u03a3\u2217)\u2227L(M2)=P(\u03a3\u2217) =\u21d2 prec(L,M1)>prec(L,M2)\nThe precision of a log on two language equivalent models should be equal, i.e., precision should not depend on the model structure.\nAxiom A4. For models M1 and M2 and a log L, L(M1)=L(M2) =\u21d2 prec(L,M1)=prec(L,M2)\nA4 was stated before in an informal manner by Rozinat and van der Aalst [11], who stated that precision should be independent of structural properties of the model.\nAdding fitting traces to a fitting log can only increase the precision of a given model with respect to the log.\nAxiom A5. For model M and logs L1 and L2, L\u03031\u2286L\u03032\u2286L(M) =\u21d2 prec(L2,M)\u2265prec(L1,M)\nFrom A5 it follows as a corollary that precision is maximal when the log contains all the traces allowed by the model, and minimal when it contains no traces allowed by the model.\nIn the coming sections we will validate whether these axioms hold for several precision measures. Some articles that introduce precision measures explicitly mention that the measure is intended to be used only with a certain subclass of Petri nets. An example of such a subclass of Petri nets are bounded Petri nets, which have the restriction that all places most have a finite number of tokens in all reachable markings. When an article that introduces a precision measure states an explicit assumption on the subclass of Petri nets, then we only validate the axioms on this subclass of Petri nets. When no explicit assumption on a subclass of Petri nets is stated, we assume that the precision measure is intended for Petri nets in general."}, {"heading": "4. Precision Metrics", "text": "In this section we give an overview of the precision measures that have been developed in the process mining field, and validate the axioms for precision measures introduced in Section 3 for each of those measures."}, {"heading": "4.1. Soundness", "text": "Greco et al. [10] were the first to propose a precision measure, defining it as the number of unique executions of the process that were seen in the event log divided by the number of unique paths through the process model. This measure is not usable in practice, because it is zero when the process model allows for an infinite number of paths through the model. Any process model having a loop has a precision of 0. More recent precision\nmeasures are capable of calculating the precision of a model for an event log even when the models allows for infinite behavior."}, {"heading": "4.2. Behavioral Appropriateness", "text": "Rozinat and Van der Aalst [11] proposed the simple behavioral appropriateness precision measure, which looks at the average number of enabled transitions during replay. The authors observed themselves that simple behavioral appropriateness is dependent on the structure of the model, and not solely dependent on the behavior that it allows, therefore A4 does not hold for this measure. Furthermore, for a process model that contains silent transitions or duplicate labels it is possible that a given trace can be replayed on this model in multiple ways, where the average number of enabled transitions can depend on the chosen replay path through the model. This replay path through the model is chosen arbitrarily from the possible ways in which the trace can be replayed. This shows that A1 does not hold for simple behavioral appropriateness, as it is not deterministic.\nIn the same paper, Rozinat and van der Aalst [11] propose advanced behavioral appropriateness, which is independent of the model structure. Advanced behavioral appropriateness calculates the sets SF\u2286\u03a3\u00d7\u03a3 of pairs of activities that sometimes, but not always, follow each other. Likewise set SP\u2286\u03a3\u00d7\u03a3 is calculated as the set of activities that sometimes, but not always, precede each other. SLF and S L P denote the sometimes-follows and sometimes-precedes relations on the log, and SMF and SMP denotes the sometimes-follows and sometimesprecedes relations according to the model. However, to calculate SMF and S M P , exhaustive exploration of the state space of the model is required, prohibiting the application of this measure for large models or highly concurrent models, where the state-space explosion problem arises. Advanced behavioral appropriateness precision is defined as a\u2032b=( |SLF\u2229SMF | 2\u00b7|SMF | + |SLP\u2229SMP | 2\u00b7|SMP | ). Because SMF and S M P are obtained through exhaustive exploration of the state space of the model, it is easy to see that they depend only on the behavior of the model and not on its structure, therefore A4 holds. A problem with advanced behavioral appropriateness occurs for deterministic models, where |SMP |=|SMF |=0, leading to undefined precision. This shows that advanced behavioral appropriateness is a partial function, which is in conflict with A1.\nRozinat and van der Aalst [11] state that simple behavioral appropriateness and advanced behavioral appropriateness assume the Petri net to be in the class of sound workflow (WF) nets [17]. A WF-net requires the Petri net to have (i) a single Start place, (ii) a single\nEnd place, and (iii) every node must be on some path from Start to End. The soundness property additionally require that each transition can be potentially executed, and that the process can always terminate properly, i.e., finish with only one token in the End place.\nConsider model M of Figure 2, which belongs to the class of sound WF-nets, and any log L such that L\u0303\u2286L(M). The loop in model M causes SMF and SMP to contain all pairs of activities of \u03a3. Therefore, |SMF | and |SMP | are identical to the sometimes relations |SM \u2032\nF | and |SM\u2032P | of any model M\u2032 with L(M\u2032)=P(\u03a3\u2217), leading to prec(L,M)=prec(L,M\u2032). As L(M)\u2282P(\u03a3\u2217), this is in conflict with A3."}, {"heading": "4.3. Escaping Edges Precision", "text": "Escaping Edges Precision (ETC) [12] calculates precision by constructing a prefix automaton, which consists of one state per unique prefix of the event log. Figure 3b shows an example prefix automaton for an event log L = [\u3008a, c\u3009, \u3008a, d\u3009]. For each state in the prefix automaton it is then determined which activities are allowed as next activities by the process model. Activities that are allowed as next activities for some prefix but that are never observed in the event log after this prefix are referred to as escaping edges.\nIn later work [18, 19], alignments [20] are used to calculate the prefix automaton on the aligned event log instead of the original event log, making the precision measure robust to non-fitting traces, i.e., traces that are not in the language of the model. For a trace \u03c3 from a log L that is fitting on an accepting Petri net APN, alignments [20] give a sequence of transition firings \u03b3\u2208T \u2217 such that m0 \u03b3 \u2212\u2192m f with m0 the initial marking and m f a final marking of APN and `(\u03b3)=\u03c3. Note that for a given trace \u03c3 and model, multiple possible alignments can exist. For non-fitting traces, alignments search for a firing sequence \u03b3\u2208T \u2217 such that `(\u03b3) is as close as possible to \u03c3. Adriansyah et al. [18] describe two versions of the alignment-based escaping edges precision: one-align ETC, which calculates the precision based on one optimal alignment of log and model, and all-align ETC, which calculates the precision based on all optimal alignments between log and model. In practice, it is often computationally infeasible to calculate all optimal alignments. A later\nprecision measure, representative-align ETC [21], calculates the escaping edges based on a sample of optimal alignments, and can therefore be seen as a trade-off between the computational efficiency of one-align ETC and the reliability of all-align ETC. The papers on ETC precision and its variants do not state an assumption on a subclass of Petri nets. ETC, one-align ETC, all-align, and representative-align ETC precision are all implemented in the package ETConformance1 as part of the process mining framework ProM [22]. The one optimal alignment that is used by one-align ETC is chosen arbitrarily from the set of optimal alignments of a log on a model. However, different optimal alignments result in different prefix automata, which can potentially lead to different precision values. This shows that A1 does not hold for one-align ETC.\nConsider log L1=[\u3008a, c\u3009, \u3008a, d\u3009], log L2=[\u3008a, c\u3009, \u3008a, d\u3009, \u3008a, c\u3009, \u3008a, b, a, b, a, b, a, b, a, b, a, c\u3009] and model M be the Petri net of Figure 3a. Note that L\u03031\u2282L\u03032. The alignment automata generated for the calculation of prec(L1,M) and the calculation of prec(L2,M) are shown in Figure 3b and Figure 3c. The circles represent the states of the automaton, and the arrows the transitions. The numbers in the states represent the weights of the states for the precision calculation, i.e., the number of times that states are visited in the alignment of log L on model M [18]. In an alternative definition of one-align ETC [19] the states are weighted by the number of times that events occurred while being in this state according to the alignment of L on M, instead of the number of times that this state was reached according to this alignment. Figure 3b shows that the initial state was visited twice, activity a occurred twice at the start in log L1, resulting in a state from which activities b, d, and c were enabled.\n1https://svn.win.tue.nl/trac/prom/browser/Packages/ETConformance\nFrom this state, activities c and d were seen once, and activity b was never seen, thus it is an escaping edge. Escaping edges precision is then the (weighted) average ratio of non-escaping edges from all outgoing edges, where states are weighted by the number of times that they are visited. Counting the weighted number of nonescaping edges in the numerator and the weighted total number of edges in the denominator in our example, we find prec(L1,M)= 2\u00d71+2\u00d72+1\u00d70+1\u00d702\u00d71+2\u00d73+1\u00d70+1\u00d70 = 6 8 =0.75. One-align ETC results in the following precision values for M on L1 and L2: prec(L1,M)=0.75 and prec(L2,M)=0.7143. This shows that A5 does not hold for one-align ETC. By comparing the automata of Figures 3b and 3c it becomes clear that the single trace that is in L2 but not in L1 brings the model to many states with three escaping edges, reducing precision. The prefix automata and the precision calculations for M on logs L1 and L2 were performed manually following the procedure from the paper and validation using the ETConformance plugin in ProM.\nNow consider log L = [\u3008a, b, c\u3009], and the three Petri nets M1, M2, M3 in Figures 4a, 4b, and 4c respectively. Note that M1 and M2 are language equivalent, as L(M1)=L(M2)={a, b, c}\u2217. M3 is more behaviorally constrained than M1 and M2, since all its traces start with activity a. The one-align precision of M1, M2, M3 on L are: prec(L,M1)=0.3333, prec(L,M2)=0.5238, and prec(L,M3)=0.4444. L(M3)\u2282L(M1), but prec(L,M3)>prec(L,M1), implying that A2 does not hold for one-align ETC. Furthermore, L(M1)=L(M2), but prec(L,M1),prec(L,M2), implying that A4 does not hold for one-align ETC.\nAnalyzing the ETConformance plugin in ProM we\nfound that the prefix automaton generated for one-align precision for calculation of prec(L,M1) results in 6 states, belonging to 3 firings of observable transitions and 2 firings of \u03c4-transitions. In 3 of the 6 states, which correspond to M1 being in the initial marking, there are 4 possible next activities according to the model, of which only one is observed for that prefix. Furthermore, it shows that the alignment automaton generated for L and M1 consists of 6 states, the automaton for L and M2 consists of 12 states, and the automaton for L and M3 consists of 5 states. This shows that the silent (\u03c4) transitions in M2 generate additional states in the alignment automaton, leading to a higher precision value.\nComputing the precision of M1 or of M2 on L did not finish with all-align ETC and representative-align ETC after 8 hours of computation time. The long computation time of all-align ETC and representative-align ETC on models where many optimal alignments exist is a known issue which hinders the application of those measures in practice."}, {"heading": "4.4. Negative Event Precision", "text": "Goedertier et al. [2] proposed a method to induce negative events, i.e., sets of events that were prevented from taking place. Negative events are induced for each position in the event log, i.e., for each event e in each trace of the log a set of events is induced that could not have taken place instead of event e. De Weerdt et al. [23] proposed a precision measure based on negative events, behavioral precision (pB), which is closely linked to how precision is defined in the area of data mining. Negative event precision regards a process model as a binary classifier that determines whether a certain event can take place given a certain prefix, and then evaluates the precision of this classifier in data mining terms taking the induced negative events as ground truth. For a given trace prefix, true positive (TP) events are defined as events that are possible according to both the process model (i.e., a transition labeled with this event is enabled) and log (i.e., this event is not a negative event). False positive events (FP) are negative events induced for a given prefix that were possible according to the model. Behavioral precision is defined as pB = T PT P+FP , which is in accordance to the definition of precision in the data mining field. In later work [24] induction of artificial negative events has been refined based on frequent temporal patterns which are mined from the event log. Finally, weighted artificial events, where negative events are weighted according to their confidence, are proposed in [13].\nWeighted behavioral precision induces negative events for an event e in the log by taking a window\nof events w that directly precede e, then calculating all subsequences of events in the log that exactly match w, and finally negative events are identified by calculating which events have never occurred in the log directly after any subsequence matching w. This procedure is repeated for different windows sizes, and the resulting negative event are weighted by window size.\nTo induce the events that could not have happened after e.g. trace prefix \u03c3\u2032 = \u3008a, c, c, d, e, c, d, e, e\u3009, the method to induce weighted negative events described in [13] searches for subsequences of events in the log that are identical to the latest k events of \u03c3\u2032 in the event log. All the activities that have never succeeded such subsequences are considered to be negative events, furthermore, the confidence of these negative events is based on the length k of those matching subsequences.\nNegative event based precision measures, with the different methods for negative event induction, are implemented in the ProM package NEConformance2. In this paper we evaluate the precision measure that uses weighted negative events [13], which is the most recent approach to induce negative events and the recommended approach for measuring precision [13]. No assumption on a subclass of Petri nets is stated in the papers on negative event precision.\nConsider models M1 and M2 of Figure 5 respectively excluding and including the arcs and places indicated in dotted lines. L(M2)\u2282L(M1), since M2 contains a long term dependency between activities a and f and between activities b and g, which M1 does not have. Consider an event log L which consists of 10 traces from M2, leading to L being fitting on both M1 and M2. We found the negative event precision of M1 and M2 on the same L to be non-deterministic, resulting in slightly different values every time that it is calculated. This shows that A1 does not hold for negative event precision.\nBecause negative event precision is nondeterministic, we calculated the precision of M1\n2http://processmining.be/neconformance/\nand M2 on L both 20 times. The highest precision found in 20 repetitions for M1 is 0.4876, while the lowest precision found for M2 is 0.4545, showing that the non-determinism has the effect that A2 does not hold for negative event precision. We found an average value of 0.4744 with a standard deviation of 0.0090 for the precision of M1 on L and an average value of 0.4640 with a standard deviation of 0.0072 for the precision of M2 on L. This shows that also in terms of average precision value A2 does not hold.\nTo test whether the difference in mean precision between M1 and M2 is due to chance alone we formulate a null hypothesis: H0 : The average negative event precision of M2 on L is higher than or equal to the average negative event precision of M1 on L.\nTesting this null hypothesis with a one-tailed Welch t-test [25] we found a p-value of 0.0001801, indicating that we can reject the null hypothesis with significance level 0.01. This shows that, with statistical significance, the precision of M1 on L is higher than the precision of M2 on L, which is in disagreement with A2.\nTo see why A2 does not hold for negative event precision, consider the negative event inducing procure being applied to trace prefix \u03c3\u2032 = \u3008a, c, c, d, e, c, d, e, e\u3009 from log L. Petri net M2 generates many different traces because of the parallel length-one-loops on activities c, d and e, which allows for any sequence of any length over these activities. Therefore, the matching subsequences of \u03c3\u2032 in the log generated from M2 are the subsequences that by chance ended in the same behavior over c, d, and e. Because the sequences of c, d and e events can be long and diverse, activity a and b are unlikely to be present in the matching subsequences, which makes it unlikely that the procedure can induce the negative event g for \u03c3\u2032. Because the negative events that reflect the constraint that M2 introduces compared to M1 cannot be induced from the log, negative event precision is not able to recognize that M2 is more precise than M1."}, {"heading": "4.5. Projected Conformance Checking", "text": "Projected Conformance Checking (PCC) precision was developed by Leemans et al. [14] as a computationally efficient precision measure that scales to event logs with billions of events. PCC precision projects both event log and model on all subsets of activities of size k, and generates minimal deterministic finite automata (DFA) for the behavior over these subsets of activities in the log (i.e., log automaton) and for the behavior over these events allowed by the model (i.e., model automaton). Based on the log automaton and model automaton it then builds a conjunction automaton which allows the\nbehavior that was allowed both in log and model automaton. It then iterates over the states of the model automaton, and calculates over the share of transitions of this state that is also possible in the corresponding state in the conjunction automaton. It defines precision as the average of this share over the model automaton states.\nPCC precision is implemented in the ProM package ProjectedRecallAndPrecision3. PCC precision assumes the Petri net to be of the class of bounded Petri nets, i.e., the Petri net for which precision is calculated must have a finite number of tokens in every place for all reachable markings.\nConsider log L = [\u3008a, b\u3009] and Petri nets M1 and M2 of Figures 6a and 6b respectively. M1 starts with a lengthone-loop on activity a, followed by activity b. M2 unrolls the length-one-loop on activity a of M1 to at most two executions, thereby limiting the behavior as it only allows at most two executions of activity a. It is easy to see that M1 and M2 both belong to the class of bounded Petri nets, as in both models each place can have at most one token. For this log and these models, PCC precision results in prec(L,M1)=0.6, and prec(L,M2)=0.5. However, since L(M2)\u2282L(M1), A2 states that the precision of M2 for fitting log L should be higher or equal to its precision of M1. This shows that A2 does not hold for PCC precision.\nThis drop in precision is an effect of the additional states that are created in the model DFA as an effect of unrolling the length-one-loop. The model DFA created from Petri net M2 (Figure 6b) for example contains a state s that is reached after firing \u3008a, a\u3009. This state however is never reached based on event log L, which only contains a trace \u3008a, b\u3009, which has the effect that none of the enabled transitions from state s were observed in the log, bringing down the precision. In the DFA generated from Petri net M1 (Figure 6a), this state s is merged with the state that one reaches after observing a single a\n3https://svn.win.tue.nl/trac/prom/browser/ Packages/ProjectedRecallAndPrecision/\nevent, as future behavior allowed by the model does not depend on the number of a-events seen.\nConsider Petri net M of Figure 7, and event logs L1=[\u3008b, a, c\u3009, \u3008a, a, c\u3009], and L2=[\u3008b, a, c\u3009, \u3008a, a, c\u3009, \u3008a, b, b, b, b, b, b, b, b, b, b, b, b, b, b, b\u3009, \u3008b, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a\u3009]. The single place of M is bounded to one token, therefore M belongs to the class of bounded Petri nets. It is easy to see that L\u03031\u2282L\u03032, since the first two traces of log L2 form log L1. PCC precision results in prec(L1,M)=0.3125 and prec(L2,M)=0.2727, violating A5. The two traces of L2 that are not in L1 are very long traces to the traces that are in L1, leading to additional states in the log automaton and the conjunction automaton. The additional states of the conjunction automaton have a low precision of 14 , since for each state the model allows for four options (firing activity a, b, c, or stopping), while only one is seen in the log. Therefore, if we would expand trace \u3008b, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a\u3009 with more events of activity a, then prec(L2,M) would approach 14 ."}, {"heading": "4.6. Overview of Precision Metric Properties", "text": "We formulated five axioms that describe desirable properties for precision measures. Table 1 gives an overview of that axioms that we showed that do hold (3) and that do not hold (7) for each precision measure. We found that none of the existing precision measures fulfills all five axioms. Empty cells in the table are currently unknown, and no formal proof nor a counter example has been found that proves or disproves the axiom for the respective precision measure."}, {"heading": "5. Contexts With Unclear Requirements for Precision Metrics", "text": "The axioms introduced in Section 3 can be regarded as necessary conditions for precision measures, but they leave precision unspecified in some contexts. Figure 8a shows a situation in which L\u0303\u2286L(M1), L\u0303\u2286L(M2), but L(M1)\\L(M2),\u2205 and L(M2)\\L(M1),\u2205. In this setting, both M1 and M2 allow for (a possibly infinite amount of) different behavior that was not seen in L. Precision measures deal with this situation by quantifying the amount of behavior of M1 and M2. However, there are no obvious formal properties telling how the precision of M1 and M2 on L should relate.\nFurthermore, all axioms define desired properties of precision measures when the event log L fits the behavior of the model M, i.e., L\u0303 \u2286 L(M). In practice, process discovery techniques will return process models with fitness below 1, i.e., there exists \u03c3\u2208L : \u03c3<L(M). The discovery algorithm may deliberately abstract from infrequent behavior. In this paper we do not formulate axioms for precision measures in the context of event logs that do not fit the process model, since we feel that there is not enough agreement in the process mining community on how a precision measure should behave in this context. Figure 8b shows an Euler diagram of a log L and two models M1 and M2 such that L(M1)\u2282L(M2) and L\u0303*L(M1), which is a non-fitting equivalent of A2. A2 prescribes prec(L,M1)\u2265prec(L,M2), however, when the log does not fit the models, the behavior that fits M2 but not M1, (L\u0303\\L(M1))\u2229L(M2), makes it unclear how the precision of M1 and M2 should relate. Furthermore, even when (L\u0303\\L(M1))\u2229L(M2)=\u2205, it can be the case that the behavior in L that does not fit the models is behaviorally similar to behavior of M2."}, {"heading": "6. Conclusions & Future Work", "text": "In this paper provides a set of minimal requirements for precision measures through axioms. We validated these axioms for existing measures. Surprisingly, we\ndiscovered that none of the existing precision measures fulfills all formulated requirements.\nIn future work, we would like fill the empty cells of Table 1 and get a complete overview of the axioms that hold for each precision measure. Furthermore, we would like to use the insights learned from evaluating the axioms on the measures to either repair one of the existing measures or come up with a completely new measure that fulfills all five axioms.\nReproducibility. The event logs and process models that are used as part of a counterexample for a combination of an axiom and a precision measure can be found at [26]."}], "references": [{"title": "Robust process discovery with artificial negative events", "author": ["S. Goedertier", "D. Martens", "J. Vanthienen", "B. Baesens"], "venue": "Journal of Machine Learning Research", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Discovering block-structured process models from event logs-a constructive approach", "author": ["S.J.J. Leemans", "D. Fahland", "W.M.P. van der Aalst"], "venue": "in: International Conference on Applications and Theory of Petri Nets and Concurrency,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "BPMN miner: automated discovery of BPMN process models with hierarchical structure", "author": ["R. Conforti", "M. Dumas", "L. Garc\u0131\u0301a-Ba\u00f1uelos", "M. La Rosa"], "venue": "Information Systems", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Avoiding over-fitting in ILP-based process discovery", "author": ["S.J. van Zelst", "B.F. van Dongen", "W.M.P. van der Aalst"], "venue": "in: International Conference on Business Process Management, Springer International Publishing,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Petri nets: Properties, analysis and applications", "author": ["T. Murata"], "venue": "Proceedings of the IEEE", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1989}, {"title": "A genetic algorithm for discovering process trees", "author": ["J.C.A.M. Buijs", "B.F. van Dongen", "W.M.P. van der Aalst"], "venue": "in: Proceedings of the 2012 IEEE Congress on Evolutionary Computation,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "YAWL: yet another workflow language, Information systems", "author": ["W.M.P. van der Aalst", "A.H.M. ter Hofstede"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "Discovering expressive process models by clustering log traces", "author": ["G. Greco", "A. Guzzo", "L. Pontieri", "D. Sacca"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Conformance checking of processes based on monitoring real behavior, Information Systems", "author": ["A. Rozinat", "W.M.P. van der Aalst"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "A fresh look at precision in process conformance", "author": ["J. Mu\u00f1oz-Gama", "J. Carmona"], "venue": "in: International Conference on Business Process Management, Springer,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Determining process model precision and generalization with weighted artificial negative events", "author": ["S.K.L.M. vanden Broucke", "J. De Weerdt", "J. Vanthienen", "B. Baesens"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Scalable process discovery and conformance checking, Software & Systems Modeling", "author": ["S.J.J. Leemans", "D. Fahland", "W.M.P. van der Aalst"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Process mining manifesto", "author": ["W.M.P. van der Aalst", "A. Adriansyah", "A.K.A. De Medeiros", "F. Arcieri", "T. Baier", "T. Blickle", "J.C. Bose", "P. van den Brand", "R. Brandtjen", "J. Buijs"], "venue": "in: International Conference on Business Process Management,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "Quality dimensions in process discovery: The importance of fitness, precision, generalization and simplicity, International", "author": ["J.C.A.M. Buijs", "B.F. van Dongen", "W.M.P. van der Aalst"], "venue": "Journal of Cooperative Information Systems", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Verification of workflow nets", "author": ["W.M.P. van der Aalst"], "venue": "in: International Conference on Application and Theory of Petri Nets, Springer,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1997}, {"title": "Alignment based precision checking", "author": ["A. Adriansyah", "J. Munoz-Gama", "J. Carmona", "B.F. van Dongen", "W.M.P. van der Aalst"], "venue": "in: International Conference on Business Process Management,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Replaying history on process models for conformance checking and performance analysis, Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery", "author": ["W.M.P. Van der Aalst", "A. Adriansyah", "B.F. van Dongen"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Conformance checking using cost-based fitness analysis", "author": ["A. Adriansyah", "B.F. van Dongen", "W.M.P. van der Aalst"], "venue": "in: Proceedings of the 15th IEEE International Enterprise Distributed Object Computing Conference,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Measuring precision of modeled behavior, Information Systems and e-Business Management", "author": ["A. Adriansyah", "J. Munoz-Gama", "J. Carmona", "B.F. van Dongen", "W.M.P. van der Aalst"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "The ProM framework: A new era in process mining tool support", "author": ["B.F. van Dongen", "A.K.A. de Medeiros", "H.M.W. Verbeek", "A.J.M.M. Weijters", "W.M.P. van der Aalst"], "venue": "in: International Conference on Application and Theory of Petri Nets, Springer,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "A robust F-measure for evaluating discovered process", "author": ["J. De Weerdt", "M. De Backer", "J. Vanthienen", "B. Baesens"], "venue": "Proceedings of the IEEE Symposium on Computational Intelligence and Data Mining,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Improved artificial negative event generation to enhance process event logs", "author": ["S.K.L.M. vanden Broucke", "J. De Weerdt", "B. Baesens", "J. Vanthienen"], "venue": "in: International Conference on Advanced Information Systems Engineering,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "The generalization of student\u2019s\u2019 problem when several different population variances are involved, Biometrika", "author": ["B.L. Welch"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1947}, {"title": "Validation of precision measures - event logs and process models, Eindhoven University of Technology. Dataset, http://dx.doi.org/10.4121/uuid:991753f7-a240- 4ba6-a8a8-67174a08c51b (2017)", "author": ["N. Tax"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2017}], "referenceMentions": [{"referenceID": 0, "context": "[2, 3, 4, 5]), producing process models in various forms, such as Petri nets [6], process trees [7], YAWL models [8], and BPMN models [9].", "startOffset": 0, "endOffset": 12}, {"referenceID": 1, "context": "[2, 3, 4, 5]), producing process models in various forms, such as Petri nets [6], process trees [7], YAWL models [8], and BPMN models [9].", "startOffset": 0, "endOffset": 12}, {"referenceID": 2, "context": "[2, 3, 4, 5]), producing process models in various forms, such as Petri nets [6], process trees [7], YAWL models [8], and BPMN models [9].", "startOffset": 0, "endOffset": 12}, {"referenceID": 3, "context": "[2, 3, 4, 5]), producing process models in various forms, such as Petri nets [6], process trees [7], YAWL models [8], and BPMN models [9].", "startOffset": 0, "endOffset": 12}, {"referenceID": 4, "context": "[2, 3, 4, 5]), producing process models in various forms, such as Petri nets [6], process trees [7], YAWL models [8], and BPMN models [9].", "startOffset": 77, "endOffset": 80}, {"referenceID": 5, "context": "[2, 3, 4, 5]), producing process models in various forms, such as Petri nets [6], process trees [7], YAWL models [8], and BPMN models [9].", "startOffset": 96, "endOffset": 99}, {"referenceID": 6, "context": "[2, 3, 4, 5]), producing process models in various forms, such as Petri nets [6], process trees [7], YAWL models [8], and BPMN models [9].", "startOffset": 113, "endOffset": 116}, {"referenceID": 7, "context": "A range of measures have been proposed for quantifying precision [10, 11, 12, 13, 14].", "startOffset": 65, "endOffset": 85}, {"referenceID": 8, "context": "A range of measures have been proposed for quantifying precision [10, 11, 12, 13, 14].", "startOffset": 65, "endOffset": 85}, {"referenceID": 9, "context": "A range of measures have been proposed for quantifying precision [10, 11, 12, 13, 14].", "startOffset": 65, "endOffset": 85}, {"referenceID": 10, "context": "A range of measures have been proposed for quantifying precision [10, 11, 12, 13, 14].", "startOffset": 65, "endOffset": 85}, {"referenceID": 11, "context": "A range of measures have been proposed for quantifying precision [10, 11, 12, 13, 14].", "startOffset": 65, "endOffset": 85}, {"referenceID": 12, "context": "[15], describe the precision dimension as \u201cPrecision: mea-", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[13] describe precision as \u201cprecision (or: appropriateness), i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "M\u0169noz-Gama and Carmona [12] describe it as \u201cPrecision: refers to overly general models, preferring models with minimal behavior to represent as closely as possible to the log.", "startOffset": 23, "endOffset": 27}, {"referenceID": 13, "context": "[16] describe precision as \u201c.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "For models M1 and M2 and a log L, L(M1)=L(M2) =\u21d2 prec(L,M1)=prec(L,M2) A4 was stated before in an informal manner by Rozinat and van der Aalst [11], who stated that precision should be independent of structural properties of the model.", "startOffset": 143, "endOffset": 147}, {"referenceID": 7, "context": "[10] were the first to propose a precision measure, defining it as the number of unique executions of the process that were seen in the event log divided by the number of unique paths through the process model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "Rozinat and Van der Aalst [11] proposed the simple behavioral appropriateness precision measure, which looks at the average number of enabled transitions during replay.", "startOffset": 26, "endOffset": 30}, {"referenceID": 8, "context": "In the same paper, Rozinat and van der Aalst [11] propose advanced behavioral appropriateness, which is independent of the model structure.", "startOffset": 45, "endOffset": 49}, {"referenceID": 8, "context": "Rozinat and van der Aalst [11] state that simple behavioral appropriateness and advanced behavioral appropriateness assume the Petri net to be in the class of sound workflow (WF) nets [17].", "startOffset": 26, "endOffset": 30}, {"referenceID": 14, "context": "Rozinat and van der Aalst [11] state that simple behavioral appropriateness and advanced behavioral appropriateness assume the Petri net to be in the class of sound workflow (WF) nets [17].", "startOffset": 184, "endOffset": 188}, {"referenceID": 9, "context": "Escaping Edges Precision (ETC) [12] calculates precision by constructing a prefix automaton, which consists of one state per unique prefix of the event log.", "startOffset": 31, "endOffset": 35}, {"referenceID": 15, "context": "In later work [18, 19], alignments [20] are used to calculate the prefix automaton on the aligned event log instead of the original event log, making the precision measure robust to non-fitting traces, i.", "startOffset": 14, "endOffset": 22}, {"referenceID": 16, "context": "In later work [18, 19], alignments [20] are used to calculate the prefix automaton on the aligned event log instead of the original event log, making the precision measure robust to non-fitting traces, i.", "startOffset": 14, "endOffset": 22}, {"referenceID": 17, "context": "In later work [18, 19], alignments [20] are used to calculate the prefix automaton on the aligned event log instead of the original event log, making the precision measure robust to non-fitting traces, i.", "startOffset": 35, "endOffset": 39}, {"referenceID": 17, "context": "APN, alignments [20] give a sequence of transition firings \u03b3\u2208T \u2217 such that m0 \u03b3 \u2212\u2192m f with m0 the initial marking and m f a final marking of APN and `(\u03b3)=\u03c3.", "startOffset": 16, "endOffset": 20}, {"referenceID": 15, "context": "[18] describe two versions of the alignment-based escaping edges precision: one-align ETC, which calculates", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "precision measure, representative-align ETC [21], calculates the escaping edges based on a sample of optimal alignments, and can therefore be seen as a trade-off between the computational efficiency of one-align ETC and the reliability of all-align ETC.", "startOffset": 44, "endOffset": 48}, {"referenceID": 19, "context": "ETC, one-align ETC, all-align, and representative-align ETC precision are all implemented in the package ETConformance1 as part of the process mining framework ProM [22].", "startOffset": 165, "endOffset": 169}, {"referenceID": 15, "context": ", the number of times that states are visited in the alignment of log L on model M [18].", "startOffset": 83, "endOffset": 87}, {"referenceID": 16, "context": "In an alternative definition of one-align ETC [19] the states are weighted by the number of times that events occurred while being in this state according to the alignment of L on M, instead of the number of times", "startOffset": 46, "endOffset": 50}, {"referenceID": 0, "context": "[2] proposed a method to induce negative events, i.", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "[23] proposed a precision measure based on negative events, behavioral precision (pB), which is closely linked to how precision is defined in the area of data mining.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "In later work [24] induction of artificial negative events has been refined based on frequent temporal patterns which are mined", "startOffset": 14, "endOffset": 18}, {"referenceID": 10, "context": "Finally, weighted artificial events, where negative events are weighted according to their confidence, are proposed in [13].", "startOffset": 119, "endOffset": 123}, {"referenceID": 10, "context": "trace prefix \u03c3\u2032 = \u3008a, c, c, d, e, c, d, e, e\u3009, the method to induce weighted negative events described in [13] searches for subsequences of events in the log that are identical to the latest k events of \u03c3\u2032 in the event log.", "startOffset": 106, "endOffset": 110}, {"referenceID": 10, "context": "In this paper we evaluate the precision measure that uses weighted negative events [13], which is the most recent approach to induce negative events and the recommended approach for measuring precision [13].", "startOffset": 83, "endOffset": 87}, {"referenceID": 10, "context": "In this paper we evaluate the precision measure that uses weighted negative events [13], which is the most recent approach to induce negative events and the recommended approach for measuring precision [13].", "startOffset": 202, "endOffset": 206}, {"referenceID": 22, "context": "Testing this null hypothesis with a one-tailed Welch t-test [25] we found a p-value of 0.", "startOffset": 60, "endOffset": 64}, {"referenceID": 11, "context": "[14] as a computationally efficient precision measure that scales to event logs with billions of events.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "The event logs and process models that are used as part of a counterexample for a combination of an axiom and a precision measure can be found at [26].", "startOffset": 146, "endOffset": 150}], "year": 2017, "abstractText": "In process mining, precision measures are used to quantify how much a process model overapproximates the behavior seen in an event log. Although several measures have been proposed throughout the years, no research has been done to validate whether these measures achieve the intended aim of quantifying over-approximation in a consistent way for all models and logs. This paper fills this gap by postulating a number of axioms for quantifying precision consistently for any log and any model. Further, we show through counter-examples that none of the existing measures consistently quantifies precision.", "creator": "LaTeX with hyperref package"}}}