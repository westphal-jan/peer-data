{"id": "1705.09879", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-May-2017", "title": "Inexpensive Cost-Optimized Measurement Proposal for Sequential Model-Based Diagnosis", "abstract": "kneipp In this gorky-9 work we present veroli strategies sullana for (princetown optimal) measurement scheibner selection ogledd in model - based sequential lighted diagnosis. In particular, assuming sirkazhi a slesinger set wayan of orseno leading harefield diagnoses being cores given, podiatrist we cing show how zao queries (sets www.caiso.com of mplm measurements) can shellac be computed 6,065 and ouellet optimized ivt along divadlo two dimensions: uner expected number zavaleta of queries and transcode cost per query. sayyid By best-seller means 98.1 of a elfin suitable rajevac decoupling counsellor of onassio two optimizations victim and malmborg a clever search malafeev space gcap reduction the computations crispinus are temman done software-based without gaedel any temminck inference techtools engine calls. niamey For stoeckel the pharmd full search space, re-joining we vanderhei give a uspsa method requiring only kongress a emmendingen polynomial number saad of inferences and anthophyllite guaranteeing query properties myehrsh existing methods fates cannot provide. Evaluation iksan results using real - world ke4 problems 1992-1997 indicate that madasamy the new platero method tamagno computes (virtually) optimal queries 25-strong instantly wlib independently of the size cheech and radivojevi\u0107 complexity culprits of 69.85 the considered giustra diagnosis fur problems.", "histories": [["v1", "Sun, 28 May 2017 00:47:29 GMT  (70kb,D)", "http://arxiv.org/abs/1705.09879v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["patrick rodler", "wolfgang schmid", "konstantin schekotihin"], "accepted": false, "id": "1705.09879"}, "pdf": {"name": "1705.09879.pdf", "metadata": {"source": "CRF", "title": "Inexpensive Cost-Optimized Measurement Proposal for Sequential Model-Based Diagnosis", "authors": ["Patrick Rodler", "Wolfgang Schmid", "Konstantin Schekotihin"], "emails": ["firstname.lastname@aau.at"], "sections": [{"heading": "1 Introduction", "text": "Model-based diagnosis (MBD) is a widely applied approach to finding explanations, called diagnoses, for unexpected behavior of observed systems including hardware, software, knowledge bases, discrete event systems, feature models, user interfaces, etc. [Reiter, 1987; Dressler and Struss, 1996; Mateis et al., 2000; Pencole\u0301 and Cordier, 2005; Kalyanpur et al., 2007; Felfernig et al., 2009; White et al., 2010]. In case the provided observations are insufficient for successful fault localization, sequential diagnosis (SQD) methods collect additional information by generating a sequence of queries [de Kleer and Williams, 1987; Pietersma et al., 2005; Feldman et al., 2010; Siddiqi and Huang, 2011; Shchekotykhin et al., 2012].1 As query answering is often costly, the goal of SQD is to minimize the diagnostic cost, like time or manpower, required to achieve a diagnostic goal, e.g. a highly probable diagnosis. To this end, the cited SQD works minimize the number of queries by a one-step lookahead measure m, e.g. entropy [de Kleer and Williams, 1987], but do not optimize the query cost, such as the time required to perform measurements [Heckerman et al., 1995].\n1Following the arguments of [Pietersma et al., 2005] we do not consider non-MBD sequential methods [Pattipati and Alexandridis, 1990; Shakeri et al., 2000; Zuzek et al., 2000; Brodie et al., 2003].\nContributions. We present a novel query optimization method that is generally applicable to any MBD problem in the sense of [de Kleer and Williams, 1987; Reiter, 1987] and (1) defines a query as a set of first-order sentences and thus generalizes the measurement notion of [de Kleer and Williams, 1987; Reiter, 1987], (2) given a set of leading diagnoses [de Kleer and Williams, 1989], allows the two-dimensional optimization of the next query in terms of the expected number of subsequent queries (measure m) and query cost (measure c), (3) for an aptly refined (yet exponential) query search space, finds \u2013 without any reasoner calls \u2013 the globally optimal query wrt. measure c that globally optimizes measure m, (4) for the full query search space, finds \u2013 with a polynomial number of reasoner calls \u2013 the (under reasonable assumptions) globally optimal query wrt. m that includes, if possible, only \u201ccost-preferred\u201d sentences, such as those answerable automatically using built-in sensors, (5) guarantees the proposal of queries that discriminate between all leading diagnoses and that unambiguously identify the actual diagnosis.\nThe efficiency of our approach is possible by the recognition that the optimizations of m and c can be decoupled and by using logical monotonicity as well as the inherent (already inferred) information in the (\u2286-minimal) leading diagnoses. In particular, the method is inexpensive as it (a) avoids the generation and examination of unnecessary (non-discriminating) or duplicate query candidates, (b) actually computes only the single best query by its ability to estimate a query\u2019s quality without computing it, and (c) guarantees soundness and completeness wrt. an exponential query search space independently of the properties and output of a reasoner. Modern SQD methods like [de Kleer and Williams, 1987] and its derivatives [Feldman et al., 2010; Shchekotykhin et al., 2012; Rodler et al., 2013] do not meet all properties (a) \u2013 (c) and extensively call a reasoner for (precomputed) inferences while computing a query. Moreover, by the generality of our query notion, our method explores a more complex search space than [de Kleer and Williams, 1987; de Kleer and Raiman, 1993], thereby guaranteeing property (5) above."}, {"heading": "2 Preliminaries", "text": "Model-Based Diagnosis (MBD). In this section we recap on important MBD concepts and draw on definitions of [Re-\nar X\niv :1\n70 5.\n09 87\n9v 1\n[ cs\n.A I]\n2 8\nM ay\n2 01\n7\niter, 1987] to characterize a system and diagnoses. Notation (*): Let X be a collection of sets, then UX and IX denote the union and intersection of all elements of X , resp. K |= S for a set S is a shorthand for K |= s for all s \u2208 S.\nA system consists of a set of components COMPS and a system description SD where {\u00acAB(c) \u2192 beh(c) | c \u2208 COMPS} \u2286 SD. The first-order sentence beh(c) describes the normal behavior of c and AB is a distinguished abnormality predicate. Any behavior different from beh(c) implies that component c is at fault, i.e. AB(c) holds.2 Note, SD \u222a {\u00acAB(c) | c \u2208 COMPS} is required to be consistent.\nFrom the viewpoint of system diagnosis, evidence about the system behavior in terms of observations OBS, positive (P ) and negative (N ) measurements [Reiter, 1987; de Kleer and Williams, 1987; Felfernig et al., 2004] is of interest. Definition 1 (DPI). Let COMPS be a finite set of constants and SD, OBS, all p \u2208 P , all n \u2208 N be finite sets of consistent first-order sentences. Then (SD, COMPS, OBS,P ,N ) is a diagnosis problem instance (DPI). Definition 2. Let (SD, COMPS, OBS,P ,N ) be a DPI. Then SD\u2217[\u2206] := SD \u222a OBS \u222a UP \u222a {AB(c) | c \u2208 \u2206} \u222a {\u00acAB(c) | c \u2208 COMPS\\\u2206} denotes the behavior description of a system (SD, COMPS) given observations OBS, union of positive measurements UP as well as that all components \u2206 \u2286 COMPS are faulty and all components in COMPS \\\u2206 are healthy.\nThe solutions of a DPI, i.e. the hypotheses that explain a given (faulty) system behavior, are called diagnoses: Definition 3 (Diagnosis). \u2206 \u2286 COMPS is a diagnosis for the DPI (SD, COMPS, OBS,P ,N ) iff \u2206 is \u2286-minimal such that \u2022 SD\u2217[\u2206] is consistent (\u2206 explains OBS and P ), and \u2022 \u2200n \u2208 N : SD\u2217[\u2206] 6|= n (\u2206 explains N ).\nWe denote the set of all diagnoses for a DPI X by DX . A diagnosis for a DPI exists iff SD\u2217[COMPS] 6|= n for all n \u2208 N [Friedrich and Shchekotykhin, 2005, Prop. 1]. Example: Consider DPI Ex (Tab. 1). Using e.g. HS-TREE [Reiter, 1987] we get (denoting components ci by i) the set of all diagnoses DEx = {\u22061,\u22062,\u22063} = {{1, 2, 5}, {1, 3, 5}, {3, 4, 5}}. E.g. \u22062 \u2208 DEx due to Def. 3 and as SD\u2217[\u22062] = [SD \u222a {AB(c1), AB(c3), AB(c5)} \u222a {\u00acAB(c2),\u00acAB(c4)}] \u222a OBS \u222a UP = [{beh(c2), beh(c4)}] \u222a \u2205 \u222a \u2205 = {A\u2192 F,L\u2192 H} 6|= {A\u2192 H} = n1 \u2208 N and is consistent. Sequential Diagnosis (SQD). Given multiple diagnoses for a DPI, SQD techniques extend the sets P and N by asking a user or an oracle (e.g. an automated system) to perform additional measurements in order to rule out irrelevant diagnoses. In line with the works of [Settles, 2012;\n2We make the stationary health assumption [Feldman et al., 2010]: behavior of each c \u2208 COMPS is constant during diagnosis.\nShchekotykhin et al., 2012; Rodler, 2015] we call a proposed measurement query and define it very generally as a set of first-order sentences (this subsumes the notion of measurement e.g. in [de Kleer and Williams, 1987; Reiter, 1987]). The task of the oracle is to assess the correctness of the sentences in the query, thereby providing the required measurements. A query Q is true (t) if all sentences in Q are correct and false (f ) if at least one sentence in Q is incorrect.\nUsually only a small computationally feasible set of leading diagnoses D (e.g. minimum cardinality [Feldman et al., 2010] or most probable [de Kleer, 1991] ones) are exploited for measurement selection [de Kleer and Williams, 1989].\nAny sets of diagnoses and first-order sentences satisfy:\nProperty 1. Let X be a set of first-order sentences and D \u2286 DDPI for DPI = (SD, COMPS, OBS, P,N). Then X induces a partition PD(X) := \u2329 D+(X),D\u2212(X),D0(X) \u232a on D where D+(X) := {\u2206 \u2208 D | SD\u2217[\u2206] |= X}, D\u2212(X) := {\u2206 \u2208 D | \u2203s \u2208 N \u222a {\u22a5} : SD\u2217[\u2206] \u222a X |= s} and D0(X) = D \\ (D+(X) \u222aD\u2212(X)).\nFrom a query, we postulate two properties, it must for any outcome (1) invalidate at least one diagnosis (search space restriction) and (2) preserve the validity of at least one diagnosis (solution preservation). In fact, the sets D+(X) and D\u2212(X) are the key in deciding whether a set of sentences X is a query or not. Based on Property 1, we define:\nDefinition 4 (Query, q-Partition). Let DPI = (SD, COMPS, OBS, P,N), D \u2286 DDPI and Q be a set of first-order sentences with PD(Q) = \u2329 D+(Q),D\u2212(Q),D0(Q) \u232a . Then Q is a query for D iff Q 6= \u2205, D+(Q) 6= \u2205 and D\u2212(Q) 6= \u2205. The set of all queries for D is denoted by QD. PD(Q) is called the q-partition (QP) of Q iff Q is a query. Inversely, Q is called a query with (or: for) the QP PD(Q). Given a QP P, we sometimes denote its three entries in turn D+(P), D\u2212(P) and D0(P).\nD+(Q) and D\u2212(Q) denote those diagnoses in D consistent only with Q\u2019s positive and negative outcome, respectively, and D0(Q) those consistent with both outcomes. Since Q \u2208 QD implies that both D+(Q) and D\u2212(Q) are nonempty, clearly Q\u2019s outcomes both dismiss and preserve at least one diagnosis. Note, in many cases a query also invalidates some (unknown) non-leading diagnoses DDPI \\D.\nWe point out that the size of the set D0(Q) (the diagnoses that cannot be eliminated given any outcome) should be minimal, i.e. zero at best, for optimal diagnoses discrimination. The algorithm presented hereafter guarantees the computation of only Q\u2019s with D0(Q) = \u2205. For example, the methods of [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013] cannot ensure this important property. Example (cont\u2019d): Let D = DEx = {\u22061,\u22062,\u22063}. Then, Q = {F \u2192 H} is a query in QD. To verify this, let us consider its QP PD(Q) = \u3008{\u22061} , {\u22062,\u22063} , \u2205\u3009. Since both D+(Q) and D\u2212(Q) are non-empty, Q is in QD. \u22061 = {1, 2, 5} \u2208 D+(Q) holds as SD\u2217[\u22061] |= {beh(c3), beh(c4)} = {B \u2228 F \u2192 H,L\u2192 H} which in turn entails Q. On the other hand, e.g. \u22062 = {1, 3, 5} \u2208 D\u2212(Q) since SD\u2217[\u22062]\u222aQ |= {A\u2192 F,L\u2192 H,F \u2192 H} |= {A\u2192 H} = n1 \u2208 N . Hence, the outcome Q = t im-\nplies that diagnoses in D\u2212(Q) = {\u22062,\u22063} are invalidated, whereas Q = f causes the dismissal of D+(Q) = {\u22061}. Applicability and Diagnostic Accuracy. For any nonsingleton set of leading diagnoses, a discriminating query exists [Rodler, 2015, Sec. 7.6]:\nProperty 2. \u2200DPI : D \u2286 DDPI, |D| \u2265 2 =\u21d2 QD 6= \u2205. This has two implications: First, we need only precompute two diagnoses to generate a query and proceed with SQD. Despite its NP-completeness [Bylander et al., 1991], the generation of two (or more) diagnoses is practical in many realworld settings [de Kleer, 1991; Shchekotykhin et al., 2014], making query-based SQD commonly applicable. Second, the query-based approach guarantees perfect diagnostic accuracy, i.e. the unambiguous identification of the actual diagnosis."}, {"heading": "3 Query Optimization for Sequential MBD", "text": "Measurement Selection. As argued, the (q-)partition PD(Q) enables both the verification whether a candidate Q is indeed a query and an estimation of the impact Q\u2019s outcomes have in terms of diagnoses invalidation. And, given (component) fault probabilities, it enables to gauge the probability of observing a positive or negative query outcome [de Kleer and Williams, 1987]. Active learning query selection measures (QSMs) m : Q 7\u2192 m(Q) \u2208 R [Settles, 2012] use exactly these query properties characterized by the QP to assess how favorable a query is. They aim at selecting queries such that the expected number of queries until obtaining a deterministic diagnostic result is minimized, i.e. \u2211 \u2206\u2286COMPS p(\u2206)q#(\u2206) \u2192 min where p(\u2206) is the (a-priori) probability that {AB(c) | c \u2208 \u2206} \u222a {\u00acAB(c) | c \u2208 COMPS \\\u2206} is the actual system state wrt. component functionality and q#(\u2206) is the number of queries required, given the initial DPI, to derive that \u2206 must be the actual diagnosis. Solving this problem is known to be NPcomplete as it amounts to optimal binary decision tree construction [Hyafil and Rivest, 1976]. Hence we restrict our algorithm to the usage of QSMs that make a locally optimal query selection through a one-step lookahead. This has been shown to be optimal in many cases and nearly optimal in most cases [de Kleer et al., 1992]. Several different QSMs m such as split-in-half, entropy, or risk-optimization have been proposed, well studied and compared against each other [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013]. E.g. using entropy as QSM, m would be exactly the scoring function $() derived in [de Kleer and Williams, 1987]. Note, we assume w.l.o.g. that the optimal query wrt. any m is the one with minimal m(Q).\nBesides minimizing the number of queries in a diagnostic session, a further goal can be the minimization of the query cost (e.g. time, manpower). To this end, one can specify a query cost measure (QCM) c : Q 7\u2192 c(Q) \u2208 R+. Examples of QCMs are c\u03a3(Q) := \u2211k i=1 ci (prefer query with minimal overall cost, e.g. when ci represents time) or cmax(Q) := maxi\u2208{1,...,k} ci (prefer query with minimal maximal cost of a single measurement, e.g. when ci represents human cognitive load) where Q = {q1, . . . , qk} and ci is the cost of evaluating the truth of the first-order sentence\nAlgorithm 1 Optimized Query Computation Input: DPI := (SD, COMPS, OBS, P,N), D \u2286 DDPI, |D| \u2265 2, QSM m, QCM c,\ncomponent fault probabilities FP = {pi | pi = p(ci), ci \u2208 COMPS}, threshold tm (i.e. |m(Q) \u2212mopt| \u2264 tm \u21d2 Q regarded optimal; mopt := optimal value of m), sound and complete inference engine Inf , set ET of entailment types Output: an optimized query Q\u2217 \u2208 QD wrt. m, tm and c (cf. Theorems 2 and 3) 1: P\u2190 OPTIMIZEQPARTITION(D,FP,m, tm) . P1 2: Q\u2217 \u2190 OPTIMIZEQUERYFORQPARTITION(P,FP, c) . P2 3: if enhance = true then 4: Q\u2032 \u2190 EXPANDQUERY(DPI,P, Inf , ET ) . (optional) P3 5: Q\u2217 \u2190 OPTIMINIMIZEQUERY(Q\u2032,P,DPI,FP, Inf ) . (optional) P3 6: return Q\u2217\nqi. The QCM c|\u00b7|(Q) = |Q| is a special case of c\u03a3(Q) where ci = cj for all i, j is assumed. Now, the problem addressed in this work is:\nProblem 1. Given: DPI := (SD, COMPS, OBS, P,N), D \u2286 DDPI with |D| \u2265 2, QSM m, QCM c, query search space S \u2286 QD. Find: A query Q\u2217 satisfying Q\u2217 = arg minQ\u2208OptQ(m,S) c(Q) where OptQ(m,S) := {Q\u2032 | Q\u2032 = arg minQ\u2208S m(Q)}, i.e. Q\u2217 has minimal cost wrt. c among all queries in S that are optimal wrt. m.\nNote there can be multiple equally good queries Q\u2217 \u2208 QD. The Algorithm we propose to solve Problem 1 is given by Alg. 1. The described query computation procedure can be divided into three phases: P1 (line 1), P2 (line 2) and (optionally) P3 (lines 4-5). We next give the intuition and explanation of these phases. Phase P1. At this stage, we optimize the given QSM m \u2013 for now without regard to the QCM c, which is optimized later in P2. This decoupling of optimization steps is possible since the QSM value m(Q) of a query Q is only affected by the (unique) QP of Q and not by Q itself. On the contrary, the QCM value c(Q) is a function of Q only and not of Q\u2019s QP. Therefore, the search performed in P1 will consider only QPs.\nTo verify whether a given 3-partition of D is a QP, however, we need a query Q for this QP which lets us determine whether D+(Q) 6= \u2205 and D\u2212(Q) 6= \u2205 (cf. Def. 4). But: Property 3. For one query there is exactly one QP (immediate from Property 1). For one QP there might be an exponential number of queries (cf. Propos. 6 later).\nTherefore, we use the notion of a canonical query (CQ), which is one well-defined query representative for a QP. From a CQ, we postulate easiness of computation and exclusion of suboptimal QPs with D0 6= \u2205 (cf. Sec. 2). The key to realizing these postulations is:\nDefinition 5. X \u2286 COMPS, BEH[X] := {beh(ci) | ci \u2208 X}. The following property is immediate from Def. 2:\nProperty 4. X \u2286 COMPS =\u21d2 SD\u2217[X] |= BEH[COMPS\\X] From Property 1 and Def. 4 we can directly conclude:\nProperty 5. A query Q \u2208 QD is a subset of the common entailments of all KBs in the set {SD\u2217[\u2206] | \u2206 \u2208 D+(Q)}.\nUsing Properties 4 and 5, the idea is now to restrict the space of entailments of the SD\u2217[\u00b7] KBs to the behavioral descriptions beh(\u00b7) of the system components. That is, each CQ should be some query Q \u2286 BEH[COMPS]. This assumption along with Def. 4 and the \u2286-minimality of diagnoses yields:\nProposition 1. Any query Q \u2286 BEH[COMPS] in QD must include some formulas in BEH[UD], need not include any formulas in BEH[COMPS \\ UD], and must not include any formulas in BEH[ID]. (Please refer to (*) in Sec. 2 for notation.)\nMoreover, the deletion of any sentences in BEH[COMPS \\ UD] from Q does not alter the QP PD(Q).\nHence, we define: Definition 6. DiscD := BEH[UD]\\BEH[ID] = BEH[UD\\ID] the discrimination sentences wrt. D (i.e. those essential for discrimination between diagnoses in D).\nCQs can now be characterized as follows: Definition 7 (CQ). Let \u2205 \u2282 D+ \u2282 D. Then Qcan(D+) := BEH[COMPS\\UD+ ] \u2229DiscD is the canonical query (CQ) wrt. seed D+ if Qcan(D+) 6= \u2205. Else, Qcan(D+) is undefined.\nNote, BEH[COMPS \\ UD+ ] are exactly the common beh(\u00b7) entailments of {SD\u2217[\u2206] | \u2206 \u2208 D+} (cf. Property 5). The CQ extracts DiscD from these entailments, thereby removing all elements that do not affect the QP (cf. Propos. 1). By Defs. 4 and 7 and the \u2286-minimality of diagnoses, we get: Proposition 2. If Q is a CQ, then Q is a query.\nThe QP for a CQ is called canonical q-partition: Definition 8 (CQP). A QP P\u2032 for which a CQ Q exists with QP P\u2032, i.e. P(Q) = P\u2032, is called a canonical QP (CQP).\nSince a CQ is a subset of BEH[COMPS] and diagnoses are \u2286-minimal, we can derive: Proposition 3. Let P be a CQP. Then D0(P) = \u2205. Discussion: The restriction to CQs during P1 has some nice implications: (1) CQs can be generated by cheap set operations (no inference engine calls), (2) each CQ is a query in QD for sure (Propos. 2), no verification of its QP (as per Def. 4) required, thence no unnecessary (non-query) candidates generated, (3) automatic focus on favorable queries wrt. the QSM m (those with empty D0, Propos. 3), (4) no duplicate QPs generated as there is a one-to-one relationship between CQs and CQPs (Property 3, Def. 7), (5) the explored search space for QPs is not dependent on the particular (entailments) output by an inference engine.\nWe emphasize that all these properties do not hold for normal (i.e. non-canonical) queries and QPs. The overwhelming impact of this will be demonstrated in Sec. 4. Example (cont\u2019d): Given D as before, DiscD = BEH[UD \\ ID] = BEH[{1, 2, 3, 4, 5} \\ {5}] = BEH[{1, 2, 3, 4}]. Let us consider the seed D+ = {\u22061} = {{1, 2, 5}}. Then the CQ Q1 := Qcan(D+) = (BEH[{1, 2, 3, 4, 5} \\ {1, 2, 5}]) \u2229 BEH[{1, 2, 3, 4}] = BEH[{3, 4}]. The associated CQP is P1 = \u3008{\u22061} , {\u22062,\u22063} , \u2205\u3009. Note, \u2206 \u2208 D+(P1) (\u2206 \u2208 D\u2212(P1)) for a \u2206 \u2208 D iff BEH[COMPS \\\u2206] \u2287 (6\u2287)Q1. E.g. \u22063 \u2208 D\u2212(P1) since BEH[COMPS \\ \u22063] = BEH[{1, 2}] 6\u2287 BEH[{3, 4}] = Q1. That is, using CQs and CQPs, reasoning is traded for set operations and comparisons.\nThe seed D+ = {\u22061,\u22063} yields Q2 := Qcan(D+) = (BEH[{1, . . . , 5} \\ {1, . . . , 5}]) \u2229 BEH[{1, . . . , 4}] = \u2205, i.e. there is no CQ wrt. seed D+ and the partition \u3008{\u22061,\u22063} , {\u22062} , \u2205\u3009 with the seed D+ as first entry is no CQP (and also no QP).\nNow, having at hand the notion of a CQP, we describe the (heuristic) depth-first, local best-first (i.e. chooses only among best direct successors at each step) backtracking CQP search procedure performed in P1.\nA (heuristic) search problem [Russell and Norvig, 2010] is defined by the initial state, a successor function enumerating all direct neighbor states of a state, the step costs from a state to a successor state, the goal test to determine if a given state is a goal state or not, (and some heuristics to estimate the remaining effort towards a goal state).\nWe define the initial state \u3008D+,D\u2212,D0\u3009 as \u3008\u2205,D, \u2205\u3009. The idea is to transfer diagnoses step-by-step from D\u2212 to D+ to construct all CQPs systematically. The step costs are irrelevant, only the found QP as such counts. Heuristics derived from the QSM m (cf. e.g. [Shchekotykhin et al., 2012]) can be (optionally) integrated into the search to enable faster convergence to the optimum. A QP is a goal if it optimizes m up to the given threshold tm (cf. [de Kleer and Williams, 1987], see Alg. 1). In order to characterize a suitable successor function, we define a direct neighbor of a QP as follows: Definition 9. Let Pi := \u3008D+i ,D \u2212 i , \u2205\u3009, Pj := \u3008D + j ,D \u2212 j , \u2205\u3009 be partitions of D. Then, Pi 7\u2192 Pj is a minimal D+transformation from Pi to Pj iff Pj is a CQP, D+i \u2282 D + j and there is no CQP \u3008D+k ,D \u2212 k , \u2205\u3009 with D + i \u2282 D + k \u2282 D + j .\nA CQP P\u2032 is called a successor of a partition P iff P\u2032 results from P by a minimal D+-transformation.\nFor the initial state successors we get [Rodler, 2015, p. 98]: Proposition 4. The CQPs \u3008{\u2206} ,D \\ {\u2206} , \u2205\u3009 for \u2206 \u2208 D are exactly all successors of \u3008\u2205,D, \u2205\u3009.\nTo specify the successors of an intermediate CQP Pk in the search, we draw on diagnoses\u2019 traits: Definition 10. Let Pk = \u3008D+k ,D \u2212 k , \u2205\u3009 be a CQP and \u2206i \u2208 D\u2212k . Then the trait \u2206 (k) i of \u2206i is defined as BEH[\u2206i \\ UD+k ].\nThe relation \u223ck associating two diagnoses in D\u2212k iff their trait is equal is obviously an equivalence relation. Now, Defs. 7, 8 and 9 let us derive: Proposition 5. Let EC := {E1, . . . , Es} be the set of all equivalence classes wrt. \u223ck. Pk has successors iff s \u2265 2. In this case, all successors are given by \u2329 D+k \u222a E,D \u2212 k \\ E, \u2205\n\u232a where E \u2208 EC and E has a \u2286-minimal trait among all classes E\u2032 \u2208 EC .\nBy Def. 9 which demands both minimal changes between state and successor state and the latter to be a CQP, we have: Theorem 1. Usage of the successor function as given in Propos. 4 (for initial state) and Propos. 5 (for intermediate states) makes the search for CQPs sound and complete.\nSince it can be proven that P = \u3008D+,D\u2212, \u2205\u3009 is a CQP iff UD+ \u2282 UD and as there are at least |D| CQPs (Propos. 4): Proposition 6. Let CQPD denote the set of CQPs for diagnoses D with |D| \u2265 2. Then |CQPD| = |{UD+ | \u2205 \u2282 D+ \u2282 D, UD+ 6= UD}| \u2265 |D|.\nWhether QPs \u3008D+,D\u2212, \u2205\u3009 exist which are no CQPs is not yet clarified, but both theoretical and empirical evidence indicate the negative. E.g., an analysis of \u2248 900 000 QPs we\nran for different diagnoses D and DPIs showed that all QPs were indeed CQPs. And, in all evaluated cases (see Sec. 4) optimal CQPs wrt. all QSMs m given in diagnosis literature [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013] were found. Hence:\nConjecture 1. Let (C)QPD denote the sets of (C)QPs (all with D0 = \u2205) for diagnoses D. Then CQPD = QPD.\nExample (cont\u2019d): Reconsider the CQP P1 = \u3008{\u22061} , {\u22062, \u22063}, \u2205\u3009. The traits are \u2206(1)2 = BEH[{1, 3, 5} \\ {1, 2, 5}] = BEH[{3}] and \u2206(1)3 = BEH[{3, 4}], representing two equivalence classes wrt. \u223c1. There is only one class with \u2286- minimal trait, i.e. {\u22062}. Hence, there is just a single successor CQP P2 = \u3008{\u22061,\u22062}, {\u22063}, \u2205\u3009 of P1. Recall, we argued that \u3008{\u22061,\u22063}, {\u22062}, \u2205\u3009 is indeed no CQP. By Propos. 6, there are |{{1, 2, 5} , {1, 3, 5} , {3, 4, 5} , {1, 2, 3, 5}, {1, 3, 4, 5}}| = 5 different CQPs wrt. D. Note, Conject. 1 is true here, i.e. the CQPD search is complete wrt. QPD. Phase P2. Phase P1 returns an optimal (C)QP Pk wrt. the QSM m. Property 3 indicates that there might be still a large search space for an optimal query wrt. the QCM c for this QP. The task in P2 is to find such query efficiently.\nFrom Pk, we can obtain the associated CQ Qk (as per Def. 7). However, usually a least requirement of any QCM c is i.a. the \u2286-minimality of a query to avoid unnecessary measurements. To this end, let Tr(Pk) denote the set of all \u2286-minimal traits wrt. \u223ck. Given a collection of sets X = {x1, . . . , xn}, a set H \u2286 UX is a hitting set (HS) of X iff H \u2229 xi 6= \u2205 for all xi \u2208 X . Then: Proposition 7. Q \u2286 DiscD is a \u2286-minimal query with QP Pk iff Q = H for some \u2286-minimal HS H of Tr(Pk).\nHence, all \u2286-minimal reductions of CQ Qk under preservation of the (already fixed and optimal) QP Pk can be computed e.g. using the classical HS-TREE [Reiter, 1987]. However, there is a crucial difference to standard application scenarios of HS-TREE, namely the fact that all sets to label the tree nodes (i.e. the \u2286-minimal traits) are readily available (without further computations). Consequently, the construction of the tree runs swiftly, as our evaluation will confirm. Note also, in principle we only require a single minimal hitting set, i.e. query. Moreover, HS-TREE can be used as uniform-cost (UC) search (cf. e.g. [Rodler, 2015, Chap. 4]), incorporating the QCM c to find queries in best-first order wrt. c. In fact, all QCMs (i.e. c\u03a3, cmax, c|\u00b7|) discussed above can be optimized using UC HS-TREE. In case some QCM c is not suitable for UC search, a brute force HS-TREE search over all \u2286-minimal queries will be practical as well (no expensive operations involved). Hence, P1 and P2 provide a solution to Problem 1 without a single inference engine call.\nTheorem 2. P1 and P2 compute a solution Q\u2217 to Problem 1 where S := {BEH[X] | X \u2286 COMPS}.\nExample (cont\u2019d): Recall the CQP P1 and let the QCM be c := c|\u00b7|. Then Tr(P1) = {BEH[{3}]}, i.e. by Propos. 7 there is a single c-optimal query BEH[{3}] for P1, a proper subset of the CQ BEH[{3, 4}] for P1. Considering the CQP P3 := \u3008{\u22062} , {\u22061,\u22063} , \u2205\u3009, Tr(P3) = {BEH[{2}], BEH[{4}]} and\nthus we have (Propos. 7) a single c-optimal query BEH[{2, 4}] which happens to be equal to the CQ for P3. Phase P3. The query Q\u2217 optimized along two dimensions (# of queries and cost per query) output by P2 can be directly proposed as next measurement. A BEH[\u00b7] query like Q\u2217 would correspond to a direct examination of one or more system components, e.g. to ping servers in a distributed system [Brodie et al., 2003], to test gates using a voltmeter in circuits [de Kleer and Williams, 1987] or to ask the stakeholders of a (software/configuration/KB) system whether specified code lines/constraints/sentences are correct [Wotawa, 2002; Felfernig et al., 2004; Friedrich and Shchekotykhin, 2005].\nAlternatively, the already optimal CQP Pk returned by P1 can be regarded as intermediate solution to building a solution query to Problem 1 with full search space S = QD. To this end, first, using the CQ Qk of Pk, a (finite) set Qexp of firstorder sentences of types ET (e.g. atoms or sentences of type A\u2192 B) are computed. Qexp must meet: (1) SD\u2217[X] |= Qexp where X is some (superset of a) diagnosis such that Qk \u2286 SD\u2217[X] (entailed by a consistent system behavior KB), (2) no qi \u2208 Qexp is an entailment of SD\u2217[X] \\ Qk (logical dependence on Qk, no irrelevant sentences) and (3) the expansion of Qk by Qexp does not alter the (already fixed and optimal) q-partition Pk, i.e. Pk = P(Qk \u222aQexp). Proposition 8. Let EntET (X) be a monotonic consequence operator realized by some inference engine that computes a finite set of entailments of types ET of a KB X . Postulations (1) \u2013 (3) are satisfied if Qexp := EntET (SD\u2217[UD] \u222a Qk) \\ EntET (SD \u2217[UD]).\nFinally, the expanded query Q\u2032 := Qk \u222aQexp can be minimized to get a \u2286-minimal subset of it under preservation of the associated QP Pk. For this purpose, one can use a variant of the polynomial divide-and-conquer method QUICKXPLAIN [Junker, 2004], e.g. the MINQ procedure given in [Rodler, 2015, p.111 ff.]. However, we propose to alter the input to MINQ as follows: Assume that Q\u2032 can be partitioned into a subset of cost-preferred sentences Q\u2032C+ (e.g. those measurements executable automatically by available built-in sensors) and cost-dispreferred ones Q\u2032C\u2212 = Q\n\u2032 \\ Q\u2032C+ (e.g. manual measurements). Let the input to MINQ be the list [Q\u2032C+, asc(Q \u2032 C\u2212)] (reordering of Q\n\u2032) where asc(Q\u2032C\u2212) means that Q\u2032C\u2212 is sorted in ascending order by sentence cost. Then: Proposition 9. MINQ with input [Q\u2032C+, asc(Q\u2032C\u2212)] returns a \u2286-minimal query Q\u2217 \u2286 Q\u2032 such that P(Q\u2217) = Pk. Further, if such a query comprising only Q\u2032C+ (and no Q \u2032 C\u2212) sentences exists, then Q\u2217 \u2286 Q\u2032C+. Else, Q\u2217 optimizes the QCM cmax (cf. page 3) among all \u2286-minimal subsets of Q\u2032 with QP Pk.\nNote, phase P3, i.e. query expansion (Propos. 8) together with optimized minimization (Propos. 9), requires only a polynomial number of inference engine calls [Junker, 2004]. Theorem 3. Let Conject. 1 hold and the QCM be cmax (cf. page 3). Then P3, using the QP output by P1 and Propos. 8 and 9, solves Problem 1 with full search space S = QD.\nExample (cont\u2019d): Assume the QP P1 is returned by P1. Let the cost ci of a sentence qi be the number of literals in its clausal form. As shown before, the CQ of P1 is Q1 := BEH[{3, 4}] = {B \u2228 F \u2192 H,L \u2192 H}. Using Propos. 8\nwith ET set to \u201cdefinite clauses with singleton body\u201d, we get Qexp = EntET (Q1)\\EntET (\u2205) = {B \u2192 H,F \u2192 H,L\u2192 H}. So, Q\u2032 = {B \u2192 H,F \u2192 H,L \u2192 H,B \u2228 F \u2192 H}. Suppose ET defines exactly the cost-preferred sentences, i.e. Q\u2032c+ = Qexp. Running MINQ with input [Qexp, {B \u2228 F \u2192 H}] yields Q\u2217 = {F \u2192 H}, a query that includes only cost-preferred elements (cf. Propos. 9). It is easily verified by means of Property 1 that Q\u2217 has still the QP P1."}, {"heading": "4 Evaluation", "text": "To evaluate our method, we used real-world inconsistent knowledge-based (KB) systems as (1) they pose a hard challenge for query selection methods due to the implicit nature of the possible queries (must be derived by inference; not directly given such as wires in a circuit), (2) any MBD system in the sense of [Reiter, 1987] is described by a KB, (3) the type of the underlying system is irrelevant to our method, only its size and (reasoning) complexity \u2013 for the optional phase P3 \u2013 and the DPI structure, e.g. size, # or probability of diagnoses \u2013 for phases P1, P2 \u2013 are critical. To account for this, we used systems (see Tab. 2, col. 1) of different size (# of components, i.e. logical axioms in the KB, see Tab. 2, col. 2), complexity (see Tab. 2, col. 3) and DPI structure (see Tab. 2, col. 4).\nIn our experiments, for each faulty system\u2019s DPI Sys in Tab. 2 and each n \u2208 {10, 20, . . . , 80}, we randomly generated 5 different D \u2208 DSys with |D| = n using INV-HS-TREE [Shchekotykhin et al., 2014] with randomly shuffled input. Each D \u2208 D was assigned a uniformly random probability.\nFor each of these 5 D-sets, we used (a) entropy (ENT) [de Kleer and Williams, 1987] and (b) split-in-half (SPL) [Shchekotykhin et al., 2012] as QSM m and c|\u00b7| (cf. page 3) as QCM c, and then ran phases (i) P1+P2 and (ii) P3 to compute an optimized query as per Theorems 2 and 3, respectively. We specified the optimality threshold tm as 0.01 in (a) and 0 in (b), cf. Alg. 1. The search in P1 (cf. Sec. 3) used the greedy heuristic discussed in [Shchekotykhin et al., 2012, p. 11]. In P3 simple definite clauses of the form \u2200x(A(x) \u2192 B(x)) were considered cost-preferred (cf. last Example above). Experimental Results are shown in Fig. 1. Times for SPL are omitted for clarity as they were quasi the same as for ENT. The dark gray area shows the # of CQPs addressed by P1, and the light gray line the time for P1+P2 using ENT. It is evident that P1+P2 always finished in less than 0.03 sec outputting an optimized query wrt. m and c. Note, albeit P1+P2 solve Prob. 1 for a restricted search space S (cf. Theor. 2), |CQPD|, a fraction of |S|, already averaged to e.g. 300 (over |D| = 10 cases) and > 530 000 (|D| = 80). That |S| is sufficiently large for all sizes |D| is also substantiated by the fact that in each single run an optimal query wrt. the very small tm ( 110 of tm used in [Shchekotykhin et al., 2012]) was found in S. Also, a brute force (BF) search (dashed line) iterating over all possible CQPs is feasible in most cases \u2013 finishing within 1 min for all runs (up to search space sizes > 120 000) except the |D| \u2265 30 cases for system CE (where up to 3 million CQPs were computed). This extreme speed is possible due to the complete avoidance of costly reasoner calls. The optional further query enhancement in P3 using a reasoner [Sirin et al., 2007] always finished within 4 sec and returned the globally\noptimal query wrt. QCM cmax (Theor. 3). The median output query size after P1+P2+P3 was 3.4. In additional scalability tests using |D| = 500 for the large enough DPIs (CC, CE, T, E) P1+P2 always ended in < 0.6 sec, P3 in < 40 sec.\nWe also simulated P1 by a method using non-canonical QPs, thus relying on a reasoner. For no DPI in Tab. 2 a result for |D| > 15 could be found in\u2264 1 h. And, the quality of the returned QP (if any) wrt. m was never better than for P1."}, {"heading": "5 Conclusion", "text": "We present a search that addresses the optimal measurement (query) selection problem for sequential diagnosis and is applicable to any model-based diagnosis problem conforming to [de Kleer and Williams, 1987; Reiter, 1987]. In particular, we allow a query to be optimized along two dimensions, i.e. number of queries and cost per query. We show that the optimizations of these properties can be decoupled and considered in sequence. For a suitably restricted (still exponential) query search space (very close approximations of) global optima wrt. given query quality measures are found without any calls to an inference engine in negligible time for diagnosis problems of any size and complexity (given the precomputation of \u2265 2 diagnoses is feasible). E.g. query search spaces of size up to 3 million can be handled instantaneously (< 0.1 sec). For the full search space, under reasonable assumptions, the globally optimal query wrt. a cost-preference measure can be found within 4 sec for up to 80 leading diagnoses."}], "references": [{"title": "and P Patel-Schneider", "author": ["F Baader", "D Calvanese", "D McGuinness", "D Nardi"], "venue": "(eds.). The Description Logic Handbook. Cambridge University Press", "citeRegEx": "Baader et al.. 2003", "shortCiteRegEx": null, "year": 2003}, {"title": "Active probing strategies for problem diagnosis in distributed systems", "author": ["M Brodie", "I Rish", "S Ma", "N Odintsova"], "venue": "IJCAI, pp. 1337\u20131338", "citeRegEx": "Brodie et al.. 2003", "shortCiteRegEx": null, "year": 2003}, {"title": "The computational complexity of abduction", "author": ["T Bylander", "D Allemang", "M Tanner", "J Josephson"], "venue": "Artif. Intell., 49:25\u201360", "citeRegEx": "Bylander et al.. 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "In Working Notes of the 4th DX Workshop", "author": ["J de Kleer", "O Raiman. How to diagnose well with very little information"], "venue": "pp. 160\u2013165,", "citeRegEx": "de Kleer and Raiman. 1993", "shortCiteRegEx": null, "year": 1993}, {"title": "Artif", "author": ["J de Kleer", "B C Williams. Diagnosing multiple faults"], "venue": "Intell., 32:97\u2013130,", "citeRegEx": "de Kleer and Williams. 1987", "shortCiteRegEx": null, "year": 1987}, {"title": "pp", "author": ["J de Kleer", "B C Williams. Diagnosis with behavioral modes. In IJCAI"], "venue": "1324\u2013 1330,", "citeRegEx": "de Kleer and Williams. 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "pp", "author": ["J de Kleer", "O Raiman", "M Shirley. One step lookahead is pretty good. In Readings in modelbased diagnosis"], "venue": "138\u2013142. Morgan Kaufmann,", "citeRegEx": "de Kleer et al.. 1992", "shortCiteRegEx": null, "year": 1992}, {"title": "pp", "author": ["J de Kleer. Focusing on probable diagnoses. In AAAI"], "venue": "842\u2013848,", "citeRegEx": "de Kleer. 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "The consistency-based approach to automated diagnosis of devices", "author": ["O Dressler", "P Struss"], "venue": "Principles of Knowl. Repr., pp. 269\u2013314", "citeRegEx": "Dressler and Struss. 1996", "shortCiteRegEx": null, "year": 1996}, {"title": "and A J C van Gemund", "author": ["A Feldman", "G M Provan"], "venue": "A model-based active testing approach to sequential diagnosis. JAIR, 39:301\u2013334", "citeRegEx": "Feldman et al.. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Consistency-based diagnosis of configuration KBs", "author": ["A Felfernig", "G Friedrich", "D Jannach", "M Stumptner"], "venue": "Artif. Intell., 152(2):213\u2013234", "citeRegEx": "Felfernig et al.. 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "Automated debugging of recommender user interface descriptions", "author": ["A Felfernig", "G Friedrich", "K Isak", "K Shchekotykhin", "E Teppan", "D Jannach"], "venue": "Applied Intell., 31(1):1\u201314", "citeRegEx": "Felfernig et al.. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "A General Diagnosis Method for Ontologies", "author": ["G Friedrich", "K Shchekotykhin"], "venue": "ISWC, pp. 232\u2013246", "citeRegEx": "Friedrich and Shchekotykhin. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Decision-theoretic troubleshooting", "author": ["D Heckerman", "J S Breese", "K Rommelse"], "venue": "Communications of the ACM, 38(3):49\u201357", "citeRegEx": "Heckerman et al.. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "Constructing optimal binary decision trees is NP-complete", "author": ["L Hyafil", "R L Rivest"], "venue": "Information processing letters, 5(1):15\u201317", "citeRegEx": "Hyafil and Rivest. 1976", "shortCiteRegEx": null, "year": 1976}, {"title": "QUICKXPLAIN: Preferred Explanations and Relaxations for Over-Constrained Problems", "author": ["U Junker"], "venue": "AAAI, pp. 167\u2013172", "citeRegEx": "Junker. 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "Finding all Justifications of OWL DL Entailments", "author": ["A Kalyanpur", "B Parsia", "M Horridge", "E Sirin"], "venue": "ISWC, pp. 267\u2013280", "citeRegEx": "Kalyanpur et al.. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "Model-Based Debugging of Java Programs", "author": ["C Mateis", "M Stumptner", "D Wieland", "F Wotawa"], "venue": "AADEBUG\u201900", "citeRegEx": "Mateis et al.. 2000", "shortCiteRegEx": null, "year": 2000}, {"title": "Application of heuristic search and information theory to sequential fault diagnosis", "author": ["K R Pattipati", "M G Alexandridis"], "venue": "IEEE Trans. on Systems, Man, and Cybernetics, 20(4):872\u2013887", "citeRegEx": "Pattipati and Alexandridis. 1990", "shortCiteRegEx": null, "year": 1990}, {"title": "A formal framework for the decentralised diagnosis of large scale discrete event systems and its application to telecommunication networks", "author": ["Y Pencol\u00e9", "M-O Cordier"], "venue": "Artif. Intell., 164(1):121\u2013170", "citeRegEx": "Pencol\u00e9 and Cordier. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "A J C van Gemund", "author": ["J Pietersma"], "venue": "and A Bos. A model-based approach to sequential fault diagnosis. In IEEE Autotestcon, pp. 621\u2013627. IEEE", "citeRegEx": "Pietersma et al.. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "A Theory of Diagnosis from First Principles", "author": ["R Reiter"], "venue": "Artif. Intell., 32(1):57\u201395", "citeRegEx": "Reiter. 1987", "shortCiteRegEx": null, "year": 1987}, {"title": "RIO: Minimizing User Interaction in Ontology Debugging", "author": ["P Rodler", "K Shchekotykhin", "P Fleiss", "G Friedrich"], "venue": "RR, pp. 153\u2013167", "citeRegEx": "Rodler et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "PhD thesis", "author": ["Patrick Rodler. Interactive Debugging of Knowledge Bases"], "venue": "Alpen-Adria Universit\u00e4t Klagenfurt,", "citeRegEx": "Rodler. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Artif", "author": ["S J Russell", "P Norvig"], "venue": "Intell.: A Modern Approach. Pearson Education", "citeRegEx": "Russell and Norvig. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Active Learning", "author": ["B Settles"], "venue": "Morgan and Claypool Publishers", "citeRegEx": "Settles. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Sequential testing algorithms for multiple fault diagnosis", "author": ["M Shakeri", "V Raghavan", "K R Pattipati", "A Patterson-Hine"], "venue": "IEEE Trans. on Systems, Man, and Cybernetics, Part A, 30(1):1\u201314", "citeRegEx": "Shakeri et al.. 2000", "shortCiteRegEx": null, "year": 2000}, {"title": "Interactive Ontology Debugging: Two Query Strategies for Efficient Fault Localization", "author": ["K Shchekotykhin", "G Friedrich", "P Fleiss", "P Rodler"], "venue": "J. of Web Semantics, 12-13:88\u2013103", "citeRegEx": "Shchekotykhin et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Sequential diagnosis of high cardinality faults in knowledge-bases by direct diagnosis generation", "author": ["K Shchekotykhin", "G Friedrich", "P Rodler", "P Fleiss"], "venue": "ECAI, pp. 813\u2013818", "citeRegEx": "Shchekotykhin et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Sequential diagnosis by abstraction", "author": ["S Siddiqi", "J Huang"], "venue": "JAIR, 41:329\u2013365", "citeRegEx": "Siddiqi and Huang. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Pellet: A practical OWL-DL reasoner", "author": ["E Sirin", "B Parsia", "B Cuenca Grau", "A Kalyanpur", "Y Katz"], "venue": "J. of Web Semantics, 5(2):51\u201353", "citeRegEx": "Sirin et al.. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "Debugging OWL Ontologies: Reality Check", "author": ["H Stuckenschmidt"], "venue": "EON, pp. 1\u201312", "citeRegEx": "Stuckenschmidt. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "Debugging functional programs", "author": ["M Stumptner", "F Wotawa"], "venue": "IJCAI, pp. 1074\u20131079", "citeRegEx": "Stumptner and Wotawa. 1999", "shortCiteRegEx": null, "year": 1999}, {"title": "Automated diagnosis of feature model configurations", "author": ["J White", "D Benavides", "D C Schmidt", "P Trinidad", "B Dougherty", "A R Cort\u00e9s"], "venue": "J. Syst. Software, 83(7):1094\u20131107", "citeRegEx": "White et al.. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "On the relationship between model-based debugging and program slicing", "author": ["F Wotawa"], "venue": "Artif. Intell., 135(1-2):125\u2013143", "citeRegEx": "Wotawa. 2002", "shortCiteRegEx": null, "year": 2002}, {"title": "Sequential diagnosis tool", "author": ["A Zuzek", "A Biasizzo", "F Novak"], "venue": "MICPRO, 24(4):191\u2013197", "citeRegEx": "Zuzek et al.. 2000", "shortCiteRegEx": null, "year": 2000}], "referenceMentions": [{"referenceID": 21, "context": "[Reiter, 1987; Dressler and Struss, 1996; Mateis et al., 2000; Pencol\u00e9 and Cordier, 2005; Kalyanpur et al., 2007; Felfernig et al., 2009; White et al., 2010].", "startOffset": 0, "endOffset": 157}, {"referenceID": 8, "context": "[Reiter, 1987; Dressler and Struss, 1996; Mateis et al., 2000; Pencol\u00e9 and Cordier, 2005; Kalyanpur et al., 2007; Felfernig et al., 2009; White et al., 2010].", "startOffset": 0, "endOffset": 157}, {"referenceID": 17, "context": "[Reiter, 1987; Dressler and Struss, 1996; Mateis et al., 2000; Pencol\u00e9 and Cordier, 2005; Kalyanpur et al., 2007; Felfernig et al., 2009; White et al., 2010].", "startOffset": 0, "endOffset": 157}, {"referenceID": 19, "context": "[Reiter, 1987; Dressler and Struss, 1996; Mateis et al., 2000; Pencol\u00e9 and Cordier, 2005; Kalyanpur et al., 2007; Felfernig et al., 2009; White et al., 2010].", "startOffset": 0, "endOffset": 157}, {"referenceID": 16, "context": "[Reiter, 1987; Dressler and Struss, 1996; Mateis et al., 2000; Pencol\u00e9 and Cordier, 2005; Kalyanpur et al., 2007; Felfernig et al., 2009; White et al., 2010].", "startOffset": 0, "endOffset": 157}, {"referenceID": 11, "context": "[Reiter, 1987; Dressler and Struss, 1996; Mateis et al., 2000; Pencol\u00e9 and Cordier, 2005; Kalyanpur et al., 2007; Felfernig et al., 2009; White et al., 2010].", "startOffset": 0, "endOffset": 157}, {"referenceID": 33, "context": "[Reiter, 1987; Dressler and Struss, 1996; Mateis et al., 2000; Pencol\u00e9 and Cordier, 2005; Kalyanpur et al., 2007; Felfernig et al., 2009; White et al., 2010].", "startOffset": 0, "endOffset": 157}, {"referenceID": 4, "context": "In case the provided observations are insufficient for successful fault localization, sequential diagnosis (SQD) methods collect additional information by generating a sequence of queries [de Kleer and Williams, 1987; Pietersma et al., 2005; Feldman et al., 2010; Siddiqi and Huang, 2011; Shchekotykhin et al., 2012].", "startOffset": 188, "endOffset": 316}, {"referenceID": 20, "context": "In case the provided observations are insufficient for successful fault localization, sequential diagnosis (SQD) methods collect additional information by generating a sequence of queries [de Kleer and Williams, 1987; Pietersma et al., 2005; Feldman et al., 2010; Siddiqi and Huang, 2011; Shchekotykhin et al., 2012].", "startOffset": 188, "endOffset": 316}, {"referenceID": 9, "context": "In case the provided observations are insufficient for successful fault localization, sequential diagnosis (SQD) methods collect additional information by generating a sequence of queries [de Kleer and Williams, 1987; Pietersma et al., 2005; Feldman et al., 2010; Siddiqi and Huang, 2011; Shchekotykhin et al., 2012].", "startOffset": 188, "endOffset": 316}, {"referenceID": 29, "context": "In case the provided observations are insufficient for successful fault localization, sequential diagnosis (SQD) methods collect additional information by generating a sequence of queries [de Kleer and Williams, 1987; Pietersma et al., 2005; Feldman et al., 2010; Siddiqi and Huang, 2011; Shchekotykhin et al., 2012].", "startOffset": 188, "endOffset": 316}, {"referenceID": 27, "context": "In case the provided observations are insufficient for successful fault localization, sequential diagnosis (SQD) methods collect additional information by generating a sequence of queries [de Kleer and Williams, 1987; Pietersma et al., 2005; Feldman et al., 2010; Siddiqi and Huang, 2011; Shchekotykhin et al., 2012].", "startOffset": 188, "endOffset": 316}, {"referenceID": 4, "context": "entropy [de Kleer and Williams, 1987], but do not optimize the query cost, such as the time required to perform measurements [Heckerman et al.", "startOffset": 8, "endOffset": 37}, {"referenceID": 13, "context": "entropy [de Kleer and Williams, 1987], but do not optimize the query cost, such as the time required to perform measurements [Heckerman et al., 1995].", "startOffset": 125, "endOffset": 149}, {"referenceID": 20, "context": "Following the arguments of [Pietersma et al., 2005] we do not consider non-MBD sequential methods [Pattipati and Alexandridis, 1990; Shakeri et al.", "startOffset": 27, "endOffset": 51}, {"referenceID": 18, "context": ", 2005] we do not consider non-MBD sequential methods [Pattipati and Alexandridis, 1990; Shakeri et al., 2000; Zuzek et al., 2000; Brodie et al., 2003].", "startOffset": 54, "endOffset": 151}, {"referenceID": 26, "context": ", 2005] we do not consider non-MBD sequential methods [Pattipati and Alexandridis, 1990; Shakeri et al., 2000; Zuzek et al., 2000; Brodie et al., 2003].", "startOffset": 54, "endOffset": 151}, {"referenceID": 35, "context": ", 2005] we do not consider non-MBD sequential methods [Pattipati and Alexandridis, 1990; Shakeri et al., 2000; Zuzek et al., 2000; Brodie et al., 2003].", "startOffset": 54, "endOffset": 151}, {"referenceID": 1, "context": ", 2005] we do not consider non-MBD sequential methods [Pattipati and Alexandridis, 1990; Shakeri et al., 2000; Zuzek et al., 2000; Brodie et al., 2003].", "startOffset": 54, "endOffset": 151}, {"referenceID": 4, "context": "We present a novel query optimization method that is generally applicable to any MBD problem in the sense of [de Kleer and Williams, 1987; Reiter, 1987] and (1) defines a query as a set of first-order sentences and thus generalizes the measurement notion of [de Kleer and Williams, 1987; Reiter, 1987], (2) given a set of leading diagnoses [de Kleer and Williams, 1989], allows the two-dimensional optimization of the next query in terms of the expected number of subsequent queries (measure m) and query cost (measure c), (3) for an aptly refined (yet exponential) query search space, finds \u2013 without any reasoner calls \u2013 the globally optimal query wrt.", "startOffset": 109, "endOffset": 152}, {"referenceID": 21, "context": "We present a novel query optimization method that is generally applicable to any MBD problem in the sense of [de Kleer and Williams, 1987; Reiter, 1987] and (1) defines a query as a set of first-order sentences and thus generalizes the measurement notion of [de Kleer and Williams, 1987; Reiter, 1987], (2) given a set of leading diagnoses [de Kleer and Williams, 1989], allows the two-dimensional optimization of the next query in terms of the expected number of subsequent queries (measure m) and query cost (measure c), (3) for an aptly refined (yet exponential) query search space, finds \u2013 without any reasoner calls \u2013 the globally optimal query wrt.", "startOffset": 109, "endOffset": 152}, {"referenceID": 4, "context": "We present a novel query optimization method that is generally applicable to any MBD problem in the sense of [de Kleer and Williams, 1987; Reiter, 1987] and (1) defines a query as a set of first-order sentences and thus generalizes the measurement notion of [de Kleer and Williams, 1987; Reiter, 1987], (2) given a set of leading diagnoses [de Kleer and Williams, 1989], allows the two-dimensional optimization of the next query in terms of the expected number of subsequent queries (measure m) and query cost (measure c), (3) for an aptly refined (yet exponential) query search space, finds \u2013 without any reasoner calls \u2013 the globally optimal query wrt.", "startOffset": 258, "endOffset": 301}, {"referenceID": 21, "context": "We present a novel query optimization method that is generally applicable to any MBD problem in the sense of [de Kleer and Williams, 1987; Reiter, 1987] and (1) defines a query as a set of first-order sentences and thus generalizes the measurement notion of [de Kleer and Williams, 1987; Reiter, 1987], (2) given a set of leading diagnoses [de Kleer and Williams, 1989], allows the two-dimensional optimization of the next query in terms of the expected number of subsequent queries (measure m) and query cost (measure c), (3) for an aptly refined (yet exponential) query search space, finds \u2013 without any reasoner calls \u2013 the globally optimal query wrt.", "startOffset": 258, "endOffset": 301}, {"referenceID": 5, "context": "We present a novel query optimization method that is generally applicable to any MBD problem in the sense of [de Kleer and Williams, 1987; Reiter, 1987] and (1) defines a query as a set of first-order sentences and thus generalizes the measurement notion of [de Kleer and Williams, 1987; Reiter, 1987], (2) given a set of leading diagnoses [de Kleer and Williams, 1989], allows the two-dimensional optimization of the next query in terms of the expected number of subsequent queries (measure m) and query cost (measure c), (3) for an aptly refined (yet exponential) query search space, finds \u2013 without any reasoner calls \u2013 the globally optimal query wrt.", "startOffset": 340, "endOffset": 369}, {"referenceID": 4, "context": "Modern SQD methods like [de Kleer and Williams, 1987] and its derivatives [Feldman et al.", "startOffset": 24, "endOffset": 53}, {"referenceID": 9, "context": "Modern SQD methods like [de Kleer and Williams, 1987] and its derivatives [Feldman et al., 2010; Shchekotykhin et al., 2012; Rodler et al., 2013] do not meet all properties (a) \u2013 (c) and extensively call a reasoner for (precomputed) inferences while computing a query.", "startOffset": 74, "endOffset": 145}, {"referenceID": 27, "context": "Modern SQD methods like [de Kleer and Williams, 1987] and its derivatives [Feldman et al., 2010; Shchekotykhin et al., 2012; Rodler et al., 2013] do not meet all properties (a) \u2013 (c) and extensively call a reasoner for (precomputed) inferences while computing a query.", "startOffset": 74, "endOffset": 145}, {"referenceID": 22, "context": "Modern SQD methods like [de Kleer and Williams, 1987] and its derivatives [Feldman et al., 2010; Shchekotykhin et al., 2012; Rodler et al., 2013] do not meet all properties (a) \u2013 (c) and extensively call a reasoner for (precomputed) inferences while computing a query.", "startOffset": 74, "endOffset": 145}, {"referenceID": 4, "context": "Moreover, by the generality of our query notion, our method explores a more complex search space than [de Kleer and Williams, 1987; de Kleer and Raiman, 1993], thereby guaranteeing property (5) above.", "startOffset": 102, "endOffset": 158}, {"referenceID": 3, "context": "Moreover, by the generality of our query notion, our method explores a more complex search space than [de Kleer and Williams, 1987; de Kleer and Raiman, 1993], thereby guaranteeing property (5) above.", "startOffset": 102, "endOffset": 158}, {"referenceID": 21, "context": "From the viewpoint of system diagnosis, evidence about the system behavior in terms of observations OBS, positive (P ) and negative (N ) measurements [Reiter, 1987; de Kleer and Williams, 1987; Felfernig et al., 2004] is of interest.", "startOffset": 150, "endOffset": 217}, {"referenceID": 4, "context": "From the viewpoint of system diagnosis, evidence about the system behavior in terms of observations OBS, positive (P ) and negative (N ) measurements [Reiter, 1987; de Kleer and Williams, 1987; Felfernig et al., 2004] is of interest.", "startOffset": 150, "endOffset": 217}, {"referenceID": 10, "context": "From the viewpoint of system diagnosis, evidence about the system behavior in terms of observations OBS, positive (P ) and negative (N ) measurements [Reiter, 1987; de Kleer and Williams, 1987; Felfernig et al., 2004] is of interest.", "startOffset": 150, "endOffset": 217}, {"referenceID": 21, "context": "HS-TREE [Reiter, 1987] we get (denoting components ci by i) the set of all diagnoses DEx = {\u22061,\u22062,\u22063} = {{1, 2, 5}, {1, 3, 5}, {3, 4, 5}}.", "startOffset": 8, "endOffset": 22}, {"referenceID": 9, "context": "We make the stationary health assumption [Feldman et al., 2010]: behavior of each c \u2208 COMPS is constant during diagnosis.", "startOffset": 41, "endOffset": 63}, {"referenceID": 4, "context": "in [de Kleer and Williams, 1987; Reiter, 1987]).", "startOffset": 3, "endOffset": 46}, {"referenceID": 21, "context": "in [de Kleer and Williams, 1987; Reiter, 1987]).", "startOffset": 3, "endOffset": 46}, {"referenceID": 9, "context": "minimum cardinality [Feldman et al., 2010] or most probable [de Kleer, 1991] ones) are exploited for measurement selection [de Kleer and Williams, 1989].", "startOffset": 20, "endOffset": 42}, {"referenceID": 7, "context": ", 2010] or most probable [de Kleer, 1991] ones) are exploited for measurement selection [de Kleer and Williams, 1989].", "startOffset": 25, "endOffset": 41}, {"referenceID": 5, "context": ", 2010] or most probable [de Kleer, 1991] ones) are exploited for measurement selection [de Kleer and Williams, 1989].", "startOffset": 88, "endOffset": 117}, {"referenceID": 4, "context": "For example, the methods of [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013] cannot ensure this important property.", "startOffset": 28, "endOffset": 106}, {"referenceID": 27, "context": "For example, the methods of [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013] cannot ensure this important property.", "startOffset": 28, "endOffset": 106}, {"referenceID": 22, "context": "For example, the methods of [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013] cannot ensure this important property.", "startOffset": 28, "endOffset": 106}, {"referenceID": 2, "context": "Despite its NP-completeness [Bylander et al., 1991], the generation of two (or more) diagnoses is practical in many realworld settings [de Kleer, 1991; Shchekotykhin et al.", "startOffset": 28, "endOffset": 51}, {"referenceID": 7, "context": ", 1991], the generation of two (or more) diagnoses is practical in many realworld settings [de Kleer, 1991; Shchekotykhin et al., 2014], making query-based SQD commonly applicable.", "startOffset": 91, "endOffset": 135}, {"referenceID": 28, "context": ", 1991], the generation of two (or more) diagnoses is practical in many realworld settings [de Kleer, 1991; Shchekotykhin et al., 2014], making query-based SQD commonly applicable.", "startOffset": 91, "endOffset": 135}, {"referenceID": 4, "context": "the probability of observing a positive or negative query outcome [de Kleer and Williams, 1987].", "startOffset": 66, "endOffset": 95}, {"referenceID": 25, "context": "Active learning query selection measures (QSMs) m : Q 7\u2192 m(Q) \u2208 R [Settles, 2012] use exactly these query properties characterized by the QP to assess how favorable a query is.", "startOffset": 66, "endOffset": 81}, {"referenceID": 14, "context": "Solving this problem is known to be NPcomplete as it amounts to optimal binary decision tree construction [Hyafil and Rivest, 1976].", "startOffset": 106, "endOffset": 131}, {"referenceID": 6, "context": "This has been shown to be optimal in many cases and nearly optimal in most cases [de Kleer et al., 1992].", "startOffset": 81, "endOffset": 104}, {"referenceID": 4, "context": "Several different QSMs m such as split-in-half, entropy, or risk-optimization have been proposed, well studied and compared against each other [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013].", "startOffset": 143, "endOffset": 221}, {"referenceID": 27, "context": "Several different QSMs m such as split-in-half, entropy, or risk-optimization have been proposed, well studied and compared against each other [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013].", "startOffset": 143, "endOffset": 221}, {"referenceID": 22, "context": "Several different QSMs m such as split-in-half, entropy, or risk-optimization have been proposed, well studied and compared against each other [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013].", "startOffset": 143, "endOffset": 221}, {"referenceID": 4, "context": "using entropy as QSM, m would be exactly the scoring function $() derived in [de Kleer and Williams, 1987].", "startOffset": 77, "endOffset": 106}, {"referenceID": 24, "context": "A (heuristic) search problem [Russell and Norvig, 2010] is defined by the initial state, a successor function enumerating all direct neighbor states of a state, the step costs from a state to a successor state, the goal test to determine if a given state is a goal state or not, (and some heuristics to estimate the remaining effort towards a goal state).", "startOffset": 29, "endOffset": 55}, {"referenceID": 27, "context": "[Shchekotykhin et al., 2012]) can be (optionally) integrated into the search to enable faster convergence to the optimum.", "startOffset": 0, "endOffset": 28}, {"referenceID": 4, "context": "[de Kleer and Williams, 1987], see Alg.", "startOffset": 0, "endOffset": 29}, {"referenceID": 4, "context": "all QSMs m given in diagnosis literature [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013] were found.", "startOffset": 41, "endOffset": 119}, {"referenceID": 27, "context": "all QSMs m given in diagnosis literature [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013] were found.", "startOffset": 41, "endOffset": 119}, {"referenceID": 22, "context": "all QSMs m given in diagnosis literature [de Kleer and Williams, 1987; Shchekotykhin et al., 2012; Rodler et al., 2013] were found.", "startOffset": 41, "endOffset": 119}, {"referenceID": 21, "context": "using the classical HS-TREE [Reiter, 1987].", "startOffset": 28, "endOffset": 42}, {"referenceID": 1, "context": "to ping servers in a distributed system [Brodie et al., 2003], to test gates using a voltmeter in circuits [de Kleer and Williams, 1987] or to ask the stakeholders of a (software/configuration/KB) system whether specified code lines/constraints/sentences are correct [Wotawa, 2002; Felfernig et al.", "startOffset": 40, "endOffset": 61}, {"referenceID": 4, "context": ", 2003], to test gates using a voltmeter in circuits [de Kleer and Williams, 1987] or to ask the stakeholders of a (software/configuration/KB) system whether specified code lines/constraints/sentences are correct [Wotawa, 2002; Felfernig et al.", "startOffset": 53, "endOffset": 82}, {"referenceID": 34, "context": ", 2003], to test gates using a voltmeter in circuits [de Kleer and Williams, 1987] or to ask the stakeholders of a (software/configuration/KB) system whether specified code lines/constraints/sentences are correct [Wotawa, 2002; Felfernig et al., 2004; Friedrich and Shchekotykhin, 2005].", "startOffset": 213, "endOffset": 286}, {"referenceID": 10, "context": ", 2003], to test gates using a voltmeter in circuits [de Kleer and Williams, 1987] or to ask the stakeholders of a (software/configuration/KB) system whether specified code lines/constraints/sentences are correct [Wotawa, 2002; Felfernig et al., 2004; Friedrich and Shchekotykhin, 2005].", "startOffset": 213, "endOffset": 286}, {"referenceID": 12, "context": ", 2003], to test gates using a voltmeter in circuits [de Kleer and Williams, 1987] or to ask the stakeholders of a (software/configuration/KB) system whether specified code lines/constraints/sentences are correct [Wotawa, 2002; Felfernig et al., 2004; Friedrich and Shchekotykhin, 2005].", "startOffset": 213, "endOffset": 286}, {"referenceID": 15, "context": "For this purpose, one can use a variant of the polynomial divide-and-conquer method QUICKXPLAIN [Junker, 2004], e.", "startOffset": 96, "endOffset": 110}, {"referenceID": 15, "context": "9), requires only a polynomial number of inference engine calls [Junker, 2004].", "startOffset": 64, "endOffset": 78}, {"referenceID": 21, "context": "To evaluate our method, we used real-world inconsistent knowledge-based (KB) systems as (1) they pose a hard challenge for query selection methods due to the implicit nature of the possible queries (must be derived by inference; not directly given such as wires in a circuit), (2) any MBD system in the sense of [Reiter, 1987] is described by a KB, (3) the type of the underlying system is irrelevant to our method, only its size and (reasoning) complexity \u2013 for the optional phase P3 \u2013 and the DPI structure, e.", "startOffset": 312, "endOffset": 326}, {"referenceID": 28, "context": ", 80}, we randomly generated 5 different D \u2208 DSys with |D| = n using INV-HS-TREE [Shchekotykhin et al., 2014] with randomly shuffled input.", "startOffset": 81, "endOffset": 109}, {"referenceID": 4, "context": "For each of these 5 D-sets, we used (a) entropy (ENT) [de Kleer and Williams, 1987] and (b) split-in-half (SPL) [Shchekotykhin et al.", "startOffset": 54, "endOffset": 83}, {"referenceID": 27, "context": "For each of these 5 D-sets, we used (a) entropy (ENT) [de Kleer and Williams, 1987] and (b) split-in-half (SPL) [Shchekotykhin et al., 2012] as QSM m and c|\u00b7| (cf.", "startOffset": 112, "endOffset": 140}, {"referenceID": 27, "context": "the very small tm ( 1 10 of tm used in [Shchekotykhin et al., 2012]) was found in S.", "startOffset": 39, "endOffset": 67}, {"referenceID": 30, "context": "The optional further query enhancement in P3 using a reasoner [Sirin et al., 2007] always finished within 4 sec and returned the globally System |COMPS| Complexity a #D/min/max b University (U) c 49 SOIN (D) 90/3/4 MiniTambis (M) c 173 ALCN 48/3/3 CMT-Conftool (CC) d 458 SIN (D) 934/2/16 Conftool-EKAW (CE) d 491 SHIN (D) 953/3/10 Transportation (T) c 1300 ALCH 1782/6/9 Economy (E) c 1781 ALCH 864/4/8 Opengalen-no-propchains (O) e 9664 ALEHIF 110/2/6 Cton (C) e 33203 SHF 15/1/5", "startOffset": 62, "endOffset": 82}, {"referenceID": 27, "context": "c Sufficiently complex systems (#D\u2265 40) used in [Shchekotykhin et al., 2012].", "startOffset": 48, "endOffset": 76}, {"referenceID": 31, "context": "d Hardest diagnosis problems mentioned in [Stuckenschmidt, 2008].", "startOffset": 42, "endOffset": 64}, {"referenceID": 27, "context": "e Hardest diagnosis problems tested in [Shchekotykhin et al., 2012].", "startOffset": 39, "endOffset": 67}, {"referenceID": 4, "context": "We present a search that addresses the optimal measurement (query) selection problem for sequential diagnosis and is applicable to any model-based diagnosis problem conforming to [de Kleer and Williams, 1987; Reiter, 1987].", "startOffset": 179, "endOffset": 222}, {"referenceID": 21, "context": "We present a search that addresses the optimal measurement (query) selection problem for sequential diagnosis and is applicable to any model-based diagnosis problem conforming to [de Kleer and Williams, 1987; Reiter, 1987].", "startOffset": 179, "endOffset": 222}], "year": 2017, "abstractText": "In this work we present strategies for (optimal) measurement selection in model-based sequential diagnosis. In particular, assuming a set of leading diagnoses being given, we show how queries (sets of measurements) can be computed and optimized along two dimensions: expected number of queries and cost per query. By means of a suitable decoupling of two optimizations and a clever search space reduction the computations are done without any inference engine calls. For the full search space, we give a method requiring only a polynomial number of inferences and guaranteeing query properties existing methods cannot provide. Evaluation results using real-world problems indicate that the new method computes (virtually) optimal queries instantly independently of the size and complexity of the considered diagnosis problems.", "creator": "TeX"}}}