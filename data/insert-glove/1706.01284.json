{"id": "1706.01284", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2017", "title": "Learning Neural Programs To Parse Programs", "abstract": "sancocho In this mir-1 work, we filinvest study 1,217 an important problem: direct-to-consumer learning re-organisation programs from input - graziani output garmisch examples. We mleggett@statesman.com propose bitcoin a wijesekera novel pugh method ducharme to 5,6 learn non-free a akranes neural pancer program clarie operating t.a. a phata domain - specific c-type non - days differentiable dantley machine, and demonstrate zeien that yuanshi this am1 method nekrasov can custom be applied to learn galca programs masoretic that are significantly vryburg more complex than polyester the latae ones synthesized before: bross programming language flakes parsers from venpres input - infra-red output 1.055 pairs revivify without knowing the underlying grammar. subh-i-azal The oco main h\u00e0m challenge is gulick to train blowhard the 5.96 neural 650-word program without gelo supervision on execution gangland traces. To tackle it, villaret we propose: (1) LL 108.66 machines twinkled and neural co-author programs operating large-bodied them oosthuizen to breitenbach effectively regularize emanuele the space of the eduction learned chansi programs; and (2) ebr\u0101h\u012bm\u0101b\u0101d a two - gaugamela phase reinforcement euro175 learning - based search agapova technique to bagneris train the chaudoir model. Our evaluation sumbat demonstrates that luck our approach 24.93 can fingerprinted successfully learn to parse zametica programs vattenfall in both an gas-turbine imperative language 493,000 and a magnificient functional language, ruhani and achieve 100% yeldon test emp\u00faries accuracy, servites while 715 existing olanchano approaches ' 78.87 accuracies ,230 are saravana almost 0% . lazarists This p\u00eache is modrikamen the first 90-87 successful moakler demonstration probation of kampot applying reinforcement learning ellen to zhare train a neural calligraphy program operating a landini non - sustainably differentiable 16:09 machine 8,000-pound that stukelj can 140-mph fully generalize oops to test iscb sets filimoni on tale a iran-140 non - trivial ashley-cooper task.", "histories": [["v1", "Mon, 5 Jun 2017 11:44:35 GMT  (1127kb,D)", "http://arxiv.org/abs/1706.01284v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.PL", "authors": ["xinyun chen", "chang liu", "dawn song"], "accepted": false, "id": "1706.01284"}, "pdf": {"name": "1706.01284.pdf", "metadata": {"source": "CRF", "title": "Learning Neural Programs To Parse Programs", "authors": ["Xinyun Chen", "Chang Liu", "Dawn Song"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Learning a domain-specific program from input-output examples is an important open challenge with many applications [4, 26, 6, 21, 10, 24, 16, 15]. Approaches in this domain largely fall into two categories. One line of work learns a neural network (i.e., a fully-differentiable program) to generate outputs from inputs directly [29, 1, 11, 10]. Despite their promising performance, these approaches typically cannot generalize well to unseen inputs. Another line of work synthesizes a non-differentiable (discrete) program in a domain-specific language (DSL) using either a neural network [10, 24] or SMT solvers [13]. However, currently the complexity of programs that can be synthesized using such approaches is limited. For example, most of these works [10, 24, 13] only focus on learning programs consisting of string operations with length at most 10.\nIn this work, we explore a new direction to learn domain-specific programs significantly more complex than previously considered in the literature of learning programs from input-output examples only. In particular, we consider an exemplary problem to learn a program to parse an input satisfying a contextfree grammar into its abstract syntax tree (or parse tree for short). This problem is challenging when the underlying grammar is unknown, and only input-output examples are provided. The program to be synthesized in this problem, i.e., a parser, is more complex than programs consisting of string operations as in many previous work [10, 24, 13], and thus serves as a good next step challenge to tackle in the domain of learning programs from input-output examples. Learning parsers is also an important problem on its own with many applications, such as easing the development of domain-specific languages and migrating legacy code into novel programming languages.\nIn this paper, we propose a combination of novel techniques to enable learning more complex domainspecific programs to achieve two goals: (1) full generalization; and (2) training with input-output examples only.\nOur approach is inspired by a number of key observations and offer valuable insights for pushing forward the frontier on learning more complex programs. In particular, we propose a new approach to learn a hybrid program, a differentiable neural program operating a domain-specific non-differentiable\nar X\niv :1\n70 6.\n01 28\n4v 1\n[ cs\n.L G\n] 5\nJ un\n2 01\n7\nmachine, from input-output examples only. Learning such a hybrid program combines the advantage of both differentiable and non-differentiable machines to enable learning more complex programs.\nTo implement this high level idea, we propose two novel techniques to make our neural programs trainable using input-output pairs only. First, we propose LL machines as an example domain-specific non-differentiable machine to be operated by neural programs, for learning parsers. Intuitively, an LL machine provides a high-level abstraction to regularize the learned programs to be within the space of LL(1) parsers [25]. The instructions provided by an LL machine provide richer semantic information than the primitives considered in previous works, so that the learning algorithm can take advantage of such information to learn more complex programs.\nSecond, we propose novel reinforcement learning-based techniques to train a neural program. Specifically, we solve the training problem in two phases: (1) we search for a valid execution trace set for each input-output example; then (2) we search for a set of input-output-trace combinations, so that a neural program can be trained to fit all training examples.\nTo show that our approach is general and can learn to parse different types of context-free languages using the same architecture and approach, we evaluate it on learning the parsing programs for an imperative language and a functional one, and demonstrate that our approach can successfully learn both of them, and the learned programs can achieve 100% on test set whose inputs are 100\u00d7 longer than training samples.\nWe summarize our contributions as follows:\n1. We propose a novel approach to learn more complex programs from input-output pairs, by learning a neural program that operates a domain-specific non-differentiable machine, and demonstrate this approach using the exemplar problem of learning program parsing with an unknown grammar;\n2. As an example domain-specific non-differentiable machine, we propose LL machines in combination with neural programs that operate them, which can effectively regularize the learned programs to be in the space of LL(1) parsers;\n3. We propose novel two-phase reinforcement learning-based techniques for training neural programs;\n4. We evaluate our approach on learning two languages: an imperative one and a functional one. Our evaluation demonstrates that our approach is generic to learn both of these two languages from the input-output pairs only without changing the network architecture, and the learned program can achieve 100% accuracy on even test sets with inputs 100\u00d7 longer than training samples;\n5. This work is the first successful demonstration that reinforcement learning can be applied to train a neural program operating a non-differentiable machine with input-output pairs only, while the learned neural program can fully generalize to longer inputs on a non-trivial task.\nOur work shows that using reinforcement learning to learn a neural program operating a domainspecific non-differentiable machine can enable learning more complex programs from input-output pairs than previously demonstrated. We hope this work can help inspire future work in learning more complex programs.\nRelated work. Learning the grammar from a corpus of examples has long been studied in the literature as the grammar induction problem, and algorithms such as L-Star [3] and RPNI [23] have been proposed to handle regular expressions. In contrast, in this work, we are interested in learning context-free languages [8], which is much more challenging than learning regular languages [9].\nRecent works propose to use sequence-to-sequence models [29, 1] and their variants [11] to directly generate parse trees from inputs. However, they often do not generalize well, and our experiments show that their test accuracy is almost 0% on inputs longer than those seen in training.\nA recent line of research [2, 7, 31] studying dependency parsing employs neural networks to operate a Shift-Reduce machine. However, each node in the generated dependency tree corresponds to an input token, while in our problem, there is not a direct correspondence between the internal nodes in parse trees and the input tokens. Further, RNNG [12] learns a neural program operating a top-down parser to generate parse trees, which include non-terminals. However, the input tokens align well\nwith the pre-order traversal of the parse tree. In our work, such order is often not preserved and the correspondence is hard to be recovered. Thus, these approaches do not directly apply to our problem.\nRecent works study learning neural programs and differentiable machines [14, 20, 17, 18, 5]. Their proposed approaches either do not generalize to longer inputs than those seen during training, or are evaluated only on simple tasks. In particular, StackRNN [17] also studies learning context-free languages, but their main focus is to generate language instances, while our goal is to learn the parser.\nOn the other hand, other works study neural programs operating non-differentiable machines [6, 21, 26, 32, 33], but in these works, either extra supervision on execution traces is needed during training [26, 6, 21], or the trained model cannot generalize well [32, 33]. In particular, [32] studies learning simple algorithms from input-output examples; however, the approach fails to generalize on very simple tasks, such as 3-number addition. Our work is the first one demonstrating that a neural program achieving full generalization to longer inputs can be trained from input-output pairs only.\nAnother line of research studies using neural networks to synthesize a program in a domain-specific language (DSL). Recent works [10, 24] study using neural networks to generate a program in a DSL from a few input-output examples for the FlashFill problem [16, 15]. However, the DSL contains only simple string operations, which is not expressive enough to implement a parser. Meanwhile, in these works, they can only successfully synthesize programs with lengths not larger than 10. These constraints make their approaches unsuitable for our problem currently. DeepCoder [4] presents a neural network-based search technique to accelerate search-based program synthesis. Again, lengths of the synthesized programs in this work are at most 5, while the parsing program that we study in this work is much more complex. There are other approaches [13] that employ SMT solvers to sample programs. Again, it is only demonstrated to solve a subset of the FlashFill problem and several simple array manipulation tasks."}, {"heading": "2 The Parsing Problem", "text": "In this section, we formally define the parsing problem and outline our approach.\nDefinition 1 (The parsing problem) Assume there exist a context-free language L and a parsing oracle \u03c0 that can parse every instance in L into an abstract syntax tree. Both L and \u03c0 are unknown. The problem is to learn a parsing program P , such that \u2200I \u2208 L, P (I) = \u03c0(I).\nFigure 1 provides an example of an input and its output parse tree. The internal nodes of the tree are called nonterminals, and the leaf nodes are called terminals. The sets of non-terminals and terminals are disjoint. Each terminal must come from one input token, but the non-terminals do not have such a correspondence. To simplify the problem, we assume the input is already tokenized. The set of all non-terminals and terminals can be extracted from the training corpus, i.e., all nodes in the output parse trees of training samples. In this work, we assume the vocabulary set (i.e., all terminals and non-terminals) is finite, and our work can be extended to handle unbounded vocabulary set with techniques such as pointer networks [28].\nLearning P is challenging for several reasons. First, the correspondence between non-terminals and input tokens is unknown. For example, in Figure 1, the parser needs to find out that token \u201c=\" corresponds to the non-terminal Assign. Second, the order of non-terminals in the tree may not align well with the input tokens. For example, in Figure 1, the sub-expression \u201ca=1\", which is to the left of the sub-expression \u201cx==y\", corresponds to the right child of the non-terminal If, which is to the right of the sub-tree corresponding to \u201cx==y\" (the sub-tree whose root is the non-terminal Eq). Third, the association of tokens may depend on other tokens. For example, in expressions \u201cx+y*z\" and \u201cx+y+z\", whether \u201cx+y\" forms a sub-tree depends on the operator (i.e., \u201c+\" or \u201c*\") after it."}, {"heading": "3 LL Machines", "text": "In this section, we present the design of our LL machines. It is inspired by the LL(1) parsing algorithm [25], although we do not require the readers to be familiar with the LL(1) algorithm. Throughout the description, we use Figure 2 as a running example to illustrate the concepts.\nStates. An LL machine maintains a sequence of (partial) input tokens and a stack of frames as its internal state. Each stack frame is an ID-list pair, where the ID is a function ID, which will be explained later, and in the list are (n, T ) pairs, where T is a parse tree, and n is the root node of T . For example, in Figure 2, after step 6, the stack frame at the top contains an ID 1 and a list of one element (Id,T2).\nInstructions. An LL machine has five types of instructions: SHIFT, CALL, RETURN, REDUCE, and FINAL. A parser operates an LL machine using these five types of instructions to construct the parse tree recursively. In the following, we explain these instructions and how they are used for parsing an input. To begin with, the stack contains one frame (0, []), where [] denotes an empty list.\nA SHIFT instruction (e.g., steps 1, 3, and 5 in Figure 2) removes the next token t from the input sequence, constructs a one-node tree T consisting of t, and appends (t, T ) to the end of the stack top\u2019s list. The SHIFT instruction has no argument.\nWhen the parser tries to parse a sub-expression as a sub-tree, it uses a CALL instruction to create a new stack frame. For example, before step 4, the sub-expression \u201cy\" needs to be parsed into T2 with root Id. In this case, a CALL instruction is executed to push a new frame with an empty list onto the stack. CALL has an argument fid , which is the function ID of the new frame at the stack top. This function ID carries information from the previous frame to the new one, e.g., to help to decide the boundary of the sub-expression. In Figure 3, for example, when parsing \u201cx+y*z\" and \u201cx*y*z\", once the first two tokens (i.e., \u201cx+\" and \u201cx*\") are consumed, the parser executes a CALL instruction to create a new frame to parse the sub-expressions \u201cy*z\" and \u201cy\" respectively. Since the remaining input sequences (i.e., \u201cy*z\") are the same in both cases, the function IDs provide the only clue to detect the boundaries of the sub-expressions.\nThe parser issues a REDUCE instruction to construct a larger tree, once all children of its root are constructed and laid out in the top frame\u2019s list. REDUCE n, (c1, ..., cm) has two arguments for specifying how to construct the new tree. The root of the newly constructed tree is n and has m children. The j-th child of n is the cj-th tree in the stack top\u2019s list. For example, in Figure 2, after step 8, T1 and T2 are combined to construct T3. The list in the top frame contains three elements, i.e., (Id,T1), (+,+), and (Id,T2). In this case, the REDUCE argument n is Id, indicating that T3\u2019s root is Id; for the second argument (c1, ..., cm), m = 2, c1 = 1 and c2 = 3, indicating that the first and third elements in the list (i.e., T1 and T2) constitute the first and second children of T3. Note that the children of the root are ordered.\nAfter a sub-expression is converted into a tree using the REDUCE instruction, a RETURN instruction can be executed to move the tree into the previous stack frame, so that it can be used to further construct larger trees. Formally, when the list in the top frame contains only one element (n, T ), RETURN (e.g., step 7 in Figure 2) pops the stack, and appends (n, T ) to the end of new stack top\u2019s list.\nWhen all input tokens are consumed and the stack contains only one tree, the parser executes FINAL (e.g., step 9 in Figure 2) to terminate the machine. Both RETURN and FINAL have no arguments.\nValid instruction set. At each step, an LL machine provides a set of valid instructions that can be executed. In doing so, the machine can guarantee that the state remains valid if the instructions to be executed are always chosen from this set. More details can be found in Appendix A."}, {"heading": "4 A Neural Parsing Program", "text": "A parsing program operates an LL machine via a sequence of LL machine instructions to parse an input to a parse tree. Specifically, a parsing program operating an LL machine decides the next instruction to execute after each timestep. A key property of the combination of the LL machine and the parsing program is that this decision can be made based on three components only: (1) the function ID of the top frame; (2) all root nodes of the trees (but not the entire trees) in the list of the top frame; and (3) the next input token. As we will explain in Appendix A, we can safely assume that the list in any stack frame can have at most K elements. Therefore, the parser only needs to learn a (small) finite number of scenarios in order to generalize to all valid inputs.\nTo learn the parsing program, we represent it as a neural network, which predicts the next instruction to be executed by the LL machine. Specifically, we consider two inference problems that compute the probabilities of the type and arguments of the next instruction respectively:\np(inst |fid , l, tok) p(arginst |inst ,fid , l, tok) where (fid , l) denotes the current stack top, tok is the first token of current input, inst is the type of the next instruction, arginst are the arguments of the next instruction inst . Note that the second probability is needed only if the predicted instruction type is either CALL or REDUCE.\nAt a high-level, at each step, the neural network first converts each root node in the list of the top stack frame into an embedding vector, and then runs three separate LSTMs to predict the type (i.e., Formula (1)) and arguments (i.e., Formula (2) and (3)) of the next instruction.\nIn the following, we use L to denote the length of l, and D the dimensionality for both input embeddings and LSTM hidden states. softmax(...)i denotes the i-th dimension of the softmax output. We explain each component in the following, and more illustration and how to guarantee the predicted instructions to be in the valid instruction set can be found in Appendix B.\nEmbeddings. For each element \u3008ni, Ti\u3009 (1 \u2264 i \u2264 L) in the stack top\u2019s list l, we use a lookup table A over all terminals and non-terminals to convert ni into the embedding space. Specifically, we compute a D-dimensional vector ei = A(ni) for 1 \u2264 i \u2264 L. Thus, we compute e1, ..., eL from l.\nInstruction probability. We use an LSTM to compute p(inst |fid , l, tok) as follows: p(inst |fid , l, tok) = softmax(W1 \u00b7 LSTM1((hfid , cfid), e1, ..., eL) +W2 \u00b7A(tok))inst (1)\nSpecifically, each function ID fid corresponds to a pair of D-dimensional trainable vectors (hfid , cfid ), which sets the initial state of the LSTM. We use LSTM1((hfid , cfid), e1, ..., eL) to indicate the final hidden state of LSTM1 when the input sequence to the LSTM is e1, ..., eL and its initial state is (hfid , cfid ). Further, A(tok) encodes the current token using the same lookup table A as above. W1 and W2 are M \u00d7D trainable matrices, where M = 5 since there are 5 different types of instructions.\nPredicting CALL arguments. To predict argument fid \u2032 of the CALL instruction, we compute\np(fid \u2032|fid , l, tok) = softmax(W \u20321 \u00b7 LSTM2((h\u2032fid , c\u2032fid), e1, ..., eL) +W \u20322 \u00b7A(tok))fid\u2032 (2) This part is similar to the one for next-instruction prediction as shown in Formula (1), though a different set of parameters (i.e., h\u2032fid , c \u2032 fid ,W \u2032 1,W \u2032 2) is used. The lookup table A is the only overlap.\nPredicting REDUCE arguments. For a REDUCE instruction, we need to predict both n and (c1, ..., cm), which define how to construct the new sub-tree. To achieve this, the model predicts n first, and then predicts (c1, ..., cm) based on n. Specifically, we have\np(n|l) = softmax(W \u2032\u2032 \u00b7 LSTM3((0, 0), e1, ..., eL))n (3) p(c1, ..., cm|n) = softmax(an)c1,...,cm (4)\nwhere LSTM3 is the third LSTM,W \u2032\u2032 is anN\u00d7D trainable matrix, and an is a trainable vector for n. Here N is the number of different types of non-terminals. Since each stack frame\u2019s list has at most K elements, we enumerate all possible combinations of c1, ..., cm, and assign each combination a unique label from 1 to f(K) = K!\u00d7 (\u2211Ki=0 1i! ), which is the total number of possible combinations, thus an is an f(K)-dimensional vector. Assume the label for (c1, ..., cm) is \u03be, then softmax(...)c1,...,cm indicates the \u03be-th dimension of the softmax output. Notice that setting K to 4 is enough to handle two non-trivial languages used in our evaluation. In both cases, f(K) \u2264 65, which is tractable as the number of classes in a classification problem. We consider to handle a larger K as future work."}, {"heading": "5 Learning a Neural Parsing Program", "text": "In this section, we consider two types of supervision for training the model. First, we consider that for each input-output pair, the execution trace is partially given. Specifically, for each step in the execution trace, the instruction type is provided, but the arguments of the instruction are not. We refer to this case as weakly supervised learning, and refer to an execution trace with instruction types only as an instruction type trace. Second, we consider that only the input-output pairs are provided without any information on the execution traces. We refer to this case as training with input-output pairs only. Both of these two cases are non-trivial. We demonstrate that the weakly supervised learning algorithm can be leveraged as a sub-routine toward solving the training problem with input-output pairs only. Our approaches to solving both problems use reinforcement learning-based algorithms, and we highlight our techniques in the rest of this section. More details about how to update the model parameters are shown in Appendix C."}, {"heading": "5.1 Weakly supervised learning", "text": "When instruction type traces are given, training the model to predict the next instruction type is a supervised learning problem, which is easy to solve. Thus, the main challenge is to learn to predict the correct arguments for each instruction. Our basic idea is to train the model via reinforcement learning. Specifically, we use REINFORCE algorithm [30]. The main challenge is that the training process is very sensitive to the design of the reward functions. In the following, we present our design of the reward functions to tackle these challenges, which allows the learned model to achieve 100% training accuracy. More details are provided in Appendix C.\nLearning to predict REDUCE arguments n and (c1, ..., cm). For the REDUCE instruction, our intuition is that if a wrong set of arguments is used, the generated sub-tree will look very different than the ground truth tree. Therefore, we design the reward function based on the difference between the predicted sub-tree and the ground truth.\nFirst, we define the difference between two trees T and T \u2032, denoted as diff (T, T \u2032), to be the edit distance between T and T \u2032 [27]. Assume T\u0302 is the final generated parse tree and Tg is the ground truth output tree. Our goal is to minimize diff (T\u0302 , Tg), i.e., to 0.\nAssume the parse tree constructed by the REDUCE instruction is T\u0302r. Since the final generated parse tree is composed by these smaller trees, a correct parse tree T\u0302r should also be a sub-tree of Tg . Based on this intuition, we define mindiff (T\u0302r, Tg) = minT\u2208S(Tg){diff (T\u0302r, T )}, where S(Tg) indicates the set of all sub-trees of Tg . If all of the REDUCE arguments are predicted correctly, mindiff (T\u0302r, Tg) should be 0.\nWe design the reward function for n and (c1, ..., cm) as below:\nrreduce(T\u0302r) = \u2212 log(\u03b1 \u00b7mindiff (T\u0302r, Tg) + \u03b2) where \u03b1 > 1, \u03b2 \u2208 (0, 1) are two hyperparameters. In our experiments, we choose \u03b1 = 3, \u03b2 = 0.01. In addition, we have a more efficient approach to learn the prediction for n via supervised learning. The details can be found in Appendix C.\nLearning to predict CALL argument fid . Designing the reward function to learn the prediction of fid is challenging. As we can see in Figure 3, the choice of each fid affects only the prediction of subsequent instruction types. Our design of the reward function for fid takes this into account. Intuitively, a wrong guess of fid will result in incorrect subsequent predicted instruction types. Based on this intuition, we design the reward function as follows:\nrf (fid (t)) =\nt\u2032\u2211\nj=t+1\nlog p( \u02c6inst (j)|fid (j), l(j), tok (j))inst(j)\nwhere t indicates the current step to execute a CALL instruction, t\u2032 the next step to execute a CALL instruction, \u02c6inst (j) and inst (j) the predicted and ground truth instruction types, and (fid (j), l(j)), tok (j) the frame at the stack top and the next input token at step j. Basically, the reward function rf accumulates the negation of the cross-entropy loss of the predicted instructions from the current CALL instruction till the next one. More details can be found in Appendix C."}, {"heading": "5.2 Training with input-output pairs only", "text": "When the training set contains only input-output pairs without any information on the execution traces, learning a model that can parse all valid inputs 100% accurately is more challenging. The main issue is that a learned model may correctly parse some inputs, but fail on others. We observe that for each input-output pair, there may exist multiple valid execution traces (see Appendix C for an example), where a model trained to mimic one certain trace for one input-output pair may not be able to learn to mimic one certain execution trace for another pair at the same time. Thus, our goal is to find consistent execution traces for all input-output pairs in the training set.\nTo achieve this goal, we learn the neural parsing program in two phases. First, for each input-output pair, we find a set of valid candidate instruction type traces with a preference toward shorter ones. We refer to this set of traces as the candidate trace set for a given input-output pair. Second, we try to search for a satisfiable specification. A specification is a set of input-output-trace triples that assign an instruction type trace from the corresponding candidate trace set for each input-output pair in the training set. We say that a specification is satisfiable, if there exists a parsing program that can parse all inputs into their outputs using the corresponding instruction type traces in the specification. We present the details of these two phases in the following.\nSearching for the candidate trace set for each input-output pair. Due to the large search space, exhaustive search is not practical even for a very short input. Instead, we adopt the idea of training a neural parsing program to explore the search space to find a feasible trace through policy gradient.\nSpecifically, we develop a two-nested-loop process to search for the candidate trace set for each input-output pair. In each iteration of the outer loop, we run a forward pass of the model to sample an execution trace including a sequence of instructions and their arguments. We sample the execution trace using the model described in Section 4, except that while sampling the next instruction type among valid instruction types, we use the following the distribution instead: p(inst |fid , l, tok) \u221d softmax(...)inst + \u03c3. Here, \u03c3 > 0 is a constant allowing exploration during the search. After a forward pass, we use the difference between the predicted parse tree and the ground truth as the reward to update the model\u2019s parameters predicting the next instruction type using policy gradient. If the predicted tree is identical to the ground truth, then we have successfully found a valid instruction type trace, and we add it into the candidate trace set. Otherwise, we test in the inner loops whether the sampled instruction type trace is wrong, or only the arguments are predicted wrongly.\nTo do so, in the inner loops, we use the sampled instruction type trace in the outer loop as the candidate ground truth, and train the model with weakly supervised learning method in Section 5.1. If any prediction tree during the inner loops matches the candidate ground truth, we add the sampled instruction type trace to the candidate set. Otherwise, the model\u2019s parameters are reverted back to those at the beginning of the inner loop, and the sampled instruction type trace is dropped.\nAt the end of the outer loop, the candidate trace set is formed, which typically includes 3 to 5 traces, and the model used during the loop is dropped. More details are in Appendix C.\nSearching for a satisfiable specification. To find a satisfiable specification, again, the naive idea to perform an exhaustive search requires to explore a total number of specifications that is exponential in the number of training samples, which is impractical.\nThus, we alternatively employ a sampling-based approach. For each input-output pair (ik, Tk) in the training set, we assume Sk = {trk,1, ..., trk,d} is its candidate trace set including d traces. We sample a trace following the distribution p(trk,j) = softmax(\u03b8k)j , where \u03b8k is a d-dimensional vector. After one trace is sampled for each input-output pair, these traces form a specification, and we try to train a model using the weakly supervised learning algorithm described in Section 5.1 with this specification. If the model can correctly parse all inputs, then we find a satisfiable specification. Otherwise, for each input-output pair (ik, Tk) that is wrongly parsed, we decrease the probability of sampling current trace in the future by updating \u03b8k using: \u03b8k \u2190 \u03b8k\u2212\u03c4 \u00b7diff (T\u0302k, Tk)\u00b7\u2207\u03b8k log p(trk,j), where T\u0302k is the predicted parse tree, and \u03c4 = 1.0. We observe that such a sampling-based approach can efficiently sample a satisfiable specification within 20 attempts in our experiments, while an exhaustive search algorithm may require to explore over tens of thousands of specifications.\nCurriculum learning. Searching for a valid trace for a longer input from a randomly initialized model can be very hard. To solve this problem, we use curriculum learning to train the model to learn to parse inputs from shorter length to longer length. In the curriculum, the first lesson contains the shortest inputs. In this case, we randomly initialize the model, and train it to parse all samples in Lesson 1. Afterwards, for each new lesson, we use the parameters learned from the previous lesson to initialize the model. When learning each lesson, all training samples from previous lessons are also added into the training set for the current lesson to avoid catastrophic forgetting [19]. Such a process continues until the model can correctly parse all samples in the curriculum."}, {"heading": "6 Evaluation", "text": "To show that our approach is general and able to learn to parse different types of context-free languages using the same architecture and approach, we evaluate our approach on two tasks to learn a parser for an imperative language WHILE and an ML-style [22] functional language LAMBDA respectively. WHILE and LAMBDA contains 73 and 66 production rules, and their parsing programs can be implemented in 89 and 46 lines of Python code respectively. Notice that these programs are more sophisticated than previous studied examples. For example, Quicksort studied in [6] can be implemented in 3 lines of Python code, and FlashFill tasks studied in [10, 24] can be implemented in 10 lines of code in their DSL. Grammar specifications of the two languages are presented in Appendix F and G respectively. The code is open sourced at https://github.com/liuchangacm/ neuralparser.\nWe compare our approach with a sequence-to-sequence approach (seq2seq) [29] and a sequenceto-tree (seq2tree) approach [11]. Other related works cannot directly be applied to our problem. For each task, we prepare two training sets: (1) Curriculum: a well-designed training curriculum including 100 to 150 examples that enumerates all language constructors; and (2) Standard: a larger set that includes all examples in the curriculum, and also 10,000 additional randomly generated inputs with length 10 on average. In both datasets, all ground truth parse trees are provided. Note that once our model learns to parse all inputs in the curriculum, it can parse all inputs in training set (2) for free. We include the Standard training set to allow a fair comparison against baseline approaches, which typically require a large amount of training data.\nFor testing, we create three levels of testsets, i.e., Test-10, Test-100 and Test-1000, where each input has 10, 100, and 1000 tokens on average respectively. Each test set contains 1000 randomly generated expressions. We guarantee that test data is not overlapping with training samples. Figure 4 show experimental results on WHILE and LAMBDA languages. We make the following observations:\n1. Our approach can be used to learn both the two different styles of programming languages without changing the network architecture; this demonstrates that our approach is generic.\n2. Our approach can train a neural program to achieve 100% accuracy on training samples. This demonstrates that our reinforcement learning-based search tehcniques can successfully train the neural program to fit to all training samples.\n3. The learned model can generalize to all test data, and achieve 100% accuracy on inputs with lengths being 100\u00d7 longer than training samples. This indicates that our learned model can fully generalize to longer inputs.\n4. When the training samples are sufficient (i.e., trained with Standard), and test inputs\u2019 lengths are about the same to the training inputs (i.e., tested on Test-10), seq2tree can achieve a better performance than seq2seq; but both methods cannot achieve 100% accuracy.\n5. On test inputs whose lengths are at least 10\u00d7 longer than training samples (i.e., Test-100 and Test-1000), the test accuracies of both seq2seq and seq2tree are almost 0%. This indicates that previous approaches cannot generalize well to longer inputs."}, {"heading": "Acknowledgement", "text": "This material is in part based upon work supported by the National Science Foundation under Grant No. TWC-1409915 and Berkeley DeepDrive. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. We thank Richard Shin, Dengyong Zhou, Yuandong Tian, He He, and Yu Zhang for their helpful discussions."}, {"heading": "A LL machines", "text": "We first demonstrate that how our LL machines regularize the space of the learned programs. To achieve this, we impose several constraints on the instruction types that can be applied at each timestep. We denote the current stack top as (fid , l), the length of l as L, and the first token of the current input as tok (tok = EOF if the current input is empty). Meanwhile, we assume that each stack frame\u2019s list has at most K elements, and we will explain why this assumption holds later. The constraints for when each of the five instructions is allowed are as below:\n1. SHIFT: it is allowed if tok 6= EOF and L < K. 2. CALL: it is allowed if tok 6= EOF, 0 < L < K, and the instruction type at previous timestep\nis not CALL. For its argument fid \u2032, 0 \u2264 fid \u2032 < F , where F > 0 is a hyperparameter. 3. RETURN: it is allowed if the current stack has more than one frame, and L = 1. 4. REDUCE: it is allowed if L > 0. For REDUCE arguments n and (c1, ..., cm), n is chosen from\nthe non-terminal set, and 1 \u2264 ci \u2264 L for 1 \u2264 i \u2264 m. 5. FINAL: it is allowed if tok = EOF, L = 1, and the current stack has only one frame.\nThen we explain why we can safely assume that there exists K such that each stack frame\u2019s list has at most K elements. As the parsing program continues, each stack frame\u2019s list contains partially finished sub-trees that correspond to a prefix of one production rule in the grammar. Since the length of production rules in a context-free grammar is finite, we can assume that the upper bound of the length is K. According to the instruction constraints imposed by LL machines, using the same K as the upper bound on the length of each stack frame\u2019s list, we can ensure that for each input in the grammar, there exists a trace satisfying such constraints that can parse the input to its parse tree correctly."}, {"heading": "B Model architecture", "text": "We first present our model architecture following Section 4. The different parts of the network are presented in Figure 5, 6, 7, and 8 respectively. Different sets of parameters are rendered in different colors. All these parts share only the lookup table A (depicted in green).\nThen we explain how the model chooses the instruction to be executed at each step. As for the prediction of instruction types, Let p(inst |fid , l, tok) be the predicted probability distribution over all different instruction types by the parsing program, which is computed in the way described in Section 4. Based on current state of the LL machine, the LL machine provides a set of valid instruction types. Then for each instruction type, if it is in the set of valid instruction types, then its probability for sampling is p(inst |fid , l, tok), otherwise its probability is set to be 0. Unless otherwise specified, at each step, the model chooses the instruction type predicted with the highest probability. The ways of predicting arguments for CALL and REDUCE instructions are similar."}, {"heading": "C Training details", "text": "Below we present full details about how to train the model. Following Section 5, we first illustrate the training approach when weak supervision is provided, and then explain how to train the model with input-output pairs only.\nC.1 Weakly supervised learning\nWe assume that the set of all parameters is \u0398. We apply Adam optimizer to update\n\u0398(i+1) \u2190 \u0398(i) \u2212 \u03b7\u2206\u0398(i)\nwhere \u03b7 is the learning rate, and \u2206\u0398(i) is the gradient that consists of three components:\n\u2206\u0398(i) = \u03b31 \u00b7\u2206\u03981 + \u03b32 \u00b7\u2206\u03982 + \u03b33 \u00b7\u2206\u03983 In the following, we describe the three components \u2206\u03981, \u2206\u03982, and \u2206\u03983 respectively.\nFigure 6: Model for predicting the CALL argument fid .\nStack top\n(Id, 1) (+,+) (Id, 2)\nA\n\ud835\udc52\" \ud835\udc52# \ud835\udc52$\n0 0 LSTM$\n\u210e\"\u2032\u2032\nLSTM$\n\u210e#\u2032\u2032\nLSTM$\n\u210e$\u2032\u2032 \u00d7\ud835\udc4a\u2032 Softm ax \u2026 \u2026 0.99 \u2026\nFigure 7: Model for predicting the REDUCE argument n.\nOp+\nSo ftm ax\n\u2026 1, 2 2, 1 1, 3 3, 1 \u2026 3,2,1 \u2026 \u2026 \u2026 0.99 \u2026 \u2026 \u2026 \ud835\udc4eOp+\nFigure 8: Model for predicting the REDUCE argument c1, ..., cm.\nC.1.1 REDUCE argument (c1, ..., cm)\nFirst, we present the details of diff (T, T \u2032) in Algorithm 1. The first component of the gradient is computed as the following:\n\u2206\u03981 = \u2211\nt\n\u2202 log p(c (t) 1 , ..., c (t) m |n(t))\n\u2202\u0398 \u00b7 rreduce(T\u0302 (t)r )\nwhere t iterates over all REDUCE operations, c(t)1 , ..., c (t) m and n(t) indicate the predicted arguments in the t-th operation, and T\u0302 (t)r indicates the predicted tree in the t-th operation.\nC.1.2 REDUCE argument n\nFor learning to predict the REDUCE argument n, we can use reinforcement learning technique similar to the method above. In the following, we present another training method using supervised learning. We observe that such a training method is more time-efficient in our experiments.\nWe first match each REDUCE operation to a tentative ground truth. Given the predicted tree T\u0302 and the ground truth Tg, we match each node in T\u0302 to a node in Tg in the following way. Assuming that T\u0302 = N\u0302(T\u03021, ..., T\u0302k) and Tg = Ng(Tg1, ..., Tgk\u2032), N\u0302 is matched to Ng first, then T\u0302i is matched to Tgi recursively for i = 1, ...,min(k, k\u2032). If k > k\u2032, then T\u0302i for i \u2208 {k\u2032, ..., k} is matched to any ground truth.\nAfterwards, the second component is computed as follows:\n\u2206\u03982 = \u2211\nt\n\u2202 log p(n (t) g |fid (t), l(t), tok (t))\n\u2202\u0398\nAlgorithm 1 The algorithm to compute the difference between T and T \u2032. In the algorithm, we use T = N(T1, ..., Tj) to indicate that T \u2019s root is non-terminal N , which has j children T1, ..., Tj .\nwhere t iterates over all REDUCE operations such that the generated non-terminal has a matched tentative ground truth n(t)g , and log p(n (t) g |fid (t), l(t), tok (t)) is the cross-entropy loss between p(n(t)|fid (t), l(t), tok (t)) and the one-hot vector of n(t)g .\nC.1.3 CALL argument fid\nWe first give an example to illustrate our design of reward function rf in Figure 9.\nThe third component is computed as follows:\n\u2206\u03983 = \u2211\nt\n\u2202 log p(fid \u2032(t)|fid (t), l(t), tok (t)) \u2202\u0398 \u00b7 rf (fid \u2032(t))\nwhere t iterates over all CALL operations.\nC.2 Training with input-output pairs only\nIn this section, we further describe the algorithm for training with input-output pairs only, especially for how to search for the candidate trace set. As explained in Section 5.2, the algorithm needs to find the set of valid candidate traces for each input-output example. Notice that for one input-output example, the possible valid execution traces are not unique. Figure 10 provides one alternative execution trace that successfully parses x+y into its parse tree. Only when combining multiple examples, the model trained with this trace cannot fit all examples at the same time.\nSearching for the candidate trace set. Here we further explain the two-nested-loop process to search for the candidate trace set following Section 5.2. First, in the outer loop, we randomly sample an instruction type trace based on the distribution described in Section 5.2. Then in the inner loop, we try to use the sampled trace in the external loop as the tentative ground truth, and then employ the weakly supervised learning approach to train the parameters predicting the arguments for M1 iterations. If in any of these M1 iterations, the correct output is produced, we add the sampled instruction trace to the candidate trace set. Otherwise, if the correct output is never produced during these M1 iterations, we revert the model\u2019s parameters to predict the arguments back to those before these M1 weak supervised learning iterations, and continue sampling another instruction trace. This process is continued for M2 iterations, i.e., a total of M2 instruction traces are sampled. Meanwhile, to escape from a sub-optimal model, we re-initialize the model with the one learned from the previous lesson every M3 iterations."}, {"heading": "D Hyperparameters of Our Proposed Method", "text": "For the LL machines, F = 10. About the capacity of each stack frame K, K = 3 for WHILE language, and K = 4 for LAMBDA language. In the architecture of the neural parsing program, each LSTM has 1 layer, with its hidden state size D = 50, which is the same as the embedding size. As for the training, learning rate is \u03b7 = 0.01 with no decay. No dropout is used. Gradient weights for the three components \u2206\u03981, \u2206\u03982 and \u2206\u03983 are \u03b31 = 10.0, \u03b32 = 1.0, and \u03b33 = 0.01 respectively. Gradients with L2 norm larger than 5.0 are scaled down to have the norm of 5.0. The model is trained using Adam optimizer. All weights are initialized uniformly randomly in [\u22120.1, 0.1]. The mini-batch size is 1. For candidate trace search, \u03c3 = 0.1, M1 = 20, M2 = 10, 000, and M3 = 2, 000."}, {"heading": "E Hyperparameters of Baseline Models", "text": "For the baseline models in our evaluation, i.e., seq2seq and seq2tree, we implement them ourselves. We choose their hyperparameters based on [29] and [11] respectively, and further tune on our datasets to get better experimental results.\nSpecifically, in the seq2seq model [29], each of the encoder and the decoder is a 3-layer LSTM, and the hidden state size of each layer is 256, which is the same as the embedding size. We apply the attention mechanism described in [29]. As for training, learning rate is 0.01. The dropout rate is 0.5. Gradients with L2 norm larger than 5.0 are scaled down to have the norm of 5.0. The model is trained using Adam optimizer. All weights are initialized uniformly randomly in [\u22120.1, 0.1]. The mini-batch size is 256.\nIn the seq2tree model [11], each of the encoder and the decoder is a 1-layer LSTM, and its hidden state size is 256, which is the same as the embedding size. We apply the attention mechanism described in [11].As for training, learning rate is 0.005. The dropout rate is 0.5. Gradients with L2 norm larger than 5.0 are scaled down to have the norm of 5.0. The model is trained using Adam optimizer. All weights are initialized uniformly randomly in [\u22120.1, 0.1]. The mini-batch size is 20."}, {"heading": "F WHILE language", "text": "Below is the grammar specification of the WHILE language.\n<Identifier> ::= x | y <Literal> ::= 0 | 1\n<Op*> ::= <Identifier>\u00d7 <Identifier> | <Identifier>\u00d7 <Literal> | <Literal>\u00d7 <Identifier> | <Literal>\u00d7 <Literal> | <Op*>\u00d7 <Identifier> | <Op*>\u00d7 <Literal>\n<Op+> ::= <Identifier> + <Identifier> | <Identifier> + <Literal> | <Identifier> + <Op*> | <Literal> + <Identifier> | <Literal> + <Literal> | <Literal> + <Op*> | <Op+> + <Identifier> | <Op+> + <Literal> | <Op+> + <Op*> | <Op*> + <Identifier> | <Op*> + <Literal> | <Op*> + <Op*>\n<Eq> ::= <Identifier> == <Identifier> | <Identifier> == <Literal> | <Identifier> == <Op+> | <Identifier> == <Op*> | <Literal> == <Identifier> | <Literal> == <Literal> | <Literal> == <Op+> | <Literal> == <Op*> | <Op+> == <Identifier> | <Op+> == <Literal> | <Op+> == <Op+> | <Op+> == <Op*> | <Op*> == <Identifier> | <Op*> == <Literal> | <Op*> == <Op+> | <Op> == <Op*>\n<Assign> ::= <Identifier> = <Identifier> | <Identifier> = <Literal> | <Identifier> = <Op+> | <Identifier> = <Op*>\n<If> ::= <Assign> if <Identifier> | <Assign> if <Literal> | <Assign> if <Op+> | <Assign> if <Op*> | <Assign> if <Eq> | <If> if <Identifier> | <If> if <Literal> | <If> if <Op+> | <If> if <Op*> | <If> if <Eq>\n<Seq> ::= <Assign> ; <Assign> | <Assign> ; <If> | <Assign> ; <While> | <If> ; <Assign> | <If> ; <If> | <If> ; <While> | <While> ; <Assign> | <While> ; <If> | <While> ; <While> | <Seq> ; <Assign> | <Seq> ; <If> | <Seq> ; <While>\n<Block> ::= { <Assign> } | { <If> } | { <While> } | { <Seq> } <While> ::= while <Identifier> <Block> | while <Literal> <Block> | while <Op+> <Block> | while <Op*> <Block> | while <Eq> <Block>"}, {"heading": "G LAMBDA language", "text": "Below is the grammar specification of the LAMBDA language.\n<Var> ::= a | b | ... | z <App> ::= <Var> <Var>\n| <App> <Var> <Bind> ::= lam a | ... | lam z <Lam> ::= <Bind> . <Var>\n| <Bind> . <App> | <Bind> . <Lam> | <Bind> . <Let>\n<LetExpr> ::= <Var> = <Var> | <Var> = <App> | <Var> = <Lam> | <Var> = <Let>\n<Let> ::= let <LetExpr> in <Var> | let <LetExpr> in <App> | let <LetExpr> in <Lam> | let <LetExpr> in <Let>"}, {"heading": "H Python implementation of WHILE language parser", "text": "1d e f n e x t I n s t r u c t i o n ( s e l f ) : 2f i d , t o p = s e l f . f i d [ \u22121] , s e l f . s t a c k [\u22121] 3n e x t = s e l f . i n p u t [ s e l f . c u r ] i f s e l f . c u r < l e n ( s e l f . i n p u t ) e l s e None 4i f l e n ( t o p ) == 0 : 5r e t u r n s e l f . s h i f t , None 6e l i f l e n ( t o p ) == 1 : 7i f t o p [ 0 ] [ 1 ] == \u2019 w h i l e \u2019 : 8r e t u r n s e l f . c a l l , 0 9e l i f t o p [ 0 ] [ 1 ] == \u2019 { \u2019 : 10r e t u r n s e l f . c a l l , 0 11e l i f t o p [ 0 ] [ 1 ] == \u2019 x \u2019 o r t o p [ 0 ] [ 1 ] == \u2019 y \u2019 : 12r e t u r n s e l f . r educe , ( IDENT , [ 0 ] ) 13e l i f t o p [ 0 ] [ 1 ] == \u2019 0 \u2019 o r t o p [ 0 ] [ 1 ] == \u2019 1 \u2019 : 14r e t u r n s e l f . r educe , ( LIT , [ 0 ] ) 15e l i f n e x t == \u2019 ; \u2019 : 16i f f i d < 1 : 17r e t u r n s e l f . s h i f t , None 18e l s e : 19r e t u r n s e l f . r e t , None 20e l i f n e x t == \u2019 i f \u2019 : 21i f f i d < 2 : 22r e t u r n s e l f . s h i f t , None 23e l s e : 24r e t u r n s e l f . r e t , None 25e l i f n e x t == \u2019= \u2019 : 26i f f i d < 3 : 27r e t u r n s e l f . s h i f t , None 28e l s e : 29r e t u r n s e l f . r e t , None 30e l i f n e x t == \u2019== \u2019 : 31i f f i d < 4 : 32r e t u r n s e l f . s h i f t , None 33e l s e : 34r e t u r n s e l f . r e t , None 35e l i f n e x t == \u2019+ \u2019 : 36i f f i d < 5 : 37r e t u r n s e l f . s h i f t , None 38e l s e : 39r e t u r n s e l f . r e t , None 40e l i f n e x t == \u2019\u2217 \u2019 : 41i f f i d < 6 : 42r e t u r n s e l f . s h i f t , None 43e l s e :\n44r e t u r n s e l f . r e t , None 45e l i f n e x t == None : 46i f l e n ( s e l f . s t a c k ) == 1 : 47r e t u r n s e l f . f i n a l , None 48e l s e : 49r e t u r n s e l f . r e t , None 50e l s e : 51r e t u r n s e l f . r e t , None 52e l i f l e n ( t o p ) == 2 : 53i f t o p [ 0 ] [ 1 ] == \u2019 { \u2019 and n e x t == \u2019 } \u2019 : 54r e t u r n s e l f . s h i f t , None 55e l s e : 56n e x t _ f i d = 0 57i f t o p [ 0 ] [ 1 ] == \u2019 w h i l e \u2019 : 58n e x t _ f i d = 6 59e l i f t o p [ 1 ] [ 1 ] == \u2019 ; \u2019 : 60n e x t _ f i d = 1 61e l i f t o p [ 1 ] [ 1 ] == \u2019 i f \u2019 : 62n e x t _ f i d = 2 63e l i f t o p [ 1 ] [ 1 ] == \u2019= \u2019 : 64n e x t _ f i d = 3 65e l i f t o p [ 1 ] [ 1 ] == \u2019== \u2019 : 66n e x t _ f i d = 4 67e l i f t o p [ 1 ] [ 1 ] == \u2019+ \u2019 : 68n e x t _ f i d = 5 69e l i f t o p [ 1 ] [ 1 ] == \u2019\u2217 \u2019 : 70n e x t _ f i d = 6 71r e t u r n s e l f . c a l l , n e x t _ f i d 72e l s e : # l e n ( t o p ) == 3 73i f t o p [ 1 ] [ 1 ] == \u2019= \u2019 : 74r e t u r n s e l f . r educe , ( ASSIGN , [ 0 , 2 ] ) 75e l i f t o p [ 1 ] [ 1 ] == \u2019 i f \u2019 : 76r e t u r n s e l f . r educe , ( IF , [ 2 , 0 ] ) 77e l i f t o p [ 1 ] [ 1 ] == \u2019 ; \u2019 : 78r e t u r n s e l f . r educe , (SEQ , [ 0 , 2 ] ) 79e l i f t o p [ 0 ] [ 1 ] == \u2019 w h i l e \u2019 : 80r e t u r n s e l f . r educe , (WHILE, [ 1 , 2 ] ) 81e l i f t o p [ 0 ] [ 1 ] == \u2019 { \u2019 and t o p [ 2 ] [ 1 ] == \u2019 } \u2019 : 82r e t u r n s e l f . r educe , (BLOCK, [ 1 ] ) 83e l s e : 84i f t o p [ 1 ] [ 1 ] == \u2019+ \u2019 : 85r e t u r n s e l f . r educe , ( OP_P , [ 0 , 2 ] ) 86e l i f t o p [ 1 ] [ 1 ] == \u2019\u2217 \u2019 : 87r e t u r n s e l f . r educe , (OP_M, [ 0 , 2 ] ) 88e l i f t o p [ 1 ] [ 1 ] == \u2019== \u2019 : 89r e t u r n s e l f . r educe , (EQ, [ 0 , 2 ] )"}, {"heading": "I Python implementation of LAMBDA language parser", "text": "1d e f n e x t I n s t r u c t i o n ( s e l f ) : 2f i d , t o p = s e l f . f i d [ \u22121] , s e l f . s t a c k [\u22121] 3n e x t = s e l f . i n p u t [ s e l f . c u r ] i f s e l f . c u r < l e n ( s e l f . i n p u t ) e l s e None 4i f l e n ( t o p ) == 0 : 5r e t u r n s e l f . s h i f t , None 6e l i f l e n ( t o p ) == 1 : 7i f t o p [ 0 ] [ 1 ] == \u2019 l e t \u2019 : 8r e t u r n s e l f . c a l l , 0 9e l i f t o p [ 0 ] [ 1 ] == \u2019 lam \u2019 : 10r e t u r n s e l f . s h i f t , None 11e l i f t o p [ 0 ] [ 0 ] < 0 and t o p [ 0 ] [ 1 ] i n s e l f . a l p h a : 12r e t u r n s e l f . r educe , (VAR, [ 0 ] ) 13e l s e : 14i f n e x t i n s e l f . a l p h a : 15i f f i d == 0 :\n16r e t u r n s e l f . c a l l , 1 17e l s e : 18r e t u r n s e l f . r e t , None 19e l i f n e x t == \u2019= \u2019 o r n e x t == \u2019 . \u2019 : 20r e t u r n s e l f . s h i f t , None 21e l s e : 22i f l e n ( s e l f . s t a c k ) > 1 : 23r e t u r n s e l f . r e t , None 24e l s e : 25r e t u r n s e l f . f i n a l , None 26e l i f l e n ( t o p ) == 2 : 27i f t o p [ 0 ] [ 1 ] == \u2019 l e t \u2019 : 28r e t u r n s e l f . s h i f t , None 29e l i f t o p [ 0 ] [ 1 ] == \u2019 lam \u2019 : 30r e t u r n s e l f . r educe , ( BIND , [ 1 ] ) 31e l i f t o p [ 1 ] [ 1 ] == \u2019= \u2019 : 32r e t u r n s e l f . c a l l , 0 33e l i f t o p [ 0 ] [ 1 ] == BIND : 34r e t u r n s e l f . c a l l , 0 35e l s e : 36r e t u r n s e l f . r educe , ( APP , [ 0 , 1 ] ) 37e l i f l e n ( t o p ) == 3 : 38i f t o p [ 0 ] [ 1 ] == \u2019 l e t \u2019 o r t o p [ 0 ] [ 1 ] == \u2019 lam \u2019 : 39r e t u r n s e l f . c a l l , 0 40e l s e : 41n t = LETEXPR 42i f t o p [ 0 ] [ 1 ] == BIND : 43n t = LAMBDA 44r e t u r n s e l f . r educe , ( n t , [ 0 , 2 ] ) 45e l s e : # l e n ( t o p ) == 4 : 46r e t u r n s e l f . r educe , ( LET , [ 1 , 3 ] )"}, {"heading": "J Miscellaneous", "text": "We present the three-line Python implementation of Quicksort below:\ndef qsort(a):\nif len(a) <= 1: return a return qsort([x for x in a if x<a[0]]) + [x for x in array if x==a[0]] + qsort([x for x in a if x>a[0]])"}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "In this work, we study an important problem: learning programs from input-output<lb>examples. We propose a novel method to learn a neural program operating a<lb>domain-specific non-differentiable machine, and demonstrate that this method<lb>can be applied to learn programs that are significantly more complex than the<lb>ones synthesized before: programming language parsers from input-output pairs<lb>without knowing the underlying grammar. The main challenge is to train the neural<lb>program without supervision on execution traces. To tackle it, we propose: (1)<lb>LL machines and neural programs operating them to effectively regularize the<lb>space of the learned programs; and (2) a two-phase reinforcement learning-based<lb>search technique to train the model. Our evaluation demonstrates that our approach<lb>can successfully learn to parse programs in both an imperative language and a<lb>functional language, and achieve 100% test accuracy, while existing approaches\u2019<lb>accuracies are almost 0%. This is the first successful demonstration of applying<lb>reinforcement learning to train a neural program operating a non-differentiable<lb>machine that can fully generalize to test sets on a non-trivial task.", "creator": "LaTeX with hyperref package"}}}