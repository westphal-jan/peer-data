{"id": "1706.03316", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jun-2017", "title": "Collect at Once, Use Effectively: Making Non-interactive Locally Private Learning Possible", "abstract": "Non - interactive non-terminal Local Differential estimation Privacy (multitap LDP) marriott requires 5.15 data analysts cockettes to collect suffixation data from users through noisy zynga channel at schuh once. polyols In byomkesh this paper, oltan we grundlagen extend the 111s frontiers unionism of dehdasht-e Non - interactive nkoulou LDP learning and financiera estimation lefort from kayama several presides aspects. For morchella learning with smooth generalized linear losses, ermengarde we nantel propose an hallenbeck approximate rijsbergen stochastic gradient refreezes oracle hickam estimated from burghy non - lugs interactive LDP channel, 22.16 using 15-25 Chebyshev savalas expansion. remmy Combined dzhabrail with tri-series inexact gradient 40,625 methods, we hastreiter obtain inflows an efficient wallfisch algorithm uop with lummox quasi - tolmie polynomial swerling sample criteriums complexity bound. agung For kaz\u0131m the high - hemorrhagic dimensional j\u00fcrgens world, madikizela we discover dmca that under $ \\ ell_2 $ - norm assumption selecting on silurians data points, c\u00e9lestin high - davinic dimensional afsana sparse linear regression kibbeh and mean estimation -1.25 can bakhtiar be arktikugol achieved yakshagana with windbag logarithmic dependence on oulipo dimension, husum using random projection sabers and 3.37 approximate mois\u00e9s recovery. slowpokes We tariq also extend rival our methods cavey to prejudged Kernel ridged Ridge Regression. Our adedayo work is dido the urara first one that playthings makes learning nat and scammer estimation yerby possible for 7.7920 a verwilghen broad range of 1963-66 learning lonseny tasks obata under non - interactive LDP fedorenko model.", "histories": [["v1", "Sun, 11 Jun 2017 07:04:50 GMT  (29kb)", "http://arxiv.org/abs/1706.03316v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["kai zheng 0007", "wenlong mou", "liwei wang 0001"], "accepted": true, "id": "1706.03316"}, "pdf": {"name": "1706.03316.pdf", "metadata": {"source": "CRF", "title": "Making Non-interactive Locally Private Learning Possible", "authors": ["Kai Zheng", "Wenlong Mou", "Liwei Wang"], "emails": ["zhengk92@pku.edu.cn", "mouwenlong@pku.edu.cn", "wanglw@cis.pku.edu.cn"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 6.\n03 31\n6v 1\n[ cs\n.L G\n] 1"}, {"heading": "1 Introduction", "text": "Data privacy has become an increasingly important issue in the age of data science. Differential Privacy (DP), proposed in 2006 by Dwork et al.,[11], provide a solid foundation and rigorous standard for private data analysis. Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering [16, 15, 34, 40], machine learning [4, 5, 30, 39], and statistical inference [27, 31]. For more details on DP results, please refer to the excellent monograph written by Dwork and Roth [12]. Intuitively, a DP algorithm uses randomized response to defend against adversary, so that change of one of data points could not be detected.\nDespite the prevailing success of this notion in academia, its applicability in data science practice could be limited. For example, if data analysts just promise to follow the differential privacy constraints, user will not feel their privacy are preserved. The promise could not be validated; the mechanisms are complicated; and even worse: users do not trust the data collector at all. Unfortunately, most of differential privacy algorithms are based on adding noise calibrated to stability of loss function, which essentially requires access to original data.\n\u2217These two authors contributed equally \u2020zhengk92@pku.edu.cn \u2021mouwenlong@pku.edu.cn \u00a7wanglw@cis.pku.edu.cn\nBorrowing ideas from classical wisdom on collecting sensitive survey data [41], Local Differential Privacy (LDP) [22, 9] was proposed as a stronger notion of privacy to resolve this problem. LDP requires each of data points to be passed through a noisy channel during collection. This channel will ensure one can hardly tell anything about the user based on what he have sent. The practical advantage of LDP is obvious: users will be comfortable sending their sensitive information through noisy channels, which are transparent and reliable; additionally, users can choose their own privacy parameters, making it possible to associate with economic value. Therefore, this line of research has attracted lots of attention [8, 9, 19, 1, 18].\nDespite the analogy in definition, the way in which LDP achieves accurate results are fundamentally different from classical DP. Essentially, the information collected from each user is almost completely noisy, from which one needs to obtain accurate results. The only way to do that is to make the independently distributed noise cancel out with each other in some sense. With sand being washed away by waves, golds begin to appear.\nTwo local privacy notions have been discussed in existing literature: the interactive model allows the algorithm to collect data sequentially, and decide what to ask based on information from previously asked users. The non-interactive model, on the contrary, requires all data to be collected at once, with no interactive queries allowed. Apparently the non-interactive model is strictly stronger, and prohibition on interactive queries rules out most of SGD-type approaches, making the problem significantly harder. However, non-interactive LDP is more useful in real-world applications, as opportunities of interactive queries may not be available in most settings.\nIn existing literature, learning and inference under interactive and non-interactive LDP therefore are exhibiting different appearances. In the interactive world, LDP is promised with connection to Statistical Query (SQ) model [25], from its very beginning [24]. SQ algorithms for a wide range of convex ERM problems were proposed by [13], implying good risk bounds for LDP. [9] established matching upper and lower bounds for convex risk minimization problems. On the other hand, very few has been done in the non-interactive setting. Existing works primarily focus on basic estimation problems such as means and discrete densities [8, 7, 1], or some function calculations [21]. Most of important modern learning and inference tasks, including estimation in linear models and convex ERM, are still poorly understood in non-interactive local DP settings.\nFor the high-dimensional world, where d \u226b n while some low-complexity constraints are imposed, we may hope the error induced by privacy constraints to be logarithmically dependent upon d. In classical differential privacy literature, this has been be addressed using different techniques, guarantee error bounds logarithmically dependent on dimension [33, 32]. However, lower bounds have been shown in local privacy model even for high-dimensional 1-sparse mean estimation, ruling out any good guarantees [7]. The lower bound result illustrates fundamental difficulties of local differential privacy. But if we still want to do high-dimensional learning under local privacy, are there additional assumptions that helps?\nTherefore, the starting point of this work lies on making learning possible under the noninteractive LDP setting, which is the hardest yet the most useful. We initiate the first attempt towards a broad range of learning tasks beyond simple distribution estimation. In particular, we investigate two important classes of problems under non-interactive LDP: (1) High-dimensional sparse linear regression and mean estimation; (2) Generalized linear models. Our focus is to design corresponding mechanisms and study their convergence rates with respect to the number and dimension of data. One can also consider optimal mechanisms in terms of privacy parameters like [14], which is of independent interests.\nOur Contributions: In this paper, we propose several efficient algorithms for learning and estimation problems under non-interactive LDP model, with good theoretical guarantees. In the following we summarize our contributions.\n(1) High Dimensional Estimation: One of exciting findings in this paper is about local privacy for high-dimensional data. Roughly speaking, convergence rate with logarithmic dependence on the dimension can be attained under LDP, if we assume data points are \u21132 bounded. This is in sharp contrast with information-theoretic lower bounds for 1-sparse mean estimation for \u2113\u221e bounded data [7]. Valid algorithms are presented for both sparse mean estimation and sparse linear regression, respectively. Intuitively, non-interactivity doesn\u2019t bring about additional difficulties, since the loss functions are quadratic forms. However, if we directly add noise to each of data points and send it to the server, the aggregated noise will lead to linear dependence on the dimension. Thus we adopt the random projection technique, and send the noisy version of projected data to the server. Based on the aggregated information, we can approximately recover the optimal solution via linear inverse problem.\n(2) Learning Smooth Generalized Linear Models: Generalized linear problems which has additional smooth properties (we call the loss with respect to it as smooth generalized linear loss (SGLL), see rigorous definition in section 2) include many common loss functions, such as logistic loss, square loss, etc. Optimizing such losses are intuitively much more difficult in noninteractive LDP model, as the loss can be an arbitrary function wTx. This even makes it difficult for us to obtain an unbiased estimator for objective function, or its gradient. As a result, when we aggregate the loss of noisy data together, it is even hard to ensure it converge to the population loss. Approximation theory techniques are introduced to tackle this problem. In particular, we use polynomials of wTx to approximate nonlinear coefficients of gradients. Chebyshev bases, instead of Taylor series, are used to get faster convergence within an arbitrary domain. Then we are able to build inexact stochastic gradient oracles to arbitrarily specified accuracy. SIGM algorithm in [10] is exploited to find the minimizer with inexact gradients.\nOther Related Work: Local privacy dates back to [41], who uses random responses to protect privacy in surveys. In recent LDP literature, both [8] and [18] studied density estimation methods and their theoretical behaviors in LDP model. Rather than statistical setting in above two work, [1] considered how to produce frequent items and corresponding frequencies of a dataset in local model. Besides, [19] investigated optimality of LDP mechanisms based on information theoretical measures for statistical discrimination.\nApproximation techniques are commonly used in DP literature. [34] employed polynomials for marginal queries. [40] leveraged trigonometric polynomials to answer smooth queries. [43] also used polynomial approximations and get basic convergence results in standard DP model. Besides, the random projection and recovery has also been used in DP learning [23] and local DP histogram estimation [1].\nIn standard DP model, both high-dimensional sparse estimation and generalized linear model have been intensively studied. [26] and [32] considered the convergence of private LASSO estimator under RSC and incoherence assumptions. [33] considered constrained ERM of sparse linear regression, and obtained O\u0303(log d/n2/3) rate using private Frank-Wolfe. Above results assume \u2113\u221e-bounded data. By stronger assumption of \u21132 bounded data, [23] gave a general framework for high dimensional empirical risk minimization (ERM) problem. There are several works to estimate generalized linear model under DP, with a particular emphasis on logistic regression. Objective and output perturbation are used to get low excess risks [4, 5]. Both [2] and [42] considered concrete private algorithms to solve ERM. None of these existing results extends directly to non-interactive LDP setting."}, {"heading": "2 Preliminaries", "text": "Some notations: [p] = {1, 2, \u00b7 \u00b7 \u00b7 , p}. Vectors are written in bold symbol, such as x,w. x represents univariate number, which has no relation with x. For a vector x = [x1, x2, \u00b7 \u00b7 \u00b7 , xd]T , xk represents the power of each element. B2(r) = {x| \u2016x\u20162 6 r}. Denote S+ as the semipositive matrix space, ProjS+(\u00b7) means projecting a matrix to S+ in terms of Frobenius norm (i.e. eliminate all negative eigenvalues). For an univariate function f(x), f (k)(x) represents its k-th derivative, and define \u2225 \u2225f (k) \u2225 \u2225\nT := \u222b 1 \u22121 |f(k+1)(x)|\u221a 1\u2212x2 dx. For the reason of limited space, all omitted proof can be found in the\nsupplementary."}, {"heading": "2.1 Local Differential Privacy", "text": "Here we adopt the LDP definition given in [1].\nDefinition 1. A mechanism Q : V \u2192 Z is said to be (\u01eb, \u03b4)-local differential private or (\u01eb, \u03b4)-LDP, if for any v,v\u2032 \u2208 V, and any (measurable) subset S \u2282 Z, there is\nPr[Q(v) \u2208 S] 6 e\u01eb Pr[Q(v\u2032) \u2208 S] + \u03b4\nJust the same with basic results in DP [12], there are corresponding basic results for LDP:\nLemma 1 (Gaussian Mechanism). If V = {v \u2208 Rd| \u2016v\u20162 6 1}, then Q(v) = v + e is (\u01eb, \u03b4)-LDP, where e \u2208 Rd, and e \u223c N (0, \u03c32Id), \u03c3 = 2 \u221a 2 ln(1.25/\u03b4)/\u01eb.\nLemma 2 (Composition Theorem1). Let Qi : V \u2192 Zi be an (\u01ebi, \u03b4i)-LDP mechanism for i \u2208 [k]. Then if Q[k] : V \u2192 \u220fk i=1Zi is defined to be Q[k](v) = (Q1(v), . . . ,Qk(v)), then Q[k] is ( \u2211k\ni=1 \u01ebi, \u2211k i=1 \u03b4i)-LDP.\nThe following simple mechanism add Gaussian noise to preserve LDP of a vector, which serves as a basic tool in LDP learning and estimation.\nAlgorithm 1 Basic Private Vector mechanism Input: A vector x \u2208 Rd, privacy parameter \u01eb, \u03b4 for LDP Output: Private vector z\n1: Setting \u03c3 =\n\u221a 2 ln(1.25/\u03b4)\n\u01eb 2: if \u2016x\u20162 > 1 then 3: x = x/ \u2016x\u20162 4: end if 5: z \u2190 x+ e, where e \u223c N (0, \u03c32Id)\nTheorem 1. Algorithm 1 preserves (\u01eb, \u03b4)-LDP."}, {"heading": "3 High Dimensional and Non-parametric Learning via Random Pro-", "text": "jections\nIn this section we consider three learning problems under non-interactive LDP: Mean Estimation and Linear Regression in High-dimensions, as well as Kernel Ridge Regression. Using random\n1Note one can also use the advanced composition mechanism [20] with a refined analysis, but the main dependence over n and d will remain nearly the same.\nprojection techniques, we are able to get logarithmic dependence on d in high-dimensional settings, and also to get good guarantees for Kernel version. The first problem is considered in statistical settings, as we need to assume a sparse mean vector. The latter two problems are considered as ERM problems, which can easily be translated to population risk using uniform convergence."}, {"heading": "3.1 High-dimensional Mean Estimation", "text": "In this section, we propose a non-interactive LDP mechanism for high-dimensional sparse mean estimation problem. By assuming \u21132 bounded data points, and \u21131 bounded population mean, we can get error rates with logarithmic dependence on d. Our results are in sharp contrast with the lower bound for \u21132-bounded general mean estimation under standard DP [2], as well as the lower bound for \u2113\u221e-bounded 1-sparse mean estimation under local DP [7]. It can be easily seen that our method extends to mean estimation problem for arbitrary low-complexity constraint set in high dimensions. We state our results in \u21131 setting to keep the arguments clear. Our problem adopts a statistical estimation setting as follows:\n\u21132-bounded sparse mean estimation Suppose there is an unknown distribution D supported on B(0, 1), with \u2016ED(x)\u20161 \u2264 \u039b. The \u21132-bounded sparse mean estimation problem requires us to produce an estimator \u03b8\u0302 that makes \u2016\u03b8 \u2212 ED(x)\u20162 small with high probability.\nAlgorithm 2 LDP \u21131 Constrained Mean Estimation Input: x1,x2, \u00b7 \u00b7 \u00b7 ,xn \u223c i.i.d.D Output: Estimator z Set p = \u2308\u039b\u01eb\u221an\u2309, and m = \u230818 log 1\u03b4 \u2309 Sample G \u223c 1\u221apN (0, 1)p\u00d7d. for User i do\nCollect yi = Gxi + ri, with ri \u223c i.i.d.N (0, 2 log(1.25/\u03b4)\u01eb2 Ip)\nend for for j \u2208 {1, 2, \u00b7 \u00b7 \u00b7 ,m} do\nSj = { 1 + (j\u22121)nm , 2 + (j\u22121)n m , \u00b7 \u00b7 \u00b7 , jn m } . Let \u00b5j = 1\n|Sj | \u2211\ni\u2208Sj yi. end for Let M = {\u00b51,\u00b52, \u00b7 \u00b7 \u00b7 ,\u00b5m}. for j \u2208 {1, 2, \u00b7 \u00b7 \u00b7 ,m} do\nLet rj = min { r : |B\u21131(\u00b5j , r) \u2229M| \u2265 m2 }\n. end for Let j\u2217 = argminj rj, and u = \u00b5j\u2217 Solve the following convex program:\nargmin z\n\u2016z\u20161\ns.t.\u2016Gz \u2212 u\u20161 \u2264 100p log(nd/\u03b4)\n\u01eb\n\u221a\nm\nn\n(1)\nIn Algorithm 2 we describe our data collection procedure and estimation algorithm. We are primarily using two techniques: random projection and recovery from low-complexity structures; median-of-mean estimator to boost failure probability. The privacy argument is directly implication\nof Theorem 1. Intuitively, adding noise to each entry of mean vector will result in error rate\u2019s linear dependence on d. Thus we adopt the random projection technique to send a compressed version of data vector through the noisy channel. This locally private estimation procedure can be viewed as a variant of noisy compressed sensing, where \u21132 recovery rate is fundamentally controlled by the Gaussian Mean Width of constraint set [38]. Though the distribution has bounded support, the concentration for mean estimation is dimension-dependent, while dimension-independent Markov Inequalities hold. To tackle this problem, we employ Median-of-Mean estimator to get exponential tails [17].\nWe first give the following bound on the error in projected space.\nLemma 3. Let x1,x2, \u00b7 \u00b7 \u00b7 ,xn \u223c i.i.d.D with \u00b5 = ED[x] and supp(D) \u2286 B(0, 1). Let G and {yi}ni=1 defined in the above procedure. For each of group Sj fixed, we have the following with probability 2/3:\n\u2225 \u2225 \u2225 1 |Sj | \u2211\nyi\u2208Sj yi \u2212G\u00b5\n\u2225 \u2225 \u2225\n1 \u2264 O\n(\np log(nd)\n\u01eb \u221a |Sj |\n)\n(2)\nThe aggregation step in Algorithm 2 is a high-dimensional generalization of Median-of-Mean estimator used in heavy-tailed statistics. The tail properties are guaranteed in the following lemma:\nLemma 4 (Proposition 9 in [17]). Suppose in metric space X , a set of points M = [\u03b81,\u03b82, \u00b7 \u00b7 \u00b7 ,\u03b8m] \u223c i.i.d.D, with Pr[dX (\u03b8i,\u03b8) \u2265 \u01eb] \u2264 23 . Let \u03b8\u0302 be generated from the following procedure: ri = min {\nr : |BX (\u03b8i, r) \u2229M| \u2265 m2 } ,and \u03b8\u0302 = argmin\u03b8i ri. Then we have:\nPr[dX (\u03b8\u0302,\u03b8) \u2265 3\u01eb] \u2264 e\u2212 m 18\nSince the original data are i.i.d. samples from underlying distribution, small group with fixed indices should also be i.i, d.. Therefore \u00b51,\u00b52, \u00b7 \u00b7 \u00b7 ,\u00b5k are i.i.d.. Combining Lemma 3 and Lemma 4 we get the following result:\nCorollary 1. The vector u constructed in Algorithm 2 satisfies the following with probability 1\u2212 \u03b4:\n\u2016u\u2212G\u00b5\u20161 \u2264 O ( p log(nd/\u03b4)\n\u01eb\n\u221a\nm\nn\n)\n(3)\nThen we turn to the recovery of original mean estimator. The primary tool we are using are General M\u2217 bound in [38].\nLemma 5 (Theorem 6.2 in [38], High Probability Version). For unknown vector x \u2208 K \u2286 Rd, let G \u223c 1\u221apN (0, 1)p\u00d7d. Noisy vector \u03bd \u2208 Rp with \u2016\u03bd\u20161 \u2264 \u03c3. Let y = Gx+ \u03bd. By solving the following optimization problem:\nargmin x\u2032 \u2016x\u2032\u2016K s.t. \u2016Gx\u2032 \u2212 y\u20161 \u2264 \u03c3 (4) where \u2016\u00b7\u2016K denotes the Minkowski functional of K. Then we can get the following with probability 1\u2212 \u03b4\n\u2016x\u2212 x\u2032\u20162 \u2264 O ( w(K) + \u03c3 + log 1\u03b4\u221a p )\nwhere w(K) denotes the Gaussian width of K.\nBy putting these results together we get the bound on estimation loss:\nTheorem 2. Algorithm 2 outputs z satisfying the following with probability 1\u2212 \u03b4:\n\u2016z \u2212 \u00b5\u20162 \u2264 O ( log nd\n\u03b4\n\u221a\nlog 1\n\u03b4\n(\n\u039b2 \u01eb2n\n) 1 4 )"}, {"heading": "3.2 Sparse Linear Regression", "text": "In this section, we consider empirical loss of sparse linear regression, i.e. L(w;D) = 12n \u2211n i=1(x T i w\u2212 yi) 2, where D = {(xi, yi)|i \u2208 [n]}, \u2016xi\u20162 6 1, yi \u2208 [\u22121, 1]. 2. Definew\u2217 = argminw\u2208C L(w;D), where C = {w| \u2016w\u20161 6 1}. We want to obtain a vectorwpriv \u2208 C within non-interactive LDP model, such that the empirical excess risk L(wpriv;D) \u2212 L(w\u2217;D) has polynomial dependences on log d and 1n .\nAs in the case of high-dimensional mean estimation, directly manipulating in the original high dimensional feature space will introduce large noise, hence we use a sub-Gaussian random matrix \u03a6 \u2208 Rm\u00d7d to project original data (i.e. vectors in Rd) into the low dimensional space (i.e. Rm) first, then perturb each data in low dimensional space (i.e. Basic Private Vector mechanism given in Algorithm 1) which protects local privacy, and send it to the server.\nHaving obtained private synopsis, the server then reconstruct an unbiased estimator for objective function according to these private synopsis. We subtract a quadratic term to ensure unbiasedness and project to PSD matrices to preserve convexity. To show good approximation guarantee, we make use of RIP bounds for random projection. As the loss function is determined by inner products between w and data, it could be uniformly preserved in projected space, which guarantees the accuracy of solution estimated with local privacy. Apparently, our methods also imply bounds with general low-complexity constraint set that preserves RIP.\nOur private learning mechanism is given in Algorithm 3 and any random projection matrix can be used here. The privacy argument directly follows from Private Vector Mechanism and composition.\nAlgorithm 3 LDP \u21131 Constrained Linear Regression Input: Personal data (x, y), parameter \u01eb, \u03b4, projection matrix \u03a6 \u2208 Rd\u00d7m Output: Learned classifier wpriv \u2208 Rd 1: for Each user i = 1, . . . , n do 2: zi \u2190 Basic Private Vector (\u03a6Txi, \u01eb/2, \u03b4/2) 3: vi \u2190 Basic Private Vector (yi, \u01eb/2, \u03b4/2) 4: end for\n5: Setting Z = [z1, \u00b7 \u00b7 \u00b7 ,zn]T , \u03c3 = 2 \u221a 2 ln(2.5/\u03b4)\n\u01eb , Q = ProjS+(Z TZ \u2212 n\u03c32Im),v = [v1, \u00b7 \u00b7 \u00b7 , vn]T\n6: wpriv \u2190 argminw\u2208C L\u0302(w;Z,v), where L\u0302(w;Z,v) := 12n(\u03a6 Tw)TQ(\u03a6Tw)\u2212 1nvTZ\u03a6Tw\nIn fact, as original data is in L2 ball, and random projection preserves norms with high probabilty, hence steps 2-4 in Algorithm 1 will be executed with very low probability.\nDenote the true objective function in low dimensional space L\u0304(w; X\u0304,y) := 12n \u2225 \u2225X\u0304\u03a6Tw \u2225 \u2225 2 \u2212 1 ny\nT X\u0304\u03a6Tw, where X\u0304 = [x1, \u00b7 \u00b7 \u00b7 ,xn]T\u03a6,w \u2208 C. Let w\u0302\u2217 := argminw\u2208C L\u0304(w; X\u0304,y). The following lemma gives the accuracy of private solution wpriv when reduced into low dimensional space:\nLemma 6. Under the assumptions made in this section, given projection matrix \u03a6, with high probability over the randomness of private mechanism, we have\nL\u0304(wpriv; X\u0304,y)\u2212 L\u0304(w\u0302\u2217; X\u0304,y) 6 O\u0303 ( \u221a m\nn\u01eb2\n)\n(5)\nNow, combined with RIP bound for random projection, we can move on to prove the empirical excess risk of sparse linear regression:\n2Our methods suits to any radius of x and y.\nTheorem 3. Under the assumption in this section, set m = \u0398 ( \u221a n\u01eb2 log d ) , then with high proba-\nbility , there is\nL(wpriv)\u2212 L(w\u2217) = O\u0303 ( ( log d\nn\u01eb2\n)1/4 )\nNote [33] assume data is in L\u221e ball, while both [23] and ours assume data is in L2 ball. However, in LDP model, [7] show it was impossible to obtain polynomial dependences over log d for \u21130 mean estimation problem if data is in L\u221e ball."}, {"heading": "3.3 Infinite Dimension: Kernel Ridge Regression", "text": "Previous method mainly applies to data with finite dimensional features. However, it is common to use kernel trick in practice. This brings about new difficulties for LDP learning, as we could not add noise in the Hilbert space. In this subsection, we take kernel ridge regression as an example to show how to use Random Fourier Features (RFF) [29] to deal with such cases caused by shift-invariant kernels (i.e. k(x,y) = k(x\u2212 y)). Note our technique also suits to similar problems.\nFix a shift-invariant kernel k(\u00b7, \u00b7), denote the Hilbert space implicitly defined as H, and the corresponding feature map as \u03a6 : Rd \u2192 H. Let the Hilbert space corresponding to the random Fourier feature map be H\u0302 \u2282 Rdp , and its feature map \u03a6\u0302 : Rd \u2192 H\u0302, where dp is the RFF projection dimension. Given a subset X \u2282 Rd and data D = {(xi, yi)|xi \u2208 X , i \u2208 [n]}, for any f \u2208 H, g \u2208 H\u0302, define loss functions in H and H\u0302 as follows:\nLH(f) := C\n2n\n\u2211\ni\n\u2225 \u2225fT\u03a6(xi)\u2212 yi \u2225 \u2225\n2 2 +\n1 2 \u2016f\u20162H (6)\nLH\u0302(g) := C\n2n\n\u2211\ni\n\u2225 \u2225 \u2225 gT \u03a6\u0302(xi)\u2212 yi \u2225 \u2225 \u2225 2\n2 +\n1 2 \u2016g\u20162 H\u0302 (7)\nwhere C is the regularization parameter. Denote f\u2217 = argminf\u2208H LH(f), g \u2217 = argming\u2208H\u0302 LH\u0302(g), G as the Lipschitz constant of square loss, which depends on the bounded norm of features. Kernel ridge regression try to optimize formula (6), while after using RFF, we try to solve formula (7) in non-interactive LDP model, which can be easily tackled with similar mechanisms like sparse linear regression above. Borrow the key result in [30] (restated in lemma 7 below), which used RFF to design private mechanims for SVM in DP model, it becomes easy to prove guarantees for kernel ridge regression in our setting (see Corollary 2).\nLemma 7 ([30]). Suppose dual variables with respect to f\u2217, g\u2217 are L1 norm bounded by some r > 0, and supx1,x2\u2208X |\u03a6(x1)T\u03a6(x2)\u2212(\u03a6\u0302(x1))T \u03a6\u0302(x2)| 6 \u03b3, then there is supx\u2208X |\u03a6(x)T f\u2217\u2212(\u03a6\u0302(x))T g\u2217| 6 r\u03b3 + 2 \u221a (CG+ r/2)r\u03b3. Corollary 2. Algorithm 4 satisfies (\u01eb, \u03b4)-LDP, and by setting dp = O\u0303 (\u221a dn\u01eb2 ) , with high probability, there is\nLH\u0302(w\u0302 priv)\u2212LH(f\u2217) 6 O\u0303\n(\n(\nd\nn\u01eb2\n)1/4 )\nsup x\u2208X\n|\u03a6(x)T f\u2217\u2212(\u03a6\u0302(x))T w\u0302priv| 6 O\u0303 ( ( d\nn\u01eb2\n)1/8 )\nAlgorithm 4 LDP kernel mechanism Input: Personal data (xi, yi), i \u2208 [n], random feature\u2019s dimension dp, shift-invariant kernel k(x1,x2) = k(x1 \u2212 x2) with Fourier transform f(s) = 12\u03c0 \u222b e\u2212js Txk(x)dx, privacy parame-\nter \u01eb, \u03b4 Output: Private output w\u0302priv \u2208 Rdp 1: Draw i.i.d. samples s1, s2, . . . , sdp \u2208 Rd from f(s) and b1, b2, . . . , bdp \u2208 R from the uniform\ndistribution on [0, 2\u03c0] 2: for i = 1, . . . , n do 3: Construct low dimensional random feature \u03a6\u0302(xi) = \u221a\n1 dp\n[\ncos(sT1 xi + b1), . . . , cos(s T dp xi + bdp)\n]\u2032 \u2208\nC\u0302 := [ \u2212 \u221a 1 dp , \u221a 1 dp ]dp \u2282 Rdp\n4: zi \u2190 Basic Private Vector (\u03a6\u0302(xi), \u01eb/2, \u03b4/2) 5: vi \u2190 Basic Private Vector (yi, \u01eb/2, \u03b4/2) 6: end for\n7: Setting Z = [z1, \u00b7 \u00b7 \u00b7 ,zn]T , \u03c3 = 2 \u221a 2 ln(2.5/\u03b4)\n\u01eb , Q = ProjS+(Z TZ \u2212 n\u03c32Idp),v = [v1, \u00b7 \u00b7 \u00b7 , vn]T\n8: w\u0302priv \u2190 argminw\u0302 L\u0302(w\u0302;Z,v), where L\u0302(w\u0302;Z,v) := 12nw\u0302 TQw\u0302 \u2212 1nvTZw\u0302"}, {"heading": "4 Learning Smooth Generalized Linear Model", "text": "In this section, we consider learning smooth generalized linear model in non-interactive LDP setting. Non-interactive LDP learning for this problem is essentially difficult, as it is even hard to obtain an unbiased estimator of gradient. We resolve this problem using Chebyshev polynomial expansion, which requires additional smoothness assumptions. Fortunately these assumptions are naturally satisfied by a broad range of learning tasks.\nWe will first define the Smooth GLM loss family with appropriate assumptions. Our definition could be shown with connection to exponential family GLM, which is commonly used in machine learning. We also illustrate our algorithm and guarantees with logistic regression.\nDefinition 2. (Absolutely Smooth Functions) We say that an univariate function h(x) is absolutely smooth, if for any r > 0, f(x) := h(rx) satisfies the following properties: there exist functions \u00b51(k; r), \u00b52(k; r), which are polynomial on k and \u00b52(k; r) = O(kr), such that for any k \u2208 N+, there is:\n(1) f(x), f \u2032(x), . . . , f (k\u22121)(x) are absolutely continuous on [\u22121, 1];\n(2) \u2225 \u2225f (k)(x) \u2225 \u2225 T 6 \u00b51(k; r) \u00b7 \u00b52(k; r)k.\nDefinition 3. (Smooth Generalized Linear Loss, SGLL) A loss function \u2113(w;x, y), is called smooth generalized linear loss, if for any given data (x, y), \u2113(w;x, y) is convex and \u03b2-smooth with respect to w, and there exist absolutely smooth functions h1(x), h2(x), such that \u2113(w;x, y) = \u2212yh1(xTw)+ h2(x Tw).\nIt will be convenient to consider population risk directly. Now, we adopt standard setting of learning problems, where each data point (x, y) is drawn from some underlying unknown distribution D and \u2016x\u20162 6 1. Given a SGLL \u2113(w;x, y), the population loss is defined as L(w) := E(x,y)\u223cD\u2113(w;x, y).\nFor simplicity, instead of assuming w belongs to B2(r), we use the following equivalent notation: \u2113(w;x, y) = \u2212yh1(rxTw) + h2(rxTw), and the constraint set for w is C = B2(1). Denote G(w;x, y) = \u2207\u2113(w;x, y) = rm(w;x, y)x, where m(w;x, y) = h\u20322(rxTw) \u2212 yh\u20321(rxTw). Suppose E(x,y)\u223cD[\u2016G(w;x, y)\u2212 g(w)\u201622] 6 \u03c320, where g(w) = \u2207L(w). This is a common assumption in stochastic optimization literature, such as [3].\nGiven any \u03b1 > 0, we hope to design a noninteractive local DP mechanism with low sample complexity, such that the final output point wpriv satisfies L(wpriv)\u2212 L(w\u2217) 6 \u03b1.\nFor GLM loss functions, it is easy to see that the stochastic gradient evaluated on w with data point xi is at the same direction with xi. So adding isotropic noise to xi provides \"unbiased\" information about direction of stochastic gradient. However, the magnitude is a nonlinear function of wTxi, making it hard for SGD even to converge to population minimizer. This is why we seek to find polynomial approximation of the magnitude of gradients.\nTo estimate the magnitude of gradients, we use Chebyshev polynomials to approximate nonlinear univariate function fi(x) = h \u2032 i(rx), where x \u2208 [\u22121, 1]. For brevity of notations, we just use f(x) to represent either f1(x) or f2(x). Denote the Chebyshev approximation with degree p as f\u0302p(x) = 1 2 + \u2211p k=1 akTk(x), where Tk(x) is the k-th Chebyshev polynomial, and ak = 2 \u03c0 \u222b 1 \u22121 f(x)Tk(x)\u221a 1\u2212x2 dx is the corresponding coefficient. According to existing results about Chebyshev approximations and some calculations, we have the following lemma:\nLemma 8. Given any \u03b1 > 0, by setting k = c ln 1\u03b1 , p = \u2308k + e\u00b52(k; r)\u2309, where c is a constant, we have \u2225 \u2225 \u2225 f\u0302p(x)\u2212 f(x) \u2225 \u2225 \u2225\n\u221e 6 \u03b1\nThe Chebyshev approximations with degree p for fi(x) (i = 1, 2) are denoted as f\u0302ip(x) = 1 2 + \u2211p k=1 aikTk(x) = \u2211p k=0 cikx k, where cik is the coefficient of term x k. Now we approximate m(w;x, y) and G(w;x, y) as follows:\nm\u0302(w;x, y) := \u2212 yf\u03021p(rxTw) + f\u03022p(rxTw)\n=\np \u2211\nk=0\n(c2k \u2212 c1ky)(rxTw)k\nG\u0302(w;x, y) :=rm\u0302(w;x, y)x\nWith these approximations, we state our mechanism in Algorithm 5, where Basic Private Vector mechanism is given in Algorithm 1. Note an important trick in Step 6-8 of Algorithm 5, is that: we run basic private mechanism p times, to obtain fresh private copies of the same vector x, which are then used to calculate an unbiased estimation of G\u0302(w;x, y) with variance as low as possible (i.e. line 8 in Algorithm 6).The LDP property of Algorithm 5 is given as follows: The privacy proof directly follows from Basic Vector Mechanism and Composition Theorem.\nTheorem 4. LDP SGLD Mechanism 5 preserves (\u01eb, \u03b4)-LDP.\nHaving obtained the private synopsis sent by all uers, now the server can construct a stochastic inexact gradient oracle (defined in Defintion 4) for any point w \u2208 C, as stated in Algorithm 6.\nDefinition 4. [10] For an objective function f(w), a (\u03b3, \u03b2, \u03c3) stochastic oracle returns a turple\nAlgorithm 5 LDP SGLD Mechanism - Collection\nInput: Personal data (x, y), expansion order p, privacy parameter \u01eb, \u03b4 Output: Private synopsis b = {zyi,zj |i \u2208 {0} \u222a [p], j \u2208 [p(p+ 1)/2]} sent to the server 1: Setting \u01eby = \u01eb 4(p+1) , \u03b4y = \u03b4 4(p+1) , \u01eb1 = \u01eb p(p+1) , \u03b41 = \u03b4 p(p+1)\n2: z0 \u2190 Basic Private Vector(x, \u01eb/4, \u03b4/4) 3: for i = 0, 1, . . . , p do 4: zyj \u2190 Basic Private Vector(y, \u01eby , \u03b4y) 5: end for 6: for j = 1, . . . , p(p+1)2 do 7: zj \u2190 Basic Private Vector(x, \u01eb1, \u03b41) 8: end for\n(F\u03b3,\u03b2,\u03c3(w; \u03be), G\u03b3,\u03b2,\u03c3(w; \u03be)), such that:\nE\u03be[F\u03b3,\u03b2,\u03c3(w; \u03be)] = f\u03b3,\u03b2,\u03c3(w)\nE\u03be[G\u03b3,\u03b2,\u03c3(w; \u03be)] = g\u03b3,\u03b2,\u03c3(w)\nE\u03be[\u2016G\u03b3,\u03b2,\u03c3(w; \u03be)\u2212 g\u03b3,\u03b2,\u03c3(w)\u20162] 6 \u03c32\n0 6 h(v,w) 6 \u03b2\n2 \u2016v \u2212w\u20162 + \u03b3,\u2200v,w \u2208 C\nwhere h(v,w) = f(v)\u2212 f\u03b3,\u03b2,\u03c3(w)\u2212 \u3008g\u03b3,\u03b2,\u03c3(w),v \u2212w\u3009.\nAlgorithm 6 LDP SGLD Mechanism - Learning Input: Private synopsis b = {zy,zj |j \u2208 {0} \u222a [p(p + 1)/2]} of each user, public coefficients {c1k, c2k|k \u2208 {0} \u222a [p]}, initial point w1 Output: Learned classifier wpriv\n1: for s = 1, . . . , n do 2: \\\\ Construct stochastic inexact gradient 3: \\\\ Denote the private synopsis of user s as b above for abbreviation 4: Set t0 = 1 5: for j = 1, . . . , p do 6: tj = \u220fj(j+1)/2 i=j(j\u22121)/2+1(w T s zi) 7: end for 8: G\u0303(ws; b) \u2190 ( p \u2211\nk=0\n(c2k \u2212 c1kzyj)tkrk+1 ) z0\n9: \\\\ One update via SIGM 10: Run one iteration of SIGM algorithm with G\u0303(ws, b) and obtain ws+1 11: end for 12: Set wpriv := wn+1\nFor any (x, y) in the domain, as loss function \u2113(w;x, y) is convex and \u03b2-smooth with respect to w, we can prove the following lemma:\nLemma 9. For any \u03b3 > 0, setting k = c ln 4r\u03b3 , p = \u2308k + 2\u00b52(k; r)\u2309, then Algorithm 6 outputs a (\u03b3, \u03b2, \u03c3) stochastic oracle defined in Definition 4, where \u03c3 = O\u0303 ( \u03c30 + \u03b3 + p2p+1(4r)p+1\n\u01ebp+2\n)\n.\nBased on above (\u03b3, \u03b2, \u03c3) stochastic oracle, and the algorithm proposed in SIGM paper [10] (omitted here, due to the limitation of space), our complete learning algorithm is given in Algorithm 6. Before proving our sample complexity, we state the basic convergence result of SIGM algorithm:\nLemma 10 ([10]). Assume a function f(w) (suppose constrain set is W) is endowed with a (\u03b3, \u03b2, \u03c3) stochastic oracle, then the sequence wk (corresponds to yk in the original paper) generated by the SIGM algorithm satisfies:\nE[f(wk)]\u2212 f(w\u2217) 6 O ( \u03c3\u221a k + \u03b3 )\nwhere expectation is over the randomness of the stochastic oracle and w\u2217 = argminw\u2208W f(w).\nThe accuracy results directly follows from the quality of inexact stochastic gradient oracle we constructed, and the convergence result of SIGM.\nTheorem 5. Consider smooth generalized linear loss. For any setting \u03b1 > 0, by setting \u03b3 = \u03b12 , k = c ln 4r\u03b3 , p = \u2308k + 2\u00b52(k; r)\u2309 in Algorithm 5, 6, if\nn > O\n(\n( 8r\n\u03b1 )4r ln ln(8r/\u03b1)\n(\n4r\n\u01eb\n)2cr ln(8r/\u03b1)+2 ( 1\n\u03b12\u01eb2\n)\n)\n,\nwe can achieve loss guarantee L(wpriv)\u2212 L(w\u2217) 6 \u03b1\nAs we can see, learning in non-interactive LDP model is more difficult than interactive form, especially when loss is highly nonlinear, we even can not obtain an unbiased estimation either for objective function or gradients. However, our method shows it possible to learn smooth GLM with quasi-polynomial sample complexity."}, {"heading": "4.1 Example: Learning Logistic Regression", "text": "Either from the view of exponential family generalized linear model or the concrete loss function, it is not difficult to see logistic loss belongs to SGLL. For example, in logistic regression, \u2113(w;x, y) = log(1+ e\u2212yw Tx) = \u2212\n(y 2w Tx )\n+ (\n1 2w Tx+ ln(1 + e\u2212w Tx)\n)\n. So we let h1(x) = x 2 , h2(x) = x 2 + ln(1+\ne\u2212x). As we know logistic loss is convex and \u03b2-smooth for some parameter \u03b2, and the absolutely smooth property of linear function is obvious, hence once we prove f(x) = ln(1+ e\u2212x) is absolutely smooth, then logistic loss satisfies the definition of SGLL. Proposition 1. f(x) = ln(1 + e\u2212x) is absolutely smooth with \u00b51(k; r) = r \u221a 4k\u03c03, \u00b52(k; r) = rk e\nHence, we can use private mechanisms (5,6) to learn logistic regression.\nTheorem 6. Consider Logistic regression problem with \u2113(w;x, y) = log(1+ exp(\u2212ywTx)) For any \u03b1 > 0, by setting \u03b3 = \u03b12 , k = c ln 4r \u03b3 , p = \u2308k+2\u00b52(k; r)\u2309, if n > O ( (8r\u03b1 ) 4r ln ln(8r/\u03b1) ( 4r \u01eb )2cr ln(8r/\u03b1)+2 ( 1 \u03b12\u01eb2 ) ) in Algorithm 5, 6, we can achieve L(wpriv)\u2212 L(w\u2217) 6 \u03b1."}, {"heading": "5 Conclusions", "text": "In this paper, we consider how to design efficient algorithms for common learning and estimation problems under non-interactive LDP model. In particular, for sparse linear regression and mean\nestimation problem, we propose efficient algorithms and prove the polynomial dependence of excess risk or square error over log d and 1n , which is exactly to be expected in high dimensional case. We also extend our methods to nonparametric case and show good bounds for Kernel Ridge Regression.\nFor more difficult smooth generalized linear loss optimization problems, we use private Chebyshev approximations to estimate gradients of the objective loss, combined with existing inexact gradient descent methods to obtain final outputs. The sample complexity of our mechanism is quasi-polynomial with respect to 1\u03b1 , where \u03b1 is the desired population excess risk.\nAn interesting open problem is whether our theoretical guarantees are optimal. If not, how to improve them while preserving the efficiency in non-interactive LDP model. We think these problems are critical to understand LDP in the future."}, {"heading": "A Appendix", "text": "A.1 Omitted Proofs in Section 3\nLemma 3. Let x1,x2, \u00b7 \u00b7 \u00b7 ,xn \u223c i.i.d.D with \u00b5 = ED[x] and supp(D) \u2286 B(0, 1). Let G and {yi}ni=1 defined in the above procedure. For each of group Sj fixed, we have the following with probability 2/3:\n\u2225 \u2225 \u2225 1 |Sj | \u2211\nyi\u2208Sj yi \u2212G\u00b5\n\u2225 \u2225 \u2225\n1 \u2264 O\n(\np log(nd)\n\u01eb \u221a |Sj |\n)\n(8)\nProof. Apparently 1|Sj | \u2211 i\u2208Sj ri \u223c N (0, 2 log(1.25/\u03b4) |Sj |\u01eb2 Id). So we have \u2016 1 |Sj | \u2211 i\u2208Sj ri\u20161 \u2264 O ( p logn \u01eb \u221a |Sj | ) with probability 19 . We then turn to bound the loss incurred by random sample of data.\nE\n\u2225 \u2225 \u2225 \u00b5\u2212 1|Sj | \u2211\ni\u2208Sj xi\n\u2225 \u2225 \u2225 2 = 1 |Sj| d \u2211\nl=1\nvar(x1l)\n\u2264 1|Sj| d \u2211\nl=1\nE[x21l] \u2264 1\n|Sj | .\n(9)\nAccording to Markov Inequality, we have\nP\n\n\n\n\u2225 \u2225 \u2225 \u00b5\u2212 1|Sj| \u2211\ni\u2208Sj xi\n\u2225 \u2225 \u2225 2 \u2265 9|Sj|\n\n\n \u2264 1 9\nGiven x1,x2, \u00b7 \u00b7 \u00b7 ,xn fixed under this event, we can easily derive upper bounds on entries of G(\u00b5 \u2212 1|Sj | \u2211 i\u2208Sj xi): for g \u223c N (0, Id) and q = \u00b5 \u2212 1 |Sj | \u2211 i\u2208Sj xi, we have |gTq| \u2264 12 \u221a log d |Sj | with probability 1\u2212 19d . By union bound we have the following with probability 29 :\n\u2225 \u2225 \u2225 G(\u00b5\u2212 1|Sj| \u2211\ni\u2208Sj xi)\n\u2225 \u2225 \u2225\n1 \u2264 O\n( \u221a\np log d\n|Sj|\n)\n.\nPutting the two inequalities together using union bound, we get the result.\nLemma 6. Under the assumptions made in Section 3.2, given projection matrix \u03a6, with high probability over the randomness of private mechanism, we have\nL\u0304(wpriv; X\u0304,y)\u2212 L\u0304(w\u0302\u2217; X\u0304,y) 6 O\u0303 ( \u221a m\nn\u01eb2\n)\n(10)\nProof. Note, once we prove the uniform convergence of |L\u0302(w;Z,v) \u2212 L\u0304(w; X\u0304,y)| 6 O ( \u221a m n\u01eb2 )\nfor any w \u2208 C, then the conclusion holds directly. Now, we will prove the uniform convergence. Note Z = X\u0304 + E, where E \u2208 Rn\u00d7m, and each entry eij \u223c N (0, \u03c32), v = y + r, where r \u223c N (0, \u03c32In). Denote w\u0304 = \u03a6Tw.\n\u2223 \u2223 \u2223 L\u0302(w;Z,v) \u2212 L\u0304(w; X\u0304,y) \u2223 \u2223 \u2223\n=\n\u2223 \u2223 \u2223 \u2223 1 2n w\u0304T (Q\u2212 X\u0304T X\u0304)w\u0304 \u2212 1 n ( vTZw\u0304 \u2212 yT X\u0304w\u0304 ) \u2223 \u2223 \u2223 \u2223\n6 1\n2n\n\u2225 \u2225Q\u2212 X\u0304T X\u0304 \u2225 \u2225 2 \u2016w\u0304\u201622 +\n1\nn\n\u2223 \u2223vTZw\u0304 \u2212 yT X\u0304w\u0304 \u2223 \u2223\n6 1\n2n\n\u2225 \u2225Q\u2212 X\u0304T X\u0304 \u2225 \u2225 F \u2016w\u0304\u201622 +\n1 n |vTZw\u0304 \u2212 yT X\u0304w\u0304|\n6 12n\n\u2225 \u2225ZTZ \u2212 n\u03c32Im \u2212 X\u0304T X\u0304 \u2225 \u2225 F \u2016w\u0304\u201622 + 1n |vTZw\u0304 \u2212 yT X\u0304w\u0304|\n6 1\n2n\n\u2225 \u2225ETE \u2212 n\u03c32Im \u2225 \u2225 F \u2016w\u0304\u201622 +\n1\nn\n\u2225 \u2225X\u0304TE \u2225 \u2225 F \u2016w\u0304\u201622 +\n1\nn\n( \u2225 \u2225ETy \u2225 \u2225\n2 +\n\u2225 \u2225X\u0304Tr \u2225 \u2225\n2 +\n\u2225 \u2225ETr \u2225 \u2225\n2\n)\n\u2016w\u0304\u20162\nFrom the property of random projection, we know \u2016w\u0304\u20162 6 1 with high probability. Besides, as each entry in E is i.i.d. Gaussian, and E[ETE] = n\u03c32Im, thus we have 1 2n \u2225 \u2225ETE \u2212 n\u03c32Im \u2225 \u2225 2 6\nO\n(\n\u03c3 \u221a\nlogm n\n)\nwith high probability according to lemma 11, hence 12n \u2225 \u2225ETE \u2212 n\u03c32Im \u2225 \u2225 F 6 O(\u03c3\n\u221a\nm logm n )\nwith high probability. As 1n2 \u2225 \u2225X\u0304TE \u2225 \u2225 2 F = 1n2 \u2211m j=1( \u2211m i=1(q T j ei) 2), where qj ,ei are the j-th and i-th column of X\u0304 and E respectively. For each j \u2208 [m], 1 n2 \u2211m i=1(q T j ei) 2 obeys Chi-square distribution (with some scaling), thus with high probability, 1 n2 \u2211m i=1(q T j ei) 2 6 O ( m\u2016qj\u20162\u03c32 n2 ) . Therefore, by union bound, we have\n1 n2 \u2211m j=1( \u2211m i=1(q T j ei) 2) 6 O\n( m \u2211\nj\u2016qj\u2016 2\u03c32\nn2\n)\n= O ( m\u03c32\nn\n)\n, as \u2211 j \u2016qj\u20162 = \u2225 \u2225X\u0304 \u2225 \u2225 2 F 6 n. Hence, there\nis 1n \u2225 \u2225X\u0304TE \u2225 \u2225 F 6 O\n(\n\u221a\nm\u03c32\nn\n)\nwith high probability. Using similar augument, we have 1n \u2225 \u2225E\u0304Ty \u2225 \u2225 2 6\nO\n(\n\u221a\nm\u03c32\nn\n)\n, 1n \u2225 \u2225E\u0304T r \u2225 \u2225 2 6 O\n(\n\u221a\nm\u03c32\nn\n)\nwith high probability. For 1n \u2225 \u2225X\u0304T r \u2225 \u2225, according to matrix\nconcentration inequality (Theorem 4.1.1 in [36]), we have 1n \u2225 \u2225X\u0304Tr \u2225 \u2225 2 6 O\n(\n1\u221a n\n)\n.\nCombine all these results together, we obtain the desired conclusion.\nLemma 11 ([37]). Suppose x \u2208 Rd be a random vector satisfies E[xxT ] = Id. Denote \u2016x\u2016\u03c61 = M , where \u2016\u00b7\u2016\u03c81 represents Orlicz \u03c81-norm. Let x1, . . . ,xn be independent copies of x, then for every \u01eb \u2208 (0, 1), we have\nPr\n( \u2225\n\u2225 \u2225 \u2225 \u2225 1 n\nn \u2211\ni=1\nxix T i \u2212 Id\n\u2225 \u2225 \u2225 \u2225 \u2225\n2\n> \u01eb\n)\n6 de\u2212n\u01eb 2/4M2\nTheorem 3. Under the assumption in this section, set m = \u0398 ( \u221a n\u01eb2 log d ) for \u03b2 > 0, then with\nhigh probability , there is\nL(wpriv)\u2212 L(w\u2217) = O\u0303 ( ( log d\nn\u01eb2\n)1/4 )\nProof. On one hand,\nL(wpriv)\u2212 L(w\u2217) =L(wpriv)\u2212 L\u0304(wpriv) + L\u0304(wpriv)\u2212 L\u0304(w\u0302\u2217)\n+ L\u0304(w\u0302\u2217)\u2212 L\u0304(w\u2217) + L\u0304(w\u2217)\u2212 L(w\u2217) 6 [ L(wpriv)\u2212 L\u0304(wpriv) + L\u0304(w\u2217)\u2212 L(w\u2217) ]\n+ L\u0304(wpriv)\u2212 L\u0304(w\u0302\u2217) 6G[max\ni {| \u2329 wpriv,xi \u232a \u2212 \u2329 \u03a6Twpriv,\u03a6Txi \u232a |}\n+max i\n{| \u3008w\u2217,xi\u3009 \u2212 \u2329 \u03a6Tw\u2217,\u03a6Txi \u232a |}]\n+ [L\u0304(wpriv)\u2212 L\u0304(w\u0302\u2217)] (11) (where G is the Lipschitz constant)\nOn the other hand, for \u2200w \u2208 C,\u2200x \u2208 D, there is\n| \u3008w,x\u3009 \u2212 \u2329 \u03a6Tw,\u03a6Tx \u232a |\n=\n\u2223 \u2223 \u2223 \u2223 \u2016\u03a6T (w+x)\u20162 2 \u2212\u2016\u03a6T (w\u2212x)\u20162 2 4 \u2212 \u2016w+x\u201622\u2212\u2016w\u2212x\u2016 2 2 4 \u2223 \u2223 \u2223 \u2223\n6\n\u2223 \u2223 \u2223 \u2223 \u2016\u03a6T (w+x)\u20162 2 \u2212\u2016w+x\u201622 4 \u2223 \u2223 \u2223 \u2223 + \u2223 \u2223 \u2223 \u2223 \u2016\u03a6T (w\u2212x)\u20162 2 \u2212\u2016w\u2212x\u201622 4 \u2223 \u2223 \u2223 \u2223\nAccording to the results of random projection w.r.t. additive error [6], we know with high\nprobability, there is | \u3008w,x\u3009 \u2212 \u2329 \u03a6Tw,\u03a6Tx \u232a | 6 O ( \u221a\nlog d m\n)\n, for \u2200w \u2208 C,\u2200x \u2208 D. Therefore, the\nfirst term in equation (11) is less than O\n(\n\u221a\nlog d m\n)\n.\nFrom lemma 6, we know L\u0304(w\u0304priv) \u2212 L\u0304(w\u0304\u2217) 6 O\u0303 (\u221a m n\u01eb2 )\nholds with high probability. Combine these two inequalities, it is easy to determine the optimal m, then obtain the conclusion.\nCorollary 2. Algorithm LDP kernel mechanism satisfies (\u01eb, \u03b4)-LDP, and with high probability, there is\nLH\u0302(w\u0302 priv)\u2212 LH(f\u2217) 6 O\u0303\n(\n(\nd\nn\u01eb2\n)1/4 )\nsup x\u2208X\n|\u03a6(x)T f\u2217 \u2212 (\u03a6\u0302(x))T w\u0302priv| 6 O\u0303 ( ( d\nn\u01eb2\n)1/8 )\nProof. Algorithm satisfies local privacy is obvious. For excess risk, as LH\u0302(w\u0302 priv) \u2212 LH(f\u2217) = LH\u0302(w\u0302 priv)\u2212 LH\u0302(g\u2217) + LH\u0302(g\u2217)\u2212 LH(f\u2217), follow nearly the same proof of lemma 5 of sparse linear regression, we have LH\u0302(w\u0302 priv)\u2212LH\u0302(g\u2217) 6 O\u0303 ( \u221a dp n\u01eb2 ) . On the other hand, nearly borrow the proof\nof Lemma 17 in [30] and property of RRF , we have\nLH\u0302(g \u2217)\u2212 LH(f\u2217) 6 O\u0303\n(\u221a\nd\ndp\n)\nCombine above two inequalities, and choose optimal dp as O\u0303 (\u221a dn\u01eb2 ) , we obtain the first inequality of the conclusion. Then combine lemma 7 in this paper, it is easy to obtaint the second inequality.\nA.2 Omitted contents and proofs in Section 4\nA.2.1 Relations between smooth generalized linear losses (SGLL) and generalized linear models (GLM)\nNote that a model is called GLM, if for x,w\u2217 \u2208 Rd, label y with respect to x is given by a distribution which belongs to the exponential family:\np(y|x,w\u2217) = exp ( y\u03b8 \u2212 b(\u03b8) \u03a6 + c(y,\u03a6) )\n(12)\nwhere \u03b8,\u03a6 are parameters, and b(\u03b8), c(y,\u03a6) are known functions. Besides, there is an one-to-one continuous differentiable transformation g(\u00b7) such that g(b\u2032(\u03b8)) = xTw\u2217.\nAccording to the key equality g(b\u2032(\u03b8)) = xTw\u2217, usually we can obtain smooth function \u03b8 = h1(x\nTw\u2217), b(\u03b8) = h2(xTw\u2217), and what\u2019s more, univariate function hi(x)(i = 1, 2) satisfies the absolutely smooth property.\nFor such GLM, if we consider optimizing the expected negative logarithmic probability \u2212E(x,y)\u223cD log p(x, y;w), once discarding unrelated terms tow, we obtain the new population loss, L(w) := E(x,y)\u223cD\u2113(w;x, y), where \u2113(w;x, y) = \u2212yh1(xTw) + h2(xTw), exactly the form of smooth generalized linear loss defined in section 4. Hence our SGLL is a natural loss defined by GLM with additional smoothness assumptions.\nA.2.2 Omitted proofs\nLemma 8. Given any \u03b1 > 0, by setting k = c ln 1\u03b1 , p = \u2308k + e\u00b52(k; r)\u2309, where c is a constant, we have \u2225 \u2225 \u2225 f\u0302p(x)\u2212 f(x) \u2225 \u2225 \u2225\n\u221e 6 \u03b1.\nProof. As f, f \u2032, \u00b7 \u00b7 \u00b7 , f (k\u22121) are absolutely continuous over [\u22121, 1], and \u2225 \u2225f (k) \u2225 \u2225\nT 6 \u00b51(k; r)\u00b52(k; r) k, according to the results in [35], we have\n\u2225 \u2225 \u2225 f\u0302p(x)\u2212 f(x) \u2225 \u2225 \u2225\n\u221e 6\n2 \u2225 \u2225f (k) \u2225 \u2225\nT\n\u03c0k(p \u2212 k)k\n6 2\u00b51(k; r)\n\u03c0kek (13)\nIt is easy to see there exists c > 0, such that the term (13) is less than \u03b1 with chosen k, hence the conclusion holds.\nLemma 9. For any \u03b3 > 0, setting k = c ln 4r\u03b3 , p = \u2308k + 2\u00b52(k; r)\u2309, then algorithm 7 outputs a (\u03b3, \u03b2, \u03c3) stochastic oracle, where \u03c3 = O\u0303 ( \u03c30 + \u03b3 + p2p+1(4r)p+1\n\u01ebp+2\n)\n.\nProof. According to lemma 8, we know the approximation error, |m\u0302(w;x, y) \u2212 m(w;x, y)| 6 \u03b3 2r . For any fixed (x, y), from the construction of stochastic inexact gradient oracle, there is E[G\u0303(w; b)|x, y] = G\u0302(w;x, y). Denote g\u0302(w) = E(x,y)\u223cD[G\u0302(w;x, y)], thus we have\nE\n[\n\u2225 \u2225 \u2225 G\u0303(w; b)\u2212 g\u0302(w) \u2225 \u2225 \u2225\n2 ]\n=E\n[\n\u2225 \u2225 \u2225 G\u0303(w; b)\u2212 G\u0302(w;x, y) \u2225 \u2225 \u2225\n2 ]\n+ E\n[\n\u2225 \u2225 \u2225 G\u0302(w;x, y)\u2212 g\u0302(w) \u2225 \u2225 \u2225\n2 ]\nFor above two terms, combined with results given in lemma 12, we we obtain\nE\n[\n\u2225 \u2225 \u2225 G\u0303(w; b)\u2212 g(w) \u2225 \u2225 \u2225\n2 ]\n6 O\u0303\n(\n(\nr(2rp)p+1\n\u01ebp+2 + \u03b3 + \u03c30\n)2 )\n. As L(v) \u2212 L(w) \u2212 g\u0302(w)T (v \u2212w) = L(v) \u2212 L(w) \u2212 g(w)T (v \u2212 w) + (g(w) \u2212 g\u0302(w))T (v \u2212 w), and from the approximation error, we know |(g(w) \u2212 g\u0302(w))T (v \u2212w)| 6 \u03b32 . What\u2019s more, as L(w)\nis convex and \u03b2-smooth, that is 0 6 L(v)\u2212 L(w)\u2212 g(w)T (v \u2212w) 6 \u03b22 \u2016v \u2212w\u2016 2. Combined these inequalities, we obtain\n\u2212\u03b32 6 L(v)\u2212 L(w)\u2212 g\u0302(w)T (v \u2212w) 6 \u03b2 2 \u2016v \u2212w\u2016 2 + \u03b32\n\u21d0\u21d20 6 L(v)\u2212 (L(w)\u2212 \u03b32 )\u2212 g\u0302(w)T (v \u2212w) 6 \u03b22 \u2016v \u2212w\u20162 + \u03b3\nNote the function value oracles in the stochastic oracle definition (either F\u03b3,\u03b2,\u03c3(\u00b7) or f\u03b3,\u03b2,\u03c3(\u00b7)) do not play any role in the optimization algorithm, hence we can set it as L(w)\u2212 \u03b32 , though we do not know how to calculate.\nLemma 12. Based on above statements, we have\nE\n[\n\u2225 \u2225 \u2225 G\u0303(w; b)\u2212 G\u0302(w;x, y) \u2225 \u2225 \u2225\n2 ]\n6 O\u0303\n(\np4p+2(4r)2p+2\n\u01eb2p+4\n)\nE\n[\n\u2225 \u2225 \u2225 G\u0302(w;x, y)\u2212 g\u0302(w) \u2225 \u2225 \u2225\n2 ]\n6 (\u03b3 + \u03c30) 2\nProof. First, we calculate the variance of each tk, var(tj) 6 \u220fj(j+1)/2 i=j(j\u22121)/2+1(var(w Tzi)+(E[w Tzi]) 2) 6 O\u0303 (\n(p(p+1)\u01eb ) 2j ) .\nNext, we upper bound the coefficient ck (as it is the same for c1k and c2k, hence we use ck for short). Note ck = \u2211p m=k ambmk, where am is the coefficient of original function represented by Chebyshev basis, bmk is the coefficient of order k monomial in Chebyshev basis Tm(x), where 0 6 k 6 m. According to the formula of Tm(x) given in [28] and well-known Stirling\u2019s approximation, after some translation, we have\n|bmk| 6 max \u03b8\u2208(0, 1 2 ) O\n(\u221a m \u00b7 [ (1\u2212 \u03b8)1\u2212\u03b8 \u03b8\u03b8(1\u2212 2\u03b8)1\u22122\u03b8 ]m)\n6O (\u221a m2m )\nBesides, from the absolutely smooth property of h\u2032i(x)(i \u2208 {1, 2}) and the convergence results in [35], we have am 6 O ( 1 m2 ) , thus ck = \u2211p m=k ambmk 6 O (2 p). Hence, there is\nvar [ (c2k \u2212 c1kzy)tkrk+1 ] 6r2k+2E [ ((c2k \u2212 c1kzy)tk)2 ]\n6O\n(\np4k+2(4r)2p+2\n\u01eb2k+2\n)\nAs each (c2k \u2212 c1kzy)tkrk+1 is independent with each other (for different k), which leads to\nvar\n[\np \u2211\nk=0\n(c2k \u2212 c1kzy)tkrk+1 ] 6 O ( p4p+2(4r)2p+2\n\u01eb2p+2\n)\nMoreover, var(z0) 6 O ( 1 \u01eb2 ) . Therefore,\nE\n[\n\u2225 \u2225 \u2225 G\u0303(w; b)\u2212 G\u0302(w;x, y) \u2225 \u2225 \u2225\n2 ]\n6 O\u0303\n(\np4p+2(4r)2p+2\n\u01eb2p+4\n)\nFor second inequality in the conclusion, there is\nE\n[\n\u2225 \u2225 \u2225 G\u0302(w;x, y)\u2212 g\u0302(w) \u2225 \u2225 \u2225\n2 ]\n6E\n[\n\u2225 \u2225 \u2225 G\u0302(w;x, y)\u2212G(w;x, y) +G(w;x, y)\u2212 g(w) + g(w)\u2212 g\u0302(w) \u2225 \u2225 \u2225\n2 ]\n6\u03b32 + \u03c320 + 2\u03c30\u03b3 = (\u03b3 + \u03c30) 2\nProposition 2. f(x) = ln(1 + e\u2212x) is absolutely smooth with \u00b51(k; r) = r \u221a 4k\u03c03, \u00b52(k; r) = rk e\nProof. For any r, k > 0, the absolutely continuous of f (k)(rx) is obvious, now consider \u2225 \u2225f (k+1)(rx) \u2225 \u2225\nT :\n\u2225 \u2225 \u2225 f (k+1) \u2225 \u2225 \u2225\nT =\n\u222b 1\n\u22121 |f (k+2)(rx)|\u221a 1\u2212 x2 dx\n6\u03c0 \u2225 \u2225 \u2225 f (k+2)(rx) \u2225 \u2225 \u2225\n\u221e\n6\u03c0rk+2 \u2225 \u2225\n\u2225 \u2211k+1 j=1(\u22121)k+jAk+1,j\u22121f j(1\u2212 f)k+2\u2212j\n\u2225 \u2225 \u2225\n\u221e\n6\u03c0rk+2 k+1 \u2211\nj=1\nAk+1,j\u22121\n6\u03c0(k + 1)!rk+2 6 \u221a 4\u03c03rk+2(k + 1)k+3/2e\u2212k\u22121\n=r \u221a 4\u03c03(k + 1)\n(\nr(k + 1)\ne\n)k+1\nTheorem 6. For any \u03b1 > 0, set \u03b3 = \u03b12 , k = c ln 4r \u03b3 , p = \u2308k + 2\u00b52(k; r)\u2309, if n > O (\n(8r\u03b1 ) 4r ln ln(8r/\u03b1)\n(\n4r \u01eb )2cr ln(8r/\u03b1)+2 ( 1 \u03b12\u01eb2 )\n)\n, using Algorithms 5 and 6, then we have L(wpriv)\u2212 L(w\u2217) 6 \u03b1.\nProof. According to lemma 10 , with a (\u03b3, \u03b2, \u03c3) stochastic oracle, SIGM algorithm converges with rate O (\n\u03c3\u221a n + \u03b3\n) . In order to have O (\n\u03c3\u221a n + \u03b3\n) 6 \u03b1, it suffices if n > O ( p4p+2(4r)2p+2\n\u03b12\u01eb2p+4\n)\n=\nO (\n(8r\u03b1 ) 4r ln ln(8r/\u03b1)\n(\n4r \u01eb )2cr ln(8r/\u03b1)+2 ( 1 \u03b12\u01eb2 )\n) , as \u03c3 = O ( p2p+1(4r)p+1\n\u01ebp+2\n)\naccording to lemma 9 (ignoring\nnegligible \u03c30, \u03b3)."}], "references": [{"title": "Local, private, efficient protocols for succinct histograms", "author": ["Raef Bassily", "Adam Smith"], "venue": "In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Private empirical risk minimization: Efficient algorithms and tight error bounds", "author": ["Raef Bassily", "Adam Smith", "Abhradeep Thakurta"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Convex optimization: Algorithms and complexity", "author": ["S\u00e9bastien Bubeck"], "venue": "Foundations and Trends R  \u00a9 in Machine Learning,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Privacy-preserving logistic regression", "author": ["K. Chaudhuri", "C. Monteleoni"], "venue": "In Conference on Neural Information Processing Systems, British Columbia,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Differentially private empirical risk minimization", "author": ["K. Chaudhuri", "C. Monteleoni", "A.D. Sarwate"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Dimensionality reduction with subgaussian matrices: a unified theory", "author": ["Sjoerd Dirksen"], "venue": "Foundations of Computational Mathematics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Minimax optimal procedures for locally private estimation", "author": ["John Duchi", "Martin Wainwright", "Michael Jordan"], "venue": "arXiv preprint arXiv:1604.02390,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Local privacy and minimax bounds: Sharp rates for probability estimation", "author": ["John Duchi", "Martin J Wainwright", "Michael I Jordan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Local privacy and statistical minimax rates", "author": ["John C Duchi", "Michael I Jordan", "Martin J Wainwright"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Stochastic intermediate gradient method for convex problems with stochastic inexact oracle", "author": ["Pavel Dvurechensky", "Alexander Gasnikov"], "venue": "Journal of Optimization Theory and Applications,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["C. Dwork", "F. McSherry", "K. Nissim", "A. Smith"], "venue": "In Theory of cryptography,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "The algorithmic foundations of differential privacy", "author": ["Cynthia Dwork", "Aaron Roth"], "venue": "Foundations and Trends R  \u00a9 in Theoretical Computer Science,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Statistical query algorithms for mean vector estimation and stochastic convex optimization", "author": ["Vitaly Feldman", "Crist\u00f3bal Guzm\u00e1n", "Santosh Vempala"], "venue": "In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2017}, {"title": "The optimal mechanism in differential privacy", "author": ["Quan Geng", "Pramod Viswanath"], "venue": "In Information Theory (ISIT),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "A simple and practical algorithm for differentially private data release", "author": ["M. Hardt", "K. Ligett", "F. Mcsherry"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "A multiplicative weights mechanism for privacy-preserving data analysis", "author": ["M. Hardt", "G.N. Rothblum"], "venue": "In IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Loss minimization and parameter estimation with heavy tails", "author": ["Daniel Hsu", "Sivan Sabato"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Discrete distribution estimation under local privacy", "author": ["Peter Kairouz", "Keith Bonawitz", "Daniel Ramage"], "venue": "In Proceedings of The 33rd International Conference on Machine Learning,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Extremal mechanisms for local differential privacy", "author": ["Peter Kairouz", "Sewoong Oh", "Pramod Viswanath"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "The composition theorem for differential privacy", "author": ["Peter Kairouz", "Sewoong Oh", "Pramod Viswanath"], "venue": "In Proceedings of The 32nd International Conference on Machine Learning,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Secure multi-party differential privacy", "author": ["Peter Kairouz", "Sewoong Oh", "Pramod Viswanath"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "What can we learn privately", "author": ["S.P. Kasiviswanathan", "H.K. Lee", "K. Nissim", "S. Raskhodnikova", "A. Smith"], "venue": "In IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "Efficient private empirical risk minimization for high-dimensional learning", "author": ["Shiva Prasad Kasiviswanathan", "Hongxia Jin"], "venue": "In Proceedings of The 33rd International Conference on Machine Learning,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "What can we learn privately", "author": ["Shiva Prasad Kasiviswanathan", "Homin K Lee", "Kobbi Nissim", "Sofya Raskhodnikova", "Adam Smith"], "venue": "SIAM Journal on Computing,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Efficient noise-tolerant learning from statistical queries", "author": ["Michael Kearns"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1998}, {"title": "Private convex empirical risk minimization and high-dimensional regression", "author": ["Daniel Kifer", "Adam Smith", "Abhradeep Thakurta"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Differentially private m-estimators", "author": ["J. Lei"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Some coefficient estimates for polynomials on the unit interval", "author": ["MA Qazi", "QI Rahman"], "venue": "Serdica Mathematical Journal,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2007}, {"title": "Random features for large-scale kernel machines", "author": ["Ali Rahimi", "Benjamin Recht"], "venue": "In NIPS,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2007}, {"title": "Learning in a large function space: Privacy-preserving mechanisms for svm learning", "author": ["B. Rubinstein", "P.L. Bartlett", "L. Huang", "N. Taft"], "venue": "Journal of Privacy and Confidentiality,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Privacy-preserving statistical estimation with optimal convergence rates", "author": ["A. Smith"], "venue": "In ACM Symposium on Theory of Computing,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2011}, {"title": "Differentially private model selection via stability arguments and the robustness of the lasso", "author": ["Adam Smith", "Abhradeep Thakurta"], "venue": "J Mach Learn Res Proc Track,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}, {"title": "Nearly optimal private lasso", "author": ["Kunal Talwar", "Abhradeep Thakurta", "Li Zhang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2015}, {"title": "Faster algorithms for privately releasing marginals", "author": ["J. Thaler", "J. Ullman", "S. Vadhan"], "venue": "In International Colloquium on Automata, Languages, and Programming,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Is gauss quadrature better than clenshaw\u2013curtis", "author": ["Lloyd N Trefethen"], "venue": "SIAM review,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2008}, {"title": "An introduction to matrix concentration inequalities", "author": ["Joel A Tropp"], "venue": "Foundations and Trends R  \u00a9 in Machine Learning,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2015}, {"title": "A note on sums of independent random matrices after ahlswede-winter", "author": ["Roman Vershynin"], "venue": "Lecture notes,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "Estimation in high dimensions: a geometric perspective", "author": ["Roman Vershynin"], "venue": "In Sampling theory, a renaissance,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2015}, {"title": "Privacy for free: Posterior sampling and stochastic gradient monte carlo", "author": ["Y. Wang", "S.E. Fienberg", "A.J. Smola"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2015}, {"title": "Differentially private data releasing for smooth queries", "author": ["Z. Wang", "C. Jin", "K. Fan", "J. Zhang", "J. Huang", "Y. Zhong", "L. Wang"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2016}, {"title": "Randomized response: A survey technique for eliminating evasive answer bias", "author": ["Stanley L Warner"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1965}, {"title": "Efficient private erm for smooth objectives", "author": ["Jiaqi Zhang", "Kai Zheng", "Wenlong Mou", "Liwei Wang"], "venue": "arXiv preprint arXiv:1703.09947,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2017}, {"title": "Functional mechanism: regression analysis under differential privacy", "author": ["Jun Zhang", "Zhenjie Zhang", "Xiaokui Xiao", "Yin Yang", "Marianne Winslett"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2012}], "referenceMentions": [{"referenceID": 10, "context": ",[11], provide a solid foundation and rigorous standard for private data analysis.", "startOffset": 1, "endOffset": 5}, {"referenceID": 15, "context": "Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering [16, 15, 34, 40], machine learning [4, 5, 30, 39], and statistical inference [27, 31].", "startOffset": 146, "endOffset": 162}, {"referenceID": 14, "context": "Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering [16, 15, 34, 40], machine learning [4, 5, 30, 39], and statistical inference [27, 31].", "startOffset": 146, "endOffset": 162}, {"referenceID": 33, "context": "Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering [16, 15, 34, 40], machine learning [4, 5, 30, 39], and statistical inference [27, 31].", "startOffset": 146, "endOffset": 162}, {"referenceID": 39, "context": "Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering [16, 15, 34, 40], machine learning [4, 5, 30, 39], and statistical inference [27, 31].", "startOffset": 146, "endOffset": 162}, {"referenceID": 3, "context": "Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering [16, 15, 34, 40], machine learning [4, 5, 30, 39], and statistical inference [27, 31].", "startOffset": 181, "endOffset": 195}, {"referenceID": 4, "context": "Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering [16, 15, 34, 40], machine learning [4, 5, 30, 39], and statistical inference [27, 31].", "startOffset": 181, "endOffset": 195}, {"referenceID": 29, "context": "Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering [16, 15, 34, 40], machine learning [4, 5, 30, 39], and statistical inference [27, 31].", "startOffset": 181, "endOffset": 195}, {"referenceID": 38, "context": "Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering [16, 15, 34, 40], machine learning [4, 5, 30, 39], and statistical inference [27, 31].", "startOffset": 181, "endOffset": 195}, {"referenceID": 26, "context": "Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering [16, 15, 34, 40], machine learning [4, 5, 30, 39], and statistical inference [27, 31].", "startOffset": 223, "endOffset": 231}, {"referenceID": 30, "context": "Since then, there has been extensive literature studying the fundamental trade-offs between differential privacy and accuracy for query answering [16, 15, 34, 40], machine learning [4, 5, 30, 39], and statistical inference [27, 31].", "startOffset": 223, "endOffset": 231}, {"referenceID": 11, "context": "For more details on DP results, please refer to the excellent monograph written by Dwork and Roth [12].", "startOffset": 98, "endOffset": 102}, {"referenceID": 40, "context": "Borrowing ideas from classical wisdom on collecting sensitive survey data [41], Local Differential Privacy (LDP) [22, 9] was proposed as a stronger notion of privacy to resolve this problem.", "startOffset": 74, "endOffset": 78}, {"referenceID": 21, "context": "Borrowing ideas from classical wisdom on collecting sensitive survey data [41], Local Differential Privacy (LDP) [22, 9] was proposed as a stronger notion of privacy to resolve this problem.", "startOffset": 113, "endOffset": 120}, {"referenceID": 8, "context": "Borrowing ideas from classical wisdom on collecting sensitive survey data [41], Local Differential Privacy (LDP) [22, 9] was proposed as a stronger notion of privacy to resolve this problem.", "startOffset": 113, "endOffset": 120}, {"referenceID": 7, "context": "Therefore, this line of research has attracted lots of attention [8, 9, 19, 1, 18].", "startOffset": 65, "endOffset": 82}, {"referenceID": 8, "context": "Therefore, this line of research has attracted lots of attention [8, 9, 19, 1, 18].", "startOffset": 65, "endOffset": 82}, {"referenceID": 18, "context": "Therefore, this line of research has attracted lots of attention [8, 9, 19, 1, 18].", "startOffset": 65, "endOffset": 82}, {"referenceID": 0, "context": "Therefore, this line of research has attracted lots of attention [8, 9, 19, 1, 18].", "startOffset": 65, "endOffset": 82}, {"referenceID": 17, "context": "Therefore, this line of research has attracted lots of attention [8, 9, 19, 1, 18].", "startOffset": 65, "endOffset": 82}, {"referenceID": 24, "context": "In the interactive world, LDP is promised with connection to Statistical Query (SQ) model [25], from its very beginning [24].", "startOffset": 90, "endOffset": 94}, {"referenceID": 23, "context": "In the interactive world, LDP is promised with connection to Statistical Query (SQ) model [25], from its very beginning [24].", "startOffset": 120, "endOffset": 124}, {"referenceID": 12, "context": "SQ algorithms for a wide range of convex ERM problems were proposed by [13], implying good risk bounds for LDP.", "startOffset": 71, "endOffset": 75}, {"referenceID": 8, "context": "[9] established matching upper and lower bounds for convex risk minimization problems.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Existing works primarily focus on basic estimation problems such as means and discrete densities [8, 7, 1], or some function calculations [21].", "startOffset": 97, "endOffset": 106}, {"referenceID": 6, "context": "Existing works primarily focus on basic estimation problems such as means and discrete densities [8, 7, 1], or some function calculations [21].", "startOffset": 97, "endOffset": 106}, {"referenceID": 0, "context": "Existing works primarily focus on basic estimation problems such as means and discrete densities [8, 7, 1], or some function calculations [21].", "startOffset": 97, "endOffset": 106}, {"referenceID": 20, "context": "Existing works primarily focus on basic estimation problems such as means and discrete densities [8, 7, 1], or some function calculations [21].", "startOffset": 138, "endOffset": 142}, {"referenceID": 32, "context": "In classical differential privacy literature, this has been be addressed using different techniques, guarantee error bounds logarithmically dependent on dimension [33, 32].", "startOffset": 163, "endOffset": 171}, {"referenceID": 31, "context": "In classical differential privacy literature, this has been be addressed using different techniques, guarantee error bounds logarithmically dependent on dimension [33, 32].", "startOffset": 163, "endOffset": 171}, {"referenceID": 6, "context": "However, lower bounds have been shown in local privacy model even for high-dimensional 1-sparse mean estimation, ruling out any good guarantees [7].", "startOffset": 144, "endOffset": 147}, {"referenceID": 13, "context": "One can also consider optimal mechanisms in terms of privacy parameters like [14], which is of independent interests.", "startOffset": 77, "endOffset": 81}, {"referenceID": 6, "context": "This is in sharp contrast with information-theoretic lower bounds for 1-sparse mean estimation for l\u221e bounded data [7].", "startOffset": 115, "endOffset": 118}, {"referenceID": 9, "context": "SIGM algorithm in [10] is exploited to find the minimizer with inexact gradients.", "startOffset": 18, "endOffset": 22}, {"referenceID": 40, "context": "Other Related Work: Local privacy dates back to [41], who uses random responses to protect privacy in surveys.", "startOffset": 48, "endOffset": 52}, {"referenceID": 7, "context": "In recent LDP literature, both [8] and [18] studied density estimation methods and their theoretical behaviors in LDP model.", "startOffset": 31, "endOffset": 34}, {"referenceID": 17, "context": "In recent LDP literature, both [8] and [18] studied density estimation methods and their theoretical behaviors in LDP model.", "startOffset": 39, "endOffset": 43}, {"referenceID": 0, "context": "Rather than statistical setting in above two work, [1] considered how to produce frequent items and corresponding frequencies of a dataset in local model.", "startOffset": 51, "endOffset": 54}, {"referenceID": 18, "context": "Besides, [19] investigated optimality of LDP mechanisms based on information theoretical measures for statistical discrimination.", "startOffset": 9, "endOffset": 13}, {"referenceID": 33, "context": "[34] employed polynomials for marginal queries.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[40] leveraged trigonometric polynomials to answer smooth queries.", "startOffset": 0, "endOffset": 4}, {"referenceID": 42, "context": "[43] also used polynomial approximations and get basic convergence results in standard DP model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "Besides, the random projection and recovery has also been used in DP learning [23] and local DP histogram estimation [1].", "startOffset": 78, "endOffset": 82}, {"referenceID": 0, "context": "Besides, the random projection and recovery has also been used in DP learning [23] and local DP histogram estimation [1].", "startOffset": 117, "endOffset": 120}, {"referenceID": 25, "context": "[26] and [32] considered the convergence of private LASSO estimator under RSC and incoherence assumptions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[26] and [32] considered the convergence of private LASSO estimator under RSC and incoherence assumptions.", "startOffset": 9, "endOffset": 13}, {"referenceID": 32, "context": "[33] considered constrained ERM of sparse linear regression, and obtained \u00d5(log d/n2/3) rate using private Frank-Wolfe.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "By stronger assumption of l2 bounded data, [23] gave a general framework for high dimensional empirical risk minimization (ERM) problem.", "startOffset": 43, "endOffset": 47}, {"referenceID": 3, "context": "Objective and output perturbation are used to get low excess risks [4, 5].", "startOffset": 67, "endOffset": 73}, {"referenceID": 4, "context": "Objective and output perturbation are used to get low excess risks [4, 5].", "startOffset": 67, "endOffset": 73}, {"referenceID": 1, "context": "Both [2] and [42] considered concrete private algorithms to solve ERM.", "startOffset": 5, "endOffset": 8}, {"referenceID": 41, "context": "Both [2] and [42] considered concrete private algorithms to solve ERM.", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "1 Local Differential Privacy Here we adopt the LDP definition given in [1].", "startOffset": 71, "endOffset": 74}, {"referenceID": 11, "context": "A mechanism Q : V \u2192 Z is said to be (\u01eb, \u03b4)-local differential private or (\u01eb, \u03b4)-LDP, if for any v,v\u2032 \u2208 V, and any (measurable) subset S \u2282 Z, there is Pr[Q(v) \u2208 S] 6 e Pr[Q(v\u2032) \u2208 S] + \u03b4 Just the same with basic results in DP [12], there are corresponding basic results for LDP: Lemma 1 (Gaussian Mechanism).", "startOffset": 224, "endOffset": 228}, {"referenceID": 19, "context": "Using random Note one can also use the advanced composition mechanism [20] with a refined analysis, but the main dependence over n and d will remain nearly the same.", "startOffset": 70, "endOffset": 74}, {"referenceID": 1, "context": "Our results are in sharp contrast with the lower bound for l2-bounded general mean estimation under standard DP [2], as well as the lower bound for l\u221e-bounded 1-sparse mean estimation under local DP [7].", "startOffset": 112, "endOffset": 115}, {"referenceID": 6, "context": "Our results are in sharp contrast with the lower bound for l2-bounded general mean estimation under standard DP [2], as well as the lower bound for l\u221e-bounded 1-sparse mean estimation under local DP [7].", "startOffset": 199, "endOffset": 202}, {"referenceID": 37, "context": "This locally private estimation procedure can be viewed as a variant of noisy compressed sensing, where l2 recovery rate is fundamentally controlled by the Gaussian Mean Width of constraint set [38].", "startOffset": 194, "endOffset": 198}, {"referenceID": 16, "context": "To tackle this problem, we employ Median-of-Mean estimator to get exponential tails [17].", "startOffset": 84, "endOffset": 88}, {"referenceID": 16, "context": "The tail properties are guaranteed in the following lemma: Lemma 4 (Proposition 9 in [17]).", "startOffset": 85, "endOffset": 89}, {"referenceID": 37, "context": "The primary tool we are using are General M\u2217 bound in [38].", "startOffset": 54, "endOffset": 58}, {"referenceID": 37, "context": "2 in [38], High Probability Version).", "startOffset": 5, "endOffset": 9}, {"referenceID": 32, "context": "Note [33] assume data is in L\u221e ball, while both [23] and ours assume data is in L2 ball.", "startOffset": 5, "endOffset": 9}, {"referenceID": 22, "context": "Note [33] assume data is in L\u221e ball, while both [23] and ours assume data is in L2 ball.", "startOffset": 48, "endOffset": 52}, {"referenceID": 6, "context": "However, in LDP model, [7] show it was impossible to obtain polynomial dependences over log d for l0 mean estimation problem if data is in L\u221e ball.", "startOffset": 23, "endOffset": 26}, {"referenceID": 28, "context": "In this subsection, we take kernel ridge regression as an example to show how to use Random Fourier Features (RFF) [29] to deal with such cases caused by shift-invariant kernels (i.", "startOffset": 115, "endOffset": 119}, {"referenceID": 29, "context": "Borrow the key result in [30] (restated in lemma 7 below), which used RFF to design private mechanims for SVM in DP model, it becomes easy to prove guarantees for kernel ridge regression in our setting (see Corollary 2).", "startOffset": 25, "endOffset": 29}, {"referenceID": 29, "context": "Lemma 7 ([30]).", "startOffset": 9, "endOffset": 13}, {"referenceID": 2, "context": "This is a common assumption in stochastic optimization literature, such as [3].", "startOffset": 75, "endOffset": 78}, {"referenceID": 9, "context": "[10] For an objective function f(w), a (\u03b3, \u03b2, \u03c3) stochastic oracle returns a turple", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Based on above (\u03b3, \u03b2, \u03c3) stochastic oracle, and the algorithm proposed in SIGM paper [10] (omitted here, due to the limitation of space), our complete learning algorithm is given in Algorithm 6.", "startOffset": 85, "endOffset": 89}, {"referenceID": 9, "context": "Before proving our sample complexity, we state the basic convergence result of SIGM algorithm: Lemma 10 ([10]).", "startOffset": 105, "endOffset": 109}, {"referenceID": 0, "context": "References [1] Raef Bassily and Adam Smith.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] Raef Bassily, Adam Smith, and Abhradeep Thakurta.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] S\u00e9bastien Bubeck et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] K.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] K.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Sjoerd Dirksen.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] John Duchi, Martin Wainwright, and Michael Jordan.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] John Duchi, Martin J Wainwright, and Michael I Jordan.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] John C Duchi, Michael I Jordan, and Martin J Wainwright.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Pavel Dvurechensky and Alexander Gasnikov.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] Cynthia Dwork and Aaron Roth.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Vitaly Feldman, Crist\u00f3bal Guzm\u00e1n, and Santosh Vempala.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] Quan Geng and Pramod Viswanath.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] Daniel Hsu and Sivan Sabato.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] Peter Kairouz, Keith Bonawitz, and Daniel Ramage.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] Peter Kairouz, Sewoong Oh, and Pramod Viswanath.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] Peter Kairouz, Sewoong Oh, and Pramod Viswanath.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] Peter Kairouz, Sewoong Oh, and Pramod Viswanath.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] Shiva Prasad Kasiviswanathan and Hongxia Jin.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] Shiva Prasad Kasiviswanathan, Homin K Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] Michael Kearns.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] Daniel Kifer, Adam Smith, and Abhradeep Thakurta.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[27] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] MA Qazi and QI Rahman.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] Ali Rahimi, Benjamin Recht, et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] B.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[31] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[32] Adam Smith and Abhradeep Thakurta.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[33] Kunal Talwar, Abhradeep Thakurta, and Li Zhang.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[35] Lloyd N Trefethen.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "[36] Joel A Tropp et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "[37] Roman Vershynin.", "startOffset": 0, "endOffset": 4}, {"referenceID": 37, "context": "[38] Roman Vershynin.", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "[39] Y.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[40] Z.", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": "[41] Stanley L Warner.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "[42] Jiaqi Zhang, Kai Zheng, Wenlong Mou, and Liwei Wang.", "startOffset": 0, "endOffset": 4}, {"referenceID": 42, "context": "[43] Jun Zhang, Zhenjie Zhang, Xiaokui Xiao, Yin Yang, and Marianne Winslett.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "1 in [36]), we have 1 n \u2225 \u2225X\u0304Tr \u2225", "startOffset": 5, "endOffset": 9}, {"referenceID": 36, "context": "Lemma 11 ([37]).", "startOffset": 10, "endOffset": 14}, {"referenceID": 5, "context": "additive error [6], we know with high probability, there is | \u3008w,x\u3009 \u2212 \u3008 \u03a6Tw,\u03a6Tx \u3009 | 6 O ( \u221a", "startOffset": 15, "endOffset": 18}, {"referenceID": 29, "context": "On the other hand, nearly borrow the proof of Lemma 17 in [30] and property of RRF , we have L\u0124(g \u2217)\u2212 LH(f) 6 \u00d5 (\u221a d dp )", "startOffset": 58, "endOffset": 62}, {"referenceID": 34, "context": "\u2225 T 6 \u03bc1(k; r)\u03bc2(k; r) k, according to the results in [35], we have", "startOffset": 54, "endOffset": 58}, {"referenceID": 27, "context": "According to the formula of Tm(x) given in [28] and well-known Stirling\u2019s approximation, after some translation, we have |bmk| 6 max \u03b8\u2208(0, 1 2 ) O (\u221a m \u00b7 [ (1\u2212 \u03b8)1\u2212\u03b8 \u03b8\u03b8(1\u2212 2\u03b8)1\u22122\u03b8 ]m)", "startOffset": 43, "endOffset": 47}, {"referenceID": 34, "context": "Besides, from the absolutely smooth property of hi(x)(i \u2208 {1, 2}) and the convergence results in [35], we have am 6 O ( 1 m2 ) , thus ck = \u2211p m=k ambmk 6 O (2 p).", "startOffset": 97, "endOffset": 101}], "year": 2017, "abstractText": "Non-interactive Local Differential Privacy (LDP) requires data analysts to collect data from users through noisy channel at once. In this paper, we extend the frontiers of Non-interactive LDP learning and estimation from several aspects. For learning with smooth generalized linear losses, we propose an approximate stochastic gradient oracle estimated from non-interactive LDP channel using Chebyshev expansion, which is combined with inexact gradient methods to obtain an efficient algorithm with quasi-polynomial sample complexity bound. For the highdimensional world, we discover that under l2-norm assumption on data points, high-dimensional sparse linear regression and mean estimation can be achieved with logarithmic dependence on dimension, using random projection and approximate recovery. We also extend our methods to Kernel Ridge Regression. Our work is the first one that makes learning and estimation possible for a broad range of learning tasks under non-interactive LDP model.", "creator": "LaTeX with hyperref package"}}}