{"id": "1708.04765", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Aug-2017", "title": "Dialogue Act Segmentation for Vietnamese Human-Human Conversational Texts", "abstract": "Dialog pankhurst act sleazier identification moe. plays mahant an donlan important lomborg role a-9 in venzuela understanding acm conversations. zepter It has relieved been 646,000 widely applied efremov in barauni many fields such logistica as dialogue hotmail systems, automatic vish machine untracked translation, walkathon automatic speech re-grouped recognition, bitzer and integraci\u00f3n especially useful mahwash in donuts systems lucille with human - faithless computer natural tranzalpine language dialogue knickknack interfaces arrangment such 5-on-3 as virtual net-centric assistants and chatbots. mortgagee The first pandeism step of identifying dialog dromaeosaurid act is leroi-gourhan identifying the lynfield boundary karabilah of the lundmark dialog cosying act sina.com.cn in khaksar utterances. palaeobiology In l'expression this uddhav paper, seagoing we focus boudinot on 110.82 segmenting the utterance according to parkade the dialog 14-percent act hinkes boundaries, substates i. e. pressure functional segments hassard identification, schwere for Vietnamese witch-hunts utterances. We investigate lefurgy carefully 800-million functional pyrrha segment identification reals in al-arqam two edificio approaches: (corns 1) vilnius machine brother/sister learning semi-naked approach using maximum sproule entropy (confucius ME) and cox.com conditional nazg\u00fbl random enset fields (CRFs ); (linen 2) deep victorian-era learning approach l.i. using bidirectional Long Short - matings Term hutzler Memory (LSTM) gamburyan with a CRF layer (Bi - tweedy LSTM - CRF) djalma on hacksaws two inverclyde different s14 conversational datasets: (clinid 1) 39-10 Facebook looy messages (zeroual Message data ); (totenkopf 2) beandali transcription einen from mafiosos phone zakka conversations (Phone data ). To the sagnol best 1,800-mile of our redmire knowledge, solennelle this churchward is the yuhuan first uttara work al-baladhuri that applies deep artificiality learning sezibera based elaphus approach ship to dialog stake act unnerved segmentation. As rangeland the antitrypsin results show, deep castelfranco learning approach 200.4 performs appreciably 3,824 better as to compare with galaxias traditional machine learning jacumba approaches. bandcamp Moreover, teuta it is taiwanensis also the h\u01b0u first tingle study that fejer tackles shouf dialog 78.45 act wachtler and functional vlcek segment identification romary for 61.04 Vietnamese.", "histories": [["v1", "Wed, 16 Aug 2017 04:27:09 GMT  (97kb,D)", "http://arxiv.org/abs/1708.04765v1", "6 pages, 2 figures"]], "COMMENTS": "6 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["thi lan ngo", "khac linh pham", "minh son cao", "son bao pham", "xuan hieu phan"], "accepted": false, "id": "1708.04765"}, "pdf": {"name": "1708.04765.pdf", "metadata": {"source": "CRF", "title": "Dialogue Act Segmentation for Vietnamese Human-Human Conversational Texts", "authors": ["Thi\u2013Lan Ngo"], "emails": ["ntlan@ictu.edu.vn", "phamkhaclinh2017@gmail.com", "soncm_58@vnu.edu.vn", "sonpb@vnu.edu.vn", "hieupx@vnu.edu.vn"], "sections": [{"heading": null, "text": "Keywords\u2014Dialog act segmentation, functional segment, Vietnamese conversation.\nI. INTRODUCTION\nAutomatic recognition of user intent from utterances in their interaction with systems through the conversational interface is a very challenging task that has attracted a lot of attention from research community for two decades. The goal is to design methods to make computers interact more naturally with human beings. Identifying dialog acts (DAs) within an utterance, i.e. identifying its illocutionary act of communication, plays a key role in understanding user\u2019s intent. Because, \u201cDialog act is a communicative activity of dialog participant, interpreted as having a certain communicative function and semantic content\" [1]. It presents meaning of utterances at the discourse level. It is a complementary process\nto concept extraction. Therefore, it is essential for the complete understanding of conversations. It is important for many applications: dialogue systems, automatic translation machine [2], automatic speech recognition, etc [3] [4] and has been studied in various languages such as English, Chinese, Arabic, Czech, Korean. Whilst in Vietnamese languages, dialog act has only been studied in linguistics, our work in this paper is a preliminary study about automatic identification of dialog act, as well as dialog act segmentation.\nPrior to DA identification, utterances must be segmented according to DA boundaries. In the past, there have been studies of DA segmentation such as Umit Guz et al. implemented DA segmentation of speech using multi-view semisupervised learning [5]; Jeremy Ang et al. explored DA segmentation using simple lexical and prosodic knowledge sources [6]; Warnke et al. calculated hypotheses for the probabilities exceeded a predefined threshold level in VERBMOBIL corpus [7]; Silvia Quarteroni et al. segmented human-human dialog into turns and intra-turn segmentation into DA boundaries using CRFs to learn models for simultaneous segmentation of DAs from whole human-human spoken dialogs [8]. These studies segmented turns into sentence unit to do dialog act segmentation. In my work, different from those studies, we segment utterances into the smallest meaningful units \u2013 \u201cfunctional segment\" unit. According to ISO 24617-2 standard about Dialog Act, a functional segment (FS) is defined as \u201cminimal stretch of communicative behavior that have a communicative function\" [1]. For example, in the utterance \u201cxin ch\u00e0o c\u1eadu kh\u1ecfe ch\u1ee9\" (\u201chello are you fine\"), there are two functional segments: \u201cxin ch\u00e0o\" (\u201chello\u201d) (its dialog act is greeting), and \u201cc\u1eadu kho\u1ebb ch\u1ee9\" (\u201care you fine\u201d) (its dialog act is check question). We investigate thoroughly functional segment identification in two approaches: (1) machine learning approach with ME, CRF; (2) deep learning approach with Bi\u2013LSTM\u2013CRF. Recently, ME, CRF and Bi\u2013LSTM\u2013CRF have been applied to a variety of sequence labeling and segmentation tasks in Natural Language Processing and have achieved state-ofthe-art results [9]. Therefore, we expect that these methods ar X iv :1 70 8. 04 76\n5v 1\n[ cs\n.C L\n] 1\napply to the FS identification task for Vietnamese can make similar successes. To do the task, we first build two annotated corpus from Facebook messages and transcription from phone conversations. For a careful evaluation, different ME, CRF and Bi\u2013LSTM\u2013CRF models were trained and their results are compared and shown contrast with each other. Moreover, we also show the characteristics of two different conversational data sets and their effect on the experimental results of the task of the dialog act segmentation task.\nWe can summary our main contributions in this paper in two aspects:\n\u2022 First, we built two Vietnamese conversational text datasets which are segmented into FSs based on FS concept from the ISO standard and ready to contribute to the DialogBank 1 for Vietnamese. We also built online chat dictionary which contains abbreviations, slang words and teen code and Vietnamese local dialect dictionary.\n\u2022 Second, two machine learning techniques and a deep learning technique are applied and compared on the task of automatic dialog act segmentation. Deep learning technique is also applied for the first time to dialog act segmentation. The results of the deep learning technique are very promising, opening up a new way to approach dialog act segmentation and dialog act in general for applications for future studies.\nThe rest of the paper is organized as follows: Section II presents briefly background about FS formation in Vietnamese conversational texts and units of a dialogue. In Section III we describe our two human-human conversation corpus. We also discuss the impact of our conversational data sets to the functional segment identification task in this section. We describe quickly the two learning models ME, CRF and the deep learning model, Bi\u2013LSTM\u2013CRF for labeling and segmenting FS in Section IV. Section V mainly presents the framework of using MEs, CRFs, Bi\u2013LSTM\u2013CRF for Vietnamese FS segmentation and result comparison and evaluation. Finally, Section VI shows some conclusions and the work that need research in the future."}, {"heading": "II. BACKGROUD: FUNCTIONAL SEGMENT AND UNITS OF A DIALOGUE", "text": "DAs are extended from the speech act theory of Austin [10] and Searle [11] to model the conversational functions that utterances can perform. It is the meaning of an utterance at the level of illocutionary force, such as statement, question and greeting. Detection of dialog acts need to perform: 1) the segmentation of human\u2013human dialogues into turns, 2) the intra-turn segmentation into DA boundaries, i.e. functional segment identification and 3) the classification of each segment according to a DA tag [12].\nIn which, \u201cturn\", \u201cdialog act\", \u201cfunctional segment\" terms are defined slightly different between different domains and different purposes. But these are standardized and united in ISO standards as follows:\n1https://dialogbank.uvt.nl/"}, {"heading": "Turn:", "text": "A \u201cturn\" is definite as \u201cstretch of communicative activity produced by one participant who occupies the speaker role bounded by periods where another participant occupies the speaker role\". Dialogue participants (sender, addressee) normally take turns in conversation. Several utterances from one of the dialogues in our corpus are shown as examples of Turn, Message, and Functional segment in Table I and Table II. In our Message data, a turn is seen as a collection of continuous messages sent by one participant. In which, a message is defined as a group of words that are sent from one dialogue participant to the other. For instance, turn t2 includes four messages ms2, ms3, ms4, ms5 (Table I)."}, {"heading": "Functional segment:", "text": "A functional segment is the \u201cminimal stretch of communicative behavior that has a communicative function\u201d, \u201cminimal in the sense of not including material that does not contribute to the expression of the function or the semantic content of the dialogue act\" [1]. A functional segment may be shorter than turns and continuous, for example as in Table I, t1 includes two functional segments fs1 and fs2. A functional segment may be discontinuous, with examples such as fs4 and fs10. fs5 is nested within fs4. In addition, functional segment fs10 is combined from two messages, fs8 overlaps fs10. Thus, we can see that a functional segment may be continuous, may be discontinuous, may be overlapped and nested. The detailed explanation of the types of FS is presented in [13] and the ISO 24617-2 standard."}, {"heading": "Dialog Act:", "text": "DA is \u201ccommunicative activity of a dialogue participant, interpreted as having a certain communicative function and semantic content\". For example:\n\u201cxin ch\u00e0o c\u1eadu kho\u1ebb ch\u1ee9\" (\u201chello are you fine\u201d)\nDAs of \u201cxin ch\u00e0o\" (hello) are Greeting and Opening. DA of \u201cc\u1eadu kho\u1ebb ch\u1ee9\" (\u201care you fine\u201d) is Check Question."}, {"heading": "III. CORPUS BUILDING: MESSAGE DATA & PHONE DATA", "text": "In Vietnamese, there is no publicly available standard corpus. Therefore we need to build first a reference corpus for training and evaluation. For this work, we have to build two corpora of data from human-human conversations in various domains. One is chat texts and other is spoken texts."}, {"heading": "A. Message corpus", "text": "Our Message data set is collected from Facebook messages of 20 volunteers. The data set contains 280 human-human Vietnamese dialogues in any topics with a total number of 4583 messages. The average length of dialogues is 16.4 messages. The data set was independently labeled by three annotators. The agreement score of our data set achieved 0.87 Fleiss\u2019 kappa measure [14]. As observed from our data, there are some challenges as follows:\n1) The data is very noisy because it contains many acronyms, misspellings, slang, and emoticons. These\nFS identification but sometimes a FS may contain multiple messages, and even may include only a part of one message and a part of the next message. This indistinct end of a turn also leads to the end of a misleading message. In sudden interruption cases, messages can become out of sync. Each participant tends to respond to a message earlier than the previous one, making the conversation also being out of order and the conversation seem inconsistent when read in sequence. This is a difficult problem for processing the dialog act segmentation.\nIn short, unlike carefully authored news text, conversational text poses a number of new challenges, due to their short, context-dependent, noisy and dynamic nature. Tackling this challenge, ideally, requires changing related natural language processing tools to become suitable for texts from social media network or normalizing conversational texts to fit with existing tools. However, both of which are hard tasks. In the scope of this paper, we standardize the message data using our online chat dictionary to match popular abbreviations, acronyms, and slang with standard words in the pre-processing stage."}, {"heading": "Online chat dictionary", "text": "Our online chat dictionary includes abbreviations, slang and the words that are written in teen style (teen code) such as \u201cbj\"- \u201cb\u00e2y gi\u1edd\" (\u201cnow\"), \u201cck\" - \u201cch\u1ed3ng\" (\u201chusband\"), \u201c4u\" - \u201ccho b\u1ea1n\" (\u201cfor you\"). The letters \u201cc\", \u201ck\", \u201cq\" are usually replaced by \u201ck\", \u201cch\u201d but often replaced with \u201cck\u201d ... Using online chat dictionary to standardize the message data, the noisiness of input data will be reduced. This make it more formal and help the models run better."}, {"heading": "B. Phone corpus", "text": "Our Phone data set is build from scripted telephone speech of LDC2017S01 data (IARPA Babel Vietnamese Language Pack IARPA-babel107b-v0.7 2). LDC2017S01 contains Vietnamese phone audios and transcripts. The Vietnamese conversations in these corpus contain different dialects that spoken in the North, North-Central, Central and Southern regions in Vietnam. We selected 22 conversations and segment its transcripts into the turn by manual. Then, the turns are annotated FS. The Phone data includes 1545 turns and 3500 FSs with an average of 70 turns and 160 FSs per conversation. The agreement scores of the phone data set is 0.84 Fleiss\u2019 kappa measure. FS recognition for spoken texts, however, is more challenging than working with written documents due to some reasons as follows:\n1) First, spoken text are commonly shorter and less grammatical, not comply with rigid syntactic constraints. Sentence elements like subject or object are often omitted. It is very context-dependent. Also, there are no punctuation marks in the texts. It, therefore, is non\u2013trivial to segment and parse spoken sentences correctly. 2) Second, conversational speech contains a lot of selfcorrecting, hesitation, and stutter. This is one of the\n2https://catalog.ldc.upenn.edu/LDC2017S01\nmain reasons that causes nested FS. fs9 and fs13 within turn t4 in Table II are the instances.\n3) Third, the output text of Automatic Speech Recognition are all in lowercase and bearing a small percentage of errors.\nThese challenges make it extremely difficult to recognize FS in particular and in understanding spoken language in general.\nVietnamese local dialect dictionary\nThe LDC2017S01 data is built from spoken conversations in the North, North-Central, Central and Southern Vietnamese dialect. Because of the nature of Vietnamese dialects, a lot of words in local dialects can be changed to standard dialect (the North Vietnamese dialect) without affecting the meaning of the utterances in which they belongs. For instances, \u201cR\u0103ng r\u1ee9a\" means \u201csao th\u1ebf\" (what up); \u201cMi \u0111i m\u00f4\" means \u201cM\u00e0y \u0111i \u0111\u00e2u\" (where are you going?). Therefore we created a dictionary to match these words with standardized words. By doing so, the data sets become more uniform. This makes it easier to handle and help the models to run better. Our dictionary is not only useful in this study but also can be very helpful in all other studies that involve Vietnamese human\u2013human, and human\u2013machine conversation."}, {"heading": "IV. DA SEGMETATION WITH ME, CRF AND BI-LSTM-CRF", "text": "The number of discontinuous or nested functional segments account for a very small percent in both data sets (0.5% in the Message corpus, 0.9% in the Phone corpus). Hence there are not enough discontinuous or nested functional segments so the models can learn to identify them. For that reason, this paper only focuses on identifying continuous and unnested functional segments (which make up more than 99% of both data sets). In future studies, we intend to increase the size of our data sets, the number of discontinuous or nested functional segments and study methods to identify these functional segments. In this paper, we cast the segmentation problem as a sequential tagging task: the first word of a FS is marked with B_fs (Begin of a FS), the token that is inside of a FS is marked with I_FS (Inside of a FS). The problem of FS identification in a sentence is modeled as the problem of labeling syllables in that sentence with two above labels. Let t = {t1, t2, ...tn} be turns and y = {B, I} be per-token output tags. We predict the most likely y, given a conditional model P (y|t)."}, {"heading": "A. Maximum Entropy", "text": "The ME (Maxent) model defines conditional distribution of class (y) given an observation vector t as the exponential form in Formula (1) [15]:\nP (y/t) = 1\nZ(t) exp ( K\u2211 1 \u03b8k(t, y) ) (1)\nwhere \u03b8k is a weight parameter to be estimated for the corresponding feature function fk(t, y), and Z(t) is a normalizing factor over all classes to ensure a proper probability. K is the total number of feature functions. We decided to use ME for evaluation and comparison because it is commented that it is suitable for sparse data like natural language, encode various rich and overlapping features at different levels of granularity [16]."}, {"heading": "B. Conditional Random Fields", "text": "The CRFs model defines also the conditional distribution of the class (y) given an observation vector t as the Formular (1) [17]. In which \u03b8k is a weight parameter to be estimated for the corresponding feature function fk(t, y), and Z(t) is a normalizing factor over all classes to ensure a proper probability. And K is the total number of feature functions. It is essentially a ME model over the entire sequence. It is unlike the Maxent above since it models the sequence information, because the Maxent model decides for each state independently with the other states. For example, a transcription utterance together with class tags used for the CRF word detection model in Dialog act segmentation as follows:\nTraining ME and CRF are commonly performed by maximizing the likelihood function with respect to the training data using advanced convex optimization techniques like L\u2013BFGS [18]."}, {"heading": "C. Deep learning\u2013based models with Bi\u2013LSTM\u2013CRF", "text": "Bi\u2013LSTM\u2013CRF network is formed by combining a bidirectional LSTM network and a CRF network [9]. Therefore Bi\u2013 LSTM\u2013CRF can efficiently use past and future input features via a Bi\u2013LSTM layer and sentence level tag information via a CRF layer. A CRF layer is represented by lines which connect consecutive output layers. A CRF layer has a state transition matrix as parameters. The following are examples of a text in the Bi\u2013LSTM\u2013CRF model: BI\u2013LSTM\u2013CRF has emerged as a\nstandard method for obtaining per-token vector representations serving as input to various token labeling tasks. We expect that dialog act segmentation in Vietnamese using BI\u2013LSTM\u2013CRFs model will also similar to highly accurate results."}, {"heading": "V. EVALUATION", "text": "The simple lexical feature, n\u2013gram (unigram, bigram and trigram), is used for the ME and CRF models. We do experi-\nments on two different conversational data sets (Message data set and Phone data set) after normalizing these data sets using local dialect dictionary and online chat dictionary.\nTraining ME and CRF are commonly performed by maximizing the likelihood function with respect to the training data using quasi-Newton methods like L\u2013BFGS [18]. Thus, in the experiments with ME and CRF, we use L-BFGS method. For CRF models, we use second-order Markov dependency. On experiment with CRF, we use tools: FlexCRFs - a C/C++ implementation of CRFs 3. On experiment with Bi\u2013LSTM\u2013 CRF, our setup is based on study of Lample et al. 4 [19] .\nFor evaluating each experiments, we randomly divide each corpus into five parts to do 5-fold cross-validation test. In each fold we take one partition for testing and 4 partitions for training. The summary of the experiment results on Message data set is shown in Table III, the experiment results on Phone data set is shown in Table IV. The results of label-based performance evaluation are significantly higher than the results of label-based performance evaluation and chunk-based performance evaluation. The evaluation measures for this task are precision and recall based on labels:\nprecision = number of correctly predicted label by the modelnumber of label predicted by the model ;\nrecall = number of correctly predicted label by the modelnumber of actual label annotated by humans ;\nAveragemacro is the average of the precision and recall of the model on different classes. Averagemicro is sum up the individual true positives, false positives, and false negatives of the model for different classes.\nThe precision and recall based on chunks is as follows:\nprecision = number of correctly predicted FS by the modelnumber of FS predicted by the model ;\nrecall = number of correctly predicted FS by the modelnumber of actual FS annotated by humans ;\nF1\u2013 score in the both of evaluations is calculated as follows:\nF1 = 2\u2217(precision\u2217recall) (precision+recall) ;\nBI\u2013LSTM\u2013CRF models achieved the highest performance (average F1 of 90.42% with Messages dataset, 73.26% with Phone dataset). This was an indication that it is robust and less affected by the removal of engineering features.\nPerformance results with Messages data (manual texts) are higher than results achieved with Phones data (Automatic Speech Recognition transcripts) because turns in Messages data set are often shorter and less ambiguous for dialog act segmentation than turns in Phone data set. Turns in Phone data set also includes hesitance, repeat, and overlap. These make discontinuous segments, either within a turn or spread over several turns as we have already discussed. A greater challenge is posed by those cases where different functional segments overlapped.\nAnother observation from the results is that Bi-LSTMCRFs, the deep learning approach, performs significantly bet-\n3http://flexcrfs.sourceforge.net/ 4https://github.com/glample/tagger\nter than both CRF and ME, the machine learning approaches, by every measure. Because deep learning has never been used for dialog act segmentation before, this result opens up a very promising new direction for future studies to approach dialog act segmentation and dialog act in general. Between the machine learning approaches, CRF performs better than ME overall. This can be explained by looking at how CRF and ME works. ME is locally re-normalized and suffers from the label bias problem, while CRFs are globally re-normalized. This label bias problem can happen a lot, especially with very context-dependent data sets like Message corpus and Phone corpus."}, {"heading": "VI. CONCLUSIONS", "text": "We have presented a thorough investigation on Vietnamese FS identification using machine learning approach and deep learning approach. We built two annotated corpora for evaluation and two dictionaries that make the data sets more uniform and help the models run better. Two machine learning techniques and a deep learning technique are applied and compared on the task of automatic dialog act segmentation. Deep learning technique is also applied for the first time to dialog act segmentation. We also draw some useful conclusions observed from the experimental results that can be very helpful for future studies.\nThese encouraging results show that the task of identifying functional segment is promising to continue to the next dialogue act identification steps and towards understanding intentions in the users\u2019 utterances for Vietnamese. For future work, we intend to extend the studies into two directions. First,\nwe plan to increase the size of our data set to get sufficient amount of instances in different types of functional segment and study deeper methods to solve nested FS identification. Second, we intend to use features included in the data sets as dialogue history, prosody to improve automatic FSs recognition and dialogue processing."}, {"heading": "ACKNOWLEDGMENT", "text": "This work was supported by the project QG.15.29 from Vietnam National University, Hanoi (VNU)."}], "references": [{"title": "ISO 24617- 2: A Semantically-Based Standard for Dialogue Annotation.", "author": ["H. Bunt", "J. Alexandersson", "J.W. Choe", "A.C. Fang", "K. Hasida", "V. Petukhova", "A. Popescu-Belis", "D. Traum"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "An efficient statistical speech act type tagging system for speech translation systems.", "author": ["H. Tanaka", "A. Yokoo"], "venue": "In ACL\u201937,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "Spoken language understanding: An introduction to the statistical framework.", "author": ["Y. Wang", "L. Deng", "A. Acero"], "venue": "IEEE Signal Processing Magazine, vol. 22,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Dialogue act recognition approaches.", "author": ["P. Kr\u00e1l", "C. Cerisara"], "venue": "In Computing and Informatics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Multi-view semisupervised learning for dialog act segmentation of speech.", "author": ["U. Guz", "S. Cuendet", "D. Hakkani-Tur", "G. Tur"], "venue": "IEEE transactions on audio, speech, and language processing,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Shriberg.\u201cAutomatic dialog act segmentation and classification in multiparty meetings.\" In: ICASSP\u201905", "author": ["Ang", "Jeremy", "Yang Liu", "Elizabeth"], "venue": "IEEE International Conference on. Vol,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2005}, {"title": "Simultaneous dialog act segmentation and classification from human-human spoken conversations.", "author": ["S. Quarteroni", "A.V. Ivanov", "G. Riccardi"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Bidirectional LSTM-CRF models for sequence tagging.", "author": ["Z. Huang", "W. Xu", "K. Yu"], "venue": "arXiv preprint arXiv:1508.01991,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "How to do things with words.", "author": ["J.L. Austin"], "venue": "Oxford university press,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1975}, {"title": "A taxonomy of illocutionary acts.", "author": ["J.R. Searle"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1975}, {"title": "Dialogue Act Detection from Human-Human Spoken Conversations.", "author": ["Ramacandran", "Nithin"], "venue": "In: International Journal of Computer Applications,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Multifunctionality in dialogue.", "author": ["H. Bunt"], "venue": "Computer Speech & Language 25.2,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Measuring nominal scale agreement among many raters", "author": ["J.L. Fleiss"], "venue": "Psychological bulletin,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1971}, {"title": "A maximum entropy approach to natural language processing.", "author": ["A. Berger", "S.A.D. Pietra", "V.J.D. Pietra"], "venue": "Computational Linguistics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1996}, {"title": "Using maximum entropy for text classifi- cation", "author": ["K. Nigam", "J. Lafferty", "A. McCallum"], "venue": "IJCAI Workshop on Machine Learn. for Info. Filtering,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1999}, {"title": "Conditional random fields: probabilistic models for segmenting and labeling sequence data.", "author": ["J.D. Lafferty", "A. McCallum", "F. Pereira"], "venue": "In: ICML,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2001}, {"title": "On the limited memory BFGS method for large\u2013scale opti- mization.", "author": ["D. Liu", "J. Nocedal"], "venue": "Mathematical Programming,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1989}, {"title": "Neural architectures for named entity recognition.", "author": ["G. Lample", "M. Ballesteros", "S. Subramanian", "K. Kawakami", "C. Dyer"], "venue": "arXiv preprint arXiv:1603.01360,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Because, \u201cDialog act is a communicative activity of dialog participant, interpreted as having a certain communicative function and semantic content\" [1].", "startOffset": 149, "endOffset": 152}, {"referenceID": 1, "context": "It is important for many applications: dialogue systems, automatic translation machine [2], automatic speech recognition, etc [3] [4] and has been studied in various languages such as English, Chinese, Arabic, Czech, Korean.", "startOffset": 87, "endOffset": 90}, {"referenceID": 2, "context": "It is important for many applications: dialogue systems, automatic translation machine [2], automatic speech recognition, etc [3] [4] and has been studied in various languages such as English, Chinese, Arabic, Czech, Korean.", "startOffset": 126, "endOffset": 129}, {"referenceID": 3, "context": "It is important for many applications: dialogue systems, automatic translation machine [2], automatic speech recognition, etc [3] [4] and has been studied in various languages such as English, Chinese, Arabic, Czech, Korean.", "startOffset": 130, "endOffset": 133}, {"referenceID": 4, "context": "implemented DA segmentation of speech using multi-view semisupervised learning [5]; Jeremy Ang et al.", "startOffset": 79, "endOffset": 82}, {"referenceID": 5, "context": "explored DA segmentation using simple lexical and prosodic knowledge sources [6]; Warnke et al.", "startOffset": 77, "endOffset": 80}, {"referenceID": 6, "context": "segmented human-human dialog into turns and intra-turn segmentation into DA boundaries using CRFs to learn models for simultaneous segmentation of DAs from whole human-human spoken dialogs [8].", "startOffset": 189, "endOffset": 192}, {"referenceID": 0, "context": "According to ISO 24617-2 standard about Dialog Act, a functional segment (FS) is defined as \u201cminimal stretch of communicative behavior that have a communicative function\" [1].", "startOffset": 171, "endOffset": 174}, {"referenceID": 7, "context": "Recently, ME, CRF and Bi\u2013LSTM\u2013CRF have been applied to a variety of sequence labeling and segmentation tasks in Natural Language Processing and have achieved state-ofthe-art results [9].", "startOffset": 182, "endOffset": 185}, {"referenceID": 8, "context": "DAs are extended from the speech act theory of Austin [10] and Searle [11] to model the conversational functions that utterances can perform.", "startOffset": 54, "endOffset": 58}, {"referenceID": 9, "context": "DAs are extended from the speech act theory of Austin [10] and Searle [11] to model the conversational functions that utterances can perform.", "startOffset": 70, "endOffset": 74}, {"referenceID": 10, "context": "functional segment identification and 3) the classification of each segment according to a DA tag [12].", "startOffset": 98, "endOffset": 102}, {"referenceID": 0, "context": "A functional segment is the \u201cminimal stretch of communicative behavior that has a communicative function\u201d, \u201cminimal in the sense of not including material that does not contribute to the expression of the function or the semantic content of the dialogue act\" [1].", "startOffset": 259, "endOffset": 262}, {"referenceID": 11, "context": "The detailed explanation of the types of FS is presented in [13] and the ISO 24617-2 standard.", "startOffset": 60, "endOffset": 64}, {"referenceID": 12, "context": "87 Fleiss\u2019 kappa measure [14].", "startOffset": 25, "endOffset": 29}, {"referenceID": 13, "context": "The ME (Maxent) model defines conditional distribution of class (y) given an observation vector t as the exponential form in Formula (1) [15]:", "startOffset": 137, "endOffset": 141}, {"referenceID": 14, "context": "We decided to use ME for evaluation and comparison because it is commented that it is suitable for sparse data like natural language, encode various rich and overlapping features at different levels of granularity [16].", "startOffset": 214, "endOffset": 218}, {"referenceID": 15, "context": "The CRFs model defines also the conditional distribution of the class (y) given an observation vector t as the Formular (1) [17].", "startOffset": 124, "endOffset": 128}, {"referenceID": 16, "context": "Training ME and CRF are commonly performed by maximizing the likelihood function with respect to the training data using advanced convex optimization techniques like L\u2013BFGS [18].", "startOffset": 173, "endOffset": 177}, {"referenceID": 7, "context": "Bi\u2013LSTM\u2013CRF network is formed by combining a bidirectional LSTM network and a CRF network [9].", "startOffset": 90, "endOffset": 93}, {"referenceID": 16, "context": "Training ME and CRF are commonly performed by maximizing the likelihood function with respect to the training data using quasi-Newton methods like L\u2013BFGS [18].", "startOffset": 154, "endOffset": 158}, {"referenceID": 17, "context": "4 [19] .", "startOffset": 2, "endOffset": 6}, {"referenceID": 0, "context": "[1] Bunt, H.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Tanaka, H.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Y.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Kr\u00e1l, P.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Guz, U.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Ang, Jeremy, Yang Liu,Elizabeth Shriberg.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[8] Quarteroni, S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9] Huang, Z.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[10] Austin, J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[11] Searle, J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] Ramacandran, Nithin.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[13] Bunt, H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[14] Fleiss, J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15] Berger, A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] Nigam, K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] Lafferty, J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] Liu, D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] Lample, G.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "Dialog act identification plays an important role in understanding conversations. It has been widely applied in many fields such as dialogue systems, automatic machine translation, automatic speech recognition, and especially useful in systems with human-computer natural language dialogue interfaces such as virtual assistants and chatbots. The first step of identifying dialog act is identifying the boundary of the dialog act in utterances. In this paper, we focus on segmenting the utterance according to the dialog act boundaries, i.e. functional segments identification, for Vietnamese utterances. We investigate carefully functional segment identification in two approaches: (1) machine learning approach using maximum entropy (ME) and conditional random fields (CRFs); (2) deep learning approach using bidirectional Long Short-Term Memory (LSTM) with a CRF layer (Bi-LSTM-CRF) on two different conversational datasets: (1) Facebook messages (Message data); (2) transcription from phone conversations (Phone data). To the best of our knowledge, this is the first work that applies deep learning based approach to dialog act segmentation. As the results show, deep learning approach performs appreciably better as to compare with traditional machine learning approaches. Moreover, it is also the first study that tackles dialog act and functional segment identification for Vietnamese. Keywords\u2014Dialog act segmentation, functional segment, Vietnamese conversation.", "creator": "LaTeX with hyperref package"}}}