{"id": "1708.07038", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Aug-2017", "title": "Non-linear Convolution Filters for CNN-based Learning", "abstract": "staphylococcus During the campanula last dreamlands years, Convolutional Neural looseleaf Networks (deitsch CNNs) \u0161ternberk have nikoli achieved upu state - retz of - cordoned the - procacci art magician performance in liding\u00f6 image al\u00e8s classification. Their rammstein architectures cobreloa have largely drawn inspiration goldberg by tiantan models 112.20 of wishbones the primate visual ddm system. blasdel However, while recent research results mbusa of 12-month neuroscience panichgul prove ponnani the quarantine existence monroy of non - alawites linear vasseur operations elvan in whimpers the leiv response kojiki of beaubassin complex visual easley cells, little toos effort akvavit has well-constructed been schottenheimer devoted to taarab extend enric the pippen convolution syafiuddin technique snac to 32,100 non - conisbee linear monterrico forms. Typical screenwriter convolutional layers are zelea linear madey systems, r.e.d. hence noncooperation their maccabe expressiveness is oldfield limited. breiman To 6-time overcome this, various non - linearities have been used kadavu as 747-8 activation suffocatingly functions pericarditis inside CNNs, while also many odr pooling strategies al-nusra have energy-momentum been mando applied. vaishnavite We address the issue 2.1-billion of qeshl\u0101q-e developing a mot\u00f6rhead convolution method in the skyworth context historias of siembieda a hoffenheim computational model of power6 the visual cortex, exploring quadratic losartan forms makana through scientologists the valign Volterra clarenceux kernels. svir Such forms, 15-square constituting joyously a sede more rich blog/ function space, 1753 are ucl used as approximations of the response profile inci of visual cells. Our 22-caliber proposed papiers second - order convolution is smartmoney tested erythritol on cursillo CIFAR - gilsland 10 spilled and CIFAR - nohlgren 100. k-series We ortegal show that a network which combines linear realpolitik and cardinal-priest non - linear filters in its convolutional bethnal layers, appease can drug-trafficking outperform networks fraunhofer that use 1,644 standard virovitica linear serra filters clubfoot with the ind\u00edgena same architecture, yielding results helgenberger competitive with 2,003 the state - kalemeh of - hudsons the - monocarpic art quiza on marakanond these christodoulakis datasets.", "histories": [["v1", "Wed, 23 Aug 2017 15:07:35 GMT  (440kb,D)", "http://arxiv.org/abs/1708.07038v1", "9 pages, 5 figures, code link, ICCV 2017"]], "COMMENTS": "9 pages, 5 figures, code link, ICCV 2017", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["georgios zoumpourlis", "alexandros doumanoglou", "nicholas vretos", "petros daras"], "accepted": false, "id": "1708.07038"}, "pdf": {"name": "1708.07038.pdf", "metadata": {"source": "CRF", "title": "Non-linear Convolution Filters for CNN-based Learning", "authors": ["Georgios Zoumpourlis", "Alexandros Doumanoglou", "Nicholas Vretos", "Petros Daras"], "emails": ["daras}@iti.gr"], "sections": [{"heading": "1. Introduction", "text": "Convolutional neural networks (CNNs) have been shown to achieve state-of-the-art results on various computer vision tasks, such as image classification. Their architectures have largely drawn inspiration by models of the primate visual system, as the one described by Hubel and Wiesel [13]. The notion of convolution, used to mimic a functional aspect of neurons in the visual cortex, is critical to understand their success.\nTypical convolutional layers are linear systems, as their outputs are affine transformations of their inputs. Due to\ntheir linear nature, they lack the ability of expressing possible non-linearities that may actually appear in the response of complex cells in the primary visual cortex [25]. Hence, we claim that their expressiveness is limited. To overcome this, various non-linearities have been used as activation functions inside CNNs, while also many pooling strategies have been applied. Little effort has been devoted to explore new computational models that extend the convolution technique to non-linear forms, taking advantage of the research results of neuroscience, that prove the existence of nonlinear operations in the response of visual cells [31][24]. The complexity of human visual cortex demonstrates gaps that need to be bridged by CNNs, regarding the way convolution operations are applied. One of these gaps, is the exploration of higher-order models.\nIn this work, we study the possibility of adopting an alternative convolution scheme to increase the learning capacity of CNNs by applying Volterra\u2019s theory [32], which has been used to study non-linear physiological systems, adapting it to the spatial domain. Considering the convolution operation, instead of summing only linear terms to compute a filter\u2019s response on a data patch, we propose to also sum the non-linear terms produced by multiplicative interactions between all the pairs of elements of the input data patch. Transforming the inputs through a second-order form, we aim at making them more separable. In this way, convolution filters with more rich properties in terms of selectivity and invariance are created.\nThe novelties of the proposed work are:\n\u2022 The incorporation of a biologically plausible nonlinear convolution scheme in the functionality of CNNs\n\u2022 The derivation of the equations that describe the forward and backward pass during the training process of this filter type\n\u2022 A CUDA-based implementation of our method as a\nar X\niv :1\n70 8.\n07 03\n8v 1\n[ cs\n.C V\n] 2\n3 A\nug 2\nnon-linear convolutional layer\u2019s module in Torch71[5]\nThe rest of the paper is organized as follows: in Section 2, related work is outlined. In Section 3, the proposed method is described, theoretically grounded to Volterra\u2019s computational method, and the concept of training is mathematically explained, while a description of our scheme\u2019s practical implementation is given in Section 4. In Section 5 experimental results on CIFAR-10 and CIFAR-100 datasets are drawn and finally in Section 6 the paper is concluded."}, {"heading": "2. Related Work", "text": "One of the first biologically-inspired neural networks, was Fukushima\u2019s Neocognitron [8], which was the predecessor of CNN, as it was introduced by LeCun et al. in [6]. Convolutional layer is the core building block of a CNN. Early implementations of CNNs have used predefined Gabor filters in their convolutional layers. This category of filters can model quite accurately the properties of simple cells found in the primary visual cortex (V1) [21].\nThis type of visual cell has a response profile which is characterized by spatial summation within the receptive field. Finding the optimal spatial stimuli [7] for simple cells is a process based on the spatial arrangement of their excitatory and inhibitory regions [23]. However, this does not hold true for complex visual cells. Also, we cannot obtain an accurate description of their properties, by finding their optimal stimulus.\nThis fact has been ignored by most of the CNN implementations so far, as they have settled to the linear type of convolution filters, trying to apply quantitative rather than qualitative changes in their functionalities. He et al. [10] proposed Residual Networks (ResNets), which have shortcut connections parallel to their normal convolutional layers, as a solution to the problems of vanishing/exploding gradient and hard optimization when increasing the model\u2019s parameters (i.e. adding more layers). Zagoruyko & Komodakis [34] showed that wide ResNets can outperform ResNets with hundrends of layers, shifting the interest to increasing the number of each layer\u2019s filters. Alternatively to works that focus on creating networks with more convolutional layers or more filters, we evaluate the impact of using both non-linear and linear terms as approximations of convolution kernels to boost the performance of CNNs.\nApart from ResNets, very low error rates have also been achieved in the ImageNet Challenge [27] by methods that used their convolutional layers in new ways, enhancing their representation ability. Lin et al. [20] proposed \u201cNetwork in Network (NIN)\u201d, as a remedy to the low level of abstraction that typical filters present. Instead of the conventional convolution filter, which is a generalized linear\n1http://torch.ch/\nmodel, they build micro neural networks with more complex structures to abstract the data within the receptive field. To map the input data to the output, they use multilayer perceptrons as a non-linear function approximator, which they call \u201cmlpconv\u201d layer. The output feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN. Szegedy et al. [30] introduced a new level of organization in the form of the \u201cInception module\u201d, which uses filters of variable sizes to capture different visual patterns of different sizes, and approximates the optimal sparse structure. Xie et al. [33] proposed a way to exploit the split-transform-merge strategy of \u201cInception\u201d models, performing a set of transformations, each on a lowdimensional embedding, whose outputs are aggregated by summation.\nThe authors of [19], based on the abundancy of recurrent synapses in the brain, proposed the use of a recurrent neural network for image classification. They proved that inserting recurrent connections within convolutional layers, gives boosted results, compared to a feed-forward architecture. Their work is a biologically plausible incorporation of mechanisms originating from neuroscience into CNNs.\nIn [28], a Boltzmann learning algorithm is proposed, where feature interactions are used to turn hidden units into higher-order feature detectors. In [22], an efficient method to apply such learning algorithms on higher-order Boltzmann Machines was proposed, making them computationally tractable for real problems.\nIn [1], Bergstra et al. created a model for neural activation which showed improved generalization on datasets, by incorporating second-order interactions and using an alternative non-linearity as activation function.\nIn [2], an attempt is made to analyze and interpret quadratic forms as receptive fields. In their study, it was found that quadratic forms can be used to model non-linear receptive fields due to the fact that they follow some of the properties of complex cells in the primary visual cortex. These properties include response to edges, phase-shift invariance, direction selectivity, non-orthogonal inhibition, end-inhibition and side-inhibition. In constrast to the standard linear forms, in quadratic and other non-linear forms the optimal stimuli do not provide a complete description of their properties. It is shown that no invariances occure for an optimal stimulus while for other general sub-optimal stimuli there may exist many invariances which could be of a large number but lack easy interpretation. Although the optimal stimulus is not related to a filter\u2019s invariance, its neighborhood is studied under a more loose sense of transformation invariance. It is shown that proper quadratic forms can demonstrate invariances in phase-shift and orientation change. From the previous discussion we conclude that using non-linear forms to convolutional layers may be a reasonable future direction in computer vision."}, {"heading": "3. Proposed Method", "text": "The proposed method, as earlier stated, makes use of the Volterra kernel theory to provide means of exploiting the non-linear operations that take place in a receptive field. Up to now, and to the best of our knowledge, non-linearities were exploited mainly through the activation functions and pooling operations between different layers of CNNs. Nevertheless, such non-linearities may be an approach to code inner processes of the visual system, but not the ones that exist in a receptive field\u2019s area.\nOur method follows the typical workflow of a CNN, by lining up layers of different purposes (convolution, pooling, activation function, batch normalization, dropout, fullyconnected etc.), while a non-linear convolutional layer can be plugged in practically in all existing architectures. Nevertheless, due to its augmentation of trainable parameters involved, care should be taken for the complexity of the overall process. To that end, a CUDA implementation in Section 4 is also provided."}, {"heading": "3.1. Volterra-based convolution", "text": "The Volterra series model is a sequence of approximations for continuous functions, developed to represent the input-output relationship of non-linear dynamical systems, using a polynomial functional expansion. Their equations can be composed by terms of infinite orders, but practical implementations based on them use truncated versions, retaining the terms up to some order r.\nIn a similar way to linear convolution, Volterra-based convolution uses kernels to filter the input data. The firstorder Volterra kernel, contains the coefficients of the filter\u2019s linear part. The second-order kernel represents the coefficients of quadratic interactions between two input elements. In general, the r-th order\u2019s kernel represents the weights that non-linear interactions between r input elements have on the response. In the field of computer vision, Volterra kernels have been previously used in [17] for face recognition, serving effectively as approximations of non-linear functionals."}, {"heading": "3.2. Forward pass", "text": "For our proposed convolution, we adopted a secondorder Volterra series. Given an input patch I \u2208 IRkh\u00d7kw with n elements (n = kh\u00b7kw), reshaped as a vector x \u2208 IRn:\nx = [ x1 x2 \u00b7 \u00b7 \u00b7 xn ]T (1)\nthe input-output function of a linear filter is:\ny(x) = n\u2211 i=1 ( wi1xi ) + b (2)\nwhere wi1 are the weights of the convolution\u2019s linear terms, contained in a vector w1, and b is the bias. In our approach, this function is expanded in the following quadratic form:\ny(x) = n\u2211 i=1 ( wi1xi ) + n\u2211 i=1 n\u2211 j=i ( wi,j2 xixj ) + b (3)\nwhere wi,j2 are the weights of the filter\u2019s second-order terms. To avoid considering twice the interaction terms for each pair of input elements (xi, xj), we adopt an uppertriangular form for the matrix w2 containing their weights, so that the number of trainable parameters for a secondorder kernel is n(n + 1)/2. The generic type to compute the total number of parameters, nV , for a Volterra-based filter of order r is:\nnV = (n+ r)!\nn!r! (4)\nIn a more compact form, (3) is written as:\ny(x) = xTw2x\ufe38 \ufe37\ufe37 \ufe38 quadratic term + w1 Tx\ufe38 \ufe37\ufe37 \ufe38 linear term +b (5)\nwhile for the Volterra kernels we have:\nw2 =  w1,12 w 1,2 2 \u00b7 \u00b7 \u00b7 w 1,n 2 0 w2,22 \u00b7 \u00b7 \u00b7 w 2,n 2 ... ... . . . ...\n0 0 \u00b7 \u00b7 \u00b7 wn,n2\n (6)\ncontaining the coefficients wi,j2 of the quadratic term, and:\nw1 T = [ w11 w 2 1 \u00b7 \u00b7 \u00b7 wn1 ] (7)\ncontaining the coefficients wi1 of the linear term. The proposed convolution\u2019s output can thus be rewritten as:\ny(x) =  w1,12 w1,22 w1,32\n... wn,n2\n T  x1x1 x1x2 x1x3 ...\nxnxn\n+ \nw11 w21 w31 ... wn1\n T  x1 x2\nx3 ... xn\n+ b (8)\nNote that superscripts (i, j) to weights wi,j2 denote correspondence to the spatial positions of the input elements xi and xj that interact."}, {"heading": "3.3. Backward pass", "text": "The derivation of the equations for the backward pass of the Volterra-based convolution, is done by adapting the classic backpropagation scheme to the aforementioned inputoutput function of (3). To train the weights of the Volterra kernels, we need to compute the gradients of the layer\u2019s output y(x), with respect to the weights wi1 and w i,j 2 . To propagate the error, we have to compute the gradients of the layer\u2019s output y(x), with respect to the inputs xi. Hence, \u2202y \u2202wi1 , \u2202y \u2202wi,j2\nand \u2202y\u2202xi are the terms that will be used to optimize the weight parameters of our Volterra-based convolutional layer and minimize the network loss. The mathematical equations of backpropagation, are as follows:\n\u2202y\n\u2202wi1 = xi\n\u2202y\n\u2202wi,j2 = xixj (9)\n\u2202y \u2202xi = wi1 + i\u2211 k=1 ( wk,i2 xk ) + n\u2211 k=i ( wi,k2 xk ) (10)"}, {"heading": "4. Quadratic convolution filter implementation", "text": "In order to experiment with the non-linear convolution filters, we used the Torch7 scientific framework. Volterrabased convolution was implemented as a module integrated with the CUDA backend for the Neural Network (cunn) Package of Torch7. Writing a module in Torch7 mainly consists of implementing the module\u2019s forward pass (3) as well as the computation of the module\u2019s gradients ( \u2202E\u2202w and \u2202E \u2202x ), that are used in back-propagation. We denote byE the error defined by the network\u2019s criterion function and refer to \u2202E \u2202w as the layer\u2019s weight gradient and \u2202E \u2202x as the layer\u2019s input gradient. To implement the forward pass in CUDA, we used the standard im2col [3] pattern to unfold data patches into columns, followed by a matrix multiplication with the Volterra-based filter weights. The im2col operation is conducted in parallel by a CUDA kernel, while for the matrix multiplication we used the well established CUDA BLAS functions. Subsequently, computing the weight gradients is, to some extent, similar to computing the forward pass. Once again, the im2col operation is executed on the input image as a CUDA kernel and its output matrix is multiplied with the previous layer\u2019s input gradient resulting into \u2202E\u2202w . The most expensive operation in a Volterra-based convolutional layer is the computation of the input gradients. As already mentioned before, in contrast to linear convolution, where the input gradient is independent of the provided input, our layer\u2019s input gradient is input-dependent. Thus, to compute the matrix of input gradients, firstly we compute an unfolded matrix containing the gradients of the output with respect to the input. This matrix is then multiplied with the previous layer\u2019s input gradient using CUDA BLAS\nfunctions. Finally, an appropriate inverse col2im CUDA kernel aggregate operation results in the final matrix of the Volterra-based layer\u2019s input gradients \u2202E\u2202x .\nA major difference between the proposed convolution scheme and linear convolution, is the fact that in our case \u2202y \u2202xi\nis a function dependent on xi. This means that, in contrast to standard filters, this term is different for every single patch of a feature map, resulting in an extra computational cost, when the error must be propagated to preceding trainable layers in the network. This cost is proportionate to Ho \u00b7 Wo, where Ho and Wo are the height and the width of the layer\u2019s output feature map, respectively. Our layer\u2019s code is available at http://vcl.iti.gr/volterra."}, {"heading": "5. Experiments", "text": "We measure the performance of our proposed Volterrabased convolution on two benchmark datasets: CIFAR-10 and CIFAR-100 [15], running our experiments on a PC equipped with Intel i7-5820K CPU, 64GB RAM and Nvidia Titan X GPU. The Volterra-based convolutional layer was implemented in Torch7. We first describe the experimental setup, then we show a quantitative analysis, in terms of parameters, classification error and train loss, for the proposed method."}, {"heading": "5.1. CNN architecture selection", "text": "As explained in Section 4, using the proposed convolution in multiple layers of a CNN, an extra computational overhead is introduced during backpropagation. For this reason, we restrain ourselves to testing such filters only in the first convolutional layer of a CNN model. We choose the modern architecture of Wide ResNet [34], which mainly consists of a convolutional layer, followed by 3 convolutional groups and a classifier. If d is such a network\u2019s depth, then each convolutional group contains N = (d \u2212 4)/6 convolutional blocks. In a group, the number of each convolutional layer\u2019s filters, is controlled by the widening factor k. In our architecture, we follow the above rules, making three changes: a) we insert a Batch Normalization layer in the start of the network b) we change the number of the first convolutional layer\u2019s output channels, from 16 to 16 \u00b7 k (i.e., equal to the number of the first group\u2019s output channels) and c) we change the shortcut of the first block in the first group, into an identity mapping, as a consequence of our second change. The first change is crucial to prevent the output of the Volterra-based convolution from exploding, due to the multiplicative interaction terms xixj . In our experiments, parameter \u03b3 of the affine transformation y = \u03b3x\u0302+ \u03b2 that is applied in this layer, settles to values 0 < \u03b3 < 1. The second change was chosen so that, when the Volterra-based convolution is applied in the first convolutional layer, there are enough non-linear filters to be learnt, producing a feature-rich signal. The third\nchange is done because when a block\u2019s input and output channels are equal, then its shortcut is an identity mapping, so that its input is added to its output, without the need to adjust the feature channels in the shortcut by using a convolutional layer. In this case, the signal of the first convolutional layer flows intact through the shortcuts of the first group\u2019s blocks.\nThe model used in our experiments is described in Table 1. To evaluate the impact of applying the Volterra-based convolution on each dataset, we tested two versions of the general CNN model. The first version, which serves as the baseline model, does not use any non-linear convolution filter. The other version contains non-linear filters in the first convolutional layer and linear filters in all the convolutional groups of the network."}, {"heading": "5.2. Experimental setup", "text": "In all our experiments we use Stochastic Gradient Descent (SGD) with momentum set to 0.9 and cross-entropy\nloss, with a batch size of 128, training our network for 220 epochs. Dropout is set to 0.3 and weight initialization is done as in [10]. The learning rate and weight decay strategy used in the experiments is shown in Table 2. For CIFAR-10\nand CIFAR-100, the data-preprocessing operation applied to both train and test set\u2019s data, is subtracting the channel means and then dividing by the channel standard deviations, computed on the train set. We apply moderate data augmentation, using horizontal flipping with a probability of 50% and reflection-padding by 4 pixels on each image side, taking a random crop of size 32\u00d7 32."}, {"heading": "5.3. CIFAR-10 and CIFAR-100", "text": "CIFAR-10 and CIFAR-100 datasets contain 60.000 32\u00d7 32 RGB images of commonly seen object categories (e.g., animals, vehicles, etc.), where the train set has 50.000 and the test set has 10.000 images. CIFAR-10 has 10 classes and CIFAR-100 has 100 classes. All classes have equal number of train and test samples. In CIFAR-10, our Volterrabased Wide ResNet yields a test error of 3.51%, which shows an improvement over the 3.62% error that we got using the baseline model, setting the state-of-the-art on this dataset. In CIFAR-100, our Volterra-based Wide ResNet yields a test error of 18.24%, which shows an improvement over the 18.29% error that we got using the baseline model. Our results on CIFAR-100 are outperformed only by [33], due to the huge number of parameters their model makes use of. The features fed to the convolutional groups, when extracted by the non-linear convolution filters, make the network avoid overfitting. This can be inferred by the loss plot of our models on CIFAR-100, which is shown in Figure 2. The Baseline Wide ResNet, although having constantly lower loss than the Volterra-based Wide ResNet, yields higher test error. Our Volterra-based Wide ResNets have only 0.05% more parameters than the Baseline counterparts. A summary of the best methods on these datasets is provided in Table 3."}, {"heading": "5.4. Weight visualization", "text": "To get an insight on what features do non-linear filters learn, we visualize their weights in a simple but efficient\nmanner. For the linear term, the process is straightforward. For the second-order term, considering the weights w2 of each filter, we can create n weight vectors qi, qi = [wi12 , w i2 2 , ..., w in 2 ]. Reshaping each one of these vectors qi into a kh \u00d7 kw matrix, we can see the weights that correspond to the interactions between xi and all of the receptive field\u2019s elements. Figure 4 shows the weights of the linear term and the interactions captured by a second-order 3 \u00d7 3 filter, allowing us to explore their contribution to the response. Another issue, is the values that the weights of the non-linear terms settle to. We investigate these values, given the filters of the first convolutional layer of our Wide ResNet model, trained on CIFAR-100. The histograms of\nthe weight values are shown in Figure 3. The value distribution of the linear convolution filters\u2019 weights is similar to that of the quadratic filters\u2019 first-order weights. Also, the values of the quadratic filters\u2019 second-order weights have reasonably smaller standard deviation."}, {"heading": "5.5. Response profiles", "text": "Following the methodology of [2], we use a set of Volterra-based filters of a Wide ResNet trained on CIFAR100, to partly characterize their response profiles. Given the weights w1, w2 of a filter, we compute its optimal stimulus, xo, and the optimal stimulus of its linear term, xl, under the constraint that their norms are equal. Then, we compute four responses, as described in Table 4, and plot them in Figure 5. Comparing the various responses, we can infer that the properties of a linear filter with weights w1, can greatly change when it\u2019s extended to a second-order Volterra form by adding a weight set w2 with quadratic contributions. The response of a Volterra-based filter is quite different from the response of its first-order terms, proving that the second-order interactions contribute significantly to the functionality of a quadratic filter.\nGiven the weight subset w1 of a Volterra-based filter, their optimal stimulus xl has a standard pattern. As the norm of xl takes values inside a bounded space, the way xl varies is just a linear increase in all its intensity values, without altering its general pattern (i.e., all vectors xl are parallel). However, this does not hold true for quadratic filters. As the norm of a Volterra-based second-order filter\u2019s optimal stimulus xo, takes values inside a bounded space, a rich variety of alterations can be observed in the elements of xo."}, {"heading": "6. Conclusion", "text": "The exploration of CNN architectures that are optimized for using non-linear convolution filters, is an open problem\nfor biologically-inspired computer vision. Questions like \u201cwhich is the ideal ratio between linear and non-linear filters in each convolutional layer?\u201d and \u201cwhich properties prevail in the response profiles of each layer\u2019s non-linear filters?\u201d are of great importance, to shed light in this hitherto unexplored category of filters. Any inference about the properties that are present to this group of quadratic filters, has the risk of being biased by the dataset used to obtain and observe them. This happens because the visual response profiles of the non-linear filters trained in the experiments, are constrained by the natural statistics of each dataset, as happens with the sensory system of primates, which adapts to its environment.\nBased on the research results of neuroscience that prove the existence of non-linearities in the response profiles of complex visual cells, we have proposed a non-linear convolution scheme that can be used in CNN architectures. Our experiments showed that a network which combines linear and non-linear filters in its convolutional layers, can outperform networks that use standard linear filters with the same architecture. Our reported error rates set the state-of-theart on CIFAR-10, while being competitive to state-of-theart results on CIFAR-100. We didn\u2019t apply our Volterrabased convolution to more layers, because our target was to demonstrate a proof of concept for the proposed method. Our claim was confirmed, as replacing only the first convolutional layer\u2019s linear filters with non-linear ones, we achieved lower error rates. Further testing quadratic convolution filters, is certainly an interesting direction for future work, to build better computer vision systems."}, {"heading": "Acknowledgment", "text": "The research leading to these results has been supported by the EU funded project FORENSOR (GA 653355)."}], "references": [{"title": "Quadratic polynomials learn better image features", "author": ["J. Bergstra", "G. Desjardins", "P. Lamblin", "Y. Bengio"], "venue": "Technical report, Technical Report 1337, D\u00e9partement d\u2019Informatique et de Recherche Op\u00e9rationnelle, Universit\u00e9 de Montr\u00e9al", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "On the analysis and interpretation of inhomogeneous quadratic forms as receptive fields", "author": ["P. Berkes", "L. Wiskott"], "venue": "Neural computation, 18(8):1868\u20131895", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "High Performance Convolutional Neural Networks for Document Processing", "author": ["K. Chellapilla", "S. Puri", "P. Simard"], "venue": "In Tenth International Workshop on Frontiers in Handwriting Recognition, La Baule (France),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Steerable cnns", "author": ["T.S. Cohen", "M. Welling"], "venue": "CoRR, abs/1612.08498", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Torch7: A Matlab-like Environment for Machine Learning", "author": ["R. Collobert", "K. Kavukcuoglu", "C. Farabet"], "venue": "BigLearn, NIPS Workshop", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Advances in neural information processing systems 2", "author": ["Y.L. Cun", "B. Boser", "J.S. Denker", "R.E. Howard", "W. Habbard", "L.D. Jackel", "D. Henderson"], "venue": "chapter Handwritten Digit Recognition with a Back-propagation Network, pages 396\u2013 404. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1990}, {"title": "Stimulus optimisation in primary visual cortex", "author": ["P. F\u00f6ldi\u00e1k"], "venue": "Neurocomputing, 3840:1217 \u2013 1222", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position", "author": ["K. Fukushima"], "venue": "36(4):193\u2013202", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1980}, {"title": "Deep pyramidal residual networks", "author": ["D. Han", "J. Kim", "J. Kim"], "venue": "CoRR, abs/1610.02915", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "CoRR, abs/1512.03385", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Identity Mappings in Deep Residual Networks", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "pages 630\u2013645. Springer International Publishing, Cham", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep networks with stochastic depth", "author": ["G. Huang", "Y. Sun", "Z. Liu", "D. Sedra", "K.Q. Weinberger"], "venue": "CoRR, abs/1603.09382", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Receptive fields, binocular interaction and functional architecture in the cat\u2019s visual cortex", "author": ["D.H. Hubel", "T.N. Wiesel"], "venue": "The Journal of physiology,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1962}, {"title": "Improving training of deep neural networks via singular value bounding", "author": ["K. Jia"], "venue": "CoRR, abs/1611.06013", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Technical report", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Delugenets: Deep networks with massive and flexible cross-layer information inflows", "author": ["J. Kuen", "X. Kong", "G. Wang"], "venue": "CoRR, abs/1611.05552", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Volterrafaces: Discriminant analysis using volterra kernels", "author": ["R. Kumar", "A. Banerjee", "B.C. Vemuri"], "venue": "Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 150\u2013155. IEEE", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Deeplysupervised nets", "author": ["C. Lee", "S. Xie", "P.W. Gallagher", "Z. Zhang", "Z. Tu"], "venue": "Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics, AISTATS 2015, San Diego, California, USA, May 9-12, 2015", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Recurrent convolutional neural network for object recognition", "author": ["M. Liang", "X. Hu"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Network in network", "author": ["M. Lin", "Q. Chen", "S. Yan"], "venue": "International Conference on Learning Representations", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Mathematical description of the responses of simple cortical cells", "author": ["S. Mar\u0109elja"], "venue": "Journal of the Optical Society of America, 70(11):1297\u20131300", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1980}, {"title": "Interpretable sparse high-order boltzmann machines", "author": ["M.R. Min", "X. Ning", "C. Cheng", "M. Gerstein"], "venue": "AISTATS", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Spatial summation in the receptive fields of simple cells in the cat\u2019s striate cortex", "author": ["J.A. Movshon", "I.D. Thompson", "D.J. Tolhurst"], "venue": "The Journal of physiology, 283:53", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1978}, {"title": "Highly Selective Receptive Fields in Mouse Visual Cortex", "author": ["C.M. Niell", "M.P. Stryker"], "venue": "Journal of Neuroscience,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2008}, {"title": "Estimating nonlinear receptive fields from natural images", "author": ["J. Rapela", "J.M. Mendel", "N.M. Grzywacz"], "venue": "Journal of Vision, 6(4):11", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2006}, {"title": "Regularizing cnns with locally constrained decorrelations", "author": ["P. Rodr\u0131\u0301guez", "J. Gonz\u00e0lez", "G. Cucurull", "J.M. Gonfaus", "F.X. Roca"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1967}, {"title": "Imagenet large scale visual recognition challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "L. Fei-Fei"], "venue": "International Journal of Computer Vision, 115(3):211\u2013252", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning symmetry groups with hidden units: Beyond the perceptron", "author": ["T.J. Sejnowski", "P.K. Kienker", "G.E. Hinton"], "venue": "Physica D: Nonlinear Phenomena, 22(1-3):260\u2013275", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1986}, {"title": "Striving for simplicity: The all convolutional net", "author": ["J. Springenberg", "A. Dosovitskiy", "T. Brox", "M. Riedmiller"], "venue": "ICLR (workshop track)", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S.E. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CoRR, abs/1409.4842", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "The two-dimensional spatial structure of nonlinear subunits in the receptive fields of complex cells", "author": ["R.G. Szulborski", "L.A. Palmer"], "venue": "Vision Research, 30(2):249\u2013254", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1990}, {"title": "Theory of Functionals and of Integral and Integro-Differential Equations", "author": ["V. Volterra"], "venue": "Dover Publications", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2005}, {"title": "Aggregated residual transformations for deep neural networks", "author": ["S. Xie", "R.B. Girshick", "P. Doll\u00e1r", "Z. Tu", "K. He"], "venue": "CoRR, abs/1611.05431", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2016}, {"title": "Wide residual networks", "author": ["S. Zagoruyko", "N. Komodakis"], "venue": "BMVC", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}, {"title": "Oriented response networks", "author": ["Y. Zhou", "Q. Ye", "Q. Qiu", "J. Jiao"], "venue": "CoRR, abs/1701.01833", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2017}], "referenceMentions": [{"referenceID": 12, "context": "Their architectures have largely drawn inspiration by models of the primate visual system, as the one described by Hubel and Wiesel [13].", "startOffset": 132, "endOffset": 136}, {"referenceID": 24, "context": "Due to their linear nature, they lack the ability of expressing possible non-linearities that may actually appear in the response of complex cells in the primary visual cortex [25].", "startOffset": 176, "endOffset": 180}, {"referenceID": 30, "context": "Little effort has been devoted to explore new computational models that extend the convolution technique to non-linear forms, taking advantage of the research results of neuroscience, that prove the existence of nonlinear operations in the response of visual cells [31][24].", "startOffset": 265, "endOffset": 269}, {"referenceID": 23, "context": "Little effort has been devoted to explore new computational models that extend the convolution technique to non-linear forms, taking advantage of the research results of neuroscience, that prove the existence of nonlinear operations in the response of visual cells [31][24].", "startOffset": 269, "endOffset": 273}, {"referenceID": 31, "context": "In this work, we study the possibility of adopting an alternative convolution scheme to increase the learning capacity of CNNs by applying Volterra\u2019s theory [32], which has been used to study non-linear physiological systems, adapting it to the spatial domain.", "startOffset": 157, "endOffset": 161}, {"referenceID": 4, "context": "non-linear convolutional layer\u2019s module in Torch71[5]", "startOffset": 50, "endOffset": 53}, {"referenceID": 7, "context": "One of the first biologically-inspired neural networks, was Fukushima\u2019s Neocognitron [8], which was the predecessor of CNN, as it was introduced by LeCun et al.", "startOffset": 85, "endOffset": 88}, {"referenceID": 5, "context": "in [6].", "startOffset": 3, "endOffset": 6}, {"referenceID": 20, "context": "This category of filters can model quite accurately the properties of simple cells found in the primary visual cortex (V1) [21].", "startOffset": 123, "endOffset": 127}, {"referenceID": 6, "context": "Finding the optimal spatial stimuli [7] for simple cells is a process based on the spatial arrangement of their excitatory and inhibitory regions [23].", "startOffset": 36, "endOffset": 39}, {"referenceID": 22, "context": "Finding the optimal spatial stimuli [7] for simple cells is a process based on the spatial arrangement of their excitatory and inhibitory regions [23].", "startOffset": 146, "endOffset": 150}, {"referenceID": 9, "context": "[10] proposed Residual Networks (ResNets), which have shortcut connections parallel to their normal convolutional layers, as a solution to the problems of vanishing/exploding gradient and hard optimization when increasing the model\u2019s parameters (i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "Zagoruyko & Komodakis [34] showed that wide ResNets can outperform ResNets with hundrends of layers, shifting the interest to increasing the number of each layer\u2019s filters.", "startOffset": 22, "endOffset": 26}, {"referenceID": 26, "context": "Apart from ResNets, very low error rates have also been achieved in the ImageNet Challenge [27] by methods that used their convolutional layers in new ways, enhancing their representation ability.", "startOffset": 91, "endOffset": 95}, {"referenceID": 19, "context": "[20] proposed \u201cNetwork in Network (NIN)\u201d, as a remedy to the low level of abstraction that typical filters present.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] introduced a new level of organization in the form of the \u201cInception module\u201d, which uses filters of variable sizes to capture different visual patterns of different sizes, and approximates the optimal sparse structure.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[33] proposed a way to exploit the split-transform-merge strategy of \u201cInception\u201d models, performing a set of transformations, each on a lowdimensional embedding, whose outputs are aggregated by summation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "The authors of [19], based on the abundancy of recurrent synapses in the brain, proposed the use of a recurrent neural network for image classification.", "startOffset": 15, "endOffset": 19}, {"referenceID": 27, "context": "In [28], a Boltzmann learning algorithm is proposed, where feature interactions are used to turn hidden units into higher-order feature detectors.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "In [22], an efficient method to apply such learning algorithms on higher-order Boltzmann Machines was proposed, making them computationally tractable for real problems.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "In [1], Bergstra et al.", "startOffset": 3, "endOffset": 6}, {"referenceID": 1, "context": "In [2], an attempt is made to analyze and interpret quadratic forms as receptive fields.", "startOffset": 3, "endOffset": 6}, {"referenceID": 16, "context": "In the field of computer vision, Volterra kernels have been previously used in [17] for face recognition, serving effectively as approximations of non-linear functionals.", "startOffset": 79, "endOffset": 83}, {"referenceID": 2, "context": "To implement the forward pass in CUDA, we used the standard im2col [3] pattern to unfold data patches into columns, followed by a matrix multiplication with the Volterra-based filter weights.", "startOffset": 67, "endOffset": 70}, {"referenceID": 14, "context": "We measure the performance of our proposed Volterrabased convolution on two benchmark datasets: CIFAR-10 and CIFAR-100 [15], running our experiments on a PC equipped with Intel i7-5820K CPU, 64GB RAM and Nvidia Titan X GPU.", "startOffset": 119, "endOffset": 123}, {"referenceID": 33, "context": "We choose the modern architecture of Wide ResNet [34], which mainly consists of a convolutional layer, followed by 3 convolutional groups and a classifier.", "startOffset": 49, "endOffset": 53}, {"referenceID": 9, "context": "3 and weight initialization is done as in [10].", "startOffset": 42, "endOffset": 46}, {"referenceID": 19, "context": "NIN [20] 8.", "startOffset": 4, "endOffset": 8}, {"referenceID": 17, "context": "DSN [18] 3 7.", "startOffset": 4, "endOffset": 8}, {"referenceID": 28, "context": "All-CNN [29] 9 1.", "startOffset": 8, "endOffset": 12}, {"referenceID": 11, "context": "ResNet with Stochastic Depth [12] 110 1.", "startOffset": 29, "endOffset": 33}, {"referenceID": 10, "context": "pre-act Resnet [11] 1001 10.", "startOffset": 15, "endOffset": 19}, {"referenceID": 33, "context": "Wide ResNet [34] 40 55.", "startOffset": 12, "endOffset": 16}, {"referenceID": 8, "context": "PyramidNet [9] 110 28.", "startOffset": 11, "endOffset": 14}, {"referenceID": 15, "context": "Wide-DelugeNet [16] 146 20.", "startOffset": 15, "endOffset": 19}, {"referenceID": 25, "context": "OrthoReg on Wide ResNet [26] 28 3.", "startOffset": 24, "endOffset": 28}, {"referenceID": 3, "context": "Steerable CNNs [4] 14 9.", "startOffset": 15, "endOffset": 18}, {"referenceID": 32, "context": "ResNeXt [33] 29 68.", "startOffset": 8, "endOffset": 12}, {"referenceID": 13, "context": "Wide ResNet with Singular Value Bounding [14] 28 36.", "startOffset": 41, "endOffset": 45}, {"referenceID": 34, "context": "Oriented Response Net [35] 28 18.", "startOffset": 22, "endOffset": 26}, {"referenceID": 32, "context": "Our results on CIFAR-100 are outperformed only by [33], due to the huge number of parameters their model makes use of.", "startOffset": 50, "endOffset": 54}, {"referenceID": 1, "context": "Following the methodology of [2], we use a set of Volterra-based filters of a Wide ResNet trained on CIFAR100, to partly characterize their response profiles.", "startOffset": 29, "endOffset": 32}], "year": 2017, "abstractText": "During the last years, Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in image classification. Their architectures have largely drawn inspiration by models of the primate visual system. However, while recent research results of neuroscience prove the existence of non-linear operations in the response of complex visual cells, little effort has been devoted to extend the convolution technique to non-linear forms. Typical convolutional layers are linear systems, hence their expressiveness is limited. To overcome this, various non-linearities have been used as activation functions inside CNNs, while also many pooling strategies have been applied. We address the issue of developing a convolution method in the context of a computational model of the visual cortex, exploring quadratic forms through the Volterra kernels. Such forms, constituting a more rich function space, are used as approximations of the response profile of visual cells. Our proposed second-order convolution is tested on CIFAR-10 and CIFAR-100. We show that a network which combines linear and non-linear filters in its convolutional layers, can outperform networks that use standard linear filters with the same architecture, yielding results competitive with the state-of-the-art on these datasets.", "creator": "LaTeX with hyperref package"}}}