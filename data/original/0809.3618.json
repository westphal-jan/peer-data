{"id": "0809.3618", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Sep-2008", "title": "Robust Near-Isometric Matching via Structured Learning of Graphical Models", "abstract": "Models for near-rigid shape matching are typically based on distance-related features, in order to infer matches that are consistent with the isometric assumption. However, real shapes from image datasets, even when expected to be related by \"almost isometric\" transformations, are actually subject not only to noise but also, to some limited degree, to variations in appearance and scale. In this paper, we introduce a graphical model that parameterises appearance, distance, and angle features and we learn all of the involved parameters via structured prediction. The outcome is a model for near-rigid shape matching which is robust in the sense that it is able to capture the possibly limited but still important scale and appearance variations. Our experimental results reveal substantial improvements upon recent successful models, while maintaining similar running times.", "histories": [["v1", "Sun, 21 Sep 2008 23:23:26 GMT  (2074kb,D)", "http://arxiv.org/abs/0809.3618v1", "11 pages, 9 figures"]], "COMMENTS": "11 pages, 9 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["julian john mcauley", "tib\u00e9rio s caetano", "alexander j smola"], "accepted": true, "id": "0809.3618"}, "pdf": {"name": "0809.3618.pdf", "metadata": {"source": "CRF", "title": "Robust Near-Isometric Matching via Structured Learning of Graphical Models", "authors": ["Julian J. McAuley", "Tib\u00e9rio S. Caetano", "Alexander J. Smola"], "emails": [], "sections": [{"heading": null, "text": "Models for near-rigid shape matching are typically based on distance-related features, in order to infer matches that are consistent with the isometric assumption. However, real shapes from image datasets, even when expected to be related by \u201calmost isometric\u201d transformations, are actually subject not only to noise but also, to some limited degree, to variations in appearance and scale. In this paper, we introduce a graphical model that parameterises appearance, distance, and angle features and we learn all of the involved parameters via structured prediction. The outcome is a model for near-rigid shape matching which is robust in the sense that it is able to capture the possibly limited but still important scale and appearance variations. Our experimental results reveal substantial improvements upon recent successful models, while maintaining similar running times."}, {"heading": "1 Introduction", "text": "Matching shapes in images has many applications, including image retrieval, alignment, and registration [1, 2, 3, 4]. Typically, matching is approached by selecting features for a set of landmark points in both images; a correspondence between the two is then chosen such that some distance measure between these features is minimised. A great deal of attention has been devoted to defining complex features which are robust to changes in rotation, scale etc. [5, 6].1\nAn important class of matching problems is that of nearisometric shape matching. In this setting, it is assumed that shapes are defined up to an isometric transformation (allowing for some noise), and therefore distance features are typically used to encode the shape. Some traditional methods for related settings focus on optimisation over the space of rigid transformations so as to minimise least-squares criteria [11,12].\nRecently, this class of problems has been approached from a different perspective, as direct optimisation over the space of correspondences [13]. Although apparently more expensive, there it is shown that the rigidity assumption imposes a convenient algebraic structure in the correspon-\n\u2217The authors are with the Statistical Machine Learning Program at NICTA, and the Research School of Information Sciences and Engineering, Australian National University.\n1We restrict our attention to this type of approach, i.e. that of matching landmarks between images. Some notable approaches deviate from this norm \u2013 see (for example) [7, 8, 9, 10].\ndence space so as to allow for efficient algorithms (exact inference in chordal graphical models of small clique size). More recently, these methods have been made substantially faster [14]. The key idea in these methods is to explicitly encode rigidity constraints into a tractable graphical model whose MAP solution corresponds to the best match. However, the main advantages of correspondence-based optimisation over transformation-based optimisation, namely the flexibility of encoding powerful local features, has not been further explored in this framework.\nOther lines of work that optimise directly over the correspondence space are those based on Graph Matching, which explicitly model all pairwise compatibilities and solve for the best match with some relaxation (since the Graph Matching problem is NP-hard for general pairwise compatibilities) [15, 16, 17]. Recently, it was shown both in [18] and in [19] that if some form of structured optimisation is used to optimise graph matching scores, relaxed quadratic assignment predictors can improve the power of pairwise features. The key idea in these methods is to learn the compatibility scores for the graph matching objective function, therefore enriching the representability of features. A downside of these graph matching methods however is that they do not typically make explicit use of the geometry of the scene in order to improve computational efficiency and/or accuracy.\nIn this paper, we combine these two lines of work into a single framework. We produce an exact, efficient model to solve near-isometric shape matching problems using not only isometry-invariant features, but also appearance and scale-invariant features, all encoded in a tractable graphical model. By doing so we can learn via large-margin structured prediction the relative importances of variations in appearance and scale with regard to variations in shape per se. Therefore, even knowing that we are in a near-isometric setting, we will still capture the eventual variations in appearance and scale into our matching criterion in order to produce a robust near-isometric matcher. In terms of learning, we introduce a two-stage structured learning approach to address the speed and memory efficiency of this model.\nThe remainder of this paper is structured as follows: in section 2, we give a brief introduction to shape matching (2.1), graphical models (2.2), and discriminative structured learning (2.3). In section 3, we present our model, and experiments follow in section 4.\nar X\niv :0\n80 9.\n36 18\nv1 [\ncs .C\nV ]\n2 1\nSe p\n20 08"}, {"heading": "2 Background", "text": ""}, {"heading": "2.1 Shape Matching", "text": "\u2018Shape matching\u2019 can mean many different things, depending on the precise type of query one is interested in. Here we study the case of identifying an instance of a template shape (S \u2286 T ) in a target scene (U) [1].2 We assume that we know S, i.e. the points in the template that we want to query in the scene. Typically both T and U correspond to a set of \u2018landmark\u2019 points, taken from a pair of images (common approaches include [6, 20,21,22]).\nFor each point t \u2208 T and u \u2208 U , a certain set of unary features are extracted (here denoted by \u03c6(t), \u03c6(u)), which contain local information about the image at that point [5, 6]. If y : S \u2192 U is a generic mapping representing a potential match, the goal is then to find a mapping y\u0302 which minimises the aggregate distance between corresponding features, i.e.\ny\u0302 = f(S,U) = argmin y |S|\u2211 i=1 c1(si, y(si)) (1)\nwhere\nc1(si, y(si)) = \u2016\u03c6(si)\u2212 \u03c6(y(si))\u201622. (2)\n(here \u2016\u00b7\u20162 denotes the L2 norm). For injective y eq. (1) is a linear assignment problem, efficiently solvable in cubic time.\nIn addition to unary or first-order features, pairwise or second-order features can be induced from the locations of the unary features. In this case eq. (1) is generalised to minimise an aggregate distance between pairwise features, i.e.\ny\u0302 = argmin y |S|\u2211 i=1 c1(si, y(si)) + |S|\u2211 i=1 |S|\u2211 j=1 c2(si, sj , y(si), y(sj)).\n(3) This however induces an NP-hard problem for general c2 (quadratic assignment). Discriminative structured learning has recently been applied to models of both linear and quadratic assignment (eq. (1) and eq. (3)) in [18]. Here we exploit the structure of c2 that arises from the nearisometric shape matching problem in order to make such a problem tractable."}, {"heading": "2.2 Graphical Models", "text": "In isometric matching settings, one may suspect that it may not be necessary to include all pairwise relations in quadratic assignment. In fact a recent paper [14] has shown that if only the distances as encoded by the graphical model depicted in figure 1 (top) are taken into account (nodes represent points in S and states represent points in U), exact probabilistic inference in such a model can solve the isometric problem optimally. That is, an energy function of the\n2Here T is the set of all points in the template scene, whereas S corresponds to those points in which we are interested. It is also important to note that we treat S as an ordered object in our setting.\nfollowing form is minimised:3\n|S|\u2211 i=1 c2(si, si+1, y(si), y(si+1)) + c2(si, si+2, y(si), y(si+2)).\n(4) Although the graphical model in figure 1 (top) does not form a single loop (a condition typically required for convergence of belief propagation [23, 24, 25]), [14] show that it is sufficient that the clique graph forms a single loop in order to guarantee convergence to the optimal assignment (figure 1, bottom). Furthermore, it is shown in [14] that the number of iterations required before convergence is small in practice.\nWe will extend this model by including a unary term, c1(si, y(si)) (as in (eq. 1)), as well as a third-order term, c3(si, si+1, si+2, y(si), y(si+1), y(si+2)); the graph topology remains the same. Note that in order to guarantee convergence, we do not require any specific form for the potentials, except that no assignment has infinite cost [14]."}, {"heading": "2.3 Discriminative Structured Learning", "text": "In practice, feature vectors may be very high-dimensional, and which components are \u2018important\u2019 will depend on the specific properties of the shapes being matched. Therefore, we introduce a parameter, \u03b8, which controls the relative importances of the various feature components. Note that\n3si+1 should be interpreted as s(i+1) mod |S| (i.e. the points form a loop).\n\u03b8 is parameterising the matching criterion itself. Hence our optimisation problem becomes\ny\u0302 = f(S,U ; \u03b8) = argmax y \u3008h(S,U , y), \u03b8\u3009 (5)\nwhere\nh(S,U , y) = \u2212 |S|\u2211 i=1 \u03a6(si, si+1, si+2, y(si), y(si+1), y(si+2)).\n(6) (y is a mapping from S to U , \u03a6 is a third-order feature vector \u2013 our specific choice is shown in section 3).4 In order to measure the performance of a particular weight vector, we use a loss function, \u2206(y\u0302, yi), which represents the cost incurred by choosing the assignment y\u0302 when the correct assignment is yi (our specific choice of loss function is described in section 4). To avoid overfitting, we also desire that \u03b8 is sufficiently \u2018smooth\u2019. Typically, one uses the squared L2 norm, \u2016\u03b8\u201622, to penalise non-smooth choices of \u03b8 [26].\nLearning in this setting now becomes a matter of choosing \u03b8 such that the empirical risk (average loss on all training instances) is minimised, but which is also sufficiently \u2018smooth\u2019 (to prevent overfitting). Specifically, if we have a set of training pairs, { (S1,U1), . . . , (SN ,UN ) } , with la-\nbelled matches { y1 . . . yN } , then we wish to minimise\n1 N N\u2211 i=1\n\u2206(f(Si,U i; \u03b8), yi)\ufe38 \ufe37\ufe37 \ufe38 empirical risk\n+ \u03bb\n2 \u2016\u03b8\u201622\ufe38 \ufe37\ufe37 \ufe38\nregulariser\n. (7)\nHere \u03bb (the regularisation constant) controls the relative importance of minimising the empirical risk against the regulariser. In our case, we simply choose \u03bb such that the empirical risk on our validation set is minimised.\nSolving (eq. 7) exactly is an extremely difficult problem and in practice is not feasible, since the loss is piecewise constant on the parameter \u03b8. Here we capitalise on recent advances in large-margin structured estimation [26], which consist of obtaining convex relaxations of this problem. Without going into the details of the solution (see, for example, [26,27]), it can be shown that a convex relaxation of this problem can be obtained, which is given by\nmin \u03b8 1 N N\u2211 i=1 \u03bei + \u03bb 2 \u2016\u03b8\u201622 (8a)\nsubject to\n\u3008h(Si,U i, yi)\u2212 h(Si,U i, y), \u03b8\u3009 \u2265 \u2206(y, yi)\u2212 \u03bei for all i and y \u2208 Y (8b)\n(where Y is the space of all possible mappings). It can be shown that for the solution of the above problem, we have that \u03be\u2217i \u2265 \u2206(f(Si,U i; \u03b8), yi). This means that we end up minimising an upper bound on the loss, instead of the loss itself.\n4We have expressed (eq. 5) as a maximisation problem as a matter of convention; this is achieved simply by negating the cost function in (eq. 6).\nSolving (8) requires only that we are able, for any value of \u03b8, to find\nargmax y\n( \u3008h(Si,U i, y), \u03b8\u3009+ \u2206(y, yi) ) . (9)\nIn other words, for each value of \u03b8, we are able to identify the mapping which is consistent with the model (eq. 5), yet incurs a high loss. This process is known as \u2018column generation\u2019 [26,27]. As we will define our loss as a sum over the nodes, solving (eq. 9) is no more difficult than solving (eq. 5)."}, {"heading": "3 Our Model", "text": "Although the model of [14] solves isometric matching problems optimally, it provides no guarantees for near -isometric problems, as it only considers those compatibilities which form cliques in our graphical model. However, we are often only interested in the boundary of the object: if we look at the instance of the model depicted in figure 2, it seems to capture exactly the important dependencies; adding additional dependencies between distant points (such as the duck\u2019s tail and head) would be unlikely to contribute to this model.\nWith this in mind, we introduce three new features (for brevity we use the shorthand yi = y(si)):\n\u03a61(s1, s2, y1, y2) = (d1(s1, s2)\u2212 d1(y1, y2))2, where d1(a, b) is the Euclidean distance between a and b, scaled according to the width of the target scene.\n\u03a62(s1, s2, s3, y1, y2, y3) = (d2(s1, s2, s3)\u2212 d2(y1, y2, y3))2, where d2(a, b, c) is the Euclidean distance between a and b scaled by the average of the distances between a, b, and c.\n\u03a63(s1, s2, s3, y1, y2, y3) = (\u2220(s1, s2, s3)\u2212 \u2220(y1, y2, y3))2, where \u2220(a, b, c) is the angle between a and c, w.r.t. b.5\nWe also include the unary features \u03a60(s1, y1) = (\u03c6(s1)\u2212 \u03c6(y1))2 (i.e. the pointwise squared difference between \u03c6(s1) and \u03c6(y1)). \u03a61 is exactly the feature used in [14], and is invariant to isometric transformations (rotation, reflection, and translation); \u03a62 and \u03a63 capture triangle similarity, and are thus also invariant to scale. In the context of (eq. 6), we have\n\u03a6(s1, s2, s3, y1, y2, y3) := [ \u03a60(s1, y1),\n\u03a61(s1, s2, y1, y2) + \u03a61(s1, s3, y1, y3), \u03a62(s1, s2, s3, y1, y2, y3) + \u03a62(s1, s3, s2, y1, y3, y2),\n\u03a63(s1, s2, s3, y1, y2, y3) ] . (10)\nThis demands some explanation: only two pairwise dependencies (\u03a61) are included in each clique \u2013 this is done to ensure that each pairwise dependency is included exactly\n5Using features of such different scales can be an issue for regularisation \u2013 in practice we adjusted these features to have roughly the same scale. For full details, our implementation is available at (not included for blind review).\nonce, as the remaining dependency is captured by an adjacent clique. Furthermore, we have included two scaled distances and one angle (\u03a62 and \u03a63) \u2013 although we could have included as many as three scaled distances and three angles, we have instead included exactly what is required to capture triangle similarity. Finally, we have enforced that features of the same type are given the same weight (\u03a61 and \u03a62), simply by adding the different instances of these features.\nIn practice, landmark detectors often identify several hundred points [6, 28], which is clearly impractical for an O(|S||U|3) method (|U| is the number of landmarks in the target scene). To address this, we adopt a two stage learning approach: in the first stage, we learn only unary compatibilities, exactly as is done in [18]. During the second stage of learning, we collapse the first-order feature vector into a single term, namely\n\u03a6\u20320(s1, y1) = \u3008\u03b80,\u03a60(s1, y1)\u3009 (11)\n(\u03b80 is the weight vector learned during the first stage). We now perform learning for the third-order model, but consider only the p \u2018most likely\u2019 matches for each node, where the likelihood is simply determined using \u03a6\u20320(s1, y1). This reduces the memory and runtime requirements to O(|S|p3). A consequence of using this approach is that we must now tune two regularisation constants; this is not an issue in practice, as learning can be performed quickly using this approach.6"}, {"heading": "4 Experiments", "text": ""}, {"heading": "4.1 House Data", "text": "In our first experiment, we compare our method to those of [14] and [18]. Both papers report the performance of their methods on the CMU \u2018house\u2019 sequence \u2013 a sequence of 111 frames of a toy house, with 30 landmarks identified in each frame.7 As in [18], we compute the Shape Context features for each of the 30 points [5].\n6In fact, even in those cases where a single stage approach was tractable (such as the experiment in section 4.1), we found that the two stage approach worked better. Typically, we required much less regularity during the second stage, possibly because the higher order features are heterogeneous.\n7http://vasc.ri.cmu.edu/idb/html/motion/house/index.html\nIn addition to the unary model of [18], a model based on quadratic assignment is also presented, in which pairwise features are determined using the adjacency structure of the graphs. Specifically, if a pair of points (p1, p2) in the template scene is to be matched to (q1, q2) in the target, there is a feature which is 1 if there is an edge between p1 and p2 in the template, and an edge between q1 and q2 in the target (and 0 otherwise). We also use such a feature for this experiment, however our model only considers matchings for which (p1, p2) forms an edge in our graphical model (see figure 3, bottom left). The adjacency structure of the graphs is determined using the Delaunay triangulation, (figure 3, top left).\nAs in [14], we compare pairs of images with a fixed baseline (separation between frames). For our loss function, \u2206(y\u0302, yi), we used the normalised Hamming loss, i.e. the proportion of mismatches. Figure 4 shows our performance on this dataset, as the baseline increases. On top we show the performance without learning, for which our model exhibits the best performance by a substantial margin.8 Our method is also the best performing after learning (figure 4 (bottom))\u2013 in fact, we achieve almost zero error for all but the largest baselines (at which point our model assumptions become increasingly violated, and we have less training data).\nIn figure 5, we see that the running time of our method is similar to the quadratic assignment method of [18]. To improve the running time, we also show our results with p = 10, i.e. for each point in the template scene, we only consider the 10 \u2018most likely\u2019 matches, using the weights from the first stage of learning. This reduces the running time by more than an order of magnitude, bringing it closer to that of linear assignment; even this model achieves approximately zero error up to a baseline of 60.\nFinally, figure 6 (top) shows the weight vector of our model, for a baseline of 70. The first 60 weights are for the Shape Context features (determined during the first stage of learning), and the final 5 show the weights from our second stage of learning (the weights correspond to the first-order\n8Interestingly, the quadratic method of [18] performs worse than their unary method; this is likely because the relative scale of the unary and quadratic features is badly tuned before learning, and is indeed similar to what the authors report. Furthermore, the results we present for the method of [18] after learning are much better than what the authors report \u2013 in that paper, the unary features are scaled using a pointwise exponent (\u2212 exp(\u2212|\u03c6a \u2212 \u03c6b|2)), whereas we found that scaling the features linearly (|\u03c6a \u2212 \u03c6b|2) worked better.\nfeatures, distances, adjacencies, scaled distances, and angles, respectively \u2013 see section 3). We can provide some explanation of the learned weights: the Shape Context features are separated into 5 radial, and 12 angular bins \u2013 the fact that there is a peak for the 14th, 26th, and 38th features indicates that a particular angular bin is more important than the others; the fact that the final 12 features have low weight indicates that the most distant radial bin has little importance (etc.). It is much more difficult to reason about the second stage of learning, as the features have different scales, and cannot be compared directly \u2013 however, it appears that all of the higher-order features are important to our model.\nIt is worth briefly mentioning that we also ran this experiment using our model, but including only the adjacency features, and ignoring all third-order features \u2013 i.e. replicating exactly the experiment from [18], but including only the limited dependencies captured by our model. In this experiment, the model of [18] performed better than ours; this indicates that the benefit of using an exact algorithm does not exceed the cost of capturing only limited dependencies. Indeed, this indicates that the third-order features are playing a very significant role in contributing to the performance of our model."}, {"heading": "4.2 Synthetic Data", "text": "For this experiment, our \u2018shape\u2019 consists of 25 points randomly distributed on the silhouette of the painting shown in figure 7 (note that this shape exhibits less structure than those in our other experiments, due to the random ordering\nof the points). In addition to the points on our shape, a number of outliers are randomly distributed on the silhouette. 10 training, testing, and validation images are then generated by randomly perturbing the x and y-coordinates of these points by between \u2212 /2 and /2 pixels, where epsilon ranges between 0 and 20. This produces 45 pairs of images for training, validation, and testing. This experiment is aimed at examining the robustness of our approach to noise and outliers, as well as the effect of choosing different values for p.9\nThe results of this experiment are shown in figure 8. Note that the \u2018point matching\u2019 method is only shown for zero outliers, as the method becomes intractable as |U| increases. The quadratic assignment method of [18] is not shown for this experiment, as the adjacency information in the graph is not robust to random error, or the addition of outliers (it performed far worse than the techniques shown). Since we cannot hope to get exact matches, we use the endpoint error instead of the normalised Hamming loss, i.e. we reward points which are close to the correct match.10 Figure 8 also examines the effect of choosing different values of p (the number of points considered during the second stage of learning).\nGiven that our datapoints are generated randomly, we observe little improvement from learning when using firstorder features. Although the higher-order model provides no benefit when there are no outliers, it is highly beneficial once outliers are introduced; we also observe a significant\n9Note that setting p = 1 essentially recovers the linear method of [18].\n10Here the endpoint error is just the average Euclidean distance from the correct label, scaled according to the width of the image.\n-6\n-4\n-2\n0\n2\n4\n6\nIm po\nrt an\nce\nIndex\nHouse data first/higher order weight vector (baseline = 70)\n-0.1\n-0.05\n0\n0.05\n0.1\n-2\n-1.5\n-1\n-0.5\n0\n0.5\n1\n1.5\n2\nIm po\nrt an\nce\nIndex\nBikes data first/higher order weight vector\n-3\n-2\n-1\n0\n1\n2\n3\nFigure 6: Top: The weight vector of our method after learning, for the \u2018house\u2019 data. The first 60 weights are for the Shape Context features from the first stage of of learning; the final 5 weights are for the second stage of learning. Bottom: The same plot, for the \u2018bikes\u2019 data.\nbenefit from learning, which likely indicates that the relative weights of the low and higher-order features are being adjusted. Finally, although we observe poor performance for p = 5, we observe almost no difference when increasing p from 10 to 20."}, {"heading": "4.3 Bikes Data", "text": "For our final experiment, we used images of bicycles from the Caltech 256 Dataset [29]. Bicycles are reasonably rigid objects, meaning that matching based on their shape is logical. Although the images in this dataset are fairly well aligned, they are subject to reflections as well as some scaling and shear. For each image in the dataset, we detected landmarks automatically, and six points on the frame were hand-labelled (see figure 9). Only shapes in which these interest points were not occluded were used, and we only included images that had a background; in total, we labelled 44 images. The first image was used as the \u2018template\u2019, the other 43 were used as targets. Thus we are learning to match bicycles similar to the chosen template.\nInitially, we used the SIFT landmarks and features as described in [6]. Since this approach typically identifies several hundred landmarks, we set p = 20 for this experiment (i.e. we consider the 20 most likely points). Again we use the endpoint error for this experiment. Table 1 reveals that the performance of this method is quite poor, even with the higher-order model, and furthermore reveals no benefit from learning. This may be explained by the fact that although the SIFT features are invariant to scale and rotation, they are not invariant to reflection.\nIn [28], the authors report that the SIFT features can provide good matches in such cases, as long as landmarks are chosen which are locally invariant to affine transformations. They give a method for identifying affine-invariant feature points, whose SIFT features are then computed.11 We achieve much better performance using this method, and also observe a significant improvement after learning. Figure 9 shows an example match using both the unary and higher-order techniques.\nFinally, figure 6 (right) shows the weights learned for this model. Interestingly, the first-order term during the second stage of learning has almost zero weight. This must not\n11We used publicly available implementations of both methods.\nbe misinterpreted: during the second stage, the response of each of the 20 candidate points is so similar that the first-order features are simply unable to convey any new information \u2013 yet they are still very useful in determining the 20 candidate points."}, {"heading": "5 Discussion and Future Work", "text": "While our model seems well motivated when applied to the problem of \u2018shape\u2019 matching (i.e. when the shape has a clearly defined boundary), we are clearly making a tradeoff when applying our model to the more general problem of matching point-patterns. In such cases, we are at a disadvantage due to the fact that we capture only a fraction of the desired dependencies, but we are at an advantage in that our model is exact, and also that it is able to capture higher-order properties of the scene. Interestingly, we found that the exactness of our model alone does not make up for this limitation. This reveals the surprising result that the scale-invariant third-order features are able to capture a great deal of additional information that is not present at lower orders.\nA hurdle faced by our approach is that of occlusions (either due to the landmark detector failing to identify part of the shape, or simply due to part of the shape being missing from the scene). Occlusions are of little concern to a firstorder model, as an incorrect assignment to a single point has no effect on other assignments, whereas they may adversely effect our model, as the assignments are inextricably linked. In this paper, we have effectively dealt with the first issue (i.e. that of the landmark detector failing to identify an important point), by using learning to select candidate landmarks. Dealing with occlusions explicitly is an important future addition to our model.\nAnother issue we encountered was that of feature scaling. For instance, suppose we express angles in degrees rather than radians; from the point of view of our model, this should make no difference \u2013 we would just scale the corresponding weights by \u03c0/180; but from the point of view of the regulariser, this is a very significant change \u2013 it is much more \u2018expensive\u2019 to include a feature with a small scale (relative to other features) than it is to include a feature with a large scale. In theory, we would like to include many different features, and have the learning algorithm separate the good from the bad; in practice, this was not possible, as we were forced to address the relative scale of our features before we were able to do learning.12 This appears to be a fundamental issue when applying learning to models with heterogeneous features, for which we are not aware of a principled solution.\nIn this paper we have used \u2018off-the-shelf\u2019 landmark detectors, and only applied learning after landmarks have been detected. Since we know the \u2018type\u2019 of landmarks we want in advance (they are labelled in the template scene), it may be possible to apply learning to the landmark detector itself in order to further improve the performance of our model.\n12For full details, our implementation is available at (our implementation will be made available at the time of publication)\nIt would also be possible to allow for shapes which are rigid in some parts, but less so in others. For instance, although the handlebars, wheels, and pedals appear in similar locations on all bicycles, the seat and crossbar do not; we could allow for this discrepancy by learning a separate weight vector for each clique."}, {"heading": "6 Conclusion", "text": "We have presented a model for near-isometric shape matching which is robust to typical additional variations of the shape. This is achieved by performing structured learning in a graphical model that encodes features with several different types of invariances, so that we can directly learn a \u201ccompound invariance\u201d instead of taking for granted the exclusive assumption of isometric invariance. Our experiments revealed that structured learning with a principled graphical model that encodes both the rigid shape as well as non-isometric variations gives substantial improvements, while still maintaining competitive performance in terms of running time."}], "references": [{"title": "Shape matching and object recognition using shape contexts", "author": ["S. Belongie", "J. Malik", "J. Puzicha"], "venue": "IEEE Trans. on PAMI, vol. 24, no. 4, pp. 509\u2013522, 2002.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "Shape contexts enable efficient retrieval of similar shapes", "author": ["G. Mori", "S. Belongie", "J. Malik"], "venue": "CVPR, 2001, pp. 723\u2013730.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Estimating human body configurations using shape context matching", "author": ["G. Mori", "J. Malik"], "venue": "ECCV, 2002, pp. 666\u2013680.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Recognizing objects in range data using regional point descriptors", "author": ["A. Frome", "D. Huber", "R. Kolluri", "T. Bulow", "J. Malik"], "venue": "ECCV, 2004.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Matching with shape contexts", "author": ["S. Belongie", "J. Malik"], "venue": "CBAIVL00, 2000, pp. 20\u201326.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "Object recognition from local scaleinvariant features", "author": ["D.G. Lowe"], "venue": "ICCV, 1999, pp. 1150\u20131157.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1999}, {"title": "Pictorial structures for object recognition", "author": ["P.F. Felzenszwalb", "D.P. Huttenlocher"], "venue": "IJCV, vol. 61, no. 1, pp. 55\u201379, 2005.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Hierarchical matching of deformable shapes", "author": ["P.F. Felzenszwalb", "J.D. Schwartz"], "venue": "CVPR, 2007.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning methods for generic object recognition with invariance to pose and lighting", "author": ["Y. LeCun", "F.J. Huang", "L. Bottou"], "venue": "CVPR, vol. 02, pp. 97\u2013104, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "Shape-based recognition of wiry objects", "author": ["O. Carmichael", "M. Hebert"], "venue": "IEEE Trans. on PAMI, vol. 26, no. 12, pp. 1537\u20131552, 2004.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Multiple View Geometry in Computer Vision, 2nd ed", "author": ["R.I. Hartley", "A. Zisserman"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Robust registration of 2d and 3d point sets", "author": ["A. Fitzgibbon"], "venue": "British Machine Vision Conference, 2001.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2001}, {"title": "Graphical models and point pattern matching", "author": ["T.S. Caetano", "T. Caelli", "D. Schuurmans", "D.A.C. Barone"], "venue": "IEEE Trans. on PAMI, vol. 28, no. 10, pp. 1646\u2013 1663, 2006.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "Graph rigidity, cyclic belief propagation and point pattern matching", "author": ["J.J. McAuley", "T.S. Caetano", "M.S. Barbosa"], "venue": "IEEE Trans. on PAMI, in press \u2013 2008.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Balanced graph matching", "author": ["T. Cour", "P. Srinivasan", "J. Shi"], "venue": "NIPS, 2006.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Shape matching and object recognition using low distortion correspondence", "author": ["A.C. Berg", "T.L. Berg", "J. Malik"], "venue": "CVPR, 2005.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "A spectral technique for correspondence problems using pairwise constraints", "author": ["M. Leordeanu", "M. Hebert"], "venue": "ICCV, 2005, pp. 1482\u20131489.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning graph matching", "author": ["T. Caetano", "L. Cheng", "Q. Le", "A. Smola"], "venue": "ICCV, 2007, pp. 1\u20138.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Smoothing-based optimization", "author": ["M. Leordeanu", "M. Hebert"], "venue": "Proceedings of CVPR, June 2008.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "A computational approach to edge detection", "author": ["J. Canny"], "venue": "RCV, 1987, pp. 184\u2013203.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1987}, {"title": "Using Canny\u2019s criteria to derive a recursively implemented optimal edge detector", "author": ["R. Deriche"], "venue": "IJCV, vol. 1, no. 2, pp. 167\u2013187, 1987.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1987}, {"title": "A new class of corner finder", "author": ["S. Smith"], "venue": "BMVC, 1992, pp. 139\u2013148.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1992}, {"title": "Message errors in belief propagation", "author": ["A.T. Ihler", "J.W. Fisher", "A.S. Willsky"], "venue": "Advances in Neural Information Processing Systems, 2005, pp. 609\u2013616.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2005}, {"title": "Correctness of local probability propagation in graphical models with loops", "author": ["Y. Weiss"], "venue": "Neural Computation, vol. 12, no. 1, pp. 1\u201341, 2000.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2000}, {"title": "On the optimality of solutions of the max-product belief-propagation algorithm in arbitrary graphs", "author": ["Weiss", "Freeman"], "venue": "IEEE Transactions on Information Theory, vol. 47, 2001.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2001}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["I. Tsochantaridis", "T. Hofmann", "T. Joachims", "Y. Altun"], "venue": "ICML, 2004.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "A scalable modular convex solver for regularized risk minimization", "author": ["C. Teo", "Q. Le", "A. Smola", "S. Vishwanathan"], "venue": "KDD, 2007. 10", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "Scale and affine invariant interest point detectors", "author": ["K. Mikolajczyk", "C. Schmid"], "venue": "vol. 60, no. 1, pp. 63\u201386, October 2004.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2004}, {"title": "Caltech- 256 object category dataset", "author": ["G. Griffin", "A. Holub", "P. Perona"], "venue": "California Institute of Technology, Tech. Rep. 7694, 2007. [Online]. Available: http://authors.library.caltech.edu/7694 11", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Matching shapes in images has many applications, including image retrieval, alignment, and registration [1, 2, 3, 4].", "startOffset": 104, "endOffset": 116}, {"referenceID": 1, "context": "Matching shapes in images has many applications, including image retrieval, alignment, and registration [1, 2, 3, 4].", "startOffset": 104, "endOffset": 116}, {"referenceID": 2, "context": "Matching shapes in images has many applications, including image retrieval, alignment, and registration [1, 2, 3, 4].", "startOffset": 104, "endOffset": 116}, {"referenceID": 3, "context": "Matching shapes in images has many applications, including image retrieval, alignment, and registration [1, 2, 3, 4].", "startOffset": 104, "endOffset": 116}, {"referenceID": 4, "context": "[5, 6].", "startOffset": 0, "endOffset": 6}, {"referenceID": 5, "context": "[5, 6].", "startOffset": 0, "endOffset": 6}, {"referenceID": 10, "context": "Some traditional methods for related settings focus on optimisation over the space of rigid transformations so as to minimise least-squares criteria [11,12].", "startOffset": 149, "endOffset": 156}, {"referenceID": 11, "context": "Some traditional methods for related settings focus on optimisation over the space of rigid transformations so as to minimise least-squares criteria [11,12].", "startOffset": 149, "endOffset": 156}, {"referenceID": 12, "context": "Recently, this class of problems has been approached from a different perspective, as direct optimisation over the space of correspondences [13].", "startOffset": 140, "endOffset": 144}, {"referenceID": 6, "context": "Some notable approaches deviate from this norm \u2013 see (for example) [7, 8, 9, 10].", "startOffset": 67, "endOffset": 80}, {"referenceID": 7, "context": "Some notable approaches deviate from this norm \u2013 see (for example) [7, 8, 9, 10].", "startOffset": 67, "endOffset": 80}, {"referenceID": 8, "context": "Some notable approaches deviate from this norm \u2013 see (for example) [7, 8, 9, 10].", "startOffset": 67, "endOffset": 80}, {"referenceID": 9, "context": "Some notable approaches deviate from this norm \u2013 see (for example) [7, 8, 9, 10].", "startOffset": 67, "endOffset": 80}, {"referenceID": 13, "context": "More recently, these methods have been made substantially faster [14].", "startOffset": 65, "endOffset": 69}, {"referenceID": 14, "context": "Other lines of work that optimise directly over the correspondence space are those based on Graph Matching, which explicitly model all pairwise compatibilities and solve for the best match with some relaxation (since the Graph Matching problem is NP-hard for general pairwise compatibilities) [15, 16, 17].", "startOffset": 293, "endOffset": 305}, {"referenceID": 15, "context": "Other lines of work that optimise directly over the correspondence space are those based on Graph Matching, which explicitly model all pairwise compatibilities and solve for the best match with some relaxation (since the Graph Matching problem is NP-hard for general pairwise compatibilities) [15, 16, 17].", "startOffset": 293, "endOffset": 305}, {"referenceID": 16, "context": "Other lines of work that optimise directly over the correspondence space are those based on Graph Matching, which explicitly model all pairwise compatibilities and solve for the best match with some relaxation (since the Graph Matching problem is NP-hard for general pairwise compatibilities) [15, 16, 17].", "startOffset": 293, "endOffset": 305}, {"referenceID": 17, "context": "Recently, it was shown both in [18] and in [19] that if some form of structured optimisation is used to optimise graph matching scores, relaxed quadratic assignment predictors can improve the power of pairwise features.", "startOffset": 31, "endOffset": 35}, {"referenceID": 18, "context": "Recently, it was shown both in [18] and in [19] that if some form of structured optimisation is used to optimise graph matching scores, relaxed quadratic assignment predictors can improve the power of pairwise features.", "startOffset": 43, "endOffset": 47}, {"referenceID": 0, "context": "Here we study the case of identifying an instance of a template shape (S \u2286 T ) in a target scene (U) [1].", "startOffset": 101, "endOffset": 104}, {"referenceID": 5, "context": "Typically both T and U correspond to a set of \u2018landmark\u2019 points, taken from a pair of images (common approaches include [6, 20,21,22]).", "startOffset": 120, "endOffset": 133}, {"referenceID": 19, "context": "Typically both T and U correspond to a set of \u2018landmark\u2019 points, taken from a pair of images (common approaches include [6, 20,21,22]).", "startOffset": 120, "endOffset": 133}, {"referenceID": 20, "context": "Typically both T and U correspond to a set of \u2018landmark\u2019 points, taken from a pair of images (common approaches include [6, 20,21,22]).", "startOffset": 120, "endOffset": 133}, {"referenceID": 21, "context": "Typically both T and U correspond to a set of \u2018landmark\u2019 points, taken from a pair of images (common approaches include [6, 20,21,22]).", "startOffset": 120, "endOffset": 133}, {"referenceID": 4, "context": "For each point t \u2208 T and u \u2208 U , a certain set of unary features are extracted (here denoted by \u03c6(t), \u03c6(u)), which contain local information about the image at that point [5, 6].", "startOffset": 171, "endOffset": 177}, {"referenceID": 5, "context": "For each point t \u2208 T and u \u2208 U , a certain set of unary features are extracted (here denoted by \u03c6(t), \u03c6(u)), which contain local information about the image at that point [5, 6].", "startOffset": 171, "endOffset": 177}, {"referenceID": 17, "context": "(3)) in [18].", "startOffset": 8, "endOffset": 12}, {"referenceID": 13, "context": "In fact a recent paper [14] has shown that if only the distances as encoded by the graphical model depicted in figure 1 (top) are taken into account (nodes represent points in S and states represent points in U), exact probabilistic inference in such a model can solve the isometric problem optimally.", "startOffset": 23, "endOffset": 27}, {"referenceID": 13, "context": "Figure 1: Top: The graphical model introduced in [14].", "startOffset": 49, "endOffset": 53}, {"referenceID": 22, "context": "(4) Although the graphical model in figure 1 (top) does not form a single loop (a condition typically required for convergence of belief propagation [23, 24, 25]), [14] show that it is sufficient that the clique graph forms a single loop in order to guarantee convergence to the optimal assignment (figure 1, bottom).", "startOffset": 149, "endOffset": 161}, {"referenceID": 23, "context": "(4) Although the graphical model in figure 1 (top) does not form a single loop (a condition typically required for convergence of belief propagation [23, 24, 25]), [14] show that it is sufficient that the clique graph forms a single loop in order to guarantee convergence to the optimal assignment (figure 1, bottom).", "startOffset": 149, "endOffset": 161}, {"referenceID": 24, "context": "(4) Although the graphical model in figure 1 (top) does not form a single loop (a condition typically required for convergence of belief propagation [23, 24, 25]), [14] show that it is sufficient that the clique graph forms a single loop in order to guarantee convergence to the optimal assignment (figure 1, bottom).", "startOffset": 149, "endOffset": 161}, {"referenceID": 13, "context": "(4) Although the graphical model in figure 1 (top) does not form a single loop (a condition typically required for convergence of belief propagation [23, 24, 25]), [14] show that it is sufficient that the clique graph forms a single loop in order to guarantee convergence to the optimal assignment (figure 1, bottom).", "startOffset": 164, "endOffset": 168}, {"referenceID": 13, "context": "Furthermore, it is shown in [14] that the number of iterations required before convergence is small in practice.", "startOffset": 28, "endOffset": 32}, {"referenceID": 13, "context": "Note that in order to guarantee convergence, we do not require any specific form for the potentials, except that no assignment has infinite cost [14].", "startOffset": 145, "endOffset": 149}, {"referenceID": 25, "context": "Typically, one uses the squared L2 norm, \u2016\u03b8\u201622, to penalise non-smooth choices of \u03b8 [26].", "startOffset": 84, "endOffset": 88}, {"referenceID": 25, "context": "Here we capitalise on recent advances in large-margin structured estimation [26], which consist of obtaining convex relaxations of this problem.", "startOffset": 76, "endOffset": 80}, {"referenceID": 25, "context": "Without going into the details of the solution (see, for example, [26,27]), it can be shown that a convex relaxation of this problem can be obtained, which is given by", "startOffset": 66, "endOffset": 73}, {"referenceID": 26, "context": "Without going into the details of the solution (see, for example, [26,27]), it can be shown that a convex relaxation of this problem can be obtained, which is given by", "startOffset": 66, "endOffset": 73}, {"referenceID": 25, "context": "This process is known as \u2018column generation\u2019 [26,27].", "startOffset": 45, "endOffset": 52}, {"referenceID": 26, "context": "This process is known as \u2018column generation\u2019 [26,27].", "startOffset": 45, "endOffset": 52}, {"referenceID": 13, "context": "Although the model of [14] solves isometric matching problems optimally, it provides no guarantees for near -isometric problems, as it only considers those compatibilities which form cliques in our graphical model.", "startOffset": 22, "endOffset": 26}, {"referenceID": 13, "context": "\u03a61 is exactly the feature used in [14], and is invariant to isometric transformations (rotation, reflection, and translation); \u03a62 and \u03a63 capture triangle similarity, and are thus also invariant to scale.", "startOffset": 34, "endOffset": 38}, {"referenceID": 5, "context": "In practice, landmark detectors often identify several hundred points [6, 28], which is clearly impractical for an O(|S||U|) method (|U| is the number of landmarks in the target scene).", "startOffset": 70, "endOffset": 77}, {"referenceID": 27, "context": "In practice, landmark detectors often identify several hundred points [6, 28], which is clearly impractical for an O(|S||U|) method (|U| is the number of landmarks in the target scene).", "startOffset": 70, "endOffset": 77}, {"referenceID": 17, "context": "To address this, we adopt a two stage learning approach: in the first stage, we learn only unary compatibilities, exactly as is done in [18].", "startOffset": 136, "endOffset": 140}, {"referenceID": 13, "context": "In our first experiment, we compare our method to those of [14] and [18].", "startOffset": 59, "endOffset": 63}, {"referenceID": 17, "context": "In our first experiment, we compare our method to those of [14] and [18].", "startOffset": 68, "endOffset": 72}, {"referenceID": 17, "context": "As in [18], we compute the Shape Context features for each of the 30 points [5].", "startOffset": 6, "endOffset": 10}, {"referenceID": 4, "context": "As in [18], we compute the Shape Context features for each of the 30 points [5].", "startOffset": 76, "endOffset": 79}, {"referenceID": 17, "context": "html In addition to the unary model of [18], a model based on quadratic assignment is also presented, in which pairwise features are determined using the adjacency structure of the graphs.", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "As in [14], we compare pairs of images with a fixed baseline (separation between frames).", "startOffset": 6, "endOffset": 10}, {"referenceID": 17, "context": "In figure 5, we see that the running time of our method is similar to the quadratic assignment method of [18].", "startOffset": 105, "endOffset": 109}, {"referenceID": 17, "context": "8Interestingly, the quadratic method of [18] performs worse than their unary method; this is likely because the relative scale of the unary and quadratic features is badly tuned before learning, and is indeed similar to what the authors report.", "startOffset": 40, "endOffset": 44}, {"referenceID": 17, "context": "Furthermore, the results we present for the method of [18] after learning are much better than what the authors report \u2013 in that paper, the unary features are scaled using a pointwise exponent (\u2212 exp(\u2212|\u03c6a \u2212 \u03c6b|)), whereas we found that scaling the features linearly (|\u03c6a \u2212 \u03c6b|) worked better.", "startOffset": 54, "endOffset": 58}, {"referenceID": 17, "context": "replicating exactly the experiment from [18], but including only the limited dependencies captured by our model.", "startOffset": 40, "endOffset": 44}, {"referenceID": 17, "context": "In this experiment, the model of [18] performed better than ours; this indicates that the benefit of using an exact algorithm does not exceed the cost of capturing only limited dependencies.", "startOffset": 33, "endOffset": 37}, {"referenceID": 17, "context": "The quadratic assignment method of [18] is not shown for this experiment, as the adjacency information in the graph is not robust to random error, or the addition of outliers (it performed far worse than the techniques shown).", "startOffset": 35, "endOffset": 39}, {"referenceID": 17, "context": "9Note that setting p = 1 essentially recovers the linear method of [18].", "startOffset": 67, "endOffset": 71}, {"referenceID": 13, "context": "Figure 8: Comparison of our technique against that of [14] (\u2018point matching\u2019), and [18] (\u2018linear\u2019).", "startOffset": 54, "endOffset": 58}, {"referenceID": 17, "context": "Figure 8: Comparison of our technique against that of [14] (\u2018point matching\u2019), and [18] (\u2018linear\u2019).", "startOffset": 83, "endOffset": 87}, {"referenceID": 13, "context": "Figure 4: Comparison of our technique against that of [14] (\u2018point matching\u2019), and [18] (\u2018linear\u2019, \u2018quadratic\u2019).", "startOffset": 54, "endOffset": 58}, {"referenceID": 17, "context": "Figure 4: Comparison of our technique against that of [14] (\u2018point matching\u2019), and [18] (\u2018linear\u2019, \u2018quadratic\u2019).", "startOffset": 83, "endOffset": 87}, {"referenceID": 17, "context": "Figure 5: The running time and performance of our method, compared to those of [18] (note that the method of [14] has running time identical to our method).", "startOffset": 79, "endOffset": 83}, {"referenceID": 13, "context": "Figure 5: The running time and performance of our method, compared to those of [18] (note that the method of [14] has running time identical to our method).", "startOffset": 109, "endOffset": 113}, {"referenceID": 28, "context": "For our final experiment, we used images of bicycles from the Caltech 256 Dataset [29].", "startOffset": 82, "endOffset": 86}, {"referenceID": 5, "context": "Initially, we used the SIFT landmarks and features as described in [6].", "startOffset": 67, "endOffset": 70}, {"referenceID": 27, "context": "In [28], the authors report that the SIFT features can provide good matches in such cases, as long as landmarks are chosen which are locally invariant to affine transformations.", "startOffset": 3, "endOffset": 7}, {"referenceID": 27, "context": "Centre: The target image, and the match (in red) using unary features with the affine invariant/SIFT model of [28] after learning (endpoint error = 0.", "startOffset": 110, "endOffset": 114}, {"referenceID": 5, "context": "SIFT [6] Affine invariant/SIFT [28] unary training: 0.", "startOffset": 5, "endOffset": 8}, {"referenceID": 27, "context": "SIFT [6] Affine invariant/SIFT [28] unary training: 0.", "startOffset": 31, "endOffset": 35}], "year": 2017, "abstractText": "Models for near-rigid shape matching are typically based on distance-related features, in order to infer matches that are consistent with the isometric assumption. However, real shapes from image datasets, even when expected to be related by \u201calmost isometric\u201d transformations, are actually subject not only to noise but also, to some limited degree, to variations in appearance and scale. In this paper, we introduce a graphical model that parameterises appearance, distance, and angle features and we learn all of the involved parameters via structured prediction. The outcome is a model for near-rigid shape matching which is robust in the sense that it is able to capture the possibly limited but still important scale and appearance variations. Our experimental results reveal substantial improvements upon recent successful models, while maintaining similar running times.", "creator": "LaTeX with hyperref package"}}}