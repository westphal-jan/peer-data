{"id": "1003.0024", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Feb-2010", "title": "Asymptotic Analysis of Generative Semi-Supervised Learning", "abstract": "Semisupervised learning has emerged as a popular framework for improving modeling accuracy while controlling labeling cost. Based on an extension of stochastic composite likelihood we quantify the asymptotic accuracy of generative semi-supervised learning. In doing so, we complement distribution-free analysis by providing an alternative framework to measure the value associated with different labeling policies and resolve the fundamental question of how much data to label and in what manner. We demonstrate our approach with both simulation studies and real world experiments using naive Bayes for text classification and MRFs and CRFs for structured prediction in NLP.", "histories": [["v1", "Fri, 26 Feb 2010 21:59:02 GMT  (280kb)", "http://arxiv.org/abs/1003.0024v1", "12 pages, 9 figures"]], "COMMENTS": "12 pages, 9 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["joshua v dillon", "krishnakumar balasubramanian", "guy lebanon"], "accepted": true, "id": "1003.0024"}, "pdf": {"name": "1003.0024.pdf", "metadata": {"source": "CRF", "title": "Asymptotic Analysis of Generative Semi-Supervised Learning", "authors": ["Joshua V Dillon", "Krishnakumar Balasubramanian"], "emails": ["jvdillon@gatech.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n00 3.\n00 24\nv1 [\ncs .L\nG ]\n2 6\nSemisupervised learning has emerged as a popular framework for improving modeling accuracy while controlling labeling cost. Based on an extension of stochastic composite likelihood we quantify the asymptotic accuracy of generative semi-supervised learning. In doing so, we complement distribution-free analysis by providing an alternative framework to measure the value associated with different labeling policies and resolve the fundamental question of how much data to label and in what manner. We demonstrate our approach with both simulation studies and real world experiments using naive Bayes for text classification and MRFs and CRFs for structured prediction in NLP."}, {"heading": "1 Introduction", "text": "Semisupervised learning (SSL) is a technique for estimating statistical models using both labeled and unlabeled data. It is particularly useful when the costs of obtaining labeled and unlabeled samples are different. In particular, assuming that unlabeled data is more easily available, SSL provides improved modeling accuracy by adding a large number of unlabeled samples to a relatively small labeled dataset.\nThe practical value of SSL has motivated several attempts to mathematically quantify its value beyond traditional supervised techniques. Of particular importance is the dependency of that improvement on the amount of unlabeled and labeled data. In the case of structured prediction the accuracy of the SSL estimator depends also on the specific manner in which sequences are labeled. Focusing on the framework of generative or likelihood-based SSL applied to classification and structured prediction we identify the following questions which we address in this paper. Q1: Consistency (classification). What combinations of labeled and unlabeled data lead to precise models in the limit of large data. Q2: Accuracy (classification). How can we quantitatively express the estimation accuracy for a particular generative model as a function of the amount of labeled and unlabeled data. What is the improvement in estimation accuracy resulting from replacing an unlabeled example with a labeled one. Q3: Consistency (structured prediction). What strategies for sequence labeling lead to precise models in the limit of large data. Q4: Accuracy (structured prediction). How can we quantitatively express the estimation quality for a particular model and structured labeling strategy. What is the improvement in estimation accuracy resulting from replacing one labeling strategy with another. Q5: Tradeoff (classification and structured prediction). How can we quantitatively express the tradeoff between the two competing goals of improved prediction accuracy and low labeling cost. What are the possible ways to resolve that tradeoff optimally within a problem-specific context.\n\u2217To whom correspondence should be addressed. Email: jvdillon@gatech.edu\nQ6: Practical Algorithms. How can we determine how much data to label in practical settings. The first five questions are of fundamental importance to SSL theory. Recent related work has concentrated on large deviation bounds for discriminative SSL as a response to Q1 and Q2 above. While enjoying broad applicability, such non-parametric bounds are weakened when the model family\u2019s worst-case is atypical. By forgoing finite sample analysis, our approach complements these efforts and provides insights which apply to the specific generative models under consideration. In presenting answers to the last question, we reveal the relative merits of asymptotic analysis and how its employ, perhaps surprisingly, renders practical heuristics for controlling labeling cost.\nOur asymptotic derivations are possible by extending the recently proposed stochastic composite likelihood formalism [5] and showing that generative SSL is a special case of that extension. The implications of this analysis are demonstrated using a simulation study as well as text classification and NLP structured prediction experiments. The developed framework, however, is general enough to apply to any generative SSL problem. As in [7], the delta method transforms our results from parameter asymptotics to prediction risk asymptotics. We omit these results for lack of space."}, {"heading": "2 Related Work", "text": "Semisupervised learning has received much attention in the past decade. Perhaps the first study in this area was done by Castelli and Cover [3] who examined the convergence of the classification error rate as a labeled example is added to an unlabeled dataset drawn from a Gaussian mixture model. Nigam et al. [9] proposed a practical SSL framework based on maximizing the likelihood of the observed data. An edited volume describing more recent developments is [4].\nThe goal of theoretically quantifying the effect of SSL has recently gained increased attention. Sinha and Belkin [11] examined the effect of using unlabeled samples with imperfect models for mixture models. Balcan and Blum [1] and Singh et al. [10] analyze discriminative SSL using PAC theory and large deviation bounds. Additional analysis has been conducted under specific distributional assumptions such as the \u201ccluster assumption\u201d, \u201csmoothness assumption\u201d and the \u201clow density assumption.\u201d[4] However, many of these assumptions are criticized in [2].\nOur work complements the above studies in that we focus on generative as opposed to discriminative SSL. In contrast to most other studies, we derive model specific asymptotics as opposed to non-parametric large deviation bounds. While such bounds are helpful as they apply to a broad set of cases, they also provide less information than model-based analysis due to their generality. Our analysis, on the other hand, requires knowledge of the specific model family and an estimate of the model parameter. The resulting asymptotics, however, apply specifically to the case at hand without the need of potentially loose bounds.\nWe believe that our work is the first to consider and answer questions Q1-Q6 in the context of generative SSL. In particular, our work provides a new framework for examining the accuracy-cost SSL tradeoff in a way that is quantitative, practical, and model-specific."}, {"heading": "3 Stochastic SSL Estimators", "text": "Generative SSL [9, 4] estimates a parametric model by maximizing the observed likelihood incorporating L labeled and U unlabeled examples\n\u2113(\u03b8) =\nL \u2211\ni=1\nlog p\u03b8(X (i), Y (i)) +\nL+U \u2211\ni=L+1\nlog p\u03b8(X (i)) (1)\nwhere p\u03b8(X (i)) above is obtained by marginalizing the latent label\n\u2211\ny p\u03b8(X (i), y). A classical example is\nthe naive Bayes model in [9] where p\u03b8(X,Y ) = p\u03b8(X |Y )p(Y ), p\u03b8(X |Y = y) = Mult([\u03b8y]1, . . . , [\u03b8y]V ). The framework, however, is general enough to apply to any generative model p\u03b8(X,Y ).\nTo analyze the asymptotic behavior of the maximizer of (1) we assume that the ratio between labeled to unlabeled examples \u03bb = L/(L + U) is kept constant while n = L + U \u2192 \u221e. More generally, we assume a stochastic version of (1) where each one of the n samples X(1), . . . , X(n) is labeled with probability \u03bb\n\u2113n(\u03b8) = n \u2211\ni=1\nZ(i) log p\u03b8(X (i), Y (i)) +\nn \u2211\ni=1\n(1\u2212 Z(i)) log p\u03b8(X(i)), Z(i) \u223c Bin(1, \u03bb). (2)\nThe variable Z(i) above is an indicator taking the value 1 with probability \u03bb and 0 otherwise. Due to the law of large numbers for large n we will have approximately L = n\u03bb labeled samples and U = n(1\u2212\u03bb) unlabeled samples thus achieving the asymptotic behavior of (1).\nEquation (2) is sufficient to handle the case of classification. However, in the case of structured prediction we may have sequencesX(i), Y (i) where for each i some components of the label sequence Y (i) are missing and some are observed. For example one label sequence may be completely observed, another may be completely unobserved, and a third may have the first half labeled and the second half not.\nMore formally, we assume the existence of a sequence labeling policy or strategy \u2118 which maps label\nsequences Y (i) = (Y (i) 1 , . . . , Y (i) m ) to a subset corresponding to the observed labels \u2118(Y (i)) \u2282 {Y (i)1 , . . . , Y (i) m }. To achieve full generality we allow the labeling policy \u2118 to be stochastic, leading to different subsets of {Y (i)1 , . . . , Y (i) m } with different probabilities. A simple \u201call or nothing\u201d labeling policy could label the entire sequence with probability \u03bb and otherwise ignore it. Another policy may label the entire sequence, the first half, or ignore it completely with equal probabilities\n\u2118(Y )=\n\n \n \nY (i) 1 , . . . , Y (i) m with probability 1/3 \u2205 with probability 1/3 Y\n(i) 1 , . . . , Y (i) \u230am/2\u230b with probability 1/3\n. (3)\nWe thus have the following generalization of (2) for structured prediction\n\u2113n(\u03b8) =\nn \u2211\ni=1\nlog p\u03b8(\u2118(Y (i)), X(i)). (4)\nEquation (4) generalizes standard SSL from all or nothing labeling to arbitrary labeling policies. The fundamental SSL question in this case is not simply what is the dependency of the estimation accuracy on n and \u03bb. Rather we ask what is the dependency of the estimation accuracy on the labeling policy \u2118. Of particular interest is the question what labeling policies \u2118 achieve high estimation accuracy coupled with low labeling cost. Answering these questions leads to a generative SSL theory that quantitatively balances estimation accuracy and labeling cost.\nFinally, we note that both (2) and (4) are random variables whose outcomes depend on the random variables Z(1), . . . , Z(n) (for (2)) or \u2118 (for (4)). Consequentially, the analysis of the maximizer \u03b8\u0302n of (2) or (4) needs to be done in a probabilistic manner."}, {"heading": "4 A1: Consistency (Classification)", "text": "Assuming that the data is generated from p\u03b80(X,Y ) consistency corresponds to the convergence of\n\u03b8\u0302n = argmax \u03b8 \u2113n(\u03b8) (5)\nto \u03b80 with probability 1 as n \u2192 \u221e (\u2113n is defined in (2)). This implies that in the limit of large data our estimator would converge to the truth. Note that large data n \u2192 \u221e in this case means that both labeled and unlabeled data increase to \u221e (but their relative sizes remain the constant \u03bb).\nWe show in this section that the maximizer of (2) is consistent assuming that \u03bb > 0. This is not an unexpected conclusion but for the sake of completeness we prove it here rigorously. The proof technique will also be used later when we discuss consistency of SSL estimators for structured prediction.\nThe central idea in the proof is to cast the generative SSL estimation problem as an extension of stochastic composite likelihood [5]. Our proof follows similar lines to the consistency proof of [5] with the exception that it does not assume independence of the indicator functions Z(i) and (1 \u2212 Z(i)) as is assumed there. Definition 1. A distribution p\u03b8(X,Y ) is said to be identifiable if \u03b8 6= \u03b7 entails that p\u03b8(X,Y )\u2212 p\u03b7(X,Y ) is not identically zero.\nProposition 1. Let \u0398 \u2282 Rr be a compact set, and p\u03b8(x, y) > 0 be identifiable and smooth in \u03b8. Then if \u03bb > 0 the maximizer \u03b8\u0302n of (2) is consistent i.e., \u03b8\u0302n \u2192 \u03b80 as n \u2192 \u221e with probability 1. Proof. The likelihood function, modified slightly by a linear combination with a constant is \u2113\u2032n(\u03b8) =\n1\nn\nn \u2211\ni=1\n(\nZ(i) log p\u03b8(X (i), Y (i))\u2212 \u03bb log p\u03b80(X(i), Y (i))\n) + 1\nn\nn \u2211\ni=1\n( (1\u2212 Z(i)) log p\u03b8(X(i))\u2212 (1\u2212 \u03bb) log p\u03b80(X(i)) ) ,\nconverges by the the strong law of large numbers as n \u2192 \u221e to its expectation with probability 1\n\u00b5(\u03b8) = \u2212\u03bbD(p\u03b80(X,Y )||p\u03b8(X,Y ))\u2212 (1\u2212 \u03bb)D(p\u03b80(X)||p\u03b8(X))).\nIf we restrict ourselves to the compact set S = {\u03b8 : c1 \u2264 \u2016\u03b8\u2212 \u03b80\u2016 \u2264 c2} then | log p\u03b8(X,Y )| < K(X,Y ) < \u221e, \u2200\u03b8 \u2208 S. As a result, the conditions for the uniform strong law of large numbers, cf. chapter 16 of [6], hold on S leading to\nP\n{\nlim n\u2192\u221e sup \u03b8\u2208S\n|\u2113\u2032n(\u03b8)\u2212 \u00b5(\u03b8)| = 0 } = 1. (6)\nDue to the identifiability of p\u03b8(X,Y ) we have D(p\u03b80(X,Y )||p\u03b8(X,Y )) \u2265 0 with equality iff \u03b8 = \u03b80. Since also D(p\u03b80(X)||p\u03b8(X))) \u2265 0 we have that \u00b5(\u03b8) \u2264 0 with equality iff \u03b8 = \u03b80 (assuming \u03bb > 0). Furthermore, since the function \u00b5(\u03b8) is continuous it attains its negative supremum on the compact S: sup\u03b8\u2208S \u00b5(\u03b8) < 0.\nCombining this fact with (6) we have that there exists N such that for all n > N the likelihood maximizers on S achieves strictly negative values of \u2113\u2032n(\u03b8) with probability 1. However, since \u2113 \u2032 n(\u03b8) can be made to achieve values arbitrarily close to zero under \u03b8 = \u03b80, we have that \u03b8\u0302n 6\u2208 S for n > N . Since c1, c2 were chosen arbitrarily \u03b8\u0302n \u2192 \u03b80 with probability 1.\nThe above proposition is not surprising. As n \u2192 \u221e the number of labeled examples increase to \u221e and thus it remains to ensure that adding an increasing number of unlabeled examples does not hurt the estimator. More interesting is the quantitative description of the accuracy of \u03b8\u0302n and its dependency on \u03b80, \u03bb, n which we turn to next."}, {"heading": "5 A2: Accuracy (Classification)", "text": "The proposition below states that the distribution of the maximizer of (2) is asymptotically normal and\nprovides its variance which may be used to characterize the accuracy of \u03b8\u0302n as a function of n, \u03b80, \u03bb. As in Section 4 our proof proceeds by casting generative SSL as an extension of stochastic composite likelihood.\nIn Proposition 2 (below) and in Proposition 4 we use Var \u03b80(H) to denote the variance matrix of a random vector H under p\u03b80 . The notations\np\u2192 , denote convergences in probability and in distribution [6] and \u2207f(\u03b8), \u22072f(\u03b8) are the r \u00d7 1 gradient vector and r \u00d7 r matrix of second order derivatives of f(\u03b8). Proposition 2. Under the assumptions of Proposition 1 as well as convexity of \u0398 we have the following convergence in distribution of the maximizer of (2)\n\u221a n(\u03b8\u0302n \u2212 \u03b80) N ( 0,\u03a3\u22121 )\n(7)\nas n \u2192 \u221e, where \u03a3 = \u03bbVar \u03b80(V1) + (1\u2212 \u03bb)Var \u03b80(V2) V1 = \u2207\u03b8 log p\u03b80(X,Y ), V2 = \u2207\u03b8 log p\u03b80(X).\nProof. By the mean value theorem and convexity of \u0398, there is \u03b7 \u2208 (0, 1) for which \u03b8\u2032=\u03b80 + \u03b7(\u03b8\u0302n \u2212 \u03b80) and\n\u2207\u2113n(\u03b8\u0302n) = \u2207\u2113n(\u03b80) +\u22072\u2113n(\u03b8\u2032)(\u03b8\u0302n \u2212 \u03b80).\nSince \u03b8\u0302n maximizes \u2113n we have \u2207\u2113n(\u03b8\u0302n) = 0 and \u221a n(\u03b8\u0302n \u2212 \u03b80) = \u2212 \u221a n ( \u22072\u2113n(\u03b8\u2032) )\u22121 (\u2207\u2113n(\u03b80)) . (8)\nBy Proposition 1 we have \u03b8\u0302n p\u2192 \u03b80 which implies that \u03b8\u2032 p\u2192 \u03b80 as well. Furthermore, by the law of large numbers and the fact that Wn p\u2192 W implies g(Wn) p\u2192 g(W ) for continuous g,\n(\u22072\u2113n(\u03b8\u2032))\u22121 p\u2192 (\u22072\u2113n(\u03b80))\u22121 (9) p\u2192 ( \u03bbE \u03b80\u22072 log p\u03b80(X,Y ) + (1\u2212 \u03bb)E \u03b80\u22072 log p\u03b80(X) )\u22121 = \u03a3\u22121\nwhere in the last equality we used a well known identity concerning the Fisher information. For the remaining term in the rhs of (8) we have\n\u2212\u221an\u2207\u2113n(\u03b80) = \u2212 \u221a n 1\nn\nn \u2211\ni=1\n(W (i) +Q(i)) (10)\nwhere W (i) = Z(i)\u2207 log p\u03b80(X(i), Y (i)), Q(i) = (1 \u2212 Z(i))\u2207 log p\u03b80(X(i)). Since (10) is an average of iid random vectors W (i) +Q(i) it is asymptotically normal by the central limit theorem with mean\nE \u03b80(Q +W ) = \u03bbE \u03b80\u2207 log p\u03b80(X,Y ) + (1\u2212 \u03bb)E\u2207 log p\u03b80(X) = \u03bb0 + (1\u2212 \u03bb)0. and variance\nVar \u03b80(W +Q) = E \u03b80W 2 + E \u03b80Q 2 + 2E \u03b80WQ\n= \u03bbVar \u03b80V1 + (1\u2212 \u03bb)Var \u03b80V2 where we used E (Z(1\u2212 Z)) = EZ \u2212 EZ2 = 0 .\nWe have thus established that\n\u2212\u221an\u2207\u2113n(\u03b80) N(0,\u03a3). (11) We finish the proof by combining (8), (15) and (11) using Slutsky\u2019s theorem.\nProposition 2 characterizes the asymptotic estimation accuracy using the matrix \u03a3. Two convenient one dimensional summaries of the accuracy are the trace and the determinant of \u03a3. In some simple cases (such as binary event naive Bayes) tr(\u03a3) can be brought to a mathematically simple form which exposes its dependency on \u03b80, n, \u03bb. In other cases the dependency may be obtained using numerical computing.\nFigure 1 displays three error measures for the multinomial naive Bayes SSL classifier [9] and the Reuters RCV1 text classification data. In all three figures the error measures are represented as functions of n (horizontal axis) and \u03bb (vertical axis). The error measures are classification error rate (left), trace of the empirical mse (middle), and log-trace of the asymptotic variance (right). The measures were obtained over held-out sets and averaged using cross validation. Figure 3 (middle) displays the asymptotic variance as a function of n and \u03bb for a randomly drawn \u03b80.\nAs expected the measures decrease with n and \u03bb in all the figures. It is interesting to note, however, that the shapes of the contour plots are very similar across the three different measures (top row). This confirms that the asymptotic variance (right) is a valid proxy for the finite sample measures of error rates and empirical mse. We thus conclude that the asymptotic variance is an attractive measure that is similar to finite sample error rate and at the same time has a convenient mathematical expression."}, {"heading": "6 A3: Consistency (Structured)", "text": "In the case of structured prediction the log-likelihood (4) is specified using a stochastic labeling policy. In this section we consider the conditions on that policy that ensures estimation consistency, or in other word convergence of the maximizer of (4) to \u03b80 as n \u2192 \u221e.\nWe assume that the labeling policy \u2118 is a probabilistic mixture of deterministic sequence labeling functions \u03c71, . . . , \u03c7k. In other words, \u2118(Y ) takes values \u03c7i(Y ), i = 1, . . . , k with probabilities \u03bb1, . . . , \u03bbk. For example the policy (3) corresponds to \u03c71(Y ) = Y , \u03c72(Y ) = \u2205, \u03c73(Y ) = {Y1, . . . , Y\u230am/2\u230b} (where Y = {Y1, . . . , Ym}) and \u03bb = (1/3, 1/3, 1/3).\nUsing the above notation we can write (4) as\n\u2113n(\u03b8) =\nn \u2211\ni=1\nk \u2211\nj=1\nZ (i) j log p\u03b8(\u03c7j(Y (i)), X(i)) (12)\nZ(i) \u223c Mult(1, (\u03bb1, . . . , \u03bbk))\nwhich exposes its similarity to the stochastic composite likelihood function in [5]. Note however that (12) is not formally a stochastic composite likelihood since Z (i) j , j = 1, . . . , k are not independent and since \u03c7j(Y ) depends on the length of the sequence Y (see for example \u03c71 and \u03c73 above). We also use the notation S m j for the subset of labels provided by \u03c7j on length-m sequences\n\u03c7j(Y1, . . . , Ym) = {Yi : i \u2208 Smj }.\nDefinition 2. A labeling policy is said to be identifiable if the following map is injective\n\u22c3\nm:q(m)>0\nk \u22c3\nj=1\n{p\u03b8({Yr : r \u2208 Smj }, X)} \u2192 p\u03b8(X,Y )\nwhere q is the distribution of sequences lengths. In other words, there is at most one collection of probabilities corresponding to the lhs above that does not contradict the joint distribution.\nThe importance of Definition 2 is that it ensures the recovery of \u03b80 from the sequences partially labeled using the labeling policy. For example, a labeling policy characterized by \u03c71(Y ) = Y1, \u03bb1 = 1 (always label only the first sequence element) is non-identifiable for most interesting p\u03b8 as the first sequence component is unlikely to provide sufficient information to characterize the parameters associated with transitions Yt \u2192 Yt+1.\nProposition 3. Assuming the same conditions as Proposition 1, and \u03bb1, . . . , \u03bbk > 0 with identifiable \u03c71, . . . , \u03c7k, the maximizer of (12) is consistent i.e., \u03b8\u0302n \u2192 \u03b80 as n \u2192 \u221e with probability 1. Proof. The log-likelihood (4), modified slightly by a linear combination with a constant is\n\u2113\u2032n(\u03b8) = 1\nn\nn \u2211\ni=1\nk \u2211\nj=1\n(\nZ (i) j log p\u03b8(\u03c7j(Y (i)), X(i))\u2212 \u03bbj log p\u03b80(\u03c7j(Y (i)), X(i)) ) .\nBy the strong law of large numbers \u2113\u2032n(\u03b8) converges to its expectation\n\u00b5(\u03b8) = \u2212 k \u2211\nj=1\n\u03bbj \u2211\nm>0\nq(m) \u00b7D(p\u03b80({Yi : i \u2208 Smj }, X)||p\u03b8({Yi : i \u2208 Smj }, X)).\nSince \u00b5 is a linear combination of KL divergences with positive weights it is non-negative and is 0 if \u03b8 = \u03b80. The identifiability of the labeling policy ensures that \u00b5(\u03b8) > 0 if \u03b8 6= \u03b80. We have thus established that \u2113n(\u03b8) converges to a non-negative continuous function \u00b5(\u03b8) whose maximum is achieved at \u03b80. The rest of the proof proceeds along similar lines as Proposition 3.\nUltimately, the precise conditions for consistency will depend on the parametric family p\u03b8 under consideration. For many structured prediction models such as Markov random fields the consistency conditions are mild. Depending on the precise feature functions, consistency is generally satisfied for every policy that labels contiguous subsequences with positive probability. However, some care need to be applied for models like HMM containing parameters associated with the start label or end label and with models asserting higher order Markov assumptions."}, {"heading": "7 A4: Accuracy (Structured)", "text": "We consider in this section the dependency of the estimation accuracy in structured prediction SSL (4) on n, \u03b80 but perhaps most interestingly on the labeling policy \u2118. Doing so provides insight into not only how much data to label but also in what way.\nProposition 4. Under the assumptions of Proposition 3 as well as convexity of \u0398 we have the following convergence in distribution of the maximizer of (12)\n\u221a n(\u03b8\u0302n \u2212 \u03b80) N ( 0,\u03a3\u22121 )\n(13)\nas n \u2192 \u221e, where\n\u03a3\u22121 = E q(m)\n\n\n\nk \u2211\nj=1\n\u03bbjVar \u03b80(\u2207Vjm)\n\n\n\nVjm = log p\u03b80({Yi : i \u2208 Smj }, X).\nProof. By the mean value theorem and convexity of \u0398 there is \u03b7 \u2208 (0, 1) for which \u03b8\u2032=\u03b80+\u03b7(\u03b8\u0302n \u2212 \u03b80) and\n\u2207\u2113n(\u03b8\u0302n) = \u2207\u2113n(\u03b80) +\u22072\u2113n(\u03b8\u2032)(\u03b8\u0302n \u2212 \u03b80).\nSince \u03b8\u0302n maximizes \u2113, \u2207\u2113n(\u03b8\u0302n) = 0 and \u221a n(\u03b8\u0302n \u2212 \u03b80) = \u2212 \u221a n(\u22072\u2113n(\u03b8\u2032))\u22121\u2207\u2113n(\u03b80). (14)\nBy Proposition 3 we have \u03b8\u0302n p\u2192 \u03b80 which implies that \u03b8\u2032 p\u2192 \u03b80 as well. Furthermore, by the law of large numbers and the fact that if Wn p\u2192 W then g(Wn) p\u2192 g(W ) for continuous g,\n(\u22072\u2113n(\u03b8\u2032))\u22121 p\u2192 (\u22072\u2113n(\u03b80))\u22121 (15)\np\u2192\n\n\n\u2211\nm>0\nq(m)\nk \u2211\nj=1\n\u03bbjE \u03b80(\u22072Vjm)\n\n\n\u22121\n= \u2212\n\n\n\u2211\nm>0\nq(m)\nk \u2211\nj=1\n\u03bbjVar \u03b80(\u2207Vjm)\n\n\n\u22121\n.\nwhere in the last equality we used a well known identity concerning the Fisher information. For the remaining term on the rhs of (14) we have\n\u221a n\u2207\u2113n(\u03b80) = \u221a n 1\nn\nn \u2211\ni=1\nWi (16)\nwhere the random vectors\nWi = \u2211\nm>0\n1{length(Y (i))=m}\nk \u2211\nj=1\nZ (i) j \u2207V (i) jm\nhave expectation 0 due to the fact that the expectation of the score is 0. The variance of Wi is\nVar \u03b80Wi =E \u03b80 \u2211\nm>0\n1{length(Y (i))=m}\nk \u2211\nj=1\nZ (i) j \u2207V (i) jm\u2207V (i)\u22a4 jm\n= \u2211\nm>0\nq(m)\nk \u2211\nj=1\n\u03bbjE ( \u2207V (i)jm\u2207V (i)\u22a4 jm )\nwhere in the first equality we used the fact that Y (i) can have only one length and only one of \u03c71, . . . , \u03c7k is chosen. Using the central limit theorem we thus conclude that\n\u221a n\u2207\u2113n(\u03b80) N ( 0,\u03a3\u22121 )\nand finish the proof by combining (14), (15), and (11) using Slutsky\u2019s theorem.\nFigure 2 (left, middle) displays the test-set per-sequence perplexity for the CoNLL2000 chunking task as a function of the total number of labeled tokens. We used the Boltzmann chain MRF model that is the MRF corresponding to HMM (though not identical e.g., [8]). We consider labeling policies \u2118 that label the entire sequence with probability \u03bb and otherwise label contiguous sequences of length 5 (left) or leave the sequence fully unlabeled (middle). Lighter nodes indicate larger n and unsurprisingly show a decrease in the test-set perplexity as n is increased. Interestingly, the middle figure shows that labeling policies using a smaller amount of labels may outperform other policies. This further motivates our analysis and indicates that naive choices of \u2118 may be inefficient, viz. inflating labeling cost with negligible accuracy improvement to accuracy (cf. also Sec. 8 for how to avoid this pitfall)."}, {"heading": "7.1 Conditional Structured Prediction", "text": "Thus far our discussion on structured prediction has been restricted to generative models such as HMM or Boltzmann chain MRF. Similar techniques, however, can be used to analyze SSL for conditional models such as CRFs that are estimated by maximizing the conditional likelihood. The key to extending the results in this paper to CRFs is to express conditional SSL estimation in a form similar to (4)\n\u03b8\u0302n = argmax\nn \u2211\ni=1\nlog p\u03b8(\u2118(Y (i))|X(i))\nand to proceed with an asymptotic analysis that extends the classical conditional MLE asymptotics. We omit further discussion due to lack of space but include some experimental results for CRFs.\nFigure 3 (left) depicts a similar experiment to the one described in the previous section for conditional estimation in CRF models. The figure displays per-sequence perplexity as a function n (x axis) and \u03bb1 (y axis). We observe a trend nearly identical to that of the Boltzmann chain MRF (Figure 2, left, middle)."}, {"heading": "8 A5: Tradeoff", "text": "As the figures in the previous sections display, the estimation accuracy increases with the total number of labels. The Cramer-Rao lower bound states that the highest accuracy is obtained by the maximum likelihood operating on fully observed data. However, assuming that a certain cost is associated with labeling data SSL resolves a fundamental accuracy-cost tradeoff. A decrease in estimation accuracy is acceptable in return for decreased labeling cost.\nOur ability to mathematically characterize the dependency of the estimation accuracy on the labeling cost leads to a new quantitative formulation of this tradeoff. Each labeling policy (\u03bb, n in classification and \u2118 in structured prediction) is associated with a particular estimation accuracy via Propositions 2 and 4 and with a particular labeling cost. The precise way to measure labeling cost depends on the situation at\nhand, but we assume in this paper that the labeling cost is proportional to the numbers of labeled samples (classification) and of labeled sequence elements (structured prediction). This assumption may be easily relaxed by using other labeling cost functions e.g, obtaining unlabeled data may incur some cost as well.\nGeometrically, each labeling policy may thus be represented in a two dimensional scatter plot where the horizontal and vertical coordinates correspond to labeling cost and estimation error respectively. Three such scatter plots appear in Figure 2 (see Section 7 for a description of the left and middle panels). The right panel corresponds to multinomial naive Bayes SSL classifier and the 20-newsgroups classification dataset. Each point in that panel corresponds to different n, \u03bb.\nThe origin corresponds to the most desirable (albeit unachievable) position in the scatter plot representing zero error at no labeling cost. The cloud of points obtained by varying n, \u03bb (classification) and \u2118 (structured prediction) represents the achievable region of the diagram. Most attractive is the lower and left boundary of that region which represents labeling policies that dominate others in both accuracy and labeling cost. The non-achievable region is below and to the left of that boundary (see shaded region in Figure 2, right). The precise position of the optimal policy on the boundary of the achievable region depends on the relative importance of minimizing estimation error and minimizing labeling cost. A policy that is optimal in one context may not be optimal in a different context.\nIt is interesting to note that even in the case of naive Bayes classification (Figure 2, right) some labeling policies (corresponding to specific choices of n, \u03bb) are suboptimal. These policies correspond to points in the interior of the achievable region. A similar conclusion holds for Boltzmann chain MRF. For example, some of the points in Figure 2 (left) denoted by the label 700 are dominated by the more lightly shaded points.\nWe consider in particular three different ways to define an optimal labeling policy (i.e., determining how much data to label) on the boundary of the achievable region\n(\u03bb\u2217, n\u2217)1 = argmin (\u03bb,n):\u03bbn\u2264C tr(\u03a3\u22121) (17) (\u03bb\u2217, n\u2217)2 = argmin (\u03bb,n):tr(\u03a3\u22121)\u2264C \u03bbn (18)\n(\u03bb\u2217, n\u2217)3 = argmin (\u03bb,n) \u03bbn+ \u03b1 tr(\u03a3\u22121). (19)\nThe first applies in situations where the labeling cost is bounded by a certain available budget. The second applies when a certain estimation accuracy is acceptable and the goal is to minimize the labeling cost. The\nthird considers a more symmetric treatment of the estimation accuracy and labeling cost. Equations (17)-(19) may be easily generalized to arbitrary labeling costs f(n, \u03bb). Equations (17)-(19) may also be generalized to the case of structured prediction with \u2118 replacing (\u03bb, n) and cost(\u2118) replacing \u03bbn."}, {"heading": "9 A6: Practical Algorithms", "text": "Choosing a policy (\u03bb, n) or \u2118 resolves the SSL tradeoff of accuracy vs. cost. Such a resolution is tantamount to answering the basic question of how many labels should be obtained (and in the case of structured prediction also which ones). Resolving the tradeoff via (17)-(19) or in any other way, or even simply evaluating the asymptotic accuracy tr(\u03a3) requires knowledge of the model parameter \u03b80 that is generally unknown in practical settings.\nWe propose in this section a practical two stage algorithm for computing an estimate \u03b8\u0302n within a particular accuracy-cost tradeoff. Assuming we have n unlabeled examples, the algorithm begins the first stage by labeling r samples. It then estimates \u03b8\u2032 by maximizing the likelihood over the r labeled and n\u2212 r unlabeled samples. The estimate \u03b8\u0302\u2032 is then used to obtain a plug-in estimate for the asymptotic accuracy tr(\u03a3). In\nthe second stage the algorithm uses the estimate t\u0302r(\u03a3) to resolve the tradeoff via (17)-(19) and determine how many more labels should be collected. Note that the labels obtained at the first stage may be used in the second stage as well with no adverse effect.\nThe two-stage algorithm spends some initial labeling cost in order to obtain an estimate for the quantitative tradeoff parameters. The final labeling cost, however, is determined in a principled way based on the relative importance of accuracy and labeling cost via (17)-(19). The selection of the initial number of labels r is important and should be chosen carefully. In particular it should not exceed the total desirable labeling cost.\nWe provide some experimental results on the performance of this algorithm in Figure 3 (right). It displays\nbox-plots for the differences between tr(\u03a3) and t\u0302r(\u03a3) as a function of the initial labeling cost r for naive Bayes SSL classifier and 20-newsgroups data. The figure illustrates that the two stage algorithm provides a very accurate estimation of tr(\u03a3) for r \u2265 1000 which becomes almost perfect for r \u2265 1300."}], "references": [{"title": "Does unlabeled data provably help? worst-case analysis of the sample complexity of semi-supervised learning", "author": ["S. Ben-David", "T. Lu", "D. Pal"], "venue": "In International Conference on Learning Theory,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "The relative value of labeled and unlabeled samples in pattern recognition with an unknown mixing parameter", "author": ["V. Castelli", "T.M. Cover"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1996}, {"title": "Statistical and computational tradeoffs in stochastic composite likelihood", "author": ["J. Dillon", "G. Lebanon"], "venue": "In Proc. of the 12th International Conference on Aritficial Intelligence and Statistics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "A Course in Large Sample Theory", "author": ["T.S. Ferguson"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1996}, {"title": "An asymptotic analysis of generative, discriminative, and pseudolikelihood estimators", "author": ["P. Liang", "M.I. Jordan"], "venue": "In Proc. of the International Conference on Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Equivalence of linear boltzmann chains and hidden markov models", "author": ["D.J.C. MacKay"], "venue": "Neural Computation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1996}, {"title": "Text classification from labeled and unlabeled documents using EM", "author": ["K. Nigam", "A. McCallum", "S. Thrun", "T. Mitchell"], "venue": "Machine Learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2000}, {"title": "Unlabeled data: Now it helps, now it doesnt", "author": ["A. Singh", "R. Nowak", "X. Zhu"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "The value of labeled and unlabeled examples when the model is imperfect", "author": ["K. Sinha", "M. Belkin"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}], "referenceMentions": [{"referenceID": 2, "context": "Our asymptotic derivations are possible by extending the recently proposed stochastic composite likelihood formalism [5] and showing that generative SSL is a special case of that extension.", "startOffset": 117, "endOffset": 120}, {"referenceID": 4, "context": "As in [7], the delta method transforms our results from parameter asymptotics to prediction risk asymptotics.", "startOffset": 6, "endOffset": 9}, {"referenceID": 1, "context": "Perhaps the first study in this area was done by Castelli and Cover [3] who examined the convergence of the classification error rate as a labeled example is added to an unlabeled dataset drawn from a Gaussian mixture model.", "startOffset": 68, "endOffset": 71}, {"referenceID": 6, "context": "[9] proposed a practical SSL framework based on maximizing the likelihood of the observed data.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Sinha and Belkin [11] examined the effect of using unlabeled samples with imperfect models for mixture models.", "startOffset": 17, "endOffset": 21}, {"referenceID": 7, "context": "[10] analyze discriminative SSL using PAC theory and large deviation bounds.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "\u201d[4] However, many of these assumptions are criticized in [2].", "startOffset": 58, "endOffset": 61}, {"referenceID": 6, "context": "3 Stochastic SSL Estimators Generative SSL [9, 4] estimates a parametric model by maximizing the observed likelihood incorporating L labeled and U unlabeled examples", "startOffset": 43, "endOffset": 49}, {"referenceID": 6, "context": "A classical example is the naive Bayes model in [9] where p\u03b8(X,Y ) = p\u03b8(X |Y )p(Y ), p\u03b8(X |Y = y) = Mult([\u03b8y]1, .", "startOffset": 48, "endOffset": 51}, {"referenceID": 2, "context": "The central idea in the proof is to cast the generative SSL estimation problem as an extension of stochastic composite likelihood [5].", "startOffset": 130, "endOffset": 133}, {"referenceID": 2, "context": "Our proof follows similar lines to the consistency proof of [5] with the exception that it does not assume independence of the indicator functions Z and (1 \u2212 Z) as is assumed there.", "startOffset": 60, "endOffset": 63}, {"referenceID": 3, "context": "chapter 16 of [6], hold on S leading to P {", "startOffset": 14, "endOffset": 17}, {"referenceID": 3, "context": "The notations p \u2192 , denote convergences in probability and in distribution [6] and \u2207f(\u03b8), \u22072f(\u03b8) are the r \u00d7 1 gradient vector and r \u00d7 r matrix of second order derivatives of f(\u03b8).", "startOffset": 75, "endOffset": 78}, {"referenceID": 6, "context": "Figure 1 displays three error measures for the multinomial naive Bayes SSL classifier [9] and the Reuters RCV1 text classification data.", "startOffset": 86, "endOffset": 89}, {"referenceID": 2, "context": ", \u03bbk)) which exposes its similarity to the stochastic composite likelihood function in [5].", "startOffset": 87, "endOffset": 90}, {"referenceID": 5, "context": ", [8]).", "startOffset": 2, "endOffset": 5}], "year": 2013, "abstractText": "Semisupervised learning has emerged as a popular framework for improving modeling accuracy while controlling labeling cost. Based on an extension of stochastic composite likelihood we quantify the asymptotic accuracy of generative semi-supervised learning. In doing so, we complement distribution-free analysis by providing an alternative framework to measure the value associated with different labeling policies and resolve the fundamental question of how much data to label and in what manner. We demonstrate our approach with both simulation studies and real world experiments using naive Bayes for text classification and MRFs and CRFs for structured prediction in NLP.", "creator": "LaTeX with hyperref package"}}}