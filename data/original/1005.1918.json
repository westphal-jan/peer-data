{"id": "1005.1918", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2010", "title": "Prediction with Expert Advice under Discounted Loss", "abstract": "We study prediction with expert advice in the setting where the losses are accumulated with some discounting---the impact of old losses may gradually vanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm for Regression to this case, propose a suitable new variant of exponential weights algorithm, and prove respective loss bounds.", "histories": [["v1", "Tue, 11 May 2010 19:27:35 GMT  (20kb)", "https://arxiv.org/abs/1005.1918v1", "22 pages; draft version"], ["v2", "Fri, 4 Jun 2010 19:13:37 GMT  (24kb)", "http://arxiv.org/abs/1005.1918v2", "26 pages; expanded (2 remarks -&gt; theorems), some misprints corrected"]], "COMMENTS": "22 pages; draft version", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alexey chernov", "fedor zhdanov"], "accepted": false, "id": "1005.1918"}, "pdf": {"name": "1005.1918.pdf", "metadata": {"source": "CRF", "title": "Prediction with Expert Advice under Discounted Loss", "authors": ["Alexey Chernov", "Fedor Zhdanov"], "emails": ["chernov@cs.rhul.ac.uk", "fedor@cs.rhul.ac.uk"], "sections": [{"heading": null, "text": "ar X\niv :1\n00 5.\n19 18\nv2 [\ncs .L\nG ]\n4 J\nWe study prediction with expert advice in the setting where the losses are accumulated with some discounting and the impact of old losses can gradually vanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm for Regression, propose a new variant of exponentially weighted average algorithm, and prove bounds on the cumulative discounted loss."}, {"heading": "1 Introduction", "text": "Prediction with expert advice is a framework for online sequence prediction. Predictions are made step by step. The quality of each prediction (the discrepancy between the prediction and the actual outcome) is evaluated by a real number called loss. The losses are accumulated over time. In the standard framework for prediction with expert advice (see the monograph [2] for a comprehensive review), the losses from all steps are just summed. In this paper, we consider a generalization where older losses can be devalued; in other words, we use discounted cumulative loss.\nPredictions are made by Experts and Learner according to Protocol 1. In\nProtocol 1 Prediction with expert advice under general discounting\nL0 := 0. L\u03b80 := 0, \u03b8 \u2208 \u0398. for t = 1, 2, . . . do Accountant announces \u03b1t\u22121 \u2208 (0, 1]. Experts announce \u03b3\u03b8t \u2208 \u0393, \u03b8 \u2208 \u0398. Learner announces \u03b3t \u2208 \u0393. Reality announces \u03c9t \u2208 \u2126. L\u03b8t := \u03b1t\u22121L\u03b8t\u22121 + \u03bb(\u03b3\u03b8t , \u03c9t), \u03b8 \u2208 \u0398. Lt := \u03b1t\u22121Lt\u22121 + \u03bb(\u03b3t, \u03c9t). end for\nthis protocol, \u2126 is the set of possible outcomes and \u03c91, \u03c92, \u03c93 . . . is the sequence\nto predict; \u0393 is the set of admissible predictions, and \u03bb : \u0393\u00d7 \u2126 \u2192 [0,\u221e] is the loss function. The triple (\u2126,\u0393, \u03bb) specifies the game of prediction. The most common examples are the binary square loss, log loss, and absolute loss games. They have \u2126 = {0, 1} and \u0393 = [0, 1], and their loss functions are \u03bbsq(\u03b3, \u03c9) = (\u03b3\u2212\u03c9)2, \u03bblog(\u03b3, 0) = \u2212 log(1\u2212 \u03b3) and \u03bblog(\u03b3, 1) = \u2212 log \u03b3, \u03bbabs(\u03b3, \u03c9) = |\u03b3\u2212\u03c9|, respectively.\nThe players in the game of prediction are Experts \u03b8 from some pool \u0398, Learner, and also Accountant and Reality. We are interested in (worst-case optimal) strategies for Learner, and thus the game can be regarded as a twoplayer game, where Learner opposes the other players. The aim of Learner is to keep his total loss Lt small as compared to the total losses L\u03b8t of all experts \u03b8 \u2208 \u0398.\nThe standard protocol of prediction with expert advice (as described in [19, 20]) is a special case of Protocol 1 where Accountant always announces \u03b1t = 1, t = 0, 1, 2, . . .. The new setting gives some more freedom to Learner\u2019s opponents.\nAnother important special case is the exponential (geometric) discounting \u03b1t = \u03b1 \u2208 (0, 1). Exponential discounting is widely used in finance and economics (see, e. g., [16]), time series analysis (see, e. g., [8]), reinforcement learning [18], and other applications. In the context of prediction with expert advice, Freund and Hsu [6] noted that the discounted loss provides an alternative to \u201ctracking the best expert\u201d framework [11]. Indeed, an exponentially discounted sum depends almost exclusively on the last O(log(1/\u03b1)) terms. If the expert with the best one-step performance changes at this rate, then Learner observing the \u03b1-discounted losses will mostly follow predictions of the current best expert. Under our more general discounting, more subtle properties of best expert changes may be specified by varying the discount factor. In particular, one can cause Learner to \u201crestart mildly\u201d giving \u03b1t = 1 (or \u03b1t \u2248 1) most of the time and \u03b1t \u226a 1 at crucial moments. (We prohibit \u03b1t = 0 in the protocol, since this is exactly the same as the stopping the current game and starting a new, independent game; on the other hand, the assumption \u03b1t 6= 0 simplifies some statements.)\nCesa-Bianchi and Lugosi [2, \u00a7 2.11] discuss another kind of discounting\nLT =\nT \u2211\nt=1\n\u03b2T\u2212tlt , (1)\nwhere lt are one-step losses and \u03b2t are some decreasing discount factors. To see the difference, let us rewrite our definition in the same style:\nLT = \u03b1T\u22121LT\u22121 + lT = \u03b1T\u22122\u03b1T\u22121LT\u22122 + \u03b1T\u22121lT\u22121 + lT = . . .\n=\nT \u2211\nt=1\n\u03b1t \u00b7 \u00b7 \u00b7\u03b1T\u22121lt = 1\n\u03b2T\nT \u2211\nt=1\n\u03b2tlt , (2)\nwhere \u03b2t = 1/\u03b11 \u00b7 \u00b7 \u00b7\u03b1t\u22121, \u03b21 = 1. The sequence \u03b2t is non-decreasing, \u03b21 \u2264 \u03b22 \u2264 \u03b23 \u2264 . . .; but it is applied \u201cin the reverse order\u201d compared to (1). So, in both definitions, the older losses are the less weight they are ascribed. However, according to (1), the losses lt have different relative weights in LT , LT+1 and so on, whereas (2) fixes the relative weight of lt with respect to all previous losses forever starting from the moment t. The latter property allows us to get uniform\nalgorithms for Learner with loss guarantees that hold for all T = 1, 2, . . .; in contrast, Theorem 2.8 in [2] gives a guarantee only at one moment T chosen in advance. The only kind of discounting that can be expressed both as (1) and as (2) is the exponential discounting \u2211T\nt=1 \u03b1 T\u2212tlt. Under this discounting,\nNormalHedge algorithm is analysed in [6]; we briefly compare the obtained bounds in Section 3.\nLet us say a few words about \u201ceconomical\u201d interpretation of discounting. Recall that \u03b1t \u2264 1 in Protocol 1, in other words, the previous cumulative loss cannot become more important at later steps. If the losses are interpreted as the lost money, it is more natural to assume that the old losses must be multiplied by something greater than 1. Indeed, the money could have been invested and have brought some interest, so the current value of an ancient small loss can be considerably large. Nevertheless, there is a not so artificial interpretation for our discounting model as well. Assume that the loss at each step is expressed as a quantity of some goods, and we pay for them in cash; say, we pay for apples damaged because of our incorrect weather prediction. The price of apples can increase but never decreases. Then \u03b2t in (2) is the current price, \u2211T t=1 \u03b2tlt is the total sum of money we lost, and LT is the quantity of apples that we could have bought now if we had not lost so much money. (We must also assume that we cannot hedge our risk by buying a lot of cheap apples in advance\u2014the apples will rot\u2014and that the bank interest is zero.)\nWe need the condition \u03b1t \u2264 1 for our algorithms and loss bounds. However, the case of \u03b1t \u2265 1 is no less interesting. We cannot say anything about it and leave it as an open problem, as well as the general case of arbitrary positive \u03b1t.\nThe rest of the paper is organized as follows. In Section 2, we propose a generalization of the Aggregating Algorithm [20] and prove the same bound as in [20] but for the discounted loss. In Section 3, we consider convex loss functions and propose an algorithm similar to the Weak Aggregating Algotihm [14] and the exponentially weighted average forecaster with time-varying learning rate [2, \u00a7 2.3], with a similar loss bound. In Section 4, we consider the use of prediction with expert advice for the regression problem and adapt the Aggregating Algorithm for Regression [22] (applied to spaces of linear functions and to reproducing kernel Hilbert spaces) to the discounted square loss. All our algorithms are inspired by the methodology of defensive forecasting [4]. We do not explicitly use or refer to this technique in the main text. However, to illustrate these ideas we provide an alternative treatment of the regression task with the help of defensive forecasting in Appendix A.2."}, {"heading": "2 Linear Bounds for Learner\u2019s Loss", "text": "In this section, we assume that the set of experts is finite, \u0398 = {1, . . . ,K}, and show how Learner can achieve a bound of the form Lt \u2264 cLkt + (c lnK)/\u03b7 for all Experts k, where c \u2265 1 and \u03b7 > 0 are constants. Bounds of this kind were obtained in [19]. Loosely speaking, such a bound holds for certain c and \u03b7 if and only if the game (\u2126,\u0393, \u03bb) has the following property:\n\u2203\u03b3 \u2208 \u0393 \u2200\u03c9 \u2208 \u2126 \u03bb(\u03b3, \u03c9) \u2264 \u2212 c \u03b7 ln\n(\n\u2211\ni\u2208I\npie \u2212\u03b7\u03bb(\u03b3i,\u03c9)\n)\n(3)\nfor any finite index set I, for any \u03b3i \u2208 \u0393, i \u2208 I, and for any pi \u2208 [0, 1] such that \u2211\ni\u2208I pi = 1. It turns out that this property is sufficient for the discounted case as well.\nTheorem 1. Suppose that the game (\u2126,\u0393, \u03bb) satisfies condition (3) for certain c \u2265 1 and \u03b7 > 0. In the game played according to Protocol 1, Learner has a strategy guaranteeing that, for any T and for any k \u2208 {1, . . . ,K}, it holds\nLT \u2264 cLkT + c lnK\n\u03b7 . (4)\nWe formulate the strategy for Learner in Subsection 2.1 and prove the theorem in Subsection 2.2.\nFor the standard undiscounted case (Accountant announces \u03b1t = 1 at each step t), this theorem was proved by Vovk in [19] with the help of the Aggregating Algorithm (AA) as Learner\u2019s strategy. It is known ([10, 20]) that this bound is asymptotically optimal for large pools of Experts (for games satisfying some assumptions): if the game does not satisfy (3) for some c \u2265 1 and \u03b7 > 0, then, for sufficiently large K, there is a strategy for Experts and Reality (recall that Accountant always says \u03b1t = 1) such that Learner cannot secure (4). For the special case of c = 1, bound (4) is tight for any fixedK as well [21]. These results imply optimality of Theorem 1 in the new setting with general discounting (when we allow arbitrary behaviour of Accountant with the only requirement \u03b1t \u2208 (0, 1]). However, they leave open the question of lower bounds under different discounting assumptions (that is, when Accountant moves are fixed); a particularly interesting case is the exponential discounting \u03b1t = \u03b1 \u2208 (0, 1)."}, {"heading": "2.1 Learner\u2019s Strategy", "text": "To prove Theorem 1, we will exploit the AA with a minor modification.\nAlgorithm 1 The Aggregating Algorithm\n1: Initialize weights of Experts wk0 := 1/K, k = 1, . . . ,K. 2: for t = 1, 2, . . . do 3: Get Experts\u2019 predictions \u03b3kt \u2208 \u0393, k = 1, . . . ,K. 4: Calculate gt(\u03c9) = \u2212 c\u03b7 ln ( \u2211K k=1 w k t\u22121e \u2212\u03b7\u03bb(\u03b3kt ,\u03c9) )\n, for all \u03c9 \u2208 \u2126. 5: Output \u03b3t := \u03c3(gt) \u2208 \u0393. 6: Get \u03c9t \u2208 \u2126. 7: Update the weights w\u0303kt := w k t\u22121e \u2212\u03b7\u03bb(\u03b3kt ,\u03c9t), k = 1, . . . ,K, 8: and normalize them wkt := w\u0303 k t / \u2211K k=1 w\u0303 k t , k = 1, . . . ,K. 9: end for.\nThe pseudocode of the AA is given as Algorithm 1. The algorithm has three parameters, which depend on the game (\u2126,\u0393, \u03bb): c \u2265 1, \u03b7 > 0, and a function \u03c3 : R\u2126 \u2192 \u0393. The function \u03c3 is called a substitution function and must have the following property: \u03bb(\u03c3(g), \u03c9) \u2264 g(\u03c9) for all \u03c9 \u2208 \u2126 if for g \u2208 R\u2126 there exists any \u03b3 \u2208 \u0393 such that \u03bb(\u03b3, \u03c9) \u2264 g(\u03c9) for all \u03c9 \u2208 \u2126. A natural example of substitution function is given by\n\u03c3(g) = argmin \u03b3\u2208\u0393\n( \u03bb(\u03b3, \u03c9)\u2212 g(\u03c9) )\n(5)\n(if the minimum is attained at several points, one can take any of them). An advantage of this \u03c3 is that the normalization step in line 8 is not necessary and one can take wkt = w\u0303 k t . Indeed, multiplying all w k t by a constant (independent of k) we add to all gt(\u03c9) a constant (independent of \u03c9), and \u03c3(gt) does not change.\nThe Aggregating Algorithm with Discounting (AAD) differs only by the use of the weights in the computation of gt and the update of the weights.\nThe pseudocode of the AAD is given as Algorithm 2.\nAlgorithm 2 The Aggregating Algorithm with Discounting\n1: Initialize weights of Experts wk0 := 1, k = 1, . . . ,K. 2: for t = 1, 2, . . . do 3: Get discount \u03b1t\u22121 \u2208 (0, 1]. 4: Get Experts\u2019 predictions \u03b3kt \u2208 \u0393, k = 1, . . . ,K. 5: Calculate gt(\u03c9) = \u2212 c\u03b7 ( ln \u2211K k=1 1 K (w k t\u22121) \u03b1t\u22121e\u2212\u03b7\u03bb(\u03b3 k t ,\u03c9) )\n, for all \u03c9 \u2208 \u2126. 6: Output \u03b3t := \u03c3(gt) \u2208 \u0393. 7: Get \u03c9t \u2208 \u2126. 8: Update the weights wkt := (w k t\u22121) \u03b1t\u22121e\u03b7\u03bb(\u03b3t,\u03c9t)/c\u2212\u03b7\u03bb(\u03b3 k t ,\u03c9t), k = 1, . . . ,K, 9: end for.\nFor a substitution function satisfying (5), one can use in line 8 the update\nrule wkt := (w k t\u22121) \u03b1t\u22121e\u2212\u03b7\u03bb(\u03b3 k t ,\u03c9t), which does not contain Learner\u2019s losses, in the same manner as the normalization in Algorithm 1 can be omitted."}, {"heading": "2.2 Proof of the Bound", "text": "Assume that c and \u03b7 are such that condition (3) holds for the game. Let us show that Algorithm 2 preserves the following condition:\nK \u2211\nk=1\n1\nK wkt \u2264 1 . (6)\nCondition (6) trivially holds for t = 0. Assume that (6) holds for t\u2212 1, that is, \u2211K\nk=1 w k t\u22121/K \u2264 1. Thus, we have\nK \u2211\nk=1\n1\nK (wkt\u22121)\n\u03b1t\u22121 \u2264 ( K \u2211\nk=1\n1\nK wkt\u22121\n)\u03b1t\u22121\n\u2264 1 ,\nsince the function x 7\u2192 x\u03b1 is concave for \u03b1 \u2208 (0, 1], x \u2265 0, and since x \u2264 1 implies x\u03b1 \u2264 1 for \u03b1 \u2265 0 and x \u2265 0.\nLet w\u0303k be any reals such that w\u0303k \u2265 (wkt\u22121)\u03b1t\u22121/K and \u2211K k=1 w\u0303 k = 1. Due\nto condition (3) there exists \u03b3 \u2208 \u0393 such that for all \u03c9 \u2208 \u2126\n\u03bb(\u03b3, \u03c9) \u2264 \u2212 c \u03b7 ln\n(\nK \u2211\nk=1\nw\u0303ke\u2212\u03b7\u03bb(\u03b3 k t ,\u03c9)\n)\n\u2264 \u2212 c \u03b7 ln\n(\nK \u2211\nk=1\n1\nK (wkt\u22121) \u03b1t\u22121e\u2212\u03b7\u03bb(\u03b3 k t ,\u03c9)\n)\n= gt(\u03c9)\n(the second inequality holds due to our choice of w\u0303k). Thus, due to the property of \u03c3, we have \u03bb(\u03b3t, \u03c9) \u2264 gt(\u03c9) for all \u03c9 \u2208 \u2126. In particular, this holds for \u03c9 = \u03c9t, and we get\n\u03bb(\u03b3t, \u03c9t) \u2264 \u2212 c\n\u03b7 ln\n(\nK \u2211\nk=1\n1\nK (wkt\u22121) \u03b1t\u22121e\u2212\u03b7\u03bb(\u03b3 k t ,\u03c9t)\n)\n,\nwhich is equivalent to (6). To get the loss bound (4), it remains to note that\nlnwkt = \u03b7 ( Lt/c\u2212 Lkt ) .\nIndeed, for t = 0, this is trivial. If this holds for wkt\u22121, then\nlnwkt = \u03b1t\u22121 ln(w k t\u22121) + \u03b7\u03bb(\u03b3t, \u03c9t)/c\u2212 \u03b7\u03bb(\u03b3kt , \u03c9t)\n= \u03b1t\u22121\u03b7 ( Lt\u22121/c\u2212 Lkt\u22121 ) + \u03b7\u03bb(\u03b3t, \u03c9t)/c\u2212 \u03b7\u03bb(\u03b3kt , \u03c9t) = \u03b7 (\n(\u03b1t\u22121Lt\u22121 + \u03bb(\u03b3t, \u03c9t))/c\u2212 (\u03b1t\u22121Lkt\u22121 + \u03bb(\u03b3kt , \u03c9t)) ) = \u03b7 ( Lt/c\u2212 Lkt )\nand we get the equality for wkt . Thus, condition (6) means that\nK \u2211\nk=1\n1\nK e\u03b7(Lt/c\u2212L k t ) \u2264 1 , (7)\nand (4) follows by lower-bounding the sum by any of its terms.\nRemark. Everything in this section remains valid, if we replace the equal initial Experts\u2019 weights 1/K by arbitrary non-negative weights wk,\n\u2211K k=1 w k = 1. This leads to a variant of (4), where the last additive term is replaced by c\u03b7 ln 1 wk\n. Additionally, we can consider any measurable space \u0398 of Experts and a nonnegative weight function w(\u03b8), and replace sums over K by integrals over \u0398. Then the algorithm and its analysis remain valid (if we impose natural integrability conditions on Experts\u2019 predictions \u03b3\u03b8t ; see [22] for more detailed discussion)\u2014this will be used in Section 4."}, {"heading": "3 Learner\u2019s Loss in Bounded Convex Games", "text": "The linear bounds of the form (4) are perfect when c = 1. However, for many games (for example, the absolute loss game), condition (3) does not hold for c = 1 (with any \u03b7 > 0), and one cannot get a bound of the form Lt \u2264 Lkt +O(1). Since Experts\u2019 losses L\u03b8T may grow as T in the worst case, any bound with c > 1 only guarantees that Learner\u2019s loss may exceed an Expert\u2019s loss by at mostO(T ). However, for a large class of interesting games (including the absolute loss game), one can obtain guarantees of the form LT \u2264 LkT + O( \u221a T ) in the undiscounted case. In this section, we prove an analogous result for the discounted setting. A game (\u2126,\u0393, \u03bb) is non-empty if \u2126 and \u0393 are non-empty. The game is called bounded if L = max\u03c9,\u03b3 \u03bb(\u03b3, \u03c9) < \u221e. One may assume that L = 1 (if not, consider the scaled loss function \u03bb/L). The game is called convex if\nfor any predictions \u03b31, . . . , \u03b3M \u2208 \u0393 and for any weights p1, . . . , pM \u2208 [0, 1], \u2211M\nm=1 pm = 1,\n\u2203\u03b3 \u2208 \u0393 \u2200\u03c9 \u2208 \u2126 \u03bb(\u03b3, \u03c9) \u2264 M \u2211\nm=1\npm\u03bb(\u03b3m, \u03c9) . (8)\nNote that if \u0393 is a convex set (e. g., \u0393 = [0, 1]) and \u03bb(\u03b3, \u03c9) is convex in \u03b3 (e. g.,\u03bbabs), then the game is convex.\nTheorem 2. Suppose that (\u2126,\u0393, \u03bb) is a non-empty convex game, and \u03bb(\u03b3, \u03c9) \u2208 [0, 1] for all \u03b3 \u2208 \u0393 and \u03c9 \u2208 \u2126. In the game played according to Protocol 1, Learner has a strategy guaranteeing that, for any T and for any k \u2208 {1, . . . ,K}, it holds\nLT \u2264 LkT + \u221a lnK\n\u221a\nBT \u03b2T , (9)\nwhere \u03b2t = 1/(\u03b11 \u00b7 \u00b7 \u00b7\u03b1t\u22121) and BT = \u2211T t=1 \u03b2t.\nNote that BT /\u03b2T is the maximal predictors\u2019 loss, which incurs when the predictor suffers the maximal possible loss lt = 1 at each step.\nIn the undiscounted case, \u03b1t = 1, thus \u03b2t = 1, BT = T , and (9) becomes\nLT \u2264 LkT + \u221a T lnK .\nA similar bound (but with worse constant \u221a 2 instead of 1 before \u221a T lnK) is obtained in [2, Theorem 2.3]:\nLT \u2264 LkT + \u221a 2T lnK + \u221a lnK\n8 .\nFor the exponential discounting \u03b1t = \u03b1, we have \u03b2t = \u03b1 \u2212t+1 and BT =\n(1\u2212 \u03b1\u2212T )/(1\u2212 1/\u03b1), and (9) transforms into\nLT \u2264 LkT + \u221a lnK\n\u221a\n1\u2212 \u03b1T 1\u2212 \u03b1 \u2264 L k T +\n\u221a\nlnK\n1\u2212 \u03b1 .\nA similar bound (with worse constants) is obtained in [6] for NormalHedge:\nLT \u2264 LkT + \u221a 8 ln 2.32K\n1\u2212 \u03b1 .\nThe NormalHedge algorithm has an important advantage: it can guarantee the last bound without knowledge of the number of experts K (see [3] for a precise definition). We can achieve the same with the help of a more complicated algorithm but at the price of a worse bound (Theorem 3)."}, {"heading": "3.1 Learner\u2019s Strategy for Theorem 2", "text": "The pseudocode of Learner\u2019s strategy is given as Algorithm 3. It contains a constant a > 0, which we will choose later in the proof.\nThe algorithm is not fully specified, since lines 6\u20137 of Algorithm 3 allow arbitrary choice of \u03b3 satisfying the inequality. The algorithm can be completed\nwith the help of a substitution function \u03c3 as in Algorithm 2, so that lines 6\u20138 are replaced by\ngt(\u03c9) = \u2212 1\n\u03b7t ln\n(\nK \u2211\nk=1\n1\nK\n( wkt\u22121 )\u03b1t\u22121\u03b7t/\u03b7t\u22121 e\u2212\u03b7t\u03bb(\u03b3 k t ,\u03c9)\u2212\u03b7 2 t /8\n)\nand \u03b3t = \u03c3(gt). However, the current form of Algorithm 3 emphasizes the similarity to the Algorithm 5, which is described later (Subsection 3.3) but actually inspired our analysis.\nAlgorithm 3 Learner\u2019s Strategy for Convex Games\n1: Initialize weights of Experts wk0 := 1, k = 1, . . . ,K. Set \u03b21 = 1, B0 = 0. 2: for t = 1, 2, . . . do 3: Get discount \u03b1t\u22121 \u2208 (0, 1]; update \u03b2t = \u03b2t\u22121/\u03b1t\u22121, Bt = Bt\u22121 + \u03b2t. 4: Compute \u03b7t = a \u221a\n\u03b2t/Bt. 5: Get Experts\u2019 predictions \u03b3kt \u2208 \u0393, k = 1, . . . ,K. 6: Find \u03b3 \u2208 \u0393 s.t. for all \u03c9 \u2208 \u2126 7: \u03bb(\u03b3, \u03c9) \u2264 \u2212 1\u03b7t ln ( \u2211K k=1 1 K ( wkt\u22121 )\u03b1t\u22121\u03b7t/\u03b7t\u22121 e\u2212\u03b7t\u03bb(\u03b3 k t ,\u03c9)\u2212\u03b7 2 t /8 ) 8: Output \u03b3t := \u03b3. 9: Get \u03c9t \u2208 \u2126.\n10: Update the weights wkt := ( wkt\u22121 )\u03b1t\u22121\u03b7t/\u03b7t\u22121\ne\u03b7t ( \u03bb(\u03b3t,\u03c9t)\u2212\u03bb(\u03b3 k t ,\u03c9t) )\n\u2212\u03b72t /8, 11: k = 1, . . . ,K, 12: end for.\nLet us explain the relation of Algorithm 3 to the Weak Aggregating Algorithm [14] and the exponentially weighted average forecaster with time-varying learning rate [2, \u00a7 2.3]. To this end, consider Algorithm 4.\nAlgorithm 4 Weak Aggregating Algorithm with Discounting\n1: Initialize Experts\u2019 cumulative losses Lk0 := 0, k = 1, . . . ,K. Set \u03b21 = 1, B0 = 0. 2: for t = 1, 2, . . . do 3: Get discount \u03b1t\u22121 \u2208 (0, 1]; update \u03b2t = \u03b2t\u22121/\u03b1t\u22121, Bt = Bt\u22121 + \u03b2t. 4: Compute \u03b7t = a \u221a \u03b2t/Bt. 5: Compute the weights qkt = e \u2212\u03b1t\u22121\u03b7tL k t\u22121 , k = 1, . . . ,K. 6: Compute the normalized weights w\u0303kt = q k t / \u2211K j=1 q j t . 7: Get Experts\u2019 predictions \u03b3kt \u2208 \u0393, k = 1, . . . ,K. 8: Find \u03b3 \u2208 \u0393 s.t. for all \u03c9 \u2208 \u2126 \u03bb(\u03b3, \u03c9) \u2264 \u2211Kk=1 w\u0303kt \u03bb(\u03b3kt , \u03c9). 9: Output \u03b3t := \u03b3.\n10: Get \u03c9t \u2208 \u2126. 11: Update Lkt := \u03b1t\u22121Lkt\u22121 + \u03bb(\u03b3kt , \u03c9t), k = 1, . . . ,K. 12: end for.\nThe proof of Theorem 2 implies that Algorithm 4 is a special case of Al-\ngorithm 3. Indeed, (15) implies that wkt\u22121 = e \u2212\u03b7t\u22121L k t\u22121+C , where C does not depend on k and wkt\u22121 are the weights from Algorithm 3. Therefore q k t =\nC\u2032(wkt\u22121) \u03b1t\u22121\u03b7t/\u03b7t\u22121 , where C\u2032 does not depend on k, and one can take w\u0303kt for w\u0303k in the proof of Theorem 2. Thus, if Algorithm 4 output some \u03b3t then Algorithm 3 can output this \u03b3t as well.\nRecall that if \u03b1t = 1 for all t (the undiscounted case), \u03b2t = 1 and Bt = t, hence \u03b7t = a/ \u221a t. In this case, Algorithm 4 is just the Weak Aggregating Algorithm as described in [14]. Consider now the case when \u0393 is a convex set and \u03bb(\u03b3, \u03c9) is convex in \u03b3. Then one can take \u03b3t = \u2211K k=1 w\u0303 k t \u03b3 k t in Algorithm 4. For \u03b1t = 1, we get exactly the exponentially weighted average forecaster with time-varying learning rate [2, \u00a7 2.3]."}, {"heading": "3.2 Proof of Theorem 2", "text": "Similarly to the case of the AAD, let us show that Algorithm 3 always can find \u03b3 in lines 6\u20137 and preserves the following condition:\nK \u2211\nk=1\n1\nK wkt \u2264 1 . (10)\nFirst check that \u03b1t\u22121\u03b7t/\u03b7t\u22121 \u2264 1. Indeed, \u03b1t\u22121 = \u03b2t\u22121/\u03b2t, and thus\n\u03b1t\u22121 \u03b7t\n\u03b7t\u22121 = \u03b2t\u22121 \u03b2t\na \u221a\n\u03b2t/Bt\na \u221a \u03b2t\u22121/Bt\u22121 =\n\u221a\n\u03b2t\u22121 \u03b2t Bt\u22121 Bt = \u221a \u03b1t\u22121\n\u221a\nBt\u22121 Bt\u22121 + \u03b2t \u2264 1 .\n(11) Condition (10) trivially holds for t = 0. Assume that (10) holds for t \u2212 1,\nthat is, \u2211K k=1 w k t\u22121/K \u2264 1. Thus, we have\nK \u2211\nk=1\n1\nK (wkt\u22121)\n\u03b1t\u22121\u03b7t/\u03b7t\u22121 \u2264 ( K \u2211\nk=1\n1\nK wkt\u22121\n)\u03b1t\u22121\u03b7t/\u03b7t\u22121\n\u2264 1 , (12)\nsince the function x 7\u2192 x\u03b1 is concave for \u03b1 \u2208 (0, 1], x \u2265 0, and since x \u2264 1 implies x\u03b1 \u2264 1 for \u03b1 \u2265 0 and x \u2265 0.\nLet w\u0303k be any reals such that w\u0303k \u2265 (wkt\u22121)\u03b1t\u22121\u03b7t/\u03b7t\u22121/K and \u2211K k=1 w\u0303 k = 1.\n(For example, w\u0303k = (wkt\u22121) \u03b1t\u22121\u03b7t/\u03b7t\u22121\n/\n\u2211K j=1(w j t\u22121) \u03b1t\u22121\u03b7t/\u03b7t\u22121 .) By the Ho-\neffding inequality (see, e. g., [2, Lemma 2.2]), we have\nln K \u2211\nk=1\nw\u0303ke\u2212\u03b7t\u03bb(\u03b3 k t ,\u03c9) \u2264 \u2212\u03b7t\nK \u2211\nk=1\nw\u0303k\u03bb(\u03b3kt , \u03c9) + \u03b72t 8 , (13)\nsince \u03bb(\u03b3, \u03c9) \u2208 [0, 1] for any \u03b3 \u2208 \u0393 and \u03c9 \u2208 \u2126. Since the game is convex, there exists \u03b3 \u2208 \u0393 such that \u03bb(\u03b3, \u03c9) \u2264 \u2211Kk=1 w\u0303k\u03bb(\u03b3kt , \u03c9) for all \u03c9 \u2208 \u2126. For this \u03b3 and for all \u03c9 \u2208 \u2126 we have\n\u03bb(\u03b3, \u03c9) \u2264 K \u2211\nk=1\nw\u0303k\u03bb(\u03b3kt , \u03c9) \u2264 \u2212 1\n\u03b7t ln\n(\nK \u2211\nk=1\nw\u0303ke\u2212\u03b7\u03bb(\u03b3 k t ,\u03c9)\u2212\u03b7 2 t /8\n)\n\u2264 \u2212 1 \u03b7t ln\n(\n\u2211 1\nK\n( wkt\u22121 )\u03b1t\u22121\u03b7t/\u03b7t\u22121 e\u2212\u03b7t\u03bb(\u03b3 k t ,\u03c9)\u2212\u03b7 2 t /8\n)\n(14)\n(the second inequality follows from (13), and the third inequality holds due to our choice of w\u0303k). Thus, one can always find \u03b3 in lines 6\u20137 of Algorithm 3. It remains to note that the inequality in line 7 with \u03b3t substituted for \u03b3 and \u03c9t substituted for \u03c9 is equivalent to\n1 \u2265 \u2211 1\nK\n( wkt\u22121 )\u03b1t\u22121\u03b7t/\u03b7t\u22121 e\u03b7t\u03bb(\u03b3t,\u03c9t)\u2212\u03b7t\u03bb(\u03b3 k t ,\u03c9t)\u2212\u03b7 2 t /8 =\n\u2211 1\nK wkt .\nNow let us check that\nlnwkt = \u03b7t ( Lt \u2212 Lkt ) \u2212 \u03b7t 8\u03b2t\nt \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4 . (15)\nIndeed, for t = 0, this is trivial. Assume that it holds for wkt\u22121. Then, taking the logarithm of the update expression in line 10 of Algorithm 3 and substituting lnwkt\u22121, we get\nlnwkt = \u03b1t\u22121\u03b7t \u03b7t\u22121 lnwkt\u22121 + \u03b7t ( \u03bb(\u03b3t, \u03c9t)\u2212 \u03bb(\u03b3kt , \u03c9t) ) \u2212 \u03b7 2 t 8\n= \u03b1t\u22121\u03b7t \u03b7t\u22121\n(\n\u03b7t\u22121 ( Lt\u22121 \u2212 Lkt\u22121 ) \u2212 \u03b7t\u22121 8\u03b2t\u22121\nt\u22121 \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4\n)\n+\u03b7t ( \u03bb(\u03b3t, \u03c9t)\u2212\u03bb(\u03b3kt , \u03c9t) )\n\u2212\u03b7 2 t\n8\n= \u03b7t ( \u03b1t\u22121Lt\u22121 + \u03bb(\u03b3t, \u03c9t)\u2212 \u03b1t\u22121Lkt\u22121 \u2212 \u03bb(\u03b3kt , \u03c9t) ) \u2212 \u03b7t 8\u03b2t\nt\u22121 \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4 \u2212 \u03b72t 8\n= \u03b7t ( Lt \u2212 Lkt ) \u2212 \u03b7t 8\u03b2t\nt \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4 .\nCondition (10) implies that wkT \u2264 K for all k and T , hence we get a loss bound\nLT \u2264 LkT + lnK\n\u03b7T +\n1\n8\u03b2T\nT \u2211\nt=1\n\u03b2t\u03b7t . (16)\nRecall that \u03b7t = a \u221a \u03b2t/Bt. To estimate \u2211T\nt=1 \u03b2t\u03b7t, we use the following inequality (see Appendix A.1 for the proof).\nLemma 1. Let \u03b2t be any reals such that 1 \u2264 \u03b21 \u2264 \u03b22 \u2264 . . .. Let BT = \u2211T\nt=1 \u03b2t. Then, for any T , it holds\n1\n\u03b2T\nT \u2211\nt=1\n\u03b2t\n\u221a\n\u03b2t Bt\n\u2264 2 \u221a\nBT \u03b2T .\nThen (16) implies\nLT \u2264 LkT + lnK\na\n\u221a\nBT \u03b2T + 2a 8\n\u221a\nBT \u03b2T = LkT + ( lnK a + a 4 )\n\u221a\nBT \u03b2T .\nChoosing a = 2 \u221a lnK, we finally get\nLT \u2264 LkT + \u221a lnK\n\u221a\nBT \u03b2T ."}, {"heading": "3.3 A Bound with respect to \u01eb-Best Expert", "text": "Algorithm 3 originates in the \u201cFake Defensive Forecasting\u201d (FDF) algorithm from [5, Theorem 9]. That algorithm is based on the ideas of defensive forecasting [4], in particular, Hoeffding supermartingales [24], combined with the ideas from an early version of the Weak Aggregating Algorithm [13]. However, our analysis in Theorem 2 is completely different from [5], following the lines of [2, Theorem 2.2] and [13].\nIn this subsection, we consider a direct extension of the FDF algorithm from [5, Theorem 9] to the discounted case. Algorithm 5 becomes the FDF algorithm when \u03b1t = 1.\nAlgorithm 5 Fake Defensive Forecasting Algorithm with Discounting\n1: Initialize cumulative losses L0 = 0, Lk0 := 0, k = 1, . . . ,K. Set \u03b21 = 1, B0 = 0. 2: for t = 1, 2, . . . do 3: Get discount \u03b1t\u22121 \u2208 (0, 1]; update \u03b2t = \u03b2t\u22121/\u03b1t\u22121, Bt = Bt\u22121 + \u03b2t. 4: Compute \u03b7t = \u221a\n\u03b2t/Bt. 5: Get Experts\u2019 predictions \u03b3kt \u2208 \u0393, k = 1, . . . ,K. 6: Find \u03b3 \u2208 \u0393 s.t. for all \u03c9 \u2208 \u2126 ft(\u03b3, \u03c9) \u2264 Ct, where ft and Ct are defined by (17) and (18), respectively. 7: Output \u03b3t := \u03b3. 8: Get \u03c9t \u2208 \u2126. 9: Update Lt := \u03b1t\u22121Lt\u22121 + \u03bb(\u03b3t, \u03c9t).\n10: Update Lkt := \u03b1t\u22121Lkt\u22121 + \u03bb(\u03b3kt , \u03c9t), k = 1, . . . ,K. 11: end for.\nAlgorithm 5 in line 6 uses the function\nft(\u03b3, \u03c9) = K \u2211\nk=1\n1\nK\n\u221e \u2211\nj=1\nc\nj2 exp\n(\nj\u03b1t\u22121\u03b7t(Lt\u22121 \u2212 Lkt\u22121)\u2212 j2\u03b7t 2\u03b2t\nt\u22121 \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4\n)\n\u00d7 exp ( j\u03b7t(\u03bb(\u03b3, \u03c9)\u2212 \u03bb(\u03b3kt , \u03c9))\u2212 j2\u03b72t 2 ) (17)\nand the constant\nCt =\nK \u2211\nk=1\n1\nK\n\u221e \u2211\nj=1\nc\nj2 exp\n(\nj\u03b1t\u22121\u03b7t(Lt\u22121 \u2212 Lkt\u22121)\u2212 j2\u03b7t 2\u03b2t\nt\u22121 \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4\n)\n, (18)\nwhere 1/c = \u2211\u221e j=1 1 j2 .\nAlgorithm 5 is more complicated than Algorithm 3, and the loss bound we get is weaker and holds for a narrower class of games. However, this bound can be stated as a bound for \u01eb-quantile regret introduced in [3]. Namely, let L\u01ebt be any value such that for at least \u01ebK Experts their loss Lkt after step t is not greater than L\u01ebt . The \u01eb-quantile regret is the difference between Lt and L\u01ebt . For \u01eb = 1/K, we can choose L\u01ebt = mink Lkt \u2264 Lkt for all k = 1, . . . ,K, and thus a bound in terms of the \u01eb-quantile regret implies a bound in terms of Lkt . The value 1/\u01eb plays the role of the \u201ceffective\u201d number of experts. Algorithm 5 guarantees a bound in terms of L\u01ebt for any \u01eb > 0, without the prior knowledge\nof \u01eb, and in this sense the algorithm works for the unknown number of Experts (see [5] for a more detailed discussion).\nFor Algorithm 5 we need to restrict the class of games we consider. The game is called compact if the set \u039b = {\u03bb(\u03b3, \u00b7) \u2208 R\u2126 | \u03b3 \u2208 \u0393} is compact in the standard topology of R\u2126.\nTheorem 3. Suppose that (\u2126,\u0393, \u03bb) is a non-empty convex compact game, \u2126 is finite, and \u03bb(\u03b3, \u03c9) \u2208 [0, 1] for all \u03b3 \u2208 \u0393 and \u03c9 \u2208 \u2126. In the game played according to Protocol 1, Learner has a strategy guaranteeing that, for any T and for any \u01eb > 0, it holds\nLT \u2264 L\u01ebT + 2 \u221a\nBT \u03b2T ln 1 \u01eb + 7\n\u221a\nBT \u03b2T , (19)\nwhere \u03b2t = 1/(\u03b11 \u00b7 \u00b7 \u00b7\u03b1t\u22121) and BT = \u2211T t=1 \u03b2t.\nProof. The most difficult part of the proof is to show that one can find \u03b3 in line 6 of Algorithm 5. We do not do this here, but refer to [5]; the proof is literally the same as in [5, Theorem 9] and is based on the supermartingale property of ft. (The rest of the proof below also follows [5, Theorem 9]; the only difference is in the definition of ft and Ct.)\nLet us check that Ct \u2264 1 for all t. Clearly, C1 = 1. Assume that we have Ct \u2264 1. This implies ft(\u03b3t, \u03c9t) \u2264 1 due to the choice of \u03b3t, and thus (ft(\u03b3t, \u03c9t))\n\u03b1t\u03b7t+1/\u03b7t \u2264 1. Similarly to (11), we have \u03b1t\u03b7t+1/\u03b7t \u2264 1. Since the function x 7\u2192 x\u03b1 is concave for \u03b1 \u2208 (0, 1], x \u2265 0, we get\n1 \u2265 ( ft(\u03b3t, \u03c9t) )\u03b1t\u03b7t+1/\u03b7t\n=\n\n\nK \u2211\nk=1\n1\nK\n\u221e \u2211\nj=1\nc\nj2 exp\n(\nj\u03b7t(Lt \u2212 Lkt )\u2212 j2\u03b7t 2\u03b2t\nt \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4\n)\n\n\n\u03b1t\u03b7t+1/\u03b7t\n\u2265 K \u2211\nk=1\n1\nK\n\u221e \u2211\nj=1\nc\nj2\n(\nexp\n(\nj\u03b7t(Lt \u2212 Lkt )\u2212 j2\u03b7t 2\u03b2t\nt \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4\n))\u03b1t\u03b7t+1/\u03b7t\n=\nK \u2211\nk=1\n1\nK\n\u221e \u2211\nj=1\nc\nj2 exp\n(\nj\u03b1t\u03b7t+1(Lt \u2212 Lkt )\u2212 j2\u03b7t+1 2\u03b2t+1\nt \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4\n)\n= Ct+1 .\nThus, for each t we have ft(\u03b3t, \u03c9t) \u2264 1, that is,\nK \u2211\nk=1\n1\nK\n\u221e \u2211\nj=1\nc\nj2 exp\n(\nj\u03b7t(Lt \u2212 Lkt )\u2212 j2\u03b7t 2\u03b2t\nt \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4\n)\n\u2264 1 .\nFor any \u01eb > 0, let us take any L\u01ebT such that for at least \u01ebK Experts their losses LkT are smaller than or equal to L\u01ebT . Then we have\n1 \u2265 K \u2211\nk=1\n1\nK\n\u221e \u2211\nj=1\nc\nj2 exp\n(\nj\u03b7t(Lt \u2212 Lkt )\u2212 j2\u03b7t 2\u03b2t\nt \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4\n)\n\u2265 \u01eb \u221e \u2211\nj=1\nc\nj2 exp\n(\nj\u03b7t(Lt \u2212 L\u01ebt)\u2212 j2\u03b7t 2\u03b2t\nt \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4\n)\n\u2265 c\u01eb j2 exp\n(\nj\u03b7t(Lt \u2212 L\u01ebt)\u2212 j2\u03b7t 2\u03b2t\nt \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4\n)\nfor any natural j. Taking the logarithm and rearranging, we get\nLt \u2264 L\u01ebt + j\n2\u03b2t\nt \u2211\n\u03c4=1\n\u03b2\u03c4\u03b7\u03c4 + 1\nj\u03b7t ln\nj2 c\u01eb .\nSubstituting \u03b7t = \u221a \u03b2t/Bt and using Lemma 1, we get\nLt \u2264 L\u01ebt + ( j + 2\nj ln j +\n1 j ln 1 \u01eb + 1 j ln 1 c\n)\n\u221a\nBt \u03b2t .\nLetting j = \u2308 \u221a ln(1/\u01eb) \u2309 +1 and using the estimates j \u2264 \u221a\nln(1/\u01eb)+2, (ln j)/j \u2264 2, (ln(1/\u01eb))/j \u2264 \u221a\nln(1/\u01eb), 1/j \u2264 1, and ln(1/c) = ln(\u03c02/6) \u2264 1, we obtain the final bound."}, {"heading": "4 Regression with Discounted Loss", "text": "In this section we consider a task of regression, where Learner must predict \u201clabels\u201d yt \u2208 R for input instances xt \u2208 X \u2286 Rn. The predictions proceed according to Protocol 2. This task can be embedded into prediction with expert\nProtocol 2 Competitive online regression\nfor t = 1, 2, . . . do Reality announces xt \u2208 X. Learner announces \u03b3t \u2208 \u0393. Reality announces yt \u2208 \u2126. end for\nadvice if Learner competes with all functions x \u2192 y from some large class serving as a pool of (imaginary) Experts."}, {"heading": "4.1 The Framework and Linear Functions as Experts", "text": "Let the input space be X \u2286 Rn, the set of predictions be \u0393 = R, and the set of outcomes be \u2126 = [Y1, Y2]. In this section we consider the square loss \u03bbsq(\u03b3, y) = (\u03b3 \u2212 y)2. Learner competes with a pool of experts \u0398 = Rn (treated as linear functionals on Rn). Each individual expert is denoted by \u03b8 \u2208 \u0398 and predicts \u03b8\u2032xt at step t.\nLet us take any distribution over the experts P (d\u03b8). It is known from [19] that (3) holds for the square loss with c = 1, \u03b7 = 2(Y2\u2212Y1)2 :\n\u2203\u03b3 \u2208 \u0393 \u2200y \u2208 \u2126 = [Y1, Y2] (\u03b3 \u2212 y)2 \u2264 \u2212 1\n\u03b7 ln\n(\u222b\n\u0398\ne\u2212\u03b7(\u03b8 \u2032xt\u2212y) 2 P (d\u03b8)\n)\n. (20)\nDenote by X the matrix of size T \u00d7 n consisting of the rows of the input vectors x\u20321, . . . , x \u2032 T . Let also WT = diag(\u03b21/\u03b2T , \u03b22/\u03b2T , . . . , \u03b2T /\u03b2T ), i.e., WT is a diagonal matrix T \u00d7 T . In a manner similar to [22], we prove the following upper bound for Learner\u2019s loss.\nTheorem 4. For any a > 0, there exists a prediction strategy for Learner in Protocol 2 achieving, for every T and for any linear predictor \u03b8 \u2208 Rn,\nT \u2211\nt=1\n\u03b2t \u03b2T\n(\u03b3t \u2212 yt)2 \u2264 T \u2211\nt=1\n\u03b2t \u03b2T (\u03b8\u2032xt \u2212 yt)2\n+ a\u2016\u03b8\u20162 + (Y2 \u2212 Y1) 2\n4 ln det\n(\nX \u2032WTX\na + I\n)\n. (21)\nIf, in addition, \u2016xt\u2016\u221e \u2264 Z for all t, then\nT \u2211\nt=1\n\u03b2t \u03b2T\n(\u03b3t \u2212 yt)2 \u2264 T \u2211\nt=1\n\u03b2t \u03b2T (\u03b8\u2032xt \u2212 yt)2\n+ a\u2016\u03b8\u20162 + n(Y2 \u2212 Y1) 2\n4 ln\n(\nZ2\na \u2211T t=1 \u03b2t \u03b2T + 1\n)\n. (22)\nIn the undiscounted case (\u03b1t = 1 for all t), the bounds in the theorem coincide with the bounds for the Aggregating Algorithm for Regression [22, Theorem 1] with Y2 = Y and Y1 = \u2212Y , since, as remarked after Theorem 2, \u03b2t = 1 and ( \u2211T t=1 \u03b2t ) /\u03b2T = T in the undiscounted case. Recall also that in the case of the exponential discounting (\u03b1t = \u03b1 \u2208 (0, 1)) we have \u03b2t = \u03b1\u2212t+1 and (\n\u2211T t=1 \u03b2t\n)\n/\u03b2T = (1\u2212\u03b1T\u22121)/(1\u2212\u03b1) \u2264 1/(1\u2212\u03b1). Thus, for the exponential discounting bound (22) becomes\nT \u2211\nt=1\n\u03b1T\u2212t(\u03b3t \u2212 yt)2 \u2264 T \u2211\nt=1\n\u03b1T\u2212t(\u03b8\u2032xt \u2212 yt)2\n+ a\u2016\u03b8\u20162 + n(Y2 \u2212 Y1) 2\n4 ln\n(\nZ2(1\u2212 \u03b1T\u22121) a(1 \u2212 \u03b1) + 1\n)\n. (23)"}, {"heading": "4.2 Functions from an RKHS as Experts", "text": "In this section we apply the kernel trick to the linear method to compete with wider sets of experts. Each expert f \u2208 F predicts f(xt). Here F is a reproducing kernel Hilbert space (RKHS) with a positive definite kernel k : X\u00d7X \u2192 R. For the definition of RKHS and its connection to kernels see [17]. Each kernel defines a unique RKHS. We use the notation KT = {k(xi, xj)}i,j=1,...,T for the kernel matrix for the input vectors at step T . In a manner similar to [7], we prove the following upper bound on the discounted square loss of Learner.\nTheorem 5. For any a > 0, there exists a strategy for Learner in Protocol 2\nachieving, for every positive integer T and any predictor f \u2208 F , T \u2211\nt=1\n\u03b2t \u03b2T\n(\u03b3t \u2212 yt)2 \u2264 T \u2211\nt=1\n\u03b2t \u03b2T (f(xt)\u2212 yt)2\n+ a\u2016f\u20162 + (Y2 \u2212 Y1) 2\n4 ln det\n(\u221a WTKT \u221a WT\na + I\n)\n. (24)\nCorollary 1. Assume that c2F = supx\u2208X k(x, x) < \u221e for the RKHS F . Under the conditions of Theorem 5, given in advance any constant T such that (\n\u2211T t=1 \u03b2t\n)\n/\u03b2T \u2264 T , one can choose parameter a such that the strategy in Theorem 5 achieves for any f \u2208 F\nT \u2211\nt=1\n\u03b2t \u03b2T\n(\u03b3t\u2212yt)2 \u2264 T \u2211\nt=1\n\u03b2t \u03b2T (f(xt)\u2212yt)2+ ( (Y2 \u2212 Y1)2 4 + \u2016f\u20162 ) cF \u221a T . (25)\nwhere c2F = supx\u2208X k(x, x) < \u221e characterizes the RKHS F . Proof. The determinant of a symmetric positive definite matrix is upper bounded by the product of its diagonal elements (see Chapter 2, Theorem 7 in [1]), and thus we have\nln det\n(\nI +\n\u221a WTKT \u221a WT\na\n)\n\u2264 T ln\n\n  1 +\nc2F\n(\n\u220fT t=1 \u03b2t \u03b2T\n)1/T\na\n\n \n\u2264 T c 2 F\na\n(\nT \u220f\nt=1\n\u03b2t \u03b2T\n)1/T\n\u2264 T c 2 F\na\u03b2T\n\u2211T t=1 \u03b2t T \u2264 c 2 FT a\n(we use ln(1 + x) \u2264 x and the inequality between the geometric and arithmetic means). Choosing a = cF \u221a T , we get bound (25) from (24).\nRecall again that (\n\u2211T t=1 \u03b2t\n)\n/\u03b2T = (1\u2212\u03b1T\u22121)/(1\u2212\u03b1) \u2264 1/(1\u2212\u03b1) in the case of the exponential discounting (\u03b1t = \u03b1 \u2208 (0, 1)), and we can take T = 1/(1\u2212\u03b1).\nIn the undiscounted case (\u03b1t = 1), we have ( \u2211T t=1 \u03b2t ) /\u03b2T = T , so we need to know the number of steps in advance. Then, bound (25) matches the bound obtained in [23, the displayed formula after (33)]. If we do not know an upper bound T in advance, it is still possible to achieve a bound similar to (25) using the Aggregating Algorithm with Discounting to merge Learner\u2019s strategies from Theorem 5 with different values of parameter a, in the same manner as in [23, Theorem 3].\nCorollary 2. Assume that c2F = supx\u2208X k(x, x) < \u221e for the RKHS F . Under the conditions of Theorem 5, there exists a strategy for Learner in Protocol 2 achieving, for every positive integer T and any predictor f \u2208 F ,\nT \u2211\nt=1\n\u03b2t \u03b2T\n(\u03b3t \u2212 yt)2 \u2264 T \u2211\nt=1\n\u03b2t \u03b2T (f(xt)\u2212 yt)2 + cF\u2016f\u2016(Y2 \u2212 Y1)\n\u221a\n\u2211T t=1 \u03b2t \u03b2T\n+ (Y2 \u2212 Y1)2\n2 ln \u2211T t=1 \u03b2t \u03b2T + \u2016f\u20162 + (Y2 \u2212 Y1)2 ln ( cF (Y2 \u2212 Y1) \u2016f\u2016 + 2 ) . (26)\nProof. Let us take the strategies from Theorem 5 for a = 1, 2, 3, . . . and provide them as Experts to the Aggregating Algorithm with Discounting, with the square loss function, \u03b7 = 2/(Y2 \u2212 Y1)2 and initial Experts\u2019 weights proprotional to 1/a2. Then Theorem 1 (extended as described in Remark at the end of Section 2) guarantees that the extra loss of the aggregated strategy (compared to the strategy from Theorem 5 with parameter a) is not greater than (Y2\u2212Y1) 2\n2 ln a2 c , where c = \u2211K k=1 1/k 2. On the other hand, for the strategy from\nTheorem 5 with parameter a similarly to the proof of Corollary 1 we get\nT \u2211\nt=1\n\u03b2t \u03b2T\n(\u03b3t \u2212 yt)2 \u2264 T \u2211\nt=1\n\u03b2t \u03b2T (f(xt)\u2212 yt)2 + a\u2016f\u20162 + c2F(Y2 \u2212 Y1)2 4a \u2211T t=1 \u03b2t \u03b2T .\nAdding (Y2\u2212Y1) 2 2 ln a2 c to the right-hand side and choosing\na =\n\n  \ncF(Y2 \u2212 Y1) 2\u2016f\u2016\n\u221a\n\u2211T t=1 \u03b2t \u03b2T\n\n  \n,\nwe get the statement after simple estimations."}, {"heading": "4.3 Proofs of Theorems 4 and 5", "text": "Let us begin with several technical lemmas from linear algebra. The proofs of some of these lemmas are moved to Appendix A.1.\nLemma 2. Let A be a symmetric positive definite matrix of size n \u00d7 n. Let \u03b8, b \u2208 Rn, c be a real number, and Q(\u03b8) = \u03b8\u2032A\u03b8 + b\u2032\u03b8 + c. Then\n\u222b\nRn e\u2212Q(\u03b8)d\u03b8 = e\u2212Q0 \u03c0n/2\u221a detA ,\nwhere Q0 = min\u03b8\u2208Rn Q(\u03b8).\nThe proof of this lemma can be found in [9, Theorem 15.12.1].\nLemma 3. Let A be a symmetric positive definite matrix of size n \u00d7 n. Let b, z \u2208 Rn, and\nF (A, b, z) = min \u03b8\u2208Rn (\u03b8\u2032A\u03b8 + b\u2032\u03b8 + z\u2032\u03b8)\u2212 min \u03b8\u2208Rn (\u03b8\u2032A\u03b8 + b\u2032\u03b8 \u2212 z\u2032\u03b8) .\nThen F (A, b, z) = \u2212b\u2032A\u22121z.\nLemma 4. Let A be a symmetric positive definite matrix of size n \u00d7 n. Let \u03b8, b1, b2 \u2208 Rn, c1, c2 be real numbers, and Q1(\u03b8) = \u03b8\u2032A\u03b8 + b\u20321\u03b8 + c1, Q2(\u03b8) = \u03b8\u2032A\u03b8 + b\u20322\u03b8 + c2. Then\n\u222b\nRn e\u2212Q1(\u03b8)d\u03b8\n\u222b\nRn e\u2212Q2(\u03b8)d\u03b8\n= ec2\u2212c1\u2212 1 4 (b2+b1) \u2032A\u22121(b2\u2212b1) .\nThe previous three lemmas were implicitly used in [22] to derive a bound on the cumulative undiscounted square loss of the algorithm competing with linear experts.\nLemma 5. For any matrix B of size n\u00d7m, any matrix C of size m\u00d7n, and any real number a such that the matrices aIm +CB and aIn +BC are nonsingular, it holds\nB(aIm + CB) \u22121 = (aIn +BC) \u22121B , (27)\nwhere In, Im are the unit matrices of sizes n\u00d7 n and m\u00d7m, respectively.\nProof. Note that this is equivalent to (aIn +BC)B = B(aIm + CB).\nLemma 6. For matrix B of size n\u00d7m, any matrix C of size m\u00d7 n, and any real number a, it holds\ndet(aIn +BC) = det(aIm + CB) , (28)\nwhere In, Im are the unit matrices of sizes n\u00d7 n and m\u00d7m, respectively."}, {"heading": "4.3.1 Proof of Theorem 4.", "text": "We take the Gaussian initial distribution over the experts with a parameter a > 0:\nP0(d\u03b8) = (a\u03b7\n\u03c0\n)n/2\ne\u2212a\u03b7\u2016\u03b8\u2016 2 d\u03b8.\nand use \u201cAlgorithm 2 with infinitely many Experts\u201d. Repeating the derivations from Subsection 2.2, we obtain the following analogue of (7):\n(a\u03b7\n\u03c0\n)n/2 \u222b\n\u0398\ne \u03b7 ( \u2211 T t=1 \u03b2t \u03b2T (\u03b3t\u2212yt) 2\u2212 \u2211 T t=1 \u03b2t \u03b2T (\u03b8\u2032xt\u2212yt) 2 ) e\u2212a\u03b7\u2016\u03b8\u2016 2 d\u03b8 \u2264 1.\nThe simple equality\nT \u2211\nt=1\n\u03b2t \u03b2T\n(\u03b8\u2032xt \u2212 yt)2 + a\u2016\u03b8\u20162 = \u03b8\u2032(aI +X \u2032WTX)\u03b8 \u2212 2 T \u2211\nt=1\n\u03b2t \u03b2T yt\u03b8 \u2032xt +\nT \u2211\nt=1\n\u03b2t \u03b2T y2t\n(29) shows that the integral can be evaluated with the help of Lemma 2:\n(a\u03b7\n\u03c0\n)n/2 \u222b\n\u0398\ne \u2212\u03b7\n(\n\u2211\nT t=1 \u03b2t \u03b2T (\u03b8\u2032xt\u2212yt) 2+a\u2016\u03b8\u20162\n)\nd\u03b8\n= ( a\n\u03c0\n)n/2\ne \u2212\u03b7min\u03b8\n(\n\u2211\nT t=1 \u03b2t \u03b2T (\u03b8\u2032xt\u2212yt) 2+a\u2016\u03b8\u20162\n) \u03c0n/2 \u221a\ndet(aI +X \u2032WTX) .\nWe take the natural logarithms of both parts of the bound and using the value \u03b7 = 2(Y2\u2212Y1)2 obtain (21). The determinant of a symmetric positive definite matrix is upper bounded by the product of its diagonal elements (see Chapter 2, Theorem 7 in [1]):\ndet\n(\nX \u2032WTX\na + I\n) \u2264 ( Z2 \u2211T\nt=1 \u03b2t a\u03b2T + 1\n)n\n,\nand thus we obtain (22)."}, {"heading": "4.3.2 Proof of Theorem 5.", "text": "We must prove that for each T and each sequence (x1, y1, . . . , xT , yT ) \u2208 (X \u00d7 R)T the guarantee (24) is satisfied. Fix T and (x1, y1, . . . , xT , yT ). Fix an isomorphism between the linear span of kx1 , . . . , kxT obtained for the Riesz Representation theorem and RT\u0303 , where T\u0303 \u2264 T is the dimension of the linear span of kx1 , . . . , kxT . Let x\u03031, . . . , x\u0303T \u2208 RT\u0303 be the images of kx1 , . . . , kxT , respectively, under this isomorphism. We have then k(\u00b7, xi) = \u3008\u00b7, x\u0303i\u3009 for any xi.\nWe apply the strategy from Theorem 4 to x\u03031, . . . , x\u0303T . The predictions of the strategies are the same due to Proposition 1 below. Any expert \u03b8 \u2208 RT\u0303 in bound (21) can be represented as\n\u03b8 =\nT \u2211\ni=1\ncix\u0303i =\nT \u2211\ni=1\ncik(\u00b7, xi)\nfor some ci \u2208 R. Thus the experts\u2019 predictions are \u03b8\u2032x\u0303t = \u2211T i=1 cik(xt, xi), and the norm is \u2016\u03b8\u20162 = \u2211Ti,j=1 cicjk(xi, xj). Denote by X\u0303 the T\u00d7T\u0303 matrix consisting of the rows of the vectors x\u0303\u20321, . . . , x\u0303\u2032T . From Lemma 6 we have\ndet\n(\nX\u0303 \u2032WT X\u0303\na + I\n)\n= det\n(\u221a WT X\u0303X\u0303 \u2032 \u221a WT\na + I\n)\n.\nThus using KT = X\u0303X\u0303 \u2032 we obtain the upper bound\nT \u2211\nt=1\n\u03b2t \u03b2T\n(\u03b3t \u2212 yt)2 \u2264 T \u2211\nt=1\n\u03b2t \u03b2T\n(\nT \u2211\ni=1\ncik(xt, xi)\u2212 yt )2\n+ a\nT \u2211\ni,j=1\ncicjk(xi, xj) + (Y2 \u2212 Y1)2\n4 ln det\n(\u221a WTKT \u221a WT\na + I\n)\nfor any ci \u2208 R, i = 1, . . . , T . By the Representer theorem (see Theorem 4.2 in [17]) the minimum of\n\u2211T t=1 \u03b2t \u03b2T (f(xt)\u2212yt)2+a\u2016f\u20162 over all f \u2208 F is achieved on one of the linear combinations from the bound obtained above. This concludes the proof."}, {"heading": "4.4 Regression Algorithms", "text": "In this subsection we derive explicit form of the prediction strategies for Learner used in Theorems 4 and 5."}, {"heading": "4.4.1 Strategy for Theorem 4.", "text": "In [22] Vovk suggests for the square loss the following substitution function satisfying (5):\n\u03b3T = Y2 + Y1 2 \u2212 gT (Y2)\u2212 gT (Y1) 2(Y2 \u2212 Y1) . (30)\nIt allows us to calculate gT with unnormalized weights:\ngT (y) = \u2212 1\n\u03b7\n(\nln\n\u222b\n\u0398\ne \u2212\u03b7\n(\n\u03b8\u2032AT \u03b8\u22122\u03b8 \u2032(bT\u22121+yxT )+\n(\n\u2211T\u22121 t=1 \u03b2t \u03b2T\ny2t+y 2 ))\nd\u03b8\n)\nfor any y \u2208 \u2126 = [Y1, Y2] (here we use the expansion (29)), where\nAT = aI +\nT\u22121 \u2211\nt=1\n\u03b2t \u03b2T xtx \u2032 t + xTx \u2032 T = aI +X \u2032WTX,\nand bT\u22121 = \u2211T\u22121 t=1 \u03b2t \u03b2T\nytxt. The direct calculation of gT is inefficient: it requires numerical integration. Instead, we notice that\n\u03b3T = Y2 + Y1 2 \u2212 gT (Y2)\u2212 gT (Y1) 2(Y2 \u2212 Y1)\n= Y2 + Y1 2 \u2212 1 2(Y2 \u2212 Y1)\u03b7 ln\n\u222b \u0398 e \u2212\u03b7\n(\n\u03b8\u2032AT \u03b8\u22122\u03b8 \u2032(bT\u22121+Y1xT )+\n(\n\u2211T\u22121 t=1 \u03b2t \u03b2T y2t+Y 2 1\n))\nd\u03b8 \u222b\n\u0398 e \u2212\u03b7\n( \u03b8\u2032AT \u03b8\u22122\u03b8\u2032(bT\u22121+Y2xT )+ ( \u2211T\u22121 t=1 \u03b2t \u03b2T y2t+Y 2 2 ))\nd\u03b8\n= Y2 + Y1 2 \u2212 1 2(Y2 \u2212 Y1)\u03b7 ln e\n\u03b7 (\nY 22 \u2212Y 2 1 \u2212(bT\u22121+( Y2+Y1 2 )xT )\n\u2032\nA\u22121 T ( Y2\u2212Y1 2 xT ) )\n=\n(\nbT\u22121 +\n(\nY2 + Y1 2\n)\nxT\n)\u2032\nA\u22121T xT , (31)\nwhere the third equality follows from Lemma 4. The strategy which predicts according to (31) requires O(n3) operations per step. The most time-consuming operation is the inverse of the matrix AT . Note that for the undiscounted case the inverse could be computed incrementally using the Sherman-Morrison formula, which leads to O(n2) operations per step."}, {"heading": "4.4.2 Strategy for Theorem 5.", "text": "We use following notation. Let\nkT be the last column of the matrix KT ,kT = {k(xi, xT )}Ti=1, YT be the column vector of the outcomes YT = (y1, . . . , yT ) \u2032. (32)\nWhen we write Z = (V;Y) or Z = (V\u2032;Y\u2032)\u2032 we mean that the column vector Z is obtained by concatenating two column vectors V,Y vertically or V\u2032,Y\u2032 horizontally. As it is clear from the proof of Theorem 5, we need to prove that the strategy for this theorem is the same as the strategy for Theorem 4 in the case when the kernel is the scalar product.\nProposition 1. The predictions (31) can be represented as\n\u03b3T =\n(\nYT\u22121; Y2 + Y1\n2\n)\u2032 \u221a\nWT\n(\naI + \u221a WTKT \u221a WT\n)\u22121 \u221a\nWTkT (33)\nfor the scalar product kernel k(x, y) = \u3008x, y\u3009, the unit T\u00d7T matrix I, and a > 0.\nProof. For the scalar product kernel we have we haveKT = X \u2032X and \u221a WTkT =\u221a\nWTXxT . By Lemma 5 we obtain\n(\naI + \u221a WTXX \u2032 \u221a WT\n)\u22121 \u221a\nWTXxT = \u221a WTX ( aI +X \u2032WTX )\u22121 xT .\nIt is easy to see that\n(\nYT\u22121; Y2 + Y1\n2\n)\u2032\nWTX =\n(\nT\u22121 \u2211\nt=1\n\u03b2t \u03b2T ytxt +\n(\nY2 + Y1 2\n)\nxT\n)\u2032\nand\nX \u2032WTX =\nT\u22121 \u2211\nt=1\n\u03b2t \u03b2T xtx \u2032 t + xTx \u2032 T .\nThus we obtain the formula (31) from (33)."}, {"heading": "Acknowledgements", "text": "We are grateful to Yura Kalnishkan and Volodya Vovk for numerous illuminating discussions. This work was supported by EPSRC (grant EP/F002998/1)."}, {"heading": "A Appendix", "text": "A.1 Proofs of Technical Lemmas\nProof of Lemma 1. For T = 1 the inequality is trivial. Assume it for T \u2212 1. Then\n1\n\u03b2T\nT \u2211\nt=1\n\u03b2t\n\u221a\n\u03b2t Bt = \u03b2T\u22121 \u03b2T\n(\n1\n\u03b2T\u22121\nT\u22121 \u2211\nt=1\n\u03b2t\n\u221a\n\u03b2t Bt\n)\n+\n\u221a\n\u03b2T BT\n\u2264 2\u03b2T\u22121 \u03b2T\n\u221a\nBT\u22121 \u03b2T\u22121 +\n\u221a\n\u03b2T BT = 2\n\u221a\n\u03b2T\u22121 \u03b2T\n\u221a\nBT\u22121 \u03b2T +\n\u221a\n\u03b2T BT\n\u2264 2 \u221a\nBT\u22121 \u03b2T +\n\u221a\n\u03b2T BT\u22121 + \u03b2T\n\u2264 2 \u221a\nBT\u22121 + \u03b2T \u03b2T = 2\n\u221a\nBT \u03b2T .\nThe first inequality is by the induction assumption, and the second inequality holds since \u03b2T\u22121 \u2264 \u03b2T . The last inequality is 2 \u221a x/ \u221a y + \u221a y/ \u221a x+ y \u2264 2 \u221a x+ y/ \u221a y, which holds for any positive x and y. (Indeed, it is equivalent to 2 \u221a x \u221a x+ y + y \u2264 2(x+ y) and 2\u221ax\u221ax+ y \u2264 x+ y + x.)\nProof of Lemma 3. This lemma is proven by taking the derivative of the quadratic forms in F by \u03b8 and calculating the minimum: min\u03b8\u2208Rn(\u03b8 \u2032A\u03b8+c\u2032\u03b8) = \u2212 (A \u22121c)\u2032\n4 c for any c \u2208 Rn (see Theorem 19.1.1 in [9]).\nProof of Lemma 4. After evaluating each of the integrals using Lemma 2 the ratio is represented as follows:\n\u222b\nRn e\u2212Q1(\u03b8)d\u03b8\n\u222b\nRn e\u2212Q2(\u03b8)d\u03b8\n= emin\u03b8\u2208Rn Q2(\u03b8)\u2212min\u03b8\u2208Rn Q1(\u03b8) .\nThe difference of minimums can be calculated using Lemma 3 with b = b2+b12 and z = b2\u2212b12 :\nmin \u03b8\u2208Rn Q2(\u03b8) \u2212 min \u03b8\u2208Rn\nQ1(\u03b8) = c2 \u2212 c1 \u2212 1\n4 (b2 + b1)\n\u2032A\u22121(b2 \u2212 b1) .\nProof of Lemma 6. Consider the product of block matrices: (\nIn B 0 Im\n)(\naIn + BC 0 \u2212C aIm\n)\n=\n(\naIn aB \u2212C aIm\n)\n=\n(\naIn 0 \u2212C aIm + CB\n)(\nIn B 0 Im\n)\nTaking the determinant of both sides, and using formulas for the determinant of a block matrix, we get the statement of the lemma.\nA.2 An Alternative Derivation of Regression Algorithms\nUsing Defensive Forecasting\nIn this section we derive the upper bound and the algorithms using a different technique, the defensive forecasting [4].\nA.2.1 Description of the Proof Technique\nWe denote the predictions of any expert \u03b8 (from a finite set or following strategies from Section 4) by \u03be\u03b8t . For each step T and each expert \u03b8 we define the function\nQ\u03b8t : \u0393\u00d7 \u2126 \u2192 [0,\u221e) Q\u03b8t (\u03b3, y) := e \u03b7(\u03bb(\u03b3,y)\u2212\u03bb(\u03be\u03b8t ,y)). (34)\nWe also define the mixture function\nQT :=\n\u222b\n\u0398\nT\u22121 \u220f\nt=1\n( Q\u03b8t )\n\u220fT\u22121 i=t\n\u03b1i Q\u03b8TP0(d\u03b8)\nwith some initial weights distribution P0(d\u03b8) on the experts. Here \u03b7 is a learning rate coefficient; it will be defined later in the section. We define the correspondence \u03b3p = p(Y2 \u2212 Y1) + Y1, p \u2208 [0, 1], (35) between [0, 1] and Learner\u2019s predictions \u03b3p \u2208 \u0393.\nLet us introduce the notion of a defensive property. We use the notation \u03b4\u2126 := {Y1, Y2}. Assume that there is a fixed bijection between the space P(\u03b4\u2126) of all probability measures on \u03b4\u2126 and the set [0, 1]. Each p\u03c0 \u2208 [0, 1] corresponds to some unique \u03c0 \u2208 P(\u03b4\u2126). Definition 1. A sequence R of functions R1, R2, . . . such that Rt : \u0393 \u00d7 \u2126 \u2192 (\u2212\u221e,\u221e] is said to have the defensive property if, for any T and any \u03c0T \u2208 P(\u03b4\u2126), it holds that\nE\u03c0TRT (\u03b3 p\u03c0T , y) \u2264 1, (36)\nwhere E\u03c0 is the expectation with respect to a measure \u03c0.\nA sequence R is called forecast-continuous if, for all T and all y \u2208 \u2126, all the functions RT (\u03b3, y) are continuous in \u03b3.\nWe now prove that Q\u03b8t has the defensive property.\nLemma 7. For \u03b7 \u2208 (\n0, 2(Y2\u2212Y1)2\n]\nQ\u03b8t = e \u03b7((\u03b3t\u2212yt)2\u2212(\u03be\u03b8t \u2212yt) 2)\nis a forecast-continuous sequence having the defensive property.\nProof. The continuity is obvious. We need to prove that\npe\u03b7((\u03b3\u2212Y2) 2\u2212(\u03be\u03b8t\u2212Y2) 2) + (1\u2212 p)e\u03b7((\u03b3\u2212Y1)2\u2212(\u03be\u03b8t\u2212Y1)2) \u2264 1 (37)\nholds for all \u03b3 \u2208 [Y1, Y2] and \u03b7 \u2208 (\n0, 2(Y2\u2212Y1)2\n]\n. Indeed, for any \u03b3 \u2208 R \\ [Y1, Y2] there exists \u03b3\u0303 \u2208 {Y1, Y2} such that (\u03b3\u0303 \u2212 y)2 \u2264 (\u03b3 \u2212 y)2 for any y \u2208 \u2126. Since the exponent function is increasing, the inequality (37) for any \u03b3 \u2208 R will follow.\nWe use the correspondence (35), \u03be\u03b8t = q(Y2 \u2212 Y1) + Y1 for some q \u2208 R, and \u00b5 = \u03b7(Y2 \u2212 Y1)2. Then we have to show that for all p \u2208 [0, 1], q \u2208 R and \u03b7 \u2208 (\n0, 2(Y2\u2212Y1)2\n]\npe\u00b5((1\u2212p) 2\u2212(1\u2212q)2) + (1 \u2212 p)e\u00b5(p2\u2212q2) \u2264 1.\nIf we substitute q = p+ x, the last inequality will reduce to\npe2\u00b5(1\u2212p)x + (1\u2212 p)e\u22122\u00b5px \u2264 e\u00b5x2 , \u2200x \u2208 R.\nApplying Hoeffding\u2019s inequality (see [12]) to the random variableX that is equal to 1 with probability p and to 0 with probability (1\u2212 p), we obtain\npeh(1\u2212p) + (1\u2212 p)e\u2212hp \u2264 eh2/8\nfor any h \u2208 R. With the substitution h := 2\u00b5x it reduces to\npe2\u00b5(1\u2212p)x + (1 \u2212 p)e\u22122\u00b5px \u2264 e\u00b52x2/2 \u2264 e\u00b5x2 ,\nwhere the last inequality holds if \u00b5 \u2264 2. The last inequality is equivalent to \u03b7 \u2264 2(Y2\u2212Y1)2 , which we assumed.\nWe will further use the maximum value for \u03b7, \u03b7 = 2(Y2\u2212Y1)2 .\nThe following lemma states the most important for us property of the sequences having the defensive property originally proven in [15].\nLemma 8. Let R be a forecast-continuous sequence having the defensive property. For any T there exists p \u2208 [0, 1] such that for all y \u2208 \u03b4\u2126\nRT (\u03b3 p, y) \u2264 1.\nProof. Define a function ft : \u03b4\u2126\u00d7 [0, 1] \u2192 (\u2212\u221e,\u221e] by\nft(p, y) = Rt(\u03b3 p, y)\u2212 1.\nSince R is forecast-continuous and the correspondence (35) is continuous, ft(y, p) is continuous in p. Since R has the defensive property, we have\npf(p, Y2) + (1\u2212 p)f(1\u2212 p, Y1) \u2264 0 (38)\nfor all p \u2208 [0, 1]. In particular, f(0, Y1) \u2264 0 and f(1, Y2) \u2264 0. Our goal is to show that for some p \u2208 [0, 1] we have f(p, Y1) \u2264 0 and f(p, Y2) \u2264 0. If f(0, Y2) \u2264 0, we can take p = 0. If f(1, Y1) \u2264 0, we can take p = 1. Assume that f(0, Y2) > 0 and f(1, Y1) > 0. Then the difference\nf(p) := f(p, Y2)\u2212 f(p, Y1)\nis positive for p = 0 and negative for p = 1. By the intermediate value theorem, f(p) = 0 for some p \u2208 (0, 1). By (38) we have f(p, Y2) = f(p, Y1) \u2264 0.\nThis lemma shows that at each step there is a probability measure (corresponding to p \u2208 [0, 1]) such that the sequence having the defensive property remains less than one for any outcome.\nThe proof of the upper bounds for Defensive Forecasting is based on the following argument.\nLemma 9. Assume that the sequence of functions Q\u03b8t is forecast-continuous and has the defensive property. Then the mixtures Qt as functions of two variables y, \u03b3 at the step t form a forecast-continuous sequence having the defensive property.\nProof. The continuity easily follows from the continuity of Q\u03b8t and the integration functional. We proceed by induction in T . For T = 0 we have E\u03c0Q0 = E\u03c01 \u2264 1. For T > 0 assume that for any y1, . . . , yT\u22122 \u2208 \u03b4\u2126 and any \u03b31, . . . , \u03b3T\u22122 \u2208 \u0393\nE\u03c0QT\u22121(y1, \u03b31, . . . , yT\u22122, \u03b3T\u22122, y, \u03b3 p\u03c0) \u2264 1\nfor any \u03c0 \u2208 P(\u03b4\u2126). Then by Lemma 8 there exists \u03c0T\u22121 \u2208 P(\u03b4\u2126) such that\nQT\u22121(y1, \u03b31, . . . , yT\u22122, \u03b3T\u22122, y, \u03b3 p\u03c0T\u22121 ) =\n\u222b\n\u0398\nT\u22122 \u220f\nt=1\n( Q\u03b8t )\n\u220fT\u22122 i=t\n\u03b1i Q\u03b8T\u22121P0(d\u03b8) \u2264 1\n(39) for any y \u2208 \u03b4\u2126. We denote \u03b3T\u22121 = \u03b3p \u03c0T\u22121 and fix any yT\u22121 \u2208 \u2126. We obtain\nE\u03c0QT (y1, \u03b31, . . . , yT\u22121, \u03b3T\u22121, y, \u03b3 p\u03c0)\n= E\u03c0\n\u222b\n\u0398\nT\u22121 \u220f\nt=1\n( Q\u03b8t (\u03b3t, yt) )\n\u220fT\u22121 i=t\n\u03b1i Q\u03b8T (\u03b3 p\u03c0 , y)P0(d\u03b8)\n=\n\u222b\n\u0398\nT\u22121 \u220f\nt=1\n( Q\u03b8t (\u03b3t, yt) )\n\u220fT\u22121 i=t \u03b1i (\nE\u03c0Q \u03b8 T (\u03b3\np\u03c0 , y) )\nP0(d\u03b8)\n\u2264 \u222b\n\u0398\nT\u22121 \u220f\nt=1\n( Q\u03b8t (\u03b3t, yt) )\n\u220fT\u22121 i=t\n\u03b1i P0(d\u03b8)\n=\n\u222b\n\u0398\n(\nT\u22122 \u220f\nt=1\n( Q\u03b8t )\n\u220fT\u22122 i=t\n\u03b1i Q\u03b8T\u22121\n)\u03b1T\u22121\nP0(d\u03b8)\n\u2264 ( \u222b\n\u0398\nT\u22122 \u220f\nt=1\n( Q\u03b8t )\n\u220fT\u22122 i=t\n\u03b1i Q\u03b8T\u22121P0(d\u03b8)\n)\u03b1T\u22121\n\u2264 1.\nThe first inequality holds because E\u03c0Q \u03b8 T (\u03b3 p\u03c0 , y) \u2264 1 for any \u03c0 \u2208 P(\u03b4\u2126). The penultimate inequality holds due to the concavity of the function x\u03b1 with x > 0, \u03b1 \u2208 [0, 1]. The last inequality holds due to (39). This completes the proof.\nBy Lemma 8 at each step t there exists a prediction \u03b3t such that Qt is less than one. Now we only need to generalize Lemma 8 for the case when the outcome set is the full interval: \u2126 = [Y1, Y2].\nLemma 10. If \u03b3T is such that QT (y1, \u03b31, . . . , yT\u22121, \u03b3T\u22121, y, \u03b3T ) \u2264 1 for all y \u2208 {Y1, Y2}, then QT (y1, \u03b31, . . . , yT\u22121, \u03b3T\u22121, y, \u03b3T ) \u2264 1 for all y \u2208 [Y1, Y2].\nProof. Note that any y \u2208 [Y1, Y2] can be represented as y = uYT,2 + (1\u2212 u)YT,1 for some u \u2208 [0, 1]. Thus\n(\u03b61 \u2212 y)2 \u2212 (\u03b62 \u2212 y)2 = \u03b621 \u2212 \u03b622 \u2212 2y(\u03b61 \u2212 \u03b62) = u[(\u03b61 \u2212 Y2)2 \u2212 (\u03b62 \u2212 Y2)2] + (1\u2212 u)[(\u03b61 \u2212 Y1)2 \u2212 (\u03b62 \u2212 Y1)2]\nfor any \u03b61, \u03b62 \u2208 R. Due to the convexity of the exponent function we have for any \u03b7 \u2265 0\ne\u03b7[(\u03b61\u2212y) 2\u2212(\u03b62\u2212y) 2] \u2264 ue\u03b7[(\u03b61\u2212Y2)2\u2212(\u03b62\u2212Y2)2] + (1\u2212 u)e\u03b7[(\u03b61\u2212Y1)2\u2212(\u03b62\u2212Y1)2].\nThus Q\u03b8T (\u03b3T , y) \u2264 uQ\u03b8T (\u03b3T , Y2) + (1\u2212 u)Q\u03b8T (\u03b3T , Y1)\nand therefore\nQT (y1, \u03b31, . . . , yT\u22121, \u03b3T\u22121, y, \u03b3T ) \u2264 uQT (y1, \u03b31, . . . , yT\u22121, \u03b3T\u22121, Y2, \u03b3T ) + (1\u2212 u)QT (y1, \u03b31, . . . , yT\u22121, \u03b3T\u22121, Y1, \u03b3T ) \u2264 1\nwhere the second inequality follows from the condition of the lemma.\nFinally we obtain\n\u222b\n\u0398\nT\u22121 \u220f\nt=1\ne\u03b7 \u220fT\u22121 i=t \u03b1i(\u03bb(\u03b3t,yt)\u2212\u03bb(\u03be\u03b8t ,yt))e\u03b7(\u03bb(\u03b3T ,yT )\u2212\u03bb(\u03be \u03b8 T ,yT ))P0(d\u03b8) \u2264 1. (40)\nA.2.2 Derivation of the Prediction Strategies Using Defensive Fore-\ncasting\nLemma 8 describes an explicit strategy of making predictions. This strategy relies on the search for a fixed point and may become very inefficient especially for the cases of infinite number of experts. Therefore we develop a more efficient strategies for each of our problems.\nWe first note that the strategy in Lemma 8 solves\n\u222b\n\u0398\nT\u22121 \u220f\nt=1\ne\u03b7 \u220fT\u22121 i=t \u03b1i(\u03bb(\u03b3t,yt)\u2212\u03bb(\u03be\u03b8t ,yt))e\u03b7(\u03bb(\u03b3,Y2)\u2212\u03bb(\u03be \u03b8 T ,Y2))P0(d\u03b8)\n\u2212 \u222b\n\u0398\nT\u22121 \u220f\nt=1\ne\u03b7 \u220fT\u22121 i=t \u03b1i(\u03bb(\u03b3t,yt)\u2212\u03bb(\u03be\u03b8t ,yt))e\u03b7T (\u03bb(\u03b3,Y1)\u2212\u03bb(\u03be \u03b8 T ,Y1))P0(d\u03b8) = 0\nin \u03b3 \u2208 [Y1, Y2] if the trivial predictions are not satisfactory (the integral becomes a sum in the case of finite number of experts). We define\ngT (y) := \u2212 1\n\u03b7 ln\n\u222b\n\u0398\ne\u2212\u03b7\u03bb(\u03be \u03b8 T ,y)\nT\u22121 \u220f\nt=1\ne\u2212\u03b7 \u220fT\u22121 i=t \u03b1i\u03bb(\u03be \u03b8 t ,yt)P0(d\u03b8) (41)\nfor any y \u2208 \u2126. Rewriting the equation for the root we have\ne\u03b7(\u03bbT (\u03b3,Y2)\u2212gT (Y2)) \u2212 e\u03b7(\u03bbT (\u03b3,Y1)\u2212gT (Y1)) = 0\nMoving the second exponent to the right-hand side and taking log\u03b7 of both sides we obtain\n\u03bb(\u03b3, Y2)\u2212 gT (Y2) = \u03bb(\u03b3, Y1)\u2212 gT (Y1). (42) For the square loss we can solve (42) in \u03b3:\n\u03b3 = Y2 + Y1 2 \u2212 g(Y2)\u2212 g(Y1) 2(Y2 \u2212 Y1) . (43)\nThis formula for predictions is equivalent to (30)."}], "references": [{"title": "Prediction, Learning, and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "A parameter-free hedging algorithm", "author": ["K. Chaudhuri", "Y. Freund", "D. Hsu"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Supermartingales in prediction with expert advice", "author": ["A. Chernov", "Y. Kalnishkan", "F. Zhdanov", "V. Vovk"], "venue": "Theoretical Computer Science,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Prediction with Advice of Unknown Number of Experts Technical report, arXiv:1006.0475 [cs.LG], arXiv.org e-Print archive", "author": ["A. Chernov", "V. Vovk"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "A new hedging algorithm and its application to inferring latent random variables. Technical report, arXiv:0806.4802v1 [cs.GT], arXiv.org e-Print archive", "author": ["Y. Freund", "D. Hsu"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "On-line prediction with kernels and the complexity approximation principle", "author": ["A. Gammerman", "Y. Kalnishkan", "V. Vovk"], "venue": "Uncertainty in Artificial Intelligence, Proc. of 20th Conf., pp", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Exponential smoothing: The state of the art \u2013 part II", "author": ["E.S. Gardner"], "venue": "International Journal of Forecasting 22,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Matrix algebra from a statistician\u2019s perspective", "author": ["D.A. Harville"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "Sequential prediction of individual sequences under general loss functions", "author": ["D. Haussler", "J. Kivinen", "M. Warmuth"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Tracking the best expert", "author": ["M. Herbster", "M.K. Warmuth"], "venue": "Machine Learning 32,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1998}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["W. Hoeffding"], "venue": "Journal of the American Statistical Association 58,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1963}, {"title": "The weak aggregating algorithm and weak mixability", "author": ["Y. Kalnishkan", "M. Vyugin"], "venue": "Technical report, CLRC-TR-03-01,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "The weak aggregating algorithm and weak mixability", "author": ["Y. Kalnishkan", "M. Vyugin"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Uniform tests of randomness", "author": ["L. Levin"], "venue": "Soviet Mathematics Doklady 17,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1976}, {"title": "Optimal properties of exponentially weighted forecasts", "author": ["J.F. Muth"], "venue": "Journal of the American Statistical Association", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1960}, {"title": "Learning with kernels: Support Vector Machines, regularization, optimization, and beyond", "author": ["B. Sch\u00f6lkopf", "A.J. Smola"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "Reinforcement learning: An introduction", "author": ["R. Sutton", "A. Barto"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1998}, {"title": "Aggregating strategies", "author": ["V. Vovk"], "venue": "Proceedings of the Third Annual Workshop on Computational Learning Theory. pp", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1990}, {"title": "A Game of Prediction with Expert Advice", "author": ["V. Vovk"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1998}, {"title": "Derandomizing stochastic prediction strategies", "author": ["V. Vovk"], "venue": "Machine Learning,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1999}, {"title": "Competitive on-line statistics", "author": ["V. Vovk"], "venue": "Int. Stat. Review 69,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2001}, {"title": "On-line regression competitive with reproducing kernel Hilbert spaces. Technical report, arXiv:cs/0511058 [cs.LG], arXiv.org e-Print archive", "author": ["V. Vovk"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "Hoeffding\u2019s inequality in game-theoretic probability. Technical Report, arXiv:0708.2502 [math.PR], arXiv.org e-Print archive", "author": ["V. Vovk"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "In the standard framework for prediction with expert advice (see the monograph [2] for a comprehensive review), the losses from all steps are just summed.", "startOffset": 79, "endOffset": 82}, {"referenceID": 17, "context": "The standard protocol of prediction with expert advice (as described in [19, 20]) is a special case of Protocol 1 where Accountant always announces \u03b1t = 1, t = 0, 1, 2, .", "startOffset": 72, "endOffset": 80}, {"referenceID": 18, "context": "The standard protocol of prediction with expert advice (as described in [19, 20]) is a special case of Protocol 1 where Accountant always announces \u03b1t = 1, t = 0, 1, 2, .", "startOffset": 72, "endOffset": 80}, {"referenceID": 14, "context": ", [16]), time series analysis (see, e.", "startOffset": 2, "endOffset": 6}, {"referenceID": 6, "context": ", [8]), reinforcement learning [18], and other applications.", "startOffset": 2, "endOffset": 5}, {"referenceID": 16, "context": ", [8]), reinforcement learning [18], and other applications.", "startOffset": 31, "endOffset": 35}, {"referenceID": 4, "context": "In the context of prediction with expert advice, Freund and Hsu [6] noted that the discounted loss provides an alternative to \u201ctracking the best expert\u201d framework [11].", "startOffset": 64, "endOffset": 67}, {"referenceID": 9, "context": "In the context of prediction with expert advice, Freund and Hsu [6] noted that the discounted loss provides an alternative to \u201ctracking the best expert\u201d framework [11].", "startOffset": 163, "endOffset": 167}, {"referenceID": 0, "context": "8 in [2] gives a guarantee only at one moment T chosen in advance.", "startOffset": 5, "endOffset": 8}, {"referenceID": 4, "context": "Under this discounting, NormalHedge algorithm is analysed in [6]; we briefly compare the obtained bounds in Section 3.", "startOffset": 61, "endOffset": 64}, {"referenceID": 18, "context": "In Section 2, we propose a generalization of the Aggregating Algorithm [20] and prove the same bound as in [20] but for the discounted loss.", "startOffset": 71, "endOffset": 75}, {"referenceID": 18, "context": "In Section 2, we propose a generalization of the Aggregating Algorithm [20] and prove the same bound as in [20] but for the discounted loss.", "startOffset": 107, "endOffset": 111}, {"referenceID": 12, "context": "In Section 3, we consider convex loss functions and propose an algorithm similar to the Weak Aggregating Algotihm [14] and the exponentially weighted average forecaster with time-varying learning rate [2, \u00a7 2.", "startOffset": 114, "endOffset": 118}, {"referenceID": 20, "context": "In Section 4, we consider the use of prediction with expert advice for the regression problem and adapt the Aggregating Algorithm for Regression [22] (applied to spaces of linear functions and to reproducing kernel Hilbert spaces) to the discounted square loss.", "startOffset": 145, "endOffset": 149}, {"referenceID": 2, "context": "All our algorithms are inspired by the methodology of defensive forecasting [4].", "startOffset": 76, "endOffset": 79}, {"referenceID": 17, "context": "Bounds of this kind were obtained in [19].", "startOffset": 37, "endOffset": 41}, {"referenceID": 17, "context": "For the standard undiscounted case (Accountant announces \u03b1t = 1 at each step t), this theorem was proved by Vovk in [19] with the help of the Aggregating Algorithm (AA) as Learner\u2019s strategy.", "startOffset": 116, "endOffset": 120}, {"referenceID": 8, "context": "It is known ([10, 20]) that this bound is asymptotically optimal for large pools of Experts (for games satisfying some assumptions): if the game does not satisfy (3) for some c \u2265 1 and \u03b7 > 0, then, for sufficiently large K, there is a strategy for Experts and Reality (recall that Accountant always says \u03b1t = 1) such that Learner cannot secure (4).", "startOffset": 13, "endOffset": 21}, {"referenceID": 18, "context": "It is known ([10, 20]) that this bound is asymptotically optimal for large pools of Experts (for games satisfying some assumptions): if the game does not satisfy (3) for some c \u2265 1 and \u03b7 > 0, then, for sufficiently large K, there is a strategy for Experts and Reality (recall that Accountant always says \u03b1t = 1) such that Learner cannot secure (4).", "startOffset": 13, "endOffset": 21}, {"referenceID": 19, "context": "For the special case of c = 1, bound (4) is tight for any fixedK as well [21].", "startOffset": 73, "endOffset": 77}, {"referenceID": 20, "context": "Then the algorithm and its analysis remain valid (if we impose natural integrability conditions on Experts\u2019 predictions \u03b3 t ; see [22] for more detailed discussion)\u2014this will be used in Section 4.", "startOffset": 130, "endOffset": 134}, {"referenceID": 4, "context": "A similar bound (with worse constants) is obtained in [6] for NormalHedge: LT \u2264 LT + \u221a", "startOffset": 54, "endOffset": 57}, {"referenceID": 1, "context": "The NormalHedge algorithm has an important advantage: it can guarantee the last bound without knowledge of the number of experts K (see [3] for a precise definition).", "startOffset": 136, "endOffset": 139}, {"referenceID": 12, "context": "Let us explain the relation of Algorithm 3 to the Weak Aggregating Algorithm [14] and the exponentially weighted average forecaster with time-varying learning rate [2, \u00a7 2.", "startOffset": 77, "endOffset": 81}, {"referenceID": 12, "context": "In this case, Algorithm 4 is just the Weak Aggregating Algorithm as described in [14].", "startOffset": 81, "endOffset": 85}, {"referenceID": 2, "context": "That algorithm is based on the ideas of defensive forecasting [4], in particular, Hoeffding supermartingales [24], combined with the ideas from an early version of the Weak Aggregating Algorithm [13].", "startOffset": 62, "endOffset": 65}, {"referenceID": 22, "context": "That algorithm is based on the ideas of defensive forecasting [4], in particular, Hoeffding supermartingales [24], combined with the ideas from an early version of the Weak Aggregating Algorithm [13].", "startOffset": 109, "endOffset": 113}, {"referenceID": 11, "context": "That algorithm is based on the ideas of defensive forecasting [4], in particular, Hoeffding supermartingales [24], combined with the ideas from an early version of the Weak Aggregating Algorithm [13].", "startOffset": 195, "endOffset": 199}, {"referenceID": 3, "context": "However, our analysis in Theorem 2 is completely different from [5], following the lines of [2, Theorem 2.", "startOffset": 64, "endOffset": 67}, {"referenceID": 11, "context": "2] and [13].", "startOffset": 7, "endOffset": 11}, {"referenceID": 1, "context": "However, this bound can be stated as a bound for \u01eb-quantile regret introduced in [3].", "startOffset": 81, "endOffset": 84}, {"referenceID": 3, "context": "of \u01eb, and in this sense the algorithm works for the unknown number of Experts (see [5] for a more detailed discussion).", "startOffset": 83, "endOffset": 86}, {"referenceID": 3, "context": "We do not do this here, but refer to [5]; the proof is literally the same as in [5, Theorem 9] and is based on the supermartingale property of ft.", "startOffset": 37, "endOffset": 40}, {"referenceID": 17, "context": "It is known from [19] that (3) holds for the square loss with c = 1, \u03b7 = 2 (Y2\u2212Y1) : \u2203\u03b3 \u2208 \u0393 \u2200y \u2208 \u03a9 = [Y1, Y2] (\u03b3 \u2212 y) \u2264 \u2212 1 \u03b7 ln (\u222b", "startOffset": 17, "endOffset": 21}, {"referenceID": 20, "context": "In a manner similar to [22], we prove the following upper bound for Learner\u2019s loss.", "startOffset": 23, "endOffset": 27}, {"referenceID": 15, "context": "For the definition of RKHS and its connection to kernels see [17].", "startOffset": 61, "endOffset": 65}, {"referenceID": 5, "context": "In a manner similar to [7], we prove the following upper bound on the discounted square loss of Learner.", "startOffset": 23, "endOffset": 26}, {"referenceID": 20, "context": "The previous three lemmas were implicitly used in [22] to derive a bound on the cumulative undiscounted square loss of the algorithm competing with linear experts.", "startOffset": 50, "endOffset": 54}, {"referenceID": 15, "context": "2 in [17]) the minimum of \u2211T t=1 \u03b2t \u03b2T (f(xt)\u2212yt)+a\u2016f\u2016 over all f \u2208 F is achieved on one of the linear combinations from the bound obtained above.", "startOffset": 5, "endOffset": 9}, {"referenceID": 20, "context": "In [22] Vovk suggests for the square loss the following substitution function satisfying (5): \u03b3T = Y2 + Y1 2 \u2212 gT (Y2)\u2212 gT (Y1) 2(Y2 \u2212 Y1) .", "startOffset": 3, "endOffset": 7}, {"referenceID": 7, "context": "1 in [9]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "2 An Alternative Derivation of Regression Algorithms Using Defensive Forecasting In this section we derive the upper bound and the algorithms using a different technique, the defensive forecasting [4].", "startOffset": 197, "endOffset": 200}, {"referenceID": 10, "context": "Applying Hoeffding\u2019s inequality (see [12]) to the random variableX that is equal to 1 with probability p and to 0 with probability (1\u2212 p), we obtain pe + (1\u2212 p)e \u2264 eh2/8 for any h \u2208 R.", "startOffset": 37, "endOffset": 41}, {"referenceID": 13, "context": "The following lemma states the most important for us property of the sequences having the defensive property originally proven in [15].", "startOffset": 130, "endOffset": 134}], "year": 2010, "abstractText": "We study prediction with expert advice in the setting where the losses are accumulated with some discounting and the impact of old losses can gradually vanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm for Regression, propose a new variant of exponentially weighted average algorithm, and prove bounds on the cumulative discounted loss.", "creator": "LaTeX with hyperref package"}}}