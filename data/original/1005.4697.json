{"id": "1005.4697", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2010", "title": "The Lambek-Grishin calculus is NP-complete", "abstract": "The Lambek-Grishin calculus LG is the symmetric extension of the non-associative Lambek calculus NL. In this paper we prove that the derivability problem for LG is NP-complete.", "histories": [["v1", "Tue, 25 May 2010 20:36:09 GMT  (13kb)", "https://arxiv.org/abs/1005.4697v1", null], ["v2", "Mon, 31 May 2010 20:16:29 GMT  (13kb)", "http://arxiv.org/abs/1005.4697v2", null], ["v3", "Wed, 25 Aug 2010 13:10:44 GMT  (13kb)", "http://arxiv.org/abs/1005.4697v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jeroen bransen"], "accepted": false, "id": "1005.4697"}, "pdf": {"name": "1005.4697.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Jeroen Bransen"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n00 5.\n46 97\nv3 [\ncs .C\nL ]\n2 5\nA ug\n2 01"}, {"heading": "1 Introduction", "text": "In his 1958 and 1961 papers, Lambek formulated two versions of the Syntactic Calculus : in (Lambek, 1958), types are assigned to strings, which are then combined by an associative operation; in (Lambek, 1961), types are assigned to phrases (bracketed strings), and the composition operation is non-associative. We refer to these two versions as L and NL respectively.\nAs for generative power, Kandulski (1988) proved thatNL defines exactly the context-free languages. Pentus (1993) showed that this also holds for associative L. As for the complexity of the derivability problem, de Groote (1999) showed that for NL this belongs to PTIME; for L, Pentus (2003) proves that the problem is NP-complete and Savateev (2009) shows that NP-completeness also holds for the product-free fragment of L.\nIt is well known that some natural language phenomena require generative capacity beyond context-free. Several extensions of the Syntactic Calculus have been proposed to deal with such phenomena. In this paper we look at the Lambek-Grishin calculus LG (Moortgat, 2007, 2009). LG is a symmetric extension of the nonassociative Lambek calculus NL. In addition to \u2297, \\, / (product, left and right division), LG has dual operations \u2295,;,\u2298 (coproduct, left and right difference). These two families are related by linear distributivity principles. Melissen (2009) shows that all languages which are the intersection of a context-free language and the permutation closure of a context-free language are recognizable in LG. This places the lower bound for LG recognition beyond LTAG. The upper bound is still open.\nThe key result of the present paper is a proof that the derivability problem for LG is NP-complete. This will be shown by means of a reduction from SAT.1"}, {"heading": "2 Lambek-Grishin calculus", "text": "We define the formula language of LG as follows.\n1 This paper has been written as a result of my Master thesis supervised by Michael Moortgat. I would like to thank him, Rosalie Iemhoff and Arno Bastenhof for comments and I acknowledge that any errors are my own.\nLet V ar be a set of primitive types, we use lowercase letters to refer to an element of V ar. Let formulas be constructed using primitive types and the binary connectives \u2297, /, \\, \u2295, \u2298 and ; as follows:\nA,B ::= p | A\u2297B | A/B | B\\A | A\u2295B | A\u2298B | B ; A\nThe sets of input and output structures are constructed using formulas and the binary structural connectives \u00b7 \u2297 \u00b7, \u00b7/\u00b7, \u00b7\\\u00b7, \u00b7 \u2295 \u00b7, \u00b7 \u2298 \u00b7 and \u00b7 ; \u00b7 as follows:\n(input) X,Y ::= A | X \u00b7 \u2297 \u00b7 Y | X \u00b7 \u2298 \u00b7 P | P \u00b7 ; \u00b7X\n(output) P,Q ::= A | P \u00b7 \u2295 \u00b7Q | P \u00b7 / \u00b7X | X \u00b7 \\ \u00b7 P\nThe sequents of the calculus are of the form X \u2192 P , and as usual we write \u22a2LG X \u2192 P to indicate that the sequent X \u2192 P is derivable in LG. The axioms and inference rules are presented in Figure 1, where we use the display logic from (Gore\u0301, 1998), but with different symbols for the structural connectives.\nIt has been proven by Moortgat (2007) that we have Cut admissibility for LG. This means that for every derivation using the Cut -rule, there exists a corresponding derivation that is Cut-free. Therefore we will assume that the Cut-rule is not needed anywhere in a derivation."}, {"heading": "3 Preliminaries", "text": ""}, {"heading": "3.1 Derivation length", "text": "We will first show that for every derivable sequent there exists a Cut-free derivation that is polynomial in the length of the sequent. The length of a sequent \u03d5, denoted as |\u03d5|, is defined as the number of (formula and structural) connectives used to construct this sequent. A subscript will be used to indicate that we count only certain connectives, for example |\u03d5|\u2297.\nLemma 1. If \u22a2LG \u03d5 there exists a derivation with exactly |\u03d5| logical rules.\nProof. If \u22a2LG \u03d5 then there exists a Cut-free derivation for \u03d5. Because every logical rule removes one logical connective and there are no rules that introduce logical connectives, this derivation contains |\u03d5| logical rules. \u2293\u2294\nLemma 2. If \u22a2LG \u03d5 there exists a derivation with at most 1 4 |\u03d5|2 Grishin interactions.\nProof. Let us take a closer look at the Grishin interaction principles. First of all, it is not hard to see that the interactions are irreversible. Also note that the interactions happen between the families of input connectives {\u2297, /, \\} and output connectives {\u2295,\u2298,;} and that the Grishin interaction principles are the only rules of inference that apply on both families. So, on any pair of one input and one output connective, at most one Grishin interaction principle can be applied.\nIf \u22a2LG \u03d5 there exists a Cut-free derivation of \u03d5. The maximum number of possible Grishin interactions in 1 Cut-free derivation is reached when a Grishin interaction is applied on every pair of one input and one output connective. Thus, the maximum number of Grishin interactions in one Cut-free derivation is |\u03d5|{\u2297,/,\\} \u00b7 |\u03d5|{\u2295,\u2298,;}.\nBy definition, |\u03d5|{\u2297,/,\\}+|\u03d5|{\u2295,\u2298,;} = |\u03d5|, so the maximum value of |\u03d5|{\u2297,/,\\}\u00b7 |\u03d5|{\u2295,\u2298,;} is reached when |\u03d5|{\u2297,/,\\} = |\u03d5|{\u2295,\u2298,;} = |\u03d5| 2 . Then the total number of Grishin interactions in 1 derivation is |\u03d5| 2 \u00b7 |\u03d5| 2 = 1 4 |\u03d5|2, so any Cut-free derivation of \u03d5 will contain at most 1 4 |\u03d5|2 Grishin interactions. \u2293\u2294\nLemma 3. In a derivation of sequent \u03d5 at most 2|\u03d5| display rules are needed to display any of the structural parts.\nProof. A structural part in sequent \u03d5 is nested under at most |\u03d5| structural connectives. For each of these connectives, one or two r or dr rules can display the desired part, after which the next connective is visible. Thus, at most 2|\u03d5| display rules are needed to display any of the structural parts.\nLemma 4. If \u22a2LG \u03d5 there exists a Cut-free derivation of length O(|\u03d5| 3).\nProof. From Lemma 1 and Lemma 2 we know that there exists a derivation with at most |\u03d5| logical rules and 1\n4 |\u03d5|2 Grishin interactions. Thus, the derivation\nconsists of |\u03d5| + 1 4 |\u03d5|2 rules, with between each pair of consecutive rules the display rules. From Lemma 3 we know that at most 2|\u03d5| display rules are needed to display any of the structural parts. So, at most 2|\u03d5|\u00b7(|\u03d5|+ 1\n4 |\u03d5|2) = 2|\u03d5|2+ 1 2 |\u03d5|3\nderivation steps are needed in the shortest possible Cut-free derivation for this sequent, and this is in O(|\u03d5|3). \u2293\u2294"}, {"heading": "3.2 Additional notations", "text": "Let us first introduce some additional notations to make the proofs shorter and easier readable.\nLet us call an input structure X which does not contain any structural operators except for \u00b7\u2297 \u00b7 a \u2297-structure. A \u2297-structure can be seen as a binary tree with \u00b7 \u2297 \u00b7 in the internal nodes and formulas in the leafs. Formally we define \u2297-structures U and V as:\nU, V ::= A | U \u00b7 \u2297 \u00b7 V\nWe define X [] and P [] as the input and output structures X and P with a hole in one of their leafs. Formally:"}, {"heading": "X [] ::= [] | X [] \u00b7 \u2297 \u00b7 Y | Y \u00b7 \u2297 \u00b7X [] | X [] \u00b7 \u2298 \u00b7Q | Y \u00b7 \u2298 \u00b7P [] | Q \u00b7; \u00b7X [] | P [] \u00b7; \u00b7Y", "text": ""}, {"heading": "P [] ::= [] | P [] \u00b7 \u2295 \u00b7Q | Q \u00b7 \u2295 \u00b7 P [] | P [] \u00b7 / \u00b7 Y | Q \u00b7 / \u00b7X [] | Y \u00b7 \\ \u00b7 P [] | X [] \u00b7 \\ \u00b7Q", "text": "This notation is similar to the one of de Groote (1999) but with structures. If X [] is a structure with a hole, we write X [Y ] for X [] with its hole filled with structure Y . We will write X\u2297[] for a \u2297-structure with a hole.\nFurthermore, we extend the definition of hole to formulas, and define A[] as a formula A with a hole in it, in a similar manner as for structures. Hence, by A[B] we mean the formula A[] with its hole filled by formula B.\nIn order to distinguish between input and output polarity formulas, we write A\u2022 for a formula with input polarity and A\u25e6 for a formula with output polarity. Note that for structures this is already defined by using X and Y for input polarity and P and Q for output polarity. This can be extended to formulas in a similar way, and we will use this notation only in cases where the polarity is not clear from the context."}, {"heading": "3.3 Derived rules of inference", "text": "Now we will show and prove some derived rules of inference of LG.\nLemma 5. If \u22a2LG A \u2192 B and we want to derive X \u2297[A] \u2192 P , we can replace A by B in X\u2297[]. We have the inference rule below:\nA \u2192 B X\u2297[B] \u2192 P\nX\u2297[A] \u2192 P Repl\nProof. We consider three cases:\n1. If X\u2297[A] = A, it is simply the cut-rule:\nA \u2192 B B \u2192 P A \u2192 P Cut\n2. If X\u2297[A] = Y \u2297[A] \u00b7 \u2297 \u00b7 V , we can move V to the righthand-side and use induction to prove the sequent:\nA \u2192 B\nY \u2297[B] \u00b7 \u2297 \u00b7 V \u2192 P Y \u2297[B] \u2192 P \u00b7 / \u00b7 V r\nY \u2297[A] \u2192 P \u00b7 / \u00b7 V Repl Y \u2297[A] \u00b7 \u2297 \u00b7 V \u2192 P r\n3. If X\u2297[A] = U \u00b7 \u2297 \u00b7 Y \u2297[A], we can move U to the righthand-side and use induction to prove the sequent:\nA \u2192 B\nU \u00b7 \u2297 \u00b7 Y \u2297[B] \u2192 P Y \u2297[B] \u2192 U \u00b7 \\ \u00b7 P r\nY \u2297[A] \u2192 U \u00b7 \\ \u00b7 P Repl U \u00b7 \u2297 \u00b7 Y \u2297[A] \u2192 P r\n\u2293\u2294\nLemma 6. If we want to derive X\u2297[A \u2298 B] \u2192 P , then we can move the expression \u2298B out of the \u2297-structure. We have the inference rule below:\nX\u2297[A] \u00b7 \u2298 \u00b7B \u2192 P\nX\u2297[A\u2298B] \u2192 P Move\nProof. We consider three cases:\n1. If X\u2297[A\u2298B] = A\u2298B, then this is simply the \u2298L-rule:\nA \u00b7 \u2298 \u00b7 B \u2192 Y A\u2298B \u2192 Y \u2298L\n2. If X\u2297[A\u2298B] = Y \u2297[A\u2298B] \u00b7\u2297 \u00b7V , we can move V to the righthand-side and use induction together with the Grishin interaction principles to prove the sequent:\n(Y \u2297[A] \u00b7 \u2297 \u00b7 V ) \u00b7 \u2298 \u00b7 B \u2192 P\nY \u2297[A] \u00b7 \u2297 \u00b7 V \u2192 P \u00b7 \u2295 \u00b7B dr Y \u2297[A] \u00b7 \u2298 \u00b7 B \u2192 P \u00b7 / \u00b7 V d\u2298 /\nY \u2297[A\u2298B] \u2192 P \u00b7 / \u00b7 V Move Y \u2297[A\u2298B] \u00b7 \u2297 \u00b7 V \u2192 P r\n3. If X\u2297[A\u2298B] = U \u00b7\u2297 \u00b7Y \u2297[A\u2298B], we can move U to the righthand-side and use induction together with the Grishin interaction principles to prove the sequent:\n(U \u00b7 \u2297 \u00b7 Y \u2297[A]) \u00b7 \u2298 \u00b7 B \u2192 P\nU \u00b7 \u2297 \u00b7 Y \u2297[A] \u2192 P \u00b7 \u2295 \u00b7B dr Y \u2297[A] \u00b7 \u2298 \u00b7 B \u2192 U \u00b7 \\ \u00b7 P d\u2298 \\\nY \u2297[A\u2298B] \u2192 U \u00b7 \\ \u00b7 P Move U \u00b7 \u2297 \u00b7 Y \u2297[A\u2298B] \u2192 P r\n\u2293\u2294\nLemma 7. \u22a2LG A1 \u2297 (A2 \u2297 . . . (An\u22121 \u2297 An)) \u2192 P iff \u22a2LG A1 \u00b7 \u2297 \u00b7 (A2 \u00b7 \u2297 \u00b7 . . . (An\u22121 \u00b7 \u2297 \u00b7 An)) \u2192 P\nProof. The if -part can be derived by the application of n\u2212 1 times the \u2297L rule together with the r rule:\nA1 \u00b7 \u2297 \u00b7 (A2 \u00b7 \u2297 \u00b7 . . . (An\u22121 \u00b7 \u2297 \u00b7 An)) \u2192 P\nAn\u22121 \u00b7 \u2297 \u00b7 An \u2192 . . . \u00b7 \\ \u00b7 (A2 \u00b7 \\ \u00b7 (A1 \u00b7 \\ \u00b7 P )) r\u2217\nAn\u22121 \u2297An \u2192 . . . \u00b7 \\ \u00b7 (A2 \u00b7 \\ \u00b7 (A1 \u00b7 \\ \u00b7 P )) \u2297L\n. . . (An\u22121 \u2297An) \u2192 A2 \u00b7 \\ \u00b7 (A1 \u00b7 \\ \u00b7 P ) . . .\nA2 \u00b7 \u2297 \u00b7 . . . (An\u22121 \u2297An) \u2192 A1 \u00b7 \\ \u00b7 P r\nA2 \u2297 . . . (An\u22121 \u2297An) \u2192 A1 \u00b7 \\ \u00b7 P \u2297L\nA1 \u00b7 \u2297 \u00b7 (A2 \u2297 . . . (An\u22121 \u2297An)) \u2192 P r\nA1 \u2297 (A2 \u2297 . . . (An\u22121 \u2297An)) \u2192 P \u2297L\nThe only-if -part can be derived by application of n \u2212 1 times the \u2297R rule followed by a Cut:\nA1 \u2192 A1\nA2 \u2192 A2\nAn\u22121 \u2192 An\u22121 An \u2192 An An\u22121 \u00b7 \u2297 \u00b7 An \u2192 An\u22121 \u2297An \u2297R\n. . . (An\u22121 \u00b7 \u2297 \u00b7An) \u2192 . . . (An\u22121 \u2297An) . . .\nA2 \u00b7 \u2297 \u00b7 . . . (An\u22121 \u00b7 \u2297 \u00b7An) \u2192 A2 \u2297 . . . (An\u22121 \u2297An) \u2297R\nA1 \u00b7 \u2297 \u00b7 (A2 \u00b7 \u2297 \u00b7 . . . (An\u22121 \u00b7 \u2297 \u00b7 An)) \u2192 A1 \u2297 (A2 \u2297 . . . (An\u22121 \u2297An)) \u2297R A1 \u2297 (A2 \u2297 . . . (An\u22121 \u2297An)) \u2192 P\nA1 \u00b7 \u2297 \u00b7 (A2 \u00b7 \u2297 \u00b7 . . . (An\u22121 \u00b7 \u2297 \u00b7 An)) \u2192 P Cut\nNote that because of the Cut elimination theorem, there exists a cut-free derivation for this sequent.\n\u2293\u2294"}, {"heading": "3.4 Type similarity", "text": "The type simililarity relation \u223c, introduced by Lambek (1958), is the reflexive transitive symmetric closure of the derivability relation. Formally we define this as:\nDefinition 1. A \u223c B iff there exists a sequence C1 . . . Cn(1 \u2264 i \u2264 n) such that C1 = A, Cn = B and Ci \u2192 Ci+1 or Ci+1 \u2192 Ci for all 1 \u2264 i < n.\nIt was proved by Lambek that A \u223c B iff one of the following equivalent statements holds (the so-called diamond property):\n\u2203C such that A \u2192 C and B \u2192 C (join)\n\u2203D such that D \u2192 A and D \u2192 B (meet)\nThis diamond property will be used in the reduction from SAT to create a choice for a truthvalue of a variable.\nDefinition 2. If A \u223c B and C is the join type of A and B so that A \u2192 C and B \u2192 C, we define A C \u2293 B = (A/((C/C)\\C)) \u2297 ((C/C)\\B) as the meet type of"}, {"heading": "A and B.", "text": "This is also the solution given by Lambek (1958) for the associative system L, but in fact this is the shortest solution for the non-associative system NL (Foret, 2003).\nLemma 8. If A \u223c B with join-type C and \u22a2LG A \u2192 P or \u22a2LG B \u2192 P , then we also have \u22a2LG A C \u2293 B \u2192 P . We can write this as a derived rule of inference:\nA \u2192 P or B \u2192 P\nA C \u2293 B \u2192 P\nMeet\nProof.\n1. If A \u2192 P :\nC \u2192 C C \u2192 C C/C \u2192 C \u00b7 / \u00b7 C /L\nC/C \u2192 C/C /R B \u2192 C\n(C/C)\\B \u2192 (C/C) \u00b7 \\ \u00b7 C \\L\n(C/C)\\B \u2192 (C/C)\\C \\R A \u2192 P\nA/((C/C)\\C) \u2192 P \u00b7 / \u00b7 ((C/C)\\B) /L\n(A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B) \u2192 P r\n(A/((C/C)\\C)) \u2297 ((C/C)\\B) \u2192 P \u2297L\n2. If B \u2192 P :\nA \u2192 C\nC \u2192 C C \u2192 C C/C \u2192 C \u00b7 / \u00b7 C /L\n(C/C) \u00b7 \u2297 \u00b7 C \u2192 C r C \u2192 (C/C) \u00b7 \\ \u00b7 C r\nC \u2192 (C/C)\\C \\R\nA/((C/C)\\C) \u2192 C \u00b7 / \u00b7 C /L\nA/((C/C)\\C) \u2192 C/C /R\nB \u2192 P\n(C/C)\\B \u2192 (A/((C/C)\\C)) \u00b7 \\ \u00b7 P \\L\n(A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B) \u2192 P r\n(A/((C/C)\\C))\u2297 ((C/C)\\B) \u2192 P \u2297L\n\u2293\u2294\nThe following lemma is the key lemma of this paper, and its use will become clear to the reader in the construction of Section 4.\nLemma 9. If \u22a2LG A C \u2293 B \u2192 P then \u22a2LG A \u2192 P or \u22a2LG B \u2192 P , if it is not the case that:\n\u2013 P = P \u2032[A\u2032[(A1 \u2297A2) \u25e6]] \u2013 \u22a2LG A/((C/C)\\C) \u2192 A1 \u2013 \u22a2LG (C/C)\\B \u2192 A2\nProof. We have that \u22a2LG (A/((C/C)\\C))\u2297 ((C/C)\\B) \u2192 P , so from Lemma 7 we know that \u22a2LG (A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B) \u2192 P . Remark that this also means that there exists a cut-free derivation for this sequent. By induction on the length of the derivation we will show that if \u22a2LG (A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/ C)\\B) \u2192 P , then \u22a2LG A \u2192 P or \u22a2LG B \u2192 P , under the assumption that P is not of the form that is explicitly excluded in this lemma. We will look at the derivations in a top-down way.\nThe induction base is the case where a logical rule is applied on the lefthandside of the sequent. At a certain point in the derivation, possibly when P is an atom, one of the following three rules must be applied:\n1. The \u2297R rule, but then P = A1 \u2297A2 and in order to come to a derivation it must be the case that \u22a2LG A/((C/C)\\C) \u2192 A1 and \u22a2LG (C/C)\\B \u2192 A2. However, this is explicitly excluded in this lemma so this can never be the case. 2. The /L rule, in this case first the r rule is applied so that we have \u22a2LG A/((C/C)\\C) \u2192 P \u00b7 / \u00b7 ((C/C)\\B). Now if the /L rule is applied, we must have that \u22a2LG A \u2192 P . 3. The \\L rule, in this case first the r rule is applied so that we have \u22a2LG (C/C)\\B \u2192 (A/((C/C)\\C)) \u00b7 \\ \u00b7 P . Now if the \\L rule is applied, we must have that \u22a2LG B \u2192 P .\nThe induction step is the case where a logical rule is applied on the righthandside of the sequent. Let \u03b4 = {r, dr, d \u2298 /, d\u2298 \\, d ; /, d ; \\} and let \u03b4\u2217 indicate a (possibly empty) sequence of structural residuation steps and Grishin interactions. For example for the \u2298R rule there are two possibilities:\n\u2013 The lefthand-side ends up in the first premisse of the \u2298R rule:\n(A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B) \u2192 P \u2032\u2032[A\u2032] P \u2032[(A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B)] \u2192 A\u2032 \u03b4\u2217 B\u2032 \u2192 Q\nP \u2032[(A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B)] \u00b7 \u2298 \u00b7Q \u2192 A\u2032 \u2298B\u2032 \u2298R\n(A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B) \u2192 P [A\u2032 \u2298B\u2032] \u03b4\u2217\nIn order to be able to apply the \u2298R rule, we need to have a formula of the form A\u2032 \u2298 B\u2032 on the righthand-side. In the first step all structural rules are applied to display this formula in the righthand-side, and we assume that in the lefthand-side the meet-type ends up in the first structural part (inside a structure with the remaining parts from P that we call P \u2032). After the \u2298R rule has been applied, we can again display our meet-type in the lefthandside of the formula by moving all other structural parts from P \u2032 back to the righthand-side (P \u2032\u2032). In this case it must be that \u22a2LG (A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B) \u2192 P\n\u2032\u2032[A\u2032], and by induction we know that in this case also \u22a2LG A \u2192 P\n\u2032\u2032[A\u2032] or \u22a2LG B \u2192 P \u2032\u2032[A\u2032]. In the case that \u22a2LG A \u2192 P\n\u2032\u2032[A\u2032], we can show that \u22a2LG A \u2192 P [A\u2032 \u2298B\u2032] as follows:\nA \u2192 P \u2032\u2032[A\u2032] P \u2032[A] \u2192 A\u2032 \u03b4\u2217 B\u2032 \u2192 Q\nP \u2032[A] \u00b7 \u2298 \u00b7Q \u2192 A\u2032 \u2298B\u2032 \u2298R\nA \u2192 P [A\u2032 \u2298B\u2032] \u03b4\u2217\nThe case for B is similar. \u2013 The lefthand-side ends up in the second premisse of the \u2298R rule:\nQ \u2192 A\u2032 (A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B) \u2192 P \u2032\u2032[B\u2032] B\u2032 \u2192 P \u2032[(A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B)] \u03b4\u2217\nQ \u00b7 \u2298 \u00b7 P \u2032[(A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B)] \u2192 A\u2032 \u2298B\u2032 \u2298R\n(A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B) \u2192 P [A\u2032 \u2298B\u2032] \u03b4\u2217\nThis case is similar to the other case, except that the meet-type ends up in the other premisse. Note that, although in this case it is temporarily moved to the righthand-side, the meet-type will still be in an input polarity position and can therefore be displayed in the lefthand-side again. In this case it must be that \u22a2LG (A/((C/C)\\C)) \u00b7 \u2297 \u00b7 ((C/C)\\B) \u2192 P\n\u2032\u2032[B\u2032], and by induction we know that in this case also \u22a2LG A \u2192 P\n\u2032\u2032[B\u2032] or \u22a2LG B \u2192 P \u2032\u2032[B\u2032]. In the case that \u22a2LG A \u2192 P\n\u2032\u2032[B\u2032], we can show that \u22a2LG A \u2192 P [A\u2032 \u2298B\u2032] as follows:\nQ \u2192 A\u2032 A \u2192 P \u2032\u2032[B\u2032] B\u2032 \u2192 P \u2032[A] \u03b4\u2217\nQ \u00b7 \u2298 \u00b7 P \u2032[A] \u2192 A\u2032 \u2298B\u2032 \u2298R\nA \u2192 P [A\u2032 \u2298B\u2032] \u03b4\u2217\nThe case for B is similar.\nThe cases for the other logical rules are similar. \u2293\u2294"}, {"heading": "4 Reduction from SAT to LG", "text": "In this section we will show that we can reduce a Boolean formula in conjunctive normal form to a sequent of the Lambek-Grishin calculus, so that the corresponding LG sequent is provable if and only if the CNF formula is satisfiable. This has already been done for the associative system L by Pentus (2003) with a similar construction.\nLet \u03d5 = c1 \u2227 . . . \u2227 cn be a Boolean formula in conjunctive normal form with clauses c1 . . . cn and variables x1 . . . xm. For all 1 \u2264 j \u2264 m let \u00ac0xj stand for the literal \u00acxj and \u00ac1xj stand for the literal xj . Now \u3008t1, . . . , tm\u3009 \u2208 {0, 1}\nm is a satisfying assignment for \u03d5 if and only if for every 1 \u2264 i \u2264 n there exists a 1 \u2264 j \u2264 m such that the literal \u00actjxj appears in clause ci.\nLet pi (for 1 \u2264 i \u2264 n) be distinct primitive types from V ar. We now define the following families of types:\nEij(t) \u21cc\n{\npi \u2298 (pi ; pi) if \u00actxj appears in clause ci pi otherwise if 1 \u2264 i \u2264 n, 1 \u2264 j \u2264 m and t \u2208 {0, 1}\nEj(t) \u21cc E 1 j (t)\u2297 (E 2 j (t)\u2297 (. . . (E n\u22121 j (t)\u2297 E n j (t)))) if 1 \u2264 j \u2264 m and t \u2208 {0, 1}\nHj \u21cc p1 \u2297 (p2 \u2297 (. . . (pn\u22121 \u2297 pn))) if 1 \u2264 j \u2264 m\nFj \u21cc Ej(1) Hj \u2293 Ej(0) if 1 \u2264 j \u2264 m\nG0 \u21cc H1 \u2297 (H2 \u2297 (. . . (Hm\u22121 \u2297Hm)))\nGi \u21cc Gi\u22121 \u2298 (pi ; pi) if 1 \u2264 i \u2264 n\nLet \u03d5\u0304 = F1 \u2297 (F2 \u2297 (. . . (Fm\u22121 \u2297Fm))) \u2192 Gn be the LG sequent corresponding to the Boolean formula \u03d5. We now claim that the \u03d5 if and only if \u22a2LG \u03d5\u0304."}, {"heading": "4.1 Example", "text": "Let us take the Boolean formula (x1\u2228\u00acx2)\u2227(\u00acx1\u2228\u00acx2) as an example. We have the primitive types {p1, p2} and the types as shown in Figure 2. The formula is satisfiable (for example with the assignment \u30081, 0\u3009), thus \u22a2LG F1 \u2297 F2 \u2192 G2. A sketch of the derivation is given in Figure 2, some parts are proved in lemma\u2019s later on."}, {"heading": "4.2 Intuition", "text": "Let us give some intuitions for the different parts of the construction, and a brief idea of why this would work. The basic idea is that on the lefthand-side we create a type for each literal (Fj is the formula for literal j), which will in the end result in the base type Hj , so F1 \u2297 (F2 \u2297 (. . . (Fm\u22121 \u2297 Fm))) will result in G0. However, on the righthand-side we have an occurence of the expression \u2298(pi;pi) for each clause i, so in order to come to a derivation, we need to apply the \u2298R rule for every clause i.\nEach literal on the lefthand-side will result in either Ej(1) (xj is true) or Ej(0) (xj is false). This choice is created using a join type Hj such that \u22a2LG Ej(1) \u2192 Hj and \u22a2LG Ej(0) \u2192 Hj , which we use to construct the meet type Fj . It can be shown that in this case \u22a2LG Fj \u2192 Ej(1) and \u22a2LG Fj \u2192 Ej(0), i.e. in the original formula we can replace Fj by either Ej(1) or Ej(0), giving us a choice for the truthvalue of xj .\nLet us assume that we need x1 = true to satisfy the formula, so on the lefthand-side we need to replace Fj by E1(1). E1(1) will be the product of exactly n parts, one for each clause (E11 (1) . . . E n 1 (1)). Here E i 1(1) is pi \u2298 (pi ; pi) iff x1 does appear in clause i, and pi otherwise. The first thing that should be noticed is that \u22a2LG pi\u2298 (pi ; pi) \u2192 pi, so we can rewrite all pi\u2298 (pi ; pi) into pi so that \u22a2LG E1(1) \u2192 H1.\nHowever, we can also use the type pi\u2298(pi;pi) to facilitate the application of the \u2298R rule on the occurrence of the expression \u2298(pi;pi) in the righthand-side. From Lemma 6 we know that \u22a2LG X \u2297[pi \u2298 (pi ; pi)] \u2192 Gi if \u22a2LG X \u2297[pi] \u00b7 \u2298 \u00b7 (pi ; pi) \u2192 Gi, so if the expression \u2298Y occurs somewhere in a \u2297-structure we can move it to the outside. Hence, from the occurrence of pi \u2298 (pi ; pi) on the lefthand-side we can move \u2298(pi ; pi) to the outside of the \u2297-structure and pi will be left behind within the original structure (just as if we rewrote it to pi). However, the sequent is now of the form X\u2297[pi] \u00b7\u2298 \u00b7 (pi ; pi) \u2192 Gi\u22121 \u2298 (pi ; pi), so after applying the \u2298R rule we have X\u2297[pi] \u2192 Gi\u22121.\nNow if the original CNF formula is satisfiable, we can use the meet types on the lefthand-side to derive the correct value of Ej(1) or Ej(0) for all j. If this assignment indeed satisfies the formula, then for each i the formula pi\u2298 (pi ;pi) will appear at least once. Hence, for all occurrences of the expression \u2298(pi ; pi) on the righthand-side we can apply the \u2298R rule, after which the rest of the pi \u2298 (pi ; pi) can be rewritten to pi in order to derive the base type.\nIf the formula is not satisfiable, then there will be no way to have the pi \u2298 (pi;pi) types on the lefthand-side for all i, so there will be at least one occurence\nof \u2298(pi ;pi) on the righthand-side where we cannot apply the \u2298R rule. Because the \u2298 will be the main connective we cannot apply any other rule, and we will never come to a valid derivation.\nNote that the meet type Fj provides an explicit switch, so we first have to replace it by either Ej(1) or Ej(0) before we can do anything else with it. This guarantees that if \u22a2LG \u03d5\u0304, there also must be some assignment \u3008t1, . . . , tm\u3009 \u2208 {0, 1}m such that \u22a2LG E1(t1)\u2297 (E2(t2)\u2297 (. . . (Em\u22121(tm\u22121)\u2297Em(tm)))) \u2192 Gn, which means that \u3008t1, . . . , tm\u3009 is a satisfying assigment for \u03d5."}, {"heading": "5 Proof", "text": "We will now prove the main claim that \u03d5 if and only if \u22a2LG \u03d5\u0304. First we will prove that if \u03d5, then \u22a2LG \u03d5\u0304."}, {"heading": "5.1 If-part", "text": "Let us assume that \u03d5, so there is an assignment \u3008t1, . . . , tm\u3009 \u2208 {0, 1} m that satisfies \u03d5.\nLemma 10. If 1 \u2264 i \u2264 n, 1 \u2264 j \u2264 m and t \u2208 {0, 1} then \u22a2LG E i j(t) \u2192 pi.\nProof. We consider two cases:\n1. If Eij(t) = pi this is simply the axiom rule. 2. If Eij(t) = pi \u2298 (pi ; pi) we can prove it as follows:\npi \u2192 pi pi \u2192 pi pi \u00b7 ; \u00b7 pi \u2192 pi ; pi ;R pi \u2192 pi \u00b7 \u2295 \u00b7 (pi ; pi) dr pi \u00b7 \u2298 \u00b7 (pi ; pi) \u2192 pi dr\npi \u2298 (pi ; pi) \u2192 pi \u2298L\n\u2293\u2294\nLemma 11. If 1 \u2264 j \u2264 m and t \u2208 {0, 1}, then \u22a2LG Ej(t) \u2192 Hj.\nProof. From Lemma 7 we know that we can turn Ej(t) into a \u2297-structure. From Lemma 10 we know that \u22a2LG E i j(t) \u2192 pi, so using Lemma 5 we can replace all Eij(t) by pi in Ej(t) after which we can apply the \u2297R rule n\u2212 1 times to prove the lemma. \u2293\u2294\nLemma 12. If 1 \u2264 j \u2264 m, then \u22a2LG Fj \u2192 Ej(tj)\nProof. From Lemma 11 we know that \u22a2LG Ej(1) \u2192 Hj and \u22a2LG Ej(0) \u2192 Hj , so Ej(1) \u223c Ej(0) with join-type Hj . Now from Lemma 8 we know that \u22a2LG Ej(1) Hj \u2293 Ej(0) \u2192 Ej(1) and \u22a2LG Ej(1) Hj \u2293 Ej(0) \u2192 Ej(0). \u2293\u2294\nLemma 13. We can replace each Fj in \u03d5\u0304 by Ej(tj), so:\nE1(t1) \u00b7 \u2297 \u00b7 (E2(t2) \u00b7 \u2297 \u00b7 (. . . (Em\u22121(tm\u22121) \u00b7 \u2297 \u00b7 Em(tm)))) \u2192 Gn\nF1 \u2297 (F2 \u2297 (. . . (Fm\u22121 \u2297 Fm))) \u2192 Gn\nProof. This can be proven by using Lemma 7 to turn it into a \u2297-structure, and then apply Lemma 12 in combination with Lemma 5 m times. \u2293\u2294\nLemma 14. In E1(t1) \u00b7 \u2297 \u00b7 (E2(t2) \u00b7 \u2297 \u00b7 (. . . (Em\u22121(tm\u22121) \u00b7 \u2297 \u00b7Em(tm)))) \u2192 Gn, there is at least one occurrence of pi \u2298 (pi ; pi) in the lefthand-side for every 1 \u2264 i \u2264 n.\nProof. This sequence of E1(t1), . . . , Em(tm) represents the truthvalue of all variables, and because this is a satisfying assignment, for all i there is at least one index k such that \u00actkxk appears in clause i. By definition we have that Eik(tk) = pi \u2298 (pi ; pi). \u2293\u2294\nDefinition 3. Y ij \u21cc Ej(tj) with every occurrence of pk \u2298 (pk ; pk) replaced by pk for all i < k \u2264 n\nLemma 15. \u22a2LG Y 0 1 \u00b7 \u2297 \u00b7 (Y 0 2 \u00b7 \u2297 \u00b7 (. . . (Y 0 m\u22121 \u00b7 \u2297 \u00b7 Y 0 m))) \u2192 G0\nProof. Because Y 0j = Hj by definition for all 1 \u2264 j \u2264 m and G0 = H1 \u2297 (H2 \u2297 (. . . (Hm\u22121\u2297Hm))), this can be proven by applying the \u2297R rule m\u22121 times. \u2293\u2294\nLemma 16. If \u22a2LG Y i\u22121 1 \u00b7 \u2297 \u00b7 (Y i\u22121 2 \u00b7 \u2297 \u00b7 (. . . (Y i\u22121 m\u22121 \u00b7 \u2297 \u00b7 Y i\u22121 m ))) \u2192 Gi\u22121, then \u22a2LG Y i 1 \u00b7 \u2297 \u00b7 (Y i 2 \u00b7 \u2297 \u00b7 (. . . (Y i m\u22121 \u00b7 \u2297 \u00b7 Y i m))) \u2192 Gi\nProof. From Lemma 14 we know that pi \u2298 (pi ; pi) occurs in Y i 1 \u00b7 \u2297 \u00b7 (Y i 2 \u00b7 \u2297 \u00b7 (. . . (Y im\u22121 \u00b7 \u2297 \u00b7 Y i m))) (because the Y i j parts are Ej(tj) but with pk \u2298 (pk ; pk) replaced by pk only for k > i). Using Lemma 6 we can move the expression \u2298(pi ; pi) to the outside of the lefthand-side of the sequent, after which we can apply the \u2298R-rule. After this we can replace all other occurrences of pi\u2298(pi;pi) by pi using Lemma 10 and Lemma 5. This process can be summarized as:\nY i\u221211 \u00b7 \u2297 \u00b7 (Y i\u22121 2 \u00b7 \u2297 \u00b7 (. . . (Y i\u22121 m\u22121 \u00b7 \u2297 \u00b7 Y i\u22121 m ))) \u2192 Gi\u22121 pi ; pi \u2192 pi ; pi\n(Y i\u221211 \u00b7 \u2297 \u00b7 (Y i\u22121 2 \u00b7 \u2297 \u00b7 (. . . (Y i\u22121 m\u22121 \u00b7 \u2297 \u00b7 Y i\u22121 m )))) \u00b7 \u2298 \u00b7 (pi ; pi) \u2192 Gi\u22121 \u2298 (pi ; pi)\n\u2298R\nY i\u221211 \u00b7 \u2297 \u00b7 (Y i\u22121 2 \u00b7 \u2297 \u00b7 (. . . (Y i\u22121 m\u22121 \u00b7 \u2297 \u00b7 Y i\u22121 m ))) \u00b7 \u2298 \u00b7 (pi ; pi) \u2192 Gi\nDef\nY i1 \u00b7 \u2297 \u00b7 (Y i 2 \u00b7 \u2297 \u00b7 (. . . (Y i m\u22121 \u00b7 \u2297 \u00b7 Y i m))) \u2192 Gi\n14, 6, 10, 5\n\u2293\u2294\nLemma 17. \u22a2LG Y n 1 \u00b7 \u2297 \u00b7 (Y n 2 \u00b7 \u2297 \u00b7 (. . . (Y n m\u22121 \u00b7 \u2297 \u00b7 Y n m))) \u2192 Gn\nProof. We can prove this using induction with Lemma 15 as base and Lemma 16 as induction step. \u2293\u2294\nLemma 18. If \u03d5, then \u22a2LG \u03d5\u0304,\nProof. From Lemma 17 we know that \u22a2LG Y n 1 \u00b7\u2297\u00b7(Y n 2 \u00b7\u2297\u00b7(. . . (Y n m\u22121 \u00b7\u2297\u00b7Y n m))) \u2192 Gn, and because by definition Y n j = Ej(tj), we also have that \u22a2LG E1(t1) \u00b7 \u2297 \u00b7 (E2(t2) \u00b7\u2297 \u00b7 (. . . (Em\u22121(tm\u22121) \u00b7\u2297 \u00b7Em(tm)))) \u2192 Gn. Finally combining this with Lemma 13 we have that \u22a2LG \u03d5\u0304 = F1 \u2297 (F2 \u2297 (. . . (Fm\u22121 \u2297 Fm))) \u2192 Gn, using the assumption that \u03d5. \u2293\u2294"}, {"heading": "5.2 Only-if part", "text": "For the only if part we will need to prove that if \u22a2LG \u03d5\u0304, then \u03d5. Let us now assume that \u22a2LG \u03d5\u0304.\nLemma 19. If \u22a2LG X \u2192 P \u2032[(P \u2298Y )\u25e6], then there exist a Q such that Q is part of X or P \u2032 (possibly inside a formula in X or P \u2032) and \u22a2LG Y \u2192 Q.\nProof. The only rule that matches a \u2298 in the righthand-side is the \u2298R rule, so somewhere in the derivation this rule must be applied on the occurrence of P \u2298 Y . Because this rule needs a \u00b7 \u2298 \u00b7 connective in the lefthand-side, we know that if \u22a2LG X \u2192 P\n\u2032[(P \u2298 Y )\u25e6] it must be the case that we can turn this into X \u2032 \u00b7 \u2298 \u00b7Q \u2192 P \u2298 Y such that \u22a2LG Y \u2192 Q. \u2293\u2294\nLemma 20. If \u22a2LG E1(t1)\u00b7\u2297\u00b7(E2(t2)\u00b7\u2297\u00b7(. . . (Em\u22121(tm\u22121)\u00b7\u2297\u00b7Em(tm))) \u2192 Gn, then there is an occurrence pi \u2298 (pi ; pi) on the lefthand-side at least once for all 1 \u2264 i \u2264 n.\nProof. Gn by definition contains an occurrence of the expression \u2298(pi ; pi) for all 1 \u2264 i \u2264 n. From Lemma 19 we know that somewhere in the sequent we need an occurrence of a structure Q such that \u22a2LG pi;pi \u2192 Q. From the construction it is obvious that the only possible type for Q is in this case pi ; pi, and it came from the occurrence of pi \u2298 (pi ; pi) on the lefthand-side. \u2293\u2294\nLemma 21. If \u22a2LG E1(t1)\u00b7\u2297\u00b7(E2(t2)\u00b7\u2297\u00b7(. . . (Em\u22121(tm\u22121)\u00b7\u2297\u00b7Em(tm))) \u2192 Gn, then \u3008t1, t2, . . . , tm\u22121, tm\u3009 is a satisfying assignment for the CNF formula.\nProof. From Lemma 20 we know that there is a pi\u2298(pi;pi) in the lefthand-side of the formula for all 1 \u2264 i \u2264 n. From the definition we know that for each i there is an index j such that Eij(tj) = pi \u2298 (pi ; pi), and this means that \u00actjxj appears in clause i, so all clauses are satisfied. Hence, this choice of t1 . . . tm is a satisfying assignment. \u2293\u2294\nLemma 22. If 1 \u2264 j \u2264 m and \u22a2LG X \u2297[Fj ] \u2192 Gn, then \u22a2LG X \u2297[Ej(0)] \u2192 Gn or \u22a2LG X \u2297[Ej(1)] \u2192 Gn.\nProof. We know that X\u2297[Fj ] is a \u2297-structure, so we can apply the r rule several times to move all but the Fj -part to the righthand-side. We then have that \u22a2LG Fj \u2192 . . . \u00b7 \\ \u00b7 Gn \u00b7 / \u00b7 . . . . From Lemma 9 we know that we now have that \u22a2LG Ej(0) \u2192 . . . \u00b7 \\ \u00b7Gn \u00b7 / \u00b7 . . . or \u22a2LG Ej(1) \u2192 . . . \u00b7 \\ \u00b7Gn \u00b7 / \u00b7 . . . . Finally we can apply the r rule again to move all parts back to the lefthand-side, to show that \u22a2LG X \u2297[Ej(0)] \u2192 Gn or \u22a2LG X \u2297[Ej(1)] \u2192 Gn.\nNote that, in order for Lemma 9 to apply, we have to show that this sequent satisfies the constraints. Gn does contain A1 \u2297A2 with output polarity, however the only connectives in A1 and A2 are \u2297. Because no rules apply on A/((C/ C)\\C) \u2192 A\u20321 \u2297 A \u2032\u2032 1 , we have that 6\u22a2LG A/((C/C)\\C) \u2192 A1. In X\n\u2297[], the only \u2297 connectives are within other Fk, however these have an input polarity and do not break the constraints either.\nSo, in all cases Fj provides an explicit switch, which means that the truthvalue of a variable can only be changed in all clauses simultanously. \u2293\u2294\nLemma 23. If \u22a2LG \u03d5\u0304, then \u03d5.\nProof. From Lemma 22 we know that all derivations will first need to replace each Fj by either Ej(1) or Ej(0). This means that if \u22a2LG F1\u2297(F2\u2297(. . . (Fm\u22121\u2297 Fm))) \u2192 Gn, then also \u22a2LG E1(t1) \u00b7 \u2297 \u00b7 (E2(t2) \u00b7 \u2297 \u00b7 (. . . (Em\u22121(tm\u22121) \u00b7 \u2297 \u00b7 Em(tm))) \u2192 Gn for some \u3008t1, t2, . . . , tm\u22121, tm\u3009 \u2208 {0, 1}\nm. From Lemma 21 we know that this is a satisfying assignment for \u03d5, so if we assume that \u22a2LG \u03d5\u0304, then \u03d5. \u2293\u2294"}, {"heading": "5.3 Conclusion", "text": "Theorem 1. LG is NP-complete.\nProof. From Lemma 4 we know that for every derivable sequent there exists a proof that is of polynomial length, so the derivability problem for LG is in NP . From Lemma 18 and Lemma 23 we can conclude that we can reduce SAT to LG. Because SAT is a known NP-hard problem (Garey and Johnson, 1979), and our reduction is polynomial, we can conclude that derivability for LG is also NP-hard.\nCombining these two facts we conclude that the derivability problem for LG is NP-complete. \u2293\u2294"}], "references": [{"title": "The Non-associative Lambek Calculus with Product in Polynomial Time", "author": ["P. de Groote"], "venue": null, "citeRegEx": "Groote,? \\Q1999\\E", "shortCiteRegEx": "Groote", "year": 1999}, {"title": "On the computation of joins for non associative Lambek categorial grammars", "author": ["A. Foret"], "venue": "In Proceedings of the 17th International Workshop on Unification,", "citeRegEx": "Foret,? \\Q2003\\E", "shortCiteRegEx": "Foret", "year": 2003}, {"title": "Computers and Intractability: A Guide to the Theory of NP-Completeness", "author": ["M.R. Garey", "D.S. Johnson"], "venue": null, "citeRegEx": "Garey and Johnson,? \\Q1979\\E", "shortCiteRegEx": "Garey and Johnson", "year": 1979}, {"title": "Substructural logics on display", "author": ["R. Gor\u00e9"], "venue": "Logic Jnl IGPL,", "citeRegEx": "Gor\u00e9,? \\Q1998\\E", "shortCiteRegEx": "Gor\u00e9", "year": 1998}, {"title": "The non-associative Lambek calculus. Categorial Grammar, Linguistic and Literary Studies in Eastern Europe (LLSEE), 25:141\u2013151", "author": ["M. Kandulski"], "venue": null, "citeRegEx": "Kandulski,? \\Q1988\\E", "shortCiteRegEx": "Kandulski", "year": 1988}, {"title": "The Mathematics of Sentence Structure", "author": ["J. Lambek"], "venue": "American Mathematical Monthly,", "citeRegEx": "Lambek,? \\Q1958\\E", "shortCiteRegEx": "Lambek", "year": 1958}, {"title": "On the calculus of syntactic types", "author": ["J. Lambek"], "venue": "Structure of Language and Its Mathematical Aspects,", "citeRegEx": "Lambek,? \\Q1961\\E", "shortCiteRegEx": "Lambek", "year": 1961}, {"title": "The generative capacity of the Lambek-Grishin calculus: A new lower bound", "author": ["M. Melissen"], "venue": "Proceedings 14th conference on Formal Grammar,", "citeRegEx": "Melissen,? \\Q2009\\E", "shortCiteRegEx": "Melissen", "year": 2009}, {"title": "Symmetries in Natural Language Syntax and Semantics: The Lambek-Grishin Calculus. In Logic, Language, Information and Computation, volume 4576 of Lecture Notes in Computer Science, pages 264\u2013284", "author": ["M. Moortgat"], "venue": null, "citeRegEx": "Moortgat,? \\Q2007\\E", "shortCiteRegEx": "Moortgat", "year": 2007}, {"title": "Symmetric categorial grammar", "author": ["M. Moortgat"], "venue": "Journal of Philosophical Logic,", "citeRegEx": "Moortgat,? \\Q2009\\E", "shortCiteRegEx": "Moortgat", "year": 2009}, {"title": "Lambek grammars are context free", "author": ["M. Pentus"], "venue": "In Proceedings of the 8th Annual IEEE Symposium on Logic in Computer Science,", "citeRegEx": "Pentus,? \\Q1993\\E", "shortCiteRegEx": "Pentus", "year": 1993}, {"title": "Lambek calculus is NP-complete", "author": ["M. Pentus"], "venue": "CUNY Ph.D. Program in Computer Science Technical Report TR\u20132003005,", "citeRegEx": "Pentus,? \\Q2003\\E", "shortCiteRegEx": "Pentus", "year": 2003}, {"title": "Product-Free Lambek Calculus Is NP-Complete", "author": ["Y. Savateev"], "venue": "Proceedings of the 2009 International Symposium on Logical Foundations of Computer Science,", "citeRegEx": "Savateev,? \\Q2009\\E", "shortCiteRegEx": "Savateev", "year": 2009}], "referenceMentions": [{"referenceID": 5, "context": "In his 1958 and 1961 papers, Lambek formulated two versions of the Syntactic Calculus : in (Lambek, 1958), types are assigned to strings, which are then combined by an associative operation; in (Lambek, 1961), types are assigned to phrases (bracketed strings), and the composition operation is non-associative.", "startOffset": 91, "endOffset": 105}, {"referenceID": 6, "context": "In his 1958 and 1961 papers, Lambek formulated two versions of the Syntactic Calculus : in (Lambek, 1958), types are assigned to strings, which are then combined by an associative operation; in (Lambek, 1961), types are assigned to phrases (bracketed strings), and the composition operation is non-associative.", "startOffset": 194, "endOffset": 208}, {"referenceID": 3, "context": "As for generative power, Kandulski (1988) proved thatNL defines exactly the context-free languages.", "startOffset": 25, "endOffset": 42}, {"referenceID": 3, "context": "As for generative power, Kandulski (1988) proved thatNL defines exactly the context-free languages. Pentus (1993) showed that this also holds for associative L.", "startOffset": 25, "endOffset": 114}, {"referenceID": 0, "context": "As for the complexity of the derivability problem, de Groote (1999) showed that for NL this belongs to PTIME; for L, Pentus (2003) proves that the problem is NP-complete and Savateev (2009) shows that NP-completeness also holds for the product-free fragment of L.", "startOffset": 54, "endOffset": 68}, {"referenceID": 0, "context": "As for the complexity of the derivability problem, de Groote (1999) showed that for NL this belongs to PTIME; for L, Pentus (2003) proves that the problem is NP-complete and Savateev (2009) shows that NP-completeness also holds for the product-free fragment of L.", "startOffset": 54, "endOffset": 131}, {"referenceID": 0, "context": "As for the complexity of the derivability problem, de Groote (1999) showed that for NL this belongs to PTIME; for L, Pentus (2003) proves that the problem is NP-complete and Savateev (2009) shows that NP-completeness also holds for the product-free fragment of L.", "startOffset": 54, "endOffset": 190}, {"referenceID": 0, "context": "As for the complexity of the derivability problem, de Groote (1999) showed that for NL this belongs to PTIME; for L, Pentus (2003) proves that the problem is NP-complete and Savateev (2009) shows that NP-completeness also holds for the product-free fragment of L. It is well known that some natural language phenomena require generative capacity beyond context-free. Several extensions of the Syntactic Calculus have been proposed to deal with such phenomena. In this paper we look at the Lambek-Grishin calculus LG (Moortgat, 2007, 2009). LG is a symmetric extension of the nonassociative Lambek calculus NL. In addition to \u2297, \\, / (product, left and right division), LG has dual operations \u2295,;,\u2298 (coproduct, left and right difference). These two families are related by linear distributivity principles. Melissen (2009) shows that all languages which are the intersection of a context-free language and the permutation closure of a context-free language are recognizable in LG.", "startOffset": 54, "endOffset": 822}, {"referenceID": 3, "context": "The axioms and inference rules are presented in Figure 1, where we use the display logic from (Gor\u00e9, 1998), but with different symbols for the structural connectives.", "startOffset": 94, "endOffset": 106}, {"referenceID": 3, "context": "The axioms and inference rules are presented in Figure 1, where we use the display logic from (Gor\u00e9, 1998), but with different symbols for the structural connectives. It has been proven by Moortgat (2007) that we have Cut admissibility for LG.", "startOffset": 95, "endOffset": 205}, {"referenceID": 0, "context": "P [] ::= [] | P [] \u00b7 \u2295 \u00b7Q | Q \u00b7 \u2295 \u00b7 P [] | P [] \u00b7 / \u00b7 Y | Q \u00b7 / \u00b7X [] | Y \u00b7 \\ \u00b7 P [] | X [] \u00b7 \\ \u00b7Q This notation is similar to the one of de Groote (1999) but with structures.", "startOffset": 141, "endOffset": 155}, {"referenceID": 5, "context": "The type simililarity relation \u223c, introduced by Lambek (1958), is the reflexive transitive symmetric closure of the derivability relation.", "startOffset": 48, "endOffset": 62}, {"referenceID": 1, "context": "This is also the solution given by Lambek (1958) for the associative system L, but in fact this is the shortest solution for the non-associative system NL (Foret, 2003).", "startOffset": 155, "endOffset": 168}, {"referenceID": 4, "context": "This is also the solution given by Lambek (1958) for the associative system L, but in fact this is the shortest solution for the non-associative system NL (Foret, 2003).", "startOffset": 35, "endOffset": 49}, {"referenceID": 5, "context": "In this section we will show that we can reduce a Boolean formula in conjunctive normal form to a sequent of the Lambek-Grishin calculus, so that the corresponding LG sequent is provable if and only if the CNF formula is satisfiable. This has already been done for the associative system L by Pentus (2003) with a similar construction.", "startOffset": 113, "endOffset": 307}, {"referenceID": 2, "context": "Because SAT is a known NP-hard problem (Garey and Johnson, 1979), and our reduction is polynomial, we can conclude that derivability for LG is also NP-hard.", "startOffset": 39, "endOffset": 64}], "year": 2017, "abstractText": "The Lambek-Grishin calculus LG is the symmetric extension of the non-associative Lambek calculus NL. In this paper we prove that the derivability problem for LG is NP-complete.", "creator": "LaTeX with hyperref package"}}}