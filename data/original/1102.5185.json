{"id": "1102.5185", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2011", "title": "Universal Higher Order Grammar", "abstract": "We examine the class of languages that can be defined entirely in terms of provability in an extension of the sorted type theory (Ty_n) by embedding the logic of phonologies, without introduction of special types for syntactic entities. This class is proven to precisely coincide with the class of logically closed languages that may be thought of as functions from expressions to sets of logically equivalent Ty_n terms. For a specific sub-class of logically closed languages that are described by finite sets of rules or rule schemata, we find effective procedures for building a compact Ty_n representation, involving a finite number of axioms or axiom schemata. The proposed formalism is characterized by some useful features unavailable in a two-component architecture of a language model. A further specialization and extension of the formalism with a context type enable effective account of intensional and dynamic semantics.", "histories": [["v1", "Fri, 25 Feb 2011 08:13:10 GMT  (34kb)", "http://arxiv.org/abs/1102.5185v1", "48 pages"]], "COMMENTS": "48 pages", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["victor gluzberg"], "accepted": false, "id": "1102.5185"}, "pdf": {"name": "1102.5185.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["gluzberg@netvision.net.il"], "sections": [{"heading": null, "text": "ar X\niv :1\n10 2.\n51 85\nv1 [\ncs .C\nL ]\n2 5\nFe b\n20 11\nWe examine the class of languages that can be defined entirely in terms of provability in an extension of the sorted type theory (Tyn) by embedding the logic of phonologies, without introduction of special types for syntactic entities. This class is proven to precisely coincide with the class of logically closed languages that may be thought of as functions from expressions to sets of logically equivalent Tyn terms. For a specific sub-class of logically closed languages that are described by finite sets of rules or rule schemata, we find effective procedures for building a compact Tyn representation, involving a finite number of axioms or axiom schemata. The proposed formalism is characterized by some useful features unavailable in a two-component architecture of a language model. A further specialization and extension of the formalism with a context type enable effective account of intensional and dynamic semantics."}, {"heading": "1 Introduction", "text": "Traditionally higher-order logic representation of natural language semantics (Thomason, 1974) had to be combined with an additional formalism to describe a syntactic structure of a language and a mapping between the two. This two-component architecture of a language model has not essentially changed with the invention and further rapid development of type-logical grammar (Lambek, 1958; Blackburn et al., 1997), i.e. a parallel logical formalism to describe a syntactic structure: in spite of the very close and deep correspondence between the two logics, their internal languages and semantics remain different.\nSeveral theoretical, methodological and technological issues are rooted in the two-component architecture of a language model, out of which it is important to mention here the following.\n1. A language in such a model cannot express anything about another language of the same model nor, of course, about itself. This kind of expressiveness is, however, one of the characteristic capabilities of a natural language.\n2. Lack of lexical robustness. As the semantic interpretation of a sentence in the two-component language model can be composed only from semantic interpretations of all its constituents, such a model fails to interpret an entire sentence if it contains even a single unrecognized (new) word. Some ad hoc add-ins to the formalism are the only known solution of the issue.\n3. Lack of structural (syntactic) robustness. Unlike the semantic logic, which may be universally applicable for a wide variety of languages, the syntactic logic often requires special extensions in order to cover different languages and even specific structures in the same language. Capturing the semantic categories and their relationships in the very formalism (rather than in a concrete language model) makes it principally incapable of modeling language self-learning, that is derivation of new grammar rules from text samples.\nThese, along with some other issues and needs motivated researches for generalizations based on a single logical system, applicable to both semantics and syntactic structure of a language together, such like (Kasper & Rounds, 1986), (King, 1989) and (Richter, 2004). Higher Order Grammar (HOG) (Pollard & Hana, 2003; Pollard, 2004; Pollard, 2006) is probably the most recent implementation of the idea and the first one based entirely on the mainstream classical higher-order logic (HOL), traditionally applied only to the semantics of natural languages. The specific HOL employed in HOG comes in result of the following main steps:\n1. introduction of a phonological base type and a constant denoting operation of concatenation of phonologies;\n2. introduction of abstract syntax entity base types and constructors of derived types, comprising (together with these base types) a type kind SIGN;\n3. introduction of another type kind HIPER for semantic interpretations, which consists of basic types of individuals and propositions and derived types - functional, product and of function to the boolean type;\n4. embedding all the three logics - of phonologies, signs and hyperintensions - into a single HOL with fixing a correspondence between SIGN and HIPER types and adding the two special families of constants denoting functions from signs to phonologies and from signs to semantic interpretations of corresponding types.\nA concrete language is modeled in HOG by adding a set of non-logical axioms to postulate semantics and phonology of specific words and rules of their composition.\nDue to introduction of the phonological type and constants for mapping signs to phonologies, HOG model is certainly better prepared for a formal account of lexical robustness. Also, since directionality in HOG can be handled by the phonological interpretation, it is sufficient for it to have a single universal sign type constructor (implication) that partially addresses the issue of structural robustness. However, as the syntactic and semantic type kinds are fully separated, HOG still cannot address the issue of self-expressiveness.\nAnother important implication of the HOG architecture, as it was noticed in (Gluzberg, 2009), is that semantic interpretation of any sentence or a constituent of it turns out to be represented not by a single HOL term, nor even by a set of some arbitrarily selected terms (in case of ambiguity), but by a whole class of logically equivalent terms, in a precise sense defined in the referenced work. Referring to languages revealing this semantic property as to logically closed languages, one can say that all HOG-defined languages are necessarily logically closed. It was also explained in (Gluzberg, 2009) why the inverse question, i.e. whether any logically closed language can be defined by a HOG with a given set of base SIGN types and type constructors, cannot be answered positively. This result gives another evidence of the limited robustness of the HOG model.\nIn the present work we examine what can be achieved by embedding into a HOL only the logic of phonologies, without introduction of special types for syntactic entities, but with use of non-logical constants of regular functional types to define syntax-to-phonology and syntax-to-semantics interfaces in a concrete language model. As such a language representation is, as well as HOG, entirely based on provability in the single HOL, all the languages it can model are still logically closed. The main result of this work consists of a proof of the inverse statement: any logically closed language can be represented in the proposed HOL framework. This justifies our referring to it as to Universal Higher-Order Grammar. Being fully free of embedded\nsyntactic restrictions and of limitations on types of semantic interpretations, this formalism can efficiently address all the issues with the two-component architecture of a language model mentioned above and therefore may have several theoretical and practical implications.\nThe structure of the paper is as follows. After the introduction in Section 2 of basic notations and some assumptions on the axiomatization of a sorted type theory (Tyn), in Section 3 we define the class of logically closed languages and introduce a few basic operations that act within this class.\nIn Section 4 we define an extension TyAn of Tyn by interpreting one of its base types as symbolic, which is quite similar to the phonological type of HOG, and introduce the notion of Tyn-representability of a language, illustrated with a few preliminary examples.\nThen in Section 5 we prove that classes of Tyn-representable and logically closed languages precisely coincide.\nIn the following sections we give explicit constructions of special Tyn representations for some important sub-classes of logically closed languages that are described by finite sets of rules or rule schemata.\nIn Section 6 we consider so-called lexicons, i.e. finitely generated logically closed languages, define special canonic Tyn representation and prove that a language has a canonic representation if and only if it is a lexicon.\nIn Section 7 a Tyn representation is built for a recursive logically closed grammar (RG), defined as a tuple of logically closed languages linked with each other by a set of relationships expressed by the basic operations introduced in Section 3. As it becomes clear from illustrating examples, the language components of an RG stand for syntactic categories.\nIn Section 8 we consider a further specialization of TyAn by interpreting another base type as a context, similar (though not identical) to \u201dstate of affairs\u201d or \u201dWorld\u201d types of (Gallin, 1975) and (Pollard, 2005), respectively. This specialization allows to represent also intensional languages and further define instructive and context-dependent languages. Introduction of a few new language construction operations then allows us to generalize the previous results to context-dependent languages. We demonstrate some important capabilities of this formalism by examples of how it addresses pronoun anaphora resolution.\nIn Section 9 we introduce translation and expression operators that lead to a special language representation, revealing a useful property of partial translation.\nIn Section 10 we conclude by briefly summarizing and discussing the most important implications of the obtained results and outline some open issues."}, {"heading": "2 Notations", "text": "Following (Gallin, 1975), we denote by Tyn a sorted type theory with a set of primitive types consisting of the truth type t and individual types e1, e2, ... en of n > 1 different sorts. For the first individual type we will also use a shorter alias e =def e1. For sake of better visibility and compactness we combine the full syntax of Tyn from syntaxes of Ty2 of (Gallin, 1975) and Q0 of (Andrews, 1986) and extend it as follows.\nDerived types\n(i) If \u03b1 and \u03b2 are types, then (\u03b1\u03b2) or just \u03b1\u03b2 is a functional type, interpreted as type of functions from \u03b1 to \u03b2. The parenthesis are mandatory only in complex types, in order to express association in an order other than from right to left, for example: et, tee, (et)e are equivalent to (et), (t(ee)), ((et)e). Note that, unlike (Andrews, 1986), we write \u201cfrom\u201d and \u201cto\u201d types from left to right.\n(ii) If \u03b1 and \u03b2 are types, then (\u03b1 \u00d7 \u03b2) or just \u03b1 \u00d7 \u03b2 is a product type, interpreted as type of pairs of elements from \u03b1 and \u03b2, so that, for example, (\u03b1 \u00d7 \u03b2)\u03b3 is equivalent to \u03b1\u03b2\u03b3 and \u03b3(\u03b1 \u00d7 \u03b2) to \u03b3\u03b1 \u00d7 \u03b3\u03b2. Repeated product constructors are also associated from right to left, i.e. (\u03b1\u00d7 \u03b2 \u00d7 \u03b3) is equivalent to (\u03b1\u00d7 (\u03b2 \u00d7 \u03b3)).\nVariables\nx, y, z subscripted by types and optionally superscripted by integer indices stand for variables of corresponding types, for example: yet, x 1 e, x 2 e.\nConstants\nNon-logical constants are written as capital C in bold, subscripted by a type and superscripted by an index, like C0t . We do not assume Tyn to necessarily have a constant Ci\u03b1 of a given type \u03b1 for any index i. Rather, we assume the constants to be indexed in such a way that admits expanding Tyn by arbitrarily many new constants of any type. We also use arbitrary letters or words in bold (likeAssert or Empty) as mnemonic aliases for some constant\nthat are assumed to have special semantics or/and satisfy some non-logical axioms in an extension of Tyn. Similar notations may also be introduced for some logical constants, i.e. pure bound terms, like, for example, identity I\u03b1\u03b1 =def \u03bbx\u03b1x\u03b1.\nTerms\n(i) Variables and constants comprise elementary terms.\n(ii) If A\u03b1\u03b2 and B\u03b1 are terms of the corresponding types, then application A\u03b1\u03b2 B\u03b1 is a term of type \u03b2 denoting (in an interpretation of Tyn) the value of the function denoted by A\u03b1\u03b2 at the argument denoted by B\u03b1.\n(iii) If A\u03b2 is a term of type \u03b2 then lambda abstraction \u03bbx\u03b1A\u03b2 is a term of type \u03b1\u03b2 denoting a function whose value for any argument is the denotation of A\u03b2.\n(iv) If A\u03b1 and B\u03b1 are terms of type \u03b1, then A\u03b1 = B\u03b1 is a term of type t, denoting the identity relation between elements of type \u03b1.\n(v) If A\u03b1 and B\u03b2 are terms of the corresponding types, then the pair (A\u03b1, B\u03b2) is a term of type \u03b1 \u00d7 \u03b2 denoting the ordered pair of denotations of A\u03b1 and B\u03b2; repeated operators (, ) are associated from right to left, so that a tuple (A1\u03b11 , A 2 \u03b12 , ...Am\u03b1m) denotes the same as\n(A1\u03b11 , (A 2 \u03b12 , (...Am\u03b1m)...)).\n(vi) Finally, for a term A\u03b1\u00d7\u03b2 of a type \u03b1\u00d7\u03b2, projections \u03c01A\u03b1\u00d7\u03b2 and \u03c02A\u03b1\u00d7\u03b2 are terms of types \u03b1 and \u03b2 respectively, denoting the elements of the pair denoted by A\u03b1\u00d7\u03b2 .\nWe assume an axiomatization of Tyn be a straightforward generalization to case of n > 2 individual types of either the theory denoted as Tyn + D in (Gallin, 1975) or the theory Q0 of (Andrews, 1986). With either choice, for any type \u03b1 the description operator \u03b9(\u03b1t)\u03b1 and hence the \u201dif-then-else\u201d constant C\u03b1\u03b1t\u03b1 are available with the fundamental properties\n\u22a2 \u03b9(\u03b1t)\u03b1 \u03bbx\u03b1(y\u03b1 = x\u03b1) = y\u03b1\n\u22a2 C\u03b1\u03b1t\u03b1 x\u03b1 y\u03b1 T = xa, \u22a2 C\u03b1\u03b1t\u03b1 x\u03b1 y\u03b1 F = ya.\nAll the usual Boolean connectives, including terms F and T denoting the false and true values, and quantifiers can be defined in Tyn exactly the\nsame way as in Ty2 and Q0. In addition, we will also employ the following notational shortcuts:\nA\u03b1 6= B\u03b1 =def \u223c (A\u03b1 = B\u03b1),\n\u223c A\u03b1t =def \u03bbx\u03b1 \u223c (A\u03b1t x\u03b1),\nA\u03b1t \u2228B\u03b1t =def \u03bbx\u03b1(A\u03b1t x\u03b1 \u2228 B\u03b1t x\u03b1),\nA\u03b1t \u2227B\u03b1t =def \u03bbx\u03b1(A\u03b1t x\u03b1 \u2227 B\u03b1t x\u03b1),\nA\u03b1t &B\u03b2t =def \u03bbx\u03b1\u03bbx\u03b2(A\u03b1t x\u03b1 & B\u03b2t x\u03b2),\nA\u03b1t \u2192 B\u03b2t =def \u2200x\u03b1(A\u03b1t x\u03b1 \u2192 B\u03b1t x\u03b1),\nA\u03b1|B\u03b1 =def C\u03b1\u03b1t\u03b1 A\u03b1 B\u03b1,\nand, for an arbitrary binary operator O:\n(O B\u03b2) =def \u03bbx\u03b1(x\u03b1 O B\u03b2),\n(A\u03b1 O) =def \u03bbx\u03b2(A\u03b1 O x\u03b2),\n(O) =def \u03bbx\u03b1\u03bbx\u03b2(x\u03b1 O x\u03b2),\n(an operator sign in such shortcuts might be subscripted by a type, like, for example, (=eet) to denote specifically \u03bbxe\u03bbye(xe = ye).\nIn the meta-language:\n(i) the \u22a2 sign denotes provability in Tyn or an extension of it, specified by a context;\n(ii) the notation A\u03b1(B\u03b2) stands for the result of substituting all occurrences of a free variable x\u03b2 in a term A\u03b1 by a term B\u03b2 free for x\u03b2 in A\u03b1;\n(iii) if M is a model of Tyn and a - an assignment of variables in this model, then J\u00b7KM denotes interpretation of a constant in M and J\u00b7KM,a denotes the value of an arbitrary term assigned to it by a in M ;\n(iv) =\u21d2 and \u21d0\u21d2 express implication and logical equivalence."}, {"heading": "3 Logically closed languages", "text": "The two fundamental formalizations of the notion of language with which we deal in this work - \u03b1-language and logically closed \u03b1-language have been introduced and informally discussed in (Gluzberg, 2009). We reproduce these\nformal definitions here with the current notations for more convenient references.\nDefinition 3.1. Let A be a finite alphabet {a1, a2, ... aN}, let A\u2217 denote the set of all words over this alphabet and let T\u03b1 denote the set of all \u03b1-terms of Tyn. An \u03b1-language is a relation L \u2282 A \u2217 \u2297 T\u03b1.\nReferring to words over alphabet A as \u201cexpressions\u201d and \u03b1-terms as \u201c\u03b1meanings,\u201d one can say that an \u03b1-language is a set of pairs of expressions and their \u03b1-meanings. A set of words L \u2282 A\u2217 can then be considered as a language for the unit type meaning. In general case, the projection of L to A\u2217 is the set of all valid expressions of L, to which set we refer as to domain of the language and the projection of L to T\u03b1 is the set of all meanings L can express, to which set we refer as to range of the language.\nA trivial particular case of an \u03b1-language is a singleton {(w,A\u03b1)}, where w \u2208 A\u2217.\nIf L and K are \u03b1-languages, then their union L \u222a K is a new \u03b1-language that contains all expressions and corresponding meanings of both L and K.\nThe following definitions introduce some further operations to build complex languages from simpler ones.\nDefinition 3.2. If L is an \u03b1-language and K is a \u03b2-language, then their language concatenation is the \u03b1\u00d7 \u03b2-language\nL \u2217 K =def {(uv, (A\u03b1, B\u03b2)) | (u,A\u03b1) \u2208 L \u2227 (v, B\u03b2) \u2208 K}\nwhere uv denotes concatenation of words u and v.\nDefinition 3.3. For a given \u03b1-language L and a relation R \u2282 T\u03b1 \u2297 T\u03b2, the semantic rule application is the \u03b2-language\nL \u22b2R =def {(w,B\u03b2) | (w,A\u03b1) \u2208 L \u2227 (A\u03b1, B\u03b2) \u2208 R}.\nThus, application of a semantic rule cannot extend the domain of a language, but only maps the set of meanings of every its expression to another set (generally of a different type); if the new set turns out to be empty, then the corresponding expression is \u201dfiltered out\u201d from the domain of resulting language. An important example of a semantic rule application is \u201dfolding\u201d product-type meanings of a concatenation of two languages to meanings of a scalar type. Note that a folding rule which also filters out some expressions\nfrom the language concatenation in fact can check an agreement between the concatenated constituents (at the semantic level).\nThe above definition of an \u03b1-language seems to provide the most general formalization for the notion of a language whose distinct meanings are understood as syntactically different (although possibly logically equivalent) Tyn terms of a certain type. For example, the representation of Tyn formulas in the Tyn language is itself a t-language. In the application to natural languages, however, a more restricted formalization might be more suitable:\nDefinition 3.4. A logically closed \u03b1-language is an \u03b1-language L such that whenever (w,B\u03b1) \u2208 L, (w,C\u03b1) \u2208 L and \u22a2 A\u03b1 = B\u03b1 \u2228 A\u03b1 = C\u03b1 then (w,A\u03b1) \u2208 L also. A minimal logically closed \u03b1-language L which includes a given arbitrary \u03b1-language L is said to be its logical closure.\nThis definition actually captures the two important features of a logically closed \u03b1-language:\n1. If an expression w in the language has a meaning B\u03b1, then it also has every meaning A\u03b1 logically equivalent to B\u03b1\n2. If an expression w is ambiguous, i.e. has at least two distinct meanings B\u03b1 and C\u03b1 being not logically equivalent, then it also has every meaning A\u03b1 which is provable to be equal either B\u03b1 or C\u03b1.\nTherefore, every valid expression of a logically closed language is associated not with a single, nor even with a set of arbitrarily selected terms (in case of ambiguity), but with a whole class of logically equivalent terms. A precise formulation of this interpretation follows.\nDefinition 3.5. A set M \u2282 T\u03b1 is said to be logically closed iff whenever B\u03b1 \u2208 M, C\u03b1 \u2208 M and\n\u22a2 A\u03b1 = B\u03b1 \u2228A\u03b1 = C\u03b1 (3.1)\nthen A\u03b1 \u2208 M also. A minimal logically closed set M \u2282 T\u03b1 which includes an arbitrary set M \u2282 T\u03b1 is said to be its logical closure. If in addition, N \u2282 T\u03b1 and M = N , we say the two sets M and N be logically equivalent and denote this relation as M \u2243 N .\nIt is readily seen that \u2243 is an equivalence relation in the power set P(T\u03b1) and therefore a logically closed \u03b1-language might be defined equivalently as a function L : A\u2217 \u2192 P(T\u03b1)/ \u2243.\nThe simplest non-empty logically closed \u03b1-language is a logical singleton\nS = {w} \u2297 {A\u03b1}. (3.2)\nAs it has been shown in (Gluzberg, 2009), any language defined by a Higher Order Grammar (HOG) (Pollard & Hana, 2003; Pollard, 2004; Pollard, 2006) is necessarily logically closed.\nNote that the class of logically closed languages is not closed under the union operation nor under operations of language concatenation and semantic rule applications defined above. Similar operations that act within this class can be defined as follows.\nDefinition 3.6. If L and K are \u03b1-languages, then their logical join is an \u03b1-language L\u222aK =def L \u222a K.\nDefinition 3.7. If L is an \u03b1-language and K is a \u03b2-language, then their logical concatenation is an \u03b1\u00d7 \u03b2-language L\u2217K =def L \u2217 K.\nDefinition 3.8. A semantic rule R \u2282 T\u03b1 \u2297 T\u03b2 is said to be logically closed if the full image of any logically closed set M \u2282 T\u03b1 under the relation R is logically closed.\nThus, a logical join and logical concatenation of arbitrary languages, as well as application of a logically closed semantic rule to any language of the matching type, are all logically closed languages.\nThe following associativity and monotonicity properties follow directly from the above definitions.\nLemma 3.1. For any \u03b1-languages K,L, a \u03b2-language M and a rule R \u2282 T\u03b1 \u2297 T\u03b2,\n(K\u222aL) \u2217M = K\u2217M \u222a L\u2217M,\nM\u2217(K\u222aL) = M\u2217K \u222a M\u2217L,\n(K\u222aL) \u22b2R = K \u22b2R \u222a L \u22b2R,\nK \u2282 L =\u21d2 K\u2217M \u2282 L\u2217M,\nK \u2282 L =\u21d2 M\u2217K \u2282 M\u2217L,\nK \u2282 L =\u21d2 K \u22b2R \u2286 L \u22b2R.\nDefinition 3.9. A logically closed set M \u2282 T\u03b1 is said to be finitely generated if it is the logical closure of a finite set M \u2282 T\u03b1.\nDefinition 3.10. A logically closed semantic rule R \u2282 T\u03b1 \u2297 T\u03b2 is said to be finitely ambiguous if for any term A\u03b1, the full image of {A\u03b1} under the relation R is finitely generated.\nAn important class of finitely ambiguous semantic rules is given by the following\nDefinition 3.11. A logically closed semantic rule R \u2282 T\u03b1 \u2297 T\u03b2 is said to have a canonic representation in D\u03b1 \u2282 T\u03b1 if there exists a TyAn term R\u03b1\u03b2t such that\n(A\u03b1, B\u03b2) \u2208 R \u21d0\u21d2 \u22a2 R\u03b1\u03b2t A\u03b1 B\u03b2\nand for any A\u03b1 \u2208 D\u03b1\n\u22a2 R\u03b1\u03b2t A\u03b1 = k\u2228\ni=1\n(= Bi\u03b2),\nwhere the terms B1\u03b2 , ... B k \u03b2 as well as the number k may depend on A\u03b1 and in the case k = 0 the disjunction is reduced to \u03bbx\u03b2F. We further qualify a rule with a canonic representation in D\u03b1 \u2282 T\u03b1 as non-degenerate, degenerate, unambiguous or ambiguous in D\u03b1, if k > 0 for all A\u03b1 \u2208 D\u03b1, k = 0 for some A\u03b1 \u2208 D\u03b1, k = 1 for all A\u03b1 \u2208 D\u03b1 or k > 1 for some A\u03b1 \u2208 D\u03b1, respectively.\nAn important example of a semantic rule with a canonic representation in any domain is given by a particular case where\nR\u03b1\u03b2t =def \u03bbx\u03b1(= F\u03b1\u03b2 x\u03b1)\nwhich is referred to below as a functional semantic rule. Note that a functional rule is both non-degenerate and unambiguous in any domain.\n4 Symbolic type and Tyn-representable\nlanguages\nConsider an extension TyAn of Tyn with the following set of non-logical axioms, where s denotes the primitive type en and As +Bs =def C 0 sss As Bs:\n\u2200xs((xs +C 0 s = xs) \u2227 (C 0 s + xs = xs)), (4.1)\n\u2200xs\u2200ys\u2200zs((xs + ys) + zs = xs + (ys + zs)), (4.2)\n\u2200xs\u2200ys\u2200zs(xs +C i s + ys 6= xs +C j s + zs), for all 1 \u2264 i < j \u2264 N. (4.3)\nIt is easy to see that these axioms are valid in a model M with the s-domain Ds =def A\u2217 and interpretation J\u00b7KM such that JC0sKM is the empty word \u01eb \u2208 A\u2217, JCisKM is ai \u2208 A for 1 \u2264 i \u2264 N , all the rest of the s-constants are interpreted by compound words from A\u2217 and, finally, the operation (+) is interpreted as the operation of word concatenation. This observation proves the consistency of TyAn and justifies our referring to the type s as symbolic type. Note that formally, with the accuracy up to the additional axiom 4.3, the symbolic type is quite similar to the phonological type of HOG (Pollard, 2006). We use the different term here in order to reflect the additional axiomatic restriction, expressing distinction of the alphabet symbols, significant in any context, and also keeping in mind that generally they may stand for symbols of an arbitrary nature, for example, graphic, as well as phonetic, in which case TyAn might be further extended to accommodate more symbol aggregation operations in addition to the linear concatenation.\nTyAn allows some \u03b1-languages to be naturally defined by its terms or possibly by the terms of its extension TyA+n with a set of additional nonlogical constants. Indeed, define the mapping TA : A\u2217 \u2192 Ts as follows\nTA(\u01eb) = C 0 s, TA(ai) = C i s, TA(aiw) = C i s + TA(w), (4.4)\nand let \u2206 be a consistent set of TyA+n formulas. Then the condition\n\u2206 \u22a2 Ls\u03b1t TA(w) A\u03b1\nfor any TyA+n term Ls\u03b1t defines an \u03b1-language (\u22a2 here and everywhere below denotes provability in TyA+n ).\nDefinition 4.1. Let TyA+n be an extension of Ty A n , \u2206 a consistent set of Ty A+ n formulas and Ls\u03b1t a Ty A+ n term. An \u03b1-language L is said to be represented by (\u2206, Ls\u03b1t) if for any Ty A n term A\u03b1 and w \u2208 A \u2217\n(w,A\u03b1) \u2208 L \u21d0\u21d2 \u2206 \u22a2 Ls\u03b1t TA(w) A\u03b1.\nNote that in the case of a finite set \u2206, by the Deduction Theorem, a language represented by (\u2206, Ls\u03b1t) is also represented by (\u2205, \u03bbxs\u03bbx\u03b1(Dt \u2192 Ls\u03b1txsx\u03b1)) where Dt is the conjunction of all formulas of \u2206 and the variables xs, x\u03b1 are not free in Dt. In this case we say the language to have a compact Tyn representation or, alternatively, to be represented by a term.\nDefinition 4.2. An \u03b1-language L is said to be representable in TyAn , or Tynrepresentable for short, if there exists an extension TyA+n of Ty A n , a consistent set \u2206 of TyA+n formulas and a Ty A+ n term Ls\u03b1t such that L is represented by (\u2206, Ls\u03b1t).\nHere are a few simple examples of Tyn-representable languages:\n\u2022 the term (= TA(w)) &(= A\u03b1) represents a logical singleton (3.2);\n\u2022 the term \u03bbxs(= C0s\u03b1 xs) represents an \u03b1-language where every word w is a valid expression for the application C0s\u03b1 TA(w);\n\u2022 the term (=sst) represents an s-language that realizes the mapping (4.4), i.e. associates with every word w a single \u201cmeaning\u201d TA(w).\nIn case of alphabet A consisting of symbols that can be typed in this paper (including a space), a more convenient notation for mapping TA can be introduced: if w is an arbitrary string of such symbols, let /w/ =def TA(w). Then, by definition 4.1, for arbitrary strings u, v, /u/ + /v/ = /uv/; for example: /c/+/a/+/r/ = /car/. We will make use of this practical notation in some of subsequent sections.\n5 Tyn representation existence theorem\nWe now show that an \u03b1-language is Tyn-representable if and only if it is logically closed.\nProposition 5.1. If an \u03b1-language L is Tyn-representable, then it is logically closed.\nProof. Let (\u2206, Ls\u03b1t) be a representation of L, w \u2208 A\u2217,\n\u2206 \u22a2 Ls\u03b1t TA(w)B\u03b1, \u2206 \u22a2 Ls\u03b1t TA(w) C\u03b1 and \u22a2 A\u03b1 = B\u03b1 \u2228A\u03b1 = C\u03b1.\nFrom this derivation, by the metatheorems\n\u22a2 At \u2228 Bt = (At|Bt)Bt, (5.1)\n\u22a2 (P\u03b1\u03b2 A\u03b1|P\u03b1\u03b2 B\u03b1) Ct = P\u03b1\u03b2((A\u03b1|B\u03b1) Ct), (5.2)\nit follows that \u22a2 A\u03b1 = (B\u03b1|C\u03b1) (A\u03b1 = C\u03b1)\nand\n\u22a2 Ls\u03b1t TA(w)A\u03b1 = (Ls\u03b1t TA(w)B\u03b1 | Ls\u03b1t TA(w) C\u03b1) (At = C\u03b1).\nThus the first two derivations imply \u2206 \u22a2 Ls\u03b1tTA(w)A\u03b1, that is, (w,A\u03b1) \u2208 L also.\nLemma 5.2. In any TyAn model, the s-domain Ds contains a subset D \u2032 s isomorphic to A\u2217 with respect to concatenation operations and such that JTA(w)KM \u2208 D\u2032s for any w \u2208 A \u2217.\nProof. Let M be a TyAn model and ci =def JC i sKM for i = 0, ... N . Define the mapping VA : A\u2217 \u2192 Ds as follows:\nVA(\u01eb) = c0, VA(ai) = ci, VA(ai + w) = ci J+KM VA(w).\nSince axioms 4.1 - 4.3 are valid in M , VA is a one-to-one mapping and\nVA(u+ v) = VA(u) J+KM VA(v).\nThus the full image D\u2032s of A \u2217 under this mapping is isomorphic to A\u2217 and, by Definition 4.4, JTA(w)KM \u2208 D\u2032s for any w \u2208 A \u2217.\nThis lemma actually allows to identify JTA(w)KM with w, J+KM - with word concatenation and the subset D\u2032s - with A \u2217 in any TyAn model M .\nLemma 5.3. If M \u2282 T\u03b1 is logically closed, A1\u03b1 \u2208 M, ... A k \u03b1 \u2208 M and \u22a2 A\u03b1 = A1\u03b1 ... \u2228 A\u03b1 = A k \u03b1, then A\u03b1 \u2208 M also.\nProof. The proof is by induction on k. For k \u2264 2, the statement follows directly from Definition 3.5. For k > 2, by the metatheorems 5.1, 5.2 and\n\u22a2 (((A\u03b1|B\u03b1) Ct) = A\u03b1) \u2228 (((A\u03b1|B\u03b1) Ct) = B\u03b1),\nwe have \u22a2 A\u03b1 = B\u03b1 \u2228A\u03b1 = A k \u03b1,\nwhere\nB\u03b1 =def (...(A 1 \u03b1| ...|A k\u22122 \u03b1 )(A\u03b1 = A k\u22122 \u03b1 )|A k\u22121 \u03b1 )(A\u03b1 = A k\u22121 \u03b1 )\nand therefore \u22a2 B\u03b1 = A 1 \u03b1 ... \u2228 B\u03b1 = A k\u22121 \u03b1 .\nThus, if this implies thatB\u03b1 \u2208 M, then A\u03b1 \u2208 M also, according to Definition 3.5.\nProposition 5.4. Let an \u03b1-language L be logically closed, let the constant C0s\u03b1t belong to Ty A+ n , but not to Ty A n , and let \u2206L be the minimal set of Ty A+ n formulas such that, whenever (w,A\u03b1) \u2208 L, the formula C0s\u03b1tTA(w)A\u03b1 belongs to \u2206L. Then (\u2206L,C 0 s\u03b1t) is a representation of L.\nProof. Consistency of the set \u2206L follows from the fact that all its formulas are valid in a model where the constant C0s\u03b1t is interpreted by a function taking the true value for all its arguments.\nThe implication (w,A\u03b1) \u2208 L =\u21d2 \u2206L \u22a2 C 0 s\u03b1t TA(w) A\u03b1 follows directly from the definition of \u2206L. To prove the opposite implication, assume that \u2206L \u22a2 C0s\u03b1t TA(w)A\u03b1 and \u2206w is the (necessarily finite) subset of axioms from \u2206L participating in a proof of this derivation, so that\n\u2206w \u22a2 C 0 s\u03b1t TA(w)A\u03b1 (5.3)\nas well. Let A1\u03b1, ... A k \u03b1 be all those terms that occur in the formulas C0s\u03b1t TA(w) A i \u03b1 belonging to \u2206w. If (w,A\u03b1) 6\u2208 L, then there exist a Ty A n model M and an assignment of variables a such that JA\u03b1KM,a 6= JAi\u03b1KM,a for all i = 1, ...k. Indeed, due to the Completeness Theorem, we would otherwise have\n\u22a2 A\u03b1 = A 1 \u03b1 ... \u2228A\u03b1 = A k \u03b1\nand therefore, by Lemma 5.3 and the assumption of logical closure of L, (w,A\u03b1) \u2208 L. Consider an extension M+ of the model M for TyA+n where JC0s\u03b1tKM is the function taking the true value for all its arguments except for (w, JA\u03b1KM,a) (where w stands for JTA(w)KM , according to Lemma 5.2). All formulas of \u2206w are satisfied by the assignment a in M\n+, but C0s\u03b1t TA(w)A\u03b1 is not. By the Soundness Theorem, this contradicts 5.3 and thus proves that (w,A\u03b1) \u2208 L.\nPropositions 5.1 and 5.4 immediately imply\nTheorem 5.5. An \u03b1-language is Tyn-representable iff it is logically closed.\nNote that this general result is not constructive in the sense that it does not entail an effective procedure for actually building a Tyn representation for an infinite language that might be defined by a finite set of rules or rule schemata. At the same time, it neither implies the uniqueness of the Tyn representation and thus does not preclude a representation of such a language\nthat may be compact or described by a finite set of axiom schemata. We will find such representations for some important special classes of logically closed languages in the following sections."}, {"heading": "6 Lexicons and canonic representation", "text": "Definition 6.1. An \u03b1\u2212 lexicon is a logically closed \u03b1-language which is the logical closure of a finite \u03b1-language.\nDefinition 6.2. An \u03b1-language is said to have a canonic representation if it is represented by a term Ls\u03b1t such that\n\u22a2 Ls\u03b1t = (= A 1 s) &(= A 1 \u03b1) ... \u2228 (= A l s) &(= A l \u03b1)\nwhere all Ais are s-constants and A i \u03b1 are Tyn terms.\nIn this section we show that any \u03b1-lexicon has a canonic representation.\nLemma 6.1. \u22a2 TA(u) = TA(v) iff u = v and \u22a2 TA(u) 6= TA(v) iff u 6= v.\nProof. According to 4.1 \u2013 4.3, if m = l and i1 = j1, ... il = jl, then\n\u22a2 Ci1s ... +C il s = C j1 s ... +C jm s\nand if at least one of these conditions does not hold, then\n\u22a2 Ci1s ... +C il s 6= C j1 s ... +C jm s .\nThis proves both statements.\nLemma 6.2. Let the mapping TA\u03b1 from the set of \u03b1-languages to the power set P(Ts \u2297 T\u03b1) be defined by\nTA\u03b1(L) = {(TA(w), A\u03b1) | (w,A\u03b1) \u2208 L}.\nThen L is the logical closure of L iff TA\u03b1(L) is the logical closure of TA\u03b1(L).\nProof. As usual for any closure constructed by a ternary relation, a term belongs to a logical closure iff there exists a finite proof tree where this term is the root, every non-leaf node A\u03b1 has a pair of children B\u03b1, C\u03b1 that satisfy the relation (3.1) and all leaves belong to the original set. Similarly, a pair\nfrom A\u2217\u2297T\u03b1 belongs to the logical closure of an \u03b1-language iff there exists a finite proof tree where this pair is the root, every non-leaf node (w,A\u03b1) has a pair of children (w,B\u03b1), (w,C\u03b1) where B\u03b1 and C\u03b1 satisfy the relation (3.1) and leaves belong to the original language. Replacing every node (w,A\u03b1) of such a tree with (TA(w), A\u03b1) by Lemma 6.1 converts it to a proof tree for the logical closure of TA\u03b1(L). Thus if L is the logical closure of L, then TA\u03b1(L) is the logical closure of TA\u03b1(L). To prove the opposite implication, note that due to the tautology\n\u22a2 At \u2227 Ct \u2228 Bt \u2227Dt \u2192 Ct \u2228Dt,\nthe relation\n\u22a2 As = Bs \u2227 A\u03b1 = B\u03b1 \u2228 As = Cs \u2227 A\u03b1 = C\u03b1\nimplies (3.1). Therefore replacing every node (As, A\u03b1) of a proof tree for the logical closure of TA\u03b1(L) with (w,A\u03b1), where w is the expression occurring in the root of the original tree, converts it to a proof tree for L, by Lemma 6.1.\nDefinition 6.3. A set M \u2282 T\u03b1 is said to be represented by a term M\u03b1t if A\u03b1 \u2208 M \u21d0\u21d2 \u22a2 M\u03b1tA\u03b1.\nLemma 6.3. The logical closure M of a finite set M = {A1\u03b1, ... A k \u03b1} is represented by the term M\u03b1t =def (= A 1 \u03b1) ... \u2228 (= A k \u03b1).\nProof. \u22a2 M\u03b1tB\u03b1 and \u22a2 M\u03b1tC\u03b1 together with (3.1) imply \u22a2 M\u03b1tA\u03b1 by the metatheorem\n\u22a2 (A\u03b1 = B\u03b1 \u2227M\u03b1tB\u03b1) \u2192 M\u03b1tA\u03b1\n(also applied to C\u03b1) and the tautology\n\u22a2 (At \u2228Bt) \u2227Dt \u2227 Et \u2192 (At \u2227Dt \u2228 Bt \u2227 Et).\nThus, the set defined by \u22a2 M\u03b1tA\u03b1 is logically closed and therefore, according to Definition 3.5, includes M. The opposite inclusion follows directly from Lemma 5.3.\nTheorem 6.4. A logically closed language has a canonic representation iff it is a lexicon.\nProof. Let L = {(w1, A1\u03b1), ... (wl, A l \u03b1)} and\nLs\u03b1t =def (= A 1 s) &(= A 1 \u03b1) ... \u2228 (= A l s) &(= A l \u03b1),\nwhere Ais =def TA(wi). According to Lemma 6.3, the term Ls\u03b1t represents the logical closure of TA\u03b1(L) and therefore, according to Lemma 6.2, also the logical closure L."}, {"heading": "7 Recursive languages and representations", "text": "Given a finite set of lexicons, one can obtain an arbitrarily complex logically closed language by recursively applying the operations of logical join, logical concatenation and application of semantic rules to the initial lexicons. In this section we will see how a compact Tyn representation of such a recursive language can be built.\nDefinition 7.1. Let L1, ...Lm be logically closed languages and let one of the following be true for every 1 \u2264 i \u2264 m:\n(i) Li is a lexicon and Lis\u03b1it is its canonic representation\n(ii) there exist such 1 \u2264 j(i) \u2264 m and 1 \u2264 k(i) \u2264 m that Li = Lj(i) \u222aLk(i)\n(iii) there exist such 1 \u2264 j(i) \u2264 m and 1 \u2264 k(i) \u2264 m that Li = Lj(i) \u2217Lk(i)\n(iv) there exists such 1 \u2264 j(i) \u2264 m that Li = Lj(i) \u22b2Ri, where a logically closed semantic rule Ri has a canonic representation Ri\u03b1j(i)\u03b1it in the\nrange of Lj(i).\nThe full set RG of these conditions comprises a recursive grammar for the languages L1, ...Lm.\nFor a given recursive grammar, letL denote the language tuple (L1, ...Lm), let L0 denote a tuple of lexicons such that L0i =def Li whenever Li is a lexicon and L0i = \u2205 otherwise and let L\n\u2032 denote a language tuple such that L\u2032i = \u2205 whenever Li is a lexicon and L\u2032i is the right-hand part of the equality in condition (ii), (iii) or (iv) otherwise. Finally, let E\u0302 denote the operator which produces L\u2032 for a given L, so that the recursive grammar can be written as\nL = L0 \u222a E\u0302L, (7.1)\nwhere \u222a stands for a component-wise logical join of language tuples of the same arity and types.\nProposition 7.1. Equation 7.1 is satisfied by\nL =\n\u221e\u22c3\ni=0\nL i, (7.2)\nwhere L i = L0 \u222a E\u0302Li\u22121, for all i \u2265 1. (7.3)\nProof. As the operator E\u0302 is a combination of logical joins, logical concatenations and semantic rule applications, it inherits the monotonicity property\nL \u2286 K =\u21d2 E\u0302L \u2286 E\u0302K, (7.4)\nwhere K is a language tuple of the same arity and types as L and \u2286 stands for component-wise inclusion. From this and 7.3, by induction on i it follows that\nL i \u2283 Li\u22121, for all i \u2265 1.\nTherefore, for any tuple e =def ((w1, A\u03b11), ...(wm, A\u03b1m)) there exists an index i(e) such that\ne \u2208 E\u0302\n\u221e\u22c3\ni=0\nL i =\u21d2 e \u2208 E\u0302Li(e),\nwhere \u2208 stands for component-wise membership. From here, for the tuple L given by 7.2 we have that\ne \u2208 L0 \u222a E\u0302L =\u21d2 e \u2208 L0 \u222a E\u0302Li(e) = Li(e)+1,\nthat is, L0 \u222a E\u0302L \u2286 L. On the other hand, from the same property 7.4 we have that L0 \u222a E\u0302L \u2287 L0 \u222a E\u0302Li for any i \u2265 0 and therefore L0 \u222a E\u0302L \u2287 L. Thus, L0 \u222a E\u0302L = L.\nNote that in the general case, 7.2 might be not a single solution satisfying a recursive grammar. It can, however, be shown to be a subset of any other existing solution. This fact will not be used below and hence needs not be proven here, but we will refer to the solution 7.2 as the minimal one.\nDefinition 7.2. For a given recursive grammar RG, let \u2206RG denote the set of m formulas D1t , ...D m t , where\n(i) Dit =def (C i s\u03b1it = Lis\u03b1it), if Li is a lexicon represented by L i s\u03b1it ,\n(ii) Dit =def (C i s\u03b1it = C j(i) s\u03b1it \u2228Ck(i)s\u03b1it), if Li = Lj(i) \u222aLk(i),\n(iii) Dit =def (C i s\u03b1it = C j(i) s\u03b1j(i)t \u2217Ck(i)s\u03b1k(i)t), if Li = Lj(i) \u2217Lk(i), so that \u03b1i =def \u03b1j(i) \u00d7 \u03b1k(i),\n(iv) Dit =def (C i s\u03b1it = C j(i) s\u03b1j(i)t \u22b2 Ri\u03b1j(i)\u03b1it), if Li = Lj(i) \u22b2Ri and Ri is repre-\nsented by Ri\u03b1j(i)\u03b1it,\nall the constants C1s\u03b11t, ... C m s\u03b1mt are assumed to exist only in an extension TyA+n , but not in Ty A n , and the Ty A n operators of logical concatenation and semantic rule application are defined as follows:\n(\u2217(s\u03b1t)(s\u03b2t)s\u03b1\u03b2t) =def \u03bbxs\u03b1t\u03bbys\u03b2t\u03bbxs\u03bbx\u03b1\u03bbx\u03b2\u2203ys\u2203zs\n(xs = ys + zs \u2227 xs\u03b1t ys x\u03b1 \u2227 ys\u03b2t zs x\u03b2),\n(\u22b2(s\u03b1t)(\u03b1\u03b2t)s\u03b2t) =def \u03bbxs\u03b1t\u03bby\u03b1\u03b2t\u03bbxs\u03bbx\u03b2\u2203x\u03b1(xs\u03b1t xs x\u03b1 \u2227 y\u03b1\u03b2t x\u03b1 x\u03b2).\nBelow we will also make use of the TyAn operator of a functional semantic rule application:\n(\u21d2(s\u03b1t)(\u03b1\u03b2)s\u03b2t) =def \u03bbxs\u03b1t\u03bby\u03b1\u03b2(xs\u03b1t \u22b2 (\u03bbx\u03b1(= y\u03b1\u03b2 x\u03b1))).\nNote that every singleton (= A1s) &(= A 1 \u03b1) can be equivalently written down as (= A1s) \u21d2 A 1 \u03b1.\nWe now prove that every language Li of the minimal solution of a recursive grammar RG is represented by (\u2206RG ,Cis\u03b1it). To do so, we introduce the following auxiliary\nDefinition 7.3. An \u03b1-language L is said to have a pseudo-canonic representation if it is represented by (\u2206, Ls\u03b1t) such that for any word w \u2208 A\u2217 there exists a finite (may be empty) set {A1\u03b1, ... A l \u03b1} of Ty A n terms such that\n\u2206 \u22a2 Ls\u03b1t TA(w) = l\u2228\ni=1\n(= Ai\u03b1)\nand adding \u2206 to TyA+n as new axioms forms a conservative extension of Ty A n (i.e. for any TyAn formula At \u22a2 At iff \u2206 \u22a2 At).\nNote that a canonic representation of an \u03b1-lexicon is a particular case of a pseudo-canonic representation.\nLemma 7.2. If \u2206 is a consistent set of TyA+n formulas and for any general model M of TyAn and an assignment of variables in that model there exists an extension M+ of M for TyA+n in which \u2206 is satisfied by the same assignment of variables, then adding \u2206 to TyA+n forms a conservative extension of Ty A n .\nProof. By the Completeness Theorem, if not \u22a2 At, then there exists a general TyAn modelM and assignment of variables a by which At is not satisfied inM . If M can be extended to a model M+ for TyA+n where \u2206 is still satisfied by a, then by the Soundness Theorem the derivation \u2206 \u22a2 At is impossible.\nLemma 7.3. The set {A1\u03b1, ... A l \u03b1} appearing in the first condition of Definition 7.3 generates all meanings of w in the language L.\nProof. If Aa is a Ty A n term and (w,A\u03b1) \u2208 L, then \u2206 \u22a2 Ls\u03b1t TA(w) Aa and therefore \u2206 \u22a2 (A\u03b1 = A 1 \u03b1) ... \u2228 (A\u03b1 = A l \u03b1),\nwhich implies that \u22a2 (A\u03b1 = A 1 \u03b1) ... \u2228 (A\u03b1 = A l \u03b1).\nThus, by Lemma 6.3, any meaning of w belongs to the logical closure of {A1\u03b1, ... A l \u03b1}.\nLemma 7.4. In any recursive grammar RG, a lexicon Li with a canonic representation Lis\u03b1it also has the pseudo-canonic representation (\u2206RG , L i s\u03b1it ).\nProof. The first condition of Definition 7.3 follows directly from the assumption that Lis\u03b1it is a canonic representation.\nNow we prove that the set \u2206RG is consistent and also satisfied by a given assignment of variables a in some extension M+ of an arbitrary TyAn model M . Lemma 5.2 and the fact that a recursive grammar is satisfied by some logically closed languages L1, ...Lm allow the extension M+ to be defined as follows: let the function JCis\u03b1itKM+ for given arguments w \u2208 Ds and v \u2208 D\u03b1i take the true value iff w \u2208 A\u2217 and the language Li contains pairs (w,A\u03b1i) such that JA\u03b1iKM+,a = v. The conditions (i)-(iv) of Definition 7.2 then imply that every Dit is satisfied by a in such an extended model. By Lemma 7.2, this proves the second condition of Definition 7.3.\nLemma 7.5. If M and N are logical closures of M \u2208 T\u03b1 and N \u2208 T\u03b1 respectively, then M\u222aN = M\u222aN .\nProof. Every element of M\u222aN belongs to M\u222aN because M \u2286 M, N \u2286 N , so a proof tree for any term from M\u222aN is also a proof tree\nfor M\u222aN . On the other hand, as every leaf of a proof tree for an element\nof M\u222aN belongs to either M or N , it can be expanded to a proof tree for the corresponding set and thus the entire tree can be converted to a proof tree for M\u222aN with the same root, that proves its membership in M\u222aN .\nProposition 7.6. Let \u03b1-languages L and K have pseudo-canonic representations (\u2206, Ls\u03b1t) and (\u2206, Ks\u03b1t) respectively. Then their logical join L\u222aK is represented by (\u2206, Ls\u03b1t\u2228Ks\u03b1t), which is also a pseudo-canonic representation.\nProof. Let\n\u2206 \u22a2 Ls\u03b1t TA(w) = l\u2228\ni=1\n(= Ai\u03b1) and \u2206 \u22a2 Ks\u03b1t TA(w) = k\u2228\ni=1\n(= Bi\u03b1).\nThen\n\u2206 \u22a2 (Ls\u03b1t \u2228Ks\u03b1t) TA(w) = l\u2228\ni=1\n(= Ai\u03b1) \u2228 k\u2228\ni=1\n(= Bi\u03b1).\nThis proves that (\u2206, Ls\u03b1t \u2228 Ks\u03b1t) is a pseudo-canonic representation and therefore for any TyAn term A\u03b1,\n\u2206 \u22a2 (Ls\u03b1t \u2228Ks\u03b1t) TA(w)A\u03b1 \u21d0\u21d2 \u22a2 l\u2228\ni=1\n(A\u03b1 = A i \u03b1) \u2228\nk\u2228\ni=1\n(A\u03b1 = B i \u03b1).\nBy Lemmas 7.3, 6.3 and 7.5 this proves that (\u2206, Ls\u03b1t \u2228 Ks\u03b1t) represents L\u222aK.\nProposition 7.7. Let an \u03b1-language L have a pseudo-canonic representation (\u2206, Ls\u03b1t) and a \u03b2-language K have a pseudo-canonic representation (\u2206, Ks\u03b2t). Then the logical concatenation L\u2217K is represented by (\u2206, Ls\u03b1t \u2217Ks\u03b2t), which is also a pseudo-canonic representation.\nProof. Let w = h0+ t0 = ... = hl+ tl be all possible splits of a word w into head and tail and\n\u2206 \u22a2 Ls\u03b1t TA(hm) = lm\u2228\ni=1\n(= Am,i\u03b1 ), \u2206 \u22a2 Ks\u03b2t TA(tm) = km\u2228\nj=1\n(= Bm,j\u03b2 )\n(for m = 0, ... l). Then by axioms 4.1 - 4.3 and metatheorems\n\u22a2 \u2203x\u03b1(At \u2228 Bt) = \u2203x\u03b1At \u2228 \u2203x\u03b1Bt, (7.5)\n\u22a2 \u2203x\u03b3(x\u03b3 = A\u03b3 \u2227 Bt(x\u03b3)) = Bt(A\u03b3) (7.6)\n(where x\u03b3 is not free in A\u03b3) we have:\n\u2206 \u22a2 (Ls\u03b1t \u2217Ks\u03b2t) TA(w) = l\u2228\nm=0\nlm\u2228\ni=1\nkm\u2228\nj=1\n(= Am,i\u03b1 ) &(= B m,j \u03b2 ).\nThis proves that (\u2206, Ls\u03b1t\u2217Ks\u03b2t) is a pseudo-canonic representation and therefore for any TyAn terms A\u03b1, B\u03b2,\n\u2206 \u22a2 (Ls\u03b1t \u2217Ks\u03b2t) TA(w)A\u03b1B\u03b2 \u21d0\u21d2 \u22a2 l\u2228\nm=0\nlm\u2228\ni=1\nkm\u2228\nj=1\n(A\u03b1 = A m,i \u03b1 ) \u2227 (B\u03b2 = B m,j \u03b2 ).\nBy Definition 3.7 and Lemma 6.3 this proves that (\u2206, Ls\u03b1t \u2217Ks\u03b2t) represents L\u2217K.\nProposition 7.8. Let an \u03b1-language L have a pseudo-canonic representation (\u2206, Ls\u03b1t) and a rule R \u2282 T\u03b1 \u2297 T\u03b2 have a canonic representation R\u03b1\u03b2t in the range of L. Then the language L\u22b2R is represented by (\u2206, Ls\u03b1t \u22b2R\u03b1\u03b2t), which is also a pseudo-canonic representation.\nProof. Let\n\u2206 \u22a2 Ls\u03b1t TA(w) = l\u2228\ni=1\n(= Ai\u03b1)\nand\n\u22a2 R\u03b1\u03b2t A i \u03b1 =\nki\u2228\nj=1\n(= Bi,j\u03b2 )\n(for i = 1, ...l). Then by metatheorem 7.6 we have\n\u2206 \u22a2 (Ls\u03b1t \u22b2R\u03b1\u03b2t) TA(w) = l\u2228\ni=1\nki\u2228\nj=1\n(= Bi,j\u03b2 ).\nThis proves that (\u2206, Ls\u03b1t \u22b2 R\u03b1\u03b2t) is a pseudo-canonic representation and therefore for any TyAn term B\u03b2 ,\n\u2206 \u22a2 (Ls\u03b1t \u22b2R\u03b1\u03b2t) TA(w)B\u03b2 \u21d0\u21d2 \u22a2 l\u2228\ni=1\nki\u2228\nj=1\n(B\u03b2 = B i,j \u03b2 ).\nBy Definition 3.3 and Lemma 6.3 this proves that (\u2206, Ls\u03b1t \u22b2R\u03b1\u03b2t) represents L \u22b2R.\nPropositions 7.6 - 7.8 establish that, given some logically closed languages known to have pseudo-canonic representations that share a single common axiom set \u2206 and semantic rules that have canonic representations, one can build Tyn representations of their logical joins, logical concatenations and applications of the rules by means of the three corresponding TyAn operators: (\u2228(s\u03b1t)(s\u03b1t)s\u03b1t), (\u2217(s\u03b1t)(s\u03b2t)s\u03b1\u03b2t) and (\u22b2(s\u03b1t)(\u03b1\u03b2t)s\u03b2t); moreover these representations are also pseudo-canonic and share the same axiom set \u2206.\nLemma 7.9. TyAn operators of logical join, logical concatenation and semantic rule application reproduce the associativity and monotonicity properties:\n\u22a2 (xs\u03b1t \u2228 ys\u03b1t) \u2217 zs\u03b2t = xs\u03b1t \u2217 zs\u03b2t \u2228 ys\u03b1t \u2217 zs\u03b2t,\n\u22a2 zs\u03b2t \u2217 (xs\u03b1t \u2228 ys\u03b1t) = zs\u03b2t \u2217 xs\u03b1t \u2228 zs\u03b2t \u2217 ys\u03b1t,\n\u22a2 (xs\u03b1t \u2228 ys\u03b1t) \u22b2 z\u03b1\u03b2t = xs\u03b1t \u22b2 z\u03b1\u03b2t \u2228 ys\u03b1t \u22b2 z\u03b1\u03b2t,\n\u22a2 (xs\u03b1t \u2192 ys\u03b1t) \u2192 (xs\u03b1t \u2217 zs\u03b2t \u2192 ys\u03b1t \u2217 zs\u03b2t),\n\u22a2 (xs\u03b1t \u2192 ys\u03b1t) \u2192 (zs\u03b2t \u2217 xs\u03b1t \u2192 zs\u03b2t \u2217 ys\u03b1t),\n\u22a2 (xs\u03b1t \u2192 ys\u03b1t) \u2192 (xs\u03b1t \u22b2 z\u03b1\u03b2t \u2192 ys\u03b1t \u22b2 z\u03b1\u03b2t).\nProof. All these properties follow from the definition of operator (\u2217(s\u03b1t)(s\u03b2t)s\u03b1\u03b2t) due to the tautologies\n\u22a2 (At\u2228Bt)\u2227Ct = At\u2227Ct\u2228Bt\u2227Ct, \u22a2 Ct\u2227 (At\u2228Bt) = Ct\u2227At\u2228Ct\u2227Bt,\n\u22a2 (At \u2192 Bt) \u2192 (At\u2227Ct \u2192 Bt\u2227Ct), \u22a2 (At \u2192 Bt) \u2192 (Ct\u2227At \u2192 Ct\u2227Bt)\nand the metatheorems 7.5 and\n\u22a2 \u2200x\u03b3(At \u2192 Bt) \u2192 (\u2203x\u03b3At \u2192 \u2203x\u03b3Bt).\nTheorem 7.10. Every language Li of the minimal solution of a recursive grammar RG is represented by (\u2206RG ,Cis\u03b1it).\nProof. If (using the notations introduced in the proof of Proposition 7.1) e \u2208 L, then there exists an index i such that e \u2208 Li. As every Li is built from lexicons L0 and L(i\u22121) by applying logical joins, logical concatenations and semantic rule applications, from Propositions 7.6 - 7.8 it follows (by induction on i) that every component Lij of L\ni has a pseudo-canonic representation (\u2206RG , L i,j \u03c4j ), where for any i > 0\nLi,j\u03c4j =def L 0,j \u03c4j \u2228 Ej\u03c41...\u03c4m\u03c4j L i\u22121,1 \u03c41 ... Li\u22121,m\u03c4m ,\n\u03c4j =def s\u03b1jt and terms E j \u03c41...\u03c4m\u03c4j stand for TyAn operators corresponding to the operator E\u0302. On the other hand, from Definition 7.2 we have\n\u2206RG \u22a2 C j \u03c4j = L0,j\u03c4j \u2228 E j \u03c41...\u03c4m\u03c4j C1\u03c41 ...C m \u03c4m .\nAs by Lemma 7.9 the terms Ej\u03c41...\u03c4m\u03c4j reproduce the monotonicity property of the operator E\u0302 , it follows from this that for all i \u2265 0\n\u2206RG \u22a2 L i,j \u03c4j \u2192 Cj\u03c4j\nand therefore, for every j that\n\u2206RG \u22a2 C j \u03c4j TA(wj) A\u03b1j .\nTo prove that, inversely, the above derivations imply e \u2208 Li, consider the TyA+n model defined in the proof of Lemma 7.4. As such a model can extend an arbitrary TyAn model, these derivations imply that there exist such terms A\u2032\u03b1j that e \u2032 =def ((w1, A \u2032 \u03b11 ), ... (wm, A \u2032 \u03b1m\n)) \u2208 L and \u22a2 A\u2032\u03b1j = A\u03b1j . As Lj are logically closed, this implies that e \u2208 L also.\nCorollary 7.11. Every language Li of the minimal solution of a recursive grammar RG is represented by the term \u03bbxs\u03bbx\u03b1iDt \u2192 C i s\u03b1it\n, where Dt is the conjunction of all formulas from \u2206RG .\nProof. See the note to Definition 4.1.\nThe significance of these results is that they, in particular, establish a class of non-trivial Tyn-representable languages which turns out to be decidable, in spite of the fact that Tyn is undecidable and hence so are generally\nTyn-representable languages. Indeed, assume all the semantic rules participating in a grammar RG to be non-degenerate. It is easy to see that in this assumption the domain of every language Li is formed by a context-free grammar with the set of terminals being the union of domains of all the lexicons participating in RG and non-terminal symbols corresponding all the Li languages. Therefore, this domain falls into the class of context-free (and hence - recursive) languages of the Chomsky hierarchy. Then, in the additional assumption of decidability of all the RG semantic rules (which holds, for example, for any functional rules), the problem of finding all the logicallyindependent representatives of the meanings of an Li expression also turns out to be decidable, merely by attributing the terminal (leaf) nodes of its syntactic parsing tree with their (lexicon-determined) meanings and inheriting and evaluating the meanings of upper nodes according to the rules, from bottom up to the root node. Furthermore, though discarding the assumption of non-degenerateness of all the RG semantic rules may generally lead to languages Li with domains being context-sensitive (in the classical sense), retaining only the assumption of the rules decidability still preserves the conclusion about decidability of languages Li. In this assumption languages Li can be parsed, for example, by the two-staged process like this:\n1. parse according to the context-free grammar RG obtained from RG by replacing every rule Ri by the trivial non-degenerate rule with the canonic representation Ri\u03b1j(i)\u03b1it =def \u03bbx\u03b1j(i)\u03bbx\u03b1iT\n2. attribute the terminal (leaf) nodes of the parsing tree with their (lexicondetermined) meanings and inherit and evaluate the meanings of upper nodes according to the actual rules Ri, or discard the parse if at any node the actual rule degenerates to \u03bbx\u03b1iF when applied to all incoming meanings.\nTo illustrate the technique of a recursive grammar representation, let us build a very simple English-like grammar from tiny lexicons, consisting of a few countable nouns and transitive verbs, the irregular verb \u201dbe\u201d, a proper\nnoun and two determiners:\nNouns(et)t = (= /builder/) \u21d2 Builderet \u2228\n(= /house/) \u21d2 Houseet \u2228\n(= /car/) \u21d2 Caret,\nVerbts(eet)t = (= /build/) \u21d2 Buildeet \u2228\n= (= /sell/) \u21d2 Selleet,\nVerbBes(eet)t = (= /be/) \u21d2 (=eet),\nNameset = (= /Jack/) \u21d2 Jacke,\nDets((et)(et)t)t = (= /a/) \u21d2 \u03bbyet\u03bbzet\u2203xe(y x \u2227 z x) \u2228\n(= /every/) \u21d2 (\u2192(et)(et)t).\nThe noun phrase can be defined by the axiom\nNPs((et)t)t = Det \u2217\u2217Noun \u21d2 I((et)(et)t)(et)(et)t \u2228\nName \u21d2 \u03bbxe\u03bbyet(y x)\nand the simple verb phrase (for the object of the third person in the singular number) by the axioms\nVPss(et)t = (Verbt \u2217 (= /s/) \u2228 ((= /is/) \u21d2 /be/) \u22b2VerbBe) \u2217\u2217NP \u21d2\n\u03bbzeet\u03bby(et)t\u03bbx 2 e(y \u03bbx 1(z x1 x2)) \u2228 ((= /does not/) \u2217\u2217Verbt \u2228 ((= /is not/) \u21d2 /be/) \u22b2VerbBe) \u2217\u2217NP \u21d2 \u03bbzeet\u03bby(et)t\u03bbx 2 e(y \u03bbx 1(\u223c (z x1 x2))),\nwhere (\u2217\u2217) =def \u03bbxs\u03b1t\u03bbys\u03b2t(x \u2217 (= / /) \u2217 y)\nrepresents phrase concatenation (with a separating space). Note that the constant VerbBe occurs here as a semantic rule applied to simple s-languages which express the morphology of the verb \u201dbe\u201d. As these languages, as well as the language represented by VerbBe itself are finite lexicons, the results of the applications are lexicons too and hence conditions of the theorem 7.10 still hold for the language we are defining. The compound verb phrase can now be defined by the axioms like\nVPms(et)t = VPs \u2217\u2217(= /and/) \u2217\u2217VPs \u21d2 (\u2227(et)(et)et)) \u2228\nVPs \u2217 (= /,/) \u2217\u2217VPm \u21d2 (\u2227(et)(et)et),\nVPs(et)t = VPs \u2228 VPm\nand the clause \u2013 by the axiom\nClstt = NP \u2217\u2217VP \u21d2 I((et)t)(et)t.\nFinally, the declarative sentence can be defined by the axiom\nSstt = Cl \u2217 (= /./) \u2228 (Cl \u2217 (= /,/) \u2217\u2217S \u2228 Cl \u2217\u2217(= /and/) \u2217\u2217S) \u21d2 (\u2227ttt).\nIf \u2206S is the set of the above axioms, then, by propositions 7.6 - 7.8, we will have, for example:\n\u2206S \u22a2 S /Jack builds a house./ \u2203xe(Build xe Jack \u2227 House xe),\n\u2206S \u22a2 S /Jack sells a car and builds a house./ (\u2203xe(Sell xe Jack \u2227 Car xe) \u2227\n\u2203xe(Build xe Jack \u2227 House xe)),\n\u2206S \u22a2 S /Jack does not build a house./ \u223c \u2203xe(Build xe Jack \u2227 House xe), \u2206S \u22a2 S /every builder builds a house./ (Builder \u2192 \u03bbx 2 e\u2203x 1 e(Build x 1 e x 2 e \u2227 House x 1 e), \u2206S \u22a2 S /Jack is a builder, Jack builds a house./ (\u2203xe(Builder xe \u2227 Jack = xe) \u2227\n\u2203xe(Build xe Jack \u2227 House xe)).\nOf course, along with these, the language represented by (\u2206S,S) also admits semantically infelicitous sentences like, for example, \u201da house builds a builder\u201d or \u201dJack is a house\u201d. If one would like to make such sentences ungrammatical, i.e. exclude them from the domain of the language represented by (\u2206S,S), this can be achieved by applying more restrictive relational semantic rules, than those simple functional rules used in the above axioms; such rules must account the animacy categories of nouns, as well as categories of subjects and objects applicable to a verb. Another, less elegant, though practically may be simpler and more efficient solution is to split lexicons and derived languages to semantically homogenous components and allow concatenation of only matching pairs, like, for example:\nClstt = (NPa \u2217\u2217VPa \u2228 NPi \u2217\u2217VPi) \u21d2 I((et)t)(et)t,\nwhere NPa,NPi are to represent animate and inanimate noun phrases and VPa,VPi to represent verb phrases applicable to animate and inanimate subjects. Note that this approach leads to splitting the verb lexicon to components corresponding different generic sentence frames as defined in (Fellbaum, 1998); in particular, the verbs \u201dbuild\u201d and \u201dsell\u201d, in terms of WordNet, will correspond the frame \u201dSomebody \u2014-s something\u201d and the verb \u201dbe\u201d will be shared by the frames \u201dSomething \u2014-s something\u201d and \u201dSomebody \u2014-s somebody\u201d."}, {"heading": "8 Context type, instructive and", "text": "context-dependent languages\nIntroduction of an additional sort of individuals in Ty2 of (Gallin, 1975) allowed to accurately interpret in this theory the intensional logic (IL), that implied interpretation of the corresponding type (s in Gallin\u2019s notations, not to be confused with the symbolic type of this work) as a set of possible \u201cstates of world\u201d or \u201cstates of affairs\u201d. Similarly to this, TyAn with n > 2 admits the same interpretation of one of its primitive types (let it be, for certainty, c =def en\u22121) and thus turns out to be capable of representing intensional languages, i.e. languages with intensional semantics, as well. In combination with the capabilities provided by the symbolic type, however, a more specific interpretation of type c in TyAn allows to go far beyond this straightforward generalization and achieve also a natural and effective account of those aspects of a language which are usually referenced in literature as dynamic semantics (Kamp, 1981; Heim, 1983; Seuren, 1985; Groenendijk & Stokhof, 1989; Groenendijk & Stokhof, 1990).\nThe basic idea is to extend TyAn with non-logical axioms like\n\u03bbx\u03b1(Deref\u03b1c\u03b1 S\u03b1 (Pcc (Setref\u03b1\u03b1cc S\u03b1 x\u03b1 yc))) = I\u03b1\u03b1 (8.1)\nUnset\u03b1cc S\u03b1 \u25e6 Pcc \u25e6 Setref\u03b1\u03b1cc S\u03b1 x\u03b1 = Icc, (8.2)\nwhere there could be some restrictions on the structure of terms S\u03b1 and Pcc and\n(\u25e6(\u03b2\u03b3)(\u03b1\u03b2)\u03b1\u03b3) =def \u03bbz\u03b2\u03b3\u03bbq\u03b1\u03b2\u03bbx\u03b1(z\u03b2\u03b3 (q\u03b1\u03b2 x\u03b1)),\nthat allow to interpret type c as a \u201dstore\u201d (Sabry, 1995) or, in the terminology of programming languages, \u201dstate\u201d and transform a Tyn representation of a language to the state-passing style (SPS) (Wadler, 1992; Sabry, 1995; Jones, 2003). In such a transformation the state actually plays a role of a context, passing \u201dside effects\u201d of parsing some constituents of an expression to others, as we explore in details below. This justifies our referring to the type c as to context type (and motivates the notation).\nNote that cc-terms like Setref\u03b1\u03b1cc S\u03b1 V\u03b1 and Unset\u03b1cc S\u03b1 present instructions to \u201dmodify\u201d a context, in the sense defined by the axioms 8.1, 8.2. Proceeding from this observation, one can further assume certain cc-terms to denote instructions whose semantics might not be representable in TyAn , but still could be implemented in a computing or another system. Instructions\nto add or remove a non-logical axiom to or from a set of axioms associated with a context, or verify whether a given formula is provable from this set are important examples of such \u201cmeta\u201d-instructions. Although their semantics are not representable within Tyn, they still might be denoted by cc terms, like, say, Asserttcc At, Refutetcc At or Testtcc At, and there could be a computing system capable of evaluating them in some conditions and providing an appropriate feedback in the event of failure. Other unrepresentable instructions might force a system to exchange information with an external environment via input/output devices or even to execute certain physical actions (like robotic ones).\nIt is easy to notice that associating a context with a set of non-logical axioms makes our c type conceptually similar to the World type of (Pollard, 2005). The principal technical (formal) difference is however that the World type in the hyperintensional semantics is defined as a derived subtype of the type of functions from Prop to Bool, while Prop is introduced as a primitive type. Unlike that, in our model, vice-versa, the context type c is introduced as primitive and the propositional type can be defined as the functional type ct (see (Gallin, 1975)). A fundamental theoretical benefit of the hyperintensional semantics is that it admits internalizing (i.e. making representable within the HOL) the entailment relation between propositions, along with the property of a set of propositions to be an ultrafilter, i.e. a maximum consistent set of propositions. However, as the World type is defined just by the ultrafilterhood predicate, i.e., informally saying, assumed to \u201csettle every issue\u201d (Pollard, 2005), it is not obvious whether this theoretical benefit would imply practical benefits in an implementation of this formalism. At the same time, our context type, of course, enforces no assumptions about completeness (and even about consistency) of axioms associated with a context, that seems to be more pragmatic and realistic.\nTo summarize this introductory informal discussion, we can state that, while type s of (Gallin, 1975) and type World of (Pollard, 2005) stand for \u201cstates of world\u201d, the similar to them type c of our model stands rather for \u201cstates of an individual mind\u201d, which mind is not necessarily complete nor consistent, but, on one hand, still determines interpretation of a text and, on the other hand, is changeable (in particular, extendable) in the process of interpretation.\nMoving on formalism, we first note that a superposition like\nP lcc \u25e6 P l\u22121 cc ... \u25e6 P 1 cc,\nrepresents a sequence of instructions, executed in order from right to left, that is a program, while the identity Icc is the empty sequence, or \u201ddo-nothing\u201d instruction. (Of course an arbitrary cc-term would not invariably represent an executable instruction, but a real implementation should necessarily provide some sort of exception handling, reducing a non-executable instruction to another or possibly do nothing instruction.)\nThus, expressions of a cc-language mean some (either executable or nonexecutable) instructions and therefore a text, i.e. an ordered sequence of such expressions can be treated as a corresponding program. A few obvious features of such an instructive language make it different in principle from a t- and even a ct-language:\n1. an instructive language text meaning captures the order of statements, that is, its semantic interpretation can depend on that order;\n2. it can also capture contradictory or equivalent truth meanings nested in subsequent instructions;\n3. it provides a natural way to distinctly represent declarative, interrogative and imperative semantics.\nGiven an initial context Cc, an instructive language text meaning Pcc determines a new context Pcc Cc depending on both the initial context Cc and the program Pcc which changes it, in the sense that a continuation of the text would already be applied to the new context. However, the program Pcc itself here does not depend on the initial context. Our next step is to employ the context type for building context-dependent languages.\nDefinition 8.1. A context-dependent \u03b1-language is a c(c\u00d7 \u03b1)-language.\nGiven a context-dependent \u03b1-language L and a context term Cc, the operation of context application\nL \u2193 Cc =def L \u22b2 CA(Cc),\nwhere the rule CA(Cc) \u2282 Tc(c\u00d7\u03b1) \u2297 Tc\u00d7\u03b1 is represented by\nCA(cc)(c\u03b1)c\u03b1t(Cc) =def \u03bbxcc\u03bbyc\u03b1((= xcc Cc) &(= yc\u03b1 Cc)),\nand the operation of context instantiation\nL \u21d3 Cc =def L \u22b2 CI(Cc),\nwhere the rule CI(Cc) \u2282 Tc(c\u00d7\u03b1) \u2297 T\u03b1 is represented by\nCI(cc)(c\u03b1)\u03b1t(Cc) =def \u03bbxcc\u03bbyc\u03b1(= yc\u03b1 Cc),\nproduce a c\u00d7\u03b1-language and a regular \u03b1-language, respectively, that depend on a context Cc. Inversely, given a regular \u03b1-language and a term F\u03b1cc, the operation of context raising\nL \u21d1 F\u03b1cc =def L \u22b2 CR(F\u03b1cc),\nwhere the rule CR(F\u03b1cc) \u2282 T\u03b1 \u2297 Tc(c\u00d7\u03b1) is represented by\nCR\u03b1(cc)(c\u03b1)t(F\u03b1cc) =def \u03bbx\u03b1((= F\u03b1cc x\u03b1) &(= \u03bbxcx\u03b1)),\nproduces a context-dependent \u03b1-language. Note that for any language and context\n\u22a2 (L \u21d1 \u03bbx\u03b1Icc) \u21d3 Cc = L,\nthat is, raising a regular language by \u03bbx\u03b1Icc converts it into a contextdependent language which however is essentially equivalent to the original one.\nIt is also noticeable that an instructive, that is a regular cc-language, turns out to be a singular case of a context-dependent unit-type-language. The reason why a context-dependent \u03b1-language is required to be of type c(c\u00d7 \u03b1), rather than of a simpler type c\u03b1, should become obvious from the following. For sake of brevity we employ notation \u03b1 =def c(c \u00d7 \u03b1) (for an arbitrary type \u03b1) everywhere below.\nDefinition 8.2. Let L be a context-dependent \u03b1-language and K - a contextdependent \u03b2-language. Then their anaphoric logical concatenation is the context-dependent \u03b1\u00d7 \u03b2-language\nL\u2212\u2192\u2217 K =def L\u2217K \u22b2AC,\nwhere the rule AC \u2282 T\u03b1\u00d7\u03b2 \u2297 T\u03b1\u00d7\u03b2 is represented by the term\nAC\u03b1\u03b2 \u03b1\u00d7\u03b2t =def \u03bbx 1 cc\u03bby 1 c\u03b1\u03bbx 2 cc\u03bby 2 c\u03b2((= x 2 cc \u25e6 x 1 cc) &(= y 1 c\u03b1) &(= y 2 c\u03b2 \u25e6 x 1 cc)),\nand their cataphoric logical concatenation is the context-dependent \u03b1 \u00d7 \u03b2language\nL\u2190\u2212\u2217 K =def L\u2217K \u22b2 CC,\nwhere the rule CC \u2282 T\u03b1\u00d7\u03b2 \u2297 T\u03b1\u00d7\u03b2 is represented by the term\nCC\u03b1\u03b2 \u03b1\u00d7\u03b2t =def \u03bbx 1 cc\u03bby 1 c\u03b1\u03bbx 2 cc\u03bby 2 c\u03b2((= x 1 cc \u25e6 x 2 cc) &(= y 1 c\u03b1 \u25e6 x 2 cc) &(= y 2 c\u03b2)).\nFor informal interpretation of this definition consider the superposition of an anaphoric concatenation with a context application:\n(L\u2212\u2192\u2217 K) \u2193 Cc = (L\u2217K) \u22b2 (CA(Cc) \u25e6 AC),\nwhere the rule superposition CA(Cc) \u25e6 AC is represented by the term\n\u03bbx1cc\u03bby 1 c\u03b1\u03bbx 2 cc\u03bby 2 c\u03b2((= x 2 cc (x 1 cc Cc)) &(= y 1 c\u03b1 Cc) &(= y 2 c\u03b2 (x 1 cc Cc))).\nThus, the anaphoric concatenation affects a meaning of the right-hand constituent by a context affected by the left-hand one, while the latter is affected directly by the initial context. Symmetrically, for the cataphoric concatenation, the effective rule superposition is represented by the term\n\u03bbx1cc\u03bby 1 c\u03b1\u03bbx 2 cc\u03bby 2 c\u03b2((= x 1 cc (x 2 cc Cc)) &(= y 1 c\u03b1 (x 2 cc Cc)) &(= y 2 c\u03b2 Cc)),\nthat is, in this case an initial context is passed to the right-hand constituent and the affected context to the left-hand one.\nNote that the construction of type \u03b1 =def c(c \u00d7 \u03b1) coincides with the construction of the state monad type in functional programming languages (Wadler, 1992; Jones, 2003) and the context raising rule\nCR\u03b1(cc)(c\u03b1)t(\u03bbx\u03b1Icc) =def \u03bbx\u03b1((= Icc) &(= \u03bbxcx\u03b1))\nprecisely corresponds to the return operator of that monad. It is also easy to verify that the rules AC\u03b1\u03b2 \u03b1\u00d7\u03b2t and CC\u03b1\u03b2 \u03b1\u00d7\u03b2t defining operations\n\u2212\u2192\u2217 and \u2190\u2212\u2217 come as results of binding by the corresponding operator of the same monad, in the first case \u2013 a meaning (x1cc, y 1 c\u03b1) of the left constituent with the operation AK\u03b1 \u03b1\u00d7\u03b2 =def \u03bbx\u03b1((x 2 cc, \u03bbycx\u03b1, y 2 c\u03b2) and in the second case \u2013 a meaning (x2cc, y 2 c\u03b2) of the second constituent with the symmetric operation\nCK\u03b2 \u03b1\u00d7\u03b2 =def \u03bbx\u03b2((x 1 cc, \u03bbycx\u03b2, y 1 c\u03b1),\nwhich operations merely combine a monadic-type-meaning of one of the constituents with a regular-type-meaning of the other. Of course, this note is nothing else than a rephrasing of the above informal interpretation of operations \u2212\u2192\u2217 and \u2190\u2212\u2217 , in terms of the state monad.\nAs the new operations \u2212\u2192\u2217 ,\u2190\u2212\u2217 , \u2193,\u21d1 and \u21d3 are defined as rule applications to regular concatenations or just special rule applications, they also reveal associativity and monotonicity properties:\nLemma 8.1. For any context-dependent \u03b1-languages K,L, a context-dependent \u03b2-language M, regular \u03b1-languages K0,L0 and a context term Cc\n(K\u222aL)\u2212\u2192\u2217 M = K\u2212\u2192\u2217 M \u222a L\u2212\u2192\u2217 M,\nM\u2212\u2192\u2217 (K\u222aL) = M\u2212\u2192\u2217 K \u222a M\u2212\u2192\u2217 L,\n(K\u222aL)\u2190\u2212\u2217 M = K\u2190\u2212\u2217 M \u222a L\u2190\u2212\u2217 M, M\u2190\u2212\u2217 (K\u222aL) = M\u2190\u2212\u2217 K \u222a M\u2190\u2212\u2217 L,\n(K0 \u222aL0) \u21d1 Cc = K0 \u21d1 Cc \u222a L0 \u21d1 Cc,\n(K\u222aL) \u21d3 Cc = K \u21d3 Cc \u222a L \u21d3 Cc,\nK \u2282 L =\u21d2 K\u2212\u2192\u2217 M \u2282 L\u2212\u2192\u2217 M, K \u2282 L =\u21d2 M\u2212\u2192\u2217 K \u2282 M\u2212\u2192\u2217 L, K \u2282 L =\u21d2 K\u2190\u2212\u2217 M \u2282 L\u2190\u2212\u2217 M, K \u2282 L =\u21d2 M\u2190\u2212\u2217 K \u2282 M\u2190\u2212\u2217 L,\nK0 \u2282 L0 =\u21d2 K0 \u21d1 Cc \u2282 L0 \u21d1 Cc,\nK \u2282 L =\u21d2 K0 \u21d3 Cc \u2282 L0 \u21d3 Cc.\nProposition 8.2. If a context-dependent \u03b1-language L has a pseudo-canonic representation (\u2206, Ls\u03b1t) and a context-dependent \u03b2-language K has a pseudocanonic representation (\u2206, Ks\u03b2t), then the concatenations L \u2212\u2192\u2217 K and L\u2190\u2212\u2217 K have pseudo-canonic representations (\u2206, Ls\u03b1t \u2212\u2192\u2217 Ks\u03b2t) and ((\u2206, Ls\u03b1t\n\u2190\u2212\u2217 Ks\u03b2t) respectively, where\n(\u2212\u2192\u2217 (s\u03b1t)(s\u03b2t)s\u03b1\u00d7\u03b2t) =def \u03bbzs\u03b1t\u03bbzs\u03b2t\u03bbxs\u03bbxcc\u03bbyc\u03b1\u03bbyc\u03b2\u2203x 1 s\u2203x 2 s\u2203x 1 cc\u2203x 2 cc\u2203y 2 c\u03b2\n(xs = x 1 s+x 2 s \u2227xcc = x 2 cc\u25e6x 1 cc\u2227 yc\u03b2 = y 2 c\u03b2\u25e6x 1 cc\u2227 zs\u03b1tx 1 sx 1 ccyc\u03b1\u2227 zs\u03b2tx 2 sx 2 ccy 2 c\u03b2),\n(\u2190\u2212\u2217 (s\u03b1t)(s\u03b2t)s\u03b1\u00d7\u03b2t) =def \u03bbzs\u03b1t\u03bbzs\u03b2t\u03bbxs\u03bbxcc\u03bbyc\u03b1\u03bbyc\u03b2\u2203x 1 s\u2203x 2 s\u2203x 1 cc\u2203x 2 cc\u2203y 1 c\u03b1\n(xs = x 1 s+x 2 s \u2227xcc = x 1 cc\u25e6x 2 cc\u2227 yc\u03b1 = y 1 c\u03b1\u25e6x 2 cc\u2227 zs\u03b1tx 1 sx 1 ccy 1 c\u03b1\u2227 zs\u03b2tx 2 sx 2 ccyc\u03b2).\nProof. The proof follows from Propositions 7.7, 7.8 and Definition 8.2, taking into account that the terms AC\u03b1\u03b2 \u03b1\u00d7\u03b2t and CC\u03b1\u03b2 \u03b1\u00d7\u03b2t are canonic representations of the corresponding rules (in any domain).\nProposition 8.3. If a context-dependent \u03b1-language L has a pseudo-canonic representation (\u2206, Ls\u03b1t), then a context instantiation L \u21d3 Cc has a pseudocanonic representation (\u2206, Ls\u03b1t \u21d3 Cc), where\n(\u21d3(s\u03b1t)cs\u03b1t) =def \u03bbz(s\u03b1t)cs\u03b1t\u03bbzc\u03bbxs\u03bby\u03b1\u2203xcc\u2203yc\u03b1(zs\u03b1t xs xcc yc\u03b1 \u2227 y\u03b1 = yc\u03b1 zc).\nProof. The proof follows from Proposition 7.6, taking into account that the term CA\u03b1c\u03b1t(Cc) is a canonic representation (in any domain) of the rule that defines the context instantiation operation.\nProposition 8.4. If an \u03b1-language L has a pseudo-canonic representation (\u2206, Ls\u03b1t), than a context raising L \u21d1 F\u03b1cc has a pseudo-canonic representation (\u2206, Ls\u03b1t \u21d1 F\u03b1cc), where\n(\u21d1(s\u03b1t)(\u03b1cc)s\u03b1t) =def \u03bbzs\u03b1t\u03bbz\u03b1cc\u03bbxs\u03bbxcc\u03bbxc\u03b1\u2203x\u03b1\n(zs\u03b1t xs x\u03b1 \u2227 xcc = z\u03b1cc x\u03b1 \u2227 xc\u03b1 = \u03bbxcx\u03b1).\nProof. Similar to Proposition 8.3, with taking into account that the term CR\u03b1\u03b1t is a canonic representation (in any domain) of the rule that defines the context raising operation.\nLemma 8.5. TyAn operators of logical join, anaphoric or cataphoric concatenations and context instantiation or raising reproduce the associativity and monotonicity properties:\n\u22a2 (xs\u03b1t \u2228 ys\u03b1t) \u2212\u2192\u2217 zs\u03b2t = xs\u03b1t \u2212\u2192\u2217 zs\u03b2t \u2228 ys\u03b1t \u2212\u2192\u2217 zs\u03b2t, \u22a2 zs\u03b2t \u2212\u2192\u2217 (xs\u03b1t \u2228 ys\u03b1t) = zs\u03b2t \u2212\u2192\u2217 xs\u03b1t \u2228 zs\u03b2t \u2212\u2192\u2217 ys\u03b1t, \u22a2 (xs\u03b1t \u2228 ys\u03b1t) \u2190\u2212\u2217 zs\u03b2t = xs\u03b1t \u2190\u2212\u2217 zs\u03b2t \u2228 ys\u03b1t \u2190\u2212\u2217 zs\u03b2t, \u22a2 zs\u03b2t \u2190\u2212\u2217 (xs\u03b1t \u2228 ys\u03b1t) = zs\u03b2t \u2190\u2212\u2217 xs\u03b1t \u2228 zs\u03b2t \u2190\u2212\u2217 ys\u03b1t, \u22a2 (xs\u03b1t \u2228 ys\u03b1t) \u21d1 z\u03b1cc = xs\u03b1t \u21d1 z\u03b1cc \u2228 ys\u03b1t \u21d1 z\u03b1cc,\n\u22a2 (xs\u03b1t \u2228 ys\u03b1t) \u21d3 zc = xs\u03b1t \u21d3 zc \u2228 ys\u03b1t \u21d3 zc, \u22a2 (xs\u03b1t \u2192 ys\u03b1t) \u2192 (xs\u03b1t \u2212\u2192\u2217 zs\u03b2t \u2192 ys\u03b1t \u2212\u2192\u2217 zs\u03b2t), \u22a2 (xs\u03b1t \u2192 ys\u03b1t) \u2192 (zs\u03b2t \u2212\u2192\u2217 xs\u03b1t \u2192 zs\u03b2t \u2212\u2192\u2217 ys\u03b1t), \u22a2 (xs\u03b1t \u2192 ys\u03b1t) \u2192 (xs\u03b1t \u2190\u2212\u2217 zs\u03b2t \u2192 ys\u03b1t \u2190\u2212\u2217 zs\u03b2t), \u22a2 (xs\u03b1t \u2192 ys\u03b1t) \u2192 (zs\u03b2t \u2190\u2212\u2217 xs\u03b1t \u2192 zs\u03b2t \u2190\u2212\u2217 ys\u03b1t), \u22a2 (xs\u03b1t \u2192 ys\u03b1t) \u2192 (xs\u03b1t \u21d1 z\u03b1cc \u2192 ys\u03b1t \u21d1 z\u03b1cc),\n\u22a2 (xs\u03b1t \u2192 ys\u03b1t) \u2192 (xs\u03b1t \u21d3 zc \u2192 ys\u03b1t \u21d3 zc).\nProof. The proof follows from the definitions of the operators and Lemma 7.9.\nPropositions 8.2 \u2013 8.4 and Lemmas 8.1 and 8.5 show that the main result of Section 7 \u2013 Theorem 7.10 \u2013 can be generalized in a straightforward manner to the case of a recursive grammar that contains a mix of regular and context-dependent languages and relations involving all seven operations \u222a, \u2217,\u2212\u2192\u2217 ,\u2190\u2212\u2217 , \u22b2,\u21d1 and \u21d3.\nLet us see how the sample recursive grammar built in the previous section can be converted to an instructive (and hence context-dependent) language grammar and extended to acquire the two important features: distinction of declarative and interrogative semantics and pronoun dereferencing. To avoid excessive technical complexity and make the example more demonstrative, we will allow pronoun \u201dhe\u201d to appear only on place of a clause subject, referencing the subject of another (previous) clause expressed by a name, and pronoun \u201dit\u201d only on place of an object, referencing the object of another (previous) affirmative verb phrase. The first can be achieved by defining the subject noun phrase by the axioms like\nSNPs(et)tt = (Det \u2217\u2217Noun \u21d2 I((et)(et)t)(et)(et)t) \u21d1 \u03bbx(et)tIcc \u2228\n(Name \u21d2 \u03bbxe\u03bbyet(y x)) \u21d1 Setref He(et)t) \u2228\nSPron \u21d2 (Icc, Deref ((et)t)c(et)t),\nSPron(et)t = (= /he/) \u21d2 He(et)t.\nNote that the constant He(et)t here does not denote any specific meaning, but plays role of a symbol to assign a meaning and carry it to a corresponding reference.\nAccurate treatment of the pronoun on place of an object (which we want to be capable of referencing an arbitrarily expressed object of another verb phrase) requires a more sophisticated technique. First, we specialize the type of the object noun phrase to (eet)et and define it by the axioms\nONP s(eet)ett = (NP \u21d2 O) \u21d1 \u03bbx(eet)etIcc \u2228 (8.3)\nOPron \u21d2 (Icc,Deref ((eet)et)c(eet)et),\nOPron(eet)et = (= /it/) \u21d2 It(eet)et,\nwhere NP is defined the same way as in the previous section and\nO((et)t)(eet)et =def \u03bbn(et)t\u03bbveet\u03bbye(n \u03bbxe(v x y))\nsimply maps its (et)t meaning to (eet)et. Note that these definitions do not yet provide setting the It reference. This is because in general case it should be dereferenced to a meaning determined not only by the object noun phrase itself, but also by a verb applied to it. For example, \u201dit\u201d referencing the object in the verb phrases \u201dbuilds a house\u201d and \u201dsells a house\u201d should be dereferenced to different meanings: \u201da house which is built\u201d and \u201da house which is sold\u201d, respectively. Therefore, our It reference can be set only upon processing the entire verb phrase, as captured in the following axiom:\nVPssett = Verbt \u2217 (= /s/) \u2217\u2217ONP \u21d2 (SetIt, Apply) \u2228 (8.4)\n((= /is/) \u21d2 /be/) \u22b2VerbBe) \u2217\u2217ONP \u21d2\n(\u03bbveet\u03bbxcc\u03bbyc(eet)etIcc, Apply) \u2228\n((= /does not/) \u2217\u2217Verbt \u2228 ((= /is not/) \u21d2 /be/) \u22b2VerbBe) \u21d2\n(\u03bbveet\u03bbxcc\u03bbyc(eet)etIcc,\u223c Apply),\nwhere\nSetIt =def \u03bbveet\u03bbxcc\u03bbyc(eet)et\u03bbzc(Setref It \u03bbueet(y (x z) (v \u2227 u))),\nApply =def \u03bbveet\u03bbxcc\u03bbyc(eet)et\u03bbzc(y (x z) v).\nWe shall see below how interaction of axioms 8.3 and 8.4 makes the correct semantics, but so far have to complete our language definition.\nThe context-dependent versions of the compound declarative verb phrase, clause and sentence can be defined straightforward by the axioms\nVPmsett = VPs \u2217\u2217(= /and/) \u2212\u2192\u2217\u2217VPs \u21d2 \u03c1 (\u2227(et)(et)et)) \u2228\nVPs \u2217 (= /,/)\u2212\u2192\u2217\u2217VPm \u21d2 \u03c1 (\u2227(et)(et)et),\nVPs(et)tt = VPs \u2228 VPm,\nClstt = SNP \u2212\u2192\u2217\u2217VP \u21d2 \u03c1 I((et)t)(et)t,\nDSstt = Cl \u2217 (= /./) \u2228 (Cl \u2217 (= /,/) \u2212\u2192\u2217\u2217DS \u2228 Cl \u2217\u2217(= /and/)\u2212\u2192\u2217\u2217DS) \u21d2 \u03c1 (\u2227ttt),\nwhere (\u2212\u2192\u2217\u2217) =def \u03bbxs\u03b1t\u03bbys\u03b2t x \u2217 (= / /) \u2212\u2192\u2217 y,\nand \u03c1(\u03b1\u03b2)\u03b1\u03b2 =def \u03bbz\u03b1\u03b2\u03bbycc\u03bbyc\u03b1 (ycc, \u03bbxc (z (yc\u03b1 x))).\nNow, to add the simplest (\u201dyes/no\u201d) interrogative sentence to our language, we need the axioms like\nIVPdosett = Verbt \u2217\u2217ONP \u21d2 (SetIt, Apply), IVPbesett = ONP \u21d2 (\u03bbxcc\u03bbyc(eet)etIcc, Apply (=eet)),\nIClstt = ((= /does/) \u2217\u2217SNP \u2212\u2192\u2217\u2217 IVPdo \u2228 (= /is/) \u2217\u2217SNP\u2212\u2192\u2217\u2217 IVPbe) \u21d2\n\u03c1 I((et)t)(et)t,\nISstt = ICl \u2217 (= /?/).\nFinally, we wrap the declarative and interrogative sentences into the general sentence of the instructive type:\nSs(cc)t = DS \u21d2 \u03bbycc\u03bbyct(Asserttcc \u25e6 yct \u25e6 ycc) \u2228 (8.5)\nIS \u21d2 \u03bbycc\u03bbyct(Testtcc \u25e6 yct \u25e6 ycc).\nIf now \u2206S denotes the new set of axioms, then, due to the results of this section and in the assumption that TyAn has been extended by the axioms 8.1, 8.2, we will have, for example:\n\u2206S \u22a2 S /Jack is a builder./\n(Assert \u2203xe(Builder xe \u2227 Jack = xe) \u25e6 Setref He Jack),\n\u2206S \u22a2 S /is Jack a builder?/\n(Test \u2203xe(Builder xe \u2227 Jack = xe) \u25e6 Setref He Jack),\n\u2206S \u22a2 S /Jack is a builder, he builds a house./\n(Assert (\u2203xe(Builder xe \u2227 Jack = xe) \u2227\n\u2203xe(Build xe Jack \u2227 House xe)) \u25e6 Setref He Jack),\n\u2206S \u22a2 S /Jack builds a house and sells it./\n(Assert (\u2203xe(Build xe Jack \u2227 House xe) \u2227\n\u2203xe((Build \u2227 Sell) xe Jack \u2227 House xe)) \u25e6\nSetref It \u03bbueet\u03bbye\u2203xe((Build \u2227 ueet) xe ye \u2227 House xe) \u25e6\nSetref He Jack).\nDue to the metatheorem\n\u22a2 (\u2203xeA \u2227 \u2203xe(A \u2227 B)) = \u2203xe(A \u2227 B),\nwhere A and B are arbitrary formulas, the last derivation also implies a shorter form\n\u2206S \u22a2 S /Jack builds a house and sells it./\n(Assert (\u2203xe((Build \u2227 Sell) xe Jack \u2227 House xe)) \u25e6\nSetref It \u03bbueet\u03bbye\u2203xe((Build \u2227 ueet) xe ye \u2227 House xe) \u25e6\nSetref He Jack).\nSimilarly, we would have also\n\u2206S \u22a2 S /Every builder builds a house and sells it./\n(Assert (Builder \u2192 \u03bbye\u2203xe((Build \u2227 Sell) xe ye \u2227 House xe)) \u25e6\nSetref It \u03bbueet\u03bbye\u2203xe((Build \u2227 ueet) xe ye \u2227 House xe)).\nThe last examples give some hints on how this formalism could address donkey pronouns (Geach, 1962; Kamp, 1981; Heim, 1982; Elbourne, 2006), remaining entirely within the mainstream higher-order logic semantics. Of course, elaboration of this topic deserves a separate publication.\nNote that, due to the special semantic rules applied in the axiom 8.5, the sentence meaning captures not only an assertion or test instruction, but also all the \u201dside effects\u201d of its reading. This is essential in order to pass the side effects between sentences, if we would like to further define a language like\nTexts(cc)t = S \u2228 S \u2212\u2192\u2217\u2217Text \u21d2 (\u25e6(cc)(cc)cc),\nso that, if \u2206S contains this last axiom too, then we would also have\n\u2206S \u22a2 Text /Jack is a builder. he builds a house./\n(Assert \u2203xe(Build xe Jack \u2227 House xe) \u25e6\nSetref It \u03bbueet\u03bbye\u2203xe((Build \u2227 ueet) xe ye \u2227 House xe) \u25e6\nAssert \u2203xe(Builder xe \u2227 Jack = xe) \u25e6\nSetref He Jack)."}, {"heading": "9 Translation/expression operators and", "text": "partial translation\nLet an \u03b1-language L be represented by a term Ls\u03b1t and let w \u2208 A \u2217 be a non-ambiguous valid expression of this language, so that\n\u22a2 \u22031x\u03b1(Ls\u03b1t /w/ x\u03b1).\nThen, by the basic property of the description operator \u03b9(\u03b1t)\u03b1,\n\u22a2 \u03b9(\u03b1t)\u03b1(Ls\u03b1t /w/) = A\u03b1,\nwhere {A\u03b1} is any generator of the meaning of w in L (for a product type \u03b1 =def \u03b2 \u00d7 \u03b3 here and below \u03b9(\u03b1t)\u03b1 denotes the pair\n(\u03bbz\u03b2\u03b3t(\u03b9(\u03b2t)\u03b2 \u03bbx\u03b2\u2203x\u03b3(z\u03b2\u03b3t x\u03b2 x\u03b3)), \u03bbz\u03b2\u03b3t(\u03b9(\u03b3t)\u03b3 \u03bbx\u03b3\u2203x\u03b2(z\u03b2\u03b3t x\u03b2 x\u03b3))) (9.1)\nwhich definition may be applied recursively). Similarly, if {A\u03b1} is a generator of a meaning which has a single expression w in L, then\n\u22a2 \u03b9(st)s\u03bbxs(Ls\u03b1t xs A\u03b1) = /w/.\nThus, given an \u03b1-language represented by a term Ls\u03b1t, the terms\n\u03c4(s\u03b1t)s\u03b1 =def \u03bbxs\u03b1t\u03bbxs(\u03b9(\u03b1t)\u03b1 (xs\u03b1t xs))\nand \u03c3(s\u03b1t)\u03b1s =def \u03bbxs\u03b1t\u03bbx\u03b1(\u03b9(st)s \u03bbxs(xs\u03b1t xs x\u03b1))\nenable Tyn representations of expression-to-meaning and meaning-to-expression mapping determined by the language, in forms like \u03c4(s\u03b1t)s\u03b1 Ls\u03b1t and \u03c3(s\u03b1t)\u03b1s Ls\u03b1t respectively. They are referred to below as translation and expression operators.\nApplication of the translation operator to an invalid expression, of course, is not provable to be equal to any meaning. However, it still represents a meaning that the expression might acquire upon possible completion of the language definition. Here is a precise formulation of this statement:\nProposition 9.1. Let (\u2206, Ls\u03b1t) be a pseudo-canonic representation of a language L and\nL+s\u03b1t =def Ls\u03b1t \u2228 \u03bbxs(= \u03c4(s\u03b1t)s\u03b1 Ls\u03b1t xs). (9.2)"}, {"heading": "If w is either a valid and non-ambiguous or invalid expression of L, then", "text": "\u2206 \u22a2 \u03c4(s\u03b1t)s\u03b1 L + s\u03b1t /w/ = \u03c4(s\u03b1t)s\u03b1 Ls\u03b1t /w/.\nProof. If w is a non-ambiguous valid expression of L and A\u03b1 its meaning, then\n\u2206 \u22a2 Ls\u03b1t /w/ = (= A\u03b1)\nand \u2206 \u22a2 \u03b9(\u03b1t)\u03b1 (Ls\u03b1t /w/) = A\u03b1,\nso that \u2206 \u22a2 L+s\u03b1t /w/ = Ls\u03b1t /w/.\nOtherwise, if w is an invalid expression, then by Lemma 6.1\n\u2206 \u22a2 Ls\u03b1t /w/ = \u03bbx\u03b1F,\nso that \u2206 \u22a2 L+s\u03b1t /w/ = (= \u03c4(s\u03b1t)s\u03b1 Ls\u03b1t xs)\nand therefore \u2206 \u22a2 \u03b9(\u03b1t)\u03b1 (L + s\u03b1t /w/) = \u03c4(s\u03b1t)s\u03b1 Ls\u03b1t xs.\nThus, the language defined by (9.2) extends the language L with all and only those pairs (w, \u03c4(s\u03b1t)s\u03b1Ls\u03b1t/w/) in which w is not a valid non-ambiguous expression of L, while similar pairs in which w is such an expression are fully contracted. In this sense, such a self-extension of a language L does not add anything new to it. However, when a language is nested into another language of a recursive grammar, employment of its self-extension enables some new and useful features, as established by the following\nProposition 9.2. Let (\u2206, Ls\u03b1t) and (\u2206, Ks\u03b2t) be pseudo-canonic representations of languages L and K respectively and let uv be a single split of a word w such that v is a valid expression of K.\nIf, additionally, v is a non-ambiguous expression of K with the meaning B\u03b2 and u an invalid expression of L, then\n\u2206 \u22a2 \u03c4(s\u03b1\u03b2t)s(\u03b1\u00d7\u03b2) (L + s\u03b1t \u2217K + s\u03b2t) /w/ = (\u03c4(s\u03b1t)s\u03b1 Ls\u03b1t /u/, B\u03b2). (9.3)\nIf, alternatively, uv is a single split of a word w such that u is valid expression of L and, additionally, u is a non-ambiguous expression of L with the meaning A\u03b1 and v - an invalid expression of K, then\n\u2206 \u22a2 \u03c4(s\u03b1\u03b2t)s(\u03b1\u00d7\u03b2) (L + s\u03b1t \u2217K + s\u03b2t) /w/ = (A\u03b1, \u03c4(s\u03b2t)s\u03b2 Ks\u03b2t /v/). (9.4)\nProof. In a similar way to the proof of Proposition 7.7, taking into account Proposition 9.1, for the first case we obtain\n\u2206 \u22a2 (L+s\u03b1t \u2217K + s\u03b2t) /w/ = (= \u03c4(s\u03b1t)s\u03b1 Ls\u03b1t /u/) &(= B\u03b2)\nand for the second case\n\u2206 \u22a2 (L+s\u03b1t \u2217K + s\u03b2t) /w/ = (= A\u03b1) &(= \u03c4(s\u03b2t)s\u03b2 Ks\u03b2t /v/).\n(9.3) and (9.4) follow from this according to (9.1).\nThe three features of the partial translations (9.3) and (9.4) worth noting are:\n1. they capture the correct overall structure of a precise meaning that the concatenation would acquire upon elaboration of an incomplete nested language;\n2. they allow accurate restoration of their expressions uv = w even while a nested language remains incomplete;\n3. translation of only a single constituent is sufficient to convert a partial translation to the full translation (A\u03b1, B\u03b2) upon an elaboration of an incomplete nested language.\nFor example, consider the self-extension\nS+ =def S \u2228 \u03bbxs(= \u03c4(stt)st S xs)\nof the sample grammar we built in section 4. If \u2206S denots the same set of axioms as in that section, then we will have, for example:\n\u2206S \u22a2 S + /Jack paints a house/\n\u2203xe(\u03c4(s(eet)t)eet Verbt /paint/ xe Jack \u2227 House xe),\n\u2206S \u22a2 S + /Jack builds a computer/\n\u2203xe(Build xe Jack \u2227 \u03c4(s(et)t)et Noun /computer/ xe),\nthat illustrates both features 1 and 2. Now assume lexicon Noun be extended with an entry (= /computer/) \u21d2 Computeret and let \u2206 \u2032 S denote the changed axiom set. Then the derivation\n\u2206\u2032S \u22a2 \u2203xe(Build xe Jack \u2227 \u03c4(s(et)t)et Noun /computer/ xe) =\n\u2203xe(Build xe Jack \u2227 Computer xe)\nfollows immediately from\n\u2206\u2032S \u22a2 Noun /computer/ = (= Computer),\nthat illustrates the feature 3."}, {"heading": "10 Conclusion", "text": "In this work we studied some classes of languages that can be defined entirely in terms of provability in an extension (TyAn ) of sorted type theory by interpreting one of its base types as symbolic, whose constants denote symbols of an alphabet A or their concatenations. The symbolic type (s) is quite similar to the phonological type of Higher Order Grammar (HOG) (Pollard & Hana, 2003; Pollard, 2004; Pollard, 2006). However, the theory TyAn differs from the logic of HOG in that it does not contain special types for syntactic entities.\nWe launched from the two simple observations. First, given an arbitrary consistent set \u2206 of non-logical axioms and a term of type s\u03b1t, one can define an \u03b1-language, i.e. a relation between strings of symbols from alphabet A and terms of type \u03b1, by the condition\n\u2206 \u22a2 Ls\u03b1t /w/ A\u03b1,\nwhere /w/ stands for an s-term denoting a word (string) w \u2208 A\u2217. Secondly, any Tyn-representable language, i.e. a language that can be defined this way, necessarily possesses the semantic property of being logically closed, meaning, loosely speaking, that the full semantic interpretation of every valid expression of the language is given by a whole class of logically equivalent terms.\nNext, we proved that the inverse statement is also true, that is, every logically closed language is Tyn-representable. This general result, however, is not constructive in the sense that it does not provide an effective procedure of actually building a Tyn representation for a language defined by a finite set of rules or rule schemata. Our further efforts therefore concentrated mainly on finding such procedures for some important special classes of logically closed languages.\nWe began this with definitions of \u03b1-lexicons and a special canonic representation and proved that a language has a canonic representation if and\nonly if it is a lexicon. The canonic representation of a lexicon is efficiently found from the description of the lexicon.\nThen we defined and investigated recursive grammars - a kind of transformational grammars equipped with Tyn semantics. We introduced Tyn operators representing the basic language-construction operations used in the recursive grammar rules and proved that a compact Tyn representation for every language component of a recursive grammar comes from its rules in a quite straightforward manner. We illustrated this technique by simple examples, from which it became clear that language components of a recursive grammar stand for syntactic categories. We also briefly discussed classification of recursively defined Tyn-representable languages in terms of Chomsky hierarchy and on this basis indicated some conditions of when such languages turn out to be decidable, in spite of the fact that Tyn is undecidable and hence so are generally Tyn-representable languages.\nThen we moved to a further specialization of TyAn by introducing the context type (c), which can be interpreted as a \u201dstore\u201d or \u201dstate\u201d and thus is similar to \u201dstate of affairs\u201d or \u201dWorld\u201d types of (Gallin, 1975) and (Pollard, 2005), respectively. We showed that our interpretation allows to model not only languages with intensional semantics (as in the above referenced works), but also so called instructive and context dependent languages. The latter come in our formalism in result of transformation of an \u03b1-language to state-passing style (SPS) (Wadler, 1992; Sabry, 1995; Jones, 2003) c(c \u00d7 \u03b1)-language, which enables passing \u201dside effects\u201d of parsing some text constituents to others. An instructive, i.e. a cc-language can be considered as a context dependent transformation of a unit-type language and provides semantic features that principally could not be modeled by a regular t-language nor by its intensional (ct) transformation. We found Tyn representations of context-dependent language construction operations (anaphoric and cataphoric concatenations and context raising and instantiation) that allow generalization of the previous results for context-dependent languages. We demonstrated how this formalism can address pronoun anaphora resolution.\nFinally, we defined translation and expression TyAn operators and introduced a special language representation (self-extension), revealing a useful property of partial translation.\nThe proposed formalism efficiently addresses the known issues inherent in the two-component language models and also partially inherited by HOG. Indeed,\n1. as there are no restrictions on a type of meanings of a Tyn-representable language or a component of it, which type, in particular, can be constructed with use of the symbolic type too, such a language can generally express facts about itself or about another Tyn-representable language;\n2. the property of partial translation of a self-extensible Tyn language representation demonstrates its built-in lexical robustness;\n3. as syntactic categories are not captured in the Tyn logic, but introduced only in non-logical axioms defining a concrete language, the Tyn representation provides full structural robustness and flexibility.\nThese results have both theoretical and practical implications. First, they facilitate modeling of such fundamental abilities associated with the human language acquisition process like communication of new grammar rules and lexical entries directly in an (already acquired) sub-set of the object language and independently acquiring new lexical entries upon encountering them in a known context, with postponed acquisition of their exact meanings. Other possible applications of the proposed formalism may include:\n1. addressing donkey pronouns (Geach, 1962; Kamp, 1981; Heim, 1982; Elbourne, 2006) and other dynamic semantic phenomena entirely within the mainstream higher-order logic semantics, as it was preliminarily outlined in section 8;\n2. modeling advanced language self-learning mechanisms, for example, such like deriving or generalization of grammar rules from text samples (may be accompanied by their semantic interpretation, communicated by other means or just expressed differently in the same language), that might be reduced, in frame of this formalism, to a problem of higher-order unification (Gardent et al., 1997; Dougherty & Mart\u0301\u0131nez, 2004).\nFinally, an implementation of the proposed formalism, like that suggested in (Gluzberg & Brenner, 2006), should provide a platform for building NLP systems with the following powerful features:\n1. the ability to recursively define more complex or more comprehensive languages in terms of previously defined simpler or limited ones;\n2. automatically acquiring new lexical entries in the process of operation;\n3. storing partial text parses which can be automatically completed later, upon extending the used language definition;\n4. freely switching between different input and output languages to access the same semantic content."}], "references": [{"title": "An Introduction to Mathematical Logic and Type Theory: To Truth Through Proof", "author": ["P.B. Andrews"], "venue": "(San Diego, CA, USA: Academic Press Professional, Inc.).", "citeRegEx": "Andrews,? 1986", "shortCiteRegEx": "Andrews", "year": 1986}, {"title": "Logical Aspects of Computational Linguistics: an Introduction (In Retor\u00e9, C. (Ed.), LACL\u201996", "author": ["P. Blackburn", "M. Dymetman", "A. Lecomte", "A. Ranta", "C. Retor\u00e9", "E.V. de la Clergerie"], "venue": "First International Conference on Logical Aspects of Computational Linguistics (pp. 1\u201320). Berlin: Springer-Verlag)", "citeRegEx": "Blackburn et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Blackburn et al\\.", "year": 1997}, {"title": "Unification and matching modulo type isomorphism", "author": ["D. Dougherty", "C. Mart\u0301\u0131nez"], "venue": "Proceedings of II international workshop of higher order rewriting", "citeRegEx": "Dougherty and Mart\u0301\u0131nez,? \\Q2004\\E", "shortCiteRegEx": "Dougherty and Mart\u0301\u0131nez", "year": 2004}, {"title": "Situations and individuals. Current Studies in Linguistics", "author": ["Elbourne", "Paul D"], "venue": null, "citeRegEx": "Elbourne and D.,? \\Q2006\\E", "shortCiteRegEx": "Elbourne and D.", "year": 2006}, {"title": "WordNet: An electronic lexical database", "author": ["Fellbaum", "Christiane"], "venue": null, "citeRegEx": "Fellbaum and Christiane,? \\Q1998\\E", "shortCiteRegEx": "Fellbaum and Christiane", "year": 1998}, {"title": "Intensional and Higher-Order Modal Logic with Applications to Montague Semantics", "author": ["D. Gallin"], "venue": "(Amsterdam: North-Holland Publishing Company).", "citeRegEx": "Gallin,? 1975", "shortCiteRegEx": "Gallin", "year": 1975}, {"title": "A multi-level, higher-order unification approach to ellipsis", "author": ["Gardent", "Claire", "Kohlhase", "Michael", "Konrad", "Karsten"], "venue": null, "citeRegEx": "Gardent et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Gardent et al\\.", "year": 1997}, {"title": "Reference and generality: An examination of some medieval and modern theories", "author": ["P.T. Geach"], "venue": null, "citeRegEx": "Geach,? \\Q1962\\E", "shortCiteRegEx": "Geach", "year": 1962}, {"title": "A note on Higher Order Grammar. Corr, abs/0910.0537", "author": ["Gluzberg", "Victor"], "venue": null, "citeRegEx": "Gluzberg and Victor.,? \\Q2009\\E", "shortCiteRegEx": "Gluzberg and Victor.", "year": 2009}, {"title": "Method and system for processing, storing, retrieving and presenting information with an extendable interface for natural and artificial languages. US Patent 6,999,934", "author": ["V. Gluzberg", "A. Brenner"], "venue": null, "citeRegEx": "Gluzberg and Brenner,? \\Q2006\\E", "shortCiteRegEx": "Gluzberg and Brenner", "year": 2006}, {"title": "Dynamic montague grammar. Pages 3\u201348 of: Papers from the second symposium on logic and language. Akademiai Kiadoo", "author": ["Groenendijk", "Jeroen", "Stokhof", "Martin"], "venue": null, "citeRegEx": "Groenendijk et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Groenendijk et al\\.", "year": 1989}, {"title": "Dynamic predicate logic", "author": ["Groenendijk", "Jeroen", "Stokhof", "Martin"], "venue": "Linguistics and philosophy,", "citeRegEx": "Groenendijk et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Groenendijk et al\\.", "year": 1990}, {"title": "The semantics of definite and indefinite noun phrases", "author": ["Heim", "Irene"], "venue": "Ph.D. thesis,", "citeRegEx": "Heim and Irene.,? \\Q1982\\E", "shortCiteRegEx": "Heim and Irene.", "year": 1982}, {"title": "File change semantics and the familiarity theory of definiteness", "author": ["Heim", "Irene"], "venue": "Pages 114\u2013126", "citeRegEx": "Heim and Irene.,? \\Q1983\\E", "shortCiteRegEx": "Heim and Irene.", "year": 1983}, {"title": "Haskell 98 language and libraries: The revised report", "author": ["Jones", "Simon Peyton"], "venue": null, "citeRegEx": "Jones and Peyton.,? \\Q2003\\E", "shortCiteRegEx": "Jones and Peyton.", "year": 2003}, {"title": "A theory of truth and semantic representation. Pages 277\u2013321", "author": ["Kamp", "Hans"], "venue": null, "citeRegEx": "Kamp and Hans.,? \\Q1981\\E", "shortCiteRegEx": "Kamp and Hans.", "year": 1981}, {"title": "A logical semantics for feature structures. Pages 257\u2013266 of: Acl proceedings, 24th annual meeting", "author": ["Kasper", "Robert", "Rounds", "William"], "venue": null, "citeRegEx": "Kasper et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Kasper et al\\.", "year": 1986}, {"title": "A Logical Formalism for Head-Driven Phrase Structure Grammar", "author": ["King", "Paul John"], "venue": null, "citeRegEx": "King and John.,? \\Q1989\\E", "shortCiteRegEx": "King and John.", "year": 1989}, {"title": "The mathematics of sentence structure", "author": ["Lambek", "Joachim"], "venue": "American mathematical monthly,", "citeRegEx": "Lambek and Joachim.,? \\Q1958\\E", "shortCiteRegEx": "Lambek and Joachim.", "year": 1958}, {"title": "Higher-order categorical grammar", "author": ["Pollard", "Carl"], "venue": "Proceedings of the International Conference on Categorial Grammars (CG2004). http://www.ling.ohiostate.edu/", "citeRegEx": "Pollard and Carl.,? \\Q2004\\E", "shortCiteRegEx": "Pollard and Carl.", "year": 2004}, {"title": "Hyperintensional semantics in a higher order logic with definable subtypes. Pages 32\u201345 of: Proceedings of the second workshop on lambda calculus, type theory, and natural language, king\u2019s college london", "author": ["Pollard", "Carl"], "venue": null, "citeRegEx": "Pollard and Carl.,? \\Q2005\\E", "shortCiteRegEx": "Pollard and Carl.", "year": 2005}, {"title": "Higher order grammar (introductory course, language and logic section). In: The 18th European Summer School in Logic, Language and Information", "author": ["Pollard", "Carl"], "venue": null, "citeRegEx": "Pollard and Carl.,? \\Q2006\\E", "shortCiteRegEx": "Pollard and Carl.", "year": 2006}, {"title": "Ambiguity, neutrality, and coordination in higher order grammar", "author": ["Pollard", "Carl", "Hana", "Jiri"], "venue": "Proceedings of formal grammar. http://www.ling.ohio-state.edu/", "citeRegEx": "Pollard et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Pollard et al\\.", "year": 2003}, {"title": "A mathematical formalism for linguistic theories with an application in head-driven phrase structure grammar. Phil", "author": ["Richter", "Frank"], "venue": null, "citeRegEx": "Richter and Frank.,? \\Q2004\\E", "shortCiteRegEx": "Richter and Frank.", "year": 2004}, {"title": "The formal relationship between direct and continuation-passing style optimizing compilers: a synthesis of two paradigms", "author": ["Sabry", "Amr Afaf"], "venue": "Ph.D. thesis,", "citeRegEx": "Sabry and Afaf.,? \\Q1995\\E", "shortCiteRegEx": "Sabry and Afaf.", "year": 1995}, {"title": "Formal philosophy: Selected Papers of Richard Montague. New Haven (Conn.) (etc.): Yale", "author": ["Thomason", "Richmond H. (ed"], "venue": null, "citeRegEx": "Thomason and .ed..,? \\Q1974\\E", "shortCiteRegEx": "Thomason and .ed..", "year": 1974}, {"title": "The essence of functional programming. Pages 1\u201314 of: Popl \u201992: Proceedings of the 19th acm sigplan-sigact symposium on principles of programming languages", "author": ["Wadler", "Philip"], "venue": "USA: ACM", "citeRegEx": "Wadler and Philip.,? \\Q1992\\E", "shortCiteRegEx": "Wadler and Philip.", "year": 1992}], "referenceMentions": [{"referenceID": 1, "context": "This two-component architecture of a language model has not essentially changed with the invention and further rapid development of type-logical grammar (Lambek, 1958; Blackburn et al., 1997), i.", "startOffset": 153, "endOffset": 191}, {"referenceID": 5, "context": "In Section 8 we consider a further specialization of Ty n by interpreting another base type as a context, similar (though not identical) to \u201dstate of affairs\u201d or \u201dWorld\u201d types of (Gallin, 1975) and (Pollard, 2005), respectively.", "startOffset": 179, "endOffset": 193}, {"referenceID": 5, "context": "Following (Gallin, 1975), we denote by Tyn a sorted type theory with a set of primitive types consisting of the truth type t and individual types e1, e2, .", "startOffset": 10, "endOffset": 24}, {"referenceID": 5, "context": "For sake of better visibility and compactness we combine the full syntax of Tyn from syntaxes of Ty2 of (Gallin, 1975) and Q0 of (Andrews, 1986) and extend it as follows.", "startOffset": 104, "endOffset": 118}, {"referenceID": 0, "context": "For sake of better visibility and compactness we combine the full syntax of Tyn from syntaxes of Ty2 of (Gallin, 1975) and Q0 of (Andrews, 1986) and extend it as follows.", "startOffset": 129, "endOffset": 144}, {"referenceID": 0, "context": "Note that, unlike (Andrews, 1986), we write \u201cfrom\u201d and \u201cto\u201d types from left to right.", "startOffset": 18, "endOffset": 33}, {"referenceID": 5, "context": "We assume an axiomatization of Tyn be a straightforward generalization to case of n > 2 individual types of either the theory denoted as Tyn + D in (Gallin, 1975) or the theory Q0 of (Andrews, 1986).", "startOffset": 148, "endOffset": 162}, {"referenceID": 0, "context": "We assume an axiomatization of Tyn be a straightforward generalization to case of n > 2 individual types of either the theory denoted as Tyn + D in (Gallin, 1975) or the theory Q0 of (Andrews, 1986).", "startOffset": 183, "endOffset": 198}, {"referenceID": 5, "context": "Introduction of an additional sort of individuals in Ty2 of (Gallin, 1975) allowed to accurately interpret in this theory the intensional logic (IL), that implied interpretation of the corresponding type (s in Gallin\u2019s notations, not to be confused with the symbolic type of this work) as a set of possible \u201cstates of world\u201d or \u201cstates of affairs\u201d.", "startOffset": 60, "endOffset": 74}, {"referenceID": 5, "context": "Unlike that, in our model, vice-versa, the context type c is introduced as primitive and the propositional type can be defined as the functional type ct (see (Gallin, 1975)).", "startOffset": 158, "endOffset": 172}, {"referenceID": 5, "context": "To summarize this introductory informal discussion, we can state that, while type s of (Gallin, 1975) and type World of (Pollard, 2005) stand for \u201cstates of world\u201d, the similar to them type c of our model stands rather for \u201cstates of an individual mind\u201d, which mind is not necessarily complete nor consistent, but, on one hand, still determines interpretation of a text and, on the other hand, is changeable (in particular, extendable) in the process of interpretation.", "startOffset": 87, "endOffset": 101}, {"referenceID": 7, "context": "The last examples give some hints on how this formalism could address donkey pronouns (Geach, 1962; Kamp, 1981; Heim, 1982; Elbourne, 2006), remaining entirely within the mainstream higher-order logic semantics.", "startOffset": 86, "endOffset": 139}, {"referenceID": 5, "context": "Then we moved to a further specialization of Ty n by introducing the context type (c), which can be interpreted as a \u201dstore\u201d or \u201dstate\u201d and thus is similar to \u201dstate of affairs\u201d or \u201dWorld\u201d types of (Gallin, 1975) and (Pollard, 2005), respectively.", "startOffset": 198, "endOffset": 212}, {"referenceID": 7, "context": "addressing donkey pronouns (Geach, 1962; Kamp, 1981; Heim, 1982; Elbourne, 2006) and other dynamic semantic phenomena entirely within the mainstream higher-order logic semantics, as it was preliminarily outlined in section 8;", "startOffset": 27, "endOffset": 80}, {"referenceID": 6, "context": "modeling advanced language self-learning mechanisms, for example, such like deriving or generalization of grammar rules from text samples (may be accompanied by their semantic interpretation, communicated by other means or just expressed differently in the same language), that might be reduced, in frame of this formalism, to a problem of higher-order unification (Gardent et al., 1997; Dougherty & Mart\u0301\u0131nez, 2004).", "startOffset": 365, "endOffset": 416}], "year": 2014, "abstractText": "We examine the class of languages that can be defined entirely in terms of provability in an extension of the sorted type theory (Tyn) by embedding the logic of phonologies, without introduction of special types for syntactic entities. This class is proven to precisely coincide with the class of logically closed languages that may be thought of as functions from expressions to sets of logically equivalent Tyn terms. For a specific sub-class of logically closed languages that are described by finite sets of rules or rule schemata, we find effective procedures for building a compact Tyn representation, involving a finite number of axioms or axiom schemata. The proposed formalism is characterized by some useful features unavailable in a two-component architecture of a language model. A further specialization and extension of the formalism with a context type enable effective account of intensional and dynamic semantics.", "creator": "dvips(k) 5.98 Copyright 2009 Radical Eye Software"}}}