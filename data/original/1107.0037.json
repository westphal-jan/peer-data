{"id": "1107.0037", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2011", "title": "Competitive Coevolution through Evolutionary Complexification", "abstract": "Two major goals in machine learning are the discovery and improvement of solutions to complex problems. In this paper, we argue that complexification, i.e. the incremental elaboration of solutions through adding new structure, achieves both these goals. We demonstrate the power of complexification through the NeuroEvolution of Augmenting Topologies (NEAT) method, which evolves increasingly complex neural network architectures. NEAT is applied to an open-ended coevolutionary robot duel domain where robot controllers compete head to head. Because the robot duel domain supports a wide range of strategies, and because coevolution benefits from an escalating arms race, it serves as a suitable testbed for studying complexification. When compared to the evolution of networks with fixed structure, complexifying evolution discovers significantly more sophisticated strategies. The results suggest that in order to discover and improve complex solutions, evolution, and search in general, should be allowed to complexify as well as optimize.", "histories": [["v1", "Thu, 30 Jun 2011 20:36:55 GMT  (755kb)", "http://arxiv.org/abs/1107.0037v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["r miikkulainen", "k o stanley"], "accepted": false, "id": "1107.0037"}, "pdf": {"name": "1107.0037.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Kenneth O. Stanley", "kstanley s.utexas.edu", "Risto Miikkulainen"], "emails": [], "sections": [{"heading": "Journal of Arti ial Intelligen e Resear h 21 (2004) 63-100 Submitted 8/03; published 2/04", "text": "Competitive Coevolution through EvolutionaryComplexi ationKenneth O. Stanley kstanley s.utexas.eduRisto Miikkulainen risto s.utexas.eduDepartment of Computer S ien esThe University of Texas at AustinAustin, TX 78712 USA Abstra tTwo major goals in ma hine learning are the dis overy and improvement of solutions to omplex problems. In this paper, we argue that omplexi ation, i.e. the in remental elab-oration of solutions through adding new stru ture, a hieves both these goals. We demon-strate the power of omplexi ation through the NeuroEvolution of Augmenting Topologies(NEAT) method, whi h evolves in reasingly omplex neural network ar hite tures. NEATis applied to an open-ended oevolutionary robot duel domain where robot ontrollers om-pete head to head. Be ause the robot duel domain supports a wide range of strategies, andbe ause oevolution bene ts from an es alating arms ra e, it serves as a suitable testbed forstudying omplexi ation. When ompared to the evolution of networks with xed stru -ture, omplexifying evolution dis overs signi antly more sophisti ated strategies. Theresults suggest that in order to dis over and improve omplex solutions, evolution, andsear h in general, should be allowed to omplexify as well as optimize.1. Introdu tionEvolutionary Computation (EC) is a lass of algorithms that an be applied to open-endedlearning problems in Arti ial Intelligen e. Traditionally, su h algorithms evolve xed-length genomes under the assumption that the spa e of the genome is su\u00c6 ient to en odethe solution. A genome ontaining n genes en odes a single point in an n-dimensional sear hspa e. In many ases, a solution is known to exist somewhere in that spa e. For example,the global maximum of a fun tion of three arguments must exist in the three dimensionalspa e de ned by those arguments. Thus, a genome of three genes an en ode the lo ationof the maximum.However, many ommon stru tures are de ned by an inde nite number of parameters.In parti ular, those solution types that an ontain a variable number of parts an berepresented by any number of parameters above some minimum. For example, the numberof parts in neural networks, ellular automata, and ele troni ir uits an vary (Miller, Job,& Vassilev, 2000a; Mit hell, Crut h eld, & Das, 1996; Stanley & Miikkulainen, 2002d). Infa t, theoreti ally two neural networks with di erent numbers of onne tions and nodes anrepresent the same fun tion (Cybenko, 1989). Thus, it is not lear what number of genes isappropriate for solving a parti ular problem. Resear hers evolving xed-length genotypesmust use heuristi s to estimate a priori the appropriate number of genes to en ode su hstru tures. 2004 AI A ess Foundation and Morgan Kaufmann Publishers. All rights reserved.\nStanley & MiikkulainenA major obsta le to using xed-length en odings is that heuristi ally determining theappropriate number of genes be omes impossible for very omplex problems. For example,how many nodes and onne tions are ne essary for a neural network that ontrols a ping-pong playing robot? Or, how many bits are needed in the neighborhood fun tion of a ellular automaton that performs information ompression? The answers to these questions an hardly be based on empiri al experien e or analyti methods, sin e little is knownabout the solutions. One possible approa h is to simply make the genome extremely large,so that the spa e it en odes is extremely large and a solution is likely to lie somewherewithin. Yet the larger the genome, the higher dimensional the spa e that evolution needs tosear h. Even if a ping-pong playing robot lies somewhere in the 10,000 dimensional spa eof a 10,000 gene genome, sear hing su h a spa e may take prohibitively long.Even more problemati are open-ended problems where phenotypes are meant to im-prove inde nitely and there is no known nal solution. For example, in ompetitive games,estimating the omplexity of the \\best\" possible player is di\u00c6 ult be ause su h an estimateimpli itly assumes that no better player an exist, whi h we annot always know. Moreover,many arti ial life domains are aimed at evolving in reasingly omplex arti ial reaturesfor as long as possible (Maley, 1999). Su h ontinual evolution is di\u00c6 ult with a xedgenome for two reasons: (1) When a good strategy is found in a xed-length genome, theentire representational spa e of the genome is used to en ode it. Thus, the only way toimprove it is to alter the strategy, thereby sa ri ing some of the fun tionality learned overprevious generations. (2) Fixing the size of the genome in su h domains arbitrarily xesthe maximum omplexity of evolved reatures, defeating the purpose of the experiment.In this paper, we argue that stru tured phenotypes an be evolved e e tively by start-ing evolution with a population of small, simple genomes and systemati ally elaboratingon them over generations by adding new genes. Ea h new gene expands the sear h spa e,adding a new dimension that previously did not exist. That way, evolution begins sear hingin a small easily-optimized spa e, and adds new dimensions as ne essary. This approa his more likely to dis over highly omplex phenotypes than an approa h that begins sear h-ing dire tly in the intra tably large spa e of omplete solutions. In fa t, natural evolutionutilizes this strategy, o asionally adding new genes that lead to in reased phenotypi om-plexity (Martin 1999; Se tion 2). In biology, this pro ess of in remental elaboration is alled omplexi ation, whi h is why we use this term to des ribe our approa h as well.In evolutionary omputation, omplexi ation refers to expanding the dimensionalityof the sear h spa e while preserving the values of the majority of dimensions. In otherwords, omplexi ation elaborates on the existing strategy by adding new stru ture without hanging the existing representation. Thus the strategy does not only be ome di erent, butthe number of possible responses to situations it an generate in reases (Figure 1).In the EC domain of neuroevolution (i.e. evolving neural networks), omplexi ationmeans adding nodes and onne tions to already-fun tioning neural networks. This is themain idea behind NEAT (NeuroEvolution of Augmenting Topologies; Stanley and Miikku-lainen 2002b, ,d), the method des ribed in this paper. NEAT begins by evolving networkswithout any hidden nodes. Over many generations, new hidden nodes and onne tions areadded, omplexifying the spa e of potential solutions. In this way, more omplex strategieselaborate on simpler strategies, fo using sear h on solutions that are likely to maintainexisting apabilities. 64\nCompetitive Coevolution through Evolutionary Complexifi ation Original Strategy Strategy Fails Altered Strategy Strategy Fails\nOriginal Strategy Strategy Fails Elaborated Strategy Skill Remains!\nAlteration\nElaboration\nFigure 1: Alteration vs. elaboration example. The dark robot must evolve to avoid thelighter robot, whi h attempts to ause a ollision. In the alteration s enario (top), thedark robot rst evolves a strategy to go around the left side of the opponent. However,the strategy fails in a future generation when the opponent begins moving to the left.Thus, the dark robot alters its strategy by evolving the tenden y to move right insteadof left. However, when the light robot later moves right, the new, altered, strategy failsbe ause the dark robot did not retain its old ability to move left. In the elaborations enario (bottom), the original strategy of moving left also fails. However, instead ofaltering the strategy, it is elaborated by adding a new ability to move right as well. Thus,when the opponent later moves right, the dark robot still has the ability to avoid it byusing its original strategy. Elaboration is ne essary for a oevolutionary arms ra e toemerge and it an be a hieved through omplexi ation.Expanding the length of the size of the genome has been found e e tive in previouswork (Cli , Harvey, & Husbands, 1993; Harvey, 1993; Koza, 1995; Lindgren & Johansson,2001). NEAT advan es this idea by making it possible to sear h a wide range of in reas-ingly omplex network topologies simultaneously. This pro ess is based on three te hni al omponents: (1) Keeping tra k of whi h genes mat h up with whi h among di erently sizedgenomes throughout evolution; (2) spe iating the population so that solutions of di ering omplexity an exist independently; and (3) starting evolution with a uniform populationof small networks. These omponents work together in omplexifying solutions as part ofthe evolutionary pro ess. In prior work, NEAT has been shown to solve hallenging rein-for ement learning problems more e\u00c6 iently than other neuroevolution methods (Stanleyand Miikkulainen 2002b, ,d). The fo us of these studies was on optimizing a given tnessfun tion through omplexifying evolution. 65\nStanley & MiikkulainenIn this paper, we fo us on open-ended problems that have no expli it tness fun tion;instead, tness depends on omparisons with other agents that are also evolving. The goalis to dis over reative solutions beyond a designer's ability to de ne a tness fun tion. It isdi\u00c6 ult to ontinually improve solutions in su h oevolutionary domains be ause evolutiontends to os illate between idiosyn rati yet uninteresting solutions (Floreano & Nol , 1997).Complexi ation en ourages ontinuing innovation by elaborating on existing solutions.In order to demonstrate the power of omplexi ation in oevolution, NEAT is appliedto the ompetitive robot ontrol domain of Robot Duel. There is no known optimal strategyin the domain but there is substantial room to ome up with in reasingly sophisti atedstrategies. The main results were that (1) evolution did omplexify when possible, (2) omplexi ation led to elaboration, and (3) signi antly more sophisti ated and su essfulstrategies were evolved with omplexi ation than without it. These results imply that omplexi ation allows establishing a oevolutionary arms ra e that a hieves a signi antlyhigher level of sophisti ation than is otherwise possible.We begin by reviewing biologi al support for omplexi ation, as well as past work in oevolution, followed by a des ription of the NEAT method, and experimental results.2. Ba kgroundThe natural pro ess of omplexi ation has led to important biologi al innovations. Itsmost natural appli ation in EC is in ompetitive oevolution, as will be reviewed below.2.1 Complexi ation in NatureMutation in nature not only results in optimizing existing stru tures: New genes are o a-sionally added to the genome, allowing evolution to perform a omplexifying fun tion overand above optimization. In addition, omplexi ation is prote ted in nature in that inter-spe ies mating is prohibited. Su h spe iation reates important dynami s di ering fromstandard GAs. In this se tion, we dis uss these hara teristi s of natural evolution as abasis for our approa h to utilizing them omputationally in geneti algorithms.Gene dupli ation is a spe ial kind of mutation in whi h one or more parental genes are opied into an o spring's genome more than on e. The o spring then has redundant genesexpressing the same proteins. Gene dupli ation has been responsible for key innovations inoverall body morphology over the ourse of natural evolution (Amores, For e, Yan, Joly,Amemiya, Fritz, Ho, Langeland, Prin e, Wang, Wester eld, Ekker, & Postlethwait, 1998;Carroll, 1995; For e, Lyn h, Pi kett, Amores, lin Yan, & Postlethwait, 1999; Martin, 1999).A major gene dupli ation event o urred around the time that vertebrates separatedfrom invertebrates. The eviden e for this dupli ation enters around HOX genes, whi hdetermine the fate of ells along the anterior-posterior axis of embryos. HOX genes are ru ial in shaping the overall pattern of development in embryos. In fa t, di eren es inHOX gene regulation explain a great deal of the diversity among arthropods and tetrapods(Carroll, 1995). Invertebrates have a single HOX luster while vertebrates have four, sug-gesting that luster dupli ation signi antly ontributed to elaborations in vertebrate body-plans (Amores et al., 1998; Holland, Gar ia-Fernandez, Williams, & Sidow, 1994; Nadeau& Sanko , 1997; Postlethwait, Yan, Gates, Horne, Amores, Brownlie, & Donovan, 1998;Sidow, 1996). The additional HOX genes took on new roles in regulating how vertebrate66\nCompetitive Coevolution through Evolutionary Complexifi ationanterior-posterior axis develops, onsiderably in reasing body-plan omplexity. AlthoughMartin (1999) argues that the additional lusters an be explained by many single gene du-pli ations a umulating over generations, as opposed to massive whole-genome dupli ations,resear hers agree that gene dupli ation in some form ontributed signi antly to body-planelaboration.A detailed a ount of how dupli ate genes an take on novel roles was given by For e et al.(1999): Base pair mutations in the generations following dupli ation partition the initiallyredundant regulatory roles of genes into separate lasses. Thus, the embryo develops in thesame way, but the genes that determine the overall body-plan are on ned to more spe i roles, sin e there are more of them. The partitioning phase ompletes when redundant lusters of genes are separated enough so that they no longer produ e identi al proteinsat the same time. After partitioning, mutations within the dupli ated luster of genesa e t di erent steps in development than mutations within the original luster. In otherwords, dupli ation reates more points at whi h mutations an o ur. In this manner,developmental pro esses omplexify.Gene dupli ation is a possible explanation how natural evolution indeed expanded thesize of genomes throughout evolution, and provides inspiration for adding new genes toarti ial genomes as well. In fa t, gene dupli ation motivated Koza (1995) to allow entirefun tions in geneti programs to be dupli ated through a single mutation, and later di er-entiated through further mutations. When evolving neural networks, this pro ess meansadding new neurons and onne tions to the networks.In order to implement this idea in arti ial evolutionary systems, we are fa ed withtwo major hallenges. First, su h systems evolve di erently sized and shaped networktopologies, whi h an be di\u00c6 ult to ross over without losing information. For example,depending on when new stru ture was added, the same gene may exist at di erent positions,or onversely, di erent genes may exist at the same position. Thus, arti ial rossover maydisrupt evolved topologies through misalignment. Se ond, with variable-length genomes,it may be di\u00c6 ult to nd innovative solutions. Optimizing many genes takes longer thanoptimizing only a few, meaning that more omplex networks may be eliminated from thepopulation before they have a su\u00c6 ient opportunity to be optimized.However, biologi al evolution also operates on variable-length genomes, and these prob-lems did not stop omplexi ation in nature. How are these problems avoided in biologi alevolution? First, nature has a me hanism for aligning genes with their ounterparts during rossover, so that data is not lost nor obs ured. This alignment pro ess has been most learly observed in E. oli (Radding, 1982; Sigal & Alberts, 1972). A spe ial protein alledRe A takes a single strand of DNA and aligns it with another strand at genes that expressthe same traits, whi h are alled homologous genes. This pro ess is alled synapsis.Se ond, innovations in nature are prote ted through spe iation. Organisms with signi - antly divergent genomes never mate be ause they are in di erent spe ies. If any organism ould mate with any other, organisms with initially larger, less- t genomes would be for edto ompete for mates with their simpler, more t ounterparts. As a result, the larger,more innovative genomes would fail to produ e o spring and disappear from the popula-tion. In ontrast, in a spe iated population, organisms with larger genomes ompete formates among their own spe ies, instead of with the population at large. That way, organ-isms that may initially have lower tness than the general population still have a han e67\nStanley & Miikkulainento reprodu e, giving novel on epts a han e to realize their potential without being pre-maturely eliminated. Be ause spe iation bene ts the evolution of diverse populations, avariety of spe iation methods have been employed in EC (Goldberg & Ri hardson, 1987;Mahfoud, 1995; Ryan, 1994).It turns out omplexi ation is also possible in evolutionary omputation if abstra tionsof synapsis and spe iation are made part of the geneti algorithm. The NEAT method(se tion 3) is an implementation of this idea: The genome is omplexi ed by adding newgenes whi h in turn en ode new stru ture in the phenotype, as in biologi al evolution.Complexi ation is espe ially powerful in open-ended domains where the goal is to ontinually generate more sophisti ated strategies. Competitive oevolution is a parti ularlyimportant su h domain, as will be reviewed in the next se tion.2.2 Competitive CoevolutionIn ompetitive oevolution, individual tness is evaluated through ompetition with otherindividuals in the population, rather than through an absolute tness measure. In otherwords, tness signi es only the relative strengths of solutions; an in reased tness in onesolution leads to a de reased tness for another. Ideally, ompeting solutions will ontinuallyoutdo one another, leading to an \"arms ra e\" of in reasingly better solutions (Dawkins &Krebs, 1979; Rosin, 1997; Van Valin, 1973). Competitive oevolution has traditionally beenused in two kinds of problems. First, it an be used to evolve intera tive behaviors thatare di\u00c6 ult to evolve in terms of an absolute tness fun tion. For example, Sims (1994)evolved simulated 3D reatures that attempted to apture a ball before an opponent did,resulting in a variety of e e tive intera tive strategies. Se ond, oevolution an be usedto gain insight into the dynami s of game-theoreti problems. For example, Lindgren &Johansson (2001) oevolved iterated Prisoner's Dilemma strategies in order to demonstratehow they orrespond to stages in natural evolution.Whatever the goal of a ompetitive oevolution experiment, interesting strategies willonly evolve if the arms ra e ontinues for a signi ant number of generations. In pra ti e, itis di\u00c6 ult to establish su h an arms ra e. Evolution tends to nd the simplest solutions that an win, meaning that strategies an swit h ba k and forth between di erent idiosyn rati yet uninteresting variations (Darwen, 1996; Floreano & Nol , 1997; Rosin & Belew, 1997).Several methods have been developed to en ourage the arms ra e (Angeline & Polla k, 1993;Fi i i & Polla k, 2001; Noble & Watson, 2001; Rosin & Belew, 1997). For example, a \"hallof fame\" or a olle tion of past good strategies an be used to ensure that urrent strategiesremain ompetitive against earlier strategies. Re ently, Fi i i and Polla k (2001) and Nobleand Watson (2001) introdu ed a promising method alled Pareto oevolution, whi h ndsthe best learners and the best tea hers in two populations by asting oevolution as a mul-tiobje tive optimization problem. This information enables hoosing the best individualsto reprodu e, as well as maintaining an informative and diverse set of opponents.Although su h te hniques allow sustaining the arms ra e longer, they do not dire tlyen ourage ontinual oevolution, i.e. reating new solutions that maintain existing apa-bilities. For example, no matter how well sele tion is performed, or how well ompetitorsare hosen, if the sear h spa e is xed, a limit will eventually be rea hed. Also, it may68\nCompetitive Coevolution through Evolutionary Complexifi ationo asionally be easier to es ape a lo al optimum by adding a new dimension to the sear hspa e than by sear hing for a new path through the original spa e.For these reasons, omplexi ation is a natural te hnique for establishing a oevolu-tionary arms ra e. Complexi ation elaborates strategies by adding new dimensions to thesear h spa e. Thus, progress an be made inde nitely long: Even if a global optimumis rea hed in the sear h spa e of solutions, new dimensions an be added, opening up ahigher-dimensional spa e where even better optima may exist.To test this idea experimentally, we hose a robot duel domain that ombines preda-tor/prey intera tion and food foraging in a novel head-to-head ompetition (Se tion 4).We use this domain to demonstrate how NEAT uses omplexi ation to ontinually elabo-rate solutions. The next se tion reviews the NEAT neuroevolution method, followed by ades ription of the robot duel domain and a dis ussion of the results.3. NeuroEvolution of Augmenting Topologies (NEAT)The NEAT method of evolving arti ial neural networks ombines the usual sear h forappropriate network weights with omplexi ation of the network stru ture. This approa his highly e e tive, as shown e.g. in omparison to other neuroevolution (NE) methods in thedouble pole balan ing ben hmark task (Stanley & Miikkulainen, 2002b, ,d). The NEATmethod onsists of solutions to three fundamental hallenges in evolving neural networktopology: (1) What kind of geneti representation would allow disparate topologies to rossover in a meaningful way? Our solution is to use histori al markings to line up geneswith the same origin. (2) How an topologi al innovation that needs a few generationsto optimize be prote ted so that it does not disappear from the population prematurely?Our solution is to separate ea h innovation into a di erent spe ies. (3) How an topologiesbe minimized throughout evolution so the most e\u00c6 ient solutions will be dis overed? Oursolution is to start from a minimal stru ture and add nodes and onne tions in rementally.In this se tion, we explain how ea h of these solutions is implemented in NEAT.3.1 Geneti En odingEvolving stru ture requires a exible geneti en oding. In order to allow stru tures to om-plexify, their representations must be dynami and expandable. Ea h genome in NEATin ludes a list of onne tion genes, ea h of whi h refers to two node genes being onne ted.(Figure 2). Ea h onne tion gene spe i es the in-node, the out-node, the weight of the on-ne tion, whether or not the onne tion gene is expressed (an enable bit), and an innovationnumber, whi h allows nding orresponding genes during rossover.Mutation in NEAT an hange both onne tion weights and network stru tures. Con-ne tion weights mutate as in any NE system, with ea h onne tion either perturbed or not.Stru tural mutations, whi h form the basis of omplexi ation, o ur in two ways (Figure3). Ea h mutation expands the size of the genome by adding gene(s). In the add onne tionmutation, a single new onne tion gene is added onne ting two previously un onne tednodes. In the add node mutation, an existing onne tion is split and the new node pla edwhere the old onne tion used to be. The old onne tion is disabled and two new onne -tions are added to the genome. The onne tion between the rst node in the hain and thenew node is given a weight of one, and the onne tion between the new node and the last69\nStanley & Miikkulainen Node 1 Sensor Node 2 Sensor Node 3 Sensor Node 4 Output Node 5 Hidden In 1 Out 4 Weight 0.7 Enabled Innov 1 In 2 Out 4 Weight\u22120.5 DISABLED Innov 2 In 3 Out 4 Weight 0.5 Enabled Innov 3 In 2 Out 5 Weight 0.2 Enabled Innov 4 In 5 In 1 In 4 Out 4 Out 5 Out 5 Weight 0.4 Weight 0.6 Weight 0.6 Enabled Enabled Enabled Innov 5 Innov 6 Innov 11 Genome (Genotype) Node Genes Connect. Genes Network (Phenotype)\n1 2 3 5\n4\nFigure 2: A NEAT genotype to phenotype mapping example. A genotype is depi ted thatprodu es the shown phenotype. There are 3 input nodes, one hidden, and one outputnode, and seven onne tion de nitions, one of whi h is re urrent. The se ond gene isdisabled, so the onne tion that it spe i es (between nodes 2 and 4) is not expressed inthe phenotype. In order to allow omplexi ation, genome length is unbounded.node in the hain is given the same weight as the onne tion being split. Splitting the on-ne tion in this way introdu es a nonlinearity (i.e. sigmoid fun tion) where there was nonebefore. When initialized in this way, this nonlinearity hanges the fun tion only slightly,and the new node is immediately integrated into the network. Old behaviors en oded in thepreexisting network stru ture are not destroyed and remain qualitatively the same, whilethe new stru ture provides an opportunity to elaborate on these original behaviors.Through mutation, the genomes in NEAT will gradually get larger. Genomes of varyingsizes will result, sometimes with di erent onne tions at the same positions. Crossover mustbe able to re ombine networks with di ering topologies, whi h an be di\u00c6 ult (Rad li e,1993). The next se tion explains how NEAT addresses this problem.3.2 Tra king Genes through Histori al MarkingsIt turns out that the histori al origin of ea h gene an be used to tell us exa tly whi h genesmat h up between any individuals in the population. Two genes with the same histori alorigin represent the same stru ture (although possibly with di erent weights), sin e theywere both derived from the same an estral gene at some point in the past. Thus, all asystem needs to do is to keep tra k of the histori al origin of every gene in the system.Tra king the histori al origins requires very little omputation. Whenever a new geneappears (through stru tural mutation), a global innovation number is in remented andassigned to that gene. The innovation numbers thus represent a hronology of every genein the system. As an example, let us say the two mutations in Figure 3 o urred one after70\nCompetitive Coevolution through Evolutionary Complexifi ation 1\n1\n1 1 2 2\n2 2 3 3\n3\n3 6\n5 5\n5 5\n4 4\n4 4\n1\u2212>4 1\u2212>4\n1\u2212>4 1\u2212>4 2\u2212>4 2\u2212>4 2\u2212>4 2\u2212>4 3\u2212>4 3\u2212>4 3\u2212>4 3\u2212>4 2\u2212>5 2\u2212>5 2\u2212>5 2\u2212>5 5\u2212>4 5\u2212>4 5\u2212>4 5\u2212>4 1\u2212>5 1\u2212>5 1\u2212>5 1\u2212>5 3\u2212>5 3\u2212>6 6\u2212>4 DIS\nDIS DIS\nDIS DIS\n1 1\n1 1 2 2 2 2 3 3 3 3 4 4\n4 4 5 5\n5 5 6 6 6 6\n7\n8 9\nMutate Add Connection\nMutate Add Node\nFigure 3: The two types of stru tural mutation in NEAT. Both types, adding a onne tionand adding a node, are illustrated with the genes above their phenotypes. The top numberin ea h genome is the innovation number of that gene. The bottom two numbers denotethe two nodes onne ted by that gene. The weight of the onne tion, also en oded in thegene, is not shown. The symbol DIS means that the gene is disabled, and therefore notexpressed in the network. The gure shows how onne tion genes are appended to thegenome when a new onne tion and a new node is added to the network. Assuming thedepi ted mutations o urred one after the other, the genes would be assigned in reasinginnovation numbers as the gure illustrates, thereby allowing NEAT to keep an impli ithistory of the origin of every gene in the population.another in the system. The new onne tion gene reated in the rst mutation is assignedthe number 7, and the two new onne tion genes added during the new node mutationare assigned the numbers 8 and 9. In the future, whenever these genomes rossover, theo spring will inherit the same innovation numbers on ea h gene. Thus, the histori al originof every gene in the system is known throughout evolution.A possible problem is that the same stru tural innovation will re eive di erent innovationnumbers in the same generation if it o urs by han e more than on e. However, by keepinga list of the innovations that o urred in the urrent generation, it is possible to ensure thatwhen the same stru ture arises more than on e through independent mutations in thesame generation, ea h identi al mutation is assigned the same innovation number. Throughextensive experimentation, we established that resetting the list every generation as opposedto keeping a growing list of mutations throughout evolution is su\u00c6 ient to prevent anexplosion of innovation numbers.Through innovation numbers, the system now knows exa tly whi h genes mat h upwith whi h (Figure 4). Genes that do not mat h are either disjoint or ex ess, depending onwhether they o ur within or outside the range of the other parent's innovation numbers.When rossing over, the genes with the same innovation numbers are lined up and are71\nStanley & Miikkulainen 1\u2212>4\n1\u2212>4\n1\u2212>4\n1\u2212>4 1\u2212>4\n2\u2212>4\n2\u2212>4\n2\u2212>4\n2\u2212>4 2\u2212>4\n3\u2212>4\n3\u2212>4\n2\u2212>5\n2\u2212>5 2\u2212>5\n2\u2212>5\n2\u2212>5\n5\u2212>4\n5\u2212>4\n5\u2212>4\n5\u2212>6\n5\u2212>4\n5\u2212>4\n1\u2212>5\n1\u2212>5\n6\u2212>4\n6\u2212>4\n1\u2212>6\n1\u2212>6\n1\u2212>61\u2212>5\n5\u2212>6\n5\u2212>6\n3\u2212>5\n3\u2212>5\n3\u2212>56\u2212>4\n3\u2212>4\n3\u2212>4 3\u2212>4\nDISAB\nDISAB\nDISAB\nDISAB\nDISAB\nDISAB DISAB DISAB\n1\n1\n1\n1 1\n2\n2\n2\n2 2\n3\n3\n4\n4 4\n4\n4\n5\n5\n5\n6\n5\n5\n8\n8\n7\n7\n10\n10\n108\n6\n6\n9\n9\n97\n3\n3 3\ndisjointdisjoint\ndisjoint\nexcessexcess\nParent1 Parent2\nParent2 Offspring\nParent1\n1\n1\n1 2\n2\n2 3\n3\n3\n5\n5\n5\n6\n4\n4 6\n4\nFigure 4: Mat hing up genomes for di erent network topologies using innovation num-bers. Although Parent 1 and Parent 2 look di erent, their innovation numbers (shownat the top of ea h gene) tell us that several of their genes mat h up even without topo-logi al analysis. A new stru ture that ombines the overlapping parts of the two parentsas well as their di erent parts an be reated in rossover. In this ase, equal tnessesare assumed, so the disjoint and ex ess genes from both parents are inherited randomly.Otherwise they would be inherited from the more t parent. The disabled genes maybe ome enabled again in future generations: There is a preset han e that an inheritedgene is disabled if it is disabled in either parent.randomly hosen for the o spring genome. Genes that do not mat h are inherited from themore t parent, or if they are equally t, from both parents randomly. Disabled genes havea 25% han e of being reenabled during rossover, allowing networks to make use of oldergenes on e again.1Histori al markings allow NEAT to perform rossover without the need for expensivetopologi al analysis. Genomes of di erent organizations and sizes stay ompatible through-out evolution, and the problem of omparing di erent topologies is essentially avoided. This1. See Appendix A for spe i mating parameters used in the experiments in this paper.72\nCompetitive Coevolution through Evolutionary Complexifi ationmethodology allows NEAT to omplexify stru ture while still maintaining geneti ompat-ibility. However, it turns out that a population of varying omplexities annot maintaintopologi al innovations on its own. Be ause smaller stru tures optimize faster than largerstru tures, and adding nodes and onne tions usually initially de reases the tness of thenetwork, re ently augmented stru tures have little hope of surviving more than one gen-eration even though the innovations they represent might be ru ial towards solving thetask in the long run. The solution is to prote t innovation by spe iating the population, asexplained in the next se tion.3.3 Prote ting Innovation through Spe iationNEAT spe iates the population so that individuals ompete primarily within their ownni hes instead of with the population at large. This way, topologi al innovations are pro-te ted and have time to optimize their stru ture before they have to ompete with otherni hes in the population. In addition, spe iation prevents bloating of genomes: Spe ies withsmaller genomes survive as long as their tness is ompetitive, ensuring that small networksare not repla ed by larger ones unne essarily. Prote ting innovation through spe iation fol-lows the philosophy that new ideas must be given time to rea h their potential before theyare eliminated.Histori al markings make it possible for the system to divide the population into spe iesbased on topologi al similarity. We an measure the distan e \u00c6 between two network en- odings as a linear ombination of the number of ex ess (E) and disjoint (D) genes, as wellas the average weight di eren es of mat hing genes (W ):\u00c6 = 1EN + 2DN + 3 W: (1)The oe\u00c6 ients 1, 2, and 3 adjust the importan e of the three fa tors, and the fa torN , the number of genes in the larger genome, normalizes for genome size (N an be setto 1 if both genomes are small). Genomes are tested one at a time; if a genome's distan eto a randomly hosen member of the spe ies is less than \u00c6t, a ompatibility threshold, itis pla ed into this spe ies. Ea h genome is pla ed into the rst spe ies from the previousgeneration where this ondition is satis ed, so that no genome is in more than one spe ies.If a genome is not ompatible with any existing spe ies, a new spe ies is reated. Theproblem of hoosing the best value for \u00c6t an be avoided by making \u00c6t dynami ; that is,given a target number of spe ies, the system an raise \u00c6t if there are too many spe ies, andlower \u00c6t if there are too few.As the reprodu tion me hanism for NEAT, we use expli it tness sharing (Goldberg &Ri hardson, 1987), where organisms in the same spe ies must share the tness of their ni he.Thus, a spe ies annot a ord to be ome too big even if many of its organisms perform well.Therefore, any one spe ies is unlikely to take over the entire population, whi h is ru ial forspe iated evolution to maintain topologi al diversity. The adjusted tness f 0i for organismi is al ulated a ording to its distan e \u00c6 from every other organism j in the population:f 0i = fiPnj=1 sh(\u00c6(i; j)) : (2)73\nStanley & MiikkulainenThe sharing fun tion sh is set to 0 when distan e \u00c6(i; j) is above the threshold \u00c6t;otherwise, sh(\u00c6(i; j)) is set to 1 (Spears, 1995). Thus,Pnj=1 sh(\u00c6(i; j)) redu es to the numberof organisms in the same spe ies as organism i. This redu tion is natural sin e spe iesare already lustered by ompatibility using the threshold \u00c6t. Every spe ies is assigneda potentially di erent number of o spring in proportion to the sum of adjusted tnessesf 0i of its member organisms. Spe ies reprodu e by rst eliminating the lowest performingmembers from the population. The entire population is then repla ed by the o spring ofthe remaining organisms in ea h spe ies.The net e e t of spe iating the population is that stru tural innovation is prote ted.The nal goal of the system, then, is to perform the sear h for a solution as e\u00c6 iently aspossible. This goal is a hieved through omplexi ation from a simple starting stru ture,as detailed in the next se tion.3.4 Minimizing Dimensionality through Complexi ationUnlike other systems that evolve network topologies and weights (Angeline, Saunders, &Polla k, 1993; Gruau, Whitley, & Pyeatt, 1996; Yao, 1999; Zhang & Muhlenbein, 1993),NEAT begins with a uniform population of simple networks with no hidden nodes, di eringonly in their initial random weights. Spe iation prote ts new innovations, allowing topo-logi al diversity to be gradually introdu ed over evolution. Thus, be ause NEAT prote tsinnovation using spe iation, it an start in this manner, minimally, and grow new stru tureover generations.New stru ture is introdu ed in rementally as stru tural mutations o ur, and only thosestru tures survive that are found to be useful through tness evaluations. This way, NEATsear hes through a minimal number of weight dimensions, signi antly redu ing the num-ber of generations ne essary to nd a solution, and ensuring that networks be ome nomore omplex than ne essary. This gradual produ tion of in reasingly omplex stru tures onstitutes omplexi ation. In other words, NEAT sear hes for the optimal topology byin rementally omplexifying existing stru ture.In previous work, ea h of the three main omponents of NEAT (i.e. histori al markings,spe iation, and starting from minimal stru ture) were experimentally ablated in order todemonstrate how they ontribute to performan e (Stanley & Miikkulainen, 2002b,d). Theablation study demonstrated that all three omponents are interdependent and ne essaryto make NEAT work. In this paper, we further show how omplexi ation establishes thearms ra e in ompetitive oevolution. The next se tion des ribes the experimental domainin whi h this result will be demonstrated.4. The Robot Duel DomainOur hypothesis is that the omplexi ation pro ess outlined above allows dis overing moresophisti ated strategies, i.e. strategies that are more e e tive, exible, and general, andin lude more omponents and variations than do strategies obtained through sear h in a xed spa e. To demonstrate this e e t, we need a domain where it is possible to developa wide range in reasingly sophisti ated strategies, and where sophisti ation an be readilymeasured. A oevolution domain is parti ularly appropriate be ause a sustained arms ra eshould lead to in reasing sophisti ation. 74\nCompetitive Coevolution through Evolutionary Complexifi ationIn hoosing the domain, it is di\u00c6 ult to strike a balan e between being able to evolve omplex strategies and being able to analyze and understand them. Pursuit and evasiontasks have been utilized for this purpose in the past (Gomez & Miikkulainen, 1997; Jim& Giles, 2000; Miller & Cli , 1994; Reggia, S hulz, Wilkinson, & Uriagereka, 2001; Sims,1994), and an serve as a ben hmark domain for omplexifying oevolution as well. Whilepast experiments evolved either a predator or a prey, an interesting oevolution task anbe established if the agents are instead equal and engaged in a duel. To win, an agent mustdevelop a strategy that outwits that of its opponent, utilizing stru ture in the environment.In this paper we introdu e su h a duel domain, in whi h two simulated robots try tooverpower ea h other (Figure 5). The two robots begin on opposite sides of a re tangularroom fa ing away from ea h other. As the robots move, they lose energy in proportion tothe amount of for e they apply to their wheels. Although the robots never run out of energy(they are given enough to survive the entire ompetition), the robot with higher energy winswhen it ollides with its ompetitor. In addition, ea h robot has a sensor indi ating thedi eren e in energy between itself and the other robot. To keep their energies high, therobots an onsume food items, arranged in a symmetri al pattern in the room.The robot duel task supports a broad range of sophisti ated strategies that are easy toobserve and interpret. The ompetitors must be ome pro ient at foraging, prey apture,and es aping predators. In addition, they must be able to qui kly swit h from one behaviorto another. The task is well-suited to ompetitive oevolution be ause naive strategies su has forage-then-atta k an be omplexi ed into more sophisti ated strategies su h as luringthe opponent to waste its energy before atta king.The simulated robots are similar to Kheperas (Mondada et al. 1993; Figure 6). Ea hhas two wheels ontrolled by separate motors. Five range nder sensors an sense food andanother ve an sense the other robot. Finally, ea h robot has an energy-di eren e sensor,and a single wall sensor.The robots are ontrolled with neural networks evolved with NEAT. The networks re- eive all of the robot sensors as inputs, as well as a onstant bias that NEAT an use to hange the a tivation thresholds of neurons. They produ e three motor outputs: Two toen ode rotation either right or left, and a third to indi ate forward motion power. Thesethree values are then translated into for es to be applied to the left and right wheels of therobot.The state st of the world at time t is de ned by the positions of the robots and food,the energy levels of the robots, and the internal states (i.e. neural a tivation) of the robots'neural networks, in luding sensors, outputs, and hidden nodes. The subsequent state st+1is determined by the outputs of the robots' neural network ontrollers, omputed from theinputs (i.e. sensor values) in st in one step of propagation through the network. The robots hange their position in st+1 a ording to their neural network outputs as follows. The hange in dire tion of motion is proportional to the di eren e between the left and rightmotor outputs. The robot drives forward a distan e proportional to the forward outputon a ontinuous board of size 600 by 600. The robot rst makes half its turn, then movesforward, then ompletes the se ond half of its turn, so that the turning and forward motionsare e e tively ombined. If the robot en ounters food, it re eives an energy boost, and thefood disappears from the world. The loss of energy due to movement is omputed as thesum of the turn angle and the forward motion, so that even turning in pla e takes energy. If75\nStanley & Miikkulainen\nFigure 5: The Robot Duel Domain. The robots begin on opposite sides of the board fa ingaway from ea h other as shown by the arrows pointing away from their enters. The on entri ir les around ea h robot represent the separate rings of opponent sensorsand food sensors available to ea h robot. Ea h ring ontains ve sensors. The robotslose energy when they move around, and gain energy by onsuming food (shown assmall sandwi hes). The food is always pla ed in the depi ted horizontally symmetri alpattern around the middle of the board. The obje tive is to attain a higher level ofenergy than the opponent, and then ollide with it. Be ause of the omplex intera tionbetween foraging, pursuit, and evasion behaviors, the domain allows for a broad rangeof strategies of varying sophisti ation. Animated demos of su h evolved strategies areavailable at www. s.utexas.edu/users/nn/pages/resear h/neatdemo.html.the robots are within a distan e of 20, a ollision o urs and the robot with a higher energywins (see Appendix B for the exa t parameter values used).Sin e the observed state ot taken by the sensors does not in lude the internal stateof the opponent robot, the robot duel is a partially-observable Markov de ision pro ess(POMDP). Sin e the next observed state ot+1 depends on the de ision of the opponent, itis ne essary for robots to learn to predi t what the opponent is likely to do, based on theirpast behavior, and also based on what is reasonable behavior in general. For example, itis reasonable to assume that if the opponent robot is qui kly approa hing and has higherenergy, it is probably trying to ollide. Be ause an important and omplex portion of s isnot observable, memory, and hen e re urrent onne tions, are ru ial for su ess.This omplex robot- ontrol domain allows ompetitive oevolution to evolve in reasinglysophisti ated and omplex strategies, and an be used to understand omplexi ation, aswill be des ribed next. 76\nCompetitive Coevolution through Evolutionary Complexifi ation\nFigure 6: Robot Neural Networks. Five food sensors and ve robot sensors dete t the presen eof obje ts around the robot. A single wall sensor indi ates proximity to walls, andthe energy di eren e sensor tells the robot how its energy level di ers from that of itsopponent. This di eren e is important be ause the robot with lower energy loses if therobots ollide. The three motor outputs are mapped to for es that ontrol the left andthe right wheel.5. ExperimentsIn order to demonstrate how omplexi ation enhan es performan e, we ran thirty-three500-generation runs of oevolution in the robot duel domain. Thirteen of these runs werebased on the full NEAT method. Complexi ation was turned o in the remaining 20 runs(although networks were still spe iated based on weight di eren es), in order to see how omplexi ation ontributes evolving sophisti ated strategies. The ompetitive oevolutionsetup is des ribed rst, followed by an overview of the dominan e tournament method formonitoring progress.5.1 Competitive Coevolution SetupThe robot duel domain supports highly sophisti ated strategies. Thus, the question insu h a domain is whether ontinual oevolution will take pla e, i.e. whether in reasinglysophisti ated strategies will appear over the ourse of evolution. The experiment has to beset up arefully for this pro ess to emerge, and to be able to identify it when it does.In ompetitive oevolution, every network should play a su\u00c6 ient number of games toestablish a good measure of tness. To en ourage interesting and sophisti ated strategies,networks should play a diverse and high quality sample of possible opponents. One wayto a omplish this goal is to evolve two separate populations. In ea h generation, ea hpopulation is evaluated against an intelligently hosen sample of networks from the otherpopulation. The population urrently being evaluated is alled the host population, andthe population from whi h opponents are hosen is alled the parasite population (Rosin &77\nStanley & MiikkulainenBelew, 1997). The parasites are hosen for their quality and diversity, making host/parasiteevolution more e\u00c6 ient and more reliable than one based on random or round robin tour-nament.In the experiment, a single tness evaluation in luded two ompetitions, one for the eastand one for the west starting position. That way, networks needed to implement generalstrategies for winning, independent of their starting positions. Host networks re eived asingle tness point for ea h win, and no points for losing. If a ompetition lasted 750 timesteps with no winner, the host re eived zero points.In sele ting the parasites for tness evaluation, good use an be made of the spe iationand tness sharing that already o ur in NEAT. Ea h host was evaluated against the fourhighest spe ies' hampions. They are good opponents be ause they are the best of thebest spe ies, and they are guaranteed to be diverse be ause their distan e must ex eed thethreshold \u00c6t (se tion 3.3). Another eight opponents were hosen randomly from a Hall ofFame omposed of all generation hampions (Rosin & Belew, 1997). The Hall of Fameensures that existing abilities need to be maintained to obtain a high tness. Ea h networkwas evaluated in 24 games (i.e. 12 opponents, 2 games ea h), whi h was found to be e e tiveexperimentally. Together spe iation, tness sharing, and Hall of Fame omprise an e e tive ompetitive oevolution methodology.It should be noted that omplexi ation does not depend on the parti ular oevolutionmethodology. For example Pareto oevolution (Fi i i & Polla k, 2001; Noble & Watson,2001) ould have been used as well, and the advantages of omplexi ation would be thesame. However, Pareto oevolution requires every member of one population to play everymember of the other, and the running time in this domain would have been prohibitivelylong.In order to interpret experimental results, a method is needed for analyzing progress in ompetitive oevolution. The next se tion des ribes su h a method.5.2 Monitoring Progress in Competitive CoevolutionA ompetitive oevolution run returns a re ord of every generation hampion from bothpopulations. The question is, how an a sequen e of in reasingly sophisti ated strategiesbe identi ed in this data, if one exists? This se tion des ribes the dominan e tournamentmethod for monitoring progress in ompetitive oevolution (Stanley & Miikkulainen, 2002a)that allows us to do that.First we need a method for performing individual omparisons, i.e. whether one strategyis better than another. Be ause the board on gurations an vary between games, hampionnetworks were ompared on 144 di erent food on gurations from ea h side of the board,giving 288 total games for ea h omparison. The food on gurations in luded the same9 symmetri al food positions used during training, plus an additional 2 food items, whi hwere pla ed in one of 12 di erent positions on the east and west halves of the board. Somestarting food positions give an initial advantage to one robot or another, depending on how lose they are to the robots' starting positions. Thus, the one who wins the majority ofthe 288 total games has demonstrated its superiority in many di erent s enarios, in ludingthose beginning with a disadvantage. We say that network a is superior to network b if awins more games than b out of the 288 total games.78\nCompetitive Coevolution through Evolutionary Complexifi ationGiven this de nition of superiority, progress an be tra ked. The obvious way to do it isto ompare ea h network to others throughout evolution, nding out whether later strategies an beat more opponents than earlier strategies. For example, Floreano & Nol (1997) useda measure alled master tournament, in whi h the hampion of ea h generation is omparedto all other generation hampions. Unfortunately, su h methods are impra ti al in a time-intensive domain su h as the robot duel ompetition. Moreover, the master tournamentonly ounts how many strategies an be defeated by ea h generation hampion, withoutidentifying whi h ones. Thus, it an fail to dete t ases where strategies that defeat fewerprevious hampions are a tually superior in a dire t omparison. For example, if strategy Adefeats 499 out of 500 opponents, and B defeats 498, the master tournament will designateA as superior to B even if B defeats A in a dire t omparison. In order to de isivelytra k strategi innovation, we need to identify dominant strategies, i.e. those that defeatall previous dominant strategies. This way, we an make sure that evolution pro eedsby developing a progression of stri tly more powerful strategies, instead of e.g. swit hingbetween alternative ones.The dominan e tournament method of tra king progress in ompetitive oevolutionmeets this goal (Stanley & Miikkulainen, 2002a). Let a generation hampion be the winnerof a 288 game omparison between the host and parasite hampions of a single genera-tion. Let dj be the jth dominant strategy to appear over evolution. Dominan e is de nedre ursively starting from the rst generation and progressing to the last: The rst dominant strategy d1 is the generation hampion of the rst generation; dominant strategy dj , where j > 1, is a generation hampion su h that for all i < j,dj is superior to di (i.e. wins the 288 game omparison with it).This stri t de nition of dominan e prohibits ir ularities. For example, d4 must be su-perior to strategies d1 through d3, d3 superior to both d1 and d2, and d2 superior to d1.We all dn the nth dominant strategy of the run. If a network exists that, for example,defeats d4 but loses to d3, making the superiority ir ular, it would not satisfy the se ond ondition and would not be entered into the dominan e hierar hy.The entire pro ess of deriving a dominan e hierar hy from a population is a dominan etournament, where ompetitors play all previous dominant strategies until they either losea 288 game omparison, or win every omparison to previous dominant strategies, therebybe oming a new dominant strategy. Dominan e tournament allows us to identify a sequen eof in reasingly more sophisti ated strategies. It also requires signi antly fewer omparisonsthan the master tournament (Stanley & Miikkulainen, 2002a).Armed with the appropriate oevolution methodology and a measure of su ess, we an now ask the question: Does the omplexi ation result in more su essful ompetitive oevolution?6. ResultsEa h of the 33 evolution runs took between 5 and 10 days on a 1GHz Pentium III pro essor,depending on the progress of evolution and sizes of the networks involved. The NEATalgorithm itself used less than 1% of this omputation: Most of the time was spent in79\nStanley & Miikkulainen\n20\n40\n60\n80\n100\n120\n140\n160\n180\n200\n220\n240\n0 50 100 150 200 250 300 350 400 450 500\nC on\nne ct\nio ns\nGeneration\nConnections in Highest Dom. Random Fitness Min. Connections Random Fitness Max. Connections\n0\n2\n4\n6\n8\n10\n12\n14\n16\n0 50 100 150 200 250 300 350 400 450 500\nN od\nes\nGeneration\nNodes in Highest Dom. Random Fitness Min. Nodes Random Fitness Max. Nodes\nFigure 7: Complexi ation of onne tions and nodes over generations. The hashed linesdepi t the average number of onne tions and the average number of hidden nodes in thehighest dominant network in ea h generation. Averages are taken over 13 omplexifyingruns. A hash mark appears every generation in whi h a new dominant strategy emergedin at least one of the 13 runs. The graphs show that as dominan e in reases, so does omplexity. The di eren es between the average nal and rst dominant strategies arestatisti ally signi ant for both onne tions and nodes (p < 0:001). For omparison thedashed lines depi t the sizes of the average smallest and largest networks in the entirepopulation over ve runs where the tness is assigned randomly. These bounds show thatthe in rease in omplexity is not inevitable; both very simple and very omplex spe iesexist in the population throughout the run. When the dominant networks omplexify,they do so be ause it is bene ial.evaluating networks in the robot duel task. Evolution of fully- onne ted topologies tookabout 90% longer than stru ture-growing NEAT be ause larger networks take longer toevaluate.In order to analyze the results, we de ne omplexity as the number of nodes and on-ne tions in a network: The more nodes and onne tions there are in the network, the more omplex behavior it an potentially implement. The results were analyzed to answer threequestions: (1) As evolution progresses does it also ontinually omplexify? (2) Does su h omplexi ation lead to more sophisti ated strategies? (3) Does omplexi ation allow bet-ter strategies to be dis overed than does evolving xed-topology networks? Ea h questionis answered in turn below.6.1 Evolution of ComplexityNEAT was run thirteen times, ea h time from a di erent seed, to verify that the resultswere onsistent. The highest levels of dominan e a hieved were 17, 14, 17, 16, 16, 18, 19,15, 17, 12, 12, 11, and 13, averaging at 15.15 (sd = 2.54).At ea h generation where the dominan e level in reased in at least one of the thirteenruns, we averaged the number of onne tions and number of nodes in the urrent dominantstrategy a ross all runs (Figure 7). Thus, the graphs represent a total of 197 dominan etransitions spread over 500 generations. The rise in omplexity is dramati , with the averagenumber of onne tions tripling and the average number of hidden nodes rising from 0 to80\nCompetitive Coevolution through Evolutionary Complexifi ationalmost six. In a smooth trend over the rst 200 generations, the number of onne tionsin the dominant strategy grows by 50%. During this early period, dominan e transitionso ur frequently (fewer prior strategies need to be beaten to a hieve dominan e). Over thenext 300 generations, dominan e transitions be ome more sparse, although they ontinueto o ur.Between the 200th and 500th generations a stepped pattern emerges: The omplexity rst rises dramati ally, then settles, then abruptly in reases again (This pattern is evenmore marked in individual omplexifying runs; the averaging done in Figure 7 smoothsit out somewhat). The ause for this pattern is spe iation. While one spe ies is adding alarge amount of stru ture, other spe ies are optimizing the weights of less omplex networks.Initially, added omplexity leads to better performan e, but subsequent optimization takeslonger in the new higher-dimensional spa e. Meanwhile, spe ies with smaller topologies havea han e to temporarily at h up through optimizing their weights. Ultimately, however,more omplex stru tures eventually win, sin e higher omplexity is ne essary for ontinuedinnovation.Thus, there are two underlying for es of progress: The building of new stru tures, andthe ontinual optimization of prior stru tures in the ba kground. The produ t of these twotrends is a gradual stepped progression towards in reasing omplexity.An important question is: Be ause NEAT sear hes by adding stru ture only, not byremoving it, does the omplexity always in rease whether it helps in nding good solutionsor not? To demonstrate that NEAT indeed prefers simple solutions and omplexi es onlywhen it is useful, we ran ve omplexifying evolution runs with tness assigned randomly(i.e. the winner of ea h game was hosen at random). As expe ted, NEAT kept a widerange of networks in its population, from very simple to highly omplex (Figure 7). That is,the dominant networks did not have to be ome more omplex; they only did so be ause itwas bene ial. Not only is the minimum omplexity in the random- tness population mu hlower than that of the dominant strategies, but the maximum omplexity is signi antlygreater. Thus, evolution omplexi es sparingly, only when the omplex spe ies holds itsown in omparison with the simpler ones.6.2 Sophisti ation through Complexi ationTo see how omplexi ation ontributes to evolution, let us observe how a sample dominantstrategy develops over time. While many omplex networks evolved in the experiments,we follow the spe ies that produ ed the winning network d17 in the third run be ause itsprogress is rather typi al and easy to understand. Let us use Sk for the best network inspe ies S at generation k, and hl for the lth hidden node to arise from a stru tural mutationover the ourse of evolution. We will tra k both strategi and stru tural innovations in orderto see how they orrelate. Let us begin with S100 (Figure 8a), when S had a mature zero-hidden-node strategy: S100's main strategy was to follow the opponent, putting it in a position where it mightby han e ollide with its opponent when its energy is up. However, S100 followed theopponent even when the opponent had more energy, leaving S100 vulnerable to atta k.S100 did not learly swit h roles between foraging and hasing the enemy, ausing itto miss opportunities to gather food. 81\nStanley & Miikkulainen\nFigure 8: Complexi ation of a Winning Spe ies. The best networks in the same spe ies aredepi ted at landmark generations. Nodes are depi ted as squares beside their node num-bers, and line thi kness represents the strength of onne tions. Over time, the networksbe ame more omplex and gained skills. (a) The hampion from generation 10 had nohidden nodes. (b) The addition of h22 and its respe tive onne tions gave new abilities.( ) The appearan e of h172 re ned existing behaviors. S200. During the next 100 generations, S evolved a resting strategy, whi h it usedwhen it had signi antly lower energy than its opponent. In su h a situation, the robotstopped moving, while the other robot wasted energy running around. By the timethe opponent got lose, its energy was often low enough to be atta ked. The restingstrategy is an example of improvement that an take pla e without omplexi ation:It involved in reasing the inhibition from the energy di eren e sensor, thereby slightlymodifying intensity of an existing behavior. In S267 (Figure 8b), a new hidden node, h22, appeared. This node arrived throughan interspe ies mating, and had been optimized for several generations already. Nodeh22 gave the robot the ability to hange its behavior at on e into an all-out atta k.Be ause of this new skill, S267 no longer needed to follow the enemy losely at alltimes, allowing it to olle t more food. By implementing this new strategy through anew node, it was possible not to interfere with the already existing resting strategy, sothat S now swit hed roles between resting when at a disadvantage to atta king whenhigh on energy. Thus, the new stru ture resulted in strategi elaboration. In S315 (Figure 8 ), another new hidden node, h172, split a link between an input sensorand h22. Repla ing a dire t onne tion with a sigmoid fun tion greatly improved S315'sability to atta k at appropriate times, leading to very a urate role swit hing betweenatta king and foraging. S315 would try to follow the opponent from afar fo using onresting and foraging, and only zoom in for atta k when vi tory was ertain. This nalstru tural addition shows how new stru ture an improve the a ura y and timing ofexisting behaviors.The analysis above shows that in some ases, weight optimization alone an produ eimproved strategies. However, when those strategies need to be extended, adding new82\nCompetitive Coevolution through Evolutionary Complexifi ation\nFigure 9: Sophisti ated Endgame. Robot S313 dashes for the last pie e of food while S210is still olle ting the se ond-to-last pie e. Although it appeared that S313 would losebe ause S210 got the se ond-to-last pie e, (gray arrow), it turns out that S210 ends witha disadvantage. It has no han e to get to the last pie e of food before S313, and S313has been saving energy while S210 wasted energy traveling long distan es. This way,sophisti ated strategies evolve through omplexi ation, ombining multiple obje tives,and utilizing weaknesses in the opponent's strategy.stru ture allows the new behaviors to oexist with old strategies. Also, in some asesit is ne essary to add omplexity to make the timing or exe ution of the behavior morea urate. These results show how omplexi ation an be utilized to produ e in reasingsophisti ation.In order to illustrate the level of sophisti ation a hieved in this pro ess, we on ludethis se tion by des ribing the ompetition between two sophisti ated strategies, S210 andS313, from another run of evolution. At the beginning of the ompetition, S210 and S313 olle ted most of the available food until their energy levels were about equal. Two pie esof food remained on the board in lo ations distant from both S210 and S313 (Figure 9).Be ause of the danger of olliding with similar energy levels, the obvious strategy is to rushfor the last two pie es of food. In fa t, S210 did exa tly that, onsuming the se ond-to-lastpie e, and then heading towards the last one. In ontrast, S313 forfeited the ra e for these ond-to-last pie e, opting to sit still, even though its energy temporarily dropped belowS210's. However, S313 was loser to the last pie e and got there rst. It re eived a boostof energy while S210 wasted its energy running the long distan e from the se ond-to-lastpie e. Thus, S313's strategy ensured that it had more energy when they nally met. RobotS313's behavior was surprisingly de eptive, showing that high strategi sophisti ation hadevolved. Similar waiting behavior was observed against several other opponents, and alsoevolved in several other runs, suggesting that it was a robust result.This analysis of individual evolved behaviors shows that omplexi ation indeed elab-orates on existing strategies, and allows highly sophisti ated behaviors to develop thatbalan e multiple goals and utilize weaknesses in the opponent. The last question is whether omplexi ation indeed is ne essary to a hieve these behaviors. 83\nStanley & Miikkulainen6.3 Complexi ation vs. Fixed-topology Evolution and Simpli ationComplexifying oevolution was ompared to two alternatives: standard oevolution in a xed sear h spa e, and to simplifying oevolution from a omplex starting point. Notethat it is not possible to ompare methods using the standard rossvalidation te hniquesbe ause no external performan e measure exists in this domain. However, the evolved neuralnetworks an be ompared dire tly by playing a duel. Thus, for example, a run of xed-topology oevolution an be ompared to a run of omplexifying oevolution by playing thehighest dominant strategy from the xed-topology run against the entire dominan e rankingof the omplexifying run. The highest level strategy in the ranking that the xed-topologystrategy an defeat, normalized by the number of dominan e levels, is a measure of itsquality against the omplexifying oevolution. For example, if a strategy an defeat up toand in luding the 13th dominant strategy out of 15, then its performan e against that runis 1315 = 86:7%. By playing every xed-topology hampion, every simplifying oevolution hampion, and every omplexifying oevolution hampion against the dominan e rankingfrom every omplexifying run and averaging, we an measure the relative performan e ofea h of these methods.In this se tion, we will rst establish the baseline performan e by playing omplexifying oevolution runs against themselves and demonstrating that a omparison with dominan elevels is a meaningful measure of performan e. We will then ompare omplexi ation with xed-topology oevolution of networks of di erent ar hite tures, in luding fully- onne tedsmall networks, fully- onne ted large networks, and networks with an optimal stru tureas determined by omplexifying oevolution. Third, we will ompare the performan e of omplexi ation with that of simplifying oevolution.6.3.1 Complexifying CoevolutionThe highest dominant strategy from ea h of the 13 omplexifying runs played the entiredominan e ranking from every other run. Their average performan e s ores were 87:9%,83:8%, 91:9%, 79:4%, 91:9%, 99:6%, 99:4%, 99:5%, 81:8%, 96:2%, 90:6%, 96:9%, and 89:3%,with an overall average of 91:4% (sd=12.8%). Above all, this result shows that omplexifyingruns produ e onsistently good strategies: On average, the highest dominant strategiesqualify for the top 10% of the other omplexifying runs. The best runs were the sixth,seventh, and eighth, whi h were able to defeat almost the entire dominan e ranking ofevery other run. The highest dominant network from the best run (99:6%) is shown inFigure 10.In order to understand what it means for a network to be one or more dominan e levelsabove another, Figure 11 shows how many more games the more dominant network anbe expe ted to win on average over all its 288-game omparisons than the less dominantnetwork. Even at the lowest di eren e (i.e. that of one dominan e level), the more domi-nant network an be expe ted to win about 50 more games on average, showing that ea hdi eren e in dominan e level is important. The di eren e grows approximately linearly:A network 5 dominan e levels higher will win 100 more games, while a network 10 levelshigher will win 150 and 15 levels higher will win 200. These results suggest that dominan elevel omparisons indeed onstitute a meaningful way to measure relative performan e.84\nCompetitive Coevolution through Evolutionary Complexifi ation\nFigure 10: The Best Complexifying Network.The highest dominant network from the sixth omplexifying oevolution run was able tobeat 99:6% of the dominan e hierar hy of the other 12 runs. The network has 11 hiddenunits and 202 onne tions (plotted as in gure 8), making signi ant use of stru ture.While it still ontains the basi dire t onne tions, the strategy they represent has beenelaborated by adding several new nodes and onne tions. For example, lateral andre urrent onne tions allow taking past events into a ount, resulting in more re nedde isions. While su h stru tures an be found reliably through omplexi ation, itturns out di\u00c6 ult to dis over them dire tly in the high dimensional spa e through xed-topology evolution or through simpli ation.6.3.2 Fixed-Topology Coevolution of Large NetworksIn xed-topology oevolution, the network ar hite ture must be hosen by the experimenter.One sensible approa h is to approximate the omplexity of the best omplexifying network.(Figure 10). This network in luded 11 hidden units and 202 onne tions, with both re ur-rent onne tions and dire t onne tions from input to output. As an idealization of thisstru ture, we used 10-hidden-unit fully re urrent networks with dire t onne tions frominputs to outputs, with a total of 263 onne tions. A network of this type should be able toapproximate the fun tionality of the most e e tive omplexifying strategy. Fixed-topology oevolution runs exa tly as omplexifying oevolution in NEAT, ex ept that no stru turalmutations an o ur. In parti ular, the population is still spe iated based on weight di er-en es (i.e. W from equation 1), using the usual spe iation pro edure.Three runs of xed-topology oevolution were performed with these networks, and theirhighest dominant strategies were ompared to the entire dominan e ranking of every om-plexifying run. Their average performan es were 29:1%, 34:4%, and 57:8%, for an overallaverage of 40:4%. Compared to the 91:4% performan e of omplexifying oevolution, it is85\nStanley & Miikkulainen\n0\n50\n100\n150\n200\n250\n300\n0 2 4 6 8 10 12 14 16 18\nA ve\nra ge\nS co\nre\nDominance Level Difference\nAverage Score Difference (out of 288) Standard Deviation\nFigure 11: Interpreting Di eren es in Dominan e Levels. The graph shows how manygames in a 288-game omparison a more dominant network an be expe ted to win,averaged over all runs at all dominan e levels of omplexifying oevolution. For example,a network one level higher wins 50 more games out of 288. A larger di eren e indominan e levels translates to a larger di eren e in performan e approximately linearly,suggesting that dominan e levels an be used as a measure of performan e when anabsolute measure is not available. lear that xed-topology oevolution produ ed onsistently inferior solutions. As a matterof fa t, no xed-topology run ould defeat any of the highest dominant strategies from the13 omplexifying oevolution runs.This di eren e in performan e an be illustrated by omputing the average generation of omplexifying oevolution with the same performan e as xed-topology oevolution. Thisgeneration turns out to be 24 (sd = 8.8). In other words, 500 generations of xed-topology oevolution rea h on average the same level of dominan e as only 24 generations of om-plexifying oevolution! In e e t, the progress of the entire xed-topology oevolution runis ompressed into the rst few generations of omplexifying oevolution (Figure 12).6.3.3 Fixed-Topology Coevolution of Small NetworksOne of the arguments for using omplexifying oevolution is that starting the sear h dire tlyin the spa e of the nal solution may be intra table. This argument may explain why theattempt to evolve xed-topology solutions at a high level of omplexity failed. Thus, inthe next experiment we aimed at redu ing the sear h spa e by evolving fully- onne ted,fully-re urrent networks with a small number of hidden nodes as well as dire t onne tionsfrom inputs to outputs. After onsiderable experimentation, we found out that ve hiddennodes (144 onne tions) was appropriate, allowing xed-topology evolution to nd the best86\nCompetitive Coevolution through Evolutionary Complexifi ation\n1 500 0\n15 D om . L ev el\nComplexifying Coevolution\n1 500 0\n15 D om . L ev el\n10\u2212 Hidden\u2212 Unit Fixed\u2212 Topoloogy\nCoevolution\nGenerations\nEquivalent Performance\nFigure 12: Comparing Typi al Runs of Complexifying Coevolution and Fixed-TopologyCoevolution with Ten Hidden Units. Dominan e levels are harted on the y-axisand generations on the x-axis. A line appears at every generation where a new dominantstrategy arose in ea h run. The height of the line represents the level of dominan e. Thearrow shows that the highest dominant strategy found in 10-hidden-unit xed-topologyevolution only performs as well as the 8th dominant strategy in the omplexifying run,whi h was found in the 19th generation. (Average = 24, sd = 8.8) In other words, onlya few generations of omplexifying oevolution are as e e tive as several hundred of xed-topology evolution.solutions it ould. Five hidden nodes is also about the same number of hidden nodes as thehighest dominant strategies had on average in the omplexifying runs.A total of seven runs were performed with the 5-hidden-node networks, with averageperforman es of 70:7%, 85:5%, 66:1%, 87:3%, 80:8%, 88:8%, and 83:1%. The overall averagewas 80:3% (sd=18.4%), whi h is better but still signi antly below the 91:4% performan eof omplexifying oevolution (p < 0:001).In parti ular, the two most e e tive omplexifying runs were still never defeated by anyof the xed-topology runs. Also, be ause ea h dominan e level is more di\u00c6 ult to a hievethan the last, on average the xed-topology evolution only rea hed the performan e ofthe 159th omplexifying generation (sd=72.0). Thus, even in the best ase, xed-topology87\nStanley & Miikkulainen\n1 500 0\n15 D om . L ev el\nComplexifying Coevolution\n1 500 0\n15 D om . L ev el\n5\u2212 Hidden\u2212 Unit Fixed\u2212 Topoloogy\nCoevolution\nGenerations\nEquivalent Performance\nFigure 13: Comparing Typi al Runs of Complexifying Coevolution and Fixed-TopologyCoevolution with Five Hidden Units. As in gure 12, dominan e levels are harted on the y-axis and generations on the x-axis, a line appears at every generationwhere a new dominant strategy arose in ea h run, and the height of the line representsthe level of dominan e. The arrow shows that the highest dominant strategy found inthe 5-hidden-unit xed-topology evolution only performs as well as the 12th dominantstrategy in the omplexifying run, whi h was found in the 140th generation (Average159, sd = 72.0). Thus, even in the best on guration, xed-topology evolution takesabout twi e as long to a hieve the same level of performan e. oevolution on average only nds the level of sophisti ation that omplexifying oevolution nds halfway through a run (Figure 13).6.3.4 Fixed-Topology Coevolution of Best Complexifying NetworkOne problem with evolving fully- onne ted ar hite tures is that they may not have anappropriate topology for this domain. Of ourse, it is very di\u00c6 ult to guess an appropriatetopology a priori. However, it is still interesting to ask whether xed-topology oevolution ould su eed in the task assuming that the right topology was known? To answer thisquestion, we evolved networks as in the other xed-topology experiments, ex ept this timeusing the topology of the best omplexifying network (Figure 10). This topology may88\nCompetitive Coevolution through Evolutionary Complexifi ation onstrain the sear h spa e in su h a way that nding a sophisti ated solution is more likelythan with a fully- onne ted ar hite ture. If so, it is possible that seeding the populationwith a su essful topology gives it an advantage even over omplexifying oevolution, whi hmust build the topology from a minimal starting point.Five runs were performed, obtaining average performan e s ore 86:2%, 83:3%, 88:1%,74:2%, and 80:3%, and an overall average of 82:4% (sd=15:1%). The 91:4% performan eof omplexifying oevolution is signi antly better than even this version of xed-topology oevolution (p < 0:001). However, interestingly, the 40:4% average performan e of 10-hidden-unit xed topology oevolution is signi antly below best-topology evolution, eventhough both methods sear h in spa es of similar sizes. In fa t, best-topology evolutionperforms at about the same level as 5-hidden-unit xed-topology evolution (80:3%), eventhough 5-hidden-unit evolution optimizes half the number of hidden nodes. Thus, the results on rm the hypothesis that using a su essful evolved topology does help onstrain thesear h. However, in omparison to omplexifying oevolution, the advantage gained fromstarting this way is still not enough to make up for the penalty of starting sear h dire tly ina high-dimensional spa e. As Figure 14 shows, best-topology evolution on average only ndsa strategy that performs as well as those found by the 193rd generation of omplexifying oevolution.The results of the xed-topology oevolution experiments an be summarized as follows:If this method is used to sear h dire tly in the high-dimensional spa e of the most e e tivesolutions, it rea hes only 40% of the performan e of omplexifying oevolution. It doesbetter if it is allowed to optimize less omplex networks; however, the most sophisti atedsolutions may not exist in that spa e. Even given a topology appropriate for the task, itdoes not rea h the same level as omplexifying oevolution. Thus, xed-topology oevolu-tion does not appear to be ompetitive with omplexifying oevolution with any hoi e oftopology.The on lusion is that omplexi ation is superior not only be ause it allows dis overingthe appropriate high-dimensional topology automati ally, but also be ause it makes theoptimization of that topology more e\u00c6 ient. This point will be dis ussed further in Se tion7.6.3.5 Simplifying CoevolutionA possible remedy to having to sear h in high-dimensional spa es is to allow evolution tosear h for smaller stru tures by removing stru ture in rementally. This simplifying oevo-lution is the opposite of omplexifying oevolution. The idea is that a medio re omplexsolution an be re ned by removing unne essary dimensions from the sear h spa e, therebya elerating the sear h.Although simplifying oevolution is an alternative method to omplexifying oevolutionfor nding topologies, it still requires a omplex starting topology to be spe i ed. Thistopology was hosen with two goals in mind: (1) Simplifying oevolution should startwith su\u00c6 ient omplexity to at least potentially nd solutions of equal or more omplexitythan the best solutions from omplexifying oevolution, and (2) with a rate of stru turalremoval equivalent to the rate of stru tural addition in omplexifying NEAT, it should bepossible to dis over solutions signi antly simpler than the best omplexifying solutions.89\nStanley & Miikkulainen\n1 500 0\n15 D om . L ev el\nComplexifying Coevolution\n1 500 0\n15 D om . L ev el\nBest Solution Fixed\u2212 Topology\nCoevolution\nGenerations\nEquivalent Performance\nFigure 14: Comparing Typi al Runs of Complexifying Coevolution and Fixed-TopologyCoevolution of the Best Complexifying Network. Dominan e levels are hartedas in gure 12. The arrow shows that the highest dominant strategy found by evolvingthe xed topology of the best omplexifying network only performs as well as the domi-nant strategy that would be found in the 193rd generation of omplexifying oevolution(Average 193, sd = 85). Thus, even with an appropriate topology given, xed-topologyevolution takes almost twi e as long to a hieve the same level of performan e.Thus, we hose to start sear h with a 12-hidden-unit, 339 onne tion fully- onne ted fully-re urrent network. Sin e 162 onne tions were added to the best omplexifying networkduring evolution, a orresponding simplifying oevolution ould dis over solutions with 177 onne tions, or 25 less than the best omplexifying network.Thus, simplify oevolution was run just as omplexifying oevolution, ex ept that theinitial topology ontained 339 onne tions instead of 39, and stru tural mutations removed onne tions instead of adding nodes and onne tions. If all onne tions of a node wereremoved, the node itself was removed. Histori al markings and spe iation worked as in omplexifying NEAT, ex ept that all markings were assigned in the beginning of evolution.(be ause stru ture was only removed and never added). A diversity of spe ies of varying omplexity developed as before. 90\nCompetitive Coevolution through Evolutionary Complexifi ation\n1 500 0\n15 D om . L ev el\nComplexifying Coevolution\n1 500 0\n15 D om . L ev el\nSimplifying Coevolution"}, {"heading": "Equivalent Performance", "text": "Generations 227\n339\nC on\nne ct\nio ns\nin D\nom .\n39\n149\nC on\nne ct\nio ns\nin D\nom .\nFigure 15: Comparing Typi al Runs of Complexifying Coevolution and Simplifying Co-evolution. Dominan e levels are harted as in gure 12. In addition, the line plotshows the omplexity of ea h dominan e level in terms of number of onne tions in thenetworks with s ale indi ated in the y-axis at right. In this typi al simplifying run, thenumber of onne tions redu ed from 339 to 227 onne tions. The arrow shows that thehighest dominant strategy found in simplifying oevolution only performs as well as the9th or 10th dominant strategy of omplexifying oevolution, whi h is normally foundafter 56 generations (sd = 31). In other words, even though simplifying oevolution nds more dominan e levels, the sear h for appropriate stru ture is less e e tive thanthat of omplexifying oevolution.The ve runs of simplifying oevolution performed at 64:8%, 60:9%, 56:6%, 36:4%, and67:9%, with an overall average of 57:3% (sd=19.8%). Again, su h performan e is signi - antly below the 91:4% performan e of omplexifying oevolution (p < 0:001). Interestingly,even though it started with 76 more onne tions than xed-topology oevolution with tenhidden units, simplifying oevolution still performed signi antly better (p < 0:001), sug-gesting that evolving stru ture through redu ing omplexity is better than evolving large xed stru tures.Like Figures 12{14, Figure 15 ompares typi al runs of omplexifying and simplifying oevolution. On average, 500 generations of simpli ation nds solutions equivalent to 56generations of omplexi ation. Simplifying oevolution also tends to nd more dominan elevels than any other method tested. It generated an average of 23:2 dominan e levels perrun, on e even nding 30 in one run, whereas e.g. omplexifying oevolution on average nds 15:2 levels. In other words, the di eren e between dominan e levels is mu h smaller in91\nStanley & MiikkulainenCoevolution Type Ave. Highest Ave. Highest Average EquivalentDom. Level Generation Performan e Generation(out of 500)Complexifying 15.2 353.6 91.4% 343Fixed-Topology 12.0 172 40.4% 2410 Hidden NodeFixed-Topology 13.0 291.4 80.3% 1595 Hidden NodeFixed-Topology 14.0 301.8 82.4% 193Best NetworkSimplifying 23.2 444.2 57.3% 56Table 1: Summary of the performan e omparison. The se ond olumn shows howmany levels of dominan e were a hieved in ea h type of oevolution on average. The thirdspe i es the average generation of the highest dominant strategy, indi ating how long inno-vation generally ontinues. The fourth olumn gives the average level in the omplexifying oevolution dominan e hierar hy that the hampion ould defeat, and the fth olumn showsits average generation. The di eren es in performan e (p < 0:001) and equivalent genera-tion (p < 0:001) between omplexifying oevolution and every other method are signi ant.The main result is that the level of sophisti ation rea hed by omplexifying oevolution issigni antly higher than that rea hed by xed-topology or simplifying oevolution.simplifying oevolution than omplexifying oevolution. Unlike in other methods, dominantstrategies tend to appear in spurts of a few at a time, and usually after omplexity hasbeen de reasing for several generations, as also shown in Figure 15. Over a number ofgenerations, evolution removes several onne tions until a smaller, more easily optimizedspa e is dis overed. Then, a qui k su ession of minute improvements reates several newlevels of dominan e, after whi h the spa e is further re ned, and so on. While su h a pro essmakes sense, the inferior results of simplifying oevolution suggest that simplifying sear his an ine e tive way of dis overing useful stru tures ompared to omplexi ation.6.3.6 Comparison SummaryTable 1 shows how the oevolution methods di er on number of dominan e levels, gener-ation of the highest dominan e level, overall performan e, and equivalent generation. The on lusion is that omplexifying oevolution innovates longer and nds a higher level ofsophisti ation than the other methods.7. Dis ussion and Future WorkWhat makes omplexi ation su h a powerful sear h method? Whereas in xed-topology oevolution, as well as in simplifying oevolution, the good stru tures must be optimizedin the high-dimensional spa e of the solutions themselves, omplexifying oevolution onlysear hes high-dimensional stru tures that are elaborations of known good lower-dimensionalstru tures. Before adding a new dimension, the values of the existing genes have alreadybeen optimized over pre eding generations. Thus, after a new gene is added, the genome is92\nCompetitive Coevolution through Evolutionary Complexifi ationalready in a promising part of the new, higher-dimensional spa e. Thus, the sear h in thehigher-dimensional spa e is not starting blindly as it would if evolution began sear hing inthat spa e. It is for this reason that omplexi ation an nd high-dimensional solutionsthat xed-topology oevolution and simplifying oevolution annot.Complexi ation is parti ularly well suited for oevolution problems. When a xedgenome is used to represent a strategy, that strategy an be optimized, but it is not possibleto add fun tionality without sa ri ing some of the knowledge that is already present. In ontrast, if new geneti material an be added, sophisti ated elaborations an be layeredabove existing stru ture, establishing an evolutionary arms ra e. This pro ess was evidentin the robot duel domain, where su essive dominant strategies often built new fun tionalityon top of existing behavior by adding new nodes and onne tions.The advantages of omplexi ation do not imply that xed-sized genomes annot some-times evolve in reasingly omplex phenotypi behavior. Depending on the mapping betweenthe genotype and the phenotype, it may be possible for a xed, nite set of genes to representsolutions (phenotypes) with varying behavioral omplexity. For example, su h behaviorshave been observed in Cellular Automata (CA), a omputational stru ture onsisting of alatti e of ells that hange their state as a fun tion of their own urrent state and the stateof other ells in their neighborhood. This neighborhood fun tion an be represented in agenome of size 2n+1 (assuming n neighboring ells with binary state) and evolved to obtaindesired target behavior. For example, Mit hell et al. (1996) were able to evolve neighbor-hood fun tions to determine whether bla k or white ells were in the majority in the CAlatti e. The evolved CAs displayed omplex global behavior patterns that onverged on asingle lassi ation, depending on whi h ell type was in the majority. Over the ourse ofevolution, the behavioral omplexity of the CA rose even as the genome remained the samesize.In the CA example, the orre t neighborhood size was hosen a priori. This hoi e isdi\u00c6 ult to make, and ru ial for su ess. If the desired behavior had not existed within the hosen size, even if the behavior would be ome gradually more omplex, the system wouldnever solve the task. Interestingly, su h a dead-end ould be avoided if the neighborhood(i.e. the genome) ould be expanded during evolution. It is possible that CAs ould bemore e e tively evolved by omplexifying (i.e. expanding) the genomes, and spe iating toprote t innovation, as in NEAT.Moreover, not only an the hosen neighborhood be too small to represent the solution,but it an also be unne essarily large. Sear hing in a spa e of more dimensions thanne essary an impede progress, as dis ussed above. If the desired fun tion existed in asmaller neighborhood it ould have been found with signi antly fewer evaluations. Indeed,it is even possible that the most e\u00c6 ient neighborhood is not symmetri , or ontains ellsthat are not dire tly adja ent to the ell being pro essed. Moreover, even the most e\u00c6 ientneighborhood may be too large a spa e in whi h to begin sear hing. Starting sear h in asmall spa e and in rementing into a promising part of higher-dimensional spa e is morelikely to nd a solution. For these reasons, omplexi ation an be an advantage, even ifbehavioral omplexity an in rease to some extent within a xed spa e.The CA example raises the intriguing possibility that any stru tured phenotype anbe evolved through omplexi ation from a minimal starting point, histori al markings,and the prote tion of innovation through spe iation. In addition to neural networks and93\nStanley & MiikkulainenCA, ele tri al ir uits (Miller et al., 2000a; Miller, Job, & Vassilev, 2000b), geneti pro-grams (Koza, 1992), robot body morphologies (Lipson & Polla k, 2000), Bayesian networks(Mengshoel, 1999), nite automata (Brave, 1996), and building and vehi le ar hite tures(O'Reilly, 2000) are all stru tures of varying omplexity that an bene t from omplexi - ation. By starting sear h in a minimal spa e and adding new dimensions in rementally,highly omplex phenotypes an be dis overed that would be di\u00c6 ult to nd if sear h beganin the intra table spa e of the nal solution, or if it was prematurely restri ted to too smalla spa e.The sear h for optimal stru tures is a ommon problem in Arti ial Intelligen e (AI).For example, Bayesian methods have been applied to learning model stru ture (Attias, 2000;Ueda & Ghahramani, 2002). In these approa hes, the posterior probabilities of di erentstru tures are omputed, allowing overly omplex or simplisti models to be eliminated.Note that these approa hes are not aimed at generating in reasingly omplex fun tionalstru tures, but rather at providing a model that explains existing data. In other ases,solutions involve growing gradually larger stru tures, but the goal of the growth is to formgradually better approximations. For example, methods like In remental Grid Growing(Bla kmore & Miikkulainen, 1995), and Growing Neural Gas (Fritzke, 1995) add neuronsto a network until it approximates the topology of the input spa e reasonably well. On theother hand, omplexifying systems do not have to be non-deterministi (like NEAT), nor dothey need to be based on evolutionary algorithms. For example, Harvey (1993) introdu ed adeterministi algorithm where the hromosome lengths of the entire population in rease allat the same time in order to expand the sear h spa e; Fahlman & Lebiere (1990) developeda supervised (non-evolutionary) neural network training method alled as ade orrelation,where new hidden neurons are added to the network in a predetermined manner in order to omplexify the fun tion it omputes. The on lusion is that omplexi ation is an importantgeneral prin iple in AI.In the future, omplexi ation may help with the general problem of nding the ap-propriate level of abstra tion for di\u00c6 ult problems. Complexi ation an start out witha simple, high-level des ription of the solution, omposed of general-purpose elements. Ifsu h an abstra tion is insu\u00c6 ient, it an be elaborated by breaking down ea h high-levelelement into lower level and more spe i omponents. Su h a pro ess an ontinue indef-initely, leading to in reasingly omplex substru tures, and in reasingly low-level solutionsto subproblems. Although in NEAT the solutions are omposed of only onne tions andnodes, it does provide an early example of how su h a pro ess ould be implemented.One of the primary and most elusive goals of AI is to reate systems that s ale up. Ina sense, omplexi ation is the pro ess of s aling up. It is the general prin iple of taking asimple idea and elaborating it for broader appli ation. Mu h of AI is on erned with sear h,whether over omplex multi-dimensional lands apes, or through highly-bran hing trees ofpossibilities. However, intelligen e is as mu h about de iding what spa e to sear h as it isabout sear hing on e the proper spa e has already been identi ed. Currently, only humansare able to de ide the proper level of abstra tion for solving many problems, whether it be asimple high-level ombination of general-purpose parts, or an extremely omplex assemblyof low-level omponents. A program that an de ide what level of abstra tion is mostappropriate for a given domain would be a highly ompelling demonstration of Arti ial94\nCompetitive Coevolution through Evolutionary Complexifi ationIntelligen e. This is, we believe, where omplexi ation methods an have their largestimpa t in the future.8. Con lusionThe experiments presented in this paper show that omplexi ation of genomes leads to ontinual oevolution of in reasingly sophisti ated strategies. Three trends were found inthe experiments: (1) As evolution progresses, omplexity of solutions in reases, (2) evo-lution uses omplexi ation to elaborate on existing strategies, and (3) omplexifying o-evolution is signi antly more su essful in nding highly sophisti ated strategies thannon- omplexifying oevolution. These results suggest that omplexi ation is a ru ial omponent of a su essful sear h for omplex solutions.A knowledgmentsThis resear h was supported in part by the National S ien e Foundation under grant IIS-0083776 and by the Texas Higher Edu ation Coordinating Board under grant ARP-003658-476-2001. Spe ial thanks to an anonymous reviewer for onstru tive suggestions for non- omplexifying omparisons.Appendix A. NEAT System ParametersEa h population had 256 NEAT networks, for a total of 512. The oe\u00c6 ients for measuring ompatibility were 1 = 1:0, 2 = 1:0, and 3 = 2:0. The initial ompatibility distan e was\u00c6t = 3:0. However, be ause population dynami s an be unpredi table over hundreds ofgenerations, we assigned a target of 10 spe ies. If the number of spe ies grew above 10, \u00c6twas in reased by 0:3 to redu e the number of spe ies. Conversely, if the number of spe iesfell below 10, \u00c6t was de reased by 0:3 to in rease the number of spe ies. The normalizationfa tor N used to ompute ompatibility was xed at one. In order to prevent stagnation,the lowest performing spe ies over 30 generations old was not allowed to reprodu e. The hampion of ea h spe ies with more than ve networks was opied into the next generationun hanged. There was an 80% han e of a genome having its onne tion weights mutated, inwhi h ase ea h weight had a 90% han e of being uniformly perturbed and a 10% han e ofbeing assigned a new random value. (The system is tolerant to frequent mutations be auseof the prote tion spe iation provides.) There was a 75% han e that an inherited gene wasdisabled if it was disabled in either parent. In 40% of rossovers, the o spring inheritedthe average of the onne tion weights of mat hing genes from both parents, instead ofthe onne tion weight of only one parent randomly. In ea h generation, 25% of o springresulted from mutation without rossover. The interspe ies mating rate was 0.05. Theprobability of adding a new node was 0.01 and the probability of a new link mutationwas 0.1. We used a modi ed sigmoidal transfer fun tion, '(x) = 11+e 4:9x , at all nodes.These parameter values were found experimentally, and they follow a logi al pattern: Linksneed to be added signi antly more often than nodes, and an average weight di eren eof 0.5 is about as signi ant as one disjoint or ex ess gene. Performan e is robust to95\nStanley & Miikkulainenmoderate variations in these values. NEAT software is available in the software se tion athttp://nn. s.utexas.edu.Appendix B. Robot Duel Domain Coe\u00c6 ients of MotionThe turn angle is determined as = 0:24jl rj, where l is the output of the left turn neuron,and r is the output of the right turn neuron. The robot moves forward a distan e of 1:33fon the 600 by 600 board, where f is the forward motion output. These oe\u00c6 ients were alibrated through experimentation to a hieve a urate and smooth motion with neuraloutputs between zero and one.Referen esAmores, A., For e, A., Yan, Y.-L., Joly, L., Amemiya, C., Fritz, A., Ho, R. K., Langeland,J., Prin e, V., Wang, Y.-L., Wester eld, M., Ekker, M., & Postlethwait, J. H. (1998).Zebra sh HOX lusters and vertebrate genome evolution. S ien e, 282, 1711{1784.Angeline, P. J., & Polla k, J. B. (1993). Competitive environments evolve better solutions for omplex tasks. In Forrest, S. (Ed.), Pro eedings of the Fifth International Conferen eon Geneti Algorithms (pp. 264{270). San Fran is o, CA: Morgan Kaufmann.Angeline, P. J., Saunders, G. M., & Polla k, J. B. (1993). An evolutionary algorithmthat onstru ts re urrent neural networks. IEEE Transa tions on Neural Networks, 5,54{65.Attias, H. (2000). A variational bayesian framework for graphi al models. In Advan esin Neural Information Pro essing Systems, 12 (pp. 209{215). Cambridge, MA: MITPress.Bla kmore, J., & Miikkulainen, R. (1995). Visualizing high-dimensional stru ture with thein remental grid growing neural network. In Prieditis, A., & Russell, S. (Eds.),Ma hineLearning: Pro eedings of the 12th Annual Conferen e (pp. 55{63). San Fran is o, CA:Morgan Kaufmann.Brave, S. (1996). Evolving deterministi nite automata using ellular en oding. In Koza,J. R., Goldberg, D. E., Fogel, D. B., & Riolo, R. L. (Eds.), Geneti Programming1996: Pro eedings of the First Annual Conferen e (pp. 39{44). Stanford University,CA, USA: MIT Press.Carroll, S. B. (1995). Homeoti genes and the evolution of arthropods and hordates.Nature, 376, 479{485.Cli , D., Harvey, I., & Husbands, P. (1993). Explorations in evolutionary roboti s. AdaptiveBehavior, 2, 73{110.Cybenko, G. (1989). Approximation by superpositions of a sigmoidal fun tion. Mathemati sof Control, Signals, and Systems, 2 (4), 303{314.96\nCompetitive Coevolution through Evolutionary Complexifi ationDarwen, P. J. (1996). Co-Evolutionary Learning by Automati Modularisation with Spe ia-tion. Do toral Dissertation, S hool of Computer S ien e, University College, Universityof New South Wales.Dawkins, R., & Krebs, J. R. (1979). Arms ra es between and within spe ies. Pro eedingsof the Royal So iety of London Series B, 205, 489{511.Fahlman, S. E., & Lebiere, C. (1990). The as ade- orrelation learning ar hite ture. InTouretzky, D. S. (Ed.), Advan es in Neural Information Pro essing Systems 2 (pp.524{532). San Fran is o, CA: Morgan Kaufmann.Fi i i, S. G., & Polla k, J. B. (2001). Pareto optimality in oevolutionary learning. InKelemen, J. (Ed.), Sixth European Conferen e on Arti ial Life. Berlin; New York:Springer-Verlag.Floreano, D., & Nol , S. (1997). God save the red queen! Competition in o-evolutionaryroboti s. Evolutionary Computation, 5.For e, A., Lyn h, M., Pi kett, F. B., Amores, A., lin Yan, Y., & Postlethwait, J. (1999).Preservation of dupli ate genes by omplementary, degenerative mutations. Geneti s,151, 1531{1545.Fritzke, B. (1995). A growing neural gas network learns topologies. In G.Tesauro,D.S.Touretzky, & T.K.Leen (Eds.), Advan es in Neural Information Pro essing Sys-tems 7 (pp. 625{632). Cambridge, MA: MIT Press.Goldberg, D. E., & Ri hardson, J. (1987). Geneti algorithms with sharing for multimodalfun tion optimization. In Grefenstette, J. J. (Ed.), Pro eedings of the Se ond Interna-tional Conferen e on Geneti Algorithms (pp. 148{154). San Fran is o, CA: MorganKaufmann.Gomez, F., & Miikkulainen, R. (1997). In remental evolution of omplex general behavior.Adaptive Behavior, 5, 317{342.Gruau, F., Whitley, D., & Pyeatt, L. (1996). A omparison between ellular en oding anddire t en oding for geneti neural networks. In Koza, J. R., Goldberg, D. E., Fogel,D. B., & Riolo, R. L. (Eds.), Geneti Programming 1996: Pro eedings of the FirstAnnual Conferen e (pp. 81{89). Cambridge, MA: MIT Press.Harvey, I. (1993). The Arti ial Evolution of Adaptive Behavior. Do toral Dissertation,S hool of Cognitive and Computing S ien es, University of Sussex, Sussex.Holland, P. W., Gar ia-Fernandez, J., Williams, N. A., & Sidow, A. (1994). Gene dupli a-tions and the origin of vertebrate development. Development Supplement, pp. 125{133.Jim, K.-C., & Giles, C. L. (2000). Talking helps: Evolving ommuni ating agents for thepredator-prey pursuit problem. Arti ial Life, 6 (3), 237{254. 97\nStanley & MiikkulainenKoza, J. (1995). Gene dupli ation to enable geneti programming to on urrently evolveboth the ar hite ture and work-performing steps of a omputer program. In Pro- eedings of the 14th International Joint Conferen e on Arti ial Intelligen e. MorganKaufmann.Koza, J. R. (1992). Geneti Programming: On the Programming of Computers by Meansof Natural Sele tion. Cambridge, MA: MIT Press.Lindgren, K., & Johansson, J. (2001). Coevolution of strategies in n-person prisoner'sdilemma. In Crut h eld, J., & S huster, P. (Eds.), Evolutionary Dynami s - Exploringthe Interplay of Sele tion, Neutrality, A ident, and Fun tion. Reading, MA: Addison-Wesley.Lipson, H., & Polla k, J. B. (2000). Automati design and manufa ture of roboti lifeforms.Nature, 406, 974{978.Mahfoud, S. W. (1995). Ni hing Methods for Geneti Algorithms. Do toral Dissertation,University of Illinois at Urbana-Champaign, Urbana, IL.Maley, C. C. (1999). Four steps toward open-ended evolution. In Pro eedings of the Ge-neti and Evolutionary Computation Conferen e (GECCO-1999) (pp. 1336{1343). SanFran is o, CA: Morgan Kaufmann.Martin, A. P. (1999). In reasing genomi omplexity by gene dupli ation and the origin ofvertebrates. The Ameri an Naturalist, 154 (2), 111{128.Mengshoel, O. J. (1999). E\u00c6 ient Bayesian Network Inferen e: Geneti Algorithms,Sto hasti Lo al Sear h, and Abstra tion. Do toral Dissertation, University of Illinoisat Urbana-Champaign Computer S ien e Department, Urbana-Champaign, IL.Miller, G., & Cli , D. (1994). Co-evolution of pursuit and evasion i: Biologi al and game-theoreti foundations. Te h. Rep. CSRP311, S hool of Cognitive and Computing S i-en es, University of Sussex, Brighton, UK.Miller, J. F., Job, D., & Vassilev, V. K. (2000a). Prin iples in the evolutionary design ofdigital ir uits { Part I. Journal of Geneti Programming and Evolvable Ma hines,1 (1), 8{35.Miller, J. F., Job, D., & Vassilev, V. K. (2000b). Prin iples in the evolutionary design ofdigital ir uits { Part II. Journal of Geneti Programming and Evolvable Ma hines,3 (2), 259{288.Mit hell, M., Crut h eld, J. P., & Das, R. (1996). Evolving ellular automata with geneti algorithms: A review of re ent work. In Pro eedings of the First International Confer-en e on Evolutionary Computation and Its Appli ations (EvCA'96). Russian A ademyof S ien es.Mondada, F., Franzi, E., & Ienne, P. (1993). Mobile robot miniaturization: A tool for in-vestigation in ontrol algorithms. In Pro eedings of the Third International Symposiumon Experimental Roboti s (pp. 501{513).98\nCompetitive Coevolution through Evolutionary Complexifi ationNadeau, J. H., & Sanko , D. (1997). Comparable rates of gene loss and fun tional divergen eafter genome dupli ations early in vertebrate evolution. Geneti s, 147, 1259{1266.Noble, J., & Watson, R. A. (2001). Pareto oevolution: Using performan e against oe-volved opponents in a game as dimensions for parerto sele tion. In et al, L. S. (Ed.),Pro eedings of the Geneti and Evolutionary Computation Conferen e (GECCO-2001).San Fran is o, CA: Morgan Kaufmann.O'Reilly, U.-M. (2000). Emergent design: Arti ial life for ar hite ture design. In 7thInternational Conferen e on Arti ial Life (ALIFE-00). Cambridge, MA: MIT Press.Postlethwait, H. H., Yan, Y. L., Gates, M. A., Horne, S., Amores, A., Brownlie, A., &Donovan, A. (1998). Vertebrate genome evolution and the zebra sh gene map. NatureGeneti s, 18, 345{349.Rad li e, N. J. (1993). Geneti set re ombination and its appli ation to neural networktopology optimization. Neural omputing and appli ations, 1 (1), 67{90.Radding, C. M. (1982). Homologous pairing and strand ex hange in geneti re ombination.Annual Review of Geneti s, 16, 405{437.Reggia, J. A., S hulz, R., Wilkinson, G. S., & Uriagereka, J. (2001). Conditions enablingthe evolution of inter-agent signaling in an arti ial world. Arti ial Life, 7, 3{32.Rosin, C. D. (1997). Coevolutionary Sear h Among Adversaries. Do toral Dissertation,University of California, San Diego, San Diego, CA.Rosin, C. D., & Belew, R. K. (1997). New methods for ompetitive evolution. EvolutionaryComputation, 5.Ryan, C. (1994). Pygmies and ivil servants. In Kinnear, Jr., K. E. (Ed.), Advan es inGeneti Programming (Chap. 11, pp. 243{263). MIT Press.Sidow, A. (1996). Gen(om)e dupli ations in the evolution of early vertebrates. CurrentOpinion in Geneti s and Development, 6, 715{722.Sigal, N., & Alberts, B. (1972). Geneti re ombination: The nature of a rossed strand-ex hange between two homologous DNA mole ules. Journal of Mole ular Biology,71 (3), 789{793.Sims, K. (1994). Evolving 3D morphology and behavior by ompetition. In Brooks, R. A.,& Maes, P. (Eds.), Pro eedings of the Fourth International Workshop on the Synthesisand Simulation of Living Systems (Arti ial Life IV) (pp. 28{39). Cambridge, MA:MIT Press.Spears, W. (1995). Spe iation using tag bits. In Handbook of Evolutionary Computation.IOP Publishing Ltd. and Oxford University Press. 99\nStanley & MiikkulainenStanley, K. O., & Miikkulainen, R. (2002a). The dominan e tournament method of moni-toring progress in oevolution. In Pro eedings of the Geneti and Evolutionary Com-putation Conferen e (GECCO-2002) Workshop Program. San Fran is o, CA: MorganKaufmann.Stanley, K. O., & Miikkulainen, R. (2002b). E\u00c6 ient evolution of neural network topologies.In Pro eedings of the 2002 Congress on Evolutionary Computation (CEC'02). IEEE.Stanley, K. O., & Miikkulainen, R. (2002 ). E\u00c6 ient reinfor ement learning through evolv-ing neural network topologies. In Pro eedings of the Geneti and Evolutionary Com-putation Conferen e (GECCO-2002). San Fran is o, CA: Morgan Kaufmann.Stanley, K. O., & Miikkulainen, R. (2002d). Evolving neural networks through augmentingtopologies. Evolutionary Computation, 10 (2), 99{127.Ueda, N., & Ghahramani, Z. (2002). Bayesian model sear h for mixture models based onoptimizing variational bounds. Neural Networks, 15, 1223{1241.Van Valin, L. (1973). A new evolutionary law. Evolution Theory, 1, 1{30.Yao, X. (1999). Evolving arti ial neural networks. Pro eedings of the IEEE, 87 (9), 1423{1447.Zhang, B.-T., & Muhlenbein, H. (1993). Evolving optimal neural networks using geneti algorithms with O am's razor. Complex Systems, 7, 199{220.\n100"}], "references": [], "referenceMentions": [], "year": 2011, "abstractText": null, "creator": "dvips(k) 5.92a Copyright 2002 Radical Eye Software"}}}