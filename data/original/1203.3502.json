{"id": "1203.3502", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2012", "title": "The Cost of Troubleshooting Cost Clusters with Inside Information", "abstract": "Decision theoretical troubleshooting is about minimizing the expected cost of solving a certain problem like repairing a complicated man-made device. In this paper we consider situations where you have to take apart some of the device to get access to certain clusters and actions. Specifically, we investigate troubleshooting with independent actions in a tree of clusters where actions inside a cluster cannot be performed before the cluster is opened. The problem is non-trivial because there is a cost associated with opening and closing a cluster. Troubleshooting with independent actions and no clusters can be solved in O(n lg n) time (n being the number of actions) by the well-known \"P-over-C\" algorithm due to Kadane and Simon, but an efficient and optimal algorithm for a tree cluster model has not yet been found. In this paper we describe a \"bottom-up P-over-C\" O(n lg n) time algorithm and show that it is optimal when the clusters do not need to be closed to test whether the actions solved the problem.", "histories": [["v1", "Thu, 15 Mar 2012 11:17:56 GMT  (292kb)", "http://arxiv.org/abs/1203.3502v1", "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)", "reviews": [], "SUBJECTS": "cs.AI cs.DS", "authors": ["thorsten j ottosen", "finn verner jensen"], "accepted": false, "id": "1203.3502"}, "pdf": {"name": "1203.3502.pdf", "metadata": {"source": "CRF", "title": "The Cost of Troubleshooting Cost Clusters with Inside Information", "authors": ["Thorsten J. Ottosen", "Finn V. Jensen"], "emails": ["nesotto@cs.aau.dk,", "fvj@cs.aau.dk"], "sections": [{"heading": null, "text": "Decision theoretical troubleshooting is about minimizing the expected cost of solving a certain problem like repairing a complicated man-made device. In this paper we consider situations where you have to take apart some of the device to get access to certain clusters and actions. Specifically, we investigate troubleshooting with independent actions in a tree of clusters where actions inside a cluster cannot be performed before the cluster is opened. The problem is non-trivial because there is a cost associated with opening and closing a cluster. Troubleshooting with independent actions and no clusters can be solved in O(n \u00b7 lg n) time (n being the number of actions) by the well-known \u201dP-over-C\u201d algorithm due to Kadane and Simon, but an efficient and optimal algorithm for a tree cluster model has not yet been found. In this paper we describe a \u201dbottom-up P-over-C\u201d O(n \u00b7 lg n) time algorithm and show that it is optimal when the clusters do not need to be closed to test whether the actions solved the problem."}, {"heading": "1 INTRODUCTION", "text": "In decision theoretical troubleshooting we are faced with a problem that needs to be solved by applying solution actions and by posing questions that gather information about the problem. The premise is that after each action we can cost free observe whether the problem was solved. The domain is assumed to be uncertain, that is, solution actions may be imperfect and information might be non-conclusive. Given a model that describes the uncertainty and the cost of actions and questions, the goal is to compute a strategy for solving the problem with the lowest expected cost.\nIf the model has the following assumptions:\n(a) the problem is due to a single fault,\n(b) different actions address different faults,\n(c) costs do not depend on the previous history, and\n(d) there are no questions,\nthen the problem is solvable in O(n \u00b7 lg n) time where n is the number of actions. This algorithm is the wellknown \u201dP-over-C\u201d algorithm by (Kadane and Simon, 1977) which was first brought into a troubleshooting context by (Kalagnanam and Henrion, 1990). Furthermore, if any of the above assumptions are relaxed without restrictions, the problem becomes NP-hard (Vomlelova\u0301, 2003). If assumption (a) is replaced with an assumption about multiple independent faults, an O(n\u00b7lg n) P-over-C-like algorithm also exists (Srinivas, 1995). Troubleshooting without assumption (b) can also be somewhat simplified due to the dependency set algorithm of (Koca and Bilgic, 2004).\n(Langseth and Jensen, 2001) proposed to relax assumption (c) slightly by considering a model where the actions can be partitioned into a flat set of socalled cost clusters (see Figure 1). The idea is that in order to access an action in a bottom level cluster Ki, you need to pay an additional cost Coi and to close the cluster you have to pay an additional cost Cci . Thereby it is possible to model e.g. the repair of complex manmade devices where you need to take apart some of the equipment to perform certain actions. If we can determine whether an action has solved the problem without assembling the cluster first, Langseth and Jensen said that the cluster has inside information; otherwise the cluster is without inside information. They furthermore describe heuristics for both problems. In this paper we present a proof of correctness of their algorithm for the problem with inside information. We furthermore extend the model to a tree of clusters and give an O(n \u00b7 lg n) time algorithm that is proved optimal. (Warnquist et al., 2008) describe a slightly more general cost cluster framework, but they do not address the issue of finding an efficient algorithm."}, {"heading": "2 PRELIMINARIES", "text": "In this paper we shall examine troubleshooting problems where the following model parameters are given. F = {f1, . . . , fm} is a set of faults describing the possible causes to the problem. For each fault f \u2208 F , we have a probability P(f) describing how likely it is that f is present when troubleshooting begins. A = {\u03b11, . . . , \u03b1n} is a set of actions that can potentially solve the problem. Each action \u03b1 has two possible outcomes, namely \u201d\u03b1 = yes\u201d (the problem was fixed) and \u201d\u03b1 = no\u201d (the action failed to fix the problem). Each action \u03b1 has a positive cost C\u03b1 describing the resources required to perform the action. Finally, each action has an associated success probability P(\u03b1 = yes | f), the probability of solving the problem by performing the action when f is present.\nThe set of actions A can be partitioned into `+1 clusters K,K1, . . . ,K` where cluster K is the top-level cluster and the remaining are bottom-level clusters. The cost of opening a cluster Ki is Coi and the cost of closing it again is Cci . We define CKi = C o i +C c i . An action \u03b1 belongs to cluster K(\u03b1).\nDuring the course of troubleshooting we gather evidence \u03b5i meaning that the first i actions failed to solve the problem, and we have by assumption P ( \u03b50 )\n= 1 because the device is faulty. We also write \u03b5x:y as shorthand for \u22c3y i=x{\u03b1i = no}. FA(\u03b5) is the set of free actions consisting of all actions (excluding those already performed) from open clusters given evidence \u03b5. CA(\u03b5) is the set of confined actions consisting of all actions from closed clusters. Note that we have FA(\u03b5) \u222a CA(\u03b5) \u2286 A and FA(\u03b5) \u2229 CA(\u03b5) = \u2205 for all evidence \u03b5. By performing an action \u03b1 from CA(\u03b5) we pay the cost CK(\u03b1) because at this point we are certain that we must both open and close the cluster. In that case \u03b1 is called an opening action (for K(\u03b1)), and all remaining actions of K(\u03b1) are released by removing them from CA(\u03b5) and adding them to FA(\u03b5). The\nconditional cost C\u03b1(\u03b5) of an action \u03b1 given evidence \u03b5 is given by C\u03b1 + CK(\u03b1) if \u03b1 \u2208 CA(\u03b5) and by C\u03b1 if \u03b1 \u2208 FA(\u03b5).\nThroughout this paper we uphold the following simplifying assumptions about the model:\n1 (The single fault assumption). Initially the problem is known to exist and it is due to the presence of a single fault from F .\n2 (The idempotent action assumption). Repeating a failed action will not fix the problem.\n3 (The carefulness assumption). By performing an action or testing the system, we never introduce new faults.\n4 (The independent actions assumption). Different actions address different faults.\n5 (The costless system test assumption). Checking whether the problem still exists after performing an action can be done at a negligible cost.\n6 (The inside information assumption). All clusters have inside information.\nDue to the single-fault assumption we may compute the repair probability of an action given evidence \u03b5 as P(\u03b1 = yes |\u03b5) = \u2211 f\u2208F P(\u03b1 = yes | f) \u00b7 P(f |\u03b5). In a few places we shall abbreviate P(\u03b1 = yes |\u03b5) with P(\u03b1 |\u03b5). Due to the independent actions assumption P(\u03b1) /P(\u03b2) = P(\u03b1 |\u03b5) /P(\u03b2 |\u03b5) for all evidence \u03b5 not involving \u03b1 or \u03b2. We shall therefore abbreviate the initial repair probability P(\u03b1 = yes) as P\u03b1 .\nA troubleshooting sequence is a sequence of actions s = \u3008\u03b11, . . . , \u03b1n\u3009 prescribing the process of repeatedly performing the next action until the problem is fixed or the last action has been performed. We shall write s[k,m] for the subsequence \u3008\u03b1k, . . . , \u03b1m\u3009 and s(k,m) for the subsequence \u3008\u03b1k+1, . . . , \u03b1m\u22121\u3009. The index of an opening action in a troubleshooting sequence s is called an opening index, and the set of all opening indices for s is denoted Z with Z \u2286 {1, . . . , n}, |Z| = `. To measure the quality of a given sequence we use the following definition.\nDefinition 1. Let s = \u3008\u03b11, . . . , \u03b1n\u3009 be a troubleshooting sequence. Then the expected cost of repair (ECR) of s is given by\nECR (s) = n\u2211 i=1 P ( \u03b5i\u22121 ) \u00b7 C\u03b1i(\u03b5i\u22121) .\nFormally, our optimization problem is to find a troubleshooting sequence with minimal ECR. Without cost clusters, the problem is easily solved due to the theorem below.\nTheorem 1 (Kadane and Simon (1977)). Let s = \u3008\u03b11, . . . , \u03b1n\u3009 be a troubleshooting sequences in a model without cost clusters. Then s is optimal if and only if\nP\u03b1i C\u03b1i \u2265 P\u03b1i C\u03b1i for i \u2208 {1, . . . , n\u2212 1} .\nIf costs are not conditional and actions are independent, the lemma below leads directly to the \u201dP-over-C\u201d algorithm.\nLemma 1 (Jensen et al. (2001)). Let s be a troubleshooting sequence and let \u03b1x and \u03b1x+1 be two adjacent actions in s. If s is optimal then\nC\u03b1x(\u03b5 x\u22121) +\n( 1\u2212 P ( \u03b1x |\u03b5x\u22121 )) \u00b7 C\u03b1x+1(\u03b5x) \u2264\nC\u03b1x+1(\u03b5 x\u22121) +( 1\u2212 P ( \u03b1x+1 |\u03b5x\u22121 )) \u00b7 C\u03b1x(\u03b5x\u22121, \u03b1a+1 = no) .\nWith assumption 1, 3, 4, and 5 we may simplify computations and notation somewhat because of the following result.\nProposition 1. Let s = \u3008\u03b11, . . . , \u03b1n\u3009 be a troubleshooting sequence. Then the ECR of s may be computed as\nECR (s) = n\u2211 i=1 C\u03b1i(\u03b5 i\u22121) \u00b7 1\u2212 i\u22121\u2211 j=1 P\u03b1j  , where 1\u2212 \u2211i\u22121 j=1 P\u03b1j = P ( \u03b5i\u22121 ) .\nThis easy computation of the probabilities can be dated back to (Kalagnanam and Henrion, 1990) and (Heckerman et al., 1995).\nThus, due to our assumptions, we may completely ignore F , P(f), and P(\u03b1 = yes|f) once the repair probabilities have been computed. Therefore, we mainly use P\u03b1 in the rest of this paper.\nUsing the set of opening indices Z, we can rewrite the definition of ECR of a sequence s to\nECR (s) = \u2211 i=1 C\u03b1i \u00b7 1\u2212 i\u22121\u2211 j=1 P\u03b1j  + \u2211 z\u2208Z CK(\u03b1z) \u00b7 1\u2212 z\u22121\u2211 j=1 P\u03b1j\n (1) where we have decomposed the terms into those that rely on the cost of performing actions and those that rely on the cost of opening and closing a cluster. We define the efficiency of an action \u03b1 given evidence \u03b5 as ef(\u03b1 |\u03b5) = P\u03b1/C\u03b1(\u03b5), and we write ef(\u03b1) for the unconditional efficiency P\u03b1/C\u03b1 . Finally, the cluster efficiency of an opening action is cef(\u03b1) = P\u03b1\nC\u03b1+CK(\u03b1) .\nLemma 2. Let s = \u3008\u03b11, . . . , \u03b1n\u3009 be an optimal troubleshooting sequence with opening indices zi \u2208 Z. Then the ` + 1 subsequences s[\u03b11, \u03b1z1), s[\u03b1zi , \u03b1zi+1) \u2200i \u2208 {1, . . . , ` \u2212 1}, and s[\u03b1z` , \u03b1n] are ordered with respect to descending efficiency.\nProof. Between opening indices the costs are not conditional, and so we must sort by descending ef(\u00b7) to be optimal.\nWe have now established that given the opening index for each cluster, it is a simple task of merging ordered sequences to establish an optimal sequence. The difficult part is to determine the opening indices."}, {"heading": "3 THE EXTENDED P-OVER-C ALGORITHM", "text": "The standard \u201dP-over-C\u201d algorithm works by sorting the actions based on descending efficiency. The extended algorithm works in a similar manner, but it also considers the efficiency of a cluster: if a cluster is more efficient than all remaining actions and clusters, we should perform some actions from that cluster first.\nDefinition 2. The efficiency of a cluster K is defined as\nef(K) = max M\u2286K\n\u2211 \u03b1\u2208M P\u03b1\nCK + \u2211 \u03b1\u2208M C\u03b1\nand the largest set M \u2286 K that maximizes the efficiency is called the maximizing set of K. The sequence of actions found by sorting the actions of the maximizing set by descending efficiency is called the maximizing sequence of K.\nIt turns out that it is quite easy to calculate the efficiency of a cluster. The following result is a slightly more informative version of the one from (Langseth and Jensen, 2001):\nLemma 3. Let K be a cluster. Then the maximizing set M can be found by including the most efficient actions of K until ef(K) starts decreasing. Furthermore, all actions \u03b1 in the maximizing set M have ef(\u03b1) \u2265 ef(K) and all actions \u03b2 \u2208 K \\ M have ef(\u03b2) < ef(K).\nThe algorithm is described in Algorithm 1. If n denotes the total number of actions, we can see that line 2 takes at most O(n \u00b7 lg n) time. Once the actions have been sorted, line 3-6 takes at most O(n) time. The loop in line 7-20 can be implemented to run in at most O(n \u00b7 lg(`+ 1)) time by using a priority queue for the most efficient element of A and the most efficient element of each cluster. Thus the algorithm has O(n\u00b7lg n) worst case running time. In the next section we prove that the algorithm returns an optimal sequence.\nAlgorithm 1 The extended P-over-C algorithm (Langseth and Jensen, 2001)\n1: function ExtendedPOverC(K,K1, . . . ,K`) 2: Sort actions of K and all Ki by descending ef(\u00b7) 3: Calculate ef(Ki) and maximizing sets Mi 4: for all i \u2208 {1, . . . , `} 5: Let Kclosed = {Ki | i \u2208 {1, . . . , `}} 6: Let A = {\u03b1 | \u03b1 \u2208 K or \u03b1 \u2208 Ki \\Mi for some i} 7: Let s = \u3008\u3009 8: repeat 9: Let \u03b2 be the most efficient action in A\n10: or cluster in Kclosed 11: if \u03b2 is an action then 12: Add action \u03b2 to s 13: Set A = A \\ {\u03b2} 14: else 15: Add all actions of the maximizing set 16: of cluster \u03b2 to s in order of 17: descending efficiency 18: Set Kclosed = Kclosed \\ {\u03b2} 19: end if 20: until Kclosed = \u2205 and A = \u2205 21: Return s 22: end function\nExample 1. We consider a model with three clusters, where K\u03b1 is the root cluster and K\u03b2 and K\u03b3 are the bottom-level clusters. We have CK\u03b2 = 2 and CK\u03b3 = 1, and the following model parameters:\nP C ef(\u00b7) cluster ef(K) \u03b11 0.14 1 0.14 K\u03b1 \u03b12 0.11 1 0.11 K\u03b1 \u03b21 0.20 1 0.067 K\u03b2 0.075 \u03b22 0.10 1 0.033 K\u03b2 \u03b31 0.25 1 0.125 K\u03b3 0.15 \u03b32 0.20 1 0.10 K\u03b3\nThe maximizing set for K\u03b2 is {\u03b21, \u03b22} and for K\u03b3 it is {\u03b31, \u03b32}, and from this the cluster efficiencies have been calculated. Algorithm 1 returns the sequence s = \u3008\u03b31, \u03b32, \u03b11, \u03b12, , \u03b21, \u03b22\u3009 which has ECR\nECR (s) = 2+0.75+0.55+0.41+0.30\u00b73+0.10 = 4.71 .\nIf we followed the simple P-over-C algorithm we would get the sequence s2 = \u3008\u03b11, \u03b31, \u03b12, \u03b32, \u03b21, \u03b22\u3009 with ECR\nECR ( s2 ) = 1+0.86\u00b72+0.61+0.50+0.30\u00b73+0.10 = 4.83 ."}, {"heading": "4 CORRECTNESS OF THE ALGORITHM", "text": "We start with a proof of Lemma 3:\nProof. We shall use the fact that for positive reals we have\na+ b c+ d \u2297 a c \u21d4 b d \u2297 a c\nfor any weak order \u2297 (e.g. \u2265 and \u2264). Let M consist of actions in K such that ef(M) is maximized. Then ef(M) equals\u2211\n\u03b1\u2208M P\u03b1 CK + \u2211 \u03b1\u2208M C\u03b1 =\n\u2211 \u03b1\u2208M\\{\u03b2} P\u03b1 + P\u03b2\nCK + \u2211 \u03b1\u2208M\\{\u03b2}C\u03b1 + C\u03b2\n= SP + P\u03b2 SC + C\u03b2 = P C\nwhere \u03b2 is chosen arbitrarily. Let furthermore \u03b3 \u2208 K \\M. We shall prove\nP\u03b2 C\u03b2 \u2265 P C > P\u03b3 C\u03b3\nwhich implies the theorem. We first prove the leftmost inequality. Because ef(M) is maximal we have\nSP + P\u03b2 SC + C\u03b2 \u2265 SP SC which is equivalent to P\u03b2 C\u03b2 \u2265 SP SC\nwhich again is equivalent to\nP\u03b2 C\u03b2 \u2265 SP + P\u03b2 SC + C\u03b2 .\nThe second inequality is proved similarly.\nWhen we look at opening indices we get the following result.\nLemma 4. Let s = \u3008. . . , \u03b1x, \u03b1x+1, . . .\u3009 be an optimal troubleshooting sequence, and let Z be the opening indices of s. Then\ncef(\u03b1x) \u2265 ef(\u03b1x+1) if x \u2208 Z, \u03b1x+1 \u2208 FA(\u03b5x\u22121) ef(\u03b1x) \u2265 cef(\u03b1x+1) if \u03b1x \u2208 FA(\u03b5x\u22121), x+ 1 \u2208 Z cef(\u03b1x) \u2265 cef(\u03b1x+1) if x \u2208 Z, x+ 1 \u2208 Z\nProof. Apply Lemma 1 and do some pencil pushing. For example, case 1: x \u2208 Z and \u03b1x+1 \u2208 FA(\u03b5x\u22121). In this case we have\nC\u03b1x + CK(\u03b1x) + ( 1\u2212 P ( \u03b1x |\u03b5x\u22121 )) \u00b7 C\u03b1x+1 \u2264\nC\u03b1x+1 + ( 1\u2212 P ( \u03b1x+1 |\u03b5x\u22121 )) \u00b7 ( C\u03b1x + CK(\u03b1x) ) m\nP ( \u03b1x+1 |\u03b5x\u22121 ) [ C\u03b1x + CK(\u03b1x) ] \u2264 P ( \u03b1x |\u03b5x\u22121 ) C\u03b1x+1\nm ef(\u03b1x+1) \u2264 cef(\u03b1x)\nbecause P(\u03b1x) \u2265 P(\u03b1x+1) \u21d4 P(\u03b1x |\u03b5) \u2265 P(\u03b1x+1 |\u03b5) for independent actions.\nDefinition 3. Let s[x, y] be a subsequence of a troubleshooting sequence s. Then the efficiency of s[x, y] is given by\nef(s[x, y]) = \u2211y i=x P\u03b1i\u2211y\ni=x C\u03b1i(\u03b5 i\u22121)\nDefinition 4. Let s = \u3008. . . , \u03b1x, . . . , \u03b1y, . . .\u3009 be a troubleshooting sequence. If all actions of the subsequence s[x, y] belong to the same cluster, we say that the subsequence is regular. If furthermore s[x, y] is as long as possible while not breaking regularity, we say that the subsequence is a maximal regular subsequence.\nRemark. Any troubleshooting sequence can be partitioned into a sequence of regular subsequences, and if all the subsequences are maximal, this partition is unique.\nLemma 5. Let s be an optimal troubleshooting sequence, and let s[x, x + k] and s[y, y + `] (with y = x + k + 1) be two adjacent regular subsequences such that K(\u03b1x) 6= K(\u03b1y) or such that neither x nor y is an opening index. Then\nef(s[x, x+ k]) \u2265 ef(s[y, y + `])\nProof. We consider the sequence\ns2 = \u3008. . . , \u03b1x\u22121, \u03b1y, . . . , \u03b1y+`, \u03b1x, . . . , \u03b1x+k, . . .\u3009\nwhich is equal to s except that the two regular sequences have been swapped. Since s is optimal we have ECR (s) \u2212 ECR ( s2 ) \u2264 0. Because the subsequences are regular and belong to different clusters or do not contain opening indices, the costs are the same in the two sequences in both s and s2. Therefore, we get that the terms of ECR (s)\u2212 ECR ( s2 ) equal\nC\u03b1x(\u03b5 x\u22121) \u00b7\n[ P ( \u03b5x\u22121 ) \u2212 P ( \u03b5x\u22121, \u03b5y:y+` )] ...\nC\u03b1x+k(\u03b5 x+k\u22121) \u00b7\n[ P ( \u03b5x+k\u22121 ) \u2212 P ( \u03b5x+k\u22121, \u03b5y:y+` )] C\u03b1y(\u03b5 y\u22121) \u00b7 [ P ( \u03b5y\u22121 ) \u2212 P ( \u03b5x\u22121\n)] ...\nC\u03b1y+`(\u03b5 y+`\u22121) \u00b7\n[ P ( \u03b5y+`\u22121 ) \u2212 P ( \u03b5x\u22121, \u03b5y:y+`\u22121 )] since the remaining terms cancel out. Now observe that\nP ( \u03b5x+i\u22121 ) \u2212 P ( \u03b5x+i\u22121, \u03b5y:y+` ) =\n1\u2212 x+i\u22121\u2211 j=1 P\u03b1j \u2212 1\u2212 x+i\u22121\u2211 j=1 P\u03b1j \u2212 y+\u2211\u0300 j=y P\u03b1j  = y+\u2211\u0300 j=y P\u03b1j\nand, similarly, P ( \u03b5y+i\u22121 ) \u2212 P ( \u03b5x\u22121, \u03b5y:y+i\u22121 ) = 1\u2212 y+i\u22121\u2211 j=1 P\u03b1j \u2212 1\u2212 x\u22121\u2211 j=1 P\u03b1j \u2212 y+i\u22121\u2211 j=y P\u03b1j  = \u2212 x+k\u2211 j=x P\u03b1j\nSo ECR (s)\u2212 ECR ( s2 ) \u2264 0 is equivalent to[\nx+k\u2211 i=x C\u03b1i(\u03b5 i\u22121) ] \u00b7 y+\u2211\u0300 j=y P\u03b1j \u2264 y+\u2211\u0300 i=y C\u03b1i(\u03b5 i\u22121)  \u00b7 x+k\u2211 j=x P\u03b1j\nwhich yields the result.\nLemma 6. There exists an optimal troubleshooting sequence s where for each opening index x \u2208 Z, there is a maximal regular subsequence s[x, x+j] (j \u2265 0) that contains the maximizing sequence for cluster K(\u03b1x).\nProof. Let s be an optimal troubleshooting sequence, and let x be an opening index. Let s[x, x + j] be a maximal regular subsequence and assume that it does not contain the maximizing set. Then there exists \u03b1y \u2208 K(\u03b1x) with y > x+ j + 1 such that\nef(\u03b1y) > ef(s[x, x+ j])\nObserve that the subsequence s[x, y \u2212 1] can be partitioned into m > 1, say, maximal regular subsequences s1, . . . , sm with s1 = s[x, x+ j]. By Lemma 5 we have\nef(\u03b1y) > ef(s1) \u2265 ef(s2) \u2265 \u00b7 \u00b7 \u00b7 \u2265 ef(sm) \u2265 ef(\u03b1y)\nwhere the last inequality follows by the fact that \u03b1y is not an opening action (so we avoid \u2265 cef(\u03b1y)). This situation is clearly impossible. Therefore s[x, x + j] must contain the maximizing set. By Lemma 2, it must also contain a maximizing sequence.\nRemark. In the above proof there is a technicality that we did not consider: there might be equality between the efficiency of an action in the maximizing sequence, the efficiency of the maximizing sequence, and one or more free actions. This problem can always be solved by rearranging the actions, and so for all proofs we shall ignore such details for the sake of clarity.\nFinally, we have the following theorem:\nTheorem 2. Algorithm 1 returns an optimal troubleshooting sequence.\nProof. By Lemma 5 we know that an optimal sequence can be partitioned into a sequence of maximal regular subsequences which is sorted by descending efficiency. If we consider Lemma 6 too, then we know that we should open the clusters in order of highest efficiency and perform at least all actions in their maximizing sequences as computed by Lemma 3. By Lemma 2 we know that the order of actions in the maximizing sequences is the optimal one. By Lemma 5 we also know that all free actions \u03b1 with ef(\u03b1) > ef(K) must be performed before opening the cluster, and all free actions with ef(\u03b1) < ef(K) must be performed after opening the cluster and performing all the actions in its maximizing sequence."}, {"heading": "5 THE TREE CLUSTER MODEL", "text": "In this section we shall investigate an extension of the flat cluster model where the clusters can be arranged as a tree. We call such a model for a tree cluster model, and an example is given in Figure 2. In the tree cluster model, the ECR does not admit the simple decomposition of Equation 1. The complication is that several clusters might need to be opened before performing an action in a deeply nested cluster. We therefore call troubleshooting sequences in the tree cluster model for tree troubleshooting sequences. Unfortunately, it is easy to construct examples that show that Algorithm 1 will not yield optimal tree troubleshooting sequences. Therefore, we shall present a new algorithm that solves the tree cluster model in O(n \u00b7 lg n) time.\nFirst we need some additional definitions. The conditional cost C\u03b1(\u03b5) of \u03b1 \u2208 Ki will now depend on how many clusters that have been opened on the path from the root K to Ki. We therefore let AK(Ki |\u03b5) denote the set of ancestor clusters that needs to be opened on the path from the root K to Ki given evidence \u03b5. We then define\nCKi(\u03b5) = \u2211\nK\u2208AK(Ki |\u03b5)\nCK , C\u03b1(\u03b5) = C\u03b1 + CK(\u03b1)(\u03b5)\nGiven this, Definition 1 is still valid for tree troubleshooting sequences.\nA single action is called an atomic action. A compound action consists of opening a cluster K and a sequence of actions in which each action may be either atomic or compound. Note that we shall usually not distinguish syntactically between atomic and compound actions. Also note that a compound action corresponds to a subsequence where the first action is an opening action, and the efficiency of a compound action is simply defined as the efficiency of the corresponding subsequence. If T is a tree cluster model and K is an arbitrary cluster in T , then the subtree model induced by K, denoted TK , is a new tree cluster model containing exactly the clusters in the subtree rooted at K, and with K as the open root cluster. If the induced subtree model is a flat cluster model, we call it a flat subtree model.\nDefinition 5. Let TK = {K,K1, . . . ,K`} be a flat subtree model. Then the absorbtion of K1, . . . ,K` into K is a new cluster K\u2191 containing\n1. for each child cluster Ki, a compound action induced by the maximizing sequence for Ki, and\n2. all remaining actions from K,K1,. . . ,K`.\nNote that in K\u2191 all the actions in a child cluster Ki that are not contained in the newly generated compound action will have a lower efficiency than the compound action for Ki. Definition 6. Let T be a tree cluster model, and let K be any cluster in T . Then TK may be transformed into a single cluster K\u2191 by repeated absorbtion into the root cluster of flat subtree models. The resulting cluster K\u2191 is called the model induced by absorbtion into K. Remark. By construction, the compound actions in a model induced by absorbtion into the root cluster K will only contain actions from the subtrees rooted at a child of K.\nWith these definitions we can now present Algorithm 2. The algorithm works in a bottom-up fashion, basically merging leaf clusters into their parents (absorbtion) until the tree is reduced to a single cluster. Then an optimal sequence is constructed by unfolding compound actions when they are most efficient.\nThe algorithm can be made to run in O(n \u00b7 lg n) time by the following argument. Sort the actions of all clusters in the tree T\u2014this takes at most O(n \u00b7 lg n) time. During absorbtion, it is important to avoid merging all actions of the child clusters into the parent cluster. Instead, we merge only the compound actions into the parent cluster (takes O(` \u00b7 lg n) time overall), and create a priority queue holding the most efficient remaining action of each child cluster. When creating a compound action for a parent cluster, we then\nAlgorithm 2 The bottom-up P-over-C algorithm\nfunction BottomUpPOverC(T ) Input: a cluster tree T with root K Compute the model K\u2191 induced by absorbtion\ninto K (see Definition 6) Let s = \u3008\u3009 while K\u2191 6= \u2205 do\nLet \u03b2 be the most efficient action in K\u2191 if \u03b2 is an atomic action then\nAdd action \u03b2 to s else\nAdd all actions of \u03b2 to s in the order prescribed by \u03b2\nend if Set K\u2191 = K\u2191 \\ {\u03b2}\nend while Return s end function\nuse actions from the priority queue as needed, and update the priority queue whenever an action is taken out. Therefore, creating all the compound actions can never take more than O(n \u00b7 lg `) time. As the absorbtion process moves towards the root, we are forced to merge priority queues from different subtrees. A simple induction argument can establish that it takes at most O(` \u00b7 lg `) time to merge all these priority queues.\nIn the following we shall prove that Algorithm 2 computes an optimal tree troubleshooting sequence. The first two lemmas are minor generalizations of previous lemmas, and the proofs are almost identical.\nLemma 7. Lemma 2 generalizes to tree troubleshooting sequences.\nLemma 8. Lemma 5 generalizes to subsequences of actions that consists of (i) only free actions, or (ii) actions from the same subtree.\nNext we shall investigate the special properties of the compound actions generated by the absorbtion process.\nDefinition 7. Let T be a tree cluster model, and let K be any non-leaf cluster in T . A maximizing compound action \u03b1\u0302 for K in T is defined as any most efficient compound action in the model induced by absorbtion into K. Lemma 9. Let T be a tree cluster model, and let K be any non-leaf cluster in T . Let TK be the subtree model induced by K, and let \u03b1\u0302 be a maximizing compound action for K in T . Then\nef(\u03b1\u0302) \u2265 ef(\u03b2)\nwhere \u03b2 is any possible compound action in TK not including actions from K.\nProof. We proceed by induction. Basis is a flat cluster model T = {K,K1, . . . ,K`} with compound actions \u03b2\u03021, . . . , \u03b2\u0302` of K and \u03b1\u0302 = maxi \u03b2\u0302i. Let \u03b2 be any compound action including actions from clusters in T \\ {K}, and assume that ef(\u03b2) > ef(\u03b1\u0302). We shall use the fact\nn min i Pi Ci \u2264 \u2211n i Pi\u2211n i Ci \u2264 nmax i Pi Ci\n(2)\n(which is also known as Cauchy\u2019s third inequality). Then by Equation 2, \u03b2 cannot be formed by any combination of the \u03b2\u0302i\u2019s as this would not increase the efficiency. Therefore \u03b2 must be formed by either a strict subset or a strict superset of one of the \u03b2\u0302i\u2019s. If \u03b2 is a subset of any \u03b2\u0302i, then the maximality of \u03b2\u0302i leads to a contradiction. If \u03b2 is a superset of any \u03b2\u0302i, then it will include subsets of actions from a set of clusters with subscripts I \u2286 {1, . . . , `}. Let us denote the subsets from each Ki as \u03b2i. We then have\nef(\u03b2) = \u2211 i\u2208I P\u03b2i\u2211 i\u2208I C\u03b2i \u2264 max i\u2208I P\u03b2i C\u03b2i \u2264 max i\u2208{1,...,`} P\u03b2\u0302i C\u03b2\u0302i = ef(\u03b1\u0302)\nwhere the first inequality follows by Equation 2, the second follows by the definition of compound actions formed during absorbtion, and the last equality is by definition of a maximizing compound action. Since the sets \u03b2i were chosen arbitrarily, we get a contradiction. Hence in all cases ef(\u03b1\u0302) \u2265 ef(\u03b2).\nInduction step: we assume the Lemma is true for all children Ki, . . . ,K` of an arbitrary cluster K where the children have maximizing compound actions \u03b2\u03021, . . . , \u03b2\u0302`. A similar argument as above then shows that the lemma is true for K as well.\nLemma 10. Let T be a tree cluster model with root cluster K. Then there exists an optimal tree troubleshooting sequence s that contains (as subsequences) all the compound actions of the model induced by absorbtion into K. Furthermore, the compound actions in s are ordered by descending efficiency.\nProof. Let s = \u3008\u03b11, . . . , \u03b1x, . . . , \u03b1x+k, . . .\u3009 be an optimal tree troubleshooting sequence and let \u03b1x be an opening action, and let s[x, x + k], k \u2265 x be the sequence of maximal length of actions from the same subtree. Let furthermore s[x, x+ k] be the first subsequence that contradicts the lemma, that is, s[x, x+ k] does not contain the compound action \u03b1\u0302 for the cluster K(\u03b1x). Then there exists an atomic action \u03b1y \u2208 \u03b1\u0302 (with y > x + k + 1) such that \u03b1y 6\u2208 s[x, x + k]. We then have\nef(\u03b1y) > ef(\u03b1\u0302) > ef(s[x, x+ k])\nbecause all atomic actions in a compound action are more efficient than the compound action itself, and because \u03b1\u0302 is the most efficient compound action in the\nsubtree rooted at K(\u03b1x) (Lemma 9). We can then partition the actions between \u03b1x+k and \u03b1y into m > 1, say, subsequences (of maximal length) s1, . . . , sm. If one (or more) of these subsequence is more efficient than \u03b1y, we immediately get a contradiction to optimality of s because such a subsequence can be moved before s[x, x + k] (Lemma 8). So we can assume that all the m subsequences are less efficient than \u03b1y. Then by successive application of Lemma 8 we can decrease the ECR by moving \u03b1y to position x + k + 1. However, this again contradicts that s was optimal. Hence s[x, x+ k] must contain \u03b1\u0302.\nBy Lemma 8 it follows that the order of the compound actions must be by descending efficiency.\nTheorem 3. Algorithm 5 returns an optimal troubleshooting sequence.\nProof. By Lemma 10 we only need to establish the order of the free actions between compound actions. By Lemma 8 it follows that any compound action is preceeded by more efficient free actions and followed by less efficient free actions."}, {"heading": "6 CONCLUSION", "text": "We have presented an algorithm, which in O(n \u00b7 lg n) time (n being the number of actions) provides an optimal troubleshooting sequence for scenarios where the cost clusters form a tree and have inside information. This is a useful result on its own, but there is more to it.\nWhen evaluating algorithms for troubleshooting, you must distinguish between off-line and on-line activity. If your task is off-line, the time complexity of your algorithm may not be particularly important as long as the result can be stored easily (like for example an optimal action sequence). However, if the decision support system is flexible, it must allow the user to interact with the recommendations and have the system calculate an optimal next action based on alternative information.\nFurthermore, for many scenarios you will request online calculation of an optimal sequence; for example when the model includes questions and tests. For this kind of scenario, a direct representation of an optimal strategy may require too much space. Therefore, a myopic question heuristic usually relies on optimal sequences of actions calculated on-line.\nFinally, our results imply a major improvement for offline methods like AO\u2217 because the search tree can now be extensively pruned. This is because all subtrees that consist entirely of actions can be replaced with a single sequence of actions."}, {"heading": "7 ACKNOWLEDGEMENTS", "text": "We would like to thank the three anonymous reviewers for their excellent feedback. Thanks also go to Sven Skyum for help with Lemma 3."}], "references": [{"title": "Decision-theoretic troubleshooting", "author": ["D. Heckerman", "J.S. Breese", "K. Rommelse"], "venue": "Communications of the ACM,", "citeRegEx": "Heckerman et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Heckerman et al\\.", "year": 1995}, {"title": "The SACSO methodology for troubleshooting complex systems", "author": ["F.V. Jensen", "U. Kj\u00e6rulff", "B. Kristiansen", "C. Skaanning", "J. Vomlel", "M. Vomlelov\u00e1"], "venue": "Artificial Intelligence for Engineering Design, Analysis and Manufacturing,", "citeRegEx": "Jensen et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Jensen et al\\.", "year": 2001}, {"title": "Optimal strategies for a class of constrained sequential problems", "author": ["J. Kadane", "H. Simon"], "venue": "The Annals of Statistics,", "citeRegEx": "Kadane and Simon.,? \\Q1977\\E", "shortCiteRegEx": "Kadane and Simon.", "year": 1977}, {"title": "A comparison of decision analysis and expert rules for sequential diagnosis", "author": ["J. Kalagnanam", "M. Henrion"], "venue": "In UAI \u201988: Proceedings of the Fourth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Kalagnanam and Henrion.,? \\Q1990\\E", "shortCiteRegEx": "Kalagnanam and Henrion.", "year": 1990}, {"title": "A troubleshooting approach with dependent actions", "author": ["E. Koca", "T. Bilgic"], "venue": "ECAI 2004: 16th European Conference on Artificial Intelligence,", "citeRegEx": "Koca and Bilgic.,? \\Q2004\\E", "shortCiteRegEx": "Koca and Bilgic.", "year": 2004}, {"title": "Heuristics for two extensions of basic troubleshooting", "author": ["H. Langseth", "F.V. Jensen"], "venue": "In Proceedings of the Seventh Scandinavian Conference on Artificial Intelligence,", "citeRegEx": "Langseth and Jensen.,? \\Q2001\\E", "shortCiteRegEx": "Langseth and Jensen.", "year": 2001}, {"title": "Complexity of decision-theoretic troubleshooting", "author": ["M. Vomlelov\u00e1"], "venue": "Int. J. Intell. Syst.,", "citeRegEx": "Vomlelov\u00e1.,? \\Q2003\\E", "shortCiteRegEx": "Vomlelov\u00e1.", "year": 2003}, {"title": "Troubleshooting when action costs are dependent with application to a truck engine", "author": ["H. Warnquist", "M. Nyberg", "P. S\u00e4by"], "venue": "In Proceeding of the Tenth Scandinavian Conference on Artificial Intelligence,", "citeRegEx": "Warnquist et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Warnquist et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 2, "context": "This algorithm is the wellknown \u201dP-over-C\u201d algorithm by (Kadane and Simon, 1977) which was first brought into a troubleshooting context by (Kalagnanam and Henrion, 1990).", "startOffset": 56, "endOffset": 80}, {"referenceID": 3, "context": "This algorithm is the wellknown \u201dP-over-C\u201d algorithm by (Kadane and Simon, 1977) which was first brought into a troubleshooting context by (Kalagnanam and Henrion, 1990).", "startOffset": 139, "endOffset": 169}, {"referenceID": 6, "context": "Furthermore, if any of the above assumptions are relaxed without restrictions, the problem becomes NP-hard (Vomlelov\u00e1, 2003).", "startOffset": 107, "endOffset": 124}, {"referenceID": 4, "context": "Troubleshooting without assumption (b) can also be somewhat simplified due to the dependency set algorithm of (Koca and Bilgic, 2004).", "startOffset": 110, "endOffset": 133}, {"referenceID": 5, "context": "(Langseth and Jensen, 2001) proposed to relax assumption (c) slightly by considering a model where the actions can be partitioned into a flat set of socalled cost clusters (see Figure 1).", "startOffset": 0, "endOffset": 27}, {"referenceID": 7, "context": "(Warnquist et al., 2008) describe a slightly more general cost cluster framework, but they do not address the issue of finding an efficient algorithm.", "startOffset": 0, "endOffset": 24}, {"referenceID": 2, "context": "Theorem 1 (Kadane and Simon (1977)).", "startOffset": 11, "endOffset": 35}, {"referenceID": 1, "context": "Lemma 1 (Jensen et al. (2001)).", "startOffset": 9, "endOffset": 30}, {"referenceID": 3, "context": "This easy computation of the probabilities can be dated back to (Kalagnanam and Henrion, 1990) and (Heckerman et al.", "startOffset": 64, "endOffset": 94}, {"referenceID": 0, "context": "This easy computation of the probabilities can be dated back to (Kalagnanam and Henrion, 1990) and (Heckerman et al., 1995).", "startOffset": 99, "endOffset": 123}, {"referenceID": 5, "context": "The following result is a slightly more informative version of the one from (Langseth and Jensen, 2001): Lemma 3.", "startOffset": 76, "endOffset": 103}, {"referenceID": 5, "context": "Algorithm 1 The extended P-over-C algorithm (Langseth and Jensen, 2001)", "startOffset": 44, "endOffset": 71}], "year": 2010, "abstractText": "Decision theoretical troubleshooting is about minimizing the expected cost of solving a certain problem like repairing a complicated man-made device. In this paper we consider situations where you have to take apart some of the device to get access to certain clusters and actions. Specifically, we investigate troubleshooting with independent actions in a tree of clusters where actions inside a cluster cannot be performed before the cluster is opened. The problem is non-trivial because there is a cost associated with opening and closing a cluster. Troubleshooting with independent actions and no clusters can be solved in O(n \u00b7 lg n) time (n being the number of actions) by the well-known \u201dP-over-C\u201d algorithm due to Kadane and Simon, but an efficient and optimal algorithm for a tree cluster model has not yet been found. In this paper we describe a \u201dbottom-up P-over-C\u201d O(n \u00b7 lg n) time algorithm and show that it is optimal when the clusters do not need to be closed to test whether the actions solved the problem.", "creator": "TeX"}}}