{"id": "1205.2611", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2012", "title": "Ordinal Boltzmann Machines for Collaborative Filtering", "abstract": "Collaborative filtering is an effective recommendation technique wherein the preference of an individual can potentially be predicted based on preferences of other members. Early algorithms often relied on the strong locality in the preference data, that is, it is enough to predict preference of a user on a particular item based on a small subset of other users with similar tastes or of other items with similar properties. More recently, dimensionality reduction techniques have proved to be equally competitive, and these are based on the co-occurrence patterns rather than locality. This paper explores and extends a probabilistic model known as Boltzmann Machine for collaborative filtering tasks. It seamlessly integrates both the similarity and co-occurrence in a principled manner. In particular, we study parameterisation options to deal with the ordinal nature of the preferences, and propose a joint modelling of both the user-based and item-based processes. Experiments on moderate and large-scale movie recommendation show that our framework rivals existing well-known methods.", "histories": [["v1", "Wed, 9 May 2012 18:35:35 GMT  (255kb)", "http://arxiv.org/abs/1205.2611v1", "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)", "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["tran the truyen", "dinh q phung", "svetha venkatesh"], "accepted": false, "id": "1205.2611"}, "pdf": {"name": "1205.2611.pdf", "metadata": {"source": "CRF", "title": "Ordinal Boltzmann Machines for Collaborative Filtering", "authors": ["Tran The Truyen", "Dinh Q. Phung", "Svetha Venkatesh"], "emails": ["t.tran2@curtin.edu.au", "d.phung@curtin.edu.au", "s.venkatesh@curtin.edu.au"], "sections": [{"heading": null, "text": "Collaborative ltering is an e ective recommendation technique wherein the preference of an individual can potentially be predicted based on preferences of other members. Early algorithms often relied on the strong locality in the preference data, that is, it is enough to predict preference of a user on a particular item based on a small subset of other users with similar tastes or of other items with similar properties. More recently, dimensionality reduction techniques have proved to be equally competitive, and these are based on the co-occurrence patterns rather than locality. This paper explores and extends a probabilistic model known as Boltzmann Machine for collaborative ltering tasks. It seamlessly integrates both the similarity and cooccurrence in a principled manner. In particular, we study parameterisation options to deal with the ordinal nature of the preferences, and propose a joint modelling of both the user-based and item-based processes. Experiments on moderate and large-scale movie recommendation show that our framework rivals existing well-known methods."}, {"heading": "1 INTRODUCTION", "text": "Collaborative ltering is based on the idea that we can predict preference of an user on unseen items by using preferences already expressed by the user and others. For example, if we want to predict how much the user likes a particular movie we may look for similar users who have rated the movie before (Resnick et al., 1994). Alternatively, the rating for this new movie can be based on ratings of other similar movies that the user has watched (Sarwar et al., 2001). This similarity-based approach relies on the strong local-\nity in the neighbourhood of highly correlated users or items. More recent development has suggested that dimensionality reduction techniques like SVD (Salakhutdinov et al., 2007), PLSA (Hofmann, 2004) and LDA (Marlin, 2004) are also competitive. The idea is to assume a low dimensional representation of rating data, which, once learnt, can be used to generate unseen ratings. Unlike the similarity-based approach, this does not assume any locality in the data.\nIn this paper, we take the view that these approaches are complementary and they address di erent aspects of the user's preferences. Speci cally, we explore the application of an undirected graphical model known as Boltzmann Machines (BMs) (Ackley et al., 1985) for the problem. The strength of BMs comes from the capacity to integrate the latent aspects of user's preferences as well as the correlation between items and between users. The undirected nature of the model allows exible encoding of data, and at the same time, it supports inference and learning in an principled manner. For example, the model supports missing ratings and joint predictions for a set of items and users. It provides some measure of con dence in each prediction made, making it easy to assess the nature of recommendation and rank results. With the hidden variables we can project user's preferences and item ratings onto a latent low dimensional space for further processing. Note that its probabilistic integration di ers from the current practice of blending multiple independent models (Koren, 2008).\nImportantly, we go beyond the standard BMs in a number of ways. Firstly, we explore various parameterisations to deal with the ordinal nature of ratings (e.g. if the true rating is 3 stars in a 5-star scale, then predicting 4 stars is preferred to predicting 5 stars). The standard discrete graphical models, on the other hand, count both the predictions as errors. One way to deal with this issue is to approximate them by continuous variables as done in (Hofmann, 2004) but this is only meaningful for numerical ratings. Secondly,\nprevious BMs generally assume that each subset of observational variables are generated from an hidden process of the same type, and the data comes with a set of i.i.d instances. In collaborative ltering, on the other hand, it is much more plausible to assume that observed ratings are co-generated by both the userbased and item-based processes. As a result, the data instances are no longer independently and identically distributed. To deal with this, we propose to integrate data instances into a single BM, in which, every rating is associated with both the user-based and itembased processes. Further, this paper studies approximate learning strategies for large BMs, including Contrastive Divergence (Hinton, 2002) (CD), a structural extension to Pseudo-Likelihood (Besag, 1975) (PL), and the combination of CD and PL for the joint model."}, {"heading": "2 USER-CENTRIC MODELLING", "text": "Denote by U = {1, 2, . . . ,M} the set of M users, and I = {1, 2, . . . ,K} the set of K items in the recommendation system of interest. Let us further denote byS the set of values a user can rate (e.g., S = {1, 2, 3, 4, 5} in the discrete case or S = [0, 1] in the continuous case). We use u throughout this paper to index the user and i to index the item. Let I(u) be the set of indices of items rated by user u. Typically, the size of I(u) is much smaller than the total number of items in the database (i.e. |I(u)| K) because each user usually votes for only a small subset of items.\nIn this section, we rst present probabilistic modelling from a single user perspective using Boltzmann machines (BMs). A user-centric BM in our view is an undirected graphical model representing user information and the set of associated rated items. A graphical\nmodel representation is shown in Fig. 1. There are two components in the model:\n\u2022 a hidden layer to capture the latent aspects of a user modelled by a d-dim binary random vector variable h = (h1, h2, ..., hd), and\n\u2022 a visible layer representing ratings on di erent items observed for this user, captured by a random vector r(u) = (ri)i\u2208I(u) . Each element variable ri receives values in the set S.\nFor the sake of understanding, we consider here discrete ratings where S is a nite discrete set and leave the case of continuous-valued ratings to the Appendix A.2. For clarity, we will drop explicit mention of user index u and the membership relation i \u2208 I(u) and reinstate them whenever confusion may arise.\nIn the extreme view, the user-centric model should have represented both rated and non-rated items, treating all non-rated items as hidden variables at the bottom layer. However, since we do not have the knowledge of which items the user will rate in the future while the number of items is typically large (at the scale of millions in real-world scenarios), it will be impractical to include all the unknown ratings into the model. Our strategy is to limit to only known ratings at training time and gradually introduce an additional unknown rating at the prediction time as an unobserved variable subject to be inferred.\nTo parameterise our model, we rst consider two additional kinds of features extracted from the set of ratings: for each rating ri we extract a vector of features {fa(ri)}Aa=1, and for each rating pair{ri, rj} a feature vector {fb(ri, rj)}Bb=1. While fa(ri) captures some intrinsic property of the item i and the rating ri, fb(ri, rj) encodes correlation between the two item i, j and their corresponding ratings. Four types of parameters are introduced (c.f. Fig. 1): each hidden unit hk is parameterised with \u03b1k, each feature fa (ri) at the rating ri with \u03b2ia, each pair (hk, fa (ri)) with \u03b3kia, and each item-to-item correlation feature fb (ri, rj) with \u03bbijb. For the user u, the model state negative energy is now ready to be de ned as\n\u2212E(u)(h, r) =  \u2211 1\u2264k\u2264d \u03b1khk + \u2211 i\u2208I(u),a \u03b2iafa(ri) + \u2211 i\u2208I(u),k,a \u03b3ikahkfa(ri)\n+ \u2211 i,j\u2208I(u);i 6=j \u2211 b \u03bbijbfb(ri, rj)\nwhere \u03b1k, \u03b2ia, \u03b3ika and \u03bbijb are model parameters which are shared among users as shown to be outside the plate in Fig.1 . Finally, the user-centric model distribution follows\nP (u)(h, r) = 1\nZ(u) exp{\u2212E(u)(h, r)} (1)\nwhere Z(u) = \u2211\nh,r exp{\u2212E(u)(h, r)} is the normalising constant. Denote by hk,1 the assignment hk = 1. The conditional distributions are (again we drop user index u)\nP (hk,1 | r) = [ 1 + exp { \u2212\u03b1k \u2212\n\u2211 ia \u03b3ikafa(ri) }]\u22121 P (ri|r\u00aci,h) \u221d exp {I (ri,h) + J (ri, r\u00aci)}\nwhere r\u00aci denote the set of ratings by the same user u other than ri, and\nI (ri,h) = \u2211 a \u03b2iafa(ri) + \u2211 ka \u03b3ikafa(ri)hk\nJ (ri, r\u00aci) = \u2211 j 6=i \u2211 b \u03bbijbfb(ri, rj)\nFor the purpose of dimensionality reduction we can use the vector {P (hk,1|r)}dk=1 as a continuous representation of the user's preference."}, {"heading": "2.1 ORDINAL FEATURES", "text": "In this paper we consider the case where user preferences are expressed in term of ordinal ratings, i.e., the set of rating values S is a set of n ordinal values, and let us denote it by S = {R1, R2, ...Rn}. A straightforward approach is to simply ignore the ordinal property and treat the ratings as categorical variables. In particular, the input bias feature can simply be an identity function fs(ri) = I[ri \u2261 Rs], and the correlation feature can be treated as the similarity between the two neighbour ratings fb(ri, rj) = I[ri \u2261 rj ]. Another way is to treat them as numerical values, for example, as random Gaussian variables (after appropriate preprocessing, see Appendix A.2 for a detailed treatment). However the shortcoming is that this treatment is only meaningful when such a numerical interpretation exists.\nA better way is to exploit the ordering property: if the true rating by the user u on item i is ri = Rs, then we would want to predict the rating as close to Rs as possible. Denote by Rs\u2032 Rs\u2032+1 the preference of Rs\u2032 to Rs\u2032+1, the ordering of preferences when the true rating is Rs can be expressed as\nRs Rs\u22121.... R1 Rs Rs+1... Rn\nIt is essential to design features {fa(ri)}Aa=1 to capture the information induced from these expressions. As Rs split the set S into two subsets, we create one set of features corresponding to s\u2032 < s and another set corresponding to s\u201d > s, i.e. fdowns\u2032 (Rs) = (s \u2032 \u2212 s)I[s\u2032 < s]\nand fups\u201d (Rs) = (s\u201d \u2212 s)I[s\u201d > s], respectively, where I[.] is the indicator function. For correlation between two items (i, j), we can measure the distance between two corresponding ratings ri = Rs and rj = Rs\u2032 by user u, i.e. fb(ri, rj) = |s\u2032 \u2212 s|."}, {"heading": "2.2 LEARNING", "text": "Training data consists of rating values for input variables. Let us denote these evidences per user u as r\u0304(u), to distinguish from the unspeci ed r(u). Standard maximum likelihood learning maximises L =\u2211 u\u2208U L(r\u0304(u)), where L(r\u0304(u)) = logP (u)(r\u0304(u)). Let us drop the index u for clarity and take the gradient with respect to model parameters yielding\n\u2202L(r\u0304) \u2202\u03b1k = P (hk,1|r\u0304)\u2212 P (hk,1) \u2202L(r\u0304) \u2202\u03b2ia = fa(r\u0304i)\u2212 \u2211 ri P (ri)fa(ri) \u2202L(r\u0304) \u2202\u03b3ika = P (hk,1|r\u0304)fa(r\u0304i)\u2212 \u2211 ri P (ri, hk,1)fa(ri) \u2202L(r\u0304) \u2202\u03bbijb = fb(r\u0304i, r\u0304j)\u2212 \u2211 ri,rj P (ri, rj)fb(ri, rj)\nGenerally, these gradients cannot be evaluated exactly. One method is to use Gibbs sampling to approximate the gradients. However, unbiased Gibbs sampling may take too much time to converge. We follow a sampling strategy called Contrastive-Divergence (CD) (Hinton, 2002), in that we start the sampling from the data distribution, and stop the random walks after a few steps. This certainly introduces bias, but it is enough to relax the distribution toward the true distribution, and more importantly, it is very e cient.\nAnother method is to utilise Pseudo-likelihood (PL) (Besag, 1975), and we approximate the model loglikelihood by\nLPL(r\u0304) = \u2211 i\u2208I(u) logP (r\u0304i|r\u0304\u00aci)\nNote that in the original PL, there are no hidden variables, thus computing the local conditional distribution P (r\u0304i|r\u0304\u00aci) is easy. In our case, the pseudolikelihood and its gradient can also be computed exactly and e ciently but the derivations are rather involved, and we leave the details in the Appendix A.1."}, {"heading": "2.3 RATING PREDICTION", "text": "Once trained, the BMs can be used for predicting the preference of a user. Recall that unseen items are not\nmodelled during training but will be added as an additional, unobserved node in the visible layer during testing1. The prediction on new item j /\u2208 I(u) is based on the MAP assignment2\nr\u2217j = arg max rj P (rj |r\u0304)\nwhere P (r\u2217j |r\u0304) is the measure of prediction con dence. Given r\u0304, the model structure is reduced to a tree with the root rj and leaves {hk}dk=1. Thus r\u2217j can be evaluated in linear time. However, the computation is still expensive for online deployment. Here we propose to use a cheaper method, which is based on mean- eld approximation:\nP (rj ,h|r\u0304) \u2248 Q(rj |r\u0304) \u220f k Q(hk|r\u0304)\nFor simplicity, we x Q(hk|r\u0304) = P (hk|r\u0304) based on the idea that previous information is rich enough to shape the distribution Q(hk|r\u0304). Minimizing the KullbackLeibler divergence between P (rj ,h|r\u0304) and its approximation, we obtain Q(rj |r\u0304) \u221d exp(\u2212EQ(rj , r\u0304)), where\nEQ(rj , r\u0304) =  \u2212\u2211a \u03b2jafa(rj) \u2212\u2211k P (hk,1|r\u0304)\u2211a \u03b3jkafa(rj) \u2212\u2211i\u2208I(u),b \u03bbijbfb(r\u0304i, rj) (2)\nThis is equivalent to replacing the hard hidden assignment hk \u2208 {0, 1} by a soft values P (hk,1|r\u0304) \u2208 [0, 1]. Finally, using Q(rj |r\u0304) in place of P (rj |r\u0304), the prediction is simpli ed as r\u2217j = arg minrj EQ(rj , r\u0304).\nNote that this mean- eld approximation has the same linear complexity as the standard MAP, but it is numerically faster because the mathematical expression is more computationally primitive."}, {"heading": "2.4 ITEM RANKING", "text": "In a recommendation system we are often interested in composing a recommendation list of items for each user. This is essentially a ranking problem, in that for a given set of candidate items, we need to provide a numerical score for each item and choose a top ranked items. In our BMs framework, adding a new item j to the model will approximately reduce the model state energy by an amount of EQ(rj , r\u0304) (de ned in Equation 2). Recall that the user likelihood in Equation 1\n1It may appear that adding new item can make the user model unspeci ed, but in fact, the item is already in the models of other users and its related parameters have been learnt.\n2Alternatively, we can take the expected rating as the prediction r\u2217j = \u2211 rj P (rj |r\u0304)rj .\nimproves if the model state energy decreases, thus motivating us to use the EQ(rj , r\u0304) as the ranking score. Since we do not know exactly the state rj , we resort to the (approximate) expected energy decrease instead \u2206Ej = \u2211 rj Q(rj |r\u0304)EQ(rj , r\u0304)."}, {"heading": "3 JOINT MODELLING OF USERS", "text": "AND ITEMS\nIn the previous section, we have assumed that ratings are generated by some user-centric process. Since users and items play an equal role in the data, we can alternatively assume that there exists some itemcentric process that generates ratings. Thus we can alternatively model the ratings observed for each item instead of user in a manner similar to Section 2. The more plausible assumption, however, is that a rating is co-generated by both the user-centric and item-centric processes. This can be realised by combining these two modelling approaches into a single uni ed BM, as depicted in Figure 2.\nMore speci cally, every user and item is modelled with its own hidden layer. Let d\u2032 be the dimensionality of the hidden variables associated with items, there are Md+Kd\u2032 hidden nodes in the joint model (every rating is associated with two hidden layers, one per the user and one per the item). The number of input nodes is the number of ratings in the whole database. Each input node corresponding to user u and item i is possibly connected to |I(u)|+ |U (i)|\u22122 other input nodes, where U (i) denotes the set of all users who rate item i. Thus, the resulting BM is a probabilistic database that supports various inference tasks.\nDenote by r and h respectively the set of all input variables (i.e., observed ratings) and all hidden variables of the entire model. The energy of the entire system is\nE(r,h) = \u2211 u\u2208U E(u)(r(u),h(u)) + \u2211 i\u2208I E(i)(r(i),h(i))\nwhere\n\u2212E(i)(r(i),h(i)) =  \u2211 k \u03b8khk + \u2211 u\u2208U(i),a \u03b7uafa(ru) + \u2211 u\u2208U(i),k,a \u03bdukahkfa(ru)\n+ \u2211 u,v\u2208U(i);u6=v \u2211 b \u03c9uvbfb(ru, rv)\nwhere \u03b8, \u03b7, \u03bd, \u03c9 are respective item-centric model parameters that play similar roles to \u03b1, \u03b2, \u03b3, \u03bb in usercentric models.\nLet r\u0304 denote all assigned rating values in the training data. Since the model structure is complex, we look for decomposition to simplify computation. As ratings can be decomposed by either user indices or item indices, we appeal to structured pseudo-likelihood learning where we try to maximise the log pseudo-likelihood instead3:\nLPL(r\u0304) = 1 2 (\u2211 u\u2208U logP (r\u0304(u)|r\u0304\u00acu)+ \u2211 i\u2208I logP (r\u0304(i)|r\u0304\u00aci) )\nThis objective function has a nice property that parameters associated with users and items are separated in corresponding components. Naturally, it suggests an alternating parameter updating strategy. Let us consider P (r\u0304(u) | r\u0304\u00acu). Using the Markov property, r\u0304\u00acu reduces to ratings by all neighbours of user u. Since each item rated by user u has its own hidden variables and integrating out these variables in standard likelihood learning may be expensive (although feasible), we further propose a mean- eld approximation approach, similar to that described in Section 2.3. More speci cally, when we update parameter associated with user u, we considered the hidden layer for item i observed with value {P (h(i)k\u2032,1|r\u0304(i))}d \u2032\nk\u2032=1. The learning now reduces to that described in Section 2.2. The overall algorithm can be summarised as follows\n\u2022 Loop until stopping criteria met:\nUse {P (h(i)k\u2032,1|r\u0304(i))}d \u2032\nk\u2032=1 as hidden values per item i, for all i \u2208 I. Fix item models parameters, update user model parameters by maximising \u2211 u\u2208U logP (r\u0304\n(u)|r\u0304\u00acu). Use {P (h(u)k,1|r\u0304(u))}dk=1 as hidden values per user u, for all u \u2208 U . Fix user model parameters, update item model parameters by maximising \u2211 i\u2208I logP (r\u0304\n(i)|r\u0304\u00aci). 3Note that there is a single distribution P (r,h) for the\nwhole data.\nIn the testing phase, we introduce a single node ruj to the model and compute r\u2217uj = arg maxruj P (ruj |r\u0304), which can be simpli ed further by noting that P (ruj |r\u0304) = P (ruj |r\u0304(u), r\u0304(j)). We can also make use of the mean- eld approximation similar to that in Section 2.3. More speci cally, we make use of all the conditional distributions of hidden variables {P (h(i)k\u2032,1|r\u0304(i))}d \u2032 k\u2032=1 for each item i and {P (h(u)k,1|r\u0304(u))}dk=1 for each user u, then compute the energy decrease as\nEQ(ruj , r\u0304) =  \u2212\u2211a \u03b2jafa(ruj)\u2212\u2211a \u03b7uafa(ru) \u2212\u2211k P (h(u)k,1|r\u0304(u))\u2211a \u03b3jkafa(ruj) \u2212\u2211i\u2208I(u),b \u03bbijbfb(r\u0304i, rj) \u2212\u2211k P (h(j)k,1|r\u0304(j))\u2211a \u03bdukafa(ru) \u2212\u2211v\u2208U(j) \u2211b \u03c9uvbfb(r\u0304u, rv)"}, {"heading": "4 EVALUATION", "text": ""}, {"heading": "4.1 SETTING", "text": "We evaluate the proposed Ordinal BMs on two movie rating datasets. The rst moderate dataset comes from the MovieLens project4, consisting of 6040 users, 3043 items and approximately 1 million ratings. The second larger dataset is extracted from the Net ix challenge5 in that the rst 3000 items are used, resulting in 208, 332 users, and 13.6 million ratings6. Ratings are integers in the 5-star scale. The two datasets include only those users who have rated more than 20 movies, and those movies rated by more than 20 users. For each user, roughly 80% of ratings is used for training and the rest is for evaluation.\nWe implement three variants of the BMs: the categorical, the ordinal and the Gaussian. For the Gaussian BMs, we need to normalise the ratings to obtain random numbers following the standard normal distribution N (0; 1). To determine the connectivity at the input layers, we rst compute the Pearson correlation between user pairs and item pairs as in standard similarity-based methods (e.g. see (Sarwar et al., 2001)), and keep only positively correlated pairs. Then, for each user/item we choose the top 100 similar users/items to be his/its neighbourhood, ranked by the Peason correlation. The BMs results reported here are based on one-step CD learning as it is empirically faster than the pseudo-likelihood method without much di erence in performance. Models are trained in an online fashion with block size of 100, learning rate\n4http://www.grouplens.org 5http://net ixprize.com 6This subset, although smaller than the original 100 millions set, is still larger than the largest non-commercial dataset current available from the MovieLens project.\nof 0.1. Parameters associated with hidden variables are initialised by a random Gaussian N (0; 0.01)."}, {"heading": "4.2 RATING PREDICTION", "text": "In the rst set of experiments, we measure the performance of BM models on the rating prediction task (Section 2.3). For comparison, we implement the Singular Value Decomposition (SVD) for incomplete data (see, for example, (Salakhutdinov et al., 2007) for a description). The SVD is currently one of the best methods for movie prediction7. The evaluation criterion is based on the popular Mean Absolute Error (MAE) measure, i.e. MAE= \u2211J j=1 |r\u2217j \u2212 r\u0304j |/J .\nFigure 3 shows the learning curves of BMs variants in comparison with the SVD, all evaluated on the 1M MovieLens dataset. The size of BM hidden layers and the rank of SVD are xed at 20. The gure clearly demonstrates the positive e ect of joint modelling, as well as of the integration of the dimensionality reduction and correlation. More importantly, the resultant model outperforms the SVD.\nTo investigate the role of hidden variables, we x the number of iterations to 20 and run BMs variants under di erent hidden sizes without the correlation in the input layer, and the results are reported in Figure 4. Generally the performance (except for the categorical BMs) increases as more hidden units are introduced, but at a slow rate after 30 units.\nThe Net ix subset is characteristically di erent from the MovieLens dataset, in that there are far more users than items, thus it is not practical to include correlations between users (the number of correlation param-\n7It appears that all leaders in the Net ix competition use some forms of SVD.\neters is M2, where M is number of users). The results are reported in Table 1, which once again demonstrate the advantage of the proposed Ordinal BMs."}, {"heading": "4.3 ITEM RANKING", "text": "In the second set of experiments, we evaluate the Ordinal BMs for the item ranking task (Section 2.4). Recall that we rst need a set of candidate items for each user. Here we use the Pearson similarity between users, that is, for each user u, we select 50 most similar users and then collect the items those users have previously rated. These items, except for those previously rated by user u, are the candidates. For comparison, we evaluate the Ordinal BMs against a baseline popularity method, in which importance of a candidate is based on the number of times it is rated by the neighbour users. Methods are tested on the MovieLens dataset only since the Net ix data is not suitable for computing user-based correlations. The evaluation criteria\nincludes the standard recall/precision measures, and the ranking utility adapted from (Breese et al., 1998). The utility is based on the assumption that the value of a recommendation, if it interests a user, is reduced exponentially with its position down the list. More speci cally, for all recommended items that appear in the test set for user u, the ranking utility is computed as \u03c0u = \u2211 p 2 \u2212(p\u22121)/(\u03b1\u22121), where p is the position of the item in the recommendation list, and \u03b1 > 0 is the interest `half-life'. The overall ranking utility is then computed as\n\u03c0 = 100 \u2211 u \u03c0u\u2211\nu \u03c0 max u where \u03c0maxu = \u2211Tu p\u2032=1 2\n\u2212(p\u2032\u22121)/(\u03b1\u22121) with Tu be the size of the test set for user u. As suggested in (Breese et al., 1998), we choose \u03b1 = 5. Figure 5 depicts the performance of the joint Ordinal BM, which clearly shows its competitiveness against the baseline. Hidden variables seem to play little role in this kind of inference, hence we report only result of model with input correlations and leave the issue for future investigation."}, {"heading": "5 RELATED WORK", "text": "The Boltzmann Machines explored in this paper are more general that the original proposal in (Ackley et al., 1985) due to the use of general exponential family instead of binary variables, in the same way that the Harmoniums (Welling et al., 2005) generalises the Restricted BMs (e.g. see (Salakhutdinov et al., 2007)). The work in (Salakhutdinov et al., 2007) applies Restricted BMs for collaborative ltering but it is limited to individual modelling of users and categorical variables.\nOther graphical models have been employed for collaborative ltering in a number of places, including Bayesian networks (Breese et al., 1998) and dependency networks (Heckerman et al., 2001). The BMs di er from Bayesian networks in that BMs are undirected models which Bayesian networks are directed.\nOur method resembles dependency networks when pseudo-likelihood (Besag, 1975) learning is employed and no hidden variables are modelled, but dependency networks are generally inconsistent.\nThe dimensionality reduction capacity of the BMs is shared by other probabilistic models, including mixture models, probabilistic latent semantic analysis (PLSA) (Hofmann, 2004) and latent Dirichlet allocation (LDA) (Marlin, 2004). These are all directed graphical models while the BMs are undirected. Machine learning (Billsus and Pazzani, 1998; Basu et al., 1998; Basilico and Hofmann, 2004) has also been successfully applied to the collaborative ltering problem. The method maps the recommendation into a classi - cation problem that existing classi ers can solve. The map typically considers each user or each item as an independent problem, and ratings are training instances."}, {"heading": "6 CONCLUSION", "text": "We have presented Boltzmann machines for collaborative ltering tasks. BMs are an expressive framework to incorporate various aspects of the data, including the low dimensional representation of item/user pro les and the correlation between items/users. We study parameterisations for handling the ordinal nature of ratings, and propose the integration of multiple BMs for joint modelling of user-based and item-based processes. We empirically shown that BMs are competitive in the movie recommendation problem.\nThis work can be furthered in a number of ways. First we need to handle incremental parameter updating when new users or items are available. The second issue is learning the structure of the BMs, including determining the number of hidden units, and and connectivity in the input layer. And third, the model should be extended to incorporate external information like user pro les and item contents."}, {"heading": "A APPENDIX", "text": "A.1 PSEUDO-LIKELIHOOD FOR THE\nDISCRETE BMs\nDenote by\n\u03c6k(hk) = exp{\u03b1khk} \u03c6i(ri) = exp{ \u2211 a \u03b2iafa(ri)}\n\u03c8ik(hk, ri) = exp{ \u2211 a \u03b3ikahkfa(ri)}\n\u03c8ij(ri, rj) = exp{ \u2211 b \u03bbijbfb(ri, rj)}\nLet us de ne the joint potential of the system \u03a6(h, r) as[\u220f\nk\n\u03c6k(hk) ][\u220f i \u03c6i(ri) ][\u220f i,k \u03c8ik(hk, ri) ][\u220f i,j \u03c8ij(ri, rj) ]\nIn pseudo-likelihood (PL) learning we need to optimise the following objective function\nLPL(r\u0304) = \u2211 i logP (r\u0304i|r\u0304\u00aci)\nwhere P (r\u0304i|r\u0304\u00aci) = \u2211\nh \u03a6(r\u0304i, r\u0304\u00aci,h)\u2211 ri \u2211 h \u03a6(ri, r\u0304\u00aci,h) = Z(r\u0304i|r\u0304\u00aci) Z(r\u0304\u00aci)\nwhere Z(ri|r\u0304\u00aci) = \u2211\nh \u03a6(ri, r\u0304\u00aci,h) and Z(r\u0304\u00aci) =\u2211 ri Z(ri|r\u0304\u00aci). Expanding Z(ri|r\u0304\u00aci) and note that all potentials associated with hk = 0 become 1, we obtain\nZ(ri|r\u0304\u00aci) = \u03c6i(ri) \u220f j 6=i \u03c8ij(ri, r\u0304j)\u00d7\n\u00d7 [\u220f k ( 1 + \u03c6k(hk,1) \u03c8ik(hk,1, ri) \u03c8ik(hk,1, r\u0304i) \u220f j \u03c8jk(hk,1, r\u0304j) )]\nThus we can compute all the Z(ri|r\u0304\u00aci) in O(|S|dNu2) time for all items rated by the user u.\nNow we come to the gradient of the pseudo-likelihood\n\u2202LPL(r\u0304) = \u2211 i\n( \u2202 logZ(r\u0304i|r\u0304\u00aci)\u2212 \u2202 logZ(r\u0304\u00aci) ) (3)\nRecall that Z(r\u0304\u00aci) = \u2211 ri Z(ri|r\u0304\u00aci), we have\n\u2202 logZ(r\u0304\u00aci) = 1\nZ(r\u0304\u00aci) \u2211 ri \u2202Z(ri|r\u0304\u00aci)\n= 1\nZ(r\u0304\u00aci) \u2211 ri Z(ri|r\u0304\u00aci)\u2202 logZ(ri|r\u0304\u00aci)\n= \u2211 ri P (ri|r\u0304\u00aci)\u2202 logZ(ri|r\u0304\u00aci)\nThus Eq.3 reduces to \u2202LPL(r\u0304) = \u2211 i (\u2211 ri {I[ri = r\u0304i]\u2212 P (ri|r\u0304\u00aci)}\u2202 logZ(ri|r\u0304\u00aci) )\n= \u2211 i (\u2211 ri D(ri|r\u0304\u00aci)\u2202 logZ(ri|r\u0304\u00aci) )\nwhere I[.] is an identity function and D(ri|r\u0304\u00aci) = I[ri = r\u0304i]\u2212 P (ri|r\u0304\u00aci). Let us consider \u2202 logZ(ri|r\u0304\u00aci). It is known that \u2202 logZ(ri|r\u0304\u00aci)\n\u2202\u03b1k = P (hk,1|ri, r\u0304\u00aci)\n\u2202 logZ(ri|r\u0304\u00aci) \u2202\u03b2ja = fa(ri)I[i = j]\n\u2202 logZ(ri|r\u0304\u00aci) \u2202\u03b3jka = { P (hk,1|ri, r\u0304\u00aci)fa(ri) for i = j P (hk,1|ri, r\u0304\u00aci)fa(r\u0304j) for i 6= j\nwhere P (hk,1|ri, r\u0304\u00aci) is \u03c6k(hk,1)\u03c8ik(hk,1, ri) \u220f j \u03c8jk(hk,1, r\u0304j)\n\u03c8ik(hk,1, r\u0304i) + \u03c6k(hk,1)\u03c8ik(hk,1, ri) \u220f j \u03c8jk(hk,1, r\u0304j)\nFinally, we need to sum over all the visible nodes as in Eq.3\n\u2202LPL(r\u0304) \u2202\u03b1k = \u2211 i \u2211 ri D(ri|r\u0304\u00aci)P (hk,1|ri, r\u0304\u00aci) \u2202LPL(r\u0304) \u2202\u03b2ja = \u2211 rj D(rj |r\u0304\u00acj)fa(rj)\n\u2202LPL(r\u0304) \u2202\u03b3jka =\n{\u2211 rj D(rj |r\u0304\u00acj)P (hk|rj , r\u0304\u00acj)\u2206fa(rj)\n+fa(r\u0304j) \u2202L(r\u0304) \u2202\u03b1k\nwhere \u2206fa(rj) = fa(rj)\u2212 fa(r\u0304j).\nA.2 BMs WITH GAUSSIAN RATINGS\nSince ratings are sometimes provided in a numerical scale, they can be approximated by continuous variables, as suggested in (Hofmann, 2004). The energy of the system is given as\nE(h, r) = { \u2212\u2211k \u03b1khk \u2212\u2211i,k \u03b3ikrihk + \u2211 i r2i 2 \u2212 \u2211 i \u03b2iri \u2212 \u2211 i,j 6=i \u03bbijrirj\nHere we assume that P (ri|r\u00aci, h) = N (\u00b5i; 1), where \u00b5i = \u03b2i + \u2211 k \u03b3ikhk + \u2211 j 6=i \u03bbijrj . Again, Gibbs sampling can be used for evaluating log-likelihood gradients in learning. In predicting new ratings, we can apply the mean- eld approximation strategy described in Section 2.3, and compute the mode of the normal distribution P (rj |r\u0304,h), which is simply \u00b5j\n\u00b5j = \u03b2j + \u2211 k \u03b3jkP (hk,1|r\u0304) + \u2211 i \u03bbij r\u0304i\nMean- eld approximation to PL learning:\nRecall that the PL learning requires the conditional distribution P (ri|r\u0304\u00aci), which is not Gaussian, making evaluation di cult. To turn it into a Gaussian, we can apply the mean- eld approximation\nP (ri|r\u0304\u00aci) = \u2211 h P (ri,h|r\u0304\u00aci)\n\u2248 Q(ri|r\u0304\u00aci) \u2211 h \u220f k Q(hk|r\u0304\u00aci)\nFurther approximation Q(hk|r\u0304\u00aci) \u2248 P (hk|r\u0304) gives Q(ri|r\u0304\u00aci) \u221d\nexp ( \u2212 r 2 i\n2 + \u03b2iri + \u2211 k P (hk,1|r\u0304)\u03b3ikri + \u2211 j 6=i \u03bbijrir\u0304j ) Thus Q(ri|r\u0304\u00aci) is a Gaussian with mean \u00b5i = \u03b2i +\u2211 k P (hk|r\u0304)\u03b3ik + \u2211 j 6=i \u03bbij r\u0304j .\nSince the mean of a Gaussian is also its mode, PL learning can be approximately carried out by minimising the reconstruction error\nE = 1 2 \u2211 i (r\u0304i \u2212 \u00b5i)2\nLet i = r\u0304i \u2212 \u00b5i. The gradients are \u2202E \u2202\u03b2i\n= \u2212 i \u2202E \u2202\u03b1k = \u2212P (hk,1|r\u0304) \u2211 i i\u03b3ik \u2202E \u2202\u03b3ik = \u2212P (hk,1|r\u0304) ( i + P (hk,1|r\u0304)ri \u2211 j j\u03b3jk )\n= \u2212P (hk,1|r\u0304) ( i \u2212 ri\n\u2202E \u2202hk,1 ) \u2202E \u2202\u03bbij = \u2212 ir\u0304j \u2212 j r\u0304i"}], "references": [{"title": "A learning algorithm for Boltzmann machines", "author": ["D. Ackley", "G. Hinton", "T. Sejnowski"], "venue": "Cognitive Science,", "citeRegEx": "Ackley et al\\.,? \\Q1985\\E", "shortCiteRegEx": "Ackley et al\\.", "year": 1985}, {"title": "Unifying collaborative and content-based ltering", "author": ["J. Basilico", "T. Hofmann"], "venue": "In Proceedings of the 21st International Conference on Machine learning (ICML),", "citeRegEx": "Basilico and Hofmann,? \\Q2004\\E", "shortCiteRegEx": "Basilico and Hofmann", "year": 2004}, {"title": "Recommendation as classi cation: Using social and content-based information in recommendation", "author": ["C. Basu", "H. Hirsh", "W. Cohen"], "venue": "In Proceedings of the 15th National Conference on Arti cial Intelligence (AAAI),", "citeRegEx": "Basu et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Basu et al\\.", "year": 1998}, {"title": "Statistical analysis of non-lattice data", "author": ["J. Besag"], "venue": "The Statistician, 24(3),", "citeRegEx": "Besag,? \\Q1975\\E", "shortCiteRegEx": "Besag", "year": 1975}, {"title": "Learning collaborative information lters", "author": ["D. Billsus", "M. Pazzani"], "venue": "In Proceedings of the 15th International Conference on Machine Learning (ICML),", "citeRegEx": "Billsus and Pazzani,? \\Q1998\\E", "shortCiteRegEx": "Billsus and Pazzani", "year": 1998}, {"title": "Empirical analysis of predictive algorithms for collaborative ltering", "author": ["J. Breese", "D. Heckerman", "C Kadie"], "venue": "In Proceedings of the 14th Conference on Uncertainty in Arti cial Intelligence (UAI),", "citeRegEx": "Breese et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Breese et al\\.", "year": 1998}, {"title": "Dependency networks for inference, collaborative ltering, and data visualization", "author": ["D. Heckerman", "D. Chickering", "C. Meek", "R. Rounthwaite", "C. Kadie"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Heckerman et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Heckerman et al\\.", "year": 2001}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["G. Hinton"], "venue": "Neural Computation,", "citeRegEx": "Hinton,? \\Q2002\\E", "shortCiteRegEx": "Hinton", "year": 2002}, {"title": "Latent semantic models for collaborative ltering", "author": ["T. Hofmann"], "venue": "ACM Transactions on Information Systems (TOIS), 22(1),", "citeRegEx": "Hofmann,? \\Q2004\\E", "shortCiteRegEx": "Hofmann", "year": 2004}, {"title": "Factorization meets the neighborhood: a multifaceted collaborative ltering model", "author": ["Y. Koren"], "venue": "In KDD", "citeRegEx": "Koren,? \\Q2008\\E", "shortCiteRegEx": "Koren", "year": 2008}, {"title": "Modeling user rating pro les for collaborative ltering", "author": ["B. Marlin"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Marlin,? \\Q2004\\E", "shortCiteRegEx": "Marlin", "year": 2004}, {"title": "GroupLens: An open architecture for collaborative ltering of netnews", "author": ["P. Resnick", "N. Iacovou", "M. Suchak", "P. Bergstorm", "J. Riedl"], "venue": "In Proceedings of ACM Conference on Computer Supported Cooperative Work,", "citeRegEx": "Resnick et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Resnick et al\\.", "year": 1994}, {"title": "Restricted Boltzmann machines for collaborative ltering", "author": ["R. Salakhutdinov", "A. Mnih", "G. Hinton"], "venue": "In Proceedings of the 24th International Conference on Machine Learning (ICML),", "citeRegEx": "Salakhutdinov et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Salakhutdinov et al\\.", "year": 2007}, {"title": "Item-based collaborative ltering recommendation algorithms", "author": ["B. Sarwar", "G. Karypis", "J. Konstan", "J. Reidl"], "venue": "In Proceedings of the 10th international conference on World Wide Web,", "citeRegEx": "Sarwar et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Sarwar et al\\.", "year": 2001}, {"title": "Exponential family harmoniums with an application to information retrieval", "author": ["M. Welling", "M. Rosen-Zvi", "G. Hinton"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Welling et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Welling et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 11, "context": "For example, if we want to predict how much the user likes a particular movie we may look for similar users who have rated the movie before (Resnick et al., 1994).", "startOffset": 140, "endOffset": 162}, {"referenceID": 13, "context": "Alternatively, the rating for this new movie can be based on ratings of other similar movies that the user has watched (Sarwar et al., 2001).", "startOffset": 119, "endOffset": 140}, {"referenceID": 12, "context": "More recent development has suggested that dimensionality reduction techniques like SVD (Salakhutdinov et al., 2007), PLSA (Hofmann, 2004) and LDA (Marlin, 2004) are also competitive.", "startOffset": 88, "endOffset": 116}, {"referenceID": 8, "context": ", 2007), PLSA (Hofmann, 2004) and LDA (Marlin, 2004) are also competitive.", "startOffset": 14, "endOffset": 29}, {"referenceID": 10, "context": ", 2007), PLSA (Hofmann, 2004) and LDA (Marlin, 2004) are also competitive.", "startOffset": 38, "endOffset": 52}, {"referenceID": 0, "context": "Speci cally, we explore the application of an undirected graphical model known as Boltzmann Machines (BMs) (Ackley et al., 1985) for the problem.", "startOffset": 107, "endOffset": 128}, {"referenceID": 9, "context": "Note that its probabilistic integration di ers from the current practice of blending multiple independent models (Koren, 2008).", "startOffset": 113, "endOffset": 126}, {"referenceID": 8, "context": "One way to deal with this issue is to approximate them by continuous variables as done in (Hofmann, 2004) but this is only meaningful for numerical ratings.", "startOffset": 90, "endOffset": 105}, {"referenceID": 7, "context": "Further, this paper studies approximate learning strategies for large BMs, including Contrastive Divergence (Hinton, 2002) (CD), a structural extension to Pseudo-Likelihood (Besag, 1975) (PL), and the combination of CD and PL for the joint model.", "startOffset": 108, "endOffset": 122}, {"referenceID": 3, "context": "Further, this paper studies approximate learning strategies for large BMs, including Contrastive Divergence (Hinton, 2002) (CD), a structural extension to Pseudo-Likelihood (Besag, 1975) (PL), and the combination of CD and PL for the joint model.", "startOffset": 173, "endOffset": 186}, {"referenceID": 7, "context": "We follow a sampling strategy called Contrastive-Divergence (CD) (Hinton, 2002), in that we start the sampling from the data distribution, and stop the random walks after a few steps.", "startOffset": 65, "endOffset": 79}, {"referenceID": 3, "context": "Another method is to utilise Pseudo-likelihood (PL) (Besag, 1975), and we approximate the model loglikelihood by", "startOffset": 52, "endOffset": 65}, {"referenceID": 13, "context": "see (Sarwar et al., 2001)), and keep only positively correlated pairs.", "startOffset": 4, "endOffset": 25}, {"referenceID": 12, "context": "For comparison, we implement the Singular Value Decomposition (SVD) for incomplete data (see, for example, (Salakhutdinov et al., 2007) for a description).", "startOffset": 107, "endOffset": 135}, {"referenceID": 5, "context": "includes the standard recall/precision measures, and the ranking utility adapted from (Breese et al., 1998).", "startOffset": 86, "endOffset": 107}, {"referenceID": 5, "context": "As suggested in (Breese et al., 1998), we choose \u03b1 = 5.", "startOffset": 16, "endOffset": 37}, {"referenceID": 0, "context": "The Boltzmann Machines explored in this paper are more general that the original proposal in (Ackley et al., 1985) due to the use of general exponential family instead of binary variables, in the same way that the Harmoniums (Welling et al.", "startOffset": 93, "endOffset": 114}, {"referenceID": 14, "context": ", 1985) due to the use of general exponential family instead of binary variables, in the same way that the Harmoniums (Welling et al., 2005) generalises the Restricted BMs (e.", "startOffset": 118, "endOffset": 140}, {"referenceID": 12, "context": "see (Salakhutdinov et al., 2007)).", "startOffset": 4, "endOffset": 32}, {"referenceID": 12, "context": "The work in (Salakhutdinov et al., 2007) applies Restricted BMs for collaborative ltering but it is limited to individual modelling of users and categorical variables.", "startOffset": 12, "endOffset": 40}, {"referenceID": 5, "context": "Other graphical models have been employed for collaborative ltering in a number of places, including Bayesian networks (Breese et al., 1998) and dependency networks (Heckerman et al.", "startOffset": 119, "endOffset": 140}, {"referenceID": 6, "context": ", 1998) and dependency networks (Heckerman et al., 2001).", "startOffset": 32, "endOffset": 56}, {"referenceID": 3, "context": "Our method resembles dependency networks when pseudo-likelihood (Besag, 1975) learning is employed and no hidden variables are modelled, but dependency networks are generally inconsistent.", "startOffset": 64, "endOffset": 77}, {"referenceID": 8, "context": "The dimensionality reduction capacity of the BMs is shared by other probabilistic models, including mixture models, probabilistic latent semantic analysis (PLSA) (Hofmann, 2004) and latent Dirichlet allocation (LDA) (Marlin, 2004).", "startOffset": 162, "endOffset": 177}, {"referenceID": 10, "context": "The dimensionality reduction capacity of the BMs is shared by other probabilistic models, including mixture models, probabilistic latent semantic analysis (PLSA) (Hofmann, 2004) and latent Dirichlet allocation (LDA) (Marlin, 2004).", "startOffset": 216, "endOffset": 230}, {"referenceID": 4, "context": "Machine learning (Billsus and Pazzani, 1998; Basu et al., 1998; Basilico and Hofmann, 2004) has also been successfully applied to the collaborative ltering problem.", "startOffset": 17, "endOffset": 91}, {"referenceID": 2, "context": "Machine learning (Billsus and Pazzani, 1998; Basu et al., 1998; Basilico and Hofmann, 2004) has also been successfully applied to the collaborative ltering problem.", "startOffset": 17, "endOffset": 91}, {"referenceID": 1, "context": "Machine learning (Billsus and Pazzani, 1998; Basu et al., 1998; Basilico and Hofmann, 2004) has also been successfully applied to the collaborative ltering problem.", "startOffset": 17, "endOffset": 91}, {"referenceID": 8, "context": "Since ratings are sometimes provided in a numerical scale, they can be approximated by continuous variables, as suggested in (Hofmann, 2004).", "startOffset": 125, "endOffset": 140}], "year": 2009, "abstractText": "Collaborative ltering is an e ective recommendation technique wherein the preference of an individual can potentially be predicted based on preferences of other members. Early algorithms often relied on the strong locality in the preference data, that is, it is enough to predict preference of a user on a particular item based on a small subset of other users with similar tastes or of other items with similar properties. More recently, dimensionality reduction techniques have proved to be equally competitive, and these are based on the co-occurrence patterns rather than locality. This paper explores and extends a probabilistic model known as Boltzmann Machine for collaborative ltering tasks. It seamlessly integrates both the similarity and cooccurrence in a principled manner. In particular, we study parameterisation options to deal with the ordinal nature of the preferences, and propose a joint modelling of both the user-based and item-based processes. Experiments on moderate and large-scale movie recommendation show that our framework rivals existing well-known methods.", "creator": "TeX"}}}