{"id": "1206.4633", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Fast Bounded Online Gradient Descent Algorithms for Scalable Kernel-Based Online Learning", "abstract": "Kernel-based online learning has often shown state-of-the-art performance for many online learning tasks. It, however, suffers from a major shortcoming, that is, the unbounded number of support vectors, making it non-scalable and unsuitable for applications with large-scale datasets. In this work, we study the problem of bounded kernel-based online learning that aims to constrain the number of support vectors by a predefined budget. Although several algorithms have been proposed in literature, they are neither computationally efficient due to their intensive budget maintenance strategy nor effective due to the use of simple Perceptron algorithm. To overcome these limitations, we propose a framework for bounded kernel-based online learning based on an online gradient descent approach. We propose two efficient algorithms of bounded online gradient descent (BOGD) for scalable kernel-based online learning: (i) BOGD by maintaining support vectors using uniform sampling, and (ii) BOGD++ by maintaining support vectors using non-uniform sampling. We present theoretical analysis of regret bound for both algorithms, and found promising empirical performance in terms of both efficacy and efficiency by comparing them to several well-known algorithms for bounded kernel-based online learning on large-scale datasets.", "histories": [["v1", "Mon, 18 Jun 2012 15:13:13 GMT  (192kb)", "http://arxiv.org/abs/1206.4633v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["steven c h hoi", "jialei wang", "peilin zhao", "rong jin", "pengcheng wu"], "accepted": true, "id": "1206.4633"}, "pdf": {"name": "1206.4633.pdf", "metadata": {"source": "META", "title": "Fast Bounded Online Gradient Descent Algorithms forScalable Kernel-Based Online Learning", "authors": ["Peilin Zhao", "Jialei Wang", "Pengcheng Wu", "Rong Jin", "Steven C.H. Hoi"], "emails": ["zhao0106@ntu.edu.sg", "jl.wang@ntu.edu.sg", "wupe0003@ntu.edu.sg", "rongjin@cse.msu.edu", "chhoi@ntu.edu.sg"], "sections": [{"heading": null, "text": "Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s)."}, {"heading": "1. Introduction", "text": "The goal of kernel-based online learning is to sequentially update a nonlinear kernel-based classifier given a sequence of training examples (Kivinen et al., 2001; Cheng et al., 2006; Crammer et al., 2006; Jin et al., 2010; Zhao et al., 2011). Although it yields significantly better performance than linear online learning, the main shortcoming of kernel-based online learning is its potentially unbounded number of support vectors, which requires a large amount of memory for storing support vectors and a high computational cost per iteration, both making it unsuitable for large-scale applications. In this work, we address this challenge by developing a computationally efficient framework for budget online learning in which the number of support vectors is bounded by a predefined size (i.e., budget).\nIn literature, several algorithms have been proposed for online budget learning. Crammer et al. (Crammer et al., 2003) proposed a heuristic approach for online budget learning, which was further improved in (Weston & Bordes, 2005). The basic idea of these two algorithms is to remove the support vector that has the least impact on the classification performance when the budget number of support vectors is reached. The main shortcoming of these two algorithms is that they are heuristic approaches and do not have solid theoretic supports (i.e., neither a mistake bound nor a regret bound is proved).\nForgetron (Dekel et al., 2005) is the first online budget learning algorithm that has guarantee on the number of mistakes. At each iteration, if the classifier makes a mistake, it conducts a three-step updating: it first runs the standard Perceptron (Rosenblatt, 1958) updating; it then shrinks the weights of support vectors by a carefully chosen scaling factor; it finally removes\nthe support vector with the least weight. Randomized Budget Perceptron (RBP) (Cavallanti et al., 2007) removes a randomly selected support vector when the number of support vectors exceeds the predefined budget. It achieves similar mistake bound and empirical performance as the Forgetron algorithm.\nUnlike the strategy that discards one of support vectors to maintain the budget, Projectron (Orabona et al., 2008) adopts a projection strategy to bound the number of support vectors. Specifically, in each iteration when the training example is misclassified, it first constructs a new kernel classifier by applying the updating rule of Perceptron to the current classifier; it then projects the new classifier into the space spanned by all the support vectors except the new example received. The classifier will remain unchanged if the difference between the new classifier and its projection is smaller than a given threshold. Empirical studies show that Projectron usually outperforms Forgetron in classification but with significantly longer running time. One main shortcoming of Projectron is that although the number of support vectors of Projectron is bounded, it is however unclear the exact number of support vectors achieved by Projectron in theory. In addition, its high computational cost makes it unsuitable for large-scale applications.\nAll the existing algorithms for online budget learning are based on the Perceptron algorithm, partially because they are mostly concerned with the mistake bound, not the regret bound. In this paper, we develop a \u201cBounded Online Gradient Descent\u201d (BOGD) framework for online budget learning algorithms, based on the online gradient descent algorithms (Kivinen et al., 2001; Zinkevich, 2003; Ying & Pontil, 2008). Similar to the Random Budget Perceptron, the proposed algorithms randomly select one of the existing support vectors to discard when the buffer of support vectors overflows. However, unlike the Random Budget Perceptron that discards every support vector with equal probability, in one of our algorithms, the probability of discarding a support vector depends on its weight, making it more effective for online budget learning. Different from most existing studies that can only obtain a guarantee on the mistake bound, we derive regret bounds for the proposed algorithms, making it possible to convert the proposed algorithms into batch learning algorithms when the received examples are iid samples. Finally, it is important to distinguish the proposed work from sparse online learning (Langford et al., 2009; Duchi & Singer, 2009) whose goal is to learn a sparse linear classifier from a sequence of training examples. In contrast, we focus on learning a nonlinear kernel classifier.\nThe rest of the paper is organized as follows. Section 2 introduces the basic setting of online budget learning, and presents both theoretical and algorithmic details of the proposed approaches for online budget learning. Section 3 discusses our empirical studies on six real world datasets. Section 4 concludes this work."}, {"heading": "2. Algorithms and Analysis", "text": "We consider kernel-based online learning for classification. Our goal is to learn a function f : Rd \u2192 R from a sequence of training examples {(xt, yt), t \u2208 [T ]}, where xt \u2208 Rd, yt \u2208 Y = {\u22121,+1} and [T ] = {1, . . . , T }. We predict the class assignment for x by sgn(f(x)), and measure the classification confidence by |f(x)|. Let \u2113(yf(x)) : R \u2192 R be a convex loss function that is Lipschitz continuous with Lipschitz constant L. Let H be an RKHS endowed with a kernel function \u03ba(\u00b7, \u00b7) : Rd \u00d7 Rd \u2192 R. We assume \u03ba(x,x) \u2264 1 for any x \u2208 Rd. Similar to kernel-based online learning (Kivinen et al., 2001; Zinkevich, 2003) and the Pegasos algorithm (Shalev-Shwartz et al., 2011), at each trial of online learning, given a received training example (xt, yt), we define the following loss function:\nLt(f) = \u03bb\n2 \u2016f\u20162H + \u2113(ytf(xt)) (1)\nWe first describe an online learning algorithm, similar to kernel-based online learning (Kivinen et al., 2001; Zinkevich, 2003), that minimizes the regret of \u2211T\nt=1 \u2113t(ft) using the online gradient descent approach. At each trial t, given the classifier ft and training example (xt, yt), we update the classifier by\nft+1(\u00b7) = ft(\u00b7)\u2212 \u03b7\u2207Lt(ft) = (1\u2212 \u03b7\u03bb)ft(\u00b7)\u2212 \u03b7yt\u2113\u2032(ytft(xt))\u03ba(xt, \u00b7) (2)\nwhere \u03b7 is the stepsize and \u03bb > 0 is the regularization parameter.\nTheorem 1. Let ft, t \u2208 [T ] be a sequence of classifiers generated by the updating rule in (2). We have the following bound for any f \u2208 H, T\u2211\nt=1\n\u2113(ytft(xt)) \u2264 \u03bbT + \u03b7\u22121\n2 \u2016f\u20162H +\nT\u2211\nt=1\n\u2113(ytf(xt)) + \u03b7L 2T\nBy setting \u03bbT = \u03b7\u22121, we have\nT\u2211\nt=1\n\u2113(ytft(xt)) \u2264 1\n\u03b7 \u2016f\u20162H +\nT\u2211\nt=1\n\u2113(ytf(xt)) + \u03b7L 2T\nwhich leads to O(1/ \u221a T ) bound if \u03b7 = O(1/ \u221a T ). Note that we did not exploit the strong convexity of Lt(f),\nwhich often leads to a better bound. This is because our goal is to bound \u2211 t \u2113t(ytft(xt)), not \u2211 t Lt(ft). In addition, to exploit the strong convexity of Lt(f), we have to vary the stepsize \u03b7 over trials, making it difficult to extend the analysis to online budget learning.\nWe now modify the updating rule in (2) for online budget learning. The first modification is to introduce a domain to which the updated classifier will be projected. Specifically, we define the domain \u2126 as:\n\u2126(\u03b7\u03b3)= { f(\u00b7)= T\u2211\nt=1\n\u03b1tyt\u03ba(xt, \u00b7) : \u03b1t \u2208 [0, \u03b3\u03b7], t \u2208 [T ] } (3)\nwhere \u03b3\u03b7 > 0 specifies the maximum weight that can be assigned to any support vector. Using the domain \u2126(\u03b7\u03b3), we modify the updating rule in (2) as follows\nft+1 = \u03c0\u2126(\u03b7\u03b3) (ft \u2212 \u03b7\u2207Lt(ft)) (4) where \u03c0\u2126(\u03b7\u03b3)(f) projects f into the domain \u2126(\u03b7\u03b3). Note that when \u03b3 \u2265 L, we have \u03c0\u2126(\u03b7\u03b3)(f) = f because the weights for support vectors never increase over trials and for any support vector, its initially assigned weight is \u03b7L.\nLet B > 0 be a predefine budget. Our goal is to bound the number of support vector by B. When the number of the support vectors in f(\u00b7) is less than B, we simply run the updating rule in (4) without any change. Without loss of generality, we consider a trial t where the number of support vectors in ft(\u00b7) is B and we need to update ft(\u00b7) with a new training example (xt, yt). Note that the gradient of Lt(ft) is written as \u03bbft(\u00b7) + yt\u2113\u2032(ytft(xt))\u03ba(xt, \u00b7). Our strategy is to approximate ft(\u00b7) in \u2207L(f) with its unbiased estimator f\u0302t(\u00b7) so that the updated classifier ft+1(\u00b7) = ft \u2212 \u03b7\u03bbf\u0302t \u2212 \u03b7yt\u2113\u2032(ytft(xt))\u03ba(xt, \u00b7) contains exactly B support vectors. More specifically, we express the classifier ft(\u00b7) as\nft(\u00b7) = B\u2211\ni=1\n\u03b1tiy t i\u03ba(x t i, \u00b7)\nwhere {(xti, yti), i \u2208 [B]} are the support vectors and \u03b1ti > 0 is the weight for support vector (x t i, y t i). In order to generate an unbiased estimator f\u0302t(\u00b7) for ft(\u00b7), we randomly select one support vector according to a distribution pt = (pt1, . . . , p t B). We introduce a binary variable Zti , with Z t i = 1 indicating that support vector (xti, y t i) is selected and zero otherwise. Evidently,\u2211B\ni=1 Z t i = 1. Based on Z t = (Zt1, . . . , Z t B), we consider the following general form for constructing the unbiased estimator f\u0302t(\u00b7)\nf\u0302t(\u00b7) = B\u2211\ni=1\n( atiZ t i + b t i ) yti\u03ba(x t i, \u00b7) (5)\nwhere ati \u2265 0 and bti are parameters that need to be determined. To ensure E[f\u0302t(\u00b7)] = ft(\u00b7), we have the following condition for ati and b t i\natip t i + b t i = \u03b1 t i, i \u2208 [B] (6)\nUsing the unbiased estimator f\u0302t(\u00b7), we have the classifier ft(\u00b7) updated as\nft+1(\u00b7) = \u03c0\u2126(\u03b7\u03b3) ( \u2212 \u03b7\u2113\u2032(ytft(xt))yt\u03ba(xt, \u00b7)\n+ B\u2211\ni=1\n( \u03b1ti \u2212 \u03bb\u03b7[bti + atiZti ] ) yti\u03ba(x t i, \u00b7) ) (7)\nIn order to ensure that the number of support vectors in ft+1(\u00b7) is B, we need to have one of the coefficients in (7) set to zero, leading to the following condition for ati and b t i.\n\u03b1ti = \u03bb\u03b7(b t i + a t i), i \u2208 [B] (8)\nConditions (6) and (8) are the key for designing the sampling probabilities pt and weights (ati, b t i) for each support vector. Given pt, we have the following expression for (ati, b t i)\nati = 1\u2212 \u03bb\u03b7\n\u03bb\u03b7(1 \u2212 pti) \u03b1ti, b t i = \u03bb\u03b7 \u2212 pti \u03bb\u03b7(1 \u2212 pti) \u03b1ti, i \u2208 [B] (9)\nAs a result, the weight \u03b1t+1i is updated as follows\n\u03b1t+1i = min ( (1\u2212 Zti )\n1\u2212 \u03bb\u03b7 1\u2212 pti \u03b1ti, \u03b3\u03b7\n) , i \u2208 [B] (10)\nAccording to (10), the weight for the selected support vector (i.e., Zit = 1) is set to zero in the updated classifier ft+1(\u00b7), implying that the selected support vector is discarded from the updated classifier. Finally, Algorithm 1 summarizes the proposed framework of Bounded Online Gradient Descent (BOGD) learning.\nGiven the sampling probabilities pt, t \u2208 [T ], we have the following theorem for Algorithm 1.\nTheorem 2. Assume \u03ba(x,x) \u2264 1 and \u03bb\u03b7 \u2264 1/2. Let ft, t \u2208 [T ] be the sequence of classifiers generated by Algorithm 1. Then, for any f \u2208 \u2126(\u03b7\u03b3), we have in expectation the overall loss bounded as follows\nE\n[ T\u2211\nt=1\n\u2113(ytft(xt))\n] \u2264 \u03b7 \u22121 + \u03bbT\n2 \u2016f\u20162H +\nT\u2211\nt=1\n\u2113(ytf(xt))\n+\u03b7L2T + (1\u2212 \u03bb\u03b7)2\n\u03b7 E\n[ \u2211\nt\u2208VT\nB\u2211\ni=1\npti[\u03b1 t i] 2\n(1\u2212 pti)2\n]\nwhere VT = [T ]/UT and UT = {t \u2208 [T ] | |SVt| < B or \u2113\u2032(ytft(xt)) = 0}.\nAlgorithm 1 A framework of Bounded Online Gradient Descent (BOGD)\nInput: the maximum budget size B, stepsize \u03b7, regularization parameter \u03bb > 0, and maximum coefficient \u03b3 > 0. Initialize S1 = \u2205, f1 = 0. for t = 1, 2, . . . , T do Receive xt; Predict y\u0302t = sgn(ft(xt)); Receive yt and suffer loss \u2113 ( ytft(xt) ) ;\nif \u2113 \u2032\n(ytft(xt)) = 0 then ft+1(\u00b7) = (1 \u2212 \u03b7\u03bb)ft(\u00b7) and St+1 = St.\nelse\nif |St| < B then ft+1(\u00b7) = (1\u2212\u03b7\u03bb)ft(\u00b7)\u2212\u03b7\u2113 \u2032\n(ytft(xt))yt\u03ba(xt, \u00b7) and St+1 = St \u222a {t}.\nelse\nCompute the sampling distribution pt = (pt1, . . . , p t B); Sample an index ik from {1, . . . , B} according to distribution pt; Set Ztik = 1 and Z t i = 0, i \u2208 [B]/{ik}; ati = 1\u2212\u03bb\u03b7\n\u03bb\u03b7(1\u2212pt i )\u03b1 t i, b t i =\n\u03bb\u03b7\u2212pt i\n\u03bb\u03b7(1\u2212pt i )\u03b1 t i, i =\n1, . . . , B; ft+1(\u00b7) = Eq. (7); St+1 = St \u222a {t}/{ik}.\nend if\nend if\nend for\nProof. Using the standard analysis of gradient descent (Kivinen et al., 2001; Zinkevich, 2003), it is not difficult to show for any f \u2208 \u2126(\u03b7\u03b3),\nE\n[ T\u2211\nt=1\n{ \u03bb\n2 \u2016ft\u20162H + \u2113(ytft(xt))\n}]\n\u2212 T\u2211\nt=1\n{ \u03bb\n2 \u2016f\u20162H + \u2113(ytf(xt))\n}\n\u2264 \u2016f\u2016 2 H\n2\u03b7 + \u03b7L2T + \u03b7E\n[ T\u2211\nt=1\n\u03bb 2\u2016f\u0302t\u20162H\n]\n(11)\nWe consider two scenarios:\nCase 1: Consider the trial t \u2208 UT . Since no sampling is done in these trials, we thus have Et[|f\u0302t|2H] = \u2016ft\u20162H. Case 2: Consider the trial t \u2208 VT , we have\nEt[|f\u0302t|2H] = \u2016ft\u20162H \u2212 \u2225\u2225\u2225\u2225\u2225 B\u2211\ni=1\natip t iy t i\u03ba(x t i, \u00b7) \u2225\u2225\u2225\u2225\u2225 2\nH\n+\nB\u2211\ni=1\npti[a t i] 2\u03ba(xti,x t i)\n\u2264 \u2016ft\u20162H + ( [\u03bb\u03b7]\u22121 \u2212 1 )2 B\u2211\ni=1\npti[\u03b1 t i] 2\n(1\u2212 pti)2\nWe complete the proof by substituting into (11) the above expression for \u2016f\u20162H.\nBelow, we discuss two different designs of sampling probabilities pt, i.e., (i) uniform sampling, and (ii) non-uniform sampling.\nUniform Sampling. In this approach, we set pti = 1/B for any i \u2208 [B] and any t \u2208 [T ]. According to Theorem 2, it is not difficult to have the following result for the loss bound.\nTheorem 3. For any classifier f \u2208 \u2126(\u03b7\u03b3), we have the following bound for Algorithm 1 using uniform sampling\nE\n[ T\u2211\nt=1\n\u2113(ytft(xt))\n] \u2264 ( ( B\nB \u2212 1) 2\u03b32 + L2\n) \u03b7T\n+ \u03b7\u22121 + \u03bbT\n2 \u2016f\u20162H +\nT\u2211\nt=1\n\u2113(ytf(xt)) = A(\u03b7) + C(\u03b7)(12)\nwhere\nA(\u03b7) = (( B\nB \u2212 1) 2\u03b32 + L2)\u03b7T +\n\u03b7\u22121 + \u03bbT\n2 \u2016f\u20162H,\nC(\u03b7) =\nT\u2211\nt=1\n\u2113(ytf(xt)).\nLet \u03bb\u03b7T = 1 and \u03b7 = 1/ \u221a T . We then have, for any f \u2208 \u2126(\u03b7\u03b3), that\nE\n[ T\u2211\nt=1\n\u2113(ytft(xt))\n] \u2212 T\u2211\nt=1\n\u2113(ytf(xt))\n\u2264 ( ( B\nB \u2212 1) 2\u03b32 + L2\n)\u221a T + \u2016f\u20162H \u221a T = O( \u221a T ) (13)\nRemark. We have two comments for the above results. First, by choosing different stepsize \u03b7, we make a tradeoff between A(\u03b7) and C(\u03b7). In particular, a small \u03b7 will result in a small value for A(\u03b7) but a large value for C(\u03b7). This is because a small \u03b7 reduces the size of hypothesis space \u2126(\u03b7\u03b3) and consequentially increases the overall loss \u2211T\nt=1 \u2113(ytf(xt)). Similarly, a large \u03b7 will lead to large A(\u03b7) but potentially small C(\u03b7). Second, although (13) shows a regret bound of O( \u221a T ) independent from B, it does not contradict the analysis presented in (Dekel et al., 2005). This is because we restrict the competitor f to the domain \u2126(\u03b7\u03b3) while the analysis in (Dekel et al., 2005) considers any hypothesis in RHKS H as a competitor. Observe that the projection \u03c0\u2126(\u03b7\u03b3)(f) in (7) is no longer in effect if we set \u03b3 \u2265 L and \u03bb\u03b7 \u2265 1/B in our algorithm. As\na result, under the conditions \u03b3 \u2265 L and \u03bb\u03b7 \u2265 1/B, for any classifier f \u2208 H, with appropriate choice of \u03b7 and \u03bb, we have the following regret bound for the the sequence of classifier generated by Algorithm 1 using uniform sampling:\nE\n[ T\u2211\nt=1\n\u2113(ytft(xt)) ] \u2212 T\u2211\nt=1\n\u2113(ytf(xt)) \u2264 O (\nT\u221a B \u2016f\u2016H\n) (14)\nAs indicated by the regret bound in (14), if we consider any f \u2208 H as a competitor, unless we set B = T , we will not be able to obtain an O( \u221a T ) regret bound. Although this result may seem significantly worse than the one presented (Dekel et al., 2005), we emphasize that (14) is about regret bound while the result in (Dekel et al., 2005) is about mistake bound. In general, deriving a good regret bound is usually more challenging than getting a similar mistake bound.\nNonuniform Sampling. To fully exploit the information we have about the classifier f(\u00b7) =\u2211B\ni=1 \u03b1iyi\u03ba(xi, \u00b7), we consider a nonuniform sampling approach to BOGD by choosing the values of p as follows:\n(1 \u2212 pi)2 = s2\u03b12i \u03ba(xi,xi), i \u2208 [B] (15)\nwhere s is the normalization factor. Given the expression in (15), it is straightforward to derive pi as follows\npi = 1\u2212 s\u03b1i \u221a \u03ba(xi,xi), (16)\nwhere s = (B\u22121)\u2211 B i=1 \u03b1i \u221a \u03ba(xi,xi) .\nBefore presenting the regret bound, we define function H(f) that measures the skewness of the coefficients for the support vectors used by f . More specifically, H(f) is defined as\nH(f) = B B\u2211\ni=1\n\u03b12i \u03ba(xi, xi)\u2212 ( B\u2211\ni=1\n\u03b1i \u221a \u03ba(xi, xi)\n)2\nAccording to Cauchy-Schwarz inequality, we always have H(f) \u2265 0 where the equality holds if and only if \u03b11 = . . . ,= \u03b1B . Theorem 4. Assume \u03ba(x,x) \u2264 1 and \u03ba(x,x\u2032) \u2265 0. Let ft, t \u2208 [T ] be the sequence of classifiers generated by Algorithm 1 using the nonuniform sampling specified in (16). Then, for any f \u2208 \u2126(\u03b7\u03b3), we have in expectation the loss experienced by {ft}Tt=1 bounded as:\nE\n[ T\u2211\nt=1\n\u2113(ytft(xt))\n]\n\u2212 T\u2211\nt=1\n\u2113(ytf(xt)) \u2264\n(( B\nB \u2212 1 ) 2 \u03b3 2 + L2)\u03b7T +\n\u03b7\u22121 + \u03bbT\n2 \u2016f\u20162H \u2212 (1\u2212 \u03bb\u03b7)2 \u03b7(B \u2212 1)2\n\u2211\nt\u2208Vt\nHt\nwhere Ht = H(ft) and Vt is the set of trials where one of the support vector is discarded.\nProof. The proof is almost identical to that of Theorem 2. The only difference is in bounding Et[|f\u0302t|2H], t \u2208 Vt, i.e.,\nEt[|f\u0302t|2H] \u2264 \u2016ft\u20162H + ( 1\u2212 \u03bb\u03b7 \u03bb\u03b7 )2 (\u2211B i=1 \u03b1 t i \u221a \u03ba(xti,x t i) )2 (B \u2212 1)2\n\u2264 \u2016ft\u20162H + (1\u2212 \u03bb\u03b7)2\n(\u03bb\u03b7)2(B \u2212 1)2\n( B B\u2211\ni=1\n[\u03b1ti] 2\u03ba(xti,x t i)\u2212Ht\n)\nThe rest of the proof follows almost the exactly same steps as that for Theorem 2.\nThe above theorem clearly indicates that nonuniform sampling reduces the regret bound by taking advantage of the skewed distribution of coefficients assigned to support vectors. We note that although Theorem 4 does not give an explicit bound for the advantage of exploiting the skewed distribution of coefficients, it does show up significantly in our empirical study."}, {"heading": "3. Experimental Results", "text": "In this section, we evaluate the empirical performance of the proposed algorithms for Bounded Online Gradient Descent (BOGD) learning algorithms by comparing them to the state-of-the-art algorithms for online budget learning."}, {"heading": "3.1. Experimental Testbed", "text": "Table 1 shows the details of six binary-class datasets used in our experiments. All of these datasets can be downloaded from LIBSVM website 1 and UCI machine learning repository 2. These datasets were chosen fairly randomly to cover a variety of datasets of different sizes."}, {"heading": "3.2. Baseline Algorithms and Setup", "text": "We refer to as \u201cBOGD\u201d the proposed BOGD algorithm using uniform sampling, and as \u201cBOGD++\u201d the proposed BOGD algorithm using nonuniform sampling. We compare the two proposed BOGD algorithms with the following state-of-the-art algorithms for online budget learning: (i) \u201cRBP\u201d \u2014 the Random Budget Perceptron algorithm (Cavallanti et al., 2007), (ii) \u201cForgetron\u201d \u2014 the Forgetron algorithm (Dekel et al., 2005), (iii) \u201cProjectron\u201d \u2014 the Projectron algorithm (Orabona et al., 2008), and (iv) \u201cProjectron++\u201d \u2014 the aggressive version of Projectron algorithm (Orabona et al., 2008). We also compare the proposed algorithms to two non-budget online learning algorithms: (i) \u201cPerceptron\u201d \u2014 the classical Perceptron algorithm (Rosenblatt, 1958), and (ii) \u201cOGD\u201d \u2014 the Online Gradient Descent algorithm (Kivinen et al., 2001; Ying & Pontil, 2008).\nTo make a fair comparison, all the algorithms in our comparison adopt the same experimental setup. The loss function \u2113 is set as the hinge loss, i.e., \u2113(yf(x)) = max(0, 1 \u2212 yf(x)). A Gaussian kernel is adopted in our study, for which the kernel width is set to 8 for all the algorithms and datasets. The regularization parameter \u03bb, stepsize \u03b7 and parameter \u03b3 in the proposed algorithm are selected using cross validation for all combinations of the datasets, algorithms and budgets(More specifically, \u03bb is chosen from { 2\u22123 T 2 , 2 \u22122 T 2 , ..., 2 3 T 2 } where T is the number of instances; \u03b7 is chosen from {2\u22123, 2\u22122, ..., 23}; \u03b3 is chosen from {20, 21, ..., 24}). The budget sizes Bs for different datasets are set as proper fractions of the support vectors numbers of Perceptron, which are shown in Table 3. All the experiments were conducted 20 times, each with a different random permutation of data points. All the results were reported by averaging over the 20 runs. For performance metrics, we evaluate the online classification performance by mistake rates and running time. Finally, all of the algorithms were implemented in C++, and all experiments were run in a linux machine with 2.5GHz CPU."}, {"heading": "3.3. Evaluation of Non-budget Algorithms", "text": "Table 2 summarizes the average performance of the two non-budget algorithms for kernel-based online learning. First, we find that OGD outperforms Perceptron significantly for all datasets according to t-test results, which implies that a budget OGD algorithm might be more effective than that based on the Perceptron algorithm. Second, the support vector size of OGD is in general much larger than that of Perceptron. Finally, the time cost of OGD is much higher than that of Perceptron, mostly due to the larger number of support vectors. Both the large number of support vectors and high computational time motivate the need of developing budget OGD algorithms."}, {"heading": "3.4. Evaluation of Budget Algorithms", "text": "Table 3 summarizes the results of different budget online learning algorithms. First, we observe that RBP and Forgetron achieve similar performance for almost all cases. In addition, we also find that Projectron++ achieves a lower mistake rate than Projectron for almost all the datasets and for all budge sizes, which is similar to the results in (Orabona et al., 2008).\nSecond, compared to the baseline algorithms for online budget learning, the proposed BOGD algorithm achieves comparable, sometimes better mistake rates, especially when the budget size is large, demonstrating the effectiveness of our framework. Among all the compared algorithms for online budget learning, when the budget is large, we find that BOGD++ always achieves the lowest mistake rates for most the cases; when the budget is small, BOGD++ often achieves the best or close to the best results (except two datasets \u201cgerman\u201d and \u201cspambase\u201d). These results indicate the importance of exploiting the skewed distribution of weights for support vectors. Moreover, it is interesting to find that on most datasets (e.g., \u201cgerman\u201d, \u201dw8a\u201d, \u201cijcnn1\u201d, \u201dmagic04\u201d and \u201ccodrna\u201d), BOGD++ can even achieve significantly lower mistake rates than Perceptron that does not a budget constraint.\nFinally, for the comparison of running time cost, the Projectron algorithms are the least efficient algorithms among all the budget online learning algorithms, mostly due to their costly projection step. For example, on the largest dataset \u201ccodrna\u201d with the budget B=2000, Projectron++ on average took more than half an hour to run one experiment. For the proposed algorithms, the time costs of both BOGD and BOGD++ are in general comparable to those of RBP and Forgetron, and are significantly more efficient than those of Projectron algorithms. For example, on dataset \u201ccodrna\u201d with the budget B=1000, BOGD++ is about 30 times faster than Projectron++, and is about 60 times faster than the original non-budget OGD algorithm. For the two proposed algorithms themselves, BOGD++ is slightly more time consuming than BOGD, due to the additional cost of computing the distribution pt towards non-uniform sampling."}, {"heading": "4. Conclusions", "text": "This paper presented a novel framework of bounded online gradient descent (BOGD) for scalable kernelbased online learning which requires the number of support vectors to be smaller than a predefined budget. The basic idea of maintaining the budget size is to remove one randomly selected support vector whenever the support vector size overflows. In particular, we proposed two efficient BOGD algorithms: (i) BOGD by randomly discarding one support vector using uniform sampling, and (ii) BOGD++ using non-uniform sampling. We conducted extensive empirical studies by comparing with several state-of-the-art algorithms, in which our results showed that the proposed algorithms achieve the promising performance in terms of both classification efficacy and computational efficiency. Future work will exploit different sampling strategies and extend our work to multi-class budget kernel-based online learning."}, {"heading": "Acknowledgments", "text": "This work was in part supported by MOE tier 1 grant (RG33/11), Microsoft Research grant (M4060936), National Science Foundation (IIS-0643494), and Office of Navy Research (ONR Award N00014-09-1-0663 and N00014-12-1-0431)."}], "references": [{"title": "Tracking the best hyperplane with a simple budget perceptron", "author": ["Cavallanti", "Giovanni", "Cesa-Bianchi", "Nicol\u00f2", "Gentile", "Claudio"], "venue": "Machine Learning,", "citeRegEx": "Cavallanti et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cavallanti et al\\.", "year": 2007}, {"title": "Implicit online learning with kernels", "author": ["Wang", "Shaojun", "Caelli", "Terry"], "venue": "In NIPS, pp", "citeRegEx": "Wang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2006}, {"title": "Online classification on a budget", "author": ["Crammer", "Koby", "Kandola", "Jaz S", "Singer", "Yoram"], "venue": "In NIPS,", "citeRegEx": "Crammer et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2003}, {"title": "Online passiveaggressive algorithms", "author": ["Crammer", "Koby", "Dekel", "Ofer", "Keshet", "Joseph", "ShalevShwartz", "Shai", "Singer", "Yoram"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Crammer et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2006}, {"title": "The forgetron: A kernel-based perceptron on a fixed budget", "author": ["Dekel", "Ofer", "Shalev-Shwartz", "Shai", "Singer", "Yoram"], "venue": "In NIPS,", "citeRegEx": "Dekel et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Dekel et al\\.", "year": 2005}, {"title": "Efficient online and batch learning using forward backward splitting", "author": ["Duchi", "John", "Singer", "Yoram"], "venue": null, "citeRegEx": "Duchi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2009}, {"title": "Online multiple kernel learning: Algorithms and mistake bounds", "author": ["Jin", "Rong", "Hoi", "Steven C. H", "Yang", "Tianbao"], "venue": "In ALT,", "citeRegEx": "Jin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jin et al\\.", "year": 2010}, {"title": "Online learning with kernels", "author": ["Kivinen", "Jyrki", "Smola", "Alex J", "Williamson", "Robert C"], "venue": "In NIPS, pp", "citeRegEx": "Kivinen et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Kivinen et al\\.", "year": 2001}, {"title": "Sparse online learning via truncated gradient", "author": ["Langford", "John", "Li", "Lihong", "Zhang", "Tong"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Langford et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Langford et al\\.", "year": 2009}, {"title": "The projectron: a bounded kernel-based perceptron", "author": ["Orabona", "Francesco", "Keshet", "Joseph", "Caputo", "Barbara"], "venue": "In ICML, pp", "citeRegEx": "Orabona et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Orabona et al\\.", "year": 2008}, {"title": "The perceptron: A probabilistic model for information storage and organization in the brain", "author": ["Rosenblatt", "Frank"], "venue": "Psychological Review,", "citeRegEx": "Rosenblatt and Frank.,? \\Q1958\\E", "shortCiteRegEx": "Rosenblatt and Frank.", "year": 1958}, {"title": "Pegasos: primal estimated sub-gradient solver for svm", "author": ["Shalev-Shwartz", "Shai", "Singer", "Yoram", "Srebro", "Nathan", "Cotter", "Andrew"], "venue": "Math. Program.,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2011}, {"title": "Online (and offline) on an even tighter budget", "author": ["Weston", "Jason", "Bordes", "Antoine"], "venue": "In AISTATS, pp", "citeRegEx": "Weston et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2005}, {"title": "Online gradient descent learning algorithms", "author": ["Ying", "Yiming", "Pontil", "Massimiliano"], "venue": "Found. Comput. Math.,", "citeRegEx": "Ying et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ying et al\\.", "year": 2008}, {"title": "Double updating online learning", "author": ["Zhao", "Peilin", "Hoi", "Steven C. H", "Jin", "Rong"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Zhao et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2011}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["Zinkevich", "Martin"], "venue": "In ICML, pp", "citeRegEx": "Zinkevich and Martin.,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich and Martin.", "year": 2003}], "referenceMentions": [{"referenceID": 7, "context": "The goal of kernel-based online learning is to sequentially update a nonlinear kernel-based classifier given a sequence of training examples (Kivinen et al., 2001; Cheng et al., 2006; Crammer et al., 2006; Jin et al., 2010; Zhao et al., 2011).", "startOffset": 141, "endOffset": 242}, {"referenceID": 3, "context": "The goal of kernel-based online learning is to sequentially update a nonlinear kernel-based classifier given a sequence of training examples (Kivinen et al., 2001; Cheng et al., 2006; Crammer et al., 2006; Jin et al., 2010; Zhao et al., 2011).", "startOffset": 141, "endOffset": 242}, {"referenceID": 6, "context": "The goal of kernel-based online learning is to sequentially update a nonlinear kernel-based classifier given a sequence of training examples (Kivinen et al., 2001; Cheng et al., 2006; Crammer et al., 2006; Jin et al., 2010; Zhao et al., 2011).", "startOffset": 141, "endOffset": 242}, {"referenceID": 14, "context": "The goal of kernel-based online learning is to sequentially update a nonlinear kernel-based classifier given a sequence of training examples (Kivinen et al., 2001; Cheng et al., 2006; Crammer et al., 2006; Jin et al., 2010; Zhao et al., 2011).", "startOffset": 141, "endOffset": 242}, {"referenceID": 2, "context": "(Crammer et al., 2003) proposed a heuristic approach for online budget learning, which was further improved in (Weston & Bordes, 2005).", "startOffset": 0, "endOffset": 22}, {"referenceID": 4, "context": "Forgetron (Dekel et al., 2005) is the first online budget learning algorithm that has guarantee on the number of mistakes.", "startOffset": 10, "endOffset": 30}, {"referenceID": 0, "context": "Randomized Budget Perceptron (RBP) (Cavallanti et al., 2007) removes a randomly selected support vector when the number of support vectors exceeds the predefined budget.", "startOffset": 35, "endOffset": 60}, {"referenceID": 9, "context": "Unlike the strategy that discards one of support vectors to maintain the budget, Projectron (Orabona et al., 2008) adopts a projection strategy to bound the number of support vectors.", "startOffset": 92, "endOffset": 114}, {"referenceID": 7, "context": "In this paper, we develop a \u201cBounded Online Gradient Descent\u201d (BOGD) framework for online budget learning algorithms, based on the online gradient descent algorithms (Kivinen et al., 2001; Zinkevich, 2003; Ying & Pontil, 2008).", "startOffset": 166, "endOffset": 226}, {"referenceID": 8, "context": "Finally, it is important to distinguish the proposed work from sparse online learning (Langford et al., 2009; Duchi & Singer, 2009) whose goal is to learn a sparse linear classifier from a sequence of training examples.", "startOffset": 86, "endOffset": 131}, {"referenceID": 7, "context": "Similar to kernel-based online learning (Kivinen et al., 2001; Zinkevich, 2003) and the Pegasos algorithm (Shalev-Shwartz et al.", "startOffset": 40, "endOffset": 79}, {"referenceID": 11, "context": ", 2001; Zinkevich, 2003) and the Pegasos algorithm (Shalev-Shwartz et al., 2011), at each trial of online learning, given a received training example (xt, yt), we define the following loss function: Lt(f) = \u03bb 2 \u2016f\u2016H + l(ytf(xt)) (1)", "startOffset": 51, "endOffset": 80}, {"referenceID": 7, "context": "We first describe an online learning algorithm, similar to kernel-based online learning (Kivinen et al., 2001; Zinkevich, 2003), that minimizes the regret of \u2211T t=1 lt(ft) using the online gradient descent approach.", "startOffset": 88, "endOffset": 127}, {"referenceID": 7, "context": "Using the standard analysis of gradient descent (Kivinen et al., 2001; Zinkevich, 2003), it is not difficult to show for any f \u2208 \u03a9(\u03b7\u03b3),", "startOffset": 48, "endOffset": 87}, {"referenceID": 4, "context": "Second, although (13) shows a regret bound of O( \u221a T ) independent from B, it does not contradict the analysis presented in (Dekel et al., 2005).", "startOffset": 124, "endOffset": 144}, {"referenceID": 4, "context": "This is because we restrict the competitor f to the domain \u03a9(\u03b7\u03b3) while the analysis in (Dekel et al., 2005) considers any hypothesis in RHKS H as a competitor.", "startOffset": 87, "endOffset": 107}, {"referenceID": 4, "context": "Although this result may seem significantly worse than the one presented (Dekel et al., 2005), we emphasize that (14) is about regret bound while the result in (Dekel et al.", "startOffset": 73, "endOffset": 93}, {"referenceID": 4, "context": ", 2005), we emphasize that (14) is about regret bound while the result in (Dekel et al., 2005) is about mistake bound.", "startOffset": 74, "endOffset": 94}, {"referenceID": 0, "context": "We compare the two proposed BOGD algorithms with the following state-of-the-art algorithms for online budget learning: (i) \u201cRBP\u201d \u2014 the Random Budget Perceptron algorithm (Cavallanti et al., 2007), (ii) \u201cForgetron\u201d \u2014 the Forgetron algorithm (Dekel et al.", "startOffset": 170, "endOffset": 195}, {"referenceID": 4, "context": ", 2007), (ii) \u201cForgetron\u201d \u2014 the Forgetron algorithm (Dekel et al., 2005), (iii) \u201cProjectron\u201d \u2014 the Projectron algorithm (Orabona et al.", "startOffset": 52, "endOffset": 72}, {"referenceID": 9, "context": ", 2005), (iii) \u201cProjectron\u201d \u2014 the Projectron algorithm (Orabona et al., 2008), and (iv) \u201cProjectron++\u201d \u2014 the aggressive version of Projectron algorithm (Orabona et al.", "startOffset": 55, "endOffset": 77}, {"referenceID": 9, "context": ", 2008), and (iv) \u201cProjectron++\u201d \u2014 the aggressive version of Projectron algorithm (Orabona et al., 2008).", "startOffset": 82, "endOffset": 104}, {"referenceID": 7, "context": "We also compare the proposed algorithms to two non-budget online learning algorithms: (i) \u201cPerceptron\u201d \u2014 the classical Perceptron algorithm (Rosenblatt, 1958), and (ii) \u201cOGD\u201d \u2014 the Online Gradient Descent algorithm (Kivinen et al., 2001; Ying & Pontil, 2008).", "startOffset": 215, "endOffset": 258}, {"referenceID": 9, "context": "In addition, we also find that Projectron++ achieves a lower mistake rate than Projectron for almost all the datasets and for all budge sizes, which is similar to the results in (Orabona et al., 2008).", "startOffset": 178, "endOffset": 200}], "year": 2012, "abstractText": "Kernel-based online learning has often shown state-of-the-art performance for many online learning tasks. It, however, suffers from a major shortcoming, that is, the unbounded number of support vectors, making it nonscalable and unsuitable for applications with large-scale datasets. In this work, we study the problem of bounded kernel-based online learning that aims to constrain the number of support vectors by a predefined budget. Although several algorithms have been proposed in literature, they are neither computationally efficient due to their intensive budget maintenance strategy nor effective due to the use of simple Perceptron algorithm. To overcome these limitations, we propose a framework for bounded kernel-based online learning based on an online gradient descent approach. We propose two efficient algorithms of bounded online gradient descent (BOGD) for scalable kernel-based online learning: (i) BOGD by maintaining support vectors using uniform sampling, and (ii) BOGD++ by maintaining support vectors using nonuniform sampling. We present theoretical analysis of regret bound for both algorithms, and found promising empirical performance in terms of both efficacy and efficiency by comparing them to several well-known algorithms for bounded kernel-based online learning on large-scale datasets. Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).", "creator": "LaTeX with hyperref package"}}}