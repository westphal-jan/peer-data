{"id": "1206.4647", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Active Learning for Matching Problems", "abstract": "Effective learning of user preferences is critical to easing user burden in various types of matching problems. Equally important is active query selection to further reduce the amount of preference information users must provide. We address the problem of active learning of user preferences for matching problems, introducing a novel method for determining probabilistic matchings, and developing several new active learning strategies that are sensitive to the specific matching objective. Experiments with real-world data sets spanning diverse domains demonstrate that matching-sensitive active learning", "histories": [["v1", "Mon, 18 Jun 2012 15:22:24 GMT  (311kb)", "http://arxiv.org/abs/1206.4647v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.IR", "authors": ["laurent charlin", "richard s zemel", "craig boutilier"], "accepted": true, "id": "1206.4647"}, "pdf": {"name": "1206.4647.pdf", "metadata": {"source": "META", "title": "Active Learning for Matching Problems", "authors": ["Laurent Charlin", "Richard Zemel", "Craig Boutilier"], "emails": ["lcharlin@cs.toronto.edu", "zemel@cs.toronto.edu", "cebly@cs.toronto.edu"], "sections": [{"heading": "1. Introduction", "text": "The burgeoning interest in recommender systems has led to a plethora of techniques for predicting user preferences or ratings for unseen items (e.g., products in e-commerce applications). Collaborative filtering (CF) methods (Goldberg et al., 1992) have proven especially popular and have attained impressive performance (Koren, 2009). In practice, however, recommendations must not only account for user preferences in isolation; one usually has to tradeoff preferences for recommended items with various constraints or objectives. For example, an online retailer may want to limit the number of recommendations (to different users) for any particular item so stock is not depleted (which would create unsatisfied customers). The same retailer may wish to facilitate serendipitous purchases by ensuring items recommended to any single user are diverse (McNee et al., 2006).\nIn this paper we focus on match-constrained recom-\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nmendation, where the quality of a set of recommendations or matching is measured relative to constraints or objectives that account for the entire set of users to whom an item is recommended, the entire set of items recommended to a single user, or both. These are traded off against the predicted degree of preference of individual recommendations. Match-constrained recommendation has wide application. For example, consider the problem of assigning papers to reviewers: given preferences (self-assessed expertise) of reviewers for certain papers, we want to find the best assignment of papers to reviewers. Recent work has used learning techniques such as CF to predict missing preferences\u2014 allowing reviewers to specify preferences for only a small selection of papers\u2014and finding high quality matches subject to specific \u201ccollective\u201d constraints on the matching (e.g., number of papers per reviewer, number of reviewers per paper) (Conry et al., 2009; Charlin et al., 2011).\nEliciting preferences (e.g., in the form of item ratings) imposes significant time and cognitive costs on users. In domains such as paper matching, product recommendation, or online dating, users will have limited patience for specifying preferences. While learning techniques can be used to limit the amount of required information in match-constrained recommendation, the intelligent selection of preference queries is just as important in reducing user burden. It is this problem we address in this paper. We frame the problem as one of active learning : our aim is to determine those preference queries with the greatest potential to improve the quality of the matching. This is a departure from most work in active learning, and, specifically, approaches tailored to recommender systems (as we discuss below) where queries are selected to improve the overall quality of ratings prediction. We develop techniques that focus on queries whose responses will directly impact\u2014possibly indirectly by changing predictions\u2014the matching objective itself.\nIn this paper we propose several new active learning methods for match-constrained recommendation. In\ncontrast to previous active approaches, our methods are sensitive to the matching objective. We also propose a new probabilistic matching technique that accounts for uncertainty in predicted preferences when constructing a matching. Finally, we test our methods on several real-life datasets for online dating, conference reviewing, and assigning jokes to users. Our results show that active learning methods that are sensitive to the matching task significantly outperform a standard active learning method. Furthermore, we show that our probabilistic methods can be successfully leveraged by active learning."}, {"heading": "2. Related Work", "text": "We define our problem formally below, but informally, assume a set of users must be matched to items subject to certain constraints or objectives on the overall matching. Items are construed broadly to refer to anything to which users might be matched: products in e-commerce recommender systems, papers in reviewer matching problems, even other users in roommate assignment, stable marriage or online dating. User preferences over items are represented by suitability scores which reflect the quality of matching a given item to a user \u201cin isolation.\u201d Again, suitabilities should be interpreted broadly as user preference, expertise, or some other application-specific metric.\nMatching problems have been studied in economics for decades, where the focus has been on incentives and stability, especially in two-sided matching domains where both users and items (e.g., other users) express preferences over the other. Classic examples include stable marriages and college admissions (Gale & Shapley, 1962), medical resident to hospital matching (Roth, 1984) and (one-sided) housing markets (Hylland & Zeckhauser, 1979). This work typically assumes all preferences have been specified.\nConsiderable work in information retrieval and machine learning has dealt with predicting suitabilities given only a partial set of scores or other relevant data. CF is, of course, a prime example (Goldberg et al., 1992). Recent work on reviewer-paper matching\u2014 a domain we consider here\u2014includes work using coauthorship graphs (Rodriguez & Bollen, 2008), language and topic models (Mimno & McCallum, 2007), and CF (Conry et al., 2009; Charlin et al., 2011). The latter work in particular shows that high-quality matchings can be constructed while eliciting only a small set of suitabilities, and that tuning the learning objective to account for the matching objective can improve match quality with limited data.\nActive learning is a rich field (e.g., see (Settles, 2009)\nfor a recent survey). Closest to our work are active learning methods developed for CF (Boutilier et al., 2003; Jin & Si, 2004; Harpale & Yang, 2008). These methods consider objectives that deal with recommendation sets (somewhat akin to our matching objective). Rigaux (2004) considers an iterative elicitation method for paper matching using neighborhood CF, but requires an initial partitioning of reviewers, and elicits scores (with the aim only of improving score prediction quality) for the same papers from all reviewers in a partition. In our work, we need not partition users, and we focus on matching quality rather than prediction accuracy. Our approach is thus conceptually similar to CF methods trained for specific recommendation tasks (e.g., (Weimer et al., 2007)). Finally, Bayesian optimization has been used for active learning recently (Brochu et al., 2009); however, these methods assume a continuous query space and some similarity metric over item space, hence are not readily adaptable to our match-constrained problems."}, {"heading": "3. Match-constrained Recommendation", "text": "In this section, we describe a general framework for exploiting learning in match-constrained recommendation, adopting the model and principles used in recent work on paper matching (Conry et al., 2009; Charlin et al., 2011). We then introduce a new model for probabilistic matching within this framework that we exploit when considering active learning in Sec. 4."}, {"heading": "3.1. Matching Framework", "text": "Our aim is to determine high quality matchings of items to users while requiring users to specify preferences or suitabilities over only a small fraction of all items. Our overall framework is illustrated in Fig. 1, and comprises three steps, which may be iterated in the active learning setting (Sec. 4). We first elicit suitability scores from users for certain items (A); we then learn some model (e.g., CF) to predict unobserved suitabilities (B); finally, some form of optimization is used to determine a matching meeting certain objectives and constraints, using both observed and predicted suitabilities (C). We first formalize the model, then discuss components (B) and (C) in more detail.\nModel Formulation We formalize our problem as\nfollows. Let r \u2208 R refer to users (e.g., reviewers, consumers, etc.), p \u2208 P to items (e.g., papers, products, other users), with |R| = N and |P| = M . Every useritem pair has a suitability score srp, the set of which forms a suitability matrix S \u2208 RN\u00d7M . Only a subset of the suitabilities are observed, namely, those elicited from users. We denote this by So, and denote the observed scores for a particular user r and item p by Sor and Sop , respectively. S u, Sur , S u p are the analogous collections of unobserved scores.\nEstimating Unobserved Scores Estimating unobserved scores given a (small) set of observed scores\u2014 together with any side-information, e.g., word vectors in submitted papers\u2014is a straightforward supervised learning task to which a variety of approaches can be applied. Conry et al. (2009), for instance, use CF to predict unknown scores in a paper matching domain. While our framework is quite general, our experiments, including those in Sec. 5 on paper matching and several other domains, suggest that Bayesian probabilistic matrix factorization (BPMF) (Salakhutdinov & Mnih, 2008a) is a very competitive CF method for matchconstrained recommendation. So we describe it here as one method, of many, that can be used.\nStandard PMF (Salakhutdinov & Mnih, 2008b) factorizes the observed score matrix, So, into two lowrank matrices, U \u2208 RN\u00d7k and V \u2208 RM\u00d7k, where k \u226a min(M,N). Unobserved scores are predicted using their product: suij is predicted to be uiv \u2032\nj . While PMF can be given a probabilistic interpretation by assuming Gaussian noise with fixed standard deviation \u03c3, BPMF provides a Bayesian extension of PMF by assuming priors on U and V . Apart from outperforming PMF on standard CF tasks, BPMF also provides a distribution over unobserved suitabilities, Pr(Su|So, \u03b8), instead of a simple point prediction.\nMatching Optimization Matching uses both observed and predicted suitability scores to assign items to users. We focus primarily on domains where constrained many-to-many matching is required, i.e., where an item is matched to multiple users and multiple users are matched to a single item. Paper matching is a prime example, where each paper needs a specific number of reviewers, and each reviewer must be assigned a number of papers within some range.\nWhile many objectives and constraints can be accommodated in our framework, we illustrate it using a simple paper matching problem. Treating self-reported interest or expertise as observed suitabilities, standard learning methods like BPMF are used to predict unobserved scores. We then formulate the matching optimization (treating predicted scores as if observed) as\nan integer program (IP) (Taylor, 2008):\nmaximize J(Y, S) = \u2211 r \u2211 p srpyrp (1)\nsubject to yrp \u2208 {0, 1}, \u2200r, p (2)\u2211 r yrp \u2265 Rmin, \u2211 r yrp \u2264 Rmax \u2200p (3)\n\u2211 p yrp \u2265 Pmin, \u2211 p yrp \u2264 Pmax, \u2200r. (4)\nHere the binary variable yrp \u2208 Y encodes the matching of item p to user r; a matching is a complete instantiation of these variables. Rmin (Rmax) is the minimum (resp. maximum) number of users per item, while Pmin (Pmax) represent the minimum (resp. maximum) user capacities. Of course, many other criteria can be incorporated into the matching optimization. While IPs of this form can quickly become intractable, the total unimodularity of the constraint matrix (Eqs. 2\u20134) allows one to use the linear programming (LP) relaxation while retaining optimality."}, {"heading": "3.2. Probabilistic Matching", "text": "While the LP optimization is straightforward, and provides optimal solutions when all scores are observed, it has potential drawbacks when used with predicted scores, and specifically, when used in conjunction with active learning. First, the LP does not consider potentially useful information contained in the uncertainty of the (predicted) suitabilities. Second, it does not express the range of possible matches that might optimize total suitability (given the constraints).\nWhile optimal matching given true scores can be viewed as a deterministic process, score prediction is inherently stochastic; and we can exploit this if our prediction model outputs a distribution over unobserved scores Su rather than a point estimate. Given inputs consisting of observed scores So and possibly additional side-information X, we can express our uncertainty over the optimal matching as:\nPr(Y |So, X, \u03b8) = \u222b Y (Su, So) Pr(Su|So, X, \u03b8) dSu, (5)\nwhere Pr(Su|So, X, \u03b8) is our score prediction model (assuming model parameters \u03b8), and Y (\u00b7) (see Eq. 1) is the optimal matching given a fixed set of scores.\nWith this in hand, we overcome the limitations of pure LP-based optimization by developing a sampling method for determining \u201csoft\u201d or probabilistic matchings that reflect the range of optimal matchings given uncertainty in predicted suitabilities. While Eq. 5 expresses the induced distribution over optimal matchings, the integral is intractable as it requires solving a large number of matching problems (e.g., LPs). Instead we take a sampling approach: we independently\nsample each score from the posterior Pr(Su|So, X, \u03b8) to build a complete score matrix, then solve the matching optimization (LP) using this sampled matrix. Repeating this process T times provides an estimated distribution over optimal matchings. We can then average the resulting match matrices, obtaining Y = 1 T \u2211T t=1 Y (t). Each entry Y rp is the (estimated) probability that user-item pair rp is matched; and the probability of this match depends, as desired, on the distribution Pr(srp|S o, X, \u03b8).\nFig. 2 illustrates Y , comparing it to the LP solution, on a randomly-generated \u201ctoy\u201d problem with 3 reviewers and 6 papers (1 reviewer per paper, 2 papers per reviewer). Assuming a fixed predicted score matrix S, two versions of Y are shown, one when all estimated variances are low, the other when they are higher.1 Note that the Y matrices respect the matching constraints by design (for visualization purposes we round matching probabilities). With low variances, Y agrees with the LP, but with higher variances, we observe the inherent uncertainty in the optimal matching; e.g., column one shows all three match probabilities to be reasonably high. In addition, the last column shows that even though the second and third users have scores that differ by 2, the high variance in their scores gives both users a reasonable probability of being matched."}, {"heading": "4. Active Querying for Matching", "text": "Since it is impractical to elicit or otherwise observe the preferences of all users for all items, supervised learning, as discussed above, can be used to effectively estimate unobserved suitabilities for match-constrained recommendation (Conry et al., 2009; Charlin et al., 2011). However, little work has considered strategies for actively querying the \u201cmost informative\u201d preferences from users, thus further reducing the elicitation burden on users. Random selection of user-item pairs for assessment will generally be sub-optimal, since query selection is uninformed by the learned model, the objective function, or any previous data. By con-\n1Variances are sampled uniformly at random; in a real problem they would be given by the prediction model.\ntrast, an active approach, in which queries are tailored to both the current preference model and the current best matching, will typically give rise to better matchings with fewer queries.2\nIn this section we describe several distinct strategies for query selection: we review a standard active learning technique and introduce several novel methods that are sensitive to the matching objective. Our methods can be broadly categorized based on two properties: whether they evaluate in score space S or matching space Y ; and whether they select queries with the maximal value M, or maximal entropy E.\nScore Entropy (SE): Uncertainty sampling is a common approach in active learning, which greedily selects queries involving (unobserved) user-item pairs for which the model is most uncertain (Settles, 2009). In our context, this corresponds to selecting the user-item pair with maximum score entropy w.r.t. the score distribution produced by the learned model. The rationale is clear: uncertainty in score predictions may lead to poor estimates of match quality. Of course, this approach fails to explicitly account for the matching objective (the term Y (Su, So) in Eq. 5), instead focusing (myopically) on entropy reduction in the predictive model (the term Pr(Su|So, X, \u03b8)).\nScore Max (SM): An alternative, simple strategy is to select queries involving user-item pairs with highest predicted score w.r.t. MAP score estimates given our predictions of unobserved scores: S\u0302u \u2261 argmaxSu Pr(S\nu|So, X, \u03b8). This may be especially advantageous for matching problems where scores for matched user-item pairs contribute an amount equal to their value in the matching objective (see Eq. 1).\nAn obvious shortcoming of both SE and SM is their insensitivity to the matching objective. Queries that reduce prediction entropy may have no influence on the resulting matching (e.g., if surp has high entropy, but a much lower mean than some \u201ccompeting\u201d sur\u2032p, user r\u2032 may remain matched to p with high probability regardless of the response to query rp). One remedy is to use expected value of information (EVOI) to measure the improvement in matching quality given the response to a query (taking expectation over predicted responses). This approach has been used effectively in (non-constrained) CF (Boutilier et al., 2003); but EVOI is notoriously hard to evaluate. In our context, we would (in principle) have to consider each possible query rp, estimate the impact of each possible response sorp on the learned model (the term Pr(S u|So, X, \u03b8) in\n2In our settings one can elicit a rating or suitability score from a user for any item (e.g., paper, date, joke); so the full set Sur serves as potential queries for user r.\nEq. 5), and re-solve the estimated matching (the term Y (Su, So) in Eq. 5). Instead, we consider several more tractable strategies.\nY -Max (YM): A simple way to select queries in a match-sensitive fashion is to consider the solution returned by the LP w.r.t. the observed scores, So, and the MAP solution of the unobserved scores, S\u0302u. We query the unknown pair rp that contributes the most to the value of the objective: argmax(rp)\u2208Su yrps\u0302rp, where yrp \u2208 Y (S o, S\u0302u) is the binary match value for user r and item p, and srp the corresponding MAP score value. In other words, we query the unobserved pair among those actually matched with the highest predicted score. We refer to this strategy as Y-Max (YM). It reflects the intuition that we should either confirm or refute scores for matched pairs, i.e., those pairs that, under the current model, that directly determine the value of the matching objective. However, YM is insensitive to score uncertainty.\nY -Max (YM)): This method exploits our probabilistic matching model to select queries. As with YM, YM queries the unobserved pair rp that contributes the most to the objective value: argmax(rp)\u2208Su Y rps\u0302rp. The difference is that we use the probabilistic match, exploiting prediction uncertainty in query selection.\nY -Entropy (Y E): This method exploits the probabilistic match Y as well, but unlike YM, Y E queries unknown pairs whose entropy in the match distribution is greatest. Specifically, we view each Yrp as a Bernoulli random variable with (estimated) success probability Y rp. We then query that pair with maximum match entropy: argmax(rp)\u2208Su [ \u2212 Y rp log Pr(Y rp) \u2212 (1\u2212 Y rp) log Pr(1\u2212 Y rp) ] .\nOne important point to note is that the matchsensitive strategies, YM, YM, Y E, all attempt to query unobserved pairs that occur (possibly stochastically) in the optimal match. When the LP does not match on any unobserved pairs, a fall-back strategy is needed. All three strategies resort to random querying as a fall-back, selecting a random unobserved item score for any specific user as its query. For YM and Y E, we refer to any query that corresponds to a useritem pair with less than a 1% chance of being matched as a \u201crandom\u201d query."}, {"heading": "5. Experiments", "text": "We test the active learning approaches described above on three data sets, each with very different characteristics. We begin with a brief description of the data sets and matching tasks, then describe our experimental setup, before proceeding to a discussion of our results.\nData sets We first describe our three data sets and define the corresponding matching tasks.\nJokes data set: The Jester data set (Goldberg et al., 2001) is a standard CF data set in which over 60,000 users have each rated a subset of 100 jokes on a scale of -10 to 10. It has a dense subset in which all users rate ten common jokes. Our experiments use a data set consisting of these ten jokes and 300 randomly selected users. We convert this to a matching problem by requiring the assignment of a single joke to each user (e.g., to be told at a convention or conference), and requiring that each joke be matched to between 25 and 35 users (to ensure jocular diversity at the convention). Fig. 3(a) provides a histogram of the suitabilities for the Jester sub-data set.\nConference data set: This data is derived from the NIPS 2010 conference. It contains suitability scores for 1251 paper submissions provided for 48 area chairs (henceforth, reviewers). Scores range from 0 (\u201cpaper lies outside my expertise\u201d) to 3 (\u201cvery qualified to review\u201d). Suitabilities for a subset of papers were elicited in two rounds. In the first round scores were elicited for about 80 papers per reviewer, with queries selected using the YM procedure described above (where the initial scores were estimated using a simple language model (Balog et al., 2006) using reviewers\u2019 published papers). In the second round, unobserved scores were estimated using both the language model and a restricted Boltzmann machine (RBM) trained on the first-round scores and paper word-frequency vectors. Each reviewer was queried about 143 papers on average (excluding one outlier), and each paper received an average of 3.3 suitability assessments (std. dev. 1.3). The mean suitability score was 1.14 (std. dev. 1.1); a histogram of scores is shown in Fig. 3(b). Each paper was then assigned to one reviewer, and each reviewer received 20\u201330 papers.\nDating data set: The third data set comes from an online dating website (see http://www.occamslab.com/petricek/data/). It contains over 17 million ratings from roughly 135,000 users of 168,000 items (other users). We use a denser subset of 32,000 ratings from 250 users (each with at least 59 ratings) over 250 items (other users); see Fig. 3(c). Since items are users with preferences over their matches, dating is generally treated as a two-sided problem. While two-sided matching can fit within our general framework, the focus of our current work is on one-sided matching. As such, we only consider user preferences for \u201citems\u201d and not vice versa. Each user is assigned 25\u201335 items (and vice versa since \u201citems\u201d are users)."}, {"heading": "5.1. Experimental Procedures", "text": "Our experiments simulate the typical interaction of a recommendation or matching engine with its users. All experiments start with a few observed preferences for each user and go through several rounds of querying. At each round, a querying strategy selects queries to ask one or more users. Note that in practice we restrict the strategies to only query (unobserved) scores available in our data sets. Once all users have responded, the system re-trains the learning model with newly and previously observed preferences, then proceeds to select the next batch of queries. This is a somewhat simplified model that assumes semi-synchronous user communication. We also assume for simplicity that the same fixed number of queries per user is asked in each round. The initial goal is simply to assess the relative performance of each method; we do relax some of these assumptions in Sec. 5.2.\nThere are a variety of reasonable interaction modes for eliciting user preferences. For example, in paperreviewer matching, posing a single query per round is undesirable, since a reviewer, after assessing a single paper, must wait for other reviewer responses\u2014and the system to re-train\u2014before being asked a subsequent query. Reviewers generally prefer to assess their expertise off-line w.r.t. a collection of papers. Consequently batch interaction is most appropriate where, at each round, users are asked to assess K items. While batch frameworks for active learning have received recent attention (e.g., (Guo & Schuurmans, 2007)), here we are interested in comparing different query strategies, hence use a very simple greedy batch approach where we elicit the \u201ctop\u201d K preferences from a user, where the \u201ctop\u201d queries are ranked by the specific active strategy under consideration. Appropriate choice of K is application dependent: smaller values of K may lead to better recommendations with fewer queries, but require more frequent user interaction and user delay. We test different values of K below.\nWe use BPMF to generate our predictions and its uncertainty model for unobserved scores. A procedure for setting some of the hyper-parameters of BPMF is outlined in (Salakhutdinov & Mnih, 2008a). We use a validation set for the other methods giving (using notation from the original paper) Jokes:\nD = 1, \u03b1 = 0.1, \u03b20u = 0.1, \u03b20v = 10; Conference: D = 15, \u03b1 = 2, \u03b20u = \u03b20v = 0.1; and Dating: D = 2, \u03b1 = 2, \u03b20u = \u03b20v = 0.1. Each observed score is assigned a fixed small uncertainty value of 1e\u22123. For Y -based methods, which require sampling, we use 50 samples in all experiments.\nWe compare query selection methods w.r.t. their matching performance\u2014i.e., the matching objective value of Eq. 1\u2014using the match matrix given by the LP using estimated scores and known scores So, evaluated on the full set of available scores. We use a random querying strategy, which selects unobserved items uniformly at random for each user, as a baseline. All figures show the number of queries per user on the x-axis. The y-axis indicates the difference in the matching objective value between a specific querying strategy and the baseline. Positive differences indicate better performance relative to the baseline. The magnitude of this difference can be best understood relative to the number of users in the data set. For example, a difference of 300 in objective value for the 300 users in the Jokes data set means that users are better by one \u201cscore unit\u201d on average. Note that as we increase the number of queries, even random queries will eventually find good matches\u2014in the limit, where all scores are observed, matching performance of all methods will be identical (hence the bell-shape curves and asymptotic convergence in our results).\nWe don\u2019t focus on running time in our experiments since query determination can often be done off-line (depending on batch sizes). Having said that, even the most intense querying techniques are fast and can support online interaction: (a) in all 3 data sets, solving the LP takes a fraction of a second; (b) BPMF can be trained in a matter of a few minutes at most, but can be run asynchronously with query selection (which will use the most \u201cup-to-date\u201d learned model available); and (c) sampling scores is very fast as the posterior distribution is Gaussian. Furthermore, given the above, our methods should scale to larger datasets although the training time of BPMF may preclude fully online interaction."}, {"heading": "5.2. Results", "text": "We first investigate the performance of the different querying strategies on our three data sets using default batch sizes\u2014these K values were deemed to be natural given the domains (different K values are discussed below). Fig. 4(a) shows results for Jokes using batches of 10 queries per user per round (K = 10). Figs. 4(b) and (c) show Conference and Dating results, respectively, both with a batch size of 20. All users start\nwith 20 observed scores: 15 are used for training and 5 for validation. We also experimented with a more realistic setting where some users have few observed scores (e.g., new users)\u2014results are qualitatively very similar.\nThe relative performance of each of the active methods exhibits a fairly consistent pattern across all three domains, which permit us to draw some reasonably strong conclusions.3 First, we see that all methods except for SE outperform the baseline in all domains. Recall that SE is essentially uncertainty sampling, a classic (match-insensitive) active learning model often used as a general baseline method for active learning. It outperforms the random baseline only occasionally, most significantly after the first round of elicitation in Dating. Second, all of our proposed match-sensitive techniques outperform SE consistently on all data sets. Third, the match-sensitive approaches that leverage uncertainty over scores, namely, YM and Y E, typically outperform YM, especially after the initial rounds of elicitation. This difference in performance behavior is most pronounced in the Conference domain.\nWe gain further insight into these results by examining the inner workings of these strategies. The overlay in Figs. 4(a\u2013c) show the number of random (or fallback) queries used (on average) by each of YM, YM and Y E. On all data sets YM resorts to the fall-back strategy significantly earlier than the others, explaining YM\u2019s fall-off in performance and indicating that the diversity of potential matches identified by our probabilistic matching technique plays a vital role in match-sensitive active learning.\nFinally, when considering the performance of these\n3We do not report the performance of SM\u2014 it is consistently outperformed by the baseline in all experiments. We have observed that SM typically selects all queries from among only a few items, namely, those with high predicted average score; hence it acquires no information about the vast majority of items.\nmethods on score prediction, we found no correlation between score prediction and matching performance. This further highlights the benefit of matchconstrained active learning methods.\nSequential Querying We employed a semisynchronous querying procedure above, where all users are queried in parallel at each round. We now consider a different mode of interaction where, at each round, users are queried sequentially in round robin fashion. This allows the responses of earlier users within a round to influence the queries asked to later users\u2014 potentially reducing the total number of queries at the expense of increased synchronization (and delay) among users. Fig. 5(a) shows that our methods are robust to this modification in the querying procedure.\nBatch Sizes The choice of the number of queries K per batch affects both the frequency with which the user interacts with the system as well as the overall match performance. For example, high values of K reduce the number of user \u201cinteractions\u201d needed for a specific level of performance, at the expense of query efficiency (improvement in matching objective per query). The \u201coptimal\u201d value for K depends on the actual recommendation application. Figs. 5(b) and (c) shows results with different values of K on Conference, using 10 and 40 queries per round, respectively. The relative performance of the active methods remains almost identical. As expected, absolute performance w.r.t. query efficiency is better with smaller values of K. The matching-sensitive strategies clearly outperform the score-based techniques. Results are similar across all data sets.\nMatching constraints Our results are also robust to different matching constraints, specifically, bounds on the numbers of items per user and vice versa (i.e., Rmin, Rmax, Pmin, Pmax). Using the Conference data set, we increase to two (from one) the number of reviewers assigned to each paper. Fig. 5(d) shows that the behavior of the methods changes little, with both\nY -methods still outperforming all other methods. The other domains (not shown) exhibit similar results."}, {"heading": "6. Conclusion", "text": "We investigated the problem of active learning for match-constrained recommendation systems. We explored several different approaches to generating queries that are guided by the matching objective, and introduced a novel method for probabilistic matching that accounts for uncertainty in predicted scores. Experiments demonstrate the effectiveness of our methods in determining high-quality matches with significantly less elicitation of user preferences than that required by uncertainty sampling, a standard active learning method. Our results highlight the importance of choosing queries in a manner that is sensitive to the matching objective and uncertainty over predicted scores.\nThere are many promising avenues of future research in match-constrained recommendation. We are currently exploring different matching objectives (e.g., two-sided matching with stability constraints) and methods for eliciting side-information from users in a way that is guided by the recommendation objective. Finally, higher-level, abstract queries (such as preferences over item categories or features) may significantly boost \u201cgain per query\u201d performance."}], "references": [{"title": "Formal models for expert finding in enterprise", "author": ["K. Balog", "L. Azzopardi", "M. de Rijke"], "venue": "corpora. SIGIR-06,", "citeRegEx": "Balog et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Balog et al\\.", "year": 2006}, {"title": "A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. TR-2009-23", "author": ["E. Brochu", "V.M. Cora", "N. de Freitas"], "venue": "CS, UBC,", "citeRegEx": "Brochu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Brochu et al\\.", "year": 2009}, {"title": "A framework for optimizing paper", "author": ["L. Charlin", "R. Zemel", "C. Boutilier"], "venue": "matching. UAI-11,", "citeRegEx": "Charlin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Charlin et al\\.", "year": 2011}, {"title": "Recommender systems for the conference paper assignment", "author": ["D. Conry", "Y. Koren", "N. Ramakrishnan"], "venue": "problem. RecSys\u201909,", "citeRegEx": "Conry et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Conry et al\\.", "year": 2009}, {"title": "College admissions and the stability of marriage", "author": ["D. Gale", "L.S. Shapley"], "venue": "Amer. Math. M.,", "citeRegEx": "Gale and Shapley,? \\Q1962\\E", "shortCiteRegEx": "Gale and Shapley", "year": 1962}, {"title": "Using collaborative filtering to weave an information tapestry", "author": ["D. Goldberg", "D. Nichols", "B.M. Oki", "D. Terry"], "venue": "Comm. ACM,", "citeRegEx": "Goldberg et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 1992}, {"title": "Eigentaste: A Constant Time Collaborative Filtering Algorithm", "author": ["K. Goldberg", "T. Roeder", "D. Gupta", "C. Perkins"], "venue": "Inf. Retr,", "citeRegEx": "Goldberg et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 2001}, {"title": "Discriminative batch mode active", "author": ["Y. Guo", "D. Schuurmans"], "venue": "learning. NIPS-07,", "citeRegEx": "Guo and Schuurmans,? \\Q2007\\E", "shortCiteRegEx": "Guo and Schuurmans", "year": 2007}, {"title": "Personalized active learning for collaborative", "author": ["A. Harpale", "Y. Yang"], "venue": "filtering. SIGIR-08,", "citeRegEx": "Harpale and Yang,? \\Q2008\\E", "shortCiteRegEx": "Harpale and Yang", "year": 2008}, {"title": "The efficient allocation of individuals to positions", "author": ["A. Hylland", "R.J. Zeckhauser"], "venue": "Journal of Political Economy,", "citeRegEx": "Hylland and Zeckhauser,? \\Q1979\\E", "shortCiteRegEx": "Hylland and Zeckhauser", "year": 1979}, {"title": "A Bayesian approach toward active learning for collaborative", "author": ["R. Jin", "L. Si"], "venue": "filtering. UAI-04,", "citeRegEx": "Jin and Si,? \\Q2004\\E", "shortCiteRegEx": "Jin and Si", "year": 2004}, {"title": "The BellKor solution to the Netflix grand prize", "author": ["Y. Koren"], "venue": "www.netflixprize.com/assets/GrandPrize2009 BPC BellKor.pdf, August,", "citeRegEx": "Koren,? \\Q2009\\E", "shortCiteRegEx": "Koren", "year": 2009}, {"title": "Being accurate is not enough: how accuracy metrics have hurt recommender systems", "author": ["S.M. McNee", "J. Riedl", "J.A. Konstan"], "venue": null, "citeRegEx": "McNee et al\\.,? \\Q2006\\E", "shortCiteRegEx": "McNee et al\\.", "year": 2006}, {"title": "Expertise modeling for matching papers with reviewers", "author": ["D.M. Mimno", "A. McCallum"], "venue": null, "citeRegEx": "Mimno and McCallum,? \\Q2007\\E", "shortCiteRegEx": "Mimno and McCallum", "year": 2007}, {"title": "An iterative rating method: application to webbased conference", "author": ["P. Rigaux"], "venue": "management. SAC-04,", "citeRegEx": "Rigaux,? \\Q2004\\E", "shortCiteRegEx": "Rigaux", "year": 2004}, {"title": "An algorithm to determine peer-reviewers", "author": ["M.A. Rodriguez", "J. Bollen"], "venue": "CIKM\u201908, pp.319\u2013328,", "citeRegEx": "Rodriguez and Bollen,? \\Q2008\\E", "shortCiteRegEx": "Rodriguez and Bollen", "year": 2008}, {"title": "The evolution of the labor market for medical interns and residents: A case study in game theory", "author": ["A.E. Roth"], "venue": "J. Political Economy,", "citeRegEx": "Roth,? \\Q1984\\E", "shortCiteRegEx": "Roth", "year": 1984}, {"title": "Bayesian probabilistic matrix factorization using Markov chain", "author": ["R. Salakhutdinov", "A. Mnih"], "venue": "Monte Carlo. ICML-08,", "citeRegEx": "Salakhutdinov and Mnih,? \\Q2008\\E", "shortCiteRegEx": "Salakhutdinov and Mnih", "year": 2008}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "Computer Sciences TR-1648, Univ. Wisconsin-Madison,", "citeRegEx": "Settles,? \\Q2009\\E", "shortCiteRegEx": "Settles", "year": 2009}, {"title": "On the optimal assignment of conference papers to reviewers", "author": ["C.J. Taylor"], "venue": "TR MS-CIS-08-30, UPenn,", "citeRegEx": "Taylor,? \\Q2008\\E", "shortCiteRegEx": "Taylor", "year": 2008}, {"title": "COFI RANK \u2013 Maximum margin matrix factorization for collaborative", "author": ["M. Weimer", "A. Karatzoglou", "Q. Le", "A. Smola"], "venue": "ranking. NIPS-07,", "citeRegEx": "Weimer et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Weimer et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 5, "context": "Collaborative filtering (CF) methods (Goldberg et al., 1992) have proven especially popular and have attained impressive performance (Koren, 2009).", "startOffset": 37, "endOffset": 60}, {"referenceID": 11, "context": ", 1992) have proven especially popular and have attained impressive performance (Koren, 2009).", "startOffset": 80, "endOffset": 93}, {"referenceID": 12, "context": "The same retailer may wish to facilitate serendipitous purchases by ensuring items recommended to any single user are diverse (McNee et al., 2006).", "startOffset": 126, "endOffset": 146}, {"referenceID": 3, "context": ", number of papers per reviewer, number of reviewers per paper) (Conry et al., 2009; Charlin et al., 2011).", "startOffset": 64, "endOffset": 106}, {"referenceID": 2, "context": ", number of papers per reviewer, number of reviewers per paper) (Conry et al., 2009; Charlin et al., 2011).", "startOffset": 64, "endOffset": 106}, {"referenceID": 16, "context": "Classic examples include stable marriages and college admissions (Gale & Shapley, 1962), medical resident to hospital matching (Roth, 1984) and (one-sided) housing markets (Hylland & Zeckhauser, 1979).", "startOffset": 127, "endOffset": 139}, {"referenceID": 5, "context": "CF is, of course, a prime example (Goldberg et al., 1992).", "startOffset": 34, "endOffset": 57}, {"referenceID": 3, "context": "Recent work on reviewer-paper matching\u2014 a domain we consider here\u2014includes work using coauthorship graphs (Rodriguez & Bollen, 2008), language and topic models (Mimno & McCallum, 2007), and CF (Conry et al., 2009; Charlin et al., 2011).", "startOffset": 193, "endOffset": 235}, {"referenceID": 2, "context": "Recent work on reviewer-paper matching\u2014 a domain we consider here\u2014includes work using coauthorship graphs (Rodriguez & Bollen, 2008), language and topic models (Mimno & McCallum, 2007), and CF (Conry et al., 2009; Charlin et al., 2011).", "startOffset": 193, "endOffset": 235}, {"referenceID": 18, "context": ", see (Settles, 2009) (A)", "startOffset": 6, "endOffset": 21}, {"referenceID": 14, "context": "Rigaux (2004) considers an iterative elicitation method for paper matching using neighborhood CF, but requires an initial partitioning of reviewers, and elicits scores (with the aim only of improving score prediction quality) for the same papers from all reviewers in a partition.", "startOffset": 0, "endOffset": 14}, {"referenceID": 1, "context": "nally, Bayesian optimization has been used for active learning recently (Brochu et al., 2009); however, these methods assume a continuous query space and some similarity metric over item space, hence are not readily adaptable to our match-constrained problems.", "startOffset": 72, "endOffset": 93}, {"referenceID": 3, "context": "In this section, we describe a general framework for exploiting learning in match-constrained recommendation, adopting the model and principles used in recent work on paper matching (Conry et al., 2009; Charlin et al., 2011).", "startOffset": 182, "endOffset": 224}, {"referenceID": 2, "context": "In this section, we describe a general framework for exploiting learning in match-constrained recommendation, adopting the model and principles used in recent work on paper matching (Conry et al., 2009; Charlin et al., 2011).", "startOffset": 182, "endOffset": 224}, {"referenceID": 3, "context": "Conry et al. (2009), for instance, use CF to predict unknown scores in a paper matching domain.", "startOffset": 0, "endOffset": 20}, {"referenceID": 19, "context": "We then formulate the matching optimization (treating predicted scores as if observed) as an integer program (IP) (Taylor, 2008):", "startOffset": 114, "endOffset": 128}, {"referenceID": 3, "context": "Since it is impractical to elicit or otherwise observe the preferences of all users for all items, supervised learning, as discussed above, can be used to effectively estimate unobserved suitabilities for match-constrained recommendation (Conry et al., 2009; Charlin et al., 2011).", "startOffset": 238, "endOffset": 280}, {"referenceID": 2, "context": "Since it is impractical to elicit or otherwise observe the preferences of all users for all items, supervised learning, as discussed above, can be used to effectively estimate unobserved suitabilities for match-constrained recommendation (Conry et al., 2009; Charlin et al., 2011).", "startOffset": 238, "endOffset": 280}, {"referenceID": 18, "context": "Score Entropy (SE): Uncertainty sampling is a common approach in active learning, which greedily selects queries involving (unobserved) user-item pairs for which the model is most uncertain (Settles, 2009).", "startOffset": 190, "endOffset": 205}, {"referenceID": 6, "context": "Jokes data set: The Jester data set (Goldberg et al., 2001) is a standard CF data set in which over 60,000 users have each rated a subset of 100 jokes on a scale of -10 to 10.", "startOffset": 36, "endOffset": 59}, {"referenceID": 0, "context": "In the first round scores were elicited for about 80 papers per reviewer, with queries selected using the YM procedure described above (where the initial scores were estimated using a simple language model (Balog et al., 2006) using reviewers\u2019 published papers).", "startOffset": 206, "endOffset": 226}], "year": 2012, "abstractText": "Effective learning of user preferences is critical to easing user burden in various types of matching problems. Equally important is active query selection to further reduce the amount of preference information users must provide. We address the problem of active learning of user preferences for matching problems, introducing a novel method for determining probabilistic matchings, and developing several new active learning strategies that are sensitive to the specific matching objective. Experiments with real-world data sets spanning diverse domains demonstrate that matching-sensitive active learning outperforms standard techniques.", "creator": "LaTeX with hyperref package"}}}