{"id": "1301.2012", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Error Correction in Learning using SVMs", "abstract": "This paper is concerned with learning binary classifiers under adversarial label-noise. We introduce the problem of error-correction in learning where the goal is to recover the original clean data from a label-manipulated version of it, given (i) no constraints on the adversary other than an upper-bound on the number of errors, and (ii) some regularity properties for the original data. We present a simple and practical error-correction algorithm called SubSVMs that learns individual SVMs on several small-size (log-size), class-balanced, random subsets of the data and then reclassifies the training points using a majority vote. Our analysis reveals the need for the two main ingredients of SubSVMs, namely class-balanced sampling and subsampled bagging. Experimental results on synthetic as well as benchmark UCI data demonstrate the effectiveness of our approach. In addition to noise-tolerance, log-size subsampled bagging also yields significant run-time benefits over standard SVMs.", "histories": [["v1", "Thu, 10 Jan 2013 00:47:21 GMT  (608kb,D)", "http://arxiv.org/abs/1301.2012v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["srivatsan laxman", "sushil mittal", "ramarathnam venkatesan"], "accepted": false, "id": "1301.2012"}, "pdf": {"name": "1301.2012.pdf", "metadata": {"source": "CRF", "title": "Error Correction in Learning using SVMs", "authors": ["Srivatsan Laxman", "Sushil Mittal", "Ramarathnam Venkatesan"], "emails": ["slaxman@microsoft.com", "mittal@stat.columbia.edu", "venkie@microsoft.com"], "sections": [{"heading": "1. Introduction", "text": "Learning in the presence of noise is notoriously difficult; there are many negative results regarding hardness of learning under adversarial or malicious noise Ben-David et al. (2003); Feldman et al. (2006); Guruswami and Raghavendra (2006); Hastad (1997); Kearns et al. (1994); Long and Servedio (2011), while positive results are mostly known only for the case of random noise or under strong distributional assumptions Blum et al. (1996); Kalai et al. (2008); Sastry et al. (2010); Servedio (2003). Somewhat more encouraging results exist in max-margin settings Buja and Stuetzle (2000); Har-peled et al. (2006); Shalev-Shwartz et al. (2010); Xu et al. (2006) but these methods are computationally prohibitive even for reasonably-sized data.\nIn this paper, we investigate the learning of binary classifiers under adversarial (worstcase) label-noise. We introduce the problem of error-correction in learning, as the task\nar X\niv :1\n30 1.\n20 12\nv1 [\ncs .L\nof correcting the label-errors in training data, D\u0302, given that the original (clean) data, D, intrinsically satisfies some regularity properties. (Given negative results such as Guruswami and Raghavendra (2006) regarding the hardness of learning better-than-random hyperplanes even from nearly-separable data, some notion of regularity becomes essential). Informally, D is said to be r-regular if SVMs trained on very small random r-subsets of D, make less than \u03b8-fraction errors over all of D. We show that every linearly separable D exhibits some regularity, and that such a D can be recovered from any D\u0302 with roughly (12\u22122\u03b8\u2212O(log\n2 r))fraction of errors. The main idea in our analysis is to apply margin-based generalization bounds under a chosen sampling distribution over D and to then adjust the bounds for the noise in D\u0302. To the best of our knowledge, this is the first positive result that is known about learning classifiers under adversarial label-errors.\nOur algorithm for error-correction, called SubSVMs (Subsample bagging of SVMs) is as follows: Train SVMs on suitably-small, class-balanced, random subsets of D\u0302 and reclassify every training point using a simple majority vote. We show that class-balanced sampling over D\u0302 minimizes the worst-case probability of drawing less than any-chosen-number of clean points per class from D\u0302. The number of worst-case errors that each SVM in the ensemble makes can grow as the squared-log of the subsample-size used, and this leads us to the final error-correction performance of SubSVMs.\nIn experimental work, we first study the error-correction achievable on synthetic linearly separable data. By comparing against performance under uniform sampling (common in standard bagging) we show that class-balanced sampling plays a vital role in errorcorrection. Then we show that error-correction based on SubSVMs leads to better classifiers which outperform regular SVMs on a range of benchmark data sets from the UCI Machine Learning Repository. Our experiments also clearly demonstrate superiority of SubSVMs over regular bagging. We inject high-levels of label-noise in the training data sets (Number of errors was fixed at 75% of the size of the minority class). On previously unseen (clean) test sets, SubSVMs even outperformed SVMs that directly used the full test sets for cross-validation. Subsampling at logarithmic sizes also gives SubSVMs substantial run-time advantages over standard SVMs and regular bagging.\nRelated Work: Several results show that learning under adversarial noise can be NPhard Hastad (1997); Kearns et al. (1994); Feldman et al. (2006); Guruswami and Raghavendra (2006). Better results (polynomial-time algorithms) are known in the context of learning max-margin classifiers from noisy data Har-peled et al. (2006); Shalev-Shwartz et al. (2010); Xu et al. (2006). However, these techniques are computationally prohibitive in practice, e.g., the method proposed in Xu et al. (2006) uses SDP solvers that can become impractical even for a hundred training points. Many boosting algorithms, with convex potential functions, have also been shown vulnerable to random classification noise Long and Servedio (2010).\nIn statistical (rather than adversarial) settings, generalization results for SVMs demonstrate efficient learnability when training and test points are drawn iid from the same (even if noisy) distribution Christianini and Shawe-Taylor (2000). Some works have focused on the ineffectiveness of SVMs in the presence of outliers and for noisy class-imbalanced data (e.g., see Akbani et al. (2004); Trafalis and Gilbert (2005); Nath and Bhattacharyya (2007)), albeit without formal analysis. Recently, large-margin half-spaces were shown to be efficiently learnable under small amounts of malicious noise Long and Servedio (2011).\nSimilarly, Dekel and Shamir (2009) demonstrates learning from multi-teacher data, where a small number of teachers can replace randomly chosen examples arbitrarily. A general framework for distribution-dependent learning in-the-limit was proposed in Caramanis and Mannor (2008); the focus, however, was on establishing informational limits rather than sample complexities. We consider learning under adversarial label-errors given that the original data satisfies some regularity properties. Our error-model is relevant both when the label-errors are inadvertent, whether systematic or random, and when errors are introduced by an adversary explicitly trying to mislead the learning process.\nSeveral studies investigated why (and under what conditions) bagging works by formalizing different notions of stability for predictors and by showing that bagging reduces the variance of unstable predictors (see, e.g., Breiman (1996); Buhlmann and Yu (2002); Elisseeff et al. (2005); Grandvalet (2004)). Experimental bias-variance analysis of random aggregation and bagging of SVMs demonstrated that working with small samples achieves greater reduction in the variance component of error than standard bagging (see Valentini (2004)). In another related work, Brodley and Friedl (1999) presented an experimental study of various methods for identifying mislabeled data. All these studies, including the ones that analyze bagging, restricted attention to distribution-based models, rather than adversarial settings."}, {"heading": "2. Error correction problem in learning", "text": "Let D = {(xi, yi) : i = 1, . . . , `} be the set of examples in a binary classification problem; the feature vectors, xi, come from some domain X and the class-labels, yi, take values from {\u22121,+1}. The proportion of minority class points in D is denoted \u03b2, 0 < \u03b2 \u2264 0.5.\nLet \u03a8D denote a binary SVM classifier trained on D 1; for x \u2208 X , the classifier returns the label \u03a8D(x) \u2208 {\u22121,+1}. We assume that \u03a8D is suitable for the given classification task. However, D is not available to train the learning algorithm. Instead, the learner only has access to D\u0302 = {(xi, y\u0302i) : i = 1, . . . , `}, which is a label-manipulated version of D2.\nThe adversary is allowed to flip labels of no more than \u03c1\u03b2` examples in D, where \u03c1 is referred to as the error parameter. Since we place no other restrictions on the points the adversary can manipulate, we must have the constraint 0 \u2264 \u03c1 < 1 (otherwise, we may be left with no training examples for one class).\nThe error-correction problem is concerned with recovering the original clean data D (or a close approximation of it) from its label-manipulated version D\u0302. To this end, we will allow some \u2018regularity\u2019 assumptions on the original data D, which essentially guarantee that SVMs trained on sufficiently-small random subsets of D can classify the points in D with high accuracy. Regularity is an intrinsic property of the original data, which can manifest and be measured in many ways; one way is to measure the redundancy structure exposed by the quadratic program underlying the max-margin formulation of SVMs.\nDefinition 1 (Data Regularity) Let D\u2217 be any (discrete) probability distribution over D and let S \u223c D\u2217, |S| \u2265 r, denote a collection of points drawn iid from D\u2217. For any \u03b4 < 0.5 and \u03b8 < 0.5, D is said to be r-regular at (\u03b4, \u03b8) if with probability at least 1\u2212 \u03b4 over choice\n1. \u03a8S denotes the SVM trained on S, etc. 2. D\u0302 is also referred to as the corrupted or noisy data.\nof S, the expected error-rate of \u03a8S does not \u03b8 with respect to test examples also drawn iid from D\u2217.\nWe are interested in regularity at small r, such as at O(log `) or O(log2 `). Data regularity can be thought of as a measure of redundancy needed to admit learning in the presence of adversarial label-noise. This is, in a sense, akin to the redundancy encoded into a message for enabling error-correction in coding theory. Regularity is a simple property that is satisfied by data from which good binary classifiers can be easily learnt, e.g., every linearly separable data set is regular.\nLemma 2 (Separability implies Regularity) Consider any linearly separable D with margin \u03b3. For any fixed \u03b4 < 0.5 and \u03b8 < 0.5, there exists r \u2208 Z+ such that D is r-regular at (\u03b4, \u03b8).\nThe proof makes use of the following 2-norm soft-margin bound from SVM generalization theory Christianini and Shawe-Taylor (2000):\nTheorem 3 (Christianini and Shawe-Taylor, 2000, Theorem 4.22) Consider thresholding real-valued linear functions L with unit weight vectors on an inner product space X and fix \u03b3 \u2208 R+. There is a constant c, such that for any probability distribution D on X \u00d7{\u22121,+1} with support in a ball of radius R around the origin, with probability 1 \u2212 \u03b4 over ` random (training) examples D = {(x1, y1), . . . , (x`, y`)}, any hypothesis f \u2208 L has error no more than\nPr (x,y)\u223cD [f(x) 6= y] \u2264 c `\n( R2 + \u2016\u03be\u201622\n\u03b32 log2 `+ log\n1\n\u03b4\n) (1)\nwhere \u03be = (\u03be1, . . . , \u03be`) is the margin slack vector with respect to f and \u03b3. The entries of \u03be are fixed as follows: \u03bei = max(0, \u03b3 \u2212 yif(xi)), i = 1, . . . , `.\nSince D is separable with margin \u03b3, every subset of D is also separable with margin at least \u03b3. Thus, the max-margin separator of every subset of D will have margin slack vector \u03be = 0 (with respect to the chosen subset). Fixing D = D\u2217 in Theorem 3, the generalization error of \u03a8S trained on any S \u223c D\u2217, |S| = r, is given by\nPr (x,y)\u223cD\u2217\n[\u03a8S(x) 6= y] \u2264 c\nr\n( R2\n\u03b32 log2 r + log\n1\n\u03b4\n) (2)\nLemma 2 follows since the RHS of (2) is O(log2 r/r).\nDefinition 4 (Error-correction in Learning) Given that D and D\u0302 disagree on no more than \u03c1\u03b2-fraction of labels, and given that D satisfies some regularity properties, the problem of error-correction in learning is to recover a data set D\u0303 with as few label disagreements with D as possible.\nWe make no assumptions regarding the nature of label-errors (such as if they are statistical or otherwise), or regarding the separate values of error-parameter (\u03c1) and true fraction of minority-class (\u03b2); we are only given that the total fraction of label-errors does not exceed \u03c1\u03b2, 0 \u2264 \u03c1 < 1 and 0 < \u03b2 \u2264 0.5.\nAlgorithm 1 [SubSVMs] Subsampled bagging of SVMs\nInput: Corrupted data D\u0302 = {(x1, y\u03021), . . . , (x1, y\u0302`)}; size, s, of subsample; sampling bias p; number of SVMs J (typically, p = 12 and s = log ` or s = log 2 `) Output: Error-corrected data D\u0303 = {(x1, y\u03031), . . . , (x1, y\u0303`)}\n/\u2217 Training \u2217/ for j = 1 to J do\nDraw random subset S\u0302j \u223c DpD\u0302 of size |S\u0302j | = s Train SVM \u03a8\nS\u0302j\n/\u2217 Error-correction \u2217/ for i = 1 to ` do\nSet y\u0303i to the majority label in {\u03a8S\u03021(xi), . . . ,\u03a8S\u0302J (xi)} Output D\u0303 = {(x1, y\u03031), . . . , (x1, y\u0303`)}\n3. The SubSVMs algorithm\nWe first define a key ingredient of the SubSVMs algorithm that we refer to as p-biased sampling.\nDefinition 5 (p-biased Sampling) The process of p-biased sampling of D\u0302 refers to the following two steps, executed in the stated order: (1) choose the minority class3 of D\u0302 with probability p (or the other class with probability 1 \u2212 p) and (2) pick a point uniformly at random from the restriction of D\u0302 to the chosen class. The corresponding sampling distribution is denoted D\npD\u0302 and S\u0302 \u223c D pD\u0302 denotes that S\u0302 is a random collection of points drawn\niid with respect to D pD\u0302 .\nThe case of p = 0.5 is referred to as class-balanced sampling of D\u0302; if \u03b2\u0302 denotes the fraction of minority class points in D\u0302, the case of p = \u03b2\u0302 is equivalent to uniform sampling over D\u0302.\nAlgorithm 1 lists the pseudo-code for subsampled bagging of SVMs (SubSVMs). Our analysis (in Secs. 3.1-3.2) reveals two important aspects of SubSVMs:\n\u2022 Class-balanced sampling provides optimal protection against worst-case label-errors.\n\u2022 The fraction of errors that can be tolerated (\u03c1\u03b2) reduces as the squared-log of samplesize s.\nBased on the above, we use class-balanced sampling (p = 1/2) and choose s to be log ` or log2 `."}, {"heading": "3.1 Error correction analysis", "text": "Our analysis uses the margin-based generalization bound for SVMs with respect to a sampling distribution over the original (clean) data D and then adjusts the bound to accommodate the number of label-errors in the corrupted training set D\u0302.\n3. If both classes of D\u0302 are of identical size, one of them is arbitrarily fixed as the \u2018minority class\u2019.\nConsider the general case of Algorithm 1, where the random subsets S\u0302j are drawn iid\nfrom D pD\u0302 . Let D be linearly separable with margin \u03b3. Consider a set of points S\u0302 \u223c D pD\u0302 . We now need to compute the expected error-rate of \u03a8\nS\u0302 with respect to test points drawn\nuniformly from D (This is the main quantity of interest in the error-correction setting). For this, we first compute the expected error-rate when the training and test cases are both drawn iid from D\npD\u0302 . This is done by using Theorem 3 (Christianini and Shawe-Taylor, 2000,\nTheorem 4.22) with f = \u03a8 S\u0302 and D = D pD\u0302 (See next paragraph for details). The error-rate can at most become /p\u2217, where p\u2217 = min{p, 1 \u2212 p}, when considering test cases drawn uniformly from D\u03024. Finally, in any uniformly drawn sample from D\u0302, the expected fraction of label disagreements with respect to the corresponding points in D is \u03c1\u03b2. Hence, the desired expected error-rate of \u03a8\nS\u0302 , where S\u0302 \u223c D pD\u0302 but the test points are drawn uniformly\nfrom D, is given by /p\u2217 + \u03c1\u03b2. We now return to the computation of error-rate when train and test points are both drawn iid from D pD\u0302 . Whenever S\u0302 contains at least r/2 clean points per class, the SVM of the corresponding r-size (clean) subset of S\u0302 would make no more than (s\u2212 r) mistakes on the rest of S\u0302. Each of these mistakes would be no farther than 2R from either supporting hyperplane. Also, the margin of this SVM would be at least \u03b3 (the max-margin achieved on the whole of D). The 2-norm SVM objective has the same form as the error-bound in (1). Hence, we apply Theorem 3 with \u2016\u03be\u201622 = 4R2(s\u2212 r) and with margin \u03b3, to obtain the generalization bound, . If \u03b7 is an upper-bound on the probability that S\u0302 contains less than r/2 clean points from either class, then with probability at least (1\u2212 \u03b7 \u2212 \u03b4)\nPr (x,y)\u223cD\npD\u0302\n[\u03a8 S\u0302 (x) 6= y] \u2264 c\ns\n( R2 + 4R2(s\u2212 r)\n\u03b32 log2 s+ log\n1\n\u03b4\n) def = .\nRecall that this error-rate, , over test points drawn from D pD\u0302 , translates to an error-rate of\n/p\u2217+\u03c1\u03b2 for test points drawn uniformly over D. Thus, the final expression for probability of error of \u03a8\nS\u0302 with respect to test points drawn uniformly from D, denoted \u03d5, can be\nwritten as follows:\nPr[\u03a8 S\u0302 (x) 6= y] \u2264 (1\u2212 \u03b7 \u2212 \u03b4)\n[\np\u2217 + \u03c1\u03b2\n] + \u03b7 + \u03b4 def = \u03d5.\nWe use J SVMs based on J random sets such as S\u0302. Thus, if \u03d5 < 0.5, then (by Hoeffding Inequality Hoeffding (1963)) the probability of a majority vote making a mistake with respect to D cannot exceed exp[\u22122J(0.5\u2212\u03d5)2]. This gives us error-correction (in the sense that D can be correctly recovered from D\u0302). To enforce the condition \u03d5 < 0.5, we must have \u03c1\u03b2 < 1\u2212 /p\u2217 \u2212 [2(1\u2212 \u03b7 \u2212 \u03b4)]\u22121. Finally, if D is r-regular at (\u03b4, \u03b8), then we have\n= c\ns\n( R2\n\u03b32 log2 s+ log\n1\n\u03b4\n) + c\ns\n( 4R2(s\u2212 r)\n\u03b32 log2 s ) \u2264 \u03b8 + c\ns\n( 4R2(s\u2212 r)\n\u03b32 log2 s\n) . (3)\nThis leads to our main result about SubSVMs:\n4. See Appendix A for a short proof.\nTheorem 6 (Error-correction) Consider linearly separable D with margin \u03b3 and \u03b2fraction of minority-class points. Fix \u03b4 < 0.5 and let D be r-regular at (\u03b4, \u03b8). Consider D\u0302 with error-rate \u03c1 and S\u0302 \u223c D\npD\u0302 , |S\u0302| = s. Let Pr[S\u0302 contains < r/2 clean points per class] \u2264\n\u03b7. If the number of label-errors in D\u0302 is bounded by \u03c1\u03b2 < 1\u2212 2\u03b8 \u2212 [ 1\n2(1\u2212 \u03b7 \u2212 \u03b4) + 4R2c(s\u2212 r) log2 s \u03b32s\n] (4)\nwhere R denotes the radius of the ball enclosing the data and c is the constant from Theorem 3, then the probability of error for SubSVMs with respect to points drawn uniformly from D is at most exp [ \u22122J(0.5\u2212 \u03d5)2 ] , where \u03d5 = \u03b7 + \u03b4 + (1 \u2212 \u03b7 \u2212 \u03b4) [ /p\u2217 + \u03c1\u03b2] and p\u2217 = min{p, 1\u2212 p}.\nHence, perfect error-correction is attained for \u03d5 < 0.5."}, {"heading": "3.2 Importance of Class-balanced Sampling", "text": "The bound in (4) has two groups of parameters. In the first group, we have r, \u03b4 and \u03b8, which are fixed by the regularity properties of D. In the second group, we have s and \u03b7, which are both determined by our sampling strategy. Since \u03b7 depends on the sampling bias p, we now discuss how to fix p and s for optimal error-correction performance.\nFrom (4) it is clear that, to maximize the number of errors that can be tolerated, we must minimize the quantity in square brackets. The first term inside the brackets is minimized when \u03b7 is minimum. Fig. 1 provides a graphical depiction of the data corruption process. The optimal value of \u03b7 typically depends on the direction-of-attack parameter, \u03b1, the error parameter \u03c1, and the true size, \u03b2, of the minority class in D. However, neither of these is known to the learner; only an upper-bound on the fraction of label-errors in D\u0302 is known. So we design our algorithm to limit the impact of worst-case label-errors. Specifically, we choose p = 0.5 since it minimizes \u03b7 in a manner that is agnostic to the true values of \u03b1, \u03c1 and \u03b2. We state this formally in Lemma 7 below.\nLemma 7 (Class-balanced Sampling) Fix any r \u2208 Z+. Given D with \u03b2-fraction of minority-class points and D\u0302 with at most \u03c1\u03b2-fraction label-errors w.r.t. D, class-balanced\nsampling of D\u0302 minimizes a worst-case upper-bound on \u03b7 (probability that the sample drawn contains less than r/2 clean points per class) if the size, s (\u2265 r), of the sample satisfies\ns \u2265 2r + 4 ( r log 2 + log2 2\u2212 log 4 ) 1 2 + log 16\u2212 4 (5)\nThe main intuition behind the proof is that, in the absence of any specific information regarding \u03c1, \u03b2 and \u03b1, choosing the sampling bias p on either side of 0.5 is vulnerable to one of the attack directions, thereby increasing the worst-case value of \u03b7. (See Appendix B for the proof).\nThe second term inside the square brackets of (4) is smallest (and equal to zero) for s = r. However, Lemma 7 shows that this is not optimal for \u03b7, since s = r fails the condition in (5). In fact, for smaller s, \u03b7 may even be maximized at p = 0.5; in general, the minimizer of \u03b7 will no longer be agnostic to \u03c1, \u03b2 and \u03b1. However, when s is set to the lower-bound of (5), the second term inside square brackets of (4) becomes O(log2 r). This gives us our next lemma.\nLemma 8 (Subsampled Bagging) Let D be linearly separable and r-regular at (\u03b4, \u03b8) and let D\u0302 contain at most (\u03c1\u03b2)-fraction of adversarial label-errors. SubSVMs based on classbalanced sampling and with subsample-size, s, set to the lower-bound in (5), can perfectly recover the original D, provided the fraction of label-errors in D\u0302 is bounded above as follows:\n\u03c1\u03b2 < 1\u2212 2\u03b8 \u2212 [\n1\n2(1\u2212 \u03b7 \u2212 \u03b4) +O(log2 r)\n] (6)\nSince the above lemma requires s to be set at the lower-bound of (5) it might appear that we are operating on a knife-edge for choosing the subsample size. Luckily, this is not the case, because if the data is regular at r, it would also be regular with same \u03b8 for every r\u2032 > r. Hence, we could set s to the lower bound in (5) corresponding to r\u2032 and the above Lemma would still hold, though with O(log2 r\u2032) rather than O(log2 r) inside the square brackets. As a result, the number of worst-case errors allowed reduces for r\u2032 > r and this is the reason why we use subsampled bagging. Typically, we choose s to be log ` or log2 ` (rather than `, which is the usual case in bagging). As long as the data is r-regular for some r < s that satisfies (5) SubSVMs will give us error-correction. As a side-benefit subsampling at logarithmic sizes will give us dramatic run-time advantages over regular SVMs. Our experimental results clearly demonstrate this aspect of SubSVMs."}, {"heading": "4. Experiments", "text": "We present experimental results of SubSVMs on simulated, linearly separable data as well as LIBSVM extracts of some UCI data sets5. SVMs are known to perform well on these data sets, so they can play the role of clean data in our experiments.\nOur data corruption process follows Fig. 1. Given \u2018clean\u2019 training data D of size ` with minority class of size \u03b2`, 0 < \u03b2 \u2264 0.5, the parameters \u03c1 and \u03b1 control the corruption. We randomly pick \u03c1\u03b2` points for corruption, of which, \u03b1-fraction are picked uniformly at\n5. http://www.csie.ntu.edu.tw/\u223ccjlin/libsvmtools/datasets\nrandom from the minority class and (1\u2212 \u03b1)-fraction from the other. By varying the attack direction \u03b1, we generated a wide range of corrupted data with different degrees of difficulty for binary classification."}, {"heading": "4.1 Synthetic Data Experiments", "text": "In the first experiment, we generated \u2018clean\u2019 data sets D comprising of 1000 d-dimensional data points from a mixture of two Gaussian distributions, each with a covariance of 0.1Id and a distance of two units between means. Three values of d were used: 2, 16 and 30. A constant margin of 0.2 units was enforced and misclassified points were manually removed. The value of \u03b2 was varied between [0.05, 0.5] in steps of 0.05, \u03c1 = 0.75 and \u03b1 was varied between [0.0, 1.0] in steps of 0.25.\nWe studied the importance of class-balanced sampling in Algorithm 1 (SubSVMs) by comparing two versions of it - one with class-balanced sampling (p = 1/2) and the other with uniform sampling (p = \u03b2). For every d, the data corresponding to each [\u03b2, \u03b1] pair was subjected to 10 random corruptions. Figs. 2a and 2b summarize the results for class-\nbalanced sampling and Figs. 2c and 2d for uniform sampling. As expected, based on Theorem 6, the number of mistakes made decays exponentially with increasing J . Nearperfect error-correction is achieved using p = 1/2 for J as small as 27. For p = \u03b2, the worst-case and average-case performances are worse by about 60% and 20%, respectively. This experimentally validates Lemma 7 for using class-balanced sampling in SubSVMs."}, {"heading": "4.2 UCI Data Experiments", "text": "We now report the performance of SubSVMs on held-out test data using the LIBSVM UCI extracts. There can be two ways to test this, either the error-corrected training data can be used to retrain a fresh standard SVM or we can just use majority voting over the J SVMs already trained in SubSVMs. In our experiments, both these approaches yielded very similar results. Therefore, we avoid retraining cost and report results using the majority voting method.\nTable 1 shows the data characteristics of the 13 data sets used. The fraction of the minority class, \u03b2 ranges from 0.03 to 0.48 in training sets and from 0.03 to 0.50 in test sets. Also, the feature dimension varies between 4 to 300. Note that although these data sets are not linearly separable, they are still referred to as \u2018clean\u2019 before they are subjected to label-manipulation. For generating different types of attacks, \u03c1 = 0.75 was used while the value of \u03b1 was varied between [0.0, 1.0] in steps of 0.25. We compare SubSVMs against of four other SVM-based classifiers:\n1. Oracle-SVM: Standard SVM learnt over training data with parameters fixed by crossvalidating directly over clean test set.\n2. Blind-SVM: Standard SVM learnt over training data with parameters fixed based on the best average performance over all test sets. This is similar to Oracle-SVM, except\nthat a single set of parameters is used for all data sets. This helps assess the feasibility of blindly fixing the same set of parameters for all test sets.\n3. Bag-SVM: Regular bagging of SVMs where each SVM in the ensemble is trained on a bootstrap sample of size same as the original data (sampled with replacement). All SVMs use the same set of optimum parameters, which were determined through test set cross-validation of Oracle-SVM.\n4. CV-SVM: Standard SVM with parameters chosen through four-fold cross-validation on the training data. In all the experiments, the results of CV-SVM are averaged over five different random splits of the training data for cross-validation.\nAll cross-validations were performed by varying the penalty parameter C between 1 and 100, ratio of the weights of the two classes W between 0.1 and 10 and the RBF kernel parameter \u03c32 between 0.1/d and 10/d, where d is the data dimensionality. For SubSVMs, the values of C = 100, w = 1, \u03c32 = 1/d, s = log2 ` and J = 1000 were fixed for all data sets without performing any sort of cross-validation. All the SVMs were trained under L-2 loss, although similar results were also obtained under L-1 loss.\nNote that Oracle-SVM, Blind-SVM and Bag-SVM use information about test set labels to obtain their corresponding set of optimum parameters for training. This gives them an unfair advantage over CV-SVM and SubSVMs that are both agnostic to test set labels.\nPerformance measure: The UCI data sets exhibit a wide range of class imbalance - a1a\u2013a5a are moderately imbalanced, splice, mushrooms and svmguide1 are class-balanced while w1a\u2013w5a are highly imbalanced. For imbalanced data, high accuracies can be trivially achieved by labeling all points with the majority class label. Since accuracy is ineffective in such settings, we use its skew-insensitive version called Balanced Accuracy6 (BAC) Brodersen et al. (2010). Note that for class-balanced data, BAC reduces to accuracy.\nTable 2 summarizes the results of all the five methods on clean as well as corrupted versions of the data. For every data set, 10 random corruptions were performed w.r.t. the corresponding attack direction \u03b1 and the averaged results are reported. Winning results, when significantly better than the rest, are highlighted7.\n\u2022 SubSVMs is almost always significantly better than all the other methods (by 5% or more) and is never significantly worse. The advantage of SubSVMs is visible in both balanced and imbalanced data; for imbalanced data, the advantage increases for smaller \u03b1. This is because the quality of minority-class data falls sharply with \u03b1.\n\u2022 Oracle-SVM is at least as good as Blind-SVM. This is because Oracle-SVM tunes parameters individually for each test set, while Blind-SVM fixes the same parameters across all test sets.\n\u2022 Oracle-SVM, Blind-SVM and Bag-SVM are better than CV-SVM. This is because all three methods cross-validate directly on the test sets.\n6. See Appendix C for details of this measure. 7. Std. devs. were negligible (mostly < 0.02, max 0.06).\n\u2022 Bag-SVM\u2019s performance is similar to that of Oracle-SVM. This is consistent with Valentini (2004) that also reported no benefit in bagging SVMs (since SVMs are stable classifiers).\n\u2022 CV-SVM is the worst performing method and is often significantly worse than others8. This shows its ineffectiveness under noisy settings.\nSimilar results were also obtained using Skew-Insensitive F-score (SIF) Flach (2003). Results using Area Under the Curve (AUC) and accuracy, their unsuitability for imbalanced data notwithstanding, are reported in Appendix D.\n8. The case of clean, balanced data is the only exception.\nRun-times: Table 3 summarizes training times averaged over different types of attacks. SubSVMs is clearly much faster than all other methods9. While our experiments were based on single-core implementations, SubSVMs can be easily parallelized to handle very large-scale problems."}, {"heading": "5. Conclusions", "text": "We present a simple algorithm (SubSVMs) for learning binary classifiers under adversarial label-noise. SubSVMs can efficiently correct a bounded number of adversarial label-errors introduced in linearly separable data. Extensions to handle attribute noise and multi-class settings are important directions for future work. It would also be interesting to explore applicability of SubSVMs for solving large, noisy, real-world problems, where SVMs typically perform poorly.\n9. See Appendix D for more detailed run-times."}, {"heading": "Appendix A. Error-rate of \u03a8S\u0302 w.r.t. samples drawn uniformly from D\u0302", "text": "Let 1 and 2 be the class conditional error rates for the two classes. Without loss of generality let 2 \u2265 1. In the absence of the knowledge whether 2 is associated with the minority class or the majority class, the overall error rate of \u03a8\nS\u0302 w.r.t. samples drawn iid\nfrom D pD\u0302 is given by\n= max (p 1 + (1\u2212 p) 2, (1\u2212 p) 1 + p 2) \u2264 2. (7)\nTherefore, if = p 1 + (1\u2212 p) 2, then\n2 = \u2212 p 1 1\u2212 p \u2264 1\u2212 p\n(8)\nand if = (1\u2212 p) 1 + p 2, then\n2 = \u2212 (1\u2212 p) 1\np \u2264 p . (9)\nTherefore,\n2 < max\n(\n1\u2212 p , p\n) =\np\u2217 (10)\nwhere p\u2217 = min{p, 1\u2212 p}.\nAppendix B. Proof for optimality of class-balanced sampling (p = 0.5)\nConsider a two-class classification problem where the two classes are represented by A and B. Without loss of generality, let A be the minority class containing 0 < \u03b2 \u2264 0.5 fraction of the points. Let A\u0302 and B\u0302 represent the two classes after one or both the classes are corrupted with adversarial noise. Let \u03c1\u03b2, 0 \u2264 \u03c1 < 1 represent the upper limit on the fraction of corrupted points. Therefore, the total number of corrupted points can be written as nc = \u03c1\u03b2`. Further, let \u03b1 be the fraction of the corrupted points that were originally in class B but were assigned to class A. Therefore, the fraction of the new classes can be given by\n|A\u0302| = \u03b2 + \u03b1\u03c1\u03b2 \u2212 (1\u2212 \u03b1)\u03c1\u03b2 (11)\n|B\u0302| = 1\u2212 \u03b2 \u2212 \u03b1\u03c1\u03b2 + (1\u2212 \u03b1)\u03c1\u03b2 (12)\nMoreover, the fraction of good (clean) and bad (mislabeled) points in both the classes are\n|A\u0302g| = \u03b2 \u2212 (1\u2212 \u03b1)\u03c1\u03b2 (13)\n|A\u0302b| = \u03b1\u03c1\u03b2 (14)\n|B\u0302g| = 1\u2212 \u03b2 \u2212 \u03b1\u03c1\u03b2 (15)\n|B\u0302b| = (1\u2212 \u03b1)\u03c1\u03b2 (16)\nTherefore, the conditional probability of picking a good or a bad point for both the classes are given by\nP (ag|A\u0302) = |A\u0302g| |A\u0302| = 1\u2212 (1\u2212 \u03b1)\u03c1 1 + \u03b1\u03c1\u2212 (1\u2212 \u03b1)\u03c1 (17)\nP (ab|A\u0302) = |A\u0302b| |A\u0302| = \u03b1\u03c1 1 + \u03b1\u03c1\u2212 (1\u2212 \u03b1)\u03c1 (18)\nP (bg|B\u0302) = |B\u0302g| |B\u0302| = 1\u2212 \u03b2 \u2212 \u03b1\u03c1\u03b2 1\u2212 \u03b2 \u2212 \u03b1\u03c1\u03b2 + (1\u2212 \u03b1)\u03c1\u03b2 (19)\nP (bb|B\u0302) = |B\u0302b| |B\u0302| = (1\u2212 \u03b1)\u03c1\u03b2 1\u2212 \u03b2 \u2212 \u03b1\u03c1\u03b2 + (1\u2212 \u03b1)\u03c1\u03b2 (20)\nAssuming that the probability with which points from classes A\u0302 and B\u0302 are picked is given by P (A\u0302) = p and P (B\u0302) = 1\u2212 p respectively, the probability of picking up a good or a bad point for both the classes are respectively given by P (ag) = P (ag|A\u0302)p, P (ab) = P (ab|A\u0302)p, P (bg) = P (bg|B\u0302)(1\u2212 p) and P (bb) = P (bb|B\u0302)(1\u2212 p).\nThe probability \u03b7 of not picking r/2 clean points from either class is upper bounded by\n\u03b7 \u2264 r/2\u22121\u2211 k=0 ( s k ) (P (ag)) k (1\u2212 P (ag))s\u2212k + r/2\u22121\u2211 k=0 ( s k ) (P (bg)) k (1\u2212 P (bg))s\u2212k . (21)\nFor worst case analysis, we need to maximize \u03b7 and therefore, minimize both P (ag) and P (bg), which in turn requires minimizing P (ag|A\u0302) and P (bg|B\u0302) w.r.t. both \u03b1 and \u03b2. Differentiating P (ag|A\u0302) w.r.t \u03b1\ndP (ag|A\u0302) d\u03b1 = \u03c1(\u22121 + \u03c1) (1\u2212 \u03c1+ 2\u03b1\u03c1)2 \u2264 0. (22)\nTherefore, arg min\n\u03b1 P (ag) = 1. (23)\nSimilarly, differentiating P (bg|B\u0302) w.r.t. \u03b1\ndP (bg|B\u0302) d\u03b1 = \u03c1\u03b2(1\u2212 \u03b2(1 + \u03c1)) (1\u2212 \u03b2 + \u03c1\u03b2 \u2212 2\u03b1\u03c1\u03b2)2 \u2265 0 (24)\nTherefore, arg min\n\u03b1 P (bg) = 0. (25)\nAlso,\ndP (bg|B\u0302) d\u03b1 = \u2212\u03c1(1\u2212 \u03b1) (1\u2212 \u03b2 + \u03c1\u03b2 \u2212 2\u03b1\u03c1\u03b2)2 \u2264 0 (26)\nimplying that\narg min \u03b2 P (bg) =\n1 2 . (27)\nSubstituting \u03b1 = 1 in P (ag) and \u03b1 = 0, \u03b2 = 1/2 in P (bg), we get\nminP (ag) = p\n1 + \u03c1 and minP (bg) = 1\u2212 p 1 + \u03c1 . (28)\nTherefore, the worst case bound for (21) can be written as\n\u03b7 \u2264 r/2\u22121\u2211 k=0 ( s k )( p 1 + \u03c1 )k ( 1\u2212 p 1 + \u03c1 )s\u2212k + r/2\u22121\u2211 k=0 ( s k )( 1\u2212 p 1 + \u03c1 )k ( 1\u2212 1\u2212 p 1 + \u03c1 )s\u2212k . (29)\nApplying Hoeffding bound Hoeffding (1963) individually on each of the two terms\n\u03b7 \u2264 1 2 exp ( \u22122 s ( sp 1\u2212 \u03c1 \u2212 r 2 + 1 )2) + 1 2 exp ( \u22122 s ( s(1\u2212 p) 1 + \u03c1 \u2212 r 2 + 1 )2) (30)\nas long as sp1+\u03c1 > r 2 \u2212 1 and s(1\u2212p) 1+\u03c1 > r 2 \u2212 1. The RHS of 30 can be rewritten as\nf = 1\n2 exp \u22121 2 p\u2212 (r\u22122)(1+\u03c1)2s( 1+\u03c1 2 \u221a s ) 2+ 1 2 exp \u22121 2 (1\u2212 p)\u2212 (r\u22122)(1+\u03c1)2s( 1+\u03c1 2 \u221a s ) 2 (31)\nwhich is simply the sum of two Gaussian with means \u00b51 = (r\u22122)(1+\u03c1) 2s and \u00b52 = 1\u2212 (r\u22122)(1+\u03c1) 2s and equal variance \u03c3 = 1+\u03c1 2 \u221a s . Differentiating the above expression w.r.t. p\ndf dp = \u2212\n2 (\nsp 1+\u03c1 \u2212 r 2 + 1 ) exp ( 2 s ( sp 1+\u03c1 \u2212 r 2 + 1 )2) (1 + \u03c1) + 2 ( s(1\u2212p) 1+\u03c1 \u2212 r 2 + 1 ) exp ( 2 s ( s(1\u2212p) 1+\u03c1 \u2212 r 2 + 1 )2) (1 + \u03c1) . (32)\nIt can be clearly seen that p = 0.5 is a solution of (32). Also, the sum of two Gaussians can be either unimodal (p = 0.5 is global maximum) or bimodal (p = 0.5 is a minimum) Behboodian (1970). The second order derivative of f w.r.t. p can be written as\nd2f\ndp =\n8 (\nsp 1+\u03c1 \u2212 r 2 + 1\n)2 \u2212 2s\nexp ( 2 s ( sp 1+\u03c1 \u2212 r 2 + 1 )2) (1 + \u03c1)2\n+ 8 ( s(1\u2212p) 1+\u03c1 \u2212 r 2 + 1 )2 \u2212 2s\nexp ( 2 s ( s(1\u2212p) 1+\u03c1 \u2212 r 2 + 1 )2) (1 + \u03c1)2 . (33)\nTherefore, enforcing a minimum at p = 0.5, we get the condition that\nd2f\ndp \u2223\u2223\u2223 p=0.5 = 32 ( s 2(1+\u03c1) \u2212 r 2 + 1 )2 exp ( 2 s ( s 2(1+\u03c1) \u2212 r 2 + 1 )2) (1 + \u03c1)2 \u2212 8s exp ( 2 s ( s 2(1+\u03c1) \u2212 r 2 + 1 )2) (1 + \u03c1)2 \u2265 0.\n(34) This directly implies that\ns \u2265 (\u03c1+ 1) ( r \u2212 2 + 1\n2 (\u03c1+ 1)\n( 1 + ( 4r + \u03c1\u2212 7 \u03c1+ 1 )1/2)) (35)\nwhich, as expected, is a stronger condition than the one required for imposing the Hoeffding bound at p = 0.5, i.e., s > (1 + \u03c1)(r \u2212 2). Furthermore, to enforce p = 0.5 to be the global minimum, we impose the condition that the value of f at p = 0.5 is strictly less than that at any of the two extreme points of f (i.e., at p = 1s (1+\u03c1)(r/2\u22121) and p = 1\u2212 1 s (1+\u03c1)(r/2\u22121)). This gives us an even stronger condition\ns \u2265 (\u03c1+ 1) ( r \u2212 2 + (\u03c1+ 1) ( log 2 + ( log 2(log 2 + 2r + \u03c1 log 2\u2212 4)\n\u03c1+ 1\n)1/2)) . (36)\nThis is the sufficient condition to guarantee that the worst case probability of selecting less than r/2 clean points per class is minimum at p = 0.5, i.e., when class-balanced sampling is performed over the data."}, {"heading": "Appendix C. Details of performance metrics", "text": "For class-imbalanced data sets, very high classification accuracy can be trivially obtained by labeling the entire data with the majority class label. The use of Balanced Accuracy (BAC) for class-imbalanced data sets is prescribed by Brodersen et al. (2010) and can be simply computed as\nBAC = sensitivity + specificity\n2 . (37)\nThe sensitivity and specificity are defined as follows\nsensitivity = tp\ntp+ fn (38)\nspecificity = tn\ntp+ fn (39)\nwhere tp and fp denote the number of true and false positives while tn and fn denote the number of true and false negatives.\nSimilarly, traditional F-score can be trivially maximized for imbalanced data sets by compromising recall for high precision. Therefore, SIF Flach (2003) serves as an alternative to the F-score for imbalanced data sets and is given by\nSIF = 2tpr\ntpr + fpr + 1 (40)\nwhere tpr and fpr are true and false positive rates respectively. Like BAC, SIF also reduces to traditional F-score for class-balanced data sets. Another popular metric for comparison of classification performances is Area Under the ROC Curve (AUC). Although, unlike BAC and SIF, AUC is not a skew-insensitive measure, we also computed AUC measures for all the methods. It is important to mention that SubSVMsis always comparable to that of the other methods w.r.t. AUC. Finally, we note that for the results reported using AUC, we needed to retrain an SVM on the error-corrected data (unlike earlier, when we directly used majority voting on the test data)."}, {"heading": "Appendix D. Additional Results", "text": "Tables 4, 5 and 6 present additional results on the UCI data sets under L-2 loss using Skew-Insensitive F-Score (SIF), Area Under the Curve (AUC) and Accuracy, respectively. Table 7 shows detailed run-times corresponding to Table 3 in the paper."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "This paper is concerned with learning binary classifiers under adversarial label-noise. We introduce the problem of error-correction in learning where the goal is to recover the original clean data from a label-manipulated version of it, given (i) no constraints on the adversary other than an upper-bound on the number of errors, and (ii) some regularity properties for the original data. We present a simple and practical error-correction algorithm called SubSVMs that learns individual SVMs on several small-size (log-size), class-balanced, random subsets of the data and then reclassifies the training points using a majority vote. Our analysis reveals the need for the two main ingredients of SubSVMs, namely class-balanced sampling and subsampled bagging. Experimental results on synthetic as well as benchmark UCI data demonstrate the effectiveness of our approach. In addition to noise-tolerance, log-size subsampled bagging also yields significant run-time benefits over standard SVMs.", "creator": "LaTeX with hyperref package"}}}