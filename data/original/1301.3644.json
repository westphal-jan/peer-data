{"id": "1301.3644", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Regularized Discriminant Embedding for Visual Descriptor Learning", "abstract": "Images can vary according to changes in viewpoint, resolution, noise, and illumination. In this paper, we aim to learn representations for an image, which are robust to wide changes in such environmental conditions, using training pairs of matching and non-matching local image patches that are collected under various environmental conditions. We present a regularized discriminant analysis that emphasizes two challenging categories among the given training pairs: (1) matching, but far apart pairs and (2) non-matching, but close pairs in the original feature space (e.g., SIFT feature space). Compared to existing work on metric learning and discriminant analysis, our method can better distinguish relevant images from irrelevant, but look-alike images.", "histories": [["v1", "Wed, 16 Jan 2013 10:12:37 GMT  (614kb,D)", "http://arxiv.org/abs/1301.3644v1", "3 pages + 1 additional page containing only cited references; The full version of this manuscript is currently under review in an international journal"]], "COMMENTS": "3 pages + 1 additional page containing only cited references; The full version of this manuscript is currently under review in an international journal", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["kye-hyeon kim", "rui cai", "lei zhang", "seungjin choi"], "accepted": false, "id": "1301.3644"}, "pdf": {"name": "1301.3644.pdf", "metadata": {"source": "CRF", "title": "Regularized Discriminant Embedding for Visual Descriptor Learning", "authors": ["Kye-Hyeon Kim", "Rui Cai", "Lei Zhang", "Seungjin Choia"], "emails": ["fenrir@postech.ac.kr,", "leizhang}@microsoft.com,", "seungjin@postech.ac.kr"], "sections": [{"heading": "1 Introduction", "text": "In many computer vision problems, images are compared using their local descriptors. A local descriptor is a feature vector, representing characteristics of an interesting local part in an image. Scale-invariant feature transform (SIFT) [2] is popularly used for extracting interesting parts and their local descriptors from an image. Then comparing two images is done by aggregating pairs between each local descriptor in one image and its closest local descriptor in another image, whose pairwise distances are below some threshold. The assumption behind this procedure is that local descriptors corresponding to the same local part (\u201cmatching descriptors\u201d) are usually close enough in the feature space, whereas local descriptors belonging to different local parts (\u201cnon-matching descriptors\u201d) are far apart.\nHowever, this assumption does not hold when there are significant changes in environmental conditions (e.g., viewpoint, illumination, noise, and resolution) between two images. For the same local part, varying environment conditions can yield varying local image patches, leading to matching descriptors far apart in the feature space. On the other hand, for different local parts, their image patches can look similar to each other in some environmental conditions, leading to non-matching descriptors close together. Fig. 1 shows some examples: in each triplet, the first two image patches belong to the same local part but captured under different environment conditions, while the third patch belongs to a different part but looks similar to the second one, resulting that the SIFT descriptors between non-matching local parts are closer than those between matching parts. Consequently, comparing two images using their local descriptors cannot be done correctly when their are significant differences in environmental conditions between the images. Fig. 2(a) shows the cases.\nIn this paper, we address this problem by learning more robust representations for local image patches where matching parts are more similar together than non-matching parts even under widely varying environmental conditions.\n\u2217The full version of this manuscript is currently under review in an international journal.\nar X\niv :1\n30 1.\n36 44\nv1 [\ncs .C\nV ]\n1 6\nJa n"}, {"heading": "2 Proposed Method", "text": "In descriptor learning [1, 3], a projection is obtained from training pairs of matching and nonmatching descriptors in order to map given local descriptors (e.g., SIFT) to a new feature space where matching descriptors are closer to each other and non-matching descriptors are farther from each other. Traditional techniques for supervised dimensionality reduction, including linear discriminant analysis (LDA) and local Fisher discriminant analysis (LFDA) [4], can be applied to descriptor learning after a slight modification. For example, linear discriminant embedding (LDE) [1] is come from LDA with a simple modification for handling pairwise training data.\nWe propose a regularized learning framework in order to further emphasize (1) matching, but far apart pairs and (2) non-matching, but look-alike pairs, under wide environmental conditions. First, we divide given training pairs of local descriptors into four subsets, Relevant-Near (Rel-Near), Relevant-Far (Rel-Far), Irrelevant-Near (Irr-Near), and Irrelevant-Far (Irr-Far). For example, the \u201cIrr-Near\u201d subset consists of irrelevant (i.e., non-matching), but near pairs. We define an irrelevant pair (xi,xj) as \u201cnear\u201d if xi is one of the k nearest descriptors1 among all non-matching descriptors of xj or vice versa. Similarly, a relevant pair (xi,xj) is called \u201cnear\u201d if xi is one of k nearest descriptors among all matching descriptors of xj . All the other pairs belong to \u201cIrr-Far\u201d or \u201cRel-Far\u201d. Then we seek a linear projection T that maximizes the following regularized ratio:\nJ(T ) = \u03b2IN\n\u2211 (i,j)\u2208PIN dij(T ) + \u03b2IF \u2211 (i,j)\u2208PIF dij(T )\n\u03b2RN \u2211 (i,j)\u2208PRN dij(T ) + \u03b2RF \u2211 (i,j)\u2208PRF dij(T ) , (1)\n1In our experiments, setting 1 \u2264 k \u2264 10 achieved a reasonable performance improvement.\nwhere dij(T ) denotes the squared distance ||T (xi\u2212xj)||2 between two local descriptors xi and xj in the projected space, and PRN ,PRF ,PIN ,PIF denote the subsets of Rel-Near, Rel-Far, Irr-Near, and Irr-Far, respectively. Four regularization constants \u03b2RN , \u03b2RF , \u03b2IN , \u03b2IF control the importance of each subset.\n\u2022 In LDE, all pairs are equally important, i.e., \u03b2RN = \u03b2RF = \u03b2IN = \u03b2IF = 1. \u2022 In LFDA , \u201cnear\u201d pairs are more important, i.e., \u03b2RN \u03b2RF and \u03b2IN \u03b2IF . \u2022 In our method, we propose to emphasize Rel-Far (matching but far apart) and Irr-Near\n(non-matching but close) pairs, i.e., \u03b2RN \u03b2RF and \u03b2IN \u03b2IF .\nFig. 3 shows when and why our method can better distinguish Irr-Near pairs from Rel-Far pairs. In Fig. 3(a), the global intra-class distribution forms a diagonal, while each local cluster has no meaningful direction of scattering. Since LFDA focuses on \u201cnear\u201d pairs, it cannot capture the true intra-class scatter well, leading to the undesirable projection. In Fig. 3(b), LDE obtains a projection that maximizes the inter-class variance, but the shape of the class boundary cannot be considered well, leading to an overlap between two classes. In this case, focusing more on Irr-Near pairs (i.e., the pairs of opposite clusters near the class boundary) can preserve the separability of classes.\nFig. 4 shows the distance distribution of local descriptors, where 20,000 pairs of each subset are randomly chosen from 500,000 local patches of Flickr images. As shown in Fig. 4(a), Rel-Near and Irr-Far pairs are already well separated in the SIFT space, but Rel-Far and Irr-Near pairs are not distinguished well (\u223c30% overlapped) and many Rel-Far pairs lie farther than Irr-Near pairs. Learning by LDE can achieve only a marginal improvement (Fig. 4(b)). By contrast, our RDE achieves a significant improvement in the separability between matching and non-matching pairs, especially two challenging subsets, Rel-Far and Irr-Near (Fig. 4(c)). Fig. 1 and 2 also show the superiority of our method over the existing work."}], "references": [{"title": "Discriminant embedding for local image descriptors", "author": ["G. Hua", "M. Brown", "S. Winder"], "venue": "Proceedings of the International Conference on Computer Vision (ICCV), 2007, pp. 1\u20138.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Object recognition from local scale-invariant features", "author": ["D.G. Lowe"], "venue": "Proceedings of the International Conference on Computer Vision (ICCV), 1999, pp. 1150\u20131157.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "Descriptor learning for efficient retrieval", "author": ["J. Philbin", "M. Isard", "J. Sivic", "A. Zisserman"], "venue": "Proceedings of the European Conference on Computer Vision (ECCV), 2010, pp. 677\u2013691.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Dimensionality reduction of multimodal labeled data by local Fisher discriminant analysis", "author": ["M. Sugiyama"], "venue": "Journal of Machine Learning Research, vol. 5, pp. 1027\u20131061, 2007. 4", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 1, "context": "Scale-invariant feature transform (SIFT) [2] is popularly used for extracting interesting parts and their local descriptors from an image.", "startOffset": 41, "endOffset": 44}, {"referenceID": 0, "context": "Using linear discriminant embedding (LDE) [1], non-matching pairs are still closer than matching pairs in the first three examples.", "startOffset": 42, "endOffset": 45}, {"referenceID": 0, "context": "In descriptor learning [1, 3], a projection is obtained from training pairs of matching and nonmatching descriptors in order to map given local descriptors (e.", "startOffset": 23, "endOffset": 29}, {"referenceID": 2, "context": "In descriptor learning [1, 3], a projection is obtained from training pairs of matching and nonmatching descriptors in order to map given local descriptors (e.", "startOffset": 23, "endOffset": 29}, {"referenceID": 3, "context": "Traditional techniques for supervised dimensionality reduction, including linear discriminant analysis (LDA) and local Fisher discriminant analysis (LFDA) [4], can be applied to descriptor learning after a slight modification.", "startOffset": 155, "endOffset": 158}, {"referenceID": 0, "context": "For example, linear discriminant embedding (LDE) [1] is come from LDA with a simple modification for handling pairwise training data.", "startOffset": 49, "endOffset": 52}], "year": 2013, "abstractText": "Images can vary according to changes in viewpoint, resolution, noise, and illumination. In this paper, we aim to learn representations for an image, which are robust to wide changes in such environmental conditions, using training pairs of matching and non-matching local image patches that are collected under various environmental conditions. We present a regularized discriminant analysis that emphasizes two challenging categories among the given training pairs: (1) matching, but far apart pairs and (2) non-matching, but close pairs in the original feature space (e.g., SIFT feature space). Compared to existing work on metric learning and discriminant analysis, our method can better distinguish relevant images from irrelevant, but look-alike images.", "creator": "LaTeX with hyperref package"}}}