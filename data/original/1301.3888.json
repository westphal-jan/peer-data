{"id": "1301.3888", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Probabilistic State-Dependent Grammars for Plan Recognition", "abstract": "Techniques for plan recognition under uncertainty require a stochastic model of the plan-generation process. We introduce Probabilistic State-Dependent Grammars (PSDGs) to represent an agent's plan-generation process. The PSDG language model extends probabilistic context-free grammars (PCFGs) by allowing production probabilities to depend on an explicit model of the planning agent's internal and external state. Given a PSDG description of the plan-generation process, we can then use inference algorithms that exploit the particular independence properties of the PSDG language to efficiently answer plan-recognition queries. The combination of the PSDG language model and inference algorithms extends the range of plan-recognition domains for which practical probabilistic inference is possible, as illustrated by applications in traffic monitoring and air combat.", "histories": [["v1", "Wed, 16 Jan 2013 15:52:22 GMT  (294kb)", "http://arxiv.org/abs/1301.3888v1", "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)"]], "COMMENTS": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["david v pynadath", "michael p wellman"], "accepted": false, "id": "1301.3888"}, "pdf": {"name": "1301.3888.pdf", "metadata": {"source": "CRF", "title": "Probabilistic State-Dependent Grammars for Plan Recognition", "authors": ["David V. Pynadath", "Marina del Rey", "M ichael P. Wellman"], "emails": ["@umich.edu"], "sections": [{"heading": null, "text": "Techniques for plan recogmtwn under uncer tainty require a stochastic model of the plan generation process. We introduce probabilistic state-dependent grammars (PSDGs) to represent an agent's plan-generation process. The PSDG language model extends probabilistic context free grammars (PCFGs) by allowing production probabilities to depend on an explicit model of the planning agent's internal and external state. Given a PSDG description of the plan-generation process, we can then use inference algorithms that exploit the particular independence proper ties of the PSDG language to efficiently answer plan-recognition queries. The combination of the PSDG language model and inference algorithms extends the range of plan-recognition domains for which practical probabilistic inference is pos sible, as illustrated by applications in traffic mon itoring and air combat.\n1 INTRODUC TION\nThe problem of plan recognition is to determine the plan of action underlying an agent's behavior, based on partial ob servation of its behavior up to the current time. We assume that this behavior is a product of executing some plan, con structed to serve the agent's objectives based on its beliefs. 1 The examples in this paper draw from a scenario in traffic monitoring, where the observed agent is driving a car along a three-lane, one-way highway.\nThe agent begins in an initial context, consisting of its po sition along the highway, presence of other cars, etc. Its mental state is comprised by its preferences (e.g., utility function over speed), beliefs (e.g., speedometer reading),\n1 We discuss our overall plan-recognition framework else where (Pynadath & Wellman, 1995; Pynadath, 1999).\nand capabilities (e.g., driving ability). We assume the plan ning process to be some rational procedure based on such a mental state. The generated plan then determines (perhaps with some uncertainty) the actions taken by the agent in the world. In the traffic example, the observed driver may plan high-level maneuvers (e.g., change of lane, pass of another car) that it ultimately executes through low-level driving actions (e.g., turning the steering wheel).\nThe recognizer uses its observations, in whatever form, to generate hypotheses about which top-level plan or interme diate subplans the agent has selected, or which low-level actions it will perform in the future. The resulting candi dates, as well as possible evaluations of their plausibilities, form the basis for decisions on potential interactions with the observed agent. In the traffic example, a recognizing driver could observe another car maneuvering nearby and compute a probability distribution over possible plan inter pretations and future actions, all as part of its own (possibly decision-theoretic) maneuver-selection process.\n1.1 BAYESIAN NETWORKS FOR PLAN\nRECOGNITION\nModeling the uncertainty inherent in planning domains provides one of the most difficult challenges in plan recog nition. Approaches based on first-order logic typically ap peal to heuristic criteria to distinguish among possible ex planations of observed phenomena (Kautz & Allen, 1986; Lin & Goebel, 1991; Tambe & Rosenbloom, 1996). How ever, to support general decision making based on such ob servations, we require an account of the relative likelihood of these explanations.\nThe most comprehensive probabilistic approach to plan recognition constructs plan recognition Bayesian networks representing the relationships among events and uses standard network inference algorithms to compute pos terior probability distributions over possible interpreta tions (Charniak & Goldman, 1993). These plan recognition Bayesian networks represent a probability distribution over a particular set of observed events, appropriate for the in-\n508 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\ntended domain of story understanding. However, in many real-world agent domains, the complete set of observations is enormous. For instance, in the traffic domain, we ob serve cars' positions along the highway repeatedly over the course of many minutes, possibly even hours. Even tually, we would be unable to represent the accumulating set of observations within a Bayesian network that would be tractable for inference.\nDynamic Bayesian networks (DBNs) (Kjrerulff, 1992) rep resent only a restricted window of the random variables by using a compact belief state to summarize the past ob servations. The belief state is sufficiently expressive to support exact inference over variables within the window. However, the generality of the DBN representation still leads to intractable inference in many plan-recognition do mains. Methods for approximate inference can answer queries with sufficient precision and efficiency for some domains (Lesh & Allen, 1999), but still take several min utes for inference. We would instead like a more restricted language that supports online inference in answering plan recognition queries in a matter of seconds, as required in the air combat and traffic domains.\n1.2 PROBABILISTIC GRAMMARS\nPattern-recognition research provides a possible source for such representations, since plans are descriptions of ac tion patterns. Grammatical representations are generative and modular, providing an appealing class of languages for specifying pattern-generation processes. If we can model a given plan-generation process within a particular grammat ical formalism, then we can use that formalism's inference techniques to answer plan-recognition queries.\nOne candidate approach would use a probabilistic context free grammar (PCFG) (Chamiak, 1993; Gonzalez & Thomason, 1978) to represent a distribution over possi ble action sequences. Existing PCFG parsing algorithms would support a restricted set of plan-recognition queries. Other grammatical models (Black et al., 1992; Schabes & Waters, 1993; Carroll & Weir, 1997; Magerman, 1995) make fewer independence assumptions than do PCFGs (thus supporting a wider class of problem domains), while still supporting efficient parsing algorithms. The typical parsing algorithm produces the conditional probability of a particular symbol (subplan) or parse tree (plan instantia tion), given a complete terminal sequence (sequence of ob servations). However, these parsing algorithms are unsuit able for most plan-recognition queries, which occur during execution, before the entire sequence is available. In ad dition, the entire sequence may never become available if there are missing observations.\nIn previous work, we have shown how to generate a Bayesian network to answer these more general queries for a given PCFG (Pynadath & Wellman, 1998). These\nBayesian networks suffer the same drawbacks as those in existing plan-recognition research, since they, too, must represent the entire set of observations. However, by bor rowing the notion of a compact belief state from DBN inference and by exploiting the specific independence as sumptions of the underlying grammatical model, we may be able to identify a belief state compact enough for practi cal inference, while still supporting exact inference.\n2 PROBABILISTIC STATE-DEPENDENT\nGRAMMARS\nThis section defines the probabilistic state-dependent grammar (PSDG), which supports such belief-state infer ence. The PSDG model adds an explicit representation of state to an underlying PCFG model of plan selection. The state model captures the dependence of plan selection on the planning context, including the agent's beliefs about the environment and its preferences over outcomes. The state model also represents the effects of the agent's plan ning choices on future states (and, consequently, on future planning choices). This section defines the language model and demonstrates its ability to represent plan generation in certain domains. Section 3 describes a practical inference algorithm that can answer plan-recognition queries based on a PSDG representation of an agent's planning process.\n2.1 PSDG DEFINITION\nA probabilistic state-dependent grammar (PSDG) is a tu ple (:E, N, S, Q, P, 1r0, 1r1), where the disjoint sets \ufffd and N specify the terminal and nonterminal symbols, respec tively, with S E N being the start symbol (as in a PCFG). P is the set of productions, taking the form X -+ ' (p), with X E N,' E (\ufffdUN)+ and p the probability that X is expanded into the string'\u00b7 Qt is a time-indexed random variable representing a state space (beyond the grammatical symbols) with domain Q.\nThe PSDG production probability, p : Q -+ [0, 1], is a function of the state. Each production X -+ ' (p) denotes that the conditional probability of expanding X into the sequence ,, given that the current state Qt = q, is p(q). We specify the time, t, of a particular nonterminal symbol as the position of its leftmost descendant terminal symbol within the overall terminal string (where t = 1 is the first terminal symbol). We can then define the current state for expanding a symbol at time t as Qt-1. For each nonter minal symbol X E N, we require that LePe(q) = 1 for all states q E Q, where Pt ranges over all the production probability functions for expansions of X.\nThe PSDG function 1ro specifies the distribution over the initial values of the state variable Q, i.e., Pr(Q0 = q) = 7ro(q). The function 1r1 (qt-1, x, qt) specifies the probabil ity that Qt = qt given that Qt -l = qt_1 and the terminal\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 509\n0) Drive --+ Stay Drive (po(q) = .. \u00b7) 1) Drive --+ Left Drive\n(p1(q) = { \ufffd-. if Lane(q) =left-lane ) 2) Drive --+ Right Drive (p2(q)) 3) Drive --+ Pass Drive (p3(q)) 4) Drive --+ Exit (p4(q)) 5) Pass --+ Left Right (p5(q)) 6) Pass --+ Right Left (p6(q))\nFigure 1: PSDG representation of simplified traffic domain.\nsymbol chosen in the intervening interval is x. The value of Qt is conditionally independent of past values of Q (as well as all symbols in the parse tree selected before t) given the value of Qt-1 and the terminal symbol chosen in the in terval between t- 1 and t.\nWe can often simplify a PSDG domain by viewing the state as a conjunction of somewhat orthogonal features repre senting individual aspects of the context. Production prob abilities are functions of only those features that influence the choice in expanding a particular symbol. For instance, a driver's decision to accelerate or decelerate may depend on only its preferred traveling speed and the current speed of the car in front, without depending on the location of the intended exit. Likewise, the distribution over a partic ular feature can depend on other certain features, without having to depend on all (e.g., the driver's position along the highway changes with the current speed, but it does not depend on the current lane). Whereas we often refer to the state as a single variable for intelligibility, Section 3's infer ence algorithms do exploit factored state representations.\n2.2 SIMPLE PSDG EXAMPLE\nConsider the PSDG of Figure 1, representing a simpli fied generative model of driving plans. The state includes the observable features of the driver's position and speed, as well as the positions and speeds of other cars on the highway. The state also includes aspects of the driver's mental state, such as the agent's preferences about driving speed, distance from other cars, intended exit, etc. Figure 2 presents one possible instance of the agent's plan genera tion and execution, as an illustration of PSDG parse tree generation. The picture labeled Q0 in the bottom left cor ner of the diagram represents the observable portion of the initial state. The solid black rectangle is the driver whose planning process we are trying to recognize. The white rectangles are the other cars on the highway.\nTo clarify the specification of certain plan events impor tant for describing both generation and recognition, we define random variables, Nj (nonterminals), Pj (produc tions), and \ufffdt (terminals), to represent an entire path from root node to leaf node (i.e., the stack of active plans). The t index indicates time from left to right in the parse tree.\n\u2022 I '0 '\n: :0 ' ' ' ' ' ' \u2022 \u2022 ' ' QO: :\nDrive\n\ufffd----Pass -...... \ufffdRight\nI A\n1[0[ ' ' ' ' 0 ' ' Qlo o\n' 0' ' ' Qlo o\n\u00a3 = 1, and all other symbol nodes have an\u00a3 index of one more than their parent nodes. In the example, the driver's plan originates with the start symbol, Nf =Drive.\nThe driver then chooses among the five possible expansions shown in Figure 1. The production variable, Pl, indicates the production chosen, as well as what symbol on the right hand side is currently being expanded. In the parse tree of Figure 2, the driver selects the production Drive -+ Pass Drive with probability p3(Q0). Therefore, Pl = (3, 1), where the first number is the production index, and the sec ond indicates that the currently active child symbol is the first symbol on the right-hand side, Pass.\nThe production probability, p3(Q0), summarizes the plan selection process conditioned on the context, Q0\u2022 We can view the set of probability functions for all expansions of Drive as a decision tree, with the state features as the in puts. For instance, in states where the driver's preferred speed is slower than the current speed of the car in front, passing is very unlikely. Likewise, if the driver's position along the highway is close to the intended exit, then passing is again unlikely, although passing becomes more likely if the driver is of an \"aggressive\" type.\nGiven that we have chosen production 3, we continue the plan expansion with the selected child, Nj =Pass. We compute p5(Q0) and p6(Q0) to determine the probability of passing on the left versus passing on the right. In the example, the driver has chosen to pass on the left (P.J = (5, 1)), so it first executes a Left action.\nThe random variable \ufffdt represents the terminal symbol at position t in the final sequence, so in this case, \ufffd1 =Left. The values of the symbol variables (both terminal and non terminal) are completely determined given the values of the production variables above them in the hierarchy. In par ticular, suppose that Pj = (a, b), where production a is X -+ Y1 Y2 \u00b7 \u00b7 \u00b7 Y m. In such a case, if Yb is a terminal sym bol, then \ufffdt = Yb; otherwise, Nl+1 = Yb.\nHaving reached a leaf node for time 1, we can apply the state transition probability, 1r1 ( Qt\n-1, \ufffdt, Qt), to compute a distribution over possible values of Q1. This transition\n510 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nprobability encodes the world dynamics, including the ef fects of the observed agent's actions on the state. For in stance, the transition probability represents the (possibly uncertain) effect that making a left lane change has on the car's lane position. It also represents the possible changes in the positions of the other cars. The diagram shows one possible value where the driver has moved into the leftmost lane (as a result of selecting the Left action) and moved be yond the other two cars.\nThe expansion of the top-level plan, Drive, did not com plete at time 1, so N'f =Drive. The expansion of Pass did not complete either, soP[ = (3, 1) and Ni =Pass. How ever, at the next level, the terminal symbol Left completed execution in time 1, so we move on to the next symbol to be expanded at that level: P:j = (5, 2) and :E2 =Right. If any new nonterminal symbols had arisen in this branch at time 2, the state Q1 would form the context when expanding them. We determine the next state value, Q2, by applying the state transition probability, n1 ( Q1, Right, Q2) .\n2.3 RELATIONSHIP OF PSDGs TO PCFGs\nBoth the traffic and air-combat PSDGs use finite state spaces. For finite state spaces, we can represent a given PSDG distribution with a corresponding PCFG. This equivalent PCFG symbol space contains tuples (qi, X, QJ ), indicating that the PSDG symbol X is expanded starting in initial state qi and ending in final state qf. Given these new symbol sets, we can construct context-free productions such that the probability of a given PSDG parse tree is iden tical to the corresponding parse tree from this constructed PCFG. However, the constructed PCFG can be larger than the original PSDG by a factor of IQim+l, where m is the maximum production length.\nIn general, if we allow the state space to be infinite, then the PSDG generative model can represent language distri butions beyond those allowed by the PCFG model. For instance, the language {ax bY ex dY, y > 0} cannot be repre sented by a context-free grammar, nor a PCFG. However, if we define the state space Q = z+ X z+ to record the values of x andy, then we can specify productions and a deterministic state transition function to represent the lan guage. In addition, the inference algorithms of Section 3 support \"recognition\" queries about this generation mech anism. We omit the PSDG constructions for more gen eral languages here, since, although inference on the con structed PSDGs is possible, it is impractical in general.\n2.4 IMPLEMENTED PSDGs: TRAFFIC AND AIR COMBAT\nRegardless of the potential computational advantage, the separation between the plan and state spaces in the PSDG model can provide a more suitable modeling language, since the dependency structure more closely mirrors that\nof most planning domains. An examination of the im plemented PSDG models of the traffic and air-combat domains illustrates the language's specific strengths and weaknesses. Overall, the complete traffic PSDG has 14 nonterminal symbols (plans), 7 terminal symbols (actions), and 15 state features (with the mean state space size be ing 431 elements). Three of these state features correspond to aspects of the driver's mental state (preferred speed, in tended exit, aggressiveness); the rest of the state features are completely observable. There are a total of 40 produc tions with a mean length of two symbols. We also imple mented a PSDG representation for an air combat domain based on an existing specification (Tambe & Rosenbloom, 1996) using Soar productions (Newell, 1990).\n2.4.1 State Models in PSDGs\nFor modeling the planning agent's environment and men tal state, the PSDG state variable specification supports ar bitrarily complex probabilistic dependency structures. We could capture probabilistic sensor models of the uncertain noise present in the agent's beliefs. However, the agent's beliefs are unobservable, and, as Section 3 discusses, the number and size of unobservable state variables have the biggest impact on the complexity costs of inference. We can often model the agent's noisy beliefs within the pro ductions themselves, thus incurring much less inferential cost. For instance, in the expansions of Drive, there is a nonzero probability for passing even when the driver is at the intended exit. This probability captures the possibility that the driver fails to notice the exit, without requiring an explicit state variable for the driver's belief.\nHowever, we cannot model beliefs and preferences that per sist throughout the agent's lifetime through the production probabilities, which are evaluated independently for each episode. PSDG state variables cannot represent distribu tions over arbitrary utility functions in a manner that sup ports tractable inference. However, if we can model the planning agent's preferences by a finite set of goals (e.g., intended exit) or finite set of utility function classes (e.g., driver aggressiveness), then we can greatly reduce the com plexity of the PSDG state variable representation.\n2.4.2 Plan Model in PSDGs\nThe PSDG production format also supports plan genera tion and execution models much more flexible than that of Figure 1. The PSDG of Figure 1 treats the lane change Left as an atomic action, but the complete PSDG for the traffic domain treats it as only an intended plan with two subcomponents, StartLeft and Executeleft. While in the first subplan, the driver is waiting for conditions to become safe before actually changing lanes. The production prob ability functions for StartLeft evaluate the highway situa tion of the current observed state, as well as the unobserv able mental state (e.g., the driver's degree of cautiousness\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 511\nor aggressiveness). If conditions are unsafe, the production probability of Startleft -+ Stay Startleft is high, as the driver prefers to stay in the current lane and postpone the lane change. If the conditions become safe, the driver stops waiting with Startleft -+ Moveleft, where Moveleft is an incremental shift (expected to be 1m) to the left. The production probabilities capture this termination condition through the relative likelihoods of the two Startleft pro ductions and their dependency on the current state.\nOnce the expansion of Startleft terminates, the driver then goes on to expand Execute left, which produces a series of Moveleft actions until the car is fully within the new lane. However, the driver also has the option of abandoning the lane change as conditions evolve. If the state is such that the driver no longer desires to move into the left lane (e.g., the car in front moves to a different lane), then the productions Startleft -+ Stay and Executeleft -+ Stay take on the highest production probabilities. Thus, the expansion of Left completes within two cycles, and the driver is free to choose a new maneuver.\nAlthough the conditional production probabilities allow great flexibility, the production structure itself does require a total order over subplans. For example, the original Soar specification of the air-combat domain did not impose an order over subplans. However, the conditions on these par ticular Soar productions implicitly serialize much of the execution, as the pre-conditions of a particular child are achieved only after the execution of its sibling. In general, we would unfortunately have to generate PSDG produc tions for all of the possible sequences of these children.\nThe production structure also serializes the execution of plans and actions, precluding the possibility of concurrent actions. The traffic PSDG mimics certain forms of con currency by using subsequences of symbols. For instance, the simplified grammar of Figure 1 includes action sym bols for only lateral movements. The complete PSDG has additional symbols corresponding to acceleration maneu vers as well, with these symbols being interleaved with the lateral movement symbols. However, this mechanism is in sufficient for general concurrency, where the plans are not separable and do not have orthogonal effects on the state.\n2.4.3 World Dynamics in PSDGs\nThe PSDG state transition probabilities can represent any joint distribution over future world states, conditioned on the past state and the low-level action taken. Most of the relationships expressed by the world dynamics in the traffic example are straightforward. For instance, the value of the lateral position at time t + 1 will be to the left of its value at time t, given an interposing Moveleft action. There is uncertainty in the exact change in value, as expressed by the probability distribution in the complete PSDG.\nHowever, the state transition probabilities cannot represent\nthe effects of subplan choices on future states. For in stance, we cannot explicitly represent the dependency of the driver's tum indicator on its high-level decisions. We instead introduced terminal symbols representing signaling as an additional concurrent action. The state of the turn in dicator is completely determined given the signaling action. In general, we cannot afford to add such indirect plan rep resentations for each such state dependent on a high-level plan. It is important to note that it is the generative model that does not capture the dependency of the agent's men tal state on plan choices. Once we observe evidence, the inference algorithms of Section 3 do capture a conditional dependency in updating the recognizer's beliefs about the agent's mental state.\n3 PSD G INFERENCE\nAlthough we can perform inference on a given PSDG with a finite state space by generating the corresponding PCFG and using PCFG inference algorithms, the explosion in the size of the symbol space can lead to prohibitive costs. In addition, as described in Section 1.2, existing PCFG algo rithms cannot handle most plan-recognition queries.\nWe can potentially perform inference by generating a DBN representation of a PSDG distribution. The definition of the PSDG language model supports an automatic DBN gener ation algorithm. The resulting DBN supports queries over the symbol, production, and state random variables. Un fortunately, the complexity of DBN inference is likely to be impractical for most PSDGs, where the belief state must represent the entire joint distribution over all possible com binations of state and parse tree branches. For instance, for the complete PSDG representation of the traffic domain, the DBN belief state would have more than 1025 entries.\nThis section presents inference algorithms that exploit the particular structure of the PSDG model to answer a set of queries more restricted than that provided by DBNs. These algorithms use a compact belief state (described in Sec tion 3. 1) to answer queries based on observations of the state variables. At time t, the recognizer observes some or perhaps all of the features of the state, Qt. We repre sent this evidence by stating that Qt E Rt, where Rt \ufffd Q represents the set of possible states consistent with the ob servations. Based on this evidence, the algorithm presented in Section 3.3 computes posterior probabilities over the in dividual state elements in Rt, as well as posterior probabil ities over the possible plans and productions that the agent executed at time t - 1. The algorithm presented in Sec tion 3.4 computes the posterior probabilities over the plans and productions that the agent will select at time t, as well as updating the recognizer's belief state. A pseudocode description of the algorithm is available in an online ap pendix2. Both the pseudocode and proofs of correctness\n2www.isi.edu/-pynadath/Research/PSDG\n512 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nare available elsewhere as well (Pynadath, 1999).\n3.1 COMPACT BELIEF STATE FOR INFERENCE\nThe high connectivity of the DBN belief state arises from its reliance on strict conditional independence as its struc turing property. The DBN representation does not exploit the weaker forms of independence present in the PSDG model. To specify these weaker independence conditions, we first define an expansion, Pi = (X -+ Y1 Y2 \u00b7 \u00b7 \u00b7 Ym, b), as terminating at time t if and only if b = m and either Y m is a terminal symbol or the child expansion, Pi+l, ter minates at time t. If we re-examine the relationship of the production variables Pi on the previous time slice, we notice that there are two possibilities when the expansion Pz-1 has not terminated. One possibility is that the ex pansion of child Ni+t has not terminated, in which case we continue expanding the child at time t as well, and the value of the parent expansion Pz-1 does not change. The other possibility is that the child expansion terminated at time t - 1, but there are still more children to expand on the right-hand side of the parent expansion: Pz-1 = (X-+ Y1Y2 \u00b7 \u00b7 \u00b7 Ym, b), b < m. In this case, we move on to the next child, so Pi = (X -+ Y1 Y2 \u00b7 \u00b7 \u00b7 Ym, b + 1). In both cases, the relationship is deterministic. If the parent expansion Pz-1 has terminated in the previous time slice, then we are choosing a new production based on the new left-hand symbol, Nj, and Qt-l, independent of the sym bols and productions of the previous time slice. We use this independence property and determinism inherent in the PSDG model to treat our beliefs about the plan variables, Nj and Pi. separately at the different levels, \u00a3, of the hier archy.\nIn addition, the DBN representation supports the computa tion of arbitrary conditional probabilities within the current window of random variables. In most problem domains, we never have direct evidence about the agent's plan choices, but rather only about the current state. For instance, in our traffic example, we can observe the position and speed of cars, but we cannot directly observe aspects of the driver's mental state or its subplan choices (e.g., whether it has cho sen a passing maneuver).\nTo support PSDG inference, DBN inference must maintain a distribution over the joint space of all variables within a given time slice. Our specialized inference algorithms instead maintain a much smaller belief state that summa rizes this probability distribution by exploiting the indepen dence properties of the PSDG model and the restricted set of PSDG queries. Table 1 lists the probability tables that form Bt, the belief state for time t, where t:t represents all evidence (Qt E Rt) received through time t. The belief component, BH\u00a3, q), represents a boolean random vari able that is true if and only if the expansion of the symbol at level \u00a3 terminates at time t. The overall belief state pro-\nFunction Bh(q) Bj.(f,X,q) B},(f, (a, b), q) B\ufffd(x, q) Bi-(f,q) B\ufffdIN (f, X, q)\nDefinition Pr( Qt 1 = qj\u00a3t 2)\n= Pr(N} = XIEt-1' Qt-1 = q) = Pr(Pf = (a, b) l&t-1' Qt-1 = q) = Pr(:Et = xiEt-1, Qt-1 = q) = Pr(TfiEt-1, Qt-1 = q) = Pr(Tfit:t-1' Qt-1 = q, Nj =X)\nIf the productions introduce possible cycles (as in the PSDG of Figure 1 ), then there is no bound on the length of parse tree branches, so there is an infinite number of possi ble hierarchy levels (index \u00a3 in the belief state). However, we can still maintain a finite belief state even if we allow recursive productions of the form X -+ Y1Y2 \u00b7 \u00b7 \u00b7 Ym-lX, where the Yb :f:. X. The}/, children have\u00a3 indices as orig inally specified, but the X on the right-hand side now has the same\u00a3 index as the X on the left-hand side. Therefore, we expand the X on the right-hand side from N\u00a3+1. We choose a new production at Pj+1, so we no longer have any record (in the current branch) of how many levels of nesting have taken place. As long as we have no need of this lost information, we can generate a finite belief-state representation of a PSDG with this limited recursion.\nThe belief state probabilities are indexed by all of the indi vidual states q E Rt consistent with our observations. The specialized PSDG belief state structure has a space com plexity of O(IRti\u00b7IPidm), where dis the maximum depth of the hierarchy (the largest\u00a3 value) and m is the maxi mum production length. The fully connected DBN belief state has a space complexity of O(IQI \u00b7 IPidmd).\nThe compact belief state, Bt, no longer explicitly stores the conditional probabilities of production variables given the left-hand symbols, nor those of right-hand symbols given the production variables. We can extract these immediately from the probabilities available in the belief state. For in stance, we know that the probability of a production state, p = (X -+ Y1 \u00b7 \u00b7 \u00b7 Ym, b), is zero when the symbol X is not present. Thus, Pr(Pi = piNf = X, t:t, Qt = q) = Bj,(\u00a3, p, q)/ B}v-(\u00a3, X, q). The conditional probabilities of symbols given parent productions is even simpler, because of their deterministic nature. For instance, for non terminals\n}/, EN, Pr(Nj+l = Yb!Pf = p, t:t, Q1 = q) = 1.0.\n3.2 BELIEF STATE INITIALIZATION\nThe initial belief state begins with Bb(q) = Pr(Q0 = q), easily obtained from the prior probability function 1r0(q). We can then work top down, computing the probability for B}v(1, S, q), Bj,(1, (a, b), q), B}v(2, X, 1), . .. ,Bt(x, q). At each step, we compute production and symbol proba bilities using the generative method used in computing the\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 513\nprobability of the sample parse tree from Section 2.2.\n3.3 EXPLANATION PROBABILITIES\nGiven a new observation at time t, of the form Qt-1 E Rt-1, we can easily compute the probability of the individ ual state instantiations in Rt-1 using 1r1, Bq1, and B\ufffd-1. With the example observations of Figure 2, we would first compute the probability of the observed state Q1 given the initial state Q0 and the possible terminal symbols. Once we had these probabilities, we can marginalize over the set of terminal symbols to determine the probability of the ob served Q1 given only Q0. In general, the time complexity of computing this probability distribution is O(IRI21 \ufffdI).\nWe can then proceed bottom-up through the subplan hi erarchy to compute the probability of the evidence con ditioned on the possible states of the nonterminal symbol nodes, similar to a generalization of the transition prob ability function 1r1. These probability values are reused many times in subsequent computations within the current time slice. We can compute such probabilities recursively by starting with the base definition of 1r1 over all terminal symbols x E I:. We then proceed up through the hierarchy, where at each level, we compute the probability of all state transitions (consistent with our prior beliefs and new obser vations) given the possible nonterminal symbols. For each symbol, we can compute this transition probability by ex amining all of the possible expansions (based on our prior beliefs) in the context of the transition probabilities of the symbols on the right-hand side (computed in previous dy namic programming passes). If m is the maximum produc tion length, and dis the depth of the hierarchy, this dynamic programming phase takes time O(IRI21Pimd).\nWe can use the dynamic programming results to obtain posterior probability distribution over symbols and produc tions at time t- 1 conditioned on evidence up to and includ ing time t, useful for answering explanation queries. The computation requires only the constant-time combination of our prior beliefs over symbols with the transition proba bilities over these symbols.\n3.4 PREDICTION PROBABILITIES\nAfter completing the explanation phase, we compute pre diction probabilities for time t using the posterior proba bilities over the variables at time t - 1. We marginalize over the two possible termination cases fort -1, i.e., either an expansion terminated or it has not. If it has, then we choose a whole new production at time t using the produc tion probability functions. If the expansion has not termi nated at time t-1, then we continue the expansion at timet. If the child symbol's expansion has terminated at time t-1, then we deterministically move to the next symbol on the right-hand side at timet. Otherwise, we continue expand ing the same child symbol. We must then marginalize over\nthe possible states, so the time complexity of computing all of the prediction probabilities is O(IRidiPim).\n3.5 COMPUTATION OF NEW BELIEF STATE\nThe prediction phase specifies the symbol and production components of the new belief state Bt. It is straightfor ward, from the definition of termination, to compute the re quired probability of termination given a particular symbol in a single bottom-up pass through the symbol and produc tion probabilities at each level of the hierarchy. We can then marginalize this result to compute the termination proba bility independent of symbol. We can compute these prob abilities in a single bottom-up pass through the hierarchy requiring time O(IRidiPI).\n3.6 EVALUATION OF PSDG INFERENCE\nOverall, these algorithms compute prediction and expla nation probabilities over the low-level actions, complex plans, and intermediate plan states. In addition, the be lief state continually updates its distribution over the un observed state variables, allowing a recognizing agent to reason about another agent's mental state. The PSDG in ference algorithms thus support many of the queries desired by recognizing agents in multiagent environments.\nHowever, the algorithms cannot exploit direct evidence about plans. Evidence about subplan choices usually comes in the form of explicit communication. For instance, a driver in a convoy may radio its intended lane change to the other drivers. Such evidence would introduce new dependencies to the belief state structure that are likely to greatly increase the complexity of the inference algorithms.\nThe overall inference algorithms for a single time step have time complexity O(IRI\u00b7II:I\u00b7IQI + IRI2diPim). If we do not compute a probability distribution over future state Qt (the distribution is not necessary for answering queries about only plans), the time complexity is O(IRI2diPim). An entire inference cycle (explanation, prediction, and belief update) takes 1 CPU second for the full traffic monitoring PSDG (where IQI \ufffd 6 x 101\\ IRI = 18,1\ufffd1 = 7, d = 6, IPI = 37, and m = 3), with the inference algorithms run ning on a SUN Spare machine. The inference for the air combat PSDG (where IQI = 1150,IRI = I. I I: I = 3, d = 6, IPI = 34, and m = 3) was even faster due to the complete observability of the state variables in that domain.\nAlthough the specialized algorithms save considerably over the DBN algorithms, the time and space complexity is still quadratic in the number of instantiations of the unobserved state variables. This cost is potentially prohibitive, since the number of such state instantiations grows exponentially with the number of unobserved state variables. This com plexity is clearly the limiting factor when determining the tractability of the PSDG approach in a given domain.\n514 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\n4 CONCLUSION\nThe assumptions of the PSDG model and inference al gorithms sacrifice the generality of some existing prob abilistic languages (Koller et a!., 1997; Goldman et a!., 1999). However, the restrictions of the PSDG model pro duce the independence properties that the algorithms ex ploit for practical inference. If we relax these restrictions (e.g., state transition probabilities depending on nontermi nal symbols as well), we can no longer partition the be lief state along the different levels of the hierarchy. Even within the existing restrictions, in domains with more com plex models of unobservable mental states, the complexity of inference could be prohibitive. One potential solution is the use of approximation methods used with similar dy namic belief models (Boyen & Koller, 1998; Ghahramani & Jordan, 1997).\nLearning algorithms, analogous to those for PCFGs, could potentially automatically generate PSDG produc tions, states, and probabilities based on labeled parse trees. Such learning algorithms would reduce the effort required in domain specification, as well as potentially supporting dynamic PSDGs that could adapt to changes in an agent's behavior. However, in domains where the observed agent's behavior depends significantly on the recognizing agent's decisions (as in the clearly adversarial domain of air com bat), even such a dynamic PSDG specification would be too weak to perform the reflexive modeling required.\nThe PSDG language contributes a new representation that exploits the partition between plans and state that exists in most plan-recognition domains. We successfully created PSDG models of planning agents in two domains, one re quiring creation of a new specification from scratch and the other requiring translation of an existing specification into the PSDG language. We were able to develop algo rithms for automatic generation of a DBN representation of a PSDG domain model, but the resulting networks were impractical for inference. We then designed specialized al gorithms that used a compact belief state to summarize the entire sequence of observations while incurring time and space complexity costs that are sublinear in the space of possible plan instantiations. Therefore, the PSDG language model supports practical probabilistic plan recognition in domains where existing languages do not.\nReferences\nBlack, E., Jelinek, F., Lafferty, J., Magerman, D. M., Mercer, R., & Roukos, S. (1992). Towards history-based grammars: Us ing richer models for probabilistic parsing. In Proceedings of the DARPA Speech and Natural Language Workshop, pp. 31-37.\nBoyen, X. & Koller, D. (1998). Tractable inference for complex stochastic processes. In Proceedings of the Conference on Uncertainty in Artificial Intelligence, pp. 33-42.\nCarroll, J. & Weir, D. (1997). Encoding frequency information in lexicalized grammars. In Proceedings of the International Workshop on Parsing Technologies, pp. 8-17.\nCharniak, E. (1993). Statistical Language Learning. MIT Press, Cambridge, MA.\nCharniak, E. & Goldman, R. P. (1993). A Bayesian model of plan recognition. Artificial Intelligence, 64(1):53-79.\nGhahramani, Z. & Jordan, M. I. (1997). Factorial hidden Markov models. Machine Learning, 29:245-275.\nGoldman, R. P., Geib, C. W., & Miller, C. A. (1999). A new model of plan recognition. In Proceedings of the Conference on Uncertainty in Artificial Intelligence, pp. 245-254.\nGonzalez, R. C. & Thomason, M. S. (1978). Syntactic Pattern Recognition: An Introduction. Addison-Wesley, Reading, MA.\nKautz, H. A. & Allen, J. F. (1986). Generalized plan recognition. In Proceedings of the National Conference on Artificial In telligence, pp. 32-37.\nKjrerulff, U. (1992). A computational scheme for reasoning in dy namic probabilistic networks. In Proceedings of the Confer ence on Uncertainty in Artificial Intelligence, pp. 121-129.\nKoller, D., McAllester, D., & Pfeffer, A. (1997). Effective Bayesian inference for stochastic programs. In Proceed ings of the National Conference on Artificial Intelligence, pp. 740-747.\nLesh, N. & Allen, J. (1999). Simulation-based inference for plan monitoring. In Proceedings of the National Conference on Artificial Intelligence, pp. 358-365.\nLin, D. & Goebel, R. (1991). A message passing algorithm for plan recognition. In Proceedings of the International Joint Conference on Artificial Intelligence, pp. 280-285.\nMagerman, D. M. (1995). Statistical decision-tree models for parsing. In Proceedings of the Annual Meeting of the As sociation for Computational Linguistics, pp. 276-283.\nNewell, A. (1990). Unified T heories of Cognition. Harvard Uni versity Press, Cambridge, MA.\nPynadath, D. V. (1999). Probabilistic Grammars for Plan Recog nition. PhD thesis, University of Michigan.\nPynadath, D. V. & Wellman, M. P. (1995). Accounting for context in plan recognition, with application to traffic monitoring. In Proceedings of the Conference on Uncertainty in Artificial Intelligence, pp. 472-481.\nPynadath, D. V. & Wellman, M.P. (1998). Generalized queries on probabilistic context-free grammars. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(1):65-77.\nSchabes, Y. & Waters, R. C. (1993). Stochastic lexicalized context-free grammar. In Proceedings of the International Workshop on Parsing Technologies, pp. 257-266.\nTambe, M. & Rosenbloom, P. S. (1996). Event tracking in a dynamic multi-agent environment. Computational Intelli gence, 12(3):499-521."}], "references": [{"title": "Statistical Language Learning", "author": ["E. Charniak"], "venue": null, "citeRegEx": "Charniak,? \\Q1993\\E", "shortCiteRegEx": "Charniak", "year": 1993}, {"title": "A new model of plan recognition", "author": ["C.W. Geib", "C.A. Miller"], "venue": "In Proceedings of the Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "P. et al\\.,? \\Q1999\\E", "shortCiteRegEx": "P. et al\\.", "year": 1999}, {"title": "Syntactic Pattern Recognition: An Introduction", "author": ["R.C. Gonzalez", "M.S. Thomason"], "venue": null, "citeRegEx": "Gonzalez and Thomason,? \\Q1978\\E", "shortCiteRegEx": "Gonzalez and Thomason", "year": 1978}, {"title": "Generalized plan recognition", "author": ["H.A. Kautz", "J.F. Allen"], "venue": "In Proceedings of the National Conference on Artificial In\u00ad telligence,", "citeRegEx": "Kautz and Allen,? \\Q1986\\E", "shortCiteRegEx": "Kautz and Allen", "year": 1986}, {"title": "A computational scheme for reasoning in dy\u00ad namic probabilistic networks", "author": ["U. Kjrerulff"], "venue": "In Proceedings of the Confer\u00ad ence on Uncertainty", "citeRegEx": "Kjrerulff,? \\Q1992\\E", "shortCiteRegEx": "Kjrerulff", "year": 1992}, {"title": "Effective Bayesian inference for stochastic programs", "author": ["D. Koller", "D. McAllester", "A. Pfeffer"], "venue": "In Proceed\u00ad ings of the National Conference on Artificial Intelligence,", "citeRegEx": "Koller et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Koller et al\\.", "year": 1997}, {"title": "Simulation-based inference for plan monitoring", "author": ["N. Lesh", "J. Allen"], "venue": "In Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "Lesh and Allen,? \\Q1999\\E", "shortCiteRegEx": "Lesh and Allen", "year": 1999}, {"title": "A message passing algorithm for plan recognition", "author": ["D. 358-365. Lin", "R. Goebel"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence,", "citeRegEx": "Lin and Goebel,? \\Q1991\\E", "shortCiteRegEx": "Lin and Goebel", "year": 1991}, {"title": "Statistical decision-tree models for parsing", "author": ["D.M. Magerman"], "venue": "In Proceedings of the Annual Meeting of the As\u00ad sociation for Computational Linguistics,", "citeRegEx": "Magerman,? \\Q1995\\E", "shortCiteRegEx": "Magerman", "year": 1995}, {"title": "Unified T heories of Cognition", "author": ["A. Newell"], "venue": null, "citeRegEx": "Newell,? \\Q1990\\E", "shortCiteRegEx": "Newell", "year": 1990}, {"title": "Probabilistic Grammars for Plan Recog\u00ad nition", "author": [], "venue": "PhD thesis, University of Michigan", "citeRegEx": ".1999..,? \\Q1999\\E", "shortCiteRegEx": ".1999..", "year": 1999}, {"title": "Accounting for context in plan recognition, with application to traffic monitoring", "author": ["D.V. Pynadath", "M.P. Wellman"], "venue": null, "citeRegEx": "Pynadath and Wellman,? \\Q1995\\E", "shortCiteRegEx": "Pynadath and Wellman", "year": 1995}, {"title": "Generalized queries on probabilistic context-free grammars", "author": ["D.V. Pynadath", "M.P. Wellman"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Pynadath and Wellman,? \\Q1998\\E", "shortCiteRegEx": "Pynadath and Wellman", "year": 1998}, {"title": "Stochastic lexicalized context-free grammar", "author": ["Y. Schabes", "R.C. Waters"], "venue": "In Proceedings of the International Workshop on Parsing Technologies,", "citeRegEx": "Schabes and Waters,? \\Q1993\\E", "shortCiteRegEx": "Schabes and Waters", "year": 1993}, {"title": "Event tracking in a dynamic multi-agent environment", "author": ["M. Tambe", "P.S. Rosenbloom"], "venue": "Computational Intelli\u00ad gence,", "citeRegEx": "Tambe and Rosenbloom,? \\Q1996\\E", "shortCiteRegEx": "Tambe and Rosenbloom", "year": 1996}], "referenceMentions": [{"referenceID": 4, "context": "Dynamic Bayesian networks (DBNs) (Kjrerulff, 1992) rep\u00ad resent only a restricted window of the random variables by using a compact belief state to summarize the past ob\u00ad servations.", "startOffset": 33, "endOffset": 50}, {"referenceID": 8, "context": "Other grammatical models (Black et al., 1992; Schabes & Waters, 1993; Carroll & Weir, 1997; Magerman, 1995) make fewer independence assumptions than do PCFGs (thus supporting a wider class of problem domains), while still supporting efficient parsing algorithms.", "startOffset": 25, "endOffset": 107}, {"referenceID": 9, "context": "We also imple\u00ad mented a PSDG representation for an air combat domain based on an existing specification (Tambe & Rosenbloom, 1996) using Soar productions (Newell, 1990).", "startOffset": 154, "endOffset": 168}], "year": 2011, "abstractText": "Techniques for plan recogmtwn under uncer\u00ad tainty require a stochastic model of the plan\u00ad generation process. We introduce probabilistic state-dependent grammars (PSDGs) to represent an agent's plan-generation process. The PSDG language model extends probabilistic context\u00ad free grammars (PCFGs) by allowing production probabilities to depend on an explicit model of the planning agent's internal and external state. Given a PSDG description of the plan-generation process, we can then use inference algorithms that exploit the particular independence proper\u00ad ties of the PSDG language to efficiently answer plan-recognition queries. The combination of the PSDG language model and inference algorithms extends the range of plan-recognition domains for which practical probabilistic inference is pos\u00ad sible, as illustrated by applications in traffic mon\u00ad itoring and air combat.", "creator": "pdftk 1.41 - www.pdftk.com"}}}