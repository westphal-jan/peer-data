{"id": "1301.7397", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2013", "title": "Magic Inference Rules for Probabilistic Deduction under Taxonomic Knowledge", "abstract": "We present locally complete inference rules for probabilistic deduction from taxonomic and probabilistic knowledge-bases over conjunctive events. Crucially, in contrast to similar inference rules in the literature, our inference rules are locally complete for conjunctive events and under additional taxonomic knowledge. We discover that our inference rules are extremely complex and that it is at first glance not clear at all where the deduced tightest bounds come from. Moreover, analyzing the global completeness of our inference rules, we find examples of globally very incomplete probabilistic deductions. More generally, we even show that all systems of inference rules for taxonomic and probabilistic knowledge-bases over conjunctive events are globally incomplete. We conclude that probabilistic deduction by the iterative application of inference rules on interval restrictions for conditional probabilities, even though considered very promising in the literature so far, seems very limited in its field of application.", "histories": [["v1", "Wed, 30 Jan 2013 15:05:34 GMT  (397kb)", "http://arxiv.org/abs/1301.7397v1", "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)"]], "COMMENTS": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["thomas lukasiewicz"], "accepted": false, "id": "1301.7397"}, "pdf": {"name": "1301.7397.pdf", "metadata": {"source": "CRF", "title": "Magic Inference Rules for Probabilistic Deduction under Taxonomic Knowledge", "authors": ["Thomas Lukasiewicz"], "emails": ["lukasiewicz@informatik.uni-giessen.de"], "sections": [{"heading": null, "text": "We present locally complete inference rules\nfor probabilistic deduction from taxonomic and probabilistic knowledge-bases over conjunctive events. Crucially, in contrast to similar infer ence rules in the literature, our inference rules are locally complete for conjunctive events and under additional taxonomic knowledge. We dis cover that our inference rules are extremely com plex and that it is at first glance not clear at all where the deduced tightest bounds come from. Moreover, analyzing the global completeness of our inference rules, we find examples of glob ally very incomplete probabilistic deductions. More generally, we even show that all systems\nof inference rules for taxonomic and probabilis tic knowledge-bases over conjunctive events are globally incomplete. We conclude that proba bilistic deduction by the iterative application of inference rules on interval restrictions for condi tional probabilities, even though considered very promising in the literature so far, seems very lim ited in its field of application.\n1 INTRODUCTION\nRepresenting and reasoning with uncertain knowledge has gained growing importance in the recent decades. The lit erature contains many different formalisms and methodolo gies for tackling uncertainty. Most of them are directly or indirectly based on probability theory.\nIn this paper, we focus on interval restrictions for condi tional probabilities as probabilistic knowledge. The con sidered probabilistic deduction problems consist of a prob\nabilistic knowledge-base and a probabilistic query. We give a classical example. As a probabilistic knowledge-base, we take the probabilistic knowledge that all ostriches are birds, that ostriches do not fly, that at least 95% of all birds fly, and\nthat not more than 10% of all birds are ostriches. As a prob abilistic query, we may wonder about the entailed greatest lower bound and the entailed least upper bound for the rate of all birds that are ostriches. The solution to this proba bilistic deduction problem is 0% for the entailed greatest lower bound, and 5% for the entailed least upper bound.\nThis kind of probabilistic deduction problems can be solved in a global approach by linear programming or in a local approach by the iterative application of inference rules. The global approach by linear programming (see, for example, [21], [12], [22], [10], [15], [14], [3], and [18]) can be performed within rich probabilistic languages capa ble of representing many facets of probabilistic knowledge (see especially [10]). Probabilistic deduction by linear pro gramming is globally complete, that is, it really produces\nthe requested tightest bounds entailed by the whole prob abilistic knowledge-base. However, it generally runs in\nexponential time in the size of the probabilistic deduction problems. Moreover, it cannot provide any explanatory in formations on how the deduced results are obtained.\nMainly to overcome these deficiencies, researchers started to work on local techniques based on inference rules. The local approach (see, for example, [7], [9], [2], [8], [25], [11], [13], and [16]) is generally performed within more restricted probabilistic languages. The iterative application of inference rules is very rarely and only within very re stricted probabilistic languages globally complete (see [11] for an example of globally complete local probabilistic de\nduction in a very restricted framework). Moreover, if the inference rules allow complex events, then they are gener ally even not locally complete anymore, that is, they gen\nerally even do not produce the tightest bounds entailed by the partial probabilistic knowledge in their premises (see [11] and [13] for inference rules that are locally complete only for complex events that are not logically related). Lo cal approaches are generally expected to be more efficient than global ones. Furthermore, they can elucidate the de duction process by the sequence of applied inference rules.\nThe local approach has been considered very promising in the literature so far. However, its major drawback for prac-\nMagic Inference Rules for Probabilistic Deduction 355\ntical applications is its global incompleteness. In partic ular, it is very disappointing that even the inference rules are generally not locally complete anymore for complex events. Hence, the first motivating idea of this paper is to elaborate new inference rules that are locally complete for complex events. Following this idea, we also hope to make a big step towards global completeness.\nComing back to our introductory example, we observe that the sentences that all ostriches are birds and that os triches do not fly are not purely probabilistic. That is, the probabilistic knowledge-base implicitly contains tax onomic knowledge. Many practical applications in fields like, for example, biology, technology, and medicine re quire the representation of this kind of taxonomic knowl edge besides purely probabilistic knowledge. Own prelim inary results in [16] now show that taxonomic knowledge can be exploited for an increased efficiency and a decreased incompleteness in the local approach to probabilistic de duction. Thus, the second motivating idea of this paper is to explore the interplay between taxonomic and probabilis tic knowledge in probabilistic deduction, and to elaborate inference rules that exploit taxonomic knowledge. The re\nlationship between taxonomic and probabilistic knowledge is also analyzed in [13], where probabilistic knowledge is integrated into a terminological language.\nWe choose taxonomic and probabilistic knowledge-bases over conjunctive events as a concrete framework in which our motivating ideas shall be realized. In this frame work, the deduction of probabilistic knowledge is NP-hard (we show in [19] that it is even NP-hard for probabilistic knowledge-bases over basic events), while the deduction of taxonomic knowledge can be done in linear time in the size of the taxonomic knowledge-base. Hence, each in\nference rule that exploits taxonomic knowledge can also be applied in linear time in the size of the taxonomic\nknowledge-base. Furthermore, taxonomic and probabilis tic knowledge-bases over conjunctive events are still ex pressive enough for many practical applications.\nThe main contributions of this paper can be summarized as follows. As a first contribution, we present locally com plete inference rules for probabilistic deduction from taxo\nnomic and probabilistic knowledge-bases over conjunctive events. More precisely, the presented inference rules de duce logically entailed tightest bounds from a biconnected chain of three conjunctive events under additional taxo nomic knowledge over conjunctive events. Crucially, in\ncontrast to existing inference rules in the literature, our in ference rules are locally complete for conjunctive events\nand under additional taxonomic knowledge.\nAs a second contribution, we discover that the presented in ference rules are surprisingly complex and that it is a huge technical effort to work them out and to show their sound ness and local completeness. Thus, since it is not obvious\nat all where the deduced tightest bounds come from, we call them 'magic' inference rules. Hence, it seems unlikely that other locally complete inference rules that have more gen eral or more extensive taxonomic and probabilistic knowl edge in their premises can be worked out.\nAs a third contribution, we show that all systems of in ference rules for probabilistic deduction in taxonomic and probabilistic knowledge-bases over conjunctive events are as a matter of principle globally incomplete. In particular, we also provide examples of taxonomic and probabilistic knowledge-bases in which our magic inference rules yield globally very incomplete probabilistic deductions.\nThe latter contributions are negative results, which are im portant for the whole probabilistic community. They show\nthat local probabilistic deduction by the iterative applica tion of inference rules on interval restrictions for condi tional probabilities is very limited in its field of application.\nThe rest of this paper is organized as follows. In Section 2, we introduce the technical background of this work. In Section 3, we briefly discuss the computational complex ity of probabilistic deduction. Section 4 provides a moti vating example. In Sections 5 and 6, we present and dis cuss our magic inference rules for locally complete proba bilistic deduction under taxonomic knowledge. Section 7 summarizes the main results and underlines the general impact of this work.\nThis paper is a revised extract of own work from [17], which we extended by a short discussion on the compu tational complexity of probabilistic deduction. Preliminary results of this paper have been presented in [ 16].\n2 TECHNICAL PRELIMINARIES\nWe briefly give a more general introduction to the kind of taxonomic and probabilistic knowledge considered in this\nwork. We deal with taxonomic and probabilistic formulas over propositional events. More precisely, taxonomic for mulas represent implications between propositional events, while probabilistic formulas express interval restrictions for conditional probabilities of propositional events. The technical background introduced in this section is com monly accepted in the literature (see, for example, [11] for other work in the same spirit).\nWe assume a nonempty and finite set of basic events B = {B1, Bz, ... , Bn}\u00b7 The set of conjunctive events C13 com prises the false event ..1.., the true event T, and all members in the closure of B under the Boolean operation /\\. We abbreviate the conjunctive event C 1\\ D by CD. The set of propositional events Yl3 is the closure of B under the Boolean operations 1\\ and ..., _ We abbreviate the proposi tional events B1 1\\ -,B1 and -,(B1 1\\ -,B1) by ..1.. and T, respectively. We abbreviate the propositional events G 1\\ H and -,Q by GH and G, respectively. Taxonomic formulas\n356 Lukasiewicz\nare expressions G --r H with propositional events G and H. Probabilistic fonnulas are expressions (H/G)[u1, u2] with real numbers u1, u2 E (0, 1] and propositional events G and H. In the probabilistic formula (H/G)[u1, u2], we call G the premise and H the conclusion.\nIn order to define probabilistic interpretations of proposi tional events, taxonomic formulas, and probabilistic formu las, we introduce atomic events and the binary relation '=>' between atomic and propositional events. The set of atomic events AB is defined by AB = { E 1 E2 \u00b7 \u00b7 \u00b7 En / Ei = Bi or Ei = Bi for all i E (1 : n]}. The atomic events of our framework coincide with the more commonly known pos sible worlds from probabilistic logic [21]. For all atomic events A and all propositional events G, let A=> G iff AG is a propositional contradiction.\nA probabilistic interpretation Pr is a mapping from AB to (0, 1] such that all Pr(A) with A E AB sum up to 1. Pr is extended in a well-defined way to propositional events G by Pr(G) = l:AEA.a,A=>G Pr(A). Pr is extended to tax onomic formulas by Pr F G --r H iff Pr(G) = Pr( GH). Pr is extended to probabilistic formulas by:\nPr F (H/G)[u1,u2] iff u1 \u00b7 Pr( G) ::; Pr( GH) ::; u2 \u00b7 Pr( G) .\nT he notions of models, satisfiability, and logical conse quence for taxonomic and probabilistic formulas are de fined in the classical way. A probabilistic interpretation Pr is a model of a formula F iff Pr F F. Pr is a model of a set of formulas KB, denoted Pr F KB, iff Pr is a model of all F E KB. A set of formulas KB is satisfiable iff a model of KB exists. A formula F is a logical consequence of a set of formulas KB, denoted KB F F, iff each model of KB is also a model of F.\nFor a probabilistic formula (H/G)[u1, u2] and a set of tax onomic and probabilistic formulas KB, let u denote the set of all real numbers u E (0, 1] for which there exists a model Pr of KB with Pr F (H/G)[u, u] and Pr(G) > 0. Now, we easily verify that (H/G)[u1, u2] is a logical con sequence of KB iff u1 ::; inf u and u2 \ufffd sup u.\nThis observation yields a canonic notion of tightness for logical consequences of probabilistic formulas: the prob abilistic formula (H/G)(u1, u2] is a tight logical conse quence of KB, denoted KB Ftight (H/G)[ul,u2], iff u1 = inf u and u2 = sup u. Note that u is a closed interval in the real numbers (see, for example, [11] and [17]). For u = 0, we canoni cally define inf u = 1 and sup u = 0. Now, u = 0 iff KB F (G/T)(O,O] iff KB Ftight (H/G)(1,0] iff KB F (H/G)[ul, u2] for all u1, u2 E (0, 1]. Based on the notions of logical consequence and of tight logical consequence, we now define probabilistic deduction problems and their solutions, that is, probabilistic queries\nto taxonomic and probabilistic knowledge-bases and their correct and tight answers.\nA taxonomic knowledge-base TKB is a set of taxonomic formulas. A probabilistic knowledge-base PKB is a set of probabilistic formulas (H/G)(u1, u2] with u1 ::; u2\u2022 A tax onomic and probabilistic knowledge-base KB is the union of a taxonomic knowledge-base TKB and a probabilistic knowledge-base PKB. A probabilistic query to KB is an expression 3(F/E)[xl, x2] with propositional events E and F, and two different variables x1 and x2. Its tight answer is the substitution u = {xrfu1, x2/u2} with u1,u2 E (0, 1] such that KB Ftight (F/E)[u1,u2]. A correct answer is a substitution u = {xrful, x2/u2} with u1, u2 E [0, 1) such that KB F (F/E)[u1,u2]. Given a probabilistic query 3( F/E) [ x1, x2], we consider its tight answer as the desired semantics: first, the tight answer for 3(F/E)(xl, x2] subsumes all correct answers. Second, there is exactly one tight answer for 3(F/E)[x1, x2], while there is generally an infinite number of correct answers. Third, also from the practical point of view, we are inter ested in the tightest bounds that are entailed by a taxonomic and probabilistic knowledge-base.\nFinally, we define the notions of soundness and of com pleteness related to inference rules and to techniques for probabilistic deduction. An inference rule KB 1- F is sound iff KB F F, where F is a taxonomic o r proba bilistic formula and KB is a taxonomic and probabilistic knowledge-base. An inference rule KB 1- (H/G)[u1, u2] is sound and locally complete iff KB Ftight (H/G)[ul, u2]. A technique for probabilistic deduction is sound iff it com putes a correct answer for any given probabilistic query. It is sound and globally complete iff it computes the tight answer for any given probabilistic query.\n3 COMWUTATIONAL COMWLEXITY\nIn the just introduced framework of taxonomic and proba bilistic formulas over propositional events, the problem of computing the tight answer for a probabilistic query is NP hard, since it is a generalization of the satisfiability problem for probabilistic logic, which is known to be NP-complete from [12]. Moreover, the problem of deciding whether a taxonomic knowledge-base is satisfiable is NP-complete, since it generalizes the NP-complete satisfiability problem for propositional logic, and since it is generalized by the NP-complete satisfiability problem for probabilistic logic. Hence, from the computational complexity point of view, it is reasonable to focus on a more restricted class of prob abilistic deduction problems.\nSurprisingly, even the problem of computing the tight an swer for a probabilistic query over basic events t o a proba bilistic knowledge-base over basic events is NP-hard, as we show in [ 19]. While already in the framework of taxonomic\nMagic Inference Rules for Probabilistic Deduction 357\nformulas over conjunctive events, the problem of decid ing whether a taxonomic formula is a logical consequence\nof a taxonomic knowledge-base can be solved in linear time in the size of the taxonomic knowledge-base. More\nprecisely, taxonomic formulas over conjunctive events are\nwell-known as functional dependencies in database theory (see, for example, [4] and [24]). The results of this area show that deducing taxonomic formulas over conjunctive events from taxonomic knowledge-bases over conjunctive events can be done in linear time by using a hull-operator on the set of all subsets of B U {1-} (see [ 16] and [ 17]). In the sequel, we focus on probabilistic queries over con junctive events to taxonomic and probabilistic knowledge bases over conjunctive events. In this framework, the deduction of probabilistic knowledge remains NP-hard. However, at least each inference rule that exploits taxo nomic knowledge can be applied in linear time in the size of the taxonomic knowledge-base. The next section provides a medical example, which shows the practical importance of this kind of probabilistic deduction problems.\n4 EXAMPLE\nWe consider the following taxonomic knowledge about bacterial infections. Tuberculosis of the lungs (tb) and lep romatous leprosy (lep) are different gram-positive bacte rial infections (g-pos). Legionellosis (leg), cholera (chol), and typhoid (typh) are different gram-negative bacterial in fections (g-neg). Gram-positive bacterial infections and gram-negative bacterial infections are different bacterial in fections (T). The symptoms of tuberculosis are cough ing (cough), chest pain (chest), and coughing up blood (cough_bl). The symptoms of leprosy are a stuffy nose (sLnose), and skin lesions and nodules (skin_le_no). This taxonomic knowledge can be expressed by the following\ntaxonomic formulas over Cs with the set of basic events B = {tb, lep, g-pos, leg, chol, typh, g-neg, cough, chest, cough_bl, sLnose, skin_le_no} (note that g-pos ---t T and g-neg ---t T are tautologies):\ntb lep ---t g-pos, tb lep ---t ..l, leg ---t g-neg, chol ---t g-neg, typh ---t g-neg, leg chol ---t ..l, leg typh ---t ..l, chol typh ---t ..l, g-pos g-neg ---t ..l, tb ---t cough chest cough_bl, lep ---t sLnose skin_le_no.\nThe symptoms of many diseases cannot be clearly defined, since different human bodies may react in different ways\nto an infection. We assume the following probabilistic knowledge about the symptoms of legionellosis, cholera, and typhoid. More than 80% of the persons infected by legionellosis have muscle aches (muscle), headache (head), tiredness (tired), dry cough followed by high fever (d_cough_h_fever), and chills (chills). More than 60% have diarrhea (diar). More than 80% of the persons in fected by cholera have a mild diarrhea (m_diar). More\nthan 70% of the persons infected by typhoid have relapses (relap). More than 80% have fever (fever), headache, constipation or diarrhea (consLor _diar), rose-colored spots on the trunk (spots), and an enlarged spleen and liver (enLspJi). Involving the additional basic events muscle, head, tired, d_cough_h_fever, chills, diar, m_diar, relap, fever, consLor _diar, spots, enl....spJi and the additional tax onomic formulas\nd_cough_h_fever ---t cough fever, m_diar ---t diar, diar ---t consLor _diar,\nwe can express this probabilistic knowledge about the symptoms of legionellosis, cholera, and typhoid by the fol lowing probabilistic formulas:\n(muscle head tired d_cough_h_fever chillsjleg)[.8, 1], (diarjleg)[.6, 1], (m_diarjchol)[.8, 1], (relapjtyph)[.7, 1], (fever head consLor _diar spots enl....spJijtyph)[.8, 1].\nWondering about the tightest lower and upper bound of the probability that typhoid causes fever and headache, we get the probabilistic query 3(fever headjtyph)[x1,x2], which yields the tight answer a = {xi/ .8, x2/1 }.\n5 THE INFERENCE RULES\nThe literature contains a variety of different inference rules for deducing probabilistic formulas from probabilis\ntic knowledge-bases. If we analyze all these inference rules more deeply, we make two important observations. First, nearly all the results of local completeness just hold for\nprobabilistic formulas over pairwise different basic events. Second, the interplay between taxonomic and probabilistic knowledge is not fully explored so far. In this section, we now present inference rules that are locally complete for probabilistic formulas over conjunctive events under addi, tional taxonomic knowledge over conjunctive events.\nWe start with fixing the inference patterns of our infer ence rules. The premise of all selected inference rules\nis a taxonomic knowledge-base over conjunctive events and a biconnected chain of three (not necessarily pair wise different) conjunctive events. In detail, it is given by KB = TKB U PKB, where TKB is an arbitrary taxonomic knowledge-base over conjunctive events and PKB = {(BjA)[u1,u2], (AjB)[v1,v2], (CjB)[x1,x2], (BjC)[y1, Y2]} with conjunctive events A, B, and C. The conclusions of the selected inference rules provide the log ically entailed tightest bounds for all probabilistic formulas that can be built from the three conjunctive events A, B, and C. In detail, they are given by (the deduced tightest bounds z1 and z2 are presented at the end of this section): \u2022 SHARPENING: (BjA)[z1,z2], (AjB)[z\ufffd,z2] \u2022 CHAINING: (CjA)[z1,z2]\n358 Lukasiewicz\n\u2022 FUSION: (ACIB)[z1, z2], (BIAC)[z1, z2] \u2022 COMBINATION: (CIAB)[z1,z2], (ABIC)[z1,z2] We chose these inference rules, since there is already a quite extensive literature on similar inference rules, which are locally complete for biconnected chains of three pair wise different basic events without any taxonomic knowl edge beside (see, for example, [9], [2], [25], [8], and [13]). Hence, the selected inference rules seem to be quite im portant, and they also have well-explored counterparts in restricted frameworks, which may serve for comparisons.\nIt remains to compute the deduced tightest bounds in the selected inference rules. Let us first give some examples to get a rough idea on possible problems that may arise to our work. Let B = {A, 8, C} and let KB = TKB U PKB, where TKB is given by Table 1, left side, and PKB is given by the conjunctive events A, B, and C in Table 1, right side, and by the bounds in Table 2.\nTable 1: Taxonomic Knowledge\nTKB A B c (a) {ABC-+ _i} A 8 c (b) {C-+ A, AB-+ C} A 8 c (c) {C-+ A} A 8 c (d) {BC-+ A} A 8 c (e) 0 A 8 AC\nTable 2: Probabilistic Knowledge\n(BIA) (AlB) (CIB) (BIG) (a) (0.90, 0.95] (0.90, 0.95] (0.20, 0.25] (0. 75, 0.80] (b) (0.85, 0.90] (0.30, 0.35] (0.20, 0.25] (0. 75, 0.80] (c) (0.90, 0.95] (0.30, 0.35] (0.20, 0.25] (0.75, 0.80] (d) (0.90, 0.95] (0.30, 0.35] (0.20, 0.25] (0. 75, 0.80] (e) (0.90, 0.95] (0.30, 0.35] (0.20, 0.25] (0. 75, 0.80]\nAt first sight, the examples (a) to (e) seem harmless. How ever, KB in (b), (c), and (e) logically entails A -+ l_ and C -+ l_. Moreover, KB in (a), (c), (d), and (e) logically entails B -+ l_. Hence, each probabilistic knowledge-base in (a) to (e) contains at least one probabilistic formula with a false premise. Of course, we should exclude taxonomic and probabilistic knowledge-bases like the ones in (a) to (e) from the premises of our inference rules:\nA taxonomic and probabilistic knowledge-base KB is in consistent iff it contains at least one (BIA)[u1, u2] with KB f= A -+ l_. A taxonomic and probabilistic knowledge base KB is consistent iff it is not inconsistent. Where do the false premises in the probabilistic formulas of PKB come from? Interestingly, KB is always consis tent if we assume that TKB = 0 and that A, B, and C are three pairwise different basic events. However, an inconsis tency may arise if we have explicit taxonomic knowledge in\nTKB or implicit taxonomic knowledge in the structure of the conjunctive events A, B, and C (for example, if A = A and C = AC, then 0 f= C -+ A, and thus TKB f= C -+ A for all taxonomic knowledge-bases TKB). The next theorem characterizes the consistency of the premises of our inference rules. It requires the following notion of coherence: KB = TKB U PKB is coherent iff for all (BIA)[ul, u2] E PKB: TKB f= AB -+ l_ <=> u2 = 0, and TKB f= A -+ B <=> u1 = 1.\nTheorem 5.1 Let KB = TKB U PKB be a coherent taxonomic and probabilistic knowledge-base, where TKB is an arbitrary taxonomic knowledge-base and PKB = {(BIA)[ul, u2], (AIB)[v1, v2], (CIB)[x1, x2], (BIC)[yl, y2]}. KB is inconsistent iff one of the conditions ( 1) to (7) holds. If one of(J) to (4) holds, then KB f= A -+ 1_, C -+ l_. If one of ( 3) to (7) holds, then KB f= B -+ l_. (1) TKB f= A-+ C, BC-+ A andu2 < Y1. (2) TKB f= C-+ A, AB-+ C andu1 > Y2\u00b7\n(3) TKB f= A-+ C andu2x2(1- Yl) < v1y1(1- u2),\n(4) TKB f= C-+ A and u1x1 (1- Y2) > V2Y2(1- u1),\n(5) TKB f= AB -+ C and v1 > x2, (6) TKB f= BC-+ Aandv2 < x1. (7) TKB f= ABC -+ l_ and x1 + v1 > 1.\nProof. The proof is given in full detail in [ 17]. D\nComing back to our examples, for (a) with TKB = {ABC -+ l_ }, we get TKB f= ABC -+ l_ and x1 + v1 = 0.2 + 0.9 = 1.1 > 1. Hence, by Theorem 5.1, KB is in consistent with KB f= B -+ l_. For (e) with A = A and C = AC, we get 0 f= C -+ A. Thus, TKB f= C -+ A and U!Xl (1-Y2) = 0.9. 0.2. (1- 0.8) > 0.35. 0.8. (1-0.9) = v2y2(1- u1). Hence, by Theorem 5.1, KB is inconsistent with KB f= A -+ 1_, B -+ 1_, C -+ l_. In summary, the premises of our inference rules must be coherent and consistent. The coherence can be checked by simply applying its plain definition, while the consistency can thereafter be checked with Theorem 5 .1.\nWe are ready to proceed with our inference rules. Again, before focusing on their technical details, let us give some illustrating examples. Let B = {A, 8, C} and let KB = TKB U PKB, where TKB is given by Table 3, left side, and PKB is given by the conjunctive events A, B, and C in Table 3, right side, and by the bounds in Table 4. We easily verify that all KB in (f) to (k) are coherent and consistent. Tables 5 to 7 show the tight logical consequences of KB that are deducible by our inference rules SHARPENING, CHAINING, FUSION, and COMBINATION (the underlined bounds for SHARPENING improve the given bounds).\nMagic Inference Rules for Probabilistic Deduction 359\nTable 3: Taxonomic Knowledge\nTKB A B c (f) {ABC-+ _l_} A B c (g) { C -+ A, AB -+ C} A B c (h) {C-+ A} A B c (i) {BC-+ A} A B c (j) 0 A B AC (k) 0 A B c\nTable 4: Probabilistic Knowledge\n(BIA) (AlB) (f) [0.90, 0.95) [0.10, 0.15) (g) [0.60, 0.65) [0.30, 0.35) (h) [0.85, 0.90) [0.30, 0.35] (i) [0.90, 0.95] [0.30, 0.35) (j) [0.85, 0.90] [0.30, 0.35] (k) [0.85, 0.90] [0.30, 0.35] (CIB) (BIG) [0.20, 0.25] [0.75, 0.80] [0.25, 0.30] [0. 75, 0.80] [0.20, 0.25] [0. 75, 0.80] [0.20, 0.25] [0.75, 0.80] [0.20, 0.25] [0. 75, 0.80] [0.20, 0.25] [0. 75, 0.80]\nTable 5: SHARPENING\n(BIA) (f) [0.90, 0.95] (g) [0.60, 0.65] (h) [0.85, 0.88] (i) [0.90, 0.95] (AlB) [0.10, 0.15] [0.30, 0.30] (CIB) [0.20, 0.25] [0.30, 0.30] [0.30, 0.35] [0.20, 0.25] [0.30, 0.35] [0.20, 0.25] (BIG) [0. 75, 0.80] [0.75, 0.80] [0.76, 0.80) [0.75, 0.80] (j) [0.85, 0.88] [0.30, 0.35] [0.20, 0.25] (0. 76, 0.80] (k) [0.85, 0.90] [0.30, 0.35] [0.20, 0.25] [0. 75, 0.80]\nTable 6: CHAINING and FUSION\n(CIA) (AIC) (f) [0.00, 0.10] [0.00, 0.07] (g) [0.75, 0.87] [1.00, 1.00] (h) [0.61, 0. 75) [1.00, 1.00) (i) [0.51, 0.85) [0.75, 0.96] (j) (0.61, 0. 75] (1.00, 1.00] (k) (0.00, 0.86] [0.00, 1.00] (BIAC) [0.00, 0.00] [0. 75, 0.80] [0. 76, 0.80] [0.84, 1.00] [0. 76, 0.80] [0.00, 1.00]\nTable 7: COMBINATION\n(CIAB) (ABIC) (f) [0.00, 0.00] (0.00, 0.00] (g) [1.00, 1.00] (0. 75, 0.80] (h) [0.57, 0.71] [0.76, 0.80] (i) [0.57, 0.83] [0. 75, 0.80] (j) [0.57, 0. 71] [0. 76, 0.80) (k) [0.00, 0.83] [0.00, 0.80] (AlEC) [0.00, 0.00) (1.00, 1.00) [1.00, 1.00] [1.00, 1.00) [1.00, 1.00) [0.00, 1.00)\n(ACIB) [0.00, 0.00] [0.30, 0.30) [0.20, 0.25] [0.20, 0.25] [0.20, 0.25] [0.00, 0.25]\n(BCIA) [0.00, 0.00) [0.60, 0.65] [0.49, 0.60] [0.51,0.79) [0.49, 0.60] [0.00, 0. 75]\nThe examples (f) to (i) contain explicit taxonomic knowl edge in the taxonomic knowledge-base, while the example G) contains implicit taxonomic knowledge in the structure of the conjunctive events (A = A and C = AC entails 0 I= C -+ A, hence TKB I= C -+ A).\nWe observe that the deduced tightest bounds in the ex amples with explicit or implicit taxonomic knowledge are much tighter than the ones in the examples without any taxonomic knowledge at all: the examples (h) and G) increase (k) by exactly the additional explicit and im plicit, respectively, taxonomic knowledge C -+ A. As a consequence, the deduced tightest bounds in (h) and U) are much tighter than the ones in (k). For instance, CHAINING deduces (CIA)[0.61,0.75) in (h) and (j) com pared to only (CIA)(O.OO, 0.86) in (k), and FUSION de duces (BIAC)[0.76, 0.80] in (h) and G) compared to only (BIAC)[O.OO, 1.00] in (k). The fact that implicit taxonomic knowledge may increase the tightness of the deduced bounds also shows that all sim ilar inference rules of the literature that are locally com plete for a biconnected chain of three pairwise different ba sic events are generally not locally complete anymore for a biconnected chain of three conjunctive events.\nFinally, we present our magic inference rules:\nTheorem 5.2 Let KB = TKB U PKB be a coherent and consistent taxonomic and probabilistic knowledge-base, where TKB is an arbitrary taxonomic knowledge-base and PKB = {(BIA)[ul, u2], (AIB)[vl, v2], ( CIB)[x1, x2], (BIC)[yl,Y2)}. In the sequel, we abbreviate TKB I= ABC-+ l_ by a, TKB I= C-+ A by /3, TKB I= A-+ C by \"f, TKB I= BC -+ A by 6, TKB I= AB -+ C by c, and TKB I= AC-+ B by (. The operands of min and max may be followed by a set of conditions that must all hold for including the operand in computing the minimum and maximum, respectively (for example, min(v2, x2, Y2 {/3, c}) denotesmin(v2, x2, Y2) ifbothf3andchold, andmin(v2, x2) otherwise). SHARPENING:\na) KB Ftight (BIA)[z1, z2] with\nZ1 = max(u1, v1y1;\ufffd\ufffdh-y1) {'Y, V1Y1 > 0}, Y1 {'Y, 6}) Z2 = min(u2, V2Y2.::nl-y2) {/3, V2Y2 > 0}, Y2 {/3, c}). b) KB Ftight (AIB)[zl, z2] with\n(U1Xl(l-y2) {/3 1 > 0} z1 =max y2(l-u1) , > u1 > Y2 , V1, X1 {6}) \u2022 (1 { } U2X2(1-yr) { } z2 = mm - X1 a , Yl(l-u2) \"(, Yl > u2 , v2, x2{c}).\nCHAINING:\nKB Ftight (CIA)[z1,z2] with\nz1 = max(O, U1 + \ufffd + ut\ufffd' {v1 + x1 > 1}, u1 {c}, ut:1 {6, V2 > 0}, \ufffd\ufffd\ufffd; {/3, V2Y2 > 0}, \ufffd {,8, c, Y2 > 0}, 1 {'Y})\n360 Lukasiewicz\nZ2 = min(l, 1- UI + ut\ufffd2 {vi >x2}, \ufffd:\ufffd; {VIYI >0}, v1y1+;\ufffdI-yl) {vi> x2, YI > 0}, 1- ui {a}, u2- u\ufffd\ufffd2 + \ufffd\ufffd\ufffd; { VIYI > 0}, \ufffd { 8, YI > u2}, \ufffd::::\ufffd; {,B,ui>Y2}, u\ufffd\ufffd2 {(,vi>x2},u2{(}, u2(I-y1) min(x2,I-vt} {a V Y > O} O {a \ufffd\"} VI Yl ' I I ' ' .. '\nFUSION:\n(1-Yt) min(x2,I-vt} { > O}) VtYt +(I-yl) min(x2,I-vl) a, VIYI \u00b7\na) If TKB \ufffd AC-+ ..L, then KB I= tight (BIAC)[zi, z2] with\nz _ max(max(Yt vt+xt-I ut(xt+vt-I)) {x +v >1} I - Yt Vt-I)+xt' u1 (xt-I)+vt I I ' ui {c:}, YI {8}, v1y1.;;!fti-yl) {c:, VIYI > 0}, XtUd:\ufffd:(Lui) {8, XIUI > 0}, 0, 1{(}) z2 =min(l, ud'Y}, y2{,B}, O{a}).\nb) KB Fright (ACIB)[zi, z2] with\nZI = max(O, XI+ VI- 1, XI {8}, VI {c:}) \u2022 ( U2:1:2(I-yt) { } Z2 = IDill V2, X2, Yt(I-u2) 'Y, YI > U2 ,\nv\ufffd\ufffd{f\ufffd\ufffd\ufffdl) {,B, UI > Y2}, 0 {a})\u00b7\nCOMBINATION:\na) If TKB \ufffd AB -+ ..L, then KB Fright (CIAB)[zi,z2] with\nZI = max(O, 1- ;1 +\ufffd{vi +xi> 1}, l{c:}, \ufffd{8, v2>0}) \u00b7 (1 Y2(I-ut) {f-1 } 0 { } z2 = min , ut(I-y2) fJ\u2022 ui > Y2 , a , \ufffd{vi> x2}).\nb) KB l=tight (ABIC)[zi,z2] with\nZI = max(O, v\ufffd\ufffd1 - * + YI {vi+ XI > 1}, YI {8}, UI {,B, c}, Utx1.:\ufffd:(\\-u1) {,B, UIXI > 0}, v\ufffd\ufffd1 {c:, X2 > 0})\nz2 = min( v\ufffd\ufffd2 {xi > v2}, u2t;,\ufffd1) {'Y, 1 > .u2}, u2x1.:;:(2I-u2) {'Y, XI> V2 > 0}, O{a}, Y2, u2{ 'Y}) .\nProof. T he proof is given in full detail in [ 17]. D\n6 DISCUSSION\nIn the previous section, we presented the magic inference rules SHARPENING, CHAINING, FUSION, and COMBINA TION, which deduce tight logical consequences from a bi connected chain of three conjunctive events under addi tional taxonomic knowledge over conjunctive events.\nWe discover that our magic inference rules are surprisingly complex. At first glance, it is not clear at all where the deduced tightest bounds come from (this is the reason for which we call them 'magic' inference rules). In [17], we need a huge technical effort to discover these bounds, and to prove soundness and local completeness of the magic in ference rules. Hence, it seems unlikely that other locally complete inference rules that have more extensive taxo nomic and probabilistic knowledge in their premises can be worked out. Also, just generalizing our inference rules to propositional events would be a nearly intractable task.\nAnother interesting result is revealed if we analyze the global completeness of a probabilistic deduction technique that is based on the iterative application of the magic infer ence rules. Since we put a huge effort in elaborating our lo cally complete magic inference rules, we may at least hope that they are also a big step towards global completeness. However, we now show that all systems of inference rules for probabilistic deduction in taxonomic and probabilistic knowledge-bases over conjunctive events are globally in complete (note that we assume a fixed number of proba bilistic formulas in the premise of each inference rule).\nWe give an indirect proof of this important result: let us as sume that we have a globally complete system of inference rules in which the number of probabilistic formulas in the premise of each inference rule is limited by k 2:: 1. Now, let B = {BI, B2, . . . , Bn} with n 2:: k + 2 and let KB = TKB U PKB be given by TKB = {BiBi-+ ..L I ::; i < j ::; n} and PKB = {(BiiT)(l/n, 1)1 1 ::; i ::; n }. We get the tight logical consequence KB Fright (BIIT) [l/n, 1/n]. However, the least upper bound 1/n cannot be deduced by the assumed system of inference rules, since it requires all the lower bounds of the n - 1 > k probabilistic formulas (BdT)[l/n, 1] with i E (2 :n]. We also cannot divide the computation, since we do not have any probabilistic formu las over conjunctive events that could keep provisional re sults. Note, however, that with probabilistic formulas over propositional events, the computation could be divided: for example, for n = k + 2, we could deduce first (B2 V B31T)[2/n, 2/n] (that is, ( --,(--,B2 1\\ \u2022B3) IT)[2/n, 2/n]) and thereafter (BIIT)[l/n, 1/n], assuming an appropriate system of inference rules.\nHence, also our magic inference rules are globally incom plete, since the maximum number of probabilistic formu las in their premises is four. In the considered example, our magic inference rules deduce the upper bound 1 - 1/ n, which is different from the least upper bound 1/n already for n > 2. Taking, for example, n = 100, the deduced upper bound is 0. 9 9, but the least upper bound is 0.01. We give another example, which shows that the itera tive application of CHAINING may globally be very in complete. LetB = {BI,B2,B3,B4}, TKB = 0, and PKB = U{ {(DIC)[O.l, 0.15], (CID) [0.8, 1]} I (C, D) E\nMagic Inference Rules for Probabilistic Deduction 361\n{(B1,B2),(B2,B3),(Bg,B4)}}. We get the tight logi cal consequence TKB U PKB Ftight (B41Bl)[O, 0.007). However, the iterative application of CHAINING just de duces the interval [0, 0.904). Note that we analyze more general probabilistic deduction problems with probabilistic formulas over basic events in [19].\nIn summary, there is a huge effort in exploring the 'magic' of locally complete inference rules for probabilistic de duction from taxonomic and probabilistic knowledge-bases over conjunctive events. Moreover, as a matter of principle, there does not exist any globally complete system of infer ence rules for this framework.\n7 SUMMARY AND CONCLUSIONS\nWe presented locally complete inference rules for proba bilistic deduction from taxonomic and probabilistic knowl edge-bases over conjunctive events. Surprisingly, these inference rules are very complex and it is at first glance not clear at all where the deduced tightest bounds come from. Moreover, analyzing the global completeness of our inference rules, we discovered examples of globally very incomplete probabilistic deductions. More generally, we even showed that all systems of inference rules for taxo nomic and probabilistic knowledge-bases over conjunctive events are globally incomplete.\nHence, probabilistic deduction by the iterative application of inference rules on probabilistic formulas seems very lim ited in its field of application. The way in which probabilis tic interpretations give semantics to probabilistic formulas seems to contradict the kind of modularity that stands be hind the iterative application of inference rules. This im portant insight has an impact on all areas that deal with probabilistic deduction in similar frameworks.\nReferences\n[1] E. W. Adams. The Logic of Conditionals, volume 86 of Synthese Library. D. Reidel, Dordrecht, Holland, 1975.\n[2] S. Amarger, D. Dubois, and H. Prade. Constraint propa gation with imprecise conditional probabilities. In Proc. of the 7th Conference on Uncertainty in Artificial Intelligence, pages 26-34. Morgan Kaufmann Publishers, 1991.\n[3] K. A. Andersen and J. N. Hooker. Bayesian logic. Decision Support Systems, 11:191-210, 1994.\n[4] C. Beeri and P. A. Bernstein. Computational problems re lated to the design of normal form relational schemas. ACM Transactions on Database Systems, 4:30-59, 1979.\n[5] R. Camap. Logical Foundations of Probability. University of Chicago Press, Chicago, 1950.\n[6] B. de Finetti. Theory of Probability. Wiley, New York, 1974.\n[7] D. Dubois and H. Prade. On fuzzy syllogisms. Computa tional Intelligence, 4(2):171-179, 1988.\n[8] D. Dubois, H. Prade, L. Godo, and R. L. de M\ufffdmtaras. A symbolic approach to reasoning with linguistic quantifiers. In Proc. of the 8th Conf on Uncertainty in Artificial Intelli gence, pages 74-82. Morgan Kaufmann Publishers, 1992.\n[9] D. Dubois, H. Prade, and J.-M. Touscas. Inference with im precise numerical quantifiers. In Intelligent Systems, chap ter 3, pages 53-72. Ellis Horwood, 1990.\n[10] R. Fagin, J. Y. Halpern, and N. Megiddo. A logic for rea soning about probabilities. Information and Computation, 87:78-128, 1990.\n[11] A.M. Frisch and P. Haddawy. Anytime deduction for prob abilistic logic. Artificial Intelligence, 69:93-122, 1994.\n[12] G. Georgakopoulos, D. Kavvadias, and C. H. Papadimitriou. Probabilistic satisfiability. J. of Complexity, 4: 1-11, 1988.\n[13] J. Heinsohn. Probabilistic description logics. In Proc. of the lOth Conference on Uncertainty in Artificial Intelligence, pages 311-318. Morgan Kaufmann Publishers, 1994.\n[14] B. Jaumard, P. Hansen, and M.P. de Aragao. Column gen eration methods for probabilistic logic. ORSA Journal of Computing, 3:135-147, 1991.\n[15] D. Kavvadias and C. H. Papadimitriou. A linear program ming approach to reasoning about probabilities. Annals of Mathematics and Artificial Intelligence, 1:189-205, 1990.\n[16] T. Lukasiewicz. Uncertain reasoning in concept lattices. In Proc. of the 3rd European Conference on Symbolic and Quantitative Approaches to Reasoning and Uncertainty, volume 946 of LNCS/LNAI, pages 293-300. Springer, 1995.\n[17] T. Lukasiewicz. Precision of Probabilistic Deduction under Taxonomic Knowledge. Doctoral Dissertation, Universitiit Augsburg, 1996.\n[18] T. Lukasiewicz. Efficient global probabilistic deduction from taxonomic and probabilistic knowledge-bases over conjunctive events. In Proc. of the 6th International Con ference on Information and Knowledge Management, pages 75-82. ACM Press, 1997.\n[19] T. Lukasiewicz. Probabilistic deduction with conditional constraints over basic events. In Principles of Knowledge Representation and Reasoning: Proc. of the 6th Interna tional Conference. Morgan Kaufmann Publishers, 1998.\n[20] T. Lukasiewicz. Probabilistic logic programming. In Proc. of the 13th European Conference on Artificial Intelligence, pages 388-392. J. Wiley & Sons, 1998. To appear.\n[21] N. J. Nilsson. Probabilistic logic. Artificial Intelligence, 28:71-88, 1986.\n[22] G. PaaB. Probabilistic Logic. In Non-Standard Logics for Automated Reasoning, chapter 8, pages 213-251. Academic Press, London, 1988.\n[23] J. Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann Pub lishers, San Mateo, California, 1988.\n[24] Y. Sagiv, C. Delobel, D. S. Parker, and R. Fagin. An equiva lence between relational database dependencies and a frag ment of propositional logic. Journal of the ACM, 28(3):435- 453, 1981.\n[25] H. Thone, U. Guntzer, and W. KieBling. Towards preci sion of probabilistic bounds propagation. In Proc. of the 8th Conference on Uncertainty in Artificial Intelligence, pages 315-322. Morgan Kaufmann Publishers, 1992."}], "references": [{"title": "The Logic of Conditionals, volume 86 of Synthese Library. D", "author": ["E.W. Adams"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1975}, {"title": "Constraint propa\u00ad gation with imprecise conditional probabilities", "author": ["S. Amarger", "D. Dubois", "H. Prade"], "venue": "In Proc. of the 7th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1991}, {"title": "Computational problems re\u00ad lated to the design of normal form relational schemas", "author": ["C. Beeri", "P.  A. Bernstein"], "venue": "ACM Transactions on Database Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1979}, {"title": "Logical Foundations of Probability", "author": ["R. Camap"], "venue": "University of Chicago Press, Chicago,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1950}, {"title": "On fuzzy syllogisms", "author": ["D. Dubois", "H. Prade"], "venue": "Computa\u00ad tional Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1988}, {"title": "A symbolic approach to reasoning with linguistic quantifiers", "author": ["D. Dubois", "H. Prade", "L. Godo", "R.L. de M\ufffdmtaras"], "venue": "In Proc. of the 8th Conf on Uncertainty in Artificial Intelli\u00ad gence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1992}, {"title": "Touscas. Inference with im\u00ad precise numerical quantifiers", "author": ["D. Dubois", "H.  Prade", "J.-M"], "venue": "In Intelligent Systems, chap\u00ad", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1990}, {"title": "A logic for rea\u00ad soning about probabilities", "author": ["R. Fagin", "J.Y. Halpern", "N. Megiddo"], "venue": "Information and Computation,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1990}, {"title": "Anytime deduction for prob\u00ad abilistic logic", "author": ["A.M.  Frisch", "P.  Haddawy"], "venue": "Artificial Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1994}, {"title": "Probabilistic description logics", "author": ["J.  Heinsohn"], "venue": "In Proc. of the lOth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1994}, {"title": "Column gen\u00ad eration methods for probabilistic logic", "author": ["B.  Jaumard", "P. Hansen", "M.P. de Aragao"], "venue": "ORSA Journal of Computing,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1991}, {"title": "A linear program\u00ad ming approach to reasoning about probabilities", "author": ["D. Kavvadias", "C.H. Papadimitriou"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1990}, {"title": "Uncertain reasoning in concept lattices", "author": ["T. Lukasiewicz"], "venue": "In Proc. of the 3rd European Conference on Symbolic and Quantitative Approaches to Reasoning and Uncertainty,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1995}, {"title": "Precision of Probabilistic Deduction under Taxonomic Knowledge", "author": ["T. Lukasiewicz"], "venue": "Doctoral Dissertation, Universitiit Augsburg,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1996}, {"title": "Efficient global probabilistic deduction from taxonomic and probabilistic knowledge-bases over conjunctive events", "author": ["T. Lukasiewicz"], "venue": "In Proc. of the 6th International Con\u00ad ference on Information and Knowledge Management,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1997}, {"title": "Probabilistic deduction with conditional constraints over basic events. In Principles of Knowledge Representation and Reasoning: Proc. of the 6th Interna\u00ad tional Conference", "author": ["T. Lukasiewicz"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}, {"title": "Probabilistic logic programming", "author": ["T. Lukasiewicz"], "venue": "In Proc. of the 13th European Conference on Artificial Intelligence,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1998}, {"title": "Probabilistic logic", "author": ["N.J. Nilsson"], "venue": "Artificial Intelligence,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1986}, {"title": "Probabilistic Logic. In Non-Standard Logics for Automated Reasoning, chapter 8, pages 213-251", "author": ["G. PaaB"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1988}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1988}, {"title": "An equiva\u00ad lence between relational database dependencies and a frag\u00ad ment of propositional logic", "author": ["Y. Sagiv", "C. Delobel", "D.  S. Parker", "R. Fagin"], "venue": "Journal of the ACM,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1981}, {"title": "Towards preci\u00ad sion of probabilistic bounds propagation", "author": ["H. Thone", "U. Guntzer", "W. KieBling"], "venue": "In Proc. of the 8th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1992}], "referenceMentions": [{"referenceID": 17, "context": "The global approach by linear programming (see, for example, [21], [12], [22], [10], [15], [14], [3], and [18]) can be performed within rich probabilistic languages capa\u00ad ble of representing many facets of probabilistic knowledge (see especially [10]).", "startOffset": 61, "endOffset": 65}, {"referenceID": 18, "context": "The global approach by linear programming (see, for example, [21], [12], [22], [10], [15], [14], [3], and [18]) can be performed within rich probabilistic languages capa\u00ad ble of representing many facets of probabilistic knowledge (see especially [10]).", "startOffset": 73, "endOffset": 77}, {"referenceID": 7, "context": "The global approach by linear programming (see, for example, [21], [12], [22], [10], [15], [14], [3], and [18]) can be performed within rich probabilistic languages capa\u00ad ble of representing many facets of probabilistic knowledge (see especially [10]).", "startOffset": 79, "endOffset": 83}, {"referenceID": 11, "context": "The global approach by linear programming (see, for example, [21], [12], [22], [10], [15], [14], [3], and [18]) can be performed within rich probabilistic languages capa\u00ad ble of representing many facets of probabilistic knowledge (see especially [10]).", "startOffset": 85, "endOffset": 89}, {"referenceID": 10, "context": "The global approach by linear programming (see, for example, [21], [12], [22], [10], [15], [14], [3], and [18]) can be performed within rich probabilistic languages capa\u00ad ble of representing many facets of probabilistic knowledge (see especially [10]).", "startOffset": 91, "endOffset": 95}, {"referenceID": 14, "context": "The global approach by linear programming (see, for example, [21], [12], [22], [10], [15], [14], [3], and [18]) can be performed within rich probabilistic languages capa\u00ad ble of representing many facets of probabilistic knowledge (see especially [10]).", "startOffset": 106, "endOffset": 110}, {"referenceID": 7, "context": "The global approach by linear programming (see, for example, [21], [12], [22], [10], [15], [14], [3], and [18]) can be performed within rich probabilistic languages capa\u00ad ble of representing many facets of probabilistic knowledge (see especially [10]).", "startOffset": 246, "endOffset": 250}, {"referenceID": 4, "context": "The local approach (see, for example, [7], [9], [2], [8], [25], [11], [13], and [16]) is generally performed within more", "startOffset": 38, "endOffset": 41}, {"referenceID": 6, "context": "The local approach (see, for example, [7], [9], [2], [8], [25], [11], [13], and [16]) is generally performed within more", "startOffset": 43, "endOffset": 46}, {"referenceID": 1, "context": "The local approach (see, for example, [7], [9], [2], [8], [25], [11], [13], and [16]) is generally performed within more", "startOffset": 48, "endOffset": 51}, {"referenceID": 5, "context": "The local approach (see, for example, [7], [9], [2], [8], [25], [11], [13], and [16]) is generally performed within more", "startOffset": 53, "endOffset": 56}, {"referenceID": 21, "context": "The local approach (see, for example, [7], [9], [2], [8], [25], [11], [13], and [16]) is generally performed within more", "startOffset": 58, "endOffset": 62}, {"referenceID": 8, "context": "The local approach (see, for example, [7], [9], [2], [8], [25], [11], [13], and [16]) is generally performed within more", "startOffset": 64, "endOffset": 68}, {"referenceID": 9, "context": "The local approach (see, for example, [7], [9], [2], [8], [25], [11], [13], and [16]) is generally performed within more", "startOffset": 70, "endOffset": 74}, {"referenceID": 12, "context": "The local approach (see, for example, [7], [9], [2], [8], [25], [11], [13], and [16]) is generally performed within more", "startOffset": 80, "endOffset": 84}, {"referenceID": 8, "context": "The iterative application of inference rules is very rarely and only within very re\u00ad stricted probabilistic languages globally complete (see [11] for an example of globally complete local probabilistic de\u00ad", "startOffset": 141, "endOffset": 145}, {"referenceID": 8, "context": "erally even do not produce the tightest bounds entailed by the partial probabilistic knowledge in their premises (see [11] and [13] for inference rules that are locally complete only for complex events that are not logically related).", "startOffset": 118, "endOffset": 122}, {"referenceID": 9, "context": "erally even do not produce the tightest bounds entailed by the partial probabilistic knowledge in their premises (see [11] and [13] for inference rules that are locally complete only for complex events that are not logically related).", "startOffset": 127, "endOffset": 131}, {"referenceID": 12, "context": "Own prelim\u00ad inary results in [16] now show that taxonomic knowledge can be exploited for an increased efficiency and a decreased incompleteness in the local approach to probabilistic de\u00ad duction.", "startOffset": 29, "endOffset": 33}, {"referenceID": 9, "context": "lationship between taxonomic and probabilistic knowledge is also analyzed in [13], where probabilistic knowledge is integrated into a terminological language.", "startOffset": 77, "endOffset": 81}, {"referenceID": 15, "context": "In this frame\u00ad work, the deduction of probabilistic knowledge is NP-hard (we show in [19] that it is even NP-hard for probabilistic", "startOffset": 85, "endOffset": 89}, {"referenceID": 13, "context": "This paper is a revised extract of own work from [17], which we extended by a short discussion on the compu\u00ad tational complexity of probabilistic deduction.", "startOffset": 49, "endOffset": 53}, {"referenceID": 12, "context": "Preliminary results of this paper have been presented in [ 16].", "startOffset": 57, "endOffset": 62}, {"referenceID": 8, "context": "The technical background introduced in this section is com\u00ad monly accepted in the literature (see, for example, [11] for other work in the same spirit).", "startOffset": 112, "endOffset": 116}, {"referenceID": 17, "context": "The atomic events of our framework coincide with the more commonly known pos\u00ad sible worlds from probabilistic logic [21].", "startOffset": 116, "endOffset": 120}, {"referenceID": 8, "context": "Note that u is a closed interval in the real numbers (see, for example, [11] and [17]).", "startOffset": 72, "endOffset": 76}, {"referenceID": 13, "context": "Note that u is a closed interval in the real numbers (see, for example, [11] and [17]).", "startOffset": 81, "endOffset": 85}, {"referenceID": 15, "context": "Surprisingly, even the problem of computing the tight an\u00ad swer for a probabilistic query over basic events t o a proba\u00ad bilistic knowledge-base over basic events is NP-hard, as we show in [ 19].", "startOffset": 188, "endOffset": 193}, {"referenceID": 2, "context": "well-known as functional dependencies in database theory (see, for example, [4] and [24]).", "startOffset": 76, "endOffset": 79}, {"referenceID": 20, "context": "well-known as functional dependencies in database theory (see, for example, [4] and [24]).", "startOffset": 84, "endOffset": 88}, {"referenceID": 12, "context": "show that deducing taxonomic formulas over conjunctive events from taxonomic knowledge-bases over conjunctive events can be done in linear time by using a hull-operator on the set of all subsets of B U {1-} (see [ 16] and [ 17]).", "startOffset": 212, "endOffset": 217}, {"referenceID": 13, "context": "show that deducing taxonomic formulas over conjunctive events from taxonomic knowledge-bases over conjunctive events can be done in linear time by using a hull-operator on the set of all subsets of B U {1-} (see [ 16] and [ 17]).", "startOffset": 222, "endOffset": 227}, {"referenceID": 6, "context": "We chose these inference rules, since there is already a quite extensive literature on similar inference rules, which are locally complete for biconnected chains of three pair\u00ad wise different basic events without any taxonomic knowl\u00ad edge beside (see, for example, [9], [2], [25], [8], and [13]).", "startOffset": 265, "endOffset": 268}, {"referenceID": 1, "context": "We chose these inference rules, since there is already a quite extensive literature on similar inference rules, which are locally complete for biconnected chains of three pair\u00ad wise different basic events without any taxonomic knowl\u00ad edge beside (see, for example, [9], [2], [25], [8], and [13]).", "startOffset": 270, "endOffset": 273}, {"referenceID": 21, "context": "We chose these inference rules, since there is already a quite extensive literature on similar inference rules, which are locally complete for biconnected chains of three pair\u00ad wise different basic events without any taxonomic knowl\u00ad edge beside (see, for example, [9], [2], [25], [8], and [13]).", "startOffset": 275, "endOffset": 279}, {"referenceID": 5, "context": "We chose these inference rules, since there is already a quite extensive literature on similar inference rules, which are locally complete for biconnected chains of three pair\u00ad wise different basic events without any taxonomic knowl\u00ad edge beside (see, for example, [9], [2], [25], [8], and [13]).", "startOffset": 281, "endOffset": 284}, {"referenceID": 9, "context": "We chose these inference rules, since there is already a quite extensive literature on similar inference rules, which are locally complete for biconnected chains of three pair\u00ad wise different basic events without any taxonomic knowl\u00ad edge beside (see, for example, [9], [2], [25], [8], and [13]).", "startOffset": 290, "endOffset": 294}, {"referenceID": 13, "context": "The proof is given in full detail in [ 17].", "startOffset": 37, "endOffset": 42}, {"referenceID": 13, "context": "T he proof is given in full detail in [ 17].", "startOffset": 38, "endOffset": 43}, {"referenceID": 13, "context": "In [17], we need a huge technical effort to discover these bounds, and to prove soundness and local completeness of the magic in\u00ad ference rules.", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "Note that we analyze more general probabilistic deduction problems with probabilistic formulas over basic events in [19].", "startOffset": 116, "endOffset": 120}], "year": 2011, "abstractText": "We present locally complete inference rules for probabilistic deduction from taxonomic and probabilistic knowledge-bases over conjunctive events. Crucially, in contrast to similar infer\u00ad ence rules in the literature, our inference rules are locally complete for conjunctive events and under additional taxonomic knowledge. We dis\u00ad cover that our inference rules are extremely com\u00ad plex and that it is at first glance not clear at all where the deduced tightest bounds come from. Moreover, analyzing the global completeness of our inference rules, we find examples of glob\u00ad ally very incomplete probabilistic deductions. More generally, we even show that all systems of inference rules for taxonomic and probabilis\u00ad tic knowledge-bases over conjunctive events are globally incomplete. We conclude that proba\u00ad bilistic deduction by the iterative application of inference rules on interval restrictions for condi\u00ad tional probabilities, even though considered very promising in the literature so far, seems very lim\u00ad ited in its field of application.", "creator": "pdftk 1.41 - www.pdftk.com"}}}