{"id": "1303.5731", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2013", "title": "A Language for Planning with Statistics", "abstract": "When a planner must decide whether it has enough evidence to make a decision based on probability, it faces the sample size problem. Current planners using probabilities need not deal with this problem because they do not generate their probabilities from observations. This paper presents an event based language in which the planner's probabilities are calculated from the binomial random variable generated by the observed ratio of one type of event to another. Such probabilities are subject to error, so the planner must introspect about their validity. Inferences about the probability of these events can be made using statistics. Inferences about the validity of the approximations can be made using interval estimation. Interval estimation allows the planner to avoid making choices that are only weakly supported by the planner's evidence.", "histories": [["v1", "Wed, 20 Mar 2013 15:31:46 GMT  (257kb)", "http://arxiv.org/abs/1303.5731v1", "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)"]], "COMMENTS": "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["nathaniel g martin", "james f allen"], "accepted": false, "id": "1303.5731"}, "pdf": {"name": "1303.5731.pdf", "metadata": {"source": "CRF", "title": "A Language for Planning with Statistics Nathaniel", "authors": [], "emails": [], "sections": [{"heading": null, "text": "1 INTRODUCTION\nPlanning relies on choosing the future actions most likely to be effective. Because actions are taken after they are planned, a planner's information is uncertain at planning time. Probabilities have been explored as a means of representing and reasoning about this uncertainty. In some domains, the necessary probabil ities can be gathered by querying experts in the field. If such experts do not exist, an agent must be able to infer probabilities from observations. This paper develops a language that combines Allen's temporal interval reasoning [Allen, 1984) with statistical infer ence [Bickel and Doksum, 1977) to facilitate planning using inferences about probabilities.\nIf a planner must calculate its probabilities, it must decide when it has enough information to be confident of its calculations. Deciding when one is sufficiently confident of probabilities generated from observations\nis called the sample size problem. The sample size problem will be ubiquitous for planners that calculate probabilities from their experience. The most imme diate incarnation of this problem is that of deciding whether choices are warranted by the evidence. A planner should make its decisions based on the proba bilities about which it has good evidence, and discount the probabilities about which it is uncertain. One ap plication of making decisions based on strength of evi dence as well as probability is dealing with facts one is told. A planner may be told that a particular course of actions is better than another, but if its evidence is suf ficiently strong, it may choose to ignore this informa tion. The sample size problem also arises when reason ing about specifying actions to an intelligent reactive execution module [Martin and Allen, 1990b). Here, the planner specifies details of its plans only if it is confi dent of the probabilities it has calculated. Yet another place the problem arises is in probabilistic solutions to the qualification problem [Martin and Allen, 1990a, Weber, 1989). The planner adds as many qualifica tions as it can without making the event about which it is reasoning so specific that there are insufficient statistics to make necessary choices.\nFeldman and Sproull [1977) deal with uncertainty by applying decision theory [Raiffa, 1970) to the problem of choosing appropriate actions guiding an A* algo rithm. Horvitz [1988) uses decision theory to reason about partial results in planning. Johnson and Schu bert [1982) use decision theory to control the cost of planning. More recently, Hartman [1990) has studied the same problem from a more formal perspective. All of these assume that probabilities are known before hand. Moreover, none of these proposals includes an explicit representation of time.\nKanazawa and Dean [1989) propose a system that uses Bayes nets to make the computation of expected util ities sufficiently efficient to be used in a reactive exe cution architecture. They suggest using maximum en tropy prior distributions as uninformative J?riors [Dean and Kanazawa, 1988). Following Jaynes l1979), they choose the distribution that assumes one will receive\nthe minimum amount of information from guessing. Kanazawa [1991] has recently coupled this Bayes net representation with a system for reasoning about prob abilities and time.\nHanks [1988, 1990b, 1990a] has developed techniques for combining reasoning about time and probabili ties. He is concerned with predicting future events given uncertain observations and actions. The planner then chooses the most effective actions given its beliefs about the state of the world in the future. Hanks also mentions maximum entropy as a guide to appropriate prior distributions.\nHaddawy [1990, 1991] develops a formal logic of time and probability in which probability is represented by a modal operator over a temporal language. His sys tem uses objective probabilities, a theory in which his tory determines chance in a fixed way. The theory of objective probabilities is a theory of causality that makes Bayesian inference valid.\nKanazawa and Hanks both choose a particular distri butwn from those warranted by theu system's expe rience. The system maintains no information about the amount of evidence on which this distribution is based, so it cannot determine that, even though the probability of one prediction is higher than another, such a prediction rests on shaky foundations. Had dawy assumes an ontology in which probabilities are defined to be determined by the past. If it is used by a planning system, this ontology will rule out the possi bility that its knowledge of the probabilities could be erroneous.\nThis paper explores interval estimation, a standard technique from statistical analysis, to deal with the sample size problem. It develops an event-based first order language using temporal intervals and confidence intervals for reasoning about plans. Observations of instances of events are used to calculate confidence in tervals with which the system represents and reasons about uncertainty. The language developed is similar to the event logic developed by Allen [1991] which is, in turn, based on the temporal logic described in Allen and Koomen [1983] and Allen [1984]. The confidence intervals are used in a manner similar to Kyburg's in terval probabilities [Kyburg, 1983]. We provide an example of a planner making decisions based on the amount of evidence it has.\nThe proposal does not address the problem of gener ating beliefs from sensor input. It assumes that the beliefs have already been formed from the input, and the planner must decide what probability it should place on projections of its beliefs. We assume that the planner is buffered from the necessity of analyzing raw sensory information and generating control signals by an intelligent reactive system. The planner's task is to monitor the progress of the reactive system and give suggestions based on its observations.\nA Language for Planning with Statistics 221\nKaelbling [1990] investigates the possibility of apply ing interval estimation techniques to learning in em bedded systems. She concludes that though learn ing algorithms that use interval estimation are slightly better than those that use point estimation, they are ill suited to learning in embedded systems because of their computational complexity and the difficulty of applying statistics to situations different from those in which they were gathered. Our use of interval estima tion differs from Kaelbling's in that we apply the tech nique to a strategic planner that is buffered from its situation by its reactive execution module. Moreover, by reasoning about the best description of its current situation, the planner can apply statistics to situations different from those in which they were gathered.\nExample As a running example, consider a robot en gineer trying to couple two cars. This engineer has a program, Old, which it executes whenever it wants to couple cars. It has executed the program 1000 times, but has coupled successfully only 500 times. Recently, a new program, New was written and added to the engmeer s repertmre. I he old program remains an ac tion the engineer can choose. Should the robot try the new program? A conservative guess of the probability of successfully coupling the cars using the new program might be 0.5, so the engineer might try it. If the engi neer tries once and fails, it will believe the probability of coupling the cars using the new program is lower than the probability of success using the old program. The engineer could be less conservative and choose a higher prior for the new program, but what should that prior be? In general, how many times should the robot try the new program before concluding that the old program is better? D\n2 KNOWLEDGE\nREPRESENTATION\nThis paper develops a first-order language that allows one to use statistics to reason about plans and ac tions. The language is concerned with five kinds of things: actions (a), event instances (e;), temporal in tervals (t;), probability intervals (i;), and a-levels (a;). This language is similar to the language developed by Allen [1991]. It differs in the inclusion of probability intervals and a-levels.\nAn event type is a set of event instances characterized by a sentence that constrains the temporal interval during which the instances of the event type occur. For simplicity, events in this paper are characterized only by their temporal properties. Therefore, a particular event instance can be specified by fixing the time at which the event occurs, Time(e). We use the term event to represent an event type; event instances will be referred to as such. The characterization of an event is a sentence. \\Ve say that one event, e1, subsumes another, ez, if the characterization of e2 is a logical\n222 Martin and Allen\nconsequence of the characterization of e1.\nEvents express context and provide the basis for the calculation of the confidence intervals. Events encode the context of an action in its characterization. For example, being in the same city might characterize an event caused by any execution of the Old program. A particular event may also have other properties such as clear weather, but as long as the characterizing sen tence is true, the event is said to hold. Probability is defined as the frequency of one event relative to an other both in the past and in the future. For example, the probability that the engineer successfully couples two cars is the ratio of the number of successful at tempts to the total number of attempts. Statistics about events change as the planner discovers more of the elements that make up the probability, but the probability itself does not change.\nThe temporal intervals associated with events allow the system to choose actions relative to an event, then order the events, allowing non-linear planning. Plans are generated as described by Allen [1991]. Tempo ral relations are specified using Allen's interval tem poral logic [Allen, 1984]. These temporal intervals al low agents to reason about sequential and concurrent actions. For example, the robot engineer may need to reason that it must keep the coupler open while back ing up if it wants to couple two cars.\nActions are the names of programs. When a program is executed, it causes an instance of an event. For example, a planner's program for coupling cars may simply back the engine until it hits a car. Clearly, if the train is on the wrong track, executing this pro gram will not have the desired effect. The predicate Causes (execute( a, t), e) indicates that the program a was executed during time interval t and caused event e. Some of the circumstances that affect the results of executing a program may be specified in the charac terization of the event caused by the execution of that program; others may not. The circumstances that are specified in the characterization of such an event ex press preconditions of the event; those that are not make the events amenable to analysis by probabilities. That is, each event describes a set of event instances, each of which is different (at the very least in its time of occurrence). Ratios of the cardinalities of these sets are the probability of one event relative to another.\nStatistics are maintained on the number of occurrences of an event, occurrences( event-type). The reactive ex ecutor updates the planner's knowledge periodically. Each time a new temporal interval is added to the planner's knowledge base, it forward chains on this new information. If, in the process of forward chain ing, it proves that an instance of event e has occurred, it increments the value of occurrences( event-type). As described here, the function occurrences is not part of the language; instead, it is used to define the confi dence intervals that are part of the language.\nExample A single constraint characterizes an event such that an instance of it occurs whenever the agent attempts the Old action,\n'v'(e) [Causes (execute( Old, Time( e)), e)=>Old-Try (e)].\nThis event represents all time intervals that match its characterization. A Couple event is characterized by,\n'v' (cl, c2, t1, t2, e) [-,Coupled (cl, c2, t1) 1\\ Coupled ( cl, c2, t2) 1\\ Starts (11, Time(e)) 1\\ Ends (t2, Time(e))\n=> Couple (cl, c2, e)].\nThat is, a couple event is one where before the event the cars were not coupled, and after the event the cars were coupled. We name the events characterized m this way by the characteristic predicate. That is\nV(e) [Couple (cl, c2, e) \ufffd e E Couple(cl, c2)]\nis always true.\nIf we assume the planner has seen 1000 Old-Try event instances, of which 500 are also Couple( cl, c2) event instances, i.e.\noccurrences( Old-Try) = 1000 occurrences( Couple( cl, c2) n Old-Try) = 500\nthen we have characterize the situation of the robot engineer at the beginning of the example mentioned above. The event described by Couple( cl, c2) n Old-Try is the least constrained one that subsumes both Couple( c1, c2) and Old-Try.\nWhen the robot is given the new program for coupling cars, it will need to be able to distinguish the event in which it tries this program. This event will be called New-Try,\n0\n'v' (e) [Causes (execute(New, Time(e)), e) => New-Try (e)].\nThe a-levels are the probability that the parameter being estimated falls outside the confidence interval computed. Confidence intervals are calculated to be of the sizes of the system's a-levels. An a-level confi dence interval for a parameter p is a random interval for which the probability that the interval contains p is a. Confidence intervals represent the strongest possi ble constraints on the location of the parameter given the data observed.\n3 INFERENCE\nUsing statistics on events, the planner can compute constraints on the probability distributions consistent\nwith its knowledge. We define PCA1_.,( e9, ea) to be the 1-a% confidence interval for the mean of the bino mial random variable calculated from the occurrences of two events, e9 and ea. We call the event in which the action is tried the reference event, the event after which the goal holds the success event.\nSuch a confidence interval can be approximated us ing the DeMoivre-Laplace theorem on the approxima tion of binomial distributions by normal distributions. Given that z.,;2 is the portion of the standard normal distribution such that\nP[Z > -Zaj2] = P[Z < Zaj2] = a/2\nthe confidence interval for n Bernoulli trials with y successes is approximated by:\nTo use these confidence intervals one must assume that the normal distribution is a good approximation to the binomial. This will be the case when the smaller of np, n( 1- p) is less than five, where p is the parameter for the binomial distribution being approximated.\nWhere there are only a few instances of an event, ex act bounds can be computed. The cost of computing these bounds is high, but they can be precomputed and stored in a relatively small table for those cases in which the normal approximation is invalid. The exact a-level confidence interval for the parameter of a bino mial random variable generated by n Bernoulli trials with y successes (y > 0) will be (p1, Pu], where PI is the unique solution to the equation,\nand Pu is the unique solution to the equation,\ny ( ) n i n-i I: i Pu (1- Pu) =a. z:::::O\nTables of confidence intervals for binomial random variables can be found in [Clopper and Pearson, 1934] and [Fisher and Yates, 1963]. There is a discussion of the trade-off between the exact confidence interval and the approximation in [Kendall and Stuart, 1961].\nTo calculate confidence intervals, the planner needs to know the number of occurrences, n, of instances of the reference event and the number of occurrences, y, of instances of the event subsumed by the reference event that are also subsumed by the success event. That is, the planner will need to known= occurrences( e. ) and y = occurrences( ea n e9) .\nA Language for Planning with Statistics 223\nConfidence intervals are represented in the language by constants allowing sentences about the systems con straints on probabilities. One interval is \"-<\" another if the upper bound of the first is less than the lower bound of the second. The intervals are equal if both bounds correspond. Intervals that overlap are said to be incomparable. That is, [0.5, 0.6] -< [0.7, 0.9] but \ufffd([0.5, 0.6] -< [0.5, 0.9]) and \ufffd([0.5, 0.9] -< [0.5, 0.6]). The planner chooses the action whose confidence in terval at a given a-level was the highest among all applicable actions using -<.\nA predicate describing the planner's preferred action, Best (a, e9, a), can be defined using this language. The planner prefers an action a if and only if the statistics it has about the event in which the action occurred give clear indication that a is most likely to cause an event that leads to the goal (i.e., Goal(e)). The predicate can be defined by the following conditional:\n(1) \\f(e9, e. , a , a) [Goal (e9)A Causes (execute( a, Time(ea)), ea)A\n\\f(eb, b) [a =F bA Causes ( execute(b, Time(eb)), eb)A PCAI-a(e9, eb)-< PCAI-a(e9, ea)] =}Best (a, e9, a)]\nThis predicate says that action a is best if and only if the planner's knowledge constrains the probability of its success to be higher than any other action.\nExample Suppose the number of occurrences of New Try and Couple(cl,c2) are as follows:\noccurrences( New-Try) = 2 occurrences(New-Try n Couple(cl, c2)) = 1.\nIn this example the engineer uses only a .05 a-level to generate its probability constraints. From the number of occurrences of the preceding events, the following constraints on the probability of the successful execu tion of the actions can be generated:\nPCA g5( Couple( cl, c2), Old-Try) = (0.4691, 0.5309] PCA95( Couple( cl, c2), New-Try) = (0.0254, 0.9747].\nThe planner knows that if these intervals1 do not over lap it can choose the higher interval, and with prob ability at least 1 - a, this decision is correct. This information is encoded in (1). Here, the planner can prove neither\nBest (Couple( cl, c2), Try-Old, .05, Old)\nnor\nBest (Couple( cl, c2), New-Try, .05, New)\nusing (1). It must give up. D\n1 The confidence interval for New is exact.\n224 Martin and Allen\nWhen intervals overlap, the statistics do not indicate a clear choice at the a = .05 confidence level. When the statistics do not provide clear guidance, the robot might fall back on heuristics. One source of these heuristics might be suggestions by the programmer writing the programs about which the pbnncr reasons.\nExample The programmer might tell the robot that the new couple program is better than the old one, since, presumably, this was the reason for writing it. The planner should take this advice only if it does not conflict with its experience. It might therefore trans late this advice into a rule saying it should choose the new program only as long as there is no clear evidence that this program is inferior to the old one. Such a rule can be defined by the following conditional:\n(2) lf(e) [ \ufffd(PCAg5(Couple(c1, c2), Old-Try)-< PCA95( Couple( cl, c2), New-Try))A\n\ufffd( PCA 95( Couple( c1, c2), New-Try) -< PCA 95( Couple( cl, c2), Old-Try))=;. Best (Coupled, e, .05 New) ].\nThis sentence states that whenever there 1s insuffi cient information to choose between the alternatives it should choose the New program. Using it, planner can prove Best (Couple( cl, c2), e, .05, New). D\nWhen the planner has clear evidence that one action is better than another, it need not rely on heuristics. This will be the case when evidence about the effec tiveness of the New action overwhelms evidence about the effectiveness of the Old action. More importantly, the planner will cease to use the New action if it gets clear information that this action does not result in improved performance.\nExample Suppose, after applying the default rule 100 times, the robot finds that New has resulted in cars being coupled 70 times. The number of times instances of the New-Try event and the Couple(c1,c2) event have occurred are\noccurrences( New-Try)= 100 occurrences( Couple( c1, c2)) = 70,\ngenerating new constraints on probability,\nPCA9s( Couple( cl, c2), New-Try) = [0.6041, 0.7811].\nBecause [0.4691, 0.5309] -< [0.6041, 0.7811], the robot chooses the New program and will continue to do so unless it discovers that the probability constraints for the New program fall below the probability con straints for the Old program.\nIf after the initial two executions of the New program, the next seven cause Couple{cl, c2} events, the robot stops relying on the heuristic and begins relying on its own experience. The exact confidence intervals for eight successes in nine trials is [0.5709, 0.9944] whereas the exact confidence interval for seven successes in\neight trials is [0.5294, 0.9937]. Therefore, seven imme diate successes (i.e. the robot has seen eight successes in all) are sufficient to make the robot choose the New program without using the heuristic.\nSuppose, alternatively, that the robot discovers that it has successfully coupled cars only 30 times after ap plying the default rule 100 times. Now the number of occurrences of the event in which it tried the New program and the event in which the cars were coupled are\noccurrences( New-Try) = 100 occurrences( Couple( cl, c2)) = 30\ngenerating new constraints on probability,\nPCA 95( Couple( cl, c2), New-Try ) = [0.2189, 0.3959].\nThe planner chooses to return the Old program be cause [0.2189, 0.3959]-< [0.4691, 0.5309].\nIf after the initial two observations of the Try-New event, the next eight event instances are not also in stances of the Couple{cl,c2) event the robot rejects the heuristic preference for the New program. Be cause [0.0057, 0.4292] is the exact confidence intervals for one success in nine trials and [0.0064, 0.4707] is the interval for one success in eight trials, the robot will need at least eight immediate failures to choose the Old action against the advice of the programmer. D\nThe robot makes a choice when it has enough informa tion to do so; it may reason further or rely on heuristics when it cannot. As the robot gathers more informa tion, it can make more choices based on its information about the probability of success of actions and rely less on guesses.\n4 PLANNING\nBesides choosing actions, a planner must deal with preconditions and composite actions. Preconditions are important because some details may dramatically affect the probability of success of the action chosen. The planner must be able to take these details into account. The planner cannot take into account every thing it knows about the current situation because, in part, there will be only one occurrence of such an event. This is the sample size problem. To solve the problem, the planner chooses the most constrained event that subsumes the current situation for which it has sufficient statistics to make a choice. We call this event the initial event.\nTo facilitate these solutions, a new event, ep, which represents the context of the action, is added to the computation of the probability of the goal given the ac tion. The planner computes PCA1-a( e9, ea, ep) from n = occurrences( ea n ep) and y = occurrences( ea n e9 n ep)\u00b7 The planner chooses the preconditions that produce the highest comparable confidence interval.\nExam pie The engineer is more likely to successfully couple cars if the cars and the engine are in the same city. These constraints can be added to the event against which the success of the action is to be mea sured. For example, suppose we have a new event called a Pre-Try in which the cars and the engine are in the same city. This event will be characterized by:\n'</ (e, cl, c2, city) (In (cJ, city, Time( e)) A In ( c2, city, Time( e)) 1\\ In (Me, city, Time( e))\n=? Pre-Try(e) ].\nAnother event, Any, describes a situation with no con straints in its characterization.\n'<l(e)[Any(e)]\nSince every event that subsumes Old-Try n Any also subsumes Old-Try n Pre-Try, the planner will have more evidence for Old-TrynAny. Since, however, suc cess is unlikely for Old-Tries that were not also sub sumed by Pre-Try, the probability of success will be higher for Old-Try n Pre-Try.\nTo choose the appropriate preconditions, the planner will also need to know that both Old and New are programs whose intention is to couple cars. This can be indicated by generating a new event that is sub sumed by either Try-Old or Try-New, i.e.,\n'</(e) (Old-Try (e) V New-Try (e)=?Try (e)].\nSuppose that the statistics mentioned above have no particular context and that there are 800 instances of an event that subsumes Try n Pre-Try. Suppose also that the number of occurrences of the success event described above is the same as the number of occur rences of success for Try n Pre-Try. That is,\noccurrences( Try n Pre-Try) == 800 occurrences( Couple( c1, c2) n Try n Pre-Try) == 501 occurrences(Tryn Any)= 1002 occurrences( Couple( c1, c2) n Try n Any) = 501.\nThese statistics lead to the following probability con straints:\nPCA.g5( Couple( cl, c2), Try, Pre-Try) = (0.5909, 0.6579]\nPCAg5(Couple(c1, c2), Try, Any)== (0.4691, 0.5309].\nSince (0.4691, 0.5309] --< (0.5922, 0.6591], the planner chooses Pre-Try as the preconditions to the action. 0\nThe planner ignores preconditions about which it has insufficient information. Even though they may affect the probability of the goal, they can be ignored with\nA Language for Planning with Statistics 225\nrelative safety because they occur infrequently. Choos ing preconditions in this manner is similar to assuming preconditions as suggested by Allen [1991].\nExample Suppose the engineer can recognize when the cars loaded or empty.\n'</ (e, cl, c2, city) (Loaded (c1, Time( e)) A Empty ( c2, Time( e)) A In ( c1, city, Time( e) ) A In ( c2, city, Time( e)) A In (Me, city, Time( e))\n=? Pre-Try2 (e)]\nThe ability to recognize the state of the cars may be important if the engineer's task is to move cargo. Due to the large number of such events, however, the engi neer may have weak statistics on them.\nSuppose that there are 100 instances of an event that subsumes Tryn Pre-Try2. Suppose also that 75 of the instances of the success events described above are are instances of Try n Pre-Try2. That is,\noccurrences( Try n Pre-Try2) == 100 occurrences( Couple( cl, c2) n Try n Pre-Try) = 75\nThese statistics lead to the following probability con straints:\nPCA.gs( Couple( c1, c2), Try, Pre-Try2) == [0.6570, 0.8245].\nSince neither (0.6570, 0.8245] --< (0.5922, 0.6591] nor (0.5922, 0.6591]--< (0.6570, 0.8245], the planner chooses Pre-Try as the preconditions to the action again. In this case it chooses to ignore a precondition because it does not have enough information about success rela tive to the precondition. As far as the planner can tell from the statistics, success assuming one event is the same as success assuming the other. 0\nOnce the planner has chosen the appropriate precondi tions for its actions, it chooses actions relative to these preconditions as outlined above.\nThe planner must also deal with sequences of actions. Due to space restrictions, there is only room for a cursory overview of the details of generating such se quences.\nWhen choosing an action in a sequence, the plan ner chooses relative to a hypothetical event caused by executing the actions chosen earlier. For exam ple, in choosing the second action of a two-action plan (A1, A2), it should select the second action in the con text of the event caused by the execution of A1 in the initial event. Since action A1 may have many possi ble effects, this new event may be no simpler than was\n226 Martin and Allen\nthe complete description of the current situation. The planner simplifies this event by reasoning relative to an event for which it has sufficient statistics to choose an appropriate action for the second step of the plan and which subsumes the event caused by executing At.\nWhen selecting an event from which to choose subse quent actions, the planner must first recognize that no single action is adequate. Because the effects of ac tions are uncertain, one possible result of any action is that the goal will hold. As a heuristic the planner might assume that no single action effectively achieves the goal when assuming it performs any single action makes the goal no more likely than assuming it does nothing. Here the planner can be confident that by using time to continue planning, it will miss deadlines. If the goal is part of the current situation, doing noth ing is most likely to cause an event in which the goal holds than doing nothing, as it causes an event that subsumes the maximum number of events and is there fore most likely to subsume the current situation.\nOnce it has realized that it must generate a series of sub-goals to achieve its main goal, it can then deal with each sub-goal as a separate problem. The problems are not really separate, however, because choosing actions that achieve remaining sub-goals may reduce the prob ability that actions already chosen achieve their sub goals. The planner avoids such interaction by choosing remaining actions relative to a hypothetical event that subsumes the event caused by executing actions chosen earlier. The order in which the planner chooses actions is unimportant because the temporal logic allows both constraints that precede and constraints that follow the execution of actions.\nIf the planner has sufficient statistics to reason about sequences of events, it will use them. That is, if it can actually make subsequent choices given the de sired results of previous choices, the planner will make the choices. In situations requiring planning, it is un likely that the planner will have good statistics for long sequences of actions, however. Except for those sequences that are chosen frequently, the statistics are likely to be very weak for the choices the planner must make in long plans. Note that it is the small sample size, not low probability, that makes such decisions untenable. The planner may have actually succeeded every time it chose an action in a very constrained event; it just has not made those choices often enough to be confident in them.\nIf the planner has insufficient statistics to make sub sequent choices, it may rely on heuristics like the one described by formula (2). For example, a good heuris tic would be to wait until further information arrives. If a planner has a partial plan it cannot complete, it might simply specify that partial plan to the reactive execution system and hope for the best. Even if the partial plan is insufficient to actually achieve the goal, the planner may have more information when it needs\nto replan.\nIf the planner has no applicable heuristics or world knowledge, it will assume the actions are independent. Such an assumption may be incorrect, but a planner that uses statistics will at least have evidence that the plans it is generating are ineffective when the statistics begin to reflect its current strategy's low probability of success. For example, if the planner cannot recog nize the event in which the cars and the engine are in the same city, it will continue to try to couple the cars, but will succeed only when the unrecognizable precondition holds. If the engine and cars are rarely in the same city, the probability of success for the en gineer's couple programs will fall, and the engineer's confidence in this low probability will increase. Even tually, the planner will become confident enough that the action rarely succeeds that it will stop attempting it.\n5 CONCLUSION\nA language for reasoning with statistics gives plan ners the ability to reason about the strength of their evidence. By reasoning about the strength of its evi dence, a planner can discount weak evidence as a rea son for preferring one action over another. As far as we are aware, no other formalism combines temporal reasoning and reasoning about evidence. Systems that gather information and generate plans based on that information will need this ability.\nA shortcoming of the proposal as presented here is the weakness of the statistical tests used. Generating confidence intervals and comparing them is wasteful of the planner's valuable data. We are studying other statistical tests that make better use of the data. An other problem is choosing preconditions based on es timations of the probability of the goal given the pre conditions. A better criterion is the information the preconditions provides for the the choice of actions. Measures of information may perform better than do constraints on probability.\nAn unnecessary restriction of the presentation is its ad herence to the frequentist view of probabilities. All of the techniques presented in this paper are equally valid if one uses Bayesian interval estimation rather than confidence intervals. Indeed, even many of the more powerful statistical tests under study have Bayesian correlates.\nA shortcoming this proposal shares with others is the large number of events needed for general purpose planning. In this system, events play the part of op erators in STRIPS. Still, probabilities may suggest a solution to this problem. One could control the num ber of events the planner needs to consider by ensuring that the event occurs frequently. If such an assurance can be made, the planner can assume that if it has\nno stat1st1cs about a particular event, that event is rare. Such assurances may be possible if events are generated through cluster analysis. If the events are generated in this way, the planner may safely assume that only rare events will have no statistics.\nAcknowledgments\nWe would like to thank George Ferguson for his many insightful commments on this work. We would also like to thank Steve Hanks and Bulent Murtezaoglu for comments on earlier drafts of the paper. This material is based on work supported by ONR/DARPA under grant number N0014-82-K-0193 and under AF-Rome Air Development Center contract number F30602-92C-0010.\nReferences\n[Allen and Koomen, 1983] James Allen and Johannes Koomen. Planning using a temporal world model. In IJCAI-83, pages 741-747, 1983.\n[Allen, 1984] James F. Allen. ory of action and time. 23(2):123-145, 1984. Towards a general the Artificial Intelligence,\n[Allen, 1991] James F. Allen. Planning as temporal reasoning. In KR-g1, pages 3-14, 1991.\n[Bickel and Doksum, 1977] Peter J. Bickel and Kjell A. Doksum. Mathematical Statistics: Basic Ideas and Selected Topics. Holden-Day, Inc., Oak land, CA, 1977.\n[Clopper and Pearson, 1934] C. J. Clopper and E. S. Pearson. The use of confidence or fiducial limits illustrated in the case of the binomial. Biometrika, 26:404-413, 1934.\n[Dean and Kanazawa, 1988] Thomas Dean and Keiji Kanazawa. Probablistic temporal reasoning. In AAAI-88, pages 125-132, 1988.\n[Feldman and Sproull, 1977] Jerome Feldman and Robert Sproull. Decision theory and artificial intel ligence II: The hungry monkey. Cognitive Science, 1:158-192, 1977.\n[Fisher and Yates, 1963] R. A. Fisher and F. Yates. Statistical Tables for Biological Agricultural and Medical Research (6th ed.). oliver and Boy de, Edin burg, 1963.\n[Haddawy, 1990] Peter Haddawy. Time, chance, and action. In Uncertainty in AI go, pages 147-153, 1990.\n[Haddawy, 1991] Peter Haddawy. A temporal proba bility logic for representing actions. In KR-g1, pages 313-324, 1991.\n[Hanks, 1988] Steve Hanks. Representing and com puting temporally scoped beliefs. In AAAI-88, pages 501-505, 1988.\nA Language for Planning with Statistics 227\n[Hanks, 1990a] Steve Hanks. Practical temoral pro jection. In AAAI-90, pages 158-163, 1990.\n[Hanks, 1990b] Steven John Hanks. Projecting Plans for Uncertain Worlds. PhD thesis, Yale University, New Haven, CT, 1990.\n[Hartman, 1990] Leo B. Hartman. Decision Theory and the Cost of Planning. PhD thesis, University of Rochester, Rochester, NY 14627, 1990.\n[Horvitz, 1988] Eric J. Horvitz. Reasoning under vary ing and uncertain resource constraints. In AAAI-88, volume 1, pages 111-116, 1988.\n[Jaynes., 1979] E. T. Jaynes. Where do we stand on maximum entropy? In R. D. Levine and M. Tribus, editors, The Maximum Entropy Formalism, pages 279-293. MIT Press, 1979.\n[Johnson and Schubert, 1982] D. T. Johnson and Lenhart K. Schubert. A planning control strategy that allows for the cost of planning. In Proc. 6th Eur. Meet. on Cybernetics and Sys. Research, pages 1-7, 1982.\n[Kaelbling, 1990] Leslie Pack Kaelbling. Learning in Embedded Systems. PhD thesis, Stanford University, Stanford, CA, 1990.\n[Kanazawa and Dean, 1989] Keiji Kanazawa and Thomas Dean. A model for projection and action. In IJCAI-89, pages 985-990, 1989.\n[Kanazawa, 1991] Kaiji Kanazawa. A logic and time nets for probabilistic inference. In AAAI-91, 1991.\n[Kendall and Stuart, 1961] M.G. Kendall and A. Stu art. The Advanced Theory of Statistics Vol II (2nd ed). Hafner Publishing Co., New York, 1961.\n[Kyburg, 1983] Henry E. Kyburg, Jr. The reference class. Philosophy of Science, 50:374-397, 1983.\n[Martin and Allen, 1990a] Nathaniel G. Martin and James F. Allen. Abstraction in planning: A prob abilistic approach. Presented at the Workshop on Automatic Generation of Approximations and Ab stractions, 1990.\n[Martin and Allen, 1990b] Nathaniel G. Martin and James F. Allen. Combining reactive and strate gic planning through decomposition abstraction. In Workshop on Innovative Approaches to Planning, Scheduling and Control, pages 137-143, 1990.\n[Raiffa, 1970] Howard Raiffa. Decision Analysis: In troductory Lectures on Choices under Uncertainty. Addison-Wesley, Reading, MA, 1970.\n[Weber, 1989] Jay C. Weber. A parallel algorithm for statistical belief refinement and its use in causal rea soning. In IJCAJ-8g, August 1989."}], "references": [{"title": "In IJCAI-83", "author": ["James Allen", "Johannes Koomen. Planning using a temporal world model"], "venue": "pages 741-747,", "citeRegEx": "Allen and Koomen. 1983", "shortCiteRegEx": null, "year": 1983}, {"title": "ory of action and time", "author": ["James F. Allen"], "venue": "23(2):123-145,", "citeRegEx": "Allen. 1984", "shortCiteRegEx": null, "year": 1984}, {"title": "In KR-g1", "author": ["James F. Allen. Planning as temporal reasoning"], "venue": "pages 3-14,", "citeRegEx": "Allen. 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "Mathematical Statistics: Basic Ideas and Selected Topics", "author": ["Peter J. Bickel", "Kjell A. Doksum"], "venue": "Holden-Day, Inc., Oak\u00ad land, CA,", "citeRegEx": "Bickel and Doksum. 1977", "shortCiteRegEx": null, "year": 1977}, {"title": "The use of confidence or fiducial limits illustrated in the case of the binomial", "author": ["C.J. Clopper", "E.S. Pearson"], "venue": "Biometrika, 26:404-413", "citeRegEx": "Clopper and Pearson. 1934", "shortCiteRegEx": null, "year": 1934}, {"title": "In AAAI-88", "author": ["Thomas Dean", "Keiji Kanazawa. Probablistic temporal reasoning"], "venue": "pages 125-132,", "citeRegEx": "Dean and Kanazawa. 1988", "shortCiteRegEx": null, "year": 1988}, {"title": "Decision theory and artificial intel\u00ad ligence II: The hungry monkey", "author": ["Jerome Feldman", "Robert Sproull"], "venue": "Cognitive Science, 1:158-192,", "citeRegEx": "Feldman and Sproull. 1977", "shortCiteRegEx": null, "year": 1977}, {"title": "Yates", "author": ["F R.A. Fisher"], "venue": "Statistical Tables for Biological Agricultural and Medical Research (6th ed.). oliver and Boy de, Edin\u00ad burg,", "citeRegEx": "Fisher and Yates. 1963", "shortCiteRegEx": null, "year": 1963}, {"title": "chance", "author": ["Peter Haddawy. Time"], "venue": "and action. In Uncertainty in AI go, pages 147-153,", "citeRegEx": "Haddawy. 1990", "shortCiteRegEx": null, "year": 1990}, {"title": "A temporal proba\u00ad bility logic for representing actions", "author": ["Peter Haddawy"], "venue": "KR-g1, pages 313-324,", "citeRegEx": "Haddawy. 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "Representing and com\u00ad puting temporally scoped beliefs", "author": ["Steve Hanks"], "venue": "AAAI-88, pages 501-505,", "citeRegEx": "Hanks. 1988", "shortCiteRegEx": null, "year": 1988}, {"title": "Practical temoral pro\u00ad jection", "author": ["Steve Hanks"], "venue": "AAAI-90, pages 158-163,", "citeRegEx": "Hanks. 1990a", "shortCiteRegEx": null, "year": 1990}, {"title": "New Haven", "author": ["Steven John Hanks. Projecting Plans for Uncertain Worlds. PhD thesis", "Yale University"], "venue": "CT,", "citeRegEx": "Hanks. 1990b", "shortCiteRegEx": null, "year": 1990}, {"title": "Rochester", "author": ["Leo B. Hartman. Decision Theory", "the Cost of Planning. PhD thesis", "University of Rochester"], "venue": "NY 14627,", "citeRegEx": "Hartman. 1990", "shortCiteRegEx": null, "year": 1990}, {"title": "Reasoning under vary\u00ad ing and uncertain resource constraints", "author": ["Eric J. Horvitz"], "venue": "AAAI-88, volume 1, pages 111-116,", "citeRegEx": "Horvitz. 1988", "shortCiteRegEx": null, "year": 1988}, {"title": "Where do we stand on maximum entropy? In R", "author": ["E.T. Jaynes"], "venue": "D. Levine and M. Tribus, editors, The Maximum Entropy Formalism, pages 279-293. MIT Press", "citeRegEx": "Jaynes.. 1979", "shortCiteRegEx": null, "year": 1979}, {"title": "6th Eur", "author": ["D.T. Johnson", "Lenhart K. Schubert. A planning control strategy that allows for the cost of planning. In Proc"], "venue": "Meet. on Cybernetics and Sys. Research, pages 1-7,", "citeRegEx": "Johnson and Schubert. 1982", "shortCiteRegEx": null, "year": 1982}, {"title": "Stanford", "author": ["Leslie Pack Kaelbling. Learning in Embedded Systems. PhD thesis", "Stanford University"], "venue": "CA,", "citeRegEx": "Kaelbling. 1990", "shortCiteRegEx": null, "year": 1990}, {"title": "In IJCAI-89", "author": ["Keiji Kanazawa", "Thomas Dean. A model for projection", "action"], "venue": "pages 985-990,", "citeRegEx": "Kanazawa and Dean. 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "A logic and time nets for probabilistic inference", "author": ["Kaiji Kanazawa"], "venue": "AAAI-91,", "citeRegEx": "Kanazawa. 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "Stu\u00ad art", "author": ["A M.G. Kendall"], "venue": "The Advanced Theory of Statistics Vol II (2nd ed). Hafner Publishing Co., New York,", "citeRegEx": "Kendall and Stuart. 1961", "shortCiteRegEx": null, "year": 1961}, {"title": "Philosophy of Science", "author": ["Henry E. Kyburg", "Jr. The reference class"], "venue": "50:374-397,", "citeRegEx": "Kyburg. 1983", "shortCiteRegEx": null, "year": 1983}, {"title": "Abstraction in planning: A prob\u00ad abilistic approach", "author": ["Nathaniel G. Martin", "James F. Allen"], "venue": "Presented at the Workshop on Automatic Generation of Approximations and Ab\u00ad stractions,", "citeRegEx": "Martin and Allen. 1990a", "shortCiteRegEx": null, "year": 1990}, {"title": "Combining reactive and strate\u00ad gic planning through decomposition abstraction", "author": ["Nathaniel G. Martin", "James F. Allen"], "venue": "Workshop on Innovative Approaches to Planning, Scheduling and Control, pages 137-143,", "citeRegEx": "Martin and Allen. 1990b", "shortCiteRegEx": null, "year": 1990}, {"title": "Decision Analysis: In\u00ad troductory Lectures on Choices under Uncertainty", "author": ["Howard Raiffa"], "venue": "Addison-Wesley, Reading, MA,", "citeRegEx": "Raiffa. 1970", "shortCiteRegEx": null, "year": 1970}, {"title": "A parallel algorithm for statistical belief refinement and its use in causal rea\u00ad soning", "author": ["Jay C. Weber"], "venue": "IJCAJ-8g, August", "citeRegEx": "Weber. 1989", "shortCiteRegEx": null, "year": 1989}], "referenceMentions": [{"referenceID": 21, "context": "The confidence intervals are used in a manner similar to Kyburg's in\u00ad terval probabilities [Kyburg, 1983].", "startOffset": 91, "endOffset": 105}, {"referenceID": 1, "context": "Tempo\u00ad ral relations are specified using Allen's interval tem\u00ad poral logic [Allen, 1984].", "startOffset": 75, "endOffset": 88}, {"referenceID": 4, "context": "Tables of confidence intervals for binomial random variables can be found in [Clopper and Pearson, 1934] and [Fisher and Yates, 1963].", "startOffset": 77, "endOffset": 104}, {"referenceID": 7, "context": "Tables of confidence intervals for binomial random variables can be found in [Clopper and Pearson, 1934] and [Fisher and Yates, 1963].", "startOffset": 109, "endOffset": 133}, {"referenceID": 20, "context": "There is a discussion of the trade-off between the exact confidence interval and the approximation in [Kendall and Stuart, 1961].", "startOffset": 102, "endOffset": 128}], "year": 2011, "abstractText": "When a planner must decide whether it has enough evidence to make a decision based on probability, it faces the sample size prob\u00ad lem. Current planners using probabilities need not deal with this problem because they do not generate their probabilities from ob\u00ad servations. This paper presents an event\u00ad based language in which the planner's proba\u00ad bilities are calculated from the binomial ran\u00ad dom variable generated by the observed ratio of one type of event to another. Such prob\u00ad abilities are subject to error, so the planner must introspect about their validity. Infer\u00ad ences about the probability of these events can be made using statistics. Inferences about the validity of the approximations can be made using interval estimation. Interval estimation allows the planner to avoid mak\u00ad ing choices that are only weakly supported by the planner's evidence.", "creator": "pdftk 1.41 - www.pdftk.com"}}}