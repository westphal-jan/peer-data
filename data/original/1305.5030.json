{"id": "1305.5030", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2013", "title": "Towards Rational Deployment of Multiple Heuristics in A*", "abstract": "The obvious way to use several admissible heuristics in A* is to take their maximum. In this paper we aim to reduce the time spent on computing heuristics. We discuss Lazy A*, a variant of A* where heuristics are evaluated lazily: only when they are essential to a decision to be made in the A* search process. We present a new rational meta-reasoning based scheme, rational lazy A*, which decides whether to compute the more expensive heuristics at all, based on a myopic value of information estimate. Both methods are examined theoretically. Empirical evaluation on several domains supports the theoretical results, and shows that lazy A* and rational lazy A* are state-of-the-art heuristic combination methods.", "histories": [["v1", "Wed, 22 May 2013 06:41:00 GMT  (522kb,D)", "http://arxiv.org/abs/1305.5030v1", "7 pages, IJCAI 2013, to appear"]], "COMMENTS": "7 pages, IJCAI 2013, to appear", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["david tolpin", "tal beja", "solomon eyal shimony", "ariel felner", "erez karpas"], "accepted": false, "id": "1305.5030"}, "pdf": {"name": "1305.5030.pdf", "metadata": {"source": "CRF", "title": "Towards Rational Deployment of Multiple Heuristics in A*", "authors": ["David Tolpin", "Tal Beja", "Solomon Eyal Shimony", "Ariel Felner"], "emails": ["tolpin@cs.bgu.ac.il", "bejat@cs.bgu.ac.il", "shimony@cs.bgu.ac.il", "felner@bgu.ac.il", "karpase@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "The A\u2217 algorithm [Hart et al., 1968] is a best-first heuristic search algorithm guided by the cost function f(n) = g(n) + h(n). If the heuristic h(n) is admissible (never overestimates the real cost to the goal) then the set of nodes expanded by A\u2217 is both necessary and sufficient to find the optimal path to the goal [Dechter and Pearl, 1985].\nThis paper examines the case where we have several available admissible heuristics. Clearly, we can evaluate all these heuristics, and use their maximum as an admissible heuristic, a scheme we callA\u2217MAX . The problem with naive maximization is that all the heuristics are computed for all the generated nodes. In order to reduce the time spent on heuristic computations, Lazy A\u2217 (or LA\u2217, for short) evaluates the heuristics one at a time, lazily. When a node n is generated, LA\u2217 only computes one heuristic, h1(n), and adds n to OPEN. Only when n re-emerges as the top of OPEN is another heuristic, h2(n), evaluated; if this results in an increased heuristic estimate, n is re-inserted into OPEN. This idea was briefly mentioned by Zhang and Bacchus (2012) in the context of the MAXSAT heuristic for planning domains. LA\u2217 is as informative as A\u2217MAX , but can significantly reduce search time, as we will not need to compute h2 for many nodes. In this paper we provide a deeper examination of LA\u2217, and characterize the savings that it can lead to. In addition, we describe several technical optmizations for LA\u2217. LA\u2217 reduces the search time, while maintaining the informativeness of A\u2217MAX . However, as noted by Domshlak et al. (2012), if the goal is to reduce search time, it may be better to compute a fast heuristic on several nodes, rather\nthan to compute a slow but informative heuristic on only one node. Based on this idea, they formulated selective max (SelMAX), an online learning scheme which chooses one heuristic to compute at each state. Sel-MAX chooses to compute the more expensive heuristic h2 for node n when its classifier predicts that h2(n) \u2212 h1(n) is greater than some threshold, which is a function of heuristic computation times and the average branching factor. Felner et al. (2011) showed that randomizing a heuristic and applying bidirectional pathmax (BPMX) might sometimes be faster than evaluating all heuristics and taking the maximum. This technique is only useful in undirected graphs, and is therefore not applicable to some of the domains in this paper. Both Sel-MAX and Random compute the resulting heuristic once, before each node is added to OPEN while LA\u2217 computes the heuristic lazily, in different steps of the search. In addition, both randomization and Sel-MAX save heuristic computations and thus reduce search time in many cases. However, they might be less informed than pure maximization and as a result expand a larger number of nodes.\nWe then combine the ideas of lazy heuristic evaluation and of trading off more node expansions for less heuristic computation time, into a new variant of LA\u2217 called rational lazy A\u2217 (RLA\u2217). RLA\u2217 is based on rational meta-reasoning, and uses a myopic value-of-information criterion to decide whether to compute h2(n) or to bypass the computation of h2 and expand n immediately when n re-emerges from OPEN. RLA\u2217 aims to reduce search time, even at the expense of more node expansions than A\u2217MAX .\nEmpirical results on variants of the 15-puzzle and on numerous planning domains demonstrate that LA\u2217 and RLA\u2217 lead to state-of-the-art performance in many cases."}, {"heading": "2 Lazy A\u2217", "text": "Throughout this paper we assume for clarity that we have two available admissible heuristics, h1 and h2. Extension to multiple heuristics is straightforward, at least for LA\u2217. Unless stated otherwise, we assume that h1 is faster to compute than h2 but that h2 is weakly more informed, i.e., h1(n) \u2264 h2(n) for the majority of the nodes n, although counter cases where h1(n) > h2(n) are possible. We say that h2 dominates h1, if such counter cases do not exist and h2(n) \u2265 h1(n) for all nodes n. We use f1(n) to denote g(n) + h1(n). Likewise, f2(n) denotes g(n) + h2(n), and fmax(n) denotes\nar X\niv :1\n30 5.\n50 30\nv1 [\ncs .A\nI] 2\n2 M\nay 2\n01 3\nAlgorithm 1: Lazy A\u2217\nInput: LAZY-A\u2217 1 Apply all heuristics to Start 2 Insert Start into OPEN 3 while OPEN not empty do 4 n\u2190 best node from OPEN 5 if Goal(n) then 6 return trace(n) 7 if h2 was not applied to n then 8 Apply h2 to n 9 insert n into OPEN\n10 continue //next node in OPEN\n11 foreach child c of n do 12 Apply h1 to c. 13 insert c into OPEN\n14 Insert n into CLOSED\n15 return FAILURE\ng(n) + max(h1(n), h2(n)). We denote the cost of the optimal solution by C\u2217. Additionally, we denote the computation time of h1 and of h2 by t1 and t2, respectively and denote the overhead of an insert/pop operation in OPEN by to. Unless stated otherwise we assume that t2 is much greater than t1 + to. LA\u2217 thus mainly aims to reduce computations of h2.\nThe pseudo-code for LA\u2217 is depicted as Algorithm 1, and is very similar toA\u2217. In fact, without lines 7 \u2013 10, LA\u2217 would be identical to A\u2217 using the h1 heuristic. When a node n is generated we only compute h1(n) and n is added to OPEN (Lines 11 \u2013 13), without computing h2(n) yet. When n is first removed from OPEN (Lines 7 \u2013 10), we compute h2(n) and reinsert it into OPEN, this time with fmax(n).\nIt is easy to see that LA\u2217 is as informative as A\u2217MAX , in the sense that both A\u2217MAX and LA\n\u2217expand a node n only if fmax(n) is the best f -value in OPEN. Therefore, LA\u2217 and A\u2217MAX generate and expand and the same set of nodes, up to differences caused by tie-breaking.\nIn its general form A\u2217 generates many nodes that it does not expand. These nodes, called surplus nodes [Felner et al., 2012], are in OPEN when we expand the goal node with f = C\u2217. All nodes in OPEN with f > C\u2217 are surely surplus but some nodes with f = C\u2217 may also be surplus. The number of surplus nodes in OPEN can grow exponentially in the size of the domain, resulting in significant costs. LA\u2217 avoids h2 computations for many of these surplus nodes. Consider a node n that is generated with f1(n) > C\u2217. This node is inserted into OPEN but will never reach the top of OPEN, as the goal node will be found with f = C\u2217. In fact, if OPEN breaks ties in favor of small h-values, the goal node with f = C\u2217 will be expanded as soon as it is generated and such savings of h2 will be obtained for some nodes with f1 = C\n\u2217 too. We refer to such nodes where we saved the computation of h2 as good nodes. Other nodes, those with f1(n) < C\n\u2217 (and some with f1(n) = C\u2217) are called regular nodes as we apply both heuristics to them. A\u2217MAX computes both h1 and h2 for all generated nodes, spending time t1 + t2 on all generated nodes. By contrast, for good nodes LA\u2217 only spends t1, and saves t2. In the basic\nimplementation of LA\u2217 (as in algorithm 1) regular nodes are inserted into OPEN twice, first for h1 (Line 13) and then for h2 (Line 9) while good nodes only enter OPEN once (Line 13). Thus, LA\u2217 has some extra overhead of OPEN operations for regular nodes. We distinguish between 3 classes of nodes: (1) expanded regular (ER) \u2014 nodes that were expanded after both heuristics were computed. (2) surplus regular (SR) \u2014 nodes for which h2 was computed but are still in OPEN when the goal was found. (3) surplus good (SG) \u2014 nodes for which only h1 was computed by LA\u2217 when the goal was found.\nThe time overhead of A\u2217MAX and LA \u2217 is summarized in Table 1. LA\u2217 incurs more OPEN operations overhead, but saves h2 computations for the SG nodes. When t2 (boldface in table 1) is significantly greater than both t1 and to there is a clear advantage for LA\u2217, as seen in the SG column."}, {"heading": "3 Enhancements to Lazy A\u2217", "text": "Several enhancements can improve basic LA\u2217 (Algorithm 1), which are effective especially if t1 and to are not negligible."}, {"heading": "3.1 OPEN bypassing", "text": "Suppose node n was just generated, and let fbest denote the best f -value currently in OPEN. LA\u2217 evaluates h1(n) and then inserts n into OPEN. However, if f1(n) \u2264 fbest, then n will immediately reach the top of OPEN and h2 will be computed. In such cases we can choose to compute h2(n) right away (after Line 12 in Algorithm 1), thus saving the overhead of inserting n into OPEN and popping it again at the next step (= 2 \u00d7 to). For such nodes, LA\u2217 is identical to A\u2217MAX , as both heuristics are computed before the node is added to OPEN. This enhancement is called OPEN bypassing (OB). It is a reminiscent of the immediate expand technique applied to generated nodes [Stern et al., 2010; Sun et al., 2009]. The same technique can be applied when n again reaches the top of OPEN when evaluating h2(n) ; if f2(n) \u2264 fbest, expand n right away. With OB, LA\u2217 will incur the extra overhead of two OPEN cycles only for nodes n where f1(n) > fbest and then later f2(n) > fbest."}, {"heading": "3.2 Heuristic bypassing", "text": "Heuristic bypassing (HBP) is a technique that allows A\u2217MAX to omit evaluating one of the two heuristics. HBP is probably used by many implementers, although to the best of our knowledge, it never appeared in the literature. HBP works for a node n under the following two preconditions: (1) the operator between n and its parent p is bidirectional, and (2) both heuristics are consistent [Felner et al., 2011].\nLet C be the cost of the operator. Since the heuristic is consistent we know that |h(p)\u2212 h(n)| \u2264 C. Therefore, h(p)\nprovides the following upper- and lower-bounds on h(n) of h(p) \u2212 C \u2264 h(n) \u2264 h(p) + C. We thus denote h(n) = h(p)\u2212 C and h(n) = h(p) + C.\nTo exploit HBP in A\u2217MAX , we simply skip the computation of h1(n) if h1(n) \u2264 h2(n), and vice versa. For example, consider node a in Figure 1, where all operators cost 1, h1(a) = 6, and h2(a) = 10. Based on our bounds h1(b) \u2264 7 and h2(c) \u2265 9. Thus, there is no need to check h1(b) as h2(b) will surely be the maximum. We can propagate these bounds further to node c. h2(c) = 8 while h1(c) \u2264 8 and again there is no need to evaluate h1(c). Only in the last node d we get that h2(d) = 8 but since h1(c) \u2264 9 then h1(c) can potentially return the maximum and should thus be evaluated.\nHBP can be combined in LA\u2217 in a number of ways. We describe the variant we used. LA\u2217 aims to avoid needless computations of h2. Thus, when h1(n) < h2(n), we delay the computation of h2(n) and add n to OPEN with f(n) = g(n) + h2(n) and continue as in LA\u2217. In this case, we saved t1, delayed t2 and used h2(n) which is more informative than h1(n). If, however, h1(n) \u2265 h2(n), then we compute h1(n) and continue regularly. We note that HBP incurs the time and memory overheads of computing and storing four bounds and should only be applied if there is enough memory and if t1 and especially t2 are very large."}, {"heading": "4 Rational Lazy A\u2217", "text": "LA\u2217 offers us a very strong guarantee, of expanding the same set of nodes as A\u2217MAX . However, often we would prefer to expand more states, if it means reducing search time. We now present Rational Lazy A* (RLA\u2217), an algorithm which attempts to optimally manage this tradeoff.\nUsing principles of rational meta-reasoning [Russell and Wefald, 1991], theoretically every algorithm action (heuristic function evaluation, node expansion, open list operation) should be treated as an action in a sequential decision-making meta-level problem: actions should be chosen so as to achieve the minimal expected search time. However, the appropriate general meta-reasoning problem is extremely hard to define precisely and to solve optimally.\nTherefore, we focus on just one decision type, made in the context of LA\u2217, when n re-emerges from OPEN (Line 7). We have two options: (1) Evaluate the second heuristic h2(n) and add the node back to OPEN (Lines 7-10) like LA\u2217, or (2) bypass the computation of h2(n) and expand n right way (Lines 11 -13), thereby saving time by not computing h2, at the risk of additional expansions and evaluations of h1. In order to choose rationally, we define a criterion based on value of information (VOI) of evaluating h2(n) in this context.\nThe only addition of RLA\u2217 to LA\u2217 is the option to bypass h2 computations (Lines 7-10). Suppose that we choose to compute h2 \u2014 this results in one of the following outcomes: 1: n is still expanded, either now or eventually. 2: n is re-inserted into OPEN, and the goal is found without ever expanding n.\nComputing h2 is helpful only in outcome 2, where potential time savings are due to pruning a search subtree at the expense of the time t2(n). However, whether outcome 2 takes\nplace after a given state is not known to the algorithm until the goal is found, and the algorithm must decide whether to evaluate h2 according to what it believes to be the probability of each of the outcomes. We derive a rational policy for when to evaluate h2, under the myopic assumption that the algorithm continues to behave like LA\u2217 afterwards (i.e., it will never again consider bypassing the computation of h2).\nThe time wasted by being sub-optimal in deciding whether to evaluate h2 is called the regret of the decision. If h2(n) is not helpful and we decide to compute it, the effort for evaluating h2(n) turns out to be wasted. On the other hand, if h2(n) is helpful but we decide to bypass it, we needlessly expand n. Due to the myopic assumption, RLA\u2217 would evaluate both h1 and h2 for all successors of n.\nTable 2 summarizes the regret of each possible decision, for each possible future outcome; each column in the table represents a decision, while each row represents a future outcome. In the table, td is the to time compute h2 and re-insert n into OPEN thus delaying the expansion of n, te is the time to remove n from OPEN, expand n, evaluate h1 on each of the b(n) (\u201clocal branching factor\u201d) children {n\u2032} of n, and insert {n\u2032} into the open list. Computing h2 needlessly wastes time td. Bypassing h2 computation when h2 would have been helpful wastes te + b(n)td time, but because computing h2 would have cost td, the regret is te + (b(n)\u2212 1)td.\nLet us denote the probability that h2 is helpful by ph. The expected regret of computing h2 is thus (1 \u2212 ph)td. On the other hand, the expected regret of bypassing h2 is ph(te + (b(n) \u2212 1)td). As we wish to minimize the expected regret, we should thus evaluate h2 just when:\n(1\u2212 ph)td < ph(te + (b(n)\u2212 1)td) (1) or equivalently:\n(1\u2212 b(n)ph)td < phte (2) If phb(n) \u2265 1, then the expected regret is minimized by always evaluating h2, regardless of the values of td and te. In these cases, RLA\u2217 cannot be expected to do better than LA\u2217. For example, in the 15-puzzle and its variants, the effective branching factor is \u2248 2. Therefore, if h2 is expected to be helpful for more than half of the nodes n on which LA\u2217 evaluates h2(n), then one should simply use LA\u2217.\nFor phb(n) < 1, the decision of whether to evaluate h2 depends on the values of td and te:\nevaluate h2 if td < ph\n1\u2212 phb(n) te (3)\nDenote by tc the time to generate the children of n. Then:\ntd = t2 + to\nte = to + tc + b(n)t1 + b(n)to (4)\nBy substituting (4) into (3), obtain: evaluate h2 if:\nt2 + to < ph [tc + b(n)t1 + (b(n) + 1)to]\n1\u2212 phb(n) (5)\nThe factor ph1\u2212phb(n) depends on the potentially unknown probability ph, making it difficult to reach the optimum decision. However, if our goal is just to do better than LA\u2217, then it is safe to replace ph by an upper bound on ph. Note that the values ph, t1, t2, tc may actually be variables that depend in complicated ways on the state of the search. Despite that, the very crude model we use, assuming that they are setting-specific constants, is sufficient to achieve improved performance, as shown in Section 5.\nWe now turn to implementation-specific estimation of the runtimes. OPEN in A\u2217 is frequently implemented as a priority queue, and thus we have, approximately, to = \u03c4 logNo for some \u03c4 , where the size of OPEN is No. Evaluating h1 is cheap in many domains, as is the case with Manhattan Distance (MD) in discrete domains, to is the most significant part of te. In such cases, rule (5) can be approximated as 6:\nevaluate h2 if t2 < \u03c4ph\n1\u2212 phb(n) (b(n) + 1) logNo (6)\nRule (6) recommends to evaluate h2 mostly at late stages of the search, when the open list is large, and in nodes with a higher branching factor.\nIn other domains, such as planning, both t1 and t2 are significantly greater than both to and tc, and terms not involving t1 or t2 can be dropped from (5), resulting in Rule (7):\nevaluate h2 if t2 t1 < phb(n) 1\u2212 phb(n) (7)\nThe right hand side of (7) grows with b(n), and here it is beneficial to evaluate h2 only for nodes with a sufficiently large branching factor."}, {"heading": "5 Empirical evaluation", "text": "We now present our empirical evaluation of LA\u2217 and RLA\u2217, on variants of the 15-puzzle and on planning domains."}, {"heading": "5.1 Weighted 15 puzzle", "text": "We first provide evaluations on the weighted 15-puzzle variant [Thayer and Ruml, 2011], where the cost of moving each tile is equal to the number on the tile. We used a subset of 36 problem instances (out of the 100 instances of Korf (1985)) which could be solved with 2Gb of RAM and 15 minutes timeout using the Weighted Manhattan heuristic (WMD) for h1. As the expensive and informative heuristic h2 we use a heuristic based on lookaheads [Stern et al., 2010]. Given a bound d we applied a bounded depth-first search from a node n and backtracked when we reached leaf nodes l for which g(l) + WMD(l) > g(n) + WMD(n) + d. f -values from leaves were propagated to n.\nTable 3 presents the results averaged on all instances solved. The runtimes are reported relative to the time\nof A\u2217 with WMD (with no lookahead), which generated 1,886,397 nodes (not reported in the table). The first 3 columns of Table 3 show the results for A\u2217 with the lookahead heuristic for different lookahead depths. The best time is achieved for lookahead 6 (0.588 compared to A\u2217 with WMD). The fact that the time does not continue to decrease with deeper lookaheads is clearly due to the fact that although the resulting heuristic improves as a function of lookahead depth (expanding and generating fewer nodes), the increasing overheads of computing the heuristic eventually outweights savings due to fewer expansions.\nThe next 4 columns show the results for LA\u2217 with WMD as h1, lookahead as h2, for different lookahead depths. The Good1 column presents the number of nodes where LA\u2217 saved the computation of h2 while the h2 column presents the number of nodes where h2 was computed. Roughly 28% of nodes were Good1 and since t2 was the most dominant time cost, most of this saving is reflected in the timing results. The best results are achieved for lookahead 8, with a runtime of 0.527 compared to A\u2217 with WMD.\nThe final columns show the results ofRLA\u2217 , with the values of \u03c4, ph, t2 calibrated for each lookahead depth using a small subset of problem instances. The Good2 column counts the number of times that RLA\u2217 decided to bypass the h2 computation. Observe that RLA\u2217 outperforms LA\u2217, which in turn outperforms A\u2217, for most lookahead depths. The lowest time with RLA\u2217 (0.371 of A\u2217 with WMD) was obtained for lookahead 10. That is achieved as the more expensive h2 heuristic is computed less often, reducing its effective computational overhead, with some adverse effect in the number of expanded nodes. Although LA\u2217 expanded fewer nodes, RLA\u2217 performed much fewer h2 computations as can be seen in the table, resulting in decreased overall runtimes."}, {"heading": "5.2 Planning domains", "text": "We implemented LA\u2217 and RLA\u2217 on top of the Fast Downward planning system [Helmert, 2006], and experimented with two state of the art heuristics: the admissible landmarks heuristic hLA (used as h1) [Karpas and Domshlak, 2009], and the landmark cut heuristic hLMCUT [Helmert and Domshlak, 2009] (used as h2). On average, hLMCUT computation is 8.36 times more expensive than hLA computation. We did not implement HBP in the planning domains as the heuristics we use are not consistent and in general the operators are not invertible. We also did not implement OB, as the cost of OPEN operations in planning is trivial compared to the cost of heuristic evaluations.\nWe experimented with all planning domains without conditional effects and derived predicates (which the heuristics we used do not support) from previous IPCs. We compare the performance of LA\u2217 and RLA\u2217 to that of A\u2217 using each\nof the heuristics individually, as well as to their max-based combination, and their combination using selective-max (SelMAX) [Domshlak et al., 2012]. The search was limited to 6GB memory, and 5 minutes of CPU time on a single core of an Intel E8400 CPU with 64-bit Linux OS.\nWhen applying RLA\u2217 in planning domains we evaluate rule (7) at every state. This rule involves two unknown quantities: t2t1 , the ratio between heuristic computations times, and ph, the probability that h2 is helpful. Estimating t2t1 is quite easy \u2014 we simply use the average computation times of both heuristics, which we measure as search progresses.\nEstimating ph is not as simple. While it is possible to empirically determine the best value for ph, as done for the weighted 15 puzzle, this does not fit the paradigm of domainindependent planning. Furthermore, planning domains are very different from each other, and even problem instances in the same domain are of varying size, and thus getting a single value for ph which works well for many problems is difficult. Instead, we vary our estimate of ph adaptively during search. To understand this estimate, first note that if n is a node at which h2 was helpful, then we computed h2 for n, but did not expand n. Thus, we can use the number of states for which we computed h2 that were not yet expanded (denoted by A), divided by the number of states for which we computed h2 (denoted by B), as an approximation of ph. However, AB is not likely to be a stable estimate at the beginning of the search, as A and B are both small numbers. To overcome this problem, we \u201cimagine\u201d we have observed k examples, which give us\nan estimate of ph = pinit, and use a weighted average between these k examples, and the observed examples \u2014 that is, we estimate ph by (AB \u00b7 B + pinit \u00b7 k)/(B + k). In our empirical evaluation, we used k = 1000 and pinit = 0.5.\nTable 4 depicts the experimental results. The leftmost part of the table shows the number of solved problems in each domain. As the table demonstrates, RLA\u2217 solves the most problems, and LA\u2217 solves the same number of problems as Sel-MAX. Thus, both LA\u2217 and RLA\u2217 are state-of-the-art in cost-optimal planning. Looking more closely at the results, note that Sel-MAX solves 10 more problems than LA\u2217 and RLA\u2217 in the freecell domain. Freecell is one of only three domains in which hLA is more informed than hLMCUT (the other two are nomystery-opt11 and visitall-opt11), violating the basic assumptions behind LA\u2217 that h2 is more informed than h1. If we ignore these domains, both LA\u2217 and RLA\u2217 solve more problems than Sel-MAX.\nThe middle part of the Table 4 shows the geometric mean of planning time in each domain, over the commonly solved problems (i.e., those that were solved by all 6 methods). RLA\u2217 is the fastest overall, with LA\u2217 second. It is important to note that both LA\u2217 and RLA\u2217 are very robust, and even in cases where they are not the best they are never too far from the best. For example, consider the miconic domain. Here, hLA is very informative and thus the variant that only computed hLA is the best choice (but a bad choice overall). Observe that both LA\u2217 andRLA\u2217 saved 86% of hLMCUT computations, and were very close to the best algorithm in this extreme case. In contrast, the other algorithms that consider\nboth heuristics (max and Sel-MAX) performed very poorly here (more than three times slower).\nThe rightmost part of Table 4 shows the average fraction of nodes for which LA\u2217 and RLA\u2217 did not evaluate the more expensive heuristic, hLMCUT , over the problems solved by both these methods. This is shown in the good columns. Our first observation is that this fraction varies between different domains, indicating why LA\u2217 works well in some domains, but not in others. Additionally, we can see that in domains where there is a difference in this number between LA\u2217 and RLA\u2217, RLA\u2217 usually performs better in terms of time. This indicates that whenRLA\u2217 decides to skip the computation of the expensive heuristic, it is usually the right decision.\nFinally, Table 5 shows the total number of expanded and generated states over all commonly solved problems. LA\u2217 is indeed as informative as A\u2217MAX (the small difference is caused by tie-breaking), while RLA\u2217 is a little less informed and expands slightly more nodes. However, RLA\u2217 is much more informative than its \u201cintelligent\u201d competitor - SelMAX, as these are the only two algorithms in our set which selectively omit some heuristic computations. RLA\u2217 generated almost half of the nodes compared to Sel-MAX, suggesting that its decisions are better."}, {"heading": "5.3 Limitations of LA\u2217: 15 puzzle example", "text": "Some domains and heuristic settings will not achieve time speedup with LA\u2217. An example is the regular, unweighed 15- puzzle. Results for A\u2217MAX and LA\n\u2217 with and without HBP on the 15-puzzle are reported in Table 6. HBP1 (HBP2) count the number of nodes where HBP pruned the need to compute h1 (resp. h2). OB is the number of nodes where OB was helpful. Bad is the number of nodes that went through two OPEN cycles. Finally, Good is the number of nodes where computation of h2 was saved due to LA\u2217.\nIn the first experiment, Manhattan distance (MD) was divided into two heuristics: \u2206x and \u2206y used as h1 and h2. Results are averaged over 100 random instances with average solution depth of 26.66. As seen from the first two lines, HBP when applied on top ofA\u2217MAXsaved about 36% of the heuristic evaluations. Next are results for LA\u2217 and LA\u2217+HBP. Many nodes are pruned by HBP, or OB. The number of good nodes dropped from 28% (Line 3) to as little as 11% when HBP was applied. Timing results (in ms) show that all variants performed equally. The reason is that the time overhead of the \u2206x and \u2206y heuristics is very small so the saving on these 28% or 11% of nodes was not significant to outweigh the HBP overhead of handling the upper and lower bounds.\nThe next experiment is with MD as h1 and a variant of the additive 7-8 PDBs [Korf and Felner, 2002], as h2. Here we can observe an interesting phenomenon. For LA\u2217, most nodes were caught by either HBP (when applicable) or by\nOB. Only 4% of the nodes were good nodes. The reason is that the 7-8 PDB heuristic always dominates MD and is always the maximum among the two. Thus, 7-8 PDB was needed at early stages (e.g. by OB) and MD itself almost never caused nodes to be added to OPEN and remain there until the goal was found.\nThese results indicate that on such domains, LA\u2217 has limited merit. Due to uniform operator cost and the heuristics being consistent and simple to compute, very little space is left for improvement with good nodes. We thus conclude that LA\u2217 is likely to be effective when there is significant difference between t1 and t2, and/or operators that are not bidirectional and/or with non-uniform costs, allowing for more good nodes and significant time saving."}, {"heading": "6 Conclusion", "text": "We discussed two schemes for decreasing heuristic evaluation times. LA\u2217 is very simple to implement and is as informative as A\u2217MAX . LA\n\u2217 can significantly speed up the search, especially if t2 dominates the other time costs, as seen in weighted 15 puzzle and planning domains. Rational LA\u2217 allows additional cuts in h2 evaluations, at the expense of being less informed than A\u2217MAX . However, due to a rational tradeoff, this allows for an additional speedup, and Rational LA\u2217 achieves the best overall performance in our domains. RLA\u2217 is simpler to implement than its direct competi-\ntor, Sel-MAX, but its decision can be more informed. When RLA\u2217 has to decide whether to compute h2 for some node n, it already knows that f1(n) \u2264 C\u2217. By contrast, although SelMAX uses a much more complicated decision rule, it makes its decision when n is first generated, and does not know whether h1 will be informative enough to prune n. Rational LA\u2217 outperforms Sel-MAX in our planning experiments. RLA\u2217 and its analysis can be seen as an instance of the rational meta-reasoning framework [Russell and Wefald, 1991]. While this framework is very general, it is extremely hard to apply in practice. Recent work exists on meta-reasoning in DFS algorithms for CSP) [Tolpin and Shimony, 2011] and in Monte-Carlo tree search [Hay et al., 2012]. This paper applies these methods successfully to a variant of A\u2217. There are numerous other ways to use rational meta-reasoning to improve A\u2217, starting from generalizing RLA\u2217 to handle more than two heuristics, to using the meta-level to control decisions in other variants of A\u2217. All these potential extensions provide fruitful ground for future work."}, {"heading": "7 Acknowledgments", "text": "The research was supported by the Israeli Science Foundation (ISF) under grant #305/09 to Ariel Felner and Eyal Shimony and by Lynne and William Frankel Center for Computer Science."}], "references": [{"title": "Generalized best-first search strategies and the optimality of A", "author": ["R. Dechter", "J. Pearl"], "venue": "Journal of the ACM, 32(3):505\u2013536", "citeRegEx": "Dechter and Pearl. 1985", "shortCiteRegEx": null, "year": 1985}, {"title": "JAIR", "author": ["Carmel Domshlak", "Erez Karpas", "Shaul Markovitch. Online speedup learning for optimal planning"], "venue": "44:709\u2013755,", "citeRegEx": "Domshlak et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Inconsistent heuristics in theory and practice", "author": ["A. Felner", "U. Zahavi", "R. Holte", "J. Schaeffer", "N. Sturtevant", "Z. Zhang"], "venue": "Artificial Intelligence, 175(910):1570\u20131603", "citeRegEx": "Felner et al.. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "and Holte R", "author": ["A. Felner", "M. Goldenberg", "G. Sharon", "R. Stern", "T. Beja", "N.R. Sturtevant", "J. Schaeffer"], "venue": "Partial-expansion a* with selective node generation. In AAAI, pages 471\u2013477", "citeRegEx": "Felner et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "A formal basis for the heuristic determination of minimum cost paths", "author": ["P.E. Hart", "N.J. Nilsson", "B. Raphael"], "venue": "IEEE Transactions on Systems Science and Cybernetics, SCC-4(2):100\u2013107", "citeRegEx": "Hart et al.. 1968", "shortCiteRegEx": null, "year": 1968}, {"title": "Selecting computations: Theory and applications", "author": ["Nicholas Hay", "Stuart Russell", "David Tolpin", "Solomon Eyal Shimony"], "venue": "Nando de Freitas and Kevin P. Murphy, editors, UAI, pages 346\u2013355. AUAI Press,", "citeRegEx": "Hay et al.. 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "critical paths and abstractions: What\u2019s the difference anyway? In ICAPS", "author": ["Malte Helmert", "Carmel Domshlak. Landmarks"], "venue": "pages 162\u2013169,", "citeRegEx": "Helmert and Domshlak. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "JAIR", "author": ["Malte Helmert. The Fast Downward planning system"], "venue": "26:191\u2013246,", "citeRegEx": "Helmert. 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "In IJCAI", "author": ["Erez Karpas", "Carmel Domshlak. Cost-optimal planning with landmarks"], "venue": "pages 1728\u20131733,", "citeRegEx": "Karpas and Domshlak. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Disjoint pattern database heuristics", "author": ["R.E. Korf", "A. Felner"], "venue": "Artificial Intelligence, 134(12):9\u201322", "citeRegEx": "Korf and Felner. 2002", "shortCiteRegEx": null, "year": 2002}, {"title": "Depth-first iterative-deepening: An optimal admissible tree search", "author": ["R.E. Korf"], "venue": "Artificial Intelligence, 27(1):97\u2013109", "citeRegEx": "Korf. 1985", "shortCiteRegEx": null, "year": 1985}, {"title": "Artificial Intelligence", "author": ["Stuart Russell", "Eric Wefald. Principles of metereasoning"], "venue": "49:361\u2013395,", "citeRegEx": "Russell and Wefald. 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "In AAAI", "author": ["Roni Stern", "Tamar Kulberis", "Ariel Felner", "Robert Holte. Using lookaheads with optimal bestfirst search"], "venue": "pages 185\u2013190,", "citeRegEx": "Stern et al.. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Simple optimization techniques for A*-based search", "author": ["X. Sun", "W. Yeoh", "P. Chen", "S. Koenig"], "venue": "AAMAS, pages 931\u2013936", "citeRegEx": "Sun et al.. 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Bounded suboptimal search: A direct approach using inadmissible estimates", "author": ["Jordan T. Thayer", "Wheeler Ruml"], "venue": "Proceedings of the Twentysecond International Joint Conference on Artificial Intelligence (IJCAI-11),", "citeRegEx": "Thayer and Ruml. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "editor", "author": ["David Tolpin", "Solomon Eyal Shimony. Rational deployment of CSP heuristics. In Toby Walsh"], "venue": "IJCAI, pages 680\u2013686. IJCAI/AAAI,", "citeRegEx": "Tolpin and Shimony. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Maxsat heuristics for cost optimal planning", "author": ["Lei Zhang", "Fahiem Bacchus"], "venue": "AAAI,", "citeRegEx": "Zhang and Bacchus. 2012", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 4, "context": "1 Introduction The A\u2217 algorithm [Hart et al., 1968] is a best-first heuristic search algorithm guided by the cost function f(n) = g(n) + h(n).", "startOffset": 32, "endOffset": 51}, {"referenceID": 0, "context": "If the heuristic h(n) is admissible (never overestimates the real cost to the goal) then the set of nodes expanded by A\u2217 is both necessary and sufficient to find the optimal path to the goal [Dechter and Pearl, 1985].", "startOffset": 191, "endOffset": 216}, {"referenceID": 3, "context": "These nodes, called surplus nodes [Felner et al., 2012], are in OPEN when we expand the goal node with f = C\u2217.", "startOffset": 34, "endOffset": 55}, {"referenceID": 12, "context": "It is a reminiscent of the immediate expand technique applied to generated nodes [Stern et al., 2010; Sun et al., 2009].", "startOffset": 81, "endOffset": 119}, {"referenceID": 13, "context": "It is a reminiscent of the immediate expand technique applied to generated nodes [Stern et al., 2010; Sun et al., 2009].", "startOffset": 81, "endOffset": 119}, {"referenceID": 2, "context": "HBP works for a node n under the following two preconditions: (1) the operator between n and its parent p is bidirectional, and (2) both heuristics are consistent [Felner et al., 2011].", "startOffset": 163, "endOffset": 184}, {"referenceID": 11, "context": "Using principles of rational meta-reasoning [Russell and Wefald, 1991], theoretically every algorithm action (heuristic function evaluation, node expansion, open list operation) should be treated as an action in a sequential decision-making meta-level problem: actions should be chosen so as to achieve the minimal expected search time.", "startOffset": 44, "endOffset": 70}, {"referenceID": 14, "context": "We first provide evaluations on the weighted 15-puzzle variant [Thayer and Ruml, 2011], where the cost of moving each tile is equal to the number on the tile.", "startOffset": 63, "endOffset": 86}, {"referenceID": 12, "context": "As the expensive and informative heuristic h2 we use a heuristic based on lookaheads [Stern et al., 2010].", "startOffset": 85, "endOffset": 105}, {"referenceID": 7, "context": "2 Planning domains We implemented LA\u2217 and RLA\u2217 on top of the Fast Downward planning system [Helmert, 2006], and experimented with two state of the art heuristics: the admissible landmarks heuristic hLA (used as h1) [Karpas and Domshlak, 2009], and the landmark cut heuristic hLMCUT [Helmert and Domshlak, 2009] (used as h2).", "startOffset": 91, "endOffset": 106}, {"referenceID": 8, "context": "2 Planning domains We implemented LA\u2217 and RLA\u2217 on top of the Fast Downward planning system [Helmert, 2006], and experimented with two state of the art heuristics: the admissible landmarks heuristic hLA (used as h1) [Karpas and Domshlak, 2009], and the landmark cut heuristic hLMCUT [Helmert and Domshlak, 2009] (used as h2).", "startOffset": 215, "endOffset": 242}, {"referenceID": 6, "context": "2 Planning domains We implemented LA\u2217 and RLA\u2217 on top of the Fast Downward planning system [Helmert, 2006], and experimented with two state of the art heuristics: the admissible landmarks heuristic hLA (used as h1) [Karpas and Domshlak, 2009], and the landmark cut heuristic hLMCUT [Helmert and Domshlak, 2009] (used as h2).", "startOffset": 282, "endOffset": 310}, {"referenceID": 1, "context": "of the heuristics individually, as well as to their max-based combination, and their combination using selective-max (SelMAX) [Domshlak et al., 2012].", "startOffset": 126, "endOffset": 149}, {"referenceID": 9, "context": "The next experiment is with MD as h1 and a variant of the additive 7-8 PDBs [Korf and Felner, 2002], as h2.", "startOffset": 76, "endOffset": 99}, {"referenceID": 11, "context": "RLA\u2217 and its analysis can be seen as an instance of the rational meta-reasoning framework [Russell and Wefald, 1991].", "startOffset": 90, "endOffset": 116}, {"referenceID": 15, "context": "Recent work exists on meta-reasoning in DFS algorithms for CSP) [Tolpin and Shimony, 2011] and in Monte-Carlo tree search [Hay et al.", "startOffset": 64, "endOffset": 90}, {"referenceID": 5, "context": "Recent work exists on meta-reasoning in DFS algorithms for CSP) [Tolpin and Shimony, 2011] and in Monte-Carlo tree search [Hay et al., 2012].", "startOffset": 122, "endOffset": 140}], "year": 2013, "abstractText": "The obvious way to use several admissible heuristics in A\u2217 is to take their maximum. In this paper we aim to reduce the time spent on computing heuristics. We discuss Lazy A\u2217, a variant of A\u2217 where heuristics are evaluated lazily: only when they are essential to a decision to be made in the A\u2217 search process. We present a new rational meta-reasoning based scheme, rational lazy A\u2217, which decides whether to compute the more expensive heuristics at all, based on a myopic value of information estimate. Both methods are examined theoretically. Empirical evaluation on several domains supports the theoretical results, and shows that lazy A\u2217 and rational lazy A\u2217 are state-of-the-art heuristic combination methods.", "creator": "LaTeX with hyperref package"}}}