{"id": "1307.7808", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jul-2013", "title": "Automated Attack Planning", "abstract": "Penetration Testing is a methodology for assessing network security, by generating and executing possible attacks. Doing so automatically allows for regular and systematic testing. A key question then is how to automatically generate the attacks. A natural way to address this issue is as an attack planning problem. In this thesis, we are concerned with the specific context of regular automated pentesting, and use the term \"attack planning\" in that sense. The following three research directions are investigated.", "histories": [["v1", "Tue, 30 Jul 2013 04:19:25 GMT  (1987kb,D)", "http://arxiv.org/abs/1307.7808v1", "PhD Thesis. 171 pages"]], "COMMENTS": "PhD Thesis. 171 pages", "reviews": [], "SUBJECTS": "cs.AI cs.CR", "authors": ["carlos sarraute"], "accepted": false, "id": "1307.7808"}, "pdf": {"name": "1307.7808.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Carlos SARRAUTE", "Gerardo Richarte", "J\u00f6rg Hoffmann", "Hugo Scolnik", "Marcelo Frias"], "emails": [], "sections": [{"heading": null, "text": "Tesis para optar al t\u0301\u0131tulo de\nDoctor en Ingenier\u0301\u0131a Informa\u0301tica\ndel\nInstituto Tecnolo\u0301gico de Buenos Aires"}, {"heading": "Automatizacio\u0301n de Planning de Ataques", "text": "Informa\u0301ticos\nAutor: Carlos SARRAUTE\nDirector: Gerardo Richarte\nCo-director: Eduardo Bonelli\nBuenos Aires, Argentina\nJulio 2012\nar X\niv :1\n30 7.\n78 08\nv1 [\ncs .A\nI] 3\n0 Ju\nl 2 01\n3"}, {"heading": "AUTOMATIZACIO\u0301N DE PLANNING DE ATAQUES", "text": "INFORMA\u0301TICOS\npor\nCarlos SARRAUTE"}, {"heading": "En cumplimiento parcial de los requisitos", "text": "para optar al grado de"}, {"heading": "DOCTOR EN INGENIERI\u0301A INFORMA\u0301TICA", "text": "del"}, {"heading": "INSTITUTO TECNOLO\u0301GICO DE BUENOS AIRES", "text": ""}, {"heading": "Buenos Aires, Argentina 2 de Julio de 2012", "text": "c\u00a9 Copyright Carlos SARRAUTE, 2012\nAUTOMATED ATTACK PLANNING\nby\nCarlos SARRAUTE"}, {"heading": "Submitted in partial fulfillment of the", "text": "requirements for the degree of\nDOCTOR EN INGENIERI\u0301A INFORMA\u0301TICA\nat"}, {"heading": "INSTITUTO TECNOLO\u0301GICO DE BUENOS AIRES", "text": ""}, {"heading": "Buenos Aires, Argentina July 2nd, 2012", "text": "c\u00a9 Copyright by Carlos SARRAUTE, 2012"}, {"heading": "Instituto Tecnolo\u0301gico de Buenos Aires", "text": ""}, {"heading": "School of Engineering", "text": "Department of Informatics Engineering\nThe undersigned hereby certify that they have examined, and recommend to the Faculty of Graduate Studies for acceptance, the thesis entitled \u201cAutomated Attack Planning\u201d by Carlos SARRAUTE in partial fulfillment of the requirements for the degree of Doctor of Philosophy.\nDated:\nSupervisor: Gerardo Richarte\nCo-supervisor: Eduardo Bonelli\nExaminers: Jo\u0308rg Hoffmann\nHugo Scolnik\nMarcelo Frias\nii"}, {"heading": "Instituto Tecnolo\u0301gico de Buenos Aires", "text": ""}, {"heading": "School of Engineering", "text": "DATE:\nAUTHOR: Carlos SARRAUTE"}, {"heading": "TITLE: Automated Attack Planning", "text": "MAJOR SUBJECT: Informatics Engineering\nDEGREE: Doctor of Philosophy\nCONVOCATION: July, 2012\nPermission is herewith granted to Instituto Tecnolo\u0301gico de Buenos Aires to circulate and to have copied for non-commercial purposes, at its discretion, the above thesis upon the request of individuals or institutions.\nSignature of Author\nThe author reserves other publication rights, and neither the thesis nor extensive extracts from it may be printed or otherwise reproduced without the author\u2019s written permission.\nThe author attests that permission has been obtained for the use of any copyrighted material appearing in the thesis (other than brief excerpts requiring only proper acknowledgement in scholarly writing), and that all such use is clearly acknowledged.\niii"}, {"heading": "Contents", "text": ""}, {"heading": "Abstract x", "text": ""}, {"heading": "Acknowledgements xii", "text": "Chapter 1 Introduction 1\n1.1 Overview of the Thesis . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 The Confluence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\nChapter 2 Background on Penetration Testing 7\n2.1 Computer Network Intrusions . . . . . . . . . . . . . . . . . . . . . 7 2.2 On Vulnerabilities and Exploits . . . . . . . . . . . . . . . . . . . . 8\n2.2.1 Basic Definitions . . . . . . . . . . . . . . . . . . . . . . . . 8 2.2.2 Anatomy of an Exploit . . . . . . . . . . . . . . . . . . . . . 9 2.2.3 Syscall Proxy Agents . . . . . . . . . . . . . . . . . . . . . . 11\n2.3 Main Steps of an Attack . . . . . . . . . . . . . . . . . . . . . . . . 13\n2.3.1 Information Gathering . . . . . . . . . . . . . . . . . . . . . 14 2.3.2 Attack and Penetrate . . . . . . . . . . . . . . . . . . . . . . 15 2.3.3 Local Information Gathering . . . . . . . . . . . . . . . . . . 15 2.3.4 Privilege Escalation . . . . . . . . . . . . . . . . . . . . . . . 15 2.3.5 Pivoting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.3.6 Clean Up . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n2.4 The Need for Automation . . . . . . . . . . . . . . . . . . . . . . . 16\nI Integrating a Pentesting Tool with Classical Planners 18\nChapter 3 Conceptual Model of Network Attacks 19\n3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 3.2 Assets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n3.2.1 Representations and Assumptions . . . . . . . . . . . . . . . 21 3.2.2 The Environment Knowledge . . . . . . . . . . . . . . . . . 22\nv\n3.3 Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n3.3.1 Goal Quantifiers . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.4 Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.4.1 Action Goal . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 3.4.2 Action Requirements . . . . . . . . . . . . . . . . . . . . . . 24 3.4.3 The Execution Phase (or the Action Itself) . . . . . . . . . . 24 3.4.4 Noise Produced and Stealthiness . . . . . . . . . . . . . . . 25 3.4.5 Running Time and Probability of Success . . . . . . . . . . 26 3.4.6 Exploited Vulnerability . . . . . . . . . . . . . . . . . . . . . 26\n3.5 Agents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n3.5.1 Human Attackers . . . . . . . . . . . . . . . . . . . . . . . . 27 3.5.2 Software Agents . . . . . . . . . . . . . . . . . . . . . . . . . 28 3.5.3 Communication between Agents . . . . . . . . . . . . . . . . 28 3.5.4 Agent Mission . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n3.6 Building an Attack . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n3.6.1 Attack Parameters . . . . . . . . . . . . . . . . . . . . . . . 29 3.6.2 Evaluating Paths . . . . . . . . . . . . . . . . . . . . . . . . 30\n3.7 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n3.7.1 Attack Planning . . . . . . . . . . . . . . . . . . . . . . . . . 31 3.7.2 Simulations and Analysis of Network Security . . . . . . . . 31\n3.8 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n3.8.1 Description of Security Incidents . . . . . . . . . . . . . . . 32 3.8.2 Attack Models . . . . . . . . . . . . . . . . . . . . . . . . . . 32 3.8.3 Attack Graphs . . . . . . . . . . . . . . . . . . . . . . . . . 32\n3.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\nChapter 4 Planning Representations 35\n4.1 Basic Formalization . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n4.1.1 Formalization as a Dynamic System . . . . . . . . . . . . . . 35 4.1.2 General Assumptions . . . . . . . . . . . . . . . . . . . . . . 36 4.1.3 Extending the Model . . . . . . . . . . . . . . . . . . . . . . 37 4.1.4 Number of States . . . . . . . . . . . . . . . . . . . . . . . . 38\n4.2 Classical Planning Representations . . . . . . . . . . . . . . . . . . 39\nvi\n4.2.1 Set-Theoretic Representation . . . . . . . . . . . . . . . . . 40 4.2.2 First Order Logic Representation . . . . . . . . . . . . . . . 43\n4.3 The PDDL Representation in Detail . . . . . . . . . . . . . . . . . 45\n4.3.1 Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 4.3.2 Predicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 4.3.3 Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 4.3.4 An Attack Plan . . . . . . . . . . . . . . . . . . . . . . . . . 49\n4.4 Expressivity of the PDDL Representation . . . . . . . . . . . . . . . 50 4.5 The Hypergraph Representation . . . . . . . . . . . . . . . . . . . . 55\n4.5.1 Basic concepts . . . . . . . . . . . . . . . . . . . . . . . . . . 55 4.5.2 NP-Hardness of the Hypergraph Formulation . . . . . . . . . 56\nChapter 5 Integration with Classical Planners 57\n5.1 Attack Planning in the Real World . . . . . . . . . . . . . . . . . . 57 5.2 Architecture of our Solution . . . . . . . . . . . . . . . . . . . . . . 58\n5.2.1 The \u201cTransform\u201d Algorithm . . . . . . . . . . . . . . . . . . 59 5.2.2 The Planner . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n5.3 Performance and Scalability Evaluation . . . . . . . . . . . . . . . . 60\n5.3.1 Generating the Test Scenarios . . . . . . . . . . . . . . . . . 62 5.3.2 Experimental Results . . . . . . . . . . . . . . . . . . . . . . 63 5.3.3 Improving the Memory Usage of Metric-FF . . . . . . . . . 69\n5.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 5.5 Summary and Future Work . . . . . . . . . . . . . . . . . . . . . . 70\nChapter 6 Simulation of Network Scenarios 72\n6.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\n6.1.1 Design Restrictions . . . . . . . . . . . . . . . . . . . . . . . 73 6.1.2 Main Features . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n6.2 Background and Related Work . . . . . . . . . . . . . . . . . . . . . 75 6.3 Insight Approach and Overview . . . . . . . . . . . . . . . . . . . . 77 6.4 The Simulated Attack Model . . . . . . . . . . . . . . . . . . . . . . 80\n6.4.1 Probabilistic Exploits . . . . . . . . . . . . . . . . . . . . . . 81 6.4.2 Remote Attack Model Overview . . . . . . . . . . . . . . . . 82\nvii\n6.4.3 Local Attack Model Overview . . . . . . . . . . . . . . . . . 83\n6.5 Detailed Description . . . . . . . . . . . . . . . . . . . . . . . . . . 84\n6.5.1 The Insight Development Library . . . . . . . . . . . . . . . 84\n6.5.2 Simulating Sockets . . . . . . . . . . . . . . . . . . . . . . . 85\n6.5.3 The Exploits Database . . . . . . . . . . . . . . . . . . . . . 86\n6.5.4 Scheduler . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n6.5.5 File System . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\n6.6 Performance Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . 90\n6.7 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\n6.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93"}, {"heading": "II Development of a Probabilistic Attack Planner 94", "text": "Chapter 7 Probabilistic Attack Planning 95\n7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n7.2 The Attack Model . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n7.2.1 Deterministic Actions with Numerical Effects . . . . . . . . 98\n7.2.2 Actions\u2019 Costs . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n7.2.3 Probabilistic Actions . . . . . . . . . . . . . . . . . . . . . . 100\n7.3 The Choose Primitive . . . . . . . . . . . . . . . . . . . . . . . . . . 101\n7.4 The Combine Primitive . . . . . . . . . . . . . . . . . . . . . . . . . 103\n7.4.1 Predefined Strategies . . . . . . . . . . . . . . . . . . . . . . 103\n7.4.2 Multiple Groups of Actions . . . . . . . . . . . . . . . . . . 105\n7.5 Using the Primitives in an Attack Tree . . . . . . . . . . . . . . . . 107\n7.5.1 Constructing the Tree . . . . . . . . . . . . . . . . . . . . . 108\n7.6 The Graph of Distinguished Assets . . . . . . . . . . . . . . . . . . 109\n7.7 Our implementation . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n7.7.1 Testing and Performance . . . . . . . . . . . . . . . . . . . . 112\n7.8 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\n7.9 Summary and Future Work . . . . . . . . . . . . . . . . . . . . . . 115\nviii"}, {"heading": "III The Search for a Better Model 117", "text": "Chapter 8 The POMDP Model 118\n8.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 8.2 Comment on Penetration Testing . . . . . . . . . . . . . . . . . . . 121 8.3 Background on POMDPs . . . . . . . . . . . . . . . . . . . . . . . . 122\n8.3.1 Basic Definitions of MDPs . . . . . . . . . . . . . . . . . . . 123 8.3.2 Basic Definitions of POMDPs . . . . . . . . . . . . . . . . . 124 8.3.3 Reformulation as an MDP over B . . . . . . . . . . . . . . . 126 8.3.4 POMDP Solving Algorithms . . . . . . . . . . . . . . . . . . 127\n8.4 Modeling Penetration Testing with POMDPs . . . . . . . . . . . . . 129\n8.4.1 States . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 8.4.2 Actions & Observations . . . . . . . . . . . . . . . . . . . . 131 8.4.3 Rewards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 8.4.4 POMDP Model Generation . . . . . . . . . . . . . . . . . . 135\n8.5 Solving Penetration Testing with POMDPs . . . . . . . . . . . . . . 137\n8.5.1 Setup of Experiments . . . . . . . . . . . . . . . . . . . . . . 137 8.5.2 Combined Scaling . . . . . . . . . . . . . . . . . . . . . . . . 138 8.5.3 The 2-Machines Case . . . . . . . . . . . . . . . . . . . . . . 140 8.5.4 POMDPs make Better Hackers . . . . . . . . . . . . . . . . 141\n8.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142\nChapter 9 Conclusions and Future Work 144\nBibliography 149\nix"}, {"heading": "Abstract", "text": "Penetration Testing (short pentesting) is a methodology for assessing network security, by generating and executing possible attacks exploiting known vulnerabilities of operating systems and applications. Doing so automatically allows for regular and systematic testing without a prohibitive amount of human labor, and makes pentesting more accessible to non-experts. A key question then is how to automatically generate the attacks.\nA natural way to address this issue is as an attack planning problem. In this thesis, we are concerned with the specific context of regular automated pentesting, and use the term \u201cattack planning\u201d in that sense. The following three research directions are investigated.\nFirst, we introduce a conceptual model of computer network attacks, based on an analysis of the penetration testing practices. We study how this attack model can be represented in the PDDL language. Then we describe an implementation that integrates a classical planner with a penetration testing tool. This allows us to automatically generate attack paths for pentesting scenarios, and to validate these attacks by executing the corresponding actions -including exploits- against the real target network. We also present another tool that we developed in order to effectively test the output of the planner: a simulation platform created to design and simulate cyber-attacks against large arbitrary target scenarios.\nSecondly, we present a custom probabilistic planner. In this part, we contribute a planning model that captures the uncertainty about the results of the actions, which is modeled as a probability of success of each action. We present efficient planning algorithms, specifically designed for this problem, that achieve industrialscale runtime performance (able to solve scenarios with several hundred hosts and exploits). Proofs are given that the solutions obtained are optimal under certain assumptions. These algorithms take into account the probability of success of the actions and their expected cost (for example in terms of execution time, or network traffic generated).\nFinally, we take a different direction: instead of trying to improve the efficiency\nx\nof the solutions developed, we focus on improving the model of the attacker. We model the attack planning problem in terms of partially observable Markov decision processes (POMDP). This grounds penetration testing in a well-researched formalism, highlighting important aspects of this problem\u2019s nature. POMDPs allow the modelling of information gathering as an integral part of the problem, thus providing for the first time a means to intelligently mix scanning actions with actual exploits.\nxi"}, {"heading": "Acknowledgements", "text": "First of all I want to thank Gerardo Richarte, with whom I invented the idea and the project of attack planning, and continued to work on its different instantiations; and who had the generosity of directing me in this special phase which is completing the Ph.D. thesis. I learned a lot working with him, but there is something that I want to highlight: Gera taught me what it means to deeply understand a problem, and to do frenetic research, the one that doesn\u2019t let you sleep.\nThanks to Emiliano Kargieman, who introduced me to the world of Hacking and Information Security, and who also created the conditions that allowed me to start the Ph.D. journey at ITBA. To Ariel Futoransky, with whom I shared countless talks and discussions around the white board. It is thanks to Futo that several ideas of this thesis and of all my other research projects took form.\nMy appreciation to Eduardo Bonelli. With his multidisciplinary interest and academic experience, he was able to put this thesis on track and guide it to its final port. To Roberto Perazzo and all the Ph.D. team at ITBA, who managed to create an environment of freedom and innovation, that I hope will continue to grow.\nThanks to Jo\u0308rg Hoffman and Olivier Buffet. Meeting Jo\u0308rg in Atlanta, and beginning a collaboration with both of you was definitely a big inflection point in my thesis, that put me in direct contact with the world of Artificial Intelligence and Planning. Thanks for receiving me at INRIA in Nancy, for sharing your knowledge and teaching me new ways of working (and also for the results obtained!)\nThanks to Hugo Scolnik, Marcelo Frias and Jo\u0308rg (again) for accepting to be\njury of my thesis, and for their reviews and comments.\nTo Jorge Lucangeli; the time that we worked together was very productive and enjoyable, I wish it would have last longer. To Luciano Notarfrancesco; brainstorming a few weeks with Luciano and Gera we produced more ideas than we\nxii\nwere able to implement in several years of work. To Aureliano Calvo, always willing to chat and discuss new ideas and algorithms. To Wata, Peter, Gutes, Fruss, Fercho, Jose and all the CoreLabs team. Thanks to you CoreLabs remained all these years a fruitful and motivating place.\nTo Dragos Ruiu, Rodrigo Branco, Philippe Langlois, Jonathan Brossard, Matthieu\nSuiche and all the hackers\u2019 community, for providing great spaces to present and discuss research ideas (and also of course to make new friends and have a great time!)\nTo James Foster, who patiently revised and corrected all my papers and pre-\nsentations.\nTo my professor Adria\u0301n Paenza, for inspiring me to be a better person, and\nkeeping alive the flame of Mathematics (in me and so many others!)\nTo my father Reynaldo, with his passion and enthusiasm he transmitted me the love for reading, writing, studying, debating, discussing... as a worker and activist, he taught me to appreciate hard work, critical and scientific thinking, and guided me to follow a path that gives me today so many satisfactions.\nTo my mother Yuriko, my sister Clara and my brother Sebas, who always accompany me with their support and affection, and open my head to new worlds.\nTo Nela, Leo\u0301n and Leia, my infinite sources of Love and happiness.\nxiii\nChapter 1"}, {"heading": "Introduction", "text": ""}, {"heading": "1.1 Overview of the Thesis", "text": "Penetration Testing (short pentesting) is a methodology for assessing network security, by generating and executing possible attacks exploiting known vulnerabilities of operating systems and applications (the necessary background is given in Chapter 2). Doing so automatically allows for regular and systematic testing without a prohibitive amount of human labor, and makes pentesting more accessible to non-experts. A key question then is how to automatically generate the attacks.\nA natural way to address this issue is as an attack planning problem. In this thesis, we are concerned with the specific context of regular automated pentesting, as in Core Security\u2019s \u201cCore Insight Enterprise\u201d tool. We will use the term \u201cattack planning\u201d in that sense.\nThe main body of this thesis is divided in three parts.\nPart I In the first part we present the basic model and a complete implementation\nthat integrates a planner system with a penetration testing framework and a network simulation tool.\nChapter 3 introduces a conceptual model of computer network attacks. This model is based on an analysis of the penetration testing practices, and of the functionality provided by pentesting frameworks. This model gives a new perspective for viewing cyberwarfare scenarios, by introducing conceptual tools to evaluate the costs of an attack, to describe the theater of operations, targets, missions, actions, plans and assets involved in cyberwarfare attacks.\nWe then present in Chapter 4 how this attack model can be represented in the PDDL language. To define with precision this representation, we start\n1\n2 with simpler representations based on set theory in Section 4.2.1 and on first order logic in Section 4.2.2.\nChapter 5 describes an implementation that integrates a classical planner with a penetration testing tool. This allows us to automatically generate attack paths for pentesting scenarios, and to validate these attacks by executing the corresponding actions -including exploits- against the real target network. We present an algorithm for transforming the information present in the pentesting tool to the planning domain in Section 5.2, and we show how the scalability issues of attack graphs can be solved using current planners. In Section 5.3 we make an analysis of the performance of our solution, showing how the model scales to medium-sized networks and the number of actions available in current pentesting tools.\nFinally, we present another tool that we developed in order to effectively test the output of the planner. Chapter 6 is devoted to a simulation platform created to design and simulate cyber-attacks against large arbitrary target scenarios. This simulator has surprisingly low hardware and configuration requirements, while making the simulation a realistic experience from the attacker\u2019s standpoint. The scenarios include a crowd of simulated actors: network devices, hardware devices, software applications, protocols, users, etc. A novel characteristic of this tool is to simulate vulnerabilities (including 0-days) and exploits, allowing an attacker to compromise machines and use them as pivoting stones to continue the attack. A user can test and modify complex scenarios, with several interconnected networks, where the attacker has no initial connectivity with the objective of the attack.\nChapters 4 and 5 are based on work done with Gerardo Richarte and Jorge Lucangeli, which has been published in the SecArt workshop at the AAAI conference [LSR10] and presented in the Hackito Ergo Sum conference [Sar10]. Chapter 6 is based on joint work with Ariel Futoransky, Fernando Miranda and Jose\u0301 Orlicki, and was published in the SIMUTools conference [FMOS09].\nPart II The second part of the thesis describes the development of a custom\nprobabilistic planner. In Chapter 7 we contribute a planning model that captures the uncertainty about the results of the actions, which is modeled\n3 as a probability of success of each action. We present efficient planning algorithms, specifically designed for this problem, that achieve industrialscale runtime performance (able to solve scenarios with several hundred hosts and exploits). These algorithms take into account the probability of success of the actions and their expected cost (for example in terms of execution time, or network traffic generated).\nOf course planning in the probabilistic setting is far more difficult than in the deterministic one. We do not propose a general algorithm, but a solution suited for the scenarios that need to be solved in a real-world penetration test. Two \u201cprimitives\u201d are presented, which are used as building blocks in a framework separating the overall problem into two levels of abstraction. The computational complexity of our planning solution is O(n log n), where n is the total number of actions in the case of an attack tree (with fixed source and target hosts), and O(M2 \u00b7 n log n) where M is the number of machines in the case of a network scenario. We discuss experimental results obtained with our implementation. For example, we were able to solve planning in scenarios with up to 1000 hosts distributed in different networks.\nThe work reported in this part was presented at the FRHACK conference [Sar09a] and the H2HC conference [Sar09b]. It was published in the ACM Workshop on Artificial Intelligence and Security [SRL11] (joint work with Gerardo Richarte and Jorge Lucangeli). A discussion on the exploits\u2019 costs was given at the 8.8 Security Conference [Sar11a].\nPart III The third part takes a different direction: instead of trying to improve\nthe efficiency of the solutions developed, we focus on improving the model of the attacker, thus formulating the problems that we think will have to be solved in the longer term.\nThe approach of Chapter 5 used classical planning and hence ignores all the incomplete knowledge that characterizes hacking. The more recent approach of Chapter 7 makes strong independence assumptions for the sake of scaling. In Chapter 8, we take the opposite extreme of the trade-off between accuracy and performance. We tackle the problem in full, in particular addressing information gathering as an integral part of the attack. We achieve this by modeling the problem in terms of partially observable\n4 Markov decision processes (POMDP). This grounds penetration testing in a well-researched formalism, highlighting important aspects of this problem\u2019s nature. POMDPs allow us to model information gathering as an integral part of the problem, thus providing for the first time a means to intelligently mix scanning actions with actual exploits.\nAs a side effect, this modeling activity serves to clarify some important aspects of this problem\u2019s nature. A basic insight is that, whereas in Chapter 7 we model the uncertainty as non-deterministic actions\u2014success probabilities of exploits\u2014this uncertainty is more naturally modeled as an uncertainty about states (in Chapter 8). The exploits as such are deterministic in that their outcome is fully determined by the system configuration. Once this basic modeling choice is made, all the rest falls into place naturally.\nOur experiments are based on a problem generator that is not industrial-scale realistic, but that allows us to create reasonable test instances by scaling the number of machines, the number of possible exploits, and the time elapsed since the last activity of the pentesting tool. Unsurprisingly, we find that POMDP solvers do not scale to large networks. However, scaling is reasonable for individual pairs of machines. As argued in Section 7.6, such pairwise strategies can serve as the basic building blocks in a framework decomposing the overall problem into two abstraction levels.\nThe material of Chapter 8 is joint work with Jo\u0308rg Hoffmann and Olivier Buffet, and has been published in the SecArt workshop at IJCAI [SBH11]. A discussion of the different directions taken in our attack planning research was given in the H2HC conference [Sar11b]."}, {"heading": "1.2 The Confluence", "text": "The work of this thesis was performed while I was working as a researcher in CoreLabs, the research center of a company that produces software for penetration testing. This is an important part of the context, since it explains the original motivation, the original questions that we tried to answer with Gerardo Richarte: We have this penetration testing tool, how can we make it easier to use? How can we make it more autonomous? How can we put more expert knowledge in the software, so it requires less expertise from the user?\n5 The work started with a strong foothold in the world of industry, and thanks to my co-supervisor Eduardo Bonelli it also gained a foothold in the academic world. For the solutions that we devised, we also asked ourselves: Has this problem already been studied? How do our solutions compare to the ones found by other researchers? What are the state-of-the-art tools that we could use? How can we assure that the solutions that we find are optimal (or at least good)?\nThis way, the natural flow of the research led us to work in what I like to think of as the confluence of Industry and Academics. Answering questions that come from real-world applications, and in the process generating ideas and formulating models that have an academic interest. In my limited experience, I saw that the worlds of Industry and Academics are often disjointed, and that there is a lot to gain by building bridges between both worlds.\nThis work is also placed in another confluence: the problems that we try to solve come from the field of Information Security, and the tools used to provide answers come mainly from the field of Artificial Intelligence. Being at this intersection also opened up the way to a very interesting experience: a collaboration with Jo\u0308rg Hoffman and Olivier Buffet, recognized experts in the field of Automated Planning, experienced researchers and great persons from whom I learned a lot. And fortunately we were not alone at this intersection: the workshops SecArt (on Intelligent Security) and AISec (on Artificial Intelligence and Security) provided a great environment to present and discuss some of the results that we obtained. Another confluence where fruitful bridges are being built.\n6\nChapter 2"}, {"heading": "Background on Penetration", "text": ""}, {"heading": "Testing", "text": "In this preliminary chapter, we give a brief background on computer network intrusions and penetration testing frameworks. The study of these tools, and the need to automate their functionality, provides the basis for the work of this thesis."}, {"heading": "2.1 Computer Network Intrusions", "text": "During a network intrusion, an attacker tries to gain access to software systems that require authorization (web servers, database servers, accounting systems). The intrusion may be illegal (this is what people usually have in mind when speaking about intrusions), or may be an authorized audit performed by security professionals. The latter is called a network penetration test, of which we give a definition below.\nDefinition 2.1. A penetration test, also called pentest, is a method of evaluating the security of a computer system or network by performing a controlled attack. The process involves an active analysis of the system for any potential vulnerabilities that could result from poor or improper system configuration, both known and unknown hardware or software flaws, or operational weaknesses in process or technical countermeasures. This analysis is carried out from the position of a potential attacker and involves active exploitation of security vulnerabilities.\nAs networks evolve, and combine a multitude of interconnected technologies, the penetration test has become an accepted practice to evaluate the global security of a network (ultimately assessing effectiveness of the deployed security countermeasures). The interesting point for us is that pentesters basically use the\n7\nsame tools and methodologies as unauthorized attackers, so we can focus on the former (whose practices are also more documented!)"}, {"heading": "2.2 On Vulnerabilities and Exploits", "text": ""}, {"heading": "2.2.1 Basic Definitions", "text": "Definition 2.2. A vulnerability (noun) is a flaw in a system that, if leveraged by an attacker, can potentially impact the security of said system. Also called a security bug, security flaw, or security hole [Arc05]. It may also be an intentional feature \u2013 in this case it is called a backdoor.\nDefinition 2.3. To exploit (verb) is to use or manipulate to one\u2019s advantage a security vulnerability.\nDefinition 2.4. An exploit (noun) is a piece of software, a chunk of data, or sequence of commands that take advantage of a bug or vulnerability in order to cause unintended or unanticipated behavior to occur on a computer software,\n9\nhardware, or electronic device. This frequently includes such things as gaining control of a computer system or allowing privilege escalation or a denial of service attack."}, {"heading": "2.2.2 Anatomy of an Exploit", "text": "The exploits are the most important actions during an attack. According to the literal meaning of \u201cexploit\u201d, it takes advantage and makes use of a hidden functionality. When used for actual network attacks, exploits execute code that can alter, destroy or expose information assets. When examining an exploit, three main components can be distinguished.\nAttack Vector\nThe attack vector is the mechanism the exploit uses to make a vulnerability manifest, in other words, how to reach and trigger the bug. For example, in the case of Apache Chunked Encoding Exploit, the attack vector is the TCP connectivity\n10\nthat must be established on port 80 to reach the application. In a client-side attack, the attack vector might be an email sent to a user, with a specially crafted attachment that will trigger a vulnerability in the application used to open it.\nExploited Vulnerability\nTo obtain an unauthorized result, the exploit makes use of a vulnerability. This can be a network configuration vulnerability, or a software vulnerability: a design flaw or an implementation flaw (buffer overflow, format string, race condition).\nThe most classic example is the buffer overflow, first described in \u201cSmashing the stack for fun and profit\u201d by Aleph One [One96]. The questions for the attacker are: how to insert code and how to modify the execution flow to execute it? In the example of a stack based buffer overflow, the code is inserted in a stack buffer and by overflowing the buffer, the attacker can overwrite the return address and jump to his code."}, {"heading": "Payload", "text": "Once the attacker manages to trigger and exploit a security flaw, he gains control of the vulnerable program. The payload is the functional component of the exploit, the code the attacker is interested in running. Classic payloads allow attackers to:\n\u2022 Add a user account: on Unix systems, it was done by adding a line to the system password file (/etc/password) or changing the password of root.\nHowever such changes are easily detected and to use the account the attacker needs connectivity through legitimate paths (firewalls can block them). This classic payload is no longer used.\n\u2022 Make changes to system configuration: for example, to add a line to inetd (Internet services daemon), to open a port and later connect to the system\nvia the newly opened port.\n\u2022 Open a shell: the payload consists of opening a shell (a command interpreter), that the attacker can use to execute available commands. These\npayloads are more difficult to detect, but are also more difficult to write.\n11\nSee the article of Aleph One [One96] for a report of this technique. Commonly known as shellcode, this was the most popular payload, until the development of exploitation frameworks such as Metasploit and Core Impact provided more generic techniques, as we discuss in the next section.\nWriting payloads is a very difficult task, that requires solving multiple restrictions simultaneously. The payload is a sequence of byte codes, so each payload will only work on a specific operating system and on a specific platform. Depending on the attack vector, the payload may be sent to the vulnerable machine as an ASCII string (or some protocol field), and thus must respect a particular grammar (examples: byte 0 is forbidden, only 7-bit ASCII is accepted, only alphanumeric characters are accepted, etc.) Libraries have been developed to help exploit writers to generate shellcodes. MOSDEF and InlineEgg are two well known cases, with tools to cope with the restrictions. The payload is also typically limited in size (for example the buffer size in the case of a buffer overflow), so the code that the attacker will run must fit in a few hundred bytes. If he wants to execute more complex applications, he must find another way..."}, {"heading": "2.2.3 Syscall Proxy Agents", "text": "We present here a solution to the limitations of payload development described in the previous section. It is called \u201csyscall proxy\u201d and was developed by Caceres et al. (see [Cac02] for more details). The idea is to build a sort of \u201cuniversal payload\u201d that allows an attacker to execute any system call on the vulnerable host. By installing a small payload (a thin syscall server), the attacker will be able to execute complex applications on his local host (a fat client), with all system calls executed remotely."}, {"heading": "Background on Syscalls", "text": "An application usually interacts with certain resources: a file on a disk, the screen, a networking card, a printer, etc. Applications can access these resources through system calls (syscalls for short). These syscalls are operating system services, usually identified with the lowest layer of communication between a user mode process and the OS kernel.\n12\nDifferent operating systems implement syscall services differently, sometimes depending on the processor\u2019s architecture. The main groups are UNIX and Windows.\nUNIX systems use a generic and homogeneous mechanism for calling system services, usually in the form of a \u201csoftware interrupt\u201d. Syscalls are classified by number and arguments are passed either through the stack, registers or a mix of both. The number of system services is usually kept to a minimum (about 380 syscalls are found in a Linux with kernel version 3.01), as more complex functionality is provided on higher user-level functions.\nWindows also provides system calls. However, for the sake of simplicity and generality, the authors of syscall proxy decided to use \u201cWindows syscalls\u201d to refer to any function in any dynamic library available to a user mode process [Cac02]."}, {"heading": "Syscall Proxy", "text": "The resources that a process can access, and the kind of access it has to them, define the \u201ccontext\u201d in which it is executed. For example, a process that reads data from a file might do so using the open, read and close syscalls.\nSyscall proxying inserts two additional layers between the process and the underlying operating system. These layers are the syscall client layer and the syscall server layer.\n1Updated as of June 2012.\n13\nSyscall client (on local system). The syscall client layer acts as a link between\nthe running process and the underlying system services. This layer is responsible for forwarding each syscall argument and generating a proper request that the syscall server can understand. It is also responsible for sending this request to the syscall server, usually through the Internet, and returning back the results to the calling process.\nSyscall server (on remote system). The syscall server layer receives requests\nfrom the syscall client to execute specific syscalls using the underlying operating system services. This layer marshals back the syscall arguments from the request in a way that the underlying OS can understand and calls the specific service. After the syscall finishes, its results are marshalled2 and sent back to the client, again through the Internet.\nDefinition 2.5. In the context of this chapter, we will refer to a syscall server on a remote system as an agent.\nIn conclusion, the syscall proxy technology gives the attacker the possibility of executing his tools on a compromised machine, without the need of actually copying all those tools on the target machine. This makes the process of installing a base camp cleaner and simpler. This technology is implemented within the agents of \u201cCore Impact Pro\u201d and \u201cCore Insight Enterprise\u201d, and allows the attacker to perform transparent pivoting on compromised machines (see Section 2.3.5).\nAs a final remark, there are multiple connection methods between agents. The originating agent can use: connect to target (similar to bindshell), connect from target (similar to reverse shell), reuse connection and HTTP tunneling. Agents can also be chained together to reach network resources with limited connectivity."}, {"heading": "2.3 Main Steps of an Attack", "text": "Traditionally, the pentesting process is divided in steps, and an attack will follow the pattern of steps that we describe below. Of course, this division in steps is arbitrary, and corresponds to an accepted practice in the field (refer to [AM04,\n2In computer science, marshalling is the process of transforming the memory representation of an object to a data format suitable for storage or transmission. It is typically used when data must be moved between different parts of a computer program or from one program to another.\n14\nAR03, Ric03]). We will show in subsequent chapters that this methodology can be improved by using planning techniques before executing the attack \u2013 and whose output may be to mix actions from different steps in order to run a faster or more reliable attack."}, {"heading": "2.3.1 Information Gathering", "text": "A successful attack depends on the ability to gather relevant information about the target network, including active IP addresses, operating systems and available services. This step is called information gathering in the context of pentesting. It is also called reconnaissance in the military context, and be considered as part of the OODA loop3 or Boyd cycle (refer to [Boy87, Hig90]).\nActions realized during this phase include:\n\u2022 Network discovery: performed using mechanisms such as ARP, TCP SYN packets, ICMP echo request, TCP connect and passive discovery.\n\u2022 Port scanning: an exhaustive scan of open and closed ports of all the network hosts.\n\u2022 OS identification: consists of recognizing the OS of a remote host by analyzing its responses to a set of tests. Classical Nmap\u2019s fingerprinting database\ncan be combined with a neural network to accurately match OS responses to signatures, see [BS06]. Additional OS identification capabilities are available for more specific situations. For instance, OS detection utilizing the DCERPC and SMB protocols can identify Windows machines more precisely.\n\u2022 Other techniques available to human attackers are social engineering and Google hacking (using publicly available information to gain insight into the\ntarget organization). Although these techniques are difficult (or impossible) to automate, they can nevertheless be included in the planning phase \u2013 eventually the execution of the resulting plan will require the intervention of a human attacker to carry out that action.\n3OODA stands for Observe, Orient, Decide, Act.\n15"}, {"heading": "2.3.2 Attack and Penetrate", "text": "During this phase, the attacker selects and launches remote exploits making use of data obtained in the Information Gathering step. According to the definition given in Section 2.2.1, an exploit is a piece of software that injects code into the vulnerable system\u2019s memory and modifies the execution flow to make the system run the exploit code. As discussed in Section 2.2.3, the exploit can be thought of as a way to install an agent on a compromised host."}, {"heading": "2.3.3 Local Information Gathering", "text": "The Local Information Gathering step collects information about computers that the attacker has successfully compromised. During this phase, the attacker may gather information about the OS, network configuration, users and installed applications; browse the filesystem on compromised systems; view rights obtained and interact with compromised systems via shells and other applications (for example, a remote desktop application)."}, {"heading": "2.3.4 Privilege Escalation", "text": "During the Privilege Escalation phase, the attacker attempts to penetrate deeper into a compromised computer by running local exploits in an attempt to obtain administrative privileges."}, {"heading": "2.3.5 Pivoting", "text": "After Privilege Escalation, the attacker can use the newly controlled host as a vantage point from which to run attacks deeper into the network (i.e. by making use of the syscall proxy agents technology presented in Section 2.2.3). By sending instructions to an installed agent, the attacker can run local exploits to attack systems internally, rather than from across the network. He can view the networks to which a compromised computer is connected, and launch attacks from any compromised system to other computers on the same network, gaining access to systems with increasing levels of security. That is, the attacker executes the previous steps (Information Gathering and Attacking) using the new agent as source.\n16"}, {"heading": "2.3.6 Clean Up", "text": "The attacker needs to erase his footprints in order to avoid detection. Towards this end, all the executed actions should minimize the produced noise, for example by making modifications only in memory and by the avoidance of writing files in the target\u2019s filesystem."}, {"heading": "2.4 The Need for Automation", "text": "To conclude this background on penetration testing, we have to speak about a new kind of information security tool, whose development started in 2001: the penetration testing frameworks. This type of tool facilitates the work of network penetration testers, and make the assessment of network security more accessible to non-experts. The main tools available are:\n\u2022 Core Impact (since 2001)\n\u2022 Immunity Canvas (since 2002)\n17\n\u2022 Metasploit (open source project that started in 2003, owned by Rapid7 since 2009)\nThe book [BKB+07] provides a survey of computer security tools, and in particular of penetration testing tools.\nThe main difference between these tools and network security scanners such as Nessus, Qualys Guard or Retina is that pentesting frameworks have the ability to launch real exploits for vulnerabilities, helping to expose risk by conducting an attack in the same way a real external attacker would [AM04].\nAs pentesting tools have evolved and have become more complex, covering new attack vectors, and shipping increasing numbers of exploits and information gathering modules, the problem of controlling the pentesting framework successfully has become an important question. We detail below the main reasons:\n\u2022 A computer-generated plan for an attack would isolate the user from the complexity of selecting suitable exploits for the hosts in the target network.\n\u2022 A suitable model to represent these attacks would help to systematize the knowledge gained during manual penetration tests performed by expert\nusers, making pentesting frameworks more accessible to non-experts.\n\u2022 The possibility of incorporating the attack planning phase into the pentesting framework would allow for optimizations based on exploit running time,\nreliability, or impact on Intrusion Detection Systems.\n\u2022 Finally, automated attacks allow the user to perform reproducible tests, which open the path to computing security metrics whose evolution would\nbe a key indicator of the security posture of the organization.\nPart I"}, {"heading": "Integrating a Pentesting Tool", "text": "with Classical Planners\n18\nChapter 3"}, {"heading": "Conceptual Model of Network", "text": ""}, {"heading": "Attacks", "text": "In the first Part of this thesis, we present the basic model of penetration testing, and a complete implementation that integrates a planner system with a penetration testing framework and a network simulation tool."}, {"heading": "3.1 Introduction", "text": "Our work on the attack planning problem applied to pentesting began in 2003 with the construction of a conceptual model of an attack, distinguishing assets, actions and goals [FNRS03, Ric03, AR03]. In this attack model, the assets represent both information and the modifications in the network that an attacker may need to obtain during an intrusion, whereas the actions are the basic steps of an attack, such as running a particular exploit against a target host. This model was designed to be realistic from an attacker\u2019s point of view, and contemplates the fact that the attacker has an initial incomplete knowledge of the network, and therefore information gathering should be considered as part of the attack.\nThis model also has a theoretical value: \u201cwe understand what we can build.\u201d Our motivation was to provide the Information Security community with a deeper and more detailed model of the attacks against computer networks. It turned out that having such a model is also necessary to communicate with other communities, such as the Artificial Intelligence and Planning ones.\nThe main application of this model is to provide a basis for autonomous attack planning, in particular for automating penetration tests. The description that we give in this chapter is still informal, and lacks the level of precision required to\n19\n20\ninteract with planning tools. In Chapter 4 we give a precise description of how these ideas can be represented in the PDDL language. In Chapter 5 we present a deterministic version of the problem, and use deterministic planning techniques to solve it. In Chapter 7 we present a probabilistic version, and algorithms to solve planning in the probabilistic setting. Chapter 8 presents a version of the attack planning problem with uncertainty about the target network, formulated in the theoretical framework of POMDPs.\nAnother important application of the model is attack simulations, which can be used by a system administrator to simulate attacks against his network, evaluate the vulnerabilities of the network and determine which countermeasures will make it safe. We present a network simulator based on these ideas in Chapter 6.\nIn the rest of this chapter we describe the components of our model \u2013 proba-\nbilistic assets, quantified goals, agents and actions \u2013 and their relations."}, {"heading": "3.2 Assets", "text": "Definition 3.1. An asset can represent anything that an attacker may need to obtain during the course of an attack. In particular it can represent the knowledge that an agent has of a real object or property of the network.\nWe describe below some examples of assets (and their parameters):\nAgentAsset (agent, capabilities, host). An AgentAsset represents an agent\nwith a collection of capabilities running on a host.\nBannerAsset (banner, host, port). A BannerAsset represents the banner that\nan agent obtains when trying to connect to a certain port on a host.\nOperatingSystemAsset (os, host). An OperatingSystemAsset represents the\nknowledge that an agent has about the operating system of a host."}, {"heading": "IPConnectivityAsset (source, target).", "text": "TCPConnectivityAsset (source, target, port). A TCPConnectivityAsset rep-\nresents the fact that an agent is able to establish a TCP connection between a source host and a certain port of a target host.\nIn the PDDL language, assets will be represented as predicates (see Section 4.3\nfor the details of the PDDL representation).\n21"}, {"heading": "3.2.1 Representations and Assumptions", "text": "In Chapters 4, 7 and 8, we will describe different representations of this general model. Different assumptions can be made about the model components in order to make different trade-offs between the complexity of the resulting planning problem and the realism of the model.\nIn the simpler case, the assets are deterministic, and can be translated as\npropositions. However this assumption can be relaxed with:"}, {"heading": "Probabilistic Assets", "text": "The assets can be probabilistic. This allows us to represent properties which the attacker guesses are true with a certain probability or negative properties (which the attacker knows to be false). This idea is further explored in Chapters 7 and 8.\nFor example, an action which determines the operating system of a host using banners (OSDetectByBannerGrabber) may give as result an OperatingSystemAsset os=linux with probability=0.8 and a second one with os=openbsd and probability=0.2. Another example, an ApplicationAsset host=192.168.13.1 and application=#Apache with probability=0 means that our agent has determined that this host is not running Apache."}, {"heading": "Level of Trust", "text": "We can allocate a certain level of trust to the information that a certain asset represents. When an action returns an asset, we may trust this information, but then trust diminishes with time. An interesting questions is how to estimate that decrease.\nProblem 3.2. Calculate the decrease of the level of trust for each asset, as a function of time.\nWhen we first considered this problem, we had no clue on how to solve it. Several years later, we eventually arrived (with Hoffman and Buffet) to the POMDP model, wherein this question can be precisely formulated. In the POMDP formulation (studied in Chapter 8), the attacker does not observe directly the state of the target network, but rather observes a probability distribution over the states of the system, which is called a belief state (see definition 8.11). The problem of\n22\nhow to estimate the initial belief state (and thus to provide an answer to Problem 3.2) is considered in Section 8.4.4."}, {"heading": "3.2.2 The Environment Knowledge", "text": "The environment knowledge is a collection of information about the computer network being attacked or hosting an agent. Naturally, this information is represented by assets (or predicates in the PDDL language). By abuse of language, we may speak of the environment instead of the environment knowledge. At the beginning of an attack, the environment contains at least an AgentAsset: the localAgent which will initiate the attack.\nThe environment will play an important role during the planning phase and during the execution phase of an attack, since it continuously feeds back the behavior of the agent. Note also that each agent has its own environment knowledge and that exchanging assets would be an important part of the communications between autonomous agents.\nAs we will discuss in Section 4.3, the input for a planner is divided in two files: the domain file which contains the PDDL representation of the attack model (in particular, the actions that are available to the attacker); and the problem file which is a collection of predicates about the initial state of the target system. The environment knowledge is thus translated as the problem file in the PDDL representation. It also corresponds to the initial state s0 \u2208 S in the Definition 4.6 of a planning problem."}, {"heading": "3.3 Goals", "text": "A goal represents a question or a request of the type: \u201ccomplete this asset\u201d (every goal has an associated asset). A goal can be quantified, and can be associated with a list of actions which may complete his asset. In the Definition 4.6 of a planning problem, the goals are represented of a set of states Sg \u2286 S. Although the goals can be enumerated explicitely, in the earlier steps of our research we found it more convenient to consider quantifiers to simplify the representation.\n23"}, {"heading": "3.3.1 Goal Quantifiers", "text": "We considered three types of quantifiers: Any, All and AllPossible. An example will clarify their meaning: consider that PortAsset has attributes (host, port, status). The following goals will mean:\nasset = PortAsset (host=192.168.13.1, status=#open),\nquantifiers = (Any #port from:1 to:1024): find an open port in host 192.168.13.1 between ports 1 and 1024. To fulfill this goal, an action like PortScan will begin examining the ports of host 192.168.13.1 until it finds an open port (completes the PortAsset and returns a success signal) - or reaches port 1024 (and returns a failure signal).\nasset = PortAsset (host=192.168.13.1, status=#open),\nquantifiers = (All #port from:#(21,22,23,80)): find whether all the ports #(21,22,23,80) are open in host 192.168.13.1. This time, PortScan will examine the four mentioned ports and return success only if the four of them are open (and in that case completes four PortAssets).\nasset = AgentAsset (capabilities=#(TCP,UDP,FileSystem)),\nquantifiers = (AllPossible #host from:192.168.1.0/24): install agents in all the hosts that you can in netblock 192.168.1.0/24. An action able to fulfill this goal will be a subclass of Exploit (for example ApacheChunkedEncodingExploit). To fulfill this goal, the Exploit action will try to exploit a vulnerability in all the machines it reaches in that netblock. It returns an AgentAsset for each compromised host, and returns success if at least one machine is compromised."}, {"heading": "3.4 Actions", "text": "These are the basic steps which form an attack. Examples of actions are: Apache Chunked Encoding Exploit, WuFTPglobbing Exploit, Banner Graber, OS Detect By Banner, OS Fingerprint, Network Discovery, IP Connect, TCP Connect. In this section we review the principal attributes of an action.\n24"}, {"heading": "3.4.1 Action Goal", "text": "An action has a goal: when executed successfully the action completes the asset associated with its goal. It is also common to speak about the result of an action (for example to increase access, obtain information, corrupt information, gain use of resources, denial of service).\nIn Chapter 4 we will formalize the notion of actions. In particular, in Definition 4.8, we will consider a set of actions A and for each action a \u2208 A the effects of a. Conceptually, with the idea of action goal, we are only taking into account the expected result of the action. Undesired results and other side effects fall into the category of noise (see Section 3.4.4). In the formalization of Chapter 4, the expected result and undesired results will be collectively considered as the effects of the action."}, {"heading": "3.4.2 Action Requirements", "text": "The requirements of an action are assets that must have been obtained before the considered action can be executed. The requirements are the equivalent of children nodes in [Sch00] and subgoals in [MEL01] and [TLFH01].\nAn abstract action has thus the information on which assets it may satisfy and which assets it requires before running. These relationships will be used to construct the attack graph, by chaining actions and connecting them with the assets they require (see also Section 7.5.1 wherein a similar graph is constructed in the context of probabilistic planning).\nFigure 3.1 shows a sample attack graph, wherein the actions are depicted as red boxes and assets as blue ellipses. This is a layered graph, with alternating layers of actions and assets. The figure also illustrates the relation between the actions and their requirements.\nIn the formalization of Chapter 4, the requirements of an action a \u2208 A are defined as the preconditions precond(a). In the notations of Definition 4.8, an action a \u2208 A is applicable to a state s \u2208 S if precond(a) \u2286 s."}, {"heading": "3.4.3 The Execution Phase (or the Action Itself)", "text": "The information about the results and requirements of the actions is used during a planning phase to obtain an attack plan \u03c0 (see Definition 4.11). Once the attack\n25\nplan is obtained, it is used to control a penetration testing framework, wherein the actions of the plan \u03c0 are effectively executed on the target network. During this execution phase, the actual code of the actions (e.g. the code of the exploits or information gathering modules) is executed by the agent.\nOne interesting point to mention here, is that the action can be executed in a real network or in a simulated network (with simulated hosts and network topology). The difference between working in those two settings will be noticeable only during the execution phase. This makes our framework easy to adapt for both real and simulated attacks. Chapter 6 will describe a network simulator specially crafted to provide realistic simulations of cyber-attacks."}, {"heading": "3.4.4 Noise Produced and Stealthiness", "text": "The execution of the action will produce noise. This noise can be network traffic, log lines in IDS, etc. Given a list as complete as possible of network sensors, we have to quantify the noise produced with respect to each of these sensors. The knowledge of the network configuration and which sensors are likely to be active,\n26\nwill allow us to calculate a global estimate of the noise produced by the action. We will come back to the issue of refining the actions\u2019 costs in Section 7.2.2 of Chapter 7, wherein we reformulate the present attack model in the context of probabilistic planning.\nWith respect to every network sensor, the noise produced can be classified into three categories: unremovable noise, noise that can be cleaned in case the action is successful (or another subsequent action is successful), noise that can be cleaned even in case of failure. So we can also estimate the noise remaining after cleanup. Of course, the stealthiness of an action will refer to the low level of noise produced."}, {"heading": "3.4.5 Running Time and Probability of Success", "text": "The expected running time and probability of success depend on the nature of the action, but also on the environment conditions, so their values must be updated every time the agent receives new information about the environment. These values are necessary to take decisions and choose a path in the graph of possible actions.\nTogether with the stealthiness, these values constitute the cost of the action and can be used to evaluate sequences of actions. This will be further discussed in Chapter 7 in the context of probabilistic planning.\nBecause of the uncertainties inherent in the execution environment, these values can be considered as dependend on the agent\u2019s belief about the target network (we will discuss that in the POMDP model of Chapter 8)."}, {"heading": "3.4.6 Exploited Vulnerability", "text": "The action, if aiming to obtain an unauthorized result, will exploit a vulnerability. The information about the exploited vulnerability is not needed by the attacking agent, but is useful for the classification and analysis of detected intrusions. This vulnerability can be:\n\u2022 software vulnerability: a design flaw or an implementation flaw (buffer overflow, format string, race condition).\n\u2022 network configuration vulnerability.\n27\n\u2022 trust relationship: this refers to higher level, non autonomous attack modules: hacking a software provider, getting an insider in a software provider,\ninserting backdoors in an open-source project."}, {"heading": "3.5 Agents", "text": "We can think of the actions as being the verbs in a sequence of sentences describing the attack. The agents will then be the subject of those verbs. Of course, an attack is always initiated by human attackers, but during the course of the attack, actions will typically be executed by software agents."}, {"heading": "3.5.1 Human Attackers", "text": "There are different types of attackers. They can be classified roughly as:\n\u2022 script kiddies, who attack more or less randomly using standard tools downloaded from the Internet;\n\u2022 hackers, who attack computers for challenge, status or research;\n\u2022 security auditors (pen testers), who evaluate the security of a network;\n\u2022 government agencies and criminal organizations, who possess access to the highest skill level and resources for performing attacks.\nThe way we model these different types of attackers is through the attack parameters: stealthiness, non traceability, expected running time, expected success; and a skill level given by the collection of actions available to the attacker. A script kiddie will not worry about stealthiness or non traceability. His attacks will have low expected success and require low skill level. On the other hand, a government agency will use maximum stealthiness, non traceability and skill level, with a high expected success. A security auditor will not worry about non traceability but may require stealthiness to carry out the penetration test.\nThere are a number of actions that will require a human agent to execute them, for example social engineering1. But it is important to include them in our model \u2013 for the sake of completeness, and also because they can be considered during the planning phase as part of an attack.\n1Note that social engineering could also be performed by an autonomous agent. An example of this would be a virus who relies on a suggestive title to be opened by the receiver.\n28"}, {"heading": "3.5.2 Software Agents", "text": "In general the execution of an action will require the execution of machine code and therefore involves a software agent A executing this code. This is a generalization of Definition 2.5, that refered to agents in the context of a penetration framework such as \u201cCore Impact\u201d.\nThe command of executing this action might come from the agent itself, from another software agent or from a human attacker: we will not distinguish between these cases but just say that the action was executed by the agent A. A software agent can take several forms: script, toolkit or other kinds of programs. Let us point out the autonomous agents who are able to take decisions and continue the attack without human intervention."}, {"heading": "3.5.3 Communication between Agents", "text": "This framework supports the interactions between agents, which collaborate to achieve the objective. The agents establish communication channels amongst themselves to exchange knowledge, gained information and missions to be executed. For example, each agent has a collection of actions. Agents can learn new actions and exchange actions with each other through the communication channels.\nThe communication between human attackers can take place through unlimited types of channels (direct interaction, telephone, email, chat, irc, written mail). We will not enter into details here. Examples of communication channels between software agents are POP3 and SMTP, HTTP/HTTPS, DNS, TCP, and covert channels like Loki."}, {"heading": "3.5.4 Agent Mission", "text": "We contemplate different types of organization between the agents. One scenario is given by a \u201croot agent\u201d who plans the attack and then gives the other agents orders (for executing actions), eventually creating new agents if necessary, and asks the agents for feedback about action results in order to decide further steps.\nAnother scenario is when the root agent delegates responsibilities to the other agents, giving them higher level missions. To fulfill the mission, the agent will have to do its own planning and communicate with other agents. This scenario\n29\nis likely to arise when stealthiness is a priority: communication is very expensive and it becomes necessary to rely on the agents to execute their missions without giving feedback (or the smallest amount of feedback, or delayed feedback because of intermittent communication channels)."}, {"heading": "3.6 Building an Attack", "text": "An attack involves a group of agents, executing a series of actions in order to fulfill a goal (or a set of goals). Notice that this goal can change during the course of the attack.\nThe target is the logical or physical entity which is the objective of the attack. Usually, the target is a computer or a computer network or some information hosted on a computer. The target can also change during the course of the attack. It is also possible that an attack has no specific target at all (for example, a script kiddie running a specific exploit against all the computers he reaches, until it succeeds).\nThe complete graph of all combinations of actions determines which goals we (as attackers) can reach. Considering the complete graph of possible actions, to build an attack will consist in finding a path to reach the objective (this implies in particular finding a path through the physical networks to reach the target)."}, {"heading": "3.6.1 Attack Parameters", "text": "We will try to find the best path to reach the objective, and to evaluate this we must take into account the attack parameters: non traceability, tolerated noise, expected success, execution time, zero-dayness. These parameters have initial values for the whole attack, but they can vary from agent to agent, for example an agent might create other agents with a different profile.\nNon traceability: refers to the ability to dissimulate the origin of the attack. We\ncould also call it \u201cdeniability\u201d. To achieve non traceability, special modules must be executed, who will insert intermediate agents (we call them \u201cpivots\u201d or stepping stones) between the originating agent and the agents executing the objective or partial objectives.\nTolerated noise: is the level of noise that we allow our agents to make. It can\n30\nvary from agent to agent, for example an agent executing a DNS spoofing module would benefit from other agents simultaneously executing a DNS flooding (and generating a high level of noise).\nExpected success: determines the priority which will be given to successfully\nexecuting the actions, over the other parameters. If set to the maximum value, the agent will try to execute the projected action, even though the noise generated might be higher than the tolerated noise level.\nExecution time: each agent will be given a limit of time to execute each action.\nThis is necessary to plan the attack, as it usually consists of a series of dependent steps.\nZero-dayness: specifies whether the agent is allowed to use zero-day exploits (a\nvaluable resource that should be used only for critical missions)."}, {"heading": "3.6.2 Evaluating Paths", "text": "A path is a sequence of actions (in a specific order and without branchings). To be able to choose between different paths, we have to evaluate the paths in terms of the attack parameters: the probability of success, the noise probably produced, the running time and the traceability.\nFor the probability of success, we consider the success of each action as independent of the previous ones, and that all the actions in the paths are necessary, so the probability of success of the path is the product of the probabilities of success of each action.\nFor the running time of the path, we consider three time estimations (minimum, average, maximum) that we have for each module and sum them to obtain the path\u2019s minimal, average and maximal running time.\nThe stealthiness of the path, that we define as the probability of not being discovered, diminishes with each executed action. As with the probability of success, we consider them independent and compute the stealthiness of the path as the product of the stealthiness of the actions.\nThe traceability is harder to estimate. It depends basically on the number of hops (or pivots or stepping stones) introduced, and this is how we compute it,\n31\nalthough each can contribute a different amount to the global \u201cnon traceability\u201d of the path of actions."}, {"heading": "3.7 Applications", "text": ""}, {"heading": "3.7.1 Attack Planning", "text": "This is the main application that we are considering in this thesis, and will be further studied in Chapters 4, 5, 7 and 8."}, {"heading": "3.7.2 Simulations and Analysis of Network Security", "text": "As we have mentioned in Section 3.4, our framework can be used to build attacks against a simulated network. Of course, the quality of this simulation will depend on how accurately we simulate the machines. Using VMwares we obtain a slow and accurate simulation, for faster simulations a tradeoff must be made between accuracy and speed.\nThe system administrator can simulate different types of attackers by using different attack parameters and different collections of available actions, and evaluate the response of his network to these attackers. For example, he can start with an attacker with a minimal portfolio of actions, and gradually add actions to the arsenal of his simulated attacker until there is a successful attack which goes undetected by the IDS. This will give him an indication of which attack actions he should defend his network against.\nAlso consider that the system administrator has a set of measures which make certain attack actions less effective (in our framework, a measure may reduce the probability of success of an attack action, or increase the noise it produces, for example by adding a new IDS). He can then use the simulation to see if his system becomes safe after all the measures are deployed, or to find a minimal set of measures which make his system safe.\nAs opposed to VMwares, rudimentary simulations of machines allow us to simulate a huge amount of machines. This can be used to investigate the dissemination of worms (considered as autonomous agents with a minimalist set of actions) in large networks. This is further studied in Chapter 6.\n32"}, {"heading": "3.8 Related Work", "text": ""}, {"heading": "3.8.1 Description of Security Incidents", "text": "In [HL98], Howard and Longstaff describe an incident taxonomy, which was the result of a project to establish a \u201ccommon language\u201d in the field of computer security. In [LJ97], Lindqvist and Jonsson also work on the classification of intrusions. We try to use the high-level terms proposed by Howard and Longstaff, in particular, the attributes: vulnerability, action, target, result and objective.\nOne common flaw of these classifications is that they exclusively adopt the point of view of the system owners or the intrusion detection sensors. But an attack is always composed of several steps, some of which may be invisible to the sensors. We will add to the attributes considered in [HL98] and [LJ97], some attributes which are relevant only to the attacker (or risk assessment team). Thus a first result of our framework will be a widening of the concepts used to describe security intrusions."}, {"heading": "3.8.2 Attack Models", "text": "In [Sch99] and [Sch00], Bruce Schneier proposes describing attacks against a system using \u201cattack trees\u201d, where each node requires the execution of children nodes, and the root node represents the goal of the attack. There are two types of nodes: OR nodes and AND nodes.\nIn [TLFH01] the authors propose an attack specification language, which extends the attack trees model. Each node has preconditions (system environment properties which facilitate the execution of the attack node), subgoals (these are the children nodes), and postconditions (changes in systems and environments). [MEL01] is also based on the attack trees model. The model is extended by attack patterns and attack profiles. These authors\u2019 objective is to provide a means for documenting intrusions. Their models are purely descriptive and doe not allow the construction or prediction of new attacks."}, {"heading": "3.8.3 Attack Graphs", "text": "Since the actions have requirements (preconditions) and results, given a goal, a graph of the actions/assets that lead to this goal can be constructed. This graph is\n33\nrelated to the attack graphs2 studied in [PS98, JNO05, NEJ+09] and many others. In [LI05] the authors reviewed past papers on attack graphs, and observed that the \u201cfirst major limitation of these studies is that most attack graph algorithms have only been able to generate attack graphs on small networks with fewer than 20 hosts\u201d. For example, Figure 3.2 shows an attack graph for a small network, comprising 14 hosts, taken from [NJ04]. This figure illustrates the fact that attack graphs become rapidly too complex to be represented in their integrity, whether visually or as a data structure in the computer\u2019s memory.\nIn [SPG98] and [JWS02] the authors propose using attack graphs to determine the security of networked systems. There are two main differences with our model. Firstly, the system they propose is an analysis system, which requires as input a great amount of information: a database of common attacks broken down into atomic steps, specific network configuration and topology information, and an attacker profile. Our model is a system for building attacks, starting with possibly zero information about the network, and gathering this information as the attack takes place. Secondly, the attack graph we construct for planning purposes differs from the attack graph of [SPG98] and [JWS02]. In particular, it has a smaller size, which allow us to effectively find a plan for real world instances of the problem.\n2Nodes in an attack graph identify a stage of the attack, while edges represent individual steps in the attack.\n34\nAdditionally we introduce several new dimensions to the graph, like quantified goals, probabilistic assets and a complex cost function."}, {"heading": "3.9 Summary", "text": "In this chapter we presented a conceptual model to evaluate the costs of an attack, to describe the theater of operations, targets, missions, actions, plans and assets involved in cybernetic attacks.\nA contribution of this model concerns the costs of the actions. We show that the cost is given by a tuple a values: not only the probability of success, but also the stealthiness (which depends on the noise produced), time consumed, non traceability and zero-dayness. The noise produced is particularly relevant, and when we first published these ideas, we had not seen it in other models3. These dimensions, considered as attack parameters, also allow us to model different types of attackers.\nThe most important application of this model is automated planning. Integrated in a tool like Core Impact, it leads the way to automated penetration testing. Used against simulated networks, it is a tool for evaluating the vulnerabilities of a network.\nWorking on this model has opened a lot of questions and directions for future work: how to estimate the probability of success and noise produced by an action, how to modify these values after an execution, how to combine the different dimensions of the cost in order to obtain a total order between costs, how to choose the agents who will execute the actions, when to create a new agent on a specific host, how to decide the profiles (or personalities) of the agents, the use of planning techniques, and the applications of the simulation scenario. It also led us to review current penetration testing practices and opened new dimensions for planning attacks and creating new tools.\n3More recent work does take the noise into account, for instance the paper [EKMM11] published at the SecArt workshop in 2011.\nChapter 4"}, {"heading": "Planning Representations", "text": "Along this thesis, we will develop several representations of the attack model that we informally presented in Chapter 3. To understand and formulate precisely the differences between those representations, we will consider them in the general model of state-transition systems and enunciate the assumptions that are relaxed in each case (in Section 4.1).\nAnother important point of this chapter is how the attack model of Chapter 3 can be represented in the PDDL language. To define with precision this representation, we start by recalling in Section 4.2 the simpler representations based on set theory and first order logic. We then provide in Section 4.3 a detailed description of the PDDL representation of the attack planning problem.\nWe conclude this chapter with two exercises concerning the expressivity of this\nrepresentation and the complexity of the corresponding planning problem."}, {"heading": "4.1 Basic Formalization", "text": "To formalize the attack model, we will use a general model of dynamic systems, the model of state-transition systems [GNT04]. We give below the basic definition, then give a list of common assumptions, and discuss how they can be relaxed to obtain different versions of the model."}, {"heading": "4.1.1 Formalization as a Dynamic System", "text": "Definition 4.1. In general, a state-transition system is a tuple \u03a3 = \u3008S,A, E , \u03b3\u3009 where:\n\u2022 S = {s1, s2, . . .} is a finite set of states;\n\u2022 A = {a1, a2, . . .} is a finite set of actions;\n35\n36\n\u2022 E = {e1, e2, . . .} is a finite set of events;\n\u2022 \u03b3 : S \u00d7A\u00d7 E \u2192 2S is a state-transition function.\nA state represents a \u201cstate of the world\u201d, which is the combined knowledge that the agents have of the environment (network topology, operating systems, running services, agents distribution, etc).\nActions are transitions that are controlled by the plan executor. If a \u2208 A is an action and \u03b3(s, a) 6= \u2205, the action a is applicable to state s.\nEvents are transitions that are contingent: instead of being controlled by the\nplan executor, they correspond to the internal dynamics of the system."}, {"heading": "4.1.2 General Assumptions", "text": "The following is a list of common assumptions made when modeling planning problems. These assumptions restrict the complexity of the problem."}, {"heading": "Assumption A1 (Fully Observable \u03a3).", "text": "The system \u03a3 is fully observable, the attacker has complete knowledge about the state of \u03a3."}, {"heading": "Assumption A2 (Deterministic \u03a3).", "text": "The system \u03a3 is deterministic. For every state s and every action a, |\u03b3(s, a)| \u2264 1. If an action is applicable to a state, its application brings a deterministic system to a single other state."}, {"heading": "Assumption A3 (Static \u03a3).", "text": "The system \u03a3 is static if the set of events E is empty. The system stays in the same state until the controller applies some action."}, {"heading": "Assumptions A4 (Restricted Goals).", "text": "The planner handles only restricted goals that are specified as an explicit goal state sg or set of goal states Sg. The objective is any sequence of state transitions that ends at one of the goal states. Extended goals such as states to be avoided and constraints on state trajectories or utility functions are nor handled under this assumption.\n37"}, {"heading": "Assumptions A5 (Sequential Plans).", "text": "A solution plan to a planning problem is a linearly ordered finite sequence of actions."}, {"heading": "Assumptions A6 (Implicit Time).", "text": "Actions and events have no duration. In state-transition systems time is not explicitly represented."}, {"heading": "Assumptions A7 (Offline Planning).", "text": "The planner is not concerned with any change that may occur in \u03a3 while it is planning."}, {"heading": "4.1.3 Extending the Model", "text": "Several models can be obtained by relaxing some of these restrictive assumptions. In the development of the thesis, we will make the following relaxations to obtain different versions of the model."}, {"heading": "Relaxing Assumption A1 (Fully Observable \u03a3).", "text": "If the system is partially observable, then the observation of \u03a3 will not fully disambiguate which state \u03a3 is in. For each observation o, ther may be more than one state s that produce the observation o. This situation will be studied with the model based on Partially Observable Markov Decision Processes (POMDP) in Chapter 8."}, {"heading": "Relaxing Assumption A2 (Deterministic \u03a3).", "text": "In a nondeterministic system, each action can lead to different possible states, so the planner may have to consider alternatives. Usually nondeterminism requires assumption A5 as well, because a plan must encode ways for dealing with alternatives. Nondeterministic systems will be studied in Chapter 7 about probabilistic algorithms and Chapter 8 about the POMDP model."}, {"heading": "Relaxing Assumption A4 (Restricted Goals).", "text": "Extended goals allow one to specify to the planner requirements not only about the final state, but also on the states traversed, for example critical states to be avoided, states that the system should go through, states it\n38\nshould stay in, and other constraints on its trajectories. Another possibility is to specify a utility function to be optimized. This is used in the POMDP model, wherein the objective of the planner is to maximize the expected reward."}, {"heading": "Relaxing Assumption A5 (Sequential Plans).", "text": "A plan may be a mathematical structure that can be richer than a simple sequence of actions. Relaxing assumption A5 is often required when other assumptions are relaxed, as we have seen in the case of nondeterministic systems (assumption A2). In the POMDP model, the output of the planner is a policy that specifies which action to execute for each belief state."}, {"heading": "Relaxing Assumption A6 (Implicit Time).", "text": "To handle time explicitly will require an extension of the model: in the PDDL model (Chapter 5) the execution time of an action a \u2208 A is specified as a numerical effect of a.\nIn the POMDP model (Chapter 8), the execution time of an action a is encoded in the reward function r(s, a)."}, {"heading": "4.1.4 Number of States", "text": "We give below some estimations of the size of the state space S in several examples.\nExample 4.2. To get a grasp on the number of states involved, let\u2019s begin with a very simple example. Let S be a scenario with M machines. Suppose that the only information that the attacker may obtain about each machine is its OS information. The only action that the attacker can execute with each machine, is to recognize its Operating System. That is, for each machine m, the attacker may have the OperatingSystemAsset for m or not. The number of states in this scenario is\n|S| = 2M .\nExample 4.3. To make the previous example slightly more realistic, suppose that for each machine, there are k bits of information that the attacker may obtain: the knowledge of the Operating System and of k \u2212 1 applications that may be running on that machine. The number of states is\n|S| = (2k)M\n39\nwhich is exponential on the number of machines.\nExample 4.4. Suppose now that the attacker can learn which Operating System version is running on a host, the applications running (and their versions), and the connectivity between machines. Let Os be the set of Operating Systems for each machine (including the \u201cunknown\u201d operating system), App the set of applications and Vs the possible versions of applications (to simplify, we suppose them to be uniform for all the applications). Then the number of states is\n|S| = (|Os| \u00d7 |Vs||App|)M \u00d7 2M\u00d7M .\nAs these examples show, representing explicitly all the states of a network, even in a simple scenario, becomes quickly unfeasible when the number M of machines grow. Implicit representations are needed, that will enable us to describe subsets of S in a way that can be easily searched. Another approach that enabled us to deal with the exponential growth of the number of states (as a function of M) was to decompose the problem into different levels of abstraction, and search for approximate solutions. We will present such ideas in Chapter 7 (used for a probabilistic planner) and in Chapter 8 (used for a planner based on POMDPs)."}, {"heading": "4.2 Classical Planning Representations", "text": "Classical planning, also called STRIPS planning, refers to planning in a restricted state-transition system. The importance of classical planning is given by the fact that several general purpose and efficient planners exist for this setting.\n40\nIn this sense, classical planners can be considered as the \u201chammers\u201d of planning, which are more suitable for real-world applications [Gef10].\nDefinition 4.5. A restricted state-transition system is one that meets the restrictive assumptions \u3008A1, . . . ,A7\u3009 given in Section 4.1.2. It is a deterministic, static, and fully observable state-transition system with restricted goals and implicit time. Such a system is denoted \u03a3 = \u3008S,A, \u03b3\u3009. Since the system is deterministic, if a is applicable to s then \u03b3(s, a) contains one state s\u2032. To simplify notations, we will say that \u03b3(s, a) = s\u2032 instead of \u03b3(s, a) = {s\u2032}. The transition function is thus noted as:\n\u03b3 : S \u00d7A \u2192 S\n\u03b3(s, a) = s\u2032 if a is applicable to sundefined otherwise Definition 4.6. A planning problem for a restricted state-transition system \u03a3 = \u3008S,A, \u03b3\u3009 is defined as a triple P = \u3008\u03a3, s0, Sg\u3009, where\n\u2022 s0 \u2208 S is the initial state,\n\u2022 Sg \u2286 S corresponds to a set of goal states.\nNote that the initial state s0 \u2208 S corresponds to what we called the \u201cenvironment knowledge\u201d of the attacker in Chapter 3.\nProblem 4.7. (Planning in the restricted model) Given \u03a3 = \u3008S,A, \u03b3\u3009, an initial state s0 and a set of goal states Sg, find a sequence of actions (a1, a2, . . . , ak) corresponding to a sequence of state transitions (s0, s1, . . . , sk) such that s1 = \u03b3(s0, a1), . . . , sk = \u03b3(sk\u22121, ak), and sk \u2208 Sg."}, {"heading": "4.2.1 Set-Theoretic Representation", "text": "The set-theoretic representation uses only a finite set of proposition symbols that represent propositions about the world. This representation is more concise and readable than enumerating all the states and transitions explicitly. It can be precisely formulated, and provides the foundation for the classical representation. We recall the basic definitions from [GNT04].\n41\nDefinition 4.8. Let L = {p1, . . . , pn} be a finite set of proposition symbols. A set-theoretic planning domain is a restricted state-transition system \u03a3 = \u3008S,A, \u03b3\u3009 such that:\n\u2022 S \u2286 2L, i.e, each state s is a subset of L. The state s tells us which propositions currently hold. If p \u2208 s, then p holds in the state of the world represented by s.\n\u2022 Each action a \u2208 A is a triple of subsets of L. We will write it as\na = (precond(a), effect\u2212(a), effect+(a))\n\u2022 The set precond(a) is called the preconditions of a.\n\u2022 The set effect\u2212(a) is called the delete effects of a, and the set effect+(a) is called the add effects of a. We require that effect\u2212(a) \u2229 effect+(a) = \u2205.\n\u2022 An action a \u2208 A is applicable to a state s \u2208 S if precond(a) \u2286 s.\n\u2022 For every s \u2208 S and action a applicable to s, the set (s \u2212 effect\u2212(a)) \u222a effect+(a) \u2208 S.\n\u2022 The state-transition function is\n\u03b3(s, a) = (s\u2212 effect \u2212(a)) \u222a effect+(a) if a is applicable to s\nundefined otherwise.\nNote that the effects of an action a \u2208 A (the add effects and delete effects) correspond to what we called the action goal (in Section 3.4.1) and the noise produced by the action (in Section 3.4.4). The preconditions of an action a correspond to the requirements of the action (as defined in Section 3.4.2).\nExample 4.9. This is a very small example involving only two hosts h1 and h2. The attacker can detect the operating system of these hosts, and install an agent if he has already detected the OS. He can also uninstall agents.\nL = { win-h1, linux-h2, agent-h1, agent-h2 } where win-h1 means that (the attacker detected that) host h1 is running windows;\nlinux-h2 means that host h2 is running linux;\n42\nagent-h1 means that host h1 has been compromised (agent installed); agent-h2 means that host h2 has been compromised.\nA = { detect-h1, detect-h2, install-h1, install-h2, uninstall-h1, uninstall-h2 } where:\ndetect-h1 = ( { }, { }, { win-h1 } ); detect-h2 = ( { }, { }, { linux-h2 } ); install-h1 = ( { win-h1 }, { }, { agent-h1 } ); install-h2 = ( { linux-h2 }, { }, { agent-h2 } ); uninstall-h1 = ( { agent-h1 }, { agent-h1 }, { } ); uninstall-h2 = ( { agent-h2 }, { agent-h2 }, { } ).\nS = {s0, . . . , s8} where: s0 = { }; s1 = { win-h1 }; s2 = { linux-h2 }; s3 = { win-h1, linux-h2 }; s4 = { win-h1, agent-h1 }; s5 = { linux-h2, agent-h2 }; s6 = { win-h1, linux-h2, agent-h1 }; s7 = { win-h1, linux-h2, agent-h2 }; s8 = { win-h1, linux-h2, agent-h1, agent-h2 }.\nDefinition 4.10. A set-theoretic planning problem is a triple P = \u3008\u03a3, s0, g\u3009 where:\n\u2022 s0 \u2208 S is the initial state.\n\u2022 g \u2286 L is a set of propositions called goal propositions that give the requirements that a state must satisfy to be a goal state. The set of goal states is\nSg = {s \u2208 S | g \u2286 s}.\nNote that the initial state s0 \u2208 S corresponds to what we called the \u201cenvironment knowledge\u201d of the attacker in Chapter 3.\nDefinition 4.11. A plan is any sequence of actions \u03c0 = \u3008a1, . . . , ak\u3009, where k \u2265 0. The length of the plan is |\u03c0| = k.\nThe state produced by applying \u03c0 to a state s is the state produced by applying the actions of \u03c0 in the given order. We extend the state-transition function as\n43\nfollows:\n\u03b3(s, \u03c0) =  s if k = 0 \u03b3(\u03b3(s, a1), \u3008a2, . . . , ak\u3009) if k > 0 and a1 is applicable to s\nundefined otherwise\nDefinition 4.12. Let P = \u3008\u03a3, s0, g\u3009 be a planning problem. A plan \u03c0 is a solution for P if g \u2286 \u03b3(s0, \u03c0). A solution \u03c0 is minimal if no other solution plan for P contains fewer actions than \u03c0."}, {"heading": "State Reachability", "text": "We give below some basic definitions and facts concerning state reachability.\nDefinition 4.13. If s is a state, then the set of all successors of s is\n\u0393(s) = {\u03b3(s, a) | a \u2208 A and a is applicable to s}\nDefinition 4.14. Let \u03932(s) = \u0393(\u0393(s)) = \u22c3 {\u0393(s\u2032) | s\u2032 \u2208 \u0393(s)}, and similarly for \u03933, . . . ,\u0393n, then the set of states reachable from s is the transitive closure:\n\u0393\u0302(s) = \u0393(s) \u222a \u03932(s) \u222a \u03933(s) \u222a . . . (4.1)\nDefinition 4.15. An action a is said to be relevant for a goal g if and only if g \u2229 effect+(a) 6= \u2205 and g \u2229 effect\u2212(a) = \u2205. In other words, these conditions state that a can contribute to producing a state in Sg = {s \u2208 S | g \u2286 s}.\nDefinition 4.16. The regression set of a goal g, for an action a that is relevant for g, is the minimal set of propositions required in a state in order to apply a and get g:\n\u03b3\u22121(g, a) = (g \u2212 effect+(a)) \u222a precond(a) (4.2)\nThus for any state s,\n\u03b3(s, a) \u2208 Sg \u21d0\u21d2 \u03b3\u22121(g, a) \u2286 s (4.3)"}, {"heading": "4.2.2 First Order Logic Representation", "text": "This representation generalizes the set-theoretic representation using first-order logic notation. We start with a first-order language L in which there is a finite number of predicate symbols and constant symbols. A state is a set of ground atoms of L.\n44\nDefinition 4.17. A planning operator o is a triple (name(o), precond(o), effects(o)) whose components are:\n\u2022 The name of the operator, name(o), is a syntactic expression of the form n(x1, . . . , xk) where n is a unique symbol and x1 . . . , xk are all the variable\nsymbols that appear anywhere in o.\n\u2022 The preconditions and effects are generalizations of the set-theoretic preconditions and effects: instead of being sets of propositions, they are sets of\nliterals (atoms and negations of atoms).\nDefinition 4.18. For any set of literals L, L+ is the set of all atoms in L and L\u2212 is the set of atoms whose negations are in L. If o is an operator, then precond+(o) and precond\u2212(o) are its positive and negative preconditions, respectively, and effect+(o) and effect\u2212(o) are its positive and negative effects, respectively.\nDefinition 4.19. An action is any ground instance of a planning operator. If a is an action and s is a state such that precond+(a) \u2286 s and precond\u2212(a) \u2229 s = \u2205, then a is applicable to s and the result of applying a to s is the state\n\u03b3(s, a) = (s\u2212 effects\u2212(a)) \u222a effects+(a)\nDefinition 4.20. Let L be a first-order language that has finitely many predicate symbols and constant symbols. A classical planning domain in L is a restricted state-transition system \u03a3 = (S,A, \u03b3) such that:\n\u2022 S \u2286 2{all ground atoms of L} .\n\u2022 A = {all ground instances of operators in O} .\n\u2022 The state-transition function is \u03b3(s, a) = (s \u2212 effects\u2212(a)) \u222a effects+(a) if a \u2208 A is applicable to s \u2208 S and undefined otherwise.\n\u2022 S is closed under \u03b3, that is for every s \u2208 S and action a applicable to s, \u03b3(s, a) \u2208 S.\n45"}, {"heading": "4.3 The PDDL Representation in Detail", "text": "We use an extension of the classical representation that allows the use of typed variables and relations. This extension improves the efficiency of a planning system by reducing the number of ground instances it needs to create. More concretely we use the PDDL planning language notation [M+98, FL03].\nThe PDDL description language serves as the bridge between the pentesting tool and the planner. Since exploits have strict platform and connectivity requirements, failing to accurately express those requirements in the PDDL model would result in plans that cannot be executed against real networks. This forces our PDDL representation of the attack planning problem to be quite verbose.\nOn top of that, we take advantage of the optimization abilities of planners that understand numerical effects1, and have the PDDL actions affect different metrics commonly associated with penetration testing such as running time, probability of success or possibility of detection (stealth).\nWe will focus on the description of the domain.pddl file, which contains the PDDL representation of the attack model. We will not delve into the details of the problem.pddl file, since it consists of a list of networks and machines, described using the predicates to be presented in this section.\nThe PDDL requirements of the representation are :typing, so that predicates can have types, and :fluents, to use numerical effects. We will first describe the types available in the model, and then list the predicates that use these types. We will continue by describing the model-related actions that make this predicates true, and then we will show an example of an action representing an exploit. We close this section with an example PDDL plan for a simple scenario."}, {"heading": "4.3.1 Types", "text": "Table 4.1 shows a list of the types that we used. Half of the object types are dedicated to describing in detail the operating systems of the hosts, since the successful execution of an exploit depends on being able to detect the specifics of the OS.\n1Numerical effects allow the actions in the PDDL representation to increase the value of different metrics defined in the PDDL scenario. The planner can then be told to find a plan that minimizes a linear function of these metrics.\n46"}, {"heading": "4.3.2 Predicates", "text": "The following are the predicates used in our model of attacks. Since exploits also have non-trivial connectivity requirements, we chose to have a detailed representation of network connectivity in PDDL. We need to be able to express how hosts are connected to networks, and the fact that exploits may need both IP and TCP or UDP connectivity between the source and target hosts, usually on a particular TCP or UDP port. These predicates express the different forms of connectivity:\n(connected_to_network ?s - host ?n - network) (IP_connectivity ?s - host ?t - host) (TCP_connectivity ?s - host ?t - host ?p - port) (TCP_listen_port ?h - host ?p - port) (UDP_listen_port ?h - host ?p - port)\nThese predicates describe the operating system and services of a host:\n(has_OS ?h - host ?os - operating_system) (has_OS_version ?h - host ?osv - OS_version) (has_OS_edition ?h - host ?ose - OS_edition) (has_OS_build ?h - host ?osb - OS_build) (has_OS_servicepack ?h - host ?ossp - OS_servicepack) (has_OS_distro ?h - host ?osd - OS_distro) (has_kernel_version ?h - host ?kv - kernel_version) (has_architecture ?h - host ?a - OS_architecture) (has_application ?h - host ?p - application)\n47"}, {"heading": "4.3.3 Actions", "text": "We require some \u201cmodel-related\u201d actions that make true the aforementioned predicates in the right cases.\n(:action IP_connect :parameters (?s - host ?t - host) :precondition (and (compromised ?s)\n(exists (?n - network)\n(and (connected_to_network ?s ?n)\n(connected_to_network ?t ?n))))\n:effect (IP_connectivity ?s ?t) )\n(:action TCP_connect :parameters (?s - host ?t - host ?p - port) :precondition (and (compromised ?s)\n(IP_connectivity ?s ?t) (TCP_listen_port ?t ?p))\n:effect (TCP_connectivity ?s ?t ?p) )\n(:action Mark_as_compromised :parameters (?a - agent ?h - host) :precondition (installed ?a ?h) :effect (compromised ?h) )\nTwo hosts on the same network possess IP connectivity, and two hosts have TCP (or UDP) connectivity if they have IP connectivity and the target host has the correct TCP (or UDP) port open. Moreover, when an exploit is successful an agent is installed on the target machine, which allows control over that machine. An installed agent is hard evidence that the machine is vulnerable, so it marks the machine as compromised2.\n2Depending on the exploit used, the agent might have regular user privileges, or superuser (root) privileges. Certain local exploits allow a low-level (user) agent to be upgraded to a highlevel agent, so we model this by having two different privileges PDDL objects.\n48\nThe penetration testing framework we used has an extensive test suite that collects information regarding running time for many exploit modules. We obtained average running times from this data and used that information as the numeric effect of exploit actions in PDDL. The metric to minimize in our PDDL scenarios is therefore the total running time of the complete attack.\nFinally, the following is an example of an action: an exploit that will attempt to install an agent on target host t from an agent previously installed on the source host s. To be successful, this exploit requires that the target runs a specific OS, has the service ovtrcd running and is listening on port 5053.\n(:action HP_OpenView_Remote_Buffer_Overflow_Exploit :parameters (?s - host ?t - host) :precondition (and (compromised ?s)\n(and (has_OS ?t Windows)\n(has_OS_edition ?t Professional) (has_OS_servicepack ?t Sp2) (has_OS_version ?t WinXp) (has_architecture ?t I386))\n(has_service ?t ovtrcd) (TCP_connectivity ?s ?t port5053)\n) :effect(and (installed_agent ?t high_privileges)\n(increase (time) 10)\n))\nIn our PDDL representation there are several versions of this exploit, one for each specific operating system supported by the exploit. For example, another supported system for this exploit looks like this:\n(:action HP_OpenView_Remote_Buffer_Overflow_Exploit :parameters (?s - host ?t - host) :precondition (and (compromised ?s)\n(and (has_OS ?t Solaris)\n(has_OS_version ?t V_10) (has_architecture ?t Sun4U))\n(has_service ?t ovtrcd) (TCP_connectivity ?s ?t port5053)\n49\n) :effect(and (installed_agent ?t high_privileges)\n(increase (time) 12)\n))\nThe main part of the domain.pddl file is devoted to the description of the actions. In our sample scenarios, this file has up to 28,000 lines and includes up to 1,800 actions. The last part of the domain.pddl file is the list of constants that appear in the scenario, including the names of the applications, the list of port numbers and operating system version details."}, {"heading": "4.3.4 An Attack Plan", "text": "We end this section with an example plan obtained by running Metric-FF on a scenario generated with this model. The goal of the scenario is to compromise host 10.0.5.12 in the target network. This network is similar to the test network that we will describe in detail in Section 5.3. The plan requires four pivoting steps and executes five different exploits in total. The localagent object represents the pentesting framework running in the machine of the user/attacker. The exploits shown are real-world exploits currently present in the pentesting framework.\n0: Mark_as_compromised localagent localhost 1: IP_connect localhost 10.0.1.1 2: TCP_connect localhost 10.0.1.1 port80 3: Phpmyadmin Server_databases Remote Code Execution\nlocalhost 10.0.1.1\n4: Mark_as_compromised 10.0.1.1 high_privileges 5: IP_connect 10.0.1.1 10.0.2.2 6: TCP_connect 10.0.1.1 10.0.2.2 port80 7: PHP memory_limit exploit\n10.0.1.1 10.0.2.2\n8: Mark_as_compromised 10.0.2.2 high_privileges 9: IP_connect 10.0.2.2 10.0.3.2\n10: SNMPc Network Manager Trap Packet Remote Buffer\nOverflow 10.0.2.2 10.0.3.2\n11: Mark_as_compromised 10.0.3.2 high_privileges 12: IP_connect 10.0.3.2 10.0.4.2\n50\n13: Snort TCP Stream Integer Overflow\n10.0.3.2 10.0.4.2\n14: Mark_as_compromised 10.0.4.2 high_privileges 15: IP_connect 10.0.4.2 10.0.5.12 16: TCP_connect 10.0.4.2 10.0.5.12 port445 17: Novell Client NetIdentity Agent Buffer Overflow\n10.0.4.2 10.0.5.12\n18: Mark_as_compromised 10.0.5.12 high_privileges"}, {"heading": "4.4 Expressivity of the PDDL Representation", "text": "Choosing to use the PDDL representation to model our problem turned out to be a very happy choice. First of all, because the PDDL language was created for the International Planning Competition, and using it we could experiment with a set of different planners designed to take PDDL input. Secondly because the PDDL language has been widely extended [FL03, YL04], and the set of problems that be represented using this language is very wide. We will illustrate its expressivity with a simple exercise: to model the Attack Trees proposed by Bruce Schneier [Sch99].\nExample 4.21. Schneier\u2019s article [Sch99] takes as an example a simple attack tree against a physical safe. The attack is represented in a tree structure, with the goal as the root node and different ways of achieving that goal as leaf nodes. There are AND nodes and OR nodes: the OR nodes are alternatives, and the AND nodes represent different steps toward achieving the same goal.\nThis representation does not distinguish between actions and assets. Let us\nmodel the same attack in the PDDL language, using predicates for the assets.\nThe actions of this example are described follow. The leaf nodes of the tree are marked as \u201cpossible\u201d or \u201cimpossible\u201d in the attack tree, this is translated as preconditions, where (possible) is a true predicate in the initial conditions of the problem.\n(:action PickLock :precondition (impossible) :effect (open_safe) )\n(:action UseLearnedCombo :precondition (safe_combination) :effect (open_safe)\n51\n)\n(:action CutOpenSafe :precondition (possible) :effect (open_safe) )\n(:action InstallImproperly :precondition (impossible) :effect (open_safe) )\n(:action FindWrittenCombo :precondition (impossible) :effect (safe_combination) )\n(:action GetComboFromTarget :precondition\n(safe_combination_from_target)\n:effect (safe_combination) )\n(:action Threaten :precondition (impossible) :effect (safe_combination_from_target) )\n(:action Blackmail :precondition (impossible) :effect (safe_combination_from_target) )\n(:action Eavesdrop :precondition (and\n(conversation_eavesdropped) (target_states_combo)\n) :effect (safe_combination_from_target) )\n(:action Bribe :precondition (possible) :effect (safe_combination_from_target) )\n(:action ListenToConversation :precondition (possible) :effect (conversation_eavesdropped) )\n(:action GetTargetToStateCombo :precondition (impossible) :effect (target_states_combo) )\nThe assets, formulated as predicates, are:\n(:predicates\n(possible) (impossible) (open_safe) (safe_combination) (safe_combination_from_target)\n52\n(conversation_eavesdropped) (target_states_combo)\n)\nThis is the domain definition of the problem. The initial conditions and the\ngoal are:\n(define (problem attack_tree_figure1)\n(:domain AttackTree)\n(:init (possible))\n(:goal (open_safe)) )\nWhen executing the planner FF with this problem, we get the following plan\nff: search configuration is best-first on 1*g(s) + 5*h(s) where\nmetric is plan length\nadvancing to distance: 1\n0\nff: found legal plan as follows\nstep 0: CutOpenSafe\nExample 4.22. Let\u2019s see a continuation of the previous example. Consider that we distinguish between actions that require special equipment and those which don\u2019t. We also add a cost to each leaf action (in thousands of dollars). This is done via the cost function and adding numerical effects to the actions. The domain with these modifications is now:\n(define (domain AttackTree)\n(:requirements :TYPING :FLUENTS)\n(:functions\n(cost)\n)\n53\n(:predicates\n(none) (special_equipment) (open_safe) (safe_combination) (safe_combination_from_target) (conversation_eavesdropped) (target_states_combo)\n)\n(:action PickLock :precondition (special_equipment) :effect (and\n(open_safe) (increase (cost) 30))\n)\n(:action UseLearnedCombo :precondition (safe_combination) :effect (open_safe) )\n(:action CutOpenSafe :precondition (special_equipment) :effect (and\n(open_safe) (increase (cost) 10))\n)\n(:action InstallImproperly :precondition (none) :effect (and\n(open_safe) (increase (cost) 100))\n)\n(:action FindWrittenCombo :precondition (none) :effect (and\n(safe_combination) (increase (cost) 75))\n)\n(:action GetComboFromTarget :precondition\n(safe_combination_from_target)\n:effect (and\n(safe_combination) (increase (cost) 0))\n)\n(:action Threaten :precondition (none) :effect (and\n(safe_combination_from_target) (increase (cost) 60))\n)\n(:action Blackmail :precondition (none) :effect (and\n(safe_combination_from_target) (increase (cost) 100))\n)\n(:action Eavesdrop :precondition (and\n(conversation_eavesdropped) (target_states_combo))\n:effect (safe_combination_from_target) )\n54\n(:action Bribe :precondition (none) :effect (and\n(safe_combination_from_target) (increase (cost) 20))\n)\n(:action ListenToConversation :precondition (special_equipment) :effect (and\n(conversation_eavesdropped)\n(increase (cost) 20))\n)\n(:action GetTargetToStateCombo :precondition (none) :effect (and\n(target_states_combo) (increase (cost) 40))\n) )\nAnd the initial conditions and the goal of the problem are now:\n(define (problem attack_tree_figure1)\n(:domain AttackTree)\n(:init\n(none) (= (cost) 0)\n)\n(:goal (open_safe))\n(:metric MINIMIZE (cost)) )\nIn particular we suppose that the attacker hasn\u2019t got the special equipment required by some actions, and the objective is to obtain the goal (open safe) while minimizing the cost function.\nThe output of the planner Metric-FF is the following plan:\nff: search configuration is best-first on 1*g(s) + 5*h(s) where\nmetric is ((1.00*[RF0](cost)) - () + 0.00)\nadvancing to distance: 1\n0\n55\nff: found legal plan as follows\nstep 0: FindWrittenCombo\n1: UseLearnedCombo\nIt is noteworthy that this plan doesn\u2019t minimize the total cost, since the given\nplan has a cost of $ 75k, whereas the optimal plan (below) has a cost of $ 20k.\nstep 0: Bribe\n1: GetComboFromTarget 2: UseLearnedCombo\nThis plan was not found by Metric-FF because in its heuristic search, the planner only considered plans with 2 actions (which are sufficient to obtain the goal) before looking for an optimal plan within that horizon.\nTo conclude the example, it showed that Schneier\u2019s Attack Trees can be perfectly modeled in PDDL with fluents, and it also showed us a limitation of MetricFF, that failed to find the optimal plan even in this very small example."}, {"heading": "4.5 The Hypergraph Representation", "text": "In this section we explore briefly the Hypergraph representation, and use it to prove that a version of the Attack Planning Problem is NP-hard. Of course this comes as no surprise, and the following section can thus be considered as an exercise performed during the early phases of our research."}, {"heading": "4.5.1 Basic concepts", "text": "We recall some basic definitions.\nDefinition 4.23. A directed hypergraph, or simply hypergraph, is a pair H = (V,E) where V is the set of nodes, and E is the set of hyperarcs. A hyperarc is a pair e = (T (e), h(e)), where T (e) \u2286 V is the tail of e while h(e) \u2208 V is the head of e.\nThe nodes represent the attack assets. The actions are modeled as hyperarcs. The assets contained in the tail T (e) of an action are the requirements. The head of the hyperarc is the result of the action.\n56\nAction templates are instantiated.\nDefinition 4.24. A directed hyperpath, or simply hyperpath, PSt from the source set S \u2286 V to the target node t \u2208 V is a minimal acyclic sub-hypergraph of H containing the nodes in S and the node t, such that each node (except the nodes in S) has exactly one entering hyperarc."}, {"heading": "4.5.2 NP-Hardness of the Hypergraph Formulation", "text": "Suppose that the hypergraph H is given. The planning problem is to find an optimal hyperpath. The following problem is NP-hard [FR99].\nProblem 4.25. (Directed Steiner Tree problem) Instance: A directed graph G = (V,E), a node s \u2208 V , a subset of nodes K = {i1, . . . , ik} \u2286 V and weights w : A \u2212\u2192 Z+. Task: Find a directed subtree T , rooted at node s and of minimum weight that contains all nodes in K.\nWe state the following version of the Attack Planning problem.\nProblem 4.26. (Attack Planning, hypergraph formulation) Instance: A directed hypergraph G = (V,E), nodes s, t and weights w : E \u2212\u2192 Z+. Task: Find a subhypergraph G1 of minimum weight that contains a directed hyperpath from node s to node t.\nWe note that if G1 contains a hyperarc ({i1, . . . , ik}, j), it must contain nodes {i1, . . . , ik, j}.\nTheorem 4.27. The version of Attack Planning Problem stated above is NP-hard.\nProof. The Attack Planning Problem contains the Directed Steiner Tree Problem as a special case. More precisely, given an instance (G, s,K, c) of the Directed Steiner Tree Problem we construct the following hypergraph G\u2032: we add an extra node t to graph G and we add a hyperarc ({i1, . . . , ik}, t) from all nodes in K to node t of zero cost. That is, let V \u2032 = V \u222a {t}, let A\u2032 = A \u222a {({i1, . . . , ik}, t)} and let G\u2032 = (V \u2032, A\u2032). The cost c\u2032 of each arc of A\u2032 is the same as before and the cost of the hyperarc is zero.\nThen, solving the Attack Planning Problem on (G\u2032, s, t, c\u2032) implies solving the\nDirected Steiner Tree Problem on (G, s,K, c).\nChapter 5"}, {"heading": "Integration with Classical", "text": ""}, {"heading": "Planners", "text": "Assessing network security is a complex and difficult task. Attack graphs have been proposed as a tool to help network administrators understand the potential weaknesses of their networks (see Section 3.8). However, one problem has not yet been addressed by previous work on this subject; namely, how to actually execute and validate the attack paths resulting from the analysis of the attack graph. In Chapter 4 we presented a complete PDDL representation of an attack model. In the rest of this chapter, we present an implementation that integrates a planner into a penetration testing tool.\nThis allows us to automatically generate attack paths for penetration testing scenarios, and to validate these attacks by executing the corresponding actions -including exploits- against the real target network. We present an algorithm for transforming the information present in the penetration testing tool to the planning domain in Section 5.2, and we show how the scalability issues of attack graphs can be solved using current planners. In Section 5.3 we make an analysis of the performance of our solution, showing how the model scales to medium-sized networks and the number of actions available in current penetration testing tools."}, {"heading": "5.1 Attack Planning in the Real World", "text": "In medium-sized networks, building complete attack graphs quickly becomes unfeasible (their size increases exponentially with the number of machines and available actions). To deal with the attack planning problem, a proposed approach [SW08, Sar09a] is to translate the model into a PDDL representation and use\n57\n58\nclassical planning algorithms to find attack paths. Planning algorithms manage to find paths in the attack graph without constructing it completely, thus helping to avoid the combinatorial explosion [BF97]. A similar approach was presented at SecArt\u201909 [GG09], but the authors\u2019 model is less expressive than the one used in this work, as their objective was to use the attack paths to build a minimal attack graph, and not to carry out these attacks against real networks.\nIn the following sections we present an implementation of these ideas. We have developed modules that integrate a pentesting framework with an external planner, and execute the resulting plans back in the pentesting framework, against a real network. We believe our implementation proves the feasability of automating the attack phases of a penetration test, and allows us to think about continuing this line of work in order to automate the whole process. We show how our model, and its PDDL representation, scales to hundreds of target nodes and available exploits, numbers that can be found when assessing medium-sized networks with current pentesting frameworks.\nThe rest of the chapter is structured as follows: in Section 5.2 we present a high-level description of our solution, describing the steps needed to integrate a planner with a penetration testing framework. We have already described the PDDL representation in detail in Section 4.3 explaining how the \u201creal world\u201d view that we take forces a particular implementation of the attack planning problem in PDDL. Section 5.3 presents the results of our scalability testing, showing how our model manages medium-sized networks using current planners."}, {"heading": "5.2 Architecture of our Solution", "text": "In this section we describe the components of our solution, and how they fit together to automate an attack. Figure 5.1 shows the relationship between these different components. The penetration testing framework is a tool that allows the user/attacker to execute exploits and other pre/post exploitation modules against the target network. Our implementation is based on Core Impact1. The planner is a tool that takes as input the description of a domain and a scenario, in PDDL2. The domain contains the definition of the available actions in the model,\n1As mentioned in the previous section, Metasploit is an open-source alternative. 2Refer to [FL03] for a description of the PDDL planning language.\n59\nand the scenario contains the definition of the objects (networks, hosts, and their characteristics), and the goal which has to be solved.\nThe attack workspace contains the information about the current attack or penetration test. In particular, the discovered networks and hosts, information about their operating systems, open/closed ports, running services and compromised machines. In the current version of our solution we assume that the workspace has this network information available, and that no network information gathering is needed to generate a solvable plan. We will address this limitation in Section 5.5 when we discuss future work."}, {"heading": "5.2.1 The \u201cTransform\u201d Algorithm", "text": "The transform algorithm generates the PDDL representation of the attack planning problem, including the initial conditions, the operators (PDDL actions), and the goal. From the pentesting framework we extract the description of the operators, in particular the requirements and results of the exploits, which will make up most of the available actions in the PDDL representation. This is encoded in the domain.pddl file, along with the predicates and types (which only depend on the details of our model).\nFrom the attack workspace we extract the information that constitutes the initial conditions for the planner: networks, machines, operating systems, ports and running services. This is encoded in the problem.pddl file, together with the goal of the attack, which will usually be the compromise of a particular machine.\nA common characteristic of pentesting frameworks is that they provide an\n60\nincomplete view of the network under attack. The pentester has to infer the structure of the network using the information that he sees from each compromised machine. The transform algorithm takes this into account, receiving extra information regarding host connectivity."}, {"heading": "5.2.2 The Planner", "text": "The PDDL description is given as input to the planner. The advantage of using the PDDL language is that we can experiment with different planners and determine which best fits our particular problem. We have evaluated our model using both SGPlan [CWH06] and Metric-FF [Hof02].\nThe planner is run from inside the pentesting framework, as a pluggable module of the framework that we call PlannerRunner. The output of the planner is a plan, a sequence of actions that lead to the completion of the goal, if all the actions are successful. We make this distinction because even with well-tested exploit code, not all exploits launched are successful. The plan is given as feedback to the pentesting framework, and executed against the real target network."}, {"heading": "5.3 Performance and Scalability Evaluation", "text": "This model, and its representation in PDDL, are intended to be used to plan attacks against real networks, and execute them using a pentesting framework. To verify that our proposed solution scales up to the domains and scenarios we need to address in real-world cases, we carried out extensive performance and scalability testing \u2013 to see how far we could take the attack model and PDDL representation with current planners. We focused our performance evaluation on four metrics:\n\u2022 Number of machines in the attacked network\n\u2022 Number of pivoting steps in the attack\n\u2022 Number of available exploits in the pentesting suite\n\u2022 Number of individual predicates that must be fulfilled to accomplish the goal\nThe rationale behind using these metrics is that we needed our solution to scale up reasonably with regard to all of them. For example, a promising use of planning\n61\nalgorithms for attack planning lies in scenarios where there are a considerable number of machines to take into account, which could be time-consuming for a human attacker.\nMoreover, many times a successful penetration test needs to reach the innermost levels of a network, sequentially exploiting many machines in order to reach one which might hold sensitive information. We need our planning solution to be able to handle these cases where many pivoting steps are needed.\nPentesting suites are constantly updated with exploits for new vulnerabilities, so that users can test their systems against the latest risks. The pentesting tool that we used currently3 has about 700 exploits, of which almost 300 are the remote exploits that get included in the PDDL domain. Each remote exploit is represented as a different operator for each target operating system, so our PDDL domains usually have about 1800 operators, and our solution needs to cope with that input.\nFinally, another promising use of planning algorithms for attack planning is the continuous monitoring of a network by means of a constant pentest. In this case we need to be able to scale to goals that involve compromising many machines.\nWe decided to use the planners Metric-FF4 [Hof02] and SGPlan5 [CWH06] since we consider them to be representative of the state of the art in classical planners. The original FF planner was the baseline planner for IPC\u2019086. MetricFF adds numerical effects to the FF planner. We modified the reachability analysis in Metric-FF to use type information, as in FF, to obtain better memory usage.\nSGPlan combines Metric-FF as a base planner with a constraint partitioning scheme which allows it to divide the main planning problem in subproblems; these subproblems are solved with a modified version of Metric-FF, and the individual solutions combined to obtain a plan for the original problem. This method, according to the authors, has the potential to significantly reduce the complexity of the original problem [CWH06]. It was successfully used in [GG09].\n3As of March, 2010. 4Latest version available (with additional improvements). 5SGPlan version 5.22. 6The International Planning Competition, 2008.\n62"}, {"heading": "5.3.1 Generating the Test Scenarios", "text": "We tested both real and simulated networks, generating the test scenarios using the same pentesting framework we would later use to attack them. For the largescale testing, we made use of a network simulator [FMOS09]. This simulator allows us to construct sizable networks7, but to still view each machine independently and, for example, to execute distinct system calls in each of them. The simulator integrates tightly with the pentesting framework, to the point where the framework is oblivious to the fact that the network under attack is simulated and not real.\nThis allowed us to use the pentesting tool to carry out all the steps of the test, including the information gathering stage of the attack. Once the information gathering was complete, we converted the attack workspace to PDDL using our transform tool.\n7We tested up to 1000 nodes in the simulator.\n63\nWe generated two types of networks for the performance evaluation. To evaluate the scalability in terms of number of machines, number of operators, and number of goals; the network consists of five subnets with varying numbers of machines, all joined to one main network to which the user/attacker initially has access. Figure 5.2 shows the high-level structure of this simulated network.\nTo evaluate the scalability in terms of the number of pivoting steps needed to reach the goal, we constructed a test network where the attacker and the target machine are separated by an increasing number of routers, and each subnetwork in between has a small number of machines.\nThe network simulator allows us to specify many details about the simulated machines, so in both networks, the subnetworks attached to the innermost routers contain four types of machines: Linux desktops and servers, and Windows desktops and servers. Table 5.1 shows the configuration for each of the four machine types, and the share of each type in the network. For server cases, each machine randomly removes one open port from the canonical list shown in the table, so that all machines are not equal and thus not equally exploitable."}, {"heading": "5.3.2 Experimental Results", "text": "As we expected, both planners generated the same plans in all cases, not taking into account plans in which goals were composite and the same actions could be executed in different orders. This is reasonable given that SGPlan uses Metric-FF as its base planner. We believe that the performance and scalability results are more interesting, since a valid plan for an attack path is a satisfactory result in itself.\nFigures 5.3 to 5.10 show how running time and memory consumption scale\n64\nfor both planners, with respect to the four metrics considered8. Recall that, as explained in Section 4.3, each exploit maps to many PDDL actions.\n8Testing was performed on a Core i5 750 2.67 GHz machine with 8 GB of RAM, running 64-bit Ubuntu Linux; the planners were 32-bit programs.\n65\nAs illustrated by Figures 5.3 and 5.4, both running time and memory consumption increase superlinearly with the number of machines in the network. We were not able to find exact specifications for the time and memory complexities of Metric-FF or SGPlan, though we believe this is because heuristics make it difficult to calculate a complexity that holds in normal cases. Nonetheless, our model, coupled with the SGPlan planner, allows us to plan an attack in a network with 480 nodes in 25 seconds and using less than 4 GB of RAM. This makes attack planning practical for pentests in medium-sized networks.\nMoving on to the scalability with regard to the depth of the attack (Figures 5.5 and 5.6), it was surprising to verify that memory consumption is constant even as we increase the depth of the attack to twenty pivoting steps, which generates a plan of more than sixty steps. Running time increases slowly, although with a small number of steps the behaviour is less predictable. The model is therefore not constrained in terms of the number of pivoting steps.\nWith regard to the number of operators (i.e. exploits) (Figures 5.7 and 5.8), both running time and memory consumption increase almost linearly; however, running time spikes in the largest cases. Doubling the number of operators, from 720 to 1440 (from 120 to 240 available exploits), increases running time by 163% for Metric-FF and 124% for SGPlan. Memory consumption, however, increases only 46% for Metric-FF, and 87% for SGPlan. In this context, the number of available exploits is not a limiting factor for the model.\nInterestingly, these three tests also verify many of the claims made by the authors of SGPlan. We see that the constraint partition used by their planner manages to reduce both running time and memory consumption, in some cases by significant amounts (like in Figure 5.6).\nThe results for the individual number of predicates in the overall goal (Figures 5.9 and 5.10) are much more surprising. While SGPlan runs faster than MetricFF in most of the cases, Metric-FF consumes significantly less memory in almost half of them. We believe that as the goal gets more complex (the largest case we tested requests the individual compromise of 100 machines), SGPlan\u2019s constraint partition strategy turns into a liability, not allowing a clean separation of the problem into subproblems. By falling back to Metric-FF, our model can solve, in under 6 seconds and using slightly more than 1 GB of RAM, attack plans where half of the machines of a 200-machine network are to be compromised.\n66\n67\n68\n69"}, {"heading": "5.3.3 Improving the Memory Usage of Metric-FF", "text": "During our initial tests with Metric-FF, we were not able to solve even mediumsized scenarios without running out of memory on a machine with 4 GB of RAM. We discovered that Metric-FF was performing a very inefficient reachability analysis before the actual planning, thus causing said memory problems. More specifically, the reachability analysis allocated four integer arrays with room for all the possible \u201cstates\u201d of each predicate. These states corresponded to all possible combination of constants for each argument of the predicate. The problem was that Metric-FF was not using type information, and therefore it considered all constants, regardless of type, for each argument of each predicate. Due to the fact that we need to represent many characteristics of the target machine and operating system for each exploit, our domain contains a lot of constants, representing port numbers, operating system versions, editions, distributions, service packs, and kernel versions.\nMetric-FF allocated \u2211p\ni=1(c ai) 32-bit integers for each array, where p is the\nnumber of predicates (20 in our scenarios), c is the number of constants (around 300 in our scenarios), and ai is the arity of predicate i (max(ai) = 3 in our scenarios). We modified Metric-FF to only allocate space for constants of the correct type, using type information as originally implemented in the planner FF, and obtained much better results. The reachability analysis for our standard domain would consume over 4 GB of RAM, and we managed to reduce that to a little over 2 MB, by significantly reducing the number of constants associated with each argument of each predicate."}, {"heading": "5.4 Related Work", "text": "Work on attack modeling applied to penetration testing had its origin in the possibility of programmatically controlling pentesting tools such as Metasploit or Core Impact. This model led to the use of attack graphs. Earlier work on attack graphs such as [PS98, RA00, SHJ+02] were based on the complete enumeration of attack states, which grows exponentially with the number of actions and machines. As we mentioned in Section 3.8 the survey of [LI05] shows that the major limitations of past studies of attack graphs is their lack of scalability to medium-sized networks.\nOne notable exception is the Topological Vulnerability Analysis (TVA) project\n70\nconducted in George Mason University described in [JNO05, NJ05, NEJ+09] and other papers, which has been designed to work in real-size networks. The main differences between our approach and TVA are the following:\n\u2022 Input. In TVA the model is populated with information from third party vulnerability scanners such as Nessus, Retina and FoundScan, from databases\nof vulnerabilities such as CVE and OSVDB and other software. All this information has to be integrated, and will suffer from the drawbacks of each information source, in particular from the false positives generated by the vulnerability scanners about potential vulnerabilities.\nIn our approach the conceptual model and the information about the target network are extracted from a consistent source: the pentesting framework exploits and workspace. The vulnerability information of an exploit is very precise: the attacker can execute it in the real network to actually compromise systems.\n\u2022 Output. The attack graph generated by TVA is presented to the end-user through an interactive graphical interface. Whereas in our approach, the\noutput of the planner is a sequence of actions that are directly executed by the pentest tool on the target network, and is shown as an actual agent installed in the target host.\n\u2022 Monotonicity. TVA assumes that the attacker\u2019s control over the network is monotonic [AWK02]. In particular, this implies that TVA cannot model\nDenial-of-Service (DoS) attacks, or the fact that an unsuccessful exploit may crash the target service or machine. It is interesting to remark that the monotonicity assumption is the same used by FF [Hof01] to create a relaxed version of the planning problem, and use it as a heuristic to guide the search through the attack graph. By relying on the planner to do the search, we do not need to make this restrictive assumption."}, {"heading": "5.5 Summary and Future Work", "text": "[FNRS03] proposed a model of computer network attacks which was designed to be realistic from an attacker\u2019s point of view. We have shown in this chapter that\n71\nthis model scales up to medium-sized networks: it can be used to automate attacks (and penetration tests) against networks with hundreds of machines.\nThe solution presented shows that it is not necessary to build the complete attack graph (one of the major limitations of earlier attack graph studies). Instead we rely on planners such as Metric-FF and SGPlan to selectively explore the state space in order to find attack paths.\nWe have successfully integrated these planners with a pentesting framework, which allowed us to execute and validate the resulting plans against a test bench of scenarios. We presented the details of how to transform the information contained in the pentesting tool to the planning domain9.\nOne important question that for future work on this subject is how to deal with incomplete knowledge of the target network (actually we deal with that issue in Chapters 7 and 8). The architecture that we presented supports running non-classical planners, so one possible approach is to use probabilistic planning techniques, where actions have different outcomes with associated probabilities. For example, a step of the attack plan could be to discover the operating system details of a particular host, so the outcome of this action would be modeled as a discrete probability distribution.\nAnother approach would be to build a \u201cmetaplanner\u201d that generates hypotheses with respect to the missing bits of information about the network, and uses the planner to test those hypotheses. Continuing the previous example, the metaplanner would assume that the operating system of the host was Windows and request the planner to compromise it as such. The metaplanner would then test the resulting plan in the real network, and verify or discard the hypothesis.\n9Our implementation uses Core Impact, but the same ideas can be extended to other tools such as the open-source project Metasploit.\nChapter 6"}, {"heading": "Simulation of Network Scenarios", "text": "In this chapter we present a simulation platform called Insight, created to design and simulate cyber-attacks against large arbitrary target scenarios. This platform was used to test the implementation described in Chapter 5, namely the integration of a classical planner with a pentesting framework. To be able to test our implementation, we needed to execute attack paths in networks with hundreds of machines, something that could only be done on a simulated network (given our current infrastructure).\nThe simulation platform that we developed has surprisingly low hardware and configuration requirements, while making the simulation a realistic experience from the attacker\u2019s standpoint. The scenarios include a crowd of simulated actors: network devices, hardware devices, software applications, protocols, users, etc.\nA novel characteristic of this tool is to simulate vulnerabilities (including 0- days) and exploits, allowing an attacker to compromise machines and use them as pivoting stones to continue the attack. A user can test and modify complex scenarios, with several interconnected networks, where the attacker has no initial connectivity with the objective of the attack.\nWe give a concise description of this new technology, and its possible uses in the security research field, such as pentesting training, study of the impact of 0-day vulnerabilities, evaluation of security countermeasures, and as a risk assessment tool (besides providing a testbed for our planning implementation)."}, {"heading": "6.1 Motivation", "text": "Computer security has become a necessity in most of today\u2019s computer uses and practices. However it is a wide topic and security issues can arise from almost everywhere: binary flaws (e.g., buffer overflows [One96]), Web flaws (e.g., SQL\n72\n73\ninjection, remote file inclusion), protocol flaws (e.g., TCP/IP flaws [Bel89]), not to mention hardware, human, cryptographic and other well known flaws.\nAlthough it may seem obvious, it is useless to secure a network with a hundred firewalls if the computers behind it are vulnerable to client-side attacks. The protection provided by an Intrusion Detection System (IDS) is worthless against new vulnerabilities and 0-day attacks. As networks have grown in size, they have implemented a wider variety of more complex configurations and include new devices (e.g. embedded devices) and technologies. This has created new flows of information and control, and therefore new attack vectors. As a result, the job of both black hat and white hat communities has become more difficult and challenging.\nThe previous examples are just the tip of the iceberg. Computer security is a complex field and it has to be approached with a global view, considering all parts of the whole picture simultaneously: network devices, hardware devices, software applications, protocols, users, et cetera. The simulation platform Insight has been created with that goal in mind."}, {"heading": "6.1.1 Design Restrictions", "text": "In practice, the simulation of complex networks requires resolving the tension between the scalability and accuracy of the simulated subsystems, devices and data. This is a complex issue, and to find a satisfying solution for this trade-off we have adopted the following design restrictions:\n1. Our goal is to have a simulator on a single desktop computer, running hun-\ndreds of simulated machines, with simulated traffic realistic only from the attacker\u2019s standpoint.\n2. Attacks within the simulator are not launched by real attackers in the wild\n(e.g. script-kiddies, worms, black hats). As a consequence, the simulation does not have to handle exploiting details such as stack overflows or heap overflows. Instead, attacks are executed from an attack framework by Insight users who know they are playing in a simulated environment.\n74"}, {"heading": "6.1.2 Main Features", "text": "To demonstrate that our approach is valid, we have developed a proof of concept called Insight. This program introduces a platform for executing attack experiments and tools for constructing these attacks. We show that users of this tool are able to design and adapt attack-related technologies, and have better tests to assess their quality. Attacks are executed from an attack framework which includes many information gathering and exploitation modules. Modules can be scripted, modified or even added.\nOne of the major Insight features is the capability to simulate exploits. An exploit is a piece of code that attempts to compromise a computer system via a specific vulnerability. There are many ways to exploit security holes. If a computer programmer makes a programming mistake in a computer program, it is sometimes possible to circumvent security. Some common exploiting techniques are stack exploits, heap exploits, format string exploits, etc.\nTo simulate these techniques in detail is very expensive. The main problem is to maintain the complete state (e.g., memory, stack, heap, CPU registers) for every simulated machine. From the attacker\u2019s point of view, an exploit can be modeled as a magic string sent to a target machine to unleash a hidden feature (e.g., reading files remotely) with a probabilistic result. This is a lightweight approach, and we have sacrificed some of the realism in order to support very large and complex scenarios. For example, 1, 000 virtual machines and network devices (e.g., hubs, switches, IDS, firewalls) can be simulated on a single Windows desktop, each one running their own simulated OS, applications, vulnerabilities and file systems. Certainly, taking into account available technologies, it is not feasible to use a complete virtualization server (e.g., VMware) running thousands of images simultaneously.\nAs a result, the main design concept of our implementation is to focus on the attacker\u2019s point of view, and to simulate on demand. In particular, the simulator only generates information as requested by the attacker. By performing this ondemand processing, the main performance bottleneck comes from the ability of the attacker to request information from the scenario. Therefore, it is not necessary, for example, to simulate the complete TCP/IP packet traffic over the network if nobody is requesting that information. A more lightweight approach is to send\n75\ndata between network sockets writing in the memory address space of the peer socket, and leaving the full packet simulation as an option."}, {"heading": "6.2 Background and Related Work", "text": "Using simulated networks as a research tool to gather knowledge regarding the techniques, strategy and procedures of the black hat community is not a new issue. Solutions such as honeypots and honeynets [Pro06, Spi02] were primarily designed to attract malicious network activities and to collect data. A precise definition for the term honeypot is given by The Honeynet Project [Pro04a]:\nDefinition 6.1. A honeypot is an information system resource whose value lies in unauthorized or illicit use of that resource.\nOver the last decade a wide variety of honeypot systems have been built [MPS+03, BCJ+05, SMS01, YBP, Pro04b], both academic and commercial. Honeypots have emerged as an interesting tool for gathering knowledge on new methods used by attackers, and the underlying strength of the approach lies in its simplicity. Typically, honeypots offer minimal interaction with the attacker, emulating only small portions of the behavior of real networks. However, this simplicity is also a weakness: none of these systems execute kernel or application code that attackers seek to compromise, and only a few ones maintain a per-flow and per-protocol state to allow richer emulation capabilities. Thus, honeypots are most useful for capturing indiscriminate or large-scale attacks, such as worms, viruses or botnets, rather than very focused intrusions targeting a particular host [VMC+05].\nIn Table 6.1 we show the main differences with our approach. In particular, we are interested in the ability to compromise machines, and use them as pivoting stones1 to build complex multi-step attacks.\nIn contrast, \u201chigh interaction honeypots\u201d and virtualization technologies (e.g., VMware, Xen, Qemu) execute native system and application code, but the price of this fidelity is quite high. For example, the RINSE approach [LLN+05] is implemented over the iSSFNet network simulator, which runs on parallel machines to support real-time simulation of large-scale networks. All these solutions share\n1 In a network attack, to pivot means to use a compromised machine as a stepping stone to reach further networks and machines, making use of its trust relationships.\nthe same principle of simulating almost every aspect of a real machine or real network, but share similar problems too: expensive configuration cost and expensive hardware and software licenses. Moreover, most of these solutions are not fully compatible with standard network protection (e.g., firewalls, IDSs), suffering a lack of integration between all security actors in complex cyber-attack scenarios.\nSecurity assessment and staging are other well known security practices. It is common, for example in web application development, to duplicate the production environment on a staging environment (accurately mimicking or mirroring the first) to anticipate changes and their impact. The downside is that it is very difficult to adopt this approach in the case of network security due to several reasons. It would require the doubling of the hardware and software licenses and (among other reasons) there are no means to automatically configure the network.\nOther interesting approaches to solve these problems include the framework developed by Bye et al. [BSLA08]. While they focus on distributed denial of service attacks (DDoS) and defensive IDS analysis, we focus on offensive strategies to understand the scenarios and develop countermeasures. Also Loddo et al. [LS08] have integrated User Mode Linux [Dik06] and Virtual Distributed Ethernet [Dav05] to create a flexible and very detailed network laboratory and simulation tool. The latter project has privileged accuracy and virtualization over scalability and performance.\n77\nThe Potemkin Virtual Honeyfarm [VMC+05] is another interesting prototype. It improves high-fidelity honeypot scalability by up to six times while still closely emulating the execution behavior of individual Internet hosts. Potemkin uses quite sophisticated on-demand techniques for instantiating hosts2, but this approach focuses on attracting real attacks and it shows the same honeypot limitations to reach this goal. As an example, to capture e-mail viruses, a honeypot must posses an e-mail address, must be scripted to read mail (executing attachments like a naive user) and, most critically, real e-mail users must be influenced to add the honeypot to their address books. Passive malware (e.g., many spyware applications) may require a honeypot to generate explicit requests, and focused malware (e.g., targeting only financial institutions) may carefully select its victims and never touch a large-scale honeyfarm. In each of these cases there are partial solutions, and they require careful engineering to truly mimic the target environment.\nIn conclusion, new trends in network technologies make cyber-attacks more difficult to understand, learn and reproduce, and the current tools to tackle these problems have some deficiencies when facing large complex scenarios. In spite of that, it is possible to overcome the problems described above using the lightweight software simulation tool we present."}, {"heading": "6.3 Insight Approach and Overview", "text": "A diagram of the Insight general architecture is showed in Fig. 6.1. The Simulator subsystem is the main component. It performs all simulation tasks on the simulated machines, such as system call execution, memory management, interrupts, device I/O management, etcetera.\nAt least one Simulator subsystem is required, but the architecture allows several ones, each running in a real computer (e.g., a Windows desktop). In this example, there are two simulation subsystems, but more could be added in order to support more virtual hosts.\nThe simulation proceeds in a lightweight fashion. It means, for example, that not all system calls for all OSes are supported by the simulation. Instead of implementing the whole universe of system calls, Insight handles a reduced and generic\n2Including copy-on-write file system optimizations implemented also in Insight, as we are going to see it in \u00a76.5.5.\n78\nset of system calls, shared by all the simulated OSes. Using this approach, a specific OS system call is mapped to an Insight syscall which works similarly to the original one. For example, the Windows sockets API is based on the Berkeley sockets API model used in Berkeley UNIX, but both implementations are slightly different3. Similarly, there are some instances where Insight sockets have to diverge from strict adherence to the Berkeley conventions, usually due to implementation difficulties in the simulated environment. In spite of this (and ignoring the differences between OSes), all sockets system calls of the real world have been mapped to this unique simulated API.\nOf course, there are some system calls and management tasks closely related to the underlying OS which were not fully supported, such as UNIX fork and signal syscalls, or the complete set of functions implemented by the Windows SDK. There is a trade-off between precision and efficiency, and the decision of which syscalls\n3For additional details look at the Winsock API documentation (available from http:// msdn.microsoft.com), which includes a section called Porting Socket Applications to Winsock.\n79\nwere implemented was made with the objective of maintaining the precision of the simulation from the attacker\u2019s standpoint.\nThe exploitation of binary vulnerabilities4 is simulated with a probabilistic approach, to keep the attack model simple, lightweight, and to avoid tracking anomalous conditions (and their countermeasures), such as buffer overflows, format string vulnerabilities, exception handler overwriting\u2014among other well known vulnerabilities [AHLR07]. This probabilistic approach allows us to mimic the unpredictable behavior when an exploit is launched against a targeted machine.\nLet us assume that a simulated computer was initialized with an underlying vulnerability (e.g. it hosts a vulnerable OS). In this case, the exploit payload is replaced by a special ID or \u201cmagic string\u201d, which is sent to the attacked application using a preexistent TCP communication channel. When the attacked application receives this ID, Insight will decide if the exploit worked or not based on a probability distribution that depends on the exploit and the properties describing the simulated computer (e.g., OS, patches, open services). If the exploit is successful, then Insight will grant the control in the target computer through the agent abstraction, which will be described in \u00a76.4.\nThe probabilistic attack model is implemented by the Simulator subsystems, and it is supported by the Exploits Database, a special configuration file which stores the information related to the vulnerabilities. This file has a XML tree structure, and each entry has the whole necessary information needed by the simulator to compute the probabilistic behavior of a given simulated exploit. For example, a given exploit succeeds against a clean XP SP2 with 83% probability if port 21 is open, but crashes the system if it is a SP1. We are going to spend some time looking at the probability distribution, how to populate the exploits database, and the Insight attack model in the next sections.\nReturning to the architecture layout showed in Fig. 6.1, all simulator subsystems are coordinated by a unique Simulator Monitor, which deals with management and administrative operations, including administrative tasks (such as starting/stopping a simulator instance) and providing statistical information for the usage and performance of these.\nA set of Configuration Files defines the snapshot of a virtual Scenario. Similarly,\n4Insight supports simulation for binary vulnerabilities. Other kind of vulnerabilities (e.g. client-side and SQL injections) will be implemented in future versions.\n80\na scenario snapshot defines the instantaneous status of the simulation, and involves a crowd of simulated actors: servers, workstations, applications, network devices (e.g. firewalls, routers or hubs) and their present status. Even users can be simulated using this approach, and this is especially interesting in client-side attack simulation, where we expect some careless users opening our poisoned crafted emails.\nFinally, at the bottom right of the architecture diagram, we can see the Penetration Testing Framework, an external system which interacts with the simulated scenario in real time, sending system call requests through a communication channel implemented by the simulator. This attack framework is a free tailored version of the Impact solution5, however other attack tools are planned to be supported in the future (e.g., Metasploit [Moo06]).\nThe attacker actions are coded as Impact script files (using Python) called modules, which have been implemented using the attack framework SDK, as shown in the architecture diagram. The framework Python modules include several tools for common tasks (e.g. information gathering, exploits, import scenarios). The attacks are executed in real time against a given simulated scenario; a simulation component can provide scenarios of thousands of computers with arbitrary configurations and topologies. Insight users can design new scenarios and they have scripts to manage the creation and modification of the simulated components, and therefore iterate, import and reproduce cyber-attack experiments."}, {"heading": "6.4 The Simulated Attack Model", "text": "One of the characteristics that distinguish the scenarios simulated by Insight is the ability to compromise machines, and use them as pivoting stones to build complex multi-step attacks. To compromise a machine means to install an agent that will be able to execute arbitrary system calls (syscalls) as a user of this system.\nThe agent architecture is based on the solution called syscall proxy (see [Cac02] for more details). The idea of syscall proxying is to build a sort of universal payload that allows an attacker to execute any system call on a compromised host. By installing a small payload (a thin syscall server) on a vulnerable machine, the\n5Available from http://trials.coresecurity.com/.\n81\nattacker will be able to execute complex applications on his local host, with all system calls executed remotely. This syscall server is called an agent.\nIn the Insight attack model, the use of syscall proxying introduces two additional layers between a process run by the attacker and the compromised OS. These layers are the syscall client layer and the syscall server layer.\nThe syscall client layer runs on the attacker\u2019s Penetration Testing Framework. It acts as a link between the process running on the attacker\u2019s machine and the system services on a remote host simulated by Insight. This layer is responsible for forwarding each syscall argument and generating a proper request that the agent can understand. It is also responsible for sending this request to the agent and sending back the results to the calling process.\nThe syscall server layer (i.e. the agent that runs on the simulated system) receives requests from the syscall client to execute specific syscalls using the OS services. After the syscall finishes, its results are marshalled and sent back to the client."}, {"heading": "6.4.1 Probabilistic Exploits", "text": "In the simulator security model, a vulnerability is a mechanism used to access an otherwise restricted communication channel. In this model, a real exploit payload is replaced by an ID or \u201cmagic string\u201d which is sent to a simulated application. If this application is defined to be vulnerable (and some other requirements are fulfilled), then an agent will be installed in the computer hosting the vulnerable application.\nThe simulated exploit payload includes the aforementioned magic string. When the Simulator subsystem receives this information, it looks up for the string in the Exploits Database. If it is found, then the simulator will decide if the exploit worked or not and with what effect based on a probability distribution that depends on the effective scenario information of that computer and the specific exploit. Suppose, for example, that the Penetration Testing Framework assumes (wrongly) the attacked machine is a Red Hat Linux 8.0, but that machine is indeed a Windows system. In this hypothetical situation, the exploit would fail with 100% of probability. On the other side, if the attacked machine is effectively running an affected version of Red Hat Linux 9.0, then the probability of success could be 75%, or as determined in the exploit database.\n82"}, {"heading": "6.4.2 Remote Attack Model Overview", "text": "In Fig. 6.2 we can see the sequence of events which occurs when an attacker launches a remote exploit against a simulated machine. The rectangles in the top are the four principal components involved: The Penetration Testing Framework, the Simulator and the Exploits Database are the subsystems explained in Fig. 6.1; the Vulnerable Application is a simulated application or service which is running inside an Insight scenario and has an open port. In the diagram the declared components are represented as named rectangles, messages are represented as solid-line arrows, and time is represented as a vertical progression.\nWhen an exploit is launched against a service running in a simulated machine, a connection is established between the Penetration Testing Framework and the\n83\nservice6. Then, the simulated exploit payload is sent to the application. The targeted application reads the payload by running the system call read. Every time the syscall read is invoked, the Simulator subsystem analyzes if a magic string is present in the data which has just been read. When a magic string is detected, the Simulator searches for it in the Exploits Database. If the exploit is found, a new agent is installed in the compromised machine.\nThe exploit payload also includes information of the OS that the Penetration Testing Framework knows about the attacked machine: OS version, system architecture, service packs, etcetera. All this information is used to compute the probabilistic function and allows the Simulator to decide whether the exploit should succeed or not."}, {"heading": "6.4.3 Local Attack Model Overview", "text": "Insight can also simulate local attacks: If an attacker gains control over a machine but does not have enough privileges to complete a specific action, a local attack can deploy a new agent with higher privileges.\n6This connection is established, for example, by a real Windows socket or a simulated TCP/IP socket, see \u00a76.5.2.\n84\nIn Fig. 6.3 we can see the sequence of events which occurs when a local attack is launched against a given machine. A running agent has to be present in the targeted machine in order to launch a local exploit. All local simulated attacks are executed by the Simulator subsystem identically: The Penetration Testing Framework will write the exploit magic string into the agent standard input, using the write system call, and the Simulator will eventually detect the magic string intercepting that system call.\nIn a similar way as the previous example, the exploit magic string is searched in the database and a new agent (with higher privileges) is installed with probabilistic chance."}, {"heading": "6.5 Detailed Description", "text": "One of the most challenging issues in the Insight architecture is to resolve the tension between realism and performance. The goal was to have a simulator on a single desktop computer, running hundreds of simulated machines, with a simulated traffic realistic from a penetration test point of view. But there is a trade-off between realism and performance and we are going to discuss some of these problems and other architecture details in the following sections."}, {"heading": "6.5.1 The Insight Development Library", "text": "New applications can be developed for the simulation platform using a minimal C standard library, a standardized collection of header files and library routines used to implement common operations such as: input, output and string handling in the C programming language.\nThis library\u2014a partial libc\u2014implements the most common functions (e.g., read, write, open), allowing any developer to implement his own services with the usual compilers and development tools (e.g., gcc, g++, MS Visual Studio). For example, a web server could be implemented, linked with the provided libc and plugged within the Insight simulated scenarios.\nThe provided libc supports the most common system calls, but it is still incomplete and we were unable to compile complex open source applications. In spite of this, some services (e.g., a small DNS) and network tools (e.g., ipconfig,\n85\nnetstat) have been included in the simulation platform, and new system calls are planned to be supported in the future."}, {"heading": "6.5.2 Simulating Sockets", "text": "A hierarchy for file descriptors has been developed as shown in Fig. 6.4. File descriptors can refer (but they are not limited) to files, directories, sockets, or pipes. At the top of the hierarchy, the tree root shows the descriptor object which typically provides the operations for reading and writing data, closing and duplicating file descriptors, among other generic system calls.\nThe simulated sockets implementation spans in two kinds of supported sockets\nsubclasses:\n1. SocketDirect. This variety of sockets is optimized for the simulation on\none computer. Socket direct is fast: as soon as a connection is established, the client keeps a file descriptor pointing directly to the server\u2019s descriptor. Routing is only executed during the connection and the protocol control blocks (PCBs) are created as expected, but they are only used during connection establishment. Reading and writing operations between direct\n86\nsockets are carried out using shared memory. Since both sockets can access the shared memory area like regular working memory, this is a very fast way of communication.\n2. SocketReal. In some particular cases, we are interested in having full socket\nfunctionality. For example, the communication between Insight and the outside world is made using real sockets. As a result, this socket subclass wraps a real BSD socket of the underlying OS.\nSupport for routing and state-less firewalling was also implemented, supporting the simulating of attack payloads that connect back to the attacker, accept connections from the attacker or reuse the attack connection."}, {"heading": "6.5.3 The Exploits Database", "text": "When an exploit is raised, Insight has to decide whether the attack is successful or not depending on the environment conditions. For example, an exploit can require either a specific service pack installed in the target machine to be successful, or a specific library loaded in memory, or a particular open port, among others requirements. All these conditions vary over the time, and they are basically unpredictable from the attacker\u2019s standpoint. As a result, the behavior of a given exploit has been modeled using a probabilistic approach.\nIn order to determine the resulting behavior of the attack, Insight uses the Exploits Database showed in the architecture layout of Fig. 6.1. It has a XML tree structure. For example, if an exploit succeeds against a clean XP professional SP2 with 83% probability, or crashes the machine with 0.05% probability in other case; this could be expressed as follows:\n<database>\n<exploit id=\"sample exploit\">\n<requirement type=\"system\">\n<os arch=\"i386\" name=\"windows\" /> <win>XP</win> <edition>professional</edition> <servicepack>2</servicepack>\n</requirement> <results>\n87\n<agent chance=\"0.83\" /> <crash chance=\"0.05\" what=\"os\" /> <reset chance=\"0.00\" what=\"os\" /> <crash chance=\"0.00\" what=\"application\" /> <reset chance=\"0.00\" what=\"application\" />\n</results>\n</exploit> <exploit> ... </exploit> <exploit> ... </exploit> ...\n</database>\nThe conditions needed to install a new agent are described in the requirements section. It is possible to use several tags in this section, they specify the conditions which have influence on the execution of the exploit (e.g., OS required, a specific application running, an open port). The results section is a list of the relevant probabilities. In order, these are the chance of:\n1. successfully installing an agent,\n2. crashing the target machine,\n3. resetting the target machine,\n4. crashing the target application,\n5. and the chance of resetting the target application.\nTo determine the result, we follow this procedure: processing the lines in order, for each positive probability, choose a random value between 0 and 1. If the value is smaller than the chance attribute, the corresponding action is the result of the exploit.\nIn this example, we draw a random number to see if an agent is installed. If the value is smaller than 0.83, an agent is installed and the execution of the exploit is finished. Otherwise, we draw a second number to see if the OS crashes. If the value is smaller than 0.05, the OS crashes and the attacked machine becomes useless, otherwise there is no visible result. Other possible results could be: raising an IDS alarm, writing some log in a network device (e.g. firewall, IDS or router) or capturing a session id, cookie, credential or password.\n88\nThe exploits database allows us to model the probabilistic behavior of any exploit from the attacker\u2019s point of view, but how do we populate our database? A paranoid approach would be to assign a probability of success of 100% to every exploit. In that way, we would consider the case where an attacker can launch each exploit as many times as he wants, and will finally compromise the target machine with 100% probability (assuming the attack does not crash the system).\nA more realistic approach is to use statistics from real networks. Currently we are using the framework presented by Picorelli [Pic06] in order to populate the probabilities in the exploits database. This framework was originally implemented to assess and improve the quality of real exploits in QA environments. It allows us to perform over 500 real exploitation tests daily on several running configurations, spanning different target operating systems with their own setups and applications that add up to more than 160 OS configurations. In this context, a given exploit is executed against:\n\u2022 All the available platforms\n\u2022 All the available applications\nAll these tests are executed automatically using low end hardware, VMware servers, OS images and snapshots. The testing framework has been designed to improve testing time and coverage, and we have modified it in order to collect statistical information of the exploitation test results."}, {"heading": "6.5.4 Scheduler", "text": "The scheduler\u2019s main task is to assign the CPU resources to the different simulated actors (e.g. simulated machines and process). The scheduling iterates over the hierarchy machine-process-thread as a tree (like a depth-first search), each machine running its processes in round-robin.\nIn a similar way, running a process is giving all its threads the order to run until a system call is needed. Obviously, depending on the state of each thread, they run, change state or finish execution. The central issue is that threads execute systems calls and then (if possible) continue their activity until they finish or another system call is required.\n89\nInsight threads are simulated within real threads of the underlying OS. Simulated machines and processes are all running within one or several working processes (running hundreds of threads), and all of them are coordinated by a unique scheduler process called the master process. Thanks to this architecture, there is a very low loss of performance due to context switching7."}, {"heading": "6.5.5 File System", "text": "In order to handle thousands of files without wasting a huge amount of disk space, the file system simulation is accomplished by mounting shared file repositories. We are going to refer to these repositories as template file systems. For example, all simulated Windows XP systems could share a file repository with the default installation provided by Microsoft. These shared templates would have reading permission only. Thus, if a virtual machine needs to read or change a file, it will be copied within the local file system of the given machine.\nThis technique is known as copy-on-write. The fundamental idea is to allow multiple callers to ask for resources which are initially indistinguishable, giving them pointers to the same resource. This function can be maintained until a caller tries to modify its copy of the resource, at which point a true private copy is created to prevent the changes from becoming visible to everyone else. All of this happens transparently to the callers. The primary advantage is that no private copy needs to be created if a caller never makes any modification.\nAdditionaly, with the purpose of improving the simulator\u2019s performance, a file cache is implemented: the simulator saves the most recent accessed files (or block of files) in memory. In high scale simulated scenarios, it is very common to have several machines doing the same task at (almost) the same time8. If the data requested by these kind of tasks are in the file system cache, the whole system performance will improve, because less disk accesses would be required, even in scenarios of hundreds or thousands of simulated machines.\n7Because descriptors and pointers remain valid when switching from one machine to the other. 8For example, when the simulation starts up, all UNIX machines would read the boot script\nfrom /etc/initd file.\n90"}, {"heading": "6.6 Performance Analysis", "text": "To evaluate the performance of the simulator we run a test including a scenario with an increasing number of complete LANs with 250 computers each, simultaneously emulated. The tests only involve the execution of a network discovery on the complete LANs through a TCP connection to port 80. An original pen-testing module used for information was executed with no modifications, this was a design goal of the simulator, to use real unmodified attack modules when possible."}, {"heading": "Performance of the simulator", "text": ""}, {"heading": "LANs Computers Time (secs) Syscalls/sec", "text": "We can observe the decrease of system calls processed per second as we increase the number of simulated computers as Insight was run on a single real computer with limited resources. Nevertheless, the simulation is efficient because system calls are required on demand by the connections of the module gathering the information of the networks through TCP connections."}, {"heading": "6.7 Applications", "text": "We have created a playground to experiment with cyber-attack scenarios which has several applications. The most important are:\nAttack Planning. This is the main application. In Chapter 5 we used this sim-\nulator to test attack planning algorithms in a variety of scenarios.\nData collection and visualization. Having the complete network scenario in\none computer allows an easy capture and log of system calls and network traffic. This information is useful for analyzing and debugging real pen-test tools and their behavior in complex scenarios. Some efforts have been made\n91\nto visualize attack pivoting and network information gathering using the platform presented.\nPentest training. Our simulation tool is already being used in Pentest courses.\nIt provides reproducible scenarios, where students can practice the different steps of a pentest: information gathering, attack and penetrate, privilege escalation, local information gathering and pivoting.\nThe simulation allows the student to grasp the essence of pivoting. Setting up a real laboratory where pivoting makes sense is an expensive task, whereas our tool requires only one computer per student (and in the case of a network / computer crash, the simulation environment can be easily reset). Configuring new scenarios with more machines or more complex topologies is easy, as a scenario wizard is provided.\nIn Pentest classes with Insight, the teacher can check the logs to see if students used the right tools with the correct parameters. He can test the students\u2019 ability to plan and see if they avoided performing unnecessary actions. The teacher can also identify their weaknesses as pentesters and plan new exercises to work on these. The students can be evaluated: success, performance, stealth and quality of reports can be measured.\nWorm Spreading Analysis. The lightweight design of the platform allows the\nsimulation of socket/network behavior of thousands of computers, providing a good framework for research on worm infestation and spreading. It should be possible to develop very accurate applications to mimic worm behavior using the Insight C programming API. There are available abstract modeling [CGK03] or high-fidelity discrete event [WMS05] studies but no system call level recreation of attacks like the one we propose as future application of this platform.\nAnalysis of countermeasures. Duplication of the production configuration on\na simulated staging environment accurately mimicking or mirroring the security aspects of an organization\u2019s network allows the anticipation of software/hardware changes and their impact on security. For example, you can answer questions like \u201cWill the network avoid attack vector A if firewall rule R is added to the complex rule set S of firewall F?\u201d\n92\nImpact of 0-day vulnerabilities. The simulator can be used to study the im-\npact of 0-days (vulnerabilities that have not been publicly disclosed) in your network. How is that possible, if we do not know current 0-days? But we can model the existence of 0-day vulnerabilities based on statistics. In our security model, the specific details of the vulnerability are not needed to study the impact on the network, just that it may exist with a measurable probability.\nC u\nm la\nte d\np r\nb a\nb ili ty u o\nThat information can be gathered from public vulnerability databases: the discovery date, exploit date, disclosure date and patch date are found in several public databases of vulnerabilities and exploits [CER, Secb, Seca, FrS].\nThe risk of a 0-day vulnerability is given by the probability of an attacker discovering and exploiting it. Although we do not have data about the security underground, the probabilities given by public information are a lower bound indicator.\nAs shown in [FMFP06], the risk posed by a vulnerability exists before the discovery date, augments as an exploit is made available for the vulnerability, and when the vulnerability is disclosed. The risk only diminishes as a patch becomes available and users apply the patches (and workarounds).\n93\nThe probability of discovery, and the probability of an exploit being developed, can be estimated as a function of the time before disclosure (see Fig. 6.5 taken from [FMFP06]). For Microsoft products, we have visibility of upcoming disclosures of vulnerabilities: every month (on patch Tuesday) on average 9.40 patches are released (high and medium risk). Based on those dates we estimate the probability that the vulnerabilities were discovered and exploited during the months before disclosure."}, {"heading": "6.8 Summary", "text": "We have created a playground to experiment with cyber-attack scenarios. The framework is based on a probabilistic attack model\u2014that model is also used by attack planning tools developed in our lab. By making use of the proxy syscalls technology, and simulating multiplatform agents, we were able to implement a simulation that is both realistic and lightweight, allowing the simulation of networks with thousands of hosts.\nThe framework provides a global view of the scenarios. It is centered on the attacker\u2019s point of view, and designed to increase the size and complexity of simulated scenarios, while remaining realistic for the attacker.\nThe value of this framework is given by its multiple applications:\n\u2022 Systematic study of Attack Planning techniques.\n\u2022 Evaluation of network security.\n\u2022 Evaluation of security countermeasures.\n\u2022 Anticipating the risk posed by 0-day vulnerabilities.\n\u2022 Pentest training.\n\u2022 Worm spreading analysis.\n\u2022 Data generation to test visualization techniques.\nPart II"}, {"heading": "Development of a Probabilistic", "text": ""}, {"heading": "Attack Planner", "text": "94\nChapter 7"}, {"heading": "Probabilistic Attack Planning", "text": "We have presented in Chapter 5 an approach to the attack planning problem based on modeling the actions and assets in the PDDL language, and using off-the-shelf AI tools to generate attack plans. This approach however is limited. In particular, the planning is classical (the actions are deterministic) and thus not able to handle the uncertainty involved in this form of attack planning.\nIn this chapter we contribute a planning model that does capture the uncertainty about the results of the actions, which is modeled as a probability of success of each action. We present efficient planning algorithms, specifically designed for this problem, that achieve industrial-scale runtime performance (able to solve scenarios with several hundred hosts and exploits). These algorithms take into account the probability of success of the actions and their expected cost (for example in terms of execution time, or network traffic generated). We thus show that probabilistic attack planning can be solved efficiently for the scenarios that arise when assessing the security of large networks (under certain simplifying assumptions that will be discussed during the chapter).\nTwo \u201cprimitives\u201d are presented, which are used as building blocks in a framework separating the overall problem into two levels of abstraction. We also present the experimental results obtained with our implementation, and conclude with some ideas for further work."}, {"heading": "7.1 Introduction", "text": "Penetration testing is one of the most trusted ways of assessing the security of networks large and small. The result of a penetration test is a repeatable set of steps that result in the compromise of particular assets in the network. As we have discussed in Chapter 2, penetration testing frameworks have been developed\n95\n96\nto facilitate the work of penetration testers and make the assessment of network security more accessible to non-expert users.\nIn Section 2.4 we discussed how the evolution of pentesting tools \u2013 covering new attack vectors, and shipping increasing numbers of exploits and information gathering techniques \u2013 created the need to automate the control of the pentest framework. This is what we call the attack planning problem. This problem was introduced to the AI planning community by Boddy et al. as the \u201cCyber Security\u201d domain [BGHH05]. In the pentesting industry, Lucangeli et al. proposed a solution based on modeling the actions and assets in the PDDL language,1 and using off-the-shelf planners to generate attack plans [LSR10]. Using PDDL to work with attack graphs has also been explored in [GG09]. Herein we are concerned with the specific context of regular automated pentesting, as in \u201cCore Insight Enterprise\u201d tool, and use the term \u201cattack planning\u201d in that sense.\nRecently, a model based on partially observable Markov decision processes (POMDP) was proposed [SBH11] (this is the subject of Chapter 8). This grounded the attack planning problem in a well-researched formalism, and provided a precise representation of the attacker\u2019s uncertainty with respect to the target network. In particular, the information gathering phase was modeled as an integral part of the planning problem. However, as the authors show, this solution does not scale to medium or large real-life networks.\nIn this chapter, we take a different direction: the uncertainty about the results of the actions is modeled as a probability of success of each action, whereas in [SBH11] the uncertainty is modeled as a distribution of probabilities over the states. This allows us to produce an efficient planning algorithm, specifically designed for this problem, that achieves industrial-scale runtime performance.\nOf course planning in the probabilistic setting is far more difficult than in the deterministic one. We do not propose a general algorithm, but a solution suited for the scenarios that need to be solved in a real world penetration test. In particular, we make simplifying assumptions about the actions and the machines, namely supposing that the actions and machines are independent from each other. In the trade-off between realism of the model and scalability of the resulting planning problem, we chose here to prioritize scalability. The computational complexity of\n1PDDL stands for Planning Domain Definition Language. Refer to [FL03] for a specification of PDDL 2.1.\n97\nour planning solution is O(n log n), where n is the total number of actions in the case of an attack tree (with fixed source and target hosts), and O(M2 \u00b7 n log n) where M is the number of machines in the case of a network scenario. With our implementation, we were able to solve planning in scenarios with up to 1000 hosts distributed in different networks.\nWe start with a brief review of the attack model in Section 7.2, then continue with a presentation of two \u201cprimitives\u201d in Sections 7.3 and 7.4. These primitives are applied in more general settings in Sections 7.5 and 7.6. Section 7.7 shows experimental results from the implementation of these algorithms. We conclude with some ideas for future work."}, {"heading": "7.2 The Attack Model", "text": "We summarize below the basic background from the conceptual model of computer attacks presented in Chapter 3 (for more details refer to [AR03, FNRS03, Ric03, RT07]), and further develop some aspects of the model like the actions\u2019 costs. This model is based on the concepts of assets, goals, agents and actions. In this description, an attack involves a set of agents, executing sequences of actions, obtaining assets (which can be information or actual modifications of the real network and systems) in order to reach a set of goals.\nAn asset can represent anything that an attacker may need to obtain during the course of an attack, including the actual goal. Examples of assets: information about the Operating System (OS) of a host H; TCP connectivity with host H on port P ; an Agent installed on a given host H. To install an agent means to break into a host, take control of its resources, and eventually use it as pivoting stone to continue the attack by launching new actions based from that host.\nThe actions are the basic steps which form an attack. Actions have requirements (also called preconditions) and a result: the asset that will be obtained if the action is successful. For example, consider the exploit IBM Tivoli Storage Manager Client Remote Buffer Overflow 2 for the vulnerabilities in dsmagent described by CVE-2008-4828. The result of this action is to install an agent, and it requires that the OS of the target host is Windows 2000, Windows XP, Solaris 10,\n2The particular implementations that we have studied are the exploit modules for Core Impact and Core Insight Enterprise, although the same model can be applied to other implementations, such as Metasploit.\n98\nWindows 2003, or AIX 5.3. In this model, all the exploits (local, remote, clientside, webapps) are represented as actions. Other examples of actions are: TCP Network Discovery, UDP Port Scan, DCERPC OS Detection, TCP Connectivity Probe.\nThe major differences between the attack model used in this work and the attack graphs used in [AWK02, JNO05, JSW02, PS98, RA00, SHJ+02] are twofold: to improve the realism of the model, we consider that the actions can produce numerical effects (for example, the expected running time of each action); and that the actions have a probability of success (which models the uncertainty about the results of the action)."}, {"heading": "7.2.1 Deterministic Actions with Numerical Effects", "text": "In the deterministic case, the actions and assets that compose a specific planning problem can be successfully represented in the PDDL language. This idea was proposed in [SW08] and further analyzed in [LSR10], and treated in Chapter 5 of this thesis. The assets are represented as PDDL predicates, and the actions are translated as PDDL operators. The authors show how this PDDL representation allowed them to integrate a penetration testing tool with an external planner, and to generate attack plans in realistic scenarios. The planners used \u2013 MetricFF [Hof02] and SGPlan [CWH06] \u2013 are state-of-the-art planners able to handle numerical effects.\nFig. 7.1 shows an example of a PDDL action: an exploit for the IBM Tivoli vulnerability, that will attempt to install an agent on target host t from an agent previously installed on the source host s. To be successful, this exploit requires that the target runs a specific OS, has the service mil-2045-47001 running and listening on port 1581.\nThe average running times of the exploits are measured by executing all the exploits of the penetration testing tool in a testing lab. More specifically, in Core\u2019s testing lab there are more than 748 virtual machines with different OS and installed applications, where all the exploits of Core Impact are executed every night [Pic06]."}, {"heading": "7.2.2 Actions\u2019 Costs", "text": "The execution of an action has a multi-dimensional cost. We detail below some values that can be measured (and optimized in an attack):\nExecution time: Average running time of the action.\nNetwork traffic: The amount of traffic sent over the network increases the level\nof noise produced.\nIDS detection: Logs lines generated and alerts triggered by the execution of the\naction increase the noise produced.\nHost resources: The execution of actions will consume resources of both the\nlocal and remote host, in terms of CPU, RAM, hard disc usage, etc.\nTraceability of the attack: Depends on the number of intermediate hops and\ntopological factors.\nZero-day exploits: Exploits for vulnerabilities that are not publicly known are\na valuable resource, that should be used only when other exploits have failed (the attacker usually wants to minimize the use of \u201c0-days\u201d).\nIn our experiments, we have chosen to optimize the expected execution time. In the context of regular penetration tests, minimizing the expectation of total\n100\nexecution time is a way of maximizing the amount of exploits successfully launched in a fixed time frame (pentests are normally executed in a bounded time period).\nHowever, the same techniques can be applied to any other scalar cost, for example to minimize the noise produced by the actions (and the probability of being detected). The issue of measuring the costs of the exploits, and more generally of evaluating Exploit Quality Metrics, was more recently discussed in [Sar11a]."}, {"heading": "7.2.3 Probabilistic Actions", "text": "Another way to add realism to the attack model is to consider that the actions are nondeterministic. This can be modeled by associating probabilities to the outcomes of the actions. In the case of an exploit, the execution of the exploit can be successful (in that case the attacker takes control of the target machine) or a failure. This is represented by associating a probability of success to each exploit.\nThe probability of success is conditional: it depends on the environment conditions. For example, the IBM Tivoli exploit for CVE-2008-4828 is more reliable (has a higher probability of success) if the OS is Solaris since it has no heap protection, the stack is not randomized and is executable by default. Alternatively, the exploit is less reliable (has a lower probability of success) if the OS is Windows XP SP2 or Windows 2003 SP1, with Data Execution Prevention (DEP) enabled. On Windows Vista, the addition of Address Space Layout Randomization (ASLR) makes the development of an exploit even more difficult, and diminishes its probability of success. In practice, the probability of success of each exploit is measured by exhaustively executing the exploit against a series of targets, covering a wide range of OS and application versions.\nAlthough it improves the realism of the model, considering probabilistic actions also makes the planning problem more difficult. Using general purpose probabilistic planners did not work as in the deterministic case; for instance, we experimented with Probabilistic-FF [DH07] with poor results, since it was able to find plans in only very small cases.\nIn the rest of this chapter, we will study algorithms to find optimal attack paths in scenarios of increasing difficulty. We first describe two primitives, and then apply them in the context of regular automated pentesting. In these scenarios we make an additional hypothesis: the independence of the actions. Relaxing this hypothesis is a subject for future work.\n101\n7.3 The Choose Primitive\nWe begin with the following basic problem. Suppose that the attacker (i.e. pentester) wants to gain access to the credit cards stored in a database server H by installing a system agent. The attacker has a set of n remote exploits that he can launch against that server. These exploits result in the installation of a system agent when successful (see Fig. 7.2).\nIn this scenario, the attacker has already performed information gathering about the server H, collecting a list of open/closed ports, and running an OS detection action such as Nmap. The pentesting tool used provides statistics on the probability of success and expected running time for each exploit in the given conditions.3 The attacker wants to minimize the expected execution time of the whole attack. A more general formulation follows:\nProblem 7.1. Let g be a fixed goal, and let {A1, . . . , An} be a set of n independent actions whose result is g. Each action Ak has a probability of success pk and expected cost tk. Actions are executed until an action is successful and provides the goal g (or all the actions fail). Task: Find the order in which the actions must be executed in order to minimize the expected total cost.\nAs already stated, we make the simplifying assumption that the probability of success of each action is independent from the others. If the actions are executed in the order A1, . . . , An, using the notation pi = 1 \u2212 pi, the expected cost can be written as\nT{1...n} = t1 + p1 t2 + . . .+ p1 p2 . . . pn\u22121 tn. (7.1)\n3In our experiments we used the database of tests of Core Impact and Core Insight Enterprise.\n102\nThe probability of success is given by\nP{1...n} = p1 + p1 p2 + p1 p2 p3 + . . .+ p1 . . . pn\u22121 pn,\nand the complement P{1...n} = p1 p2 . . . pn. In particular this shows that the total probability of success does not depend on the order of execution.\nEven though this problem is very basic, we didn\u2019t find references to its solution.\nThis is why we give below some details on the solution that we found.\nLemma 7.2. Let A1, . . . , An be actions such that t1/p1 6 t2/p2 6 . . . 6 tn/pn. Then T{1...n\u22121} P{1...n\u22121} 6 tn pn . Proof. We prove it by induction. The case with two actions is trivial, since we know by hypothesis that t1/p1 6 t2/p2. For the inductive step, suppose that the proposition holds for n \u2212 1 actions. Consider the first three actions A1, A2, A3. The inequality\nT{12} P{12} 6 t3 p3\nholds if and only if t2/p2 6 t3/p3. So the first two actions can be considered as a single action A12 with expected cost (e.g. running time) T{12} and probability of success P{12}. We have reduced to the case of n \u2212 1 actions, and we can use the induction hypothesis to conclude the proof.\nProposition 7.3. A solution to Problem 7.1 is to sort the actions according to the coefficient tk/pk (in increasing order), and to execute them in that order. The complexity of finding an optimal plan is thus O(n log n).\nProof. We prove it by induction. We begin with the case of two actions Ai and Aj such that ti/pi 6 tj/pj. It follows easily that \u2212pitj 6 \u2212pjti and that\nti + (1\u2212 pi) tj 6 tj + (1\u2212 pj) ti.\nFor the inductive step, suppose for the moment that the actions are numbered so that t1/p1 6 . . . 6 tn/pn, and that the proposition holds for all sets of n \u2212 1 actions. We have to prove that executing A1 first is better that executing any other action Ak for all k 6= 1. We want to show that\nt1 + \u2211 26i6n ti \u00b7 \u220f 16j6i\u22121 pj\n6 tk + \u2211\n16i6n, i 6=k\nti \u00b7 pk \u00b7 \u220f\n16j6i\u22121, j 6=k\npj.\n103\nNotice that in the two previous sums, the coefficients of tk+1, . . . , tn are equal in both expressions. They can be simplified, and using notations previously introduced, the inequality can be rewritten\nT{1...k\u22121} + P{1...k\u22121} tk 6 tk + pk T{1...k\u22121}\nwhich holds if and only if T{1...k\u22121} P{1...k\u22121} 6 tk pk which is true by Lemma 7.2. We have reduced the problem to sorting the coefficients tk/pk. The complexity is that of making the n divisions tk/pk and sorting the coefficients. Thus it is O(n+ n log n) = O(n log n).\nWe call this the choose primitive because it tells you, given a set of actions, which action to choose first: the one that has the smallest t/p value. In particular, it says that you should execute first the actions with smaller cost (e.g. runtime) or higher probability of success, and precisely which is the trade-off between these two dimensions.\nThe problem of choosing the order of execution within a set of exploits is very common in practice. In spite of that, the automation methods currently implemented in penetration testing frameworks offer an incomplete solution,4 over which the one proposed here constitutes an improvement.\n7.4 The Combine Primitive"}, {"heading": "7.4.1 Predefined Strategies", "text": "We now consider the slightly more general problem where the goal g can be obtained by predefined strategies. We call strategy a group of actions that must be executed in a specific order. The strategies are a way to incorporate the expert knowledge of the attacker in the planning system (cf. the opening moves in chess). This idea has been used in the automation of pentesting tools, see [SW08].\n4As of July 2011, Immunity Canvas [Ait04] doesn\u2019t provide automated execution of exploits; Metasploit [Moo10] has a feature called \u201cautopwn\u201d that launches all the exploits available for the target ports in arbitrary order; Core Impact Pro launches first a set of \u201cfast\u201d exploits and then \u201cbrute-force\u201d exploits [SW08], but arbitrary order is used within each set; Core Insight Enterprise uses planning techniques based on a PDDL description [LSR10] that takes into account the execution time but not the probability of success of the exploits.\n104\nFor example consider an attacker who has installed an agent with low privileges on a host H running Windows XP, and whose goal is to obtain system privileges on that host. The attacker has a set of n predefined strategies to perform this privilege escalation (see Fig. 7.3). An example of a strategy is: refine knowledge of the OS version; verify that the edition is Home or Professional, with SP2 installed; get users and groups; then launch the local exploit Microsoft NtUserMessageCall Kernel Privilege Escalation that (ab)uses the vulnerability CVE-2008-1084. More generally:\nProblem 7.4. Let g be a fixed goal, and {G1, . . . , Gn} a set of n strategies, where each strategy Gk is a group of ordered actions. For a strategy to be successful, all its actions must be successful. As in Problem 7.1, the task is to minimize the expected total cost.\nIn this problem, actions are executed sequentially, choosing at each step one action from one group, until the goal g is obtained. Considering only one strategy G, we can calculate its expected cost and probability of success. Suppose the actions of G are {A1, . . . , An} and are executed in that order. Then the expected cost (e.g. expected runtime) of the group G is\nTG = t1 + p1 t2 + p1 p2 t3 + . . .+ p1 p2 . . . pn\u22121 tn\nand, since all the actions must be successful, the probability of success of the group is simply PG = p1 p2 . . . pn (again, we suppose that the actions are independent).\n105\nProposition 7.5. A solution to this problem is to sort the strategies according to the coefficient TG/PG (smallest value first), and execute them in that order. For each strategy group, execute the actions until an action fails or all the actions are successful.\nProof. In this problem, an attack plan could involve choosing actions from different groups without completing all the actions of each group. But it is clear that this cannot happen in an optimal plan.\nIn effect, suppose that there are only two groups GA and GB, whose actions are {A1, . . . , As} and {B1, . . . , Bt} respectively. Suppose that in the optimal plan As precedes Bt. Suppose also that the execution of an action Bj 6= Bt precedes the execution of As. Executing Bj will not result in success (that requires executing Bt as well), and it will delay the execution of As by the expected running time of Bj. Thus to minimize the expected total running time, a better solution can be obtained by executing Bj after the execution of As. This contradiction shows that all the actions of GB must be executed after As in an optimal solution. This argument can be easily extended to any number of groups.\nSo an optimal attack plan consists in choosing a group and executing all the actions of that group. Since the actions of each group G are executed one after the other, they can be considered as a single action with probability PG and expected time TG. Using the choose primitive, it follows that groups should be ordered according to the coefficients TG/PG."}, {"heading": "7.4.2 Multiple Groups of Actions", "text": "We extend the previous problem to consider groups of actions bounded by an AND relation (all the actions of the group must be successful in order to obtain the result g), but where the order of the actions is not specified. The difference with Problem 7.4 is that now we must determine the order of execution within each group.\nFig. 7.4 shows an example of this situation. A System Agent can be installed by using a Remote exploit, a Client-side exploit or a SQL injection in a web application. Each of these actions has requirements represented as assets, which can be fulfilled by the actions represented on the second layer. For example, before executing the Remote exploit, the attacker must run a Host probe (to\n106\nverify connectivity with the target host), Port probe (to verify that the target port of the exploit is open), and an OS Detection module (to verify the OS of the target host).\nProblem 7.6. Same as Problem 7.4, except that we have n groups {G1, . . . , Gn} of unordered actions. If all the actions in a group are successful, the group provides the result g.\nProposition 7.7. Let G = {A1, . . . , An} be a group of actions bounded by an AND relation. To minimize the expected total cost, the actions must be ordered according to the coefficient tk/(1\u2212 pk).\nProof. If the actions are executed in the order A1, . . . , An, then the expected cost is\nTG = t1 + p1 t2 + . . .+ p1 p2 . . . pn\u22121 tn (7.2)\nThis expression is very similar to equation (7.1). The only difference is that costs are multiplied by pk instead of pk. So in this case, the optimal solution is to order the actions according to the coefficient tk/pk = tk/(1\u2212 pk).\nIntuitively the actions that have higher probability of failure have higher priority, since a failure ends the execution of the group. The coefficient tk/(1 \u2212 pk) represents a trade-off between cost (time) and probability of failure.\n107\nWrapping up the previous results, to solve Problem 7.6, first order the actions in each group according to the coefficient t/(1 \u2212 p) in increasing order. Then calculate for each group G the values TG and PG. Order the groups according to the coefficient TG/PG, and select them in that order. For each group, execute the actions until an action fails or all the actions are successful.\nWe call it the combine primitive, because it tells you how to combine a group of actions and consider them (for planning purposes) as a single action with probability of success PG and expected running time TG."}, {"heading": "7.5 Using the Primitives in an Attack Tree", "text": "We apply below the choose and the combine primitives to a probabilistic attack tree, where the nodes are bounded by AND relations and OR relations. The tree is composed of two types of nodes, distributed in alternating layers of asset nodes and action nodes (see Fig. 7.5)."}, {"heading": "Asset", "text": "An asset node is connected by an OR relation to all the actions that provide this asset: for example, an Agent asset is connected to the Exploit actions that may install an agent on the target host.\nAn action node is connected by an AND relation to its requirements: for example, the local exploit Microsoft NtUserMessageCall Kernel Privilege Escalation requires an agent asset (with low level privileges) on the target host H, and a Windows XP OS asset for H.\n108\nThe proposed solution is obtained by composing the primitives from previous sections. In the AND-OR tree, the leaves that are bounded by an AND relation can be considered as a single node. In effect, using the combine primitive, that group G can be considered as a single action with compound probability of success PG and execution time TG.\nThe leaves that are bounded by an OR relation can also be (temporarily) considered as a single node. In effect, in an optimal solution, the node that minimizes the t/p coefficient will be executed first (using the choose primitive), and be considered as the cost of the group in a single step plan.\nBy iteratively reducing groups of nodes, we build a single path of execution that minimizes the expected cost. After executing a step of the plan, the costs may be modified and the shape of the graph may vary. Since the planning algorithm is very efficient, we can replan after each execution and build a new path of execution. We are assured that before each execution, the proposed attack plan is optimal given the current environment knowledge and within the horizon of a single next step. It is still only an approximation to the global optimal plan, whose computation requires a much powerful (and computationally expensive) framework such as the POMDP framework of Chapter 8."}, {"heading": "7.5.1 Constructing the Tree", "text": "We briefly describe how to construct a tree beginning with an agent asset (e.g. the objective is to install an agent on a fixed machine). Taking this goal as root of the tree, we recursively add the actions that can complete the assets that appear in the tree, and we add the assets required by each action.\nTo ensure that the result is a tree and not a DAG, we make an additional independence assumption: the assets required by each action are considered as independent (i.e. if an asset is required by two different actions, it will appear twice in the tree).\nThat way we obtain an AND-OR tree with alternating layers of asset nodes and action nodes (as the one in Fig. 7.5). The only actions added are Exploits, TCP/UDP Connectivity checks, and OS Detection modules. These actions don\u2019t have as requirements assets that have already appeared in the tree, in particular the tree only has one agent asset (the root node of the tree). So, by construction,\n109\nwe are assured that no loops will appear, and that the depth of the tree is very limited.\nWe construct the tree in this top-down fashion, and as we previously saw, we can solve it bottom-up to obtain as output the compound probability of success and the expected running time of obtaining the goal agent."}, {"heading": "7.6 The Graph of Distinguished Assets", "text": "In this section we use the previous primitives to build an algorithm for attack planning in arbitrary networks, by making an additional assumption of independence between machines. First we distinguish a class of assets, namely the assets related with agents. We refer to them as distinguished assets. At the PDDL level, the predicates associated with the agents are considered as a separate class.\nPlanning is done in two different abstraction levels: in the first level, we evaluate the cost of compromising one target distinguished asset from one fixed source distinguished asset. More concretely, we compute the cost and probability of obtaining a target agent given a source agent. At this level, the attack plan must not involve a third agent. The algorithm at the first level is thus to construct the attack tree and compute an attack plan as described in Section 7.5.\nAt the second level, we build a directed graph G = (V , E) where the nodes are distinguished assets (in our scenario, the hosts in the target network where we may install agents), and the edges are labeled with the compound probability and expected time obtained at the first level. Given this graph, an initial asset s \u2208 V (the local agent of the attacker) and a final asset g \u2208 V (the goal of the attack), we now describe two algorithms to find a path that approximates the minimal expected time of obtaining the goal g.\nThe first algorithm is a modification of Floyd-Warshall\u2019s algorithm to find shortest paths in a weighted graph. Let M = |V| be the number of machines in the target network. By executing M2 times the first level procedure, we obtain two functions: the first is Prob(i, j) which returns the compound probability of obtaining node j from node i (without intermediary hops), or 0 if that is not possible in the target network; the second is Time(i, j) which returns the expected time of obtaining node j directly from node i, or +\u221e if that is not possible. The procedure is described in Algorithm 1.\n110\nAlgorithm 1 Modified Floyd-Warshall\nP [i, j]\u2190 Prob(i, j) \u2200 1 \u2264 i, j \u2264M T [i, j]\u2190 Time(i, j) \u2200 1 \u2264 i, j \u2264M for k = 1 to M do\nfor i = 1 to M do\nfor j = 1 to M do\nT \u2032 \u2190 T [i, k] + P [i, k]\u00d7 T [k, j] P \u2032 \u2190 P [i, k]\u00d7 P [k, j] if T \u2032/P \u2032 < T [i, j]/P [i, j] then\nT [i, j]\u2190 T \u2032 P [i, j]\u2190 P \u2032\nreturn \u3008T, P \u3009\nWhen the execution of this algorithm finishes, for each i, j the matrices contain the compound probability P [i, j] and the expected time T [i, j] of obtaining the node j starting from the node i. This holds in particular when i = s (the source of the attack) and j = g (the goal of the attack). The attack path is reconstructed just as in the classical Floyd-Warshall algorithm.\nIn a similar fashion, Dijkstra\u2019s shortest path algorithm can be modified to use\nthe choose and combine primitives. See the description of Algorithm 2.\nWhen execution finishes, the matrices contain the compound probability P [v] and the expected time T [v] of obtaining the node v starting from the node s. Using the modified Dijkstra\u2019s algorithm has the advantage that its complexity is O(M2) instead of O(M3) for Floyd-Warshall. Let n be the number of actions that appear in the attach trees, this gives us that the complexity of the complete planning solution is O(M2 \u00b7 n log n+M2) = O(M2 \u00b7 n log n)."}, {"heading": "7.7 Our implementation", "text": "We have developed a proof-of-concept implementation of these ideas in the Python language. This planner takes as input a description of the scenario in the PPDDL language, an extension of PDDL for expressing probabilistic effects [YL04].\nOur main objective was to build a probabilistic planner able to solve scenarios with 500 machines, which was the limit reached with classical (deterministic)\n111\nAlgorithm 2 Modified Dijkstra\u2019s algorithm\nT [s] = 0, P [s] = 1 T [v] = +\u221e, P [v] = 0 \u2200v \u2208 V , v 6= s S \u2190 \u2205 Q\u2190 V (where Q is a priority queue) while Q 6= \u2205 do\nu\u2190 arg minx\u2208Q T [x]/P [x] Q\u2190 Q\\{u}, S \u2190 S \u222a {u} for all v \u2208 V\\S adjacent to u do\nT \u2032 = T [u] + P [u]\u00d7 Time(u, v) P \u2032 = P [u]\u00d7 Prob(u, v) if T \u2032/P \u2032 < T [v]/P [v] then\nT [v]\u2190 T \u2032 P [v]\u2190 P \u2032\nreturn \u3008T, P \u3009\nplanning solutions in [LSR10]. Additionally we wanted to tame memory complexity, which was the limiting factor. The planner was integrated with the pentesting framework Core Impact, using the procedures previously developed for the work [LSR10]. The architecture of this solution is described in Fig. 7.6.\nThis planner solves the planning problem by breaking it into two levels as described in Section 7.6. On the higher level, a graph representation of goal objects is built. More concretely, there is a distinguished node for each host. The directed\n112\nedges in this graph are obtained by carrying out the tree procedure described in Section 7.5.1, obtaining a value for the probability and the cost of obtaining the predicate represented by the target node, when the predicate represented by the source node is true.\nThe final plan can then be determined by using the modified versions of Dijkstra and Floyd-Warshall algorithms. The figures that follow show the planner running time using the modified Dijkstra\u2019s algorithm."}, {"heading": "7.7.1 Testing and Performance", "text": "The experiments were run on a machine with an Intel Core2 Duo CPU at 2.4 GHz and 8 GB of RAM. We focused our performance evaluation on the number of machines M in the attacked network. We generated a network consisting of five subnets with varying number of machines, all joined to one main network to which the attacker initially has access.\nFig. 7.7 shows the memory consumption of this planning solution, which clearly grows linearly with M . Our current implementation manages to push the network size limit up to 1000 machines, and brings memory consumption under control.5\n5By contrast, in [LSR10] the hard limit was memory: in scenarios with 500 machines we ran out of memory in a computer with 8 GB of RAM. The memory consumption growth was clearly exponential, for instance 400 machines used 4 GB of RAM. This was difficult to scale up.\n113\nFor M = 1000, we are using less than 1 GB of RAM, with a planner completely written in Python (not optimized in terms of memory consumption).\nFig. 7.8 shows the growth of solver running time, which seems clearly quadratic, whereas in [LSR10] the growth was exponential. It should be noted however that, comparing only up to 500 machines, running times are slightly worse than those of the solution based on deterministic planners. This can be improved: since our planner is written in Python, a reasonable implementation in C of the more CPU intensive loops should allow us to lower significantly the running time.\nAnd of course we added a notion of probability of success that wasn\u2019t present before. As a comparison, in another approach that accounts for the uncertainty about the attacker\u2019s actions [SBH11], the authors use off-the-shelf solvers, managing to solve scenarios with up to 7 machines \u2013 and are thus still far from the network sizes reached here.\nBoth curves are compared in Fig. 7.9 showing the quadratic growth of solver runtime. In the testing scenarios, the nodes are fully connected, so we have to solve a quadratic number of attack trees. This figure also confirms in practice the computed complexity.\nAn interesting characteristic of the solution proposed is that it is inherently parallelizable. The main workload are the M2 executions of the first level procedure of Section 7.6. This could be easily distributed between CPUs or GPUs to\n114\nobtain a faster planner. Another possible improvement is to run the planner \u201cin the cloud\u201d with the possibility of adding processors on demand."}, {"heading": "7.8 Related Work", "text": "Early work on attack graph solving relied on model checking techniques [JSW02, SHJ+02], with their inherent scalability restrictions; or on monotonicity assumptions [AWK02, NEJ+09, NJ05] that are not able to express situations in which compromised resources are lost due to crashes, detection or other unforeseen circumstances.\nThe first application of planning techniques and PDDL solving for the security realm was [BGHH05], however this application was not focused on finding actual attack paths or driving penetration testing tools. In [GG09] attack paths are generated from PDDL description of networks, hosts and exploits, although the scenarios studied do not cover realistic scales. Previous work by the authors [LSR10] addresses this limitation by solving scenarios with up 500 machines, and feeding the generated attack plans to guide a penetration testing tool. However, this work does not include probabilistic considerations. Recent work [EKMM11] also manages to provide attack paths to a penetration testing tool, in this case the Metasploit Framework, but again does not include probabilistic considerations.\n115\nPrevious work by one of the authors [SBH11] takes into account the uncertainty about the result of the attacker\u2019s actions. This POMDP-based model also accounts for the uncertainty about the target network, addressing information gathering as an integral part of the attack, and providing a comprehensive notion of attack planning under uncertainty. However, as previously stated, this solution does not scale to medium or large real-life networks."}, {"heading": "7.9 Summary and Future Work", "text": "We have shown in this chapter an extension of established attack graphs models, that incorporates probabilistic effects, and numerical effects (e.g. the expected running time of the actions). This model is more realistic than the deterministic setting, but introduces additional difficulties to the planning problem. We have demonstrated that under certain assumptions, an efficient algorithm exists that provides optimal attack plans with computational complexity O(n log n), where n is the number of actions and assets in the case of an attack tree (between two fixed hosts), and O(M2 \u00b7 n log n) where M is the number of machines in the case of a network scenario.\nOver the last years, the difficulties that arose in our research in attack planning were related to the exponential nature of planning algorithms (especially in the probabilistic setting), and our efforts were directed toward the aggregation of nodes and simplification of the graphs, in order to tame the size and complexity of the problem. Having a very efficient algorithm in our toolbox gives us a new direction of research: to refine the model, and break down the actions in smaller parts, without fear of producing an unsolvable problem.\nA future step in this research is thus to analyze and divide the exploits into basic components. This separation gives a better probability distribution of the exploit execution. For example, the Debian OpenSSL Predictable Random Number Generation Exploit \u2013 which exploits the vulnerability CVE-2008-0166 reported by Luciano Bello \u2013 brute forces the 32,767 possible keys. Each brute forcing iteration can be considered as a basic action, and be inserted independently in the attack plan. Since the keys depend on the Process ID (PID), some keys are more probable than others.6 So the planner can launch the Debian OpenSSL PRNG\n6The OpenSSL keys generated in vulnerable Debians only depend on the PID. Since Secure\n116\nexploit, execute brute forcing iterations for the more probable keys, switch to others exploits and come to back to the Debian PRNG exploit if the others failed. This finer level of control over the exploit execution should produce significant gains in the total execution time of the attack.\nOther research directions in which we are currently working are to consider actions with multidimensional numeric effects (e.g. to minimize the expected running time and generated network traffic simultaneously); and to extend the algorithm to solve probabilistic attack planning in Directed Acyclic Graphs (DAG) instead of trees. In this setting, an asset may influence the execution of several actions. This relaxes the independence assumption of Sections 7.4.2 and 7.5. Although finding a general algorithm that scales to the network sizes that we consider here seems a difficult task, we believe that efficient algorithms specifically designed for network attacks scenarios can be found.\nShell usually generates the key in a new installation, PIDs between 2,000 and 5,000 are more probable than the others.\nPart III"}, {"heading": "The Search for a Better Model", "text": "117\nChapter 8"}, {"heading": "The POMDP Model", "text": "In Chapter 5 we presented an approach to the attack planning problem that uses classical planning and hence ignores all the incomplete knowledge that characterizes hacking. The more recent approach of Chapter 7 makes strong independence assumptions for the sake of scaling, and lacks a clear formal concept of what the attack planning problem actually is. In this chapter, we model that problem in terms of partially observable Markov decision processes (POMDP). This grounds penetration testing in a well-researched formalism, highlighting important aspects of this problem\u2019s nature. POMDPs allow to model information gathering as an integral part of the problem, thus providing for the first time a means to intelligently mix scanning actions with actual exploits."}, {"heading": "8.1 Introduction", "text": "The problem of automatically generating attacks to assess network security is known in the AI Planning community as the \u201cCyber Security\u201d domain [BGHH05]. Independently (though considerably later), the approach was put forward also by the pentesting industry [LSR10]. The two domains essentially differ only in the industrial context addressed.1 Herein, we are concerned exclusively with the specific context of regular automatic pentesting, as in Core Security\u2019s \u201cCore Insight Enterprise\u201d tool. We will use the term \u201cattack planning\u201d in that sense.\n1Boddy et al. [BGHH05] provide a tool for system administrators to experiment with attacker models including behavioral attributes, and model also actions in the physical world, i.e., office environments.\n118\n119\nLucangeli et al. [LSR10] encoded attack planning into PDDL, and used off-theshelf planners. This already is useful,2 however it is still quite limited. In particular, the planning is classical\u2014complete initial states and deterministic actions\u2014 and thus not able to handle the uncertainty involved in this form of attack planning. We herein contribute a planning model that does capture this uncertainty, and allows to generate plans taking it into account. To understand the added value of this technology, it is necessary to examine the relevant context in some detail.\nThe pentesting tool has access to the details of the client network. So why is there any uncertainty? The answer is simple: pentesting is not Orwell\u2019s \u201cBig Brother\u201d. Do your IT guys know everything that goes on inside your computer?\nIt is safe to assume that the pentesting tool will be kept up-to-date about the structure of the network, i.e., the set of machines and their connections\u2014these changes are infrequent and can easily be registered. It is, however, impossible to be up-to-date regarding all the details of the configuration of each machine, in the typical setting where that configuration is ultimately in the hands of the individual users. Thus, since the last series of attacks was scheduled, the configurations may have changed, and the pentesting tool does not know how exactly. Its task is to figure out whether any of the changes open new dangerous vulnerabilities.\nOne might argue that the pentesting tool should first determine what has changed, via scanning methods, and then address what is now a classical planning problem involving only exploits, i.e., hacking actions modifying the system state. There are two flaws in this reasoning: (a) scanning doesn\u2019t yield perfect knowledge so a residual uncertainty remains; (b) scanning generates significant costs in terms of running time and network traffic. So what we want is a technique that (like a real hacker) can deal with uncertainty by intelligently inserting scanning actions where they are useful for scheduling the best exploits. To our knowledge, ours is the first work that indeed offers such a method.\nThere is hardly any related work tackling uncertainty measures (probabilities) in network security. The few works that exist (e.g., [Bil03, DH03]) are concerned with the defender\u2019s viewpoint, and tackle a very different kind of uncertainty attempting to model what an attacker would be likely to do. The above mentioned\n2In fact, this technology is currently employed in Core Security\u2019s commercial product, using a variant of Metric-FF.\n120\nwork on classical planning is embedded into a pentesting tool running a large set of scans as a pre-process, and afterwards ignoring the residual uncertainty. This incurs both drawbacks (a) and (b) above. The single work addressing (a) was performed in part by one of the authors [SRL11]. On the positive side, the proposed attack planner demonstrates industrial-scale runtime performance, and in fact its worst-case runtime is low-order polynomial. On the negative side, the planner does not offer a solution to (b)\u2014it still reasons only about exploits, not scanning\u2014and of course its efficiency is bought at the cost of strong simplifying assumptions. Also, the work provides no clear notion of what attack planning under uncertainty actually is.\nHerein, we take the opposite extreme of the trade-off between accuracy and performance. We tackle the problem in full, in particular addressing information gathering as an integral part of the attack. We achieve this by modeling the problem in terms of partially observable Markov decision processes (POMDP). As a side effect, this modeling activity serves to clarify some important aspects of this problem\u2019s nature. A basic insight is that, whereas Sarraute et al. [SRL11] model the uncertainty as non-deterministic actions\u2014success probabilities of exploits\u2014 this uncertainty is more naturally modeled as an uncertainty about states. The exploits as such are deterministic in that their outcome is fully determined by the system configuration.3 Once this basic modeling choice is made, all the rest falls into place naturally.\nOur experiments are based on a problem generator that is not industrial-scale realistic, but that allows to create reasonable test instances by scaling the number of machines, the number of possible exploits, and the time elapsed since the last activity of the pentesting tool. Unsurprisingly, we find that POMDP solvers do not scale to large networks. However, scaling is reasonable for individual pairs of machines. As argued by Sarraute et al. [SRL11], such pairwise strategies can serve as the basic building blocks in a framework decomposing the overall problem into two abstraction levels.\nWe next provide some additional background on pentesting and POMDPs. We then detail our POMDP model of attack planning, and our experimental findings. We close the chapter with a brief discussion of future work.\n3Sometimes, non-deterministic effects are an adequate abstraction of state uncertainty, as in \u201ccrossing the street\u201d. The situation in pentesting is different because repeated executions will yield identical outcomes.\n121"}, {"heading": "8.2 Comment on Penetration Testing", "text": "The objective of a typical penetration testing task is to gain control over as many computers in a network as possible, with a preference for some machines (e.g., because of their critical content). It starts with one controlled computer: either outside the targeted network (so that its first targets are machines accessible from the internet), or inside this network (e.g., using a Trojan horse). As illustrated in Figure 8.1, at any point in time one can distinguish between 3 types of computers: those under control (on which an agent has been installed, allowing to perform actions); those which are reachable from a controlled computer because they share a sub-network with one of them: and those which are unreachable from any controlled computer.\nGiven currently controlled machines, one can perform two types of actions targeting a reachable machine: tests\u2014to identify its configuration (OS, running applications, . . . )\u2014, and exploits\u2014to install an agent by exploiting a vulnerability. A successful exploit turns a reachable computer into a controlled one, and all its previously unreachable neighbors into reachable computers.\nA \u201cclassic\u201d pentest methodology consists of a series of fixed steps (refer also\nto Section 2.3), for example:\n\u2022 perform a network discovery (obtain a list of all the reachable machines), \u2022 port scan all the reachable machines (given a fixed list of common ports,\nprobe if they are open/closed/filtered),\n122\n\u2022 given the previous information, perform OS detection module(s) on reachable machines (e.g., run nmap tests), \u2022 once the information gathering phase is completed, the following phase is to launch exploits against the (potentially vulnerable) machines.\nThis could be improved\u2014a long-term objective of this work\u2014as POMDP planning allows for more efficiency by mixing actions from the different steps.\nMore details on pentesting will be given later when we describe how to model\nit using the POMDP formalism."}, {"heading": "8.3 Background on POMDPs", "text": "Before describing how penetration testing can be modeled in terms of POMDPs in Section 8.4, we provide the necessary background and terminology. Planning based on Markov Decision Processes (MDPs) is designed to deal with nondeterminism, probabilities, partial observability, and extended goals. It is based on the following conventions:\n\u2022 A planning domain is modeled as a stochastic system, that is a nondeterministic state-transition system that assigns probabilities to state transitions.\n\u2022 Goals are represented by means of utility functions, numeric funtions that give preferences to states to be traversed and/or actions to be performed.\nUtility functions can express preferences on the entire execution path of a plan, rather than just desired final states.\n\u2022 Plans are represented as policies that specify the action to execute in each belief state.\n\u2022 The planning problem is seen as an optimization problem, in which planning algorithms search for a plan that maximizes the utility function.\n\u2022 Partial observability is modeled by observations that return a probability distribution over the state space, called belief states.\n123"}, {"heading": "8.3.1 Basic Definitions of MDPs", "text": "Definition 8.1. A Markov Decision Process (MDP), also called stochastic system [GNT04], is a nondeterministic state-transition system with a probability distribution on each state transition. It is defined by a tuple \u03a3 = \u3008S,A, T \u3009 where:\n\u2022 The state space S is a finite set of states.\n\u2022 The action space A is a finite set of actions.\n\u2022 T : S \u00d7 A \u2192 \u03a0(S) is the state-transition function, giving for each world state s and agent action a, a probability distribution over world states. We\nwrite T (s, a, s\u2032) for the probability of ending in state s\u2032 given that the agent starts in state s and executes action a.\n\u2022 r : S\u00d7A \u2192 R is the reward function, giving the expected immediate reward gained by the agent for taking action a in state s.\nDefinition 8.2. A plan specifies the actions that a controller should execute in a given state, and can thus be represented as a policy \u03c0, a function mapping states into actions:\n\u03c0 : S \u2192 A (8.1)\nDefinition 8.3. Policy executions correspond to infinite sequence of states, called histories, which are Markov Chains. Given a policy, we can compute the probability of a history. Let \u03c0 be a policy and h = \u3008s0, s1, s2, . . .\u3009 be a history. The probability of h induced by \u03c0 is the product of all transition probabilities induced by the policy:\nPr(h|\u03c0) = \u220f i\u22650 T (si, \u03c0(si), si+1) (8.2)\nDefinition 8.4. A common way to ensure a bounded measure of utilities for infinite histories is to introduce a discount factor \u03b3, with 0 < \u03b3 < 1, that makes rewards accumulated at later stages count less than those accumulated at early stages.\nDefinition 8.5. Let h be a history \u3008s0, s1, s2, . . .\u3009. We define the utility of h induced by a policy \u03c0 as follows:\nV (h|\u03c0) = \u2211 i\u22650 \u03b3i r(si, \u03c0(si)) (8.3)\n124\nDefinition 8.6. Let \u03a3 be a stochastic system, H be the set of all the possible histories of \u03a3, and \u03c0 be a policy for \u03a3. Then the expected utility of \u03c0 is\nE(\u03c0) = \u2211 h\u2208H Pr(h|\u03c0)V (h|\u03c0) (8.4)\nDefinition 8.7. A policy \u03c0\u2217 is an optimal policy for a stochastic system \u03a3 if E(\u03c0\u2217) \u2265 E(\u03c0), for any policy \u03c0 for \u03a3. We can now define a planning problem as an optimization problem: given a stochastic system \u03a3 and a utility function, a solution to a planning problem is an optimal policy.\nDefinition 8.8. Given an optimal policy \u03c0\u2217, E(\u03c0\u2217) is called the optimal reward.\nDefinition 8.9. Let E(s) be the expected reward in a state s. We define Q(s, a), the expected reward in a state s when we execute action a:\nQ(s, a) = r(s, a) + \u03b3 \u2211 s\u2032\u2208S T (s, a, s\u2032)E(s\u2032) (8.5)\nIt can be shown that the optimal reward E(\u03c0\u2217) satisfies the fixed-point equation\nE(s) = max a\u2208A\nQ(s, a) for all s \u2208 S (8.6)\nFormula (8.6) is called the Bellman Equation [Bel54]. We call E\u03c0\u2217(s) the optimal reward in state s. From the Bellman Equation we have that:\nE\u03c0\u2217(s) = max a\u2208A\n{ r(s, a) + \u03b3\n\u2211 s\u2032\u2208S T (s, a, s\u2032)E\u03c0\u2217(s \u2032)\n} (8.7)"}, {"heading": "8.3.2 Basic Definitions of POMDPs", "text": "Definition 8.10. POMDPs are usually defined [Mon82, Cas98, GNT04] by a tuple \u03a3 = \u3008S,A,O, T, O, r, b0\u3009 where:\n\u2022 \u3008S,A, T, r\u3009 is a Markov decision process.\n\u2022 The observation space O is a finite set of observations.\n\u2022 b0 is the initial probability distribution over states.\n\u2022 At any time step, the system being in some state s \u2208 S, the agent performs an action a \u2208 A that results in\n125\n1. a transition to a state s\u2032 according to the transition function:\nT : S \u00d7A\u00d7 S \u2192 [0, 1]\nT (s, a, s\u2032) = Pr(s\u2032|s, a)\n2. an observation o \u2208 O according to the observation function:\nO : S \u00d7A\u00d7O \u2192 [0, 1]\nO(s\u2032, a, o) = Pr(o|s\u2032, a)\n3. a scalar reward r(s, a) according to the reward function:\nr : S \u00d7A \u2192 R\nDefinition 8.11. In POMDPs, the controller can observe a probability distribution over states of the system, rather than exactly the state of the system. Probability distributions over S are called belief states. Let b be a belief state and B = \u03a0(S) the set of belief states. Let b(s) denote the probability assigned to state s by the belief state b. Because b(s) is a probability, we require 0 \u2264 b(s) \u2264 1 for all s \u2208 S and \u2211 s\u2208S b(s) = 1.\nDefinition 8.12. In POMDPs, a policy is a function that maps belief states into actions. Let B \u2286 [0, 1]|S| be the set of belief states. A policy is a function\n\u03c0 : B \u2192 A (8.8)\nIn this setting, the problem is for the agent to find a decision policy \u03c0 choosing, at each time step, the best action based on its past observations and actions so as to maximize its future gain (which can be measured for example through the total accumulated reward). Compared to classical deterministic planning, the agent has to face the difficulty in accounting for a system not only with uncertain dynamics but also whose current state is imperfectly known.\nGiven a belief state b, the execution of an action a results in a temporary belief state ba (before the observation is made). For each s \u2032\u2032 \u2208 S, the probability ba(s\u2032\u2032) can be computed as:\nba(s \u2032\u2032) = Pr(s\u2032\u2032|a, b) = \u2211 s\u2208S Pr(s\u2032\u2032|a, s) b(s)\n= \u2211 s\u2208S T (s, a, s\u2032\u2032) b(s) (8.9)\n126\nThe probability of observing o \u2208 O after executing action a \u2208 A in belief state b is:\nPr(o|a, b) = \u2211 s\u2032\u2032\u2208S O(s\u2032\u2032, a, o) ba(s \u2032\u2032) (8.10)\nThe agent typically reasons about the hidden state of the system using the following Bayesian update formula, which gives the probability boa(s \u2032) that the state is s\u2032 after performing action a in belief state b and observing o:\nboa(s \u2032) = Pr(s\u2032|o, a, b) = Pr(o|s \u2032, a, b)\nPr(o|a, b) Pr(s\u2032|a, b)\n= O(s\u2032, a, o) Pr(o|a, b) \u2211 s\u2208S T (s, a, s\u2032)b(s). (8.11)"}, {"heading": "8.3.3 Reformulation as an MDP over B", "text": "Using belief states, a POMDP can be rewritten as an MDP over the belief space, or belief MDP, \u03a3\u2032 = \u3008B,A, T , \u03c1\u3009, where the new transition and reward functions are both defined over B\u00d7A\u00d7B. With this reformulation, a number of theoretical results about MDPs can be extended, such as the existence of a deterministic policy that is optimal. An issue is that this belief MDP is defined over a continuous\u2014and thus infinite\u2014belief space.\nLet us first compute the transition probabilities for belief states. Given a belief state b \u2208 B and an action a \u2208 A, each observation can yield a different succeeding belief state. The belief state transition \u03c4 can be written as:\n\u03c4(b, a, b\u2032) = Pr(b\u2032|a, b) = \u2211 o\u2208O Pr(o|a, b) \u03b4(boa, b\u2032) (8.12)\nwhere\n\u03b4(x, y) = 1 if x = y0 if x 6= y. (8.13) In other words, the probability of a belief state is the sum of the probabilities of all the observation that would lead to that belief state.\nSince A and O are finite, there are only a finite number of possible successor belief states. We define the set of possible successor states as:\nB\u2032(b, a) = {boa | o \u2208 O} (8.14)\n127\nThe reward \u03c1 for the belief MDP has to be defined for each belief state-action\npair. For the belief state b, it\u2019s simply the expectation over all states:\n\u03c1(b, a) = \u2211 s\u2208S r(s, a) b(s) (8.15)\nAs in Definition 8.9, we define Q(b, a), the expected reward in a state b when\nwe execute action a:\nQ(b, a) = \u03c1(b, a) + \u03b3 \u2211 b\u2032\u2208B \u03c4(b, a, b\u2032)E(b\u2032) (8.16)\nThe Bellman Equation (8.6) is now written as:\nE\u03c0\u2217(b) = max a\u2208A\n{ \u03c1(b, a) + \u03b3\n\u2211 b\u2032\u2208B \u03c4(b, a, b\u2032)E\u03c0\u2217(b \u2032)\n} (8.17)\nFor a finite horizon4 T > 0 the objective is to find a policy verifying \u03c0\u2217 =\narg max\u03c0\u2208AB J \u03c0(b0) with\nJ\u03c0(b0) = E [ T\u22121\u2211 t=0 \u03b3trt \u2223\u2223\u2223\u2223\u2223b0, \u03c0 ] ,\nwhere b0 is the initial belief state, rt the reward obtained at time step t, and \u03b3 \u2208 (0, 1) a discount factor. Bellman\u2019s principle of optimality [Bel54] lets us compute this function recursively through the value function\nVn(b) = max a\u2208A\n[ \u03c1(b, a) + \u03b2\n\u2211 b\u2032\u2208B \u03d5(b, a, b\u2032)Vn\u22121(b \u2032)\n] ,\nwhere, for all b \u2208 B, V0(b) = 0, and J\u03c0(b) = Vn=T (b)."}, {"heading": "8.3.4 POMDP Solving Algorithms", "text": "A number of algorithms exploit the fact that Vn(b) is a piecewise linear and convex function (PWLC). This allows for direct computations or approximations where the target function is the upper envelope of a set of hyperplanes. This led to algorithms performing exact updates like Batch Enumeration [Mon82], Witness or Incremental Pruning [Cas98], but also approximate ones as in Point-Based\n4In practice we consider an infinite horizon.\n128\nValue Iteration (PBVI) [PGT06], Heuristic Search Value Iteration (HSVI) [SS04], PERSEUS [SV05] or SARSOP [KHL08].\nIf not relying on PWLC functions, one can also solve a POMDP as an MDP on a continuous state space, for example with tree search algorithms\u2014which allow for online planning [RPPCd08]\u2014or with RTDP-bel, a variant of dynamic programming that continuously focuses on relevant parts of the state space [BG09].\nLet us also mention that some algorithms\u2014such as Symbolic HSVI [SKK+08]\u2014 can exploit the structure of a factored POMDP, i.e., a POMDP in which the state and/or the observation is described through multiple variables."}, {"heading": "SARSOP Solver", "text": "For our experiments we use SARSOP [KHL08], a state of the art point-based algorithm, i.e., an algorithm approximating the value function as the upper envelope of a set of hyperplanes, these hyperplanes corresponding to a selection of particular belief points.\nSARSOP is being developed at the National University of Singapore, with the goal of creating practical POMDP algorithms and software for common robotic tasks \u2013 such as coastal navigation, grasping, mobile robot exploration and target tracking, all modeled as POMDPs with a large number of states.\nThe key idea of point-based POMDP algorithms is to sample a set of points from B and use it as an approximate representation of B, instead of representing B exactly.\nDefinition 8.13. The reachable spaceR(b0) is the subset of belief points reachable from a given initial point b0 \u2208 B under arbitrary sequences of actions.\nDefinition 8.14. The optimally reachable space R\u2217(b0) is the subset of belief points reachable from a given initial point b0 \u2208 B under optimal sequences of actions.\nNote that R\u2217(b0) is usually much smaller than R(b0), which is in turn usually much smaller than B. In particular:\nR\u2217(b0) \u2286 R(b0) \u2286 B\nOf course, R\u2217(b0) is not known in advance, since it requires to know which are the optimal sequences of actions. SARSOP proceeds by computing successive\n129\napproximations of R\u2217(b0), hence the acronym (Successive Approximations of the Reachable Space under Optimal Policies)."}, {"heading": "8.4 Modeling Penetration Testing with POMDPs", "text": "As penetration testing is about acting under partial observability, POMDPs are a natural candidate to model this particular problem. They allow to model the problem of knowledge acquisition and to account for probabilistic information, e.g., the fact that certain configurations or vulnerabilities are more frequent than others. In comparison, classical planning approaches [LSR10] assume that the whole network configuration is known, so that no exploration is required. The present section discusses how to formalize penetration testing using POMDPs. As we shall see, the uncertainty is located essentially in the initial belief state. This is different from modeling the uncertainty in pentesting using probabilistic action outcomes as in [SRL11], which does not account for the real dynamics of the system. Also, as indicated previously, unlike our POMDPs, the approach of Sarraute et al. [SRL11] only chooses exploits, assuming a naive a priori knowledge acquisition and thus ignoring the interaction between these two."}, {"heading": "8.4.1 States", "text": "First, any sensible penetration test will have a finite execution. There is nothing to be gained here by infinitely executing a looping behavior. Every pentest terminates either when some event (e.g., an attack detection) stops it, or when the additional access rights that could yet be gained (from the finite number of access rights) do not outweigh the associated costs. This implies that there exists an absorbing terminal state and that we are solving a Stochastic Shortest Path problem (SSP).\nThen, in the context of pentesting, we do not need the full state of the system to describe the current situation. We will thus focus on aspects that are relevant for the task at hand. This state for example does not need to comprise the network topology as it is assumed here to be static and known. But it will have to account for the configuration and status of each computer on the network.\nA computer\u2019s configuration needs to describe the applications present on the computer and that may (i) be vulnerable or (ii) reveal information about potentially vulnerable applications. This comprises its operating system (OS) as well as\nserver applications for the web, databases, email, ... The description of an application does not need to give precise version numbers, but should give enough details to know which (known) vulnerabilities are present, or what information can be obtained about the system. For example, the open ports on a given computer are aspects of the OS that may reveal not only the OS but also which applications it is running.\nThe computers\u2019 configurations (and the network topology) give a static picture of the system independently of the progress of the pentest. To account for the current situation one needs to specify, for each computer, whether a given agent has been installed on it, whether some applications have crashed (e.g., due to the failure of an exploit), and which computers are accessible. Which computers are accessible depends only on the network topology and on where agents have been installed, so that there is no need to explicitly add this information in the state. Table 8.1 gives a states section from an actual POMDP file (using the file format of Cassandra\u2019s toolbox) in a setting with a single machine M0, which is always accessible (not mentioning the computer from which the pentest is started).\nNote that a computer\u2019s configuration should also provide information on whether\nhaving access to it is valuable in itself, e.g., if there is valuable data on its hard drive. This will be used when defining the reward function."}, {"heading": "8.4.2 Actions & Observations", "text": "First, we need a Terminate action that can be used to reach the terminal state voluntarily. Note that specific outcomes of certain actions could also lead to that state.\nBecause we assume that the network topology is known a priori, there is no need for actions to discover reachable machines. We are thus left with two types of actions: tests, which allow to acquire information about a computer\u2019s configuration, and exploits, which attempt to install an agent on a computer by exploiting a vulnerability. Table 8.2 lists actions in our running example started in Table 8.1."}, {"heading": "Tests", "text": "Tests are typically performed using programs such as nmap [Lyo98], which scans a specific computer for open ports and, by analyzing the response behavior of ports, allows to make guesses about which OS and services are running. Note that such observation actions have a cost either in terms of time spent performing analyses, or because of the probability of being detected due to the generated network activity. This is the reason why one has to decide which tests to perform rather than perform them all.\nIn our setting, we only consider two types of tests:\nOS detection: A typical OS detection will return a list of possible OSes, the\nones likely to explain the observations of the analysis tool. As a result, one can prune from the belief state (=set to zero probability) all the states corresponding with non-matching OSes, and then re-normalize the remaining non-zero probabilities. Keeping with the same running example, Table 8.3 presents the transition and observation models associated with action OSDetect-M0, which can distinguish winXP configurations from win2000/2003; and following is an example of the evolution of the belief state:\ninitial (0,0,0,0,0,0,1 8 ,1 8 ,1 8 ,1 8 ,0,1 8 ,1 8 ,1 8 ,1 8 ,0,0,0,0) winXP (0,0,0,0,0,0,0,0,0,0,0,1 4 ,1 4 ,1 4 ,1 4 ,0,0,0,0)\nwin2000/2003 (0,0,0,0,0,0,1 4 ,1 4 ,1 4 ,1 4 ,0,0,0,0,0,0,0,0,0)\nPort scan: Scanning port X simply tells if it is open or closed; by pruning from\nthe belief state the states that match the open/closed state of port X, one implicitely refines which OS and applications may be running. Action Probe-M0-p445, for example, is modeled as depicted on Table 8.4 and could give the following evolution:\ninitial (0,0,0,0,0,0,1 8 ,1 8 ,1 8 ,1 8 ,0,1 8 ,1 8 ,1 8 ,1 8 ,0,0,0,0)\nopen-port (0,0,0,0,0,0,0,1 6 ,1 6 ,1 6 ,0,0,1 6 ,1 6 ,1 6 ,0,0,0,0)\nclosed-port (0,0,0,0,0,0,1 2 ,0,0,0,0,1 2 ,0,0,0,0,0,0,0)\nNote that a test has no state outcome (the state remains the same), and that its observation outcome is considered as deterministic: given the\u2014real, but hidden\u2014 configuration of a computer, a given test always returns the same observation.\nAnother interesting point is that (i) tests provide information about computer configurations and (ii) computer configurations are static, so that there is no use repeating a test as it cannot provide or update any information."}, {"heading": "Exploits", "text": "Exploits make use of an application\u2019s vulnerability to gain (i) some control over a computer from another computer (remote exploit), or (ii) more control over a computer (local exploit / privilege escalation). Local exploits do not differ significantly from remote exploits since it amounts to considering each privilege level as a different (virtual) computer in a sub-network. As a consequence, for the sake of clarity, we only consider one privilege level per computer.\nMore precisely, we consider that any successful exploit will provide the same control over the target computer, whatever the exploit and whatever its configuration. This allows (i) to assume that the same set of actions is available on any controlled computer, and (ii) to avoid giving details about which type of agent is installed on a computer.\nThe success of a given exploit action E depends deterministically on the configuration of the target computer, so that: (i) there is no use in attempting an exploit E if none of the probable configurations is compatible with this exploit, and (ii) the outcome of E\u2014either success or failure\u2014provides information about"}, {"heading": "T: Exploit-M0-win2003-SMB identity", "text": "the configuration of the target. In the present chapter, we even assume that a computer\u2019s configuration is completely observed once it is under control.\nExploit-M0-win2003-SMB is modeled in Table 8.5, and an example evolution\nof the belief under this action is:\ninitial (0,0,0,0,0,0,18 , 1 8 , 1 8 , 1 8 ,0, 1 8 , 1 8 , 1 8 , 1 8 ,0,0,0,0) success (0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0)\nfailure (0,0,0,0,0,0,17 , 1 7 , 1 7 , 1 7 ,0, 1 7 , 1 7 , 1 7 ,0,0,0,0,0)"}, {"heading": "8.4.3 Rewards", "text": "First, no reward is received when the Terminate action is used, or once the terminal state is reached. Otherwise, the reward function has to account for various things:\nValue of a computer (rc): The objective of a pentest is to gain access to a\nnumber of computers. Here we thus propose to assign a fixed reward for each successful exploit (on a previously uncontrolled machine). In a more realistic setting, one could reward accessing for the first time a given valuable data, whatever computer hosts these data.\nTime is money (rt): Each action\u2014may it be a test or an exploit\u2014has a du-\nration, so that the expected duration of the pentest may be minimized by assigning each transition a cost (negative reward) proportional to its duration. One could also consider a maximum time for the pentest rather than minimizing it.\n135\nRisk of detection (rd): We do not explicitely model the event of being detected\n(that would lead to the terminal state with an important cost), but simply consider transition costs that depend on the probability of being detected.\nAs a result, a transition s, a, s\u2032 comes with a reward that is the sum of these three components: r = rc + rt + rd. Although some rewards are positive, we are still solving an SSP since such positive rewards cannot be received multiple times and thus cyclic behavior is not sensible."}, {"heading": "8.4.4 POMDP Model Generation", "text": "Generating a POMDP model for pentesting requires knowledge about possible states, actions, and observations, plus the reward function and the initial belief state. Note first that the POMDP model may evolve from one pentest to the next due to new applications, exploits or tests.\nAction and observation models for the various possible tests and exploits can be derived from the documentation of testing tools (see, e.g., nmap\u2019s manpage) and databases such as CVE (Common Vulnerabilities and Exposures)5. Information could presumably be automatically extracted from such databases, which are already very structured. In our experiments, we start from a proprietary database of Core Security Technologies. The two remaining components of the model\u2014 the reward function and the initial belief state\u2014involve quantitative information which is more difficult to acquire. In our experiments, this information is estimated based on expert knowledge.\nRegarding rewards, statistical models can be used to estimate, for any particular action, the probability of being detected, and the probabilistic model of its duration. But a human decision is required to assign a value for the cost of a detection, for gaining control over one target computer or the other, and for spending a certain amount of time.\nThe definition of the initial belief state is linked to the fact that penetration testing is a task repeated regularly, and has access to previous pentesting reports on the same network. The pentester thus has knowledge about the previous configuration of the network (topology and machines), and which weaknesses have\n5http://cve.mitre.org/\n136\nbeen reported. This information, plus knowledge of typical update behaviors (applying patches or not, downloading service packs...), allows an informed guess on the current configuration of the network.\nWe propose to mimick this reasoning to compute the initial belief state. To keep things simple, we only consider a basic software update behavior (assuming that softwares are independent from each other): each day, an application may probabilistically stay unchanged, or be upgraded to the next version or to the latest version. The updating process of a given application can then be viewed as a Markov chain as illustrated in Fig. 8.2. Assuming that (i) the belief about a given application version was, at the end of the last pentest, some vector v0, and (ii) T days (the time unit in the Markov chain) have passed, then this belief will have to be updated as vT = U Tv0, where U is the matrix representation of the chain. For Fig. 8.2, this matrix reads:\nU =  p1,1 0 0 0 0 p1,2 p2,2 0 0 0 0 p2,3 p3,3 0 0 0 0 p3,4 p4,4 0\np1,5 p2,5 p3,5 p4,5 p5,5\n .\nThis provides a factored approach to compute initial belief states. Of course, in this form the approach is very simplistic. A realistic method would involve elaborating a realistic model of system development. This is a research direction in its own right. We come back to this at the end of the chapter.\n137"}, {"heading": "8.5 Solving Penetration Testing with POMDPs", "text": "We now describe our experiments. We first fill in some details on the setup, then discuss different scaling scenarios, before having a closer look at some example policies generated by the POMDP solver."}, {"heading": "8.5.1 Setup of Experiments", "text": "The experiments are run on a machine with an Intel Core2 Duo CPU at 2.2 GHz and 3 GB of RAM. We use the APPL (Approximate POMDP Planning) toolkit6. This C++ implementation of the SARSOP algorithm is easy to compile and use, and has reasonable performance. The solver is run without time horizon limit, until a target precision = 0.001 is reached. Since we are solving a stochastic shortest path problem, a discount factor is not required, however we use \u03b3 = 0.95 to improve performance. We will briefly discuss below the effect of changing and \u03b3.\nOur problem generator is implemented in Python. It has 3 parameters:\n\u2022 number of machines M in the target network, \u2022 number of exploits E in the pentesting tool, that are applicable in the target\nnetwork,\n\u2022 time delay T since the last pentest, measured in days.\nFor simplicity we assume that, at time T = 0, the information about the network is perfect, i.e., there is no uncertainty. As T grows, uncertainty increases as described in the previous section, where the parameters of the underlying model, cf. Fig. 8.2, are estimated by hand. The network topology consists of 1 outside machine and M \u2212 1 other machines in a fully connected network. The configuration details are scaled along with E, i.e., details are added as relevant for the exploits (note that irrelevant configuration details would not serve any purpose in this application). As indicated, the exploits are taken from a Core Security database which contains the supported systems for each exploit (specific OS and application versions that are vulnerable). The E exploits are distributed evenly over the M machines. We require that E \u2265M so that each machine gets at least one exploit (otherwise the machine could be removed from the encoding).\n6APPL 0.93 at http://bigbird.comp.nus.edu.sg/pmwiki/farm/appl/\n138"}, {"heading": "8.5.2 Combined Scaling", "text": "We discuss performance\u2014solver runtime\u2014as a function of M , E, and T . To make data presentation feasible, at any one time we scale only 2 of the parameters.\nConsider first Figure 8.3, which scales M and T . E is fixed to the minimum value, i.e., each machine has a fixed OS version and one target application. In this setting, there are 3M states. For M = 8, the generated POMDP file has 6562 states and occupies 71 MB on disk; the APPL solver runs out of memory when attempting to parse it. Thus, in this and all experiments to follow, M \u2264 7.\n139\nNaturally, runtime grows exponentially with M\u2014after all, even the solver input does. As for T , interestingly this exhibits a very pronounced easy-hard-easy pattern. Investigating the reasons for this, we found that it is due to a low-highlow pattern of the \u201camount of uncertainty\u201d as a function of T . Intuitively, as T increases, the probability distribution in the initial belief state first becomes \u201cbroader\u201d because more application updates are possible. Then, after a certain point, the probability mass accumulates more and more \u201cat the end\u201d, i.e., at the latest application versions, and the uncertainty decreases again. Formally, this can be captured in terms of the entropy of b0, which exhibits a low-high-low pattern reflecting that of Figure 8.3.\n140\nIn Figure 8.4, scaling the number E of exploits as well as T , the number of machines is fixed to 2 (the localhost of the pentester, and one target machine). We observe the same easy-hard-easy pattern over T . As with M , runtime grows exponentially with E (and must do so since the solver input does). However, with small or large T , the exponential behavior does not kick in until the maximum number of exploits, 10, that we consider here. This is important for practice since small values of T (up to T = 50) are rather realistic in regular pentesting. In the next sub-section, we will examine this in more detail to see how far we can scale E, in the 2-machines case, with small T .\nFigures 8.5 and 8.6 show the combined scaling over machines and exploits, for a favorable value of T (T = 10, Fig. 8.5) and an unfavorable one (T = 80, Fig. 8.6). Here the behavior is rather regular. By all appearances, it grows exponentially in both parameters. An interesting observation is that, in Fig. 8.5, the growth in M kicks in earlier, and rather more steeply, for M . This is not as much the case for the larger T value in Fig. 8.6. Note though that, there, the curve over E flattens around T = 10. It is not clear to us what is causing this behavior; cf. the next sub-section.\nTo give an impression on the effect of the discount factor on solver performance, with M = 2, E = 11, T = 40, solver runtime goes from 17.77 s (with \u03b3 = 0.95) to 279.65 s (with \u03b3 = 0.99). APPL explicitly checks that \u03b3 < 1, so \u03b3 = 1 could not be tried. With our choice \u03b3 = 0.95 we still get good policies (cf. further below)."}, {"heading": "8.5.3 The 2-Machines Case", "text": "As hinted, the 2-machines case is relevant because it may serve as the \u201catomic building block\u201d in an industrial-scale solution, cf. also the discussion in the outlook below. The question then is whether or not we can scale the number of exploits into a realistic region. We have seen above already that this is not possible for unfavorable values of T . However, are these values to be expected in practice? As far as Core Security\u2019s \u201cCore Insight Enterprise\u201d tool goes, the answer is \u201cno\u201d. In security aware environments, pentesting should be performed at regular intervals of at most 1 month. Consequently, Figure 8.7 shows data for T \u2264 50.\nFor the larger values of T , the data shows a very steep incline between E = 5 and E = 10, followed by what appears to be linear growth. This behavior is caused\n141\nby an unwanted bias in our current generator.7 Ignoring this phenomenon, what matters to us here is that, for the most realistic values of T (T = 10, 20), scaling is very good indeed, showing no sign of hitting a barrier even at E = 50. Of course, this result must be qualified against the realism of the current generator. It remains an open question whether similar scaling will be achieved for more realistic simulations of network development."}, {"heading": "8.5.4 POMDPs make Better Hackers", "text": "As an illustration of the policies found by the POMDP solver, consider a simple example wherein the pentester has 4 exploits: an SSH exploit (on OpenBSD, port 22), a wu-ftpd exploit (on Linux, port 21), an IIS exploit (on Windows, port 80), and an Apache exploit (on Linux, port 80). The probability of the target machine being Windows is higher than the probability of the other OSes.\nPrevious automated pentesting methods, e.g. Lucangeli et al. [LSR10], proceed by first performing a port scan on common ports, then executing OS detection module(s), and finally launching exploits for potentially vulnerable services.\n7The exploits to be added are ordered in a way so that their likelihood of succeeding decreases monotonically with |E|. After a certain point, they are too unlikely to affect the policy quality by more than the target precision . The POMDP solver appears to determine this effectively.\n142\nWith our POMDP model, the policy obtained is to first test whether port 80 is open, because the expected reward is greater for the two exploits which target port 80, than for each of the exploits for port 21 or 22. If port 80 is open, the next action is to launch the IIS exploit for port 80, skipping the OS detection because Windows is more probable than Linux, and the additional information that OS Detect can provide doesn\u2019t justify its cost (additional running time). If the exploit is successful, terminate. Otherwise, continue with the Apache exploit (not probing port 80 since that was already done), and if that fails then probe port 21, etc.\nIn summary, the policy orders exploits by promise, and executes port probe and OS detection actions on demand where they are cost-effective. This improves on Sarraute et al. [SRL11], whose technique is capable only of ordering exploits by promise. What\u2019s more, practical cases typically involve exploits whose outcome delivers information about the success probability of other exploits, due to common reasons for failure\u2014exploitation prevention techniques. Then the best ordering of exploits depends on previous exploits\u2019 outcome. POMDP policies handle this naturally, however it is well beyond the capabilities of Sarraute et al.\u2019s approach. We omit the details for space reasons."}, {"heading": "8.6 Discussion", "text": "POMDPs can model pentesting more naturally and accurately than previously proposed planning-based models [LSR10, SRL11]. While, in general, scaling is limited, we have seen that it appears reasonable in the 2-machines case where we are considering only how to get from one machine to another. An idea to use POMDP reasoning in practice is thus to perform it for all connected pairs of machines in the network, and thereafter use these solutions as the input for a highlevel planning procedure. That procedure would consider the pairwise solutions to be atomic, i.e., no backtracking over these decisions would be made. Indeed, this is one of the abstractions made\u2014successfully, as far as runtime performance is concerned\u2014by Sarraute et al. [SRL11]. Our immediate future work will be to explore whether a POMDP-based solution of this type is useful, the question being how large the overhead for planning all pairs is, and how much of the solution quality gets retained at the global level.\n143\nA line of basic research highlighted by our work is the exploitation of special structures in POMDPs. First, in our model, all actions are deterministic. Second, some of the uncertain parts of the state (e.g. the operating systems) are static, for the purpose of pentesting, in the sense that none of the actions affect them. Third, unless one models possible detrimental side-effects of exploits (cf. directly below), pentesting is \u201cmonotonic\u201d: accessibility, and thus the set of actions applicable, can only grow. Fourth, any optimal policy will apply each action at most once. Finally, some aspects of the state\u2014in particular, which computers are controlled and reachable\u2014are directly visible and could be separately modeled as being such. To our knowledge, this last property alone has been exploited in POMDP solvers (e.g., [ALTBC10]), and the only other property mentioned in the literature appears to be the first one (e.g., [Bon09]).\nWhile accurate, our current model is of course not \u201cthe final word\u201d on modeling pentesting with POMDPs. As already mentioned, we currently do not explicitly model the detrimental side-effects exploits may have, i.e., the cases where they are detected (spawning a reaction of the network defense) or where they crash a machine/application. Another important aspect that could be modeled in the POMDP framework is that machines are not independent. Knowing the configuration of some computers in the network provides information about the configuration of other computers in the same network. This can be modeled in terms of the probability distribution given in the initial belief. An interesting question for future research then is how to generate these dependencies\u2014and thus the initial belief\u2014in a realistic way. Answering this question could go hand in hand with more realistically simulating the effect of the \u201ctime delay\u201d in pentesting. Both could potentially be adressed by learning appropriate graphical models [KF09], based on up-to-date real-world statistics.\nTo close the chapter, it must be admitted that, in general, \u201cpentesting 6= POMDP solving\u201d. Computer security is always evolving, so that the probability of meeting certain computer configurations changes with time. An ideal attacker should continuously learn the probability distributions describing the network and computer configurations it can encounter. This kind of learning can be done outside the POMDP model, but there may be better solutions doing it more natively. Furthermore, if the administrator of a target network reacts to an attack, running specific counter-attacks, then the problem turns into an adversarial game.\nChapter 9"}, {"heading": "Conclusions and Future Work", "text": "Part I\nIn this first part, we presented the basic model and a complete implementation that integrates a planner system with a penetration testing framework. We described an algorithm for transforming the information present in the pentesting tool to the planning domain, and we showed how the scalability issues of attack graphs can be solved using current planners.\nThe planner retained in our implementation is Metric-FF, developed by Jo\u0308rg Hoffmann [Hof02]. Our research prototype continued its way outside the research lab: it was adopted by the engineering team in charge of developing the product Core Insight Enterprise, integrated into the product and shipped to customers. To meet the engineering requirements, further work was performed on the prototype. In particular, the testing team of Core Insight Enterprise developed a suite of testing scenarios, more realistic and closer to the customer\u2019s networks than the ones used during our research. Having access to those testing scenarios was a valuable resource in subsequent steps of the research, in particular the testing and evaluation of the prototypes of Parts II and III.\nPart II\nIn the second part, we introduced a custom probabilistic planner, specifically designed for this problem. We contributed a planning model that captures the uncertainty about the results of the actions, which is modeled as a probability of success of each action; and we presented efficient planning algorithms, that achieve industrial-scale runtime performance. The computational complexity of\n144\n145\nthis planning solution is O(M2 \u00b7 n log n) where n is the total number of actions, and M is the number of machines in the target network.\nAfter this work was published in [Sar09a, Sar09b, SRL11], the following step was to further evaluate this research prototype as a potential engineering solution (i.e. to perform attack planning for the company\u2019s product). As part of this evaluation, we tested the probabilistic planner prototype with the scenarios developed by the testing team. This allowed us to improve both the planner prototype and the testing scenarios. In particular, by making clever use of the results of intermediate computations, we were able to bring down the complexity of the solution to O(M \u00b7 n log n), and obtain remarkable improvements in planner runtime. A natural next step for this prototype is thus to graduate from the research lab, and enter the engineering circuit.\nPart III\nThe work described in the third part is the result of a collaboration with Jo\u0308rg Hoffman (Saarland University) and Olivier Buffet (INRIA, Nancy). In this collaboration we took a different direction: instead of trying to improve the efficiency of the solutions developed, we focused on improving the model of the attacker, and formulating the problems that we think will have to be solved in the longer term.\nWe modeled the attack planning problem in terms of partially observable Markov decision processes (POMDP). This grounded penetration testing in a wellresearched formalism, and highlighted important aspects of the problem\u2019s nature. In particular POMDPs allowed us to model information gathering as an integral part of the attack, thus providing for the first time a means to intelligently mix scanning actions with actual exploits.\nAs a continuation of this modeling activity, we devised a method that relies on POMDPs to find good attacks on individual machines, which are then composed into an attack on the network as a whole. This decomposition exploits the network structure to the extent possible, making targeted approximations (only) where needed. This new approach will be presented at the JFPDA conference in Nancy, France, during May 2012 [SBH12a]; and at the AAAI conference, that will take\n146\nplace in Toronto, Canada, in July 2012 [SBH12b]. An insight of this approach was given at the Hackito Ergo Sum conference this year [Sar12].\nWe give below a brief summary of the ideas of this decomposition. The approach is called 4AL since it addresses network attack at 4 different levels of abstraction. 4AL is a POMDP solver specialized in attack planning as addressed here. Its inputs are the logical network LN and POMDP models encoding attacks on individual machines. Its output is a policy (an attack) for the global POMDP encoding LN , as well as an approximation of the value of the global value function.\nThe four levels are: (1) Decomposing the Network, (2) Attacking Components, (3) Attacking Subnetworks, and (4) Attacking Individual Machines. We outline these levels in turn. Figure 9.1 provides illustrations.\n\u2022 Level 1: Decompose the logical network LN into a tree of biconnected components, rooted at \u2217. In reverse topological order, call the Level 2 procedure on each component; propagate the outcomes upwards in the tree.\n\u2022 Level 2: Given component C, consider, for each rewarded subnetwork N \u2208\n147\nC, all paths P in C that reach N . Backwards along each P , call the Level 3 procedure on each subnetwork and associated firewall. Choose the best path for each N . Aggregate these path values over all N , by summing up but disregarding rewards that were already accounted for by a previous path in the sum.\n\u2022 Level 3: Given a subnetwork N and a firewall F through which to attack N , for each machine m \u2208 N approximate the reward obtained when attacking m first. For this, modify m\u2019s reward to take into account that, after breaking\nm, we are behind F : call Level 4 to obtain the values of all m\u2032 6= m with an empty firewall; then add these values, plus any pivoting reward, to the reward of m and call Level 4 on this modified m with firewall F . Maximize the resulting value over all m \u2208 N .\n\u2022 Level 4: Given a machine m and a firewall F , model the single-machine attack planning problem as a POMDP, and run an off-the-shelf POMDP\nsolver. Cache known results to avoid duplicated effort.\nIn conclusion, the POMDP model of penetration testing that we devised allows us to naturally represent many of the features of this application, in particular incomplete knowledge about the network configuration, as well as dependencies between different attack possibilities, and firewalls. Unlike any previous methods, the approach is able to intelligently mix scans with exploits. While this accurate solution does not scale, large networks can be tackled by a decomposition algorithm. Our present empirical results suggest that this can be accomplished with a small loss in quality relative to a global POMDP solution.\nAn important open question is to what extent our POMDP + decomposition approach is more cost-effective than the classical planning solution currently employed by Core Security. Our next step will be to answer this question experimentally, comparing the attack quality of 4AL against that of the policy that runs extensive scans and then attaches FF\u2019s plan for the most probable configuration.\nOther important directions for future work are to devise more accurate models of software updates (hence obtaining more realistic designs of the initial belief); to tailor POMDP solvers to this particular kind of problem, which has certain special features, in particular the absence of non-deterministic actions and that some of the uncertain parts of the state (e.g. the operating systems) are static;\n148\nand to drive the industrial application of this technology. We hope that these will inspire other researchers as well."}], "references": [{"title": "The Shellcoder\u2019s Handbook", "author": ["Chris Anley", "John Heasman", "Felix Lindner", "Gerardo Richarte"], "venue": null, "citeRegEx": "Anley et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Anley et al\\.", "year": 2007}, {"title": "An introduction to MOSDEF", "author": ["Dave Aitel"], "venue": "In Black Hat Briefings,", "citeRegEx": "Aitel.,? \\Q2004\\E", "shortCiteRegEx": "Aitel.", "year": 2004}, {"title": "A closer look at MOMDPs", "author": ["Mauricio Araya-L\u00f3pez", "Vincent Thomas", "Olivier Buffet", "Fran\u00e7ois Charpillet"], "venue": "In Proc. of ICTAI-10,", "citeRegEx": "Araya.L\u00f3pez et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Araya.L\u00f3pez et al\\.", "year": 2010}, {"title": "Why attacking systems is a good idea", "author": ["Ivan Arce", "Gary McGraw"], "venue": "IEEE Computer Society - Security & Privacy Magazine,", "citeRegEx": "Arce and McGraw.,? \\Q2004\\E", "shortCiteRegEx": "Arce and McGraw.", "year": 2004}, {"title": "State of the art security from an attacker\u2019s viewpoint", "author": ["Ivan Arce", "Gerardo Richarte"], "venue": "In PacSec Conference,", "citeRegEx": "Arce and Richarte.,? \\Q2003\\E", "shortCiteRegEx": "Arce and Richarte.", "year": 2003}, {"title": "On the quality of exploit code: An evaluation of publicly available exploit code", "author": ["Ivan Arce"], "venue": "In RSA Security Conference,", "citeRegEx": "Arce.,? \\Q2005\\E", "shortCiteRegEx": "Arce.", "year": 2005}, {"title": "Scalable, graph-based network vulnerability analysis", "author": ["Paul Ammann", "Duminda Wijesekera", "Saket Kaushik"], "venue": "In Proceedings of the 9th ACM Conference on Computer and Communications Security,", "citeRegEx": "Ammann et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Ammann et al\\.", "year": 2002}, {"title": "The internet motion sensor: A distributed blackhole monitoring system", "author": ["Michael Bailey", "Evan Cooke", "Farnam Jahanian", "Jose Nazario", "David Watson"], "venue": "In Proceedings of Network and Distributed System Security Symposium NDSS", "citeRegEx": "Bailey et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Bailey et al\\.", "year": 2005}, {"title": "The theory of dynamic programming", "author": ["Richard Bellman"], "venue": "Bull. Amer. Math. Soc.,", "citeRegEx": "Bellman.,? \\Q1954\\E", "shortCiteRegEx": "Bellman.", "year": 1954}, {"title": "Security problems in the TCP/IP protocol suite", "author": ["Steven M. Bellovin"], "venue": "Computer Communications Review,", "citeRegEx": "Bellovin.,? \\Q1989\\E", "shortCiteRegEx": "Bellovin.", "year": 1989}, {"title": "Fast planning through planning graph analysis", "author": ["Avrim Blum", "Merrick L. Furst"], "venue": "Artificial intelligence,", "citeRegEx": "Blum and Furst.,? \\Q1997\\E", "shortCiteRegEx": "Blum and Furst.", "year": 1997}, {"title": "Solving POMDPs: RTDP-Bel vs. point-based algorithms", "author": ["Blai Bonet", "Hector Geffner"], "venue": "In Proc. of IJCAI-09,", "citeRegEx": "Bonet and Geffner.,? \\Q2009\\E", "shortCiteRegEx": "Bonet and Geffner.", "year": 2009}, {"title": "Course of action generation for cyber security using classical planning", "author": ["Mark S. Boddy", "Johnathan Gohde", "Thomas Haigh", "Steven A. Harp"], "venue": "In Proc. of ICAPS\u201905,", "citeRegEx": "Boddy et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Boddy et al\\.", "year": 2005}, {"title": "Quantitative Risk Analysis of Computer Networks", "author": ["Daniel Bilar"], "venue": "PhD thesis, Dartmouth College,", "citeRegEx": "Bilar.,? \\Q2003\\E", "shortCiteRegEx": "Bilar.", "year": 2003}, {"title": "Deterministic POMDPs revisited", "author": ["Blai Bonet"], "venue": "In Proc. of UAI\u201909,", "citeRegEx": "Bonet.,? \\Q2009\\E", "shortCiteRegEx": "Bonet.", "year": 2009}, {"title": "A discourse on winning and losing", "author": ["John R. Boyd"], "venue": "Technical report, USAF,", "citeRegEx": "Boyd.,? \\Q1987\\E", "shortCiteRegEx": "Boyd.", "year": 1987}, {"title": "Outrepasser les limites des techniques classiques de prise d\u2019empreintes grace aux r\u00e9seaux de neurones", "author": ["Javier Burroni", "Carlos Sarraute"], "venue": "In Symposium sur la Se\u0301curite\u0301 des Technologies de l\u2019Information et des Communications (SSTIC), Rennes, France,", "citeRegEx": "Burroni and Sarraute.,? \\Q2006\\E", "shortCiteRegEx": "Burroni and Sarraute.", "year": 2006}, {"title": "Application-level simulation for network security", "author": ["Rainer Bye", "Stephan Schmidt", "Katja Luther", "Sahin Albayrak"], "venue": "In Proceedings of the First International Conference on Simulation Tools and Techniques for Communications, Networks and Systems,", "citeRegEx": "Bye et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bye et al\\.", "year": 2008}, {"title": "Syscall Proxying - Simulating remote execution", "author": ["Max Caceres"], "venue": "Black Hat USA Conference,", "citeRegEx": "Caceres.,? \\Q2002\\E", "shortCiteRegEx": "Caceres.", "year": 2002}, {"title": "Exact and Approximate Algorithms for Partially Observable Markov Decision Processes", "author": ["Anthony R. Cassandra"], "venue": "PhD thesis,", "citeRegEx": "Cassandra.,? \\Q1998\\E", "shortCiteRegEx": "Cassandra.", "year": 1998}, {"title": "Modeling the spread of active worms", "author": ["Z. Chen", "L. Gao", "K. Kwiat"], "venue": "In Proceedings of IEEE INFOCOM", "citeRegEx": "Chen et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2003}, {"title": "Temporal planning using subgoal partitioning and resolution in SGPlan", "author": ["Yixin Chen", "Benjamin W. Wah", "Chihwei Hsu"], "venue": "J. of Artificial Intelligence Research,", "citeRegEx": "Chen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2006}, {"title": "VDE: virtual distributed Ethernet", "author": ["R. Davoli"], "venue": "In First International Conference on Testbeds and Research Infrastructures for the Development of Networks and Communities,", "citeRegEx": "Davoli.,? \\Q2005\\E", "shortCiteRegEx": "Davoli.", "year": 2005}, {"title": "A systematic approach to multi-stage network attack analysis", "author": ["J. Dawkins", "J. Hale"], "venue": "In Proc. of DISCEX III,", "citeRegEx": "Dawkins and Hale.,? \\Q2003\\E", "shortCiteRegEx": "Dawkins and Hale.", "year": 2003}, {"title": "Probabilistic planning via heuristic forward search and weighted model counting", "author": ["C. Domshlak", "J\u00f6rg Hoffmann"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Domshlak and Hoffmann.,? \\Q2007\\E", "shortCiteRegEx": "Domshlak and Hoffmann.", "year": 2007}, {"title": "Fidius: Intelligent support for vulnerability testing", "author": ["D. Elsbroek", "D. Kohlsdorf", "D. Menke", "L. Meyer"], "venue": "In Working Notes for the 2011 IJCAI Workshop on Intelligent Security (SecArt),", "citeRegEx": "Elsbroek et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Elsbroek et al\\.", "year": 2011}, {"title": "PDDL2.1: An extension to PDDL for expressing temporal planning domains", "author": ["M. Fox", "D. Long"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Fox and Long.,? \\Q2003\\E", "shortCiteRegEx": "Fox and Long.", "year": 2003}, {"title": "Large-scale vulnerability analysis", "author": ["Stefan Frei", "Martin May", "Ulrich Fiedler", "Bernhard Plattner"], "venue": "LSAD", "citeRegEx": "Frei et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Frei et al\\.", "year": 2006}, {"title": "Simulating cyber-attacks for fun and profit", "author": ["Ariel Futoransky", "Fernando Miranda", "Jose Orlicki", "Carlos Sarraute"], "venue": "In 2nd International Conference on Simulation Tools and Techniques (SIMUTools", "citeRegEx": "Futoransky et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Futoransky et al\\.", "year": 2009}, {"title": "Building computer network attacks", "author": ["Ariel Futoransky", "Luciano Notarfrancesco", "Gerardo Richarte", "Carlos Sarraute"], "venue": "Technical report, CoreLabs,", "citeRegEx": "Futoransky et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Futoransky et al\\.", "year": 2003}, {"title": "The Directed Steiner Network Problem is tractable for a constant number of terminals", "author": ["Jon Feldman", "Matthias Ruhl"], "venue": "In FOCS,", "citeRegEx": "Feldman and Ruhl.,? \\Q1999\\E", "shortCiteRegEx": "Feldman and Ruhl.", "year": 1999}, {"title": "The model-based approach to autonomous behavior: A personal view", "author": ["Hector Geffner"], "venue": "In Proceedings of AAAI-10. Atlanta,", "citeRegEx": "Geffner.,? \\Q2010\\E", "shortCiteRegEx": "Geffner.", "year": 2010}, {"title": "An intelligent technique for generating minimal attack graph", "author": ["Nirnay Ghosh", "S.K. Ghosh"], "venue": "In First Workshop on Intelligent Security (Security and Artificial Intelligence) (SecArt", "citeRegEx": "Ghosh and Ghosh.,? \\Q2009\\E", "shortCiteRegEx": "Ghosh and Ghosh.", "year": 2009}, {"title": "Automated Planning: theory and practice", "author": ["Malik Ghallab", "Dana Nau", "Paolo Traverso"], "venue": null, "citeRegEx": "Ghallab et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Ghallab et al\\.", "year": 2004}, {"title": "Historical applications of maneuver warfare in the 20th century", "author": ["Peter E. Higgins"], "venue": "Technical report,", "citeRegEx": "Higgins.,? \\Q1990\\E", "shortCiteRegEx": "Higgins.", "year": 1990}, {"title": "A common language for computer security incidents", "author": ["John D. Howard", "Thomas A. Longstaff"], "venue": "Sandia Report: SAND98-8667, Sandia National Laboratories,", "citeRegEx": "Howard and Longstaff.,? \\Q1998\\E", "shortCiteRegEx": "Howard and Longstaff.", "year": 1998}, {"title": "FF: The fast-forward planning system", "author": ["J\u00f6rg Hoffmann"], "venue": "AI magazine,", "citeRegEx": "Hoffmann.,? \\Q2001\\E", "shortCiteRegEx": "Hoffmann.", "year": 2001}, {"title": "Extending FF to numerical state variables", "author": ["J\u00f6rg Hoffmann"], "venue": "In Proceedings of the 15th European Conference on Artificial Intelligence", "citeRegEx": "Hoffmann.,? \\Q2002\\E", "shortCiteRegEx": "Hoffmann.", "year": 2002}, {"title": "Topological analysis of network attack vulnerability. Managing Cyber Threats: Issues, Approaches and Challenges", "author": ["S. Jajodia", "S. Noel", "B. O\u2019Berry"], "venue": null, "citeRegEx": "Jajodia et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Jajodia et al\\.", "year": 2005}, {"title": "Two formal analyses of attack graphs", "author": ["S. Jha", "O. Sheyner", "J. Wing"], "venue": "In 15th IEEE Computer Security Foundations Workshop,", "citeRegEx": "Jha et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Jha et al\\.", "year": 2002}, {"title": "Minimization and reliability analyses of attack", "author": ["Somesh Jha", "Jeannette Wing", "Oleg Sheyner"], "venue": null, "citeRegEx": "Jha et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Jha et al\\.", "year": 2002}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": null, "citeRegEx": "Koller and Friedman.,? \\Q2009\\E", "shortCiteRegEx": "Koller and Friedman.", "year": 2009}, {"title": "SARSOP: Efficient pointbased POMDP planning by approximating optimally reachable belief spaces", "author": ["H. Kurniawati", "D. Hsu", "W. Lee"], "venue": "In RSS IV,", "citeRegEx": "Kurniawati et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kurniawati et al\\.", "year": 2008}, {"title": "An annotated review of past papers on attack graphs", "author": ["Richard Lippmann", "Kyle Ingols"], "venue": "Technical Report ESC-TR-2005-054, Lincoln Laboratory,", "citeRegEx": "Lippmann and Ingols.,? \\Q2005\\E", "shortCiteRegEx": "Lippmann and Ingols.", "year": 2005}, {"title": "How to systematically classify computer security intrusions", "author": ["Ulf Lindqvist", "Erland Jonsson"], "venue": "Proceedings of the 1997 IEEE Symposium on Security and Privacy,", "citeRegEx": "Lindqvist and Jonsson.,? \\Q1997\\E", "shortCiteRegEx": "Lindqvist and Jonsson.", "year": 1997}, {"title": "Rinse: The real-time immersive network simulation environment for network security exercises", "author": ["Michael Liljenstam", "Jason Liu", "David Nicol", "Yougu Yuan", "Guanhua Yan", "Chris Grier"], "venue": "In Workshop on Principles of Advanced and Distributed Simulation,", "citeRegEx": "Liljenstam et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Liljenstam et al\\.", "year": 2005}, {"title": "Marionnet: A virtual network laboratory and simulation tool", "author": ["Jean-Vincent Loddo", "Luca Saiu"], "venue": "In First International Conference on Simulation Tools and Techniques for Communications, Networks and Systems,", "citeRegEx": "Loddo and Saiu.,? \\Q2008\\E", "shortCiteRegEx": "Loddo and Saiu.", "year": 2008}, {"title": "Attack Planning in the Real World", "author": ["Jorge Lucangeli", "Carlos Sarraute", "Gerardo Richarte"], "venue": "In Proceedings of the AAAI Workshop on Intelligent Security (SecArt", "citeRegEx": "Lucangeli et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lucangeli et al\\.", "year": 2010}, {"title": "Remote OS detection via TCP/IP stack fingerprinting", "author": ["Gordon Fyodor Lyon"], "venue": "Phrack Magazine,", "citeRegEx": "Lyon.,? \\Q1998\\E", "shortCiteRegEx": "Lyon.", "year": 1998}, {"title": "The PDDL Planning Domain Definition Language", "author": ["Drew McDermott"], "venue": "The AIPS-98 Planning Competition Committee,", "citeRegEx": "McDermott,? \\Q1998\\E", "shortCiteRegEx": "McDermott", "year": 1998}, {"title": "Attack modeling for information security and survivability", "author": ["A.P. Moore", "R.J. Ellison", "R.C. Linger"], "venue": "Technical Note CMU/SEI-2001TN-001,", "citeRegEx": "Moore et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Moore et al\\.", "year": 2001}, {"title": "A survey of partially observable Markov decision processes", "author": ["G. Monahan"], "venue": "Management Science,", "citeRegEx": "Monahan.,? \\Q1982\\E", "shortCiteRegEx": "Monahan.", "year": 1982}, {"title": "Penetration testing automation", "author": ["H.D. Moore"], "venue": "In SANS Penetration Testing Summit,", "citeRegEx": "Moore.,? \\Q2010\\E", "shortCiteRegEx": "Moore.", "year": 2010}, {"title": "Inside the slammer worm", "author": ["David Moore", "Vern Paxson", "Stefan Savage", "Colleen Shannon", "Stuart Staniford", "Nicholas Weaver"], "venue": "IEEE Security and Privacy,", "citeRegEx": "Moore et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Moore et al\\.", "year": 2003}, {"title": "Advances in Topological Vulnerability Analysis", "author": ["S. Noel", "M. Elder", "S. Jajodia", "P. Kalapa", "S. O\u2019Hare", "K. Prole"], "venue": "In Proceedings of the 2009 Cybersecurity Applications & Technology Conference for Homeland Security,", "citeRegEx": "Noel et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Noel et al\\.", "year": 2009}, {"title": "Managing attack graph complexity through visual hierarchical aggregation", "author": ["S. Noel", "S. Jajodia"], "venue": "In Proceedings of the 2004 ACM workshop on Visualization and data mining for computer security,", "citeRegEx": "Noel and Jajodia.,? \\Q2004\\E", "shortCiteRegEx": "Noel and Jajodia.", "year": 2004}, {"title": "Understanding complex network attack graphs through clustered adjacency matrices", "author": ["S. Noel", "S. Jajodia"], "venue": "In Proceedings of the 21st Annual Computer Security Applications Conference,", "citeRegEx": "Noel and Jajodia.,? \\Q2005\\E", "shortCiteRegEx": "Noel and Jajodia.", "year": 2005}, {"title": "Anytime point-based approximations for large POMDPs", "author": ["J. Pineau", "G. Gordon", "S. Thrun"], "venue": "JAIR, 27:335\u2013380,", "citeRegEx": "Pineau et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Pineau et al\\.", "year": 2006}, {"title": "A virtual honeypot framework", "author": ["Niels Provos"], "venue": "Proceedings of the 13th USENIX Security Symposium,", "citeRegEx": "Provos.,? \\Q2004\\E", "shortCiteRegEx": "Provos.", "year": 2004}, {"title": "A graph-based system for network-vulnerability analysis", "author": ["Cynthia A. Phillips", "Laura Painton Swiler"], "venue": "In Workshop on New Security Paradigms,", "citeRegEx": "Phillips and Swiler.,? \\Q1998\\E", "shortCiteRegEx": "Phillips and Swiler.", "year": 1998}, {"title": "Using model checking to analyze network vulnerabilities", "author": ["R. Ritchey", "Paul Ammann"], "venue": "In IEEE Symposium on Security and Privacy,", "citeRegEx": "Ritchey and Ammann.,? \\Q2000\\E", "shortCiteRegEx": "Ritchey and Ammann.", "year": 2000}, {"title": "Modern intrusion practices", "author": ["Gerardo Richarte"], "venue": "In Black Hat Briefings,", "citeRegEx": "Richarte.,? \\Q2003\\E", "shortCiteRegEx": "Richarte.", "year": 2003}, {"title": "Online planning algorithms for POMDPs", "author": ["S. Ross", "J. Pineau", "S. Paquet", "B. Chaib-draa"], "venue": "JAIR, 32:663\u2013704,", "citeRegEx": "Ross et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2008}, {"title": "Zombie 2.0", "author": ["F. Russ", "D. Tiscornia"], "venue": "In Hack.lu Conference,", "citeRegEx": "Russ and Tiscornia.,? \\Q2007\\E", "shortCiteRegEx": "Russ and Tiscornia.", "year": 2007}, {"title": "New algorithms for attack planning", "author": ["Carlos Sarraute"], "venue": "In FRHACK Conference,", "citeRegEx": "Sarraute.,? \\Q2009\\E", "shortCiteRegEx": "Sarraute.", "year": 2009}, {"title": "Probabilistic Attack Planning in Network + WebApps Scenarios", "author": ["Carlos Sarraute"], "venue": null, "citeRegEx": "Sarraute.,? \\Q2009\\E", "shortCiteRegEx": "Sarraute.", "year": 2009}, {"title": "Using AI Techniques to improve Pentesting Automation", "author": ["Carlos Sarraute"], "venue": "In Hackito Ergo Sum (HES), Paris, France,", "citeRegEx": "Sarraute.,? \\Q2010\\E", "shortCiteRegEx": "Sarraute.", "year": 2010}, {"title": "On exploit quality metrics \u2013 and how to use them for automated pentesting", "author": ["Carlos Sarraute"], "venue": null, "citeRegEx": "Sarraute.,? \\Q2011\\E", "shortCiteRegEx": "Sarraute.", "year": 2011}, {"title": "Some research directions in automated pentesting", "author": ["Carlos Sarraute"], "venue": null, "citeRegEx": "Sarraute.,? \\Q2011\\E", "shortCiteRegEx": "Sarraute.", "year": 2011}, {"title": "Decomposing the network to perform attack planning under uncertainty", "author": ["Carlos Sarraute"], "venue": "In Hackito Ergo Sum (HES), Paris, France,", "citeRegEx": "Sarraute.,? \\Q2012\\E", "shortCiteRegEx": "Sarraute.", "year": 2012}, {"title": "Penetration testing == POMDP planning", "author": ["Carlos Sarraute", "Olivier Buffet", "J\u00f6rg Hoffmann"], "venue": "In Proceedings of the 3rd Workshop on Intelligent Security (SecArt\u201911),", "citeRegEx": "Sarraute et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sarraute et al\\.", "year": 2011}, {"title": "Les POMDP font de meilleurs hackers: Tenir compte de l\u2019incertitude dans les tests de p\u00e9n\u00e9tration", "author": ["Carlos Sarraute", "Olivier Buffet", "J\u00f6rg Hoffmann"], "venue": "In Proceedings of JFPDA-12,", "citeRegEx": "Sarraute et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sarraute et al\\.", "year": 2012}, {"title": "POMDPs make better hackers: Accounting for uncertainty in penetration testing", "author": ["Carlos Sarraute", "Olivier Buffet", "J\u00f6rg Hoffmann"], "venue": "In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence", "citeRegEx": "Sarraute et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sarraute et al\\.", "year": 2012}, {"title": "Secrets & lies: digital security in a networked world, chapter 21", "author": ["Bruce Schneier"], "venue": null, "citeRegEx": "Schneier.,? \\Q2000\\E", "shortCiteRegEx": "Schneier.", "year": 2000}, {"title": "Automated generation and analysis of attack graphs", "author": ["O. Sheyner", "J. Haines", "S. Jha", "R. Lippmann", "J.M. Wing"], "venue": "In IEEE Symposium on Security and Privacy,", "citeRegEx": "Sheyner et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Sheyner et al\\.", "year": 2002}, {"title": "Symbolic heuristic search value iteration for factored POMDPs", "author": ["H.S. Sim", "K.-E. Kim", "J.H. Kim", "D.-S. Chang", "M.-W. Koo"], "venue": "In Proc. of AAAI\u201908,", "citeRegEx": "Sim et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sim et al\\.", "year": 2008}, {"title": "A snapshot of global internet worm activity", "author": ["D. Song", "R. Malan", "R. Stone"], "venue": "Technical report, Arbor Networks,", "citeRegEx": "Song et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Song et al\\.", "year": 2001}, {"title": "A graphbased network-vulnerability analysis system", "author": ["Laura P. Swiler", "Cynthia Phillips", "Timothy Gaylor"], "venue": "Technical report,", "citeRegEx": "Swiler et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Swiler et al\\.", "year": 1998}, {"title": "Honeypots: Tracking Hackers", "author": ["L. Spitzner"], "venue": null, "citeRegEx": "Spitzner.,? \\Q2002\\E", "shortCiteRegEx": "Spitzner.", "year": 2002}, {"title": "An algorithm to find optimal attack paths in nondeterministic scenarios", "author": ["Carlos Sarraute", "Gerardo Richarte", "Jorge Lucangeli"], "venue": "In Proceedings of the ACM Workshop on Artificial Intelligence and Security (AISec\u201911),", "citeRegEx": "Sarraute et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sarraute et al\\.", "year": 2011}, {"title": "Heuristic search value iteration for POMDPs", "author": ["T. Smith", "R.G. Simmons"], "venue": "In Proc. of UAI\u201904,", "citeRegEx": "Smith and Simmons.,? \\Q2004\\E", "shortCiteRegEx": "Smith and Simmons.", "year": 2004}, {"title": "Perseus: Randomized point-based value iteration for POMDPs", "author": ["M. Spaan", "N. Vlassis"], "venue": "JAIR, 24:195\u2013220,", "citeRegEx": "Spaan and Vlassis.,? \\Q2005\\E", "shortCiteRegEx": "Spaan and Vlassis.", "year": 2005}, {"title": "Advances in automated attack planning", "author": ["Carlos Sarraute", "Alejandro Weil"], "venue": "In PacSec Conference,", "citeRegEx": "Sarraute and Weil.,? \\Q2008\\E", "shortCiteRegEx": "Sarraute and Weil.", "year": 2008}, {"title": "Modeling internet attacks", "author": ["T. Tidwell", "R. Larson", "K. Fitch", "J. Hale"], "venue": "In Proceedings of the 2001 IEEE Workshop on Information Assurance and Security,", "citeRegEx": "Tidwell et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Tidwell et al\\.", "year": 2001}, {"title": "Scalability, fidelity, and containment in the Potemkin virtual honeyfarm", "author": ["Michael Vrable", "Justin Ma", "Jay Chen", "David Moore", "Erik Vandekieft", "Alex C. Snoeren", "Geoffrey M. Voelker", "Stefan Savage"], "venue": "SIGOPS Oper. Syst. Rev.,", "citeRegEx": "Vrable et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Vrable et al\\.", "year": 2005}, {"title": "Distributed worm simulation with a realistic internet model", "author": ["Songjie Wei", "Jelena Mirkovic", "Martin Swany"], "venue": "In PADS \u201905: Proceedings of the 19th Workshop on Principles of Advanced and Distributed Simulation,", "citeRegEx": "Wei et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Wei et al\\.", "year": 2005}, {"title": "The design and use of internet sinks for network abuse monitoring", "author": ["V. Yegneswaran", "P. Barford", "D. Plonka"], "venue": "In Proceedings of Recent Advances in Intrusion Detection (RAID),", "citeRegEx": "Yegneswaran et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Yegneswaran et al\\.", "year": 2004}, {"title": "PPDDL 1.0: The language for the probabilistic part of IPC-4", "author": ["H.L.S. Younes", "M.L. Littman"], "venue": "In Proc. International Planning Competition,", "citeRegEx": "Younes and Littman.,? \\Q2004\\E", "shortCiteRegEx": "Younes and Littman.", "year": 2004}], "referenceMentions": [], "year": 2013, "abstractText": "x Acknowledgements xii Chapter", "creator": "LaTeX with hyperref package"}}}