{"id": "1311.6421", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Nov-2013", "title": "Synchronous Context-Free Grammars and Optimal Linear Parsing Strategies", "abstract": "Synchronous Context-Free Grammars (SCFGs), also known as syntax-directed translation schemata, are unlike context-free grammars in that they do not have a binary normal form. In general, parsing with SCFGs takes space and time polynomial in the length of the input strings, but with the degree of the polynomial depending on the permutations of the SCFG rules. We consider linear parsing strategies, which add one nonterminal at a time. We show that for a given input permutation, the problems of finding the linear parsing strategy with the minimum space and time complexity are both NP-hard.", "histories": [["v1", "Mon, 25 Nov 2013 19:48:30 GMT  (45kb)", "http://arxiv.org/abs/1311.6421v1", null]], "reviews": [], "SUBJECTS": "cs.FL cs.CL", "authors": ["pierluigi crescenzi", "daniel gildea", "rea marino", "gianluca rossi", "giorgio satta"], "accepted": false, "id": "1311.6421"}, "pdf": {"name": "1311.6421.pdf", "metadata": {"source": "CRF", "title": "Synchronous Context-Free Grammars and Optimal Linear Parsing Strategies", "authors": ["Pierluigi Crescenzi", "Daniel Gildea", "Andrea Marino", "Gianluca Rossi", "Giorgio Satta"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n31 1.\n64 21\nv1 [\ncs .F\nL ]\n2 5\nSynchronous Context-Free Grammars (SCFGs), also known as syntax-directed translation schemata [AU69, AU72], are unlike context-free grammars in that they do not have a binary normal form. In general, parsing with SCFGs takes space and time polynomial in the length of the input strings, but with the degree of the polynomial depending on the permutations of the SCFG rules. We consider linear parsing strategies, which add one nonterminal at a time. We show that for a given input permutation, the problems of finding the linear parsing strategy with the minimum space and time complexity are both NP-hard."}, {"heading": "1 Introduction", "text": "SynchronousContext-FreeGrammars (SCFGs) are widely used tomodel translational equivalence between strings in both the area of compilers for programming languages and, more recently, in the area of machine translation of natural languages. The formalism was first introduced by Lewis and Stearns [LS68] under the name of syntax-directed transduction grammars, and was later called syntax-directed translation schemata by Aho and Ullman [AU69, AU72]. The name SCFG, which we use in this article, was later introduced in the literature on computational linguistics, where the term \u201csynchronous\u201d refers to rewriting systems that generate strings in both a source and target language simultaneously [SS90, SS94, Chi04]. In fact, SCFGs can be seen as a natural extension of the well-known rewriting formalism of Context-Free Grammars (CFGs). More precisely, while a CFG generates a set of strings, a SCFG generates a set of string pairs using essentially the same context-free rewriting mechanism, along with some special synchronization between the two derivations, as discussed below.\n\u2217Dipartimento di Sistemi e Informatica, Universita\u0300 di Firenze, Viale Morgagni, 65, 50134 Firenze, Italy. \u2020Computer Science Department, University of Rochester, Rochester, NY 14627. \u2021Dipartimento di Informatica, Universita\u0300 di Milano, Via Festa del Perdono 7, 20122 Milano, Italy. \u00a7Dipartimento di Matematica, Universita\u0300 di Roma Tor Vergata, Via Ricerca Scientifica 1, 00133 Roma, Italy. \u00b6Department of Information Engineering, University of Padua, Via Gradenigo 6/A, 35131 Padova, Italy.\nA SCFG is a string rewriting system based on synchronous rules. Informally, a synchronous rule is composed of two CFG rules along with a bijective pairing between all the occurrences of the nonterminal symbols in the right-hand side of the first rule and all the occurrences of the nonterminal symbols in the right-hand side of the second rule. There is no restriction on the terminal symbols appearing in the right-hand sides of the two CFG rules. Two nonterminal occurrences that are associated by the above bijection are called linked nonterminals. Linked nonterminals are not necessarily occurrences of the same nonterminal symbol. In what follows, we will often view a synchronous rule as a permutation of the nonterminal occurrences in the two right-hand sides, combined with some renaming of these occurrences and with some insertion and deletion of terminal symbols.\nIn a SCFG rewriting is restricted in two ways: the two CFG rule components in a synchronous rule must be applied simultaneously, and rewriting must take place at linked nonterminals. Other than that, the application of a synchronous rule is independent of the context, similarly to the CFG case. As a result, a SCFG generates a pair of strings by means of two context-free parse trees that have the same skeleton but differ by some reordering and renaming of the nonterminal children at each internal node, and by the insertion and the deletion of the terminal children of that node. Moreover, the projection of the generated string pairs on both dimensions are still context-free languages. Thus, the added generative power of a SCFG lies in its ability to model long-distance movement of phrase constituents in the translation from the source to the target language, through simple permutations implemented at the internal nodes in the generated trees, something that is not possible with models based on finite-state transducers.\nRecently, SCFGs have received wide attention in the area of natural language processing, where several variants of SCFGs augmented with probabilities are currently used for translation between natural languages. This is due to the recent surge of interest in commercial systems for statistical machine translation working on large scale, real-world applications such as the translation of text documents from the world-wide web. However, from a theoretical perspective our knowledge of the parsing problem based on SCFGs and of several related tasks is quite limited, with many questions still left unanswered, as discussed below. This is rather surprising, in view of the fact that SCFGs are a very natural extension of the class of CFGs, for which the parsing problem has been extensively investigated and is well understood nowadays.\nIn the context of statistical machine translation, SCFGs are automatically induced from parallel corpora, that is, very large collections of source texts that come with target translations, and are usually enriched with annotations aligning source and target words [Chi07, GHKM04]. Alternative translation models are currently in use in machine translation, such as word-to-word translation models [BDDM93] or phrase-based translation models [KOM03], which are essentially finite-state models. However, it has been experimentally shown that the more powerful generative capacity of SCFGs achieves better accuracy than finite-state models in real-world machine translation applications [Chi07].\nThe recognition (or membership) problem for SCFGs is defined as follows. Given as input a SCFG G and strings w1 and w2, we have to decide whether the pair w1,w2 can be generated by G. The parsing problem for SCFGs (or synchronous parsing problem) is defined for the same input\nG, w1 and w2, and produces as output some suitable representation of the set of all parse trees in G that generate w1 and w2. Finally, the decoding (or translation) problem for SCFGs requires as input a SCFG G and a single string w1, and produces as output some suitable representation of the set of all parse trees in G that generate pairs of the form w1,w2, for some string w2. In this paper we investigate the synchronous parsing problem, which is strictly related to the other two problems, as will be discussed in more detail in Section 5.\nFrom the perspective of synchronous parsing, a crucial difference between CFGs and SCFGs is that SCFGs cannot always be binarized, that is, cast into a normal form with no more than two nonterminals on the right-hand side of each rule component in a synchronous rule. In fact, SCFGs form an infinite hierarchy, where grammars with at most r nonterminals on the right-hand side of a rule can generate sets of string pairs not achievable by grammars with the same quantity bounded by r\u2212 1, for each r > 3 [AU72]. Binarization is crucial to standard algorithms for CFG parsing, whether explicitly as a preprocessing transformation on the grammar, as for instance in the case of the Cocke-Kasami-Younger algorithm [You67], or implicitly through the use of dotted rule symbols indicating which nonterminals have already been parsed, as in the case of Earley algorithm [Ear70]. Unfortunately these techniques cannot be applied to SCFGs, because of the above restrictions on binarization, and the parsing problem for SCFGs seems significantly more complex than the parsing problem for CFGs, from a computational perspective. While parsing for CFGs can be solved in polynomial space and time by the above mentioned algorithms, it has been shown in [SP05] that parsing for SCFGs is NP-hard, when the grammar is considered as part of the input.\nDespite this hardness result, when the SCFG is fixed, parsing can be performed in time polynomial in the length of the input strings using the bottom-up dynamic programming framework described in Section 2. The degree of the polynomial is determined by themaximum complexity of any rule in the grammar, because rules are parsed independently of one another. More precisely, the complexity of a given rule isO(nd(\u03c0,\u03c3)), where n is the sentence length, and d is some function of \u03c0, the permutation associated with the rule, and \u03c3, a parsing strategy for the rule. This leads us to consider the problem of finding the best strategy for a given rule, that is, finding the \u03c3 that minimizes d(\u03c0, \u03c3). We investigate the problem of finding the best linear parsing strategy for a given synchronous rule, that is, the ways of collecting one after the other the linked nonterminals in a synchronous rule that result in the optimization of the space and time complexity for synchronous parsing. We show that this task is NP-hard. This solves an open problem that has been addressed in several previously published works; see for instance [GS\u030c07], [HZGK09], and [CGM+11].\nRelationwith previouswork The problem that we explore in this article is an instance of a grammar factorization problem. Factorization is the general method of breaking a grammar rule into a number of equivalent, smaller rules, usually for the purpose of finding efficient parsing algorithms. Our linear parsing strategies for SCFGs process two linked nonterminals from the original rule at each step. Each of these steps is equivalent to applying a binary rule in another rewriting system, which must be more general than SCFGs, since after all SCFGs cannot be binarized.\nThe general problem of grammar factorization has received a great deal of study recently in the\nfield of computational linguistics, with the rise of statistical systems for natural language translation, as well as systems for parsing with monolingual grammars that are more powerful than CFGs [HZGK09, GRKSW09, SS10, GRKS10]. Most work in this area addresses some subclasses of the very general rewriting framework known as Linear Context-Free Rewriting Systems (LCFRS) [VSWJ87], which is equivalent to Multiple Context-Free Grammars [SMFK91], and which subsumes SCFGs and many other formalisms. Many algorithms have been proposed for efficiently factorizing subclasses of LCFRS, in order to optimize parsing under various criteria. Our result in this article is a hardness result, showing that such algorithms cannot generalize to the widely used and theoretically important class of SCFGs. A related result has been presented by Crescenzi et al. [CGM+11], showing that optimal linear factorization for general LCFRS is NP-hard. Their reduction involves constructing LCFRS rules that are not valid as SCFG rules. Indeed, as already mentioned, SCFG rules can be viewed as permutations, and the special structure of these objects makes reductions less straightforward than in the case of LCFRS. This article therefore strengthens the result in [CGM+11], showing that even if we restrict ourselves to SCFGs, detection of optimal linear parsing strategies is still NP-hard."}, {"heading": "2 Preliminaries", "text": "In this section we formally introduce the class of synchronous context-free grammars, along with the computational problem that we investigate in this article. We assume the reader to be familiar with basic definitions from formal language theory, and we only briefly summarize here the adopted notation.\nFor any positive integer n, we write [n] to denote the set {1, . . . , n}, and for n = 0 we let [n] be\nthe empty set. We also write [n]0 to denote the set [n] \u222a {0}."}, {"heading": "2.1 Synchronous Context-Free Grammars", "text": "Let \u03a3 be some finite alphabet. A string x over \u03a3 is a finite ordered sequence of symbols from \u03a3. The length of x is written |x|; the empty string is denoted by \u03b5 and we have |\u03b5| = 0. We write \u03a3\u2217 for the set of all strings over \u03a3, and \u03a3+ = \u03a3\u2217 \\ {\u03b5}. For strings x, y \u2208 \u03a3\u2217, x \u00b7 y denotes the concatenation of x and y, which we abbreviate as xy.\nA context-free grammar (CFG for short) is a tuple G = (VN,VT, P, S), where VN is a finite set of nonterminals, VT is a finite set of terminals with VT \u2229 VN = \u2205, S \u2208 VN is a special symbol called the start symbol, and P is a finite set of rules having the form A \u2192 \u03b1, with A \u2208 VN and \u03b1 \u2208 (VT \u222aVN) \u2217. The size of a CFG G is defined as |G| = \u2211(A\u2192\u03b3)\u2208P |A\u03b3|.\nThe derive relation associated with a CFG G is written \u21d2G ; we also use the reflexive and transitive closure of \u21d2G , written \u21d2 \u2217 G . The language (set of strings) derived in G is defined as L(G) = {w | S \u21d2\u2217G w, w \u2208 V \u2217 T}.\nIn what follows we need to represent bijections between the occurrences of nonterminals in two strings over VN \u222a VT. This can be realized by annotating nonterminals with indices from an infinite set. In this article, we draw indices from the set of positive natural numbers N. We define\nI(VN) = {A t | A \u2208 VN, t \u2208 N} and VI = I(VN) \u222aVT. For a string \u03b3 \u2208 V \u2217 I , we write index(\u03b3) to denote the set of all indices that appear in symbols in \u03b3.\nTwo strings \u03b31,\u03b32 \u2208 V \u2217 I are synchronous if each index from N occurs at most once in \u03b31 and\nat most once in \u03b32, and index(\u03b31) = index(\u03b32). Therefore \u03b31,\u03b32 have the general form\n\u03b31 = u1,0A t1 1,1u1,1A t2 1,2u1,2 \u00b7 \u00b7 \u00b7 u1,r\u22121A tr 1,ru1,r \u03b32 = u2,0A t\u03c0(1) 2,1 u2,1A t\u03c0(2) 2,2 u2,2 \u00b7 \u00b7 \u00b7 u2,r\u22121A t\u03c0(r) 2,r u2,r\nwhere r \u2265 0, u1,i, u2,i \u2208 V \u2217 T for each i \u2208 [r]0, A\nti 1,i , A t\u03c0(i) 2,i \u2208 I(VN) for each i \u2208 [r], ti 6= tj for\ni 6= j, and \u03c0 is a permutation of the set [r]. Note that, under the above convention, nonterminals A1,i, A2,\u03c0\u22121(i) appear with the same index ti, for each i \u2208 [r]. In a pair of synchronous strings, two nonterminal occurrences with the same index are called linked nonterminals.\nA synchronous context-free grammar (SCFG) is a tuple G = (VN,VT, P, S), 1 where VN, VT and S are defined as for CFGs, and P is a finite set of synchronous rules. Each synchronous rule has the form [A1 \u2192 \u03b11, A2 \u2192 \u03b12], where A1, A2 \u2208 VN and where \u03b11, \u03b12 \u2208 V \u2217 I are synchronous strings. We refer to A1 \u2192 \u03b11 and A2 \u2192 \u03b12, respectively, as the left and right components of the synchronous rule. Note that if we ignore the indices annotating the nonterminals in \u03b11 and \u03b12, then A1 \u2192 \u03b11 and A2 \u2192 \u03b12 are context-free rules.\nExample 1. The list of synchronous rules reported below implicitly defines a SCFG. Symbols si are rule labels, to be used as references in later examples.\ns1 : [S \u2192 A 1 B 2 , S \u2192 B 2 A 1 ] s2 : [A \u2192 aA 1 b, A \u2192 bA 1 a] s3 : [A \u2192 ab, A \u2192 ba] s4 : [B \u2192 cB 1 d, B \u2192 dB 1 c] s5 : [B \u2192 cd, B \u2192 dc]\nWe now define the notion of derivation associated with a SCFG. In a derivation we rewrite a pair of synchronous strings, always producing a new pair of synchronous strings. This is done in several steps, where, at each step, two linked nonterminals are rewritten by a synchronous rule. We use below the auxiliary notion of reindexing, which is an injective function f from N to N. We extend f to VI by letting f (A t ) = A f (t) for A t \u2208 I(VN) and f (a) = a for a \u2208 VT. We also extend f to strings in V\u2217I by letting f (\u03b5) = \u03b5 and f (X\u03b3) = f (X) f (\u03b3), for each X \u2208 VI and \u03b3 \u2208 V \u2217 I .\nLet \u03b31,\u03b32 \u2208 V \u2217 I be two synchronous strings. The derive relation [\u03b31, \u03b32] \u21d2G [\u03b41, \u03b42] holds whenever there exist an index t in index(\u03b31) = index(\u03b32), a synchronous rule s \u2208 P of the form [A1 \u2192 \u03b11, A2 \u2192 \u03b12], and some reindexing f such that\n(i) index( f (\u03b11)) \u2229 (index(\u03b31) \\ {t}) = \u2205;\n(ii) \u03b31 = \u03b3 \u2032 1A t 1 \u03b3 \u2032\u2032 1 , \u03b32 = \u03b3 \u2032 2A t 2 \u03b3 \u2032\u2032 2 ; and\n(iii) \u03b41 = \u03b3 \u2032 1 f (\u03b11)\u03b3 \u2032\u2032 1 , \u03b42 = \u03b3 \u2032 2 f (\u03b12)\u03b3 \u2032\u2032 2 .\n1We overload symbol G . It will always be clear from the context whether G refers to a CFG or to a SCFG.\nWe also write [\u03b31, \u03b32] \u21d2 s G [\u03b41, \u03b42] to explicitly indicate that the derive relation holds through rule s.\nNote that \u03b41, \u03b42 above are guaranteed to be synchronous strings, because \u03b11 and \u03b12 are synchronous strings and because of condition (i) above. Note also that, for a given pair [\u03b31, \u03b32] of synchronous strings, an index t and a synchronous rule as above, there may be infinitely many choices of a reindexing f such that the above constraints are satisfied. However, all essential results about SCFGs are independent of the specific choice of reindexing, and therefore we will not further discuss this issue here.\nA derivation in G is a sequence \u03c3 = s1s2 \u00b7 \u00b7 \u00b7 sd, d \u2265 0, of synchronous rules si \u2208 P, i \u2208 [d], with \u03c3 = \u03b5 for d = 0, satisfying the following property. For some pairs of synchronous strings [\u03b31,i, \u03b32,i], i \u2208 [d]0, we have [\u03b31,i\u22121, \u03b32,i\u22121] \u21d2 si G [\u03b31,i, \u03b32,i] for each i \u2208 [d]. We always implicitly assume some canonical form for derivations in G, by demanding for instance that each step rewrites a pair of linked nonterminal occurrences of which the first is leftmost in the left component. Whenwewant to focus on the specific synchronous strings being derived, we also write derivations in the form [\u03b31,0, \u03b32,0] \u21d2 \u03c3 G [\u03b31,d, \u03b32,d], and we write [\u03b31,0, \u03b32,0] \u21d2 \u2217 G [\u03b31,d, \u03b32,d] when \u03c3 is not further specified. The translation generated by a SCFG G is defined as\nT(G) = {[w1, w2] | [S 1 , S 1 ] \u21d2\u2217G [w1, w2], w1,w2 \u2208 V \u2217 T} .\nExample 2. Consider the SCFG G from Example 1. The following is a (canonical) derivation in G\n[S 1 , S 1 ] \u21d2s1G [A 1 B 2 , B 2 A 1 ]\n\u21d2s2G [aA 3 bB 2 , B 2 bA 3 a] \u21d2s2G [aaA 4 bbB 2 , B 2 bbA 4 aa] \u21d2s3G [aaabbbB 2 , B 2 bbbaaa] \u21d2s4G [aaabbbcB 5 d, dB 5 cbbbaaa] \u21d2s5G [aaabbbccdd, ddccbbbaaa]\nIt is not difficult to see that T(G) = {[apbpcqdq, dqcqbpap] | p, q \u2265 1}.\nWe conclude this section with a remark. Our definition of SCFG is essentially the same as the definition of the syntax-directed transduction grammars in [LS68] and the syntax-directed translation schemata in [AU69, AU72], as already mentioned in the introduction. The only difference is that in a synchronous rule [A1 \u2192 \u03b11, A2 \u2192 \u03b12] we allow A1, A2 to be different nonterminals, while in the above formalisms we always have A1 = A2. Although our generalization does not add to the weak generative power of the model, that is, the class of translations generated by the two models are the same, it does increase its strong generative capacity, that is, the parse tree mappings defined by syntax-directed translation schemata are a proper subset of the parse tree mappings defined by SCFGs. As a consequence of this fact, when the definitions of the two models are enrichedwith probabilities, SCFGs can define certain parse tree distributions that cannot be captured by syntax-directed translation schemata, as argued in [SP05]. The above generalization has been adopted in several translation models for natural language."}, {"heading": "2.2 Parsing Strategies for SCFGs", "text": "Recognition and parsing algorithms for SCFGs are commonly used in the area of statistical machine translation. Despite the fact that the underlying problems are NP-hard, it has been experimentally shown that the typology of synchronous rules that we encounter in real world applications can be processed efficiently, for the most of the cases, if we adopt the appropriate parsing strategy, as already discussed in Section 1. We are thus interested in the problem of finding optimal parsing strategies for synchronous rules, under some specific parsing framework.\nStandard parsing algorithms for SCFGs exploit dynamic programming techniques, and are derived as a generalization of the well-known Cocke-Kasami-Younger algorithm for word recognition based on CFGs [You67, HU79], which essentially uses a bottom-up strategy. All these algorithms are based on the representation described below. For a string w = a1 \u00b7 \u00b7 \u00b7 an, n \u2265 1, and for integers i, j \u2208 [n]0 with i < j, we write w[i, j] to denote the substring ai+1 \u00b7 \u00b7 \u00b7 aj. Assume we are given the input pair [w1, w2]. To simplify the discussion, we focus on a sample synchronous rule containing only occurrences of nonterminal symbols\ns : [A1 \u2192 A 1 1,1A 2 1,2A 3 1,3A 4 1,4A 5 1,5A 6 1,6,\nA2 \u2192 A 6 2,1A 1 2,2A 4 2,3A 2 2,4A 5 2,5A 3 2,6], (1)\nSynchronous rule s can be associated with the permutation \u03c0 of the set [6] identified by the sequence 614253, which is visualized in Figure 1a. Recall that, for each k \u2208 [6], nonterminals A1,k, A2,\u03c0\u22121(k) are linked in rule s.\nAssume that, for each k \u2208 [6], we have already parsed linked nonterminals A1,k, A2,\u03c0\u22121(k), re-\nalizing that [A 11,k, A 1 2,\u03c0\u22121(k) ] \u21d2\u2217G [w1[i1,k, j1,k], w2[i2,\u03c0\u22121(k), j2,\u03c0\u22121(k)]], for integers i1,k, j1,k \u2208 [|w1|]0 and i2,\u03c0\u22121(k), j2,\u03c0\u22121(k) \u2208 [|w2|]0. Informally, we say that linked nonterminals A1,k, A2,\u03c0\u22121(k) span substrings w1[i1,k, j1,k] and w2[i2,\u03c0\u22121(k), j2,\u03c0\u22121(k)] of the input. In order to parse the left-hand side nonterminals A1, A2, we need to gather together all linked nonterminals A1,k, A2,\u03c0\u22121(k), and check whether the combination of the above derivations can provide a new derivation of the form [A 11 , A 1 2 ] \u21d2 \u2217 G [w1[i1,1, j1,6], w2[i2,1, j2,6]]. In other words, we want to know whether the combination of the derivations for linked nonterminals A1,k, A2,\u03c0\u22121(k) can span two (contiguous) substrings of the input.\nFor reasons of computational efficiency, it is advantageous to break the parsing of a synchronous rule into several steps, adding linked nonterminals one pair at each step, according to some fixed total ordering, which we call a linear parsing strategy. The result of the partial analyses obtained at each step is represented by means of a data structure which we call a state. To provide a concrete example, let us choose the linear parsing strategy \u03c3 of gathering all the A1k\u2019s on the first component of rule s from left to right. At the first step we then collect linked nonterminals A1,1, A2,\u03c0\u22121(1) = A2,2 and construct the partial analysis represented by the state \u3008(s, \u03c3, 1), (i1,1, j1,1), (i2,2, j2,2)\u3009, meaning that A1,1 spans substring w1[i1,1, j1,1] and A2,2 spans substring w2[i2,2, j2,2]. The first element in the state, (s, \u03c3, 1), indicates that this state is generated from synchronous rule s after the first combination step, assuming our current strategy \u03c3. We refer to this first element as the type of the state.\nAssuming now that j1,1 = i1,2, at the second step we add to our partial analysis the linked nonterminals A1,2, A2,4, as shown in Figure 1b. We construct a new state \u3008(s, \u03c3, 2), (i1,1, j1,2), (i2,2, j2,2), (i2,4, j2,4)\u3009, meaning that A1,1, A1,2 together span w1[i1,1, j1,2], A2,2 spans w2[i2,2, j2,2] and A2,4 spans w2[i2,4, j2,4]. Note here that the specific value of j1,1 = i1,2 is dropped from the description of the state, since it will not be referenced by any further step based on the associated partial analysis. After adding the third pair of linked nonterminals A1,3, A2,6, and assuming j1,2 = i1,3, we create state \u3008(s, \u03c3, 3), (i1,1, j1,3), (i2,2, j2,2), (i2,4, j2,4), (i2,6, j2,6)\u3009, spanning four separate substrings of the input, as shown in Figure 1c. Assume now that j2,2 = i2,3 and j2,3 = i2,4. After adding the linked nonterminals A1,4, A2,3, we have that the span of A2,3 fills in the gap between the spans of the previously parsed nonterminals A2,2 and A2,4, as shown in Figure 1d. We can then collapse these three spans into a single string, obtaining a new state \u3008(s, \u03c3, 4), (i1,1, j1,4), (i2,2, j2,4), (i2,6, j2,6)\u3009which spans three separate substrings of the input. Finally, assuming that j2,1 = i2,2 and j2,4 = i2,5, at the next two steps states of type (s, \u03c3, 5) and (s, \u03c3, 6) can be constructed, each spanning two substrings only.\nWe refer below to the number of substrings spanned by a state as the fan-out of the state (this notion will be formally defined later). The above example shows that the fan-out of each state depends on the parsing strategy that we are adopting.\nBottom-up dynamic programming algorithms for the parsing problem for SCFGs are designed on the basis of the above state representation for partial analyses. These algorithms store in some appropriate data structure the states that have already been constructed, and then retrieve and combine states in order to construct new states. Let n be the maximum length between the input strings w1 and w2. Because a state with fan-out f may have O(n 2 f ) instantiations, fan-out provides a way of bounding the space complexity of our algorithm. When we use linear parsing strategies, fan-out is also relevant in assessing upper bounds on time complexity. Consider the basic step of adding the (k + 1)-th pair of linked nonterminals to a state of type (s, \u03c3, k) having fan-out f . As before, we have O(n2 f ) instantiations for states of type (s, \u03c3, k). We also have O(n4) possible instantiations for the span of the (k + 1)-th pair, since any pair of linked nonterminals spans exactly two substrings. However, the (k + 1)-th pair might share some of its boundaries with the boundaries of the state of type (s, \u03c3, k), depending on the permutation associated with the synchronous rule s. If we define \u03b4(s, \u03c3, k) as the number of independent boundaries in the (k+ 1)-th pair, with 0 \u2264 \u03b4(s, \u03c3, k) \u2264 4, we have that all executions of the above step can be carried out in time O(n2 f+\u03b4(s,\u03c3,k)).\nIf we want to optimize the space or the time complexity of a dynamic programming algorithm cast in the above framework, we need to search for a parsing strategy that minimizes the maximum fan-out of its states, or else a strategy that minimizes the maximum value of the sum of the fan-out and the \u03b4() function. This needs to be done for each individual synchronous rule in the grammar. In our running example, the critical step is provided by state type (s, \u03c3, 3) with fanout 4, leading to space complexity of O(n8). Furthermore, the combination of state type (s, \u03c3, 2) (fan-out 3) with linked pair A1,3, A2,6 (\u03b4(s, \u03c3, 3) = 3) leads to time complexity of O(n 9). However, we can switch to a different strategy \u03c3\u2032, by collecting linked nonterminal pairs in s in the order given by the left components A1,4, A1,5, A1,2, A1,3, A1,1, A1,6. According to this new strategy, states\nof types (s, \u03c3\u2032, 2) and (s, \u03c3\u2032, 3) both have fan-out three, while every other state type has fan-out two. This leads to space complexity of O(n6) for rule s. It is not difficult to see that this strategy is also space optimal for rule s, on the basis of the observation that any grouping of two linked nonterminals A1,k, A2,\u03c0\u22121(k) and A1,k\u2032 , A2,\u03c0\u22121(k\u2032) with k, k \u2032 \u2208 [6] and k 6= k\u2032, has a fan-out of at least three. As for the time complexity, the critical step is the combination of state type (s, \u03c3\u2032 , 2) (fan-out 3) with linked pair A1,2, A2,4 (\u03b4(s, \u03c3 \u2032 , 3) = 2), leading to time complexity of O(n8) for this strategy. It is not difficult to verify that \u03c3\u2032 is also a time optimal strategy."}, {"heading": "2.3 Fan-out and Optimization of Parsing", "text": "What we have informally shown in the previous section is that, under the outlined framework based on state representations for partial analyses, we can exploit the properties of the specific permutation of a given synchronous rule to reduce the maximum fan-out of states, and hence improve the space and time complexity of our parsing algorithms. In this section, we provide formal definitions of these concepts, and introduce the computational problem that is investigated in this article.\nLet s be a synchronous rule with r > 2 linked nonterminals, and let \u03c0s be the permutation representing s. A linear parsing strategy for s is defined as a permutation \u03c3s of the set [r]. The intended meaning of \u03c3s is that, when parsing the rule s, the pair of linked nonterminals A1,\u03c3(k), A2,\u03c0\u22121(\u03c3(k)) is collected at the k-th step, for each k \u2208 [r], as shown in Figure 1.\nLet us consider state type (s, \u03c3s, k), k \u2208 [r], defined as in Section 2.2. We define the count of\ninternal boundaries for (s, \u03c3s, k) as\nib(\u03c0s, \u03c3s, k) = \u2223 \u2223 \u2223 { h : \u03c3\u22121s (h) \u2264 k \u2227 \u03c3 \u22121 s (h+ 1) > k }\u2223 \u2223 \u2223 +\n\u2223 \u2223 \u2223 { h : \u03c3\u22121s (h) > k \u2227 \u03c3 \u22121 s (h+ 1) \u2264 k }\u2223 \u2223 \u2223 + \u2223 \u2223 \u2223 { h : \u03c3\u22121s (\u03c0 \u22121 s (h)) \u2264 k \u2227 \u03c3 \u22121 s (\u03c0 \u22121 s (h+ 1)) > i } \u2223 \u2223 \u2223 + \u2223 \u2223 \u2223 { h : \u03c3\u22121s (\u03c0 \u22121 s (h)) > k \u2227 \u03c3 \u22121 s (\u03c0 \u22121 s (h+ 1)) \u2264 k } \u2223 \u2223 \u2223 . (2)\nIn the definition above, the term \u2223 \u2223 { h : \u03c3\u22121s (j) \u2264 i \u2227 \u03c3 \u22121 s (h+ 1) > k }\u2223 \u2223 counts the number of nonterminals A1,i that have already been collected at step k and such that nonterminal A1,i+1 has not yet been collected. Informally, this term counts the nonterminals in the right-hand side of the first CFG rule component of s that represent right internal boundaries of the span of a state of type (s, \u03c3s, k). The second term in the definition counts the number of nonterminals in the right-hand side of the same rule component that represent left internal boundaries. Similarly, the remaining two terms count right and left internal boundary nonterminals, respectively, in the right-hand side of the second CFG rule component of s.\nFor state type (s, \u03c3s, k), k \u2208 [r], we also define the count of external boundaries as\neb(\u03c0s, \u03c3s, k) =I(\u03c3 \u22121 s (1) \u2264 k) + I(\u03c3 \u22121 s (n) \u2264 k)+\nI(\u03c3\u22121s (\u03c0 \u22121 s (1)) \u2264 k) + I(\u03c3 \u22121 s (\u03c0 \u22121 s (n)) \u2264 k) . (3)\nThe indicator functions I() count the number of nonterminals that are placed at the left and right ends of the right-hand sides of the two rule components and that have already been collected at step k. Informally, the sum of these functions counts the nonterminals that represent external boundaries of the span of state type (s, \u03c3s, k).\nFinally, the fan-out of state type (s, \u03c3s, k) is defined as\nfo(\u03c0s, \u03c3s, k) = 1\n2 (ib(\u03c0s, \u03c3s, k) + eb(\u03c0s, \u03c3s, k)) . (4)\nDividing the total number of boundaries by two gives the number of substrings spanned by the state type (s, \u03c3s, k). Observe that the fan-out at step k is a function of both the permutation \u03c0s associated with the SCFG rule s, and the linear parsing strategy \u03c3s.\nAs discussed in Section 2.2, the fan-out at step k gives space and time bounds on the parsing algorithm relative to that step and parsing strategy \u03c3s. Thus the complexity of the parsing algorithm relative to synchronous rule s depends on the fan-out at the most complex step of \u03c3s. We wish to find, for an input synchronous rule s with associated permutation \u03c0s, the linear parsing strategy that minimizes quantity\nmin \u03c3 max k\u2208[r] fo(\u03c0s, \u03c3, k) , (5)\nwhere \u03c3 ranges over all possible linear parsing strategies for s. Our main result in this article is that this minimization problem is NP-hard. This is shown by first proving that the optimization of the ib(\u03c0s, \u03c3s, k) component of the fan-out is NP-hard, in the next section, and then by extending the result to the whole fan-out in a successive section."}, {"heading": "3 Permutation Multigraphs and Cutwidth", "text": "With the goal of showing that the minimization problem in (5) is NP-hard, in this section we investigate the minimization problem for the ib(\u03c0s, \u03c3s, k) component of the fan-out, defined in (2). More precisely, given as input a synchronous rule s with r > 2 nonterminals and with associated permutation \u03c0s, we investigate a decision problem associated with the computation of the quantity\nmin \u03c3 max k\u2208[r] ib(\u03c0s, \u03c3, k) , (6)\nwhere \u03c3 ranges over all possible linear parsing strategies for s. We do this by introducing a multigraph representation for the synchronous rule s, and by studying the so-called cutwidth problem for such a multigraph."}, {"heading": "3.1 Permutation Multigraphs", "text": "Our strategy for proving the NP-hardness of the optimization problem in (6) will be to reduce to the problem of finding the cutwidth of a certain class of multigraphs, which represent the relevant structure of the input synchronous rule. In this section we introduce this class of multigraphs, and discuss its relation with synchronous rules. We denote undirected multigraphs as pairs G = (V, E), with set of nodes V and multiset of edges E.\nA permutation multigraph is a multigraph G = (V, A \u228e B) such that both PA = (V, A) and PB = (V, B) are Hamiltonian paths, and \u228e is the merge operation defined for multisets. In the following, the edges in A will be called red, the edges in B will be called green.\nA permutation multigraph G = (V, A \u228e B) can be thought of as encoding some permutation: if we identify nodes in V with integers in [|V|] according to their position on path A, the order of vertices along path B defines a permutation of set [|V|]. We can therefore use a permutation multigraph to encode the permutation associated with a given synchronous rule. More precisely, let s be a synchronous rule of the form\ns : [A1 \u2192 u1,0A 1 1,1u1,1 \u00b7 \u00b7 \u00b7 u1,r\u22121A r 1,ru1,r,\nA2 \u2192 u2,0A \u03c0s(1) 2,1 u2,1 \u00b7 \u00b7 \u00b7 u2,r\u22121B \u03c0s(r) 2,r u2,r] , (7)\nwhere r \u2265 2, u1,i, u2,i \u2208 V \u2217 T for each i \u2208 [r]0 and \u03c0s is a permutation of the set [r]. We associate with s the permutation multigraph Gs = (Vs, Es,A \u228e Es,B) defined as\n\u2022 Vs = {(A1,i, A2,\u03c0\u22121s (i)) : i \u2208 [r]};\n\u2022 Es,A = {((A1,i, A2,\u03c0\u22121s (i)), (A1,j, A2,\u03c0\u22121s (j))) : i, j \u2208 [r] \u2227 |i\u2212 j| = 1};\n\u2022 Es,B = {((A1,\u03c0s(i), A2,i), (A1,\u03c0s(j), A2,j)) : i, j \u2208 [r] \u2227 |i\u2212 j| = 1}.\nTo see that Gs is a permutation multigraph, observe that Gs is the superposition of the following two Hamiltonian paths\n\u2022 \u3008(A1,1, A2,\u03c0\u22121s (1)), ((A1,2, A2,\u03c0\u22121s (2)), . . . , (A1,r\u22121, A2,\u03c0\u22121s (r\u22121)), (A1,r, A2,\u03c0\u22121s (r))\u3009;\n\u2022 \u3008(A1,\u03c0s(1), A2,1), (A1,\u03c0s(2), A2,2), . . . , (A1,\u03c0s(r\u22121), A2,r\u22121), (A1,\u03c0s(r), A2,r)\u3009.\nAn example permutation multigraph is shown in Figure 2, with one Hamiltonian path shown above and one below the vertices.\nWe shall now discuss a mathematical relation between internal boundary counts for states associated with linear parsing strategies for the synchronous rule s and width values for the permutation multigraph Gs. We first recall the definition of the width and cutwidth of a graph and a multigraph. Let G = (V, E) be an undirected (multi)graph such that |V| = n > 1. A linear arrangement of G is a bijective mapping \u03bd from V to [n]. We call positions the integer values of\n\u03bd. For any i \u2208 [n\u2212 1], the width of G at i with respect to \u03bd, denoted by wd(G, \u03bd, i), is defined as |{(u, v) \u2208 E : \u03bd(u) \u2264 i < \u03bd(v)}|. In the case of a multigraph, the size of the previous set should be computed taking into account multiple occurrences. Informally, wd(G, \u03bd, i) is the number of distinct edges crossing over the gap between positions i and i+ 1 in the linear arrangement \u03bd. To simplify the notation below, we also let wd(G, \u03bd, n) = 0. The cutwidth of G is then defined as\ncw(G) = min \u03bd max i\u2208[n] wd(G, \u03bd, i) ,\nwhere \u03bd ranges over all possible linear arrangements of G. The cutwidth of the multigraph of Figure 2 is six, which is achieved between (A1,3, A2,6) and (A1,4, A2,3) in the linear arrangement shown.\nLet us now consider synchronous rule s in (7) and the associated permutation \u03c0s, and let \u03c3s be some linear parsing strategy defined for s. The linear arrangement associated with \u03c3s is the linear arrangement \u03bds for permutation multigraph Gs = (Vs, Es) defined as follows. For each i \u2208 [r], \u03bds((A1,i, A2,\u03c0\u22121s (i))) = k if and only if \u03c3s(k) = (A1,i, A2,\u03c0\u22121s (i)). The following relation motivates our investigation of the cutwidth problem for permutation multigraphs in the remaining part of this section.\nLemma 1. Let s be a synchronous rule with r > 2 linked nonterminals, and let \u03c3s be a linear parsing strategy for s. Let \u03c0s and Gs be the permutation and the permutation multigraph, respectively, associated with s, and let \u03bds be the linear arrangement for Gs associated with \u03c3s. For every i \u2208 [r] we have\nwd(Gs, \u03bds, i) = ib(\u03c0s, \u03c3s, i) .\nProof. The lemma follows from the definition of the internal boundary function in (2) and the definition of the permutation multigraph. The first two terms in (2) count edges from the set Es,A crossing the gap at position i in linear arrangement \u03bds of Gs, while the second two terms in (2) count edges from the set Es,B.\nNote that Lemma 1 directly implies the relation cw(Gs) = min\u03c3 maxi\u2208[r] ib(\u03c0s, \u03c3, k). In the rest of the present section we investigate the permutation multigraph cutwidth problem, or PMCW for short. An instance of PMCW consists of a permutationmultigraph G and an integer k, and we have to decide whether cw(G) \u2264 k. We show that the PMCW problem is NP-complete. We reduce from the minimum bisection width problem, or MBW for short. The MBW problem consists of deciding whether, given a graph G and an integer k, there is a partition of the nodes of G into two equal size subsets V1 and V2, such that the number of edges with one endpoint in V1 and one endpoint in V2 is not greater than k. It is known that the MBW problem is NP-complete even when restricted to cubic graphs, that is, 3-regular graphs, with no multi-edges and no selfloops [BCLS87]. We use this variant of the MBW problem in our reduction. Our proof that the PMCW problem is NP-complete is a modification of the proof reported in [MPS85, Theorem 4.1, p. 434], showing that the problem of deciding whether an undirected graph has (modified) cutwidth not greater than a given integer is NP-complete for graphs with maximum vertex degree of three."}, {"heading": "3.2 Construction of Permutation Multigraph G\u2032", "text": "Throughout the rest of this section, we let G = (V, E) be a cubic graph where V = {v1, . . . , vn} is the set of its vertices. Note that n > 1 must be even. We also let k be an arbitrary positive integer. We construct a permutation multigraph G\u2032 and an integer k\u2032 such that \u3008G, k\u3009 is a positive instance of MBW if and only if \u3008G\u2032, k\u2032\u3009 is a positive instance of PMCW (this statement will be shown in Sections 3.3 and 3.4).\nLet H and W be positive integers. We will make use of a grid gadget X = \u0393[H,W] with H rows and W columns; for an example, see the left part of Figure 3. More precisely, for any h \u2208 [H] and for any w \u2208 [W], the grid X includes a node xh,w. Moreover, for any h \u2208 [H] and for any w \u2208 [W \u2212 1], there is an edge ( xh,w, xh,w+1 ) , and, for any h \u2208 [H \u2212 1] and for any w \u2208 [W], there is an edge ( xh,w, xh+1,w ) . It is known that, for any H andW greater than 2, cw(X) = min{H + 1,W + 1} [RSV95].\nFor positive integers Hl, Wl , Hm, and Wm with Hl > Hm, we will also exploit a composed grid \u03a3[Hl ,Wl ,Hm,Wm], which is formed by combining two grid gadgets L = \u0393[Hl ,Wl ] and R = \u0393[Hl ,Wl ] with a grid gadget M = \u0393[Hm,Wm], as shown in the right part of Figure 3. The nodes of L, R, and M will be denoted as lh,w, rh,w, and mh,w, respectively. Besides the edges of the three grids L, R, and M, for any h \u2208 [Hm], the composed grid \u03a3[Hl ,Wl ,Hm,Wm] also includes the edges (\nlh,Wl ,mh,1 ) and ( mh,Wm , rHl\u2212Hm+h,1 ) .\nThe target graph G\u2032 consists of several grid gadgets. More specifically, it has one grid Gi = \u0393[2n4 + 1, 6n4], i \u2208 [n], for each of the n nodes of the source cubic graph G. The nodes of Gi will be denoted as gh,wi . In addition, G \u2032 has a composed grid S = \u03a3[3n4 + 1, 12n4, 2n4 + 1, 8n4 + 1]. For each grid Gi, i \u2208 [n], we add to G \u2032 a sheaf of 4n2 edges connecting distinct nodes in the first or in the last row of Gi to 4n 2 distinct nodes of the first row of M, as will be explained in detail below. In addition, for each edge (vi, vj) \u2208 E with i < j, we add to G \u2032 two edges, each edge connecting a node in the first row of Gi with a node in the last row of Gj. The choice of all of the above connections will be done in a way that guarantees that G\u2032 is a permutation multigraph.\nBefore providing a mathematical specification of G\u2032, we informally summarize the organiza-\ntion of the edges of G\u2032 connecting the M and Gi grids. When scanning the columns of M from left to right, we will have a first column that has no connection to any of the Gi components, followed by a first block of 4n2 columns with connections to the G1 component, followed by a second block of 4n2 columns with connections to G2, and so on up to the n-th block of 4n 2 columns with connections to Gn. The remaining columns of M do not have any connection with the Gi components.\nLooking at one of the grids Gi, the columns are organized into three blocks, when scanning\nfrom left to right.\n\u2022 Block 1 (left portion of Gi in Figure 4): The first column has two edges connecting to the\nM component, one from its top vertex and one from its bottom vertex, and the remaining columns in the block each have a single edge connecting to M from the column\u2019s bottom vertex. This block extends from column with index 1 to column 4n2 \u2212 4\u2212 2d>i , where d > i denotes the number of edges of G of the form (vi, vj) with j > i, that is, the number of \u201cforward\u201d neighbors of i. The block therefore contains a total of 4n2 \u2212 3\u2212 2d>i edges connecting Gi to M.\n\u2022 Block 2 (Figure 5): This block represents the edges from the source graph G. For each edge\n(vi, vj) of G such that i < j, we have two columns each having a single edge connecting to M from the column\u2019s bottom vertex, and a single edge connecting to the grid Gj from the column\u2019s top vertex. This is followed by two columns for each edge (vi, vj) in G such that j < i, with each column having its bottom vertex connected to the grid Gj and no connection to M. Block 2 extends from column 4n2\u2212 3\u2212 2d>i to column 4n 2\u2212 4+ 2d<i , where d < i denotes the number of edges of G of the form (vi, vj) with j < i, that is, the number of \u201cbackward\u201d\nneighbors of i. The number of edges connecting Gi to M is 2d > i , and the number of edges connecting Gi to grids Gj with j 6= i is 2d > i + 2d < i = 6, where the equality follows from the fact that G is a cubic graph.\n\u2022 Block 3 (right portion of Gi in Figure 4): The first column has the top vertex connected to\nM. All remaining columns of Gi do not have connections with M, with the exception of the rightmost column, which has two edges connecting its top and bottom vertices to M. This block extends from column with index 4n2 \u2212 3 + 2d<i to column with index 6n 4, and the block contains 3 edges connecting Gi to M.\nAltogether, the above blocks provide a total number of edges connecting Gi and M equal to (4n 2\u2212 3\u2212 2d>i ) + 2d > i + 3 = 4n 2, as anticipated.\nTo define the edges in each of these three blocks, we need to introduce some auxiliary notation. In what follows, for every i \u2208 [n], we denote by N<i the set of \u201cbackward\u201d neighbors of vi, that is, N<i = {j : (vi, vj) \u2208 E \u2227 j \u2208 [i \u2212 1]}. Similarly, the set of \u201cforward\u201d neighbors of vi is the set N>i = {j : (vi, vj) \u2208 E \u2227 j \u2208 [n] \\ [i]}. We then have d < i = |N < i | and d > i = |N > i |. As already observed, we must have d>i + d < i = 3 since G is a cubic graph. For every i \u2208 [n] and j \u2208 [i] we also define d <,j i = |N < i \u2229 [j\u2212 1]|; in words, d <,j i is the number of backward neighbors of vi having index strictly smaller than j. Note that d<,ii = d < i for every i \u2208 [n].\nFor every i \u2208 [n] and h \u2208 [d>i ], we denote by n h i the index of the h-th forward neighbor of vi\nfrom left-to-right: formally, nhi is the value j such that j \u2208 N > i and |[j\u2212 1] \u2229 N > i | = h\u2212 1. Finally, for every i \u2208 [n+ 1], we define \u03c3i = 4n 2(i\u2212 1) + 1. This quantity will be used in the construction of G\u2032 below as an offset when locating the index of the next available column, from left to right, in the M component. For instance, we have \u03c3i = 1 since in M the first block with 4n 2 connections to G1 starts at column 2, as already anticipated.\nWe are now ready to specify precisely each of the three blocks of edges connecting each Gi to\nthe other grids.\nBlock 1 For any h \u2208 [ 2n2 \u2212 2\u2212 d>i ] , G\u2032 includes the edges (see Figure 4)\n(\nm1,\u03b1i,h , g2n 4+1,2h\u22121\ni\n) , ( g2n 4+1,2h\ni ,m 1,\u03b1i,h+1\n)\n,\nwhere \u03b1i,h = \u03c3i + (2h\u2212 1). In addition to the above edges, there is one edge connecting node g 1,1 i with M that is associated with Block 1. However, in order to simplify the presentation, it is more convenient to list such edge under Block 3 below.\nBlock 2 We now add to G\u2032 the edges that are derived from the original graph G. For every i \u2208 [n] and for every h \u2208 [\nd>i ] , that is, for any forward edge (vi, vnhi ) in G, G\u2032 includes the four edges (see\nFigure 5)\n(\nm1,\u03b2i,h , g 2n4+1,\u03b3i,h i\n)\n,\n(\ng 1,\u03b3i,h i , g 2n4+1,\u03b3\u2032i,h nhi\n)\n,\n(\ng 2n4+1,\u03b3\u2032i,h+1\nnhi , g\n1,\u03b3i,h+1 i\n)\n, ( g 2n4+1,\u03b3i,h+1 i ,m 1,\u03b2i,h+1 ) ,\nwhere \u03b2i,h = \u03c3i + 4n 2 \u2212 4\u2212 2d>i + (2h\u2212 1), \u03b3i,h = 4n 2 \u2212 4\u2212 2d>i + (2h\u2212 1), and \u03b3 \u2032 i,h = 4n 2 \u2212 3+ 2d<,i nhi . Observe that \u03b2i,1 = \u03b1i,2n2\u22122\u2212d>i + 1, so that the two runs of edges defined by Block 1 and Block 2, connecting grid Gi to grid M, are one next to the other. We have thus added to G \u2032, for any edge (vi, vj) of G, two edges connecting the two grids Gi and Gj, and two edges connecting grid Gi to grid M.\nCombining Block 1 and Block 2 together, we have added a total of 4n2 \u2212 4 edges from grid Gi to grid M, for every i \u2208 [n].\nBlock 3 Finally, G\u2032 includes the four edges (see Figure 4)\n( m1,\u03c3i+1\u22123, g 1,4n2\u22123+2d<i i ) , ( g1,6n 4 i ,m 1,\u03c3i+1\u22122 ) , ( m1,\u03c3i+1\u22121, g1,1i ) , ( g2n 4+1,6n4 i ,m 1,\u03c3i+1 ) .\nCombining all three blocks, we have a total of 4n2 edges connecting Gi to M. We further note that each vertex of Gi has at most one edge connecting to vertices outside Gi; this property will play an important role later in our proofs.\nSo far we have specified G\u2032 as if it were a (plain) graph; however, G\u2032 is a permutation multigraph. The coloring of the edges of G\u2032, that is, the definition of the two edge sets A and B, is specified below by describing the Hamiltonian path of red edges and the Hamiltonian path of green edges. Some of the edges specified above are included in both the red and green paths; these are double edges in the multigraph G\u2032.\nRed path The red path is schematically represented in Figure 6. The path starts from l3n 4+1,1 (that is, the bottom left corner of L) and travels horizontally through the n4 bottom lines of L, alternating the left-to-right and the right-to-left directions and moving upward, until it reaches\nnode l2n 4+1,1 coming from previous node l2n 4+2,1. Then the path continues traveling horizontally through the three components L, M and R, once again alternating the horizontal directions. The path eventually reaches the node m1,1 coming from previous node l1,12n 4 , since 2n4 + 1 is always odd. At this point, the red path continues horizontally, from left to right, until it arrives at some node m1,\u03c3i+1\u22121, i \u2208 [n]; let us call xi such a node. Observe that xi is the penultimate node in the first row of M, from left to right, that is connected with a node in the leftmost column of Gi (see Figure 4).\nNext, the path moves one step forward from xi to the leftmost column of Gi, reaching node g1,1i . Now, the path starts traveling horizontally from the first to the last row of Gi, alternating the left-to-right direction with the right-to-left direction, until it arrives at g2n 4+1,6n4\ni . Afterward, the\nred path returns to M by reaching the node to the right of xi. The path then continues horizontally from left to right, repeating the process of visiting the components Gi for i \u2208 [n], as described above, eventually reaching node rn 4+1,1 from previous node m1,8n 4+1. The path can now visit the remaining nodes of R by traveling horizontally and alternating the left-to-right and the right-toleft directions, until it reaches node r1,12n 4 , where the path stops.\nGreen path The green path is schematically represented in Figure 7. The path starts from l1,1 (that is, the top left corner of L). It travels vertically, alternating the top-to-bottom direction with the bottom-to-top direction andmoving rightward, until it reaches node l1,12n 4 from previous node l2,12n 4 . The path thenmoves tom1,1, travels vertically down tom2n 4+1,1, moves one step to the right\nto node m2n 4+1,2 and again travels vertically up to m1,2. From now on, as soon as there is an edge exiting M and reaching some yet unvisited node in the last row of some grid Gi, the green path follows such an edge and travels vertically through the current column in Gi, until it reaches a node xi in the first row. We need to distinguish two cases for xi.\n\u2022 If xi has no edge exiting Gi, then the green path makes a step to the vertex to the right of xi.\nThis means that we are in Block 1 of Gi.\n\u2022 On the other hand, if xi has an edge exiting Gi, then the green path follows this edge thus\nreaching a node in the last row of a grid Gj, for some j > i (as in Figure 4). This means that we are visiting the first part of Block 2 of Gi, where edges (vi, vj) in the source graph G with j > i are encoded by our construction. The path then travels vertically through two columns in Gj, until it reaches the node in the bottom row of the second column, and, from there, it returns to Gi at the vertex to the right of xi.\nFrom the vertex to the right of xi, the green path continues vertically down in the current column of Gi. Upon reaching the bottom vertex of this column, the path exits Gi and comes back to some node in the top row of M. Such node is placed in the column of M adjacent at the right to the last column of M that the green path had visited before its exit to Gi. Then the green path\nproceeds downward, along the current column of M, it moves to the next column at the right, and alternates its direction to reach the node in the first row of M. The above process is then iterated, until all the columns in Block 1 and Block 2 of the current grid Gi have been visited.\nWhen the green path reaches node m1,\u03c3i+1\u22123, it exits M and reaches the top node in the column of Gi with index 4n 2 \u2212 3 + 2d<i (see Figure 4), entering for the first time Block 3 of the current grid Gi. We remark that this step represents a switch in the construction of the green path, in the following sense. Block 1 and Block 2 of Gi are visited by the green path in such a way that oddindexed columns are visited bottom-to-top and even-indexed columns are visited top-to-bottom. On the other hand, when Block 3 of Gi is entered, we revert the previous pattern in such a way that odd-indexed columns are visited top-to-bottom and even-indexed columns are visited bottom-totop.\nOnce Block 3 of Gi is entered, the green path travels vertically through its columns, by alternating direction and moving rightward, never leaving Gi at its intermediate nodes. In this way the path eventually reaches the node g1,6n 4\ni , at which point it can return to M, reaching the topmost\nnode in the column with index \u03c3i+1 \u2212 2 (see again Figure 4).\nAt this point the columns with indices \u03c3i+1 \u2212 2, \u03c3i+1 \u2212 1, and \u03c3i+1 are visited vertically, alternating the top-to-bottom direction with the bottom-to-top direction and moving rightward. After this step, the green path is located at the bottom of column \u03c3i+1 + 1, coming from the bottom of column \u03c3i+1, and it moves upward to the first line of M, where the path is ready to start visiting the next grid Gi+1. This is done by iterating all of the process described above.\nWhen all of the grids Gi have been visited, there are no more edges exiting M. The path then continues vertically, alternating the top-to-bottom direction with the bottom-to-top direction and moving rightward, until it reaches node m2n 4+1,8n4+1, since 8n4 + 1\u2212 \u03c3n+1 = 8n 4 + 1\u2212 4n2 \u00b7 n is always even. The path can nowmove one step to the right to node r3n 4+1,1, and visit the remaining nodes of R by traveling vertically and alternating the vertical direction. In the end, the green path ends at node r3n 4+1,12n4 .\nDouble Edges Some edges are included in both the red path and the green path. These are double edges in G\u2032, and count double when computing the width function. Double edges occur on the first and the last columns of the various component grids Gi, L, M, and R, where the red path crosses from one row to the next, and on the upper and lower rows of these grids, where the green path crosses from one column to the next. There are no duplicate edges in the interior of any grid. There are also no duplicate edges between any two grids, with the only exceptions of the points where the green path connects L to M, and the point where the green path connects M to R.\nTo be used later, we need to establish exact values for the cutwidth of the multigraph grids Gi, L, M, and R. In order to do so, we define a multigraph grid Xm, which consists of the (regular) grid X = \u0393[H,W] with the following double edges\n\u2022 from x1,i to x1,i+1, for any i odd in [W \u2212 1]\n\u2022 from xH,i to xH,i+1, for any i even in [W \u2212 1]\n\u2022 from xi,1 to xi+1,1, for any i odd in [H \u2212 1]\n\u2022 from xi,W to xi+1,W , for any i even in [H \u2212 1].\nThe set of edges of the grid X is contained in the set of edges of the multigraph grid Xm. Hence the cutwidth of Xm is at least min{H + 1,W + 1}, which is the cutwidth of X as reported at the beginning of Section 3.2. Without loss of generality, let us assume H \u2264 W, and let us consider the linear arrangement \u03bd of Xm such that, for any x i,j, \u03bd(xi,j) = (j \u2212 1)H + i if j is even, and (j\u2212 1)H + H \u2212 i otherwise. It is easy to verify that \u03bd induces a maximum width equal to H + 1. This proves that the cutwidth of the multigraph grid Xm is still min{H + 1,W + 1}.\nObserve that the multigraph grid R which we use in G\u2032 has a set of edges which is a proper subset of the set of edges of Xm, for appropriate values of H and W. The subset relation follows from the fact that R does not have double edges at the portion of its leftmost column that connects with M. Similarly, the multigraph grid L has a set of edges which is a proper subset of the set of edges of an upside-down instance of Xm. Thus both L and R have cutwidth min{H + 1,W + 1}. Consider now grid M. The set of its edges is a proper subset of the edges of an upside-down instance of Xm. This follows from the fact that M does not have double edges at its leftmost and rightmost columns, where it connects with L and R, respectively. Furthermore, the green path through M sometimes leaves the first row of M to connect to some grid Gi, as depicted in Figure 7. Thus we can claim a cutwidth of min{H + 1,W + 1} for this grid as well. It is easy to verify that each of the green paths through grids L, M and R corresponds to a linear arrangement that realizes the maximum width of min{H + 1,W + 1} for these grids.\nFinally, each grid Gi can be split into two parts. The first part consists of what we have called blocks 1 and 2, and the second part consists of block 3. The first part is a grid with a proper subset of the edges of an upside-down instance of Xm, for appropriate values of H and W. This is so because the green path at block 2 repeatedly leaves Gi to connect to three other grids Gj, j 6= i, irrespective of whether these connections are backward or forward in the source graph G. The second part of Gi is an instance of Xm, for appropriate values of H and W. The difference between these two parts is due to the fact that, when moving from block 2 to block 3, the green path switches to a \u201creversed\u201d pattern, as already observed in this section. An optimal linear arrangement for Gi can be defined by following the green path within each column of this grid, and moving from one column to the next in a left to right order. The maximum width in the first part of Gi, with the exception of the last column, is then min{H + 1,W + 1}, and this is also the maximum width in the second part, with the exception of the first column. It is not difficult to verify that, even for the positions corresponding to the two adjacent columns above, this arrangement induces a maximum width of min{H + 1,W + 1}. We have thus found that all of the grid components in G\u2032 have cutwidth of min{H + 1,W + 1}.\nWe conclude our construction by setting k\u2032 = 3n4 + 2n3 + 2k+ 2 in the target instance \u3008G\u2032, k\u2032\u3009\nof the PMCW problem.\n3.3 MBW to PMCW\nWe show here that if G admits a partition of its nodes into two equal size subsets, inducing a cut of size at most k, then G\u2032 admits a linear arrangement \u03bd\u2032 whose maximum width is at most k\u2032.\nLemma 2. If \u3008G, k\u3009 is a positive instance of MBW then \u3008G\u2032, k\u2032\u3009 is a positive instance of PMCW.\nProof. We specify a linear arrangement of G\u2032 having width no greater than k\u2032 at each position. We arrange the vertices within each grid component Gi, as well as within grid components R, M, and L, to be contiguous to one another. Within each grid component, we arrange the vertices in column-major order proceeding through the columns from left to right; within each column, we place vertices in the order specified by the green path of G\u2032. This is the same linear arrangement for each multigraph grid that has been presented in the paragraph \u201cDouble Edges\u201d, at the end of Section 3.2. Disregarding edges that are not internal to the grid itself, this results in a maximal width of H + 1 for each individual grid, as already discussed.\nWe concatenate the linear arrangements for the grid components in a manner corresponding to a solution of the MBW problem given by \u3008G, k\u3009. To this end, let V1 and V2 be the sets in a partition of the vertices in G such that |V1| = |V2| and at most k edges in G have one endpoint in V1 and the other endpoint in V2.\nOur linear arrangement begins with the grid components Gi for all i such that vi \u2208 V1, in any order, then concatenates components L, M, and R, and finally adds Gi for all i such that vi \u2208 V2, in any order. Each position in the linear arrangement within component L has at most 3n4 + 2 edges internal to L, since the height of L\u2019s grid is 3n4 + 1. In addition, each position within L has 4n2 edges connecting M to each of the n2 components Gi to the left of L, for a total of 2n 3 edges. Finally, each position within L has at most 2k edges connecting components Gi and Gj for i, j such that vi \u2208 V1, vj \u2208 V2 and (vi, vj) \u2208 E. Thus, the total width at each position within L is at most 3n4 + 2+ 2n3 + 2k = k\u2032. The same analysis applies to each position within R.\nAt all other positions in the linear arrangement, we have smaller width. This is because, for\npositions within each Gi, we have at most 2n 4 + 2 edges from the grid Gi itself, at most 2n 3 edges from M to any Gj standing on the same side as Gi with respect to M, and no more than 3n edges from some Gj to some Gh, since the source graph G is cubic and each connection between two vertices in G corresponds to two arcs connecting the associated grids in G\u2032. For positions within M, we have at most 2n4 + 2 edges internal to M, at most 4n3 edges from M to some Gi, and 2k < 3n edges from some Gi to some Gj. Finally, positions between grid components have at most 2n3 edges from M to some Gi, at most 3n edges from some Gi to some Gj, and, in the case of positions between M and either L or R, 2n4 + 1 edges connecting M to either L or R. Thus, all positions outside grids L and R have a width bound of 2n4 +O(n3).\nWe conclude that the maximum width of the linear arrangement is that of the L and R compo-\nnents, 3n4 + 2+ 2n3 + 2k = k\u2032. Then \u3008G\u2032, k\u2032\u3009 is a positive instance of PMCW.\n3.4 PMCW to MBW\nIn this sectionwe shall prove that if G\u2032 admits a linear arrangement \u03bd\u2032 whosemaximumwidth is at most k\u2032, then our source graph G admits a partition into two equal size subsets of nodes inducing\na cut of size at most k. To this aim, we need to develop several intermediate results. Informally, our strategy is to investigate the family of linear arrangements for G\u2032 having maximum width bounded by k\u2032 + n2. We show that, in these arrangements, two important properties hold for the grid components L,M, R and Gi, i \u2208 [n], of G \u2032, described in what follows.\n\u2022 The first property states that, for each grid component, a subset of its nodes must appear\nall in a row in the linear arrangement. We call such a subset the kernel of the grid. In other words, nodes from different kernels cannot be intermixed, and each linear arrangement induces a total order among the kernels. In addition, the kernels of the grids L,M, R must appear one after the other in the total order, and the kernels of the grids Gi can only be placed to the left or to the right of the kernels of L,M, R. We therefore call L,M, R the middle grids.\n\u2022 We illustrate the second property bymeans of an example. Consider one of themiddle grids,\nsay L. Assume that, under our liner arrangement, there is a grid X with kernel to the left of L\u2019s kernel and a grid Y with kernel to the right of L\u2019s kernel. Assume also some edge e of G\u2032, connecting a node x from X with a node y from Y. If x and y are in the kernels of their respective grids, edge e must cross over L\u2019s kernel, contributing one unit to the width of G\u2032 at each gap i within L\u2019s kernel. If x and y are not in the kernels of their respective grids, it is possible to \u201cmisplace\u201d one of these two nodes, say x, moving it to the opposite side with respect to L\u2019s kernel, in such a way that e no longer contributes to the width at i. The second property states that, if we do this, we will bring new edges, internal to grid X, into the count of width at i. This means that, if our goal is the one of optimizing the width at i, we will have no gain in misplacing node x or node y.\nWith the two properties above, we can then show that exactly n2 of the Gi grids must be placed to the left of the middle grids L,M, R, and all of the remaining Gi grids must be placed to the right of the middle grids, which eventually leads to the fact that if \u3008G\u2032, k\u2032\u3009 is a positive instance of PMCW then \u3008G, k\u3009 is a positive instance of MBW.\nWe start with some preliminary results, needed to prove the first property above. Let V1 and V2 be sets of nodes from some graph with V1 \u2229 V2 = \u2205, and let E be the set of edges of the graph. We write \u03b4 (V1,V2) = |{(u, v) : (u, v) \u2208 E \u2227 u \u2208 V1 \u2227 v \u2208 V2}|.\nLemma 3. For any grid X = \u0393[H,W] with W \u2265 2H + 1 and for any partition of its nodes in two sets V1 and V2 with |V1| \u2265 H 2 and |V2| \u2265 H2, we have \u03b4 (V1,V2) \u2265 H.\nProof. We distinguish the following three cases.\n(i) For each h with 1 \u2264 h \u2264 H there exist wh,1 and wh,2 with 1 \u2264 wh,1,wh,2 \u2264 W such that\nxh,wh,1 \u2208 V1 and x h,wh,2 \u2208 V2. This implies that, for each row of the grid, there exists at least one edge connecting one node in V1 to one node in V2. Hence, \u03b4 (V1,V2) \u2265 H.\n(ii) There exists h with 1 \u2264 h \u2264 H such that, for any w with 1 \u2264 w \u2264 W, xh,w \u2208 V1. In this case,\nfor each w with 1 \u2264 w \u2264 W, either there exists hw with 1 \u2264 hw \u2264 H such that xhw ,w \u2208 V2 (and, hence, the w-th column of X contributes to \u03b4 (V1,V2) by at least one unit) or else, for all\nh with 1 \u2264 h \u2264 H, xh,w \u2208 V1. This latter case can happen at most \u230a |V1 | H \u230b times: this implies that the former case happens at leastW \u2212 \u230a\n|V1| H\n\u230b\n. Hence,\n\u03b4 (V1,V2) \u2265 W \u2212\n\u230a\n|V1|\nH\n\u230b\n\u2265 WH \u2212 |V1|\nH =\n|V2|\nH \u2265 H,\nwhere the last inequality is due to the fact that |V2| \u2265 H2.\n(iii) There exists h with 1 \u2264 h \u2264 H such that, for any w with 1 \u2264 w \u2264 W, xh,w \u2208 V2. We can deal\nwith this case similarly to the previous one.\nThe lemma thus follows.\nCorollary 1. For any grid X = \u0393[H,W] with W \u2265 2H + 1, for any linear arrangement \u03bd of X, and for any i with H2 \u2264 i \u2264 HW \u2212 H2, wd(X, \u03bd, i) \u2265 H.\nProof. The result follows by observing that, for any i with H2 \u2264 i \u2264 HW \u2212 H2, we can define a partition of the nodes of the grid by including in V1 all the nodes x such that \u03bd(x) \u2264 i and by including in V2 all the other nodes. Since this partition satisfies the hypothesis of the previous lemma, we have that wd(X, \u03bd, i) \u2265 H.\nLet \u03bd be an arbitrary linear arrangement for the nodes of G\u2032. We denote by \u03bdi (respectively, \u03bdL, \u03bdM, and \u03bdR) the linear arrangement of Gi (respectively, L, M, and R) induced by \u03bd. Moreover, for any node x of Gi (respectively, L, M, and R) and the associated position p = \u03bd(x) under \u03bd, we denote by pi = \u03bdi(x) (respectively, pL = \u03bdL(x), pM = \u03bdM(x), and pR = \u03bdR(x)) the corresponding position of x under \u03bdi (respectively, \u03bdL, \u03bdM, and \u03bdR).\nWe now introduce the notion of kernel, which plays a major role in the development of our proofs below. Consider any linear arrangement \u03bd of G\u2032 and any of the grids Gi. The kernel K (\u03bd) i relative to \u03bd and Gi is a set of positions p of the nodes of G \u2032 under \u03bd such that ( 2n4 + 1 )2\n\u2264 pi \u2264 (\n6n4 ) ( 2n4 + 1 ) \u2212 ( 2n4 + 1 )2 . Corollary 1 implies that for any p \u2208 K (\u03bd) i , wd(Gi, \u03bdi, pi) \u2265 2n 4 + 1.\nSimilarly, we define the kernel K (\u03bd) L (respectively, K (\u03bd) R ) as the set of positions p of the nodes of\nG\u2032 under \u03bd such that ( 3n4 + 1 )2 \u2264 pL, pR \u2264 ( 12n4 ) ( 3n4 + 1 ) \u2212 ( 3n4 + 1 )2 . Again, Corollary 1 implies that for any p \u2208 K (\u03bd) L (respectively, p \u2208 K (\u03bd) R ), we have wd(L, \u03bdL, pL) \u2265 3n 4 + 1 (respectively, wd(R, \u03bdR, pR) \u2265 3n 4 + 1). We define the kernel K (\u03bd) M as the set of positions p of the nodes of G \u2032 under \u03bd such that ( 2n4 + 1 )2 \u2264 pM \u2264 ( 2n4 + 1 ) ( 8n4 + 1 ) \u2212 ( 2n4 + 1 )2 . Corollary 1 implies that for any p \u2208 K (\u03bd) M we have wd(M, \u03bdM, pM) \u2265 2n 4 + 1.\nObserve that, for any i \u2208 [n], we have |K (\u03bd) i | = (2n 4 + 1)(6n4) \u2212 2((2n4 + 1)2) + 1 \u2265 3n8\nfor n sufficiently large. Furthermore, for n sufficiently large, we have |K (\u03bd) L | = |K (\u03bd) R | = (3n 4 + 1)(12n4)\u2212 2((3n4 + 1)2) + 1 \u2265 17n8, and |K (\u03bd) M | = (2n 4 + 1)(8n4 + 1)\u2212 2((2n4 + 1)2 + 8n4 + 1) + 1 \u2265 7n8.\nRecall that in our construction in Section 3.2 we have set k\u2032 = 3n4 + 2n3 + 2k+ 2. From now on, we denote by \u03bd\u2032 any linear arrangement of G\u2032 having maximum width at most k\u2032 + n2. For any\ntwo sets of positive integers A and B, we will write A < B if each element of A is smaller than every element in B.\nLemma 4. Let \u03bd\u2032 be a linear arrangement of G\u2032 having maximum width at most k\u2032 + n2, and let K(\u03bd \u2032) = {K (\u03bd\u2032) L ,K (\u03bd\u2032) M ,K (\u03bd\u2032) R } \u222a {K (\u03bd\u2032) i : i \u2208 [n]}. For any pair of kernels K \u2032,K\u2032\u2032 \u2208 K(\u03bd \u2032) with K\u2032 6= K\u2032\u2032, either K\u2032 < K\u2032\u2032 or K\u2032\u2032 < K\u2032.\nProof. We first consider the kernels in {K (\u03bd\u2032) i : i \u2208 [n]}. Let p, p \u2032 \u2208 K (\u03bd\u2032) i be two positions such that pi = p \u2032 i \u2212 1. Assume that there exists a position q \u2208 K (\u03bd\u2032) j , j 6= i, such that p < q < p \u2032. We know (by Corollary 1 and definition of kernel) thatwd(Gi, \u03bd \u2032 i , pi) \u2265 2n 4 + 1 andwd(Gj, \u03bd \u2032 j , qj) \u2265 2n 4 + 1. Since Gi and Gj have disjoint edge sets, and since in between p and q there is no position associated with a node from Gi, we conclude that wd(G \u2032, \u03bd\u2032, q) \u2265 4n4 + 2 > k\u2032 + n2, for n sufficiently large. This is in contrast with our assumption about the linear arrangement \u03bd\u2032.\nEssentially the same argument can be used when we consider all of the kernels in K(\u03bd \u2032).\nIntuitively, the above lemma states that in any linear arrangement \u03bd\u2032 of G\u2032 with maximum width at most k\u2032 + n2, the kernels of the grid components of G\u2032 cannot overlap one with the other. As a consequence, \u03bd\u2032 induces an ordering of the nodes of the source graph G which is determined by the positions of the corresponding kernels.\nLemma 5. Let \u03bd\u2032 be a linear arrangement of G\u2032 having maximum width at most k\u2032 + n2. Then either K (\u03bd\u2032) L < K (\u03bd\u2032) M < K (\u03bd\u2032) R or K (\u03bd\u2032) R < K (\u03bd\u2032) M < K (\u03bd\u2032) L .\nProof. Assuming K (\u03bd\u2032) L < K (\u03bd\u2032) R , we show below that, under \u03bd \u2032, kernel K (\u03bd\u2032) R cannot be placed in between kernels K (\u03bd\u2032) L and K (\u03bd\u2032) M . Essentially the same argument can be used to show that kernel K (\u03bd\u2032) L cannot be placed in between kernels K (\u03bd\u2032) M and K (\u03bd\u2032) R .\nAssume that we have K (\u03bd\u2032) L < K (\u03bd\u2032) R < K (\u03bd\u2032) M . Since the number of nodes of L which lie to the\nleft of K (\u03bd\u2032) R is at least equal to 17n 8, and since at most n4(12n4) nodes of L can belong to its last n4 rows, we have that at least 5n8 nodes of the first 2n4 + 1 rows of L lie to the left of K (\u03bd\u2032) R . On the other hand, since at least 7n8 nodes of M belong to K (\u03bd\u2032) M , we have that at least 7n 8 nodes of M lie to the right of K (\u03bd\u2032) R .\nLet us now consider the grid X = \u0393[2n4 + 1, 12n4 + 8n4 + 1] composed by the (2n4 + 1) upper rows of L and all of the rows of M. We apply Lemma 3 to X. If we define V1 (respectively, V2) as the set of nodes of X contained in K (\u03bd\u2032) L (respectively, K (\u03bd\u2032) M ), we have that both |V1| and |V2| are greater than (2n4 + 1)2. Then we have that at least 2n4 + 1 edges internal to X cross over all positions (gaps) of K (\u03bd\u2032) R . From the definition of kernels, there are at least 3n 4 + 1 edges internal to K (\u03bd\u2032) R crossing over each position of K (\u03bd\u2032) R . Adding these together, we have at least 5n 4 + 2 edges at each position of K (\u03bd\u2032) R , which is greater than k \u2032 + n2 (for n sufficiently large).\nThe case of K (\u03bd\u2032) R < K (\u03bd\u2032) L can be dealt with in a very similar way and the lemma thus follows.\nIn the following, without loss of generality, we will always assume that K (\u03bd\u2032) L < K (\u03bd\u2032) M < K (\u03bd\u2032) R . By applying essentially the same argument from the proof of Lemma 5, we can show that K (\u03bd\u2032) i cannot lie between K (\u03bd\u2032) L and K (\u03bd\u2032) M or between K (\u03bd\u2032) M and K (\u03bd\u2032) R , which implies the following result.\nLemma 6. Let \u03bd\u2032 be a linear arrangement of G\u2032 having maximum width at most k\u2032 + n2. For any i \u2208 [n], either K (\u03bd\u2032) i < K (\u03bd\u2032) L or K (\u03bd\u2032) i > K (\u03bd\u2032) R .\nSo far we have seen that kernels always appear in some total order in the linear arrangements we are interested in, and with the kernels of grids L,M and R all in a row. We move on now with a second property of the family of linear arrangements we are looking at. As already described above, this property states that, if our goal is the one of optimizing the width at certain gaps, then misplacing nodes that are not in a kernel does not result in any gain. We first provide two results about general grids, and then come back to G\u2032 and our linear arrangements.\nLemma 7. Let X = \u0393[H,W] and let S be a set of nodes of X such that |S| \u2264 W(H \u2212 e\u2212 2) with e \u2265 0 and there exists w with 1 \u2264 w \u2264 W such that, for any h with 1 \u2264 h \u2264 H, xh,w \u2208 S (in other words S contains an entire column of the grid). Then, \u03b4(S, S) contains at least e+ 2 edges in distinct rows, where S denotes the set of nodes of the grid which do not belong to S.\nProof. For each h with 1 \u2264 h \u2264 H, either there exists w with 1 \u2264 w < W such that (xh,w \u2208 S\u2227 xh,w+1 \u2208 S)\u2228 (xh,w \u2208 S\u2227 xh,w+1 \u2208 S) (in this case, the row contributes at least by one horizontal edge to \u03b4(S, S)), or, for any w with 1 \u2264 w \u2264 W, xh,w \u2208 S. This latter case, however, can happen at most \u230a\n|S| W\n\u230b\ntimes. Since |S| \u2264 W(H \u2212 e\u2212 2), we have that the first case happens at least e+ 2\ntimes, thus proving the lemma.\nLemma 8. Let X = \u0393[H,W] and let S be a set of nodes of X such that |S| \u2264 W(H \u2212 |F| \u2212 2), where F is a subset of the set of nodes of the first row or of the last row which belong to S. Then, \u03b4(S, S) contains at least |F| edges not included in the first row or in the last row.\nProof. For each w with 1 \u2264 w \u2264 W such that x1,w \u2208 F \u2228 xH,w \u2208 F, either there exists h with 1 \u2264 h < H such that (xh,w \u2208 S \u2227 xh+1,w \u2208 S) \u2228 (xh,w \u2208 S \u2227 xh+1,w \u2208 S) (in this case, the column contributes at least by one vertical edge to \u03b4(S, S)), or, for any h with 1 \u2264 h \u2264 H, xh,w \u2208 S (that is, S includes the entire w-th column). If this latter case happens at least once, then we can apply the previous lemma with e = |F|, thus obtaining that \u03b4(S, S) contains at least |F|+ 2 horizontal edges on distinct rows, which implies that \u03b4(S, S) contains at least |F| edges not included in the first row or in the last row. Otherwise, \u03b4(S, S) contains at least |F| vertical edges: indeed, if x1,w \u2208 S and xH,w 6\u2208 S or vice versa, then at least one vertical edge of the w-th column is in \u03b4(S, S), otherwise at least two vertical edges of this column are in \u03b4(S, S) (since, in this case, we have both to exit from S and to enter again in S).\nWe need to introduce some additional notation. From now on, we denote by l\u2217 the first gap\nfrom left to right occurring between two vertices of K (\u03bd\u2032) L , and we denote by r \u2217 the first gap from left to right occurring between two vertices of K (\u03bd\u2032) R . For any i \u2208 [n], we define the value \u03b1i as follows. If K (\u03bd\u2032) i > K (\u03bd\u2032) L , \u03b1i is the number of nodes of the first or of the last row of Gi whose\nposition under \u03bd\u2032 is smaller than l\u2217 and which are endpoints of an edge exiting Gi. Otherwise, \u03b1i is the number of nodes of the first or of the last row of Gi whose position is greater than l \u2217 and which are endpoints of an edge exiting Gi. Similarly, we denote by \u03b1M the number of nodes of the first row of M whose position is smaller than l\u2217 and which are endpoints of an edge exiting M.\nLemma 9. For any linear arrangement \u03bd\u2032 of G\u2032 having maximumwidth at most k\u2032+ n2 and for any i \u2208 [n], there exist at least \u03b1i distinct edges within Gi which cross over l \u2217.\nProof. First observe that \u03b1i \u2264 4n 2 + 6 because there are 4n2 edges connecting Gi to M and 6 edges connecting Gi to other grids Gj. We only study the case in which K (\u03bd\u2032) i > K (\u03bd\u2032) L , since the other case can be proved in the same way.\nLet Vi be the vertex set of Gi. Let P(Gi) = {p : (\u03bd \u2032)\u22121(p) \u2208 Vi} and let Si = {p : (\u03bd \u2032)\u22121(p) \u2208\nVi \u2227 p < l \u2217} (clearly, |Si| \u2265 \u03b1i). Since |P(Gi)| = 12n 8 + 6n4 \u2264 13n8 and |K (\u03bd\u2032) i | \u2265 3n 8, and since Si is a subset of P(Gi)\u2212 K (\u03bd\u2032) i , we are guaranteed that |Si| \u2264 10n 8. Because 10n8 \u2264 (6n4)(2n4 + 1\u2212 \u03b1i \u2212 2) (assuming n \u2265 4) we have the precondition |Si| \u2264 (6n 4)(2n4 + 1\u2212 \u03b1i \u2212 2) that we need in order to apply Lemma 8. Lemma 8 implies that there exist at least |\u03b1i| distinct edges connecting Si to Si (that is, edges within Gi): these edges clearly cross over l \u2217.\nSimilarly, we can prove the following result.\nLemma 10. For any linear arrangement \u03bd\u2032 of G\u2032 having maximum width at most k\u2032 + n2, there exist at least \u03b1M distinct edges within M which cross over l \u2217.\nFrom now on, let \u03ba (\u03bd\u2032) l be the number of kernels K (\u03bd\u2032) i such that K (\u03bd\u2032) i < K (\u03bd\u2032) L and let \u03ba (\u03bd\u2032) r be the\nnumber of kernels K (\u03bd\u2032) i such that K (\u03bd\u2032) i > K (\u03bd\u2032) R . Let also \u03c4 (\u03bd\u2032) denote the number of edges (vi, vj) in G such that K (\u03bd\u2032) i < K (\u03bd\u2032) L and K (\u03bd\u2032) j > K (\u03bd\u2032) L .\nLemma 11. Let \u03bd\u2032 be a linear arrangement of G\u2032 having maximum width at most k\u2032 + n2. There exist at least \u03ba (\u03bd\u2032) l \u00b7 (4n 2) + 2\u03c4(\u03bd \u2032) distinct edges which cross over l\u2217, not including edges internal to L or R.\nProof. We define I (\u03bd\u2032) L as the set of integers i \u2208 [n] such that K (\u03bd\u2032) i < K (\u03bd\u2032) L . Thus we have |I (\u03bd\u2032) L | = \u03ba (\u03bd\u2032) l . We also define J (\u03bd\u2032) L as the set of integers j \u2208 [n] such that K (\u03bd\u2032) j > K (\u03bd\u2032) L and there exists i \u2208 I (\u03bd\u2032) L with (vi, vj) \u2208 E, where E is the set of edges of G.\nFor each i \u2208 I (\u03bd\u2032) L , let us consider the 4n 2 distinct edges connecting Gi to M, along with each\npair of edges connecting Gi to each grid Gj such that K (\u03bd\u2032) j > K (\u03bd\u2032) L and (vi, vj) \u2208 E. Let also E be the set of all these edges, for every i \u2208 I (\u03bd\u2032) L . Thus we have |E | = \u03bal \u00b7 (4n 2) + 2\u03c4(\u03bd \u2032).\nConsider now an arbitrary edge e \u2208 E . Let x be one of the two endpoints of e, and assume that x belongs to some grid X among the n+ 3 grid components of G\u2032. We say that x is misplaced if, under \u03bd\u2032, the kernel of X is placed at some side with respect to l\u2217 and x is placed at the opposite side. From the definition of E , it is easy to see that if none of the endpoints of e are misplaced, or else if both of the endpoints of e are misplaced, then e must cross over l\u2217. On the other hand, if exactly one of the endpoints of e is misplaced, then e does not cross over l\u2217.\nConsider then the set of all the misplaced endpoints of some edge in E . By construction of G\u2032, these endpoints are distinct and belong to the first row or to the last row of some grid component of G\u2032. Furthermore, the edges in E are all single rather than multiple edges, as already observed in Section 3.2. By definition of \u03b1M and \u03b1i, i \u2208 [n], we have that \u03b1M + \u2211i\u2208(I(\u03bd \u2032)\nL \u222aJ (\u03bd\u2032) L )\n\u03b1i is greater\nthan or equal to the number of all the misplaced endpoints of some edge in E , and from the above observations we have that the latter number is in turn greater than or equal to the number of edges in E which do not cross over l\u2217. By Lemmas 9 and 10, it follows that, among the edges within M and among the edges within the components Gi, i \u2208 (I (\u03bd\u2032) L \u222a J (\u03bd\u2032) L ), there exist \u03b1M + \u2211i\u2208(I(\u03bd\n\u2032) L \u222aJ (\u03bd\u2032) L )\n\u03b1i\ndistinct edges which cross over l\u2217. This quantity plus the number of edges in E which cross over l\u2217 gives us the desired result.\nWe are now ready to show the inverse relation of the statement in Lemma 2. In what follows we focus our attention on linear arrangements of G\u2032 having maximum width at most k\u2032. The reason why all of the previous lemmas in this section have been stated for linear arrangements with maximum width at most k\u2032 + n2 is because in Section 4 we need to refer to this extended class.\nLemma 12. If \u3008G\u2032, k\u2032\u3009 is a positive instance of PMCW then \u3008G, k\u3009 is a positive instance of MBW.\nProof. Let \u03bd\u2032 be a linear arrangement of G\u2032 having maximum width bounded by k\u2032 = 3n4 + 2n3 + 2k+ 2, and consider quantity wd(G\u2032, \u03bd\u2032, l\u2217). From Lemma 11 there are at least \u03ba (\u03bd\u2032) l \u00b7 (4n 2) + 2\u03c4(\u03bd \u2032) distinct edges which cross over l\u2217, not including edges internal to the grids L or R. In addition, recall that there are at least 3n4 + 1 edges internal to L that are crossing over l\u2217. This is because of Corollary 1 and because of the way we have defined kernels. If \u03ba (\u03bd\u2032) l > n 2 , the number of edges contributing to wd(G\u2032, \u03bd\u2032, l\u2217) would be at least 3n4 + 1+ ( n2 + 1) \u00b7 4n 2 = 3n4 + 2n3 + 4n2 + 1 > 3n4 + 2n3 + 2k + 2 = k\u2032, for sufficiently large values of n, where the inequality follows from the fact that k is bounded by the number of edges in G, which is 3n2 . This is against our assumptions on \u03bd\u2032. Thus we must conclude that \u03ba (\u03bd\u2032) l \u2264 n 2 . Similarly, we can prove that \u03ba (\u03bd\u2032) r cannot be greater than n2 . Hence, we have that \u03ba (\u03bd\u2032) l = \u03ba (\u03bd\u2032) r = n 2 .\nUsing the above fact in Lemma 11, we have that the number of edges external to L and R crossing over l\u2217 is at least 2n3 + 2\u03c4(\u03bd \u2032). Including the edges internal to L gives at least 3n4 + 2n3 + 2\u03c4(\u03bd \u2032) + 1 edges crossing over l\u2217. Since the width of l\u2217 is at most 3n4 + 2n3 + 2k+ 2, it also follows that \u03c4(\u03bd \u2032) \u2264 k+ 12 . This means that the number of edges (vi, vj) in G such that K (\u03bd\u2032) i < K (\u03bd\u2032) L and K (\u03bd\u2032) j > K (\u03bd\u2032) L is at most k. Hence, by partitioning the nodes of G according to the position of their corresponding kernels under \u03bd\u2032, we have an equal size subset partition whose cut is at most k."}, {"heading": "3.5 Cutwidth and Internal Boundaries", "text": "We can now present the main results of Section 3.\nTheorem 1. The problem PMCW is NP-complete.\nProof. Let G be a cubic graph with n > 1 vertices, and let k > 0 be some integer. From Lemma 2 and from Lemma 12, we have that \u3008G, k\u3009 is a positive instance of MBW if and only if \u3008G\u2032, k\u2032\u3009 is a positive instance of PMCW. This relation shows that an algorithm for PMCW could be used to solve MBW, and thus PMCW is NP-hard.\nTo conclude the proof, we observe that the problem PMCW is in NP because a linear arrangement of a graph can be guessed in polynomial time and its maximum width can be computed in polynomial time as well.\nWe can now deal with a decision problem associated with the problem of finding a linear parsing strategy for a synchronous rule that minimizes the number of internal boundaries, defined in (2).\nTheorem 2. Let s be a synchronous rule with r nonterminals and with associated permutation \u03c0s, and let k be some positive integer. The problem of deciding whether\nmin \u03c3 max i\u2208[r] ib(\u03c0s, \u03c3, i) \u2264 k\nis NP-complete.\nProof. We have already observed that the relation cw(Gs) = min\u03c3 maxi\u2208[r] ib(\u03c0s, \u03c3, k) directly follows from Lemma 1. The statement then follows from Theorem 1."}, {"heading": "4 Relating Permutation Multigraphs to SCFGs", "text": "As discussed in Section 2, our main goal is finding efficient ways of parsing synchronous contextfree rules. In this section, we use our results on permutation multigraphs to prove NP-hardness for optimizing both space complexity and time complexity of linear parsing strategies for SCFG rules. We begin by examining space complexity, and then generalize the argument to prove our result on time complexity."}, {"heading": "4.1 Space Complexity", "text": "Optimizing the space complexity of a parsing strategy is equivalent to minimizing the maximum that the fan-out function achieves across the steps of the parsing strategy (5). According to the definition of the fan-out function (4), fan-out consists of the two terms ib and eb, accounting for the internal and the external boundaries, respectively, realized at a given step by a linear parsing strategy. Let s be a synchronous rule with Gs the associated permutation multigraph. We have already seen in Lemma 1 a relation between the ib term and the width function for Gs. In order to make precise the equivalence between the fan-out problem and the cutwidth problem for Gs, we must now account for the eb term.\nLet bR and eR be the first and the last vertices of the red path in Gs, and let bG and eG be the first and the last vertices of the green path. We collectively refer to these vertices as the endpoints of Gs, and we define Ve = {bR, eR, bG, eG}. Let \u03c3s be some linear parsing strategy for rule s, and\nlet \u03bds be the corresponding linear arrangement for Gs, as defined in Section 3.1. Informally, we observe that under \u03c3s the number of external boundaries at a given step i is the number of vertices from the set Ve that have been seen to the left of the current position i under \u03bds (including i itself). Using definition (4) and Lemma 1, this suggests that we can represent the fan-out at i as the width of an augmented permutation multigraph containing special edges from the vertices in Ve, where the special edges always extend past the right end of any linear arrangement. We introduce below some mathematical definitions that formalize this idea.\nAssumeGs has n nodes and set of edges E. We define the extended width at position i \u2208 [n]\u2212 1\nto be\newd(Gs, \u03bds, i) = wd(Gs, \u03bds, i) + \u2211 v\u2208Ve I(\u03bds(v) \u2264 i) . (8)\nThe contribution of the endpoints to the extended width can be visualized as counting, at each position in the linear arrangement, an additional set of edges running from the endpoint of the red and green paths all the way to the right end of the linear arrangement, as shown in Figure 8. We will refer to these additional edges as extended edges. To simplify the notation below, we also let ewd(Gs, \u03bds, n) = 4.\nLet \u03c0s be the permutation associated with synchronous rule s. Observe that the first term in (8) corresponds to the number of internal boundaries ib(\u03c0s, \u03c3s, i), by Lemma 1, and the second term counts the number of external boundaries eb(\u03c0s, \u03c3s, i). We can then write, for each i \u2208 [n]\nfo(\u03c0s, \u03c3s, i) = 1\n2 ewd(Gs, \u03bds, i) , (9)\nwhich will be used below to assess the complexity of the fan-out problem. Finally, we define the extended cutwidth of Gs as\necw(Gs) = min \u03bd max i\u2208[n] ewd(Gs, \u03bd, i) . (10)\nFrom (9) and (10) we see that the extended cutwidth of Gs is related to the optimal computational complexity that we can achieve when parsing synchronous rule s with the techniques described in Section 2.2. With such motivation, we investigate below a decision problem related to the computation of the extended cutwidth of a permutation multigraph.\nFrom now on, we assume that \u3008G, k\u3009 is an instance of MBW, where G is a cubic graph with n\nvertices. We also assume that G\u2032 and k\u2032 are constructed from G and k as in Section 3.2.\nLemma 13. If \u3008G, k\u3009 is a positive instance of MBW, then ecw(G\u2032) \u2264 k\u2032 + 2.\nProof. Under the assumption that \u3008G, k\u3009 is a positive instance of MBW, consider the linear arrangement \u03bd used in the proof of Lemma 2 to show that \u3008G\u2032, k\u2032\u3009 is a positive instance of PMCW. We already know that the maximum (regular) width of \u03bd is at most k\u2032. With the exception of the first column of grid L and the last column of grid R, the extended width under \u03bd at positions within L and R is two greater than the (regular) width, because the vertices bR and bG are both to the left, while eR and eG are to the right. For positions in the first column of L, the extended width is one greater than the width, because only bG is to the left, as depicted in Figure 7.\nThe critical point is the last column of R. We observe that the edges connecting vertices in the grid components Gi and M contribute to the extended width at positions within R always in the same amount. We thus focus our analysis on the only edges that are internal to R. Recall that eR is the topmost vertex in the last column of R. We let i be the position of eR under \u03bd. At position i\u2212 1 the contribution to the extendedwidth of the edges internal to R consists of 3n4 + 1 red edges and one green edge; see again Figure 7. At the next position i, one red edge and one green edge internal to R are lost. However, these two edges are replaced by one new red edge from R and one new extended edge impinging on vertex eR. Thus the extended width at positions i\u2212 1 and i must be the same. For all of the next positions corresponding to vertices in the last column of R, the contribution to the extended width of the edges internal to R always decreases.\nFrom the above observations, we conclude that the extended width at positions within grid components L and R is bounded by k\u2032 + 2 = 3n4 + 2n3 + 2k+ 4. As already observed in the proof of Lemma 2, the width at all of the remaining positions for \u03bd is lower by n4+O(n3), and this must also be the case for the extended width, since this quantity exceeds the (regular) width by at most four. The existence of linear arrangement \u03bd thus implies ecw(G\u2032) \u2264 k\u2032 + 2.\nLet \u03bd\u2032 be a linear arrangement of G\u2032 having maximum width at most k\u2032 + n2. Then \u03bd\u2032 satisfies the hypotheses of all of the lemmas in Section 3.4 constraining the linear arrangement of the kernels of the grid components of G\u2032. However, contrary to the case of the regular cutwidth, the extended cutwidth is not invariant to a reversal of a linear arrangement. This is so because the extended edges always end up at a position to the right of the right end of any linear arrangement. For this reason we can no longer assume that in \u03bd\u2032 we have L < R. Let then XL and XR be the leftmost and the rightmost, respectively, of L and R under \u03bd\u2032. Let also e\u2217 be the rightmost of l\u2217 and r\u2217.\nWe already know from the first part of the proof of Lemma 12 that the number of kernels\nto the left of K (\u03bd\u2032) XL is n2 , and this is also the number of kernels to the right of K (\u03bd\u2032) XR . Using this fact, the following result can easily be shown using the same argument presented in the proof of\nLemma 11. As in Section 3.4, let \u03c4(\u03bd \u2032) denote the number of edges (vi, vj) in G such that K (\u03bd\u2032) i < K (\u03bd\u2032) XL and K (\u03bd\u2032) j > K (\u03bd\u2032) XR .\nLemma 14. Let \u03bd\u2032 be a linear arrangement of G\u2032 having maximum width at most k\u2032 + n2. There are at least n 2 \u00b7 (4n 2) + 2\u03c4(\u03bd \u2032) distinct edges which cross over e\u2217, not including edges internal to the grids L or R.\nThe proof of the next lemma uses arguments very similar to those already exploited in the\nproof of Lemma 9 and in the proof of Lemma 12.\nLemma 15. If ecw(G\u2032) \u2264 k\u2032 + 2, then \u3008G, k\u3009 is a positive instance of MBW.\nProof. Let \u03bd\u2032 be a linear arrangement of G\u2032 having maximum extendedwidth bounded by k\u2032 + 2 = 3n4 + 2n3 + 2k + 4. Since the maximum (regular) width of G\u2032 is at most its maximum extended width, \u03bd\u2032 satisfies the hypotheses of all of the lemmas in Section 3.4 constraining the arrangement of the kernels and the misplaced nodes from the grid components of G\u2032.\nFrom Lemma 14 there are at least 2n3 + 2\u03c4(\u03bd \u2032) distinct edges which cross over e\u2217, not including edges internal to the grids L or R. In addition, there are at least 3n4 + 1 edges internal to XR that are crossing over e\u2217. Finally, consider the two endpoints of either the red or green path appearing in the first and in the last lines of XL, and let \u03b1e be the number of such endpoints that have been misplaced to the right of e\u2217 under \u03bd\u2032. Note that we have 0 \u2264 \u03b1e \u2264 2.\nLet P(XL) = {p : (\u03bd \u2032)\u22121(p) \u2208 XL} and let SXL = {p : (\u03bd \u2032)\u22121(p) \u2208 XL \u2227 p > e \u2217}. Because\n|P(XL)| = 36n 8 + 12n4 and |KXL | \u2265 17n 8, we know that |SXL | \u2264 |P(XL)\u2212 KL\u2032 | \u2264 20n 8. Therefore |SXL | \u2264 (12n 4)(3n4 + 1\u2212 \u03b1e \u2212 2) and we can apply Lemma 8 with X = XL and S = SXL . From Lemma 8, there are at least \u03b1e edges internal to XL that cross over e \u2217. Along with the 2 \u2212 \u03b1e extended edges departing from XL, this accounts for two additional edges that cross over e \u2217.\nCombining all of the above contributions, the total number of edges crossing over e\u2217 is at least 3n4 + 2n3 + 2\u03c4(\u03bd \u2032) + 3. Since the extended width of e\u2217 is at most 3n4 + 2n3 + 2k+ 4, it also follows that \u03c4(\u03bd \u2032) \u2264 k+ 12 . This means that the number of edges (vi, vj) in G such that K (\u03bd\u2032) i < K (\u03bd\u2032) L and K (\u03bd\u2032) j > K (\u03bd\u2032) L is at most k. Hence, by partitioning the nodes of G according to the position of their corresponding kernels under \u03bd\u2032, we have an equal size subset partition whose cut is at most k.\nTheorem 3. Let G be a permutation multigraph and let k be a positive integer. The problem of deciding whether ecw(G) \u2264 k is NP-complete.\nProof. By Lemma 13 and Lemma 15, an algorithm that decides whether ecw(G) \u2264 k can be used to solve MBW. Thus the problem in the statement of the theorem is NP-hard. The problem is in NP because the maximum extended width of a linear arrangement can be verified in polynomial time.\nTheorem 4. Let s be a synchronous rule with r nonterminals and with associated permutation \u03c0s, and let k be a positive integer. The problem of deciding whether\nmin \u03c3 max i\u2208[n] fo(\u03c0s, \u03c3, i) \u2264 k\nis NP-complete, where \u03c3 ranges over all linear parsing strategies for s.\nProof. The NP-hardness part directly follows from Theorem 3, along with (9) and (10). The problem is also in NP, because the maximum value of the fan-out for a guessed linear parsing strategy can be computed in polynomial time.\nWe have already discussed how fan-out is directly related to the space complexity of the implementation of a linear parsing strategy. From Theorem 4 we then conclude that optimization of the space complexity of linear parsing for SCFGs is NP-hard."}, {"heading": "4.2 Time Complexity", "text": "We now turn to the optimization of the time complexity of linear parsing for SCFGs. It turns out that at each step of a linear parsing strategy, the time complexity is related to a variant of the notion of width, called modifiedwidth, computed for the correspondingposition of a permutation graph. With this motivation, we investigate below themodifiedwidth and some extensions of this notion, and we derive our main result in a way which parallels what we have already done in Section 4.1.\nWe start with some additional notation. Let G = (V, E) be an undirected (multi)graph such that |V| = n > 1, and let \u03bd be some linear arrangement of G. For any i \u2208 [n], the modified width of G at i with respect to \u03bd, written mwd(G, \u03bd, i), is defined as |{(u, v) \u2208 E : \u03bd(u) < i < \u03bd(v)}|. Informally, mwd(G, \u03bd, i) is the number of distinct edges crossing over the vertex at position i-th in the linear arrangement \u03bd. Again in case of multigraphs the size of the previous set should be computed taking into account multiple edge occurrences. The following result is a corollary to Lemma 3.\nCorollary 2. For any grid X = \u0393[H,W] with W \u2265 2H + 1, for any linear arrangement \u03bd of X, and for any i with H2 < i \u2264 HW \u2212 H2, mwd(X, \u03bd, i) \u2265 H \u2212 2.\nProof. Modified width at the vertex in position i can be related to the (regular) width of the gaps before and after position i, and the degree \u2206(\u03bd\u22121(i)) of the vertex at position i\nmwd(X, \u03bd, i) = 1\n2 (wd(X, \u03bd, i\u2212 1) +wd(X, \u03bd, i)\u2212 \u2206(\u03bd\u22121(i))) .\nFor each i with H2 < i \u2264 HW \u2212 H2, we can use Corollary 1 and write\nmwd(X, \u03bd, i) \u2265 H \u2212 1\n2 \u2206(\u03bd\u22121(i))) .\nBecause vertices in a grid have degree at most four, we have mwd(X, \u03bd, i) \u2265 H \u2212 2.\nLet s be a synchronous rule and let Gs be the associated permutation multigraph. Let also \u03bds be a linear arrangement for Gs. We define the extended modified width at i \u2208 [n] as\nemwd(Gs, \u03bds, i) = wd(Gs, \u03bds, i) + \u2211 v\u2208Ve I(\u03bds(v) \u2264 i) . (11)\nAgain, the contribution of the endpoints of Gs to the extended modified width can be visualized as counting, at each position in the linear arrangement, an additional set of edges running from\nthe endpoint of the red and green paths all the way to the right end of the linear arrangement, as shown in Figure 8. The extended modified cutwidth of Gs is\nemcw(Gs) = min \u03bd max i\u2208[n] emwd(Gs, \u03bd, i) ,\nwhere \u03bd ranges over all possible linear arrangements for Gs.\nFrom now on, we assume that \u3008G, k\u3009 is an instance of MBW, where G is a cubic graph with n\nvertices. We also assume that G\u2032 and k\u2032 are constructed from G and k as in Section 3.2.\nLemma 16. If \u3008G, k\u3009 is a positive instance of MBW, then emcw(G\u2032) \u2264 k\u2032.\nProof. Consider the linear arrangement used in Lemma 13 to show that ecw(G\u2032) \u2264 k\u2032 + 2. The critical points in that linear arrangement are all within the L and R components. At all positions in these components, each vertex has two edges extending to its right and two edges extending to its left (one red and one green in each case). Thus, at these positions, the extended modified cutwidth is less than the extended cutwidth by two.\nLemma 17. If emcw(G\u2032) \u2264 k\u2032, then \u3008G, k\u3009 is a positive instance of MBW.\nProof. Assume a linear arrangement \u03bd\u2032 forG\u2032 havingmaximum extendedmodifiedwidth bounded by k\u2032. The maximum (non-extended)modified width of G\u2032 must be smaller than or equal to k\u2032, and the maximum (non-extended, non-modified) width of G\u2032 must be smaller than or equal to k\u2032 + 4, because the maximum degree of vertices in G\u2032 is four. Since the maximum width of G\u2032 under \u03bd\u2032 is bounded by k\u2032 + n2, we apply Lemma 14 and conclude that there are at least 2n3 + 2\u03c4(\u03bd \u2032) distinct edges which cross over the vertex to the left of the gap e\u2217, not including edges internal to the grids L or R.\nBy Corollary 2, the number of edges internal to XR which cross over the vertex to the left of the gap e\u2217 is at least 3n4 \u2212 1. Finally, consider the two endpoints of either the red or green path appearing in the first and in the last lines of XL, and let \u03b1e be the number of such endpoints that have been misplaced to the right of e\u2217 under \u03bd\u2032, with 0 \u2264 \u03b1e \u2264 2. We apply the same argument as in the proof of Lemma 15, and conclude that there are at least \u03b1e edges internal to XL that cross over the vertex to the left of the gap e\u2217. Along with the 2\u2212 \u03b1e extended edges departing from XL, this accounts for two additional edges that cross over the vertex to the left of the gap e\u2217.\nCombining all of the above contributions, the total number of edges crossing over the vertex to the left of the gap e\u2217 is at least 3n4 + 2n3 + 2\u03c4(\u03bd \u2032) + 1. Since the extended modified width of the vertex to the left of the gap e\u2217 is at most k\u2032 = 3n4 + 2n3 + 2k+ 2, it also follows that \u03c4(\u03bd \u2032) \u2264 k+ 12 . This means that the number of edges (vi, vj) in G such that K (\u03bd\u2032) i < K (\u03bd\u2032) XL and K (\u03bd\u2032) j > K (\u03bd\u2032) XR is at most k. Hence, by partitioning the nodes of G according to the position of their corresponding kernels under \u03bd\u2032, we have an equal size subset partition whose cut is at most k.\nTheorem 5. Let G be a permutation multigraph and let k be a positive integer. The problem of deciding whether emcw(G) \u2264 k is NP-complete.\nProof. By Lemma 17 and Lemma 16, an algorithm that decides whether emcw(G) \u2264 k can be used to solve MBW. Thus deciding whether emcw(G) \u2264 k is NP-hard. The problem is in NP because the maximum extended modified width of a linear arrangement can be verified in polynomial time.\nWe now relate the notion of extended modified width for a permutation multigraph and the time complexity of a parsing algorithm using a linear strategy. Let s be a synchronous rule with r nonterminals having the form in (7), and let Gs be the permutation multigraph associated with s. Let also \u03c3s be some linear parsing strategy defined for s, and let \u03bds be the linear arrangement associated with \u03c3s, as defined in Section 3.1. Recall from Section 2.2 that the family of parsing algorithms we investigate in this article use parsing states to represent the boundaries (internal and external) that delimit the substrings of the input that have been parsed at some step, following our strategy \u03c3s.\nFor some i with i \u2208 [r \u2212 1], let us consider some parsing state with state type (s, \u03c3s, i). In the next parsing step i + 1, we move to a new state with state type (s, \u03c3s, i+ 1) by adding to our partial analyses the (i+ 1)-th pair of nonterminals from the right-hand side of s, defined according to \u03c3s. As already observed in Section 2.2, this operation involves some updates to the sequence of boundaries of our old state of type (s, \u03c3s, i). More precisely, the new state is constructed from the old state by removing a number \u03b4 (\u2212) i+1 of boundaries, and by adding a number \u03b4 (+) i+1 of new boundaries. From the definition of Gs, we know that \u03b4 (\u2212) i+1 is the number of backward edges at vertex i + 1, and \u03b4 (+) i+1 is the number of forward edges at vertex i + 1, where backward, forward and vertex i + 1 are all defined relative to the linear arrangement \u03bds and include the extended edges. We also have \u03b4 (\u2212) i+1 + \u03b4 (+) i+1 = \u2206(\u03bd \u22121 s (i+ 1)), where \u2206(\u03bd \u22121(i+ 1)) is the degree of the vertex at position i+ 1.\nThe total number of boundaries ti+1 involved in the parsing step i + 1 is then the number of boundaries for state type (s, \u03c3s, i), which includes the \u03b4 (\u2212) i+1 boundaries that need to be removed at such step, plus the new boundaries \u03b4 (+) i+1 . We already know that ewd(Gs, \u03bds, i) is the number of boundaries for (s, \u03c3s, i). We can then write\nti+1 = ewd(Gs, \u03bds, i) + \u03b4 (+) i+1\n= ewd(Gs, \u03bds, i)\u2212 \u03b4 (\u2212) i+1 + \u03b4 (\u2212) i+1 + \u03b4 (+) i+1 = emwd(Gs, \u03bds, i+ 1) + \u2206(\u03bd \u22121 s (i+ 1)) = emwd(Gs, \u03bds, i+ 1) + 4 .\nThat is, the total number of boundaries involved in a parsing step is the number of boundaries that are not affected by the step, which correspond to edges passing over a vertex in the linear arrangement, emwd(Gs, \u03bds, i+ 1), plus the number of boundaries opened or closed by adding the new nonterminal, which is the vertex\u2019s degree \u2206(\u03bd\u22121s (i+ 1)).\nLet w1 and w2 be the input strings in our synchronous parsing problem, and let n be the maximumbetween the lengths ofw1 andw2. Observe that theremay beO(n ti+1) different instantiations of parsing step i+ 1 in our algorithm. In order to optimize the time complexity of our algorithm,\nrelative to synchronous rule s, we then need to choose a linear arrangement that achieves maximum extended modified width of emcw(Gs). From Theorem 5, we then conclude that optimization of the time complexity of linear parsing for SCFGs is NP-hard."}, {"heading": "5 Discussion", "text": "In this section, we discuss the implications of our results for machine translation. Synchronous parsing is the problem of finding a suitable representation of the derivations of a string pair consisting of one string from each language in the translation. In the context of statistical machine translation, this problem arises when we wish to analyze string pairs consisting of known parallel text in, say, English and Chinese, for the purposes of counting how often each SCFG rule is used and estimating its probability. Thus, synchronous parsing corresponds to the training phase of a statistical machine translation system. Our results show that it is NP-hard to find the linear synchronous parsing strategy with the lowest space complexity or the lowest time complexity. This indicates that learning complex translation models from parallel text is a fundamentally hard problem.\nA separate, but closely related, problem arises when translating new Chinese sentences into English, a problem known as decoding. A simple decoding algorithm consists of parsing the Chinese string with the Chinese side of the SCFG, and simply reading the English translation off of the English side of each rule used. This can be accomplished in time O(n3) using the CYK parsing algorithm for (monolingual) context-free grammars, since we use only one side of the SCFG.\nMore generally, we may wish to compute not only the single highest-scoring translation, but a compact representation of all English translations of the Chinese string. Just as the chart constructed during monolingual parsing can be viewed as a non-recursive CFG generating all analyses of a string, we can parse the Chinese string with the Chinese side of the SCFG, retain the resulting chart, and use the English sides of the rules as a non-recursive CFG generating all possible English translations of the Chinese string. However, in general, the rules cannot be binarized in this construction, since the Chinese and English side of each rule are intertwined. This means that the resulting non-recursive CFG has size greater than O(n3), with the exponent depending on the maximum length of the SCFG rules. One way to reduce the exponent is to factor each SCFG rule into a sequence of steps, as in our linear SCFG parsing strategies.\nMachine translation systems do, in fact, require such a representation of possible translations, rather than simply taking the single best translation according to the SCFG. This is because the score from the SCFG is combined with a score from an English N-gram language model in order to bias the output English string toward hypotheseswith a high prior probability, that is, strings that look like valid English sentences. In order to incorporate scores from an English N-gram language model of order m, we extend the dynamic programming algorithm to include in the state of each hypothesis the first and last m \u2212 1 words of each contiguous segment of the English sentence. Thus, the number of contiguous segments in English, which is the fan-out of the parsing strategy on the English side, again enters into the complexity [HZGK09]. Given a parsing strategywith fan-\nout fc on the Chinese side and fan-out fe on the English side, the space complexity of the dynamic programming table is O(n fcV2 fe(m\u22121)), where n is the length of the Chinese input string, V is the size of the English vocabulary, and m is the order of N-gram language model. Under the standard assumption that each Chinese word has a constant number of possible English translations, this is equivalent to O(n fc+2 fe(m\u22121)). Thus, our NP-hardness result for the space complexity of linear strategies for synchronous parsing also applies to the space complexity of linear strategies for decoding with an integrated language model.\nSimilarly, the time complexity of language-model-integrated decoding is related to the time complexity of synchronous parsing through the order m of the N-gram language model. In synchronous parsing, the time complexity of a step combining of state of type (s, \u03c3, k) and a nonterminal (A1,k+1, A2,\u03c0\u22121(k+1)) to produce a state of type (s, \u03c3, k+ 1) is O(n a+b+c), where a is the number of boundaries in states of type (s, \u03c3, k), b the number in nonterminal (A1,k+1, A2,\u03c0\u22121(k+1)), and c the number in type (s, \u03c3, k + 1). If we rewrite a as ac + ae, where ac is the number of boundaries in Chinese and ae is the number of boundaries in English, then the exponent for the complexity of synchronous parsing is:\nae + be + ce + ac + be + ce\nand the exponent for language-model-integrated decoding is:\n(m\u2212 1)(ae + be + ce) + ac + be + ce\nNote that these two expressions coincide in the case where m = 2. Since we proved that optimizing the time complexity of linear synchronous parsing strategies is NP-complete, our result also applies to the more general problem of optimizing time complexity of language-model-integrated decoding for language models of general order m.\nOpen Problems This article presents the first NP-hardness result regarding parsing strategies for SCFGs. However, there is a more general version of the problem whose complexity is still open. In this article, we have restricted ourselves to linear parsing strategies, that is, strategies that add one nonterminal at a time to the subset of right hand side nonterminals recognized so far. In general, parsing strategies may group right hand side nonterminals hierarchically into a tree. For some permutations, hierarchical parsing strategies for SCFG rules can be more efficient than linear parsing strategies [HZGK09]. Whether the time complexity of hierarchical parsing strategies is NP-hard is not known even for the more general class of LCFRS. An efficient algorithm for minimizing the time complexity of hierarchical strategies for LCFRS would imply an improved approximation algorithm for the well-studied graph-theoretic problem of treewidth [Gil11]. Minimizing fan-out of hierarchical strategies, on the other hand, is trivial, for both LCFRS and SCFG. This is because the strategy of combining all right hand side nonterminals in one step (that is, forming a hierarchy of only one level) is optimal in terms of fan-out, despite its high time complexity."}], "references": [{"title": "Syntax directed translations and the pushdown assembler", "author": ["Alfred V. Aho", "Jeffery D. Ullman"], "venue": "J. Computer and System Sciences,", "citeRegEx": "Aho and Ullman.,? \\Q1969\\E", "shortCiteRegEx": "Aho and Ullman.", "year": 1969}, {"title": "The Theory of Parsing, Translation, and Compiling, volume", "author": ["Albert V. Aho", "Jeffery D. Ullman"], "venue": null, "citeRegEx": "Aho and Ullman.,? \\Q1972\\E", "shortCiteRegEx": "Aho and Ullman.", "year": 1972}, {"title": "Graph bisection algorithms with good average case", "author": ["T. Bui", "S. Chaudhuri", "T. Leighton", "M. Sipser"], "venue": "behavior. Combinatorica,", "citeRegEx": "Bui et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Bui et al\\.", "year": 1987}, {"title": "The mathematics of statistical machine translation: Parameter estimation", "author": ["Peter F. Brown", "Stephen A. Della Pietra", "Vincent J. Della Pietra", "Robert L. Mercer"], "venue": "Computational Linguistics,", "citeRegEx": "Brown et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "Optimal head-driven parsing complexity for linear context-free rewriting systems", "author": ["Pierluigi Crescenzi", "Daniel Gildea", "Andrea Marino", "Gianluca Rossi", "Giorgio Satta"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Crescenzi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Crescenzi et al\\.", "year": 2011}, {"title": "Evaluation of Grammar Formalisms for Applications to Natural Language Processing and Biological Sequence Analysis", "author": ["David Chiang"], "venue": "PhD thesis, University of Pennsylvania,", "citeRegEx": "Chiang.,? \\Q2004\\E", "shortCiteRegEx": "Chiang.", "year": 2004}, {"title": "Hierarchical phrase-based translation", "author": ["David Chiang"], "venue": "Computational Linguistics,", "citeRegEx": "Chiang.,? \\Q2007\\E", "shortCiteRegEx": "Chiang.", "year": 2007}, {"title": "An efficient context-free parsing algorithm", "author": ["Jay Earley"], "venue": "Communications of the ACM,", "citeRegEx": "Earley.,? \\Q1970\\E", "shortCiteRegEx": "Earley.", "year": 1970}, {"title": "What\u2019s in a translation rule", "author": ["Michel Galley", "Mark Hopkins", "Kevin Knight", "Daniel Marcu"], "venue": "In Proceedings of the 2004 Meeting of the North American chapter of the Association for Computational Linguistics", "citeRegEx": "Galley et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Galley et al\\.", "year": 2004}, {"title": "Grammar factorization by tree decomposition", "author": ["Daniel Gildea"], "venue": "Computational Linguistics,", "citeRegEx": "Gildea.,? \\Q2011\\E", "shortCiteRegEx": "Gildea.", "year": 2011}, {"title": "Efficient parsing of well-nested linear context-free rewriting systems", "author": ["Carlos G\u00f3mez-Rodr\u0131\u0301guez", "Marco Kuhlmann", "Giorgio Satta"], "venue": "In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "G\u00f3mez.Rodr\u0131\u0301guez et al\\.,? \\Q2010\\E", "shortCiteRegEx": "G\u00f3mez.Rodr\u0131\u0301guez et al\\.", "year": 2010}, {"title": "Optimal reduction of rule length in Linear Context-Free Rewriting Systems", "author": ["Carlos G\u00f3mez-Rodr\u0131\u0301guez", "Marco Kuhlmann", "Giorgio Satta", "DavidWeir"], "venue": "In Proceedings of the 2009 Meeting of the North American chapter of the Association for Computational Linguistics", "citeRegEx": "G\u00f3mez.Rodr\u0131\u0301guez et al\\.,? \\Q2009\\E", "shortCiteRegEx": "G\u00f3mez.Rodr\u0131\u0301guez et al\\.", "year": 2009}, {"title": "Worst-case synchronous grammar rules", "author": ["Daniel Gildea", "Daniel \u0160tefankovi\u010d"], "venue": "In Proceedings of the 2007 Meeting of the North American chapter of the Association for Computational Linguistics", "citeRegEx": "Gildea and \u0160tefankovi\u010d.,? \\Q2007\\E", "shortCiteRegEx": "Gildea and \u0160tefankovi\u010d.", "year": 2007}, {"title": "Introduction to Automata Theory, Languages, and Computation", "author": ["John E. Hopcroft", "Jeffrey D. Ullman"], "venue": null, "citeRegEx": "Hopcroft and Ullman.,? \\Q1979\\E", "shortCiteRegEx": "Hopcroft and Ullman.", "year": 1979}, {"title": "Binarization of synchronous context-free grammars", "author": ["Liang Huang", "Hao Zhang", "Daniel Gildea", "Kevin Knight"], "venue": "Computational Linguistics,", "citeRegEx": "Huang et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2009}, {"title": "Statistical phrase-based translation", "author": ["Philipp Koehn", "Franz Josef Och", "Daniel Marcu"], "venue": "In Proceedings of the 2003 Meeting of the North American chapter of the Association for Computational Linguistics", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Syntax-directed transduction", "author": ["II P.M. Lewis", "R.E. Stearns"], "venue": "Journal of the ACM,", "citeRegEx": "Lewis and Stearns.,? \\Q1968\\E", "shortCiteRegEx": "Lewis and Stearns.", "year": 1968}, {"title": "Topological bandwidth", "author": ["F.S. Makedon", "C.H. Papadimitriou", "I.H. Sudborough"], "venue": "SIAM Journal on Algebraic and Discrete Methods,", "citeRegEx": "Makedon et al\\.,? \\Q1985\\E", "shortCiteRegEx": "Makedon et al\\.", "year": 1985}, {"title": "Optimal cutwidths and bisection widths of 2- and 3-dimensional meshes", "author": ["Jos\u00e9 D.P. Rolim", "Ondrej S\u00fdkora", "Imrich Vrto"], "venue": "In 21st International Workshop on GraphTheoretic Concepts in Computer Science,", "citeRegEx": "Rolim et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Rolim et al\\.", "year": 1995}, {"title": "On multiple context-free grammars", "author": ["H. Seki", "T. Matsumura", "M. Fujii", "T. Kasami"], "venue": "Theoretical Computer Science,", "citeRegEx": "Seki et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Seki et al\\.", "year": 1991}, {"title": "Some computational complexity results for synchronous context-free grammars", "author": ["Giorgio Satta", "Enoch Peserico"], "venue": "In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP),", "citeRegEx": "Satta and Peserico.,? \\Q2005\\E", "shortCiteRegEx": "Satta and Peserico.", "year": 2005}, {"title": "Synchronous tree-adjoining grammars", "author": ["Stuart Shieber", "Yves Schabes"], "venue": "In Proceedings of the 13th International Conference on Computational Linguistics (COLING-90),", "citeRegEx": "Shieber and Schabes.,? \\Q1990\\E", "shortCiteRegEx": "Shieber and Schabes.", "year": 1990}, {"title": "An alternative conception of tree-adjoining derivation", "author": ["Yves Schabes", "Stuart M. Shieber"], "venue": "Computational Linguistics,", "citeRegEx": "Schabes and Shieber.,? \\Q1994\\E", "shortCiteRegEx": "Schabes and Shieber.", "year": 1994}, {"title": "Optimal rank reduction for linear context-free rewriting systems with fan-out two", "author": ["Beno\u0131\u0302t Sagot", "Giorgio Satta"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Sagot and Satta.,? \\Q2010\\E", "shortCiteRegEx": "Sagot and Satta.", "year": 2010}, {"title": "Characterizing structural descriptions produced by various grammatical formalisms", "author": ["K. Vijay-Shankar", "D.L. Weir", "A.K. Joshi"], "venue": "In Proceedings of the 25th Annual Conference of the Association for Computational Linguistics", "citeRegEx": "Vijay.Shankar et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Vijay.Shankar et al\\.", "year": 1987}, {"title": "Recognition and parsing of context-free languages in time n3", "author": ["Daniel H. Younger"], "venue": "Information and Control,", "citeRegEx": "Younger.,? \\Q1967\\E", "shortCiteRegEx": "Younger.", "year": 1967}], "referenceMentions": [], "year": 2013, "abstractText": "Synchronous Context-Free Grammars (SCFGs), also known as syntax-directed translation schemata [AU69, AU72], are unlike context-free grammars in that they do not have a binary normal form. In general, parsing with SCFGs takes space and time polynomial in the length of the input strings, but with the degree of the polynomial depending on the permutations of the SCFG rules. We consider linear parsing strategies, which add one nonterminal at a time. We show that for a given input permutation, the problems of finding the linear parsing strategy with the minimum space and time complexity are both NP-hard.", "creator": "LaTeX with hyperref package"}}}