{"id": "1312.3258", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Dec-2013", "title": "Implicit Sensitive Text Summarization based on Data Conveyed by Connectives", "abstract": "So far and trying to reach human capabilities, research in automatic summarization has been based on hypothesis that are both enabling and limiting. Some of these limitations are: how to take into account and reflect (in the generated summary) the implicit information conveyed in the text, the author intention, the reader intention, the context influence, the general world knowledge. Thus, if we want machines to mimic human abilities, then they will need access to this same large variety of knowledge. The implicit is affecting the orientation and the argumentation of the text and consequently its summary. Most of Text Summarizers (TS) are processing as compressing the initial data and they necessarily suffer from information loss. TS are focusing on features of the text only, not on what the author intended or why the reader is reading the text. In this paper, we address this problem and we present a system focusing on acquiring knowledge that is implicit. We principally spotlight the implicit information conveyed by the argumentative connectives such as: but, even, yet and their effect on the summary.", "histories": [["v1", "Wed, 11 Dec 2013 17:50:21 GMT  (274kb)", "http://arxiv.org/abs/1312.3258v1", "4 pages, 2 figures, journal IJACSA; (IJACSA) International Journal of Advanced Computer Science and Applications, Vol. 4, No. 11, 2013"]], "COMMENTS": "4 pages, 2 figures, journal IJACSA; (IJACSA) International Journal of Advanced Computer Science and Applications, Vol. 4, No. 11, 2013", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["henda chorfi ouertani"], "accepted": false, "id": "1312.3258"}, "pdf": {"name": "1312.3258.pdf", "metadata": {"source": "CRF", "title": "Implicit Sensitive Text Summarization based on Data Conveyed by Connectives", "authors": ["Henda Chorfi Ouertani"], "emails": [], "sections": [{"heading": null, "text": "1 | P a g e www.ijacsa.thesai.org\nresearch in automatic summarization has been based on hypothesis that are both enabling and limiting. Some of these limitations are: how to take into account and reflect (in the generated summary) the implicit information conveyed in the text, the author intention, the reader intention, the context influence, the general world knowledge\u2026. Thus, if we want machines to mimic human abilities, then they will need access to this same large variety of knowledge. The implicit is affecting the orientation and the argumentation of the text and consequently its summary. Most of Text Summarizers (TS) are processing as compressing the initial data and they necessarily suffer from information loss. TS are focusing on features of the text only, not on what the author intended or why the reader is reading the text. In this paper, we address this problem and we present a system focusing on acquiring knowledge that is implicit. We principally spotlight the implicit information conveyed by the argumentative connectives such as: but, even, yet \u2026. and their effect on the summary.\nKeywords\u2014Automatic summarization; implicit data; topoi;\ntopos; argumentation\nI. INTRODUCTION\nNowadays, text summarization has become widely used on the internet. Users of text summarization are countless. They can be simple internet surfers searching for different news, elearners looking for specific educational materials or scientists exploring particular publications\u2026 Text summarization can help those users identify, in a short time (by reducing a large amount of information to a summary), which documents are most relevant to their needs. But, there is widespread agreement that summarization that reduces a large volume of information to a summary preserving only the most essential items, is a very hard process. Indeed, the human summarization is the process that given a document one tries to understand, interpret, abstract it and finally generate a new document as its summary [1].\nSo far and trying to reach human capabilities, research in automatic summarization has been based on hypothesis that are both enabling and limiting. Some of these limitations are: how to take into account and reflect (in the generated summary) the implicit information conveyed in the text, the author intention, the reader intention, the context influence, the general world knowledge ... Thus, If we want machines to mimic human abilities, then they will need access to this same large variety of knowledge [2].\nMost of Text Summarizers (TS) are processing as compressing the initial data and they necessarily suffer from information loss. TS are focusing on features of the text only, not on what the author intended or why the reader is reading the text. Thus a TS system must identify important parts and preserve them. In this paper, we will focus on acquiring knowledge that is implicit in the data and how to preserve it when generating the summary. The system we present generate argumentative text based on the implicit stored data conveyed by the \u201cargumentative connectives\u201d such as nevertheless, therefore, but, little, a little... When those connectives appear in sentences, they impose constraints on the argumentative movement. This movement is based on gradual rules of inference denoted by \u201ctopoi\u201d [3]\nThe paper is organized as follows: in section 2, we give an overview of the state of the art on text summarization. Section 3 reports on the theory of Argumentation Within Language (AWL) on which is based our implicit extractor. In section 4, we describe our system architecture. In conclusion, we summarize the contributions of this paper and introduce future research directions.\nII. TEXT SUMMARIZATION"}, {"heading": "A. Types of summarizers", "text": "Text summarization is now an established field of natural language processing, attracting many researchers and developers. We can distinguish two types of summarizers based on the volume of text to be summarized:\n- Single Document Summarization (SDS): If\nsummarization is performed for a single text\ndocument then it is called as the single document text\nsummarization\n- Mutli Document Summarization (MDS) : If the\nsummary is to be created for multiple text documents\nthen it is called as the multi document text\nsummarization"}, {"heading": "B. Summarization techniques", "text": "Techniques may vary depending on the summarization type. When considering the Single Document Summarization, we can cite the most important techniques:\n- Sentences extracting: This technique relies on trivial features of sentences, such as word frequency, presence of keywords, and sentence position, or a combination of such features [4], [5].\n2 | P a g e www.ijacsa.thesai.org\n- Identification of the relevant information: permitting to generate a textual summary from the facts that need to be included [6], [7].\nHowever, when dealing with Multi-document summarization, we can talk about\n- Extractive summarization: this technique involves assigning scores to some units (e.g. sentences, paragraphs) of the documents and extracting those with highest scores [8].\n- Abstractive summarization: this technique usually needs information fusion, sentence compression and reformulation [4].\nIII. HOW CONNECTIVES ARE AFFECTING SENTENCE ORIENTATION\nA. Introduction\nIn order to show the importance of the connective on the orientation of the sentence and on its general meaning, we used LSA tool (http://lsa.colorado.edu/) to compare two apparently same sentences. LSA is a theory and a method for extracting and representing the contextual usage meaning of words by statistical computation. LSA measures of similarity are considered highly correlated with human meaning similarities among words and texts. Moreover, it successfully imitates human word selection and category judgments [9].\nExample 1: Let us consider the two following sentences:\n1) The weather is beautiful but I have to work\n2) I have to work but the weather is beautiful\nWith LSA the two sentences will be represented with the same semantic vectors (fig. 1.) because for LSA the words like I, to, but \u2026 are ignored and the word order is not take into account.\nBut we agree that the two sentences argue to two different conclusions. So, it is definitely the impact of ignoring the connective but."}, {"heading": "B. Argumentation Within Language Theory", "text": "The Argumentation Within Language Theory (AWL) [10] has been concerned with the analysis of the \u201cargumentative\narticulators\u201d such as nevertheless, therefore, but, little, a little... When those articulators appear in utterances, they impose on constraints on the argumentative movement. This movement is based on gradual rules of inference denoted by \u201ctopoi\u201d. According to [11] and [12], a topos is an argumentative rule shared by a given community (which need have no more members than the speaker and the hearer). Topoi are the guarantors of the passage from the argument to the conclusion. Topoi are used to license the move from an argument to a conclusion.\nA topos (singular of topoi) is:\n- Presented as general: in the sense that the speaker implicates that the topos holds for other situations. It is not particular for the situation where it is used.\n- Presented as shared: in the sense that the speaker considers that the topos is accepted at least by the audience.\n- Gradual.\nThe canonical form of the topos includes two argumentative scales: the argument (antecedent) and the conclusion (consequent).\nEach scale is marked on \u201cplus\u201d or on \u201cminus\u201d from which the next topical forms are concluded:\n// + P , + Q//, // - P , - Q//,\n// + P , - Q// and // - P , + Q//.\nIf we believe // + P , + Q//, we necessarily believe // - P , - Q// and in the same way for (//+ P , - Q// ; // - P , + Q//) To illustrate the presentation above, let us consider the utterance\n(1) The weather is beautiful but I have to work.\nThe antecedent uses a topos such as //plus weather is beautiful, plus we want to go out//, the conclusion uses a topos such as //plus I have a work to do, minus I go out//. The use of \u201cbut\u201d in the utterance influences its argumentative orientation and the all utterance orientation will be the orientation of the conclusion.\nLet us now consider together the two sentences of example1: According to the AWL, the two sentences have opposite argumentative orientations.\nIndeed, for the sentence 1, if the antecedent uses topos like //+ beautiful weather, + outing// and the conclusion uses topos like //+ work, - outing// then the presence of \u201cbut\u201d imposes that the sentence have the argumentative orientation of the conclusion i.e. \u201c- outing\u201d.\nHowever, for the sentence 2, and with the same reasoning, its argumentative orientation is \u201c+ outing\u201d\nTo end this illustration, we note the importance of \u201cbut\u201d, in the sense that it imposes the argumentative orientation of the sentence. This importance of connectives was already\n3 | P a g e www.ijacsa.thesai.org\nrevealed by different works on Natural Language Process such as in [13] \u201cinterclausal connectives carry meaning, they connect textual meanings at both local and global levels and they mark discourse continuity and discontinuity both in the text and as inferred by the reader\u201d\nConnectives can shape the actual meaning of the text, they can also serve as efficient markers for instructions in the communicative process established between writer and reader.\nAfter this short outline on the theory of the Argumentation Within Language, in the next section we give a description of the architecture of an Argumentative Single Document Summarizer (ASDS).\nIV. SYSTEM ARCHITECTURE\nThis section gives an overview of the ASDS architecture and describes the functions of its various components. The global architecture is represented in Figure 1. It is composed of three layers of software : the Data pre-processor, the constraints generator and the summary generator.\nThe pre-processing layer aims at extracting connective elements. ASDS uses GATE [14] a natural language processing system.\nThe generator constraints layer Generate constraints based on the connectives constraints and the topos base. It permits to annotate the relevant sentences in the text. In our work we consider the sentence as the basic extraction unit. The connective constraints determine the type of argumentative relation between the argument and the conclusion - whether an argument-conclusion relation or argument-anti-argument relation- The topos base is used to link arguments to conclusions. This base allows the comparison of two arguments across scales (since a topos is gradual as discussed above).\nWe notice that the proposed summarization is focused on single document texts where argumentation takes an important place. The summary generator aims to filter sentence according to the constraints predetermined by the constraints generator. The algorithm below gives the different steps of summary generation :\n- Identify all sentences S={Si} of the document d. - Calculate sentences score with respect to their importance for the overall understanding of the text. This ranking is based on key words and connectives.\nSentences with connectives are weighted contrary to other sentences.\nKey words are determined by their frequency in the document.\nA Word-Sentence matrix is generated, where the column represents the sentences and the row represents the words. Words with maximum frequency are considered as key words.\nCalculate the score for each sentence using a formula using the key words weight and connectives weight :\nScore(Si) = Cw*Ww\nS1 S2 \u2026 \u2026. Sn\nW1\nW2\n..\n\u2026\nWn\nWw\nCw\nScore\nWhere Cw is the weight of connectives and Ww is the weight of key words.\n- Rank the sentences in the decreasing order of\ncalculated scores.\n- Apply connectives constraints on sentences including\nconnectives to generate conclusions.\n- Top ranked sentences and generated conclusions are\ncombined in sequence as document summary.\nV. FUTURE WORK\nIn the present work, we showed the role of connectives in argumentative texts when dealing with the orientation of the whole text. The analysis of these connectives indicates the existence of specific values intentionally assigned to them by the writer named topoi. As future work, we plan to investigate the topoi base. Many works need to be conducted especially how this base will be initialized and how it will be updated. We would like to continue the implementation of ASDS to apply our approach. Moreover, choosing argumentative texts to be used as input to our system needs further investigation.\nVI. CONCLUSION\nIn this paper we showed the role of connectives in argumentative texts when dealing with the orientation of the whole text. The analysis of these connectives indicates the existence of specific values intentionally assigned to them by the writer. For example But was shown to be functioning in sentence to impose constraints on the conclusion intended by the writer. Some recent trends of investigation support\n4 | P a g e www.ijacsa.thesai.org\ndifferent roles for these connectives in the construction of summaries of argumentative texts. In this context, we present the architecture of ASDS, an Argumentative Single Document Summarizer. ASDS is based on topoi which are gradual rules of inference. Topoi are the guarantors of the passage from the argument to the conclusion."}, {"heading": "ACKNOWLEDGMENT", "text": "This research project was supported by a grant from the Research Center of the Center for Female Scientific and Medical Colleges in King Saud University."}], "references": [{"title": "SEWISE: An Ontology-based Web Information Search Engine", "author": ["Georges Gardarin", "Huaizhong Kou", "KarineZeitouni", "XiaofengMeng", "Haiyan Wang"], "venue": "NLDB", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "Extracting Implicit Knowledge from Text, ProQuest", "author": ["Benjamin D. Van Durme"], "venue": "UMI Dissertation Publishing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Raccah, Argumentation and the lexical topical fields", "author": ["S.Bruxelles", "P.Y.O.Ducrot"], "venue": "Journal of Pragmatics", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1995}, {"title": "The identification of important concepts in highly structured technical papers", "author": ["Paice", "Chris", "Paul Jones"], "venue": "In Proceedings of the Conference on Research and Development in Information Retrieval", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1993}, {"title": "A trainable document summarizer", "author": ["J. Kupiec", "J. Pedersen", "F. Chen"], "venue": "In Proceedings of the 18th ACMSIGIR Conference,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1995}, {"title": "Generating natural language summaries from multiple on-line sources.Computational Linguistics", "author": ["D. Radev", "K. McKeown"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1998}, {"title": "Automated Acquisition of Topic Signatures for Text Summarization", "author": ["C.Y. Lin", "E. Hovy.The"], "venue": "In Proceedings of the 18International Conference on Computational Linguistics", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "An Algorithm for Language Independent Single and Multiple Document Summarization", "author": ["Rada Mihalcea", "Paul Tarau"], "venue": "In Proceedings of theInternational Joint Conference on Natural Language Processing (IJCNLP),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "An introduction to Latent Semantic Analysis", "author": ["Landauer", "T.k", "Foltz", "P. w", "Laham d"], "venue": "Discourse processes,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Metalinguistic Operators with Reference to French.Bern", "author": ["T. Nyan"], "venue": "Peter Lang,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1998}, {"title": "The Role of Interclausal Connectives in Narrative Structuring: Evidence from Adults", "author": ["E.M. SEGAL", "J.F. DUCHAN", "P. SCOTT"], "venue": "Interpretations of Simple Stories.\u201d Discourse Processes", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1991}, {"title": "GATE: A framework and graphical development environment for robust NLP tools and applications", "author": ["H. Cunningham", "D. Maynard", "K. Bontcheva", "V. Tablan"], "venue": "In ACL-02,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "Indeed, the human summarization is the process that given a document one tries to understand, interpret, abstract it and finally generate a new document as its summary [1].", "startOffset": 168, "endOffset": 171}, {"referenceID": 1, "context": "Thus, If we want machines to mimic human abilities, then they will need access to this same large variety of knowledge [2].", "startOffset": 119, "endOffset": 122}, {"referenceID": 2, "context": "This movement is based on gradual rules of inference denoted by \u201ctopoi\u201d [3]", "startOffset": 72, "endOffset": 75}, {"referenceID": 3, "context": "- Sentences extracting: This technique relies on trivial features of sentences, such as word frequency, presence of keywords, and sentence position, or a combination of such features [4], [5].", "startOffset": 183, "endOffset": 186}, {"referenceID": 4, "context": "- Sentences extracting: This technique relies on trivial features of sentences, such as word frequency, presence of keywords, and sentence position, or a combination of such features [4], [5].", "startOffset": 188, "endOffset": 191}, {"referenceID": 5, "context": "org - Identification of the relevant information: permitting to generate a textual summary from the facts that need to be included [6], [7].", "startOffset": 131, "endOffset": 134}, {"referenceID": 6, "context": "org - Identification of the relevant information: permitting to generate a textual summary from the facts that need to be included [6], [7].", "startOffset": 136, "endOffset": 139}, {"referenceID": 7, "context": "sentences, paragraphs) of the documents and extracting those with highest scores [8].", "startOffset": 81, "endOffset": 84}, {"referenceID": 3, "context": "- Abstractive summarization: this technique usually needs information fusion, sentence compression and reformulation [4].", "startOffset": 117, "endOffset": 120}, {"referenceID": 8, "context": "Moreover, it successfully imitates human word selection and category judgments [9].", "startOffset": 79, "endOffset": 82}, {"referenceID": 9, "context": "According to [11] and [12], a topos is an argumentative rule shared by a given community (which need have no more members than the speaker and the hearer).", "startOffset": 22, "endOffset": 26}, {"referenceID": 10, "context": "org revealed by different works on Natural Language Process such as in [13] \u201cinterclausal connectives carry meaning, they connect textual meanings at both local and global levels and they mark discourse continuity and discontinuity both in the text and as inferred by the reader\u201d", "startOffset": 71, "endOffset": 75}, {"referenceID": 11, "context": "ASDS uses GATE [14] a natural language processing system.", "startOffset": 15, "endOffset": 19}], "year": 2013, "abstractText": "So far and trying to reach human capabilities, research in automatic summarization has been based on hypothesis that are both enabling and limiting. Some of these limitations are: how to take into account and reflect (in the generated summary) the implicit information conveyed in the text, the author intention, the reader intention, the context influence, the general world knowledge.... Thus, if we want machines to mimic human abilities, then they will need access to this same large variety of knowledge. The implicit is affecting the orientation and the argumentation of the text and consequently its summary. Most of Text Summarizers (TS) are processing as compressing the initial data and they necessarily suffer from information loss. TS are focusing on features of the text only, not on what the author intended or why the reader is reading the text. In this paper, we address this problem and we present a system focusing on acquiring knowledge that is implicit. We principally spotlight the implicit information conveyed by the argumentative connectives such as: but, even, yet .... and their effect on the summary. Keywords\u2014Automatic summarization; implicit data; topoi; topos; argumentation", "creator": "Microsoft\u00ae Office Word 2007"}}}