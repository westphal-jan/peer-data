{"id": "1401.3467", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Planning over Chain Causal Graphs for Variables with Domains of Size 5 Is NP-Hard", "abstract": "Recently, considerable focus has been given to the problem of determining the boundary between tractable and intractable planning problems. In this paper, we study the complexity of planning in the class C_n of planning problems, characterized by unary operators and directed path causal graphs. Although this is one of the simplest forms of causal graphs a planning problem can have, we show that planning is intractable for C_n (unless P = NP), even if the domains of state variables have bounded size. In particular, we show that plan existence for C_n^k is NP-hard for k&gt;=5 by reduction from CNFSAT. Here, k denotes the upper bound on the size of the state variable domains. Our result reduces the complexity gap for the class C_n^k to cases k=3 and k=4 only, since C_n^2 is known to be tractable.", "histories": [["v1", "Wed, 15 Jan 2014 05:25:29 GMT  (592kb)", "http://arxiv.org/abs/1401.3467v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CC", "authors": ["omer gim\\'enez", "ers jonsson"], "accepted": false, "id": "1401.3467"}, "pdf": {"name": "1401.3467.pdf", "metadata": {"source": "CRF", "title": "Planning over Chain Causal Graphs for Variables with Domains of Size 5 Is NP-Hard", "authors": ["Omer Gim\u00e9nez", "Anders Jonsson"], "emails": ["omer.gimenez@upc.edu", "anders.jonsson@upf.edu"], "sections": [{"heading": null, "text": "n of planning problems, characterized by unary operators and\ndirected path causal graphs. Although this is one of the simplest forms of causal graphs a planning problem can have, we show that planning is intractable for C\nn (unless P = NP),\neven if the domains of state variables have bounded size. In particular, we show that plan existence for Ck\nn is NP-hard for k \u2265 5 by reduction from Cnf-Sat. Here, k denotes the\nupper bound on the size of the state variable domains. Our result reduces the complexity gap for the class Ck\nn to cases k = 3 and k = 4 only, since C2 n is known to be tractable."}, {"heading": "1. Introduction", "text": "There is an ongoing effort in the planning community to determine the complexity of different classes of planning problems. Known tractable classes are usually characterized by a simple causal graph structure accompanied by additional restrictions on variables and operators. However, the boundary between tractable and intractable planning problems is still not clearly established. The present paper contributes a novel complexity result for a class of planning problems with simple causal graph structure from the literature, in an effort to reduce this complexity gap.\nThe problem of determining tractable classes of planning problems is not purely of theoretical interest. For instance, complex planning problems can be projected onto tractable fragments of planning problems to generate heuristics to be used during search (Katz & Domshlak, 2008b). Also, the causal graph heuristic (Helmert, 2006) exploits the hierarchical structure of a planning problem by transforming it into a more tractable form: first, it translates propositional variables into multi-valued variables, a process that simplifies the causal graph of the problem; then, it keeps relaxing the problem until the causal graph becomes acyclic.\nThe present paper aims to study the complexity of planning problems in the class Cn, defined by Domshlak and Dinitz (2001). The class Cn contains planning problems with\nc\u00a92009 AI Access Foundation. All rights reserved.\nmulti-valued variables and chain causal graphs, i.e., the causal graph is just a directed path (implying that operators are unary). The notation n indicates that the number of state variables is unbounded. In particular, we study the complexity of plan existence for Cn, i.e., determining whether or not there exists a plan that solves a planning problem in Cn.\nEven though planning problems in Cn exhibit an extremely basic form of causal structure, i.e., linear dependence between state variables, solving planning problems in Cn is not necessarily tractable, even if we impose additional restrictions. Let Ckn be the subclass of Cn for which state variables have domains of size at most k. It is known that class C 2 n is polynomial-time solvable (Brafman & Domshlak, 2003) and that plan existence for class Cn is NP-hard (Gime\u0301nez & Jonsson, 2008a). Our aim is to study the complexity of plan existence for those classes in between, namely Ckn for k \u2265 3.\nDomshlak and Dinitz (2001) showed that there are solvable instances of C3n that require exponentially long plans. This means that there is no polynomial-time plan generation algorithm for Ckn with k \u2265 3, as was the case for C 2 n. However, this does not rule out the existence of a polynomial-time algorithm that determines plan existence for class Ckn, or even an algorithm that generates plans in some succinct form, like those of Jonsson (2007) and Gime\u0301nez and Jonsson (2008a). This is not incompatible with Cn being NP-hard.\nIn this paper, we prove that plan existence for the class Ckn is NP-hard for k \u2265 5. In other words, even if the causal graph is a directed path and the domains of the state variables are restricted to contain no more than 5 values, deciding whether or not a plan exists for solving the corresponding planning problem is NP-hard. Our result implies that it is not sufficient for a planning problem to exhibit linear variable dependence and restricted variable domain sizes; additional restrictions are necessary to make planning tractable.\nTable 1 shows an overview of the complexity results for the class Ckn to date. By \u201cMacro plan generation\u201d we mean any algorithm for generating a compact representation of the solution, such as in the work of Jonsson (2007) and Gime\u0301nez and Jonsson (2008a). The \u201cIntractable\u201d result for this column means that the complexity is yet unknown but cannot be in P unless P = NP (else plan existence would be in P). The row for k = 2 is due to Brafman and Domshlak (2003), the column for plan generation is due to Domshlak and Dinitz (2001), and the contributions of the present paper are marked in boldface. Note that the novel result subsumes that of Gime\u0301nez and Jonsson (2008a), who showed NP-hardness for k = O(n).\nThis paper is organized as follows. In Section 2 we relate our results to previous work, and in Section 3 we introduce the notation used throughout. In Section 4 we give formal proof of a reduction from Cnf-Sat to planning problems in C11n . The main result, a reduction from Cnf-Sat to planning problems in C5n, is then proved in Section 5. Although the result for C5n subsumes that for C 11 n , we believe that the intuitive idea behind the C 11 n\nreduction is easier to understand, and may be of interest for anyone trying to prove hardness results under similar circumstances. In Section 6 we discuss the complexity of the remaining classes C3n and C 4 n.\nWe also prove the correctness of a third reduction, this time from Cnf-Sat to C7n, in Appendix A. The reductions for C11n and C 7 n previously appeared in a conference paper (Gime\u0301nez & Jonsson, 2008b), and the present paper provides formal proof of their correctness."}, {"heading": "2. Related Work", "text": "The complexity of planning has been studied extensively over the last twenty years (Bylander, 1994; Chapman, 1987; Erol, Nau, & Subrahmanian, 1995). Many tractable classes of planning problems exploit the notion of a causal graph in one way or another. Knoblock (1994) is usually credited with introducing the causal graph in his work on hierarchical planning. Williams and Nayak (1997) required planning problems to have acyclic causal graphs in an effort to ensure tractability. Jonsson and Ba\u0308ckstro\u0308m (1998) defined the class 3S of planning problems, also with acyclic causal graphs, and showed that plan existence is tractable for this class.\nDomshlak and Dinitz (2001) introduced the class Cn of planning problems studied in this paper, as well as several related classes, all of which have a particular causal graph structure. Brafman and Domshlak (2003) designed a polynomial-time algorithm for solving planning problems with binary state variables and polytree causal graphs of bounded indegree, proving that planning is tractable for the class C2n. Brafman and Domshlak (2006) presented complexity results related to the tree-width of the causal graph. Katz and Domshlak (2008a) used causal graph structure to prove several complexity results for optimal planning.\nJonsson (2007) and Gime\u0301nez and Jonsson (2008a) designed polynomial-time algorithms that solve planning problems with restricted causal graphs by generating a hierarchy of macros. Recently, Chen and Gime\u0301nez (2008) showed that the complexity of planning is intractable unless the size of the largest connected component of the causal graph is bounded by a constant. Consequently, causal graph structure alone is not enough to guarantee tractability, implying that additional restrictions are needed."}, {"heading": "3. Notation", "text": "Throughout the paper, we use [i. .n] to denote the set {i, . . . , n}.\nLet V be a set of state variables, and let D(v) be the finite domain of state variable v \u2208 V . We define a state s as a function on V that maps each state variable v \u2208 V to a value s(v) \u2208 D(v) in its domain. A partial state p is a function on a subset Vp \u2286 V of state variables that maps each state variable v \u2208 Vp to p(v) \u2208 D(v). We frequently use the notation (v1 = x1, . . . , vk = xk) to denote a partial state p defined by Vp = {v1, . . . , vk} and p(vi) = xi for each vi \u2208 Vp.\nA planning problem is a tuple P = \u3008V, init, goal, A\u3009, where V is the set of variables, init is an initial state, goal is a partial goal state, and A is a set of operators. An operator a = \u3008pre(a); post(a)\u3009 \u2208 A consists of a partial state pre(a) called the pre-condition and a\nv 1\nv 2\nv 3\nv 4\nv 5\nFigure 1: Example causal graph of a planning problem in the class Ck5.\npartial state post(a) called the post-condition. Operator a is applicable in any state s such that s(v) = pre(a)(v) for each v \u2208 Vpre(a), and applying operator a in state s results in a new state s\u2032 such that s\u2032(v) = post(a)(v) if v \u2208 Vpost(a) and s \u2032(v) = s(v) otherwise.\nA partial plan \u03a0 for planning problem P is a sequence of operators a1, . . . , ak \u2208 A k, k \u2265 0, such that a1 is applicable in the initial state init and, for each i \u2208 [2 . .k], ai is applicable following the application of a1, . . . , ai\u22121 starting in init. Note that a partial plan does not necessarily solve P . A plan \u03a0 for solving P is a partial plan such that the goal state goal is satisfied following the application of a1, . . . , ak. P is solvable if and only if there exists such a plan \u03a0.\nThe causal graph of a planning problem P is a directed graph (V,E) with the state variables as nodes. There is an edge (u, v) \u2208 E if and only if u 6= v and there exists an operator a \u2208 A such that u \u2208 Vpre(a) \u222a Vpost(a) and v \u2208 Vpost(a). Figure 1 shows an example causal graph in the form of a directed path. The structure of the causal graph implies that each operator a \u2208 A is unary, i.e., the post-condition of a is specified on a single variable v, and the pre-condition of a is specified on (at most) v and its predecessor v\u2032 in the causal graph.\nIn this paper we study the class Ckn of planning problems, defined as follows:\nDefinition 3.1. A planning problem P belongs to the class Ckn if and only if the causal graph of P is a directed path and, for each v \u2208 V , |D(v)| \u2264 k.\nFor planning problems in Ckn, the domain transition graph, or DTG, of a state variable v is a labelled, directed graph (D(v), E\u2032) with the values in the domain of v as nodes. There is an edge (x, y) \u2208 E\u2032 with label l \u2208 D(v\u2032) if and only if there exists an operator \u3008v\u2032 = l, v = x; v = y\u3009 in A, where v\u2032 is the predecessor of v in the causal graph. An edge without label indicates that the pre-condition of the corresponding operator is defined on v alone. An edge with more than one label indicates the existence of multiple operators with the same pre- and post-condition on v but different pre-conditions on v\u2032.\n4. C11n Is NP-hard\nIn this section we prove that C11n is NP-hard by reduction from Cnf-Sat. In other words, to every CNF formula F we associate a planning instance P11(F ) of C 11 n such that P11(F ) is solvable if and only if F is satisfiable. We first describe the planning problem P11(F ), then explain the intuitive idea behind the reduction, and finally provide formal proof of its correctness.\nLet F = C1 \u2227 \u00b7 \u00b7 \u00b7 \u2227 Ck be a CNF formula on k clauses and n variables x1, . . . , xn. We define the planning problem P11(F ) = (V, init, goal, A) as follows. The variable set V is {si | i \u2208 [1 . .2n\u2212 1]} \u222a {vs} \u222a {vij | i \u2208 [1 . .k], j \u2208 [1 . .n]} \u222a {ve} \u222a {ei | i \u2208 [1 . .2n\u2212 1]}, with domains D(si) = D(ei) = D(ve) = {0, 1} for i \u2208 [1 . .2n \u2212 1], D(vs) = {0, 1, x}, and D(vij) = {gx, g0, g1, ax, a0, a1, b0, b1, cx, c0, c1} for i \u2208 [1 . .k], j \u2208 [1 . .n]. The initial state is defined by init(si) = init(ei) = init(ve) = 0, i \u2208 [1 . .2n \u2212 1], init(vs) = x, and init(vij) = ax\nfor i \u2208 [1 . .k], j \u2208 [1 . .n], and the goal state is a partial state defined by goal(vin) = gx for each i \u2208 [1 . .k], goal(ve) = 0, and goal(ei) = (i mod 2) for each i \u2208 [1 . .2n\u2212 1].\nBefore providing a formal definition of the operators in A, we give an intuitive overview of the planning problem P11(F ). To do this, we present the causal graph of P11(F ) as well as the DTGs of each state variable. A reader who is only interested in the formal proof of the correctness of the reduction may skip to Section 4.2, where we introduce the formal definitions of operators in order to prove several theoretical properties of P11(F )."}, {"heading": "4.1 Intuition", "text": "The planning problem P11(F ) associated to each CNF formula F consists of three parts, each with a clearly defined role. The three parts are illustrated in Figure 2, showing the causal graph of P11(F ). The first part of P11(F ) corresponds to state variables s1, . . . , s2n\u22121, vs, the second part corresponds to state variables v11, . . . , v1n, . . . , vk1, . . . , vkn, and the third part corresponds to state variables ve, e1, . . . , e2n\u22121. The role of the first part is to generate a message corresponding to an assignment to the variables of the CNF formula F . The role of the second part is to verify whether this assignment satisfies each clause Ci, and to remember this fact (using a value of state variable vin). Finally, the role of the third part is to make sure that the message is propagated all the way to the end of the chain.\nThe DTGs of state variables s1, . . . , s2n\u22121, vs appear in Figure 3. These state variables are used to generate an assignment \u03c3 to the variables x1, . . . , xn of the CNF formula F . To do this, the operators of P11(F ) are defined in such a way that the value of vs can change from x to either 0 or 1, while from 0 or 1 it can only change back to x. Thus, by applying the operators of P11(F ) it is possible to generate a sequence x,m1, x, . . . , x,mn, x of values of vs, where mj \u2208 {0, 1} for each j \u2208 [1 . .n].\nWe define a message m as the sequence m1, . . . ,mn of n symbols (either 0 or 1) corresponding to a sequence of values of vs. In what follows, we refer to these symbols as the \u201cbits\u201d of the message. The value x is used as a separator to distinguish between consecutive bits of the message. Given a message m, the assignment \u03c3 is defined as \u03c3(xj) = mj for each j \u2208 [1 . .n]. Thus, the assignment to x1 is determined by the first choice of whether to change the value of vs from x to 0 or 1, and so on. The only purpose of the remaining state variables si of the first part is to restrict the message m to contain no more than n bits.\nThe DTGs of state variables vij , i \u2208 [1 . .k] and j \u2208 [1 . .n], appear in Figure 4. The dashed edges in the DTGs indicate that the corresponding operators depend on the CNF formula F . For example, if the assignment \u03c3(x1) = 1 satisfies the clause C1, the edge from v11 = ax with label 1 in Figure 4(a) points to g1, else it points to b1. Likewise, if \u03c3(x1) = 0 satisfies C1, the edge from v11 = ax with label 0 points to g0, else it points to b0.\nRecall that the role of the second part is to check whether the assignment \u03c3 generated by the first part satisfies the CNF formula F . For each clause Ci and each variable xj of F , the main function of state variable vij is to check whether the assignment \u03c3(xj) = mj satisfies Ci. To do this, state variable vij acts as a finite state automaton that propagates each bit of the message m while keeping track of when the j-th bit of the message arrives. Since the domain size of state variables is restricted, there is no way for vij to count the number of bits it has received. Instead, the fact that the j-th bit has arrived is indicated to it by vi(j\u22121). Moreover, the last state variable vin for each clause Ci has to remember whether or not Ci has been satisfied by the assignment to some variable xj .\nIn summary, each state variable vij in the second part performs the following functions through its values and operators:\n1. Propagate the message m generated by vs.\n2. Check whether the assignment to xj (the j-th bit of m) satisfies the clause Ci.\n3. Remember whether Ci was satisfied by the assignment to some xl, l \u2264 j.\n4. If j < n and Ci has been satisfied, propagate this fact.\n5. If j < n, let vi(j+1) know when the (j + 1)-th bit of the message has arrived.\nNote that the third function is only strictly necessary for j = n. However, including it for all state variables makes the reduction more compact because of symmetry.\nNext, we briefly describe how vij implements each of these functions. Each value in the domain of vij has subscript 0, 1, or x. To propagate the message, vij always moves to a value whose subscript matches that of its predecessor (in the case of v11, its subscript should match the value of vs). Unless Ci is satisfied by the assignment to xl, l < j, the value of vij remains in the subdomain {a0, a1, ax} prior to the arrival of the j-th bit.\nThe clause Ci is encoded into the dashed edges of the DTGs of variables vij . These operators are such that when the j-th bit mj arrives, vij moves from ax to gmj if the assignment \u03c3(xj) = mj satisfies Ci, and to bmj otherwise. The fact that the value of vij is in the subdomain {g0, g1, gx} indicates that Ci was satisfied by the assignment to some xl, l \u2264 j. This fact is propagated all the way to vin since each subsequent state variable for Ci is forced to move to a value in the subdomain {g0, g1, gx} whenever the value of its predecessor is in {g0, g1, gx}. Whether or not a clause Ci has been satisfied is checked by defining a goal state vin = gx.\nFinally, if j < n and vij moves to bmj , then vi(j+1) moves to amj . From there, vij has no choice but to move to cx, causing vi(j+1) to return to ax. When the next bit arrives, vij moves to either c0 or c1, correctly indicating to vi(j+1) that the (j + 1)-th bit has arrived. Consequently, vi(j+1) moves to either g0 (g1) or b0 (b1), depending on whether or not the assignment to xj+1 satisfies Ci. Hence, the values of type b are used to delay the transition of vi(j+1) from a value of type a to either b or g. This is the mechanism that allows a variable vij to react to the j-th bit. For each clause Ci, the operators for vi1 are defined such that vi1 always reacts to the first bit.\nThe DTGs of state variables ve, e1, . . . , e2n\u22121 appear in Figure 5. The function of these state variables is to make sure that all n bits of the message m are propagated to the end of the causal graph. A state variable (strictly speaking, a planner solving the planning problem) is never forced to select an operator, so it can choose not to propagate a bit of the message and instead wait for the next bit to arrive before acting. In turn, this may cause another state variable to incorrectly conclude that a clause has (not) been satisfied. The variables of the third part prevent this from happening, since the goal state is defined in such a way that it cannot be reached unless all bits of the message arrive at the end of the causal graph."}, {"heading": "4.2 Formal Proof", "text": "In this section, we prove that C11n is NP-hard by showing that the planning problem P11(F ) is solvable if and only if the formula F has a satisfying assignment. To start with, we provide formal definitions of the operators of P11(F ). The operators for s1, . . . , s2n\u22121, vs appear in Table 2, and the corresponding DTGs appear in Figure 3. The operators for variables vij , i \u2208 [1 . .k] and j \u2208 [1 . .n], appear in Table 3, and the DTGs appear in Figure 4. Finally, the operators for ve, e1, . . . , e2n\u22121 appear in Table 4, and the DTGs appear in Figure 5.\nTo reduce the space requirement we use shorthand in the definitions of operators. In other words, \u3008v\u2032 = m, v = c; v = m\u3009, m \u2208 {a, b}, denotes the existence of two operators \u3008v\u2032 = a, v = c; v = a\u3009 and \u3008v\u2032 = b, v = c; v = b\u3009. Similarly, \u3008v\u2032 \u2208 {a, b}, v = c; v = d\u3009 denotes the existence of two operators \u3008v\u2032 = a, v = c; v = d\u3009 and \u3008v\u2032 = b, v = c; v = d\u3009. For state variables vij we also introduce reference numbers that allow us to easily refer to operators.\nFurthermore, some operators are conditional on properties of the CNF formula F ; such an operator only exists if the indicated property is satisfied. For example, the operator \u3008v22 = c0, v23 = ax; v23 = g0\u3009 only exists if the clause C2 is satisfied by x3, and the operator \u3008v22 = c0, v23 = ax; v23 = b0\u3009 only exists if C2 is not satisfied by x3. We use the set notation xj \u2208 Ci to denote that the literal xj appears in the clause Ci.\nThe proof is organized as follows. We begin with a series of technical definitions and lemmas (4.1\u20134.6) related to the operators and their implications. Definition 4.7 then introduces the notion of admissible plans, and Lemma 4.8 states that any plan for solving P11(F ) has to be admissible. Next, Lemma 4.10 establishes that any admissible plan corresponds to an assignment to the variables of the CNF formula F , and that all operator choices of the plan are forced given this assignment. Finally, Lemma 4.13 determines the exact sequence of values taken on by each state variable during the execution of an admissible plan, making it possible to check whether the goal state is reached at the end of the execution. Theorem 4.14 then concludes that the only admissible plans solving P11(F ) are those corresponding to satisfying assignments of F .\nDefinition 4.1. Given a partial plan \u03a0 for P11(F ) and a variable v \u2208 V , \u03a0(v) is the number of times the value of v is changed by operators in \u03a0.\nLemma 4.2. For each partial plan \u03a0 for P11(F ), it holds that\n\u2022 \u03a0(si) \u2264 i for i \u2208 [1 . .2n\u2212 1], and\n\u2022 \u03a0(vs) \u2264 2n.\nProof. By induction on i. For i = 1, variable s1 can only change once, so \u03a0(s1) \u2264 1. For i \u2208 [2 . .2n\u2212 1], it follows from inspection of the operators that we cannot change the value of si twice without changing the value of si\u22121 once in between (the operator for setting si to 1 has si\u22121 = 0 as a pre-condition, and the operator for resetting si to 0 has si\u22121 = 1 as a pre-condition). Since we can change the value of si once in the initial state without first changing the value of si\u22121, it follows that \u03a0(si) \u2264 \u03a0(si\u22121) + 1 \u2264 (i \u2212 1) + 1 = i by induction. The same argument holds for variable vs and its predecessor s2n\u22121, so \u03a0(vs) \u2264 \u03a0(s2n\u22121) + 1 \u2264 (2n\u2212 1) + 1 = 2n.\nLemma 4.3. For each partial plan \u03a0 for P11(F ) and each vij, i \u2208 [1 . .k] and j \u2208 [1 . .n], it holds that \u03a0(vij) \u2264 \u03a0(v \u2032), where v\u2032 is the predecessor of vij in the causal graph.\nProof. Just as before, it follows by inspection of the operators that we cannot change the value of vij twice without changing the value of v\n\u2032 in between. To see this, note that the subscript of each value in D(vij) is either x, 0, or 1. An operator for vij either changes its value from one with subscript x to one with subscript 0 (1), if v\u2032 also has a value with subscript 0 (1), or from one with subscript 0 (1) to one with subscript x, if v\u2032 also has a value with subscript x (the same argument holds for v11, although the values of its predecessor vs are x, 0, and 1 without subscripts).\nNote that the value of vij cannot change in the initial state without first changing the value of v\u2032, since v\u2032 has to have a value with subscript 0 or 1 for the value of vij to change from its initial value ax. Consequently, the value of vij cannot change more times than the value of v\u2032, so \u03a0(vij) \u2264 \u03a0(v \u2032) as claimed.\nLemma 4.4. For each vij, i \u2208 [1 . .k] and j \u2208 [1 . .n], and each partial state (v \u2032 = x, vij = y), where v\u2032 is the predecessor of vij in the causal graph, there is at most one applicable operator for changing the value of vij.\nProof. By inspecting the operators it is easy to see that each pair of operators for vij have different pre-conditions. The only exception to this rule are operators that do not exist simultaneously due to properties of the CNF formula F (e.g. operators (1) and (2)).\nLemma 4.5. For each partial plan \u03a0 for P11(F ), it holds that\n\u2022 \u03a0(ve) \u2264 \u03a0(vkn),\n\u2022 \u03a0(e1) \u2264 \u03a0(ve), and\n\u2022 \u03a0(ei) \u2264 \u03a0(ei\u22121) for i \u2208 [2 . .2n\u2212 1].\nProof. Let v be a variable among ve, e1, . . . , e2n\u22121, and let v \u2032 be its predecessor in the causal graph. As before, we cannot change the value of v twice without changing the value of v\u2032 once in between. If v \u2208 {e1, . . . , e2n\u22121}, the operator setting v to 1 requires v \u2032 = 1, and the operator resetting v to 0 requires v\u2032 = 0. For v = ve, the operator setting v to 1 requires v\u2032 to have a value with subscript 0 or 1, while the operator resetting v to 0 requires v\u2032 to have a value with subscript x. Note that, in either case, we cannot change the value of v in the initial state without first changing the value of v\u2032. Thus, \u03a0(v) \u2264 \u03a0(v\u2032) for each of these variables, as claimed.\nWe now turn to the problem of finding a plan \u03a0 that solves P11(F ).\nLemma 4.6. Let \u03a0 be a plan that solves P11(F ). Then\n\u2022 \u03a0(ei) \u2265 2n\u2212 i for i \u2208 [1 . .2n\u2212 1], and\n\u2022 \u03a0(ve) \u2265 2n.\nProof. By descending induction on i. For i = 2n \u2212 1, goal(e2n\u22121) = 1, so the value of e2n\u22121 has to change at least once from its initial value init(e2n\u22121) = 0, implying \u03a0(e2n\u22121) \u2265 1 = 2n \u2212 (2n \u2212 1). For i \u2208 [1 . .2n \u2212 2], assume that \u03a0(ei+1) \u2265 2n \u2212 (i + 1) holds by induction. From Lemma 4.5 it follows that \u03a0(ei) \u2265 \u03a0(ei+1) \u2265 2n \u2212 (i + 1). However, since goal(ei) 6= goal(ei+1) and since \u03a0 solves P11(F ), it follows that \u03a0(ei) 6= \u03a0(ei+1). Hence \u03a0(ei) > \u03a0(ei+1), from which it follows that \u03a0(ei) \u2265 2n \u2212 i, as claimed. The same argument applies to e1 and its predecessor ve, since goal(ve) = 0 6= 1 = goal(e1), yielding \u03a0(ve) \u2265 2n.\nDefinition 4.7. An admissible plan \u03a0 for planning problem P11(F ) is a partial plan such that \u03a0(si) = i, \u03a0(vs) = \u03a0(v11) = . . . = \u03a0(vkn) = \u03a0(ve) = 2n, and \u03a0(ei) = 2n\u2212 i, for each i \u2208 [1 . .2n\u2212 1].\nLemma 4.8. Any plan \u03a0 that solves P11(F ) is admissible.\nProof. By Lemmas 4.3 and 4.5 we have that \u03a0(vs) \u2265 \u03a0(v11) \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03a0(vkn) \u2265 \u03a0(ve). But, by Lemmas 4.2 and 4.6, all these values are equal to 2n, since 2n \u2265 \u03a0(vs) and \u03a0(ve) \u2265 2n. From the proof of Lemma 4.2 we have that \u03a0(si) \u2264 \u03a0(si\u22121) + 1, i \u2208 [2 . .2n \u2212 1], and \u03a0(vs) \u2264 \u03a0(s2n\u22121) + 1, which together with Lemma 4.2 and \u03a0(vs) = 2n implies \u03a0(si) = i, i \u2208 [1 . .2n\u22121]. From the proof of Lemma 4.6 we have that \u03a0(ve) > \u03a0(e1), \u03a0(ei) > \u03a0(ei+1), i \u2208 [1 . .2n\u2212 2], and \u03a0(e2n\u22121) \u2265 1, which together with Lemma 4.6 and \u03a0(ve) = 2n implies \u03a0(ei) = 2n\u2212 i, i \u2208 [1 . .2n\u2212 1].\nPlease note that the converse of Lemma 4.8 is not true, that is, not all admissible plans do solve the planning problem P11(F ).\nAs a consequence of Lemma 4.8, to find a plan that solves P11(F ) we only need to consider admissible plans. In particular, an admissible plan changes the value of variable vs exactly 2n times, generating a sequence of 2n+ 1 values. Note that the value of vs always changes from x to either 0 or 1, and then back to x.\nDefinition 4.9. Let \u03a0 be an admissible plan, and let x,m1, x, . . . , x,mn, x be the sequence of 2n+ 1 values that variable vs takes on during the execution of \u03a0, where mj \u2208 {0, 1} for each j \u2208 [1 . .n]. We use m\u03a0 to denote the message m1, . . . ,mn induced by \u03a0, and we use \u03c3\u03a0 to denote the formula assignment \u03c3\u03a0(xj) = mj for each j \u2208 [1 . .n].\nAs it turns out, the operators that are part of an admissible plan \u03a0 are completely determined by the message m\u03a0 induced by \u03a0.\nLemma 4.10. Let \u03a0 be an admissible plan for P11(F ) and let m\u03a0 be its induced message. The operators in \u03a0 for changing the value of variable vij, i \u2208 [1 . .k] and j \u2208 [1 . .n], as well as the sequence of values that variable vij takes on during the execution of \u03a0, are completely determined by m\u03a0.\nProof. For each v \u2208 {v11, . . . , vkn}, let v \u2032 be its causal graph predecessor. From the proof of Lemma 4.3 we know that we cannot change the value of v twice without changing the value of v\u2032 in between, and that in the initial state, we have to change the value of v\u2032 before we can change the value of v. From the definition of admissible we know that \u03a0(v\u2032) = \u03a0(v) = 2n. The only way an admissible plan can change the value of v 2n times without changing the value of v\u2032 more than 2n times is to first change the value of v\u2032, then v, then v\u2032, and so on.\nNow, from Lemma 4.4 we know that, given a partial state (v\u2032 = x, v = y), there is at most one applicable operator for changing the value of v. Thus, each time the admissible plan changes the value of v for some value of v\u2032, there is at most one operator for doing so. The plan has no choice but to select this operator since it is not allowed to change the value of v\u2032 again before changing the value of v. Consequently, if the sequence of values taken on by v\u2032 is completely determined, the operators for v, as well as the sequence of values it takes on, are completely determined also. The proof follows by a double induction on i and j, since the sequence of values taken on by vs (the predecessor of v11) is completely determined by the message m\u03a0.\nIt follows from Lemma 4.10 that the only relevant \u201cdegree of freedom\u201d of an admissible plan \u03a0 is selecting the elements of the message m\u03a0, by repeatedly deciding whether to move to vs = 0 or vs = 1 from vs = x. Once m\u03a0 has been selected, all other operator choices are forced, else the plan is not admissible. In particular, for each message m\u03a0 there is a unique state s such that executing any admissible plan starting from init results in s. It remains to determine whether this unique state matches the goal state.\nRemark. Note that Lemma 4.10 does not mention the operator order of an admissible plan. Indeed, we can change the order of the operators of an admissible plan without making the plan inadmissible. As an example, let v1, v2, and v3 be three consecutive variables in the causal graph, and let \u3008a11, a 1 2, a 1 3, a 2 1, a 2 2, a 2 3\u3009 be a subsequence of operators for changing their values, such that aji is the j-th operator for changing the value of vi. Then the subsequence \u3008a11, a 1 2, a 2 1, a 1 3, a 2 2, a 2 3\u3009 achieves the same result. As long as the partial order \u3008a j i , a j i+1, a j+1 i \u3009 is respected for each i and j, we can change the operator order as we please.\nWe proceed to determine the sequence of values that variable vij , i \u2208 [1 . .k] and j \u2208 [1 . .n], takes on during the execution of an admissible plan \u03a0 with induced message m\u03a0. First, we define the satisficing index of clauses, and the sequence of values of a plan.\nDefinition 4.11. Let \u03a0 be an admissible plan with induced message m\u03a0 = m. For each clause Ci, let the satisficing index Ti \u2208 [1 . .n+1] be the smallest number such that \u03c3\u03a0(xTi) = mTi satisfies Ci. If no such number exists, Ti = n+ 1.\nDefinition 4.12. Let \u03a0 be an admissible plan. For each clause Ci and each t \u2208 [1 . .2n+1], let the sequence of values Qti(\u03a0) be the vector of n values representing, for each variable vij , j \u2208 [1 . .n], the t-th value taken on by vij during the execution of \u03a0.\nThe following lemma is key to understanding the idea behind the reduction for C11n , since it specifies the sequences of values that an admissible plan induces during its execution.\nLemma 4.13. Let \u03c3 be an assignment to variables x1, . . . , xn of formula F .\n1) Existence. There exists an admissible plan \u03a0 of planning problem P11(F ) with induced assignment \u03c3\u03a0 = \u03c3.\n2) Claim. Let Qti be the sequences of values described in Part 3) of this lemma. All admissible plans \u03a0 with \u03c3\u03a0 = \u03c3 have the same sequences of values Q t i(\u03a0) = Q t i, for\nall i \u2208 [1 . .k] and t \u2208 [1 . .2n+ 1].\n3) Sequence of values. The sequence of values Qti, for i \u2208 [1 . .k] and t \u2208 [1 . .2n+ 1], is as follows.\na) If j < Ti, then\nQ2j\u22121i =\nj\u22121 \ufe37 \ufe38\ufe38 \ufe37 cx \u00b7 \u00b7 \u00b7 cx ax\nn\u2212j \ufe37 \ufe38\ufe38 \ufe37\nax \u00b7 \u00b7 \u00b7 ax Q2ji = cmj \u00b7 \u00b7 \u00b7 cmj bmj amj \u00b7 \u00b7 \u00b7 amj\nQ2j+1i = cx \u00b7 \u00b7 \u00b7 cx cx ax \u00b7 \u00b7 \u00b7 ax\nb) If j = Ti, then\nQ2j\u22121i =\nj\u22121 \ufe37 \ufe38\ufe38 \ufe37 cx \u00b7 \u00b7 \u00b7 cx ax\nn\u2212j \ufe37 \ufe38\ufe38 \ufe37\nax \u00b7 \u00b7 \u00b7 ax Q2ji = cmj \u00b7 \u00b7 \u00b7 cmj gmj gmj \u00b7 \u00b7 \u00b7 gmj\nQ2j+1i = cx \u00b7 \u00b7 \u00b7 cx gx gx \u00b7 \u00b7 \u00b7 gx\nc) If j > Ti, then\nQ2j\u22121i =\nTi\u22121 \ufe37 \ufe38\ufe38 \ufe37 cx \u00b7 \u00b7 \u00b7 cx\nj\u2212Ti \ufe37 \ufe38\ufe38 \ufe37 gx \u00b7 \u00b7 \u00b7 gx gx\nn\u2212j \ufe37 \ufe38\ufe38 \ufe37\ngx \u00b7 \u00b7 \u00b7 gx Q2ji = cmj \u00b7 \u00b7 \u00b7 cmj gmj \u00b7 \u00b7 \u00b7 gmj gmj gmj \u00b7 \u00b7 \u00b7 gmj\nQ2j+1i = cx \u00b7 \u00b7 \u00b7 cx gx \u00b7 \u00b7 \u00b7 gx gx gx \u00b7 \u00b7 \u00b7 gx\nProof. Before proving the lemma, we must check that the definition of Qti given in Part 3 is consistent. This is necessary due to the overlapping of the statements, namely, for every odd t other than 1 and 2n+1, the sequence Qti is defined twice, once as Q 2j\u22121 i for j = \u2308 t 2\u2309, and another time as Q2j \u2032+1\ni for j \u2032 = \u230a t2\u230b. However, these sequences of values are well-defined\nbecause the definitions of Q2j\u22121i and Q 2j\u2032+1 i match for any combination of j and j \u2032 = j \u2212 1, as shown in the following table.\nj\u2032 j Q2j \u2032+1 i = Q 2j\u22121 i\n1 < j < Ti: Case (a) Case (a)\nj\u2032\n\ufe37 \ufe38\ufe38 \ufe37 cx \u00b7 \u00b7 \u00b7 cx\nn\u2212j\u2032\n\ufe37 \ufe38\ufe38 \ufe37 ax \u00b7 \u00b7 \u00b7 ax\n1 < j = Ti: Case (a) Case (b)\nj\u2032\n\ufe37 \ufe38\ufe38 \ufe37 cx \u00b7 \u00b7 \u00b7 cx\nn\u2212j\u2032\n\ufe37 \ufe38\ufe38 \ufe37 ax \u00b7 \u00b7 \u00b7 ax\nj = Ti + 1 \u2264 n: Case (b) Case (c)\nTi\u22121 \ufe37 \ufe38\ufe38 \ufe37 cx \u00b7 \u00b7 \u00b7 cx n\u2212Ti+1 \ufe37 \ufe38\ufe38 \ufe37 gx \u00b7 \u00b7 \u00b7 gx\nTi + 1 < j \u2264 n: Case (c) Case (c)\nTi\u22121 \ufe37 \ufe38\ufe38 \ufe37 cx \u00b7 \u00b7 \u00b7 cx n\u2212Ti+1 \ufe37 \ufe38\ufe38 \ufe37 gx \u00b7 \u00b7 \u00b7 gx\nNow, we prove Parts 2 and 3 of the lemma. Assume \u03a0 is an admissible plan with induced assignment \u03c3\u03a0 = \u03c3. The proof proceeds by a double induction on i and j. In particular, we prove the validity of the three statements of type Q2j\u22121i , Q 2j i , Q 2j+1 i , assuming that all statements of type Qti\u2032 (for any i \u2032 < i and any t) and that all statements of type Q2j \u2032\u22121 i , Q 2j\u2032 i and Q2j \u2032+1\ni (for any j \u2032 < j) already hold. We first prove the validity of Q2j\u22121i . For j = 1,\nQ2j\u22121i = Q 1 i = ax \u00b7 \u00b7 \u00b7 ax in Cases (a) and (b) corresponds to the initial state of vi1, . . . , vin (note that Case (c) cannot hold for j = 1). When j > 1 we know that, since the statements are consistent, Q2j\u22121i = Q 2j\u2032+1 i for j\n\u2032 = j \u2212 1, hence the correctness of Q2j\u22121i follows by induction on j.\nNext, we prove the statements relative to Q2ji and Q 2j+1 i . Consider the variable v \u2032 that precedes vi1 in the causal graph, and values number 2j \u2212 1, 2j, and 2j + 1 it takes on during the execution of \u03a0. If i = 1, then v\u2032 = vs and the values are x,mj , x. If i > 1, then v\u2032 = v(i\u22121)n and, by induction on i, the values are ax, amj , ax if j < Ti\u22121 and j < n; ax, bmj , cx if j = n < Ti\u22121; ax, gmj , gx if j = Ti\u22121; or gx, gmj , gx if j > Ti\u22121.\nThe proof is divided into 6 parts, depending on the values of j and Ti.\nI) 1 = j < Ti. Consider the following table, where we write m instead of mj = m1 to simplify the notation.\nv\u2032 vi1 vi2 \u00b7 \u00b7 \u00b7 vin 2j \u2212 1 {x, ax, gx} ax ax \u00b7 \u00b7 \u00b7 ax 2j {m, am, bm, gm} \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 2j + 1 {x, ax, cx, gx} \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7\nThe three rows of the table correspond to values number 2j \u2212 1, 2j, and 2j + 1 of variables v\u2032, vi1, . . . , vin. The first column corresponds to the possible values that the predecessor v\u2032 of vi1 can take on. The first row is given by Q 2j\u22121 i , while the second and third rows, to be filled, correspond to Q2ji and Q 2j+1 i .\nLet A2j be the operator causing the 2j-th value of vi1. According to the previous table, the pre-condition of A2j must be compatible with\n\u3008v\u2032 \u2208 {m1, am1 , bm1 , gm1}, vi1 = ax\u3009\nthat is, the values of variables v\u2032 and vi1 when A2j is applied. Since Ti > 1, \u03c3\u03a0(x1) = m1 does not satisfy clause Ci, so the operator A2j must be one of those labelled (2) and (4) in Table 3. (Only one of these operators is applicable, depending on the value of m1 and whether v\n\u2032 is vs or v(i\u22121)n.) In either case, the application of A2j causes the value of vi1 to become bm1 , so we can fill in a blank in the previous table.\nv\u2032 vi1 vi2 \u00b7 \u00b7 \u00b7 vin 2j \u2212 1 {x, ax, gx} ax ax \u00b7 \u00b7 \u00b7 ax 2j {m, am, bm, gm} bm(2, 4) \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 2j + 1 {x, ax, cx, gx} \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7\nIn the same way, we can check that A2j+1, the operator causing the (2j +1)-th value of vi1, must be one of those labelled (7) in Table 3; the new value of vi1 is cx. As for\nthe remaining variables, it is easy to check that variables vi2, . . . , vin become am1 , due to operators of type (14), and then become ax, due to operators of type (18). The table is now complete:\nv\u2032 vi1 vi2 \u00b7 \u00b7 \u00b7 vin 2j \u2212 1 {x, ax, gx} ax ax \u00b7 \u00b7 \u00b7 ax 2j {m, am, bm, gm} bm(2, 4) am \u00b7 \u00b7 \u00b7 am(14) 2j + 1 {x, ax, cx, gx} cx (7) ax \u00b7 \u00b7 \u00b7 ax (18)\nThis shows that Case (a) of Lemma 4.13 holds when j = 1 and Ti > 1.\nII) 1 = j = Ti. The proof is similar to that of Case (I). Since Ti = 1, \u03c3\u03a0(x1) = m1 satisfies clause Ci. As a result, the admissible operators for causing the 2j-th value of vi1 are now those labelled (1) and (3). In either case, the value of vi1 becomes gm1 . Consequently, the admissible operators for vi2, . . . , vin are different from before. This is the resulting table:\nv\u2032 vi1 vi2 \u00b7 \u00b7 \u00b7 vin 2j \u2212 1 {x, ax, gx} ax ax \u00b7 \u00b7 \u00b7 ax 2j {m, am, bm, gm} gm(1, 3) gm \u00b7 \u00b7 \u00b7 gm(15) 2j + 1 {x, ax, cx, gx} gx (9) gx \u00b7 \u00b7 \u00b7 gx (21)\nIII) 1 < j < Ti. In this case, as in the remaining ones, we just show the resulting table. We always write m = mj . In what follows, we omit the column for v\n\u2032 since its possible values are always the same.\nvi1 vi2 \u00b7 \u00b7 \u00b7 vi(j\u22121) vij vi(j+1) \u00b7 \u00b7 \u00b7 vin 2j \u2212 1 cx cx \u00b7 \u00b7 \u00b7 cx ax ax \u00b7 \u00b7 \u00b7 ax 2j cm(5) cm \u00b7 \u00b7 \u00b7 cm (16) bm(11, 13) am \u00b7 \u00b7 \u00b7 am (14) 2j + 1 cx (8) cx \u00b7 \u00b7 \u00b7 cx (20) cx (19) ax \u00b7 \u00b7 \u00b7 ax (18)\nIV) 1 < j = Ti.\nvi1 vi2 \u00b7 \u00b7 \u00b7 vi(j\u22121) vij vi(j+1) \u00b7 \u00b7 \u00b7 vin 2j \u2212 1 cx cx \u00b7 \u00b7 \u00b7 cx ax ax \u00b7 \u00b7 \u00b7 ax 2j cm(5) cm \u00b7 \u00b7 \u00b7 cm (16) gm(10, 12) gm \u00b7 \u00b7 \u00b7 gm (15) 2j + 1 cx (8) cx \u00b7 \u00b7 \u00b7 cx (20) gx (21) gx \u00b7 \u00b7 \u00b7 gx (21)\nV) 1 = Ti < j. vi1 vi2 \u00b7 \u00b7 \u00b7 vin\n2j \u2212 1 gx gx \u00b7 \u00b7 \u00b7 gx 2j gm(6) gm \u00b7 \u00b7 \u00b7 gm(17) 2j + 1 gx (9) gx \u00b7 \u00b7 \u00b7 gx (21)\nVI) 1 < Ti < j. vi1 vi2 \u00b7 \u00b7 \u00b7 vi(Ti\u22121) viTi \u00b7 \u00b7 \u00b7 vin\n2j \u2212 1 cx cx \u00b7 \u00b7 \u00b7 cx gx \u00b7 \u00b7 \u00b7 gx 2j cm(5) cm \u00b7 \u00b7 \u00b7 cm (16) gm \u00b7 \u00b7 \u00b7 gm (17) 2j + 1 cx (8) cx \u00b7 \u00b7 \u00b7 cx (20) gx \u00b7 \u00b7 \u00b7 gx (21)\nIt just remains to check that Case (a) of Lemma 4.13 follows from parts (I) and (III), Case (b) from parts (II) and (IV), and Case (c) from parts (V) and (VI). This proves Part 2 and 3 of the lemma.\nFinally, note that the existence of an admissible plan \u03a0 directly follows from the previous discussion, since we have always specified which operators should be used in every situation, and not just assumed their existence. This proves Part 1 of the lemma.\nTheorem 4.14. There exists a plan that solves the planning problem P11(F ) if and only if there exists an assignment \u03c3 that satisfies the CNF formula F .\nProof. \u21d0: Given an assignment \u03c3 that satisfies F , construct an admissible plan \u03a0 whose induced formula assignment \u03c3\u03a0 equals \u03c3, by choosing the sequence of values of vs accordingly. It follows that Ti \u2264 n for each clause Ci, since there exists a variable xj such that \u03c3\u03a0(xj) = mj satisfies Ci. Then, Q 2n+1 i has the form indicated in Case (b) or (c) of Lemma 4.13. In either case, the (2n+1)-th value of variable vin is gx, as required by the goal state. The plan \u03a0 thus solves P11(F ).\n\u21d2: Let \u03a0 be a plan that solves the planning problem P11(F ). By Lemma 4.8 the plan \u03a0 is admissible. We show by contradiction that \u03c3 = \u03c3\u03a0 satisfies F . Assume not. Then there exists a clause Ci not satisfied by \u03c3, implying Ti = n + 1. Since n < Ti, the (2n + 1)-th value of variable vin is cx according to Case (a) of Lemma 4.13. This contradicts \u03a0 solving P11(F ), since the goal value of vin is not cx but gx.\nProposition 4.15. Plan existence for C11n is NP-hard.\nProof. The largest variable domains of the planning problem P11(F ) are those of variables v11, . . . , vkn, which contain 11 values. The proof follows immediately from the well-known NP-hardness of Cnf-Sat, Theorem 4.14, and the fact that we can produce the planning problem P11(F ) in polynomial time given the CNF formula F ."}, {"heading": "4.3 Example", "text": "We illustrate the reduction using a small example CNF formula F = (x1 \u2228 x2) on one clause and two variables x1 and x2. The variable set of the corresponding planning problem P11(F ) is V = {s1, s2, s3, vs, v11, v12, ve, e1, e2, e3}. An admissible plan \u03a0 can induce any of four different messages (0, 0), (0, 1), (1, 0), and (1, 1). Only the message (0, 0) corresponds to an assignment that does not satisfy F . A plan \u03a0 that solves P11(F ) with induced message (0, 1) appears in Table 5. Note that, following execution of the plan, the goal state goal = (v12 = gx, ve = 0, e1 = 1, e2 = 0, e3 = 1) is satisfied as desired; the last value change of each variable appearing in the goal state is marked using boldface.\n5. C5n Is NP-hard\nIn this section, we describe a reduction from Cnf-Sat to C5n. To each CNF formula F we associate a planning problem P5(F ). For each clause Ci and variable xj of F , P5(F ) contains two state variables v1ij , with domain D(v 1 ij) = {ax, a0, a1, bx}, and v 2 ij , with domain D(v 2 ij) = {ax, a0, a1, b0, b1}. The values a0 and a1 are omitted for v 2 in, so D(v 2 in) = {ax, b0, b1}. The\nstate variables s1, . . . , s2n\u22121, vs, ve, e1, . . . , e2n\u22121, as well as their domains and corresponding operators, are the same as before, except the predecessor of ve is now v 2 kn.\nThe initial state on the new state variables is init(v1ij) = init(v 2 ij) = ax, i \u2208 [1 . .k] and j \u2208 [1 . .n], and the goal state is goal(v1i1) = ax, i \u2208 [1 . .k]. Table 6 lists the operators for variables v1ij and v 2 ij , i \u2208 [1 . .k] and j \u2208 [1 . .n], and Figure 6 shows the corresponding DTGs. Table 6 also lists the new operators for variable ve, which have different pre-conditions now that the predecessor of ve is v 2 kn."}, {"heading": "5.1 Intuition", "text": "The reduction for C5n is based on the following idea: instead of using an explicit value to remember that a clause has been satisfied, the goal is to remain in the initial value ax. This way we were able to reduce the size of the variable domains needed for the reduction. Somewhat surprisingly, the new reduction uses fewer total operators than that for C11n .\nOur reduction for C5n also uses another new idea. In the reduction for C 11 n , information was propagated forward, i.e., variable vij changed its value according to the value of its predecessor vi(j\u22121). The reduction for C 5 n, however, is constructed such that some information is propagated forward (in particular, the bits of the message) but other information is propagated backwards (the index of the bit we are currently checking). The planning problem is arranged such that a variable v may have several applicable operators, but only one of them satisfies the pre-condition of an applicable action for its successor v\u2032. The result is that the value of v at time t+ 1 depends on the value of v\u2032 at time t.\nWe explain the planning problem P5(F ) in a bit more detail. Due to the backward propagation mechanism, the bits of the message are checked in reverse order. In other words, vin now checks the first bit, vi(n\u22121) checks the second bit, and vi1 checks the n-th bit. The purpose of v2ij is to check whether the (n \u2212 j + 1)-th bit satisfies the clause Ci, whereas the purpose of v1ij is to inform v 2 i(j\u22121) that the (n \u2212 j + 2)-th bit has arrived. Implicitly, v1ij also keeps track of whether Ci has been satisfied after the first (n \u2212 j + 1) bits.\nAssume without loss of generality that the message is 0 \u00b7 \u00b7 \u00b7 0. Let us see what happens if the corresponding assignment does not satisfy the clause Ci. Upon arrival of the first bit, state variable v2in has to move to b0. This requires v 1 in = a0 as a pre-condition, which in turn requires state variables vlij , j \u2208 [1 . .n \u2212 1] and l \u2208 {1, 2}, to be in a0. Next, v 2 in has to move back to ax, which requires the pre-condition v 1 in = bx. In turn, this requires state variables vlij , j \u2208 [1 . .n\u2212 1] and l \u2208 {1, 2}, to be in ax. When v 1 in moves again it is from bx to a0, requiring v 2 i(n\u22121) = b0 as a pre-condition.\nWe see that, as long as the clause remains unsatisfied, v1ij is in bx following the (n\u2212j+1)th bit. In particular, this means v1i1 is in bx following the last bit. Assume now that the (n \u2212 j + 1)-th bit satisfies clause Ci. When v 2 ij moves from b0 to ax, this requires v 1 ij to move to ax instead of bx. From there, there is no way for v 1 i(j\u22121) to be in bx following the (n\u2212 j + 2)-th bit. In particular, v1i1 will be in ax following the last bit, satisfying the goal state."}, {"heading": "5.2 Formal Proof", "text": "The proof for C5n is organized much in the same way as that for C 11 n . Note that variables s1, . . . , s2n\u22121, vs, ve, e1, . . . , e2n\u22121 are the same as before, so Lemmas 4.2 and 4.6 still apply to P5(F ). It is easy to check that Lemmas 4.3, 4.5 and 4.8 also hold for P5(F ). However, Lemma 4.4 no longer holds, since several operators share the same preconditions, namely operators (2) and (3), (5) and (6), (8) and (10), and (11) and (13). In spite of this, the operators and sequences of values of an admissible plan \u03a0 are completely determined by its induced message m\u03a0, just as for P11(F ) (as shown in Lemma 4.10):\nLemma 5.1. Let \u03a0 be an admissible plan for P5(F ) and let m\u03a0 be its induced message. The operators in \u03a0 for changing the value of variable vlij, i \u2208 [1 . .k], j \u2208 [1 . .n], and l \u2208 {1, 2}, as well as the sequence of values that variable vlij takes on during the execution of \u03a0, are completely determined by m\u03a0.\nProof. First consider variable v111, and assume without loss of generality that its value is a0. Given (vs = x), there are two applicable operators for v 1 11, namely (2), changing its value to\nax, and (3), changing its value to bx. At first sight, an admissible plan \u03a0 can choose either. However, for \u03a0 to be admissible, it has to change the value of v211 in between each pair of value changes for v111. Note that when v 1 11 = a0, v 2 11 can have either of two values, namely a0 or b0. If the value of v 2 11 is a0, the only admissible operator for v 2 11 is (12), which has pre-condition v111 = ax. Thus, if \u03a0 changes the value of v 1 11 to bx it is no longer admissible, so it has to choose operator (2). If the value of v211 is b0, the correct choice depends on the CNF formula F . If xn satisfies clause C1, the only admissible operator for v 2 11 is (16) with pre-condition v111 = ax, so \u03a0 should choose operator (2). Otherwise, the only admissible operator for v211 is (17) with pre-condition is v 1 11 = bx, so \u03a0 should choose operator (3). In either case, the operator choice for v111 is forced given the value of v 2 11.\nThe same reasoning applies to variables v1i1, i \u2208 [2 . .k], v 1 ij , i \u2208 [1 . .k] and j \u2208 [2 . .k], and v2ij , i \u2208 [1 . .k] and j \u2208 [1 . .n\u2212 1], and the corresponding operators that share the same pre-conditions. The only degree of freedom of an admissible plan is selecting its induced message m\u03a0 by choosing the operators for vs accordingly. The remaining operator choices and, consequently, sequences of values are completely determined by the induced message m\u03a0.\nWe now prove a lemma similar to Lemma 4.13, establishing the sequence of values taken on by state variables in P5(F ) during the execution of an admissible plan.\nDefinition 5.2. Let \u03a0 be an admissible plan for P5(F ). For each clause Ci and each t \u2208 [1 . .2n+ 1], let the sequence of values Qti(\u03a0) be the vector of 2n elements representing, for each variable vlij , j \u2208 [1 . .n] and l \u2208 {1, 2}, the t-th value taken on by variable v l ij during the execution of \u03a0. Let us denote this value by Qt(\u03a0)[vlij ]. We define the diagonal value qij(\u03a0), for i \u2208 [1 . .k] and j \u2208 [1 . .n], as the value Q 2j+1(\u03a0)[v1 i(n\u2212j+1)].\nLemma 5.3. Let \u03c3 be an assignment to variables x1, . . . , xn of formula F .\n1) Existence. There exists an admissible plan \u03a0 of planning problem P5(F ) with induced assignment \u03c3\u03a0 = \u03c3.\n2) Claim. Let qij be as described in Part 3) of this lemma. All admissible plans \u03a0 with\n\u03c3\u03a0 = \u03c3 have the same diagonal values q i j(\u03a0) = q i j for each i \u2208 [1 . .k] and j \u2208 [1 . .n].\n3) Diagonal values. The diagonal values qij, for i \u2208 [1 . .k] and j \u2208 [1 . .n], are as follows.\na) If j < Ti, then q i j = bx.\nb) If j \u2265 Ti, then q i j = ax.\nProof. Note that, according to Lemma 5.1, not only the diagonal values qij(\u03a0), but also the full sequences of values Qti(\u03a0), are completely determined for an admissible plan \u03a0. We have to prove, then, that admissible plans exist for any assignment \u03c3, as claimed in Part 1, and that the diagonal values match the expression given in Part 3. We prove these two facts by doing a careful, general analysis of the planning problem P5(F ), and then explaining how this analysis implies the lemma. Incidentally, the sequences of values Qti(\u03a0) can also\nbe obtained from our analysis; we do not study them because they are not important for our purposes.\nLet \u03a0 be an admissible plan, and let v = vlij be some variable of P5(F ). Clearly, the subscript of the t-th value Qt(\u03a0)[v] that v takes on depends on the parity of t, since all operators affecting v change its subscript from x to m = {0, 1} and from there back to x. Namely, the subscript of Qt(\u03a0)[v] is x if t = 2p \u2212 1, and m if t = 2p, where m is the p-th bit of the message m\u03a0.\nNow, for some j \u2208 [2 . .n\u2212 1] and i \u2208 [1 . .k], consider the t-th values that variables v1ij , v2ij , v 1 i(j+1) take on, for t = 2p \u2212 1, 2p, 2p + 1. The previous observation on the subscripts implies that we (trivially) know something about these values.\nQt(\u03a0)[v1ij ] Q t(\u03a0)[v2ij ] Q t(\u03a0)[v1 i(j+1)]\nt = 2p\u2212 1 {ax, bx} ax {ax, bx} t = 2p am {am, bm} am t = 2p+ 1 {ax, bx} ax {ax, bx}\nWe study how the value Q2p\u22121(\u03a0)[v1 i(j+1)] affects the other values on the diagonal,\nnamely Q2p(\u03a0)[v2ij ] and Q 2p+1(\u03a0)[v1ij ]. If Q 2p\u22121(\u03a0)[v1 i(j+1)] = ax, then we can check there is only one possible outcome.\nRule I Qt(\u03a0)[v1ij ] Q t(\u03a0)[v2ij ] Q t(\u03a0)[v1 i(j+1)]\nt = 2p\u2212 1 {ax, bx} ax ax t = 2p am am (11) am (7) t = 2p+ 1 ax (8) ax (12) {ax, bx}\nThat is, a value of type ax is propagated along the diagonal to another value ax. We call this Propagation Rule I.\nNow we study which are the possible outcomes when Q2p\u22121(\u03a0)[v1 i(j+1)] = bx. In this case, the other values Q2p(\u03a0)[v2ij ] and Q 2p+1(\u03a0)[v1ij ] on the diagonal depend on whether the p-th bit m of the message m\u03a0 is such that clause Ci is satisfied by xn\u2212j+1 = m (c.f. operators (14)\u2013(17) and (18)\u2013(22) in Table 6). If Ci is satisfied by xn\u2212j+1 = m, it follows that these values must be bm and ax. This is Propagation Rule II.\nRule II Qt(\u03a0)[v1ij ] Q t(\u03a0)[v2ij ] Q t(\u03a0)[v1 i(j+1)]\nt = 2p\u2212 1 {ax, bx} ax bx t = 2p am bm (13) am (9) t = 2p+ 1 ax (8) ax (14, 16) {ax, bx}\nOn the contrary, if clause Ci is not satisfied, then these values must be bm and bx. We call this Propagation Rule III.\nRule III Qt(\u03a0)[v1ij ] Q t(\u03a0)[v2ij ] Q t(\u03a0)[v1 i(j+1)]\nt = 2p\u2212 1 {ax, bx} ax bx t = 2p am bm (13) am (9) t = 2p+ 1 bx (10) ax (15, 17) {ax, bx}\nFinally, let us consider the cases j = 1 and j = n, which have not been treated in the previous analysis. Note that variables v2in do not have values of type am. Also note that variables v1i1 cannot take on value bx at time t < 2n+ 1, for then it cannot change further, since the pre-conditions of operators (1)\u2013(3), if i = 1, or (4)\u2013(6), if i \u2208 [2 . .k], are not compatible with v1i1 = bx. Thus, the only possible outcome for these two variables when p < n is the following.\nQt(\u03a0)[v1in] Q t(\u03a0)[v2in] Q t(\u03a0)[v1(i+1)1]\nt = 2p\u2212 1 {ax, bx} ax ax t = 2p am bm (18) am (4) t = 2p+ 1 {ax, bx} (8; 10) ax (19, 21; 20, 22) ax (5)\nNote that, when p = n, the value Q2p+1(\u03a0)[v1(i+1)1] can be either ax or bx, using operators (5) and (6). The reader can check that a similar analysis applies to variable v111, where operators (1)\u2013(3) take the role of operators (4)\u2013(6).\nLet us summarize the previous analysis in the following table.\nv1i1 v 2 i1 v 1 i2 \u00b7 \u00b7 \u00b7 v 1 i(n\u22121) v 2 i(n\u22121) v 1 in v 2 in\nt = 1 ax ax ax \u00b7 \u00b7 \u00b7 ax ax ax ax t = 2 am bm t = 3 ax ax t = 4 am bm ... ... ...\nt = 2n\u2212 2 am bm t = 2n\u2212 1 ax ax t = 2n am bm t = 2n+ 1 \u2217 \u2217 \u00b7 \u00b7 \u00b7 \u2217 \u2217 ax\nThe first row in the previous table contains the initial state of the planning problem: all variables are set to ax. The leftmost column and the rightmost column contain the values taken on by variables v1i1 and v 2 in. Then, the values bm of the right column are propagated along the diagonals using the three propagation rules already discussed: a value of type a yields more values of type a according to Rule I; a value of type b yields a value of type a if the clause is satisfied by Rule II, and of type b if it is not satisfied, by Rule III. The same applies when propagating the values of the first row: since they are all of type a, all values of the top-left triangle are of type a, according to Rule I. Note also that the longest diagonal coincides with the diagonal values qij of Definition 5.2.\nAfter this discussion we proceed to prove the lemma. Let \u03c3 be an assignment of formula F . The existence of a plan \u03a0 with \u03c3\u03a0 = \u03c3 is implied from the analysis already done on the values Qt[vlij ], since we have shown which operators can be used in each case to produce the actual changes of value.\nFinally, consider the diagonal values qij(\u03a0) for j = 1, . . . , n, that is, the valuesQ 3(\u03a0)[v1in],\nQ5(\u03a0)[v1 i(n\u22121)], . . ., Q 2n+1(\u03a0)[v1i1]. Let j < Ti as in Case (a), that is, the first j bits of the message m\u03a0, when assigned to variables x1, . . . , xj , do not satisfy clause Ci. Consequently, the diagonal values qi1 = Q 3(\u03a0)[v1in], q i 2 = Q 5(\u03a0)[v1 i(n\u22121)], . . ., q i j = Q 2j+1(\u03a0)[v1 i(n+1\u2212j)] must\nall be bx, according to Rule III. On the contrary, if we assume j \u2265 Ti as in Case (b), then it follows that qip = bx for p < Ti due to Rule III, that q i p = ax for p = Ti due to Rule II, and that qip = ax for j \u2265 p > Ti due to Rule I.\nTheorem 5.4. There exists a valid plan for solving the planning problem P5(F ) if and only if there exists an assignment \u03c3 that satisfies the CNF formula F .\nProof. \u21d0: By Lemma 5.3, the existence of an assignment \u03c3 that satisfies F implies that all admissible plans \u03a0 with \u03c3\u03a0 = \u03c3 satisfy q i j(\u03a0) = q i j . Since Ti \u2264 n for all i \u2208 [1 . .k], it follows that qin = ax, as required by the goal state of P5(F ). The plan \u03a0 thus solves P5(F ). \u21d2: Let \u03a0 be a plan solving the planning problem P5(F ). Since Lemma 4.8 holds for P5(F ), the plan \u03a0 is admissible. We show by contradiction that \u03c3 = \u03c3\u03a0 satisfies F . Assume not. Then there exists a clause Ci not satisfied by \u03c3. Thus, Lemma 5.3 implies that qij(\u03a0) = bx for all j \u2208 [1 . .n]. In particular, the value of v 1 i1 following the execution of \u03a0 is bx. This contradicts \u03a0 solving P5(F ), since bx is different from the goal state goal(v 1 i1) = ax.\nProposition 5.5. Plan existence for C5n is NP-hard.\nProof. The largest variable domains of the planning problem P5(F ) are those of variables v2ij , i \u2208 [1 . .k] and j \u2208 [1 . .n \u2212 1], which contain 5 values. The proof follows immediately from the NP-hardness of Cnf-Sat, Theorem 5.4, and the fact that we can produce the planning problem P5(F ) in polynomial time given the CNF formula F ."}, {"heading": "6. Discussion", "text": "In this paper, we have shown that the problem of determining whether a solution plan exists for planning problems in the class Ckn is NP-hard whenever k \u2265 5. In contrast, Brafman and Domshlak (2003) developed a polynomial-time algorithm for generating plans that solve planning problems in the class C2n. What can be said about the intermediate cases, namely C\nk n for k \u2208 {3, 4}? In what follows, we sketch some arguments for and against tractability of these cases. Although the discussion is mostly based on intuition gained from studying these classes, it might prove helpful for someone trying to determine their complexity.\nOn one hand, it seems likely to us that plan existence for C4n is also NP-hard. Our reduction for C5n only uses one type of state variable whose domain is larger than 4, namely v2ij . Finding a reduction for C 4 n seems possible, although it will likely be difficult since the available options become increasingly restricted as the state variable domains get smaller. In particular, we tried but failed to find a reduction for C4n.\nDomshlak and Dinitz (2001) showed that there exist planning problems in C3n with exponential length minimal solutions. Although this often indicates that a planning class is difficult, it does not imply that plan existence is intractable. This is exemplified by Jonsson and Ba\u0308ckstro\u0308m (1998) who define a class of planning problems with exponential length minimal solutions but where plan existence could be checked in polynomial time. The present authors (Gime\u0301nez & Jonsson, 2008a) showed that even plan generation for this particular class could be done in polynomial time, if the resulting plans are given in a compact format such as macros.\nA second argument in favor of the hardness of C3n is that there may be multiple ways to transition between two values of a variable. For example, consider a planning problem\nsuch that there are two actions for changing the value of a variable v from 0 to 1, namely a = \u3008v\u2032 = 0, v = 0; v = 1\u3009 and a\u2032 = \u3008v\u2032 = 1, v = 0; v = 1\u3009. Since variables can have 3 values, it is possible that neither v\u2032 = 0 nor v\u2032 = 1 hold in the current state. A planner would thus have to choose whether to satisfy v\u2032 = 0 or v\u2032 = 1. In contrast, for C2n the same two actions could be replaced by a single action \u3008v = 0; v = 1\u3009 since one of a and a\u2032 is always applicable. As a consequence, even if the minimal plan length is bounded for a planning problem in C3n, there may be exponentially many plans of that length (in fact, this is the main idea behind our reductions).\nAnother observation regards the number of possible domain transition graphs for each state variable. For each k \u2265 2, it is possible to show that a state variable in Ckn may have 2k\n2(k\u22121) distinct domain transition graphs. In other words, the number of graphs grows exponentially in k. In particular, while state variables in C2n can only have 2\n4 = 16 distinct graphs, the same number for C3n is 2\n18. Although a large number of possibilities does not guarantee hardness, it is clear that the expressive power of C3n is much higher than that of C 2 n.\nThe evidence provided above suggests that C3n is significantly harder than C 2 n. However, we are not sure that C3n is hard enough to be intractable. State variables with just three values do not lend themselves well to the type of reduction we have presented, since just propagating the message requires three values. If there is such a reduction for C3n, the idea underlying it may not be the message-passing mechanism we have exploited. On the other hand, maybe there is some way to determine plan existence of C3n in polynomial time. Such an algorithm would take into consideration the multiple (but finite) combinations of domain transition graphs of three values, as well as any inherent structure of the graphs. We know that the expressive power of domain transition graphs of 5 values is just too large to handle in polynomial time; maybe this is not the case when using just 3 values."}, {"heading": "Acknowledgments", "text": "This work was partially funded by APIDIS and MEC grant TIN2006-15387-C03-03.\nAppendix A. C7n Is NP-hard\nIn this appendix, we describe how to modify the reduction for C11n so that the resulting planning problem, which we call P7(F ), only needs variable domains of size 7. This reduction previously appeared in a conference paper (Gime\u0301nez & Jonsson, 2008b), but without proof. The main idea of the reduction is the same, but the construction used to check if the assignment \u03c3\u03a0 satisfies a clause Ci is more involved. Previously, we used n variables {vij}j\u2208[1 . .n] whose role was, essentially, to check whether the j-th bit \u03c3\u03a0(xj) of the propagated message satisfies Ci. In the modified reduction, each variable vij is replaced by three variables v1ij , v 2 ij , and v 3 ij , that collectively play the same role. The variables s1, . . . , s2n\u22121, vs, ve, e1, . . . , e2n\u22121, as well as their domains and corresponding operators, are the same as before, except the predecessor of ve is now v 3 kn.\nThe domains of these new variables are D(v1ij) = D(v 3 ij) = {ax, a0, a1, bx, b0, b1, gx} and D(v2ij) = {gx, g0, g1, ax, a0, a1, bx} for each i \u2208 [1 . .k], j \u2208 [1 . .n]. The initial state on these variables is init(v1ij) = init(v 2 ij) = init(v 3 ij) = ax, i \u2208 [1 . .k] and j \u2208 [1 . .n], and the goal\nstate is goal(v2in) = gx, i \u2208 [1 . .k]. Table 7 shows the operators for variables v 1 ij , i \u2208 [1 . .k] and j \u2208 [1 . .n], and Table 8 shows the operators for variables v2ij and v 3 ij , i \u2208 [1 . .k] and j \u2208 [1 . .n]. Figures 7 and 8 shows the corresponding domain transition graphs. Table 8 also shows the new operators for variable ve, which have different pre-conditions now that the predecessor of ve is v 3 kn.\nA.1 Intuition\nThe intuition behind the reduction for C7n is largely the same as that for C 11 n . The planning problem P7(F ) corresponding to a CNF formula F consists of three parts, the first and third being identical to those of P11(F ). Thus, the difference lies in the second part. Recall that in the reduction for C11n , for each clause Ci and each variable xj of F , the planning problem P11(F ) contains a state variable vij that performs the following functions:\n1. Propagate the message m generated by vs.\n2. Check whether the assignment to xj (the j-th bit of m) satisfies the clause Ci.\n3. Remember whether Ci was satisfied by the assignment to some xl, l \u2264 j.\n4. If j < n and Ci has been satisfied, propagate this fact.\n5. If j < n, let vi(j+1) know when the (j + 1)-th bit of the message has arrived.\nThe first and fourth function is to propagate information and thus has to be performed by all state variables if information is not to be lost. However, the other functions can be performed by different state variables. The idea behind the reduction for C7n is to split vij into three variables: v1ij , that performs the second function, v 2 ij , that performs the third, and v3ij , that performs the fifth.\nJust as before, the messagem is propagated using the subscripts of values in the domains of state variables. When the j-th bit mj of the message arrives, state variable v 1 ij moves from ax to gx if the assignment \u03c3(xj) = mj satisfies Ci, and to bmj otherwise. If v 1 ij moves to gx, it is forced to move to bmj next, forgetting that Ci was satisfied. However, while the value of v1ij is gx, all subsequent state variables for Ci can also move to gx, propagating the fact that Ci has been satisfied. Consequently, state variable v 2 in is able to remember that Ci has been satisfied by remaining within the subdomain {g0, g1, gx}. If \u03c3(xj) = mj does not satisfy Ci, v 1 ij moves to bmj , causing v 2 ij and v 3 ij to move to amj . From there, v1ij , v 2 ij , and v 3 ij all move to bx. When the next bit arrives, v 1 ij moves to b0 (b1), causing v2ij to move to a0 (a1) and v 3 ij to b0 (b1). This indicates to v 1 i(j+1) that the (j+1)-th bit has arrived, causing it to act accordingly. Just as before, the operators are defined such that v1i1 always reacts to the first bit for each clause Ci.\nA.2 Formal Proof\nSince variables s1, . . . , s2n\u22121, vs, ve, e1, . . . , e2n\u22121 are the same as before, Lemmas 4.2 and 4.6 both apply to P7(F ). However, Lemma 4.3 is violated since it is sometimes possible to change the value of a variable twice without changing the value of its predecessor (e.g. using operators (1) and (5)). Consequently, Lemma 4.8, which states that all plans that solve P11(F ) are admissible, no longer holds for P7(F ).\nTo prove equivalent lemmas for P7(F ), we redefine \u03a0(v l ij) for variables in the middle of\nthe causal graph:\nDefinition A.1. Given a partial plan \u03a0 and variable vlij , i \u2208 [1 . .k], j \u2208 [1 . .n], and l \u2208 {1, 2, 3}, let \u03a0(vlij) be the number of subscript changes of v l ij during the execution of \u03a0.\nLemma A.2. For each partial plan \u03a0 for P7(F ) and each v l ij, i \u2208 [1 . .k], j \u2208 [1 . .n], and l \u2208 {1, 2, 3}, it holds that \u03a0(vlij) \u2264 \u03a0(v \u2032), where v\u2032 is the predecessor of vlij in the causal graph.\nProof. Follows immediately from inspection of the operators for vlij . Each operator that changes the subscript of vlij to z \u2208 {0, 1, x} has a pre-condition on v \u2032 with subscript z (or value z in the case of v111 and its predecessor vs). There are operators for changing the value of v1ij to gx that have a pre-condition on v \u2032 with a subscript (or value) different from x, but these operators do not change the subscript of v1ij since their pre-condition on v 1 ij is ax.\nLemma A.3. For each partial plan \u03a0 for P7(F ), \u03a0(ve) \u2264 \u03a0(v 3 kn).\nProof. Note that \u03a0(ve) still denotes the number of value changes of ve, while \u03a0(v 3 kn) denotes the number of subscript changes of v3kn. Each time we change the value of ve we need to change the subscript of v3kn in between. In addition, the first value change of ve requires a subscript for v3kn different from that in the initial state. Thus, \u03a0(ve) \u2264 \u03a0(v 3 kn).\nDefinition A.4. An admissible plan \u03a0 for planning problem P7(F ) is a partial plan such that \u03a0(si) = i, \u03a0(vs) = \u03a0(v 1 11) = . . . = \u03a0(v 3 kn) = \u03a0(ve) = 2n, and \u03a0(ei) = 2n\u2212 i, for each i \u2208 [1 . .2n\u2212 1].\nLemma A.5. Any plan \u03a0 that solves the planning problem P7(F ) is admissible.\nProof. By Lemmas A.2 and A.3 we have that \u03a0(vs) \u2265 \u03a0(v 1 11) \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03a0(v 3 kn) \u2265 \u03a0(ve). We can now use Lemmas 4.2 and 4.6 and apply the same reasoning as in the proof of Lemma 4.8.\nIn other words, an admissible plan has to change the subscript of each vlij exactly 2n times, although it can change the value of vlij an extra time by moving through gx. However, even with the new definition of \u03a0(vlij), we cannot prove an equivalent of Lemma 4.10 for P7(F ), since a variable v l ij , l \u2208 {1, 2}, can choose not to follow its predecessor to gx without making the plan inadmissible. Consequently, the sequences of values Qti(\u03a0) of an admissible plan \u03a0 are no longer completely determined by the induced message m\u03a0. Nevertheless, we can still prove a lemma similar to Lemma 4.13.\nDefinition A.6. Let \u03a0 be an admissible plan. For each clause Ci and each t \u2208 [1 . .2n+1], let the sequence of values Qti(\u03a0) be the vector of 3n elements representing, for each variable vlij , j \u2208 [1 . .n] and l \u2208 {1, 2, 3}, the first value following the (t \u2212 1)-th subscript change of vlij during the execution of \u03a0.\nLemma A.7. Let \u03c3 be an assignment of variables x1, . . . , xn of formula F .\n1) Existence. There exists an admissible plan \u03a0 of planning problem P7(F ) with induced assignment \u03c3\u03a0 = \u03c3.\n2) Claim. Let Qti be the sequences of values described in Part 3) of this lemma. If \u03c3 satisfies F , then there exists an admissible plan \u03a0 with \u03c3\u03a0 = \u03c3 such that Q t i(\u03a0) = Q t i,\nfor all t \u2208 [1 . .2n+1] and i \u2208 [1 . .k]. If \u03c3 does not satisfy clause Ci, then all admissible plans \u03a0 with \u03c3\u03a0 = \u03c3 have Q t i(\u03a0) = Q t i, for all t \u2208 [1 . .2k + 1].\n3) Sequence of values. The sequence of values Qti, for i \u2208 [1 . .k] and t \u2208 [1 . .2n+ 1], is as follows.\na) If j < Ti, then\nQ2j\u22121i =\nj\u22121 \ufe37 \ufe38\ufe38 \ufe37 bxbxbx \u00b7 \u00b7 \u00b7 bxbxbx axaxax\nn\u2212j \ufe37 \ufe38\ufe38 \ufe37\naxaxax \u00b7 \u00b7 \u00b7 axaxax Q2ji = bmambm \u00b7 \u00b7 \u00b7 bmambm bmamam amamam \u00b7 \u00b7 \u00b7 amamam\nQ2j+1i = bxbxbx \u00b7 \u00b7 \u00b7 bxbxbx bxbxbx axaxax \u00b7 \u00b7 \u00b7 axaxax\nb) If j = Ti, then\nQ2j\u22121i =\nj\u22121 \ufe37 \ufe38\ufe38 \ufe37 bxbxbx \u00b7 \u00b7 \u00b7 bxbxbx axaxax\nn\u2212j \ufe37 \ufe38\ufe38 \ufe37\naxaxax \u00b7 \u00b7 \u00b7 axaxax Q2ji = bmambm \u00b7 \u00b7 \u00b7 bmambm bmgmbm bmgmbm \u00b7 \u00b7 \u00b7 bmgmbm\nQ2j+1i = bxbxbx \u00b7 \u00b7 \u00b7 bxbxbx bxgxbx bxgxbx \u00b7 \u00b7 \u00b7 bxgxbx\nc) If j > Ti, then\nQ2j\u22121i =\nTi\u22121 \ufe37 \ufe38\ufe38 \ufe37 bxbxbx \u00b7 \u00b7 \u00b7 bxbxbx\nj\u2212Ti \ufe37 \ufe38\ufe38 \ufe37 bxgxbx \u00b7 \u00b7 \u00b7 bxgxbx bxgxbx\nn\u2212j \ufe37 \ufe38\ufe38 \ufe37\nbxgxbx \u00b7 \u00b7 \u00b7 bxgxbx Q2ji = bmambm \u00b7 \u00b7 \u00b7 bmambm bmgmbm \u00b7 \u00b7 \u00b7 bmgmbm bmgmbm bmgmbm \u00b7 \u00b7 \u00b7 bmgmbm\nQ2j+1i = bxbxbx \u00b7 \u00b7 \u00b7 bxbxbx bxgxbx \u00b7 \u00b7 \u00b7 bxgxbx bxgxbx bxgxbx \u00b7 \u00b7 \u00b7 bxgxbx\nProof. Note the similarity of this lemma with Lemma 4.13. As before, we must show that there are operators, this time in Tables 7 and 8, whose post-conditions equal the values given by Q2j\u22121i , Q 2j i and Q 2j+1 i . Again, we must check for consistency in the statements of Q2j\u22121i and Q 2j\u2032+1 i with j \u2032 = j \u2212 1. This implies, as in Lemma 4.13, that the statements for Q2j\u22121i are valid, due to the initial state being ax \u00b7 \u00b7 \u00b7 ax and by induction on j. It just remains to show that the statements for Q2ji and Q 2j+1 i are also valid.\nThe proof is divided into the same six parts as that of Lemma 4.13. Note that, in contrast to that lemma, here we aim to show that, when \u03c3 satisfies F , there exists an admissible plan with given Qti, not that all admissible plans have this form. This is because sometimes during the execution of the plan more than one operator could have been chosen, and the resulting plan would still be admissible. In the tables that follow, which are alike to those in the proof of Lemma 4.13, we only indicate the operator choice that leads to the desired Qti, and we use boldface to remark that these operators are not \u201cforced\u201d. We add an extra row to the tables to indicate that sometimes we need to apply two operators for each variable before changing its subscript. These disparities with respect to Lemma 4.13 only occur in parts II and IV of the proof, which require Ti \u2264 n, that is, \u03c3 satisfying clause Ci, for some fixed i. Thus, when \u03c3 does not satisfy clause Ci, all admissible plans \u03a0 have the same sequences of values Qti for each t \u2208 [1 . .2n+ 1].\nI) 1 = j < Ti. v1i1v 2 i1v 3 i1 v 1 ikv 2 ikv 3 ik |k \u2208 [2 . .n]\n2j \u2212 1 axaxax axaxax 2j bmamam(2, 4; 18; 25) amamam (13; 18; 25) 2j + 1 bxbxbx (7; 23; 30) axaxax (16; 22; 29)\nII) 1 = j = Ti. v1i1v 2 i1v 3 i1 v 1 ikv 2 ikv 3 ik |k \u2208 [2 . .n]\n2j \u2212 1 axaxax axaxax gxgxgx(1, 3;19; 26) gxgxgx (12;19; 26)\n2j bmgmbm(5; 20; 27) bmgmbm (14; 20; 27) 2j + 1 bxgxbx(7; 24; 31) bxgxbx (17; 24; 31)\nIII) 1 < j < Ti.\nv1ikv 2 ikv 3 ik |k \u2208 [1 . .j \u2212 1] v 1 ijv 2 ijv 3 ij v 1 ikv 2 ikv 3 ik |k \u2208 [j + 1 . .n]\n2j \u2212 1 bxbxbx axaxax axaxax 2j bmambm (6, 15; 21; 28) bmamam(9, 11; 18; 25) amamam (13; 18; 25) 2j + 1 bxbxbx (7, 17; 23; 31) bxbxbx (17; 23; 30) axaxax (16; 22; 29)\nIV) 1 < j = Ti.\nv1ikv 2 ikv 3 ik |k \u2208 [1 . .j \u2212 1] v 1 ijv 2 ijv 3 ij v 1 ikv 2 ikv 3 ik |k \u2208 [j + 1 . .n]\n2j \u2212 1 bxbxbx axaxax axaxax bmambm (6, 15; 21; 28) gxgxgx (8, 10;19; 26) gxgxgx (12;19; 26)\n2j bmambm bmgmbm(14; 20; 27) bmgmbm (14; 20; 27) 2j + 1 bxbxbx (7, 17; 23; 31) bxgxbx (17; 24; 31) bxgxbx (17; 24; 31)\nV) 1 = Ti < j. v1i1v 2 i1v 3 i1 v 1 ikv 2 ikv 3 ik |k \u2208 [2 . .n]\n2j \u2212 1 bxgxbx bxgxbx 2j bmgmbm(6; 20; 28) bmgmbm (15; 20; 28) 2j + 1 bxgxbx(7; 24; 31) bxgxbx (17; 24; 31)\nVI) 1 < Ti < j.\nv1ikv 2 ikv 3 ik |k \u2208 [1 . .Ti \u2212 1] v 1 ikv 2 ikv 3 ik |k \u2208 [Ti . .n]\n2j \u2212 1 bxbxbx bxgxbx 2j bmambm (6, 15; 21; 28) bmgmbm (15; 20; 28) 2j + 1 bxbxbx (7, 17; 23; 31) bxgxbx (17; 24; 31)\nTheorem A.8. There exists a plan that solves the planning problem P7(F ) if and only if there exists an assignment \u03c3 that satisfies the CNF formula F .\nProof. \u21d0: Given an assignment \u03c3 that satisfies F , construct an admissible plan whose induced formula assignment \u03c3\u03a0 equals \u03c3, by choosing the sequence of values of vs accordingly. It follows that for each clause Ci, Ti \u2264 n, since there exists a variable xj such that \u03c3\u03a0(xj) = mj satisfies Ci. Since n \u2265 Ti, there exists an admissible plan \u03a0 for which Q 2n+1 i has the form indicated in Case (b) or (c) of Lemma A.7. In either case, the (2n + 1)-th value of variable v2in is gx, as required by the goal state. The plan \u03a0 thus solves P7(F ).\n\u21d2: Let \u03a0 be a plan that solves the planning problem P7(F ). By Lemma A.5 the plan \u03a0 is admissible. We show by contradiction that \u03c3 = \u03c3\u03a0 satisfies F . Assume not. Then there exists a clause Ci not satisfied by \u03c3. Thus, Lemma A.7 applies to the sequence of values Q2n+1i of \u03a0. In particular, this means that the value of v 2 in following the execution of \u03a0 is bx according to Case (a) of the lemma. This contradicts \u03a0 solving P7(F ), since bx is different from the goal state goal(v2in) = gx.\nProposition A.9. Plan existence for C7n is NP-hard.\nProof. The largest variable domains of the planning problem P7(F ) are those of variables v111, . . . , v 3 kn, which contain 7 values. The proof follows immediately from the NP-hardness of Cnf-Sat, Theorem A.8, and the fact that we can produce the planning problem P7(F ) in polynomial time given a CNF formula F ."}], "references": [], "referenceMentions": [], "year": 2009, "abstractText": "Recently, considerable focus has been given to the problem of determining the boundary between tractable and intractable planning problems. In this paper, we study the complexity of planning in the class C n of planning problems, characterized by unary operators and directed path causal graphs. Although this is one of the simplest forms of causal graphs a planning problem can have, we show that planning is intractable for C n (unless P = NP), even if the domains of state variables have bounded size. In particular, we show that plan existence for C n is NP-hard for k \u2265 5 by reduction from Cnf-Sat. Here, k denotes the upper bound on the size of the state variable domains. Our result reduces the complexity gap for the class C n to cases k = 3 and k = 4 only, since C n is known to be tractable.", "creator": null}}}