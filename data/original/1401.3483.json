{"id": "1401.3483", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Relaxed Survey Propagation for The Weighted Maximum Satisfiability Problem", "abstract": "The survey propagation (SP) algorithm has been shown to work well on large instances of the random 3-SAT problem near its phase transition. It was shown that SP estimates marginals over covers that represent clusters of solutions. The SP-y algorithm generalizes SP to work on the maximum satisfiability (Max-SAT) problem, but the cover interpretation of SP does not generalize to SP-y. In this paper, we formulate the relaxed survey propagation (RSP) algorithm, which extends the SP algorithm to apply to the weighted Max-SAT problem. We show that RSP has an interpretation of estimating marginals over covers violating a set of clauses with minimal weight. This naturally generalizes the cover interpretation of SP. Empirically, we show that RSP outperforms SP-y and other state-of-the-art Max-SAT solvers on random Max-SAT instances. RSP also outperforms state-of-the-art weighted Max-SAT solvers on random weighted Max-SAT instances.", "histories": [["v1", "Wed, 15 Jan 2014 05:36:10 GMT  (809kb)", "http://arxiv.org/abs/1401.3483v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["hai leong chieu", "wee sun sun lee"], "accepted": false, "id": "1401.3483"}, "pdf": {"name": "1401.3483.pdf", "metadata": {"source": "CRF", "title": "Relaxed Survey Propagation for The Weighted Maximum Satisfiability Problem", "authors": ["Hai Leong Chieu", "Wee Sun Lee"], "emails": ["chaileon@dso.org.sg", "leews@comp.nus.edu.sg"], "sections": [{"heading": "1. Introduction", "text": "The 3-SAT problem is the archetypical NP-complete problem, and the difficulty of solving random 3-SAT instances has been shown to be related to the clause to variable ratio, \u03b1=M/N , where M is the number of clauses and N the number of variables. A phase transition occurs at the critical value of \u03b1c \u2248 4.267: random 3-SAT instances with \u03b1<\u03b1c are generally satisfiable, while instances with \u03b1>\u03b1c are not. Instances close to the phase transition are generally hard to solve using local search algorithms (Mezard & Zecchina, 2002; Braunstein, Mezard, & Zecchina, 2005).\nThe survey propagation (SP) algorithm was invented in the statistical physics community using approaches used for analyzing phase transitions in spin glasses (Mezard & Zecchina, 2002). The SP algorithm has surprised computer scientists by its ability to solve efficiently extremely large and difficult Boolean satisfiability (SAT) instances in the phase transition region. The algorithm has also been extended to the SP-y algorithm to handle the maximum satisfiability (Max-SAT) problem (Battaglia, Kolar, & Zecchina, 2004).\nProgress has been made in understanding why the SP algorithm works well. Braunstein and Zecchina (2004) first showed that SP can be viewed as the belief propagation (BP) algorithm (Pearl, 1988) on a related factor graph where only clusters of solutions represented by covers have non-zero probability. It is not known whether a similar interpretation can be given to the SP-y algorithm. In this paper, we extend the SP algorithm to handle weighted\nc\u00a92009 AI Access Foundation. All rights reserved.\nMax-SAT instances in a way that preserves the cover interpretation, and we call this new algorithm the Relaxed Survey Propagation (RSP) algorithm. Empirically, we show that RSP outperforms SP-y and other state-of-the-art solvers on random Max-SAT instances. It also outperforms state-of-the-art solvers on a few benchmark Max-SAT instances. On random weighted Max-SAT instances, it outperforms state-of-the-art weighted Max-SAT solvers.\nThe rest of this paper is organized as follows. In Section 2, we describe the background literature and mathematical notations necessary for understanding this paper. This includes a brief review of the definition of joint probability distributions over factor graphs, an introduction to the SAT, Max-SAT and the weighted Max-SAT problem, and how they can be formulated as inference problems over a probability distribution on a factor graph. In Section 3, we give a review of the BP algorithm (Pearl, 1988), which plays a central role in this paper. In Section 4, we give a description of the SP (Braunstein et al., 2005) and the SP-y (Battaglia et al., 2004) algorithm, explaining them as warning propagation algorithms. In Section 5, we define a joint distribution over an extended factor graph given a weighted Max-SAT instance. This factor graph generalizes the factor graph defined by Maneva, Mossel and Wainwright (2004) and by Chieu and Lee (2008). We show that, for solving SAT instances, running the BP algorithm on this factor graph is equivalent to running the SP algorithm derived by Braunstein, Mezard and Zecchina (2005). For the weighted Max-SAT problem, this gives rise to a new algorithm that we call the Relaxed Survey Propagation (RSP) algorithm. In Section 7, we show empirically that RSP outperforms other algorithms for solving hard Max-SAT and weighted Max-SAT instances."}, {"heading": "2. Background", "text": "While SP was first derived from principles in statistical physics, it can be understood as a BP algorithm, estimating marginals for a joint distribution defined over a factor graph. In this section, we will provide background material on joint distributions defined over factor graphs. We will then define the Boolean satisfiability (SAT) problem, the maximum satisfiability (Max-SAT) problem, and the weighted maximum satisfiability (weighted MaxSAT) problem, and show that these problems can be solved by solving an inference problem over joint distributions defined on factor graphs. A review of the definition and derivation of the BP algorithm will then follow in the next section, before we describe the SP algorithm in Section 4."}, {"heading": "2.1 Notations", "text": "First, we will define notations and concepts that are relevant to the inference problems over factor graphs. Factor graphs provide a framework for reasoning and manipulating the joint distribution over a set of variables. In general, variables could be continuous in nature, but in this paper, we limit ourselves to discrete random variables.\nIn this paper, we denote random variables using large Roman letters, e.g., X,Y . The random variables are always discrete in this paper, taking values in a finite domain. Usually, we are interested in vectors of random variables, for which we will write the letters in bold face, e.g., X,Y. We will often index random variables by the letters i, j, k..., and write, for example, X = {Xi}i\u2208V , where V is a finite set. For a subset W \u2286 V , we will denote\nXW = {Xi}i\u2208W . We call an assignment of values to the variables in X a configuration, and will denote it in small bold letters, e.g. x. We will often write x to represent an event X = x and, for a probability distribution p, write p(x) to mean p(X = x). Similarly, we will write x to denote the event X = x, and write p(x) to denote p(X = x).\nA recurring theme in this paper will be on defining message passing algorithms for joint distributions on factor graphs (Kschischang, Frey, & Loeliger, 2001). In a joint distribution defined as a product of local functions (functions defined on a small subset of variables), we will refer to the local functions as factors. We will index factors, e.g. \u03c8\u03b2, with Greek letters, e.g., \u03b2, \u03b3 (avoiding \u03b1 which is used as the symbol for clause to variable ratio in SAT instances). For each factor \u03c8\u03b2, we denote V (\u03b2) \u2286 V as the subset of variables on which \u03c8\u03b2 is defined, i.e. \u03c8\u03b2 is a function defined on the variables XV (\u03b2). In message passing algorithms, messages are vectors of real numbers that are sent from factors to variables or vice versa. A vector message sent from a variable Xi to a factor \u03c8\u03b2 will be denoted as Mi\u2192\u03b2, and a message from \u03c8\u03b2 to Xi will be denoted as M\u03b2\u2192i."}, {"heading": "2.2 Joint Distributions and Factor Graphs", "text": "Given a large set of discrete, random variables X = {Xi}i\u2208V , we are interested in the joint probability distribution p(X) over these variables. When the set V is large, it is often of interest to assume a simple decomposition, so that we can draw conclusions efficiently from the distribution. In this paper, we are interested in the joint probability distribution that can be decomposed as follows\np(X = x) = 1 Z \u220f \u03b2\u2208F \u03c8\u03b2(xV(\u03b2)), (1)\nwhere the set F indexes a set of functions {\u03c8\u03b2}\u03b2\u2208F . Each function \u03c8\u03b2 is defined on a subset of variables XV (\u03b2) of the set X, and maps configurations xV (\u03b2) into non-negative real numbers. Assuming that each function \u03c8\u03b2 is defined on a small subset of variables XV (\u03b2), we hope to do efficient inference with this distribution, despite the large number of variables in X. The constant Z is a normalization constant, which ensures that the distribution sums to one over all configurations x of X.\nA factor graph (Kschischang et al., 2001) provides a useful graphical representation illustrating the dependencies defined in the joint probability distribution in Equation 1. A factor graph G = ({V, F}, E), is a bipartite graph with two sets of nodes, the set of variable nodes, V , and the set of factor nodes, F . The set of edges E in the factor graph connects variable nodes to factor nodes, hence the bipartite nature of the graph. For a factor graph representing the joint distribution in Equation 1, an edge e = (\u03b2, i) is in E if and only if\nthe variable Xi is a parameter of the factor \u03c8\u03b2 (i.e. i \u2208 V (\u03b2)). We will denote V (i) as the set of factors depending on the variable Xi, i.e.\nV (i) = {\u03b2 \u2208 F | i \u2208 V (\u03b2)} (2)\nWe show a simple example of a factor graph in Figure 1. In this small example, we have for example, V (\u03b2) = {1, 2} and V (2) = {\u03b2, \u03b2\u2032\u2032}. The factor graph representation is useful for illustrating inference algorithms on joint distributions in the form of Equation 1 (Kschischang et al., 2001). In Section 3, we will describe the BP algorithm by using the factor graph representation.\nEquation 1 defines the joint distribution as a product of local factors. It is often useful to represent the distribution in the following exponential form:\np(x) = exp ( \u2211 \u03b2\u2208F \u03c6\u03b2(xV (\u03b2))\u2212 \u03a6) (3)\nThe above equation is a reparameterization of Equation 1, with \u03c8\u03b2(xV (\u03b2)) = exp(\u03c6\u03b2(xV (\u03b2))) and \u03a6 = lnZ. In statistical physics, the exponential form is often written as follows:\np(x) = 1 Z exp(\u2212 1 kBT E(x)), (4)\nwhere E(x) is the Hamiltonian or energy function, kB is the Boltzmann\u2019s constant, and T is the temperature. For simplicity, we set kBT = 1, and Equations 3 and 4 are equivalent with E(x) = \u2212 \u2211 \u03b2\u2208F \u03c6\u03b2(xV (\u03b2)).\nBayesian (belief) networks and Markov random fields are two other graphical representations often used to describe multi-dimensional probability distributions. Factor graphs are closely related to both Bayesian networks and Markov random fields, and algorithms operating on factor graphs are often directly applicable to Bayesian networks and Markov random fields. We refer the reader to the work of Kschischang et al. (2001) for a comparison between factor graphs, Bayesian networks and Markov random fields."}, {"heading": "2.3 Inference on Joint Distributions", "text": "In the literature, \u201cinference\u201d on a joint distribution can refer to solving one of two problems. We define the two problems as follows:\nProblem 1 (MAP problem). Given a joint distribution, p(x), we are interested in the configuration(s) with the highest probability. Such configurations, x\u2217, are called the maximuma-posteriori configurations, or MAP configurations\nx\u2217 = arg max x p(x) (5)\nFrom the joint distribution in Equation 4, the MAP configuration minimizes the energy function E(x), and hence the MAP problem is sometimes called the energy minimization problem.\nProblem 2 (Marginal problem). Given a joint distribution, p(x), of central interest are the calculation or estimation of probabilities of events involving a single variable Xi = xi. We refer to such probabilities as marginal probabilities:\npi(xi) = \u2211 x\\xi p(x). (6)\nThe notation \u2211\nx\\xi means summing over all configurations of X with the variable Xi set to xi. Marginals are important as they represent the underlying distribution of individual variables.\nIn general, both problems are not solvable in reasonable time by currently known methods. Naive calculation of pi(xi) involves summing the probabilities of all configurations for the variables X for which Xi = xi. For example, in a factor graph with n variables of cardinality q, finding the marginal of one of the variables will involve summing over qn\u22121 configurations. Furthermore, NP-complete problems such as 3-SAT can be simply coded as factor graphs (see Section 2.4.1). As such, the MAP problem is in general NP-complete, while the marginal problem is equivalent to model counting for 3-SAT, and is #P-complete (Cooper, 1990). Hence, in general, we do not expect to solve the inference problems (exactly) in reasonable time, unless the problems are very small, or have special structures that can be exploited for efficient inference.\nOf central interest in this paper is a particular approximate inference method known as the (sum-product) belief propagation (BP) algorithm. We defer the discussion of the BP algorithm to the next section. In the rest of this section, we will describe the SAT, Max-SAT and weighted Max-SAT problems, and how they can be simply formulated as inference problems on a joint distribution over a factor graph."}, {"heading": "2.4 The SAT and Max-SAT Problem", "text": "A variable is Boolean if it takes values in {FALSE,TRUE}. In this paper, we will follow conventions in statistical physics, where Boolean variables take values in {\u22121,+1}, with \u22121 corresponding to FALSE, and +1 corresponding to TRUE.\nThe Boolean satisfiability (SAT) problem is given as a Boolean propositional formula written with the operators AND (conjunction), OR (disjunction), NOT (negation), and parenthesis. The objective of the SAT problem is to decide whether there exists a configuration such that the propositional formula is satisfied (evaluates to TRUE). The SAT problem is the first problem shown to be NP-complete in Stephen Cook\u2019s seminal paper in 1971 (Cook, 1971; Levin, 1973).\nThe three operators in Boolean algebra are defined as follows: given two propositional formulas A and B, OR(A,B) is true if either A or B is true; AND(A,B) is true only if both A and B are true; and NOT(A) is true if A is false. In the rest of the paper, we will use the standard notations in Boolean algebra for the Boolean operators: A \u2228B means OR(A,B), A \u2227 B means AND(A,B), and A means NOT(A). The parenthesis is available to allow nested application of the operators, e.g. (A \u2228B) \u2227 (B \u2228 C).\nThe conjunctive normal form (CNF) is often used as a standard form for writing Boolean formulas. The CNF consists of a conjunction of disjunctions of literals, where a literal is either a variable or its negation. For example, (X1 \u2228 X2) \u2227 (X3 \u2228 X4) is in CNF, while\nX1 \u2228X2 and (X1\u2227X2)\u2228(X2\u2227X3) are not. Any Boolean formula can be re-written in CNF using De Morgan\u2019s law and the distributivity law, although in practice, this may lead to an exponential blowup in the size of the formula, and the Tseitin transformation is often used instead (Tseitin, 1968). In CNF, a Boolean formula can be considered to be the conjunction of a set of clauses, where each clause is a disjunction of literals. Hence, a SAT problem is often given as (X,C), where X is the vector of the Boolean variables, and C is a set of clauses. Each clause in C is satisfied by a configuration if it evaluates to TRUE for that configuration. Otherwise, it is said to be violated by the configuration. We will use Greek letters (e.g. \u03b2, \u03b3) as indices for clauses in C, and denote by V (\u03b2) as the set of variables in the clause \u03b2 \u2208 C. The K-SAT problem is a SAT problem for which each clause in C consists of exactly K literals. The K-SAT problem is NP-complete, for K \u2265 3 (Cook, 1971).\nThe maximum satisfiability problem (Max-SAT) problem is the optimization version of the SAT problem, where the aim is to minimize the number of violated constraints in the formula. We define a simple working example of the Max-SAT problem that we will use throughout the paper:\nExample 1. Define an instance of the Max-SAT problem in CNF with the following clauses \u03b21 = (x1\u2228x2), \u03b22 = (x2\u2228x3), \u03b23 = (x3\u2228x1), \u03b24 = (x1\u2228x2\u2228x3), \u03b25 = (x1\u2228x2\u2228x3) and \u03b26 = (x1 \u2228 x2). The Boolean expression representing this problem would be\n(x1 \u2228 x2) \u2227 (x2 \u2228 x3) \u2227 (x3 \u2228 x1) \u2227 (x1 \u2228 x2 \u2228 x3) \u2227 (x1 \u2228 x2 \u2228 x3) \u2227 (x1 \u2228 x2). (7)\nThe objective of the Max-SAT problem would be to find a configuration minimizing the number of violated clauses."}, {"heading": "2.4.1 Factor Graph Representation for SAT Instances", "text": "The SAT problem in CNF can easily be represented as a joint distribution over a factor graph. In the following definition, we give a possible definition of a joint distribution over Boolean configurations for a given SAT instance, where the Boolean variables take values in {\u22121,+1}.\nDefinition 1. Given an instance of the SAT problem, (X,C) in conjunctive normal form, where X is a vector of N Boolean variables. We define the energy, E(x), and the distribution, p(x), over configurations of the SAT instance (Battaglia et al., 2004)\n\u2200\u03b2 \u2208 C, C\u03b2(xV (\u03b2)) = \u220f\ni\u2208V (\u03b2)\n1 2 (1 + J\u03b2,ixi), (8)\nE(x) = \u2211 \u03b2\u2208C C\u03b2(xV (\u03b2)), (9)\np(x) = 1 Z exp(\u2212E(x)), (10)\nwhere x \u2208 {\u22121,+1}N , and J\u03b2,i takes values in {\u22121,+1}. If J\u03b2,i = +1 (resp. \u22121), then \u03b2 contains Xi as a negative (resp. positive) literal. Each clause \u03b2 is satisfied if one of its variables Xi takes the value \u2212J\u03b2,i. When a clause \u03b2 is satisfied, C\u03b2(xV (\u03b2)) = 0. Otherwise C\u03b2(xV (\u03b2)) = 1.\nWith the above definition, the energy function is zero for satisfying configurations, and equals the number of violated clauses for non-satisfying configuration. Hence, satisfying configurations of the SAT instance are the MAP configurations of the factor graph.\nIn this section, we make some definitions that will be useful in the rest of the paper. For a clause \u03b2 containing a variable Xi (associated with the value of J\u03b2,i), we will say that Xi satisfies \u03b2 if Xi = \u2212J\u03b2,i. In this case, the clause \u03b2 is satisfied regardless of the values taken by the other variables. Conversely, we say that Xi violates \u03b2 if Xi does not satisfy \u03b2. In this case, it is still possible that \u03b2 is satisfied by other variables.\nDefinition 2. For a clause \u03b2 \u2208 C, we define u\u03b2,i (resp. s\u03b2,i) as the value of Xi \u2208 {\u22121,+1} that violates (resp. satisfies) clause \u03b2. This means that s\u03b2,i = \u2212J\u03b2,i and u\u03b2,i = +J\u03b2,i. We define the following sets\nV +(i) = {\u03b2 \u2208 V (i); s\u03b2,i = +1}, V \u2212(i) = {\u03b2 \u2208 V (i); s\u03b2,i = \u22121}, V s\u03b2 (i) = {\u03b3 \u2208 V (i) \\ {\u03b2}; s\u03b2,i = s\u03b3,i}, V u\u03b2 (i) = {\u03b3 \u2208 V (i) \\ {\u03b2}; s\u03b2,i 6= s\u03b3,i}.\n(11)\nIn the above definitions, V +(i) (resp. V \u2212(i)) is the set of clauses that contain Xi as a positive literal (resp. negative literal). V s\u03b2 (i) (resp. V u \u03b2 (i)) is the set of clauses containing Xi that agrees (resp. disagrees) with the clause \u03b2 concerning Xi. These sets will be useful when we define the SP message passing algorithms for SAT instances.\nThe factor graph representing the Max-SAT instance given in Example 1 is shown in Figure 2. For this example, V +(1) = {\u03b23, \u03b25, \u03b26}, V \u2212(1) = {\u03b21, \u03b24}, V s\u03b23(1) = {\u03b25, \u03b26}, and V u\u03b23(1) = {\u03b21, \u03b24}. The energy for this example is as follows:\nE(x) = 1 4 (1 + x1)(1\u2212 x2) + 1 4 (1 + x2)(1\u2212 x3) + 1 4\n(1 + x3)(1\u2212 x1) + 1 8 (1 + x1)(1 + x2)(1 + x3) + 1 8 (1\u2212 x1)(1\u2212 x2)(1\u2212 x3) + 1 4 (1\u2212 x1)(1\u2212 x2) (12)"}, {"heading": "2.4.2 Related Work on SAT", "text": "The SAT problem is well studied in computer science: as the archetypical NP-complete problem, it is common to reformulate other NP-complete problems such as graph coloring as a SAT problem (Prestwich, 2003). SAT solvers are either complete or incomplete. The best known complete solver for solving the SAT problem is probably the Davis-PutnamLogemann-Loveland (DPLL) algorithm (Davis & Putnam, 1960; Davis, Logemann, & Loveland, 1962). The DPLL algorithm is a basic backtracking algorithm that runs by choosing a literal, assigning a truth value to it, simplifying the formula and then recursively checking if the simplified formula is satisfiable; if this is the case, the original formula is satisfiable; otherwise, the same recursive check is done assuming the opposite truth value. Variants of the DPLL algorithm such as Chaff (Moskewicz & Madigan, 2001), MiniSat (Een & So\u0308rensson, 2005), and RSAT (Pipatsrisawat & Darwiche, 2007) are among the best performers in recent SAT competitions (Berre & Simon, 2003, 2005). Solvers such as satz (Li & Anbulagan, 1997) and cnfs (Dubois & Dequen, 2001) have also been making progress in solving hard random 3-SAT instances.\nMost solvers that participated in recent SAT competitions are complete solvers. While incomplete or stochastic solvers do not show that a SAT instance is unsatisfiable, they are often able to solve larger satisfiable instances than complete solvers. Incomplete solvers usually start with a randomly initialized configuration, and different algorithms differ in the way they flip selected variables to move towards a solution. One disadvantage of such an approach is that in hard SAT instances, a large number of variables have to be flipped to move a current configuration out of a local minimum, which acts as a local trap. Incomplete solvers differ in the strategies used to move the configuration out of such traps. For example, simulated annealing (Kirkpatrick, Jr., & Vecchi, 1983) allows the search to move uphill, controlled by a temperature parameter. GSAT (Selman, Levesque, & Mitchell, 1992) and WalkSAT (Selman, Kautz, & Cohen, 1994) are two algorithms developed in the 1990s that allow randomized moves when the solution cannot be improved locally. The two algorithms differ in the way they choose the variables to flip. GSAT makes the change which minimizes the number of unsatisfied clauses in the new configuration, while WalkSAT selects the variable that, when flipped, results in no previously satisfied clauses becoming unsatisfied. Variants of algorithms such as WalkSAT and GSAT use various strategies, such as tabusearch (McAllester, Selman, & Kautz, 1997) or adapting the noise parameter that is used, to help the search out of a local minima (Hoos, 2002). Another class of approaches is based on applying discrete Lagrangian methods on SAT as a constrained optimization problem (Shang & Wah, 1998). The Lagrange mutlipliers are used as a force to lead the search out of local traps.\nThe SP algorithm (Braunstein et al., 2005) has been shown to beat the best incomplete solvers in solving hard random 3-SAT instances efficiently. SP estimates marginals on all variables and chooses a few of them to fix to a truth value. The size of the instance is then reduced by removing these variables, and SP is run again on the remaining instance. This iterative process is called decimation in the SP literature. It was shown empirically that SP rarely makes any mistakes in its decimation, and SP solves very large 3-SAT instances that are very hard for local search algorithms. Recently, Braunstein and Zecchina (2006) have\nshown that by modifying BP and SP updates with a reinforcement term, the effectiveness of these algorithms as solvers can be further improved."}, {"heading": "2.5 The Weighted Max-SAT Problem", "text": "The weighted Max-SAT problem is a generalization of the Max-SAT problem, where each clause is assigned a weight. We define an instance of the weighted Max-SAT problem as follows:\nDefinition 3. A weighted Max-SAT instance (X,C,W) in CNF consists of X, a vector of N variables taking values in {\u22121,+1}, C, a set of clauses, and W, the set of weights for each clause in C. We define the energy of the weighted Max-SAT problem as\nE(x) = \u2211 \u03b2\u2208C \u220f i\u2208V (\u03b2) w\u03b2 2 (1 + J\u03b2,ixi), (13)\nwhere x \u2208 {\u22121,+1}N , and J\u03b2,i takes values in {\u22121,+1}, and w\u03b2 is the weight of the clause \u03b2. The total energy, E(x), of a configuration x equals the total weight of violated clauses.\nSimilarly to SAT, there are also complete and incomplete solvers for the weighted MaxSAT problem. Complete weighted Max-SAT solvers involve branch and bound techniques by calculating bounds on the cost function. Larrosa and Heras (2005) introduced a framework that integrated the branch and bound techniques into a Max-DPLL algorithm for solving the Max-SAT problem. Incomplete solvers generally employ heuristics that are similar to those used for SAT problems. An example of an incomplete method is the min-conflicts hillclimbing with random walks algorithm (Minton, Philips, Johnston, & Laird, 1992). Many SAT solvers such as WalkSAT can be extended to solve weighted Max-SAT problems, where the weights are used as a criterion in the selection of variables to flip.\nAs a working example in this paper, we define the following instance of a weighted Max-SAT problem:\nExample 2. We define a set of weighted Max-SAT clauses in the following table:\nId Clause Weight - - - - - + - + - - + + + - - + - + + + - + + + \u03b21 x1 \u2228 x2 1 3 3 3 3 5 5 3 3 \u03b22 x2 \u2228 x3 2 3 3 5 3 3 3 5 3 \u03b23 x3 \u2228 x1 3 3 5 3 5 3 3 3 3 \u03b24 x1 \u2228 x2 \u2228 x3 4 3 3 3 3 3 3 3 5 \u03b25 x1 \u2228 x2 \u2228 x3 5 5 3 3 3 3 3 3 3 \u03b26 x1 \u2228 x2 6 5 5 3 3 3 3 3 3\nEnergy 1 9 2 3 1 1 2 4\nThis weighted Max-SAT example has the same variables and clauses as the Max-SAT example given in Example 1. In the above table, we show the clauses satisfied (a tick) or violated (a cross) by each of the 8 possible configurations of the 3 variables. In the first\nrow, the symbol \u2212 corresponds to the value \u22121, and + corresponds to +1. For example, the string \u201c\u2212\u2212+ \u201d corresponds to the configuration (X1, X2, X3) = (\u22121,\u22121,+1). The last row of the table shows the energy of the configuration in each column.\nThe factor graph for this weighted Max-SAT example is the same as the one for the Max-SAT example in Example 1. The differences between the two examples are in the clause weights, which are reflected in the joint distribution, but not in the factor graph. The energy for this example is as follows:\nE(x) = 1 4 (1 + x1)(1\u2212 x2) + 2 4 (1 + x2)(1\u2212 x3) + 3 4\n(1 + x3)(1\u2212 x1) + 4 8 (1 + x1)(1 + x2)(1 + x3) + 5 8 (1\u2212 x1)(1\u2212 x2)(1\u2212 x3) + 6 4 (1\u2212 x1)(1\u2212 x2)(14)"}, {"heading": "2.6 Phase Transitions", "text": "The SP algorithm has been shown to work well on 3-SAT instances near its phase transition, where instances are known to be very hard to solve. The term \u201cphase transition\u201d arises from the physics community. To understand the notion of \u201chardness\u201d in optimization problems, computer scientists and physicists have been studying the relationship between computational complexity in computer science and phase transitions in statistical physics. In statistical physics, the phenomenon of phase transitions refers to the abrupt changes in one or more physical properties in thermodynamic or magnetic systems with a small change in the value of a variable such as the temperature. In computer science, it has been observed that in random ensembles of instances such as K-SAT, there is a sharp threshold where randomly generated problems undergo an abrupt change in properties. For example, in K-SAT, it has been observed empirically that as the clause to variable ratio \u03b1 changes, randomly generated instances change abruptly from satisfiable to unsatisfiable at a particular value of \u03b1, often denoted as \u03b1c. Moreover, instances generated with a value of \u03b1 close to \u03b1c are found to be extremely hard to solve.\nComputer scientists and physicists have worked on bounding and calculating the precise value of \u03b1c where the phase transition for 3-SAT occurs. Using the cavity approach, physicists claim that \u03b1c \u2248 4.267 (Mezard & Zecchina, 2002). While their derivation of the value of \u03b1c is non-rigorous, it is based on this derivation that they formulated the SP algorithm. Using rigorous mathematical approaches, the upper bounds to the value of \u03b1c can be derived using first-order methods. For example, in the work of Kirousis, Kranakis, Krizanc, and Stamatiou (1998), \u03b1c for 3-SAT was upper bounded by 4.571. Achlioptas, Naor and Peres (2005) lower-bounded the value of \u03b1c using a weighted second moments method, and their lower bound is close to the upper bounds for K-SAT ensembles for large values of K. However, their lower bound for 3-SAT is 2.68, rather far from the conjectured value of 4.267. A better (algorithmic) lower bound of 3.52 can be obtained by analyzing the behavior of algorithms that find SAT configurations (Kaporis, Kirousis, & Lalas, 2006).\nPhysicists have also shown rigorously using second moment methods that as \u03b1 approaches \u03b1c, the search space fractures dramatically, with many small solution clusters appearing relatively far apart from each other (Mezard, Mora, & Zecchina, 2005). Clusters of solutions are generally defined as a set of connected components of the solution space, where two adjacent solutions have a Hamming distance of 1 (differ by one variable). Daude,\nMezard, Mora, and Zecchina (2008) redefined the notion of clusters by using the concept of x-satisfiability: a SAT instance is x-satisfiable if there exists two solutions differing by Nx variables, where N is the total number of variables. They showed that near the phase transition, x goes from around 12 to very small values, without going through a phase of intermediate values. This clustering phenomenon explains why instances generated with \u03b1 close to \u03b1c are extremely hard to solve with local search algorithm: it is difficult for the local search algorithm to move from a local minimum to the global minimum."}, {"heading": "3. The Belief Propagation Algorithm", "text": "The BP algorithm has been reinvented in different fields under different names. For example, in the speech recognition community, the BP algorithm is known as the forward-backward procedure (Rabiner & Juang, 1993). On tree-structured factor graphs, the BP algorithm is simply a dynamic programming approach applied to the tree structure, and it can be shown that BP calculates the marginals for each variable in the factor graph (i.e. solving Problem 2). In loopy factor graphs, the BP algorithm has been found to provide a reasonable approximation to solving the marginal problem when the algorithm converges. In this case, the BP algorithm is often called the loopy BP algorithm. Yedidia, Freeman and Weiss (2005) have shown that the fixed points of the loopy BP algorithm correspond to the stationary points of the Bethe free energy, and is hence a sensible approximate method for estimaing marginals.\nIn this section, we will first describe the BP algorithm as a dynamic programming method for solving the marginal problem (Problem 2) for tree-structured factor graphs. We will also briefly describe how the BP algorithm can be applied to factor graphs with loops, and refer the reader to the work of Yedidia et al. (2005) for the underlying theoretical justification in this case.\nGiven a factor graph representing a distribution p(x), the BP algorithm involves iteratively passing messages from factor nodes \u03b2 \u2208 F to variable nodes i \u2208 V , and vice versa. Each factor node \u03b2 represents a factor \u03c8\u03b2, which is a factor in the joint distribution given in Equation 1. In Figure 3, we give an illustration of how the messages are passed between factor nodes and variable nodes. Each Greek alphabet (e.g. \u03b2 \u2208 F ) in a square represents a factor (e.g. \u03c8\u03b2) and each Roman alphabet (e.g. i \u2208 V ) in a circle represents a variable (e.g. Xi).\nThe factor to variable messages (e.g. M\u03b2\u2192i), and the variable to factor messages (e.g. Mi\u2192\u03b2) are vectors of real numbers, with length equal to the cardinality of the variable Xi.\nWe denote by M\u03b2\u2192i(xi) or Mi\u2192\u03b2(xi) the component of the vector corresponding to the value Xi = xi.\nThe message update equations are as follows:\nMj\u2192\u03b2(xj) = \u220f\n\u03b2\u2032\u2208V (j)\\\u03b2 M\u03b2\u2032\u2192j(xj) (15)\nM\u03b2\u2192i(xi) = \u2211\nxV (\u03b2)\\xi\n\u03c8\u03b2(xV (\u03b2)) \u220f\nj\u2208V (\u03b2)\\i Mj\u2192\u03b2(xj), (16)\nwhere \u2211\nxV (\u03b2)\\xi means summing over all configurations XV (\u03b2) with Xi set to xi. For a tree-structured factor graph, the message updates can be scheduled such that after two parses over the tree structure, the messages will converge. Once the messages converge, the beliefs at each variable node are calculated as follows:\nBj(xj) = \u220f\n\u03b2\u2208V (j) M\u03b2\u2192j(xj). (17)\nFor a tree-structured graph, the normalized beliefs for each variable will be equal to its marginals.\nINPUT: A joint distribution p(x) defined over a tree-structured factor graph ({V, F}, E), and a variable Xi \u2208 X.\nOUTPUT: Exact marginals for the variable Xi.\nALGORITHM :\nThe algorithm for calculating the exact marginals of a given variable Xi, is given in Figure 4. This algorithm is simply a dynamic programming procedure for calculating the marginals, pi(Xi), by organizing the sums so that the sums at the leaves are done first. For the simple example in Figure 1, for calculating p1(x1), the sum can be ordered as follows:\np1(x1) = \u2211\nx2,x3,x4\np(x)\n= \u03c8\u03b2(x1, x2) \u2211 x2 . \u2211 x3 \u03c8\u03b2\u2032(x1, x3) \u2211 x4 \u03c8\u03b2\u2032\u2032(x2, x4)\nThe BP algorithm simply carries out this sum by using the node for X1 as the root of the tree-structured factor graph in Figure 1.\nThe BP algorithm can also be used for calculating marginals for all variables efficiently, with the message passing schedule given in Figure 5. This schedule involves selecting a random variable node as the root of the tree, and then passing the messages from the leaves to the root, and back down to the leaves, After the two parses, all the message updates required in the algorithm in Figure 4 for any one variable would have been performed, and the beliefs of all the variables can be calculated from the messages. The normalized beliefs for each variable will be equal to the marginals for the variable.\nINPUT: A joint distribution p(x) defined over a tree-structured factor graph (V, F ).\nOUTPUT: Exact marginals for all variables in V .\nALGORITHM :\nIf the factor graph is not tree-structured (i.e. contains loops), then the message updates cannot be scheduled in the simple way described in the algorithm in Figure 5. In this case, we can still apply BP by iteratively updating the messages with Equations 15 and 16, often in a round-robin manner over all factor-variable pairs. This is done until all the messages converge (i.e. the messages do not change over iterations). There is no guarantee that all the messages will converge for general factor graphs. However, if they do converge, it was observed that the beliefs calculated with Equation 17 are often a good approximation of the exact beliefs of the joint distribution (Murphy, Weiss, & Jordan, 1999). When applied in this manner, the BP algorithm is often called the loopy BP algorithm. Recently, Yedidia, Freeman and Weiss (2001, 2005) have shown that loopy BP has an underlying variational principle. They showed that the fixed points of the BP algorithm correspond to the stationary points of the Bethe free energy. This fact serves in some sense to justify the BP algorithm even when the factor graph it operates on has loops, because minimizing the Bethe free energy is a sensible approximation procedure for solving the marginal problem. We refer the reader to the work of Yedidia et al. (2005) for more details.\n4. Survey Propagation: The SP and SP-y Algorithms\nRecently, the SP algorithm (Braunstein et al., 2005) has been shown to beat the best incomplete solvers in solving hard 3-SAT instances efficiently. The SP algorithm was first derived from principles in statistical physics, and can be explained using the cavity approach (Mezard & Parisi, 2003). It was first given a BP interpretation in the work of Braunstein and Zecchina (2004). In this section, we will define the SP and the SP-y algorithms for solving SAT and Max-SAT problems, using a warning propagation interpretation for these algorithms."}, {"heading": "4.1 SP Algorithm for The SAT Problem", "text": "In Section 2.4.1, we have defined a joint distribution for the SAT problem (X,C), where the energy function of a configuration is equal to the number of violated clauses for the configuration. In the factor graph ({V, F}, E) representing this joint distribution, the variable nodes in V correspond to the Boolean variables in X, and each factor node in F represents a clause in C. In this section, we provide an intuitive overview of the SP algorithm as it was formulated in the work of Braunstein et al. (2005).\nThe SP algorithm can be defined as a message passing algorithm on the factor graph ({V, F}, E). Each factor \u03b2 \u2208 F passes a single real number, \u03b7\u03b2\u2192i to a neighboring variable Xi in the factor graph. This real number \u03b7\u03b2\u2192i is called a survey. According to the warning propagation interpretation given in the work of Braunstein et al. (2005), the survey \u03b7\u03b2\u2192i corresponds to the probability1 of the warning that the factor \u03b2 is sending to the variable Xi. Intuitively, if \u03b7\u03b2\u2192i is close to 1, then the factor \u03b2 is warning the variable Xi against taking a value that will violate the clause \u03b2. If \u03b7\u03b2\u2192i is close to 0, then the factor \u03b2 is indifferent over the value taken by Xi, and this is because the clause \u03b2 is satisfied by other variables in V (\u03b2).\nWe first define the messages sent from a variable Xj to a neighboring factor \u03b2, as a function of the inputs from other factors containing Xj , i.e. {\u03b7\u03b2\u2032\u2192j}\u03b2\u2032\u2208V (j)\\\u03b2. In SP, this message is a vector of three numbers, \u03a0uj\u2192\u03b2,\u03a0 s j\u2192\u03b2, and \u03a0 0 j\u2192\u03b2, with the following interpretations:\n\u03a0uj\u2192\u03b2 is the probability that Xj is warned (by other clauses) to take a value that will violate the clause \u03b2. \u03a0sj\u2192\u03b2 is the probability that Xj is warned (by other clauses) to take a value that will satisfy the clause \u03b2. \u03a00j\u2192\u03b2 is the probability that Xj is free to take any value.\nWith these defintions, the update equations are as follows: \u03a0uj\u2192\u03b2 = [1\u2212 \u220f\n\u03b2\u2032\u2208V u \u03b2 (j)\n(1\u2212 \u03b7\u03b2\u2032\u2192j)] \u220f\n\u03b2\u2032\u2208V s \u03b2 (j)\n(1\u2212 \u03b7\u03b2\u2032\u2192j), (18)\n\u03a0sj\u2192\u03b2 = [1\u2212 \u220f\n\u03b2\u2032\u2208V s \u03b2 (j)\n(1\u2212 \u03b7\u03b2\u2032\u2192j)] \u220f\n\u03b2\u2032\u2208V u \u03b2 (j)\n(1\u2212 \u03b7\u03b2\u2032\u2192j), (19)\n1. SP reasons over clusters of solutions, and the probability of a warning in this section is used loosely in the SP literature to refer to the fraction of clusters for which the warning applies. In the next section, we will define a rigorous probability distribution over covers for the RSP algorithm.\n\u03a00j\u2192\u03b2 = \u220f\n\u03b2\u2032\u2208V (j) (1\u2212 \u03b7\u03b2\u2032\u2192j), (20)\n\u03b7\u03b2\u2192i = \u220f\nj\u2208V (\u03b2)\u2212i\n\u03a0uj\u2192\u03b2 \u03a0uj\u2192\u03b2 + \u03a0 s j\u2192\u03b2 + \u03a0 0 j\u2192\u03b2\n(21)\nThese equations are defined using the sets of factors V u\u03b2 (j) and V s \u03b2 (j), which has been defined in Section 2.4.1. For the event where the variable Xj is warned to take on a value violating \u03b2, it has to be (a) warned by at least one factor \u03b2\u2032 \u2208 V u\u03b2 (j) to take on a satisfying value for \u03b2\u2032, and (b) all the other factors in V s\u03b2 (j) are not sending warnings. In Equation 18, the probability of this event, \u03a0uj\u2192\u03b2, is a product of two terms, the first corresponding to event (a) and the second to event (b). The definitions of \u03a0sj\u2192\u03b2 and \u03a0 0 j\u2192\u03b2 are defined in a similar manner. In Equation 21, the final survey \u03b7\u03b2\u2192i is simply the probability of the joint event that all incoming variables Xj are violating the clause \u03b2, forcing the last variable Xi to satisfy \u03b2.\nThe SP algorithm consists of iteratively running the above update equations until the surveys converge. When the surveys converged, we can then calculate local biases as follows:\n\u03a0+j = [1\u2212 \u220f\n\u03b2\u2208V +(j) (1\u2212 \u03b7\u03b2\u2032\u2192j)] \u220f \u03b2\u2208V \u2212(j) (1\u2212 \u03b7\u03b2\u2192j), (22)\n\u03a0+j = [1\u2212 \u220f\n\u03b2\u2208V \u2212(j) (1\u2212 \u03b7\u03b2\u2032\u2192j)] \u220f \u03b2\u2208V +(j) (1\u2212 \u03b7\u03b2\u2192j), (23)\n\u03a00j = \u220f\n\u03b2\u2208V (j) (1\u2212 \u03b7\u03b2\u2192j), (24)\nW+i = \u03a0+j\n\u03a0+j + \u03a0 \u2212 j + \u03a0 0 j\n(25)\nW\u2212i = \u03a0\u2212j\n\u03a0+j + \u03a0 \u2212 j + \u03a0 0 j\n(26)\nTo solve an instances of the SAT problem, the SP algorithm is run until it converges, and a few variables that are highly constrained are set to their preferred values. The SAT instance is then reduced to a smaller instance, and SP can be run again on the smaller instance. This continues until SP fails to set any more variables, and in this case, a local search algorithm such as WalkSAT is run on the remaining instance. This algorithm, called the survey inspired decimation algorithm (Braunstein et al., 2005), is given in the algorithm in Figure 6.\n4.2 The SP-y Algorithm\nIn contrast to the SP algorithm, the SP-y algorithm\u2019s objective is to solve Max-SAT instances, and hence clauses are allowed to be violated, at a price. The SP algorithm can be understood as a special case of the SP-y algorithm, with y taken to infinity (Battaglia et al., 2004). In SP-y, a penalty value of exp(\u22122y) is multiplied into the distribution for each violated clause. Hence, although the message passing algorithm allows the violation of clauses, but as the value of y increases, the surveys will prefer configurations that violate a minimal number of clauses.\nINPUT: A SAT problem, and a constant k.\nOUTPUT: A satisfying configuration, or report FAILURE.\nALGORITHM :\nThe SP-y algorithm can still be understood as a message passing algorithm over factor graphs. As in SP, each factor, \u03b2, passes a survey, \u03b7\u03b2\u2192i, to a neighboring variable Xi, corresponding to the probability of the warning. To simplify notations, we define \u03b7+\u03b2\u2192i (resp. \u03b7\u2212\u03b2\u2192i) to be the probability of the warning against taking the value +1 (resp. \u22121), and we define \u03b70\u03b2\u2192i = 1 \u2212 \u03b7 + \u03b2\u2192i \u2212 \u03b7 \u2212 \u03b2\u2192i. In practice, since a clause can only warn against either +1 or \u22121 but not both, either \u03b7+\u03b2\u2192i or \u03b7 \u2212 \u03b2\u2192i equals zero: \u03b7 J\u03b2,i \u03b2\u2192i = \u03b7\u03b2\u2192i, and \u03b7 \u2212J\u03b2,i \u03b2\u2192i = 0, where J\u03b2,i is defined in Definition 1. Since clauses can be violated, it is insufficient to simply keep track of whether a variable has been warned against a value or not. It is now necessary to keep track of how many times the variable has been warned against each value, so that we know how many clauses will be violated if the variable was to take a particular value. Let H+j\u2192\u03b2 (resp. H \u2212 j\u2192\u03b2) be the number of times the variable Xj is warned by factors in {\u03b2\u2032}\u03b2\u2032\u2208V (j)\\\u03b2 against the value +1 (resp. \u22121). In SP-y, the variable Xj will be forced by \u03b2 to take the value +1 if H+j\u2192\u03b2 is smaller than H\u2212j\u2192\u03b2, and the penalty in this case will be exp(\u22122yH + j\u2192\u03b2). In notations used in the work of Battaglia et al. (2004) describing SP-y, let hj\u2192\u03b2 = H+j\u2192\u03b2 \u2212H \u2212 j\u2192\u03b2.\nBattaglia et al. (2004) defined the SP-y message passing equations that calculate the probability distribution over hj\u2192\u03b2, based on the input surveys,\n{\u03b7\u03b2\u2032\u2192j}\u03b2\u2032\u2208V (j)\\\u03b2 = {\u03b7\u03b21\u2192j , \u03b7\u03b22\u2192j , ..., \u03b7\u03b2(|V (j)|\u22121)\u2192j}, (27)\nwhere |V (j)| refers to the cardinality of the set V (j). The unnormalized distributions P\u0303j\u2192\u03b2(h) are calculated as follows:\nP\u0303 (1) j\u2192\u03b2(h) = \u03b7 0 \u03b21\u2192i\u03b4(h) + \u03b7 + \u03b21\u2192i\u03b4(h\u2212 1) + \u03b7 \u2212 \u03b21\u2192i\u03b4(h+ 1), (28)\n\u2200\u03b3 \u2208 [2, |V (j)| \u2212 1], P\u0303 (\u03b3)j\u2192\u03b2(h) = \u03b7 0 \u03b2\u03b3\u2192iP\u0303 (\u03b3\u22121) j\u2192\u03b2 (h)\n+\u03b7+\u03b2\u03b3\u2192iP\u0303 (\u03b3\u22121) j\u2192\u03b2 (h\u2212 1) exp [\u22122y\u03b8(\u2212h)] +\u03b7\u2212\u03b2\u03b3\u2192iP\u0303 (\u03b3\u22121) j\u2192\u03b2 (h+ 1) exp [\u22122y\u03b8(h)], (29)\nP\u0303j\u2192\u03b2(h) = P\u0303 (|V (j)|\u22121) j\u2192\u03b2 (h), (30)\nwhere \u03b4(h) = 1 if h = 0, and zero otherwise, and \u03b8(h) = 1 if h \u2265 0, and zero otherwise. The above equations take into account each neighbor of j excluding \u03b2, from \u03b3 = 1 to \u03b3 = |V (j)|\u22121. The penalties exp(\u22122y) are multiplied every time the value of hj\u2192\u03b2 decreases in absolute value, as each new neighbor of Xj , \u03b2\u03b3 , is added. At the end of the procedure, this is equivalent to multiplying the messages with a factor of exp(\u22122y\u00d7min(H+j\u2192\u03b2, H \u2212 j\u2192\u03b2)).\nThe P\u0303j\u2192\u03b2(h) are then normalized into Pj\u2192\u03b2(h) by computing P\u0303j\u2192\u03b2(h) for all possible values of h in [\u2212|V (j)|+ 1, |V (j)| \u2212 1]. The message updates for the surveys are as follows:\nW+j\u2192\u03b2 = |V (j)|\u22121\u2211 h=1 Pj\u2192\u03b2(h), (31)\nW\u2212j\u2192\u03b2 = \u22121\u2211\nh=\u2212|V (j)|+1 Pj\u2192\u03b2(h), (32)\n\u03b7 \u2212J\u03b2,i \u03b2\u2192i = 0, (33)\n\u03b7 J\u03b2,i \u03b2\u2192i = \u220f j\u2208V (j)\\i W J\u03b2,j j\u2192\u03b2, (34)\n\u03b70\u03b2\u2192i = 1\u2212 \u03b7 J\u03b2,i \u03b2\u2192i, (35)\nThe quantity W+j\u2192\u03b2 (resp. W \u2212 j\u2192\u03b2) is the probability of all events warning against the value +1 (resp. \u22121). Equation 34 reflects the fact that a warning is sent from \u03b2 to the variable Xi if and only if all other variables in \u03b2 are warning \u03b2 that they are going to violate \u03b2.\nWhen SP-y converges, the preference of each variable is calculated as follows:\nW+j = |V (j)|\u2211 h=1 Pj(h), (36)\nW\u2212j = \u22121\u2211\nh=\u2212|V (j)| Pj(h), (37)\nwhere the Pj(h) are calculated in a similar manner as the Pj\u2192\u03b2(h), except that it does not exclude \u03b2 in its calculations.\nWith the above definitions for message updates, the SP-y algorithm can be used to solve Max-SAT instances by a survey inspired decimation algorithm similar to the one for\nSP given in the algorithm in Figure 6. At each iteration of the decimation process, the SP-y decimation procedure selects variables to fix to their preferred values based on the quantity\nbfix(j) = |W+j \u2212W \u2212 j | (38)\nIn the work of Battaglia et al. (2004), an additional backtracking process was introduced to make the decimation process more robust. This backtracking process allows the decimation procedure to unfix variables already fixed to their values. For a variable Xj fixed to the value xj , the following quantities are calculated:\nbbacktrack(j) = \u2212xj(W+j \u2212W \u2212 j ) (39)\nVariables are ranked according to this quantity and the top variables are chosen to be unfixed. In the algorithm in Figure 7, we show the backtracking decimation algorithm for SP-y (Battaglia et al., 2004), where the value of y is either given as input, or can be determined empirically.\nINPUT: A Max-SAT instance and a constant k. Optional input: yin and a backtracking probability r.\nOUTPUT: A configuration.\nALGORITHM :"}, {"heading": "5. Relaxed Survey Propagation", "text": "It was shown (Maneva et al., 2004; Braunstein & Zecchina, 2004) that SP for the SAT problem can be reformulated as a BP algorithm on an extended factor graph. However, their formulation cannot be generalized to explain the SP-y algorithm which is applicable to Max-SAT problems. In a previous paper (Chieu & Lee, 2008), we extended the formulation in the work of Maneva et al. (2004) to address the Max-SAT problem. In this section, we will modify the formulation in our previous paper (Chieu & Lee, 2008) to address the weighted Max-SAT problem, by setting up an extended factor graph on which we run the BP algorithm. In Theorem 3, we show that this formulation generalizes the BP interpretation of SP given in the work of Maneva et al. (2004), and in the main theorem (Theorem 2), we show that running the loopy BP algorithm on this factor graph estimates marginals over covers of configurations violating a set of clauses with minimal total weight.\nWe will first define the concept of covers in Section 5.1, before defining the extended factor graph in Section 5.2. In the rest of this section, given a weighted Max-SAT problem (X,C,W), we will assume that variables in X take values in {\u22121,+1, \u2217}: the third value is a \u201cdon\u2019t care\u201d state, corresponding to a no-warning message for the SP algorithm defined in the Section 4."}, {"heading": "5.1 Covers in Weighted Max-SAT", "text": "First, we need to define the semantics of the value \u2217 as a \u201cdon\u2019t care\u201d state.\nDefinition 4. (Maneva et al., 2004) Given a configuration x, we say that a variable Xi is the unique satisfying variable for a clause \u03b2 \u2208 C if it is assigned s\u03b2,i whereas all other variables Xj in the clause are assigned u\u03b2,j (see Definition 2 for the definitions of s\u03b2,i and u\u03b2,i). A variable Xi is said to be constrained by the clause \u03b2 if it is the unique satisfying variable for \u03b2. A variable is unconstrained if it is not constrained by any clauses. Define\nCONi,\u03b2(x\u03b2) = Ind(xi is constrained by \u03b2), (40)\nwhere Ind(P ) equals 1 if the predicate P is true, and 0 otherwise.\nAs an illustration, consider the configuration X = (+1,\u22121,\u22121) in Example 2. In this configuration, X1 = +1 is constrained by the clauses \u03b25 and \u03b26, X2 = \u22121 is constrained by \u03b22, while X3 = \u22121 is unconstrained: flipping X3 to +1 will not violate any additional clauses for the configuration.\nIn the following definition, we redefine when a configuration taking values in {\u22121,+1, \u2217} satisfies or violates a clauses.\nDefinition 5. A configuration satisfies a clause \u03b2 if and only if (i) \u03b2 contains a variable Xi set to the value s\u03b2,i, or (ii) when at least two variables in \u03b2 take the value \u2217. A configuration violates a clause \u03b2 if all the variables Xj in \u03b2 are set to u\u03b2,j. A configuration x is invalid for clause \u03b2 if and only if exactly one of the variables in \u03b2 is set to \u2217, and all the other remaining variables in \u03b2 are set to u\u03b2,i. A configuration is valid if it is valid for all clauses in C.\nThe above definition for invalid configurations reflects the interpretation that the \u2217 value is a \u201cdon\u2019t care\u201d state: clauses containing a variable Xi = \u2217 should already be satisfied by\nother variables, and the value of Xi does not matter. So Xi = \u2217 cannot be the last remaining possibility of satisfying any clause. In the case where a clause contains two variables set to \u2217, the clause can be satisfied by either one of these two variables, so the other variable can take the \u201cdon\u2019t care\u201d value.\nWe define a partial order on the set of all valid configurations as follows (Maneva et al., 2004):\nDefinition 6. Let x and y be two valid configurations. We write x \u2264 y if \u2200i, (1) xi = yi or (2) xi = \u2217 and yi 6= \u2217.\nThis partial order defines a lattice, and Maneva et al. (2004) showed that SP is a \u201cpeeling\u201d procedure that peels a satisfying configuration to its minimal element in the lattice. A cover is a minimal element in the lattice. In the SAT region, a cover can be defined as follows (Kroc, Sabharwal, & Selman, 2007):\nDefinition 7. A cover is a valid configuration x \u2208 {\u22121,+1, \u2217}N that satisfies all clauses, and has no unconstrained variables assigned -1 or +1.\nThe SP algorithm was shown to return marginals over covers (Maneva et al., 2004). In principle, there are two kinds of covers: true covers which correspond to satisfying configurations, and false covers which do not. Kroc et al. (2007) showed empirically that the number of false covers is negligible for SAT instances. For RSP to apply to weighted Max-SAT instances, we introduce the notion of v-cover:\nDefinition 8. A v-cover is a valid configuration x \u2208 {\u22121,+1, \u2217}N such that\n1. the total weight of clauses violated by the configuration equals v,\n2. x has no unconstrained variables assigned -1 or +1.\nHence the covers defined in Definition 7 are simply v-covers with v = 0 (i.e. 0-covers)."}, {"heading": "5.2 The Extended Factor Graph", "text": "In this section, we will define a joint distribution over an extended factor graph that is positive only over v-covers. First, we will need to define functions that will be used to define the factors in the extended factor graph.\nDefinition 9. For each clause, \u03b2 \u2208 C, the following function assigns different values to configurations that satisfy, violate or are invalid (see Definition 5) for \u03b2:\nVAL\u03b2(xV (\u03b2)) =  1 if xV (\u03b2) satisfies \u03b2 exp(\u2212w\u03b2y) if xV (\u03b2) violates \u03b2 0 if xV (\u03b2) is invalid\n(41)\nIn the above definition, we introduced a parameter y in the RSP algorithm, which plays a similar role to the y in the SP-y algorithm. The term exp(\u2212w\u03b2y) is the penalty for violating a clause with weight w\u03b2.\nDefinition 10. (Maneva et al., 2004) Given a configuration x, we define the parent set Pi(x) of a variable Xi to be the set of clauses for which Xi = xi is the unique satisfying variable in a configuration x, (i.e. the set of clauses constraining Xi to its value). Formally,\nPi(x) = {\u03b2 \u2208 C|CONi,\u03b2(xV(\u03b2)) = 1} (42)\nIn Example 2, for the configuration x = (+1,\u22121,\u22121), the parent sets are P1(x) = {\u03b25, \u03b26}, P2(x) = {\u03b22}, and P3(x) = \u2205.\nGiven the weighted Max-SAT instance (X,C,W) and its factor graph, G = ({V, F}, E), we now construct another distribution with an associated factor graph Gs = ({V, Fs}, Es) as follows. For each i \u2208 V , let P (i) be the set of all possible parent sets of the variable Xi. Due to the restrictions imposed by our definition, Pi(x) must be contained in either V +(i) or V \u2212(i), but not both. Therefore, the cardinality of P (i) is 2|V +(i)|+2|V \u2212(i)|\u22121. Our extended factor graph is defined on set of the variables \u039b = (\u039b1,\u039b2, ...,\u039bn) \u2208 X1 \u00d7 X2 \u00d7 ... \u00d7 Xn, where Xi := {\u22121,+1, \u2217} \u00d7 P (i). Hence this factor graph has the same number of variables as the original SAT instance, but each variable has a large cardinality. Given configurations x for the SAT instance, we denote configurations of \u039b as \u03bb(x) = {\u03bbi(x)}i\u2208V , where \u03bbi(x) = (xi, Pi(x)).\nThe definitions given so far define the semantics of valid configurations and parent sets, and in the rest of this section, we will define factors in the extended factor graph Gs to ensure that the above definitions are satisfied by configurations of \u039b.\nThe single variable compatibilities (\u03a8i) are defined by the following factor on each variable \u03bbi(x):\n\u03a8i(\u03bbi(x) = {xi, Pi(x)}) =  0 if Pi(x) = \u2205, xi 6= \u2217 1 if Pi(x) = \u2205, xi = \u2217 1 for any other valid (xi, Pi(x)) . (43)\nThe first case in the above definition for Pi(x) = \u2205 and xi 6= \u2217 corresponds to the case where the variable Xi is unconstrained, and yet takes a value in {\u22121,+1}. Valid configurations that are not v-covers (with unconstrained variables set to \u22121 or +1) have a zero value in the above factor. Hence only v-covers have a positive value for these factors. In the last case in the above definition, the validity of (xi, Pi(x)) simply means that if xi = +1 (resp. xi = \u22121), Pi(x) \u2286 V +(i) (resp. Pi(x) \u2286 V \u2212(i).).\nThe clause compatibilities (\u03a8\u03b2) are:\n\u03a8\u03b2(\u03bb(x)V (\u03b2)) = VAL\u03b2(xV(\u03b2)) \u220f k\u2208V (\u03b2) Ind ( [\u03b2 \u2208 Pk(x)] = CON\u03b2,k(xV (\u03b2)) ) , (44)\nwhere Ind is defined in Definition 4. These clause compatibilities introduce the penalties in VAL\u03b2(xV (\u03b2)) into the joint distribution. The second term in the above equation enforces that the parent sets Pk(x) are consistent with the definitions of parent sets in Definition 10 for each variable Xk in the clause \u03b2.\nThe values of x determines uniquely the values of P = {Pi(x)}i\u2208V , and hence the distribution over \u03bb(x) = {xi, Pi(x)}i\u2208V is simply a distribution over x.\nTheorem 1. Using the notation UNSAT(x) to represent the set of all clauses violated by x, the underlying distribution p(\u039b) of the factor graph defined in this section is positive only\nover v-covers, and for a v-cover x, we have:\np(X = x) = p(\u039b = \u03bb(x)) \u221d \u220f\n\u03b2\u2208UNSAT(x) exp(\u2212w\u03b2y), (45)\nProof. Configurations that are not v-covers are either invalid or contains unconstrained variables set to \u22121 or +1. For invalid configurations, the distribution is zero because of the definition of VAL\u03b2, and for configurations with unconstrained variables set to \u22121 or +1, the distribution is zero due to the definition of the factors \u03c8i. For each v-cover, the total penalty from violated clauses is the product term in Equation 45.\nThe above definition defines a joint distribution over a factor graph. The RSP algorithm is a message passing algorithm defined on this factor graph:\nDefinition 11. The RSP algorithm is defined as the loopy BP algorithm applied to the extended factor graph Gs associated with a MaxSAT instance (X,C,W).\nIn Section 6, we will formulate the message passing updates for RSP, as well as a decimation algorithm for using RSP as a solver for weighted Max-SAT instances. As an example, Figure 8 shows the extended factor graph for the weighted Max-SAT instance defined in Example 1.\nDefinition 12. We define a min-cover for a weighted Max-SAT instance as the m-cover, where m is the minimum total weight of violated clauses for the instance.\nTheorem 2. When y is taken to \u221e, RSP estimates marginals over min-covers in the following sense: the stationary points of the RSP algorithm correspond to the stationary points of the Bethe free energy on a distribution that is uniform over min-covers.\nProof. The ratio of the probability of a v-cover to that of a (v + )-cover equals exp( y). When y is taken to \u221e, the distribution in Equation 45 is positive only over min-covers. Hence RSP, as the loopy BP algorithm over the factor graph representing Equation 45, estimates marginals over min-covers.\nIn the application of RSP to weighted Max-SAT instances, taking y to \u221e would often cause the RSP algorithm to fail to converge. Taking y to a sufficiently large value is often sufficient for RSP to be used to solve weighted Max-SAT instances.\nIn Figure 9, we show the v-covers of a small weighted Max-SAT example in Example 2. In this example, there is a unique min-cover with X1 = +1, X2 = \u22121, and X3 = \u2217.\nManeva et al. (2004) formulated the SP-\u03c1 algorithm, which is equivalent to the SP algorithm (Braunstein et al., 2005) for \u03c1 = 1. The SP-\u03c1 algorithm is the loopy BP algorithm on the extended factor graph defined in the work of Maneva et al. (2004). Comparing the definitions of the extended factor graph and factors for RSP and SP-\u03c1, we have (Chieu & Lee, 2008):\nTheorem 3. By taking y \u2192\u221e, RSP is equivalent to SP-\u03c1 with \u03c1 = 1.\nProof. The definitions of the joint distribution for SP-\u03c1 for \u03c1 = 1 (Maneva et al., 2004), and for RSP in this paper differ only in Definition 9, and with y \u2192 \u221e in RSP, their definitions become identical. Since SP-\u03c1 and RSP are both equivalent to the loopy BP on the distribution defined on their extended factor graphs, the equivalence of their joint distribution means that the algorithms are equivalent.\nTaking y to infinity corresponds to disallowing violated clauses, and SP-\u03c1 was formulated for satisfiable SAT instances, where all clauses must be satisfied. For SP-\u03c1, clause weights are inconsequential as all clauses have to be satisfied.\nIn this paper, we disallow unconstrained variables to take the value \u2217. In the Appendix A, we give an alternative definition for the single variable potentials in Equation 43. With\nthis definition, Maneva et al. (2004) defines a smoothing interpretation for SP-\u03c1. This smoothing can also be applied to RSP. See Theorem 6 in the work of Maneva et al. (2004) and the Appendix A for more details."}, {"heading": "5.3 The Importance of Convergence", "text": "It was found that message passing algorithms such as the BP and the SP algorithms perform well whenever they converge (e.g., see Kroc, Sabharwal, & Selman, 2009). While the success of the RSP algorithm on random ensembles of Max-SAT and weighted Max-SAT instances are believed to be due to the clustering phenomenon on such problems, we found that RSP could also be successful in cases where the clustering phenomenon is not observed. We believe that the presence of large clusters help the SP algorithm to converge well, but as long as the SP algorithm converges, the presence of clusters is not necessary for good performance.\nWhen covers are simply Boolean configurations (with no variables taking the \u2217 value), they represent singleton clusters. We call such covers degenerate covers. In many structured and non random weighted Max-SAT problems, we have found that the covers we found are often degenerate. In a previous paper (Chieu, Lee, & Teh, 2008), we have defined a modified version of RSP for energy minimization over factor graphs, and we show in Lemma 2 in that paper that configurations with * have zero probability, i.e. all covers are degenerate. In that paper, we showed that the value of y can be tuned to favor the convergence of the RSP algorithm.\nIn Section 7.3, we show the success of RSP on a few benchmark Max-SAT instances. In trying to recover the covers of the configurations found by RSP, we found that all the benchmark instances used have degenerate covers. The fact that RSP converged on these instances is sufficient for RSP to outperform local search algorithms."}, {"heading": "6. Using RSP for Solving the Weighted Max-SAT Problem", "text": "In the previous section, we defined the RSP algorithm in Definition 11 to be the loopy BP algorithm over the extended factor graph. In this section, we will derive the RSP message passing algorithm based on this definition, before giving the decimation-based algorithm used for solving weighted Max-SAT instances."}, {"heading": "6.1 The Message Passing Algorithm", "text": "The variables in the extended factor graphs are no longer Boolean. They are of the form \u03bbi(x) = (xi, Pi(x)), which are of large cardinalities. In the definition of the BP algorithm, we have stated that the message vector passed between factors and variables are of length equal to the cardinality of the variables. In this section, we show that the messages passed in RSP can be grouped into a few groups, so that each message passed between variables and factors has only three values.\nIn RSP, the factor to variable messages are grouped as follows:\nM s\u03b2\u2192i if xi = s\u03b2,i, Pi(x) = S \u222a {\u03b2}, where S \u2286 V s\u03b2 (i), (all cases where the variable xi is constrained by the clause \u03b2),\nMu\u03b2\u2192i if xi = u\u03b2,i, Pi(x) \u2286 V u\u03b2 (i), (all cases where the variable xi is constrained to be u\u03b2,i by other clauses),\nM s\u2217\u03b2\u2192i if xi = s\u03b2,i, Pi(x) \u2286 V s\u03b2 (i), (all cases where the variable xi = s\u03b2,i is not constrained by \u03b2. At least one other variable xj in \u03b2 satisfies \u03b2 or equals \u2217. Otherwise xi will be constrained),\nM\u2217\u2217\u03b2\u2192i if xi = \u2217, Pi(x) = \u2205.\nThe last two messages are always equal:\nM\u2217\u03b2\u2192i = M s\u2217 \u03b2\u2192i = M \u2217\u2217 \u03b2\u2192i.\nThis equality is due to the fact that for a factor that is not constraining its variables, it does not matter whether a variable is satisfying or is \u2217, as long as there are at least two variables that are either satisfying or is \u2217. In the following, we will consider the two equal messages as a single message, M\u2217\u03b2\u2192i.\nThe variable to factor messages are grouped as follows:\nRsi\u2192\u03b2:= \u2211 S\u2286V s \u03b2 (i)Mi\u2192a(s\u03b2,i, S \u222a {\u03b2}),\nVariable xi is constrained by \u03b2 to be s\u03b2,i,\nRui\u2192\u03b2:= \u2211 Pi(x)\u2286V u\u03b2 (i)\nMi\u2192a(u\u03b2,i, Pi(x)), Variable xi is constrained by other clauses to be u\u03b2,i,\nRs\u2217i\u2192\u03b2:= \u2211 Pi(x)\u2286V s\u03b2 (i)\nMi\u2192a(s\u03b2,i, Pi(x)), Variable xi is not constrained by \u03b2, but constrained by other clauses to be s\u03b2,i,\nR\u2217\u2217i\u2192\u03b2:= Mi\u2192\u03b2(\u2217, \u2205), Variable xi unconstrained and equals *.\nThe last two messages can again be grouped as one message (as was done in our previous paper, Chieu & Lee, 2008) as follows,\nR\u2217i\u2192\u03b2 = R s\u2217 i\u2192\u03b2 +R \u2217\u2217 i\u2192\u03b2,\nsince in calculating the updates of the M\u03b2\u2192j messages from the Ri\u2192\u03b2 messages, only R\u2217i\u2192\u03b2 is required. The update equations of RSP for weighted Max-SAT are given in Figure 10. These update equations are derived based on loopy BP updates in Equations 15 and 16 in Section 3. In the worst case in a densely connected factor graph, each iteration of updates can be performed in O(MN) time, where N is the number of variables, and M the number of clauses."}, {"heading": "6.1.1 Factor to Variable Messages", "text": "We will begin with the update equations for the messages from factors to variables, given in Equations 46, 47 and 48. The message M s\u03b2\u2192i groups cases where Xi is constrained by\nthe factor \u03b2. This means that all other variables in \u03b2 are violating the factor \u03b2, and hence we have Equation 46\nM s\u03b2\u2192i = \u220f\nj\u2208V (\u03b2)\\{i} Ruj\u2192\u03b2,\nwhere Ruj\u2192\u03b2 are messages from neighbors of \u03b2 stating that they will violate \u03b2. The next equation for Mu\u03b2\u2192i states that the variable Xi is violating \u03b2. In this case, the other variables in \u03b2 are in these possible cases\n1. Two or more variables in \u03b2 satisfying \u03b2, with the message update\u220f j\u2208V (\u03b2)\\{i} (Ruj\u2192\u03b2 +R \u2217 j\u2192\u03b2)\u2212 \u2211 k\u2208V (\u03b2)\\{i} R\u2217k\u2192\u03b2 \u220f j\u2208V (\u03b2)\\{i,k} Ruj\u2192\u03b2 \u2212 \u220f j\u2208V (\u03b2)\\{i} Ruj\u2192\u03b2.\n2. Exactly one variable in V (\u03b2)\\{i} constrained by \u03b2, and all other variables are violating \u03b2, with the message update\u2211\nk\u2208V (\u03b2)\\{i} Rsk\u2192\u03b2 \u220f j\u2208V (\u03b2)\\{i,k} Ruj\u2192\u03b2\n3. All other variables are violating \u03b2, and in this case, there is a penalty factor of exp(\u2212w\u03b2y), with the message update\nexp(\u2212w\u03b2y) \u220f\nj\u2208V (\u03b2)\\{i} Ruj\u2192\u03b2\nThe sum of these three cases result in Equation 48. The third update equation for M\u2217\u03b2\u2192i is for the case where the variable Xi is unconstrained by \u03b2, satisfying \u03b2 with s\u03b2,i (for the case M s\u2217\u03b2\u2192i) or \u2217 (for M\u2217\u2217\u03b2\u2192i). This means that there is at least one other satisfying variable that is unconstrained by \u03b2, with the message update \u220f\nj\u2208V (\u03b2)\\{i} (Ruj\u2192\u03b2 +R \u2217 j\u2192\u03b2)\u2212 \u220f j\u2208V (\u03b2)\\{i} Ruj\u2192\u03b2"}, {"heading": "6.1.2 Variable to Factor Messages", "text": "The first message Rsi\u2192\u03b2 consists of the case where the variable Xi is constrained by the factor \u03b2, which means that it satisfies neighboring factors in V s\u03b2 (i), and violates factors in V u\u03b2 (i), with probability\n\u220f \u03b3\u2208V u\n\u03b2 (i)\nMu\u03b3\u2192i  \u220f \u03b3\u2208V s\n\u03b2 (i)\n(M s\u03b3\u2192i +M s\u2217 \u03b3\u2192i)  . The second message Rui\u2192\u03b2 is the case where Xi violates \u03b2. In this case, all other variables in V u\u03b2 (i) are satisfied, while clauses in V s \u03b2 (i) are violated. In this case, the variable Xi must\nbe constrained by one of the clauses in V u\u03b2 (i). Hence the message update is\n\u220f \u03b3\u2208V s\n\u03b2 (i)\nMu\u03b3\u2192i  \u220f \u03b3\u2208V u\n\u03b2 (i)\n(M s\u03b3\u2192i +M s\u2217 \u03b3\u2192i)\u2212 \u220f \u03b3\u2208V u\n\u03b2 (i)\nM s\u2217\u03b3\u2192i  The third message R\u2217i\u2192\u03b2 is the sum of two messages R s\u2217 i\u2192\u03b2 and R \u2217\u2217 i\u2192\u03b2. For the message Rs\u2217i\u2192\u03b2, the variable Xi satisfies \u03b2 but is not constrained by \u03b2, and so it must be constrained by some other factors:\n\u220f \u03b3\u2208V u\n\u03b2 (i)\nMu\u03b3\u2192i  \u220f \u03b3\u2208V s\n\u03b2 (i)\n(M s\u03b3\u2192i +M s\u2217 \u03b3\u2192i)\u2212 \u220f \u03b3\u2208V s\n\u03b2 (i)\nM s\u2217\u03b3\u2192i  The second part of the message, R\u2217\u2217i\u2192\u03b2, is the case where Xi = \u2217, :\u220f\n\u03b3\u2208V s \u03b2 (i)\u222aV u \u03b2 (i)\nM\u2217\u2217\u03b3\u2192i,\nand the sum of the above two equations results in Equation 51."}, {"heading": "6.1.3 The Beliefs", "text": "The beliefs can be calculated from the factor to variable messages once the algorithm converges, to obtain estimates of the marginals over min-covers. The calculation of the beliefs is similar to the calculation of the variable to factor messages.\nThe belief Bi(\u22121) is the belief or the variable Xi taking the value \u22121. This is the case where the variable Xi satisfies clauses in V \u2212(i), and violates clauses in V +(i). In this case, Xi must be constrained by one of the factors in V \u2212(i). Hence the belief is as follows:\n\u220f \u03b2\u2208V +(i) Mu\u03b2\u2192i  \u220f \u03b2\u2208V \u2212(i) (M s\u03b2\u2192i +M s\u2217 \u03b2\u2192i)\u2212 \u220f \u03b2\u2208V \u2212(i) M s\u2217\u03b2\u2192i  . The calculation of the belief Bi(+1) is similar to Bi(\u22121). The belief Bi(\u2217) is the case where Xi = \u2217, and hence it is calculated as follows:\u220f\n\u03b2\u2208V (i)\nM\u2217\u2217\u03b2\u2192i.\n6.2 Comparing the RSP and SP-y Message Passing Algorithms\nThe message passing algorithms for RSP and SP-y share many similarities. Both algorithms\n1. include a multiplicative penalty into the distribution for each violated clause.\n2. contain a mechanism for a \u201cdon\u2019t care\u201d state. For SP-y, this occurs when a variable receives no warnings from neighboring factors.\nHowever, there are a number of significant differences in the two algorithms.\n1. In RSP, the penalties are imposed as each factor passes a message to a variable. For SP-y, the penalties are imposed when a variable compiles all the incoming warnings, and decides how many factors it is going to violate.\n2. Importantly, in RSP, variables participating in violated clauses can never take the * value. For SP-y, a variable receiving an equal number of warnings from the set of factors {\u03b2\u2032}\u03b2\u2032\u2208V (i)\\\u03b2 against taking the +1 and the \u22121 value (i.e. hj\u2192\u03b2 = H+j\u2192\u03b2 \u2212 H\u2212j\u2192\u03b2 = 0) will decide to pass a message with no warning to \u03b2. Hence for SP-y, it is possible for variables in violated clauses to take a \u201cdon\u2019t care\u201d state.\n3. In the work of Battaglia et al. (2004) where SP-y was formulated with the cavity approach, it was found that the optimal value of y for a given Max-SAT problem is y\u2217 = \u03b4\u03a3\u03b4e , where \u03a3 is the complexity in statistical physics, and e is the energy density (Mezard & Zecchina, 2002). They stated that y\u2217 is a finite value when the energy of the Max-SAT problem is not zero. In Theorem 2, we show that for RSP, y should be as large as possible so that the underlying distribution is over min-covers. In our experimental results in Figure 12, we showed that this is indeed true for RSP, as long as it converges.\nINPUT: A (weighted) Max-SAT instance, a constant k, and yin\nOUTPUT: A configuration.\nALGORITHM :"}, {"heading": "6.3 The Decimation Algorithm", "text": "The decimation algorithm is shown in Figure 11. This is the algorithm we used for our experiments described in Section 7. In comparing RSP with SP-y on random Max-SAT instances in Section 7.1, we run both algorithms with a fixed yin, and vary the yin over a range of values. Comparing Figure 11 to Figure 7 for SP-y, the condition used in SPy to check for a paramagnetic solution is replaced by the condition given in Step (2) in Figure 11. In the experimental results in Section 7.1, we used the SP-y implementation\navailable online (Battaglia et al., 2004), which contains a mechanism for backtracking on decimation decisions (see Figure 7). In Section 7.1, RSP still outperforms SP-y despite not backtracking on its decisions. When running RSP on weighted Max-SAT, we found that it was necessary to adjust y dynamically during the decimation process. For details on experimental settings, please refer to Section 7."}, {"heading": "7. Experimental Results", "text": "We run experiments on random Max-3-SAT, random weighted Max-SAT, as well as on a few benchmark Max-SAT instances used in the work of Lardeux, Saubion, and Hao (2005).\n."}, {"heading": "7.1 Random Max-3-SAT", "text": "We run experiments on randomly generated Max-3-SAT instances of 104 variables, with different clause-to-variable ratios. The random instances are generated by the SP-y code available online (Battaglia et al., 2004). In Figure 12, we compare SP-y and RSP on random Max-3-SAT with different clause-to-variable ratio, \u03b1. We vary \u03b1 from 4.2 to 5.2 to show the performance of SP-y and RSP in the UNSAT region of 3-SAT, beyond its phase transition at \u03b1c \u2248 4.267. For each value of \u03b1, the number of violated clauses (y-axis) is plotted against the value of y used.\nWe perform the decimation procedure in Figure 11 for RSP, for a fixed value of yin, decimating 100 variables at a time (i.e. k = 100). For SP-y, we run the SP-y code available on line, with the option of decimating 100 variables at each iteration, and with two different settings: with and without backtracking (Battaglia et al., 2004). Backtracking is a procedure used in SP-y to improve performance, by unfixing previously fixed variables at a rate r = 0.2, so that errors made by the decimation process can be corrected. For RSP, we do not run backtracking. Note that the y in our formulation equals to 2y in the formulation in the work of Battaglia et al. (Battaglia et al., 2004).\nBoth SP-y and RSP fail to converge when y becomes large enough. When this happens, the output of the algorithm is the result returned by WalkSAT on the original instance. In Figure 12, we see this happening when a curve reaches a horizontal line, signifying that the algorithm is returning the same configuration regardless of y (we \u201cseed\u201d the randomized WalkSAT so that results are identical when instances are identical). From Figure 12, we see RSP performs more consistently than SP-y: as y increases, the performance of RSP improves, until a point where RSP fails to converge. Interestingly for Max-3-SAT instances, we observed that once RSP converges for a value of y for a given instance, it will continue to converge for the same value of y throughout the decimation process. Hence, the best value of y for RSP is obtainable without going through the decimation process: we can commence decimation at the largest value of y for which RSP converges. In Table 1, we show that RSP outperforms SP-y for \u03b1 \u2265 4.7, despite the fact that we did not allow backtracking for RSP. We also compare RSP and SP-y with the local search solvers implemented in UBCSAT (Tompkins & Hoos, 2004). We run 1000 iterations of each of the 20 Max-SAT solvers in UBCSAT, and take the best result among the 20 solvers. The results are shown in Table 1. We see that the local solvers in UBCSAT does worse than both RSP and SP-y. We have also tried running complete solvers such as toolbar (de Givry, Heras, Zytnicki, & Larrosa, 2005) and maxsatz (Li, Manya\u0300, & Planes, 2006). They are unable to deal with instances of size 104."}, {"heading": "7.2 Random Weighted Max-3-SAT", "text": "We have also run experiments on randomly generated weighted Max-3-SAT instances. These instances are generated in the same way as the instances for Max-3-SAT, and in addition, the weights of each clause is uniformly sampled as integers in the set [1,M ], where M is the upper bound on the weights. We show the experimental results for M = 5 and M = 10 in Figure 13. We compare RSP with the 13 weighted Max-SAT solvers implemented in UBCSAT. For RSP, we run all our experiments with an initial y set to 10, and whenever the algorithm fails to converge, we lower the value of y by 1, or halve the value of y if y is less than 1 (see Figure 11). We see that RSP outperforms UBCSAT consistently in all experiments in Figure 13."}, {"heading": "7.3 Benchmark Max-SAT Instances", "text": "We compare RSP with UBCSAT on instances used in the work of Lardeux et al. (2005), which were instances used in the SAT 2003 competition. Among the 27 instances, we use the seven largest instances with more than 7000 variables. We run RSP in two settings: decimating either 10 or 100 variables at a time. We run RSP for increasing values of y: for\neach y, RSP fixes a number of spins, and we stop increasing y when the number of spins fixed decreases over the previous value of y. For UBCSAT, we run 1000 iterations for each of the 20 solvers. Results are shown in Table 2. Out of the seven instances, RSP fails to fix any spins on the first one, but outperforms UBCSAT on the rest. Lardeux et al. (2005) did not show best performances in their paper, but their average results were an order of magnitude higher than results in Table 2. Figure 12 shows that finding a good y for SP-y is hard. On the benchmark instances, we run SP-y with the \u201c-Y\u201d option (Battaglia et al., 2004) that uses dichotomic search for y: SP-y failed to fix any spins on all 7 instances.\nThe success of the SP family of algorithms on random ensembles of SAT or Max-SAT problem are usually due to the clustering phenomenon on such random ensembles. As the benchmark instances are not random instances, we attempted to see if the configurations found by RSP do indeed belong to a cover representing a cluster of solutions. Rather disappointingly, we found that for all 6 solutions where RSP outperformed local search algorithms, the variables in the solutions are all constrained by at least one clause. Hence, the v-covers found are degenerate covers, i.e. the covers do not contain variables set to \u2217. It appears that the success of RSP on these benchmark instances is not due to the clustering phenomenon, but simply because RSP manages to converge for these instances, for some value of y. Kroc, Sabharwal, and Selman (2009) made a similar observation: the convergence of BP or SP like algorithms is often sufficient for obtaining a good solution to a given problem. As discussed in Section 5.3, the ability to vary y to improve convergence is a useful feature of RSP, but one that is distinct from its ability to exploit the clustering phenomenon."}, {"heading": "8. Conclusion", "text": "While recent work on Max-SAT or weighted Max-SAT tends to focus more on complete solvers, these solvers are unable to handle large instances. In the Max-SAT competition 2007 (Argelich, Li, Manya, & Planes, 2007), the largest Max-3-SAT instances used have only 70 variables. For large instances, complete solvers are still not practical, and local search procedures have been the only feasible alternative. SP-y, generalizing SP, has been shown to be able to solve large Max-3-SAT instances at its phase transition, but lacks the theoretical explanations that recent work on SP has generated.\nFor 3-SAT, there is an easy-hard-easy transition as the clause-to-variable ratio increases. For Max-3-SAT, however, it has been shown empirically that beyond the phase transition of satisfiability, all instances are hard to solve (Zhang, 2001). In this paper, we show that\nRSP outperforms SP-y as well as other local search algorithms on Max-SAT and weighted Max-SAT instances, well beyond the phase transition region.\nBoth RSP and SP-y do well on Max-SAT instances near the phase transition. The mechanisms behind SP-y and RSP are similar: both algorithms impose a penalty term for each violated constraint, and both reduce to SP when y \u2192 \u221e. SP-y uses a population dynamics algorithm, which can also be seen as a warning propagation algorithm. In this paper, we have formulated the RSP algorithm as a BP algorithm over an extended factor graph, enabling us to understand RSP as estimating marginals over min-covers."}, {"heading": "Acknowledgments", "text": "This work is supported in part by NUS ARF grant R-252-000-240-112."}, {"heading": "Appendix A. Smoothing Interpretation for RSP", "text": "In the definition of SP-\u03c1 (Maneva et al., 2004), the parameter \u03c1 was introduced to define a whole family of algorithms. For \u03c1 = 1, the SP-\u03c1 algorithm corresponds to the SP algorithm, while for \u03c1 = 0, the SP-\u03c1 algorithm corresponds to the BP algorithm. In this section, we develop a more general version of the extended factor graph defined in Section 5, that incorporates the \u03c1 in SP-\u03c1. We will call the corresponding RSP algorithm on this new factor graph the RSP-\u03c1 algorithm.\nThe only difference between the factor graph for RSP-\u03c1 and the one in Section 5 is the definition of the variable compatibilities in Equation 43. Following notations in the work of Maneva et al. (2004), we introduce the parameters \u03c90 and \u03c9\u2217, and we restrict ourselves to the case where \u03c90 + \u03c9\u2217 = 1 (The \u03c1 in SP-\u03c1 or RSP-\u03c1 is equal to \u03c9\u2217). We redefine the variable compatibilities as follows\n\u03a8i(\u03bbi(x) = {xi, Pi(x)}) =  \u03c90 if Pi(x) = \u2205, xi 6= \u2217 \u03c9\u2217 if Pi(x) = \u2205, xi = \u2217 1 for any other valid (xi, Pi(x)) , (55)\nwith \u03c90 + \u03c9\u2217 = 1. The definition in Equation 43 corresponds to the particular case where \u03c90 = 0 and \u03c9\u2217 = 1. In Section 5, we have defined the factor graph so that unconstrained variables must take the value \u2217. With the new definition of \u03a8i above, unconstrained variables are allowed to take on the values \u22121 or +1 with weight \u03c90, and the \u2217 value with weight \u03c9\u2217.\nWith the above definition, the joint distribution in Equation 45 is redefined as follows:\nP (x) = P ({xk, Pk}k) \u221d \u03c9 n0(x) 0 \u03c9 n\u2217(x) \u2217 \u220f \u03b2\u2208UNSAT(x) exp(\u2212w\u03b2y). (56)\nwhere n0(x) is the number of unconstrained variables in x taking +1 or \u22121, and n\u2217(x) the number of unconstrained variables taking \u2217 in x.\nCase \u03c9\u2217 = 1: we have studied this case in the main paper: the underlying distribution is a distribution which is positive only over v-covers.\nCase \u03c9\u2217 = 0: in this case, only configurations x with n\u2217(x) = 0 have non-zero probability in the distribution given in Equation 56. Hence, the value \u2217 is forbidden, and all variables take values in \u22121,+1. A Boolean configuration violating clauses with total weight W has a probability proportional to exp(\u2212yW ). Hence we retreive the weighted Max-SAT energy defined in Equation 13. In this case, the factor graph is equivalent to the original weighted Max-SAT factor graph defined in Definition 3, and hence RSP-\u03c1 is equivalent to the loopy BP algorithm on the original weighted Max-SAT problem.\nCase \u03c9\u2217 6= 1 and \u03c9\u2217 6= 0: in this case, all valid configurations x violating clauses with a total weight W has a probability proportional to \u03c9n0(x)0 \u03c9 n\u2217(x) \u2217 exp(\u2212yW ). Hence, the probability of v-covers in the case where \u03c9\u2217 = 1 are spread over the lattice for which it is the minimal element.\nWith the above formulation, RSP-\u03c1 can be seen as a family of algorithms that include the BP and the RSP algorithm, moving from BP to RSP as \u03c1 (or \u03c9\u2217) varies from 0 to 1."}], "references": [{"title": "Rigorous location of phase transitions in hard optimization problems", "author": ["D. Achlioptas", "A. Naor", "Y. Peres"], "venue": "Nature,", "citeRegEx": "Achlioptas et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Achlioptas et al\\.", "year": 2005}, {"title": "Second evaluation of max-sat solvers", "author": ["J. Argelich", "C.M. Li", "F. Manya", "J. Planes"], "venue": "Tenth International Conference on Theory and Applications of Satisfiability Testing", "citeRegEx": "Argelich et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Argelich et al\\.", "year": 2007}, {"title": "Minimizing energy below the glass thresholds", "author": ["D. Battaglia", "M. Kolar", "R. Zecchina"], "venue": "Physical Review E,", "citeRegEx": "Battaglia et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Battaglia et al\\.", "year": 2004}, {"title": "The essentials of the SAT 2003 competition", "author": ["D.L. Berre", "L. Simon"], "venue": "Sixth International Conference on Theory and Applications of Satisfiability Testing", "citeRegEx": "Berre and Simon,? \\Q2003\\E", "shortCiteRegEx": "Berre and Simon", "year": 2003}, {"title": "Special volume on the SAT 2005 competitions and evaluations", "author": ["D.L. Berre", "L. Simon"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation,", "citeRegEx": "Berre and Simon,? \\Q2005\\E", "shortCiteRegEx": "Berre and Simon", "year": 2005}, {"title": "Survey propagation: An algorithm for satisfiability", "author": ["A. Braunstein", "M. Mezard", "R. Zecchina"], "venue": "Random Structures and Algorithms,", "citeRegEx": "Braunstein et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Braunstein et al\\.", "year": 2005}, {"title": "Survey propagation as local equilibrium equations", "author": ["A. Braunstein", "R. Zecchina"], "venue": "Journal of Statistical Mechanics: Theory and Experiment,", "citeRegEx": "Braunstein and Zecchina,? \\Q2004\\E", "shortCiteRegEx": "Braunstein and Zecchina", "year": 2004}, {"title": "Learning by message-passing in networks of discrete synapses", "author": ["A. Braunstein", "R. Zecchina"], "venue": "Physical Review Letters,", "citeRegEx": "Braunstein and Zecchina,? \\Q2006\\E", "shortCiteRegEx": "Braunstein and Zecchina", "year": 2006}, {"title": "Relaxed survey propagation: a sum-product algorithm for Max-SAT", "author": ["H.L. Chieu", "W.S. Lee"], "venue": "In AAAI\u201908: Twenty-Third AAAI Conference on Artificial Intelligence", "citeRegEx": "Chieu and Lee,? \\Q2008\\E", "shortCiteRegEx": "Chieu and Lee", "year": 2008}, {"title": "Cooled and relaxed survey propagation for MRFs", "author": ["H.L. Chieu", "W.S. Lee", "Y.W. Teh"], "venue": "In NIPS\u201907: Advances in Neural Information Processing Systems", "citeRegEx": "Chieu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Chieu et al\\.", "year": 2008}, {"title": "The complexity of theorem-proving procedures", "author": ["S.A. Cook"], "venue": "Third annual ACM symposium on Theory of computing,", "citeRegEx": "Cook,? \\Q1971\\E", "shortCiteRegEx": "Cook", "year": 1971}, {"title": "The computational complexity of probabilistic inference using bayesian belief networks (research note)", "author": ["G.F. Cooper"], "venue": "Artif. Intell.,", "citeRegEx": "Cooper,? \\Q1990\\E", "shortCiteRegEx": "Cooper", "year": 1990}, {"title": "Pairs of sat-assignments in random boolean formul\u00e6", "author": ["H. Daud\u00e9", "M. M\u00e9zard", "T. Mora", "R. Zecchina"], "venue": "Theor. Comput. Sci.,", "citeRegEx": "Daud\u00e9 et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Daud\u00e9 et al\\.", "year": 2008}, {"title": "A machine program for theorem-proving", "author": ["M. Davis", "G. Logemann", "D. Loveland"], "venue": "Commun. ACM,", "citeRegEx": "Davis et al\\.,? \\Q1962\\E", "shortCiteRegEx": "Davis et al\\.", "year": 1962}, {"title": "A computing procedure for quantification theory", "author": ["M. Davis", "H. Putnam"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Davis and Putnam,? \\Q1960\\E", "shortCiteRegEx": "Davis and Putnam", "year": 1960}, {"title": "Existential arc consistency: Getting closer to full arc consistency in weighted CSPs", "author": ["S. de Givry", "F. Heras", "M. Zytnicki", "J. Larrosa"], "venue": "In IJCAI\u201905: Nineteenth International Joint Conference on Artificial Intelligence", "citeRegEx": "Givry et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Givry et al\\.", "year": 2005}, {"title": "A backbone-search heuristic for efficient solving of hard 3SAT formulae", "author": ["O. Dubois", "G. Dequen"], "venue": "In IJCAI\u201905: Seventeenth International Joint Conference on Artificial Intelligence,", "citeRegEx": "Dubois and Dequen,? \\Q2001\\E", "shortCiteRegEx": "Dubois and Dequen", "year": 2001}, {"title": "MiniSat - a SAT solver with conflict-clause minimization", "author": ["N. Een", "N. S\u00f6rensson"], "venue": "Eighth International Conference on Theory and Applications of Satisfiability Testing", "citeRegEx": "Een and S\u00f6rensson,? \\Q2005\\E", "shortCiteRegEx": "Een and S\u00f6rensson", "year": 2005}, {"title": "An adaptive noise mechanism for walksat", "author": ["H.H. Hoos"], "venue": "In AAAI\u201902: Eighteenth National Conference on Artificial Intelligence,", "citeRegEx": "Hoos,? \\Q2002\\E", "shortCiteRegEx": "Hoos", "year": 2002}, {"title": "The probabilistic analysis of a greedy satisfiability algorithm", "author": ["A.C. Kaporis", "L.M. Kirousis", "E.G. Lalas"], "venue": "Random Structures and Algorithms,", "citeRegEx": "Kaporis et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kaporis et al\\.", "year": 2006}, {"title": "Optimization by simulated annealing", "author": ["S. Kirkpatrick", "C.D.G. Jr.", "M.P. Vecchi"], "venue": null, "citeRegEx": "Kirkpatrick et al\\.,? \\Q1983\\E", "shortCiteRegEx": "Kirkpatrick et al\\.", "year": 1983}, {"title": "Approximating the unsatisfiability threshold of random formulas", "author": ["L.M. Kirousis", "E. Kranakis", "D. Krizanc", "Y.C. Stamatiou"], "venue": "Random Structures and Algorithms,", "citeRegEx": "Kirousis et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Kirousis et al\\.", "year": 1998}, {"title": "Survey propagation revisited", "author": ["L. Kroc", "A. Sabharwal", "B. Selman"], "venue": "In UAI\u201907: Twenty-Third Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "Kroc et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kroc et al\\.", "year": 2007}, {"title": "Message-passing and local heuristics as decimation strategies for satisfiability", "author": ["L. Kroc", "A. Sabharwal", "B. Selman"], "venue": "In SAC-09. 24th Annual ACM Symposium on Applied Computing", "citeRegEx": "Kroc et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kroc et al\\.", "year": 2009}, {"title": "Factor graphs and the sum-product algorithm", "author": ["F.R. Kschischang", "B. Frey", "Loeliger", "H.-A"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Kschischang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Kschischang et al\\.", "year": 2001}, {"title": "Three truth values for the SAT and MAXSAT problems", "author": ["F. Lardeux", "F. Saubion", "Hao", "J.-K"], "venue": "In IJCAI\u201905: Nineteenth International Joint Conference on Artificial Intelligence", "citeRegEx": "Lardeux et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Lardeux et al\\.", "year": 2005}, {"title": "Resolution in Max-SAT and its relation to local consistency in weighted CSPs", "author": ["J. Larrosa", "F. Heras"], "venue": "In IJCAI\u201905: Nineteenth International Joint Conference on Artificial Intelligence", "citeRegEx": "Larrosa and Heras,? \\Q2005\\E", "shortCiteRegEx": "Larrosa and Heras", "year": 2005}, {"title": "Universal search problems", "author": ["L.A. Levin"], "venue": "Problemy Peredaci Informacii,", "citeRegEx": "Levin,? \\Q1973\\E", "shortCiteRegEx": "Levin", "year": 1973}, {"title": "Heuristics based on unit propagation for satisfiability problems", "author": ["C.M. Li"], "venue": "In IJCAI\u201997: Fifteenth International Joint Conference on Artificial Intelligence,", "citeRegEx": "Li,? \\Q1997\\E", "shortCiteRegEx": "Li", "year": 1997}, {"title": "Detecting disjoint inconsistent subformulas for computing lower bounds for max-sat", "author": ["C.M. Li", "F. Many\u00e0", "J. Planes"], "venue": "In AAAI\u201906: Twenty-First AAAI Conference on Artificial Intelligence", "citeRegEx": "Li et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Li et al\\.", "year": 2006}, {"title": "A new look at survey propagation and its generalizations. http://arxiv.org/abs/cs.CC/0409012", "author": ["E. Maneva", "E. Mossel", "M. Wainwright"], "venue": null, "citeRegEx": "Maneva et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Maneva et al\\.", "year": 2004}, {"title": "Evidence for invariants in local search", "author": ["D. McAllester", "B. Selman", "H. Kautz"], "venue": "Proceedings of the Fourteenth National Conference on Artificial Intelligence,", "citeRegEx": "McAllester et al\\.,? \\Q1997\\E", "shortCiteRegEx": "McAllester et al\\.", "year": 1997}, {"title": "Clustering of solutions in the random satisfiability problem", "author": ["M. Mezard", "T. Mora", "R. Zecchina"], "venue": "Physical Review Letters,", "citeRegEx": "Mezard et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Mezard et al\\.", "year": 2005}, {"title": "The cavity method at zero temperature", "author": ["M. Mezard", "G. Parisi"], "venue": "Journal of Statistical Physics,", "citeRegEx": "Mezard and Parisi,? \\Q2003\\E", "shortCiteRegEx": "Mezard and Parisi", "year": 2003}, {"title": "The random k-satisfiability problem: from an analytic solution to an efficient algorithm", "author": ["M. Mezard", "R. Zecchina"], "venue": "Physical Review E,", "citeRegEx": "Mezard and Zecchina,? \\Q2002\\E", "shortCiteRegEx": "Mezard and Zecchina", "year": 2002}, {"title": "Minimizing conflicts: a heuristic repair method for constraint satisfaction and scheduling problems", "author": ["S. Minton", "A. Philips", "M.D. Johnston", "P. Laird"], "venue": "Artificial Intelligence,", "citeRegEx": "Minton et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Minton et al\\.", "year": 1992}, {"title": "Chaff: Engineering an efficient SAT solver", "author": ["M.W. Moskewicz", "C.F. Madigan"], "venue": "In DAC\u201901: Thirty-Ninth Design Automation Conference,", "citeRegEx": "Moskewicz and Madigan,? \\Q2001\\E", "shortCiteRegEx": "Moskewicz and Madigan", "year": 2001}, {"title": "Loopy belief propagation for approximate inference: An empirical study", "author": ["K. Murphy", "Y. Weiss", "M. Jordan"], "venue": "In UAI\u201999: Fifteenth Annual Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Murphy et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Murphy et al\\.", "year": 1999}, {"title": "Probabilistic reasoning in intelligent systems: networks of plausible inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1988\\E", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Rsat 2.0: Sat solver description", "author": ["K. Pipatsrisawat", "A. Darwiche"], "venue": "Tech. rep.,", "citeRegEx": "Pipatsrisawat and Darwiche,? \\Q2007\\E", "shortCiteRegEx": "Pipatsrisawat and Darwiche", "year": 2007}, {"title": "Local search on sat-encoded colouring problems", "author": ["S.D. Prestwich"], "venue": "SAT, Vol. 2919 of Lecture Notes in Computer Science,", "citeRegEx": "Prestwich,? \\Q2003\\E", "shortCiteRegEx": "Prestwich", "year": 2003}, {"title": "Fundamentals of Speech Recognition", "author": ["L. Rabiner", "B. Juang"], "venue": null, "citeRegEx": "Rabiner and Juang,? \\Q1993\\E", "shortCiteRegEx": "Rabiner and Juang", "year": 1993}, {"title": "Noise strategies for improving local search", "author": ["B. Selman", "H.A. Kautz", "B. Cohen"], "venue": "In AAAI\u201997: Twelfth National Conference on Artificial Intelligence,", "citeRegEx": "Selman et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Selman et al\\.", "year": 1994}, {"title": "A new method for solving hard satisfiability problems", "author": ["B. Selman", "H.J. Levesque", "D. Mitchell"], "venue": "Tenth National Conference on Artificial Intelligence,", "citeRegEx": "Selman et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Selman et al\\.", "year": 1992}, {"title": "A discrete lagrangian-based global-searchmethod for solving satisfiability problems", "author": ["Y. Shang", "B.W. Wah"], "venue": "Journal of Global Optimization,", "citeRegEx": "Shang and Wah,? \\Q1998\\E", "shortCiteRegEx": "Shang and Wah", "year": 1998}, {"title": "UBCSAT: An implementation and experimentation environment for SLS algorithms for SAT and MAX-SAT", "author": ["D. Tompkins", "H. Hoos"], "venue": "Seventh International Conference on Theory and Applications of Satisfiability Testing", "citeRegEx": "Tompkins and Hoos,? \\Q2004\\E", "shortCiteRegEx": "Tompkins and Hoos", "year": 2004}, {"title": "On the complexity of derivations in the propositional calculus", "author": ["G.S. Tseitin"], "venue": "Studies in Mathematics and Mathematical Logic,", "citeRegEx": "Tseitin,? \\Q1968\\E", "shortCiteRegEx": "Tseitin", "year": 1968}, {"title": "Generalized belief propagation", "author": ["J. Yedidia", "W. Freeman", "Y. Weiss"], "venue": "In NIPS\u201900: Advances in Neural Information Processing Systems", "citeRegEx": "Yedidia et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Yedidia et al\\.", "year": 2001}, {"title": "Constructing free-energy approximations and generalized belief propagation algorithms", "author": ["J. Yedidia", "W. Freeman", "Y. Weiss"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Yedidia et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Yedidia et al\\.", "year": 2005}, {"title": "Phase transitions and backbones of 3-SAT and maximum 3-SAT", "author": ["W. Zhang"], "venue": "In Proceedings of the Seventh International Conference on Principles and Practice of Constraint Programming", "citeRegEx": "Zhang,? \\Q2001\\E", "shortCiteRegEx": "Zhang", "year": 2001}], "referenceMentions": [{"referenceID": 38, "context": "Braunstein and Zecchina (2004) first showed that SP can be viewed as the belief propagation (BP) algorithm (Pearl, 1988) on a related factor graph where only clusters of solutions represented by covers have non-zero probability.", "startOffset": 107, "endOffset": 120}, {"referenceID": 6, "context": "Braunstein and Zecchina (2004) first showed that SP can be viewed as the belief propagation (BP) algorithm (Pearl, 1988) on a related factor graph where only clusters of solutions represented by covers have non-zero probability.", "startOffset": 0, "endOffset": 31}, {"referenceID": 38, "context": "In Section 3, we give a review of the BP algorithm (Pearl, 1988), which plays a central role in this paper.", "startOffset": 51, "endOffset": 64}, {"referenceID": 5, "context": "In Section 4, we give a description of the SP (Braunstein et al., 2005) and the SP-y (Battaglia et al.", "startOffset": 46, "endOffset": 71}, {"referenceID": 2, "context": ", 2005) and the SP-y (Battaglia et al., 2004) algorithm, explaining them as warning propagation algorithms.", "startOffset": 21, "endOffset": 45}, {"referenceID": 2, "context": ", 2005) and the SP-y (Battaglia et al., 2004) algorithm, explaining them as warning propagation algorithms. In Section 5, we define a joint distribution over an extended factor graph given a weighted Max-SAT instance. This factor graph generalizes the factor graph defined by Maneva, Mossel and Wainwright (2004) and by Chieu and Lee (2008).", "startOffset": 22, "endOffset": 313}, {"referenceID": 2, "context": ", 2005) and the SP-y (Battaglia et al., 2004) algorithm, explaining them as warning propagation algorithms. In Section 5, we define a joint distribution over an extended factor graph given a weighted Max-SAT instance. This factor graph generalizes the factor graph defined by Maneva, Mossel and Wainwright (2004) and by Chieu and Lee (2008). We show that, for solving SAT instances, running the BP algorithm on this factor graph is equivalent to running the SP algorithm derived by Braunstein, Mezard and Zecchina (2005).", "startOffset": 22, "endOffset": 341}, {"referenceID": 2, "context": ", 2005) and the SP-y (Battaglia et al., 2004) algorithm, explaining them as warning propagation algorithms. In Section 5, we define a joint distribution over an extended factor graph given a weighted Max-SAT instance. This factor graph generalizes the factor graph defined by Maneva, Mossel and Wainwright (2004) and by Chieu and Lee (2008). We show that, for solving SAT instances, running the BP algorithm on this factor graph is equivalent to running the SP algorithm derived by Braunstein, Mezard and Zecchina (2005). For the weighted Max-SAT problem, this gives rise to a new algorithm that we call the Relaxed Survey Propagation (RSP) algorithm.", "startOffset": 22, "endOffset": 521}, {"referenceID": 24, "context": "A factor graph (Kschischang et al., 2001) provides a useful graphical representation illustrating the dependencies defined in the joint probability distribution in Equation 1.", "startOffset": 15, "endOffset": 41}, {"referenceID": 24, "context": "The factor graph representation is useful for illustrating inference algorithms on joint distributions in the form of Equation 1 (Kschischang et al., 2001).", "startOffset": 129, "endOffset": 155}, {"referenceID": 24, "context": "We refer the reader to the work of Kschischang et al. (2001) for a comparison between factor graphs, Bayesian networks and Markov random fields.", "startOffset": 35, "endOffset": 61}, {"referenceID": 11, "context": "As such, the MAP problem is in general NP-complete, while the marginal problem is equivalent to model counting for 3-SAT, and is #P-complete (Cooper, 1990).", "startOffset": 141, "endOffset": 155}, {"referenceID": 10, "context": "The SAT problem is the first problem shown to be NP-complete in Stephen Cook\u2019s seminal paper in 1971 (Cook, 1971; Levin, 1973).", "startOffset": 101, "endOffset": 126}, {"referenceID": 27, "context": "The SAT problem is the first problem shown to be NP-complete in Stephen Cook\u2019s seminal paper in 1971 (Cook, 1971; Levin, 1973).", "startOffset": 101, "endOffset": 126}, {"referenceID": 46, "context": "Any Boolean formula can be re-written in CNF using De Morgan\u2019s law and the distributivity law, although in practice, this may lead to an exponential blowup in the size of the formula, and the Tseitin transformation is often used instead (Tseitin, 1968).", "startOffset": 237, "endOffset": 252}, {"referenceID": 10, "context": "The K-SAT problem is NP-complete, for K \u2265 3 (Cook, 1971).", "startOffset": 44, "endOffset": 56}, {"referenceID": 2, "context": "We define the energy, E(x), and the distribution, p(x), over configurations of the SAT instance (Battaglia et al., 2004)", "startOffset": 96, "endOffset": 120}, {"referenceID": 40, "context": "The SAT problem is well studied in computer science: as the archetypical NP-complete problem, it is common to reformulate other NP-complete problems such as graph coloring as a SAT problem (Prestwich, 2003).", "startOffset": 189, "endOffset": 206}, {"referenceID": 18, "context": "Variants of algorithms such as WalkSAT and GSAT use various strategies, such as tabusearch (McAllester, Selman, & Kautz, 1997) or adapting the noise parameter that is used, to help the search out of a local minima (Hoos, 2002).", "startOffset": 214, "endOffset": 226}, {"referenceID": 5, "context": "The SP algorithm (Braunstein et al., 2005) has been shown to beat the best incomplete solvers in solving hard random 3-SAT instances efficiently.", "startOffset": 17, "endOffset": 42}, {"referenceID": 5, "context": "The SP algorithm (Braunstein et al., 2005) has been shown to beat the best incomplete solvers in solving hard random 3-SAT instances efficiently. SP estimates marginals on all variables and chooses a few of them to fix to a truth value. The size of the instance is then reduced by removing these variables, and SP is run again on the remaining instance. This iterative process is called decimation in the SP literature. It was shown empirically that SP rarely makes any mistakes in its decimation, and SP solves very large 3-SAT instances that are very hard for local search algorithms. Recently, Braunstein and Zecchina (2006) have", "startOffset": 18, "endOffset": 628}, {"referenceID": 26, "context": "Larrosa and Heras (2005) introduced a framework that integrated the branch and bound techniques into a Max-DPLL algorithm for solving the Max-SAT problem.", "startOffset": 0, "endOffset": 25}, {"referenceID": 47, "context": "We will also briefly describe how the BP algorithm can be applied to factor graphs with loops, and refer the reader to the work of Yedidia et al. (2005) for the underlying theoretical justification in this case.", "startOffset": 131, "endOffset": 153}, {"referenceID": 47, "context": "We refer the reader to the work of Yedidia et al. (2005) for more details.", "startOffset": 35, "endOffset": 57}, {"referenceID": 5, "context": "Survey Propagation: The SP and SP-y Algorithms Recently, the SP algorithm (Braunstein et al., 2005) has been shown to beat the best incomplete solvers in solving hard 3-SAT instances efficiently.", "startOffset": 74, "endOffset": 99}, {"referenceID": 5, "context": "Survey Propagation: The SP and SP-y Algorithms Recently, the SP algorithm (Braunstein et al., 2005) has been shown to beat the best incomplete solvers in solving hard 3-SAT instances efficiently. The SP algorithm was first derived from principles in statistical physics, and can be explained using the cavity approach (Mezard & Parisi, 2003). It was first given a BP interpretation in the work of Braunstein and Zecchina (2004). In this section, we will define the SP and the SP-y algorithms for solving SAT and Max-SAT problems, using a warning propagation interpretation for these algorithms.", "startOffset": 75, "endOffset": 428}, {"referenceID": 5, "context": "In this section, we provide an intuitive overview of the SP algorithm as it was formulated in the work of Braunstein et al. (2005). The SP algorithm can be defined as a message passing algorithm on the factor graph ({V, F}, E).", "startOffset": 106, "endOffset": 131}, {"referenceID": 5, "context": "In this section, we provide an intuitive overview of the SP algorithm as it was formulated in the work of Braunstein et al. (2005). The SP algorithm can be defined as a message passing algorithm on the factor graph ({V, F}, E). Each factor \u03b2 \u2208 F passes a single real number, \u03b7\u03b2\u2192i to a neighboring variable Xi in the factor graph. This real number \u03b7\u03b2\u2192i is called a survey. According to the warning propagation interpretation given in the work of Braunstein et al. (2005), the survey \u03b7\u03b2\u2192i corresponds to the probability1 of the warning that the factor \u03b2 is sending to the variable Xi.", "startOffset": 106, "endOffset": 470}, {"referenceID": 5, "context": "This algorithm, called the survey inspired decimation algorithm (Braunstein et al., 2005), is given in the algorithm in Figure 6.", "startOffset": 64, "endOffset": 89}, {"referenceID": 2, "context": "The SP algorithm can be understood as a special case of the SP-y algorithm, with y taken to infinity (Battaglia et al., 2004).", "startOffset": 101, "endOffset": 125}, {"referenceID": 5, "context": "Figure 6: The survey inspired decimation (SID) algorithm for solving a SAT problem (Braunstein et al., 2005)", "startOffset": 83, "endOffset": 108}, {"referenceID": 2, "context": "In notations used in the work of Battaglia et al. (2004) describing SP-y, let hj\u2192\u03b2 = H j\u2192\u03b2 \u2212H \u2212 j\u2192\u03b2.", "startOffset": 33, "endOffset": 57}, {"referenceID": 2, "context": "In notations used in the work of Battaglia et al. (2004) describing SP-y, let hj\u2192\u03b2 = H j\u2192\u03b2 \u2212H \u2212 j\u2192\u03b2. Battaglia et al. (2004) defined the SP-y message passing equations that calculate the probability distribution over hj\u2192\u03b2, based on the input surveys, {\u03b7\u03b2\u2032\u2192j}\u03b2\u2032\u2208V (j)\\\u03b2 = {\u03b7\u03b21\u2192j , \u03b7\u03b22\u2192j , .", "startOffset": 33, "endOffset": 125}, {"referenceID": 2, "context": "In the work of Battaglia et al. (2004), an additional backtracking process was introduced to make the decimation process more robust.", "startOffset": 15, "endOffset": 39}, {"referenceID": 2, "context": "In the algorithm in Figure 7, we show the backtracking decimation algorithm for SP-y (Battaglia et al., 2004), where the value of y is either given as input, or can be determined empirically.", "startOffset": 85, "endOffset": 109}, {"referenceID": 2, "context": "Figure 7: The survey inspired decimation (SID) algorithm for solving a Max-SAT instance (Battaglia et al., 2004)", "startOffset": 88, "endOffset": 112}, {"referenceID": 30, "context": "Relaxed Survey Propagation It was shown (Maneva et al., 2004; Braunstein & Zecchina, 2004) that SP for the SAT problem can be reformulated as a BP algorithm on an extended factor graph.", "startOffset": 40, "endOffset": 90}, {"referenceID": 30, "context": "Relaxed Survey Propagation It was shown (Maneva et al., 2004; Braunstein & Zecchina, 2004) that SP for the SAT problem can be reformulated as a BP algorithm on an extended factor graph. However, their formulation cannot be generalized to explain the SP-y algorithm which is applicable to Max-SAT problems. In a previous paper (Chieu & Lee, 2008), we extended the formulation in the work of Maneva et al. (2004) to address the Max-SAT problem.", "startOffset": 41, "endOffset": 411}, {"referenceID": 30, "context": "Relaxed Survey Propagation It was shown (Maneva et al., 2004; Braunstein & Zecchina, 2004) that SP for the SAT problem can be reformulated as a BP algorithm on an extended factor graph. However, their formulation cannot be generalized to explain the SP-y algorithm which is applicable to Max-SAT problems. In a previous paper (Chieu & Lee, 2008), we extended the formulation in the work of Maneva et al. (2004) to address the Max-SAT problem. In this section, we will modify the formulation in our previous paper (Chieu & Lee, 2008) to address the weighted Max-SAT problem, by setting up an extended factor graph on which we run the BP algorithm. In Theorem 3, we show that this formulation generalizes the BP interpretation of SP given in the work of Maneva et al. (2004), and in the main theorem (Theorem 2), we show that running the loopy BP algorithm on this factor graph estimates marginals over covers of configurations violating a set of clauses with minimal total weight.", "startOffset": 41, "endOffset": 773}, {"referenceID": 30, "context": "(Maneva et al., 2004) Given a configuration x, we say that a variable Xi is the unique satisfying variable for a clause \u03b2 \u2208 C if it is assigned s\u03b2,i whereas all other variables Xj in the clause are assigned u\u03b2,j (see Definition 2 for the definitions of s\u03b2,i and u\u03b2,i).", "startOffset": 0, "endOffset": 21}, {"referenceID": 30, "context": "We define a partial order on the set of all valid configurations as follows (Maneva et al., 2004):", "startOffset": 76, "endOffset": 97}, {"referenceID": 30, "context": "This partial order defines a lattice, and Maneva et al. (2004) showed that SP is a \u201cpeeling\u201d procedure that peels a satisfying configuration to its minimal element in the lattice.", "startOffset": 42, "endOffset": 63}, {"referenceID": 30, "context": "The SP algorithm was shown to return marginals over covers (Maneva et al., 2004).", "startOffset": 59, "endOffset": 80}, {"referenceID": 22, "context": "Kroc et al. (2007) showed empirically that the number of false covers is negligible for SAT instances.", "startOffset": 0, "endOffset": 19}, {"referenceID": 30, "context": "(Maneva et al., 2004) Given a configuration x, we define the parent set Pi(x) of a variable Xi to be the set of clauses for which Xi = xi is the unique satisfying variable in a configuration x, (i.", "startOffset": 0, "endOffset": 21}, {"referenceID": 5, "context": "(2004) formulated the SP-\u03c1 algorithm, which is equivalent to the SP algorithm (Braunstein et al., 2005) for \u03c1 = 1.", "startOffset": 78, "endOffset": 103}, {"referenceID": 30, "context": "The definitions of the joint distribution for SP-\u03c1 for \u03c1 = 1 (Maneva et al., 2004), and for RSP in this paper differ only in Definition 9, and with y \u2192 \u221e in RSP, their definitions become identical.", "startOffset": 61, "endOffset": 82}, {"referenceID": 29, "context": "Maneva et al. (2004) formulated the SP-\u03c1 algorithm, which is equivalent to the SP algorithm (Braunstein et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 5, "context": "(2004) formulated the SP-\u03c1 algorithm, which is equivalent to the SP algorithm (Braunstein et al., 2005) for \u03c1 = 1. The SP-\u03c1 algorithm is the loopy BP algorithm on the extended factor graph defined in the work of Maneva et al. (2004). Comparing the definitions of the extended factor graph and factors for RSP and SP-\u03c1, we have (Chieu & Lee, 2008): Theorem 3.", "startOffset": 79, "endOffset": 233}, {"referenceID": 30, "context": "this definition, Maneva et al. (2004) defines a smoothing interpretation for SP-\u03c1.", "startOffset": 17, "endOffset": 38}, {"referenceID": 30, "context": "this definition, Maneva et al. (2004) defines a smoothing interpretation for SP-\u03c1. This smoothing can also be applied to RSP. See Theorem 6 in the work of Maneva et al. (2004) and the Appendix A for more details.", "startOffset": 17, "endOffset": 176}, {"referenceID": 2, "context": "In the work of Battaglia et al. (2004) where SP-y was formulated with the cavity approach, it was found that the optimal value of y for a given Max-SAT problem is y\u2217 = \u03b4\u03a3 \u03b4e , where \u03a3 is the complexity in statistical physics, and e is the energy density (Mezard & Zecchina, 2002).", "startOffset": 15, "endOffset": 39}, {"referenceID": 2, "context": "available online (Battaglia et al., 2004), which contains a mechanism for backtracking on decimation decisions (see Figure 7).", "startOffset": 17, "endOffset": 41}, {"referenceID": 2, "context": "The random instances are generated by the SP-y code available online (Battaglia et al., 2004).", "startOffset": 69, "endOffset": 93}, {"referenceID": 2, "context": "For SP-y, we run the SP-y code available on line, with the option of decimating 100 variables at each iteration, and with two different settings: with and without backtracking (Battaglia et al., 2004).", "startOffset": 176, "endOffset": 200}, {"referenceID": 2, "context": "(Battaglia et al., 2004).", "startOffset": 0, "endOffset": 24}, {"referenceID": 25, "context": "3 Benchmark Max-SAT Instances We compare RSP with UBCSAT on instances used in the work of Lardeux et al. (2005), which were instances used in the SAT 2003 competition.", "startOffset": 90, "endOffset": 112}, {"referenceID": 2, "context": "On the benchmark instances, we run SP-y with the \u201c-Y\u201d option (Battaglia et al., 2004) that uses dichotomic search for y: SP-y failed to fix any spins on all 7 instances.", "startOffset": 61, "endOffset": 85}, {"referenceID": 24, "context": "Lardeux et al. (2005) did not show best performances in their paper, but their average results were an order of magnitude higher than results in Table 2.", "startOffset": 0, "endOffset": 22}, {"referenceID": 25, "context": "Columns: \u201cinstance\u201d shows the instance name in the paper of Lardeux et al. (2005), \u201cnvar\u201d the number of variables, \u201cubcsat\u201d and \u201crsp-x\u201d (x is the number of decimations at each iteration) the number of violated clauses returned by each algorithm, and \u201cfx-x\u201d the number of spins fixed by RSP.", "startOffset": 60, "endOffset": 82}, {"referenceID": 49, "context": "For Max-3-SAT, however, it has been shown empirically that beyond the phase transition of satisfiability, all instances are hard to solve (Zhang, 2001).", "startOffset": 138, "endOffset": 151}, {"referenceID": 30, "context": "Smoothing Interpretation for RSP In the definition of SP-\u03c1 (Maneva et al., 2004), the parameter \u03c1 was introduced to define a whole family of algorithms.", "startOffset": 59, "endOffset": 80}, {"referenceID": 30, "context": "Smoothing Interpretation for RSP In the definition of SP-\u03c1 (Maneva et al., 2004), the parameter \u03c1 was introduced to define a whole family of algorithms. For \u03c1 = 1, the SP-\u03c1 algorithm corresponds to the SP algorithm, while for \u03c1 = 0, the SP-\u03c1 algorithm corresponds to the BP algorithm. In this section, we develop a more general version of the extended factor graph defined in Section 5, that incorporates the \u03c1 in SP-\u03c1. We will call the corresponding RSP algorithm on this new factor graph the RSP-\u03c1 algorithm. The only difference between the factor graph for RSP-\u03c1 and the one in Section 5 is the definition of the variable compatibilities in Equation 43. Following notations in the work of Maneva et al. (2004), we introduce the parameters \u03c90 and \u03c9\u2217, and we restrict ourselves to the case where \u03c90 + \u03c9\u2217 = 1 (The \u03c1 in SP-\u03c1 or RSP-\u03c1 is equal to \u03c9\u2217).", "startOffset": 60, "endOffset": 713}], "year": 2009, "abstractText": "The survey propagation (SP) algorithm has been shown to work well on large instances of the random 3-SAT problem near its phase transition. It was shown that SP estimates marginals over covers that represent clusters of solutions. The SP-y algorithm generalizes SP to work on the maximum satisfiability (Max-SAT) problem, but the cover interpretation of SP does not generalize to SP-y. In this paper, we formulate the relaxed survey propagation (RSP) algorithm, which extends the SP algorithm to apply to the weighted Max-SAT problem. We show that RSP has an interpretation of estimating marginals over covers violating a set of clauses with minimal weight. This naturally generalizes the cover interpretation of SP. Empirically, we show that RSP outperforms SP-y and other state-of-the-art Max-SAT solvers on random Max-SAT instances. RSP also outperforms state-of-the-art weighted Max-SAT solvers on random weighted Max-SAT instances.", "creator": "TeX"}}}