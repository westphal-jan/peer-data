{"id": "1402.5164", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2014", "title": "Distribution-Independent Reliable Learning", "abstract": "We study several questions in the reliable agnostic learning framework of Kalai et al. (2009), which captures learning tasks in which one type of error is costlier than others. A positive reliable classifier is one that makes no false positive errors. The goal in the positive reliable agnostic framework is to output a hypothesis with the following properties: (i) its false positive error rate is at most $\\epsilon$, (ii) its false negative error rate is at most $\\epsilon$ more than that of the best positive reliable classifier from the class. A closely related notion is fully reliable agnostic learning, which considers partial classifiers that are allowed to predict \"unknown\" on some inputs. The best fully reliable partial classifier is one that makes no errors and minimizes the probability of predicting \"unknown\", and the goal in fully reliable learning is to output a hypothesis that is almost as good as the best fully reliable partial classifier from a class.", "histories": [["v1", "Thu, 20 Feb 2014 22:41:39 GMT  (24kb)", "http://arxiv.org/abs/1402.5164v1", "20 pages"]], "COMMENTS": "20 pages", "reviews": [], "SUBJECTS": "cs.LG cs.CC cs.DS", "authors": ["varun kanade", "justin thaler"], "accepted": false, "id": "1402.5164"}, "pdf": {"name": "1402.5164.pdf", "metadata": {"source": "CRF", "title": "Distribution-Independent Reliable Learning", "authors": ["Varun Kanade", "Justin Thaler"], "emails": ["vkanade@eecs.berkeley.edu", "jthaler@seas.harvard.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 2.\n51 64\nv1 [\ncs .L\nG ]\n2 0\nFe b\n20 14\nFor distribution-independent learning, the best known algorithms for PAC learning typically utilize polynomial threshold representations, while the state of the art agnostic learning algorithms use pointwise polynomial approximations. We show that one-sided polynomial approximations, an intermediate notion between polynomial threshold representations and point-wise polynomial approximations, suffice for learning in the reliable agnostic settings. We then show that majorities can be fully reliably learned and disjunctions of majorities can be positive reliably learned, through constructions of appropriate onesided polynomial approximations. Our fully reliable algorithm for majorities provides the first evidence that fully reliable learning may be strictly easier than agnostic learning. Our algorithms also satisfy strong attribute-efficiency properties, and in many cases they provide smooth tradeoffs between sample complexity and running time.\n\u2217University of California, Berkeley. Email: vkanade@eecs.berkeley.edu \u2020The Simons Institute for the Theory of Computing at UC Berkeley. Email: jthaler@seas.harvard.edu"}, {"heading": "1 Introduction", "text": "In many learning tasks, one type of error is costlier than other types. For example, when detecting spam messages, an important mail marked as spam (a false positive) is a major problem, whereas false negatives are only a minor nuisance. On the other hand, in settings such as detecting failures in an electric network, false negatives may be very harmful. In yet other settings, it may be better to refrain from making a prediction at all, rather than make a wrong one, e.g., when detecting medical ailments. Following Kalai et al. (2012), we call these kinds of tasks reliable learning. Closely related tasks have been widely studied in the statistics and machine learning literature. We discuss some of this work later; here, we simply note that the work of Kalai et al. and the present work depart from much of the extant literature by emphasizing computational considerations, i.e., by focusing on \u201cfast\u201d algorithms, and guarantees with respect to the zero-one loss.\nKalai et al. (2012) introduced a formal framework to study reliable learning in the agnostic setting, which is a challenging model that captures the problem of learning in the presence of adversarial classification noise. In particular, the goal of an agnostic learning algorithm is to produce a hypothesis that has error that is at most \u01eb higher than the best from a certain class. A false positive error occurs when the true label is negative, but the hypothesis predicts positive. Analogously, a false negative error occurs when the true label is positive, but the hypothesis predicts negative.\nThe best positive reliable classifier from a class is one that make no false positive errors and minimizes false negative errors. In the positive reliable learning setting, the goal of a learning algorithm is to output a hypothesis with the following properties: (i) its false positive error rate is at most \u01eb, (ii) its false negative error rate is at most \u01eb more than that of the best positive reliable classifier from the class. The notion of negative reliable learning is identical with the roles of false positive and false negatives reversed.\nKalai et al. (2012) also introduced the notion of full reliability. A partial classifier is one that is allowed to sometimes predict \u201c?\u201d or unknown. The best partial classifier from a class is one that makes no errors and minimizes the probability of predicting ?. In the fully reliable learning setting, the goal of the learning algorithm is to output a hypothesis h : X \u2192 {\u22121, ?,+1} such that (i) the error of h is at most \u01eb, (ii) the probability that h predicts \u2018?\u2019 is at most \u01eb more than the best partial classifier from the class."}, {"heading": "1.1 Our Contributions", "text": "In this work, we focus on distribution-independent reliable learning, and our main technical contribution is to give new reliable learning algorithms for a variety of concept classes. We now place our reliable learning algorithms in the context of prior work on PAC and agnostic learning.\nThe threshold degree of a Boolean function f : {\u22121, 1}n \u2192 {\u22121, 1} is the least degree of a real polynomial that agrees in sign with f at all inputs x \u2208 {\u22121, 1}n. The approximate degree (with error parameter \u01eb) of f is the least degree of a real polynomial that point-wise approximates f to error at most \u01eb. It is well-known that concept classes with low threshold degree can be efficiently learned in Valiant\u2019s PAC model under arbitrary distributions; indeed, threshold degree upper bounds underlie the fastest known PAC learning algorithms for a variety of fundamental concept classes, including DNF and read-once formulae (Klivans and Servedio, 2004, Ambainis et al., 2010). Meanwhile, concept classes with low approximate degree can be efficiently learned in the agnostic model, a connection that has yielded the fastest known algorithms for distribution-independent agnostic learning (Kalai et al., 2005).\nWe show that concept classes with low one-sided approximate degree can be efficiently learned in the reliable agnostic model. Here, one-sided approximate degree is an intermediate notion that lies between threshold degree and approximate degree; we defer a formal definition to Section 2.3. One-sided approx-\nimate degree was introduced in its present form by Bun and Thaler (2013a) (see also (Sherstov, 2014)), though equivalent dual formulations had been used in several prior works (Gavinsky and Sherstov, 2010, Sherstov, 2013a, Bun and Thaler, 2013b). Our learning algorithm is similar to the L1 regression algorithm of Kalai et al. (2005); however, the analysis of our algorithm is more delicate. Specifically, due to asymmetry in the type of errors considered in the reliable setting, our analysis requires the use of two loss functions. On one side, we use the hinge loss rather than L1 loss, since one-sided polynomial approximations may be unbounded, and on the other, we use a non-convex Lipschitz approximation to the zero-one loss.\nWe identify important concept classes, such as majorities and intersections of majorities, whose onesided approximate degree is strictly smaller than its approximate degree. Consequently, we obtain reliable (in the case of majorities, even fully reliable) agnostic learning algorithms that are strictly more efficient than the fastest known algorithms in the standard agnostic setting. Our fully reliable learning algorithm for majorities gives the first indication that fully reliable learning may be strictly easier than agnostic learning. Finally, we show how to obtain smooth tradeoffs between sample complexity and runtime of algorithms for agnostically learning conjunctions, and for positive reliably learning DNF formulae.\nIn more detail, we summarize our new algorithmic results as follows (for simplicity, we omit dependence on the error parameter \u01eb of the learning algorithm from this overview). We give:\n\u2022 A simple poly(n) time algorithm for positive reliable learning of disjunctions.\n\u2022 A 2O\u0303( \u221a n) time algorithm for fully reliable learning of majorities. In contrast, no 2o(n)-time algorithm\nfor agnostically learning majorities is known in the arbitrary-distribution setting.\n\u2022 A 2O\u0303( \u221a n logm) time algorithm for positive (respectively, negative) reliable learning of disjunctions\n(respectively, conjunctions) of m majorities.\n\u2022 For any d > n1/2, a nO(d)-time algorithm with sample complexity nO(n/d) for agnostically learning conjunctions, and for positive reliably learning poly(n)-term DNFs.\nAll of our algorithms also satisfy very strong attribute-efficiency properties: if the function being learned depends on only k \u226a n of the n input variables, then the sample complexity of the algorithm depends only logarithmically on n, though the dependence on k may be large. We defer a detailed statement of these properties until Section 3.2."}, {"heading": "1.2 Related Work", "text": "The problem of reliable classification can be expressed as minimizing a loss function with different costs for false negative and false positive errors (see e.g., (Domingos, 1999, Elkan, 2001)). Reliable learning is also related to the Neyman-Pearson criterion from classical statistics \u2014 where it has been shown that the optimal strategy to minimize one type of errors, subject to the other type being bounded, is to threshold the ratio of the likelihoods (Neyman and Pearson, 1933). However, the main problem is computational; in general the loss functions with different costs from these prior works are not convex and the resulting optimization problems are intractable. The work of Kalai et al. (2012) and the present work departs from the prior work in that we focus on algorithms with both provable guarantees on their generalization error with respect to the zero-one loss, and bounds on their computational complexity, rather than focusing purely on statistical efficiency.\nKalai et al. (2012) showed that any concept class that is agnostically learnable under a fixed distribution is also learnable in the reliable agnostic learning models under the same distribution. Furthermore, they\nshowed that if a class C is agnostically learnable, the class of disjunctions of concepts in C is positive reliably learnable (and the class of conjunctions of concepts in C is negative reliably learnable). Finally, they showed that if C is both positive and negative reliably learnable, then it is also fully reliably learnable. Using these general reductions, Kalai et al. showed that the class of polynomial-size DNF formulae is positive reliable learnable under the uniform distribution in polynomial time with membership queries (it also follows from their reductions and the agnostic learning algorithm of Kalai et al. (2005) described below that DNF formulae can be positive reliably learned in the distribution-independent setting in time 2O\u0303( \u221a n)). Agnostically learning DNFs under the uniform distribution remains a notorious open problem, and thus their work gave the first indication that positive (or negative) reliable learning may be easier than agnostic learning.\nKalai et al. (2005) put forth an algorithm for agnostic learning based on L1-regression. Our reliable learning algorithms based on one-sided approximate degree upper bounds is inspired by and generalizes their work. Klivans and Sherstov (2010) subsequently established strong limitations on the L1-regression approach of Kalai et al. (2005), proving lower bounds on the size of any set of \u201cfeature functions\u201d that can point-wise approximate the concept classes of majorities and conjunctions. Their work implies that substantially new ideas will be required to obtain a 2o(n)-time distribution-independent agnostic learning algorithm for majorities, or a 2o( \u221a n) time algorithm for agnostically learning conjunctions.\nFinally, lower bounds on one-sided approximate degree have recently been used in several works to establish strong limitations on the power of existing algorithms for PAC learning (Bun and Thaler, 2013a, Sherstov, 2014, Bun and Thaler, 2013b, Gavinsky and Sherstov, 2010, Sherstov, 2013a). In this paper, we do the opposite: we use one-sided approximate degree upper bounds to give new, more efficient learning algorithms in the reliable agnostic setting.\nOrganization\nIn Section 2, we review the definitions of agnostic learning, and positive, negative and fully reliable learning. In Section 3, we first give a very simple polynomial time algorithm for positive reliable learning of disjunctions, before showing that appropriate one-sided polynomial approximations for function classes result in efficient reliable learning algorithms. In Section 4, we give constructions of one-sided approximating polynomials for (conjunctions and disjunctions of) low-weight halfspaces, as well as for DNF and CNF formulae. In Section 5, we show how tradeoffs may be obtained for some of our results between sample complexity and running time, and in Section 6, we describe some limitations of our approach. We end with a discussion and directions for future work."}, {"heading": "2 Preliminaries and Definitions", "text": "Let X = {\u22121, 1}n denote the instance space. Let C denote a concept class of functions from X \u2192 {\u22121, 1}. We will use the convention that +1 is TRUE and \u22121 is FALSE.1 For ease of notation, we will keep the parameter n, corresponding to the length of input vectors, implicit in the discussion. Let c, h : X \u2192 {\u22121, 1} be Boolean functions. For a distribution \u00b5 over X, let err(h, (\u00b5, c)) = Prx\u223c\u00b5[c(x) 6= h(x)], denote the error of hypothesis h with respect to concept c and distribution \u00b5. Let EX(c, \u00b5) denote the example oracle, which when queried returns a pair (x, c(x)), where x is drawn from distribution \u00b5, and c is a concept in C . Since the algorithms presented in this paper typically do not run in polynomial time, we do not impose\n1This is contrary to the usual convention in the analysis of Boolean functions. However, our definitions would appear a lot more counter-intuitive in the standard notation.\nsuch a condition in the definitions of learnability. We will explicitly mention the running time and sample complexity in all of our results.\nDefinition 1 (PAC Learning (Valiant, 1984)). A concept class C is probably approximately correct (PAC) learnable if there exists a learning algorithm that for any c \u2208 C , any distribution \u00b5 over X, any \u01eb, \u03b4 > 0, with access to an example oracle EX(c, \u00b5), outputs a hypothesis h, such that with probability at least 1\u2212 \u03b4, err(h, (\u00b5, c)) \u2264 \u01eb.\nIn the case of agnostic learning, the data may come from an arbitrary joint distribution on examples and labels. Let D denote a distribution over X \u00d7 {\u22121, 1}. Also, let err(h,D) = Pr(x,y)\u223cD[h(x) 6= y], denote the error of h with respect to D, and let EX(D) denote the example oracle which when queried returns (x, y) \u223c D.\nDefinition 2 (Agnostic Learning (Haussler, 1992, Kearns et al., 1994)). A concept class C is agnostically learnable if there exists a learning algorithm that for any distribution D over X \u00d7 {\u22121, 1}, any \u01eb, \u03b4 > 0, with access to example oracle EX(D), outputs a hypothesis h, such that with probability at least 1 \u2212 \u03b4, err(h,D) \u2264 opt+\u01eb, where opt = min\nc\u2208C err(c,D)."}, {"heading": "2.1 Reliable Learning", "text": "We review the various notions of reliable agnostic learning proposed by Kalai et al. (2012). As in the case of agnostic learning, the data comes from an arbitrary joint distribution D over X\u00d7{\u22121, 1}. For a Boolean function, h : X \u2192 {\u22121, 1}, define the false positive error (false+) and the false negative error (false\u2212) with respect to D as follows:\nfalse+(h,D) = Pr (x,y)\u223cD\n[h(x) = 1 \u2227 y = \u22121]\nfalse\u2212(h,D) = Pr (x,y)\u223cD\n[h(x) = \u22121 \u2227 y = +1]\nLet C denote the concept class of interest for learning. For a distribution D, define the following:\nC+(D) = {c \u2208 C | false+(c,D) = 0} C\u2212(D) = {c \u2208 C | false\u2212(c,D) = 0}\nWe call the concepts in C+ (respectively, C\u2212) positive (respectively, negative) reliable with respect to D. Below we define positive and negative reliable learning. In short, positive reliable learning requires that the learning algorithm produce a hypothesis that makes (almost) no false positive errors, while simultaneously minimizing false negative errors. Likewise, in the case of negative reliable learning, the learning algorithm must output a hypothesis that makes (almost) no false negative errors, while simultaneously minimizing false positive errors. Although the definitions of positive and negative reliable learning are entirely symmetric, we define the two separately for the sake of clarity.\nDefinition 3 (Positive Reliable Learning (Kalai et al., 2012)). A concept class C is positive reliably learnable if there exists a learning algorithm that for any distribution D over X \u00d7 {\u22121, 1}, and any \u01eb, \u03b4 > 0, when given access to the example oracle EX(D), outputs a hypothesis h that satisfies the following with probability at least 1\u2212 \u03b4,\n1. false+(h,D) \u2264 \u01eb\n2. false\u2212(h,D) \u2264 opt++\u01eb, where opt+ = min c\u2208C+(D) false\u2212(c,D)\nWe refer to \u01eb as the error parameter of the learning algorithm.\nDefinition 4 (Negative Reliable Learning (Kalai et al., 2012)). A concept class C is negative reliably learnable, if there exists a learning algorithm that for any distribution D over X \u00d7 {\u22121, 1}, any \u01eb, \u03b4 > 0, with access to the example oracle EX(D), outputs a hypothesis h, that satisfies the following with probability at least 1\u2212 \u03b4,\n1. false\u2212(h,D) \u2264 \u01eb\n2. false+(h,D) \u2264 opt\u2212+\u01eb, where opt\u2212 = min c\u2208C\u2212(D) false+(c,D)\nWe refer to \u01eb as the error parameter of the learning algorithm.\nKalai et al. (2012) also define a notion of fully reliable learning. Here, the learning algorithm may output a partial classifier h : X \u2192 {\u22121, ?,+1}, and must make (almost) no errors, while simultaneously minimizing the probability of abstaining from prediction, i.e., outputting ?. Again, recall that we are in the agnostic setting, and let D be an arbitrary distribution over X\u00d7{\u22121, 1}. For some partial classifier, h : X \u2192 {\u22121, ?,+1}, let err(h,D) = Pr(x,y)\u223cD[h(x) = \u2212y] denote the error, and ?(h,D) = Pr(x,y)\u223cD[h(x) =?] denote the uncertainty of h. From a concept class C , each pair of concepts defines a partial classifier, cp = (c+, c\u2212), defined as: cp(x) = c+(x), if c+(x) = c\u2212(x), and cp(x) =? otherwise. Let Cf (D) = {cp = (c+, c\u2212) | err(cp,D) = 0} denote the fully reliable partial classifiers with respect to distribution D. Formally, fully reliable learning is defined as:\nDefinition 5 (Fully Reliable Learning (Kalai et al., 2012)). A concept class C is fully reliable learnable, if there exists a learning algorithm that for any distribution D over X \u00d7{\u22121, 1}, any \u01eb, \u03b4 > 0, with access to the example oracle EX(D), outputs a partial hypothesis h : X \u2192 {\u22121, ?,+1}, that satisfies the following with probability at least 1\u2212 \u03b4,\n1. err(h,D) \u2264 \u01eb\n2. ?(h,D) \u2264 opt? +\u01eb, where opt? = min cp\u2208Cf (D) ?(cp,D)\nWe refer to \u01eb as the error parameter of the learning algorithm.\nKalai et al. (2012) showed the following simple result.\nTheorem 1 ((Kalai et al., 2012)). If a concept class C is positive and negative reliable learnable in time T (n, \u01eb) and with sample complexity S(n, \u01eb), then C is fully reliable learnable in time O(T (n, \u01eb/4)) and sample complexity O(S(n, \u01eb/4))."}, {"heading": "2.2 Approximating Polynomials", "text": "Throughout, if p : {\u22121, 1}n \u2192 R is a real polynomial, deg(p) will denote the total degree of p. Let f : {\u22121, 1}n \u2192 {\u22121, 1} be a Boolean function. We say that a polynomial p : {\u22121, 1}n \u2192 {\u22121, 1} is an \u01eb-approximation for f if |p(x)\u2212 f(x)| \u2264 \u01eb for all x \u2208 {\u22121, 1}n. We let d\u0303eg\u01eb(f) denote the least degree of an \u01eb-approximation for f . We define d\u0303eg(f) = d\u0303eg1/3(f) and refer to the approximate degree of f without qualification. The constant 1/3 is arbitrary and is chosen by convention."}, {"heading": "2.3 One-sided Approximating Polynomials", "text": "We define the notion of one-sided approximating polynomials. The definitions as they are presented here essentially appeared in prior work of Bun and Thaler (2013a) (see also Sherstov (2014)), who only required the notion we refer to as positive one-sided approximate degree. Here, we explicitly distinguish between positive and negative one-sided approximations.\nDefinition 6 (Positive One-Sided Approximating Polynomial). Let f : {\u22121, 1}n \u2192 {\u22121, 1} be a Boolean function. We say that a polynomial p is a positive one-sided \u01eb-approximation for f if p satisfies the following two conditions.\n1. For all x \u2208 f\u22121(1), p(x) \u2208 [1\u2212 \u01eb,\u221e)\n2. For all x \u2208 f\u22121(\u22121), p(x) \u2208 [\u22121\u2212 \u01eb,\u22121 + \u01eb].\nAnalogously, we say that p is a negative one-sided \u01eb-approximation for f if p satisfies:\n1. For all x \u2208 f\u22121(1), p(x) \u2208 [1\u2212 \u01eb, 1 + \u01eb].\n2. For all x \u2208 f\u22121(\u22121), p(x) \u2208 (\u2212\u221e,\u22121 + \u01eb].\nWe define the positive and negative one-sided approximate degrees of f , denoted d\u0303eg+,\u01eb(f) and d\u0303eg\u2212,\u01eb(f) respectively, to be the minimum degree of a positive (respectively, negative) one-sided \u01eb-approximating polynomial p for f . We define d\u0303eg+ := d\u0303eg+,1/3 and d\u0303eg\u2212 := d\u0303eg\u2212,1/3, and refer to these quantities as the positive and negative one-sided approximate degrees of f without qualification.\nFor a polynomial p : {\u22121, 1}n \u2192 {\u22121, 1}, we define its weight to be the sum of the absolute values of its coefficients and denote it by weight(p). Let C be a concept class of Boolean functions; we say that C is positive one-sided \u01eb-approximated by degree d and weight W polynomials, if the following is true: for every c \u2208 C , there exists a polynomial p of weight at most W and degree at most d, such that p is a positive one-sided \u01eb-approximation of c. An analogous definition can be made for the negative one-sided \u01eb-approximation of a concept class."}, {"heading": "2.4 Additional Notation", "text": "Throughout this paper, we use O\u0303 to hide factors polylogarithmic in n and log(1/\u01eb). We also define sgn(t) = \u22121 if t \u2264 0 and 1 otherwise."}, {"heading": "2.5 Generalization Bounds", "text": "We review the basic results required to bound the generalization error of our algorithms for reliable agnostic learning. Let F : X \u2192 R be a function class. Let \u01eb1, . . . , \u01ebn independently take values in {\u22121,+1} with equal probability, and let the variables x1, . . . , xn be chosen i.i.d. from some distribution \u00b5 over X. Then the Rademacher complexity of F , denoted Rm(F), is defined as:\nRm(F) = E [ sup f\u2208F 1 n m\u2211\ni=1\nf(xi)\u01ebi\n] ,\nRademacher complexities have been widely used in the statistical learning theory literature to obtain bound on generalization error. Here, we only cite results that are directly relevant to our work. Suppose\nD is some distribution over X \u00d7 {\u22121, 1}. Let \u2113 : R \u00d7 {\u22121, 1} \u2192 R+ be a loss function. For a function, f : X \u2192 R, the expected loss is given by L(f) = E(x,y)\u223cD[\u2113(f(x), y)]. For a sample, \u3008(xi, yi)\u3009mi=1, let L\u0302(f) = 1m \u2211m i=1 \u2113(f(xi), yi) denote the empirical loss. Bartlett and Mendelson (2002) proved the following result:\nTheorem 2 ((Bartlett and Mendelson, 2002)). Let \u2113 be a Lipschitz loss function (with respect to its first argument) with Lipschitz parameter L, and suppose that \u2113 is bounded above by B. Then for any \u03b4 > 0, with probability at least 1 \u2212 \u03b4 (over the random sample draw), simultaneously for all f \u2208 F , the following is true:\n|L(f)\u2212 L\u0302(f)| \u2264 4LRm(F) + 2B \u221a log(1/\u03b4)\n2m ,\nwhere Rm(F) is the Rademacher complexity of the function class F , and m is the sample size. Finally, let X = {\u22121, 1}n and let Pd,W be the class of n-variate polynomials of degree at most d and weight at most W . Observe that for x \u2208 X, \u2016x\u2016\u221e \u2264 1. Note that we can view p(x) as a linear function in an expanded feature space of dimension nd, and the 1-norm of p in such a space is bounded by W . Kakade et al. (2008) proved the following result:\nTheorem 3 ((Kakade et al., 2008)). Let X be an n dimensional instance space and W = {w |w(x) 7\u2192 w\u00b7x} be a class of linear functions, such that for each x \u2208 X, \u2016x\u2016\u221e \u2264 1, and for each w \u2208 W , \u2016w\u20161 \u2264 W , then, Rm(W) \u2264 W \u221a 2 log(2n)\nm .\nIn our setting, the above implies that the Rademacher complexity of Pd,W is bounded as follows:\nRm(Pd,W ) \u2264 W \u221a 2d log(2n)\nm . (1)"}, {"heading": "3 Learning Algorithms", "text": "We first present a very simple algorithm for positive reliable learning disjunctions in Section 3.1. It is unlikely, however, that such simple algorithms for reliable learning exist for richer classes; in Section 3.2, we present our main result deriving reliable learning algorithms from one-sided polynomial approximations."}, {"heading": "3.1 A Simple Algorithm for Positive Reliably Learning Disjunctions", "text": "The learning algorithm (presented in Fig. 1) ignores all positive examples and finds a disjunction that is maximally positive and classifies all the negative examples correctly (see also Kearns and Vazirani (1994, Chap. 1)).\nTheorem 4. The algorithm in Fig. 1 positive reliably learns the class of disjunctions for some m in O(n/\u01eb2), where m is the number of labeled examples that the algorithm takes as input.\nProof. Let DISJ denote the class of disjunctions and let D be the distribution over X\u00d7{\u22121, 1}. It is known that VC-DIM(DISJ) = n, and hence for some m = O(n/\u01eb2), the following is true for every c \u2208 DISJ:\n| false+(c;D)\u2212 1\nm\n\u2211\ni:yi=\u22121 I(c(xi) = +1)| \u2264 \u01eb/2,\n| false\u2212(c;D)\u2212 1\nm\n\u2211\ni:yi=+1\nI(c(xi) = \u22121)| \u2264 \u01eb/2.\nRecall that DISJ+(D) denotes the positive reliable disjunctions for distribution D. Let c\u2217+ \u2208 DISJ+(D) be such that false\u2212(c\u2217+) = minc\u2208DISJ+(D) false\u2212(c). Both h and c \u2217 + classify all the negative examples in the sample correctly; since h is chosen to have the largest number of literals subject to this property, it is the case that (1/m)\n\u2211 i:yi=+1 I(h(xi) = \u22121) \u2264 \u2211 i:yi=+1 I(c\u2217+(xi) = \u22121). Then, we have\nfalse+(h) \u2264 1\nm\n\u2211\ni:yi=\u22121 I(h(xi) = +1) + \u01eb/2,= 0 + \u01eb/2 \u2264 \u01eb\nfalse\u2212(h) \u2264 1\nm\n\u2211\ni:yi=+1\nI(h(xi) = \u22121) + \u01eb/2.\n\u2264 1 m\n\u2211\ni:yi=+1\nI(c\u2217+(xi) = \u22121) + \u01eb/2 \u2264 false\u2212(c\u2217+) + \u01eb"}, {"heading": "3.2 From One-Sided Approximations to Reliable Learning", "text": "In this section, we prove our main learning result. We describe a generic algorithm that positive reliably learns any concept class that can be positive one-sided approximated by degree d and weight W polynomials. The weight W controls the sample complexity of the learning algorithm, and the degree d controls the running time. For many natural classes, the resulting algorithm is has strong attribute-efficient properties, since the weight of the approximating polynomial typically depends only on the number of relevant attributes.\nOur algorithm extends the L1-regression technique of Kalai et al. (2005) for agnostic learning, but we require a more detailed analysis. In the case of positive-reliable learning, it is required that the hypothesis output by the algorithm makes almost no false positive errors \u2014 this is enforced as constraints in a linear program. To control the false negative errors of the hypothesis, we have the objective function of the linear program minimize the hinge loss, which is analogous to the L1 loss, but the penalty is only enforced when the prediction disagrees in sign with the true label. To bound the generalization error of the output hypothesis, we use bounds on the Rademacher complexity of the approximating polynomials (see Section 2.5 for details).\nTheorem 5. Let C be a concept class that is positive (negative) one-sided \u01eb-approximated by polynomials of degree d and weight W . Then, C can be positive (negative) reliably learned by an algorithm with the following properties:\n1. The running time of the learning algorithm is polynomial in nd and 1/\u01eb.\n2. The sample complexity is m = max{512 \u01eb4 \u00b7W 2d log(2n), 64 \u01eb2 (W + 1)2 log ( 1 \u03b4 ) }\n3. The hypothesis output by the algorithm can be evaluated at any x \u2208 X in time O(nd).\nProof. We only prove the theorem for the case of positive reliable learning. The case of negative reliable learning is entirely symmetric.\nDescription of Algorithm. Suppose D is an arbitrary distribution over X\u00d7{\u22121, 1} and let S = \u3008(xi, yi)\u3009mi=1 be a sample drawn according to D. The learning algorithm first solves the following mathematical program.\nminimize p : deg(p)\u2264d\n\u2211\ni:yi=+1\n(1\u2212 p(xi))+\nsubject to p(xi) \u2264 \u22121 + \u01eb \u2200i such that yi = \u22121 weight(p) \u2264 W.\nHere (a)+ denotes a if a > 0 and 0 otherwise. This program is similar to one used in the L1-regression algorithm for agnostic learning introduced by Kalai et al. (2005). The variables of the program are the\u2211d\nj=0 (n j ) = O(nd) coefficients of the polynomial p(x). The above mathematical program is then easily implemented as a linear program. Let p denote an optimal solution to the linear program. The hypothesis output by the algorithm will be a randomized boolean function, defined as follows:\n1. If p(x) \u2264 \u22121, h(x) = \u22121.\n2. If p(x) \u2265 1, h(x) = +1. 3. If \u22121 < p(x) < +1, h(x) = { +1 with probability(1 + p(x))/2\n\u22121 with probability(1\u2212 p(x))/2\nRunning Time. Since the above program can be implemented as a linear program with O(nd) variables and O(m+ nd) constraints, the running time to produce the output polynomial p is poly(m,nd). Note that the polynomial p defines the output hypothesis h completely, except for the randomness used by h. For any x, h(x) can be evaluated in time O(nd) by a randomized Turing machine. Remark 1 explains how h can be converted to a deterministic hypothesis.\nGeneralization Error. We will use two loss functions in our analysis. Define \u2113+ : R \u00d7 {\u22121, 1} \u2192 R+ as follows:\n\u2113+(y \u2032,+1) = 0,\n\u2113+(y \u2032,\u22121) =    0 y\u2032 \u2264 \u22121 + \u01eb 1 \u01eb (y\n\u2032 + 1\u2212 \u01eb) \u22121 + \u01eb < y\u2032 \u2264 \u22121 + 2\u01eb 1 \u22121 + 2\u01eb < y\u2032\nClearly \u2113+ is bounded between [0, 1] always and also it is 1/\u01eb-Lipschitz. For a function, f : X \u2192 R, let L+(f) denote the expected loss of f under D and the loss function \u2113+, and similarly let L\u0302+(f) denote the empirical loss of f under \u2113+.\nDefine \u2113\u2212 : R\u00d7 {\u22121, 1} \u2192 R+ as follows:\n\u2113\u2212(y \u2032,\u22121) = 0, \u2113\u2212(y \u2032,+1) = (1\u2212 y\u2032)+\nLet p continue to denote an optimal solution to the linear program. Note that since X = {\u22121, 1}n, and weight(p) \u2264 W , it holds that |p(x)| \u2264 W for all x \u2208 X. It follows that \u2113\u2212(p(x), b) \u2264 W +1 for all x \u2208 X and b \u2208 {\u22121,+1}. Moreover, \u2113\u2212 is easily seen to be 1-Lipschitz. For a function, f : X \u2192 R, let L\u2212(f) and L\u0302\u2212(f) denote the expected and empirical loss of f respectively under distribution D and loss function \u2113\u2212.\nRecall that C+(D) = {c \u2208 C | false+(c) = 0}. Let c\u2217 \u2208 C+(D) be an optimal positive reliable classifier, i.e., false\u2212(c\u2217) = min\nc\u2208C+(D) false\u2212(c). Let p\u2217 \u2208 Pd,W be a positive one-sided \u01eb-approximating\npolynomial for c\u2217 whose existence is guaranteed by hypothesis. Note that since p\u2217(x) \u2265 1 \u2212 \u01eb for x \u2208 (c\u2217)\u22121(1) and p\u2217(x) \u2208 [\u22121\u2212 \u01eb,\u22121 + \u01eb] for x \u2208 (c\u2217)\u22121(\u22121), the following is true:\nL+(p\u2217) = 0 L\u2212(p\u2217) \u2264 2 false\u2212(c\u2217) + \u01eb\nHere, the inequality holds because \u2113\u2212(y\u2032, 1) = (1 \u2212 y\u2032)+, which is between 2 \u2212 \u01eb and 2 + \u01eb when p\u2217(x) \u2208 [\u22121\u2212 \u01eb,\u22121 + \u01eb]. Thus, each x on which c\u2217 makes a false negative error contributes approximately 2 to L\u2212(p); the extra \u01eb accounts for the approximation error.\nFix a \u03b4 > 0. Recall that Pd,W is the class of degree d and weight W polynomials. Then the Rademacher complexity, Rm(Pd,W ) \u2264 W \u221a (2d log(2n))/m (see (1) in Section 2.5). Let \u03b1 = (4/\u01eb)Rm(Pd,W )+2(W+\n1)\n\u221a log(1/\u03b4)\n2m . Recall that p is the polynomial output by running the linear program. Then the following holds with probability 1\u2212 \u03b4:\nL\u2212(p) \u2264 L\u0302\u2212(p) + \u03b1 Using Theorem 2 \u2264 L\u0302\u2212(p\u2217) + \u03b1 Since p\u2217 is a feasible solution \u2264 L\u2212(p\u2217) + 2\u03b1 Using Theorem 2 \u2264 2 false\u2212(c\u2217) + 2\u03b1+ \u01eb. (2)\nSimilarly, using Theorem 2 and the fact that L\u0302+(p) = 0, we have that L+(p) \u2264 \u03b1. We have the following:\nfalse+(h) = E(x,y)\u223cD[I(y = \u22121)I(h(x) = 1)] = E(x,y)\u223cD[I(y = \u22121)Pr(h(x) = 1 | p(x))].\nThe inner probability is only over the randomness used by the hypothesis h. It follows from the definition of the randomized hypothesis h and the loss function \u2113+, that Pr(h(x) = 1 | p(x)) \u2264 \u2113+(p(x),\u22121) + \u01eb/2. This together with the fact that \u2113+(p(x),+1) = 0 for all x, and L+(p) \u2264 \u03b1, gives us\nfalse+(h) \u2264 E(x,y)\u223cD[\u01eb/2 + \u2113+(p(x), y)] \u2264 \u01eb/2 + L+(p) \u2264 \u01eb/2 + \u03b1.\nSimilarly, we have the following:\nfalse\u2212(h) = E(x,y)\u223cD[I(y = +1)I(h(x) = \u22121)] = E(x,y)\u223cD[I(y = +1)Pr(h(x) = \u22121 | p(x))]\nAgain, the inner probability is only over the randomness of the hypothesis h. From the definitions of \u2113\u2212 and h, it follows that Pr(h(x) = \u22121 | p(x)) \u2264 \u2113\u2212(p(x),+1)/2. Using this along with the fact that \u2113\u2212(p(x),\u22121) = 0 for all x, and (2) we get\nfalse\u2212(h) \u2264 E(x,y)\u223cD[ 1 2 \u2113\u2212(p(x), y)] \u2264 false\u2212(c\u2217) + \u03b1+ \u01eb/2\nFinally, it is easily verified that for the value of m in the theorem statement, \u03b1 \u2264 \u01eb/2. This completes the proof of the theorem.\nRemark 1. The randomized hypothesis h can easily be converted to a deterministic one as follows: let H(x) = chop(p(x)), where chop(a) = a for a \u2208 [\u22121, 1] and chop(a) = sgn(a) for a 6\u2208 [\u22121, 1]. Note that E[h(x)] = H(x) for each x. Take a fresh sample of size m = O(1/\u01eb2) and construct \u3008(H(xi), yi)\u3009mi=1. For a threshold t, let ht = sgn(H(x)\u2212t). Find the smallest value t\u2217, such that 1m \u2211 yi=\u22121 I(ht\u2217(xi) = +1) \u2264 \u01eb. Then, a simple VC argument implies that ht\u2217 is a deterministic hypothesis with the required properties.\nTheorem 5 satisfies a strong attribute-efficiency property. The sample complexity depends only logarithmically on n, and polynomially on the weight of the polynomial approximations, which can be much smaller then nd. A similar statement can also be made for agnostic learning; this observation was already implicit in some prior work (see e.g., (Feldman et al., 2013)); we state this as a theorem for completeness. Instead of the mathematical program described in the proof of Theorem 5, to obtain Theorem 6, the L1regression algorithm of Kalai et al. (2005) is directly applied, with the added constraint that the weight of the approximating polynomial is at most W . The rest of the proof is similar, but simpler \u2014 we only use \u2113(y\u2032, y) = |y\u2032 \u2212 y| as the loss function in the analysis. The proof is omitted since it is essentially a simplification of the proof of Theorem 5.\nTheorem 6. Let C be a concept class of functions from X \u2192 {\u22121, 1}, such that for every c \u2208 C , there exists a polynomial p of degree at most d and weight at most W , such that for all x \u2208 X, |p(x)\u2212 c(x)| \u2264 \u01eb. Then, C can be agnostically learned with the following properties:\n1. The running time of the learning algorithm is polynomial in nd and 1/\u01eb.\n2. The sample complexity is polynomial in W , log(n), log(1/\u03b4) and 1/\u01eb.\n3. The hypothesis output by the algorithm can be evaluated at any x \u2208 X in time O(nd)."}, {"heading": "4 One-sided Polynomial Approximations", "text": "In this section, we construct both positive and negative one-sided polynomial approximations for low-weight halfspaces, as well as positive (respectively, negative) one-sided approximations for disjunctions (respectively, conjunctions) of low-weight halfspaces. Theorem 7. Let h(x) = sgn(w0 + \u2211n\ni=1wixi) denote any halfspace, where wi are integers. Let W =\u2211n i=0 |wi| denote the weight of h. Both d\u0303eg+,\u01eb(h) and d\u0303eg\u2212,\u01eb(h) are in O\u0303 (\u221a W log (1/\u01eb) ) , with the relevant approximating polynomials having weight at most exp ( O\u0303 (\u221a W log (1/\u01eb) )) . In particular, the majority function MAJ(x) = sgn( \u2211n\ni=1 xi) has both positive and negative \u01eb-approximating polynomials of\ndegree at most O\u0303( \u221a n log (1/\u01eb)) and weight at most exp ( O\u0303( \u221a n log (1/\u01eb)) )\nRemark. By adapting standard symmetrization arguments (cf. Buhrman et al. (1999)), the O\u0303( \u221a n log (1/\u01eb))\nupper bound on d\u0303eg+,\u01eb(MAJ) is easily seen to be tight up to factors hidden by the O\u0303 notation.\nProof. We begin with the case of constant \u01eb; i.e., we first show that for \u01eb = 1/4, d\u0303eg+,\u01eb(h) and d\u0303eg\u2212,\u01eb(h) are in O(W 1/2). We use the following standard properties of the Chebyshev polynomials (cf. the standard texts of Cheney (1982) and Rivlin (1981)).\nFact 1. The d\u2019th Chebyshev polynomial of the first kind, Td(t) : R \u2192 R has degree d and satisfies\n|Td(t)| \u2264 1 for all \u2212 1 \u2264 t \u2264 1. (3) 2 \u2264 T\u2308a\u2309(1 + 1/a2) for all a \u2265 1. (4) Td(t) is non-decreasing on the interval [1,\u221e]. (5) All coefficients of Td are bounded in absolute value by 3 d. (6)\nLet d = \u2308W 1/2\u2309. Consider the univariate polynomial G(t) = Td(2t/W + 1). Then G satisfies the following properties.\nG(t) \u2208 [\u22121, 1] for all t \u2208 [\u2212W, 0]. (7) G(t) \u2265 2 for all t \u2208 [1,\u221e]. (8)\nIndeed, Property 7 follows from Property 3, while Property 8 follows from Properties 4 and 5. Now consider the univariate polynomial P (t) = G(t)4/4\u2212 1. It is straightforward to check that\nP (t) \u2208 [\u22123/4, 1] for all t \u2208 [\u2212W, 0]. (9) P (t) \u2265 3 for all t \u2208 [1,\u221e]. (10)\nFinally, consider the n-variate polynomial p : {\u22121, 1}n \u2192 R defined via\np(x) = P (w0 +\nn\u2211\ni=1\nwixi).\nCombining the fact that \u2211n\ni=0 |wi| \u2264 W with Properties 9 and 10, we see that p is a positive one-sided 1/4- approximation for h. Moreover, deg(p) \u2264 deg(P ) = O(W 1/2), and the weight of p is at most WO( \u221a W ). Similarly, \u2212p(\u2212x) is a negative one-sided 1/4-approximation for h. This completes the proof for \u01eb = 1/4. The construction for \u01eb = o(1) is somewhat more complicated. For any k \u2265 1 and any W , Kahn et al. (1996) construct a univariate polynomial Sk satisfying the following properties:\ndeg(Sk) \u2264 k. (11) Sk(t) \u2265 1 for all t \u2265 W. (12) Sk(t) \u2264 exp ( \u2212\u2126(k2/W logW ) ) for all t \u2208 {0, . . . ,W \u2212 1}. (13)\nAll coefficients of Sk(t) are bounded in absolute value by W O(k). (14)\nFor completeness, we give the details of this construction and a proof of Properties 11-14 in Appendix A.\nFor any \u01eb > 0, let k = \u2308(W logW log (1/\u01eb))1/2\u2309, and let q : {\u22121, 1}n \u2192 R denote the n-variate polynomial defined via\nq(x) = Sk ( W +w0 + n\u2211\ni=1\nwixi\n) .\nIt is then straightforward to check that q is a positive one-sided \u01eb-approximation for h of degree at most k =\nO\u0303 (\u221a W log (1/\u01eb) )\nand weight at most W O\u0303(k). Similarly, \u2212q(\u2212x) is a negative one-sided \u01eb-approximation for h. This completes the proof.\nThe concept class of majorities is defined as the collection of the majority functions on each of the 2n\nsubsets of the variables.\nCorollary 1. The concept class of Majorities on n variables can be positive or negative reliably agnostically learned with error parameter \u01eb in time 2 O\u0303 (\u221a n log(1/\u01eb) ) .\nProof. Combine Theorems 5 and 7, noting that any majority function is a halfspace of weight at most n.\nBy combining Corollary 1 with Theorem 1, we obtain a fully reliable algorithm for learning low-weight halfspaces.\nCorollary 2. The concept class of Majorities on n variables can be fully reliably learned with error parameter \u01eb in time 2 O\u0303 (\u221a n log(1/\u01eb) ) .\nWe now consider significantly more expressive concept classes: disjunctions and conjunctions of majorities.\nTheorem 8. Consider m functions f1 . . . fm. Fix a d > 0, and suppose that each fi has a positive one-sided (\u01eb/m)-approximating polynomial of degree at most d and weight at most W . Then ORm(f1, . . . , fm) has a positive one-sided \u01eb-approximating polynomial of degree at most d and weight at most m \u00b7W .\nSimilarly, if each fi has a negative one-sided (\u01eb/m)-approximating polynomial of degree at most d and weight at most W , then ANDm(f1, . . . , fm) has a negative one-sided \u01eb-approximating polynomial of degree at most d and weight at most m \u00b7W .\nProof. We prove the statement about ORm(f1, . . . , fm); the statement about ANDm(f1, . . . , fm) is analogous. Let pi be a positive one-sided (\u01eb/m)-approximating polynomial for fi. Then p = \u22121+ \u2211m i=1(1+pi) is a positive one-sided \u01eb-approximating polynomial for f . Moreover, the degree of p is at most maxi{deg(pi)} \u2264 d, while the weight of p is at most m \u00b7W . This completes the proof.\nCorollary 3. Disjunctions of m Majorities can be positive reliably learned with error parameter \u01eb in time 2O\u0303( \u221a n log(m/\u01eb)). Conjunctions of m Majorities can also be negative reliably learned in the same time bound.\nProof. Combine Theorems 5, 7, and 8."}, {"heading": "5 Trading off Runtime for Sample Complexity", "text": ""}, {"heading": "5.1 Standard Agnostic Learning of Conjunctions", "text": "Kalai et al. (2005) showed how to use L1-regression to agnostically learn conjunctions on n variables in time\n2O\u0303( \u221a n log(1/\u01eb)). However, the sample complexity of the algorithm can also be as large as 2O\u0303( \u221a n log(1/\u01eb)).\nThis result relies on the existence of \u01eb-approximating polynomials for the n-variate AND function of degree O\u0303( \u221a n log(1/\u01eb)).\nTheorem 6 gives an avenue for obtaining better sample complexity, at the cost of increased runtime: if we can show that any conjunction on n variables can be \u01eb-approximated by a degree d polynomial of weight W \u226a 2 \u221a\nn log(1/\u01eb), then the L1-regression algorithm will have sample complexity only poly(d,W ) and runtime nO(d). Thus, in order to obtain tradeoffs between runtime and sample complexity for algorithms that agnostically learn conjunctions, it suffices to understand what are the achievable tradeoffs between degree and weight of \u01eb-approximating polynomials for the AND function.\nIn fact, this question is already well-understood in the case of constant \u01eb: letting ANDn denote the AND function on n variables, Servedio et al. (2012) implicitly showed that for any \u221a n < d and any \u01eb = \u0398(1), there exists an \u01eb-approximating polynomial for the ANDn function of degree d and weight poly(n)\u00b72O\u0303(n/d). In fact, this construction is essentially optimal, matching a lower bound for constant \u01eb proved in the same paper (see also (Bun and Thaler, 2013a, Lemma 20)). We now extend the ideas of Servedio et al. (2012) to handle subconstant values of \u01eb. Theorem 9. Fix a d > \u2126\u0303 (\u221a n log n log(1/\u01eb) ) . There exists an (explicit) \u01eb-approximating polynomial for\nANDn of degree d and weight 2O\u0303(n log(1/\u01eb)/d).\nProof. We write ANDn as an \u201cand-of-ands\u201d, where the outer AND has fan-in t, and the inner ANDs each have fan-in n/t, where we choose t such that t/ log t = n2 log(1/\u01eb)/d2. That is, we write ANDn(x) = ANDt(ANDn/t(x (1)), . . . ,ANDn/t(x (t))), where x(i) = (xn\u00b7(i\u22121)/t+1, . . . , xn\u00b7i/t) denotes the ith \u201cblock\u201d of variables in x. Note that t \u2264 n by the assumption that d > \u2126\u0303 (\u221a n log n log(1/\u01eb) ) .\nWe obtain an \u01eb-approximating polynomial p for ANDn as follows. Kahn et al. (1996) gave an explicit \u01ebapproximating polynomial pt for ANDt of degree d\u2032 = O( \u221a t log t log(1/\u01eb)). It is an immediate consequent of Parseval\u2019s inequality that pt has weight at most td \u2032/2. We will also need the following standard fact. Fact 2. The real polynomial q : {\u22121, 1}n/t \u2192 {\u22121, 1} defined via q(y1, . . . yn/t) = 2 \u220fn/t i=1 1+yi 2 \u2212 1 computes ANDn/t(x). Moreover, q has degree at most n/t and weight at most 3.\nFinally, we define p(x) = pt(q(x(1)), . . . q(x(t))). Notice that p has degree at most d\u2032 \u00b7 n/t = O (\u221a t log t log(1/\u01eb) \u00b7 n/t ) =O ( n \u221a log t log(1/\u01eb)/t ) = O(d) and weight at most tO(d \u2032) = 2O\u0303(n log(1/\u01eb)/d)\nas claimed.\nWe obtain the following learning result that holds even for \u01eb = o(1).\nCorollary 4. For any d > \u2126\u0303 (\u221a n log n log(1/\u01eb) ) and \u01eb, the class of conjunctions on n variables can be\nagnostically learned to error \u01eb in time nO(d), with sample complexity 2O\u0303(n log(1/\u01eb)/d)."}, {"heading": "5.2 Positive Reliable Learning of DNFs", "text": "As discussed in Section 1.2, the reductions of Kalai et al. (2012), combined with the agnostic learning algorithm for conjunctions due to Kalai et al. (2005), imply that DNFs can be positive reliably learned in time 2(O\u0303( \u221a n)). However, the sample complexity of the resulting algorithm may be as large as its runtime. Here, we give an algorithm for positive reliable learning of DNFs that has smaller sample complexity, at the cost of larger runtime.\nTheorem 10. For any DNF F of size m and width (i.e., maximum term length) at most w, and any d > \u2126\u0303 (\u221a w logw log(1/\u01eb) ) , there exists an (explicit) positive one-sided \u01eb-approximating polynomial for F of\ndegree d and weight 2O\u0303(w log(m/\u01eb)/d). Similarly, any CNF F of size m and width at most w has a negative one-sided \u01eb-approximation with the same weight and degree bounds.\nProof. We prove the result for DNFs; the case of CNFs is analogous. Let Ci denote the ith clause of F . Since Ci has width at most w, Theorem 9 implies the existence of an \u01eb/m-approximating polynomial pi for Ci of degree d and weight at most 2O\u0303(w log(m/\u01eb)/d). Then p = \u22121 + \u2211m i=1(1 + pi) is a positive one-sided \u01eb-approximating polynomial for F . Moreover, the degree of p is at most maxi{deg(pi)} \u2264 d, while the weight of p is at most m \u00b7 2O\u0303(w log(m/\u01eb)/d) = 2O\u0303(w log(m/\u01eb)/d). This completes the proof.\nWe obtain the following learning result as a corollary.\nCorollary 5. For any d > \u2126\u0303 (\u221a w logw log(1/\u01eb) ) , the concept class of DNFs of size m and width at most\nw can be positive reliably learned in time nO(d), using at most 2O\u0303(w log(m/\u01eb)/d) samples. The class of CNFs of size m and width at most w can be negative reliably learned with the same efficiency guarantees.\nProof. Combine Theorems 5 and 10."}, {"heading": "6 Limitations of Our Techniques", "text": ""}, {"heading": "6.1 On Halfspaces", "text": "Theorem 7 establishes that all low-weight halfspaces (i.e., weight o(n2\u2212\u03b4) for some \u03b4 > 0) can be (both positive and negative) reliably learned in time 2o(n). It is reasonable to ask whether we can reliably learn all halfspaces in time 2o(n) using our techniques. Unfortunately, the answer is no.\nTheorem 11. There exists a halfspace h for which d\u0303eg+,1/8(h) and d\u0303eg\u2212,1/8(h) are both \u2126(n).\nProof. We prove the statement about d\u0303eg+,1/4, as the case of d\u0303eg\u2212,1/4 is similar. Given a Boolean function h : {\u22121, 1}n \u2192 {\u22121, 1}, let gh : {\u22121, 1}2n \u2192 {\u22121, 1} denote the function g(x, y) = h(x1)\u2229h(x2), where x1, x2 \u2208 {\u22121, 1}n. That is, g computes the intersection of two copies of h, where the two copies are applied to disjoint sets of input variables. Sherstov (2013b) proved that there exists a halfspace h such that deg\u00b1(g) = \u2126(n). Here, deg\u00b1(g) denotes the least degree of a real polynomial p that agrees in sign with g at all Boolean inputs. Notice deg\u00b1(g) \u2264 deg+,\u01eb(g) for any function g and any \u01eb < 1.\nCombining Sherstov\u2019s lower bound with Theorem 8 implies that \u2126(n) = deg\u00b1(g) \u2264 d\u0303eg+,1/4(g) \u2264 deg+,1/8(h). This completes the proof."}, {"heading": "6.2 On DNFs", "text": "All polynomial-sized DNFs can be positive reliably learned in time and sample complexity 2O\u0303( \u221a n), and Corollary 5 shows how to obtain smooth tradeoffs between runtime and sample complexity for this learning task. It is natural to ask whether DNFs can be negative reliably learned with similar efficiency using our techniques. Unfortunately, this is not the case. Bun and Thaler (2013a), extending a seminal lower bound of Aaronson and Shi (2004), showed that there is a polynomial-sized DNF f (more specifically, f is the negation of the ELEMENT DISTINCTNESS function) satisfying d\u0303eg\u2212(f) = \u2126((n/ log n) 2/3); thus, our\ntechniques cannot negative reliably learn polynomial-sized DNFs in time better than exp ( O\u0303 ( n2/3 )) .\nWhile Bun and Thaler\u2019s is the best-known lower bound on the negative one-sided approximate degree of any polynomial-sized DNF \u2013 indeed, up to polylogarithmic factors, it is the best-known lower bound for any function in AC0 \u2013 no o(n) upper bound is known for the negative one-sided approximate degree of polynomial-sized DNFs."}, {"heading": "7 Discussion", "text": "We have shown that concept classes with low one-sided approximate degree can be efficiently learned in the reliable agnostic model. As we have seen, one-sided approximate degree is an intermediate notion that lies between threshold degree and approximate degree; we have identified important concept classes, such as majorities and intersections of majorities, whose one-sided approximate degree is strictly smaller than its approximate degree. Consequently, we have obtained reliable (in some cases, even fully reliable) agnostic learning algorithms that are strictly more efficient than the fastest known agnostic ones. We have thereby given the first evidence that even fully reliable agnostic learning may be strictly easier than agnostic learning.\nThe notion of one-sided polynomial approximation has only been introduced very recently (Bun and Thaler (2013a)), and previously had only been used to prove lower bounds. By giving the first algorithmic application of one-sided polynomial approximations, our work lends further credence to the notion that these approximations are fundamental objects worthy of further study in their own right. Just as threshold degree and approximate degree have found applications (both positive and negative) in many domains outside of learning theory, we hope that one-sided approximate degree will as well. Identifying such applications is a significant direction for further work.\nOur work does raise several open questions specific to one-sided polynomial approximations. Here we highlight two. We have shown that halfspaces of weight at most W have one-sided approximate degree O\u0303(W 1/2), and yet there exist halfspaces with one-sided approximate degree \u2126(n). However, the (nonexplicit) halfspace from Sherstov (2013b) that we used to demonstrate the \u2126(n) lower bound has weight 2\u2126(n). Is it possible that all halfspaces of weight 2O(n\n1\u2212\u03b4) for some \u03b4 > 0 always have one-sided approximate degree o(n)? We also showed how to obtain tradeoffs between the weight and degree of one-sided polynomial approximations for DNFs. Is it possible to obtain similar tradeoffs for majorities?"}, {"heading": "Acknowledgments", "text": "VK is supported by a Simons Postdoctoral Fellowship. JT is supported by a Simons Research Fellowship. This research was carried out while the authors were at the Simons Institute for the Theory of Computing at the University of California, Berkeley."}, {"heading": "A Missing Details For Theorem 7", "text": "For any k > 0, Kahn et al. (1996) define the polynomial Sk(t) as follows (in the below, a, b, and r are parameters that Kahn et al. ultimately set to a = \u0398(k/ logW ), b = \u0398(k2/(W logW )), and r = k\u2212a\u2212 b).\nSk(t) = C \u22121 \u00b7\n  a\u220f\ni=0\n(t\u2212 i) \u00b7 W\u220f\nj=W\u2212b (t\u2212 j)\n  \u00b7 Tr(\nt\u2212 a W \u2212 b\u2212 a), (15)\nwhere C = (\u220fa i=0(W \u2212 i) \u00b7 \u220fW j=W\u2212b(W \u2212 j) ) \u00b7 Tr( W\u2212aW\u2212b\u2212a) is a normalization constant chosen so\nthat Sk(W ) = 1, and as usual Tr denotes the r\u2019th Chebyshev polynomial of the first kind. We now verify that Sk satisfies Properties 11-14, which we restate here for the reader\u2019s convenience.\nProperty 11: deg(Sk) \u2264 k. Property 12: Sk(t) \u2265 1 for all t \u2265 W. Property 13: Sk(t) \u2264 exp ( \u2212\u2126(k2/W logW ) ) for all t \u2208 {0, . . . ,W \u2212 1}.\nProperty 14: All coefficients of Sk(t) are bounded in absolute value by W O(k).\nProperty 11 is immediate from the definition of Sk and the choice of r = k \u2212 a\u2212 b.\nTo see that Property 12 holds, we note that Sk(W ) = 1. The property will therefore follow if we can prove that\nSk(t) \u2265 Sk(W ) for all t \u2265 W. (16) To establish Equation (16), note first that Tr is non-decreasing on the interval [1,\u221e] (cf. Property 5). Second, notice that t\u2212aW\u2212b\u2212a is an increasing function on [W,\u221e], and is also larger than 1 on this interval. Thus, Tr( t\u2212aW\u2212b\u2212a) is a non-decreasing function in t for t \u2208 [W,\u221e]. Finally, it is an easy observation that \u220fa i=0(t \u2212 i) \u00b7\n\u220fW j=W\u2212b(t \u2212 j) is a non-decreasing function in t on the interval t \u2208 [W,\u221e]. Thus,\u220fa\ni=0(t \u2212 i) \u00b7 \u220fW\nj=W\u2212b(t \u2212 j) \u00b7 Tr( t\u2212aW\u2212b\u2212a) is a non-decreasing function of t on the same interval, and Equation (16) follows.\nProperty 13 is immediate from the analysis of Kahn et al. (1996). To see that Property 14 holds, note that \u220fa i=0(t \u2212 i) \u220fW j=W\u2212b(t \u2212 j) is a polynomial in t with coefficients all bounded in absolute value by W a+b \u2264 W k, while Tr( t\u2212aW\u2212b\u2212a) is also a polynomial in t, with coefficients bounded in absolute value by (3 + a)r \u2264 W k (cf. Property 6)."}], "references": [{"title": "Quantum lower bounds for the collision and the element distinctness problems", "author": ["Scott Aaronson", "Yaoyun Shi"], "venue": "J. ACM,", "citeRegEx": "Aaronson and Shi.,? \\Q2004\\E", "shortCiteRegEx": "Aaronson and Shi.", "year": 2004}, {"title": "Any and-or formula of size n can be evaluated in time n1/2+o(1) on a quantum computer", "author": ["Andris Ambainis", "Andrew M. Childs", "Ben Reichardt", "Robert Spalek", "Shengyu Zhang"], "venue": "SIAM J. Comput.,", "citeRegEx": "Ambainis et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ambainis et al\\.", "year": 2010}, {"title": "Rademacher and gaussian complexities: Risk bounds and structural results", "author": ["Peter L. Bartlett", "Shahar Mendelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bartlett and Mendelson.,? \\Q2002\\E", "shortCiteRegEx": "Bartlett and Mendelson.", "year": 2002}, {"title": "Bounds for small-error and zero-error quantum algorithms. In FOCS, pages 358\u2013368", "author": ["Harry Buhrman", "Richard Cleve", "Ronald de Wolf", "Christof Zalka"], "venue": "IEEE Computer Society,", "citeRegEx": "Buhrman et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Buhrman et al\\.", "year": 1999}, {"title": "Hardness amplification and the approximate degree of constant-depth circuits", "author": ["Mark Bun", "Justin Thaler"], "venue": null, "citeRegEx": "Bun and Thaler.,? \\Q2013\\E", "shortCiteRegEx": "Bun and Thaler.", "year": 2013}, {"title": "Dual lower bounds for approximate degree and markov-bernstein inequalities", "author": ["Mark Bun", "Justin Thaler"], "venue": null, "citeRegEx": "Bun and Thaler.,? \\Q2013\\E", "shortCiteRegEx": "Bun and Thaler.", "year": 2013}, {"title": "Introduction to Approximation Theory", "author": ["E.W. Cheney"], "venue": "AMS Chelsea Publishing Series. AMS Chelsea Pub.,", "citeRegEx": "Cheney.,? \\Q1982\\E", "shortCiteRegEx": "Cheney.", "year": 1982}, {"title": "Metacost: A general method for making classifiers cost-sensitive", "author": ["Pedro Domingos"], "venue": "Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Domingos.,? \\Q1999\\E", "shortCiteRegEx": "Domingos.", "year": 1999}, {"title": "The foundations of cost-sensitive learning", "author": ["Charles Elkan"], "venue": "Proceedings of the 17th International Joint Conference on Artificial Intelligence,", "citeRegEx": "Elkan.,? \\Q2001\\E", "shortCiteRegEx": "Elkan.", "year": 2001}, {"title": "Representation, approximation and learning of submodular functions using low-rank decision trees", "author": ["Vitaly Feldman", "Pravesh Kothari", "Jan Vondr\u00e1k"], "venue": "In Proceedings of the Conference on Learning Theory (COLT),", "citeRegEx": "Feldman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2013}, {"title": "A separation of np and conp in multiparty communication", "author": ["Dmitry Gavinsky", "Alexander A. Sherstov"], "venue": "complexity. Theory of Computing,", "citeRegEx": "Gavinsky and Sherstov.,? \\Q2010\\E", "shortCiteRegEx": "Gavinsky and Sherstov.", "year": 2010}, {"title": "Decision theoretic generalizations of the PAC model for neural net and other learning applications", "author": ["David Haussler"], "venue": "Information and Computation,", "citeRegEx": "Haussler.,? \\Q1992\\E", "shortCiteRegEx": "Haussler.", "year": 1992}, {"title": "On the complexity of linear prediction: Risk bounds, margin bounds, and regularization", "author": ["Sham M. Kakade", "Karthik Sridharan", "Ambuj Tewari"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Kakade et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kakade et al\\.", "year": 2008}, {"title": "Agnostically learning halfspaces", "author": ["Adam Tauman Kalai", "Adam R. Klivans", "Yishay Mansour", "Rocco A. Servedio"], "venue": "In FOCS,", "citeRegEx": "Kalai et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Kalai et al\\.", "year": 2005}, {"title": "Reliable agnostic learning", "author": ["Adam Tauman Kalai", "Varun Kanade", "Yishay Mansour"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Kalai et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kalai et al\\.", "year": 2012}, {"title": "Toward efficient agnostic learning", "author": ["Michael Kearns", "Robert E. Schapire", "Linda M. Sellie"], "venue": "In Machine Learning,", "citeRegEx": "Kearns et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Kearns et al\\.", "year": 1994}, {"title": "An Introduction to Computational Learning Theory", "author": ["Michael J. Kearns", "Umesh Vazirani"], "venue": null, "citeRegEx": "Kearns and Vazirani.,? \\Q1994\\E", "shortCiteRegEx": "Kearns and Vazirani.", "year": 1994}, {"title": "Lower bounds for agnostic learning via approximate rank", "author": ["Adam R. Klivans", "Alexander A. Sherstov"], "venue": "Computational Complexity,", "citeRegEx": "Klivans and Sherstov.,? \\Q2010\\E", "shortCiteRegEx": "Klivans and Sherstov.", "year": 2010}, {"title": "On the problem of the most efficient tests for statistical hypotheses", "author": ["J. Neyman", "E.S. Pearson"], "venue": "Philos. Trans. R. So. Lond. Ser. A Contain. Pap. Math. Phys. Character,", "citeRegEx": "Neyman and Pearson.,? \\Q1933\\E", "shortCiteRegEx": "Neyman and Pearson.", "year": 1933}, {"title": "An Introduction to the Approximation of Functions. Blaisdell book in numerical analysis and computer science", "author": ["T.J. Rivlin"], "venue": "Dover Publications,", "citeRegEx": "Rivlin.,? \\Q1981\\E", "shortCiteRegEx": "Rivlin.", "year": 1981}, {"title": "Attribute-efficient learning and weight-degree tradeoffs for polynomial threshold functions", "author": ["Rocco A. Servedio", "Li-Yang Tan", "Justin Thaler"], "venue": "JMLR Proceedings,", "citeRegEx": "Servedio et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Servedio et al\\.", "year": 2012}, {"title": "Breaking the Minsky-Papert barrier for constant-depth circuits", "author": ["A.A. Sherstov"], "venue": "In STOC,", "citeRegEx": "Sherstov.,? \\Q2014\\E", "shortCiteRegEx": "Sherstov.", "year": 2014}, {"title": "Approximating the and-or tree", "author": ["Alexander A. Sherstov"], "venue": "Theory of Computing,", "citeRegEx": "Sherstov.,? \\Q2013\\E", "shortCiteRegEx": "Sherstov.", "year": 2013}, {"title": "Optimal bounds for sign-representing the intersection of two halfspaces by polynomials", "author": ["Alexander A. Sherstov"], "venue": null, "citeRegEx": "Sherstov.,? \\Q2013\\E", "shortCiteRegEx": "Sherstov.", "year": 2013}, {"title": "A theory of the learnable", "author": ["Leslie G. Valiant"], "venue": "Communications of the ACM,", "citeRegEx": "Valiant.,? \\Q1984\\E", "shortCiteRegEx": "Valiant.", "year": 1984}], "referenceMentions": [{"referenceID": 13, "context": "Abstract We study several questions in the reliable agnostic learning framework of Kalai et al. (2009), which captures learning tasks in which one type of error is costlier than other types.", "startOffset": 83, "endOffset": 103}, {"referenceID": 13, "context": "Following Kalai et al. (2012), we call these kinds of tasks reliable learning.", "startOffset": 10, "endOffset": 30}, {"referenceID": 13, "context": "Following Kalai et al. (2012), we call these kinds of tasks reliable learning. Closely related tasks have been widely studied in the statistics and machine learning literature. We discuss some of this work later; here, we simply note that the work of Kalai et al. and the present work depart from much of the extant literature by emphasizing computational considerations, i.e., by focusing on \u201cfast\u201d algorithms, and guarantees with respect to the zero-one loss. Kalai et al. (2012) introduced a formal framework to study reliable learning in the agnostic setting, which is a challenging model that captures the problem of learning in the presence of adversarial classification noise.", "startOffset": 10, "endOffset": 482}, {"referenceID": 13, "context": "Following Kalai et al. (2012), we call these kinds of tasks reliable learning. Closely related tasks have been widely studied in the statistics and machine learning literature. We discuss some of this work later; here, we simply note that the work of Kalai et al. and the present work depart from much of the extant literature by emphasizing computational considerations, i.e., by focusing on \u201cfast\u201d algorithms, and guarantees with respect to the zero-one loss. Kalai et al. (2012) introduced a formal framework to study reliable learning in the agnostic setting, which is a challenging model that captures the problem of learning in the presence of adversarial classification noise. In particular, the goal of an agnostic learning algorithm is to produce a hypothesis that has error that is at most \u01eb higher than the best from a certain class. A false positive error occurs when the true label is negative, but the hypothesis predicts positive. Analogously, a false negative error occurs when the true label is positive, but the hypothesis predicts negative. The best positive reliable classifier from a class is one that make no false positive errors and minimizes false negative errors. In the positive reliable learning setting, the goal of a learning algorithm is to output a hypothesis with the following properties: (i) its false positive error rate is at most \u01eb, (ii) its false negative error rate is at most \u01eb more than that of the best positive reliable classifier from the class. The notion of negative reliable learning is identical with the roles of false positive and false negatives reversed. Kalai et al. (2012) also introduced the notion of full reliability.", "startOffset": 10, "endOffset": 1628}, {"referenceID": 13, "context": "Meanwhile, concept classes with low approximate degree can be efficiently learned in the agnostic model, a connection that has yielded the fastest known algorithms for distribution-independent agnostic learning (Kalai et al., 2005).", "startOffset": 211, "endOffset": 231}, {"referenceID": 21, "context": "imate degree was introduced in its present form by Bun and Thaler (2013a) (see also (Sherstov, 2014)), though equivalent dual formulations had been used in several prior works (Gavinsky and Sherstov, 2010, Sherstov, 2013a, Bun and Thaler, 2013b).", "startOffset": 84, "endOffset": 100}, {"referenceID": 4, "context": "imate degree was introduced in its present form by Bun and Thaler (2013a) (see also (Sherstov, 2014)), though equivalent dual formulations had been used in several prior works (Gavinsky and Sherstov, 2010, Sherstov, 2013a, Bun and Thaler, 2013b).", "startOffset": 51, "endOffset": 74}, {"referenceID": 4, "context": "imate degree was introduced in its present form by Bun and Thaler (2013a) (see also (Sherstov, 2014)), though equivalent dual formulations had been used in several prior works (Gavinsky and Sherstov, 2010, Sherstov, 2013a, Bun and Thaler, 2013b). Our learning algorithm is similar to the L1 regression algorithm of Kalai et al. (2005); however, the analysis of our algorithm is more delicate.", "startOffset": 51, "endOffset": 335}, {"referenceID": 18, "context": "Reliable learning is also related to the Neyman-Pearson criterion from classical statistics \u2014 where it has been shown that the optimal strategy to minimize one type of errors, subject to the other type being bounded, is to threshold the ratio of the likelihoods (Neyman and Pearson, 1933).", "startOffset": 262, "endOffset": 288}, {"referenceID": 7, "context": ", (Domingos, 1999, Elkan, 2001)). Reliable learning is also related to the Neyman-Pearson criterion from classical statistics \u2014 where it has been shown that the optimal strategy to minimize one type of errors, subject to the other type being bounded, is to threshold the ratio of the likelihoods (Neyman and Pearson, 1933). However, the main problem is computational; in general the loss functions with different costs from these prior works are not convex and the resulting optimization problems are intractable. The work of Kalai et al. (2012) and the present work departs from the prior work in that we focus on algorithms with both provable guarantees on their generalization error with respect to the zero-one loss, and bounds on their computational complexity, rather than focusing purely on statistical efficiency.", "startOffset": 3, "endOffset": 546}, {"referenceID": 7, "context": ", (Domingos, 1999, Elkan, 2001)). Reliable learning is also related to the Neyman-Pearson criterion from classical statistics \u2014 where it has been shown that the optimal strategy to minimize one type of errors, subject to the other type being bounded, is to threshold the ratio of the likelihoods (Neyman and Pearson, 1933). However, the main problem is computational; in general the loss functions with different costs from these prior works are not convex and the resulting optimization problems are intractable. The work of Kalai et al. (2012) and the present work departs from the prior work in that we focus on algorithms with both provable guarantees on their generalization error with respect to the zero-one loss, and bounds on their computational complexity, rather than focusing purely on statistical efficiency. Kalai et al. (2012) showed that any concept class that is agnostically learnable under a fixed distribution is also learnable in the reliable agnostic learning models under the same distribution.", "startOffset": 3, "endOffset": 842}, {"referenceID": 10, "context": "Using these general reductions, Kalai et al. showed that the class of polynomial-size DNF formulae is positive reliable learnable under the uniform distribution in polynomial time with membership queries (it also follows from their reductions and the agnostic learning algorithm of Kalai et al. (2005) described below that DNF formulae can be positive reliably learned in the distribution-independent setting in time 2\u00d5( \u221a n)).", "startOffset": 32, "endOffset": 302}, {"referenceID": 10, "context": "Using these general reductions, Kalai et al. showed that the class of polynomial-size DNF formulae is positive reliable learnable under the uniform distribution in polynomial time with membership queries (it also follows from their reductions and the agnostic learning algorithm of Kalai et al. (2005) described below that DNF formulae can be positive reliably learned in the distribution-independent setting in time 2\u00d5( \u221a n)). Agnostically learning DNFs under the uniform distribution remains a notorious open problem, and thus their work gave the first indication that positive (or negative) reliable learning may be easier than agnostic learning. Kalai et al. (2005) put forth an algorithm for agnostic learning based on L1-regression.", "startOffset": 32, "endOffset": 670}, {"referenceID": 10, "context": "Using these general reductions, Kalai et al. showed that the class of polynomial-size DNF formulae is positive reliable learnable under the uniform distribution in polynomial time with membership queries (it also follows from their reductions and the agnostic learning algorithm of Kalai et al. (2005) described below that DNF formulae can be positive reliably learned in the distribution-independent setting in time 2\u00d5( \u221a n)). Agnostically learning DNFs under the uniform distribution remains a notorious open problem, and thus their work gave the first indication that positive (or negative) reliable learning may be easier than agnostic learning. Kalai et al. (2005) put forth an algorithm for agnostic learning based on L1-regression. Our reliable learning algorithms based on one-sided approximate degree upper bounds is inspired by and generalizes their work. Klivans and Sherstov (2010) subsequently established strong limitations on the L1-regression approach of Kalai et al.", "startOffset": 32, "endOffset": 894}, {"referenceID": 10, "context": "Using these general reductions, Kalai et al. showed that the class of polynomial-size DNF formulae is positive reliable learnable under the uniform distribution in polynomial time with membership queries (it also follows from their reductions and the agnostic learning algorithm of Kalai et al. (2005) described below that DNF formulae can be positive reliably learned in the distribution-independent setting in time 2\u00d5( \u221a n)). Agnostically learning DNFs under the uniform distribution remains a notorious open problem, and thus their work gave the first indication that positive (or negative) reliable learning may be easier than agnostic learning. Kalai et al. (2005) put forth an algorithm for agnostic learning based on L1-regression. Our reliable learning algorithms based on one-sided approximate degree upper bounds is inspired by and generalizes their work. Klivans and Sherstov (2010) subsequently established strong limitations on the L1-regression approach of Kalai et al. (2005), proving lower bounds on the size of any set of \u201cfeature functions\u201d that can point-wise approximate the concept classes of majorities and conjunctions.", "startOffset": 32, "endOffset": 991}, {"referenceID": 24, "context": "Definition 1 (PAC Learning (Valiant, 1984)).", "startOffset": 27, "endOffset": 42}, {"referenceID": 13, "context": "We review the various notions of reliable agnostic learning proposed by Kalai et al. (2012). As in the case of agnostic learning, the data comes from an arbitrary joint distribution D over X\u00d7{\u22121, 1}.", "startOffset": 72, "endOffset": 92}, {"referenceID": 14, "context": "Definition 3 (Positive Reliable Learning (Kalai et al., 2012)).", "startOffset": 41, "endOffset": 61}, {"referenceID": 14, "context": "Definition 4 (Negative Reliable Learning (Kalai et al., 2012)).", "startOffset": 41, "endOffset": 61}, {"referenceID": 14, "context": "Definition 5 (Fully Reliable Learning (Kalai et al., 2012)).", "startOffset": 38, "endOffset": 58}, {"referenceID": 14, "context": "Theorem 1 ((Kalai et al., 2012)).", "startOffset": 11, "endOffset": 31}, {"referenceID": 4, "context": "The definitions as they are presented here essentially appeared in prior work of Bun and Thaler (2013a) (see also Sherstov (2014)), who only required the notion we refer to as positive one-sided approximate degree.", "startOffset": 81, "endOffset": 104}, {"referenceID": 4, "context": "The definitions as they are presented here essentially appeared in prior work of Bun and Thaler (2013a) (see also Sherstov (2014)), who only required the notion we refer to as positive one-sided approximate degree.", "startOffset": 81, "endOffset": 130}, {"referenceID": 2, "context": "Bartlett and Mendelson (2002) proved the following result: Theorem 2 ((Bartlett and Mendelson, 2002)).", "startOffset": 70, "endOffset": 100}, {"referenceID": 2, "context": "Bartlett and Mendelson (2002) proved the following result: Theorem 2 ((Bartlett and Mendelson, 2002)).", "startOffset": 0, "endOffset": 30}, {"referenceID": 12, "context": "(2008) proved the following result: Theorem 3 ((Kakade et al., 2008)).", "startOffset": 47, "endOffset": 68}, {"referenceID": 12, "context": "Kakade et al. (2008) proved the following result: Theorem 3 ((Kakade et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 13, "context": "Our algorithm extends the L1-regression technique of Kalai et al. (2005) for agnostic learning, but we require a more detailed analysis.", "startOffset": 53, "endOffset": 73}, {"referenceID": 13, "context": "This program is similar to one used in the L1-regression algorithm for agnostic learning introduced by Kalai et al. (2005). The variables of the program are the \u2211d j=0 (n j ) = O(nd) coefficients of the polynomial p(x).", "startOffset": 103, "endOffset": 123}, {"referenceID": 9, "context": ", (Feldman et al., 2013)); we state this as a theorem for completeness.", "startOffset": 2, "endOffset": 24}, {"referenceID": 9, "context": ", (Feldman et al., 2013)); we state this as a theorem for completeness. Instead of the mathematical program described in the proof of Theorem 5, to obtain Theorem 6, the L1regression algorithm of Kalai et al. (2005) is directly applied, with the added constraint that the weight of the approximating polynomial is at most W .", "startOffset": 3, "endOffset": 216}, {"referenceID": 3, "context": "Buhrman et al. (1999)), the \u00d5( \u221a n log (1/\u01eb)) upper bound on d\u0303eg+,\u01eb(MAJ) is easily seen to be tight up to factors hidden by the \u00d5 notation.", "startOffset": 0, "endOffset": 22}, {"referenceID": 6, "context": "the standard texts of Cheney (1982) and Rivlin (1981)).", "startOffset": 22, "endOffset": 36}, {"referenceID": 6, "context": "the standard texts of Cheney (1982) and Rivlin (1981)).", "startOffset": 22, "endOffset": 54}, {"referenceID": 13, "context": "1 Standard Agnostic Learning of Conjunctions Kalai et al. (2005) showed how to use L1-regression to agnostically learn conjunctions on n variables in time 2 \u221a n .", "startOffset": 45, "endOffset": 65}, {"referenceID": 18, "context": "In fact, this question is already well-understood in the case of constant \u01eb: letting ANDn denote the AND function on n variables, Servedio et al. (2012) implicitly showed that for any \u221a n < d and any \u01eb = \u0398(1), there exists an \u01eb-approximating polynomial for the ANDn function of degree d and weight poly(n)\u00b72\u00d5(n/d).", "startOffset": 130, "endOffset": 153}, {"referenceID": 4, "context": "In fact, this construction is essentially optimal, matching a lower bound for constant \u01eb proved in the same paper (see also (Bun and Thaler, 2013a, Lemma 20)). We now extend the ideas of Servedio et al. (2012) to handle subconstant values of \u01eb.", "startOffset": 125, "endOffset": 210}, {"referenceID": 13, "context": "2, the reductions of Kalai et al. (2012), combined with the agnostic learning algorithm for conjunctions due to Kalai et al.", "startOffset": 21, "endOffset": 41}, {"referenceID": 13, "context": "2, the reductions of Kalai et al. (2012), combined with the agnostic learning algorithm for conjunctions due to Kalai et al. (2005), imply that DNFs can be positive reliably learned in time 2(\u00d5( \u221a n)).", "startOffset": 21, "endOffset": 132}, {"referenceID": 21, "context": "Sherstov (2013b) proved that there exists a halfspace h such that deg\u00b1(g) = \u03a9(n).", "startOffset": 0, "endOffset": 17}, {"referenceID": 3, "context": "Bun and Thaler (2013a), extending a seminal lower bound of Aaronson and Shi (2004), showed that there is a polynomial-sized DNF f (more specifically, f is the negation of the ELEMENT DISTINCTNESS function) satisfying d\u0303eg\u2212(f) = \u03a9((n/ log n) 2/3); thus, our techniques cannot negative reliably learn polynomial-sized DNFs in time better than exp ( \u00d5 ( n2/3 )) .", "startOffset": 0, "endOffset": 23}, {"referenceID": 0, "context": "Bun and Thaler (2013a), extending a seminal lower bound of Aaronson and Shi (2004), showed that there is a polynomial-sized DNF f (more specifically, f is the negation of the ELEMENT DISTINCTNESS function) satisfying d\u0303eg\u2212(f) = \u03a9((n/ log n) 2/3); thus, our techniques cannot negative reliably learn polynomial-sized DNFs in time better than exp ( \u00d5 ( n2/3 )) .", "startOffset": 59, "endOffset": 83}, {"referenceID": 4, "context": "The notion of one-sided polynomial approximation has only been introduced very recently (Bun and Thaler (2013a)), and previously had only been used to prove lower bounds.", "startOffset": 89, "endOffset": 112}, {"referenceID": 4, "context": "The notion of one-sided polynomial approximation has only been introduced very recently (Bun and Thaler (2013a)), and previously had only been used to prove lower bounds. By giving the first algorithmic application of one-sided polynomial approximations, our work lends further credence to the notion that these approximations are fundamental objects worthy of further study in their own right. Just as threshold degree and approximate degree have found applications (both positive and negative) in many domains outside of learning theory, we hope that one-sided approximate degree will as well. Identifying such applications is a significant direction for further work. Our work does raise several open questions specific to one-sided polynomial approximations. Here we highlight two. We have shown that halfspaces of weight at most W have one-sided approximate degree \u00d5(W 1/2), and yet there exist halfspaces with one-sided approximate degree \u03a9(n). However, the (nonexplicit) halfspace from Sherstov (2013b) that we used to demonstrate the \u03a9(n) lower bound has weight 2\u03a9(n).", "startOffset": 89, "endOffset": 1010}], "year": 2017, "abstractText": "We study several questions in the reliable agnostic learning framework of Kalai et al. (2009), which captures learning tasks in which one type of error is costlier than other types. A positive reliable classifier is one that makes no false positive errors. The goal in the positive reliable agnostic framework is to output a hypothesis with the following properties: (i) its false positive error rate is at most \u01eb, (ii) its false negative error rate is at most \u01eb more than that of the best positive reliable classifier from the class. A closely related notion is fully reliable agnostic learning, which considers partial classifiers that are allowed to predict \u201cunknown\u201d on some inputs. The best fully reliable partial classifier is one that makes no errors and minimizes the probability of predicting \u201cunknown\u201d, and the goal in fully reliable learning is to output a hypothesis that is almost as good as the best fully reliable partial classifier from a class. For distribution-independent learning, the best known algorithms for PAC learning typically utilize polynomial threshold representations, while the state of the art agnostic learning algorithms use pointwise polynomial approximations. We show that one-sided polynomial approximations, an intermediate notion between polynomial threshold representations and point-wise polynomial approximations, suffice for learning in the reliable agnostic settings. We then show that majorities can be fully reliably learned and disjunctions of majorities can be positive reliably learned, through constructions of appropriate onesided polynomial approximations. Our fully reliable algorithm for majorities provides the first evidence that fully reliable learning may be strictly easier than agnostic learning. Our algorithms also satisfy strong attribute-efficiency properties, and in many cases they provide smooth tradeoffs between sample complexity and running time. University of California, Berkeley. Email: vkanade@eecs.berkeley.edu The Simons Institute for the Theory of Computing at UC Berkeley. Email: jthaler@seas.harvard.edu", "creator": "LaTeX with hyperref package"}}}