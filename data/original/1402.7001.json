{"id": "1402.7001", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2014", "title": "Marginalizing Corrupted Features", "abstract": "The goal of machine learning is to develop predictors that generalize well to test data. Ideally, this is achieved by training on an almost infinitely large training data set that captures all variations in the data distribution. In practical learning settings, however, we do not have infinite data and our predictors may overfit. Overfitting may be combatted, for example, by adding a regularizer to the training objective or by defining a prior over the model parameters and performing Bayesian inference. In this paper, we propose a third, alternative approach to combat overfitting: we extend the training set with infinitely many artificial training examples that are obtained by corrupting the original training data. We show that this approach is practical and efficient for a range of predictors and corruption models. Our approach, called marginalized corrupted features (MCF), trains robust predictors by minimizing the expected value of the loss function under the corruption model. We show empirically on a variety of data sets that MCF classifiers can be trained efficiently, may generalize substantially better to test data, and are also more robust to feature deletion at test time.", "histories": [["v1", "Thu, 27 Feb 2014 18:31:33 GMT  (2669kb,D)", "http://arxiv.org/abs/1402.7001v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["laurens van der maaten", "minmin chen", "stephen tyree", "kilian weinberger"], "accepted": false, "id": "1402.7001"}, "pdf": {"name": "1402.7001.pdf", "metadata": {"source": "CRF", "title": "Marginalizing Corrupted Features", "authors": ["Laurens van der Maaten", "Minmin Chen", "Kilian Q. Weinberger"], "emails": ["lvdmaaten@gmail.com", "m.chen@criteo.com", "swtyree@wustl.edu", "kilian@wustl.edu"], "sections": [{"heading": "1. Introduction", "text": "Dealing with overfitting is one of the key problems one encounters when training machinelearning models. When a learner overfits, it performs substantially better on its training data than on held-out test data. An overfitted learner relates the label or target value with patterns within the noise instead of within the data distribution. Three approaches are commonly used to combat overfitting: 1. early-stopping techniques monitor the performance of the model on a validation set during training, and stop the learning as soon as the validation performance deteriorates; 2. regularization techniques encourage the learning to find \u201csimple\u201d models by penalizing \u201ccomplex\u201d models, e.g., models with large parameter values; and 3. Bayesian techniques define a prior distribution over models that favor simple models, and perform predictions by averaging over the model posterior. Regularization and\nar X\niv :1\n40 2.\n70 01\nv1 [\ncs .L\nG ]\nBayesian techniques are intimately related because regularization techniques can often be viewed as introducing a prior over models and performing maximum-likelihood estimation.\nIn this paper, we propose a new alternative to counter overfitting. Instead of requiring the user to define prior distributions or regularizers over model parameters, which can be very counter intuitive, we focus on corruptions of the data. Our approach is based on the observation that overfitting would completely disappear if we were to train our models on infinite data drawn from the data distribution P. In such a hypothetical scenario, it is impossible to overfit models; and even high-variance models, such as the nearest neighbor classifier (Cover and Hart, 1967), become close to optimal (viz. the error of a nearest neighbor classifier is twice the Bayes error). Unfortunately, a learning scenario in which we only obtain a finite training set is more realistic; here, some variations in the data distribution will not be captured and the learned model performs worse at test time than during training.\nIn many learning scenarios, we may however have some additional knowledge about the data distribution: we might know that certain corruptions of data instances do not affect their conditional label distributions. As an example, deleting a few words in a text document rarely changes its topic. With this prior knowledge, we can corrupt existing data to generate new artificial instances that resemble those sampled from the actual data distribution. In fact, we will corrupt the existing finite training examples with a fixed corrupting distribution to construct an infinite training set. We show that for a wide range of learning models and noise distributions, it is practical to train models on such an infinite, augmented training set. We refer to the resulting framework as learning with marginalized corrupted features (MCF). So instead of approximating the exact statistics of P with finite data, MCF learns from a slightly modified data distribution P \u2032 with infinite data.\nBurges and Scho\u0308lkopf (1997) explicitly augment the training set with additional examples that are corrupted through similar transformations. Although the simplicity of such an approach is appealing, it lacks elegance and the computational cost of processing the additional corrupted training examples is prohibitive for most real-world problems. In contrast, we show that it is efficient to train predictors on an infinite amount of corrupted copies of the training data by marginalizing out the corrupting distribution. In particular, we focus on empirical risk minimization and derive analytical solutions for the expected loss under a large family of corrupting distributions for quadratic and exponential loss functions. This allows us to minimize the expected loss in computational time linear in the number of training examples. For logistic loss functions, which are used in many probabilistic models, we derive practical approximations and upper bounds for the expected value of the loss under the corrupting distribution.\nOur augmented data distribution P \u2032 is constructed using a simple stochastic rule: pick one of the finite training examples uniformly at random and transform it with some predefined corrupting distribution. Many corrupting distributions are possible, but in this paper we focus on 1. Gaussian corruption, 2. Poisson corruption, and 3. (unbiased) blankout or dropout corruption (random deletion of features). The Gaussian corruption model is mainly of interest for continuous-valued data sets; special cases of MCF with Gaussian corruption have already been studied in the context of Parzen density estimation (Parzen, 1962) and in the context of vicinal risk minimization (Chapelle et al., 2000). The Poisson corruption model is of interest when the data comprises count vectors, e.g.,\nin document classification. Poisson corruption is particularly appealing as it introduces no additional hyper-parameters and, in our results, improves the test accuracy on almost all data sets that comprise count data. The blankout corruption model is of interest in data sets with heavy-tailed feature distributions, such as filter responses, and in settings where blankout noise is a known source of variance in the original data distribution P\u2014 possibly unobserved in the training data. This happens, e.g., in document classification from term-frequency vectors: a big portion of each document (especially after stop-word removal) is sampled from the tail of the power-law distribution, for which the blankout noise model is a surprisingly good approximation: it models the common case that some of the words related to the class of the document are missing, e.g. because the author used other synonyms. Blankout corruption is also of interest in the \u201cnightmare at test time\u201d scenario (Globerson and Roweis, 2006) in which some of the features are deleted during testing, e.g., due to sensors failures or because the feature computation exceeds a time budget, and we wish to make predictions that are robust to this feature deletion. Different from previous work (Bhattacharyya et al., 2004; Globerson and Roweis, 2006; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007), our setting focuses on random feature removal and not on the (in practice much rarer) worst-case adversarial setting.\nAn earlier short paper on this work (van der Maaten et al., 2013) already introduces the MCF learning framework, but the present paper provides a large amount of additional details, analysis, and experiments. The paper makes the following contributions: 1. we introduce learning with marginalized corrupted features, a framework that trains robust classifiers by marginalizing out all possible feature corruptions from a pre-defined distribution; 2. we derive plug-in solutions for the quadratic, exponential, and logistic loss functions for a range of corrupting distributions, which can be incorporated into learning algorithms out-of-the-box; and 3. on several real-world data sets, we show that training with MCF may lead to more robust classifiers and may substantially decrease generalization errors in various learning settings. Given the simplicity and elegance of MCF, it could become a valuable alternative to the common l1 or l2-norm regularizers.\nThe outline of the remainder of this paper is as follows. In Section 2, we discuss prior work that is related to the work presented in this paper. In Section 3, we introduce marginalized corrupted features (MCF) regularization and we derive MCF variants of quadratic and exponential loss. In Section 4, we present approximations and upper bounds that allow MCF to be used with logistic loss functions. Section 5 presents an extensive experimental evaluation in which we compare MCF-regularized predictors with standard predictors in various document and image classification problems, in a classification problem from bioinformatics, and in the \u201cnightmare at test time scenario\u201d. Section 6 concludes the paper with a discussion of the results presented in the paper as well as directions for future work."}, {"heading": "2. Related work", "text": "There are two motivations for training a classifier with MCF: 1. to reduce the effects of overfitting during training ; and 2. to combat the effect of data corruption during testing. Both motivations connect with different lines of prior work, and in this section we discuss both of them."}, {"heading": "2.1 Corruption during training", "text": "The initial publication by Burges and Scho\u0308lkopf (1997) has inspired various lines of work that explicitly corrupt training data during training. Most prominently, Vincent et al. (2008, 2010) propose to randomly blank out features in the training data that is used as input to autoencoders, whilst leaving the desired output (the original training data) unaltered. The resulting denoising autoencoder model is now commonly used as a building block in deep learning (Maillet et al., 2009; Glorot et al., 2011; Mesnil et al., 2011), and blankout corruption is also increasingly applied on the hidden units of neural networks as a form of regularization (Hinton et al., 2012). Since autoencoders are non-linear, the marginalization over the corrupting distribution cannot be performed analytically in such models. Linear denoising autoencoders (Chen et al., 2012) can be viewed as a special case of MCF that aim to minimize the expected value of the reconstruction error under blankout corruption\u2014 and which are stacked in multiple layers. Herbrich and Graepel (2004) propose an elegant generalization of SVMs that learns to be invariant to polynomial input transformations via a semi-definite programming formulation.\nIn online learning and bandit problems, various studies have shown that it is possible to learn from data that are subject to a (possibly unknown) corrupting distribution (Flaxman et al., 2005; Abernethy et al., 2008; Cesa-Bianchi et al., 2010). For instance, Cesa-Bianchi et al. (2011) show that noise in the data does not affect the convergence rate of online learners. A similar regret bound is proven by Rostamizadeh et al. (2011) for online learning under the presence of randomly missing features (i.e. blankout corruption). These studies differ from our work in that they show that (unknown) corruptions in the data do not impair learning performance too much. By contrast, our work shows that adding corruptions to the data can actually improve learning performance."}, {"heading": "2.2 Corruption during testing", "text": "Several prior studies consider implicit approaches for data sets that are subject to corruptions during test time (this is also known as \u201cthe nightmare at test-time\u201d scenario). Most of these studies propose to minimize the loss under an adversarial worst-case scenario. In particular, Globerson and Roweis (2006) propose a minimax-formulation in which the loss is minimized assuming maximum \u201cdamage\u201d through corruption. By contrast, Dekel and Shamir (2008) propose a linear-programming formulation that minimizes an approximation to the same quantity for margin-based predictors. Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature. Livni et al. (2012) consider a scenario in which an adversarial chooses the corrupting distribution from the set of all distributions with a pre-specified variance as to increase the expected loss under the corruption as much as possible. Chechik et al. (2008) propose an algorithm that maximizes the margin in the subspace of the observed features for each training instance to be robust against random feature deletion. Teo et al. (2008) generalize the worst-case scenario from simple feature corruption to obtain invariances to transformations such as image rotations or translations. Their framework incorporates sev-\neral prior formulations on learning with invariants as special cases, most prominently, the formulation of Herbrich and Graepel (2004).\nSuch previous work differs from our approach in that it focuses on adversarial scenarios and does not consider the corruption analytically in expectation. Further, it mostly focuses on a very specific corruption model. In particular, existing approaches suffer from three main disadvantages: 1. they are complex and computationally expensive; 2. they minimize the loss of a worst-case scenario that is very unlikely to be encountered in practice; and 3. they do not provide a flexible framework that can be used with a variety of models and corrupting distributions. By contrast, we propose a much simpler approach that scales linearly in the number of training samples, that considers an average-case instead of a worstcase scenario, and that can readily be used with a variety of loss functions and a large family of corruption models."}, {"heading": "3. Learning with Marginalized Corrupted Features (MCF)", "text": "To derive the marginalized corrupted features (MCF) framework, we start by defining a corrupting distribution that specifies how training observations x are transformed into corrupted versions x\u0303. Throughout the paper, we assume that the corrupting distribution factorizes over dimensions and that each individual distribution PE is a member of the natural exponential family. (We will see later that for MCF with quadratic loss functions, these assumptions may be relaxed.) Specifically, we assume a corrupting distribution of the form:\np(x\u0303|x) = D\u220f d=1 PE(x\u0303d|xd; \u03b7d), (1)\nwhere \u03b7d represents user-defined hyperparameters of the corrupting distribution on dimension d. Corrupting distributions of interest, for PE , include: 1. independent salt or \u201cblankout\u201d (or dropout) noise in which the d-th feature is randomly set to zero with probability qd; 2. bit-swap noise in which the value of the d-th bit is randomly swapped with probability qd; 3. independent Gaussian noise on the d-th feature with variance \u03c3 2 d; 4. independent Laplace noise on the d-th feature with variance 2\u03bb2d; and 5. independent Poisson corruption in which the d-th feature is used as the rate of the Poisson distribution. Note that the definition in (1) allows for different features to use arbitrary different corrupting distributions. In the remainder of this paper, we propose an efficient way to train a classifier on corrupted inputs x\u0303, sampled from the distribution p(x\u0303|x)P(x). There are at least two motivations for doing so:\n1. Nightmare at test-time. In the nightmare at test-time scenario, introduced by Globerson and Roweis (2006), there is an expectation that corruption will appear during test-time. Although the training data is sampled from P(x), the test data will be sampled from the distribution p(x\u0303|x)P(x). Training the classifier on the corrupted data corrects this distribution drift. This scenario appears, for example, in the context of search engines. A feature can be reliably collected for the training set, but during testing it is dropped if its computation time exceeds a pre-specified time limit. The frequency of these feature drop-outs can be measured and incorporated into training with the appropriate dropout\ndistribution. Similarly, one can imagine scenarios (e.g. in robotics or sensor networks) where features correspond to unreliable sensor readings.\n2. Regularization. The more common motivation is improved generalization. Here, the corrupting distribution is meant to capture some of the variance inherent in P(x). In this setting, one must guarantee that the classifier is still applicable for the test case, where data is sampled directly from P. More precisely, it must be unbiased. Let h(x) be the classification function, we therefore require of the corrupting distribution that\nE[h(x\u0303)]p(x\u0303|x) = h(x). (2)\nIn other words, corrupting an input should not change its expected prediction and a test input obtains the expected prediction that the same input would obtain during training. In the linear case, the classifier is parameterized by a vector w. For regression, the prediction function is defined as h(x) = w>x and we require E[x\u0303] = x. For classification, it is h(x) = sign(w>x), which necessitates the slightly weaker condition E[x\u0303] = s(x)x for any bounded s(x) > 0. Table 1 showcases several biased and unbiased distributions.\nAssume we are provided with a training data set D = {(xn, yn)}Nn=1 and a loss function L(x, y; \u0398), with model parameters \u0398. A simple approach to approximately learn from the distribution p(x\u0303|x)P(x) is to follow the spirit of Burges and Scho\u0308lkopf (1997) and corrupt each training sample M times, following (1). For each xn \u2208 D, this results in corresponding corrupted observations x\u0303nm (with m = 1, . . . ,M) and leads to the construction of a new data set D\u0303 of size |D\u0303| = MN . This new data set can be used for training in an empirical risk minimization framework by minimizing the surrogate loss function:\nL(D\u0303; \u0398) = 1 N N\u2211 n=1 1 M M\u2211 m=1 L(x\u0303nm, yn; \u0398), (3)\nwith x\u0303nm \u223c p(x\u0303nm|xn). Such approaches have recently become popular, in particular, in the deep-learning community as a way to regularize deep networks (Hinton et al., 2012).\nAlthough approaches that explicitly corrupt the training data are effective, they lack elegance and come with high computational costs: the minimization of L(D\u0303; \u0398) scales linearly in the number of corrupted observations, i.e. it scales as O(NM). It is, however, of interest to consider the limiting case in which M \u2192\u221e. In this case, we can apply the weak law of large numbers and rewrite 1M \u2211M m=1 L(x\u0303m, ym; \u0398) as its expectation (Duda et al., 2001, \u00a72.10.2) to obtain the following surrogate loss:\nL(D; \u0398) = 1 N N\u2211 n=1 E[L(x\u0303n, yn; \u0398)]p(x\u0303n|xn). (4)\nMinimizing the expected value of the loss under the corruption model leads to a new approach for training predictors that we refer to as learning with marginalized corrupted features (MCF). MCF may lead to algorithms with an O(N) training complexity in situations in which the expectation in (4) is tractable, which is indeed the case for commonly used loss functions L(x\u0303n, yn; \u0398) and corrupting distributions p(x\u0303|x).\nIn the following, we show that for linear predictors that employ a quadratic or exponential loss function, the required expectations under p(x\u0303|x) in (4) can be computed analytically for all corrupting distributions in the natural exponential family. For linear predictors with logistic loss we derive practical approximations and upper bounds for the expected loss under p(x\u0303|x), which may serve as surrogate loss functions."}, {"heading": "3.1 Quadratic loss", "text": "Assuming a linear model parametrized by vector w and a target variable y (for regression, y is continuous; for binary classification, y \u2208 {\u22121,+1}), the expected value of the quadratic loss under corrupting distribution p(x\u0303|x) is given by:\nL(D; w) = 1 N N\u2211 n=1 E\n[( w>x\u0303n \u2212 yn )2] p(x\u0303n|xn)\n= 1\nN N\u2211 n=1 E [ w>x\u0303nx\u0303 > nw \u2212 2ynw>x\u0303n + y2n ] p(x\u0303n|xn)\n= w> ( 1\nN N\u2211 n=1 [ E[x\u0303n]E[x\u0303n]> + diag (V[x\u0303n]) ]) w \u2212 2 ( 1 N N\u2211 n=1 ynE [x\u0303n] )> w + 1.\n(5)\nHerein, V[x] denotes the variance of x, and all expectations are under p(x\u0303n|xn). Note that irrespective of what corruption model is used, (5) is quadratic in w, and hence convex. The optimal solution w\u2217 can be computed with a variation of the ordinary least squares closed-form solution:\nw\u2217 = ( N\u2211 n=1 [ E[x\u0303n]E[x\u0303n]> + diag (V[x\u0303n]) ])\u22121( N\u2211 n=1 ynE [x\u0303n] ) . (6)\nHence, to minimize the expected quadratic loss under the corruption model, we only need to compute the mean and variance of the corrupting distribution, which is practical for all exponential-family distributions (as well as for certain distributions outside of the exponential family, such as Student-t distributions with more than two degrees of freedom). Table 1 gives an overview of the required mean and variance for six corrupting distributions of interest.\nSpecial case. An interesting setting of MCF with quadratic loss occurs when the corrupting distribution p(x\u0303|x) is an isotropic Gaussian distribution with mean x and variance \u03c32I. For such a Gaussian corruption model, we obtain the standard l2-regularized quadratic loss with regularization parameter \u03c32 that is used in ridge regression as special case (Chapelle et al., 2000):\nL(D; w) = w> ( 1\nN N\u2211 n=1 xnx > n ) w \u2212 2 ( 1 N N\u2211 n=1 ynxn )> w + \u03c32w>w + 1. (7)\nPerhaps surprisingly, using MCF with Laplace corruption also leads to ridge regression with the regularization parameter taking value 2\u03bb2. Indeed, ridge regression arises for every\nunbiased corrupting distribution whose variance is not data-dependent. For corrupting distributions whose variance is data-dependent, other regularizers are obtained (see below).\nBlankout corruption. We study the use of blankout corruption in MCF quadratic loss in more detail here to show what kind of regularizers it produces. By plugging the relevant quantities from Table 1 into (6), we obtain the following solution for w\u2217 with MCF blankout (assuming \u2200d : qd = q):\nw\u2217 = ( N\u2211 n=1 xnx > n + q(1\u2212 q)S )\u22121( N\u2211 n=1 xnyn ) , where: S = ( N\u2211 n=1 xnx > n ) \u25e6 I (8)\nwhere \u25e6 denotes an element-wise Hadamard product. In words, the matrix S consists of only the diagonal of the Gram matrix. Consequently, MCF blankout corruption has the effect of multiplying the diagonal of the Gram matrix by a factor (1 + q\u2212 q2). This makes the MCF regularizer data-dependent : the regularization is stronger on dimensions that on average have a larger norm. This may be desirable in situations in which the data dimensions live on different scales as happens, for example, in word-count features. This is in contrast to the data-independent l2-regularizer, that simply adds a fixed value \u03bb to the diagonal of the scatter matrix\u2014treating all features alike. Similar data-dependent regularizers have previously been studied by Grave et al. (2011).\nPoisson corruption. Using Poisson corruption in MCF quadratic loss leads to:\nw\u2217 = ( N\u2211 n=1 xnx > n + diag ( N\u2211 n=1 xn ))\u22121( N\u2211 n=1 xnyn ) . (9)\nPoisson corruption thus leads to a parameterless, additive, data-dependent regularizer that adds larger values to the diagonal of the Gram matrix for features that occur more on\naverage. (Note that Poisson corruption can only be used on non-negative data, \u2200n, d : xnd \u2265 0, so the contribution of the regularizer is always non-negative.) The main difference between blankout and Poisson corruption is in how strongly features with large values are regularized; the multiplicative blankout corruption regularizes common features more than the additive Poisson corruption.\nLeave-one-out errors. A nice property of linear models employing quadratic loss is that they allow us to compute the leave-one-out error of the model from only the training predictions y\u0302n (Allen, 1974). We show that this property still holds for MCF quadratic losses, irrespective of the corrupting distribution that is used. Defining the target vector y = [y1, . . . , yN ]\n> and the data matrix X = [x1, . . . ,xN ], we can rewrite the prediction vector y\u0302 = [y\u03021, . . . , y\u0302N ] as:\ny\u0302 = X>w\u2217 = X> ( N\u2211 n=1 [ E[x\u0303n]E[x\u0303n]> + diag (V[x\u0303n]) ])\u22121( N\u2211 n=1 E [x\u0303n] yn ) = Hy, (10) where H is often referred to as the hat matrix. If a single target value yn is replaced by y\u0302 \u2212n n , the prediction made by the model trained on all data except example n, the hat matrix H does not change because it does not depend on y. If we construct a new target vector z with this replacement in it, z = [y1, . . . , yn\u22121, y\u0302 \u2212n n , yn+1, . . . , yN ], and use the simple fact\nthat y\u0302\u2212nn = \u2211N m=1Hnmzm (see Allen (1974) for details) we obtain:\ny\u0302n \u2212 y\u0302\u2212nn = N\u2211 m=1 Hnmym \u2212 N\u2211 m=1 Hnmzm = Hnnyn \u2212Hnny\u0302\u2212nn . (11)\nUsing this equality, we can compute y\u0302\u2212nn without performing the minimization of the MCF quadratic loss \u2013 with example n left out \u2013 over w:\ny\u0302\u2212nn = Hnnyn \u2212 y\u0302n Hnn \u2212 1 . (12)\nThis allows us to express the leave-one-out error LOO of the MCF quadratic loss model as:\nLOO = 1\nN N\u2211 n=1 ( yn \u2212 y\u0302\u2212nn )2 = 1 N N\u2211 n=1 ( yn \u2212 y\u0302n 1\u2212Hnn )2 . (13)"}, {"heading": "3.2 Exponential loss", "text": "Whilst quadratic losses are of interest to regression problems, they seem less appropriate for use in classification. Exponential loss is a loss function that is commonly used for classification, e.g., in AdaBoost (Freund and Schapire, 1995). Assuming a label variable y \u2208 {0, 1}, the expected value of the exponential loss under corruption model p(x\u0303|x) is given by:\nL(D; w) = 1 N N\u2211 n=1 E [ exp ( \u2212ynw>x\u0303n )] p(x\u0303n|xn)\n= 1\nN N\u2211 n=1 D\u220f d=1 E [exp (\u2212ynwdx\u0303nd)]p(x\u0303nd|xnd) , (14)\nwhich we refer to as MCF exponential loss. Note that in the derivation, we used the assumption that the corruption is independent across features. The above equation can be recognized as a product of moment-generating functions E[exp(tndx\u0303nd)] with tnd = \u2212ynwd. By definition, the moment-generating function (MGF) can be computed for all corrupting distributions that are member of the natural exponential family. An overview of the moment-generating functions for some corrupting distributions of interest is given in Table 2. Noting that f(x) is convex iff \u2200x : \u22022f(x) \u2202x2\n\u2265 0 and noting that sums of convex functions are themselves convex, it is straightforward to verify that MCF exponential loss is convex for all corrupting distributions. We also note that for corrupting distributions that do not permit a moment-generating function but that have bounded support, it may be practical to upper bound (14) using Hoeffding\u2019s lemma; we leave such investigations to future work.\nThe derivation of (14) can readily be extended to a multi-class exponential loss with K classes by replacing the weight vector w by a D \u00d7K weight matrix W, and by replacing the labels y by label vectors y = {1,\u2212 1K\u22121}K with \u2211K k=1 yk = 0 (Zhu et al., 2006).\nUnlike the minimization of MCF quadratic loss, the minimization of MCF exponential losses cannot be done in closed form and needs to be performed using gradient-descent techniques. Motivated by Sha and Pereira (2003), we used an L-BFGS optimizer to minimize MCF exponential loss in this study.\nBlankout corruption. As an illustrative example, we work out MCF exponential loss with blankout corruption:\nL(D; w) = 1 N N\u2211 n=1 D\u220f d=1 (qd + (1\u2212 qd) exp(\u2212ynwdxnd)) . (15)\nThe gradient of this loss function is given by:\n\u2202L \u2202wd = \u2212 1 N N\u2211 n=1 (1\u2212 qd) exp(\u2212ynwdxnd)ynxnd \u220f d\u2032 6=d (qd\u2032 + (1\u2212 qd\u2032) exp(\u2212ynwd\u2032xnd\u2032)) . (16)\nAlthough the complexity of training with MCF remains O(N), evaluating this gradient requires more computation than evaluating the gradient of a standard exponential loss: in\npractice, the computation of the MCF exponential loss gradient is about twice as expensive when computation from the loss (15) is reused efficiently."}, {"heading": "4. MCF for Logistic Loss", "text": "In the case of the logistic loss, the solution to the expected loss (4) cannot be computed in closed form. Instead, we derive one approximation and two practical upper bounds for the expected logistic loss, all of which can be used as surrogate loss functions in practice. In this section we follow the framework of Wager et al. (2013), which is clearer than our previously used derivation (van der Maaten et al. (2013)) and leads to a nice interpretation of MCF as an adaptive regularizer.\nWe will focus on binary classification in our derivations below, but our results can readily be extended to multi-class logistic loss. (In general, this is achieved by redefining the labels y to be label vectors of the form y \u2208 {0, 1}K with \u2211Kk=1 yk = 1; and by defining the loss as the logarithm of the softmax probability of the correct prediction.)"}, {"heading": "4.1 MCF Regularizer", "text": "Assuming labels y \u2208 {\u22121,+1}, we may define the logistic regression model as a generalized linear model, p(y|x; w) = exp(yw>x)\nexp(\u2212w>x)+exp(w>x) . The negative log-likelihood, or the logistic\nloss, of an instance pair (x, y) under this model can be written as: L(x, y,w) = \u2212yw>x +A(w>x) with: A(w>x) = log [ exp ( \u2212w>x ) + exp ( w>x )] . (17)\nHere, A(w>x) is the log-partition function, which is independent of the label y. Noting that we assumed the corruption to be unbiased (i.e. E[x\u0303] = x), we can plug (17) into the expected loss (4) and obtain:\nL(D; w) = \u2212 1 N N\u2211 n=1 E [ ynw >x\u0303n \u2212A(w>x\u0303n) ] p(x\u0303n|xn)\n= 1\nN N\u2211 n=1 L(xn, yn,w)\ufe38 \ufe37\ufe37 \ufe38 log-loss +E [ A(w>x\u0303n) ] p(x\u0303n|xn)\n\u2212A(w>xn)\ufe38 \ufe37\ufe37 \ufe38 regularizer  . (18) Wager et al. (2013) observe that the first part of (18) is the regular logistic loss without MCF, and the second part can be interpreted as an adaptive regularizer that satisfies several appealing properties: 1. it only depends on w and xn but not on the label y; 2. it is always non-negative\u2014which follows directly from the fact that A(w>x) is convex and an application of Jensen\u2019s inequality, i.e. E[A(w>x\u0303)] \u2265 A(E[w>x\u0303]) = A(w>x); and 3. it has an intuitive interpretation, as it minimizes the difference between the expected prediction before and after corruption\u2014in other words, the score that the classifier assigns to an example xn should be robust with respect to the corruption distribution.\nUnfortunately, E[A(w>x\u0303)] in (18) cannot be expressed in closed form. In the following three sections we therefore derive practical closed-form approximations and upper bounds that can be used to form surrogate loss functions for (18)."}, {"heading": "4.2 Quadratic Approximation", "text": "A quadratic approximation to the expected logistic loss can be obtained by deriving a second-order Taylor expansion of A(w>x\u0303) around w>x and working out the expectation (Wager et al., 2013). The resulting quadratic approximation to the expected logistic loss then becomes:\nL(D; w) \u2248 1 N N\u2211 n=1 [ \u2212ynw>xn +A(w>xn) + 1 2 \u22022A(w>xn) \u2202(w>xn)2 V[w>x\u0303n]p(x\u0303n|xn) ] (19)\n= 1\nN N\u2211 n=1 [ L(xn, yn,w) + 1 2 \u22022A(w>xn) \u2202(w>xn)2 V[w>x\u0303n]p(x\u0303n|xn) ] . (20)\nIn this equation, the first-order term has vanished because we assumed the corrupting distribution to be unbiased, E[x\u0303] = x. The expression V[w>x\u0303n]p(x\u0303n|xn) denotes the variance of w>x\u0303n under the corrupting distribution, which takes the form:\nV[w>x\u0303n]p(x\u0303n|xn) = w > ( E[x\u0303nx\u0303>n ]p(x\u0303n|xn) \u2212 xnx>n ) w. (21)\nThe second derivative of the log-partition function takes the form:\n\u22022A(w>xn)\n\u2202(wxn)2 = 4 exp(\u22122w>xn) (1 + exp(\u22122w>xn))2 = 4\u03c3(2w>xn)(1\u2212 \u03c3(2w>xn)) = V[y\u0302n], (22)\nwhere \u03c3(z) denotes the sigmoid function, \u03c3(z) = 11+exp(\u2212z) , and V[y\u0302n] denotes the variance of the prediction y\u0302n = sign(w >xn) under the logistic regression model 1. Hence, the quadratic approximation (20) can be interpreted as the sum of the standard logistic loss and a datadependent, additive regularizer that is a product of: 1. the variance of the classifier score under the data corruption and 2. the variance of the prediction under the logistic regression model. Because the regularizer is the product of two variances, it is guaranteed to be nonnegative. The additive regularizer vanishes when no corruption is applied on the data, because (21) is zero when the data is not corrupted."}, {"heading": "4.3 Jensen\u2019s upper bound", "text": "As an alternative to the quadratic approximation, we can obtain an effective upper bound on the expected logistic loss under the corrupting distribution using Jensen\u2019s inequality, which states that, because log(\u00b7) is a concave function, E[log(z)] \u2264 log(E[z]). In particular, we obtain the following upper bound on the log-partition function:\nE [ log ( exp ( \u2212w>x\u0303 ) + exp ( w>x\u0303 ))] \u2264 log ( E [ exp ( \u2212w>x\u0303 )] + E [ exp ( w>x\u0303 )]) , (23)\nwhere all expectations are under the corrupting distribution p(x\u0303|x). An alternative, somewhat simpler way to express the Jensen\u2019s upper bound on L(D; w) can be achieved by redefining the labels y \u2208 {0, 1}, and rephrasing (18) as:\nL(D; w) = 1 N N\u2211 n=1 E [ log ( 1 + exp ( \u2212ynw>x\u0303n ))] p(x\u0303n|xn) , (24)\n1. Please note that the mean E[y\u0302] = \u2202A(w >x) \u2202(wx) = 2\u03c3(2w>x) \u2212 1.\nApplying Jensen\u2019s inequality for log(\u00b7) to (24), and subsequently following the same steps as in (14), leads to:\nL(D; w) \u2264 1 N N\u2211 n=1 log ( 1 + D\u220f d=1 E [exp (\u2212ynwdx\u0303nd)]p(x\u0303nd|xnd) ) . (25)\nWe again recognize a product of MGFs, which can be computed in closed-form for corrupting distributions in the natural exponential family (see Table 2). The upper bound on the expected logistic loss (25) can be rewritten as a log-sum-exp or log-integral-exp function (depending on whether the corruption is discrete or continuous) of an affine function of the parameters w, as a result of which it is guaranteed to be convex (Boyd and Vandenberghe, 2004, \u00a73.1.5). We note here that the evaluation of (25) in a numerically stable way is non-trivial when blankout corruption is used; for details on numerical stability, we refer to Appendix B.\nPoisson corruption. As an illustrative example, we show the upper bound of the logistic loss (25), where inputs are corrupted with the Poisson distribution:\nL(D; w) \u2264 1 N N\u2211 n=1 log\n( 1 + exp ( D\u2211 d=1 xnd(exp(\u2212ynwd)\u2212 1) )) . (26)\nAs with all MCF losses that use Poisson corruption, this regularized loss does not have any additional hyper-parameters. Further, the sum over all features can still be computed efficiently for sparse data by summing only over non-zero entries in xn. As for MCF exponential loss, we perform the minimization of this surrogate loss with an L-BFGS optimizer. The gradient of (26) is given by:\n\u2202L \u2202wd = \u2212 1 N N\u2211 n=1\nexp (\u2211 d\u2032 6=d xnd\u2032(exp(\u2212ynwd\u2032)\u2212 1) )\n1 + exp (\u2211D d=1 xnd(exp(\u2212ynwd)\u2212 1) ) exp(ynwd)ynxnd. (27)\nIt is fair to say that in practice, the computation of the gradient of this MCF logistic loss takes approximately 10\u00d7 longer than the computation of a regular logistic loss gradient (due to extra exponentiations and multiplications in the gradient computation)."}, {"heading": "4.4 Variational bound", "text": "Indeed, Jensen\u2019s inequality is not the only bound that may be used to derive an upper bound on MCF logistic loss. In particular, we also consider variational bounds of the form:\nL(D; w) = 1 N N\u2211 n=1 E [ log(1 + exp(\u2212ynw>x\u0303n)) ] p(x\u0303n|xn)\n= min \u03bb\u2208[0,1]\n1\nN N\u2211 n=1 ( E [ \u2212\u03bbynw>x\u0303n ] p(x\u0303n|xn) + E [ log(exp(\u03bbynw >x\u0303n)(1 + exp(\u2212ynw>x\u0303n))) ])\n\u2264 min \u03bb\u2208[0,1]\n1\nN N\u2211 n=1 ( log ( E [ exp(\u03bbynw >x\u0303n) ] + E [ exp((\u03bb\u2212 1)ynw>x\u0303n) ]) \u2212 \u03bbynw>xn ) ,\n(28)\nwhere we use the assumption that the corrupting distribution is unbiased, E[x\u0303] = x. The expression above contains two moment-generating functions (with t = \u03bbynw and t = (\u03bb \u2212 1)ynw, respectively), which can be evaluated as before. Minimizing (28) over the hyperparameter \u03bb \u2208 [0, 1], using a grid or gradient search, leads to a potentially tighter bound than that in (25). Note that the special case \u03bb = 0 equals (25), as a result of which the alternative bound is always at least as tight. The bounds are illustrated for various values of \u03bb in Figure 1."}, {"heading": "4.5 Graphical model interpretation", "text": "Finally, minimizing MCF logistic loss can also be interpreted as training the parameters of the simple Bayesian network in Figure 2 via maximum likelihood. In this network, p(x\u0303d|xd) denotes a corrupting distribution, and p(y|x\u0303) comprises a simple linear logistic regressor: p(y|x\u0303) = 1/(1 + exp(\u2212yw>x\u0303)). Marginalizing out the corrupted data x\u0303, we obtain:\np(yn|xn) = E [\n1\n1 + exp(\u2212ynw>x\u0303n) ] p(x\u0303n|xn)\n\u2265 1 1 + E [exp(\u2212ynw>x\u0303n)]p(x\u0303n|xn) , (29)\nwhere we have used the fact that 11+z is convex on [0,\u221e) and that \u2200z : 1 + exp(z) > 1 to lower bound p(y|x) using Jensen\u2019s inequality. (Indeed, we could also have applied the quadratic approximation of 4.2 or the variational approximation of 4.4 here.)\nBecause the corrupting distribution p(x\u0303|x) factorizes over dimensions, the log-likelihood ` of data D can thus be lower bounded by:\n`(D; w) \u2265 \u2212 N\u2211 n=1 log\n( 1 +\nD\u220f d=1 E [exp(\u2212ynwdx\u0303nd)]p(x\u0303nd|xnd)\n) . (30)\nIt is straightforward to verify that maximizing this lower bound on the log-likelihood is identical to minimizing (25). Further, it it possible to develop a similar graphical model for MCF-quadratic loss by setting p(yn|x\u0303n) = N (yn|w>x\u0303, \u03c32).\nThe graphical model interpretation of MCF also suggests an alternative way to make predictions with models trained using MCF, viz. by evaluating (29). In practice, this amounts to generating infinitely many corrupted copies of the test data using p(x\u0303|x) and averaging over the predictions for all corrupted test points. While corrupting test data during prediction may sound counterintuitive at first, it does provide an elegant way to remove the restriction for MCF corruption distributions to be unbiased (especially in the case of regression). In classification, corrupting test data provides a natural way to measure the uncertainty of a prediction, even when the original predictor was non-probabilistic (much like conformal prediction; Shafer and Vovk (2008))."}, {"heading": "5. Experiments", "text": "We evaluate MCF predictors on four tasks: 1. document classification based on word-count features using MCF with blankout and Poisson corruption; 2. image classification based on bag-of-visual-word features using MCF with blankout and Poisson corruption; 3. splicejunction recognition in DNA sequences using blankout and multinomial corruption; and 4. classification of objects in the \u201cnightmare at test time\u201d scenario using MCF with blankout corruption. The four sets of experiments are described separately below. Code to reproduce the results of our experiments is available online2.\n2. A Matlab implementation is available at http://bit.ly/11bn2GG.\nBlankout corruption level q\nC la\nss ifi\nca tio\nn er\nro r\n0 0.2 0.4 0.6 0.8 1\n0.15\n0.16\n0.17\n0.18\n0 0.2 0.4 0.6 0.8 10.1\n0.11\n0.12 Cl as\nsi fic\nat io\nn er\nro r\n0 0.2 0.4 0.6 0.8 10.34\n0.36\n0.38\n0.4\n0.42\n0.44\n0.46\n0.48\n0 0.2 0.4 0.6 0.8 10.13\n0.14\n0.15\n0.16\n0.17\n0.18\nDMOZ\n0 0.2 0.4 0.6 0.8 10.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\nReuters\nBlankout corruption level q\n0 0.2 0.4 0.6 0.8 10.11\n0.12\n0.13\n0.14\n0.15\nQuadratic loss Exponential loss Logistic loss Blankout MCF (Qua.) Blankout MCF (Exp.) Blankout MCF (Log.) Poisson MCF (Qua.) Poisson MCF (Exp.) Poisson MCF (Log.)\nAmazon / Kitchen\nAmazon / DVDAmazon / Electronics Amazon / Books\n0 0.2 0.4 0.6 0.8 1\n0.15\n0.16\n0.17\n0.18\n0 0.2 0.4 0.6 0.8 10.1\n0.11\n0.12 Cl as\nsi fic\nat io\nn er\nro r\n0 0.2 0.4 0.6 0.8 10.34\n0.36\n0.38\n0.4\n0.42\n0.44\n0.46\n0.48\n0 0.2 0.4 0.6 0.8 10.13\n0.14\n0.15\n0.16\n0.17\n0.18\nDMOZ\n0 0.2 0.4 0.6 0.8 10.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\nReuters\nBlankout corruption level q\n0 0.2 0.4 0.6 0.8 10.11\n0.12\n0.13\n0.14\n0.15\nQuadratic loss Exponential loss Logistic loss Blankout MCF (Qua.) Blankout MCF (Exp.) Blankout MCF (Log.) Poisson MCF (Qua.) Poisson MCF (Exp.) Poisson MCF (Log.)\nAmazon / Kitchen\nAmazon / DVDAmazon / Electronics Amazon / Books\n0 0.2 0.4 0.6 0.8 1\n0.15\n0.16\n0.17\n0.18\n0 0.2 0.4 0.6 0.8 10.1\n0.11\n0.12 Cl as\nsi fic\nat io\nn er\nro r\n0 0.2 0.4 0.6 0.8 10.34\n0.36\n0.38\n0.4\n0.42\n0.44\n0.46\n0.48\n0 0.2 0.4 0.6 0.8 10.13\n0.14\n0.15\n0.16\n0.17\n0.18\nDMOZ\n0 0.2 0.4 0.6 0.8 10.06\n.08\n0.1\n0.12\n.\n0.16\n0.18\nReuters\nBlankout corruption level q\n0 0.2 0.4 0.6 0.8 10.11\n0.12\n0.13\n0.14\n0.15\nQuadratic loss Exponential loss Logistic loss Blankout MCF (Qua.) Blankout MCF (Exp.) Blankout MCF (Log.) Poisson MCF (Qua.) Poisson MCF (Exp.) Poisson MCF (Log.)\nAmazon / Kitchen\nAmazon / DVDAmazon / Electronics Amazon / Books\n0 0.2 0.4 0.6 0.8 1\n0.15\n0.16\n0.17\n0.18\n0 0.2 0.4 0.6 0.8 10.1\n0.11\n0.12 Cl as\nsi fic\nat io\nn er\nro r\n0 0.2 0.4 0.6 0.8 10.34\n0.36\n0.38\n0.4\n.4\n0.44\n0.46\n0.48\n0 0.2 0.4 0.6 0.8 10.13\n0.14\n0.15\n0.16\n0.17\n0.18\nDMOZ\n0 0.2 0.4 0.6 0.8 10.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\nReuters\nBlankout corruption level q\n0 0.2 0.4 0.6 0.8 10.11\n0.12\n. 3\n0.14\n0.15\nQuadratic loss Exponential loss Logistic loss Blankout MCF (Qua.) Blankout MCF (Exp.) Blankout MCF (Log.) Poisson MCF (Qua.) Poisson MCF (Exp.) Poisson MCF (Log.)\nKitchen\nAmazon / DVDAmazon / Electronics Amazon / Books\n0 0.2 0.4 0.6 0.8 1\n0.15\n0.16\n0.17\n. 8\n0 0.2 0.4 0.6 0.8 10.1\n0.11\n0.12 Cl as\nsi fic\nat io\nn er\nro r\n0 0.2 0.4 0.6 0.8 10.34\n0.36\n0.38\n0.4\n0.42\n0.44\n0.46\n0.48\n0 0.2 0.4 0.6 0.8 10.13\n0.14\n0.15\n0.16\n0.18\nDMOZ\n0 0.2 0.4 0.6 0.8 10.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\nReuters\nBlankout corruption level q\n0 0.2 0.4 0.6 0.8 10.11\n0.12\n0.13\n.14\n0.15\nQuadratic loss Exponential loss Logistic loss Blankout MCF (Qua.) Blankout MCF (Exp.) Blankout MCF (Log.) Poisson MCF (Qua.) Poisson MCF (Exp.) Poisson MCF (Log.)\nAmazon / Kitchen\nAmazon / DVDAmazon / Electronics Amazon / Books\n0 0.2 0.4 0.6 0.8 1\n.15\n0.16\n0.17\n0.18\n0 0.2 0.4 0.6 0.8 10.1\n0.11\n0.12 Cl as\nsi fic\nat io\nn er\nro r\n0 0.2 0.4 0.6 0.8 10.34\n0.36\n0.38\n0.4\n0.42\n0.44\n0.46\n0.48\n0 0.2 0.4 0.6 0.8 10.13\n0.14\n0.15\n0.16\n0.17\n0.18\nDMOZ\n0 0.2 0.4 0.6 0.8 10.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\nReuters\nBlankout corruption level q\n0 0.2 0.4 0.6 0.8 10.11\n0.12\n0.13\n0.14\n0.15\nQuadratic loss Exponential loss Logistic loss Blankout MCF (Qua.) Blankout MCF (Exp.) Blankout MCF (Log.) Poisson MCF (Qua.) Poisson MCF (Exp.) Poisson MCF (Log.)\nAmazon / Kitchen\nAmazon / DVDAmazon / Electronics Amazon / Books\nFigure 3: Classification errors of MCF predictors using blankout and Poisson corruption \u2013 as a function of the blankout corruption level q \u2013 on the Amazon data set for l2-regularized quadratic, exponential, and quadratic loss functions. Classification errors are represented on the y-axis, whereas the blankout corruption level q is represented on the x-axis. The case of MCF with blankout corruption and q = 0 corresponds to a standard l2-regularized classifier. Figure best viewed in color."}, {"heading": "5.1 Document classification", "text": "We first test MCF predictors with blankout and Poisson corruption on document classification tasks. Specifically, we focus on three data sets: the Dmoz data set, the Reuters data set, and the Amazon review benchmark set (Blitzer et al., 2007).\nData sets. The Dmoz open directory (http://www.dmoz.org) contains a large collection of webpages arranged into a tree hierarchy. We use a subset consisting of N = 8, 980 webpages from the K = 16 categories in the top level of the hierarchy. Each webpage is represented by a bag-of-words representation with D = 16, 498 words. The Reuters document classification data set consists of N = 8, 293 news articles that appeared on the Reuters newswire in 1987 belonging to K = 65 topics (documents corresponding to multiple topics were removed from the data). The bag-of-words representation contains D = 18, 933 words for each document. The four Amazon data sets consist of approximately N = 6, 000 reviews of four types of products: books, DVDs, electronics, and kitchen appliances. Each review is represented by a bag-of-words representation of the D = 20, 000 most common words. On the Dmoz and Reuters data sets, the task is to classify the documents into one of the predefined categories. On the Amazon data set, the task is to decide whether a review is positive or negative.\nSetup. On the Dmoz and Reuters data sets, we use fixed 75%/25% training/test splits. On the Amazon data set, we follow the experimental setup of Blitzer et al. (2007) by using a predefined division of the data into approximately 2, 000 training examples and about 4, 000 test examples (the exact numbers vary slightly between tasks). We perform experiments with linear classifiers that are trained using l2-regularized quadratic, exponential, and logistic loss functions. In all experiments, the amount of l2-regularization is determined via cross-validation. The minimization of the (expected) exponential and logistic losses is performed by running Mark Schmidt\u2019s http://www.di.ens.fr/~mschmidt/Software/ minFunc.htmlminFunc-implementation of L-BFGS until convergence or until a predefined maximum number of iterations is reached. In our experiments with MCF logistic loss, we used the Jensen\u2019s upper bound of Eqn. (25).\nAll our predictors included a bias term that is neither regularized nor corrupted. In our experiments with MCF using blankout corruption, we use the same noise level for each feature, i.e. we assume that \u2200d : qd = q. On all data sets, we first investigate the performance of MCF as a function of the corruption level q (but we still cross-validate over the l2-regularizer). In a second set of experiments, we cross-validate over the blankout corruption parameter q and study to what extent the performance (improvements) of MCF depend on the amount of available training data. (MCF with Poisson corruption has no additional hyperparameters, as a result of which it requires no extra cross-validations.)\nResults. Figure 3 shows the test error of our MCF predictors on all data sets as a function of the blankout corruption level q. Herein, corruption level q = 0 corresponds to the baseline predictors, i.e. to predictors that do not employ MCF at all (but they do employ l2-regularization). The results show: 1. that MCF consistently improves over standard predictors for both blankout corruption (for all corruption levels q) and Poisson corruption on five out of six tasks; 2. that MCF with Poisson corruption leads to substantial performance improvements over standard classifiers whilst introducing no additional hyperparameters; and 3. that the best performance tends to be achieved by MCF with blankout corruption\nwith relatively high corruption levels are used. In particular, the best corruption level q for the Amazon dataset is in the order of 0.8 or 0.9. Our explanation is that the ratio of relevant features (in this case, sentiment words) is fairly low in these data, and higher dropout increases the robustness of the classifiers against irrelevant features. However, further increasing the corruption level will lead to over-regularization. As shown in Figure 4, the test error of MCF predictors increases drastically as the blankout corruption level exceeds 0.9.\nThe best-performing MCF classifiers reduce the test errors by up to 22% on the Amazon data if q is properly set. In many of the experiments with MCF-trained losses (in particular, when blankout corruption is used), we observe that the optimal level of l2-regularization is 0. This showcases the regularizing effect of MCF, which can render additional regularization superfluous.\nFigure 5 presents the results of a second set of experiments on the Dmoz and Reuters data sets, in which we study how the performance of MCF depends on the amount of\ntraining data. For each training set size, we repeat the experiment five times with randomly sub-sampled training sets; the figure reports the mean test errors and the corresponding standard deviations. The results show that classifiers trained with MCF (solid curves) significantly outperform their counterparts without MCF (dashed curves). The performance improvement is consistent irrespective of the training set size, viz. up to 25% on the Dmoz data set.\nExplicit vs. implicit feature corruption. Figure 6 shows the classification error on the Amazon Books data set when a classifier without MCF is trained on the data set with additional explicitly corrupted samples, as formulated in equation (3). To generate the results in the left graph of Figure 6, we use the blankout corruption model with q set by cross-validation for each training set size. To generate the right graph of Figure 6, we used the Poisson corruption model (which has no hyperparameters). In both experiments, we trained the classifiers using quadratic loss and l2-regularization (with cross-validation over the regularization parameter for each data size).\nThe graphs in the figure show a clear trend that the error decreases when the training set contains more corrupted versions of the original training data, i.e. with higher M in equation (3). The graphs also illustrate that the best performance is obtained as M approaches infinity, which is equivalent to MCF with blankout or Poisson corruption (big markers in the bottom right). This nicely illustrates the potential of MCF to improve generalization by training on corrupted examples without increasing the computational complexity of learning.\nComparing approximations and bounds for MCF logistic loss. We also performed experiments to evaluate the effectiveness of the three approaches to deal with MCF logistic loss, viz. the quadratic approximation of Eqn. (20), the Jensen\u2019s upper bound of Eqn. (25), and the variational upper bound of Eqn. (28). Specifically, we compared the performance of the three approaches when using blankout corruption with different values\nof q on the four Amazon data sets. As before, all classifiers used additional l2-regularization; the regularization parameters were set by cross-validating on a held-out validation set.\nThe results of these experiments are shown in Figure 7 (please note that, again, the setting q = 0 corresponds to training classifiers using standard logistic loss). The results presented in the figure show that classifiers trained using logistic loss with MCF-blankout outperform classifiers that are trained using standard logistic loss, irrespective of whether the quadratic approximation or one of the two upper bounds is used. Having said that, the results also show that the two upper bounds on MCF logistic loss outperform the quadratic approximation in most experiments. In addition, the results show that the use of Jensen\u2019s upper bound tends to lead to better results than the use of the variational upper bound to the logistic loss, despite the fact that the variational bound is always at least as tight as Jensen\u2019s bound. We surmise this results is due to the fact that the variational bound of Eqn. (28) is not jointly convex in w and \u03bb, whereas the Jensen\u2019s bound of Eqn. (25) is\nconvex in w. As a result, we may get stuck in poorer local minima of the loss when using the variational upper bound."}, {"heading": "5.2 Image classification", "text": "We perform image-classification experiments with MCF on the CIFAR-10 data set (Krizhevsky, 2009), which is a subset of the 80 million tiny images (Torralba et al., 2008). The data set contains RGB images with 10 classes of size 32 \u00d7 32, and consists of a fixed training set of 50, 000 images and a fixed test set of 10, 000 images.\nSetup. We follow the experimental setup of Coates et al. (2011): we whiten the training images and extract a set of 7 \u00d7 7 image patches on which we apply k-means clustering (with k = 2048) to construct a codebook of prototypical image patches. Next, we slide a 7 \u00d7 7 pixel window over each image and identify the nearest prototype in the codebook for each window location. We construct an image descriptor by subdividing the image into four equally sized quadrants and counting the number of times each prototype occurs in each quadrant, which leads to a descriptor of dimensionality D = 4 \u00d7 2048. This way of extracting the image features is referred to by Coates et al. (2011) as k-means with hard assignment, average pooling, patch size 7 \u00d7 7, and stride 1. Because all images have the same size, we do not need to normalize the descriptors. We train MCF predictors with blankout and Poisson corruption on the full set of training images, cross-validating over a range of l2-regularization parameters. The generalization error is evaluated on the test set. For our experiments with logistic loss, we used the Jensen\u2019s upper bound of Eqn. (25).\nResults. The results are reported in Table 3. The baseline classifiers (without MCF) are comparable to the 68.8% accuracy reported by Coates et al. (2011) with exactly the same experimental setup (except for exponential loss). The results illustrate the potential of MCF classifiers to improve the prediction performance on bag-of-visual-words features, in particular, when using quadratic or logistic loss in combination with Poisson corruption.\nAlthough our focus in this section is to merely illustrate the potential of MCF on image classification tasks, it is worth noting that the best results in Table 3 match those of a highly non-linear mean-covariance RBMs trained on the same data (Ranzato and Hinton, 2010), despite our use of very simple visual features and of linear classifiers."}, {"heading": "5.3 Analysis of DNA", "text": "We also performed experiments with MCF in which the aim is to automatically recognize splice-junctions in DNA: the locations that indicate the boundaries between regions of\nDNA that are used in the production of mRNA (so-called introns) and regions of DNA that are removed in the production of mRNA (exons). The two types of boundaries are called acceptors (exon-to-intron boundaries) and donors (intron-to-exon boundaries). The mRNA that is created using the information in the DNA is subsequently translated into proteins, which form the basis of all chemical processes inside the cell. Therefore, automatic recognition of splice-junctions is essential in the analysis of cell processes.\nSetup. We perform experiments on the data set constructed by Noordewier et al. (1991). The data set comprises 3190 examples of three classes: it contains 767 examples of acceptors, 768 examples of donors, and 1655 negative examples. Each example is represented by a DNA subsequence of 120 nucleotides: 60 on each side of the boundary for positive examples (acceptors and donors). We represent the nucleotides using a 1-of-K representation, where K = 4 is the number of distinct nucleotides (A, G, T, and C). This leads to binary feature vectors of dimensionality D = 480.\nWe measure the performance of our classifiers using 10-fold cross-validation. We repeat each experiment fifty times and average the performances across the fifty runs. In this experiment, we focus on MCF with logistic loss because in preliminary experiments, models trained with logistic loss produced substantially better results than models that used other loss functions. As in the previous experiments, we use the Jensen\u2019s upper bound on MCF-logistic loss of Eqn. (25) as surrogate loss function. Because of the binary nature of our data, we focus on using blankout corruption in MCF. In addition, we explore a simple multinomial corruption model that aims to model the sequencing errors that are made by DNA sequencing machines (e.g., Le et al. (2013); Zagordi et al. (2010)). The multinomial corruption model assumes that a base pair x \u2208 {1, . . . ,K} is an erroneous read with probability q, and assumes a uniform distribution over all alternative base pairs in case of an erroneous read:\np(x\u0303 = x) = 1\u2212 q and \u2200k 6= x : p(x\u0303 = k) = q K \u2212 1 . (31)\nWe note here that this corrupting distribution violates the assumption that E[x\u0303] = x. However, this is not a problem since we are focusing on a classification task (the unbiasedness assumption is only relevant to regression tasks).\nResults. Figure 8 presents the performance of our MCF classifiers with blankout corruption (left) and multinomial corruption (right) as a function of the MCF corruption rate q. The results presented in the figure show that MCF with blankout may improve the performance of linear models for the recognition of splice-junctions by more than 0.6%, which corresponds to a relative improvement of approximately 15%. Improvements in performance are obtained for a wide range of blankout rates, with optimal blankout rates ranging between 0.15 and 0.4. The results also show that the multinomial corruption model is too simple to lead to performance improvements. However, we expect that these results can be substantially improved by incorporating in the corruption process knowledge about: 1. the coverage obtained on a particular base pair (base-pair reads with higher coverage are read in more DNA snippets and are, therefore, less likely to be erroneous) and 2. knowledge on the error distribution of a DNA sequencing machine (for instance, sequencing machines are more likely to confuse A and T than A and G). Both types of knowledge are available for modern DNA sequencing processes (Le et al., 2013; Zagordi et al., 2010). The MCF frame-\nwork allows us to model such domain knowledge into the the corruption model. However, since no information on the coverage and sequencing error distribution is available for our data set (Noordewier et al., 1991), we leave such extensions of the DNA experiments to future work."}, {"heading": "5.4 Nightmare at test time", "text": "To test the performance of our MCF predictors with blankout corruption under the \u201cnightmare at test time\u201d scenario, we perform experiments on the MNIST data set of handwritten digit images. The MNIST data set contains N = 60, 000 training and 10, 000 test images of size D = 28\u00d7 28 = 784 pixels, and comprises K = 10 classes.\nSetup. We train our predictors on the full training set, and evaluate their performance on versions of the test set in which a certain percentage of the pixels are randomly blanked out, i.e. set to zero. We compare the performance of our MCF-predictors (using blankout corruption) with that of standard predictors that use l1 or l2-regularized quadratic, exponential, logistic, and hinge loss. As before, we used the Jensen\u2019s upper bound for predictors with MCF logistic loss, and we use cross-validation to determine the optimal value of the regularization parameter. For MCF predictors, we also cross-validate over the blankout corruption level q (again, we use the same noise level for each feature, i.e. \u2200d : qd = q). In addition to the comparisons with standard predictors, we also compare the performance of MCF with that of FDROP (Globerson and Roweis, 2006), which is a state-of-the-art algorithm for the \u201cnightmare at test time\u201d setting that minimizes the hinge loss under an adversarial worst-case scenario (see section 2).\nThe performances are reported as a function of the feature-deletion percentage in the test set, i.e. as a function of the probability with which a pixel in the test set is switched off. Following the experimental setting of Globerson and Roweis (2006), we perform the crossvalidation for each deletion percentage independently, i.e. we create a small validation set with the same feature-deletion level and use it to determine the best regularization parameters and blankout corruption level q for that percentage of feature deletions. We are thus assuming a transductive learning setting, which is a common assumption in many learning scenarios with domain shift (Blitzer et al., 2007; Daume\u0301 III, 2007).\nResults. Figure 9 shows the performance of our predictors as a function of the percentage of deletions in the test images. The figure shows the performance for all three loss functions with MCF (solid lines) and without MCF (dashed lines). The performance of a standard predictor using hinge loss is shown as a red dashed line; the performance of FDROP (a state-of-the-art method for this learning setting) is shown as a black dashed line. The results presented in Figure 9 clearly illustrate the ability of MCF with blankout corruption to produce predictors that are more robust to the \u201cnightmare at test time\u201d scenario: MCF\nimproves the performance substantially for all three loss functions considered. For instance, in the case in which 50% of the pixels in the test images is deleted, the performance improvements obtained using MCF for quadratic, exponential, and logistic loss are 40%, 47%, and 60%, respectively. Further, the results also indicate that MCF-losses may outperform FDROP; in particular, our average-case logistic loss outperforms FDROP\u2019s worst-case hinge loss across the board3. This is particularly impressive as FDROP uses the hinge loss, which performs surprisingly better than the alternative losses on this data set (the improvement of FDROP over the generic hinge-loss is in fact relatively modest). This result suggests that it is better to consider an average-case scenario than a worst-case scenario in the \u201cnightmare at test time\u201d setting."}, {"heading": "6. Discussion and Conclusion", "text": "We presented an approach to learn classifiers by marginalizing corrupted features (MCF). Specifically, MCF trains predictors by introducing corruption on the training examples, which is marginalized out in the expectation of the loss function. We minimize the expected loss with respect to the model parameters. Our experimental results show that MCF predictors with blankout and Poisson corruption perform very well in the context of bag-of-words features, whilst MCF with blankout corruption was also very effective on DNA data. MCF with blankout corruption appears to be most effective in high-dimensional learning problems in which the data is sparse. MCF with Poisson corruption is particularly interesting for count features, as it improves classification performances without introducing any additional hyper-parameters. As a disclaimer, care must be taken when applying MCF with Poisson corruption on data sets with outliers. The Poisson corruption may strongly emphasize outliers in the expected loss because the variance of a Poisson distribution is identical to its mean, and because we use loss functions that are not robust to outliers. A simple solution to this problem may be to redefine the corruption distribution to p(x\u0303d|xd) = Pois(x\u0303nd|min{xnd, u}) for some cutoff parameter u \u2265 0.\nThroughout our experiments with MCF on exponential and logistic losses, the weight of the l2-regularization term, which was set by cross-validation, typically ended up very close to zero. This implies that the regularizing effect of MCF corruption is sufficient even for high dimensional data. In comparison with traditional regularization, MCF corruption shines in two ways: 1. it often yields superior classification performance and 2. it can be much more intuitive to set parameters about data corruption than about model hyper parameters. Further, MCF with blankout corruption also appears to prevent weight undertraining (Sutton et al., 2005): it encourages the weight on each feature to be non-zero, in case this particular feature survives the corruption.\nThe resulting redundancy is one of the key factors why MCF corruption makes classifiers so effective against the \u201cnightmare at test-time\u201d scenario. Consequently, MCF classifiers are particularly useful in learning settings in which features in the test data may be missing (e.g., because sensors that were measuring these features temporarily broke down). Learning with MCF is quite different from previous approaches for this setting (Dekel and Shamir, 2008; Globerson and Roweis, 2006). In particular, prior work focuses on the worst-case sce-\n3. Quadratic and exponential losses perform somewhat worse because they are less appropriate for linear classifiers, but even they outperform FDROP for large numbers of feature deletions in the test data.\nnario whereas we explicitly consider the (arguably) more common average-case scenario by considering all possible corrupted observations. This has the advantage that it is computationally much cheaper and that it allows for incorporating prior knowledge in the learning. For instance, if the data is generated by a collection of unreliable sensors, knowledge on the reliability of a sensor may be used to set the corresponding qd-parameter. The strong performance of MCF in the \u201cnightmare at test-time\u201d scenario suggest it be well suited for learning under domain shift (Blitzer et al., 2007; Daume\u0301 III, 2007). In particular, as the corrupting distribution may be used to shift the data distribution in the source domain towards the data distribution in the target domain \u2014 potentially, by learning the parameters of the corrupting distribution using maximum likelihood. We leave such investigations for future work.\nAnother interesting direction for future work is to investigate extensions of MCF to structured prediction (Wang et al., 2013), as well as to investigate if MCF can be employed for kernel machines. We also plan to explore in more detail what corruption models p(x\u0303|x) are useful for what types of data. Further, MCF could be used in the training of neural networks with a single layer of hidden units: blankout noise on the hidden nodes can improve the performance of the networks (LeCun et al., 1990; Hinton et al., 2012) and can be marginalized out analytically. Moreover, classifiers trained using MCF-blankout may be very well suited for application in anytime classification scenarios (Grubb and Bagnell, 2012), as they are optimized to work well on all possible subsets of features. Another interesting direction for future work is to investigate the theoretical properties of learning with MCF. Xu et al. (2009) have derived generalization bounds for learning with corruption under the worst-case scenario (i.e. for the related models discussed in Section 2), and McAllester (2013) recently derived a PAC-Bayesian bound for learning linear models with blankout in the average-case scenario; however, generic bounds for learning with MCF do not yet exist. A final interesting direction would be to investigate the effect of marginalizing corrupted labels or target values (Lawrence and Scho\u0308lkopf, 2001; Chen et al., 2013)."}, {"heading": "Acknowledgements", "text": "The authors thank Fei Sha, Wouter Kouw, Max Welling, and Lawrence Saul for helpful discussions. In particular, the variational upper bound for the logistic loss was suggested by Lawrence Saul. Laurens van der Maaten acknowledges support from the Netherlands Organisation for Scientific Research (NWO; grant 612.001.301), from the EU-FP7 SSPNet and INSIDDE projects, and from the AAL project SALIG++. Kilian Weinberger, Minmin Chen, and Stephen Tyree are supported by NSF grants 1149882 and 1137211."}, {"heading": "Appendix A. Overview of loss functions", "text": "Table 4 gives an overview of all MCF loss functions discussed in the paper. Table 5 lists the associated gradients required for learning. For an overview of moment-generating functions and their gradients, we refer to Table 2.\n4. For MCF quadratic loss, the optimal parameters can be identified via the closed-form solution in (6)."}, {"heading": "Appendix B. Numerical stability", "text": "When using dropout, the Jensen\u2019s upper bound on the expected logistic loss is not numerically stable. In particular, the upper bound L\u0302 takes the following form for multi-class classification:\nL\u0302(D; w) = \u2212 N\u2211 n=1 log\n[ \u220fD d=1(qd + (1\u2212 qd) exp(y>nwdxnd))\u2211\ny\u2032n\n\u220fD d=1(qd + (1\u2212 qd) exp(y\u2032>nwdxnd))\n] . (32)\nAs is common in logistic regression, we can evaluate this expression by expressing the nominator and denominator in the log-domain, performing a log-shift, and exponentiating both sides:\nL\u0302(D; w) = \u2212 N\u2211 n=1 log\n exp ( s+ \u2211D d=1 log [ qd + (1\u2212 qd) exp(y>nwdxnd) ]) \u2211\ny\u2032n exp\n( s+ \u2211D d=1 log [ qd + (1\u2212 qd) exp(y\u2032>nwdxnd)\n])  , (33)\nfor some appropriately chosen log-shift s. However, the computation of this quantity may be problematic when y>nwdxnd > 0. We resolve this by noting the following equality:\nlog [ qd + (1\u2212 qd) exp(y>nwdxnd) ] = y>nwdxnd + log [ qd exp(\u2212y>nwdxnd) + 1\u2212 qd ] . (34)\nDepending on the sign of y>nwdxnd, we compute the left-hand side or the right-hand side of this equation."}], "references": [{"title": "Competing in the dark: An efficient algorithm for bandit linear optimization", "author": ["J. Abernethy", "E. Hazan", "A. Rakhlin"], "venue": "In Proceedings of the Conference on Learning Theory,", "citeRegEx": "Abernethy et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Abernethy et al\\.", "year": 2008}, {"title": "The relationship between variable selection and data augmentation and a method for prediction", "author": ["D.M. Allen"], "venue": null, "citeRegEx": "Allen.,? \\Q1974\\E", "shortCiteRegEx": "Allen.", "year": 1974}, {"title": "A second order cone programming formulation for classifying missing data", "author": ["C. Bhattacharyya", "K.S. Pannagadatta", "A.J. Smola"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bhattacharyya et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Bhattacharyya et al\\.", "year": 2004}, {"title": "Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification", "author": ["J. Blitzer", "M. Dredze", "F. Pereira"], "venue": "In Association for Computational Linguistics,", "citeRegEx": "Blitzer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Blitzer et al\\.", "year": 2007}, {"title": "Convex optimization", "author": ["S.P. Boyd", "L. Vandenberghe"], "venue": null, "citeRegEx": "Boyd and Vandenberghe.,? \\Q2004\\E", "shortCiteRegEx": "Boyd and Vandenberghe.", "year": 2004}, {"title": "Improving the accuracy and speed of support vector machines", "author": ["C.J.C. Burges", "B. Sch\u00f6lkopf"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Burges and Sch\u00f6lkopf.,? \\Q1997\\E", "shortCiteRegEx": "Burges and Sch\u00f6lkopf.", "year": 1997}, {"title": "Online learning of noisy data with kernels", "author": ["N. Cesa-Bianchi", "S. Shalev-Shwartz", "O. Shamir"], "venue": "In Proceedings of the Conference on Learning Theory,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2010}, {"title": "Online learning of noisy data", "author": ["N. Cesa-Bianchi", "S. Shalev-Shwartz", "O. Shamir"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2011}, {"title": "Vicinal risk minimization", "author": ["O. Chapelle", "J. Weston", "L. Bottou", "V. Vapnik"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Chapelle et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2000}, {"title": "Max-margin classification of data with absent features", "author": ["G. Chechik", "G. Heitz", "G. Elidan", "P. Abbeel", "D. Koller"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Chechik et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Chechik et al\\.", "year": 2008}, {"title": "Marginalized denoising autoencoders for domain adaptation", "author": ["M. Chen", "Z. Xu", "K.Q. Weinberger", "F. Sha"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Chen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2012}, {"title": "Fast image tagging", "author": ["M. Chen", "A. Zheng", "K.Q. Weinberger"], "venue": "In Proceedings of 30th International Conference on Machine Learning,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["A. Coates", "H. Lee", "A.Y. Ng"], "venue": "In Proceedings of the International Conference on Artificial Intelligence & Statistics, JMLR W&CP", "citeRegEx": "Coates et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2011}, {"title": "Nearest neighbor pattern classification", "author": ["T. Cover", "P. Hart"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Cover and Hart.,? \\Q1967\\E", "shortCiteRegEx": "Cover and Hart.", "year": 1967}, {"title": "Frustratingly easy domain adaptation", "author": ["H. Daum\u00e9 III"], "venue": "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,", "citeRegEx": "III.,? \\Q2007\\E", "shortCiteRegEx": "III.", "year": 2007}, {"title": "Learning to classify with missing and corrupted features", "author": ["O. Dekel", "O. Shamir"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Dekel and Shamir.,? \\Q2008\\E", "shortCiteRegEx": "Dekel and Shamir.", "year": 2008}, {"title": "Online convex optimization in the bandit setting: Gradient descent without a gradient", "author": ["A. Flaxman", "A. Kalai", "H. McMahan"], "venue": "In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "Flaxman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Flaxman et al\\.", "year": 2005}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "In Proceedings of the Second European Conference on Computational Learning Theory,", "citeRegEx": "Freund and Schapire.,? \\Q1995\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 1995}, {"title": "Nightmare at test time: Robust learning by feature deletion", "author": ["A. Globerson", "S. Roweis"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Globerson and Roweis.,? \\Q2006\\E", "shortCiteRegEx": "Globerson and Roweis.", "year": 2006}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Glorot et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Glorot et al\\.", "year": 2011}, {"title": "Trace lasso: A trace norm regularization for correlated designs", "author": ["E. Grave", "G. Obozinski", "F. Bach"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Grave et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Grave et al\\.", "year": 2011}, {"title": "Speedboost: Anytime prediction with uniform near-optimality", "author": ["A. Grubb", "J.A. Bagnell"], "venue": "In Proceedings of the International Conference on Artificial Intelligence & Statistics (AISTATS),", "citeRegEx": "Grubb and Bagnell.,? \\Q2012\\E", "shortCiteRegEx": "Grubb and Bagnell.", "year": 2012}, {"title": "Invariant pattern recognition by semidefinite programming machines", "author": ["R. Herbrich", "T. Graepel"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Herbrich and Graepel.,? \\Q2004\\E", "shortCiteRegEx": "Herbrich and Graepel.", "year": 2004}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["G.E. Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R.R. Salakhutdinov"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Technical report, University of Toronto,", "citeRegEx": "Krizhevsky.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky.", "year": 2009}, {"title": "Estimating a kernel Fisher discriminant in the presence of label noise", "author": ["N.D. Lawrence", "B. Sch\u00f6lkopf"], "venue": "In Proceedings of the International Conference in Machine Learning,", "citeRegEx": "Lawrence and Sch\u00f6lkopf.,? \\Q2001\\E", "shortCiteRegEx": "Lawrence and Sch\u00f6lkopf.", "year": 2001}, {"title": "Probabilistic error correction for RNA sequencing", "author": ["H.S. Le", "M.H. Schulz", "B.M. McCauley", "V.F. Hinman", "Z. Bar-Joseph"], "venue": "Nucleic Acids Research,", "citeRegEx": "Le et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Le et al\\.", "year": 2013}, {"title": "Optimal brain damage", "author": ["Y. LeCun", "J.S. Denker", "S.A. Solla"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "LeCun et al\\.,? \\Q1990\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1990}, {"title": "A simple geometric interpretation of svm using stochastic adversaries", "author": ["R. Livni", "K. Crammer", "A. Globerson"], "venue": "In Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AI-STATS),", "citeRegEx": "Livni et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Livni et al\\.", "year": 2012}, {"title": "Steerable playlist generation by learning song similarity from radio station playlists", "author": ["F. Maillet", "D. Eck", "G. Desjardins", "P. Lamere"], "venue": "In Proceedings of the International Society for Music Information Retrieval Conference,", "citeRegEx": "Maillet et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Maillet et al\\.", "year": 2009}, {"title": "A PAC-Bayesian tutorial with a dropout", "author": ["D. McAllester"], "venue": null, "citeRegEx": "McAllester.,? \\Q2013\\E", "shortCiteRegEx": "McAllester.", "year": 2013}, {"title": "Unsupervised and transfer learning challenge: a deep learning approach", "author": ["G. Mesnil", "Y. Dauphin", "X. Glorot", "S. Rifai", "Y. Bengio", "I. Goodfellow", "E. Lavoie", "X. Muller", "G. Desjardins", "D. Warde-Farley", "P. Vincent", "A. Courville", "J. Bergstra"], "venue": "JMLR: Workshop and Conference Proceedings,", "citeRegEx": "Mesnil et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mesnil et al\\.", "year": 2011}, {"title": "Training knowledge-based neural networks to recognize genes in DNA sequences", "author": ["M.O. Noordewier", "G.G. Towell", "J.W. Shavlik"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Noordewier et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Noordewier et al\\.", "year": 1991}, {"title": "On estimation of a probability density function and mode", "author": ["E. Parzen"], "venue": "Annals of Mathematical Statistics,", "citeRegEx": "Parzen.,? \\Q1962\\E", "shortCiteRegEx": "Parzen.", "year": 1962}, {"title": "Modeling pixel means and covariances using factorized thirdorder Boltzmann machines", "author": ["M. Ranzato", "G.E. Hinton"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Ranzato and Hinton.,? \\Q2010\\E", "shortCiteRegEx": "Ranzato and Hinton.", "year": 2010}, {"title": "Learning with missing features", "author": ["A. Rostamizadeh", "A. Agarwal", "P. Bartlett"], "venue": "In Proceedings of Uncertainty in Artificial Intelligence,", "citeRegEx": "Rostamizadeh et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rostamizadeh et al\\.", "year": 2011}, {"title": "Shallow parsing with Conditional Random Fields", "author": ["F. Sha", "F. Pereira"], "venue": "In Proceedings of Human Language Technology \u2013 NAACL", "citeRegEx": "Sha and Pereira.,? \\Q2003\\E", "shortCiteRegEx": "Sha and Pereira.", "year": 2003}, {"title": "A tutorial on conformal prediction", "author": ["G. Shafer", "V. Vovk"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Shafer and Vovk.,? \\Q2008\\E", "shortCiteRegEx": "Shafer and Vovk.", "year": 2008}, {"title": "Second order cone programming approaches for handling missing and uncertain data", "author": ["P.K. Shivaswamy", "C. Bhattacharyya", "A.J. Smola"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Shivaswamy et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Shivaswamy et al\\.", "year": 2006}, {"title": "Feature bagging: Preventing weight undertraining in structured discriminative learning", "author": ["C. Sutton", "M. Sindelar", "A. McCallum"], "venue": "Technical Report IR-402,", "citeRegEx": "Sutton et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 2005}, {"title": "Convex learning with invariances", "author": ["C.H. Teo", "A. Globerson", "S. Roweis", "A. Smola"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Teo et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Teo et al\\.", "year": 2008}, {"title": "80 million tiny images: A large dataset for non-parametric object and scene recognition", "author": ["A. Torralba", "R. Fergus", "W.T. Freeman"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Torralba et al\\.,? \\Q1958\\E", "shortCiteRegEx": "Torralba et al\\.", "year": 1958}, {"title": "Robust support vector machines for classification and computational issues", "author": ["T. Trafalis", "R. Gilbert"], "venue": "Optimization Methods and Software,", "citeRegEx": "Trafalis and Gilbert.,? \\Q2007\\E", "shortCiteRegEx": "Trafalis and Gilbert.", "year": 2007}, {"title": "Learning by marginalizing corrupted features", "author": ["L.J.P. van der Maaten", "M. Chen", "S. Tyree", "K.Q. Weinberger"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Maaten et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2013}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["P. Vincent", "H. Larochelle", "Y. Bengio", "P.A. Manzagol"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Vincent et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2008}, {"title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "author": ["P. Vincent", "H. Larochelle", "I. Lajoie", "Y. Bengio", "P.-A. Manzagol"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Vincent et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2010}, {"title": "Dropout training as adaptive regularization", "author": ["S. Wager", "S. Wang", "P. Liang"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Wager et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wager et al\\.", "year": 2013}, {"title": "Feature noising for log-linear structured prediction", "author": ["S. Wang", "M. Wang", "S. Wager", "P. Liang", "C.D. Manning"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Wang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2013}, {"title": "Robustness and regularization of support vector machines", "author": ["H. Xu", "C. Caramanis", "S. Mannor"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Xu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2009}, {"title": "Error correction of next-generation sequencing data and reliable estimation of HIV quasispecies", "author": ["O. Zagordi", "R. Klein", "M. D\u00e4umer", "N. Beerenwinkel"], "venue": "Nucleic Acids Research,", "citeRegEx": "Zagordi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zagordi et al\\.", "year": 2010}, {"title": "Multi-class AdaBoost", "author": ["J. Zhu", "S. Rosset", "H. Zou", "T. Hastie"], "venue": "Technical Report 430, Department of Statistics, University of Michigan,", "citeRegEx": "Zhu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 13, "context": "In such a hypothetical scenario, it is impossible to overfit models; and even high-variance models, such as the nearest neighbor classifier (Cover and Hart, 1967), become close to optimal (viz.", "startOffset": 140, "endOffset": 162}, {"referenceID": 33, "context": "The Gaussian corruption model is mainly of interest for continuous-valued data sets; special cases of MCF with Gaussian corruption have already been studied in the context of Parzen density estimation (Parzen, 1962) and in the context of vicinal risk minimization (Chapelle et al.", "startOffset": 201, "endOffset": 215}, {"referenceID": 8, "context": "The Gaussian corruption model is mainly of interest for continuous-valued data sets; special cases of MCF with Gaussian corruption have already been studied in the context of Parzen density estimation (Parzen, 1962) and in the context of vicinal risk minimization (Chapelle et al., 2000).", "startOffset": 264, "endOffset": 287}, {"referenceID": 5, "context": "Burges and Sch\u00f6lkopf (1997) explicitly augment the training set with additional examples that are corrupted through similar transformations.", "startOffset": 0, "endOffset": 28}, {"referenceID": 18, "context": "Blankout corruption is also of interest in the \u201cnightmare at test time\u201d scenario (Globerson and Roweis, 2006) in which some of the features are deleted during testing, e.", "startOffset": 81, "endOffset": 109}, {"referenceID": 2, "context": "Different from previous work (Bhattacharyya et al., 2004; Globerson and Roweis, 2006; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007), our setting focuses on random feature removal and not on the (in practice much rarer) worst-case adversarial setting.", "startOffset": 29, "endOffset": 138}, {"referenceID": 18, "context": "Different from previous work (Bhattacharyya et al., 2004; Globerson and Roweis, 2006; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007), our setting focuses on random feature removal and not on the (in practice much rarer) worst-case adversarial setting.", "startOffset": 29, "endOffset": 138}, {"referenceID": 38, "context": "Different from previous work (Bhattacharyya et al., 2004; Globerson and Roweis, 2006; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007), our setting focuses on random feature removal and not on the (in practice much rarer) worst-case adversarial setting.", "startOffset": 29, "endOffset": 138}, {"referenceID": 42, "context": "Different from previous work (Bhattacharyya et al., 2004; Globerson and Roweis, 2006; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007), our setting focuses on random feature removal and not on the (in practice much rarer) worst-case adversarial setting.", "startOffset": 29, "endOffset": 138}, {"referenceID": 29, "context": "The resulting denoising autoencoder model is now commonly used as a building block in deep learning (Maillet et al., 2009; Glorot et al., 2011; Mesnil et al., 2011), and blankout corruption is also increasingly applied on the hidden units of neural networks as a form of regularization (Hinton et al.", "startOffset": 100, "endOffset": 164}, {"referenceID": 19, "context": "The resulting denoising autoencoder model is now commonly used as a building block in deep learning (Maillet et al., 2009; Glorot et al., 2011; Mesnil et al., 2011), and blankout corruption is also increasingly applied on the hidden units of neural networks as a form of regularization (Hinton et al.", "startOffset": 100, "endOffset": 164}, {"referenceID": 31, "context": "The resulting denoising autoencoder model is now commonly used as a building block in deep learning (Maillet et al., 2009; Glorot et al., 2011; Mesnil et al., 2011), and blankout corruption is also increasingly applied on the hidden units of neural networks as a form of regularization (Hinton et al.", "startOffset": 100, "endOffset": 164}, {"referenceID": 23, "context": ", 2011), and blankout corruption is also increasingly applied on the hidden units of neural networks as a form of regularization (Hinton et al., 2012).", "startOffset": 129, "endOffset": 150}, {"referenceID": 10, "context": "Linear denoising autoencoders (Chen et al., 2012) can be viewed as a special case of MCF that aim to minimize the expected value of the reconstruction error under blankout corruption\u2014 and which are stacked in multiple layers.", "startOffset": 30, "endOffset": 49}, {"referenceID": 16, "context": "In online learning and bandit problems, various studies have shown that it is possible to learn from data that are subject to a (possibly unknown) corrupting distribution (Flaxman et al., 2005; Abernethy et al., 2008; Cesa-Bianchi et al., 2010).", "startOffset": 171, "endOffset": 244}, {"referenceID": 0, "context": "In online learning and bandit problems, various studies have shown that it is possible to learn from data that are subject to a (possibly unknown) corrupting distribution (Flaxman et al., 2005; Abernethy et al., 2008; Cesa-Bianchi et al., 2010).", "startOffset": 171, "endOffset": 244}, {"referenceID": 6, "context": "In online learning and bandit problems, various studies have shown that it is possible to learn from data that are subject to a (possibly unknown) corrupting distribution (Flaxman et al., 2005; Abernethy et al., 2008; Cesa-Bianchi et al., 2010).", "startOffset": 171, "endOffset": 244}, {"referenceID": 4, "context": "The initial publication by Burges and Sch\u00f6lkopf (1997) has inspired various lines of work that explicitly corrupt training data during training.", "startOffset": 27, "endOffset": 55}, {"referenceID": 4, "context": "The initial publication by Burges and Sch\u00f6lkopf (1997) has inspired various lines of work that explicitly corrupt training data during training. Most prominently, Vincent et al. (2008, 2010) propose to randomly blank out features in the training data that is used as input to autoencoders, whilst leaving the desired output (the original training data) unaltered. The resulting denoising autoencoder model is now commonly used as a building block in deep learning (Maillet et al., 2009; Glorot et al., 2011; Mesnil et al., 2011), and blankout corruption is also increasingly applied on the hidden units of neural networks as a form of regularization (Hinton et al., 2012). Since autoencoders are non-linear, the marginalization over the corrupting distribution cannot be performed analytically in such models. Linear denoising autoencoders (Chen et al., 2012) can be viewed as a special case of MCF that aim to minimize the expected value of the reconstruction error under blankout corruption\u2014 and which are stacked in multiple layers. Herbrich and Graepel (2004) propose an elegant generalization of SVMs that learns to be invariant to polynomial input transformations via a semi-definite programming formulation.", "startOffset": 27, "endOffset": 1064}, {"referenceID": 0, "context": ", 2005; Abernethy et al., 2008; Cesa-Bianchi et al., 2010). For instance, Cesa-Bianchi et al. (2011) show that noise in the data does not affect the convergence rate of online learners.", "startOffset": 8, "endOffset": 101}, {"referenceID": 0, "context": ", 2005; Abernethy et al., 2008; Cesa-Bianchi et al., 2010). For instance, Cesa-Bianchi et al. (2011) show that noise in the data does not affect the convergence rate of online learners. A similar regret bound is proven by Rostamizadeh et al. (2011) for online learning under the presence of randomly missing features (i.", "startOffset": 8, "endOffset": 249}, {"referenceID": 2, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature.", "startOffset": 14, "endOffset": 112}, {"referenceID": 38, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature.", "startOffset": 14, "endOffset": 112}, {"referenceID": 42, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature.", "startOffset": 14, "endOffset": 112}, {"referenceID": 48, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature.", "startOffset": 14, "endOffset": 112}, {"referenceID": 15, "context": "In particular, Globerson and Roweis (2006) propose a minimax-formulation in which the loss is minimized assuming maximum \u201cdamage\u201d through corruption.", "startOffset": 15, "endOffset": 43}, {"referenceID": 13, "context": "By contrast, Dekel and Shamir (2008) propose a linear-programming formulation that minimizes an approximation to the same quantity for margin-based predictors.", "startOffset": 13, "endOffset": 37}, {"referenceID": 2, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature. Livni et al. (2012) consider a scenario in which an adversarial chooses the corrupting distribution from the set of all distributions with a pre-specified variance as to increase the expected loss under the corruption as much as possible.", "startOffset": 15, "endOffset": 347}, {"referenceID": 2, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature. Livni et al. (2012) consider a scenario in which an adversarial chooses the corrupting distribution from the set of all distributions with a pre-specified variance as to increase the expected loss under the corruption as much as possible. Chechik et al. (2008) propose an algorithm that maximizes the margin in the subspace of the observed features for each training instance to be robust against random feature deletion.", "startOffset": 15, "endOffset": 588}, {"referenceID": 2, "context": "Other studies (Bhattacharyya et al., 2004; Shivaswamy et al., 2006; Trafalis and Gilbert, 2007; Xu et al., 2009) also use minimax approaches that minimize losses under a worst-case scenario, but they focus on a somewhat different corruption model that adds a uniformly drawn constant, within a fixed interval, to each feature. Livni et al. (2012) consider a scenario in which an adversarial chooses the corrupting distribution from the set of all distributions with a pre-specified variance as to increase the expected loss under the corruption as much as possible. Chechik et al. (2008) propose an algorithm that maximizes the margin in the subspace of the observed features for each training instance to be robust against random feature deletion. Teo et al. (2008) generalize the worst-case scenario from simple feature corruption to obtain invariances to transformations such as image rotations or translations.", "startOffset": 15, "endOffset": 767}, {"referenceID": 22, "context": "eral prior formulations on learning with invariants as special cases, most prominently, the formulation of Herbrich and Graepel (2004). Such previous work differs from our approach in that it focuses on adversarial scenarios and does not consider the corruption analytically in expectation.", "startOffset": 107, "endOffset": 135}, {"referenceID": 18, "context": "In the nightmare at test-time scenario, introduced by Globerson and Roweis (2006), there is an expectation that corruption will appear during test-time.", "startOffset": 54, "endOffset": 82}, {"referenceID": 5, "context": "A simple approach to approximately learn from the distribution p(x\u0303|x)P(x) is to follow the spirit of Burges and Sch\u00f6lkopf (1997) and corrupt each training sample M times, following (1).", "startOffset": 102, "endOffset": 130}, {"referenceID": 23, "context": "Such approaches have recently become popular, in particular, in the deep-learning community as a way to regularize deep networks (Hinton et al., 2012).", "startOffset": 129, "endOffset": 150}, {"referenceID": 8, "context": "For such a Gaussian corruption model, we obtain the standard l2-regularized quadratic loss with regularization parameter \u03c32 that is used in ridge regression as special case (Chapelle et al., 2000):", "startOffset": 173, "endOffset": 196}, {"referenceID": 20, "context": "Similar data-dependent regularizers have previously been studied by Grave et al. (2011). Poisson corruption.", "startOffset": 68, "endOffset": 88}, {"referenceID": 1, "context": "A nice property of linear models employing quadratic loss is that they allow us to compute the leave-one-out error of the model from only the training predictions \u0177n (Allen, 1974).", "startOffset": 166, "endOffset": 179}, {"referenceID": 1, "context": ", yN ], and use the simple fact that \u0177\u2212n n = \u2211N m=1Hnmzm (see Allen (1974) for details) we obtain: \u0177n \u2212 \u0177\u2212n n = N \u2211", "startOffset": 62, "endOffset": 75}, {"referenceID": 17, "context": ", in AdaBoost (Freund and Schapire, 1995).", "startOffset": 14, "endOffset": 41}, {"referenceID": 50, "context": "The derivation of (14) can readily be extended to a multi-class exponential loss with K classes by replacing the weight vector w by a D \u00d7K weight matrix W, and by replacing the labels y by label vectors y = {1,\u2212 1 K\u22121} with \u2211K k=1 yk = 0 (Zhu et al., 2006).", "startOffset": 238, "endOffset": 256}, {"referenceID": 36, "context": "Motivated by Sha and Pereira (2003), we used an L-BFGS optimizer to minimize MCF exponential loss in this study.", "startOffset": 13, "endOffset": 36}, {"referenceID": 45, "context": "In this section we follow the framework of Wager et al. (2013), which is clearer than our previously used derivation (van der Maaten et al.", "startOffset": 43, "endOffset": 63}, {"referenceID": 43, "context": "(2013), which is clearer than our previously used derivation (van der Maaten et al. (2013)) and leads to a nice interpretation of MCF as an adaptive regularizer.", "startOffset": 70, "endOffset": 91}, {"referenceID": 46, "context": "2 Quadratic Approximation A quadratic approximation to the expected logistic loss can be obtained by deriving a second-order Taylor expansion of A(w>x\u0303) around w>x and working out the expectation (Wager et al., 2013).", "startOffset": 196, "endOffset": 216}, {"referenceID": 37, "context": "In classification, corrupting test data provides a natural way to measure the uncertainty of a prediction, even when the original predictor was non-probabilistic (much like conformal prediction; Shafer and Vovk (2008)).", "startOffset": 195, "endOffset": 218}, {"referenceID": 3, "context": "Specifically, we focus on three data sets: the Dmoz data set, the Reuters data set, and the Amazon review benchmark set (Blitzer et al., 2007).", "startOffset": 120, "endOffset": 142}, {"referenceID": 3, "context": "Specifically, we focus on three data sets: the Dmoz data set, the Reuters data set, and the Amazon review benchmark set (Blitzer et al., 2007). Data sets. The Dmoz open directory (http://www.dmoz.org) contains a large collection of webpages arranged into a tree hierarchy. We use a subset consisting of N = 8, 980 webpages from the K = 16 categories in the top level of the hierarchy. Each webpage is represented by a bag-of-words representation with D = 16, 498 words. The Reuters document classification data set consists of N = 8, 293 news articles that appeared on the Reuters newswire in 1987 belonging to K = 65 topics (documents corresponding to multiple topics were removed from the data). The bag-of-words representation contains D = 18, 933 words for each document. The four Amazon data sets consist of approximately N = 6, 000 reviews of four types of products: books, DVDs, electronics, and kitchen appliances. Each review is represented by a bag-of-words representation of the D = 20, 000 most common words. On the Dmoz and Reuters data sets, the task is to classify the documents into one of the predefined categories. On the Amazon data set, the task is to decide whether a review is positive or negative. Setup. On the Dmoz and Reuters data sets, we use fixed 75%/25% training/test splits. On the Amazon data set, we follow the experimental setup of Blitzer et al. (2007) by using a predefined division of the data into approximately 2, 000 training examples and about 4, 000 test examples (the exact numbers vary slightly between tasks).", "startOffset": 121, "endOffset": 1388}, {"referenceID": 24, "context": "2 Image classification We perform image-classification experiments with MCF on the CIFAR-10 data set (Krizhevsky, 2009), which is a subset of the 80 million tiny images (Torralba et al.", "startOffset": 101, "endOffset": 119}, {"referenceID": 12, "context": "We follow the experimental setup of Coates et al. (2011): we whiten the training images and extract a set of 7 \u00d7 7 image patches on which we apply k-means clustering (with k = 2048) to construct a codebook of prototypical image patches.", "startOffset": 36, "endOffset": 57}, {"referenceID": 12, "context": "We follow the experimental setup of Coates et al. (2011): we whiten the training images and extract a set of 7 \u00d7 7 image patches on which we apply k-means clustering (with k = 2048) to construct a codebook of prototypical image patches. Next, we slide a 7 \u00d7 7 pixel window over each image and identify the nearest prototype in the codebook for each window location. We construct an image descriptor by subdividing the image into four equally sized quadrants and counting the number of times each prototype occurs in each quadrant, which leads to a descriptor of dimensionality D = 4 \u00d7 2048. This way of extracting the image features is referred to by Coates et al. (2011) as k-means with hard assignment, average pooling, patch size 7 \u00d7 7, and stride 1.", "startOffset": 36, "endOffset": 672}, {"referenceID": 34, "context": "Although our focus in this section is to merely illustrate the potential of MCF on image classification tasks, it is worth noting that the best results in Table 3 match those of a highly non-linear mean-covariance RBMs trained on the same data (Ranzato and Hinton, 2010), despite our use of very simple visual features and of linear classifiers.", "startOffset": 244, "endOffset": 270}, {"referenceID": 12, "context": "8% accuracy reported by Coates et al. (2011) with exactly the same experimental setup (except for exponential loss).", "startOffset": 24, "endOffset": 45}, {"referenceID": 31, "context": "We perform experiments on the data set constructed by Noordewier et al. (1991). The data set comprises 3190 examples of three classes: it contains 767 examples of acceptors, 768 examples of donors, and 1655 negative examples.", "startOffset": 54, "endOffset": 79}, {"referenceID": 26, "context": ", Le et al. (2013); Zagordi et al.", "startOffset": 2, "endOffset": 19}, {"referenceID": 26, "context": ", Le et al. (2013); Zagordi et al. (2010)).", "startOffset": 2, "endOffset": 42}, {"referenceID": 26, "context": "Both types of knowledge are available for modern DNA sequencing processes (Le et al., 2013; Zagordi et al., 2010).", "startOffset": 74, "endOffset": 113}, {"referenceID": 49, "context": "Both types of knowledge are available for modern DNA sequencing processes (Le et al., 2013; Zagordi et al., 2010).", "startOffset": 74, "endOffset": 113}, {"referenceID": 32, "context": "However, since no information on the coverage and sequencing error distribution is available for our data set (Noordewier et al., 1991), we leave such extensions of the DNA experiments to future work.", "startOffset": 110, "endOffset": 135}, {"referenceID": 18, "context": "In addition to the comparisons with standard predictors, we also compare the performance of MCF with that of FDROP (Globerson and Roweis, 2006), which is a state-of-the-art algorithm for the \u201cnightmare at test time\u201d setting that minimizes the hinge loss under an adversarial worst-case scenario (see section 2).", "startOffset": 115, "endOffset": 143}, {"referenceID": 18, "context": "Classification errors of standard and MCF predictors with a blankout corruption model \u2013 trained using three different losses \u2013 and of FDROP (Globerson and Roweis, 2006) on the MNIST data set using the \u201cnightmare at test time\u201d scenario.", "startOffset": 140, "endOffset": 168}, {"referenceID": 3, "context": "We are thus assuming a transductive learning setting, which is a common assumption in many learning scenarios with domain shift (Blitzer et al., 2007; Daum\u00e9 III, 2007).", "startOffset": 128, "endOffset": 167}, {"referenceID": 16, "context": "Following the experimental setting of Globerson and Roweis (2006), we perform the crossvalidation for each deletion percentage independently, i.", "startOffset": 38, "endOffset": 66}, {"referenceID": 39, "context": "Further, MCF with blankout corruption also appears to prevent weight undertraining (Sutton et al., 2005): it encourages the weight on each feature to be non-zero, in case this particular feature survives the corruption.", "startOffset": 83, "endOffset": 104}, {"referenceID": 15, "context": "Learning with MCF is quite different from previous approaches for this setting (Dekel and Shamir, 2008; Globerson and Roweis, 2006).", "startOffset": 79, "endOffset": 131}, {"referenceID": 18, "context": "Learning with MCF is quite different from previous approaches for this setting (Dekel and Shamir, 2008; Globerson and Roweis, 2006).", "startOffset": 79, "endOffset": 131}, {"referenceID": 3, "context": "The strong performance of MCF in the \u201cnightmare at test-time\u201d scenario suggest it be well suited for learning under domain shift (Blitzer et al., 2007; Daum\u00e9 III, 2007).", "startOffset": 129, "endOffset": 168}, {"referenceID": 47, "context": "Another interesting direction for future work is to investigate extensions of MCF to structured prediction (Wang et al., 2013), as well as to investigate if MCF can be employed for kernel machines.", "startOffset": 107, "endOffset": 126}, {"referenceID": 27, "context": "Further, MCF could be used in the training of neural networks with a single layer of hidden units: blankout noise on the hidden nodes can improve the performance of the networks (LeCun et al., 1990; Hinton et al., 2012) and can be marginalized out analytically.", "startOffset": 178, "endOffset": 219}, {"referenceID": 23, "context": "Further, MCF could be used in the training of neural networks with a single layer of hidden units: blankout noise on the hidden nodes can improve the performance of the networks (LeCun et al., 1990; Hinton et al., 2012) and can be marginalized out analytically.", "startOffset": 178, "endOffset": 219}, {"referenceID": 21, "context": "Moreover, classifiers trained using MCF-blankout may be very well suited for application in anytime classification scenarios (Grubb and Bagnell, 2012), as they are optimized to work well on all possible subsets of features.", "startOffset": 125, "endOffset": 150}, {"referenceID": 25, "context": "A final interesting direction would be to investigate the effect of marginalizing corrupted labels or target values (Lawrence and Sch\u00f6lkopf, 2001; Chen et al., 2013).", "startOffset": 116, "endOffset": 165}, {"referenceID": 11, "context": "A final interesting direction would be to investigate the effect of marginalizing corrupted labels or target values (Lawrence and Sch\u00f6lkopf, 2001; Chen et al., 2013).", "startOffset": 116, "endOffset": 165}, {"referenceID": 3, "context": "The strong performance of MCF in the \u201cnightmare at test-time\u201d scenario suggest it be well suited for learning under domain shift (Blitzer et al., 2007; Daum\u00e9 III, 2007). In particular, as the corrupting distribution may be used to shift the data distribution in the source domain towards the data distribution in the target domain \u2014 potentially, by learning the parameters of the corrupting distribution using maximum likelihood. We leave such investigations for future work. Another interesting direction for future work is to investigate extensions of MCF to structured prediction (Wang et al., 2013), as well as to investigate if MCF can be employed for kernel machines. We also plan to explore in more detail what corruption models p(x\u0303|x) are useful for what types of data. Further, MCF could be used in the training of neural networks with a single layer of hidden units: blankout noise on the hidden nodes can improve the performance of the networks (LeCun et al., 1990; Hinton et al., 2012) and can be marginalized out analytically. Moreover, classifiers trained using MCF-blankout may be very well suited for application in anytime classification scenarios (Grubb and Bagnell, 2012), as they are optimized to work well on all possible subsets of features. Another interesting direction for future work is to investigate the theoretical properties of learning with MCF. Xu et al. (2009) have derived generalization bounds for learning with corruption under the worst-case scenario (i.", "startOffset": 130, "endOffset": 1395}, {"referenceID": 3, "context": "The strong performance of MCF in the \u201cnightmare at test-time\u201d scenario suggest it be well suited for learning under domain shift (Blitzer et al., 2007; Daum\u00e9 III, 2007). In particular, as the corrupting distribution may be used to shift the data distribution in the source domain towards the data distribution in the target domain \u2014 potentially, by learning the parameters of the corrupting distribution using maximum likelihood. We leave such investigations for future work. Another interesting direction for future work is to investigate extensions of MCF to structured prediction (Wang et al., 2013), as well as to investigate if MCF can be employed for kernel machines. We also plan to explore in more detail what corruption models p(x\u0303|x) are useful for what types of data. Further, MCF could be used in the training of neural networks with a single layer of hidden units: blankout noise on the hidden nodes can improve the performance of the networks (LeCun et al., 1990; Hinton et al., 2012) and can be marginalized out analytically. Moreover, classifiers trained using MCF-blankout may be very well suited for application in anytime classification scenarios (Grubb and Bagnell, 2012), as they are optimized to work well on all possible subsets of features. Another interesting direction for future work is to investigate the theoretical properties of learning with MCF. Xu et al. (2009) have derived generalization bounds for learning with corruption under the worst-case scenario (i.e. for the related models discussed in Section 2), and McAllester (2013) recently derived a PAC-Bayesian bound for learning linear models with blankout in the average-case scenario; however, generic bounds for learning with MCF do not yet exist.", "startOffset": 130, "endOffset": 1565}], "year": 2014, "abstractText": "The goal of machine learning is to develop predictors that generalize well to test data. Ideally, this is achieved by training on an almost infinitely large training data set that captures all variations in the data distribution. In practical learning settings, however, we do not have infinite data and our predictors may overfit. Overfitting may be combatted, for example, by adding a regularizer to the training objective or by defining a prior over the model parameters and performing Bayesian inference. In this paper, we propose a third, alternative approach to combat overfitting: we extend the training set with infinitely many artificial training examples that are obtained by corrupting the original training data. We show that this approach is practical and efficient for a range of predictors and corruption models. Our approach, called marginalized corrupted features (MCF), trains robust predictors by minimizing the expected value of the loss function under the corruption model. We show empirically on a variety of data sets that MCF classifiers can be trained efficiently, may generalize substantially better to test data, and are also more robust to feature deletion at test time.", "creator": "LaTeX with hyperref package"}}}