{"id": "1405.7430", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-May-2014", "title": "BayesOpt: A Bayesian Optimization Library for Nonlinear Optimization, Experimental Design and Bandits", "abstract": "BayesOpt is a library with state-of-the-art Bayesian optimization methods to solve nonlinear optimization, stochastic bandits or sequential experimental design problems. Bayesian optimization is sample efficient by building a posterior distribution to capture the evidence and prior knowledge for the target function. Built in standard C++, the library is extremely efficient while being portable and flexible. It includes a common interface for C, C++, Python, Matlab and Octave.", "histories": [["v1", "Thu, 29 May 2014 00:37:28 GMT  (11kb)", "http://arxiv.org/abs/1405.7430v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ruben martinez-cantin"], "accepted": false, "id": "1405.7430"}, "pdf": {"name": "1405.7430.pdf", "metadata": {"source": "CRF", "title": "BayesOpt: A Bayesian Optimization Library for Nonlinear Optimization, Experimental Design and Bandits", "authors": ["Ruben Martinez-Cantin"], "emails": ["rmcantin@unizar.es"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 5.\n74 30\nv1 [\ncs .L\nG ]\n2 9\nM ay"}, {"heading": "1 Introduction", "text": "Bayesian optimization (Mockus, 1989; Brochu et al., 2010) is a special case of nonlinear optimization where the algorithm decides which point to explore next based on the analysis of a distribution over functions P (f), for example a Gaussian process or other surrogate model. The decision is taken based on a certain criterion C(\u00b7) called acquisition function. Bayesian optimization has the advantage of having a memory of all the observations, encoded in the posterior of the surrogate model P (f |D) (see Figure 1). Usually, this posterior distribution is sequentially updated using a nonparametric model. In this setup, each observation improves the knowledge of the function in all the input space, thanks to the spatial correlation (kernel) of the model. Consequently, it requires a lower number of iterations compared to other nonlinear optimization algorithms. However, updating the posterior distribution and maximizing the acquisition function increases the cost per sample. Thus, Bayesian optimization is normally used to optimize expensive target functions f(\u00b7), which can be multimodal or without closed-form. The quality of the prior and posterior information about the surrogate model is of paramount importance for Bayesian optimization, because it can reduce considerably the number of evaluations to achieve the same performance."}, {"heading": "2 BayesOpt library", "text": "BayesOpt uses a surrogate model of the form: f(x) = \u03c6(x)Tw + \u01eb(x), where we have \u01eb(x) \u223c NP (\n0, \u03c32s(K(\u03b8) + \u03c3 2 nI)\n)\n. Here, NP() means a nonparametric process, for example, a Gaussian, Student-t or Mixture of Gaussians process. This model can be considered as a linear regression model \u03c6(x)Tw with heteroscedastic perturbation \u01eb(x), as a nonparametric process with nonzero mean function or as a semiparametric model. The library allows to define hyperpriors on w, \u03c32s and\n\u03b8. The marginal posterior P (f |D) can be computed in closed form, except for the kernel parameters \u03b8. Thus, BayesOpt allows to use different posteriors based on empirical Bayes (Santner et al., 2003) or MCMC (Snoek et al., 2012)."}, {"heading": "2.1 Implementation", "text": "Efficiency has been one of the main objectives during development. For empirical Bayes (ML or MAP of \u03b8), we found that a combination of global and local derivative free methods such as DIRECT (Jones et al., 1993) and BOBYQA (Powell, 2009) marginally outperforms in CPU time to gradient based method for optimizing \u03b8 by avoiding the overhead of computing the marginal likelihood derivative. Also, updating \u03b8 every iteration might be unnecessary or even counterproductive (Bull, 2011).\nOne of the most critical components, in terms of computational cost, is the computation of the inverse of the kernel matrix K(\u00b7)\u22121. We compared different numerical solutions and we found that the Cholesky decomposition method outperforms any other method in terms of performance and numerical stability. Furthermore, we can exploit the structure of the Bayesian optimization algorithm in two ways. First, points arrive sequentially. Thus, we can do incremental computations of matrices and vectors, except when the kernel parameters \u03b8 are updated. For example, at each iteration, we know that only n new elements will appear in the correlation matrix, i.e.: the correlation of the new point with each of the existing points. The rest of the matrix remains invariant. Thus, instead of computing the whole Cholesky decomposition, being O(n3) we just add the new row of elements to the triangular matrix, which is O(n2). Second, finding the optimal decision at each iteration xi requires multiple queries of the acquisition function from the same posterior C(x|P (f |D)) (see Figure 1). Also, many terms of the criterion function are independent of the query point x and can be precomputed. This behavior is not standard in nonparametric models, and to our knowledge, this is the first software for Gaussian processes/Bayesian optimization that exploits the idea of precomputing all terms independent of x.\nA comparison of CPU time (single thread) vs accuracy with respect to other open source libraries is represented in Table 1 with respect to two different configurations of BayesOpt. SMAC (Hutter et al., 2011), HyperOpt (Bergstra et al., 2011) and Spearmint (Snoek et al., 2012) used the HPOlib (Eggensperger et al., 2013) timing system (based on runsolver). DiceOptim (Roustant et al., 2012) used R timing system (proc.time). For BayesOpt, standard ctime was used.\nAnother main objective has been flexibility. The user can easily select among different algorithms, hyperpriors, kernels or mean functions. Currently, the library supports continuous, discrete and categorical optimization. We also provide a method for optimization in high-dimensional spaces (Wang et al., 2013). The initial set of points (initial design, see Figure 1) can be selected using well\nknown methods such as latin hypercube sampling or Sobol sequences. BayesOpt relies on a factorylike design for many of the components of the optimization process. This way, the components can be selected and combined at runtime while maintaining a simple structure. This has two advantages. First, it is very easy to create new components. For example, a new kernel can be defined by inheriting the abstract kernel or one of the existing kernels. Then, the new kernel is automatically integrated in the library. Second, inspired by the GPML toolbox by Rasmussen and Nickisch (2010), we can easily combine different components, like a linear combination of kernels or multiple criteria. This can be used to optimize a function considering an additional cost for each sample, for example a moving sensor (Marchant and Ramos, 2012). BayesOpt also implements metacriteria algorithms, like the bandit algorithm GP-Hedge by Hoffman et al. (2011) that can be used to automatically select the most suitable criteria during the optimization. Examples of these combinations can be found in Section 2.3.2.\nThe third objective is correctness. For example, the library is thread and exception safe, allowing parallelized calls. Numerically delicate parts, such as the GP-Hedge algorithm, had been implemented with variation of the actual algorithm to avoid over- or underflow issues. The library internally uses NLOPT by Johnson (2014) for the inner optimization loops (optimize criteria, learn kernel parameters, etc.).\nThe library and the online documentation can be found at: https://bitbucket.org/rmcantin/bayesopt/"}, {"heading": "2.2 Compatibility", "text": "BayesOpt has been designed to be highly compatible in many platforms and setups. It has been tested and compiled in different operating systems (Linux, Mac OS, Windows), with different compilers (Visual Studio, GCC, Clang, MinGW). The core of the library is written in C++, however, it provides interfaces for C, Python and Matlab/Octave."}, {"heading": "2.3 Using the library", "text": "There is a common API implemented for several languages and programming paradigms. Before running the optimization we need to follow two simple steps:"}, {"heading": "2.3.1 Target function definition", "text": "Defining the function that we want to optimize can be achieved in two ways. We can directly send the function (or a pointer) to the optimizer based on a function template. For example, in C/C++:\ndouble my function (unsigned int n query , const double \u2217query , double \u2217 gradient , void \u2217 f unc data ) ;\nThe gradient has been included for future compatibility. Python, Matlab and Octave interfaces define a similar template function.\nFor a more object oriented approach, we can inherit the abstract module and define the virtual methods. Using this approach, we can also include nonlinear constraints in the checkReachability method. This is available for C++ and Python. For example, in C++:\nclass MyOptimization : public bayesopt : : ContinuousModel { public : MyOptimization( s i z e t dim , bopt params param ) : ContinousModel (dim , param) {} double evaluateSample ( const boost : : numeric : : ublas : : vector<double> &query ) { // My func t i on here } ; bool checkReachab i l i ty ( const boost : : numeric : : ublas : : vector<double> &query ) { // My con s t r a i n t s here } ; } ;"}, {"heading": "2.3.2 BayesOpt parameters", "text": "The parameters are defined in the bopt params struct \u2013or a dictionary in Python\u2013. The details of each parameter can be found in the included documentation. The user can define expressions to combine different functions (kernels, criteria, etc.). All the parameters have a default value, so it is not necessary to define all of them. For example, in Matlab:\npar . surr name = \u2019sStudentTProcessNIG \u2019 ; % Surrogate model and hype rp r i o r s % We combine Expected Improvement , Lower Conf idence Bound and Thompson sampling par . c r i t name = \u2019cHedge (cEI ,cLCB ,cThompsonSampling)\u2019 ; par . kernel name = \u2019kSum(kMaternISO3 ,kRQISO )\u2019 ; % Sum of ke r ne l s par . kernel hp mean = [ 1 , 1 ] ; par . k e r ne l hp s td = [ 5 , 5 ] ; % Hyperpr ior on ke r ne l par . l t y p e = \u2019L_MCMC \u2019 ; % Method f o r l e a r n i ng the ke r ne l parameters par . s c type = \u2019SC_MAP \u2019 ; % Score f unc t i on f o r l e a r n i ng the ke r ne l parameters par . n i t e r a t i o n s = 200 ; % Number o f i t e r a t i o n s <=> Budget par . e p s i l o n = 0 . 1 ; % Add an eps i l on\u2212greedy s tep f o r be t t e r exp l o r a t i on"}], "references": [{"title": "Algorithms for hyper-parameter optimization", "author": ["James Bergstra", "Remi Bardenet", "Yoshua Bengio", "Bal\u00e1zs K\u00e9gl"], "venue": "In NIPS,", "citeRegEx": "Bergstra et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2011}, {"title": "A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning", "author": ["Eric Brochu", "Vlad M. Cora", "Nando de Freitas"], "venue": null, "citeRegEx": "Brochu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Brochu et al\\.", "year": 2010}, {"title": "Convergence rates of efficient global optimization algorithms", "author": ["Adam D. Bull"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bull.,? \\Q2011\\E", "shortCiteRegEx": "Bull.", "year": 2011}, {"title": "Towards an empirical foundation for assessing bayesian optimization of hyperparameters", "author": ["Katharina Eggensperger", "Matthias Feurer", "Frank Hutter", "James Bergstra", "Jasper Snoek", "Holger Hoos", "Kevin Leyton-Brown"], "venue": "In BayesOpt workshop (NIPS),", "citeRegEx": "Eggensperger et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Eggensperger et al\\.", "year": 2013}, {"title": "Portfolio allocation for Bayesian optimization", "author": ["Matthew Hoffman", "Eric Brochu", "Nando de Freitas"], "venue": "In UAI,", "citeRegEx": "Hoffman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffman et al\\.", "year": 2011}, {"title": "Sequential model-based optimization for general algorithm configuration", "author": ["Frank Hutter", "Holger H. Hoos", "Kevin Leyton-Brown"], "venue": "In LION-5, page 507523,", "citeRegEx": "Hutter et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2011}, {"title": "Lipschitzian optimization without the Lipschitz constant", "author": ["Donald R. Jones", "Cary D. Perttunen", "Bruce E. Stuckman"], "venue": "Journal of Optimization Theory and Applications,", "citeRegEx": "Jones et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Jones et al\\.", "year": 1993}, {"title": "Bayesian optimisation for intelligent environmental monitoring", "author": ["Roman Marchant", "Fabio Ramos"], "venue": "In IEEE/RSJ IROS,", "citeRegEx": "Marchant and Ramos.,? \\Q2012\\E", "shortCiteRegEx": "Marchant and Ramos.", "year": 2012}, {"title": "Bayesian Approach to Global Optimization, volume 37 of Mathematics and Its Applications", "author": ["Jonas Mockus"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "Mockus.,? \\Q1989\\E", "shortCiteRegEx": "Mockus.", "year": 1989}, {"title": "The BOBYQA algorithm for bound constrained optimization without derivatives", "author": ["Michael J.D. Powell"], "venue": "Technical Report NA2009/06,", "citeRegEx": "Powell.,? \\Q2009\\E", "shortCiteRegEx": "Powell.", "year": 2009}, {"title": "Gaussian processes for machine learning (GPML) toolbox", "author": ["Carl E. Rasmussen", "Hannes Nickisch"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Rasmussen and Nickisch.,? \\Q2010\\E", "shortCiteRegEx": "Rasmussen and Nickisch.", "year": 2010}, {"title": "DiceKriging, DiceOptim: two R packages for the analysis of computer experiments by kriging-based metamodelling and optimization", "author": ["Olivier Roustant", "David Ginsbourger", "Yves Deville"], "venue": "Journal of Statistical Software,", "citeRegEx": "Roustant et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Roustant et al\\.", "year": 2012}, {"title": "Practical Bayesian optimization of machine learning algorithms", "author": ["Jasper Snoek", "Hugo Larochelle", "Ryan Adams"], "venue": "In NIPS,", "citeRegEx": "Snoek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Snoek et al\\.", "year": 2012}, {"title": "Bayesian optimization in a billion dimensions via random embeddings", "author": ["Ziyu Wang", "Masrour Zoghi", "David Matheson", "Frank Hutter", "Nando de Freitas"], "venue": "In IJCAI,", "citeRegEx": "Wang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 8, "context": "Bayesian optimization (Mockus, 1989; Brochu et al., 2010) is a special case of nonlinear optimization where the algorithm decides which point to explore next based on the analysis of a distribution over functions P (f), for example a Gaussian process or other surrogate model.", "startOffset": 22, "endOffset": 57}, {"referenceID": 1, "context": "Bayesian optimization (Mockus, 1989; Brochu et al., 2010) is a special case of nonlinear optimization where the algorithm decides which point to explore next based on the analysis of a distribution over functions P (f), for example a Gaussian process or other surrogate model.", "startOffset": 22, "endOffset": 57}, {"referenceID": 12, "context": ", 2003) or MCMC (Snoek et al., 2012).", "startOffset": 16, "endOffset": 36}, {"referenceID": 6, "context": "For empirical Bayes (ML or MAP of \u03b8), we found that a combination of global and local derivative free methods such as DIRECT (Jones et al., 1993) and BOBYQA (Powell, 2009) marginally outperforms in CPU time to gradient based method for optimizing \u03b8 by avoiding the overhead of computing the marginal likelihood derivative.", "startOffset": 125, "endOffset": 145}, {"referenceID": 9, "context": ", 1993) and BOBYQA (Powell, 2009) marginally outperforms in CPU time to gradient based method for optimizing \u03b8 by avoiding the overhead of computing the marginal likelihood derivative.", "startOffset": 19, "endOffset": 33}, {"referenceID": 2, "context": "Also, updating \u03b8 every iteration might be unnecessary or even counterproductive (Bull, 2011).", "startOffset": 80, "endOffset": 92}, {"referenceID": 5, "context": "SMAC (Hutter et al., 2011), HyperOpt (Bergstra et al.", "startOffset": 5, "endOffset": 26}, {"referenceID": 0, "context": ", 2011), HyperOpt (Bergstra et al., 2011) and Spearmint (Snoek et al.", "startOffset": 18, "endOffset": 41}, {"referenceID": 12, "context": ", 2011) and Spearmint (Snoek et al., 2012) used the HPOlib (Eggensperger et al.", "startOffset": 22, "endOffset": 42}, {"referenceID": 3, "context": ", 2012) used the HPOlib (Eggensperger et al., 2013) timing system (based on runsolver).", "startOffset": 24, "endOffset": 51}, {"referenceID": 11, "context": "DiceOptim (Roustant et al., 2012) used R timing system (proc.", "startOffset": 10, "endOffset": 33}, {"referenceID": 13, "context": "We also provide a method for optimization in high-dimensional spaces (Wang et al., 2013).", "startOffset": 69, "endOffset": 88}, {"referenceID": 7, "context": "This can be used to optimize a function considering an additional cost for each sample, for example a moving sensor (Marchant and Ramos, 2012).", "startOffset": 116, "endOffset": 142}, {"referenceID": 8, "context": "Second, inspired by the GPML toolbox by Rasmussen and Nickisch (2010), we can easily combine different components, like a linear combination of kernels or multiple criteria.", "startOffset": 40, "endOffset": 70}, {"referenceID": 4, "context": "BayesOpt also implements metacriteria algorithms, like the bandit algorithm GP-Hedge by Hoffman et al. (2011) that can be used to automatically select the most suitable criteria during the optimization.", "startOffset": 88, "endOffset": 110}, {"referenceID": 4, "context": "BayesOpt also implements metacriteria algorithms, like the bandit algorithm GP-Hedge by Hoffman et al. (2011) that can be used to automatically select the most suitable criteria during the optimization. Examples of these combinations can be found in Section 2.3.2. The third objective is correctness. For example, the library is thread and exception safe, allowing parallelized calls. Numerically delicate parts, such as the GP-Hedge algorithm, had been implemented with variation of the actual algorithm to avoid over- or underflow issues. The library internally uses NLOPT by Johnson (2014) for the inner optimization loops (optimize criteria, learn kernel parameters, etc.", "startOffset": 88, "endOffset": 593}], "year": 2014, "abstractText": "BayesOpt is a library with state-of-the-art Bayesian optimization methods to solve nonlinear optimization, stochastic bandits or sequential experimental design problems. Bayesian optimization is sample efficient by building a posterior distribution to capture the evidence and prior knowledge for the target function. Built in standard C++, the library is extremely efficient while being portable and flexible. It includes a common interface for C, C++, Python, Matlab and Octave.", "creator": "LaTeX with hyperref package"}}}