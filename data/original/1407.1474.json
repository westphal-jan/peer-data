{"id": "1407.1474", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jul-2014", "title": "Fuzzy Model on Human Emotions Recognition", "abstract": "This paper discusses a fuzzy model for multi-level human emotions recognition by computer systems through keyboard keystrokes, mouse and touchscreen interactions. This model can also be used to detect the other possible emotions at the time of recognition. Accuracy measurements of human emotions by the fuzzy model are discussed through two methods; the first is accuracy analysis and the second is false positive rate analysis. This fuzzy model detects more emotions, but on the other hand, for some of emotions, a lower accuracy was obtained with the comparison with the non-fuzzy human emotions detection methods. This system was trained and tested by Support Vector Machine (SVM) to recognize the users' emotions. Overall, this model represents a closer similarity between human brain detection of emotions and computer systems.", "histories": [["v1", "Sun, 6 Jul 2014 09:38:21 GMT  (337kb)", "http://arxiv.org/abs/1407.1474v1", "12th WSEAS International Conference on Applications of Computer Engineering (ACE '13), Cambridge, MA, USA, 30 Jan. - 1 Feb. 2013 ISBN: 978-1-61804-156-2, Pages 77-82"]], "COMMENTS": "12th WSEAS International Conference on Applications of Computer Engineering (ACE '13), Cambridge, MA, USA, 30 Jan. - 1 Feb. 2013 ISBN: 978-1-61804-156-2, Pages 77-82", "reviews": [], "SUBJECTS": "cs.AI cs.HC", "authors": ["kaveh bakhtiyari", "hafizah husain"], "accepted": false, "id": "1407.1474"}, "pdf": {"name": "1407.1474.pdf", "metadata": {"source": "CRF", "title": "Fuzzy Model on Human Emotions Recognition", "authors": ["KAVEH BAKHTIYARI"], "emails": ["hafizah.ukm@gmail.com"], "sections": [{"heading": null, "text": "The importance of human emotions recognition is reflected by its wide applications of this system in different areas. Computer games (entertainments), computer-based tutors (e-learning), machine and system controlling (industrial areas), criminology, computer privacy and security and so on [1].\nFor instance, the emotional states of students at a presentation in an online tutor reflect the usability and performance of the class on students. This information even can help teachers or intelligent systems to adapt the training system for a better educational ambiance to deliver more knowledge as possible to students [1, 2].\nRecently, the accuracy of human emotions recognition is improving by employing different available methods and techniques such as image processing, voice recognition, natural language processing, keystroke dynamics, mouse movements, touch-screen interactions, EEG devices, measuring heart rates, body heat, blood pressure and so on [3-\n7]. Some methods like image processing, voice recognition and NLP are time and resource consuming and they need some special circumstances such as availability of video camera (webcam) or microphone, and some other methods require highly technical equipment such as for EEG or heart rate measuring [2]. These are medical machines which need a technical training to be installed and used, and sometimes the part of skin for installation should be shaved because of the inferences and noises. Keyboard keystroke dynamics, mouse movement and touch-screen interaction are the three methods which are mostly available on every computer or even portable digital devices such as handhelds, tablets, and mobile phones. This research has focused on these three methods for human emotions recognition because of availability and popularity of the devices and equipment.\nEmotions are discussed by two factors in psychology. The first factor is Arousal which talks about the amount of energy of emotions. In literature, different amount of energy has been named such as happiness, sadness and so on. The second factor is Valence which shows the pleasure level, whether it is a positive or a negative emotion. There are 3 problems which are usually ignored in most of the researches for human emotions recognition in computer systems. Firstly, human emotions are not constant and they do not occur and\nISBN: 978-1-61804-156-2 77\nexist in one single level. For instance, if you feel happiness for 2 days, the level and strength of feeling would not be the same for every moment that you have the same emotion. It means that emotions are more than being represented in 0 and 1. Nowadays, most of research papers present detection methods of emotion whether they exist or not. For example, if the user is happy or not; but it does not define the level of possible happiness. All the eight basic emotions according to the Sanskrit texts and the other sub-emotions are following the level based definitions [8]. Emotions have a fuzzy basis, and a discrete calculation would not be a solution on it.\nThe second problem is that users as human beings may not have only one emotion at a time; they may have different emotions in different levels. This second fact is also ignored in the most of researches, and the current human emotions recognition systems attempt to find only one current emotion and perhaps the strongest emotion at that time [9]. It is very clear that many emotions influence our life style and we are living with the combination of emotions. The happiness at the time of receiving a gift and the happiness at the time being in a theme park can be at a same level, but they are presented in 2 different qualities because the other available emotions are different in those two cases [10].\nThirdly, psychological studies show a difference in human emotional changes pattern based on cultural and language backgrounds. These differences say that a specific emotional pattern which is extracted from a specific area cannot be extended to the other part of the world [11].\nThis paper tries to analyze human emotions based on a fuzzy model which is able to recognize the human emotions in 5 levels and also to estimate the other possible emotions and their levels."}, {"heading": "2 Methodology", "text": "Emotions\u2019 fuzzy model classifies the emotions into 5 different levels from 0 to 4. Zero (0) shows 0% of the emotion or in the other hand, it does not exist, and 4 shows the highest level of that appropriate emotion. Experience Sampling Methodology (ESM) has been used to collect the raw data for modeling classification. PANAS is a standard to find negative or positive emotions of the people [12]. PANAS uses 20 emotions and the seven missed basic emotions were added to this list in our research; and this standard was used to evaluate our system. The list of these 27 emotions is as follows:\nJoy Surprise Excited Enthusias Inspired Active Anticipatio Fear\nUpset Proud Nervous Afraid Anger Acceptanc Strong Irritable\nDetermine Disgust Interested Guilty Alert Attentive Sadness Distresse\nHostile Ashamed Jittery This system was prepared as part of human emotions recognition by using keyboard keystroke dynamics, mouse movement, and touch screen interactions. Prototype software was developed based on Microsoft Windows to collect the required data, and users were prompted to enter their emotions and their level from 0 to 4 every 4 hours.\nAbout 130 people participated in our project to have their emotional states recorded in our system. The people who participated were as below:\nMen: 51% - Average Age: 30.13 Years Old Women: 49% - Average Age: 28.29 Years Old People were originally from: Europe: 18.37% Middle East: 44.18% South East Asia: 13.17% East Asia: 7.75% People were living in: Europe: 27.90% South East Asia: 34.88% East Asia: 16.37% Middle East: 11.62% 45% of people were living in different regions of their own country.\nIn the collected data, men\u2019s emotions (selfreported) were stronger than women\u2019s, or at least they felt them stronger. The strongest emotion was ACTIVE in a range of 3.24 out of 4 and the least one was UNFRIENDLY with the value of 1.62 out of 4. It showed that most of the people thought that they were super active and less unfriendly in their normal life."}, {"heading": "2.1 Analysis of Emotions", "text": "Here, only eight basic emotions were discussed which are Joy, Anticipation, Anger, Disgust, Sadness, Surprise, Fear, and Acceptance.\nHowever, some similar change patterns were found among some emotions. Basically, both negative and positive emotions have similar change patterns, but between those basic emotions, some of\nISBN: 978-1-61804-156-2 78\nthem are very close to each other. For instance Disgust and Anger have a similar change rate pattern with each other, and Sadness is closer to them in comparison with the other emotions. On the other hand, Acceptance and Anticipation have very similar change pattern with each other. As it can be seen, these emotions are in a same group in terms of positive and negative emotions. Table 1 shows a similar change pattern, when the level of Joy is increasing from 0 to 4. Fig.1 also presents the graphed data of table 1.\nFig.1. Emotions change pattern by the term of \u201cJoy\u201d\nConversely, the above values demonstrate the probabilistic of the existence for the other emotions. For example, when Joy is about 50%, it can be estimated that Disgust may exist at the level of 21%, or even Fear at the level of 26% can be possible; but we can be sure that 55% of Fear is unacceptable but Acceptance can be accepted in this level at the same time of 50% of Joy\nThe following 4 tables show the extracted analyzed data from our research based on the growth of some important basic emotions.\nAll above values are between 0 and 4. Later, it is tried to compare emotions changes pattern of people in different regions of the world. As described in the introduction, there are some psychological studies that indicate different emotions\u2019 concepts in different parts of the world [11, 13]. We have used our research data to confirm if the different emotions\u2019 concepts may cause different emotions changes patterns. For this section, 3 regions namely Europe, Middle East and South East Asia were chosen and the same data of the users with the emotion of Joy at the value of 2 or 50% were analyzed. Table 6 shows the classified values by regions.\nFig.2 demonstrates the graphed values in table 6. The emotional pattern of Europe and Middle East are similar, but South East Asia follows a very different pattern in comparison with the other two. This graph proves the psychological studies based on the influences of cultural and language backgrounds on emotions.\nFig.2. Classified graph of Joy \u2013 50% for different regions\nJoy Anticipation Disgust Sadness Surprise Fear Acceptance 2.01 1.42 0.21 0.65 0.59 0.63 1.8 2.31 2 0.86 1 1.62 1.2 2.13 1.85 2.42 1.23 2.09 1.42 1.66 2.42\n2.3 2.1 1.7 1.8 1.4 2 2 1.25 1.62 3 3.25 1.62 0.85 1.87"}, {"heading": "2.2 Fuzzy Human Emotions Recognition", "text": "In order to recognize the emotions, the system was trained and tested by Support Vector Machine (SVM) to recognize the users\u2019 emotions. The above results are now used in the evaluation for multi-level detection of emotions from 0 to 4, and also it is tried to recognize multi emotions at each stage of recognition process. Table 7 shows the final result of recognition after applying the fuzzy logic concept to detect each emotion by SVM in a range of 0 to 4.\nThe following table shows a lower accuracy in recognition of some of multi-level emotions in compare to the other non-fuzzy methods, because the number of available states has been increased to detect the emotion; but the accuracy in the emotion of Nervous has been increased.\nApplication of fuzzy model on human emotions recognition systems represent more natural report on human emotions which includes all possible emotions and their levels and strengths. This report may not be as accurate as single emotion recognition like we had in the classic researches but it provides more reliable result for computer applications."}, {"heading": "2.3 Fuzzy Model on Human Emotions Recognition: Discussion", "text": "The above data and classification were used as a fuzzy model in our human emotions recognition system. The accuracy of the emotions detection was evaluated from 2 different aspects. The first aspect evaluated whether the name of the recognized emotion or emotions are correct or not, and in the second aspect, it evaluated the system by the percentage of detected emotions [14, 15]. For example, consider a user with 2 emotions of Joy \u2013 50% and Fear \u2013 20%. In the first aspect of evaluation, if the system could detect Joy and Fear, evaluation is successfully done; but in the second aspect, not only Joy and Fear should be detected correctly, but also the detected level of the other emotions would be considered in the accuracy of the system [16].\nThis model was tested on human emotions recognition system which was working based on keyboard keystroke dynamics, mouse movements and touch-screen interactions. Support Vector Machine (SVM) was chosen as the system machine learning method.\nAfter testing this fuzzy model on the system, the accuracy of the system from the first aspect increased from 3% to 5% as it was dependent on the emotions. This model estimated other emotions which can be possible in parallel with the other emotions.\nFrom the second aspect of our evaluation, we gained the result from 0% to 16.7% of false positive rate for detecting the emotions level.\nBoth methods and aspects of evaluations for our analyzed data were reliable due to the high accuracy in the first method and low false positive rate for the second method."}, {"heading": "3 Conclusion", "text": "This research proposed a new fuzzy based model through presenting a new solution based on the statistics and probabilistic for human emotions recognition to overcome some of the problems in this research area. This model detected the other possible emotions simultaneously, and worked more naturally by recognition of emotions in terms of levels and not through a discrete name of the emotion. The human emotions recognition system, which this model was implemented on, could gain up to 5% higher accuracy in the detection procedure, and a maximum 16.7% of false positive rate for recognizing the level of the emotions.\nThis model can be extended, improved, and even integrated into different systems. Future research work will be on human emotions recognition by extracted model for each region of the world and then comparing the accuracies and false positive rates of these different regions."}, {"heading": "Acknowledgement", "text": "We thank the students of Universiti Kebangsaan Malaysia (The National University of Malaysia) and Duisburg-Essen University. This research was part of a master\u2019s thesis of Artificial Intelligence in The National University of Malaysia. References: [1] R. Cowie, E. Douglas-Cowie, N. Tsapatsoulis,\nG. Votsis, S. Kollias, W. Fellenz, and J. G.\nISBN: 978-1-61804-156-2 81\nTaylor, \"Emotion recognition in humancomputer interaction,\" Signal Processing Magazine, IEEE, vol. 18, pp. 32-80, 2001.\n[2] C. Epp, M. Lippold, and R. L. Mandryk, \"Identifying emotional states using keystroke dynamics,\" presented at the Proceedings of the 2011 annual conference on Human factors in computing systems, Vancouver, BC, Canada, 2011. [3] Y. Liu, O. Sourina, and M. K. Nguyen, \"Realtime EEG-based Human Emotion Recognition and Visualization,\" 2010, pp. 262-269. [4] M. Milanova and N. Sirakov, \"Recognition of Emotional states in Natural Human-Computer Interaction,\" 2008, pp. 186-191. [5] M. G. Bashir, R. Nagarajan, and D. Hazry, \"Facial emotion detection using GPSO and Lucas-Kanade algorithms,\" 2010. [6] E. C. C. Kao, C. C. Liu, T. H. Yang, C. T. Hsieh, and V. W. Soo, \"Towards Text-based Emotion Detection,\" 2009, pp. 70-74. [7] S. Amarakeerthi, R. Ranaweera, and M. Cohen, \"Speech-Based Emotion Characterization Using Postures and Gestures in CVEs,\" 2010, pp. 72-76. [8] P. E. Griffiths, \"Basic Emotions, Complex Emotions, Machiavellian Emotions,\" Royal Institute of Philosophy Supplement, vol. 52, p. 28, 2003. [9] M. Gendron and L. F. Barrett, \"Reconstructing the Past: A Century of Ideas About Emotion in Psychology,\" The International Society for Research on Emotion vol. 1, p. 24, 2009. [10] C. E. J. Hartel, N. M. Ashkanasy, and W. J. Zerbe, Functionality, Intentionality and Morality, 1st ed. vol. 3: Elsevier, 2007. [11] M. Lewis, J. M. Haviland-Jones, and L. F. Barrett, \"The Cultural Psychology of the Emotions - Ancient and Renewed,\" in Handbook of Emotions, J. H. Richard A. Shweder, Randall Horton, Craig Joseph, Ed., 3rd ed: The Guilford Press, 2010, p. 19. [12] D. Watson, L. A. Clark, and A. Tellegen, \"Development and validation of brief measures of positive and negative affect: The PANAS scales,\" Journal of Personality and Social Psychology, vol. 54, pp. 1063-1070, Jun 1988 1988. [13] D. R. Combs, W. Wohlfahrt, and M. R. Basso, \"Understanding the emotion process: The clinical neuropsychology of emotion: A review of Yana Suchy, 2011. Clinical neuropsychology of emotion,\" Journal of Clinical and Experimental Neuropsychology, vol. 34, pp. 113-116, 2012.\n[14] N. Yusoff and S. Salim, \"SCOUT and affective interaction design: Evaluating physiological signals for usability in emotional processing,\" 2010, pp. V1-201-V1-205. [15] X. Kong and Y. Yang, \"Measuring emotions in interactive contexts,\" 2009, pp. 526-530. [16] E. Mower, M. Mataric, and S. Narayanan, \"A framework for automatic human emotion classification using emotion profiles,\" Audio, Speech, and Language Processing, IEEE Transactions on, pp. 1-1, 2010.\nISBN: 978-1-61804-156-2 82"}], "references": [{"title": "and J", "author": ["R. Cowie", "E. Douglas-Cowie", "N. Tsapatsoulis", "G. Votsis", "S. Kollias", "W. Fellenz"], "venue": "G.  Recent Advances in Electrical and Computer Engineering ISBN: 978-1-61804-156-2  81  Taylor, \"Emotion recognition in humancomputer interaction,\" Signal Processing Magazine, IEEE, vol. 18, pp. 32-80", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2001}, {"title": "and R", "author": ["C. Epp", "M. Lippold"], "venue": "L. Mandryk, \"Identifying emotional states using keystroke dynamics,\" presented at the Proceedings of the 2011 annual conference on Human factors in computing systems, Vancouver, BC, Canada", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Realtime EEG-based Human Emotion Recognition and Visualization,", "author": ["Y. Liu", "O. Sourina", "M.K. Nguyen"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Recognition of Emotional states in Natural Human-Computer Interaction,", "author": ["M. Milanova", "N. Sirakov"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Hazry, \"Facial emotion detection using GPSO and Lucas-Kanade", "author": ["M.G. Bashir", "R. Nagarajan"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Towards Text-based Emotion Detection,", "author": ["E.C.C. Kao", "C.C. Liu", "T.H. Yang", "C.T. Hsieh", "V.W. Soo"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Speech-Based Emotion Characterization Using Postures and Gestures in CVEs,", "author": ["S. Amarakeerthi", "R. Ranaweera", "M. Cohen"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Basic Emotions", "author": ["P.E. Griffiths"], "venue": "Complex Emotions, Machiavellian Emotions,\" Royal Institute of Philosophy Supplement, vol. 52, p. 28", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Reconstructing the Past: A Century of Ideas About Emotion in Psychology,", "author": ["M. Gendron", "L.F. Barrett"], "venue": "The International Society for Research on Emotion vol", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Functionality", "author": ["C.E.J. Hartel", "N.M. Ashkanasy", "W.J. Zerbe"], "venue": "Intentionality and Morality, 1st ed. vol. 3: Elsevier", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "and L", "author": ["M. Lewis", "J.M. Haviland-Jones"], "venue": "F. Barrett, \"The Cultural Psychology of the Emotions - Ancient and Renewed,\" in Handbook of Emotions, J. H. Richard A. Shweder, Randall Horton, Craig Joseph, Ed., 3rd ed: The Guilford Press", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Tellegen, \"Development and validation of brief measures of positive and negative affect: The PANAS scales,", "author": ["D. Watson", "L.A. Clark"], "venue": "Journal of Personality and Social Psychology,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1988}, {"title": "Understanding the emotion process: The clinical neuropsychology of emotion: A review of Yana Suchy", "author": ["D.R. Combs", "W. Wohlfahrt", "M.R. Basso"], "venue": "2011. Clinical neuropsychology of emotion,\" Journal of Clinical and Experimental Neuropsychology, vol. 34, pp. 113-116", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "SCOUT and affective interaction design: Evaluating physiological signals for usability in emotional processing,", "author": ["N. Yusoff", "S. Salim"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Measuring emotions in interactive contexts,", "author": ["X. Kong", "Y. Yang"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "and S", "author": ["E. Mower", "M. Mataric"], "venue": "Narayanan, \"A framework for automatic human emotion classification using emotion profiles,\" Audio, Speech, and Language Processing, IEEE Transactions on, pp. 1-1", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Computer games (entertainments), computer-based tutors (e-learning), machine and system controlling (industrial areas), criminology, computer privacy and security and so on [1].", "startOffset": 173, "endOffset": 176}, {"referenceID": 0, "context": "educational ambiance to deliver more knowledge as possible to students [1, 2].", "startOffset": 71, "endOffset": 77}, {"referenceID": 1, "context": "educational ambiance to deliver more knowledge as possible to students [1, 2].", "startOffset": 71, "endOffset": 77}, {"referenceID": 1, "context": "Some methods like image processing, voice recognition and NLP are time and resource consuming and they need some special circumstances such as availability of video camera (webcam) or microphone, and some other methods require highly technical equipment such as for EEG or heart rate measuring [2].", "startOffset": 294, "endOffset": 297}, {"referenceID": 7, "context": "All the eight basic emotions according to the Sanskrit texts and the other sub-emotions are following the level based definitions [8].", "startOffset": 130, "endOffset": 133}, {"referenceID": 8, "context": "This second fact is also ignored in the most of researches, and the current human emotions recognition systems attempt to find only one current emotion and perhaps the strongest emotion at that time [9].", "startOffset": 199, "endOffset": 202}, {"referenceID": 9, "context": "The happiness at the time of receiving a gift and the happiness at the time being in a theme park can be at a same level, but they are presented in 2 different qualities because the other available emotions are different in those two cases [10].", "startOffset": 240, "endOffset": 244}, {"referenceID": 10, "context": "These differences say that a specific emotional pattern which is extracted from a specific area cannot be extended to the other part of the world [11].", "startOffset": 146, "endOffset": 150}, {"referenceID": 11, "context": "PANAS is a standard to find negative or positive emotions of the people [12].", "startOffset": 72, "endOffset": 76}, {"referenceID": 10, "context": "As described in the introduction, there are some psychological studies that indicate different emotions\u2019 concepts in different parts of the world [11, 13].", "startOffset": 146, "endOffset": 154}, {"referenceID": 12, "context": "As described in the introduction, there are some psychological studies that indicate different emotions\u2019 concepts in different parts of the world [11, 13].", "startOffset": 146, "endOffset": 154}, {"referenceID": 13, "context": "The first aspect evaluated whether the name of the recognized emotion or emotions are correct or not, and in the second aspect, it evaluated the system by the percentage of detected emotions [14, 15].", "startOffset": 191, "endOffset": 199}, {"referenceID": 14, "context": "The first aspect evaluated whether the name of the recognized emotion or emotions are correct or not, and in the second aspect, it evaluated the system by the percentage of detected emotions [14, 15].", "startOffset": 191, "endOffset": 199}, {"referenceID": 15, "context": "In the first aspect of evaluation, if the system could detect Joy and Fear, evaluation is successfully done; but in the second aspect, not only Joy and Fear should be detected correctly, but also the detected level of the other emotions would be considered in the accuracy of the system [16].", "startOffset": 287, "endOffset": 291}, {"referenceID": 0, "context": "References: [1] R.", "startOffset": 12, "endOffset": 15}, {"referenceID": 1, "context": "[2] C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Y.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] P.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] N.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] X.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] E.", "startOffset": 0, "endOffset": 4}], "year": 2013, "abstractText": "This paper discusses a fuzzy model for multi-level human emotions recognition by computer systems through keyboard keystrokes, mouse and touch-screen interactions. This model can also be used to detect the other possible emotions at the time of recognition. Accuracy measurements of human emotions by the fuzzy model are discussed through two methods; the first is accuracy analysis and the second is false positive rate analysis. This fuzzy model detects more emotions, but on the other hand, for some of emotions, a lower accuracy was obtained with the comparison with the non-fuzzy human emotions detection methods. This system was trained and tested by Support Vector Machine (SVM) to recognize the users\u2019 emotions. Overall, this model represents a closer similarity between human brain detection of emotions and computer systems. Key-Words: fuzzy emotions, multi-level emotions, human emotion recognition, human computer interaction.", "creator": "Adobe Acrobat Pro 10.1.0"}}}