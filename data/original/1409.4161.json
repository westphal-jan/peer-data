{"id": "1409.4161", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Sep-2014", "title": "Crowdsourcing Pareto-Optimal Object Finding by Pairwise Comparisons", "abstract": "This is the first study on crowdsourcing Pareto-optimal object finding, which has applications in public opinion collection, group decision making, and information exploration. Departing from prior studies on crowdsourcing skyline and ranking queries, it considers the case where objects do not have explicit attributes and preference relations on objects are strict partial orders. The partial orders are derived by aggregating crowdsourcers' responses to pairwise comparison questions. The goal is to find all Pareto-optimal objects by the fewest possible questions. It employs an iterative question-selection framework. Guided by the principle of eagerly identifying non-Pareto optimal objects, the framework only chooses candidate questions which must satisfy three conditions. This design is both sufficient and efficient, as it is proven to find a short terminal question sequence. The framework is further steered by two ideas---macro-ordering and micro-ordering. By different micro-ordering heuristics, the framework is instantiated into several algorithms with varying power in pruning questions. Experiment results using both real crowdsourcing marketplace and simulations exhibited not only orders of magnitude reductions in questions when compared with a brute-force approach, but also close-to-optimal performance from the most efficient instantiation.", "histories": [["v1", "Mon, 15 Sep 2014 06:38:57 GMT  (539kb)", "http://arxiv.org/abs/1409.4161v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DB", "authors": ["abolfazl asudeh", "gensheng zhang", "naeemul hassan", "chengkai li", "gergely v zaruba"], "accepted": false, "id": "1409.4161"}, "pdf": {"name": "1409.4161.pdf", "metadata": {"source": "CRF", "title": "Crowdsourcing Pareto-Optimal Object Finding by Pairwise Comparisons", "authors": ["Abolfazl Asudeh", "Gensheng Zhang", "Naeemul Hassan", "Chengkai Li", "Gergely V. Zaruba"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n40 9.\n41 61\nv1 [\ncs .A\nI] 1\n5 Se\np 20\n14\nI. INTRODUCTION\nThe growth of user engagement and functionality in crowdsourcing platforms has made computationally challenging tasks unprecedentedly convenient. The subject of our study is one such task\u2014crowdsourcing Pareto-optimal object finding. Consider a set of objects O and a set of criteria C for comparing the objects. An object x\u2208O is Pareto-optimal if and only if x is not dominated by any other object, i.e., \u2204y\u2208O such that y\u227bx. An object y dominates x (denoted y\u227bx) if and only if x is not better than y by any criterion and y is better than x by at least one criterion, i.e., \u2200c\u2208C : x\u2281cy and \u2203c\u2208C : y \u227bc x. If x and y do not dominate each other (i.e., x\u2281y and y\u2281x), we denote it by x\u223cy. The preference (betterthan) relation Pc (also denoted \u227bc) for each c\u2208C is a binary relation subsumed by O\u00d7O, in which a tuple (x, y)\u2208Pc (also denoted x\u227bcy) is interpreted as \u201cx is better than (preferred over) y with regard to criterion c\u201d. Hence, if (x, y)/\u2208Pc (also denoted x\u2281cy), x is not better than y by criterion c. We say x and y are indifferent regarding c (denoted x\u223ccy), if (x, y)/\u2208Pc\u2227(y, x)/\u2208Pc, i.e., \u201cx and y are equally good or incomparable with regard to c.\u201d We consider the setting where each Pc is a strict partial order as opposed to a bucket order [1] or a total order, i.e., Pc is irreflexive (\u2200x : (x, x) /\u2208 Pc) and transitive (\u2200x, y : (x, y)\u2208Pc\u2227(y, z)\u2208Pc\u21d2(x, z)\u2208Pc), which together imply asymmetry (\u2200x, y : (x, y)\u2208Pc \u21d2 (y, x)/\u2208Pc).\nPareto-optimal object finding lends itself to applications in several areas, including public opinion collection, group\ndecision making, and information exploration, exemplified by the following motivating examples.\nExample 1 (Collecting Public Opinion and Group Decision Making). Consider a set of movies O={a,b,c,d,e,f} and a set of criteria C={story, music, acting} (denoted by s, m, a in the ensuing discussion). Fig.1a shows the individual preference relations (i.e., strict partial orders), one per criterion. Each strict partial order is graphically represented as a directed acyclic graph (DAG), more specifically a Hasse diagram. The existence of a simple path from x to y in the DAG means x is better than (preferred to) y by the corresponding criterion. For example, (a, e)\u2208Pm (a\u227bme), i.e., a is better than e by music. (b, d)/\u2208Ps and (d, b)/\u2208Ps; hence b\u223csd. The partial orders define the dominance relation between objects. For instance, movie c dominates d (c\u227bd), because c is preferred than d on story and music and they are indifferent on acting, i.e., c\u227bsd, c\u227bmd, and c\u223cad; a and b do not dominate each other (a\u223cb), since b\u227bsa, a\u227bmb and b\u227baa. Based on the three partial orders, movie b is the only Pareto-optimal object, since no other objects dominate it and every other object is dominated by some object.\nNote that tasks such as the above one may be used in both understanding the public\u2019s preference (i.e., the preference\nrelations are collected from a large, anonymous crowd) and making decisions for a target group (i.e., the preference relations are from a small group of people).\nExample 2 (Information Exploration). Consider a photography enthusiast, Amy, who is drown in a large number of photos she has taken and wants to select a subset of the better ones. She resorts to crowdsourcing for the task, as it has been exploited by many for similar tasks such as photo tagging, location/face identification, sorting photos by (guessed) date, and so on. Particularly, she would like to choose Pareto-optimal photos with regard to color, sharpness and landscape.\nBy definition, the crux of finding Pareto-optimal objects lies in obtaining the preference relations, i.e., the strict partial orders on individual criteria. Through crowdsourcing, the preference relations are derived by aggregating the crowd\u2019s responses to pairwise comparison tasks. Each such comparison between objects x and y by criterion c is a question, denoted x?cy, which has three possible outcomes\u2014x\u227bcy, y\u227bcx, and x\u223ccy, based on the crowd\u2019s answers. An example is as follows.\nExample 3 (Deriving Preference Relations from Pairwise Comparisons by the Crowd). Fig.1b shows the hypothetical results of all 15 pairwise comparisons between the 6 movies in Example 1, by criterion s=story. The outcomes of all comparisons form the crowd\u2019s preference relation on story (the leftmost DAG in Fig.1a). Fig.2 is the screenshot of a question form designed for one such comparison. A crowdsourcer, when facing this question, would make a choice among the three possible answers or skip a question if they do not have enough confidence or knowledge to answer it. Fig.1b shows how many crowdsourcers have selected each answer. For instance, for question a?sf, three people preferred movie a, one person preferred f , and one person is indifferent. By aggregating these answers, it is derived that a is better than f with regard to story, since 60% of the crowdsourcers who responded to the question chose this answer. For question b?sc, the result is b\u223csc, since neither b\u227bsc nor b\u227asc received enough votes. (Assuming a threshold \u03b8=60%, i.e., either b\u227bsc or b\u227asc should have at least 60% of votes, in order to not declare b\u223csc.)\nTo the best of our knowledge, this paper is the first work on crowdsourcing Pareto-optimal object finding. The definition of Pareto-optimal objects follows the concept of Pareto composition of preference relations in [2]. It also resembles the definition of skyline objects on totally-ordered attribute domains (pioneered by [3]) and partially-ordered domains [4], [5], [6], [7]. However, except for [8], previous\nstudies on preference and skyline queries do not use the crowd; they focus on query processing on existing data. On the contrary, we examine how to ask the crowd as few questions as possible in obtaining sufficient data for determining Paretooptimal objects. Furthermore, our work differs from preference and skyline queries (including [8]) in several radical ways:\n\u2022 The preference relation for a criterion is not governed by explicit scores or values on object attributes (e.g., sizes of houses, prices of hotels), while preference and skyline queries on both totally- and partially-ordered domains assumed explicit attribute representation. For many comparison criteria, it is difficult to model objects by explicit attributes, not to mention asking people to provide such values or scores; people\u2019s preferences are rather based on complex, subtle personal perceptions, as demonstrated in Examples 1 and 2. \u2022 Due to the above reason, we request crowdsourcers to perform pairwise comparisons instead of directly providing attribute values or scores. On the contrary, [8] uses the crowd to obtain missing attribute values. Pairwise comparison is extensively studied in social choice and welfare, preferences, and voting. It is known that people are more comfortable and confident with comparing objects than directly scoring them, since it is easier, faster, and less error-prone [9]. \u2022 The crowd\u2019s preference relations are modeled as strict partial orders, as opposed to bucket orders or full orders. This is not only a direct effect of using pairwise comparisons instead of numeric scores or explicit attribute values, but also a reflection of the psychological nature of human\u2019s preferences [10], [2], since it is not always natural to enforce a total or bucket order. Most studies on skyline queries assume total/bucket orders, except for [4], [5], [6], [7] which consider partial orders.\nOur objective is to find all Pareto-optimal objects with as few questions as possible. A brute-force approach will obtain the complete preference relations via pairwise comparisons on all object pairs by every criterion. However, without such exhaustive comparisons, the incomplete knowledge collected from a small set of questions may suffice in discerning all Pareto-optimal objects. Toward this end, it may appear that we can take advantage of the transitivity of object dominance\u2014a cost-saving property often exploited in skyline query algorithms (e.g., [3]) to exclude dominated objects from participating in any future comparison once they are detected. But, we shall prove that object dominance in our case is not transitive (Property 1), due to the lack of explicit attribute representation. Hence, the aforementioned cost-saving technique is inapplicable.\nAiming at Pareto-optimal object finding by a short sequence of questions, we introduce a general, iterative algorithm framework (Sec.III). Each iteration goes through four steps\u2014question selection, outcome derivation, contradiction resolution, and termination test. In the i-th iteration, a question qi=x?cy is selected and its outcome is determined based on crowdsourcers\u2019 answers. On unusual occasions, if the outcome presents a contradiction to the obtained outcomes of other\nquestions, it is changed to the closest outcome such that the contradiction is resolved. Based on the transitive closure of the outcomes to the questions so far, the objects O are partitioned into three sets\u2014O\u221a (objects that must be Pareto-optimal), O\u00d7 (objects that must be non-Pareto optimal), and O? (objects whose Pareto-optimality cannot be fully discerned by the incomplete knowledge so far). When O? becomes empty, O\u221a contains all Pareto-optimal objects and the algorithm terminates. The question sequence so far is thus a terminal sequence.\nThere are a vast number of terminal sequences. Our goal is to find one that is as short as possible. We observe that, for a non-Pareto optimal object, knowing that it is dominated by at least one object is sufficient, and we do not need to find all its dominating objects. It follows that we do not really care about the dominance relation between non-Pareto optimal objects and we can skip their comparisons. Hence, the overriding principle of our question selection strategy is to identify non-Pareto optimal objects as early as possible. Guided by this principle, the framework only chooses from candidate questions which must satisfy three conditions (Sec.III-A). This design is sufficient, as we prove that an empty candidate question set implies a terminal sequence, and vice versa (Proporty 2). The design is also efficient, as we further prove that, if a question sequence contains non-candidate questions, there exists a shorter or equally long sequence with only candidate questions that produces the same O\u00d7, matching the principle of eagerly finding non-Pareto optimal objects (Theorem 1). Moreover, by the aforementioned principle, the framework selects in every iteration such a candidate question x?cy that x is more likely to be dominated by y. The selection is steered by two ideas\u2014macro-ordering and micro-ordering. By using different micro-ordering heuristics, the framework is instantiated into several algorithms with varying power in pruning questions (Sec.IV). We also derive a lower bound on the number of questions required for finding all Pareto-optimal objects (Theorem 2).\nIn summary, this paper makes the following contributions: \u2022 This is the first work on crowdsourcing Pareto-optimal\nobject finding. Prior studies on crowdsourcing skyline queries [8] assumes explicit attribute representation and uses crowd to obtain missing attribute values. We define preference relations purely based on pairwise comparisons and we aim to find all Pareto-optimal objects by as few comparisons as possible. \u2022 We propose a general, iterative algorithm framework (Sec.III) which follows the strategy of choosing only candidate questions that must satisfy three conditions. We prove important properties that establish the advantage of the strategy (Sec.III-A). \u2022 We design macro-ordering and micro-ordering heuristics for finding a short terminal question sequence. Based on the heuristics, the generic framework is instantiated into several algorithms (RandomQ, RandomP, FRQ) with varying efficiency. We also derive a non-trivial lower bound on the number of required pairwise comparison questions. (Sec.IV)\n\u2022 We carried out experiments by simulations to compare the amount of comparisons required by different instantiations of the framework under varying problem sizes. We also investigated two case studies by using human judges and real crowdsourcing marketplace. The results demonstrate the effectiveness of selecting only candidate questions, macroordering, and micro-ordering. When these ideas are stacked together, they use orders of magnitude less comparisons than a brute-force approach. The results also reveal that FRQ is nearly optimal and the lower bound is practically tight, since FRQ gets very close to the lower bound. (Sec.V)"}, {"heading": "II. RELATED WORK", "text": "This is the first work on crowdsourcing Pareto-optimal object finding. There are several recent studies on using crowdsourcing to rank objects and answer group-by, top-k and skyline queries. Crowd-BT [11] ranks objects by crowdsourcing pairwise object comparisons. Polychronopoulos et al. [12] find top-k items in an itemset by asking human workers to rank small subsets of items. Davidson et al. [13] evaluate top-k and group-by queries by asking the crowd to answer type questions (whether two objects belong to the same group) and value questions (ordering two objects). Lofi et al. [8] answer skyline queries over incomplete data by asking the crowd to provide missing attribute values. Table I summarizes the similarities and differences between these studies and our work. The studies on full and top-k ranking [11], [12], [13] do not consider multiple attributes in modeling objects. On the contrary, the concepts of skyline [8] and Pareto-optimal objects (this paper) are defined in a space of multiple attributes. [8] assumes explicit attribute representation. Therefore, they resort to the crowd for completing missing values, while other studies including our work request the crowd to compare objects. Our work considers strict partial orders among objects on individual attributes. Differently, other studies assume a bucket/total order [11], [12], [13] or multiple bucket/total orders on individual attributes [8].\nBesides [11], there were multiple studies on ranking objects by pairwise comparisons, which date back to decades ago as aggregating the preferences of multiple agents has always been a fundamental problem in social choice and welfare [14]. The more recent studies can be categorized into three types: 1) Approaches such as [15], [16], [17] predict users\u2019 object ranking by completing a user-object scoring matrix. Their predications take into account users\u2019 similarities in pairwise comparisons, resembling collaborative filtering [18]. They thus do not consider explicit attribute representation for objects. 2) Approaches such as [19], [20], [21] infer queryspecific (instead of user-specific) ranked results to web search queries. Following the paradigm of learning-to-rank [22], they rank a query\u2019s result documents according to pairwise result comparisons of other queries. The documents are modeled by explicit ranking features. 3) Approaches such as [23], [24], [25], [26], [27] are similar to [11] as they use pairwise comparisons to infer a single ranked list that is neither user-specific nor query-specific. Among them, [24] is special\nin that it also applies learning-to-rank and requires explicit feature representation. Different from our work, none of these studies is about Pareto-optimal objects, since they all assume a bucket/total order among objects; those using learning-to-rank require explicit feature representation, while the rest do not consider multiple attributes. Moreover, except [24], [25], [26], they all assume comparison results are already obtained before their algorithms kick in. In contrast, we aim at minimizing the pairwise comparison questions to ask in finding Pareto-optimal objects."}, {"heading": "III. GENERAL FRAMEWORK", "text": "By the definition of Pareto-optimal objects, the key to finding such objects is to obtain the preference relations, i.e., the strict partial orders on individual criteria. Toward this end, the most basic operation is to perform pairwise comparison\u2014 given a pair of objects x and y and a criterion c, determine whether one is better than the other (i.e., (x, y) \u2208 Pc or (y, x) \u2208 Pc) or they are indifferent (i.e., (x, y) /\u2208 Pc \u2227 (y, x) /\u2208 Pc).\nThe problem of crowdsourcing Pareto-optimal object finding is thus essentially crowdsourcing pairwise comparisons. Each comparison task between x and y by criterion c is presented to the crowd as a question q (denoted x?cy). The outcome to the question (denoted rlt(q)) is aggregated from the crowd\u2019s answers. Given a set of questions, the outcomes thus contain an (incomplete) knowledge of the crowd\u2019s preference relations for various criteria. Fig.2 illustrates the screenshot of one such question (comparing two movies by story) used in our empirical evaluation. We note that there are other viable designs of question, e.g., only allowing the first two choices (x\u227bcy and y\u227bcx). Our work is agnostic to the specific question design.\nGiven n objects and r criteria, a brute-force approach will perform pairwise comparisons on all object pairs by every criterion, which leads to r\u00b7n\u00b7(n\u22121)/2 comparisons. The corresponding question outcomes amount to the complete underlying preference relations. The quadratic nature of the brute-force approach renders it wasteful. The bad news is that, in the worst case, we cannot do better than it. To understand this, consider the scenario where all objects are indifferent by every criterion. If any comparison x?cy is skipped, we cannot determine if x and y are indifferent or if one dominates another.\nIn practice, though, the outlook is much brighter. Since we look for only Pareto-optimal objects, it is an overkill to obtain the complete preference relations. Specifically, for a Pareto-optimal object, knowing that it is not dominated by any object is sufficient, and we do not need to find all the objects dominated by it; for a non-Pareto optimal object, knowing\nthat it is dominated by at least one object is sufficient, and we do not need to find all its dominating objects. Hence, without exhausting all possible comparisons, the incomplete knowledge on preference relations collected from a set of questions may suffice in fully discerning all Pareto-optimal objects.\nOur objective is to find all Pareto-optimal objects with as few questions as possible. By pursuing this goal, we are applying a very simple cost model\u2014the cost of a solution only depends on its number of questions. Although the cost of a task in a crowdsourcing environment may depend on monetary cost, latency and other factors, the number of questions is a generic, platform-independent cost measure and arguably proportionally correlates with the real cost. Therefore, we assume a sequential execution model which asks the crowd an ordered sequence of questions Q = \u3008q1, ..., qn\u3009\u2014it only asks qi+1 after rlt(qi) is obtained. Thereby, we do not consider asking multiple questions concurrently. Furthermore, in discussion of our approach, the focus shall be on how to find a short question sequence instead of the algorithms\u2019 complexity.\nTo find a short sequence, we design a general algorithm framework, as displayed in Fig.3. Alg.1 shows the framework\u2019s pseudo-code. Its execution is iterative. Each iteration goes\nthrough four steps\u2014question selection, outcome derivation, contradiction resolution, and termination test. In the i-th iteration, a question qi=x?cy is selected and presented to the crowd. The question outcome rlt(qi) is derived from the crowd\u2019s aggregated answers. On unusual occasions, if the outcome presents a contradiction to the obtained outcomes of other questions so far, it is changed to the closest outcome to resolve contradiction. By computing R+(Qi), the transitive closure of R(Qi)\u2014the obtained outcomes to questions so far \u3008q1, . . . , qi\u3009, the outcomes to certain questions are derived and such questions will never be asked. Based on R+(Qi), if every object is determined to be either Pareto-optimal or non-Pareto optimal without uncertainty, the algorithm terminates.\nBelow, we discuss outcome derivation and termination test. Sec.III-A examines the framework\u2019s key step\u2014question selection, and Sec.III-B discusses contradiction resolution. Outcome derivation Given a question x?cy, its outcome rlt(x?cy) must be aggregated from multiple crowdsourcers, in order to reach a reliable result with confidence. Particularly, one of three mutually-exclusive outcomes is determined based on k crowdsourcers\u2019 answers to the question:\nrlt(x?cy) =\n\n\n\nx \u227bc y if #x k \u2265 \u03b8 y \u227bc x if #y k\n\u2265 \u03b8 x \u223cc y (x \u2281c y \u2227 y \u2281c x) otherwise\n(1)\nwhere \u03b8 is such a predefined threshold that \u03b8>50%, #x is the number of crowdsourcers (out of k) preferring x over y on criterion c, and #y is the number of crowdsourcers preferring y over x on c. Fig.1b shows the outcomes of all 15 questions according to Equation (1) for comparing movies by story using k=5 and \u03b8=60%. Other conceivable definitions may be used in determining the outcome of x?cy. For example, the outcome may be defined as the choice (out of the three possible choices) that receives the most votes from the crowd. The ensuing discussion is agnostic to the specific definition.\nThe current framework does not consider different levels of confidence on question outcomes. The confidence on the outcome of a question may be represented as a probability value based on the distribution of crowdsourcers\u2019 responses. An interesting direction for future work is to find Paretooptimal objects in probabilistic sense. The confidence may also reflect the crowdsourcers\u2019 quality and credibility [28]. Termination test In each iteration, Alg.1 partitions the objects into three sets by their Pareto-optimality based on the transitive closure of question outcomes so far. If every object\u2019s Pareto-optimality has been determined without uncertainty, the algorithm terminates. Details are as follows.\nDefinition 1 (Transitive Closure of Outcomes). Given a set of questions Q=\u3008q1, ..., qn\u3009, the transitive closure of their outcomes R(Q)= {rlt(q1), ..., rlt(qn)} is R+(Q)={x\u223ccy | x\u223ccy \u2208 R(Q)} \u22c3\n{x\u227bcy | (x\u227bcy \u2208 R(Q)) \u2228 (\u2203 w1,w2,...,wm : w1=x, wm=y \u2227 (\u22000<i<m : wi \u227bc wi+1 \u2208 R(Q))) }.\nIn essence, the transitive closure dictates x\u227bcz without asking the question x?cz, if the existing outcomes R(Q) (and recursively the transitive closure R+(Q)) contains both x\u227bcy\nand y\u227bcz. Based on R+(Q), the objects O can be partitioned into three sets: O\u221a = {x \u2208 O | \u2200y \u2208 O : (\u2203c \u2208 C : x\u227bcy \u2208 R+(Q)) \u2228 (\u2200c \u2208 C : x\u223ccy \u2208 R\n+(Q))}; O\u00d7 = {x \u2208 O | \u2203y \u2208 O : (\u2200c \u2208 C : y\u227bcx \u2208 R+(Q)\u2228 x\u223ccy \u2208 R+(Q)) \u2227 (\u2203c \u2208 C : y\u227bcx \u2208 R\n+(Q))}; O? = O\\(O\u221a \u222aO\u00d7). O\u221a contains objects that must be Pareto-optimal, O\u00d7 contains objects that cannot possibly be Pareto-optimal, and O? contains objects for which the incomplete knowledge R+(Q) is insufficient for discerning their Pareto-optimality. The objects in O? may turn out to be Pareto-optimal after more comparison questions. If the set O? for a question sequence Q is empty, O\u221a contains all Pareto-optimal objects and the algorithm terminates. We call such a Q a terminal sequence, defined below.\nDefinition 2 (Terminal Sequence). A question sequence Q is a terminal sequence if and only if, based on R+(Q), O?=\u2205."}, {"heading": "A. Question Selection", "text": "Given objects O and criteria C, there can be a huge number of terminal sequences. Our goal is to find a sequence as short as possible. As Fig.3 and Alg.1 show, the framework is an iterative procedure of object partitioning based on question outcomes. It can also be viewed as the process of moving objects from O? to O\u221a and O\u00d7. Once an object is moved to O\u221a or O\u00d7, it cannot be moved again. With regard to this process, we make two important observations, as follows.\n\u2022 In order to declare an object x not Pareto-optimal, it is sufficient to just know x is dominated by another object. It immediately follows that we do not really care about the dominance relationship between objects in O\u00d7 and thus can skip the comparisons between such objects. Once we know x\u2208O? is dominated by another object, it cannot be Paretooptimal and is immediately moved to O\u00d7. Quickly moving objects into O\u00d7 can allow us skipping many comparisons between objects in O\u00d7. \u2022 In order to declare an object x Pareto-optimal, it is necessary to know that no object can dominate x. This means we may need to compare x with all other objects including non Pareto-optimal objects. As an extreme example, it is possible for x to be dominated by only a non-Pareto optimal object y but not by any other object (not even the objects dominating y). This is because object dominance based on preference relations is intransitive, which is formally stated in Property 1.\nProperty 1 (Intransitivity of Object Dominance). Object dominance based on the preference relations over a set of criteria is not transitive. Specifically, if x\u227by and y\u227bz, it is not necessarily true that x\u227bz. In other words, it is possible that x\u223cz or even z\u227bx.\nWe show the intransitivity of object dominance by an example. Consider objects O={x,y,z}, criteria C={c1, c2, c3}, and the preference relations in Fig.4. Three dominance relationships violate transitivity: (i) x\u227by (based on x\u227bc1y,\nBased on these observations, the overriding principle of our question selection strategy (shown in Alg.2) is to identify non-Pareto optimal objects as early as possible. At every iteration of the framework (Alg.1), we choose to compare x and y by criterion c (i.e., ask question x?cy) where x?cy belongs to candidate questions. Such candidate questions must satisfy three conditions (Definition 3). There can be many candidate questions. In choosing the next question, by the aforementioned principle, we select such x?cy that x is more likely to be dominated by y. More specifically, we design two ordering heuristics\u2014macro-ordering and micro-ordering. Given the three object partitions O\u221a, O\u00d7 and O?, the macroordering idea is simply that we choose x from O? (required by one of the conditions on candidate questions) and y from O\u221a\u222aO? (if possible) or O\u00d7 (otherwise). The reason is that it is less likely for an object in O\u00d7 to dominate x. Micro-ordering further orders all candidate questions satisfying the macroordering heuristic. In Sec.IV, we instantiate the framework into a variety of solutions with varying power in pruning questions, by using different micro-ordering heuristics.\nDefinition 3 (Candidate Question). Given Q, the set of asked questions so far, x?cy is a candidate question if and only if it satisfies the following conditions:\n(i) The outcome of x?cy is unknown yet, i.e., rlt(x?cy) /\u2208 R+(Q);\n(ii) x must belong to O?; (iii) Based on R+(Q), the possibility of y\u227bx must not be\nruled out yet, i.e., \u2204c\u2032 \u2208 C : x \u227bc\u2032 y \u2208 R+(Q). We denote the set of candidate questions by Qcan. Thus, Qcan = {x?cy | rlt(x?cy) /\u2208 R +(Q) \u2227 x \u2208 O? \u2227 (\u2204c\u2032 \u2208 C : x \u227bc\u2032 y \u2208 R +(Q))}.\nIf no candidate question exists, the question sequence Q is a terminal sequence. The reverse statement is also true, i.e., upon a terminal sequence, there is no candidate question left. This is formalized in the following property.\nProperty 2. Qcan = \u2205 if and only if O? = \u2205.\nProof: It is straightforward that O?=\u2205\u21d2Qcan=\u2205, since an empty O? means no question can satisfy condition (ii). We prove Qcan=\u2205\u21d2O?=\u2205 by proving its equivalent contrapositive O? 6=\u2205\u21d2Qcan 6=\u2205. Assume O? 6=\u2205, i.e., O? contains at least one object x (condition (ii) satisfied). Since x does not belong to O\u221a, there exists at least an object y that may turn out to dominate x (condition (iii) satisfied). Since x is not in O\u00d7, we cannot conclude yet that y dominates x. Hence, there must exist a criterion c for which we do not know the outcome of x?cy yet, i.e., rlt(x?cy) /\u2208 R+(Q) (condition (i) satisfied). The question x?cy would be a candidate question because it satisfies all three conditions. Hence Ocan 6=\u2205.\nQuestions violating the three conditions may also lead to terminal sequences. However, choosing only candidate questions matches our objective of quickly identifying nonPareto optimal objects. Below we justify the conditions.\nCondition (i): This is straightforward. If R(Q) or its transitive closure already contains the outcome of x?cy, we do not ask the same question again.\nCondition (ii): This condition essentially dictates that at least one of the two objects in comparison is from O?. (If only one of them belongs to O?, we make it x.) Given a pair x and y, if neither is from O?, there are three scenarios\u2014 (1) x\u2208O\u221a, y\u2208O\u221a, (2) x\u2208O\u221a, y\u2208O\u00d7 or x\u2208O\u00d7, y\u2208O\u221a, (3) x\u2208O\u00d7, y\u2208O\u00d7. Once we know an object is in O\u221a or O\u00d7, its membership in such a set will never change. Hence, we are not interested in knowing the dominance relationship between objects from O\u221a and O\u00d7 only. In all these three scenarios, comparing x and y is only useful for indirectly determining (by transitive closure) the outcome of comparing other objects. Intuitively speaking, such indirect pruning is not as efficient as direct pruning.\nCondition (iii): This condition requires that, when x?cy is chosen, we cannot rule out the possibility of y dominating x. Otherwise, if y cannot possibly dominate x, the outcome of x?cy cannot help prune x. Note that, in such a case, comparing x and y by c may help prune y, if y still belongs to O? and x may dominate y. Such possibility is not neglected and is covered by a different representation of the same question\u2014 y?cx, i.e., swapping the positions of x and y in checking the\nthree conditions. If it is determined x and y cannot dominate each other, then their further comparison is only useful for indirectly determining the outcome of comparing other objects. Due to the same reason explained for condition (ii), such indirect pruning is less efficient.\nThe following simple Property 3 helps to determine whether y\u227bx is possible: If x is better than y by any criterion, then we can already rule out the possibility of y\u227bx, without knowing the outcome of their comparison by every criterion. This allows us to skip further comparisons between them. Its correctness is straightforward based on the definition of object dominance.\nProperty 3 (Non-Dominance Property). At any given moment, suppose the set of asked questions is Q. Consider two objects x and y for which the comparison outcome is not known for every criterion, i.e., \u2203c such that rlt(x?cy) /\u2208 R+(Q). It can be determined that y\u2281x if \u2203c \u2208 C such that x\u227bcy\u2208 R+(Q).\nIn justifying the three conditions in defining candidate questions, we intuitively explained that indirect pruning is less efficient\u2014if it is known that x does not belong to O? or y cannot possibly dominate x, we will not ask question x?cy. We now justify this strategy theoretically and precisely. Consider a question sequence Q=\u3008q1, . . . , qn\u3009. We use O\u221a(Q), O?(Q), O\u00d7(Q) to denote object partitions according to R+(Q). For any question qi, the subsequence comprised of its preceding questions is denoted Qi\u22121=\u3008q1, . . . , qi\u22121\u3009. If qi was not a candidate question when it was chosen (i.e., after R(Qi\u22121) was obtained), we say it is a non-candidate. The following Theorem 1 states that, if a question sequence contains noncandidate questions, we can replace it by a shorter or equally long sequence without non-candidate questions that produces the same set of dominated objects O\u00d7. Recall that the key to our framework is to recognize dominated objects and move them into O\u00d7 as early as possible. Hence, the new sequence will likely lead to less cost when the algorithm terminates. Hence, it is a good idea to only select among candidate questions.\nTheorem 1. If Q contains non-candidate questions, there exists a question sequence Q\u2032 without non-candidate questions such that |Q\u2032| \u2264 |Q| and O\u00d7(Q\u2032) = O\u00d7(Q).\nProof: We prove by demonstrating how to transform Q into such a Q\u2032. Given any non-candidate question qi=x?cy in Q, we remove it and, when necessary, replace several questions. The decisions and choices are partitioned into the following three mutually exclusive scenarios, which correspond to violations of the three conditions in Definition 3.\nCase (i): qi violates condition (i), i.e., rlt(qi) \u2208 R+(Qi\u22121). We simply remove qi from Q, which does not change O\u00d7, since the transitive closure already contains the outcome.\nCase (ii): qi conforms to condition (i) but violates condition (ii), i.e., rlt(qi) /\u2208 R+(Qi\u22121) and x /\u2208 O?(Qi\u22121). The proof for this case is similar to a subset of the proof for the following case(iii). We omit the complete proof.\nCase (iii): qi conforms to conditions (i) and (ii) but violates condition (iii), i.e., rlt(qi)/\u2208R+(Qi\u22121), x\u2208O?(Qi\u22121), \u2203c\u2032 \u2208 C : x\u227bc\u2032y. There are three possible subcases, as follows.\n(iii-1): rlt(qi)=x\u223ccy. We simply remove qi from Q and thus remove x\u223ccy from R+(Q). (We shall explain one exception, for which we replace qi instead of removing it.) The removal of qi does not change object partitioning and thus does not change O\u00d7, as explained below. The difference between R+(Q) and R(Q) is due to transitivity. Since x\u223ccy does not participate in transitivity, we only need to consider the direct impact of removing x\u223ccy from R+(Q). Therefore, (1) with respect to any object z that is not x or y, x\u223ccy does not have any impact on z since it does not involve z. (2) With regard to x, if x/\u2208O\u00d7(Q), removing x\u223ccy from R+(Q) will not move x into O\u00d7(Q\u2032); if x\u2208O\u00d7(Q), then Q must contain comparisons between x and z6=y such that z\u227bx. (z6=y, because case(iii) violates condition (iii), i.e., y\u227bx is impossible.) Removing x\u223ccy from R+(Q) does not affect the comparisons between z and x and thus does not affect O\u00d7. (3) For y, if y/\u2208O\u00d7(Q), removing x\u223ccy from R+(Q) will not move y into O\u00d7(Q\u2032); if y\u2208O\u00d7(Q), then there are three possible situations\u2014(a) If y\u2208O\u00d7(Qi\u22121), removing x\u223ccy will not move y out of Q\u00d7 and thus will not change Q\u00d7. (b) If y\u2208O?(Qi\u22121) and x\u227by was ruled out before qi, then Q must contain comparisons between y and z6=x such that z dominates y. Removing x\u223ccy from R+(Q) does not affect Q\u00d7 since it does not affect the comparisons between z and y; (c) If y\u2208O?(Qi\u22121) and x\u227by was not ruled out before qi, then we replace qi (instead of removing qi) by y?cx. Note that y?cx and x?cy (i.e., qi) are the same question but different with regard to satisfying the three conditions for candidate questions. Different from qi, y?cx is a candidate question when it is chosen (i.e., with regard to Qi\u22121)\u2014rlt(y?cx)/\u2208R+(Qi\u22121), y\u2208O?(Qi\u22121), x\u227by is not ruled out.\n(iii-2): rlt(qi)=x\u227bcy. We remove qi and replace some questions in Q. Consider S=O\u00d7(Q) \\ O\u00d7(Q\\{qi}), i.e., the objects that would be in O\u00d7(Q) but instead are in O?(Q\\{qi}) due to the removal of x\u227bcy form R+(Q). The question replacements are for maintaining O\u00d7 intact. Fig.5 eases our explanation of this case. Suppose S1={y} \u222a {v | y\u227bcv\u2208R\n+(Q)} and S2={x} \u222a {u | u\u227bcx\u2208R+(Q)}. We can derive that (1) S\u2286S1. The reason is that the outcome rlt(qi)=x\u227bcy may have impact on whether other objects dominate v only if v=y or y\u227bcv, i.e., v\u2208S1. For an object v not in S1, the removal of qi cannot possibly move v from O\u00d7(Q) into O?(Q\\{qi}). (2) \u2200v\u2208S, \u2203u\u2208S2 such that u\u227bv and u\u227bcv. This is because, if there does not exist such a u, removing qi cannot possibly move v from O\u00d7(Q) into O?(Q\\{qi}), which contradicts with v\u2208S.\nAccording to the above results, \u2203w1, ...,wm\u22121,wm such that w1=u,wm=v, \u22000<j<m, wj\u227bcwj+1\u2208R(Q). In order to make\nsure v stays in O\u00d7, we replace the question wm\u22121?cv by v?cu. If removing wm\u22121?cv moves any object from O\u00d7 into O?, we recursively deal with it as we do for qi. Note that v?cu is a candidate question when it succeeds Qi\u22121, since rlt(v?cu) /\u2208 R+(Qi\u22121) (otherwise v does not belong to S), v\u2208O?(Qi\u22121) (again, since v\u2208S), and u\u227bv cannot be ruled out.\n(iii-3): rlt(qi) = y\u227bcx. This case is symmetric to (iii-2) and so is the proof. We thus omit the details."}, {"heading": "B. Resolving Unusual Contradictions in Question Outcomes", "text": "A preference relation can be more accurately derived, if more input is collected from the crowd. However, under practical constraints on budget and time, the limited responses from the crowd (k answers per question) may present two types of contradicting preferences.\n(i) Suppose rlt(x?cy)=x\u227bcy and rlt(y?cz)=y\u227bcz have been derived, i.e., they belong to R(Q). They together imply x\u227bcz, since a preference relation must be transitive. Therefore the question x?cz will not be asked. If the crowd is nevertheless asked to further compare x and z, the result rlt(x?cz) might be possibly z\u227bcx, which presents a contradiction.\n(ii) Suppose rlt(x?cy)=x\u223ccy and rlt(y?cz)=y\u227bcz have been derived from the crowd. If the crowd is asked to further compare x and z, the result rlt(x?cz) might be possibly z\u227bcx. The outcomes y\u227bcz and z\u227bcx together imply y\u227bcx, which contradicts with x\u223ccy. (A symmetric case is rlt(x?cy)=x\u223ccy, rlt(y?cz)=z\u227bcy, and the crowd might respond with rlt(x?cz)=x\u227bcz, which also leads to contradiction with x\u223ccy. The following discussion applies to this symmetric case, which is thus not mentioned again.)\nIn practice, such contradictions are rare, even under just modest number of answers per question (k) and threshold (\u03b8). This is easy to understand intuitively\u2014as long as the underlying preference relation is transitive, the collective wisdom of the crowds will reflect it. We can find indirect evidence of it in [29], [30], which confirmed that preference judgments of relevance in document retrieval are transitive. Our empirical results also directly verified it. We asked Amazon Mechanical Turk workers to compare 10 photos by color, sharpness and landscape, and we asked students at our institution to compare 10 U.S. cities with regard to weather, living expenses, and job opportunities. In both experiments, we asked all possible questions\u2014comparing every pair of objects by every criterion. For each criterion, we considered the graph representing the outcomes of questions, where a directed edge represents \u201cbetter-than\u201d and an undirected edge represents \u201cindifferent\u201d. If there is such a \u201ccycle\u201d that it contains zero or one undirected edge and all its directed edges are in the same direction, the outcomes in the cycle form a contradiction. We adapted depth-first search to detect all elementary cycles. (A cycle is elementary if no vertices in the cycle (except the start/end vertex) appear more than once.) The number of elementary cycles amounts to only 2.9% and 2.2% of the number of question outcomes in the two experiments. These values would be smaller if we had used larger k and \u03b8.\nNevertheless, contradictions still occur. Type (i) contradictions can be prevented by enforcing the following simple Rule 1 to assume transitivity and thus skip certain questions. They will never get into the derived preference relations. In fact, in calculating transitive closure (Definition 1) and defining candidate questions (Sec.III-A), we already apply this rule.\nRule 1 (Contradiction Prevention by Skipping Questions). Given objects x, y, z and a criterion c, if rlt(x?cy)=x\u227bcy and rlt(y?cz)=y\u227bcz, we assume rlt(x?cz)=x\u227bcz and thus will not ask the crowd to further compare x and z by criterion c.\nTo resolve type (ii) contradictions, we enforce the following simple Rule 2.\nRule 2 (Contradiction Resolution by Choosing Outcomes). Consider objects x, y, z and a criterion c. Suppose rlt(x?cy)= x\u223ccy and rlt(y?cz)=y\u227bcz are obtained from the crowd. If rlt(x?cz)=z\u227bcx is obtained from the crowd afterwards, we replace the outcome of this question by x\u223ccz. (Note that we do not replace it by x\u227bcz, since z\u227bcx is closer to x\u223ccz.)"}, {"heading": "IV. MICRO-ORDERING IN QUESTION SELECTION", "text": "At every iteration of Alg.1, we choose a question x?cy from the set of candidate questions. By macro-ordering, when available, we choose a candidate question in which y /\u2208 O\u00d7, i.e., we choose from Q1can. Otherwise, we choose from Q 2 can. The size of Q1can and Q 2 can can be large. Micro-ordering is for choosing from the many candidates. As discussed in Sec.III, in order to find a short question sequence, the overriding principle of our question selection strategy is to identify non-Pareto optimal objects as early as possible. Guided by this principle, we discuss several micro-ordering strategies in this section. Since the strategies are the same for Q1can and Q 2 can, we will simply use the term \u201ccandidate questions\u201d, without distinction between Q1can and Q 2 can.\nA. Random Question (RandomQ) RandomQ, as its name suggests, simply selects a random candidate question. Table II shows an execution of the general framework under RandomQ for Example 1. For each iteration i, the table shows the question outcome rlt(qi). Following the question form x?cy in Definition 3, the object \u201cx\u201d in a question is underlined when we present the question outcome. The column \u201cderived results\u201d displays derived question outcomes by transitive closure (e.g., a\u227bme based on rlt(q7)=d\u227bme and rlt(q10)=a\u227bmd) and derived object dominance (e.g., b\u227bd after q20). The table also shows the object partitions (O\u221a, O? and O\u00d7) when the execution starts and when the partitions are changed after an iteration. Multiple iterations may be presented together if other columns are the same for them.\nAs Table II shows, this particular execution under RandomQ requires 30 questions. When the execution terminates, it finds the only Pareto-optimal object b. This simplest micro-ordering strategy (or rather no strategy at all) already avoids many questions in the brute-force approach. The example clearly demonstrates the benefits of choosing candidate questions only and applying macro-strategy.\nB. Random Pair (RandomP)\nRandomP randomly selects a pair of objects x and y and keeps asking questions to compare them (x?cy or y?cx) until there is no such candidate question, upon which it randomly picks another pair of objects. This strategy echoes our principle of eagerly identifying non-Pareto optimal objects. In order to declare an object x non-Pareto optimal, we must identify another object y such that y dominates x. If we directly compare x and y, it requires comparing them by every criterion in C in order to make sure y\u227bx. By skipping questions according to transitive closure, we do not need to directly compare them by every criterion. However, Property 4 below states that we still need at least |C| questions involving x\u2014some are direct comparisons with y, others are comparisons with other objects which indirectly lead to outcomes of comparisons with y. When there is a candidate question x?cy, it means y may dominate x. In such a case, the fewer criteria remain for comparing them, the more likely y will dominate x. Hence, by keeping comparing the same object pair, RandomP aims at finding more non-Pareto objects by less questions.\nProperty 4. Given a set of criteria C and an object x\u2208O, at least |C| pairwise comparison questions involving x are required in order to find another object y such that y\u227bx.\nProof: By the definition of object dominance, if y\u227bx, then \u2200c\u2208C, either y\u227bcx\u2208R+(Q) or x\u223ccy\u2208R+(Q), and \u2203c\u2208C such that y\u227bcx\u2208R+(Q). Given any particular c, if x\u223ccy\u2208R+(Q), then x\u223ccy\u2208R(Q), i.e., a question x?cy or y?cx belongs to the sequence Q, because indifference of objects on a criterion cannot be derived by transitive closure. If y\u227bcx\u2208R+(Q), then y\u227bcx\u2208R(Q) or \u2203 w1, . . . ,wm\u2208O such that y\u227bcw1\u2208R(Q), . . ., wi\u227bcwi+1\u2208R(Q), . . ., wm\u227bcx\u2208R(Q). Either way, at least one question involving x on each criterion c is required. Thus, it takes at least |C| questions involving x to determine y\u227bx.\nTable III illustrates an execution of RandomP Example 1. The initial two questions are between c and f. Afterwards, it is concluded that c\u223cf by Property 3. Therefore, RandomP moves on to ask 3 questions between a and e. In total, the execution requires 28 questions. Although it is shorter than Table II by\nonly 2 questions due to the small size of the example, it clearly moves objects into O\u00d7 more quickly. (In Table II, O\u00d7 is empty until the 20th question. In Table III, O\u00d7 already has 3 objects after 20 questions.) The experiment results in Sec.V exhibit significant performance gain of RandomP over RandomQ on larger data.\nC. Pair Having the Fewest Remaining Questions (FRQ) Similar to RandomP, once a pair of objects x and y are chosen, FRQ keeps asking questions between x and y until there is no such candidate questions. Different from RandomP, instead of randomly picking a pair of objects, FRQ always chooses a pair with the fewest remaining questions. There may be multiple such pairs. To break ties, FRQ chooses such a pair that x has dominated the fewest other objects and y has dominated the most other objects. Furthermore, in comparing x and y, FRQ orders their remaining questions (and thus criteria) by how likely x is worse than y on the criteria. Below we explain this strategy in more detail.\nSelecting Object Pair Consider a question sequence Qi so far and FRQ is to select the next question Qi+1. We use Cx,y to denote the set of criteria c such that x?cy is a candidate question, i.e., Cx,y={c\u2208C | x?cy\u2208Q1can}. (We assume Q 1 can is not empty. Otherwise, FRQ chooses from Q2can in the same way; cf. Alg.2.) By Definition 3, the outcomes of these questions are unknown, i.e., \u2200c\u2208Cx,y : rlt(x?cy)/\u2208R+(Qi). Furthermore, if any remaining question (whose outcome is unknown) between x and y is a candidate question, then all remaining questions between them are candidate questions. FRQ chooses a pair with the fewest remaining candidate questions, i.e., a pair belonging to S1=argmin(x,y) |Cx,y|.\nThe reason to choose such a pair is intuitive. It requires at least |Cx,y| candidate questions to determine y\u227bx. (The proof would be similar to that of Property 4.) Therefore, min(x,y) |Cx,y| is the minimum number of candidate questions to further ask, in order to determine that an object is dominated, i.e., non-Pareto optimal. Thus, a pair in S1 may lead to a\ndominated object by the fewest questions, matching our goal of identifying non-Pareto optimal objects as soon as possible.\nWe can further justify this strategy in a probabilistic sense. For y\u227bx to be realized, it is necessary that none of the remaining questions has an outcome x\u227bcy, i.e., \u2200c\u2208Cx,y : rlt(x?cy) 6= x\u227bcy. Make the simplistic assumption that every question x?cy has an equal probability p of not having outcome x\u227bcy, i.e., \u2200x?cy\u2208Q1can, P (rlt(x?cy)6=x\u227bcy)=p. Further assuming independence of question outcomes, the probability of satisfying the aforementioned necessary condition is p|Cx,y|. By taking a pair belonging to S1, we have the largest probability of finding a dominated object. We note that, for y\u227bx to be realized, in addition to the above necessary condition, another condition must be satisfied\u2014if \u2204c such that y\u227bcx \u2208 R+(Qi), the outcome of at least one remaining question should be y\u227bcx, i.e., \u2203c\u2208Cx,y : rlt(x?cy)=y\u227bcx. Our informal probability-based analysis does not consider this extra requirement.\nBreaking Ties There can be multiple object pairs with the fewest remaining questions, i.e., |S1|>1. To break ties, FRQ chooses such an x that has dominated the fewest other objects, since it is more likely to be dominated. If there are still ties, FRQ further chooses such a y that has dominated the most other objects, since it is more likely to dominate x. More formally, FRQ chooses a pair belonging to S2={(x,y)\u2208S1 | \u2204(x\u2019,y\u2019)\u2208S1 such that d(x\u2019)>d(x) \u2228 (d(x\u2019)= d(x) \u2227 d(y\u2019)>d(y))}, where the function d(\u00b7) returns the number of objects so far dominated by an object, i.e., \u2200x, d(x) = |{y|x\u227by based on R+(Qi)}|. This heuristic follows the principle of detecting non-Pareto optimal objects as early as possible. Note that S2 may still contain multiple object pairs. In such a case, FRQ chooses an arbitrary pair.\nSelecting Comparison Criterion Once a pair (x,y) is chosen, FRQ has to select a criterion for the next question. FRQ orders the remaining criteria Cx,y based on the heuristic that the sooner it understands y\u227bx will not happen, the lower cost it pays. As discussed before, |Cx,y| questions are required in order to conclude that y\u227bx; on the other hand, only one question (if asked first) can be enough for ruling it out. Consider the case that x is better than y by only one remaining criterion, i.e., \u2203c\u2208Cx,y : rlt(x?cy)=x\u227bcy and \u2200c\u2032\u2208Cx,y, c\u2032 6=c : rlt(x?c\u2032y)=x\u2281c\u2032y. If FRQ asks x?cy after all other remaining questions, it takes |Cx,y| questions to understand y does not dominate x; but if x?cy is asked first, no more questions are necessary, because there will be no more candidate questions in the form of x?cy.\nTherefore, FRQ orders the criteria Cx,y by a scoring function that reflects the likelihood of x\u2019s superiority than y by the corresponding criteria. More specifically, for each c\u2208Cx,y, its score is rc(x,y)=rc(y)+r\u2032c(y)\u2212r\u2032\u2032c(y)\u2212(rc(x)+r\u2032c(x)\u2212r\u2032\u2032c(x)) where rc(y)=|{z | z\u227bcy\u2208R+(Qi)}|, r\u2032c(y)=|{z | y\u223ccz\u2208R\n+(Qi)}|, and r\u2032\u2032c(y)=|{z | y\u227bcz\u2208R+(Qi)}|. In this scoring function, rc(y) is the number of objects preferred over y by criterion c, r\u2032c(y) is the number of objects equally good (or bad) as y by c, and r\u2032\u2032c(y) is the number of objects\nto which y is preferred with regard to c. FRQ asks the remaining questions in decreasing order of the corresponding criteria\u2019s scores. This way, it may find such a question that rlt(x?cy)=x\u227bcy earlier than later.\nTable IV presents the framework\u2019s execution for Example 1, by applying the FRQ policy. In addition to the same columns in Tables II and III, Table IV also includes an extra column to show, at each iteration, the chosen object pair for the next question (x,y) and the set of remaining comparison criteria between them (Cx,y). The criteria in Cx,y are ordered by the aforementioned ranking function r(\u00b7). At the beginning of the execution, the object pair is arbitrarily chosen and the criteria are arbitrarily ordered. In the example, we assume a?sb is chosen as the first question. After q2, FRQ can derive that a\u223cb. Hence, there is no more candidate question between them and FRQ chooses the next pair (a,c). Three questions are asked for comparing them. At the end of q5, multiple object pairs have the fewest remaining questions. By breaking ties, (b,c) is chosen as the next pair, since only c has dominated any object so far. The remaining criteria Cb,c are ordered as {a, s,m}, because ra(b,c)>rs(b,c) and ra(b,c)>rm(b,c). The execution sequence terminates after 17 questions, much shorter than the 30 and 28 questions by RandomQ and RandomP, respectively.\nTo conclude the discussion on micro-ordering, we derive a lower bound on the number of questions required for finding all Pareto-optimal objects (Theorem 2). The experiment results in Sec.V reveal that FRQ is nearly optimal and the lower bound is practically tight, since the number of questions used by FRQ is very close to the lower bound.\nTheorem 2. Given objects O and criteria C, to find all Pareto-optimal objects in O, at least (|O|\u2212k)\u00d7|C|+(k\u22121)\u00d72 pairwise comparison questions are necessary, where k is the number of Pareto-optimal objects in O.\nProof: Suppose the non-Pareto optimal objects are O1 and the Pareto-optimal objects are O2 (O1\u222aO2=O and O1\u2229O2 =\u2205). We first separately consider n1 (the minimum number of questions involving objects in O1) and n2 (the minimum number of questions comparing objects within O2 only).\n(1) By Property 4 (and its proof), for every non-Pareto optimal object x\u2208O1, at least |C| questions involving x are\nrequired. There exists at least an object y such that y\u227bx. The required |C| questions lead to outcome either y\u223ccx or z\u227bcx such that y\u227bc . . . \u227bcz\u227bcx (z can be y) for each c\u2208C. For different x, the |C| questions cannot overlap\u2014for a question with outcome z\u227bcx, the x is different; for a question with outcome y\u223ccx, the same question cannot be part of both the |C| questions for x and the |C| questions for y to detect both as non-Pareto optimal, because it is impossible that x\u227by and y\u227bx. Hence, n1=(|O|\u2212k)\u00d7|C|.\n(2) Given any Pareto-optimal object x\u2208O2, for any other y\u2208O2, either (a) x\u223ccy for all criteria c\u2208C or (b) there exist at least two criteria c1 and c2 such that x\u227bc1y and y\u227bc2x. Among the k\u22121 other objects in O2, suppose ka and kb of them belong to cases (a) and (b), respectively (ka+kb=k\u22121). Under case (a), each of the ka objects requires |C| questions. Under case (b), there must be a question leading to outcome z\u227bc1y, where z=x or x\u227bc1 . . . \u227bc1z\u227bc1y. Similarly, there must be a question with outcome y\u227bc2z such that z=x or y\u227bc2z\u227bc2 . . . \u227bc2x. Therefore, each of the kb objects requires at least 2 questions. Clearly, such required questions for comparing x with the k\u22121 other objects in O2 are all distinct. They are also all different from the questions involving non-Pareto optimal objects (case (1)). Hence, n2=ka\u00d7|C|+kb\u00d72 \u2265 (k\u22121)\u00d72.\nSumming up n1 and n2, a lower bound on the number of required questions is thus (|O|\u2212k)\u00d7|C|+(k\u22121)\u00d72. Note that, when k=0, a trivial, tighter lower bound is |O|\u00d7|C|. (One example in which k=0 is Fig.4.)"}, {"heading": "V. EXPERIMENTS AND CASE STUDIES", "text": "We designed and conducted experiments to compare the efficiency of different instantiations of the general framework under varying problem sizes, by simulations on a large dataset. We also investigated two case studies by using a set of human judges and a real crowdsourcing marketplace."}, {"heading": "A. Efficiency and Scalability Test by Simulation", "text": "In this experiment we studied the efficiency and scalability of various instantiations of the general framework. Given the large number of questions required for such a study, we cannot afford using a real crowdsourcing marketplace. Hence, we performed the following simulation. Each object is an NBA player in a particular year. The objects are compared by 10 criteria, i.e., performance categories such as points, rebounds, assists, etc. We simulated the corresponding 10 preference relations based on the players\u2019 real performance in individual years, as follows. Consider a performance category c and two objects x=(player1, year1) and y=(player2, year2). Suppose x.c>y.c, where x.c is player1\u2019s per-game performance on category c in year1 (similarly for y.c). We generated a uniform random number v in [0, 1]. If v<1\u2212 e\u2212(x.c\u2212y.c), we set x\u227bcy, otherwise we set x\u223ccy. This way, we introduced a perturbation into the preference relations in order to make sure they are partial orders, as opposed to directly using real performance statistics (which would imply bucket orders). Fig.6 shows that the number of Pareto-optimal objects increases by the sizes of\nboth object set O (objects are randomly selected) and criteria set C (the first |C| criteria of the aforementioned 10 criteria).\n1) Effectiveness of candidate questions and macro-ordering: To verify the effectiveness of candidate questions and macro-ordering, we compared five methods\u2014BruteForce, \u2013 CQ\u2013MO, \u2013CQ+MO, +CQ\u2013MO, and +CQ+MO. The notation +/\u2013 before CQ and MO indicates whether a method only selects candidate questions (CQ) and whether it applies the macroordering strategy (MO), respectively. In all these five methods, qualifying questions are randomly selected, i.e., no particular micro-ordering heuristics are applied. For instance, +CQ+MO selects only candidate questions and applies macro-ordering. Hence, it is equivalent to RandomQ. Fig.7 shows the numbers of required pairwise comparisons (in logarithmic scale) for each method, varying by object set size (|O| from 500 to 10, 000 for |C|=4) and criterion set size (|C| from 3 to 10 for |O|=10, 000). The figure clearly demonstrates the effectiveness of both CQ and MO, as taking out either feature leads to significantly worse performance than RandomQ. Particularly, the gap between +CQ\u2013MO and \u2013CQ+MO suggests that choosing only candidate questions has more fundamental impact than macro-ordering. If neither is applied (i.e., \u2013CQ\u2013 MO), the performance is equally poor as that of BruteForce. (\u2013CQ\u2013MO uses slightly less questions than BruteForce, since it can terminate before exhausting all questions. However, the difference is negligible for practical purpose, as their curves overlap under logarithmic scale.)\n2) Effectiveness of micro-ordering: Fig.8 presents the numbers of pairwise comparisons required by different microordering heuristics (RandomQ, i.e., +CQ+MO, RandomP, FRQ) and LowerBound (cf. Theorem 2) under varying sizes of the object set (|O| from 500 to 10, 000 for |C|=4) and the criteria set (|C| from 3 to 10 for |O|=10, 000). In all these instantiations of the general framework, CQ and MO are\napplied. The results are averaged across 30 executions. All these methods outperformed BruteForce by orders of magnitude. (BruteForce is not shown in Fig.8 since it is off scale, but its number can be calculated by equation |C|\u00d7|O|\u00d7(|O|\u2212 1)/2.) For instance, for 5, 000 objects and 4 criteria, the ratio of pairwise comparisons required by even the naive RandomQ to that used by BruteForce is already as low as 0.0048. This clearly shows the effectiveness of CQ and MO, as discussed for Fig.7. The ratios for RandomP and FRQ are further several times smaller (0.00094 and 0.00048, respectively). The big gain by FRQ justifies the strategy of choosing object pairs with the fewest remaining questions. Especially, FRQ has nearly optimal performance, because it gets very close to LowerBound in Fig.8. The small gap between FRQ and LowerBound also indicates that the lower bound is practically tight. The figure further suggests excellent scalability of FRQ as its number of questions grows linearly by both |C| and |O|."}, {"heading": "B. Case Studies", "text": "1) Case Study 1: collecting opinions from a small group of people (cf. Example 1): We asked a small number of students at our institution to compare 10 U.S. cities by overall weather, job opportunities, and living expenses. The 135 possible pairwise comparison questions were partitioned into 15 question forms, each of which contains 9 questions on a criterion. Fig.9 shows one such question. We requested responses from 10 people for each form. Some people skipped various questions, allowed by the \u201cnot sure\u201d option in Fig.9. Eventually we collected at least 6 responses to each question. The question outcomes were derived by setting \u03b8=60% (cf. Equation (1)).\nTable V shows the numbers of questions taken by various methods in this case study, averaged over 30 executions. While the performance gap between different methods is far less than in Sec.V-A, we note that it is due to the very small object set. In fact, based on the question outcomes, there are 4 Pareto-optimal cities out of the 10 cities, which makes it less likely for cities to dominate each other and thus requires more questions. Fig.10 shows the Hasse diagram for representing the\ndominance relation between the cities. 2) Case Study 2: information exploration using a crowdsourcing marketplace (cf. Example 2): This study was conducted in similar manner as Case Study 1. We used a real crowdsourcing marketplace\u2014Amazon Mechanical Turk\u2014 to compare 10 photos of our institution with regard to color, sharpness and landscape. The 135 possible questions were also partitioned into 15 tasks, each containing 9 questions on a criterion. We did not provide the \u201cskip\u201d option, because the questions require no special knowledge. We did basic quality control by including in each task two validation questions that expect certain answers. For instance, one such question asks the crowd to compare a colorful photo and a dull photo by criterion color. A crowdsourcer\u2019s input is discarded if their response to a validation question deviates from our expectation. (5 crowdsourcers failed on this.) The parameters in Equation (1) were set to be k=10 and \u03b8=0.6. (Thus each of the 15 tasks was taken by 10 crowdsourcers that passed the validation.) As Table V shows, the numbers of questions by various methods are similar to those in Case Study 1. Based on the question outcomes, 3 of the 10 photos are Pareto-optimal. Fig.11 shows the Hasse diagram for the photos."}, {"heading": "VI. CONCLUSIONS", "text": "This paper is the first study on how to use crowdsourcing to find Pareto-optimal objects when objects do not have explicit attributes and preference relations are strict partial orders. The partial orders are obtained by pairwise comparison questions to the crowd. It introduces an iterative questionselection framework that is instantiated into different methods by exploiting the ideas of candidate questions, macroordering and micro-ordering. Experiment were conducted by simulations on large object sets and case studies were carried out using both human judges and a real crowdsourcing marketplace. The results exhibited not only orders of magnitude reductions in questions when compared with a brute-force approach, but also close-to-optimal performance from the most efficient method."}], "references": [{"title": "Comparing and aggregating rankings with ties", "author": ["R. Fagin", "R. Kumar", "M. Mahdian", "D. Sivakumar", "E. Vee"], "venue": "PODS, 2004, pp. 47\u201358.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Preference formulas in relational queries", "author": ["J. Chomicki"], "venue": "TODS, 2003. 12  Fig. 11: Hasse diagram for the 10 photos in Case Study 2.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "The skyline operator", "author": ["S. Borzsony", "D. Kossmann", "K. Stocker"], "venue": "ICDE, 2001, pp. 421\u2013430.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2001}, {"title": "Stratified computation of skylines with partially-ordered domains", "author": ["C.-Y. Chan", "P.-K. Eng", "K.-L. Tan"], "venue": "SIGMOD, 2005, pp. 203\u2013214.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "Topologically sorted skylines for partially ordered domains", "author": ["D. Sacharidis", "S. Papadopoulos", "D. Papadias"], "venue": "ICDE, 2009, pp. 1072\u20131083.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Categorical skylines for streaming data", "author": ["N. Sarkas", "G. Das", "N. Koudas", "A.K. Tung"], "venue": "SIGMOD, 2008, pp. 239\u2013250.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Efficient skyline evaluation over partially ordered domains", "author": ["S. Zhang", "N. Mamoulis", "D.W. Cheung", "B. Kao"], "venue": "VLDB, 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Skyline queries in crowdenabled databases", "author": ["C. Lofi", "K. El Maarry", "W.-T. Balke"], "venue": "EDBT, 2013, pp. 465\u2013476.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "A law of comparative judgment", "author": ["L.L. Thurstone"], "venue": "Psychological Review, vol. 34, pp. 273\u2013286, 1927.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1927}, {"title": "Foundations of preferences in database systems", "author": ["W. Kie\u00dfling"], "venue": "VLDB, 2002, pp. 311\u2013322.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2002}, {"title": "Pairwise ranking aggregation in a crowdsourced setting", "author": ["X. Chen", "P.N. Bennett", "K. Collins-Thompson", "E. Horvitz"], "venue": "WSDM, 2013.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Human-powered top-k lists", "author": ["V. Polychronopoulos", "L. de Alfaro", "J. Davis", "H. Garcia-Molina", "N. Polyzotis"], "venue": "WebDB, 2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Using the crowd for top-k and group-by queries", "author": ["S.B. Davidson", "S. Khanna", "T. Milo", "S. Roy"], "venue": "ICDT, 2013, pp. 225\u2013236.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Probabilistic latent preference analysis for collaborative filtering", "author": ["N.N. Liu", "M. Zhao", "Q. Yang"], "venue": "CIKM, 2009, pp. 759\u2013766.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "BPR: Bayesian personalized ranking from implicit feedback", "author": ["S. Rendle", "C. Freudenthaler", "Z. Gantner", "L. Schmidt-Thieme"], "venue": "UAI, 2009.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Inferring users\u2019 preferences from crowdsourced pairwise comparisons: A matrix completion approach", "author": ["J. Yi", "R. Jin", "S. Jain", "A.K. Jain"], "venue": "HCOMP, 2013.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Using collaborative filtering to weave an information tapestry", "author": ["D. Goldberg", "D. Nichols", "B.M. Oki", "D. Terry"], "venue": "CACM, vol. 35, no. 12, 1992.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1992}, {"title": "Learning to rank using gradient descent", "author": ["C. Burges", "T. Shaked", "E. Renshaw", "A. Lazier", "M. Deeds", "N. Hamilton", "G. Hullender"], "venue": "ICML, 2005, pp. 89\u201396.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2005}, {"title": "Adapting ranking SVM to document retrieval", "author": ["Y. Cao", "J. Xu", "T.-Y. Liu", "H. Li", "Y. Huang", "H.-W. Hon"], "venue": "SIGIR, 2006, pp. 186\u2013193.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning to Rank with Nonsmooth Cost Functions", "author": ["C.J.C. Burges", "R. Ragno", "Q.V. Le"], "venue": "NIPS, 2006, pp. 193\u2013200.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning to rank for information retrieval", "author": ["T.-Y. Liu"], "venue": "Foundations and Trends in Information Retrieval, vol. 3, no. 3, pp. 225\u2013331, Mar. 2009.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Noisy sorting without resampling", "author": ["M. Braverman", "E. Mossel"], "venue": "SODA, 2008, pp. 268\u2013276.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "Active ranking using pairwise comparisons", "author": ["K.G. Jamieson", "R.D. Nowak"], "venue": "NIPS, 2011, pp. 2240\u20132248.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Active learning ranking from pairwise preferences with almost optimal query complexity", "author": ["N. Ailon"], "venue": "NIPS, 2011, pp. 810\u2013818.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "An active learning algorithm for ranking from pairwise preferences with an almost optimal query complexity", "author": ["\u2014\u2014"], "venue": "Journal of Machine Learning Research, vol. 13, no. 1, pp. 137\u2013164, Jan. 2012.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "Iterative ranking from pair-wise comparisons", "author": ["S. Negahban", "S. Oh", "D. Shah"], "venue": "NIPS, 2012, pp. 2483\u20132491.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Quality management on amazon mechanical turk", "author": ["P.G. Ipeirotis", "F. Provost", "J. Wang"], "venue": "HCOMP, 2010, pp. 64\u201367.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "The simple scalability of documents", "author": ["M.E. Rorvig"], "venue": "Journal of the American Society for Information Science, vol. 41, no. 8, 1990.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1990}, {"title": "Here or there: Preference judgments for relevance", "author": ["B. Carterette", "P.N. Bennett", "D.M. Chickering", "S.T. Dumais"], "venue": "ECIR, 2008, pp. 16\u201327. 13", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "\u201d We consider the setting where each Pc is a strict partial order as opposed to a bucket order [1] or a total order, i.", "startOffset": 95, "endOffset": 98}, {"referenceID": 1, "context": "The definition of Pareto-optimal objects follows the concept of Pareto composition of preference relations in [2].", "startOffset": 110, "endOffset": 113}, {"referenceID": 2, "context": "It also resembles the definition of skyline objects on totally-ordered attribute domains (pioneered by [3]) and partially-ordered domains [4], [5], [6], [7].", "startOffset": 103, "endOffset": 106}, {"referenceID": 3, "context": "It also resembles the definition of skyline objects on totally-ordered attribute domains (pioneered by [3]) and partially-ordered domains [4], [5], [6], [7].", "startOffset": 138, "endOffset": 141}, {"referenceID": 4, "context": "It also resembles the definition of skyline objects on totally-ordered attribute domains (pioneered by [3]) and partially-ordered domains [4], [5], [6], [7].", "startOffset": 143, "endOffset": 146}, {"referenceID": 5, "context": "It also resembles the definition of skyline objects on totally-ordered attribute domains (pioneered by [3]) and partially-ordered domains [4], [5], [6], [7].", "startOffset": 148, "endOffset": 151}, {"referenceID": 6, "context": "It also resembles the definition of skyline objects on totally-ordered attribute domains (pioneered by [3]) and partially-ordered domains [4], [5], [6], [7].", "startOffset": 153, "endOffset": 156}, {"referenceID": 7, "context": "However, except for [8], previous studies on preference and skyline queries do not use the crowd; they focus on query processing on existing data.", "startOffset": 20, "endOffset": 23}, {"referenceID": 7, "context": "Furthermore, our work differs from preference and skyline queries (including [8]) in several radical ways:", "startOffset": 77, "endOffset": 80}, {"referenceID": 7, "context": "On the contrary, [8] uses the crowd to obtain missing attribute values.", "startOffset": 17, "endOffset": 20}, {"referenceID": 8, "context": "It is known that people are more comfortable and confident with comparing objects than directly scoring them, since it is easier, faster, and less error-prone [9].", "startOffset": 159, "endOffset": 162}, {"referenceID": 9, "context": "This is not only a direct effect of using pairwise comparisons instead of numeric scores or explicit attribute values, but also a reflection of the psychological nature of human\u2019s preferences [10], [2], since it is not always natural to enforce a total or bucket order.", "startOffset": 192, "endOffset": 196}, {"referenceID": 1, "context": "This is not only a direct effect of using pairwise comparisons instead of numeric scores or explicit attribute values, but also a reflection of the psychological nature of human\u2019s preferences [10], [2], since it is not always natural to enforce a total or bucket order.", "startOffset": 198, "endOffset": 201}, {"referenceID": 3, "context": "Most studies on skyline queries assume total/bucket orders, except for [4], [5], [6], [7] which consider partial orders.", "startOffset": 71, "endOffset": 74}, {"referenceID": 4, "context": "Most studies on skyline queries assume total/bucket orders, except for [4], [5], [6], [7] which consider partial orders.", "startOffset": 76, "endOffset": 79}, {"referenceID": 5, "context": "Most studies on skyline queries assume total/bucket orders, except for [4], [5], [6], [7] which consider partial orders.", "startOffset": 81, "endOffset": 84}, {"referenceID": 6, "context": "Most studies on skyline queries assume total/bucket orders, except for [4], [5], [6], [7] which consider partial orders.", "startOffset": 86, "endOffset": 89}, {"referenceID": 2, "context": ", [3]) to exclude dominated objects from participating in any future comparison once they are detected.", "startOffset": 2, "endOffset": 5}, {"referenceID": 7, "context": "Prior studies on crowdsourcing skyline queries [8] assumes explicit attribute representation and uses crowd to obtain missing attribute values.", "startOffset": 47, "endOffset": 50}, {"referenceID": 10, "context": "Crowd-BT [11] ranks objects by crowdsourcing pairwise object comparisons.", "startOffset": 9, "endOffset": 13}, {"referenceID": 11, "context": "[12] find top-k items in an itemset by asking human workers to rank small subsets of items.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] evaluate top-k and group-by queries by asking the crowd to answer type questions (whether two objects belong to the same group) and value questions (ordering two objects).", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8] answer skyline queries over incomplete data by asking the crowd to provide missing attribute values.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "The studies on full and top-k ranking [11], [12], [13] do not consider multiple attributes in modeling objects.", "startOffset": 38, "endOffset": 42}, {"referenceID": 11, "context": "The studies on full and top-k ranking [11], [12], [13] do not consider multiple attributes in modeling objects.", "startOffset": 44, "endOffset": 48}, {"referenceID": 12, "context": "The studies on full and top-k ranking [11], [12], [13] do not consider multiple attributes in modeling objects.", "startOffset": 50, "endOffset": 54}, {"referenceID": 7, "context": "On the contrary, the concepts of skyline [8] and Pareto-optimal objects (this paper) are defined in a space of multiple attributes.", "startOffset": 41, "endOffset": 44}, {"referenceID": 7, "context": "[8] assumes explicit attribute representation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "Differently, other studies assume a bucket/total order [11], [12], [13] or multiple bucket/total orders on individual attributes [8].", "startOffset": 55, "endOffset": 59}, {"referenceID": 11, "context": "Differently, other studies assume a bucket/total order [11], [12], [13] or multiple bucket/total orders on individual attributes [8].", "startOffset": 61, "endOffset": 65}, {"referenceID": 12, "context": "Differently, other studies assume a bucket/total order [11], [12], [13] or multiple bucket/total orders on individual attributes [8].", "startOffset": 67, "endOffset": 71}, {"referenceID": 7, "context": "Differently, other studies assume a bucket/total order [11], [12], [13] or multiple bucket/total orders on individual attributes [8].", "startOffset": 129, "endOffset": 132}, {"referenceID": 10, "context": "Besides [11], there were multiple studies on ranking objects by pairwise comparisons, which date back to decades ago as aggregating the preferences of multiple agents has always been a fundamental problem in social choice and welfare [14].", "startOffset": 8, "endOffset": 12}, {"referenceID": 13, "context": "The more recent studies can be categorized into three types: 1) Approaches such as [15], [16], [17] predict users\u2019 object ranking by completing a user-object scoring matrix.", "startOffset": 83, "endOffset": 87}, {"referenceID": 14, "context": "The more recent studies can be categorized into three types: 1) Approaches such as [15], [16], [17] predict users\u2019 object ranking by completing a user-object scoring matrix.", "startOffset": 89, "endOffset": 93}, {"referenceID": 15, "context": "The more recent studies can be categorized into three types: 1) Approaches such as [15], [16], [17] predict users\u2019 object ranking by completing a user-object scoring matrix.", "startOffset": 95, "endOffset": 99}, {"referenceID": 16, "context": "Their predications take into account users\u2019 similarities in pairwise comparisons, resembling collaborative filtering [18].", "startOffset": 117, "endOffset": 121}, {"referenceID": 17, "context": "2) Approaches such as [19], [20], [21] infer queryspecific (instead of user-specific) ranked results to web search queries.", "startOffset": 22, "endOffset": 26}, {"referenceID": 18, "context": "2) Approaches such as [19], [20], [21] infer queryspecific (instead of user-specific) ranked results to web search queries.", "startOffset": 28, "endOffset": 32}, {"referenceID": 19, "context": "2) Approaches such as [19], [20], [21] infer queryspecific (instead of user-specific) ranked results to web search queries.", "startOffset": 34, "endOffset": 38}, {"referenceID": 20, "context": "Following the paradigm of learning-to-rank [22], they rank a query\u2019s result documents according to pairwise result comparisons of other queries.", "startOffset": 43, "endOffset": 47}, {"referenceID": 21, "context": "3) Approaches such as [23], [24], [25], [26], [27] are similar to [11] as they use pairwise comparisons to infer a single ranked list that is neither user-specific nor query-specific.", "startOffset": 22, "endOffset": 26}, {"referenceID": 22, "context": "3) Approaches such as [23], [24], [25], [26], [27] are similar to [11] as they use pairwise comparisons to infer a single ranked list that is neither user-specific nor query-specific.", "startOffset": 28, "endOffset": 32}, {"referenceID": 23, "context": "3) Approaches such as [23], [24], [25], [26], [27] are similar to [11] as they use pairwise comparisons to infer a single ranked list that is neither user-specific nor query-specific.", "startOffset": 34, "endOffset": 38}, {"referenceID": 24, "context": "3) Approaches such as [23], [24], [25], [26], [27] are similar to [11] as they use pairwise comparisons to infer a single ranked list that is neither user-specific nor query-specific.", "startOffset": 40, "endOffset": 44}, {"referenceID": 25, "context": "3) Approaches such as [23], [24], [25], [26], [27] are similar to [11] as they use pairwise comparisons to infer a single ranked list that is neither user-specific nor query-specific.", "startOffset": 46, "endOffset": 50}, {"referenceID": 10, "context": "3) Approaches such as [23], [24], [25], [26], [27] are similar to [11] as they use pairwise comparisons to infer a single ranked list that is neither user-specific nor query-specific.", "startOffset": 66, "endOffset": 70}, {"referenceID": 22, "context": "Among them, [24] is special", "startOffset": 12, "endOffset": 16}, {"referenceID": 10, "context": "Task Question type Multiple attributes Order among objects (on each attribute) Explicit attribute representation [11] full ranking pairwise comparison no bucket/total order no [12] top-k ranking rank subsets of objects no bucket/total order no [13] top-k ranking and grouping pairwise comparison no bucket/total order no [8] skyline queries missing value inquiry yes bucket/total order yes This work Pareto-optimal object finding pairwise comparison yes strict partial order no", "startOffset": 113, "endOffset": 117}, {"referenceID": 11, "context": "Task Question type Multiple attributes Order among objects (on each attribute) Explicit attribute representation [11] full ranking pairwise comparison no bucket/total order no [12] top-k ranking rank subsets of objects no bucket/total order no [13] top-k ranking and grouping pairwise comparison no bucket/total order no [8] skyline queries missing value inquiry yes bucket/total order yes This work Pareto-optimal object finding pairwise comparison yes strict partial order no", "startOffset": 176, "endOffset": 180}, {"referenceID": 12, "context": "Task Question type Multiple attributes Order among objects (on each attribute) Explicit attribute representation [11] full ranking pairwise comparison no bucket/total order no [12] top-k ranking rank subsets of objects no bucket/total order no [13] top-k ranking and grouping pairwise comparison no bucket/total order no [8] skyline queries missing value inquiry yes bucket/total order yes This work Pareto-optimal object finding pairwise comparison yes strict partial order no", "startOffset": 244, "endOffset": 248}, {"referenceID": 7, "context": "Task Question type Multiple attributes Order among objects (on each attribute) Explicit attribute representation [11] full ranking pairwise comparison no bucket/total order no [12] top-k ranking rank subsets of objects no bucket/total order no [13] top-k ranking and grouping pairwise comparison no bucket/total order no [8] skyline queries missing value inquiry yes bucket/total order yes This work Pareto-optimal object finding pairwise comparison yes strict partial order no", "startOffset": 321, "endOffset": 324}, {"referenceID": 22, "context": "Moreover, except [24], [25], [26], they all assume comparison results are already obtained before their algorithms kick in.", "startOffset": 17, "endOffset": 21}, {"referenceID": 23, "context": "Moreover, except [24], [25], [26], they all assume comparison results are already obtained before their algorithms kick in.", "startOffset": 23, "endOffset": 27}, {"referenceID": 24, "context": "Moreover, except [24], [25], [26], they all assume comparison results are already obtained before their algorithms kick in.", "startOffset": 29, "endOffset": 33}, {"referenceID": 26, "context": "The confidence may also reflect the crowdsourcers\u2019 quality and credibility [28].", "startOffset": 75, "endOffset": 79}, {"referenceID": 2, "context": "Differently, transitivity of object dominance holds in skyline analysis [3].", "startOffset": 72, "endOffset": 75}, {"referenceID": 27, "context": "We can find indirect evidence of it in [29], [30], which confirmed that preference judgments of relevance in document retrieval are transitive.", "startOffset": 39, "endOffset": 43}, {"referenceID": 28, "context": "We can find indirect evidence of it in [29], [30], which confirmed that preference judgments of relevance in document retrieval are transitive.", "startOffset": 45, "endOffset": 49}, {"referenceID": 0, "context": "We generated a uniform random number v in [0, 1].", "startOffset": 42, "endOffset": 48}], "year": 2014, "abstractText": "This is the first study on crowdsourcing Paretooptimal object finding, which has applications in public opinion collection, group decision making, and information exploration. Departing from prior studies on crowdsourcing skyline and ranking queries, it considers the case where objects do not have explicit attributes and preference relations on objects are strict partial orders. The partial orders are derived by aggregating crowdsourcers\u2019 responses to pairwise comparison questions. The goal is to find all Pareto-optimal objects by the fewest possible questions. It employs an iterative question-selection framework. Guided by the principle of eagerly identifying non-Pareto optimal objects, the framework only chooses candidate questions which must satisfy three conditions. This design is both sufficient and efficient, as it is proven to find a short terminal question sequence. The framework is further steered by two ideas\u2014macro-ordering and micro-ordering. By different micro-ordering heuristics, the framework is instantiated into several algorithms with varying power in pruning questions. Experiment results using both real crowdsourcing marketplace and simulations exhibited not only orders of magnitude reductions in questions when compared with a brute-force approach, but also close-to-optimal performance from the most efficient instantiation.", "creator": "gnuplot 4.6 patchlevel 3"}}}