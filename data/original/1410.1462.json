{"id": "1410.1462", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Oct-2014", "title": "Top Rank Optimization in Linear Time", "abstract": "Bipartite ranking aims to learn a real-valued ranking function that orders positive instances before negative instances. Recent efforts of bipartite ranking are focused on optimizing ranking accuracy at the top of the ranked list. Most existing approaches are either to optimize task specific metrics or to extend the ranking loss by emphasizing more on the error associated with the top ranked instances, leading to a high computational cost that is super-linear in the number of training instances. We propose a highly efficient approach, titled TopPush, for optimizing accuracy at the top that has computational complexity linear in the number of training instances. We present a novel analysis that bounds the generalization error for the top ranked instances for the proposed approach. Empirical study shows that the proposed approach is highly competitive to the state-of-the-art approaches and is 10-100 times faster.", "histories": [["v1", "Mon, 6 Oct 2014 17:10:23 GMT  (101kb,D)", "http://arxiv.org/abs/1410.1462v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.IR", "authors": ["nan li", "rong jin", "zhi-hua zhou"], "accepted": true, "id": "1410.1462"}, "pdf": {"name": "1410.1462.pdf", "metadata": {"source": "CRF", "title": "Top Rank Optimization in Linear Time", "authors": ["Nan Li", "Rong Jin", "Zhi-Hua Zhou"], "emails": ["zhouzh@lamda.nju.edu.cn"], "sections": [{"heading": null, "text": "Bipartite ranking aims to learn a real-valued ranking function that orders positive instances before negative instances. Recent efforts of bipartite ranking are focused on optimizing ranking accuracy at the top of the ranked list. Most existing approaches are either to optimize task specific metrics or to extend the ranking loss by emphasizing more on the error associated with the top ranked instances, leading to a high computational cost that is super-linear in the number of training instances. We propose a highly efficient approach, titled TopPush, for optimizing accuracy at the top that has computational complexity linear in the number of training instances. We present a novel analysis that bounds the generalization error for the top ranked instances for the proposed approach. Empirical study shows that the proposed approach is highly competitive to the stateof-the-art approaches and is 10-100 times faster. Key words: bipartite ranking, accuracy at the top, linear computational complexity, convex conjugate, dual problem, Neterov\u2019s method"}, {"heading": "1. Introduction", "text": "Bipartite ranking aims to learn a real-valued ranking function that places positive instances above negative instances. It has attracted much attention because of its applications in several areas such as information retrieval and recommender systems [34, 27]. In the past decades, many ranking methods have been developed for bipartite ranking, and most of them are essentially based on pairwise ranking. These algorithms reduce the ranking problem into a binary classification problem by treating each positive-negative instance pair as a single object to be classified [17,\n\u2217Corresponding author. Email: zhouzh@lamda.nju.edu.cn\nPreprint submitted for review October 7, 2014\nar X\niv :1\n41 0.\n14 62\nv1 [\ncs .L\nG ]\n6 O\nct 2\n01 4\n13, 6, 41, 40, 35, 1, 4]. Since the number of instance pairs can grow quadratically in the number of training instances, one limitation of these methods is their high computational costs, making them not scalable to large datasets.\nSince for applications such as document retrieval and recommender systems, only the top ranked instances will be examined by users, there has been a growing interest in learning ranking functions that perform especially well at the top of the ranked list [8, 4]. In the literature, most of these existing methods can be classified into two groups. The first group maximizes the ranking accuracy at the top of the ranked list by optimizing task specific metrics [18, 23, 24, 42], such as average precision (AP) [44], NDCG [41] and partial AUC [29, 30]. The main limitation of these methods is that they often result in non-convex optimization problems that are difficult to solve efficiently. Structural SVM [39] addresses this issue by translating the non-convexity into an exponential number of constraints. It can still be computationally challenging because it usually requires to search for the most violated constraint at each iteration of optimization. In addition, these methods are statistically inconsistency [38, 23], thus often leading to suboptimal solutions. The second group of methods are based on pairwise ranking. They design special convex loss functions that place more penalties on the ranking errors related to the top ranked instances, for example, by weighting [40] or exploiting special functions such as p-norm [35] and infinite norm [1]. Since these methods are essentially based on pairwise ranking, their computational costs are usually proportional to the number of positive-negative instance pairs, making them unattractive for large datasets.\nIn this paper, we address the computational challenge of bipartite ranking by designing a ranking algorithm, named TopPush, that can efficiently optimize the ranking accuracy at the top. The key feature of the proposed TopPush algorithm is that its time complexity is only linear in the number of training instances. This is in contrast to most existing methods for bipartite ranking whose computational costs depend on the number of instance pairs. Moreover, we develop novel analysis for bipartite ranking. One shortcoming of the existing theoretical studies [35, 1] on bipartite ranking is that they try to bound the probability for a positive instance to be ranked before any negative instance, leading to relatively pessimistic bounds. We overcome this limitation by bounding the probability of ranking a positive instance before most negative instances, and show that TopPush is effective in placing positive instances at the top of a ranked list. Extensive empirical study shows that TopPush is computationally more efficient than most\nranking algorithms, and yields comparable performance as the state-of-the-art approaches that maximize the ranking accuracy at the top.\nThe rest of this paper is organized as follows. Section 2 introduces the preliminaries of bipartite ranking, and addresses the difference between AUC optimization and maximizing accuracy at the top. Section 3 presents the proposed TopPush algorithm and its key theoretical properties. Section 4 gives proofs and technical details. Section 5 summarizes the empirical study, and Section 6 concludes this work with future directions."}, {"heading": "2. Bipartite Ranking: AUC vs Accuracy at the Top", "text": "Let X = {x \u2208 Rd : \u2016x\u2016 \u2264 1} be the instance space. Let S = S+ \u222a S\u2212 be a set of training instances, where S+ = {x+i \u2208 X}mi=1 and S\u2212 = {x \u2212 i \u2208 X}ni=1 include m positive instances and n negative instances independently sampled from distributions P+ and P\u2212, respectively. The goal of bipartite ranking is to learn a ranking function f : X 7\u2192 R that is likely to place a positive instance before most negative ones. In the literature, bipartite ranking has found applications in many domains, and its theoretical properties have been examined by several studies [for example, 2, 7, 22, 28].\nAUC is a commonly used evaluation metric for bipartite ranking [16, 10]. By exploring its equivalence to Wilcoxon-Mann-Whitney statistic [16], many ranking algorithms have been developed to optimize AUC by minimizing the ranking loss defined as\nLrank(f ;S) = 1\nmn m\u2211 i=1 n\u2211 j=1 I ( f(x+i ) \u2264 f(x \u2212 j ) ) , (1)\nwhere I(\u00b7) is the indicator function with I(true) = 1 and 0 otherwise. Other than a few special loss functions such as exponential and logistic loss [35, 22], most of these methods need to enumerate all the positive-negative instance pairs, making them unattractive for large datasets. Various methods have been developed to address this computational challenge. For example, in recent years, [45] and [14] respectively studied online and one-pass AUC optimization .\nIn recent literature, there is a growing interest in optimizing accuracy at the top of the ranked list [8, 4]. Maximizing AUC is not suitable for this goal as indicated by the analysis in [8]. To\naddress this challenge, we propose to maximize the number of positive instances that are ranked before the first negative instance, which is known as positives at the top [35, 1, 4]. We can translate this objective into the minimization of the following loss\nL(f ;S) = 1 m m\u2211 i=1 I ( f(x+i ) \u2264 max1\u2264j\u2264n f(x \u2212 j ) ) . (2)\nwhich computes the fraction of positive instances ranked below the top ranked negative instance. By minimizing the loss in (2), we essentially push negative instances away from the top of the ranked list, leading to more positive ones placed at the top. We note that (2) is fundamentally different from AUC optimization as AUC does not focus on the ranking accuracy at the top. This can be seen from the relationship between the loss functions (1) and (2) as summarized below.\nProposition 1 Let S be a dataset consisting of m positive instances and n negative instances, and f : X 7\u2192 R be a ranking function, we have\nLrank(f ;S) \u2264 L(f ;S) \u2264 min ( nLrank(f ;S), 1 ) . (3)\nThe proof of this proposition is deferred to Section 4.1. According to Proportion 1, we can see if the ranking loss Lrank(f ;S) is greater than 1/n which is common in practice, the loss L(f ;S) can be as large as one, implying that no positive instance is ranked above any negative instance. Surely, this is not what we want, also it indicates that our goal of maximizing positives at the top can not be achieved by AUC optimization, consistent with the theoretical analysis in [8]. Meanwhile, we can find that L(f ;S) is an upper bound over the ranking loss Lrank(f ;S), thus by minimizing L(f ;S), small ranking loss can be expected, benefiting AUC optimization. This constitutes the main motivation of current work.\nTo design practical learning algorithms, we replace the indicator function in (2) with its convex surrogate, leading to the following loss function\nL`(f ;S) = 1 m m\u2211 i=1 ` ( max 1\u2264j\u2264n f(x\u2212j )\u2212 f(x + i ) ) , (4)\nwhere `(\u00b7) is a convex surrogate loss function that is non-decreasing1 and differentiable. Examples of such loss functions include truncated quadratic loss `(z) = [1 + z]2+, exponential loss `(z) = e z,\n1 In this paper, we let `(z) to be non-decreasing for the simplicity of formulating dual problem.\nand logistic loss `(z) = log(1 + ez), etc. In the discussion below, we restrict ourselves to the truncated quadratic loss, even though most of our analysis applies to other loss functions.\nIt is easy to verify that the loss function L`(f ;S) in (4) is equivalent to the loss used in InfinitePush [1] (a special case of P -norm Push [35])\nL`\u221e(f ;S) = max 1\u2264j\u2264n\n1\nm m\u2211 i=1 ` ( f(x\u2212j )\u2212 f(x + i ) ) . (5)\nThe apparent advantage of employing L`(f ;S) instead of L`\u221e(f ;S) is that it only needs to evaluate on m positive-negative instance pairs, whereas the later needs to enumerate all the mn instance pairs. As a result, the number of dual variables induced by L`(f ;S) is n + m, linear in the number of training instances, which is significantly smaller than mn, the number of dual variables induced by L`\u221e(f ;S) [see 1, 33]. It is this difference that makes the proposed algorithm achieve a computational complexity linear in the number of training instances and therefore be more efficient than most state-of-the-art algorithms for bipartite ranking."}, {"heading": "3. TopPush for Optimizing Top Accuracy", "text": "In this section, we first present a learning algorithm to minimize the loss function in (4), and then the computational complexity and performance guarantee for the proposed algorithm."}, {"heading": "3.1. Dual Formulation", "text": "We consider linear ranking function, that is f(x) = w>x, where w \u2208 Rd is the weight vector to be learned. For nonlinear ranking function, we can use kernel methods, and Nystro\u0308m method and random Fourier features can transform the kernelized problem into a linear one, see [43] for more discussions on this topic. As a result, the learning problem is given by the following optimization problem\nmin w\n\u03bb 2 \u2016w\u20162 + 1 m m\u2211 i=1 ` ( max 1\u2264j\u2264n w>x\u2212j \u2212w >x+i ) , (6)\nwhere \u03bb > 0 is a regularization parameter.\nDirectly minimizing the objective in (6) can be challenging because of the max operator in the loss function. We address this challenge by developing a dual formulation for (6). Specifically, given a convex and differentiable function `(z), we can rewrite it in its convex conjugate form as\n`(z) = max \u03b1\u2208\u2126\n\u03b1z \u2212 `\u2217(\u03b1) ,\nwhere `\u2217(\u03b1) is the convex conjugate of `(z) and \u2126 is the domain of dual variable [5]. For example, the convex conjugate of truncated quadratic loss is\n`\u2217(\u03b1) = \u2212\u03b1+ \u03b12/4 with \u2126 = R+ .\nWe note that dual form has been widely used to improve computational efficiency [37] and connect different styles of learning algorithms [20]. Here we exploit this technique to overcome the difficulty caused by max operator. The dual form of (6) is given in the following theorem, whose detailed proof is deferred to section 4.2.\nTheorem 1 Define X+ = (x+1 , . . . ,x + m) > and X\u2212 = (x\u22121 , . . . ,x \u2212 n ) >, the dual problem of the problem in (6) is\nmin (\u03b1,\u03b2)\u2208\u039e\ng(\u03b1,\u03b2) = 1\n2\u03bbm \u2016\u03b1>X+ \u2212 \u03b2>X\u2212\u20162 + m\u2211 i=1 `\u2217(\u03b1i) (7)\nwhere \u03b1 and \u03b2 are dual variables, and the domain \u039e is defined as\n\u039e = { \u03b1 \u2208 Rm+ , \u03b2 \u2208 Rn+ : 1>m\u03b1 = 1>n\u03b2 } . (8)\nLet \u03b1\u2217 and \u03b2\u2217 be the optimal solution to the dual problem in (7). Then, the optimal solution w\u2217 to the primal problem in (6) is given by\nw\u2217 = 1\n\u03bbm\n( a\u2217>X+ \u2212 \u03b2\u2217>X\u2212 ) . (9)\nThe key feature of the dual problem in (7) is that the number of dual variables is m+ n. This is in contrast to the InfinitPush algorithm [1] that introduces mn dual variables. In addition, the objective function in (7) is smooth if the convex conjugate `\u2217(\u00b7) is smooth, which is true for many common loss functions (e.g., truncated quadratic loss, exponential loss and logistic loss). It is well known in the literature of optimization that an O(1/T 2) convergence rate can be achieved if the objective function is smooth, where T is the number of iterations. Surely, this also helps in designing efficient learning algorithm."}, {"heading": "3.2. Linear Time Bipartite Ranking Algorithm", "text": "According to Theorem 1, to learn a ranking function f(w), it is sufficient to learn the dual variables \u03b1 and \u03b2 by solving the problem in (7). For this purpose, we adopt the accelerated gradient method due to its light computation per iteration. Since we are pushing positive instances before the top-ranked negative, we refer the obtained algorithm as TopPush."}, {"heading": "3.2.1. Efficient Optimization", "text": "We choose the Nesterov\u2019s method [32, 31] that achieves an optimal convergence rate O(1/T 2) for smooth objective function. One of the key features of the Nesterov\u2019s method is that besides the solution sequence {(\u03b1k,\u03b2k)}, it also maintains a sequence of auxiliary solutions {(s\u03b1k ; s \u03b2 k)}, which is introduced to exploit the smoothness of the objective function to achieve faster convergence rate. Meanwhile, its step size depends on the smoothness of the objective function, in current work, we adopt the Nemirovski\u2019s line search scheme [31] to estimate the smoothness parameter. Of course, other schemes such as the one developed in [25] can also be used.\nAlgorithm 1 summarizes the steps of the TopPush algorithm. At each iteration, the gradients of the objective function g(\u03b1,\u03b2) can be efficiently computed as\n\u2207\u03b1g(\u03b1,\u03b2) = X+\u03bd>\n\u03bbm + `\u2032\u2217(\u03b1) , \u2207\u03b2g(\u03b1,\u03b2) = \u2212\nX\u2212\u03bd>\n\u03bbm . (10)\nwhere \u03bd = \u03b1>X+ \u2212 \u03b2>X\u2212 and `\u2032\u2217(\u00b7) is the derivative of `\u2217(\u00b7). It should be noted that, the problem in (7) is a constrained optimization problem, and therefore, at each step of gradient mapping, we have to project the dual solution into the domain \u039e (that is, in step 9) to keep them feasible. Below, we discuss how to solve this projection step efficiently."}, {"heading": "3.2.2. Projection Step", "text": "For clear notations, we expand the projection step into the problem\nmin \u03b1\u22650,\u03b2\u22650\n1 2 \u2016\u03b1\u2212\u03b10\u20162 + 1 2 \u2016\u03b2 \u2212 \u03b20\u20162 (11)\ns.t. 1>m\u03b1 = 1 > n\u03b2\nAlgorithm 1 The TopPush Algorithm\nInput: X+ \u2208 Rm\u00d7d, X\u2212 \u2208 Rn\u00d7d, \u03bb, Output: w 1: let t\u22121 = 0, t0 = 1 and L0 = 1\nm+n\n2: initialize \u03b11 = \u03b10 = 0m and \u03b21 = \u03b20 = 0n 3: for k = 0, 1, 2, . . . do 4: set \u03c9k = tk\u22122\u22121 tk\u22121 and Lk = Lk\u22121 5: compute the auxiliary solution:\nsak = \u03b1k + \u03c9k(\u03b1k \u2212\u03b1k\u22121) and s \u03b2 k = \u03b2k + \u03c9k(\u03b2k \u2212 \u03b2k\u22121)\n6: compute the gradient at the auxiliary solution:\ng\u03b1 = \u2207\u03b1g(s\u03b1k , s \u03b2 k) and g\u03b2 = \u2207\u03b2g(s \u03b1 k , s \u03b2 k)\n7: while true do 8: compute \u03b1\u2032k+1 = s \u03b1 k \u2212 1 Lk g\u03b1 and \u03b2 \u2032 k+1 = s \u03b2 k \u2212 1 Lk g\u03b2 9: Projection Step: (by invoking Algorithm 2)\n[\u03b1k+1;\u03b2k+1] = \u03c0\u039e([\u03b1 \u2032 k+1;\u03b2 \u2032 k+1])\n10: if g(\u03b1k+1,\u03b2k+1) \u2264 g(s\u03b1k , s \u03b2 k) + \u2016g\u03b1\u20162+\u2016g\u03b2\u20162 2Lk then 11: break 12: end if 13: Lk = 2Lk 14: end while\n15: update tk = (1 + \u221a 1 + 4t2k\u22121)/2 16: if |g(\u03b1k+1,\u03b2k+1)\u2212 g(\u03b1k,\u03b2k)| < then 17: return w = 1\u03bb\u00b7m(\u03b1 > k+1X + \u2212 \u03b2>k+1X\u2212) 18: end if 19: end for\nwhere \u03b10 and \u03b20 are the solutions to be projected. We note that similar projection problems have been studied in [36, 26] whereas they either have O((m + n) log(m + n)) time complexity or only provide approximate solutions. Instead, based on the following proposition, we provide a method which find the exact solution to (11) in O(n+m) time.\nProposition 2 The optimal solution to the projection problem in (11) is given by\n\u03b1\u2217 = [ \u03b10 \u2212 \u03b3\u2217 ] + and \u03b2\u2217 = [ \u03b20 + \u03b3\u2217 ] + ,\nwhere \u03b3\u2217 is the unique root of function\n\u03c1(\u03b3) = m\u2211 i=1 [ \u03b10i \u2212 \u03b3 ] + \u2212 n\u2211 j=1 [ \u03b20j + \u03b3 ] + . (12)\nThe proof of this proposition is similar to that for [26, Theorem 2], thus omitted here. According to Proposition 2, the key to solving the projection problem is to find the root of \u03c1(\u03b3). Instead of approximating the solution via bisection as in [26], we develop a different scheme to get the exact solution as follows.\nFor a given value of \u03b3, define two index sets\nI(\u03b3) = { i \u2208 [1,m] : \u03b10i > \u03b3 } and J (\u03b3) = { j \u2208 [1, n] : \u03b20j \u2265 \u2212\u03b3 } ,\nthen the function \u03c1(\u03b3) in (12) can be rewrite as \u03c1(\u03b3) = \u2211 i\u2208I(\u03b3) \u03b10i \u2212 \u2211 j\u2208J (\u03b3) \u03b20j \u2212 ( |I(\u03b3)|+ |J (\u03b3)| ) \u03b3 . (13) Also, define\nU = {\u03b10i : 1 \u2264 i \u2264 m} \u222a {\u2212\u03b20j : 1 \u2264 j \u2264 n} ,\nand let u(i) denote its i-th order statistics, that is, u(1) \u2264 u(2) \u2264 . . . ,\u2264 u(|U|). It can be found that for a given k and any \u03b3 in the interval [u(k), u(k+1)), it holds that\nI(\u03b3) = I(u(k)) and J (\u03b3) = J (u(k)) .\nThus, from (13), if the interval [u(k), u(k+1)) contains the root of \u03c1(\u03b3), the root \u03b3 \u2217 can be exactly computed as\n\u03b3\u2217 =\n\u2211 i\u2208I(u(k)) \u03b1 0 i \u2212 \u2211 j\u2208J (u(k)) \u03b2 0 j\n|I(u(k))|+ |J (u(k))| . (14)\nConsequently, the task can be reduced to finding k such that \u03c1(s(k)) > 0 and \u03c1(s(k+1)) \u2264 0.\nInspired by [11], we devise a divide-and-conquer procedure based on a modification of the randomized median finding algorithm [9, Chapter 9], and it is summarized in Algorithm 2. In particular, it maintains a set2 of unprocessed elements from U , whose relationship to an element u we do\n2To make the updating of partial sums efficient, in practice, two sets U\u03b1 and U\u03b2 are respectively maintained\nfor \u03b10 and \u2212\u03b20, and U is their union. Also, the sets G and L are handled in a similar manner.\nnot know. On each round, we partition U into two subsets G and L, which respectively contains the elements in U that are respectively greater and less than the element u that is picked up at random from U . Then, by evaluating the function \u03c1 in (13), we update U to the set (i.e., G or L) containing the needed element and discard the other. The process ends when U is empty. Afterwards, we compute the exact optimal \u03b3\u2217 as (14) and perform projection as described in Proposition 2. In addition, for efficiency issues, along the process we keep track of the partial sums in (13) such that they will be not recalculated. Based on similar analysis of the randomized median finding algorithm, we can obtain Algorithm 2 has expected linear time complexity."}, {"heading": "3.3. Convergence and Computational Complexity", "text": "The theorem below states the convergence of the TopPush algorithm, which follows immediately from the convergence result for the Nesterov\u2019s method [31].\nTheorem 2 Let \u03b1T and \u03b2T be the solution output from the TopPush algorithm after T iterations, we have\ng(\u03b1T ,\u03b2T ) \u2264 min (\u03b1,\u03b2)\u2208\u039e g(\u03b1,\u03b2) +\nprovided T \u2265 O(1/ \u221a ).\nFinally, the computational cost of each iteration is dominated by the gradient evaluation and the projection step. Since the complexity of projection step is O(m+ n) and the cost of computing the gradient is O((m + n)d), the time complexity of each iteration is O((m + n)d). Combining this result with Theorem 2, we have, to find an -suboptimal solution, the total computational complexity of the TopPush algorithm is O((m+n)d/ \u221a ), which is linear in the number of training instances.\nTable 1 compares the computational complexity of TopPush with that of some state-of-the-art ranking algorithms. It is easy to see that TopPush is asymptotically more efficient than the state-of-the-art ranking algorithm3. For instances, it is much more efficient than InfinitePush\n3In Table 1, we report the complexity of SVMpAUCtight in [30], which is more efficient than SVM pAUC in [29]. In\naddition, SVMpAUCtight is used in experiments and we do not distinguish between them in this paper.\nAlgorithm 2 Linear Time Projection\nInput: \u03b10 \u2208 Rm, \u03b20 \u2208 Rn Output: \u03b1\u2217, \u03b2\u2217 1: initialize U\u03b1 = {\u03b10i }mi=1, U\u03b2 = {\u2212\u03b20j }nj=1, and U = U\u03b1 \u222a U\u03b2 2: initialize s\u03b1 = 0, s\u03b2 = 0, n\u03b1 = 0, n\u03b2 = 0 3: while U 6= \u2205 do 4: pick u \u2208 U at random, and use it to partition Ua and Uq:\nG\u03b1 = {\u03b1 \u2208 U\u03b1 : \u03b1 > u} L\u03b1 = {\u03b1 \u2208 U\u03b1 : \u03b1 \u2264 u} G\u03b2 = {\u03b2 \u2208 U\u03b2 : \u03b2 \u2265 u} L\u03b2 = {\u03b2 \u2208 U\u03b2 : \u03b2 < u}\n5: compute \u2206n\u03b1 = |G\u03b1|, \u2206s\u03b1 = \u2211\n\u03b1\u2208G\u03b1 \u03b1 and \u2206n\u03b2 = |L\u03b2|, \u2206s\u03b2 = \u2211\n\u03b2\u2208L\u03b2 \u03b2\n6: let s\u2032 = s\u03b1 + \u2206s\u03b1 + s\u03b2 + \u2206s\u03b2 and n\u2032 = n\u03b1 + \u2206n\u03b1 + n\u03b2 + \u2206n\u03b2 7: if s\u2032 < n\u2032u then 8: update U\u03b1 = L\u03b1 and U\u03b2 = L\u03b2 9: update s\u03b1 = s\u03b1 + \u2206s\u03b1 and n\u03b1 = n\u03b1 + \u2206n\u03b1\n10: else 11: update U\u03b1 = G\u03b1 and U\u03b2 = G\u03b2 12: update s\u03b2 = s\u03b2 + \u2206s\u03b2 and n\u03b2 = n\u03b1 + \u2206n\u03b2 13: end if 14: let U = (U\u03b1 \u222a U\u03b2) \\ {u} 15: end while 16: let \u03b3 = (s\u03b1 + s\u03b2)/(n\u03b1 + n\u03b2)\n17: return \u03b1\u2217 = [ \u03b1\u2212 \u03b3 ] + and \u03b2\u2217 = [ \u03b20 + \u03b3 ] +\nand its sparse extension L1SVIP whose complexity depends on the number of positive-negative instance pairs; compared with SVMRank, SVMMAP and SVMpAUC that handle specific performance metrics via structural-SVM, the linear dependence on the number of training instances makes our proposed TopPush algorithm more appealing, especially for large datasets."}, {"heading": "3.4. Theoretical Guarantee", "text": "We develop theoretical guarantee for the ranking performance of TopPush. In [35, 1], the authors have developed margin-based generalization bounds for the loss function L`\u221e . One limitation with the analysis in [35, 1] is that they try to bound the probability for a positive instance to be ranked before any negative instance, leading to relatively pessimistic bounds. For instance, for the bounds in [35, Theorems 2 and 3], the failure probability can be as large as 1 if the parameter p is large. Our analysis avoids this pitfall by considering the probability of ranking a positive instance before most negative instances.\nTo this end, we first define hb(x,w), the probability for any negative instance to be ranked above x using ranking function f(x) = w>x, as\nhb(x,w) = E x\u2212\u223cP\u2212\n[ I(w>x \u2264 w>x\u2212) ] .\nSince we are interested in whether positive instances are ranked above most negative instances, we will measure the quality of f(x) = w>x by the probability for any positive instance to be ranked below \u03b4 percent of negative instances, that is\nPb(w, \u03b4) = Pr x+\u223cP+\n( hb(x + i ,w) \u2265 \u03b4 ) .\nClearly, if a ranking function achieves a high ranking accuracy at the top, it should have a large percentage of positive instances with ranking scores higher than most of the negative instances, leading to a small value for Pb(w, \u03b4) with little \u03b4. The following theorem bounds Pb(w, \u03b4) for TopPush, whose proof can be found in the supplementary document.\nTheorem 3 Given training data S consisting of m independent samples from P+ and n independent samples from P\u2212, let w\u2217 be the optimal solution to the problem in (6). Assume m \u2265 12 and n t, we have, with a probability at least 1\u2212 2e\u2212t,\nPb(w \u2217, \u03b4) \u2264 L`(w\u2217, S) +O (\u221a (t+ logm)/m ) where \u03b4 = O( \u221a logm/n) and\nL`(w\u2217, S) = 1 m m\u2211 i=1 `( max 1\u2264j\u2264n w\u2217>x\u2212j \u2212w \u2217>x+i )\nis the empirical loss.\nTheorem 3 implies that if the empirical loss L`(w\u2217, S) \u2264 O(logm/m), for most positive instance x+ (i.e., 1\u2212O(logm/m)), the percentage of negative instances ranked above x+ is upper bounded\nby O( \u221a logm/n). We observe that m and n play different roles in the bound. That is, since the empirical loss compares the positive instances to the negative instance with the largest score, it usually grows significantly slower with increasing n. For instance, the largest absolute value of Gaussian random samples grows in log n. Thus, we believe that the main effect of increasing n in our bound is to reduce \u03b4 (decrease at the rate of 1/ \u221a n), especially when n is large. Meanwhile, by increasing the number of positive instances m, we will reduce the bound for Pb(w, \u03b4), and consequently increase the chance of finding positive instances at the top."}, {"heading": "4. Proofs and Technical Details", "text": "In this section, we give all the detailed proofs missing from the main text, along with ancillary remarks and comments."}, {"heading": "4.1. AUC vs. Accuracy at the Top", "text": "We investigate the relationship between AUC and accuracy at the top by their corresponding loss functions, i.e. the ranking loss Lrank in (1) and our loss L in (2). Proof: [of Proposition 1]\nIt is easy to verify that the loss L in (2) is equivalent to\nL\u221e(f ;S) = max 1\u2264j\u2264n\n1\nm m\u2211 i=1 I ( f(x+i ) \u2264 f(x \u2212 j ) ) .\nDefine \u03baj = 1 m \u2211m i=1 I ( f(x+i ) \u2264 f(x \u2212 j ) ) , thus we have \u03baj \u2208 [0, 1], and\nL(f ;S) = L\u221e(f ;S) = max 1\u2264j\u2264n\n\u03baj , Lrank(f ;S) = 1\nn \u2211n j=1 \u03baj .\nBased on the relationship between the mean and the maximum of a set of elements, we can obtain the conclusion."}, {"heading": "4.2. Proof of Theorem 1", "text": "Since `(z) is a convex loss function that is non-decreasing and differentiable, it can be rewritten in its convex conjugate form, that is\n`(z) = max \u03b1\u22650\n\u03b1z \u2212 `\u2217(\u03b1)\nwhere `\u2217(\u03b1) is the convex conjugate of `(z), and hence rewritten the problem in (6) as\nmin w max \u03b1\u22650\n1\nm m\u2211 i=1 \u03b1i ( max 1\u2264j\u2264n w>x\u2212j \u2212w >x+i ) \u2212 1 m m\u2211 i=1 `\u2217(\u03b1i) + \u03bb 2 \u2016w\u20162 , (15)\nwhere \u03b1 = (\u03b11, . . . , \u03b1m) > are dual variables.\nLet p \u2208 Rn and \u2206 = {p : p \u2265 0 and 1>np = 1} be the standard n-simplex, we have\nmax 1\u2264j\u2264n w>x\u2212j = max p\u2208\u2206 n\u2211 j=1 pjw >x\u2212j . (16)\nBy substituting (16) into (15), the optimization problem becomes\nmin w max \u03b1\u22650,p\u2208\u2206\n1\nm n\u2211 j=1 pj m\u2211 i=1 \u03b1iw >x\u2212j \u2212 1 m m\u2211 i=1 \u03b1iw >x+i \u2212 1 m m\u2211 i=1 `\u2217(\u03b1i) + \u03bb 2 \u2016w\u20162. (17)\nBy defining \u03b2j = pj \u2211m i=1 \u03b1i and then using variable replacement, (17) can be equivalently rewritten as\nmin w max \u03b1\u22650,\u03b2\u22650\n1\nm  n\u2211 j=1 \u03b2jw >x\u2212j \u2212 m\u2211 i=1 \u03b1iw >x+i \u2212 1 m m\u2211 i=1 `\u2217(\u03b1i) + \u03bb 2 \u2016w\u20162\ns.t. 1>m\u03b1 = 1 > n\u03b2 , (18)\nwhere \u03b2 = [\u03b21, . . . , \u03b2n] > are new variables, the constraint p \u2208 \u2206 is replaced with the \u03b2 \u2265 0, and the equality constraint 1>m\u03b1 = 1 > n\u03b2 to keep two problems equivalent.\nSince the objective of (18) is convex in w, and jointly concave in \u03b1 and \u03b2, also its feasible domain is convex; hence it satisfies the strong max-min property [5], the min and max can be swapped. After swapping min and max, we first consider the inner minimization subproblem over w, that is\nmin w\n1\nm n\u2211 j=1 \u03b2jw >x\u2212j \u2212 1 m m\u2211 i=1 \u03b1iw >x+i + \u03bb 2 \u2016w\u20162 ,\nwhere 1m \u2211m i=1 `\u2217(ai) is omitted since it does not depend on w. This is an unconstrained quadratic programming problem, whose solution is\nw\u2217 = 1\n\u03bbm (a>X+ \u2212 \u03b2>X\u2212) ,\nand the minimal value is given as\n\u2212 1 2\u03bbm2 \u2016a>X+ \u2212 \u03b2>X\u2212\u20162 .\nThen, by considering the maximization over \u03b1 and \u03b2, we can obtain the conclusion of Theorem 1 (after multiplying the objective function with m)."}, {"heading": "4.3. Proof of Theorem 3", "text": "For the convenience of analysis, we consider the constrained version of the optimization problem in (6), that is\nmin w\u2208W L`(w;S) = 1 m m\u2211 i=1 ` ( max 1\u2264j\u2264n w>x\u2212j \u2212w >x+i ) (19)\nwhere W = {w \u2208 Rd : \u2016w\u2016 \u2264 \u03c1} is a domain and \u03c1 > 0 specifies the size of the domain that plays similar role as the regularization parameter \u03bb in (6).\nFirst, we denote G as the Lipschitz constant of the truncated quadratic loss `(z) on the domain [\u22122\u03c1, 2\u03c1], and define the following two functions based on `(z), i.e.,\nh`(x,w) = E x\u2212\u223cP\u2212\n[ `(w>x\u2212 \u2212w>x) ] and P`(w, \u03b4) = Pr\nx+\u223cP+\n( h`(x + i ,w) \u2265 \u03b4 ) .\nThe lemma below relates the empirical counterpart of P` with the loss L`.\nLemma 1 With a probability at least 1\u2212 e\u2212t, for any w \u2208 W, we have\n1\nm m\u2211 i=1 I ( h`(x + i ,w) \u2265 \u03b4 ) \u2264 L`(w, S) ,\nwhere\n\u03b4 = 4G(\u03c1+ 1)\u221a\nn +\n5\u03c1(t+ logm)\n3n + 2G\u03c1\n\u221a 2(t+ logm)\nn . (20)\nProof: For any w \u2208 W, we define two instance sets by splitting S+, that is\nA(w) = { x+i : w\n>x+i > max j\u2208[n]\nw>x\u2212j + 1 } , B(w) = { x+i : w\n>x+i \u2264 max j\u2208[n]\nw>x\u2212j + 1 } .\nFor x+i \u2208 A(w), we define\n\u2016P \u2212 Pn\u2016W = sup \u2016w\u2016\u2264\u03c1 \u2223\u2223\u2223\u2223\u2223\u2223h`(x+i ,w)\u2212 1n n\u2211 j=1 `(w>x\u2212j \u2212w >x+i ) \u2223\u2223\u2223\u2223\u2223\u2223 . Using the Talagrand\u2019s inequality and in particular its variant (specifically, Bousquet bound) with improved constants derived in [3] [see also 21, Chapter 2], we have, with probability at least 1\u2212 e\u2212t,\n\u2016P \u2212 Pn\u2016W \u2264 E \u2016P \u2212 Pn\u2016W + 2t\u03c1\n3n +\n\u221a 2t\nn\n( \u03c32P (W) + 2E\u2016P \u2212 Pn\u2016W ) . (21)\nWe now bound each item on the right hand side of (21). First, we bound E\u2016Pn \u2212 P\u2016W as\nE\u2016P \u2212 Pn\u2016W = 2\nn E  sup \u2016w\u2016\u2264\u03c1 n\u2211 j=1 \u03c3j`(w >(x\u2212j \u2212 x + i ))  \u2264 4G\nn E  sup \u2016w\u2016\u2264\u03c1 n\u2211 j=1 \u03c3j(w >(x\u2212j \u2212 x + i ))  \u2264 4G\u03c1\u221a n , (22)\nwhere \u03c3j \u2019s are Rademacher random variables, the fist inequality utilizes the contraction property of Rademacher complexity, and the last follows from Cauchy-Schwarz inequality and Jensen\u2019s inequality. Next, we bound \u03c32P (W), that is,\n\u03c32P (W) = sup \u2016w\u2016\u2264\u03c1 h2` (x,w) \u2264 4G2\u03c12 . (23)\nBy putting (22) and (23) into (21) and using the fact that\n1 n n\u2211 j=1 `(w>(x\u2212j \u2212 x + i )) = 0 for x + i \u2208 A(w),\nwe thus have, with probability 1\u2212 e\u2212t,\n|h`(x+i ,w)| \u2264 \u2016P \u2212 Pn\u2016W \u2264 4G\u03c1\u221a n + 2t\u03c1 3n +\n\u221a 2t\nn\n( 4G2\u03c12 +\n8G\u03c1\u221a n ) \u2264 4G\u03c1\u221a\nn +\n2t\u03c1 3n + 2G\u03c1\n\u221a 2t\nn + 4G\u221a n + t\u03c1 n\n\u2264 4G(\u03c1+ 1)\u221a n + 5t\u03c1 3n + 2G\u03c1\n\u221a 2t\nn .\nUsing the union bound over all x+i \u2019s, we obtain\nmax x+i \u2208A(w)\nh`(x + i ,w) \u2264 \u03b4 ,\nwhere \u03b4 is in (20). Thus, with probability 1\u2212 e\u2212t, it follows\n\u2211 x+i \u2208A(w) I ( h`(x + i ,w) \u2265 \u03b4 ) = 0 .\nTherefore, we can obtain the conclusion based on the fact |B(w)| \u2264 mL`(w, S).\nBased on Lemma 1, we are at the position to prove Theorem 3.\nProof: [of Theorem 3] Let S(W, \u03b5) be a proper \u03b5-net of W and N(\u03c1, \u03b5) be the corresponding covering number. According to standard result, we have\nlogN(\u03c1, \u03b5) \u2264 d log(9\u03c1/\u03b5) .\nBy using concentration inequality and union bound over w\u2032 \u2208 S(W, \u03b5), we have, with probability at least 1\u2212 e\u2212t,\nsup w\u2032\u2208S(W,\u03b5)\nP`(w \u2032, \u03b4)\u2212 1\nm m\u2211 i=1 I(h`(x+i ,w \u2032) \u2265 \u03b4) \u2264\n\u221a 2(t+ d log(9\u03c1/\u03b5))\nm . (24)\nLet d = x\u2212\u2212x+ and \u03b5 = 1 2 \u221a m . For w\u2217 \u2208 W, there exists w\u2032 \u2208 S(W, \u03b5) such that \u2016w\u2032\u2212w\u2217\u2016 \u2264 \u03b5, it holds that\nI(w\u2217>d \u2265 0) = I(w\u2032>d \u2265 (w\u2032 \u2212w\u2217)>d) \u2264 I(w\u2032>d \u2265 \u2212 1\u221a m ) \u2264 2`(w\u2032>d) .\nwhere the last step is based on `(\u00b7) is non-decreasing and `(\u22121/ \u221a m) \u2265 12 if m \u2265 12 . We thus have hb(x +,w\u2217) \u2264 2h`(x+,w\u2032) and therefore Pb(w\u2217, \u03b4) \u2264 P`(w\u2032, \u03b4/2).\nAs a consequence, from (24), Lemma 1 and the fact\nL`k(w\u2032, S) \u2264 L`k(w, S) + G\u03c1\u221a m ,\nwe have, with probability at least 1\u2212 2e\u2212t,\nPb(w \u2217, \u03b4) \u2264 L`k(w\u2217, S) + G\u03c1\u221a m +\n\u221a 2t+ 2d log(9\u03c1) + d logm\nm ,\nwhere \u03b4 is as defined in (20), and the conclusion follows by hiding constants."}, {"heading": "5. Experiments", "text": "To evaluate the performance of the proposed TopPush algorithm, we conduct a set of experiments on real-world datasets."}, {"heading": "5.1. Settings", "text": "Table 2 (left column) summarizes the datasets used in our experiments. Some of them were used in previous studies [1, 33, 4], and others are larger datasets from different domains. For example, diabetes is a medical task, news20-forsale is on text classification, spambase is about email spam filtering, and nslkdd is a network intrusion dataset. It should be noted that news20-forsale is transformed from the news20 dataset by treating forsale as positive class and others as negative. All these datasets are publicly available4.\nWe compare TopPush with state-of-the-art ranking algorithms that focus on accuracy at the top, including SVMMAP [44], SVMpAUC [30] with \u03b1 = 0 and \u03b2 = 1/n, AATP [4] and InfinitePush [1]. In addition, since the bipartite ranking problem can be solved as a binary classification problem, logistic regression (LR) which is shown to be consistent with bipartite ranking [22] and costsensitive SVM (cs-SVM) that addresses imbalance class distribution by introducing different misclassification costs are compared. Also, for completeness, SVMRank [19] for AUC optimization are included in the comparison. We implement TopPush and InfinitePush using MATLAB,\n4These datasets are available at http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets and http://\nnsl.cs.unb.ca/NSL-KDD/ .\nimplement AATP using CVX [15] as in [4], and use LIBLINEAR [12] for LR and cs-SVM, and use the codes shared by the authors of the original works for other algorithms. It should be noted that binary classification algorithms LR and cs-SVM implemented by LIBLINEAR are of state-of-the-art efficiency.\nIn experiments, we measure the accuracy at the top of the ranked list by several commonly used metrics: (i) positives at the top (Pos@Top) [1, 33, 4], which is defined as the fraction of positive instances ranked above the top-ranked negative instance, (ii) average precision (AP) and (iii) normalized DCG scores (NDCG). In addition, ranking performance in terms of AUC are also reported.\nOn each dataset, experiments are run for thirty trials. In each trial, the dataset is randomly divided into two subsets: 2/3 for training and 1/3 for test. For all algorithms in comparison, we set the precision parameter to 10\u22124, choose other parameters by a 5-fold cross validation (based on the average value of Pos@Top) on training set, and evaluate the performance on test set. In detail, the regularization parameter \u03bb or C is chosen from {10\u22123, 10\u22122, . . . , 103}. For cs-SVM, the misclassification cost for positive instances is chosen from {10\u22123, 10\u22122, . . . , 103}. For AATP, the parameter \u03c4 is from {2\u22125, 2\u22124, . . . , 1} \u00d7 mm+n , where m and n are the number of positive and negative instances respectively. The intervals are extended if the best parameter is on the boundary. Finally, averaged results over thirty trails are reported. All experiments are run on a workstation with two Intel Xeon E7 CPUs and 16G memory."}, {"heading": "5.2. Results", "text": "In Table 2, we report the performance of the algorithms in comparison, where the statistics of testbeds are included in the first column of the table. For better comparison between the performance of TopPush and baselines, pairwise t-tests at the significance level of 0.9 are performed and results are marks \u201c\u2022 / \u25e6\u201d in Table 2 when they are statistically significantly worse/better than TopPush. When an evaluation task that evaluates one algorithm on a dataset, including parameter selection, training and testing, can not be completed in two weeks, it will be stopped automatically, and no result will be reported. This is why some algorithms are missing from the table for certain datasets, especially for those large datasets.\nWe can see from Table 2 that TopPush, LR and cs-SVM succeed to finish the evaluation on all datasets (even the largest datasets url). In contrast, SVMRank, SVMRank and SVMpAUC fail to complete the task in time for several large datasets. InfinitePush and AATP have the worst scalability: they are only able to finish the smallest dataset diabetes, this is easy to understand since InfinitePush needs to solve an optimization problem with mn variables and AATP needs to solve m + n quadratic program problems. We thus find that overall, the proposed TopPush algorithm scales well to large datasets."}, {"heading": "5.2.1. Ranking Performance", "text": "In terms of evaluation metric Pos@Top, we find that TopPush yields similar performance as InfinitePush and AATP, and performs significantly better than the other baselines including LR and cs-SVM, SVMRank, SVMMAP and SVMpAUC. This is consistent with the design of TopPush that aims to maximize the accuracy at the top of the ranked list. Since the loss function optimized by InfinitePush and AATP are similar as that for TopPush, it is not surprising that they yield similar performance. The key advantage of using the proposed algorithm versus InfinitePush and AATP is that it is computationally more efficient and scales well to large datasets. In terms of AP and NDCG, we observe that TopPush yield similar, if not better, performance as the state-of-the-art methods, such as SVMMAP and SVMpAUC, that are designed to optimize these metrics. Overall, we can conclude that TopPush is effective in optimizing the ranking accuracy for the top ranked instances.\nMeanwhile, we can see that TopPush achieves similar AUC values with on most datasets (only worse than SVMRank that is specially designed for AUC optimization on three datasets, but their differences are not large). This can be understood by Proposition 1, which shows that the loss function (2) is a upper bound over the ranking loss, and TopPush which minimizes (2) can also achieve a small ranking loss and hereafter a good AUC."}, {"heading": "5.2.2. Training Efficiency", "text": "To evaluate computational efficiency, we set the parameters of different algorithms to be the values that are selected by cross-validation, and run these algorithms on full datasets that include both training and testing sets. Table 2 summarizes the training time of different algorithms. From the\nresults, we can see that TopPush is faster than state-of-the-art ranking methods on most datasets. In fact, the training time of TopPush is even similar to that of LR and cs-SVM implemented by LIBLINEAR. Since the time complexity of learning a binary classification model is usually linear in the number of training instances, this result implicitly suggests a linear time complexity for the proposed algorithm."}, {"heading": "5.2.3. Scalability", "text": "We study how TopPush scales to different number of training examples by using the largest dataset url. Figure 1 shows the log-log plot for the training time of TopPush vs. the size of training data, where different lines correspond to different values of \u03bb. Lines in a log-log plot correspond to polynomial growth \u0398(xp), where p corresponds to the slope of the line. For the purpose of comparison, we also include a black dash-dot line that tries to fit the training time by a linear function in the number of training instances (i.e., \u0398(m+ n)). From the plot, we can see that for different regularization parameter \u03bb, the training time of TopPush increases even slower than the number of training data. This is consistent with our theoretical analysis given in Section 3.3."}, {"heading": "5.2.4. Influence of Parameters", "text": "We study the influence of precision parameter and regularization parameter \u03bb on the computational cost and prediction performance of TopPush. First, we fix \u03bb to be 1, and run TopPush\nwith \u2208 {10\u22128, . . . , 10\u22122}. We measure the number of iterations needed to achieve the accuracy\n, and the prediction performance of the learned ranking function. Figure 2 show the results for dataset w8a. Similar results are obtained for the other datasets. It is not surprising to observe that the smaller the , the better the prediction performance, but at the price of a larger number of iterations and consequentially a longer training time. Evidently, we may want to set the precision parameter to balance the tradeoff between computational time and prediction performance. According to Figure 2, we found that = 10\u22124 appears to achieve nearly optimal performance with a small number of iterations.\nIn the second experiment, we fix to 10\u22124, and examine the influence of \u03bb. Figure 2 shows how the number of iterations and prediction accuracy are affected by different \u03bb on dataset w8a. We observe that the smaller the \u03bb, the smaller the number of iterations. This is because regularization parameter \u03bb controls the domain size, and as a result, a smaller \u03bb will lead to a smaller solution domain and thus a faster convergence to the optimal solution. As expected, we need to choose the value \u03bb to achieve good performance, since it is a regularization parameter. Meanwhile, the computational cost of TopPush reduces when a larger value of \u03bb is used. This is easy to understand, because \u03bb controls the size of the domain from which TopPush searches the optimal ranking function, and a large \u03bb reduces the domain size. Empirically, we can set \u03bb to 1 by default, and search \u03bb in {10\u22122, . . . , 102} for better solution."}, {"heading": "6. Conclusion and Future Work", "text": "In this paper, we focus on bipartite ranking algorithms that optimize accuracy at the top of the ranked list. To this end, we consider to maximize the number of positive instances that are ranked above any negative instances, and develop an efficient algorithm, named as TopPush to solve related optimization problem. Compared with existing work on this topic, the proposed TopPush algorithm scales linearly in the number of training instances, which is in contrast to most existing algorithms for bipartite ranking whose time complexities dependents on the number of positivenegative instance pairs. Moreover, our theoretical analysis clearly shows that it will lead to a ranking function that places many positive instances the top of the ranked list. Empirical studies verify the theoretical claims: the TopPush algorithm is effective in maximizing the accuracy at the top and is significantly more efficient than the state-of-the-art algorithms for bipartite ranking. In the future, we plan to develop appropriate univariate loss, instead of pairwise ranking loss, for efficient bipartite ranking that maximize accuracy at the top."}, {"heading": "Acknowledgments", "text": "This research was supported by the 973 Program (2014CB340501), NSFC (61333014), NSF (IIS1251031), and ONR Award (N000141210431). Z.-H. Zhou is the corresponding author of this paper."}], "references": [], "referenceMentions": [], "year": 2014, "abstractText": "Bipartite ranking aims to learn a real-valued ranking function that orders positive instances before<lb>negative instances. Recent efforts of bipartite ranking are focused on optimizing ranking accuracy<lb>at the top of the ranked list. Most existing approaches are either to optimize task specific metrics<lb>or to extend the ranking loss by emphasizing more on the error associated with the top ranked<lb>instances, leading to a high computational cost that is super-linear in the number of training<lb>instances. We propose a highly efficient approach, titled TopPush, for optimizing accuracy at the<lb>top that has computational complexity linear in the number of training instances. We present a<lb>novel analysis that bounds the generalization error for the top ranked instances for the proposed<lb>approach. Empirical study shows that the proposed approach is highly competitive to the state-<lb>of-the-art approaches and is 10-100 times faster.<lb>", "creator": "LaTeX with hyperref package"}}}