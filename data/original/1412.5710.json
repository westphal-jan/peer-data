{"id": "1412.5710", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Dec-2014", "title": "Multiobjective Optimization of Classifiers by Means of 3-D Convex Hull Based Evolutionary Algorithm", "abstract": "Finding a good classifier is a multiobjective optimization problem with different error rates and the costs to be minimized. The receiver operating characteristic is widely used in the machine learning community to analyze the performance of parametric classifiers or sets of Pareto optimal classifiers. In order to directly compare two sets of classifiers the area (or volume) under the convex hull can be used as a scalar indicator for the performance of a set of classifiers in receiver operating characteristic space.", "histories": [["v1", "Thu, 18 Dec 2014 03:01:10 GMT  (4369kb)", "http://arxiv.org/abs/1412.5710v1", "32 pages, 26 figures"]], "COMMENTS": "32 pages, 26 figures", "reviews": [], "SUBJECTS": "cs.NE cs.LG", "authors": ["jiaqi zhao", "vitor basto fernandes", "licheng jiao", "iryna yevseyeva", "asep maulana", "rui li", "thomas b\\\"ack", "michael t m emmerich"], "accepted": false, "id": "1412.5710"}, "pdf": {"name": "1412.5710.pdf", "metadata": {"source": "CRF", "title": "Multiobjective Optimization of Classifiers by Means of 3-D Convex Hull Based Evolutionary Algorithms", "authors": ["Jiaqi Zhao", "Vitor Basto Fernandes", "Licheng Jiao", "Iryna Yevseyeva", "Asep Maulana", "Rui Li", "Thomas B\u00e4ck", "Michael T. M. Emmerich"], "emails": ["jiaqizhao88@126.com,", "lchjiao@mail.xidian.edu.cn)."], "sections": [{"heading": null, "text": "Finding a good classifier is a multiobjective optimization problem with different error rates and the costs to be minimized. The receiver operating characteristic is widely used in the machine learning community to analyze the performance of parametric classifiers or sets of Pareto optimal classifiers. In order to directly compare two sets of classifiers the area (or volume) under the convex hull can be used as a scalar indicator for the performance of a set of classifiers in receiver operating characteristic space.\nRecently, the convex hull based multiobjective genetic programming algorithm was proposed and successfully applied to maximize the convex hull area for binary classification problems. The contribution of this paper is to extend this algorithm for dealing with higher dimensional problem formulations. In particular, we discuss problems where parsimony (or classifier complexity) is stated as a third objective and multi-class classification with three different true classification rates to be maximized.\nThe design of the algorithm proposed in this paper is inspired by indicator-based evolutionary algorithms, where first a performance indicator for a solution set is established and then a selection operator is designed that complies with the performance indicator. In this case, the performance indicator will be the volume under the convex hull. The algorithm is tested and analyzed in a proof of concept study on different benchmarks that are designed for measuring its capability to capture relevant parts of a convex hull.\nFurther benchmark and application studies on email classification and feature selection round up the analysis\nand assess robustness and usefulness of the new algorithm in real world settings.\nIndex Terms\nConvex hull, area under ROC, classification, indicator based EA, multiobjective algorithm, ROC analysis,\nROCCH, SPAM, feature selection.\nI. INTRODUCTION\nClassification is one of the most common problems in machine learning. The task of classification is to assign instances in a data set to target classes based on classifiers previously learned. The receiver operating characteristic (ROC) graph is a technique for visualizing, organizing and selecting classifiers based on their performance [1]. ROC graphs are usually used to evaluate and compare the performance of classifiers and they also have properties that make them especially useful for domains with skewed class distributions and different classes of problems that assign costs to misclassification. Originating from the field of object classification in radar images, ROC analysis has become increasingly important in many other areas with cost sensitive classification and/or unbalanced data distribution, such as medical decision making [2], signal detection [3], diagnostic systems [4].\nJiaqi Zhao and Licheng Jiao are with the Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education, International Research Center for Intelligent Perception and Computation, Xidian University, Xi\u2019an Shaanxi Province 710071, China (emails:jiaqizhao88@126.com, lchjiao@mail.xidian.edu.cn).\nVitor Basto Fernandes is with the School of Technology and Management, Computer Science and Communications Research Centre,\nPolytechnic Institute of Leiria, 2411-901 Leiria, Portugal. (e-mail: vitor.fernandes@ipleiria.pt).\nAsep Maulana, Thomas Ba\u0308ck and Michael T.M. Emmerich are with the Leiden Institute for Advanced Computer Science (LIACS), Leiden\nUniversity, 2333 CA Leiden, Netherlands. (e-mails: {a.asep.maulana, t.h.w.baeck, m.t.m.emmerich}@liacs.leidenuniv.nl). Rui Li is with Microsoft Research Asia, Beijing 100190, China (e-mail: lerain@gmail.com).\nIryna Yevseyeva is with Cyber Security Research Institute, School of Computing Science, Newcastle University, NE1 7RU, Newcastle-\nupon-Tyne, UK (e-mail:iryna.yevseyeva@newcastle.ac.uk).\nMore recently, research has drawn attention to ROC convex hull (ROCCH) analysis that covers potentially optimal points for a given set of classifiers [1]. ROCCH makes use of the finding that two hard classifiers can be combined to a classifier that has characteristics in ROC space that correspond to linear combinations of the characteristics of single classifiers and thus these linear combinations do not have to be explicitly represented in ROC space. A performance indicator for sets of hard binary classifiers that is compliant with the improvement of ROCCH is the area under the convex hull (AUC).\nSome evolutionary multiobjective optimization algorithms (EMOAs) [5] have been applied to machine learning and image processing areas [6]. The maximization of the performance of ROC representations with respect to this indicator has been subject to a recent study by Wang et al. [7], who showed that the proposed algorithm, CH-EMOA, is capable to show a strong performance for improving ROCCH with respect to AUC as compared to using state-of-the-art EMOAs (NSGA-II [36], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]) for the same task.\nSo far algorithms that seek to maximize ROCCH performance have only focused on the problem of optimizing binary classifiers with respect to two criteria. There is however an increasing interest in extending ROCCH performance analysis to more than two criteria. In this research we consider the following additional objectives:\n\u2022 Complexity minimization: The objective here is to find models with maximum simplicity (parsimony)\nor minimum computational costs. It can be described as the number of rules defining a classifier in proportion of the number of possible rules. In the context of feature selection this objective favors classifiers with a small number of features. \u2022 Three-class classification: There can be three or more classes and for each class the error rates need\nto be minimized. A simplified ROC is estimated from a three-class classifier by only considering the rate of every correctly classified category [8], which ensures that good classifiers tend to result in better ROCCH than poorer ones.\nThe contribution of this article is to extend the CH-EMOA to deal with 3-D ROCCH problems, by considering these additional objectives for the classifier. As a new algorithm, the 3-D convex hull evolutionary multiobjective algorithm (3DCH-EMOA) can deal with many additional problems in the machine learning field. Moreover, we analyze and assess the performance of the algorithm in different studies on, partly new, academic problems and practical applications. To analyze the capability of different algorithms to maximize convex hull volume, in a more fundamental study two sets of test problems named ZEJD and ZED are proposed and the capability of 3DCH-EMOA to capture only the convex part of a Pareto front is assessed. These benchmarks are accompanied by standard benchmarks from the machine learning community. Besides, we include a study on SPAM filter design and a study on feature selection. While in the SPAM filter study the number of rules determines the complexity objective in terms of number of used rules, the goal in feature selection is to reduce the number of features. 3DCH-EMOA is compared with state-of-the-art EMOAs such as NSGA-II [36], GDE3 [39], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]on the test problems.\nThis paper is organized as follows: the related work is outlined in Section II and the background of 3-D ROC surfaces and the theory of multiobjective optimization are introduced in Section III. We describe the framework of the 3DCH-EMOA algorithm in Section IV and experimental results on ZJED and ZED benchmarks test problems are described and discussed in Section V. The description of the SPAM filter application and experimental results are shown in Section VI. In Section VII the experimental results of feature selection for binary and three-class classification are discussed. Section VIII provides the conclusions and a discussion on the important aspects and future perspectives of this work.\nII. RELATED WORK\nA. ROCCH in classification\nThe receiver operating characteristic convex hull (ROCCH) covers all the potential optimal classifiers in a given set of classifiers. Therefore, the aim of ROCCH maximization is to find a group of classifiers\nthat perform well as a set. Despite the fact that ROCCH is an important topic in classification, there is not much work focusing focus on how to maximize the ROCCH. A reason for this could be that this is a relatively complex task compared to approaches that assess performance of a classifier by means of a single number. However, the additional gain in information about the trade-off between different objectives and the possibilities it offers for online adjustments of classifiers should justify the development of more mature methods for ROCCH maximization. The set of existing methods could be partitioned into two categories: one is ROC geometric analysis based machine learning methods and the other one is evolutionary multiobjective optimization methods.\nROCCH maximization problems were first described in [9]. One approach is to identify portions of the ROCCH to use iso-performance lines [1] that are translated from operating conditions of classifiers. Suitable classifiers for data sets with different skewed class distribution or misclassification costs can be chosen based on these iso-performance lines. In addition, a rule learning mechanism is described in [10] and in [11]. It combines rule sets to produce instance scores indicating the likelihood that an instance belongs to a given class, which induces decision rules in ROC space. In the above methods a straightforward way was used to analyze the geometrical properties of ROC curves to generate decision rules. However, the procedure is not effective and easily gets trapped in local optima.\nIn [12], a method for detecting and repairing concavities in ROC curves is studied. In that work, a point in the concavity is mirrored to a better point. This way the original ROC curve can be transformed to a ROC curve that performs better. The Neyman-Pearson lemma is introduced to the context of ROCCH in [13], which is the theoretical basis for finding the optimal combination of classifiers to maximize the ROCCH. This method not only focuses on repairing the concavity but it also improves the ROC curve, which is different with [12]. For a given set of rules, the method can combine the rules using and and or to get the optimum rule subset efficiently. But it can not generate new rules in the global rule set. More recently, ROCCER was proposed in [11]. It is reported to be less dependent on the previously induced rules.\nRecently also multiobjective optimization techniques to maximize ROCCH received attention. The ROCCH maximization problem is a special case of a multiobjective optimization problem, because the minimization of false positive rates and maximization of true positive rates can be viewed as conflicting objectives, and the parameters of a classifier can be viewed as decision variables. In [14], non-dominated decision trees were developed, which are used to support the decision which classifier to choose. A multiobjective genetic programming approach was proposed to envelop the alternative Pareto optimal decision trees. However, it is not a general method for ROCCH maximization because it only pays attention to cost sensitive classification problem.\nThe Pareto front of multiobjective genetic programming is used to maximize the accuracy of each minority class with unbalanced data set in [15]. Moreover, in [16], the technique of multiobjective optimization genetic programming is employed to evolve diverse ensembles to maximize the classification performance for unbalanced data.\nSome more evolutionary multiobjective optimization algorithms (EMOAs) have been combined with genetic programming to maximize ROC performance in [17]. Although they have been used in ROCCH maximization, these techniques do not consider special characteristics of ROCCH. This is done in convex hull multiobjective genetic programming (CH-MOGP), which is proposed in [7]. CH-MOGP is a multiobjective indicator-based evolutionary algorithm (IBEA) using the area under the convex hull (AUC) as a performance indicator for guiding the search. It has been compared to other state-of-the-art methods and showed the best performance for binary classifiers on the UCI benchmark [18]. However, it is so far limited to binary classifiers and does not take into account additional objectives, such as parsimony. The new research discussed in the following takes the algorithm design and analysis to the next level by extending the concepts introduced in CH-MOGP to problems with three objective functions, and by providing a detailed analysis for the performance of the resulting algorithm 3DCH-EMOA.\nB. ROC from multiclass classifiers\nThe ROC graph is often used to evaluate and optimize the performance of a binary classifier. The area under the ROC convex hull (AUC) has become a standard performance evaluation criterion in binary pattern recognition problems and it has been widely used to compare different classifiers independently of priors of distribution and costs of misclassification [8]. However, the AUC measure is only applicable to the binary classification problem.\nThe ROC curve is extended to multi-class classification problems in [19]. Instead of two-dimensional points, now optimal classifiers are represented by points in an n-dimensional ROC space. A more recent example is the ROC hyper-surface (see, e.g., [20]) that comprises the non-dominated boundary of the convex hull in n-dimensional ROC space. Many desirable properties, such as the possibility to repair concavities, are preserved by the ROC hyper-surface.\nIt has been shown that a multi-class classifier with good ROC hyper-surface can lead to classifiers suitable for various class distributions and misclassification costs via re-optimization of its output matrix [20]. However, due to the increase of the dimensionality of the ROC space, achieving the optimal ROC hyper-surface is even more difficult than achieving the optimal ROC curve [21]. Hence, AUC has to be extended to multi-class classifiers to enable the comparison between classifiers on the basis of more detailed information about the performance characteristics. A straightforward way to generalize AUC is the volume under the ROC (a surface in 3-D and a hyper-surface in n-D) surface (VUS) [22]. Methods from computational geometry can be used to efficiently compute the VUS, but, as compared to the 2-D case, this is relatively complicated [23]. Moreover, the VUS value of a \u201cnear guessing\u201d classifier is almost the same as a \u201cnear perfect\u201d classifier for more than two classes (see [24]). However, alternative definitions of VUS have been proposed where this problem does not occur [8]. This will be discussed later in more detail.\nThe VUS from multi-class classifiers is simplified by considering the AUC between each class and all of the other classes (one vs. all strategy) in [25], turning the problem to a problem that considers a set of binary classifiers. This approach ignores higher order interactions and depends only on class distribution priors and misclassification costs. In [26], multi-class area under convex hull (MAUC) has been proposed as a simpler generalization of AUC for multi-class classification problems. MAUC has been widely used in recent work [21], [27]. MAUC is estimated by averaging the AUC between all pairs of classes. This leads to a quadratically growing number of required comparisons in the number of classes [8].\nThe VUS of three-class classifiers has been studied in [28] and [29]. The simplified ROC is estimated from a multiclass classifier by only considering the rate of every correctly classified category [8], which ensures that good classifiers tend to result in better VUS than bad classifiers. The theory of ROCCH can easily be applied to multi-class classifiers in this way and many results, such as the possibility to heal concavities, can be generalized. In this paper, we therefore focus on finding (sets of) classifiers with optimal VUS considering the simplified ROC proposed in [8]."}, {"heading": "C. Convex Hull based EMOA", "text": "In the past, convex hull based selection operators were employed in EMOA to maintain a well-distributed\nset or make the non-dominated sorting more effective (cf. [30], [31]).\nIn [32] a multiobjective evolutionary algorithm based on the properties of the convex hulls defined in the 2-D ROC space was proposed, which was applied to determine a set of fuzzy rule-based binary classifiers with different trade-offs between false positive rate (fpr) and true positive rate (tpr). NSGA-II was used to generate an approximation of a Pareto front composed of genetic fuzzy classifiers with different trade-offs among sensitivity, specificity, and interpretability in [33]. After projecting the overall Pareto front onto the ROC space, ROC convex hull method was used to determine the potential optimal classifiers on the ROC plane.\nIn a recent research article Wang et al. discuss the optimization of binary classifiers based on receiver operator characteristic [17]. They use an indicator-based selection operator that seeks to maximize the\nAUC. This strategy proves to be very effective for finding relevant parts of the Pareto front. Here, we therefore adopt the strategy, but lift it to the next level by considering multidimensional objective spaces.\nIII. 3-D ROC AND MULTIOBJECTIVE OPTIMIZATION\nOur study aims at looking at different types of three-objective problems, including (1) maximization of true category classification in three-class classification problems and (2) binary classification problems with parsimony or complexity (number of rules, number of features) as a third objective. For this we propose a multiobjective optimization algorithm to maximize ROCCH in 3-D.\nThe ROC curve of a binary classifier is defined by a two-by-two confusion matrix which describes the relationship between the true labels and predicted labels from a classifier. An example of a confusion matrix is shown in Fig. 1. There are four possible outcomes with binary classifiers in a confusion matrix. It is a true positive (TP), if a positive instance is classified as positive. We call it false negative (FN), if a positive instance is classified as negative. If a negative instance is correctly classified we call it a true negative (TN), else we call it a false positive (FP).\nLet fpr = FP/(TN+FP) be the false positive rate and fnr = FN/(TP+FN) be the false negative rate. Since no perfect classifier exists, and fpr and fnr are conflicting with each other, ROC graphs are used to depict the trade-off between them. ROC graphs are two-dimensional graphs in which the fpr is plotted on the X axis and fnr is plotted on the Y axis.\nBasically, finding a set of optimal classifiers is a bi-objective problem. Next we will look at related problem definitions with more than two objective functions: Firstly, classifier complexity (or simply \u2018complexity\u2019) is discussed as a third objective function and secondly the three-class classification problem is introduced."}, {"heading": "A. Complexity as a third objective function", "text": "Besides fpr and fnr, we define the third objective as complexity of the classifier. In classifiers with feature selection the number of features or used features rate (ufr which is defined in Eq. 1) can be used as the third objective, whereas in rule-based classifiers the number of rules from a rule base or used rules rate (urr which is defined in Eq. 2) can be used as a complexity objective. In the general case we will use the term classifier complexity ratio (ccr) for both of them.\nufr = number of used features\ntotal number of features (1)\nurr = number of used rules\ntotal number of rules (2)\nThe ccr will obtain its maximum in the value 1.0 (all features or, respectively, rules are used) and its minimum in the value of 0.0 (no feature or, respectively, rule is used). The computational cost of a classifier with a high ccr is considered to be higher than that of a lower ccr, while the classifier with the lower ccr should be preferred given the false positive and false negative rates are the same. It is always possible to construct a classifier the characteristic of which is a convex combination of the original classifier by\nmeans of randomization, and in some cases, by means of finding classifiers that combine features, or respectively, rules of two classifiers. We name the ROC space with complexity of binary classifiers as a third axis in the augmented ROC space.\nIn augmented ROC space for complexity classifiers, fpr is plotted on X axis, fnr is plotted on Y axis, and ccr is plotted on the Z axis, which is depicted in Fig. 2. Normally, ccr, fpr and fnr are conflicting with each other. A low value of ccr means low complexity of the classifier, i.e. there are less rules for rule-based classifier or less features for feature selection problem, which would result in a poor performance of fpr and fnr. The new proposed algorithm aims at finding trade-offs among the three objectives.\nSeveral points in augmented ROC space are important to note. The point (0,0,0) represents the strategy of never issuing a wrong classification and the classifier with a cost of zero. This point represents a perfect classifier and a classifier corresponding to such a point does not exist in reality but can be approximated as closely as possible. The point (1,0,0) represents the strategy of issuing all the instances as negative by a classifier whose complexity is zero. The point (0,1,0) represents a classifier that predicts all instances as positive without using any rules or features. In a similar way, predicting all of the instances as negative with all the rules or features results in the point (1,0,1). The point (0,1,1) can be obtained by predicting all of the instances as positive with all the rules or features. For all points in {(1,0,0), (0,1,0), (1,0,1), (0,1,1) } a classifier can be constructed. The surface of fpr+fnr=1 represents randomly guessing classifiers, which is shown in Fig. 3. The classifiers which we search for should be in the space of fpr+fnr<1. In this paper, we treat the points (1,0,0), (0,1,0), (1,0,1) and (0,1,1) as reference points to build ROCCH and to calculate the VUS in augmented ROC space. For a set of randomly guessing classifiers the VUS will be 0, and for a set of perfect classifiers the VUS will be 0.5 in augmented ROC space.\nEvery complexity augmented binary classifier can be mapped to the augmented ROC space. The ROCCH is the collection of all potentially optimal classifiers in a given set of classifiers. Furthermore, a classifier is potentially optimal if and only if it lies on the augmented ROCCH of the set of points in ROC space for complexity classifiers. In Fig. 2 the points a, b, c are on the ROC surface and the point d is above it. a, b, c represent potentially optimal classifiers and d is not. Any virtual classifier can be constructed by\ncombining two or more classifiers on the ROC surface. The newly proposed method aims at maximizing ROCCH by maximizing VUS.\nB. ROCCH for three-class classification\nBasically, ROC analysis concerns the confusion matrix for the outputs of a classifier, which is defined by a three-by-three matrix for a three-class classifier as it is shown in Fig. 4. In order to explain it clearly, we define the three classes as class A, B and C. There are nine possible outcomes with a three-class classification problem. An outcome is called a True A (TA) if an instance A is classified as A, we call it a False Ab (FAb) if an instance B is classified as A and we call it a False Ac (FAc) if an instance C is classified as A. In a similar way, we define a False Ba (FBa), a True B (TB), a False Bc (FBc), a False Ca (FCa) and a False Cb (FCb) and True C (TC) which are described in Fig. 4. Six variables are required to describe the confusion matrix exactly. The problem is simplified by only considering the diagonal elements of the matrix in [8]. Let tar = TA/(TA+FBa+FCa) be the true A rate, tbr = TB/(TB+FAb+FCb) be the true B rate and tcr = TC/(TC+FAc+FBc) be the true C rate. In this way, the problem of threeclass classification turns out to maximize the tar, tbr and tcr simultaneously. However, because they are normally conflicting each other, the newly proposed method aims at finding trade-offs among them.\nROC graphs for three-class classifiers are three-dimensional graphs in which tar is plotted on the X\naxis, tbr is plotted on the Y axis and tcr is plotted on the Z axis, as it is shown in Fig. 5.\nSeveral points in three-class ROC space are important to note. The lower point (0,0,0) represents the strategy of never issuing a right classification, all of the outcomes of such a classifier are wrong labels. The opposite strategy, the upper point (1,1,1) represents the strategy of never issuing a wrong classification, which represents a perfect classifier. Both of these classifiers can normally not be constructed. The point (1,0,0) represents the case where all instances of the true class A are classified as A but no true instances of class B and C are correctly classified. The point (1,0,0) can be achieved by classifying all the instances as class A. The point (0,1,0) represents the case where all instances of the true class B are classified as B but no true instances of class A and C are correctly classified. And the point (0,0,1) represents the case where all instances of the true class C are classified as C but no true class A and B are correctly classified. The points (1,0,0), (0,1,0) and (0,0,1) are fixed points on three-class ROC graphs. We treat\nthem as reference points to build ROCCH and to calculate the VUS under 3-D ROC space of three-class classification case. The value of VUS will be zero for random guessing classifiers and the value of a perfect classifier is 5/6. The value of VUS of common classifiers is in the range [0, 5/6], a large value always corresponding to classifiers with good performance.\nThe surface tar+tbr+tcr=1 on the 3-D ROC space represents the strategy of randomly guessing a class for the instance, see e.g. Fig. 5. For example, if a classifier randomly guesses the A class 0.4 times on average, the B class 0.4 times on average and the C class 0.2 of the total time used for classification, 40 percent of the class A instances can be correctly classified, 40 percent of class B instances will be correctly classified and only 20 percent of class C instances will be correctly classified. This yields the point (0.4,0.4,0.2) in 3-D ROC space. If it guesses the instances as class A all the times on average and no times for class B and class C, 100 percent of class A instances will be correctly classified and 0 percent of both class B and class C will be correctly classified. This yields the point (1,0,0) in 3-D ROC space. Any classifiers on the triangle surface in 3-D ROC space may be said to have no information about the class. A classifier that appears in the lower triangle surface performs worse than random guessing. A more effective classifier produces the ROC surface above the triangle surface.\nIn the following, we will give an example of using 3-D ROC to search optimal classifiers for data sets with different class distributions. One important goal of classification problems is to maximize the total accuracy. Suppose the priori probability of the data distribution of every class is denoted as p(a), p(b) and p(c), where p(a)+p(b)+p(c)=1. The accuracy (acc) of a classifier can then be represented as in Eq. 3.\nacc = p(a) \u00b7 tar + p(b) \u00b7 tbr + p(c) \u00b7 tcr (3)\nWhile considering cost-sensitive problems, the cost function is simplified by only considering the cost of misclassified instances for each class. We denote the cost of each class as c(a), c(b) and c(c). Here c(a) represents the cost of classifying an instance of class a as class b or class c, c(b) and c(c) are defined in a similar way. The total cost is described in Eq. 4, in which N is the total number of instances.\ncost = N \u00b7 p(a) \u00b7 c(a) \u00b7 (1\u2212 tar) +N \u00b7 p(b) \u00b7 c(b) \u00b7 (1\u2212 tbr) +N \u00b7 p(c) \u00b7 c(c) \u00b7 (1\u2212 tcr) (4)\nIf there are two points (tar1,tbr1,tcr1) and (tar2,tbr2,tcr2) that have the same accuracy or cost, we can get an extended iso-performance surface as described in Eq. 5 and Eq. 6. Both Eq. 5 and Eq. 6 are surface functions which are named as iso-performance surface in ROC analysis theory [1].\np(a)(tar1\u2212 tar2) +p(b)(tbr1\u2212 tbr2)\n+p(c)(tcr1\u2212 tcr2) = 0 (5)\np(a) \u00b7 c(a)(tar1\u2212 tar2) +p(b) \u00b7 c(b)(tbr1\u2212 tbr2)\n+p(c) \u00b7 c(c)(tcr1\u2212 tcr2) = 0 (6)\nAll the classifiers corresponding to the points on an iso-performance surface have the same expected accuracy or cost. Moreover, each set of class distribution defines a family of iso-performance surfaces. By moving the iso-performance surface until it gets in contact with a point in ROCCH, the joint point represents a classifier which can produce highest accuracy or lowest cost under that condition. Generally, the larger value of VUS the better performance the ROCCH will be.\nSometimes the classifier with desired performance is not in the set of available classifiers, but lies between two of them. The classifier with desired performance can be obtained by sampling the decisions\nof each classifier. The sampling ratio is determined by the position where the resulting classifier lies. The way to find a desired optimal classifier is similar to ROCCH for binary classifiers which is described in [1].\nImprecise distribution information of data defines a range of parameters for iso-performance lines (surfaces) and the range of lines (surfaces) will intersect a segment of 3D ROCCH. If the segment defined by a range of lines corresponds to a single point in ROC space, then there is no sensitivity to the distribution assumptions, otherwise the ROCCH is sensitive to the distribution assumptions. In order to improve the robustness of ROCCH not only the VUS should be maximized but also its structure should be optimized. Usually, the more uniform the distribution of points in the ROCCH, the more nonsensitive the ROCCH is. The gini coefficient [34] is used to evaluate the uniformity of the solution of the test functions in this paper, and the details will be discussed later."}, {"heading": "C. ROCCH maximization and multiobjective optimization", "text": "The goals of augmented ROCCH and three-class ROCCH maximization are to find a group of classifiers that approximate the perfect point (0,0,0) for complexity binary classifiers and (1,1,1) for three-class classifiers, respectively. The ROCCH maximization problems turn out to be minimization multiobjective optimization problems by multiplying each objective function with minus one as described in Eq. 7.\nminF (x) = (f1(x), f2(x), f3(x))\nsubject to x \u2208 \u2126 (7)\nIn Eq. 7, x is a set of classifiers, \u2126 is the solution space, i.e. the set of all possible classifiers, and F (x) is a vector function for ROC distribution. In the theory of multiobjective optimization, dominance is an important concept which is defined as: Let \u00b5 = (\u00b51, \u00b52, \u00b53), \u03bd = (\u03bd1, \u03bd2, \u03bd3) be two vectors, \u03bd is said to dominate \u00b5 if \u03bdi \u2264 \u00b5i for all i = 1, 2, 3, and \u03bd =\u00b5, this is denoted as \u03bd \u227a \u00b5. \u03bd and \u00b5 are incomparable if \u03bd and \u00b5 do not dominate each other [7]. The Pareto set (PS) is the collection of all the Pareto optimal points in decision space, i.e. of all points x \u2208 \u2126 with no x\u2032 \u2208 \u2126 such that f(x\u2032) \u227a f(x). The Pareto front is the set of all objective vectors of points in PS in objective space PF = {F (x) | x \u2208 PS} [17].\nA special approach based on ROCCH is proposed in [7] to solve the ROC maximization problem for binary classification. The convex hull is different from the Pareto front though they are similar to each other. In the example of Fig. 6 points a, b, c, d, e are non-dominated points in traditional multiobjective optimization algorithms. However, only points a, b and e are on the convex hull. This is the special character of the ROCCH maximization problem and new strategies need to be researched to deal with it. We call these problems ROCCH optimization problems. While in [7] binary classifiers were considered, here we consider complexity augmented binary classifiers and three-class classifiers and in the context of 3-D ROCCH multiobjective maximization."}, {"heading": "D. The motivation and ideas for 3-D ROCCH maximization", "text": "There are two key steps of any EMOAs, one is how to rank the population and the other one is selecting solutions that survive to the next generation. The ranking approach of NSGA-II, probably the most popular EMOA used up-to-date, includes two steps. First sorting the population into several levels indicating the priority, and second designing a selection scheme which is used to choose winner individuals to survive from populations at the same level. While dealing with the 3-D ROCCH maximization problem, 3-D convex hull based sorting without redundancy is used to sort the population, which makes the diversity increase fast in the evolutionary process. A volume contribution selection scheme is adopted to calculate the contribution to the volume of 3-D ROCCH of each solution. Based on our insight, the VUS based selection strategy has a better performance than hyper-volume or crowding-distance to deal with the 3-D ROCCH maximization problem, because the special characteristic of ROCCH problem has been taken into consideration. The excellent performance will be shown in the experimental results.\nIV. 3-D CONVEX HULL BASED EVOLUTIONARY MULTIOBJECTIVE OPTIMIZATION\nIn this section, the newly proposed 3-D convex hull based evolutionary multiobjective optimization algorithm (3DCH-EMOA) is described. There are several differences between 3DCH-EMOA and other EMOAs. Firstly, 3-D convex hull (3DCH) based sorting without redundancy approach is used to rank the individuals into several priority levels as proposed in [7]. Secondly, a new strategy of VUS contribution is designed to rank the solutions in the same priority level. Thirdly, a non-descending (\u00b5 + 1) selection strategy is employed in this paper, rather than the approximate (\u00b5 + \u00b5) scheme in CH-MOGP [7]. The 3-D convex hull is built by the quickhull algorithm which is proposed in [37]. The quickhull algorithm is used to sort the populations in different levels and calculate the VUS contribution for every point on the convex hull. The details of these strategies are discussed next.\nA. 3DCH based sorting without redundancy\nConvex hull based sorting without redundancy strategy was first proposed in [7], which has a good performance to deal with binary classification problems. The convex hull based sorting approach is extended to three dimensions in this paper. The strategy works effectively, not only because it can maintain the diversity of the population, but also because it takes into consideration the properties of ROCCH. With this strategy, if there are not enough non-redundant solutions to fill the whole population, the redundant solutions which are preserved in the archive should be randomly selected in population. It will be shown in Section V that the strategy can preserve the diversity of the population by keeping non-redundant solutions with bad performance and discarding the redundant solutions even with good performance. In addition, the non-redundancy strategy can avoid the solutions at the convex hull being copied many times at the selection step of the algorithm.\nThe framework of 3DCH based without redundancy sorting is described in Algorithm 1. At first the solution set Q is divided into two parts, one is the redundancy solution set Qr the other is the nonredundancy solution set Qnr. The redundancy solution set Qr will be assigned to the last level of priority of the solution set and the non-redundancy solution set Qnr will be assigned into different priority levels by a convex hull based ranking method. Before ranking the non-redundancy solution set Qnr, a reference point set R should be merged with it and a set of candidate points of convex hull T is constructed. The 3-D quickhull algorithm [37] is adopted to build the convex hull with the candidate points set, which is widely used in 3-D convex hull related applications. The points (solutions) on the convex hull surface are considered as the current Pareto set and the first level of the Pareto front (note that all points can be constructed by means of a convex combination of classifiers in the set) and the remaining points will be used to build the new convex hull for the next level of Pareto front. Usually, there are several levels of solutions in the beginning of the algorithm and the number of levels will converge to one with the evolution of the population.\nAlgorithm 1 3DCH based sorting without redundancy (Q,R)\nRequire: Q = \u2205. Q is a solution set. Qr is the redundancy solution set. Qnr is the non-redundancy solution set. R is the set of reference points. F is the ranked solution set in different levels. F0 represents the Pareto front of the population. Ensure: 3DCH based sorting without redundancy\n1: Q = Qr +Qnr 2: T = Qnr \u222aR 3: F0 = 3D quickhull algorithm(T) [37] 4: Qnr = Qnr \u2212 F0 5: i=1 6: while Qnr = \u2205 do 7: T = Qnr \u222aR 8: Fi = 3D quickhull algorithm(T) 9: Qnr = Qnr \u2212 Fi\n10: i = i+ 1 11: end while 12: Fi = Qr 13: return the ranked solution set F\nAn example of the result of 3DCH based sorting without redundancy is given in Fig. 6. The surfaces s1 and s2 represent two levels of solutions of different priority, the solutions on surface s1 are better than those on surface s2 and the solutions on surface s1 have much more opportunity to survive to the next generation than those on s2.\nAfter ranking the individuals into different priority levels, another question arises such as how to analyze the importance of individuals in the same priority level. As the redundant solutions have no additional information about the population, the algorithm selects some of them to survive to the next generation randomly. If there are too many non-redundant solutions to fill the new population, the contribution to the VUS will be used as metric measure to rank the individuals in the same level, and only the high contribution individuals will survive. The details of the contribution of VUS will be described in the next section.\nB. VUS contribution selection scheme\nIn this section, we describe the VUS contribution indicator to evaluate the importance of individuals within the same priority level. We hypothesize that the new VUS contribution indicator is a more efficient strategy to maximize the volume under the 3-D convex hull when compared to the hyper-volume based contribution [38] or crowding distance indicator [36]. To calculate the contribution of an individual, a new convex hull should be built by subtracting from the total population volume the volume of the population without the individual, as shown in Eq. 8.\n\u2206V USi = V US(Q)\u2212 V US(Q\u2212 {qi}) i = 1, ...,m (8)\nThe procedure of calculating the VUS contribution for the non-redundancy solution set Qnr is given in Algorithm 2. After calculating the contribution to the VUS of each individual in Qnr, the individuals in\nthe same priority level can be ranked by the volume of \u2206VUS. The larger the volume of the contribution to VUS the more important the individual will be.\nAlgorithm 2 \u2206VUS(Qnr, R) Require: Qnr = \u2205 Qnr is the non-redundancy solution set R is a reference points set Ensure: \u2206VUS\n1: m = sizeof(Qnr) 2: P = Qnr \u222aR 3: V olumeall = V US(P ) [37] 4: for all i=1:m do 5: qi \u2190 Qnr(i) 6: \u2206V USi = V olumeall \u2212 V US(P \u2212 {qi}) 7: end for 8: return \u2206VUS\nC. 3DCH-EMOA\nThe framework of 3DCH-EMOA is described in Algorithm 3, which is inspired by indicator-based evolutionary algorithms. To optimize the multiple objectives on the convex hull space the initial population Q0 should be built randomly. The scheme of a (\u00b5+ 1) evolutionary algorithm is adopted within 3DCHEMOA to maximize the ROC performance, rather than the (\u00b5+\u00b5) scheme used in CH-MOGP [17], which causes the algorithm to converge too quickly. For each iteration there is only one offspring produced by the evolutionary operators and to keep the size of population constant, the least performing individual should be deleted. The non-descending reduce strategy given in Algorithm 4 is adopted in this method to remove an individual from the population, which ensures that the population becomes better with the evolution of the generation.\nAlgorithm 3 3DCH based EMOA (Max,N)\nRequire: Max > 0, N > 0 Max is the maximum number of evaluations N is the population size Ensure: 3DCH-EMOA\n1: Q0 = initialization() 2: t0 = 0 3: m = 0 4: while m < Max do 5: qi \u2190 Generate New Offspring (Qt) 6: Qt+1 \u2190 Non-Descending Reduce(Qt, qi) 7: t \u2190 t+ 1 8: m \u2190 m+ 1 9: end while\nIn Algorithm 4, the population is firstly divided into non-redundancy part Qnr and redundancy part Qr. If the redundancy set Qr is not empty, an individual can be selected randomly to be deleted from the population. If there is no individual in Qr, all of the solutions are of non-redundancy type, then 3DCH based sorting without redundancy can be used to rank the population into several priority levels. If there is only one level of solutions, it means that all solutions in the population are non-dominated,\nthen the contribution of each solution to VUS should be calculated and the least contribution one will be deleted from the population. If there are several levels of the population, only the contribution to VUS of individuals on the last priority level should be calculated and the individual with least contribution should be removed from the population.\nAlgorithm 4 Non-Descending Reduce (Q, q)\nRequire: Q = \u2205 Q is a set of solutions q is a solution Ensure: Reduce\n1: Split Q\u222a{q} into two subpopulation Qr and Qnr (Qr is the collection of redundancy individuals and Qnr is the collection of non-redundancy individuals) 2: if sizeof(Qr) >= 1 then 3: p \u2190 Randomly select an individual from Qr 4: Q \u2190 Qnr \u222aQr \u2212 {p} 5: else 6: F1, ..., Fv \u2190 3DCH based sorting without redundancy(Qnr) 7: if sizeof(F2) = 0 then 8: V olori = V US(Q) 9: V olq = V US(Q+ {q})\n10: if V olori < V olq then 11: d \u2190 The minimum \u2206VUS(Fv) 12: Q \u2190 Qnr \u2212 {d} 13: else 14: Q \u2190 Q 15: end if 16: else 17: d \u2190 The minimum \u2206VUS(Fv) 18: Q \u2190 Qnr \u2212 {d} 19: end if 20: end if 21: return Q"}, {"heading": "V. EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS", "text": "In this section, ZEJD and ZED test functions are designed to test the performance of 3DCH-EMOA and several other EMOAs, such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA/D [41]. To evaluate the performance of these algorithms VUS, gini coefficient and time cost are adopted in this section. By comparing the results of all algorithms we can make a conclusion that the new proposed algorithm has a good performance to deal with 3-D ROCCH maximization problem. The details of the experiments are described next."}, {"heading": "A. ZEJD Problem", "text": "In this section three ZEJD (Zhao, Emmerich, Jiao, Deutz) problems are designed to evaluate the performance of several kinds of EMOAs on ROCCH maximization problems. The test problem is a simulation of augmented ROCCH distribution of complexity classifiers, which has several important properties. Firstly, the points (1,0,0), (0,1,0) and (0,0,1) are included in the Pareto front. Secondly, the Pareto front should be below the ROC surface of random guessing classifiers which is described in Fig. 3. Thirdly, all of the solutions are in the space of the unit cube. The objective of this set of test problems\nis to find the maximum value of the volume under the convex hull surface. The range of variation of each object is in [0,1], the problem of ZEJD1 is defined in Eq. 9.\nf1 = 1\u2212 \u221a 2cos(x1 \u2217 \u03c0/2)(1\u2212 x3)\nf2 = 1\u2212 \u221a 2sin(x1 \u2217 \u03c0/2)cos(x2 \u2217 \u03c0/2)(1\u2212 x3) (9) f3 = 1\u2212 \u221a 2sin(x1 \u2217 \u03c0/2)sin(x2 \u2217 \u03c0/2)(1\u2212 x3)\nwhere x1, x2, x3 are all in [0, 1] and f1, f2, f3 are all in [0, 1].\nThe Pareto front of ZEJD1 is shown in Fig. 7. The problem ZEJD2 and ZEJD3 both are version of ZEJD1 modified by additional dent on the surface. in which some parts of Pareto Front are not on the convex hull. These two test problems are designed to test whether the algorithms can avoid the dent areas. ZEJD2 is defined by Eq. 10, a dent is made in the area satisfied f1 < a, f2 < a, g < a, by making the function decrease slowly. In our experiments we set a = 0.3,\u03bb = 0.5, the Pareto front of ZEJD2 is shown in Fig. 8. ZEJD3 is defined by Eq. 11, a dent is made by adding a surface d(x,y) which is shown in Fig. 9. In order to keep the points (1,0,0), (0,1,0) and (0,0,1) in the Pareto front, d(0, 0) is subtracted to obtain f3. In this paper, we set A = 0.15, \u03b3 = 400, the Pareto front of ZEJD3 is shown in Fig. 9. The objectives of both ZEJD2 and ZEJD3 are f1, f2 and f3, f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].\nf1 = 1\u2212 \u221a 2cos(x1 \u2217 \u03c0/2)(1\u2212 x3)\nf2 = 1\u2212 \u221a 2sin(x1 \u2217 \u03c0/2)cos(x2 \u2217 \u03c0/2)(1\u2212 x3)\ng = 1\u2212 \u221a 2sin(x1 \u2217 \u03c0/2)sin(x2 \u2217 \u03c0/2)(1\u2212 x3) (10)\nf3 =\n{\na+ \u03bb(g \u2212 a) if f1 < a, f2 < a, g < a g else\nf1 = 1\u2212 \u221a 2cos(x1 \u2217 \u03c0/2)(1\u2212 x3)\nf2 = 1\u2212 \u221a 2sin(x1 \u2217 \u03c0/2)cos(x2 \u2217 \u03c0/2)(1\u2212 x3)\ng = 1\u2212 \u221a 2sin(x1 \u2217 \u03c0/2)sin(x2 \u2217 \u03c0/2)(1\u2212 x3)\nd(x, y) = A \u2217 e\u2212\u03b3{(x\u22120.173)2+(y\u22120.173)2} (11) k(f1, f2) = g + d(f1, f2)\u2212 d(0, 0)\nf3 =\n{\nk(f1, f2) if k(f1, f2) > 0 0 else"}, {"heading": "B. ZED Problem", "text": "In this section three ZED (Zhao, Emmerich, Deutz) problems are designed to evaluate the performance of several kinds of EMOAs on ROCCH maximization problems. The test problem is a simulation of 3-D ROC distribution of three-class classifiers, which has several important properties. Firstly, the points (1,0,0), (0,1,0) and (0,0,1) are included in the Pareto front. Secondly, the Pareto front should be above the surface of random guess which is shown in Fig. 5. Thirdly, all of the solutions are in the space of the unit cube. The objective of this set of test problems is to find the maximum value of the volume under the convex hull. The range of variation of each objective is in [0,1], the problem of ZED1 is defined in Eq. 12.\nf1 = cos(x1 \u2217 \u03c0/2)(1\u2212 x3) f2 = sin(x1 \u2217 \u03c0/2)cos(x2 \u2217 \u03c0/2)(1\u2212 x3) (12) f3 = sin(x1 \u2217 \u03c0/2)sin(x2 \u2217 \u03c0/2)(1\u2212 x3)\nwhere x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1]. The Pareto front of ZED1 is shown in Fig. 10. The problem ZED2 and ZED3 are version of ZED1 modified by additional dent on the surface, in which some parts of Pareto Front are not on the convex hull. These two test problems are designed to test whether the algorithms can avoid the dent areas. ZED2 is defined by Eq. 13, a dent is made in the area satisfied f1 > a, f2 > a, g > a, by making the function increase slowly. In our experiments we set a = 0.4,\u03bb = 0.5, the Pareto front of ZED2 is shown in Fig. 11. ZED3 is defined by Eq. 14, a dent is made by subtracting a surface d(x, y) which is shown in Fig. 12. In order to keep the points (1,0,0), (0,1,0) and (0,0,1) in the Pareto front, d(0, 0) is added to k(f1, f2) as defined in Eq. 14. The points which are less than zero in k(0, 0) are set to zero when computing the value to f3. In this paper, we set A = 0.15, \u03b3 = 100, the Pareto front of ZED3 is shown in Fig. 12. The objectives of both ZED2 and ZED3 are f1, f2 and f3, all of the objectives are in [0, 1].\nf1 = cos(x1 \u2217 \u03c0/2)(1\u2212 x3) f2 = sin(x1 \u2217 \u03c0/2)cos(x2 \u2217 \u03c0/2)(1\u2212 x3) g = sin(x1 \u2217 \u03c0/2)sin(x2 \u2217 \u03c0/2)(1\u2212 x3) (13)\nf3 =\n{\na+ \u03bb(g \u2212 a) if f1 > a, f2 > a, g > a g else\nf1 = cos(x1 \u2217 \u03c0/2)(1\u2212 x3) f2 = sin(x1 \u2217 \u03c0/2)cos(x2 \u2217 \u03c0/2)(1\u2212 x3) g = sin(x1 \u2217 \u03c0/2)sin(x2 \u2217 \u03c0/2)(1\u2212 x3)\nd(x, y) = A \u2217 e\u2212\u03b3{(x\u22120.5)2+(y\u22120.5)2} (14) k(f1, f2) = g \u2212 d(f1, f2) + d(0, 0)\nf3 =\n{\nk(f1, f2) if k(f1, f2) > 0 0 else"}, {"heading": "C. Metrics", "text": "Three metrics are chosen to evaluate the performance of the different algorithms in the comparative experiment on the ZEJD and ZED problems. VUS metric can evaluate the solution set directly, the better the solution set the larger the value of VUS will be. For complicity binary classifiers problem and ZEJD problems the smallest value of VUS is 0 with random guessing classifiers and the largest value of VUS is\n0.5. For three-class classification problem and ZED problems the smallest value of VUS is 0 with random guessing classifiers and the largest value of VUS is 5/6.\nThe gini coefficient is commonly used as a measure of statistical dispersion intended to represent the income distribution of a nation\u2019s residents [34]. In this work, the gini coefficient is used to evaluate the uniformity of the solution set by calculating the statistical distribution of the nearest neighbor distance of each solution. The gini coefficient can describe the spread of neighboring individuals on the achieved Pareto front. The value of gini coefficient will be zero if the solution set is distributed uniformly. The definition of gini coefficient is described in Eq. 15. The lower the value of gini coefficient the more evenly distributed the solution set will be.\nG = 1\nn\n( n+ 1\u2212 2 (\u2211n i=1(n+ 1\u2212 i)di \u2211n\ni=1 di\n))\n(15)\nwhere G represents the value of gini coefficient, n is the number of solutions in the set, di is the nearest neighbor distance for each solution in the space.\nTime cost is used to measure the complexity of each algorithm in this section. In general, the most\ncomplex algorithms are most computationally expensive.\n1) Parameters Setting: All algorithms are run for 25000 function evaluations. The simulated binary crossover (SBX) operator and the polynomial mutation are applied in all experiments. The crossover probability of pc = 0.9 and a mutation probability of pm = 1/n where n is the number of decision variables are used. The population size is set to 50 for ZEJD problem and 100 for ZED problem, because the convex hull surface of ZED is larger than the convex hull surface of ZEJD. The size of archive for SPEA2 is equal to the size of the population. All of the experiments are based on jMetal framework [42], [43]. All of the algorithms are run 30 times independently."}, {"heading": "D. Experimental results and discussions", "text": "1) ZEJD problem: The comparison of simulation experiments with NSGA-II, GDE3, SPEA2, MOEA/D, SMS-EMOA, and 3DCH-EMOA on ZEJD problems is discussed in this section. The results of experiments are given as follows: the results not only include the plots of solution set in the objective space but also include statistical analysis on the metrics of these results. The illustrations of solutions set in the f1\u2212f2\u2212f3 objectives space are plotted for the ZEJD problems. The solutions obtained are depicted in dark dots and the true non-dominated solutions are in green dots.\nThe results of ZEJD1 are shown in Fig. 13, of ZEJD2 are shown in Fig. 14 and of ZEJD3 are shown in Fig. 15. By comparing the Pareto fronts of all the results we can make some conclusions: NSGA-II, GDE3 and SPEA2 show the worst convergence. MOEA/D can converge to the true Pareto front, however it does not give good results on diversity and distribution uniformity. The result of MOEA/D has no solutions on the edges of the solution space. SMS-EMOA and 3DCH-EMOA have good performance on\nconvergence, diversity and distribution uniformity. However the points near (0,0,1) are not included in the results of SMS-EMOA, which results in bad performance of VUS metric. There are several points on the dent areas in the results on ZEJD2 and ZEJD3 for the most of the algorithms. However, the new proposed algorithm 3DCH-EMOA can always heal the dent area of ZEJD2 and ZEJD3 test problems, but other algorithms are not so reliable. In summary, 3DCH-EMOA can always achieve better results than other algorithms, not only on convergence and distribution uniformity, but also has the ability to heal the dent area.\nIn the experiments, each algorithm is run for 30 times independently on ZEJD test problems to evaluate and compare the robustness of these algorithms. The performance characteristics of each algorithm can be seen from the statistical analysis of the experimental results. The statistical results (mean and standard deviation) of the VUS are shown in Table.I. The detailed discussion follows next.\nWhile dealing with the ZEJD problems and considering the metric of VUS, 3DCH-EMOA gets the largest value of mean and the smallest value of standard deviation, which shows that 3DCH-EMOA has a good performance not only in convergence but also in stability. GDE3 obtains the second best result with these test functions. SPEA2 and SMS-EMOA did not have good performance because they missed points near (0,0,1) in the solution space.\nThe statistical results of the gini coefficient are shown in Table.II. By comparing the results on the table we can see that 3DCH-EMOA gets the smallest value of mean and the smallest value of standard deviation, which shows that 3DCH-EMOA has a good performance in uniformity and diversity of the population. SPEA2 obtains the second best result, however it did not have good performance on convergence. SMSEMOA obtains the third best result and it also has good performance on convergence.\nThe statistical results of time cost of optimization are shown in Table. III. MOEA/D always cost the least time and NSGA-II performs better than others. SMS-EMOA is the most time consuming algorithm and 3DCH-EMOA only performs better than SMS-EMOA. In the case of machine learning problems, such as feature selection and parameters optimization of classifiers, the evaluation takes much more time than optimization process, which is different from test functions. Considering problems in machine learning,\nthe cost of time of optimization is not a key obstacle, especially for off line learning area, 3DCH-EMOA plays well with it which is shown in the next section.\n2) ZED problem: The comparison of simulation experiments with NSGA-II, GDE3, SPEA2, MOEA/D, SMS-EMOA, and 3DCH-EMOA on ZED problems is discussed in this section. The results of experiments are given in the following, not only the plots of the solution sets are included but also the statistical results on the metrics are analyzed. The illustrations of solution set are plotted in the f1\u2212f2\u2212f3 objectives space, in which the solutions obtained by each algorithm are depicted in dark dots and the true non-dominated solutions in green dots.\nThe results of ZED1 are shown in Fig. 16, of ZED2 are shown in Fig. 17 and of ZED3 are shown in Fig. 18. By comparing the Pareto fronts of all the results we can make some conclusions: NSGA-II and GDE3 show the worst convergence. MOEA/D can converge to the true Pareto front, however it does not give good result on diversity and distribution uniformity. The result of MOEA/D has too many solutions on the edges and the middle area of solution space. SPEA2, SMS-EMOA and 3DCH-EMOA have good performance on convergence, diversity and distribution uniformity. However there are no solutions on the edges of solution space for SMS-EMOA, and the distribution of solutions on the edges of solution space for SPEA2 are not as uniform as with 3DCH-EMOA. There are several points on the dent areas for the results of ZED2 and ZED3 problems for the most of the algorithms. However, the new proposed algorithm can always heal the dent area of ZED2 and ZED3 test problems, but the other algorithms can not. In summary, 3DCH-EMOA can always achieve better results than other algorithms, not only on convergence and distribution uniformity but also has the ability to heal the dent area.\nIn these experiments, each algorithm is run 30 times independently on ZED test problems to evaluate and compare the robustness of the algorithms. The performance characteristics of each algorithm can be seen from the statistical analysis of the experimental results. The statistical results of the VUS are shown in Table.IV. The detailed discussion follows next.\nFor the ZED1, ZED2 and ZED3 problem, 3DCH-EMOA gets the largest value of mean and the smallest value of standard deviation of VUS, which shows that 3DCH-EMOA has good performance not only in convergence but also in stability. SPEA2 obtains better results than the remaining algorithms with these test functions.\nThe statistical results of the gini coefficient are shown in Table.V. The detailed discussion of each\nproblem follows next.\nFor the ZED1, ZED2 and ZED3 problem, 3DCH-EMOA gets the smallest value of mean and the smallest value of standard deviation of the gini coefficient, which shows that 3DCH-EMOA has a good performance in uniformity. SPEA2 obtains better result than others but 3DCH-EMOA.\nThe statistical results of time cost of optimization are shown in Table. VI. NSGA-II always computa-\ntionally least expensive and MOEA/D performs better than others but NSGA-II. SMS-EMOA is the most time cost algorithm and 3DCH-EMOA only performs better than SMS-EMOA.\nThe new proposed algorithm is computationally expensive due to large computational resources needed for computing the VUS contribution of every point in the solution space. The dynamic convex hulls algorithm [44] will be adapted in future work to reduce the computational complexity of the new method."}, {"heading": "VI. SPAM PROBLEM", "text": "From a technical point of view, an email anti-SPAM system consists of a set of boolean filtering rules, that jointly allows for SPAM messages detection. Discovering the relative importance of these rules and assigning the corresponding scores (weights) of each rule, is a complex setup process.\nThe need of frequent scores reassignment for existing rules and setting scores for new rules, to keep the anti-SPAM filter updated and running, requires the adoption of machine learning and optimization techniques."}, {"heading": "A. SPAM multiobjective problem formulation", "text": "SPAM filtering problem optimization has been addressed by the techniques surveyed in [45], [46]. The formulation of the scores setting optimization problem is naturally bi-objective, a typical user would wish to minimize both, the number of SPAM messages not identified by anti-spam filtering techniques, called false negative rate (fnr), and the number of legitimate messages classified as SPAM by mistake, called false positive rate (fpr). A business email is one of extreme cases of anti-SPAM systems setup with such objectives, where the fpr and fnr should be tuned to have lowest possible rate of legitimate messages lost, usually at the expenses of higher false negative classifications. On the other extreme is content management systems (CMSs) devoted to entertainment, where dismissing some legitimate messages keeps or improves the interest on their usage, while the acceptance of any SPAM message is not allowed. The cases between these two extremes are also of high interest for a variety of the problem areas.\nIn previous work on anti-SPAM filter optimization [46] it was observed that many rules were not participating in the classification process and some (with very small weights) only marginally influenced the classification results. This observation suggests that in addition to optimizing fpr and fnr, the complexity of the anti-SPAM filter or its parsimony can be optimized.\nThe trend of increasing the number of rules for the system operation creates an empirically known potential inefficiency phenomenon, which is addressed under the so called principle of parsimony. This principle states, in one of its simplified formulations, that unnecessary assumptions for a theory (conclusion) should not be considered if they have no consequence for the conclusion [47].\nParsimony is measured in the context of the current anti-SPAM study, as the minimum number of rules\nwith score different from zero, that support a specific classification quality.\nIn our study we also follow a three-objective problem formulation, minimizing all three objectives, fpr, fnr and ccr (number of anti-SPAM filter rules rate) to be used in the classification process. 1) SpamAssassin Corpus: For the multiobjective anti-SPAM problem formulation experiments, we adopted the SpamAssassin system [48]. SpamAssassin was selected due to its popularity and wide adoption by the open source community, the research community on anti-SPAM systems, wide commercial usage, and available email corpora. The SpamAssassin corpus used in our experiments is composed of 9349 email messages, 2398 SPAM and 6951 legitimate messages [49].\nSpamAssassin became a reference in the anti-SPAM filtering domain, not only due to its public\navailability to research and development, but also because of its performance (classification quality). 2) Algorithms Involved: Five reference multiobjective algorithms were tested (NSGA-II, SPEA2, MOEA/D, SMS-EMOA and 3DCH-EMOA), for the three objectives anti-SPAM filtering problem formulation, using the SpamAssassin corpus [49] for SPAM classification quality assessment. Experiments were performed with jMetal [43], an optimization framework for the development of multiobjective metaheuristics in Java. 3) Configuration and Evaluation: Default parameters for problem formulation, experiments and algorithms settings were adopted for the experiments.\nEncoding: We employed a jMetal RealBinary encoding scheme where the chromosome is constituted by an array of real values in the interval [\u22125; 5] and a bit string of equal length. The length of the chromosome is determined by the number of anti-SPAM filtering rules. In this study the rules available in the SpamAssassin software public distributions that effectively match SpamAssassin email messages corpus is 330. Each rule is associated with a real value score in the [\u22125, 5] interval and a one bit in the chromosome. If the ith bit is 0 the ith rule is ignored, and otherwise the rule is considered by the SPAM classifier with the ith corresponding real value score (weight). Messages are classified as SPAM when the sum of the active rules that match the message is equal or greater than the threshold value of 5.\nConfiguration: The five (NSGA-II, SPEA2, SMS-EMOA, MOEA/D, 3DCH-EMOA) algorithms are set with a maximum of 25000 function evaluations as the experiment stopping criteria. The SBX single point crossover and polynomial bit flip mutation operators are applied in the experiments. The crossover probability of pc = 0.9 and a mutation probability of pm = 1/n where n is the number of anti-spam filtering rules. The population size is set to 100 for all algorithms, archive size 100 for SPEA2 and offset 100 for SMS-EMOA and 3DCH-EMOA. All of the algorithms are run 30 times independently.\n4) Results and analysis: The comparison of NSGA-II, MOEA/D, SPEA2, SMS-EMOA and 3DCHEMOA algorithms for the three objectives SPAM problem formulation is done with respect to the reference Pareto front, which is taken as a close approximation of the true Pareto front. The reference Pareto front is calculated as the best set of solutions of all algorithms achieved in all experimental runs.\nWe will first interpret this reference Pareto front shown in Fig. 19, Fig. 20 and Fig. 21, corresponding to ccr x fpr (classifier complexity ratio x false positive rate), ccr x fnr (classifier complexity ratio x false negative rate) and the three axis projections, respectively (all objectives are to be minimized).\nThe plots show the boundary between the dominated and non-dominated space (attainment curve). All values are percentages relative to the number of anti-SPAM filtering rules (330) and number of email messages (9349).\nFrom the plots we conclude that: 1) Even for a classifier using the maximal number of rules, the fnr could not be reduced to zero, but it got very close to it; 2) The fpr is almost exactly zero for SPAM filters that use only ca. 15% of the rules; 3) Using about 20% of the rules, the knee point solution is found. From then on, only marginal improvements are possible by adding more rules.\nIn summary, the adding of a third objective is particularly valuable because it can help to reduce the computational effort for the classification to ca. 20% of the effort when all rules are used, losing almost no performance. The second question is how close different algorithms get to the true Pareto front, here represented by the reference Pareto front. For this, one might look at Pareto fronts of each algorithm that have an average performance in VUS. Also, we can look at summary statistics on performance metrics, first and foremost on the VUS performance.\nThe performance statistics in Table VII, Fig. 22 and Fig. 23 indicate that the 3DCH-EMOA has clearly the best performance in the VUS metric and also it achieves a relative good SPREAD. Because the VUS metric is the most relevant to 3-D ROC optimization, it is recommended to use 3DCH-EMOA for finding Pareto front approximations for the 3-D anti-SPAM filtering problem. Interestingly, the results on the hypervolume metric, which is also a volume based indicator, are relatively bad for 3DCH-EMOA (Fig. 24). This shows that a good performance in the hypervolume metric does not coincide with a good performance in the VUS metric."}, {"heading": "VII. FEATURE SELECTION AND CLASSIFICATION", "text": "Feature selection is a data mining technique to mine useful information in the vast amount of information. Feature selection methods provide us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications [50].\nThese methods refer to the process of selecting descriptors that are most effective while reducing effects from noise or irrelevant variables and still provide good prediction results. Feature selection aims at reducing the number of given features to the subset of most useful features. To evaluate all the subsets of set with N feature, 2N evaluations are needed. The problem becomes an NP-hard problem as the number of features grows. Evolutionary algorithms have proved to be particularly useful to discover significant and meaningful information in large quantities of raw noisy data [51].\nA. Binary classification problem\nGenerally speaking, the more features in a dataset, the more information would be available for classification. However, because of some irrelevant and redundant features in the data set, not all of the features have a positive contribution for the classification process. Actually, reducing the number of features in a data set can lead to faster model training and to improve the performance of classifiers.\nThe feature selection problem for binary classification (\u2126, F ) can formally be defined as a multiobjective optimization problem: determine the feature set S as it is described in Eq. 16.\nminF (S) = (fpr, fnr, ccr)\nsubject to S \u2208 \u2126 (16) where \u2126 is the set of all possible feature subsets and S refers to feature subsets.\nBesides fpr and fnr for binary classifiers, we define the third objective as used features rate (ufr or ccr). The subset of features with lower ccr should be preferred given the same fpr and fnr. The computational cost of a classifier with higher ccr is considered to be higher than that with a lower ccr. It is possible to construct a classifier with different classifiers trained by subsets of features in 3-D ROC space by means of randomization, which has computation complexity between them [1].\n1) Data sets: Twenty-four data sets are selected from UCI repository [18] and described in Table VIII. Balanced and imbalanced benchmark data sets are included, and the number of instances of these data sets ranges from hundreds to thousands.\n2) Tested algorithms: To evaluate the performance of the new proposed method, comparisons with state of the art EMOAs such as NSGA-II, SPEA2 and SMS-EMOA were done. For classification performance comparison the C4.5 classifier was adopted. It is an algorithm used to generate a decision tree, proposed in [52], with an open source Java implementation (J48), available in the weka data mining tool [53]. 3) Configuration and Evaluation: Default parameters for problem formulation, experiments and algorithms settings were adopted.\nEncoding: We employed binary encoding scheme where the chromosome is a bit string. The length of the chromosome is determined by the number of features of the dataset. Each feature is associated with one bit in the chromosome. If the ith bit is 0 the ith feature is ignored, otherwise that feature is selected. Each chromosome represents a subset of features and a set of parameters of the classifier.\nConfiguration: All algorithms are run for 2000 classification evaluations. The single point crossover operator and bit flip mutation are applied in the experiments. The crossover probability of pc = 0.9 and a mutation probability of pm = 1/n where n is the number of variables. The population size is set to 20 for all algorithms and the size of SPEA2 archive is the 20 too. We apply each algorithm on each data set with five-fold cross-validation for 10 times independently. All experiments are based on jMetal [43] and Weka [53]. 4) Results and Analysis: The performance comparison of NSGA-II, SPEA2, SMS-EMOA and 3DCHEMOA on feature selection with UCI data sets is discussed here. The results include the plots of augmented ROC space and statistical analysis on VUS metric. The Pareto front of the feature selection result of vote data set is shown in Fig. 25 and the details are discussed below.\nThe reference Pareto front is shown in Fig. 25(e), which is obtained by putting the results of all different algorithms together. Some conclusions can be made from the reference Pareto front. The vote data set can obtain good performance with about 20% to 100% of features. The performance of the classification decreases slowly with the reduction of features from 100% to 20%. With less than 20% of the features a signification decrease in performance occurs. Only the new proposed method can obtain result similar\nwith reference Pareto front. The other algorithms missed the subsets with more than 45% of features. The new proposed algorithm is more useful in reality.\nThe statistical results (mean and standard deviation) of the VUS metric are shown in Table.IX. For most of the results, 3DCH-EMOA obtains the largest value of mean and small value of standard deviation, which shows that 3DCH-EMOA not only has good performance in convergence but also has good performance in stability. SPEA2 is the second best performing algorithm on most of data sets.\nB. Three-class classification\nIn this part, we focus on the feature selection for three-class classification problem. With the technique of iso-performance [1] we can obtain any classifiers on the surface of ROCCH. Generally, the larger value of the VUS the more diverse the set of classification will be. Ensemble learning is a powerful learning approach that combines multiple classifiers to build up more accurate classifier than each of the individual classifier [54]. The performance of ensemble learning always rely on the diversity of feature subset selection [55].\nFor three-class classification problem, we define the three objectives as far, fbr and fcr. The feature\nselection problem is described in Eq. 17.\nmaxF (S) = (tar, tbr, tcr)\nsubject to S \u2208 \u2126 (17) where \u2126 is the set of possible feature subsets, S refers to feature subsets.\nThe aim of three-class ROCCH maximization is to maximize the three objectives simultaneously. As the three objectives are in conflict with each other, the new proposed algorithm try to find the best trade-offs\namong them. It is possible to construct a classifier with two different classifiers with subsets of features in 3-D ROC space by means of randomization with the theory of iso-performance [1], which has computation complexity between the two classifiers.\n1) Data sets: Five data sets are selected from UCI repository [18] and described in Table X.\n2) Tested algorithms: Similarly to the previous section, NSGA-II, MOEA/D, SPEA2 are involved to make experimental comparisons, and C4.5 [52] is used with J48 Java open source implementation of weka data mining tool [53].\n3) Configuration and Evaluation: The goal of feature selection for three-class classification is to obtain large diverse subsets of features, which will lead to good performance of the classifiers ensemble. We use the VUS to measure the diversity of subsets of features in the 3-D ROC space.\nThe encoding of the chromosome and configuration of the algorithms are similarly to the presentation\nused in the previous Section VII-A.\n4) Results and Analysis: The performance comparison of NSGA-II, SPEA2, SMS-EMOA and 3DCHEMOA on feature selection for three-class classification with UCI data sets is discussed in this part. The results include the plots of 3-D ROC space and statistical analysis on VUS metric. The Pareto front of each algorithm of waveform data set are shown in Fig. 26, and the statistical results of the VUS are shown in Table.XI.\nBy comparing all the results we see the solutions of NSGA-II, SPEA2 and SMS-EMOA are centered on the surroundings of point (0,0,0), which means these algorithms do not have good performance on diversity. The new proposed method can obtain a solution space with higher value of VUS than others\nfor most of the results, which is shown in Table. XI. From the Fig. 26(d) we can see that the solutions of 3DCH-EMOA are more scattered than other algorithms, which results in good performance of ensemble learning."}, {"heading": "VIII. CONCLUSIONS AND FUTURE WORK", "text": "In this paper, we analyzed the properties of augmented and 3-D ROC. 3DCH-EMOA is proposed to optimize the performance of 3-D ROCCH for classification. In order to evaluate the performance of several evolutionary multiobjective algorithms two set of test problems, ZEJD and ZED were designed. 3DCHEMOA is compared with other EMOAs, such as NSGA-II, GDE3, SPEA2, MOEA/D and SMS-EMOA on ZEJD and ZED test problems. 3DCH-EMOA always obtain the best results not only in convergence but also in diversity. 3DCH-EMOA revealed a good ability to heal the dent in 3-D ROC space, which is really important in ROCCH maximization problems. We also applied this algorithm to the area of SPAM filtering optimization and feature selection. Extensive experimental studies compared the new proposed method with state-of-the-art approaches, proving that the proposed algorithm is promising and effective.\nHowever, the new proposed method is time consuming, because it needs to compute the VUS contribution of every point in the first priority level solutions. In the future, the dynamic convex hulls strategy\nwill be adapted to reduce the computational complexity."}, {"heading": "ACKNOWLEDGMENT", "text": "This work was partially supported by the National Basic Research Program (973 Program) of China (No. 2013CB329402), the National Natural Science Foundation of China (No. 61273317, 61271301, 61272279, 61001202, 61203303, 61003199 and 61003198), The Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project) (No. B07048), the National Research Foundation for the Doctoral Program of Higher Education of China (No. 20100203120008), the Program for Cheung Kong Scholars and Innovative Research Team in University (No. IRT1170), the Natural Science Basic Research Plan in Shaanxi Province of China (Program No.2014JM8301), and the European Union Seventh Framework Programme under Grant agreements (No. 247619) on Nature Inspired Computation and its Applications (NICaiA)."}], "references": [{"title": "An introduction to ROC analysis", "author": ["T. Fawcett"], "venue": "Pattern recognition letters, vol. 27, no. 8, pp. 861\u2013874, 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Medical decision making", "author": ["H.C. Sox", "M.C. Higgins", "D.K. Owens"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Signal detection theory and ROC analysis", "author": ["J.P. Egan"], "venue": "1975.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1975}, {"title": "Measuring the accuracy of diagnostic systems", "author": ["J.A. Swets"], "venue": "Science, vol. 240, no. 4857, pp. 1285\u20131293, 1988.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1988}, {"title": "A novel selection evolutionary strategy for constrained optimization", "author": ["L. Jiao", "L. Li", "R. Shang", "F. Liu", "R. Stolkin"], "venue": "Information Sciences, vol. 239, no. 1, pp. 122 \u2013 141, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "An evolutionary multi-objective approach to sparse reconstruction", "author": ["L. Li", "X. Yao", "R. Stolkin", "M. Gong", "S. He"], "venue": "IEEE Transactions on Evolutionary Computation, vol. PP, no. 99, pp. 1\u20131, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Convex hull-based multi-objective genetic programming for maximizing receiver operator characteristic performance", "author": ["P. Wang", "M. Emmerich", "R. Li", "K. Tang", "T. B\u00e4ck", "X. Yao"], "venue": "IEEE Transactions on Evolutionary Computation, vol. PP, no. 99, pp. 1\u20131, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "A simplified extension of the area under the ROC to the multiclass domain", "author": ["T. Landgrebe", "R. Duin"], "venue": "Seventeenth annual symposium of the pattern recognition association of South Africa. Citeseer, 2006.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Robust classification for imprecise environments", "author": ["F. Provost", "T. Fawcett"], "venue": "Machine Learning, vol. 42, no. 3, pp. 203\u2013231, 2001.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2001}, {"title": "Using rule sets to maximize ROC performance", "author": ["T. Fawcett"], "venue": "Data Mining, 2001. ICDM 2001, Proceedings IEEE International Conference on. IEEE, 2001, pp. 131\u2013138.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2001}, {"title": "Prie: a system for generating rulelists to maximize ROC performance", "author": ["T. Fawcett"], "venue": "Data Mining and Knowledge Discovery, vol. 17, no. 2, pp. 207\u2013224, 2008.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Repairing concavities in ROC curves.", "author": ["P.A. Flach", "S. Wu"], "venue": "in IJCAI. Citeseer,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Optimal ROC curve for a combination of classifiers.", "author": ["M. Barreno", "A.A. C\u00e1rdenas", "J.D. Tygar"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "A multi-objective genetic programming approach to developing pareto optimal decision trees", "author": ["H. Zhao"], "venue": "Decision Support Systems, vol. 43, no. 3, pp. 809\u2013826, 2007.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Multi-objective genetic programming for classification with unbalanced data", "author": ["U. Bhowan", "M. Zhang", "M. Johnston"], "venue": "AI 2009: Advances in Artificial Intelligence. Springer, 2009, pp. 370\u2013380.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Evolving diverse ensembles using genetic programming for classification with unbalanced data", "author": ["U. Bhowan", "M. Johnston", "M. Zhang", "X. Yao"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 17, no. 3, pp. 368\u2013386, 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Multiobjective genetic programming for maximizing ROC performance", "author": ["P. Wang", "K. Tang", "T. Weise", "E. Tsang", "X. Yao"], "venue": "Neurocomputing, vol. 125, pp. 102\u2013118, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "UCI machine learning repository", "author": ["K. Bache", "M. Lichman"], "venue": "2013. [Online]. Available: http://archive.ics.uci.edu/ml", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Note on the location of optimal classifiers in n-dimensional ROC space", "author": ["A. Srinivasan", "A. Srinivasan"], "venue": "Tech. Rep., 1999.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1999}, {"title": "On reoptimizing multi-class classifiers", "author": ["C. Bourke", "K. Deng", "S.D. Scott", "R.E. Schapire", "N.V. Vinodchandran"], "venue": "Machine Learning, vol. 71, pp. 219\u2013242, 2008.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Towards maximizing the area under the ROC curve for multi-class classification problems.", "author": ["K. Tang", "R. Wang", "T. Chen"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Volume under the ROC surface for multi-class problems", "author": ["C. Ferri", "J. Hern\u00e1ndez-Orallo", "M.A. Salido"], "venue": "Machine Learning: ECML 2003. Springer, 2003, pp. 108\u2013120.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2003}, {"title": "Efficient multiclass ROC approximation by decomposition via confusion matrix perturbation analysis", "author": ["T.C. Landgrebe", "R.P. Duin"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 30, no. 5, pp. 810\u2013822, 2008.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "The hypervolume under the ROC hypersurface of \u201cnear-guessing\u201d and \u201cnear-perfect\u201d observers in n-class classification tasks", "author": ["D.C. Edwards", "C.E. Metz", "R.M. Nishikawa"], "venue": "IEEE Transactions on Medical Imaging, vol. 24, no. 3, pp. 293\u2013299, 2005.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2005}, {"title": "Well Trained PETs: Improving Probability Estimation Trees", "author": ["F. Provost", "P. Domingos"], "venue": "CeDER Working Paper IS-00-04, Stern School of Business, New York Univ.,2001.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2001}, {"title": "A simple generalisation of the area under the ROC curve for multiple class classification problems", "author": ["D.J. Hand", "R.J. Till"], "venue": "Machine Learning, vol. 45, no. 2, pp. 171\u2013186, 2001.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2001}, {"title": "Evolving neural networks with maximum auc for imbalanced data classification", "author": ["X. Lu", "K. Tang", "X. Yao"], "venue": "Hybrid Artificial Intelligence Systems. Springer, 2010, pp. 335\u2013342.  32  ARXIV, COMPUTER SCIENCE, DECEMBER, 2014", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Comparing three-class diagnostic tests by three-way ROC analysis", "author": ["S. Dreiseitl", "L. Ohno-Machado", "M. Binder"], "venue": "Medical Decision Making, vol. 20, no. 3, pp. 323\u2013331, 2000.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2000}, {"title": "Three-way rocs", "author": ["D. Mossman"], "venue": "Medical Decision Making, vol. 19, no. 1, pp. 78\u201389, 1999.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1999}, {"title": "The multi-objective differential evolution algorithm based on quick convex hull algorithms", "author": ["J. Shan-Fan", "S.-W. Xiong", "J. Zhuo-Wang"], "venue": "Natural Computation, 2009. ICNC\u201909. Fifth International Conference on, vol. 4. IEEE, 2009, pp. 469\u2013473.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Convex hull ranking algorithm for multi-objective evolutionary algorithms", "author": ["M. Davoodi Monfared", "A. Mohades", "J. Rezaei"], "venue": "Scientia Iranica, vol. 18, no. 6, pp. 1435\u20131442, 2011.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "A new multi-objective evolutionary algorithm based on convex hull for binary classifier optimization", "author": ["M. Cococcioni", "P. Ducange", "B. Lazzerini", "F. Marcelloni"], "venue": "IEEE Congress on Evolutionary Computation, 2007. CEC 2007. IEEE, 2007, pp. 3150\u20133156.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2007}, {"title": "Multi-objective genetic fuzzy classifiers for imbalanced and cost-sensitive datasets", "author": ["P. Ducange", "B. Lazzerini", "F. Marcelloni"], "venue": "Soft Computing, vol. 14, no. 7, pp. 713\u2013728, 2010.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Relative deprivation and the gini coefficient", "author": ["S. Yitzhaki"], "venue": "The Quarterly Journal of Economics, pp. 321\u2013324, 1979.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1979}, {"title": "Muiltiobjective optimization using nondominated sorting in genetic algorithms", "author": ["N. Srinivas", "K. Deb"], "venue": "Evolutionary computation, vol. 2, no. 3, pp. 221\u2013248, 1994.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1994}, {"title": "A fast and elitist multiobjective genetic algorithm: NSGA-II", "author": ["K. Deb", "A. Pratap", "S. Agarwal", "T. Meyarivan"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 6, no. 2, pp. 182\u2013197, 2002.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2002}, {"title": "The quickhull algorithm for convex hulls", "author": ["C.B. Barber", "D.P. Dobkin", "H. Huhdanpaa"], "venue": "ACM Transactions on Mathematical Software (TOMS), vol. 22, no. 4, pp. 469\u2013483, 1996.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1996}, {"title": "SMS-EMOA: Multiobjective selection based on dominated hypervolume", "author": ["N. Beume", "B. Naujoks", "M. Emmerich"], "venue": "European Journal of Operational Research, vol. 181, no. 3, pp. 1653\u20131669, 2007.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2007}, {"title": "GDE3: The third evolution step of generalized differential evolution", "author": ["S. Kukkonen", "J. Lampinen"], "venue": "Evolutionary Computation, 2005. The 2005 IEEE Congress on, vol. 1. IEEE, 2005, pp. 443\u2013450.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2005}, {"title": "SPEA2: Improving the strength pareto evolutionary algorithm", "author": ["E. Zitzler", "M. Laumanns", "L. Thiele", "E. Zitzler", "E. Zitzler", "L. Thiele", "L. Thiele"], "venue": "TIK-Report 103, Department of Electrical Engineering, Swiss Federal Institute of Technology (ETH), 2001.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2001}, {"title": "MOEA/D: A multiobjective evolutionary algorithm based on decomposition", "author": ["Q. Zhang", "H. Li"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 11, no. 6, pp. 712\u2013731, 2007.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2007}, {"title": "The JMetal framework for multi-objective optimization: Design and architecture", "author": ["J. Durillo", "A. Nebro", "E. Alba"], "venue": "CEC 2010, Barcelona, Spain, July 2010, pp. 4138\u20134325.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2010}, {"title": "jMetal: A java framework for multi-objective optimization", "author": ["J.J. Durillo", "A.J. Nebro"], "venue": "Advances in Engineering Software, vol. 42, pp. 760\u2013771, 2011. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0965997811001219", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2011}, {"title": "Four Results on Randomized Incremental Constructions", "author": ["K.L. Clarkson", "K. Mehlhorn", "R. Seidel"], "venue": "Computational Geometry: Theory and Applications, vol. 3, pp. 185\u2013212, 1993.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1993}, {"title": "Anti-spam multiobjective genetic algorithms optimization analysis", "author": ["V. Basto-Fernandes", "I. Yevseyeva", "J.R.M\u00e9ndez"], "venue": "International Resource Management Journal, vol. 26, pp. 54\u201367, 2012.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2012}, {"title": "Optimising anti-spam filters with evolutionary algorithms", "author": ["I. Yevseyeva", "V. Basto-Fernandes", "D. Ruano-Ord\u00e1s", "J.R. M\u00e9ndez"], "venue": "Expert Systems with Applications, vol. 40, no. 10, pp. 4010\u20134021, 2013.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2013}, {"title": "Ockham\u2019s razor: A historical and philosophical analysis of Ockham\u2019s principle of parsimony", "author": ["R. Ariew"], "venue": "1976.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 1976}, {"title": "The apache spamassassin project", "author": ["Internet"], "venue": "2006. [Online]. Available: http://spamassassin.apache.org/publiccorpus", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2006}, {"title": "A survey on feature selection methods", "author": ["G. Chandrashekar", "F. Sahin"], "venue": "Computers & Electrical Engineering, vol. 40, no. 1, pp. 16 \u2013 28, 2014, 40th-year commemorative issue.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2014}, {"title": "A survey of multiobjective evolutionary algorithms for data mining: Part I", "author": ["A. Mukhopadhyay", "U. Maulik", "S. Bandyopadhyay", "C. Coello Coello"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 18, no. 1, pp. 4\u201319, Feb 2014.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2014}, {"title": "C4.5: programs for machine learning", "author": ["J.R. Quinlan"], "venue": null, "citeRegEx": "52", "shortCiteRegEx": "52", "year": 1993}, {"title": "The WEKA data mining software: An update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "SIGKDD Explorations, vol. 11, pp. 9\u201318, 2009.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2009}, {"title": "A review on ensembles for the class imbalance problem: Bagging-, boosting-, and hybrid-based approaches", "author": ["M. Galar", "A. Fernandez", "E. Barrenechea", "H. Bustince", "F. Herrera"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews, vol. 42, no. 4, pp. 463\u2013484, July 2012.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2012}, {"title": "Training ensemble of diverse classifiers on feature subsets", "author": ["R. Gupta", "K. Audhkhasi", "S. Narayanan"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), May 2014, pp. 2927\u20132931.", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "The receiver operating characteristic (ROC) graph is a technique for visualizing, organizing and selecting classifiers based on their performance [1].", "startOffset": 146, "endOffset": 149}, {"referenceID": 1, "context": "Originating from the field of object classification in radar images, ROC analysis has become increasingly important in many other areas with cost sensitive classification and/or unbalanced data distribution, such as medical decision making [2], signal detection [3], diagnostic systems [4].", "startOffset": 240, "endOffset": 243}, {"referenceID": 2, "context": "Originating from the field of object classification in radar images, ROC analysis has become increasingly important in many other areas with cost sensitive classification and/or unbalanced data distribution, such as medical decision making [2], signal detection [3], diagnostic systems [4].", "startOffset": 262, "endOffset": 265}, {"referenceID": 3, "context": "Originating from the field of object classification in radar images, ROC analysis has become increasingly important in many other areas with cost sensitive classification and/or unbalanced data distribution, such as medical decision making [2], signal detection [3], diagnostic systems [4].", "startOffset": 286, "endOffset": 289}, {"referenceID": 0, "context": "More recently, research has drawn attention to ROC convex hull (ROCCH) analysis that covers potentially optimal points for a given set of classifiers [1].", "startOffset": 150, "endOffset": 153}, {"referenceID": 4, "context": "Some evolutionary multiobjective optimization algorithms (EMOAs) [5] have been applied to machine learning and image processing areas [6].", "startOffset": 65, "endOffset": 68}, {"referenceID": 5, "context": "Some evolutionary multiobjective optimization algorithms (EMOAs) [5] have been applied to machine learning and image processing areas [6].", "startOffset": 134, "endOffset": 137}, {"referenceID": 6, "context": "[7], who showed that the proposed algorithm, CH-EMOA, is capable to show a strong performance for improving ROCCH with respect to AUC as compared to using state-of-the-art EMOAs (NSGA-II [36], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]) for the same task.", "startOffset": 0, "endOffset": 3}, {"referenceID": 35, "context": "[7], who showed that the proposed algorithm, CH-EMOA, is capable to show a strong performance for improving ROCCH with respect to AUC as compared to using state-of-the-art EMOAs (NSGA-II [36], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]) for the same task.", "startOffset": 187, "endOffset": 191}, {"referenceID": 39, "context": "[7], who showed that the proposed algorithm, CH-EMOA, is capable to show a strong performance for improving ROCCH with respect to AUC as compared to using state-of-the-art EMOAs (NSGA-II [36], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]) for the same task.", "startOffset": 199, "endOffset": 203}, {"referenceID": 40, "context": "[7], who showed that the proposed algorithm, CH-EMOA, is capable to show a strong performance for improving ROCCH with respect to AUC as compared to using state-of-the-art EMOAs (NSGA-II [36], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]) for the same task.", "startOffset": 212, "endOffset": 216}, {"referenceID": 37, "context": "[7], who showed that the proposed algorithm, CH-EMOA, is capable to show a strong performance for improving ROCCH with respect to AUC as compared to using state-of-the-art EMOAs (NSGA-II [36], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]) for the same task.", "startOffset": 231, "endOffset": 235}, {"referenceID": 7, "context": "A simplified ROC is estimated from a three-class classifier by only considering the rate of every correctly classified category [8], which ensures that good classifiers tend to result in better ROCCH than poorer ones.", "startOffset": 128, "endOffset": 131}, {"referenceID": 35, "context": "3DCH-EMOA is compared with state-of-the-art EMOAs such as NSGA-II [36], GDE3 [39], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]on the test problems.", "startOffset": 66, "endOffset": 70}, {"referenceID": 38, "context": "3DCH-EMOA is compared with state-of-the-art EMOAs such as NSGA-II [36], GDE3 [39], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]on the test problems.", "startOffset": 77, "endOffset": 81}, {"referenceID": 39, "context": "3DCH-EMOA is compared with state-of-the-art EMOAs such as NSGA-II [36], GDE3 [39], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]on the test problems.", "startOffset": 89, "endOffset": 93}, {"referenceID": 40, "context": "3DCH-EMOA is compared with state-of-the-art EMOAs such as NSGA-II [36], GDE3 [39], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]on the test problems.", "startOffset": 102, "endOffset": 106}, {"referenceID": 37, "context": "3DCH-EMOA is compared with state-of-the-art EMOAs such as NSGA-II [36], GDE3 [39], SPEA2 [40], MOEA/D [41], and SMS-EMOA [38]on the test problems.", "startOffset": 121, "endOffset": 125}, {"referenceID": 8, "context": "ROCCH maximization problems were first described in [9].", "startOffset": 52, "endOffset": 55}, {"referenceID": 0, "context": "One approach is to identify portions of the ROCCH to use iso-performance lines [1] that are translated from operating conditions of classifiers.", "startOffset": 79, "endOffset": 82}, {"referenceID": 9, "context": "In addition, a rule learning mechanism is described in [10] and in [11].", "startOffset": 55, "endOffset": 59}, {"referenceID": 10, "context": "In addition, a rule learning mechanism is described in [10] and in [11].", "startOffset": 67, "endOffset": 71}, {"referenceID": 11, "context": "In [12], a method for detecting and repairing concavities in ROC curves is studied.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "The Neyman-Pearson lemma is introduced to the context of ROCCH in [13], which is the theoretical basis for finding the optimal combination of classifiers to maximize the ROCCH.", "startOffset": 66, "endOffset": 70}, {"referenceID": 11, "context": "This method not only focuses on repairing the concavity but it also improves the ROC curve, which is different with [12].", "startOffset": 116, "endOffset": 120}, {"referenceID": 10, "context": "More recently, ROCCER was proposed in [11].", "startOffset": 38, "endOffset": 42}, {"referenceID": 13, "context": "In [14], non-dominated decision trees were developed, which are used to support the decision which classifier to choose.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "The Pareto front of multiobjective genetic programming is used to maximize the accuracy of each minority class with unbalanced data set in [15].", "startOffset": 139, "endOffset": 143}, {"referenceID": 15, "context": "Moreover, in [16], the technique of multiobjective optimization genetic programming is employed to evolve diverse ensembles to maximize the classification performance for unbalanced data.", "startOffset": 13, "endOffset": 17}, {"referenceID": 16, "context": "Some more evolutionary multiobjective optimization algorithms (EMOAs) have been combined with genetic programming to maximize ROC performance in [17].", "startOffset": 145, "endOffset": 149}, {"referenceID": 6, "context": "This is done in convex hull multiobjective genetic programming (CH-MOGP), which is proposed in [7].", "startOffset": 95, "endOffset": 98}, {"referenceID": 17, "context": "It has been compared to other state-of-the-art methods and showed the best performance for binary classifiers on the UCI benchmark [18].", "startOffset": 131, "endOffset": 135}, {"referenceID": 7, "context": "The area under the ROC convex hull (AUC) has become a standard performance evaluation criterion in binary pattern recognition problems and it has been widely used to compare different classifiers independently of priors of distribution and costs of misclassification [8].", "startOffset": 267, "endOffset": 270}, {"referenceID": 18, "context": "The ROC curve is extended to multi-class classification problems in [19].", "startOffset": 68, "endOffset": 72}, {"referenceID": 19, "context": ", [20]) that comprises the non-dominated boundary of the convex hull in n-dimensional ROC space.", "startOffset": 2, "endOffset": 6}, {"referenceID": 19, "context": "It has been shown that a multi-class classifier with good ROC hyper-surface can lead to classifiers suitable for various class distributions and misclassification costs via re-optimization of its output matrix [20].", "startOffset": 210, "endOffset": 214}, {"referenceID": 20, "context": "However, due to the increase of the dimensionality of the ROC space, achieving the optimal ROC hyper-surface is even more difficult than achieving the optimal ROC curve [21].", "startOffset": 169, "endOffset": 173}, {"referenceID": 21, "context": "A straightforward way to generalize AUC is the volume under the ROC (a surface in 3-D and a hyper-surface in n-D) surface (VUS) [22].", "startOffset": 128, "endOffset": 132}, {"referenceID": 22, "context": "Methods from computational geometry can be used to efficiently compute the VUS, but, as compared to the 2-D case, this is relatively complicated [23].", "startOffset": 145, "endOffset": 149}, {"referenceID": 23, "context": "Moreover, the VUS value of a \u201cnear guessing\u201d classifier is almost the same as a \u201cnear perfect\u201d classifier for more than two classes (see [24]).", "startOffset": 137, "endOffset": 141}, {"referenceID": 7, "context": "However, alternative definitions of VUS have been proposed where this problem does not occur [8].", "startOffset": 93, "endOffset": 96}, {"referenceID": 24, "context": "all strategy) in [25], turning the problem to a problem that considers a set of binary classifiers.", "startOffset": 17, "endOffset": 21}, {"referenceID": 25, "context": "In [26], multi-class area under convex hull (MAUC) has been proposed as a simpler generalization of AUC for multi-class classification problems.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "MAUC has been widely used in recent work [21], [27].", "startOffset": 41, "endOffset": 45}, {"referenceID": 26, "context": "MAUC has been widely used in recent work [21], [27].", "startOffset": 47, "endOffset": 51}, {"referenceID": 7, "context": "This leads to a quadratically growing number of required comparisons in the number of classes [8].", "startOffset": 94, "endOffset": 97}, {"referenceID": 27, "context": "The VUS of three-class classifiers has been studied in [28] and [29].", "startOffset": 55, "endOffset": 59}, {"referenceID": 28, "context": "The VUS of three-class classifiers has been studied in [28] and [29].", "startOffset": 64, "endOffset": 68}, {"referenceID": 7, "context": "The simplified ROC is estimated from a multiclass classifier by only considering the rate of every correctly classified category [8], which ensures that good classifiers tend to result in better VUS than bad classifiers.", "startOffset": 129, "endOffset": 132}, {"referenceID": 7, "context": "In this paper, we therefore focus on finding (sets of) classifiers with optimal VUS considering the simplified ROC proposed in [8].", "startOffset": 127, "endOffset": 130}, {"referenceID": 29, "context": "[30], [31]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[30], [31]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 31, "context": "In [32] a multiobjective evolutionary algorithm based on the properties of the convex hulls defined in the 2-D ROC space was proposed, which was applied to determine a set of fuzzy rule-based binary classifiers with different trade-offs between false positive rate (fpr) and true positive rate (tpr).", "startOffset": 3, "endOffset": 7}, {"referenceID": 32, "context": "NSGA-II was used to generate an approximation of a Pareto front composed of genetic fuzzy classifiers with different trade-offs among sensitivity, specificity, and interpretability in [33].", "startOffset": 184, "endOffset": 188}, {"referenceID": 16, "context": "discuss the optimization of binary classifiers based on receiver operator characteristic [17].", "startOffset": 89, "endOffset": 93}, {"referenceID": 7, "context": "The problem is simplified by only considering the diagonal elements of the matrix in [8].", "startOffset": 85, "endOffset": 88}, {"referenceID": 0, "context": "6 are surface functions which are named as iso-performance surface in ROC analysis theory [1].", "startOffset": 90, "endOffset": 93}, {"referenceID": 0, "context": "The way to find a desired optimal classifier is similar to ROCCH for binary classifiers which is described in [1].", "startOffset": 110, "endOffset": 113}, {"referenceID": 33, "context": "The gini coefficient [34] is used to evaluate the uniformity of the solution of the test functions in this paper, and the details will be discussed later.", "startOffset": 21, "endOffset": 25}, {"referenceID": 6, "context": "\u03bd and \u03bc are incomparable if \u03bd and \u03bc do not dominate each other [7].", "startOffset": 63, "endOffset": 66}, {"referenceID": 16, "context": "The Pareto front is the set of all objective vectors of points in PS in objective space PF = {F (x) | x \u2208 PS} [17].", "startOffset": 110, "endOffset": 114}, {"referenceID": 6, "context": "A special approach based on ROCCH is proposed in [7] to solve the ROC maximization problem for binary classification.", "startOffset": 49, "endOffset": 52}, {"referenceID": 6, "context": "While in [7] binary classifiers were considered, here we consider complexity augmented binary classifiers and three-class classifiers and in the context of 3-D ROCCH multiobjective maximization.", "startOffset": 9, "endOffset": 12}, {"referenceID": 6, "context": "Firstly, 3-D convex hull (3DCH) based sorting without redundancy approach is used to rank the individuals into several priority levels as proposed in [7].", "startOffset": 150, "endOffset": 153}, {"referenceID": 6, "context": "Thirdly, a non-descending (\u03bc + 1) selection strategy is employed in this paper, rather than the approximate (\u03bc + \u03bc) scheme in CH-MOGP [7].", "startOffset": 134, "endOffset": 137}, {"referenceID": 36, "context": "The 3-D convex hull is built by the quickhull algorithm which is proposed in [37].", "startOffset": 77, "endOffset": 81}, {"referenceID": 6, "context": "Convex hull based sorting without redundancy strategy was first proposed in [7], which has a good performance to deal with binary classification problems.", "startOffset": 76, "endOffset": 79}, {"referenceID": 36, "context": "The 3-D quickhull algorithm [37] is adopted to build the convex hull with the candidate points set, which is widely used in 3-D convex hull related applications.", "startOffset": 28, "endOffset": 32}, {"referenceID": 36, "context": "Ensure: 3DCH based sorting without redundancy 1: Q = Qr +Qnr 2: T = Qnr \u222aR 3: F0 = 3D quickhull algorithm(T) [37] 4: Qnr = Qnr \u2212 F0 5: i=1 6: while Qnr = \u2205 do 7: T = Qnr \u222aR 8: Fi = 3D quickhull algorithm(T) 9: Qnr = Qnr \u2212 Fi 10: i = i+ 1 11: end while 12: Fi = Qr 13: return the ranked solution set F", "startOffset": 109, "endOffset": 113}, {"referenceID": 37, "context": "We hypothesize that the new VUS contribution indicator is a more efficient strategy to maximize the volume under the 3-D convex hull when compared to the hyper-volume based contribution [38] or crowding distance indicator [36].", "startOffset": 186, "endOffset": 190}, {"referenceID": 35, "context": "We hypothesize that the new VUS contribution indicator is a more efficient strategy to maximize the volume under the 3-D convex hull when compared to the hyper-volume based contribution [38] or crowding distance indicator [36].", "startOffset": 222, "endOffset": 226}, {"referenceID": 36, "context": "Algorithm 2 \u2206VUS(Qnr, R) Require: Qnr = \u2205 Qnr is the non-redundancy solution set R is a reference points set Ensure: \u2206VUS 1: m = sizeof(Qnr) 2: P = Qnr \u222aR 3: V olumeall = V US(P ) [37] 4: for all i=1:m do 5: qi \u2190 Qnr(i) 6: \u2206V USi = V olumeall \u2212 V US(P \u2212 {qi}) 7: end for 8: return \u2206VUS", "startOffset": 180, "endOffset": 184}, {"referenceID": 16, "context": "The scheme of a (\u03bc+ 1) evolutionary algorithm is adopted within 3DCHEMOA to maximize the ROC performance, rather than the (\u03bc+\u03bc) scheme used in CH-MOGP [17], which causes the algorithm to converge too quickly.", "startOffset": 151, "endOffset": 155}, {"referenceID": 35, "context": "EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS In this section, ZEJD and ZED test functions are designed to test the performance of 3DCH-EMOA and several other EMOAs, such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA/D [41].", "startOffset": 186, "endOffset": 190}, {"referenceID": 38, "context": "EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS In this section, ZEJD and ZED test functions are designed to test the performance of 3DCH-EMOA and several other EMOAs, such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA/D [41].", "startOffset": 197, "endOffset": 201}, {"referenceID": 37, "context": "EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS In this section, ZEJD and ZED test functions are designed to test the performance of 3DCH-EMOA and several other EMOAs, such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA/D [41].", "startOffset": 212, "endOffset": 216}, {"referenceID": 39, "context": "EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS In this section, ZEJD and ZED test functions are designed to test the performance of 3DCH-EMOA and several other EMOAs, such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA/D [41].", "startOffset": 224, "endOffset": 228}, {"referenceID": 40, "context": "EXPERIMENTAL STUDIES ON ARTIFICIAL TEST FUNCTIONS In this section, ZEJD and ZED test functions are designed to test the performance of 3DCH-EMOA and several other EMOAs, such as NSGA-II [36], GDE3 [39], SMS-EMOA [38], SPEA2 [40], MOEA/D [41].", "startOffset": 237, "endOffset": 241}, {"referenceID": 0, "context": "The range of variation of each object is in [0,1], the problem of ZEJD1 is defined in Eq.", "startOffset": 44, "endOffset": 49}, {"referenceID": 0, "context": "where x1, x2, x3 are all in [0, 1] and f1, f2, f3 are all in [0, 1].", "startOffset": 28, "endOffset": 34}, {"referenceID": 0, "context": "where x1, x2, x3 are all in [0, 1] and f1, f2, f3 are all in [0, 1].", "startOffset": 61, "endOffset": 67}, {"referenceID": 0, "context": "The objectives of both ZEJD2 and ZEJD3 are f1, f2 and f3, f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 63, "endOffset": 69}, {"referenceID": 0, "context": "The objectives of both ZEJD2 and ZEJD3 are f1, f2 and f3, f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 76, "endOffset": 82}, {"referenceID": 0, "context": "The objectives of both ZEJD2 and ZEJD3 are f1, f2 and f3, f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 89, "endOffset": 95}, {"referenceID": 0, "context": "The range of variation of each objective is in [0,1], the problem of ZED1 is defined in Eq.", "startOffset": 47, "endOffset": 52}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 24, "endOffset": 30}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 37, "endOffset": 43}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 53, "endOffset": 59}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 66, "endOffset": 72}, {"referenceID": 0, "context": "where x1 \u2208 [0, 1], x2 \u2208 [0, 1], x3 \u2208 [0, 1] and f1 \u2208 [0, 1], f2 \u2208 [0, 1], f3 \u2208 [0, 1].", "startOffset": 79, "endOffset": 85}, {"referenceID": 0, "context": "The objectives of both ZED2 and ZED3 are f1, f2 and f3, all of the objectives are in [0, 1].", "startOffset": 85, "endOffset": 91}, {"referenceID": 33, "context": "The gini coefficient is commonly used as a measure of statistical dispersion intended to represent the income distribution of a nation\u2019s residents [34].", "startOffset": 147, "endOffset": 151}, {"referenceID": 41, "context": "All of the experiments are based on jMetal framework [42], [43].", "startOffset": 53, "endOffset": 57}, {"referenceID": 42, "context": "All of the experiments are based on jMetal framework [42], [43].", "startOffset": 59, "endOffset": 63}, {"referenceID": 43, "context": "The dynamic convex hulls algorithm [44] will be adapted in future work to reduce the computational complexity of the new method.", "startOffset": 35, "endOffset": 39}, {"referenceID": 44, "context": "SPAM multiobjective problem formulation SPAM filtering problem optimization has been addressed by the techniques surveyed in [45], [46].", "startOffset": 125, "endOffset": 129}, {"referenceID": 45, "context": "SPAM multiobjective problem formulation SPAM filtering problem optimization has been addressed by the techniques surveyed in [45], [46].", "startOffset": 131, "endOffset": 135}, {"referenceID": 45, "context": "In previous work on anti-SPAM filter optimization [46] it was observed that many rules were not participating in the classification process and some (with very small weights) only marginally influenced the classification results.", "startOffset": 50, "endOffset": 54}, {"referenceID": 46, "context": "This principle states, in one of its simplified formulations, that unnecessary assumptions for a theory (conclusion) should not be considered if they have no consequence for the conclusion [47].", "startOffset": 189, "endOffset": 193}, {"referenceID": 47, "context": "The SpamAssassin corpus used in our experiments is composed of 9349 email messages, 2398 SPAM and 6951 legitimate messages [49].", "startOffset": 123, "endOffset": 127}, {"referenceID": 47, "context": "2) Algorithms Involved: Five reference multiobjective algorithms were tested (NSGA-II, SPEA2, MOEA/D, SMS-EMOA and 3DCH-EMOA), for the three objectives anti-SPAM filtering problem formulation, using the SpamAssassin corpus [49] for SPAM classification quality assessment.", "startOffset": 223, "endOffset": 227}, {"referenceID": 42, "context": "Experiments were performed with jMetal [43], an optimization framework for the development of multiobjective metaheuristics in Java.", "startOffset": 39, "endOffset": 43}, {"referenceID": 48, "context": "Feature selection methods provide us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications [50].", "startOffset": 202, "endOffset": 206}, {"referenceID": 49, "context": "Evolutionary algorithms have proved to be particularly useful to discover significant and meaningful information in large quantities of raw noisy data [51].", "startOffset": 151, "endOffset": 155}, {"referenceID": 0, "context": "It is possible to construct a classifier with different classifiers trained by subsets of features in 3-D ROC space by means of randomization, which has computation complexity between them [1].", "startOffset": 189, "endOffset": 192}, {"referenceID": 17, "context": "1) Data sets: Twenty-four data sets are selected from UCI repository [18] and described in Table VIII.", "startOffset": 69, "endOffset": 73}, {"referenceID": 50, "context": "It is an algorithm used to generate a decision tree, proposed in [52], with an open source Java implementation (J48), available in the weka data mining tool [53].", "startOffset": 65, "endOffset": 69}, {"referenceID": 51, "context": "It is an algorithm used to generate a decision tree, proposed in [52], with an open source Java implementation (J48), available in the weka data mining tool [53].", "startOffset": 157, "endOffset": 161}, {"referenceID": 42, "context": "All experiments are based on jMetal [43] and Weka [53].", "startOffset": 36, "endOffset": 40}, {"referenceID": 51, "context": "All experiments are based on jMetal [43] and Weka [53].", "startOffset": 50, "endOffset": 54}, {"referenceID": 0, "context": "With the technique of iso-performance [1] we can obtain any classifiers on the surface of ROCCH.", "startOffset": 38, "endOffset": 41}, {"referenceID": 52, "context": "Ensemble learning is a powerful learning approach that combines multiple classifiers to build up more accurate classifier than each of the individual classifier [54].", "startOffset": 161, "endOffset": 165}, {"referenceID": 53, "context": "The performance of ensemble learning always rely on the diversity of feature subset selection [55].", "startOffset": 94, "endOffset": 98}, {"referenceID": 0, "context": "It is possible to construct a classifier with two different classifiers with subsets of features in 3-D ROC space by means of randomization with the theory of iso-performance [1], which has computation complexity between the two classifiers.", "startOffset": 175, "endOffset": 178}, {"referenceID": 17, "context": "1) Data sets: Five data sets are selected from UCI repository [18] and described in Table X.", "startOffset": 62, "endOffset": 66}, {"referenceID": 50, "context": "5 [52] is used with J48 Java open source implementation of weka data mining tool [53].", "startOffset": 2, "endOffset": 6}, {"referenceID": 51, "context": "5 [52] is used with J48 Java open source implementation of weka data mining tool [53].", "startOffset": 81, "endOffset": 85}], "year": 2014, "abstractText": "Finding a good classifier is a multiobjective optimization problem with different error rates and the costs to be minimized. The receiver operating characteristic is widely used in the machine learning community to analyze the performance of parametric classifiers or sets of Pareto optimal classifiers. In order to directly compare two sets of classifiers the area (or volume) under the convex hull can be used as a scalar indicator for the performance of a set of classifiers in receiver operating characteristic space. Recently, the convex hull based multiobjective genetic programming algorithm was proposed and successfully applied to maximize the convex hull area for binary classification problems. The contribution of this paper is to extend this algorithm for dealing with higher dimensional problem formulations. In particular, we discuss problems where parsimony (or classifier complexity) is stated as a third objective and multi-class classification with three different true classification rates to be maximized. The design of the algorithm proposed in this paper is inspired by indicator-based evolutionary algorithms, where first a performance indicator for a solution set is established and then a selection operator is designed that complies with the performance indicator. In this case, the performance indicator will be the volume under the convex hull. The algorithm is tested and analyzed in a proof of concept study on different benchmarks that are designed for measuring its capability to capture relevant parts of a convex hull. Further benchmark and application studies on email classification and feature selection round up the analysis and assess robustness and usefulness of the new algorithm in real world settings.", "creator": "cairo 1.13.1 (http://cairographics.org)"}}}