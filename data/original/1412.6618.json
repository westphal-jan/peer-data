{"id": "1412.6618", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2014", "title": "Permutohedral Lattice CNNs", "abstract": "This paper presents a convolutional layer that is able to process sparse input features. As an example, for image recognition problems this allows an efficient filtering of signals that do not lie on a dense grid (like pixel position), but of more general features (such as color values). The presented algorithm makes use of the permutohedral lattice data structure. The permutohedral lattice was introduced to efficiently implement a bilateral filter, a commonly used image processing operation. Its use allows for a generalization of the convolution type found in current (spatial) convolutional network architectures.", "histories": [["v1", "Sat, 20 Dec 2014 07:08:54 GMT  (29kb)", "https://arxiv.org/abs/1412.6618v1", null], ["v2", "Thu, 26 Feb 2015 14:16:58 GMT  (31kb)", "http://arxiv.org/abs/1412.6618v2", null], ["v3", "Sun, 3 May 2015 11:26:34 GMT  (32kb)", "http://arxiv.org/abs/1412.6618v3", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["martin kiefel", "varun jampani", "peter v gehler"], "accepted": true, "id": "1412.6618"}, "pdf": {"name": "1412.6618.pdf", "metadata": {"source": "CRF", "title": "PERMUTOHEDRAL LATTICE CNNS", "authors": ["Martin Kiefel", "Varun Jampani"], "emails": ["peter.gehler}@tuebingen.mpg.de"], "sections": [{"heading": null, "text": "ar X\niv :1\n41 2.\n66 18\nv3 [\ncs .C\nV ]\n3 M\nay 2\n01 5"}, {"heading": "1 INTRODUCTION", "text": "In the domain of image recognition, the convolutional layer of a CNN today is almost exclusively associated with a spatial convolution in the image domain. In this work we will take a more signal theoretic viewpoint of the convolutional operation and present an algorithm that allows to process also sparse input data. This work is inspired by the use of special data structures (Adams et al., 2010) for bilateral filters (Aurich & Weule, 1995; Smith & Brady, 1997; Tomasi & Roberto, 1998) and generalizes it for the use of convolutional architectures.\nAlthough the approach presented here is more general, the following two scenarios are instructive. Consider that at training time we have access to full resolution images to train a classifier. At test time only a random number of pixels from the test image is available. In other words, we sample the signal differently during training and test time. For a traditional CNN this would require a preprocessing step, for example to map from subsets of pixels to a dense grid that is the image. In our view there is no change, it is not required that we have a dense grid and access to all pixels of the image. That is the integration domain does not change. This is one example of sparsity, here we deal with a set of pixels, whose values are RGB and features are position. Similarly, color information can be used to define the filtering operation as well. One can devise a convolution with a domain respecting color and location information (or color alone). One view from the image processing community is that of an edge-aware filter, the filter will be adaptive to the color and/or gradient of the image. RGB values do not lie on a regular dense grid, therefore a direct expansion of the spatial convolution is not applicable.\nThis approach falls into line with the view on encoding invariants (Mallat, 2012). It is possible to encode our knowledge invariants that we have about the data with the new way of looking at the data. Encoded in a spatial convolution is the prior knowledge about translation invariance. How to encode roation invariance, how similarity in color space? In the view we take here these are simply convolutions over different domains. A grid based convolution cannot easily be used to work with the sparse data (an interpolation might be needed) but the permutohedral lattice provides the right space and allows efficient implementations. Therefore the runtime is comparable to the ones of spatial convolutions, depending on the size of the invariants to include and can simply be used as a replacement of the traditional layers."}, {"heading": "2 PERMUTOHEDRAL LATTICE CONVOLUTION", "text": "We propose a convolution operation of a d-dimensional input space that entirely works on a lattice. Input data is a tuple (fi, vi) of feature locations fi \u2208 Rd and corresponding signal values vi \u2208\nR. Importantly, this does not assume the feature locations fi to be sampled on a regular grid, for example fi can be position and RGB value. We then map the input signal to a regular structure, the so-called permutohedral lattice. A convolution then operates on the constructed lattice and the result is mapped back to the output space. Hence, the entire operation consists of three stages (see fig. 1): splat (the mapping to the lattice space), convolution and slice (the mapping back from the lattice). This strategy has already been used to implement fast Gaussian filtering (Paris & Durand, 2009; Adams et al., 2010; 2009). Here we generalize it to arbitrary convolutions.\nThe permutohedral lattice is the result of the projection of the set Zd+1 onto a plane defined by its orthogonal vector 1 \u2208 Rd+1. This d dimensional plane is embedded into Rd+1. The lattice points tessellate the subspace with regular cells. Given a point from the embedding space, it is efficient to find the enclosing simplex of the projection onto the plane. We will represent a sparse set of points from Rd by a sparse set of simplex corners in the lattice. Importantly, the number of corners does not grow exponentially with the dimension d as it would for an axis-align simplex representation. We continue to describe the different parts of the permutohedral convolution.\nThe splat and slice operations take the role of an interpolation between the different signal representations. All input samples that belong to a cell adjacent to lattice point j are summed up and weighted with the barycentric coordinates to calculate the value lj = \u2211 i\u2208C(j) bi,jvi. This is the splatting operation. The barycentric coordinates bi,j depend on both the corner point j and the feature location fi. The reverse operation slice finds an output value v\u2032k by using its barycentric coordinates inside the lattice simplex and sums over the corner points v\u2032k = \u2211 j\u2208C(k) bk,j l \u2032 j .\nThe convolution is then performed on the permutohedral lattice. It uses a convolution kernel wn to compute l\u2032j\u2032 = \u2211 (n,j)\u2208N(j\u2032) wnlj . The convolution kernel wn is problem specific and its domain is restricted to the set of neighboring lattice points N(j). For bilateral filters, this is set to be a Gaussian filter, here we learn the kernel values using back-propagation.\nThe size of the neighborhood takes a similar role as the filter size (spatial extent) of the grid-based CNN. A transitional convolutional kernel which considers s sampled points to either side has (2s+ 1)d \u2208 O(sd) parameters. A comparable filter on the permutohedral lattice with a s neighborhood has (s+ 1)d+1 \u2212 sd+1 \u2208 O(sd) elements."}, {"heading": "3 SPARSE CNNS AND ENCODING INVARIANTS", "text": "The permutohedral convolution can be used as a new building block in a CNN architecture. We will omit the derivation of the gradients for the filter elements with respect to the output of such a new layer due to space constraints. We will discuss two possible application scenarios.\nFirst, as mentioned before we are free to change the sampling of the input signal of a lattice-based convolution. The choice of the sampling is problem specific. Missing measurements or domain specific sampling techniques that gather more information in highly discriminant areas are only two possible scenarios. Furthermore, as we will show in our experiments the method is robust in cases where train-time sampling and test-time sampling do not coincide.\nSecond, the proposed method provides a tool to encode additional data invariances in a principled way. A common technique to include domain knowledge is to artificially augment the training set\nwith deformations that leave the output signal invariant, such as translations, rotations, or nosiy versions.\nA feature mapping \u03a6 is invariant with respect to a transformation L and a signal v if \u03a6(v) \u2248 \u03a6(vL). In the case where L belongs to a set of translations a possible invariant feature is the convolution with a window function w (given its support has the right size) \u03a6(v, s) = \u222b w(t)v(s \u2212 t)dt. The same idea can be applied to the more general case and again calculating a mean with the help of a window function: \u03a6(v, L) = \u222b w(M)v(M\u22121L)dM .\nWe can use the permutohedral convolution to encode invariances like rotation and translation. Approximating the above integral by a finite sum and using lattice points as integration samples we arrive at \u03a6(v, L) \u2248 \u2211 lattice: M wMv(M\n\u22121L). We further approximate v(M\u22121L) with look-up at a lattice point location.\nConsider the case of rotation and translation invariance. More intuitively, we stack rotated versions of the input images onto each other in a 3 dimensional space \u2013 2 dimensions for the location of a sample and 1 dimension for the rotation of the image. A grid-based convolution would not work here because the rotated image points might not coincide with a grid anymore. Filtering in the permutohedral space naturally respects the augmented feature space."}, {"heading": "4 EXPERIMENTS", "text": "We investigate the performance and flexibility of the proposed method on two sets of experiments. The first setup compares the permutohedral convolution with a spatial convolution that has been combined with a bilinear interpolation. The second part adds a denoising experiment to show the modelling strength of the permutohedral convolution.\nIt is natural to ask, how a spatial convolution combined with an interpolation compares to a permutohedral convolutional neural network (PCNN). The proposed convolution is particularly advantageous in cases where samples are addressed in a higher dimensional space. Nevertheless, a bilinear interpolation prior to a spatial convolution can be used for dense 2-dimensional positional features.\nWe take a reference implementation of LeNet (LeCun et al., 1998) that is part of the caffe project (Jia et al., 2014) on the MNIST dataset as a starting point for the following experiments. The permutohedral convolutional layer is also implemented in this framework.\nWe first compare the LeNet in terms of test-time accuracy when substituting only the first of the convolutional layers with a (position only) permutohedral layer and leave the rest identical. Table 1a shows that a similar performance is achieved, so it seems model flexibility is not lost. The network is\ntrained according to the training parameters from the reference implementation. Next, we randomly sample continuous points in the input image, use their interpolated values as signal and continuous positions as features. Interestingly, we can train models with a different amount of sub-sampling than at test time. The permutohedral representation is robust with respect to this sparse input signal. Table 1a shows experiments with different signal degradation levels. All the sampling strategies have in common that the original input space of 28 by 28 pixels is densely covered. Hence, a bilinear interpolation prior to the first convolution allows us to compare against the original LeNet architecture. This baseline model performs similar to a PCNN.\nOne of the strengths of the proposed method is that it does not depend on a regular grid sampling as the tranditional convolution operators. We highlight this feature with the following denoising experiment and change the sampling space to be both sparse and 3-dimensional. The higher dimensional space renders a bilinear interpolation and spatial convolution more and more in-feasible due to the high number of corners of the hyper-cubical tessellation of the space. We compare the proposed permutohedral convolution in an illustrative denoising experiment to a spatial convolution. For bilateral filtering, which is one of the algorithmic use-cases of the permutohedral lattice, the input space features contain both the coordinates of a data sample and the color information of the image; hence a 5-dimensional vector for color images and a 3-dimensional vector for gray-scale images. In contrast to a direct application of a bilateral convolution to the noisy input the filter for a bilateral layer of a PCNN can now be trained. All experiments compare the performance of a PCNN to a common CNN with images from the BSDS500 dataset (Arbelez et al., 2011). Each image is transformed into gray-scale by taking the mean across channels and noise is artificially added to it with samples from a Gaussian distribution N (\u00b5, \u03c32), \u00b5 = 0, \u03c3 = 25255 .\nThe baseline network uses a spatial convolution (\u201cCNN\u201d in Table 1b) with a kernel size of 5 and predicts the scalar gray-scale value at each pixel (25 filter weights). The layer is trained with a fixed learning rate of 10\u22123, momentum weight of 0.9 and a weight decay of 5 \u00b7 10\u22124 on the \u201ctrain\u201d set. In the second architecture the convolution is performed on the permutohedral lattice (\u201cPCNN Gauss\u201d and \u201cPCNN Trained\u201d in Table 1b). We include the pixel\u2019s gray value as an additional feature for the generalized operation and set the neighborhood size to 2 (65 filter weights). The filter weights are initialized with a Gaussian blur and are either applied directly to the noisy input (\u201cPCNN Gauss\u201d) or trained on the \u201ctrain\u201d set to minimize the Euclidean distance to the clean image with a learning rate of 0.1. We cross-validate the scaling of the input space on the \u201cval\u201d image set and reuse this setting for all experiments that operate on the permutohedral lattice. A third architecture that combines both spatial and permutohedral convolutions by summation (\u201cCNN + PCNN\u201d) is similarly trained and tested.\nWe evaluate the PSNR utility averaged over the images from the \u201ctest\u201d set and see a slightly better performance of the bilateral network (\u201cPCNN trained\u201d) with trained filters in comparison to a bilateral filter (\u201cPCNN Gauss\u201d) and linear filter (\u201cCNN\u201d), see Table 1b. Both convolutional operations combined further improve the performance and suggest that they have complementary strengths. Admittedly this setup is rather simple, but it validates that the generalized filtering has an advantage.\nIn the future we plan to investigate the use of the PCNN architecture for other computer vision problems, e.g. semantic segmentation, and modeling domain knowledge like rotation or scale invariance."}, {"heading": "5 CONCLUSION", "text": "This paper presents a generalization of the convolutional operation to sparse input signals. We envision many consequences of this work. Consider signals that are naturally represented as measurements instead of images, like MRT scan readings. The permutohedral lattice filtering avoids the pre-processing assembling operation into a dense image, it is possible to work on the measured sparse signal directly. Another promising use of this filter is to encode scale invariance, typically this is encoded by presenting multiple scaled versions of an image to several branches of a network. The convolution presented here can be defined on the continuous range of image scales without a finite subselection. In summary, this technique allows to encode prior knowledge about the observed signal to define the domain of the convolution. The typical spatial filter of CNNs is a particular type of prior knowledge, we generalize this to sparse signals."}], "references": [{"title": "Gaussian kd-trees for fast high-dimensional filtering", "author": ["Adams", "Andrew", "Gelfand", "Natasha", "Dolson", "Jennifer", "Levoy", "Marc"], "venue": "In ACM SIGGRAPH 2009 Papers,", "citeRegEx": "Adams et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Adams et al\\.", "year": 2009}, {"title": "Fast high-dimensional filtering using the permutohedral lattice", "author": ["Adams", "Andrew", "Baek", "Jongmin", "Davis", "Myers Abraham"], "venue": "Comput. Graph. Forum,", "citeRegEx": "Adams et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Adams et al\\.", "year": 2010}, {"title": "Contour detection and hierarchical image segmentation", "author": ["Arbelez", "Pablo", "Maire", "Michael", "Fowlkes", "Charless", "Malik", "Jitendra"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Arbelez et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Arbelez et al\\.", "year": 2011}, {"title": "Non-linear Gaussian filters performing edge preserving diffusion", "author": ["Aurich", "Volker", "Weule", "J\u00f6rg"], "venue": "Mustererkennung", "citeRegEx": "Aurich et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Aurich et al\\.", "year": 1995}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Jia", "Yangqing", "Shelhamer", "Evan", "Donahue", "Jeff", "Karayev", "Sergey", "Long", "Jonathan", "Girshick", "Ross", "Guadarrama", "Sergio", "Darrell", "Trevor"], "venue": "arXiv preprint arXiv:1408.5093,", "citeRegEx": "Jia et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2014}, {"title": "Gradient-based learning applied to document recognition", "author": ["LeCun", "Yann", "Bottou", "L\u00e9on", "Bengio", "Yoshua", "Haffner", "Patrick"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Group invariant scattering", "author": ["Mallat", "St\u00e9phane"], "venue": "Communications in Pure and Applied Mathematics,", "citeRegEx": "Mallat and St\u00e9phane.,? \\Q2012\\E", "shortCiteRegEx": "Mallat and St\u00e9phane.", "year": 2012}, {"title": "A fast approximation of the bilateral filter using a signal processing approach", "author": ["Paris", "Sylvain", "Durand", "Fr\u00e9do"], "venue": "International Journal of Compututer Vision,", "citeRegEx": "Paris et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Paris et al\\.", "year": 2009}, {"title": "SUSAN \u2013 a new approach to low level image processing", "author": ["Smith", "Stephen M", "Brady", "J. Michael"], "venue": "Int. J. Comput. Vision,", "citeRegEx": "Smith et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Smith et al\\.", "year": 1997}, {"title": "Bilateral filtering for gray and color images", "author": ["Tomasi", "Carlo", "Roberto", "Manduchi"], "venue": "In Proceedings of the Sixth International Conference on Computer Vision,", "citeRegEx": "Tomasi et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Tomasi et al\\.", "year": 1998}], "referenceMentions": [{"referenceID": 1, "context": "This work is inspired by the use of special data structures (Adams et al., 2010) for bilateral filters (Aurich & Weule, 1995; Smith & Brady, 1997; Tomasi & Roberto, 1998) and generalizes it for the use of convolutional architectures.", "startOffset": 60, "endOffset": 80}, {"referenceID": 1, "context": "This strategy has already been used to implement fast Gaussian filtering (Paris & Durand, 2009; Adams et al., 2010; 2009).", "startOffset": 73, "endOffset": 121}, {"referenceID": 5, "context": "We compare the LeNet (LeCun et al., 1998) implementation that is part of Caffe (Jia et al.", "startOffset": 21, "endOffset": 41}, {"referenceID": 4, "context": ", 1998) implementation that is part of Caffe (Jia et al., 2014) to the network with the first layer replaced by a permutohedral convolution layer (PCNN).", "startOffset": 45, "endOffset": 63}, {"referenceID": 2, "context": "(b) PSNR results of a denoising task using the BSDS500 dataset (Arbelez et al., 2011).", "startOffset": 63, "endOffset": 85}, {"referenceID": 5, "context": "We take a reference implementation of LeNet (LeCun et al., 1998) that is part of the caffe project (Jia et al.", "startOffset": 44, "endOffset": 64}, {"referenceID": 4, "context": ", 1998) that is part of the caffe project (Jia et al., 2014) on the MNIST dataset as a starting point for the following experiments.", "startOffset": 42, "endOffset": 60}, {"referenceID": 2, "context": "All experiments compare the performance of a PCNN to a common CNN with images from the BSDS500 dataset (Arbelez et al., 2011).", "startOffset": 103, "endOffset": 125}], "year": 2015, "abstractText": "This paper presents a convolutional layer that is able to process sparse input features. As an example, for image recognition problems this allows an efficient filtering of signals that do not lie on a dense grid (like pixel position), but of more general features (such as color values). The presented algorithm makes use of the permutohedral lattice data structure. The permutohedral lattice was introduced to efficiently implement a bilateral filter, a commonly used image processing operation. Its use allows for a generalization of the convolution type found in current (spatial) convolutional network architectures.", "creator": "LaTeX with hyperref package"}}}