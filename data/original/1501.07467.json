{"id": "1501.07467", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jan-2015", "title": "Regression and Learning to Rank Aggregation for User Engagement Evaluation", "abstract": "User engagement refers to the amount of interaction an instance (e.g., tweet, news, and forum post) achieves. Ranking the items in social media websites based on the amount of user participation in them, can be used in different applications, such as recommender systems. In this paper, we consider a tweet containing a rating for a movie as an instance and focus on ranking the instances of each user based on their engagement, i.e., the total number of retweets and favorites it will gain.", "histories": [["v1", "Thu, 29 Jan 2015 14:54:12 GMT  (49kb)", "http://arxiv.org/abs/1501.07467v1", "In Proceedings of the 2014 ACM Recommender Systems Challenge, RecSysChallenge '14"]], "COMMENTS": "In Proceedings of the 2014 ACM Recommender Systems Challenge, RecSysChallenge '14", "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["hamed zamani", "azadeh shakery", "pooya moradi"], "accepted": false, "id": "1501.07467"}, "pdf": {"name": "1501.07467.pdf", "metadata": {"source": "CRF", "title": "Regression and Learning to Rank Aggregation for User Engagement Evaluation", "authors": ["Hamed Zamani", "Pooya Moradi"], "emails": ["po.moradi}@ut.ac.ir", "permissions@acm.org."], "sections": [{"heading": null, "text": "ar X\niv :1\n50 1.\n07 46\n7v 1\n[ cs\n.I R\n] 2\n9 Ja\nn 20\n15\nFor this task, we define several features which can be extracted from the meta-data of each tweet. The features are partitioned into three categories: user-based, movie-based, and tweet-based. We show that in order to obtain good results, features from all categories should be considered. We exploit regression and learning to rank methods to rank the tweets and propose to aggregate the results of regression and learning to rank methods to achieve better performance.\nWe have run our experiments on an extended version of MovieTweeting dataset provided by ACM RecSys Challenge 2014. The results show that learning to rank approach outperforms most of the regression models and the combination can improve the performance significantly.\nCategories and Subject Descriptors H.2.8 [Database Management]: Data Mining; J.4 [Computer Applications]: Social and Behavioral Sciences\nGeneral Terms Algorithm, Experimentation\nKeywords Twitter, User engagement, Ranking aggregation"}, {"heading": "1. INTRODUCTION", "text": "Twitter is an online social information network which has become tremendously popular in the past few years [19].\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. RecSysChallenge\u201914, October 10, 2014, Foster City, CA, USA. Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$15.00.\nMillions of users are sharing rich information using social media sites, such as Twitter, which can be used by social recommender systems [12]. Item providers often let users express their opinion about an item in social networks. For instance, users can give a rating to each movie in Internet Movie Database (IMDb) website1 and also share it in Twitter. This intensifies the importance of considering social media sites for recommendation and information filtering systems [31].\nProduct rating prediction is a traditional recommender system problem which has been studied extensively in the literature [10, 23, 24]. One important issue in recommender systems is the engagement which can be gained by the users\u2019 comments/opinions. When users share their comments on different items, the amount of user interactions achieved by each comment can be used to improve the quality of recommender systems. In this paper, we focus on ranking these comments by their engagements.\nWe focus on movie ratings tweeted by IMDb users in Twitter. Hereafter, we use the word \u201cengagement\u201d as the user interaction which is expressed by adding up the number of retweets and favorites a tweet has gained. Our purpose is to rank the tweets of each user, each containing a rating for a movie in IMDb, by their engagements.\nFor this task, we first extract several features from the tweets. The features are categorized into three groups: userbased, movie-based, and tweet-based. It should be noted that the content of the tweets are hidden and there is no textual feature among our defined features. Then, we propose two different supervised approaches in order to rank the tweets. The first approach tires to predict the tweets engagements globally. In other words, although our purpose is to sort the tweets of each user, we consider tweets of all the users together and then try to predict the tweets engagements. We can then extract the sorted list of each user from the global ranked list. Therefore, we fit regression models to predict the engagement of each tweet. In the second approach, for each user, we rank the tweets by their engagement without predicting the engagements. To this aim, we use learning to rank approach which is extensively exploited in information retrieval, natural language processing, and recommender systems. Learning to rank methods rank the tweets for each user. In contrary to regression models which try to predict the engagements by considering all the tweets together, learning to rank methods emphasize on maximizing an objective function for each user. According to the different points of view of regression and learning to\n1http://imdb.com\nrank methods, we further propose to aggregate the results obtained by different regression and learning to rank methods to improve the performance.\nIn the experiments, we use an extended version of MovieTweetings dataset [9] provided by ACM RecSys Challenge 2014 and report the results of a number of state-of-the-art regression and learning to rank methods, separately. We further discuss the aggregation of the results of these two approaches. The experimental results show that although the results of regression methods are not so impressive, aggregation of regression and learning to rank methods improves the results significantly."}, {"heading": "2. RELATED WORK", "text": "The problem of engagement prediction or online participation has been studied from different points of view in news websites, social networks, and discussion forums. Several machine learning algorithms have been used in the literature for this task.\nTo address the problem of engagement prediction, several features have been proposed for training a model. Suh et al. [28] have provided an analysis on the factors impacting the number of retweets. They have concluded that hashtags, number of followers, number of followees, and the account age play important roles in increasing the probability of the tweets to be retweeted. Zaman et al. [34] have trained a probabilistic collaborative filtering model to predict the future retweets using the history of the previous ones.\nLinear models have been used in some other studies to predict the popularity of videos on YouTube by observing their popularity after regular periods [29]. Petrovic et al. [26] have proposed a passive-aggressive algorithm to predict whether a tweet will be retweeted or not.\nRecognizing popular messages is also one of the similar problems which is used for breaking news detection and personalized tweet/content recommendation. Hong et al. [13] have formulated this task as a classification problem by exploiting content-based features, temporal information, meta-data of messages, and the users social graph.\nPredicting the extent to which a news is going to be breaking or how many comments a news is going to gain is one of the engagement prediction problems. Tatar et al. [30] have analyzed a news dataset to address this problem. They have focused on sorting the articles based on their future popularity and they have proposed to use linear regression for this task.\nIt is worth noting that ranking instances is one of the problems which has been extensively studied in information retrieval, natural language processing, and machine learning fields [21]. To solve a similar problem, Uysal and Croft [31] have proposed \u201cCoordinate Ascent learning to rank\u201d algorithm to rank tweets for a user in a way that tweets which are more likely to be retweeted come on top. They have also worked on ranking users for a tweet in a way that the higher the rank, the more likely the given tweet will be retweeted. Several learning to rank algorithms have been proposed in the literature. Moreover, there are some supervised and unsupervised ensemble methods to aggregate different rankings, such as Borda Count [2] and Cranking [20]. Previous studies show that in many cases, ranking aggregation methods outperform single ranking methods [8, 21]."}, {"heading": "3. METHODOLOGY", "text": "In general, our idea is to extract a number of features for each tweet and then try to learn machine learning based models on the training data. Then, for each user in test data, we apply the learned model to rank his/her tweets based on their engagements. In this section, we first introduce the features, and then we propose some machine learning approaches to rank the tweets based on their engagements. We also try to aggregate the results of these different techniques to improve the performance. In the following subsections, we explain our methodology in details."}, {"heading": "3.1 Features", "text": "Each tweet contains the opinion of a user about a specific movie. We partition the features extracted from each tweet into three different categories: user-based, movie-based, and tweet-based features. Overall, we extract several features from each tweet T tweeted by user U about movie M. Userbased features give us some information about the user who has tweeted his/her opinion about a specific movie. These features are not tweet-specific and they are equal for all tweets of each user. The total number of followers of U is an example of user-based features. Movie-based features only include information about movie M, e.g., the total number of tweets about movie M. Tweet-based features contain specific information of tweet T. This information may also contain the opinion of user U about movie M. The time and language of a tweet are two examples of tweet-based features.\nThe name and description of the extracted features are shown in Table 1. These features are extracted for each tweet T. We specify the category of the features and also their type; \u201cN\u201d, \u201cC\u201d, and \u201cB\u201d are used for numerical, categorical, and boolean types, respectively. It should be noted that the feature values are normalized using z-score normalization method.\nWe also perform feature selection to improve the performance and also to analyse the effectiveness of the proposed features. We exploit backward elimination for feature selection. The bolded features in Table 1 are those that are retained after performing feature selection. We discuss the selected features in Subsection 4.1"}, {"heading": "3.2 Machine Learning Techniques for User Engagement Ranking", "text": "In this subsection, we propose two different learning based approaches to rank the tweets of each user based on their engagements. The first approach is predicting the engagement of tweets, globally. In other words, for predicting the engagement of tweets of a user, we consider the tweets of all users for training the model and not only the tweets of the user. To this aim, we use regression models to predict the engagement of each tweet. The next approach is to rank the tweets for each user without predicting their engagements. We exploit learning to rank methods to rank the tweets of each user, which focus on ranking the tweets of each user individually and try to maximize a given objective function for each user. Finally, we propose a supervised method to aggregate the regression and learning to rank results using supervised Kemeny approach [1]. In the following, we explain our proposed methods in details.\n3.2.1 Regression To rank the tweets of each user based on their possible\nengagements, we can first predict the engagement of each tweet and then sort the tweets by their predicted values. To predict the engagements, we propose to train regression models by using the features defined in Subsection 3.1 as the features and the engagements as the labels. Then, we apply the learned model on the same extracted features from the test set.\nTo create the regression model, we exploit Extremely Randomized Trees (also known as Extra-Trees) [11], Bayesian Ridge Regression [22], and Stochastic Gradient Descent Regression (SGDR) [4]. Extra-Trees are tree-based ensemble regression methods which are successfully used in several tasks. In Extra-Trees, when a tree is built, the node splitting step is done randomly by choosing the best split among a random subset of features. The results of all trees are combined by averaging the individual predictions. SGDR is a generalized linear regression model that tries to fit a linear model by minimizing a regularized empirical loss function using gradient descent technique.\n3.2.2 Learning to Rank Instead of predicting the exact engagements, we can rank\nthe tweets directly, without predicting the engagements of each tweet. Learning to Rank (LTR) methods are machine learning techniques which try to solve ranking problems [21]. LTR methods have been widely used in many different areas such as information retrieval, natural language processing, and recommender systems [16, 21]. LTR methods train a ranking model and use the learned model to rank the instances using several features which are extracted from each instance.\nTo build our LTR model, we consider a number of ranking algorithms which are among state-of-the-art in many test collections: ListNet [7], RankingSVM [15], AdaRank [33], RankNet [6], LambdaRank [5], and ListMLE [32]. ListNet is a probabilistic listwise approach to solve ranking problems, which exploits a parameterized Plackett-Luce model to compute different permutations. Ranking SVM is a pairwise ranking approach which uses SVM classifier in its core computations. The basic idea behind AdaRank is constructing some weak rankers and combining them linearly to achieve a better performance. Although, Ranking SVM creates a ranking model by minimizing the classification error on instance pairs, AdaRank tries to minimize the loss function which is directly defined as an evaluation measure (such as NDCG@10). RankNet is one of the pairwise methods that adopts cross entropy as the loss function. RankNet employs a three layered neural network with a single output node to compare each pairs. LambdaRank is one of the ranking algorithms inspired by RankNet which uses Gradient Descent approach to optimize the evaluation measure. Similar to ListNet, ListMLE is a probabilistic listwise approach to rank instances by maximizing a logarithmic loss function.\n3.2.3 Aggregating Regression and Learning to Rank Outputs\nAccording to the aforementioned facts, regression and learning to rank techniques take two different points of view into consideration and their results might be totally different. Therefore, by aggregating their results, the performance can potentially be increased.\nTo aggregate all the mentioned regression and learning to rank results, we use supervised Kemeny approach [1]. Kemeny optimal aggregation [17] tries to minimize total number of pairwise disagreements between the final ranking and the outputs of all base rankers. In other words, if r1, r2, ..., rn represent the outputs of n different rankers, the final ranking r\u2217 is computed as:\nr \u2217 = argmax\nr {\nn\u2211\ni=1\nk(r, ri)}\nwhere k(\u03b1, \u03b2) is the Kendall tau distance [18] measured as:\n|(i, j) : i < j, \u03b1i > \u03b1j \u2227 \u03b2i < \u03b2j |\nwhere \u03b1i denotes the i th position of ranking \u03b1.\nWhile in Kemeny optimal aggregation all the rankers have the same importance, supervised Kemeny approach assumes that there is a weight for each ranker. In more details, in supervised Kemeny instead of counting the number of disagreements, we use the following equation to compute the final ranking:\nr \u2217 = argmax\nr {\nn\u2211\ni=1\nk(r, ri) \u2217 wi}\nwhere wi denotes the weight of i th ranker. To find the weight of each ranker, we propose to perform a Randomized Search [3]. To this aim, we perform cross validation over training data and find the optimal weight for each ranker."}, {"heading": "4. EXPERIMENTS", "text": "In the experiments, we consider an extended version of MovieTweetings dataset [9] which is provided by ACM RecSys Challenge 2014 [27].2 The dataset contains movie ratings which are automatically tweeted by the users of IMDb iOS application. The reported results throughout this work are those obtained on the test set. The evaluation measure is the mean of normalized discounted cumulative gain [14] computed for top 10 tweets of each user. We call it NDCG@10, hereafter.\nIn our experiments, we used Scikit-learn library [25] for all the regression and feature selection algorithms. To select the parameters of the learning methods, we performed hyper-parameter optimization using Randomized Search [3] with 5-fold cross validation. For the learning to rank algorithms except AdaRank, we exploited an open source package, named ToyBox-Ranking3. For AdaRank, we used the software developed in Microsoft Research [33].4"}, {"heading": "4.1 Experimental Results and Discussion", "text": "In this subsection, we report and discuss the results of different regression and learning to rank methods. We also provide the results obtained by aggregating the regression and learning to rank results using the supervised Kemeny approach.\nTo show the impact of feature selection, we report the results of regression and learning to rank methods both before and after feature selection. As mentioned before, the bolded features in Table 1 are those retained after performing backward elimination method. The selected features are\n2http://2014.recsyschallenge.com/ 3https://github.com/y-tag/cpp-ToyBox-Ranking 4http://goo.gl/xycK0h\ndiffused among all the three feature categories. This shows the importance of using a combination of different kinds of features in this problem. The selected user-based features show how active and popular the user is in Twitter. Interestingly, all the boolean features are selected and none of the categorical features are retained. The reason may be that the values of the boolean features are constant and the difference between them are not a continuous value. So it may be easier and more efficient to use these features. Moreover, for the categorical features, we assign a number to each possible category and the arithmetic difference between these numbers is not informative.\nTable 2 shows the results obtained by different regression algorithms, in terms of NDCG@10. In Table 2, \u201cXT\u201d, \u201cBRR\u201d, and \u201cSGDR\u201d respectively denote Extremely Randomized Trees, Bayesian Ridge Regression, and Stochastic Gradient Descent Regression.\nThe results reported in Table 2 demonstrate that feature selection does not help with regression algorithms. In other words, after performing the feature selection, the results of regression models are dropped dramatically. This shows that backward elimination is not sufficient for regression models. According to Table 2, there is a considerable difference between the results achieved by different regression models.\nTable 3 shows the results of using several learning to rank methods. The results also include NDCG@10 before and after applying feature selection. The results reported in Table 3 emphasize on the importance of using feature selection in learning to rank methods; since after performing feature selection, the results are improved. Therefore, backward elimination method works well for LTR methods. Table 3 demonstrates that ListNet performs better than the other LTR methods. Comparing the results of Table 2 and Table 3 shows that all the learning to rank methods outperform all the regression models.\nTable 4 represents the results obtained by aggregating the mentioned regression and learning to rank results using supervised Kemeny approach. To show the importance of considering both regression and learning to rank methods together, we also report the results achieved by aggregating all the LTR methods and all the regression methods, separately. Table 4 indicates that although most of the results of regression models are far lower than the LTR methods, their aggregation improves the results. It shows that aggregating regression and learning to rank methods achieves better results in comparison with aggregating only LTR methods or regression models. To show that this improvement is significant, we performed 10-fold cross validation over the training data and conducted a statistical significant test (t-test) on the improvements of LTRs+REGs over the other methods. The results show that the improvement achieved by LTRs+REGs is statistically significant (p\u2212 value < 0.01)."}, {"heading": "5. CONCLUSIONS", "text": "In this paper, to rank the tweets of each user based on their engagements, we first defined several features partitioned into three different categories: user-based, moviebased, and tweet-based. We showed that after performing feature selection, the features are selected from all of these categories. Then, we exploited regression and learning to rank methods to rank the tweets of each user by their engagements. Finally, we aggregated the results of all the regression and learning to rank methods using supervised Kemeny approach.\nWe evaluated our methods on an extended version of MovieTweeting dataset provided by ACMRecSys Challenge 2014. The experimental results demonstrate that feature selection significantly affects the performance. The results also show that however the results of most regression models are far lower than learning to rank methods, their aggregation improves the performance."}, {"heading": "6. REFERENCES", "text": "[1] A. Agarwal, H. Raghavan, K. Subbian, P. Melville,\nR. D. Lawrence, D. C. Gondek, and J. Fan. Learning to rank for robust question answering. In Proceedings of the 21st ACM International Conference on Information and Knowledge Management, CIKM \u201912, pages 833\u2013842, 2012.\n[2] J. A. Aslam and M. Montague. Models for metasearch. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research\nand Development in Information Retrieval, SIGIR \u201901, pages 276\u2013284, 2001.\n[3] J. Bergstra and Y. Bengio. Random search for hyper-parameter optimization. J. Mach. Learn. Res., 13(1):281\u2013305, 2012.\n[4] L. Bottou. Stochastic learning. In Advanced Lectures on Machine Learning, Lecture Notes in Artificial Intelligence, LNAI 3176, pages 146\u2013168. 2004.\n[5] C. Burges, R. Ragno, and Q. Le. Learning to rank with non-smooth cost functions. In Advances in Neural Information Processing Systems 19, 2007.\n[6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In Proceedings of the 22nd International Conference on Machine Learning, ICML \u201905, pages 89\u201396, 2005.\n[7] Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. Learning to rank: From pairwise approach to listwise approach. In Proceedings of the 24th International Conference on Machine Learning, ICML \u201907, pages 129\u2013136, 2007.\n[8] O. Chapelle and Y. Chang. Yahoo! learning to rank challenge overview. Journal of Machine Learning Research - Proceedings Track, 14:1\u201324, 2011.\n[9] S. Dooms, T. De Pessemier, and L. Martens. Movietweetings: a movie rating dataset collected from twitter. In Workshop on Crowdsourcing and Human Computation for Recommender Systems, CrowdRec at\nRecSys 2013, 2013.\n[10] M. D. Ekstrand, J. T. Riedl, and J. A. Konstan. Collaborative filtering recommender systems. Found. Trends Hum.-Comput. Interact., 4(2):81\u2013173, 2011.\n[11] P. Geurts, D. Ernst, and L. Wehenkel. Extremely randomized trees. Mach. Learn., 63(1):3\u201342, 2006.\n[12] I. Guy and D. Carmel. Social recommender systems. In Proceedings of the 20th International Conference Companion on World Wide Web, WWW \u201911, pages 283\u2013284, 2011.\n[13] L. Hong, O. Dan, and B. D. Davison. Predicting popular messages in twitter. In Proceedings of the 20th International Conference Companion on World Wide\nWeb, WWW \u201911, pages 57\u201358, 2011.\n[14] K. Ja\u0308rvelin and J. Keka\u0308la\u0308inen. Cumulated gain-based evaluation of ir techniques. ACM Trans. Inf. Syst., 20(4):422\u2013446, 2002.\n[15] T. Joachims. Optimizing search engines using clickthrough data. In Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge\nDiscovery and Data Mining, KDD \u201902, pages 133\u2013142, 2002.\n[16] A. Karatzoglou, L. Baltrunas, and Y. Shi. Learning to rank for recommender systems. In Proceedings of the 7th ACM Conference on Recommender Systems, RecSys \u201913, pages 493\u2013494, 2013.\n[17] J. G. Kemeny. Mathematics without numbers. Daedalus, 88(4), 1959.\n[18] M. G. Kendall. A new measure of rank correlation. Biometrika, 30(1/2):81\u201393, 1938.\n[19] S. M. Kywe, E.-P. Lim, and F. Zhu. A survey of recommender systems in twitter. In Proceedings of the 4th International Conference on Social Informatics, SocInfo \u201912, pages 420\u2013433, 2012.\n[20] G. Lebanon and J. D. Lafferty. Cranking: Combining rankings using conditional probability models on permutations. In Proceedings of the Nineteenth\nInternational Conference on Machine Learning, ICML \u201902, pages 363\u2013370, 2002.\n[21] H. Li and G. Hirst. Learning to Rank for Information Retrieval and Natural Language Processing. Morgan & Claypool, 2011.\n[22] D. J. C. MacKay. Bayesian interpolation. Neural computation, 4:415\u2013447, 1992.\n[23] T. Nguyen. Web based recommender systems and rating prediction. Master\u2019s thesis, San Jose State University, 2009.\n[24] A. Oghina, M. Breuss, M. Tsagkias, and M. de Rijke. Predicting imdb movie ratings using social media. In Proceedings of the 34th European Conference on\nAdvances in Information Retrieval, ECIR\u2019 12, pages 503\u2013507, 2012.\n[25] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in python. J. Mach. Learn. Res., 12:2825\u20132830, 2011.\n[26] S. Petrovic, M. Osborne, and V. Lavrenko. Rt to win! predicting message propagation in twitter. In International AAAI Conference on Weblogs and Social\nMedia, pages 586\u2013589, 2011.\n[27] A. Said, S. Dooms, B. Loni, and D. Tikk. Recommender systems challenge 2014. In Proceedings of the eighth ACM conference on Recommender\nsystems, RecSys \u201914, 2014.\n[28] B. Suh, L. Hong, P. Pirolli, and E. H. Chi. Want to be retweeted? large scale analytics on factors impacting retweet in twitter network. In Proceedings of the 2010 IEEE Second International Conference on Social\nComputing, SOCIALCOM \u201910, pages 177\u2013184, 2010.\n[29] G. Szabo and B. A. Huberman. Predicting the popularity of online content. Commun. ACM, 53(8):80\u201388, 2010.\n[30] A. Tatar, P. Antoniadis, M. D. de Amorim, and S. Fdida. Ranking news articles based on popularity prediction. In Proceedings of the 2012 International Conference on Advances in Social Networks Analysis\nand Mining, ASONAM \u201912, pages 106\u2013110, 2012.\n[31] I. Uysal and W. B. Croft. User oriented tweet ranking: A filtering approach to microblogs. In Proceedings of the 20th ACM International Conference on\nInformation and Knowledge Management, CIKM \u201911, pages 2261\u20132264, 2011.\n[32] F. Xia, T.-Y. Liu, J. Wang, W. Zhang, and H. Li. Listwise approach to learning to rank: Theory and algorithm. In Proceedings of the 25th International Conference on Machine Learning, ICML \u201908, pages 1192\u20131199, 2008.\n[33] J. Xu and H. Li. Adarank: A boosting algorithm for information retrieval. In Proceedings of the 30th Annual International ACM SIGIR Conference on\nResearch and Development in Information Retrieval, SIGIR \u201907, pages 391\u2013398, 2007.\n[34] T. R. Zaman, R. Herbrich, J. Van Gael, and D. Stern. Predicting information spreading in twitter. In Workshop on Computational Social Science and the\nWisdom of Crowds, NIPS, 2010."}], "references": [{"title": "Learning to rank for robust question answering", "author": ["A. Agarwal", "H. Raghavan", "K. Subbian", "P. Melville", "R.D. Lawrence", "D.C. Gondek", "J. Fan"], "venue": "Proceedings of the 21st ACM International Conference on Information and Knowledge Management, CIKM \u201912, pages 833\u2013842", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Models for metasearch", "author": ["J.A. Aslam", "M. Montague"], "venue": "Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR \u201901, pages 276\u2013284", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Random search for hyper-parameter optimization", "author": ["J. Bergstra", "Y. Bengio"], "venue": "J. Mach. Learn. Res., 13(1):281\u2013305", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Stochastic learning", "author": ["L. Bottou"], "venue": "Advanced Lectures on Machine Learning, Lecture Notes in Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Learning to rank with non-smooth cost functions", "author": ["C. Burges", "R. Ragno", "Q. Le"], "venue": "Advances in Neural Information Processing Systems 19", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning to rank using gradient descent", "author": ["C. Burges", "T. Shaked", "E. Renshaw", "A. Lazier", "M. Deeds", "N. Hamilton", "G. Hullender"], "venue": "Proceedings of the 22nd International Conference on Machine Learning, ICML \u201905, pages 89\u201396", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning to rank: From pairwise approach to listwise approach", "author": ["Z. Cao", "T. Qin", "T.-Y. Liu", "M.-F. Tsai", "H. Li"], "venue": "Proceedings of the 24th International Conference on Machine Learning, ICML \u201907, pages 129\u2013136", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Yahoo! learning to rank challenge overview", "author": ["O. Chapelle", "Y. Chang"], "venue": "Journal of Machine Learning Research - Proceedings Track, 14:1\u201324", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Movietweetings: a movie rating dataset collected from twitter", "author": ["S. Dooms", "T. De Pessemier", "L. Martens"], "venue": "Workshop on Crowdsourcing and Human Computation for Recommender Systems, CrowdRec at RecSys 2013", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Collaborative filtering recommender systems", "author": ["M.D. Ekstrand", "J.T. Riedl", "J.A. Konstan"], "venue": "Found. Trends Hum.-Comput. Interact., 4(2):81\u2013173", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Extremely randomized trees", "author": ["P. Geurts", "D. Ernst", "L. Wehenkel"], "venue": "Mach. Learn., 63(1):3\u201342", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Social recommender systems", "author": ["I. Guy", "D. Carmel"], "venue": "Proceedings of the 20th International Conference Companion on World Wide Web, WWW \u201911, pages 283\u2013284", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Predicting popular messages in twitter", "author": ["L. Hong", "O. Dan", "B.D. Davison"], "venue": "Proceedings of the 20th International Conference Companion on World Wide Web, WWW \u201911, pages 57\u201358", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Cumulated gain-based evaluation of ir techniques", "author": ["K. J\u00e4rvelin", "J. Kek\u00e4l\u00e4inen"], "venue": "ACM Trans. Inf. Syst., 20(4):422\u2013446", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2002}, {"title": "Optimizing search engines using clickthrough data", "author": ["T. Joachims"], "venue": "Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201902, pages 133\u2013142", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning to rank for recommender systems", "author": ["A. Karatzoglou", "L. Baltrunas", "Y. Shi"], "venue": "Proceedings of the 7th ACM Conference on Recommender Systems, RecSys \u201913, pages 493\u2013494", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Mathematics without numbers", "author": ["J.G. Kemeny"], "venue": "Daedalus, 88(4)", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1959}, {"title": "A new measure of rank correlation", "author": ["M.G. Kendall"], "venue": "Biometrika, 30(1/2):81\u201393", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1938}, {"title": "A survey of recommender systems in twitter", "author": ["S.M. Kywe", "E.-P. Lim", "F. Zhu"], "venue": "Proceedings of the 4th International Conference on Social Informatics, SocInfo \u201912, pages 420\u2013433", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Cranking: Combining rankings using conditional probability models on permutations", "author": ["G. Lebanon", "J.D. Lafferty"], "venue": "Proceedings of the Nineteenth  International Conference on Machine Learning, ICML \u201902, pages 363\u2013370", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2002}, {"title": "Learning to Rank for Information Retrieval and Natural Language Processing", "author": ["H. Li", "G. Hirst"], "venue": "Morgan & Claypool", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Bayesian interpolation", "author": ["D.J.C. MacKay"], "venue": "Neural computation, 4:415\u2013447", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1992}, {"title": "Web based recommender systems and rating prediction", "author": ["T. Nguyen"], "venue": "Master\u2019s thesis, San Jose State University", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "and M", "author": ["A. Oghina", "M. Breuss", "M. Tsagkias"], "venue": "de Rijke. Predicting imdb movie ratings using social media. In Proceedings of the 34th European Conference on Advances in Information Retrieval, ECIR\u2019 12, pages 503\u2013507", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Scikit-learn: Machine learning in python", "author": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V. Dubourg", "J. Vanderplas", "A. Passos", "D. Cournapeau", "M. Brucher", "M. Perrot", "E. Duchesnay"], "venue": "J. Mach. Learn. Res., 12:2825\u20132830", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Rt to win! predicting message propagation in twitter", "author": ["S. Petrovic", "M. Osborne", "V. Lavrenko"], "venue": "International AAAI Conference on Weblogs and Social Media, pages 586\u2013589", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2011}, {"title": "Recommender systems challenge 2014", "author": ["A. Said", "S. Dooms", "B. Loni", "D. Tikk"], "venue": "Proceedings of the eighth ACM conference on Recommender systems, RecSys \u201914", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Want to be retweeted? large scale analytics on factors impacting retweet in twitter network", "author": ["B. Suh", "L. Hong", "P. Pirolli", "E.H. Chi"], "venue": "Proceedings of the 2010 IEEE Second International Conference on Social Computing, SOCIALCOM \u201910, pages 177\u2013184", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Predicting the popularity of online content", "author": ["G. Szabo", "B.A. Huberman"], "venue": "Commun. ACM, 53(8):80\u201388", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "M", "author": ["A. Tatar", "P. Antoniadis"], "venue": "D. de Amorim, and S. Fdida. Ranking news articles based on popularity prediction. In Proceedings of the 2012 International Conference on Advances in Social Networks Analysis and Mining, ASONAM \u201912, pages 106\u2013110", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "User oriented tweet ranking: A filtering approach to microblogs", "author": ["I. Uysal", "W.B. Croft"], "venue": "Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM \u201911, pages 2261\u20132264", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "Listwise approach to learning to rank: Theory and algorithm", "author": ["F. Xia", "T.-Y. Liu", "J. Wang", "W. Zhang", "H. Li"], "venue": "Proceedings of the 25th International Conference on Machine Learning, ICML \u201908, pages 1192\u20131199", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2008}, {"title": "Adarank: A boosting algorithm for information retrieval", "author": ["J. Xu", "H. Li"], "venue": "Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR \u201907, pages 391\u2013398", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2007}, {"title": "Predicting information spreading in twitter", "author": ["T.R. Zaman", "R. Herbrich", "J. Van Gael", "D. Stern"], "venue": "Workshop on Computational Social Science and the Wisdom of Crowds, NIPS", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 18, "context": "Twitter is an online social information network which has become tremendously popular in the past few years [19].", "startOffset": 108, "endOffset": 112}, {"referenceID": 11, "context": "Millions of users are sharing rich information using social media sites, such as Twitter, which can be used by social recommender systems [12].", "startOffset": 138, "endOffset": 142}, {"referenceID": 30, "context": "This intensifies the importance of considering social media sites for recommendation and information filtering systems [31].", "startOffset": 119, "endOffset": 123}, {"referenceID": 9, "context": "Product rating prediction is a traditional recommender system problem which has been studied extensively in the literature [10, 23, 24].", "startOffset": 123, "endOffset": 135}, {"referenceID": 22, "context": "Product rating prediction is a traditional recommender system problem which has been studied extensively in the literature [10, 23, 24].", "startOffset": 123, "endOffset": 135}, {"referenceID": 23, "context": "Product rating prediction is a traditional recommender system problem which has been studied extensively in the literature [10, 23, 24].", "startOffset": 123, "endOffset": 135}, {"referenceID": 8, "context": "In the experiments, we use an extended version of MovieTweetings dataset [9] provided by ACM RecSys Challenge 2014 and report the results of a number of state-of-the-art regression and learning to rank methods, separately.", "startOffset": 73, "endOffset": 76}, {"referenceID": 27, "context": "[28] have provided an analysis on the factors impacting the number of retweets.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34] have trained a probabilistic collaborative filtering model to predict the future retweets using the history of the previous ones.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "Linear models have been used in some other studies to predict the popularity of videos on YouTube by observing their popularity after regular periods [29].", "startOffset": 150, "endOffset": 154}, {"referenceID": 25, "context": "[26] have proposed a passive-aggressive algorithm to predict whether a tweet will be retweeted or not.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] have formulated this task as a classification problem by exploiting content-based features, temporal information, meta-data of messages, and the users social graph.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] have analyzed a news dataset to address this problem.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "It is worth noting that ranking instances is one of the problems which has been extensively studied in information retrieval, natural language processing, and machine learning fields [21].", "startOffset": 183, "endOffset": 187}, {"referenceID": 30, "context": "To solve a similar problem, Uysal and Croft [31] have proposed \u201cCoordinate Ascent learning to rank\u201d algorithm to rank tweets for a user in a way that tweets which are more likely to be retweeted come on top.", "startOffset": 44, "endOffset": 48}, {"referenceID": 1, "context": "Moreover, there are some supervised and unsupervised ensemble methods to aggregate different rankings, such as Borda Count [2] and Cranking [20].", "startOffset": 123, "endOffset": 126}, {"referenceID": 19, "context": "Moreover, there are some supervised and unsupervised ensemble methods to aggregate different rankings, such as Borda Count [2] and Cranking [20].", "startOffset": 140, "endOffset": 144}, {"referenceID": 7, "context": "Previous studies show that in many cases, ranking aggregation methods outperform single ranking methods [8, 21].", "startOffset": 104, "endOffset": 111}, {"referenceID": 20, "context": "Previous studies show that in many cases, ranking aggregation methods outperform single ranking methods [8, 21].", "startOffset": 104, "endOffset": 111}, {"referenceID": 0, "context": "Finally, we propose a supervised method to aggregate the regression and learning to rank results using supervised Kemeny approach [1].", "startOffset": 130, "endOffset": 133}, {"referenceID": 10, "context": "To create the regression model, we exploit Extremely Randomized Trees (also known as Extra-Trees) [11], Bayesian Ridge Regression [22], and Stochastic Gradient Descent Regression (SGDR) [4].", "startOffset": 98, "endOffset": 102}, {"referenceID": 21, "context": "To create the regression model, we exploit Extremely Randomized Trees (also known as Extra-Trees) [11], Bayesian Ridge Regression [22], and Stochastic Gradient Descent Regression (SGDR) [4].", "startOffset": 130, "endOffset": 134}, {"referenceID": 3, "context": "To create the regression model, we exploit Extremely Randomized Trees (also known as Extra-Trees) [11], Bayesian Ridge Regression [22], and Stochastic Gradient Descent Regression (SGDR) [4].", "startOffset": 186, "endOffset": 189}, {"referenceID": 20, "context": "Learning to Rank (LTR) methods are machine learning techniques which try to solve ranking problems [21].", "startOffset": 99, "endOffset": 103}, {"referenceID": 15, "context": "LTR methods have been widely used in many different areas such as information retrieval, natural language processing, and recommender systems [16, 21].", "startOffset": 142, "endOffset": 150}, {"referenceID": 20, "context": "LTR methods have been widely used in many different areas such as information retrieval, natural language processing, and recommender systems [16, 21].", "startOffset": 142, "endOffset": 150}, {"referenceID": 6, "context": "To build our LTR model, we consider a number of ranking algorithms which are among state-of-the-art in many test collections: ListNet [7], RankingSVM [15], AdaRank [33], RankNet [6], LambdaRank [5], and ListMLE [32].", "startOffset": 134, "endOffset": 137}, {"referenceID": 14, "context": "To build our LTR model, we consider a number of ranking algorithms which are among state-of-the-art in many test collections: ListNet [7], RankingSVM [15], AdaRank [33], RankNet [6], LambdaRank [5], and ListMLE [32].", "startOffset": 150, "endOffset": 154}, {"referenceID": 32, "context": "To build our LTR model, we consider a number of ranking algorithms which are among state-of-the-art in many test collections: ListNet [7], RankingSVM [15], AdaRank [33], RankNet [6], LambdaRank [5], and ListMLE [32].", "startOffset": 164, "endOffset": 168}, {"referenceID": 5, "context": "To build our LTR model, we consider a number of ranking algorithms which are among state-of-the-art in many test collections: ListNet [7], RankingSVM [15], AdaRank [33], RankNet [6], LambdaRank [5], and ListMLE [32].", "startOffset": 178, "endOffset": 181}, {"referenceID": 4, "context": "To build our LTR model, we consider a number of ranking algorithms which are among state-of-the-art in many test collections: ListNet [7], RankingSVM [15], AdaRank [33], RankNet [6], LambdaRank [5], and ListMLE [32].", "startOffset": 194, "endOffset": 197}, {"referenceID": 31, "context": "To build our LTR model, we consider a number of ranking algorithms which are among state-of-the-art in many test collections: ListNet [7], RankingSVM [15], AdaRank [33], RankNet [6], LambdaRank [5], and ListMLE [32].", "startOffset": 211, "endOffset": 215}, {"referenceID": 0, "context": "To aggregate all the mentioned regression and learning to rank results, we use supervised Kemeny approach [1].", "startOffset": 106, "endOffset": 109}, {"referenceID": 16, "context": "Kemeny optimal aggregation [17] tries to minimize total number of pairwise disagreements between the final ranking and the outputs of all base rankers.", "startOffset": 27, "endOffset": 31}, {"referenceID": 17, "context": "where k(\u03b1, \u03b2) is the Kendall tau distance [18] measured as:", "startOffset": 42, "endOffset": 46}, {"referenceID": 2, "context": "To find the weight of each ranker, we propose to perform a Randomized Search [3].", "startOffset": 77, "endOffset": 80}, {"referenceID": 8, "context": "In the experiments, we consider an extended version of MovieTweetings dataset [9] which is provided by ACM RecSys Challenge 2014 [27].", "startOffset": 78, "endOffset": 81}, {"referenceID": 26, "context": "In the experiments, we consider an extended version of MovieTweetings dataset [9] which is provided by ACM RecSys Challenge 2014 [27].", "startOffset": 129, "endOffset": 133}, {"referenceID": 13, "context": "The evaluation measure is the mean of normalized discounted cumulative gain [14] computed for top 10 tweets of each user.", "startOffset": 76, "endOffset": 80}, {"referenceID": 24, "context": "In our experiments, we used Scikit-learn library [25] for all the regression and feature selection algorithms.", "startOffset": 49, "endOffset": 53}, {"referenceID": 2, "context": "To select the parameters of the learning methods, we performed hyper-parameter optimization using Randomized Search [3] with 5-fold cross validation.", "startOffset": 116, "endOffset": 119}, {"referenceID": 32, "context": "For AdaRank, we used the software developed in Microsoft Research [33].", "startOffset": 66, "endOffset": 70}], "year": 2015, "abstractText": "User engagement refers to the amount of interaction an instance (e.g., tweet, news, and forum post) achieves. Ranking the items in social media websites based on the amount of user participation in them, can be used in different applications, such as recommender systems. In this paper, we consider a tweet containing a rating for a movie as an instance and focus on ranking the instances of each user based on their engagement, i.e., the total number of retweets and favorites it will gain. For this task, we define several features which can be extracted from the meta-data of each tweet. The features are partitioned into three categories: user-based, movie-based, and tweet-based. We show that in order to obtain good results, features from all categories should be considered. We exploit regression and learning to rank methods to rank the tweets and propose to aggregate the results of regression and learning to rank methods to achieve better performance. We have run our experiments on an extended version of MovieTweeting dataset provided by ACM RecSys Challenge 2014. The results show that learning to rank approach outperforms most of the regression models and the combination can improve the performance significantly.", "creator": "LaTeX with hyperref package"}}}