{"id": "1503.01655", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Mar-2015", "title": "Studying the Wikipedia Hyperlink Graph for Relatedness and Disambiguation", "abstract": "Hyperlinks and other relations in Wikipedia are a extraordinary resource which is still not fully understood. In this paper we study the different types of links in Wikipedia, and contrast the use of the full graph with respect to just direct links. We apply a well-known random walk algorithm on two tasks, word relatedness and named-entity disambiguation. We show that using the full graph is more effective than just direct links by a large margin, that non-reciprocal links harm performance, and that there is no benefit from categories and infoboxes, with coherent results on both tasks. We set new state-of-the-art figures for systems based on Wikipedia links, comparable to systems exploiting several information sources and/or supervised machine learning. Our approach is open source, with instruction to reproduce results, and amenable to be integrated with complementary text-based methods.", "histories": [["v1", "Thu, 5 Mar 2015 15:08:21 GMT  (52kb,D)", "https://arxiv.org/abs/1503.01655v1", null], ["v2", "Thu, 12 Mar 2015 23:10:41 GMT  (52kb,D)", "http://arxiv.org/abs/1503.01655v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["eneko agirre", "er barrena", "aitor soroa"], "accepted": false, "id": "1503.01655"}, "pdf": {"name": "1503.01655.pdf", "metadata": {"source": "CRF", "title": "Studying the Wikipedia Hyperlink Graph for Relatedness and Disambiguation", "authors": ["Eneko Agirre", "Ander Barrena"], "emails": ["e.agirre@ehu.eus", "ander.barrena@ehu.eus", "a.soroa@ehu.eus"], "sections": [{"heading": null, "text": "Hyperlinks and other relations in Wikipedia are a extraordinary resource which is still not fully understood. In this paper we study the different types of links in Wikipedia, and contrast the use of the full graph with respect to just direct links. We apply a well-known random walk algorithm on two tasks, word relatedness and named-entity disambiguation. We show that using the full graph is more effective than just direct links by a large margin, that non-reciprocal links harm performance, and that there is no benefit from categories and infoboxes, with coherent results on both tasks. We set new state-of-the-art figures for systems based on Wikipedia links, comparable to systems exploiting several information sources and/or supervised machine learning. Our approach is open source, with instruction to reproduce results, and amenable to be integrated with complementary text-based methods."}, {"heading": "1 Introduction", "text": "Hyperlinks and other relations between concepts and instances in Wikipedia have been successfully used in semantic tasks (Milne and Witten, 2013). Still, many questions about the best way to leverage those links remain unanswered. For instance, methods using direct hyperlinks alone would wrongly disambiguate Lions in Figure 1 to B&I Lions, a rugby team from Britain and Ireland, as it shares two direct links to potential referents in the context (Darrel Fletcher, a British football player, and Cape Town, the city where the team suffered some memorable defeats), while Highveld Lions, a cricket\nteam from South Africa, has only one. When considering the whole graph of hyperlinks we find that the cricket team is related to two cricketers named Alan Kourie and Duncan Fletcher and could thus pick the right entity for Lions in this context. In this paper we will study this and other questions about the use of hyperlinks in word relatedness (Gabrilovich and Markovitch, 2007) and named-entity disambiguation, NED (Hachey et al., 2012).\nPrevious work on this area has typically focused on novel algorithms which work on a specific mix of resource, information source, task and test dataset (cf. Sect. 7). In the case of NED, the evaluation of the disambiguation component is confounded by interactions with mention spotting and candidate\nar X\niv :1\n50 3.\n01 65\n5v 2\n[ cs\n.C L\n] 1\n2 M\nar 2\n01 5\ngeneration. With very few exceptions, there is little analysis of components and alternatives, and it is very difficult to learn any insight beyond the fact that the mix under study attained certain performance on the target dataset1. The number of algorithms and datasets is growing by the day, with no wellestablished single benchmark, and the fact that some systems are developed on test data, coupled with reproducibility problems (Fokkens et al., 2013, on word relatedness), makes it very difficult to know where the area stands. There is a need for clear points of reference which allow to understand where each information source and algorithm stands with respect to other alternatives.\nWe thus depart from previous work, seeking to set such a point of reference, and focus on a single knowledge source (hyperlinks in Wikipedia) with a clear research objective: given a wellestablished random walk algorithm (Personalized PageRank (Haveliwala, 2002)) we explore sources of links and filtering methods, and contrast the use of the full graph with respect to using just direct links. We follow a clear development/test/analysis methodology, evaluating on a extensive range of both relatedness and NED datasets. The results are confirmed in both tasks, yielding more support to the findings in this research. All software and data are publicly available, with instructions to obtain out-ofthe-box replicability2.\nThe contributions of our research are the following: (1) We show for the first time that performing random walks over the full graph is preferable than considering only direct links. (2) We study several sources of links, showing that non-reciprocal links hurt and that the contribution of the category structure and links in infoboxes is residual. (3) We set the new state-of-the-art for systems based on Wikipedia links for both word relatedness and named-entity disambiguation. The results are close to the best systems to date, which use several information sources and/or supervised machine learning techniques, and specialize on either relatedness or disambiguation.\n1See (Hachey et al., 2012) and (Garc\u0131\u0301a et al., 2014) for two exceptions on NED. The first is limited to a single dataset, the second explores methods based on direct links, which we extend to using the full graph.\n2http://ixa2.si.ehu.es/ukb/README.wiki. txt\nOur work shows that a careful analysis of varieties of graphs using a well-known random walk algorithm pays off more than most ad-hoc algorithms.\nThe article is structured as follows. We first present previous work, followed by the different options to build hyperlink graphs. Sect. 4 reviews random walks for relatedness and NED. Sect. 5 sets the experimental methodology, followed by the analysis and results on development data (Sect. 6) and the comparison to the state of the art (Sect. 7). Finally, Sect. 8 draws the conclusions."}, {"heading": "2 Previous work", "text": "The irruption of Wikipedia has opened up enormous opportunities for natural language processing (Hovy et al., 2013), with many derived knowledge-bases, including DBpedia (Bizer et al., 2009), Freebase (Bollacker et al., 2008), and BabelNet (Navigli and Ponzetto, 2012a), to name a few. These resources have been successfully used on semantic processing tasks like word relatedness, named-entity disambiguation (NED), also known as entity linking, and the closely related Wikification. Broadly speaking, Wikipedia-based approaches to those tasks can be split between those using the text in the articles (e.g., Gabrilovich and Markovitch, 2007) and those using the links between articles (e.g., Guo et al., 2011).\nRelatedness systems take two words and return a high number if the two words are similar or closely related3 (e.g. professor - student), and a low number otherwise (e.g. professor - cucumber). Evaluation is performed comparing the returned values to those by humans (Rubenstein and Goodenough, 1965).\nIn NED (Hachey et al., 2012) the input is a mention of a named-entity in context and the output is the appropriate instance from Wikipedia, DBpedia or Freebase (cf. Figure 1). Wikification is similar (Mihalcea and Csomai, 2007), but target terms include common nouns and only relevant terms are disambiguated. Note that the disambiguation component in Wikification and NED can be the same.\nOur work focuses on relatedness and NED. We favored NED over Wikification because of the larger number of systems and evaluation datasets, but our conclusions are applicable to Wikification, as well\n3Relatedness is more general than similarity. For the sake of simplicity, we will talk about relatedness on this paper.\nas other Wikipedia-derived resources. In this section we will focus on previous work using Wikipedia links for relatedness, NED and Wikification. Although relatedness and disambiguation are closely related (relatedness to context terms is an important disambiguation clue for NED), most of the systems are evaluated in either relatedness or NED, with few exceptions, like WikiMiner (Milne and Witten, 2013), KORE (Hoffart et al., 2012) and the one presented in this paper.\nMilne and Witten (2008a) are the first to use hyperlinks between articles for relatedness. They compare two articles according to the number of incoming links that they have in common (i.e. overlap of direct-links) based on Normalized Google Distance (NGD), combined with several heuristics and collocation strength. In later work (Milne and Witten, 2013), they incorporated machine learning. The authors also apply their technique to NED (Milne and Witten, 2008b), using their relatedness measures to train a supervised classifier. Unfortunately they do not present results of their link-based method alone, so we decided to reimplement it (cf. Sect. 6). We show that, under the same conditions, using the fullgraph is more effective in both tasks. We also run their out-of-the-box system4 on the same datasets as ours (cf. Sect. 7), with results below ours.\nApart from hyperlinks between articles, other works on relatedness use the category structure (Strube and Ponzetto, 2006; Ponzetto and Strube, 2007; Ponzetto and Strube, 2011) to run path-based relatedness algorithms which had been successful on WordNet (Pedersen et al., 2004), or use relations in infoboxes (Nastase and Strube, 2013). In all cases, they obtain performance figures well below hyperlink-based systems (cf. Sect. 7). We will explore the contribution of such relations (cf. Sect. 3), incorporating them to the hyperlink graph.\nAttempts to use the whole graph of hyperlinks for relatedness have been reported before. Yeh et al. (2009) obtained very low results on relatedness using an algorithm based on random walks similar to ours. Similar in spirit, Yazdani and Popescu-Belis (2013) built a graph derived from the Freebase Wikipedia Extraction dataset, which is derived but richer\n4https://sourceforge.net/projects/ wikipedia-miner/\nthan Wikipedia. Even if they mix hyperlinks with textual similarity, their results are lower than ours. One of the key differences with these systems is that we remove non-reciprocal links (cf. Sect. 3).\nRegarding link-based methods for NED, there is only one system which relies exclusively on hyperlinks. Guo et al. (2011) use direct hyperlinks between the target entity and the mentions in the context, counting the number of such links. We show that the use of the full graph produces better results.\nThe rest of NED systems present complex combinations. Lemahnn et al. (2010) present a supervised system combining features based on hyperlinks, categories, text similarity and relations from infoboxes. Despite their complex and rich system, we will show that they perform worse than our system. Hachey et al. (2011) explored hyperlinks beyond direct links for NED, building subgraphs for each context using paths of length two departing from the context terms, combined with text-based relatedness. We will show that the full graph is more effective than limiting the distance to two, and report better results than their system. Several authors have included direct links using the aforementioned NGD in their combined systems (Ratinov et al., 2011; Hoffart et al., 2011). Unfortunately, they do no report separate results for the NGD component. In very recent work Garc\u0131\u0301a et al. (2014) compare NGD with several other algorithms using direct links, but do not explore the full graph, or try to characterize links. We will see that their results are well below ours (cf. Sect. 7).\nGraph-based algorithms for relatedness and disambiguation have been successfully used on other resources, particularly WordNet. Hughes and Ramage (2007) were the first presenting a random walk algorithm over the WordNet graph. Agirre et al. (2010) improved over their results using a similar random walk algorithm on several variations of WordNet relations, reporting the best results to date among WordNet-based algorithms. The same algorithm was used for word sense disambiguation (Agirre et al., 2014), also reporting state-of-the-art results. We use the same open source software in our experiments. As an alternative to random walks, Tsatsaronis et al. (2010) use a path-based system over the WordNet relation graph.\nIn more recent work (Navigli and Ponzetto, 2012b; Pilehvar et al., 2013), the authors present two\nrelatedness algorithms for BabelNet, an enriched version of WordNet including articles from Wikipedia, hyperlinks and cross-lingual relations from nonEnglish Wikipedias. In related work, Moro et al. (2014) present a multi-step NED algorithm on BabelNet, building semantic graphs for each context. We will show that Wikipedia hyperlinks alone are able to provide similar performance on both tasks."}, {"heading": "3 Building Wikipedia Graphs", "text": "Wikipedia pages can be classified into main articles, category pages, redirects and disambiguation pages. Given a Wikipedia dump (a snapshot from April 4, 2013), we mine links between articles, between articles and category pages, as well as the links between category pages (the category structure). Our graphs include a directed edge from one article to another iff the text of the first article contains a hyperlink to the second article. In addition, we also include hyperlinks in infoboxes.\nThe graph contains two types of nodes (articles and categories) and three types of directed edges: hyperlinks from article to article (H), infobox links from article to article (I), links from article to category and links from category to category (C).\nWe constructed several graphs using different combinations of nodes and edges. In addition to the directed versions (D) we also constructed an undirected version (U), and a reduced graph which only contains links which are reciprocal (R), that is, we add a pair of edges between a1 and a2 if and only if there exists a hyperlink from a1 to a2 and from a2 to a1. Reciprocal links capture the intuition that both articles are relevant to each other, and tackle issues with links to low relevance articles, e.g. links to articles on specific years like 1984. Some authors weight links according to their relevance (Milne and Witten, 2013). Our heuristic to keep only reciprocal links can be seen as a simpler, yet effective, method to avoid low relevance links.\nTable 1 gives the number of nodes and edges in some selected graphs. The graph with less edges is the one with reciprocal hyperlinks HR, and the graphs with most edges are those with undirected edges, as each edge is modeled as two directed edges5. The number of nodes is similar in all, except\n5This was done in order to combine undirected and recipro-\nfor the infobox graphs (infoboxes are only available for a few articles), and the reciprocal graph HR, as relatively few nodes have reciprocal edges."}, {"heading": "3.1 Building the dictionary", "text": "In order to link running text to the articles in the graph, we use a dictionary, i.e., a static association between string mentions with all possible articles the mention can refer to.\nWe built our dictionary from the same Wikipedia dump, using article titles, redirections, disambiguation pages, and anchor text. Mention strings are lowercased and all text between parentheses is removed. If an anchor links to a disambiguation page, the text is associated with all possible articles the disambiguation page points to. Each association between a mention and article is scored with the prior probability, estimated as the number of times that the mention occurs in an anchor divided by the to-\ncal edges, and could be avoided in other cases.\ntal number of occurrences of the mention as anchor. Note that our dictionary can disambiguate any mention, just returning the highest-scoring article. Table 2 partially shows a sample entry in our dictionary."}, {"heading": "4 Random Walks", "text": "The PageRank random walk algorithm (Brin and Page, 1998) is a method for ranking the vertices in a graph according to their relative structural importance. PageRank can be viewed as the result of a random walk process, where the final rank of node i represents the probability of a random walk over the graph ending on node i, at a sufficiently large time.\nPersonalized PageRank (PPR) is a variation of PageRank (Haveliwala, 2002), where the query of the user defines the importance of each node, biasing the resulting PageRank score to prefer nodes in the vicinity of the query nodes. The query bias is also called the teleport vector. PPR has been successfully used on the WordNet graph for relatedness (Hughes and Ramage, 2007; Agirre et al., 2010) and WSD (Agirre and Soroa, 2009; Agirre et al., 2014). In our experiments we use UKB version 2.16, an open source software for relatedness and disambiguation based on PPR. For the sake of space, we will skip the details, and refer the reader to those papers. PPR has two parameters: the number of iterations, and the damping factor, which controls the relative weight of the teleport vector."}, {"heading": "4.1 Random walks on Wikipedia", "text": "Given a dictionary and graph derived from Wikipedia (cf. Sect. 3), PPR expects a set of mentions, i.e., a set of strings which can be linked to Wikipedia articles via the dictionary. The method first initializes the teleport vector: for each mention in the input, the articles in the respective dictionary entry are set with an initial probability, and the rest of articles are set to\n6http://ixa2.si.ehu.es/ukb\nzero. We explored two options to set the initial probability of each article: the uniform probability or the prior probability in the dictionary. When an article appears in the dictionary entry for two mentions, the initial probability is summed up. In a second step, we apply PPR for a number of iterations, producing a probability distribution over Wikipedia articles in the form of a PPR vector (PPV).\nThe probability vector can be used for both relatedness and NED. For relatedness we produce a PPV vector for each of the words to be compared, using the single word as input mention. The relatedness between the target words is computed as the cosine between the respective PPV vectors. In order to speed up the computation, we can reduce the size of the PPV vectors, setting to zero all values below rank k after ordering the values in decreasing order.\nTable 3 shows the top 5 articles in the PPV vectors of two sample words. The relatedness between pairs Drink and Alcohol would be non-zero, as their respective vectors contain common articles.\nFor NED the input comprises the target entity mention and its context, defined as the set of mentions occurring within a 101 token window centered in the target. In order to extract mentions to articles in Wikipedia from the context, we match the longest strings in our dictionary as we scan tokens from left to right. We then initialize the teleport probability with all articles referred by the mentions. After computing Personalized PageRank, we output the article with highest rank in PPV among the possible articles for the target entity mention. Figure 1 shows an example of NED.\nIf the prior is being used to initialize weights, we multiply the prior probability with the Pagerank probabilities before computing the final ranks. In the rare cases7 where no known mention is found in the context, we return the node with the highest prior.\nNote that our NED and relatedness algorithms are related. NED is using using relatedness, as Pagerank probabilities are capturing how related is each candidate article to the context of the mention. Following the first-order and second-order co-occurrence abstraction (Islam and Inkpen, 2006; Agirre and Edmonds, 2007, Ch. 6), we can interpret that we do NED using first-order relatedness, while our relat-\n7Less than 3% of instances.\nedness uses second-order relatedness. Figure 2 summarizes all parameters mentioned so far, as well as their default values, which were set following previous work (Agirre et al., 2010; Agirre et al., 2014)."}, {"heading": "5 Experimental methodology", "text": "We summarize the datasets used in Table 4. RG, MC and 353 are the most used relatedness datasets to date, with TSA and KORE being more recent datasets where some top-ranking systems have been evaluated. Word relatedness datasets were lemmatized and lowercased, except for KORE, which is an entity relatedness dataset where the input comprises article titles8. Following common practice rankcorrelation (Spearman) was used for evaluation.\n8We had to manually adjust the articles in KORE, as the exact title depends on the Wikipedia version. We missed 3 for our 2013 version, which could slightly degrade our results.\nRegarding NED, the TAC Entity Linking competition is held annually. Due to its popularity it is useful to set the state of the art. We selected the datasets in 2009 and 2010, as they have been used to evaluate several top ranking systems, as well as the 2013 dataset, which is the most recent. In addition, we also provide results for AIDA, the largest and only dataset providing annotations for all entities in the documents, and KORE, a recent, very small dataset focusing on difficult mentions and short contexts. Evaluation was performed using accuracy, the ratio between correctly disambiguated instances and the total number of instances that have a link to an entity in the knowledge base9. Each dataset uses a different Wikipedia version, but fortunately Wikipedia keeps redirects from older article titles to the new version. As customary in the task, we automatically map the articles returned by our system to the version used in the gold standard.\nFollowing standard practice in NED, we do not evaluate mention detection10, that is, the datasets already specify which are the target mentions. Note that TAC provides so called \u201cqueries\u201d which can be substrings of the full mention, e.g. \u201cSmith\u201d for a mention like \u201cJohn Smith\u201d). Given a mention, we devised the following heuristics to improve candidate generation: (1) remove substring contained in parenthesis from the mention, then check dictionary, (2) if not found, remove \u201cthe\u201d if first token in the mention, then check dictionary, (3) if not found, remove middle token if mention contains three tokens, then check dictionary, (4) if not found, search for a matching entity using the Wikipedia API11. The heuristics provide an improvement of around 4 points on development. Later analysis showed that these heuristics seem to be only relevant on the TAC datasets, because of the way the query strings are designed, but not on AIDA or KORE."}, {"heading": "5.1 Development and test", "text": "We wanted to follow a standard experimental design, with a clear development/test split for each task. Unfortunately there is no standard split in the literature,\n9Corresponds to non-NIL accuracy at TAC-KBP (also called KB accuracy) and Micro P@1.0 in (Hoffart et al., 2011)\n10See (Cornolti et al., 2013) for a framework to evaluate both mention detection and disambiguation.\n11http://en.wikipedia.org/w/api.php\nand the choice is difficult: The development dataset should be representative enough to draw conclusions on different alternatives and parameters, but at the same time the most relevant datasets in the literature should be left for testing, in order to have enough points for comparison. In addition, some recent algorithms suposedly setting the state of the art are only tested on newly produced datasets. Note also that relatedness datasets are small, making it difficult to find statistically significant differences.\nIn order to strike a balance between the need for in-depth analysis and fair comparison to previous results, we decided to focus on the two oldest datasets from each task for development and analysis: RG for relatedness and a subset of 200 polysemic instances from TAC09 for NED (TAC09200)12. The rest will be used for test, where the parameters have been set on development. Given the need for significant conclusions, we re-checked the main conclusions drawn from development data using the aggregation of all test datasets, but only after the comparison to the state of the art had been performed. This way we ensure both a fair comparison with the state of the art and a well-grounded analysis.\nWe performed significance tests using Fisher\u2019s ztransformation for relatedness (Press et al., 2002, equation 14.5.10), and paired bootstrap resampling for NED (Noreen, 1989), accepting differences with p-value < 0.05. Given the small size of the datasets, when necessary, we also report statistical significance when joining all datasets as just mentioned."}, {"heading": "6 Studying the graph and parameters", "text": "In this section we study the performance of the different graphs and parameters on the two development datasets, RG and TAC09200. The next section reports the results on the test sets for the best parameters, alongside state-of-the-art system results.\nAs mentioned in Sect. 4.1, PPR has several parameters and variants (cf. Figure 2). We first checked exhaustively all possible combinations for different graphs, with the rest of parameters set to default values. We then optimized each of the parameters in turn, seeking to answer the following questions:\nWhich links help most? Table 1 shows the 12The dataset in http://ixa2.si.ehu.es/ukb/\nREADME.wiki.txt includes the subset.\nresults for selected graphs. The first seven rows present the results for each edge source in isolation, both using directed and undirected edges. Categories and infoboxes suffer from producing smaller graphs, with the hyperlinks yielding the best results. The undirected versions improve over directed links in all cases, with the use of reciprocal edges for hyperlinks obtaining the best results overall (the graphs with reciprocal edges for categories and infoboxes were too small and we omit them). The trend is the same in both relatedness and NED, highlighting the robustness of these results.\nRegarding combined graphs, we report the most significant combinations. The reciprocal graph of hyperlinks outperforms all combinations (including the combinations which were omitted), showing that categories and infoboxes do not help or even degrade slightly the results. The differences are statistically significant (either on the individual datasets or in the aggregation on all datasets) in all cases, confirming that HR is significantly better.\nThe degradation or lack of improvement when using infoboxes is surprising. We hypothesized that it could be caused by non-reciprocal links in HRIU. In fact, removing non-reciprocal links from HRIU improved results slightly on NED, matching those of HR. This lack of improvement with infoboxes, even when removing non-reciprocal links, can be explained by the fact that only 5% of reciprocal links in IU are not in HR. It seems that this additional 5% is not helping in this particular dataset. Regarding categories, the category structure is mostly a tree, which is a structure where random walks do not seem to be effective, as already observed in (Agirre et al., 2014) for WordNet.\nIs initialization of random walks important? The second row in Table 5 reports the result when using uniform distributions when initializing the random walks (instead of prior probabilities). The results degrade in both datasets, the difference being significant only for NED. This was later confirmed in the rest of relatedness and NED datasets: using prior probabilities for initialization improves results in all cases, but it is only significant in NED datasets. These results show that relatedness is less sensitive to changes in the distribution of meanings, that is, using the more informative prior distributions of meaning only improves results slightly. NED, on the contrary, is more sensitive, as the distribution of senses affects dramatically the performance.\nIs the value of \u03b1 and i important? The best \u03b1 on both datasets was obtained with default values (cf. Table 5), in agreement with related work using WordNet (Agirre et al., 2010). The lowest number of iterations where convergence was obtained were 30 and 15, respectively, although as few as 5 iterations yielded very similar performance (87.1 on relatedness, 68.0 on NED).\nIs the size of the vector, k, important for relatedness? The best performance was attained for the default k, with minor variations for k > 1000.\nIs the full graph helping? When the PPR algorithm does a single iteration, we can interpret that it is ranking all entities using direct links. When doing two iterations, we can loosely say that it is using links at distance two, and so on. Table 6 shows that\nPPR is able to take profit from the full graph well beyond 2 iterations, specially in relatedness. These results were confirmed in the full set of datasets, with statistically significant differences in all cases.\nIn addition, we reimplemented the relatedness and NED algorithms based on NGD over direct links (Milne and Witten, 2008a; Milne and Witten, 2008b), allowing to compare them to PPR on the same experimental conditions. We first developed the relatedness algorithm13. Table 6 reports the best variant, which outperforms the 0.64 on RG reported in their paper. We followed a similar methodology for NED14. Table 6 shows the results for NGD, which performs worse than PPR. This trend was confirmed on the full set of datasets for relatedness and NED with statistical significance in all cases except KORE, which is the smallest NED dataset. Figure 1 illustrates why the use of longer paths is beneficial. In fact, NGD returns 0.14 for B&I Lions and 0.13 for Highveld Lions, but PPR correctly returns 0.05 and 0.75, respectively.\nHow important is the Wikipedia version? Table 7 shows that the versions we tested are not affecting the results dramatically, and that using the last version does not yield better results in NED. Perhaps the larger size and number of hyperlinks of newer versions would only affect new articles and rare articles, but not the ones present in TAC09200. We kept using 2013 for test.\nWhat is the efficiency of the algorithm? The initialization takes around 5 minutes15, where most of the time is spent loading the dictionary into memory, 4m50s. Using a database instead, initialization takes 10s. Memory requirements for HR were\n13In order to replicate the NGD relatedness algorithm, we checked the open source code available, exploring the use of inlinks and outlinks and the use of maximum pairwise article relatedness. We also realized that the use of priors (\u201ccommonness\u201d according to the terminology in the paper) was hurting, so we dropped it. We checked both reciprocal and unidirectional versions of the hyperlink graph, with better results for the reciprocal graph.\n14We checked both reciprocal and undirected graphs with similar results, combined with prior (similar results), weighted terms in the context (with improvement) and checked the use of ambiguous mentions in the context (marginal improvement). Reported results correspond to reciprocal, combination with prior, weighting terms and using only monosemous mentions.\n15Time measured in a single server with Xeon E7-4830 8 core processors, 2130 MHz, 64 GB RAM.\n4.7 Gb, down to 1.1 Gb when using the database. The main bottleneck of our system is the computation of Personalized PageRank, each iteration taking around 0.60 seconds. We are currently checking fast approximations for Pagerank, and plan to improve efficiency."}, {"heading": "7 Comparison to related work", "text": "In the previous section we presented several results on the same experimental conditions. We now use the graph and parametrization which yield the best results on development (default parameters with HR). Comparison to the state of the art is complicated by many systems reporting results on different datasets, which causes the tables in this section to be rather sparse. The comparison for relatedness is straightforward, but, in NED, it is not possible to factor out the impact of the candidate generation step. Given the fact that our candidate generation procedure is not particularly sophisticated, we don\u2019t think this is a decisive factor in favour of our results.\nTable 8 and 9 report the results of the best sys-\ntems on both tasks. Given that several systems were developed on test data, we also report our results on RG and TAC2009, marking all such results (see caption of tables for details). We split the results in both tables in three sets: top rows for systems using link and graph information alone, middle rows for link- and graph-based systems using WordNet and/or Wikipedia, and bottom rows for more complex systems. We report the results of our system repeatedly in each set of rows, for easier comparison. Our main focus is on the top rows, which show the superiority of our results with respect to other systems using Wikipedia links and graphs. The middle and bottom rows show the relation to the state of the art.\nFor easier exposition, we will examine the results by row section simultaneously on relatedness and NED. The top rows in Table 8 report four relatedness systems which have already been presented in Sect. 2, showing that our system is best in all five datasets. Note that the (Milne and Witten, 2013) row was obtained running their publicly available system\nwith the supervised Machine Learning component turned off (see below for the results using SUP). The top rows of table 9 report the most frequent baseline (as produced by our dictionary) and three link-based systems (cf. Sect. 2), showing that our method is best in all five datasets. These results show that the use of the full graph as devised in this paper is a winning strategy.\nThe relatedness results in the middle rows of Table 8 include several systems using WordNet and/or Wikipedia (cf. Sect. 2), including the system in (Agirre et al., 2010), which we run out-of-the-box with default values. To date, link-based systems using WordNet had reported stronger results than their counterparts on Wikipedia, but the table shows that our Wikipedia-based results are the strongest on all relatedness datasets but one (MC, the smallest dataset, with only 30 pairs). In addition, the table shows our results when combining random walks on Wikipedia and WordNet16, which yields improvements in most datasets. In the counterpart for NED in Table 9, Moro et al. (2014) outperform our system, specially in the smaller KORE (143 instances), but note that they use a richer graph which combines WordNet, the English Wikipedia and hyperlinks from other language Wikipedias.\nFinally, the bottom rows in both tables report the\n16We multiply the scores of PPR on Wikipedia and WordNet.\nbest systems to date. For lack of space, we cannot review systems not using Wikipedia links. Regarding relatedness, we can see that our combination of WordNet and Wikipedia would rank second in all datasets, with only one single system (based on corpora) beating our system in more than one dataset (Radinsky et al., 2011). Regarding NED, our system ranks first in the TAC datasets, including the best systems that participated in the TAC competitions (Varma et al., 2009; Lehmann et al., 2010; Cucerzan and Sil, 2013), and second to (Moro et al., 2014) on AIDA and KORE."}, {"heading": "8 Conclusions and Future Work", "text": "This work departs from previous work based on Wikipedia and derived resources, as it focuses on a single knowledge source (links in Wikipedia) with a clear research objective: given a well-established random walk algorithm we explored which sources of links and filtering methods are useful, contrasting the use of the full graph with respect to using just direct links. We follow a clear development/test/analysis methodology, evaluating on a extensive range of both relatedness and NED datasets. All software and data are publicly available, with instructions to obtain out-of-the-box replicability17.\n17http://ixa2.si.ehu.es/ukb/README.wiki. txt\nWe show for the first time that random walks over the full graph of links improve over direct links. We studied several variations of sources of links, showing that non-reciprocal links hurt and that the contribution of the category structure and relations in infoboxes is residual. This paper sets a new state-ofthe-art for systems based on Wikipedia links on both word relatedness and named-entity disambiguation datasets. The results are close to those of the best combined systems, which specialize on either relatedness or disambiguation, use several information sources and/or supervised machine learning techniques. This work shows that a careful analysis of varieties of graphs using a well-known random walk algorithm pays off more than most ad-hoc algorithms proposed up to date.\nFor the future, we would like to explore ways to filter out informative hyperlinks, perhaps weighting edges according to their relevance, and would also like to speed up the random-walk computations.\nThis article showed the potential of the graph of hyperlinks. We would like to explore combinations with other sources of information and algorithms, perhaps using supervised machine learning. For relatedness, we already showed improvement when combining with random walks over WordNet, but would like to explore tighter integration (Pilehvar et al., 2013). For NED, local methods (Ratinov et al., 2011; Han and Sun, 2011), global optimization strategies based on keyphrases in context like KORE (Hoffart et al., 2012) and doing NED jointly with word sense disambiguation (Moro et al., 2014), all are complementary to our method and thus promising directions."}, {"heading": "Acknowledgements", "text": "This work was partially funded by MINECO (CHIST-ERA READERS project \u2013 PCIN-2013002- C02-01) and the European Commission (QTLEAP \u2013 FP7-ICT-2013.4.1-610516). Ander Barrena is supported by a PhD grant from the University of the Basque Country."}], "references": [{"title": "Personalizing PageRank for Word Sense Disambiguation", "author": ["E. Agirre", "A. Soroa."], "venue": "Proceedings of 14th Conference of the European Chapter of the Association for Computational Linguistics, Athens, Greece.", "citeRegEx": "Agirre and Soroa.,? 2009", "shortCiteRegEx": "Agirre and Soroa.", "year": 2009}, {"title": "A Study on Similarity and Relatedness Using Distributional and WordNet-based Approaches", "author": ["E. Agirre", "A. Soroa", "E. Alfonseca", "K. Hall", "J. Kravalova", "M. Pasca."], "venue": "Proceedings of annual meeting of the North American Chapter of the Association of Compu-", "citeRegEx": "Agirre et al\\.,? 2009", "shortCiteRegEx": "Agirre et al\\.", "year": 2009}, {"title": "Exploring Knowledge Bases for Similarity", "author": ["E. Agirre", "M. Cuadros", "G. Rigau", "A. Soroa."], "venue": "Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC\u201910), Valletta, Malta, May. European Language Resources As-", "citeRegEx": "Agirre et al\\.,? 2010", "shortCiteRegEx": "Agirre et al\\.", "year": 2010}, {"title": "Random walks for knowledge-based word sense disambiguation", "author": ["Eneko Agirre", "Oier Lopez de Lacalle", "Aitor Soroa."], "venue": "Computational Linguistics, 40(1):57\u201388.", "citeRegEx": "Agirre et al\\.,? 2014", "shortCiteRegEx": "Agirre et al\\.", "year": 2014}, {"title": "Don\u2019t count, predict! A systematic comparison of context-counting vs", "author": ["Marco Baroni", "Georgiana Dinu", "Germn Kruszewski."], "venue": "context-predicting semantic vectors. In Proceedings of ACL.", "citeRegEx": "Baroni et al\\.,? 2014", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Dbpedia - a crystallization point for the web of data", "author": ["Christian Bizer", "Jens Lehmann", "Georgi Kobilarov", "S\u00f6ren Auer", "Christian Becker", "Richard Cyganiak", "Sebastian Hellmann."], "venue": "Web Semant., 7(3):154\u2013165, September.", "citeRegEx": "Bizer et al\\.,? 2009", "shortCiteRegEx": "Bizer et al\\.", "year": 2009}, {"title": "Freebase: A collaboratively created graph database for structuring human knowledge", "author": ["Kurt Bollacker", "Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor."], "venue": "Proceedings of the 2008 ACM SIGMOD International Conference on Management", "citeRegEx": "Bollacker et al\\.,? 2008", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "The Anatomy of a Largescale Hypertextual Web Search Engine", "author": ["S. Brin", "L. Page."], "venue": "Proceedings of the seventh international conference on World Wide Web 7, WWW7, pages 107\u2013117, Amsterdam, The Netherlands, The Netherlands. Elsevier Science", "citeRegEx": "Brin and Page.,? 1998", "shortCiteRegEx": "Brin and Page.", "year": 1998}, {"title": "Using encyclopedic knowledge for named entity disambiguation", "author": ["Razvan C. Bunescu", "Marius Pasca."], "venue": "EACL. The Association for Computer Linguistics.", "citeRegEx": "Bunescu and Pasca.,? 2006", "shortCiteRegEx": "Bunescu and Pasca.", "year": 2006}, {"title": "A framework for benchmarking entityannotation systems", "author": ["Marco Cornolti", "Paolo Ferragina", "Massimiliano Ciaramita."], "venue": "Proceedings of the 22Nd International Conference on World Wide Web, WWW", "citeRegEx": "Cornolti et al\\.,? 2013", "shortCiteRegEx": "Cornolti et al\\.", "year": 2013}, {"title": "The msr systems for entity linking and temporal slot filling at tac 2013", "author": ["Silviu Cucerzan", "Avirup Sil."], "venue": "Proceedings of the Sixth Text Analysis Conference (TAC 2013), page 10. National Institute of Standards and Technology (NIST).", "citeRegEx": "Cucerzan and Sil.,? 2013", "shortCiteRegEx": "Cucerzan and Sil.", "year": 2013}, {"title": "Large-Scale Named Entity Disambiguation Based on Wikipedia Data", "author": ["S. Cucerzan."], "venue": "Proceedings of EMNLP-CoNLL, volume June, pages 708\u2013716.", "citeRegEx": "Cucerzan.,? 2007", "shortCiteRegEx": "Cucerzan.", "year": 2007}, {"title": "Offspring from reproduction problems: What replication failure teaches us", "author": ["Antske Fokkens", "Marieke van Erp", "Marten Postma", "Ted Pedersen", "Piek Vossen", "Nuno Freire."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguis-", "citeRegEx": "Fokkens et al\\.,? 2013", "shortCiteRegEx": "Fokkens et al\\.", "year": 2013}, {"title": "Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis", "author": ["E. Gabrilovich", "S. Markovitch."], "venue": "Proc of IJCAI, pages 6\u201312.", "citeRegEx": "Gabrilovich and Markovitch.,? 2007", "shortCiteRegEx": "Gabrilovich and Markovitch.", "year": 2007}, {"title": "Comparative evaluation of link-based approaches for candidate ranking in link-to-wikipedia systems", "author": ["Norberto Fern\u00e1ndez Garc\u0131\u0301a", "Jes\u00fas Arias-Fisteus", "Luis S\u00e1nchez Fern\u00e1ndez"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "Garc\u0131\u0301a et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Garc\u0131\u0301a et al\\.", "year": 2014}, {"title": "A graph-based method for entity linking", "author": ["Yuhang Guo", "Wanxiang Che", "Ting Liu", "Sheng Li."], "venue": "Proceedings of 5th International Joint Conference on Natural Language Processing, page 10101018, Chiang Mai, Thailand, November. Asian Federation of", "citeRegEx": "Guo et al\\.,? 2011", "shortCiteRegEx": "Guo et al\\.", "year": 2011}, {"title": "Graphbased Named Entity Linking with Wikipedia", "author": ["B. Hachey", "W. Radford", "J.R. Curran."], "venue": "Proceedings of the 12th international conference on Web information system engineering, WISE\u201911, pages 213\u2013226, Berlin, Heidelberg. Springer-Verlag.", "citeRegEx": "Hachey et al\\.,? 2011", "shortCiteRegEx": "Hachey et al\\.", "year": 2011}, {"title": "Evaluating Entity Linking with Wikipedia", "author": ["B. Hachey", "W. Radford", "J. Nothman", "M. Honnibal", "J.R. Curran."], "venue": "Artif. Intell., 194:130\u2013150, January.", "citeRegEx": "Hachey et al\\.,? 2012", "shortCiteRegEx": "Hachey et al\\.", "year": 2012}, {"title": "A Generative Entity-mention Model for Linking Entities with Knowledge Base", "author": ["X. Han", "L. Sun."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, volume 1, pages 945\u2013954.", "citeRegEx": "Han and Sun.,? 2011", "shortCiteRegEx": "Han and Sun.", "year": 2011}, {"title": "Topic-sensitive PageRank", "author": ["T.H. Haveliwala."], "venue": "Proceedings of the 11th international conference on World Wide Web (WWW\u201902), pages 517\u2013526, New York, NY, USA.", "citeRegEx": "Haveliwala.,? 2002", "shortCiteRegEx": "Haveliwala.", "year": 2002}, {"title": "Robust Disambiguation of Named", "author": ["J. Hoffart", "M.A. Yosef", "I. Bordino", "H. F\u00fcrstenau", "M. Pinkal", "M. Spaniol", "B. Taneva", "S. Thater", "G. Weikum"], "venue": null, "citeRegEx": "Hoffart et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffart et al\\.", "year": 2011}, {"title": "Kore: Keyphrase overlap relatedness for entity disambiguation", "author": ["Johannes Hoffart", "Stephan Seufert", "Dat Ba Nguyen", "Martin Theobald", "Gerhard Weikum."], "venue": "Proceedings of the 21st ACM international conference on Information and knowledge manage-", "citeRegEx": "Hoffart et al\\.,? 2012", "shortCiteRegEx": "Hoffart et al\\.", "year": 2012}, {"title": "Collaboratively built semi-structured content and artificial intelligence: The story so far", "author": ["Eduard Hovy", "Roberto Navigli", "Simone Paolo Ponzetto."], "venue": "Artif. Intell., 194:2\u201327, January.", "citeRegEx": "Hovy et al\\.,? 2013", "shortCiteRegEx": "Hovy et al\\.", "year": 2013}, {"title": "Lexical Semantic Relatedness with Random Graph Walks", "author": ["T. Hughes", "D. Ramage."], "venue": "Proceedings of EMNLP-CoNLL-2007, pages 581\u2013589.", "citeRegEx": "Hughes and Ramage.,? 2007", "shortCiteRegEx": "Hughes and Ramage.", "year": 2007}, {"title": "Second order cooccurrence pmi for determining the semantic similarity of words", "author": ["A. Islam", "D. Inkpen."], "venue": "Proceedings of the International Conference on Language Resources and Evaluation (LREC 2006), pages 1033\u20131038.", "citeRegEx": "Islam and Inkpen.,? 2006", "shortCiteRegEx": "Islam and Inkpen.", "year": 2006}, {"title": "LCC Approaches to Knowledge Base Population at TAC 2010", "author": ["J. Lehmann", "S. Monahan", "L. Nezda", "A. Jung", "Y. Shi."], "venue": "Proceedings of the Text Analysis Conference.", "citeRegEx": "Lehmann et al\\.,? 2010", "shortCiteRegEx": "Lehmann et al\\.", "year": 2010}, {"title": "An Evaluation of Technologies for Knowledge Base Population", "author": ["P. McNamee", "H.T. Dang", "H. Simpson", "P. Schone", "S.M. Strassel."], "venue": "Proceedings of the 7th International Conference on Language Resources and Evaluation, page 369372.", "citeRegEx": "McNamee et al\\.,? 2010", "shortCiteRegEx": "McNamee et al\\.", "year": 2010}, {"title": "Wikify!: linking documents to encyclopedic knowledge", "author": ["Rada Mihalcea", "Andras Csomai."], "venue": "Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, pages 233\u2013242. ACM.", "citeRegEx": "Mihalcea and Csomai.,? 2007", "shortCiteRegEx": "Mihalcea and Csomai.", "year": 2007}, {"title": "Contextual correlates of semantic similarity", "author": ["George A. Miller", "Walter G. Charles."], "venue": "Language and Cognitive Processes, 6(1):1\u201328.", "citeRegEx": "Miller and Charles.,? 1991", "shortCiteRegEx": "Miller and Charles.", "year": 1991}, {"title": "An Effective, LowCost Measure of Semantic Relatedness Obtained from Wikipedia Links", "author": ["D. Milne", "I.H. Witten."], "venue": "Proceedings of the first AAAI Workshop on Wikipedia and Artificial Intelligence.", "citeRegEx": "Milne and Witten.,? 2008a", "shortCiteRegEx": "Milne and Witten.", "year": 2008}, {"title": "Learning to Link with Wikipedia", "author": ["D. Milne", "I.H. Witten."], "venue": "Proceeding of the 17th ACM conference on Information and knowledge mining - CIKM \u201908, page 509, New York, New York, USA. ACM Press.", "citeRegEx": "Milne and Witten.,? 2008b", "shortCiteRegEx": "Milne and Witten.", "year": 2008}, {"title": "An open-source toolkit for mining wikipedia", "author": ["David Milne", "Ian H. Witten."], "venue": "Artificial Intelligence, 194:222\u2013239, January.", "citeRegEx": "Milne and Witten.,? 2013", "shortCiteRegEx": "Milne and Witten.", "year": 2013}, {"title": "Entity linking meets word sense disambiguation: a unied approach", "author": ["Andrea Moro", "Alessandro Raganato", "Roberto Navigli."], "venue": "Transactions of the Association of Computational Linguistics, 2:231\u2013244, May.", "citeRegEx": "Moro et al\\.,? 2014", "shortCiteRegEx": "Moro et al\\.", "year": 2014}, {"title": "Transforming Wikipedia into a large Scale Multilingual Concept Network", "author": ["V. Nastase", "M. Strube."], "venue": "Artif. Intell., 194:62\u201385.", "citeRegEx": "Nastase and Strube.,? 2013", "shortCiteRegEx": "Nastase and Strube.", "year": 2013}, {"title": "BabelNet: The Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network", "author": ["R. Navigli", "S.P. Ponzetto."], "venue": "Artificial Intelligence, 193:217\u2013250.", "citeRegEx": "Navigli and Ponzetto.,? 2012a", "shortCiteRegEx": "Navigli and Ponzetto.", "year": 2012}, {"title": "BabelRelate! A Joint Multilingual Approach to Computing Semantic Relatedness", "author": ["R. Navigli", "S.P. Ponzetto."], "venue": "J\u00f6rg Hoffmann and Bart Selman, editors, AAAI. AAAI Press.", "citeRegEx": "Navigli and Ponzetto.,? 2012b", "shortCiteRegEx": "Navigli and Ponzetto.", "year": 2012}, {"title": "Computer-Intensive Methods for Testing Hypotheses", "author": ["E.W. Noreen."], "venue": "John Wiley & Sons.", "citeRegEx": "Noreen.,? 1989", "shortCiteRegEx": "Noreen.", "year": 1989}, {"title": "Wordnet::similarity: Measuring the relatedness of concepts", "author": ["Ted Pedersen", "Siddharth Patwardhan", "Jason Michelizzi."], "venue": "Demonstration Papers at HLT-NAACL 2004, HLT-NAACL\u2013Demonstrations \u201904, pages 38\u201341, Stroudsburg, PA, USA. Association", "citeRegEx": "Pedersen et al\\.,? 2004", "shortCiteRegEx": "Pedersen et al\\.", "year": 2004}, {"title": "Align, Disambiguate and Walk: a Unified Approach for Measuring Semantic Similarity", "author": ["Mohammad Taher Pilehvar", "David Jurgens", "Roberto Navigli."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1341\u2013", "citeRegEx": "Pilehvar et al\\.,? 2013", "shortCiteRegEx": "Pilehvar et al\\.", "year": 2013}, {"title": "Knowledge derived from Wikipedia for computing semantic relatedness", "author": ["S.P. Ponzetto", "M. Strube."], "venue": "Journal of Artificial Intelligence Research, 30:181\u2013 212.", "citeRegEx": "Ponzetto and Strube.,? 2007", "shortCiteRegEx": "Ponzetto and Strube.", "year": 2007}, {"title": "Taxonomy Induction based on a Collaboratively built Knowledge Repository", "author": ["S.P. Ponzetto", "M. Strube."], "venue": "Artificial Intelligence, 175:1737\u20131756.", "citeRegEx": "Ponzetto and Strube.,? 2011", "shortCiteRegEx": "Ponzetto and Strube.", "year": 2011}, {"title": "Numerical Recipes: The Art of Scientific Computing V 2.10 With Linux Or Single-Screen License", "author": ["W.H. Press", "S.A. Teukolsky", "W.T. Vetterling", "B.P. Flannery"], "venue": null, "citeRegEx": "Press et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Press et al\\.", "year": 2002}, {"title": "A word at a time: computing word relatedness using temporal semantic analysis", "author": ["Kira Radinsky", "Eugene Agichtein", "Evgeniy Gabrilovich", "Shaul Markovitch."], "venue": "Proceedings of the 20th international conference on World wide web, WWW \u201911, pages 337\u2013346,", "citeRegEx": "Radinsky et al\\.,? 2011", "shortCiteRegEx": "Radinsky et al\\.", "year": 2011}, {"title": "Local and Global Algorithms for Disambiguation to Wikipedia", "author": ["L.A. Ratinov", "D. Roth", "D. Downey", "M. Anderson."], "venue": "The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Con-", "citeRegEx": "Ratinov et al\\.,? 2011", "shortCiteRegEx": "Ratinov et al\\.", "year": 2011}, {"title": "Contextual Correlates of Synonymy", "author": ["H. Rubenstein", "J.B. Goodenough."], "venue": "Communications of the ACM, 8(10):627\u2013633.", "citeRegEx": "Rubenstein and Goodenough.,? 1965", "shortCiteRegEx": "Rubenstein and Goodenough.", "year": 1965}, {"title": "Wikirelate! computing semantic relatedness using wikipedia", "author": ["Michael Strube", "Simone Paolo Ponzetto."], "venue": "Proceedings of the National Conference on Artificial Intelligence, volume 21, pages 1419\u20131424. Menlo Park, CA; Cambridge, MA; London; AAAI", "citeRegEx": "Strube and Ponzetto.,? 2006", "shortCiteRegEx": "Strube and Ponzetto.", "year": 2006}, {"title": "Text Relatedness Based on a Word Thesaurus", "author": ["G. Tsatsaronis", "I. Varlamis", "M. Vazirgiannis."], "venue": "J. Artif. Intell. Res. (JAIR), 37:1\u201339.", "citeRegEx": "Tsatsaronis et al\\.,? 2010", "shortCiteRegEx": "Tsatsaronis et al\\.", "year": 2010}, {"title": "IIIT Hyderabad at TAC 2009", "author": ["V. Varma", "V. Bharat", "S. Kovelamudi", "P. Bysani", "S. GSK", "K. Kumar N", "K. Reddy", "K. Kumar", "N. Maganti."], "venue": "Technical report.", "citeRegEx": "Varma et al\\.,? 2009", "shortCiteRegEx": "Varma et al\\.", "year": 2009}, {"title": "Computing text semantic relatedness using the contents and links of a hypertext encyclopedia", "author": ["Majid Yazdani", "Andrei Popescu-Belis."], "venue": "Artificial Intelligence, 194:176\u2013202, January.", "citeRegEx": "Yazdani and Popescu.Belis.,? 2013", "shortCiteRegEx": "Yazdani and Popescu.Belis.", "year": 2013}, {"title": "WikiWalk: Random walks on Wikipedia for Semantic Relatedness", "author": ["E. Yeh", "D. Ramage", "C.D. Manning", "E. Agirre", "A. Soroa."], "venue": "Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing (TextGraphs-4), pages 41\u2013", "citeRegEx": "Yeh et al\\.,? 2009", "shortCiteRegEx": "Yeh et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 31, "context": "Hyperlinks and other relations between concepts and instances in Wikipedia have been successfully used in semantic tasks (Milne and Witten, 2013).", "startOffset": 121, "endOffset": 145}, {"referenceID": 13, "context": "In this paper we will study this and other questions about the use of hyperlinks in word relatedness (Gabrilovich and Markovitch, 2007) and named-entity disambiguation, NED (Hachey et al.", "startOffset": 101, "endOffset": 135}, {"referenceID": 17, "context": "In this paper we will study this and other questions about the use of hyperlinks in word relatedness (Gabrilovich and Markovitch, 2007) and named-entity disambiguation, NED (Hachey et al., 2012).", "startOffset": 173, "endOffset": 194}, {"referenceID": 19, "context": "to set such a point of reference, and focus on a single knowledge source (hyperlinks in Wikipedia) with a clear research objective: given a wellestablished random walk algorithm (Personalized PageRank (Haveliwala, 2002)) we explore sources", "startOffset": 201, "endOffset": 219}, {"referenceID": 17, "context": "See (Hachey et al., 2012) and (Garc\u0131\u0301a et al.", "startOffset": 4, "endOffset": 25}, {"referenceID": 14, "context": ", 2012) and (Garc\u0131\u0301a et al., 2014) for two exceptions on NED.", "startOffset": 12, "endOffset": 34}, {"referenceID": 22, "context": "The irruption of Wikipedia has opened up enormous opportunities for natural language processing (Hovy et al., 2013), with many derived knowledge-bases, including DBpedia (Bizer et al.", "startOffset": 96, "endOffset": 115}, {"referenceID": 5, "context": ", 2013), with many derived knowledge-bases, including DBpedia (Bizer et al., 2009), Freebase", "startOffset": 62, "endOffset": 82}, {"referenceID": 6, "context": "(Bollacker et al., 2008), and BabelNet (Navigli and Ponzetto, 2012a), to name a few.", "startOffset": 0, "endOffset": 24}, {"referenceID": 34, "context": ", 2008), and BabelNet (Navigli and Ponzetto, 2012a), to name a few.", "startOffset": 22, "endOffset": 51}, {"referenceID": 44, "context": "Evaluation is performed comparing the returned values to those by humans (Rubenstein and Goodenough, 1965).", "startOffset": 73, "endOffset": 106}, {"referenceID": 17, "context": "In NED (Hachey et al., 2012) the input is a mention of a named-entity in context and the output is the appropriate instance from Wikipedia, DBpedia", "startOffset": 7, "endOffset": 28}, {"referenceID": 27, "context": "Wikification is similar (Mihalcea and Csomai, 2007), but target terms include common nouns and only relevant terms are disambiguated.", "startOffset": 24, "endOffset": 51}, {"referenceID": 31, "context": "are closely related (relatedness to context terms is an important disambiguation clue for NED), most of the systems are evaluated in either relatedness or NED, with few exceptions, like WikiMiner (Milne and Witten, 2013), KORE (Hoffart et al.", "startOffset": 196, "endOffset": 220}, {"referenceID": 21, "context": "are closely related (relatedness to context terms is an important disambiguation clue for NED), most of the systems are evaluated in either relatedness or NED, with few exceptions, like WikiMiner (Milne and Witten, 2013), KORE (Hoffart et al., 2012) and", "startOffset": 227, "endOffset": 249}, {"referenceID": 31, "context": "In later work (Milne and Witten, 2013), they incorporated machine learning.", "startOffset": 14, "endOffset": 38}, {"referenceID": 37, "context": "2007; Ponzetto and Strube, 2011) to run path-based relatedness algorithms which had been successful on WordNet (Pedersen et al., 2004), or use relations in infoboxes (Nastase and Strube, 2013).", "startOffset": 111, "endOffset": 134}, {"referenceID": 33, "context": ", 2004), or use relations in infoboxes (Nastase and Strube, 2013).", "startOffset": 39, "endOffset": 65}, {"referenceID": 48, "context": "Yeh et al. (2009) obtained very low results on relatedness using an algorithm based on random walks similar to ours.", "startOffset": 0, "endOffset": 18}, {"referenceID": 48, "context": "Similar in spirit, Yazdani and Popescu-Belis (2013) built a graph derived from the Freebase Wikipedia Extraction dataset, which is derived but richer", "startOffset": 19, "endOffset": 52}, {"referenceID": 15, "context": "Guo et al. (2011) use direct hyperlinks between the target entity and the mentions in the con-", "startOffset": 0, "endOffset": 18}, {"referenceID": 16, "context": "Hachey et al. (2011) explored hyperlinks beyond direct links", "startOffset": 0, "endOffset": 21}, {"referenceID": 43, "context": "Several authors have included direct links using the aforementioned NGD in their combined systems (Ratinov et al., 2011; Hoffart et al., 2011).", "startOffset": 98, "endOffset": 142}, {"referenceID": 20, "context": "Several authors have included direct links using the aforementioned NGD in their combined systems (Ratinov et al., 2011; Hoffart et al., 2011).", "startOffset": 98, "endOffset": 142}, {"referenceID": 3, "context": "The same algorithm was used for word sense disambiguation (Agirre et al., 2014), also reporting state-of-the-art results.", "startOffset": 58, "endOffset": 79}, {"referenceID": 20, "context": "Hughes and Ramage (2007) were the first presenting a random walk algorithm over the WordNet graph.", "startOffset": 0, "endOffset": 25}, {"referenceID": 1, "context": "Agirre et al. (2010) improved over their results using a similar random walk algorithm on several variations of WordNet relations, reporting the best results to date among WordNet-based algorithms.", "startOffset": 0, "endOffset": 21}, {"referenceID": 1, "context": "Agirre et al. (2010) improved over their results using a similar random walk algorithm on several variations of WordNet relations, reporting the best results to date among WordNet-based algorithms. The same algorithm was used for word sense disambiguation (Agirre et al., 2014), also reporting state-of-the-art results. We use the same open source software in our experiments. As an alternative to random walks, Tsatsaronis et al. (2010) use a path-based system over the WordNet relation graph.", "startOffset": 0, "endOffset": 438}, {"referenceID": 35, "context": "In more recent work (Navigli and Ponzetto, 2012b; Pilehvar et al., 2013), the authors present two", "startOffset": 20, "endOffset": 72}, {"referenceID": 38, "context": "In more recent work (Navigli and Ponzetto, 2012b; Pilehvar et al., 2013), the authors present two", "startOffset": 20, "endOffset": 72}, {"referenceID": 31, "context": "Some authors weight links according to their relevance (Milne and Witten, 2013).", "startOffset": 55, "endOffset": 79}, {"referenceID": 7, "context": "The PageRank random walk algorithm (Brin and Page, 1998) is a method for ranking the vertices in", "startOffset": 35, "endOffset": 56}, {"referenceID": 19, "context": "Personalized PageRank (PPR) is a variation of PageRank (Haveliwala, 2002), where the query of the user defines the importance of each node, biasing", "startOffset": 55, "endOffset": 73}, {"referenceID": 23, "context": "PPR has been successfully used on the WordNet graph for relatedness (Hughes and Ramage, 2007; Agirre et al., 2010) and WSD", "startOffset": 68, "endOffset": 114}, {"referenceID": 2, "context": "PPR has been successfully used on the WordNet graph for relatedness (Hughes and Ramage, 2007; Agirre et al., 2010) and WSD", "startOffset": 68, "endOffset": 114}, {"referenceID": 0, "context": "(Agirre and Soroa, 2009; Agirre et al., 2014).", "startOffset": 0, "endOffset": 45}, {"referenceID": 3, "context": "(Agirre and Soroa, 2009; Agirre et al., 2014).", "startOffset": 0, "endOffset": 45}, {"referenceID": 44, "context": "Name Reference # RG (Rubenstein and Goodenough, 1965) 65 MC (Miller and Charles, 1991) 30 353 (Gabrilovich and Markovitch, 2007) 353 TSA (Radinsky et al.", "startOffset": 20, "endOffset": 53}, {"referenceID": 28, "context": "Name Reference # RG (Rubenstein and Goodenough, 1965) 65 MC (Miller and Charles, 1991) 30 353 (Gabrilovich and Markovitch, 2007) 353 TSA (Radinsky et al.", "startOffset": 60, "endOffset": 86}, {"referenceID": 13, "context": "Name Reference # RG (Rubenstein and Goodenough, 1965) 65 MC (Miller and Charles, 1991) 30 353 (Gabrilovich and Markovitch, 2007) 353 TSA (Radinsky et al.", "startOffset": 94, "endOffset": 128}, {"referenceID": 42, "context": "Name Reference # RG (Rubenstein and Goodenough, 1965) 65 MC (Miller and Charles, 1991) 30 353 (Gabrilovich and Markovitch, 2007) 353 TSA (Radinsky et al., 2011) 287 KORE (Hoffart et al.", "startOffset": 137, "endOffset": 160}, {"referenceID": 21, "context": ", 2011) 287 KORE (Hoffart et al., 2012) 420 TAC09 (McNamee et al.", "startOffset": 17, "endOffset": 39}, {"referenceID": 26, "context": ", 2012) 420 TAC09 (McNamee et al., 2010) 1675 TAC10 http://www.", "startOffset": 18, "endOffset": 40}, {"referenceID": 20, "context": "gov/tac/ 1183 AIDA (Hoffart et al., 2011) 4401 KORE (Hoffart et al.", "startOffset": 19, "endOffset": 41}, {"referenceID": 21, "context": ", 2011) 4401 KORE (Hoffart et al., 2012) 143", "startOffset": 18, "endOffset": 40}, {"referenceID": 2, "context": "Figure 2 summarizes all parameters mentioned so far, as well as their default values, which were set following previous work (Agirre et al., 2010; Agirre et al., 2014).", "startOffset": 125, "endOffset": 167}, {"referenceID": 3, "context": "Figure 2 summarizes all parameters mentioned so far, as well as their default values, which were set following previous work (Agirre et al., 2010; Agirre et al., 2014).", "startOffset": 125, "endOffset": 167}, {"referenceID": 20, "context": "0 in (Hoffart et al., 2011) See (Cornolti et al.", "startOffset": 5, "endOffset": 27}, {"referenceID": 9, "context": ", 2011) See (Cornolti et al., 2013) for a framework to evaluate both mention detection and disambiguation.", "startOffset": 12, "endOffset": 35}, {"referenceID": 36, "context": "for NED (Noreen, 1989), accepting differences with p-value < 0.", "startOffset": 8, "endOffset": 22}, {"referenceID": 3, "context": "Regarding categories, the category structure is mostly a tree, which is a structure where random walks do not seem to be effective, as already observed in (Agirre et al., 2014) for WordNet.", "startOffset": 155, "endOffset": 176}, {"referenceID": 2, "context": "Table 5), in agreement with related work using WordNet (Agirre et al., 2010).", "startOffset": 55, "endOffset": 76}, {"referenceID": 29, "context": "links (Milne and Witten, 2008a; Milne and Witten, 2008b), allowing to compare them to PPR on the same experimental conditions.", "startOffset": 6, "endOffset": 56}, {"referenceID": 30, "context": "links (Milne and Witten, 2008a; Milne and Witten, 2008b), allowing to compare them to PPR on the same experimental conditions.", "startOffset": 6, "endOffset": 56}, {"referenceID": 40, "context": "Source RG 353 TSA MC KORE (Ponzetto and Strube, 2011) Wiki11 c 75.", "startOffset": 26, "endOffset": 53}, {"referenceID": 33, "context": "0* (Nastase and Strube, 2013) Wiki13 ci 67.", "startOffset": 3, "endOffset": 29}, {"referenceID": 31, "context": "0 (Milne and Witten, 2013) Wiki13 la 69.", "startOffset": 2, "endOffset": 26}, {"referenceID": 49, "context": "9r (Yeh et al., 2009) Wiki09 g 48.", "startOffset": 3, "endOffset": 21}, {"referenceID": 2, "context": "2 (Agirre et al., 2010) WNet g 1 86.", "startOffset": 2, "endOffset": 23}, {"referenceID": 46, "context": "2r (Tsatsaronis et al., 2010) WNet g 86.", "startOffset": 3, "endOffset": 29}, {"referenceID": 35, "context": "0 (Navigli and Ponzetto, 2012b) WNet+Wiki12 (cl) g+CL 65.", "startOffset": 2, "endOffset": 31}, {"referenceID": 38, "context": "0 (Pilehvar et al., 2013) WNet+Wiki13 g 86.", "startOffset": 2, "endOffset": 25}, {"referenceID": 13, "context": "2 (Gabrilovich and Markovitch, 2007) Wiki07 t 82.", "startOffset": 2, "endOffset": 36}, {"referenceID": 21, "context": "0 (Hoffart et al., 2012) Wiki12 t 0 69.", "startOffset": 2, "endOffset": 24}, {"referenceID": 48, "context": "8* (Yazdani and Popescu-Belis, 2013) Freebase gt 70.", "startOffset": 3, "endOffset": 36}, {"referenceID": 42, "context": "0* (Radinsky et al., 2011) Time C 1 80.", "startOffset": 3, "endOffset": 26}, {"referenceID": 4, "context": "0 (Baroni et al., 2014) Corpus C 84.", "startOffset": 2, "endOffset": 23}, {"referenceID": 1, "context": "0 (Agirre et al., 2009) WNet+Corpus Cg+SUP 0 96.", "startOffset": 2, "endOffset": 23}, {"referenceID": 31, "context": "0x (Milne and Witten, 2013) Wiki13 la+SUP 83.", "startOffset": 3, "endOffset": 27}, {"referenceID": 31, "context": "Note that the (Milne and Witten, 2013) row was obtained running their publicly available system", "startOffset": 14, "endOffset": 38}, {"referenceID": 15, "context": "4 (Guo et al., 2011) Wiki10 l 1 74.", "startOffset": 2, "endOffset": 20}, {"referenceID": 31, "context": "1 (Milne and Witten, 2013) Wiki13 la 57.", "startOffset": 2, "endOffset": 26}, {"referenceID": 14, "context": "7r (Garc\u0131\u0301a et al., 2014) Wiki12 l 76.", "startOffset": 3, "endOffset": 25}, {"referenceID": 32, "context": "8 (Moro et al., 2014) WNet+Wiki13 g+CL 1 82.", "startOffset": 2, "endOffset": 21}, {"referenceID": 8, "context": "8 (Bunescu and Pasca, 2006) Wiki11 tc 0 83.", "startOffset": 2, "endOffset": 27}, {"referenceID": 11, "context": "4ra (Cucerzan, 2007) Wiki11 tc 0 83.", "startOffset": 4, "endOffset": 20}, {"referenceID": 16, "context": "0ro (Hachey et al., 2011) Wiki11 tcg 79.", "startOffset": 4, "endOffset": 25}, {"referenceID": 21, "context": "8* (Hoffart et al., 2012) Wiki12 t 0 81.", "startOffset": 3, "endOffset": 25}, {"referenceID": 20, "context": "6* (Hoffart et al., 2011) Wiki11 tli+SUP 0 81.", "startOffset": 3, "endOffset": 25}, {"referenceID": 31, "context": "8* (Milne and Witten, 2013) Wiki13 la+SUP 57.", "startOffset": 3, "endOffset": 27}, {"referenceID": 17, "context": "Some early systems have been reimplemented and tested by others: ra for (Hachey et al., 2012), ro (Hoffart et al.", "startOffset": 72, "endOffset": 93}, {"referenceID": 20, "context": ", 2012), ro (Hoffart et al., 2011).", "startOffset": 12, "endOffset": 34}, {"referenceID": 2, "context": "2), including the system in (Agirre et al., 2010), which we run out-of-the-box with default values.", "startOffset": 28, "endOffset": 49}, {"referenceID": 32, "context": "In the counterpart for NED in Table 9, Moro et al. (2014) outperform our system, specially in the smaller KORE (143 instances), but note that they use a richer graph which combines WordNet, the English Wikipedia and hyperlinks from other language Wikipedias.", "startOffset": 39, "endOffset": 58}, {"referenceID": 42, "context": "(Radinsky et al., 2011).", "startOffset": 0, "endOffset": 23}, {"referenceID": 47, "context": "Regarding NED, our system ranks first in the TAC datasets, including the best systems that participated in the TAC competitions (Varma et al., 2009; Lehmann et al., 2010; Cucerzan and Sil, 2013), and second to (Moro et al.", "startOffset": 128, "endOffset": 194}, {"referenceID": 25, "context": "Regarding NED, our system ranks first in the TAC datasets, including the best systems that participated in the TAC competitions (Varma et al., 2009; Lehmann et al., 2010; Cucerzan and Sil, 2013), and second to (Moro et al.", "startOffset": 128, "endOffset": 194}, {"referenceID": 10, "context": "Regarding NED, our system ranks first in the TAC datasets, including the best systems that participated in the TAC competitions (Varma et al., 2009; Lehmann et al., 2010; Cucerzan and Sil, 2013), and second to (Moro et al.", "startOffset": 128, "endOffset": 194}, {"referenceID": 32, "context": ", 2010; Cucerzan and Sil, 2013), and second to (Moro et al., 2014) on AIDA and KORE.", "startOffset": 47, "endOffset": 66}, {"referenceID": 38, "context": "would like to explore tighter integration (Pilehvar et al., 2013).", "startOffset": 42, "endOffset": 65}, {"referenceID": 43, "context": "For NED, local methods (Ratinov et al., 2011; Han and Sun, 2011), global optimization strategies based on keyphrases in context like KORE (Hoffart et al.", "startOffset": 23, "endOffset": 64}, {"referenceID": 18, "context": "For NED, local methods (Ratinov et al., 2011; Han and Sun, 2011), global optimization strategies based on keyphrases in context like KORE (Hoffart et al.", "startOffset": 23, "endOffset": 64}, {"referenceID": 21, "context": ", 2011; Han and Sun, 2011), global optimization strategies based on keyphrases in context like KORE (Hoffart et al., 2012) and doing NED jointly with word sense disambiguation (Moro et al.", "startOffset": 100, "endOffset": 122}, {"referenceID": 32, "context": ", 2012) and doing NED jointly with word sense disambiguation (Moro et al., 2014), all", "startOffset": 61, "endOffset": 80}], "year": 2015, "abstractText": "Hyperlinks and other relations in Wikipedia are a extraordinary resource which is still not fully understood. In this paper we study the different types of links in Wikipedia, and contrast the use of the full graph with respect to just direct links. We apply a well-known random walk algorithm on two tasks, word relatedness and named-entity disambiguation. We show that using the full graph is more effective than just direct links by a large margin, that non-reciprocal links harm performance, and that there is no benefit from categories and infoboxes, with coherent results on both tasks. We set new state-of-the-art figures for systems based on Wikipedia links, comparable to systems exploiting several information sources and/or supervised machine learning. Our approach is open source, with instruction to reproduce results, and amenable to be integrated with complementary text-based methods.", "creator": "TeX"}}}