{"id": "1503.02578", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Mar-2015", "title": "Modeling State-Conditional Observation Distribution using Weighted Stereo Samples for Factorial Speech Processing Models", "abstract": "This paper investigates the role of factorial speech processing models in noise-robust automatic speech recognition tasks. Factorial models can embed non-stationary noise models using Markov chains as one of its source chain. The paper proposes a modeling scheme for modeling state-conditional observation distribution of factorial models based on weighted stereo samples. This scheme is an extension to previous single pass retraining for ideal model compensation and here we used it to construct ideal state-conditional observation distributions. Experiments of this paper over the set A of the Aurora 2 dataset shows that by considering noise models with multiple states, system performance can be improved especially in low SNR conditions up to 4% absolute word recognition performance. In addition to its power in accurate representation of state-conditional observation distribution, it has an important advantage over previous methods by providing the opportunity to independently select feature spaces for both source and corrupted features. This opens a new window for seeking better feature spaces appropriate for noise-robust tasks independent from clean speech feature space.", "histories": [["v1", "Mon, 9 Mar 2015 17:40:08 GMT  (731kb)", "http://arxiv.org/abs/1503.02578v1", null], ["v2", "Wed, 5 Oct 2016 12:05:10 GMT  (882kb)", "http://arxiv.org/abs/1503.02578v2", "Updated version of the first submission. Several clarifications are added to previous version. One experiment is added to the experiments, Circuits Syst Signal Process, Apr. 2016"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.SD", "authors": ["mahdi khademian", "mohammad mehdi homayounpour"], "accepted": false, "id": "1503.02578"}, "pdf": {"name": "1503.02578.pdf", "metadata": {"source": "CRF", "title": "Modeling State-Conditional Observation Distribution using Weighted Stereo Samples for Factorial Speech Processing Models", "authors": ["Mahdi Khademian", "Mohammad Mehdi Homayounpour"], "emails": [], "sections": [{"heading": null, "text": "This paper investigates the role of factorial speech processing models in noise-robust automatic speech recognition tasks. Factorial models can embed non-stationary noise models using Markov chains as one of its source chain. The paper proposes a modeling scheme for modeling state-conditional observation distribution of factorial models based on weighted stereo samples. This scheme is an extension to previous single pass retraining for ideal model compensation and here we used it to construct ideal state-conditional observation distributions. Experiments of this paper over the set A of the Aurora 2 dataset shows that by considering noise models with multiple states, system performance can be improved especially in low SNR conditions up to 4% absolute word recognition performance. In addition to its power in accurate representation of state-conditional observation distribution, it has an important advantage over previous methods by providing the opportunity to independently select feature spaces for both source and corrupted features. This opens a new window for seeking better feature spaces appropriate for noise-robust tasks independent from clean speech feature space.\nKeywords: factorial speech processing models, state-conditional observation distribution, stereo samples"}, {"heading": "1. Introduction", "text": "Despite long term efforts and great successes in automatic speech recognition (ASR) systems, rapid degradation of performance in the presence of noise and other competing sources remains the Achilles Heel of these systems [1]. While some feature enhancement and model adaptation techniques loosely use noise source characteristics to increase performance of speech recognition systems, model based methods try to use as much as information they can acquire from noise sources [2]. Such information ranges from static distortion occurred in the extracted features of noisy signals to dynamic information of cyclo-stationary noises.\nFactorial speech processing models [3]\u2013[5] are extension of Hidden Markov Models (HMM) which model audio sources and the way that these sources are combined in a generative manner. They model each of audio sources separately; this can include modeling dynamic changes of audio sources by hidden Markov models. Additionally factorial models, model how these audio sources are combined to produce output or distorted features. Because of this, factorial models can use noise characteristics for improving system performance.\nFrom modeling point of view, factorial models are powerful modeling tools for speech processing applications. They can be used for speech enhancement, noise-robust speech recognition, multi-talker speech recognition, and robust speaker identification. These models perform well in the specific application of multi-talker speech recognition where the sound sources have significant dynamic information and there are two or more competing speakers speaking simultaneously. Recent researches achieve higher performance even than human in the multi-talker speech recognition challenge by use of factorial models of speech processing in some specific conditions [6], [7]. Despite their successes in the mentioned challenge and their modeling power, factorial models are not widely used for real noise-robust speech processing applications [8]; their computational demand for inference and difficulties in representing their central conditional probability distribution (CPD) are the two main reasons for this lack of use [2].\nFigure 1 shows a generic HMM for conventional acoustic modeling in speech recognition and a factorial model for noise robust speech recognition expressed in the Probabilistic Graphical Models (PGM) language. HMM is extended in the two ways for creating factorial model of speech processing. The first one is that factorial models have multiple state chains which are useful for modeling systems with multiple underlying independent processes [9], i.e. two audio sources with their corresponding temporal models (in Figure 1.b \ud835\udc60\ud835\udc61 \ud835\udc5b and \ud835\udc60\ud835\udc61 \ud835\udc65 are noise and speech source state variables). The second one is the interaction model, [2]; CPD of the observed signal features conditioned on features of its corresponding sources, \ud835\udc5d(\ud835\udc9a\ud835\udc61|\ud835\udc99\ud835\udc61 , \ud835\udc8f\ud835\udc61) in Figure 1.b. This CPD in its deterministic form is called mismatch function [10], [11].\nEach of the two extensions imposes its own complexity to the basic HMM during learning and inference. On the one hand, multiple state sequence increases computational complexity of inference (which is also required for learning) to \ud835\udc42(\ud835\udc47\ud835\udc46\ud835\udc3e) in which \ud835\udc47 is inference window or lag, \ud835\udc3e is number of underlying chain, and \ud835\udc46 is maximum number of states in the chains [12], [13]. In comparison with standard HMM with \ud835\udc42(\ud835\udc47\ud835\udc462) as its required calculations for inference, we see exponential growth of calculations by increasing the number of audio sources.\nOn the other hand, accurate modeling of probabilistic relationship between the observed features and their sources is not always possible in speech recognition applications [2]. Several approximations are used for developing mismatch functions so far. Ignoring phase difference between spectral features of audio sources or use of pseudo inverse of DCT matrix for transforming features from Cepstral domain back to log-spectral domain are two examples of these approximations. Moreover, the interaction model is not directly used in the inference. Inference on factorial models requires State-Conditional Observation Distribution (SCOD); i.e. observed feature distribution conditioned on states of the source chains, \ud835\udc5d(\ud835\udc9a\ud835\udc61|\ud835\udc60 \ud835\udc65, \ud835\udc60\ud835\udc5b). This distribution is directly calculated by marginalizing-out source features variables (\ud835\udc99, \ud835\udc8f); i.e. \u222c \ud835\udc5d(\ud835\udc9a, \ud835\udc99, \ud835\udc8f|\ud835\udc60\ud835\udc65, \ud835\udc60\ud835\udc5b)\ud835\udc51\ud835\udc99\ud835\udc51\ud835\udc8f. The direct calculation of SCOD causes more challenges in the use of factorial models which necessitates additional approximations. As a result, having more accurate interaction models leads to more approximations in calculation of SCOD and doing exact SCOD calculations forced us to use approximate interaction models.\nThis paper focuses on the second challenge of factorial models by incorporating the idea of single-pass retraining [10], [14] for ideal SCOD modeling to be used in factorial speech processing models. We want to evaluate whether these models are effective against non-stationary noises as good as they are in multi-talker tasks. In addition it presents a modified expectation maximization (EM) algorithm for parametric modeling of this ideal SCOD. Next section briefly reviews previous methods for modeling the SCOD by starting with description of the commonly used environment model and the most useful mismatch function inference especially in speech recognition. Then it shows how the previous VTS based and IDPMC techniques can be used for the SCOD modeling. Finally it presents the way we perform inference in factorial models based on the SCOD models and an extended Viterbi algorithm. The proposed method of SCOD modeling is proposed in section 3; this section first describes the way that combined features are sampled and become weighted and then the extension of the EM algorithm for parametric modeling of SCODs is described. Section 4 describes experiments by providing the block diagram of the proposed method for SCOD modeling and then presents the results; we used the Aurora 2 dataset for this evaluation. Finally section 5 concludes the paper."}, {"heading": "2. Background", "text": "In the model based noise-robust ASR methods, the following relation is considered between speech and noise\nsignals in an assumed environment for generation of distorted speech signals [3], [15]:\n\ud835\udc66 = \ud835\udc65 \u2217 \u210e + \ud835\udc5b (1)\nwhere \ud835\udc65 and \ud835\udc5b are speech and noise signals and \u210e is the channel model of the speech capturing environment. In the power spectrum domain by short-term discrete Fourier transform we have:\n|\ud835\udc9a\ud835\udc61| 2 = |\ud835\udc99\ud835\udc61\ud835\udc89| 2 + |\ud835\udc8f\ud835\udc61| 2 + 2|\ud835\udc99\ud835\udc61\ud835\udc89||\ud835\udc8f\ud835\udc61| cos(\ud835\udf53\ud835\udc61) (2)\nin which \ud835\udf53\ud835\udc61 is vector of phase difference between frequency bins of \ud835\udc99\ud835\udc61\ud835\udc89 and \ud835\udc8f\ud835\udc61 complex vectors. In (2), frequency index is omitted since variables are written in vector form. Additionally, time index will be removed in subsequent expressions for brevity. While (2) provides a mismatch function useful for speech enhancement applications, power\nspectrum is not appropriate for speech recognition. By applying filterbank, taking logarithm and use of truncated DCT\nmatrix, the following interaction model is derived for MFCC features [11]:\n\ud835\udc5d(\ud835\udc9a\ud835\udc50|\ud835\udc99\ud835\udc50, \ud835\udc89\ud835\udc50 , \ud835\udc8f\ud835\udc50) = \ud835\udeff (\ud835\udc9a\ud835\udc50 \u2212 \ud835\udc02 \ud835\udc25\ud835\udc28\ud835\udc20 (\ud835\udc1e\ud835\udc31\ud835\udc29(\ud835\udc02\u2212\ud835\udfcf(\ud835\udc99\ud835\udc50 + \ud835\udc89\ud835\udc50)) + \ud835\udc1e\ud835\udc31\ud835\udc29(\ud835\udc02\u2212\ud835\udfcf\ud835\udc8f\ud835\udc50) + \ud835\udf50(\ud835\udc99\ud835\udc50 , \ud835\udc89\ud835\udc50 , \ud835\udc8f\ud835\udc50))) (3)\nwhere its residual equals to:\n\ud835\udf50(\ud835\udc99, \ud835\udc89, \ud835\udc8f) = 2\ud835\udf36 \ud835\udc1e\ud835\udc31\ud835\udc29(\ud835\udc02\u2212\ud835\udfcf(\ud835\udc99 + \ud835\udc89 + \ud835\udc8f)/2) (4)\nThis residual reflects the effects of the phase difference of (2) and by considering uniform distribution for phase difference, \ud835\udf36 in this residual becomes stochastic; its properties is investigated in [16]. Interaction models useful for speech recognition applications contain this residual. The interaction model is usually approximated by removing the residual [8] or considering its \ud835\udf36 as constant; same value for all frequency bins [17]. Based on these interaction models (or mismatch functions) most of model compensation techniques were developed before."}, {"heading": "2.1. State-conditional observation distribution", "text": "The interaction model (or mismatch function) is not directly used in inference of factorial models. Instead by\nmarginalizing source features as follows, the SCOD is used during the inference:\n\ud835\udc5d(\ud835\udc9a|\ud835\udc60\ud835\udc65 , \ud835\udc60\ud835\udc5b) = \u222c \ud835\udc5d(\ud835\udc9a, \ud835\udc99, \ud835\udc8f|\ud835\udc60\ud835\udc65, \ud835\udc60\ud835\udc5b)\ud835\udc51\ud835\udc99\ud835\udc51\ud835\udc8f = \u222c \ud835\udc5d(\ud835\udc9a|\ud835\udc99, \ud835\udc8f)\ud835\udc5d(\ud835\udc99|\ud835\udc60\ud835\udc65)\ud835\udc5d(\ud835\udc8f|\ud835\udc60\ud835\udc5b)\ud835\udc51\ud835\udc99\ud835\udc51\ud835\udc8f (5)\nDirect calculation of (5) was performed for simple feature domains and by approximations in the mismatch function.\nTwo examples are max and soft-max approximation for log-power-spectral features [2], [18]. But this domain is not\nappropriate for speech recognition applications. Therefore, instead of direct calculation, the SCOD model is extracted by transforming the source models or use of Monte Carlo methods.\nThree categories of approaches are used for SCOD modeling. Approaches in the first set, by making an assumption\nthat the SCOD is Gaussian in specific feature domains, estimate approximate Gaussian parameters. Parallel model combination (PMC) is an example of this group [19]. Methods in the second set, approximate the non-linear mismatch\nfunctions by its linearization around an expansion point with Taylor series. Then transform source model parameters by applying this approximation. Several variations of these methods were developed, depending on linearization point,\nsupport of dynamic coefficients order of approximation, and compensation of channel effect. A successful and\ncomplete VTS based compensation is presented in [17]. The third set, uses conditional samples of observation distribution for estimating parameters of the SCOD model which is usually modeled by Gaussian Mixture Models\n(GMM). Samples are generated by forward sampling and consequent use of mismatch function. Developed methods in this set are known as variations of data-driven PMC [10]. Next sub-sections describe VTS and DPMC based SCOD\nmodeling adopted for factorial speech processing models. Most of the previous works consider stationary noises and\ntherefore consider only one noise state in their SCOD models. Actually in this case, clean source models are replaced with their corresponding SCODs, which means plugging new observation models into the original HMMs. This is the\nreason for naming this kind of robust speech recognition, \u201cmodel compensation\u201d [11]."}, {"heading": "2.1.1. VTS based SCOD models", "text": "In the VTS based methods, mismatch function is approximated by the first order Taylor series expanded around\n(\ud835\udc990, \ud835\udc890, \ud835\udc8f0). For example for mismatch function of (3) in the form of \ud835\udc9a = \ud835\udc87(\ud835\udc99, \ud835\udc89, \ud835\udc8f), we have:\n\ud835\udc9a \u2248 \ud835\udc87(\ud835\udc990, \ud835\udc890, \ud835\udc8f0) + \ud835\udf4f\ud835\udc87\n\ud835\udf4f\ud835\udc99 (\ud835\udc99 \u2212 \ud835\udc990) +\n\ud835\udf4f\ud835\udc87 \ud835\udf4f\ud835\udc89 (\ud835\udc89 \u2212 \ud835\udc890) + \ud835\udf4f\ud835\udc87 \ud835\udf4f\ud835\udc8f (\ud835\udc8f \u2212 \ud835\udc8f0) (6)\nBy considering the above approximation as transformation of source models, and assuming that the source\ndistribution remains Gaussian after corruption, we can transform source model parameters to obtain SCOD parameters. With selection of conditional source distribution means as the expansion point, we have:\n\ud835\udc5d(\ud835\udc9a|\ud835\udc60\ud835\udc65 = \ud835\udc56, \ud835\udc60\ud835\udc5b = \ud835\udc57)~\ud835\udca9(\ud835\udc9a; \ud835\udf41\ud835\udc56 + \ud835\udf41\u210e + \ud835\udc88(\ud835\udf41\ud835\udc56, \ud835\udf41\u210e , \ud835\udf41\ud835\udc5b), \ud835\udc06\ud835\udeba\ud835\udc56\ud835\udc06 \ud835\udc47 + \ud835\udc05\ud835\udeba\ud835\udc57\ud835\udc05 \ud835\udc47) (7)\nwhere \ud835\udc88(\ud835\udc99, \ud835\udc89, \ud835\udc8f) = \ud835\udc02 \ud835\udc25\ud835\udc28\ud835\udc20 (\ud835\udc1e\ud835\udc31\ud835\udc29(\ud835\udc02\u2212\ud835\udfcf(\ud835\udc99 + \ud835\udc89)) + \ud835\udc1e\ud835\udc31\ud835\udc29(\ud835\udc02\u2212\ud835\udfcf\ud835\udc8f) + \ud835\udf50(\ud835\udc99, \ud835\udc89, \ud835\udc8f)), \ud835\udc06 = \ud835\udf4f\ud835\udc87\n\ud835\udf4f\ud835\udc99 , and \ud835\udc05 =\n\ud835\udf4f\ud835\udc87 \ud835\udf4f\ud835\udc8f . For source models\nwith GMM observation distribution, the SCOD can be conditioned on each source component distribution.\nAdditionally for delta and delta-delta coefficient SCOD parameters are extracted as follows:\n\ud835\udc5d(\ud835\udc9a\u0394|\ud835\udc60 \ud835\udc65 = \ud835\udc56, \ud835\udc60\ud835\udc5b = \ud835\udc57)~\ud835\udca9(\ud835\udc9a\u0394; \ud835\udc06\ud835\udf41\u0394\ud835\udc56 + \ud835\udc05\ud835\udf41\u0394\ud835\udc57 , \ud835\udc06\ud835\udeba\u0394\ud835\udc56\ud835\udc06 \ud835\udc47 + \ud835\udc05\ud835\udeba\u0394\ud835\udc57\ud835\udc05 \ud835\udc47) (8)\n\ud835\udc5d(\ud835\udc9a\u0394\u0394|\ud835\udc60 \ud835\udc65 = \ud835\udc56, \ud835\udc60\ud835\udc5b = \ud835\udc57)~\ud835\udca9(\ud835\udc9a\u0394\u0394; \ud835\udc06\ud835\udf41\u0394\u0394\ud835\udc56 + \ud835\udc05\ud835\udf41\u0394\u0394\ud835\udc57 , \ud835\udc06\ud835\udeba\u0394\u0394\ud835\udc56\ud835\udc06 \ud835\udc47 + \ud835\udc05\ud835\udeba\u0394\u0394\ud835\udc57\ud835\udc05 \ud835\udc47) (9)\nDetail derivation of these expressions for single state noise models can be found in [11], [17]; extending them for\nmultiple noise sates is straightforward."}, {"heading": "2.1.2. DPMC based SCOD models", "text": "In data-driven PMC methods, by use of forward sampling, state-conditional observed feature samples are used for SCOD modeling. First, source states are fixed; i.e. \u2329\ud835\udc60\ud835\udc65 = \ud835\udc56, \ud835\udc60\ud835\udc5b = \ud835\udc57\u232a. Then based on fixed states and use of source models, conditional source features are generated. Now by use of appropriate mismatch function, observed features are extracted from source features (\ud835\udc9a\ud835\udc59|\ud835\udc56,\ud835\udc57 = \ud835\udc87(\ud835\udc99\ud835\udc59|\ud835\udc56,\ud835\udc57 , \ud835\udc8f\ud835\udc59|\ud835\udc56,\ud835\udc57)). These samples can represent empirical SCOD as follows:\n\ud835\udc5d(\ud835\udc9a|\ud835\udc60\ud835\udc65 = \ud835\udc56, \ud835\udc60\ud835\udc5b = \ud835\udc57) = 1\n\ud835\udc3f \u2211 \ud835\udeff(\ud835\udc9a\ud835\udc59|\ud835\udc56,\ud835\udc57 \u2212 \ud835\udc9a)\n\ud835\udc3f \ud835\udc59=1 (10)\nwhere \ud835\udc3f is the number of samples and \ud835\udeff is Dirac delta function. At this step, parametric model of SCOD can be trained by use of state-conditional samples. This model may consist of single Gaussian or multiple Gaussians where the\nmethod is named DPMC or IDPMC respectively [10], [11]."}, {"heading": "2.2. Inference", "text": "In factorial models with multiple hidden Markov chains such as models that are used in multi-talker speech recognition and robust speech recognition tasks, the objective of inference is to find the most probable source states given the observation feature vectors:\n\ud835\udc601:\ud835\udc47 \u2217\ud835\udc65,\ud835\udc5b = argmax\n\ud835\udc601:\ud835\udc47 \ud835\udc65,\ud835\udc5b\n\ud835\udc5d(\ud835\udc601:\ud835\udc47 \ud835\udc65,\ud835\udc5b|\ud835\udc9a1:\ud835\udc47) (11)\nSince in robust speech recognition tasks, noise states are not important, so they are discarded. Finding the most probable states conditioned on observation vectors is done by two-dimensional Viterbi search. Na\u00efve implementation requires likelihood evaluation of (\ud835\udc46\ud835\udc65\ud835\udc46\ud835\udc5b)\ud835\udc47 different paths among source states. By creating a mega-state HMM from FHMM, the number of operations reduces to \ud835\udc42(\ud835\udc47(\ud835\udc46\ud835\udc65\ud835\udc46\ud835\udc5b)2). In mega-state HMM a new state variable is defined equals to Cartesian product of source states. Thus, similar to HMM, decoding requires \ud835\udc42(\ud835\udc47\ud835\udc462) operations, where \ud835\udc46 = \ud835\udc46\ud835\udc65\ud835\udc46\ud835\udc5b. But by using two-dimensional Viterbi search, this reduces to \ud835\udc42(\ud835\udc47\ud835\udc462\ud835\udc65\ud835\udc46\ud835\udc5b). The following recursions are used in two-dimensional Viterbi search to find the most probable speech states:\n\ud835\udf0f\ud835\udc61(\ud835\udc60\ud835\udc61 \ud835\udc65 , \ud835\udc60\ud835\udc61+1 \ud835\udc5b ) = max \ud835\udc60\ud835\udc61 \ud835\udc5b \ud835\udc43(\ud835\udc60\ud835\udc61+1 \ud835\udc5b |\ud835\udc60\ud835\udc61 \ud835\udc5b)\ud835\udc5d(\ud835\udc9a\ud835\udc61|\ud835\udc60\ud835\udc61 \ud835\udc65 , \ud835\udc60\ud835\udc61 \ud835\udc5b)\ud835\udf0f\ud835\udc61\u22121(\ud835\udc60\ud835\udc61 \ud835\udc65 , \ud835\udc60\ud835\udc61 \ud835\udc5b) (12)\n\ud835\udf0f\ud835\udc61(\ud835\udc60\ud835\udc61+1 \ud835\udc65 , \ud835\udc60\ud835\udc61+1 \ud835\udc5b ) = max \ud835\udc60\ud835\udc61 \ud835\udc65 \ud835\udc43(\ud835\udc60\ud835\udc61+1 \ud835\udc65 |\ud835\udc60\ud835\udc61 \ud835\udc65) \ud835\udf0f\ud835\udc61(\ud835\udc60\ud835\udc61 \ud835\udc65 , \ud835\udc60\ud835\udc61+1 \ud835\udc5b ) (13)\nin which \ud835\udc43(\ud835\udc60\ud835\udc61+1 \ud835\udc5b |\ud835\udc60\ud835\udc61 \ud835\udc5b) and \ud835\udc43(\ud835\udc60\ud835\udc61+1 \ud835\udc65 |\ud835\udc60\ud835\udc61 \ud835\udc65) are transition probabilities in source Markov chains and \ud835\udc5d(\ud835\udc9a\ud835\udc61|\ud835\udc60\ud835\udc61 \ud835\udc65 , \ud835\udc60\ud835\udc61 \ud835\udc5b) is stateconditional observation distribution. It is noteworthy that the role of SCOD in inference here is similar to the observation model in HMMs; like \ud835\udc4f\ud835\udc56(\ud835\udc5c\ud835\udc61) according to notations of [20]. Recursions start with:\n\ud835\udf0f0(\ud835\udc601 \ud835\udc65, \ud835\udc601 \ud835\udc5b) = \ud835\udc43(\ud835\udc601 \ud835\udc65)\ud835\udc43(\ud835\udc601 \ud835\udc5b) (14)\nSimilar to conventional Viterbi algorithm, in each step, a back-pointer is used to determine target state sequence:\n\ud835\udf19\ud835\udc61(\ud835\udc60\ud835\udc61 \ud835\udc65 , \ud835\udc60\ud835\udc61+1 \ud835\udc5b ) = argmax \ud835\udc60\ud835\udc61 \ud835\udc5b \ud835\udc43(\ud835\udc60\ud835\udc61+1 \ud835\udc5b |\ud835\udc60\ud835\udc61 \ud835\udc5b)\ud835\udc5d(\ud835\udc9a\ud835\udc61|\ud835\udc60\ud835\udc61 \ud835\udc65 , \ud835\udc60\ud835\udc61 \ud835\udc5b)\ud835\udf0f\ud835\udc61\u22121(\ud835\udc60\ud835\udc61 \ud835\udc65 , \ud835\udc60\ud835\udc61 \ud835\udc5b) (15)\n\ud835\udf19\ud835\udc61(\ud835\udc60\ud835\udc61+1 \ud835\udc65 , \ud835\udc60\ud835\udc61+1 \ud835\udc5b ) = argmax \ud835\udc60\ud835\udc61 \ud835\udc65 \ud835\udc43(\ud835\udc60\ud835\udc61+1 \ud835\udc65 |\ud835\udc60\ud835\udc61 \ud835\udc65) \ud835\udf0f\ud835\udc61(\ud835\udc60\ud835\udc61 \ud835\udc65, \ud835\udc60\ud835\udc61+1 \ud835\udc5b ) (16)\nFor more details on the two chain models or general cases of using the algorithm, the reader is referred to [6] or [9, Ch. 8], [12] respectively. In fact, here, dynamic programming is run also within time-slices in addition to standard Viterbi algorithm which only runs between time-slices. This is the reason for the reduction of calculations by a factor of \ud835\udc46\ud835\udc5b."}, {"heading": "3. The proposed method", "text": "The proposed method solves the problem of modeling state-conditional observation distribution in a way different from previous methods which are based on interaction model or mismatch functions. It models State-Conditional\nObservation Distribution using samples where the samples are not generated by forward sampling and use of mismatch function as in the data-driven PMC methods. Sampling of corrupted feature distribution, is started from source signals\nin time domain. At the first step, segments of source signals are combined together by the freely assumed environment model (such as (1)) to make the corrupted speech in time domain, \ud835\udc66[\ud835\udc61]. Then, the corresponding features are extracted from these time domain signals; i.e. \ud835\udc99\ud835\udc59, \ud835\udc8f\ud835\udc59 and \ud835\udc9a\ud835\udc59 are \ud835\udc59th sources and corrupted features. These feature vectors are known as stereo features [8], [21]. We also called them \u201cstereo\u201d due to one to one mapping between these features but here three sets of features are related together.\nSource features are then examined in their corresponding source models to compute their state-conditional likelihoods, (\ud835\udc5d(\ud835\udc99\ud835\udc59|\ud835\udc56) and \ud835\udc5d(\ud835\udc8f\ud835\udc59|\ud835\udc57)). Finally, the time domain segments and source feature vectors are discarded. Samples of \ud835\udc9a and their source state-conditional likelihoods will be used for modeling later."}, {"heading": "3.1. Empirical distribution", "text": "Since we have no restriction of source states, samples of \ud835\udc9a are extracted from non-conditional observation distribution rather than SCOD. Therefore these samples cannot be used directly for SCOD modeling. We use importance sampling scheme [22] to correct bias occurred by non-conditional samples for modeling the SCOD using\nparticle weights which indicates association of particle weights to states. Particle weights are calculated in each source spaces as follows:\n\ud835\udc64\ud835\udc59|\ud835\udc56 = \ud835\udc5d(\ud835\udc99\ud835\udc59|\ud835\udc56) \ud835\udc5d(\ud835\udc99\ud835\udc59)\u2044 = \ud835\udc5d(\ud835\udc99\ud835\udc59|\ud835\udc56) \u2211 \ud835\udc5d(\ud835\udc99\ud835\udc59|\ud835\udc56)\ud835\udc5d(\ud835\udc56)\ud835\udc56\u2044 (17)\n\ud835\udc64\ud835\udc59|\ud835\udc57 = \ud835\udc5d(\ud835\udc8f\ud835\udc59|\ud835\udc57) \ud835\udc5d(\ud835\udc8f\ud835\udc59)\u2044 = \ud835\udc5d(\ud835\udc8f\ud835\udc59|\ud835\udc57) \u2211 \ud835\udc5d(\ud835\udc8f\ud835\udc59|\ud835\udc57)\ud835\udc5d(\ud835\udc57)\ud835\udc57\u2044 (18)\nBy assuming source features independence (which is true for many additive noise environments), we have:\n\ud835\udc64\ud835\udc59|\ud835\udc57 = \ud835\udc64\ud835\udc59|\ud835\udc56\ud835\udc64\ud835\udc59|\ud835\udc57 (19)\nNow the combined conditional speech distribution can be modeled empirically by the weighted particles as follows:\n\ud835\udc5d(\ud835\udc9a|\ud835\udc56, \ud835\udc57) = \u2211 \ud835\udc64\ud835\udc59|\ud835\udc56,\ud835\udc57\ud835\udeff(\ud835\udc9a\ud835\udc59 \u2212 \ud835\udc9a) \ud835\udc3f \ud835\udc59=1 (20)\nwhere \ud835\udc9a\ud835\udc59 is the particle sampled from \ud835\udc5d(\ud835\udc9a) and \ud835\udc64\ud835\udc59|\ud835\udc56,\ud835\udc57 is its adjusting weight for \ud835\udc5d(\ud835\udc9a|\ud835\udc56, \ud835\udc57).\nBy iterating \ud835\udc56 and \ud835\udc57 through their corresponding random variable support set and calculating their \ud835\udc64\ud835\udc59|\ud835\udc56,\ud835\udc57, the\nSCOD is extracted for all source states."}, {"heading": "3.2. Parametric distribution", "text": "The empirical distribution cannot be used directly in the recognition application and we need parametric model of\nthe SCOD. Parameter estimation of single Gaussian models can be done by maximum weighted likelihood estimators [23] as:\nargmax \ud835\udf03\n\u220f \ud835\udc5d\ud835\udc64\ud835\udc59|\ud835\udc56,\ud835\udc57(\ud835\udc9a\ud835\udc59; \ud835\udf03) \ud835\udc3f \ud835\udc59=1 (21)\nTherefore Gaussian parameters are estimated by weighted samples as follows:\n\ud835\u0302\udf41\ud835\udc56,\ud835\udc57 = (\u2211 \ud835\udc64\ud835\udc59|\ud835\udc56,\ud835\udc57\ud835\udc9a\ud835\udc59 \ud835\udc3f \ud835\udc59=1 ) \ud835\udc64\ud835\udc56,\ud835\udc57\u2044 (22)\n\ud835\u0302\udf2e\ud835\udc56,\ud835\udc57 = (\u2211 \ud835\udc64\ud835\udc59|\ud835\udc56,\ud835\udc57(\ud835\udc9a\ud835\udc59 \u2212 \ud835\u0302\udf41\ud835\udc56,\ud835\udc57)(\ud835\udc9a\ud835\udc59 \u2212 \ud835\u0302\udf41\ud835\udc56,\ud835\udc57) \ud835\udc47\ud835\udc3f \ud835\udc59=1 ) \ud835\udc64\ud835\udc56,\ud835\udc57\u2044 (23)\nin which \ud835\udc64\ud835\udc56,\ud835\udc57 = \u2211 \ud835\udc64\ud835\udc59|\ud835\udc56,\ud835\udc57 \ud835\udc3f \ud835\udc59=1 . Depending on feature spaces, single-component Gaussian may not be an appropriate candidate for SCOD modeling. In these cases, GMM is used as a more flexible modeling tool. While the EM algorithm is used for training GMMs, the standard algorithm does not support weighted samples. Because of this, the standard EM algorithm is extended to support weighted samples.\nConsider the following \ud835\udc44-function as the expected value of weighted complete-data log likelihood in which the expectation is taken over the latent variable posterior for supporting weighted samples (state indices are omitted for brevity of notation):\n\ud835\udcac(\ud835\udf03, \ud835\udf03\u2032) = \ud835\udd3c\ud835\udc67|\ud835\udc9a;\ud835\udf03\u2032[ln \u2112(\ud835\udc9a1:\ud835\udc3f , \ud835\udc641:\ud835\udc3f , \ud835\udc671:\ud835\udc3f; \ud835\udf03)] = \u2211 \ud835\udc64\ud835\udc59\ud835\udd3c[ln \ud835\udc5d(\ud835\udc9a\ud835\udc59 , \ud835\udc67\ud835\udc59; \ud835\udf03)] \ud835\udc3f \ud835\udc59=1 (24)\nFor mixture of Gaussians with \ud835\udf03 = (\ud835\udf411:\ud835\udc3e , \ud835\udeba1:\ud835\udc3e , \ud835\udf45) in which \ud835\udf0b\ud835\udc58 is the component\u2019s prior, the \ud835\udc44-function becomes:\n\u2211 \ud835\udc64\ud835\udc59 \u2211 \ud835\udefe\ud835\udc59(\ud835\udc58)[ln \ud835\udc5d(\ud835\udc9a\ud835\udc59; \ud835\udf41\ud835\udc58 , \ud835\udeba\ud835\udc58) + ln \ud835\udf0b\ud835\udc58] \ud835\udc3e \ud835\udc58=1 \ud835\udc3f \ud835\udc59=1 (25)\nin which \ud835\udc58 is index of Gaussian component in the mixture and \ud835\udefe\ud835\udc59(\ud835\udc58) is defined as the \ud835\udc58th component responsibility to the \ud835\udc59th sample based on old parameters (\ud835\udf03\u2032) as follows:\n\ud835\udefe\ud835\udc59(\ud835\udc58) \u225d \ud835\udc43(\ud835\udc67 = \ud835\udc58|\ud835\udc9a\ud835\udc59; \ud835\udf03 \u2032) (26)\nin fact, this posterior is outcome of E-step of the EM algorithm (calculation of component responsibilities is provided in the appendix A). Equation (24) is weighted version of the standard EM \ud835\udc44-function for supporting weighted samples. This \ud835\udc44-function must be optimized with respect to \ud835\udf03, new parameter set, during the M-step of the EM algorithm. Optimizing the \ud835\udc44-function with respect to new parameters leads to the following parameter update equations (detailed derivation is provided in the paper appendix A):\n\ud835\udf41\ud835\udc58 = (\u2211 \ud835\udc64\ud835\udc59\ud835\udefe\ud835\udc59(\ud835\udc58)\ud835\udc9a\ud835\udc59 \ud835\udc3f \ud835\udc59=1 ) \ud835\udc4a\ud835\udc58\u2044 (27)\n\ud835\udeba\ud835\udc58 = (\u2211 \ud835\udc64\ud835\udc59\ud835\udefe\ud835\udc59(\ud835\udc58)(\ud835\udc9a\ud835\udc59 \u2212 \ud835\udf41\ud835\udc58)(\ud835\udc9a\ud835\udc59 \u2212 \ud835\udf41\ud835\udc58) \ud835\udc47\ud835\udc3f \ud835\udc59=1 ) \ud835\udc4a\ud835\udc58\u2044 (28)\n\ud835\udf0b\ud835\udc58 = \ud835\udc4a\ud835\udc58 \ud835\udc4a\u2044 (29)\nin which \ud835\udc4a\ud835\udc58 = \u2211 \ud835\udc64\ud835\udc59\ud835\udefe\ud835\udc59(\ud835\udc58) \ud835\udc3f \ud835\udc59=1 and \ud835\udc4a = \u2211 \ud835\udc64\ud835\udc59 \ud835\udc3f \ud835\udc59=1 . By applying the extended EM algorithm, weighted \u201cstereo\u201d samples are used to model the SCOD for all source states."}, {"heading": "4. Experiments", "text": "The Aurora 2 task [24] for recognizing utterances of digit series corrupted by additive and convolutive noises is selected for evaluating the effectiveness of the proposed method for handling noise models with multiple noise states\nin SCOD modeling in factorial models. This task has three test sets A, B and C and our method is evaluated using set A. Set A is designed to test robustness of recognition methods against additive noises considering this point that\nthe noise information could be used during the training phase and in our experiment we assume that we have noise\ndistribution and signals before test. In this test set, four noises are artificially added to 8440 clean utterances. Corrupted utterances are used during the training phase for multi-condition training scenarios and in this set, the same noises are\nused for creation of corrupted test utterances. The four noises are Subway, Babble, Car and Exhibition which are artificially added to clean utterances in different SNRs varying from 20 dB to -5 dB in 5 dB steps\nBefore describing the details of the conducted experiments, the whole procedure of the proposed method for noise-\nrobust ASR applications is described first. Figure 2 shows the block diagram of SCOD modeling using weighted \u201cstereo\u201d samples and decoding test utterances using the factorial speech processing models. Output of each step is\nspecified in its block. In source modeling step, speech and noise source models are trained from clean speech utterances and noise signals. Speech models are usually HMMs trained for triphones or whole word depending on the\ntask. For stationary noises, a multivariate Gaussian distribution may be used as the noise model and for non-stationary\nnoise GMMs and HMMs may be used. For non-stationary noises with some patterns in state dynamics, transition matrix of HMMs represents state dynamics (Details of source and SCOD modeling for our experiments is provided\nin the next sub-section). In the next step, SCOD models are trained based on weighted \u201cstereo\u201d samples where the\nobserved feature samples are initially extracted from non-conditional observation distribution and are weighted according to their corresponding source samples and source models. Then the SCOD models are trained by weighted\n\u201cstereo\u201d samples using the extended EM method. Finally in the test phase, features of the test utterance are extracted and state-conditional observation likelihoods are calculated to perform decoding using two-dimensional Viterbi\nalgorithm."}, {"heading": "4.1. Source modeling", "text": "Speech source models are created by the Aurora 2 standard recognition scripts [24] in clean condition training mode using HTK toolkit [14] except that for the front-end we use feature extraction functions of the Voicebox toolbox [25]. Framing and windowing are done similar to the standard Aurora 2 recognition scripts. Despite the fact that the proposed method for SCOD modeling allows us independently select feature spaces of source and observed features, but for comparing the performance of the ideal SCOD models to other methods, we limit ourselves to Mel-Frequency Cepstral Coefficients (MFCC) with an specific configuration which is supported by the mismatch functions. Since second order derivatives of MFCCs provide no significant improvements in the experiments we only use first order derivatives. Instead of log energy of frame, zero order coefficient of MFCC features is used. In addition, the applied filterbank to power spectrum only contains 13 filters which enables us to use full DCT matrix in feature extraction and normal inverse of DCT matrix in the mismatch functions. Feature spaces of speech, noise and corrupted signal are selected to be the same with 26 coefficients (MFCC_0_D(26)).\nFor each digit of the dataset, a sixteen states HMM model is trained by the Aurora 2 standard scripts. In addition for silence and short pause models, three and one state HMMs are used. Observation models of digits consist of three component GMMs while silence and short pause models use six component GMMs. All GMMs have diagonal covariance matrices.\nTwo sets of noise models are used in the experiments. In the first set, noise models have only one component multivariate Gaussians for each noise while in the second set, an HMM with optimized number of states are trained. Noise models of the second set are created by STACS tool [26] and noise modeling is done for each noise separately. This tool starts with single sate model and increases HMM states while train new models in an efficient manner to find best model selected by the BIC criterion. Each state has a multivariate Gaussian as its observation distribution with a diagonal covariance matrix. Trained models for Subway, Babble, Car, and Exhibition noises contain 3, 8, 4 and 4 states accordingly. These models are used in VTS, IDPMC and the proposed WSS SCOD modeling experiments."}, {"heading": "4.2. Modeling state-conditional observation distributions", "text": "For the IDPMC SCOD modeling, generated samples are extracted from source state GMMs while for VTS, SCOD models are conditioned for source states and GMM components of speech state. Therefore IDPMC SCOD models are conditioned on joint speech and noise sates while VTS SCOD models are additionally conditioned on component of each speech state. Additionally VTS based SCOD models are trained by two alpha values (see (4)). At first effect of phase difference is ignored by setting the alpha value to zero. Then second alpha value is set to 2.5 which provides the best results in [17] experiments.\nFor the proposed method, different SCOD models are trained for each noise types by introducing all four types of set A noises by using environment model of (1) except that we ignore the effect of channel distortion. About 17000 speech utterances from train set of dataset are used for creating \u201cstereo\u201d features. Gain coefficient is adjusted to simulate SNRs from -5 dB to 20 dB including infinity. Voice activity detection and speech energy determination is done by the tools provided in the Voicebox, based on ITU recommendation P.56 (similar to Aurora 2 test sets). Moreover, in our experiments, number of mixture components for modeling of SCOD is determined experimentally and is set to three for GMMs with full covariance matrices. Model selection techniques can be used here to select the best models for each speech-noise state SCOD."}, {"heading": "4.3. Results", "text": "In the first experiment, performance of compensated system (single noise state factorial model) based on IDPMC and VTS based SCODs for two selected alpha values are compared. Average word recognition accuracy for four noises of set A against different SNRs for two selected alpha values are plotted in Figure 3.\nAs mentioned in [17] selecting alpha to invalid constant 2.5 (invalid regarding to its support set which is [\u22121, 1]), provides better result than ignoring it, both in VTS and IDPMC SCOD models but with less effect in the IDPMC case.\nAdditionally we observed that IDPMC based SCOD models yields higher recognition rate than VTS based models.\nTherefore alpha is set to be 2.5 for further experiments.\nNow the proposed method for training ideal SCOD models for single noise state and multiple noise states is compared to VTS and IDPMC based SCOD models. Figure 4-left shows this comparison by average word recognition accuracy over four noises in single noise state mode. In addition Figure 4-right, shows absolute improvement in average recognition accuracy for these three methods when multiple noise states are used.\nTable 1 shows detailed recognition accuracy for this case. As we can see use of multiple noise states improves recognition accuracy in all cases and more improvement is achieved in low level SNRs. Additionally while IDPMC based factorial models gain more from using multiple state noise models but WSS based factorial models achieve the best results. This is due to this fact that \u201cstereo\u201d data provides frame-level mapping between the clean speech noise\nsignal and corrupted utterances, hence better implicit mapping of actual corrupted features to clean speech and noise signal features. While the other methods establish this relationship using approximated mismatch functions.\nFigure 4-left depicts the performance of multi-conditioned trained system against three compensation schemes. This\nshows that even for one noise state, the performance of compensated system is greater than multi-conditioned trained\nsystem especially in low SNR conditions. Additionally since all SCOD models are trained based on clean trained source models, recognition performance of clean trained system is also provided in Figure 4-left."}, {"heading": "5. Conclusion", "text": "In this paper, a modeling method based on weighted \u201cstereo\u201d samples for creating state-conditional observation distribution to be used in factorial speech processing models is proposed. In fact the idea behind this method is similar to single pass retraining scheme presented in [10] for model compensation. We present this method with different formulation in addition to its support for non-stationary noises. As it is shown in our experiments, using multiple noise-states increases recognition accuracy especially in low SNR conditions. Due to the use of \u201cstereo\u201d data, the proposed method cannot be used directly in many real applications because this data is not available always. But similar to the ideal compensated models in the single pass retrained systems, we are able to train ideal SCOD models here to assess capabilities of other useful modeling techniques. The purpose for presenting this method is to provide a way to investigate whether increasing the number of noise states in noise models is useful for non-stationary noises in order to improve the overall system performance. As the result, increasing system performance in our experiments encourages researchers for developing methods capable of handling non-stationary noises to be used in factorial speech processing models. Moreover the proposed method is still applicable in noise specific environments where noise information is available in advance in the training phase and it performs far better than multi-condition trained systems."}, {"heading": "Appendix A", "text": "Extending the EM algorithm for modeling mixture of Gaussians based on weighted samples\nIn the E-step of the EM algorithm for weighted particles, particle weights have no effect on the component responsibility equations. By considering particle weights as the replicating order of the particles (similar to (21)), this replication has no effect on the component responsibilities to each particle. Therefore component responsibilities are calculated without considering particle weights by the old parameter set as in E-step of the standard EM algorithm for GMMs:\n\ud835\udefe\ud835\udc59(\ud835\udc58) \u221d \ud835\udf0b\ud835\udc58 \u2032 \ud835\udca9(\ud835\udc9a\ud835\udc59; \ud835\udf41\ud835\udc58 \u2032 , \ud835\udeba\ud835\udc58 \u2032 ) (30)\nwhere the normalization constant is \u2211 \ud835\udf0b\ud835\udc58 \u2032 \ud835\udca9(\ud835\udc9a\ud835\udc59 ; \ud835\udf41\ud835\udc58 \u2032 , \ud835\udeba\ud835\udc58 \u2032 )\ud835\udc3e\ud835\udc58=1 .\nFor the M-step, the following optimization problem must be solved:\n\ud835\udf03\ud835\udc5b\ud835\udc52\ud835\udc64 = argmax \ud835\udf03 \ud835\udcac(\ud835\udf03, \ud835\udf03\u2032)\n\ud835\udc60\ud835\udc61: \u2211 \ud835\udf0b\ud835\udc58 \ud835\udc3e \ud835\udc58=1 = 1\n(31)\nUsing the method of Lagrange multiplier for satisfying the constraint for component priors, we have the\nfollowing objective function for optimization:\n\ud835\udc54(\ud835\udf41, \ud835\udeba, \ud835\udf45) = \u2211 \ud835\udc64\ud835\udc59 \u2211 \ud835\udefe\ud835\udc59(\ud835\udc58)[ln \ud835\udc5d(\ud835\udc9a\ud835\udc59; \ud835\udf41\ud835\udc58 , \ud835\udeba\ud835\udc58) + ln \ud835\udf0b\ud835\udc58] \ud835\udc3e \ud835\udc58=1 \ud835\udc3f \ud835\udc59=1 + \ud835\udf06(\u2211 \ud835\udf0b\ud835\udc58 \ud835\udc3e \ud835\udc58=1 \u2212 1) (32)\nTaking the derivative \ud835\udc54 with respect to \ud835\udf41\ud835\udc58 results in:\n\ud835\udf15\ud835\udc54 \ud835\udf15\ud835\udf41\ud835\udc58\u2044 = 2 \u2211 \ud835\udc64\ud835\udc59\ud835\udefe\ud835\udc59(\ud835\udc58)[\ud835\udeba\ud835\udc58 \u22121(\ud835\udc9a\ud835\udc59 \u2212 \ud835\udf41\ud835\udc58)] \ud835\udc3f \ud835\udc59=1 (33)\nNow (27) is easily obtained for updating \ud835\udf41\ud835\udc58 by setting this derivative to zero. For estimating \ud835\udeba\ud835\udc58 , according to [27] the derivative takes the following form:\n\ud835\udf15\ud835\udc54 \ud835\udf15\ud835\udeba\ud835\udc58\u2044 = \u2212 1\n2 \u2211 \ud835\udc64\ud835\udc59\ud835\udefe\ud835\udc59(\ud835\udc58)[\ud835\udeba\ud835\udc58\n\u22121 \u2212 \ud835\udeba\ud835\udc58 \u22121(\ud835\udc9a\ud835\udc59 \u2212 \ud835\udf41\ud835\udc58)(\ud835\udc9a\ud835\udc59 \u2212 \ud835\udf41\ud835\udc58) \ud835\udc47\ud835\udeba\ud835\udc8c \u2212\ud835\udfcf]\ud835\udc3f\ud835\udc59=1 (34)\nin which the \ud835\udf41\ud835\udc58 is estimated by (27). Setting it to zero, we obtain:\n\u2211 \ud835\udc64\ud835\udc59\ud835\udefe\ud835\udc59(\ud835\udc58)(\ud835\udc9a\ud835\udc59 \u2212 \ud835\udf41\ud835\udc58)(\ud835\udc9a\ud835\udc59 \u2212 \ud835\udf41\ud835\udc58) \ud835\udc47\ud835\udeba\ud835\udc58 \u22121\ud835\udc3f \ud835\udc59=1 = \u2211 \ud835\udc64\ud835\udc59\ud835\udefe\ud835\udc59(\ud835\udc58) \ud835\udc3f \ud835\udc59=1 (35)\nThen (28) is obtained for estimating \ud835\udeba\ud835\udc58 in which when the number of samples are significant, there is no need for adjusting the estimator for bias.\nFinally for \ud835\udf0b\ud835\udc58 we have:\n\ud835\udf15\ud835\udc54 \ud835\udf15\ud835\udf0b\ud835\udc58\u2044 = \u2211 (\ud835\udc64\ud835\udc59\ud835\udefe\ud835\udc59(\ud835\udc58)) \ud835\udf0b\ud835\udc58\u2044 \ud835\udc3f \ud835\udc59=1 + \ud835\udf06 = 0 (36)\nby using the assumption \u2211 \ud835\udf0b\ud835\udc58 \ud835\udc3e \ud835\udc58=1 = 1 and considering \ud835\udefe\ud835\udc59(\ud835\udc58) as a valid conditional probability mass function, \ud835\udf06 is calculated by:\n\ud835\udf06 = \u2212 \u2211 \ud835\udc64\ud835\udc59 \ud835\udc3f \ud835\udc59=1 (37)\nNow we can eliminate \ud835\udf06 from (36) by (37) which leads to (29) for updating \ud835\udf0b\ud835\udc58 ."}], "references": [{"title": "Developments and directions in speech recognition and understanding, Part 1 [DSP Education", "author": ["J. Baker", "L. Deng", "J. Glass", "S. Khudanpur", "C. Lee", "N. Morgan", "D. O\u2019Shaughnessy"], "venue": "IEEE Signal Process. Mag., vol. 26, no. 3, pp. 75 \u201380, May 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Factorial Models for Noise Robust Speech Recognition", "author": ["J.R. Hershey", "S.J. Rennie", "J. Le Roux"], "venue": "Techniques for Noise Robustness in Automatic Speech Recognition, T. Virtanen, R. Singh, and B. Raj, Eds. John Wiley & Sons, Ltd, 2012, pp. 311\u2013345.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "ALGONQUIN: Iterating Laplace\u2019s method to remove multiple types of acoustic distortion for robust speech recognition", "author": ["B.J. Frey", "L. Deng", "A. Acero", "T. Kristjansson"], "venue": "presented at the EUROSPEECH 2001, 2001, pp. 901\u2013904.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2001}, {"title": "Factorial Hidden Markov Models for Speech Recognition: Preliminary Experiments", "author": ["B. Logan", "P.J. Moreno"], "venue": "Cambridge Research Laboratory, Cambridge, Massachusetts, 1997.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1997}, {"title": "Factorial models and refiltering for speech separation and denoising", "author": ["S.T. Roweis"], "venue": "Eighth European Conference on Speech Communication and Technology, 2003.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Super-human multi-talker speech recognition: A graphical modeling approach", "author": ["J.R. Hershey", "S.J. Rennie", "P.A. Olsen", "T.T. Kristjansson"], "venue": "Comput. Speech Lang., vol. 24, no. 1, pp. 45\u201366, Jan. 2010.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Single-Channel Multitalker Speech Recognition", "author": ["S.J. Rennie", "J.R. Hershey", "P.A. Olsen"], "venue": "IEEE Signal Process. Mag., vol. 27, no. 6, pp. 66\u201380, Nov. 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "An Overview of Noise-Robust Automatic Speech Recognition", "author": ["J. Li", "L. Deng", "Y. Gong", "R. Haeb-Umbach"], "venue": "IEEEACM Trans. Audio Speech Lang. Process., vol. 22, no. 4, pp. 745\u2013777, Apr. 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Model-Based Techniques for Noise Robust Speech Recognition", "author": ["M.J.F. Gales"], "venue": "Ph.D. Thesis, University of Cambridge, 1995.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1995}, {"title": "Statistical models for noise-robust speech recognition", "author": ["R.C. Van Dalen"], "venue": "Ph.D. Thesis, Cambridge, 2011.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Factorial Hidden Markov Models", "author": ["Z. Ghahramani", "M.I. Jordan"], "venue": "Mach. Learn., vol. 29, no. 2, pp. 245\u2013 273, 1997.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1997}, {"title": "Dynamic bayesian networks: representation, inference and learning", "author": ["K.P. Murphy"], "venue": "Ph.D. Thesis, University of California, 2002.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2002}, {"title": "The HTK book", "author": ["S. Young", "G. Evermann", "D. Kershaw", "G. Moore", "J. Odell", "D. Ollason", "V. Valtchev", "P. Woodland"], "venue": "Camb. Univ. Eng. Dep., vol. 3, 2002.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2002}, {"title": "Enhancement of log Mel power spectra of speech using a phase-sensitive model of the acoustic environment and sequential estimation of the corrupting noise", "author": ["L. Deng", "J. Droppo", "A. Acero"], "venue": "IEEE Trans. Speech Audio Process., vol. 12, no. 2, pp. 133 \u2013 143, Mar. 2004.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "An analytic derivation of a phase-sensitive observation model for noise robust speech recognition", "author": ["V. Leutnant", "R. Haeb-Umbach"], "venue": "INTERSPEECH, 2009, pp. 2395\u20132398.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "A unified framework of HMM adaptation with joint compensation of additive and convolutive distortions", "author": ["J. Li", "L. Deng", "D. Yu", "Y. Gong", "A. Acero"], "venue": "Comput. Speech Lang., vol. 23, no. 3, pp. 389\u2013405, Jul. 2009.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Single-Channel Speech Separation Using Soft Mask Filtering", "author": ["M.H. Radfar", "R.M. Dansereau"], "venue": "IEEE Trans. Audio Speech Lang. Process., vol. 15, no. 8, pp. 2299 \u20132310, Nov. 2007.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Robust continuous speech recognition using parallel model combination", "author": ["M.J.F. Gales", "S.J. Young"], "venue": "IEEE Trans. Speech Audio Process., vol. 4, no. 5, pp. 352\u2013359, Sep. 1996.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1996}, {"title": "A tutorial on hidden Markov models and selected applications in speech recognition", "author": ["L.R. Rabiner"], "venue": "Proc. IEEE, vol. 77, no. 2, pp. 257\u2013286, 1989.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1989}, {"title": "Stereo-Based Stochastic Mapping for Robust Speech Recognition", "author": ["M. Afify", "X. Cui", "Y. Gao"], "venue": "IEEE Trans. Audio Speech Lang. Process., vol. 17, no. 7, pp. 1325\u20131334, Sep. 2009.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Introduction to Monte Carlo Methods", "author": ["D.J.C. Mackay"], "venue": "Learning in Graphical Models, vol. 89, M. I. Jordan, Ed. Springer Netherlands, 1998, pp. 175\u2013204.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1998}, {"title": "Maximum weighted likelihood estimation", "author": ["S.X. Wang"], "venue": "Ph.D. Thesis, University of British Columbia, Vancouver, Canada, 2001.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}, {"title": "The Aurora experimental framework for the performance evaluation of speech recognition systems under noisy conditions", "author": ["H.G. Hirsch", "D. Pearce"], "venue": "ASR2000-Automatic Speech Recognition: Challenges for the new Millenium ISCA Tutorial and Research Workshop (ITRW), 2000.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2000}, {"title": "VOICEBOX: Speech Processing Toolbox for MATLAB", "author": ["M. Brookes"], "venue": "Imperial College, Exhibition Road,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1997}, {"title": "Fast state discovery for HMM model selection and learning", "author": ["S.M. Siddiqi", "G.J. Gordon", "A.W. Moore"], "venue": "International Conference on Artificial Intelligence and Statistics, 2007, pp. 492\u2013499.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "Some Applications of Matrix Derivatives in Multivariate Analysis", "author": ["P.S. Dwyer"], "venue": "J. Am. Stat. Assoc., vol. 62, no. 318, pp. 607\u2013625, Jun. 1967.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1967}], "referenceMentions": [{"referenceID": 0, "context": "Despite long term efforts and great successes in automatic speech recognition (ASR) systems, rapid degradation of performance in the presence of noise and other competing sources remains the Achilles Heel of these systems [1].", "startOffset": 222, "endOffset": 225}, {"referenceID": 1, "context": "While some feature enhancement and model adaptation techniques loosely use noise source characteristics to increase performance of speech recognition systems, model based methods try to use as much as information they can acquire from noise sources [2].", "startOffset": 249, "endOffset": 252}, {"referenceID": 2, "context": "Factorial speech processing models [3]\u2013[5] are extension of Hidden Markov Models (HMM) which model audio sources and the way that these sources are combined in a generative manner.", "startOffset": 35, "endOffset": 38}, {"referenceID": 4, "context": "Factorial speech processing models [3]\u2013[5] are extension of Hidden Markov Models (HMM) which model audio sources and the way that these sources are combined in a generative manner.", "startOffset": 39, "endOffset": 42}, {"referenceID": 5, "context": "Recent researches achieve higher performance even than human in the multi-talker speech recognition challenge by use of factorial models of speech processing in some specific conditions [6], [7].", "startOffset": 186, "endOffset": 189}, {"referenceID": 6, "context": "Recent researches achieve higher performance even than human in the multi-talker speech recognition challenge by use of factorial models of speech processing in some specific conditions [6], [7].", "startOffset": 191, "endOffset": 194}, {"referenceID": 7, "context": "Despite their successes in the mentioned challenge and their modeling power, factorial models are not widely used for real noise-robust speech processing applications [8]; their computational demand for inference and difficulties in representing their central conditional probability distribution (CPD) are the two main reasons for this lack of use [2].", "startOffset": 167, "endOffset": 170}, {"referenceID": 1, "context": "Despite their successes in the mentioned challenge and their modeling power, factorial models are not widely used for real noise-robust speech processing applications [8]; their computational demand for inference and difficulties in representing their central conditional probability distribution (CPD) are the two main reasons for this lack of use [2].", "startOffset": 349, "endOffset": 352}, {"referenceID": 1, "context": "The second one is the interaction model, [2]; CPD of the observed signal features conditioned on features of its corresponding sources, p(yt|xt , nt) in Figure 1.", "startOffset": 41, "endOffset": 44}, {"referenceID": 8, "context": "This CPD in its deterministic form is called mismatch function [10], [11].", "startOffset": 63, "endOffset": 67}, {"referenceID": 9, "context": "This CPD in its deterministic form is called mismatch function [10], [11].", "startOffset": 69, "endOffset": 73}, {"referenceID": 10, "context": "On the one hand, multiple state sequence increases computational complexity of inference (which is also required for learning) to O(TS) in which T is inference window or lag, K is number of underlying chain, and S is maximum number of states in the chains [12], [13].", "startOffset": 256, "endOffset": 260}, {"referenceID": 11, "context": "On the one hand, multiple state sequence increases computational complexity of inference (which is also required for learning) to O(TS) in which T is inference window or lag, K is number of underlying chain, and S is maximum number of states in the chains [12], [13].", "startOffset": 262, "endOffset": 266}, {"referenceID": 1, "context": "On the other hand, accurate modeling of probabilistic relationship between the observed features and their sources is not always possible in speech recognition applications [2].", "startOffset": 173, "endOffset": 176}, {"referenceID": 8, "context": "This paper focuses on the second challenge of factorial models by incorporating the idea of single-pass retraining [10], [14] for ideal SCOD modeling to be used in factorial speech processing models.", "startOffset": 115, "endOffset": 119}, {"referenceID": 12, "context": "This paper focuses on the second challenge of factorial models by incorporating the idea of single-pass retraining [10], [14] for ideal SCOD modeling to be used in factorial speech processing models.", "startOffset": 121, "endOffset": 125}, {"referenceID": 2, "context": "In the model based noise-robust ASR methods, the following relation is considered between speech and noise signals in an assumed environment for generation of distorted speech signals [3], [15]:", "startOffset": 184, "endOffset": 187}, {"referenceID": 13, "context": "In the model based noise-robust ASR methods, the following relation is considered between speech and noise signals in an assumed environment for generation of distorted speech signals [3], [15]:", "startOffset": 189, "endOffset": 193}, {"referenceID": 9, "context": "By applying filterbank, taking logarithm and use of truncated DCT matrix, the following interaction model is derived for MFCC features [11]:", "startOffset": 135, "endOffset": 139}, {"referenceID": 14, "context": "This residual reflects the effects of the phase difference of (2) and by considering uniform distribution for phase difference, \u03b1 in this residual becomes stochastic; its properties is investigated in [16].", "startOffset": 201, "endOffset": 205}, {"referenceID": 7, "context": "The interaction model is usually approximated by removing the residual [8] or considering its \u03b1 as constant; same value for all frequency bins [17].", "startOffset": 71, "endOffset": 74}, {"referenceID": 15, "context": "The interaction model is usually approximated by removing the residual [8] or considering its \u03b1 as constant; same value for all frequency bins [17].", "startOffset": 143, "endOffset": 147}, {"referenceID": 1, "context": "Two examples are max and soft-max approximation for log-power-spectral features [2], [18].", "startOffset": 80, "endOffset": 83}, {"referenceID": 16, "context": "Two examples are max and soft-max approximation for log-power-spectral features [2], [18].", "startOffset": 85, "endOffset": 89}, {"referenceID": 17, "context": "Parallel model combination (PMC) is an example of this group [19].", "startOffset": 61, "endOffset": 65}, {"referenceID": 15, "context": "A successful and complete VTS based compensation is presented in [17].", "startOffset": 65, "endOffset": 69}, {"referenceID": 8, "context": "Developed methods in this set are known as variations of data-driven PMC [10].", "startOffset": 73, "endOffset": 77}, {"referenceID": 9, "context": "This is the reason for naming this kind of robust speech recognition, \u201cmodel compensation\u201d [11].", "startOffset": 91, "endOffset": 95}, {"referenceID": 9, "context": "Detail derivation of these expressions for single state noise models can be found in [11], [17]; extending them for multiple noise sates is straightforward.", "startOffset": 85, "endOffset": 89}, {"referenceID": 15, "context": "Detail derivation of these expressions for single state noise models can be found in [11], [17]; extending them for multiple noise sates is straightforward.", "startOffset": 91, "endOffset": 95}, {"referenceID": 8, "context": "This model may consist of single Gaussian or multiple Gaussians where the method is named DPMC or IDPMC respectively [10], [11].", "startOffset": 117, "endOffset": 121}, {"referenceID": 9, "context": "This model may consist of single Gaussian or multiple Gaussians where the method is named DPMC or IDPMC respectively [10], [11].", "startOffset": 123, "endOffset": 127}, {"referenceID": 18, "context": "It is noteworthy that the role of SCOD in inference here is similar to the observation model in HMMs; like bi(ot) according to notations of [20].", "startOffset": 140, "endOffset": 144}, {"referenceID": 5, "context": "For more details on the two chain models or general cases of using the algorithm, the reader is referred to [6] or [9, Ch.", "startOffset": 108, "endOffset": 111}, {"referenceID": 10, "context": "8], [12] respectively.", "startOffset": 4, "endOffset": 8}, {"referenceID": 7, "context": "These feature vectors are known as stereo features [8], [21].", "startOffset": 51, "endOffset": 54}, {"referenceID": 19, "context": "These feature vectors are known as stereo features [8], [21].", "startOffset": 56, "endOffset": 60}, {"referenceID": 20, "context": "We use importance sampling scheme [22] to correct bias occurred by non-conditional samples for modeling the SCOD using particle weights which indicates association of particle weights to states.", "startOffset": 34, "endOffset": 38}, {"referenceID": 21, "context": "Parameter estimation of single Gaussian models can be done by maximum weighted likelihood estimators [23] as:", "startOffset": 101, "endOffset": 105}, {"referenceID": 22, "context": "The Aurora 2 task [24] for recognizing utterances of digit series corrupted by additive and convolutive noises is selected for evaluating the effectiveness of the proposed method for handling noise models with multiple noise states in SCOD modeling in factorial models.", "startOffset": 18, "endOffset": 22}, {"referenceID": 22, "context": "Source modeling Speech source models are created by the Aurora 2 standard recognition scripts [24] in clean condition training mode using HTK toolkit [14] except that for the front-end we use feature extraction functions of the Voicebox toolbox [25].", "startOffset": 94, "endOffset": 98}, {"referenceID": 12, "context": "Source modeling Speech source models are created by the Aurora 2 standard recognition scripts [24] in clean condition training mode using HTK toolkit [14] except that for the front-end we use feature extraction functions of the Voicebox toolbox [25].", "startOffset": 150, "endOffset": 154}, {"referenceID": 23, "context": "Source modeling Speech source models are created by the Aurora 2 standard recognition scripts [24] in clean condition training mode using HTK toolkit [14] except that for the front-end we use feature extraction functions of the Voicebox toolbox [25].", "startOffset": 245, "endOffset": 249}, {"referenceID": 24, "context": "Noise models of the second set are created by STACS tool [26] and noise modeling is done for each noise separately.", "startOffset": 57, "endOffset": 61}, {"referenceID": 15, "context": "5 which provides the best results in [17] experiments.", "startOffset": 37, "endOffset": 41}, {"referenceID": 15, "context": "As mentioned in [17] selecting alpha to invalid constant 2.", "startOffset": 16, "endOffset": 20}, {"referenceID": 8, "context": "In fact the idea behind this method is similar to single pass retraining scheme presented in [10] for model compensation.", "startOffset": 93, "endOffset": 97}, {"referenceID": 25, "context": "For estimating \u03a3k , according to [27] the derivative takes the following form: \u2202g \u2202\u03a3k \u2044 = \u2212 1 2 \u2211 wl\u03b3l(k)[\u03a3k \u22121 \u2212 \u03a3k (yl \u2212 \u03bck)(yl \u2212 \u03bck) \u03a3k ] l=1 (34)", "startOffset": 33, "endOffset": 37}], "year": 2015, "abstractText": "This paper investigates the role of factorial speech processing models in noise-robust automatic speech recognition tasks. Factorial models can embed non-stationary noise models using Markov chains as one of its source chain. The paper proposes a modeling scheme for modeling state-conditional observation distribution of factorial models based on weighted stereo samples. This scheme is an extension to previous single pass retraining for ideal model compensation and here we used it to construct ideal state-conditional observation distributions. Experiments of this paper over the set A of the Aurora 2 dataset shows that by considering noise models with multiple states, system performance can be improved especially in low SNR conditions up to 4% absolute word recognition performance. In addition to its power in accurate representation of state-conditional observation distribution, it has an important advantage over previous methods by providing the opportunity to independently select feature spaces for both source and corrupted features. This opens a new window for seeking better feature spaces appropriate for noise-robust tasks independent from clean speech feature space.", "creator": "Microsoft\u00ae Word 2013"}}}