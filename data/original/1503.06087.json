{"id": "1503.06087", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2015", "title": "The RatioLog Project: Rational Extensions of Logical Reasoning", "abstract": "Higher-level cognition includes logical reasoning and the ability of question answering with common sense. Our RatioLog project addresses the problem of rational reasoning in deep question answering by methods from automated deduction and cognitive computing. In a first phase, we combine techniques from information retrieval and machine learning to find appropriate answer candidates from the huge amount of text in the German version of the free encyclopedia \"Wikipedia\". In a second phase, an automated theorem prover tries to verify the answer candidates on the basis of their logical representations. In a third phase - because the knowledge may be incomplete and inconsistent -, we consider extensions of logical reasoning to improve the results. In this context, we work toward application of techniques from human reasoning: We employ defeasible reasoning to compare the answers w.r.t. specificity, deontic logic, normative reasoning, and model construction. Moreover, we use integrated case-based reasoning and machine learning techniques on the basis of the semantic structure of the questions and answer candidates to learn giving the right answers.", "histories": [["v1", "Fri, 20 Mar 2015 14:33:48 GMT  (170kb,D)", "https://arxiv.org/abs/1503.06087v1", null], ["v2", "Thu, 30 Jul 2015 08:21:03 GMT  (1885kb,D)", "http://arxiv.org/abs/1503.06087v2", "7 pages, 3 figures"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ulrich furbach", "claudia schon", "frieder stolzenburg", "karl-heinz weis", "claus-peter wirth"], "accepted": false, "id": "1503.06087"}, "pdf": {"name": "1503.06087.pdf", "metadata": {"source": "CRF", "title": "The RatioLog Project: Rational Extensions of Logical Reasoning", "authors": ["Ulrich Furbach"], "emails": ["schon}@uni-koblenz.de,", "khweis@weis-consulting.de", "fstolzenburg@hs-harz.de,", "wirth@logic.at"], "sections": [{"heading": null, "text": "Keywords automated deduction \u00b7 case-based reasoning \u00b7 common-sense reasoning \u00b7 defeasible reasoning \u00b7 deontic logic \u00b7 question answering \u00b7 specificity\nU. Furbach, C. Schon, K.-H. Weis Artificial Intelligence Research Group, Universita\u0308t Koblenz-Landau, Universita\u0308tsstr. 1, 56070 Koblenz, Germany E-mail: {uli, schon}@uni-koblenz.de, khweis@weis-consulting.de\nF. Stolzenburg, C.-P. Wirth Automation and Computer Sciences Department, Harz University of Applied Sciences, Friedrichstr. 57\u201359, 38855 Wernigerode, Germany E-mail: fstolzenburg@hs-harz.de, wirth@logic.at"}, {"heading": "1 Rational Reasoning and Question Answering", "text": "The development of formal logic played a big role in the field of automated reasoning, which led to the development of the field of artificial intelligence (AI). Applications of automated deduction in mathematics have been investigated from the early years on. Nowadays automated deduction techniques are successfully applied in hard- and software verification and many other areas (for an overview see [2]).\nIn contrast to formal logical reasoning, however, human reasoning does not strictly follow the rules of classical logic. Reasons may be incomplete knowledge, incorrect beliefs, and inconsistent norms. From the very beginning of AI research, there has been a strong emphasis on incorporating mechanisms for rationality, such as abductive or defeasible reasoning. From these efforts, as part of the field of knowledge representation, common-sense reasoning has emerged as a branching discipline with many applications in AI [17].\nNowadays there is a chance to join automated deduction and common-sense reasoning within the paradigm of cognitive computing, which allows the implementation of rational reasoning [16]. The general motivation for the development of cognitive systems is that computers can solve welldefined mathematical problems with enormous precision at a reasonably sufficient speed in practice. It remains difficult, however, to solve problems that are only vaguely outlined. One important characteristic of cognitive computing is that many different knowledge formats and many different information processing methods are used in a combined fashion. Also the amount of knowledge is huge and, even worse, it is even increasing steadily. For the logical reasoning, a similar argument holds: Different reasoning mechanisms have to be employed and combined, such as classical deduction (forward reasoning) on the one hand, and abduction or other non-monotonic reasoning mechanisms on the other hand.\nLet us illustrate this with a well-known example from the literature:\nar X\niv :1\n50 3.\n06 08\n7v 2\n[ cs\n.A I]\n3 0\nJu l 2\n01 5\n1. Tom is an emu. 2. Emus are birds. 3. Birds normally fly. 4. Emus do not fly.\nThe question is: Can emus fly or not? Forward reasoning allows us to infer that emus are birds and hence can normally fly. This is in conflict, however, with the strict background knowledge that emus do not fly. The conflict can be solved by assuming certain knowledge as default or defeasible, which only holds normally. Hence we may conclude here that emus and therefore Tom does not fly. We will come back to this example later (namely in Section 2.2 and 2.3).\nRational reasoning must be able to deal with incomplete as well as conflicting (or even inconsistent) knowledge. Moreover, huge knowledge bases with inconsistent contents must be handled. Therefore, it seems to be a good idea to combine and thus enhance rational reasoning by information retrieval techniques, e.g. techniques from machine learning. This holds especially for the domain of deep question answering, where communication with patterns of human reasoning is desirable.\n1.1 Deep Question Answering and the LogAnswer System\nTypically, question answering systems, including application programs such as Okay Googler or Appler\u2019s Siri, communicate with the user in natural language. They accept properly formulated questions and return concise answers. These automatically generated answers are usually not extracted directly from the web, but, in addition, the system operates on an extensive (background) knowledge base, which has been derived from textual sources in advance.\nLogAnswer [8,9] is an open-domain question answering system, accessible via a web interface (www.loganswer. de) similar to that of a search engine. The knowledge used to answer the question is gained from 29.1 million naturallanguage sentences of a snapshot of the German Wikipedia. Furthermore, a background knowledge consisting of 12,000 logical facts and rules is used. The LogAnswer system was developed in the DFG-funded LogAnswer project, a cooperation between the groups on Intelligent Information and\nCommunication Systems at the FernUniversita\u0308t Hagen and the AI research group at the University of Koblenz-Landau. The project aimed at the development of efficient and robust methods for logic-based question answering. The user enters a question and LogAnswer presents the five best answers from a snapshot of the German \u201cWikipedia\u201d, highlighted in the context of the relevant textual sources.\nMost question answering systems rely on shallow linguistic methods for answer derivation, and there is only little effort to include semantics and logical reasoning. This may make it impossible for the system to find any answers: A superficial word matching algorithm is bound to fail if the textual sources use synonyms of the words in the question. Therefore, the LogAnswer system models some form of background knowledge, and combines cognitive aspects of linguistic analysis, such as semantic nets in a logical representation, with machine learning techniques for determining the most appropriate answer candidate.\nContrary to other systems, LogAnswer uses an automated theorem prover to compute the replies, namely Hyper [3], an implementation of the hypertableaux calculus [1], extended with equality among others. It has demonstrated its strength in particular for reasoning problems with a large number of irrelevant axioms, as they are characteristic for the setting of question answering. The logical reasoning is done on the basis of a logical representation of the semantics of the entire text contained in the Wikipedia snapshot. This is computed beforehand with a system developed by computational linguists [13] which employs the MultiNet graph formalism (Multilayered Extended Semantic Networks) [15].\nSince methods from natural-language processing are often confronted with flawed textual data, they strive toward robustness and speed, but often lack the ability to perform more complex inferences. By contrast, a theorem prover uses a sound calculus to derive precise proofs of a higher complexity; even minor flaws or omissions in the data, however, lead to a failure of the entire derivation process. Thus, additional techniques from machine learning, defeasible and normative reasoning etc. should be applied to improve the quality of the answers \u2014 as done in the RatioLog project.\nFor this, the reasoning in classical logic is extended by various forms of non-monotonic aspects, such as defeasible argumentation. By these extensions, the open-domain question answering system LogAnswer is turned into a system for rational question answering, which offers a testbed for the evaluation of rational reasoning.\n1.2 The LogAnswer System and its Modules\nWhen processing a question, the LogAnswer system performs several different steps. Figure 1 presents details on these steps. At first, information retrieval (IR), i.e. pattern matching, is used to filter text passages suitable for the given question from the textual representation of the Wikipedia. For this, the text sources are segmented into sentence-sized passages. The corresponding representation can be enriched by the descriptors of other sentences that result from a coreference solution of pronouns, where the referred phrase is added to the description, if e.g. the pronoun \u2019he\u2019 refers to the individual \u2019Ian Fleming\u2019. Then decision tree learning ranks the text passages and chooses a set of answer candidates from these text passages (Ranking step in Figure 1). Here, features like the number of matching lexemes between passages and the question or the occurrences of proper names in the passage are computed. Up to 200 text passages are extracted from the knowledge base according to this ranking.\nIn the next step (Reasoning), the Hyper theorem prover is used to check if these text passages provide an answer to the question. For every answer candidate, a first-order logic representation of both the question and the answer candidate is combined with a huge background knowledge. These proofs provide the answer to the question by means of variable assignments. The proofs for the answer candidates are then ranked again using decision tree learning (in the answer validation phase). For the five best answers, text passages providing the answer are highlighted and presented to\nthe user. This is done by a natural language (NL) answer generation module, which eventually yields the final answer candidates, in our case that Ian Fleming is a British author.\nIn the LogAnswer system, various techniques work interlocked. See Figure 2 for an overview of the different techniques together with the modules in which they are used. Extraction of text passages for a certain question is performed in the candidate selection module. In this module, both information retrieval and decision tree learning work hand in hand to find a list of answer candidates for the current question. For each answer candidate, the reasoning module is invoked. This module consists of the Hyper theorem prover, which is used to check if the answer candidate provides an answer for the question. Since Hyper is able to handle first-order logic with equality and knowledge bases given in description logic, it is possible to incorporate background knowledge given in various (formal) languages.\nAn interesting extension of usual background knowledge is the use of a knowledge base containing normative statements formalized in deontic logic. These normative statements enable the system to reason in a rational way. Since deontic logic can be translated into description logics, Hyper can be used to reason on such knowledge bases. Reasoning in defeasible logic is another technique contained in the reasoning module of the LogAnswer system. With the help of defeasible logic reasoning, different proofs produced by Hyper are compared. The proofs found by Hyper provide answers to the given question by means of variable assignments. Comparing the proofs for different answer candidates therefore is used to determine the best answer. Hence defeasible logic is contained in the answer validation module. In addition to that, the answer validation module contains decision tree learning to rank different proofs found by Hyper and case-based reasoning. Details on the use of case-based reasoning and reasoning in defeasible logic, that can both be used in the answer validation phase (see Figure 1), can be found in the Section 2."}, {"heading": "2 Searching for Good Answers", "text": "As depicted before, the reasoning component of the LogAnswer system delivers proofs, which represent the possible answers to the given question. The proofs are ranked by decision trees which take into account several attributes of the reasoning process together with the attribute from the previous information retrieval step.\nIn addition to this ranking, we experiment with different other techniques to improve the evaluation of answers. These are case-based reasoning (CBR) (Section 2.1), defeasible reasoning (Section 2.2), and normative (deontic) reasoning (Section 2.3). To perform systematic and extensive tests with LogAnswer, we used the CLEF database, strictly speaking, its question answering part.\nCLEF stands for cross-language evaluation forum, see www. clef-campaign.org. It is an international campaign providing language data in different languages, e.g. from newspaper articles. Its workshop and competition series contains a track on question answering. We used data from CLEF2007 and CLEF-2008 [12,18].\n2.1 CBR Similarity Measures and Machine Learning\nAnswer validation can be enhanced by using experience knowledge in form of cases in a case base. The resulting system module is designed as a learning system and based on a dedicated CBR control structure. Contrary to common procedures in natural-language processing, however, we do not follow the textual approach, where experiences are available in unstructured or semi-structured text form, but use a structured approach along the lines of [4]. This is possible because the knowledge source is available not only in textual but also in a logical format. The semantics of the naturallanguage text is given basically by first-order predicate logic formulae, which are represented by MultiNet graphs [15]. Our basis is a manually achieved classification for each pair of question (from the CLEF 2007 and 2008 data) and answer candidate (from the LogAnswer system) whether the answer candidate is a good one for the question. In order to compare and to define a similarity measure of the MultiNet graphs, we have developed a new graph similarity measure [14,22] which improves other existing measures, e.g. [4,6].\nWe measured the CBR system classification accuracy by running tests with a case base from the CLEF 2007 and 2008 data. Our overall test set had 254 very heterogeneous questions and ca. 15000 cases. For instance, in one of the evaluations, namely the user interaction simulation (see Figure 3), we examined the development of the results for a growing knowledge base. We simulated users that give reliable feedback to new, heterogeneous questions for which the LogAnswer system provides answers candidates. The test setting was to guess the classification of questions and answer candidates the system does not have in the knowledge base. The results show the increase of the classification accuracy with a growing number of correct cases in the case base. We performed a number of other evaluation experiments, e.g. 3- and 10-fold cross validations. For more information about the integrated CBR/Machine learning evaluation and test settings, please refer to [14,22].\nWe further integrated case-based reasoning into the already existing answer selection techniques in LogAnswer (answer validation phase, see Figure 1). For this, the results of the CBR stage were turned into numeric features. A ranking model determined by a supervised learning-to-rank approach combined these CBR-based features with other answer selection features determined by shallow linguistic processing and logical answer validation The final machine\nlearning ranker is an ensemble of ten rank-optimizing decision trees, obtained by stratified bagging, whose individual probability estimates are combined by averaging. When training the machine learning ranker on a case base optimized for perfect treatment of correct answer candidates, we get the best overall result in our tests with a mean reciprocal rank (MRR) of 0.74 (0.72 without CBR) and a correct topranked answer chosen in 61% (58% without CBR) of the cases. It is instructive to consider the usage of CBR features in the machine learning ranker, by inspecting all branching conditions in the generated trees and counting the frequency of occurrence of each feature in such a branching condition, since 10 bags of 10 decision trees were generated in the 10 cross-validation runs, there is a total of 100 trees to base results on [14,22]. In total, 42.5% of all split conditions in the learned trees involve one of the CBR attributes. This further demonstrates the strong impact of CBR results on answer re-ranking.\n2.2 The Specificity Criterion\nMore specific answer candidates are to be preferred to less specific ones, and we can compare them according to their specificity as follows. To obtain what argumentation theories call an argument, we form a pair of an answer candidate and its derivation. The derivation can be based on positiveconditional rules, generated from Hyper\u2019s verifications and capturing the Wikipedia page of the answer candidate and the linguistic knowledge actually applied. Now we find ourselves in the setting of defeasible reasoning and can sort the arguments according to their specificity.\nIn defeasible reasoning, certain knowledge is assumed to be defeasible. Strict knowledge, however, is specified by contingent facts (e.g. in the emu example from Section 1, \u201cTom is an emu\u201d) and general rules holding in all possi-\nble worlds without exception (e.g. \u201cemus do not fly\u201d). Strict knowledge is always preferred to knowledge depending also on defeasible rules (e.g. \u201cbirds normally fly\u201d).\nAlready in 1985, David Poole had the idea to prefer more specific arguments in case of conflicting results as follows [19]: For any derivation of a given result, represented as a tree, consider the sets of all leaves that contribute to the applications of defeasible rules. An activation set is a set of literals from which all literals labeling such a set of leaves is derivable. Thereby, an activation set is sufficient to activate the defeasible parts of a derivation in the sense of a presupposition, without using any additional contingent facts.\nOne argument is now more specific than another one if all its activation sets are activation sets of the other one. This means that each activation set of the more specific argument (seen as the conjunction of its literals) must be more specific than an activation set of the other one. Note that the meaning of the latter usage of the word \u201cspecific\u201d is just the traditional common-sense concept of specificity, according to which a criterion (here: conjunction of literals) is more specific than another one if it entails the other one.\nWe discovered several weaknesses of Poole\u2019s relation, such as its non-transitivity: Contrary to what is obviously intended in [19] and \u201cproved\u201d in [20], Poole\u2019s relation is not a quasi-ordering and cannot generate an ordering. We were able to cure all the discovered weaknesses by defining a quasi-ordering [23,24] (i.e. a reflexive and transitive binary relation), which can be seen as a correction of Poole\u2019s relation, maintaining and clarifying Poole\u2019s original intuition.\nThe intractability of Poole\u2019s relation, known at least since 2003 [21], was attenuated by our quasi-ordering and then overcome by restricting the rules to instances that were actually used in the proofs found by Hyper, and by treating the remaining variables (if any) as constants. With these restrictions, the intractability did not show up anymore in any of the hundreds of examples we tested with our PROLOG implementation.\nRunning this implementation through the entire CLEF2008 database, almost all suggested answer solutions turned out to be incomparable w.r.t. specificity, although our quasiordering can compare more arguments in practice than Poole\u2019s original relation. One problem here is that we have to classify the rules of the CLEF examples as being either general or defeasible, but there is no obvious way to classify them. Another problem with the knowledge encoded in the MultiNet formalism is that it first and foremost encodes only linguistic knowledge, e.g., who is the agent of a given sentence. Only little background knowledge is available, such as on ontology. All data from the web pages, however, are represented by literals.\nTo employ more (defeasible) background knowledge we investigated other examples, such as the emu example from Section 1. Here, the formalization in first-order logic of the\nnatural-language knowledge on individuals can be achieved with the Boxer system [5,7], which is dedicated to largescale language processing applications. These examples can be successfully treated with the specificity criterion and also with deontic logic (see subsequent section).\n2.3 Making Use of Deontic Logic\nNormative statements like \u201cyou ought not steal\u201d are omnipresent in our everyday life, and humans are used to do reason with respect to them. Since norms can be helpful to model rationality, they constitute an important aspect for common-sense reasoning. This is why normative reasoning is investigated in the RatioLog project [10]. Standard deontic logic (SDL) [11] is a logic which is very suitable for the formalization of knowledge about norms. SDL corresponds to the modal logic K together with a seriality axiom. In SDL the modal operator 2 is interpreted as \u201cit is obligatory that\u201d and the 3 operator as \u201cit is permitted that\u201d. For example a norm like \u201cyou ought not steal\u201d can be intuitively formalized as 2\u00acsteal. From a model theoretic point of view, the seriality axiom contained in SDL ensures that, whenever it is obligatory that something holds, there is always an ideal world fulfilling the obligation.\nIn the RatioLog project, we experiment with SDL by adding normative statements into the background knowledge. The emu example from Section 1 contains the normative assertion\nBirds normally fly.\nwhich can be modeled using SDL as\nBird\u21922Flies\nand is added to the background knowledge. In addition to normative statements, the background knowledge furthermore contains assertions not containing any modal operators, e.g. something like the statement that all emus are birds. Formulae representing contingent facts, like the assertion\nTom is an emu.\nin the emu example, are combined with the background knowledge containing information about norms. The Hyper theorem prover [3] can be used to analyze the resulting knowledge base. For example, it is possible to ask the prover if the observed world with the emu Tom fulfills the norm that birds usually are able to fly.\nWithin the RatioLog project both defeasible logic and deontic logic are used. There are similarities between defeasible logic and deontic logic. For example in defeasible logic there are rules which are considered to be not strict but defeasible. These defeasible rules are similar to normative statements, since norms only describe how the world ought\nto be and not how it actually is. This is why we are also investigating the connection between these two logics within the RatioLog project."}, {"heading": "3 Conclusions", "text": "Deep question answering does not only require pattern matching and indexing techniques, but also rational reasoning. This has been investigated within the RatioLog project as demonstrated in this article. Techniques from machine learning with similarity measures and case-based reasoning, defeasible reasoning with (a revision of) the specificity criterion, and normative reasoning with deontic logic help to select good answer candidates. If the background knowledge, however, mainly encodes linguistic knowledge \u2014 without general common-sense world knowledge \u2014 then the effect on finding good answer candidates is low. Therefore, future work will concentrate on employing even more background world knowledge (e.g. from ontology databases), so that rational reasoning can be exploited more effectively when applied to this concrete knowledge.\nAcknowledgements The authors gratefully acknowledge the support of the DFG under the grants FU 263/15-1 and STO 421/5-1 Ratiolog."}], "references": [{"title": "Hyper tableaux", "author": ["P. Baumgartner", "U. Furbach", "I. Niemel\u00e4"], "venue": "J.J. Alferes, L.M. Pereira, E. Orlowska (eds.) Proceedings of 5th European Workshop on Logics in AI \u2013 JELIA\u201996, LNCS 1126, pp. 1\u201317. Springer", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1996}, {"title": "Reasoning and verification: State of the art and current trends", "author": ["B. Beckert", "R. H\u00e4hnle"], "venue": "IEEE Intelligent Systems 29(1), 20\u201329", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "System description: EKRHyper 1.4 \u2013 extensions for unique names and description logic", "author": ["M. Bender", "B. Pelzer", "C. Schon"], "venue": "In: M.P. Bonacina (ed.) CADE-24,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Experience Management \u2013 Foundations, Development Methodology and Internet-Based Applications", "author": ["R. Bergmann"], "venue": "Springer, Berlin, Heidelberg, New York", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2002}, {"title": "Towards wide-coverage semantic interpretation", "author": ["J. Bos"], "venue": "Proceedings of 6th International Workshop on Computational Semantics IWCS-6, pp. 42\u201353. Tilburg, Netherlands", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Similarity measures for structured representations", "author": ["H. Bunke", "B.T. Messmer"], "venue": "Topics in Case-Based Reasoning: 1st European Workshop EWCBR-93", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1993}, {"title": "Linguistically motivated largescale NLP with C&C and Boxer", "author": ["J.R. Curran", "S. Clark", "J. Bos"], "venue": "Proceedings of the ACL 2007 Demo and Poster Sessions, pp. 33\u201336. Prague, Czech Republic", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Logic-based question answering", "author": ["U. Furbach", "I. Gl\u00f6ckner", "H. Helbig", "B. Pelzer"], "venue": "KI \u2013 K\u00fcnstliche Intelligenz 24(1), 51\u201355", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "An application of automated reasoning in natural language question answering", "author": ["U. Furbach", "I. Gl\u00f6ckner", "B. Pelzer"], "venue": "AI Communications 23(2-3), 241\u2013265", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Automated reasoning in deontic logic", "author": ["U. Furbach", "C. Schon", "F. Stolzenburg"], "venue": "M.N. Murty, X. He, R.R. Chillarige, P. Weng (eds.) Proceedings of MIWAI 2014: Multi-Disciplinary International Workshop on Artificial Intelligence, LNAI 8875, pp. 57\u201368. Springer", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Handbook of Deontic Logic and Normative Systems", "author": ["D. Gabbay", "J. Horty", "X. Parent", "R. van der Meyden", "van der Torre", "L. (eds."], "venue": "College Publications", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Overview of the CLEF 2007 multilingual question answering track", "author": ["D. Giampiccolo", "P. Forner", "J. Herrera", "A. Pe\u00f1as", "C. Ayache", "C. Forascu", "V. Jijkoun", "P. Osenova", "P. Rocha", "B Sacaleanu"], "venue": "Advances in Multilingual and Multimodal Information Retrieval, pp. 200\u2013236. Springer", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Logical validation, answer merging and witness selection: A study in multi-stream question answering", "author": ["I. Gl\u00f6ckner", "S. Hartrumpf", "J. Leveling"], "venue": "Proceedings of RIAO-07. Pittsburgh", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "An integrated machine learning and case-based reasoning approach to answer validation", "author": ["I. Gl\u00f6ckner", "K.H. Weis"], "venue": "Proceedings ICMLA 2012. Boca Raton (FL)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Wissensverarbeitung und die Semantik der nat\u00fcrlichen Sprache, 2nd edn", "author": ["H. Helbig"], "venue": "Springer, Berlin, Heidelberg, New York", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Smart Machines: IBM\u2019s Watson and the Era of Cognitive Computing", "author": ["J.E. Kelly III", "S. Hamm"], "venue": "Columbia Business School Publishing", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Commonsense Reasoning, 2nd edn", "author": ["E.T. Mueller"], "venue": "Morgan Kaufmann, San Francisco", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Cross-language evaluation forum \u2013 CLEF 2008", "author": ["C. Peters"], "venue": "DLib Magazine 14(11/12)", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "On the comparison of theories: Preferring the most specific explanation", "author": ["D.L. Poole"], "venue": "A. Joshi (ed.) Proc. 9th Int. Joint Conf. on Artificial Intelligence (IJCAI), 1985, Aug. 18\u201325, Los Altos (CA), pp. 144\u2013147. Morgan Kaufmann (Elsevier)", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1985}, {"title": "A mathematical treatment of defeasible reasoning and its implementation", "author": ["G.R. Simari", "R.P. Loui"], "venue": "Artificial Intelligence 53, 125\u2013 157", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1992}, {"title": "Computing generalized specificity", "author": ["F. Stolzenburg", "A.J. Garc\u0131\u0301a", "C.I. Ches\u00f1evar", "G.R. Simari"], "venue": "Journal of Applied Non-Classical Logics 13, 87\u2013113", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2003}, {"title": "A case based reasoning approach for answer reranking in question answering", "author": ["K.H. Weis"], "venue": "M. Horbach (ed.) Informatik 2013 \u2013 Proceedings, no. 220 in GI-Edition, Lecture Notes in Informatics, pp. 93\u2013104. Koblenz", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "David Poole\u2019s specificity revised", "author": ["C.P. Wirth", "F. Stolzenburg"], "venue": "C. Baral, G.D. Giacomo, T. Eiter (eds.) Int. Conf. on Principles of Knowledge Representation and Reasoning, pp. 168\u2013177. AAAI Press", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "A series of revisions of David Poole\u2019s specificity", "author": ["C.P. Wirth", "F. Stolzenburg"], "venue": "Annals of Mathematics and Artificial Intelligence", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 1, "context": "Nowadays automated deduction techniques are successfully applied in hard- and software verification and many other areas (for an overview see [2]).", "startOffset": 142, "endOffset": 145}, {"referenceID": 16, "context": "From these efforts, as part of the field of knowledge representation, common-sense reasoning has emerged as a branching discipline with many applications in AI [17].", "startOffset": 160, "endOffset": 164}, {"referenceID": 15, "context": "nitive computing, which allows the implementation of rational reasoning [16].", "startOffset": 72, "endOffset": 76}, {"referenceID": 7, "context": "LogAnswer [8,9] is an open-domain question answering system, accessible via a web interface (www.", "startOffset": 10, "endOffset": 15}, {"referenceID": 8, "context": "LogAnswer [8,9] is an open-domain question answering system, accessible via a web interface (www.", "startOffset": 10, "endOffset": 15}, {"referenceID": 2, "context": "Contrary to other systems, LogAnswer uses an automated theorem prover to compute the replies, namely Hyper [3], an implementation of the hypertableaux calculus [1], extended with equality among others.", "startOffset": 107, "endOffset": 110}, {"referenceID": 0, "context": "Contrary to other systems, LogAnswer uses an automated theorem prover to compute the replies, namely Hyper [3], an implementation of the hypertableaux calculus [1], extended with equality among others.", "startOffset": 160, "endOffset": 163}, {"referenceID": 12, "context": "This is computed beforehand with a system developed by computational linguists [13] which employs the MultiNet graph formalism (Multilayered Extended Semantic Networks) [15].", "startOffset": 79, "endOffset": 83}, {"referenceID": 14, "context": "This is computed beforehand with a system developed by computational linguists [13] which employs the MultiNet graph formalism (Multilayered Extended Semantic Networks) [15].", "startOffset": 169, "endOffset": 173}, {"referenceID": 11, "context": "We used data from CLEF2007 and CLEF-2008 [12,18].", "startOffset": 41, "endOffset": 48}, {"referenceID": 17, "context": "We used data from CLEF2007 and CLEF-2008 [12,18].", "startOffset": 41, "endOffset": 48}, {"referenceID": 3, "context": "Contrary to common procedures in natural-language processing, however, we do not follow the textual approach, where experiences are available in unstructured or semi-structured text form, but use a structured approach along the lines of [4].", "startOffset": 237, "endOffset": 240}, {"referenceID": 14, "context": "The semantics of the naturallanguage text is given basically by first-order predicate logic formulae, which are represented by MultiNet graphs [15].", "startOffset": 143, "endOffset": 147}, {"referenceID": 13, "context": "In order to compare and to define a similarity measure of the MultiNet graphs, we have developed a new graph similarity measure [14,22] which improves other existing measures, e.", "startOffset": 128, "endOffset": 135}, {"referenceID": 21, "context": "In order to compare and to define a similarity measure of the MultiNet graphs, we have developed a new graph similarity measure [14,22] which improves other existing measures, e.", "startOffset": 128, "endOffset": 135}, {"referenceID": 3, "context": "[4,6].", "startOffset": 0, "endOffset": 5}, {"referenceID": 5, "context": "[4,6].", "startOffset": 0, "endOffset": 5}, {"referenceID": 13, "context": "For more information about the integrated CBR/Machine learning evaluation and test settings, please refer to [14,22].", "startOffset": 109, "endOffset": 116}, {"referenceID": 21, "context": "For more information about the integrated CBR/Machine learning evaluation and test settings, please refer to [14,22].", "startOffset": 109, "endOffset": 116}, {"referenceID": 13, "context": "It is instructive to consider the usage of CBR features in the machine learning ranker, by inspecting all branching conditions in the generated trees and counting the frequency of occurrence of each feature in such a branching condition, since 10 bags of 10 decision trees were generated in the 10 cross-validation runs, there is a total of 100 trees to base results on [14,22].", "startOffset": 370, "endOffset": 377}, {"referenceID": 21, "context": "It is instructive to consider the usage of CBR features in the machine learning ranker, by inspecting all branching conditions in the generated trees and counting the frequency of occurrence of each feature in such a branching condition, since 10 bags of 10 decision trees were generated in the 10 cross-validation runs, there is a total of 100 trees to base results on [14,22].", "startOffset": 370, "endOffset": 377}, {"referenceID": 18, "context": "Already in 1985, David Poole had the idea to prefer more specific arguments in case of conflicting results as follows [19]: For any derivation of a given result, represented as a tree, consider the sets of all leaves that contribute to the applications of defeasible rules.", "startOffset": 118, "endOffset": 122}, {"referenceID": 18, "context": "We discovered several weaknesses of Poole\u2019s relation, such as its non-transitivity: Contrary to what is obviously intended in [19] and \u201cproved\u201d in [20], Poole\u2019s relation is not a quasi-ordering and cannot generate an ordering.", "startOffset": 126, "endOffset": 130}, {"referenceID": 19, "context": "We discovered several weaknesses of Poole\u2019s relation, such as its non-transitivity: Contrary to what is obviously intended in [19] and \u201cproved\u201d in [20], Poole\u2019s relation is not a quasi-ordering and cannot generate an ordering.", "startOffset": 147, "endOffset": 151}, {"referenceID": 22, "context": "We were able to cure all the discovered weaknesses by defining a quasi-ordering [23,24] (i.", "startOffset": 80, "endOffset": 87}, {"referenceID": 23, "context": "We were able to cure all the discovered weaknesses by defining a quasi-ordering [23,24] (i.", "startOffset": 80, "endOffset": 87}, {"referenceID": 20, "context": "The intractability of Poole\u2019s relation, known at least since 2003 [21], was attenuated by our quasi-ordering and then overcome by restricting the rules to instances that were actually used in the proofs found by Hyper, and by treating the remaining variables (if any) as constants.", "startOffset": 66, "endOffset": 70}, {"referenceID": 4, "context": "Here, the formalization in first-order logic of the natural-language knowledge on individuals can be achieved with the Boxer system [5,7], which is dedicated to largescale language processing applications.", "startOffset": 132, "endOffset": 137}, {"referenceID": 6, "context": "Here, the formalization in first-order logic of the natural-language knowledge on individuals can be achieved with the Boxer system [5,7], which is dedicated to largescale language processing applications.", "startOffset": 132, "endOffset": 137}, {"referenceID": 9, "context": "This is why normative reasoning is investigated in the RatioLog project [10].", "startOffset": 72, "endOffset": 76}, {"referenceID": 10, "context": "Standard deontic logic (SDL) [11] is a logic which is very suitable for the formalization of knowledge about norms.", "startOffset": 29, "endOffset": 33}, {"referenceID": 2, "context": "The Hyper theorem prover [3] can be used to analyze the resulting", "startOffset": 25, "endOffset": 28}], "year": 2015, "abstractText": "Higher-level cognition includes logical reasoning and the ability of question answering with common sense. The RatioLog project addresses the problem of rational reasoning in deep question answering by methods from automated deduction and cognitive computing. In a first phase, we combine techniques from information retrieval and machine learning to find appropriate answer candidates from the huge amount of text in the German version of the free encyclopedia \u201cWikipedia\u201d. In a second phase, an automated theorem prover tries to verify the answer candidates on the basis of their logical representations. In a third phase \u2014 because the knowledge may be incomplete and inconsistent \u2014, we consider extensions of logical reasoning to improve the results. In this context, we work toward the application of techniques from human reasoning: We employ defeasible reasoning to compare the answers w.r.t. specificity, deontic logic, normative reasoning, and model construction. Moreover, we use integrated case-based reasoning and machine learning techniques on the basis of the semantic structure of the questions and answer candidates to learn giving the right answers.", "creator": "LaTeX with hyperref package"}}}