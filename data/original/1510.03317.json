{"id": "1510.03317", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Oct-2015", "title": "The Inductive Constraint Programming Loop", "abstract": "Constraint programming is used for a variety of real-world optimisation problems, such as planning, scheduling and resource allocation problems. At the same time, one continuously gathers vast amounts of data about these problems. Current constraint programming software does not exploit such data to update schedules, resources and plans. We propose a new framework, that we call the Inductive Constraint Programming loop. In this approach data is gathered and analyzed systematically, in order to dynamically revise and adapt constraints and optimization criteria. Inductive Constraint Programming aims at bridging the gap between the areas of data mining and machine learning on the one hand, and constraint programming on the other hand.", "histories": [["v1", "Mon, 12 Oct 2015 14:51:03 GMT  (776kb,D)", "http://arxiv.org/abs/1510.03317v1", "17 pages, 9 figures"]], "COMMENTS": "17 pages, 9 figures", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["christian bessiere", "luc de raedt", "tias guns", "lars kotthoff", "mirco nanni", "siegfried nijssen", "barry o'sullivan", "anastasia paparrizou", "dino pedreschi", "helmut simonis"], "accepted": false, "id": "1510.03317"}, "pdf": {"name": "1510.03317.pdf", "metadata": {"source": "CRF", "title": "The Inductive Constraint Programming Loop", "authors": ["Christian Bessiere", "Luc De Raedt", "Tias Guns", "Lars Kotthoff", "Mirco Nanni", "Siegfried Nijssen", "Barry O\u2019Sullivan", "Anastasia Paparrizou", "Dino Pedreschi", "Helmut Simonis"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Machine Learning/Data Mining (ML/DM) and Constraint Programming (CP) are central to many application problems. ML is concerned with learning functions/patterns characterizing some training data whereas CP is concerned with finding solutions to problems subject to constraints and possibly an optimization function.\nThe problem with current technology is that the problems of data analysis and constraint satisfaction/optimization have almost always been studied independently and in isolation. Indeed, there exist a wide variety of successful approaches to analysing data in the field of ML, DM and statistics, and at the same time, advanced techniques for addressing constraint satisfaction and optimization problems have been developed in the CP community. Over the past decade a limited number of isolated studies on specific cases has indicated that significant benefits can be obtained by connecting these two fields\nar X\niv :1\n51 0.\n03 31\n7v 1\n[ cs\n.A I]\n[EF01, XHHL08, DGN08, BHO09, KBC10, CJSS12], but so far a truly general, integrated and cross-disciplinary approach is missing.\nCP technology is used to solve many types of problems, such as power companies generating and distributing electricity, hospitals planning their surgeries, and public transportation companies scheduling buses. Despite the availability of effective and scalable solvers, current approaches are still unsatisfactory. The reason is when using CP technology to solve these applications, the constraints and criteria, that is, the model, must be statically specified. However, in reality often this model needs to be revised over time. The revision can be needed to reflect changes in the environment due to external events that impact the problem. The revision can also be needed because the execution of the solution generated by the model has modified the characteristics of the problem. Finally the revision can be needed simply because the original model did not capture correctly the problem. Observing the impact of the solution allows us to correct or improve the model. Therefore, there is an urgent need for improving and revising a model over time based on data that is continuously gathered about the performance of the solutions and the environment they are used in.\nExploiting gathered data to modify the model is difficult and labor intensive with state-of-the-art solvers, as these solvers do not support DM and ML. As a consequence, the data that is being gathered today in order to monitor the quality of the produced solutions and to help evaluating the effect of possible adjustments to the constraints or optimization criteria, is not fully exploited when changes in a schedule or plan are needed. Hence, schedules and plans that are produced are often suboptimal. This, in turn, leads to a waste of resources. Instead of using data passively, data should be actively analysed in order to discover and update the underlying regularities, constraints and criteria that govern the data.\nIn this paper, we propose and formalize the new framework of inductive constraint programming. This framework is based on what we call the Inductive Constraint Programming loop, which is an interaction between a machine learning component (ML) and a constraint programming component (CP). The ML observes the world and extracts patterns. The CP solves a constraint satisfaction or optimization problem using these patterns and whose solution is applied to the world. We assume the world changes over time, possibly due to the impact of applying our solution. This process is repeated in a loop. Inductive constraint programming will serve the long-term vision of easier-to-use and more effective tools for resource optimization and task scheduling."}, {"heading": "2 Background", "text": "In this section we introduce the basic concepts used later in the paper. We briefly define and explain what is a constraint problem and a learning problem."}, {"heading": "2.1 Constraint problem", "text": "The central notion in constraint programming is the constraint. A constraint is a Boolean function whose scope is a set of (integer) variables. Depending on whether the function returns true or false for a given input assignment of its variables, the constraint accepts or rejects the assignment. For instance, the constraint X1 + X2 = X3 specifies that any combination of values for variables X1, X2 and X3 has to be such that the sum of X1 and X2 equals X3. Based on the notion of constraint, we define constraint network and solver.\nA constraint network N = (X,D,C, f) is composed of: a set X of variables taking values in domain D. These variables are subject to constraints in the set C. The optional evaluation function f takes as input an assignment on X and returns a cost for it. A solution (optionally best solution) of N is a tuple in DX satisfying all the constraints in C (optionally minimizing f). A solver takes as input a constraint network and returns a solution/best solution or failure in case no solution satisfying all the constraints exists.\nThere exist several languages/formats for specifying a constraint problem to be given to a solver for solving. Take for instance the Sudoku problem. Figure 1 expresses Sudoku as a constraint satisfaction problem, using a pseudo-MiniZinc language [MS14]. Line 1 defines an input matrix start containing the prefilled cells of the Sudoku. Line 2 defines the matrix puzzle of variables that will contain the solution of the Sudoku. Lines 4-5 put equality constraints between the prefilled cells in the input matrix start and the matrix of variables puzzle. Lines 7-8 post an alldifferent constraint on every row of puzzle. alldifferent(xi | i in 1..n) is a global constraint that specifies that variables x1..xn must all take different values. Lines 10-11 do the same for the columns. Lines 13-15 is a bit more tricky as it has to play with the indices of the subsquares to post the allfdifferent constraints on the variables of every subsquare in puzzle. Finally, line 16 calls the solver on the instance."}, {"heading": "2.2 Learning problem", "text": "In machine learning, the goal is to learn a hypothesis that explains the observed data. The data typically consists of a set of training examples E, which are assumed to be independent and identically distributed. Different learning methods differ largely in the type of examples to learn from, and the type of hypothesis they want to learn. The most popular learning setting is supervised learning, where each example in E is accompanied by a label that should be predicted. One can then search for a linear function over the examples that best predicts the labels, or for a decision tree that does so. More formally, we define the learning task as follows:\nA learning problem L = (E,H, t, loss) is composed of a set E of examples, a hypothesis space H, the target function t that one wants to learn, and a loss function loss(E, h, t) that measures the quality of a hypothesis h \u2208 H w.r.t. dataset E and the target hypothesis t. The task is to find a hypothesis that minimizes the loss.\nFor example, given real-valued data E \u2282 Rd and real-valued labels identified by target function t, where \u2200e \u2208 E : t(e) \u2208 R, the goal of linear regression is to learn a linear function hc : E \u2192 R with coefficients c that minimizes the sum of squared errors between the predicted value and the observed value: loss(E, hc, t) = \u2211 e\u2208E |hc(e) \u2212 t(e)|2 = \u2211 e\u2208E |e \u00b7 c \u2212 t(e)|2. Many other loss functions and hypothesis spaces have been defined in the literature. A range of machine learning methods such as (linear) regression and support vector machines can be expressed as standard optimisation problems (often unconstrained), where the goal is to find an assignment to function parameters such that the loss is minimized. In practice, usually specialised solving methods are used."}, {"heading": "3 Inductive Constraint Programming Loop", "text": "The inductive constraint programming loop will cope with changes in the world by iteratively solving a learning problem and a constraint problem. The loop is composed of several components that interact with each other through writing and reading operations. A visualization of the loop is given in Figure 2. We introduce each of the elements in the loop in turn.\nThe CP component is composed of a constraint network N = (X,D,C, f) (f is optional), a constraint solver Xsolve, and a Solutions repository. Xsolve\ngenerates solutions of N , or good/best solutions of N according to f , that it writes in the Solutions repository. In case Xsolve is not able to produce any solution to be applied to the world, the CP component notifies the ML component by sending information about the failure.\nThe ML component is composed of a learning problem L = (E,H, t, loss), a learner XLearn, and a Patterns repository. XLearn learns hypotheses t (typically one) and writes them in the Patterns repository.\nThe World component is composed of a world W , an evaluation function eval world, and a Observations repository. The world W can have its own independent behavior, dynamically changing under the effect of time and the effect of applying solutions of the Solutions repository. The solutions are evaluated by the eval world function and this feedback is stored in the Observations repository.\nNow that we have defined the basis of the inductive constraint programming loop, we need to define the way the CP component, the ML component and the world interact with each other. They interact through a set of reading/writing functions.\nAn inductive constraint programming loop is composed of a world (W, eval world),\na CP component (N,Xsolve), and an ML component (L,XLearn). The loop uses the following channels of communication:\n\u2022 function World-to-ML reads data and evaluations from the Observations repository and updates the learning problem L, that will be used by XLearn to learn a hypothesis h;\n\u2022 function CP-to-ML is used to send feedback from the CP component to the ML component when Xsolve cannot find any satisfactory solution to be applied to the world;\n\u2022 function World-to-CP reads data from the Observations repository that can be used to directly update the constraint network N used by Xsolve;\n\u2022 function ML-to-CP reads patterns from the Patterns repository and updates the constraint network N used by Xsolve to produce solutions;\n\u2022 function Apply-to-World takes solutions in the Solutions repository and applies them to the world, if possible.\nThe following pseudo code demonstrates how these communication channels are used in the inductive constraint programming loop:\nAlgorithm 1 Pseudo code of a loop cycle using the components.\nfunction cycle(Observations, optional PreviousSolutions) Lo \u2190 World-to-ML(Observations) Lp \u2190 CP-to-ML(PreviousSolutions) L\u2190 constructL(Lo, Lp) Patterns \u2190 applyXlearn(L) No \u2190 World-to-CP(Observations) Np \u2190 ML-to-CP(Patterns) N \u2190 constructN(No, Np) Solutions \u2190 applyXsolve(N) if Apply-to-World(Solutions) then\nreturn else\ncycle(Observations, Solutions) end if\nend function\nInitially, World-to-ML is used to gather training data to the ML component. These data can be feedback from previous executions of solutions of the CP component on the world. The solution of the previous cycle can also directly be used as well, through CP-to-ML. This is especially useful if the previous solution could not be applied to the world, for example because the learned patterns lead to an inconsistency. Using the output of World-to-ML and CPto-ML, the learning problem L can then be constructed, specific to the learner\nat hand. Next, the learner is applied to L and patterns are obtained. These patterns can be weights of an objective function, constraints, or any other type of structural information that is part of the CP problem.\nA similar process then happens for the CP component, the network is constructed using the output of World-to-CP and ML-to-CP, after which the solving method is used and solutions are obtained.\nThese solutions are then applied to the world using Apply-to-World. As mentioned before, it may be that the found solution (or non-solution) is not applicable to the world. In that case, a new iteration of the loop is started immediately which bypasses the world. Otherwise the solutions are applied to the world, after which a new cycle with new observations can be started.\nWe can observe that there is no direct link between the ML component and the world. Our framework is indeed devoted to solving combinatorial problems such as scheduling and routing, revising them based on feedback from the world; it does not aim to only classify or predict events in the world."}, {"heading": "4 Illustrative Example", "text": "To illustrate the inductive constraint programming loop we will use a scheduling setting that occurs in hospitals. This setting includes an ML component, a CP component and a world component.\nWe will first describe the CP component. In this component we focus on a task scheduling problem. The treatment of a patient typically involves the execution of various tasks on this patient, such as executing scans, taking blood tests, operating the patient, physiotherapeutic sessions, and so on. These tasks need to be executed in a well-defined order, and require the use of the resources of the hospital for a certain amount of time. The overall scheduling problem is how to schedule these tasks in the shortest amount of time possible, using the limited resources of the hospital.\nImportant parameters of this scheduling problem hence include the resources available in the hospital and the tasks that need to be executed. For each task, it is important which resources need to be used, how many such resources are needed, and for how long they need to be used.\nWhereas for many patients it is clear which procedures need to be followed before the patient can be discharged from the hospital, this is not the case for the duration of these tasks: depending on parameters such as age or health conditions, a certain task may take much longer for one patient than for another patient.\nThe task of the ML component is to address this challenge: its task is to predict how long a task is estimated to take for a patient. This task involves solving a regression problem as identified earlier: for each given task for a patient, we need to predict its duration, which is a real number.\nThe world component executes the schedules; it produces data about patients and observations concerning the true durations of tasks.\nClearly, as the tasks are executed in the hospital, the predicted durations may differ from the actual durations. Furthermore, new patients and hence new tasks arrive. This means that the hospital needs to schedule tasks on a regular basis. The patient data that is collected during each such iteration can here be used to improve the quality of the predicted task durations. This makes it a good example of the inductive constraint programming loop. Within this loop, we can distinguish the following components and functions:\n\u2022 function World-to-ML reads historical patient data and historical task durations for these patients; furthermore, it reads the patients that are currently in the hospital and the tasks that need to be executed for these patients;\n\u2022 the ML component predicts the durations for the tasks that need to be executed, using the historical data;\n\u2022 function ML-to-CP reads the learned durations and updates the CP network accordingly;\n\u2022 function World-to-CP reads the tasks that need to be executed from the world, as well as the resources available in the hospital;\n\u2022 the CP component solves the updated scheduling problem;\n\u2022 function Apply-to-World applies the resulting schedule in the world.\nIn this example, the function CP-to-ML is not used; it could be used, for instance, if there is a preference to schedule nurses and doctors in similar teams or with similar load or time-breaks from day-to-day.\nBoth components can be formalized using a CP language, such as the MiniZinc language mentioned earlier. Figure 3 shows MiniZinc code for the task scheduling problem. In this model, the parameters of the problem setting are reflected as follows:\n\u2022 the dur array represents the durations of all the tasks, as predicted by the ML component (line 3);\n\u2022 the prev array indicates for each task which task needs to be executed before this task; note that we assume that there is a dummy first task that precedes all tasks (line 4);\n\u2022 the cap array represents the capacity of the resources available (line 7);\n\u2022 the use array represents how many resources of each type need to be used to execute a certain task (line 8).\nThe variables that need to be found are the start variables (line 11), which indicate at which times the tasks need to be executed. The constant max_time represents the latest time at which a task may still start, this could be specified for each task separately as well.\nThe constraints are twofold:\n\u2022 the constraint on line 14 is a cumulative constraint; for a given resource, it ensures for each time point that the use of the resource is within the capacity bound of that resource. Note that the cumulative constraint is a built-in constraint available in the MiniZinc language. Constraints that can involve any number of variables are called global constraints. They can capture complex structural constraints of the problem. Global constraints are an essential part of the efficiency of CP models.\n\u2022 the constraint on line 17 ensures that a task only executes after the task that should precede it has finished.\nThe optimization criterion is to minimize the makespan, that is, to assign the start variables so that the total amount of time used by the schedule is minimum (line 19).\nTo predict the durations of the tasks in the hospital, a regression task needs to be solved. Many different models can be made for this regression task, each corresponding to learning a different type of regression model. Arguably the most simple regression model is the linear model, in which the task duration prediction is based on a linear combination of the characteristics of the patient on which the task is executed.\nThe problem of learning such a regression model is formalized in Figure 4. Variables X and Y represent the training data, where X contains the descriptive attributes of various tasks and Y the historical durations of these tasks; variable W represents the weights of the features that we are learning.\nBased on these weights, we can calculate an error for the predictions; line 10 calculates a weighted linear combination for each training example, using the weights W; this prediction is used in line 12 to calculate an error for each example. Line 15 minimizes the error over all examples, where line 17 defines that the errors for the individual examples are combined by summing the squared errors.\nThe scheduling model and the machine learning model together define both components of the inductive constraint programming loop. We here demonstrated how a declarative, unified language could be used to model both the learning problem and the solving problem. While a single language for both the learning and solving is an appealing prospect, it is not a requirement for the applicability of the inductive constraint programming loop."}, {"heading": "5 Other Examples", "text": "We now briefly describe a number of other problems that can be captured in the inductive constraint programming loop. For each of them, we define the\nproblem, and then define the interactions between the world, the ML component, and the CP component. The first three problems we describe (optimizing bus schedules, car pooling, and energy-aware data centers) are real world problems that can be expressed in a neat and efficient way through the inductive constraint programming loop. The two last (constraint acquisition and portfolio selection) are existing academic problems that can be seen with a new eye through the inductive constraint programming loop."}, {"heading": "5.1 Optimizing bus schedules", "text": "In order to improve human mobility, the region of Pisa plans to take into account information about the trajectories of people taking their car in order to improve the public transportation system. The problem is composed of two parts. The first one consists in tracking the GPS localisation of cell phones to understand the way people commute in the Pisa region. The second part consists in optimising bus schedules to meet as much as possible the requirements of these people. The problem is dynamic as the implementation of the generated bus schedule will affect the way people commute, which should be observed again, and so on. Such a problem can be represented in the inductive constraint programming loop framework.\nThe world is observed through the GPS localisation of cells phones in the region of Pisa and is represented by a set of trajectories of individuals. An evaluation of the traffic quality is provided by the eval world function. eval world is based on a measure of the amount of traffic jams generated by the traffic. All these observations are stored in the Observations repository. The function World-to-ML reads observations that are given as input to the ML component. The ML component uses these observations to learn patterns from the trajectories and from the quality evaluation of the traffic. These learned patterns on the trajectories/time slots are written in the Patterns repository. The CP component contains a constraint network that models the problem of generating good\nbus schedules for the region of Pisa, that is, bus schedules that cover as much as possible trajectories of people at the time they need them. It is parameterized by the weight of each trajectory/time slot. The values of these parameters are computed by the function ML-to-CP based on the input from Patterns. The output of the CP component is a new bus schedule that is written in the Solutions repository to be applied to the world by function Apply-to-World. The process can loop for ever. Figure 5 shows the loop solving this problem."}, {"heading": "5.2 Carpooling", "text": "The carpooling application is aimed at proposing carpooling matches to a set U of users participating to the service, based on their actual mobility (the trips they performed with their private cars) and any information about which kind of match proposals are likely to be accepted by a user. This problem can be modelled in the inductive constraint programming loop framework.\nThe world is observed through a set of raw trajectories for each user, describing the recent mobility of that user. The eval world function returns the response of each user to the previous carpooling solution offered to her (accepted, rejected, will reject next time). All these data are written in the Observations repository. The function World-to-ML simply reads this information and sends it to the ML component, which will perform some mining operations to produce a temporally labelled weighted oriented graph G = (U,E, t, p), where there exists an edge (u, v) \u2208 E if and only if user v can give a lift to user u. Each edge e is labelled with the time t(e) the lift can take place, and a probability p(e) of having the match proposal being accepted by both u and v. The graph G is written in the Patterns repository. ML-to-CP reads this graph and encodes it as a constraint network. The observation of the world also provides other information useful to the carpooling system, e.g. the number of passengers that can be hosted in the users vehicle. The function World-to-CP reads this information and directly sends it to the CP component, which will add the relevant\nconstraints in the network. For each user u, a constraint c(u) defining the maximum capacity of the vehicle of user u wil be added. The CP component solves the network to find the best solution. This solution is a carpooling assignment that maximizes the reduction of cars and the likelihood of acceptance by users. It is written in the Solutions repository, then proposed to the users. Figure 6 shows the loop solving this problem."}, {"heading": "5.3 Energy-aware Data Centres", "text": "The aim is to improve the energy-efficiency of data-centers. Consider a cloud computing service, where customers contract to run computing services (tasks) throughout the day. Tasks are assigned to machines within the data centre and require a certain amount of resources for the duration which they run. The aim is to schedule these tasks such that the overall cost of energy used is minimized. However this is complicated by the fact that large electricity consumers, like a data centre, will typically pay a variable price for their electricity, which is not known in advance. In Ireland for example, the price is not known until four days after. The price may also fluctuate significantly throughout the day, which provides the opportunity to reduce the energy use during peak periods and instead perform the work during cheaper periods. This requires a forecast of the price ahead of time and to produce a schedule of the tasks based on the forecasted price data.\nThis application was the focus of the first inductive CP Challenge1 and is modeled in the inductive constraint programming loop as follows. The world consists of a number of elements: the wide range of factors which affect the energy market, like weather conditions, producers/consumers of electricity, etc; and customers of the data center who contract the various workloads. Worldto-CP gives to the CP component the tasks to be scheduled at the next turn;\n1http://iconchallenge.insight-centre.org/\nWorld-to-ML takes input from the world to produce a hypothesis h modeling the electricity price. ML-to-CP incorporates this forecast to produce a solution to the scheduling problem minimizing the forecast energy cost. Apply-to-World takes this schedule and applies it to the world. As time progresses and the world changes World-to-ML will need to evolve the forecast model, and subsequently the schedule, to take account of factors affecting the energy price. Figure 7 shows the loop solving this problem.\nHere, the machine learning is applied once and the outcome is directly used by the CP program. An alternative, proposed by Tulabandhula and Rudin [TR13], is to do the machine learning while taking the operational cost (the outcome of the CP problem with the learned weights) into account. This can be achieved by making the operational cost a part of the loss function of the ML problem. One can then repeatedly iterate between solving the ML and CP component, before applying the found schedule in the world."}, {"heading": "5.4 Constraint acquisition", "text": "Modeling a problem as a constraint network requires expertise in constraint programming. If we want novices to use constraint programming, we need automatic constraint acquisition systems that assist the user in the modeling task. CONACQ is such a system [BCOP07]. CONACQ interacts with a user to learn a target constraint network that represents the problem of the user. We describe how CONACQ can be implemented as an instance of the inductive constraint programming loop.\nThe world involves a set of examples defined on a set of objects/variables X. An example is an assignment of a value to each of the variables in X. Examples are produced by the CP component or by the world itself. The evaluation function eval world is the user herself, who evaluates the quality of examples. In CONACQ the quality is either true or false, depending on if the example is a solution of the target constraint network or not. The examples and their\nevaluation are written in the Observations repository. World-to-ML simply reads the classified examples from Observations and gives them to the ML component. The hypotheses space H used by the ML component is defined by the language of constraints used to express the target network. When reading examples from Observations, the ML component updates \u2013if needed\u2013 the hypothesis h in the form of a set of constraints that correctly classify the examples. These learned constraints are written in the Patterns repository. Based on the learned constraints, the ML component generates other constraints that implement the followed query strategy (e.g., near-miss). These constraints together with the learned constraints are sent to the CP component via the ML-to-CP function. The CP component solves the network built with all the constraints provided by the ML component and generates new solutions that are stored in the Solutions repository. Apply-to-World sends the solutions from the repository to the world to be classified by the user/eval world function. In case the constraint network has no solution that can be provided to the world, the CP-to-ML function notifies the ML component that it was not able to generate a satisfactory query, possibly with some reasons of failure such as an inconsistent set of constraints. Figure 8 shows the loop solving this problem."}, {"heading": "5.5 Portfolio selection", "text": "An algorithm portfolio contains a number of algorithms or solvers which are all suitable for solving the same kind of problem, but have different performance characteristics. The aim is to, given a problem instance to solve, determine the best solver for that particular problem, where \u201cbest\u201d is defined according to an application-specific metric. Algorithm portfolios have been shown to achieve significant performance improvements over individual algorithms. One prominent application area of these techniques is constraint programming.\nWithin the inductive constraint programming loop, this problem can be modelled as a data mining problem that takes its data from runs of CP solvers.\nThe world consists of the performance data of CP solvers on CP instances. World-to-ML reads this performance information and the ML component learns a model that describes the predicted performance of CP solvers on CP instances and allows to determine the best CP solver for a particular CP instance. When a new CP instance to be solved appears in the world, World-to-ML and Worldto-CP read it. World-to-ML sends it to the ML component, which classifies it and writes the classification in the Patterns repository. World-to-CP sends the CP instance to be solved to the CP component. ML-to-CP reads in the Patterns repository the classification provided by the ML component to decide which solver to use. The selected solver then solves the instance and generates a new data point in the world through the Apply-to-World function. This new world can lead the ML component to update the predictive model, and so forth. Figure 9 shows the loop solving this problem."}, {"heading": "6 Conclusion", "text": "After a brief introduction to constraint programming and machine learning, we have introduced the framework of inductive constraint programming. The key idea in the inductive constraint programming loop is that the CP and ML components interact with each other and with the world in order to adapt the solutions to changes in the world. This is an essential need in problems that change under the effect of time, or problems that are influenced by the application of a previous solution. It is also very effective for problems that are only partially specified and where the ML component learns from observation of applying a partial solution, e.g. in the case of constraint acquisition. We have presented multiple examples of the use of inductive constraint programming loop in real world problem settings. Many other settings exist, and as more and more often learning methods are used for producing schedules and other operational plans, the need for a framework that can adapt to changes in the world will increase."}], "references": [{"title": "Query-driven constraint acquisition", "author": ["C. Bessiere", "R. Coletta", "B O\u2019Sullivan", "M. Paulin"], "venue": "In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence", "citeRegEx": "Bessiere et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bessiere et al\\.", "year": 2007}, {"title": "Minimising decision tree size as combinatorial optimisation", "author": ["C. Bessiere", "E. Hebrard", "B. O\u2019Sullivan"], "venue": "In Proceedings of the 15th International Conference on Principles and Practice of Constraint Programming (CP", "citeRegEx": "Bessiere et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bessiere et al\\.", "year": 2009}, {"title": "A sat-based approach for discovering frequent, closed and maximal patterns in a sequence", "author": ["E. Coquery", "S. Jabbour", "L. S\u00e4\u0131s", "Y. Salhi"], "venue": "In Proceedings of the 20th European Conference on Artificial Intelligence (ECAI", "citeRegEx": "Coquery et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Coquery et al\\.", "year": 2012}, {"title": "Constraint programming for itemset mining", "author": ["L. De Raedt", "T. Guns", "S. Nijssen"], "venue": "In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "Raedt et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Raedt et al\\.", "year": 2008}, {"title": "Collaborative learning for constraint solving", "author": ["Susan L. Epstein", "Eugene C. Freuder"], "venue": "In Proceedings of the 7th International Conference on Principles and Practice of Constraint Programming (CP", "citeRegEx": "Epstein and Freuder.,? \\Q2001\\E", "shortCiteRegEx": "Epstein and Freuder.", "year": 2001}, {"title": "Constraint programming for mining n-ary patterns", "author": ["M. Khiari", "P. Boizumault", "B. Cr\u00e9milleux"], "venue": "In Proceedings of the 16th International Conference on Principles and Practice of Constraint Programming (CP", "citeRegEx": "Khiari et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Khiari et al\\.", "year": 2010}, {"title": "A minizinc tutorial", "author": ["K. Marriott", "P.J. Stuckey"], "venue": "http://www.minizinc.org/downloads/doc-latest/minizinc-tute.pdf,", "citeRegEx": "Marriott and Stuckey.,? \\Q2014\\E", "shortCiteRegEx": "Marriott and Stuckey.", "year": 2014}, {"title": "Machine learning with operational costs", "author": ["Theja Tulabandhula", "Cynthia Rudin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Tulabandhula and Rudin.,? \\Q2013\\E", "shortCiteRegEx": "Tulabandhula and Rudin.", "year": 2013}, {"title": "Satzilla: Portfolio-based algorithm selection for SAT", "author": ["Lin Xu", "Frank Hutter", "Holger H. Hoos", "Kevin Leyton-Brown"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "Xu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2008}], "referenceMentions": [], "year": 2015, "abstractText": "Constraint programming is used for a variety of real-world optimisation problems, such as planning, scheduling and resource allocation problems. At the same time, one continuously gathers vast amounts of data about these problems. Current constraint programming software does not exploit such data to update schedules, resources and plans. We propose a new framework, that we call the Inductive Constraint Programming loop. In this approach data is gathered and analyzed systematically, in order to dynamically revise and adapt constraints and optimization criteria. Inductive Constraint Programming aims at bridging the gap between the areas of data mining and machine learning on the one hand, and constraint programming on the other hand.", "creator": "LaTeX with hyperref package"}}}