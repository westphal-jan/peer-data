{"id": "1512.01568", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Dec-2015", "title": "Hybrid Approach for Inductive Semi Supervised Learning using Label Propagation and Support Vector Machine", "abstract": "Semi supervised learning methods have gained importance in today's world because of large expenses and time involved in labeling the unlabeled data by human experts. The proposed hybrid approach uses SVM and Label Propagation to label the unlabeled data. In the process, at each step SVM is trained to minimize the error and thus improve the prediction quality. Experiments are conducted by using SVM and logistic regression(Logreg). Results prove that SVM performs tremendously better than Logreg. The approach is tested using 12 datasets of different sizes ranging from the order of 1000s to the order of 10000s. Results show that the proposed approach outperforms Label Propagation by a large margin with F-measure of almost twice on average. The parallel version of the proposed approach is also designed and implemented, the analysis shows that the training time decreases significantly when parallel version is used.", "histories": [["v1", "Wed, 2 Dec 2015 12:04:30 GMT  (404kb,D)", "http://arxiv.org/abs/1512.01568v1", "Presented in the 11th International Conference, MLDM, Germany, July 20 - 21, 2015. Springer, Machine Learning and Data Mining in Pattern Recognition, LNAI Vol. 9166, p. 199-213, 2015"]], "COMMENTS": "Presented in the 11th International Conference, MLDM, Germany, July 20 - 21, 2015. Springer, Machine Learning and Data Mining in Pattern Recognition, LNAI Vol. 9166, p. 199-213, 2015", "reviews": [], "SUBJECTS": "cs.LG cs.DC", "authors": ["aruna govada", "pravin joshi", "sahil mittal", "sanjay k sahay"], "accepted": false, "id": "1512.01568"}, "pdf": {"name": "1512.01568.pdf", "metadata": {"source": "CRF", "title": "Hybrid Approach for Inductive Semi Supervised Learning using Label Propagation and Support Vector Machine", "authors": ["Aruna Govada", "Pravin Joshi", "Sahil Mittal", "Sanjay K Sahay"], "emails": [], "sections": [{"heading": null, "text": "Keywords: Semi-Supervised Learning, Data Mining, Support Vector Machine, Label Propagation"}, {"heading": "1 Introduction", "text": "Semi supervised learning methods are mainly classified into two broad classes: Inductive and Transductive. In both Inductive and transductive the learner has both labeled training data set (xi, yi)i=1...l \u223c p(x, y) and unlabeled training data set (xi)i=l+1...l+u p(x), where l u. The inductive learner learns a predictor f : X \u2192 Y , f \u2208 F where F is the hypothesis space, x \u2208 X is an input instance, y \u2208 Y its class label. The predictor learns in such a way that it predicts the future test data better than the predictor learned from the labeled data alone. In transductive learning, it is expected to predict the unlabeled data (xi)i=l+1...l+u without any expectations of generalizing the model to future test data. Gaussian processes, transductive SVM and graph-based methods fall in the latter category. On the other hand, the former models are based on joint distribution and examples include Expectation Maximization. In many real world scenarios, it is easy to collect a large amount of unlabeled data {x}. For example, the catalogue of celestial objects can be obtained from sky surveys, Geo spatial data can be received from satellites, the documents can be browsed through the web. ar X iv :1 51 2.\n01 56\n8v 1\n[ cs\n.L G\n] 2\nD ec\n2 01\n5\nHowever, their corresponding labels {y} for the prediction, such as classification of the galaxies, prediction of the climate conditions, categories of documents often requires expensive laboratory experiments, human expertise and a lot of time. This labeling obstruction results in an insufficiency in labeled data with an excess of unlabeled data left over. Utilizing this unlabeled data along with the limited labeled data in constructing the generalized predictive models is desirable. Semi supervised learning model can either be built by first training the model on unlabeled data and using labeled data to induce class labels or vice versa. The proposed inductive approach labels the unlabeled data using a hybrid model which involves both Label Propagation and SVM. At every step in the process, it fits the model to minimize error and thus improve the prediction quality. The rest of the paper is organized as follows. The related work is discussed in section 2.Label propagation, SVM are discussed in section 3 and the proposed approach is presented in section 4. Section 5 contains the experimental results and comparison of the proposed approach with the Label Propagation algorithm followed by Conclusion and future work in section 6."}, {"heading": "2 Related Work", "text": "A decent amount of work has been done in the field of semi-supervised learning in which major role has been played by the unlabeled data which is in huge amount as compared to the labeled data.Castelli et al.[1],[2] and Ratsaby et al.[3] showed that unlabeled data can predict better if the model assumption is correct. But if the model assumption is wrong, unlabeled data may actually hurt accuracy.Cozman et al.[4] provide theoretical analysis of deterioration in performance with an increase in unlabeled data and argue that bias is adversely affected in such situations. Another technique that can be used to get the model correct is to down weight the unlabeled data by Corduneanu et al.[5].CallisonBurch et al [6] used the down-weighing scheme to estimate word alignment for machine translation.\nA lot of algorithms have been designed to make use of abundant unlabeled data. Nigam et al.[7] apply the Expectation Maximization[8] algorithm on mixture of multinomial for the task of text classification and showed that the resulting classifiers predict better than classifier trained only on labeled data.\nClustering has also been employed over the years to make use of unlabeled data along with the labeled data.The dataset is clustered and then each cluster is labeled with the help of labeled data.Demiriz et al.[9] and Dara et al.[10] used this cluster and label approach successfully to increase prediction performance.\nA commonly used technique for semi-supervised learning is self-training. In this, a classifier is initially trained with the small quantity of labeled data. The classifier is then used to classify the unlabeled data and unlabeled points which are classified with most confidence are added to the training set. The classifier is re-trained and the procedure is repeated. Word sense disambiguation is successfully achieved by Yarowsky et al.[11] using self-training. Subjective nouns are identified by Riloff et.al[12]. Parsing and machine translation is also done with\nthe help of self-training methods as shown by Rosenberg et al.[13] in detection of object systems from images.\nA method which sits apart from all already mentioned methods in the field of semi supervised learning is Co-training. Co-training [14] assumes that (i) features can be split into two sets; (ii) Each sub-feature set is sufficient to train a good classifier; (iii) the two sets are conditionally independent given the class. Balcan et al.[15] show that co-training can be quite effective and that in the extreme case only one labeled point is needed to learn the classifier.\nA very effective way to combine labeled data with unlabeled data is described by Xiaojin Zhu et al.[16] which propagated labels from labeled data points to unlabeled ones. An approach based on a linear neighborhood model is discussed by Fei Wang et al.[17] which can propagate the labels from the labeled points to the whole data set using these linear neighborhoods with sufficient smoothness. Graph based method is proposed in [18] wherein vertices represent the labeled and unlabeled records and edge weights denote similarity between them. Their extensive work involves using the label propagation to label the unlabeled data, role of active learning in choosing labeled data, using hyper parameter learning to learn good graphs and handling scalability using harmonic mixtures."}, {"heading": "3 Label Propagation", "text": "Let (x1, y1)......(xl, yl) be labeled data, where (x1.......xl) are the instances, Y = (y1.....yl) \u2208 (1....C) are the corresponding class labels. Let (xl+1, yl+1).....(xl+u, yl+u) be unlabeled data where YU = (yl+1.....yu) are unobserved. YU has to be estimated using X and YL, where X = (x1......xl........xl+u)\nF : L \u222a U \u2212\u2192 R wij is similarity between i and j, where i, j \u2208 X F should minimize the energy function\n(f) = 1\n2 \u2211 i,j wij(f(i)\u2212 f(j))2 = fT 4 f\nand fi, Fj should be similar for a high wij . Label propagation assumes that the number of class labels are known, and all classes present in the labeled data."}, {"heading": "3.1 Support Vector Machine", "text": "The learning task in binary SVM can be represented as the following\nminw = \u2016 w \u20162\n2\nsubject to yi(w.xi+b) \u2265 1, i = 1, 2, ....N where w and b are the parameters of the model for total N number of instances.\nUsing Legrange multiplier method the following equation to be solved,\nLp = \u2016 w \u20162\n2 \u2212 \u2211 i=1...N \u03bbi(yi(w.xi + b)\u2212 1), \u03bbi\nare called legrange multipliers. By solving the following partial derivatives, we will be able to derive the decision boundary of the SVM.\n\u2202p \u2202w = 0 \u2264 w \u21d2 \u2211 i=1....N \u03bbiyixi = 0\n\u2202p \u2202b = 0 \u2264 w \u21d2 \u2211 i=1....N \u03bbiyi = 0"}, {"heading": "4 Proposed Approach", "text": "The proposed Algorithm is an inductive semi supervised learning, an iterative approach in which at each iteration the following steps are executed. In the first step label propagation is run on the training data and the probability matrix is computed for the unlabeled data. The second step is to train the SVM on the available labeled data. Now in the third step, the classes for unlabeled data are predicted using SVM and class probabilities computed in step 1 are compared with the threshold. In step 4, all the records for which both label propagation and SVM agree on the class label, are labeled with corresponding class.This continues till all the records are labeled or no new records are labeled in an iteration. One-one multi class SVM is used as the data consists of multi classes.\nThe records of each of the data sets are shuffled, 70% is considered for training and the rest is considered for testing. 80% of the training data is unlabeled.\nThe algorithm is implemented in both the serial and parallel versions."}, {"heading": "4.1 Serial Version", "text": "Input: Classifier, Threshold Output: F-measure\n1. (labeled records, unlabeled records) = select next train folds() # Each fold of data is split into labeled and unlabeled records with 20:80 ratio # unlabeled records have their class field set to -1 2. test records = select next test fold() # Concatenate labeled and unlabeled records to get train records 3. train records = labeled records + unlabeled records 4. newly labeled = 0 5. while len(labeled records) < len (train records):\n5.1 lp probability matrix = run lp(labeled records + unlabeled records) 5.2 model = fit classifier(classifier, labeled records) 5.3 labeled atleast one = False\n5.4 for record in unlabeled records: i. classifier out = model.predict class(record.feature vector)\n# Test for LP and classifier agreement ii. if lp probability matrix[record.feature vector][classifier out]\u2265 thresh-\nold: a. unlabeled records.remove(record) b. record.class label = classifier out #label the record c. labeled records.add(record) #add the newly labeled record to set\nof labeled records d. newly added += 1\n# Set labeled atleast one flag to True if at least one new record is labeled in current iteration of while loop e. labeled atleast one = True # Break the loop if no new record is labeled in current iteration of while loop\n5.5 if labeled atleast one == False: 5.5.1 break\n# Compute F-measure of constructed model 6. test records features = test records.get feature vectors() 7. test records labels = test records.get labels() 8. predicted labels = model.predict(test records features) 9. f-measure = compute fmeasure(predicted labels, test records labels)"}, {"heading": "4.2 Parallel Version", "text": "Input: Classifier, Threshold, No of tasks #Number of parallel processes Output: F-measure\n1. newly labeled = 0 2. while len(labeled records) < len(train records):\n2.1 lp train records = labeled records + unlabeled records 2.2 lp probability matrix = []; classifier out = [] 2.3 lp process = new process(target = run lp, args = (lp train records, lp probability matrix)) 2.4 lp process.start() 2.5 classifier process = new process(target = fit classifier, args = (classifier,\nlabeled records, unlabeled records, classifier all out)) 2.6 classifier process.start() 2.7 lp process.join() 2.8 classifier process.join() 2.9 atleast one labeled = False\n2.10 chunk size = len(unlabeled records) / No of tasks 2.11 all pids = [] 2.12 None initialize(labeled lists, No of tasks) 2.13 None initialize(unlabeled copies, No of tasks) 2.14 for i in range(len(labeled lists)):\ni. start = i * chunk size\nii. end = (i+1) * chunk size iii. unlabeled copies = unlabeled records[start : end] iv. lp probabilities = lp probability matrix[start : end] v. classifier outs = classifier all outs[start : end] vi. label records process = new process(func = label data, args = (unlabeled copies[i], labeled lists[i], lp probabilities, classifier outs, threshold))\nvii. label records process.start() viii. all pids.append(label records process)\n2.15 unlabeled records = [] 2.16 done processes = [] 2.17 while len(done pids) < len(all pids):\ni. for i in range(len(all pids)): . if not all pids[i].is alive() and (i not in done pids): a. done processes.append(i) b. unlabeled records += unlabeled copies[i] c. labeled records += labeled lists[i]\n2.18 if atleast one labeled == False: 2.18.1 break\n# Compute F-measure of constructed model 3. predicted labels = [ ] 4. test records features = test records.get feature vectors() 5. test records labels = test records.get labels() 6. run parallel classifier(predicted labels, labeled records, test records features,\nclassifier, no of tasks) 7. f-measure = compute fmeasure(predicted labels, test records labels)"}, {"heading": "5 Experimental Section", "text": "In our experimental analysis, we considered 12 different datasets. The datasets along with their number of attributes (excluding the class label) and number of instances are as follows (in the formatdataset : (no of attributes, no of records )): Vowel: (10, 528), Letter: (16, 10500) , Segment: (18, 2310), Iris scale random: (4, 149), Satimage: (36, 1331), 10000 SDSS : (7, 10000), 1000 SDSS : (7, 1000), Glass scale random : (9, 214), Letter 1 : (16, 4500), Mfeat : (214, 2000), Pendigits : (16, 7494) and Shuttle : (9, 12770). In our experimental analysis, the following comparisons are made.\n1.Serial version of our hybrid approach with Zhu et.al[16]. 2.Serial version of our hybrid approach with supervised learning classifier SVM. 3.Parallelization of our algorithm with our own serial implementation. Before performing the above comparisons,the serial version of our hybrid approach is examined on the following aspects. The algorithm is run for different values of threshold of the probability matrix of label propagation and percentage of initially labeled data in each of the training data set. We observed the values\nof percentage of increase in labeled records for each iteration, percentage of labeled data at the final iteration and finally the training time and F-measure.An alternative classifier Logreg is also implemented and its performance is compared with SVM based on factors like F-measure and training time.\nAs it can be seen from Fig 1, varying the threshold of the probability matrix of label propagation has little impact on the F-measure. Considering only label propagation increase in threshold would lead to stricter labeling resulting in increase in precision and decrease in recall. Similarly, the decrease in probability threshold results in an increase in number of unlabeled records being considered for labeling. Hence, it should increase the labeling rate of the records. But when SVM is used with label propagation precision and recall are not allowed to vary significantly because a record can be labeled only when SVM and Label Propagation agree on the class label. So, unlabeled records marked by label propagation for labeling with low confidence are discarded by output of SVM. Thus the percentage of labeled data at the end of the final iteration fluctuates very little for all the thresholds (as it is shown in next graph Fig 2). So change in thresholds, has little effect on F-measure of the model.\nTo see the effect of the dimension and the number of records in the dataset, In Fig 3, we plotted Training time with respect to the cube of number of records in the dataset for the best performing classifier and threshold. The axis were chosen by keeping in mind the O (dim*N3) complexities of both SVM and Logreg. The graph tends to show polynomial increase in training time as N increases (instead of linear). This may be the effect of neglecting lower order terms in the complexity expression of SVM and Logreg.\nThe analysis of Fig 1 and Fig 2 explains the following feature of the algorithm. For the datasets: 1000 records Sloan Digital Sky survey (SDSS), 10000 records SDSS, Mfeat, Pendigits and Shuttle,Percentage of labeled data is very low 0- 20%. But F-measures are reasonably high between 0.67 to 0.9. This shows that their high F-measure does not always require high amount of unlabeled data to\nbe labeled. As long as the algorithm is able to label representative records in the dataset, it is likely to give good F-measure.\nWe observed the percentage of increase in labeled records for every iteration for the best choice of classifier and threshold (according to F-measure). In Fig 4, it shows that percentage of increase in labeled records decreases exponentially (note the log scale) as the iterations progress. This means not much data gets labeled as loop progresses. This is the consequence of Label propagation and SVM not agreeing on deciding the class label which is to be assigned to the unlabeled record. While labeling an unlabeled record, there is a low chance of misclassification by SVM , since it is always trained on labeled data. This means that the quality of labeling done by Label propagation decreases significantly as the iterations progresses. This deterioration in Label Propagations quality has very little effect on algorithms overall prediction quality because of the right predictions done by SVM at every step while labeling the unlabeled records leading to better performance than Label propagation.\nThe performance of the proposed approach is compared with the label propagation algorithm[16] for all the datasets and shown in Fig 5. F-measures of\nthe proposed approach were noted for best choice of classifier and threshold. For label propagation, all the unlabeled records were labeled according to the class corresponding to highest label propagation Probability. In all the cases, the proposed approach outperforms label propagation by a large margin. This high quality of performance can be attributed use of SVM together with Label Propagation to label the unlabeled examples. No unlabeled example is labeled without the agreement of both SVM and label propagation. This significantly reduces the pitfalls caused by label propagation increasing the prediction quality of overall approach.\nThe analysis of our approach(semi supervised learning) with the supervised SVM is also studied. Results in Fig 6 show that the F-measure of our approach is comparable.\nFig 7 to 12 are plotted for different percentages of initially unlabeled data for the data sets Vowel, Irisscalerandom, Satimage, 1000-SDSS, Glassscalrandom, Mfeat respectively considering best choice of Threshold (as per the F-measure). As can be seen, F-measure of the model tends to fall as percentage of initially unlabeled data increases. This is intuitive. As the amount of labeled data in the initial data increases, the algorithm is able to learn the pattern present in a representative sample of the dataset. Thus it can successfully generalize the pattern to the test set leading to a overall increase in F-measure.\nFinally, The parallel version of the proposed approach is also implemented. As the results can be seen from Fig 13, parallelizing the algorithm helps to improve training time of the algorithm. Two of the most expensive steps in the algorithm are training SVM and label propagation on the data. Doing these two in parallel reduces training time significantly (note that training time is in log scale).\nThe analysis is done for SDSS dataset for samples of different sizes.The results are shown in Fig 14. For each sample, we ran different number of parallel tasks and training time is observed. Results show that number of parallel tasks\nhave reasonable effect on training time only when dataset size exceeds a certain threshold (around 60000 records in this case). Further, for each dataset, there is an optimum number of parallel tasks which yields minimum training time. If number of parallel tasks is above this optimum level, the cost of maintaining these parallel tasks exceeds the gain earned by parallel computation. On the other hand, if number of parallel tasks is set to a value less than optimum level, system resources are poorly utilized. So it is necessary to set number of parallel tasks to optimum value for maximum benefit.\nThe proposed approach is tested on skewed datasets also. The proportion of class labels in the skewed dataset is at least 1:8. F-measure of 10000-SDSS drops by approximately 0.1 when it has skewed class proportions. But skewed version of Shuttle shows exceptional behavior. Its F-measure remains almost the same. This shows that skewness of the data has little or no effect on F-measure of algorithm. It can be inferred that the distribution of the data plays a major role in performance of semi-supervised algorithm. The results are shown in Fig 15."}, {"heading": "6 Conclusion and Future work", "text": "The proposed approach uses SVM along with Label Propagation algorithm to yield a very high overall prediction quality. It can use a small amount of labeled data along with a large quantity of unlabeled data to yield a high F-measure on test data. It has a very small margin for error since it labels the unlabeled data using consent of both - SVM and Label Propagation. On testing both the algorithms on 12 different datasets we can conclude that the proposed approach performs much better than label propagation[16] alone. It yields F-measure values which are almost twice as compared to Label Propagation. Further, we designed the parallel version of the approach and were able to decrease the training time significantly. In future, the parallel algorithm can be further enhanced to yield linear or super linear scale up. Further research on the role of supervised algorithms in the field of semi supervised learning could be beneficial.\nAcknowledgments. We are thankful for the support provided by the Department of Computer Science and Informations Systems, BITS, Pilani, K.K. Birla Goa Campus to carry out the experimental analysis."}], "references": [{"title": "The exponential value of labeled samples", "author": ["V. Castelli", "T. Cover"], "venue": "Pattern Recognition Letters,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1995}, {"title": "The relative value of labeled and unlabeled samples in pattern recognition with an unknown mixing parameter", "author": ["V. Castelli", "T. Cover"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1996}, {"title": "Learning from a mixture of labeled and unlabeled examples with parametric side information", "author": ["J. Ratsaby", "S. Venkatesh"], "venue": "Proceedings of the Eighth Annual Conference on Computational Learning", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1995}, {"title": "Semi-supervised learning of mixture models.", "author": ["Cozman", "Fabio Gagliardi", "Ira Cohen", "Marcelo Cesar Cirelo"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "Stable mixing of complete and incomplete information (Technical Report AIM-2001-030)", "author": ["A. Corduneanu", "T. Jaakkola"], "venue": "MIT AI Memo", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Statistical machine translation with word- and sentence-aligned parallel corpora", "author": ["C. Callison-Burch", "D. Talbot", "M. Osborne"], "venue": "Proceedings of the ACL", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Text classification from labeled and unlabeled documents using EM", "author": ["K. Nigam", "A.K. McCallum", "S. Thrun", "T. Mitchell"], "venue": "Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, Series B", "author": ["A. Dempster", "N. Laird", "D. Rubin"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1977}, {"title": "Semi-supervised support vector machines.Advances in Neural Information", "author": ["K. Bennett", "A. Demiriz"], "venue": "Processing Systems,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1999}, {"title": "Clsutering unlabeled data with SOMs improves classification of labeled real-world data", "author": ["R. Dara", "S. Kremer", "D. Stacey"], "venue": "Proceedings of the World Congress on Computational Intelligence (WCCI)", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}, {"title": "Unsupervised word sense disambiguation rivaling supervised methods", "author": ["D. Yarowsky"], "venue": "Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (pp. 189196)", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1995}, {"title": "Learning subjective nouns using extraction pattern bootstrapping", "author": ["E. Riloff", "J. Wiebe", "T. Wilson"], "venue": "Proceedings of the Seventh Conference on Natural Language Learning", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Semi-supervised self training of object detection models", "author": ["C. Rosenberg", "M. Hebert", "H. Schneiderman"], "venue": "Seventh IEEE Workshop on Applications of Computer Vision", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Combining labeled and unlabeled data with cotraining", "author": ["A. Blum", "T. Mitchell"], "venue": "COLT: Proceedings of the Workshop on Computational Learning Theory", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1998}, {"title": "An augmented pac model for semi-supervised learning", "author": ["Balcan", "M.-F", "A. Blum"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "Learning from labeled and unlabeled data with label propagation", "author": ["Xiaojin Zhu", "Zoubin Ghahramani"], "venue": "Technical Report CMU-CALD-02-107,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}, {"title": "Label Propagation Through Linear Neighborhoods 2008 http://machinelearning.wustl.edu/mlpapers/paper files/icml2006 WangZ06.pdf", "author": ["Fei Wang", "Changshui Zhang"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Semi-supervised learning with graphs. Diss.Carnegie Mellon University, Language Technologies Institute", "author": ["Xiaojin Zhu", "John Lafferty", "Ronald Rosenfeld"], "venue": "School of Computer Science,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}, {"title": "Support vector machines,", "author": ["M.A. Hearst", "S.T. Dumais", "E. Osman", "J. Platt", "B. Scholkopf"], "venue": "Intelligent Systems and their Applications,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}], "referenceMentions": [{"referenceID": 0, "context": "[1],[2] and Ratsaby et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[1],[2] and Ratsaby et al.", "startOffset": 4, "endOffset": 7}, {"referenceID": 2, "context": "[3] showed that unlabeled data can predict better if the model assumption is correct.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] provide theoretical analysis of deterioration in performance with an increase in unlabeled data and argue that bias is adversely affected in such situations.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5].", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "CallisonBurch et al [6] used the down-weighing scheme to estimate word alignment for machine translation.", "startOffset": 20, "endOffset": 23}, {"referenceID": 6, "context": "[7] apply the Expectation Maximization[8] algorithm on mixture of multinomial for the task of text classification and showed that the resulting classifiers predict better than classifier trained only on labeled data.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[7] apply the Expectation Maximization[8] algorithm on mixture of multinomial for the task of text classification and showed that the resulting classifiers predict better than classifier trained only on labeled data.", "startOffset": 38, "endOffset": 41}, {"referenceID": 8, "context": "[9] and Dara et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] used this cluster and label approach successfully to increase prediction performance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] using self-training.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "al[12].", "startOffset": 2, "endOffset": 6}, {"referenceID": 12, "context": "[13] in detection of object systems from images.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "Co-training [14] assumes that (i) features can be split into two sets; (ii) Each sub-feature set is sufficient to train a good classifier; (iii) the two sets are conditionally independent given the class.", "startOffset": 12, "endOffset": 16}, {"referenceID": 14, "context": "[15] show that co-training can be quite effective and that in the extreme case only one labeled point is needed to learn the classifier.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] which propagated labels from labeled data points to unlabeled ones.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] which can propagate the labels from the labeled points to the whole data set using these linear neighborhoods with sufficient smoothness.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "Graph based method is proposed in [18] wherein vertices represent the labeled and unlabeled records and edge weights denote similarity between them.", "startOffset": 34, "endOffset": 38}, {"referenceID": 15, "context": "al[16].", "startOffset": 2, "endOffset": 6}, {"referenceID": 15, "context": "The performance of the proposed approach is compared with the label propagation algorithm[16] for all the datasets and shown in Fig 5.", "startOffset": 89, "endOffset": 93}, {"referenceID": 15, "context": "The comparison of the proposed approach with the label propagation[16].", "startOffset": 66, "endOffset": 70}, {"referenceID": 15, "context": "On testing both the algorithms on 12 different datasets we can conclude that the proposed approach performs much better than label propagation[16] alone.", "startOffset": 142, "endOffset": 146}], "year": 2015, "abstractText": "Semi supervised learning methods have gained importance in today\u2019s world because of large expenses and time involved in labeling the unlabeled data by human experts. The proposed hybrid approach uses SVM and Label Propagation to label the unlabeled data. In the process, at each step SVM is trained to minimize the error and thus improve the prediction quality. Experiments are conducted by using SVM and logistic regression(Logreg). Results prove that SVM performs tremendously better than Logreg. The approach is tested using 12 datasets of different sizes ranging from the order of 1000s to the order of 10000s. Results show that the proposed approach outperforms Label Propagation by a large margin with F-measure of almost twice on average. The parallel version of the proposed approach is also designed and implemented, the analysis shows that the training time decreases significantly when parallel version is used.", "creator": "LaTeX with hyperref package"}}}