{"id": "1512.02394", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Dec-2015", "title": "Online Gradient Descent in Function Space", "abstract": "In many problems in machine learning and operations research, we need to optimize a function whose input is a random variable or a probability density function, i.e. to solve optimization problems in an infinite dimensional space. On the other hand, online learning has the advantage of dealing with streaming examples, and better model a changing environ- ment. In this paper, we extend the celebrated online gradient descent algorithm to Hilbert spaces (function spaces), and analyze the convergence guarantee of the algorithm. Finally, we demonstrate that our algorithms can be useful in several important problems.", "histories": [["v1", "Tue, 8 Dec 2015 10:38:19 GMT  (13kb)", "http://arxiv.org/abs/1512.02394v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["changbo zhu", "huan xu"], "accepted": false, "id": "1512.02394"}, "pdf": {"name": "1512.02394.pdf", "metadata": {"source": "CRF", "title": "Online Gradient Descent in Function Space", "authors": ["Changbo Zhu", "Huan Xu"], "emails": ["mpexuh}@nus.edu.sg"], "sections": [{"heading": null, "text": "ar X\niv :1\n51 2.\n02 39\n4v 1\n[ cs\n.L G\n] 8\nD ec\n2 01"}, {"heading": "1 Introduction", "text": "Regret minimization is a general setting used in decision making and prediction. A merge of convex optimization and regret minimization leads to the online convex optimization problem [12]. Due to its simple setting and generality, online convex optimization has raised many attentions recently [12, 22]. Online convex optimization can be modeled as a game: at each time t, the online player chooses a point xt from K \u2282 Rn. Typically, we assume that K is nonempty, closed and convex. After committing to this choice xt, a convex cost function ft is revealed and the player incurs a cost ft(xt). Suppose this game has in total T rounds, we are interested in minimizing the regret \u2013 the gap between the actual cost and the cost of the best fixed decision in hindsight:\nRegret(T ) =\nT \u2211\nt=1\nft(xt)\u2212min x\u2208K\nT \u2211\nt=1\nft(x).\nZinkevich proposed the following algorithm called online gradient descent [25] for the above problem: play x1 \u2208 K arbitrarily and at round t play xt := PK(xt\u22121 \u2212\u2207f(xt\u22121)), where PK stands for projection into K. The regret of online gradient descent is shown upper bounded by O( \u221a T ). By assuming that all ft has second derivatives bounded below by a strictly positive number, Hazan et al [13] gave an algorithm which can achieve O(log(T )) regret bound. Subsequently, Hazan et al [14] provide an algorithm achieving rates inteplay between O( \u221a T ) and O(log(T )) without a priori knowledge of the lower bound on the second derivatives. In the above setup, the online player chooses a point in a finite dimensional Euclidean space at each step. However, in many cases, we need to make decisions over a set of functions or random variables. For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19]. In all these cases, we need to consider optimization problems in some infinite dimensional space. In this paper, we propose the online functional gradient algorithm which extends online gradient descent algorithm of Zinkevich [25] to a general Hilbert space (function space). We then establish the regret bound of the algorithm. Since sometimes exact projection to a convex closed set in infinite dimensional space may be hard compute, we also analyze the noisy version of the algorithm when the projection at each step is not accurate. Finally, we illustrate applications of\nour algorithms in online classifier selection, risk measure minimization and distributionally robust stochastic program. Notation: in this paper, we use H to denote a Hilbert space with inner product \u3008\u00b7, \u00b7\u3009H and induced norm \u2016x\u2016H = \u221a\n\u3008x, x\u3009 for any x \u2208 H. Also, let B = {x \u2208 H | \u2016x\u2016H \u2264 1} denote the clsoed ball of H and R denote the set of real numbers. Let (\u2126,\u03a3, \u00b5) be a measure space. For 1 \u2264 p < \u221e, the space Lp(\u2126,\u03a3, \u00b5) is the set of all \u00b5-measurable functions f : \u2126 \u2192 [\u2212\u221e,+\u221e] such that \u222b\n|f |p d\u00b5 < \u221e. For a random variable \u03be, we use small p to denote its probability density function and big P to denote its probability distribution. Further, for a sequence {\u01ebt}Tt=1 , we use \u01eb\u0304 to denote its average, i.e. \u01eb\u0304 =\n\u2211T t=1 \u01ebt/T ; and \u03a5\u0304 to denote the average of squares, i.e. \u03a5\u0304 = \u2211T t=1 \u01eb 2 t/T. Finally, we use\nP to denote the projection mapping and E to denote the expectation of a random variable."}, {"heading": "2 Motivating Examples", "text": "In this section, we provide some examples of problems which need either gradient descent or online gradient descent in the function space."}, {"heading": "2.1 Online Classifier Selection", "text": "Assuming that we can collect data points {(xt, yt)}Tt=1 from an unknown distribution P on X\u00d7Y, where X \u2286 Rn is the space of data points and Y \u2286 R is the space of labels. Then, we can learn a classifier f : X \u2192 Y, which can best predict the label of a data point by solving the following problem\nmin f\u2208C\n1\nT\nT \u2211\nt=1\nl(f(xt), yt), (1)\nwhere C is a predefined set of classifiers and l is the loss function. If f is linear, then (1) can be reduced to a standard minimization problem (like linear SVM) in Rn. A more interesting case is studied in [18], in which the authors considered C as the set of all linear combinations of finitely many base-classifiers and then apply the gradient descent algorithm in a suitable function space to solve the problem. Another example is the nonlinear SVM considered in [21, 7], which is solved by letting C be a certain Reproducing Kernel Hilbert Space (RKHS) and using the representer theorem [15] to convert the problem into an optimization problem in Rn. A natural extension of (1), which we consider in this paper, is its online version. That is, the data points are supplied sequentially, and the goal of learning is to minimize the following regret,\nRegret(T ) = 1\nT\nT \u2211\nt=1\nl(ft(xt), yt)\u2212min f\u2208C\n1\nT\nT \u2211\nt=1\nl(f(xt), yt), (2)\nwhere ft \u2208 C only depends on {x1, \u00b7 \u00b7 \u00b7 , xt\u22121, f1, \u00b7 \u00b7 \u00b7 , ft\u22121} . Notice that in this case, it is challenging to convert Problem (2) into a minimization problem over Rn even with the help of representer theorem, as the data now are supplied sequentially. Hence, it is desirable to develop an online gradient descent algorithm in some proper funtion space to solve Problem (2). We remark that the case when C is an entire Reproducing Kernel Hilbert Space is considered in [16], which is a significantly simpler case than the general setup we considered in this paper, as there is no projection involved."}, {"heading": "2.2 Risk Measure Minimization", "text": "Risk Measure is used to quantify and compare uncertain outcomes, which is a central concept in decision theory [1, 20]. In this subsection, let (\u2126,\u03a3, \u00b5) be a probability space, i.e., \u2126 is a set of outcomes, \u03c3-algebra \u03a3 is a collection of events and \u00b5(\u2126) = 1 is a probability measure. Then a real valued random variable X is a \u00b5-measurable function X : \u2126 \u2192 R, which represents an uncertain outcome. We shall focus on the space L2(\u2126,\u03a3, \u00b5), which contains all the random variables X such that \u222b |X |2 d\u00b5 < \u221e and is a Hilbert space with inner product defined as \u3008X,Y \u3009 = \u222b\nXY d\u00b5. By a risk measure \u03c1, we mean a function \u03c1 : L2(\u2126,\u03a3, \u00b5) \u2192 R, which assigns a real number to each\nrandom variable (uncertain outcome). Then, a general risk measure minimization problem can be formulated as following\nmin X\u2208C \u03c1(X), (3)\nwhere C is typically a subset of L2(\u2126,\u03a3, \u00b5). In practice, uncertain outcomes (random variables) often result from decisions (actions) in some uncertain systems [20]. Mathematically, this can be modeled by a function f : S \u2192 L2(\u2126,\u03a3, \u00b5), where S stands for the set of feasible decisions, and is a subset of some vector space V . Then, we have C = f(S) in this case. Problem (3) is generally hard even if we can convert it to an optimization problem in the Euclidean space. On the other hand, under some conditions, we can solve or estimate the true solution by directly doing gradient descent in space L2(\u2126,\u03a3, \u00b5)."}, {"heading": "2.3 Distributionally Robust Stochastic Program", "text": "Robust Optimization (RO) is a framework in decision making under uncertainty that has attracted fast growing attention. RO addresses decision problems in which the problem parameter is not specific but known to belong to an uncertainty set [4, 9, 24, 5]. Mathematically, robust optimization problem can be formulated as following\nmin x\u2208X max \u03be\u2208S f(x, \u03be), (4)\nwhere X \u2286 Rm is the feasible set of solutions, \u03be is the problem parameter and S \u2286 Rn is the unertainty set. If the uncertainty instead is probabilistic, and is governed by a probability distribution P , which itself is uncertain and belongs to a set of distributions P , we get the following Distributionally Robust Stochastic Program (DRSP) aka Distributionally Robust Optimization [8, 10, 23],\nmin x\u2208X\n(\nmax P\u2208P EP [f(x, \u03be)]\n)\n, (5)\nwhere X \u2286 Rn and P is the uncertainty set consists of possible distributions of the parameter. Problem (5) is usually harder than Problem (4), because the maximization part is over a subset of some infinite dimensional space. In literature, DRSP is typically solved by exploiting special structures of the uncertainty set P and convert the problem to an optimization problem over Euclidean space. However, this is not always possible. In this paper, we propose a novel solution approach which depends on online gradient descent algorithm in function space. We briefly describe the idea here and defer the full analysis to Section 4.3: At each step t, if a distribution Pt \u2208 P is given, then we solve a xt which approximately minimizes the function g(x, Pt) = EPt [f(x, \u03be)]. By performing online gradient desent with respect to P , we can upper bound the term maxP g(x\u0304, P ) by \u2211T\nt=1 g(xt, Pt)/T + \u03b4, where x\u0304 = ( \u2211T\nt=1 xt)/T and \u03b4 is small. Since, each g(xt, Pt) is small by the construction of xt, we conclude that maxP g(x\u0304, P ) is also small."}, {"heading": "3 Online Functional Gradient Descent", "text": "In this section, we present the online functional gradient descent algorithm and its variants. All proofs are postponed to the supplementary material. We also provide a brief overview of relevant background knowledge from functional analysis in the supplementary material for the completeness. Before presenting our results, we first describe the assumptions on the set, from which the online player make decisions.\nAssumption 1. K \u2286 H is nonempty, closed, convex and K \u2286 RB for some R \u2208 R.\nAlso, we make some assumptions on the cost functions received by the player.\nAssumption 2. f : K \u2192 R is convex, Ga\u0302teaux differentiable over K and all the Ga\u0302teaux gradients {\u2207f(x) |x \u2208 K} have finite norm, i.e. \u2016\u2207f(x)\u2016H < +\u221e for all x \u2208 K.\nLemma 1. Let C \u2286 H be a nonempty closed convex subset, then for all x \u2208 H and x\u0302 \u2208 C, we have\n\u2016PC(x) \u2212 x\u0302\u2016H \u2264 \u2016x\u2212 x\u0302\u2016H.\nProof. By Theorem 3.14 in [2], we have\n\u3008x\u0302\u2212PC(x), x \u2212PC(x)\u3009H \u2264 0,\nwhich further implies that\n\u2016PC(x)\u2212 x\u0302\u20162H + \u2016x\u2212PC(x)\u20162H \u2264 \u2016x\u2212 x\u0302\u20162H.\nThroughout this section, let x\u2217 \u2208 K be the optimal solution of \u2211Tt=1 ft : K \u2192 R or f : K \u2192 R over K, then the online functional gradient descent algorithm proceeds as follows: pick x1 \u2208 K arbitrarily and for t = 2, \u00b7 \u00b7 \u00b7 , T , choose xt as xt = PK (xt\u22121 \u2212 \u03b7\u2207ft\u22121 (xt\u22121)). Then, we have the following theorem upper bounds the regret.\nTheorem 1. [Online Functional Gradient Descent] Suppose K satisfies Assumption 1 and let f1, f2, \u00b7 \u00b7 \u00b7 , fT : K \u2192 R be an arbitrary sequence of functions that satisfy Assumption 2. Pick x1 \u2208 K arbitrarily and let x2, \u00b7 \u00b7 \u00b7 , xT be defined by xt+1 = PK (xt \u2212 \u03b7\u2207ft (xt)) . Let G = maxt \u2016\u2207ft(xt)\u2016H and select \u03b7 = R/G \u221a T , we have\nT \u2211\nt=1\nft(xt)\u2212 T \u2211\nt=1\nft(x \u2217) \u2264 RG \u221a T .\nProof. Since each ft is convex, Ga\u0302teaux differentiable over K, by Theorem 7.3.6 in [17], there exists a x\u2217 in K minimizing \u2211Tt=1 ft(x). Since ft is convex, by Proposition 17.10 in [2], we have\nft(xt)\u2212 ft(x\u2217) \u2264 \u3008\u2207ft(xt), xt \u2212 x\u2217\u3009H . (6)\nSince K is nonempty, convex and closed, by Lemma 1, we have for all x \u2208 H, \u2016PK(x) \u2212 x\u2217\u2016H \u2264 \u2016x\u2212 x\u2217\u2016H. So,\n\u2016xt+1 \u2212 x\u2217\u20162H = \u2016PK (xt \u2212 \u03b7\u2207ft(xt))\u2212 x\u2217\u20162H \u2264 \u2016xt \u2212 \u03b7\u2207ft(xt)\u2212 x\u2217\u20162H = \u2016xt \u2212 x\u2217\u20162H + \u03b72\u2016\u2207ft(xt)\u20162H \u2212 2\u03b7 \u3008\u2207ft(xt), xt \u2212 x\u2217\u3009H \u2264 \u2016xt \u2212 x\u2217\u20162H + \u03b72G2 \u2212 2\u03b7 \u3008\u2207ft(xt), xt \u2212 x\u2217\u3009H .\nAfter rearranging terms, we have\n\u3008\u2207ft(xt), xt \u2212 x\u2217\u3009H \u2264 \u2016xt \u2212 x\u2217\u20162H \u2212 \u2016xt+1 \u2212 x\u2217\u20162H + \u03b72G2\n2\u03b7 .\nCombining with equation (6) and summing over t, we have\nT \u2211\nt=1\nft(xt)\u2212 T \u2211\nt=1\nft(x \u2217) \u2264 R\n2\n2\u03b7 + T\n\u03b7G2\n2\n\u2264 RG \u221a T .\nIf we only consider a single function, i.e. all the ft are the same, then the online functional gradient descent reduces to functional gradient descent, with its performance characterized by the following corollary. The idea of gradient descent and variants in function space has appeared before [18, 19, 16], but all these works consider the unconstrained case only, i.e., K = H, and hence is a significantly easier case as no projection is involved.\nCorollary 1 (Functional Gradient Descent). Suppose K satisfies Assumption 1 and f : K \u2192 R satisfies Assumption 2. Pick x1 \u2208 K arbitrarily and let x2, \u00b7 \u00b7 \u00b7 , xT be defined by xt+1 = PK (xt \u2212 \u03b7\u2207f (xt)) . Let G = maxt \u2016\u2207f(xt)\u2016H and select \u03b7 = R/G \u221a T , we have\nf\n(\n1\nT\nT \u2211\nt=1\nxt\n)\n\u2212 f(x\u2217) \u2264 RG\u221a T .\nProof. Follows from the convexity of f and Theorem 1.\nIn some cases, the projection PK in general Hilbert space is not easy to calculate exactly. Hence we develop the following results with respect to noisy projection, which shows the online gradient algorithm achieves comparable guarantees if only approximated projection is used at each step.\nTheorem 2 (Online Functional Gradient Descent with Noisy Projection). Suppose K satisfies Assumption 1 and f1, f2, \u00b7 \u00b7 \u00b7 , fT : K \u2192 R be an arbitrary sequence of functions that satisfy Assumption 2. Pick x1 \u2208 K arbitrarily and let x2, \u00b7 \u00b7 \u00b7 , xT be calculated such that \u2016xt+1 \u2212 PK (xt \u2212 \u03b7\u2207ft (xt)) \u2016H \u2264 \u01ebt. Let G = maxt \u2016\u2207ft(xt)\u2016H and select \u03b7 = \u221a\nR2/T + 4R\u01eb\u0304+ \u03a5\u0304/G, we have\nT \u2211\nt=1\nft(xt)\u2212 T \u2211\nt=1\nft(x \u2217) \u2264 RG \u221a T + ( 2 \u221a R\u01eb\u0304+ \u221a \u03a5\u0304 ) GT. (7)\nProof. Since each ft is convex, Ga\u0302teaux differentiable over K, by Theorem 7.3.6 in [17], there exists a x\u2217 in K minimizing \u2211Tt=1 ft(x). Since ft is convex, by Proposition 17.10 in [2], we have ft(xt)\u2212 ft(x\u2217) \u2264 \u3008\u2207ft(xt), xt \u2212 x\u2217\u3009H . (8) Since K is nonempty, convex and closed, by Lemma 1, we have for all x \u2208 H, \u2016PK(x) \u2212 x\u2217\u2016H \u2264 \u2016x\u2212 x\u2217\u2016H. So,\n\u2016xt+1 \u2212 x\u2217\u20162H \u2264 (\u2016xt+1 \u2212PK(xt \u2212 \u03b7\u2207ft(xt))\u2016H + \u2016PK(xt \u2212 \u03b7\u2207ft(xt))\u2212 x\u2217\u2016H)2\n\u2264 \u2016xt \u2212 \u03b7\u2207ft(xt)\u2212 x\u2217\u20162H + 4R\u01ebt + \u01eb2t = \u2016xt \u2212 x\u2217\u20162H + \u03b72\u2016\u2207ft(xt)\u20162H \u2212 2\u03b7 \u3008\u2207ft(xt), xt \u2212 x\u2217\u3009H + 4R\u01ebt + \u01eb2t \u2264 \u2016xt \u2212 x\u2217\u20162H + \u03b72G2 \u2212 2\u03b7 \u3008\u2207ft(xt), xt \u2212 x\u2217\u3009H + 4R\u01ebt + \u01eb2t .\nAfter rearranging terms, we have\n\u3008\u2207ft(xt), xt \u2212 x\u2217\u3009H \u2264 \u2016xt \u2212 x\u2217\u20162H \u2212 \u2016xt+1 \u2212 x\u2217\u20162H + \u03b72G2 + 4R\u01ebt + \u01eb2t\n2\u03b7 .\nCombining with equation (8) and summing over t, we have\nT \u2211\nt=1\nft(xt)\u2212 T \u2211\nt=1\nft(x \u2217) \u2264 R\n2 + \u2211T t=1(4R\u01ebt + \u01eb 2 t )\n2\u03b7 + T\n\u03b7G2\n2\n= G\n\u221a \u221a \u221a\n\u221aR2T + T \u2211\nt=1\n(4R\u01ebt + \u01eb2t ) T\n\u2264 RG \u221a T + ( 2 \u221a R\u01eb\u0304+ \u221a \u03a5\u0304 ) GT.\nSimilarly, when all the functions {ft} are the same, we have the following result: Corollary 2. [Functional Gradient Descent with Noisy Projection] Suppose K satisfies Assumption 1 and f : K \u2192 R satisfies Assumption 2. Pick x1 \u2208 K arbitrarily and let x2, \u00b7 \u00b7 \u00b7 , xT be calculated such that \u2016xt+1 \u2212 PK (xt \u2212 \u03b7\u2207f (xt)) \u2016H \u2264 \u01ebt. Let G = maxt \u2016\u2207f(xt)\u2016H and select \u03b7 = \u221a R2/T + 4R\u01eb\u0304+ \u03a5\u0304/G, we have\nf\n(\n1\nT\nT \u2211\nt=1\nxt\n)\n\u2212 f(x\u2217) \u2264 RG\u221a T + (\n2 \u221a R\u01eb\u0304+ \u221a \u03a5\u0304 ) G.\nProof. Follows from the convexity of f and Theorem 2.\nWe remark that the Ga\u0302teaux differentiability used in previous results is to guarantee that the optimal solution x\u2217 exists in C. We can relax this assumption and use subgradient instead, which leads to the following results:\nAssumption 3. f : K \u2192 R is convex, subdifferentiable function over K and all the subgradients {ux |x \u2208 K and ux \u2208 \u2202f(x)} have finite norm, i.e. \u2016ux\u2016H < +\u221e for all x \u2208 K and ux \u2208 \u2202f(x).\nCorollary 3. Suppose K satisfies Assumption 1 and f1, f2, \u00b7 \u00b7 \u00b7 , fT : K \u2192 R be an arbitrary sequence of functions that satisfy Assumption 3. Pick x1 \u2208 K arbitrarily and let x2, \u00b7 \u00b7 \u00b7 , xT be calculated such that \u2016xt+1 \u2212PK (xt \u2212 \u03b7ut) \u2016H \u2264 \u01ebt, where ut \u2208 \u2202ft(xt). Let G = maxt \u2016ut\u2016H and select \u03b7 = \u221a R2/T + 4R\u01eb\u0304+ \u03a5\u0304/G, we have\nT \u2211\nt=1\nft(xt)\u2212 T \u2211\nt=1\nft(x) \u2264 RG \u221a T + ( 2 \u221a R\u01eb\u0304+ \u221a \u03a5\u0304 ) GT, for all x \u2208 K.\nProof. By the definition of subgradient, it holds that\nft(xt)\u2212 ft(x) \u2264 \u3008ut, xt \u2212 x\u3009H for all x \u2208 H and ut \u2208 \u2202ft(xt). (9)\nThen, replace equation (8) with (9) and change \u2207ft(xt) to ut in the rest proof of Theorem 2, we can prove the result.\nCorollary 4. Suppose K satisfies Assumption 1 and f : K \u2192 R satisfies Assumption 3. Pick x1 \u2208 K arbitrarily and let x2, \u00b7 \u00b7 \u00b7 , xT be calculated such that \u2016xt+1 \u2212PK (xt \u2212 \u03b7ut) \u2016H \u2264 \u01ebt, where ut \u2208 \u2202f(xt). Let G = maxt \u2016ut\u2016H and select \u03b7 = \u221a R2/T + 4R\u01eb\u0304+ \u03a5\u0304/G, we have\nf\n(\n1\nT\nT \u2211\nt=1\nxt\n)\n\u2212 f(x) \u2264 RG\u221a T + (\n2 \u221a R\u01eb\u0304+ \u221a \u03a5\u0304 ) G, for all x \u2208 K.\nProof. Follows from the convexity of f and Corollary 2."}, {"heading": "3.1 Calculate the Projection", "text": "Here, we introduce some exact formulas to calculate projections onto some common sets and refer Chapter 28 in [2] for a comprehensive study of the projection operator in Hilbert space. The following two examples show that it is easy to project a point onto a closed ball or a hyperplane.\nExample 1. Let B \u2286 H be the closed ball with radius 1, then\n\u2200x \u2208 H PB(x) = 1\nmax {\u2016x\u2016H, 1} x.\nExample 2. Let u \u2208 H be a nonzero vector, let \u03b7 \u2208 R and set C = {x \u2208 H| \u3008x, u\u3009H = \u03b7}, then we have\n\u2200x \u2208 H PC(x) = x+ \u03b7\u2212\u3008x,u\u3009H\u2016u\u20162 H u.\nSometimes, a function f \u2208 L2(\u2126,\u03a3, \u00b5) is required to have nonnegative values (e.g., density functions), in which case we have the following formula:\nExample 3. Set C = { p \u2208 L2(\u2126,\u03a3, \u00b5) | p \u2265 0 } , then for any q \u2208 L2(\u2126,\u03a3, \u00b5), the projection PC(q) is given by\nPC(q) = [q]+ , where for all x \u2208 \u2126, [q]+ (x) = { q(x) if q(x) \u2265 0, 0 if q(x) < 0.\nThe following algorithm explains how to project a point onto the intersection of multiple sets, if calculating the projection onto each set is easy.\nTheorem 3 (Dykstra\u2019s Algorithm). Let m be a strictly positive integer, set I = {1, \u00b7 \u00b7 \u00b7 ,m}, let (Ci)i\u2208I be a family of closed convex subsets of H such that C = \u2229i\u2208ICi 6= \u2205, and let x0 \u2208 H. Set\ni : N \u2192 I as i(n) = 1 + rem(n\u2212 1,m),\nwhere rem(\u00b7,m) is the remainder function of the division by m. For every strictly positive integer n, set Pn = PCn , where Cn = Ci(n) if n > m. Moreover, set q\u2212(m\u22121) = \u00b7 \u00b7 \u00b7 = q\u22121 = q0 = 0 and\n(\u2200n \u2208 N {0} ) {\nxn = Pn(xn\u22121 + qn\u2212m), qn = xn\u22121 + qn\u2212m \u2212 xn.\nThen xn \u2192 PC(x0)."}, {"heading": "4 Applications", "text": "In this section, we discuss some concrete examples to illustrate how to apply the developed framework. In particular, how to compute the corresponding derivatives and the projections. For each particular application, a suitable Hilbert space is chosen."}, {"heading": "4.1 Online Classifier Selection", "text": "The online classifier selection problem is described above in Section 2.1. Here, let H be a Reproducing Kernel Hilbert Space of real valued functions defined on X \u2286 Rn and associated with a reproducing kernel k : X\u00d7 X \u2192 R. We consider the problem of minimizing the following regret:\nRegret(T ) = 1\nT\nT \u2211\nt=1\nlt (ft)\u2212min f\u2208C\n1\nT\nT \u2211\nt=1\nlt (f) , (10)\nwhere {lt} and C are defined by \n \n \nlt(f) = (f(xt)\u2212 yt)2 , C = (\n\u22c2m i=1 C\u0302i\n)\n\u2229RB, where B is the closed ball of H, Given gi \u2208 H, ai \u2208 R, we have C\u0302i = {f \u2208 H| \u3008f, gi\u3009H = ai} .\nEach C\u0302i corresponds to a linear constraint imposed on f . For instance, suppose we want to guarantee that f(x1) = 1 (e.g., (x1, 1) is a sample of high-confidence), we can add the linear constraint \u3008k(\u00b7, x1), f\u3009H = 1. For the above problem, we can apply the online functional gradient descent algorithm, in which projection and gradient are calculated as follows: Gradient: we first calculate the gradient of lt for t = 1, \u00b7 \u00b7 \u00b7 , T\nfor any h \u2208 H, \u2207lt(f)(h) = lim \u03b1\u21930 lt(f + \u03b1h)\u2212 lt(f) \u03b1\n= lim \u03b1\u21930 (f(xt) + \u03b1h(xt)\u2212 yt)2 \u2212 (f(xt)\u2212 yt)2 \u03b1 =2 (f(xt)\u2212 yt)h(xt), = \u30082 (f(xt)\u2212 yt) k(\u00b7, xt), h\u3009H (reproducing property).\nBy Remark 2.44 in [2], we have \u2207lt(f) = 2 (f(xt)\u2212 yt) k(\u00b7, xt). Projection: for any g \u2208 H, we calculate the projection PC(g) onto C. Firstly, we can use Example 2 to calculate the projection PC\u0302i(g) onto each C\u0302i and Example 1 to calculate the projection PRB(g) onto RB. Then, we can calculate the projection onto the intersection of C\u0302i and RB, i.e. onto C, using Theorem 3."}, {"heading": "4.2 Risk Measure Minimization", "text": "The risk measure minimization problem is introduced in Section 2.2. Here, we consider the following mean variance risk measure minimization problem as a concrete example:\nmin X\u2208C\nE(X) + c\u2016X \u2212E(X)\u20162L2(\u2126,\u03a3,\u00b5),\nwhere c \u2265 0 is a given constant and C is defined as \n\n\nC = (\n\u22c2m i=1 C\u0302i\n)\n\u2229RB, where B is the closed ball of L2(\u2126,\u03a3, \u00b5), Given Yi \u2208 L2(\u2126,\u03a3, \u00b5), ai \u2208 R, we have C\u0302i = { X \u2208 L2(\u2126,\u03a3, \u00b5) \u2223 \u2223 \u3008X,Yi\u3009L2(\u2126,\u03a3,\u00b5) = ai } .\nNotice that each C\u0302i is a linear constraint which stands for E(XYi) = ai. In particular, if Yi(x) \u2261 1 for all x \u2208 \u2126, then C\u0302i is the set of random variables whose mean is ai. Set \u03c1(X) = E(X) + c\u2016X \u2212 E(X)\u20162L2(\u2126,\u03a3,\u00b5), it is proved in [6] (Chapter4 page128) that \u03c1 is convex. Also, the derivative and projection can be calculated as following: Gradient: we first calculate the gradient of \u03c1 at X , for any Y \u2208 L2(\u2126,\u03a3, \u00b5),\n\u2207\u03c1(X)(Y ) = lim \u03b1\u21930 \u03c1(X + \u03b1Y )\u2212 \u03c1(X) \u03b1\n= lim \u03b1\u21930\n\u222b \u03b1Y d\u00b5+ c\u2016X + \u03b1Y \u2212 \u222b X + \u03b1Y d\u00b5\u20162L2(\u2126,\u03a3,\u00b5) \u2212 c\u2016X \u2212 \u222b X d\u00b5\u20162L2(\u2126,\u03a3,\u00b5) \u03b1\n=\n\u222b\nY d\u00b5+ 2c\n\u2329\nX \u2212 \u222b X d\u00b5, Y \u2212 \u222b Y d\u00b5\n\u232a\nL2(\u2126,\u03a3,\u00b5)\n= \u30081 + 2cX \u2212 2cE(X), Y \u3009L2(\u2126,\u03a3,\u00b5) .\nSo, we have \u2207\u03c1(X) = 1 + 2cX \u2212 2cE(X). Projection: for any Y \u2208 L2(\u2126,\u03a3, \u00b5), the projection onto each C\u0302i and RB can be calculated seperately by Example 2 and 1. Then, we can use Theorem 3 to calculate the projection onto C."}, {"heading": "4.3 Distributionally Robust Stochastic Program", "text": "Applying online functional gradient descent to solve Distributionally Robust Stochastic Program is more involved than the previous examples. Here, we consider a slightly different version of Problem (5), i.e., we focus on probability density functions instead of probability distributions. In particular, we consider the space L2(Rn) = L2 (Rn,\u03a3, \u00b5), where \u03a3 and \u00b5 are the \u03c3-algebra of Lebesgue measurable sets and the Lebesgue measure on Rn respectively. Then, L2(Rn) is a Hilbert space with inner product defined as \u3008f, g\u3009L2 = \u222b\nfg d\u00b5. Correspondingly, the induced norm on L2(Rn) is \u2016 \u00b7 \u2016L2 and we use BL2 to denote the closed ball of L2(Rn). Assuming that \u03be is a random variable with probability density function p \u2208 P , then the Distributionally Robust Stochastic Program can be written as\nmin x\u2208X\n(\nmax p\u2208P Ep [f(x, \u03be)]\n)\n, (11)\nwhere X \u2286 Rn and P \u2286 L2(Rn) is a set of probability density functions. The main idea to solve this problem is inspired by [3], in which they use online learning methods to solve (arguably easier) Robust Optimization. Optimization via Binary Search: We first convert the optimization problem into a decision problem. Suppose we know the feasible range of the objective value of maxp\u2208P Ep [f(x, \u03be)], Problem (11) can be solved by a binary search procedure in the following way: let b be our current guess of the optimal value and shift f downwards by b, i.e., h(x, \u03be) = f(x, \u03be) \u2212 b. Then, we solve the following decision problem, i.e., a YES or NO problem,\n\u2203?x \u2208 Rn such that Ep [h(x, \u03be)] \u2264 0 \u2200p \u2208 P . (12)\nAn answer YES means the true optimal value is smaller than b and NO means larger. Correspondingly, if the answer is YES (NO), we should make our new guess smaller (bigger). In the rest of the section we will focus on solving Problem (12). We say that x is a \u03b4-approximate solution to Problem (12) if Ep [h(x, \u03be)] \u2264 \u03b4 for all p \u2208 P . In the following, we will use online functional gradient descent with noisy projection to get a 2\u03b4-approximate solution to Problem (12). Oracle: notice that if we fix p \u2208 P , then Ep [h(x, \u03be)] is a function mapping from Rn to R. We assume this finite dimensional function is easy to optimize. In particular, we assume that there exists an Oracle O\u03b4 such that given any p \u2208 P , it either returns a x \u2208 X such that\nEp [h(x, \u03be)] \u2264 \u03b4,\nor return \u201cinfeasible\u201d if there does not exist a vector x \u2208 X such that\nEp [h(x, \u03be)] \u2264 0."}, {"heading": "4.3.1 Functional Dual Gradient Descent", "text": "Setting g(x, p) = Ep [h(x, \u03be)], we assume that g is convex in x (which is true when h(\u00b7, \u03be) is convex), P \u2286 RBL2 is convex and maxx,p \u2016\u2207pg(x, p)\u2016L2 \u2264 G. Then, we propose the following algorithm to solve Problem (12).\nAlgorithm 1: Functional Dual Gradient Descent with Noisy Projection\ninput : \u03b4,G Initialize p0 \u2208 P arbitrarily Choose T , {\u01ebt}Tt=1 such that RG\u221aT + ( 2 \u221a R\u01eb\u0304+ \u221a \u03a5\u0304 ) G \u2264 \u03b4 and set \u03b7 = \u221a R2/T + 4R\u01eb\u0304+ \u03a5\u0304/G for t = 1, 2, \u00b7 \u00b7 \u00b7 , T do Calculate pt such that pt \u2208 P and \u2016pt \u2212PP (pt\u22121 + \u03b7\u2207pg(xt\u22121, pt\u22121)) \u2016L2 \u2264 \u01ebt Set xt = O\u03b4(pt) if the Oracle declared infeasibility then\nreturn \u201cNO\u201d\nreturn x\u0304 = 1 T \u2211T t=1 xt\nTheorem 4. Algorithm 1 either returns an 2\u03b4-approximate solution or concludes that the answer is \u201cNo\u201d for Problem (12).\nProof. First, if the algorithm returns \u201cNO\u201d, then by the definition of the Oracle, for some t, there does not exists x \u2208 Rn such that Ept [h(x, \u03be)] \u2264 0, which means the answer to Problem (12) is \u201cNO\u201d. Second, otherwise, then a solution is returned, and the premise of the oracle implies that\n1\nT\nT \u2211\nt=1\ng(xt, pt) \u2264 \u03b4.\nFrom the regret guarantee of the online functional gradient descent algorithm we have\nmax p\u2208P\n1\nT\nT \u2211\nt=1\ng(xt, p)\u2212 1\nT\nT \u2211\nt=1\ng(xt, pt) \u2264 RG\u221a T + (\n2 \u221a R\u01eb\u0304+ \u221a \u03a5\u0304 ) G \u2264 \u03b4.\nWe conclude that\n\u03b4 \u2265 1 T\nT \u2211\nt=1\ng(xt, pt) \u2265 max p\u2208P\n1\nT\nT \u2211\nt=1\ng(xt, p)\u2212 \u03b4 \u2265 max p\u2208P g(x\u0304, p)\u2212 \u03b4.\nHence, we have g(x\u0304, p) \u2264 2\u03b4 for all p \u2208 P ."}, {"heading": "4.3.2 A Concrete Example", "text": "In this subsection, we consider the following simple example to illustrate how to solve DRSP via the framework outlined above:\nmin x\u2208B max p\u2208P\nEp [ (xT \u03be)2 ] , (13)\nwhere B \u2286 R2 is the closed ball ofR2, the random variable \u03be takes value fromC = { (x, y) |x2 + y2 \u2264 1, x \u2265 0, y \u2265 0 } and the uncertainty set P is defined as\nP = { p \u2208 L2(R2) \u2223 \u2223 Ep [\u03be] = b \u2208 R2, p \u2265 0, \u222b\nC p d\u00b5 = 1,\n\u222b\nC |p|2 d\u00b5 \u2264 2\n}\n.\nWe define the characteristic function \u03c7C by \u03c7C(x) = 1 if x \u2208 C and \u03c7C(x) = 0 otherwise. Further, set \u03be = (\u03be1, \u03be2) T and t = (t1, t2) T with ti(x) = xi for x \u2208 R2, i = 1, 2. Then, we can write P = P1 \u2229 P2 \u2229 P3 \u2229 P4 \u2229 P5, where {\nPi = { p \u2208 L2(R2) | Ep(\u03bei) = \u3008ti\u03c7C, p\u3009L2 = bi }\nfor i = 1, 2; P3 = { p \u2208 L2(R2) | p \u2265 0 } ,P4 = { p \u2208 L2(R2) |\u3008\u03c7C, p\u3009L2 = 1 } ,P5 = 2BL2.\nWe can solve Problem (13) using Algorithm 1, in which the gradient and projection can be calculated as following: Gradient: fix any x \u2208 R2 and set g(p) = Ep [ (xT \u03be)2 ] , we calculate \u2207g(p) with respect to p,\nfor any q \u2208 L2(R2), \u2207g(p)(q) = lim \u03b1\u21930 g(p+ \u03b1q)\u2212 g(p) \u03b1\n= lim \u03b1\u21930\n\u222b\n\u03c7C(x T t)2(p+ \u03b1q) d\u00b5\u2212\n\u222b\n\u03c7C(x T t)2p d\u00b5\n\u03b1\n= \u2329 \u03c7C(x T t)2, q \u232a .\nHence, we conclude \u2207g(p) = \u03c7C(xT t)2. Projection: for any q \u2208 L2(R2), the projection onto P3 and P5 can be calculated by Example 3 and Example 1 respectively. Also, the projection onto P1,P2 and P4 can be calculated by Example 2. Finally, we approximate the projection onto P by Dykstra\u2019s algorithm described in Theorem 3."}, {"heading": "5 Conclusion", "text": "In this work, we consider online learning in infinite dimensional space. In particular, we propose an online learning algorithm called online functional gradient descent, which extends the well known online gradient descent algorithm of Zinkevich [25]. We then provide theoretical results for the proposed algorithms. Finally, we illustrate how to apply our algorithm into practical problems in machine learning and operations research, including online classifier selection, risk measure minimization and distributionally robust optimization."}], "references": [{"title": "Coherent measures of risk", "author": ["Philippe Artzner", "Freddy Delbaen", "Jean-Marc Eber", "David Heath"], "venue": "Mathematical finance,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1999}, {"title": "Convex analysis and monotone operator theory in Hilbert spaces", "author": ["Heinz H Bauschke", "Patrick L Combettes"], "venue": "Springer Science & Business Media,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Robust convex optimization", "author": ["Aharon Ben-Tal", "Arkadi Nemirovski"], "venue": "Mathematics of Operations Research,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1998}, {"title": "The price of robustness", "author": ["Dimitris Bertsimas", "Melvyn Sim"], "venue": "Operations research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Probabilistic and randomized methods for design under uncertainty", "author": ["Giuseppe Calafiore", "Fabrizio Dabbene"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Distributionally robust optimization under moment uncertainty with application to data-driven problems", "author": ["Erick Delage", "Yinyu Ye"], "venue": "Operations research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Robust solutions to least-square problems to uncertain data matrices", "author": ["L EI-Ghaoui", "H Lebret"], "venue": "Sima Journal on Matrix Analysis and Applications,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "Distributionally robust optimization and its tractable approximations", "author": ["Joel Goh", "Melvyn Sim"], "venue": "Operations research,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Optimization in the space of distribution functions and applications in the Bayes analysis", "author": ["Alexandr N Golodnikov", "Pavel S Knopov", "Panos M Pardalos", "Stanislav P Uryasev"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2000}, {"title": "The convex optimization approach to regret minimization. Optimization for machine learning, pages", "author": ["Elad Hazan"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["Elad Hazan", "Amit Agarwal", "Satyen Kale"], "venue": "Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Adaptive online gradient descent", "author": ["Elad Hazan", "Alexander Rakhlin", "Peter L Bartlett"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "A correspondence between bayesian estimation on stochastic processes and smoothing by splines", "author": ["George S Kimeldorf", "Grace Wahba"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1970}, {"title": "Online learning with kernels", "author": ["Jyrki Kivinen", "Alexander J Smola", "Robert C Williamson"], "venue": "Signal Processing, IEEE Transactions on,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}, {"title": "Convex functional analysis", "author": ["Andrew J Kurdila", "Michael Zabarankin"], "venue": "Springer Science & Business Media,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Boosting algorithms as gradient descent in function space", "author": ["Llew Mason", "Jonathan Baxter", "Peter Bartlett", "Marcus Frean"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1999}, {"title": "Grafting: Fast, incremental feature selection by gradient descent in function space", "author": ["Simon Perkins", "Kevin Lacker", "James Theiler"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2003}, {"title": "Optimization of convex risk functions", "author": ["Andrzej Ruszczynski", "Alexander Shapiro"], "venue": "Mathematics of operations research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond", "author": ["Bernhard Scholkopf", "Alexander J. Smola"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2001}, {"title": "Online learning and online convex optimization", "author": ["Shai Shalev-Shwartz"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "A distributional interpretation of robust optimization", "author": ["Huan Xu", "Constantine Caramanis", "Shie Mannor"], "venue": "Mathematics of Operations Research,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Robustness and generalization", "author": ["Huan Xu", "Shie Mannor"], "venue": "Machine learning,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["Martin Zinkevich"], "venue": "In Proceedings of the Twentieth International Conference on Machine Learning,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2003}], "referenceMentions": [{"referenceID": 9, "context": "A merge of convex optimization and regret minimization leads to the online convex optimization problem [12].", "startOffset": 103, "endOffset": 107}, {"referenceID": 9, "context": "Due to its simple setting and generality, online convex optimization has raised many attentions recently [12, 22].", "startOffset": 105, "endOffset": 113}, {"referenceID": 19, "context": "Due to its simple setting and generality, online convex optimization has raised many attentions recently [12, 22].", "startOffset": 105, "endOffset": 113}, {"referenceID": 22, "context": "Zinkevich proposed the following algorithm called online gradient descent [25] for the above problem: play x1 \u2208 K arbitrarily and at round t play xt := PK(xt\u22121 \u2212\u2207f(xt\u22121)), where PK stands for projection into K.", "startOffset": 74, "endOffset": 78}, {"referenceID": 10, "context": "By assuming that all ft has second derivatives bounded below by a strictly positive number, Hazan et al [13] gave an algorithm which can achieve O(log(T )) regret bound.", "startOffset": 104, "endOffset": 108}, {"referenceID": 11, "context": "Subsequently, Hazan et al [14] provide an algorithm achieving rates inteplay between O( \u221a T ) and O(log(T )) without a priori knowledge of the lower bound on the second derivatives.", "startOffset": 26, "endOffset": 30}, {"referenceID": 4, "context": "For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19].", "startOffset": 84, "endOffset": 87}, {"referenceID": 8, "context": "For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19].", "startOffset": 161, "endOffset": 165}, {"referenceID": 13, "context": "For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19].", "startOffset": 216, "endOffset": 228}, {"referenceID": 15, "context": "For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19].", "startOffset": 216, "endOffset": 228}, {"referenceID": 16, "context": "For example, minimizing a risk measure over a set of random variables (chapter 4 in [6]), solving an optimization problem in the space of distribution functions [11] and learning a classifier over a set of functions [16, 18, 19].", "startOffset": 216, "endOffset": 228}, {"referenceID": 22, "context": "In this paper, we propose the online functional gradient algorithm which extends online gradient descent algorithm of Zinkevich [25] to a general Hilbert space (function space).", "startOffset": 128, "endOffset": 132}, {"referenceID": 15, "context": "A more interesting case is studied in [18], in which the authors considered C as the set of all linear combinations of finitely many base-classifiers and then apply the gradient descent algorithm in a suitable function space to solve the problem.", "startOffset": 38, "endOffset": 42}, {"referenceID": 18, "context": "Another example is the nonlinear SVM considered in [21, 7], which is solved by letting C be a certain Reproducing Kernel Hilbert Space (RKHS) and using the representer theorem [15] to convert the problem into an optimization problem in R.", "startOffset": 51, "endOffset": 58}, {"referenceID": 12, "context": "Another example is the nonlinear SVM considered in [21, 7], which is solved by letting C be a certain Reproducing Kernel Hilbert Space (RKHS) and using the representer theorem [15] to convert the problem into an optimization problem in R.", "startOffset": 176, "endOffset": 180}, {"referenceID": 13, "context": "We remark that the case when C is an entire Reproducing Kernel Hilbert Space is considered in [16], which is a significantly simpler case than the general setup we considered in this paper, as there is no projection involved.", "startOffset": 94, "endOffset": 98}, {"referenceID": 0, "context": "2 Risk Measure Minimization Risk Measure is used to quantify and compare uncertain outcomes, which is a central concept in decision theory [1, 20].", "startOffset": 139, "endOffset": 146}, {"referenceID": 17, "context": "2 Risk Measure Minimization Risk Measure is used to quantify and compare uncertain outcomes, which is a central concept in decision theory [1, 20].", "startOffset": 139, "endOffset": 146}, {"referenceID": 17, "context": "In practice, uncertain outcomes (random variables) often result from decisions (actions) in some uncertain systems [20].", "startOffset": 115, "endOffset": 119}, {"referenceID": 2, "context": "RO addresses decision problems in which the problem parameter is not specific but known to belong to an uncertainty set [4, 9, 24, 5].", "startOffset": 120, "endOffset": 133}, {"referenceID": 6, "context": "RO addresses decision problems in which the problem parameter is not specific but known to belong to an uncertainty set [4, 9, 24, 5].", "startOffset": 120, "endOffset": 133}, {"referenceID": 21, "context": "RO addresses decision problems in which the problem parameter is not specific but known to belong to an uncertainty set [4, 9, 24, 5].", "startOffset": 120, "endOffset": 133}, {"referenceID": 3, "context": "RO addresses decision problems in which the problem parameter is not specific but known to belong to an uncertainty set [4, 9, 24, 5].", "startOffset": 120, "endOffset": 133}, {"referenceID": 5, "context": "If the uncertainty instead is probabilistic, and is governed by a probability distribution P , which itself is uncertain and belongs to a set of distributions P , we get the following Distributionally Robust Stochastic Program (DRSP) aka Distributionally Robust Optimization [8, 10, 23], min x\u2208X (", "startOffset": 275, "endOffset": 286}, {"referenceID": 7, "context": "If the uncertainty instead is probabilistic, and is governed by a probability distribution P , which itself is uncertain and belongs to a set of distributions P , we get the following Distributionally Robust Stochastic Program (DRSP) aka Distributionally Robust Optimization [8, 10, 23], min x\u2208X (", "startOffset": 275, "endOffset": 286}, {"referenceID": 20, "context": "If the uncertainty instead is probabilistic, and is governed by a probability distribution P , which itself is uncertain and belongs to a set of distributions P , we get the following Distributionally Robust Stochastic Program (DRSP) aka Distributionally Robust Optimization [8, 10, 23], min x\u2208X (", "startOffset": 275, "endOffset": 286}, {"referenceID": 1, "context": "14 in [2], we have \u3008x\u0302\u2212PC(x), x \u2212PC(x)\u3009H \u2264 0, which further implies that \u2016PC(x)\u2212 x\u0302\u2016H + \u2016x\u2212PC(x)\u2016H \u2264 \u2016x\u2212 x\u0302\u2016H.", "startOffset": 6, "endOffset": 9}, {"referenceID": 14, "context": "6 in [17], there exists a x\u2217 in K minimizing \u2211Tt=1 ft(x).", "startOffset": 5, "endOffset": 9}, {"referenceID": 1, "context": "10 in [2], we have ft(xt)\u2212 ft(x) \u2264 \u3008\u2207ft(xt), xt \u2212 x\u3009H .", "startOffset": 6, "endOffset": 9}, {"referenceID": 15, "context": "The idea of gradient descent and variants in function space has appeared before [18, 19, 16], but all these works consider the unconstrained case only, i.", "startOffset": 80, "endOffset": 92}, {"referenceID": 16, "context": "The idea of gradient descent and variants in function space has appeared before [18, 19, 16], but all these works consider the unconstrained case only, i.", "startOffset": 80, "endOffset": 92}, {"referenceID": 13, "context": "The idea of gradient descent and variants in function space has appeared before [18, 19, 16], but all these works consider the unconstrained case only, i.", "startOffset": 80, "endOffset": 92}, {"referenceID": 14, "context": "6 in [17], there exists a x\u2217 in K minimizing \u2211Tt=1 ft(x).", "startOffset": 5, "endOffset": 9}, {"referenceID": 1, "context": "10 in [2], we have ft(xt)\u2212 ft(x) \u2264 \u3008\u2207ft(xt), xt \u2212 x\u3009H .", "startOffset": 6, "endOffset": 9}, {"referenceID": 1, "context": "1 Calculate the Projection Here, we introduce some exact formulas to calculate projections onto some common sets and refer Chapter 28 in [2] for a comprehensive study of the projection operator in Hilbert space.", "startOffset": 137, "endOffset": 140}, {"referenceID": 1, "context": "44 in [2], we have \u2207lt(f) = 2 (f(xt)\u2212 yt) k(\u00b7, xt).", "startOffset": 6, "endOffset": 9}, {"referenceID": 4, "context": "Set \u03c1(X) = E(X) + c\u2016X \u2212 E(X)\u2016L2(\u03a9,\u03a3,\u03bc), it is proved in [6] (Chapter4 page128) that \u03c1 is convex.", "startOffset": 56, "endOffset": 59}, {"referenceID": 22, "context": "In particular, we propose an online learning algorithm called online functional gradient descent, which extends the well known online gradient descent algorithm of Zinkevich [25].", "startOffset": 174, "endOffset": 178}], "year": 2016, "abstractText": "In many problems in machine learning and operations research, we need to optimize a function whose input is a random variable or a probability density function, i.e. to solve optimization problems in an infinite dimensional space. On the other hand, online learning has the advantage of dealing with streaming examples, and better model a changing environment. In this paper, we extend the celebrated online gradient descent algorithm to Hilbert spaces (function spaces), and analyze the convergence guarantee of the algorithm. Finally, we demonstrate that our algorithms can be useful in several important problems.", "creator": "LaTeX with hyperref package"}}}