{"id": "1602.00309", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Jan-2016", "title": "Bandits meet Computer Architecture: Designing a Smartly-allocated Cache", "abstract": "In many embedded systems, such as imaging sys- tems, the system has a single designated purpose, and same threads are executed repeatedly. Profiling thread behavior, allows the system to allocate each thread its resources in a way that improves overall system performance. We study an online resource al- locationproblem,wherearesourcemanagersimulta- neously allocates resources (exploration), learns the impact on the different consumers (learning) and im- proves allocation towards optimal performance (ex- ploitation). We build on the rich framework of multi- armed bandits and present online and offline algo- rithms. Through extensive experiments with both synthetic data and real-world cache allocation to threads we show the merits and properties of our al- gorithms", "histories": [["v1", "Sun, 31 Jan 2016 19:53:49 GMT  (215kb,D)", "http://arxiv.org/abs/1602.00309v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yonatan glassner", "koby crammer"], "accepted": false, "id": "1602.00309"}, "pdf": {"name": "1602.00309.pdf", "metadata": {"source": "CRF", "title": "Bandits meet Computer Architecture: Designing a Smartly-allocated Cache", "authors": ["Yonatan Glassner", "Koby Crammer"], "emails": ["yglasner@tx.technion.ac.il,", "koby@ee.technion.ac.il"], "sections": [{"heading": null, "text": "In many embedded systems, such as imaging systems, the system has a single designated purpose, and same threads are executed repeatedly. Profiling thread behavior, allows the system to allocate each thread its resources in a way that improves overall system performance. We study an online resource allocation problem, where a resource manager simultaneously allocates resources (exploration), learns the impact on the different consumers (learning) and improves allocation towards optimal performance (exploitation). We build on the rich framework of multiarmed bandits and present online and offline algorithms. Through extensive experiments with both synthetic data and real-world cache allocation to threads we show the merits and properties of our algorithms."}, {"heading": "1 Introduction", "text": "Consider a real-time X-ray system used for surgery. Such a system performs extensive real time image processing of a stream of images, and is required not to have delays, nor loose frames. In practice such a system executes many threads (such as FFT on various parts of the image) on a few cores and a shared cache, which allows fast access to memory. Since the amount of cache is limited, there is a need to allocate\ncache to the threads in a way to maximize hit-rate, namely the fraction of memory calls get answered by the (fast) cache, and not the (slow) memory. An effective allocation would take into consideration the various requirements of the threads and their behavior when memory lacks. However, the exact nature of this behavior is unknown, and should be learned from experience. The repeatability of such systems provides opportunity for good threads identification (hit rate as function of given resources), which allows the resource allocator to approach optimal allocations.\nThe problem of making decisions under uncertainty, or partial knowledge, was studied extensively in the literature, and a popular model for this problem is the Multi-Armed Bandit (MAB) [1]. In our setting, on each iteration the decision maker must choose an allocation of the available resources (memory) for the threads to be executed, corresponding to the \u2019arms\u2019 in the MAB model. Subsequently, all threads are executed (arm is pulled), and a stochastic hit rate (reward) is observed for each thread. A suitable framework for our setting is the combinatorial bandits (aka CMAB) framework, under full information feedback settings.\nA typical relation between the memory allocated to a thread and its hit-rate is presented in Fig. 1 (we present the hit-rate vs the amount of memory allocated for two applications: gcc and bzip, which are\nar X\niv :1\n60 2.\n00 30\n9v 1\n[ cs\n.L G\n] 3\n1 Ja\npart of the CPU SPEC 2006 benchmark). This relation is stochastic, and, its mean is characterized by two important properties: it is monotonic in the allocated memory, and exhibits a \u2019diminishing returns\u2019 phenomena. Note that the memory\u2013expected hit-rate relation is clearly non-linear, thus discouraging the use of linear bandits based approaches.\nMany existing approaches for this problem are static and hard-coded into hardware (see Liu et al. [2]). Moreover, they ignore the specific characteristics of the threads. Instead, we propose to learn the statistical nature of threads, and use it to make a good dynamic allocation. We study the empirical properties of a benchmark applications. We suggest a parametric model with the same qualitative properties as the real data. The model parameters are estimated during run-time. However, allocations are made during the process, even if the estimates are only rough.\nThe rest of the paper is organized as follows: in Sec. 2 we describe related work in the field of multi armed bandits. In addition, we briefly provide related work in the field of dynamic resource allocation in computer systems. In Sec. 3 we formulate our problem and the modeling function chosen with respect to the formulation. In Sec. 4 we introduce our algorithms together with their analysis of expected performance. Empirical study with both synthetic and real data is summarized in Sec. 5, and we conclude with Sec. 6. Due to lack of space, some Technical material and proofs are not provided in this paper."}, {"heading": "2 Related work", "text": "The MAB problem is widely studied these days, where different formulations model various exploration-exploitation (aka exp-exp) tradeoff alternatives. We clearly can not review all variants, and refer the reader to a recent manuscript in the area [3].\nLai and Robbins [1] proposed one of the earliest MAB version, in which there are N independent arms, each producing stochastic i.i.d rewards, taken from a known family of distributions, with unknown parameters. The objective is to choose arms sequentially, so as to maximize the total reward.\nIn their fundamental paper, Auer et al. [4] presented the UCB1 (upper confidence bound) algorithm. On each iteration, the algorithm chooses the arm with the highest UCB of the estimated expected value. Their key-method performs the explorationexploitation tradeoff implicitly. They prove that the number of time steps a sub-optimal arm is played is bounded, yielding logarithmic regret (performance difference of an algorithm and optimal policy) uniformly for all finite times.\nAnother line of research is when the algorithm may choose more than a single arm, and there is a dependency between the arms. See again the manuscript [3] for details and examples. The Combinatorial MAB (CMAB) is a special case of MAB. Here, arms (sometime also called super arms) are a combination of basic arms, chosen from a finite set F . Therefore, there is a structured dependency between super arms. Ignoring that structure and using traditional algorithms yields poor performance (see e.g. the work of Gai et al. [5]), compared to structureconsidered algorithm.\nIn a more recent paper, Chen et al. [6] proposed a general CMAB formulation. On each step, a super arm, which is a subset of arms, is chosen out of a finite subset group F \u2208 2[m], where 2[m] is the set of all possible subsets of arms, taken from m basic arms. The expected reward is a general function of the set of arms played and expected performance of all arms. In their algorithm, they assumed the existence of an Oracle, which provides a good super arm with high probability. In our specific problem, we do not assume such an oracle exists, thus can not use their framework directly. We rather provide a selfcontained algorithm, which senses the environment, provides predictions and acts.\nIn a more practical aspect, resource allocation was investigated in the field of computer architecture (see the work of Liu et al. [2] and of Suh et al. [7] for cache hit rate optimization, and of Bitirgen et al. [8] for global resources optimization using Artificial Neural Network). However, we are interested in providing a general framework for the resource allocation problem, rather than a fine-tuned per domain practical solution.\nRecently, Lattimore et al. [9] studied a similar resource allocation problem, where a system manager allocated resources to maximize system gain. However, they assume a piece-wise linear cut-off model, defined by a single parameter, which is the change point between the linear and constant range. We use a different model which we believe is closer to real world behavior. Specifically, we assume a nonlinear function, controlled by two parameters to model the consumer gain. Our more complicated model yields different algorithms with different behavior."}, {"heading": "3 Problem Setting", "text": "We now describe formally the memory to threads allocation problem. There are N threads (or arms) which share M identical units of memory. We will next assume, by a simple normalization, that all resources are summed to 1. On iteration t an allocation algorithm partitions the memory to the threads, allocating mt,i \u2208 [0, 1] fraction of the memory to thread i. We denote by ~mt = (mt,1 . . .mt,N ) the resource allocation vector, where clearly the algorithm can not allocate more than 100% of the resource nor allocate negative resources, thus \u2211 imt,i \u2264 1 and mt,i \u2265 0,\u2200t, i. Once the resources are allocated, or partitioned, each thread i receives a stochastic bounded reward st,i \u2208 [0, 1] based on these resources. We denote the reward vector by ~st = (st,1 . . . st,N ). We assume that the expectation of each reward is given by a function of the resource allocated, that is E [st,i] = fi(mt,i), where fi(x) is a fixed unknown (or partly unknown) function. In our application of allocating memory to threads, the algorithm reward is the hit-rate obtained for the specific allocation. We denote by ~f = (f1(\u00b7) . . . fN (\u00b7)), the vector of expected reward-functions, and by,\n\u03c1 ( ~f, ~m ) = N\u2211 i fi(mi) ,\nThe expected reward of allocation ~m with reward functions ~f . Given a set ofN functions ~f , an optimal allocation maximizes the expected reward and given by ~m\u2217 = argmax~m \u03c1 { ~f, ~m } subject to \u2211 imi \u2264\n1. The expected reward of the algorithm at time t is given by,\nE [ N\u2211 i=1 st,i ] = \u03c1 ( ~f, ~mt ) .\nSimilarly, the optimal expected reward is given by, \u03c1 ( ~f, ~m\u2217 ) . The expected instantaneous regret is defined to be the difference of rewards, R(t) = \u03c1 ( ~f, ~m\u2217 ) \u2212\u03c1 ( ~f, ~mt ) , and the cumulative expected regret is the sum of instantaneous regrets, R =\u2211T t=1R\n(t). The goal of a learning algorithm is to minimize the expected cumulative regret.\nIt remains to define a family of parametric reward functions F from which fi will be chosen. We restrict our discussion to families with two natural properties, which are inherent for the resource allocation model: Monotonicity: Allocating more memory does not decrease the expected reward, that is f(m1) \u2265 f(m2) for m1 \u2265 m2. Diminishing returns: Allocating more of memory does not increase the per-memory unit expected reward, that is, f(m1 + \u03b4) \u2212 f(m1) \u2265 f(m2 + \u03b4) \u2212 f(m2) for m1 \u2264 m2.\nThese two properties were also observed in our task of allocating memory. In Fig. 1, mentioned previously, we can clearly observe, that these two above properties hold for real applications.\nThe above observation motivated us to propose the following simple family of functions, with two parameters \u03b3i and \u03b2i,\nfi(mi; \u03b3i) = \u03b3i \u00b7m\u03b2ii\nwhere \u03b3i, \u03b2i \u2208 [0, 1]. The parameter \u03b3i indicates the maximal expected reward of thread i if all resources are allocated to it, as fi(1; \u03b3i) = \u03b3i, and thus is bounded by a unit, the maximal possible expected reward. \u03b2i is a curvature parameter and is bounded by a linear line. For \u03b2 \u2248 0 an infinitesimal amount of resource allows maximal gain, while for larger values of \u03b2 the hit-rate - memory dependency is closer to linear.\nFor a given ~\u03b2, we identify a concave function f(m) with the single associated parameter ~\u03b3. We\nabuse notation and write the expected instantaneous reward as, \u03c1 ( ~\u03b3, ~m; ~\u03b2 ) = \u2211N\ni \u03b3im \u03b2i i , which can be\ncomputed analytically if there is a shared parameter \u03b2 across all threads. We use that property in the convergence proof.\nWe use the fact that \u03c1 (~\u03b3, ~m) is a weighted \u03b2-norm of the allocation vector ~m to find the optimal allocation ~m\u2217 when the parameter vector ~\u03b3 is known.\nLemma 1. Assuming \u03b2i = \u03b2,\u2200i, the optimal allocation which maximizes the gain ~m\u2217 = argmax~m\u2032 \u03c1 (~\u03b3, ~m \u2032) is given by,\nm\u2217i = \u03b3\n1 1\u2212\u03b2 i\nN\u2211 j=1 \u03b3 1 1\u2212\u03b2 j , (1)\nand the expected reward is given by,\nmax ~m\u2032\n\u03c1 ( ~\u03b3, ~m\u2032 ) = \u03c1 (~\u03b3, ~m\u2217) = \u2016~\u03b3\u2016 1\n1\u2212\u03b2 . (2)\nFor brevity, the proof is not given here, but it can be easily derived by applying Ho\u0308lder inequality."}, {"heading": "4 Algorithms", "text": "A simple approach for solving our problem is to discrete the allocation space of ~m and treat each com-\nbination as an arm. We can now play with all arms using the existing MAB algorithms (i.e. UCB1 of Auer et al. [4]). However, such an approach ignores the structure of the problem and, since the actions are exponential in the number of threads, that approach is not feasible in practice. We propose two algorithms. The first algorithm performs an initial pure exploration stage, and then a pure exploitation stage. The second algorithm is a UCB-like algorithm, which fundamentally trades-off explorationexploitation. We analyze the algorithms in the shared \u03b2 case, while our experiments also done for the perthread \u03b2i parameters.\nWe start with the first algorithm. When the number of rounds T is known, the algorithm performs pure-exploitation for \u03be T rounds, allocating an equal amount of 1/N memory to all threads. At this point the algorithm computes estimation of the parameters \u03b3\u0302i. In the remaining rounds, the algorithm allocates mi(\u03b3\u03021 . . . \u03b3\u0302N ) using (1) as if the estimates are the optimal parameters. We call that algorithm FETE (First Explore Then Exploit) and it is summarized in Fig. 4.\nWe use the following linear estimator for \u03b3i from pairs {(mt,i, st,i)}Tt=1 (all parameters are subjected\nto thread i)\n\u03b3\u0302t = \u2211t \u03c4=1 \u03c9\u03c4 \u00b7 s\u03c4\u2211t \u03c4=1 \u03c9\u03c4 \u00b7m \u03b2 \u03c4 . (3)\nIt is easy to show that this general formulation of a linear estimator, given a set of coefficients \u03c9\u03c4,i\n\u03c4=1,\u00b7\u00b7\u00b7 ,t \u2208\nR, is unbiased:\nE [\u03b3\u0302t] = E [ \u2211t \u03c4=1 \u03c9\u03c4 \u00b7 s\u03c4\u2211t \u03c4=1 \u03c9\u03c4 \u00b7m \u03b2 \u03c4 ] = \u2211t \u03c4=1 \u03c9\u03c4,i \u00b7 \u03b3m \u03b2 \u03c4,i\u2211t \u03c4=1 \u03c9\u03c4,i \u00b7m \u03b2 \u03c4,i = \u03b3\nOne can show that the MMSE estimator is given by\n\u03b3\u0302t,i =\n\u2211t \u03c4=1m\n\u03b2 \u03c4,i \u00b7 s\u03c4,i\u2211t\n\u03c4=1m 2\u03b2 \u03c4,i\nIt is also concentrated around its mean, applying Hoeffding inequality [10]\nPr [|\u03b3\u0302t,i \u2212 \u03b3i| > ] \u2264 2 exp ( \u22122 2 \u00b7\nt\u2211 \u03c4=1 m2\u03b2\u03c4\n) .\n(4)\nAn interesting property of that concentration inequality is that the variance is monotonically decreasing in the amount of resources an arm receives. However, dependency is not linear. The algorithm must perform efficient exploration steps given this property.\nThe following theorem bounds the regret of the algorithm, by setting \u03be as a function of the number of rounds T .\nTheorem 1. Assuming \u03b2i = \u03b2,\u2200i, the regret of the algorithm in Fig. 4 is upper bounded by, R \u2264 \u03beTN+ \u221a 2N 1\u221a\n\u03be\n\u221a T \u221a log(2/\u03b4) . Furthermore, plug-\nging the optimal value, \u03beopt = 3 \u221a ln( 2\u03b4 ) 2T , yields, R \u2264 2NT 2 3 3 \u221a ln( 2\u03b4 )\n2 = O(T 2 3 ) .\nIn contrast to the FETE algorithm which separates the exploration and exploitation to distinct epochs, we now propose an alternative algorithm which inherently combines exp-exp, using the UCB technique.\nOur algorithmic approach for the second algorithm is inspired by the UCB1 algorithm of Auer et al. [4]. However, since each arm reward is a function of its given resources, we provide at each time t a Model Upper Confidence Bound (which is simply a UCB on the model parameters) which we obtain by the statistical model, and previous allocations and rewards. We then optimize the allocation according to the optimistic model, rather than the current estimated one.\nIn the general case, our algorithm estimates model parameters {\u03b3\u0302t,i} and computes optimal allocation with respect to UCB upon model variables. This ensures that all threads will receive enough memory to explore (estimate) well, and that the parameters estimators will converge quickly enough to their true values.\nWe call the algorithm UCB-RA for resource allocation, and it is summarized in Fig. 2. In each step, we provide a UCB et,i on the \u03b3t,i estimator. In the general case, we set et,i using (4). For the analysis, we again assume that \u03b2i is equal for all threads. For that case, we set et,i = et = t\u2212\u03b7 for \u03b7 = 0.5(1\u2212 \u03b2). This term is clearly not optimal, since at time t it has shared value for all threads, regardless of their performance so far. This choice of \u03b7 allows us to prove the following theorem, which is provided here without proof, for space limitation.\nTheorem 2. The regret of the algorithm of Fig. 2 is upper bounded by, O\u0303 ( F (N, \u03b2) + T 1+\u03b2 2 ) , where the\nfunction F is independent of T ."}, {"heading": "5 Experimental results", "text": "We evaluate our algorithms\u2019 performance on both synthetic and real data. Starting with the synthetic data, we generated data using that model: a thread produces a Bernoulli distributed binary stochastic reward, such that Pr (st,i = 1) = \u03b3im \u03b2i t,i.\nWe first assume shared \u03b2 and random values of ~\u03b3. We varied the number of threads - N . Once these parameters were set, we executed each algorithm for 10, 000 iterations, and computed reward and regret with respect to the optimal allocation (according to the value set for ~\u03b3 and \u03b2).\nNext, we ran our algorithms for known values of different \u03b2, one per process. Yet, since knowing the \u03b2\u2019s is a strong assumption, we assumed that the \u03b2\u2019s are known up to a small difference. This assumption is realistic, as we observed in real data that there are roughly two clusters of programs: memory-intensive and non-intensive. Memory-intensive programs have lower \u03b2\u2019s in contrast with the non-intensive ones. This clustering can be performed off-line, with respect to the program\u2019s characteristics. For the FETE algorithm we simply took the highest \u03b2 as a shared one.\nWe compare five algorithms: (1) Fair-Share, which is simply a uniform allocation, (2)+(3) tgreedy, which performs a random exploration step with probability t, or otherwise exploits. We compare two versions of t-greedy: the first uses the model in the exploitation step while the second uses the empiric best-so-far allocation. The parameter t decreases over time, and is given by: t = 0\u221at We tried different values of 0, and took the one with best performance. (4) The explore then exploit Fig. 4. (5)UCB-RA of Fig. 2. The methods of Liu et al. [2], Suh et al. [7], Bitirgen et al. [8] are not relevant to our settings, as the first is not designed to optimize the cumulative hit-rate, the second used a pre-defined model, and the third assumes the statistics are known (i.e., there is a separate training phase).\nExperiments are summarized in Fig. 3. The case of same \u03b2 is not a realistic case, and was simulated to support the theoretical analysis. One can clearly observe the \u201dknee\u201d of the FETE algorithm, which mark the exploration-exploitation transition point. The uniform and -greedy algorithm w\\o the model suffer a linear regret. In the case of different and partly-known \u03b2\u2019s (as explained previously), our UCB-RA algorithm obtain the best results (see Fig. 3(b)).\nWe performed extensive experiments to evaluate\nthe algorithms in a real-world setting. The task is to divide L1-cache among threads which are executed on the core.\nWe chose six programs belong to the SPECCPU2006 benchmark: bzip, lbm, mcf, waves and 2 gcc instances with different inputs. We executed each of the six programs and recorded all the memory accesses, both read and write. We then divided each memtrace to T distinct consecutive segments. We simulated each of these memtraces using a cache simulator, with 2K available 2-set cache, divided into blocks of size 16 bit.\nWe evaluate combinations of 2, 3 or 4 out of the 6 programs. For example, we started the execution of bzip and gcc at the same time, and so they needed to share memory.\nTwo metrics are used: the hit-rate, which is the frequency of memory accesses that were stored in the cache, and instructions per cycle (IPC). Specifically, we computed the memory dependent IPC (and not the total IPC, which depends on many parameters). For simplicity, we replaced the different cache hierarchy timings and probabilities with one term: Memorytime, and used the following equation to compute the IPC:\n(IPCmem) \u22121 = MR\u00d7Memorytime + (1\u2212MR)\u00d7 Cachetime ,\nwhere MR is the average miss-rate of a program, Memorytime and Cachetime are the time (in cycles) needed for a memory access and cache access. The former is about 20 times the latter.\nPerformance for 2, 3 and 4 program combinations is summarized in Fig. 5. Each point in the graph represents a specific combination of applications to be executed. The x-axis is an index of a specific combination. The y-axis is the IPC normalized by IPCopt (1 is the maximal value). The optimal allocation was computed by an exhaustive search in the optional allocations space.\nFor each algorithm, higher points indicate better performance. In the left panel we choose 2 out of 6 programs (15 combinations), in 13 of which UCBRA was better than FairShare. In the middle graph - 19 out of 20, and in the right graph - 13 out of 15. Note that the reward tends to be more significant than FairShare when the problem is hard, i.e., the hit rate is low. Note that though -greedy achieves high performance, we still needed to set its parameters, and thus is less robust."}, {"heading": "6 Discussion", "text": "We investigated statistical methods to allocate memory to threads. We proposed a simple model for the problem, that accurately captures the properties of the real memory allocation problem. We provided two algorithms for the task, and performed an empirical study with both synthetic and real-world data. We executed several real applications in a controlled memory environment and analyzed a few allocation strategies. The memory-UCB outperformed all other methods.\nAlthough we have restricted our discussion to allocating memory to threads, the tools developed here can be used in other contexts, such as allocating main memory and cores to processes, allocating network bandwidth to clients, and so on."}], "references": [{"title": "Asymptotically efficient adaptive allocation rules", "author": ["T.L. Lai", "H. Robbins"], "venue": "Advances in applied mathematics, vol. 6, no. 1, pp. 4\u201322, 1985.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1985}, {"title": "Organizing the last line of defense before hitting the memory wall for cmps", "author": ["C. Liu", "A. Sivasubramaniam", "M. Kandemir"], "venue": "Software, IEE Proceedings-. IEEE, 2004, pp. 176\u2013185.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Regret analysis of stochastic and nonstochastic multi-armed bandit problems", "author": ["S. Bubeck", "N. Cesa-Bianchi"], "venue": "Foundations and Trends in Machine Learning, vol. 5, no. 1, pp. 1\u2013122, 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine learning, vol. 47, no. 2-3, pp. 235\u2013256, 2002.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2002}, {"title": "Combinatorial network optimization with unknown variables: Multi-armed bandits with linear rewards", "author": ["Y. Gai", "B. Krishnamachari", "R. Jain"], "venue": "arXiv preprint arXiv:1011.4748, 2010.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Combinatorial multiarmed bandit: General framework and applications", "author": ["W. Chen", "Y. Wang", "Y. Yuan"], "venue": "Proceedings of the 30th International Conference on Machine Learning (ICML-13), 2013, pp. 151\u2013159.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "A new memory monitoring scheme for memory-aware scheduling and partitioning", "author": ["G.E. Suh", "S. Devadas", "L. Rudolph"], "venue": "High-Performance Computer Architecture, 2002. Proceedings. Eighth International Symposium on. IEEE, 2002, pp. 117\u2013128.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2002}, {"title": "Coordinated management of multiple interacting resources in chip multiprocessors: A machine learning approach", "author": ["R. Bitirgen", "E. Ipek", "J.F. Martinez"], "venue": "Proceedings of the 41st annual IEEE/ACM International Symposium on Microarchitecture. IEEE Computer Society, 2008, pp. 318\u2013329.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Optimal resource allocation with semi-bandit feedback", "author": ["T. Lattimore", "K. Crammer", "C. Szepesv\u00e1ri"], "venue": "Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence (UAI), 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["W. Hoeffding"], "venue": "Journal of the American Statistical Association, vol. 58, no. 301, pp. 13\u201330, March 1963. [Online]. Available: http://www.jstor.org/ stable/2282952? 8", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1963}], "referenceMentions": [{"referenceID": 0, "context": "The problem of making decisions under uncertainty, or partial knowledge, was studied extensively in the literature, and a popular model for this problem is the Multi-Armed Bandit (MAB) [1].", "startOffset": 185, "endOffset": 188}, {"referenceID": 1, "context": "[2]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "We clearly can not review all variants, and refer the reader to a recent manuscript in the area [3].", "startOffset": 96, "endOffset": 99}, {"referenceID": 0, "context": "Lai and Robbins [1] proposed one of the earliest MAB version, in which there are N independent arms, each producing stochastic i.", "startOffset": 16, "endOffset": 19}, {"referenceID": 3, "context": "[4] presented the UCB1 (upper confidence bound) algorithm.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "See again the manuscript [3] for details and examples.", "startOffset": 25, "endOffset": 28}, {"referenceID": 4, "context": "[5]), compared to structureconsidered algorithm.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] proposed a general CMAB formulation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] and of Suh et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] for cache hit rate optimization, and of Bitirgen et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] for global resources optimization using Artificial Neural Network).", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] studied a similar resource allocation problem, where a system manager allocated resources to maximize system gain.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "On iteration t an allocation algorithm partitions the memory to the threads, allocating mt,i \u2208 [0, 1] fraction of the memory to thread i.", "startOffset": 95, "endOffset": 101}, {"referenceID": 0, "context": "Once the resources are allocated, or partitioned, each thread i receives a stochastic bounded reward st,i \u2208 [0, 1] based on these resources.", "startOffset": 108, "endOffset": 114}, {"referenceID": 0, "context": "where \u03b3i, \u03b2i \u2208 [0, 1].", "startOffset": 15, "endOffset": 21}, {"referenceID": 3, "context": "[4]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "It is also concentrated around its mean, applying Hoeffding inequality [10]", "startOffset": 71, "endOffset": 75}, {"referenceID": 3, "context": "[4].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2], Suh et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7], Bitirgen et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] are not relevant to our settings, as the first is not designed to optimize the cumulative hit-rate, the second used a pre-defined model, and the third assumes the statistics are known (i.", "startOffset": 0, "endOffset": 3}], "year": 2016, "abstractText": "In many embedded systems, such as imaging systems, the system has a single designated purpose, and same threads are executed repeatedly. Profiling thread behavior, allows the system to allocate each thread its resources in a way that improves overall system performance. We study an online resource allocation problem, where a resource manager simultaneously allocates resources (exploration), learns the impact on the different consumers (learning) and improves allocation towards optimal performance (exploitation). We build on the rich framework of multiarmed bandits and present online and offline algorithms. Through extensive experiments with both synthetic data and real-world cache allocation to threads we show the merits and properties of our algorithms.", "creator": "LaTeX with hyperref package"}}}