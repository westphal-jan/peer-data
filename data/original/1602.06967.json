{"id": "1602.06967", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Feb-2016", "title": "Blind score normalization method for PLDA based speaker recognition", "abstract": "Probabilistic Linear Discriminant Analysis (PLDA) has become state-of-the-art method for modeling $i$-vector space in speaker recognition task. However the performance degradation is observed if enrollment data size differs from one speaker to another. This paper presents a solution to such problem by introducing new PLDA scoring normalization technique. Normalization parameters are derived in a blind way, so that, unlike traditional \\textit{ZT-norm}, no extra development data is required. Moreover, proposed method has shown to be optimal in terms of detection cost function. The experiments conducted on NIST SRE 2014 database demonstrate an improved accuracy in a mixed enrollment number condition.", "histories": [["v1", "Mon, 22 Feb 2016 21:22:49 GMT  (22kb)", "http://arxiv.org/abs/1602.06967v1", "4 pages, 1 figure, presented at the Interspeech 2015. In Sixteenth Annual Conference of the International Speech Communication Association 2015"]], "COMMENTS": "4 pages, 1 figure, presented at the Interspeech 2015. In Sixteenth Annual Conference of the International Speech Communication Association 2015", "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.SD", "authors": ["danila doroshin", "nikolay lubimov", "marina nastasenko", "mikhail kotov"], "accepted": false, "id": "1602.06967"}, "pdf": {"name": "1602.06967.pdf", "metadata": {"source": "CRF", "title": "Blind score normalization method for PLDA based speaker recognition", "authors": ["Danila Doroshin", "Nikolay Lubimov", "Marina Nastasenko", "Mikhail Kotov"], "emails": ["kotov}@stel.ru"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 2.\n06 96\n7v 1\n[ cs\n.C L\n] 2\n2 Fe\nb 20\n16"}, {"heading": "1. Introduction", "text": "One trial of automatic speaker verification process consists of estimating probability whether two utterances belong to the same speaker. Typically one utterance is taken from enrollment set of target speakers, another one is unknown test utterance. The decision is taken by the comparison of the verification score with a threshold. The combination of i-vector and Probabilistic Linear Discriminant Analysis (PLDA) approaches is a state-of-the-art speaker recognition method allowing to obtain this score. The i-vector approach is based on the total variability model [1] representing speaker data in the low-dimensional space. PLDA [2] handles the influence of the channel variability in the i-vector space [3] and also enables to compute the Log-Likelihood Ratio (LLR) score between target and nontarget hypothesis. There are two concurrent hypothesis forming this LLR score based on dependency of random latent variables which make probabilistic inference of visible data.\nThere are various strategies for PLDA score obtaining depending on the enrollment data size [4]. The approach with multiple enrollment utterances shows the best results among other strategies in the text-dependent verification [5]. However in real applications it often happens that the available data is limited and varied from one speaker to another. Using classical PLDA modeling approach in this case, system performance may be unstable depending on the enrollment size. In this paper, we introduce new PLDA scoring normalization technique that deals with this variation by minimizing detection cost function. Unlike traditional ZT-norm that is used to handle the effect of new environment [6], the introduced method handles the effect of different quality of speaker models and does not require extra development data. Speaker dependent score distributions for target and non-target hypothesis are considered to pose the problem.\nThe paper is organized as follows. In section 2, the proposed PLDA scores normalization technique is presented. In\nsection 3, the process of estimation of speaker dependent distribution parameters is presented. In section 4 the train and test data sets are described. The results for NIST SRE 2014 data set are given. In section 5, conclusions and future work directions are discussed."}, {"heading": "2. Score normalization for normal distributed scores", "text": "Consider speaker dependent Gaussian distributions for PLDA LLR scores and corresponding Cumulative Distribution Functions (CDF) in the cases of target H1 and non-target hypothesis H2\nPr(s|H1) = N (s, \u00b51, \u03c3 2 1), \u03a6S(t|H1) = Pr(S < t|H1) (1) Pr(s|H2) = N (s, \u00b52, \u03c3 2 2), \u03a6S(t|H2) = Pr(S < t|H2) (2)\nwhere r is an index of the speaker, \u00b51, \u03c31, \u00b52, \u03c32 \u2013 speaker dependent parameters, s is a PLDA LLR score. The choice of Gaussian distribution for scores will be discussed in section 3. We use minDCF as a measure of the system performance: minDCF = mint(FR(t) + \u03b2FA(t)), where FA and FR denote the false acceptance and the false rejection rates, \u03b2 is a fixed constant, and t the varying threshold.\nIt is expected that the value of the speaker specific threshold depends on the quality of the speaker model. This quality depends on the speaker\u2019s enrollment size, to what extent this enrollment represents speakers speech and also depends on the environment during enrollment recording.\nThe process of deriving the optimal threshold that is individual for each speaker is considered below. Rewrite minDCF in terms of CDF\nminDCF = min t \u03a6S(t|H1) + \u03b2(1\u2212 \u03a6S(t|H2)) (3)\nThis is unconstrained optimization problem, that can be solved by setting derivative w.r.t t to zero, Thus the following equation can be obtained\nN (t, \u00b51, \u03c3 2 1) N (t, \u00b52, \u03c322) = \u03b2\nThis equation reduces to the quadratic equation by taking a logarithm. In the case \u03c31 6= \u03c32, the solution is\nt1,2 = \u03c321\u00b52 \u2212 \u03c3 2 2\u00b51\n\u03c321 \u2212 \u03c3 2 2\n\u00b1 \u03c31\u03c32\n\u221a\n(\u00b51 \u2212 \u00b52)2 +\u2206(\u03c321 \u2212 \u03c3 2 2)\n\u03c321 \u2212 \u03c3 2 2\n(4) where \u2206 = 2 log (\u03b2\u03c31/\u03c32). When \u03c31 > \u03c32, the right root gives the minimum and when \u03c31 < \u03c32, the left root is the solution of the problem (3). In the case of \u03c31 = \u03c32 = \u03c3 and \u00b51 > \u00b52 the solution is\nt = \u00b51 + \u00b52\n2 +\n\u03c32\u2206\n2(\u00b51 \u2212 \u00b52) (5)\nThe case when \u00b51 < \u00b52 is unusual for speaker verification task. For speaker dependent PLDA scores, parameters \u00b51, \u03c31, \u00b52, \u03c32 depend on the speaker\u2019s enrolment, on the number of utterances in the enrolment. If these parameters for the specific speaker are known, then the value of the optimal threshold t is determined using (4), (5). The score normalization expression that we suggest shifts minDCF point to the zero and is is following\nsnorm = 1 \u221a\n\u03c321 + \u03c3 2 2\n(s\u2212 t)\nHere the empirical normalization by the total variance is applied. While shifting by speaker dependent t aligns minDCF threshold for all speakers, presented scale normalization aligns scores in the vicinity of a minDCF point. Also this technique showed good results in our experiments on NIST SRE 2014 database."}, {"heading": "3. Speaker dependent distribution of PLDA scores", "text": "In this section we derive speaker specific parameters \u00b5, \u03c3 for score distributions of target and non-target hypotheses. First, standard PLDA model will be described and then score in multiple enrollment case will be presented. We approximate score distribution using Gaussian distribution and examine two cases: when test vector correlates with speaker\u2019s enrollment set, i.e. target hypothesis H1, and when there is no correlation, i.e. nontarget hypothesis H2.\nGiven a speaker and a set of i-vectors i1, ..., iL , PLDA assumes [2] that the i-vectors are distributed according to\nin = m+ Fx+Gyn + en\nx \u223c N (x, 0, If ), yn \u223c N (yn, 0, Ig)\nen \u223c N (en, 0,\u03a3)\nwhere m is the mean vector, x \u2208 Rf is a speaker factor that supposed to be the same for all i-vectors of the speaker, yn \u2208 R\ng is a channel factor, en is a residual, I is an identity matrix of respectable dimension, and \u03a3 is a diagonal covariance matrix. Further, for simplicity of calculations we assume that the mean vector m is equal to zero. This can be achieved by preliminary subtracting it from the data.\nConsider the trial containing the speaker\u2019s enrolment set i1, ..., iL and the test i-vector it. PLDA LLR verification score s for this trial can be written [5, 4] as\ns = 1\n2\n[\n(i+ it) TKL+1(i+ it)\u2212 i TKLi\u2212 i T t K1it\n]\n+\u03b1(L)\n(6) where i = \u2211L\nn=1 in - the sum of the speaker\u2019s i-vectors and\nKL, \u03b1(L) are defined as follows\nKL = U\u0304FM \u22121 L F T U\u0304\n\u03b1(L) = log det (ML+1)\n\u22121\ndet (ML) \u22121 \u00b7 det (M1) \u22121\nwhere U = GGT +\u03a3, U\u0304 = U\u22121, ML = L \u00b7F T U\u0304F +If . Further, to derive speaker dependent distribution we assume that the speaker\u2019s enrollment is known and it is random variable. To deduce this distribution, the expression for the score (6) is rewritten as a quadratic form in the variable it\ns = 1\n2 (it \u2212 d)\nTA(it \u2212 d) T + c\u2212\n1 2 bTA\u22121b (7)\nusing following notations\nA = KL+1 \u2212K1, b = KL+1i\nc = 1\n2 iT (KL+1 \u2212KL)i+ \u03b1(L), d = \u2212A \u22121b\nParameters of the quadratic form depend on the enrollment size L and the sum of enrollment i-vectors i. Here should be considered distribution of the quadratic form with normal distributed vector it. There has been some works on computing such distributions [7], [8], [9], [10], [11]. Quadratic form can be rewritten as a linear combination of independent non-central chi-squared distributed variables by using the transition to the new variables associated with the principal components of the matrix A. The convolution of this distributions leads to the complex distribution for which the solution of the problem (3) seems difficult. In the i-vector case (7), this sum consists of 400 to 600 elements since it is the typical dimension of i-vector space. In this work, we approximate this distribution by using Gaussian distribution and reserve the case of non-Gaussian distribution for possible further research.\nConsider quadratic form z = qT\u039bq, where q is the random vector with the expected value \u00b5q and covariance matrix \u03a3q . Then, the expectation and variance of z are defined as follows\n\u00b5z = tr (\u039b\u03a3q) + \u00b5 T q \u039b\u00b5q (8)\n\u03c32z = 2 tr (\u039b\u03a3q\u039b\u03a3q) + 4\u00b5 T q \u039b\u03a3q\u039b\u00b5q (9)\nConsider first case of the non-target hypotheses H2 when the test i-vector has zero expectation and covariance matrix R = V + U , where V = FF T . Parameters of the distribution (2) are obtained by applying (8), (9) to the quadratic form (7)\n\u00b52 = 1\n2 tr (AR) + c\n\u03c322 = 1\n2 tr (ARAR) + bTRb\nIn the case of the target hypotheses H1, test i-vector is correlated with speaker\u2019s enrolment and has more complex distribution. Combined vector [it, i1, . . . , iN ]T has zero expectation and covariance matrix\nC =\n\n    U + V V . . . V V U + V . . . V ... ... . . .\n... V V . . . U + V\n\n   \nIt can be shown [4] that conditional probability distribution of it given i1, . . . , iN has the following expectation and covariance\n\u00b5\u0302 = ( V U\u0304 + L \u00b7 V Q ) i\nR\u0302 = R\u2212 L \u00b7 ( V U\u0304 + L \u00b7 V Q ) V\nwhere Q = \u2212(L \u00b7 V +U)\u22121V U\u0304 . Now, using (8) and (9), final expressions for \u00b51 and \u03c321 from (1) are derived\n\u00b51 = 1\n2 tr(AR\u0302)\u2212 \u00b5\u0302TAd+\n1 2 \u00b5\u0302TA\u00b5\u0302+ c\n\u03c321 = 1 2 tr ( AR\u0302AR\u0302 ) + (d\u2212 \u00b5\u0302)TAR\u0302A(d\u2212 \u00b5\u0302)\nAs a result, it is clear that the parameters of speaker dependent score distributions \u00b51, \u03c31, \u00b52, \u03c32 depend on the speaker\u2019s enrollment size L and on the sum of enrollment i-vectors."}, {"heading": "4. Experimental results", "text": ""}, {"heading": "4.1. Data set and PLDA parameters estimation", "text": "NIST i-vector Machine Learning Challenge 2014 data set has been chosen to test the efficiency of the proposed model. The data set consists of a labeled development set (devset), a labeled model set (modelset) with 5 i-vectors per model and an unlabeled test set (testset). Since labels for the devset were not available during the challenge, the best results were obtained from methods that allowed to cluster the devset and then to apply PLDA [12, 13]. The original devset labels have been used in the presented experiments.\nIn our experiments the datasets have been initially preprocessed. Preliminary all i-vectors with duration less then 10 seconds have been removed [12, 13]. We construct a new labeled trainset, modelset, testset, modelsetCV, testsetCV. Speakers from devset with 3 to 10 i-vectors combined with the initial modelset are assigned to the trainset, with 11 to 15 i-vectors are assigned to the new modelset and testset, remaining speakers with more then 15 i-vectors form cross validation set (modelsetCV, testsetCV). First 5 i-vectors from each speaker set are used as enrollment in the modelset and the remaining as the testset. The same is done for the cross validation set. Eventually the trainset contains 3281 speakers and total 18759 i-vectors, 717 speakers with 3585 i-vectors and 5400 i-vectors in the modelset and the testset respectively.We used minDCF with \u03b2 = 100 as a measure of the system performance.\nThe whitening process is applied to the trainset [14]. Whitened trainset is used for the PLDA model parameter estimation. The parameters of whitening are computed on the trainset too. Whitened trainset was projected on the unit sphere [14]. This transform is used further for all trials. Best speaker and channel factor dimensions for PLDA are equal to 590 and 10 respectively. Optimal parameters were found on cross validation set - modelsetCV, testsetCV."}, {"heading": "4.2. Results", "text": "The experiments were performed with various enrollment size conditions. modelset contains speakers with 5 i-vectors per speaker. We compare general PLDA scoring with suggested normalized scoring (2) on the following enrollment sets. Fist, 5 sets with L = {1, 2, 3, 4, 5} i-vectors per speaker are configured using modelset. For example, the set with L = 3 is composed using first 3 i-vectors of each speaker from modelset. In addition, the set with the mixed enrollment conditions is configured. This set is composed from modelset speakers with the reduced enrollment and contain 94 speakers with 1 i-vector per speaker, 93 speakers with 2 i-vectors per speaker, 194 speakers with 3 i-vectors per speaker, 189 speakers with 4 i-vectors per speaker, 113 speakers with 5 i-vectors per speaker.\nFigure 1. demonstrates the histograms of the speaker dependent thresholds for models with various enrollment sizes L. These thresholds are found to be optimal in terms of minDCF (3) with \u03b2 = 100. As could be seen, the means of threshold distribution differ based on size of enrollment set, and variances indicates uncertainties of different speaker scores. Table 1 demonstrates results for all sets. In the case of the uniform enrollment conditions L = {1, 2, 3, 4, 5}, the suggested normalization technique shows almost the same performance as the standard PLDA scoring. Much better results are achieved on the set with mixed enrollment conditions. As it is expected, using constant threshold gives worse results than by using proposed normalization. At the same time it doesn\u2019t bring extra com-\nputational costs since parameter estimation is made in a blind manner. This experiments shows that the performance really degrades with unfixed enrollment size and could be enhanced with this cheap procedure. In the current challenge normalized scoring decreases minDCF by 30% comparing with general PLDA scoring."}, {"heading": "5. Conclusions and Further Work", "text": "This paper presents a novel normalization technique for ivector PLDA speaker verification in the mixed enrollment number condition. The main contribution to existed normalization methods is that this technique does not require extra development data and based only on the properties of the PLDA model. This provide more stable verification scores almost without additional computational costs. The experiments conducted on NIST SRE 2014 database demonstrate that minDCF decrease in the mixed enrollment number condition.\nIn further work, the problem of non-Gaussian distribution for PLDA scores can be considered. This can lead to a more accurate estimate of the speaker specific threshold."}, {"heading": "6. Acknowledgement", "text": "Research is conducted by Stel - Computer systems ltd. with support of the Ministry of Education and Science of the Russian Federation (Contract 14.579.21.0058) Unique ID for Applied Scientific Research (project) RFMEFI57914X0058. The data presented, the statements made, and the views expressed are solely the responsibility of the authors."}, {"heading": "7. References", "text": "[1] N. Dehak, P. Kenny, R. Dehak, P. Dumouchel, and P. Ouel-\nlet, \u201cFront-end factor analysis for speaker verification,\u201d Audio, Speech, and Language Processing, IEEE Transactions on, vol. 19, no. 4, pp. 788\u2013798, 2011.\n[2] S. J. Prince and J. H. Elder, \u201cProbabilistic linear discriminant analysis for inferences about identity,\u201d in Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on. IEEE, 2007, pp. 1\u20138.\n[3] P. Kenny, P. Ouellet, N. Dehak, V. Gupta, and P. Dumouchel, \u201cA study of interspeaker variability in speaker verification,\u201d Audio, Speech, and Language Processing, IEEE Transactions on, vol. 16, no. 5, pp. 980\u2013988, 2008.\n[4] P. Rajan, A. Afanasyev, V. Hautama\u0308ki, and T. Kinnunen, \u201cFrom single to multiple enrollment i-vectors: Practical plda scoring variants for speaker verification,\u201d Digital Signal Processing, vol. 31, pp. 93\u2013101, 2014.\n[5] A. Larcher, K. A. Lee, B. Ma, and H. Li, \u201cPhoneticallyconstrained plda modeling for text-dependent speaker verification with multiple short utterances,\u201d in Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on. IEEE, 2013, pp. 7673\u20137677.\n[6] C. Barras and J.-L. Gauvain, \u201cFeature and score normalization for speaker verification of cellular data,\u201d in Acoustics, Speech, and Signal Processing, 2003. Proceedings.(ICASSP\u201903). 2003 IEEE International Conference on, vol. 2. IEEE, 2003, pp. II\u201349.\n[7] A. Castan\u0303o-Mart\u0131\u0301nez and F. Lo\u0301pez-Bla\u0301zquez, \u201cDistribution of a sum of weighted noncentral chi-square variables,\u201d Test, vol. 14, no. 2, pp. 397\u2013415, 2005.\n[8] H. Liu, Y. Tang, and H. H. Zhang, \u201cA new chi-square approximation to the distribution of non-negative definite quadratic forms in non-central normal variables,\u201d Computational Statistics & Data Analysis, vol. 53, no. 4, pp. 853\u2013856, 2009.\n[9] J. Bausch, \u201cOn the efficient calculation of a linear combination of chi-square random variables with an application in counting string vacua,\u201d Journal of Physics A: Mathematical and Theoretical, vol. 46, no. 50, p. 505202, 2013.\n[10] D. Kuonen, \u201cMiscellanea. saddlepoint approximations for distributions of quadratic forms in normal variables,\u201d Biometrika, vol. 86, no. 4, pp. 929\u2013935, 1999.\n[11] J. Sheil and I. O\u2019Muircheartaigh, \u201cAlgorithm as 106: The distribution of non-negative quadratic forms in normal variables,\u201d Applied Statistics, pp. 92\u201398, 1977.\n[12] E. Khoury, L. El Shafey, M. Ferras, and S. Marcel, \u201cHierarchical speaker clustering methods for the nist i-vector challenge,\u201d in Odyssey: The Speaker and Language Recognition Workshop, no. EPFL-CONF-198439, 2014.\n[13] S. Novoselov, T. Pekhovsky, and K. Simonchik, \u201cStc speaker recognition system for the nist i-vector challenge,\u201d in Odyssey: The Speaker and Language Recognition Workshop, 2014, pp. 231\u2013240.\n[14] D. Garcia-Romero and C. Y. Espy-Wilson, \u201cAnalysis of i-vector length normalization in speaker recognition systems.\u201d in Interspeech, 2011, pp. 249\u2013252."}], "references": [{"title": "Front-end factor analysis for speaker verification", "author": ["N. Dehak", "P. Kenny", "R. Dehak", "P. Dumouchel", "P. Ouellet"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 19, no. 4, pp. 788\u2013798, 2011.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic linear discriminant analysis for inferences about identity", "author": ["S.J. Prince", "J.H. Elder"], "venue": "Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on. IEEE, 2007, pp. 1\u20138.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "A study of interspeaker variability in speaker verification", "author": ["P. Kenny", "P. Ouellet", "N. Dehak", "V. Gupta", "P. Dumouchel"], "venue": "Audio, Speech, and Language Processing, IEEE Transactions on, vol. 16, no. 5, pp. 980\u2013988, 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "From single to multiple enrollment i-vectors: Practical plda scoring variants for speaker verification", "author": ["P. Rajan", "A. Afanasyev", "V. Hautam\u00e4ki", "T. Kinnunen"], "venue": "Digital Signal Processing, vol. 31, pp. 93\u2013101, 2014.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Phoneticallyconstrained plda modeling for text-dependent speaker verification with multiple short utterances", "author": ["A. Larcher", "K.A. Lee", "B. Ma", "H. Li"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on. IEEE, 2013, pp. 7673\u20137677.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Feature and score normalization for speaker verification of cellular data", "author": ["C. Barras", "J.-L. Gauvain"], "venue": "Acoustics, Speech, and Signal Processing, 2003. Proceedings.(ICASSP\u201903). 2003 IEEE International Conference on, vol. 2. IEEE, 2003, pp. II\u201349.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Distribution of a sum of weighted noncentral chi-square variables", "author": ["A. Casta\u00f1o-Mart\u0131\u0301nez", "F. L\u00f3pez-Bl\u00e1zquez"], "venue": "Test, vol. 14, no. 2, pp. 397\u2013415, 2005.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "A new chi-square approximation to the distribution of non-negative definite quadratic forms in non-central normal variables", "author": ["H. Liu", "Y. Tang", "H.H. Zhang"], "venue": "Computational Statistics & Data Analysis, vol. 53, no. 4, pp. 853\u2013856, 2009.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "On the efficient calculation of a linear combination of chi-square random variables with an application in counting string vacua", "author": ["J. Bausch"], "venue": "Journal of Physics A: Mathematical and Theoretical, vol. 46, no. 50, p. 505202, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Miscellanea. saddlepoint approximations for distributions of quadratic forms in normal variables", "author": ["D. Kuonen"], "venue": "Biometrika, vol. 86, no. 4, pp. 929\u2013935, 1999.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1999}, {"title": "Algorithm as 106: The distribution of non-negative quadratic forms in normal variables", "author": ["J. Sheil", "I. O\u2019Muircheartaigh"], "venue": "Applied Statistics, pp. 92\u201398, 1977.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1977}, {"title": "Hierarchical speaker clustering methods for the nist i-vector challenge", "author": ["E. Khoury", "L. El Shafey", "M. Ferras", "S. Marcel"], "venue": "Odyssey: The Speaker and Language Recognition Workshop, no. EPFL-CONF-198439, 2014.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1984}, {"title": "Stc speaker recognition system for the nist i-vector challenge", "author": ["S. Novoselov", "T. Pekhovsky", "K. Simonchik"], "venue": "Odyssey: The Speaker and Language Recognition Workshop, 2014, pp. 231\u2013240.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Analysis of i-vector length normalization in speaker recognition systems.", "author": ["D. Garcia-Romero", "C.Y. Espy-Wilson"], "venue": "in Interspeech,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "The i-vector approach is based on the total variability model [1] representing speaker data in the low-dimensional space.", "startOffset": 62, "endOffset": 65}, {"referenceID": 1, "context": "PLDA [2] handles the influence of the channel variability in the i-vector space [3] and also enables to compute the Log-Likelihood Ratio (LLR) score between target and nontarget hypothesis.", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "PLDA [2] handles the influence of the channel variability in the i-vector space [3] and also enables to compute the Log-Likelihood Ratio (LLR) score between target and nontarget hypothesis.", "startOffset": 80, "endOffset": 83}, {"referenceID": 3, "context": "There are various strategies for PLDA score obtaining depending on the enrollment data size [4].", "startOffset": 92, "endOffset": 95}, {"referenceID": 4, "context": "The approach with multiple enrollment utterances shows the best results among other strategies in the text-dependent verification [5].", "startOffset": 130, "endOffset": 133}, {"referenceID": 5, "context": "Unlike traditional ZT-norm that is used to handle the effect of new environment [6], the introduced method handles the effect of different quality of speaker models and does not require extra development data.", "startOffset": 80, "endOffset": 83}, {"referenceID": 1, "context": ", iL , PLDA assumes [2] that the i-vectors are distributed according to", "startOffset": 20, "endOffset": 23}, {"referenceID": 4, "context": "PLDA LLR verification score s for this trial can be written [5, 4] as", "startOffset": 60, "endOffset": 66}, {"referenceID": 3, "context": "PLDA LLR verification score s for this trial can be written [5, 4] as", "startOffset": 60, "endOffset": 66}, {"referenceID": 6, "context": "There has been some works on computing such distributions [7], [8], [9], [10], [11].", "startOffset": 58, "endOffset": 61}, {"referenceID": 7, "context": "There has been some works on computing such distributions [7], [8], [9], [10], [11].", "startOffset": 63, "endOffset": 66}, {"referenceID": 8, "context": "There has been some works on computing such distributions [7], [8], [9], [10], [11].", "startOffset": 68, "endOffset": 71}, {"referenceID": 9, "context": "There has been some works on computing such distributions [7], [8], [9], [10], [11].", "startOffset": 73, "endOffset": 77}, {"referenceID": 10, "context": "There has been some works on computing such distributions [7], [8], [9], [10], [11].", "startOffset": 79, "endOffset": 83}, {"referenceID": 3, "context": "It can be shown [4] that conditional probability distribution of it given i1, .", "startOffset": 16, "endOffset": 19}, {"referenceID": 11, "context": "Since labels for the devset were not available during the challenge, the best results were obtained from methods that allowed to cluster the devset and then to apply PLDA [12, 13].", "startOffset": 171, "endOffset": 179}, {"referenceID": 12, "context": "Since labels for the devset were not available during the challenge, the best results were obtained from methods that allowed to cluster the devset and then to apply PLDA [12, 13].", "startOffset": 171, "endOffset": 179}, {"referenceID": 11, "context": "Preliminary all i-vectors with duration less then 10 seconds have been removed [12, 13].", "startOffset": 79, "endOffset": 87}, {"referenceID": 12, "context": "Preliminary all i-vectors with duration less then 10 seconds have been removed [12, 13].", "startOffset": 79, "endOffset": 87}, {"referenceID": 13, "context": "The whitening process is applied to the trainset [14].", "startOffset": 49, "endOffset": 53}, {"referenceID": 13, "context": "Whitened trainset was projected on the unit sphere [14].", "startOffset": 51, "endOffset": 55}], "year": 2016, "abstractText": "Probabilistic Linear Discriminant Analysis (PLDA) has become state-of-the-art method for modeling i-vector space in speaker recognition task. However the performance degradation is observed if enrollment data size differs from one speaker to another. This paper presents a solution to such problem by introducing new PLDA scoring normalization technique. Normalization parameters are derived in a blind way, so that, unlike traditional ZT-norm, no extra development data is required. Moreover, proposed method has shown to be optimal in terms of detection cost function. The experiments conducted on NIST SRE 2014 database demonstrate an improved accuracy in a mixed enrollment number condition.", "creator": "LaTeX with hyperref package"}}}