{"id": "1603.03158", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Mar-2016", "title": "Scenario Submodular Cover", "abstract": "Many problems in Machine Learning can be modeled as submodular optimization problems. Recent work has focused on stochastic or adaptive versions of these problems. We consider the Scenario Submodular Cover problem, which is a counterpart to the Stochastic Submodular Cover problem studied by Golovin and Krause. In Scenario Submodular Cover, the goal is to produce a cover with minimum expected cost, where the expectation is with respect to an empirical joint distribution, given as input by a weighted sample of realizations. In contrast, in Stochastic Submodular Cover, the variables of the input distribution are assumed to be independent, and the distribution of each variable is given as input. Building on algorithms developed by Cicalese et al. and Golovin and Krause for related problems, we give two approximation algorithms for Scenario Submodular Cover over discrete distributions. The first achieves an approximation factor of O(log Qm), where m is the size of the sample and Q is the goal utility. The second, simpler algorithm achieves an approximation bound of O(log QW), where Q is the goal utility and W is the sum of the integer weights. (Both bounds assume an integer-valued utility function.) Our results yield approximation bounds for other problems involving non-independent distributions that are explicitly specified by their support.", "histories": [["v1", "Thu, 10 Mar 2016 06:43:52 GMT  (46kb,D)", "http://arxiv.org/abs/1603.03158v1", "32 pages, 1 figure"]], "COMMENTS": "32 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.DS cs.LG", "authors": ["nathaniel grammel", "lisa hellerstein", "devorah kletenik", "patrick lin"], "accepted": false, "id": "1603.03158"}, "pdf": {"name": "1603.03158.pdf", "metadata": {"source": "CRF", "title": "Scenario Submodular Cover", "authors": ["Nathaniel Grammel", "Lisa Hellerstein", "Devorah Kletenik", "Patrick Lin"], "emails": ["ngrammel@nyu.edu", "lisa.hellerstein@nyu.edu", "kletenik@sci.brooklyn.cuny.edu", "plin15@illinois.edu"], "sections": [{"heading": null, "text": "\u2217 Partially Supported by NSF Grant 1217968\nc\u00a9 2016 N. Grammel, L. Hellerstein, D. Kletenik & P. Lin.\nar X\niv :1\n60 3.\n03 15\n8v 1"}, {"heading": "1. Introduction", "text": "Many problems in Machine Learning can be modeled as submodular optimization problems. Recent work has focused on stochastic or adaptive versions of submodular optimization problems, which reflect the need to make sequential decisions when outcomes are uncertain.\nThe Submodular Cover problem generalizes the classical NP-complete Set Cover problem and is a fundamental problem in submodular optimization. Adaptive versions of this problem have applications to a variety of machine learning problems that require building a decision tree, where the goal is to minimize expected cost. Examples include problems of entity identification (exact learning with membership queries), classification (equivalence class determination), and decision region identification (cf. Golovin and Krause (2011); Golovin et al. (2010); Bellala et al. (2012); Javdani et al. (2014)). Other applications include reducing prediction costs for learned Boolean classifiers, when there are costs for determining attribute values (Deshpande et al. (2014)).\nPrevious work on the Stochastic Submodular Cover problem assumes that the variables of the input probability distribution are independent. Optimization is performed with respect to this distribution. We consider a new version of the problem that we call Scenario Submodular Cover, that removes the independence assumption. In this problem, optimization is performed with respect to an input distribution that is given explicitly by its support (with associated probability weights). We give approximation algorithms solving the Scenario Submodular Cover problem over discrete distributions.\nBefore describing our contributions in more detail, we give some background. In generic terms, an adaptive submodular cover problem is a sequential decision problem where we must choose items one by one from an item set N = {1, . . . , n}. Each item has an initially unknown state, which is a member of a finite state set \u0393. The state of an item is revealed only after we have chosen the item. We represent a subset S of items and their states by a vector x \u2208 (\u0393 \u222a {\u2217})n where xi = \u2217 if i 6\u2208 S, and xi is the state of item i otherwise. We are given a monotone, submodular utility function g : (\u0393 \u222a {\u2217})n \u2192 Z\u22650. It assigns a non-negative integer value to each subset of the items and the value can depend on the states of the items.1 There is a non-negative goal utility value Q, such that g(a) = Q for all a \u2208 \u0393n. There is a cost associated with choosing each item, which we are given. In distributional settings, we are also given the joint distribution of the item states. We must continue choosing items until their utility value is equal to the goal utility, Q. The problem is to determine the adaptive order in which to choose the items so as to minimize expected cost (in distributional settings) or worst-case cost (in adversarial settings).\nStochastic Submodular Cover is an adaptive submodular cover problem, in a distributional setting. In this problem, the state of each item is a random variable, and these variables are assumed to be independent. The distributions of the variables are given as input. Golovin and Krause introduced a simple greedy algorithm for this problem, called Adaptive Greedy, that achieves an approximation factor of O(logQ). A dual greedy algorithm for the problem, called Adaptive Dual Greedy, was presented and analyzed by Deshpande et al. (2014). These greedy algorithms have been useful in solving other stochastic optimization\n1. The definitions of the terms \u201cmonotone\u201d and \u201csubmodular,\u201d for state-dependent utility functions, has not been standardized. We define these terms in Section 2. In the terminology used by Golovin and Krause Golovin and Krause (2011), g is pointwise monotone and pointwise submodular.\nproblems, which can be reduced to Stochastic Submodular Cover through the construction of appropriate utility functions (e.g., Javdani et al. (2014); Chen et al. (2015a); Deshpande et al. (2014); Golovin et al. (2010)).\nThe problem we study in this paper, Scenario Submodular Cover (Scenario SC), is also a distributional, adaptive submodular cover problem. The distribution is given by a weighted sample, which is provided as part of the input to the problem. Each element of the sample is a vector in \u0393n, representing an assignment of states to the items in N . Associated with each assignment is a positive integer weight. The sample and its weights define a joint distribution on \u0393n, where the probability of a vector \u03b3 in the sample is proportional to its weight. (The probability of a vector in \u0393n that is not in the sample is 0.) As in Stochastic Submodular Cover, the problem is to choose the items and achieve utility Q, in a way that minimizes the expected cost incurred. However, because many of the proofs of results for the Stochastic Submodular Cover problem rely on the independence assumption, the proofs do not apply to the Scenario SC problem."}, {"heading": "Results", "text": "We present an approximation algorithm for the Scenario SC problem that we call Mixed Greedy. It uses two different greedy criteria. It is a generalization of an algorithm by Cicalese et al. (2014) for the Equivalence Class Determination problem (which has also been called the Group Identification problem and the Discrete Function Evaluation problem).\nThe approximation factor achieved by Mixed Greedy for the Scenario SC problem is O (\n1 \u03c1 logQ\n) , where \u03c1 is a quantity that depends on the utility function g. In the case of the\nutility function constructed for the Equivalence Class Determination Problem, \u03c1 is constant, but this is not true in general.\nWe describe a modified version of Mixed Greedy that we call Scenario Mixed Greedy. It works by first constructing a new monotone, submodular utility function gS from g and the sample, for which \u03c1 is constant. It then runs Mixed Greedy on gS with goal value Qm, where m is the size of the sample. We show that Scenario Mixed Greedy achieves an O(logQm) approximation factor for any Scenario SC problem.\nMixed Greedy is very similar to the algorithm of Cicalese et al., and we use the same basic analysis. However, at the heart of their analysis is a technical lemma with a lengthy proof bounding a quantity that they call the \u201csepcost\u201d. The proof applies only to the particular utility function used in the Equivalence Class Determination problem. We replace this proof with an entirely different proof that applies to the general Scenario SC problem. Our proof is based on the work of Streeter and Golovin (2009) for the Min-Sum Submodular Cover problem.\nIn addition to presenting and analyzing Mixed Greedy, we also present another algorithm for the Scenario SC problem that we call Scenario Adaptive Greedy. It is a modified version of the Adaptive Greedy algorithm of Golovin and Krause. Scenario Adaptive Greedy is simpler and more efficient than Mixed Greedy, and is therefore likely to be more useful in practice. However, the approximation bound proved by Golovin and Krause for Adaptive Greedy depends on the assumption that g and the distribution defined by the sample weights jointly satisfy the adaptive submodularity property. This is not the case for general instances of the Scenario SC problem. We extend the approach used in constructing gS to\ngive a simple, generic method for constructing a modified utility function gW , with goal utility QW , from g, which incorporates the weights on the sample. We prove that utility function gW and the distribution defined by the sample weights jointly satisfy adaptive submodularity. This allows us to apply the Adaptive Greedy algorithm, and to achieve an approximation bound of O(logQW ) for the Scenario SC problem, where W is the sum of the weights.\nOur constructions of gS and gW are similar to constructions used in previous work on Equivalence Class Determination and related problems (cf. Golovin et al. (2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al. (2015a,b)), namely showing that the value of a certain function is non-decreasing along a path between two points; however, we are addressing a more general problem and the details of our proof are different.\nWe believe that our work on Adaptive Greedy should make it easier to develop efficient approximation algorithms for sample-based problems in the future. Previously, using ordinary Adaptive Greedy to solve a sample-based problem involved the construction of a utility function g, and a proof that g, together with the distribution on the weighted sample, was adaptive submodular. The proof was usually the most technically difficult part of the work (see, e.g., Golovin et al. (2010); Bellala et al. (2012); Javdani et al. (2014); Chen et al. (2015b)). Our construction of gW , and our proof of adaptive submodularity, make it possible to achieve an approximation bound using Adaptive Greedy after proving only submodularity of a constructed g, rather than adaptive submodularity of g and the distribution. Proofs of submodularity are generally easier because they do not involve distributions and expected values. Also, the standard OR construction described in Section 2 preserves submodularity, while it does not preserve Adaptive Submodularity (Chen et al. (2015a)).\nGiven a monotone, submodular g with goal value Q, we can use the algorithms in this paper to immediately obtain three approximation results for the associated Scenario SC problem: running Mixed Greedy with g yields an O (\n1 \u03c1 logQ\n) approximation, running Mixed\nGreedy with gS yields an O(logQm) approximation, and running Adaptive Greedy with gW yields an O(logQW ) approximation. By the results of Golovin and Krause (2011), running Adaptive Greedy with g yields an O(logQ) approximation for the associated Stochastic SC problem."}, {"heading": "Applications", "text": "Our results on Mixed Greedy yield approximation bounds for other problems. For example, we can easily obtain a new bound for the Decision Region Identification problem studied by Javdani et al. (2014), which is an extension of the Equivalence Class Determination problem. Javdani et al. construct a utility function whose value corresponds to a weighted sum of the hyperedges cut in a certain hypergraph. We can define a corresponding utility function whose value is the number of hyperedges cut. This utility function is clearly monotone and submodular. Using Mixed Greedy with this utility function yields an approximation bound of O(k logm), where k is a parameter associated with the problem, and m is the size\nof the input sample for this problem. In contrast, the bound achieved by Javdani et al. is O ( k log ( W\nwmin\n)) , where wmin is the minimum weight on a assignment in the sample.\nWe can apply our greedy algorithms to Scenario BFE (Boolean Function Evaluation) problems, which we introduce here. These problems are a counterpart to the Stochastic BFE problems2 that have been studied in AI, operations research, and in the context of learning with attribute costs (see e.g., U\u0308nlu\u0308yurt (2004); Deshpande et al. (2014); Kaplan et al. (2005)). In a Scenario BFE problem, we are given a Boolean function f . For each i \u2208 {1, . . . , n}, we are also given a cost ci > 0 associated with obtaining the value of the ith bit of an initially unknown assignment a \u2208 {0, 1}n. Finally, we are given a weighted sample S \u2286 {0, 1}n. The problem is to compute a (possibly implicit) decision tree computing f , such that the expected cost of evaluating f on a \u2208 {0, 1}n, using the tree, is minimized. The expectation is with respect to the distribution defined by the sample weights.\nDeshpande et al. (2014) gave approximation algorithms for some Stochastic BFE problems that work by constructing an appropriate monotone, submodular utility function g and running Adaptive Greedy. By substituting the sample-based algorithms in this paper in place of Adaptive Greedy, we obtain approximation results for analogous Scenario BFE problems. For example, using Mixed Greedy, we can show that the Scenario BFE problem for k-of-n functions has an approximation algorithm achieving a factor of O(k log n) approximation, independent of the size of the sample. Details are in Appendix B. Bounds for other functions follow easily using Scenario Mixed Greedy and Scenario Adaptive Greedy. For example, Deshpande et al. (2014) presented an algorithm achieving an O(log t) approximation for the Stochastic BFE problem for evaluating decision trees of size t. Substituting Scenario Mixed Greedy for Adaptive Greedy in this algorithm yields an O(log tm) approximation for the associated Scenario BFE problem.\nWe note that our Scenario BFE problem differs from the function evaluation problem by Cicalese et al. (2014). In their problem, the computed decision tree need only compute f correctly on assignments a \u2208 {0, 1}n that are in the sample, while ours needs to compute f correctly on all a \u2208 {0, 1}n. To see the difference, consider the problem of evaluating the Boolean OR function, for a sample S consisting of only a \u2208 {0, 1}n with at least one 1. If the tree only has to be correct on a \u2208 S, a one-node decision tree that immediately outputs 1 is valid, even though it does not compute the OR function. Also, in Scenario BFE we assume that the function f is given with the sample, and we consider particular types of functions f ."}, {"heading": "Organization", "text": "We begin with definitions in Section 2. In Section 3, we present the overview of the Mixed Greedy algorithm. Finally, we present Scenario Mixed Greedy in Section 4, followed by Scenario Adaptive Greedy in Section 5.\n2. In the Operations Research literature, Stochastic Function Evaluation is often called Sequential Testing or Sequential Diagnosis."}, {"heading": "2. Definitions", "text": "Let N = {1, . . . , n} be the set of items and \u0393 be a finite set of states. A sample is a subset of \u0393n. A realization of the items is an element a \u2208 \u0393n, representing an assignment of states to items, where for i \u2208 N , ai represents the state of item i. We also refer to an element of \u0393n as an assignment.\nWe call b \u2208 (\u0393 \u222a {\u2217})n a partial realization. Partial realization b represents the subset of items I = {i | bi 6= \u2217} where each item i \u2208 I has state bi. For \u03b3 \u2208 \u0393, the quantity bi\u2190\u03b3 denotes the partial realization that is identical to b except that bi = \u03b3. For partial realizations b, b\u2032 \u2208 (\u0393 \u222a {\u2217})n, b\u2032 is an extension of b, written b\u2032 b, if b\u2032i = bi for all bi 6= \u2217. We use b\u2032 b to denote that b\u2032 b and b\u2032 6= b.\nLet g : (\u0393 \u222a {\u2217})n \u2192 Z\u22650 be a utility function. Utility function g : (\u0393 \u222a {\u2217})n \u2192 Z\u22650 has goal value Q if g(a) = Q for all realizations a \u2208 \u0393n.\nWe define \u2206g(b, i, \u03b3) := g(bi\u2190\u03b3)\u2212 g(b). A standard utility function is a set function f : 2N \u2192 R\u22650. It is monotone if for all S \u2282 S\u2032 \u2286 N , f(S) \u2264 f(S\u2032). It is submodular if in addition, for i \u2208 N\u2212S, f(S\u222a{i})\u2212f(S) \u2265 f(S\u2032\u222a{i})\u2212f(S\u2032). We extend the definitions of monotonicity and submodularity to (statedependent) utility function g : (\u0393 \u222a {\u2217})n \u2192 Z\u22650 as follows:\n\u2022 g is monotone if for b \u2208 (\u0393 \u222a {\u2217})n, i \u2208 N such that bi = \u2217, and \u03b3 \u2208 \u0393, we have g(b) \u2264 g(bi\u2190\u03b3)\n\u2022 g is submodular if for all b, b\u2032 \u2208 (\u0393 \u222a {\u2217})n such that b\u2032 b, i \u2208 N such that bi = b\u2032i = \u2217, and \u03b3 \u2208 \u0393, we have \u2206g(b, i, \u03b3) \u2265 \u2206g(b\u2032i, \u03b3).\nLet D be a probability distribution on \u0393n. Let X be a random variable drawn from D. For a \u2208 \u0393n and b \u2208 (\u0393 \u222a {\u2217})n, we define Pr[a | b] := Pr[X = a | a b]. For i such that bi = \u2217, we define E[\u2206g(b, i, \u03b3)] := \u2211 a\u2208\u0393n:a b \u2206g(b, i, ai) Pr[a | b].\n\u2022 g is adaptive submodular with respect to D if for all b\u2032, b such that b\u2032 b, i \u2208 N such that bi = b \u2032 i = \u2217, and \u03b3 \u2208 \u0393, we have E[\u2206g(b, i, \u03b3)] \u2265 E[\u2206g(b\u2032, i, \u03b3)].\nIntuitively, we can view b as partial information about states of items i in a random realization a \u2208 \u0393n, with bi = \u2217 meaning the state of item i is unknown. Then g measures the utility of that information, and E[\u2206g(b, i, \u03b3)] is the expected increase in utility that would result from discovering the state of i.\nFor g : (\u0393\u222a{\u2217})n \u2192 Z\u22650 with goal value Q, and b \u2208 (\u0393\u222a{\u2217})n and i \u2208 N , where bi = \u2217, let \u03b3b,i be the state \u03b3 \u2208 \u0393 such that \u2206g(b, i, \u03b3) is minimized (if more than one minimizing state exists, choose one arbitrarily). Thus \u03b3b,i is the state of item i that would produce the smallest increase in utility, and thus is \u201cworst-case\u201d in terms of utility gain, if we start from b and then discover the state of i.\nFor fixed g : (\u0393\u222a{\u2217})n \u2192 Z\u22650 with goal value Q, we define an associated quantity \u03c1, as follows:\n\u03c1 := min \u2206g(b, i, \u03b3)\nQ\u2212 g(b) where the minimization is over b, i, \u03b3, where b \u2208 (\u0393 \u222a {\u2217})n such that g(b) < Q, i \u2208 N , bi = \u2217, and \u03b3 \u2208 \u0393\u2212 {\u03b3b,i}.\nIntuitively, right before the state of an item i is discovered, there is a certain distance from the current utility achieved to the goal utility. When the state of that item is discovered, the distance to goal is reduced by some fraction (or possibly by zero). The size of that fraction can vary depending on the state of the item. In the definition of \u03c1, we are concerned with the value of that fraction, not for the worst-case state in this case (leading to the smallest fraction), but for the next-to-worst case state. The parameter \u03c1 is the smallest possible value for this fraction, starting from any partial realization, and considering any item i whose state is about to be discovered.\nAn instance of the Scenario SC problem is a tuple (g,Q, S,w, c), where g : (\u0393\u222a{\u2217})n \u2192 Z\u22650 is an integer-valued, monotone submodular utility function with goal value Q > 0, S \u2286 \u0393n, w : S \u2192 Zn>0 assigns a weight to each realization a \u2208 S, and c \u2208 Rn>0 is a cost vector. We consider a setting where we select items without repetition from the set of items N , and the states of the items correspond to an initially unknown realization a \u2208 \u0393n. Each time we select an item, the state ai of the item is revealed. The selection of items can be adaptive, in that the next item chosen can depend on the states of the previous items. We continue to choose items until g(b) = Q, where b is the partial realization representing the states of the chosen items.\nThe Scenario SC problem asks for an adaptive order in which to choose the items (i.e., a strategy), until goal value Q is achieved, such that the expected sum of the costs of the chosen items is minimized. The expectation is with respect to the distribution on \u0393n that is proportional to the weights on the assignments in the sample: Pr[a] = 0 if a 6\u2208 S, and Pr[a] = w(a)W otherwise, where W = \u2211 a\u2208S w(a). We call this the sample distribution defined by S and w and denote it by DS,w. The strategy corresponds to a decision tree. The internal nodes of the tree are labeled with items i \u2208 N , and each such node has one child for each state \u03b3 \u2208 \u0393. Each root-leaf path in the tree is associated with a partial realization b such that for each consecutive pairs of nodes v and v\u2032 on the path, if i is the label of v, and v\u2032 is the \u03b3-child of v, then bi = \u03b3. If i does not label any node in the path, then bi = \u2217. The tree may be output in an implicit form (for example, in terms of a greedy rule), specifyng how to determine the next item to choose, given the previous items chosen and their states. Although realizations a 6\u2208 S do not contribute to the expected cost of the strategy, we require the strategy to achieve goal value Q on all realizations a \u2208 \u0393n.\nWe will make frequent use of a construction that we call the standard OR construction (cf. Guillory and Bilmes (2011); Deshpande et al. (2014)). It is a method for combining two monotone submodular utility functions g1 and g2 defined on (\u0393\u222a {\u2217})n, and values Q1 and Q2, into a new monotone submodular utility function g. For b \u2208 (\u0393 \u222a {\u2217})n,\ng(b) = Q1Q2 \u2212 (Q1 \u2212 g1(b))(Q2 \u2212 g2(b))\nSuppose that on any a \u2208 \u0393n, g1(a) = Q1 or g2(a) = Q2. Then, g(a) = Q1Q2 for all a \u2208 \u0393n."}, {"heading": "3. Mixed Greedy", "text": "The Mixed Greedy algorithm is a generalization of the approximation algorithm developed by Cicalese et al. for the Equivalence Class Determination problem. That algorithm effectively solves the Scenario Submodular Cover problem for a particular \u201cPairs\u201d utility\nfunction associated with Equivalence Class Determination. In contrast, Mixed Greedy can be used on any monotone, submodular utility function g.\nFollowing Cicalese et al., we present Mixed Greedy as outputting a decision tree. If the strategy is only to be used on one realization, it is not necessary to build the entire tree. While Mixed Greedy is very similar to the algorithm of Cicalese et al, we describe it fully here so that our presentation is self-contained."}, {"heading": "3.1. Algorithm", "text": "The Mixed Greedy algorithm builds a decision tree for Scenario SC instance (g,Q, S,w, c). The tree is built top-down. It has approximately optimal expected cost, with respect to the sample distribution DS,w defined by S and w. Each internal node of the constructed tree has |\u0393| children, one corresponding to each state \u03b3 \u2208 \u0393. We refer to the child corresponding to \u03b3 as the \u03b3-child.\nThe Mixed Greedy algorithm works by calling the recursive function MixedGreedy, whose pseudocode we present in Algorithm 1. In the initial call to MixedGreedy, b is set to be equal to (\u2217, . . . , \u2217). Only the value of b changes between the recursive calls; the other values remain fixed. Each call to MixedGreedy constructs a subtree of the full tree for g, rooted at a node v of that tree. In the recursive call that builds the subtree rooted at v, b is the partial realization corresponding to the path from the root to v in the full tree: bi = \u03b3 if the path includes a node labeled i and its \u03b3-child, and bi = \u2217 otherwise.\nThe algorithm of Cicalese et al. for the Equivalence Class Determination problem is essentially the same as our Mixed Greedy algorithm, for g equal to their \u201cPairs\u201d utility function. (There is one small difference \u2013 in their algorithm, the first stage ends right before the greedy step in which the budget B would be exceeded, whereas we allow the budget to be exceeded in the last step.) Like their algorithm, our Mixed Greedy algorithm relies on a greedy algorithm for the Budgeted Submodular Cover problem due to Wolsey. We describe Wolsey\u2019s algorithm in detail in Appendix A.1.\nIf g(b) = Q, then MixedGreedy returns an (unlabeled) single node, which will be a leaf of the full tree for g. Otherwise, MixedGreedy constructs a tree T . It does so by computing a special realization called \u03c3, and then iteratively using \u03c3 to construct a path descending from the root of this subtree, which is called the backbone. It uses recursive calls to build the subtrees \u201changing\u201d off the backbone. The backbone has a special property: for each node v\u2032 in the path, the successor node in the path is the \u03c3i child of v\n\u2032, where i is the item labeling node v\u2032.\nThe construction of the backbone is done as follows. Using subroutine FindBudget, MixedGreedy first computes a lower bound B on the minimum additional cost required in order to achieve a portion \u03b1 of the goal value Q, assuming we start with partial realization b (Step 6). This computation is done using the Greedy algorithm of Wolsey (1982) described in Section A.1 in the Appendix.\nAfter calculating B, MixedGreedy constructs the backbone in two stages, using a different greedy criterion in each to determine which item i to place in the current node. In the first stage, corresponding to the first repeat loop of the pseudocode, the goal is to remove weight (probability mass) from the backbone, as cheaply and as soon as possible. That is, consider a realization a \u2208 \u0393n to be removed from the backbone (or \u201ccovered\u201d) if\nAlgorithm 1\nProcedure MixedGreedy(g,Q, S,w, c, b)\n1: If g(b) = Q then return a single (unlabeled) leaf l 2: Let T be an empty tree 3: N \u2032 \u2190 {i : bi = \u2217} 4: For i \u2208 N \u2032, \u03c3i \u2190 arg min\n\u03b3\u2208\u0393 \u2206g(b, i, \u03b3)\n5: Define g\u2032 : 2N \u2032 \u2192 Z\u22650 such that for all U \u2286 N \u2032, g\u2032(U) = g(bU )\u2212 g(b), where bU is the extension\nof b produced by setting bi = \u03c3i for all i \u2208 U . 6: B \u2190 FindBudget(N \u2032, g\u2032, c), spent\u2190 0, spent2 \u2190 0, k \u2190 1 7: I \u2190 {i \u2208 N \u2032|ci \u2264 B} 8: For all R \u2286 I, define DR := {a \u2208 S|a b and ai 6= \u03c3i for some i \u2208 R} 9: Define h : 2I \u2192 Z\u22650 such that for all R \u2286 I, h(R) = \u2211 a\u2208DR w(a)\n10: R\u2190 \u2205 11: repeat 12: Let i be an item which maximizes h(R\u222a{i})\u2212h(R)ci among all items i \u2208 I 13: Let tk be a new node labeled with item i 14: If k = 1 then make t1 the root of T 15: else make tk the \u03c3j-child of tk\u22121 16: j \u2190 i 17: for every \u03b3 \u2208 \u0393 such that \u03b3 6= \u03c3i do 18: T \u03b3 \u2190 MixedGreedy(g,Q, S,w, c, bi\u2190\u03b3) 19: Attach T \u03b3 to T by making the root of T \u03b3 the \u03b3-child of tk 20: bi \u2190 \u03c3i, R\u2190 R \u222a {i}, I \u2190 I \u2212 {i}, spent\u2190 spent+ ci, k \u2190 k + 1 21: until spent \u2265 B 22: repeat 23: Let i be an item which maximizes \u2206g(b,i,\u03c3i)ci among all items i \u2208 I 24: Let tk be a node labeled with item i 25: Make tk the \u03c3j-child of tk\u22121 26: j \u2190 i 27: for every \u03b3 \u2208 \u0393 such that \u03b3 6= \u03c3i do 28: T \u03b3 \u2190 MixedGreedy(g,Q, S,w, c, bi\u2190\u03b3) 29: Attach T \u03b3 to T by making the root of T \u03b3 the \u03b3-child of tk 30: bi \u2190 \u03c3i, I \u2190 I \u2212 {i}, spent2 \u2190 spent2 + ci, k \u2190 k + 1 31: until spent2 \u2265 B or I = \u2205 32: T \u2032 \u2190 MixedGreedy(g,Q, S,w, c, b); Attach T \u2032 to T by making the root of T \u2032 the \u03c3j-child of tk\u22121\n33: Return T\nProcedure FindBudget(I, f, c)\n1: Let \u03b1 = 1\u2212 e\u2212\u03c7 \u2248 0.35 2: Do a binary search in the interval [0, \u2211 i\u2208I ci] to find the smallest B such that Wolsey\u2019s\ngreedy algorithm for maximizing a submodular function within a budget of B, applied to f and the items in I, returns a set of items with utility at least \u03b1f(I)\n3: Return B\ni labels a node in the spine and ai 6= \u03c3i; removing a from the backbone results in the loss of weight w(a) from the backbone. The greedy choice used in the first stage in Step 12 follows the standard rule of maximizing bang-for-the-buck; the algorithm chooses i such that the amount of probability mass removed from the backbone, divided by the cost ci, is maximized. However, in making this greedy choice, it only considers items that have cost at most B. The first stage ends as soon as the total cost of the items in the chosen sequence is at least B. For each item i chosen during the stage, bi is set to \u03c3i.\nIn the second stage, corresponding to the second repeat loop, the goal is to increase utility as measured by g, under the assumption that we already have b, and that the state of each remaining item i is \u03c3i. The algorithm again uses the bang-for-the-buck rule, choosing the i that maximizes the increase in utility, divided by the cost ci (Step 23). In making this greedy choice, it again considers only items that have cost at most B. The stage ends as soon as the total cost of the items in the chosen sequence is at least B. For each item i chosen during the stage, bi is set to \u03c3i.\nIn Section 2, we defined the value \u03c1. The way the value B is chosen guarantees that the updates to b during the two greedy stages cause the value of Q \u2212 g(b) to shrink by at least a fraction \u03c1 before each recursive call. In Appendix A, we prove this fact and use it to prove the following theorem.\nTheorem 1 Mixed Greedy is an approximation algorithm for the Scenario Adaptive Submodular Cover problem that achieves an approximation factor of O(1\u03c1 logQ)."}, {"heading": "4. Scenario Mixed Greedy", "text": "We now present a variant of Mixed Greedy that eliminates the dependence on \u03c1 in the approximation bound in favor of a dependence on m, the size of the sample. We call this variant Scenario Mixed Greedy.\nScenario Mixed Greedy works by first modifying g to produce a new utility function gS , and then running Mixed Greedy with gS , rather than g. Utility function gS is produced by combining g with another utility function hS , using the standard OR construction described at the end of Section 2. Here hS : (\u0393 \u222a {\u2217})n \u2192 Z\u22650, where hS(b) = m\u2212 |{a \u2208 S : a b}| and m = |S|. Thus hS(b) is the total number of assignments that have been eliminated from S because they are incompatible with the partial state information in b. Utility m for hS is achieved when all assignments in S have been eliminated. Clearly, hS is monotone and submodular.\nWhen the OR construction is applied to combine g and hS , the resulting utility function gS reaches its goal value Qm when all possible realizations of the sample have been eliminated or when goal utility is achieved for g.\nIn an on-line setting, Scenario Mixed Greedy uses the following procedure to determine the adaptive sequence of items to choose on an initially unknown realization a."}, {"heading": "Scenario Mixed Greedy:", "text": "1. Construct utility function gS by applying the standard OR construction to g and\nutility function hS .\n2. Adaptively choose a sequence of items by running Mixed Greedy for utility function gS with goal value Qm, with respect to the sample distribution DS,w.\n3. After goal value Qm is achieved, if the final partial realization b computed by Mixed Greedy does not satisfy g(b) = Q, then choose the remaining items in N in a fixed but arbitrary order until g(b) = Q.\nThe third step in the procedure is present because goal utility Q must be reached for g even on realizations a that are not in S.\nTheorem 2 Scenario Mixed Greedy is an approximation algorithm for the Scenario Submodular Cover problem that achieves an approximation factor of O(logQm), where m is the size of sample S.\nProof Scenario Mixed Greedy achieves utility value Q for g when run on any realization a \u2208 \u0393n, because the b computed by Mixed Greedy is such that a b, and the third step ensures that Q is reached.\nLet c(g) and c(gS) denote the expected cost of the optimal strategies for the Scenario SC problems on g and gS respectively, with respect to the sample distribution DS,w. Let \u03c4 be an optimal strategy for g achieving expected cost c(g). It is also a valid strategy for the problem on gS , since it achieves goal utility Q for g on all realizations, and hence achieves goal utility Qm for gS on all realizations. Thus c(gS) \u2264 c(g).\nThe two functions, g and hS , are monotone and submodular. Since the function gS is produced from them using the standard OR construction, gS is also monotone and submodular. Let \u03c1S be the value of parameter \u03c1 for the function gS . By the bound in Theorem 1, running Mixed Greedy on gS , for the sample distribution DS,w, has expected cost that is at most a O( 1\u03c1S logQm) factor more than c(gS). Its expected cost is thus also within an O( 1\u03c1S logQm) factor of c(g). Making additional choices on realizations not in S, as done in the last step of Scenario Mixed Greedy, does not affect the expected cost, since these realizations have zero probability.\nGeneralizing an argument from Cicalese et al. (2014), we now prove that \u03c1S is lower bounded by a constant fraction. Consider any b \u2208 (\u0393 \u222a {\u2217})n and i \u2208 N such that bi = \u2217, and any \u03b3 \u2208 \u0393 where \u03b3 6= \u03b3b,i. Let Cb = |S| \u2212 hS(b) = |{a \u2208 S | a b}|. Since the sets {a \u2208 S | a b and ai = \u03b3} and {a \u2208 S | a b and ai = \u03b3b,i} are disjoint, it is not possible for both of them to have size greater than Cb2 . It follows that \u2206hS(b, i, \u03b3) \u2265 Cb 2 or \u2206hS(b, i, \u03b3b,i) \u2265 Cb2 or both. By the construction of gS , it immediately follows that \u2206gS(b, i, \u03b3) \u2265 (Q\u2212g(b))Cb2 or \u2206gS(b, i, \u03b3b,i) \u2265 (Q\u2212g(b))Cb 2 or both. Since \u03b3b,i is the \u201cworstcase\u201d setting for bi with respect to gS , it follows that \u2206gS(b, i, \u03b3) \u2265 \u2206gS(b, i, \u03b3b,i), and so in all cases \u2206gS(b, i, \u03b3) \u2265 (Q\u2212g(b))Cb2 . Also, (Q\u2212 g(b))Cb = Qm\u2212 gS(b). Therefore, \u03c1S \u2265 1 2 . The theorem follows from the bound given in Theorem 1."}, {"heading": "5. Scenario Adaptive Greedy", "text": "Scenario Adaptive Greedy works by first constructing a utility function gW , produced by applying the standard OR construction to g and utility function hW . Here hW : (\u0393 \u222a {\u2217})n \u2192 Z\u22650, where hW (b) = W \u2212 \u2211 a\u2208S:a bw(a). Intuitively, hW (b) is the total weight of assignments that have been eliminated from S because they are incompatible with the partial\nstate information in b. Utility W is achieved for hW when all assignments in S have been eliminated. It is obvious that hW is monotone and submodular. The function gW reaches its goal value QW when all possible realizations of the sample have been eliminated or when goal utility is achieved for g. Once gW is constructed, Scenario Adaptive Greedy runs Adaptive Greedy on gW .\nIn an on-line setting, Scenario Adaptive Greedy uses the following procedure to determine the adaptive sequence of items to choose on an initially unknown realization a."}, {"heading": "Scenario Adaptive Greedy:", "text": "1. Construct modified utility function gW by applying the standard OR construction to g and utility function hW .\n2. Run Adaptive Greedy for utility function gW with goal value QW , with respect to sample distribution DS,w, to determine the choices to make on a.\n3. After goal value QW is achieved, if the partial realization b representing the states of the chosen items of a does not satisfy g(b) = Q, then choose the remaining items in N in arbitrary order until g(b) = Q.\nIn Appendix C, we prove the following lemma.\nLemma 3 Utility function gW is adaptive submodular with respect to sample distribution DS,w.\nThe consequence of Lemma 3 is that we may now use any algorithm designed for adaptive submodular utility functions. This gives us Theorem 4.\nTheorem 4 Scenario Adaptive Greedy is an approximation algorithm for the Scenario Adaptive Submodular Cover problem that achieves an approximation factor of O(logQW ), where W is the sum of the weights on the realizations in S.\nProof Since gW is produced by applying the OR construction to g and hW , which are both monotone, so is gW . By Lemma 3, gW is adaptive submodular with respect to the sample distribution. Thus by the bound of Golovin and Krause on Adaptive Greedy, running that algorithm on gW yields an ordering of choices with expected cost that is at most a O(logQW ) factor more than the optimal expected cost for gW . By the analogous argument as in the proof of Theorem 2, it follows that Scenario Adaptive Greedy solves the Scenario Submodular Cover problem for g, and achieves an approximation factor of O(logQW )."}, {"heading": "Acknowledgments", "text": "L. Hellerstein thanks Andreas Krause for useful discussions at ETH, and especially for directing our attention to the bound of Streeter and Golovin for min-sum submodular cover."}, {"heading": "Appendix A. Proof of Bound for Mixed Greedy", "text": "We first discuss the algorithm of Wolsey used in FindBudget."}, {"heading": "A.1. Wolsey\u2019s Greedy Algorithm for Budgeted Submodular Cover", "text": "The Budgeted Submodular Cover problem takes as input a finite set N of items, a positive integer B > 0 called the budget, a monotone submodular set function f : 2N \u2192 Z\u22650, and a vector c indexed by the items in N , such that ci \u2208 R\u22650 for all i \u2208 N . The problem is to find a subset R \u2286 N such that \u2211 i\u2208R ci \u2264 B, and f(R) is maximized.\nWolsey (1982) developed a greedy approximation algorithm for this problem. We present the pseudocode for this algorithm here, together with Wolsey\u2019s approximation bound.\nProcedure WolseyGreedy(N, f, c, B)\n1: spent\u2190 0, R\u2190 \u2205, k \u2190 0 2: repeat 3: k \u2190 k + 1 4: Let ik be the i \u2208 N that minimizes f(R\u222a{i})\u2212f(R)ci among all i \u2208 N with ci \u2264 B 5: N \u2190 N \u2212 {i}, spent\u2190 spent+ ci, R\u2190 R \u222a {ik} 6: until spent > B or N = \u2205 7: if f({ik}) \u2265 f(R\u2212 {ik}) then 8: return {ik} 9: else\n10: return R\u2212 {ik}\nLemma 5 (Wolsey (1982)) Let R\u2217 be the optimal solution to the Budgeted Submodular Cover problem on instance (N, f, c, B). Let R = {i1, . . . , ik} be the set of items chosen by running Wolsey-Greedy(N, f, c, B). Let e be the base of the natural logarithm, and let \u03c7 be the solution to e\u03c7 = 2\u2212 \u03c7. Then f(R) \u2265 (1\u2212 e\u2212\u03c7)f(R\u2217)."}, {"heading": "A.2. Analysis of Mixed Greedy", "text": "Consider a Scenario SC instance (g,Q, S,w, c), and a partial realization b \u2208 (\u0393\u222a{\u2217})n. We now consider MixedGreedy(g,Q, S,w, c, b). It constructs a tree for the Scenario SC instance induced by b. In this induced instance, the item set is N \u2032 = {i | bi = \u2217}. Without loss of generality, assume that N \u2032 = {1, . . . , n\u2032} for some n\u2032. For d \u2208 (\u0393 \u222a {\u2217})n such that d b, define \u03bd(d) be the restriction of d to the items in N \u2032. For d\u2032 \u2208 (\u0393 \u222a {\u2217})n\u2032 , \u03bd\u22121(d\u2032) denotes the extension d d\u2032 to all elements in N such that di = d\u2032i for i \u2208 N \u2032 and di = bi otherwise.\nThe utility function g\u2032 : (\u0393\u222a{\u2217})n\u2032 \u2192 Z\u22650 for the instance induced by b is a function on partial realizations d\u2032 of the items in N \u2032. Specifically, for d\u2032 \u2208 (\u0393\u222a{\u2217})n\u2032 , g\u2032(d\u2032) = g(\u03bd\u22121(d\u2032)). The sample S\u2032 in the induced instance consists of the restrictions of the realizations in {a \u2208 S | a b} to the items in N \u2032. That is, S\u2032 = {\u03bd(a) | a \u2208 S, a b}. Note that each realization in S\u2032 corresponds to a unique realization in S. The weight function w\u2032 for the induced instance is such that for all d\u2032 \u2208 S\u2032, w\u2032(d\u2032) = w(\u03bd\u22121(d\u2032)). The goal value for the induced instance is Q.\nIf g(b) = Q, then MixedGreedy(g,Q, S,w, c, b) returns the optimal tree for the instance induced by b, which is a single (unlabeled) leaf with expected cost 0. Assume g(b) < Q.\nFor any decision tree \u03c4 for the induced instance and any realization a defined over the item set N \u2032 (or over any superset of N \u2032), let \u03ba(\u03c4, a) = \u2211 i\u2208M ci, where M is the set of items labeling the nodes on the root-leaf path followed in \u03c4 on realization a. That is, \u03ba(\u03c4, a) is the cost incurred when using tree \u03c4 on realization a.\nLet \u03c4\u2217 be a decision tree that is an optimal solution for the induced instance. Let C\u2217 = E[\u03ba(\u03c4\u2217, a)] where a is a random realization drawn from DS\u2032,w\u2032 . Thus C\u2217 is the expected cost of an optimal solution to the induced instance. Let \u03c4G denote the tree output by running MixedGreedy(g,Q, S,w, c, b).\nLet \u03c3 \u2208 \u0393n\u2032 be such that for i \u2208 N \u2032, \u03c3i = arg min \u03b3\u2208\u0393 g(bi\u2190\u03b3). Thus, \u03c3 is the realization whose entries are computed in Step 4 of MixedGreedy. For each node v in the tree \u03c4G, let p\u0303(v) denote the probability that node v will be reached when using \u03c4G on a random realization a drawn from DS\u2032,w\u2032 . Let cv = ci where i is the item labeling node v. Consider the backbone constructed during the call to MixedGreedy(g,Q, S,w, c, b). The backbone consists of the nodes created during the two repeat loops in this call, excluding the recursive calls. Let Y be the set of nodes in the backbone. Let cY = \u2211 v\u2208Y p\u0303(v)cv. Thus cY is the contribution of the nodes in the backbone to the expected cost of tree \u03c4G. The following lemma says that this contribution is no more than a constant times the expected cost of the optimal tree \u03c4\u2217.\nLemma 6 cY \u2264 24C\u2217.\nLemma 6 is the key technical lemma in our analysis, and it is the proof of this lemma that constitutes the major difference between our analysis and the analysis in Cicalese et al. (2014). We defer the proof of this lemma to Section A.3. Using this lemma, it is easy to generalize the rest of the analysis of Cicalese et al. to obtain the proof of Theorem 1. The proofs in the remainder of this section closely follow the proofs in Cicalese et al. We present them so that this paper will be self-contained.\nLet B be the budget that is computed in Line 6, with FindBudget, when running MixedGreedy(g,Q, S,w, c, b). Recall the constant \u03b1 defined in FindBudget, based on the bound on Wolsey\u2019s Greedy algorithm (Lemma 5).\nLemma 7 The condition at the end of the first repeat loop (spent \u2265 B) will be satisfied. Also, \u03ba(\u03c4\u2217, \u03c3) \u2265 B.\nProof Trees \u03c4G and \u03c4\u2217 must achieve utility Q\u2212 g(b) on realization \u03c3. The binary search procedure in FindBudget finds the least budget B allowing Wolsey\u2019s greedy algorithm to achieve a total increase in utility of at least \u03b1(Q \u2212 g(b)), on realization \u03c3. It follows from the bound on Wolsey\u2019s greedy algorithm (Lemma 5) that on realization \u03c3, an increase of \u03b1(Q\u2212 g(b)) could not be achieved with a budget smaller than B. Thus, \u03ba(\u03c4\u2217, \u03c3) \u2265 B.\nThe next lemma clearly holds because in the two repeat loops, we only consider items of cost at most B, and we continue choosing items of cost at most B until a budget of B is met or exceeded. Lemma 8 \u2211\nv\u2208Y cv \u2264 4B.\nLet bfinal denote the final value of b in the last recursive call, in Line 32, when running MixedGreedy(g,Q, S,w, c, b).\nLemma 9 g(bfinal) \u2265 g(b) + 19(Q\u2212 g(b)).\nProof Recall that N \u2032 = {1, . . . , n\u2032}. For any D \u2286 N \u2032, let \u03c3\u0302D denote the extension of b, to (\u0393 \u222a {\u2217})n, such that \u03c3\u0302Di = \u03c3i (as specified in line 4 of MixedGreedy(g,Q, S,w, c, b)) for i \u2208 D, and \u03c3\u0302Di = bi otherwise.\nIt follows from the way that B was computed in FindBudget, and the fact that the value of g is Q on any (full) realization of the items in N , that there is a subset L \u2286 N \u2032 such that \u2211 i\u2208L ci = B and g(\u03c3\u0302\nL) \u2265 \u03b1(Q\u2212 g(b)) + g(b). Let Y1 and Y2 be the set of items i chosen in the first and second repeat loops respectively.\nThus bfinal = \u03c3\u0302Y1\u222aY2 . Let d1 = g(\u03c3\u0302\nY1) \u2212 g(b) represent the utility gained in the first repeat loop. Let d2 = g(\u03c3\u0302\nY1\u222aL) \u2212 g(\u03c3\u0302Y1) represent the additional utility that the items in L \\ Y1 would provide. Since g(\u03c3\u0302L) \u2265 \u03b1(Q\u2212 g(b)) + g(b) and g is monotone, g(\u03c3\u0302Y1\u222aL) \u2265 g(\u03c3\u0302L), and thus g(\u03c3\u0302Y1\u222aL) \u2265 \u03b1(Q\u2212g(b)) +g(b). So d1 +d2 \u2265 \u03b1(Q\u2212g(b)). At the end of the first repeat loop the items in Y1 have been chosen. If we were to add the items in L\\Y1 to those in Y1, it would increase the utility by d2 \u2265 \u03b1(Q\u2212 g(b))\u2212 d1. Since the items in the second repeat loop are chosen greedily with respect to g (and c) until budget B is met or exceeded, or goal value Q is attained, it follows by the approximation bound on Wolsey\u2019s algorithm (Lemma 5) that the amount of additional utility added during the second repeat loop is at least \u03b1 times the amount of additional utility that would be added by instead choosing the items in L\\Y1. We thus have g(\u03c3\u0302Y1\u222aY2)\u2212 g(\u03c3\u0302Y1) \u2265 \u03b1d2. Adding d1 to both sides, from the definition of d1 we get g(\u03c3\u0302Y1\u222aY2)\u2212g(b) \u2265 d1 +\u03b1d2. We know from above that d2 \u2265 \u03b1(Q\u2212g(b))\u2212d1 so we have g(\u03c3\u0302Y1\u222aY2) \u2212 g(b) \u2265 d1 + \u03b1 (\u03b1 (Q\u2212 g(b))\u2212 d1) \u2265 d1 + \u03b12 (Q\u2212 g(b)) \u2212 \u03b1d1 \u2265 \u03b12 (Q\u2212 g(b)). The lemma follows because the constant \u03b12 is greater than 19 .\nWe can now give the proof of Theorem 1, stating that the Mixed Greedy algorithm achieves an approximation factor of O(1\u03c1 logQ).\nProof of Theorem 1 The Mixed Greedy algorithm solves the Scenario SC instance (g,Q, S,w, c) by running recursive function MixedGreedy(g,Q, S,w, c, b). In the initial call, b is set to \u2217n.\nLet \u03c4G denote the tree that is output by running MixedGreedy(g,Q, S,w, c, b). Let \u03c4\u2217\ndenote the optimal tree for the Scenario SC instance induced by b. The expected cost of \u03c4G can be broken into the part that is due to costs incurred on items\nin the backbone in the top-level call to the MixedGreedy function, and costs incurred in the subtrees built in the recursive calls to MixedGreedy. The recursive calls in Steps 18 and 28 build subtrees of \u03c4G that are rooted at a \u03b3-child of a node labeled i, such that \u03b3 6= \u03c3i. It follows from the definition of \u03c1 that the value of the partial realization used in each of these recursive calls, bi\u2190\u03b3 is such that g(bi\u2190\u03b3)\u2212g(b) \u2265 \u03c1(Q\u2212g(b)), so g(bi\u2190\u03b3) \u2265 \u03c1(Q\u2212g(b))+g(b),\nThe remaining recursive call is performed on bfinal, and by Lemma 9, g(bfinal) \u2265 19(Q\u2212 g(b)).\nLet \u03b7 = min{\u03c1, 19}. Let b 1, . . . , bt denote the partial realizations on which the recursive calls are made, and for which the value of g on the partial realization is strictly less than Q. These are the recursive calls which result in the construction of non-trivial subtrees, with non-zero cost. Note that b1, . . . , bt may include bfinal. For all j \u2208 {1, . . . , t}, g(bj) \u2265 \u03b7(Q\u2212 g(b)) + g(b), or equivalently\nQ\u2212 g(bj) \u2264 (1\u2212 \u03b7)(Q\u2212 g(b)) (1)\nFor j \u2208 {1, . . . , t}, let \u03c4Gj denote the tree returned by the recursive call on bj . Let S\u2032 be the sample for the Scenario SC instance induced by b, so S\u2032 = {\u03bd(a) | a \u2208 A}. Let w\u2032 be the weight function for that induced instance. Let Aj = {\u03bd(a) | a \u2208 S, a bj}. Let \u00b5\u2217j denote an optimal decision tree for the Scenario SC instance induced by b\nj . Consider the optimal decision tree \u03c4\u2217 for the instance induced by b, and use it to form a decision tree \u03c4\u2217j for the instance induced by b\nj as follows: for each item i such that bi = \u2217 and bji 6= \u2217, fix i to have state b j i in the tree. That is, for any node in the tree labeled i, delete all its children except the one corresponding to state bji , and then delete the node, connecting the parent of the node to its one remaining child. Since \u00b5\u2217j is optimal for the induced problem, \u03c4\u2217j cannot have lower expected cost for this problem. It follows that\u2211\na\u2208Aj w \u2032(a)\u03ba(\u03c4\u2217j , a) \u2265 \u2211 a\u2208Aj w \u2032(a)\u03ba(\u00b5\u2217j , a). Further, since \u03ba(\u03c4 \u2217, a) \u2265 \u03ba(\u03c4\u2217j , a) for any\na \u2208 Aj , \u2211 a\u2208Aj w(a)\u03ba(\u03c4\u2217, a) \u2265 \u2211 a\u2208Aj w\u2032(a)\u03ba(\u00b5\u2217j , a). (2)\nFrom the description of MixedGreedy, it is easy to verify that the Aj are disjoint subsets of S\u2032. Therefore, \u2211\na\u2208S\u2032 w\u2032(a)\u03ba(\u03c4\u2217, a) = t\u2211 j=1 \u2211 a\u2208Aj w\u2032(a)\u03ba(\u03c4\u2217, a)\nLet W = \u2211\na\u2208S\u2032 w \u2032(a). For a \u2208 S\u2032, let p(a) be the probability assigned to a by\ndistribution DS\u2032,w\u2032 , so p(a) = w \u2032(a)/W . Let cY be the sum of the costs incurred on\nthe backbone of \u03c4G as in Lemma 6. Taking expectations with respect to DS\u2032,w\u2032 , we have E[\u03ba(\u03c4G, a)] = cY + \u2211t j=1 \u2211 a bj p(a)\u03ba(\u03c4 G j , a). We can now bound the ratio between G = E[\u03ba(\u03c4G, a)] and C\u2217 = E[\u03ba(\u03c4\u2217, a)].\nG\nC\u2217 =\n\u2211 a\u2208S\u2032 w\n\u2032(a)\u03ba(\u03c4G, a)\u2211 a\u2208S\u2032 w \u2032(a)\u03ba(\u03c4\u2217, a)\n= WcY +\n\u2211t j=1 \u2211 a\u2208Aj w\n\u2032(a)\u03ba(\u03c4Gj , a)\u2211 a\u2208S\u2032 w \u2032(a)\u03ba(\u03c4\u2217, a)\n= WcY\u2211\na\u2208S\u2032 w \u2032(a)\u03ba(\u03c4\u2217, a)\n+\n\u2211t j=1 \u2211 a\u2208Aj w\n\u2032(a)\u03ba(\u03c4Gj , a)\u2211 a\u2208S\u2032 w \u2032(a)\u03ba(\u03c4\u2217, a)\n\u2264 24 + \u2211t j=1 \u2211 a\u2208Aj w\n\u2032(a)\u03ba(\u03c4Gj , a)\u2211 a\u2208S\u2032 w \u2032(a)\u03ba(\u03c4\u2217, a) by Lemma 6\n= 24 +\n\u2211t j=1 \u2211 a\u2208Aj w\n\u2032(a)\u03ba(\u03c4Gj , a)\u2211t j=1 \u2211 a\u2208Aj w \u2032(a)\u03ba(\u03c4\u2217, a)\n\u2264 24 + max j\n\u2211 a\u2208Aj w\n\u2032(a)\u03ba(\u03c4Gj , a)\u2211 a\u2208Aj w \u2032(a)\u03ba(\u00b5\u2217j , a)\nIn the last line, we substitute \u03ba(\u03c4\u2217, a) with \u03ba(\u00b5\u2217j , a) because of (2), and we use the max because of the fact that \u2211 xi\u2211 yi \u2264 max\ni\nxi yi for xi, yi > 0.\nAs described above, for each j, the recursive call to MixedGreedy on b = bj constructs a tree \u03c4Gj for a Scenario SC instance I \u2032 induced by bj , with goal value Q\u2212 g(bj). The tree\n\u00b5\u2217j is an optimal tree for instance I \u2032. It follows that the ratio\n\u2211 a\u2208Aj\u2032\nw(a)\u03ba(\u03c4Gj ,a)\u2211 a\u2208Aj w(a)\u03ba(\u00b5\u2217j ,a) is equal to\nGj C\u2217j , where Gj and C \u2217 j are the values of C \u2217 and G for the induced instance I \u2032. Thus we have G C\u2217 \u2264 24 + maxj Gj C\u2217j .\nWe now prove that GC\u2217 \u2264 1 + 24 1 \u03b7 ln(Q \u2212 g(b)), when g(b) < Q, by induction on the total number of items n = |N |. The base case n = 1 clearly holds. Assume inductively that G C\u2217 \u2264 1 + 24 1 \u03b7 ln(Q \u2212 g(b)) when the number of items is less than n, where Q is the goal value. Then for n items, we have GC\u2217 \u2264 24 + (1 + 24 1 \u03b7 (ln(Q\u2212 g(b\nj)))) for the j maximizing Gj C\u2217j . By (1), Q\u2212 g(bj) \u2264 (1\u2212 \u03b7)(Q\u2212 g(b)) so\nG\nC\u2217 \u2264 24 +\n( 1 + 24 1\n\u03b7 ln((1\u2212 \u03b7)(Q\u2212 g(b)) ) \u2264 1 + 24 ( 1 + 1\n\u03b7 ln((1\u2212 \u03b7)(Q\u2212 g(b)) ) = 1 + 24 ( 1 + 1\n\u03b7 ln(1\u2212 \u03b7) + 1 \u03b7 ln(Q\u2212 g(b))\n)\n\u2264 1 + 241 \u03b7 ln(Q\u2212 g(b))\nwhere the last inequality holds because 1\u2212\u03b7 \u2264 e\u2212\u03b7 so log(1\u2212\u03b7) \u2264 \u2212\u03b7 and thus 1\u03b7 ln(1\u2212\u03b7) \u2264 \u22121.\nSince Q \u2265 Q\u2212 g(b), the expected cost of the greedy tree \u03c4G constructed by the Mixed Greedy algorithm is within an O( 1\u03b7 lnQ) factor of the expected cost of the optimal tree. Also, since \u03b7 = min{\u03c1, 19}, we know that 1 \u03b7 is either constant or it is equal to 1 \u03c1 . We therefore have that the expected cost of \u03c4G is within an O(1\u03c1 logQ) factor of the expected cost of the optimal tree."}, {"heading": "A.3. Proof of Lemma 6", "text": "We now present our proof bounding the expected cost incurred on the backbone of the greedy tree. Our proof relies heavily on the work of Streeter and Golovin (2009) on the Min-Sum Submodular Cover problem. We use some of their terminology and definitions in our proof."}, {"heading": "A.3.1. Definitions", "text": "We begin by defining a discrete version of the Min-Sum Submodular Cover problem. Let N = {1, . . . , n} be a set of items, and let c \u2208 Zn\u22650 be a non-negative integer vector of \u201ctimes\u201d associated with those items. Let f : 2N \u2192 Z\u22650 be a monotone, submodular utility function and let Q = f(N). We define a schedule to be a finite sequence S = \u3008(i1, \u03c41), . . . , (im, \u03c4m)\u3009 of pairs in N \u00d7 R\u22650 and refer to \u03c4j as the time to process item ij .\nFor a schedule S, we define `(S) = \u2211\nj\u22651 \u03c4j to be the sum of the times spent on all items in S. Given a schedule S = \u3008(v1, \u03c41), (v2, \u03c42), . . . \u3009, we define S\u3008t\u3009 to be the schedule such that for t \u2264 `(S),\nS\u3008t\u3009 = \u3008(v1, \u03c41), (v2, \u03c42), . . . , (vk, \u03c4k), (vk+1, t\u2212 \u2211k i=1 \u03c4i)\u3009\nwhere k = max{j : \u2211j\ni=1 \u03c4i < t}. For t > `(S), we let S\u3008t\u3009 = S. We refer to S\u3008t\u3009 as S truncated at time t.\nLet f c denote the function defined on schedules S such that f c(S) = 1f(N)f({i | (i, ci) \u2208 S}). Thus, the only pairs (i, \u03c4) in the schedule that contribute to the value of f c are those for which \u03c4 = ci. Where c is understood, we will omit the superscript and use f to denote both the original utility function on 2N , and the function f c which is defined on schedules.\nWe define the cost of schedule S, with respect to f and c, to be\ncost(f c, S) = \u222b `(S) t=0 1\u2212 f c(S\u3008t\u3009)dt (3)\nWe define the Discrete Min-Sum Submodular Cover Problem on f and c to be the problem of finding a schedule S that achieves f c(S) = 1 with minimum cost.\nStreeter and Golovin presented a greedy algorithm for the general Min-Sum Submodular Cover problem. In Discrete Min-Sum Submodular Cover, a pair (i, \u03c4) can only contribute to the utility of a schedule if \u03c4 = ci. The general problem studied by Streeter and Golovin does not have this restriction."}, {"heading": "A.3.2. Standard Greedy Algorithm for Discrete Min-Sum Submodular Cover", "text": "The algorithm of Streeter and Golovin for the general Min-Sum Submodular Cover problem uses a standard greedy approach. It adds pairs (i, \u03c4) iteratively to the end of an initially empty schedule, using the greedy rule of choosing the pair that will result in the largest increase in utility per unit time. We call this algorithm Standard Greedy.\nWe restrict our attention to the Discrete Min-Sum Submodular Cover problem. Applied to this problem, Standard Greedy uses the greedy rule of choosing the pair (i, ci) that will result in the largest increase in utility as measured by f c, per unit time. The algorithm ends when the constructed schedule S satisfies f c(S) = 1.\nMore formally, Standard Greedy uses the greedy rule below to construct a greedy schedule G = \u3008(g1, \u03c41), (g2, \u03c42), . . . \u3009, where each gj = i for some i \u2208 N , and \u03c4i = ci. Since each \u03c4i is determined by gi, we drop the \u03c4i from the description of the schedule, and consider G to be simply a list of actions g = \u3008g1, g2, . . . , \u3009.\nWe define Gj = \u3008g1, g2, . . . gj\u22121\u3009, where G1 = \u3008 \u3009. The action gj chosen using the greedy rule is as follows (using \u2295 to represent the concatenation of two schedules):\ngj = arg max (i,ci)|i\u2208N\n{ f(Gj \u2295 \u3008(i, ci)\u3009)\u2212 f(Gj)\nci\n} (4)\nThe following theorem of Streeter and Golovin shows that the schedule constructed by Standard Greedy has a cost that is within a factor of 4 of the cost achieved by any schedule (including the optimal schedule).\nTheorem 10 (Streeter and Golovin (2009)) Let I be an instance of the Discrete MinSum Submodular Cover problem with time vector c, monotone submodular utility function f , and item set N . Let S denote the set of all schedules S for item set N and cost vector c that satisfy f c(S) = 1. Let G be the schedule constructed by running Standard Greedy algorithm on instance I. Then for all S \u2208 S, cost(f c, G) \u2264 4 cost(f c, S)."}, {"heading": "A.3.3. Bound on Cost of MixedGreedy", "text": "We now return to our analysis of MixedGreedy(g,Q, S,w, c, b). As part of our analysis, we will prove a result similar to Theorem 10.\nWithout loss of generality, assume that b = \u2217n. Recall that cY = \u2211 v\u2208Y p\u0303(v)cv, where Y is the set of nodes in the backbone, p\u0303(v) is the probability that a random realization will reach node v, and cv is the cost of the item labeling node v. Let SY = \u3008(i1, ci1), . . . , (ik\u22121, cik\u22121)\u3009 be the schedule such that i1, . . . , ik\u22121 is the sequence of items labeling the nodes in the backbone, from the top of the backbone and moving downwards.\nDefine a utility function hp : 2 N \u2192 R\u22650 such that for R \u2208 2N , hp(R) = 1\u2212 \u2211 a \u03c3R p(a), where \u03c3R is the realization in \u0393n such that \u03c3Ri = \u03c3i for i \u2208 R, and \u03c3Ri = \u2217 otherwise. The function hp is clearly monotone and submodular. Additionally, we can see that \u2211 v\u2208Y p\u0303(v)cv is the cost of schedule SY with respect to utility function utility function hp. Recall that \u03c4\u2217 denotes the optimal strategy solving the Scenario Submodular Cover instance on g and c. Consider the sequence j1, . . . , jt of items chosen by \u03c4 \u2217 on realization \u03c3.\nLet S\u2217 = \u3008(j1, cj1), . . . , (jt, cjt)\u3009. The schedule SY created by MixedGreedy is constructed greedily, using the same type of greedy rule as in (4). However, SY is constructed in two stages: the first stage greedily chooses with respect to hp, and the second chooses greedily with respect to an entirely different utility function. We therefore cannot directly apply Theorem 10 to bound the cost of schedule SY . We deal with this by using an approach analogous to one used by Cicalese et al. (2014) (in the analysis of their Equivalence Class Determination algorithm) that allows us to concentrate only on the cost of the portion of the schedule constructed during the first stage.\nTo do this, we note that schedule SY can be expressed as the concatenation of two schedules, S1 and S2, where S1 contains the ij chosen during the first repeat loop, with their costs, and S2 contains the ij chosen during the second, also with their costs. Recall that \u2211 v\u2208Y p\u0303(v)cv is the cost of schedule S\nY with respect to hp. We can express this cost as follows:\n\u2211 v\u2208Y p\u0303(v)cv = \u222b `(S1) t=1 1\u2212 hp(S1\u3008t\u3009)dt+ \u222b `(S2) t=0 1\u2212 hp(S1 \u2295 S2\u3008t\u3009)dt\nNote that `(S2) \u2264 2B, since we have assumed that each ci \u2264 B, and the second repeat loop of MixedGreedy ends as soon as the last item added causes the length of S2 to exceed B. Since hp is monotone, the value of the second integral is at most 2B(1 \u2212 hp(S1)), and the value of the first integral is at least B(1 \u2212 hp(S1)) because `(S1) \u2265 B. It follows that the value of the second integral is at most twice the value of the first, so we have\n\u2211 v\u2208Y p\u0303(v)cv \u2264 3 \u222b `(S1) t=0 1\u2212 hp(S1\u3008t\u3009)dt\nwhich yields the following inequality, allowing us to bound the total cost of SY by analyzing the cost of S1.\ncost(hp, S Y ) \u2264 3 cost(hp, S1) (5)\nTherefore, to prove Lemma 6, it suffices to bound \u222b `(S1) t=0 1\u2212hp(S 1 \u3008t\u3009)dt, which is the cost of schedule S1 with respect to hp. Schedule S1 selects items greedily with respect to hp. However, we cannot apply Theorem 10 to bound the cost of S1 in terms of the cost of S \u2217, because only items of cost at most B are considered in greedily forming S1, while items of cost greater than B may be included in S\u2217.\nWe will instead bound the cost of S1 in terms of the cost of the truncated schedule S\u2217\u3008B\u3009. To do this, we will prove a lemma that is similar to Theorem 10. We defer its proof to the next section, since it is somewhat technical and is similar to the proof of Theorem 10. The definitions of Gj and d are as given in the previous section.\nThe statement of the lemma is as follows.\nLemma 11 Let I be an instance of the Discrete Min-Sum Submodular Cover problem with time vector c, utility function f , and item set N . Let S denote the set of all schedules S for item set N and cost vector c satisfying f c(S) = f(N). Let G = \u3008g1, g2, . . . \u3009 be the schedule\nconstructed by running Standard Greedy on instance I and let Gj = \u3008g1, g2, . . . gj\u22121\u3009, where G1 = \u3008 \u3009. Let B \u2208 R be such that `(G) \u2265 B and let d be the maximum j such that `(Gj) < B. For any schedule S \u2208 S, cost(f,Gd) \u2264 4 cost(f, S\u3008B\u3009). Further, cost(f,Gd+1) \u2264 8 cost(f, S\u3008B\u3009).\nWe now show how to use Lemma 11 to prove Lemma 6. Let m be such that S\u2217\u3008B\u3009 = \u3008(j1, cj1), . . . , (jm\u22121, cjm\u22121), (jm, \u03c4jm)\u3009. By the definition of schedule truncation, \u03c4jm \u2264 cjm . Since the length of S\u2217\u3008B\u3009 is B, each of cj1 , . . . , cjm\u22121 is at most B, but it is possible that cjm > B.\nConsider a restricted version I \u2032 of our current Min-Sum Submodular Cover instance I in which we include only those items i \u2208 N such that ci \u2264 B. Let N \u2032 be the set of those items. Let S\u2032 be the schedule that results from concatenating \u3008(j1, cj1), . . . , (jm\u22121, cjm\u22121)\u3009 with an arbitrary sequence of pairs (i, ci) with i \u2208 N \u2032, such that hp(S\u2032) = hp(N \u2032). Let `\u2032 denote `(\u3008(j1, cj1), . . . , (jm\u22121, cjm\u22121\u3009). Comparing S\u2032\u3008B\u3009 to S \u2217 \u3008B\u3009, both have the same first m\u22121 elements. Schedule S\u2217\u3008B\u3009 then has (jm, \u03c4jm) where \u03c4jm = B\u2212` \u2032, whereas schedule S\u2032\u3008B\u3009 may then have multiple elements in N \u2032 \u00d7 Z\u22650 which together have length B \u2212 `\u2032. Because hp is monotone, and the cost of hp on schedule S \u2217 \u3008B\u3009 is cost(hp, S \u2217 \u3008B\u3009) = \u222b B t=0 1\u2212 hp(S \u2217 \u3008t\u3009)dt, and analogously for S\u2032\u3008B\u3009, it immediately follows that\ncost(hp, S \u2032 \u3008B\u3009) \u2264 cost(hp, S \u2217 \u3008B\u3009) (6)\nNow consider the schedule S1 that is computed during the the first stage of running MixedGreedy. Let G\u2032 be the greedy schedule produced by running the Greedy algorithm on instance I \u2032, with utility function hp and times c. Because only items i with ci \u2264 B are considered when S1 is constructed, and items are chosen greedily with respect to hp, S\n1 is a prefix of G\u2032.\nLet d be such that S1 = \u3008(i1, ci1), . . . , (id, cid)\u3009. Thus, S1 = G\u2032d+1. in particular, we have that `(S1) \u2265 B and `(\u3008(i1, ci1), . . . , (id\u22121, cid\u22121)\u3009) < B. It follows from (6) and from Lemma 11 that\ncost(hp, S 1) \u2264 8 cost(hp, S\u2032\u3008B\u3009) \u2264 8 cost(hp, S \u2217 \u3008B\u3009) (7)\nand therefore cost(hp, S 1) \u2264 8 cost(hp, S\u2217) (8)\nWe have that cost(hp, S Y ) \u2264 3 cost(hp, S1). We also have that cY = cost(hp, SY ) and\nC\u2217 = cost(hp, S \u2217). Therefore, we have\ncY = cost(hp, S Y ) \u2264 3 cost(hp, S1) \u2264 24 cost(hp, S\u2217) = 24C\u2217\nA.4. Proof of Lemma 11, approximation bounds for truncated schedules\nWe prove Lemma 11, which states that the following two properties hold:\nProperty 1: cost(f,Gd) \u2264 4 cost(f, S\u3008B\u3009)\nProperty 2: cost(f,Gd+1) \u2264 8 cost(f, S\u3008B\u3009)\nThe proof is similar to the proof of Streeter and Golovin for Theorem 10. 3 We will assume that f : 2N \u2192 [0, 1]. We can transform any f : 2N \u2192 R\u22650 into a function of this type by scaling f so that for all S \u2208 2N , the scaled version of f(S) is equal to f(S)\u2212f(\u2205)f(N)\u2212f(\u2205) .\nRecall that f c is the function defined on schedules S such that f c(S) = 1f(N)f({i | (i, ci) \u2208 S}). We call f c a job. We refer to a pair (i, \u03c4) \u2208 N \u00d7R\u22650 as an action and to \u03c4 as the time taken by that action.\nAs in Section A.3, let G = \u3008(g1, \u03c41), (g2, \u03c42), . . . \u3009, denote the schedule computed by the Greedy algorithm on I and let Gj = \u3008g1, g2, . . . gj\u22121\u3009. et S be an arbitrary schedule for the instance with f(S) = f(N). Let d be the maximum j such that `(Gj) < B.\nWe may assume without loss of generality that for every (i, \u03c4) in S, \u03c4 = ci, since f c does not gain any value from pairs (i, \u03c4) with \u03c4 6= ci. As before, we will generally omit the superscript on f c and simply write f(S).\nWe begin by showing that Property 1 implies Property 2. Property 1 \u21d2 Property 2: We define fGd(S), a new function defined on schedules that is derived from f . Intuitively, Gd completes some portion of the job f ; we wish to consider the portion of the job that remains to be completed after the actions in Gd have been performed. The function fGd(S) is defined to be the portion of the job completed by first executing schedule Gd and then executing schedule S. We express this as fGd(S) = f(Gd \u2295 S). Note that fGd still satisfies the essential conditions for a job as it is monotone and submodular. It should be noted, however, that unless f(Gd) = 0, then fGd(\u3008\u3009) 6= 0 (equivalently, due to monotonicity, there is no schedule S for which fGd(S) = 0).\nIt is easy to show that the cost(fGd , S) represents the additional cost incurred by schedule S on job f after the schedule Gd has already been executed.\ncost(fGd , S) = \u222b `(S) t=0 ( 1\u2212 fGd(S\u3008t\u3009) ) dt\n= \u222b `(S) t=0 ( 1\u2212 f(Gd \u2295 S\u3008t\u3009) ) dt\n= \u222b `(Gd\u2295S) t=`(Gd) ( 1\u2212 f ( (Gd \u2295 S)\u3008t\u3009 )) dt\n= \u222b `(Gd\u2295S) t=0 ( 1\u2212 f ( (Gd \u2295 S)\u3008t\u3009 )) dt\u2212 \u222b `(Gd) t=0 ( 1\u2212 f(Gd \u3008t\u3009) ) dt\nTherefore, we have\ncost(f,Gd) + cost(fGd , S) = cost(f,Gd \u2295 S) (9)\nProperty 1 asserts that cost(f,Gd) \u2264 4 cost(f, S\u3008B\u3009) for any schedule S \u2208 S. STOPPED HERE Also from this assumption, the greedy schedule for fGd is within a factor of 4 of any other schedule for fGd . Additionally, if we look at only the first action of the greedy\n3. Although we give a proof only for Discrete Min-Sum Submodular Cover, the proof can easily be adapted to give the same result for the more general Min-Sum Submodular Cover problem considered by Streeter and Golovin.\nschedule for fGd (i.e. action gd), the cost incurred by this one action is less than that of the entire greedy schedule for fGd , which in turn is less than 4 times any other schedule for fGd . Thus, we also have that cost(fGd , \u3008gd\u3009) \u2264 4 cost(fGd , S\u2217\u3008B\u3009). Therefore, we have\ncost(f,Gd+1) = cost(f,Gd) + cost(fGd , \u3008gd\u3009) (by (9)) \u2264 4 cost(f, S\u2217\u3008B\u3009) + 4 cost(fGd , S \u2217 \u3008B\u3009)\n\u2264 8 cost(f, S\u2217\u3008B\u3009)\nsince, by the monotonicity of f , cost(fGd , S \u2217 \u3008B\u3009) \u2264 cost(f, S \u2217 \u3008B\u3009).\nProof of Property 1: We first define a few values. The quantity Rj = 1\u2212f(Gj) represents how much of our task remains to be completed before the jth item of the greedy schedule is chosen. We define sj to be the \u201cbang for the buck\u201d earned from that item. That is, sj = (Rj\u2212Rj+1)\n\u03c4j . Then, let pj = Rj sj for all j \u2264 d, and pj = 0 for j > d. Let xj = pj2 and let yj = Rj 2 . Also, let \u03c8(x) = 1\u2212 f(S \u2217 \u3008x\u3009).\nIn order to prove the theorem, we wish to show\u222b B t=0 ( 1\u2212 f(S\u2217\u3008t\u3009) ) dt = \u222b B x=0 \u03c8(x) dx \u2265 1 4 cost(f,Gd)\nWe need to integrate \u03c8(x) only up to x = B. When x = B, \u03c8(x) = \u03c8(B) is the amount of the task that remains to be completed at time B under schedule the optimal schedule S\u2217. We associate with this amount a yk, corresponding to the greedy schedule, where k = min{ j : yj \u2264 \u03c8(B) }. This can be seen in Figure 1, where x = B and y = \u03c8(B) are shown as dotted lines, with yk being the first yj appearing below the dotted line y = \u03c8(B).\nWe first present an important fact. For any schedule S, any positive integer j \u2264 d, and any t >= 0,\nf(S\u3008t\u3009) \u2264 f(Gj) + t \u00b7 sj (10)\nThis is a consequence of the monotonicity and submodularity of f , together with the fact that the greedy algorithm always chooses the item with the best \u201cbang for the buck\u201d. It is shown in Streeter and Golovin (2009) as Fact 1.\nUsing this fact, we have\nf(S\u2217\u3008xj\u3009) \u2264 f(Gj) + xjsj = f(Gj) + Rj 2\nSo, for j \u2264 d we have\n\u03c8(xj) = 1\u2212 f(S\u2217\u3008xj\u3009) \u2265 1\u2212 f(Gj)\u2212 Rj 2 = Rj \u2212 Rj 2\nand therefore\n\u03c8(xj) \u2265 yj (11)\nNote that (11) holds for j > d as well, since xj = 0 by definition; thus, \u03c8(xj) = \u03c8(0) = 1 \u2265 yj .\nThe cost of the greedy schedule is \u2211d\nj=1Rj\u03c4j . The quantity Rj\u03c4j is the contribution of action j to the cost of the greedy schedule. We can think of this quantity as charging \u03c4j per unit of Rj . We can rewrite the contribution by instead dividing the charge per unit of utility change, Rj\u2212Rj+1. That is, we can rewrite Rj\u03c4j as the product of Rj\u03c4j/ (Rj \u2212Rj+1) and Rj \u2212Rj+1. It follows from the definitions that Rj\u03c4j/ (Rj \u2212Rj+1) = Rjsj and therefore\nxj(yj \u2212 yj+1) = 1\n4 Rj\u03c4j (12) Since cost(f,Gd) = \u2211d j=1Rj\u03c4j , we now have\n1 4 cost(f,Gd) = d\u2211 j=1 xj(yj \u2212 yj+1) (13)\nThe lemma now follows immediately from the following claim:\nClaim 1 \u2211d j=1 xj(yj \u2212 yj+1) \u2264 \u222b B x=0 \u03c8(x)dx.\nTo prove this claim, we note that for each j, we have a pair (xj , yj). Figure 1 shows two histograms (represented by gray bars). For any given j, we have a gray bar such that the top of the bar is at yj , the bottom is at yj+1, and the length of the bar is xj .\nProving the claim is equivalent to showing that the total area of the gray bars does not exceed the integral of \u03c8(x) up to x = B. Combining (11) with the fact that \u03c8 is non-increasing, it follows that for a gray bar extending to a length of xj , the gray bar has a height no more than yj and thus is below the graph of \u03c8. This allows us to conclude that the gray bars fit entirely inside of the graph of \u03c8. However, since we are integrating \u03c8 only up to x = B, there may be some gray bars which, although they are within the graph of \u03c8, fall outside of the area of integration of \u03c8. These are the values xj such that xj > B. We note the following important fact:\nFact 1 For all j < k, xj \u2264 B.\nThe justification for this fact is as follows: For any xj > B, we know that yj \u2264 \u03c8(xj) from (11) and \u03c8(xj) \u2264 \u03c8(B) since \u03c8 is nonincreasing. So, since xj > B implies that yj \u2264 \u03c8(B), we know that yj > \u03c8(B) implies that xj \u2264 B. For all j < k, by the definition of k, we know that yj > \u03c8(B), and thus xj \u2264 B.\nIn order to show that the area of the histogram defined by the (xj , yj) pairs is no larger than the integral up to x = B of \u03c8(x), we will break the integral into two parts:\u222b B\nx=0 \u03c8(x)dx = \u222b B x=0 (\u03c8(x)\u2212 yk)dx+ \u222b B x=0 ykdx\nand analyze each part. We note that the first part of the integral consists of the area above the line y = yk. Above this line, the reasoning follows the same reasoning as in Streeter and Golovin (2009): Due to (11), we see that each bar is contained entirely inside the graph of \u03c8, and since j < k, the bar is entirely inside the area of integration.\nThe second part of the integral consists of the area below y = yk, where the bars are still inside the graph of \u03c8, but may extend past x = B and thus fall outside the area of\nintegration. We must use different reasoning to show that the area of the bars below y = yk do not exceed the area of \u03c8 below y = yk and left of x = B.\nLet B\u2032 = `(Gd). We have B \u2032 = \u2211 j \u03c4j \u2265 \u2211 j\u2265k \u03c4j . Therefore, using (12), and the fact that\nRj \u2264 Rk for j \u2265 k, d\u2211 j=k xj(yj \u2212 yj+1) = d\u2211 j=k 1 4 \u03c4jRj \u2264 1 4 RkB \u2032 (14)\nThis holds true even when d < k, as in this case the sum is simply 0. Using this fact, combined with the fact that \u03c8(xj) \u2265 yj for j < d, we can prove the\nclaim. We have that\u222b B x=0 ykdx = ykB = 1 2 RkB > 1 4 RkB \u2032 \u2265 d\u2211 j=k xj(yj \u2212 yj+1) (15)\nwhere the last inequality follows from (14). If we look once again at Figure 1, we see that for each j, we have a gray bar with area xj(yj \u2212 yj+1). From (11), we know that the gray bars fit entirely inside \u03c8(x), and so the area of the gray bars above yk is not more than the area under \u03c8(x) and above yk. That is,\u222b B\nx=0 (\u03c8(x)\u2212 yk)dx \u2265 k\u22121\u2211 j=1 xj (yj \u2212 yj+1) (16)\nBy using (15) and (16), we now have\u222b B x=0 \u03c8(x) dx = \u222b B x=0 (\u03c8(x)\u2212 yk) dx+ \u222b B x=0 ykdx\n\u2265 d\u2211 j=1 xj (yj \u2212 yj+1) (17)\nas desired, thus proving Claim 1. By proving Claim 1, we have therefore also proven Property 1, and thus Lemma 11.\nAppendix B. O(k log n)-approximation for Scenario k-of-n function evaluation\nLet k \u2208 {0, . . . , n} and let f : {0, 1}n \u2192 {0, 1} be the Boolean k-of-n function where f(x) = 1 iff at least k bits of f are equal to 1. To determine the value of this f on an unknown a \u2208 {0, 1}n, we need to determine whether f has at least k ones, or at least n\u2212k+ 1 zeros. There is an elegant polynomial-time exact algorithm solving the Stochastic BFE problem for Boolean k-of-n functions (cf. Salloum (1979); Salloum and Breuer (1984); Ben-Dov (1981); Chang et al. (1990)).\nHere we consider the Scenario BFE problem for k-of-n functions. Following techniques used in a reduction of Deshpande et al. (2014) for Stochastic BFE, we reduce this problem\nto a Scenario SC problem, through the construction of an appropriate utility function g for the state set \u0393 = {0, 1}. We obtain g by combining two other functions g0, and g1, with respective goal values n \u2212 k + 1 and k respectively, using the standard OR construction described in Section 2. Function g1 : {0, 1, \u2217}n \u2192 Z\u22650 is such that for all b \u2208 {0, 1, \u2217}n, g1(b) = min{k, |{i | bi = 1}|}. Similarly, g0(b) = min{n \u2212 k + 1, |{i | bi = 0}|}. Combining g0 and g1, and their goal values using the OR construction yields the new function g : {0, 1, \u2217}n \u2192 Z\u22650 such that for b \u2208 {0, 1, \u2217}n, g(b) = k(n\u2212 k+ 1)\u2212 ((n\u2212 k+ 1)\u2212 g0(b))(k\u2212 g1(b)). The new goal value is Q = k(n \u2212 k + 1). For b \u2208 {0, 1, \u2217}n, g(b) = Q iff b either contains at least (n \u2212 k + 1) 0\u2019s or at least k 1\u2019s, and thus determining the value of f on initially unknown a is equivalent to achieving goal value for g.\nWe now lower bound the value of parameter \u03c1 for this g. For b \u2208 {0, 1, \u2217}n where g(b) < Q, and i such that bi = \u2217, \u2206g(b, i, 1) \u2265 (n\u2212k+1\u2212g0(b)) and \u2206g(b, i, 0) \u2265 (k\u2212g1(b)). Thus\n\u2206g(b,i,1) Q\u2212g(b) \u2265 n\u2212k+1\u2212g0(b) (n\u2212k+1\u2212g0(b))(k\u2212g1(b)) = 1 k\u2212g1(b) and \u2206g(b,i,0) Q\u2212g(b) \u2265 k\u2212g1(b) (n\u2212k+1\u2212g0(b))(k\u2212g1(b)) \u2265 1 k .\nThe larger of these is at least 1k , and hence the value of \u03c1 for g is at least 1 k . It follows that running Mixed Greedy on g with respect to the sample distribution, gives an O(k log n) approximation algorithm for our Scenario Boolean k-of-n function evaluation problem. The bound O(k log n) has no dependence on the sample size or on the weights. For constant k, this bound is O(log n).\nOur Scenario k-of-n function evaluation problem has some similarities to the Generalized Min-Sum Set Cover problem, which has a constant-factor approximation algorithm (see, e.g., Skutella and Williamson (2011)). However, in the Generalized Min-Sum Set Cover problem, the goal is to find a non-adaptive strategy of minimum cost. Further, the sample is unweighted, and the covering requirements are different for different assignments in the input sample."}, {"heading": "Appendix C. Adaptive Submodularity of gW", "text": "Proof of Lemma 3 Let w(b) = \u2211\na\u2208S:a bw(a) be the sum of the weights of realizations in the sample S that are extensions of b. Then, we can write hW (b) = W \u2212 w(b).\nThe OR construction gives us\ngW (b) = QW \u2212 (Q\u2212 g(b))(W \u2212 hW (b))\nBy the properties of the standard OR construction, because g and hW are monotone and submodular, so is gW .\nLet b, b\u2032 \u2208 (\u0393 \u222a {\u2217})n such that b\u2032 b, and i \u2208 N where bi = b\u2032i = \u2217. To show that gW is adaptive submodular with respect to distribution DS,w, we must show that E[\u2206gW (b, i, \u03b3)] \u2265 E[\u2206gW (b\u2032, i, \u03b3)] with respect to DS,w.\nWe start by finding \u2206gW (b, i, \u03b3) for any b \u2208 (\u0393 \u222a {\u2217})n, \u03b3 \u2208 \u0393, and i \u2208 N such that bi = \u2217:\n\u2206gW (b, i, \u03b3) = QW \u2212 (Q\u2212 g(bi\u2190\u03b3)) (W \u2212 hW (bi\u2190\u03b3)) \u2212QW + (Q\u2212 g(b)) (W \u2212 hW (b))\n= QhW (bi\u2190\u03b3) +Wg(bi\u2190\u03b3)\u2212 g(bi\u2190\u03b3)hW (bi\u2190\u03b3) \u2212QhW (b)\u2212Wg(b) + g(b)hW (b)\n= Q\u2206hW (b, i, \u03b3) +W\u2206g(b, i, \u03b3) + g(b)hW (b)\u2212 g(bi\u2190\u03b3)hW (bi\u2190\u03b3)\nBy adding and subtracting the same quantity, g(b)hW (bi\u2190\u03b3), to the expression on the last line, we get\n\u2206gW (b, i, \u03b3) = Q\u2206hW (b, i, \u03b3) +W\u2206g(b, i, \u03b3) + g(b)hW (b)\u2212 g(bi\u2190\u03b3)hW (bi\u2190\u03b3) + g(b)hW (bi\u2190\u03b3)\u2212 g(b)hW (bi\u2190\u03b3)\n= Q\u2206hW (b, i, \u03b3) +W\u2206g(b, i, \u03b3)\n\u2212 g(b)(hW (bi\u2190\u03b3)\u2212 h(b))\u2212 hW (bi\u2190\u03b3)(g(bi\u2190\u03b3)\u2212 g(b)) = Q\u2206hW (b, i, \u03b3) +W\u2206g(b, i, \u03b3)\n\u2212\u2206hW (b, i, \u03b3)g(b)\u2212\u2206g(b, i, \u03b3)hW (bi\u2190\u03b3) = \u2206hW (b, i, \u03b3)(Q\u2212 g(b)) + \u2206g(b, i, \u03b3)(W \u2212 hW (bi\u2190\u03b3))\nWe next recall that, by definition, hW (b) = W \u2212w(b). Thus, we have that W \u2212hW (bi\u2190\u03b3) = w(bi\u2190\u03b3), and we can simplify further:\n\u2206gW (b, i, \u03b3) = \u2206hW (b, i, \u03b3)(Q\u2212 g(b)) + \u2206g(b, i, \u03b3)w(bi\u2190\u03b3)\nWe define for any partial realization d, the function Q\u0302(d) = Q \u2212 g(d) to represent the amount of utility remaining to be achieved by d. Also, let U\u03b3 = \u2206g(b, i, \u03b3) represent the utility gained in g by observing state \u03b3 for item i in partial realization b. Let W\u03b3 = w(bi\u2190\u03b3) represent the weight of all realizations in S consistent with bi\u2190\u03b3 , referred to as the total weight of state \u03b3. Let W \u03b3 = \u2211 \u03b3\u2032 6=\u03b3W\u03b3\u2032 represent the total weight of all states which are not \u03b3. It is clear that \u2206hW (b, i, \u03b3) = W \u03b3 . That is, the change in utility in hW (or conceptually, the amount of weight eliminated) is equal to the total weight of states which are not the observed state, \u03b3. We can now substitute these new values in the above equation and get:\n\u2206gW (b, i, \u03b3) = W \u03b3 Q\u0302(b) + U\u03b3W\u03b3\nWe now consider the calculation of the expected value of \u2206gW . For a realization a \u2208 \u0393n drawn from DS,w, we have that Pr[ai = \u03b3 | a b] = w(bi\u2190\u03b3)w(b) = W\u03b3 w(b) . Then, the expected increase in utility is\nE[\u2206gW (b, i, \u03b3)] = \u2211 \u03b3 W\u03b3 w(b) \u2206gW (b, i, \u03b3)\n= \u2211 \u03b3 W\u03b3 w(b) ( Q\u0302(b)W \u03b3 + U\u03b3W\u03b3 ) = \u2211 \u03b3W\u03b3W \u03b3Q\u0302(b) + U\u03b3W 2 \u03b3\nw(b)\n=\n\u2211 \u03b3W\u03b3W \u03b3Q\u0302(b) + U\u03b3W\n2 \u03b3\u2211\n\u03b3W\u03b3\nThe last equality is true since W\u03b3 = w(bi\u2190\u03b3) and the sum of w(bi\u2190\u03b3) for all \u03b3 is equal to w(b).\nWe now consider the partial realization b\u2032. The expected value on partial realization b\u2032\nis analogous to the above expected value on b: E[\u2206gW (b\u2032, i, \u03b3)] = \u2211 \u03b3W \u2032 \u03b3W \u2032 \u03b3Q\u0302(b \u2032) + U \u2032\u03b3W \u20322 \u03b3\u2211\n\u03b3W \u2032 \u03b3\nwhere W \u2032\u03b3 = w(b \u2032 i\u2190\u03b3), W \u2032 \u03b3 = \u2211 \u03b3\u2032 6=\u03b3W \u2032 \u03b3\u2032 , and U \u2032 \u03b3 = \u2206g(b\n\u2032, i, \u03b3). Next, let W = (W\u03b31 ,W\u03b32 , . . . ) be the tuple containing all of the weights of the possible states with respect to b, and let U = (U\u03b31 , U\u03b32 , . . . ) be the tuple containing all of the U\u03b3 values for each of the possible states. We also let W \u2032 = (W \u2032\u03b31 ,W \u2032 \u03b32 , . . . ) and U\n\u2032 = (U \u2032\u03b31 , U \u2032 \u03b32 , . . . ).\nIt follows from the submodularity of g that Q\u0302(b\u2032) \u2264 Q\u0302(b) and U \u2032\u03b3 \u2264 U\u03b3 . Clearly W \u2032\u03b3 \u2264 W\u03b3 . Finally, since g is monotone, and the maximum value of g on its domain is Q, U\u03b3 \u2264 Q\u0302(b) and U \u2032\u03b3 \u2264 Q\u0302(b\u2032).\nNow let r = |\u0393|. We will use w\u03b31 , w\u03b32 , . . . , w\u03b3r to represent variables for a new function which we will define. Similarly, we will use u\u03b31 , u\u03b32 , . . . , u\u03b3r to represent variables of the same function. We will also let w\u03b3 = \u2211 \u03b3\u2032 6=\u03b3 w\u03b3\u2032 to simplify the definition of the function. The w\u03b3 and u\u03b3 variables are analogous to the W\u03b3 and U\u03b3 in the expression for expected value above. We now define our function f : R2|\u0393|+1 \u2192 R such that\nf(w\u03b31 , . . . , w\u03b3r , u\u03b31 , . . . , u\u03b3r , q) =\n\u2211 \u03b3 qw\u03b3w\u03b3 + w\n2 \u03b3u\u03b3\u2211\n\u03b3 w\u03b3\nNote that this function is analogous to the formula for expected value above. Specifically, we consider the point (W\u2032,U\u2032, Q\u0302(b\u2032)) and the point (W,U, Q\u0302(b)). It should be noted that f(W\u2032,U\u2032, Q\u0302(b\u2032)) = E[\u2206gW (b, i, \u03b3)] and f(W,U, Q\u0302(b)) = E[\u2206gW (b\u2032, i, \u03b3)]. Let P be the path from the first point to the second point, which increases q continuously from Q\u0302(b\u2032) to Q\u0302(b), then increases each u\u03b3i continuously from U \u2032 \u03b3i to U\u03b3i for i = 1, 2, . . . , r, and finally increases each w\u03b3i continuously from W \u2032 \u03b3i to W\u03b3i for i = 1, 2, . . . , r. We show that for every point along the path P , the partial derivatives of f are non-negative, and therefore the value of f is nondecreasing along the path. This proves that f(W,U, Q\u0302(b)) \u2265 f(W\u2032,U\u2032, Q\u0302(b\u2032)). This implies that E[\u2206gW (b, i, \u03b3)] \u2265 E[\u2206gW (b\u2032, i, \u03b3)], and thus gW is adaptive submodular with respect to distribution DS,w.\nWe let K = \u2211\n\u03b3 w\u03b3 . Then, we start by taking the partial derivative with respect to q:\n\u2202f \u2202q =\n\u2211 \u03b3 (w\u03b3w\u03b3)\nK \u2265 0\nfor all points on P since all weights are nonnegative and thus w\u03b3 \u2265 0. We also examine the partial derivative with respect to each u\u03b3 . Given any \u03b3, the partial derivative is \u2202f\n\u2202u\u03b3 = w2\u03b3 K \u2265 0\nbecause K is positive since all weights are nonnegative (i.e. w\u03b3 \u2265 0 for all w\u03b3). Finally, for each w\u03b3 , we will use the fact that w\u03b3 = \u2211 \u03b3\u2032 6=\u03b3 w\u03b3\u2032 . This means that for any\n\u03b3, we can express the sum of all weights as K = w\u03b3 + \u2211 \u03b3\u2032 6=\u03b3 w\u03b3\u2032 = w\u03b3 + w\u03b3 . This fact is\nused several times in the following. We have\n\u2202f\n\u2202w\u03b3 =\n( w\u03b3q + 2w\u03b3u\u03b3 +\n\u2211 \u03b3\u2032 6=\u03b3 w\u03b3\u2032q\n) K \u2212 (\u2211 \u03b3\u2032 [ w\u03b3\u2032w\u03b3\u2032q + w 2 \u03b3\u2032u\u03b3\u2032 ]) K2\n=\n(w\u03b3q + 2w\u03b3u\u03b3 + w\u03b3q) (w\u03b3 + w\u03b3)\u2212 \u2211 \u03b3\u2032 ( w\u03b3\u2032w\u03b3\u2032q + w 2 \u03b3\u2032u\u03b3\u2032 ) K2\n=\n( 2w\u03b3w\u03b3q + 2w 2 \u03b3u\u03b3 + 2w 2 \u03b3q + 2w\u03b3w\u03b3u\u03b3 ) \u2212 \u2211 \u03b3\u2032 ( w\u03b3\u2032w\u03b3\u2032q + w 2 \u03b3\u2032u\u03b3\u2032 ) K2\nIn the summation in the numerator, we look at the term for which \u03b3\u2032 = \u03b3 and we can simplify the numerator:\n\u2202f\n\u2202w\u03b3 =\nw\u03b3w\u03b3q + w 2 \u03b3u\u03b3 + 2w 2 \u03b3q + 2w\u03b3w\u03b3u\u03b3 \u2212 \u2211 \u03b3\u2032 6=\u03b3 ( w\u03b3\u2032w\u03b3\u2032q + w 2 \u03b3\u2032u\u03b3\u2032 ) K2\nThen, we can find a lower bound on this expression for all points on P . We note that initially, u\u03b3 \u2264 q since U\u03b3 \u2264 Q\u0302(b\u2032) for all \u03b3. We first increase q continuously to Q\u0302(b). Then we increase each u\u03b3 continuously from U \u2032 \u03b3 to U\u03b3 . We also note that U \u2032 \u03b3 \u2264 Q\u0302(b), and so after we have increased each u\u03b3 we still have that u\u03b3 \u2264 q. So at all points on the path we have that u\u03b3 \u2264 q, and we can replace in the summation in the numerator each u\u03b3\u2032 by q to produce our lower bound:\n\u2202f \u2202w\u03b3 \u2265 w\u03b3w\u03b3q + w\n2 \u03b3u\u03b3 + 2w 2 \u03b3q + 2w\u03b3w\u03b3u\u03b3 \u2212 \u2211 \u03b3\u2032 6=\u03b3 ( w\u03b3\u2032 ( w\u03b3\u2032q + w\u03b3\u2032q )) K2\n=\nw\u03b3w\u03b3q + w 2 \u03b3u\u03b3 + 2w 2 \u03b3q + 2w\u03b3w\u03b3u\u03b3 \u2212 \u2211 \u03b3\u2032 6=\u03b3 ( qw\u03b3\u2032 ( w\u03b3\u2032 + w\u03b3\u2032 )) K2\n=\nw\u03b3w\u03b3q + w 2 \u03b3u\u03b3 + 2w 2 \u03b3q + 2w\u03b3w\u03b3u\u03b3 \u2212 q \u2211 \u03b3\u2032 6=\u03b3 ( w\u03b3\u2032K ) K2\n=\nw\u03b3w\u03b3q + w 2 \u03b3u\u03b3 + 2w 2 \u03b3q + 2w\u03b3w\u03b3u\u03b3 \u2212 qK \u2211 \u03b3\u2032 6=\u03b3 ( w\u03b3\u2032 )\nK2\nThen we note that, by definition, w\u03b3 = \u2211 \u03b3\u2032 6=\u03b3 w\u03b3\u2032 , and simplify further:\n= w\u03b3w\u03b3q + w\n2 \u03b3u\u03b3 + 2w 2 \u03b3q + 2w\u03b3w\u03b3u\u03b3 \u2212 qKw\u03b3 K2\n= w\u03b3q (w\u03b3 + w\u03b3) + w\n2 \u03b3u\u03b3 + w 2 \u03b3q + 2w\u03b3w\u03b3u\u03b3 \u2212 qKw\u03b3\nK2\n= w\u03b3qW + w\n2 \u03b3u\u03b3 + w 2 \u03b3q + 2w\u03b3w\u03b3u\u03b3 \u2212 qKw\u03b3 K2\n= w2\u03b3u\u03b3 + w 2 \u03b3q + 2w\u03b3w\u03b3u\u03b3\nK2\n\u2265 0\nfor all points on P because w\u03b3 and u\u03b3 are nonnegative on P . Thus, f is nondecreasing along path P , and gW is adaptive submodular with respect to the distribution DS,w."}], "references": [{"title": "Group-based active query selection for rapid diagnosis in time-critical situations", "author": ["G. Bellala", "S. Bhavnani", "C. Scott"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Bellala et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bellala et al\\.", "year": 2012}, {"title": "Optimal testing procedure for special structures of coherent systems", "author": ["Y. Ben-Dov"], "venue": "Management Science,", "citeRegEx": "Ben.Dov.,? \\Q1981\\E", "shortCiteRegEx": "Ben.Dov.", "year": 1981}, {"title": "Optimal diagnosis procedures for k-out-of-n structures", "author": ["M.-F. Chang", "W. Shi", "W.K. Fuchs"], "venue": "IEEE Transactions on Computers,", "citeRegEx": "Chang et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Chang et al\\.", "year": 1990}, {"title": "Submodular surrogates for value of information", "author": ["Yuxin Chen", "Shervin Javdani", "Amin Karbasi", "J. Andrew Bagnell", "Siddhartha S. Srinivasa", "Andreas Krause"], "venue": "In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January 25-30,", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Submodular surrogates for value of information", "author": ["Yuxin Chen", "Shervin Javdani", "Amin Karbasi", "J. Andrew Bagnell", "Siddhartha S. Srinivasa", "Andreas Krause"], "venue": "(long version). 2015b. URL http://las.ethz.ch/files/chen15submsrgtvoi-long.pdf", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Diagnosis determination: decision trees optimizing simultaneously worst and expected testing cost", "author": ["Ferdinando Cicalese", "Eduardo Laber", "Aline Medeiros Saettler"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "Cicalese et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cicalese et al\\.", "year": 2014}, {"title": "Approximation algorithms for stochastic boolean function evaluation and stochastic submodular set cover", "author": ["A. Deshpande", "L. Hellerstein", "D. Kletenik"], "venue": "In Symposium on Discrete Algorithms,", "citeRegEx": "Deshpande et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Deshpande et al\\.", "year": 2014}, {"title": "Adaptive submodularity: Theory and applications in active learning and stochastic optimization", "author": ["D. Golovin", "A. Krause"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Golovin and Krause.,? \\Q2011\\E", "shortCiteRegEx": "Golovin and Krause.", "year": 2011}, {"title": "Near-optimal Bayesian active learning with noisy observations", "author": ["D. Golovin", "A. Krause", "D. Ray"], "venue": "In 24th Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Golovin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Golovin et al\\.", "year": 2010}, {"title": "Simultaneous learning and covering with adversarial noise", "author": ["Andrew Guillory", "Jeff A. Bilmes"], "venue": "In Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "Guillory and Bilmes.,? \\Q2011\\E", "shortCiteRegEx": "Guillory and Bilmes.", "year": 2011}, {"title": "Near optimal bayesian active learning for decision making", "author": ["Shervin Javdani", "Yuxin Chen", "Amin Karbasi", "Andreas Krause", "Drew Bagnell", "Siddhartha S. Srinivasa"], "venue": "In Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Javdani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Javdani et al\\.", "year": 2014}, {"title": "Learning with attribute costs", "author": ["H. Kaplan", "E. Kushilevitz", "Y. Mansour"], "venue": "In Symposium on the Theory of Computing,", "citeRegEx": "Kaplan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Kaplan et al\\.", "year": 2005}, {"title": "Optimal testing algorithms for symmetric coherent systems", "author": ["S. Salloum"], "venue": "PhD thesis, University of Southern California,", "citeRegEx": "Salloum.,? \\Q1979\\E", "shortCiteRegEx": "Salloum.", "year": 1979}, {"title": "Above this line, the reasoning follows the same reasoning as in Streeter and Golovin", "author": ["y = yk"], "venue": null, "citeRegEx": "yk.,? \\Q2009\\E", "shortCiteRegEx": "yk.", "year": 2009}, {"title": "Here we consider the Scenario BFE problem for k-of-n functions. Following techniques used in a reduction of Deshpande et al. (2014) for Stochastic BFE", "author": ["Ben-Dov"], "venue": null, "citeRegEx": "Ben.Dov,? \\Q1990\\E", "shortCiteRegEx": "Ben.Dov", "year": 1990}], "referenceMentions": [{"referenceID": 6, "context": "We consider the Scenario Submodular Cover problem, which is a counterpart to the Stochastic Submodular Cover problem studied by Golovin and Krause (2011). In Scenario Submodular Cover, the goal is to produce a cover with minimum expected cost, where the expectation is with respect to an empirical joint distribution, given as input by a weighted sample of realizations.", "startOffset": 128, "endOffset": 154}, {"referenceID": 5, "context": "Building on algorithms developed by Cicalese et al. (2014) and Golovin and Krause (2011) for related problems, we give two approximation algorithms for Scenario Submodular Cover over discrete distributions.", "startOffset": 36, "endOffset": 59}, {"referenceID": 5, "context": "Building on algorithms developed by Cicalese et al. (2014) and Golovin and Krause (2011) for related problems, we give two approximation algorithms for Scenario Submodular Cover over discrete distributions.", "startOffset": 36, "endOffset": 89}, {"referenceID": 5, "context": "Golovin and Krause (2011); Golovin et al.", "startOffset": 0, "endOffset": 26}, {"referenceID": 5, "context": "Golovin and Krause (2011); Golovin et al. (2010); Bellala et al.", "startOffset": 0, "endOffset": 49}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Javdani et al.", "startOffset": 8, "endOffset": 30}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Javdani et al. (2014)).", "startOffset": 8, "endOffset": 53}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Javdani et al. (2014)). Other applications include reducing prediction costs for learned Boolean classifiers, when there are costs for determining attribute values (Deshpande et al. (2014)).", "startOffset": 8, "endOffset": 220}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Javdani et al. (2014)). Other applications include reducing prediction costs for learned Boolean classifiers, when there are costs for determining attribute values (Deshpande et al. (2014)). Previous work on the Stochastic Submodular Cover problem assumes that the variables of the input probability distribution are independent. Optimization is performed with respect to this distribution. We consider a new version of the problem that we call Scenario Submodular Cover, that removes the independence assumption. In this problem, optimization is performed with respect to an input distribution that is given explicitly by its support (with associated probability weights). We give approximation algorithms solving the Scenario Submodular Cover problem over discrete distributions. Before describing our contributions in more detail, we give some background. In generic terms, an adaptive submodular cover problem is a sequential decision problem where we must choose items one by one from an item set N = {1, . . . , n}. Each item has an initially unknown state, which is a member of a finite state set \u0393. The state of an item is revealed only after we have chosen the item. We represent a subset S of items and their states by a vector x \u2208 (\u0393 \u222a {\u2217})n where xi = \u2217 if i 6\u2208 S, and xi is the state of item i otherwise. We are given a monotone, submodular utility function g : (\u0393 \u222a {\u2217})n \u2192 Z\u22650. It assigns a non-negative integer value to each subset of the items and the value can depend on the states of the items.1 There is a non-negative goal utility value Q, such that g(a) = Q for all a \u2208 \u0393n. There is a cost associated with choosing each item, which we are given. In distributional settings, we are also given the joint distribution of the item states. We must continue choosing items until their utility value is equal to the goal utility, Q. The problem is to determine the adaptive order in which to choose the items so as to minimize expected cost (in distributional settings) or worst-case cost (in adversarial settings). Stochastic Submodular Cover is an adaptive submodular cover problem, in a distributional setting. In this problem, the state of each item is a random variable, and these variables are assumed to be independent. The distributions of the variables are given as input. Golovin and Krause introduced a simple greedy algorithm for this problem, called Adaptive Greedy, that achieves an approximation factor of O(logQ). A dual greedy algorithm for the problem, called Adaptive Dual Greedy, was presented and analyzed by Deshpande et al. (2014). These greedy algorithms have been useful in solving other stochastic optimization", "startOffset": 8, "endOffset": 2600}, {"referenceID": 7, "context": "In the terminology used by Golovin and Krause Golovin and Krause (2011), g is pointwise monotone and pointwise submodular.", "startOffset": 27, "endOffset": 72}, {"referenceID": 6, "context": ", Javdani et al. (2014); Chen et al.", "startOffset": 2, "endOffset": 24}, {"referenceID": 3, "context": "(2014); Chen et al. (2015a); Deshpande et al.", "startOffset": 8, "endOffset": 28}, {"referenceID": 3, "context": "(2014); Chen et al. (2015a); Deshpande et al. (2014); Golovin et al.", "startOffset": 8, "endOffset": 53}, {"referenceID": 3, "context": "(2014); Chen et al. (2015a); Deshpande et al. (2014); Golovin et al. (2010)).", "startOffset": 8, "endOffset": 76}, {"referenceID": 5, "context": "It is a generalization of an algorithm by Cicalese et al. (2014) for the Equivalence Class Determination problem (which has also been called the Group Identification problem and the Discrete Function Evaluation problem).", "startOffset": 42, "endOffset": 65}, {"referenceID": 5, "context": "It is a generalization of an algorithm by Cicalese et al. (2014) for the Equivalence Class Determination problem (which has also been called the Group Identification problem and the Discrete Function Evaluation problem). The approximation factor achieved by Mixed Greedy for the Scenario SC problem is O ( 1 \u03c1 logQ ) , where \u03c1 is a quantity that depends on the utility function g. In the case of the utility function constructed for the Equivalence Class Determination Problem, \u03c1 is constant, but this is not true in general. We describe a modified version of Mixed Greedy that we call Scenario Mixed Greedy. It works by first constructing a new monotone, submodular utility function gS from g and the sample, for which \u03c1 is constant. It then runs Mixed Greedy on gS with goal value Qm, where m is the size of the sample. We show that Scenario Mixed Greedy achieves an O(logQm) approximation factor for any Scenario SC problem. Mixed Greedy is very similar to the algorithm of Cicalese et al., and we use the same basic analysis. However, at the heart of their analysis is a technical lemma with a lengthy proof bounding a quantity that they call the \u201csepcost\u201d. The proof applies only to the particular utility function used in the Equivalence Class Determination problem. We replace this proof with an entirely different proof that applies to the general Scenario SC problem. Our proof is based on the work of Streeter and Golovin (2009) for the Min-Sum Submodular Cover problem.", "startOffset": 42, "endOffset": 1439}, {"referenceID": 5, "context": "Golovin et al. (2010); Bellala et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al.", "startOffset": 8, "endOffset": 30}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al.", "startOffset": 8, "endOffset": 179}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al. (2015a,b)), namely showing that the value of a certain function is non-decreasing along a path between two points; however, we are addressing a more general problem and the details of our proof are different. We believe that our work on Adaptive Greedy should make it easier to develop efficient approximation algorithms for sample-based problems in the future. Previously, using ordinary Adaptive Greedy to solve a sample-based problem involved the construction of a utility function g, and a proof that g, together with the distribution on the weighted sample, was adaptive submodular. The proof was usually the most technically difficult part of the work (see, e.g., Golovin et al. (2010); Bellala et al.", "startOffset": 8, "endOffset": 884}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al. (2015a,b)), namely showing that the value of a certain function is non-decreasing along a path between two points; however, we are addressing a more general problem and the details of our proof are different. We believe that our work on Adaptive Greedy should make it easier to develop efficient approximation algorithms for sample-based problems in the future. Previously, using ordinary Adaptive Greedy to solve a sample-based problem involved the construction of a utility function g, and a proof that g, together with the distribution on the weighted sample, was adaptive submodular. The proof was usually the most technically difficult part of the work (see, e.g., Golovin et al. (2010); Bellala et al. (2012); Javdani et al.", "startOffset": 8, "endOffset": 907}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al. (2015a,b)), namely showing that the value of a certain function is non-decreasing along a path between two points; however, we are addressing a more general problem and the details of our proof are different. We believe that our work on Adaptive Greedy should make it easier to develop efficient approximation algorithms for sample-based problems in the future. Previously, using ordinary Adaptive Greedy to solve a sample-based problem involved the construction of a utility function g, and a proof that g, together with the distribution on the weighted sample, was adaptive submodular. The proof was usually the most technically difficult part of the work (see, e.g., Golovin et al. (2010); Bellala et al. (2012); Javdani et al. (2014); Chen et al.", "startOffset": 8, "endOffset": 930}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al. (2015a,b)), namely showing that the value of a certain function is non-decreasing along a path between two points; however, we are addressing a more general problem and the details of our proof are different. We believe that our work on Adaptive Greedy should make it easier to develop efficient approximation algorithms for sample-based problems in the future. Previously, using ordinary Adaptive Greedy to solve a sample-based problem involved the construction of a utility function g, and a proof that g, together with the distribution on the weighted sample, was adaptive submodular. The proof was usually the most technically difficult part of the work (see, e.g., Golovin et al. (2010); Bellala et al. (2012); Javdani et al. (2014); Chen et al. (2015b)).", "startOffset": 8, "endOffset": 951}, {"referenceID": 0, "context": "(2010); Bellala et al. (2012); Chen et al. (2015a,b)). Our proof of adaptive submodularity uses the same basic approach as used in previous work (see, e.g., Golovin et al. (2010); Chen et al. (2015a,b)), namely showing that the value of a certain function is non-decreasing along a path between two points; however, we are addressing a more general problem and the details of our proof are different. We believe that our work on Adaptive Greedy should make it easier to develop efficient approximation algorithms for sample-based problems in the future. Previously, using ordinary Adaptive Greedy to solve a sample-based problem involved the construction of a utility function g, and a proof that g, together with the distribution on the weighted sample, was adaptive submodular. The proof was usually the most technically difficult part of the work (see, e.g., Golovin et al. (2010); Bellala et al. (2012); Javdani et al. (2014); Chen et al. (2015b)). Our construction of gW , and our proof of adaptive submodularity, make it possible to achieve an approximation bound using Adaptive Greedy after proving only submodularity of a constructed g, rather than adaptive submodularity of g and the distribution. Proofs of submodularity are generally easier because they do not involve distributions and expected values. Also, the standard OR construction described in Section 2 preserves submodularity, while it does not preserve Adaptive Submodularity (Chen et al. (2015a)).", "startOffset": 8, "endOffset": 1469}, {"referenceID": 7, "context": "By the results of Golovin and Krause (2011), running Adaptive Greedy with g yields an O(logQ) approximation for the associated Stochastic SC problem.", "startOffset": 18, "endOffset": 44}, {"referenceID": 10, "context": "For example, we can easily obtain a new bound for the Decision Region Identification problem studied by Javdani et al. (2014), which is an extension of the Equivalence Class Determination problem.", "startOffset": 104, "endOffset": 126}, {"referenceID": 8, "context": "In contrast, the bound achieved by Javdani et al. is O ( k log ( W wmin )) , where wmin is the minimum weight on a assignment in the sample. We can apply our greedy algorithms to Scenario BFE (Boolean Function Evaluation) problems, which we introduce here. These problems are a counterpart to the Stochastic BFE problems2 that have been studied in AI, operations research, and in the context of learning with attribute costs (see e.g., \u00dcnl\u00fcyurt (2004); Deshpande et al.", "startOffset": 35, "endOffset": 452}, {"referenceID": 5, "context": ", \u00dcnl\u00fcyurt (2004); Deshpande et al. (2014); Kaplan et al.", "startOffset": 19, "endOffset": 43}, {"referenceID": 5, "context": ", \u00dcnl\u00fcyurt (2004); Deshpande et al. (2014); Kaplan et al. (2005)).", "startOffset": 19, "endOffset": 65}, {"referenceID": 5, "context": ", \u00dcnl\u00fcyurt (2004); Deshpande et al. (2014); Kaplan et al. (2005)). In a Scenario BFE problem, we are given a Boolean function f . For each i \u2208 {1, . . . , n}, we are also given a cost ci > 0 associated with obtaining the value of the ith bit of an initially unknown assignment a \u2208 {0, 1}n. Finally, we are given a weighted sample S \u2286 {0, 1}n. The problem is to compute a (possibly implicit) decision tree computing f , such that the expected cost of evaluating f on a \u2208 {0, 1}n, using the tree, is minimized. The expectation is with respect to the distribution defined by the sample weights. Deshpande et al. (2014) gave approximation algorithms for some Stochastic BFE problems that work by constructing an appropriate monotone, submodular utility function g and running Adaptive Greedy.", "startOffset": 19, "endOffset": 616}, {"referenceID": 5, "context": ", \u00dcnl\u00fcyurt (2004); Deshpande et al. (2014); Kaplan et al. (2005)). In a Scenario BFE problem, we are given a Boolean function f . For each i \u2208 {1, . . . , n}, we are also given a cost ci > 0 associated with obtaining the value of the ith bit of an initially unknown assignment a \u2208 {0, 1}n. Finally, we are given a weighted sample S \u2286 {0, 1}n. The problem is to compute a (possibly implicit) decision tree computing f , such that the expected cost of evaluating f on a \u2208 {0, 1}n, using the tree, is minimized. The expectation is with respect to the distribution defined by the sample weights. Deshpande et al. (2014) gave approximation algorithms for some Stochastic BFE problems that work by constructing an appropriate monotone, submodular utility function g and running Adaptive Greedy. By substituting the sample-based algorithms in this paper in place of Adaptive Greedy, we obtain approximation results for analogous Scenario BFE problems. For example, using Mixed Greedy, we can show that the Scenario BFE problem for k-of-n functions has an approximation algorithm achieving a factor of O(k log n) approximation, independent of the size of the sample. Details are in Appendix B. Bounds for other functions follow easily using Scenario Mixed Greedy and Scenario Adaptive Greedy. For example, Deshpande et al. (2014) presented an algorithm achieving an O(log t) approximation for the Stochastic BFE problem for evaluating decision trees of size t.", "startOffset": 19, "endOffset": 1322}, {"referenceID": 5, "context": "We note that our Scenario BFE problem differs from the function evaluation problem by Cicalese et al. (2014). In their problem, the computed decision tree need only compute f correctly on assignments a \u2208 {0, 1}n that are in the sample, while ours needs to compute f correctly on all a \u2208 {0, 1}n.", "startOffset": 86, "endOffset": 109}, {"referenceID": 8, "context": "Guillory and Bilmes (2011); Deshpande et al.", "startOffset": 0, "endOffset": 27}, {"referenceID": 6, "context": "Guillory and Bilmes (2011); Deshpande et al. (2014)).", "startOffset": 28, "endOffset": 52}, {"referenceID": 5, "context": "The algorithm of Cicalese et al. for the Equivalence Class Determination problem is essentially the same as our Mixed Greedy algorithm, for g equal to their \u201cPairs\u201d utility function. (There is one small difference \u2013 in their algorithm, the first stage ends right before the greedy step in which the budget B would be exceeded, whereas we allow the budget to be exceeded in the last step.) Like their algorithm, our Mixed Greedy algorithm relies on a greedy algorithm for the Budgeted Submodular Cover problem due to Wolsey. We describe Wolsey\u2019s algorithm in detail in Appendix A.1. If g(b) = Q, then MixedGreedy returns an (unlabeled) single node, which will be a leaf of the full tree for g. Otherwise, MixedGreedy constructs a tree T . It does so by computing a special realization called \u03c3, and then iteratively using \u03c3 to construct a path descending from the root of this subtree, which is called the backbone. It uses recursive calls to build the subtrees \u201changing\u201d off the backbone. The backbone has a special property: for each node v\u2032 in the path, the successor node in the path is the \u03c3i child of v \u2032, where i is the item labeling node v\u2032. The construction of the backbone is done as follows. Using subroutine FindBudget, MixedGreedy first computes a lower bound B on the minimum additional cost required in order to achieve a portion \u03b1 of the goal value Q, assuming we start with partial realization b (Step 6). This computation is done using the Greedy algorithm of Wolsey (1982) described in Section A.", "startOffset": 17, "endOffset": 1491}, {"referenceID": 5, "context": "Generalizing an argument from Cicalese et al. (2014), we now prove that \u03c1S is lower bounded by a constant fraction.", "startOffset": 30, "endOffset": 53}, {"referenceID": 5, "context": "Lemma 6 is the key technical lemma in our analysis, and it is the proof of this lemma that constitutes the major difference between our analysis and the analysis in Cicalese et al. (2014). We defer the proof of this lemma to Section A.", "startOffset": 165, "endOffset": 188}, {"referenceID": 5, "context": "We deal with this by using an approach analogous to one used by Cicalese et al. (2014) (in the analysis of their Equivalence Class Determination algorithm) that allows us to concentrate only on the cost of the portion of the schedule constructed during the first stage.", "startOffset": 64, "endOffset": 87}, {"referenceID": 13, "context": "We note that the first part of the integral consists of the area above the line y = yk. Above this line, the reasoning follows the same reasoning as in Streeter and Golovin (2009): Due to (11), we see that each bar is contained entirely inside the graph of \u03c8, and since j < k, the bar is entirely inside the area of integration.", "startOffset": 84, "endOffset": 180}, {"referenceID": 9, "context": "Salloum (1979); Salloum and Breuer (1984); Ben-Dov (1981); Chang et al.", "startOffset": 0, "endOffset": 15}, {"referenceID": 9, "context": "Salloum (1979); Salloum and Breuer (1984); Ben-Dov (1981); Chang et al.", "startOffset": 0, "endOffset": 42}, {"referenceID": 1, "context": "Salloum (1979); Salloum and Breuer (1984); Ben-Dov (1981); Chang et al.", "startOffset": 43, "endOffset": 58}, {"referenceID": 1, "context": "Salloum (1979); Salloum and Breuer (1984); Ben-Dov (1981); Chang et al. (1990)).", "startOffset": 43, "endOffset": 79}, {"referenceID": 1, "context": "Salloum (1979); Salloum and Breuer (1984); Ben-Dov (1981); Chang et al. (1990)). Here we consider the Scenario BFE problem for k-of-n functions. Following techniques used in a reduction of Deshpande et al. (2014) for Stochastic BFE, we reduce this problem", "startOffset": 43, "endOffset": 213}], "year": 2016, "abstractText": "Many problems in Machine Learning can be modeled as submodular optimization problems. Recent work has focused on stochastic or adaptive versions of these problems. We consider the Scenario Submodular Cover problem, which is a counterpart to the Stochastic Submodular Cover problem studied by Golovin and Krause (2011). In Scenario Submodular Cover, the goal is to produce a cover with minimum expected cost, where the expectation is with respect to an empirical joint distribution, given as input by a weighted sample of realizations. In contrast, in Stochastic Submodular Cover, the variables of the input distribution are assumed to be independent, and the distribution of each variable is given as input. Building on algorithms developed by Cicalese et al. (2014) and Golovin and Krause (2011) for related problems, we give two approximation algorithms for Scenario Submodular Cover over discrete distributions. The first achieves an approximation factor of O(logQm), where m is the size of the sample and Q is the goal utility. The second, simpler algorithm achieves an approximation bound of O(logQW ), where Q is the goal utility and W is the sum of the integer weights. (Both bounds assume an integer-valued utility function.) Our results yield approximation bounds for other problems involving non-independent distributions that are explicitly specified by their support. \u2217 Partially Supported by NSF Grant 1217968 c \u00a9 2016 N. Grammel, L. Hellerstein, D. Kletenik & P. Lin. ar X iv :1 60 3. 03 15 8v 1 [ cs .D S] 1 0 M ar 2 01 6 Grammel Hellerstein Kletenik Lin", "creator": "LaTeX with hyperref package"}}}