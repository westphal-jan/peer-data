{"id": "1604.01221", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Apr-2016", "title": "Character-Level Neural Translation for Multilingual Media Monitoring in the SUMMA Project", "abstract": "The paper steps outside the comfort-zone of the traditional NLP tasks like automatic speech recognition (ASR) and machine translation (MT) to addresses two novel problems arising in the automated multilingual news monitoring: segmentation of the TV and radio program ASR transcripts into individual stories, and clustering of the individual stories coming from various sources and languages into storylines. Storyline clustering of stories covering the same events is an essential task for inquisitorial media monitoring. We address these two problems jointly by engaging the low-dimensional semantic representation capabilities of the sequence to sequence neural translation models. To enable joint multi-task learning for multilingual neural translation of morphologically rich languages we replace the attention mechanism with the sliding-window mechanism and operate the sequence to sequence neural translation model on the character-level rather than on the word-level. The story segmentation and storyline clustering problem is tackled by examining the low-dimensional vectors produced as a side-product of the neural translation process. The results of this paper describe a novel approach to the automatic story segmentation and storyline clustering problem.", "histories": [["v1", "Tue, 5 Apr 2016 11:34:11 GMT  (444kb)", "http://arxiv.org/abs/1604.01221v1", "LREC-2016 submission"]], "COMMENTS": "LREC-2016 submission", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["guntis barzdins", "steve renals", "didzis gosko"], "accepted": false, "id": "1604.01221"}, "pdf": {"name": "1604.01221.pdf", "metadata": {"source": "CRF", "title": "Character-Level Neural Translation for Multilingual Media Monitoring in the SUMMA Project", "authors": ["Guntis Barzdins", "Steve Renals", "Didzis Gosko"], "emails": ["guntis.barzdins@lu.lv,", "s.renals@ed.ac.uk,", "didzis.gosko@leta.lv"], "sections": [{"heading": null, "text": "1. \u00a0 The SUMMA Project Overview Media monitoring enables the global news media to be viewed in terms of emerging trends, people in the news, and the evolution of storylines (Risen et al., 2013). The massive growth in the number of broadcast and Internet media channels requires innovative ways to cope with this increasing amount of data. It is the aim of SUMMA 1 project to significantly improve media monitoring by creating a platform to automate the analysis of media streams across many languages. Within SUMMA project three European news broadcasters BBC, Deutche Welle, and Latvian news agency LETA are joining the forces with the University of Edinburgh, University College London, Swiss IDIAP Research Institute, Qatar Computing Research Institute, and Priberam Labs from Portugal to adapt the emerging big data neural deep learning NLP techniques to the needs of the international news monitoring industry. BBC Monitoring undertakes one of the most advanced, comprehensive, and large scale media monitoring operations world-wide, providing news and information from media sources around the world. BBC monitoring journalists and analysts translate from over 30 languages into English, and follow approximately 13,500 sources, of which 1,500 are television broadcasters, 1,300 are radio, 3,700 are key news portals world-wide, 20 are commercial news feeds, and the rest are RSS feeds and selected Social Media sources. Monitoring journalists follow important stories and flag breaking news events as part of the routine monitoring.\n1 SUMMA (Scalable Understanding of Multilingual MediA) is project 688139 funded by the European Union H2020-ICT-16\nThe central idea behind SUMMA is to develop a scalable multilingual media monitoring platform (Fig.1) that combines the real-time media stream processing (speech recognition, machine translation, story clustering) with indepth batch-oriented construction of a rich knowledge base of reported events and entities mentioned, enabling extractive summarization of the storylines in the news.\nIn this paper we focus only on the streaming shallow processing part of the SUMMA project (the dark block in Fig.1), where the recently developed neural machine translation techniques (Sutskerev, Vinyals & Le, 2014; Bahdanau, Cho & Bengio, 2014) enable radically new end-\nBigData-research call. The project started in February 2016 and will last 3 years.\nto-end approach to machine translation and clustering of the incoming news stories. The approach is informed by our previous work on machine learning (Barzdins, Paikens, Gosko, 2013), media monitoring (Barzdins et al.,2014), and character-level neural translation (Barzdins & Gosko, 2016).\n2. \u00a0 Multilingual Neural Translation Automation of media monitoring tasks has been the focus of the number of earlier projects such as European Media Monitor (emm.newsbrief.eu), EventRegistry (eventregistry.org), xLike (xlike.org), Bison (bisonproject.eu), NewsReader (newsreader-project.eu), MultiSensor (multisensorproject.eu), inEvent (inventproject.eu), and xLiMe project (xlime.eu). These predecessor projects are dominated by the paradigm of NLP pipelines [20] based on shallow machine learning.\nwithin SUMMA. The key difference of the SUMMA project is that it has been incepted after the recent paradigm-shift (Manning, 2015) in the NLP community towards neural network inspired deep learning techniques such as end-to-end automatic speech recognition (Graves & Jaitly, 2014; Hannun et al., 2014; Amodei, 2015), end-to-end machinetranslation (Sutskerev, Vinyals & Le, 2014; Bahdanau, Cho & Bengio, 2014; Luong et al., 2015), efficient distributed vectorspace word embeddings (Mikolov et al., 2013), image and video captioning (Xu et al., 2015; Venugopalan et al., 2015), unsupervised learning of document representations by autoencoders (Li, Luong & Jurafsky, 2015). These recent deep learning breakthroughs along with massively parallel GPU computing allow addressing the media monitoring tasks in the completely new end-toend manner rather than relying on the legacy NLP pipelines. The novelty of the SUMMA project approach is that all languages covered by the project (Table 1) can be embedded in the same vectorspace by means of joint multitask learning (Collobert et al., 2011; Dong et al., 2015; Pham, Luong & Manning, 2015) of eight LSTM-RNN translational autoencoders with hidden layer parameters shared as illustrated in Fig.2. Sharing the same vectorspace for sentences in all project languages enables accurate multilingual news story clustering without resorting to the clustering of the less accurate target (English) language machine translations. This shared vectorspace approach\nextends also to the unsupervised multi-task learning of language models from the large monolingual corpora (Fig. 3), which is crucial for low-resourced languages: having a generic language model learned in parallel from the monolingual corpora reduces (Dai & Le, 2015) the need for large supervised parallel corpora to achieve the same translational accuracy for the Fig. 2 setup.\nThe joint training of seventeen translational and samelanguage autoencoders with shared parameters (Fig. 2 and Fig. 3 together) to our knowledge has not been attempted so far. Even training of a single state-of-the-art sentencelevel translational autoencoder requires days of GPU computing (Barzdins & Gosko, 2016)) in TensorFlow (Abadi et al., 2015) seq2seq model (Sutskerev, Vinyals & Le, 2014; Bahdanau, Cho & Bengio, 2014). To avoid complexities of asynchronous parallel training with shared parameter server (Dean et al., 2012), the architecture in Fig.2 and Fig. 3 instead can be trained using the alternating training approach proposed in (Luong et al., 2016), where each task is optimized for a fixed number of parameter updates (or mini-batches) before switching to the next task (which is a different language pair). Although such alternating approach prolongs the training process, it is preferred for simplicity and robustness reasons. Once produced within SUMMA project, these translational autoencoders with shared vectorspace will be a unique language resource of likely interest also to the wider NLP community for multilingual applications outside the media monitoring domain.\n3. \u00a0 Character-level Neural Translation for Streams\nNeural translation attention mechanism (Bahdanau, Cho & Bengio, 2014) has been shown to be highly beneficial for bi-lingual neural translation of long sentences, but it is not compatible with the multi-task multilingual translation models (Dong et al., 2015; Luong et al, 2016) described in the previous Section and character-level translation models (Barzdins & Gosko, 2016) described in this Section. For these reasons we replace the neural translation attention mechanism with much simpler sliding-window translation\nTable 2: English-Latvian sliding window stream translation. Final translation (bottom) consists of words appearing at least twice in the neighboring columns. Word suffixes are ignored if the initial 6 characters match.\napproach to cope with long sentences (or potentially unsegmented streams of words produced by ASR systems during audio and video media transcription) in both multilingual and character based neural translation. Sliding-window approach quality-wise cannot compete with the state-of-art translation systems, but is adequate for fast previewing of multilingual content, especially for ASR audio transcripts with inevitably high word error rate (WER) anyway. Additional problem with the low-resourced languages (bottom part in Table 1) is that most of them are highly inflective languages with rich morphology. For example, in Latvian each verb has more than 250 inflected forms. Applying regular word-level seq2seq neural translation model to such languages is impractical due to exploding vocabulary size leading to high rate of out of vocabulary (OOV) word forms and poor coordination. A better approach to translating such languages is to use the character-level translation model (Barzdins & Gosko, 2016; Karpathy, 2015; Jozefowicz, 2016). Moving from wordlevel to character-level neural translation makes it even harder to cope with long sentences presenting additional reason to employ the sliding-window translation approach. Table 2 illustrates the character-level neural translation from English to Latvian using modified 2 TensorFlow (Abadi et al., 2015) seq2seq (Sutskerev, Vinyals & Le, 2014) neural translation model. The character-level neural translation is enabled by forcing tokenizer to treat each input symbol as a separate \u201cword\u201d leading to the small and fixed \u201cvocabulary\u201d containing only 90 most frequently encountered characters. Another necessary change to the TensorFlow default seq2seq settings is disabling the attention (Bahdanau, Cho & Bengio, 2014) mechanism which is known to interfere with character-level translation (Barzdins & Gosko, 2016) because there are no mappings between the characters of the translated words. The small vocabulary of 90 words automatically disables also the sampled softmax functionality of seq2seq improving the overall performance. Finally, we configure single bucket of size 100 characters, which will be the max translation window size. Other hyperparameters used are: 1 LSTM\n2 https://github.com/didzis/tensorflowAMR\nlayer of size 400, batch size 16. Training is performed on Europarl v7 EN-LV corpus3 for 24h on TitanX GPU. The sliding-window mechanism is used only during decoding (translation), mapping a fragment of 6 English words into 5 Latvian words (Latvian translations typically contain less words than English source \u2013 rich morphology substitutes for most prepositions and articles). The multiple sliding-window translations produced are later merged into the final translation consisting only of words appearing at least twice in the neighboring sliding window columns (word suffixes are ignored if the initial 6 characters of the words match \u2013 this reduces word drop due to inflection errors). The final translation in Table 2 (bottom row) is close to the manual verbatim translation (top row) and conveys the topic of the original sentence. Moreover, the slidingwindow translations are surprisingly fluent Latvian phrases with correct word forms and mostly correct coordination. The only non-Latvian \u201cwords\u201d fabricated by the characterlevel translation in the Table 2 are \u201ctranspastiv\u0113\u0161ana\u201d, \u201ctranspitts\u201d, \u201ctranspirma\u201d and apparently are triggered by the English verb \u201ctransits\u201d, because in Latvian \u201ctranz\u012bts\u201d is used only as a noun without a close substitute verb. Sliding-window translation method, obviously, cannot handle long-range dependencies well and occasionally drops or inserts words in the translation \u2013 therefore SUMMA provides also state-of-the-art translation service in parallel to the one described here. Meanwhile the sliding-window character-based translation method has unique advantages relevant to the scope of SUMMA project, discussed in the next Section.\n4. \u00a0 Potential Applications of the Multilingual Character-level Stream Translation\nHaving a shared vectorspace multilingual translation system (Fig.2 and Fig.3) able to operate on unsegmented streams of text have a number of novel applications. The most straightforward novel application is the possibility to embed the documents of all project languages into the same shared semantics vectorspace and compute document semantic similarity (Hill, Cho & Korhonen, 2016) irrespective of the document language. The sliding-window translation approach allows to view the document as a sequence (trace) of vectors corresponding to every slidingwindow step while translating the document. These vectors are similar to word embedding vectors, but are likely to be\n3 http://www.statmt.org/europarl/\nVairumu Eiropas Savien\u012bbas1 j\u016bras transporta p\u0101rvad\u0101 caur j\u016bras ost\u0101m Eiropas transporta t\u012bkl\u0101 The overwhelming majority of Union maritime traffic transits through the maritime ports of the7 European transport network Vair\u0101kums apsveicamu Eiropas Savien\u012bbas j\u016bras *\nVair\u0101kums attiec\u012bb\u0101 uz Eiropas Savien\u012bbas * Vairumam* Eiropas Savien\u012bbas7 j\u016bras transpastiv\u0113\u0161anas*\nno juridisks j\u016bras transpiltts p\u0101rraudz\u012bts * Savien\u012bbas7 j\u016bras transpirma tranz\u012btu p\u0101rvad\u0101t\u0101s *\nrakstiski PT P\u0101rraid\u012bt tirdzniec\u012bbas p\u0101rvad\u0101\u0161anas* rakstiski p\u0101rvietojumi p\u0101rrobe\u017eu jaut\u0101jum\u0101 izstr\u0101d\u0101t *\nSarunas par j\u016bras ostu jaut\u0101jumu * Ar j\u016bras ties\u012bbu* aktu iesp\u0113jas *\np\u0101rvad\u0101t\u0101ju ierosin\u0101jumi Eiropas rakstiski PT Eiropas transporta apliecin\u0101juma *\nEiropas transporta t\u012bkls . . no Eiropas transporta7 t\u012bkls .\nVair\u0101kums 7 Eiropas Savien\u012bbas j\u016bras 7 transpD p\u0101rvad\u0101D j\u016bras Eiropas transporta t\u012bkls . 7\nsemantically richer, as they would mostly distinguish word-senses in the context of the window. Such vectortraces corresponding to the documents can be compared in the bag-of-words fashion by measuring cosine-distance between the sums of document trace-vectors (as part of kmeans clustering or nearest-neighbor search). This can be used as a building block for multilingual semantic clustering of stories into storylines, or for the semantic search of the documents in any language which are similar to the given document. Another novel application of the character-level neural translation is stream segmentation into the individual stories \u2013 a difficult task for news ingested from audio or video sources and transcribed with ASR and thus lacking any explicit sentence or story segmentation information. For stream segmentation into the stories it is possible to utilize the exceptional generalization and memorization capacity of the neural networks, which is already applied in the neural dialogue systems such as Gmail Smart Replies (Corrado, 2015; Vinyals&Le, 2015). Table 3 illustrates how mere 400 LSTM cells of our single-layer 90-character neural translator have been able to generalize and memorize rather correct translations for the first 100 characters of the entire Europarl v7 EN-LV training corpus containing 600,000 sentence pairs. For story segmentation a sliding-window neural translation system can be incrementally trained to monolingually \u201ctranslate\u201d the current 5 words of the stream into the next 5 words of the stream (predicting next 5 words from previous 5 words), based on the actual news streams encountered. Such system should be able to predict reasonably well the next 5 words within the news story, but will fail to do so when there is a transition from one story to the next. Along with additional auxiliary information such as time-code (when exactly the phrase was spoken and pauses in the speech) and speaker identification for each phrase this should provide a rather reliable segmentation signal.\nTable 3: Europarl v7 training corpus fragment (only first 100 characters of each sentence were used for training) and the character-level neural translation output illustrating the memorization of the training corpus.\n5. \u00a0 Conclusions It is still an open issue which vectorspace projections yield the semantically best clusters (Hill, Cho & Korhonen, 2016) and further experiments are needed. Particularly for storyline (Rissen et al., 2013) clustering the signals for the stories belonging to the same storyline might be not so much the semantic similarity of the articles (they might report various developments of the storyline from differing viewpoints), but rather the matching time and location as well as same organizations and people being involved \u2013 the information typically supplied by Named Entity Linking (NEL) tools. The tradeoffs between semantic clustering quality and computational complexity are likely to be crucial. Once trained, the run-time use of the multilingual translation modules for translation and news story clustering is around 1 sec on TitanX GPU per average news story. This is an order of magnitude slower than regular NEL or IF IDF bagof-words based clustering methods. Establishing reliable storyline clustering benchmarking data sets and metrics is one of the goals of the SUMMA project, as good storyline clusters are the prerequisite for downstream storyline summarization, visualization, and predictive anticipation of upcoming developments.\n6. \u00a0 Acknowledgments This work was supported in part by H2020 SUMMA project under grant agreement 688139/H2020-ICT-2015 and in part by the Latvian National research program SOPHIS under grant agreement Nr.10-4/VPP-4/11.\nEnglish(original Latvian(manual(translation Latvian(character3level(neural(translation In#the#last#ten#years,#Europe#has#not#made#progress#in#terms#of#the#number#of#universities#of#excellence#in#the#ranking#of#the#top#100#universities.# P\u0113d\u0113jo des it#gadu laik\u0101#Ei opa# av#palielin\u0101jusi#t\u0101du#izcil\u012bbas#universit\u0101\u0161u#skaitu,#kas b\u016btu#starp#100#lab\u0101kaj\u0101m#universit\u0101t\u0113m.# P\u0113d\u0113jo#desmit#gadu#laik\u0101#Eiropa#nav#pan\u0101kusi# rogresu#simbolu#universit\u0101t\u0113m#universit\u0101t\u0113m#universit\u0101 We#need#to#conclude#the#Bologna#Process. # Mums#j\u0101pabeidz#Bolo\u0146as#process. # Mums#j\u0101pabeidz#Bolo\u0146as#process. We#need#to#promote,#facilitate#and#open#up#expectations#for#increasingly#European#universities#and#increasingly#European#research,#because#they#are#undoubtedly#the#impetus#for#the#future.# Mums#j\u0101veicina,#j\u0101sekm\u0113#un#j\u0101nodro\u0161i a#vair\u0101k#Eiropas#universit\u0101\u0161u#un#v ir\u0101k#Eiropas#p\u0113tniec\u012bbas,#jo#tas# eap\u0161aub\u0101mi#ir n\u0101ko nes#stimuls.# Mum #j\u0101veicina#veici \u0101t#k\u0101#atv\u0113rtu#un#aizvien#vair\u0101k#univ rsit\u0101 s#un#vienotas#universit\u0101\u0161u# n#vieno We#are#no#longer#competing#country#against#country,#but#as#Europeans,#as#Europe,#because#the#other#players#are#the#size#of#China,#India,#the#United#States#and#the#emerging#countries.# M\u0113s#vairs#nekonkur\u0113jam#valsts#ar#valsti,#bet#konkur\u0113jam#k\u0101# iropi \u0161i#un#k\u0101#Eiropa,#jo#citi#dal\u012bbniek #ir#\u0136\u012bn ,#Indija,#ASV#un#jau \u0101s#tirgus# konomikas#valstis.# M s#vairs#nekonkur\u0113jot#pret#valsti bet k\u0101#Eiropas#iedz\u012bvot\u0101ji,#jo cita sast\u0101vda\u013ca#ar#citu#t\u0101l\u0101ku#ci If#we#do#not#make#the#most#of#the#synergy#represented#by#the#500#million#citizens#in#the#economy,#which#means#tens#of#thousands#of#enterprises#with#huge#capacity#and#millions#of#workers,#who#need#to#be#provided#with#increasingly#better#training,#we#will#not#be#the#real#leading#players#of#the#future,#in#terms#of#economic#prosperity#through#innovation#and#technology,#in#this#scenario#of#globalisation.# Ja#m\u0113s#maksim\u0101li#neizma tosim#siner\u0123iju,#kuru#nodro\u0161ina#500#miljonu#pilso\u0146 #t utsaimniec\u012bba,#kas#noz\u012bm\u0113#desmitiem#t\u016bksto\u0161u#uz\u0146\u0113mumu#ar#milz\u012bgu#jaudu un miljoniem#darbinieku,#kuriem#j\u0101nodro\u0161i a#aizvien#lab\u0101ka#apm\u0101c\u012bba,#m\u0113s#nesp\u0113sim#b\u016bt#patiesi#vado\u0161ie#n\u0101kotnes#dal\u012bbnieki#globaliz\u0113taj\u0101#pasaul\u0113#saist\u012bb\u0101#ar#ekon misko#labkl\u0101j\u012bbu,#izmant jot#inov\u0101cijas#un#tehnolo\u0123ijas.# Ja#m\u0113s#nepadaram#visl el\u0101ko da\u013cu# iner\u0123iju# r#000#miljoni m#ekonomiku,#kas#par t\u0101 sak\u0101vi,#vai#tas t We#will#be#spectators,#not#leading#players. # M\u0113s#b\u016bsim#skat\u012bt\u0101ji,#nevis#vado\u0161ie#dal\u012bbnieki. # M\u0113s#b\u016bsim#spektori,#nevis#vado\u0161ie#dal\u012bbnieki. The#way#forward#is#the#Union:#more#common#economic#policy,#more#integration,#more#shared#vision,#more#Europe.# Ce\u013c\u0161#uz#priek\u0161u#saist\u012bts#ar#Ei opas#Savien\u012bbu:#Vair\u0101k#kop\u012bgas# kon mikas#politikas,#vair\u0101k#integr\u0101cijas,#vair\u0101k#kop\u012bgu#redz\u0113jumu#un#vair\u0101k#Eiropas.# T\u0101#ir#vienot\u0101#vienot\u0101#ekonomikas#politika,#ekonomikas#politika,#momo#integr\u0101cija,#veicin\u0101jum ,#momo# Not#putting#up#more#barriers,#but#removing#barriers,#not#dividing#but#bringing#together,#having#a#vision#of#the#Union#that#promotes#competitiveness,#integration#and#innovation.# N vis jaunu#ierobe\u017eojumu#noteik\u0161ana,#bet#ierobe\u017eojumu#atcel\u0161a a;# evis#\u0161\u0137el\u0161ana,#bet#apvieno\u0161ana,#\u012bstenojo #Eiropas#Savien\u012bbas#redz\u0113jumu,#kas#sekm\u0113#konkur\u0113tsp\u0113ju,#integr\u0101ciju#un#inov\u0101cijas.# Ne#vair\u0101k barjeru,#b t#nevis#s m zin\u0101jo\u0161\u0101ks,#n vis#sadal\u012bt#k p\u0101,#t \u010du#kop\u0101#savu#v\u012bru#ir#sa azin\u0101ju\u0161\u0101 We#have#confidence#in#the#Commission#regarding#this#2020#Strategy,#which#must#also#incorporate#a#discussion#about#the#future#of#the#Common#Agricultural#Policy,#which#is#a#fundamental#policy#in#terms#of#environmental#protection,#food#safety#and#the#incomes#of#many#European#citizens.# M\u0113s#pa\u013caujamies#uz#Komisiju#attiec\u012bb\u0101#uz#2020.#gad strat\u0113\u0123iju,#kur\u0101#j\u0101ietver#ar\u012b#diskusijas#par#kop\u0113j\u0101s#lauks imniec\u012bbas#politikas# \u0101kotni,#jo#\u0161\u012b#ir#galven\u0101#politika#attiec\u012bb\u0101#uz#vides#aizsardz\u012bbu, p\u0101rtikas#nekait\u012bgumu#un#daudzu iropas#pilso\u0146u#ien\u0101kumiem.# Mums#ir#uztic\u012bba#Komisij\u0101,#k s#attiecas#uz#\u0161o#0000#ku\u0123i,#kuri#ir#j\u0101 ek\u013cauj ar\u012b sav #di\u017eena#tikai sa We#are#convinced#that#the#debate#that#is#going#to#take#place#in#the#European#Council#and#the#Commission#and,#of#course,#the#dialogue#with#the#European#Parliament,#must#bring#about#a#2020#Strategy#that#involves#serious#governance#and#is#demanding#in#its#objectives#and#focused#on#the#areas#that#I#have#just#mentioned.# M\u0113s#esam#p\u0101rliecin\u0101ti,#ka#debat\u0113m,#kas# orisin\u0101sies#Eiropadom\u0113#un#Komisij\u0101,#k\u0101# r\u012b,#protams,#dialogam# r#Eirop s#Parla entu#j\u0101noved#pie .#gada#strat\u0113\u0123ijas,#kura# aist\u012bta ar#nopietnu p\u0101rval \u012bbu#un# r#pras\u012bga#attiec\u012bb\u0101#uz#t\u0101s#m\u0113r\u0137iem,#k\u0101#ar\u012b#koncen r\u0113t #uz#jom\u0101m,#ko# upat#min\u0113ju.M\u0113s#esam#p\u0101rliecin\u0101ti,#ka#debates#notiks#Eirop d mei u #Komisijai#un#komis\u0101res#kundzes vietai. Economic#change#and#political#change,#and#change#in#the#government#of#the#Union.# Ekonomisk\u0101s#p\u0101r ai\u0146as,#politisk\u0101s#p\u0101rmai\u0146as#un#Eiropas#Savien\u012bbas#p\u0101rvald\u012bbas#p\u0101rmai\u0146as.# konomisk\u0101#p\u0101rmai\u0146as#un#politisk\u0101#groz\u012bjumi#ir#izmain\u012bti#vald\u012bb\u0101#Eiropas#Savien\u012bb\u0101. The#Treaty#of#Lisbon#establishes#new#institutions:#the#permanent#President#of#the#Council#and#the#High#Representative#for#Foreign#Affairs.# Lisabonas#l\u012bgums#izveido#jaunus#amat s:#past\u0101v\u012bgu#Padom s#pri k\u0161s\u0113d\u0113t\u0101ju#un#Augsto#p\u0101rst\u0101vi#\u0101rliet\u0101s.# Lisabonas#l\u012bgums#izveido as#jaunas#iest\u0101\u017eu#statist kas#b#Padomes#priek\u0161s\u0113d\u0113t\u0101ja#un#Hichard#Hharnen#p It#strengthens#Parliament,#the#heart#of#European#democracy,#and#also#strengthens#the#Commission.# Tas#nostiprina Eiropas#demokr\u0101tijas#sirds#b#Parlame ta#b,#k\u0101#ar\u012b#Komisijas#noz\u012bmi.# Tas#nostiprina#Eiropas#demokr\u0101tijas#sirds#un#stiprin\u0101t#ar\u012b#Komisiju. I#can#make#a#commitment#before#Parliament,#which#represents#all#European#citizens,#that#the#Spanish#rotating#Presidency#will#be#loyal#to,#and#will#cooperate#with,#the#new#institutions.# Parlamentam,#kas#p\u0101rst\u0101v#visus#Eiropas#pilso\u0146us,#es#varu#p ust#savu#ap\u0146em\u0161anos,#ka#Sp\u0101nij s#rot\u0113jo\u0161\u0101# rezident\u016bra#b\u016bs#loj\u0101la#a tiec\u012bb\u0101#pret#jauno#amatu#ie\u0146\u0113m\u0113jiem#un#ar#tiem#sadarbosies.# E # # dar\u012bt#parl mentu,#ka #p\u0101rst\u0101v#visus#Eiropas ilso\u0146us,#ka#Sp\u0101nija#un#Sp\u0101nijas#pamat\u0101. We#want#those#institutions#to#have#the#meaning#established#in#the#treaty:#namely,#the#need#for#the#European#Union#to#function#so#that#the#permanent#President#of#the#Council#can#represent#the#European#Union#and#carry#out#all#his#functions,#along#with#the#High#Representative.# M\u0113s#v\u0113 amies,#lai#\u0161ie#amati ir#t\u0101di,#k\u0101#noteikts#l\u012bgum\u0101,#p ti,#lai#Eiropas#Savien\u012bba#funkcion\u0113#t\u0101,#lai#past\u0101v\u012bgais#Padomes#priek\u0161s\u0113d\u0113t\u0101js#kop\u0101#ar#Augsto#p\u0101rst\u0101vi var\u0113tu#p\u0101rst\u0101v\u0113t#Eiropas#Savien\u012bbu#un#veikt#savas#funkcijas.# M\u0113s v\u0113lamies,#la #\u0161\u012bs#instit\u016bc jas ir#tie,#kas#izveidots#l\u012bgum\u0101:#b#vai#ne#tam#vajadz\u012bba#uz#vi\u0146u#v ja We#are#aware#that#this#sixbmonth#period#will#be#the#first#proof#of#how#the#new#institutional#structure#works,#and#we#will#also#support#a#strengthened#Commission#and#Parliament,#which#is#increasingly#the#political#centre#of#the#European#Union.# M\u0113s#apzin\u0101mies,#ka#\u0161is se\u0161u#m\u0113ne\u0161u#periods b\u016bs#pirmais#apliecin\u0101jums#tam,#k\u0101#darbojas#jaun\u0101#iest\u0101\u017eu strukt\u016bra,#un#m\u0113s# \u012b# tbals \u012bsim#pastiprin\u0101tu# oz\u012bmi,#kas#piem\u012bt#Komisijai#un#Parlamentam,#kur\u0161#aizvien#vair\u0101k#nostiprina#savas#poz\u012bcijas#k\u0101#Eiropas#Savien\u012bbas#politiskais#centrs.# M\u0113s# pzin\u0101mies,#ka#\u0161is#se\u0161us#m\u0113ne\u0161a#pirmais pi augums#b\u016bs#pirm\u0101#pier\u0101d\u012bju s#par#to,#k\u0101#st uktur\u0113tais We#are#going#to#do#this,#and#I#hope#that#we#will#be#judged#satisfactorily#at#the#end#of#this#period,#because#our#commitment#is#very#firm.M\u0113s#to#dar\u012b im#un#es#ceru,#ka#m\u016bs#\u0161\u012b#per oda#beig\u0101s#nov\u0113rt\u0113s#apmierino\u0161i,#jo#m\u016bsu#ap\u0146em\u0161an\u0101s#ir#\u013coti#cie\u0161a.# M\u0113s#to#dar\u012bsim,#un#es#c ru, ka#m\u0113s#tiksi #pietieko\u0161i#nosk \u0146oti#no#\u0161\u012bs#periodam#beigas#un#attiec\u012bb\u0101#u There#are#various#powers#governing#the#European#Union,#and#they#need#to#have#a#common#thread,#which#is#cooperative#loyalty.# Eiropas#Savien\u012bbu#p\u0101rvalda#da\u017e\u0101das#varas,#kam#j\u0101nosaka#kop\u012bgs#virziens,#pr ti,#uz#sadarb\u012bbu#pamatota#lojalit\u0101te.# Ir#d \u017e\u0101di#p lnvaras,#un#t\u0101m#ir#j\u0101b\u016bt#kop\u0113jai tirdzniec\u012bb\u0101m,#kuru#pamat\u0101#ir#tikpat#p\u0101ri#uztic\u0113\u0161an\u0101s,# That#is#how#we#shall#work. # T\u0101#m\u0113s#str\u0101d\u0101sim. # T\u0101#m\u0113s#str\u0101d\u0101sim. Mr#President,#ladies#and#gentlemen,#we#are#also#experiencing#changes#in#the#area#of#external#relations,#not#only#because#of#the#existence#of#the#High#Representative#and#the#launch#of#the#European#External#Action#Service.# Priek\u0161s\u0113d\u0113t\u0101ja kungs,#d\u0101mas#un#kungi,#p\u0101rm i\u0146as#v\u0113rojamas#ar\u012b#\u0101r\u0113jo#attiec\u012bbu#jom\u0101#un#n #tikai#Augst\u0101#p\u0101rst\u0101vja#un#Eiropas#\u0100r\u0113j\u0101s#darb\u012bbas dienest #d\u0113\u013c.Pr ek\u0161s\u0113d\u0113t\u0101ja kungs,#d\u0101mas#un#kungi!#M\u0113s#esam#p\u0101rmai\u0146u#p\u0101rmai\u0146as#ar\u012b#\u0101r\u0113jo#attiec\u012bbu#un#p\u0101rm i\u0146u#jo There#will#also#be#changes#because#in#this#context#of#globalisation#and#change,#we#have#a#decisive#sixbmonth#agenda.# Izmai\u0146as# \u016bs#v\u0113rojamas#ar\u012b#t\u0101d\u0113\u013c,#ka#saist\u012bb\u0101#ar#globaliz\u0101ciju#un#p\u0101rmai\u0146\u0101m#mums#ir#iz\u0161\u0137iro\u0161s#se\u0161u#m\u0113ne\u0161u#pl\u0101ns.# Past\u0101v#ar\u012b#t\u0101d\u0113\u013c,#ka#\u0161\u012b#globaliz\u0101cijas kontek t #un#globaliz\u0101cijas#m\u0113s#main\u0101m#iz\u0161\u0137iro\u0161u#saimniec\u012bbu#\n7. \u00a0 References Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z.,\nCitro, C., Corrado, G.S., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard, M., Jozefowicz, R., Jia, Y., Kaiser, L., Kudlur, M., Leven-berg, J., Man\u00e9, D., Schuster, M., Monga, R., Moore, S., Murray, D., Olah, C., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan, V., Vi\u00e9gas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke, W., Yu, Y., Zheng, X. (2015). TensorFlow: Large-scale machine learning on heterogeneous systems. Google Research whitepaper. Software available from tensorflow.org.\nAmodei, D., Anubhai, R., Battenberg, E., Case, C., Casper, J., Catanzaro, B., Chen, J., Chrzanowski, M., Coates, A., Diamos, G., et al. (2015). Deep speech 2: End-to-end speech recognition in english and mandarin. arXiv preprint arXiv:1512.02595. Bahdanau, D., Cho, K., Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473. Barzdins, G., Gosko, D. (2016). Riga: Impact of Smatch Extensions and Character-Level Neural Translation on AMR Parsing Accuracy. In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval 2016), (to appear) Barzdins, G., Gosko, D., Rituma, L., Paikens, P. (2014). Using C5.0 and Exhaustive Search for Boosting FrameSemantic Parsing Accuracy. In Proceedings of the 9th Language Resources and Evaluation Conference (LREC), pp. 4476-4482. Barzdins, G., Paikens, P., Gosko, D. (2015). Riga: from FrameNet to Semantic Frames with C6.0 Rules. In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), Association for Computational Linguistics, pp. 960\u2013964. Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., Kuksa, P. (2011). Natural language processing (almost) from scratch. The Journal of Machine Learning Research, 12, pp. 2493--2537. Corrado, G. (2015). Smart Replay. Google Research Blog post, http://googleresearch.blogspot.com/2015/11/computerrespond-to-this-email.html Dai, A.M., Le, Q.V. (2015). Semi-supervised Sequence Learning. In NIPS-2015. Dean, J., Corrado, G. S., Monga, R., Chen, K., Devin, M., Le, Q.V., Mao, M.Z., Ranzato, M., Senior, A., Tucker, P., Yang, K., Ng, A.Y. (2012). Large scale distributed deep networks. In NIPS-2012. Dong, D., Wu, H., He, W., Yu, D., Wang, H. (2015). MultiTask Learning for Multiple Language Translation. In Proceedings of the 53rd Annual Meeting of the ACL and the 7th International Joint Conference on Natural Language Processing, Beijing, China, pp. 1723--1732. Graves, A., Jaitly, N. (2014). Towards end-to-end speech recognition with recurrent neural networks. In ICML2014.\nHannun, A., Case, C., Casper, J., Catanzaro, B., Diamos, G., Elsen, E., Prenger, R., Satheesh, S., Sengupta, S., Coates, A., Ng, A.Y. (2014) Deep Speech: Scaling up end-to-end speech recognition. arXiv preprint arXiv:1412.5567. Hill, F., Cho, K., Korhonen, A. (2016). Learning Distributed Representations of Sentences from Unlabelled Data. arXiv preprint arXiv:1602.03483 Jozefowicz, R., Vinyals, O., Schuster, M., Shazeer, N., Wu, W. (2016). Exploring the Limits of Language Modeling. arXiv preprint arXiv:1602.02410 Karpathy, A. (2015). The unreasonable effectiveness of recurrent neural networks. Blog post, http://karpathy.github.io/2015/05/21/rnn-effectiveness/ Li, J., Luong, T., Jurafsky, D. (2015). A Hierarchical Neural Autoencoder for Paragraphs and Documents. In Proceedings of the 53rd Annual Meeting of the ACL and the 7th International Joint Conference on NLP, Beijing, China, pp. 1106--1115. Luong, T., Le, Q.V., Sutskever, I., Vinyals, O., Kaiser, L. (2016). Multi-task Sequence to Sequence Learning. In ICLR-2016. Luong, T., Sutskever, I., Le, Q.V., Vinyals, O., Zaremba, W. (2015). Addressing the rare word problem in neural machine translation. In Proceedings of the 53rd Annual Meeting of the ACL and the 7th International Joint Conference on NLP, Beijing, China, pp. 11--19. Manning, C.D. (2015). Computational Linguistics and Deep Learning. Computational Linguistics, 41(4), pp. 701--707. Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J. (2013) Distributed Representations of Words and Phrases and their Compositionality. In NIPS-2013. Pham, H., Luong, M., Manning, C.D. (2015). Learning Distributed Representations for Multilingual Text Sequences. In NAACL-2015. Rissen, P., Lippell, H., Chadburn, M., Leitch, T., Brickley, D., Smethurst, M., Cevey, S. (2013). Storyline Ontology. Blog post, http://www.bbc.co.uk/ontologies/storyline Rupnik, J., Muhic, A., Leban, G., Skraba, P., Fortuna, B., Grobelnik, M. (2016). News Across Languages - CrossLingual Document Similarity and Event Tracking. Journal of Artificial Intelligence Research, 55, pp.283-316. Sutskever, I., Vinyals, O., Le, Q.V. (2014). Sequence to sequence learning with neural networks. In NIPS-2014, pp. 3104--3112. Venugopalan, S., Xu, H., Donahue, J., Rohrbach, M., Mooney, R., Saenko, K. (2015). Translating Videos to Natural Language Using Deep Recurrent Neural Networks. In NAACL-2015, pp. 1494--1504. Vinyals, Q., Le, Q.L. (2015). A Neural Conversation Model. arXiv preprint arXiv:1506.05869 Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., Zemel, R., Bengio, Y. (2015). Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. arXiv preprint arXiv:1502.03044."}], "references": [{"title": "TensorFlow: Large-scale machine learning on", "author": ["S. Moore", "D. Murray", "C. Olah", "J. Shlens", "B. Steiner", "I. Sutskever", "K. Talwar", "P. Tucker", "V. Vanhoucke", "V. Vasudevan", "F. Vi\u00e9gas", "O. Vinyals", "P. Warden", "M. Wattenberg", "W. Wicke", "Y. Yu", "X. Zheng"], "venue": null, "citeRegEx": "Moore et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Moore et al\\.", "year": 2015}, {"title": "Deep speech 2: End-to-end speech recognition in english and mandarin", "author": ["D. Amodei", "R. Anubhai", "E. Battenberg", "C. Case", "J. Casper", "B. Catanzaro", "J. Chen", "M. Chrzanowski", "A. Coates", "G Diamos"], "venue": "arXiv preprint arXiv:1512.02595", "citeRegEx": "Amodei et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Amodei et al\\.", "year": 2015}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "arXiv preprint arXiv:1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Riga: Impact of Smatch Extensions and Character-Level Neural Translation on AMR Parsing Accuracy", "author": ["G. Barzdins", "D. Gosko"], "venue": "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval 2016), (to appear)", "citeRegEx": "Barzdins and Gosko,? 2016", "shortCiteRegEx": "Barzdins and Gosko", "year": 2016}, {"title": "Using C5.0 and Exhaustive Search for Boosting FrameSemantic Parsing Accuracy", "author": ["G. Barzdins", "D. Gosko", "L. Rituma", "P. Paikens"], "venue": "In Proceedings of the 9th Language Resources and Evaluation Conference (LREC),", "citeRegEx": "Barzdins et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Barzdins et al\\.", "year": 2014}, {"title": "Riga: from FrameNet to Semantic Frames with C6.0 Rules", "author": ["G. Barzdins", "P. Paikens", "D. Gosko"], "venue": "In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "Barzdins et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Barzdins et al\\.", "year": 2015}, {"title": "Natural language processing (almost) from scratch", "author": ["R. Collobert", "J. Weston", "L. Bottou", "M. Karlen", "K. Kavukcuoglu", "P. Kuksa"], "venue": "The Journal of Machine Learning Research, 12, pp. 2493--2537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Smart Replay", "author": ["G. Corrado"], "venue": "Google Research Blog post, http://googleresearch.blogspot.com/2015/11/computerrespond-to-this-email.html", "citeRegEx": "Corrado,? 2015", "shortCiteRegEx": "Corrado", "year": 2015}, {"title": "Semi-supervised Sequence Learning", "author": ["A.M. Dai", "Q.V. Le"], "venue": "NIPS-2015.", "citeRegEx": "Dai and Le,? 2015", "shortCiteRegEx": "Dai and Le", "year": 2015}, {"title": "Large scale distributed deep networks", "author": ["J. Dean", "G.S. Corrado", "R. Monga", "K. Chen", "M. Devin", "Q.V. Le", "M.Z. Mao", "M. Ranzato", "A. Senior", "P. Tucker", "K. Yang", "A.Y. Ng"], "venue": "NIPS-2012.", "citeRegEx": "Dean et al\\.,? 2012", "shortCiteRegEx": "Dean et al\\.", "year": 2012}, {"title": "MultiTask Learning for Multiple Language Translation", "author": ["D. Dong", "H. Wu", "W. He", "D. Yu", "H. Wang"], "venue": "Proceedings of the 53rd Annual Meeting of the ACL and the 7th International Joint Conference on Natural Language Processing, Beijing, China, pp. 1723--1732.", "citeRegEx": "Dong et al\\.,? 2015", "shortCiteRegEx": "Dong et al\\.", "year": 2015}, {"title": "Towards end-to-end speech recognition with recurrent neural networks", "author": ["A. Graves", "N. Jaitly"], "venue": "ICML2014.", "citeRegEx": "Graves and Jaitly,? 2014", "shortCiteRegEx": "Graves and Jaitly", "year": 2014}, {"title": "Deep Speech: Scaling up end-to-end speech recognition", "author": ["A. Hannun", "C. Case", "J. Casper", "B. Catanzaro", "G. Diamos", "E. Elsen", "R. Prenger", "S. Satheesh", "S. Sengupta", "A. Coates", "A.Y. Ng"], "venue": "arXiv preprint arXiv:1412.5567", "citeRegEx": "Hannun et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hannun et al\\.", "year": 2014}, {"title": "Learning Distributed Representations of Sentences from Unlabelled Data", "author": ["F. Hill", "K. Cho", "A. Korhonen"], "venue": "arXiv preprint arXiv:1602.03483", "citeRegEx": "Hill et al\\.,? 2016", "shortCiteRegEx": "Hill et al\\.", "year": 2016}, {"title": "Exploring the Limits of Language Modeling", "author": ["R. Jozefowicz", "O. Vinyals", "M. Schuster", "N. Shazeer", "W. Wu"], "venue": "arXiv preprint arXiv:1602.02410", "citeRegEx": "Jozefowicz et al\\.,? 2016", "shortCiteRegEx": "Jozefowicz et al\\.", "year": 2016}, {"title": "The unreasonable effectiveness of recurrent neural networks", "author": ["A. Karpathy"], "venue": "Blog post, http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "citeRegEx": "Karpathy,? 2015", "shortCiteRegEx": "Karpathy", "year": 2015}, {"title": "A Hierarchical Neural Autoencoder for Paragraphs and Documents", "author": ["J. Li", "T. Luong", "D. Jurafsky"], "venue": "Proceedings of the 53rd Annual Meeting of the ACL and the 7th International Joint Conference on NLP, Beijing, China, pp. 1106--1115.", "citeRegEx": "Li et al\\.,? 2015", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Multi-task Sequence to Sequence Learning", "author": ["T. Luong", "Q.V. Le", "I. Sutskever", "O. Vinyals", "L. Kaiser"], "venue": "ICLR-2016.", "citeRegEx": "Luong et al\\.,? 2016", "shortCiteRegEx": "Luong et al\\.", "year": 2016}, {"title": "Addressing the rare word problem in neural machine translation", "author": ["T. Luong", "I. Sutskever", "Q.V. Le", "O. Vinyals", "W. Zaremba"], "venue": "Proceedings of the 53rd Annual Meeting of the ACL and the 7th International Joint Conference on NLP, Beijing, China, pp. 11--19.", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Computational Linguistics and Deep Learning", "author": ["C.D. Manning"], "venue": "Computational Linguistics, 41(4), pp. 701--707.", "citeRegEx": "Manning,? 2015", "shortCiteRegEx": "Manning", "year": 2015}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G. Corrado", "J. Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Learning Distributed Representations for Multilingual Text Sequences", "author": ["H. Pham", "M. Luong", "C.D. Manning"], "venue": "NAACL-2015.", "citeRegEx": "Pham et al\\.,? 2015", "shortCiteRegEx": "Pham et al\\.", "year": 2015}, {"title": "Storyline Ontology", "author": ["P. Rissen", "H. Lippell", "M. Chadburn", "T. Leitch", "D. Brickley", "M. Smethurst", "S. Cevey"], "venue": "Blog post, http://www.bbc.co.uk/ontologies/storyline", "citeRegEx": "Rissen et al\\.,? 2013", "shortCiteRegEx": "Rissen et al\\.", "year": 2013}, {"title": "News Across Languages - CrossLingual Document Similarity and Event Tracking", "author": ["J. Rupnik", "A. Muhic", "G. Leban", "P. Skraba", "B. Fortuna", "M. Grobelnik"], "venue": "Journal of Artificial Intelligence Research, 55, pp.283-316.", "citeRegEx": "Rupnik et al\\.,? 2016", "shortCiteRegEx": "Rupnik et al\\.", "year": 2016}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "NIPS-2014, pp. 3104--3112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Translating Videos to Natural Language Using Deep Recurrent Neural Networks", "author": ["S. Venugopalan", "H. Xu", "J. Donahue", "M. Rohrbach", "R. Mooney", "K. Saenko"], "venue": "NAACL-2015, pp. 1494--1504.", "citeRegEx": "Venugopalan et al\\.,? 2015", "shortCiteRegEx": "Venugopalan et al\\.", "year": 2015}, {"title": "A Neural Conversation Model", "author": ["Q. Vinyals", "Q.L. Le"], "venue": "arXiv preprint arXiv:1506.05869", "citeRegEx": "Vinyals and Le,? 2015", "shortCiteRegEx": "Vinyals and Le", "year": 2015}, {"title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention", "author": ["K. Xu", "J. Ba", "R. Kiros", "K. Cho", "A. Courville", "R. Salakhutdinov", "R. Zemel", "Y. Bengio"], "venue": "arXiv preprint arXiv:1502.03044.", "citeRegEx": "Xu et al\\.,? 2015", "shortCiteRegEx": "Xu et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 19, "context": "The key difference of the SUMMA project is that it has been incepted after the recent paradigm-shift (Manning, 2015) in the NLP community towards neural network inspired deep learning techniques such as end-to-end automatic speech recognition (Graves & Jaitly, 2014; Hannun et al.", "startOffset": 101, "endOffset": 116}, {"referenceID": 12, "context": "The key difference of the SUMMA project is that it has been incepted after the recent paradigm-shift (Manning, 2015) in the NLP community towards neural network inspired deep learning techniques such as end-to-end automatic speech recognition (Graves & Jaitly, 2014; Hannun et al., 2014; Amodei, 2015), end-to-end machinetranslation (Sutskerev, Vinyals & Le, 2014; Bahdanau, Cho & Bengio, 2014; Luong et al.", "startOffset": 243, "endOffset": 301}, {"referenceID": 18, "context": ", 2014; Amodei, 2015), end-to-end machinetranslation (Sutskerev, Vinyals & Le, 2014; Bahdanau, Cho & Bengio, 2014; Luong et al., 2015), efficient distributed vectorspace word embeddings (Mikolov et al.", "startOffset": 53, "endOffset": 134}, {"referenceID": 20, "context": ", 2015), efficient distributed vectorspace word embeddings (Mikolov et al., 2013), image and video captioning (Xu et al.", "startOffset": 59, "endOffset": 81}, {"referenceID": 27, "context": ", 2013), image and video captioning (Xu et al., 2015; Venugopalan et al., 2015), unsupervised learning of document representations by autoencoders (Li, Luong & Jurafsky, 2015).", "startOffset": 36, "endOffset": 79}, {"referenceID": 25, "context": ", 2013), image and video captioning (Xu et al., 2015; Venugopalan et al., 2015), unsupervised learning of document representations by autoencoders (Li, Luong & Jurafsky, 2015).", "startOffset": 36, "endOffset": 79}, {"referenceID": 6, "context": "The novelty of the SUMMA project approach is that all languages covered by the project (Table 1) can be embedded in the same vectorspace by means of joint multitask learning (Collobert et al., 2011; Dong et al., 2015; Pham, Luong & Manning, 2015) of eight LSTM-RNN translational autoencoders with hidden layer parameters shared as illustrated in Fig.", "startOffset": 174, "endOffset": 246}, {"referenceID": 10, "context": "The novelty of the SUMMA project approach is that all languages covered by the project (Table 1) can be embedded in the same vectorspace by means of joint multitask learning (Collobert et al., 2011; Dong et al., 2015; Pham, Luong & Manning, 2015) of eight LSTM-RNN translational autoencoders with hidden layer parameters shared as illustrated in Fig.", "startOffset": 174, "endOffset": 246}, {"referenceID": 9, "context": "To avoid complexities of asynchronous parallel training with shared parameter server (Dean et al., 2012), the architecture in Fig.", "startOffset": 85, "endOffset": 104}, {"referenceID": 17, "context": "3 instead can be trained using the alternating training approach proposed in (Luong et al., 2016), where each task is optimized for a fixed number of parameter updates (or mini-batches) before switching to the next task (which is a different language pair).", "startOffset": 77, "endOffset": 97}, {"referenceID": 10, "context": "Neural translation attention mechanism (Bahdanau, Cho & Bengio, 2014) has been shown to be highly beneficial for bi-lingual neural translation of long sentences, but it is not compatible with the multi-task multilingual translation models (Dong et al., 2015; Luong et al, 2016) described in the previous Section and character-level translation models (Barzdins & Gosko, 2016) described in this Section.", "startOffset": 239, "endOffset": 277}, {"referenceID": 15, "context": "A better approach to translating such languages is to use the character-level translation model (Barzdins & Gosko, 2016; Karpathy, 2015; Jozefowicz, 2016).", "startOffset": 96, "endOffset": 154}, {"referenceID": 7, "context": "For stream segmentation into the stories it is possible to utilize the exceptional generalization and memorization capacity of the neural networks, which is already applied in the neural dialogue systems such as Gmail Smart Replies (Corrado, 2015; Vinyals&Le, 2015).", "startOffset": 232, "endOffset": 265}, {"referenceID": 22, "context": "Particularly for storyline (Rissen et al., 2013) clustering the signals for the stories belonging to the same storyline might be not so much the semantic similarity of the articles (they might report various developments of the storyline from differing viewpoints), but rather the matching time and location as well as same organizations and people being involved \u2013 the information typically supplied by Named Entity Linking (NEL) tools.", "startOffset": 27, "endOffset": 48}], "year": 2016, "abstractText": "The paper steps outside the comfort-zone of the traditional NLP tasks like automatic speech recognition (ASR) and machine translation (MT) to addresses two novel problems arising in the automated multilingual news monitoring: segmentation of the TV and radio program ASR transcripts into individual stories, and clustering of the individual stories coming from various sources and languages into storylines. Storyline clustering of stories covering the same events is an essential task for inquisitorial media monitoring. We address these two problems jointly by engaging the low-dimensional semantic representation capabilities of the sequence to sequence neural translation models. To enable joint multi-task learning for multilingual neural translation of morphologically rich languages we replace the attention mechanism with the sliding-window mechanism and operate the sequence to sequence neural translation model on the character-level rather than on the word-level. The story segmentation and storyline clustering problem is tackled by examining the low-dimensional vectors produced as a side-product of the neural translation process. The results of this paper describe a novel approach to the automatic story segmentation and storyline clustering problem.", "creator": "Word"}}}