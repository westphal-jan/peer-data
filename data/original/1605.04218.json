{"id": "1605.04218", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-May-2016", "title": "Anytime Inference in Valuation Algebras", "abstract": "Anytime inference is inference performed incrementally, with the accuracy of the inference being controlled by a tunable parameter, usually time. Such anytime inference algorithms are also usually interruptible, gradually converging to the exact inference value until terminated. While anytime inference algorithms for specific domains like probability potentials exist in the literature, our objective in this article is to obtain an anytime inference algorithm which is sufficiently generic to cover a wide range of domains. For this we utilise the theory of generic inference as a basis for constructing an anytime inference algorithm, and in particular, extending work done on ordered valuation algebras. The novel contribution of this work is the construction of anytime algorithms in a generic framework, which automatically gives us instantiations in various useful domains. We also show how to apply this generic framework for anytime inference in semiring induced valuation algebras, an important subclass of valuation algebras, which includes instances like probability potentials, disjunctive normal forms and distributive lattices.", "histories": [["v1", "Fri, 13 May 2016 15:40:10 GMT  (46kb,D)", "http://arxiv.org/abs/1605.04218v1", "9 pages, 1 figure"]], "COMMENTS": "9 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["abhishek dasgupta", "samson abramsky"], "accepted": false, "id": "1605.04218"}, "pdf": {"name": "1605.04218.pdf", "metadata": {"source": "CRF", "title": "Anytime Inference in Valuation Algebras", "authors": ["Abhishek Dasgupta", "Samson Abramsky"], "emails": ["abhishek.dasgupta@cs.ox.ac.uk", "samson.abramsky@cs.ox.ac.uk"], "sections": [{"heading": null, "text": "Keywords: Approximation; Anytime algorithms; Resourcebounded computation; Generic inference; Valuation algebras; Local computation; Binary join trees."}, {"heading": "1 Introduction", "text": "The inference problem is one of the most-important and well-studied problems in the field of statistics and machine learning. Inference can be considered as the (1) combination of information from various sources, which could be in the form of probability distributions from a probabilistic graphical model [12], belief functions in DempsterShafer theory [3, 8] or tables in a relational database; and (2) subsequent focusing or projection to variables of interest, which corresponds to projection for variables in probabilistic graphical models, or a query in the relational database. Our work is based on the theory of generic inference [17] which abstracts and generalises the inference problem across these different areas.\nThe utility of generic inference can be understood as an analogue to sorting, which is agnostic to the specific data type, as long as there is a total order. Generic inference generalises inference algorithms by abstracting the essential components of information in an algebraic structure. In [13], an algorithm was defined which solved the inference problem on Bayesian networks, using a technique called local computation. It was noted in [23] that the same algorithm could be used to solve the inference problem on belief functions, and a sufficient set of axioms were proposed for an algebraic framework that is necessary for the generic inference algorithm. This was extended by Kohlas into a theory of valuation algebras, and a computer implementation of inference over valuation algebras along with concrete instantiations was developed in [16].\n1 Department of Computer Science, University of Oxford, e-mail: abhishek.dasgupta@cs.ox.ac.uk 2 Department of Computer Science, University of Oxford, e-mail: samson.abramsky@cs.ox.ac.uk\nGeneric inference as formulated in [17] solves the inference problem in the exact case. As exact inference is an #P-hard problem [25], in practice, we need frameworks for approximate inference. Approximation schemes exist for specific instances of valuation algebras (probability potentials [2], belief potentials [6]); as well as for the generic case [5], but there is no such generic framework for anytime inference. In this paper, we extend the approximate inference framework in [5] to support anytime inference.\nIn anytime algorithms, instead of an algorithm terminating after an unspecified amount of time with a specific accuracy, we are able to tune the accuracy via a parameter passed to the algorithm. The algorithm can also be designed to be interruptible, gradually improving its accuracy until terminated by the user. Such algorithms are important in online learning where new data is being streamed in [24], in intelligent systems, decision making under uncertainty [7] and robotics [28] where due to the limitation of interacting in real-time there may not be sufficient time to compute an exact solution. We shall consider interruptible anytime algorithms which can be interrupted at any time and the approximation can be improved by resuming the algorithm. This affords the greatest flexibility from the user\u2019s perspective, with applications of such algorithms to real-time systems such as sensor networks and path planning.\nTable 1 notes the previous work done in the area of inference algorithms, in both the generic case and for the specific case of probability potentials, and situates our work in context.\nWe note that the successive rows in the above table refine upon the previous one, and include it; the approximate inference framework can also perform exact inference, and the anytime inference framework presented here gives an approximate solution which incrementally improves with time, converging on the solution obtained from exact inference given sufficient time.\nThis article is divided into the following sections. Section 2 reviews the framework of valuation algebras and ordered valuation algebras. Section 3 introduces our extension to ordered valuation algebras to support anytime inference, and proves soundness and completeness theorems for anytime inference. Section 4 describes instances of the framework, including its application to anytime inference in semiringinduced valuation algebras. Section 5 gives a complexity analysis of the algorithm. Section 6 shows implementation results of anytime inference on a Bayesian network. Section 7 concludes.\nar X\niv :1\n60 5.\n04 21\n8v 1\n[ cs\n.A I]\n1 3\nM ay\n2 01\n6"}, {"heading": "2 Valuation Algebras", "text": "Valuation algebras are the core algebraic structure in the theory of generic inference. In a valuation algebra, we consider the various pieces of information in an inference problem (conditional probability distributions, belief potentials, relational database tables, etc.) as elements in an algebraic structure with a set of axioms. We review the axioms of valuation algebra [17] below, preceded by some remarks on notation.\nAll operations in the valuation algebra are defined on elements denoted by lowercase Greek letters: \u03c6 ,\u03c8, . . .. We can think of a valuation as the information contained by the possible values of a set of variables, which are denoted by Roman lowercase letters (with possible subscripts): x,y, . . . and denote sets of variables by uppercase letters: S,T, . . .. Each valuation refers to the information contained in a set of variables which we call the domain of a valuation, denoted by d(\u03c6) for a valuation \u03c6 . For a finite set of variables D, \u03a6D denotes the set of valuations \u03c6 for which d(\u03c6) = D. Thus, the set of all possible valuations for a countable set of variables V is\n\u03a6 = \u22c3\nD\u2286V \u03a6D (1)\nIf D\u0302 = P f (V ) the finite powerset of V , and \u03a6 the set of valuations with domains in D\u0302; we define the following operations on \u3008\u03a6, D\u0302\u3009: (i) labeling: \u03a6 \u2192 D\u0302;\u03c6 7\u2192 d(\u03c6) (ii) combination: \u03a6 \u00d7 \u03a6 7\u2192 \u03a6;(\u03c6 ,\u03c8) 7\u2192 \u03c6 \u2297 \u03c8 (iii) projection: \u03a6\u00d7 D\u0302\u2192\u03a6;(\u03c6 ,X) 7\u2192 \u03c6\u2193X for X \u2286 d(\u03c6)\nThese are the basic operations of a valuation algebra. Using the view of valuations as pieces of information which refer to questions as valuations, the labelling operation tells us which set of variables the valuation refers to; the combination operation aggregates the information, and the projection operation focuses the information on a particular question (query) of interest. Projection is also referred to as focusing or marginalization. The following axioms are then imposed on \u3008\u03a6, D\u0302\u3009:\n(A1) Commutative semigroup: \u03a6 is associative and commutative under \u2297\n(A2) Labeling: For \u03c6 ,\u03c8 \u2208\u03a6, d(\u03c6 \u2297\u03c8) = d(\u03c6)\u222ad(\u03c8). (A3) Projection: For \u03c6 \u2208 \u03a6,X \u2208 D\u0302 and X \u2286 d(\u03c6), d(\u03c6\u2193X ) = X . Alternatively this is equivalent to the following elimination operation, \u03c6\u2193X = \u03c6\u2212(d(\u03c6)\\X) where all the variables except those in X are eliminated.\n(A4) Transitivity: For \u03c6 \u2208\u03a6 and X \u2286 Y \u2286 d(\u03c6), (\u03c6\u2193Y )\u2193X = \u03c6\u2193X . (A5) Combination: For \u03c6 ,\u03c8 \u2208 \u03a6 with d(\u03c6) = X , d(\u03c8) = Y and\nZ \u2208 D such that X \u2286 Z \u2286 X \u222aY , (\u03c6 \u2297\u03c8)\u2193Z = \u03c6 \u2297\u03c8\u2193Z\u2229Y . (A6) Domain: For \u03c6 \u2208\u03a6 with d(\u03c6) = X , \u03c6\u2193X = \u03c6 .\nFor the intuitive reading of these axioms, we refer the reader to [17, 23].\nBefore proceeding to approximate inference, we formally define the inference problem:\nDefinition 1. The inference problem is the task of computing\n\u03c6\u2193X = (\u03c61\u2297\u00b7\u00b7 \u00b7\u2297\u03c6r)\u2193X (2)\nfor a given knowledgebase {\u03c61, . . . ,\u03c6r} \u2286\u03a6; domain X is the query for the inference problem.\nNext we consider approximate inference. Existing approximation schemes, like the mini-bucket scheme [2] are either not general enough or do not provide a reliable measure of the approximation and\nhow to improve the approximation in an anytime algorithm. In this article, we have used the ordered valuation algebra framework defined in [5] as a basis for constructing an anytime algorithm. We thus review the extra axioms of the ordered valuation algebra framework, which introduces the notion of a partial order into the valuation algebra, and defines a partial combination operator \u2297t to construct approximate inference algorithms.\nFirstly we define a relation which represents an information ordering. If \u03c6 ,\u03c6 \u2032 are two valuations, then \u03c6 \u03c6 \u2032 means that \u03c6 is more complete than \u03c6 \u2032. Intuitively, the information contained in \u03c6 is more informative and a better approximation than the information contained by \u03c6 \u2032; generally this means \u03c6 \u2032 has a more compact or sparse representation than \u03c6 . Furthermore, we assume that this relation is a partial order. It is also reasonable to assume that approximations are only valid for valuations with equal domains; thus \u03c6 \u03c6 \u2032 implies d(\u03c6) = d(\u03c6 \u2032) for all \u03c6 ,\u03c6 \u2032 \u2208 \u03a6. Thus actually defines separate completeness relations D for each sub-semigroup \u03a6D.\nWe also impose the condition of each sub-semigroup \u03a6D having a zero element, denoted by nD, where \u03c6 \u2297 nD = nD\u2297 \u03c6 = nD. For notational simplicity we shall also denote the neutral element by \u2205 (without a subscript), denoting the appropriate neutral element corresponding to a particular domain.\nAn ordered valuation algebra is still a valuation algebra, so it retains all the axioms (A1)-(A6) introduced previously. The additional axioms are about how behaves under combination and marginalization:\n(A7) Partial order: There is a partial order on \u03a6 such that \u03c6 \u03c6 \u2032 implies d(\u03c6) = d(\u03c6 \u2032) for all \u03c6 ,\u03c6 \u2032 \u2208\u03a6.\n(A8) Zero element: We assume that the zero element for the combination operation, nD is the least element of the approximation order D for all D\u2286V . Also, since zero elements for a particular domain are unique, nD1 \u2297nD2 = nD1\u222aD2 for D1,D2 \u2286V . Also, n \u2193D\u2032 D = nD\u2032 for all D\u2032 \u2286 D.\n(A9) Combination preserves partial order: If \u03c61,\u03c6 \u20321,\u03c62,\u03c6 \u2032 2 \u2208\u03a6 are valuations such that \u03c61 \u03c6 \u20321 and \u03c62 \u03c6 \u20322, then \u03c61\u2297\u03c62 \u03c6 \u20321\u2297\u03c6 \u20322 (A10) Marginalisation preserves partial order: If \u03c6 ,\u03c6 \u2032 \u2208 \u03a6 are valuations such that \u03c6 \u03c6 \u2032, then \u03c6\u2193D \u03c6 \u2032\u2193D for all D \u2286 d(\u03c6) = d(\u03c6 \u2032).\nDefinition 2. The time-bounded combination operator [5] \u2297t : \u03a6\u00d7\u03a6\u2192 \u03a6 is used to approximate the exact computation during the propagation phase. \u2297t performs a partial combination of two valuations within time t units, where t \u2208R+. The following properties are satisfied by \u2297t :\n(R1) \u03c61\u2297\u03c62 \u03c61\u2297t \u03c62.\n(R2) \u03c61\u2297t \u2032 \u03c62 \u03c61\u2297t \u03c62 for all t \u2032 > t.\n(R3) \u03c61\u22970 \u03c62 = nd(\u03c61)\u222ad(\u03c62).\n(R4) \u03c61\u2297\u221e \u03c62 = \u03c61\u2297\u03c62.\nDefinition 3. Such a system \u3008\u03a6,V, ,d,\u2297,\u2193,\u2297t\u3009 of valuations \u03a6, variables V , a completeness relation and a time-bounded combination operation \u2297t is called an ordered valuation algebra, if the labeling operations d, combination \u2297 and marginalization \u2193 satisfy (A1)-(A10).\nDefinition 4. A binary join tree (BJT) N = \u3008V,E\u3009 corresponding to a knowledgebase {\u03c61, . . . ,\u03c6r} is a covering junction tree for the\ninference problem, constructed in a manner such that the tree is binary. The valuations in the knowledgebase form the leaves of the tree, thus |V (N)| = 2r\u2212 1, |E(N)| = 2r\u2212 2, while the query X \u2286 d(root(N)). Inference takes place by message passing in the BJT (for details of the algorithm, see [22, 5]). In the next section we shall modify this message passing algorithm to cache partial valuations for anytime inference."}, {"heading": "3 Anytime Ordered Valuation Algebras", "text": "In this section, we augment ordered valuation algebras in a structure we refer to as anytime ordered valuation algebras. We introduce the extension, and in the following section give examples of anytime ordered valuation algebras. The primary purpose of introducing anytime ordered valuation algebras is to develop an anytime inference algorithm within the framework of generic inference. Such extensions preserve the generic structure of valuation algebras, but add restrictions to simplify or add features to the inference algorithm; in another instance, valuation algebras were extended to weighted valuation algebras to study communication complexity [18].\nBefore defining anytime ordered valuation algebras, we define a couple of prerequisites; the composition operation and a truncation function.\nDefinition 5. The composition operator,\u2295 : \u03a6\u00d7\u03a6\u2192\u03a6;(\u03c6 \u2032,\u03c6 \u2032\u2032) 7\u2192 \u03c6 combines valuations \u03c6 \u2032 and \u03c6 \u2032\u2032 into a valuation \u03c6 more complete than either (\u03c6 \u03c6 \u2032,\u03c6 \u03c6 \u2032\u2032). This is not to be confused with the combination operation \u2297 which generally combines valuations from different domains. The valuations being composed belong to the same approximation order D, where D = d(\u03c6 \u2032) = d(\u03c6 \u2032\u2032) = d(\u03c6). It is natural in this context to consider whether composition should be a supremum operation. However, this cannot be assumed in general.\nDefinition 6. The truncation function \u03c1 : \u03a6\u00d7R+ \u2192 \u03a6 performs a truncation of the information contained in the valuation, according to the real valued parameter. Also, \u03c1 is defined to be monotonically increasing with the real valued parameter, thus \u03c1(\u03c6 ,k) \u03c1(\u03c6 ,k\u2032) whenever k \u2265 k\u2032.\nThe time-bounded combination operation \u2297t can be recast such that truncation of the original pair of valuations followed by exact combination is equivalent to doing a time-bounded combination:\n\u03c61\u2297t \u03c62 = \u03c1(\u03c61,k1)\u2297\u03c1(\u03c62,k2) (3)\nThe parameters k1,k2 determining the truncated portions of \u03c61,\u03c62 will be important later in defining the partial valuations which will be used in the refinement algorithm for anytime inference. As k1,k2 are parameters that depend on the particular valuations \u03c61,\u03c62 and the time t, this assumes a function K(\u03c61,\u03c62, t) = (k1,k2).\nFollowing these two definitions, we extend the system of axioms (A1-A10) for ordered valuation algebras, with the properties (P1) and (P2):\n(P1) The combination operation \u2297 distributes over \u2295:\n(\u03c6 \u20321\u2295\u03c6 \u2032\u20321 )\u2297 (\u03c6 \u20322\u2295\u03c6 \u2032\u20322 ) = (\u03c6 \u20321\u2297\u03c6 \u20322)\u2295 (\u03c6 \u20321\u2297\u03c6 \u2032\u20322 )\u2295 (\u03c6 \u2032\u20321 \u2297\u03c6 \u20322)\u2295 (\u03c6 \u2032\u20321 \u2297\u03c6 \u2032\u20322 )\ufe38 \ufe37\ufe37 \ufe38 REFINE\u2032(\u03c6 \u20321,\u03c6 \u2032\u20321 ,\u03c6 \u20322,\u03c6 \u2032\u20322 )\n(4)\nHere, \u03c6 \u20321\u2297 \u03c6 \u20322 = \u03c1(\u03c61,k1)\u2297\u03c1(\u03c62,k2) is a truncated valuation of the exact combined valuation \u03c61\u2297\u03c62; REFINE\u2032 is the part of the exact valuation that needs to be composed with the truncated valuation \u03c6 \u20321 \u2297 \u03c6 \u20322 to complete the valuation. We also use the time-bounded operation REFINE\u2032t for the same operation bounded by a time t, with an analogous definition in terms of truncation functions as \u2297t in equation 3:\nREFINE\u2032t(\u03c6 \u2032 1,\u03c6 \u2032\u2032 1 ,\u03c6 \u2032 2,\u03c6 \u2032\u2032 2 ) = REFINE \u2032(\u03c6 \u20321,\u03c1(\u03c6 \u2032\u2032 1 ,k1),\u03c6 \u2032 2,\u03c1(\u03c6 \u2032\u2032 2 ,k2))\n(5) where the parameters k1,k2 are obtained from an assumed function K\u2032(\u03c61,\u03c6 \u20321,\u03c6 \u2032 2,\u03c6 \u2032\u2032 2 , t) = (k1,k2).\n(P2) The projection operation \u2193 distributes over \u2295:\n(\u03c6 \u2032\u2295\u03c6 \u2032\u2032)\u2193D = \u03c6 \u2032\u2193D\u2295\u03c6 \u2032\u2032\u2193D,D\u2286 d(\u03c6). (6)\nWe can now formally define the anytime ordered valuation algebra.\nDefinition 7. An anytime ordered valuation algebra is an ordered valuation algebra \u3008V,\u03a6,d,\u2297,\u2193,\u2297t , \u3009 with the additional operations of composition \u2295 and the function \u03c1 , making the structure \u3008V,\u03a6,d,\u03c1,\u2297,\u2193,\u2295,\u2297t , \u3009, which satisfies properties (P1) and (P2).\nWe show by construction that the composition operator \u2295 : \u03a6\u00d7\u03a6\u2192 \u03a6 with (P1, P2) along with the truncation function \u03c1 : \u03a6\u00d7R+\u2192\u03a6 is sufficient to construct a refinement algorithm to improve the accuracy of a valuation.\nTo describe a refinement algorithm to improve upon the result provided by INWARD(N, t), we need to cache the partial valuations at each step so that we can use REFINE\u2032 to improve upon them. We use a modified version of the propagation algorithm [22, 5], where \u03c4 and \u03c4\u0304 store the partial and complementary partial valuations respectively for a particular BJT node, where the complementary partial valuation \u03c1\u0304(\u03c6 ,k) is such that \u03c1\u0304(\u03c6 ,k)\u2295\u03c1(\u03c6 ,k)= \u03c6 . In the following procedures, \u2206(n) = d(n)\\d(P(n)) is the set of variables to be eliminated as we propagate messages to the parent node. To get the solution to the inference problem at the final step, we also define \u2206(root(N)) = d(root(N))\\X where X is the query. There are r valuations in the knowledgebase resulting in r\u22121 combination steps in the BJT. P(n) is the parent of n, \u03c6(n) is the valuation at node n, \u03c6s(n) is the message from n to P(n); L(n),R(n) are the left and right nodes of n respectively and\nnext(N) = {n \u2208 N : \u03c6s(n) = nil,\u03c6s(L(n)) 6= nil,\u03c6s(R(n)) 6= nil} (7)\nBoth INWARD(N, t) and REFINE(N, t) return valuations which are the (approximate) solution to the inference problem.\n1: procedure INWARD(N, t) 2: s\u2190 r\u22121; 3: initialise timer to t units. 4: for all n \u2208 leaves(N) do \u03c6s(n)\u2190 \u03c6(n)\u2212\u2206(n) 5: while next(N) 6= /0 do 6: select n \u2208 next(N) 7: (k1,k2)\u2190 K(\u03c6s(L(n)),\u03c6s(R(n)), t/s) 8: \u03c6(n)\u2190 \u03c6s(L(n))\u2297t/s \u03c6s(R(n)) 9: \u03c4(L(n))\u2190 \u03c1(\u03c6s(L(n)),k1)\n10: \u03c4(R(n))\u2190 \u03c1(\u03c6s(R(n)),k2) 11: \u03c4\u0304(L(n))\u2190 \u03c1\u0304(\u03c6s(L(n)),k1)"}, {"heading": "12: \u03c4\u0304(R(n))\u2190 \u03c1\u0304(\u03c6s(R(n)),k2)", "text": "13: \u03c6s(n)\u2190 \u03c6(n)\u2212\u2206(n) 14: s\u2190 s\u22121 15: t\u2190 timer() 16: end while 17: return \u03c6s(root(N)) 18: end procedure\nWe can use the cached partial valuations in \u03c4 and \u03c4\u0304 to define the refinement algorithm that follows in a similar manner to the algorithm in [6].\n1: procedure REFINE(N, t) 2: initialise timer to t units 3: s\u2190 r\u22121 4: while next(N) 6= /0 do 5: select n \u2208 next(N) 6: (k1,k2)\u2190 K\u2032(\u03c4(L(n)), \u03c4\u0304(L(n)),\u03c4(R(n)), \u03c4\u0304(R(n)), t/s) 7: \u03bd \u2190 REFINE\u2032t/s(\u03c4(L(n)), \u03c4\u0304(L(n)),\u03c4(R(n)), \u03c4\u0304(R(n))) 8: t\u2190 timer() 9: \u03c4(L(n))\u2190 \u03c4(L(n))\u2295\u03c1(\u03c4\u0304(L(n)),k1)\n10: \u03c4(R(n))\u2190 \u03c4(R(n))\u2295\u03c1(\u03c4\u0304(R(n)),k2) 11: \u03c4\u0304(L(n))\u2190 \u03c1\u0304(\u03c4\u0304(L(n)),k1) 12: \u03c4\u0304(R(n))\u2190 \u03c1\u0304(\u03c4\u0304(R(n)),k2) 13: \u03c6(n)\u2190 \u03c6(n)\u2295\u03bd 14: \u03c4\u0304(n)\u2190 \u03c4\u0304(n)\u2295\u03bd\u2212\u2206(n) 15: s\u2190 s\u22121 16: end while 17: return \u03c6s(root(N)) 18: end procedure\nThis procedure refines the existing valuations in the binary join tree N, taking at most time t units. We ensure that the algorithm is interruptible in lines 9\u201312 using appropriate caching of partial valuations. A diagram of the truncation of a valuation is shown below to illustrate anytime refinement.\n\u03c6k \u03c6k \u03c6(exact) uncomputed\nHere, and in the following proof, the notation \u03c6 k := \u03c1(\u03c6 ,k) and \u03c6k := \u03c1\u0304(\u03c6 ,k). We shall also abbreviate the notation \u03c4(L(n)) as \u03c4L and \u03c4\u0304(L(n)) as \u03c4\u0304L (accordingly for R(n)), and \u03c4\u0304(n) as \u03c4\u0304 . The shaded region \u03c6 k is the part that has already been combined, while \u03c6k represents the cached part that has not been combined yet. The dotted region represents the part of \u03c6 that is yet uncomputed, due to truncated messages from child nodes; line 14 in REFINE(N, t) shrinks the uncomputed portion by extending \u03c4\u0304 .\nTheorem 1 (Soundness of anytime inference). If \u03c6[t0,t1,...,t j ] is the valuation returned after the following invocations:[ INWARD(N0, t0 > 0), REFINE(N1, t1), . . . , REFINE(N j, t j) ] , where Nk+1 is the modified BJT with the cached valuations after step k, then \u03c6[t0] \u03c6[t0,t1] \u00b7\u00b7 \u00b7 \u03c6[t0,t1,...,t j ] \u00b7\u00b7 \u00b7 \u03c6 where \u03c6 is the exact valuation. The sequence becomes strictly increasing (upto the exact\nvaluation) if ti > t\u03b5 for all i > 0 where t\u03b5 is the minimum time required for the refinement to update one valuation.\nProof. We split the proof into two parts: (S1) proving that the sequence of valuations returned from successive calls to REFINE are partially ordered and (S2) showing the upper bound is the exact valuation, to which the partial valuations converge after a finite time.\nProving (S1) is trivial; for each node, \u03c6 is updated once (line 13), thus \u03c6 \u2032 = (\u03c6 \u2295\u03bd) \u03c6 , where \u03c6 \u2032 is the valuation at node n after a call to REFINE. Using transitivity of the partial order, we obtain (S1). In the case when ti > t\u03b5 , at least one valuation is updated, resulting in \u03bd \u2205, which gives \u03c6 \u2032 \u03c6 .\nTo prove (2) we shall note the following statements\n(T1) (\u03c6k)m = (\u03c6 k+m)k\n(T2) \u03c6 k\u2295\u03c6k = \u03c6\n(T3) \u03c6 k\u2295 (\u03c6k)m = \u03c6 k+m\n(T4) (\u03c6k)m = \u03c6k+m\nFor notational simplicity, only for the following proof, we denote \u03c6\u03c8 := \u03c6 \u2297\u03c8 and + :=\u2295.\nSince each node is only updated once, we can consider a particular node; let\u2019s denote by \u03c6 the valuation at node n after INWARD(N, t0). If (k1,k2) are the parameters obtained from K\u2032 in REFINE(N1, t1) then the updated valuation \u03c6 \u2032 = \u03c6 + \u03c4L\u03c4\u0304k2R + \u03c4\u0304 k1 L \u03c4R + \u03c4\u0304 k1 L \u03c4\u0304 k2 R , where \u03c6 = \u03c4L\u03c4R.\nHere we note that we can replace (\u03c4\u0304L,R)k with their exact counterpart (\u03c4\u0304\u221eL,R)\nk, where we use the \u03c4\u0304\u221e to denote the exact valuation. This can be done as the truncation function is invariant under extension of the valuation to incorporate previously uncomputed information. Following this, we shall drop the superscript and use \u03c4\u0304L to denote \u03c4\u0304\u221eL .\nThen if we consider a subsequent call, REFINE(N2, t2), \u03c6 \u2032\u2032 = \u03c6 \u2032+ \u03c4 \u2032L\u03c4\u0304 \u2032m2 R + \u03c4\u0304 \u2032m1 L \u03c4 \u2032 R + \u03c4\u0304 \u2032m1 L \u03c4\u0304 \u2032m2 R . where the additional prime indicates the the value for this iteration, and (m1,m2) are the parameters obtained from K\u2032.\nFrom lines 9\u201312 in REFINE we get: \u03c4 \u2032L = \u03c4L + \u03c4\u0304 k1 L , \u03c4 \u2032 R = \u03c4R + \u03c4\u0304 k2 R ,\n\u03c4\u0304 \u2032L = (\u03c4\u0304L)k1 , \u03c4\u0304 \u2032 R = (\u03c4\u0304R)k2\nExpanding \u03c6 \u2032\u2032 we get:\n\u03c6 \u2032\u2032 = \u03c4L\u03c4R + \u03c4L\u03c4\u0304k2R + \u03c4\u0304 k1 L \u03c4R + \u03c4\u0304 k1 L \u03c4\u0304 k2 R\n+ (\u03c4L + \u03c4\u0304k1L )(\u03c4\u0304R,k2) m2 +(\u03c4\u0304L,k1) m1(\u03c4R + \u03c4\u0304k2R )+(\u03c4\u0304L,k1) m1(\u03c4\u0304R,k2) m2\n= \u03c4L\u03c4R + \u03c4L\u03c4\u0304k2R + \u03c4\u0304 k1 L \u03c4R + \u03c4\u0304 k1 L \u03c4\u0304 k2 R + \u03c4L(\u03c4\u0304R,k2) m2\n+(\u03c4\u0304k1L )(\u03c4\u0304R,k2) m2 +(\u03c4\u0304L,k1) m1 \u03c4R +(\u03c4\u0304L,k1)\u03c4\u0304 k2 R +(\u03c4\u0304L,k1) m1(\u03c4\u0304R,k2) m2\n= \u03c4L\u03c4R + \u03c4L\u03c4\u0304k2+m2R + \u03c4\u0304 k1+m1 L \u03c4R + \u03c4\u0304 k1+m1 L \u03c4\u0304 k2+m2 R\nHere we use (T1,T3) to simplify the expression. Note that this is the same form as \u03c6 \u2032 = \u03c6 + \u03c4L\u03c4\u0304k2R + \u03c4\u0304 k1 L \u03c4R + \u03c4\u0304 k1 L \u03c4\u0304 k2 R , with k1 \u2192 k1 +m1, k2 \u2192 k2 +m2. Thus, subsequent calls to REFINE will always result in \u03c6 having the same form by induction. From the definition of the truncation function, \u03c6 k \u03c6 k\u2032 for k \u2265 k\u2032, from which (S1) follows as well, by preservation of partial order under combination and composition. To show (S2) we note that for finite valuations, there exists k, such that \u03c6 k = \u03c6 . As the exponent is monotonically increasing with subsequent calls to REFINE, we shall eventually get \u03c6[t0,t1,...,t j ] = \u03c4L\u03c4R + \u03c4L\u03c4\u0304R + \u03c4\u0304L\u03c4R + \u03c4\u0304L\u03c4\u0304R = (\u03c4L + \u03c4\u0304L)(\u03c4R + \u03c4\u0304R), the\nexact valuation at node n. Thus, we shall eventually get the exact valuation at the root after finite invocations of REFINE.\nTheorem 2 (Completeness of anytime inference). If \u03c6[t0,t] is the valuation returned after the following invocations: [INWARD(N, t0 > 0), REFINE(N\u2032, t)], where N\u2032 is the modified BJT with the cached valuations after the call to INWARD(N, t0), then there exists a T such that for all t \u2265 T \u03c6[t0,t] = \u03c6 = ( \u2297 \u03c8\u2208\u03a6 \u03c8)\u2193X , the exact solution to the inference problem.\nProof. We consider two cases:\nCase 1: INWARD(N, t0) has performed exact inference.\nWe shall show that REFINE(N, t) is a null operation which does not change \u03c6 ,\u03c4, \u03c4\u0304; then the statement of the theorem follows if we set T = t0.\n\u03c6 \u2032 = \u03c6 \u2295\u03bd (line 13), so if we show \u03bd =\u2205, we are done.\n\u03bd = REFINE\u2032t/s(\u03c4L, \u03c4\u0304L,\u03c4R, \u03c4\u0304R), but \u03c4\u0304L = \u03c4\u0304R =\u2205 as \u03c4\u0304 represents the partial valuation that has not been combined, which is null for the exact inference case. Thus \u03bd =\u2205.\nCase 2: INWARD(N, t0) gives a partial result.\nIn general, \u03bd is also a partial valuation due to the time restriction. Since we are operating on finite datasets, the combination operation at a particular node in REFINE\u2032 takes a finite amount of time, say tn. Thus REFINE\u2032tn at a node n is the exact refinement, making \u03c6(n) exact after line 13, and thus m(root(N)) is exact after completion of the propagation. So we set T = \u2211n\u2208V tn to get the time bound, such that for all t \u2265 T we get the exact result."}, {"heading": "4 Instances of anytime ordered valuation algebras", "text": "In the following sections, we describe instances of anytime ordered valuation algebras. Specifically we show that the important class of semiring induced valuation algebras, [9], can be considered as anytime ordered valuation algebras. We also remark on the application of our framework to belief potentials."}, {"heading": "4.1 Semiring induced valuation algebras", "text": "Semiring induced valuation algebras are a subclass of valuation algebras with several useful instances like probability potentials and disjunctive normal forms. We use the definition of semiring induced valuation algebras from [9] and review the following standard notation. The semiring is denoted by A = \u3008A,+,\u00d7\u3009 with the semiring operations +,\u00d7 on a set A, where +,\u00d7 are assumed to be commutative and associative, with \u00d7 distributing over +. Lowercase letters like x are variables, with a corresponding finite set of values for x, called the frame of x and denoted by \u2126x. Each \u2126x also has an associated total order on its elements. If the frame has two elements, then it is the frame of a binary variable. If the binary elements represent true and false, then we call the variable propositional. For a domain D\u2286V where V is the set of all variables in the system, the corresponding set of possible values becomes the Cartesian product \u2126D = \u220f{\u2126x : x \u2208 D}, whose elements x \u2208\u2126D are called D-configurations or D-tuples. For a subset D\u2032 \u2286 D, x\u2193D\u2032 \u2208 \u2126D\u2032 is the projection of x to D\u2032. Where D\nis empty, we use the convention that the frame is a singleton set: \u2126\u03c6 = { }. Any set of D-configurations can be ordered using a lexicographical order.\nDefinition 8. An A -valuation \u03c6 with domain D associates a value in A with each configuration x \u2208\u2126D, i.e. \u03c6 is a function \u03c6 : \u2126D\u2192 A.\nThe set of all such A -valuations with a domain D is denoted by \u03a6D, and the union of all such sets with D \u2286 V is the set of all A -valuations \u03a6. The operations +,\u00d7 on A then induce a valuation algebra structure on \u3008\u03a6,P f (V )\u3009 where P f (V ) is the finite powerset of the set of variables V [9, Theorem 2], using the following definitions of combination and projection:\n1. Combination: \u2297 : \u03a6\u00d7\u03a6\u2192\u03a6 defined for x \u2208\u2126d(\u03c6)\u222ad(\u03c8) by\n\u03c6 \u2297\u03c8(x) = \u03c6(x\u2193d(\u03c6))\u00d7\u03c8(x\u2193d(\u03c8)) (8)\n2. Projection: \u2193: \u03a6\u00d7D\u2192\u03a6 defined for all \u03c6 \u2208\u03a6 and T \u2286 d(\u03c6) for x \u2208\u2126T by\n\u03c6\u2193T (x) = \u2211 z\u2208\u2126d(\u03c6): z\u2193T=x \u03c6(z) (9)\nTheorem 3. Semiring induced valuation algebras, provided the underlying semiring has a zero element, form an ordered valuation algebra.\nProof. To show semiring induced valuation algebras are an ordered valuation algebra, we have to show (A7-A10):\n(A7) The preorder is defined by \u03c6 \u03c6 \u2032 iff \u03c6(x) A \u03c6 \u2032(x) for all x \u2208\u2126d(\u03c6), where A is the preorder on the semiring [9, Prop. 1, p1362] defined as b A a iff a = b or there exists c such that a+c = b, with d(\u03c6) = d(\u03c6 \u2032) as it only makes sense to compare valuations on the same domain. However we need a partial order for this axiom, which is possible if the additive monoid is positive, has a zero element and is cancellative:\nLemma 4. The preorder defined on a positive, cancellative, commutative monoid, \u3008A,+\u3009 with a zero element, is a partial order.\nProof. A preorder implies a b iff a+ c = b. For a partial order, we need asymmetry: if a b and b a, then a = b.\na b implies there exists c such that a+ c = b; similarly there exists d such that b+d = a; substituting gives us b+d + c = b+0, the cancellative property implies d+ c = 0 and the positivity property implies c = d = 0, implying a = b, and we have a partial order.\n(A8) Zero element: Most common instances of semiring induced valuation algebras have a zero element. Specifically semirings with zero elements induce valuation algebras with the zero element nD such that nD(x) = 0 for all x \u2208\u2126D.\n(A9, A10) Combination and marginalisation preserve partial order. This follows from the fact that \u00d7 and + preserve partial order in the underlying semiring structure.\nHaving shown that semiring induced valuation algebras satisfy the ordered valuation algebra axioms (A7\u2013A10) provided the underlying semiring has a zero element and the additive commutative monoid is\ncancellative and positive, we proceed to define the composition and truncation functions for semiring induced valuation algebras.\n1. We denote the composition operator on semiring induced valuation algebras as (\u03c6 \u2295\u03c6 \u2032)(x) = \u03c6(x)+\u03c6 \u2032(x), d(\u03c6) = d(\u03c6 \u2032) 2. The function \u03c1 is defined on the semiring induced valuation algebra as \u03c1(\u03c6 ,k) = the first k (lexicographically ordered on x) elements of graph(\u03c6); where graph(\u03c6) = {(x,\u03c6(x)) | x \u2208\u2126d(\u03c6)}. For efficient implementation, we only store (x,\u03c6(x)) where \u03c6(x) 6= 0. In case the semiring has a total order (as in the case of probability potentials), we order the configurations in decreasing weight order: [(xi,\u03c6(xi)), . . .] where \u03c6(xi)\u2265 \u03c6(x j) for i\u2264 j.\nWe also define the time-bounded combination operation \u03c61 \u2297t \u03c62, where L\u03c61 = [(x1,\u03c61(x1)), . . .], and L\u03c62 = [(y1,\u03c62(y1)), . . .]. xy denotes the configuration in \u2126d(\u03c61)\u222ad(\u03c62) such that (xy)\n\u2193d(\u03c61) = x and (xy)\u2193d(\u03c62) = y.\nWe define helper functions INSERT, which inserts a combination into the configuration space provided there is a common support and COMBINE-EXTEND which incrementally adds combinations into the configuration and updates the state, going from the state \u03c1(\u03c61, i)\u2297 \u03c1(\u03c62, j) to \u03c1(\u03c61, i+ i\u2032)\u2297\u03c1(\u03c62, j+ j\u2032). Finally we define COMBINE which performs the combination operation within the allocated time constraint.\n1: function INSERT(\u03c61,\u03c62, i, j,L) 2: x = L\u03c61 ;y = L\u03c62 3: if x\u2193D1\u2229D2i = y \u2193D1\u2229D2 r then 4: insert [xiy j,\u03c61(xi)\u00d7\u03c62(y j)] into L. 5: end if 6: end function\n1: function COMBINE-EXTEND(\u03c61,\u03c62,\u3008i, j,L\u3009, i\u2032, j\u2032) 2: for k\u2190 1 to i+ i\u2032 do 3: for m\u2190 j to j+ j\u2032 do 4: INSERT(\u03c61,\u03c62,k,m,L) 5: end for 6: end for 7: for k\u2190 i to i+ i\u2032 do 8: for m\u2190 1 to j+ j\u2032 do 9: INSERT(\u03c61,\u03c62,k,m,L)\n10: end for 11: end for 12: return \u3008i, j,L\u3009 13: end function\n1: function COMBINE(\u03c61,\u03c62, t) 2: L\u2190 \u3008\u3009; i\u2190 1; j\u2190 1;n1\u2190 |L\u03c61 |;n2\u2190 |L\u03c62 | 3: initialise timer to t units 4: while timer()> 0 and i\u2264 n1 and j \u2264 n2 do 5: \u3008i, j,L\u3009 \u2190 COMBINE-EXTEND(\u03c61,\u03c62,\u3008i, j,L\u3009,0,1) 6: if not timer()> 0 then 7: break 8: end if 9: \u3008i, j,L\u3009 \u2190 COMBINE-EXTEND(\u03c61,\u03c62,\u3008i, j,L\u3009,1,0)\n10: end while 11: if i > n1 then\n12: m\u2190 j+1 13: while timer()> 0 and m\u2264 n2 do 14: \u3008i, j,L\u3009 \u2190 COMBINE-EXTEND(\u03c61,\u03c62,\u3008i, j,L\u3009,0,1) 15: m\u2190 m+1 16: end while 17: else 18: m\u2190 i+1 19: while timer()> 0 and m\u2264 n1 do 20: \u3008i, j,L\u3009 \u2190 COMBINE-EXTEND(\u03c61,\u03c62,\u3008i, j,L\u3009,1,0) 21: m\u2190 m+1 22: end while 23: end if 24: return valuation corresponding to L 25: end function\nTheorem 5. Semiring induced valuation algebras, provided the underlying semiring has a zero element, along with the composition operator and the truncation function defined above form an anytime ordered valuation algebra.\nProof. Semiring induced valuation algebras form an ordered valuation algebra as shown in Theorem 3. To show that they also constitute an anytime ordered valuation algebra, we have to show properties (P1, P2), i.e. combination and projection distribute over \u2295:\n(P1) If p1 = p\u20321\u2295 p\u2032\u20321 and p2 = p\u20322\u2295 p\u2032\u20322 then we have to show that: p1\u2297 p2 = (p\u20321\u2297 p\u20322)\u2295 (p\u20321\u2297 p\u2032\u20322)\u2295 (p\u2032\u20321\u2297 p\u20322)\u2295 (p\u2032\u20321\u2297 p\u2032\u20322).\nLHS applied to x is p1(x\u2193S)\u00d7 p2(x\u2193T ), where d(p1) = S and d(p2) = T .\nRHS is (p\u20321(x \u2193S)\u00d7 p\u20322(x\u2193T ))+(p\u20321(x\u2193S)\u00d7 p\u2032\u20322(x\u2193T ))+\n(p\u2032\u20321(x \u2193S)\u00d7 p\u20322(x\u2193T ))+(p\u2032\u20321(x\u2193S)\u00d7 p\u2032\u20322(x\u2193T ))\n= (p\u20321(x \u2193S)+ p\u2032\u20321(x \u2193S))\u00d7 (p\u20322(x\u2193S)+ p\u2032\u20322(x\u2193T ) = LHS using distributivity of\u00d7over + .\n(P2) We have to show that if p = p\u2032\u2295 p\u2032\u2032 that p\u2193D = p\u2032\u2193D\u2295 p\u2032\u2032\u2193D, where D \u2286 d(p). The LHS applied to x is p\u2193D(x) = \u2211z\u2193D=x p(z) = \u2211z\u2193D=x(p\u2032\u2295 p\u2032\u2032)(z), and the RHS is\n(p\u2032\u2193D\u2295 p\u2032\u2032\u2193D)(x) = p\u2032\u2193D(x)+ p\u2032\u2032\u2193D(x)) = \u2211\nz\u2193D=x p\u2032(z)+ \u2211 z\u2193D=x p\u2032\u2032(z) = \u2211 z\u2193D=x (p\u2032\u2295 p\u2032\u2032)(z)\nwhere we use the associativity and commutativity of +.\nAs stated earlier, several common instances of valuation algebra can be considered as semiring induced. We present a couple of important examples below:\nExample 1. Probability potentials are semiring induced valuation algebras on R+ with the semiring operations being the arithmetic addition and multiplication. Also known as arithmetic potentials, these describe (unnormalised) probability distributions, and thus inference in probabilistic graphical models.\nExample 2. Disjunctive normal forms (abbreviated as DNF) are of the form \u03b11\u2228\u03b12 \u00b7 \u00b7 \u00b7\u2228\u03b1n where \u03b1i is of the form x1\u2227x2\u2227\u00b7\u00b7 \u00b7\u2227xk and x j is a literal; either a logical variable or its negation. All frames are binary reflecting true and false values respectively. DNF potentials\nare induced by the semiring with + and \u00d7 being defined as a+b = max(a,b) and a\u00d7b=min(a,b); which are equivalent to the definition of logical-or and logical-and.\nThere are many other examples of semiring induced valuation algebras, a detailed introduction to which can be found in [9]. In certain cases, the valuation algebra induced by the semiring has the idempotent property, i.e. \u03c6 \u2297\u03c6 = \u03c6 ; then we may use more efficient architectures for local computation such as the Lauritzen-Spiegelhalter architecture [10].\nIt is also pertinent to mention that for DNF potentials, one can alternately consider the valuation algebra over the formulae itself instead of the models [11], which simplifies computation extensively. This alternative representation is also an anytime ordered valuation algebra, but we have omitted the proof for the purposes of brevity."}, {"heading": "4.2 Belief functions", "text": "Belief potentials are a generalisation of probability potentials to subsets of the configuration space in Dempster-Shafer\u2019s theory of evidence [21]. The advantage of belief potentials over standard probability theory is in their ability to express partially available information in a manner not possible in probability theory. This is the reason for the usage of belief functions in sensor network literature, which involves fusion of information from various sources [14, 4, 20, 27].\nFor the instance of belief functions, with the composition operator defined as [\u03c6 \u2295\u03c6 \u2032]m(A) = [\u03c6 ]m(A)+ [\u03c6 \u2032]m(A), where [\u03c6 ]m is the mass function associated with the belief function \u03c6 , our framework specialises to anytime inference in belief potentials as described in [6].\nTheorem 6. Belief functions, along with the composition operator defined above, and the truncation operation \u03c1(\u03c6 ,k) as the potential that contains the k focal sets of \u03c6 with the highest masses, form an anytime ordered valuation algebra.\nProof. Belief functions already form an ordered valuation algebra [5], as well as permit anytime inference [6]. The anytime inference algorithm in [6] turns out to be a specific case of the generic anytime inference framework presented in this article. In particular if we denote\u2295 :=+ in their notation, and the truncation function \u03c1(\u03c6 ,k) := \u03c1k(\u03c6) then [6, Theorem 9,10] shows that belief functions also form an anytime ordered valuation algebra according to the axioms in Section 3."}, {"heading": "5 Complexity Analysis", "text": "The anytime inference algorithm presented in Section 3 hides the time complexity of approximate inference by restricting the accuracy of the valuations. While we don\u2019t have an explicit control over the accuracy, we can improve it by allocating more time to the refinement algorithm. In this section, we take an alternative approach of focussing on accuracy and estimating the time complexity, which also allows us to use a tuning parameter which scales from zero accuracy (null valuations) to the valuation obtained after exact inference.\nSince complexity of exact (and approximate) inference depends upon the complexity of the combination operation (usually the more\ntime-consuming operation among combination and focussing), we consider the specific instance of semiring-induced valuation algebras. As there are n valuations, \u03c61, . . . ,\u03c6n, the resulting BJT N will have 2n\u22121 nodes, n of which are the valuations themselves at the leaves of the tree. We denote the maximum frame size of a variable in the semiring induced valuation algebra as m := max{|\u2126x|,x \u2208V}. As we are representing semiring induced valuations in memory in terms of a tuple of the configuration and its associated value, the number of words required to represent the configuration is a key component in the time and communication complexity. The upper bound on the size of the configuration space for a valuation is thus m|d(\u03c6)|.\nDefinition 9. The approximation parameter k is a tunable parameter that goes from 0 to m\u03c9 , where \u03c9 is the treewidth of the binary join tree N.\nm\u03c9 is the maximum size of the configuration space that we have to process during the inward or outward propagation phase of the Shenoy-Shafer algorithm. Now we can define the following.\nDefinition 10. The approximate combination operation\u2297k : \u03a6\u00d7\u03a6\u2192 \u03a6 is defined as combining the elements of the configuration space of the valuations in a semiring-induced valuation algebra, until we get k resultant elements.\nLemma 7. The complexity of the approximate combination operator \u2297k is O(k).\nProof. The worst-case scenario is when the configuration spaces are independent (no variables in common). Then there is no requirement for common support and we can take the pairwise multiplication of the elements of the configuration space, till we get k elements, giving us O(k) complexity.\nThe INWARD-APPROX(N,k) algorithm is defined similarly to the INWARD algorithm, with the instances of the time-bound combination operator \u2297t replaced by the approximate combination operator \u2297k. In the following, K(\u03c6 ,\u03c8,k) returns (k1,k2) such that \u03c1(\u03c6 ,k1)\u2297\u03c1(\u03c8,k2) has at most k elements.\nfunction INWARD-APPROX(N,k) for all n \u2208 leaves(N) do \u03c6s(n)\u2190 \u03c6(n)\u2212\u2206(n) while next(N) 6= /0 do\nselect n from next(N) (k1,k2)\u2190 K(\u03c6s(L(n)),\u03c6s(R(n)),k) \u03c6(n)\u2190 \u03c6s(L(n))\u2297k \u03c6s(R(n)); \u03c6s(n)\u2190 \u03c6(n)\u2212\u2206(n) \u03c4(L(n))\u2190 \u03c1(\u03c6s(L(n)),k1) \u03c4(R(n))\u2190 \u03c1(\u03c6s(R(n)),k2) \u03c4\u0304(L(n))\u2190 \u03c1\u0304(\u03c6s(L(n)),k1) \u03c4\u0304(R(n))\u2190 \u03c1\u0304(\u03c6s(R(n)),k2) \u03c6s(n)\u2190 \u03c6(n)\u2212\u2206(n) s\u2190 s\u22121\nend while end function\nTheorem 8. The time complexity of INWARD-APPROX(N,k) in the Shenoy-Shafer architecture, with the approximation parameter of k, given that there are n valuations in the knowledgebase is O((n\u22121)k).\nProof. There are n\u22121 combinations as the number of combinations in the binary join tree is the same as the number of non-leaf nodes. As each combination has a complexity of O(k), we get a complexity of O((n\u2212 1)k). Projection has a complexity of O(k) as there are k elements in the configuration space, so at most k\u2212 1 summations, which is the case when we are marginalising to the null set (equivalent to eliminating all the variables), thus it does not change the asymptotic complexity.\nWe get the same time complexity for an analogous REFINE-APPROX algorithm, with a modification to lines 6\u20137 of REFINE to combine at most k elements.\nMatching in the exact inference case. In the exact inference case, the complexity is known to be in the class #P-hard. In the discussion on complexity [17], Kohlas and Pouly derive the estimate O(|V |. f (\u03c9)) where \u03c9 is the treewidth, with f (x) = mx for the case of semiring induced valuation algebras with variables having a upper bound frame size of m. |V | is the number of vertices in the join tree. Substituting |V | = n,k = m\u03c9 in the time complexity O(n\u2212 1)k and taking k = m\u03c9 , we get the same time complexity as the exact inference case; thus the approximate time complexity obtained in terms of the approximation parameter k gives us a transition from k = 0 (null valuations, obtained when we set the t = 0 in INWARD(N, t)) to k = m\u03c9 , the exact inference case.\nEstimation of accuracy from elapsed time. It can be useful to derive an estimate of the accuracy of a valuation given the elapsed time of the algorithm in specific cases. Here, we shall consider the example of probability potentials. The time-bound combination operator combines the configurations with the largest weight first so that we get diminishing returns; the accuracy also depends on the sparsity of the probability potential. For simplicity we consider uniform distributions, where the weights are uniformly distributed in the configuration space. Then we can state the following:\nLemma 9. The fractional error estimate compared to the exact probability potential is\n\u03b5(t) = 1\u2212max ( 1, t\nm\u03c9 c(n\u22121)\n) (10)\nwhere \u03c9 is the treewidth, c is the constant time required to combine two elements in the configuration space, and n is the number of valuations in the knowledgebase.\nProof. As each configuration has an uniform weight, the accuracy of combination at the root node (which is the solution to the inference problem obtained from the inward propagation algorithm) is directly proportional to the allocated time which is on average t/(n\u2212 1) as there are n\u2212 1 combinations. Considering that each combination takes c units, and in the worst-case each configuration has weight 1/m\u03c9 (for a normalised potential; for unnormalised, this introduces a constant factor which is cancelled out by considering a fractional error estimate), we get the fractional error estimate as above.\nAs can be easily seen, \u03b5(0) = 1, and \u03b5(O((n\u22121).m\u03c9 )) = 0 where O((n\u22121).m\u03c9 ) is the exact inference time complexity."}, {"heading": "6 Implementation", "text": "We implemented the anytime inference algorithm using the Python programming language, on a Core i5 CPU with 4GB RAM. While we have shown anytime inference in a Bayesian network here, the framework, being generic, can be applied to other valuation algebras which satisfy the necessary axioms.\nThe figure shows progress of anytime inference on the CHILD dataset, which was used as a case study for exact inference in [1]. The progress is shown as a function of the fractional error estimate with time units (the actual total time for the series of successive refinements, up to the exact valuation is < 10s):\n\u03b5(t) = 1\u2212 \u2211 L\u03c6t\n\u2211L\u03c6 (11)\nHere the sum is over the weights of the configurations L\u03c6 of a valuation \u03c6 ; \u03c6t is the valuation obtained at the root after time t, and \u03c6 is the exact valuation. As expected, the fractional error estimate converges to zero as we obtain the exact valuation."}, {"heading": "7 Conclusion", "text": "In this work, we have shown that we can construct anytime algorithms for generic classes of valuation algebras, provided certain conditions are satisfied. We have also shown that the important subclass of semiring induced valuation algebras admit an anytime inference algorithm as they meet the aforementioned conditions. This is useful as semiring induced valuation algebras include important valuation algebra instances like probability potentials, DNF potentials and relational algebras, among others.\nFrom a broader perspective, the advantage of operating in the generic framework of valuation algebras has been addressed before [17]; we can target a large class of problems using a unified framework; the inference or projection problem can be found in various forms: Fourier transforms, linear programming and constraint satisfaction problems. Enriching the valuation algebra structure through extensions is thus useful. Anytime inference in particular has a wide spectrum of applications. We also plan to study the applicability of our framework across these various domains in future work.\nWe are currently working on implementation of other instances of anytime ordered valuation algebras, as well as conducting a complexity analysis of the algorithm in a distributed setting using the Bulk Synchronous Parallel [26] model."}], "references": [{"title": "Probabilistic networks and expert systems, exact computational methods for Bayesian networks", "author": ["Robert G Cowell", "A Philip Dawid", "Steffen L Lauritzen", "David J Spiegelhalter"], "venue": "series: information science and statistics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Bucket elimination: A unifying framework for probabilistic inference\u2019, in Learning in graphical models, 75\u2013104", "author": ["Rina Dechter"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}, {"title": "A generalization of Bayesian inference", "author": ["Arthur P Dempster"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1968}, {"title": "A neural network classifier based on Dempster-Shafer theory\u2019, Systems, Man and Cybernetics, Part A: Systems and Humans", "author": ["Thierry Denoeux"], "venue": "IEEE Transactions on,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "Ordered valuation algebras: a generic framework for approximating inference", "author": ["Rolf Haenni"], "venue": "International Journal of Approximate Reasoning,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Resource bounded and anytime approximation of belief function computations", "author": ["Rolf Haenni", "Norbert Lehmann"], "venue": "International Journal of Approximate Reasoning,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "An anytime algorithm for decision making under uncertainty", "author": ["Michael C Horsch", "David Poole"], "venue": "Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1998}, {"title": "Dempster\u2019s rule as seen by little colored balls", "author": ["Audun J\u00f8sang", "Simon Pope"], "venue": "Computational Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Semiring induced valuation algebras: Exact and approximate local computation algorithms", "author": ["Juerg Kohlas", "Nic Wilson"], "venue": "Artificial Intelligence,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Information algebras: Generic structures for inference", "author": ["J\u00fcrg Kohlas"], "venue": "Springer Science & Business Media,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Propositional information systems", "author": ["J\u00fcrg Kohlas", "Rolf Haenni", "Seraf\u0131\u0301n Moral"], "venue": "Journal of Logic and Computation,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1999}, {"title": "Probabilistic Graphical Models: Principles and Techniques, Adaptive Computation and Machine Learning", "author": ["Daphne Koller", "Nir Friedman"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Readings in uncertain reasoning\u2019, chapter Local Computations with Probabilities on Graphical Structures and Their Application to Expert Systems, 415\u2013448", "author": ["S.L. Lauritzen", "D.J. Spiegelhalter"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1990}, {"title": "Dempster-Shafer theory for sensor fusion in autonomous mobile robots", "author": ["Robin R Murphy"], "venue": "Robotics and Automation, IEEE Transactions on,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1998}, {"title": "Reverend Bayes on inference engines: a distributed hierarchical approach, Cognitive Systems Laboratory, School of Engineering and Applied Science, University of California", "author": ["J. Pearl"], "venue": "Los Angeles,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1982}, {"title": "NENOK \u2013 A software architecture for generic inference", "author": ["Marc Pouly"], "venue": "International Journal on Artificial Intelligence Tools,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Generic Inference: A Unifying Theory for Automated Reasoning, Wiley-Blackwell", "author": ["Marc Pouly", "Juerg Kohlas"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Minimizing communication costs of distributed local computation", "author": ["Marc Pouly", "J\u00fcrg Kohlas"], "venue": "Technical report,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}, {"title": "Anytime anyspace probabilistic inference", "author": ["Fabio Tozeto Ramos", "Fabio Gagliardi Cozman"], "venue": "International Journal of Approximate Reasoning,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "Combination of evidence in Dempster- Shafer theory, volume 4015", "author": ["Kari Sentz", "Scott Ferson"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2002}, {"title": "Binary join trees for computing marginals in the Shenoy-Shafer architecture", "author": ["Prakash P Shenoy"], "venue": "International Journal of approximate reasoning,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1997}, {"title": "Axioms for probability and belieffunction propagation", "author": ["Prakash P Shenoy", "Glenn Shafer"], "venue": "Classic Works of the Dempster-Shafer Theory of Belief Functions,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "Anytime classification using the nearest neighbor algorithm with applications to stream mining\u2019, in Data Mining, 2006. ICDM\u201906", "author": ["Ken Ueno", "Xiaopeng Xi", "Eamonn Keogh", "Dah-Jye Lee"], "venue": "Sixth International Conference on,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}, {"title": "The complexity of enumeration and reliability problems", "author": ["Leslie G Valiant"], "venue": "SIAM Journal on Computing,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1979}, {"title": "A bridging model for parallel computation", "author": ["Leslie G. Valiant"], "venue": "Commun.  ACM,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1990}, {"title": "Alert confidence fusion in intrusion detection systems with extended Dempster-Shafer theory", "author": ["Dong Yu", "Deborah Frincke"], "venue": "Proceedings of the 43rd annual Southeast regional conference-Volume", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2005}, {"title": "Using anytime algorithms in intelligent systems", "author": ["Shlomo Zilberstein"], "venue": "AI magazine,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1996}], "referenceMentions": [{"referenceID": 4, "context": "In this article we construct an anytime inference algorithm based on principles introduced in the theory of generic inference; and in particular, extending the work done on ordered valuation algebras [5].", "startOffset": 200, "endOffset": 203}, {"referenceID": 11, "context": "Inference can be considered as the (1) combination of information from various sources, which could be in the form of probability distributions from a probabilistic graphical model [12], belief functions in DempsterShafer theory [3, 8] or tables in a relational database; and (2) subsequent focusing or projection to variables of interest, which corresponds to projection for variables in probabilistic graphical models, or a query in the relational database.", "startOffset": 181, "endOffset": 185}, {"referenceID": 2, "context": "Inference can be considered as the (1) combination of information from various sources, which could be in the form of probability distributions from a probabilistic graphical model [12], belief functions in DempsterShafer theory [3, 8] or tables in a relational database; and (2) subsequent focusing or projection to variables of interest, which corresponds to projection for variables in probabilistic graphical models, or a query in the relational database.", "startOffset": 229, "endOffset": 235}, {"referenceID": 7, "context": "Inference can be considered as the (1) combination of information from various sources, which could be in the form of probability distributions from a probabilistic graphical model [12], belief functions in DempsterShafer theory [3, 8] or tables in a relational database; and (2) subsequent focusing or projection to variables of interest, which corresponds to projection for variables in probabilistic graphical models, or a query in the relational database.", "startOffset": 229, "endOffset": 235}, {"referenceID": 16, "context": "Our work is based on the theory of generic inference [17] which abstracts and generalises the inference problem across these different areas.", "startOffset": 53, "endOffset": 57}, {"referenceID": 12, "context": "In [13], an algorithm was defined which solved the inference problem on Bayesian networks, using a technique called local computation.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "It was noted in [23] that the same algorithm could be used to solve the inference problem on belief functions, and a sufficient set of axioms were proposed for an algebraic framework that is necessary for the generic inference algorithm.", "startOffset": 16, "endOffset": 20}, {"referenceID": 15, "context": "This was extended by Kohlas into a theory of valuation algebras, and a computer implementation of inference over valuation algebras along with concrete instantiations was developed in [16].", "startOffset": 184, "endOffset": 188}, {"referenceID": 16, "context": "uk Generic inference as formulated in [17] solves the inference problem in the exact case.", "startOffset": 38, "endOffset": 42}, {"referenceID": 23, "context": "As exact inference is an #P-hard problem [25], in practice, we need frameworks for approximate inference.", "startOffset": 41, "endOffset": 45}, {"referenceID": 1, "context": "Approximation schemes exist for specific instances of valuation algebras (probability potentials [2], belief potentials [6]); as well as for the generic case [5], but there is no such generic framework for anytime inference.", "startOffset": 97, "endOffset": 100}, {"referenceID": 5, "context": "Approximation schemes exist for specific instances of valuation algebras (probability potentials [2], belief potentials [6]); as well as for the generic case [5], but there is no such generic framework for anytime inference.", "startOffset": 120, "endOffset": 123}, {"referenceID": 4, "context": "Approximation schemes exist for specific instances of valuation algebras (probability potentials [2], belief potentials [6]); as well as for the generic case [5], but there is no such generic framework for anytime inference.", "startOffset": 158, "endOffset": 161}, {"referenceID": 4, "context": "In this paper, we extend the approximate inference framework in [5] to support anytime inference.", "startOffset": 64, "endOffset": 67}, {"referenceID": 22, "context": "Such algorithms are important in online learning where new data is being streamed in [24], in intelligent systems, decision making under uncertainty [7] and robotics [28] where due to the limitation of interacting in real-time there may not be sufficient time to compute an exact solution.", "startOffset": 85, "endOffset": 89}, {"referenceID": 6, "context": "Such algorithms are important in online learning where new data is being streamed in [24], in intelligent systems, decision making under uncertainty [7] and robotics [28] where due to the limitation of interacting in real-time there may not be sufficient time to compute an exact solution.", "startOffset": 149, "endOffset": 152}, {"referenceID": 26, "context": "Such algorithms are important in online learning where new data is being streamed in [24], in intelligent systems, decision making under uncertainty [7] and robotics [28] where due to the limitation of interacting in real-time there may not be sufficient time to compute an exact solution.", "startOffset": 166, "endOffset": 170}, {"referenceID": 16, "context": "inference generic probability potentials exact [17] [15] approximate [5] loopy belief propagation, [2] anytime [our work] [19]", "startOffset": 47, "endOffset": 51}, {"referenceID": 14, "context": "inference generic probability potentials exact [17] [15] approximate [5] loopy belief propagation, [2] anytime [our work] [19]", "startOffset": 52, "endOffset": 56}, {"referenceID": 4, "context": "inference generic probability potentials exact [17] [15] approximate [5] loopy belief propagation, [2] anytime [our work] [19]", "startOffset": 69, "endOffset": 72}, {"referenceID": 1, "context": "inference generic probability potentials exact [17] [15] approximate [5] loopy belief propagation, [2] anytime [our work] [19]", "startOffset": 99, "endOffset": 102}, {"referenceID": 18, "context": "inference generic probability potentials exact [17] [15] approximate [5] loopy belief propagation, [2] anytime [our work] [19]", "startOffset": 122, "endOffset": 126}, {"referenceID": 16, "context": "We review the axioms of valuation algebra [17] below, preceded by some remarks on notation.", "startOffset": 42, "endOffset": 46}, {"referenceID": 16, "context": "For the intuitive reading of these axioms, we refer the reader to [17, 23].", "startOffset": 66, "endOffset": 74}, {"referenceID": 21, "context": "For the intuitive reading of these axioms, we refer the reader to [17, 23].", "startOffset": 66, "endOffset": 74}, {"referenceID": 1, "context": "Existing approximation schemes, like the mini-bucket scheme [2] are either not general enough or do not provide a reliable measure of the approximation and how to improve the approximation in an anytime algorithm.", "startOffset": 60, "endOffset": 63}, {"referenceID": 4, "context": "In this article, we have used the ordered valuation algebra framework defined in [5] as a basis for constructing an anytime algorithm.", "startOffset": 81, "endOffset": 84}, {"referenceID": 4, "context": "The time-bounded combination operator [5] \u2297t : \u03a6\u00d7\u03a6\u2192 \u03a6 is used to approximate the exact computation during the propagation phase.", "startOffset": 38, "endOffset": 41}, {"referenceID": 20, "context": "Inference takes place by message passing in the BJT (for details of the algorithm, see [22, 5]).", "startOffset": 87, "endOffset": 94}, {"referenceID": 4, "context": "Inference takes place by message passing in the BJT (for details of the algorithm, see [22, 5]).", "startOffset": 87, "endOffset": 94}, {"referenceID": 17, "context": "Such extensions preserve the generic structure of valuation algebras, but add restrictions to simplify or add features to the inference algorithm; in another instance, valuation algebras were extended to weighted valuation algebras to study communication complexity [18].", "startOffset": 266, "endOffset": 270}, {"referenceID": 20, "context": "We use a modified version of the propagation algorithm [22, 5], where \u03c4 and \u03c4\u0304 store the partial and complementary partial valuations respectively for a particular BJT node, where the complementary partial valuation \u03c1\u0304(\u03c6 ,k) is such that \u03c1\u0304(\u03c6 ,k)\u2295\u03c1(\u03c6 ,k)= \u03c6 .", "startOffset": 55, "endOffset": 62}, {"referenceID": 4, "context": "We use a modified version of the propagation algorithm [22, 5], where \u03c4 and \u03c4\u0304 store the partial and complementary partial valuations respectively for a particular BJT node, where the complementary partial valuation \u03c1\u0304(\u03c6 ,k) is such that \u03c1\u0304(\u03c6 ,k)\u2295\u03c1(\u03c6 ,k)= \u03c6 .", "startOffset": 55, "endOffset": 62}, {"referenceID": 5, "context": "We can use the cached partial valuations in \u03c4 and \u03c4\u0304 to define the refinement algorithm that follows in a similar manner to the algorithm in [6].", "startOffset": 141, "endOffset": 144}, {"referenceID": 8, "context": "Specifically we show that the important class of semiring induced valuation algebras, [9], can be considered as anytime ordered valuation algebras.", "startOffset": 86, "endOffset": 89}, {"referenceID": 8, "context": "We use the definition of semiring induced valuation algebras from [9] and review the following standard notation.", "startOffset": 66, "endOffset": 69}, {"referenceID": 8, "context": "There are many other examples of semiring induced valuation algebras, a detailed introduction to which can be found in [9].", "startOffset": 119, "endOffset": 122}, {"referenceID": 9, "context": "\u03c6 \u2297\u03c6 = \u03c6 ; then we may use more efficient architectures for local computation such as the Lauritzen-Spiegelhalter architecture [10].", "startOffset": 127, "endOffset": 131}, {"referenceID": 10, "context": "It is also pertinent to mention that for DNF potentials, one can alternately consider the valuation algebra over the formulae itself instead of the models [11], which simplifies computation extensively.", "startOffset": 155, "endOffset": 159}, {"referenceID": 13, "context": "This is the reason for the usage of belief functions in sensor network literature, which involves fusion of information from various sources [14, 4, 20, 27].", "startOffset": 141, "endOffset": 156}, {"referenceID": 3, "context": "This is the reason for the usage of belief functions in sensor network literature, which involves fusion of information from various sources [14, 4, 20, 27].", "startOffset": 141, "endOffset": 156}, {"referenceID": 19, "context": "This is the reason for the usage of belief functions in sensor network literature, which involves fusion of information from various sources [14, 4, 20, 27].", "startOffset": 141, "endOffset": 156}, {"referenceID": 25, "context": "This is the reason for the usage of belief functions in sensor network literature, which involves fusion of information from various sources [14, 4, 20, 27].", "startOffset": 141, "endOffset": 156}, {"referenceID": 5, "context": "For the instance of belief functions, with the composition operator defined as [\u03c6 \u2295\u03c6 \u2032]m(A) = [\u03c6 ]m(A)+ [\u03c6 \u2032]m(A), where [\u03c6 ]m is the mass function associated with the belief function \u03c6 , our framework specialises to anytime inference in belief potentials as described in [6].", "startOffset": 272, "endOffset": 275}, {"referenceID": 4, "context": "Belief functions already form an ordered valuation algebra [5], as well as permit anytime inference [6].", "startOffset": 59, "endOffset": 62}, {"referenceID": 5, "context": "Belief functions already form an ordered valuation algebra [5], as well as permit anytime inference [6].", "startOffset": 100, "endOffset": 103}, {"referenceID": 5, "context": "The anytime inference algorithm in [6] turns out to be a specific case of the generic anytime inference framework presented in this article.", "startOffset": 35, "endOffset": 38}, {"referenceID": 16, "context": "In the discussion on complexity [17], Kohlas and Pouly derive the estimate O(|V |.", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "The figure shows progress of anytime inference on the CHILD dataset, which was used as a case study for exact inference in [1].", "startOffset": 123, "endOffset": 126}, {"referenceID": 16, "context": "From a broader perspective, the advantage of operating in the generic framework of valuation algebras has been addressed before [17]; we can target a large class of problems using a unified framework; the inference or projection problem can be found in various forms: Fourier transforms, linear programming and constraint satisfaction problems.", "startOffset": 128, "endOffset": 132}, {"referenceID": 24, "context": "We are currently working on implementation of other instances of anytime ordered valuation algebras, as well as conducting a complexity analysis of the algorithm in a distributed setting using the Bulk Synchronous Parallel [26] model.", "startOffset": 223, "endOffset": 227}], "year": 2016, "abstractText": "The novel contribution of this work is the construction of anytime algorithms in a generic framework, which automatically gives us instantiations in many useful domains. We also show that semiring induced valuation algebras, an important subclass of valuation algebras are amenable to anytime inference. Anytime inference, and inference algorithms in general have been a well-researched area in the last few decades. Inference is an important component in most pattern recognition and machine learning algorithms; it also shares theoretical connections with other branches of computer science like theorem-proving. Anytime inference is important in applications with limited space, for efficiency reasons, such as in continuous learning and robotics. In this article we construct an anytime inference algorithm based on principles introduced in the theory of generic inference; and in particular, extending the work done on ordered valuation algebras [5].", "creator": "LaTeX with hyperref package"}}}