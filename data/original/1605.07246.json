{"id": "1605.07246", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2016", "title": "Adaptive ADMM with Spectral Penalty Parameter Selection", "abstract": "The alternating direction method of multipliers (ADMM) is a versatile tool for solving a wide range of constrained optimization problems, with differentiable or non-differentiable objective functions. Unfortunately, its performance is highly sensitive to a penalty parameter, which makes ADMM often unreliable and hard to automate for a non-expert user. We tackle this weakness of ADMM by proposing a method to adaptively tune the penalty parameters to achieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm, inspired by the successful Barzilai-Borwein spectral method for gradient descent, yields fast convergence and relative insensitivity to the initial stepsize and problem scaling.", "histories": [["v1", "Tue, 24 May 2016 00:48:28 GMT  (48kb,D)", "http://arxiv.org/abs/1605.07246v1", null], ["v2", "Fri, 10 Jun 2016 19:21:26 GMT  (168kb,D)", "http://arxiv.org/abs/1605.07246v2", null], ["v3", "Fri, 9 Sep 2016 19:51:17 GMT  (48kb,D)", "http://arxiv.org/abs/1605.07246v3", null], ["v4", "Wed, 25 Jan 2017 18:49:04 GMT  (403kb,D)", "http://arxiv.org/abs/1605.07246v4", "AISTATS 2017"], ["v5", "Wed, 19 Jul 2017 16:23:11 GMT  (240kb,D)", "http://arxiv.org/abs/1605.07246v5", "AISTATS 2017"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.NA", "authors": ["zheng xu", "mario a t figueiredo", "tom goldstein"], "accepted": false, "id": "1605.07246"}, "pdf": {"name": "1605.07246.pdf", "metadata": {"source": "CRF", "title": "Adaptive ADMM with Spectral Penalty Parameter Selection", "authors": ["Zheng Xu", "M\u00e1rio A. T. Figueiredo", "Thomas Goldstein"], "emails": ["1xuzh@cs.umd.edu,", "tomg@cs.umd.edu,", "2mario.figueiredo@tecnico.ulisboa.pt"], "sections": [{"heading": "1 Introduction", "text": "The alternating direction method of multipliers (ADMM) is an invaluable element of the modern optimization toolbox. ADMM decomposes complex optimization problems into sequences of simpler subproblems, often solvable in closed form; its simplicity, flexibility, and broad applicability, made ADMM a state-of-the-art solver in machine learning, signal processing, and many other areas [2].\nIt is well known that the efficiency of ADMM hinges on the careful selection of a penalty parameter, which is often manually tuned by users for their particular problem instances. For gradient descent and proximal-gradient methods, adaptive (i.e. automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].\nIn this paper, we propose to automate and speed up ADMM by using stepsize selection rules imported from the gradient descent literature, namely the Barzilai-Borwein \u201cspectral\u201d method for smooth unconstrained problems [1, 7]. Since ADMM handles multi-term objectives and linear constraints, it is not immediately obvious how to adopt such rules. The key to our approach is to analyze the dual of the ADMM problem, which can be written without constraints. To ensure reliability of the method, we develop a correlation criterion that safeguards it against inaccurate stepsize choices. The resulting adaptive ADMM (AADMM) is fully automated and fairly insensitive to the initial stepsize."}, {"heading": "2 Background and Related Work", "text": ""}, {"heading": "2.1 Alternating Direction Method of Multipliers", "text": "ADMM dates back to the 1970s [8, 10]. Its convergence was shown in the 1990s [4], and convergence rates have been the topic of much recent work (see [11, 14, 18] and references therein). In the last decade, ADMM became one of the tools of choice to handle a wide variety of optimization problems in machine learning, signal processing, and many other areas (for a comprehensive review, see [2]).\nADMM tackles problems in the form\nmin u\u2208Rn,v\u2208Rm H(u) +G(v), subject to Au+Bv = b, (1)\nar X\niv :1\n60 5.\n07 24\n6v 1\n[ cs\n.L G\n] 2\n4 M\nay 2\nwhere H : Rn \u2192 R\u0304 and G : Rm \u2192 R\u0304 are closed, proper, convex functions, A \u2208 Rp\u00d7n, B \u2208 Rp\u00d7m, and b \u2208 Rp. With \u03bb\u2208Rp denoting the dual variables (Lagrange multipliers), ADMM has the form\nuk+1 = arg min u H(u) + \u3008\u03bbk,\u2212Au\u3009+ \u03c4k 2 \u2016b\u2212Au\u2212Bvk\u201622 (2)\nvk+1 = arg min v G(v) + \u3008\u03bbk,\u2212Bv\u3009+ \u03c4k 2 \u2016b\u2212Auk+1 \u2212Bv\u201622 (3)\n\u03bbk+1 =\u03bbk + \u03c4k(b\u2212Auk+1 \u2212Bvk+1), (4) where the sequence of penalties \u03c4k is the only free choice, and has a high impact on the algorithm\u2019s performance. Our goal is to automate this choice, by adaptively tuning \u03c4k for optimal performance.\nThe convergence of the algorithm can be monitored using primal and dual \u201cresiduals,\u201d both of which approach zero as the iterates become more accurate, and which are defined as\nrk = b\u2212Auk \u2212Bvk, and dk = \u03c4kATB(vk \u2212 vk\u22121), (5) respectively [2]. The iteration is generally stopped when \u2016rk\u20162 \u2264 tol max{\u2016Auk\u20162, \u2016Bvk\u20162, \u2016b\u20162} and \u2016dk\u20162 \u2264 tol\u2016AT\u03bbk\u20162, where tol > 0 is the stopping tolerance (e.g., tol \u2248 10\u22123 )."}, {"heading": "2.2 Parameter tuning and adaptation", "text": "Relatively little work has been done on automating ADMM, i.e., on adaptively choosing \u03c4k. In the specific case where the objective is a strictly convex quadratic function, criteria for choosing an optimal constant penalty have been recently proposed [9, 19].\nResidual balancing (RB [2, 15]) is the only available adaptive method for general form problems (1). RB is based on the following observation: increasing \u03c4k strengthens the penalty term, resulting in smaller primal residuals but larger dual ones; conversely, decreasing \u03c4k leads to larger primal and smaller dual residuals. Since both residuals must be small at convergence, it makes sense to \u201cbalance\u201d them, i.e., to tune \u03c4k to keep both residuals of similar magnitude. A simple scheme for this goal is\n\u03c4k+1 =  \u03b7\u03c4k if \u2016dk\u20162 > \u00b5\u2016rk\u20162 \u03c4k/\u03b7 if \u2016rk\u20162 > \u00b5\u2016dk\u20162 \u03c4k otherwise,\n(6)\nfor parameters \u00b5 > 1 and \u03b7 > 1 [2]. RB has recently been adapted to distributed optimization [22] and other primal-dual splitting methods [13]. ADMM with adaptive penalty is not guaranteed to converge, although convergence can be enforced by fixing \u03c4k = \u03c4 after a finite number of iterations [15].\nThe RB idea suffers from a fundamental flaw. The relative size of the residuals depends on the (arbitrary) scaling of the problem; for example, with the change of variable u \u2190 10u, problem (1) can be re-scaled so that ADMM produces an equivalent sequence of iterates with residuals of very different magnitudes. Consequently, RB criteria are arbitrary for some problems, and their performance varies wildly with different problem scalings (see Section 4.4). Furthermore, the penalty parameter may adapt slowly if the initial value is far from optimal. Finally, without a careful choice of \u03b7 and \u00b5, the penalty parameters may oscillate and the algorithm fails to converge before \u03c4k is fixed."}, {"heading": "2.3 Dual interpretation of ADMM", "text": "We now explain the close relationship between ADMM and Douglas-Rachdord Splitting (DRS) [4, 6, 11], which plays a central role in the proposed approach. The starting observation is that the dual of problem (1) has the form\nmin \u03b6\u2208Rp H\u2217(AT \u03b6)\u2212 \u3008\u03b6, b\u3009\ufe38 \ufe37\ufe37 \ufe38 H\u0302(\u03b6) +G\u2217(BT \u03b6)\ufe38 \ufe37\ufe37 \ufe38 G\u0302(\u03b6) ; (7)\nwith F \u2217 denoting the Fenchel conjugate of F , defined as F \u2217(y) = supx\u3008x, y\u3009 \u2212 F (x) [20].\nThe DRS algorithm solves (7) by generating two sequences (\u03b6k)k\u2208N and (\u03b6\u0302k)k\u2208N according to\n0 \u2208 \u03b6\u0302k+1 \u2212 \u03b6k \u03c4k + \u2202H\u0302(\u03b6\u0302k+1) + \u2202G\u0302(\u03b6k) (8) 0 \u2208 \u03b6k+1 \u2212 \u03b6k \u03c4k + \u2202H\u0302(\u03b6\u0302k+1) + \u2202G\u0302(\u03b6k+1), (9)\nwhere we use the standard notation \u2202F (x) for the subdifferential of F evaluated at x [20].\nReferring back to ADMM in (2)\u2013(4), and defining \u03bb\u0302k+1 = \u03bbk+\u03c4k(b\u2212Auk+1\u2212Bvk), the optimality condition for the minimization of (2) is\n0 \u2208 \u2202H(uk+1)\u2212AT\u03bbk \u2212 \u03c4kAT (b\u2212Auk+1 \u2212Bvk) = \u2202H(uk+1)\u2212AT \u03bb\u0302k+1, (10)\nwhich is equivalent to AT \u03bb\u0302k+1 \u2208 \u2202H(uk+1), thus1 uk+1 \u2208 \u2202H\u2217(AT \u03bb\u0302k+1). A similar argument using the optimality condition for (3) leads to vk+1 \u2208 \u2202G\u2217(BT\u03bbk+1). Recalling (7), we arrive at\nAuk+1 \u2212 b \u2208 \u2202H\u0302(\u03bb\u0302k+1) and Bvk+1 \u2208 \u2202G\u0302(\u03bbk+1). (11) Using these identities, we finally have\n\u03bb\u0302k+1 = \u03bbk + \u03c4k(b\u2212Auk+1 \u2212Bvk) \u2208 \u03bbk \u2212 \u03c4k ( \u2202H\u0302(\u03bb\u0302k+1) + \u2202G\u0302(\u03bbk) ) (12)\n\u03bbk+1 = \u03bbk + \u03c4k(b\u2212Auk+1 \u2212Bvk+1) \u2208 \u03bbk \u2212 \u03c4k ( \u2202H\u0302(\u03bb\u0302k+1) + \u2202G\u0302(\u03bbk+1) ) , (13)\nshowing that the sequences (\u03bbk)k\u2208N and (\u03bb\u0302k)k\u2208N satisfy the same conditions (8) and (9) as (\u03b6k)k\u2208N and (\u03b6\u0302k)k\u2208N, thus proving that ADMM for problem (1) is equivalent to DRS for its dual (7)."}, {"heading": "2.4 Spectral (Barzilai-Borwein) stepsize selection", "text": "The classical gradient descent step for unconstrained minimization of a smooth function F: Rn\u2192 R has the form xk+1 = xk\u2212\u03c4k\u2207F (xk). Spectral gradient methods, pioneered by Barzilai and Borwein (BB) [1], adaptively choose the stepsize \u03c4k to achieve fast convergence. In a nutshell, the standard (there are variants) BB method sets \u03c4k = 1/\u03b1k, with \u03b1k chosen such that \u03b1kI mimics the Hessian of F over the last step, seeking a quasi-Newton step. Using a least squares criterion yields\n\u03b1k = argmin \u03b1\u2208R \u2016\u2207F (xk)\u2212\u2207F (xk\u22121)\u2212 \u03b1(xk \u2212 xk\u22121)\u201622, (14)\nwhich is an estimate of the curvature of F across the previous step of the algorithm. Spectral gradient methods dramatically outperform schemas with constant stepsize in many applications [7, 24] and have been generalized to handle non-differentiable problems via proximal gradient methods [23, 12]. Finally, notice that (14) is equivalent to modeling the gradient\u2207F (xk) as a linear function of xk,\n\u2207F (xk) \u2248 \u2207F (xk\u22121) + \u03b1k(xk \u2212 xk\u22121) = \u03b1k xk + ak, (15) where ak = \u2207F (xk\u22121)\u2212 \u03b1k xk\u22121\u2208 Rn. The observation that a local linear approximation of the gradient has an optimal parameter equal to the inverse of the BB stepsize will play an important role below."}, {"heading": "3 Spectral penalty parameters", "text": "Inspired by the BB method [1], we propose a spectral penalty parameter selection method for ADMM. We first derive a spectral stepsize rule for DRS, and then adapt this rule to ADMM. Finally, we discuss safeguarding methods to prevent unexpected behavior when curvature estimates are inaccurate."}, {"heading": "3.1 Spectral stepsize for Douglas-Rachford splitting", "text": "Considering the dual problem (7), and following the observation in (15) about the BB method, we model/approximate \u2202H\u0302(\u03b6\u0302) and \u2202G\u0302(\u03b6) at iteration k as linear functions of their arguments,\n\u2202H\u0302(\u03b6\u0302) = \u03b1k \u03b6\u0302 + \u03a8k and \u2202G\u0302(\u03b6) = \u03b2k \u03b6 + \u03a6k, (16)\nwhere \u03b1k > 0, \u03b2k > 0 are local curvature estimates of H\u0302 and G\u0302, respectively, and \u03a8k,\u03a6k \u2282 Rp. Once we obtain these curvature estimates, we will be able to exploit the following proposition. Proposition 1 (Spectral DRS). Suppose the DRS steps (8)\u2013(9) are applied to problem (7), where (omitting the subscript k from \u03b1k, \u03b2k,\u03a8k,\u03a6k to lighten the notation in what follows)\n\u2202H\u0302(\u03b6\u0302) = \u03b1 \u03b6\u0302 + \u03a8 and \u2202G\u0302(\u03b6) = \u03b2 \u03b6 + \u03a6.\nThen, the minimal residual of H\u0302(\u03b6k+1) + G\u0302(\u03b6k+1) is obtained by setting \u03c4k = 1/ \u221a \u03b1\u03b2.\n1An important property relating F and F \u2217 is that y \u2208 \u2202H(x) if and only if x \u2208 \u2202H\u2217(y) [20].\nProof. Inserting (16) into the DRS step (8)\u2013(9), we have\n0 \u2208 \u03b6\u0302k+1 \u2212 \u03b6k \u03c4 + (\u03b1 \u03b6\u0302k+1 + \u03a8) + (\u03b2 \u03b6k + \u03a6) (17) 0 \u2208 \u03b6k+1 \u2212 \u03b6k \u03c4 + (\u03b1 \u03b6\u0302k+1 + \u03a8) + (\u03b2 \u03b6k+1 + \u03a6). (18)\nFrom (17)\u2013(18), we can explicitly get the update for \u03b6\u0302k+1 as\n\u03b6\u0302k+1 = 1\u2212 \u03b2 \u03c4 1 + \u03b1 \u03c4 \u03b6k \u2212 a\u03c4 + b\u03c4 1 + \u03b1 \u03c4 , (19)\nwhere a \u2208 \u03a8 and b \u2208 \u03a6, and for \u03b6k+1 as\n\u03b6k+1 = 1\n1 + \u03b2 \u03c4 \u03b6k \u2212\n\u03b1 \u03c4\n1 + \u03b2 \u03c4 \u03b6\u0302k+1 \u2212\na \u03c4 + b\u03c4 1 + \u03b2 \u03c4 = (1 + \u03b1\u03b2 \u03c42)\u03b6k \u2212 (a+ b)\u03c4 (1 + \u03b1 \u03c4)(1 + \u03b2 \u03c4) , (20)\nwhere the second equality results from using the expression for \u03b6\u0302k+1 from (19).\nThe residual rDR at \u03b6k+1 is simply the magnitude of the subgradient (corresponding to elements a \u2208 \u03a8 and b \u2208 \u03a6) of the objective that is given by\nrDR = \u2016(\u03b1+ \u03b2)\u03b6k+1 + (a+ b)\u2016 = 1 + \u03b1\u03b2 \u03c42\n(1 + \u03b1 \u03c4)(1 + \u03b2 \u03c4) \u2016(\u03b1+ \u03b2)\u03b6k + (a+ b)\u2016, (21)\nwhere \u03b6k+1 in (21) was substituted with (20). The optimal stepsize \u03c4k minimizes the residual\n\u03c4k = arg min \u03c4 rDR = arg max \u03c4\n(1 + \u03b1 \u03c4)(1 + \u03b2 \u03c4)\n1 + \u03b1\u03b2 \u03c42 = arg max \u03c4\n(\u03b1+ \u03b2)\u03c4 1 + \u03b1\u03b2\u03c42 = 1/\n\u221a \u03b1\u03b2.\nFinally (recovering the iteration subscript k), notice that \u03c4k = (\u03b1\u0302k \u03b2\u0302k)1/2, where \u03b1\u0302k = 1/\u03b1k and \u03b2\u0302k = 1/\u03b2k are the spectral gradient descent stepsizes for H\u0302 and G\u0302, at \u03b6\u0302k and \u03b6k, respectively."}, {"heading": "3.2 Spectral stepsize estimation", "text": "Proposition 1 shows how to adaptively choose the penalty parameters. We can begin by obtaining linear estimates of the subgradients of the terms in the dual objective (7). The geometric mean of the optimal gradient descent stepsizes for those two terms is then the optimal DRS stepsize, and also the optimal penalty parameter for ADMM, thanks to the equivalence presented in Subsection 2.3.\nWe now address the question of how to estimate \u03b1\u0302k = \u03b1\u22121k and \u03b2\u0302k = \u03b2 \u22121 k for the components G\u0302(\u03bb\u0302k) and H\u0302(\u03bbk) at the k-th iteration. The curvature parameters are estimated based on the results from iteration k and an older iteration k0 < k . Noting the identities (11), we define\n\u2206\u03bb\u0302k := \u03bb\u0302k \u2212 \u03bb\u0302k0 and \u2206H\u0302k := \u2202H\u0302(\u03bb\u0302k)\u2212 \u2202H\u0302(\u03bb\u0302k0) = A(uk \u2212 uk0). (22)\nAssuming, as above, a linear model for \u2202H\u0302 , we expect \u2206H\u0302k \u2248 \u03b1\u2206\u03bb\u0302k + a. As is typical in the spectral stepsize literature [24], the curvature of H\u0302(\u03bb) is estimated via one of the two least squares problems\nmin \u03b1 \u2016\u2206H\u0302k \u2212 \u03b1\u2206\u03bb\u0302k\u201622 or min \u03b1 \u2016\u03b1\u22121\u2206H\u0302k \u2212\u2206\u03bb\u0302k\u201622. (23)\nThe closed form solutions for the corresponding spectral stepsizes \u03b1\u0302k = 1/\u03b1k are, respectively,\n\u03b1\u0302SDk = \u3008\u2206\u03bb\u0302k,\u2206\u03bb\u0302k\u3009 \u3008\u2206H\u0302k,\u2206\u03bb\u0302k\u3009\nand \u03b1\u0302MGk = \u3008\u2206H\u0302k,\u2206\u03bb\u0302k\u3009 \u3008\u2206H\u0302k,\u2206H\u0302k\u3009 , (24)\nwhere (following [24]) SD stands for steepest descent stepsize, and MG for minimum gradient stepsize. The Cauchy-Schwarz inequality can be used to show that \u03b1\u0302SDk \u2265 \u03b1\u0302MGk . Rather than choosing one or the other, we suggest the hybrid stepsize rule proposed in [12, 24], defined as\n\u03b1\u0302k =\n{ \u03b1\u0302MGk if 2 \u03b1\u0302 MG k > \u03b1\u0302 SD k\n\u03b1\u0302SDk \u2212 \u03b1\u0302MGk /2 otherwise. (25)\nThe spectral stepsize \u03b2\u0302k = 1/\u03b2k of G\u0302(\u03bbk) is similarly estimated as,\n\u03b2\u0302k =\n{ \u03b2\u0302MGk if 2 \u03b2\u0302 MG k > \u03b2\u0302 SD k\n\u03b2\u0302SDk \u2212 \u03b2\u0302MGk /2 otherwise, (26)\nwhere \u03b2\u0302SDk = \u3008\u2206\u03bbk,\u2206\u03bbk\u3009/\u3008\u2206G\u0302k,\u2206\u03bbk\u3009, \u03b2\u0302MGk = \u3008\u2206G\u0302k,\u2206\u03bbk\u3009/\u3008\u2206G\u0302k,\u2206G\u0302k\u3009, \u2206G\u0302k = B(vk\u2212vk0), and \u2206\u03bbk = \u03bbk \u2212 \u03bbk0 . It is important to note that \u03b1\u0302k and \u03b2\u0302k are obtained from the iterates of ADMM alone, i.e., our scheme does not require the user to supply the dual problem."}, {"heading": "3.3 Safeguarding: testing the quality of stepsize estimates", "text": "On some iterations, the linear models for one or both subgradients that underly the spectral stepsize choice may be very inaccurate. When this occurs, the least squares procedure may produce ineffective stepsize values. The classical BB method for unconstrained problems uses a line search to safeguard against unstable stepsizes when curvature estimates are unreliable. For ADMM, however, there is no notion of \u201cstable\u201d stepsize (any constant stepsizes is stable), thus line search methods are not applicable. Rather, we propose to safeguard the method by assessing the quality of the curvature estimates, and only updating the stepsize if the curvature estimates satisfy a reliability criterion.\nThe linear model (16) assumes the change in dual gradient is linearly proportional to the change in the dual variables. To test the validity of this assumption, we measure the correlation between these quantities (equivalently, the cosine of their angle):\n\u03b1corrk = \u3008\u2206H\u0302k,\u2206\u03bb\u0302k\u3009 \u2016\u2206H\u0302k\u2016\u2016\u2206\u03bb\u0302k\u2016\nand \u03b2corrk = \u3008\u2206G\u0302k,\u2206\u03bbk\u3009 \u2016\u2206G\u0302k\u2016\u2016\u2206\u03bbk\u2016 . (27)\nThe correlations indicate whether the linear assumptions (16) are suitable to estimate the gradients, thus the spectral stepsizes \u03b1\u0302k and \u03b2\u0302k are utilized only if the correlations indicate the estimation is credible enough. Finally, the safeguarded spectral adaptive penalty parameter rule is\n\u03c4k+1 =  \u221a \u03b1\u0302k\u03b2\u0302k if \u03b1corrk > corr and \u03b2corrk > corr \u03b1\u0302k if \u03b1corrk > corr and \u03b2corrk \u2264 corr\n\u03b2\u0302k if \u03b1corrk \u2264 corr and \u03b2corrk > corr \u03c4k otherwise,\n(28)\nwhere corr is a quality threshold for the curvature estimates, while \u03b1\u0302k and \u03b2\u0302k are the spectral stepsizes given by (25) and (26). The proposed method falls back to constant penalty parameter when both curvature estimates are deemed inaccurate."}, {"heading": "3.4 Adaptive ADMM with spectral penalty parameter", "text": "The complete adaptive ADMM (AADMM) is shown in Algorithm 1. We suggest only updating the stepsize every Tf iterations. The overhead of the proposed adaptivity scheme is modest, requiring only a few inner products, plus the storage needed to hold one previous iterate. As noted in [15], convergence is guaranteed if the adaptivity is turned off after a finite number of iterations; however, we have found this to be unnecessary in practice."}, {"heading": "4 Experiments", "text": ""}, {"heading": "4.1 Experimental setting", "text": "We consider several applications to demonstrate the effectiveness of the proposed AADMM. We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2]. We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].\nFor comparison, we implemented vanilla ADMM, fast ADMM with a restart strategy [11], and ADMM with residual balancing [2, 15], using \u00b5 = 10 and \u03b7 = 2 in (6), and turned off after 1000\nAlgorithm 1 Adaptive ADMM (AADMM) with spectral penalty parameter selection Input: initialize v0, \u03bb0, \u03c40, k0 = 0, corr = 0.2, update frequency Tf = 2\n1: for k = 0, 1, 2, . . . ,maxiter do 2: uk+1 \u2190 arg minuH(u) + \u3008\u03bbk,\u2212Au\u3009+ \u03c4k2 \u2016b\u2212Au\u2212Bvk\u2016 2 3: vk+1 \u2190 arg minv G(v) + \u3008\u03bbk,\u2212Bv\u3009+ \u03c4k2 \u2016b\u2212Auk+1 \u2212Bv\u2016 2 4: \u03bbk+1 \u2190 \u03bbk + \u03c4k(b\u2212Auk+1 \u2212Bvk+1) 5: if mod(k, Tf ) = 1 then 6: \u03bb\u0302k+1 = \u03bbk + \u03c4k(b\u2212Auk+1 \u2212Bvk) 7: Compute spectral stepsizes \u03b1\u0302k, \u03b2\u0302k using (25) and (26) 8: Estimate correlations \u03b1corrk , \u03b2 corr k , as given in (27)\n9: Update \u03c4k+1 using (28) 10: k0 \u2190 k 11: else 12: \u03c4k+1 \u2190 \u03c4k 13: end if 14: end for\niterations to guarantee convergence. The proposed AADMM is implemented as shown in Algorithm 1, with fixed parameters corr = 0.2 and Tf = 2.\nWe set the stopping tolerance to tol = 10\u22125, 10\u22123, and 0.05 for small, medium, and large scale problems, respectively. The initial penalty \u03c40 = 1/10 is used for all problems except the general QP problem, where \u03c40 is set to the value proposed for quadratic problems in [19]."}, {"heading": "4.2 Applications", "text": "Linear regression with elastic net (EN) regularization. EN is a modification of the `1 (or LASSO) regularizer that helps preserving groups of highly correlated variables [11, 25], and requires solving\nmin x\n1 2 \u2016Dx\u2212 c\u201622 + \u03c11\u2016x\u20161 + \u03c12 2 \u2016x\u201622, (29)\nwhere \u2016 \u00b7 \u20161 denotes the `1 norm, D is a data matrix, c contains measurements, and x is the regression coefficients. One way to apply ADMM to this problem is to rewrite it as\nmin u,v\n1 2 \u2016Du\u2212 c\u201622 + \u03c11\u2016v\u20161 + \u03c12 2 \u2016v\u201622 subject to u\u2212 v = 0. (30)\nThe synthetic dataset introduced in [11, 25] and realistic dataset introduced in [5, 25] are investigated. Typical parameters \u03c11 = \u03c12 = 1 are used in all experiments.\nSupport vector machine (SVM) and QP. The dual of the SVM learning problem is a QP\nmin z\n1 2 zTQz \u2212 eT z subject to cT z = 0 and 0 \u2264 z \u2264 C, (31)\nwhere z is the SVM dual variable, Q is the kernel matrix, c is a vector of labels, e is a vector of ones, and C > 0 [3]. We also consider the canonical QP\nmin x\n1 2 xTQx+ qTx subject to Dx \u2264 c, (32)\nwhich could be solved by applying ADMM to\nmin u,v\n1 2 uTQu+ qTu+ \u03b9{z: zi\u2264c}(v) subject to Du\u2212 v = 0; (33)\nhere, \u03b9S is the characteristic function of set S: \u03b9S(v) = 0, if v \u2208 S, and \u03b9S(v) =\u221e, otherwise. We study classification problems from [16, 21] with C = 1 and a random synthetic QP from [11], where Q \u2208 R500\u00d7500 with condition number approximately 4.5\u00d7 105. Basis pursuit (BP) and sparse representation. BP solves the constrained minimization problem\nmin x \u2016x\u20161 subject to Dx = c, (34)\nwhere D \u2208 Rm\u00d7n, c \u2208 Rm,m < n. An extended form with D\u0302 = [D, I] \u2208 Rm\u00d7(n+m) has been used to reconstruct occluded and corrupted faces [23]. To apply ADMM, problem (34) is rewritten as\nmin u,v\n\u03b9{z:Dz=c}(u) + \u2016v\u20161 subject to u\u2212 v = 0. (35)\nWe experiment with synthetic random D \u2208 R10\u00d730. We also use a data matrix for face reconstruction from the Extended Yale B Face dataset [23], where each frontal face image is scaled to 32\u00d7 32. For each human subject, an image is selected and corrupted with 5% noisy pixels, and the remaining images from the same subject are used to reconstruct the corrupted image.\nConsensus `1-regularized logistic regression. ADMM has become an important tool for solving distributed problems [2]. Here, we consider the consensus `1-regularized logistic regression\nmin xi,z N\u2211 i=1 ni\u2211 j=1 log(1 + exp(\u2212cjDjxi)) + \u03c1\u2016z\u20161 subject to xi \u2212 z = 0, i = 1, . . . , N, (36)\nwhere xi \u2208 Rm represents the local variable on the ith distributed node, z is the global variable, ni is the number of samples in the ith block, Dj \u2208 Rm is the jth sample, and cj \u2208 {\u22121, 1} is the corresponding label. The synthetic problem is constructed with Gaussian random data and sparse ground truth solutions. Binary classification problems from [16, 17, 21] are also used to test the effectiveness of the proposed method. We use \u03c1 = 1, for small and medium datasets, and \u03c1 = 5 for the large datasets to encourage sparsity. We split the data equally into two blocks and use a loop to simulate the distributed computing of consensus subproblems."}, {"heading": "4.3 Convergence results", "text": "Table 1 reports the convergence speed of ADMM and its variants for the applications described in Subsection 4.2. Vanilla ADMM with fixed stepsize does poorly in practice: in 9 out of 17 realistic datasets, it fails to converge in the maximum number of iterations 2. Fast ADMM [11] often outperforms vanilla ADMM, but does not compete with the proposed AADMM, which also outperforms residual balancing in all test cases except in the Rcv1 problem for consensus logistic regression."}, {"heading": "4.4 Sensitivity to initial stepsize and problem scaling", "text": "Finally, we study the sensitivity of the different ADMM variants to the initial penalty parameter (\u03c40) choice and problem scaling. Fig. 1 presents iteration counts for a wide range of values of \u03c40, for elastic net regression (left) and general QP (right) with synthetic datasets. Scaling sensitivity experiments were done by multiplying the measurement vector c in elastic net and QP by a scalar s . Fast ADMM and vanilla ADMM use the fixed initial penalty parameter \u03c40, and are highly sensitivity to this choice, as shown in Fig. 1; in contrast, AADMM is stable with respect to the initial \u03c40 and the problem scale s."}, {"heading": "5 Conclusion", "text": "We have proposed adaptive ADMM (AADMM), a new variant of the very popular ADMM algorithm that tackles one of its fundamental drawbacks: critical dependence on a penalty parameter that needs careful tuning. This drawback has made ADMM difficult to use by non-experts, thus AADMM has the potential to contribute to wider and easier applicability of this highly flexible and efficient optimization tool. Our approach imports and adapts the Barzilai-Borwein \u201cspectral\u201d stepsize method from the smooth optimization literature, tailoring it to the more general class of problems handled by ADMM. The cornerstone of our approach is the fact that ADMM is equivalent to Douglas-Rachford splitting (DRS) applied to the dual problem, for which we develop a spectral stepsize selection rule; this rule is then translated into a criterion to select the penalty parameter of ADMM. A safeguarding function that avoids unreliable stepsize choices finally yields AADMM. Experiments on a wide range of problems and datasets have shown that AADMM outperforms other variants of ADMM. AADMM was also shown to be robust with respect to initial parameter choice and problem scaling."}], "references": [{"title": "Two-point step size gradient methods", "author": ["J. Barzilai", "J. Borwein"], "venue": "IMA J. Num. Analysis,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1988}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": "Found. and Trends in Mach. Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "LIBSVM: a library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "On the Douglas-Rachford splitting method and the proximal point algorithm for maximal monotone operators", "author": ["J. Eckstein", "D. Bertsekas"], "venue": "Mathematical Programming,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1992}, {"title": "Least angle regression", "author": ["B. Efron", "T. Hastie", "I. Johnstone", "R. Tibshirani"], "venue": "The Annals of statistics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Applications of Lagrangian-based alternating direction methods and connections to split Bregman", "author": ["E. Esser"], "venue": "CAM report,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "On the Barzilai-Borwein method. In Optimization and control with applications, pages 235\u2013256", "author": ["R. Fletcher"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "A dual algorithm for the solution of nonlinear variational problems via finite element approximation", "author": ["D. Gabay", "B. Mercier"], "venue": "Computers & Mathematics with Applications,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1976}, {"title": "Optimal parameter selection for the alternating direction method of multipliers: quadratic problems", "author": ["E. Ghadimi", "A. Teixeira", "I. Shames", "M. Johansson"], "venue": "IEEE Trans. Autom. Control,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Sur l\u2019approximation, par \u00e9l\u00e9ments finis d\u2019ordre un, et la r\u00e9solution, par p\u00e9nalisation-dualit\u00e9 d\u2019une classe de probl\u00e9mes de Dirichlet non lin\u00e9aires", "author": ["R. Glowinski", "A. Marroco"], "venue": "ESAIM: Mode\u0301lisation Mathe\u0301matique et Analyse Nume\u0301rique,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1975}, {"title": "Fast alternating direction optimization methods", "author": ["T. Goldstein", "B. O\u2019Donoghue", "S. Setzer", "R. Baraniuk"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "A field guide to forward-backward splitting with a FASTA implementation", "author": ["T. Goldstein", "C. Studer", "R. Baraniuk"], "venue": "arXiv preprint arXiv:1411.3406,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Adaptive primal-dual splitting methods for statistical learning and image processing", "author": ["T. Goldstein", "M. Li", "X. Yuan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "On non-ergodic convergence rate of Douglas-Rachford alternating direction method of multipliers", "author": ["B. He", "X. Yuan"], "venue": "Numerische Mathematik,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Alternating direction method with self-adaptive penalty parameters for monotone variational inequalities", "author": ["B. He", "H. Yang", "S. Wang"], "venue": "Jour. Optim. Theory and Appl.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2000}, {"title": "Efficient L1 regularized logistic regression", "author": ["S.-I. Lee", "H. Lee", "P. Abbeel", "A. Ng"], "venue": "In AAAI,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Large-scale sparse logistic regression", "author": ["J. Liu", "J. Chen", "J. Ye"], "venue": "In ACM SIGKDD,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "A general analysis of the convergence of ADMM", "author": ["R. Nishihara", "L. Lessard", "B. Recht", "A. Packard", "M. Jordan"], "venue": "In ICML,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Alternating direction method of multipliers for strictly convex quadratic programs: Optimal parameter selection", "author": ["A. Raghunathan", "S. Di Cairano"], "venue": "In American Control Conf.,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Convex Analysis", "author": ["R. Rockafellar"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1970}, {"title": "Fast optimization methods for l1 regularization: A comparative study and two new approaches", "author": ["M. Schmidt", "G. Fung", "R. Rosales"], "venue": "In ECML,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "Fast ADMM algorithm for distributed optimization with adaptive penalty", "author": ["C. Song", "S. Yoon", "V. Pavlovic"], "venue": "arXiv preprint arXiv:1506.08928,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Sparse reconstruction by separable approximation", "author": ["S. Wright", "R. Nowak", "M. Figueiredo"], "venue": "IEEE Trans. Signal Processing,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Gradient methods with adaptive step-sizes", "author": ["B. Zhou", "L. Gao", "Y.-H. Dai"], "venue": "Computational Optimization and Applications,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}, {"title": "Regularization and variable selection via the elastic net", "author": ["H. Zou", "T. Hastie"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}], "referenceMentions": [{"referenceID": 1, "context": "ADMM decomposes complex optimization problems into sequences of simpler subproblems, often solvable in closed form; its simplicity, flexibility, and broad applicability, made ADMM a state-of-the-art solver in machine learning, signal processing, and many other areas [2].", "startOffset": 267, "endOffset": 270}, {"referenceID": 0, "context": "automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].", "startOffset": 138, "endOffset": 156}, {"referenceID": 6, "context": "automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].", "startOffset": 138, "endOffset": 156}, {"referenceID": 11, "context": "automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].", "startOffset": 138, "endOffset": 156}, {"referenceID": 22, "context": "automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].", "startOffset": 138, "endOffset": 156}, {"referenceID": 23, "context": "automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].", "startOffset": 138, "endOffset": 156}, {"referenceID": 0, "context": "In this paper, we propose to automate and speed up ADMM by using stepsize selection rules imported from the gradient descent literature, namely the Barzilai-Borwein \u201cspectral\u201d method for smooth unconstrained problems [1, 7].", "startOffset": 217, "endOffset": 223}, {"referenceID": 6, "context": "In this paper, we propose to automate and speed up ADMM by using stepsize selection rules imported from the gradient descent literature, namely the Barzilai-Borwein \u201cspectral\u201d method for smooth unconstrained problems [1, 7].", "startOffset": 217, "endOffset": 223}, {"referenceID": 7, "context": "ADMM dates back to the 1970s [8, 10].", "startOffset": 29, "endOffset": 36}, {"referenceID": 9, "context": "ADMM dates back to the 1970s [8, 10].", "startOffset": 29, "endOffset": 36}, {"referenceID": 3, "context": "Its convergence was shown in the 1990s [4], and convergence rates have been the topic of much recent work (see [11, 14, 18] and references therein).", "startOffset": 39, "endOffset": 42}, {"referenceID": 10, "context": "Its convergence was shown in the 1990s [4], and convergence rates have been the topic of much recent work (see [11, 14, 18] and references therein).", "startOffset": 111, "endOffset": 123}, {"referenceID": 13, "context": "Its convergence was shown in the 1990s [4], and convergence rates have been the topic of much recent work (see [11, 14, 18] and references therein).", "startOffset": 111, "endOffset": 123}, {"referenceID": 17, "context": "Its convergence was shown in the 1990s [4], and convergence rates have been the topic of much recent work (see [11, 14, 18] and references therein).", "startOffset": 111, "endOffset": 123}, {"referenceID": 1, "context": "In the last decade, ADMM became one of the tools of choice to handle a wide variety of optimization problems in machine learning, signal processing, and many other areas (for a comprehensive review, see [2]).", "startOffset": 203, "endOffset": 206}, {"referenceID": 1, "context": "The convergence of the algorithm can be monitored using primal and dual \u201cresiduals,\u201d both of which approach zero as the iterates become more accurate, and which are defined as rk = b\u2212Auk \u2212Bvk, and dk = \u03c4kAB(vk \u2212 vk\u22121), (5) respectively [2].", "startOffset": 236, "endOffset": 239}, {"referenceID": 8, "context": "In the specific case where the objective is a strictly convex quadratic function, criteria for choosing an optimal constant penalty have been recently proposed [9, 19].", "startOffset": 160, "endOffset": 167}, {"referenceID": 18, "context": "In the specific case where the objective is a strictly convex quadratic function, criteria for choosing an optimal constant penalty have been recently proposed [9, 19].", "startOffset": 160, "endOffset": 167}, {"referenceID": 1, "context": "Residual balancing (RB [2, 15]) is the only available adaptive method for general form problems (1).", "startOffset": 23, "endOffset": 30}, {"referenceID": 14, "context": "Residual balancing (RB [2, 15]) is the only available adaptive method for general form problems (1).", "startOffset": 23, "endOffset": 30}, {"referenceID": 1, "context": "for parameters \u03bc > 1 and \u03b7 > 1 [2].", "startOffset": 31, "endOffset": 34}, {"referenceID": 21, "context": "RB has recently been adapted to distributed optimization [22] and other primal-dual splitting methods [13].", "startOffset": 57, "endOffset": 61}, {"referenceID": 12, "context": "RB has recently been adapted to distributed optimization [22] and other primal-dual splitting methods [13].", "startOffset": 102, "endOffset": 106}, {"referenceID": 14, "context": "ADMM with adaptive penalty is not guaranteed to converge, although convergence can be enforced by fixing \u03c4k = \u03c4 after a finite number of iterations [15].", "startOffset": 148, "endOffset": 152}, {"referenceID": 3, "context": "We now explain the close relationship between ADMM and Douglas-Rachdord Splitting (DRS) [4, 6, 11], which plays a central role in the proposed approach.", "startOffset": 88, "endOffset": 98}, {"referenceID": 5, "context": "We now explain the close relationship between ADMM and Douglas-Rachdord Splitting (DRS) [4, 6, 11], which plays a central role in the proposed approach.", "startOffset": 88, "endOffset": 98}, {"referenceID": 10, "context": "We now explain the close relationship between ADMM and Douglas-Rachdord Splitting (DRS) [4, 6, 11], which plays a central role in the proposed approach.", "startOffset": 88, "endOffset": 98}, {"referenceID": 19, "context": "with F \u2217 denoting the Fenchel conjugate of F , defined as F \u2217(y) = supx\u3008x, y\u3009 \u2212 F (x) [20].", "startOffset": 86, "endOffset": 90}, {"referenceID": 19, "context": "where we use the standard notation \u2202F (x) for the subdifferential of F evaluated at x [20].", "startOffset": 86, "endOffset": 90}, {"referenceID": 0, "context": "Spectral gradient methods, pioneered by Barzilai and Borwein (BB) [1], adaptively choose the stepsize \u03c4k to achieve fast convergence.", "startOffset": 66, "endOffset": 69}, {"referenceID": 6, "context": "Spectral gradient methods dramatically outperform schemas with constant stepsize in many applications [7, 24] and have been generalized to handle non-differentiable problems via proximal gradient methods [23, 12].", "startOffset": 102, "endOffset": 109}, {"referenceID": 23, "context": "Spectral gradient methods dramatically outperform schemas with constant stepsize in many applications [7, 24] and have been generalized to handle non-differentiable problems via proximal gradient methods [23, 12].", "startOffset": 102, "endOffset": 109}, {"referenceID": 22, "context": "Spectral gradient methods dramatically outperform schemas with constant stepsize in many applications [7, 24] and have been generalized to handle non-differentiable problems via proximal gradient methods [23, 12].", "startOffset": 204, "endOffset": 212}, {"referenceID": 11, "context": "Spectral gradient methods dramatically outperform schemas with constant stepsize in many applications [7, 24] and have been generalized to handle non-differentiable problems via proximal gradient methods [23, 12].", "startOffset": 204, "endOffset": 212}, {"referenceID": 0, "context": "Inspired by the BB method [1], we propose a spectral penalty parameter selection method for ADMM.", "startOffset": 26, "endOffset": 29}, {"referenceID": 19, "context": "An important property relating F and F \u2217 is that y \u2208 \u2202H(x) if and only if x \u2208 \u2202H\u2217(y) [20].", "startOffset": 85, "endOffset": 89}, {"referenceID": 23, "context": "As is typical in the spectral stepsize literature [24], the curvature of \u0124(\u03bb) is estimated via one of the two least squares problems", "startOffset": 50, "endOffset": 54}, {"referenceID": 23, "context": "where (following [24]) SD stands for steepest descent stepsize, and MG for minimum gradient stepsize.", "startOffset": 17, "endOffset": 21}, {"referenceID": 11, "context": "Rather than choosing one or the other, we suggest the hybrid stepsize rule proposed in [12, 24], defined as", "startOffset": 87, "endOffset": 95}, {"referenceID": 23, "context": "Rather than choosing one or the other, we suggest the hybrid stepsize rule proposed in [12, 24], defined as", "startOffset": 87, "endOffset": 95}, {"referenceID": 14, "context": "As noted in [15], convergence is guaranteed if the adaptivity is turned off after a finite number of iterations; however, we have found this to be unnecessary in practice.", "startOffset": 12, "endOffset": 16}, {"referenceID": 10, "context": "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].", "startOffset": 124, "endOffset": 128}, {"referenceID": 1, "context": "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].", "startOffset": 157, "endOffset": 171}, {"referenceID": 8, "context": "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].", "startOffset": 157, "endOffset": 171}, {"referenceID": 10, "context": "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].", "startOffset": 157, "endOffset": 171}, {"referenceID": 18, "context": "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].", "startOffset": 157, "endOffset": 171}, {"referenceID": 1, "context": "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].", "startOffset": 187, "endOffset": 194}, {"referenceID": 10, "context": "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].", "startOffset": 187, "endOffset": 194}, {"referenceID": 1, "context": "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].", "startOffset": 245, "endOffset": 248}, {"referenceID": 4, "context": "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].", "startOffset": 108, "endOffset": 131}, {"referenceID": 15, "context": "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].", "startOffset": 108, "endOffset": 131}, {"referenceID": 16, "context": "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].", "startOffset": 108, "endOffset": 131}, {"referenceID": 20, "context": "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].", "startOffset": 108, "endOffset": 131}, {"referenceID": 22, "context": "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].", "startOffset": 108, "endOffset": 131}, {"referenceID": 24, "context": "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].", "startOffset": 108, "endOffset": 131}, {"referenceID": 10, "context": "For comparison, we implemented vanilla ADMM, fast ADMM with a restart strategy [11], and ADMM with residual balancing [2, 15], using \u03bc = 10 and \u03b7 = 2 in (6), and turned off after 1000", "startOffset": 79, "endOffset": 83}, {"referenceID": 1, "context": "For comparison, we implemented vanilla ADMM, fast ADMM with a restart strategy [11], and ADMM with residual balancing [2, 15], using \u03bc = 10 and \u03b7 = 2 in (6), and turned off after 1000", "startOffset": 118, "endOffset": 125}, {"referenceID": 14, "context": "For comparison, we implemented vanilla ADMM, fast ADMM with a restart strategy [11], and ADMM with residual balancing [2, 15], using \u03bc = 10 and \u03b7 = 2 in (6), and turned off after 1000", "startOffset": 118, "endOffset": 125}, {"referenceID": 18, "context": "The initial penalty \u03c40 = 1/10 is used for all problems except the general QP problem, where \u03c40 is set to the value proposed for quadratic problems in [19].", "startOffset": 150, "endOffset": 154}, {"referenceID": 10, "context": "EN is a modification of the `1 (or LASSO) regularizer that helps preserving groups of highly correlated variables [11, 25], and requires solving", "startOffset": 114, "endOffset": 122}, {"referenceID": 24, "context": "EN is a modification of the `1 (or LASSO) regularizer that helps preserving groups of highly correlated variables [11, 25], and requires solving", "startOffset": 114, "endOffset": 122}, {"referenceID": 10, "context": "The synthetic dataset introduced in [11, 25] and realistic dataset introduced in [5, 25] are investigated.", "startOffset": 36, "endOffset": 44}, {"referenceID": 24, "context": "The synthetic dataset introduced in [11, 25] and realistic dataset introduced in [5, 25] are investigated.", "startOffset": 36, "endOffset": 44}, {"referenceID": 4, "context": "The synthetic dataset introduced in [11, 25] and realistic dataset introduced in [5, 25] are investigated.", "startOffset": 81, "endOffset": 88}, {"referenceID": 24, "context": "The synthetic dataset introduced in [11, 25] and realistic dataset introduced in [5, 25] are investigated.", "startOffset": 81, "endOffset": 88}, {"referenceID": 2, "context": "where z is the SVM dual variable, Q is the kernel matrix, c is a vector of labels, e is a vector of ones, and C > 0 [3].", "startOffset": 116, "endOffset": 119}, {"referenceID": 15, "context": "We study classification problems from [16, 21] with C = 1 and a random synthetic QP from [11], where Q \u2208 R500\u00d7500 with condition number approximately 4.", "startOffset": 38, "endOffset": 46}, {"referenceID": 20, "context": "We study classification problems from [16, 21] with C = 1 and a random synthetic QP from [11], where Q \u2208 R500\u00d7500 with condition number approximately 4.", "startOffset": 38, "endOffset": 46}, {"referenceID": 10, "context": "We study classification problems from [16, 21] with C = 1 and a random synthetic QP from [11], where Q \u2208 R500\u00d7500 with condition number approximately 4.", "startOffset": 89, "endOffset": 93}, {"referenceID": 22, "context": "An extended form with D\u0302 = [D, I] \u2208 Rm\u00d7(n+m) has been used to reconstruct occluded and corrupted faces [23].", "startOffset": 103, "endOffset": 107}, {"referenceID": 22, "context": "We also use a data matrix for face reconstruction from the Extended Yale B Face dataset [23], where each frontal face image is scaled to 32\u00d7 32.", "startOffset": 88, "endOffset": 92}, {"referenceID": 1, "context": "ADMM has become an important tool for solving distributed problems [2].", "startOffset": 67, "endOffset": 70}, {"referenceID": 15, "context": "Binary classification problems from [16, 17, 21] are also used to test the effectiveness of the proposed method.", "startOffset": 36, "endOffset": 48}, {"referenceID": 16, "context": "Binary classification problems from [16, 17, 21] are also used to test the effectiveness of the proposed method.", "startOffset": 36, "endOffset": 48}, {"referenceID": 20, "context": "Binary classification problems from [16, 17, 21] are also used to test the effectiveness of the proposed method.", "startOffset": 36, "endOffset": 48}, {"referenceID": 10, "context": "Fast ADMM [11] often outperforms vanilla ADMM, but does not compete with the proposed AADMM, which also outperforms residual balancing in all test cases except in the Rcv1 problem for consensus logistic regression.", "startOffset": 10, "endOffset": 14}, {"referenceID": 10, "context": "Application Dataset #samples \u00d7 #features 3 Vanilla ADMM Fast ADMM [11] Residual balance [15] Adaptive ADMM", "startOffset": 66, "endOffset": 70}, {"referenceID": 14, "context": "Application Dataset #samples \u00d7 #features 3 Vanilla ADMM Fast ADMM [11] Residual balance [15] Adaptive ADMM", "startOffset": 88, "endOffset": 92}], "year": 2017, "abstractText": "The alternating direction method of multipliers (ADMM) is a versatile tool for solving a wide range of constrained optimization problems, with differentiable or non-differentiable objective functions. Unfortunately, its performance is highly sensitive to a penalty parameter, which makes ADMM often unreliable and hard to automate for a non-expert user. We tackle this weakness of ADMM by proposing a method to adaptively tune the penalty parameters to achieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm, inspired by the successful Barzilai-Borwein spectral method for gradient descent, yields fast convergence and relative insensitivity to the initial stepsize and problem scaling.", "creator": "LaTeX with hyperref package"}}}