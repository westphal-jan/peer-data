{"id": "1605.08527", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-May-2016", "title": "Stochastic Optimization for Large-scale Optimal Transport", "abstract": "Optimal transport (OT) defines a powerful framework to compare probability distributions in a geometrically faithful way. However, the practical impact of OT is still limited because of its computational burden. We propose a new class of stochastic optimization algorithms to cope with large-scale problems routinely encountered in machine learning applications. These methods are able to manipulate arbitrary distributions (either discrete or continuous) by simply requiring to be able to draw samples from them, which is the typical setup in high-dimensional learning problems. This alleviates the need to discretize these densities, while giving access to provably convergent methods that output the correct distance without discretization error. These algorithms rely on two main ideas: (a) the dual OT problem can be re-cast as the maximization of an expectation ; (b) entropic regularization of the primal OT problem results in a smooth dual optimization optimization which can be addressed with algorithms that have a provably faster convergence. We instantiate these ideas in three different setups: (i) when comparing a discrete distribution to another, we show that incremental stochastic optimization schemes can beat Sinkhorn's algorithm, the current state-of-the-art finite dimensional OT solver; (ii) when comparing a discrete distribution to a continuous density, a semi-discrete reformulation of the dual program is amenable to averaged stochastic gradient descent, leading to better performance than approximately solving the problem by discretization ; (iii) when dealing with two continuous densities, we propose a stochastic gradient descent over a reproducing kernel Hilbert space (RKHS). This is currently the only known method to solve this problem, apart from computing OT on finite samples. We backup these claims on a set of discrete, semi-discrete and continuous benchmark problems.", "histories": [["v1", "Fri, 27 May 2016 07:47:30 GMT  (611kb,D)", "http://arxiv.org/abs/1605.08527v1", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG math.NA", "authors": ["aude genevay", "marco cuturi", "gabriel peyr\u00e9", "francis r bach"], "accepted": true, "id": "1605.08527"}, "pdf": {"name": "1605.08527.pdf", "metadata": {"source": "CRF", "title": "Stochastic Optimization for Large-scale Optimal Transport", "authors": ["Aude Genevay"], "emails": ["genevay@ceremade.dauphine.fr", "mcuturi@i.kyoto-u.ac.jp", "gabriel.peyre@ceremade.dauphine.fr", "francis.bach@inria.fr"], "sections": [{"heading": "1 Introduction", "text": "Many problems in computational sciences require to compare probability measures or histograms. As a set of representative examples, let us quote: bag-of-visual-words comparison in computer vision [17], color and shape processing in computer graphics [21], bag-of-words for natural language processing [11] and multi-label classification [9]. In all of these problems,\nar X\niv :1\n60 5.\n08 52\n7v 1\n[ m\nat h.\na geometry between the features (words, visual words, labels) is usually known, and can be leveraged to compare probability distributions in a geometrically faithful way. This underlying geometry might be for instance the planar Euclidean domain for 2-D shapes, a perceptual 3D color metric space for image processing or a high-dimensional semantic embedding for words. Optimal transport (OT) [23] is the canonical way to automatically lift this geometry to define a metric for probability distributions. That metric is known as the Wasserstein or earth mover\u2019s distance. As an illustrative example, OT can use a metric between words to build a metric between documents that are represented as frequency histograms of words (see [11] for details). All the above-cited lines of work advocate, among others, that OT is the natural choice to solve these problems, and that it leads to performance improvement when compared to geometrically-oblivious distances such as the Euclidean or \u03c72 distances or the Kullback-Leibler divergence. However, these advantages come at the price of an enormous computational overhead. This is especially true because current OT solvers require to sample beforehand these distributions on a pre-defined set of points, or on a grid. This is both inefficient (in term of storage and speed) and counter-intuitive. Indeed, most high-dimensional computational scenarios naturally represent distributions as objects from which one can sample, not as density functions to be discretized. Our goal is to alleviate these shortcomings. We propose a class of provably convergent stochastic optimization schemes that can handle both discrete and continuous distributions through sampling.\nPrevious works. The prevalent way to compute OT distances is by solving the so-called Kantorovitch problem [10] (see Section 2 for a short primer on the basics of OT formulations), which boils down to a large-scale linear program when dealing with discrete distributions (i.e., finite weighted sums of Dirac masses). This linear program can be solved using network flow solvers, which can be further refined to assignment problems when comparing measures of the same size with uniform weights [3]. Recently, regularized approaches that solve the OT with an entropic penalization [6] have been shown to be extremely efficient to approximate OT solutions at a very low computational cost. These regularized approaches have supported recent applications of OT to computer graphics [21] and machine learning [9]. These methods apply the celebrated Sinkhorn algorithm\u2019s [20], and can be extended to solve more exotic transportation-related problems such as the computation of barycenters [21]. Their chief computational advantage over competing solvers is that each iteration boils down to matrix-vector multiplications, which can be easily parallelized, streams extremely well on GPU, and enjoys linear-time implementation on regular grids or triangulated domains [21].\nThese methods are however purely discrete and cannot cope with continuous densities. The only known class of methods that can overcome this limitation are so-called semi-discrete solvers [1], that can be implemented efficiently using computational geometry primitives [12]. They can compute distance between a discrete distributions and a continuous density. Nonetheless, they are restricted to the Euclidean squared cost, and can only be implemented in low dimensions (2-D and 3-D). Solving these semi-discrete problems efficiently could have a significant impact for applications to density fitting with an OT loss [2] for machine learning applications, see [13]. Lastly, let us point out that there is currently no method that can compute OT distances between two continuous densities, which is thus an open problem we tackle in this article.\nContributions. This paper introduces stochastic optimization methods to compute large-scale optimal transport in all three possible settings: discrete OT, to compare a discrete vs. another discrete measure; semi-discrete OT, to compare a discrete vs. a continuous measure; and continous OT, to compare a continuous vs. another continuous measure. These methods can be used to solve both classical OT problems and their entropic-regularized versions (which enjoy faster convergence properties). We show that the discrete OT problem can be tackled using incremental algorithms, and we consider in particular the stochastic averaged gradient (SAG) method [19]. Each iteration of that algorithm requires N operations (N being the size of the supports of the input distributions), which makes it scale better in large-scale problems than the state-of-the-art Sinkhorn algorithm, while still enjoying\na convergence rate of O(1/k), k being the number of iterations. We show that the semidiscrete OT problem can be solved using averaged stochastic gradient descent (SGD), whose convergence rate is O(1/ \u221a k). For large-scale problems, this approach is numerically advantageous over the brute force approach consisting in sampling first the continuous density to solve next a discrete OT problem. Lastly, for continuous optimal transport, we propose a novel method which makes use of an expansion of the dual variables in a reproducing kernel Hilbert space (RKHS). This allows us for the first time to compute with a converging algorithm OT distances between two arbitrary densities, under the assumption that the two potentials belong to such an RKHS.\nNotations. In the following we consider two metric spaces X and Y. We denote by M1+(X ) the set of positive Radon probability measures on X , and C(X ) the space of continuous functions on X . Let \u00b5 \u2208M1+(X ), \u03bd \u2208M1+(Y), we define\n\u03a0(\u00b5, \u03bd) def. = { \u03c0 \u2208M1+(X \u00d7 Y) ; \u2200(A,B) \u2282 X \u00d7 Y, \u03c0(A\u00d7 Y) = \u00b5(A), \u03c0(X \u00d7B) = \u03bd(B) } the set of joint probability measures on X \u00d7Y with marginals \u00b5 and \u03bd. The Kullback-Leibler divergence between joint probabilities is defined as\n\u2200(\u03c0, \u03be) \u2208M1+(X \u00d7 Y)2, KL(\u03c0|\u03be) def. = \u222b X\u00d7Y ( log ( d\u03c0 d\u03be (x, y) ) \u2212 1 ) d\u03c0(x, y),\nwhere we denote d\u03c0d\u03be the relative density of \u03c0 with respect to \u03be, and by convention KL(\u03c0|\u03be) def. = +\u221e if \u03c0 does not have a density with respect to \u03be. The Dirac measure at point x is \u03b4x. For a set C, \u03b9C(x) = 0 if x \u2208 C and \u03b9C(x) = +\u221e otherwise. The probability simplex of N bins is \u03a3N = { \u00b5 \u2208 RN+ ; \u2211 i \u00b5i = 1 } . Element-wise multiplication of vectors is denoted by\nand K> denotes the transpose of a matrix K. We denote 1N = (1, . . . , 1)> \u2208 RN and 0N = (0, . . . , 0)> \u2208 RN ."}, {"heading": "2 Optimal Transport: Primal, Dual and Semi-dual Formulations", "text": "We consider the optimal transport problem between two measures \u00b5 \u2208 M1+(X ) and \u03bd \u2208 M1+(Y), defined on metric spaces X and Y. No particular assumption is made on the form of \u00b5 and \u03bd, we simply assume that they both can be sampled from to be able to apply our algorithms.\nPrimal, Dual and Semi-dual Formulations. The Kantorovich formulation [10] of OT and its entropic regularization [6] can be conveniently written in a single convex optimization problem as follows\n\u2200(\u00b5, \u03bd) \u2208M1+(X )\u00d7M1+(Y), W\u03b5(\u00b5, \u03bd) def. = min\n\u03c0\u2208\u03a0(\u00b5,\u03bd) \u222b X\u00d7Y\nc(x, y)d\u03c0(x, y) + \u03b5KL(\u03c0|\u00b5\u2297 \u03bd). (P\u03b5)\nHere c \u2208 C(X \u00d7 Y) and c(x, y) should be interpreted as the \u201cground cost\u201d to move a unit of mass from x to y. This c is typically application-dependent, and reflects some prior knowledge on the data to process. We refer to the introduction for a list of previous work where various examples (in imaging, vision, graphics or machine learning) of such costs are given.\nWhen X = Y , \u03b5 = 0 and c = dp for p \u2265 1, where d is a distance on X , then W0(\u00b5, \u03bd) 1 p is known as the p-Wasserstein distance onM1+(X ). Note that this definition can be used for any type of measure, both discrete and continuous. When \u03b5 > 0, problem (P\u03b5) is strongly convex, so that the optimal \u03c0 is unique, and algebraic properties of the KL regularization result in computations that can be tackled using the Sinkhorn algorithm [6].\nFor any c \u2208 C(X \u00d7 Y), we define the following constraint set\nUc def. = {(u, v) \u2208 C(X )\u00d7 C(Y) ; \u2200(x, y) \u2208 X \u00d7 Y, u(x) + v(y) \u2264 c(x, y)} ,\nand define its indicator function as well as its \u201csmoothed\u201d approximation\n\u03b9\u03b5Uc(u, v) def. = { \u03b9Uc(u, v) if \u03b5 = 0, \u03b5 \u222b X\u00d7Y exp( u(x)+v(y)\u2212c(x,y) \u03b5 )d\u00b5(x)d\u03bd(y) if \u03b5 > 0.\n(1)\nFor any v \u2208 C(Y), we define its c-transform and its \u201csmoothed\u201d approximation\n\u2200x \u2208 X , vc,\u03b5(x) def.=  miny\u2208Y c(x, y)\u2212 v(y) if \u03b5 = 0,\u2212\u03b5 log (\u222bY exp( v(y)\u2212c(x,y)\u03b5 )d\u03bd(y)) if \u03b5 > 0. (2) The proposition below describes two dual problems. It is central to our analysis and\npaves the way for the application of stochastic optimization methods.\nProposition 2.1 (Dual and semi-dual formulations). For \u03b5 \u2265 0, one has\nW\u03b5(\u00b5, \u03bd) = max u\u2208C(X ),v\u2208C(Y)\nF\u03b5(u, v) def. = \u222b X u(x)d\u00b5(x) + \u222b Y v(y)d\u03bd(y)\u2212 \u03b9\u03b5Uc(u, v), (D\u03b5)\n= max v\u2208C(Y)\nH\u03b5(v) def. = \u222b X vc,\u03b5(x)d\u00b5(x) + \u222b Y v(y)d\u03bd(y)\u2212 \u03b5, (S\u03b5)\nwhere \u03b9\u03b5Uc is defined in (1) and v c,\u03b5 in (2). Furthermore, u solving (D\u03b5) is recovered from an optimal v solving (S\u03b5) as u = vc,\u03b5. For \u03b5 > 0, the solution \u03c0 of (P\u03b5) is recovered from any (u, v) solving (D\u03b5) as d\u03c0(x, y) = exp(u(x)+v(y)\u2212c(x,y)\u03b5 )d\u00b5(x)d\u03bd(y). Proof. Problem (D\u03b5) is the convex dual of (P\u03b5), and is derived using Fenchel-Rockafellar\u2019s theorem. The relation between u and v is obtained by writing the first order optimality condition for v in (D\u03b5). Plugging this expression back in (D\u03b5) yields (S\u03b5).\nProblem (P\u03b5) is called the primal while (D\u03b5) is its associated dual problem. We refer to (S\u03b5) as the \u201csemi-dual\u201d problem, because in the special case \u03b5 = 0, (S\u03b5) boils down to the so-called semi-discrete OT problem [1]. Both dual problems are concave maximization problems. The optimal dual variables (u, v)\u2014known as Kantorovitch potentials\u2014are not unique, since for any solution (u, v) of (D\u03b5), (u+ \u03bb, v \u2212 \u03bb) is also a solution for any \u03bb \u2208 R. When \u03b5 > 0, they can be shown to be unique up to this scalar translation [6]. We refer to Appendix A for a discussion (and proofs) of the convergence of the solutions of (P\u03b5), (D\u03b5) and (S\u03b5) towards those of (P0), (D0) and (S0) as \u03b5\u2192 0.\nA key advantage of (S\u03b5) over (D\u03b5) is that, when \u03bd is a discrete density (but not necessarily \u00b5), then (S\u03b5) is a finite-dimensional concave maximization problem, which can thus be solved using stochastic programming techniques, as highlighted in Section 4. By contrast, when both \u00b5 and \u03bd are continuous densities, these dual problems are intrinsically infinite dimensional, and we propose in Section 5 more advanced techniques based on RKHSs.\nStochastic Optimization Formulations. The fundamental property needed to apply stochastic programming is that both dual problems (D\u03b5) and (S\u03b5) must be rephrased as minimizing expectations:\n\u2200\u03b5 > 0, F\u03b5(u, v) = EX,Y [f\u03b5(X,Y, u, v)] and \u2200\u03b5 \u2265 0, H\u03b5(v) = EX [h\u03b5(X, v)] , (3)\nwhere the random variables X and Y are independent and distributed according to \u00b5 and \u03bd respectively, and where, for (x, y) \u2208 X \u00d7 Y and (u, v) \u2208 C(X )\u00d7 C(Y),\n\u2200\u03b5 > 0, f\u03b5(x, y, u, v) def.= u(x) + v(y)\u2212 \u03b5 exp (u(x) + v(y)\u2212 c(x, y)\n\u03b5\n) ,\n\u2200\u03b5 \u2265 0, h\u03b5(x, v) def.= \u222b Y v(y)d\u03bd(y) + vc,\u03b5(x)\u2212 \u03b5.\nThis reformulation is at the heart of the methods detailed in the remainder of this article. Note that the dual problem (D\u03b5) cannot be cast as an unconstrained expectation maximization problem when \u03b5 = 0, because of the constraint on the potentials which arises in that case."}, {"heading": "3 Discrete Optimal Transport", "text": "We assume in this section that both \u00b5 and \u03bd are discrete measures, i.e. finite sums of Diracs, of the form \u00b5 = \u2211I i=1 \u00b5i\u03b4xi and \u03bd = \u2211J j=1 \u03bdj\u03b4yj , where (xi)i \u2282 X and (yj)j \u2282 Y, and the histogram vector weights are \u00b5 \u2208 \u03a3I and \u03bd \u2208 \u03a3J . These discrete measures may come from the evaluation of continuous densities on a grid, counting features in a structured object, or be empirical measures based on samples. This setting is relevant for several applications, including all known applications of the earth mover\u2019s distance. We show in this section that our stochastic formulation can prove extremely efficient to compare measures with a large number of points.\nDiscrete Optimization and Sinkhorn. In this setup, the primal (P\u03b5), dual (D\u03b5) and semi-dual (S\u03b5) problems can be rewritten as finite-dimensional optimization problems involving the cost matrix c \u2208 RI\u00d7J+ defined by ci,j = c(xi, yj):\nW\u03b5(\u00b5, \u03bd) = min \u03c0\u2208RI\u00d7J+\n{\u2211 i,j ci,j\u03c0i,j + \u03b5 \u2211 i,j ( log \u03c0i,j \u03bdi\u00b5j \u2212 1 ) \u03c0i,j ; \u03c01J = \u00b5,\u03c0 >1I = \u03bd } ,\n(P\u0304\u03b5) = max\nu\u2208RI ,v\u2208RJ\n\u2211 i ui\u00b5i + \u2211 j vj\u03bdj \u2212 \u03b5 \u2211 i,j exp ( ui+vj\u2212ci,j \u03b5 ) \u00b5i\u03bdj , (for \u03b5 > 0) (D\u0304\u03b5)\n= max v\u2208RJ\nH\u0304\u03b5(v) = \u2211 i\u2208I h\u0304\u03b5(xi,v)\u00b5i, where (S\u0304\u03b5)\nh\u0304\u03b5(x,v) = \u2211 j\u2208J vj\u03bdj + { \u2212\u03b5 log(\u2211j\u2208J exp(vj\u2212c(x,yj)\u03b5 )\u03bdj)\u2212 \u03b5 if \u03b5 > 0, minj (c(x, yj)\u2212 vj) if \u03b5 = 0,\n(4)\nThe state-of-the-art method to solve the discrete regularized OT (i.e. when \u03b5 > 0) is Sinkhorn\u2019s algorithm [6, Alg.1], which has linear convergence rate [8]. It corresponds to a block coordinate maximization, successively optimizing (D\u0304\u03b5) with respect to either u or v. Each iteration of this algorithm is however costly, because it requires a matrix-vector multiplication. Indeed, this corresponds to a \u201cbatch\u201d method where all the samples (xi)i and (yj)j are used at each iteration, which has thus complexity O(N2) where N = max(I, J). We now detail how to alleviate this issue using online stochastic optimization methods.\nIncremental Discrete Optimization when \u03b5 > 0. Stochastic gradient descent (SGD), in which an index k is drawn from distribution \u00b5 at each iteration can be used to minimize the finite sum that appears in in S\u0304\u03b5. The gradient of that term h\u0304\u03b5(xk, \u00b7) is\n\u2207vh\u0304\u03b5(x,v) = \u03bd \u2212 \u03c7\u03b5(c(x,y`)\u2212v`)` , where \u2200\u03b5 > 0, (\u03c7 \u03b5 r)j def. = e\u2212 rj \u03b5 \u03bdj (\u2211 ` e \u2212 r`\u03b5 \u03bd` )\u22121 .\nThis gradient can then be used as a proxy for the full gradient in a standard gradient ascent step to maximize H\u0304\u03b5. Note that in the case where \u03b5 = 0, one can define \u03c70r def. = earg min` r` , where e` is the `th canonical basis vector. When the set arg min` r` is not a singleton, one can arbitrarily choose any element from this set, and \u2207vh\u0304\u03b5(x,v) is then a sub-gradient of the convex function h\u0304\u03b5(x, \u00b7).\nAlgorithm 1 SAG for Discrete OT Input: C Output: v v\u2190 0J , d\u2190 0J , \u2200i,gi \u2190 0J for k = 1, 2, . . . do\nSample i \u2208 {1, 2, . . . , I} uniform. d\u2190 d\u2212 gi gi \u2190 \u00b5i\u2207vh\u0304\u03b5(xi,v) d\u2190 d + gi ; v\u2190 v + Cd\nend for When \u03b5 > 0, the finite sum appearing in (S\u0304\u03b5) suggests to use incremental gradient methods\u2014 rather than purely stochastic ones\u2014which are known to converge faster than SGD. We propose to use the stochastic averaged gradient (SAG) [19]. As SGD, SAG operates at each iteration by sampling a point xk from \u00b5, to compute the gradient corresponding to that sample for the current estimate v. Unlike SGD, SAG keeps in memory a copy of that gradient, until that particular point is sampled again, at which point the copy is updated. Unlike SGD, SAG applies a fixed length update, in the direction of the average of all gradients stored so far, which provides a better proxy\nof the gradient corresponding to the entire sum. This improves the convergence rate to |H\u0304\u03b5(v?\u03b5)\u2212 H\u0304\u03b5(vk)| = O(1/k), where v?\u03b5 is a minimizer of H\u0304\u03b5, at the expense of storing the gradient for each of the I points. This expense can be mitigated by considering mini-batches instead of individual points. Note finally that the SAG algorithm is adaptive to strongconvexity and will be linearly convergent around the optimum. The pseudo-code for SAG is provided in Algorithm 1, and we defer more details on SGD for Section 4, in which it will be shown to play a crucial role. Note that the Lipschitz constant of all these terms is upperbounded by L = maxi \u00b5i/\u03b5.\nNumerical Illustrations on Bags of Word-Embeddings. Comparing texts using a Wasserstein distance on their representations as clouds of word embeddings (so called word mover\u2019s distances) has been recently shown to yield state-of-the-art accuracy for text classification [11]. The authors of [11] have however highlighted that this accuracy comes at a large computational cost. We test our stochastic approach to discrete OT in this scenario, using the complete works of 35 authors1. We use Glove word embeddings [14], namely X = Y = R300. We discard all most frequent 1, 000 words that appear at the top of the file glove.840B.300d provided on the authors\u2019 website. We sample N = 20, 000 words (found within the remaining huge dictionary of relatively rare words) from each authors\u2019 complete work. Each author is thus represented as a cloud of 20, 000 points in R300. The cost function c between the word embeddings is the squared-Euclidean distance, re-scaled so that it has a unit empirical median on 2, 000 points sampled randomly among all vector embeddings. We set \u03b5 to 0.01. We compute all (35 \u00d7 34/2 = 595) pairwise regularized Wasserstein distances using both the Sinkhorn algorithm and SAG. Following the recommendations in [19], SAG\u2019s stepsize is tested for 3 different settings, 1/L, 3/L and 5/L. The convergence of each algorithm is measured by computing the `1 norm of the gradient of the full sum (which also corresponds to the marginal violation of the primal transport solution that can be recovered with these dual variables[6]), as well as the `2 norm of the deviation to the optimal scaling found after 4, 000 passes for any of the three methods. Results are presented in Fig. 1 and suggest that SAG can be more than twice faster than Sinkhorn on average for all tolerance thresholds. Note finally that SAG retains exactly the same parallel properties as Sinkhorn: all of these computations can be streamlined on GPUs. We used 4 Tesla K80 cards to compute both SAG and Sinkhorn results. For each distance computation, all 4, 000 passes (far more than is needed to approximate only the distance) take less than 2 minutes."}, {"heading": "4 Semi-Discrete Optimal Transport", "text": "In this section, we assume that \u00b5 is an arbitrary measure (in particular, it needs not to be discrete) and that \u03bd = \u2211J j=1 \u03bdj\u03b4yj is a discrete measure. This corresponds to the semi-discrete OT problem [1, 12]. The semi-dual problem (S\u03b5) is then a finite-dimensional maximization problem, written in expectation form as W\u03b5(\u00b5, \u03bd) = max v\u2208RJ EX [ h\u0304\u03b5(X,v) ] where X \u223c \u00b5 and h\u0304\u03b5 is defined in (4). Stochastic Semi-discrete Optimization. Since the expectation is taken over an arbitrary measure, neither Sinkhorn algorithm nor incremental algorithms such as SAG can be used. An alternative is to approximate \u00b5 by an empirical measure \u00b5\u0302N def. = 1N \u2211N i=1 \u03b4xi where (xi)i=1,...,N are i.i.d samples from \u00b5, and computing W\u03b5(\u00b5\u0302N , \u03bd) using the discrete methods (Sinkhorn or SAG) detailed in Section 3. However this introduces a discretization noise in the solution as the discrete problem is now different from the original one and thus has a different solution. Averaged SGD on the other hand does not require \u00b5 to be discrete and is thus perfectly adapted to this semi-discrete setting. The algorithm is detailed in\n1 The list of authors we consider is: Keats, Cervantes, Shelley, Woolf, Nietzsche, Plutarch, Franklin, Coleridge, Maupassant, Napoleon, Austen, Bible, Lincoln, Paine, Delafontaine, Dante, Voltaire, Moore, Hume, Burroughs, Jefferson, Dickens, Kant, Aristotle, Doyle, Hawthorne, Plato, Stevenson, Twain, Irving, Emerson, Poe, Wilde, Milton, Shakespeare.\nAlgorithm 2 (the expression for \u2207h\u0304\u03b5 being given in Equation 4). The convergence rate is O(1/ \u221a k) thanks to averaging v\u0303k [15].\nAlgorithm 2 Averaged SGD for Semi-Discrete OT Input: C Output: v v\u0303\u2190 0J , v\u2190 v\u0303 for k = 1, 2, . . . do\nSample xk from \u00b5 v\u0303\u2190 v\u0303 + C\u221a\nk \u2207vh\u0304\u03b5(xk, v\u0303)\nv\u2190 1k v\u0303 + k\u22121n v end for\nNumerical Illustrations. Numerical simulations are performed in X = Y = R3. Here \u00b5 is a Gaussian mixture (i.e. a continuous density) and the measure \u03bd = 1J \u2211J j=1 \u03b4yj with J = 10 and (xj)j are i.i.d. samples drawn from another gaussian mixture. Each mixture is composed of three gaussians whose means are drawn randomly in [0, 1]3, and their correlation matrices are constructed as \u03a3 = 0.01(RT + R) + 3I3 where R is a 3 \u00d7 3 matrix with random entries in [0, 1]. In the following, we denote v?\u03b5 a solution of (S\u03b5), which is approximated numerically by running SGD with for a large enough number of iterations.\nFigure 2 (a) shows the evolution of \u2016vk \u2212 v?0\u20162 / \u2016v?0\u20162 as a function of k. It highlights the influence of the regularization parameters \u03b5 on the iterates of SGD. While the regularized iterates converge faster, they do not converge to the correct unregularized solution. This figure also illustrates the convergence theorem of solution of (S\u03b5) toward those (S0) when \u03b5\u2192 0, which can be found in Appendix A.\nFigure 2 (b) shows the evolution of \u2016vk \u2212 v?\u03b5\u20162 / \u2016v?\u03b5\u20162 averaged over 40 runs as a function of k, for a fixed regularization parameter value \u03b5 = 10\u22122. It compares SGD to SAG using different numbers N of samples for the empirical measures \u00b5\u0302N . While SGD converges to the true solution of the semi-discrete problem, the solution computed by SAG is biased because of the approximation error which comes from the discretization of \u00b5. This error decreases when the sample size N is increased, as the approximation of \u00b5 by \u00b5\u0302N becomes more accurate."}, {"heading": "5 Continuous optimal transport using RKHS", "text": "In the case where neither \u00b5 nor \u03bd are discrete, problem (S\u03b5) is infinite-dimensional, so it cannot be solved directly using stochastic SGD. We propose in this section to solve the initial dual problem (D\u03b5), using expansions of the dual variables in two reproducing kernel Hilbert\nspaces (RKHS). Recall that contrarily to the methods from previous sections, we can only solve the regularized problem here (i.e. \u03b5 > 0), since (D\u03b5) cannot be cast as an expectation maximization problem when \u03b5 = 0.\nStochastic Continuous Optimization. We consider two reproducing kernel Hilbert spaces (RKHS) H and G defined on X and on Y, with kernels \u03ba and `, associated with norms \u2016 \u00b7 \u2016H and \u2016 \u00b7 \u2016G . Recall the two main properties of RKHS: (a) if u \u2208 H, then u(x) = \u3008u, \u03ba(\u00b7, x)\u3009H and (b) \u03ba(x, x\u2032) = \u3008\u03ba(\u00b7, x), \u03ba(\u00b7, x\u2032)\u3009H.\nThe dual problem (D\u03b5) is conveniently re-written in (3) as the maximization of the expectation of f\u03b5(X,Y, u, v) with respect to the random variables (X,Y ) \u223c \u00b5\u2297 \u03bd. The SGD algorithm applied to this problem reads, starting with u0 = 0 and v0 = 0,\n(uk, vk) def. = (uk\u22121, vk\u22121) + C\u221a k \u2207f\u03b5(xk, yk, uk\u22121, vk\u22121) \u2208 H \u00d7 G, (5)\nwhere (xk, yk) are i.i.d. samples from \u00b5 \u2297 \u03bd. The following proposition shows that these (uk, vk) iterates can be expressed as finite sums of kernel functions, and that the coefficients of these expansions enjoy a particularly simple recursion formula.\nProposition 5.1. The iterates (uk, vk) defined in (5) satisfy\n(uk, vk) def. = k\u2211 i=1 \u03b1i(\u03ba(\u00b7, xi), `(\u00b7, yi)), where \u03b1i def.= \u03a0Br ( C\u221a i ( 1\u2212 e ui\u22121(xi)+vi\u22121(yi)\u2212c(xi,yi) \u03b5 )) ,\n(6) where (xi, yi)i=1...k are i.i.d samples from \u00b5\u2297 \u03bd and \u03a0Br is the projection on the centered ball of radius r. If the solutions of (D\u03b5) are in the H \u00d7 G and if r is large enough, the iterates (uk,vk) converge to a solution of (D\u03b5). Proof. Rewriting u(x) and v(y) as scalar products in f\u03b5(X,Y, u, v) yields\nf\u03b5(x, y, u, v) = \u3008u, \u03ba(x, \u00b7)\u3009H + \u3008v, `(y, \u00b7)\u3009G \u2212 \u03b5 exp ( \u3008u, \u03ba(x, \u00b7)\u3009H + \u3008v, `(y, \u00b7)\u3009G \u2212 c(x, y)\n\u03b5\n) .\nPlugging this formula in iteration (5) yields : (uk, vk) = uk\u22121 + \u03b1k(\u03ba(\u00b7, xk), `(\u00b7, yk)) ,where \u03b1k is defined in (6). Since the parameters (\u03b1i)i<k are not updated at iteration k, we get the announced formula. Putting a bound on the iterates of \u03b1 by projecting on Br ensures convergence [7].\nThe algorithm for kernel SGD is outlined in Algorithm 3. Both potentials u and v are approximated by a linear combination of kernel functions. The main cost is the computation of uk\u22121(xk) = \u2211k\u22121 i=1 \u03b1i\u03ba(xk, xi) and vk\u22121(yk) = \u2211k\u22121 i=1 \u03b1i`(yk, yi) which yields complexity O(k2). Several methods exist to alleviate the running time complexity of kernel algorithms, e.g. random Fourier features [16] or incremental incomplete Cholesky decomposition [24].\nAlgorithm 3 Kernel SGD for continuous OT Input: C, kernels \u03ba and ` Output: (\u03b1k, xk, yk)k=1,...\nfor k = 1, 2, . . . do Sample xk from \u00b5 Sample yk from \u03bd uk\u22121(xk) def. = \u2211k\u22121 i=1 \u03b1i\u03ba(xk, xi)\nvk\u22121(yk) def. = \u2211k\u22121 i=1 \u03b1i`(yk, yi) \u03b1k def. = C\u221a\nk\n( 1\u2212 e uk\u22121(xk)+vk\u22121(yk)\u2212c(xk,yk) \u03b5 ) end for\nKernels that are associated with dense RHKS are called universal [22] and thus can approach any arbitrary potential. When working over Euclidean spaces X = Y = Rd for some d > 0, a natural choice of universal kernel is the kernel defined by \u03ba(x, x\u2032) = exp(\u2212\u2016x\u2212x\n\u2032\u20162 \u03c32 ). Tuning the bandwidth \u03c3 is\ncrucial to obtain a good convergence of the algorithm.\nFinally, let us note that, while entropy regularization of the primal problem (P\u03b5) was instrumental to be able to apply semidiscrete methods in Sections 3 and 4, this is not the case here. Indeed, since the kernel SGD algorithm is applied to the dual (D\u03b5), it is possible to replace KL(\u03c0|\u00b5\u2297 \u03bd) appearing in (P\u03b5) by other regularizing divergences. A typical example would be a \u03c72 divergence\u222b X\u00d7Y( d\u03c0 d\u00b5d\u03bd (x, y))\n2d\u00b5(x)d\u03bd(y) (with positivity constraints on \u03c0). Numerical Illustrations. We consider optimal transport in 1D between a Gaussian \u00b5 and a Gaussian mixture \u03bd whose densities are represented in Figure 3 (a). Since there is no existing benchmark for continuous transport, we use the solution of the semi-discrete problem W\u03b5(\u00b5, \u03bd\u0302N ) with N = 103 computed with SGD as a proxy for the solution and we denote it by u\u0302?. We focus on the convergence of the potential u, as it is continuous in both problems contrarily to v. Figure 3 (b) represents the plot of \u2016uk \u2212 u\u0302?\u20162/\u2016u\u0302?\u20162 where u is the evaluation of u on a sample (xi)i=1...N \u2032 drawn from \u00b5. This gives more emphasis to the norm on points where \u00b5 has more mass. The convergence is rather slow but still noticeable. The iterates uk are plotted on a grid for different values of k in Figure 3 (c), to emphasize the convergence to the proxy u\u0302?. We can see that the iterates computed with the RKHS converge faster where \u00b5 has more mass, which is actually where the value of u has the greatest impact in F\u03b5 (u being integrated against \u00b5).\nConclusion We have shown in this work that the computations behind (regularized) optimal transport can be considerably alleviated, or simply enabled, using a stochastic optimization approach. In the discrete case, we have shown that incremental gradient methods can surpass the Sinkhorn algorithm in terms of efficiency, taken for granted that the (constant) stepsize has been correctly selected, which should be possible in practical applications. We have\nalso proposed the first known methods that can address the challenging semi-discrete and continuous cases. All of these three settings can open new perspectives for the application of OT to high-dimensional problems."}, {"heading": "Acknowledgement", "text": "The work of G. Peyr\u00e9 has been supported by the European Research Council (ERC project SIGMA-Vision). The work of A. Genevay has been supported by R\u00e9gion Ile-de-France. M. Cuturi gratefully acknowledges the support of JSPS young research A grant 26700002."}, {"heading": "A Convergence of (S\u03b5) as \u03b5\u2192 0", "text": "The convergence of the solution of (P\u03b5) toward a solution of (P0) as \u03b5\u2192 0 is proved in [4]. The convergence of solutions of (D\u03b5) toward solutions of (D0) as \u03b5 \u2192 0 is proved for the special case of discrete measures in [5]. To the best of our knowledge, the behavior of (S\u03b5) has not been studied in the literature, and we propose a convergence result in the case where \u03bd is discrete, which is the setting in which this formulation is most advantageous.\nProposition A.1. We assume that \u2200y \u2208 Y, c(\u00b7, y) \u2208 L1(\u00b5), that \u03bd = \u2211Jj=1 \u03bdj\u03b4yj , and we fix x0 \u2208 X ,. For all \u03b5 > 0, let v\u03b5 be the unique solution of (S\u03b5) such that v\u03b5(x0) = 0. Then (v\u03b5)\u03b5 is bounded and all its converging sub-sequences for \u03b5\u2192 0 are solutions of (S0).\nWe first prove a useful lemma.\nLemma A.2. If \u2200y, x 7\u2192 c(x, y) \u2208 L1(\u00b5) then H\u03b5 converges pointwise to H0.\nProof. Let \u03b1j(x) def. = vj \u2212 c(x, yj) and j? def.= arg maxj \u03b1j(x). On the one hand, since \u2200j, \u03b1j(x) \u2264 \u03b1j?(x) we get\n\u03b5 log( J\u2211 j=1 e \u03b1j(x) \u03b5 \u03bdj) = \u03b5 log(e \u03b1j? (x) \u03b5 J\u2211 j=1 e \u03b1j(x)\u2212\u03b1j? (x) \u03b5 \u03bdj) \u2264 \u03b1j?(x) + \u03b5 log( J\u2211 j=1 \u03bdj) = \u03b1j?(x) (7)\nOn the other hand, since log is increasing and all terms in the sum are non negative we have\n\u03b5 log( J\u2211 j=1 e \u03b1j(x) \u03b5 \u03bdj) \u2265 \u03b5 log(e \u03b1j? (x) \u03b5 \u03bdj?) = \u03b1j?(x) + \u03b5 log(\u03bdj?) \u03b5\u21920\u2212\u2192 \u03b1j?(x) (8)\nHence \u03b5 log( \u2211J j=1 e \u03b1j(x) \u03b5 \u03bdj) \u03b5\u21920\u2212\u2192 \u03b1j?(x) and \u03b5 log( \u2211J j=1 e \u03b1j(x)\n\u03b5 \u03bdj) \u2264 \u03b1j?(x). Since we assumed x 7\u2192 c(x, yj) \u2208 L1(\u00b5), then \u03b1j? \u2208 L1(\u00b5) and by dominated convergence we get that H\u03b5(v) \u03b5\u21920\u2212\u2192 H0(v).\nProof of Proposition A.1. First, let\u2019s prove that (v\u03b5)\u03b5 has a converging subsequence. With similar computations as in Proposition 2.1 we get that v\u03b5(yi) = \u2212\u03b5 log( \u222b X e u\u03b5(x)\u2212c(x,yi) \u03b5 d\u00b5(x)). We denote by v\u0303\u03b5 the c-transform of u\u03b5 such that v\u0303\u03b5(yi) = minx\u2208X c(x, yi) \u2212 u\u03b5(x). From standard results on optimal transport (see [18], p.11) we know that | v\u0303\u03b5(yi) \u2212 v\u0303\u03b5(yj) |\u2264 \u03c9(\u2016yi \u2212 yj\u2016) where \u03c9 is the modulus of continuity of the cost c. Besides, using once again the soft-max argument we can bound | v\u03b5(y)\u2212 v\u0303\u03b5(y) | by some constant C.\nThus we get that :\n| v\u03b5(yi)\u2212 v\u03b5(yj) | \u2264 | v\u03b5(yi)\u2212 v\u0303\u03b5(yi) | + | v\u0303\u03b5(yi)\u2212 v\u0303\u03b5(yj) | + | v\u0303\u03b5(yj)\u2212 v\u03b5(yj) | (9) \u2264 C + \u03c9(\u2016yi \u2212 yj\u2016) + C (10)\nBesides, the regularized potentials are unique up to an additive constant. Hence we can set without loss of generality v\u03b5(y0) = 0. So from the previous inequality yields :\nv\u03b5(yi) \u2264 2C + \u03c9(\u2016yi \u2212 y0\u2016) (11)\nSo v\u03b5 is bounded on RJ which is a compact set and thus we can extract a subsequence which converges to a certain limit that we denote by v\u0304.\nLet v? \u2208 arg maxvH0. To prove that v\u0304 is optimal, it suffices to prove thatH0(v?) \u2264 H0(v\u0304). By optimality of v\u03b5,\nH\u03b5(v ?) \u2264 H\u03b5(v\u03b5) (12)\nThe term on the left-hand side of the inequality converges to H0(v?) since H\u03b5 converges pointwise to H0. We still need to prove that the right-hand term converges to H0(v\u0304).\nBy the Mean Value Theorem, there exists v\u0303\u03b5 def. = (1\u2212 t\u03b5)v\u03b5 + t\u03b5v\u0304 for some t\u03b5 \u2208 [0, 1] such that | H\u03b5(v\u03b5)\u2212H\u03b5(v\u0304) |\u2264 \u2016\u2207H\u03b5(v\u0303\u03b5)\u2016 \u2016v\u03b5 \u2212 v\u0304\u2016 (13)\nThe gradient of H\u03b5 reads \u2207vH\u03b5(v) = \u03bd \u2212 \u03c0(v) (14) where \u03c0i(v) = \u222b X e vi\u2212c(x,yi) \u03b5 \u03bdid\u00b5(x)\u222b\nX \u2211J j=1 e vj\u2212c(x,yj) \u03b5 \u03bdjd\u00b5(x)\nIt is the difference of two elements in the simplex thus it is bounded by a constant C independently of \u03b5.\nUsing this bound in (13) get\nH\u03b5(v\u0304)\u2212 C \u2016v\u03b5 \u2212 v\u0304\u2016 \u2264 H\u03b5(v\u03b5) \u2264 H\u03b5(v\u0304) + C \u2016v\u03b5 \u2212 v\u0304\u2016 (15)\nBy pointwise convergence of H\u03b5 we know that H\u03b5(v\u0304) \u2192 H0(v\u0304), and since v\u0304 is a limit point of v\u03b5 we can conclude that the left and right hand term of the inequality converge to H0(v\u0304). Thus we get H\u03b5(v\u03b5)\u2192 H0(v\u0304)."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Optimal transport (OT) defines a powerful framework to compare probability distri-<lb>butions in a geometrically faithful way. However, the practical impact of OT is still<lb>limited because of its computational burden. We propose a new class of stochastic opti-<lb>mization algorithms to cope with large-scale problems routinely encountered in machine<lb>learning applications. These methods are able to manipulate arbitrary distributions<lb>(either discrete or continuous) by simply requiring to be able to draw samples from them,<lb>which is the typical setup in high-dimensional learning problems. This alleviates the<lb>need to discretize these densities, while giving access to provably convergent methods<lb>that output the correct distance without discretization error. These algorithms rely<lb>on two main ideas: (a) the dual OT problem can be re-cast as the maximization of an<lb>expectation ; (b) entropic regularization of the primal OT problem results in a smooth<lb>dual optimization optimization which can be addressed with algorithms that have a<lb>provably faster convergence. We instantiate these ideas in three different setups: (i)<lb>when comparing a discrete distribution to another, we show that incremental stochastic<lb>optimization schemes can beat Sinkhorn\u2019s algorithm, the current state-of-the-art finite<lb>dimensional OT solver; (ii) when comparing a discrete distribution to a continuous<lb>density, a semi-discrete reformulation of the dual program is amenable to averaged<lb>stochastic gradient descent, leading to better performance than approximately solving<lb>the problem by discretization ; (iii) when dealing with two continuous densities, we<lb>propose a stochastic gradient descent over a reproducing kernel Hilbert space (RKHS).<lb>This is currently the only known method to solve this problem, apart from computing<lb>OT on finite samples. We backup these claims on a set of discrete, semi-discrete and<lb>continuous benchmark problems.", "creator": "LaTeX with hyperref package"}}}