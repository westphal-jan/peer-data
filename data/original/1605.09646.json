{"id": "1605.09646", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2016", "title": "Average-case hardness of RIP certification", "abstract": "The restricted isometry property (RIP) for design matrices gives guarantees for optimal recovery in sparse linear models. It is of high interest in compressed sensing and statistical learning. This property is particularly important for computationally efficient recovery methods. As a consequence, even though it is in general NP-hard to check that RIP holds, there have been substantial efforts to find tractable proxies for it. These would allow the construction of RIP matrices and the polynomial-time verification of RIP given an arbitrary matrix. We consider the framework of average-case certifiers, that never wrongly declare that a matrix is RIP, while being often correct for random instances. While there are such functions which are tractable in a suboptimal parameter regime, we show that this is a computationally hard task in any better regime. Our results are based on a new, weaker assumption on the problem of detecting dense subgraphs.", "histories": [["v1", "Tue, 31 May 2016 14:38:03 GMT  (52kb,D)", "http://arxiv.org/abs/1605.09646v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CC math.ST stat.ML stat.TH", "authors": ["tengyao wang", "quentin berthet", "yaniv plan"], "accepted": true, "id": "1605.09646"}, "pdf": {"name": "1605.09646.pdf", "metadata": {"source": "CRF", "title": "Average-case hardness of RIP certification", "authors": ["Tengyao Wang", "Quentin Berthet", "Yaniv Plan"], "emails": [], "sections": [{"heading": null, "text": "Introduction\nIn many areas of data science, high-dimensional signals contain rich structure. It is of great interest to leverage this structure to improve our ability to describe characteristics of the signal and to make future predictions. Sparsity is a structure of wide applicability (see, e.g. Mallat, 1999; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012), with a broad literature dedicated to its study in various scientific fields.\nThe sparse linear model takes the form y = X\u03b2 + \u03b5, where y \u2208 Rn is a vector of observations, X \u2208 Rn\u00d7p is a design matrix, \u03b5 \u2208 Rn is noise, and the vector \u03b2 \u2208 Rp\n\u2217University of Cambridge, supported by Benefactors\u2019 Scholarship, St John\u2019s College. \u2020University of Cambridge, supported by the Isaac Newton Trust Early Career Support Scheme \u2021University of British Columbia, supported by NSERC grant 22R23068\nar X\niv :1\n60 5.\n09 64\n6v 1\n[ cs\n.L G\n] 3\n1 M\nis assumed to have a small number k of non-zero entries. Estimating \u03b2 or the mean response, X\u03b2, are among the most widely studied problems in signal processing, as well as in statistical learning. In high-dimensional problems, one would wish to recover \u03b2 with as few observations as possible. For an incoherent design matrix, it is known that an order of k2 observations suffice (Donoho, Elad and Temlyakov, 2006; Donoho and Elad, 2003). However, this appears to require a number of observations far exceeding the information content of \u03b2, which has only k variables, albeit with unknown locations.\nThis dependence in k can be greatly improved by using design matrices that are almost isometries on some low dimensional subspaces, i.e., matrices that satisfy the restricted isometry property with parameters k and \u03b8, or RIP(k, \u03b8) (see Definition 1). It is a highly robust property, and in fact implies that many different polynomial time methods, such as greedy methods (Blumensath and Davies, 2009; Needell and Tropp, 2009; Dai and Milenkovic, 2009) and convex optimization (Cande\u0300s, 2008; Cande\u0300s, Romberg and Tao, 2006b; Cande\u0300s and Tao, 2005, 2006), are stable in recovering \u03b2. Random matrices are known to satisfy the RIP when the number n of observation is more than about k log(p)/\u03b82. These results were developed in the field of compressed sensing (Cande\u0300s, Romberg and Tao, 2006a; Donoho, 2006; Cande\u0300s and Tao, 2006; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012) where the use of randomness still remains pivotal for near-optimal results. Properties related to the conditioning of design matrices have also been shown to play a key role in the statistical properties of computationally efficient estimators of \u03b2 (Zhang, Wainwright and Jordan, 2014). While the assumption of randomness allows great theoretical leaps, it leaves open questions for practitioners.\nScientists working on data closely following this model cannot always choose their design matrix X, or at least choose one that is completely random. Moreover, it is in general practically impossible to check that a given matrix satisfies these desired properties, as RIP certification is NP-hard (Bandeira et al., 2012). Having access to a function, or statistic, of X that could be easily computed, which determines how well \u03b2 may be estimated, would therefore be of a great help.\nThe search for such statistics has been of great importance for over a decade now, and several have been proposed (d\u2019Aspremont and El Ghaoui, 2011; Lee and Bresler, 2008; Juditsky and Nemirovski, 2011; d\u2019Aspremont, Bach and El Ghaoui, 2008). Perhaps the simplest and most popular is the incoherence parameter, which measures the maximum inner product between distinct, normalized, columns of X. However, all of these are known to necessarily fail to guarantee good recovery when p \u2265 2n unless n is of order k2 (d\u2019Aspremont and El Ghaoui, 2011). Given a specific problem instance, the strong recovery guarantees of compressed sensing cannot be verified based on these statistics.\nIn this article, we study the problem of average-case certification of the Restricted Isometry Property (RIP). A certifier takes as input a design matrix X, always outputs\n\u2018false\u2019 when X does not satisfy the property, and outputs \u2018true\u2019 for a large proportion of matrices (see Definition 4). Indeed, worst-case hardness does not preclude a problem from being solvable for most instances. The link between restricted isometry and incoherence implies that polynomial time certifiers exists in a regime where n is of order k2 log(p)/\u03b82. It is natural to ask whether the RIP can be certified for sample size n k log(p)/\u03b82, where most matrices (with respect to, say, the Gaussian measure) are RIP. If it does, it would also provide a Las Vegas algorithm to construct RIP design matrices of optimal sizes. This should be compared with the currently existing limitations for the deterministic construction of RIP matrices.\nOur main result is that certification in this sense is hard even in a near-optimal regime, assuming a new, weaker assumption on detecting dense subgraphs, related to the Planted Clique hypothesis.\nTheorem (Informal). There is no computationally efficient average-case certifier for RIPn,p(k, \u03b8) uniformly over an asymptotic regime where n k1+\u03b1/\u03b82, for any \u03b1 < 1.\nThis suggests that even in the average case, RIP certification requires almost k2 log(p)/\u03b82\nobservations. This contrasts highly with the fact that a random matrix satisfies RIP with high probability when n exceeds about k log(p)/\u03b82. Thus, there appears to be a large gap between what a practitioner may be able to certify given a specific problem instance, and what holds for a random matrix. On the other hand, if a certifier is found which fills this gap, the result would not only have huge practical implications in compressed sensing and statistical learning, but would also disprove a long-standing conjecture from computational complexity theory.\nOur result shares many characteristics with a hypothesis by Feige (2002) on the hardness of refuting random satisfiability formulas. Indeed, our statement is also about the hardness of verifying that a property holds for a particular instance (RIP for design matrices, instead of unsatisfiability for boolean formulas). It concerns a regime where such a property should hold with high probability (n of order k1+\u03b1/\u03b82, linear regime for satisfiability), cautiously allowing only one type of errors, false negatives, for a problem that is hard in the worst case. In these two examples, such certifiers exist in an a sub-optimal regime. Our problem is conceptually different from results regarding the worst-case hardness of certifying this property (see, e.g. Bandeira et al., 2012; Koiran and Zouzias, 2012; Tillmann and Pfetsch, 2014). It is closer to another line of work concerned with computational lower bounds for statistical learning problems based on average-case assumptions. The planted clique assumption has been used to prove computational hardness results for statistical problems such as estimation and testing of sparse principal components (Berthet and Rigollet, 2013a,b; Wang, Berthet and Samworth, 2016), testing and localization of submatrix signals (Ma and Wu, 2013; Chen and Xu, 2014), community\ndetection (Hajek, Wu and Xu, 2015) and sparse canonical correlation analysis (Gao, Ma and Zhou, 2014). The intractability of noisy parity recovery problem (Blum, Kalai and Wasserman, 2003) has also been used recently as an average-case assumption to deduce computational hardness of detection of satisfiability formulas with lightly planted solutions (Berthet and Ellenberg, 2015). Additionally, several unconditional computational hardness results are shown for statistical problems under constraints of learning models (Feldman et al., 2013; Feldman, Perkins and Vempala, 2013). The present work has two main differences compared to previous computational lower bound results. First, in a detection setting, these lower bounds concern two specific distributions (for the null and alternative hypothesis), while ours is valid for all sub-Gaussian distributions, and there is no alternative distribution. Secondly, our result is not based on the usual assumption for the Planted Clique problem. Instead, we use a weaker assumption on a problem of detecting planted dense graphs. This does not mean that the planted graph is a random graph with edge probability q > 1/2 as considered in (Arias-Castro and Verzelen, 2013; Bhaskara et al., 2010; Awasthi et al., 2015), but that it can be any graph with an unexpectedly high number of edges (see section 3.1). This choice is made to strengthen our result: it would \u2018survive\u2019 the discovery of an algorithm that would use very specific properties of cliques (or even of random dense graphs) to detect their presence. As a consequence, the analysis of our reduction is more technically complicated.\nOur work is organized in the following manner: We recall in Section 1 the definition of the restricted isometry property, and some of its known properties. In Section 2, we define the notion of certifier, and prove the existence of a computationally efficient certifier in a sub-optimal regime. Our main result is developed in Section 3, focused on the hardness of average-case certification. The proofs of the main results are in Appendix A and those of auxiliary results in Appendix B."}, {"heading": "1 Restricted Isometric Property", "text": ""}, {"heading": "1.1 Formulation", "text": "We use the definition of Cande\u0300s and Tao (2005), who introduced this notion. Below, for a vector u \u2208 Rp, \u2016u\u20160 is the number of non-zero entries. Definition 1 (RIP). A matrix X \u2208 Rn\u00d7p satisfies the restricted isometry property with sparsity k \u2208 {1, . . . , p} and distortion \u03b8 \u2208 (0, 1), denoted by X \u2208 RIPn,p(k, \u03b8), if it holds that 1\u2212 \u03b8 \u2264 \u2016Xu\u201622 \u2264 1 + \u03b8, for every u \u2208 Sp(k) := {u \u2208 Rp : \u2016u\u20162 = 1, \u2016u\u20160 \u2264 k}.\nThis can be equivalently defined by a property on submatrices of the design matrix: X is in RIPn,p(k, \u03b8) if and only if for any set S of k columns of X, the submatrix formed by taking any these columns is almost an isometry, i.e. if the spectrum of its Gram matrix is contained in the interval [1\u2212 \u03b8, 1 + \u03b8]:\n\u2016X>SXS \u2212 Ik\u2016op \u2264 \u03b8 .\nDenote by \u2016 \u00b7 \u2016op,k the k-sparse operator norm, defined for a matrix A as \u2016A\u2016op,k = supx\u2208Sp(k) \u2016Ax\u20162. This yields another equivalent formulation of the RIP property: X \u2208 RIPn,p(k, \u03b8) if and only if\n\u2016X>X \u2212 Ip\u2016op,k \u2264 \u03b8 . We assume in the following discussion that the distortion parameter \u03b8 is upperbounded by 1. For v \u2208 Rp and T \u2286 {1, . . . , p}, we write vT for the #T -dimensional vector obtained by restricting v to coordinates indexed by T . Similarly, for an n \u00d7 p matrix A and subsets S \u2286 {1, . . . , n} and T \u2286 {1, . . . , p}, we write AS\u2217 for the submatrix obtained by restricting A to rows indexed by S, A\u2217T for the submatrix obtained by restricting A to columns indexed by T ."}, {"heading": "1.2 Generation via Random Design", "text": "Matrices that satisfy the restricted isometry property have many interesting applications in high-dimensional statistics and compressed sensing. However, there is no known way to generate them deterministically in general, and it is even NP-hard to check whether a given matrix X belongs to RIPn,p(k, \u03b8) (see, e.g Bandeira et al., 2012). Several deterministic constructions of RIP matrices exist for sparsity level k . \u03b8 \u221a n. For example, using equitriangular tight frames and Gershgorin\u2019s circle theorem, one can construct RIP matrices with sparsity k \u2264 \u221a n and distortion \u03b8 bounded away from 0 (see, e.g. Bandeira et al., 2012). The limitation k \u2264 \u03b8 \u221a n is known as the \u2018square root bottleneck\u2019. To date, the only constructions that break the \u2018square root bottleneck\u2019 are due to Bourgain et al. (2011) and Bandeira, Mixon and Moreira (2014), both of which give RIP guarantee for k of order n1/2+ for some small > 0 and fixed \u03b8 (the latter construction is conditional on a number-theoretic conjecture being true).\nInterestingly though, it is easy to generate large matrices satisfying the restricted isometry property through random design, and compared to the fixed design matrices mentioned in the previous paragraph, these random design constructions are much less restrictive on the sparsity level, typically allowing k up to the order n/ log(p) (assuming \u03b8 is bounded away from zero). They can be constructed easily from any centred subGaussian distribution. We recall that a distribution (and its associated random variable) is said to be sub-Gaussian with parameter \u03c3 if \u222b R e \u03bbx dQ(x) \u2264 e\u03bb2\u03c32/2 for all \u03bb \u2208 R.\nDefinition 2. Define Q = Q\u03c3 to be the set of sub-Gaussian distributions Q over R with zero mean, unit variance, and sub-Gaussian parameter at most \u03c3.\nThe most common choice for a Q \u2208 Q is the standard normal distribution N (0, 1). Note that by Taylor expansion, for any Q \u2208 Q, we necessarily have \u03c32 \u2265 \u222b R x 2 dQ(x) = 1. In the rest of the paper, we treat \u03c3 as fixed. Define the normalized distribution Q\u0303 to be the distribution of Z/ \u221a n for Z \u223c Q. The following well-known result states that by concentration of measure, random matrices generated with distribution Q\u0303\u2297(n\u00d7p) satisfy restricted isometries (see, e.g. Cande\u0300s and Tao (2005) and Baraniuk et al. (2008)). For completeness, we include a proof that establishes these particular constants stated here. All proofs are deferred to Appendix A or Appendix B.\nProposition 1. Suppose X is a random matrix with distribution Q\u0303\u2297(n\u00d7p), where Q \u2208 Q. It holds that\nP ( X \u2208 RIPn,p(k, \u03b8) ) \u2265 1\u2212 2 exp { k log ( 9ep\nk\n) \u2212 n\u03b8 2\n256\u03c34\n} . (1)\nIn order to clarify the notion of asymptotic regimes used in this paper, we introduce the following.\nDefinition 3. For 0 \u2264 \u03b1 \u2264 1, define the asymptotic regime R\u03b1 := { (pn, kn, \u03b8n)n : p, k \u2192\u221e and n k1+\u03b1n log(pn)\n\u03b82n\n} .\nIt is an immediate consequence of (1) that for (p, k, \u03b8) = (pn, kn, \u03b8n) \u2208 R0 we have, limn\u2192\u221e Q\u0303 \u2297(n\u00d7p)(X \u2208 RIPn,p(k, \u03b8)) = 1."}, {"heading": "2 Certification of Restricted Isometry", "text": ""}, {"heading": "2.1 Objectives and definition", "text": "In practice, it is useful to know with certainty whether a particular realization of a random design matrix satisfies the RIP condition. It is known that the problem of deciding if a given matrix is RIP is NP-hard (Bandeira et al., 2012). However, NP-hardness is a only a statement about worst-case instances. It would still be of great use to have an algorithm that can correctly decide RIP property for an average instance of a design matrix, with some accuracy. Such an algorithm should identify a high proportion of RIP matrices generated through random design and make no false positive claims. We call such an algorithm an average-case certifier, or a certifier for short.\nDefinition 4 (Certifier). Given a parameter sequence (p, k, \u03b8) = (pn, kn, \u03b8n), we define a certifier for Q\u0303\u2297(n\u00d7p)-random matrices to be a sequence (\u03c8n)n of measureable functions \u03c8n : Rn\u00d7p \u2192 {0, 1}, such that\n\u03c8\u22121n (1) \u2286 RIPn,p(k, \u03b8) and lim sup n\u2192\u221e\nQ\u0303\u2297(n\u00d7p) ( \u03c8\u22121n (0) ) \u2264 1/3. (2)\nNote the definition of a certifier depends on both the asymptotic parameter sequence (pn, kn, \u03b8n) and the sub-Gaussian distribution Q. However, when it is clear from the context, we will supress the dependence and refer to certifiers for RIPn,p(k, \u03b8) properties of Q\u0303\u2297(n\u00d7p)-random matrices simply as \u2018certifiers\u2019.\nThe two defining properties in (2) can be understood as follows. The first condition means that if a certifier outputs 1, we know with certainty that the matrix is RIP. The second condition means that the certifier is not overly conservative; it is allowed to output 0 for at most one third (with respect to Q\u0303\u2297(n\u00d7p) measure) of the matrices. The choice of 1/3 in the definition of a certifier is made to simplify proofs. However, all subsequent results will still hold if we replace 1/3 by any constant in (0, 1). In view of Proposition 1, the second condition in (2) can be equivalently stated as\nlim n\u2192\u221e\nQ\u0303\u2297(n\u00d7p) { \u03c8n(X) = 1 \u2223\u2223 X \u2208 RIPn,p(k, \u03b8)} \u2265 2/3 With such a certifier, given an arbitrary problem fitting the sparse linear model, the matrix X could be tested for the restricted isometry property, with some expectation of a positive result. This would be particularly interesting given a certifier in the parameter regime n \u03b82nk2n, in which presently known polynomial-time certifiers cannot give positive results.\nEven though it is not the main focus of our paper, we also note that a certifier \u03c8 with the above properties for some distribution Q \u2208 Q would form a certifier/distribution couple (\u03c8,Q), that yields in the usual manner a Las Vegas algorithm to generate RIP matrices. The (random) algorithm keeps generating random matrices X \u223c Q\u0303\u2297(n\u00d7p) until \u03c8n(X) = 1. The number of times that the certifier is invoked has a geometric distribution with success probability Q\u0303\u2297(n\u00d7p) ( \u03c8\u22121n (1) ) . Hence, the Las Vegas algorithm runs in randomized polynomial time if and only if \u03c8n runs in randomized polynomial time."}, {"heading": "2.2 Certifier properties", "text": "Although our focus is on algorithmically efficient certifiers, we establish first the properties of a certifier that is computationally intractable. This certifier serves as a benchmark\nfor the performance of other candidates. Indeed, we exhibit in the following proposition a certifier, based on the k-sparse operator norm, that works uniformly well in the same asymptotic parameter regime R0, where Q\u0303\u2297(n\u00d7p)-random matrices are RIP with asymptotic probability 1. For clarity, we stress that our criterion when judging a certifier will always be its uniform performance over asymptotic regimes R\u03b1 for some \u03b1 \u2208 [0, 1].\nProposition 2. Suppose (p, k, \u03b8) = (pn, kn, \u03b8n) \u2208 R0. Furthermore, Let Q \u2208 Q and X \u223c Q\u0303\u2297(n\u00d7p). Then the sequence of tests (\u03c8op,k)n based on sparse operator norms, defined by\n\u03c8op,k(X) = 1 { \u2016X>X \u2212 Ip\u2016op,k \u2264 \u03b8 } .\nis a certifier for Q\u0303\u2297(n\u00d7p)-random matrices.\nBy a direct reduction from the clique problem, one can show that it is NP-hard to compute the k-sparse operator norm of a matrix. Hence the certifier \u03c8op,k is computationally intractable. The next proposition concerns the certifier property of a test based on the maximum incoherence between columns of the design matrix. It follows directly from a well-known result on the incoherence parameter of a random matrix (see, e.g. Rauhut and Foucart (2013, Proposition 6.2)) and allows the construction of a polynomial-time certifier that works uniformly well in the asymptotic parameter regime R1.\nProposition 3. Suppose (p, k, \u03b8) = (pn, kn, \u03b8n) satisfies n \u2265 196\u03c34k2 log(p)/\u03b82. Let Q \u2208 Q and X \u223c Q\u0303\u2297(n\u00d7p), then the tests \u03c8\u221e defined by\n\u03c8\u221e(X) = 1 { \u2016X>X \u2212 Ip\u2016\u221e \u2264 14\u03c32 \u221a log(p)\nn\n} ,\nis a certifier for Q\u0303\u2297(n\u00d7p)-random matrices.\nProposition 3 shows that, when the sample size n is above k2 log(p)/\u03b82 in magnitude (in particular, this is satisfied asymptotically when (p, k, \u03b8) = (pn, kn, \u03b8n) \u2208 R1), there is a polynomial time certifier. In other words, in this high-signal regime, the average-case decision problem for RIP property is much more tractable than indicated by the worstcase result. On the other hand, the certifier in Proposition 3 works in a much smaller parameter range when compared to \u03c8op,k in Proposition 2. Combining Proposition 2 and 3, we have the following schematic diagram (Figure 2.2). When the sample size is lower than specified in R0, the property does not hold, with high probability, and no certifier exists. A computationally intractable certifier works uniformly over R0. On the other end of the spectrum, when the sample size is large enough to be in R1, a simple\ncertifier based on the maximum incoherence of the design matrix is known to work in polynomial time. This leaves open the question of whether (randomized) polynomial time certifiers can work uniformly well in R0, or R\u03b1 for any \u03b1 \u2208 [0, 1). We will see in the next section that, assuming a weaker variant of the Planted Clique hypothesis from computational complexity theory, R1 is essentially the largest asymptotic regime where a randomized polynomial time certifier can exist."}, {"heading": "3 Hardness of Certification", "text": ""}, {"heading": "3.1 Planted dense subgraph assumptions", "text": "We show in this section that certification of RIP property is an average-case hard problem in the parameter regime R\u03b1 for any \u03b1 < 1. This is precisely the regime not covered by Proposition 3. The average-case hardness result is proved via reduction to the planted dense subgraph assumption.\nFor any integer m \u2265 0, denote Gm the collection of all graphs on m vertices. We write V (G) and E(G) for the set of vertices and edges of a graph G. For H \u2208 G\u03ba where \u03ba \u2208 {0, . . . ,m}, let G(m, 1/2, H) be the random graph model that generates a random graph G on m vertices as follows. It first picks \u03ba random vertices K \u2286 V (G) and plants an isomorphic copy of H on these \u03ba vertices, then every pair of vertices not in K\u00d7K is connected by an edge independently with probability 1/2. We write PH for the probability measure on Gm associated with G(m, 1/2, H). Note that if H is the empty graph, then G(m, 1/2, \u2205) describes the Erdo\u030bs\u2013Re\u0301nyi random graph. With slight abuse of notation, we write P0 in place of P\u2205. On the other hand, for \u2208 (0, 1/2], if H belongs\nto the set\nH = H\u03ba, := { H \u2208 G\u03ba : #E(H) \u2265 (1/2 + )\n\u03ba(\u03ba\u2212 1) 2\n} ,\nthen G(m, 1/2, H) generates random graphs that contain elevated local edge density. The planted dense graph problem concerns testing apart the following two hypotheses:\nH0 : G \u223c G(m, 1/2, \u2205) and H1 : G \u223c G(m, 1/2, H) for some H \u2208 H\u03ba, . (3)\nIt is widely believed that for \u03ba = O(m1/2\u2212\u03b4), there does not exist randomized polynomial time tests to distinguish between H0 and H1 (see, e.g. Jerrum (1992); Feige and Krauthgamer (2003); Feldman et al. (2013)). More precisely, we have the following assumption.\nAssumption (A1) 1. Fix \u2208 (0, 1/2] and \u03b4 \u2208 (0, 1/2). let (\u03bam)m be any sequence of integers such that \u03bam \u2192 \u221e and \u03bam = O ( m1/2\u2212\u03b4 ) . For any sequence of randomized polynomial time tests (\u03c6m : Gm \u2192 {0, 1})m, we have\nlim inf m\n{ P0 ( \u03c6(G) = 1 ) + max H\u2208H\u03ba, PH ( \u03c6(G) = 0) )} > 1/3 .\nWe remark that if = 1/2, then H\u03ba, contains only the \u03ba-complete graph and the testing problem becomes the well-known planted clique problem (cf. Jerrum (1992) and references in Berthet and Rigollet (2013a,b)).\nThe difficulty of this problem has been used as a primitive for hardness of other tasks, such as cryptographic applications, in Juels and Peinado (2000), testing for kwise dependence in Alon et al. (2007), approximating Nash equilibria in Hazan and Krauthgamer (2011). In this case, Assumption (A1) is a version of the planted clique hypothesis (see, e.g. Berthet and Rigollet (2013b, Assumption APC)). We emphasize that Assumption A1 is significantly milder than the planted clique hypothesis (since it allows any \u2208 (0, 1/2]), or that an hypothesis on planted random graphs. We also note that when \u03ba \u2265 C \u221a m, spectral methods can be used to detect such graphs with high probability. Indeed, when G contains a graph of H, AG\u221211>/2 has a leading eigenvalue greater than (\u03ba\u2212 1), whereas it is of order \u221a m for a usual Erdo\u030bs\u2013Re\u0301nyi random graph.\nThe following theorem relates the hardness of the planted dense subgraph testing problem to the hardness of certifying restricted isometry of random matrices. We recall that the distribution of X is that of an n\u00d7 p random matrix with entries independently and identically sampled from Q\u0303 d = Q/ \u221a n, for some Q \u2208 Q. We also write \u03a8rp for the class of randomized polynomial time certifiers.\nTheorem 4. Assume (A1) and fix any \u03b1 \u2208 [0, 1). Then there exists a sequence (p, k, \u03b8) = (pn, kn, \u03b8n) \u2208 R\u03b1, such that there is no certifier/distribution couple (\u03c8,Q) \u2208 \u03a8rp \u00d7Q with respect to this sequence of parameters.\nOur proof of Theorem 4 relies on the following ideas: Given a graph G, instance of the planted clique problem in the assumed hard regime, we construct n random vectors based on the adjacency matrix of a bipartite subgraph of G, between two random sets of vertices. Each coefficient of these vectors is then randomly drawn from one of two carefully chosen distributions, conditionally on the presence or absence of a particular edge. This construction ensures that if the graph is an Erdo\u030bs\u2013Re\u0301nyi random graph (i.e. with no planted graph), the vectors are independent with independent coefficients, with distribution Q\u0303. Otherwise, we show that with high probability, the presence of an unusually dense subgraph will make it very likely that the matrix does not satisfy the restricted isometry property, for a set of parameters in R\u03b1. As a consequence, if there existed a certifier/distribution couple (\u03c8,Q) \u2208 \u03a8rp\u00d7Q in this range of parameters, it could be used - by using as input in the certifier the newly constructed matrix - to determine with high probability the distribution of G, violating our assumption (A1).\nWe remark that this result holds for any distribution in Q, in contrast to computational lower bounds in statistical learning problems, that apply to a specific distribution. For the sake of simplicity, we have kept the coefficients of X identically distributed, but our analysis is not dependent on that fact, and our result can be directly extended to the case where the coefficients are independent, with different distributions in Q.\nTheorem 4 may be viewed as providing an asymptotic lower bound of the sample size n for the existence of a computationally feasible certifier. It establishes this computational lower bound by exhibiting some specific \u2018hard\u2019 sequences of parameters inside R\u03b1 and shows through a reduction to the planted dense subgraph problem. All hardness results, whether in a worst-case (NP-hardness, or other) or the average-case (by reduction from a hard problem), are by nature statements on the impossibility of accomplishing a task in a computationally efficient manner, uniformly over a range of parameters. They are therefore always based on the construction of a \u2018hard\u2019 sequence of parameters used in the reduction, for which a contradiction is shown. Here, the \u2018hard\u2019 sequence is explicitly constructed in the proof to be some (p, k, \u03b8) = (pn, kn, \u03b8n) satisfying p \u2265 n and n1/(3\u2212\u03b1\u22124\u03b2) k n1/(2\u2212\u03b2)\u2212\u03b4, for \u03b2 \u2208 [0, (1 \u2212 \u03b1)/3) and any small \u03b4 > 0. The tuning parameter \u03b2 is to allow additional flexibility in choosing these \u2018hard\u2019 sequences. More precisely, using an averaging trick first seen in Ma and Wu (2013), we are able to show that the existence of such \u2018hard\u2019 sequences is not confined only in the sparsity regime k n1/2 . We note that in all our \u2018hard\u2019 sequences, \u03b8n must depend on n. An interesting extension is to see if similar computational lower bounds hold when restricted to a subset\nof R\u03b1 where \u03b8 is constant."}, {"heading": "A Proofs of Main Results", "text": "Proof of Theorem 4. We prove by contradiction. Assume the contrary, that (\u03c8n)n is a polynomial time computable certifier for Q\u0303\u2297(n\u00d7p)-random matrices. Let \u03be denote the median of Q\u0303. By definition of the median, there exists a unique decomposition of the probability measure Q\u0303 as Q\u0303 = 1\n2 Q\u0303+ + 1 2 Q\u0303\u2212, where Q\u0303+ and Q\u0303\u2212 are probability measures\nsupported on (\u2212\u221e, \u03be] and [\u03be,\u221e) respectively. For \u03b1 < 1 and 0 \u2264 \u03b2 < 1\n3 (1 \u2212 \u03b1), let (p, k, \u03b8) = (pn, kn, \u03b8n) \u2208 R\u03b1 be a sequence\nsatisfying p \u2265 n, n 1 3\u2212\u03b1\u22124\u03b2 k n 1 2\u2212\u03b2\u2212\u03b4 for some \u03b4 > 0. Let L = 10 and ` = bk\u03b2c. Define m = L`n and \u03ba = Lk. We check that\n\u03ba2 k2\u2212\u03b2k\u03b2 n1\u2212\u03b4` \u2248 m1\u2212\u03b4\u2032\nfor some positive \u03b4\u2032 that depends on \u03b4 only. We prove below that Algorithm 1, which runs in randomized polynomial time, can distinguish between P0 and PH with zero asymptotic error for any choice of H \u2208 H\u03ba, .\nFirst, assume G \u223c P0. Then matrix A from Step 1 of Algorithm 1 have independent Rademacher entries, which implies that X \u223c Q\u0303\u2297(n\u00d7p). Therefore, by (2) in Section 2 we must have\nP0(\u03c6(G) = 1) = Q\u0303 \u2297(n\u00d7p)(\u03c8\u22121n (0))\u2192 0.\nNext, assume G is generated with probability measure PH for some H \u2208 H\u03ba, . We claim that\nX\u0303 /\u2208 RIPn,n ( k, ck2\nn`2\n) (4)\nfor some absolute positive constant c. Since\nk2 n`2 \u221a k1+\u03b1 n \u03b8,\nwe have that for large n, X\u0303 /\u2208 RIPn,n(k, \u03b8). Hence X is a fortiori not an RIPn,p(k, \u03b8) matrix. As a result,\nlim inf m max H\u2208H\u03ba,\nPH ( \u03c6(G) = 0) ) < 1/3,\ncontradicting Hypothesis AH . It remains to verify the claimed result in (4). LetK \u2286 V (G) be the \u03ba-subset of vertices on which the subgraph H is planted. We write U = {u1, . . . , uN} and W = {w1, . . . , wN}\nAlgorithm 1: Pseudo-code for an algorithm to distinguish between P0 and PH .\nInput: m \u2208 N, \u03ba \u2208 {1, . . . ,m}, G \u2208 Gm, L \u2208 N begin\nStep 1: Let N \u2190 bm/Lc, `\u2190 bk\u03b2c, n\u2190 bN/`c, p\u2190 pn, k \u2190 b\u03ba/Lc. Draw u1, . . . , uN , w1, . . . , wN uniformly at random without replacement from V (G). Form A = (Aij) \u2208 RN\u00d7N where Aij = 2 \u00b7 1{ui\u223cwj} \u2212 1. Step 2: Let Y + = (Y +ij ) and Y\n\u2212 = (Y \u2212ij ) be N -by-N random matrices independent from all other random variables and from each other, and such that Y +ij i.i.d.\u223c Q\u0303+ and Y \u2212ij\ni.i.d.\u223c Q\u0303\u2212. Define Z = (Zij) by Zij = 1{Aij = 1}Y +ij + 1{Aij = \u22121}Y \u2212ij . Step 3: For 0 \u2264 a, b \u2264 `\u2212 1, define Z(a,b) \u2208 Rn\u00d7n by Z(a,b)i,j = Zan+i,bn+j. Define X\u0303 \u2190 `\u22121 \u2211 0\u2264a,b<` Z (a,b). Finally, let X \u2190 ( X\u0303 X\u0303 \u2032 ) where X\u0303 \u2032 \u2208 Rn\u00d7(p\u2212n) has entries independently drawn from distribution Q\u0303. Step 4: Let \u03c6(G)\u2190 1\u2212 \u03c8n(X).\nend\nOutput: \u03c6(G)\nfor the two random subsets of vertices. Let NU,W ;K be the random variable counting the number of edges in G with two endpoints in U \u2229K and W \u2229K respectively. Then\nNU,W ;K = # { {u,w} \u2208 E(G) : u \u2208 U \u2229K,w \u2208 W \u2229K } = \u2211 u\u2208K \u2211 w\u2208K 1{u \u2208 U}1{w \u2208 W}1{u \u223c w}.\nDefine\n\u21261 := { NU,W ;K \u2265 ( 1\n2 + 4\n) k2 } \u2229 {\u2223\u2223#U \u2229K \u2212 k\u2223\u2223 \u2264\n8 k\n} \u2229 {\u2223\u2223#W \u2229K \u2212 k\u2223\u2223 \u2264\n8 k\n} .\nLemma 5 below shows that \u21261 has asymptotic probability 1. Note \u21261 is in the \u03c3-algebra of (U,W ). Let U = U0 and W = W0 be any realization satisfying \u21261. We write PU0,W0 and EU0,W0 as shorthand for the probability and expectation conditional on U = U0 and W = W0.\nFor each j \u2208 {1, . . . , n}, define sj := \u2211\nui\u2208U\u2229K Ai,j. Write k1 := (1 \u2212 /8)k and k2 = (1+ /8)k. Let S := {i : ui \u2208 U\u2229K}, and let T be a subset of k1 indices in {1, . . . , n}\ncorresponding to the k1 largest values of sj (breaking ties arbitrarily). Note that S and T are functions of U and V . On the event U = U0 and W = W0, both #S = #U \u2229K and #W \u2229 K are bounded in the interval [k1, k2], so in particular k1 \u2264 #W \u2229 K. We have\u2211 wj\u2208W\u2229K sj = 2NU,W ;K \u2212#(U \u2229K)\u00d7#(W \u2229K) \u2265 { (1 + /2)\u2212 (1 + /8)2 } k2 \u2265 5 k2.\nAs elements of T index columns of A corresponding to largest values of sjs, we have that on event {U = U0,W = W0},\u2211\nj\u2208T\nsj \u2265 #T\n#W \u2229K 5 k2 \u2265 5 k2k1 k2 \u2265 6 kk1. (5)\nDefine the unit vector v \u2208 Rn by vT = k\u22121/21 1k1 and vT c = 0. Note that v is k1-sparse and hence also k-sparse. Conditional on U = U0 and W = W0, Zij = Y + ij if Aij = 1 and Zij = Y \u2212 ij if Aij = \u22121. By definition of Q\u0303+ and Q\u0303\u2212, and the fact that Q\u0303 is not a point\nmass, we have EY +ij = \u2212EY \u2212ij = c1/ \u221a n for some absolute constant c1 > 0. By (5), the sum \u2211\ni\u2208S,j\u2208T Zij can be bounded below in conditional expectation by\nEU0,W0 \u2211\ni\u2208S,j\u2208T Zij \u2265 EU0,W0 ( \u2211 i\u2208S,j\u2208T (1{Aij = 1}Y +ij + 1{Aij = \u22121}Y \u2212ij ) )\n= c1\u221a n (\u2211 j\u2208T sj ) \u2265 c1\u221a n 6 kk1 .\nBy Lemma 7, both Y +ij \u2212 EY +ij and Y \u2212ij \u2212 EY \u2212ij are sub-Gaussian with parameter at most c2\u03c3/ \u221a n for some absolute constant c2 > 0. By Hoeffding\u2019s inequality for sums of sub-Gaussian random variables (see e.g. Vershynin (2012, Proposition 5.10)),\nPU0,W0 ( \u2211 i\u2208S,j\u2208T Zij > c1 12 \u221a n kk1 ) \u2265 1\u2212 2 exp { \u2212 ( c1 12 \u221a n kk1) 2 2c22\u03c3 2k1k2k/n } \u2192 1. (6)\nBy (6) and the fact that P(\u21261)\u2192 1, the event\n\u21262 := { \u2211 i\u2208S,j\u2208T Zij \u2265 c1 kk1 12 \u221a n } has asymptotic probability 1.\nNow define\nS\u0303 = {i \u2208 {1, . . . , n} : uan+i \u2208 U \u2229K for some 0 \u2264 a \u2264 `\u2212 1} T\u0303 = {j \u2208 {1, . . . , n} : wbn+j \u2208 W \u2229K for some 0 \u2264 b \u2264 `\u2212 1}\nAlso, define v(b) = (vbn+1, . . . , vbn+n) > for 0 \u2264 b \u2264 ` \u2212 1, v\u0303sum = \u2211 0\u2264b\u2264`\u22121 v (b) and v\u0303 = v\u0303sum/\u2016v\u0303sum\u20162. By Lemma 10, we have \u2016v\u0303sum\u2016\u221e \u2264 c2k\u22121/21 with asymptotic probability 1 for some c2 depending on \u03b2 only. Hence \u2016v\u0303sum\u20162 \u2264 c2. Thus, by Cauchy\u2013Schwarz inequality, we have with asymptotic probability 1,\n\u2016X\u0303S\u0303\u2217v\u0303\u20162 \u2265 \u2016v\u0303sum\u2016 \u22121 2 \u2016v\u0303\u2016 \u22121/2 0 \u2016X\u0303S\u0303\u2217v\u0303sum\u20161 \u2265 \u2016v\u0303\u2016 \u22121 2 \u2016v\u0303\u2016 \u22121/2 0\n1\n` \u221a k1 \u2211 i\u2208S,j\u2208T Zij \u2265 c3 k ` \u221a n .\nOn the other hand, the submatrix X\u0303S\u0303c\u2217 has independent and identically distributed entries. By Vershynin (2012, Lemma 5.9), for i \u2208 S\u0303c and 1 \u2264 j \u2264 n, X\u0303ij = `\u22121 \u2211`\u22121 a,b=0 Z (a,b) an+i,bn+j\nis a centred sub-Gaussian random variable with sub-Gaussian parameter \u03c3/ \u221a n and variance 1/n. Let X\u0303i denote the ith row vector of the matrix X\u0303, then X\u0303 > i v\u0303 is also a centred\nsub-Gaussian random variable with parameter \u03c3/ \u221a n and variance 1/n. Using Lemma 9, we have\nP ( \u2016X\u0303Sc\u2217v\u0303\u201622 \u2212\nn\u2212#S\u0303 n \u2264 \u2212\n\u221a log n\nn\u2212#S\u0303\n) \u2264 exp { \u2212 log n\n64\u03c34\n} \u2192 0.\nSince #S\u0303 \u2264 k2 with asymptotic probability 1, the event\n\u21263 := { \u2016X\u0303S\u0303c\u2217v\u0303\u2016 2 2 \u2265 1\u2212 k2 n \u2212 \u221a 2 log n n } has asymptotic probability 1. Finally, since X\u0303v\u0303 = (X\u0303S\u0303\u2217v\u0303, X\u0303S\u0303c\u2217v) >, on \u21262 \u2229 \u21263,\n\u2016X\u0303v\u0303\u201622 = \u2016X\u0303S\u0303\u2217v\u0303\u2016 2 2 + \u2016X\u0303S\u0303c\u2217v\u2016 2 2 \u2265 1 +\nc23 2k2 `2n \u2212 k2 n \u2212 \u221a 2 log n n .\nThe right hand side is at least 1 + ck2/n for some absolute positive constant c for all large values of n. This verifies (4) and concludes the proof.\nLemma 5. Let G be a graph on m vertices and K a \u03ba-subset of V (G), such that the edge density of G restricted to K is at least 1/2 + . Let n, p be integers less than m/2. Choose u1, . . . , un and w1, . . . , wp independently at random without replacement from V (G). Denote U = {u1, . . . , un} and W = {w1, . . . , wp}. Define NU,W ;K to be\nthe number of edges with two endpoints in U and W respectively. Then for m,n, p, \u03ba sufficiently large.\nP {\u2223\u2223\u2223\u2223#U \u2229K \u2212 n\u03bam \u2223\u2223\u2223\u2223 \u2264 8 n\u03bam } \u2264 8 \u221a m n\u03ba ,\nP {\u2223\u2223\u2223\u2223#W \u2229K \u2212 p\u03bam \u2223\u2223\u2223\u2223 \u2264 8 p\u03bam } \u2264 8 \u221a m p\u03ba ,\nP { NU,W ;K \u2265 ( 1\n2 + 4\n) np\u03ba2\nm2\n} \u2264 4 \u221a m(p\u03ba+ n\u03ba+m)\nnp\u03ba2 .\nProof. The cardinality of U \u2229K has HyperGeom(m,\u03ba, n) distribution. Hence\nE(#U \u2229K) = n\u03ba m and var(#U \u2229K) = n \u03ba m m\u2212 \u03ba m m\u2212 n m\u2212 1 \u2264 n\u03ba m .\nThe first inequality in the lemma now follows from an application of Chebyshev\u2019s inequality. A similar argument establishes the second inequality. For the final inequality in the lemma, we have that for \u03ba sufficiently large,\nE(NU,W ;K) = \u2211 u\u2208K \u2211 w\u2208K P(u \u2208 U,w \u2208 W )1{v \u223c w}\n= np m(m\u2212 1) \u2211 u\u2208K \u2211 w\u2208K 1{u \u223c w} \u2265 (1 2 + )np\u03ba(\u03ba\u2212 1) m(m\u2212 1) \u2265 (1 2 + 2 )np\u03ba2 m2 ..\nWe then compute the variance of NU,W ;K by\nvar(NU,W ;K) = cov (\u2211 u\u2208K \u2211 w\u2208K 1{u \u2208 U,w \u2208 W,u \u223c w}, \u2211 u\u2032\u2208K \u2211 w\u2032\u2208K 1{u\u2032 \u2208 U,w\u2032 \u2208 W,u\u2032 \u223c w\u2032} )\n= \u2211\nu,w,u\u2032,w\u2032\u2208K\ncov ( 1{u \u2208 U,w \u2208 W,u \u223c w},1{u\u2032 \u2208 U,w\u2032 \u2208 W,u\u2032 \u223c w\u2032} ) =: I + II + III + IV,\nwhere the four terms I, II, III and IV handle sums over subsets of indices {(u,w, u\u2032, w\u2032) \u2208 K4 : u 6= u\u2032, w 6= w\u2032}, {(u,w, u\u2032, w\u2032) \u2208 K4 : u = u\u2032, w 6= w\u2032}, {(u,w, u\u2032, w\u2032) \u2208 K4 : u 6= u\u2032, w = w\u2032} and {(u,w, u\u2032, w\u2032) \u2208 K4 : u = u\u2032, w = w\u2032} respectively.\nWe bound the four terms separately. For the first term, we have I = \u2211\nu,u\u2032,w,w\u2032 distinct\n{ P(u, u\u2032 \u2208 U,w,w\u2032 \u2208 W )\u2212 P(u \u2208 U,w \u2208 W )P(u\u2032 \u2208 U,w\u2032 \u2208 W ) } 1{v \u223c w}1{u\u2032 \u223c w\u2032}\n= \u2211\nu,u\u2032,w,w\u2032 distinct\n{ n(n\u2212 1)p(p\u2212 1) m(m\u2212 1)(m\u2212 2)(m\u2212 3) \u2212 (\nnp\nm(m\u2212 1)\n)2} 1{u \u223c w}1{u\u2032 \u223c w\u2032}.\nWhen m > max(2n, 2p), the term in bracket above is non-positive, hence I \u2264 0. For the second term, we get that\nII = \u2211\nu,w,w\u2032 distinct\n{ P(u \u2208 U,w,w\u2032 \u2208 W )\u2212 P(u \u2208 U,w \u2208 W )P(u \u2208 U,w\u2032 \u2208 W ) } 1{u \u223c w}1{u\u2032 \u223c w\u2032}\n= \u2211\nu,w,w\u2032 distinct\n{ np(p\u2212 1) m(m\u2212 1)(m\u2212 2) \u2212 (\nnp\nm(m\u2212 1)\n)2} 1{u \u223c w}1{u \u223c w\u2032}\n\u2264 np(p\u2212 1) m(m\u2212 1)(m\u2212 2) \u2211 u,w,w\u2032 distinct 1{u \u223c w}1{u \u223c w\u2032} \u2264 np 2\u03ba3 m3 .\nSimilarly, we have\nIII \u2264 n(n\u2212 1)p\u03ba(\u03ba\u2212 1)(\u03ba\u2212 2) m(m\u2212 1)(m\u2212 2) \u2264 n 2p\u03ba3 m3 .\nAnd finally, IV = \u2211\nu,w distinct\n{ P(u \u2208 U,w \u2208 W )\u2212P(u \u2208 U,w \u2208 W )2 } 1{u \u223c w} \u2264 np\u03ba(\u03ba\u2212 1)\nm(m\u2212 1) \u2264 np\u03ba\n2\nm2 .\nSum up the four terms, we get that\nvar(NU,W ;K) \u2264 np\u03ba2\nm2\n( p\u03ba\nm + n\u03ba m + 1\n) .\nBy Chebyshev\u2019s inequality, we get that\nP { NU,W ;K \u2265 ( 1\n2 + 4\n) np\u03ba2\nm2\n} \u2264 4 \u221a m(p\u03ba+ n\u03ba+m)\nnp\u03ba2 ,\nas desired."}, {"heading": "B Auxiliary Results", "text": "Proof of Proposition 1. Let Xi denote the ith row vector of X. Then for any fixed u \u2208 Sp(k),\nEe\u03bb(X>i u) = \u220f\n1\u2264j\u2264p Ee\u03bbXijuj \u2264 \u220f j e\u03bb 2u2j/(2\u03c3 2n) = e\u03bb 2/(2\u03c32n).\nApply Lemma 9 to \u2016Xu\u201622\u2212 1 = n\u22121 \u2211n i=1 { ( \u221a nX>i u) 2\u2212E( \u221a nX>i u) 2 }\n, and use the fact that \u03b8/(8\u03c32) \u2264 1, we have\nP ( 1\u2212 \u03b8 \u2264 \u2016Xu\u201622 \u2264 1 + \u03b8 ) \u2265 1\u2212 2e\u2212n\u03b82/(64\u03c34).\nWe claim that there is a set N of cardinality at most ( p k ) 9k such that\nsup u\u2208Sp(k) \u2223\u2223\u2016Xu\u201622 \u2212 1\u2223\u2223 \u2264 2 sup u\u2208N \u2223\u2223\u2016Xu\u201622 \u2212 1\u2223\u2223 (7) Given (7), by union bound, we have\nP(X \u2208 RIP(k, \u03b8)) = P (\nsup u\u2208Sp(k) \u2223\u2223\u2016Xu\u201622 \u2212 1\u2223\u2223 \u2264 \u03b8) \u2265 P(sup u\u2208N \u2223\u2223\u2016Xu\u201622 \u2212 1\u2223\u2223 \u2264 \u03b8/2) \u2265 1\u2212 2 ( p\nk\n) 9ke\u2212n\u03b8 2/(256\u03c34) \u2265 1\u2212 2 exp { k log ( 9ep\nk\n) \u2212 n\u03b8 2\n256\u03c34\n} ,\nas desired. It remains to verify Claim (7). For any cardinality k subset J \u2286 {1, . . . , p}, let BJ = {u \u2208 Sp(k) : uJc = 0}. Each BJ contains a 1/4-net, NJ , of cardinality at most 9k (Vershynin, 2012, Lemma 5.2). Then N := \u222aJNJ form a 1/4-net for Sp(k). Define uJ \u2208 argmaxu\u2208BJ\u2016Xu\u2016\n2 and let vJ be an element in NJ closest in Euclidean distance to uJ . Define A := X >X \u2212 Ip. We have\n|u>JAuJ | \u2264 |v>J AvJ |+ |(uJ \u2212 vJ)>AvJ |+ |u>JA(uJ \u2212 vJ)| \u2264 max u\u2208NI |u>Au|2 + 1 2 |u>JAuJ |.\nHence sup\nu\u2208Sp(k) |u>Au| \u2264 2 max u\u2208N |u>Au|,\nwhich verifies the claim.\nProof of Proposition 2. By definition, \u2016X>X\u2212Ip\u2016op,k \u2264 \u03b8 is equivalent toX \u2208 RIPn,p(k, \u03b8). Moreover, by Proposition 1, X \u2208 RIPn,p(k, \u03b8) with probability converging to 1, under Q\u0303\u2297(n\u00d7p). The certifier hence satisfies the two desired properties.\nProof of Proposition 3. The proposed certifier is clearly polynomial time computable (it has time complexity O(n2p)). To verify that it is a certifier, we check that (i) \u03c8\u22121n (1) \u2286 RIPn,p(k, \u03b8) and (ii) limn\u2192\u221e Q\u0303 \u2297(n\u00d7p)(\u03c8\u22121n (1)) > 2/3.\nFor (i), on the event \u2016X>X \u2212 Ip\u2016\u221e \u2264 14\u03c32 \u221a log p n , for any index set T \u2208 {1, . . . , p} of\ncardinality k, we have \u2016X>\u2217TX\u2217T \u2212 Ik\u2016\u221e \u2264 14\u03c32 \u221a log p n , which implies that\n\u2016X>\u2217TX\u2217T \u2212 Ik\u2016op \u2264 14\u03c32k \u221a log p\nn \u2264 \u03b8\nFor (ii), let Yn \u223c \u03c72n. Using Lemma 9 and fact that for any A \u2208 Rp\u00d7p\n\u2016A\u2016\u221e = sup S\u2286{1,...,p},#S=2 \u2016ASS\u2016\u221e \u2264 sup S\u2286{1,...,p},#S=2 \u2016ASS\u2016op = \u2016A\u2016op,2\nwe get P { \u2016X>X \u2212 Ip\u2016\u221e \u2264 14\u03c32 \u221a log p\nn\n} \u2265 P { sup\nu\u2208Sp(2)\n\u2223\u2223\u2016Xu\u201622 \u2212 1\u2223\u2223 \u2264 14\u03c32\u221a log pn }\n\u2265 1\u2212 2 ( p\n2\n) 92 exp { \u2212 n\n64\u03c34 196\u03c34 log p n } \u2265 1\u2212 81p2 exp{\u22123 log p} \u2192 1.\nas desired.\nLemma 6. Let Z be a non-negative random variable and r \u2265 2, then\nE(Zr) \u2265 E(|Z \u2212 EZ|r)."}, {"heading": "In other words, centring a nonnegative random variable shrinks its second or higher absolute moments.", "text": "Proof. Let \u00b5 := E(Z) and define Y = Z \u2212 \u00b5. Let P denote the probability measure on R associated with random variable Y . Hence \u222b [\u2212\u00b5,\u221e) y dP (y) = 0. Without loss\nof generality, we may assume that Z is not a point mass. Then \u222b [\u2212\u00b5,0](\u2212y) dP (y) =\u222b\n(0,\u221e) y dP (y) = A for some A > 0. For any measureable function f : R \u2192 [0,\u221e), we may write\nA \u222b [\u2212\u00b5,\u221e) f(y) dP (y) = \u222b [\u2212\u00b5,0] (\u2212v) dP (v) \u222b (0,\u221e) f(u) dP (u) + \u222b (0,\u221e) u dP (u) \u222b [\u2212\u00b5,0] f(v)dP (v)\n= \u222b u\u2208(0,\u221e) \u222b v\u2208[\u2212\u00b5,0] ( u u\u2212 v f(v)\u2212 v u\u2212 v f(u) ) (u\u2212 v) dP (v) dP (u).\n(8)\nLet (U, V ) be a bivariate random vector having probability measure\n1 A (u\u2212 v)1(0,\u221e)(u)1[\u2212\u00b5,0](v) dP (u) dP (v)\non R2 (that this is a probability measure follows from substituting f(y) \u2261 1 in (8)). Then (8) can be rewritten as\nE { f(Y ) } = E\n{ U\nU \u2212 V f(V )\u2212 V U \u2212 V f(U)\n} .\nNow consider choosing f to be f1(y) = |y|r and f2(y) = (y+ b)r respectively in the above equation. Note that for u \u2208 (0,\u221e) and v \u2208 [\u2212\u00b5, 0] and r \u2265 2, we always have\nuf2(v)\u2212 vf2(u) \u2265 \u2212vf2(u) \u2265 \u2212v(u\u2212 v)r \u2265 (\u2212v)ru+ (\u2212v)ur \u2265 uf1(v)\u2212 vf1(u).\nTherefore,\nE(|Y |m) = E { U\nU \u2212 V f1(V )\u2212\nV\nU \u2212 V f1(U) } \u2264 E { U\nU \u2212 V f2(V )\u2212\nV\nU \u2212 V f2(U)\n} = E(|Y + b|m),\nas desired.\nLemma 7. Suppose X is a sub-Gaussian random variable with parameter \u03c3 and median \u03be. Let X+ = X | X \u2265 \u03be and X\u2212 = X | X < \u03be. Then X+ \u2212 EX+ and X\u2212 \u2212 EX\u2212 are both sub-Gaussian with parameters are most c\u03c3 for some absolute constant c.\nProof. By Vershynin (2012, Lemma 5.5), X is sub-Gaussian with parameter \u03c3 implies that (E|X|p)1/p \u2264 c1\u03c3 \u221a p for some absolute constant c1. Hence by Lemma 6, we have\nE (\u2223\u2223X+ \u2212 EX+\u2223\u2223p)1/p \u2264 (E\u2223\u2223X+\u2223\u2223p)1/p = 2(E\u2223\u2223X1{X \u2265 \u03be}\u2223\u2223p)1/p \u2264 2c1\u03c3\u221ap.\nUsing Vershynin (2012, Lemma 5.5) again, we have that X+ \u2212 EX+ is sub-Gaussian with parameter at most c\u03c3 for some absolute constant c. A similar argument holds for X\u2212 \u2212 EX\u2212.\nLemma 8. Suppose X is a random variable satisfying Ee\u03bbX \u2264 e\u03c32\u03bb2/2 for all \u03bb \u2208 R. Define Y = X2 \u2212 EX2. Then Ee\u03bbY \u2264 e16\u03c34\u03bb2 for all |\u03bb| \u2264 1\n4\u03c32 .\nProof. By Markov\u2019s inequality, P(|X| \u2265 t) = P(X \u2265 t)+P(\u2212X \u2265 t) = e\u2212t2/\u03c32E ( etX/\u03c3 2) +e\u2212t 2/\u03c32E ( e\u2212tX/\u03c3 2) \u2264 2e\u2212t2/(2\u03c32). From Lemma 6, for r \u2265 2\nE(|Y |r) \u2264 E(|X|2r) = \u222b \u221e 0 P(|X| \u2265 t)(2r)t2r\u22121 dt \u2264 \u222b \u221e 0 4rt2r\u22121e\u2212t 2/(2\u03c32) dt = 2(2\u03c32)r\u0393(r+1).\nConsequently, if |2\u03c32\u03bb| \u2264 1/2, then\nEe\u03bbY = \u221e\u2211 r=0 \u03bbrEY r r! \u2264 1 + 2 \u221e\u2211 r=2 (2\u03c32\u03bb)r \u2264 1 + 16\u03c34\u03bb2 \u2264 e16\u03c34\u03bb2 ,\nas desired.\nLemma 9. Let X1, X2, . . . , Xn be independent sub-Gaussian random variables with subGaussian parameters at most \u03c3. Let Yi := X 2 i \u2212 EX2i . Then\nP ( n\u2211 i=1 Yi \u2265 \u03b8 ) \u2264 exp { \u2212 ( \u03b82 64n\u03c34 \u2227 \u03b8 8\u03c32 )} P ( n\u2211 i=1 Yi \u2264 \u2212\u03b8 ) \u2264 exp { \u2212 \u03b8 2 64n\u03c34\n} Proof. Using Markov\u2019s inequality, we have\nP ( n\u2211 i=1 Yi \u2265 \u03b8 ) = P ( e\u03bb \u2211 i Yi \u2265 e\u03bb\u03b8 ) \u2264 e\u2212\u03bb\u03b8 \u220f i Ee\u03bbYi .\nSet \u03bb = \u03b8 32n\u03c34 \u2227 1 4\u03c32 . By Lemma 8, we have P ( n\u2211 i=1 Yi \u2265 \u03b8 ) \u2264 e\u2212\u03bb\u03b8+16\u03bb2n\u03c34 \u2264 e\u2212\u03bb\u03b8/2,\nwhich establishes the first desired inequality. Applying the same argument with \u2212Yi in place of Yi we get\nP ( n\u2211 i=1 Yi \u2264 \u2212\u03b8 ) \u2264 exp { \u2212 ( \u03b82 64n\u03c34 \u2227 \u03b8 8\u03c32 )} . (9)\nTaylor expand the moment generating function of Xi around 0, we have EX2i \u2264 \u03c32. Hence we may assume \u03b8 \u2264 n\u03c32. Then we have\n\u03b82\n64n\u03c34 <\n\u03b8\n8\u03c32 ,\nwhich together with (9) implies the desired result.\nLemma 10. Suppose n` balls are arranged in an array of n rows and ` columns and k balls (k < n) are chosen uniformly at random. Let Vi be the number of chosen balls in row i and V = (V1, . . . , Vn) >. Then\nP ( \u2016V \u20160 \u2264 k \u2212 k2 2n \u2212 \u221a k log k ) \u2264 1 k2 .\nMoreover, if k \u2264 n\u03b3 for some \u03b3 < 1, then P ( \u2016V \u2016\u221e \u2265 a ) \u2264 n1\u2212a(1\u2212\u03b3) ( 1\u2212 n\u2212(1\u2212\u03b3) ) .\nProof. Let Ui be the number of balls chosen in row i when balls are drawn with replacement from the array and U = (U1, . . . , Un)\n>. Then \u2016V \u20160 is stochastically larger than \u2016U\u20160 and \u2016V \u2016\u221e is stochastically smaller than \u2016U\u20160. So it suffices to show the desired inequalities with U replacing V . In the following argument, we consider only drawing with replacement.\nLet X = {e1, . . . , en} where ei denotes the ith standard basis vector in Rn. For 1 \u2264 r \u2264 k, let Xr be uniformly distributed in X . Then U d = \u2211k\nr=1Xr. We note that changing the value of any one Xr affects the value of \u2016U\u20160 by at most 1. By McDiarmid\u2019s inequality (McDiarmid, 1989), we have that for any t > 0,\nP ( \u2016U\u20160 \u2212 E\u2016U\u20160 \u2264 \u2212t ) \u2264 e\u2212 2t2 k . (10)\nFor 1 \u2264 i \u2264 n. Define Ji = 1{no ball is chosen in row i}, then\nE\u2016U\u20160 = n\u2212 n\u2211 i=1 EJi = n\u2212 n(1\u2212 1/n)k \u2265 k ( 1\u2212 k 2n ) .\nThus, together with (10), we have P ( \u2016U\u20160 \u2264 k \u2212 k2 2n \u2212 \u221a k log k ) \u2264 P ( \u2016U\u20160 \u2212 E\u2016U\u20160 \u2264 \u2212 \u221a k log k ) \u2264 e\u22122 log k = k\u22122,\nas desired. For the second inequality, we have by union bound that\nP(\u2016U\u2016\u221e \u2265 a) \u2264 nP(U1 \u2265 a) = n k\u2211 s=a ( k s ) n\u2212s\n\u2264 n \u221e\u2211 s=a (k/n)s = n (k/n)a 1\u2212 k/n \u2264 n1\u2212a(1\u2212\u03b3)(1\u2212 n\u2212(1\u2212\u03b3)),\nas desired."}], "references": [{"title": "Testing k-wise and almost k-wise independence", "author": ["N. Alon", "A. Andoni", "T. Kaufman", "K. Matulef", "R. Rubinfeld", "N. Xie"], "venue": "Proceedings of the Thirty-ninth ACM STOC", "citeRegEx": "Alon et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Alon et al\\.", "year": 2007}, {"title": "Label optimal regret bounds for online local learning", "author": ["P. Awasthi", "M. Charikar", "K.A. Lai", "A. Risteki"], "venue": "J. Mach. Learn. Res. (COLT),", "citeRegEx": "Awasthi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Awasthi et al\\.", "year": 2015}, {"title": "Certifying the restricted isometry property is hard", "author": ["A.S. Bandeira", "E. Dobriban", "D.G. Mixon", "W.F. Sawin"], "venue": "IEEE Trans. Information Theory,", "citeRegEx": "Bandeira et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bandeira et al\\.", "year": 2012}, {"title": "A conditional construction of restricted isometries", "author": ["A.S. Bandeira", "D.G. Mixon", "J. Moreira"], "venue": null, "citeRegEx": "Bandeira et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bandeira et al\\.", "year": 2014}, {"title": "A simple proof of the restricted isometry property for random matrices", "author": ["R. Baraniuk", "M. Davenport", "R. DeVore", "M. Wakin"], "venue": "Constructive Approximation,", "citeRegEx": "Baraniuk et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Baraniuk et al\\.", "year": 2008}, {"title": "Detection of Planted Solutions for Flat Satisfiability Problems", "author": ["Q. Berthet", "J.S. Ellenberg"], "venue": null, "citeRegEx": "Berthet and Ellenberg,? \\Q2015\\E", "shortCiteRegEx": "Berthet and Ellenberg", "year": 2015}, {"title": "Optimal detection of sparse principal components in high dimension", "author": ["Q. Berthet", "Rigollet P"], "venue": "Ann. Statist.,", "citeRegEx": "Berthet and P.,? \\Q2013\\E", "shortCiteRegEx": "Berthet and P.", "year": 2013}, {"title": "Complexity theoretic lower bounds for sparse principal component detection", "author": ["Q. Berthet", "Rigollet P"], "venue": "J. Mach. Learn. Res. (COLT),", "citeRegEx": "Berthet and P.,? \\Q2013\\E", "shortCiteRegEx": "Berthet and P.", "year": 2013}, {"title": "Detecting High Log-Densities an O(n) Approximation for Densest k-Subgraph", "author": ["A. Bhaskara", "M. Charikar", "E. Chlamtac", "U. Feige", "A. Vijayaraghavan"], "venue": "Proceedings of the forty-second ACM symposium on Theory of computing,", "citeRegEx": "Bhaskara et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bhaskara et al\\.", "year": 2010}, {"title": "Noise-tolerant learning, the parity problem, and the statistical query model", "author": ["A. Blum", "A. Kalai", "H. Wasserman"], "venue": "Journal of the ACM,", "citeRegEx": "Blum et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2003}, {"title": "Iterative hard thresholding for compressed sensing", "author": ["T. Blumensath", "M.E. Davies"], "venue": "Applied and Computational Harmonic Analysis,", "citeRegEx": "Blumensath and Davies,? \\Q2009\\E", "shortCiteRegEx": "Blumensath and Davies", "year": 2009}, {"title": "Explicit constructions of RIP matrices and related problems", "author": ["J. Bourgain", "S. Dilworth", "K. Ford", "S. Konyagin"], "venue": "Duke Math. J.,", "citeRegEx": "Bourgain et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bourgain et al\\.", "year": 2011}, {"title": "The restricted isometry property and its implications for compressed sensing", "author": ["E.J. Cand\u00e8s"], "venue": "Comptes Rendus Mathematique,", "citeRegEx": "Cand\u00e8s,? \\Q2008\\E", "shortCiteRegEx": "Cand\u00e8s", "year": 2008}, {"title": "Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information", "author": ["E.J. Cand\u00e8s", "J. Romberg", "T. Tao"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2006}, {"title": "Stable signal recovery from incomplete and inaccurate measurements", "author": ["E.J. Cand\u00e8s", "J.K. Romberg", "T. Tao"], "venue": "Communications on pure and applied mathematics,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2006}, {"title": "Decoding by Linear Programming", "author": ["Cand\u00e8s E. J", "T. Tao"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "J. and Tao,? \\Q2005\\E", "shortCiteRegEx": "J. and Tao", "year": 2005}, {"title": "Near-optimal signal recovery from random projections: Universal encoding strategies", "author": ["Cand\u00e8s E. J", "T. Tao"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "J. and Tao,? \\Q2005\\E", "shortCiteRegEx": "J. and Tao", "year": 2005}, {"title": "Statistical-computational tradeoffs in planted problems and submatrix localization with a growing number of clusters and submatrices", "author": ["Y. Chen", "J. Xu"], "venue": null, "citeRegEx": "Chen and Xu,? \\Q2014\\E", "shortCiteRegEx": "Chen and Xu", "year": 2014}, {"title": "Optimal solutions for sparse principal component analysis", "author": ["A. d\u2019Aspremont", "F. Bach", "L. El Ghaoui"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "d.Aspremont et al\\.,? \\Q2008\\E", "shortCiteRegEx": "d.Aspremont et al\\.", "year": 2008}, {"title": "Testing the nullspace property using semidefinite programming", "author": ["A. d\u2019Aspremont", "L. El Ghaoui"], "venue": "Mathematical programming,", "citeRegEx": "d.Aspremont and Ghaoui,? \\Q2011\\E", "shortCiteRegEx": "d.Aspremont and Ghaoui", "year": 2011}, {"title": "Subspace pursuit for compressive sensing signal reconstruction", "author": ["W. Dai", "O. Milenkovic"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "Dai and Milenkovic,? \\Q2009\\E", "shortCiteRegEx": "Dai and Milenkovic", "year": 2009}, {"title": "Compressed sensing", "author": ["D.L. Donoho"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "Donoho,? \\Q2006\\E", "shortCiteRegEx": "Donoho", "year": 2006}, {"title": "mally sparse representation in general (nonorthogonal) dictionaries via `1 minimization", "author": ["D.L. Donoho", "M. Elad"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Donoho and Elad,? \\Q2003\\E", "shortCiteRegEx": "Donoho and Elad", "year": 2003}, {"title": "Stable recovery of sparse overcomplete representations in the presence of noise", "author": ["D.L. Donoho", "M. Elad", "V.N. Temlyakov"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "Donoho et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Donoho et al\\.", "year": 2006}, {"title": "Compressed Sensing: Theory and Applications", "author": ["Y.C. Eldar", "G. Kutyniok"], "venue": null, "citeRegEx": "Eldar and Kutyniok,? \\Q2012\\E", "shortCiteRegEx": "Eldar and Kutyniok", "year": 2012}, {"title": "The probable value of the Lov\u00e0sz\u2013Schrijver relaxations for a maximum independent set", "author": ["U. Feige", "R. Krauthgamer"], "venue": "SIAM J. Comput.,", "citeRegEx": "Feige and Krauthgamer,? \\Q2003\\E", "shortCiteRegEx": "Feige and Krauthgamer", "year": 2003}, {"title": "Statistical Algorithms and a Lower Bound for Detecting Planted Cliques", "author": ["V. Feldman", "E. Grigorescu", "L. Reyzin", "S.S. Vempala", "Y. Xiao"], "venue": "Proceedings of the Fortyfifth Annual ACM Symposium on Theory of Computing", "citeRegEx": "Feldman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2013}, {"title": "On the complexity of random satisfiability problems with planted solutions", "author": ["V. Feldman", "W. Perkins", "S. Vempala"], "venue": "Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing,", "citeRegEx": "Feldman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2013}, {"title": "Sparse CCA: adaptive estimation and computational barriers", "author": ["C. Gao", "Z. Ma", "H.H. Zhou"], "venue": null, "citeRegEx": "Gao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gao et al\\.", "year": 2014}, {"title": "Computational Lower Bounds for Community Detection on Random Graphs", "author": ["B. Hajek", "Y. Wu", "Xu"], "venue": "Proceedings of The 28th Conference on Learning", "citeRegEx": "Hajek et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hajek et al\\.", "year": 2015}, {"title": "How hard is it to approximate the best nash equilibrium", "author": ["E. Hazan", "R. Krauthgamer"], "venue": "SIAM J. Comput.,", "citeRegEx": "Hazan and Krauthgamer,? \\Q2011\\E", "shortCiteRegEx": "Hazan and Krauthgamer", "year": 2011}, {"title": "Large cliques elude the Metropolis process", "author": ["M. Jerrum"], "venue": "Random Struct. Algor.,", "citeRegEx": "Jerrum,? \\Q1992\\E", "shortCiteRegEx": "Jerrum", "year": 1992}, {"title": "On verifiable sufficient conditions for sparse signal recovery via `1 minimization", "author": ["A. Juditsky", "A. Nemirovski"], "venue": "Mathematical programming,", "citeRegEx": "Juditsky and Nemirovski,? \\Q2011\\E", "shortCiteRegEx": "Juditsky and Nemirovski", "year": 2011}, {"title": "Hiding cliques for cryptographic security", "author": ["A. Juels", "M. Peinado"], "venue": "Des. Codes Cryptography", "citeRegEx": "Juels and Peinado,? \\Q2000\\E", "shortCiteRegEx": "Juels and Peinado", "year": 2000}, {"title": "Hidden cliques and the certification of the restricted isometry property", "author": ["P. Koiran", "A. Zouzias"], "venue": null, "citeRegEx": "Koiran and Zouzias,? \\Q2012\\E", "shortCiteRegEx": "Koiran and Zouzias", "year": 2012}, {"title": "Computing performance guarantees for compressed sensing", "author": ["K. Lee", "Y. Bresler"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "Lee and Bresler,? \\Q2008\\E", "shortCiteRegEx": "Lee and Bresler", "year": 2008}, {"title": "Computational barriers in minimax submatrix detection", "author": ["Z. Ma", "Y. Wu"], "venue": null, "citeRegEx": "Ma and Wu,? \\Q2013\\E", "shortCiteRegEx": "Ma and Wu", "year": 2013}, {"title": "A wavelet tour of signal processing", "author": ["S. Mallat"], "venue": null, "citeRegEx": "Mallat,? \\Q1999\\E", "shortCiteRegEx": "Mallat", "year": 1999}, {"title": "On the method of bounded differences", "author": ["C. McDiarmid"], "venue": "Surveys in Combinatorics,", "citeRegEx": "McDiarmid,? \\Q1989\\E", "shortCiteRegEx": "McDiarmid", "year": 1989}, {"title": "CoSaMP: Iterative signal recovery from incomplete and inaccurate samples", "author": ["D. Needell", "J.A. Tropp"], "venue": "Applied and Computational Harmonic Analysis,", "citeRegEx": "Needell and Tropp,? \\Q2009\\E", "shortCiteRegEx": "Needell and Tropp", "year": 2009}, {"title": "A Mathematical Introduction to Compressive Sensing. Birkh\u00e4user", "author": ["H. Rauhut", "S. Foucart"], "venue": null, "citeRegEx": "Rauhut and Foucart,? \\Q2013\\E", "shortCiteRegEx": "Rauhut and Foucart", "year": 2013}, {"title": "The computational complexity of the restricted isometry property, the nullspace property, and related concepts in compressed sensing", "author": ["A.N. Tillmann", "Pfetsch M. E"], "venue": "IEEE Trans. Inform. Theory,", "citeRegEx": "Tillmann and E.,? \\Q2014\\E", "shortCiteRegEx": "Tillmann and E.", "year": 2014}, {"title": "Introduction to the non-asymptotic analysis of random matrices", "author": ["R. Vershynin"], "venue": null, "citeRegEx": "Vershynin,? \\Q2012\\E", "shortCiteRegEx": "Vershynin", "year": 2012}, {"title": "Statistical and computational tradeoffs in Estimation of Sparse Pincipal Components", "author": ["T. Wang", "Q. Berthet", "R.J. Samworth"], "venue": "Ann. Statist.,", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Lower bounds on the performance of polynomial-time algorithms for sparse linear regression", "author": ["Y. Zhang", "M.J. Wainwright", "M.I. Jordan"], "venue": "JMLR: Workshop and Conference Proceedings (COLT),", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 40, "context": "Sparsity is a structure of wide applicability (see, e.g. Mallat, 1999; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012), with a broad literature dedicated to its study in various scientific fields.", "startOffset": 46, "endOffset": 122}, {"referenceID": 24, "context": "Sparsity is a structure of wide applicability (see, e.g. Mallat, 1999; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012), with a broad literature dedicated to its study in various scientific fields.", "startOffset": 46, "endOffset": 122}, {"referenceID": 22, "context": "For an incoherent design matrix, it is known that an order of k observations suffice (Donoho, Elad and Temlyakov, 2006; Donoho and Elad, 2003).", "startOffset": 85, "endOffset": 142}, {"referenceID": 10, "context": "It is a highly robust property, and in fact implies that many different polynomial time methods, such as greedy methods (Blumensath and Davies, 2009; Needell and Tropp, 2009; Dai and Milenkovic, 2009) and convex optimization (Cand\u00e8s, 2008; Cand\u00e8s, Romberg and Tao, 2006b; Cand\u00e8s and Tao, 2005, 2006), are stable in recovering \u03b2.", "startOffset": 120, "endOffset": 200}, {"referenceID": 39, "context": "It is a highly robust property, and in fact implies that many different polynomial time methods, such as greedy methods (Blumensath and Davies, 2009; Needell and Tropp, 2009; Dai and Milenkovic, 2009) and convex optimization (Cand\u00e8s, 2008; Cand\u00e8s, Romberg and Tao, 2006b; Cand\u00e8s and Tao, 2005, 2006), are stable in recovering \u03b2.", "startOffset": 120, "endOffset": 200}, {"referenceID": 20, "context": "It is a highly robust property, and in fact implies that many different polynomial time methods, such as greedy methods (Blumensath and Davies, 2009; Needell and Tropp, 2009; Dai and Milenkovic, 2009) and convex optimization (Cand\u00e8s, 2008; Cand\u00e8s, Romberg and Tao, 2006b; Cand\u00e8s and Tao, 2005, 2006), are stable in recovering \u03b2.", "startOffset": 120, "endOffset": 200}, {"referenceID": 12, "context": "It is a highly robust property, and in fact implies that many different polynomial time methods, such as greedy methods (Blumensath and Davies, 2009; Needell and Tropp, 2009; Dai and Milenkovic, 2009) and convex optimization (Cand\u00e8s, 2008; Cand\u00e8s, Romberg and Tao, 2006b; Cand\u00e8s and Tao, 2005, 2006), are stable in recovering \u03b2.", "startOffset": 225, "endOffset": 299}, {"referenceID": 21, "context": "These results were developed in the field of compressed sensing (Cand\u00e8s, Romberg and Tao, 2006a; Donoho, 2006; Cand\u00e8s and Tao, 2006; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012) where the use of randomness still remains pivotal for near-optimal results.", "startOffset": 64, "endOffset": 184}, {"referenceID": 40, "context": "These results were developed in the field of compressed sensing (Cand\u00e8s, Romberg and Tao, 2006a; Donoho, 2006; Cand\u00e8s and Tao, 2006; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012) where the use of randomness still remains pivotal for near-optimal results.", "startOffset": 64, "endOffset": 184}, {"referenceID": 24, "context": "These results were developed in the field of compressed sensing (Cand\u00e8s, Romberg and Tao, 2006a; Donoho, 2006; Cand\u00e8s and Tao, 2006; Rauhut and Foucart, 2013; Eldar and Kutyniok, 2012) where the use of randomness still remains pivotal for near-optimal results.", "startOffset": 64, "endOffset": 184}, {"referenceID": 2, "context": "Moreover, it is in general practically impossible to check that a given matrix satisfies these desired properties, as RIP certification is NP-hard (Bandeira et al., 2012).", "startOffset": 147, "endOffset": 170}, {"referenceID": 35, "context": "The search for such statistics has been of great importance for over a decade now, and several have been proposed (d\u2019Aspremont and El Ghaoui, 2011; Lee and Bresler, 2008; Juditsky and Nemirovski, 2011; d\u2019Aspremont, Bach and El Ghaoui, 2008).", "startOffset": 114, "endOffset": 240}, {"referenceID": 32, "context": "The search for such statistics has been of great importance for over a decade now, and several have been proposed (d\u2019Aspremont and El Ghaoui, 2011; Lee and Bresler, 2008; Juditsky and Nemirovski, 2011; d\u2019Aspremont, Bach and El Ghaoui, 2008).", "startOffset": 114, "endOffset": 240}, {"referenceID": 34, "context": "Our problem is conceptually different from results regarding the worst-case hardness of certifying this property (see, e.g. Bandeira et al., 2012; Koiran and Zouzias, 2012; Tillmann and Pfetsch, 2014).", "startOffset": 113, "endOffset": 200}, {"referenceID": 36, "context": "The planted clique assumption has been used to prove computational hardness results for statistical problems such as estimation and testing of sparse principal components (Berthet and Rigollet, 2013a,b; Wang, Berthet and Samworth, 2016), testing and localization of submatrix signals (Ma and Wu, 2013; Chen and Xu, 2014), community", "startOffset": 284, "endOffset": 320}, {"referenceID": 17, "context": "The planted clique assumption has been used to prove computational hardness results for statistical problems such as estimation and testing of sparse principal components (Berthet and Rigollet, 2013a,b; Wang, Berthet and Samworth, 2016), testing and localization of submatrix signals (Ma and Wu, 2013; Chen and Xu, 2014), community", "startOffset": 284, "endOffset": 320}, {"referenceID": 5, "context": "The intractability of noisy parity recovery problem (Blum, Kalai and Wasserman, 2003) has also been used recently as an average-case assumption to deduce computational hardness of detection of satisfiability formulas with lightly planted solutions (Berthet and Ellenberg, 2015).", "startOffset": 248, "endOffset": 277}, {"referenceID": 26, "context": "Additionally, several unconditional computational hardness results are shown for statistical problems under constraints of learning models (Feldman et al., 2013; Feldman, Perkins and Vempala, 2013).", "startOffset": 139, "endOffset": 197}, {"referenceID": 8, "context": "This does not mean that the planted graph is a random graph with edge probability q > 1/2 as considered in (Arias-Castro and Verzelen, 2013; Bhaskara et al., 2010; Awasthi et al., 2015), but that it can be any graph with an unexpectedly high number of edges (see section 3.", "startOffset": 107, "endOffset": 185}, {"referenceID": 1, "context": "This does not mean that the planted graph is a random graph with edge probability q > 1/2 as considered in (Arias-Castro and Verzelen, 2013; Bhaskara et al., 2010; Awasthi et al., 2015), but that it can be any graph with an unexpectedly high number of edges (see section 3.", "startOffset": 107, "endOffset": 185}, {"referenceID": 12, "context": "1 Formulation We use the definition of Cand\u00e8s and Tao (2005), who introduced this notion.", "startOffset": 39, "endOffset": 61}, {"referenceID": 2, "context": "g Bandeira et al., 2012). Several deterministic constructions of RIP matrices exist for sparsity level k . \u03b8 \u221a n. For example, using equitriangular tight frames and Gershgorin\u2019s circle theorem, one can construct RIP matrices with sparsity k \u2264 \u221a n and distortion \u03b8 bounded away from 0 (see, e.g. Bandeira et al., 2012). The limitation k \u2264 \u03b8 \u221a n is known as the \u2018square root bottleneck\u2019. To date, the only constructions that break the \u2018square root bottleneck\u2019 are due to Bourgain et al. (2011) and Bandeira, Mixon and Moreira (2014), both of which give RIP guarantee for k of order n for some small > 0 and fixed \u03b8 (the latter construction is conditional on a number-theoretic conjecture being true).", "startOffset": 2, "endOffset": 492}, {"referenceID": 2, "context": "g Bandeira et al., 2012). Several deterministic constructions of RIP matrices exist for sparsity level k . \u03b8 \u221a n. For example, using equitriangular tight frames and Gershgorin\u2019s circle theorem, one can construct RIP matrices with sparsity k \u2264 \u221a n and distortion \u03b8 bounded away from 0 (see, e.g. Bandeira et al., 2012). The limitation k \u2264 \u03b8 \u221a n is known as the \u2018square root bottleneck\u2019. To date, the only constructions that break the \u2018square root bottleneck\u2019 are due to Bourgain et al. (2011) and Bandeira, Mixon and Moreira (2014), both of which give RIP guarantee for k of order n for some small > 0 and fixed \u03b8 (the latter construction is conditional on a number-theoretic conjecture being true).", "startOffset": 2, "endOffset": 531}, {"referenceID": 11, "context": "Cand\u00e8s and Tao (2005) and Baraniuk et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 4, "context": "Cand\u00e8s and Tao (2005) and Baraniuk et al. (2008)).", "startOffset": 26, "endOffset": 49}, {"referenceID": 2, "context": "It is known that the problem of deciding if a given matrix is RIP is NP-hard (Bandeira et al., 2012).", "startOffset": 77, "endOffset": 100}, {"referenceID": 28, "context": "Jerrum (1992); Feige and Krauthgamer (2003); Feldman et al.", "startOffset": 0, "endOffset": 14}, {"referenceID": 25, "context": "Jerrum (1992); Feige and Krauthgamer (2003); Feldman et al.", "startOffset": 15, "endOffset": 44}, {"referenceID": 25, "context": "Jerrum (1992); Feige and Krauthgamer (2003); Feldman et al. (2013)).", "startOffset": 15, "endOffset": 67}, {"referenceID": 29, "context": "Jerrum (1992) and references in Berthet and Rigollet (2013a,b)).", "startOffset": 0, "endOffset": 14}, {"referenceID": 29, "context": "Jerrum (1992) and references in Berthet and Rigollet (2013a,b)). The difficulty of this problem has been used as a primitive for hardness of other tasks, such as cryptographic applications, in Juels and Peinado (2000), testing for kwise dependence in Alon et al.", "startOffset": 0, "endOffset": 218}, {"referenceID": 0, "context": "The difficulty of this problem has been used as a primitive for hardness of other tasks, such as cryptographic applications, in Juels and Peinado (2000), testing for kwise dependence in Alon et al. (2007), approximating Nash equilibria in Hazan and Krauthgamer (2011).", "startOffset": 186, "endOffset": 205}, {"referenceID": 0, "context": "The difficulty of this problem has been used as a primitive for hardness of other tasks, such as cryptographic applications, in Juels and Peinado (2000), testing for kwise dependence in Alon et al. (2007), approximating Nash equilibria in Hazan and Krauthgamer (2011). In this case, Assumption (A1) is a version of the planted clique hypothesis (see, e.", "startOffset": 186, "endOffset": 268}, {"referenceID": 36, "context": "More precisely, using an averaging trick first seen in Ma and Wu (2013), we are able to show that the existence of such \u2018hard\u2019 sequences is not confined only in the sparsity regime k n .", "startOffset": 55, "endOffset": 72}, {"referenceID": 38, "context": "By McDiarmid\u2019s inequality (McDiarmid, 1989), we have that for any t > 0,", "startOffset": 26, "endOffset": 43}], "year": 2016, "abstractText": "The restricted isometry property (RIP) for design matrices gives guarantees for optimal recovery in sparse linear models. It is of high interest in compressed sensing and statistical learning. This property is particularly important for computationally efficient recovery methods. As a consequence, even though it is in general NP-hard to check that RIP holds, there have been substantial efforts to find tractable proxies for it. These would allow the construction of RIP matrices and the polynomial-time verification of RIP given an arbitrary matrix. We consider the framework of average-case certifiers, that never wrongly declare that a matrix is RIP, while being often correct for random instances. While there are such functions which are tractable in a suboptimal parameter regime, we show that this is a computationally hard task in any better regime. Our results are based on a new, weaker assumption on the problem of detecting dense subgraphs.", "creator": "LaTeX with hyperref package"}}}