{"id": "1606.03474", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2016", "title": "On degeneracy control in overcomplete ICA", "abstract": "Understanding the effects of degeneracy control mechanisms when learning overcomplete representations is crucial for applying Independent Components Analysis (ICA) in machine learning and theoretical neuroscience. A number of approaches to degeneracy control have been proposed which can learn non-degenerate complete representations, however some of these methods can fall into bad local minima when extended to overcomplete ICA. Furthermore, they may have unintended side-effects on the distribution of learned basis elements, which may lead to a biased exploration of the data manifold. In this work, we identify and theoretically analyze the cause of these failures and propose a framework that can be used to evaluate arbitrary degeneracy control mechanisms. We evaluate different methods for degeneracy control in overcomplete ICA and suggest two novel approaches, one of which can learn highly orthonormal bases. Finally, we compare all methods on the task of estimating an overcomplete basis on natural images.", "histories": [["v1", "Fri, 10 Jun 2016 20:34:54 GMT  (1785kb,D)", "https://arxiv.org/abs/1606.03474v1", "9 pages, 4 figures, under review at NIPS 2016"], ["v2", "Sat, 25 Jun 2016 00:21:47 GMT  (1214kb,D)", "http://arxiv.org/abs/1606.03474v2", "12 pages, 4 figures, under review at NIPS 2016"]], "COMMENTS": "9 pages, 4 figures, under review at NIPS 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jesse a livezey", "alejandro f bujan", "friedrich t sommer"], "accepted": false, "id": "1606.03474"}, "pdf": {"name": "1606.03474.pdf", "metadata": {"source": "CRF", "title": "On degeneracy control in overcomplete ICA", "authors": ["Jesse A. Livezey", "Alejandro F. Bujan"], "emails": ["jesse.livezey@berkeley.edu", "afbujan@berkeley.edu", "fsommer@berkeley.edu"], "sections": [{"heading": "1 Introduction", "text": "Independent Components Analysis (ICA) is a technique for learning the underlying non-Gaussian and mutually independent sources S in a dataset X (Comon, 1994; Bell and Sejnowski, 1997). ICA is formulated as a linear generative model:\nX = AS, (1)\nwhere A is usually referred to as the mixing matrix. In the complete case, the reconstruction of the original sources is possible as the mixing matrix can be inverted. The goal of ICA is then to find the unmixing matrix W such that the sources can be recovered, S = WX with W = A\u22121. The unmixing matrix W can be obtained by solving the following constrained optimization problem:\nargmin W\n\u2211m i=1 \u2211k j=1 g(Wjx (i))\ns.t. WWT = I (2)\nwhere g(\u00b7) is termed the contrast function and is usually a softer version of the L1 norm like the log(cosh(\u00b7)). The constraint WWT = I prevents the bases from becoming degenerate (Hyv\u00e4rinen and Oja, 1997).\nar X\niv :1\n60 6.\n03 47\n4v 2\n[ cs\n.L G\nThis constrained optimization can be relaxed into an unconstrained one by adding a new cost C to the objective function (Le et al., 2011). This cost should then play the role of the constraint, preventing the co-alignment of the bases. The new unconstrained optimization problem becomes:\nargmin W C(W ) + \u03bb m\u2211 i=1 k\u2211 j=1 g(Wjx (i)). (3)\nIn addition to its use in machine learning, e.g. blind source separation, ICA learns filters which are similar to neuronal receptive fields found in early stages of visual cortex (V1), which gives insight into the connections between natural scene statistics and sensory learning in the brain.\nOvercomplete versions of sparse coding and ICA (Lewicki and Olshausen, 1999; Hyv\u00e4rinen, 2005; Le et al., 2011) have been proposed. Overcomplete representations have been used to improve classification (Hinton et al., 2006; Bengio et al., 2007; Coates et al., 2011) and learn more diverse features (Rehn and Sommer, 2007; Olshausen, 2013). ICA, as an alternative to sparse coding, has the advantage that the inference process is a linear transformation versus a maximum a posteriori (MAP) estimation or posterior estimation which often require computationally expensive methods. Overcomplete ICA lacks a natural mechanism for explaining-away between bases, which arises naturally during inference in sparse coding. Degeneracy control represents a way to incorporate an explaining-away-like effect into overcomplete ICA.\nIn overcomplete ICA, orthonormality can no longer be enforced for all bases, therefore some other form of degeneracy control (Hyv\u00e4rinen et al., 1999) is needed to prevent bases from learning identical features, i.e. the angles between all pairs of bases should be pushed away from zero. Different methods for degeneracy control have been proposed: a quasi-orthogonality constraint (Hyv\u00e4rinen et al., 1999), a reconstruction cost (referred to as L2 cost here) (Le et al., 2011), and a random prior cost (Hyv\u00e4rinen and Inki, 2002) (see Methods for more details). However, a systematic analysis of the properties of these methods is still missing.\nHere, we show that while theL2 cost has the correct behavior for a complete basis, in the overcomplete case, there are local minina which allow pairs of basis vectors to become arbitrarily close to each other. We introduce a theoretical framework for evaluating different degeneracy control costs, and propose two new costs, which we compare with previously proposed methods. Our first novel approach is the L4 cost on the difference between the identity matrix and the Gram matrix of the bases. The second method is a cost which we term the Coulomb cost because it is derived from the physics problem of the electrostatic repulsion between charged particles on the surface of a hyper-sphere.\nIn addition to preventing degeneracy, we show that these costs will influence the distribution of an overcomplete set of bases in the high dimensional space. We provide analytic and numerical methods for evaluating potential degeneracy controls and investigate their effect on the distribution of pairwise angles between bases. In this work, we apply this framework to the two novel methods as well as other methods from the literature. Finally, we evaluate the diversity of bases learned on natural images using different non-degeneracy costs."}, {"heading": "2 Methods", "text": ""}, {"heading": "2.1 Non-degeneracy constraints and costs", "text": "Here, we briefly describe previous methods for degeneracy control in overcomplete ICA."}, {"heading": "2.1.1 Quasi-orthogonality constraint", "text": "Hyv\u00e4rinen et al. (1999) suggest a quasi-orthogonality update which approximates a symmetric GramSchmidt orthogonalization scheme for an overcomplete basis W and can be formulated as follows:\nW \u2190 3 2 W \u2212 1 2 WWTW. (4)"}, {"heading": "2.1.2 Reconstruction cost and the L2 cost", "text": "Le et al. (2011) propose adding a reconstruction cost to the ICA prior (RICA) as a form of degeneracy control, which they show is equivalent to a cost on the L2 norm of the difference between the Gram\nmatrix of the filters and an identity matrix for whitened data\nCRICA = 1\nN \u2211 ij (X (i) j \u2212 \u2211 kl WkjWklX (i) l ) 2 \u221d CL2 = \u2211 ij (\u03b4ij\u2212 \u2211 k WikWjk) 2 = \u2211 ij (\u03b4ij\u2212cos \u03b8ij)2,\n(5) where Wij is the component of the ith source for the jth mixture , Xij is the jth element of the ith sample, \u03b8 is the angle between pairs of basis, and \u03b4ij is the Kronecker delta."}, {"heading": "2.1.3 Random prior cost", "text": "Hyv\u00e4rinen and Inki (2002) use a prior on the distribution of pairwise angles to encourage quasiorthonormality and non-degeneracy. The prior is derived from assuming that the distribution of pairwise angles for all basis vectors is the same as the distribution of pairwise angles for just two vectors2.\nCRandom prior = \u2212 logP (cos \u03b8ij) \u221d \u2212 \u2211 i 6=j log(1\u2212 cos2 \u03b8ij) (6)"}, {"heading": "2.2 Model implementation", "text": "All models were implemented in Theano (Theano Development Team, 2016) and trained using L-BFGS-B (Byrd et al., 1995) and the norm-ball projection (Le et al., 2011) to keep the bases normalized. A repository with code to reproduce the results will be posted online."}, {"heading": "2.3 Fitting Gabor parameters", "text": "We fit the Gabor parameters (Ringach, 2002) to the learned bases using an iterative grid-search and optimization scheme which gave the best results on generated filters. The learned parameters were the center vector, planar-rotation angle \u03c6, phase, frequency, and envelope variances parallel and perpendicular to the oscillations. The outline of the procedure is listed in the supplement."}, {"heading": "3 Theoretical results and novel costs", "text": "Non-degeneracy costs will influence the distribution of an overcomplete set of bases in the high dimensional space. The properties of a cost can be investigated theoretically by evaluating its behavior as a function of the pairwise angles between bases which are either nearly orthogonal or nearly parallel (| cos \u03b8| \u223c 0 or 1 respectively). In order to isolate the effects of the degeneracy costs, we ignore the data-dependent ICA prior on the sources for the theoretical analysis."}, {"heading": "3.1 Pathological degeneracy in the L2 cost", "text": "For the L2 cost (Le et al., 2011), it can be shown that in the overcomplete case there exists a set of degenerate solutions in which the angle between pairs of bases becomes exactly zero. This is illustrated with a two dimensional, two times overcomplete example in figure 1. It can be shown that in this example, there are pathological minima, figure 1 (a), which can be continuously rotated into other \u201cgood\u201d minima with no parallel bases, figure 1 (b). These solutions are equivalent in terms of the value of the cost, lie on a connected family of solutions, and yet one is degenerate.\nIn order to understand these minima, we evaluate the structure of the cost in the two dimensional example analytically. The global rotational symmetry of the cost allows us to parameterize all solutions with respect to one fixed basis element, x\u0302, without loss of generality. The bases, shown in figure 1, are: (\n1 0\n) , ( cos \u03b81 sin \u03b81 ) , ( cos \u03b82 sin \u03b82 ) , ( cos \u03b82 + \u03b83 sin \u03b82 + \u03b83 ) . (7)\nSetting \u03b81 and \u03b83 to \u03c0/2, i.e. creating two orthonormal bases, forms a ring of local minima as \u03b82 is varied. This can be shown by computing the derivative of the cost and evaluating the eigenvalues of\n2For both the random prior and the Coulomb cost (section 3.3), we regularize the costs and their derivatives near | cos \u03b8| = 1 by adding a small positive constant in the objective, i.e. 1\u2212 cos \u03b82ij \u2192 1 + | | \u2212 cos \u03b82ij .\nthe Hessian of the cost at these points.\nCL2(\u03b81, \u03b82, \u03b83)|\u03b81,\u03b83=\u03c02 = 4\n\u2202CL2(\u03b81, \u03b82, \u03b83)\n\u2202~\u03b8 | \u03b81,\u03b83= \u03c0 2 = (0 0 0)\nEig.(HL2)|\u03b81,\u03b83=\u03c02 =  08 sin2 \u03b82 8 cos2 \u03b82  (8)\nThe first derivative is zero everywhere along this path, which shows that it is critical point. The first eigenvalue of the Hessian, 0, corresponds to moving in the \u03b82 direction (see Supplement for details), which has no effect on the cost. The second two eigenvalues will be positive as long as \u03b82 is not n\u03c0 or (n+ 12 )\u03c0 respectively. At the points where they are zero, the second derivatives vanish, but inspection of the cost along these axes show that they will be locally stable as the fourth derivative is positive.\nAs we show empirically in section 4.1, equivalent degenerate minima also exist in high dimensional overcomplete bases for the L2 cost. The simplest examples are subsets of N orthonormal bases in an multiple of N times overcomplete basis. Although these minima exist in high dimensions, it is unclear whether all local minima are of this type. We found that all local minima discovered from random initialization and numerical optimization have the same value of the cost as the degenerate solutions (data not shown).\nOur numerical results, section 4.1, suggest that these pathological solutions are also present in the quasi-orthonormality constraint (Hyv\u00e4rinen et al., 1999). In summary, we find that several proposed degeneracy control methods do not perform well in the overcomplete case which implies that there is a need for new forms of degeneracy control."}, {"heading": "3.2 The L4 cost as degeneracy control", "text": "We propose a novel degeneracy control cost termed the L4 cost, which transforms the degenerate minima into saddle points.\nCL4 = \u2211 ij (\u03b4ij \u2212 \u2211 k WikWjk) 4 = \u2211 ij (\u03b4ij \u2212 cos \u03b8ij)4 (9)\nFollowing the same analysis as section 3.1, we show that the degenerate solutions are either reduced to saddle points at \u03b82 = n\u03c02 or local minima at \u03b82 = (2n+ 1) \u03c0 4 , which correspond to good solutions.\nCL4(\u03b81, \u03b82, \u03b83)|\u03b81,\u03b83=\u03c02 = 3 + cos 4\u03b82\n\u2202CL4(\u03b81, \u03b82, \u03b83)\n\u2202~\u03b8 | \u03b81,\u03b83= \u03c0 2 = (2 sin 4\u03b82 \u22124 sin 4\u03b82 \u22122 sin 4\u03b82)\nEig.(HL4)|\u03b81,\u03b83=\u03c02 =  4(cos 2\u03b82 \u2212 cos 4\u03b82) \u22122 cos 2\u03b82 \u2212 14 cos 4\u03b82 \u2212 . . . . . . \u221a 2 \u221a 34\u2212 2 cos 2\u03b82 + cos 4\u03b82 \u2212 2 cos 6\u03b82 + 33 cos 8\u03b82\n\u22122 cos 2\u03b82 \u2212 14 cos 4\u03b82 + . . . . . . \u221a 2 \u221a 34\u2212 2 cos 2\u03b82 + cos 4\u03b82 \u2212 2 cos 6\u03b82 + 33 cos 8\u03b82\n (10)"}, {"heading": "3.3 The Coulomb cost as degeneracy control", "text": "We also propose a stronger cost, where the repulsion from large cosine distances is Coulombic: the Coulomb cost. Degeneracy control can then be related to the problem of characterizing the minimum energy states of M charged particles on a n-sphere, an open problem in electrostatics(Smale, 1998). The energy, ECoulomb, of two charged point particles of the the same sign is proportional to the inverse of their distance, ~rij :\nECoulombij \u221d 1\n|~rij | . (11)\nTo map this problem onto ICA, the cost should be made symmetric around \u03b8 = \u03c0/2 which can be accomplished by replacing \u03b8 with 2\u03b8, i.e. |rij | = \u221a 1\u2212 cos2 \u03b8ij2 \u2192 \u221a\n1\u2212 cos2 \u03b8ij . As a results, the Coulomb cost can be formulated as follows:\nCCoulomb = \u2211 ij 1\u221a 1\u2212 cos \u03b82ij\n(12)\nWe evaluate this cost numerically in section 4.1."}, {"heading": "4 Experimental Results", "text": ""}, {"heading": "4.1 Distribution of bases", "text": "In high dimensional spaces, it may be difficult to analytically understand the behavior of different degeneracy control mechanisms. In these cases, the behavior can be analyzed numerically by optimizing the different costs, C. To more systematically probe the effects of the different controls on the pairwise angle distributions, we use two different initializations of the bases. These are: a random uniform initialization, and a pathological initialization (as in section 3.1).\nIn the random uniform case, the bases are evenly initialized on the unit hyper-sphere. After the optimization , the quasi-orthogonality update (Hyv\u00e4rinen et al., 1999) produces a distribution which is less uniform than random (figure 2 a). The other costs force the angles close to 90 degrees at the cost of producing distributions with longer tails. This trade-off is particularly pronounced for the L2 cost which peaks at 90 degrees but also has the longest tail towards small angles. The other 3 costs have shorter tails and have varying amounts of density near 90 degrees. Of all costs, the L4 cost distributes the angles most evenly which is reflected by its distribution having the narrowest width.\nThe pathological initialization shows how the quasi-orthogonality update and the L2 cost can fall into pathological minima. The pathological initialization tiles an orthonormal, complete basis two times and adds Gaussian noise to every basis element. Most bases start either close to either 90 or 0 degrees apart as shown in the two peaks in the initial distribution. The L2 cost is unable to move away from this solution unlike the other costs, which generate comparable solutions for all initializations.\nIn order to gain more insight into the qualitative differences in the distributions of angles, we analyze the behavior of the costs around \u03b8 = 0 and \u03b8 = 90 (figure 2c-d respectively). The gradient of the cost close to | cos \u03b8| = 1 is proportional to the force the angles feel to stay away from zero which will determine the tail of the angle distribution.\nTaylor expanding all the costs near cos \u03b8 = 0 reveals that all cost functions have non-zero second order terms except for the L4 cost which only has a fourth order term. Costs which have non-zero\nsecond order terms will have gradients which scale linearly in cos \u03b8, whereas the L4 cost\u2019s gradient grows slowly (\u223c x3) near zero, as shown in figure 2d. These gradients affect the behavior of bases which are nearly orthogonal, namely gradients which scale linearly will encourage pairs of basis vectors to be more orthogonal at the expense of skewing the angle distribution towards small values. This leads to distributions of angles which are less uniform over all elements of the basis.\nThe effect of the gradient of the costs for intermediate values of \u03b8 is difficult to analyze because in addition to forces coming from the costs, there are effective forces coming from the constraint that all of the basis vectors must live on a unit hyper-sphere. For instance, since the gradient of the random prior is larger than the Coulomb cost near zero, one would expect this to cause the distribution to be higher near 90 degrees. Surprisingly, this is not the case, which can be understood by taking into account that the gradients at smaller angles are also larger which can lead to a distribution with a higher peak and less mass near 90 degrees."}, {"heading": "4.2 Experiments on natural images", "text": "We test whether the results obtained from evaluating the degeneracy control costs in isolation persist when the costs are used to train ICA models on natural images, i.e., equation 3. We train four times overcomplete ICA models on 8-by-8 whitened image patches at a fixed level of sparsity across costs. It is known that for natural images data sets, bases learned with ICA can be well-fit by Gabor filters (Bell and Sejnowski, 1997). Hence, we evaluate the distribution of the learned basis by inspecting the parameters obtained from fitting the bases to Gabor filters (see supplement for details).\nOur results show that the distributions of angles from the trained ICA models are inline with the theoretical results from section 4.1 (figure 3 a). The L2 cost has a long tail compared to the other costs with the L4 having the largest minimum angle between bases. For the range of sparsities which were considered, the visual appearance of the bases is similar to results from previous ICA work and similar across costs (L4 bases are shown in figure 3 b). We also find that for the degrees of sparseness used in the experiments, the reconstruction errors are comparable across costs.\nWe then visualize in more detail the tiling properties of the learned dictionaries. Figure 4 shows the summary of these results across costs. We find that for some parameters, the L4 cost has superior tiling properties. In particular, the distribution of angles and scales seems to better cover the range. The last column of (a) and (b) in figure 4 most clearly shows this difference. Altogether these results suggest that the use of a cost which encourages a more even distribution of basis vectors on the hyper-sphere has the potential to recover a larger diversity of sources from a natural images dataset."}, {"heading": "5 Discussion", "text": "In overcomplete ICA, degeneracy control is needed to prevent bases from becoming co-aligned. As we have shown, the choice of degeneracy control costs will also have an influence on the distribution of bases elements. In this paper we suggest two novel costs which prevent degenerate solutions. We show the L2 cost and quasi-orthogonality update have pathological solutions which are not present when used in complete ICA.\nIn general, the choice of a model and cost function should take into account knowledge about the structure of the data on which it is being trained. For instance, natural images have translational and rotational invariances both locally and globally which may not be modeled well by a degeneracy cost which also promotes global heterogeneity. Subspace ICA methods (Hyv\u00e4rinen and Hoyer, 2000) have been proposed to model these invariances and an overcomplete subspace-ICA model may benefit from a careful evaluation of different degeneracy control costs.\nIdeally, the distribution of bases should only be influenced by the dataset they are being learned on. Practically, the random initialization of bases, degeneracy control costs, and optimization algorithm can bias the distribution of bases learned. Therefore, it is important to have a theoretical and computational framework to evaluate these biases."}, {"heading": "6 Acknowledgements", "text": "We thank Yubei Chen, Alexander Anderson, and Kristofer Bouchard for their helpful discussions. JAL was supported by the Laboratory Directed Research and Development Program of Lawrence Berkeley National Laboratory under U.S. Department of Energy Contract No. DE-AC02-05CH11231. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Tesla K40 GPU used for this research. JAL and AFB were supported by the Applied Mathematics Program within the Office of Science Advanced Scientific Computing Research of the U.S. Department of Energy under contract No. DE-AC02-05CH11231. FTS was supported by INTEL, the Kavli Foundation and the National Science Foundation (grants 0855272, 1219212, 1516527)."}, {"heading": "L4 cost", "text": "CL4(\u03b81, \u03b82, \u03b83)|\u03b81,\u03b83=\u03c02 = 3 + cos 4\u03b82\n\u2202CL4(\u03b81, \u03b82, \u03b83)\n\u2202~\u03b8 | \u03b81,\u03b83= \u03c0 2 = (2 sin 4\u03b82 \u22124 sin 4\u03b82 \u22122 sin 4\u03b82)\nH(CL4)|\u03b81,\u03b83=\u03c02 =\n( \u22128 cos 4\u03b82 8 cos 4\u03b82 4(cos 2\u03b82 + cos 4\u03b82) 8 cos 4\u03b82 \u221216 cos 4\u03b82 \u22128 cos 4\u03b82\n4(cos 2\u03b82 + cos 4\u03b82) \u22128 cos 4\u03b82 \u22128 cos 4\u03b82\n)\nEig.(HL4)|\u03b81,\u03b83=\u03c02 =  4(cos 2\u03b82 \u2212 cos 4\u03b82) \u22122 cos 2\u03b82 \u2212 14 cos 4\u03b82 \u2212 . . . . . . \u221a 2 \u221a 34\u2212 2 cos 2\u03b82 + cos 4\u03b82 \u2212 2 cos 6\u03b82 + 33 cos 8\u03b82\n\u22122 cos 2\u03b82 \u2212 14 cos 4\u03b82 + . . . . . . \u221a 2 \u221a 34\u2212 2 cos 2\u03b82 + cos 4\u03b82 \u2212 2 cos 6\u03b82 + 33 cos 8\u03b82  EVec.(HL4)|\u03b81,\u03b83=\u03c02 = ( 1 0 1 ) ,\n \u22121 ( \u221a 2 8 \u221a 2 cos 2\u03b82 + cos 4\u03b82 \u2212 . . . . . . 2 cos 6\u03b82 + 33 cos 8\u03b82 + 34 \u2212 . . .\n. . .\u2212 2 cos 2\u03b82) sec 4\u03b82 + 14 1  ,  \u22121 1 4 \u2212 (2 cos 1 4\u03b82 + . . . . . . \u221a 2 8 \u221a \u22122 cos 2\u03b82 + cos 4\u03b82 \u2212 2 cos 6\u03b82 + . . .\n. . . 33 cos 8\u03b82 + 34 ) sec 4\u03b82\n1\n\n(14)\nMinima analysis for high dimensions\nFor an N dimensional space with an M (integer) times overcomplete basis, the pathological case is M orthonormal subsets, each its own orthonormal basis. We label our bases into the sequential\nsubsets of orthornormal subsets by label W1, . . . ,WN , . . . ,W2N , . . . ,WM\u00d7N . So, bases W1 through WN form a full-rank orthonormal basis and this basis is tiled M times.\nWe show that starting from the pathological initialization, applying a rotation to one set of bases leaves the value of the cost unchanged, and we also show that this initialization is a critical point of the cost.\nSymmetry under rotations\nWe can show that the L2 cost is invariant to rotations applied to any basis subset. This shows that configurations where no basis are exactly aligned and configurations where a large number of bases are exactly aligned can have the same value of the cost. However, it does not imply that these configurations are local minima of the cost.\nConsider the following partition of the bases: partition A is the first orthonormal set, i.e. bases W1 through WN , and partition B the remainder of the bases, i.e. bases WN+1 through WM\u00d7N . If a rotation is applied to A, only terms in the cost between elements of A and B will change. It is straightforward to show that the terms in the cost that have both elements within A or both within B are constant since the rotation does not alter the relative pairwise angles.\nFor some element Wi \u2208 B, we can write down the terms in the cost which contain itself and elements from A:\nCA,Wi = \u2211 Wj\u2208A (WTj Wi) 2 + (WTi Wj) 2 = 2 \u2211 Wj\u2208A ( ProjWj (Wi) )2 = 2|Wi|2. (15)\nSince the Wj \u2208 A remain an orthonormal basis under a rotation, the sum of the projections-squared is just the L2 norm-squared of Wi which is constant. Since this is true for every Wi \u2208 B, the entire cost is constant under this rotation.\nCritical point analysis\nWe can also show that this initialization is a critical point of the cost for all dimensions and integer overcompletenesses. This initialization is symmetric under the permutation of basis element labels, so showing that this initialization is a critical point for perturbations to one basis element shows that it is a critical point for perturbations to all elements.\nConsider an infinitesimal rotation operator in S2, R = I + G, expanded to first order for small where G is the generator of the rotation R and I is the identity. Showing that the L2 cost has no first order dependence on when the rotation is applied to a specific element, Wi shows that this initialization is a critical point. Since only Wj is being perturbed, we only need to consider terms in the cost which depend on Wi. We partition the terms into one set \u2016, which contains all bases which are parallel to Wi and a second set \u22a5, which contains all bases which are perpendicular to Wi:\nCWi( ) = \u2211 Wj\u2208\u2016 (WTj (I + G)Wi) 2 + (((I + G)Wi) TWj) 2\n+ \u2211 Wj\u2208\u22a5 (WTj (I + G)Wi) 2 + (((I + G)Wi) TWj) 2.\n(16)\nThis can be simplified using the identity GT = \u2212G as G is a skew-symmetric matrix. Grouping the terms by their O( ) dependence gives the following expression:\nCWi( ) = \u2211 Wj\u2208\u2016 2 (WTj IWi)(W T j GWi)\u2212 2 (WTi IWj)(WTi GWj)\n+ \u2211 Wj\u2208\u22a5 2 (WTj IWi)(W T j GWi)\u2212 2 (WTi IWj)(WTi GWj)\n+ const. +O( 2 + ...) = 0 + const. +O( 2 + ...).\n(17)\nIt is useful to note that this equality does not rely on the cancellation of the two pairs of terms, but, in fact, all four terms are exactly zero. The first two terms are exactly zero because \u3008x,Gx\u3009 = 0 for a\nskew-symmetric matrix, G (can be seen by applying skew-symmetric identity above.) The second two terms are zero because Wi and Wj are perpendicular and the first terms in the products are zero.\nFitting Gabor kernels\nThe procedure for finding the best Gabor kernel parameters was to save the parameter set with best mean-squared error with the following trials:\n1. for different initial widths, fit the center vector for the envelope to the absolute value of the basis after blurring it,\n2. for different rotations and frequencies, numerically optimize the rotation, phase, and frequency of the Gabor\n3. for the best fits from above, re-optimize the centers, widths, and phases.\nA repository with code to reproduce the results will be posted online."}], "references": [{"title": "The \u201cindependent components\u201d of natural scenes are edge filters", "author": ["A.J. Bell", "T.J. Sejnowski"], "venue": "Vision research, 37(23):3327\u20133338.", "citeRegEx": "Bell and Sejnowski,? 1997", "shortCiteRegEx": "Bell and Sejnowski", "year": 1997}, {"title": "Greedy layer-wise training of deep networks. Advances in neural information processing", "author": ["Y. Bengio", "P. Lamblin", "D. Popovici", "H Larochelle"], "venue": null, "citeRegEx": "Bengio et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2007}, {"title": "A limited memory algorithm for bound constrained optimization", "author": ["R.H. Byrd", "P. Lu", "J. Nocedal", "C. Zhu"], "venue": "SIAM Journal on Scientific Computing, 16(5):1190\u20131208.", "citeRegEx": "Byrd et al\\.,? 1995", "shortCiteRegEx": "Byrd et al\\.", "year": 1995}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["A. Coates", "A.Y. Ng", "H. Lee"], "venue": "International conference on artificial intelligence and statistics, pages 215\u2013223.", "citeRegEx": "Coates et al\\.,? 2011", "shortCiteRegEx": "Coates et al\\.", "year": 2011}, {"title": "Independent component analysis, a new concept", "author": ["P. Comon"], "venue": "Signal processing,", "citeRegEx": "Comon,? \\Q1994\\E", "shortCiteRegEx": "Comon", "year": 1994}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Teh", "Y.-W."], "venue": "Neural computation, 18(7):1527\u20131554.", "citeRegEx": "Hinton et al\\.,? 2006", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Estimation of non-normalized statistical models by score matching", "author": ["A. Hyv\u00e4rinen"], "venue": "Journal of Machine Learning Research, pages 695\u2013709.", "citeRegEx": "Hyv\u00e4rinen,? 2005", "shortCiteRegEx": "Hyv\u00e4rinen", "year": 2005}, {"title": "A fast algorithm for estimating overcomplete ica bases for image windows", "author": ["A. Hyv\u00e4rinen", "R. Cristescu", "E. Oja"], "venue": "Neural Networks, 1999. IJCNN\u201999. International Joint Conference on, volume 2, pages 894\u2013899. IEEE.", "citeRegEx": "Hyv\u00e4rinen et al\\.,? 1999", "shortCiteRegEx": "Hyv\u00e4rinen et al\\.", "year": 1999}, {"title": "Emergence of phase-and shift-invariant features by decomposition of natural images into independent feature subspaces", "author": ["A. Hyv\u00e4rinen", "P. Hoyer"], "venue": "Neural computation, 12(7):1705\u20131720.", "citeRegEx": "Hyv\u00e4rinen and Hoyer,? 2000", "shortCiteRegEx": "Hyv\u00e4rinen and Hoyer", "year": 2000}, {"title": "Estimating overcomplete independent component bases for image windows", "author": ["A. Hyv\u00e4rinen", "M. Inki"], "venue": "Journal of Mathematical Imaging and Vision, 17(2):139\u2013152.", "citeRegEx": "Hyv\u00e4rinen and Inki,? 2002", "shortCiteRegEx": "Hyv\u00e4rinen and Inki", "year": 2002}, {"title": "A fast fixed-point algorithm for independent component analysis", "author": ["A. Hyv\u00e4rinen", "E. Oja"], "venue": "Neural computation, 9(7):1483\u20131492.", "citeRegEx": "Hyv\u00e4rinen and Oja,? 1997", "shortCiteRegEx": "Hyv\u00e4rinen and Oja", "year": 1997}, {"title": "Ica with reconstruction cost for efficient overcomplete feature learning", "author": ["Q.V. Le", "A. Karpenko", "J. Ngiam", "A.Y. Ng"], "venue": "Advances in Neural Information Processing Systems, pages 1017\u20131025.", "citeRegEx": "Le et al\\.,? 2011", "shortCiteRegEx": "Le et al\\.", "year": 2011}, {"title": "Probabilistic framework for the adaptation and comparison of image codes", "author": ["M.S. Lewicki", "B.A. Olshausen"], "venue": "JOSA A, 16(7):1587\u20131601.", "citeRegEx": "Lewicki and Olshausen,? 1999", "shortCiteRegEx": "Lewicki and Olshausen", "year": 1999}, {"title": "Highly overcomplete sparse coding", "author": ["B.A. Olshausen"], "venue": "IS&T/SPIE Electronic Imaging, pages 86510S\u201386510S. International Society for Optics and Photonics.", "citeRegEx": "Olshausen,? 2013", "shortCiteRegEx": "Olshausen", "year": 2013}, {"title": "A network that uses few active neurones to code visual input predicts the diverse shapes of cortical receptive fields", "author": ["M. Rehn", "F.T. Sommer"], "venue": "Journal of computational neuroscience, 22(2):135\u2013146.", "citeRegEx": "Rehn and Sommer,? 2007", "shortCiteRegEx": "Rehn and Sommer", "year": 2007}, {"title": "Spatial structure and symmetry of simple-cell receptive fields in macaque primary visual cortex", "author": ["D.L. Ringach"], "venue": "Journal of neurophysiology, 88(1):455\u2013463.", "citeRegEx": "Ringach,? 2002", "shortCiteRegEx": "Ringach", "year": 2002}, {"title": "Mathematical problems for the next century", "author": ["S. Smale"], "venue": "The Mathematical Intelligencer, 20(2):7\u201315.", "citeRegEx": "Smale,? 1998", "shortCiteRegEx": "Smale", "year": 1998}, {"title": "Theano: A Python framework for fast computation of mathematical expressions", "author": ["Theano Development Team"], "venue": "arXiv e-prints, abs/1605.02688.", "citeRegEx": "Team,? 2016", "shortCiteRegEx": "Team", "year": 2016}], "referenceMentions": [{"referenceID": 4, "context": "Independent Components Analysis (ICA) is a technique for learning the underlying non-Gaussian and mutually independent sources S in a dataset X (Comon, 1994; Bell and Sejnowski, 1997).", "startOffset": 144, "endOffset": 183}, {"referenceID": 0, "context": "Independent Components Analysis (ICA) is a technique for learning the underlying non-Gaussian and mutually independent sources S in a dataset X (Comon, 1994; Bell and Sejnowski, 1997).", "startOffset": 144, "endOffset": 183}, {"referenceID": 10, "context": "The constraint WW = I prevents the bases from becoming degenerate (Hyv\u00e4rinen and Oja, 1997).", "startOffset": 66, "endOffset": 91}, {"referenceID": 11, "context": "This constrained optimization can be relaxed into an unconstrained one by adding a new cost C to the objective function (Le et al., 2011).", "startOffset": 120, "endOffset": 137}, {"referenceID": 12, "context": "Overcomplete versions of sparse coding and ICA (Lewicki and Olshausen, 1999; Hyv\u00e4rinen, 2005; Le et al., 2011) have been proposed.", "startOffset": 47, "endOffset": 110}, {"referenceID": 6, "context": "Overcomplete versions of sparse coding and ICA (Lewicki and Olshausen, 1999; Hyv\u00e4rinen, 2005; Le et al., 2011) have been proposed.", "startOffset": 47, "endOffset": 110}, {"referenceID": 11, "context": "Overcomplete versions of sparse coding and ICA (Lewicki and Olshausen, 1999; Hyv\u00e4rinen, 2005; Le et al., 2011) have been proposed.", "startOffset": 47, "endOffset": 110}, {"referenceID": 5, "context": "Overcomplete representations have been used to improve classification (Hinton et al., 2006; Bengio et al., 2007; Coates et al., 2011) and learn more diverse features (Rehn and Sommer, 2007; Olshausen, 2013).", "startOffset": 70, "endOffset": 133}, {"referenceID": 1, "context": "Overcomplete representations have been used to improve classification (Hinton et al., 2006; Bengio et al., 2007; Coates et al., 2011) and learn more diverse features (Rehn and Sommer, 2007; Olshausen, 2013).", "startOffset": 70, "endOffset": 133}, {"referenceID": 3, "context": "Overcomplete representations have been used to improve classification (Hinton et al., 2006; Bengio et al., 2007; Coates et al., 2011) and learn more diverse features (Rehn and Sommer, 2007; Olshausen, 2013).", "startOffset": 70, "endOffset": 133}, {"referenceID": 14, "context": ", 2011) and learn more diverse features (Rehn and Sommer, 2007; Olshausen, 2013).", "startOffset": 40, "endOffset": 80}, {"referenceID": 13, "context": ", 2011) and learn more diverse features (Rehn and Sommer, 2007; Olshausen, 2013).", "startOffset": 40, "endOffset": 80}, {"referenceID": 7, "context": "In overcomplete ICA, orthonormality can no longer be enforced for all bases, therefore some other form of degeneracy control (Hyv\u00e4rinen et al., 1999) is needed to prevent bases from learning identical features, i.", "startOffset": 125, "endOffset": 149}, {"referenceID": 7, "context": "Different methods for degeneracy control have been proposed: a quasi-orthogonality constraint (Hyv\u00e4rinen et al., 1999), a reconstruction cost (referred to as L2 cost here) (Le et al.", "startOffset": 94, "endOffset": 118}, {"referenceID": 11, "context": ", 1999), a reconstruction cost (referred to as L2 cost here) (Le et al., 2011), and a random prior cost (Hyv\u00e4rinen and Inki, 2002) (see Methods for more details).", "startOffset": 61, "endOffset": 78}, {"referenceID": 9, "context": ", 2011), and a random prior cost (Hyv\u00e4rinen and Inki, 2002) (see Methods for more details).", "startOffset": 33, "endOffset": 59}, {"referenceID": 6, "context": "1 Quasi-orthogonality constraint Hyv\u00e4rinen et al. (1999) suggest a quasi-orthogonality update which approximates a symmetric GramSchmidt orthogonalization scheme for an overcomplete basis W and can be formulated as follows: W \u2190 3 2 W \u2212 1 2 WWW.", "startOffset": 33, "endOffset": 57}, {"referenceID": 11, "context": "2 Reconstruction cost and the L2 cost Le et al. (2011) propose adding a reconstruction cost to the ICA prior (RICA) as a form of degeneracy control, which they show is equivalent to a cost on the L2 norm of the difference between the Gram", "startOffset": 38, "endOffset": 55}, {"referenceID": 6, "context": "3 Random prior cost Hyv\u00e4rinen and Inki (2002) use a prior on the distribution of pairwise angles to encourage quasiorthonormality and non-degeneracy.", "startOffset": 20, "endOffset": 46}, {"referenceID": 2, "context": "All models were implemented in Theano (Theano Development Team, 2016) and trained using L-BFGS-B (Byrd et al., 1995) and the norm-ball projection (Le et al.", "startOffset": 97, "endOffset": 116}, {"referenceID": 11, "context": ", 1995) and the norm-ball projection (Le et al., 2011) to keep the bases normalized.", "startOffset": 37, "endOffset": 54}, {"referenceID": 15, "context": "We fit the Gabor parameters (Ringach, 2002) to the learned bases using an iterative grid-search and optimization scheme which gave the best results on generated filters.", "startOffset": 28, "endOffset": 43}, {"referenceID": 11, "context": "1 Pathological degeneracy in the L2 cost For the L2 cost (Le et al., 2011), it can be shown that in the overcomplete case there exists a set of degenerate solutions in which the angle between pairs of bases becomes exactly zero.", "startOffset": 57, "endOffset": 74}, {"referenceID": 7, "context": "1, suggest that these pathological solutions are also present in the quasi-orthonormality constraint (Hyv\u00e4rinen et al., 1999).", "startOffset": 101, "endOffset": 125}, {"referenceID": 16, "context": "Degeneracy control can then be related to the problem of characterizing the minimum energy states of M charged particles on a n-sphere, an open problem in electrostatics(Smale, 1998).", "startOffset": 169, "endOffset": 182}, {"referenceID": 7, "context": "After the optimization , the quasi-orthogonality update (Hyv\u00e4rinen et al., 1999) produces a distribution which is less uniform than random (figure 2 a).", "startOffset": 56, "endOffset": 80}, {"referenceID": 0, "context": "It is known that for natural images data sets, bases learned with ICA can be well-fit by Gabor filters (Bell and Sejnowski, 1997).", "startOffset": 103, "endOffset": 129}, {"referenceID": 8, "context": "Subspace ICA methods (Hyv\u00e4rinen and Hoyer, 2000) have been proposed to model these invariances and an overcomplete subspace-ICA model may benefit from a careful evaluation of different degeneracy control costs.", "startOffset": 21, "endOffset": 48}], "year": 2016, "abstractText": "Understanding the effects of degeneracy control mechanisms when learning overcomplete representations is crucial for applying Independent Components Analysis (ICA) in machine learning and theoretical neuroscience. A number of approaches to degeneracy control have been proposed which can learn non-degenerate complete representations, however some of these methods can fall into bad local minima when extended to overcomplete ICA. Furthermore, they may have unintended side-effects on the distribution of learned basis elements, which may lead to a biased exploration of the data manifold. In this work, we identify and theoretically analyze the cause of these failures and propose a framework that can be used to evaluate arbitrary degeneracy control mechanisms. We evaluate different methods for degeneracy control in overcomplete ICA and suggest two novel approaches, one of which can learn highly orthonormal bases. Finally, we compare all methods on the task of estimating an overcomplete basis on natural images.", "creator": "LaTeX with hyperref package"}}}