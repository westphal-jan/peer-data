{"id": "1606.05467", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2016", "title": "Gender Inference using Statistical Name Characteristics in Twitter", "abstract": "Much attention has been given to the task of gender inference of Twitter users. Although names are strong gender indicators, the names of Twitter users are rarely used as a feature; probably due to the high number of ill-formed names, which cannot be found in any name dictionary. Instead of relying solely on a name database, we propose a novel name classifier. Our approach extracts characteristics from the user names and uses those in order to assign the names to a gender. This enables us to classify international first names as well as ill-formed names.", "histories": [["v1", "Fri, 17 Jun 2016 10:24:29 GMT  (228kb,D)", "https://arxiv.org/abs/1606.05467v1", "9 pages (8 pages in actual proceedings), 2 figures, 8 tables, conference: MISNC, SI, DS '16, August 15 - 17, 2016, Union, NJ, USA"], ["v2", "Fri, 1 Jul 2016 12:38:04 GMT  (62kb,D)", "http://arxiv.org/abs/1606.05467v2", "9 pages (8 pages in actual proceedings), 2 figures, 8 tables, conference: MISNC, SI, DS '16, August 15 - 17, 2016, Union, NJ, USA"]], "COMMENTS": "9 pages (8 pages in actual proceedings), 2 figures, 8 tables, conference: MISNC, SI, DS '16, August 15 - 17, 2016, Union, NJ, USA", "reviews": [], "SUBJECTS": "cs.CL cs.SI", "authors": ["juergen mueller", "gerd stumme"], "accepted": false, "id": "1606.05467"}, "pdf": {"name": "1606.05467.pdf", "metadata": {"source": "META", "title": "Gender Inference using Statistical Name Characteristics in Twitter", "authors": ["Juergen Mueller", "Gerd Stumme"], "emails": ["mueller@cs.uni-kassel.de", "stumme@cs.uni-kassel.de", "permissions@acm.org."], "sections": [{"heading": null, "text": "CCS Concepts \u2022Information systems\u2192 Information extraction; Evaluation of retrieval results; Data mining; \u2022Human-centered computing \u2192 Social networking sites;\nKeywords Gender Inference; Classification; Experimentation; Social Networks; Twitter"}, {"heading": "1. INTRODUCTION", "text": "Both academia and companies have genuine interest in understanding the gender distribution in social networks. Social scientists could study gender as an influence on human behavior in online communities [9] or on scientific and technological productivity from countries [7]. The industry would gain additional information about their customers, which allows them to improve the efficiency of targeted advertisements [2].\nTwitter is currently one of the biggest, most important, and scientifically best covered social networks. Data are mostly public and it is well understood by academia, which allows good comparisons in return. Unfortunately, explicit gender information is not included in the Twitter data. Therefore, it\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. MISNC, SI, DS \u201916, August 15 - 17, 2016, Union, NJ, USA c\u00a9 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-4129-5/16/08. . . $15.00\nDOI: http://dx.doi.org/10.1145/2955129.2955182\nhas to be inferred, for example, using machine learning methods. Accordingly, automated gender inference of Twitter users is a relevant topic of research. Amongst those, classification using Support Vector Machines (SVMs) have been found to be the best gender inference approaches [4, 14, 21]. Examples for the most commonly used features are bag of words, n-grams, hashtags, or the friend-follower ratio.\nSurprisingly, the self-reported names1 of the users are rarely used as a classification feature. This was mentioned by Liu and Ruths [14] who conducted some experiments that are based on the self-reported name of the Twitter users as additional feature.\nOne could argue that the self-reported names and profile images offer no guarantee to be true. But according to Herring and Stoerger [8], the number of users who masquerade themselves for someone else is not statistically significant and can be ignored in most cases.\nMaking use of some name dictionary seems to be an obvious solution to get gender information about a given name. Such dictionaries contain known names that are actually used by human beings. Twitter users, however, did not restrict their choice to this set of names nor does Twitter enforce it. Users are named with their actual names, made-up names, or nicknames.\nWe will present a new classifier named NamChar that assigns gender labels to first names based on their written form. It uses methods from the study of onomastics to extract characteristics from the name that correlate with the two genders. Our paper tries to answer the following research questions:\n1. In their outlook, Liu and Ruths [14] considered a bigger name dictionary as promising improvement for their gender score. Therefore, we answer the question \u201cdoes a broader name dictionary improve the performance of the gender score?\u201d 2. We want to improve the result of Liu and Ruths by using name characteristics. This enables the classification of names that cannot be found in a name dictionary. This leads to the following two sub-questions:\n(a) \u201cAre name characteristics able to improve the performance of the gender score?\u201d (b) \u201cAre name characteristics able to improve the\n1Twitter has two names per user. We refer here to the \u201creal name\u201d that is displayed on the profile page. There is also the \u201cusername\u201d that is used as unique identifier for every user.\nar X\niv :1\n60 6.\n05 46\n7v 2\n[ cs\n.C L\n] 1\nJ ul\n2 01\n6\noverall performance of Liu and Ruths\u2019s gender inference method?\u201d\nIn the sequel, we always use the word \u201cgender\u201d as synonym for \u201cgender of first names\u201d (with the two instances \u201cfemale\u201d and \u201cmale\u201d) unless we explicitly talk about the gender of people. We could add \u201cunisex\u201d as a third gender, but have refrained from it, because we have no ground truth covering \u201cunisex\u201d names on Twitter."}, {"heading": "2. RELATED WORK", "text": "A gender-labeled dataset of names can be very beneficial for gender classification. However, it cannot be used as sole data source, because Twitter names are not limited to real names. There are many sources for name lists on the Internet. Most sources, however, give no information about the quality of the data. Nevertheless, we found four data sources of trustworthy quality:\n\u2022 The list of most frequently chosen baby names for every year since 1880 as published by the US Social Security Agency.2 \u2022 The names of the participants of the 1990 Census as published by the US Census Bureau.3 \u2022 Jo\u0308rg Michael published a self collected dataset of names.4 \u2022 Wikipedia contains dedicated pages covering first names\nthat are available as download from Wikimedia.5\nTang et al. [27] proposed a gender inference classifier for Facebook users from New York City. They collected 1.67 million profiles and extracted a gender-labeled list of names from this dataset. They used the top baby names published by the US Social Security Agency, their list of collected Facebook names, data from the Facebook fields \u201crelationship status\u201d, \u201cinterested in\u201d, and \u201clooking for\u201d, as well as information about the Facebook friends to predict the gender of the users with an accuracy of up to 95.2 %. The authors decided to randomly assign a gender if a user\u2019s name is not found in their list of names, which leaves room for further improvement.\nKarimi et al. [10] compared five gender inference tools in the realm of research names. They used an image-based gender inference on the five first search engine results using the first and last name. Their approach, however, works with actual names to query the search engine. Twitter names mostly do not fall into this category.\nLiu and Ruths [14] proposed a novel gender inference classifier using an SVM that uses the names of Twitter users as additional feature. As Twitter offers no gender information and there was no publicly available labeled dataset at the time, they created a classified dataset on their own. They used Amazon Mechanical Turk (AMT) workers for determining the gender of users based on their profile images. Liu and Ruths introduced a gender-name association score (from now on referred to as \u201cgender score\u201d) for all names in the Census data.\n2Source: File \u201cnames.zip\u201d from https://ssa.gov/oact/ babynames/limits.html 3Source: File \u201cdist.female.first\u201d and \u201cdist.male.first\u201d from http://census.gov/topics/population/genealogy/data/ 1990 census/1990 census namefiles.html 4Source: File \u201cnam dict.txt\u201d from https://heise.de/ct, softlink 0717182 (c) by Jo\u0308rg MICHAEL, Hannover, Germany, 2007-2008 5Source: https://dumps.wikimedia.org\nThe gender score is computed using the gender distribution of each name and reflects how often it has been given to a male or female person. They used common features for their classification and added the gender score as additional feature. Their results show that the use of this gender score reduced the classification error rate by 11.4 %, which they improved further to 22.8 % by the use of a threshold value. Their approach, however, can only work to its full potential, when the name of concern is represented in the Census data. But Twitter is an international network with users from all around the world. Accordingly, they could not assign a gender score to about two-thirds of the users. Even a hypothetical dataset with gender-labeled names covering all countries of the world could not classify all Twitter users, because Twitter does no force its users to use real names.\nOne attempt to infer the gender of Twitter users is the analysis of the self-reported name directly. Slater and Feinman [26] and Cutler et al. [6] discovered a significant correlation between name characteristics and the gender of North American names. Their findings were later transferred successfully to German names by Oelkers [20] and Seibicke [24]. The English and German findings can be used to identify the gender of a given name based on the number of syllables, number of vowels, number of consonants, vowel brightness, and ending character. Among those, the ending sound is the strongest. The majority of female names ends with a vowel, while most names that end with a consonant are male. This implication is true for about 60 % of North American and 80 % of German cases. Unfortunately, some characteristics depend on the pronunciation, which is problematic, because we have no information about the origin of the names and their actual pronunciation.\nAnother promising approach to extract the gender of a name from its written word was discovered by Sidhu and Pexman [25]. They analyzed the use of the Bouba/Kiki effect on given names. The Bouba/Kiki effect describes a nonarbitrary mapping between a speech sound and the visual shape of objects (see Figure 1) [12]. Sidhu and Pexman asked the participants of their study to assign a given English first name to two shapes (i.e., Bouba or Kiki) that are shown to them during the experiment. Every name was assigned to either Bouba or Kiki beforehand based on the findings of previous research [17, 19]. Sidhu and Pexman found a relationship between Bouba with female names and Kiki with male names through the answers of the participants. These characteristics, however, suffer from the same challenge as parts of the aforementioned name characteristics: we do not know the actual pronunciation. Further, these findings only account for a correlation in the English language."}, {"heading": "3. DATASETS", "text": "This section describes the data used throughout this paper. First we present the gender-labeled name data that can be used to get the true gender from a given name. Second we\ndescribe the data that is used for our Twitter experiments. Note that we considered only \u201cmale\u201d and \u201cfemale\u201d as potential genders of people, ignoring sexual identities like \u201cCisgender\u201d or \u201cTransgender\u201d, because there is no available ground truth for that."}, {"heading": "3.1 Gender-labeled Name Data", "text": "A reliable gender-labeled name dataset is required in order to make assumptions about the performance of a name-driven gender inference classifier. We decided to use the Census3 and the nam dict data4 throughout our experiments for the following reasons: First, the Census data was used by Liu and Ruths [14] and we will use their results as baseline in Section 5. Second, the nam dict dataset is the biggest dataset we know of that covers non-American names as well. Following is a short description of both datasets:\nCensus: The Census dataset was created in 1990 by the US Census Bureau and consists of three files, one for female first names, one for male first names, and one for all last names. Each file contains for each upper-cased name, the frequency of its usage in percent, the cumulative usage frequency in percent, and its rank. The dataset contains only names that are used by at least 0.001 % of US citizens, which results in 5,163 names and corresponds to about 90 % of the population of the United States of America. We use only the files for first names and therein only the names and their frequencies.\nnam dict: The name dictionary nam dict in version 1.2 was collected by Jo\u0308rg Michael in 2008. It is with 45,513 first names and nicknames more than eight times bigger than the Census data. The name dictionary contains names covering 51 geographic regions of the world. All names are stored in their actual writing (i.e., no upper- or lower-casing was applied) alongside information about their gender association and how often they are used in every geographic region. The gender association is encoded into seven categories, which provides the following gender information: \u201cmostly male/female name\u201d, \u201cfemale/male name if first part of the name\u201d, and \u201cmale/female/unisex first name\u201d.\nTable 1 shows the different gender labels and numbers of names assigned to them in both datasets. Note that the Census data does not contain dedicated gender labels. The names are assigned to a gender using their presence in one of two files. Therefore, the number of unisex names is not explicitly given. After intersecting the names from both data files, we found that 331 names in the Census data are used by both genders. The names from the nam dict dataset are stored and labeled in a single file. Their labels directly correspond to those categories used in Table 1. The Census data contain a much bigger share of female names than the nam dict data. The nam dict dataset contains far more unisex names."}, {"heading": "3.2 Twitter Data", "text": "Next, we describe the data that will be used for the gender inference of Twitter users. It consists of two parts, namely a gender-labeled reference and a corresponding crawled Twitter sample. Following is a short description of both datasets:\nGround truth: Reliable information about the actual gender of the Twitter users is essential in order to conduct gender inference experiments. Such data is hard to find and rarely shared. Liu and Ruths [14] were faced with the same issue and, therefore, created their own dataset and made it\nTwitter sample: We collected all messages and relevant profile information from the Twitter users contained in the ground truth data created by Liu and Ruths. Only 9,060 of the 12,681 users could still be accessed via the Twitter API to date. This breaks down to 3,471 male and 5,589 female users (according to the AMT workers). Reasons for the decreased amount of accessible users could be that the dataset was collected before 2013 and many users deactivated their account or increased their privacy level since then. Liu and Ruths had not used all 12,681 users either, but made a sub-sample of 4,000 male and 4,000 female users to create equal sized data for both genders. However, we could only access 3,471 profiles from male users. Following the equalsized approach of Liu and Ruths, we created a sub-sample of 3,471 users per gender."}, {"heading": "4. NAMCHAR", "text": "Our first contribution is a name classifier that works on the written word of a first name. We first present the task description, following a discussion of the possible name characteristics that could be used. At the end of this section, we present our novel name classifier NamChar and its configuration."}, {"heading": "4.1 Task Description", "text": "Given is a list of first names with their gender information. We want to find a classifier that is able to assign gender labels to those names, using only the written name itself."}, {"heading": "4.2 Data Preparation", "text": "6Source: File \u201clabel.json\u201d from http://networkdynamics.org/ static/datasets/LiuRuthsMicrotext.zip\nWe choose to use the nam dict dataset because it contains the most extensive name information at hand. As shown in Table 1, the dataset contains many more categories and, therefore, had to be pre-processed as follows: The gender information was transformed by assigning the categories \u201cmale first name\u201d, \u201cmostly male name\u201d, and \u201cmale name if first part of the name\u201d to \u201cmale\u201d, the categories \u201cfemale first name\u201d, \u201cmostly female name\u201d, and \u201cfemale name if first part of the name\u201d to \u201cfemale\u201d, and the category \u201cunisex first name\u201d was removed, because it could decrease the accuracy."}, {"heading": "4.3 Feature Selection", "text": "First, we need to identify a set of characteristics that can be extracted from the written word of a name. They should be easy to extract while giving enough information about the corresponding gender. Therefore, we will first discuss the characteristics that were identified in onomastic research [6, 20, 24, 26]:\n\u2022 Number of syllables: Female names tend to have more syllables than their male counterparts. \u2022 Number of consonants: Male names tend to contain\nmore consonants than female names. \u2022 Number of vowels: Female first name tend to contain\nmore vowels than male names. \u2022 Vowel brightness: Female names contain more brightly\nemphasized vowels than male names. \u2022 Ending character: Female names end more often with a\nvowel while male names tend to end with a consonant.\nFurther, one could use the findings of Sidhu and Pexman [25] and count vowels and consonants that are associated with Bouba or Kiki. Sidhu and Pexman discovered a relationship of Bouba with female first names and Kiki with male first names. Therefore, one can use four additional name characteristics using the encoding schema for Bouba/Kiki that is provided by previous work as follows [17, 19]:\n\u2022 Number of Bouba consonants: Female name can be identified by counting the voiced consonants \u201cb\u201d, \u201cl\u201d, \u201cm\u201d, and \u201cn\u201d. \u2022 Number of Bouba vowels: Female name can be iden-\ntified by counting the rounded vowels \u201cu\u201d, \u201co\u201d, and \u201c6\u201d. \u2022 Number of Kiki consonants: Male name can be identi-\nfied by counting the voiceless stop consonants \u201ck\u201d, \u201cp\u201d, and \u201ct\u201d. \u2022 Number of Kiki vowels: Male name can be identified\nby counting the unrounded vowels \u201ci\u201d, \u201ce\u201d, \u201c\u03b5\u201d, and \u201c2\u201d.\nAll of these characteristics can be extracted from a written name. The ending character is the strongest amongst those characteristics as the majority of female names end with a vowel, while most names that end with a consonant are male. However, there are some limitations to the use of some of those characteristics. First do all characteristics depend on the pronunciation of the name, except of the number of consonants, number of vowels, and the ending character. Unfortunately, there is no indication about the pronunciation of a name in Twitter. Second, the Bouba/Kiki findings have not been transferred to other languages before and can, therefore, only ensure for a correlation in the English language. Hence, we should be very sensitive while using these characteristics!\nWe conducted a logistic regression in order to identify the strong predictors amongst the name characteristics. These predictors later will be used as variables in our classifier. During our experiments, all pronunciation-dependent variables where computed using the English language.\nThe data consists of the gender and the characteristics for every non-unisex name in the nam dict dataset mentioned above. The data consists of 18,204 (51.23 %) male and 17,328 (48.77 %) were female names. The research hypothesis posed to the data is that \u201cthe likelihood that a name is used by women is related to its characteristics\u201d. Thus, the outcome variable gender is a name being used by female (1 = yes, 0 = no). The ending character is coded as 1 = vowel and 0 = consonant. The distribution was 58 % (n = 21,729) vowels and 42 % (n = 15,455) consonants. The description of the interval scale-based variables is shown in Table 2. We observed a variance inflation factor (VIF) of 10.1 for the vowel brightness after the first run. Following the rules given by Kutner et al. [11], we removed this variable in order to remove the multicollinearity.\nThe results of the final model are shown in Table 4. The number of consonants and syllables are not significant (p = .4510, respectively p = .1745). The number of Kiki vowels and consonants are significant on a < .05 level and the remaining variables are all significant on a < .01 level. The validity of the predicted probabilities is documented in Table 3. According to the table is NamChar more likely to predict male names correctly than female\u201466.39 % for female and 76.50 % for male names\u2014while both stay well above random. The overall prediction was 70.59 %, an improvement over the chance level."}, {"heading": "4.4 Classification Model", "text": "Inspired by Liu and Ruths, we applied an SVM (i.e., LIBSVM [5]) with the radial basis function as kernel. Following the logistic regression results in Table 4, we include all variables except of the vowel brightness and the number of consonants and syllables to our SVM model. We used a grid search technique with a 10-fold cross-validation with three repeats to find the best parameter that are \u03b3 = 0.1745521\nand Costs = 1 with an accuracy of 70.9 % and a Kappa value of 0.419.\nThe default approach to assign genders to the names without a classification would be through random guessing. On the other hand, our NamChar is able to classify a name correctly in 70.9 % cases as mentioned in the previous paragraph. This is a considerable improvement compared to random guessing. We expect that the model works as well on unknown names.\nWe will use this approach in the following section where it will be used to classify Twitter names. Most Twitter names are not in any gender-labeled name database. Therefore, NamChar will be used when a name that is not represented in the database of known names needs to be classified."}, {"heading": "5. TWITTER GENDER INFERENCE", "text": "The second contribution of this paper is to show how gender inference for Twitter users can be improved by applying NamChar. We recall the gender score of Liu and Ruths [14] and introduce our refinement, the NamChar score. Then we show how the gender classification of Twitter users can be improved by extending the NamChar Threshold Classifier. The key idea of both approaches is to look up the name in a database. The stored score is used if the database contains the name. If this is not the case, Liu and Ruths [14] use a score of 0.0 whereas our approach applies NamChar.\nIt is important to note that the nam dict data is used here as input data, rather than as ground truth as in Section 4."}, {"heading": "5.1 Gender Scores", "text": "The gender score s(n) as introduced by Liu and Ruths [14] reflects the information that some names are more frequently assigned to male than to female people. For example, the names \u201cJohn\u201d (s(n) = 0.993) and \u201cAshley\u201d (s(n) = \u22120.912) are clearly associated to one gender while \u201cBerry\u201d (s(n) = 0.714) and \u201cKim\u201d (s(n) = \u22120.728) are used by both genders. The gender score on the Census data is computed using the following equation: s(n) = M(n)\u2212F (n) M(n)+F (n) , where n is the name of interest, M(n) is the number of times n is assigned to men, and F (n) is the number of times n is assigned to women. The score ranges from \u22121.0 for names that are given solely to women to 1.0 for names that are given to men only. For names that are not present in the Census data, the score is set to 0.0.\nThe gender score can be calculated directly from the Census data, because they contain explicit frequencies for the usage of the names by each gender. The nam dict data lacks such\ninformation, because it contains only binned information about the usage. In order to adapt the gender score to the nam dict data, we will translate the categories \u201cmale/female first name\u201d to \u00b11.0 and\u201cmostly male/female name\u201d to a value of \u00b10.8. \u201cfemale/male name if first part of the name\u201d will be used as the description suggests; that is \u00b11.0 if it actually is the first part of a name and 0.0 otherwise. The nam dict data may contain multiple entries for some names, if they are used for different genders in different geographic regions. We use the average of the gender scores of all occurrences in those cases.\nFigure 2 shows the distribution of all names of the Twitter dataset by their gender score. Both plots show the same trimodal characteristics as in the original work by Liu and Ruths [14]. Most classified names are unambiguously assigned to one of the two genders, but of particular note is that the vast majority of names has a score of 0.0. These names cannot be matched to an entry of the name database and can therefore not be used in Liu and Ruth\u2019s algorithm. Amongst those are uncommon names like \u201cWela P Msimanga\u201d, \u201cJessele Competente\u201d, or \u201cLaketa Page\u201d that sound like actual names,\nbut are not included in either of our name databases. Liu and Ruths [14] already identified this issue and separated the unknown names into five categories:7\n1. Unknown names like \u201cLim\u201d (which is actually a unisex name according to the nam dict data). Those names are not present in the Census data. Therefore, Liu and Ruths were not able to assign a meaningful gender score to those names. This category is largely covered by the use of the nam dict data. 2. Nicknames and name abbreviations like \u201cBig Daddy C\u201d or \u201cCJ Sullivan\u201d. Those names do not match to existing names. Nicknames, however, still contain some name characteristics. These signals will be exploited by our NamChar classifier. 3. Mangled names like\u201cAlanLeong\u201dor\u201c[-!Raphael-]\u201d. Those names contain valid given names, but are run together or decorated. Decorated names are less of a problem during our experiments, because we remove all decorating symbols from the name string. Names that are run together are more difficult because we lose the ending character as a feature. 4. Usernames like\u201cswagboiboo504\u201d. Those names read like user names or mail addresses. They could contain some gender characteristics similar to nicknames or mangled names, because they are likely to either contain them. 5. Non-names like \u201cMarried To Bieber\u201d, \u201cApple Support\u201d or \u201cThe Great Gatsby\u201d. Those names are no first names in any sense and are not intended to be so. Therefore, it is very unlikely that we could use them in a meaningful way. Worse, those names will likely reduce the accuracy of our approach.\nUsing a larger database of first names (i.e., the nam dict data) increased the number of assigned gender scores, but the number of names with a gender score of 0.0 still remains very high. While 4,790 user names received ay value of 0.0 with the Census data, 4,323 did so with the nam dict data; a reduction of 9.7 %. The fact that still 47.7 % of our Twitter users do not use common names is a strong signal that relying solely on name lists can only be part of a gender inference solution. Based on our observations in Section 4, we expect to assign helpful gender scores to at least some of those 4,323 users using NamChar.\nWe introduce the NamChar gender score that addresses this issue. It applies NamChar on those names that could not be found in the name dataset and uses the classification probability as gender score. This reduces the number of users without a meaningful gender score to 288, which is only 3.2 % of all users. Those remaining names are without exception names that consist solely of Unicode characters that could not be translated to common Latin letters, like Arabic names.\nNext, we compare both gender scores as predictor for the true genders of all collected Twitter users (N = 9,060) in order to find out whether or not a broader name dictionary improves the gender score (Research Question 1). The first two rows of Table 5 show the results of our experiments. The two datasets lead to similar results. A comparison of both datasets shows comparable results across all evaluation measures: For a paired-samples t-test (using SPSS version 23) we scaled the gender scores to the range of 0 to 1\u2014using\n7Examples adopted from Liu and Ruths [14].\ns(n)/x + 5 for male and \u2212s(n)/x + 5 for female names. The test shows that there is a slightly, but significant difference between both results, t(9, 059) = 6.10, p < .001, in which the gender scores based on the Census data obtained better results (Census: M=0.683, SD=0.277; nam dict: M=0.669 SD=0.282). This disproves the assumption of Liu and Ruths that a broader name database could improve their approach.\nLiu and Ruths [14] where not able to assign a valid gender score to two thirds of the Twitter users. 9.7 % more users receive a gender score if the Census data are replaced by the nam dict data, but on the expense of worse results. Therefore, we continue to use the Census data, but will present in the sequel a better approach to assign gender scores to those names that are not contained in the dataset.\nWe address these cases by using our NamChar score, which applies NamChar on all instances where the gender score equaled zero. The corresponding results can be found in Row 3 of Table 5. The overall results are better compared to the original approach (Row 1) for all measures. The biggest improvement is to be found for Recall which increases by 44 % from 0.429 to 0.630. Therefore, the NamChar score is able to classify many more Twitter users. The t-test shows that this improvement is significant, t(9, 059) = 3.27, p < .01, in which the NamChar scores obtained better results (gender score: M=0.683, SD=0.277; NamChar score: M=0.692 SD=0.377). Therefore, concerning Research Question 2a we conclude that the performance of the gender score can indeed be improved by the use of NamChar."}, {"heading": "5.2 Gender Inference Methods", "text": "In this section, we describe our modification of the Threshold Classifier of Liu and Ruths, including in particular the use of NamChar. We begin with recalling Liu and Ruths\u2019s approach.\n5.2.1 Threshold Classifier The Threshold Classifier of Liu and Ruths [14] uses a two-\nstep approach. During the first step, the absolute value of the gender score is compared with a threshold value \u03c4 (set to 0.85 by Liu and Ruths [14]). The gender label that corresponds to this gender score is used directly if the absolute value is above the threshold, because these names are predominantly used by a single gender only.\nIn Step 2, the remaining user\u2019s names are classified by an SVM with a radial basis function8 using a feature set that was developed in prior work [4, 14, 21, 23]. These features consist of the following three groups:\n\u2022 Features that are extracted from the full text messages (i.e., Tweets) of the given Twitter user. They consist\n8Liu and Ruths found the parameters for gamma and costs using a grid search technique, but did not mention them.\nThe k-top full text features are computed by selecting a score for every term t using s(t) = |tmale| \u2212 |tfemale|, where |t{gender}| is the number of times the term was used by all users of the given gender. This results in one list of ktop terms for male and one for female; therefore, in 2 \u00d7 k features. The scores of the feature vector are then computed for every user u using s(u) = |tu||Tu| , where tu is the number of occurrences the term is used by the given user and |Tu| is the number of all terms used by the same user.\nTable 6 shows as an example the 3-top terms for every feature category by gender that are obtained from all collected Twitter data. The complete list of 20-top terms for male names contains only verbs and conjunction words. The top words for female users on the other hand contain many more nouns. Men\u2019s hashtags tend to contain more technical or business tags, while women use more emotional tags.\n5.2.2 NamChar Threshold Classifier Our NamChar Threshold Classifier is a modification of Liu\nand Ruths\u2019s Threshold Classifier. It varies in two aspects: First, we apply a pre-processing step to remove decorative elements as discussed in Section 5.1. Then, we use NamChar to assign a gender score to all names that are not found in the Census data.\nLiu and Ruths discovered that they could not assign a meaningful gender score (i.e., 6= 0.0) to 66 % of the names they found on Twitter. Extending the name data by using the\n9The stems are obtained by passing the words of all Tweets to the Lovins stemmer [16].\nnam dict data instead of the Census data did not reduce the number of those instances significantly, as shown in Figure 2. Consequently, they would still lower the effect of the given name as a feature on the overall threshold classification. To this end, our goal is to further decrease the amount of those instances as much as possible by applying more pre-processing and adapting the way the gender score is computed.\nOne major challenge, while classifying the names of Twitter users is the multitude of special characters that are used in many user names. Therefore, we applied\u2014unlike Liu and Ruths\u2014the following pre-processing steps to all user names in the given order:\n1. Latin to ASCII conversion: There are many regional letter variations of all vowels. We applied a Latin to ASCII conversion to all names in order to make the extraction of the number of vowels more robust (e.g., the vowel \u201cu\u0308\u201d will be converted to the vowel \u201cu\u201d). 2. Removal of all non-letters: Next, we removed from the converted names all characters that are not letters or whitespaces. This step removes all numbers, punctuation signs, and emoji like flags and smilies. It enables us to classify decorated names (see Section 5.1).\nThe pre-processed name strings are used to determine the NamChar gender score. To this end, the name string is split at white-spaces. Then we check if we can find any part in the currently applied name databases, going from left to right. This procedure ends as soon as we find our first match, in which case the gender score of the match is assigned to the name of interest. A score of 0.0 is assigned, should no match be found. This reduces the number of unknown names on Twitter further by 426 names or 8.89 %.\nNext, we need a way to translate the predictions of NamChar to a meaningful gender score. It should reflect the reliability of the NamChar classifier. We use the probability of the classifier and linearly scale it to the gender score range of \u22121.0 (\u201cfemale\u201d) to 1.0 (\u201cmale\u201d).\nFollowing Liu and Ruths, we used a value of 20 for the number k of top terms and 0.85 for the threshold value \u03c410. We randomly split the dataset into halves and used the first partition to find the gamma and costs parameters for the SVM using a grid search technique. The best found parameters were then used to conduct the actual evaluation on the second partition.\nIn order to improve the gender classification of Twitter users, we evaluated both steps of the Threshold Classifier separately. First, we wanted to know whether or not it is possible to improve the performance for the first step where the threshold values decides the outcome. This part is independent from the actual classification and, therefore, cannot improve using our NamChar approach. Then, we tried to improve the classification performance on the remaining Twitter users using NamChar.\nThe findings on the gender score in Section 5.1 indicated that the Census data is better suited than the nam dict data if applied on the whole dataset. But, only gender scores above the threshold value are relevant in Step 1. It is still possible that the nam dict data is better in generating such\n10Note that \u03c4 = 0.85 implies that \u201cmostly male/female name\u201d, which obtained a gender score of 0.8 in Section 5.1, will be processed in Step 2 of the Threshold Classifier for further differentiation."}, {"heading": "TH 0.00400 1 0.892 0.814 0.813 0.628", "text": ""}, {"heading": "TH + NC 0.00379 1 0.896 0.820 0.815 0.639", "text": "scores. Table 7 shows the performance that is achieved during this step. The data confirms that using the Census data results in better results in all four measures. Additionally, the gender score was able to label more Twitter users than with NamChar score.\nThe remaining 3,980 Twitter users were passed on to the classification step. 3,708 of those users have a gender score of 0.0, which leaves 272 users with a low gender score. Our expectation is that the classification of these user names\u2014which cannot be done by a simple lookup in the database\u2014will benefit more strongly from a more sophisticated classifier. To evaluate this assumption, we ran two experiments comparing the Threshold Classifier (TH) with the NamChar Threshold Classifier (TH + NC) on the Census data. Each experiment was conducted using a 10-fold cross validation with three repeats. The true gender was given by the labels assigned by the AMT workers in the ground truth data of Liu and Ruths, as described in Section 3.2.\nTable 8 shows the results for all names that have a gender score below threshold \u03c4 . This is the part where the classification is executed using the full text, profile, and gender information. The use of NamChar results in a slight improvement compared to the plain Threshold Classifier. This is a further 4.4 % reduction of the error rate compared to 0.892 of the Threshold Classifier without NamChar. The t-test shows that this difference between both results is significant, t(3, 979) = 2.04, p < .05, in which the NamChar Threshold Classifier obtained better results (TH: M=0.809, SD=0.151; NC + TH: M=0.811 SD=0.152). We used the classifiers probability p for a certain class\u2014using p for male and 1\u2212 p for female names\u2014as input for the t-test. Therefore, concerning Research Question 2b, we conclude that Liu and Ruths\u2019 approach can indeed be improved by assigning gender scores to those names that are not found in the database.\nOverall, our experiments show that the influence of the user name data is more complex than originally expected. Liu and Ruths raised the concern that the Census data are not broad enough to be used on Twitter, because it contains only names that are used in the United States of America, whereas Twitter is used by people from all around the world. We could show, however, that a larger dataset did\nnot necessarily improve the performance of the Threshold Classifier. The names that are not contained in the database are good candidates for improvement. We utilized them by assigning a score using the NamChar approach. Further, Liu and Ruths were only able to assign scores to names from the US, while NamChar works in other countries and for ill-formed names as well."}, {"heading": "6. CONCLUSIONS AND FUTURE WORK", "text": "Our first contribution was the proposal of a novel name classifier\u2014NamChar\u2014that is able to label a given name as one of the two genders using only a small set of characteristics extracted from the written first name. We evaluated the performance of all possible name characteristics and selected the statistically significant characteristics.\nOur second contribution was the introduction of an improved gender inference classifier for Twitter users. We observed that only using a larger name database will not improve the performance of the Threshold Classifier. The best results were achieved by our NamChar Threshold Classifier.\nThere are some issues that might be interesting to investigate further. It is for example surprising that Liu et al. used only the Lovins stemmer to compute the k-top stems and co-stems during the feature computation. The Porter stemmer [22] has become a de facto standard since then and has mostly replaced the Lovins stemmer. It would be interesting to compare the influence of both stemmers on the overall performance. We refrained from doing this here, because our intention was to study the effect of the gender score.\nThe further reduction of unknown names is also a field of further improvement. One step into this direction could be the discovery of personal names from nicknames. Bollegala et al. [3] proposed a method for this task that could be tested on Twitter names.\nOur ground truth data was already cleared from company accounts, which is not the case if we want to apply it on all Twitter users. Finding a reliable way to distinguish personal from company accounts would be required.\nWe considered some characteristics like the emphasized vowels or the finding of Sidhu and Pexman [25] about the application of the Bouba/Kiki effect as problematic, because we had no information about the proper pronunciation of the users\u2019 names. They could be more effective if one had information about the actual pronunciation, for example, when the origin of the Twitter user could be identified.\nOne general drawback of the threshold classification approach is its strong dependency on the used language. Tweets that are not written in English will create no meaningful feature vector. This could be solved by adding more language independent features like \u201cfrequency statistics\u201d, \u201cretweeting tendency\u201d, or \u201cneighborhood size:\u201d to the feature vector. For instance, one could use text-independent approaches like using profile image attributes [1] or by extracting user attributes from the tweeted images [18]."}, {"heading": "7. ACKNOWLEDGMENTS", "text": "We thank Stephan Doerfel, Janina Krawitz, Folke Mitzlaff, and Christoph Scholz for comments that greatly improved the manuscript."}], "references": [{"title": "Language independent gender classification on twitter", "author": ["J.S. Alowibdi", "U.A. Buy", "P. Yu"], "venue": "IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, pages 739\u2013743. ACM,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Sex differences in responses to probability markers in advertising claims", "author": ["I.A. Berney-Reddish", "C.S. Areni"], "venue": "J. Advertising, 35(2):7\u201316,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Automatic discovery of personal name aliases from the web", "author": ["D. Bollegala", "Y. Matsuo", "M. Ishizuka"], "venue": "IEEE T. Knowl. Data En., 23(6):831\u2013844,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Discriminating gender on twitter", "author": ["J.D. Burger", "J. Henderson", "G. Kim", "G. Zarrella"], "venue": "Conference on Empirical Methods in Natural Language Processing, pages 1301\u20131309. ACL,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "LIBSVM: A library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Trans. Intell. Syst. Technol., 2(3):27:1\u201327:27,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Elizabeth and john: Sound patterns of men\u2019s and women\u2019s names", "author": ["A. Cutler", "J. McQueen", "K. Robinson"], "venue": "J. Linguist., 26(02):471\u2013482,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1990}, {"title": "Gender-specific patterns in patenting and publishing", "author": ["R. Frietsch", "I. Haller", "M. Funken-Vrohlings", "H. Grupp"], "venue": "Res. Policy, 38(4):590 \u2013 599,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Gender and (a)nonymity in computer-mediated communication", "author": ["S.C. Herring", "S. Stoerger"], "venue": "The Handbook of Language, Gender, and Sexuality, pages 567\u2013586. Wiley-Blackwell,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Belief in dangerous virtual communities as a predictor of continuance intention mediated by general and online social anxiety: The facebook perspective", "author": ["J.-C. Hong", "M.-Y. Hwang", "C.-H. Hsu", "K.-H. Tai", "Y.-C. Kuo"], "venue": "Comput. Hum. Behav., 48:663\u2013670,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Inferring gender from names on the web: A comparative evaluation of gender detection methods", "author": ["F. Karimi", "C. Wagner", "F. Lemmerich", "M. Jadidi", "M. Strohmaier"], "venue": "25th International Conference Companion on World Wide Web, pages 53\u201354. ACM,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Applied Linear Statistical Models", "author": ["M.H. Kutner", "C.J. Nachtsheim", "J. Neter", "W. Li"], "venue": "McGraw-Hill/Irwin,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "Gestalt Psychology: The Definitive Statement of the Gestalt Theory", "author": ["W. K\u00f6hler"], "venue": "Liveright,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1970}, {"title": "Classifying with co-stems", "author": ["N. Lipka", "B. Stein"], "venue": "Advances in Information Retrieval, pages 307\u2013313. Springer,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "What\u2019s in a name? using first names as features for gender inference in twitter", "author": ["W. Liu", "D. Ruths"], "venue": "Analyzing Microtext AAAI 2013 Spring Symposium, pages 10\u201316. AAAI,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Using social media to infer gender composition of commuter populations", "author": ["W. Liu", "F. Al Zamal", "D. Ruths"], "venue": "Workshop on When the City Meets the Citizen, 6th International AAAI Conference on Weblogs and Social Media, pages 26\u201329. AAAI,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Development of a stemming algorithm", "author": ["J.B. Lovins"], "venue": "Mechanical Translation and Computational Linguistics, 11(1&2):181\u2013187,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1968}, {"title": "The shape of boubas: Sound\u2013shape correspondences in toddlers and adults", "author": ["D. Maurer", "T. Pathman", "C.J. Mondloch"], "venue": "Developmental Sci., 9(3):316\u2013322,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2006}, {"title": "You are what you tweet...pic! gender prediction based on semantic analysis of social media images", "author": ["M. Merler", "L. Cao", "J.R. Smith"], "venue": "In International Conference on Multimedia and Expo,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "The sound of round: Evaluating the sound-symbolic role of consonants in the classic takete-maluma phenomenon", "author": ["A. Nielsen", "D. Rendall"], "venue": "Can. J. Exp. Psychol., 65 (2):115\u2013124,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Naming Gender: Empirische Untersuchungen zur phonologischen Struktur von Vornamen im Deutschen [Naming Gender: Empirical Studies on the Phonological Structure on German Given Names", "author": ["S. Oelkers"], "venue": "Lang,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}, {"title": "A machine learning approach to twitter user classification", "author": ["M. Pennacchiotti", "A.-M. Popescu"], "venue": "5th International AAAI Conference on Weblogs and Social Media, pages 281\u2013288. AAAI,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "An algorithm for suffix stripping", "author": ["M.F. Porter"], "venue": "Program, 14(3):130\u2013137,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1980}, {"title": "Learning age and gender of blogger from stylistic variation", "author": ["M. Rustagi", "R. Prasath", "S. Goswami", "S. Sarkar"], "venue": "Pattern Recognition and Machine Intelligence, pages 205\u2013212. Springer,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Die Personennamen im Deutschen: Eine Einf\u00fchrung [Personal Names in German: An Introduction", "author": ["W. Seibicke"], "venue": "De Gruyter Studienbuch. De Gruyte,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "What\u2019s in a name? sound symbolism and gender in first names", "author": ["D.M. Sidhu", "P.M. Pexman"], "venue": "PLOS ONE, 10(5):e0126809,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2015}, {"title": "Gender and the phonology of north american first names", "author": ["A.S. Slater", "S. Feinman"], "venue": "Sex Roles, 13(7-8):429\u2013 440,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1985}, {"title": "What\u2019s in a name: A study of names, gender inference, and gender behavior in facebook", "author": ["C. Tang", "K. Ross", "N. Saxena", "R. Chen"], "venue": "2nd International Workshop on Social Networks and Social Media Mining on the Web, 16th International Conference, pages 344\u2013356. Springer,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 8, "context": "Social scientists could study gender as an influence on human behavior in online communities [9] or on scientific and technological productivity from countries [7].", "startOffset": 93, "endOffset": 96}, {"referenceID": 6, "context": "Social scientists could study gender as an influence on human behavior in online communities [9] or on scientific and technological productivity from countries [7].", "startOffset": 160, "endOffset": 163}, {"referenceID": 1, "context": "The industry would gain additional information about their customers, which allows them to improve the efficiency of targeted advertisements [2].", "startOffset": 141, "endOffset": 144}, {"referenceID": 3, "context": "Amongst those, classification using Support Vector Machines (SVMs) have been found to be the best gender inference approaches [4, 14, 21].", "startOffset": 126, "endOffset": 137}, {"referenceID": 13, "context": "Amongst those, classification using Support Vector Machines (SVMs) have been found to be the best gender inference approaches [4, 14, 21].", "startOffset": 126, "endOffset": 137}, {"referenceID": 20, "context": "Amongst those, classification using Support Vector Machines (SVMs) have been found to be the best gender inference approaches [4, 14, 21].", "startOffset": 126, "endOffset": 137}, {"referenceID": 13, "context": "This was mentioned by Liu and Ruths [14] who conducted some experiments that are based on the self-reported name of the Twitter users as additional feature.", "startOffset": 36, "endOffset": 40}, {"referenceID": 7, "context": "But according to Herring and Stoerger [8], the number of users who masquerade themselves for someone else is not statistically significant and can be ignored in most cases.", "startOffset": 38, "endOffset": 41}, {"referenceID": 13, "context": "In their outlook, Liu and Ruths [14] considered a bigger name dictionary as promising improvement for their gender score.", "startOffset": 32, "endOffset": 36}, {"referenceID": 26, "context": "[27] proposed a gender inference classifier for Facebook users from New York City.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10] compared five gender inference tools in the realm of research names.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "Liu and Ruths [14] proposed a novel gender inference classifier using an SVM that uses the names of Twitter users as additional feature.", "startOffset": 14, "endOffset": 18}, {"referenceID": 25, "context": "Slater and Feinman [26] and Cutler et al.", "startOffset": 19, "endOffset": 23}, {"referenceID": 5, "context": "[6] discovered a significant correlation between name characteristics and the gender of North American names.", "startOffset": 0, "endOffset": 3}, {"referenceID": 19, "context": "Their findings were later transferred successfully to German names by Oelkers [20] and Seibicke [24].", "startOffset": 78, "endOffset": 82}, {"referenceID": 23, "context": "Their findings were later transferred successfully to German names by Oelkers [20] and Seibicke [24].", "startOffset": 96, "endOffset": 100}, {"referenceID": 24, "context": "Another promising approach to extract the gender of a name from its written word was discovered by Sidhu and Pexman [25].", "startOffset": 116, "endOffset": 120}, {"referenceID": 11, "context": "The Bouba/Kiki effect describes a nonarbitrary mapping between a speech sound and the visual shape of objects (see Figure 1) [12].", "startOffset": 125, "endOffset": 129}, {"referenceID": 16, "context": "Every name was assigned to either Bouba or Kiki beforehand based on the findings of previous research [17, 19].", "startOffset": 102, "endOffset": 110}, {"referenceID": 18, "context": "Every name was assigned to either Bouba or Kiki beforehand based on the findings of previous research [17, 19].", "startOffset": 102, "endOffset": 110}, {"referenceID": 13, "context": "We decided to use the Census and the nam dict data throughout our experiments for the following reasons: First, the Census data was used by Liu and Ruths [14] and we will use their results as baseline in Section 5.", "startOffset": 154, "endOffset": 158}, {"referenceID": 13, "context": "Liu and Ruths [14] were faced with the same issue and, therefore, created their own dataset and made it Table 1: Number of names contained in each genderlabeled name dataset.", "startOffset": 14, "endOffset": 18}, {"referenceID": 5, "context": "Therefore, we will first discuss the characteristics that were identified in onomastic research [6, 20, 24, 26]:", "startOffset": 96, "endOffset": 111}, {"referenceID": 19, "context": "Therefore, we will first discuss the characteristics that were identified in onomastic research [6, 20, 24, 26]:", "startOffset": 96, "endOffset": 111}, {"referenceID": 23, "context": "Therefore, we will first discuss the characteristics that were identified in onomastic research [6, 20, 24, 26]:", "startOffset": 96, "endOffset": 111}, {"referenceID": 25, "context": "Therefore, we will first discuss the characteristics that were identified in onomastic research [6, 20, 24, 26]:", "startOffset": 96, "endOffset": 111}, {"referenceID": 24, "context": "Further, one could use the findings of Sidhu and Pexman [25] and count vowels and consonants that are associated with Bouba or Kiki.", "startOffset": 56, "endOffset": 60}, {"referenceID": 16, "context": "Therefore, one can use four additional name characteristics using the encoding schema for Bouba/Kiki that is provided by previous work as follows [17, 19]:", "startOffset": 146, "endOffset": 154}, {"referenceID": 18, "context": "Therefore, one can use four additional name characteristics using the encoding schema for Bouba/Kiki that is provided by previous work as follows [17, 19]:", "startOffset": 146, "endOffset": 154}, {"referenceID": 10, "context": "[11], we removed this variable in order to remove the multicollinearity.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": ", LIBSVM [5]) with the radial basis function as kernel.", "startOffset": 9, "endOffset": 12}, {"referenceID": 13, "context": "We recall the gender score of Liu and Ruths [14] and introduce our refinement, the NamChar score.", "startOffset": 44, "endOffset": 48}, {"referenceID": 13, "context": "If this is not the case, Liu and Ruths [14] use a score of 0.", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "The gender score s(n) as introduced by Liu and Ruths [14] reflects the information that some names are more frequently assigned to male than to female people.", "startOffset": 53, "endOffset": 57}, {"referenceID": 13, "context": "Both plots show the same trimodal characteristics as in the original work by Liu and Ruths [14].", "startOffset": 91, "endOffset": 95}, {"referenceID": 13, "context": "Liu and Ruths [14] already identified this issue and separated the unknown names into five categories:", "startOffset": 14, "endOffset": 18}, {"referenceID": 13, "context": "Examples adopted from Liu and Ruths [14].", "startOffset": 36, "endOffset": 40}, {"referenceID": 13, "context": "Liu and Ruths [14] where not able to assign a valid gender score to two thirds of the Twitter users.", "startOffset": 14, "endOffset": 18}, {"referenceID": 13, "context": "The Threshold Classifier of Liu and Ruths [14] uses a twostep approach.", "startOffset": 42, "endOffset": 46}, {"referenceID": 13, "context": "85 by Liu and Ruths [14]).", "startOffset": 20, "endOffset": 24}, {"referenceID": 3, "context": "In Step 2, the remaining user\u2019s names are classified by an SVM with a radial basis function using a feature set that was developed in prior work [4, 14, 21, 23].", "startOffset": 145, "endOffset": 160}, {"referenceID": 13, "context": "In Step 2, the remaining user\u2019s names are classified by an SVM with a radial basis function using a feature set that was developed in prior work [4, 14, 21, 23].", "startOffset": 145, "endOffset": 160}, {"referenceID": 20, "context": "In Step 2, the remaining user\u2019s names are classified by an SVM with a radial basis function using a feature set that was developed in prior work [4, 14, 21, 23].", "startOffset": 145, "endOffset": 160}, {"referenceID": 22, "context": "In Step 2, the remaining user\u2019s names are classified by an SVM with a radial basis function using a feature set that was developed in prior work [4, 14, 21, 23].", "startOffset": 145, "endOffset": 160}, {"referenceID": 12, "context": "k-top co-stems (Lipka and Stein [13] demonstrate that the stem-reduced words, or co-stems, yield a significant improvement over classical bag of words models; for example, \u201cs\u201d for \u201cpapers\u201d), k-top digrams (the most discriminating digrams; for example, \u201cpa\u201d, \u201cap\u201d, \u201cpe\u201d, and \u201cer\u201d), k-top trigrams (the most discriminating trigrams; for example, \u201cpap\u201d, \u201cape\u201d, and \u201cper\u201d), and k-top hashtags (hashtags are labels that are attached by the users to their Tweet messages; for example, \u201cpaper\u201d for \u201c#paper\u201d).", "startOffset": 32, "endOffset": 36}, {"referenceID": 13, "context": "1 had been added as sole name-related feature by Liu and Ruths [14] in their original experiments.", "startOffset": 63, "endOffset": 67}, {"referenceID": 15, "context": "The stems are obtained by passing the words of all Tweets to the Lovins stemmer [16].", "startOffset": 80, "endOffset": 84}, {"referenceID": 21, "context": "The Porter stemmer [22] has become a de facto standard since then and has mostly replaced the Lovins stemmer.", "startOffset": 19, "endOffset": 23}, {"referenceID": 2, "context": "[3] proposed a method for this task that could be tested on Twitter names.", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "We considered some characteristics like the emphasized vowels or the finding of Sidhu and Pexman [25] about the application of the Bouba/Kiki effect as problematic, because we had no information about the proper pronunciation of the users\u2019 names.", "startOffset": 97, "endOffset": 101}, {"referenceID": 0, "context": "For instance, one could use text-independent approaches like using profile image attributes [1] or by extracting user attributes from the tweeted images [18].", "startOffset": 92, "endOffset": 95}, {"referenceID": 17, "context": "For instance, one could use text-independent approaches like using profile image attributes [1] or by extracting user attributes from the tweeted images [18].", "startOffset": 153, "endOffset": 157}], "year": 2016, "abstractText": "Much attention has been given to the task of gender inference of Twitter users. Although names are strong gender indicators, the names of Twitter users are rarely used as a feature; probably due to the high number of ill-formed names, which cannot be found in any name dictionary. Instead of relying solely on a name database, we propose a novel name classifier. Our approach extracts characteristics from the user names and uses those in order to assign the names to a gender. This enables us to classify international first names as well as ill-formed names.", "creator": "LaTeX with hyperref package"}}}