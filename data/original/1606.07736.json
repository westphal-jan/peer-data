{"id": "1606.07736", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2016", "title": "Issues in evaluating semantic spaces using word analogies", "abstract": "The offset method for solving word analogies has become a standard evaluation tool for vector-space semantic models: it is considered desirable for a space to represent semantic relations as consistent vector offsets. We show that the method's reliance on cosine similarity conflates offset consistency with largely irrelevant neighborhood structure, and propose simple baselines that should be used to improve the utility of the method in vector space evaluation.", "histories": [["v1", "Fri, 24 Jun 2016 15:59:14 GMT  (278kb,D)", "http://arxiv.org/abs/1606.07736v1", "6 pages; The First Workshop on Evaluating Vector Space Representations for NLP"]], "COMMENTS": "6 pages; The First Workshop on Evaluating Vector Space Representations for NLP", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["tal linzen"], "accepted": false, "id": "1606.07736"}, "pdf": {"name": "1606.07736.pdf", "metadata": {"source": "CRF", "title": "Issues in evaluating semantic spaces using word analogies", "authors": ["Tal Linzen"], "emails": ["tal.linzen@ens.fr"], "sections": [{"heading": "1 Introduction", "text": "Vector space models of semantics (VSMs) represent words as points in a high-dimensional space (Turney and Pantel, 2010). There is considerable interest in evaluating VSMs without needing to embed them in a complete NLP system. One such intrinsic evaluation strategy that has gained in popularity in recent years uses the offset approach to solving word analogy problems (Levy and Goldberg, 2014; Mikolov et al., 2013c; Mikolov et al., 2013a; Turney, 2012). This method assesses whether a linguistic relation \u2014 for example, between the base and gerund form of a verb (debug and debugging) \u2014 is consistently encoded as a particular linear offset in the space. If that is the case, estimating the offset using one pair of words related in a particular way should enable us to go back and forth between other pairs of words that are related in the same way, e.g., scream and screaming in the base-to-gerund case (Figure 1).\nSince VSMs are typically continuous spaces, adding the offset between debug and debugging to scream is unlikely to land us exactly on any particular word. The solution to the analogy problem is therefore taken to be the word closest in\ncosine similarity to the landing point. Formally, if the analogy is given by\na : a\u2217 :: b : (1)\nwhere in our example a is debug, a\u2217 is debugging and b is scream, then the proposed answer to the analogy problem is\nx\u2217 = argmax x\u2032 cos(x\u2032, a\u2217 \u2212 a+ b) (2)\nwhere cos(v, w) =\nv \u00b7 w \u2016v\u2016\u2016w\u2016\n(3)\nThe central role of cosine similarity in this method raises the concern that the method does not only evaluate the consistency of the offsets a\u2217\u2212 a and b\u2217\u2212 b but also the neighborhood structure of x = a\u2217\u2212a+b. For instance, if a\u2217 and a are very similar to each other (as scream and screaming are likely to be) the nearest word to x may simply be the nearest neighbor of b. If in a given set of analogies the nearest neighbor of b tends to be b\u2217, then, the method may give the correct answer regardless of the consistency of the offsets (Figure 2).\nIn this note we assess to what extent the performance of the offset method provides evidence for offset consistency despite its potentially problematic reliance on cosine similarity. We use two\nar X\niv :1\n60 6.\n07 73\n6v 1\n[ cs\n.C L\n] 2\n4 Ju\nn 20\n16\nmethods. First, we propose new baselines that perform the task without using the offset a\u2217 \u2212 a and argue that the performance of the offset method should be compared to those baselines. Second, we measure how the performance of the method is affected by reversing the direction of each analogy problem (Figure 3). If the method truly measures offset consistency, this reversal should not affect its accuracy."}, {"heading": "2 Analogy functions", "text": "We experiment with the following functions. In all of the methods, every word in the vocabulary can serve as a guess, except when a, a\u2217 or b are explicitly excluded as noted below. Since the size of the vocabulary is typically very large, chance performance, or the probability of a random word in the vocabulary being the correct guess, is extremely low.\nVANILLA: This function implements the offset method literally (Equation 2).\nADD: The x\u2217 obtained from Equation 2 is often trivial (typically equal to b). In practice, most studies exclude a, a\u2217 and b from consideration:\nx\u2217 = argmax x\u2032 6\u2208{a,a\u2217,b} cos(x\u2032, a\u2217 \u2212 a+ b) (4)\nONLY-B: This method ignores both a and a\u2217 and simply returns the nearest neighbor of b:\nx\u2217 = argmax x\u2032 6\u2208{a,a\u2217,b} cos(x\u2032, b) (5)\nAs shown in Figure 2, this baseline is likely to give a correct answer in cases where a\u2217\u2212a is small and b\u2217 happens to be the nearest neighbor of b.\nIGNORE-A: This baseline ignores a and returns the word that is most similar to both a\u2217 and b:\nx\u2217 = argmax x\u2032 6\u2208{a,a\u2217,b} cos(x\u2032, a\u2217 + b) (6)\nA correct answer using this method indicates that b\u2217 is closest to a point y that lies mid-way between a\u2217 and b (i.e. that maximizes the similarity to both words).\nADD-OPPOSITE: This function takes the logic behind the ONLY-B baseline a step further \u2013 if the neighborhood of b is sufficiently sparse, we will get the correct answer even if we go in the opposite direction from the offset a\u2217 \u2212 a:\nx\u2217 = argmax x\u2032 6\u2208{a,a\u2217,b} cos(x\u2032,\u2212(a\u2217 \u2212 a) + b) (7)\nMULTIPLY: Levy and Goldberg (2014) show that Equation 2 is equivalent to adding and subtracting cosine similarities, and propose replacing it with multiplication and division of similarities:\nx\u2217 = argmax x\u2032 6\u2208{a,a\u2217,b}\ncos(x\u2032, a\u2217) cos(x\u2032, b)\ncos(x\u2032, a) (8)\nREVERSE (ADD): This is simply ADD applied to the reverse analogy problem: if the original problem is debug : debugging :: scream : , the reverse problem is debugging : debug :: screaming : . A substantial difference in accuracy between the two directions in a particular type of analogy problem (e.g., base-to-gerund compared to gerund-to-base) would indicate that the neighborhoods of one of the word categories (e.g., gerund) tend to be sparser than the neighborhoods of the other type (e.g., base).\nREVERSE (ONLY-B): This baseline is equivalent to ONLY-B, but applied to the reverse problem: it returns b\u2217, in the notation of the original analogy problem."}, {"heading": "3 Experimental setup", "text": "Analogy problems: We use the analogy dataset proposed by Mikolov et al. (2013a). This dataset, which has become a standard VSM evaluation set (Baroni et al., 2014; Faruqui et al., 2015; Schnabel et al., 2015; Zhai et al., 2016), contains 14 categories; see Table 1 for a full list. A number of these categories, sometimes referred to as \u201csyntactic\u201d, test whether the structure of the space captures simple morphological relations, such as the relation between the base and gerund form of a verb (scream : screaming). Others evaluate the knowledge that the space encodes about the world, e.g., the relation between a country and its currency (latvia : lats). A final category that doesn\u2019t fit neatly into either of those groups is the relation between masculine and feminine versions of the same concept (groom : bride). We follow Levy and Goldberg (2014) in calculating separate accuracy measures for each category.\nSemantic spaces: In addition to comparing the performance of the analogy functions within a single VSM, we seek to understand to what extent this performance can differ across VSMs. To this end, we selected three VSMs out of the set of spaces evaluated by Linzen et al. (2016). All three spaces were produced by the skip-gram with negative sampling algorithm implemented in word2vec (Mikolov et al., 2013b), and were trained on the concatenation of ukWaC (Baroni et al., 2009) and a 2013 dump of the English Wikipedia.\nThe spaces, which we refer to as s2, s5 and s10, differed only in their context window parameters. In s2, the window consisted of two words on ei-\nther side of the focus word. In s5 it included five words on either side of the focus word, and was \u201cdynamic\u201d \u2013 that is, it was expanded if any of the context words were excluded for low or high frequency (for details, see Levy et al. (2015)). Finally, the context in s10 was a dynamic window of ten words on either side. All other hyperparameters were set to standard values."}, {"heading": "4 Results", "text": "Baselines: Figure 4 shows the success of all of the analogy functions in recovering the intended analogy target b\u2217 in space s5. In line with Levy and Goldberg (2014), there was a slight advantage for MULTIPLY over ADD (mean difference in accuracy: .03), as well as dramatic variability across categories (ranging from .13 to .90 in ADD). This variability cuts across the distinction between the world-knowledge and morphological categories; performance on currencies and adjectives-to-adverbs was poor, while performance on capitals and comparatives was high.\nAlthough ADD and MULTIPLY always outperformed the baselines, the margin varied widely across categories. The most striking case is the plurals category, where the accuracy of ONLY-B reached .70, and even ADD-OPPOSITE achieved\na decent accuracy (.45). Taking a\u2217 but not a into account (IGNORE-A) outperformed ONLY-B in ten out of 14 categories. Finally, the poor performance of VANILLA confirms that a, a\u2217 and b must be excluded from the pool of potential answers for the offset method to work. When these words were not excluded, the nearest neighbor of a\u2217 \u2212 a + b was b in 93% of the cases and a\u2217 in 5% of the cases (it was never a).\nReversed analogies: Accuracy decreased in most categories when the direction of the analogy was reversed (mean difference \u22120.11). The changes in the accuracy of ADD between the original and reversed problems were correlated across categories with the changes in the performance of the ONLY-B baseline before and after reversal (Pearson\u2019s r = .72). The fact that the performance of the baseline that ignores the offset was a reliable predictor of the performance of the offset method again suggests that the offset method when applied to the Mikolov et al. (2013a) sets jointly evaluates the consistency of the offsets and the probability that b\u2217 is the nearest neighbor of b.\nThe most dramatic decrease was in the US cities category (.69 to .17). This is plausibly due to the fact that the city-to-state relation is a many-to-one mapping; as such, the offsets derived from two specific city-states pairs \u2014 e.g., Sacramento:California and Chicago:Illinois \u2014 are unlikely to be exactly the same. Another sharp decrease was observed in the common capitals category (.9 to .53), even though that category is presumably a one-to-one mapping.\nComparison across spaces: The overall accuracy of ADD was similar across spaces, with a small advantage for s5 (Table 2). Yet the breakdown of the results by category (Figure 5) shows that the similarity in average performance across the spaces obscures differences across categories: s2 performed much better than s10 in some of the morphological inflection categories (e.g., .7 compared to .44 for the base-to-third-person relation),\nwhereas s10 had a large advantage in some of the world-knowledge categories (e.g., .68 compared to .42 in the US cities category). The advantage of smaller window sizes in capturing \u201csyntactic\u201d information is consistent with previous studies (Redington et al., 1998; Sahlgren, 2006). Note also that overall accuracy figures are potentially misleading in light of the considerable variability in the number of analogies in each category (see Table 1): the \u201call capitals\u201d category has a much greater effect on overall accuracy than gender, for example.\nSpaces also differed in how much ADD improved over the baselines. The overall advantage over the baselines was highest for s2 and lowest for s10 (Table 2). In particular, although accuracy was similar across spaces in the nationalities and common capitals categories, much more of this accuracy was already captured by the IGNORE-A baseline in s10 than in s2 (Figure 5)"}, {"heading": "5 Discussion", "text": "The success of the offset method in solving word analogy problems has been taken to indicate that systematic relations between words are represented in the space as consistent vector offsets\n(Mikolov et al., 2013c). The present note has examined potential difficulties with this interpretation. A literal (\u201cvanilla\u201d) implementation of the method failed to perform the task: the nearest neighbor of a\u2217\u2212a+b was almost always b or a\u2217.1 Even when those candidates were excluded, some of the success of the method on the analogy sets that we considered could also be obtained by baselines that ignored a or even both a and a\u2217. Finally, reversing the direction of the analogy affected accuracy substantially, even though the same offset was involved in both directions.\nThe performance of the baselines varied widely across analogy categories. Baseline performance was poor in the adjective-to-superlative relation, and was very high in the plurals category (even when both a and a\u2217 were ignored). This suggests that analogy problems in the plural category category may not measure whether the space encodes the single-to-plural relation as a vector offset, but rather whether the plural form of a noun tends to be close in the vector space to its singular form. Baseline performance varied across spaces as well; in fact, the space with the weakest overall performance (s2) showed the largest increases over the baselines, and therefore the most evidence for consistent offsets.\nWe suggest that future studies employing the analogy task report the performance of the simple baselines we have suggested, in particular ONLYB and possibly also IGNORE-A. Other methods for evaluating the consistency of vector offsets may be less vulnerable to trivial responses and neighborhood structure, and should be considered instead of the offset method (Dunbar et al., 2015).\nOur results also highlight the difficulty in comparing spaces based on accuracy measures averaged across heterogeneous and unbalanced analogy sets (Gladkova et al., 2016). Spaces with similar overall accuracy can vary in their success on particular categories of analogies; effective representations of \u201cworld-knowledge\u201d information are likely to be useful for different downstream tasks than effective representations of formal linguistic properties. Greater attention to the fine-grained strengths of particular spaces may lead to the\n1A human with any reasonable understanding of the analogy task is likely to also exclude a, a\u2217 and b as possible responses, of course. However, such heuristics that are baked into an analogy solver, while likely to improve its performance, call into question the interpretation of the success of the analogy solver as evidence for the geometric organization of the underlying semantic space.\ndevelopment of new spaces that combine these strengths."}, {"heading": "Acknowledgments", "text": "I thank Ewan Dunbar, Emmanuel Dupoux, Omer Levy and Benjamin Spector for comments and discussion. This research was supported by the European Research Council (grant ERC-2011-AdG 295810 BOOTPHON) and the Agence Nationale pour la Recherche (grants ANR-10-IDEX-000102 PSL and ANR-10-LABX-0087 IEC)."}], "references": [{"title": "The WaCky wide web: a collection of very large linguistically processed web-crawled corpora", "author": ["Marco Baroni", "Silvia Bernardini", "Adriano Ferraresi", "Eros Zanchetta."], "venue": "Language Resources and Evaluation, 43(3):209\u2013226.", "citeRegEx": "Baroni et al\\.,? 2009", "shortCiteRegEx": "Baroni et al\\.", "year": 2009}, {"title": "Don\u2019t count, predict! A systematic comparison of context-counting vs", "author": ["Marco Baroni", "Georgiana Dinu", "Germ\u00e1n Kruszewski."], "venue": "context-predicting semantic vectors. In Proceedings of the 52nd Annual Meeting of the Association for", "citeRegEx": "Baroni et al\\.,? 2014", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Quantitative methods for comparing featural representations", "author": ["Ewan Dunbar", "Gabriel Synnaeve", "Emmanuel Dupoux."], "venue": "Proceedings of the 18th International Congress of Phonetic Sciences.", "citeRegEx": "Dunbar et al\\.,? 2015", "shortCiteRegEx": "Dunbar et al\\.", "year": 2015}, {"title": "Retrofitting word vectors to semantic lexicons", "author": ["Manaal Faruqui", "Jesse Dodge", "Sujay Kumar Jauhar", "Chris Dyer", "Eduard Hovy", "Noah A. Smith."], "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association", "citeRegEx": "Faruqui et al\\.,? 2015", "shortCiteRegEx": "Faruqui et al\\.", "year": 2015}, {"title": "Analogy-based detection of morphological and semantic relations with word embeddings: what works and what doesn\u2019t", "author": ["Anna Gladkova", "Aleksandr Drozd", "Satoshi Matsuoka."], "venue": "Proceedings of the NAACL Student Research Workshop, pages", "citeRegEx": "Gladkova et al\\.,? 2016", "shortCiteRegEx": "Gladkova et al\\.", "year": 2016}, {"title": "Linguistic regularities in sparse and explicit word representations", "author": ["Omer Levy", "Yoav Goldberg."], "venue": "Proceedings of the Eighteenth Conference on Computational Language Learning, pages 171\u2013 180.", "citeRegEx": "Levy and Goldberg.,? 2014", "shortCiteRegEx": "Levy and Goldberg.", "year": 2014}, {"title": "Improving distributional similarity with lessons learned from word embeddings", "author": ["Omer Levy", "Yoav Goldberg", "Ido Dagan."], "venue": "Transactions of the Association for Computational Linguistics, 3:211\u2013225.", "citeRegEx": "Levy et al\\.,? 2015", "shortCiteRegEx": "Levy et al\\.", "year": 2015}, {"title": "Quantificational features in distributional word representations", "author": ["Tal Linzen", "Emmanuel Dupoux", "Benjamin Spector."], "venue": "Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics (*SEM 2016).", "citeRegEx": "Linzen et al\\.,? 2016", "shortCiteRegEx": "Linzen et al\\.", "year": 2016}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "Proceedings of ICLR.", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg Corrado", "Jeff Dean."], "venue": "Advances in Neural Information Processing Systems, pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Linguistic regularities in continuous space word representations", "author": ["Tomas Mikolov", "Wen-tau Yih", "Geoffrey Zweig."], "venue": "Proceedings of NAACLHLT, pages 746\u2013751.", "citeRegEx": "Mikolov et al\\.,? 2013c", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributional information: A powerful cue for acquiring syntactic categories", "author": ["Martin Redington", "Nick Chater", "Steven Finch."], "venue": "Cognitive Science, 22(4):425\u2013469.", "citeRegEx": "Redington et al\\.,? 1998", "shortCiteRegEx": "Redington et al\\.", "year": 1998}, {"title": "The Word-Space Model: Using distributional analysis to represent syntagmatic and paradigmatic relations between words in highdimensional vector spaces", "author": ["Magnus Sahlgren."], "venue": "Ph.D. thesis, Stockholm University.", "citeRegEx": "Sahlgren.,? 2006", "shortCiteRegEx": "Sahlgren.", "year": 2006}, {"title": "Evaluation methods for unsupervised word embeddings", "author": ["Tobias Schnabel", "Igor Labutov", "David Mimno", "Thorsten Joachims."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Schnabel et al\\.,? 2015", "shortCiteRegEx": "Schnabel et al\\.", "year": 2015}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["Peter D. Turney", "Patrick Pantel."], "venue": "Journal of Artificial Intelligence Research, 37(1):141\u2013188.", "citeRegEx": "Turney and Pantel.,? 2010", "shortCiteRegEx": "Turney and Pantel.", "year": 2010}, {"title": "Domain and function: A dual-space model of semantic relations and compositions", "author": ["Peter D Turney."], "venue": "Journal of Artificial Intelligence Research, pages 533\u2013585.", "citeRegEx": "Turney.,? 2012", "shortCiteRegEx": "Turney.", "year": 2012}, {"title": "Intrinsic and extrinsic evaluations of word embeddings", "author": ["Michael Zhai", "Johnny Tan", "Jinho D Choi."], "venue": "Thirtieth AAAI Conference on Artificial Intelligence.", "citeRegEx": "Zhai et al\\.,? 2016", "shortCiteRegEx": "Zhai et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 14, "context": "Vector space models of semantics (VSMs) represent words as points in a high-dimensional space (Turney and Pantel, 2010).", "startOffset": 94, "endOffset": 119}, {"referenceID": 5, "context": "One such intrinsic evaluation strategy that has gained in popularity in recent years uses the offset approach to solving word analogy problems (Levy and Goldberg, 2014; Mikolov et al., 2013c; Mikolov et al., 2013a; Turney, 2012).", "startOffset": 143, "endOffset": 228}, {"referenceID": 10, "context": "One such intrinsic evaluation strategy that has gained in popularity in recent years uses the offset approach to solving word analogy problems (Levy and Goldberg, 2014; Mikolov et al., 2013c; Mikolov et al., 2013a; Turney, 2012).", "startOffset": 143, "endOffset": 228}, {"referenceID": 8, "context": "One such intrinsic evaluation strategy that has gained in popularity in recent years uses the offset approach to solving word analogy problems (Levy and Goldberg, 2014; Mikolov et al., 2013c; Mikolov et al., 2013a; Turney, 2012).", "startOffset": 143, "endOffset": 228}, {"referenceID": 15, "context": "One such intrinsic evaluation strategy that has gained in popularity in recent years uses the offset approach to solving word analogy problems (Levy and Goldberg, 2014; Mikolov et al., 2013c; Mikolov et al., 2013a; Turney, 2012).", "startOffset": 143, "endOffset": 228}, {"referenceID": 10, "context": "Figure 1: Using the vector offset method to solve the analogy task (Mikolov et al., 2013c).", "startOffset": 67, "endOffset": 90}, {"referenceID": 5, "context": "MULTIPLY: Levy and Goldberg (2014) show that Equation 2 is equivalent to adding and subtracting cosine similarities, and propose replacing it with multiplication and division of similarities:", "startOffset": 10, "endOffset": 35}, {"referenceID": 8, "context": "Table 1: The analogy categories of Mikolov et al. (2013a) and the number of problems per category.", "startOffset": 35, "endOffset": 58}, {"referenceID": 1, "context": "This dataset, which has become a standard VSM evaluation set (Baroni et al., 2014; Faruqui et al., 2015; Schnabel et al., 2015; Zhai et al., 2016), contains 14 categories; see Table 1 for a full list.", "startOffset": 61, "endOffset": 146}, {"referenceID": 3, "context": "This dataset, which has become a standard VSM evaluation set (Baroni et al., 2014; Faruqui et al., 2015; Schnabel et al., 2015; Zhai et al., 2016), contains 14 categories; see Table 1 for a full list.", "startOffset": 61, "endOffset": 146}, {"referenceID": 13, "context": "This dataset, which has become a standard VSM evaluation set (Baroni et al., 2014; Faruqui et al., 2015; Schnabel et al., 2015; Zhai et al., 2016), contains 14 categories; see Table 1 for a full list.", "startOffset": 61, "endOffset": 146}, {"referenceID": 16, "context": "This dataset, which has become a standard VSM evaluation set (Baroni et al., 2014; Faruqui et al., 2015; Schnabel et al., 2015; Zhai et al., 2016), contains 14 categories; see Table 1 for a full list.", "startOffset": 61, "endOffset": 146}, {"referenceID": 4, "context": "Analogy problems: We use the analogy dataset proposed by Mikolov et al. (2013a). This dataset, which has become a standard VSM evaluation set (Baroni et al.", "startOffset": 57, "endOffset": 80}, {"referenceID": 0, "context": "This dataset, which has become a standard VSM evaluation set (Baroni et al., 2014; Faruqui et al., 2015; Schnabel et al., 2015; Zhai et al., 2016), contains 14 categories; see Table 1 for a full list. A number of these categories, sometimes referred to as \u201csyntactic\u201d, test whether the structure of the space captures simple morphological relations, such as the relation between the base and gerund form of a verb (scream : screaming). Others evaluate the knowledge that the space encodes about the world, e.g., the relation between a country and its currency (latvia : lats). A final category that doesn\u2019t fit neatly into either of those groups is the relation between masculine and feminine versions of the same concept (groom : bride). We follow Levy and Goldberg (2014) in calculating separate accuracy measures for each category.", "startOffset": 62, "endOffset": 774}, {"referenceID": 9, "context": "All three spaces were produced by the skip-gram with negative sampling algorithm implemented in word2vec (Mikolov et al., 2013b), and were trained on the concatenation of ukWaC (Baroni et al.", "startOffset": 105, "endOffset": 128}, {"referenceID": 0, "context": ", 2013b), and were trained on the concatenation of ukWaC (Baroni et al., 2009) and a 2013 dump of the English Wikipedia.", "startOffset": 57, "endOffset": 78}, {"referenceID": 5, "context": "To this end, we selected three VSMs out of the set of spaces evaluated by Linzen et al. (2016). All three spaces were produced by the skip-gram with negative sampling algorithm implemented in word2vec (Mikolov et al.", "startOffset": 74, "endOffset": 95}, {"referenceID": 6, "context": "In s5 it included five words on either side of the focus word, and was \u201cdynamic\u201d \u2013 that is, it was expanded if any of the context words were excluded for low or high frequency (for details, see Levy et al. (2015)).", "startOffset": 194, "endOffset": 213}, {"referenceID": 5, "context": "In line with Levy and Goldberg (2014), there was a slight advantage for MULTIPLY over ADD (mean difference in accuracy: .", "startOffset": 13, "endOffset": 38}, {"referenceID": 8, "context": "The fact that the performance of the baseline that ignores the offset was a reliable predictor of the performance of the offset method again suggests that the offset method when applied to the Mikolov et al. (2013a) sets jointly evaluates the consistency of the offsets and the probability that b\u2217 is the nearest neighbor of b.", "startOffset": 193, "endOffset": 216}, {"referenceID": 11, "context": "The advantage of smaller window sizes in capturing \u201csyntactic\u201d information is consistent with previous studies (Redington et al., 1998; Sahlgren, 2006).", "startOffset": 111, "endOffset": 151}, {"referenceID": 12, "context": "The advantage of smaller window sizes in capturing \u201csyntactic\u201d information is consistent with previous studies (Redington et al., 1998; Sahlgren, 2006).", "startOffset": 111, "endOffset": 151}, {"referenceID": 10, "context": "(Mikolov et al., 2013c).", "startOffset": 0, "endOffset": 23}, {"referenceID": 2, "context": "Other methods for evaluating the consistency of vector offsets may be less vulnerable to trivial responses and neighborhood structure, and should be considered instead of the offset method (Dunbar et al., 2015).", "startOffset": 189, "endOffset": 210}, {"referenceID": 4, "context": "Our results also highlight the difficulty in comparing spaces based on accuracy measures averaged across heterogeneous and unbalanced analogy sets (Gladkova et al., 2016).", "startOffset": 147, "endOffset": 170}], "year": 2016, "abstractText": "The offset method for solving word analogies has become a standard evaluation tool for vector-space semantic models: it is considered desirable for a space to represent semantic relations as consistent vector offsets. We show that the method\u2019s reliance on cosine similarity conflates offset consistency with largely irrelevant neighborhood structure, and propose simple baselines that should be used to improve the utility of the method in vector space evaluation.", "creator": "TeX"}}}