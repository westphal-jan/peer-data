{"id": "1606.08733", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jun-2016", "title": "Recurrent Neural Networks for Dialogue State Tracking", "abstract": "This paper discusses models for dialogue state tracking using recurrent neural networks (RNN). We present experiments on the standard dialogue state tracking (DST) dataset, DSTC2 [6]. On the one hand, RNN models became state of the art in DST, on the other hand, most state-of-the-art models are only turn-based and require dataset-specific preprocessing (e.g. DSTC2-specific) in order to achieve state-of-the-art results. We implemented two architectures which can be used in incremental settings and require almost no preprocessing. We compare their performance to the benchmarks on DSTC2 and discuss their properties. With only trivial preprocessing, the performance of our models is close to the state-of-the-art results.", "histories": [["v1", "Tue, 28 Jun 2016 14:33:29 GMT  (48kb,D)", "https://arxiv.org/abs/1606.08733v1", "preprint"], ["v2", "Wed, 13 Jul 2016 21:42:58 GMT  (49kb,D)", "http://arxiv.org/abs/1606.08733v2", "Accepted to slo-nlp 2016"]], "COMMENTS": "preprint", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ond\\v{r}ej pl\\'atek", "petr b\\v{e}lohl\\'avek", "vojt\\v{e}ch hude\\v{c}ek", "filip jur\\v{c}\\'i\\v{c}ek"], "accepted": false, "id": "1606.08733"}, "pdf": {"name": "1606.08733.pdf", "metadata": {"source": "CRF", "title": "Recurrent Neural Networks for Dialogue State Tracking", "authors": ["Ond\u0159ej Pl\u00e1tek", "Petr B\u011blohl\u00e1vek", "Vojt\u011bch Hude\u010dek", "Filip Jur\u010d\u00ed\u010dek"], "emails": ["oplatek@ufal.mff.cuni.cz,", "jurcicek@ufal.mff.cuni.cz,", "me@petrbel.cz,", "vojta.hudecek@gmail.com,"], "sections": [{"heading": "1 Introduction", "text": "Dialogue state tracking (DST) is a standard and important task for evaluating task-oriented conversational agents [18, 7, 8]. Such agents play the role of a domain expert in a narrow domain, and users ask for information through conversation in natural language (see the example system and user responses in Figure 1). A dialogue state tracker summarizes the dialogue history and maintains a probability distribution over the (possible) user\u2019s goals (see annotation in Figure 1). Dialogue agents as introduced in [20] decide about the next action based on the dialogue state distribution given by the tracker. User\u2019s goals are expressed in a formal language, typically represented as a dialogue act items (DAIs) (see Section 2) and the tracker updates probability for each item. The dialogue state is a latent variable [20] and one needs to label the conversations in order to train a dialogue state tracker using supervised learning. It was shown that with a better dialogue state tracker, conversation agents achieve better success rate in overall completion of the their task [11].\n1Acknowledgment: We thank Mirek Vodol\u00e1n and Ondr\u030cej Du\u0161ek for useful comments. This research was partly funded by the Ministry of Education, Youth and Sports of the Czech Republic under the grant agreement LK11221, core research funding, grant GAUK 1915/2015, and also partially supported by SVV project number 260 333. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Tesla K40c GPU used for this research. Computational resources were provided by the CESNET LM2015042 and the CERIT Scientific Cloud LM2015085, provided under the programme \u201cProjects of Large Research, Development, and Innovations Infrastructures\u201d.\n. . . Dial. state n: food:None, area:None, pricerange:None System: What part of town do you have in mind? User: West part of town. Dial. state n+1: food:None, area:west, pricerange:None System: What kind of food would you like? User: Indian Dial. state n+2: food:Indian, area:west, pricerange:None System: India House is a nice place in the west of town serving tasty Indian food. . . .\nFigure 1: Example of golden annotation of Dialogue Act Items (DAIs). The dialogue act items comprise from act type (all examples have type inform) and slots (food, area, pricerange) and their values (e.g. Indian, west, None).\nThis paper compares two different RNN architectures for dialogue state tracking (see Section 3). We describe state-of-the art word-by-word dialogue state tracker architectures and propose to use a new encoder-decoder architecture for the DST task (see Section 4.2).\nWe focus only on the goal slot predictions because the other groups are trivial to predict2.\nWe also experiment with re-splitting of the DSTC2 data because there are considerable differences between the standard train and test datasets [7]. Since the training, development and test set data are distributed differently, the resulting performance difference between training and test data is rather high. Based on our experiments, we conclude that DSTC2 might suggest a too pessimistic view of the state-of-the-art methods in dialogue state tracking caused by the data distribution mismatch."}, {"heading": "2 Dialogue state tracking on DSTC2 dataset", "text": "Dialogue state trackers maintain their believes beliefs about users\u2019 goals by updating probabilities of dialogue history representations. In the DSTC2 dataset, the history is captured by dialogue act items and their probabilities. A Dialogue act item is a triple of the following form (actionType,slotName,slotValue).\nThe DSTC2 is a standard dataset for DST, and most of the state-of-the-art systems in DST have reported their per-\n2The slots Requested and Method have accuracies 0.95 and 0.95 on the test set according to the state-of-the-art [19].\nar X\niv :1\n60 6.\n08 73\n3v 2\n[ cs\n.C L\n] 1\n3 Ju\nl 2 01\n6\nformance on this dataset [7]. The full dataset is freely available since January 2014 and it contains 1612 dialogues in the training set, 506 dialogues in the development set and 1117 dialogues in the test set.3 The conversations are manually annotated at the turn level where the hidden information state is expressed in form of (actionType,slotName,slotValue) based on the domain ontology. The task of the domain is defined by a database of restaurants and their properties4. The database and the manually designed ontology that captures a restaurant domain are both distributed with the dataset."}, {"heading": "3 Models", "text": "Our models are all based on a RNN encoder [17]. The models update their hidden states h after processing each word similarly to the RNN encoder of \u017dilka and Jurc\u030c\u00edc\u030cek [16]. The encoder takes as inputs the previous state ht\u22121, representing history for first t \u2212 1 words, and features Xt for the current word wt . It outputs the current state ht representing the whole dialogue history up to current word. We use a Gated Recurrent Unit (GRU) cell [5] as the update function instead of a simple RNN cell because it does not suffer from the vanishing gradient problem [10]. The model optimizes its parameters including word embeddings [3] during training.\nFor each input token, our RNN encoder reads the word embedding of this token along with several binary features. The binary features for each word are:\n\u2022 the speaker role, representing either user or system,\n\u2022 and also indicators describing whether the word is part of a named entity representing a value from the database.\nSince the DSTC2 database is a simple table with six columns, we introduce six binary features firing if the word is a substring of named entity from the given column. For example, the word indian will not only trigger the feature for column f ood and its value indian but also for column restaurant name and its value indian heaven. The features make the data dense by abstracting the meaning from the lexical level.\nOur model variants differ only in the way they predict goal labels, i.e., f ood, area and pricerange from the RNN\u2019s last encoded state.5 The first model predicts the output slot labels independently by employing three independent classifiers (see Section 3.1). The second model uses a decoder in order to predict values one after the other from the hT (see Section 3.2).\nThe models were implemented using the TensorFlow [1] framework.\n3Available online at http://camdial.org/~mh521/dstc/. 4There are six columns in the database: name, food, price_range, area, telephone, address. 5Accuracy measure with schedule 2 on slot f ood, area and pricerange about which users can inform the system is a featured metric for DSTC2 challenge [7]."}, {"heading": "3.1 Independent classifiers for each label", "text": "The independent model (see Figure 3.1) consists of three models which predict f ood, area and pricerange based on the last hidden state hT independently. The independent slot prediction that uses one classifier per slot is straightforward to implement, but the model introduces an unrealistic assumption of uncorrelated slot properties. In case of DSTC2 and the Cambridge restaurant domain, it is hard to believe that, e.g., the slots area and pricerange are not correlated.\nWe also experimented with a single classifier which predicts the labels jointly (see Figure 3) but it suffers from data sparsity of the predicted tuples, so we focused only on the independent label prediction and encoder-decoder models."}, {"heading": "3.2 Encoder-decoder framework", "text": "We cast the slot predictions problem as a sequence-tosequence predictions task and we use a encoder-decoder model with attention [2] to learn this representation together with slot predictions (see Figure 4). To our knowledge, we are the first who used this model for dialogue state tracking. The model is successfully used in machine translation where it is able to handle long sequences with good accuracy [2]. In DST, it captures correlation between the decoded slots easily. By introducing the encoderdecoder architecture, we aim to overcome the data sparsity problem and the incorrect independence assumptions.\nXT Slot1 Slot2 Slot3 EOS\nWe employ the encoder RNN cell that captures the history of the dialogue which is represented as a sequence of words from the user and the system. The words are fed to the encoder as they appear in the dialogue - turn by turn - where the user and the system responses switch regularly. The encoder updates its internal state hT after each processed word. The RNN decoder model is used when the system needs to generate its output, in our case it is at the end of the user response. The decoder generates arbitrary length sequences of words given the encoded state hT step by step. In each step, an output word and a new hidden state hT+1 is generated. The generation process is finished when a special token End of Sequence (EOS) is decoded. This mechanism allows the model to terminate the output sequence. The attention part of model is used at decoding time for weighting the importance of the history.\nThe disadvantage of this model is its complexity. Firstly, the model is not trivial to implement6. Secondly, the decoding time is asymptotically quadratic in the length of the decoded sequences, but our target sequences are always four tokens long nevertheless."}, {"heading": "4 Experiments", "text": "The results are reported on the standard DSTC2 data split where we used 516 dialogues as a validation set for early stopping [14] and the remaining 1612 dialogues for training. We use 1-best Automatic Speech Recognition (ASR) transcriptions of conversation history of the input and measure the joint slot accuracy. The models are evaluated using the recommended measure accuracy [7] with schedule 2 which skips the first turns where the believe tracker does not track any values. In addition, our models are also evaluated on a randomly split DSTC2 dataset (see Section 4.3).\nFor all our experiments, we train word embeddings of size 100 and use the encoder state size of size 100, together with a dropout keep probability of 0.7 for both encoder inputs and outputs. These parameters are selected by a grid search over the hyper-parameters on development data.\n6We modified code from the TensorFlow \u2018seq2seq\u2018 module.\nJoint labels distribution"}, {"heading": "4.1 Training", "text": "The training procedure minimizes the cross-entropy loss function using the Adam optimizer [12] with a batch size of 10. We train predicting the goal slot values for each turn. We treat each dialogue turn as a separate training example, feeding the whole dialogue history up to the current turn into the encoder and predicting the slot labels for the current turn.\nWe use early stopping with patience [14], validating on the development set after each epoch and stopping if the three top models does not change for four epochs.\nThe predicted labels in DST task depend not only on the last turn, but on the dialogue full history as well. Since the lengths of dialogue histories vary a lot7 and we batch our inputs, we separated the dialogues into ten buckets accordingly to their lengths in order to provide a computational speed-up. We reshuffle the data after each epoch only within each bucket.\nIn informal experiments, we tried to speed-up the training by optimizing the parameters only on the last turn8 but the performance dropped relatively by more than 40%."}, {"heading": "4.2 Comparing models", "text": "Predicting the labels jointly is quite challenging because the distribution of the labels is skewed as demonstrated in Figure 5. Some of the labels combinations are very rare, and they occur only in the development and test set so the joint model is not able to predict them. During first informal experiments the joint model performed poorly arguably due to data sparsity of slot triples. We further focus on model with independent classifiers and encoderdecoder architecture.\nThe model with independent label prediction is a strong baseline which was used, among others, in work of \u017dilka and Jurc\u030c\u00edc\u030cek [16]. The model suffers less from dataset\n7The maximum dialogue history length is 487 words and 95% percentile is 205 words for the training set.\n8The prediction was conditioned on the full history but we backpropagated the error only in words within the last turn.\nmismatch because it does not model the correlation between predicted labels. This property can explain a smaller performance drop between the test set from reshuffled data and the official test set in comparison to encoder-decoder model.\nSince the encoder-decoder architecture is very general and can predict arbitrary output sequences, it also needs to learn how to predict only three slot labels in the correct order. It turned out that the architecture learned to predict quadruples with three slot values and the EOS symbol quickly, even before seeing a half of the training data in the first epoch.9 At the end of the first epoch, the system made no more mistakes on predicting slot values in the incorrect order. The encoder-decoder system is competitive with state-of-the art architectures and the time needed for learning the output structure was surprisingly short.10"}, {"heading": "4.3 Data preparation experiments", "text": "The data for the DSTC2 test set were collected using a different spoken dialogue system configuration than the data for the validation and the training set.[7]. We intended to investigate the influence of the complexity of the task, hence we merged all DSTC2 data together and created splits of 80%, 10% and 10% for the training, development and test sets. The results in Table 2 show that the complexity of the task dropped significantly.\n9We could have modified the decoder to always predict three symbols for our three slots, but our experiments showed that the encoderdecoder architecture does not make mistakes at predicting the order of the three slots and EOS symbol.\n10The best model weights were found after 18 to 23 epochs for all model architectures."}, {"heading": "5 Related work", "text": "Since there are numerous systems which reported on the DSTC2 dataset, we discuss only the systems which use RNNs. In general, the RNN systems achieved excellent results.\nOur system is related to the RNN tracker of \u017dilka and Jurc\u030c\u00edc\u030cek [16], which reported near state-of-the art results on the DSTC2 dataset and introduced the first incremental system which was able to update the dialogue state wordby-word with such accuracy. In contrast to work of \u017dilka and Jurc\u030c\u00edc\u030cek [16], we use no abstraction of slot values. Instead, we add the additional features as described in Section 3. The first system which used a neural network for dialogue state tracking [6] used a feed-forward network and more than 10 manually engineered features across different levels of abstraction of the user input, including the outputs of the spoken language understanding component (SLU). In our work, we focus on simplifying the architecture, hence we used only features which were explicitly given by the dialogue history word representation and the database.\nThe system of Henderson et al. [9] achieves the stateof-the-art results and, similarly to our system, it predicts the dialogue state from words by employing a RNN. On the other hand, their system heavily relies on the user input abstraction. Another dialogue state tracker with LSTM was used in the reinforcement setting but the authors also used information from the SLU pipeline [13].\nAn interesting approach is presented in the work of Vodol\u00e1n et al. [15], who combine a rule-based and a machine learning based approach. The handcrafted features are fed to an LSTM-based RNN which performs a dialog-state update. However, unlike our work, their system requires SLU output on its input.\nIt is worth noting that there are first attempts to train an end-to-end dialogue system even without explicitly modeling the dialogue state [4], which further simplifies the architecture of a dialogue system. However, the reported end-to-end model was evaluated only on artificial dataset and cannot be compared to DSTC2 dataset directly."}, {"heading": "6 Conclusion", "text": "We presented and compared two dialogue state tracking models which are based on state-of-the-art architectures using recurrent neural networks. To our knowledge, we are the first to use an encoder-decoder model for the dialogue state tracking task, and we encourage others to do so because it is competitive with the standard RNN model.11 The models are comparable to the state-of-the-art models. We evaluate the models on DSTC2 dataset containing task-oriented dialogues in the restaurant domain. The 11The presented experiments are published at https://github. com/oplatek/e2end/ under Apache license. Informal experiments were conducted during the Statistical Dialogue Systems course at Charles University (see https://github.com/oplatek/sds-tracker).\nmodels are trained using only ASR 1-best transcriptions and task-specific lexical features defined by the task database. We observe that dialogue state tracking on DSTC2 test set is notoriously hard and that the task becomes substantially easier if the data is reshuffled.\nAs future work, we plan to investigate the influence of the introduced database features on models accuracy. To our knowledge there is no dataset which can be used for evaluating incremental dialogue state trackers, so it would be beneficial to collect the word-level annotations so one can evaluate incremental DST models."}], "references": [{"title": "TensorFlow: Large-scale machine learning on heterogeneous systems", "author": ["Mart\u0131n Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1409.0473,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "A Neural probabilistic language model", "author": ["Yoshua Bengio", "Rejean Ducharme", "Pascal Vincent"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Learning End-to-End Goal-Oriented Dialog", "author": ["Antoine Bordes", "Jason Weston"], "venue": "arXiv preprint arXiv:1605.07683,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "\u00c7aglar G\u00fcl\u00e7ehre", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": "CoRR, abs/1406.1078,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Deep neural network approach for the dialog state tracking challenge", "author": ["Matthew Henderson", "Blaise Thomson", "Steve Young"], "venue": "Proceedings of the SIG- DIAL 2013 Conference,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "The second dialog state tracking challenge", "author": ["Matthew Henderson", "Blaise Thomson", "Jason Williams"], "venue": "In 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "The third dialog state tracking challenge", "author": ["Matthew Henderson", "Blaise Thomson", "Jason D Williams"], "venue": "In Spoken Language Technology Workshop (SLT), 2014 IEEE,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Word-based dialog state tracking with recurrent neural networks", "author": ["Matthew Henderson", "Blaise Thomson", "Steve Young"], "venue": "In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Gradient flow in recurrent nets: the difficulty of learning", "author": ["Sepp Hochreiter", "Yoshua Bengio", "Paolo Frasconi", "J\u00fcrgen Schmidhuber"], "venue": "long-term dependencies,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "Reinforcement learning for parameter estimation in statistical spoken dialogue systems", "author": ["Filip Jur\u010d\u00ed\u010dek", "Blaise Thomson", "Steve Young"], "venue": "Computer Speech & Language,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Dialog History Construction with Long-Short Term Memory for Robust Generative Dialog State Tracking", "author": ["Byung-Jun Lee", "Kee-Eung Kim"], "venue": "Dialogue & Discourse,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "Early stopping-but when? In Neural Networks: Tricks of the trade, pages 55\u201369", "author": ["Lutz Prechelt"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1998}, {"title": "Hybrid Dialog State Tracker", "author": ["Miroslav Vodol\u00e1n", "Rudolf Kadlec", "Jan Kleindienst"], "venue": "CoRR, abs/1510.03710,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Incremental LSTM-based dialog state tracker", "author": ["Luk\u00e1s \u017dilka", "Filip Jur\u010d\u00ed\u010dek"], "venue": "arXiv preprint arXiv:1507.03471,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Backpropagation through time: what it does and how to do it", "author": ["Paul J Werbos"], "venue": "Proceedings of the IEEE,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1990}, {"title": "The dialog state tracking challenge", "author": ["Jason Williams", "Antoine Raux", "Deepak Ramachandran", "Alan Black"], "venue": "In Proceedings of the SIGDIAL 2013 Conference,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Web-style ranking and SLU combination for dialog state tracking", "author": ["Jason D Williams"], "venue": "In 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "The hidden information state model: A practical framework for POMDP-based spoken dialogue management", "author": ["Steve Young", "Milica Ga\u0161i\u0107", "Simon Keizer", "Fran\u00e7ois Mairesse", "Jost Schatzmann", "Blaise Thomson", "Kai Yu"], "venue": "Computer Speech & Language,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}], "referenceMentions": [{"referenceID": 6, "context": "We present experiments on the standard dialogue state tracking (DST) dataset, DSTC2 [7].", "startOffset": 84, "endOffset": 87}, {"referenceID": 17, "context": "Dialogue state tracking (DST) is a standard and important task for evaluating task-oriented conversational agents [18, 7, 8].", "startOffset": 114, "endOffset": 124}, {"referenceID": 6, "context": "Dialogue state tracking (DST) is a standard and important task for evaluating task-oriented conversational agents [18, 7, 8].", "startOffset": 114, "endOffset": 124}, {"referenceID": 7, "context": "Dialogue state tracking (DST) is a standard and important task for evaluating task-oriented conversational agents [18, 7, 8].", "startOffset": 114, "endOffset": 124}, {"referenceID": 19, "context": "Dialogue agents as introduced in [20] decide about the next action based on the dialogue state distribution given by the tracker.", "startOffset": 33, "endOffset": 37}, {"referenceID": 19, "context": "The dialogue state is a latent variable [20] and one needs to label the conversations in order to train a dialogue state tracker using supervised learning.", "startOffset": 40, "endOffset": 44}, {"referenceID": 10, "context": "It was shown that with a better dialogue state tracker, conversation agents achieve better success rate in overall completion of the their task [11].", "startOffset": 144, "endOffset": 148}, {"referenceID": 6, "context": "We also experiment with re-splitting of the DSTC2 data because there are considerable differences between the standard train and test datasets [7].", "startOffset": 143, "endOffset": 146}, {"referenceID": 18, "context": "95 on the test set according to the state-of-the-art [19].", "startOffset": 53, "endOffset": 57}, {"referenceID": 6, "context": "formance on this dataset [7].", "startOffset": 25, "endOffset": 28}, {"referenceID": 16, "context": "Our models are all based on a RNN encoder [17].", "startOffset": 42, "endOffset": 46}, {"referenceID": 15, "context": "The models update their hidden states h after processing each word similarly to the RNN encoder of \u017dilka and Jur\u010d\u00ed\u010dek [16].", "startOffset": 118, "endOffset": 122}, {"referenceID": 4, "context": "We use a Gated Recurrent Unit (GRU) cell [5] as the update function instead of a simple RNN cell because it does not suffer from the vanishing gradient problem [10].", "startOffset": 41, "endOffset": 44}, {"referenceID": 9, "context": "We use a Gated Recurrent Unit (GRU) cell [5] as the update function instead of a simple RNN cell because it does not suffer from the vanishing gradient problem [10].", "startOffset": 160, "endOffset": 164}, {"referenceID": 2, "context": "The model optimizes its parameters including word embeddings [3] during training.", "startOffset": 61, "endOffset": 64}, {"referenceID": 0, "context": "The models were implemented using the TensorFlow [1] framework.", "startOffset": 49, "endOffset": 52}, {"referenceID": 6, "context": "5Accuracy measure with schedule 2 on slot f ood, area and pricerange about which users can inform the system is a featured metric for DSTC2 challenge [7].", "startOffset": 150, "endOffset": 153}, {"referenceID": 1, "context": "We cast the slot predictions problem as a sequence-tosequence predictions task and we use a encoder-decoder model with attention [2] to learn this representation together with slot predictions (see Figure 4).", "startOffset": 129, "endOffset": 132}, {"referenceID": 1, "context": "The model is successfully used in machine translation where it is able to handle long sequences with good accuracy [2].", "startOffset": 115, "endOffset": 118}, {"referenceID": 13, "context": "The results are reported on the standard DSTC2 data split where we used 516 dialogues as a validation set for early stopping [14] and the remaining 1612 dialogues for train-", "startOffset": 125, "endOffset": 129}, {"referenceID": 6, "context": "The models are evaluated using the recommended measure accuracy [7] with schedule 2 which skips the first turns where the believe tracker does not track any values.", "startOffset": 64, "endOffset": 67}, {"referenceID": 11, "context": "The training procedure minimizes the cross-entropy loss function using the Adam optimizer [12] with a batch size of 10.", "startOffset": 90, "endOffset": 94}, {"referenceID": 13, "context": "We use early stopping with patience [14], validating on the development set after each epoch and stopping if the three top models does not change for four epochs.", "startOffset": 36, "endOffset": 40}, {"referenceID": 15, "context": "The model with independent label prediction is a strong baseline which was used, among others, in work of \u017dilka and Jur\u010d\u00ed\u010dek [16].", "startOffset": 125, "endOffset": 129}, {"referenceID": 14, "context": "[15] - 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "\u017dilka and Jur\u010d\u00ed\u010dek [16] 0.", "startOffset": 19, "endOffset": 23}, {"referenceID": 5, "context": "[6] - 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "DSTC2 stacking ensemble [7] - 0.", "startOffset": 24, "endOffset": 27}, {"referenceID": 6, "context": "[7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "Our system is related to the RNN tracker of \u017dilka and Jur\u010d\u00ed\u010dek [16], which reported near state-of-the art results on the DSTC2 dataset and introduced the first incremental system which was able to update the dialogue state wordby-word with such accuracy.", "startOffset": 63, "endOffset": 67}, {"referenceID": 15, "context": "In contrast to work of \u017dilka and Jur\u010d\u00ed\u010dek [16], we use no abstraction of slot values.", "startOffset": 42, "endOffset": 46}, {"referenceID": 5, "context": "The first system which used a neural network for dialogue state tracking [6] used a feed-forward network and more than 10 manually engineered features across different levels of abstraction of the user input, including the outputs of the spoken language understanding component (SLU).", "startOffset": 73, "endOffset": 76}, {"referenceID": 8, "context": "[9] achieves the stateof-the-art results and, similarly to our system, it predicts the dialogue state from words by employing a RNN.", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "Another dialogue state tracker with LSTM was used in the reinforcement setting but the authors also used information from the SLU pipeline [13].", "startOffset": 139, "endOffset": 143}, {"referenceID": 14, "context": "[15], who combine a rule-based and a machine learning based approach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "It is worth noting that there are first attempts to train an end-to-end dialogue system even without explicitly modeling the dialogue state [4], which further simplifies the architecture of a dialogue system.", "startOffset": 140, "endOffset": 143}], "year": 2016, "abstractText": "This paper discusses models for dialogue state tracking using recurrent neural networks (RNN). We present experiments on the standard dialogue state tracking (DST) dataset, DSTC2 [7]. On the one hand, RNN models became the state of the art models in DST, on the other hand, most state-of-the-art DST models are only turn-based and require dataset-specific preprocessing (e.g. DSTC2-specific) in order to achieve such results. We implemented two architectures which can be used in an incremental setting and require almost no preprocessing. We compare their performance to the benchmarks on DSTC2 and discuss their properties. With only trivial preprocessing, the performance of our models is close to the state-ofthe-art results.1", "creator": "LaTeX with hyperref package"}}}