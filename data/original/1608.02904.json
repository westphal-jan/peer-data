{"id": "1608.02904", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Aug-2016", "title": "TweeTime: A Minimally Supervised Method for Recognizing and Normalizing Time Expressions in Twitter", "abstract": "We describe TweeTIME, a temporal tagger for recognizing and normalizing time expressions in Twitter. Most previous work in social media analysis has to rely on temporal resolvers that are designed for well-edited text, and therefore suffer from the reduced performance due to domain mismatch. We present a minimally supervised method that learns from large quantities of unlabeled data and requires no hand-engineered rules or hand-annotated training corpora. TweeTIME achieves 0.68 F1 score on the end-to-end task of resolving date expressions, outperforming a broad range of state-of-the-art systems.", "histories": [["v1", "Tue, 9 Aug 2016 18:29:04 GMT  (532kb,D)", "http://arxiv.org/abs/1608.02904v1", "EMNLP 2016"], ["v2", "Sat, 24 Sep 2016 03:54:13 GMT  (562kb,D)", "http://arxiv.org/abs/1608.02904v2", "EMNLP 2016"], ["v3", "Sat, 1 Oct 2016 19:24:23 GMT  (568kb,D)", "http://arxiv.org/abs/1608.02904v3", "EMNLP 2016"]], "COMMENTS": "EMNLP 2016", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["jeniya tabassum", "alan ritter", "wei xu"], "accepted": true, "id": "1608.02904"}, "pdf": {"name": "1608.02904.pdf", "metadata": {"source": "CRF", "title": "A Minimally Supervised Method for Recognizing and Normalizing Time Expressions in Twitter", "authors": ["Jeniya Tabassum", "Alan Ritter", "Wei Xu"], "emails": ["bintejafar.1@osu.edu", "ritter.1492@osu.edu", "xwe@cis.upenn.edu"], "sections": [{"heading": "1 Introduction", "text": "Temporal expressions are words or phrases that refer to dates, times or durations. Resolving time expressions is an important task in information extraction (IE) that enables downstream applications such as calendars or timelines of events (Derczynski and Gaizauskas, 2013; Do et al., 2012; Ritter et al., 2012; Ling and Weld, 2010), knowledge base population (Ji et al., 2011), information retrieval (Alonso et al., 2007), automatically scheduling meetings from email and more. Previous work in this area has applied rule-based systems (Mani and Wilson, 2000; Bethard, 2013b; Chambers, 2013) or supervised machine learning on small collections of hand-annotated news documents (Angeli et al., 2012; Lee et al., 2014).\n1We will make our code and data available with the publication of this paper.\nSocial media especially contains time-sensitive information and requires accurate temporal analysis, for example, for detecting real-time cybersecurity events (Ritter et al., 2015; Chang et al., 2016), disease outbreaks (Kanhabua et al., 2012) and extracting personal information (Schwartz et al., 2015). However, most work on social media simply uses generic temporal resolvers and therefore suffers from suboptimal performance. The increasing research interest in temporal resolution focuses primarily on news articles and clinical texts (UzZaman et al., 2013; Bethard and Savova, 2016).\nResolving time expressions in social media is a non-trivial problem. Besides many spelling variations, time expressions are more likely to refer to future dates than in newswire. For the example in\nar X\niv :1\n60 8.\n02 90\n4v 1\n[ cs\n.I R\n] 9\nA ug\n2 01\nFigure 1, we need to recognize that Monday refers to the upcoming Monday and not the previous one to resolve to its correct normalized date (5/9/2016). We also need to identify that the word Sun is not referring to a Sunday in this context.\nIn this paper, we present a new minimally supervised approach to temporal resolution that requires no in-domain annotation or hand-crafted rules, instead learning from large quantities of unlabeled text in conjunction with a database of known events. Our approach is capable of learning robust time expression models adapted to the informal style of text found on social media.\nFor popular events, some related tweets (e.g. Figure 2) may contain explicit or other simple time mentions that can be captured by a generic temporal tagger. An open-domain information extraction system (Ritter et al., 2012) can then identify events (e.g. [Mercury, 5/9/2016]) by aggregating those tweets. To automatically generate temporally annotated data for training, we make the following novel distant supervision assumption:2\nTweets posted near the time of a known event that mention central entities are likely to contain time expressions that refer to the date of the event.\nSo that, other tweets (e.g. Figure 1) that contain the same named entity can be heuristically labeled as training data. Each tweet is associated with multiple overlapping labels that indicate the day of the week, day of the month, whether the event is in the past or future and other time properties of the event date in relation to the tweet\u2019s creation date. In order to learn a tagger that can recognize temporal expressions at the word-level, we present a multiple-instance learning approach to model sentence and word-level tags jointly and handle overlapping labels. Using heuristically labeled data and the temporal tags predicted by the multiple-instance learning model as input, we then train a log-linear model that normalizes time expressions to calendar dates.\nBuilding on top of the multiple-instance learning model, we further improve performance using\n2We focus on resolving dates, arguably the most important and frequent category of time expressions in social media data, and leave other phenomenon such as times and durations to traditional methods or future work.\na missing data model that addresses the problem of errors introduced during the heuristic labeling process. Our best model achieves a 0.68 F1 score when resolving date mentions in Twitter. This is a 17% increase over SUTime (Chang and Manning, 2012), outperforming other state-of-the-art time expression resolvers HeidelTime (Stro\u0308tgen and Gertz, 2013), TempEX (Mani and Wilson, 2000) and UWTime (Lee et al., 2014) as well. Our approach also produces a confidence score that allows us to trade recall for precision. To the best of our knowledge, TweeTIME is the first time resolver designed specifically for social media data.3 This is also the first time that distant supervision is successfully applied for end-to-end temporal recognition and normalization. Previous distant supervision approaches (Angeli et al., 2012; Angeli and Uszkoreit, 2013) only address the normalization problem, assuming gold time mentions are available at test time."}, {"heading": "2 System Overview", "text": "Our TweeTIME system consists of two major components as shown in Figure 3:\n1. A Temporal Recognizer which identifies time expressions (e.g. Monday) in English text and outputs 5 different temporal types (described in Table 1) indicating timeline direction, month of year, date of month, day of week or no temporal information (NA). It is realized as a multipleinstance learning model, and in an enhanced version, as a missing data model.\n2. A Temporal Normalizer that takes a tweet with its creation time and temporal expressions tagged by the above step as input, and outputs their normalized forms (e.g. Monday \u2192 5/9/2016). It is a log-linear model that uses both lexical features and temporal tags.\nTo train these two models without corpora manually annotated with time expressions, we leverage a large database of known events as distant supervision. The event database is extracted automatically from Twitter using the open-domain IE system\n3The closest work is HeidelTime\u2019s colloquial English version (Stro\u0308tgen and Gertz, 2012) developed from annotated SMS data and slang dictionary. Our TweeTIME significantly outperforms on Twitter data.\nproposed by Ritter et al. (2012). Each event consists of one or more named entities, in addition to the date on which the event takes place, for example [Mercury, 5/9/2016]. Tweets are first processed by a Twitter named entity recognizer (Ritter et al., 2011), and a generic date resolver (Mani and Wilson, 2000). Events are then extracted based on the strength of association between each named entity and calendar date, as measured by a G2 test on their co-occurrence counts. More details of the Event Extractor can be found in Section 5.1.\nThe following two sections describe the details of our Temporal Recognizer and Temporal Normalizer separately."}, {"heading": "3 Distant Supervision for Recognizing Time Expressions", "text": "The goal of the recognizer is to predict the temporal tag of each word, given a sentence (or a tweet) w = w1, . . . , wn. We propose a multiple-instance\nlearning model and a missing data model that are capable of learning word-level taggers given only sentence-level labels.\nOur recognizer module in is built using a database of known events as distant supervision. We assume tweets published around the time of a known event that mention a central entity are also likely to contain time expressions referring to the event\u2019s date. For each event, such as [Mercury, 5/9/2016], we gather all tweets that contain the central entity Mercury and are posted within 7 days of 5/9/2016. We then label each tweet based on the event date in addition to the tweet\u2019s creation date. The sentence-level temporal tags for the tweet in Figure 1 are: TL=future, DOW=Mon, DOM=9, MOY=May."}, {"heading": "3.1 Multiple-Instance Learning Temporal Tagging Model (MultiT)", "text": "Unlike supervised learning, where labeled instances are provided to the learner, in multiple instance learning scenarios (Dietterich et al., 1997), the learner is only provided with bags of instances labeled as either positive (where at least one instance is positive) or all negative. This is a close match to our problem setting, in which sentences are labeled with tags that should be assigned to one or more words.\nWe represent sentences and their labels using a graphical model that is divided into word-level and sentence-level variables (as shown in Figure 4). Unlike the standard supervised tagging prob-\nlem, we never directly observe the words\u2019 tags (z = z1, . . . , zn) during learning. Instead, they are latent and we only observe the date of an event mentioned in the text, from which we derive sentencelevel binary variables t = t1, . . . , tk corresponding to temporal tags for the sentence. Following previous work on multiple-instance learning (Hoffmann et al., 2011a; Xu et al., 2014), we model the connection between sentence-level labels and word-level tags using a set of deterministic-OR factors \u03c6sent.\nThe overall conditional probability of our model is defined as:\nP (t, z|w;\u03b8r)\n= 1\nZ k\u220f i=1 \u03c6sent(ti, z)\u00d7 n\u220f j=1 \u03c6word(zj , wj)\n= 1\nZ k\u220f i=1 \u03c6sent(ti, z)\u00d7 n\u220f j=1 e\u03b8 r \u00b7f(zj ,wj)\n(1)\nwhere f(zj , wj) is a feature vector and\n\u03c6sent(ti, z) =  1 if ti = true \u2227 \u2203j : zj = i 1 if ti = false \u2227 \u2200j : zj 6= i 0 otherwise (2) We include a standard set of tagging features that\nincludes word shape and identity in addition to prefixes and suffixes. To learn parameters \u03b8r of the Temporal Tagger, we maximize the likelihood of the sentence-level heuristic labels conditioned on observed words over all tweets in the training corpus. Given a training instance w with label t, the gradient of the conditional log-likelihood with respect to the parameters is:\n\u2207P (t|w) = \u2211\nz P (z|w, t;\u03b8r) \u00b7 f(z,w)\n\u2212 \u2211 t,z P (t, z|w;\u03b8r) \u00b7 f(z,w)\n(3)\nThis gradient is the difference of two conditional expectations over the feature vector f: a \u201cclamped\u201d expectation that is conditioned on the observed words and tags (w, t) and a \u201cfree\u201d expectation that is only conditioned on the words in the text, w, and ignores the sentence-level labels. To make the inference tractable, we use a Viterbi approximation that replaces the expectations with maximization. Because each sentence corresponds to more than one temporal tag, the maximization of the \u201cclamped\u201d maximization is somewhat challenging to compute. We use the approximate inference algorithm of Hoffmann et al. (2011a), that views inference as a weighted set cover problem, with worst case running time (|T | \u00b7 |W |), where |T | is the number of all possible temporal tag values and |W | is the number of words in a sentence."}, {"heading": "3.2 Missing Data Temporal Tagging Model (MiDaT)", "text": "While the multiple-instance learning assumption works well much of the time, it can easily be violated \u2013 there are many tweets that mention entities involved in an event but that never explicitly mention its date.\nThe missing data modeling approach to weakly supervised learning proposed by Ritter et. al. (2013) addresses this problem by relaxing the hard constraints of deterministic-OR factors, such as those described above, as soft constraints. Our missingdata model for weakly supervised tagging splits the sentence-level variables, t into two parts : m which represents whether a temporal tag is mentioned by at least one word of the tweet, and t\u2032 which represents\nwhether a temporal tag can be derived from the event date. A set of pairwise potentials \u03c8(mj , t\u2032j) are introduced that encourage (but don\u2019t strictly require) agreement between mj and t\u2032j , that is:\n\u03c8(mj , t \u2032 j) = { \u03b1p, if t\u2032j 6= mj \u03b1r, if t\u2032j = mj\n(4)\nHere, \u03b1p (Penalty), and \u03b1r (Reward) are parameters for the MiDaT model. \u03b1p is the penalty for extracting a temporal tag that is not related to the event-date and \u03b1r is the reward for extracting a tag that matches the date.\nDuring learning, if the local classifier is very confident, it is possible for a word to be labeled with a tag that is not derived from the event-date, and also for a sentence-level tag to be ignored, although either case will be penalized by the agreement potentials, \u03c8(mj , t\u2032j), in the global objective. We use a local-search approach to inference that was empirically demonstrated to nearly always yield exact solutions by Ritter et. al. (2013)."}, {"heading": "4 A Log-Linear Model for Normalizing Time Expressions", "text": "The Temporal Normalizer is built using a log-linear model which takes the tags t produced by the Temporal Recognizer as input and outputs one or more dates mentioned in a tweet. We formulate date normalization as a binary classification problem: given a tweet w published on date dpub, we consider 22 candidate target dates (w, dcandl ) such that d cand l = dpub + l, where l = \u221210, . . . ,\u22121, 0,+1, . . . ,+10, limiting the possible date references that are considered within 10 days before or after the tweet creation date, in addition to dcandl = null (the tweet does not mention a date). 4 While our basic approach has the limitation, that it is only able to predict dates within \u00b110 days of the target date, we found that in practice the majority of date references on social media fall within this window. Our approach is also able to score dates outside this range that are generated by traditional approaches to resolving time expressions, as described in Section 5.3.3.\n4Although the temporal recognizer is trained with tweets from \u00b17 days around the event date, we found that extending the candidate date range to \u00b110 days for the temporal normalizer increased the performance of TweeTIME in the dev set.\nThe classifier is similarly trained using the event database as distant supervision. The probability that a tweet mentions a candidate date is estimated using a log-linear model:\nP (dcand|w, dpub) \u221d e\u03b8n\u00b7g(w,dpub,t) (5)\nwhere \u03b8n and g are the parameter and feature vector respectively in the Temporal Normalizer. For every tweet and candidate date pair (w, dcandl ), we extract the following set of features:\nTemporal Tag Features that indicate whether the candidate date agrees with the temporal tags extracted by the Temporal Recognizer. Three cases can happen here: The recognizer can extract a tag that can not be derived from the candidate date; The recognizer can miss a tag derived from the candidate date; The recognizer can extract a tag that is derived from the candidate date.\nLexical Features that include two types of binary features from the tweet: 1) Word Tag features consist of conjunctions of words in the tweet and tags associated with the candidate date. We remove URLs, stop words and punctuation; 2) Word POS features that are the same as above, but include conjunctions of POS tags, words and temporal tags derived from the candidate date.\nTime Difference Features are numerical features that indicate the distance between the creation date and the candidate date. They include difference of day ranges form -10 to 10 and the difference of week ranges from -2 to 2."}, {"heading": "5 Experiments", "text": "In the following sub-sections we present experimental results on learning to resolve time expressions in Twitter using minimal supervision. We start by describing our dataset, and proceed to present our results, including a large-scale evaluation on heuristically-labeled data and an evaluation comparing against human judgements."}, {"heading": "5.1 Data Collection", "text": "We collected around 120 million tweets posted in a one year window starting from April 2011 to May 2012. These tweets were automatically annotated with named entities, POS tags and TempEx dates (Ritter et al., 2011).\nFrom this automatically-annotated corpus we extract the top 10, 000 events and their corresponding dates using the G2 test, which measures the strength of association between an entity and date using the log-likelihood ratio between a model in which the entity is conditioned on the date and a model of independence (Ritter et al., 2012). Events extracted using this approach then simply consist of the highest-scoring entity-date pairs, for example [Mercury, 5/9/2016].\nAfter automatically extracting the database of events, we next gather all tweets that mention an entity from the list that are also written within \u00b17 days of the event. These tweets and the dates of the known events serve as labeled examples that are likely to mention a known date.\nWe also include a set of pseudo-negative examples, that are unlikely to refer to any event, by gathering a random sample of tweets that do not mention any of the top 10, 000 events and where TempEx does not extract any date."}, {"heading": "5.2 Large-Scale Heuristic Evaluation", "text": "We first evaluate our tagging model, by testing how well it can predict the heuristically generated labels. As noted in previous work on distant supervision (Mintz et al., 2009a), this type of evaluation usually under-estimates precision, however it provides us with a useful intrinsic measure of performance.\nIn order to provide even coverage of months in the training and test set, we divide the twitter corpus into 3 subsets based on the mod-5 week of each tweet\u2019s creation date. To train system we use tweets that are created in 1st, 2nd or 3rd weeks. To tune parameters of the MiDaT model we used tweets from 5th weeks, and to evaluate the performance of the trained model we used tweets from 4th weeks.\nThe performance of the MiDaT model varies with the penalty and reward parameters. To find a (near) optimal setting of the values we performed a grid search on the dev set and found that a penalty of\n\u221225 and reward of 500 works best. A comparison of MultiT and MiDaT\u2019s performance at predicting heuristically generated labels is shown in Table 2.\nThe word level tags predicted by the temporal recognizer are used as the input to the temporal normalizer, which predicts the referenced date from each tweet. The overall system\u2019s performance at predicting event dates on the automatically generated test set, compared against SUTime, is shown in Table 3."}, {"heading": "5.3 Evaluation Against Human Judgements", "text": "In addition to automatically evaluating our tagger on a large corpus of heuristically-labeled tweets, we also evaluate the performance of our tagging and date-resolution models on a random sample of tweets taken from a much later time period, that were manually annotated by the authors."}, {"heading": "5.3.1 Word-Level Tags", "text": "To evaluate the performance of the MiDaT-tagger we randomly selected 50 tweets and labeled each word with its corresponding tag. Against this hand annotated test set, MiDaT achieves Precision=0.54, Recall=0.45 and F-value=0.49. A few examples of word-level tags predicted by MiDaT are shown in Table 4. We found that because the tags are learned as latent variables inferred by our model, they sometimes don\u2019t line up exactly with our intuitions but\nstill provide useful predictions, for example in Table 4, Christmas is labeled with the tag MOY=dec."}, {"heading": "5.3.2 End-to-end Date Resolution", "text": "To evaluate the final performance of our system and compare against existing state-of-the art time resolvers, we randomly sampled 250 tweets from 2014-2016 and manually annotated them with normalized dates; note that this is a separate date range from our weakly-labeled training data which is taken from 2011-2012. We use 50 tweets as a development set and the remaining 200 as a final test set. We experimented with different feature sets on the development data. Feature ablation experiments are presented in Table 5.\nThe final performance of our system, compared\nagainst a range of state-of-the-art time resolvers is presented in Table 6. We see that TweeTIME outperforms SUTime, Tempex, HeidelTime (using its COLLOQUIAL mode, which is designed for SMS text) and UWTime. Brief descriptions of each system can be found in Section 6."}, {"heading": "5.3.3 System Combination with SUTime", "text": "As our basic TweeTIME system is designed to predict dates within +/-10 days of the creation date, it fails when a tweet refers to a date outside this range. To overcome this limitation we append the date predicted by SUTime in the list of candidate days. We then re-rank SUTime\u2019s predictions using our log-linear model, and include its output as a predicted date if the confidence of our normalizer is sufficiently high."}, {"heading": "5.3.4 Error Analysis", "text": "Tweets where TweeTIME extracts the correct date, but other systems fail, often consist of examples containing colloquial expressions or spelling variations, for example Jan1 in the following Tweet:\nJUST IN Delhi high court asks state government to submit data on changes in pollution level since #OddEven rule came into effect on Jan1\nTweeTIME is able to correctly extract 01/01/2016, whereas HeidelTime, SUTime, TempEX and UWTime failed to extract any dates."}, {"heading": "6 Related Work", "text": "Temporal Resolvers primarily utilize either rulebased or probabilistic approaches. Notable rulebased systems such as TempEx (Mani and Wilson, 2000), SUTime (Chang and Manning, 2012) and HeidelTime (Stro\u0308tgen and Gertz, 2013) provide particularly competitive performance compared to the state-of-the-art machine learning methods. Probabilistic approaches use supervised classifiers trained on in-domain annotated data (Kolomiyets and Moens, 2010; Bethard, 2013a; Filannino et al., 2013) or hybrid with hand-engineered rules (UzZaman and Allen, 2010; Lee et al., 2014). UWTime (Lee et al., 2014) is one of the most recent and competitive systems and uses Combinatory Categorial Grammar (CCG).\nAlthough the recent research challenge TempEval (UzZaman et al., 2013; Bethard and Savova, 2016) offers an evaluation in the clinical domain besides newswire, most participants used the provided annotated corpus to train supervised models in addition to employing hand-coded rules. Previous work on adapting temporal taggers primarily focus on scaling up to more languages. HeidelTime was extended to multilingual (Stro\u0308tgen and Gertz, 2015), colloquial (SMS) and scientific texts (Stro\u0308tgen and Gertz, 2012) using dictionaries and additional in-domain annotated data. One existing work used distant supervision (Angeli et al., 2012; Angeli and Uszkoreit, 2013), but for normalization only, assuming gold time mentions as input. They used an EM-style bootstrapping approach and a CKY parser. Distant Supervision has recently become popular in natural language processing. Much of the\nwork has focused on the task of relation extraction (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Mintz et al., 2009b; Riedel et al., 2010; Hoffmann et al., 2011b; Nguyen and Moschitti, 2011; Surdeanu et al., 2012; Xu et al., 2013; Ritter et al., 2013; Angeli et al., 2014). Recent work also shows exciting results on extracting named entities (Ritter et al., 2011), emotions (Purver and Battersby, 2012), sentiment (Marchetti-Bowick and Chambers, 2012), as well as finding evidence in medical publications (Wallace et al., 2016). Our work is closely related to the joint word-sentence model that exploits multiple-instance learning for paraphrase identification (Xu et al., 2014) in Twitter."}, {"heading": "7 Conclusions", "text": "In this paper, we showed how to learn time resolvers from large amounts of unlabeled text, using a database of known events as distant supervision. We presented a method for learning a wordlevel temporal tagging models from tweets that are heuristically labeled with only sentence-level labels. This approach was further extended to account for the case of missing tags, or temporal properties that are not explicitly mentioned in the text of a tweet. These temporal tags were then combined with a variety of other features in a novel date-resolver that predicts normalized dates referenced in a Tweet. By learning from large quantities of in-domain data, we were able to achieve 0.68 F1 score on the end-to-end time normalization task for social media data, significantly outperforming SUTime, TempEx, HeidelTime and UWTime on this challenging dataset for time normalization."}], "references": [{"title": "On the value of temporal", "author": ["cardo Baeza-Yates"], "venue": null, "citeRegEx": "Baeza.Yates.,? \\Q2007\\E", "shortCiteRegEx": "Baeza.Yates.", "year": 2007}, {"title": "Combining distant and partial supervision for relation extraction", "author": ["Angeli et al.2014] Gabor Angeli", "Julie Tibshirani", "Jean Wu", "Christopher D Manning"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Angeli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Angeli et al\\.", "year": 2014}, {"title": "SemEval-2016 Task 12: Clinical TempEval", "author": ["Bethard", "Savova2016] Steven Bethard", "Guergana Savova"], "venue": "In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval)", "citeRegEx": "Bethard et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bethard et al\\.", "year": 2016}, {"title": "ClearTKTimeML: A minimalist approach to TempEval", "author": ["Steven Bethard"], "venue": "In Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval)", "citeRegEx": "Bethard.,? \\Q2013\\E", "shortCiteRegEx": "Bethard.", "year": 2013}, {"title": "A synchronous context free grammar for time normalization", "author": ["Steven Bethard"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Bethard.,? \\Q2013\\E", "shortCiteRegEx": "Bethard.", "year": 2013}, {"title": "Learning to extract relations from the Web using minimal supervision", "author": ["Bunescu", "Mooney2007] Razvan C. Bunescu", "Raymond J. Mooney"], "venue": "In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL)", "citeRegEx": "Bunescu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bunescu et al\\.", "year": 2007}, {"title": "NavyTime: Event and time ordering from raw text", "author": ["Nathanael Chambers"], "venue": "In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval)", "citeRegEx": "Chambers.,? \\Q2013\\E", "shortCiteRegEx": "Chambers.", "year": 2013}, {"title": "SUTime: A library for recognizing and normalizing time expressions", "author": ["Chang", "Manning2012] Angel X Chang", "Christopher D Manning"], "venue": "In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC)", "citeRegEx": "Chang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2012}, {"title": "Expectation-regulated neural model for event mention extraction", "author": ["Zhiyang Teng", "Yue Zhang"], "venue": "Proccedings of the 2016 Conference of the North American Chapter of the Association", "citeRegEx": "Chang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2016}, {"title": "Constructing biological knowledge bases by extracting information from text sources", "author": ["Craven", "Kumlien1999] Mark Craven", "Johan Kumlien"], "venue": "In Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology (ISMB)", "citeRegEx": "Craven et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Craven et al\\.", "year": 1999}, {"title": "Temporal signals help label temporal relations", "author": ["Derczynski", "Gaizauskas2013] Leon Derczynski", "Robert J Gaizauskas"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL)", "citeRegEx": "Derczynski et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Derczynski et al\\.", "year": 2013}, {"title": "Solving the multiple instance problem with axis-parallel rectangles", "author": ["Richard H Lathrop", "Tom\u00e1s Lozano-P\u00e9rez"], "venue": "Artificial intelligence,", "citeRegEx": "Dietterich et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Dietterich et al\\.", "year": 1997}, {"title": "Joint inference for event timeline construction", "author": ["Do et al.2012] Quang Xuan Do", "Wei Lu", "Dan Roth"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning", "citeRegEx": "Do et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Do et al\\.", "year": 2012}, {"title": "ManTIME: Temporal expression identification and normalization in the TempEval-3 challenge", "author": ["Gavin Brown", "Goran Nenadic"], "venue": "In Proceedings of the Seventh International Workshop on Semantic Evaluation (Se-", "citeRegEx": "Filannino et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Filannino et al\\.", "year": 2013}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations", "author": ["Congle Zhang", "Xiao Ling", "Luke Zettlemoyer", "Daniel S. Weld"], "venue": "In The 49th Annual Meeting of the Association", "citeRegEx": "Hoffmann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2011}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations", "author": ["Congle Zhang", "Xiao Ling", "Luke S. Zettlemoyer", "Daniel S. Weld"], "venue": "In Proceedings of the 49th Annual Meeting", "citeRegEx": "Hoffmann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2011}, {"title": "Overview of the tac 2011 knowledge base population track", "author": ["Ji et al.2011] Heng Ji", "Ralph Grishman", "Hoa Trang Dang", "Kira Griffitt", "Joe Ellis"], "venue": "In Proceedings of the Fourth Text Analysis Conference (TAC)", "citeRegEx": "Ji et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2011}, {"title": "Supporting temporal analytics for health-related events in microblogs", "author": ["Sara Romano", "Avar\u00e9 Stewart", "Wolfgang Nejdl"], "venue": "In Proceedings of the 21st ACM International Conference on Information and Knowledge", "citeRegEx": "Kanhabua et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kanhabua et al\\.", "year": 2012}, {"title": "KUL: Recognition and normalization of temporal expressions", "author": ["Kolomiyets", "Moens2010] Oleksandr Kolomiyets", "Marie-Francine Moens"], "venue": "In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval)", "citeRegEx": "Kolomiyets et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kolomiyets et al\\.", "year": 2010}, {"title": "Context-dependent semantic parsing for time expressions", "author": ["Lee et al.2014] Kenton Lee", "Yoav Artzi", "Jesse Dodge", "Luke Zettlemoyer"], "venue": "In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics (ACL)", "citeRegEx": "Lee et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2014}, {"title": "Temporal information extraction", "author": ["Ling", "Weld2010] Xiao Ling", "Daniel S Weld"], "venue": "In Proceedings of the 24th AAAI Conference on Artificial Intelligence (AAAI)", "citeRegEx": "Ling et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2010}, {"title": "Robust temporal processing of news", "author": ["Mani", "Wilson2000] Inderjeet Mani", "George Wilson"], "venue": "In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics (ACL)", "citeRegEx": "Mani et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Mani et al\\.", "year": 2000}, {"title": "Learning for microblogs with distant supervision: Political forecasting with Twitter", "author": ["Marchetti-Bowick", "Nathanael Chambers"], "venue": "In Proceedings of the 13th Conference of the European Chapter", "citeRegEx": "Marchetti.Bowick et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Marchetti.Bowick et al\\.", "year": 2012}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mintz et al.2009a] Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky"], "venue": "In Proceedings of the Joint Conference of the Association of Computational Linguistics and the International Joint Confer-", "citeRegEx": "Mintz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mintz et al.2009b] Mike Mintz", "Steven Bills", "Rion Snow", "Daniel Jurafsky"], "venue": "In Proceedigns of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th Interna-", "citeRegEx": "Mintz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "End-to-end relation extraction using distant supervision from external semantic repositories", "author": ["Nguyen", "Alessandro Moschitti"], "venue": "In Proceedings of the 49th Annual Meeting of the Association", "citeRegEx": "Nguyen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2011}, {"title": "Experimenting with distant supervision for emotion classification", "author": ["Purver", "Battersby2012] Matthew Purver", "Stuart Battersby"], "venue": "In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL)", "citeRegEx": "Purver et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Purver et al\\.", "year": 2012}, {"title": "Modeling relations and their mentions without labeled text", "author": ["Limin Yao", "Andrew McCallum"], "venue": "In Proceedigns of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery", "citeRegEx": "Riedel et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2010}, {"title": "Named entity recognition in Tweets: An experimental study", "author": ["Ritter et al.2011] Alan Ritter", "Sam Clark", "Oren Etzioni"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Ritter et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "Open domain event extraction from twitter", "author": ["Ritter et al.2012] Alan Ritter", "Oren Etzioni", "Sam Clark"], "venue": "In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD)", "citeRegEx": "Ritter et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2012}, {"title": "Modeling missing data in distant supervision for information extraction. Transactions of the Association for Computational Linguistics (TACL), 1:367\u2013378", "author": ["Ritter et al.2013] Alan Ritter", "Luke Zettlemoyer", "Mausam", "Oren Etzioni"], "venue": null, "citeRegEx": "Ritter et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2013}, {"title": "Weakly supervised extraction of computer security events from Twitter", "author": ["Ritter et al.2015] Alan Ritter", "Evan Wright", "William Casey", "Tom Mitchell"], "venue": null, "citeRegEx": "Ritter et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2015}, {"title": "Extracting human temporal orientation in Facebook language", "author": ["Greg Park", "Maarten Sap", "Evan Weingarten", "Johannes Eichstaedt", "Margaret Kern", "Jonah Berger", "Martin Seligman", "Lyle Ungar"], "venue": null, "citeRegEx": "Schwartz et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schwartz et al\\.", "year": 2015}, {"title": "Temporal tagging on different domains: Challenges, strategies, and gold standards", "author": ["Str\u00f6tgen", "Gertz2012] Jannik Str\u00f6tgen", "Michael Gertz"], "venue": "In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC)", "citeRegEx": "Str\u00f6tgen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Str\u00f6tgen et al\\.", "year": 2012}, {"title": "Multilingual and cross-domain temporal tagging", "author": ["Str\u00f6tgen", "Gertz2013] Jannik Str\u00f6tgen", "Michael Gertz"], "venue": "Language Resources and Evaluation,", "citeRegEx": "Str\u00f6tgen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Str\u00f6tgen et al\\.", "year": 2013}, {"title": "A baseline temporal tagger for all languages", "author": ["Str\u00f6tgen", "Gertz2015] Jannik Str\u00f6tgen", "Michael Gertz"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Str\u00f6tgen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Str\u00f6tgen et al\\.", "year": 2015}, {"title": "Multi-instance multi-label learning for relation extraction", "author": ["Julie Tibshirani", "Ramesh Nallapati", "Christopher D. Manning"], "venue": "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Surdeanu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2012}, {"title": "TRIPS and TRIOS system for Tempeval-2: Extracting temporal information from text", "author": ["UzZaman", "Allen2010] Naushad UzZaman", "James F Allen"], "venue": "In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval)", "citeRegEx": "UzZaman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "UzZaman et al\\.", "year": 2010}, {"title": "SemEval-2013 Task 1: TEMPEVAL-3: Evaluating time expressions, events, and temporal relations", "author": ["Hector Llorens", "James Allen", "Leon Derczynski", "Marc Verhagen", "James Pustejovsky"], "venue": null, "citeRegEx": "UzZaman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "UzZaman et al\\.", "year": 2013}, {"title": "Extracting PICO sentences from clinical trial reports using supervised distant supervision", "author": ["Jo\u00ebl Kuiper", "Aakash Sharma", "Mingxi Brian Zhu", "Iain J Marshall"], "venue": "Journal of Machine Learning Research (JMLR)", "citeRegEx": "Wallace et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wallace et al\\.", "year": 2016}, {"title": "Filling knowledge base gaps for distant supervision of relation extraction", "author": ["Xu et al.2013] Wei Xu", "Raphael Hoffmann", "Zhao Le", "Ralph Grishman"], "venue": "In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics (ACL)", "citeRegEx": "Xu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 12, "context": "Resolving time expressions is an important task in information extraction (IE) that enables downstream applications such as calendars or timelines of events (Derczynski and Gaizauskas, 2013; Do et al., 2012; Ritter et al., 2012; Ling and Weld, 2010), knowledge base population (Ji et al.", "startOffset": 157, "endOffset": 249}, {"referenceID": 29, "context": "Resolving time expressions is an important task in information extraction (IE) that enables downstream applications such as calendars or timelines of events (Derczynski and Gaizauskas, 2013; Do et al., 2012; Ritter et al., 2012; Ling and Weld, 2010), knowledge base population (Ji et al.", "startOffset": 157, "endOffset": 249}, {"referenceID": 16, "context": ", 2012; Ling and Weld, 2010), knowledge base population (Ji et al., 2011), information retrieval (Alonso et al.", "startOffset": 56, "endOffset": 73}, {"referenceID": 6, "context": "Previous work in this area has applied rule-based systems (Mani and Wilson, 2000; Bethard, 2013b; Chambers, 2013) or supervised machine learning on small collections of hand-annotated news documents (Angeli et al.", "startOffset": 58, "endOffset": 113}, {"referenceID": 19, "context": "Previous work in this area has applied rule-based systems (Mani and Wilson, 2000; Bethard, 2013b; Chambers, 2013) or supervised machine learning on small collections of hand-annotated news documents (Angeli et al., 2012; Lee et al., 2014).", "startOffset": 199, "endOffset": 238}, {"referenceID": 31, "context": "Social media especially contains time-sensitive information and requires accurate temporal analysis, for example, for detecting real-time cybersecurity events (Ritter et al., 2015; Chang et al., 2016), disease outbreaks (Kanhabua et al.", "startOffset": 159, "endOffset": 200}, {"referenceID": 8, "context": "Social media especially contains time-sensitive information and requires accurate temporal analysis, for example, for detecting real-time cybersecurity events (Ritter et al., 2015; Chang et al., 2016), disease outbreaks (Kanhabua et al.", "startOffset": 159, "endOffset": 200}, {"referenceID": 17, "context": ", 2016), disease outbreaks (Kanhabua et al., 2012) and extracting personal information (Schwartz et al.", "startOffset": 27, "endOffset": 50}, {"referenceID": 32, "context": ", 2012) and extracting personal information (Schwartz et al., 2015).", "startOffset": 44, "endOffset": 67}, {"referenceID": 38, "context": "The increasing research interest in temporal resolution focuses primarily on news articles and clinical texts (UzZaman et al., 2013; Bethard and Savova, 2016).", "startOffset": 110, "endOffset": 158}, {"referenceID": 29, "context": "An open-domain information extraction system (Ritter et al., 2012) can then identify events (e.", "startOffset": 45, "endOffset": 66}, {"referenceID": 19, "context": "This is a 17% increase over SUTime (Chang and Manning, 2012), outperforming other state-of-the-art time expression resolvers HeidelTime (Str\u00f6tgen and Gertz, 2013), TempEX (Mani and Wilson, 2000) and UWTime (Lee et al., 2014) as well.", "startOffset": 206, "endOffset": 224}, {"referenceID": 28, "context": "Tweets are first processed by a Twitter named entity recognizer (Ritter et al., 2011), and a generic date resolver (Mani and Wilson, 2000).", "startOffset": 64, "endOffset": 85}, {"referenceID": 28, "context": "proposed by Ritter et al. (2012). Each event consists of one or more named entities, in addition to the date on which the event takes place, for example [Mercury, 5/9/2016].", "startOffset": 12, "endOffset": 33}, {"referenceID": 11, "context": "Unlike supervised learning, where labeled instances are provided to the learner, in multiple instance learning scenarios (Dietterich et al., 1997), the learner is only provided with bags of instances labeled as either positive (where at least one instance is positive) or all negative.", "startOffset": 121, "endOffset": 146}, {"referenceID": 14, "context": "We use the approximate inference algorithm of Hoffmann et al. (2011a), that views inference as a weighted set cover problem, with worst case running time (|T | \u00b7 |W |), where |T | is the number of all possible temporal tag values and |W | is the number of words in a sentence.", "startOffset": 46, "endOffset": 70}, {"referenceID": 28, "context": "These tweets were automatically annotated with named entities, POS tags and TempEx dates (Ritter et al., 2011).", "startOffset": 89, "endOffset": 110}, {"referenceID": 29, "context": "From this automatically-annotated corpus we extract the top 10, 000 events and their corresponding dates using the G2 test, which measures the strength of association between an entity and date using the log-likelihood ratio between a model in which the entity is conditioned on the date and a model of independence (Ritter et al., 2012).", "startOffset": 316, "endOffset": 337}, {"referenceID": 13, "context": "Probabilistic approaches use supervised classifiers trained on in-domain annotated data (Kolomiyets and Moens, 2010; Bethard, 2013a; Filannino et al., 2013) or hybrid with hand-engineered rules (UzZaman and Allen, 2010; Lee et al.", "startOffset": 88, "endOffset": 156}, {"referenceID": 19, "context": ", 2013) or hybrid with hand-engineered rules (UzZaman and Allen, 2010; Lee et al., 2014).", "startOffset": 45, "endOffset": 88}, {"referenceID": 19, "context": "UWTime (Lee et al., 2014) is one of the most recent and competitive systems and uses Combinatory Categorial Grammar (CCG).", "startOffset": 7, "endOffset": 25}, {"referenceID": 38, "context": "Although the recent research challenge TempEval (UzZaman et al., 2013; Bethard and Savova, 2016) offers an evaluation in the clinical domain besides newswire, most participants used the provided annotated corpus to train supervised models in addition to employing hand-coded rules.", "startOffset": 48, "endOffset": 96}, {"referenceID": 27, "context": "Much of the work has focused on the task of relation extraction (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Mintz et al., 2009b; Riedel et al., 2010; Hoffmann et al., 2011b; Nguyen and Moschitti, 2011; Surdeanu et al., 2012; Xu et al., 2013; Ritter et al., 2013; Angeli et al., 2014).", "startOffset": 64, "endOffset": 292}, {"referenceID": 36, "context": "Much of the work has focused on the task of relation extraction (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Mintz et al., 2009b; Riedel et al., 2010; Hoffmann et al., 2011b; Nguyen and Moschitti, 2011; Surdeanu et al., 2012; Xu et al., 2013; Ritter et al., 2013; Angeli et al., 2014).", "startOffset": 64, "endOffset": 292}, {"referenceID": 40, "context": "Much of the work has focused on the task of relation extraction (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Mintz et al., 2009b; Riedel et al., 2010; Hoffmann et al., 2011b; Nguyen and Moschitti, 2011; Surdeanu et al., 2012; Xu et al., 2013; Ritter et al., 2013; Angeli et al., 2014).", "startOffset": 64, "endOffset": 292}, {"referenceID": 30, "context": "Much of the work has focused on the task of relation extraction (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Mintz et al., 2009b; Riedel et al., 2010; Hoffmann et al., 2011b; Nguyen and Moschitti, 2011; Surdeanu et al., 2012; Xu et al., 2013; Ritter et al., 2013; Angeli et al., 2014).", "startOffset": 64, "endOffset": 292}, {"referenceID": 1, "context": "Much of the work has focused on the task of relation extraction (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Mintz et al., 2009b; Riedel et al., 2010; Hoffmann et al., 2011b; Nguyen and Moschitti, 2011; Surdeanu et al., 2012; Xu et al., 2013; Ritter et al., 2013; Angeli et al., 2014).", "startOffset": 64, "endOffset": 292}, {"referenceID": 28, "context": "Recent work also shows exciting results on extracting named entities (Ritter et al., 2011), emotions (Purver and Battersby, 2012), sentiment (Marchetti-Bowick and Chambers, 2012), as well as finding evidence in medical publications (Wallace et al.", "startOffset": 69, "endOffset": 90}, {"referenceID": 39, "context": ", 2011), emotions (Purver and Battersby, 2012), sentiment (Marchetti-Bowick and Chambers, 2012), as well as finding evidence in medical publications (Wallace et al., 2016).", "startOffset": 149, "endOffset": 171}], "year": 2016, "abstractText": "We describe TweeTIME, a temporal tagger for recognizing and normalizing time expressions in Twitter. Most previous work in social media analysis has to rely on temporal resolvers that are designed for well-edited text, and therefore suffer from the reduced performance due to domain mismatch. We present a minimally supervised method that learns from large quantities of unlabeled data and requires no hand-engineered rules or hand-annotated training corpora. TweeTIME achieves 0.68 F1 score on the end-to-end task of resolving date expressions, outperforming a broad range of state-of-the-art systems.1", "creator": "LaTeX with hyperref package"}}}