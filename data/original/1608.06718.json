{"id": "1608.06718", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Aug-2016", "title": "A Large-Scale Multilingual Disambiguation of Glosses", "abstract": "Linking concepts and named entities to knowledge bases has become a crucial Natural Language Understanding task. In this respect, recent works have shown the key advantage of exploiting textual definitions in various Natural Language Processing applications. However, to date there are no reliable large-scale corpora of sense-annotated textual definitions available to the research community. In this paper we present a large-scale high-quality corpus of disambiguated glosses in multiple languages, comprising sense annotations of both concepts and named entities from a unified sense inventory. Our approach for the construction and disambiguation of the corpus builds upon the structure of a large multilingual semantic network and a state-of-the-art disambiguation system; first, we gather complementary information of equivalent definitions across different languages to provide context for disambiguation, and then we combine it with a semantic similarity-based refinement. As a result we obtain a multilingual corpus of textual definitions featuring over 38 million definitions in 263 languages, and we make it freely available at", "histories": [["v1", "Wed, 24 Aug 2016 05:30:45 GMT  (323kb,D)", "http://arxiv.org/abs/1608.06718v1", "Accepted in LREC 2016"]], "COMMENTS": "Accepted in LREC 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jos\\'e camacho collados", "claudio delli bovi", "alessandro raganato", "roberto navigli"], "accepted": false, "id": "1608.06718"}, "pdf": {"name": "1608.06718.pdf", "metadata": {"source": "CRF", "title": "A Large-Scale Multilingual Disambiguation of Glosses", "authors": ["Jos\u00e9 Camacho-Collados", "Claudio Delli Bovi", "Alessandro Raganato", "Roberto Navigli"], "emails": ["collados@di.uniroma1.it", "dellibovi@di.uniroma1.it", "raganato@di.uniroma1.it", "navigli@di.uniroma1.it"], "sections": [{"heading": null, "text": "Keywords: Word Sense Disambiguation, Entity Linking, textual definitions, definitional knowledge, multilingual corpus"}, {"heading": "1. Introduction", "text": "In addition to lexicography, where their use is of paramount importance, textual definitions drawn from dictionaries or encyclopedias have been widely used in various Natural Language Processing tasks and applications. Some of the areas where the use of definitional knowledge has proved to be key in achieving state-of-the-art results are Word Sense Disambiguation (Lesk, 1986; Banerjee and Pedersen, 2002; Navigli and Velardi, 2005; Agirre and Soroa, 2009; Fernandez-Ordonez et al., 2012; Chen et al., 2014; Camacho-Collados et al., 2015b), Taxonomy and Ontology Learning (Velardi et al., 2013; Flati et al., 2014; Espinosa-Anke et al., 2016), Information Extraction (Richardson et al., 1998; Delli Bovi et al., 2015), Plagiarism Detection (Franco-Salvador et al., 2016), and Question Answering (Hill et al., 2015).\nIn fact, textual definitions (or glosses) are today widely to be found in resources of various kinds, from lexicons and dictionaries, such as WordNet (Miller et al., 1990) or Wiktionary, to encyclopedias and knowledge bases, such as Wikidata and OmegaWiki. These include Wikipedia itself: indeed, the first sentence of a Wikipedia article is generally regarded as the definition of its subject1. In any case, an accurate semantic analysis of a definition corpus is made difficult by the short and concise nature of definitional text. Furthermore, the majority of approaches making use of definitions are restricted to corpora where each concept or entity is associated with a single definition, while definitions coming from different resources are often complementary and might give different perspectives on the definiendum. Moreover, equivalent definitions of the same concept or entity may vary substantially according to the language, and be more precise or self-explanatory in some languages than\n1According to the Wikipedia guidelines an article should begin with a short declarative sentence defining what (or who) the subject is and why it is notable.\nothers. This has the potential to be especially valuable in the context of disambiguation (Navigli, 2009), where highly ambiguous terms in one language may become less ambiguous (or even unambiguous) in other languages.\nIn this paper we bring together definitions coming from both different resources and different languages, and disambiguate them by exploiting their cross-lingual and crossresource complementarities. Our goal is to obtain a largescale high-quality corpus of sense-annotated textual definitions. In order to do this we leverage BabelNet2 (Navigli and Ponzetto, 2012), a multilingual lexicalized semantic network obtained from the automatic integration of lexicographic and encyclopedic resources. Due to its wide coverage of both lexicographic and encyclopedic terms, BabelNet gives us a very large sense inventory for disambiguation, as well as a vast and comprehensive target corpus of textual definitions. In fact, as it is a merger of various different resources, BabelNet provides a large heterogeneous set of over 35 million definitions for over 250 languages from WordNet, Wikipedia, Wiktionary, Wikidata and OmegaWiki. To the best of our knowledge, this set constitutes the largest available corpus of definitional text.\nWe evaluate our sense-annotated corpus intrinsically, obtaining a disambiguation precision of over 90% on a random sample of definitions in three different languages, and extrinsically on Open Information Extraction and Sense Clustering tasks. Our experiments show the potential of exploiting our disambiguated glosses within the pipelines of two state-of-the-art systems, improving on their original performance."}, {"heading": "2. Related Work", "text": "Among all resources using textual definitions, WordNet has definitely been the most popular and the most exploited\n2http://babelnet.org\nar X\niv :1\n60 8.\n06 71\n8v 1\n[ cs\n.C L\n] 2\n4 A\nug 2\n01 6\nto date. In fact, WordNet glosses have still been used successfully in recent work (Khan et al., 2013; Chen et al., 2015).\nA first attempt to disambiguate WordNet glosses automatically was proposed as part of the eXtended WordNet project3 (Novischi, 2002). However, this attempt\u2019s estimated coverage did not reach 6% of the total amount of sense-annotated instances. Moldovan and Novischi (2004) proposed an alternative disambiguation approach, specifically targeted at the WordNet sense inventory and based on a supervised model trained on the SemCor sense-annotated corpus (Miller et al., 1993). In general, the drawback of supervised models arises from the so-called knowledgeacquisition bottleneck, a problem that becomes particularly vexed when such models are applied to larger inventories, due to the vast amount of annotated data they normally require. Another disambiguation task focused on WordNet glosses was presented as part of the SensEval-3 workshop (Litkowski, 2004). However, the best reported system obtained precision and recall figures below 70%, which arguably is not enough to provide high-quality senseannotated data for current state-of-the-art NLP systems.\nIn addition to annotation reliability, another issue that arises when producing a corpus of textual definitions is wide coverage. In fact, reliable corpora of sense-annotated definitions produced to date, such as the Princeton WordNet Gloss Corpus4, have usually been obtained by relying on human annotators. The Princeton corpus of WordNet disambiguated glosses has already been shown to be successful as part of the pipeline in semantic similarity (Pilehvar et al., 2013), domain labeling (Gonza\u0301lez et al., 2012) and Word Sense Disambiguation (Agirre and Soroa, 2009; Camacho-Collados et al., 2015b) systems. However, as new encyclopedic knowledge about the world is constantly being harvested, keeping up using only human annotation is becoming an increasingly expensive endeavor. With a view to tackling this problem, a great deal of research has recently focused on the automatic extraction of definitions from unstructured text (Navigli and Velardi, 2010; Benedictis et al., 2013; Espinosa-Anke and Saggion, 2014; Dalvi et al., 2015). On the other hand, the prominent role of collaborative resources (Hovy et al., 2013) has created a convenient development ground for NLP systems based on encyclopedic definitional knowledge. Nevertheless, extending the manual annotation of definitions to much larger and up-todate knowledge repositories like BabelNet is not feasible. First of all, the number of items to disambiguate is massive; moreover, as the number of concepts and named entities increases, annotators would have to deal with the added difficulty of selecting context-appropriate synsets from an extremely large sense inventory. In fact, WordNet 3.0 comprises 117 659 synsets and a definition for each synset, while BabelNet 3.0 covers 13 801 844 synsets with a total of 40 328 194 definitions.\nInstead, in this paper we propose an automatic disambiguation approach which leverages multilinguality and cross-resource information along with a state-of-the-art\n3http://www.hlt.utdallas.edu/\u02dcxwn/ 4http://wordnet.princeton.edu/glosstag.\nshtml\nmultilingual Word Sense Disambiguation/Entity Linking system (Moro et al., 2014) and a vector-based semantic representation of concepts and entities (Camacho-Collados et al., 2015a). By exploiting these features, we are able to produce a large-scale high-quality corpus of glosses, automatically disambiguated with BabelNet synsets5."}, {"heading": "3. Methodology", "text": "The gist of our approach lies in the combination of different languages and resources for high-quality disambiguation. In fact, since many definitions are short and concise, the lack of meaningful context would negatively affect the performance of a Word Sense Disambiguation/Entity Linking system targeted at individual definitions.\nTo improve the data quality before the disambiguation step, we tokenize and Part-of-Speech (PoS) tag the definitions for a subset of languages:\nTokenization. We use the tokenization system available from the polyglot project6 for 165 languages.\nPart-of-Speech tagging. We train the Stanford tagger (Toutanova et al., 2003), for 30 languages using the available data from the Universal Dependencies project7(Nivre, 2015).\nOur disambiguation strategy is based on two steps: (1) all definitions are gathered together, grouped by definiendum and disambiguated using a multilingual disambiguation system (Section 3.1.); (2) the disambiguation output is then refined using semantic similarity (Section 3.2.)."}, {"heading": "3.1. Context-rich Disambiguation", "text": "As an example, consider the following definition of castling in chess as provided by WordNet:\nInterchanging the positions of the king and a rook. (1)\nThe context in (1) is limited and it might not be obvious for an automatic disambiguation system that the concept being defined relates to chess: an alternative definition of castling where the game of chess is explicitly mentioned would definitely help the disambiguation process. Following this idea, given a BabelNet synset, we carry out a context enrichment procedure by collecting all the definitions of this synset in every available language and resource, and gathering them together into a single multilingual text.\nWe use a state-of-the-art graph-based approach to Entity Linking and Word Sense Disambiguation, Babelfy8 (Moro et al., 2014), to disambiguate definitions after preprocessing and context-enrichment. Our methodology relies on the fact that, as shown in Section 3.1., disambiguation systems like Babelfy work better with richer context. When provided with the definition of Example (1) in isolation,\n5Note that BabelNet covers WordNet and Wikipedia among other resources, which makes our sense annotations expandable to any of these resources.\n6http://polyglot.readthedocs.org/en/ latest/Tokenization.html\n7https://universaldependencies.github.io/ docs/\n8http://babelfy.org\nBabelfy incorrectly disambiguates rook as \u201drookie, inexperienced youth\u201d. However, by using additional definitions from other resources and languages, Babelfy exploits the added context and disambiguates rook with its correct chess sense. This approach is particularly advantageous for languages with low resources, where standard disambiguation techniques have not yet proved to be reliable, due to the shortage of annotated data."}, {"heading": "3.2. Disambiguation Refinement", "text": "Babelfy outputs a set D of disambiguated instances, i.e. mappings from text fragments to items in the BabelNet sense inventory, each associated with a confidence score (Babelfy score henceforth). When Babelfy score goes below 0.7, a back-off strategy based on the most common sense is used by default for that instance. Our aim is to correct or discard these low-confidence instances using Semantic Similarity.\nFirst, for each disambiguated instance d \u2208 D we compute a coherence scoreCd. The coherence score is provided by Babelfy as the number of semantic connections from d to the rest of disambiguation instances in the semantic graph (normalized):\nCd = |Disambiguated instances connected to d|\n|Disambiguated instances| \u2212 1 (2)\nWe empirically set a coherence score threshold to 0.125 (i.e. one semantic connection out of eight disambiguated instances). Let L be the set of disambiguated instances below both Babelfy and coherence score thresholds (low confidence). In order to refine the disambiguated instances in L, we use NASARI9 (Camacho-Collados et al., 2015a; Camacho-Collados et al., 2015b). NASARI provides vector representations for over four million BabelNet synsets built by exploiting the complementary knowledge of Wikipedia and WordNet. These semantic representations have proved capable of obtaining state-of-the-art results in various lexical semantics tasks such as Semantic Similarity, Sense Clustering and Word Sense Disambiguation.We consider those instances in L for which a NASARI vector can be retrieved (virtually all noun instances), and compute an additional score (NASARI score). First, we calculate the centroid \u00b5 of all the NASARI vectors for instances in D \\ L. Then, for each disambiguated instance l \u2208 L,\n9We use the 2.1 release version of the NASARI-embed vectors, downloaded from http://lcl.uniroma1.it/nasari\nwe retrieve all the candidate senses of its surface form in BabelNet and calculate a NASARI score Ns for each candidate sense. Ns is calculated as the cosine similarity between the centroid \u00b5 and its corresponding NASARI vector NASARI(s):\nNs = Sim(\u00b5,NASARI(s)) (3)\nThe NASARI score allows us to both discard lowconfidence disambiguated instances and correct the original disambiguation output by Babelfy in some cases. Then, each l \u2208 L is re-tagged with the sense obtaining the highest NASARI score:\ns\u0302 = argmax s\u2208Sl Nl (4)\nwhere Sl is the set containing all the candidate senses for l. For what concerns the high-precision disambiguated glosses release (see Section 6.) we set the NASARI threshold to 0.75. Considering example (1) again, Babelfy does not provide a high-confidence disambiguation for the word king, which is then incorrectly disambiguated using the most common sense strategy. However, the error is fixed during the refinement step: our system accurately selects the chess sense of king thanks to its high semantic connection with the disambiguated instances in D \\ L."}, {"heading": "4. Statistics", "text": "The output of our disambiguation procedure is a corpus of 38 820 114 glosses extracted from BabelNet (corresponding to 8 665 300 BabelNet synsets), covering 263 languages and 5 different resources (Wiktionary, WordNet10, Wikidata, Wikipedia11 and OmegaWiki) and including 249 544 708 annotations from the BabelNet sense inventory (6.4 annotations per definition on average). Table 1 reports some general statistics of the complete corpus of disambiguated textual definitions and for five sample languages: English, Spanish, French, Italian and Persian.\nThe number of disambiguated instances, before and after the refinement step, are displayed in Tables 2 and 3, organized, respectively, by language and Part-of-Speech (PoS). Babelfy and NASARI refer to the instances disambiguated by the two respective approaches and MCS to the\n10Including Open Multilingual WordNet. 11Definitions from Wikipedia include both first sentences of Wikipedia articles and definitions coming from Wikipedia\u2019s disambiguation pages.\ninstances which were disambiguated using the Most Common Sense (MCS) heuristic. After refinement, 24.7% of the low-confidence noun annotations are fixed using semantic similarity (see Section 3.2.). Assuming the coverage of our first disambiguation step (see Section 3.1.) to be 100%12, the coverage of our system after the refinement step is estimated to be 65.3%. As shown in Table 3, discarded annotations mostly include verbs, adjectives and adverbs, often harder to disambiguate as they are not directly related to the definiendum. In fact, the coverage of noun instances after refinement is estimated to be 73.9%."}, {"heading": "5. Evaluation", "text": ""}, {"heading": "5.1. Intrinsic evaluation", "text": "We first carry out an intrinsic evaluation of the resource, by manually assessing the quality of disambiguation on some randomly extracted samples of definitions. We rely on three human judges and evaluate samples of 100 items for three languages. We evaluated the disambiguation output before and after the refinement step, and compared against a baseline where each definition is disambiguated in isolation with Babelfy. Table 4 reports the evaluation on the three sample languages: English, Spanish and Italian. Although the disambiguation of context-free definitions improves only slightly with respect to the disambiguation of definitions in isolation, this improvement is consistent across languages. Furthermore, our system significantly increases the precision after the refinement step. Refinement reduces the coverage by 35% for English, and by 43% for Spanish and Italian, but increases precision by almost 11% for English, 20% for Spanish and 13% for Italian.\n12There is no straightforward way to estimate the coverage of a disambiguation system automatically. In our first step using Babelfy, we provide disambiguated instances for all content words (including multi-word expressions) from BabelNet and also for overlapping mentions. Therefore the output of our first step, even if not perfectly accurate, may be considered to have full coverage in comparison with our refinement step."}, {"heading": "5.2. Extrinsic evaluation", "text": "The sense-annotated corpus of definitions is also evaluated extrinsically with two experiments. The first experiment (Section 5.2.1.) evaluates our corpus before the highprecision refinement, and is focused on DEFIE (Delli Bovi et al., 2015), an Open Information Extraction (OIE) system that works on textual definitions. In its original implementation DEFIE uses Babelfy to disambiguate definitions oneby-one before extracting relation instances. We modified that implementation and used the glosses disambiguated with our approach as input for the system, and we compared the extracted information with the information obtained by the original implementation. The second experiment (Section 5.2.2.), instead, evaluates our refined highprecision corpus, and focuses on the semantic representations of NASARI (Section 3.2.). These representations were constructed based on the BabelNet semantic network. We reimplemented NASARI using the same network enriched with the high-precision disambiguated glosses and compared these with the original glosses in the sense clustering task."}, {"heading": "5.2.1. Open Information Extraction", "text": "In this experiment we investigated the impact of our disambiguation approach on the definitional corpus used as input for the pipeline of DEFIE. The original OIE pipeline of the system takes as input an unstructured corpus of textual definitions, which are then preprocessed one-by-one to extract syntactic dependencies and disambiguate word\nsenses and entity mentions. After this preprocessing stage, the algorithm constructs a syntactic-semantic graph representation for each definition, from which subject-verbobject triples (relation instances) are eventually extracted. As highlighted in Section 3.1., poor context of particularly short definitions may introduce disambiguation errors in the preprocessing stage, which then tend to propagate and reflect on both relations and relation instances. To assess the quality of our disambiguation methodology as compared to a standard approach, we modified the implementation of DEFIE to consider our disambiguated instances instead of executing the original disambiguation step, and then we evaluated the results obtained at the end of the pipeline in terms of quality of relation and relation instances.\nExperimental setup. We first selected a random sample of 150 textual definitions from our disambiguated corpus (Section 4.). We generated a baseline for the experiment by discarding all disambiguated instances from the sample, and treating the sample itself as an unstructured text of textual definitions which we used as input for DEFIE, letting the original pipeline of the system carry out the disambiguation step. Then we carried out the same procedure using, instead, the modified implementation for which our disambiguated instances are taken into account. In both cases, we ran the extraction algorithm of DEFIE and evaluated the output in terms of both relations and relation instances. Following Delli Bovi et al. (2015), we relied on two human judges and performed the same evaluation procedure described therein over the set of distinct relations extracted from the sample, as well as the set of extracted relation instances.\nResults. Results reported in Tables 5 and 6 show a slight but consistent improvement resulting from our disambiguated glosses over both the number of extracted relations and triples and over the number of glosses with at least one extraction (Table 5), as well as over the estimated precision of such extractions (Table 6). Context-rich disambiguation of glosses across resources and languages enabled the extraction of 6.5% additional instances from the sample (2.26 extractions on the average from each definition) and, at the same time, increased the estimated precision of relation and relation instances over the sample by \u223c1%."}, {"heading": "5.2.2. Sense Clustering", "text": "This experiment focuses on the sense clustering task. Knowledge resources such as Wikipedia or WordNet suffer from the high granularity of their sense inventories. A\nmeaningful cluster of senses within these sense inventories would help boost the performance in different applications (Hovy et al., 2013). In this section we will explain how to deal with this issue in Wikipedia.\nWe integrate the high-precision version of the network as enrichment of the BabelNet semantic network in order to improve the results of the state-of-the-art system based on NASARI lexical vectors (more details of NASARI in Section 3.2.). NASARI uses Wikipedia ingoing links and the BabelNet taxonomy in the process of obtaining contextual information for a given concept. We simply enrich the BabelNet taxonomy with the high-precision disambiguated glosses (see Section 3.2.) of the target language. The highprecision disambiguated glosses are synsets that are highly semantically connected with the definiendum, which makes them particularly suitable for enriching a semantic network. The rest of the default NASARI lexical pipeline for obtaining semantic representations (lexical specificity applied to the contextual information) remains unchanged. By integrating the high-precision disambiguated glosses into the NASARI pipeline, we obtain a new set of vector representations for BabelNet synsets, increasing its initial coverage (4.4M synsets covered by the default NASARI compared to 4.6M synsets covered by NASARI enriched with our disambiguated glosses).\nExperimental setup. We used the two sense clustering datasets created by Dandala et al. (2013). The task in these datasets consists of, given a pair of Wikipedia articles, to decide whether they should be merged into a single cluster or not. The first dataset (500-pair henceforth) contains 500 pairs of Wikipedia articles, while the second dataset (SemEval) consists of 925 pairs coming from a set of highly ambiguous words taken from disambiguation tasks of SemEval workshops. We follow the original setting of (Camacho-Collados et al., 2015a) and only cluster a pair of Wikipedia articles if their similarity, calculated by using the square-rooted Weighted Overlap comparison measure (Pilehvar et al., 2013), surpasses 0.5 (i.e. the middle point in the Weighted Overlap similarity scale).\nResults. Table 7 shows the results of different systems in the sense clustering task. As a naive baseline we include a system which clusters all pairs. For comparison we also include the Support Vector Machine classifier of Dandala et al. (2013) exploiting information of Wikipedia in four different languages (Dandala-multilingual). Finally, we report the results of the default NASARI English lexical vectors (NASARI13) and the NASARI-based vectors obtained from the BabelNet semantic network enriched with our high-precision disambiguated glosses (NASARI+glosses). As we can see from Table 7, the enrichment produced by our glosses proved to be highly beneficial, significantly improving on the original results obtained by NASARI. Moreover, NASARI+glosses obtains the best performance overall, outperforming Dandala-multilingual in terms of accuracy in both datasets.\n13Downloaded from http://lcl.uniroma1.it/ nasari/"}, {"heading": "6. Release", "text": "The corpus of disambiguated glosses is freely available at http://lcl.uniroma1.it/ disambiguated-glosses. We released both the complete (Section 3.1.) and the high-precision (Section 3.2.) versions of our corpus. The format for each of the two versions is almost identical: the corpus is first divided by resource (WordNet, Wikipedia, Wiktionary, Wikidata and OmegaWiki) and each resource is then divided by language.\nThe disambiguated glosses for each language and resource are stored in standard XML files. Figures 1 and 2 show a sample definition as displayed in the XML files of, respectively, the high-precision and complete version of our disambiguated corpus. Each file contains a list of definition tags, with their respective id14 as attribute. Then, each definition tag is composed by the original definition as plain text and annotations. The annotation tag refers to the sense-annotations provided as a result of our disambiguation process. Each annotation includes its disambiguated BabelNet id and has four (or five) attributes (see Section 3. for more details about the attributes):\n\u2022 source: this indicates whether the disambiguation has been performed by Babelfy, the Most Common Sense (\u201dMCS\u201d) heuristic (only in the complete version of the corpus) or NASARI (only in the high-precision version of the corpus).\n14Identifiers depend on the resource, e.g. offsets in WordNet and page titles in Wikipedia.\n\u2022 anchor: this corresponds to the exact surface form match found within the definition.\n\u2022 bfScore: this corresponds to the Babelfy score.\n\u2022 coherenceScore: this corresponds to the coherence score.\n\u2022 nasariScore: this corresponds to the NASARI score (only for the high-precision annotations)."}, {"heading": "7. Conclusion", "text": "In this paper we presented a large-scale multilingual corpus of disambiguated glosses. Disambiguation was performed by exploiting cross-resource and cross-language complementarities of textual definitions. By leveraging the structure of a wide-coverage semantic network and sense inventory like BabelNet, we obtained a fully disambiguated corpus of textual definitions coming from multiple sources and multiple languages which, to the best of our knowledge, constitutes the largest available corpus of its kind. Additionally, we refined our sense annotations by integrating a module based on semantic similarity into our disambiguation pipeline, in order to identify a subset of highprecision disambiguated instances across the definitions. This refined version of the corpus has a great potential in high-precision low-coverage applications, where having a disambiguation error as low as possible is the first requirement. Since the disambiguated instances in this version of the corpus are directly connected to the definiendum, this high-precision disambiguated corpus may also be used to enrich a semantic network, or even used as a semantic network on its own. We evaluated our corpus intrinsically on three different languages, showing that our system outperforms previous approaches and a standard state-of-theart disambiguation system in terms of coverage, precision and recall. We also carried out an extrinsic evaluation that shows some applications of our resource: we integrated the complete and high-precision versions of our corpus into the pipeline of both an Open Information Extraction system and a Sense Clustering system, improving on their original results and obtaining state-of-the-art figures in both tasks."}, {"heading": "Acknowledgments", "text": "The authors gratefully acknowledge the support of the ERC Starting Grant MultiJEDI No. 259234."}, {"heading": "8. References", "text": "Agirre, E. and Soroa, A. (2009). Personalizing PageR-\nank for Word Sense Disambiguation. In Proceedings of EACL, pages 33\u201341. Banerjee, S. and Pedersen, T. (2002). An adapted Lesk algorithm for Word Sense Disambiguation using WordNet. In Proceedings of the Third International Conference on Computational Linguistics and Intelligent Text Processing, CICLing\u201902, pages 136\u2013145, Mexico City, Mexico. Benedictis, F. D., Faralli, S., and Navigli, R. (2013). GlossBoot: Bootstrapping Multilingual Domain Glossaries from the Web. In Proceedings of ACL, pages 528\u2013538. Camacho-Collados, J., Pilehvar, M. T., and Navigli, R. (2015a). NASARI: a Novel Approach to a SemanticallyAware Representation of Items. In Proceedings of NAACL, pages 567\u2013577. Camacho-Collados, J., Pilehvar, M. T., and Navigli, R. (2015b). A unified multilingual semantic representation of concepts. In Proceedings of ACL (2), pages 741\u2013751, Beijing, China, July. Chen, X., Liu, Z., and Sun, M. (2014). A unified model for word sense representation and disambiguation. In Proceedings of EMNLP, pages 1025\u20131035, Doha, Qatar. Chen, T., Xu, R., He, Y., and Wang, X. (2015). Improving distributed representation of word sense via wordnet gloss composition and context clustering. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). Dalvi, B., Minkov, E., Talukdar, P. P., and Cohen, W. W. (2015). Automatic Gloss Finding for a Knowledge Base using Ontological Constraints. In Proceedings of WSDM, pages 369\u2013378. Dandala, B., Hokamp, C., Mihalcea, R., and Bunescu, R. C. (2013). Sense clustering using Wikipedia. In Proceedings of Recent Advances in Natural Language Processing, pages 164\u2013171, Hissar, Bulgaria. Delli Bovi, C., Telesca, L., and Navigli, R. (2015). LargeScale Information Extraction from Textual Definitions through Deep Syntactic and Semantic Analysis. Transactions of the Association for Computational Linguistics (TACL), 3. Espinosa-Anke, L. and Saggion, H. (2014). Applying Dependency Relations to Definition Extraction. Natural Language Processing and Information Systems, 8455:63\u201374. Espinosa-Anke, L., Saggion, H., Ronzano, F., and Navigli, R. (2016). ExTaSem! Extending, Taxonomizing and Semantifying Domain Terminologies. In Proceedings of the 30th Conference on Artificial Intelligence (AAAI\u201916). Fernandez-Ordonez, E., Mihalcea, R., and Hassan, S. (2012). Unsupervised word sense disambiguation with multilingual representations. In LREC, pages 847\u2013851.\nFlati, T., Vannella, D., Pasini, T., and Navigli, R. (2014). Two is bigger (and better) than one: the Wikipedia Bitaxonomy project. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 945\u2013955, Baltimore, USA.\nFranco-Salvador, M., Rosso, P., and Montes-y Go\u0301mez, M. (2016). A systematic study of knowledge graph analysis for cross-language plagiarism detection. Information Processing & Management.\nGonza\u0301lez, A., Rigau, G., and Castillo, M. (2012). A graphbased method to improve Wordnet domains. In Proceedings of 13th International Conference on Intelligent Text Processing and Computational Linguistics (CICLING), pages 17\u201328, New Delhi, India.\nHill, F., Cho, K., Korhonen, A., and Bengio, Y. (2015). Learning to understand phrases by embedding the dictionary. arXiv preprint arXiv:1504.00548.\nHovy, E. H., Navigli, R., and Ponzetto, S. P. (2013). Collaboratively built semi-structured content and Artificial Intelligence: The story so far. Artificial Intelligence, 194:2\u201327.\nKhan, M. F., Khan, A., and Khan, K. (2013). Efficient word sense disambiguation technique for sentence level sentiment classification of online reviews. Science International (Lahore), 25:937\u2013943.\nLesk, M. (1986). Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In Proceedings of the 5th Annual Conference on Systems Documentation, Toronto, Ontario, Canada, pages 24\u201326.\nLitkowski, K. C. (2004). Senseval-3 task: Word-sense disambiguation of wordnet glosses. In In Proc. of SENSEVAL-3 Workshop on Sense Evaluation, in the 42th Annual Meeting of the Association for Computational Linguistics (ACL 2004. Citeseer.\nMiller, G. A. and Beckwith, R.T. and Fellbaum, Christiane D. and Gross, D. and Miller, K. (1990). WordNet: an Online Lexical Database.\nMiller, G. A., Leacock, C., Tengi, R., and Bunker, R. (1993). A semantic concordance. In Proceedings of the 3rd DARPA Workshop on Human Language Technology, pages 303\u2013308.\nMoldovan, D. and Novischi, A. (2004). Word sense disambiguation of wordnet glosses. Computer Speech & Language, 18(3):301\u2013317.\nMoro, A., Raganato, A., and Navigli, R. (2014). Entity Linking meets Word Sense Disambiguation: a Unified Approach. Transactions of the Association for Computational Linguistics (TACL), 2:231\u2013244.\nNavigli, R. and Ponzetto, S. P. (2012). BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network. Artificial Intelligence, 193:217\u2013250.\nNavigli, R. and Velardi, P. (2005). Structural Semantic Interconnections: a knowledge-based approach to Word Sense Disambiguation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(7):1075\u20131088.\nNavigli, R. and Velardi, P. (2010). Learning Word-Class Lattices for definition and hypernym extraction. In Pro-\nceedings of ACL 2010, pages 1318\u20131327, Uppsala, Sweden. Navigli, R. (2009). Word Sense Disambiguation: A survey. ACM Computing Surveys, 41(2):1\u201369. Nivre, J. (2015). Towards a universal grammar for natural language processing. In Computational Linguistics and Intelligent Text Processing, pages 3\u201316. Springer. Novischi, A. (2002). Accurate semantic annotations via pattern matching. In FLAIRS Conference, pages 375\u2013 379. Pilehvar, M. T., Jurgens, D., and Navigli, R. (2013). Align, Disambiguate and Walk: a Unified Approach for Measuring Semantic Similarity. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1341\u20131351, Sofia, Bulgaria. Richardson, S. D., Dolan, W. B., and Vanderwende, L. (1998). MindNet: Acquiring and Structuring Semantic Information from Text. In Proceedings of ACL, pages 1098\u20131102. Toutanova, K., Klein, D., Manning, C. D., and Singer, Y. (2003). Feature-rich part-of-speech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1, pages 173\u2013180. Association for Computational Linguistics. Velardi, P., Faralli, S., and Navigli, R. (2013). OntoLearn Reloaded: A Graph-Based Algorithm for Taxonomy Induction. Computational Linguistics, 39(3):665\u2013707."}], "references": [{"title": "Personalizing PageRank for Word Sense Disambiguation", "author": ["E. Agirre", "A. Soroa"], "venue": "Proceedings of EACL, pages 33\u201341.", "citeRegEx": "Agirre and Soroa,? 2009", "shortCiteRegEx": "Agirre and Soroa", "year": 2009}, {"title": "An adapted Lesk algorithm for Word Sense Disambiguation using WordNet", "author": ["S. Banerjee", "T. Pedersen"], "venue": "Proceedings of the Third International Conference on Computational Linguistics and Intelligent Text Processing, CICLing\u201902, pages 136\u2013145, Mexico City, Mexico.", "citeRegEx": "Banerjee and Pedersen,? 2002", "shortCiteRegEx": "Banerjee and Pedersen", "year": 2002}, {"title": "GlossBoot: Bootstrapping Multilingual Domain Glossaries from the Web", "author": ["F.D. Benedictis", "S. Faralli", "R. Navigli"], "venue": "Proceedings of ACL, pages 528\u2013538.", "citeRegEx": "Benedictis et al\\.,? 2013", "shortCiteRegEx": "Benedictis et al\\.", "year": 2013}, {"title": "NASARI: a Novel Approach to a SemanticallyAware Representation of Items", "author": ["J. Camacho-Collados", "M.T. Pilehvar", "R. Navigli"], "venue": "Proceedings of NAACL, pages 567\u2013577.", "citeRegEx": "Camacho.Collados et al\\.,? 2015a", "shortCiteRegEx": "Camacho.Collados et al\\.", "year": 2015}, {"title": "A unified multilingual semantic representation of concepts", "author": ["J. Camacho-Collados", "M.T. Pilehvar", "R. Navigli"], "venue": "Proceedings of ACL (2), pages 741\u2013751, Beijing, China, July.", "citeRegEx": "Camacho.Collados et al\\.,? 2015b", "shortCiteRegEx": "Camacho.Collados et al\\.", "year": 2015}, {"title": "A unified model for word sense representation and disambiguation", "author": ["X. Chen", "Z. Liu", "M. Sun"], "venue": "Proceedings of EMNLP, pages 1025\u20131035, Doha, Qatar.", "citeRegEx": "Chen et al\\.,? 2014", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Improving distributed representation of word sense via wordnet gloss composition and context clustering", "author": ["T. Chen", "R. Xu", "Y. He", "X. Wang"], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint", "citeRegEx": "Chen et al\\.,? 2015", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Automatic Gloss Finding for a Knowledge Base using Ontological Constraints", "author": ["B. Dalvi", "E. Minkov", "P.P. Talukdar", "W.W. Cohen"], "venue": "Proceedings of WSDM, pages 369\u2013378.", "citeRegEx": "Dalvi et al\\.,? 2015", "shortCiteRegEx": "Dalvi et al\\.", "year": 2015}, {"title": "Sense clustering using Wikipedia", "author": ["B. Dandala", "C. Hokamp", "R. Mihalcea", "R.C. Bunescu"], "venue": "Proceedings of Recent Advances in Natural Language Processing, pages 164\u2013171, Hissar, Bulgaria.", "citeRegEx": "Dandala et al\\.,? 2013", "shortCiteRegEx": "Dandala et al\\.", "year": 2013}, {"title": "LargeScale Information Extraction from Textual Definitions through Deep Syntactic and Semantic Analysis", "author": ["C. Delli Bovi", "L. Telesca", "R. Navigli"], "venue": "Transactions of the Association for Computational Linguistics (TACL), 3.", "citeRegEx": "Bovi et al\\.,? 2015", "shortCiteRegEx": "Bovi et al\\.", "year": 2015}, {"title": "Applying Dependency Relations to Definition Extraction", "author": ["L. Espinosa-Anke", "H. Saggion"], "venue": "Natural Language Processing and Information Systems, 8455:63\u201374.", "citeRegEx": "Espinosa.Anke and Saggion,? 2014", "shortCiteRegEx": "Espinosa.Anke and Saggion", "year": 2014}, {"title": "ExTaSem! Extending, Taxonomizing and Semantifying Domain Terminologies", "author": ["L. Espinosa-Anke", "H. Saggion", "F. Ronzano", "R. Navigli"], "venue": "Proceedings of the 30th Conference on Artificial Intelligence (AAAI\u201916).", "citeRegEx": "Espinosa.Anke et al\\.,? 2016", "shortCiteRegEx": "Espinosa.Anke et al\\.", "year": 2016}, {"title": "Unsupervised word sense disambiguation with multilingual representations", "author": ["E. Fernandez-Ordonez", "R. Mihalcea", "S. Hassan"], "venue": "LREC, pages 847\u2013851.", "citeRegEx": "Fernandez.Ordonez et al\\.,? 2012", "shortCiteRegEx": "Fernandez.Ordonez et al\\.", "year": 2012}, {"title": "Two is bigger (and better) than one: the Wikipedia Bitaxonomy project", "author": ["T. Flati", "D. Vannella", "T. Pasini", "R. Navigli"], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 945\u2013955, Baltimore, USA.", "citeRegEx": "Flati et al\\.,? 2014", "shortCiteRegEx": "Flati et al\\.", "year": 2014}, {"title": "A systematic study of knowledge graph analysis for cross-language plagiarism detection", "author": ["M. Franco-Salvador", "P. Rosso", "M. Montes-y G\u00f3mez"], "venue": "Information Processing & Management.", "citeRegEx": "Franco.Salvador et al\\.,? 2016", "shortCiteRegEx": "Franco.Salvador et al\\.", "year": 2016}, {"title": "A graphbased method to improve Wordnet domains", "author": ["A. Gonz\u00e1lez", "G. Rigau", "M. Castillo"], "venue": "Proceedings of 13th International Conference on Intelligent Text Processing and Computational Linguistics (CICLING), pages 17\u201328, New Delhi, India.", "citeRegEx": "Gonz\u00e1lez et al\\.,? 2012", "shortCiteRegEx": "Gonz\u00e1lez et al\\.", "year": 2012}, {"title": "Learning to understand phrases by embedding the dictionary", "author": ["F. Hill", "K. Cho", "A. Korhonen", "Y. Bengio"], "venue": "arXiv preprint arXiv:1504.00548.", "citeRegEx": "Hill et al\\.,? 2015", "shortCiteRegEx": "Hill et al\\.", "year": 2015}, {"title": "Collaboratively built semi-structured content and Artificial Intelligence: The story so far", "author": ["E.H. Hovy", "R. Navigli", "S.P. Ponzetto"], "venue": "Artificial Intelligence, 194:2\u201327.", "citeRegEx": "Hovy et al\\.,? 2013", "shortCiteRegEx": "Hovy et al\\.", "year": 2013}, {"title": "Efficient word sense disambiguation technique for sentence level sentiment classification of online reviews", "author": ["M.F. Khan", "A. Khan", "K. Khan"], "venue": "Science International (Lahore), 25:937\u2013943.", "citeRegEx": "Khan et al\\.,? 2013", "shortCiteRegEx": "Khan et al\\.", "year": 2013}, {"title": "Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone", "author": ["M. Lesk"], "venue": "Proceedings of the 5th Annual Conference on Systems Documentation, Toronto, Ontario, Canada, pages 24\u201326.", "citeRegEx": "Lesk,? 1986", "shortCiteRegEx": "Lesk", "year": 1986}, {"title": "Senseval-3 task: Word-sense disambiguation of wordnet glosses", "author": ["K.C. Litkowski"], "venue": "In Proc. of SENSEVAL-3 Workshop on Sense Evaluation, in the 42th Annual Meeting of the Association for Computational Linguistics (ACL 2004. Citeseer.", "citeRegEx": "Litkowski,? 2004", "shortCiteRegEx": "Litkowski", "year": 2004}, {"title": "A semantic concordance", "author": ["G.A. Miller", "C. Leacock", "R. Tengi", "R. Bunker"], "venue": "Proceedings of the 3rd DARPA Workshop on Human Language Technology, pages 303\u2013308.", "citeRegEx": "Miller et al\\.,? 1993", "shortCiteRegEx": "Miller et al\\.", "year": 1993}, {"title": "Word sense disambiguation of wordnet glosses", "author": ["D. Moldovan", "A. Novischi"], "venue": "Computer Speech & Language, 18(3):301\u2013317.", "citeRegEx": "Moldovan and Novischi,? 2004", "shortCiteRegEx": "Moldovan and Novischi", "year": 2004}, {"title": "Entity Linking meets Word Sense Disambiguation: a Unified Approach", "author": ["A. Moro", "A. Raganato", "R. Navigli"], "venue": "Transactions of the Association for Computational Linguistics (TACL), 2:231\u2013244.", "citeRegEx": "Moro et al\\.,? 2014", "shortCiteRegEx": "Moro et al\\.", "year": 2014}, {"title": "BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network", "author": ["R. Navigli", "S.P. Ponzetto"], "venue": "Artificial Intelligence, 193:217\u2013250.", "citeRegEx": "Navigli and Ponzetto,? 2012", "shortCiteRegEx": "Navigli and Ponzetto", "year": 2012}, {"title": "Structural Semantic Interconnections: a knowledge-based approach to Word Sense Disambiguation", "author": ["R. Navigli", "P. Velardi"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(7):1075\u20131088.", "citeRegEx": "Navigli and Velardi,? 2005", "shortCiteRegEx": "Navigli and Velardi", "year": 2005}, {"title": "Learning Word-Class Lattices for definition and hypernym extraction", "author": ["R. Navigli", "P. Velardi"], "venue": "Pro-", "citeRegEx": "Navigli and Velardi,? 2010", "shortCiteRegEx": "Navigli and Velardi", "year": 2010}, {"title": "Word Sense Disambiguation: A survey", "author": ["R. Navigli"], "venue": "ACM Computing Surveys, 41(2):1\u201369.", "citeRegEx": "Navigli,? 2009", "shortCiteRegEx": "Navigli", "year": 2009}, {"title": "Towards a universal grammar for natural language processing", "author": ["J. Nivre"], "venue": "Computational Linguistics and Intelligent Text Processing, pages 3\u201316. Springer.", "citeRegEx": "Nivre,? 2015", "shortCiteRegEx": "Nivre", "year": 2015}, {"title": "Accurate semantic annotations via pattern matching", "author": ["A. Novischi"], "venue": "FLAIRS Conference, pages 375\u2013 379.", "citeRegEx": "Novischi,? 2002", "shortCiteRegEx": "Novischi", "year": 2002}, {"title": "Align, Disambiguate and Walk: a Unified Approach for Measuring Semantic Similarity", "author": ["M.T. Pilehvar", "D. Jurgens", "R. Navigli"], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1341\u20131351, Sofia, Bulgaria.", "citeRegEx": "Pilehvar et al\\.,? 2013", "shortCiteRegEx": "Pilehvar et al\\.", "year": 2013}, {"title": "MindNet: Acquiring and Structuring Semantic Information from Text", "author": ["S.D. Richardson", "W.B. Dolan", "L. Vanderwende"], "venue": "Proceedings of ACL, pages 1098\u20131102.", "citeRegEx": "Richardson et al\\.,? 1998", "shortCiteRegEx": "Richardson et al\\.", "year": 1998}, {"title": "Feature-rich part-of-speech tagging with a cyclic dependency network", "author": ["K. Toutanova", "D. Klein", "C.D. Manning", "Y. Singer"], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language", "citeRegEx": "Toutanova et al\\.,? 2003", "shortCiteRegEx": "Toutanova et al\\.", "year": 2003}, {"title": "OntoLearn Reloaded: A Graph-Based Algorithm for Taxonomy Induction", "author": ["P. Velardi", "S. Faralli", "R. Navigli"], "venue": "Computational Linguistics, 39(3):665\u2013707.", "citeRegEx": "Velardi et al\\.,? 2013", "shortCiteRegEx": "Velardi et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 19, "context": "Some of the areas where the use of definitional knowledge has proved to be key in achieving state-of-the-art results are Word Sense Disambiguation (Lesk, 1986; Banerjee and Pedersen, 2002; Navigli and Velardi, 2005; Agirre and Soroa, 2009; Fernandez-Ordonez et al., 2012; Chen et al., 2014; Camacho-Collados et al., 2015b), Taxonomy and Ontology Learning (Velardi et al.", "startOffset": 147, "endOffset": 322}, {"referenceID": 1, "context": "Some of the areas where the use of definitional knowledge has proved to be key in achieving state-of-the-art results are Word Sense Disambiguation (Lesk, 1986; Banerjee and Pedersen, 2002; Navigli and Velardi, 2005; Agirre and Soroa, 2009; Fernandez-Ordonez et al., 2012; Chen et al., 2014; Camacho-Collados et al., 2015b), Taxonomy and Ontology Learning (Velardi et al.", "startOffset": 147, "endOffset": 322}, {"referenceID": 25, "context": "Some of the areas where the use of definitional knowledge has proved to be key in achieving state-of-the-art results are Word Sense Disambiguation (Lesk, 1986; Banerjee and Pedersen, 2002; Navigli and Velardi, 2005; Agirre and Soroa, 2009; Fernandez-Ordonez et al., 2012; Chen et al., 2014; Camacho-Collados et al., 2015b), Taxonomy and Ontology Learning (Velardi et al.", "startOffset": 147, "endOffset": 322}, {"referenceID": 0, "context": "Some of the areas where the use of definitional knowledge has proved to be key in achieving state-of-the-art results are Word Sense Disambiguation (Lesk, 1986; Banerjee and Pedersen, 2002; Navigli and Velardi, 2005; Agirre and Soroa, 2009; Fernandez-Ordonez et al., 2012; Chen et al., 2014; Camacho-Collados et al., 2015b), Taxonomy and Ontology Learning (Velardi et al.", "startOffset": 147, "endOffset": 322}, {"referenceID": 12, "context": "Some of the areas where the use of definitional knowledge has proved to be key in achieving state-of-the-art results are Word Sense Disambiguation (Lesk, 1986; Banerjee and Pedersen, 2002; Navigli and Velardi, 2005; Agirre and Soroa, 2009; Fernandez-Ordonez et al., 2012; Chen et al., 2014; Camacho-Collados et al., 2015b), Taxonomy and Ontology Learning (Velardi et al.", "startOffset": 147, "endOffset": 322}, {"referenceID": 5, "context": "Some of the areas where the use of definitional knowledge has proved to be key in achieving state-of-the-art results are Word Sense Disambiguation (Lesk, 1986; Banerjee and Pedersen, 2002; Navigli and Velardi, 2005; Agirre and Soroa, 2009; Fernandez-Ordonez et al., 2012; Chen et al., 2014; Camacho-Collados et al., 2015b), Taxonomy and Ontology Learning (Velardi et al.", "startOffset": 147, "endOffset": 322}, {"referenceID": 4, "context": "Some of the areas where the use of definitional knowledge has proved to be key in achieving state-of-the-art results are Word Sense Disambiguation (Lesk, 1986; Banerjee and Pedersen, 2002; Navigli and Velardi, 2005; Agirre and Soroa, 2009; Fernandez-Ordonez et al., 2012; Chen et al., 2014; Camacho-Collados et al., 2015b), Taxonomy and Ontology Learning (Velardi et al.", "startOffset": 147, "endOffset": 322}, {"referenceID": 33, "context": ", 2015b), Taxonomy and Ontology Learning (Velardi et al., 2013; Flati et al., 2014; Espinosa-Anke et al., 2016), Information Extraction (Richardson et al.", "startOffset": 41, "endOffset": 111}, {"referenceID": 13, "context": ", 2015b), Taxonomy and Ontology Learning (Velardi et al., 2013; Flati et al., 2014; Espinosa-Anke et al., 2016), Information Extraction (Richardson et al.", "startOffset": 41, "endOffset": 111}, {"referenceID": 11, "context": ", 2015b), Taxonomy and Ontology Learning (Velardi et al., 2013; Flati et al., 2014; Espinosa-Anke et al., 2016), Information Extraction (Richardson et al.", "startOffset": 41, "endOffset": 111}, {"referenceID": 31, "context": ", 2016), Information Extraction (Richardson et al., 1998; Delli Bovi et al., 2015), Plagiarism Detection (Franco-Salvador et al.", "startOffset": 32, "endOffset": 82}, {"referenceID": 14, "context": ", 2015), Plagiarism Detection (Franco-Salvador et al., 2016), and Question Answering (Hill et al.", "startOffset": 30, "endOffset": 60}, {"referenceID": 16, "context": ", 2016), and Question Answering (Hill et al., 2015).", "startOffset": 32, "endOffset": 51}, {"referenceID": 27, "context": "This has the potential to be especially valuable in the context of disambiguation (Navigli, 2009), where highly ambiguous terms in one language may become less ambiguous (or even unambiguous) in other languages.", "startOffset": 82, "endOffset": 97}, {"referenceID": 24, "context": "In order to do this we leverage BabelNet2 (Navigli and Ponzetto, 2012), a multilingual lexicalized semantic network obtained from the automatic integration of lexicographic and encyclopedic resources.", "startOffset": 42, "endOffset": 70}, {"referenceID": 18, "context": "In fact, WordNet glosses have still been used successfully in recent work (Khan et al., 2013; Chen et al., 2015).", "startOffset": 74, "endOffset": 112}, {"referenceID": 6, "context": "In fact, WordNet glosses have still been used successfully in recent work (Khan et al., 2013; Chen et al., 2015).", "startOffset": 74, "endOffset": 112}, {"referenceID": 29, "context": "A first attempt to disambiguate WordNet glosses automatically was proposed as part of the eXtended WordNet project3 (Novischi, 2002).", "startOffset": 116, "endOffset": 132}, {"referenceID": 21, "context": "Moldovan and Novischi (2004) proposed an alternative disambiguation approach, specifically targeted at the WordNet sense inventory and based on a supervised model trained on the SemCor sense-annotated corpus (Miller et al., 1993).", "startOffset": 208, "endOffset": 229}, {"referenceID": 20, "context": "Another disambiguation task focused on WordNet glosses was presented as part of the SensEval-3 workshop (Litkowski, 2004).", "startOffset": 104, "endOffset": 121}, {"referenceID": 30, "context": "The Princeton corpus of WordNet disambiguated glosses has already been shown to be successful as part of the pipeline in semantic similarity (Pilehvar et al., 2013), domain labeling (Gonz\u00e1lez et al.", "startOffset": 141, "endOffset": 164}, {"referenceID": 15, "context": ", 2013), domain labeling (Gonz\u00e1lez et al., 2012) and Word Sense Disambiguation (Agirre and Soroa, 2009; Camacho-Collados et al.", "startOffset": 25, "endOffset": 48}, {"referenceID": 0, "context": ", 2012) and Word Sense Disambiguation (Agirre and Soroa, 2009; Camacho-Collados et al., 2015b) systems.", "startOffset": 38, "endOffset": 94}, {"referenceID": 4, "context": ", 2012) and Word Sense Disambiguation (Agirre and Soroa, 2009; Camacho-Collados et al., 2015b) systems.", "startOffset": 38, "endOffset": 94}, {"referenceID": 26, "context": "With a view to tackling this problem, a great deal of research has recently focused on the automatic extraction of definitions from unstructured text (Navigli and Velardi, 2010; Benedictis et al., 2013; Espinosa-Anke and Saggion, 2014; Dalvi et al., 2015).", "startOffset": 150, "endOffset": 255}, {"referenceID": 2, "context": "With a view to tackling this problem, a great deal of research has recently focused on the automatic extraction of definitions from unstructured text (Navigli and Velardi, 2010; Benedictis et al., 2013; Espinosa-Anke and Saggion, 2014; Dalvi et al., 2015).", "startOffset": 150, "endOffset": 255}, {"referenceID": 10, "context": "With a view to tackling this problem, a great deal of research has recently focused on the automatic extraction of definitions from unstructured text (Navigli and Velardi, 2010; Benedictis et al., 2013; Espinosa-Anke and Saggion, 2014; Dalvi et al., 2015).", "startOffset": 150, "endOffset": 255}, {"referenceID": 7, "context": "With a view to tackling this problem, a great deal of research has recently focused on the automatic extraction of definitions from unstructured text (Navigli and Velardi, 2010; Benedictis et al., 2013; Espinosa-Anke and Saggion, 2014; Dalvi et al., 2015).", "startOffset": 150, "endOffset": 255}, {"referenceID": 17, "context": "On the other hand, the prominent role of collaborative resources (Hovy et al., 2013) has created a convenient development ground for NLP systems based on encyclopedic definitional knowledge.", "startOffset": 65, "endOffset": 84}, {"referenceID": 1, "context": ", 2013; Chen et al., 2015). A first attempt to disambiguate WordNet glosses automatically was proposed as part of the eXtended WordNet project3 (Novischi, 2002). However, this attempt\u2019s estimated coverage did not reach 6% of the total amount of sense-annotated instances. Moldovan and Novischi (2004) proposed an alternative disambiguation approach, specifically targeted at the WordNet sense inventory and based on a supervised model trained on the SemCor sense-annotated corpus (Miller et al.", "startOffset": 8, "endOffset": 301}, {"referenceID": 23, "context": "shtml multilingual Word Sense Disambiguation/Entity Linking system (Moro et al., 2014) and a vector-based semantic representation of concepts and entities (Camacho-Collados et al.", "startOffset": 67, "endOffset": 86}, {"referenceID": 3, "context": ", 2014) and a vector-based semantic representation of concepts and entities (Camacho-Collados et al., 2015a).", "startOffset": 76, "endOffset": 108}, {"referenceID": 32, "context": "We train the Stanford tagger (Toutanova et al., 2003), for 30 languages using the available data from the Universal Dependencies project7(Nivre, 2015).", "startOffset": 29, "endOffset": 53}, {"referenceID": 28, "context": ", 2003), for 30 languages using the available data from the Universal Dependencies project7(Nivre, 2015).", "startOffset": 91, "endOffset": 104}, {"referenceID": 23, "context": "We use a state-of-the-art graph-based approach to Entity Linking and Word Sense Disambiguation, Babelfy8 (Moro et al., 2014), to disambiguate definitions after preprocessing and context-enrichment.", "startOffset": 105, "endOffset": 124}, {"referenceID": 3, "context": "In order to refine the disambiguated instances in L, we use NASARI9 (Camacho-Collados et al., 2015a; Camacho-Collados et al., 2015b).", "startOffset": 68, "endOffset": 132}, {"referenceID": 4, "context": "In order to refine the disambiguated instances in L, we use NASARI9 (Camacho-Collados et al., 2015a; Camacho-Collados et al., 2015b).", "startOffset": 68, "endOffset": 132}, {"referenceID": 9, "context": "Following Delli Bovi et al. (2015), we relied on two human judges and performed the same evaluation procedure described therein over the set of distinct relations extracted from the sample, as well as the set of extracted relation instances.", "startOffset": 16, "endOffset": 35}, {"referenceID": 17, "context": "A meaningful cluster of senses within these sense inventories would help boost the performance in different applications (Hovy et al., 2013).", "startOffset": 121, "endOffset": 140}, {"referenceID": 3, "context": "We follow the original setting of (Camacho-Collados et al., 2015a) and only cluster a pair of Wikipedia articles if their similarity, calculated by using the square-rooted Weighted Overlap comparison measure (Pilehvar et al.", "startOffset": 34, "endOffset": 66}, {"referenceID": 30, "context": ", 2015a) and only cluster a pair of Wikipedia articles if their similarity, calculated by using the square-rooted Weighted Overlap comparison measure (Pilehvar et al., 2013), surpasses 0.", "startOffset": 150, "endOffset": 173}, {"referenceID": 6, "context": "We used the two sense clustering datasets created by Dandala et al. (2013). The task in these datasets consists of, given a pair of Wikipedia articles, to decide whether they should be merged into a single cluster or not.", "startOffset": 53, "endOffset": 75}, {"referenceID": 8, "context": "For comparison we also include the Support Vector Machine classifier of Dandala et al. (2013) exploiting information of Wikipedia in four different languages (Dandala-multilingual).", "startOffset": 72, "endOffset": 94}], "year": 2016, "abstractText": "Linking concepts and named entities to knowledge bases has become a crucial Natural Language Understanding task. In this respect, recent works have shown the key advantage of exploiting textual definitions in various Natural Language Processing applications. However, to date there are no reliable large-scale corpora of sense-annotated textual definitions available to the research community. In this paper we present a large-scale high-quality corpus of disambiguated glosses in multiple languages, comprising sense annotations of both concepts and named entities from a unified sense inventory. Our approach for the construction and disambiguation of the corpus builds upon the structure of a large multilingual semantic network and a state-of-the-art disambiguation system; first, we gather complementary information of equivalent definitions across different languages to provide context for disambiguation, and then we combine it with a semantic similarity-based refinement. As a result we obtain a multilingual corpus of textual definitions featuring over 38 million definitions in 263 languages, and we make it freely available at http://lcl.uniroma1.it/disambiguated-glosses. Experiments on Open Information Extraction and Sense Clustering show how two state-of-the-art approaches improve their performance by integrating our disambiguated corpus into their pipeline.", "creator": "LaTeX with hyperref package"}}}