{"id": "1608.07879", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Aug-2016", "title": "Causality and Responsibility for Formal Verification and Beyond", "abstract": "The theory of actual causality, defined by Halpern and Pearl, and its quantitative measure - the degree of responsibility - was shown to be extremely useful in various areas of computer science due to a good match between the results it produces and our intuition. In this paper, I describe the applications of causality to formal verification, namely, explanation of counterexamples, refinement of coverage metrics, and symbolic trajectory evaluation. I also briefly discuss recent applications of causality to legal reasoning.", "histories": [["v1", "Mon, 29 Aug 2016 01:35:46 GMT  (19kb,D)", "http://arxiv.org/abs/1608.07879v1", "In Proceedings CREST 2016,arXiv:1608.07398. Invited paper"]], "COMMENTS": "In Proceedings CREST 2016,arXiv:1608.07398. Invited paper", "reviews": [], "SUBJECTS": "cs.SE cs.AI", "authors": ["hana chockler"], "accepted": false, "id": "1608.07879"}, "pdf": {"name": "1608.07879.pdf", "metadata": {"source": "CRF", "title": "Causality and Responsibility for Formal Verification and Beyond", "authors": ["Hana Chockler"], "emails": ["hana.chockler@kcl.ac.uk"], "sections": [{"heading": null, "text": "G. Go\u0308ssler and O. Sokolsky (Eds.): 1st Workshop on Causal Reasoning for Embedded and safety-critical Systems Technologies (CREST\u201916) EPTCS 224, 2016, pp. 1\u20138, doi:10.4204/EPTCS.224.1\nc\u00a9 Hana Chockler This work is licensed under the Creative Commons Attribution License.\nCausality and Responsibility for Formal Verification and Beyond\nHana Chockler Department of Informatics\nKing\u2019s College London hana.chockler@kcl.ac.uk\nThe theory of actual causality, defined by Halpern and Pearl, and its quantitative measure \u2013 the degree of responsibility \u2013 was shown to be extremely useful in various areas of computer science due to a good match between the results it produces and our intuition. In this paper, I describe the applications of causality to formal verification, namely, explanation of counter-examples, refinement of coverage metrics, and symbolic trajectory evaluation. I also briefly discuss recent applications of causality to legal reasoning."}, {"heading": "1 Introduction", "text": "The definition of causality given by Halpern and Pearl [15], like other definitions of causality in the philosophy literature going back to Hume [19], is based on counterfactual dependence. Essentially, event A is a cause of event B if, had A not happened (this is the counterfactual condition, since A did in fact happen) then B would not have happened. Unfortunately, this definition does not capture all the subtleties involved with causality. For example, suppose that Suzy and Billy both pick up rocks and throw them at a bottle ( the example is due to Hall [14]). Suzy\u2019s rock gets there first, shattering the bottle. Since both throws are perfectly accurate, Billy\u2019s would have shattered the bottle had it not been preempted by Suzy\u2019s throw. (This story is taken from [14].) Thus, according to the counterfactual condition, Suzy\u2019s throw is not a cause for shaterring the bottle. This problem is dealt with in [15] by, roughly speaking, taking A to be a cause of B if B counterfactually depends on A under some contingency. For example, Suzy\u2019s throw is a cause of the bottle shattering because the bottle shattering counterfactually depends on Suzy\u2019s throw, under the contingency that Billy doesn\u2019t throw. It may seem that this solves one problem only to create another. While this allows Suzy\u2019s throw to be a cause of the bottle shattering, it also seems to allow Billy\u2019s throw to be a cause too, which seems counter-intuitive to most people. As is shown in [17], it is possible to build a more sophisticated model that expresses the subtlety of pre-emption in this case, using auxiliary variables to express the order in which the rocks hit the bottle and preventing Billy\u2019s throw from being a cause of the bottle shattering. One moral of this example is that, according to the [17] definitions, whether or not A is a cause of B depends in part on the model used.\nHalpern and Pearl\u2019s definition of causality, while extending and refining the counter-factual definition, still treats causality as an all-or-nothing concept. That is, A is either a cause of B or it is not. The concept of responsibility, introduced in [5], presents a way to quantify causality and hence the ability to measure the degree of influence (aka \u201cthe degree of responsibility\u201d) of different causes on the outcome. For example, suppose that Mr. B wins an election against Mr. G. If the vote has been 11\u20130, it is clear that each of the people who voted for Mr. B is a cause of him winning, but the degree of responsibility of each voter for Mr. B is lower than in a vote 6\u20135.\nThinking in terms of causality and responsibility was shown to be beneficial for a seemingly unrelated area of research, namely formal verification (model checking) of computerised systems. In model\nchecking, we verify the correctness of a finite-state system with respect to a desired behavior by checking whether a labeled state-transition graph that models the system satisfies a specification of this behavior [12]. If the answer to the correctness query is negative, the tool provides a counterexample to the satisfaction of the specification in the system. These counterexamples are used for debugging the system, as they demonstrate an example of an erroneous behaviour [13]. As counterexamples can be very long and complex, there is a need for an additional tool explaining \u201cwhat went wrong\u201d, that is, pinpointing the causes of an error on the counterexample. As I describe in more details in the following sections, the causal analysis of counterexamples, described in [2], is an integral part of an industrial hardware verification platform RuleBase of IBM [25].\nOn the other hand, if the answer is positive, the tools usually perform some type of a sanity check, to verify that the positive result was not caused by an error or underspecification (see [20] for a survey). Vacuity check, which is the most common sanity check and is a standard in industrial model checking tools, was first defined by Beer et al. [3] as a situation, where the property passes in a \u201cnon-interesting way\u201d, that is, a part of a property does not affect the model checking procedure in the system. Beer et al. state that vacuity was a serious problem in verification of hardware designs at IBM: \u201cour experience has shown that typically 20% of specifications pass vacuously during the first formal-verification runs of a new hardware design, and that vacuous passes always point to a real problem in either the design or its specification or environment\u201d [3]. The general vacuity problem was formalised by Kupferman and Vardi, who defined a vacuous pass as a pass, where some subformula of the original property can be replaced by its\u22a5 value without affecting the satisfaction of the property in the system [21], and there is a plethora of subsequent papers and definitions addressing different aspects and nuances of vacuous satisfaction.\nNote that vacuity, viewed from the point of view of causal analysis, is counterfactual causality. Indeed, a property passes non-vacuously if each its subformula, if replaced by \u22a5, causes falsification of the property in the system. Due to the nature of specifications as more general than implementations, it is quite natural to expect that the specification allows some degree of freedom in how it is going to be satisfied. Consider, for example, a specification G(p\u2228q), meaning that either p or q should hold in each state. If in the system under verification both p and q are true in all states, the standard vacuity check will alert the verification engineer to vacuity in p and in q. In contrast, introducing a contingency where p is set to false causes the result of model checking to counterfactually depend on q (and similarly for q and p), indicating that both p and q play some role in the satisfaction of the specification in the system.\nCoverage check is a concept \u201cborrowed\u201d from testing and simulation-based verification, where various coverage metrics are traditionally used as heuristic measures of exhaustiveness of the verification procedure [29]. In model checking, the suitable coverage concept is mutation coverage, introduced by Hoskote et al. [18], and formalized in [8, 7, 6, 9]. In this definition, an element of the system under verification is considered covered by the specification if changing (mutating) this element falsifies the specification in the system. Note, again, that this definition is, essentially, a counter-factual causality. As a motivating example to the necessity to finer-grained analysis consider the property Freq, meaning in every computation there is at least one request. Now consider a system in which requests are sent frequently, resulting in several requests on each of the computational paths. All these requests will be considered not covered by the mutation coverage metric, as changing each one of them separately to false does not falsify the property; and yet, each of these requests plays a role in the satisfaction of the specification (or, using the notions from causality, for each request there exists a contingency that creates a counterfactual dependence between this request and the satisfaction of the specification) [11].\nWhile causality allows to extend the concepts of vacuity and coverage to include elements that affect the satisfaction of the specification in the system in some way, it is still an all-or-nothing concept. Harnessing the notion of responsibility to measure the influence of different elements on the success or\nfailure of the model checking process introduces the quantification aspect, providing a finer-grained analysis. While, as I discuss in more detail below, the full-blown responsibility computation is intractable for all but very small systems, introducing a threshold on the value of responsibility, in order to detect only the most influential causes, reduces the complexity and makes the computation manageable for real systems [11].\nThe quantification provided by the notion of responsibility and the distinction between influential and non-influential causes have been applied to the symbolic trajectory evaluation, where ordering the causes by their degree of responsibility was demonstrated to be a good heuristic for instantiating a minimal number of variables that is sufficient to determine the output value of the circuit [4].\nIn the next sections I provide a brief overview of the relevant concepts and describe the applications of causality to formal verification in more detail."}, {"heading": "2 Causality and Responsibility \u2013 Definitions", "text": "In this section, I briefly review the details of Halpern and Pearl\u2019s definition (HP) of causal models and causality [15] and the definitions of responsibility and blame [5] in causal models."}, {"heading": "2.1 Causal models", "text": "A signature is a tuple S = \u3008U,V,R\u3009, where U is a finite set of exogenous variables, V is a finite set of endogenous variables, and R associates with every variable Y \u2208 U\u222aV a finite nonempty set R(Y ) of possible values for Y . Intuitively, the exogenous variables are ones whose values are determined by factors outside the model, while the endogenous variables are ones whose values are ultimately determined by the exogenous variables. A (recursive) causal model over signature S is a tuple M = \u3008S,F\u3009, where F associates with every endogenous variable X \u2208 V a function FX such that FX : (\u00d7U\u2208UR(U)\u00d7 (\u00d7Y\u2208V\\{X}R(Y )))\u2192 R(X), and functions have no circular dependency. That is, FX describes how the value of the endogenous variable X is determined by the values of all other variables in U\u222aV. If all variables have only two values, we say that M is a binary causal model.\nWe can describe (some salient features of) a causal model M using a causal network, which is a graph with nodes corresponding to the variables in M and edges corresponding to the dependence between variables. We focus our attention on recursive models \u2013 those whose associated causal network is a directed acyclic graph.\nA causal network is a graph with nodes corresponding to the random variables in V and an edge from a node labeled X to one labeled Y if FY depends on the value of X . Intuitively, variables can have a causal effect only on their descendants in the causal network; if Y is not a descendant of X , then a change in the value of X has no affect on the value of Y . A setting~u for the variables in U is called a context. It should be clear that if M is a recursive causal model, then there is always a unique solution to the equations in M, given a context.\nGiven a causal model M = (S,F), a (possibly empty) vector ~X of variables in V, and a vector ~x of values for the variables in ~X , a new causal model, denoted M~X\u2190~x, is defined as identical to M, except that the equation for the variables ~X in F is replaced by ~X =~x. Intuitively, this is the causal model that results when the variables in ~X are set to ~x by some external action that affects only the variables in ~X (and overrides the effects of the causal equations).\nA causal formula \u03d5 \u2013 a Boolean combination of events capturing the value of variables in the model \u2013 is true or false in a causal model, given a context. We write (M,~u) |= \u03d5 if \u03d5 is true in the causal model\nM, given the context ~u. (M,~u) |= [~Y \u2190~y](X = x) if the variable X has value x in the unique solution to the equations in M~Y\u2190~y in context~u. We now review the HP definition of causality..\nDefinition 2.1 (Cause [15]) ~X =~x is a cause of \u03d5 in (M,~u) if the following three conditions hold:\nAC1. (M,~u) |= (~X =~x)\u2227\u03d5 .\nAC2. There exist a partition (~Z, ~W ) of V with ~X \u2286 ~Z and some setting (~x\u2032,~w) of the variables in (~X , ~W ) such that if (M,~u) |= Z = z\u2217 for Z \u2208~Z, then\n(a) (M,~u) |= [~X \u2190~x\u2032, ~W \u2190 ~w]\u00ac\u03d5 . (b) (M,~u) |= [~X \u2190~x, ~W \u2032\u2190 ~w,~Z\u2032\u2190~z\u2217]\u03d5 for all subsets ~Z\u2032 of ~Z \\~X and all subsets ~W \u2032 of ~W. The\ntuple (~W ,~w,~x\u2032) is said to be a witness to the fact that ~X =~x is a cause of \u03d5 .\nAC3. (~X =~x) is minimal; no subset of ~X satisfies AC2.\nEssentially, Definition 2.1 extends the counterfactual definition of causality by considering contingencies ~W \u2013 changes in the current context that by themselves do not change the value of \u03d5 , but create a counterfactual dependence between the value of a ~X and the value of \u03d5 . The variables in ~Z should be thought of as describing the \u201cactive causal process\u201d from X to \u03d5 , and are needed in order to make sure that, while introducing contingencies, we preserve the causal process from ~X to \u03d5 . The minimality requirement AC3 is needed in order to avoid adding irrelevant variables to ~X .\nWe note that Halpern recently updated the definition of causality, changing the concept to focus on the variables that are frozen in their original values, rather than considering contingencies [16]. Since the existing work on the applications of causality to formal verification uses the previous definition, we continue using it in this paper."}, {"heading": "2.2 Responsibility and Blame", "text": "Causality is a \u201c0\u20131\u201d concept; ~X =~x is either a cause of \u03d5 or it is not. Now consider two voting scenarios: in the first, Mr. G beats Mr. B by a vote of 11\u20130. In the second, Mr. G beats Mr. B by a vote of 6\u20135. According to the HP definition, all the people who voted for Mr. G are causes of him winning. While this does not seem so unreasonable, it does not capture the intuition that each voter for Mr. G is more critical to the victory in the case of the 6\u20135 vote than in the case of the 11\u20130 vote. The notion of degree of responsibility, introduced by Chockler and Halpern [5], extends the notion of causality to capture the differences in the degree of criticality of causes. In the case of the 6\u20135 vote, no changes have to be made to make each voter for Mr. G critical for Mr. G\u2019s victory; if he had not voted for Mr. G, Mr. G would not have won. Thus, each voter has degree of responsibility 1 (i.e., k = 0). On the other hand, in the case of the 11\u20130 vote, for a particular voter to be critical, five other voters have to switch their votes; thus, k = 5, and each voter\u2019s degree of responsibility is 1/6. This notion of degree of responsibility has been shown to capture (at a qualitative level) the way people allocate responsibility [22].\nDefinition 2.2 (Degree of Responsibility [5]) The degree of responsibility of ~X = ~x for \u03d5 in (M,~u), denoted dr((M,~u),(~X \u2190~x),\u03d5), is 0 if ~X =~x is not a cause of \u03d5 in (M,~u); it is 1/(k+ 1) if ~X =~x is a cause of \u03d5 in (M,~u) according to Definition 2.1 with ~W of size k being a smallest witness to the fact that ~X =~x is a cause of \u03d5 .\nWhen determining responsibility, it is assumed that everything relevant about the facts of the world and how the world works (which we characterize in terms of structural equations) is known. But this misses out on important component of determining what Chockler and Halpern call blame: the epistemic state. Formally, the degree of blame, introduced by Chockler and Halpern is the expected degree of\nresponsibility [5]. This is perhaps best understood by considering a firing squad with ten excellent marksmen (the example is by Tim Williamson). Only one of them has live bullets in his rifle; the rest have blanks. The marksmen do not know which of them has the live bullets. The marksmen shoot at the prisoner and he dies. The only marksman that is the cause of the prisoner\u2019s death is the one with the live bullets. That marksman has degree of responsibility 1 for the death; all the rest have degree of responsibility 0. However, each of the marksmen has degree of blame 1/10.\nAn agent\u2019s uncertainty is modelled by a pair (K,Pr), where K is a set of pairs of the form (M,~u), where M is a causal model and ~u is a context, and Pr is a probability distribution over K. Note that probability is used here in a rather non-traditional sense, to capture the epistemic state of an agent, rather than an actual probability over values of variables. Definition 2.3 (Blame [5]) The degree of blame of setting ~X to~x for \u03d5 relative to epistemic state (K,Pr), denoted db(K,Pr,~X \u2190 ~x,\u03d5), is defined as an expected value of the degree of responsibility over the probability space (K,Pr)."}, {"heading": "3 Coverage in the framework of causality", "text": "The following definition of coverage is based on the study of mutant coverage in simulation-based verification [23, 24, 1], and is the one that is adopted in all (or almost all) papers on coverage metrics in formal verification today (see, for example, [18, 8, 7, 6, 9]). For a Kripke structure K, an atomic proposition q, and a state w, we denote by K\u0303w,q the Kripke structure obtained from K by flipping the value of q in w. Definition 3.1 (Coverage) Consider a Kripke structure K, a specification \u03d5 that is satisfied in K, and an atomic proposition q \u2208 AP. A state w of K is q-covered by \u03d5 if K\u0303w,q does not satisfy \u03d5 .\nIt is easy to see that coverage corresponds to the simple counterfactual-dependence approach to causality. Indeed, a state w of K is q-covered by \u03d5 if \u03d5 holds in K and if q had other value in w, then \u03d5 would not have been true in K. The following example illustrates the notion of coverage and shows that the counter-factual approach to coverage misses some important insights in how the system satisfies the specification. Let K be a Kripke structure presented with one path, where one request is followed by three grants in subsequent states, and let \u03d5 = G(req\u2192 Fgrant) (every request is eventually granted). It is easy to see that K satisfies \u03d5 , but that none of the states are covered with respect to grant, as flipping the value of grant in one of them does not falsify \u03d5 in K. On the other hand, representing the model checking procedure as a causal model with a context corresponding to the actual values of atomic propositions in states (see [11] for a formal description of this representation), demonstrates that for each state there exists a contingency where the result counterfactually depends on the value of grant in this state; the contingency is removing grants in the two other states. Hence, while none of the states is covered with respect to grant, they are all causes of \u03d5 in K with the responsibility 1/3.\nIn the example above, and typically in the applications of causality to formal verification, there are no structural equations over the internal endogenous variables. However, if we want to express the temporal characteristics of our model \u2013 for example, to say that the first grant is important, whereas subsequent ones are not \u2013 the way to do so is by introducing internal auxiliary variables, expressing the order between the grants in the system."}, {"heading": "4 Explanation of Counterexamples Using Causality", "text": "Explanation of counterexamples addresses a basic aspect of understanding a counterexample: the task of finding the failure in the trace itself. To motivate this approach, consider a verification engineer, who\nis formally verifying a hardware design written by a logic designer. The verification engineer writes a specification \u2013 a temporal logic formula \u2013 and runs a model checker, in order to check the formula on the design. If the formula fails on the design-under-test (DUT), a counterexample trace is produced and displayed in a trace viewer. The verification engineer does not attempt to debug the DUT implementation (since that is the responsibility of the the logic designer who wrote it). Her goal is to look for some basic information about the manner in which the formula fails on the specific trace. If the formula is a complex combination of several conditions, she needs to know which of these conditions has failed. These basic questions are prerequisites to deeper investigations of the failure. Ben-David et al. present a method and a tool for explaining the trace, without involving the model from which it was extracted [2]. This gives the approach the advantage of being light-weight, as its running time depends only on the size of the specification and the counterexample, which is much smaller than the size of the system. An additional advantage of the tool is that it is independent on the verification procedure, and can be added as an external layer to any tool, or even applied as an explanation of simulation traces. The main idea of the algorithm is to represent the trace and the property that fails on this trace as a causal model and context (see Section 3 on the description of the transformation). Then, the values of signals in specific cycles are viewed as variables, and the set of causes for failure is marked as red dots on the trace that is shown to the user graphically, in form of a timing diagram. The tool is a part of the IBM RuleBase verification platform [25] and is used extensively by the users. While the trace is small compared to the system, the complexity of the exact algorithm for computing causality leads to time-consuming computations; in order to keep the interactive nature of the tool, the algorithm operates in one pass on the trace and computes an approximate set of causes, which coincides with the actual set of causes on all but contrived examples. The reader is referred to [2] for more details of the implementation."}, {"heading": "5 Responsibility in Symbolic Trajectory Evaluation", "text": "Symbolic Trajectory Evaluation (STE) [27] is a powerful model checking technique for hardware verification, which combines symbolic simulation with 3-valued abstraction. Consider a circuit M, described as a Directed Acyclic Graph of nodes that represent gates and latches. For such a circuit, an STE assertion is of the form A\u2192C, where the Antecedent A imposes constraints over nodes of M at different times, and the Consequent C imposes requirements on M\u2019s nodes at different times. The antecedent may introduce symbolic Boolean variables on some of the nodes. The nodes that are not restricted by A are initialized by STE to the value X (\u201dunknown\u201d), thus obtaining an abstraction of the checked model.\nSTE is successfully used in the hardware industry for verifying very large models with wide data paths [28, 26, 30]. The common method for performing STE is by representing the values of each node in the circuit by Binary Decision Diagrams (BDDs). To avoid the potential state explosion resulting from instantiating all unconstrained nodes, typically the circuit is refined manually in iterations, until the value of the circuit is determined.\nTo avoid the need for manual refinement (which requires a close familiarity with the structure of the circuit), [4] suggest to compute an approximation of the degree of responsibility of each node in the value of the output circuit. Then, the instantiation can proceed in the order of decreasing degree of responsibility. The idea behind this algorithm is that the nodes with the highest degree of responsibility are more likely to influence the value of the circuit, and hence we will avoid instantiating too many nodes. The algorithm was implemented in Intel STE framework for hardware verification and demonstrated better results than manual refinement [4]."}, {"heading": "6 . . . and Beyond", "text": "In formal verification, there is no natural application for the notion of blame (Def. 2.3), since the model and the property are assumed to be known. On the other hand, in legal applications it is quite natural to talk about an epistemic state of an agent, representing what the agent knew or should have known. As [15] points out, the legal system does not agree with the structural definitions of causality, responsibility, and blame. However, it is still possible to apply our methodology of representing a problem using causal models in order to improve our understanding and analysis of particular situations. In [10], we make the case of using the framework of actual causality in order to guide legal inquiry. In fact, the concepts of responsibility and blame fit the procedure of legal inquiry very well, since we can capture both the limited knowledge of the participants in the case, and the unknown factors in the case. We use the case of baby P. \u2013 a baby that died from continuous neglect and abuse, which was completely missed by the social services and the doctor who examined him \u2013 to demonstrate how we can capture the known and unknown factors in the case and attempt to quantify the blame of different parties involved in the case."}], "references": [{"title": "A specification-based coverage metric to evaluate test", "author": ["P.E.P. Ammann"], "venue": "Black", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "Explaining counterexamples using causality", "author": ["I. Beer", "S. Ben-David", "H. Chockler", "A. Orni", "R.J. Trefler"], "venue": "Formal Methods in System Design", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Efficient detection of vacuity in ACTL formulas", "author": ["I. Beer", "S. Ben-David", "C. Eisner", "Y. Rodeh"], "venue": "Formal Methods in System Design", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2001}, {"title": "Efficient automatic STE refinement using responsibility", "author": ["H. Chockler", "O. Grumberg", "A. Yadgar"], "venue": "Proc. 14th Conference on Tools and Algorithms for the Construction and Analysis of Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Responsibility and blame: a structural-model approach", "author": ["J.Y.H. Chockler"], "venue": "Journal of Artificial Intelligence Research (JAIR)", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Coverage of Implementations by Simulating Specifications", "author": ["H. Chockler", "O. Kupferman"], "venue": "editors: Proceedings of 2nd IFIP International Conference on Theoretical Computer Science, IFIP Conference Proceedings", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "A Practical Approach to Coverage in Model Checking", "author": ["H. Chockler", "O. Kupferman", "M.Y.R.P. Kurshan"], "venue": "Computer Aided Verification, Proc. 13th International Conference, Lecture Notes in Computer Science 2102,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "Coverage Metrics for Temporal Logic Model Checking. In: Tools and algorithms for the construction and analysis of systems, Lecture Notes in Computer Science 2031", "author": ["H. Chockler", "M.Y.O. Kupferman"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Coverage Metrics for Formal Verification. In: Correct Hardware Design and Verification Methods (CHARME), Lecture Notes in Computer Science 2860", "author": ["H. Chockler", "M.Y.O. Kupferman"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2003}, {"title": "Causal analysis for attributing responsibility in legal cases", "author": ["Hana Chockler", "Norman E. Fenton", "Jeroen Keppens", "David A. Lagnado"], "venue": "Proceedings of the 15th International Conference on Artificial Intelligence and Law, ICAIL, ACM,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "What causes a system to satisfy a specification", "author": ["Hana Chockler", "Joseph Y. Halpern", "Orna Kupferman"], "venue": "ACM Trans. Comput. Log", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Efficient generation of counterexamples and witnesses in symbolic model checking", "author": ["E.M. Clarke", "O. Grumberg", "K.L. McMillan", "X. Zhao"], "venue": "Proc. 32nd Design Automation Conference, IEEE Computer Society,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1995}, {"title": "Two concepts of causation", "author": ["N. Hall"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "Causes and explanations: A structural-model approach. Part I: Causes", "author": ["J.Y. Halpern", "J. Pearl"], "venue": "British Journal for Philosophy of Science", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "A Modification of the Halpern-Pearl Definition of Causality", "author": ["Joseph Y. Halpern"], "venue": "Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Coverage estimation for symbolic model checking", "author": ["Y. Hoskote", "T. Kam", "P.-H Ho", "X. Zhao"], "venue": "Proc. 36th Design automation conference,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1999}, {"title": "A treatise of human nature", "author": ["D. Hume"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1939}, {"title": "Sanity Checks in Formal Verification", "author": ["O. Kupferman"], "venue": "Proc. 17th International Conference on Concurrency Theory, Lecture Notes in Computer Science 4137,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Vacuity detection in temporal model checking", "author": ["M.Y.O. Kupferman"], "venue": "Journal on Software Tools For Technology Transfer", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "Causal responsibility and counterfactuals", "author": ["D.A. Lagnado", "R.T. Gerstenberg"], "venue": "Zultan", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Hints on test data selection: Help for the practicing programmer", "author": ["R.A. De Millo", "F.G.R.J. Lipton"], "venue": "Sayward", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1978}, {"title": "Constraint-based automatic test data generation", "author": ["A.J.R.A. De Millo"], "venue": "Offutt", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1991}, {"title": "An Industrially Effective Environment for Formal Hardware Verification", "author": ["C.-J.H. Seger", "R.B. Jones", "J.W. O\u2019Leary", "T.F. Melham", "M. Aagaard", "C. Barrett", "D. Syme"], "venue": "IEEE Trans. on Computer-Aided Design of Integrated Circuits and Systems", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2005}, {"title": "Coverage Metrics for Functional Validation of Hardware Designs", "author": ["S. Tasiran", "K. Keutzer"], "venue": "IEEE Design and Test of Computers", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2001}], "referenceMentions": [{"referenceID": 13, "context": "The definition of causality given by Halpern and Pearl [15], like other definitions of causality in the philosophy literature going back to Hume [19], is based on counterfactual dependence.", "startOffset": 55, "endOffset": 59}, {"referenceID": 16, "context": "The definition of causality given by Halpern and Pearl [15], like other definitions of causality in the philosophy literature going back to Hume [19], is based on counterfactual dependence.", "startOffset": 145, "endOffset": 149}, {"referenceID": 12, "context": "For example, suppose that Suzy and Billy both pick up rocks and throw them at a bottle ( the example is due to Hall [14]).", "startOffset": 116, "endOffset": 120}, {"referenceID": 12, "context": "(This story is taken from [14].", "startOffset": 26, "endOffset": 30}, {"referenceID": 13, "context": "This problem is dealt with in [15] by, roughly speaking, taking A to be a cause of B if B counterfactually depends on A under some contingency.", "startOffset": 30, "endOffset": 34}, {"referenceID": 4, "context": "The concept of responsibility, introduced in [5], presents a way to quantify causality and hence the ability to measure the degree of influence (aka \u201cthe degree of responsibility\u201d) of different causes on the outcome.", "startOffset": 45, "endOffset": 48}, {"referenceID": 11, "context": "These counterexamples are used for debugging the system, as they demonstrate an example of an erroneous behaviour [13].", "startOffset": 114, "endOffset": 118}, {"referenceID": 1, "context": "As I describe in more details in the following sections, the causal analysis of counterexamples, described in [2], is an integral part of an industrial hardware verification platform RuleBase of IBM [25].", "startOffset": 110, "endOffset": 113}, {"referenceID": 17, "context": "On the other hand, if the answer is positive, the tools usually perform some type of a sanity check, to verify that the positive result was not caused by an error or underspecification (see [20] for a survey).", "startOffset": 190, "endOffset": 194}, {"referenceID": 2, "context": "[3] as a situation, where the property passes in a \u201cnon-interesting way\u201d, that is, a part of a property does not affect the model checking procedure in the system.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "state that vacuity was a serious problem in verification of hardware designs at IBM: \u201cour experience has shown that typically 20% of specifications pass vacuously during the first formal-verification runs of a new hardware design, and that vacuous passes always point to a real problem in either the design or its specification or environment\u201d [3].", "startOffset": 344, "endOffset": 347}, {"referenceID": 18, "context": "The general vacuity problem was formalised by Kupferman and Vardi, who defined a vacuous pass as a pass, where some subformula of the original property can be replaced by its\u22a5 value without affecting the satisfaction of the property in the system [21], and there is a plethora of subsequent papers and definitions addressing different aspects and nuances of vacuous satisfaction.", "startOffset": 247, "endOffset": 251}, {"referenceID": 23, "context": "Coverage check is a concept \u201cborrowed\u201d from testing and simulation-based verification, where various coverage metrics are traditionally used as heuristic measures of exhaustiveness of the verification procedure [29].", "startOffset": 211, "endOffset": 215}, {"referenceID": 15, "context": "[18], and formalized in [8, 7, 6, 9].", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[18], and formalized in [8, 7, 6, 9].", "startOffset": 24, "endOffset": 36}, {"referenceID": 6, "context": "[18], and formalized in [8, 7, 6, 9].", "startOffset": 24, "endOffset": 36}, {"referenceID": 5, "context": "[18], and formalized in [8, 7, 6, 9].", "startOffset": 24, "endOffset": 36}, {"referenceID": 8, "context": "[18], and formalized in [8, 7, 6, 9].", "startOffset": 24, "endOffset": 36}, {"referenceID": 10, "context": "All these requests will be considered not covered by the mutation coverage metric, as changing each one of them separately to false does not falsify the property; and yet, each of these requests plays a role in the satisfaction of the specification (or, using the notions from causality, for each request there exists a contingency that creates a counterfactual dependence between this request and the satisfaction of the specification) [11].", "startOffset": 437, "endOffset": 441}, {"referenceID": 10, "context": "While, as I discuss in more detail below, the full-blown responsibility computation is intractable for all but very small systems, introducing a threshold on the value of responsibility, in order to detect only the most influential causes, reduces the complexity and makes the computation manageable for real systems [11].", "startOffset": 317, "endOffset": 321}, {"referenceID": 3, "context": "The quantification provided by the notion of responsibility and the distinction between influential and non-influential causes have been applied to the symbolic trajectory evaluation, where ordering the causes by their degree of responsibility was demonstrated to be a good heuristic for instantiating a minimal number of variables that is sufficient to determine the output value of the circuit [4].", "startOffset": 396, "endOffset": 399}, {"referenceID": 13, "context": "In this section, I briefly review the details of Halpern and Pearl\u2019s definition (HP) of causal models and causality [15] and the definitions of responsibility and blame [5] in causal models.", "startOffset": 116, "endOffset": 120}, {"referenceID": 4, "context": "In this section, I briefly review the details of Halpern and Pearl\u2019s definition (HP) of causal models and causality [15] and the definitions of responsibility and blame [5] in causal models.", "startOffset": 169, "endOffset": 172}, {"referenceID": 13, "context": "1 (Cause [15]) ~X =~x is a cause of \u03c6 in (M,~u) if the following three conditions hold:", "startOffset": 9, "endOffset": 13}, {"referenceID": 14, "context": "We note that Halpern recently updated the definition of causality, changing the concept to focus on the variables that are frozen in their original values, rather than considering contingencies [16].", "startOffset": 194, "endOffset": 198}, {"referenceID": 4, "context": "The notion of degree of responsibility, introduced by Chockler and Halpern [5], extends the notion of causality to capture the differences in the degree of criticality of causes.", "startOffset": 75, "endOffset": 78}, {"referenceID": 19, "context": "This notion of degree of responsibility has been shown to capture (at a qualitative level) the way people allocate responsibility [22].", "startOffset": 130, "endOffset": 134}, {"referenceID": 4, "context": "2 (Degree of Responsibility [5]) The degree of responsibility of ~X = ~x for \u03c6 in (M,~u), denoted dr((M,~u),(~X \u2190~x),\u03c6), is 0 if ~X =~x is not a cause of \u03c6 in (M,~u); it is 1/(k+ 1) if ~X =~x is a cause of \u03c6 in (M,~u) according to Definition 2.", "startOffset": 28, "endOffset": 31}, {"referenceID": 4, "context": "responsibility [5].", "startOffset": 15, "endOffset": 18}, {"referenceID": 4, "context": "3 (Blame [5]) The degree of blame of setting ~X to~x for \u03c6 relative to epistemic state (K,Pr), denoted db(K,Pr,~X \u2190 ~x,\u03c6), is defined as an expected value of the degree of responsibility over the probability space (K,Pr).", "startOffset": 9, "endOffset": 12}, {"referenceID": 20, "context": "The following definition of coverage is based on the study of mutant coverage in simulation-based verification [23, 24, 1], and is the one that is adopted in all (or almost all) papers on coverage metrics in formal verification today (see, for example, [18, 8, 7, 6, 9]).", "startOffset": 111, "endOffset": 122}, {"referenceID": 21, "context": "The following definition of coverage is based on the study of mutant coverage in simulation-based verification [23, 24, 1], and is the one that is adopted in all (or almost all) papers on coverage metrics in formal verification today (see, for example, [18, 8, 7, 6, 9]).", "startOffset": 111, "endOffset": 122}, {"referenceID": 0, "context": "The following definition of coverage is based on the study of mutant coverage in simulation-based verification [23, 24, 1], and is the one that is adopted in all (or almost all) papers on coverage metrics in formal verification today (see, for example, [18, 8, 7, 6, 9]).", "startOffset": 111, "endOffset": 122}, {"referenceID": 15, "context": "The following definition of coverage is based on the study of mutant coverage in simulation-based verification [23, 24, 1], and is the one that is adopted in all (or almost all) papers on coverage metrics in formal verification today (see, for example, [18, 8, 7, 6, 9]).", "startOffset": 253, "endOffset": 269}, {"referenceID": 7, "context": "The following definition of coverage is based on the study of mutant coverage in simulation-based verification [23, 24, 1], and is the one that is adopted in all (or almost all) papers on coverage metrics in formal verification today (see, for example, [18, 8, 7, 6, 9]).", "startOffset": 253, "endOffset": 269}, {"referenceID": 6, "context": "The following definition of coverage is based on the study of mutant coverage in simulation-based verification [23, 24, 1], and is the one that is adopted in all (or almost all) papers on coverage metrics in formal verification today (see, for example, [18, 8, 7, 6, 9]).", "startOffset": 253, "endOffset": 269}, {"referenceID": 5, "context": "The following definition of coverage is based on the study of mutant coverage in simulation-based verification [23, 24, 1], and is the one that is adopted in all (or almost all) papers on coverage metrics in formal verification today (see, for example, [18, 8, 7, 6, 9]).", "startOffset": 253, "endOffset": 269}, {"referenceID": 8, "context": "The following definition of coverage is based on the study of mutant coverage in simulation-based verification [23, 24, 1], and is the one that is adopted in all (or almost all) papers on coverage metrics in formal verification today (see, for example, [18, 8, 7, 6, 9]).", "startOffset": 253, "endOffset": 269}, {"referenceID": 10, "context": "On the other hand, representing the model checking procedure as a causal model with a context corresponding to the actual values of atomic propositions in states (see [11] for a formal description of this representation), demonstrates that for each state there exists a contingency where the result counterfactually depends on the value of grant in this state; the contingency is removing grants in the two other states.", "startOffset": 167, "endOffset": 171}, {"referenceID": 1, "context": "present a method and a tool for explaining the trace, without involving the model from which it was extracted [2].", "startOffset": 110, "endOffset": 113}, {"referenceID": 1, "context": "The reader is referred to [2] for more details of the implementation.", "startOffset": 26, "endOffset": 29}, {"referenceID": 22, "context": "STE is successfully used in the hardware industry for verifying very large models with wide data paths [28, 26, 30].", "startOffset": 103, "endOffset": 115}, {"referenceID": 3, "context": "To avoid the need for manual refinement (which requires a close familiarity with the structure of the circuit), [4] suggest to compute an approximation of the degree of responsibility of each node in the value of the output circuit.", "startOffset": 112, "endOffset": 115}, {"referenceID": 3, "context": "The algorithm was implemented in Intel STE framework for hardware verification and demonstrated better results than manual refinement [4].", "startOffset": 134, "endOffset": 137}, {"referenceID": 13, "context": "As [15] points out, the legal system does not agree with the structural definitions of causality, responsibility, and blame.", "startOffset": 3, "endOffset": 7}, {"referenceID": 9, "context": "In [10], we make the case of using the framework of actual causality in order to guide legal inquiry.", "startOffset": 3, "endOffset": 7}], "year": 2016, "abstractText": "The theory of actual causality, defined by Halpern and Pearl, and its quantitative measure \u2013 the degree of responsibility \u2013 was shown to be extremely useful in various areas of computer science due to a good match between the results it produces and our intuition. In this paper, I describe the applications of causality to formal verification, namely, explanation of counter-examples, refinement of coverage metrics, and symbolic trajectory evaluation. I also briefly discuss recent applications of causality to legal reasoning.", "creator": "LaTeX with hyperref package"}}}