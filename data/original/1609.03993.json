{"id": "1609.03993", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Sep-2016", "title": "A Generic Bet-and-run Strategy for Speeding Up Traveling Salesperson and Minimum Vertex Cover", "abstract": "A common strategy for improving optimization algorithms is to restart the algorithm when it is believed to be trapped in an inferior part of the search space. However, while specific restart strategies have been developed for specific problems (and specific algorithms), restarts are typically not regarded as a general tool to speed up an optimization algorithm. In fact, many optimization algorithms do not employ restarts at all.", "histories": [["v1", "Tue, 13 Sep 2016 19:36:45 GMT  (747kb,D)", "http://arxiv.org/abs/1609.03993v1", "15 pages"]], "COMMENTS": "15 pages", "reviews": [], "SUBJECTS": "cs.AI cs.DS", "authors": ["tobias friedrich", "timo k\\\"otzing", "markus wagner"], "accepted": false, "id": "1609.03993"}, "pdf": {"name": "1609.03993.pdf", "metadata": {"source": "CRF", "title": "A Generic Bet-and-run Strategy for Speeding Up Traveling Salesperson and Minimum Vertex Cover\u2217", "authors": ["Tobias Friedrich", "Timo K\u00f6tzing", "Markus Wagner"], "emails": [], "sections": [{"heading": null, "text": "Recently, bet-and-run was introduced in the context of mixed-integer programming, where first a number of short runs with randomized initial conditions is made, and then the most promising run of these is continued. In this article, we consider two classical NP-complete combinatorial optimization problems, traveling salesperson and minimum vertex cover, and study the effectiveness of different bet-and-run strategies. In particular, our restart strategies do not take any problem knowledge into account, nor are tailored to the optimization algorithm. Therefore, they can be used off-the-shelf. We observe that state-of-the-art solvers for these problems can benefit significantly from restarts on standard benchmark instances."}, {"heading": "1 Introduction", "text": "When a desktop PC is not working properly, the default answer of an experienced system administrator is restarting it. The same holds for stochastic algorithms and randomized search heuristics: If we are not satisfied with the result, we might just try restarting the algorithm again and again. While thish is well-known [16, 18], very few algorithms directly incorporate such restart strategies. We assume that this is due to the\n\u2217This work has been supported by the ARC Discovery Early Career Researcher Award DE160100850.\nar X\niv :1\n60 9.\n03 99\n3v 1\n[ cs\nadded complexity of designing an appropriate restart strategy that is advantageous for the considered algorithm.\nHence, it would be beneficial to have a generic framework for restart strategies which is not overly dependent on the exact algorithm used or the problem under consideration. In this paper we want to show that there are restart strategies which are of benefit in a variety of settings.\nThere are some theories on how to choose optimal restart strategies, independently of the setting. For example, Luby, Sinclair, and Zuckerman [17] showed that, for Las Vegas algorithms with known run time distribution, there is an optimal stopping time in order to minimize the expected running time. They also showed that, if the distribution is unknown, there is an universal sequence of running times given by (1,1,2,1,1,2,4,1,1,2,1,1,2,4,8,...), which is the optimal restarting strategy up to constant factors. These results have the appeal that they can be used for every problem setting; however, they only apply to Las Vegas algorithms.\nFor the case of optimization, the situation is much less clear, with plenty of different approaches presented by the stochastic optimization community. A gentle introduction to practical approaches for such restart strategies is given by Mart [18] and Loureno et al. [16], and a recent theoretical result is presented by Schoenauer, Teytaud, and Teytaud [23]. Particularly for the satisfiability problem (SAT), there are several studies that make an empirical comparison of a number of restart policies [5, 15]. These show the substantial impact of the restart policy on the efficiency of SAT solvers. In the context of satisfiability problems this might be unsurprising as state-of-the-art SAT and CSP solvers often speed up their search by learning \u201cno-goods\u201d during backtracking [10].\nWhile classical optimization algorithms are often deterministic and thus cannot be improved by restarts (neither their run time nor their outcome will alter), many modern optimization algorithms, while also working mostly deterministically, have some randomized component, for example by choosing a random starting point. Thus, the initial solution often strongly influences the quality of the outcome. It follows that it is natural to do several runs of the algorithm. Two very typical uses for an algorithm with time budget t are to (a) use all of time t for a single run of the algorithm (single-run strategy), or (b) to make a number of k runs of the algorithm, each with running time t/k (multi-run strategy).\nExtending these two classical strategies, Fischetti and Monaci [13] investigated the use of the following bet-and-run strategy with a total time limit t:\nPhase 1 performs k runs of the algorithm for some (short) time limit t1 with t1 \u2264 t/k.\nPhase 2 uses remaining time t2 = t\u2212k \u00b7 t1 to continue only the best run from the first phase until timeout.\nThis strategy is illustrated in Figure 1. Note that the multi-run strategy of restarting from scratch k times is a special case by choosing t1 = t/k and t2 = 0 and the singlerun strategy corresponds to k = 1; thus, it suffices to consider different parameter settings of the bet-and-run strategy to also cover these two strategies.\nFischetti and Monaci [13] experimentally studied such a bet-and-run strategy for mixed-integer programming. They explicitly introduce diversity in the starting conditions of the used MIP solver (IBM ILOG CPLEX) by directly accessing internal\nmechanisms. In their experiments with k = 5, bet-and-run was typically beneficial. de Perthuis de Laillevault, Doerr, and Doerr [12] have recently shown that a bet-andrun strategy can also benefit asymptotically from larger k: For the pseudo-boolean test function ONEMAX it was proven that choosing k > 1 decreases the O(n log n) expected run time of the (1+1) evolutionary algorithm by an additive term of \u2126( \u221a n) [12]. They also rigorously showed that the optimal gain is achieved for some k of order k = \u221a n.\nIn this paper we want to show that there is no need to tailor the restart strategy or to access the internal mechanisms of available solvers: in fact there are generic betand-run restart strategies that consistently outperform single-run and multi-run strategies across different domains! We benchmark our strategies on two different problems: traveling sales person (TSP) and minimum vertex cover (MVC). We observe statistically significant improvements of our bet-and-run strategy on standard corpora for state-of-the-art solvers for both optimization problems.\nDetails for our design choices can be found in Section 2, along with a formal definition of the problems. Since it is a priori not obvious what bet-and-run strategies are most promising, we define a generic scheme of restart strategies in Section 3; we compare these strategies in Section 4, where we find 14 parameter settings for the betand-run strategy (k and t1) that are representative of the space of possible parameter settings. Finally, in Section 5, we show that there are bet-and-run strategies that perform well across a wide range of instances in different domains."}, {"heading": "2 Problems and Benchmarks", "text": "In the following we briefly introduce the two NP-complete problems we consider, as well as the corresponding solvers and benchmarks used in this paper.\nTraveling Salesperson The Traveling Salesperson problem considers an edge-weighted graph G = (V,E,w), the vertices V = {1, . . . , n} are referred to as cities. It asks for a permutation \u03c0 of V such that (\nn\u22121\u2211 i=1 w(\u03c0(i), \u03c0(i+ 1))\n) + w(\u03c0(n), \u03c0(1))\n(the cost of visiting the cities in the order of the permutation and then returning to the origin \u03c0(1)) is minimized.\nApplications of the traveling salesperson problem arise naturally in areas like planning and logistics [19], but they are also encountered in a large number of other domains; the textbook by Applegate, Bixby, Chvatal, and Cook [3] gives an overview of such encounters, listing areas as diverse as genome sequencing, drilling problems, aiming telescopes, and data clustering. TSP is identified as one of the most important (and most studied) optimization problems.\nWe use the Chained-Lin-Kernighan (CLK) heuristic [2], a state-of-the-art incomplete solver for the Traveling Salesperson problem. The CLK code is available online [11]. Despite being a few years old, CLK still holds the records for a number of large TSPlib instances.\nThe TSPlib is a classic repository of TSP instances [20], which are available online [21]. For our first investigations, we pick from TSPlib the nine largest symmetric instances which have between 5,934 and 85,900 cities, and the Mona Lisa TSP Challenge instance [6], which contains 100,000 cities. In summary, the instances are rl5934, pla7397, rl11849, usa13509, brd14051, d15112, d18512, pla33810, pla85900, and mona-lisa100k. For the first seven instances, CLK takes less than 0.3 seconds to initialize. For the remaining three instances, the initialization times are 0.5, 2.5, and 2.5 seconds.\nMinimum Vertex Cover Finding a minimum vertex cover of a graph is a classical NP-hard problem. Given an unweighted, undirected graph G = (V,E), a vertex cover is defined as a subset of the vertices S \u2286 V , such that every edge of G has an endpoint in S, i.e. for all edges {u, v} \u2208 E, u \u2208 S or v \u2208 S. The NP-complete decision problem k-vertex cover decides whether a vertex cover of size k exists. We consider the optimization problem which aims at finding a vertex cover of minimum size.\nApplications of the vertex cover problem arise in various areas like network security, scheduling and VLSI design [14]. To give an example, finding a minimum vertex cover in a network corresponds to locating an optimal set of nodes on which to strategically place controllers such that they can monitor the data going through every link in the network. The vertex cover problem is also closely related to the question of finding a maximum clique. This has a range of applications in bioinformatics and biology, such as identifying related protein sequences [1].\nOver the past two decades, numerous algorithms have been proposed for solving the vertex cover problem. We choose FASTVC [7] over the popular NUMVC [9] as a solver for the minimum vertex cover problem as it works better for massive graphs. FASTVC is based on two low-complexity heuristics, one for initial construction of a vertex cover, and one to choose the vertex to be removed in each exchanging step. The code of FASTVC is available online [8].\nFor our initial experimental investigations, we select from the 86 instances used by Cai [7] the 10 instances for which FASTVC outperforms NUMVC the most. With this approach to instance selection (which differs from the one we used for TSP) we attempt to further increase the performance gap between both algorithms. In the order of increasing performance difference, these instances are rec-amazon, large-soc-gowalla, soc-digg, sc-shipsec1, soc-youtube, sc-shipsec5, soc-flickr, soc-youtube-snap, web-it2004, and ca-coauthors-dblp. On all instances, FASTVC\u2019s initialisation takes at most 1.5 seconds. All instances are available online [22]."}, {"heading": "3 Restart Strategies", "text": "A restart strategy describes how the total time budget is distributed over a number of independent runs. We consider two different kinds of restart strategies as follows. On the one hand, we consider the bet-and-run strategies where all initial runs have the same length. On the other hand, we are inspired by Luby et al. [17] for defining a kind of restart strategy with different lengths in an attempt to be more robust with respect to choosing the right time s for the initial runs. Luby et al. [17] define a simple universal strategy, defined as an (infinite) sequence indicating how many time units should be used for each run. This sequence is given as\nSuniv = (1, 1, 2, 1, 1, 2, 4, 1, 1, 2, 1, 1, 2, 4, 8, 1, . . .)\nand, more formally, by \u2200i \u2265 1,\nSuniv(i) = { 2k\u22121, if i = 2k \u2212 1; Suniv(i\u2212 2k\u22121 + 1), if 2k\u22121 \u2264 i < 2k \u2212 1.\nThe numbers given in the Luby sequence refer to the number of time units to employ per run. Thus, in order to use the Luby sequence, we have to define the length of this time unit, which we will call Luby time unit. We indicate it as x% of the total time budget. Thus, we get the following definition.\nRESTARTSkx% refers to the strategy where k initial runs are performed, and each of the runs has a computational budget of x% of the total time budget.\nRESTARTSLUBYkx% refers to the strategy that uses in its first phase runs whose lengths are defined by the Luby sequence. k refers to the sequence length used in the first phase, and each Luby time unit is x% of the total time.\n4 Choosing Representative Restart Strategies\n6\nIn the following, we investigate different bet-and-run strategies for different instances. For each combination of algorithm, instance, and overall run time budget, we average the outcomes of 100 independent repetitions on a compute cluster with Intel Xeon E5620 CPUs (2.4GHz).1 The benefit of using 100 repetitions is that the standard error of the mean is only 10% of the sample\u2019s standard deviation, which means that the resulting averages are reasonably accurate representatives of the actual average performance, despite the algorithms\u2019 randomized nature. This in turn allows us to draw conclusions about the average advantage of our approach across different instances and problem domains.\nFor each heatmap we use one fixed total time budget, and we systematically vary the number of runs in the first phase and their run times. In each plot we show a diagonal line that indicates the schemes RESTARTSx1/x, which corresponds to performing x independent runs with each 1/x-th of the total budget. Every scheme above this line would violate the total time budget, which gives the heatmaps a triangular shape.\nBefore we come to the discussion of the experimental results, a note regarding the implementation. Often algorithm implementations do not allow us to pause and continue their operation at arbitrary points in time, or to provide initial solutions together with a full internal state of the algorithm. While both options are implementable, the source code is not always available, or it cannot be easily modified. Therefore, we employ a trick that can easily be applied if the implementation accepts run time limits and seeds for the random number generation. In our investigations, we first execute all runs of the first phase sequentially, each with the respective allotted time budget. Then we determine the best performing run b that used time tb and the randomly set seed sb. In order to complete the restart scheme\u2019s second phase, we run b not just with the remaining time budget t2 (see Figure 1), but we restart it from scratch with tb + t2 and with the previously used seed sb. This allows the algorithm to reach its previous state after tb (which we do not count toward the total time budget) and to continue for t2.\n1Our code and results have been made publicly available: https://bitbucket.org/ markuswagner/restarts\nFigure 2 depicts how the total budget influences the relative performance of the restart strategies on a TSP instance. For a small total time budget we see that 4 to 10 short initial runs are best; with an increase in the budget, more and more strategies with even longer initial run times perform better than the single-run strategy. Also, it should be noted that when the number of initial runs or the time budget for them increases too much, the performance of the scheme deteriorates quickly.\nSimilar observations also hold for our restart scheme on MVC instances, as shown in Figure 3. Also, we see that the Luby time unit has an impact on the overall performance of the approach, as does the length of the Luby sequence used.\nIn summary, no single bet-and-run performs best across both problem domains. However, there are always schemes that outperform the naive scheme with just a single run, giving clear evidence for an advantage of our bet-and-run approach.\nFor our general study of restart strategies (across different problems and instances), we use the following diverse set of 14 strategies that vary in the number of runs used in Phase 1 and in the run time allocated to each run.\n\u2022 Phase 1 takes 100% of the total time\n\u2013 RESTARTS1100%: 1 regular run \u2013 RESTARTS425%: 4 runs, 25% each\n\u2022 Phase 1 takes 40% of the total time\n\u2013 RESTARTS410%: 4 runs with 10% each \u2013 RESTARTS104%: 10 runs with 4% each\n\u2013 RESTARTS401%: 40 runs with 1% each\n\u2022 Phase 1 takes 10% of the total time\n\u2013 RESTARTS42.5%: 4 runs with 2.5% each \u2013 RESTARTS101%: 10 runs, each with 1% each \u2013 RESTARTS400.25%: 40 runs, each with 0.25% each\n\u2022 Phase 1 takes 4% of the total time\n\u2013 RESTARTS41%: 4 runs with 1% each \u2013 RESTARTS100.4%: 10 runs with 0.4% each \u2013 RESTARTS400.1%: 40 runs with 0.1% each\n\u2022 Three Luby-based strategies\n\u2013 RESTARTSLUBY41%: Luby sequence length 4 (5 units in total)\n\u2013 RESTARTSLUBY101%: Luby sequence length 10 (16 units in total)\n\u2013 RESTARTSLUBY401%: Luby sequence length 40 (96 units in total)\nIn all cases, Phase 2 continues with the bet-and-run found in Phase 1. In Figure 4 we show for one representative instance the points in the RESTARTSlandscape that we will be investigating subsequently.\n10"}, {"heading": "5 Cross Problem Study", "text": "A crucial decision is the total time budget allotted for each instance. If the time limit is too short, no strategy has enough time to finish even its initialization. If the time limit is too long, the differences between the strategies might vanish. To investigate the impact of different total run time budgets, we consider five different budgets. These budgets are all relative to the time tinit needed to initialize the algorithm with the given instance. The overall run time budgets that we consider are 100 \u00b7 tinit, 400 \u00b7 tinit, 1 000 \u00b7 tinit, 4 000 \u00b7 tinit, and 10 000 \u00b7 tinit.\nAs an example we present Figure 5 to show the results of the impact of the total run time budget, considering the minimum vertex cover instance sc-shipsec5. It is clearly visible that a single run without restarts has the worst performance. This configuration is outperformed by all others, even the one where four independent runs are given just 25% of the total computation budget. These observations hold independently of the chosen total budget. When relatively little time is available (e.g. 100 \u00b7 tinit), the performance of the different restart schemes varies significantly.However, the differences between our different schemes seem to disappear with increasing time budget, and the restart schemes are able to find smaller and smaller vertex covers.\nIn order to allow all restart strategies introduced in Section 4 to have a fair chance to finish at least the initialization in each run, we have to make sure that each run of Phase 1 gets at least time tinit. For example for RESTARTS400.1% this implies that the total time budget has to be at least 1000 \u00b7 tinit. As computational resources are the bottleneck for our subsequent studies, we focus on the shortest three total time budgets: 100 \u00b7 tinit, 400 \u00b7 tinit and 1000 \u00b7 tinit.\nIn our first cross problem domain study we determine the average rank of the 14 restart strategies described in Section 4 for the two optimization problems. For each of the 20 instances listed in Section 2 we perform 100 independent repetitions. Based on the results, we then determine the relative ranks of the 14 restart strategies for both total time budgets.\nFigure 6 shows the average ranks, which are reflecting the trends that we have previously seen in the heatmaps. For the two different problem domains, we observe the following:\n\u2022 For TSP it is best to use a relatively large fraction (40%) of the total time budget with 4 to 40 runs in the first phase. If less time is used for the initial runs, then the average rank worsens quickly.\n\u2022 For the MVC instances, the range of effective budgets for the first phase is wider, it covers the range from 4\u201340%. However, schemes with only a few runs perform the worst.\nIn all cases, the bet-and-run approaches clearly outperform the commonly used single-run strategy, which ends up on one of the worst ranks. When considering the average performance across all total time limits, our schemes RESTARTS401% and RESTARTS104% can almost be considered universal for the given instances and solvers. For the TSP and the MVC, they achieve the best or second best rankings. The universal sequence of Luby et al. [17] turned out inferior compared to restarts of fixed length,\nwhich matches the earlier studies on the decision version of SAT/UNSAT problems by Audemard and Simon [4].\nLastly, we investigate the broader applicability of the best performing strategy RESTARTS401% when the total time limit was 1000 \u00b7 tinit. We apply it to the 86 MVC instances used in [7], which come from 10 categories of networks, and to the 111 symmetric TSP instances from TSPlib, which cover geographical instances as well as circuit board layouts. As before, we repeat each experiment 100 times independently in order to get reasonable estimates of the performance distribution. The results in Figure 7 show that on almost all instances, the standard run is outperformed by our bet-and-run strategy RESTARTS401%."}, {"heading": "6 Conclusions and Future Work", "text": "We study a generic bet-and-run restart strategy, which is easy to implement as an additional speed-up heuristic for solving difficult optimization problems. We demonstrate its efficiency on two classical NP-complete optimization problems with state-of-the-art solvers. Our experiments show a significant advantage of bet-and-run strategies on all problems. The best strategy overall was RESTARTS401%, which in the first phase does 40 short runs with a time limit that is 1% of the total time budget and then uses the remaining 60% of the total time budget to continue the best run of the first phase. The universal sequence of Luby et al. [17] turned out inferior.\nThe gain achieved by our bet-and-run strategy differs depending on the studied optimization problem. For both TSP and MVC the gain is significant.\nAs the two problem domains are structurally different, we expect that bet-and-\nrun strategies are generally helpful. Future research should study further classes of optimization problems such as multi-objective problems or continuous domains. While we focus on strategies with two phases only, it is interesting to consider iterated or hierarchical best-of strategies. Another direction are dynamic bet-and-run strategies, which restart runs that stop improving."}], "references": [{"title": "Scalable parallel algorithms for FPT problems", "author": ["F.N. Abu-Khzam", "M.A. Langston", "P. Shanbhag", "C.T. Symons"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Chained Lin-Kernighan for large traveling salesman problems", "author": ["D.L. Applegate", "W.J. Cook", "A. Rohe"], "venue": "INFORMS Journal on Computing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "The Traveling Salesman Problem: A Computational Study: A Computational Study", "author": ["D.L. Applegate", "R.E. Bixby", "V. Chvatal", "W.J. Cook"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Proceedings of the 18th International Conference on Principles and Practice of Constraint Programming (CP), chapter Refining Restarts Strategies for SAT and UNSAT", "author": ["G. Audemard", "L. Simon"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Adaptive restart strategies for conflict driven SAT solvers", "author": ["A. Biere"], "venue": "In Proceedings of the 11th International Conference on Theory and Applications of Satisfiability Testing (SAT),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Mona Lisa TSP Challenge (Website)", "author": ["R. Bosch"], "venue": "http://www.math. uwaterloo.ca/tsp/data/ml/monalisa.html,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Balance between complexity and quality: Local search for minimum vertex cover in massive graphs", "author": ["S. Cai"], "venue": "Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (IJ- CAI),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Local Search for Minimum Vertex Cover (Website)", "author": ["S. Cai"], "venue": "http://lcs. ios.ac.cn/ \u0303caisw/MVC.html,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Numvc: An efficient local search algorithm for minimum vertex cover", "author": ["S. Cai", "K. Su", "C. Luo", "A. Sattar"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Parallel restarted search", "author": ["A.A. Cir\u00e9", "S. Kadioglu", "M. Sellmann"], "venue": "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "The Traveling Salesperson Problem: Downloads (Website)", "author": ["W. Cook"], "venue": "http://www.math.uwaterloo.ca/tsp/concorde/downloads/ downloads.htm,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "Money for nothing: Speeding up evolutionary algorithms through better initialization", "author": ["A. de Perthuis de Laillevault", "B. Doerr", "C. Doerr"], "venue": "In Proceedings of the Annual Conference on Genetic and Evolutionary Computation (GECCO),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Exploiting erraticism in search", "author": ["M. Fischetti", "M. Monaci"], "venue": "Operations Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Experimental analysis of approximation algorithms for the vertex cover and set covering problems", "author": ["F.C. Gomes", "C.N. Meneses", "P.M. Pardalos", "G.V.R. Viana"], "venue": "Compututers and Operations Research,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "The effect of restarts on the efficiency of clause learning", "author": ["J. Huang"], "venue": "In Proceedings of the 20th International Joint Conference on Artifical Intelligence (IJCAI),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Iterated local search: Framework and applications", "author": ["H.R. Loureno", "O.C. Martin", "T. St\u00fctzle"], "venue": "Handbook of Metaheuristics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Optimal speedup of Las Vegas algorithms", "author": ["M. Luby", "A. Sinclair", "D. Zuckerman"], "venue": "Information Processing Letters,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1993}, {"title": "Multi-start methods", "author": ["R. Mart"], "venue": "Handbook of Metaheuristics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2003}, {"title": "Scheduling periodic customer visits for a traveling salesperson", "author": ["M. Polacek", "K.F. Doerner", "R.F. Hartl", "G. Kiechle", "M. Reimann"], "venue": "European Journal of Operational Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "TSPLIB \u2013 A Traveling Salesman Problem Library", "author": ["G. Reinelt"], "venue": "ORSA Journal on Computing,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1991}, {"title": "Symmetric traveling salesman problem: TSP data (Website)", "author": ["G. Reinelt"], "venue": "http: //comopt.ifi.uni-heidelberg.de/software/TSPLIB95/tsp/,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "The Network Data Repository with Interactive Graph Analytics and Visualization (Website)", "author": ["R.A. Rossi", "N.K. Ahmed"], "venue": "http:// networkrepository.com,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "A rigorous runtime analysis for quasi-random restarts and decreasing stepsize", "author": ["M. Schoenauer", "F. Teytaud", "O. Teytaud"], "venue": "In Artificial Evolution,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}], "referenceMentions": [{"referenceID": 15, "context": "While thish is well-known [16, 18], very few algorithms directly incorporate such restart strategies.", "startOffset": 26, "endOffset": 34}, {"referenceID": 17, "context": "While thish is well-known [16, 18], very few algorithms directly incorporate such restart strategies.", "startOffset": 26, "endOffset": 34}, {"referenceID": 16, "context": "For example, Luby, Sinclair, and Zuckerman [17] showed that, for Las Vegas algorithms with known run time distribution, there is an optimal stopping time in order to minimize the expected running time.", "startOffset": 43, "endOffset": 47}, {"referenceID": 17, "context": "A gentle introduction to practical approaches for such restart strategies is given by Mart [18] and Loureno et al.", "startOffset": 91, "endOffset": 95}, {"referenceID": 15, "context": "[16], and a recent theoretical result is presented by Schoenauer, Teytaud, and Teytaud [23].", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[16], and a recent theoretical result is presented by Schoenauer, Teytaud, and Teytaud [23].", "startOffset": 87, "endOffset": 91}, {"referenceID": 4, "context": "Particularly for the satisfiability problem (SAT), there are several studies that make an empirical comparison of a number of restart policies [5, 15].", "startOffset": 143, "endOffset": 150}, {"referenceID": 14, "context": "Particularly for the satisfiability problem (SAT), there are several studies that make an empirical comparison of a number of restart policies [5, 15].", "startOffset": 143, "endOffset": 150}, {"referenceID": 9, "context": "In the context of satisfiability problems this might be unsurprising as state-of-the-art SAT and CSP solvers often speed up their search by learning \u201cno-goods\u201d during backtracking [10].", "startOffset": 180, "endOffset": 184}, {"referenceID": 12, "context": "Extending these two classical strategies, Fischetti and Monaci [13] investigated the use of the following bet-and-run strategy with a total time limit t:", "startOffset": 63, "endOffset": 67}, {"referenceID": 12, "context": "Fischetti and Monaci [13] experimentally studied such a bet-and-run strategy for mixed-integer programming.", "startOffset": 21, "endOffset": 25}, {"referenceID": 11, "context": "de Perthuis de Laillevault, Doerr, and Doerr [12] have recently shown that a bet-andrun strategy can also benefit asymptotically from larger k: For the pseudo-boolean test function ONEMAX it was proven that choosing k > 1 decreases the O(n log n) expected run time of the (1+1) evolutionary algorithm by an additive term of \u03a9( \u221a n) [12].", "startOffset": 45, "endOffset": 49}, {"referenceID": 11, "context": "de Perthuis de Laillevault, Doerr, and Doerr [12] have recently shown that a bet-andrun strategy can also benefit asymptotically from larger k: For the pseudo-boolean test function ONEMAX it was proven that choosing k > 1 decreases the O(n log n) expected run time of the (1+1) evolutionary algorithm by an additive term of \u03a9( \u221a n) [12].", "startOffset": 332, "endOffset": 336}, {"referenceID": 18, "context": "Applications of the traveling salesperson problem arise naturally in areas like planning and logistics [19], but they are also encountered in a large number of other domains; the textbook by Applegate, Bixby, Chvatal, and Cook [3] gives an overview of such encounters, listing areas as diverse as genome sequencing, drilling problems, aiming telescopes, and data clustering.", "startOffset": 103, "endOffset": 107}, {"referenceID": 2, "context": "Applications of the traveling salesperson problem arise naturally in areas like planning and logistics [19], but they are also encountered in a large number of other domains; the textbook by Applegate, Bixby, Chvatal, and Cook [3] gives an overview of such encounters, listing areas as diverse as genome sequencing, drilling problems, aiming telescopes, and data clustering.", "startOffset": 227, "endOffset": 230}, {"referenceID": 1, "context": "We use the Chained-Lin-Kernighan (CLK) heuristic [2], a state-of-the-art incomplete solver for the Traveling Salesperson problem.", "startOffset": 49, "endOffset": 52}, {"referenceID": 10, "context": "The CLK code is available online [11].", "startOffset": 33, "endOffset": 37}, {"referenceID": 19, "context": "The TSPlib is a classic repository of TSP instances [20], which are available online [21].", "startOffset": 52, "endOffset": 56}, {"referenceID": 20, "context": "The TSPlib is a classic repository of TSP instances [20], which are available online [21].", "startOffset": 85, "endOffset": 89}, {"referenceID": 5, "context": "For our first investigations, we pick from TSPlib the nine largest symmetric instances which have between 5,934 and 85,900 cities, and the Mona Lisa TSP Challenge instance [6], which contains 100,000 cities.", "startOffset": 172, "endOffset": 175}, {"referenceID": 13, "context": "Applications of the vertex cover problem arise in various areas like network security, scheduling and VLSI design [14].", "startOffset": 114, "endOffset": 118}, {"referenceID": 0, "context": "This has a range of applications in bioinformatics and biology, such as identifying related protein sequences [1].", "startOffset": 110, "endOffset": 113}, {"referenceID": 6, "context": "We choose FASTVC [7] over the popular NUMVC [9] as a solver for the minimum vertex cover problem as it works better for massive graphs.", "startOffset": 17, "endOffset": 20}, {"referenceID": 8, "context": "We choose FASTVC [7] over the popular NUMVC [9] as a solver for the minimum vertex cover problem as it works better for massive graphs.", "startOffset": 44, "endOffset": 47}, {"referenceID": 7, "context": "The code of FASTVC is available online [8].", "startOffset": 39, "endOffset": 42}, {"referenceID": 6, "context": "For our initial experimental investigations, we select from the 86 instances used by Cai [7] the 10 instances for which FASTVC outperforms NUMVC the most.", "startOffset": 89, "endOffset": 92}, {"referenceID": 21, "context": "All instances are available online [22].", "startOffset": 35, "endOffset": 39}, {"referenceID": 16, "context": "[17] for defining a kind of restart strategy with different lengths in an attempt to be more robust with respect to choosing the right time s for the initial runs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] define a simple universal strategy, defined as an (infinite) sequence indicating how many time units should be used for each run.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] turned out inferior compared to restarts of fixed length,", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "which matches the earlier studies on the decision version of SAT/UNSAT problems by Audemard and Simon [4].", "startOffset": 102, "endOffset": 105}, {"referenceID": 6, "context": "We apply it to the 86 MVC instances used in [7], which come from 10 categories of networks, and to the 111 symmetric TSP instances from TSPlib, which cover geographical instances as well as circuit board layouts.", "startOffset": 44, "endOffset": 47}, {"referenceID": 16, "context": "[17] turned out inferior.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "A common strategy for improving optimization algorithms is to restart the algorithm when it is believed to be trapped in an inferior part of the search space. However, while specific restart strategies have been developed for specific problems (and specific algorithms), restarts are typically not regarded as a general tool to speed up an optimization algorithm. In fact, many optimization algorithms do not employ restarts at all. Recently, bet-and-run was introduced in the context of mixed-integer programming, where first a number of short runs with randomized initial conditions is made, and then the most promising run of these is continued. In this article, we consider two classical NP-complete combinatorial optimization problems, traveling salesperson and minimum vertex cover, and study the effectiveness of different bet-and-run strategies. In particular, our restart strategies do not take any problem knowledge into account, nor are tailored to the optimization algorithm. Therefore, they can be used off-the-shelf. We observe that state-of-the-art solvers for these problems can benefit significantly from restarts on standard benchmark instances.", "creator": "LaTeX with hyperref package"}}}