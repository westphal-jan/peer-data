{"id": "1609.06438", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Sep-2016", "title": "Large-Scale Strategic Games and Adversarial Machine Learning", "abstract": "Decision making in modern large-scale and complex systems such as communication networks, smart electricity grids, and cyber-physical systems motivate novel game-theoretic approaches. This paper investigates big strategic (non-cooperative) games where a finite number of individual players each have a large number of continuous decision variables and input data points. Such high-dimensional decision spaces and big data sets lead to computational challenges, relating to efforts in non-linear optimization scaling up to large systems of variables. In addition to these computational challenges, real-world players often have limited information about their preference parameters due to the prohibitive cost of identifying them or due to operating in dynamic online settings. The challenge of limited information is exacerbated in high dimensions and big data sets. Motivated by both computational and information limitations that constrain the direct solution of big strategic games, our investigation centers around reductions using linear transformations such as random projection methods and their effect on Nash equilibrium solutions. Specific analytical results are presented for quadratic games and approximations. In addition, an adversarial learning game is presented where random projection and sampling schemes are investigated.", "histories": [["v1", "Wed, 21 Sep 2016 07:10:13 GMT  (88kb,D)", "http://arxiv.org/abs/1609.06438v1", "7 pages, 1 figure; CDC'16 to appear"]], "COMMENTS": "7 pages, 1 figure; CDC'16 to appear", "reviews": [], "SUBJECTS": "cs.GT cs.LG", "authors": ["tansu alpcan", "benjamin i p rubinstein", "christopher leckie"], "accepted": false, "id": "1609.06438"}, "pdf": {"name": "1609.06438.pdf", "metadata": {"source": "CRF", "title": "Large-Scale Strategic Games and Adversarial Machine Learning", "authors": ["Tansu Alpcan", "Benjamin I. P. Rubinstein", "Christopher Leckie"], "emails": ["tansu.alpcan@unimelb.edu.au", "benjamin.rubinstein@unimelb.edu.au", "caleckie@unimelb.edu.au"], "sections": [{"heading": null, "text": "I. INTRODUCTION Game theory, which has its roots in economics, has recently become a mainstream approach to a multitude of engineering problems in communications [1], electricity grids [2]\u2013[4], and network security [5]\u2013[7]. Providing a solid mathematical foundation for multi-agent decision making, game theory has also been used extensively in optimization and control of networked and cyber-physical systems [8].\nWith the advent of large-scale data analytics, large-scale decision problems have become prevalent in many engineering disciplines. Linear Programs with thousands of variables are now common-place; and convex optimization on largescale data, aiming to overcome computational, storage and communication bottlenecks [9], has emerged as a major area of study. Strategic games with continuous decision variables often rely on convex optimization and linear system theory. Unlike games with finite states and actions, studies on continuous-kernel games traditionally do not emphasize scalability nor large-scale data. In contrast to numerous works on game abstraction, there has been little discussion in the classical game theory literature on games with large numbers of continuous variables and big data sets.\nStrategic games with a large number of continuous variables and high-dimensional strategy spaces share unique\nThis work was supported in part by the ARC Discovery Project DP140100819, DECRA DE160100584 and grant FLI-RFP-AI1.\nT. Alpcan tansu.alpcan@unimelb.edu.au is with Department of Electrical and Electronic Engineering; B. Rubinstein benjamin.rubinstein@unimelb.edu.au and C. Leckie caleckie@unimelb.edu.au are with Department of Computing and Information Systems, The University of Melbourne, Australia.\nresearch challenges with those involving large number of finite states and/or actions [10]. One research challenge, common with convex optimization on large-scale data, is computational. Finding Nash Equilibrium strategies is often computationally prohibitive in large-scale games [11]. There have recently been efforts to address these computational issues using active-set or similar methods [12]. However, even novel computational methods may be infeasible in certain scenarios such as repeated games played in real-time. The second and arguably more important challenge is a lack of information. It is difficult and oftentimes infeasible to identify the utility functions and preferences of individual players for each decision variable, especially if the number of variables grows to thousands or more.\nThis paper presents a framework for large-scale strategic (non-cooperative) games where a finite number individual players each have a large number of continuous decision variables. Hence, it can be seen as complementary to the existing literature on game abstraction which shares similar aims [10]. The main difference is the focus on continuous-kernel games and strategy/action spaces. Specifically, nonzero-sum large-scale strategic games with highdimensional continuous decision spaces and random projection methods are investigated as a starting point. Our investigation centers around the reduction of large-scale strategic games using transformations such as random projections and their effect on Nash Equilibrium solutions. Analytically tractable results are presented for quadratic games and in an adversarial machine learning setting.\nA. Related Work\nGames with a large number of players are well-known in the literature, cf. e.g., the concept of Wardrop Equilibrium [13]. More recently, mean-field games have been studied under the assumption of very large numbers of players on large systems. The basic idea behind mean-field games is approximating large games by a stylized model with a continuum of players [14].\nScalability issues arise in games from a number of different perspectives. For example, in cooperative decisionmaking among a large population of agents whose opinions must be considered, [15] propose a Bayesian belief aggregation scheme among many agents holding a potentially diverse range of opinions. [16] examine how the performance of a team of diverse agents improves in cooperative games, as the number of agents or possible actions increases.\nRather than cooperative games, this paper focuses on strategic (non-cooperative) games. In our setting, recent work has investigated how scalability issues arise in specific con-\nar X\niv :1\n60 9.\n06 43\n8v 1\n[ cs\n.G T\n] 2\n1 Se\np 20\n16\ntexts. [12] consider strategic games with sequential strategies, in which large search spaces arise due to strategies that require perfect memory of the history of play for ensuring the existence of equilibria. The authors propose a hybrid approach that combines a compact representation for strategies with an incremental approach to strategy generation in order to address the search space complexity. [17] address the problem of Stackelberg security games, in which defenders need to assign resources to protect targets against attackers. The major challenge that they focus on is finding defender strategies that satisfy the underlying constraints on the resources that need to be allocated to each strategy. The authors use a cutting-plane algorithm to speed up the search in the defender\u2019s solution space.\nGame abstraction has emerged in recent years as a key enabler for solving large incomplete-information games with finite states and/or action sets. [10] presents an excellent survey of abstraction of information or actions in games, motivated by incomplete information or scalability. Distinct to the literature on game abstraction, the focus of this paper is on games with continuous decision variables.\nLarge-scale strategic games also arise in the context of adversarial machine learning: the study of statistical inference under adversarial influence. A number of threat models fall under this umbrella [18]. While privacy-preserving learning has been met successfully by the theoretical frameworks of secure multi-party computation [19] and differential privacy [20], less is known about how to learn or predict on poisoned data. The bulk of related work in computer security, has been on one-shot attacker strategies seeking to force classifier errors. Related case studies include attacks on spam detection [21]\u2013[23], polymorphic worm detectors [24], and on network anomaly detectors [25], [26].\nLittle progress has been made on defenses in adversarial learning. [27] considered patching of simple classifier\u2019s \u2018blind spots\u2019 to attack by instances that optimize an attacker cost function in a one-shot game-theoretic setting. [28] identify conditions for the existence of unique Nash equilibria for static games for learning. However the models learned in both works are linear, representing a useful but limited model class. Regret minimizing learners [29] have been used in security settings [7], [30] but not with popular \u201cbatch\u201d learners. Learning models in much larger classes such as random forests or deep neural networks are significantly high-dimensional, particularly in large-scale data settings where the data set size can support learning of large numbers of parameters in so-called non-parametric methods. These problems thus motivate the study of large-scale strategic games.\nThe adversarial learning setting relates to robust statistics [31] and online learning theory or the theory of regret minimization [29]. The former assumes that an infinitesimal proportion of otherwise i.i.d. training data is contaminated by unbounded noise: not modeling a real-world attacker but rather a tool for studying break-down points and robustness to passive, benign outliers. Online learning theory comes closer to game theory, but the approach is typically to directly\nrepresent and update mixed strategies over predictions based on feedback in rounds. While there have been applications in security [7], [26], [30], neither framework has so far had a large impact on research in security.\nMany machine learning problems involve inference over high-dimensional data\u2014such as images, gene expression assays, text corpora\u2014which can lead to both computational and statistical challenges. As a consequence, many machine learning researchers apply some form of dimensionality reduction. While some appeal to heuristic approaches such as performing principal components analysis prior to learning, theoretical foundations of projections have now become mainstream showing that learning on projected data requires less data or equivalently can be more accurate, while in some cases also requiring less time to achieve.\nProjections used in machine learning are analogous to the reductions for large-scale strategic games discussed in this paper. The Johnson-Lindenstrauss Lemma [32] established the existence of low-dimensional linear projections that approximately preserve inter-point distances, a key characteristic used by many learning algorithms. The randomized version proves the same for random linear projections, with high probability. In their landmark paper, [33] built on this property of random projections to show that model classes (that are robust, with some margin) are still PAC learnable [34] when randomly projected by data-independent mappings. The consequence being that learning may be possible with less data (in a formal sense) under projections. Such projections may prove useful in large-scale game reductions.\nMore recently, Rahimi & Recht [35] use random projections to reduce the computational complexity of training support vector machine (SVM) classifiers on large data sets. For many problems, non-linear SVMs achieve stateof-the-art accuracy but take time cubic in the number of training examples n to learn. SVM learning involves solving a quadratically-constrained quadratic program [36] whose dual involves the data only via inner-products\u2014a kernel matrix. Their novel randomized projections are constructed such that inner-products are approximated uniformly, with high probability depending on the image dimension. This dimension can be taken to be much less than n, yielding much faster training as fewer parameters are learned, without paying with statistical performance since the SVM is relatively stable with respect to perturbations of the kernel.\nB. Contributions\nThe main contributions of the paper include: \u2022 The characterization of large-scale strategic games; \u2022 Reductions of large-scale strategic games using linear\ntransformations such as random projections and their effect on equilibrium solutions; \u2022 An analysis of convex and quadratic 2-player large-scale games and their equilibrium solutions; and \u2022 An adversarial machine learning game that incorporates random projection and sampling based on a linear SVM formulation."}, {"heading": "II. MODEL AND DEFINITIONS", "text": "The general model presented in this section focuses on nonzero-sum large-scale strategic games with highdimensional continuous decision spaces and reduced games obtained through a linear mapping of player decision spaces.\nLet N := {P1,P2, . . . ,PN} be the set of players in a static, continuous kernel, N-Player strategic (non-cooperative) game. Each player i \u2208N chooses a pure strategy (decision) vector, xi from its convex and compact decision set X i \u2286RM . The joint decision space of the game is therefore the product space X = X1\u00d7 . . .XN \u2286 RM\u00d7N . Each player is associated with a cost function Ji(xi,x\u2212i) : X \u2192 R, where xi \u2208 X i and x\u2212i is a shorthand for the decision vectors of all other players, [x1, . . . ,xi\u22121,xi+1, . . . ,xN ]. The players are assumed to be rational and choose their decisions based on a best response strategy by solving the optimization problem\nxi,BR \u2208 arg min xi\u2208X i Ji(xi,x\u2212i) ,\ngiven the actions of all other players x\u2212i. Large-scale games are often identified by the fact that their players have a very large strategy or decision space. The following straightforward definition formalizes this important distinction.\nDefinition 1. Consider the static, continuous kernel, NPlayer strategic (non-cooperative) game G (N ,X ,J), where N is the set of players, X \u2286 RM\u00d7N is the joint decision space, and J = [J1, . . . ,JN ] denotes the real-valued player cost functions. The game is called a large-scale strategic game, G B if the individual player decision spaces have a very large dimension, i.e., M 1.\nAssumption 1. The large-scale game in Definition 1 is assumed to be intractable in its original form.\nThis assumption holds in at least two well-motivated cases: 1) The players cannot fully identify their and others\u2019 cost\nfunctions due to a large number of decision variables and preference parameters; or 2) The large-scale problem of finding best responses or Nash equilibria is computationally infeasible within timing and resource constraints.\nAs a starting point consider a reduced decision space Y \u2286RK\u00d7N , where K <M, obtained through a linear transformation T : X \u2192Y represented by per-player transformation matrices Ai,\nT : yi = Aixi, xi \u2208 X i \u2286 RM, yi \u2208 Y i \u2286 RK , \u2200i \u2208N , (1)\nas illustrated in Figure 1. Based on Assumption 1, the players of the large-scale game G B in Definition 1 make decisions on a reduced space Y resulting in a tractable game G T (N ,Y , J\u0303).\nThe transformation matrices Ai may, for example, randomly select a subset of decision variables or data points, as defined next, or represent a random projection.\nDefinition 2 (Dimension reduction through selection). A transformation matrix A with K rows and M columns is\nsaid to be a selection matrix, if it is of rank K < M and its elements akm satisfy:\nakm \u2208 {0,1} and M\n\u2211 m=1 akm = 1 , \u2200m .\nRandom projections are extremely popular techniques in machine learning for dealing with the curse-ofdimensionality [33], [35]. If a random projection matrix AR is carefully chosen, then all pairwise Euclidean distances, and hence, the geometry of the set of points in X are preserved in Y with high probability. There are many possible constructions for the random projection matrix AR that preserve pairwise distances. The most common one is choosing entries as i.i.d. standard Gaussian random variables. Another common alternative is the random sign matrix whose entries are set to +1 or \u22121 with equal probability. The well-known Johnson-Lindenstrauss Lemma [32] formalizes this idea. A version adopted to this paper\u2019s notation and context is presented next for completeness.\nTheorem 1. Let x1,x2 \u2208X \u2282 Rd and y1 = 1\u221ar x 1AR, y2 = 1\u221a r x\n2AR be a pair of vectors in X and their corresponding mapping to Y . Let AR be an d\u00d7 r random matrix whose entries are chosen independently from either a zero-mean unit-variance Gaussian distribution or as +1 or \u22121 with equal probability. Then, for \u03b3 > 0,\nP [ (1\u2212 \u03b3) \u2225\u2225x1\u2212 x2\u2225\u22252 \u2264 \u2225\u2225y1\u2212 y2\u2225\u22252 \u2264 (1+ \u03b3)\u2225\u2225x1\u2212 x2\u2225\u22252] \u2265 1\u22122e\u2212(\u03b32\u2212\u03b33) r 4 .\nNote that, while it is possible to make the selection of the linear mapping T and matrices A introduced in the previous section a part of the decision problem, doing so would obviously defeat the purpose of the transformation since (A,y) has a higher dimension than the original largescale game decisions, x.\nLemma 2. The combined problem of a player i optimally choosing (Ai,yi) as a reduction has a higher-dimension than the original problem of optimally choosing xi in the largescale game G B for a generic linear transformation Ai.\nProof. The proof immediately follows from definitions. Since A has K rows and M columns, the total number of variables in (A,y) is K(M + 1) > M in the reduced case, which defeats the purpose since xi has M elements."}, {"heading": "III. ANALYSIS OF LARGE-SCALE AND REDUCED GAMES", "text": "A fundamental question of interest in large-scale games is how a Nash Equilibrium (NE) solution of the original game, G B, relates to that of the tractable game G T obtained through a linear transformation such as random projection in the decision space. First, basic results will be discussed for the general case of N-players. Then, specific results for two-player quadratic games will be presented.\nLemma 3. If the cost function of player i, Ji in a large-scale game G B is convex in xi, then J\u0303 of the tractable game G T is also convex in yi.\nProof. The result is due to linearity of the mapping T , see e.g., [37, Chap. 3.2.2].\nThe following well-known result from [38] establishes sufficient conditions for existence of NE in the game G B.\nProposition 4. If the decision space X i of each player i in the large-scale game G B is closed, bounded, and convex, and the cost function Ji is jointly continuous in all its arguments and strictly convex in xi for any x\u2212i and for all i \u2208N , then the game admits a (pure) Nash Equilibrium solution.\nCombining Lemma 3 and Proposition 4 leads to:\nProposition 5. If the large-scale game G B satisfies the sufficient conditions in Proposition 4 and admits a (pure) NE, then the tractable game G T also admits a (pure) NE.\nA. Convex Large-Scale and Reduced Games\nProposition 5 leads to the question of when and where can Large-Scale and Reduced Games be equivalent. The player costs in the large-scale and reduced games G B, G T , are defined as Ji(xi,x\u2212i) and J\u0303i(yi,y\u2212i) = J\u0303i(Aixi,A\u2212ix\u2212i), respectively. Assume that Ji is convex in xi for all players i. Hence, G T is also convex and both admit NE solutions from Lemma 3 and Proposition 4. Let x? be the NE of G B. The Taylor series expansions of the costs Ji and J\u0303i around x?i given x\u2212i,? provide the following second-order approximations:\nJi(xi,x\u2212i)\u2248 Ji(xi,,x\u2212i,?)+ [ \u2207xiJ i]T \u00b7 (xi\u2212 xi,?) + (xi\u2212 xi,?)T [ \u22072xi xiJ\ni] \u00b7 (xi\u2212 xi,?) (2) and\nJ\u0303i(Aixi,A\u2212ix\u2212i) \u2248 J\u0303i(Aixi,?,A\u2212ix\u2212i,?)+ [ Ai,T \u2207xi J\u0303 i]T \u00b7 (xi\u2212 xi,?) + (xi\u2212 xi,?)T [ Ai,T \u22072xi xi J\u0303 iAi ] \u00b7 (xi\u2212 xi,?) , (3)\nwhere \u2016x\u2212 x?\u2016< \u03b5 for a small \u03b5 > 0. The convex games G B and G T are locally approximately equivalent around the NE x?, if\nJi(xi,x\u2212i) = J\u0303i(Aixi,A\u2212ix\u2212i)+\u03b4\nfor {x \u2208X | \u2016x\u2212 x?\u2016< \u03b5}, where the scalar \u03b4 > 0 accounts for the discrepancy due to higher-than-second-order terms. Then, the following relationships, obtained using basic linear\nalgebraic manipulations, establish a connection between the first- and second-order terms in the large-scale and reduced games such that:\n\u2207xi J\u0303 i = (AiAi,T )\u22121Ai [ \u2207xiJ i(xi,x\u2212i) ]\n(4)\nand\n\u22072xi xi J\u0303 i = (AiAi,T )\u22121Ai [ \u22072xi xiJ i]Ai,T (AiAi,T )\u22121 , (5) for all i and x such that \u2016x\u2212 x?\u2016< \u03b5 .\nNext, the relationship between large-scale and tractable games is investigated for the special case of two-player quadratic games.\nB. Quadratic 2-Player Large-Scale And Reduced Games\nQuadratic games are of particular interest in game theory as they constitute second-order approximation to games with nonlinear cost functions, while admitting closed-form equilibrium solutions that provide useful insights [38]. They are also related to Quadratic Programming which is encountered in key machine learning training algorithms [39].\nConsider the following special case of the game G T with only two players P1 and P2 having the respective cost functions:\nJ\u03031 ( y1,y2 ) = y1,T Q\u03031y2\u2212 y1,T r\u03031 + v1 , (6)\nJ\u03032 ( y1,y2 ) = y2,T Q\u03032y1\u2212 y2,T r\u03032 + v2 . (7)\nThe game parameters are the scalars v1, v2, the vectors r\u03031, r\u03032, and matrices Q\u03031, Q\u03032.\nThe corresponding cost functions (6)\u2013(7) of the original Large-scale Game G B can be written as\nJ1 ( x1,x2 ) = x1,T Q1x2\u2212 x1,T r1 + v1 , (8)\nJ2 ( x1,x2 ) = x2,T Q2x1\u2212 x2,T r2 + v2 . (9)\nIf the matrices Q1 and Q2 are positive definite and hence invertible [40], then the cost functions J1 and J2 are both quadratic and strictly convex. Therefore, the first derivatives vanishing serves as necessary and sufficient for optimality in calculating player best responses\nx1,? = (Q2) \u22121 r2 and x2,? = (Q1) \u22121 r1 .\nThus, x? = [x1,?,x2,?] is the unique NE of the original largescale game. Note that the NE strategy of one player is determined by the parameters of the other player.\nWhen are the outcomes of these two games equivalent? To answer this question, let J1 = J\u03031 for Player 1. Since y1 = A1x1 and y2 = A2x2, the equivalence between linear terms are immediately established by r1 = A1,T r\u03031 and r2 = A2,T r\u03032. Focusing on the quadratic terms,\nx1,T Q1x2 = y1,T Q\u03031y2\nand x1,T Q1x2 = x1,T A1,T Q\u03031A2x2,\nlead to Q1 = A1,T Q\u03031A2. (10)\nMultiplying each side first with A1 and A2,T , and then with (A1A1,T )\u22121 and (A2A2,T )\u22121 from left and right, respectively, yields\nQ\u03031 = (A1A1,T )\u22121A1Q1A2,T (A2A2,T )\u22121. (11)\nThe analysis can be repeated similarly for J2 = J\u03032. From (10) and (11), it is observed that unless A1 = A2, i.e., the players use the same reduction mappings, positive definiteness of Qi does not guarantee the positive definiteness of Q\u0303i and vice versa. However, if A1 = A2, then one matrix being positive definite ensures that the other one is so as well. In this case, the matrices can be decomposed as RiRi,T and R\u0303iR\u0303i,T , respectively. Consequently,\nR\u0303iR\u0303i,T = (AAT )\u22121ARiRi,T AT (AAT )\u22121, i = 1,2,\nor R\u0303i = (AAT )\u22121ARi, i = 1,2. (12)\nThe relationships (10)-(12) establish a connection between the quadratic terms in the large-scale and reduced versions of the game. These can be used in design of reductions and/or choice of cost parameters."}, {"heading": "IV. LARGE-SCALE GAMES FOR ADVERSARIAL MACHINE LEARNING", "text": "Security games have been used increasingly to model decision making in network and real-life problems with resource constraints [5]\u2013[7]. Adversarial machine learning (AdvML) is the study of effective machine (or statistical) learning techniques against an adversarial opponent, who aims to disrupt the learning and hence subsequent decision making process with malicious intent. Many adversarial learning problems can be posed as security games. Moreover, high-dimensional and high-volume data generated by modern systems naturally lead to large-scale game formulations which can be analyzed adopting an approach similar to the one discussed in the previous sections. A specific adversarial learning problem based on linear Support Vector Machines (SVMs) is investigated next, which leads to a large-scale game formulation.\nConsider a linear SVM as a binary classifier trained using a large and high-dimensional labeled data set consisting of n d\u2212dimensional real data vectors with respective {\u22121,+1} labels, where n,d 1. The choice of linear SVM is without loss of any generality since nonlinear kernels can be embedded into the random projection, i.e. the inner product of projected points can approximate their original kernel evaluation if the transformation is carefully selected [35].\nThe training of the SVM involves solving an optimization problem where a hyperplane with normal vector, w?, is obtained that maximizes the (soft) geometric margin (the minimum distance of a data point to the hyperplane). The dual formulation of the problem leads to the following wellknown formulation:\nmax \u03b1 1T \u03b1\u2212 1 2 \u03b1TY XXTY \u03b1\ns.t. 1TY\u03b1 = 0, 0\u2264 \u03b1 \u2264 C, (13)\nwhere \u03b1 is the vector of Lagrange multipliers, C > 0 is a constant, 1 is a vector of ones, X \u2208Rn\u00d7d is an n\u00d7d matrix whose rows are the data vectors, and Y \u2208Rn\u00d7n is a diagonal matrix with diagonal entries the corresponding {\u22121,+1} labels. The optimal separating hyperplane is represented by w? = \u03b1?,TY X , where \u03b1? is the optimal solution to (13). Note that, Y T = Y by definition and if an \u03b1?i > 0 then the corresponding data point is called a support vector.\nLet the player who solves (13) with the aim of maximizing the geometric (soft) margin be called \u201cDefender\u201d. Since the data set has a large number of points, n 1, and each data point is high-dimensional, d 1, the Defender adopts random projection as dimension reduction and random data selection as volume reduction strategies. Let AR be a d\u00d7 r random projection matrix, r < d, as defined in Theorem 1 and AS be a n\u00d7n matrix, which extends the selection matrix in Definition 2 by adding zero rows to appropriate places. Thus, XAR is a random projection of data vectors where their distances are preserved with a high probability. The selection mapping ASX , on the other hand, deletes a subset of data vectors to reduce the data volume. The reduction in training data dimension and volume decreases the computational and information burden of the Defender. It also provides a certain degree of robustness against malicious attacks in an adversarial setting.\nA common attack type in adversarial learning is malicious distortion of training data points (vectors) by an Attacker. Let X +D be the distorted data matrix, where D is determined by the Attacker. The amount of injected distortion to the data is often bounded due to either the computational burden or increasing risk of discovery of the Attack(er). For example, some of the rows of D may be zero indicating that the Attacker distorts only a subset of the data.\nThe counterpart of (13) in the adversarial learning formulation describes is then:\nmax \u03b1 1T AS\u03b1\u2212 1 2 \u03b1TYAS(X +D)ARATR(X +D) T ASY \u03b1\ns.t. 1TYAS\u03b1 = 0, 0\u2264 \u03b1 \u2264 C, (14)\nThe optimal geometric margin \u03b3? of the canonical hyperplane w? obtained from (13) is defined as \u03b3? = 1/\u2016w?\u20162, where \u2016w?\u201622 = \u2211i \u03b1i. Define, likewise, \u03b3\u0303? using (14). Since geometric margin plays a foundational role in the formulation of the binary SVM classification problem, it makes sense to use it as a criterion in the adversarial learning game. Hence, the player objectives can be posed as minimizing (maximizing) the distortion in the geometric margin |\u03b3?\u2212 \u03b3\u0303?| for the Defender (Attacker), respectively.\nAs a starting point of the analysis, the optimization problem (14) is reformulated by capturing the impact of random selection mapping AS through a set of new constraints:\nmax \u03b1 1T \u03b1\u2212 1 2 \u03b1TY (X +D)ARATR(X +D) TY \u03b1\ns.t. 1TY\u03b1 = 0, 0\u2264 \u03b1 \u2264 C, (15) and (I\u2212AS)X = 0, (I\u2212AS)\u03b1 = 0. (16)\nNote that,\n\u03b1TY (X +D)ARATR(X +D) TY \u03b1 = \u2225\u2225\u03b1TY (X +D)AR\u2225\u222522 . Using the triangle inequality,\n(1\u2212\u03b4 ) \u2225\u2225\u03b1TY XAR\u2225\u222522 \u2264 \u2225\u2225\u03b1TY (X +D)AR\u2225\u222522 (17)\n\u2264 (1+\u03b4 ) \u2225\u2225\u03b1TY XAR\u2225\u222522 ,\nwhere\n\u03b4 := \u2225\u2225\u03b1TY DAR\u2225\u222522 \u2016\u03b1TY XAR\u201622 < 1 .\nLet Zpds(\u03b1?pds) be the optimal value of (14) and (15)-(16). The value, Zpd(\u03b1?pd), obtained by resolving (15) without the constraints in (16) clearly leads to a higher or equal value such that\nZpd = \u03b2Zpds , \u03b2 \u2265 1 .\nIt is worth noting that \u03b2 is a function of the data X as well as AR, AS, and D.\nDefine\nZp(\u03b1?pd) := 1 T \u03b1?pd\u2212 \u2225\u2225\u2225\u03b1?,Tpd Y XAR\u2225\u2225\u222522 , which is the optimal value without any malicious distortion, D = 0, of the data set. Then, from (17),\nZp(\u03b1?pd)\u2265 Zpd(\u03b1?pd)\u2212\u03b4 \u2225\u2225\u2225\u03b1?,Tpd Y XAR\u2225\u2225\u222522\nand hence Zp(\u03b1?pd)\u2265 \u03b2Zpds(\u03b1?pds)\u2212\u03b4 \u2225\u2225\u2225\u03b1?,Tpd Y XAR\u2225\u2225\u222522 . (18)\nLet Z(\u03b1?) denote the optimal value of the original problem, (13). It is important to note that \u03b1?pd is also a feasible (but clearly not optimal) solution of (13). Hence, Z(\u03b1?) \u2265 Zp(\u03b1?pd) by definition.\nThe rest of the analysis closely follows the one in [41]. Let V \u2208 Rd\u00d7\u03c1 be any matrix with orthonormal columns. Define E := V TV \u2212V T ARATRV , and assume \u2016E\u20162 < \u03c6 for a given AR. Then,\nZ(\u03b1?)\u2265 Zp(\u03b1?pd)\u2212 1 2 \u2016E\u20162 \u2225\u2225\u2225\u03b1?,Tpd Y X\u2225\u2225\u222522 . It is shown in [41] that\u2225\u2225\u2225\u03b1?,Tpd Y X\u2225\u2225\u222522 \u2264 11\u2212\u2016E\u20162\n\u2225\u2225\u2225\u03b1?,Tpd Y XAR\u2225\u2225\u222522 . Thus, from (18),\nZ(\u03b1?)\u2265 \u03b2Zpds(\u03b1?pds)\n\u2212 \u03b2 2\n( \u2016E\u20162\n1\u2212\u2016E\u20162 +2\u03b4 )\u2225\u2225\u2225\u03b1?,TpdsY XAR\u2225\u2225\u222522 . (19) Remember that, from its definition w? = \u03b1?,TY X =\n\u2211i \u03b1?i and w?pds = \u03b1 ?,T pdsY X = \u2211i \u03b1 ? pds,i. Therefore, Z(\u03b1 ?) = 0.5\u2016w?\u201622, Zpds = 0.5 \u2225\u2225\u2225w?pds\u2225\u2225\u222522, and the geometric margins\nare \u03b3? = 1/\u2016w?\u20162 and \u03b3\u0303? = 1/ \u2225\u2225\u2225w?pds\u2225\u2225\u22252. Combining these definitions with (19) leads to\nZ(\u03b1?)\u2265 \u03b2 (\n1\u2212 \u2016E\u20162 1\u2212\u2016E\u20162\n\u22122\u03b4 )\nZpds(\u03b1?pds)\nor \u03b3\u0303?2 \u2265 \u03b2 (1\u2212\u03c6 \u22122\u03b4 )\u03b3?2 . (20)\nNow, the adversarial machine learning game between the Defender and Attacker can be defined based on this worstcase gap between the margins,\u2223\u2223\u03b3?2\u2212 \u03b3\u0303?2\u2223\u2223/\u03b3?2 \u2264 1\u2212\u03b2 (1\u2212\u03c6 \u22122\u03b4 ) . Let (AR,AS) represent the actions of the Defender and D of the Attacker. As one possibility, the Defender aims to maximize \u03b2 (1\u2212\u03c6 \u22122\u03b4 ) to decrease the worst-case margin gap, while the Attacker tries to minimize it. It is assumed here that random projection, selection, and malicious distortions do not inadvertently increase the margin and help the Defender. The cost functions also capture the computational gains for the Defender due to reductions and risk of detection for the Attacker. Thus, the cost functions of the Defender and Attacker are defined as:\nmin AR,AS\nJD(AR,AS,D) =\u2212\u03b2 (AS)(1\u2212\u03c6(AR)\u22122\u03b4 (D)) (21)\n+cDR \u2016AR\u2016+ cDS \u2016AS\u2016 , min\nD JA(AR,AS,D) = \u03b2 (AS)(1\u2212\u03c6(AR)\u22122\u03b4 (D))\n+cA \u2016D\u2016 (22)\nThe following observations can be made: \u2022 \u03b2 (AS) is increasing in \u2016I\u2212AS\u2016, i.e. the number of\nsamples deleted from the data set; \u2022 \u03c6(AR) is increasing as the random projection space\ndecreases in number of dimensions, i.e., number of columns, r, in the d\u00d7 r matrix AR decreases; and \u2022 \u03b4 (D) is increasing in \u2016D\u2212 I\u2016, i.e., the amount of distortion introduced to training data by malicious attacker increases.\nThe adversarial machine learning game is then defined as G AdvML ( {De f ender,Attacker},{(AR,AS), D},{JD, JA} ) ,\nwhere JD and JA are defined in (21), (22), respectively. It is important to note that this game can only be solved numerically due to the nonlinear nature of the functions \u03b2 (AS), \u03c6(AR), and \u03b4 (D)."}, {"heading": "V. CONCLUSION", "text": "A framework for large-scale strategic games with continuous decision variables has been introduced in this paper. First, a characterization and basic definitions of large-scale strategic games have been presented. Second, motivated by information limitations, reduction of large-scale strategic games using linear transformations such as random projections and their effect on equilibrium solutions have been discussed. Third, a set of analytical results on convex and quadratic 2-player large-scale games and their equilibrium\nsolutions have been obtained. Finally, a specific adversarial machine learning game formulation has been used to illustrate context-specific selection of linear reductions in largescale games.\nLarge-scale strategic games as defined in this paper can be seen as complementary to their finite state and/or action counterparts, and hence to the game abstraction literature. There are multiple interesting future research directions in the continuous-kernel game domain. One open direction is further investigation of specific transformation techniques for reduction of large-scale games and projection methods. A second direction is exploration of practical solution algorithms for large-scale data-driven games and learning schemes, e.g. the game defined at the end of Section IV. A third direction is additional applications of adversarial learning games to specific problem domains."}, {"heading": "VI. ACKNOWLEDGMENTS", "text": "The authors thank Dr. Sarah Monazam Erfani for the\nhelpful comments and discussions."}], "references": [{"title": "Mechanisms and Games for Dynamic Spectrum Allocation", "author": ["T. Alpcan", "H. Boche", "M.L. Honig", "H.V. Poor"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "A Game-Theoretic Analysis of Wind Generation Variability on Electricity Markets", "author": ["D. Chattopadhyay", "T. Alpcan"], "venue": "IEEE Trans. on Power Systems, vol. 29, no. 5, pp. 2069\u20132077, September 2014.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Game-Theoretic Methods for the Smart Grid: An Overview of Microgrid Systems, Demand-Side Management, and Smart Grid Communications", "author": ["W. Saad", "Zhu Han", "H.V. Poor", "T. Basar"], "venue": "IEEE Signal Proc. Magazine, vol. 29, no. 5, pp. 86\u2013105, September 2012.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Security Games for Risk Minimization in Automatic Generation Control", "author": ["Y.W. Law", "T. Alpcan", "M. Palaniswami"], "venue": "IEEE Trans. on Power Systems, vol. 30, no. 1, pp. 223\u2013232, January 2015.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Security and Game Theory: Algorithms, Deployed Systems, Lessons Learned", "author": ["M. Tambe"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "A Learning- Based Approach to Reactive Security", "author": ["Adam Barth", "Benjamin I.P. Rubinstein", "Mukund Sundararajan", "John C. Mitchell", "Dawn Song", "Peter L. Bartlett"], "venue": "IEEE Trans. Dependable and Secure Comp., vol. 9, no. 4, pp. 482\u2013493, 2012, Special Issue on Learning, Games and Security.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Game-Theoretic Methods for Robustness, Security, and Resilience of Cyberphysical Control Systems: Games-in- Games Principle for Optimal Cross-Layer Resilient Control Systems", "author": ["Quanyan Zhu", "T. Basar"], "venue": "IEEE Control Systems, vol. 35, no. 1, pp. 46\u201365, February 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Convex Optimization for Big Data: Scalable, randomized, and parallel algorithms for big data analytics", "author": ["V. Cevher", "S. Becker", "M. Schmidt"], "venue": "IEEE Signal Proc. Magazine, vol. 31, no. 5, pp. 32\u201343, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Abstraction for Solving Large Incomplete- Information Games", "author": ["Tuomas Sandholm"], "venue": "AAAI, 2015.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Combining Compact Representation and Incremental Generation in Large Games with Sequential Strategies", "author": ["B. Bosansky", "A. Jiang", "M. Tambe", "C. Kiekintveld"], "venue": "AAAI, January 2015, pp. 812\u2013818.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "On the relationship between Nash\u2014 Cournot and Wardrop equilibria", "author": ["A. Haurie", "P. Marcotte"], "venue": "Networks, vol. 15, no. 3, pp. 295\u2013 308, 1985.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1985}, {"title": "Nonasymptotic Mean-Field Games", "author": ["H. Tembine"], "venue": "IEEE Trans. on Cybernetics, vol. 44, no. 12, pp. 2744\u20132756, December 2014.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Satisficing the Masses: Applying Game Theory to Large-Scale, Democratic Decision Problems", "author": ["Kshanti A. Greene", "Joe Michael Kniss", "George F. Luger", "Carl R. Stern"], "venue": "12th IEEE Intl. Conf. Comp Sci. Eng. (CSE), Vancouver, BC, Canada, August 2009, pp. 1156\u20131162.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Give a Hard Problem to a Diverse Team: Exploring Large Action Spaces", "author": ["Leandro Soriano Marcolino", "Haifeng Xu", "Albert Xin Jiang", "Milind Tambe", "Emma Bowring"], "venue": "AAAI, 2014, pp. 1485\u2013 1491.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Scaling-up Security Games with Boundedly Rational Adversaries: A Cutting-plane Approach", "author": ["Rong Yang", "Albert Xin Jiang", "Milind Tambe", "Fernando Ord\u00f3\u00f1ez"], "venue": "IJCAI, August 2013, pp. 404\u2013410.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "The Security of Machine Learning", "author": ["Marco Barreno", "Blaine Nelson", "Anthony D. Joseph", "J.D. Tygar"], "venue": "Machine Learning, vol. 81, no. 2, pp. 121\u2013148, November 2010.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Privacy preserving data mining", "author": ["Yehuda Lindell", "Benny Pinkas"], "venue": "CRYPTO, 2000, pp. 36\u201354.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2000}, {"title": "Calibrating Noise to Sensitivity in Private Data Analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith"], "venue": "TCC, 2006, pp. 265\u2013284.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "On Attacking Statistical Spam Filters", "author": ["Gregory L. Wittel", "S. Felix Wu"], "venue": "CEAS, 2004.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "Good Word Attacks on Statistical Spam Filters", "author": ["Daniel Lowd", "Christopher Meek"], "venue": "CEAS, 2005.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2005}, {"title": "Exploiting machine learning to subvert your spam filter", "author": ["Blaine Nelson", "Marco Barreno", "Fuching Jack Chi", "Anthony D. Joseph", "Benjamin I.P. Rubinstein", "Udam Saini", "Charles Sutton", "J.D. Tygar", "Kai Xia"], "venue": "Proc. 1st USENIX Work. Large-Scale Exploits and Emergent Threats (LEET). 2008, pp. 1\u20139, USENIX Association.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "Paragraph: Thwarting Signature Learning by Training Maliciously", "author": ["James Newsome", "Brad Karp", "Dawn Song"], "venue": "RAID, 2006, pp. 81\u2013 105.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2006}, {"title": "Evading Network Anomaly Detection Systems: Formal Reasoning and Practical Techniques", "author": ["Prahlad Fogla", "Wenke Lee"], "venue": "CCS, 2006, pp. 59\u201368.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2006}, {"title": "ANTIDOTE: Understanding and Defending against Poisoning of Anomaly Detectors", "author": ["Benjamin I.P. Rubinstein", "Blaine Nelson", "Ling Huang", "Anthony D. Joseph", "Shing-hon Lau", "Satish Rao", "Nina Taft", "J.D. Tygar"], "venue": "IMC, 2009, pp. 1\u201314.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Adversarial Classification", "author": ["Nilesh Dalvi", "Pedro Domingos", "Mausam", "Sumit Sanghai", "Deepak Verma"], "venue": "KDD, 2004, pp. 99\u2013108.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2004}, {"title": "Nash Equilibria of Static Prediction Games", "author": ["Michael Br\u00fcckner", "Tobias Scheffer"], "venue": "NIPS, 2009, pp. 171\u2013179.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Prediction, Learning, and Games", "author": ["Nicol\u00f2 Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2006}, {"title": "Regret Minimizing Audits: A Learning-Theoretic Basis for Privacy Protection", "author": ["Jeremiah Blocki", "Nicolas Christin", "Anupam Datta", "Arunesh Sinha"], "venue": "CSF, 2011, pp. 312\u2013327.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Robust Statistics, Probability and Mathematical Statistics", "author": ["Peter J. Huber"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1981}, {"title": "Extensions of Lipschitz mappings into a Hilbert space", "author": ["William B Johnson", "Joram Lindenstrauss"], "venue": "Contemporary Mathematics, vol. 26, no. 189-206, pp. 189\u2013206, 1984.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1984}, {"title": "An algorithmic theory of learning: Robust concepts and random projection", "author": ["Rosa I Arriaga", "Santosh Vempala"], "venue": "FOCS, 1999, pp. 616\u2013623.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1999}, {"title": "A theory of the learnable", "author": ["Leslie Valiant"], "venue": "Communications of the ACM, vol. 27, pp. 1134\u20131142, 1984.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1984}, {"title": "Random features for large-scale kernel machines", "author": ["Ali Rahimi", "Benjamin Recht"], "venue": "Advances in neural information processing systems, 2007, pp. 1177\u20131184.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning with kernels: support vector machines, regularization, optimization, and beyond", "author": ["Bernhard Scholkopf", "Alexander J Smola"], "venue": "MIT press,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2001}, {"title": "The Matrix Cookbook", "author": ["K.B. Petersen", "M.S. Pedersen"], "venue": "October 2008.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2008}, {"title": "Random Projections for Linear Support Vector Machines", "author": ["C. Boutsidis M. Magdon-Ismail P. Drineas S. Paul"], "venue": "ACM Transactions on Knowledge Discovery from Data, vol. 8, no. 4, pp. 22:1\u201322:25, Oct. 2014.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Game theory, which has its roots in economics, has recently become a mainstream approach to a multitude of engineering problems in communications [1], electricity grids [2]\u2013[4], and network security [5]\u2013[7].", "startOffset": 146, "endOffset": 149}, {"referenceID": 1, "context": "Game theory, which has its roots in economics, has recently become a mainstream approach to a multitude of engineering problems in communications [1], electricity grids [2]\u2013[4], and network security [5]\u2013[7].", "startOffset": 169, "endOffset": 172}, {"referenceID": 3, "context": "Game theory, which has its roots in economics, has recently become a mainstream approach to a multitude of engineering problems in communications [1], electricity grids [2]\u2013[4], and network security [5]\u2013[7].", "startOffset": 173, "endOffset": 176}, {"referenceID": 5, "context": "Game theory, which has its roots in economics, has recently become a mainstream approach to a multitude of engineering problems in communications [1], electricity grids [2]\u2013[4], and network security [5]\u2013[7].", "startOffset": 203, "endOffset": 206}, {"referenceID": 6, "context": "Providing a solid mathematical foundation for multi-agent decision making, game theory has also been used extensively in optimization and control of networked and cyber-physical systems [8].", "startOffset": 186, "endOffset": 189}, {"referenceID": 7, "context": "Linear Programs with thousands of variables are now common-place; and convex optimization on largescale data, aiming to overcome computational, storage and communication bottlenecks [9], has emerged as a major area of study.", "startOffset": 182, "endOffset": 185}, {"referenceID": 8, "context": "research challenges with those involving large number of finite states and/or actions [10].", "startOffset": 86, "endOffset": 90}, {"referenceID": 9, "context": "There have recently been efforts to address these computational issues using active-set or similar methods [12].", "startOffset": 107, "endOffset": 111}, {"referenceID": 8, "context": "Hence, it can be seen as complementary to the existing literature on game abstraction which shares similar aims [10].", "startOffset": 112, "endOffset": 116}, {"referenceID": 10, "context": "librium [13].", "startOffset": 8, "endOffset": 12}, {"referenceID": 11, "context": "The basic idea behind mean-field games is approximating large games by a stylized model with a continuum of players [14].", "startOffset": 116, "endOffset": 120}, {"referenceID": 12, "context": "For example, in cooperative decisionmaking among a large population of agents whose opinions must be considered, [15] propose a Bayesian belief aggrega-", "startOffset": 113, "endOffset": 117}, {"referenceID": 13, "context": "[16] examine how the performance of a team of diverse agents improves in cooperative games, as the number of agents or possible actions increases.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[12] consider strategic games with sequential strategies,", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[17] address", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[10] presents an excellent survey of abstraction of information or actions in games, motivated by incomplete information or scalability.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "A number of threat models fall under this umbrella [18].", "startOffset": 51, "endOffset": 55}, {"referenceID": 16, "context": "While privacy-preserving learning has been met successfully by the theoretical frameworks of secure multi-party computation [19] and differential privacy [20], less is known about how to learn or predict on poisoned data.", "startOffset": 124, "endOffset": 128}, {"referenceID": 17, "context": "While privacy-preserving learning has been met successfully by the theoretical frameworks of secure multi-party computation [19] and differential privacy [20], less is known about how to learn or predict on poisoned data.", "startOffset": 154, "endOffset": 158}, {"referenceID": 18, "context": "Related case studies include attacks on spam detection [21]\u2013[23], polymorphic worm detectors [24], and on network anomaly detectors [25], [26].", "startOffset": 55, "endOffset": 59}, {"referenceID": 20, "context": "Related case studies include attacks on spam detection [21]\u2013[23], polymorphic worm detectors [24], and on network anomaly detectors [25], [26].", "startOffset": 60, "endOffset": 64}, {"referenceID": 21, "context": "Related case studies include attacks on spam detection [21]\u2013[23], polymorphic worm detectors [24], and on network anomaly detectors [25], [26].", "startOffset": 93, "endOffset": 97}, {"referenceID": 22, "context": "Related case studies include attacks on spam detection [21]\u2013[23], polymorphic worm detectors [24], and on network anomaly detectors [25], [26].", "startOffset": 132, "endOffset": 136}, {"referenceID": 23, "context": "Related case studies include attacks on spam detection [21]\u2013[23], polymorphic worm detectors [24], and on network anomaly detectors [25], [26].", "startOffset": 138, "endOffset": 142}, {"referenceID": 24, "context": "[27] considered patching of simple classifier\u2019s \u2018blind spots\u2019 to attack by instances that optimize an attacker cost function in a one-shot game-theoretic setting.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[28] identify conditions for the existence of unique Nash equilibria for static games for learning.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "Regret minimizing learners [29] have been used in security settings [7], [30] but not with popular \u201cbatch\u201d", "startOffset": 27, "endOffset": 31}, {"referenceID": 5, "context": "Regret minimizing learners [29] have been used in security settings [7], [30] but not with popular \u201cbatch\u201d", "startOffset": 68, "endOffset": 71}, {"referenceID": 27, "context": "Regret minimizing learners [29] have been used in security settings [7], [30] but not with popular \u201cbatch\u201d", "startOffset": 73, "endOffset": 77}, {"referenceID": 28, "context": "The adversarial learning setting relates to robust statistics [31] and online learning theory or the theory of regret minimization [29].", "startOffset": 62, "endOffset": 66}, {"referenceID": 26, "context": "The adversarial learning setting relates to robust statistics [31] and online learning theory or the theory of regret minimization [29].", "startOffset": 131, "endOffset": 135}, {"referenceID": 5, "context": "While there have been applications in security [7], [26], [30], neither framework has so far had a large impact on research in security.", "startOffset": 47, "endOffset": 50}, {"referenceID": 23, "context": "While there have been applications in security [7], [26], [30], neither framework has so far had a large impact on research in security.", "startOffset": 52, "endOffset": 56}, {"referenceID": 27, "context": "While there have been applications in security [7], [26], [30], neither framework has so far had a large impact on research in security.", "startOffset": 58, "endOffset": 62}, {"referenceID": 29, "context": "The Johnson-Lindenstrauss Lemma [32] established the existence of low-dimensional linear projections that approximately preserve inter-point distances, a key characteristic used by many learning algorithms.", "startOffset": 32, "endOffset": 36}, {"referenceID": 30, "context": "In their landmark paper, [33] built on this property of random projections to show that model classes (that are robust, with some margin) are still PAC learnable [34] when randomly projected by data-independent mappings.", "startOffset": 25, "endOffset": 29}, {"referenceID": 31, "context": "In their landmark paper, [33] built on this property of random projections to show that model classes (that are robust, with some margin) are still PAC learnable [34] when randomly projected by data-independent mappings.", "startOffset": 162, "endOffset": 166}, {"referenceID": 32, "context": "More recently, Rahimi & Recht [35] use random projections to reduce the computational complexity of training support vector machine (SVM) classifiers on large data sets.", "startOffset": 30, "endOffset": 34}, {"referenceID": 33, "context": "SVM learning involves solving a quadratically-constrained quadratic program [36] whose dual involves the data only via inner-products\u2014a kernel matrix.", "startOffset": 76, "endOffset": 80}, {"referenceID": 30, "context": "Random projections are extremely popular techniques in machine learning for dealing with the curse-ofdimensionality [33], [35].", "startOffset": 116, "endOffset": 120}, {"referenceID": 32, "context": "Random projections are extremely popular techniques in machine learning for dealing with the curse-ofdimensionality [33], [35].", "startOffset": 122, "endOffset": 126}, {"referenceID": 29, "context": "The well-known Johnson-Lindenstrauss Lemma [32] formalizes this idea.", "startOffset": 43, "endOffset": 47}, {"referenceID": 34, "context": "If the matrices Q1 and Q2 are positive definite and hence invertible [40], then the cost functions J1 and J2 are both quadratic and strictly convex.", "startOffset": 69, "endOffset": 73}, {"referenceID": 5, "context": "Security games have been used increasingly to model decision making in network and real-life problems with resource constraints [5]\u2013[7].", "startOffset": 132, "endOffset": 135}, {"referenceID": 32, "context": "the inner product of projected points can approximate their original kernel evaluation if the transformation is carefully selected [35].", "startOffset": 131, "endOffset": 135}, {"referenceID": 35, "context": "The rest of the analysis closely follows the one in [41].", "startOffset": 52, "endOffset": 56}, {"referenceID": 35, "context": "It is shown in [41] that \u2225\u2225\u2225\u03b1?,T pd Y X\u2225\u2225\u222522 \u2264 1 1\u2212\u2016E\u20162 \u2225\u2225\u2225\u03b1?,T pd Y XAR\u2225\u2225\u222522 .", "startOffset": 15, "endOffset": 19}], "year": 2016, "abstractText": "Decision making in modern large-scale and complex systems such as communication networks, smart electricity grids, and cyber-physical systems motivate novel gametheoretic approaches. This paper investigates big strategic (noncooperative) games where a finite number of individual players each have a large number of continuous decision variables and input data points. Such high-dimensional decision spaces and big data sets lead to computational challenges, relating to efforts in non-linear optimization scaling up to large systems of variables. In addition to these computational challenges, real-world players often have limited information about their preference parameters due to the prohibitive cost of identifying them or due to operating in dynamic online settings. The challenge of limited information is exacerbated in high dimensions and big data sets. Motivated by both computational and information limitations that constrain the direct solution of big strategic games, our investigation centers around reductions using linear transformations such as random projection methods and their effect on Nash equilibrium solutions. Specific analytical results are presented for quadratic games and approximations. In addition, an adversarial learning game is presented where random projection and sampling schemes are investigated.", "creator": "LaTeX with hyperref package"}}}