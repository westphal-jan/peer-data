{"id": "1610.01858", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Oct-2016", "title": "A Robust Framework for Classifying Evolving Document Streams in an Expert-Machine-Crowd Setting", "abstract": "An emerging challenge in the online classification of social media data streams is to keep the categories used for classification up-to-date. In this paper, we propose an innovative framework based on an Expert-Machine-Crowd (EMC) triad to help categorize items by continuously identifying novel concepts in heterogeneous data streams often riddled with outliers. We unify constrained clustering and outlier detection by formulating a novel optimization problem: COD-Means. We design an algorithm to solve the COD-Means problem and show that COD-Means will not only help detect novel categories but also seamlessly discover human annotation errors and improve the overall quality of the categorization process. Experiments on diverse real data sets demonstrate that our approach is both effective and efficient.", "histories": [["v1", "Thu, 6 Oct 2016 13:20:07 GMT  (1689kb,D)", "http://arxiv.org/abs/1610.01858v1", "Accepted at ICDM 2016"]], "COMMENTS": "Accepted at ICDM 2016", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["muhammad imran", "sanjay chawla", "carlos castillo"], "accepted": false, "id": "1610.01858"}, "pdf": {"name": "1610.01858.pdf", "metadata": {"source": "CRF", "title": "A Robust Framework for Classifying Evolving Document Streams in an Expert-Machine-Crowd Setting", "authors": ["Muhammad Imran", "Sanjay Chawla"], "emails": ["mimran@qf.org.qa", "schawla@qf.org.qa", "chato@acm.org"], "sections": [{"heading": null, "text": "Keywords-stream classification; text classification; novel concept detection; social media; outlier detection\nI. INTRODUCTION\nThe application that motivates our work is time-critical analysis of a social media stream. We consider a basic operation on this stream, which is to rapidly categorize messages into a series of classes of interest and also to capture novel emerging categories. This is a relevant problem during all sort of crises, such as mass convergence events and emergencies, including sudden-onset natural and man-made disasters. This problem, in practice, is addressed through automatic classification, crowdsourced classification, or a combination of both [1, 2].\nWe developed a system [3] that follows the latter approach. The system combines human and machine intelligence to categorize crisis-related messages on Twitter during the sudden-onset of natural or man-made disasters. The system obtains labels (for the messages) from human workers (volunteers in this case) and trains machine learning classifiers. The trained classifiers then enable the automatic classification of subsequent incoming messages into the defined categories. We refer to this unique collaboration between domain experts, crowd volunteers and machine learning classification as the Expert-Machine-Crowd (EMC) framework.\nThere are two important challenges that have emerged for such a system to work in an optimal fashion.\nDefining the categorization scheme: While it is impossible to predict apriori all types of categories (e.g. previously unknown needs of affected people) that are likely to emerge during a crisis, there is increasing evidence that most disasters do have a lot in common [4]. However, the dictionary of all possible information categories people write about in social media is potentially very large. For instance, in an analysis in 2012 of social media during 4 disasters, 28 information categories were found in the messages posted on this platform [5]. Having a large set of categories is problematic from the crowdsourcing point of view as unskilled annotators cannot distinguish between very finegrained categories, which introduce labeling errors and also drastically limits the size of the annotator pool. A large number of categories also increases burn-in (performance reduction in the pool) and drop-out (annotators leaving the pool), particularly in volunteer crowdsourcing settings [3].\nLabeling Errors: The dynamic nature, brevity and ambiguity of messages often lead to labeling errors by annotators which can drastically reduce the accuracy and thus usefulness of the classifier. Experiments with real data have shown that even a few poorly labeled messsages can often lead to dramatically divergent results.\nWe propose a new optimization problem COD-Means (where COD stands for Constrained Outlier Detection) to address the problem of simultaneously discovering new categories and identifying labeling errors. Initial categories and labeling are expressed in terms of constraints and an outlier detection step is used for error detection. The outlier discovery through COD-Means is carried out by extending the k-means-- algorithm [6]. The cluster refinement process is carried out by using constrained clustering which allows the generation of new and semantically distinct categories. The expert then refines the categories based on the output of COD-means. Later initializations of COD-means (i.e. once the supervised learning system is trained) can be triggered by the expert after a fixed time-interval or on observing a low classification accuracy. In that case, the COD-Means also uses machine classified items for which the machine confidence is high (e.g. \u2265 90%). ar X\niv :1\n61 0.\n01 85\n8v 1\n[ cs\n.C L\n] 6\nO ct\n2 01\nWe formally define the problem in the next Section II. A novel optimization formulation and the associated algorithm are the subject of Section III. An extensive suite of experiments were carried out to test the EMC framework and are described in Section IV. Related work is the subject of Section V and we conclude in Section VI with a summary."}, {"heading": "II. PROBLEM DEFINITION", "text": "We are given as input a data set D of documents which have been categorized by crowdsourcing workers (not necessarily experts) or an automatic classifier into a taxonomy T = {T1, . . . , Tk, Z} containing |T | = k + 1 categories. The taxonomy forms a partition of the documents: A\u2229B = \u2205 \u2200A,B \u2208 T , A 6= B.\nWe call categories Ti the pre-existing categories, which are defined by the expert before the data begins to arrive, based on background domain knowledge.\nThe category Z, instead, is the \u201cmiscellaneous\u201d category, used for documents that do not fit in any of the Ti categories. In practical cases for the domain in which we focus (disasters and social media), this category contains anywhere from about 10% to 30% of the messages [7].\nOur task is to produce a new taxonomy\nT \u2032 = {T \u20321, . . . , T \u2032k, N1, . . . , Nn, Z \u2032}\nwith the following characteristics: \u2022 There are n new categories: |T \u2032| = |T |+ n. \u2022 Pre-existing categories are only slightly modified: Ti \u2248 T \u2032i \u2200i = 1 . . . k.\n\u2022 New categories are different from previous pre-existing categories: Ti 6\u2248 Nj \u2200i = 1 . . . k, j = 1 . . . n \u2022 |Z \u2032| < |Z|: the size miscellaneous category is reduced At a high level, our algorithm attempts to partition D into k+ n+ 1 categories, guiding the clustering process in such a way that k of these categories resemble the original Ti, and none of the categories overlap with each other."}, {"heading": "III. PROPOSED SOLUTION", "text": "Our solution framework consists of three parts (i) the crowd effort and the supervised learning output (the populated taxonomy T ) are captured as must-link (ML) and cannot-link (CL) constraints [8]; (ii) discovery of new categories is framed as a constrained clustering problem where the number of clusters specified is greater than the size of the original taxonomy T ; (iii) to identify discrepancies between human and machine annotation, a new clustering problem COD-Means is defined. A k-means type algorithm is proposed to solve COD-Means.\nA. Constraints Formation\nOur objective is to infer new categories and we use constrained clustering to encode the output of the crowd and the supervised learning (SL) process. We form two types\nof constraints: Must-Link (ML) constraints and CannotLink (CL) constraints. For the taxonomy T we formulate these constraints as follows. ML constraints: data elements belonging to a category Ti are encoded as ML constraints, i.e., if a and b both belong to Ti then a constraint ML(a, b) is created. CL constraints: data elements belonging to different categories Ti and Tj are encoded as CL constraints, i.e., if a \u2208 Ti and b \u2208 Tj and i 6= j, then CL(a, b) is created.\nAn important point to note is that data elements of the miscellaneous Z category are not encoded with any constraints. In the unsupervised learning process these data points have the freedom to move to any cluster.\nB. Constrained Clustering\nFor constrained clustering we use Davidson and Ravi\u2019s CVEQ (Constrained Vector Quantization Error) formulation to extend the k-means objective to capture both ML and CL constraints [8].\nLet d(x, y) : D \u00d7 D \u2192 R be the distance function in the context of the application. For a clustering problem on data set D with k clusters, let g : D \u2192 {1, . . . , k} be the mapping from D to cluster labels. Let C = {c1, . . . , ck} be a set of representative cluster centroids and let h : C \u2192 C be a function such that h(c) is the nearest centeroid to c for h(c) 6= c. Finally, let \u03c0 represent a cluster set. We define the error objective function of assigning D to C as\nE(C,D) = 1\n2 k\u2211 j=1  \u2211 xi\u2208\u03c0j\nd2(xi, cj) + (1)\u2211 x\u2208\u03c0j\n(xi,xa)\u2208ML g(xi)6=g(xa)\nd2(cg(xa), cj)+ (2)\n\u2211 xi\u2208\u03c0j\n(xi,xa)\u2208CL g(xi)=g(xa)\nd2(ch(g(xa)), cj) }\n(3)\nThe intuition behind the design of E(C,D) is that besides the standard distortion error (the first term), if an ML constraint (xi, xa) is violated then the cost of the violation is equal to the distance between the two centroids that contain the instances which should have been together. Similarly if a CL constraint (xi, xa) is violated then the error cost is the distance between the centroid c assigned to the pair and its nearest nearest centroid h(c).\nBased on the error objective E(C,D) a k-means style of algorithm can be designed which iterates, until convergence, between an assignment and update rule defined as follows [8]:\nAssignment Rule:\n\u2200xi /\u2208ML \u222a CL : argmin j d2(xi, cj) (4)\n\u2200(x, y) \u2208ML : argmin\ni,j\n{ d2(x, ci) + d 2(y, cj) + \u00ac\u03b4(x, y) \u2217 d2(ci, cj) } (5)\n\u2200(x, y) \u2208 CL : argmin\ni,j\n{ d2(x, ci) + d 2(y, cj) + \u00ac\u03b4(x, y) \u2217 d2(ci, h(ci)) } (6)\nHere \u03b4(x, y) is the Kronecker delta function, i.e., \u03b4(x, y) = 1 if x = y and \u03b4(x, y) = 0 if x 6= y. Thus if (x, y) is an ML constraint and x 6= y, then \u00ac\u03b4(x, y) = 1 and if x and y end up belonging to different clusters (ci and cj) then an error of d2(ci, cj) is incurred. Similarly, if (x, y) in a CL constraint and x and y end up in the same cluster then a cost of d2(ci, h(ci)) is incurred where h(ci) is the nearest cluster centroid to ci. Note each of the argmin operators in the above assignment rules will output the centroid or pair of centroids.\nUpdate Rule:\ncj =\n\u2211 xi\u2208\u03c0j [xi + \u2211\n(xi,y)\u2208ML, g(xi)6=g(y)\ncg(y) + \u2211\n(xi,y)\u2208CL, g(xi)=g(y)\nch(g(y)) ]\n|\u03c0j |+ \u2211\n(xi,y)\u2208ML, g(xi) 6=g(y)\n1 + \u2211\n(xi,y)\u2208CL, g(xi)=g(y)\n1\n(7)\nThe update rule of cj computes a modified average of all points that belong to \u03c0j . The modification captures the number of elements in \u03c0j which violated the ML and CL constraints.\nC. The COD-Means Problem\nIn order to formally capture the tendency of humans (and the SL algorithm)) to make errors during the labeling process, we introduce a new computational problem to capture clustering, constraints and outliers.\nProblem 1: (COD-Means) Given a data set D, a distance function d : D \u00d7 D \u2192 R, constraint sets ML and CL, parameters k and ` find a set C = {c1, . . . , ck} and a set L consisting of k \u00d7 ` points (` points per cluster) in order to minimize the error\nE(D,C,L) = E(D \\ L, C) (8)\nObservation: The COD-Means problem is NP-hard for k > 1 and ` \u2265 0. This is clear because without the outliers the problem is standard clustering with constraints which is known to be NP-hard in the presence of CL constraints.\nD. Algorithm\nWe propose a natural extension of the constrained clustering algorithm to minimize E(D,C,L) shown in Algorithm 1. The algorithm is similar to a standard clustering algorithm with assignment rules given in Equation 4 - 6. The key difference is in Lines 9 - 13, where the points in each cluster \u03c0 are first sorted based on their distance to the centroid c\u03c0 and the top ` points are removed from \u03c0 and inserted into L(\u03c0). The update rule (Equation 7) is then applied to the modified \u03c0.\nNote that because of the presence of ML and CL constraints and that they have to be processed in pairs, the running time of the algorithm is bounded by O(|D|2k2I) where I is the number of iterations. We have omitted the convergence analysis of the algorithm due to space limitations; it is an extension of [6].\nAlgorithm 1 The COD-Means Algorithm Input: Data D, ML and CL constraints on D, k number\nof clusters, l number of outliers per cluster Output: Cluster sets \u03a0, Outlier sets L\n1: Initialize with c1, . . . , ck centroids 2: while (not converged) do 3: for all x /\u2208ML \u222a CL do 4: Use Assignment Rule (Eqn 4) 5: for all (x, y) \u2208ML do 6: Use Assignment Rule (Eqn 5) 7: for all (x, y) \u2208 CL do 8: Use Assignment Rule (Eqn 6) 9: for all \u03c0 \u2208 \u03a0 do\n10: Re-order points xi in \u03c0 such that 11: d(x1, c(\u03c0)) \u2265 d(x2, c(\u03c0)) . . . ,\u2265 d(x|\u03c0|, c(\u03c0)) 12: L(\u03c0) = {x1, . . . , x`} 13: \u03c0 = \u03c0 \\ L(\u03c0) 14: Update c\u03c0 using Update Rule (Eqn 7) 15: \u03a0 = {\u03c01, . . . \u03c0k} 16: L = {L(\u03c01), . . . , L(\u03c0k)}"}, {"heading": "IV. EXPERIMENTS", "text": "We have designed and executed an extensive set of experiments to validate the proposed Expert-Machine-Crowd (EMC) framework. In particular we would like to resolve the following questions:\n1) Are the new clusters identified by the COD-Means algorithm genuinely different and novel compared to the topical clusters (i.e. existing categories) previously defined? 2) What is the nature of outliers (i.e. in our case represent labeling errors) discovered by the COD-Means algorithm. Are they genuine outliers, i.e., they do not (semantically) belong to the clusters.\n3) What is the impact of outliers on the quality of clusters generated from the COD-Means algorithm? 4) Once the new clusters are added to the training process and the outliers/wrong labels removed, does the overall accuracy of the classification process improve?\nA. Datasets\nWe use 8 datasets from [9], which corresponds to English messages posted on Twitter during crises in 2012 and 2013. Each crisis in this collection comprises 1,000 tweets annotated using the following categories: TA: Affected individuals, TB : Infrastructure and utilities, TC : Donations and volunteering, TD: Caution and advice, TE : Sympathy and emotional support, Z: Miscellaneous.\nTable I lists the crises and the prevalence of the topical (Ti) and miscellaneous (Z) categories.\nFirst we compare our proposed algorithm with the baseline algorithm i.e. standard k-means. For this purpose, we use standard cluster metrics: cluster cohesiveness and novelty.\nCohesiveness. We measure cohesiveness based on standard intra- and inter-similarity metrics. For a cluster Ci, we denote by intra(Ci) its intra-cluster distance, defined as the average distance of elements inside the cluster:\nintra(Ci) =\n\u2211 a,b\u2208Ci d(a, b)\n|Ci|2 .\nFor Ci, we denote by inter(Ci, Cci ) its average intercluster distance with respect to elements in the pre-existing categories:\ninter(Ci,\u222aki=1Ti) = \u2211 a\u2208Ci,b\u2208\u222aki=1Ti d(a, b)\n|Ci|| \u222aki=1 Ti| .\nWe ignore the Z category in this inter-cluster calculation, as it does not represent a specific topic, but corresponds to elements that do not fit in any of the existing topics. The cohesiveness of a cluster Ci is defined as a combination of the cluster intra-similarity and its inter-similarity with other clusters: intra(Ci)/ inter(Ci, Cci ). Ideally, a cluster/category should have high cohesiveness, i.e. small intra-cluster distance and large inter-cluster distances.\nNovelty. A candidate category must not to be similar to previously existing categories i.e. it must be novel. Similar categories confuse human annotators and reduce the effectiveness of an automatic classifier. The novelty of a cluster Ci is determined as maxDist(Ci)\u2212minDist(Ci) where:\nmaxDist(Ci) = max a\u2208Ci,b\u2208\u222aki=1Ti d(a, b)\nand minDist(Ci) = min\na\u2208Ci,b\u2208\u222aki=1Ti d(a, b) .\nA high novelty is observed when a cluster is far apart from all the other pre-existing clusters Ti.\nComparison. To generate clusters using both approaches (kmeans and COD-means), we generate ko + n+ 1 clusters, where ko is the number of pre-existing non-miscellaneous categories (i.e. 5 in our case), n is the number of new categories we aim to generate from the Z category. In this case, we use n = 4 which is set heuristically, as we observe that slightly larger values (from 5 to 10) do not yield significantly different results and can cause labeling errors (as discussed above), and smaller values tend to yield very general categories. The +1 corresponds to the new miscellaneous category Z \u2032. We vary the number of outliers ` from ` = 0 . . .m.\nResults generated using ` = 0 represent the standard kmeans algorithm i.e. without outliers detection. We compute cohesiveness and novelty scores for the clusters generated using each value of `. We pick the \u201ctop\u201d clusters from the output. We define a \u201ctop\u201d cluster as one that is either among the m having the largest coherence, the m having the largest novelty, or both, with m < k. We use m = 2 to reduce the number of annotations needed.\nFigure 1 depicts the results for all the datasets. The proposed approach generates more cohesive and novel clusters by removing outliers. As the value of ` increases, more tight and coherent clusters are observed. This also helped us determine an optimal value of the ` parameter for each dataset (i.e. where the high coherence and novelty scores were noticed) to be used in the next experiments.\nC. Data improvements evaluations\nTo achieve high classification accuracy, we aim to discover and remove incorrectly categorized items to miscellaneous and non-miscellaneous categories. We perform the following two data improvements experiments.\n1) Labeling errors in non-miscellaneous categories: As described earlier COD-Means discovers local outliers for each newly generated cluster. To determine whether outliers of the non-miscellaneous clusters are semantically genuine outliers, which we also call labeling errors, we have performed a user study.\nTo generate clusters and discover outliers, we ran COD-Means using k = ko + n + 1 where ko represents\nTable 1\n1st cluster coh. 2nd cluster coh. 1st cluster novelty 2nd cluster novelty 1st cluster coh. 2nd cluster coh. 1st cluster novelty 2nd cluster novelty\nVol all Vol Z Colorado wildfires 943 426 Vol all Vol z Selected L =10 Alberta floods 173 Parameter L (outliers) 1st cluster coh. 2nd cluster coh. 1st cluster novelty 2nd cluster novelty Selected L = 8\n0 0.72 0.59 0.65 0.45 Parameter L (outliers) 1st cluster coh. 2nd cluster coh. 1st cluster novelty 2nd cluster novelty 1 0.74 0.6 0.68 0.48 0 0.42 0.37 0.6 0.49 2 0.78 0.62 0.7 0.5 1 0.44 0.39 0.62 0.51 3 0.79 0.63 0.72 0.52 2 0.46 0.41 0.64 0.52 4 0.82 0.63 0.74 0.54 3 0.5 0.43 0.67 0.54 5 0.83 0.7 0.76 0.57 4 0.54 0.46 0.69 0.58 6 0.87 0.73 0.77 0.58 5 0.58 0.5 0.71 0.6 7 0.91 0.82 0.77 0.6 6 0.62 0.54 0.74 0.62 8 0.94 0.83 0.8 0.63 7 0.64 0.58 0.74 0.63 9 0.95 0.89 0.84 0.63 8 0.7 0.66 0.76 0.65 10 0.96 0.94 0.88 0.64 9 0.7 0.67 0.77 0.67 11 0.95 0.94 0.95 0.67 10 0.69 0.65 0.78 0.69 12 0.95 0.93 0.97 0.69 13 0.91 0.92 0.98 0.7 14 0.91 0.92 0.98 0.71 15 0.88 0.92 0.99 0.72 16 0.88 0.92 1 0.74\nVol Vol z Australian bushfire 378 Vol all Vol z Selected L =10 Boston bombing 913 381 Parameter L (outliers) 1st cluster coh. 2nd cluster coh. 1st cluster novelty 2nd cluster novelty Selected L =15\n0 0.64 0.57 0.54 0.65 Parameter L (outliers) 1st cluster coh. 2nd cluster coh. 1st cluster novelty 2nd cluster novelty 1 0.65 0.58 0.56 0.68 0 0.45 0.41 0.35 0.32 2 0.67 0.6 0.59 0.7 1 0.46 0.42 0.37 0.34 3 0.69 0.61 0.61 0.72 2 0.48 0.44 0.39 0.35 4 0.72 0.63 0.63 0.74 3 0.5 0.44 0.4 0.36 5 0.75 0.67 0.65 0.77 4 0.53 0.46 0.42 0.38 6 0.78 0.7 0.68 0.78 5 0.52 0.49 0.45 0.4 7 0.8 0.73 0.73 0.8 6 0.54 0.51 0.48 0.43 8 0.82 0.75 0.75 0.83 7 0.57 0.53 0.5 0.45 9 0.84 0.79 0.78 0.83 8 0.59 0.54 0.52 0.48 10 0.86 0.83 0.8 0.84 9 0.6 0.54 0.54 0.5 11 0.86 0.82 0.84 0.87 10 0.63 0.59 0.56 0.52 12 0.85 0.81 0.85 0.89 11 0.62 0.62 0.59 0.54 13 0.86 0.82 0.86 0.9 12 0.65 0.63 0.61 0.54 14 0.85 0.79 0.89 0.91 13 0.67 0.65 0.63 0.56 15 0.86 0.78 0.9 0.92 14 0.7 0.67 0.64 0.58 16 0.84 0.79 0.94 0.94 15 0.7 0.69 0.64 0.61\n16 0.69 0.68 0.65 0.64 17 0.68 0.67 0.69 0.67 18 0.69 0.68 0.69 0.68 19 0.68 0.66 0.7 0.69 20 0.67 0.67 0.72 0.69\nVol all Vol z Colorado floods 901 222 Vol all Vol Z Selected L =8 NY Train crash 999 456 Parameter L (outliers) 1st cluster coh. 2nd cluster coh. 1st cluster novelty 2nd cluster novelty Selected L =18\n0 0.58 0.46 0.42 0.35 Parameter L (outliers) 1st cluster coh. 2nd cluster coh. 1st cluster novelty 2nd cluster novelty 1 0.6 0.47 0.43 0.37 0 0.38 0.32 0.41 0.37 2 0.59 0.47 0.45 0.38 1 0.38 0.33 0.41 0.37 3 0.62 0.5 0.47 0.41 2 0.39 0.33 0.42 0.38 4 0.63 0.52 0.49 0.42 3 0.4 0.35 0.43 0.39 5 0.67 0.54 0.5 0.45 4 0.43 0.38 0.43 0.42 6 0.7 0.57 0.53 0.47 5 0.44 0.4 0.45 0.43 7 0.74 0.59 0.55 0.49 6 0.46 0.42 0.45 0.44 8 0.78 0.64 0.56 0.5 7 0.5 0.43 0.47 0.46 9 0.78 0.63 0.57 0.53 8 0.52 0.46 0.46 0.48 10 0.76 0.62 0.59 0.55 9 0.52 0.49 0.48 0.47\n10 0.58 0.51 0.5 0.48 11 0.59 0.53 0.52 0.49 12 0.62 0.54 0.53 0.51 13 0.64 0.55 0.55 0.53 14 0.67 0.59 0.54 0.54 15 0.69 0.6 0.57 0.56 16 0.73 0.6 0.58 0.58 17 0.74 0.63 0.59 0.59 18 0.74 0.64 0.62 0.61 19 0.73 0.64 0.64 0.61 20 0.73 0.65 0.66 0.62\nVol all Vol Z Queensla nd floods 892 279 Vol all Vol Z Selected L =10 West Texas explosion 883 211 Parameter L (outliers) 1st cluster coh. 2nd cluster coh. 1st cluster novelty 2nd cluster novelty Selected L =12\n0 0.42 0.34 0.48 0.45 Parameter L (outliers) 1st cluster coh. 2nd cluster coh. 1st cluster novelty 2nd cluster novelty 1 0.44 0.35 0.5 0.45 0 0.38 0.33 0.43 0.39 2 0.43 0.35 0.5 0.47 1 0.38 0.35 0.45 0.4 3 0.45 0.37 0.51 0.48 2 0.4 0.35 0.45 0.42 4 0.48 0.38 0.54 0.49 3 0.41 0.36 0.47 0.43 5 0.54 0.39 0.56 0.5 4 0.43 0.37 0.48 0.45 6 0.57 0.42 0.57 0.52 5 0.45 0.38 0.51 0.46 7 0.59 0.43 0.58 0.53 6 0.47 0.4 0.53 0.48 8 0.62 0.45 0.59 0.55 7 0.53 0.42 0.54 0.5 9 0.66 0.47 0.61 0.56 8 0.56 0.45 0.56 0.51 10 0.69 0.48 0.63 0.57 9 0.57 0.47 0.57 0.53 11 0.69 0.51 0.64 0.58 10 0.6 0.48 0.59 0.55 12 0.68 0.51 0.65 0.6 11 0.62 0.5 0.6 0.57 13 0.68 0.51 0.65 0.6 12 0.63 0.53 0.63 0.58 14 0.68 0.51 0.65 0.6 13 0.63 0.53 0.64 0.6\n14 0.62 0.52 0.66 0.63\n1\nEval of Z to ABC in terms of Precision Eval outliers of ABC in terms of Precision Full name Crisis Name Precision = (# of correctly assigned items) / (# of assigned items) 1 2012 Colorado Wildfires2012_CWF Full name Crisis Name Precision # of correctly assigned items# of assigned items Category Precision # of correctly assigned items# of assigned items 2012 Colorado Wildfires2012_CWF 0.6 133 222 Affected individuals0.78 7 9 2013 Alberta Floods 2013_AF 0.68 85 125 Caution and advice 0 0 3 2013 Australia Bushfire2013_ABF 0.71 201 284 Donations and volunteering0.5 3 6 2013 Boston Bombings2013_BB 0.68 129 190 Results took from combined sheet (yellow color) Infrastructure and utilities0.44 4 9 2013 Colorado Floods2013_CF 0.73 72 99 Results took from combined sheet (yellow color) Sympathy and support0.33 3 9 2013 NY Train Crash 2013_NYTC 0.78 206 264 Results took from combined sheet (yellow color) Misc. to other categories0.6 133 222 2013 Queensland Floods2013_QF 0.78 201 257 Results took from combined sheet (yellow color) 2013 West Texas Explosion2013_WTE 0.82 102 125 Results took from combined sheet (yellow color)\n2 2013 Alberta Floods2013_AF\nCategory Precision # of correctly assigned items# of assigned items Affected individuals0.63 5 8 Caution and advice0.38 3 8 Donations and volunteering0.29 2 7 Infrastructure and utilities0.75 6 8\nFull name Precision Sympathy and support0.5 4 8 2012 Colorado Wildfires0.6 Misc. to other categories0.68 85 125 2013 Alberta Floods 0.68 2013 Australia Bushfire0.71 2013 Boston Bombings0.68 2013 Colorado Floods 0.73 2013 NY Train Crash 0.78 2013 Queensland Floods0.78 2013 West Texas Explosion0.82 3 2013 Australia Bushfire2013_ABF\nCategory Precision # of correctly assigned items# of assigned items Affected individuals0.67 6 9 Caution and advice0.57 4 7 Donations and volunteering0.5 5 10 Infrastructure and utilities0.63 5 8 Sympathy and support0.56 5 9 Misc. to other categories0.71 201 284\n4 2013 Boston Bombings2013_BB\nCateg ry Precision # of correctly assigned items# of assigned items Affected individuals0.67 10 15 Caution and advice 0 0 1 Donations and volunteering0.44 4 9 Infrastructure and utilities0.33 1 3 Sympathy and support0.53 8 15 Misc. to other categories0.68 129 190\n5 2013 Colorado Floods2013_CF\nCategory Precision # of correctly assigned items# of assigned items Affected individuals0.63 5 8 Caution and advice 0 0 2 Donations and volunteering0.33 2 6 Infrastructure and utilities0.33 2 6 Sympathy and support0.5 3 6 Misc. to other categories0.73 72 99\n6 2013 NY Train Crash2013_NYTC\nCategory Precision # of correctly assigned items# of assigned items Affected individuals0.21 3 14 Caution and advice0.36 4 11 Donations and volunteering0.5 2 4 Infrastructure and utilities0.4 4 10 Sympathy and support0.4 4 10 Misc. to other categories0.78 206 264\n7 2013 Queensland Floods2013_Q\nCategory Precision # of correctly assigned items# of assigned items Affected individuals 0.9 9 10 Caution and advice 0.5 2 4 Donations and volunteering0.2 2 10 Infrastructure and utilities0.6 6 10 Sympathy and support0.3 3 10 Misc. to other categories0.78 201 257\n8 2013 West Texas Explosion2013_WTE\nCategory Precision # of correctly assigned items# of assigned items Affected individuals 0.6 6 10 Caution and advice0.43 3 7 Donations and volunteering0.2 1 5 Infrastructure and utilities0.14 1 7 Sympathy and support0.25 3 12 Misc. to other categories0.82 102 125\n2012 Colorado Wildfires 2013 Alberta Floods 2013 Australia Bushfire 2013 Boston Bombings 2013 Colorado Floods 2013 NY Train Crash\n2013 Queensland Floods 2013 West Texas Explosion\nPrecision\n0 0.25 0.5 0.75 1\nthe number of non-miscellaneous categories i.e. 5 in all of our datasets. As in this evaluation we are not interested in generating new clusters from Z, we set n = 0, and as always we keep +1, that makes k = 6. The optimal values for ` identified in the previous section were used for each dataset. Labeling errors from each non-miscellaneous clusters are obtained. Table II s ows a few examples of wrongly labeled items identified by COD-Means.\nNext, we generate crowdsourcing tasks using the identified outliers. A crowdsourcing task consists of an outlier item, its actual category (i.e. name of a Ti), and the category description. Workers were asked to read the category description and choose whether the given item is related to the category, or not. We used the CrowdFlower1 crowdsourcing platform. At least three different workers were required to finalize a task. For this task the inter-annotator agreement was 78%.\nFigure 2 depicts the results obtained from the crowdsourcing task in terms of precision. The precision P is measured as: P = number of correctly identified outliersnumber of identified outliers . From the results (Figure 2 and Table II) we can see that the proposed approach can help discover real labeling errors. To achieve a high classification accuracy, wrongly labeled items must be discarded to help classifier achieve higher\n1http://crowdflower.com/\ngeneralization accuracy [10], which we test in section IV-D. 2) Items incorrectly labeled as miscellaneous: In this task, we aim to evaluate whether items moved from the miscellaneous category to one of the non-miscellaneous categories are genuinely correct. We ran the COD-means algorithm using the same settings specified in section IV-C1. We asked crowd workers to specify whether an item\u2019s newly assigned category is correct or not. The inter-annotator agreement for this task was 76%.\nFigure 2 shows the results (see precision scores against \u201cmisc. to other category\u201d). The precision P is measured as: P = number of correctly assigned itemsnumber of assigned items The results clearly show that a large proportion of newly assigned items to the nonmiscellaneous categories are indeed correct assignments. Hence, if used as a training set, they can boost classification accuracy, which we empirically prove in the next section.\nD. Evaluation in terms of utility as training sets To further validate the results obtained from the data improvements process, we train machine learning classifiers to compare classification accuracy before and after data improvements.\nTwo training sets are formed (i.e. original labels and labels after the data improvements process). We remove stopwords, URLs, and user mentions from the items. Stemming is performed using the Lovins stemmer. Uni-grams and bigrams are used as features and we used the information gain feature selection method to select top 1k features. We use three well-known learning algorithms: SVM (support vector machines), Naive Bayes (NB), and Random forest (RF). We perform the evaluation of the learned model using 10-fold cross validation. Table III shows the classification results in terms of AUC. A substantial gain in AUC can be clearly observed in case of the improved training data."}, {"heading": "V. RELATED WORK", "text": "In general cluster analysis methods attempt to form disjoint groups of unlabeled data items such that items in\nsame group are similar while items in different groups are dissimilar. For instance, one such famous clustering method is k-means [11]. However, in a semi-supervised clustering approach, the algorithm uses both labeled and unlabeled data. In this particular case, the labeled data items are used as background knowledge during the clusters generation process.\nMany works described the use of constraints in different ways, e.g. some use constraints at group-level (i.e. on group of items) and other use at item-level (i.e. between two items) as a way to provide background knowledge [12\u201314]. For instance, in [14] k-means algorithm is extended to use instance-level constraints. However, our method, in addition to the instance-level constraints, discovers and removes outliers during the cluster generation process by which more compact clusters can be obtained.\nWhile it is well-known that outlier detection in a training set can help improve the accuracy of a classifier built using that training set (e.g. [10]), previous methods do not take into consideration the existing categories. Our method unifies constrained clustering and outlier detection by formulating a novel optimization problem and algorithm COD-Means."}, {"heading": "VI. CONCLUSIONS", "text": "As supervised learning systems can not be used to identify novel concepts, for this purpose, we employ unsupervised learning techniques. We presented a novel clustering algorithm COD-Means, which uses human and machine categorized items as background knowledge to form constraints and detects novel categories. The proposed algorithm, not only help detect novel categories, but also seamlessly discover outliers from each cluster by which categorization errors are fixed. Extensive experiments using real datasets demonstrate that our approach is effective and efficient."}], "references": [{"title": "Engineering crowdsourced stream processing systems", "author": ["M. Imran", "I. Lykourentzou", "C. Castillo"], "venue": "CoRR, vol. abs/1310.5463, 2013.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "CrowdFlow: Integrating machine learning with mechanical turk for Speed-Costquality flexibility", "author": ["A.J. Quinn", "B.B. Bederson", "T. Yeh", "J. Lin"], "venue": "CHI 2011 Workshop on Crowdsourcing and Human Computation, 2011.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "AIDR: Artificial intelligence for disaster response", "author": ["M. Imran", "C. Castillo", "J. Lucas", "P. Meier", "S. Vieweg"], "venue": "Proc. of 23rd WWW companion, 2014, pp. 159\u2013162.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Situational awareness in mass emergency: A behavioral and linguistic analysis of microblogged communications", "author": ["S.E. Vieweg"], "venue": "2012.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "k-means--: A unified approach to clustering and outlier detection.", "author": ["S. Chawla", "A. Gionis"], "venue": "in SDM,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Towards a data-driven approach to identify crisis-related topics in social media streams", "author": ["M. Imran", "C. Castillo"], "venue": "Proc. of 24th WWW Companion, 2015, pp. 1205\u20131210.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Clustering with constraints: Feasibility issues and the k-means algorithm", "author": ["I. Davidson", "S.S. Ravi"], "venue": "Proceedings of the 2005 SIAM International Conference on Data Mining, 2005, pp. 138\u2013149.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "What to expect when the unexpected happens: Social media communications across crises", "author": ["A. Olteanu", "S. Vieweg", "C. Castillo"], "venue": "In Proc. of 18th ACM CSCW, 2015.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Modified support vector novelty detector using training data with outliers", "author": ["L.J. Cao", "H.P. Lee", "W.K. Chong"], "venue": "Pattern Recognition Letters, 2003.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "Algorithm as 136: A k-means clustering algorithm", "author": ["J.A. Hartigan", "M.A. Wong"], "venue": "Applied statistics, pp. 100\u2013108, 1979.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1979}, {"title": "Distance metric learning with application to clustering with side-information", "author": ["E.P. Xing", "M.I. Jordan", "S. Russell", "A.Y. Ng"], "venue": "Advances in neural information processing systems, 2002, pp. 505\u2013 512.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "Active semi-supervision for pairwise constrained clustering.", "author": ["S. Basu", "A. Banerjee", "R.J. Mooney"], "venue": "in SDM,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "Constrained kmeans clustering with background knowledge", "author": ["K. Wagstaff", "C. Cardie", "S. Rogers", "S. Schr\u00f6dl"], "venue": "ICML, vol. 1, 2001, pp. 577\u2013584.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "This problem, in practice, is addressed through automatic classification, crowdsourced classification, or a combination of both [1, 2].", "startOffset": 128, "endOffset": 134}, {"referenceID": 1, "context": "This problem, in practice, is addressed through automatic classification, crowdsourced classification, or a combination of both [1, 2].", "startOffset": 128, "endOffset": 134}, {"referenceID": 2, "context": "We developed a system [3] that follows the latter approach.", "startOffset": 22, "endOffset": 25}, {"referenceID": 3, "context": "For instance, in an analysis in 2012 of social media during 4 disasters, 28 information categories were found in the messages posted on this platform [5].", "startOffset": 150, "endOffset": 153}, {"referenceID": 2, "context": "A large number of categories also increases burn-in (performance reduction in the pool) and drop-out (annotators leaving the pool), particularly in volunteer crowdsourcing settings [3].", "startOffset": 181, "endOffset": 184}, {"referenceID": 4, "context": "The outlier discovery through COD-Means is carried out by extending the k-means-- algorithm [6].", "startOffset": 92, "endOffset": 95}, {"referenceID": 5, "context": "In practical cases for the domain in which we focus (disasters and social media), this category contains anywhere from about 10% to 30% of the messages [7].", "startOffset": 152, "endOffset": 155}, {"referenceID": 6, "context": "Our solution framework consists of three parts (i) the crowd effort and the supervised learning output (the populated taxonomy T ) are captured as must-link (ML) and cannot-link (CL) constraints [8]; (ii) discovery of new categories is framed as a constrained clustering problem where the number of clusters specified is greater than the size of the original taxonomy T ; (iii) to identify discrepancies between human and machine annotation, a new clustering problem COD-Means is defined.", "startOffset": 195, "endOffset": 198}, {"referenceID": 6, "context": "For constrained clustering we use Davidson and Ravi\u2019s CVEQ (Constrained Vector Quantization Error) formulation to extend the k-means objective to capture both ML and CL constraints [8].", "startOffset": 181, "endOffset": 184}, {"referenceID": 6, "context": "Based on the error objective E(C,D) a k-means style of algorithm can be designed which iterates, until convergence, between an assignment and update rule defined as follows [8]:", "startOffset": 173, "endOffset": 176}, {"referenceID": 4, "context": "We have omitted the convergence analysis of the algorithm due to space limitations; it is an extension of [6].", "startOffset": 106, "endOffset": 109}, {"referenceID": 7, "context": "We use 8 datasets from [9], which corresponds to English messages posted on Twitter during crises in 2012 and 2013.", "startOffset": 23, "endOffset": 26}, {"referenceID": 8, "context": "com/ generalization accuracy [10], which we test in section IV-D.", "startOffset": 29, "endOffset": 33}], "year": 2016, "abstractText": "An emerging challenge in the online classification of social media data streams is to keep the categories used for classification up-to-date. In this paper, we propose an innovative framework based on an Expert-Machine-Crowd (EMC) triad to help categorize items by continuously identifying novel concepts in heterogeneous data streams often riddled with outliers. We unify constrained clustering and outlier detection by formulating a novel optimization problem: COD-Means. We design an algorithm to solve the COD-Means problem and show that COD-Means will not only help detect novel categories but also seamlessly discover human annotation errors and improve the overall quality of the categorization process. Experiments on diverse real data sets demonstrate that our approach is both effective and efficient. Keywords-stream classification; text classification; novel concept detection; social media; outlier detection", "creator": "LaTeX with hyperref package"}}}