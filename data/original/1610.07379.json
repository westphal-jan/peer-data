{"id": "1610.07379", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Oct-2016", "title": "Truncated Variance Reduction: A Unified Approach to Bayesian Optimization and Level-Set Estimation", "abstract": "We present a new algorithm, truncated variance reduction (TruVaR), that treats Bayesian optimization (BO) and level-set estimation (LSE) with Gaussian processes in a unified fashion. The algorithm greedily shrinks a sum of truncated variances within a set of potential maximizers (BO) or unclassified points (LSE), which is updated based on confidence bounds. TruVaR is effective in several important settings that are typically non-trivial to incorporate into myopic algorithms, including pointwise costs and heteroscedastic noise. We provide a general theoretical guarantee for TruVaR covering these aspects, and use it to recover and strengthen existing results on BO and LSE. Moreover, we provide a new result for a setting where one can select from a number of noise levels having associated costs. We demonstrate the effectiveness of the algorithm on both synthetic and real-world data sets.", "histories": [["v1", "Mon, 24 Oct 2016 12:18:00 GMT  (2536kb,D)", "http://arxiv.org/abs/1610.07379v1", "Accepted to NIPS 2016"]], "COMMENTS": "Accepted to NIPS 2016", "reviews": [], "SUBJECTS": "stat.ML cs.IT cs.LG math.IT", "authors": ["ilija bogunovic", "jonathan scarlett", "andreas krause 0001", "volkan cevher"], "accepted": true, "id": "1610.07379"}, "pdf": {"name": "1610.07379.pdf", "metadata": {"source": "CRF", "title": "Truncated Variance Reduction: A Unified Approach to Bayesian Optimization and Level-Set Estimation", "authors": ["Ilija Bogunovic", "Jonathan Scarlett", "Andreas Krause", "Volkan Cevher"], "emails": ["ilija.bogunovic@epfl.ch,", "jonathan.scarlett@epfl.ch,", "volkan.cevher@epfl.ch,", "krausea@ethz.ch"], "sections": [{"heading": "1 Introduction", "text": "Bayesian optimization (BO) [1] provides a powerful framework for automating design problems, and finds applications in robotics, environmental monitoring, and automated machine learning, just to name a few. One seeks to find the maximum of an unknown reward function that is expensive to evaluate, based on a sequence of suitably-chosen points and noisy observations. Numerous BO algorithms have been presented previously; see Section 1.1 for an overview.\nLevel-set estimation (LSE) [2] is closely related to BO, with the added twist that instead of seeking a maximizer, one seeks to classify the domain into points that lie above or below a certain threshold. This is of considerable interest in applications such as environmental monitoring and sensor networks, allowing one to find all \u201csufficiently good\u201d points rather than the best point alone.\nWhile BO and LSE are closely related, they are typically studied in isolation. In this paper, we provide a unified treatment of the two via a new algorithm, Truncated Variance Reduction (TRUVAR), which enjoys theoretical guarantees, good computational complexity, and the versatility to handle important settings such as pointwise costs, non-constant noise, and multi-task scenarios. The main result of this paper applies to the former two settings, and even the fixed-noise and unit-cost case, we refine existing bounds via a significantly improved dependence on the noise level."}, {"heading": "1.1 Previous Work", "text": "Three popular myopic techniques for Bayesian optimization are expected improvement (EI), probability of improvement (PI), and Gaussian process upper confidence bound (GP-UCB) [1, 3], each of which chooses the point maximizing an acquisition function depending directly on the current posterior mean and variance. In [4], the GP-UCB-PE algorithm was presented for BO, choosing the highest-variance point within a set of potential maximizers that is updated based on confidence bounds. Another relevant BO algorithm is BaMSOO [5], which also keeps track of potential maximizers, but instead chooses points based on a global optimization technique called simultaneous\nar X\niv :1\n61 0.\n07 37\n9v 1\n[ st\nat .M\nL ]\n2 4\nO ct\nonline optimization (SOO). An algorithm for level-set estimation with GPs is given in [2], which keeps track of a set of unclassified points. These algorithms are computationally efficient and have various theoretical guarantees, but it is unclear how best to incorporate aspects such as pointwise costs and heteroscedastic noise [6]. The same is true for the Straddle heuristic for LSE [7].\nEntropy search (ES) [8] and its predictive version [9] choose points to reduce the uncertainty of the location of the maximum, doing so via a one-step lookahead of the posterior rather than only the current posterior. While this is more computationally expensive, it also permits versatility with respect to costs [6], heteroscedastic noise [10], and multi-task scenarios [6]. A recent approach called minimum regret search (MRS) [11] also performs a look-ahead, but instead chooses points to minimize the regret. To our knowledge, no theoretical guarantees have been provided for these.\nThe multi-armed bandit (MAB) [12] literature has developed alongside the BO literature, with the two often bearing similar concepts. The MAB literature is far too extensive to cover here, but we briefly mention some variants relevant to this paper. Extensive attention has been paid to the bestarm identification problem [13], and cost constraints have been incorporated in a variety of forms [14]. Moreover, the concept of \u201czooming in\u201d to the optimal point has been explored [15]. In general, the assumptions and analysis techniques in the MAB and BO literature are quite different."}, {"heading": "1.2 Contributions", "text": "We present a unified analysis of Bayesian optimization and level-set estimation via a new algorithm Truncated Variance Reduction (TRUVAR). The algorithm works by keeping track of a set of potential maximizers (BO) or unclassified points (LSE), selecting points that shrink the uncertainty within that set up to a truncation threshold, and updating the set using confidence bounds. Similarly to ES and MRS, the algorithm performs a one-step lookahead that is highly beneficial in terms of versatility. However, unlike these previous works, our lookahead avoids the computationally expensive task of averaging over the posterior distribution and the observations.\nAlso in contrast with ES and MRS, we provide theoretical bounds for TRUVAR characterizing the cost required to achieve a certain accuracy in finding a near-optimal point (BO) or in classifying each point in the domain (LSE). By applying this to the standard BO setting, we not only recover existing results [2, 4], but we also strengthen them via a significantly improved dependence on the noise level, with better asymptotics in the small noise limit. Moreover, we provide a novel result for a setting in which the algorithm can choose the noise level, each coming with an associated cost.\nFinally, we compare our algorithm to previous works on several synthetic and real-world data sets, observing it to perform favorably in a variety of settings."}, {"heading": "2 Problem Setup and Proposed Algorithm", "text": "Setup: We seek to sequentially optimize an unknown reward function f(x) over a finite domain D.1 At time t, we query a single point xt \u2208 D and observe a noisy sample yt = f(xt) + zt, where zt \u223c N(0, \u03c32(xt)) for some known noise function \u03c32(\u00b7) : D \u2192 R+. Thus, in general, some points may be noisier than others, in which case we have heteroscedastic noise [10]. We associate with each point a cost according to some known cost function c : D \u2192 R+. If both \u03c32(\u00b7) and c(\u00b7) are set to be constant, then we recover the standard homoscedastic and unit-cost setting.\nWe model f(x) as a Gaussian process (GP) [16] having mean zero and kernel function k(x, x\u2032), normalized so that k(x, x) = 1 for all x \u2208 D. The posterior distribution of f given the points and observations up to time t is again a GP, with the posterior mean and variance given by [10]\n\u00b5t(x) = kt(x) T ( Kt + \u03a3t )\u22121 yt (1)\n\u03c3t(x) 2 = k(x, x)\u2212 kt(x)T ( Kt + \u03a3t )\u22121 kt(x), (2)\nwhere kt(x) = [ k(xi, x) ]t i=1 , Kt = [ k(xt, xt\u2032) ] t,t\u2032\n, and \u03a3t = diag(\u03c32(x1), . . . , \u03c32(xt)). We also let \u03c32t\u22121|x(x) denote the posterior variance of x upon observing x along with x1, \u00b7 \u00b7 \u00b7 , xt\u22121.\n1Extensions to continuous domains are discussed in the supplementary material.\nWe consider both Bayesian optimization, which consists of finding a point whose function value is as high as possible, and level-set estimation, which consists of classifying the domain according into points that lie above or below a given threshold h. The precise performance criteria for these settings are given in Definition 3.1 below. Essentially, after spending a certain cost we report a point (BO) or a classification (LSE), but there is no preference on the values of f(xt) for the points xt chosen before coming to such a decision (in contrast with other notions such as cumulative regret).\nTRUVAR algorithm: Our algorithm is described in Algorithm 1, making use of the updates described in Algorithm 2. The algorithm keeps track of a sequence of unclassified points Mt, representing potential maximizers for BO or points close to h for LSE. This set is updated based on the confidence bounds depending on constants \u03b2(i). The algorithm proceeds in epochs, where in the i-th epoch it seeks to bring the confidence \u03b21/2(i) \u03c3t(x) of points within Mt below a target value \u03b7(i). It does this by greedily minimizing the sum of truncated variances\u2211 x\u2208Mt\u22121 max{\u03b2(i)\u03c3 2 t\u22121|x(x), \u03b7(i)} arising from choosing the point x, along with a normalization and division by c(x) to favor low-cost points. The truncation by \u03b7(i) in this decision rule means that once the confidence of a point is below the current target value, there is no preference in making it any lower (until the target is decreased). Once the confidence of every point in Mt is less than a factor 1 + \u03b4 above the target value, the target confidence is reduced according to a multiplication by r \u2208 (0, 1). An illustration of the process is given in Figure 1, with details in the caption. For level-set estimation, we also keep track of the sets Ht and Lt, containing points believed to have function values above and below h, respectively. The constraint x \u2208 Mt\u22121 in (5)\u2013(7) ensures that {Mt} is non-increasing with respect to inclusion, and Ht and Lt are non-decreasing.\nAlgorithm 1 Truncated Variance Reduction (TRUVAR)\nInput: Domain D, GP prior (\u00b50, \u03c30, k), confidence bound parameters \u03b4 > 0, r \u2208 (0, 1), {\u03b2(i)}i\u22651, \u03b7(1) > 0, and for LSE, level-set threshold h\n1: Initialize the epoch number i = 1 and potential maximizers M(0) = D. 2: for t = 1, 2, . . . do 3: Choose\nxt = arg max x\u2208D\n\u2211 x\u2208Mt\u22121 max{\u03b2(i)\u03c3 2 t\u22121(x), \u03b7 2 (i)} \u2212 \u2211 x\u2208Mt\u22121 max{\u03b2(i)\u03c3 2 t\u22121|x(x), \u03b7 2 (i)}\nc(x) . (3)\n4: Observe the noisy function sample yt, and update according to Algorithm 2 to obtain Mt, \u00b5t, \u03c3t, lt and ut, as well as Ht and Lt in the case of LSE 5: while maxx\u2208Mt \u03b2 1/2 (i) \u03c3t(x) \u2264 (1 + \u03b4)\u03b7(i) do 6: Increment i, set \u03b7(i) = r \u00d7 \u03b7(i\u22121).\nThe choices of \u03b2(i), \u03b4, and r are discussed in Section 4. As with previous works, the kernel is assumed known in our theoretical results, whereas in practice it is typically learned from training data [3]. Characterizing the effect of model mismatch or online hyperparameter updates is beyond the scope of this paper, but is an interesting direction for future work.\nAlgorithm 2 Parameter Updates for TRUVAR\nInput: Selected points and observations {xt\u2032}tt\u2032=1; {yt\u2032}tt\u2032=1, previous sets Mt\u22121, Ht\u22121, Lt\u22121, parameter \u03b21/2(i) , and for LSE, level-set threshold h.\n1: Update \u00b5t and \u03c3t according to (1)\u2013(2), and form the upper and lower confidence bounds\nut(x) = \u00b5t(x) + \u03b2 1/2 (i) \u03c3t(x), `t(x) = \u00b5t(x)\u2212 \u03b2 1/2 (i) \u03c3t(x). (4)\n2: For BO, set Mt = { x \u2208Mt\u22121 : ut(x) \u2265 max\nx\u2208Mt\u22121 `t(x)\n} , (5)\nor for LSE, set\nMt = { x \u2208Mt\u22121 : ut(x) \u2265 h and `t(x) \u2264 h } (6)\nHt = Ht\u22121 \u222a { x \u2208Mt\u22121 : `t(x) > h } , Lt = Lt\u22121 \u222a { x \u2208Mt\u22121 : ut(x) < h } . (7)\nSome variants of our algorithm and theory are discussed in the supplementary material due to lack of space, including pure variance reduction, non-Bayesian settings [3], continuous domains [3], the batch setting [4], and implicit thresholds for level-set estimation [2]."}, {"heading": "3 Theoretical Bounds", "text": "In order to state our results for BO and LSE in a unified fashion, we define a notion of -accuracy for the two settings. That is, we define this term differently in the two scenarios, but then we provide theorems that simultaneously apply to both. All proofs are given in the supplementary material.\nDefinition 3.1. After time step t of TRUVAR, we use the following terminology:\n\u2022 For BO, the set Mt is -accurate if it contains all true maxima x\u2217 \u2208 arg maxx f(x), and all of its points satisfy f(x\u2217)\u2212 f(x) \u2264 . \u2022 For LSE, the triplet (Mt, Ht, Lt) is -accurate if all points in Ht satisfy f(x) > h, all points in Lt satisfy f(x) < h, and all points in Mt satisfy |f(x)\u2212 h| \u2264 2 .\nIn both cases, the cumulative cost after time t is defined as Ct = \u2211t t\u2032=1 c(xt\u2032).\nWe use 2 in the LSE setting instead of since this creates a region of size where the function value lies, which is consistent with the BO setting. Our performance criterion for level-set estimation is slightly different from that of [2], but the two are closely related."}, {"heading": "3.1 General Result", "text": "Preliminary definitions: Suppose that the {\u03b2(i)} are chosen to ensure valid confidence bounds, i.e., lt(x) \u2264 f(x) \u2264 ut(x) with high probability; see Theorem 3.1 and its proof below for such choices. In this case, we have after the i-th epoch that all points are either already discarded (BO) or classified (LSE), or are known up to the confidence level (1 + \u03b4)\u03b7(i). For the points with such confidence, we have ut(x)\u2212 lt(x) \u2264 2(1 + \u03b4)\u03b7(i), and hence\nut(x) \u2264 lt(x) + 2(1 + \u03b4)\u03b7(i) \u2264 f(x) + 2(1 + \u03b4)\u03b7(i), (8)\nand similarly lt(x) \u2265 f(x)\u2212 2(1 + \u03b4)\u03b7(i). This means that all points other than those within a gap of width 4(1 + \u03b4)\u03b7(i) must have been discarded or classified:\nMt \u2286 { x : f(x) \u2265 f(x\u2217)\u2212 4(1 + \u03b4)\u03b7(i) } =: M (i) (BO) (9)\nMt \u2286 { x : |f(x)\u2212 h| \u2264 2(1 + \u03b4)\u03b7(i) } =: M (i) (LSE) (10)\nSince no points are discarded or classified initially, we define M (0) = D.\nFor a collection of points S = (x\u20321, . . . , x \u2032 |S|), possibly containing duplicates, we write the total cost as c(S) = \u2211|S| i=1 c(x \u2032 i). Moreover, we denote the posterior variance upon observing the points up to time t\u2212 1 and the additional points in S by \u03c3t\u22121|S(x). Therefore, c(x) = c({x}) and \u03c3t\u22121|x(x) = \u03c3t\u22121|{x}(x). The minimum cost (respectively, maximum cost) is denoted by cmin = minx\u2208D c(x) (respectively, cmax = maxx\u2208D c(x)).\nFinally, we introduce the quantity\nC\u2217(\u03be,M) = min S\n{ c(S) : max\nx\u2208M \u03c30|S(x) \u2264 \u03be\n} , (11)\nrepresenting the minimum cost to achieve a posterior standard deviation of at most \u03be within M .\nMain result: In all of our results, we make the following assumption. Assumption 3.1. The kernel k(x, x\u2032) is such that the variance reduction function\n\u03c8t,x(S) = \u03c3 2 t (x)\u2212 \u03c32t|S(x) (12)\nis submodular [17] for any time t, and any selected points (x1, . . . , xt) and query point x.\nThis assumption has been used in several previous works based on Gaussian processes, and sufficient conditions for its validity can be found in [18, Sec. 8]. We now state the following general guarantee. Theorem 3.1. Fix > 0 and \u03b4 \u2208 (0, 1), and suppose there exist values {C(i)} and {\u03b2(i)} such that\nC(i) \u2265 C\u2217 ( \u03b7(i)\n\u03b2 1/2 (i)\n,M (i\u22121)\n) log |M (i\u22121)|\u03b2(i)\n\u03b4 2 \u03b72(i)\n+ cmax, (13)\nand\n\u03b2(i) \u2265 2 log |D| (\u2211 i\u2032\u2264i C(i\u2032) )2 \u03c02\n6\u03b4c2min . (14)\nThen if TRUVAR is run with these choices of \u03b2(i) until the cumulative cost reaches C = \u2211\ni : 4(1+\u03b4)\u03b7(i\u22121)>\nC(i), (15)\nthen with probability at least 1\u2212 \u03b4, we have -accuracy.\nWhile this theorem is somewhat abstract, it captures the fact that the algorithm improves when points having a lower cost and/or lower noise are available, since both of these lead to a smaller value of C\u2217(\u03be,M); the former by directly incurring a smaller cost, and the latter by shrinking the variance more rapidly. Below, we apply this result to some important cases."}, {"heading": "3.2 Results for Specific Settings", "text": "Homoscedastic and unit-cost setting: Define the maximum mutual information [3]\n\u03b3T = max x1,...,xT\n1 2 log det\n( IT + \u03c3 \u22122KT ) , (16)\nand consider the case that \u03c32(x) = \u03c32 and c(x) = 1. In the supplementary material, we provide a theorem with a condition for -accuracy of the form T \u2265 \u2126\u2217 ( C1\u03b3T \u03b2T 2 + 1 )\nwith C1 = 1log(1+\u03c3\u22122) , thus matching [2, 4] up to logarithmic factors. In the following, we present a refined version that has a significantly better dependence on the noise level, thus exemplifying that a more careful analysis of (13) can provide improvements over the standard bounding techniques.\nCorollary 3.1. Fix > 0 and \u03b4 \u2208 (0, 1), define \u03b2T = 2 log |D|T 2\u03c02 6\u03b4 , and set \u03b7(1) = 1 and r = 1 2 . There exist choices of \u03b2(i) (not depending on the time horizon T ) such that we have -accuracy with probability at least 1\u2212 \u03b4 once the following condition holds:\nT \u2265 ( 2\u03c32\u03b3T\u03b2T 96(1 + \u03b4)2\n2 + C1\u03b3T\u03b2T\n6(1 + \u03b4)2 \u03c32 + 2 \u2308 log2 32(1 + \u03b4)2 \u03c3 \u2309) log 16(1 + \u03b4)2|D|\u03b2T \u03b4 2 2 ,\n(17) where C1 = 1log(1+\u03c3\u22122) . This condition is of the form T \u2265 \u2126 \u2217(\u03c32\u03b3T \u03b2T 2 + C1\u03b3T \u03b2T \u03c32 + 1 ) .\nThe choices \u03b7(1) = 1 and r = 12 are made for mathematical convenience, and a similar result follows for any other choices \u03b7(1) > 0 and r \u2208 (0, 1), possibly with different constant factors.\nAs \u03c32 \u2192\u221e (i.e., high noise), both of the above-mentioned bounds have noise dependence O\u2217(\u03c32), since log(1 + \u03b1\u22121) = O(\u03b1\u22121) as \u03b1 \u2192 \u221e. On the other hand, as \u03c32 \u2192 0 (i.e., low noise), C1 is logarithmic, and Corollary 3.1 is significantly better provided that \u03c3. Choosing the noise and cost: Here we consider the setting that there is a domain of points D0 that the reward function depends on, and alongside each point we can choose a noise variance \u03c32(k) (k = 1, . . . ,K). Hence,D = D0\u00d7{1, \u00b7 \u00b7 \u00b7 ,K}. Lower noise variances incur a higher cost according to a cost function c(k).\nCorollary 3.2. For each k = 1, \u00b7 \u00b7 \u00b7 ,K, let T \u2217(k) denote the smallest value of T such that (17) holds with \u03c32(k) in place of \u03c32, and with \u03b2T = 2 log\n|D|T 2c2max\u03c02 6\u03b4c2min\n. Then, under the preceding setting, there exist choices of \u03b2(i) (not depending on T ) such that we have -accuracy with probability at least 1\u2212\u03b4 once the cumulative cost reaches mink c(k)T \u2217(k).\nThis result roughly states that we obtain a bound as good as that obtained by sticking to any fixed choice of noise level. In other words, every choice of noise (and corresponding cost) corresponds to a different version of a BO or LSE algorithm (e.g., [2, 4]), and our algorithm has a similar performance guarantee to the best among all of those. This is potentially useful in avoiding the need for running an algorithm once per noise level and then choosing the best-performing one. Moreover, we found numerically that beyond matching the best fixed noise strategy, we can strictly improve over it by mixing the noise levels; see Section 4."}, {"heading": "4 Experimental Results", "text": "We evaluate our algorithm in both the level-set estimation and Bayesian optimization settings.\nParameter choices: As with previous GP-based algorithms that use confidence bounds, our theoretical choice of \u03b2(i) in TRUVAR is typically overly conservative. Therefore, instead of using (14) directly, we use a more aggressive variant with similar dependence on the domain size and time: \u03b2(i) = a log(|D|t2(i)), where t(i) is the time at which the epoch starts, and a is a constant. Instead of the choice a = 2 dictated by (14), we set a = 0.5 for BO to avoid over-exploration. We found exploration to be slightly more beneficial for LSE, and hence set a = 1 for this setting. We found TRUVAR to be quite robust with respect to the choices of the remaining parameters, and simply set \u03b7(1) = 1, r = 0.1, and \u03b4 = 0 in all experiments; while our theory assumes \u03b4 > 0, in practice there is negligible difference between choosing zero and a small positive value.\nLevel-set estimation: For the LSE experiments, we use a common classification rule in all algorithms, classifying the points according to the posterior mean as H\u0302t = {x : \u00b5t(x) \u2265 h} and L\u0302t = {x : \u00b5t(x) < h}. The classification accuracy is measured by the F1-score (i.e., the harmonic mean of precision and recall) with respect to the true super- and sub-level sets.\nWe compare TRUVAR against the GP-based LSE algorithm [2], which we name via the authors\u2019 surnames as GCHK, as well as the state-of-the-art straddle (STR) heuristic [7] and the maximum variance rule (VAR) [2]. Descriptions can be found in the supplementary material. GCHK includes an exploration constant \u03b2t, and we follow the recommendation in [2] of setting \u03b2 1/2 t = 3.\nLake data (unit cost): We begin with a data set from the domain of environmental monitoring of inland waters, consisting of 2024 in situ measurements of chlorophyll concentration within a vertical transect plane, collected by an autonomous surface vessel in Lake Zu\u0308rich [19]. As in [2], our goal is to detect regions of high concentration. We evaluate each algorithm on a 50 \u00d7 50 grid of points, with the corresponding values coming from the GP posterior that was derived using the original data (see Figure 2d). We use the Mate\u0301rn-5/2 ARD kernel, setting its hyperparameters by maximizing the likelihood on the second (smaller) available dataset. The level-set threshold h is set to 1.5.\nIn Figure 2a, we show the performance of the algorithms averaged over 100 different runs; here the randomness is only with respect to the starting point, as we are in the noiseless setting. We observe that in this unit-cost case, TRUVAR performs similarly to GCHK and STR. All three methods outperform VAR, which is good for global exploration but less suited to level-set estimation.\nLake data (varying cost): Next, we modify the above setting by introducing pointwise costs that are a function of the previous sampled point x\u2032, namely, cx\u2032(x) = 0.25|x1 \u2212 x\u20321| + 4(|x2| + 1), where x1 is the vessel position and x2 is the depth. Although we did not permit such a dependence on x\u2032 in our original setup, the algorithm itself remains unchanged. Our choice of cost penalizes the distance traveled |x1 \u2212 x\u20321|, as well as the depth of the measurement |x2|. Since incorporating costs into existing algorithms is non-trivial, we only compare against the original version of GCHK that ignores costs.\nIn Figure 2b, we see that TruVaR significantly outperforms GCHK, achieving a higher F1 score for a significantly smaller cost. The intuition behind this can be seen in Figures 2e and 2f, where we show the points sampled by TruVaR and GCHK in one experiment run, connecting all pairs of consecutive points. GCHK is designed to pick few points, but since it ignores costs, the distance traveled is large. In contrast, by incorporating costs, TRUVAR tends to travel small distances, often even staying in the same x1 location to take measurements at multiple depths x2.\nSynthetic data with multiple noise levels: In this experiment, we demonstrate Corollary 3.2 by considering the setting in which the algorithm can choose the sampling noise variance and incur the associated cost. We use a synthetic function sampled from a GP on a 50\u00d7 50 grid with an isotropic squared exponential kernel having length scale l = 0.1 and unit variance, and set h = 2.25. We use three different noise levels, \u03c32 \u2208 {10\u22126, 10\u22123, 0.05}, with corresponding costs {15, 10, 2}. We run GCHK separately for each of the three noise levels, while running TRUVAR as normal and allowing it to mix between the noise levels. The resulting F1-scores are shown in Figure 2c. The best-performing version of GCHK changes throughout the time horizon, while TRUVAR is consistently better than all three. A discussion on how TRUVAR mixes between the noise levels can be found in the supplementary material.\nBayesian optimization. We now provide the results of two experiments for the BO setting.\nSynthetic data: We first conduct a similar experiment as that in [8, 11], generating 200 different test functions defined on [0, 1]2. To generate a single test function, 200 points are chosen uniformly at random from [0, 1]2, their function values are generated from a GP using an isotropic squared exponential kernel with length scale l = 0.1 and unit variance, and the resulting posterior mean forms the function on the whole domain [0, 1]2. We subsequently assume that samples of this function are corrupted by Gaussian noise with \u03c32 = 10\u22126. The extension of TRUVAR to continuous domains is straightforward, and is explained in the supplementary material. For all algorithms considered, we evaluate the performance according to the regret of a single reported point, namely, the one having the highest posterior mean.\nWe compare the performance of TRUVAR against expected improvement (EI), GP-upper confidence bound (GP-UCB), entropy search (ES) and minimum regret search (MRS), whose acquisition functions are outlined in the supplementary material. We use publicly available code for ES and MRS [20]. The exploration parameter \u03b2t in GP-UCB is set according to the recommendation in [3] of dividing the theoretical value by five, and the parameters for ES and MRS are set according to the recommendations given in [11, Section 5.1].\nFigure 3a plots the median of the regret, and Figure 3b plots the mean after removing outliers (i.e., the best and worst 5% of the runs). In the earlier rounds, ES and MRS provide the best performance, while TRUVAR improves slowly due to exploration. However, the regret of TRUVAR subsequently drops rapidly, giving the best performance in the later rounds after \u201czooming in\u201d towards the maximum. GP-UCB generally performs well with the aggressive choice of \u03b2t, despite previous works\u2019 experiments revealing it to perform poorly with the theoretical value.\nHyperparameter tuning data: In this experiment, we use the SVM on grid dataset, previously used in [21]. A 25\u00d7 14\u00d7 4 grid of hyperparameter configurations resulting in 1400 data points was preevaluated, forming the search space. The goal is to find a configuration with small validation error. We use a Mate\u0301rn-5/2 ARD kernel, and re-learn its hyperparameters by maximizing the likelihood after sampling every 3 points. Since the hyperparameters are not fixed in advance, we replace Mt\u22121 by D in (5) to avoid incorrectly ruling points out early on, allowing some removed points to be added again in later steps. Once the estimated hyperparameters stop to vary significantly, the size of the set of potential maximizers decreases almost monotonically. Since we consider the noiseless setting here, we measure performance using the simple regret, i.e., the best point found so far.\nWe again average over 100 random starting points, and plot the resulting validation error in Figure 3c. Even in this noiseless and unit-cost setting that EI and GP-UCB are suited to, we find that TRUVAR performs slightly better, giving a better validation error with smaller error bars."}, {"heading": "5 Conclusion", "text": "We highlight the following aspects in which TRUVAR is versatile:\n\u2022 Unified optimization and level-set estimation: These are typically treated separately, whereas TRUVAR and its theoretical guarantees are essentially identical in both cases\n\u2022 Actions with costs: TRUVAR naturally favors cost-effective points, as this is directly incorporated into the acquisition function.\n\u2022 Heteroscedastic noise: TRUVAR chooses points that effectively shrink the variance of other points, thus directly taking advantage of situations in which some points are noisier than others.\n\u2022 Choosing the noise level: We provided novel theoretical guarantees for the case that the algorithm can choose both a point and a noise level, cf., Corollary 3.2.\nHence, TRUVAR directly handles several important aspects that are non-trivial to incorporate into myopic algorithms. Moreover, compared to other BO algorithms that perform a lookahead (e.g., ES and MRS), TRUVAR avoids the computationally expensive task of averaging over the posterior and/or measurements, and comes with rigorous theoretical guarantees.\nAcknowledgment: This work was supported in part by the European Commission under Grant ERC Future Proof, SNF Sinergia project CRSII2-147633, SNF 200021-146750, and EPFL Fellows Horizon2020 grant 665667."}, {"heading": "B Further Details of Numerical Experiments", "text": "Other algorithms considered: We outline the algorithms that TRUVAR is compared against; full details can be found in the cited papers. For level-set estimation, we have the following:\n\u2022 The GCHK algorithm [2] evaluates, at each iteration, the point that is not yet classified with the largest ambiguity: xt = arg maxx\u2208Mt\u22121 min{ut(x) \u2212 h, h \u2212 `t(x)}, where ut and `t are defined as in (4) with a parameter \u03b2t replacing \u03b2(i). Here, similarly to our algorithm, Mt\u22121 is the set of points that have not yet been classified as having a value above or below the threshold h.\n\u2022 The straddle (STR) heuristic [7] chooses xt = arg maxx\u2208D 1.96\u03c3t\u22121(x)\u2212 |\u00b5t\u22121(x)\u2212 h|, favoring high-uncertainty points that are expected to have function values closer to h.\n\u2022 The maximum variance rule (VAR) [2] simply chooses xt = arg maxx\u2208D \u03c3t\u22121(x).\nFor Bayesian optimization, we have the following:\n\u2022 The expected improvement (EI) algorithm [1] chooses xt = arg maxx\u2208D Et[(f(x) \u2212 \u03bet)1{f(x) > \u03bet}], where Et[\u00b7] denotes averaging with respect to the posterior distribution at time t, and \u03bet is the best observed value so far. Since the posterior is Gaussian, the expectation can easily be expressed in closed form.\n\u2022 The Gaussian Process Upper Confidence Bound (GP-UCB) algorithm [3] chooses the points with the highest upper confidence bounds, xt = arg maxx\u2208D \u00b5t\u22121(x) +\u03b2t\u03c3t\u22121(x), where \u03b2t is a parameter controlling the level of exploration performed.\n\u2022 The Entropy Search (ES) algorithm can be interpreted as approximating the rule xt = arg minx\u2208D h(fx\u2217|t,x), where h(f) = \u222b D f(x) log 1f(x)dx denotes the differential entropy,\nand fx\u2217|t,x denotes the density function of the optimal action x\u2217 given the observations up to time t along with the additional observation x. Intuitively, this rule seeks to minimize the uncertainty of x\u2217. Since its exact evaluation is intractable, it is approximated using Monte Carlo techniques to average with respect to the posterior distribution and the measurements.\n\u2022 The Minimum Regret Search (MRS) algorithm [11] also resembles ES, but works with the expected regret instead of the differential entropy. Once again, Monte Carlo techniques are used to average with respect to the posterior distribution and the measurements.\nEfficiently computing the acquisition function: To compute the value of the acquisition function (3) for different x \u2208 D, we need to compute \u03c32t\u22121|x(Mt\u22121) \u2208 R\n|Mt\u22121|, i.e., the posterior variance of points in Mt\u22121 upon observing x along with x1, \u00b7 \u00b7 \u00b7 , xt\u22121. Instead of computing it directly, it is more efficient to recursively compute \u03c32t\u22121|x(Mt\u22121) = \u03c3 2 t\u22121(Mt\u22121)\u2212\u2206t\u22121|x(Mt\u22121). The difference term, \u2206t\u22121|x(Mt\u22121), can be computed as [8]:\n\u2206t\u22121|x(Mt\u22121) = diag ( Covt\u22121(Mt\u22121, x)(\u03c32 + \u03c32t\u22121(x)) \u22121Covt\u22121(Mt\u22121, x)T ) , (18)\nwhere\n\u03c32t\u22121(x) = k(x, x)\u2212 kt\u22121(x)T ( Kt\u22121 + \u03a3t\u22121 )\u22121 kt\u22121(x) (19)\nCovt\u22121(Mt\u22121, x) = k(Mt\u22121, x)\u2212 kt\u22121(Mt\u22121)T ( Kt\u22121 + \u03a3t\u22121 )\u22121 kt\u22121(x), (20)\nand where k(Mt\u22121, x) = [ k(x, x) ] x\u2208|Mt\u22121| \u2208 R\n|Mt\u22121|, and kt\u22121(Mt\u22121) =[ k(x, x) ] x\u2208|Mt\u22121|,x\u2208{1,...,t\u22121} \u2208 R |Mt\u22121|\u00d7(t\u22121). When the Cholesky decomposition of\nKt\u22121 + \u03a3t\u22121 is known, ( Kt\u22121 + \u03a3t\u22121 )\u22121 kt\u22121(x) can be computed in time O(t2).\nDetails on LSE experiment with multiple noise levels: Figure 4a plots the randomly-generated function that was used in this experiment. Figure 4b plots the average cost spent by TRUVAR on each noise level by the end of the experiment, again averaged over 100 trials. We see that the cost is roughly equally distributed across the three levels. To be more specific, we observed that TRUVAR initially chooses high noise levels in order to cheaply explore, and throughout the course of the experiments, it gradually switches to lower noise levels in order to accurately determine the function values around the maximum. This is consistent with the behavior of the three version of GCHK, with \u03c32 = 0.05 performing well in the early stages, but \u03c32 = 10\u22126 being preferable in the later stages.\nExtension of TRUVAR for synthetic BO experiment We used the extension of TRUVAR to continuous domains outlined in Appendix A, approximating the integrals over Mt by summations that are restricted to points on a uniformly-spaced 50 \u00d7 50 grid covering [0, 1]2. We optimized our acquisition function using DIRECT [23]."}, {"heading": "C Proof of General Result (Theorem 3.1)", "text": "We begin with the following lemma from [3].\nLemma C.1. [3] For each t, define \u03b2t = 2 log |D|t 2\u03c02\n6\u03b4 . With probability at least 1\u2212 \u03b4, we have for all x and t that |f(x)\u2212 \u00b5t(x)| \u2264 \u03b21/2t \u03c3t(x).\nWe conclude that in order for \u00b5t(\u00b7) \u00b1 \u03b21/2(i) \u03c3t(\u00b7) to provide valid confidence bounds, it suffices to ensure that \u03b2(i) \u2265 \u03b2t for all t in epoch i. From (14), we see that this is true provided that the time taken to reach the end of the i-th epoch is at most 1cmin \u2211 i\u2032\u2264i C(i\u2032). Since cmin is the minimum pointwise cost, this holds provided that the cost incurred in epoch i is at most C(i). The bulk of the proof is devoted to showing that this is the case.\nWe connect TRUVAR with the following budgeted submodular covering problem:2\nminimizeS c(S) subject to gt(S) = gt,max, (21)\nwhere\ngt(S) = \u2211\nx\u2208Mt\u22121\nmax { \u03c32t\u22121(x), \u03b72(i)\n\u03b2(i)\n} \u2212 \u2211 x\u2208Mt\u22121 max { \u03c32t\u22121|S(x), \u03b72(i) \u03b2(i) } , (22)\nand where gt,max is the highest possible value of gt(S) over arbitrarily large S, i.e., it is the value obtained once all of the summands in the second summation in (22) have saturated to \u03b72(i) \u03b2(i) :\ngt,max = \u2211\nx\u2208Mt\u22121\n( max { \u03c32t\u22121(x), \u03b72(i)\n\u03b2(i)\n} \u2212 \u03b72(i)\n\u03b2(i)\n) (23)\n= \u2211\nx\u2208Mt\u22121\nmax { 0, \u03c32t\u22121(x)\u2212 \u03b72(i)\n\u03b2(i)\n} . (24)\nWe thus refer to gt,max as the excess variance; see Figure 5 for an illustration. Note that each time instant t corresponds to a different function gt(S), and we are considering sets S of an arbitrary size even though our algorithm only chooses one point at each time instant.\n2Recall that S may contain duplicates, and these are counted multiple times accordingly in the definitions of both c(S) and gt(S). All of our equations can be cast in terms of standard sets (without duplicates) by expanding D to D \u00d7 {1, \u00b7 \u00b7 \u00b7 , N} for any integer N that is larger than the maximum number of points that are chosen throughout the course of the algorithm.\nBy our assumption on the submodularity of the variance reduction function, and the fact that taking the minimum with a constant3 preserves submodularity [17], gt(S) is also submodular. It is also easily seen to be monotonically increasing, and normalized in the sense that gt(\u2205) = 0. Our selection rule (3) at time t can now be interpreted as the first step in a greedy algorithm for solving the budgeted submodular optimization problem (21); specifically, the greedy rule optimizes the objective value per unit cost. To obtain performance guarantees, we use Lemma 2 of [24] specialized to |S| = 1, which reads as follows in our own notation:\ngt({xt}) \u2265 c(xt)\nc(S\u2217t ) gt,max, (25)\nwhere S\u2217t is an optimal solution to (21), and hence gt(S \u2217) = gt,max. Here xt is the point chosen greedily by our algorithm.\nWe now consider the behavior of the excess variance gt,max in a single epoch, i.e., the duration of a single value of i in the algorithm. We claim that for t and t+ 1 in the same epoch, we have\ngt+1,max \u2264 gt,max \u2212 gt({xt}). (26) To see this, we note from (22)\u2013(23) that this would hold with equality if we were to have Mt = Mt\u22121, since by definition we have \u03c32t (x) = \u03c3 2 t\u22121|{xt}(x). We therefore obtain (26) by recalling that Mt is decreasing in t with respect to inclusion, and noting from (24) that any given gt,max can only decrease when Mt\u22121 is smaller.\nCombining (25)\u2013(26) gives\ngt+1,max \u2264 (\n1\u2212 c(xt) c(S\u2217t )\n) gt,max. (27)\nWe also note that c(S\u2217t+1) \u2264 c(S\u2217t ), which follows since \u03c32t (\u00b7) is decreasing in t and Mt is shrinking in t, and therefore at time t + 1 a smaller cost is required to ensure that all terms in the second summation of (22) have saturated to \u03b72(i) \u03b2(i)\n. Hence, and applying (27) recursively, we obtain for t and t+ ` in the same epoch that\ngt+`,max gt,max\n\u2264 t+\u220f\u0300\nt\u2032=t+1\n( 1\u2212 c(xt \u2032)\nc(S\u2217t )\n) (28)\n\u2264 exp ( \u2212 \u2211t+` t\u2032=t+1 c(xt\u2032)\nc(S\u2217t )\n) , (29)\nwhere we have applied the inequality 1 \u2212 \u03b1 \u2264 e\u2212\u03b1. Moreover, the total cost incurred by choosing these points is precisely \u2211t+` t\u2032=t+1 c(xt). Thus, letting t(i) be the first time index in the i-th epoch, we find that in order to remove all but a proportion \u03b3 of the initial excess variance gt(i),max, it suffices that the cost incurred is at least\nc(S\u2217t(i)) log 1\n\u03b3 . (30)\n3The minimum becomes a maximum after negation.\nNext, we observe that since the posterior variance is upper bounded by one due to the assumption k(x, x) = 1, the initial excess variance gt(i),max is upper bounded by gt(i),max \u2264 |Mt(i)\u22121|, the size of the set of potential maximizers at the start of the epoch. It follows that if we set\n\u03b3 = \u03b4 2 \u03b72(i)\n\u03b2(i)|Mt(i)\u22121| , (31)\nthen removing all but a proportion \u03b3 of gt(i),max also implies removing all but \u03b4 2 \u03b72(i) \u03b2(i)\nof it. In other words, if at time t we have incurred a cost in epoch i satisfying (30) with \u03b3 as in (31), then we must have gt,max \u2264 \u03b4 2 \u03b72(i) \u03b2(i) .\nRemoving all of the excess variance would imply \u03b7(i)-confidence at all points in Mt. In the worst case, the remaining excess variance \u03b4 2 \u03b72(i) \u03b2(i) is concentrated entirely on a single point, in which case\nits confidence is upper bounded by \u221a 1 + \u03b4 2 \u03b7(i), which is further upper bounded by (1 + \u03b4)\u03b7(i) due to the identity \u221a\n1 + \u03b12 \u2264 1 + \u03b1. Combining these observations, we conclude that in the i-th epoch, upon incurring a cost of at least\nc(S\u2217t(i)) log |Mt(i)\u22121|\u03b2(i)\n\u03b4 2 \u03b72(i)\n, (32)\nwe are guaranteed to have (1 + \u03b4)\u03b7(i)-confidence for all points in Mt. Having such confidence is precisely the condition used in the algorithm to move onto the next epoch, and we conclude that the epoch must end by (or sooner than) the time that (32) holds.\nIn accordance with the discussion following Lemma C.1, we need to show that when the highprobability event in that lemma holds true, (32) is upper bounded by the right-hand side of (13) for all epochs. We do this via an induction argument on the epoch number:\n\u2022 As a base case, recalling that M0 = M(0) = D, we find that (32) and (13) coincide, with the addition of cmax arising since once (32) is exceeded, it may be exceeded by any amount up to cmax.\n\u2022 Fix an epoch number i > 1, and suppose that for all i\u2032 < i, the cost incurred in epoch i\u2032 was at most C\u2217 ( \u03b7(i\u2032) \u03b2 1/2\n(i\u2032)\n,M (i\u2032\u22121) ) log |M(i\u2032\u22121)|\u03b2(i\u2032)\n\u03b4 2 \u03b72 (i\u2032)\n+ cmax. By the choice of \u03b2(i\u2032) in (14), we find that under the event in Lemma C.1, the confidence bounds \u00b5t \u00b1 \u221a \u03b2(i\u2032)\u03c3t must have been valid for all t in the epochs i\u2032 < i, and hence M (i\u22121) \u2286Mt(i)\u22121 (cf., (9)\u2013(10)). From this, we claim that an analogous argument to the base case implies that (32) is upper bounded by the right-hand side of (13), as required. The only additional argument compared to the base case is noting that c(S\u2217t(i)) defines the minimum cost to uniformly shrink the posterior standard deviation within Mt(i)\u22121 down to \u03b72(i) \u03b2(i) after already having chosen x1, . . . , xt(i)\u22121,\nwhereas C\u2217 ( \u03b7(i) \u03b2 1/2\n(i)\n,M (i\u22121) ) is defined analogously for the set M (i\u22121) with no previously-chosen\npoints. The latter clearly upper bounds the former.\nFinally, we check the conditions for -accuracy in Definition 3.1. In the case of BO, summing (13) over all of the epochs such that 4(1 + \u03b4)\u03b7(i\u22121) > yields (15); recall from (9) that after any epoch i such that 4(1 + \u03b4)\u03b7(i) \u2264 , all points are at most -suboptimal. We also note that all true maxima must remain in Mt, due to the fact that we showed \u03b2(i) yields valid confidence bounds with high probability, and we only ever discard points that are deemed suboptimal according to those bounds. For LSE, a similar conclusion follows from (10) by summing over all epochs such that"}, {"heading": "2(1 + \u03b4)\u03b7(i\u22121) >", "text": "2 , which is the same as 4(1 + \u03b4)\u03b7(i\u22121) > . Once again, all points in Ht and Lt are correct due to the validity of our confidence bounds."}, {"heading": "D Simplified Result for the Homoscedastic and Unit-Cost Setting", "text": "Since we are focusing on unit costs c(x) = 1, the cost simply corresponds to the number of rounds T . To highlight this fact, we replace C\u2217 in (11) by\nT \u2217(\u03be,M) = min S\n{ |S| : max\nx\u2208M \u03c30|S(x) \u2264 \u03be\n} , (33)\nand similarly replace (34)\u2013(36) by T(i) \u2265 T \u2217 ( \u03b7(i)\n\u03b2 1/2 (i)\n,M (i\u22121)\n) log |M (i\u22121)|\u03b2(i)\n\u03b4 2 \u03b72(i)\n+ 1 (34)\n\u03b2(i) \u2265 2 log |M (i\u22121)|\n(\u2211 i\u2032\u2264i T(i\u2032) )2 \u03c02\n6\u03b4 (35) T = \u2211\ni : 4(1+\u03b4)\u03b7(i\u22121)>\nT(i). (36)\nIn this section, we prove the following as an application of Theorem 3.1.\nCorollary D.1. Fix > 0 and \u03b4 \u2208 (0, 1), define \u03b2T = 2 log |D|T 2\u03c02 6\u03b4 , and set \u03b7(1) = 1 and r = 1 2 . There exist choices of \u03b2(i) (not depending on the time horizon T ) such that we have -accuracy with probability at least 1\u2212 \u03b4 once the following condition holds:\nT \u2265 ( C1\u03b3T\u03b2T 96(1 + \u03b4)2 2 + 2 \u2308 log2 8(1 + \u03b4) \u2309) log\n16(1 + \u03b4)2|D|\u03b2T \u03b4 2 2 , (37)\nwhere C1 = 1log(1+\u03c3\u22122) . This condition is of the form T \u2265 \u2126 \u2217(C1\u03b3T \u03b2T 2 + 1 ) .\nWe bound the cardinality of S in (33) by considering a procedure that greedily picks arg maxx\u2208M \u03c3t(x). We claim that after selecting k points according to this procedure to construct a set Sk, we have\nmax x \u03c320|Sk(x) \u2264 C1 \u03b3k k , (38)\nwhere C1 = 1log(1+\u03c3\u22122) . This is seen by writing\nkmax x\u2208M\n\u03c320|Sk(x) = k\u03c3 2 0|Sk(xk) (39)\n\u2264 k\u2211 j=1 \u03c320|Sj (xj) (40)\n\u2264 1 log(1 + \u03c3\u22122) \u03b3k, (41)\nwhere we respectively used that xk maximizes \u03c30|Sk , that \u03c30|Si(xi) always decreases as more points are chosen, and the bound on the sum of variances of sampled points from [3, Lemma 5.4].\nIdentifying k with T \u2217, and maxx\u2208M \u03c30|Sk(x) with \u03be = \u03b7 \u03b21/2 (for some \u03b7 and \u03b2 to be specified), we obtain from (41) that\nT \u2217 ( \u03b7\n\u03b21/2 ,M\n) \u2264 min { T \u2217 : T \u2217 \u2265 C1\u03b3T \u2217\u03b2\n\u03b72\n} . (42)\nConsider the value T \u2217 ( \u03b7(i) \u03b2 1/2\n(i)\n,M (i\u22121) ) corresponding to the parameters \u03b7 = \u03b7(i) and \u03b2 = \u03b2(i)\nassociated with epoch i. Letting T = T denote the total time horizon, and using (36), we find that \u03b2(i) in (35) can be upper bounded by 2 log |D|T 2\u03c02 6\u03b4 , which is precisely \u03b2T . By similarly using the monotonicity of \u03b3t, we obtain\nT \u2217 ( \u03b7(i)\n\u03b2 1/2 (i)\n,M (i\u22121)\n) \u2264 C1\u03b3T\u03b2T\n\u03b72(i) + 1, (43)\nwhere the addition of one is to account for possible rounding up to the nearest integer.\nUsing (43), we find that in order for (34) to hold it suffices that T(i) \u2265 ( C1\u03b3T\u03b2T \u03b72(i) + 1 ) log |M (i\u22121)|\u03b2(i)\n\u03b4 2 \u03b72(i)\n+ 1. (44)\nSince we are only considering values of i such that 4(1 + \u03b4)\u03b7(i\u22121) > , and since M (i\u22121) \u2286 D, we can upper bound the logarithm by log 16(1+\u03b4)\n2|D|\u03b2(i) \u03b4 2 2\n> 1, and hence in order for (44) to hold it suffices that T(i) \u2265 ( C1\u03b3T\u03b2T \u03b72(i) + 2 ) log 16(1 + \u03b4)2|D|\u03b2T \u03b4 2 2 . (45)\nWe also note that since \u03b7(i) = \u03b7(1)ri\u22121, the condition 4(1 + \u03b4)\u03b7(i\u22121) > is equivalent to\n4(1 + \u03b4)\u03b7(1)r i\u22122 > (46)\n\u21d0\u21d2 ri\u22122 > 4(1 + \u03b4)\u03b7(1)\n(47)\n\u21d0\u21d2 i < 2 + log1/r 4(1 + \u03b4)\u03b7(1)\n(48)\n\u21d0\u21d2 i \u2264 \u2308 log1/r 4(1 + \u03b4)\u03b7(1) \u2309 + 1 (49)\n\u21d0\u21d2 i \u2264 \u2308 log1/r 4(1 + \u03b4)\u03b7(1)\nr\n\u2309 , (50)\nwhere in the last line we used log1/r 1 r = 1. Summing (45) over all such i in accordance with (36), we obtain following sufficient condition on the time horizon for -accuracy:\nT \u2265 ( C1\u03b3T\u03b2T dlog1/r 4(1+\u03b4)\u03b7(1) e+1\u2211 i=1 1 \u03b72(i) + 2 \u2308 log1/r 4(1 + \u03b4)\u03b7(1) r \u2309) log 16(1 + \u03b4)2|D|\u03b2T \u03b4 2 2 . (51)\nFinally, we weaken this condition by upper bounding the summation as follows:\ndlog1/r 4(1+\u03b4)\u03b7(1) e+1\u2211 i=1 1 \u03b72(i) = dlog1/r 4(1+\u03b4)\u03b7(1) e+1\u2211 i=1\n1\n\u03b72(1)r 2(i\u22121) (52)\n=\ndlog1/r 4(1+\u03b4)\u03b7(1) e\u2211 i=0 1 \u03b72(1)r 2i\n(53)\n\u2264 1 r2(1\u2212 r2)\n16(1 + \u03b4)2\n2 , (54)\nwhere the last line follows from the identity \u2211dlog1/r Ae i=0 1 r2i \u2264 1 r2(1\u2212r2)A\n2 for log1/r A > 0. Substituting r = 12 and \u03b7(1) = 1 concludes the proof; the former yields 1 r2(1\u2212r2) = 16 3 \u2264 6."}, {"heading": "E Proof of Improved Noise Dependence (Corollary 3.1))", "text": "The bound in (41) is based on the inequality [3, Lemma 5.4]\n\u03c32t \u03c32 \u2264 C1 log\n( 1 +\n\u03c32t \u03c32\n) (55)\nfor \u03c32t \u2208 [0, 1] (with C1 = \u03c3 \u22122 log(1+\u03c3\u22122) ), which can be very loose when \u03c3 2 is small. Our starting point to improve the noise dependence is to note that the following holds under the more restrictive\ncondition \u03c32t \u2264 \u03c32:\n\u03c32t = \u03c3 2\u03c3\n2 t\n\u03c32 (56) \u2264 2\u03c32 log (\n1 + \u03c32t \u03c32\n) , (57)\nwhere we have used the fact that \u03b1 \u2264 2 log(1 + \u03b1) for \u03b1 \u2208 [0, 1]. The idea now is to use (57) in the epochs that are late enough so that \u03c32t \u2264 \u03c32, and (41) in the earlier epochs. Since (1 + \u03b4)\u03b7(i) is the confidence level obtained after epoch i, and since \u03b2 1/2 (i) \u03c3t is the confidence level after time t, we find that in order to ensure \u03c32t \u2264 \u03c32 it suffices that (1+\u03b4)2\u03b72(i) \u03b2(i) \u2264 \u03c32. Moreover, our choice of \u03b2(i) in (14) is always greater than one when |D| \u2265 2 (which is a trivial condition), and hence we can weaken this condition to (1 + \u03b4)2\u03b72(i) \u2264 \u03c3\n2, and write\u2211 i T(i) \u2264 \u2211\ni : (1+\u03b4)2\u03b72 (i\u22121)>\u03c3 2\nT (C1) (i) + \u2211 i T (2\u03c32) (i) , (58)\nwhere T (C1)(i) denotes bound on T(i) in (45) based on (41), and T (C1) (i) denotes the analogous bound based on (57) with 2\u03c32 in place of C1. Similarly to (50), the first summation is over a subset of the range i \u2264 dlog1/r (1+\u03b4)\u03b7(1) r\u03c3 e, and it follows that the condition (51) may be replaced by\nT \u2265 ( 2\u03c32\u03b3T\u03b2T dlog1/r 4(1+\u03b4)\u03b7(1) e+1\u2211 i=1 1 \u03b72(i) + 2 \u2308 log1/r 4(1 + \u03b4)\u03b7(1) r \u2309) log 16(1 + \u03b4)2|D|\u03b2T \u03b4 2 2\n+ ( C1\u03b3T\u03b2T dlog1/r (1+\u03b4)\u03b7(1) \u03c3 e+1\u2211 i=1 +2 \u2308 log1/r (1 + \u03b4)\u03b7(1) r\u03c3 \u2309) log 16(1 + \u03b4)2|D|\u03b2T \u03b4 2 2 . (59)\nThe first summation is handled in the same way as the previous subsection, and the second summation is upper bounded by writing\ndlog1/r (1+\u03b4)\u03b7(1) \u03c3 e+1\u2211 i=1 1 \u03b72(i) = dlog1/r (1+\u03b4)\u03b7(1) \u03c3 e+1\u2211 i=1\n1\n\u03b72(1)r 2(i\u22121) (60)\n\u2264 (1 + \u03b4) 2 r2(1\u2212 r2) 1 \u03c32 , (61)\nwhere (60) follows since \u03b7(i) = \u03b7(1)ri\u22121, and (61) follows in the same way as (54). Once again, setting r = 12 and \u03b7(1) = 1 concludes the proof, with the third term in (17) coming from the identity\n2 \u2308\nlog2 8(1+\u03b4)\n\u2309 + 2 \u2308\nlog2 2(1+\u03b4) \u03c3\n\u2309 \u2264 2 \u2308 log2 32(1+\u03b4)2\n\u03c3\n\u2309 ."}, {"heading": "F Proof for the Setting of Choosing Noise (Corollary 3.2)", "text": "The proof follows the same arguments as those of Appendices D and E, with C\u2217 being upper bounded in K different ways, one for each possible noise level. The choice \u03b2T = 2 log\n|D|T 2c2max\u03c02 6\u03b4c2min\narises as a simple upper bound to the right-hand side of (14) resulting from the fact that\u2211T t=1 c(xt) \u2264 cmaxT ."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "We present a new algorithm, truncated variance reduction (TRUVAR), that treats<lb>Bayesian optimization (BO) and level-set estimation (LSE) with Gaussian pro-<lb>cesses in a unified fashion. The algorithm greedily shrinks a sum of truncated<lb>variances within a set of potential maximizers (BO) or unclassified points (LSE),<lb>which is updated based on confidence bounds. TRUVAR is effective in several<lb>important settings that are typically non-trivial to incorporate into myopic algo-<lb>rithms, including pointwise costs and heteroscedastic noise. We provide a general<lb>theoretical guarantee for TRUVAR covering these aspects, and use it to recover<lb>and strengthen existing results on BO and LSE. Moreover, we provide a new result<lb>for a setting where one can select from a number of noise levels having associated<lb>costs. We demonstrate the effectiveness of the algorithm on both synthetic and<lb>real-world data sets.", "creator": "LaTeX with hyperref package"}}}