{"id": "1611.00791", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Nov-2016", "title": "Predicting Domain Generation Algorithms with Long Short-Term Memory Networks", "abstract": "Various families of malware use domain generation algorithms (DGAs) to generate a large number of pseudo-random domain names to connect to a command and control (C&amp;C) server. In order to block DGA C&amp;C traffic, security organizations must first discover the algorithm by reverse engineering malware samples, then generating a list of domains for a given seed. The domains are then either preregistered or published in a DNS blacklist. This process is not only tedious, but can be readily circumvented by malware authors using a large number of seeds in algorithms with multivariate recurrence properties (e.g., banjori) or by using a dynamic list of seeds (e.g., bedep). Another technique to stop malware from using DGAs is to intercept DNS queries on a network and predict whether domains are DGA generated. Such a technique will alert network administrators to the presence of malware on their networks. In addition, if the predictor can also accurately predict the family of DGAs, then network administrators can also be alerted to the type of malware that is on their networks. This paper presents a DGA classifier that leverages long short-term memory (LSTM) networks to predict DGAs and their respective families without the need for a priori feature extraction. Results are significantly better than state-of-the-art techniques, providing 0.9993 area under the receiver operating characteristic curve for binary classification and a micro-averaged F1 score of 0.9906. In other terms, the LSTM technique can provide a 90% detection rate with a 1:10000 false positive (FP) rate---a twenty times FP improvement over comparable methods. Experiments in this paper are run on open datasets and code snippets are provided to reproduce the results.", "histories": [["v1", "Wed, 2 Nov 2016 20:34:56 GMT  (1055kb,D)", "http://arxiv.org/abs/1611.00791v1", null]], "reviews": [], "SUBJECTS": "cs.CR cs.AI", "authors": ["jonathan woodbridge", "hyrum s", "erson", "anjum ahuja", "daniel grant"], "accepted": false, "id": "1611.00791"}, "pdf": {"name": "1611.00791.pdf", "metadata": {"source": "CRF", "title": "Predicting Domain Generation Algorithms with Long Short-Term Memory Networks", "authors": ["Jonathan Woodbridge", "Hyrum S. Anderson", "Anjum Ahuja"], "emails": ["jwoodbridge@endgame.com", "hyrum@endgame.com", "aahuja@endgame.com", "dgrant@endgame.com"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nMany malware families contain domain generation algorithms (DGAs) to make preemptive defenses difficult. Domains are generated pseudo-randomly in bulk (hundreds to tens-ofthousands per day) by a malware sample. The malware then attempts to connect to all or a portion of these generated domains in hopes of finding a command and control (C2)\nserver from which it can update, upload gathered intelligence, or pursue other malicious activities. The malicious actor only needs to register a small number of these domains to be successful. However, all the domains must be sinkholed, registered, or blacklisted before they go into use in order to preemptively defeat such an attack. This defense becomes increasingly difficult as the rate of dynamically generated domains increases.\nAuthors in [1] presented a thorough review of the efficacy of blacklists. As a part of this review, authors analyzed both public and private blacklists for DGA coverage, (i.e., how many domains generated by DGAs were contained in blacklists). Public blacklists were surprisingly lacking in terms of DGA coverage with less than 1.2% of DGAs analyzed by the authors being contained in any of the blacklists. Vendor provided blacklists fared better, but had mixed results over malware families with coverage varying from 0% to 99.5%. These results suggest that blacklists are useful, but must be supplemented by other techniques to provide a more adequate level of protection.\nAnother approach to combating malware using DGAs is to build a DGA classifier. This classifier can live in the network sniffing out DNS requests and looking for DGAs. When DGAs are detected, the classifier notifies other automated tools or network administrators to further investigate the origin of a DGA. Previous work in DGA detection can be broken down into two categories: retrospective detection and real-time detection. Retrospective detection makes bulk predictions on large sets of domains and are designed as a reactionary system that cannot be used for real-time detection and prevention [2], [3], [4]. In these systems, sets of domains are broken down into groupings using clustering with the intent to generate statistical properties of each grouping. Classification is accomplished by generating templates during training and using statistical tests (e.g., Kullback-Leibler divergence) to classify groups of potential DGAs. In addition, these techniques incorporate contextual information such as HTTP headers, NXDomains across a network, and passive DNS to further improve performance. Much of the previous work in DGA detection falls in the former category and, unfortunately, does not meet the needs of many real-world security applications that require real-time detection and prevention [5]. In addition, it is often unrealistic for many security applications to use contextual information. For example, endpoint detection and response (EDR) systems run on endpoints and hosts and have strict performance requirements on processing, network, and memar X iv :1 61 1.\n00 79\n1v 1\n[ cs\n.C R\n] 2\nN ov\n2 01\n6\nory usage. Aggregating such contextual information from the network to each endpoint requires far too much overhead and is not practical for a real-world deployment.\nReal-time detection techniques attempts to classify domains as DGA generated on a per domain basis using only the domains\u2019 names (i.e., no additional contextual information). Real-time detection is a considerably harder problem than retrospective techniques and techniques often exhibit performance far too low for a real-world deployment. (Suprisingly, authors in [5] found that retropsective techniques had similarly bad performance!) Many of the previous real-time approaches use hand picked features (e.g., entropy, string length, vowel to consonant ratio, etc.) that are fed into a machine learning model, such as a random forest classifier. Using hand-crafted features have two major drawbacks. First, hand-crafted features are easy to circumvent. Second, deriving hand-crafted features is a time consuming process. If, and when, a malicious actor derives a new DGA family around beating a set of features, security professionals will need to spend considerable time creating new features. To the best of our knowledge, authors in [2] presented the first (and only until this paper) featureless real-time technique by using Hidden Markov Models (HMMs). However, as shown later in the paper, HMMs perform quite poorly on detecting DGAs. To note, the HMMs in [2] were part of a much larger retrospective detection system.\nThis paper presents a feature-less real-time technique using Long Short-Term Memory networks (LSTMs) to classify DGAs. This technique has four significant advantages over other techniques in the literature. First, the LSTM DGA classifier is featureless, in that it operates on raw domain names (e.g., google.com, facebook.com, etc.). If a new family of DGA appears, then the classifier can be retrained without the tedious step of hand picking features. LSTMs work largely as a black box making it very difficult for adversaries to reverse engineer and beat a classifier without the same training set. Second, the presented technique has a significantly better true positive rate/false positive rate over previously published retrospective and real-time approaches. Third, the technique also works in a multiclass classification setting. Therefore, the algorithm not only provides a binary decision of whether a domain is DGA or not, but can accurately fingerprint a unique DGA\u2019s structure. Fourth, the presented algorithm can classify in real-time using absolutely no contextual information. Classification of a domain takes 20ms on commodity hardware.1 The technique is trivial to implement and can run on virtually any security environment. In fact, all the code required to implement this system is provided in this paper demonstrating its ease of deployment.\nIn this paper, we make the following contributions. We\n1) introduce an LSTM network to predict DGA generated domains, which to our knowledge, is the first application and in-depth analysis of deep learning to this domain; 2) present complete experimental results showing significant improvements over previous techniques (both real-time and retrospective) in the literature using open datasets; and 3) provide source code to reproduce results.\n1Apple MacBook Pro with a 2.2 GHz Intel Core i7 and 16GB of memory\nTo allow for easily reproducible results, Python source code built on the open source framework Keras [6] is provided. Experiments were run on GPU hardware, but it\u2019s possible to run all experiments on commodity desktop or laptop hardware. An overview of LSTMs and previous work is discussed in Section II. Details of reproducing the results are given in Sections III and IV. Full results are given in Section V with suggestions for future work in Section VI."}, {"heading": "II. BACKGROUND", "text": "Domain fluxing is a technique used by botnets and command-and-control (C2) servers to create many domains using a Domain Generation Algorithm (DGA) [7], [8]. All botnets and C2 servers in the same infrastructure use the same seeded algorithm such that they all create the same pseudorandomly generated domains. A subset of these domains are registered by the C2 servers while each botnet iterates through the DGA generated domains until it finds one that is registered. To further complicate the process, C2 servers continually switch to new DGA generated domains making blacklist creation and take down efforts difficult.\nOne approach to combating domain fluxing is to reverse engineer a piece of malware and its respective DGA [8]. Once a DGA and its respective seed is known, future domains can be registered and used as an impostor C2 server to hijack botnets (a process known as sinkholing). Once a campaign has been hijacked, adversaries must redeploy new botnets with updated seeds to continue.\nBlacklisting is another approach to combat domain fluxing [1]. DGA generated domains are added to a blacklist that can be used by a network administrator to block connections to potential C2 servers. However, both blacklists and sinkholing are only effective when both the algorithm and seed used by a campaign is known."}, {"heading": "A. Domain Generation Algorithms", "text": "This paper evaluates the ability to classify DGA generated domains from 30 different types of malware. Malware families include ransomware, such as Cryptolocker [9], [10] and Cryptowall [11], banking trojans, such as Hesperbot [12], and general information-stealing tactics, such as ramnit [13].\nDGA techniques vary in complexity from simple uniformly generated domain names to those that attempt to model distributions that are seen in real domains. ramnit, for example, creates domains with a series of divides, multiplies and modulos computed on a seed [13] while suppobox creates domains by concatenating two random strings (typically taken from the English language) [14].\nPredicting DGA generated domains from such algorithms as suppobox is extremely difficult without using contextual information. In fact, the LSTM technique presented in this paper was the only real-time technique able to classify such domains."}, {"heading": "B. DGA Classification", "text": "DGA classification can be a useful component of a domain reputation system. Domain reputation systems have the task of\nassigning a trustworthy score of a domain. This score typically varies from 0 (most benign) to 1 (most malicious). Domain reputation systems typically incorporate many pieces of heterogeneous data, such as passive DNS (pDNS), to make decisions on a domain\u2019s reputation [15], [16], [17]. DGA classification is one piece of information that can help assign a reputation to a domain. Previous approaches to DGA classification can be roughly broken down into two categories:\n1) Retrospective: classifying domains in groups to take advantage of bulk statistical properties or common contextual information; and 2) Real-time: classifying domains individually with no additional contextual information.\nAuthors in [3], [4] detect DGAs by using both unigram and bigram statistics of domain clusters. The training set is separated into two subsets: those generated by a DGA and those not generated by a DGA. The distributions of both unigrams and bigrams are calculated for both the subsets. Classification occurs in batches. Each batch of unknown domains is clustered by shared second level domain and domains sharing the same IP address. The unigram and bigram distributions are calculated for each cluster and compared to the two known (labeled) subsets using the Kullback-Leibler (KL) distance. In addition, the authors use the Jaccard distance to compare bigrams between clusters and the known (labeled) sets as well.\nAuthors in [2] apply a similar clustering process to classify domains with unsuccessful DNS resolutions. To train, statistical features are calculated for each subset of labeled DGA generated domains, such as Bobax, Torpig, and Conficker.C. Unknown domains are clustered by statistical characteristics such as length, entropy, and character frequency distribution, as well as shared hosts requesting the domain (i.e., cluster two domains together if the same host made a DNS query for both domains). Next, statistical features are calculated for each cluster and compared to the training subsets to classify the clusters as formed by a known DGA. If a cluster is classified as belonging to a known DGA, the host is deemed to be infected.\nOnce a host is deemed to be infected with a DGA-bot, the authors attempt to identify the bots active C2 server. This stage of the process uses a Hidden Markov Model trained on each known family of DGA and applied to single domains (i.e., this technique follows the same assumptions as the LSTM technique proposed by this paper). Each domain with a successful DNS request is fed through each HMM. If a domain receives an adequate score (i.e., greater than some threshold \u03b8), the domain is labeled as a DGA. The threshold is learned at training time and set to a maximum false positive rate of 1%. We use this HMM technique as one of our comparisons to previous work.\nThe aforementioned techniques (with exception to the HMM technique in [2]) are accomplished retrospectively. Authors in [5] perform an in-depth comparison of these techniques and discuss two important findings. First, retrospective techniques are too slow for most real-world deployments and often take hours to detect malicious domains. Second, the performance of these systems are quite poor in terms of false positives and true positives. These authors present their own technique that overlaps both retrospective and real-time\ntechniques. They apply an online form of sequential hypothesis testing to NXDomains only. Clients in a network are given an evolving score based on the number and maliciousness of NXDomains. A client can be labeled as malicious or benign once its score goes above or below predefined thresholds. While this system is a big improvement over retrospective systems, it has three main drawbacks. First, detection is not always in real-time as a client takes time to build an appropriate score. Authors reported that only 83% of domains were detected in time to prevent a connection. Second, performance of their system is considerably less than most real-time solutions as we show in section V. Third, their system cannot perform multiclass classification as their system bases classification solely on the presence of NXDomains.\nAuthors in [18] present a real-time DGA classifier that uses two basic linguistic features named meaningful characters ratio and n-gram normality score. The meaningful characters ratio calculates the ratio of characters in a domain that comprise of a meaningful word. For example, facebook has a ratio of 1 as all character in the domain are covered by the words face and book while face1234 has a ratio of 0.5 as only half of its character are covered by the word face. The n-gram normality score is calculated by finding n-grams with n \u2208 1, 2, 3 within a domain and calculating their count in the English language. The mean and covariance of these four features are calculated from a benign set (Alexa top 100,000). Unknown domains are then classified by their Mahalanobis distance to the benign set (i.e. a larger distance is indicative of a DGA generated domain).\nThe approach in [18] is used as a filter step. Once domains have been classified as a DGA they are fed to a clustering technique (similar to those described above) to further classify the domains.\nSection V shows a comparison of our technique to both retrospective and real-time systems. Our technique significantly outperforms retrospective techniques and the comparison is brief and compares findings to those in [5]. An in depth comparison is performed between our technique and the aforementioned real-time systems. More specififcally, we compare our technique to the HMM defined by [2] as well as a Random Forest Classifier trained on features defined in [2], [3], [4], [18]. We do not perform an in depth comparison on the full systems as defined in [2], [3], [4] as they are retrospective systems and have already been shown to perform far worse than our system [5]."}, {"heading": "C. LSTM Networks", "text": "In a variety of natural language tasks, recurrent neural networks (RNNs) have been used to capture meaningful temporal relationships among tokens in a sequence [19], [20], [21], [22]. The key benefit of RNNs is that they incorporate contextual (state) information in their mapping from input to output. That is, the output of a single RNN cell is a function of the input layer and previous RNN activations. Due to long chains of operations that are introduced by including self-recurrent connections, the output of a traditional RNN may decay exponentially (or, more rarely but catastrophically explode) for a given input, leading to the well-known vanishing gradients problem. This makes learning long-term dependencies in an RNN difficult to achieve.\nThe problem of vanishing gradients is a key motivation behind the application of the Long Short-Term Memory (LSTM) cell [23], [24], [25], which consists of a state that can be read, written or reset via a set of programmable gates. The cell\u2019s state has a self-recurrent connection that allows the cell to exactly retain state between time steps. However, that state may be modulated by a new input via an input gate, which effectively multiplies the input by a number that ranges between 0 and 1 (sigmoid activation) or -1 and 1 (tanh activation). Likewise, a forget gate modulates the self-recurrent state connection by a number between 0 and 1. Thus, if the input gate modulates the input with 0, and the forget gate modulates the recurrent connection with 1, the cell ignores the input and perfectly retains state. On the other hand, a 1 (input) and a 0 (forget) causes the cell\u2019s state to be overwritten by the input. And in the case of a 0 (input) and 0 (forget), the state is reset to 0. Finally, an output gate modulates the contribution of the cell\u2019s state to the output, which propagates to the input gates of LSTM cells across the layer, as well as to subsequent layers of the network.\nThe LSTM cell\u2019s design with multiplicative gates allows a network to store and access state over long sequences, thereby mitigating the vanishing gradients problem. For our use with domain names, the state space is intended to capture combinations of letters that are important to discriminating DGA domains from non-DGA domains. This flexible architecture generalizes manual feature extraction via bigrams, for example, but instead learns dependencies of one or multiple characters, whether in succession or with arbitrary separation."}, {"heading": "III. METHOD", "text": "We employ an LSTM network for detecting DGAs. The model has the following advantages:\n\u2022 the model accepts variable-length character sequences as input, so that there is no auxiliary requirement for feature extraction2;\n\u2022 the model is very compact, comprised simply of an embedding layer, an LSTM network layer, and a fully connected output layer that is simple logistic (or for multiclass, multinomial logistic) regression; and\n\u2022 although training on a large dataset is computationally intensive, the shallow structure allows for very fast query times.\nA graphical depiction of our model is shown in Fig. 1. To prevent overfitting when training neural networks, it is common practice to employ dropout. Dropout consists of randomly removing a random subset of edges between layers of a network during each iteration of training, but restoring their contribution at test time. We apply dropout after the LSTM layer prior to logistic regression.\nThe embedding layer projects `-length sequences of input characters from the input domain S \u2282 Z` to a sequence of vectors Rd\u00d7`, where ` is an upper bounded length determined from the training set. The input domain consists of nonredundant valid domain name characters (lowercase alphanumeric, period, dash and underscore), and the output dimension\n2In experiments, we employ a trivial pre-processing step to remove top-level domains and convert all characters to lowercase.\nd is a tunable parameter that represents an embedding. In our model, we choose d = 128 > |S| to provide additional degrees of freedom to the model, but preliminary experiments showed that results are relatively insensitive to the particular choice of d.\nThe LSTM layer can be thought of as implicit feature extraction, as opposed to explicit feature extraction (e.g., ngrams) used in other approaches. Rather than represent domain names explicitly as a bag of bigrams, for example, the LSTM learns patterns of characters (or in our case, embedded vectors) that maximize the performance of the second classification layer. In our experiments we compare the LSTM model to an explicit bigram logistic regression model.\nAll LSTM code was written in Python using the Keras framework [6]. Two models are generated: one for a binary classification and one for a multiclass classification. Code for the binary classification is shown in Fig. 2 and the multiclass classification in Fig. 3.\nThe two code examples have a few small differences. The final dense layer goes from an output of one value in the binary classifier (line 15) to nb_classes in the multiclass classifier (line 17). A binary decision only requires a single value from [0, 1] where 0 is the most benign and 1 is the most DGA. The multiclass model produces nb_classes scores, one for each family known by the classifier, where multinomial logistic regression is employed on softmaxed activations on line 18 to encode a distribution that sums to unity."}, {"heading": "IV. EXPERIMENTAL SETUP", "text": "In the following section, we describe details of our experimental setup in evaluating DGA classifiers in a binary experiment (DGA vs. non-DGA) and multiclass experiment (which DGA?) using publically available domain names and DGA data."}, {"heading": "A. Evaluation Metrics", "text": "Precision, Recall, F1 score, and Receiver Operating Characteristic (ROC) are the four evaluation metrics used to compare the LSTM classification technique to other state-of-the-art techniques. Precision is defined as\n1 from keras.preprocessing import pad_sequences 2 from keras.models import Sequential 3 from keras.layers.core import Dense 4 from keras.layers.core import Dropout 5 from keras.layers.core import Activation 6 from keras.layers.embeddings import Embedding 7 from keras.layers.recurrent import LSTM 8 9 model=Sequential()\n10 model.add(Embedding(max_features, 11 128, 12 input_length=75)) 13 model.add(LSTM(128)) 14 model.add(Dropout(0.5)) 15 model.add(Dense(1)) 16 model.add(Activation(\u2019sigmoid\u2019)) 17 18 model.compile(loss=\u2019binary_crossentropy\u2019, 19 optimizer=\u2019rmsprop\u2019) 20 21 # Pad sequence where sequences are case 22 # insensitive characters encoded to 23 # integers from 0 to number of valid 24 # characters 25 X_train=sequence.pad_sequences(X_train, 26 maxlen=75) 27 28 # Train where y_train is 0-1 29 model.fit(X_train, y_train, 30 batch_size=batch_size, nb_epoch=1)\nand measures the purity of all positively labeled instances (i.e., the ratio of correct positively labeled instances to all positively labeled instances). Recall is defined as\nRecall = \u2211\nTrue Positive\u2211 True Positive + \u2211 False Negative ,\nand measures the completeness of positively labeled instances (i.e., the ratio of correct positively labeled instances to all instances that should have been labeled positive). F1 score is the harmonic mean of Precision and Recall:\nF1 = 2 \u00b7 Precision \u00b7 Recall\nPrecision + Recall .\nROC measures the trade-off of the true positive rate (TPR) to false positive rate (FPR) where\nTPR = \u2211\nTrue Positive\u2211 True Positive + \u2211 False Negative ,\nand\n1 from keras.preprocessing import pad_sequences 2 from keras.models import Sequential 3 from keras.layers.core import Dense 4 from keras.layers.core import Dropout 5 from keras.layers.core import Activation 6 from keras.layers.embeddings import Embedding 7 from keras.layers.recurrent import LSTM 8 9 model=Sequential()\n10 model.add(Embedding(max_features, 11 128, 12 input_length=75)) 13 model.add(LSTM(128)) 14 model.add(Dropout(0.5)) 15 # nb_classes is the number of classes in 16 # the training set 17 model.add(Dense(nb_classes)) 18 model.add(Activation(\u2019softmax\u2019)) 19 20 model.compile(loss=\u2019categorical_crossentropy\u2019, 21 optimizer=\u2019rmsprop\u2019) 22 23 # Pad sequence where sequences are case 24 # insensitive characters encoded to 25 # integers from 0 to number of valid 26 # characters 27 X_train=sequence.pad_sequences(X_train, 28 maxlen=75) 29 30 # Train where y_train is one-hot encoded for 31 # each class 32 model.fit(X_train, y_train, 33 batch_size=batch_size, nb_epoch=1)\nThe ROC is generated by evaluating the TPR and FPR at all thresholds of score returned by a classifier. For example, the ROC is calculated for a probabilistic classifier by varying a threshold from 0.0 to 1.0 and calculating FPR and TPR for each value in the range. Area under the curve (AUC) is a common single metric to compare ROC curves, and as the name implies, is just the area under the ROC curve. An AUC of 1 is perfect, and an AUC of 0.5 is the same as chance in a binary classifier.\nAveraging results over classes is done using both a micro and macro average. Micro averaging takes into account the number of elements in the test set. This means that smaller classes will account for less in the average than larger classes. Macro, on the other hand, averages over all classes regardless of the number of elements in each individual class. For this paper, macro averaging is probably a better predictor of performance as the distributions of classes in our dataset may not accurately represent the true distributions in the wild. However, both measures are provided for completeness."}, {"heading": "B. Experimental Designs", "text": "The proposed technique is evaluated using three different experimental designs:\n1) binary classification with random holdout test sets to measure the general ability to detect DGA vs. nonDGA, 2) binary classification with holdout DGA algorithm families to measure the ability to detect new DGAs, and 3) multiclass classification to measure the ability to distinguish one DGA algorithm from another.\nThe binary classification experimental design tests each DGA classifier for it\u2019s ability to make an accurate binary decision: DGA or not DGA. The DGA class consists of domains from all thirty families in our training set. This experiment is run using n-fold cross validation with ten folds. Evaluation is accomplished with both an ROC as well as a detailed Precision, Recall and F1 score broken down by each class. Both the micro and macro averages of Precision, Recall and F1 score are also given.\nIn the second experiment, we test each classifier\u2019s ability to discover new DGA families not used in the training set. The ten smallest DGA families are removed from the dataset and each classifier is trained on all samples from the remaining classes. Precision, Recall and F1 score is calculated on the test set. In addition, we find both the micro and macro average of these scores over all classes for each algorithm.\nThe multiclass classification design tests each DGA classifier for its ability to make an accurate decision on the family of DGA. The random forest DGA classifier (using manual features) uses a One vs. Rest while the LSTM and Bigram classifiers do a direct multiclass classification. We display a class breakdown of Precision, Recall and F1 score for each class as well as the micro and macro average."}, {"heading": "C. Data", "text": "This paper uses open datasets for reproducibility. A realworld system should use an expanded dataset to make it more difficult for an adversary to reverse engineer and defeat the classifier. The experimental designs use data from two sources.\n1) The Alexa top 1 million domains [26] are used for training domains that are not DGAs. 2) The OSINT DGA feed from Bambenek Consulting [27] is used for DGA domains.\nThe OSINT DGA feed consists of thirty families of DGAs with a varying number of examples from each class. This feed contains approximately 750,000 DGA examples."}, {"heading": "D. Comparison to state of the art", "text": "For each experiment, we compare the featureless LSTM DGA classifier to\n\u2022 a featureless HMM model3 defined in [2],\n3HMM is excluded from the multiclass experiment due to poor performance.\n\u2022 logistic regression on character bigrams (simple features), and\n\u2022 a random forest DGA classifier using manually-crafted domain features defined in [2], [3], [4], [18].\nIn particular, the manually crafted features of the random forest DGA classifier include the following:\n\u2022 length of domain name, \u2022 entropy of character distribution in domain name, \u2022 vowel to consonant ratio, \u2022 Alexa 1M n-gram frequency distribution co-\noccurrence count, where n = 3, 4 or 5,\n\u2022 n-gram normality score, and \u2022 meaningful characters ratio.\nNote that for the n-gram normality score, we use n = 3, n = 4 and n = 5 as three distinct features as opposed to n = 1, n = 2 and n = 3 as in [18] since the larger n-gram size performed better in preliminary experiments. In addition, features were trained in a random forest DGA classifier as opposed to a Mahalanobis distance classifier as used in [18] as the random forest DGA classifier produced better results.\nFour separate HMMs are trained with one trained on the non-DGA class, and three trained on the three largest DGA classes in terms of support (Post, banjori, and ramnit). The number of hidden states is set to the average length of the domain names in the training set. We use the Neyman-Pearson likelihood ratio test to classify a domain as DGA generated if\nlogPi\u2217 \u2212 logP0 \u2265 \u03b7,\nwhere\ni\u2217 = argmax i\u2208{banjori, ramnit, Post} Pi,\nP0 is the probability of being a non-DGA, and \u03b7 is a user specified threshold. There are a few key differences from the HMM presented in [2]. Authors in [2] use a distinct HMM for each family of DGA, while we only create an HMM for the three largest classes of DGAs in the training set. In addition, we use the Neyman-Pearson likelihood ratio test as opposed to a threshold directly on the maximum HMM score from the DGA HMMs. Preliminary results showed a significant improvement in ROC over the algorithm presented in [2] when using these updates.\nEven with the improved algorithm, the HMM performed worse than other techniques evaluated in this paper. This is especially true for the multiclass experiment. The original HMM algorithm in [2] was presented on only four classes, each with a significant support. This is unlike our setup that has thirty classes with varying degrees of support. For this reason we omit HMM results for the multiclass experiment.\nWe also compare our results with those of retrospective techniques as reported in [5]. This comparison is only done for the binary classification as our dataset only contains\ndomain names without any contextual information. In addition, retrospective techniques perform far worse than real-time techniques for binary classification and, therefore, will likely degrade even further for multiclass classification."}, {"heading": "V. RESULTS", "text": "Results for the three experiments and an interpretation of model performance are presented in this section."}, {"heading": "A. Binary Classification", "text": "The ROC curves for the HMM, random forest classifier with manually-crafted features (Manual Features), logistic regression classifier on character bigrams (Bigrams), and LSTM DGA clasifier (LSTM) are presented in Fig. 4. Note that the abscissa (false positive rate) is on a log scale to highlight the differences in the algorithms. LSTM provides the best performance with an AUC of 0.9993 with the bigram model at 0.9939. The difference between the two algorithms may seem small, but are actually quite significant in a production system. As an example, the LSTM model can classify 90% of all DGAs with a 1 in 10,000 false positive rate. On the other hand, a Bigram model will classify the same percentage of DGA\u2019s with a 1 in 550 false positive rate (i.e., the Bigram model produces a false positive rate that is 20\u00d7 that of the LSTM model).\nThe breakdown of Precision, Recall, and F1 for each class as classified by the binary classifiers is given in Table II. The support (size of test set) is given in the last column. In general, classes that are the most difficult to detect have smaller support. This is expected as they have a smaller contribution to model updates during training than larger classes. In addition matsnu was undetectable by all algorithms. matsnu is a dictionary-based DGA, meaning it is created by randomly selecting and concatenating multiple words from a dictionary. Interestingly, suppobox is also a dictionary based DGA, but was detectable (to some extent) by the LSTM. The size of the suppobox training was about twenty times that of matsnu allowing for repeats of randomly selected dictionary words. These repeats allow the LSTM to learn the dictionaries of such DGAs. We leave an in-depth analysis of dictionary based DGA to future work.\nThe HMM performed worse than expected. The results presented in [2] only used a small number of homogenous DGA families (Conficker, Murofet, Bobax and, Sinowal) while the experiments in this paper use over 30 different families. Some of these families in this paper are related, but overall, our results were generated from a larger/more rich dataset. As discussed later in this paper, the letter distributions are very different across the 30 DGA families used in this paper. For example, DGA families such as Cryptolocker and ramnit have near uniform distributions over letters, dyre has a uniform distribution over hexadecimal characters with a dictionary word as a prefix, and suppobox and matsnu use English words to create domains giving a distribution very similar to english based domains. In contrast, Conficker [28], Murofet [29], Bobax [30] and Sinowal [31] all use a generator that gives a uniform distribution over letters similar to Cryptolocker and ramnit.\nTable I displays the true positive rate and false positive rate for retrospective techniques as compared to the LSTM technique presented by this paper. As can be seen, the LSTM technique significantly outperforms the best retrospective techniques."}, {"heading": "B. Leave-Class-Out Binary Classification", "text": "The binary leave-one-out classifier is interesting as it tests each algorithm\u2019s robustness to DGA families not seen during\ntraining. Only Recall is presented for this experiment as there are no non-DGA generated domains in this test set. The results for this experiment are shown in Table III.\nThe manual features random forest classifier performs best in terms of both micro and macro average. On the other hand, the LSTM classifier has the most families that it performs best on (five in total as opposed to four in total for the manual features classifier). The biggest discrepancy between manual features and LSTM was with beebone. In particular, the manual features classifier identifies all of the beebone samples, while the LSTM model recovers none. The domain names from beebone have a rigid structure, like ns1.backdates13.biz andns1.backdates0.biz, so that the LSTM model was unable to learn the structure that included the word backdates without training data. The results are nearly as dramatic for symmi, which produces nearly-pronounceable domain names like hakueshoubar.ddns.net, by drawing a random vowel or a random consonant at each even-numbered index, then drawing a random character of the opposite class (vowel/consonant) in the subsequent index location. These examples highlight blind spots in the LSTM classifier. However, these blind spots can be easily fixed through training with the use of an adversarial network (i.e., train a generator network that creates domains that confuses our classifier).\nApparently, the structure of some DGA families\u2013even if not elaborately designed\u2013are peculiar enough to necessitate their inclusion in the training set. As evident in the results for Experiment 1 in Table II, the LSTM readily detects these families with distinct structure when accounted for in the training set with sufficient support. The manual features\nappear to be generic enough to detect these families with high recall. However, its important to note that manual features were designed specifically for known DGA families and all of our DGAs in our test set are known (i.e., our dataset is known and labeled) making this experiment biased to a feature based classifier. Even with this bias, the LSTM classifier still performs best in terms of the number of DGA families it detects."}, {"heading": "C. Multiclass", "text": "The HMM results were omitted from the multiclass experiments due to poor performance. As stated previously, the HMM algorithm was designed for few DGAs, whereas our experiments include over 30 classes. Precision, Recall, and F1 is displayed in Table IV for the random forest classifier with manual features (Manual Features), multinomial logistic regression on character bigrams (Bigram) and the LSTM classifier. The LSTM classifier significantly outperforms the other two algorithms in both the micro and macro averaged Precision, Recall, and F1 score. In general, poor performance resulted from classes with small representation. One exception was Cryptolocker, which no multiclass classifier was able to detect. However, all the binary classifiers were able to distinguish Cryptolocker from other families.\nFig. 5 shows the confusion matrix for the LSTM multiclass classifier. A large number of the incorrectly classified Cryptolocker DGAs are classified as ramnit. To further investigate, the unigram distributions for four DGA families and Alexa are shown in Fig. 6. The distributions for Cryptolocker and ramnit are both uniform over the same range. This is expected as they are both generated\nusing a series of multiplies, divisions and modulos based on a single seed [13], [10]. On the other hand, suppobox is interesting as it generates unigrams similar to distributions seen by the Alexa top one million domains and is often confused with the benign set. As discussed earlier, suppobox is an English dictionary-based DGA, meaning domains are constructed by concatenating multiple, randomly chosen words from the English dictionary. Interestingly, only the LSTM classifier was able to consistently detect suppobox (as seen in Table II). This shows LSTM\u2019s ability to extract some deep understanding that is lost by other classifiers. Specifically, the LSTM actually learns the dictionary used by suppobox to construct domains.\nFig. 7 shows the all-to-all cosine distance of the unigram distribution between all DGA families and the Alexa top one million domains. dyre stands out as it is extremely dissimilar to other algorithms. This is not surprising when comparing this figure to Table 6. dyre has a nearly uniform distribution over primarily hexadecimal numbers (non-hexadecimal letters exist, but are rare).\nWhen comparing both Fig. 5, Fig. 7, and Table II, some correlation can be seen between the unigram distribution and DGA algorithms that are often misclassified. This suggests that it\u2019s not only the lack of representation of these algorithms in the training set, but also the distribution of letters that is causing much of the misclassification. More specifically, many\nDGAs produce domains that look nearly identical in terms of their character distributions making multiclass classification difficult if not impossible. To test this, we performed agglomerative clustering on each DGA\u2019s family unigram distribution using cosine distance. We set a threshold of 0.2 to define super families (the threshold was chosen using domain knowledge of DGA families). These super families are shown in Table V. Interesting super families include Super Family 4 (dictionarybased DGAs), Super Family 5 (randomly selected character DGAs), and Super Family 7 (randomly selected characters with near equal vowels and consonants).\nThe same multiclass classification experiment was run on these super families and the results are shown in VI. As expected, all three classifiers performed much better on super families. Results demonstrate that an actual deployment of a multiclass DGA classification would be best run on super families, often alerting on groups of DGAs instead of alerting on a single family. Again, the LSTM classifier performs significantly better than other algorithms."}, {"heading": "D. Model Interpretability", "text": "We analyze the binary LSTM classifier in order to provide some intuition about the function of the various layers. It is important to note that in the LSTM model, each layer in Fig. 1 is jointly optimized for the binary classification task.\nTABLE VI: Precision, Recall and F1 Score for Multiclass Classifiers\nPrecision Recall F1 Score\nDomain Type Features Bigram LSTM Features Bigram LSTM Features Bigram LSTM Support\nAlexa 0.930 0.980 0.990 0.960 0.990 1.000 0.940 0.990 0.990 199906 Super Family 0 0.980 0.990 1.000 1.000 0.990 1.000 0.990 0.990 1.000 1603 Super Family 1 1.000 1.000 1.000 0.590 1.000 1.000 0.740 1.000 1.000 43 Super Family 2 0.000 1.000 1.000 0.000 1.000 0.970 0.000 1.000 0.990 203 Super Family 3 0.000 0.950 0.980 0.000 0.810 0.900 0.000 0.870 0.940 1998 Super Family 4 0.910 0.990 1.000 0.920 1.000 1.000 0.910 0.990 1.000 81559 Super Family 5 0.870 0.950 0.970 0.880 0.940 0.970 0.870 0.950 0.970 40450 Super Family 6 0.000 0.840 0.960 0.000 0.550 0.670 0.000 0.670 0.790 2877 Super Family 7 0.000 0.830 0.940 0.000 0.680 0.910 0.000 0.750 0.920 3326 Super Family 8 0.940 0.990 1.000 1.000 0.990 1.000 0.970 0.990 1.000 13267 Super Family 9 0.000 0.980 1.000 0.000 0.910 1.000 0.000 0.940 1.000 52 Super Family 10 0.000 0.000 0.910 0.000 0.000 0.830 0.000 0.000 0.870 11 Micro Average 0.896 0.977 0.990 0.919 0.979 0.992 0.903 0.980 0.988 28774 Macro Average 0.469 0.875 0.979 0.446 0.822 0.938 0.452 0.845 0.956 28774\nNevertheless, analyzing each layer independently does provide some intuition about the model\u2019s operation and performance.\nThe embedding layer in Fig. 1 learns a 128-dimensional vector representation for each character in the set of valid domain characters. A two-dimensional linear projection (via PCA) of the character embeddings is shown in Fig. 8. It is clear that the learned embedding consists of non-orthogonal vectors for each character. This is in contrast to the orthonormal one-hot encoding of bigrams used in the logistic regression character bigram model. The placement of vectors in the\n- . 0 1 2 3 4 5 6 7 8 9 _ a b c d e f g h i j k l m n o p q r s t u v w x y z 0.0\n0.1\n0.2 Cryptolocker\n- . 0 1 2 3 4 5 6 7 8 9 _ a b c d e f g h i j k l m n o p q r s t u v w x y z 0.0\n0.1\n0.2 ramnit\n- . 0 1 2 3 4 5 6 7 8 9 _ a b c d e f g h i j k l m n o p q r s t u v w x y z 0.0\n0.1\n0.2 dyre\n- . 0 1 2 3 4 5 6 7 8 9 _ a b c d e f g h i j k l m n o p q r s t u v w x y z 0.0\n0.1\n0.2 suppobox\n- . 0 1 2 3 4 5 6 7 8 9 _ a b c d e f g h i j k l m n o p q r s t u v w x y z 0.0\n0.1\n0.2 Alexa Top 1M\nFig. 6: Unigram distributions for Cryptolocker, ramnit, dyre, suppobox and the Alexa top one million.\nembedding space (and subsequently, the two-dimensional plot) relates to the similarity or interchangeability of characters for the DGA vs. non-DGA discrimination task. For example, one would infer from the plot that replacing \u201c9\u201d with \u201c5\u201d would have much less effect on the score of the DGA classifier than would replacing \u201c9\u201d with \u201cw\u201d. The plot shows that there are obvious clusters of numeric digits and alphabetic characters (and underscore), while the less-common hyphen and period are fairly dissimilar to every other character.\nNext, we investigate the state (or memory) of several LSTM cells in the second layer of the LSTM model in Fig. 1. The state of an LSTM cell has an initial value that is updated as each character of a domain is fed through the model. It is a function of the current input (embedded character vector) and the previous emission of the LSTM cell. In turn, the LSTM\u2019s emission is a function of the current state, current input, and previous emission. In our model, the final emission (corresponding to the last character in the domain) from each of 128 LSTM cells is fed to the final logistic regression layer of the model to produce the DGA score.\nEach LSTM cell acts somewhat as an optimized feature extractor on the sequences of embedded character vectors produced from the previous embedding layer, and the cell\u2019s state provides an indication of what the cell is tracking. Similar to [32], Fig. 9 shows the tanh of a particular LSTM cell\u2019s state (called memory in [32]) as it is updated characterby-character during a prediction task. As shown in Fig. 9, some states in our model have a tendency to track common characteristics of domain names in the dataset. For example, Fig. 9(a) shows a state that seems to trend with domain name length, with soft resets on periods and hyphens. The LSTM cell state depicted in Fig. 9(b) appears to accumulate large\nvalues for long sequences of random alphanumeric characters. The state in Fig. 9(c) seems to accumulate value on sequences of hexadecimal characters, as is the predominant pattern in dyre. Finally, Fig. 9(d) depicts the most common scenario we encountered while inspecting states: it\u2019s generally very difficult to determine precisely what the state is tracking. We note that our application of LSTMs for DGA classification does not yield quite as clearly the distinctive purpose of states as has been demonstrated for natural language models [32]."}, {"heading": "VI. CONCLUSION", "text": "This paper presented an approach using LSTM networks to classify DGA generated domains. LSTMs are advantageous over other techniques as they are featureless, using raw domain names as its input. There is no need to manually create features that are difficult to maintain and can be rendered useless in an adversarial machine learning setting. In addition, an LSTM classifier can be run in real-time on single domains on standard commodity hardware making it trivial to deploy in virtually all security settings. Experiments on publiclyavailable datasets showed that the LSTM classifier performed significantly better than other techniques (both real-time and retrospective), with the ability to classify 90% of DGAs with a false positive rate of 10\u22124. In addition, the LSTM classifier may be trivially modified for multiclass classification, which can provide context about the origin and intent of the domaingenerating malware.\nAn in-depth analysis of results showed that the most difficult algorithms to classify are, intuitively, those that are modeled from a similar character distribution as domains in the Alexa top one million. Some of these DGA families concatenate randomly selected words from (typically) English dictionaries. However, the LSTM classifier was able to distinguish those DGA families when the amount of training examples were significant and the families were grouped together in super families.\nWe also provided an in-depth analysis of the functional interpretability of each layer in the LSTM DGA classifier. Our analysis revealed that the model optimized vector embeddings for each character in a somewhat intuitive way, with distinct clusters for alphabetic and numeric digits. Our analysis of the LSTM layer revealed the existence of LSTM cells that track a few somewhat interpretable features such as a hexadecimal and random character sequences. However, we found that most states did not provide clear interpretable evidence of function, in contrast to other applications of LSTMs, e.g., [32].\nLike all models, experiments show that our model is sensitive to class imbalance, which limits its ability to detect families with very little support in the training set (e.g., matsnu, symmi and cryptowall). In the extreme case of zero training support, it was found that the LSTM model does not generalize well for detecting all families with very distinctive structure. Manually-engineered features were able to detect some of those families that an LSTM classifier missed, and we hypothesize that this is directly a result of expert-tuned bias in the feature set that cannot be represented in the featureless LSTM model.\nAll relevant source code and suggestions on deploying a real-world LSTM DGA classifier were provided by this paper. In addition, we reference open datasets to create an equal classifier to that presented in this paper. To the best of our knowledge, the presented system is by far the best performing DGA classification system as well as one of the easiest to deploy."}], "references": [{"title": "Paint it black: Evaluating the effectiveness of malware blacklists", "author": ["M. K\u00fchrer", "C. Rossow", "T. Holz"], "venue": "Research in Attacks, Intrusions and Defenses, pp. 1\u201321, Springer, 2014.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "From throw-away traffic to bots: detecting the rise of DGA-based malware", "author": ["M. Antonakakis", "R. Perdisci", "Y. Nadji", "N. Vasiloglou", "S. Abu-Nimeh", "W. Lee", "D. Dagon"], "venue": "P21st USENIX Security Symposium (USENIX Security 12), pp. 491\u2013506, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Detecting algorithmically generated malicious domain names", "author": ["S. Yadav", "A.K.K. Reddy", "A. Reddy", "S. Ranjan"], "venue": "Proc. 10th ACM SIGCOMM conference on Internet measurement, pp. 48\u201361, ACM, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Detecting algorithmically generated domain-flux attacks with DNS traffic analysis", "author": ["S. Yadav", "A.K.K. Reddy", "A.N. Reddy", "S. Ranjan"], "venue": "Networking, IEEE/ACM Transactions on, vol. 20, no. 5, pp. 1663\u20131677, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Crossing the threshold: Detecting network malfeasance via sequential hypothesis testing", "author": ["S. Krishnan", "T. Taylor", "F. Monrose", "J. McHugh"], "venue": "2013 43rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN), pp. 1\u201312, IEEE, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Good guys vs. bot guise: Mimicry attacks against fast-flux detection systems", "author": ["M. Knysz", "X. Hu", "K.G. Shin"], "venue": "INFOCOM, 2011 Proceedings IEEE, pp. 1844\u20131852, IEEE, 2011.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Analysis of a botnet takeover", "author": ["B. Stone-Gross", "M. Cova", "B. Gilbert", "R. Kemmerer", "C. Kruegel", "G. Vigna"], "venue": "Security & Privacy, IEEE, vol. 9, no. 1, pp. 64\u201372, 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Cryptolocker victims to get files back for free", "author": ["M. Ward"], "venue": "BBC News, August, vol. 6, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Ransomware: Emergence of the cyberextortion menace", "author": ["N. Hampton", "Z.A. Baig"], "venue": "Australian Information Security Management Conference, 2015.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Hesperbot-A new, advanced banking trojan in the wild", "author": ["A. Cherepanov", "R. Lipovsky"], "venue": "2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "End-to-end analysis of a domain generating algorithm malware family.", "author": ["J. Geffner"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Building a dynamic reputation system for DNS", "author": ["M. Antonakakis", "R. Perdisci", "D. Dagon", "W. Lee", "N. Feamster"], "venue": "USENIX security symposium, pp. 273\u2013290, 2010.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Exposure: Finding malicious domains using passive analaysis", "author": ["L. Bilge", "E. Kirda", "C. Kruegel", "M. Balduzzi"], "venue": "18th Annual Network and Distributed System Security Symposium, 2011.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Exposure: a passive DNS analysis service to detect and report malicious domains", "author": ["L. Bilge", "S. Sen", "D. Balzarotti", "E. Kirda", "C. Kruegel"], "venue": "ACM Transactions on Information and System Security (TISSEC), vol. 16, no. 4, p. 14, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Phoenix: DGAbased botnet tracking and intelligence", "author": ["S. Schiavoni", "F. Maggi", "L. Cavallaro", "S. Zanero"], "venue": "Detection of intrusions and malware, and vulnerability assessment, pp. 192\u2013211, Springer, 2014.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "An application of recurrent nets to phone probability estimation", "author": ["A.J. Robinson"], "venue": "Neural Networks, IEEE Transactions on, vol. 5, no. 2, pp. 298\u2013305, 1994.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1994}, {"title": "Recurrent neural network based language model", "author": ["T. Mikolov", "M. Karafi\u00e1t", "L. Burget", "J. Cernock\u1ef3", "S. Khudanpur"], "venue": "INTERSPEECH, vol. 2, p. 3, 2010.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Sequence transduction with recurrent neural networks", "author": ["A. Graves"], "venue": "arXiv preprint arXiv:1211.3711, 2012.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Advances in optimizing recurrent networks", "author": ["Y. Bengio", "N. Boulanger-Lewandowski", "R. Pascanu"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, pp. 8624\u2013 8628, IEEE, 2013.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1997}, {"title": "Learning to forget: Continual prediction with LSTM", "author": ["F.A. Gers", "J. Schmidhuber", "F. Cummins"], "venue": "Neural computation, vol. 12, no. 10, pp. 2451\u20132471, 2000.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2000}, {"title": "Learning precise timing with LSTM recurrent networks", "author": ["F.A. Gers", "N.N. Schraudolph", "J. Schmidhuber"], "venue": "J. Machine Learning Research, vol. 3, pp. 115\u2013143, 2003.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2003}, {"title": "A foray into conficker\u2019s logic and rendezvous points", "author": ["P.A. Porras", "H. Sa\u0131\u0308di", "V. Yegneswaran"], "venue": "LEET, 2009.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Highly resilient peer-to-peer botnets are here: An analysis of gameover zeus", "author": ["D. Andriesse", "C. Rossow", "B. Stone-Gross", "D. Plohmann", "H. Bos"], "venue": "Malicious and Unwanted Software:\u201d The Americas\u201d(MALWARE), 2013 8th International Conference on, pp. 116\u2013123, IEEE, 2013.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "On the kraken and bobax botnets.", "author": ["P. Royal"], "venue": "https://www.damballa. com/downloads/r pubs/Kraken Response.pdf,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "Your botnet is my botnet: analysis of a botnet takeover", "author": ["B. Stone-Gross", "M. Cova", "L. Cavallaro", "B. Gilbert", "M. Szydlowski", "R. Kemmerer", "C. Kruegel", "G. Vigna"], "venue": "Proceedings of the 16th ACM conference on Computer and communications security, pp. 635\u2013647, ACM, 2009.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Visualizing and understanding recurrent networks", "author": ["A. Karpathy", "J. Johnson", "F.-F. Li"], "venue": "to appear in Proceedings of the International Conference on Learning Representations, 2016. arXiv preprint arXiv:1506.02078.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Authors in [1] presented a thorough review of the efficacy of blacklists.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "Retrospective detection makes bulk predictions on large sets of domains and are designed as a reactionary system that cannot be used for real-time detection and prevention [2], [3], [4].", "startOffset": 172, "endOffset": 175}, {"referenceID": 2, "context": "Retrospective detection makes bulk predictions on large sets of domains and are designed as a reactionary system that cannot be used for real-time detection and prevention [2], [3], [4].", "startOffset": 177, "endOffset": 180}, {"referenceID": 3, "context": "Retrospective detection makes bulk predictions on large sets of domains and are designed as a reactionary system that cannot be used for real-time detection and prevention [2], [3], [4].", "startOffset": 182, "endOffset": 185}, {"referenceID": 4, "context": "Much of the previous work in DGA detection falls in the former category and, unfortunately, does not meet the needs of many real-world security applications that require real-time detection and prevention [5].", "startOffset": 205, "endOffset": 208}, {"referenceID": 4, "context": "(Suprisingly, authors in [5] found that retropsective techniques had similarly bad performance!) Many of the previous real-time approaches use hand picked features (e.", "startOffset": 25, "endOffset": 28}, {"referenceID": 1, "context": "To the best of our knowledge, authors in [2] presented the first (and only until this paper) featureless real-time technique by using Hidden Markov Models (HMMs).", "startOffset": 41, "endOffset": 44}, {"referenceID": 1, "context": "To note, the HMMs in [2] were part of a much larger retrospective detection system.", "startOffset": 21, "endOffset": 24}, {"referenceID": 5, "context": "Domain fluxing is a technique used by botnets and command-and-control (C2) servers to create many domains using a Domain Generation Algorithm (DGA) [7], [8].", "startOffset": 148, "endOffset": 151}, {"referenceID": 6, "context": "Domain fluxing is a technique used by botnets and command-and-control (C2) servers to create many domains using a Domain Generation Algorithm (DGA) [7], [8].", "startOffset": 153, "endOffset": 156}, {"referenceID": 6, "context": "One approach to combating domain fluxing is to reverse engineer a piece of malware and its respective DGA [8].", "startOffset": 106, "endOffset": 109}, {"referenceID": 0, "context": "Blacklisting is another approach to combat domain fluxing [1].", "startOffset": 58, "endOffset": 61}, {"referenceID": 7, "context": "Malware families include ransomware, such as Cryptolocker [9], [10] and Cryptowall [11], banking trojans, such as Hesperbot [12], and general information-stealing tactics, such as ramnit [13].", "startOffset": 58, "endOffset": 61}, {"referenceID": 8, "context": "Malware families include ransomware, such as Cryptolocker [9], [10] and Cryptowall [11], banking trojans, such as Hesperbot [12], and general information-stealing tactics, such as ramnit [13].", "startOffset": 83, "endOffset": 87}, {"referenceID": 9, "context": "Malware families include ransomware, such as Cryptolocker [9], [10] and Cryptowall [11], banking trojans, such as Hesperbot [12], and general information-stealing tactics, such as ramnit [13].", "startOffset": 124, "endOffset": 128}, {"referenceID": 10, "context": "ramnit, for example, creates domains with a series of divides, multiplies and modulos computed on a seed [13] while suppobox creates domains by concatenating two random strings (typically taken from the English language) [14].", "startOffset": 221, "endOffset": 225}, {"referenceID": 11, "context": "Domain reputation systems typically incorporate many pieces of heterogeneous data, such as passive DNS (pDNS), to make decisions on a domain\u2019s reputation [15], [16], [17].", "startOffset": 154, "endOffset": 158}, {"referenceID": 12, "context": "Domain reputation systems typically incorporate many pieces of heterogeneous data, such as passive DNS (pDNS), to make decisions on a domain\u2019s reputation [15], [16], [17].", "startOffset": 160, "endOffset": 164}, {"referenceID": 13, "context": "Domain reputation systems typically incorporate many pieces of heterogeneous data, such as passive DNS (pDNS), to make decisions on a domain\u2019s reputation [15], [16], [17].", "startOffset": 166, "endOffset": 170}, {"referenceID": 2, "context": "Authors in [3], [4] detect DGAs by using both unigram and bigram statistics of domain clusters.", "startOffset": 11, "endOffset": 14}, {"referenceID": 3, "context": "Authors in [3], [4] detect DGAs by using both unigram and bigram statistics of domain clusters.", "startOffset": 16, "endOffset": 19}, {"referenceID": 1, "context": "Authors in [2] apply a similar clustering process to classify domains with unsuccessful DNS resolutions.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "The aforementioned techniques (with exception to the HMM technique in [2]) are accomplished retrospectively.", "startOffset": 70, "endOffset": 73}, {"referenceID": 4, "context": "Authors in [5] perform an in-depth comparison of these techniques and discuss two important findings.", "startOffset": 11, "endOffset": 14}, {"referenceID": 14, "context": "Authors in [18] present a real-time DGA classifier that uses two basic linguistic features named meaningful characters ratio and n-gram normality score.", "startOffset": 11, "endOffset": 15}, {"referenceID": 14, "context": "The approach in [18] is used as a filter step.", "startOffset": 16, "endOffset": 20}, {"referenceID": 4, "context": "Our technique significantly outperforms retrospective techniques and the comparison is brief and compares findings to those in [5].", "startOffset": 127, "endOffset": 130}, {"referenceID": 1, "context": "More specififcally, we compare our technique to the HMM defined by [2] as well as a Random Forest Classifier trained on features defined in [2], [3], [4], [18].", "startOffset": 67, "endOffset": 70}, {"referenceID": 1, "context": "More specififcally, we compare our technique to the HMM defined by [2] as well as a Random Forest Classifier trained on features defined in [2], [3], [4], [18].", "startOffset": 140, "endOffset": 143}, {"referenceID": 2, "context": "More specififcally, we compare our technique to the HMM defined by [2] as well as a Random Forest Classifier trained on features defined in [2], [3], [4], [18].", "startOffset": 145, "endOffset": 148}, {"referenceID": 3, "context": "More specififcally, we compare our technique to the HMM defined by [2] as well as a Random Forest Classifier trained on features defined in [2], [3], [4], [18].", "startOffset": 150, "endOffset": 153}, {"referenceID": 14, "context": "More specififcally, we compare our technique to the HMM defined by [2] as well as a Random Forest Classifier trained on features defined in [2], [3], [4], [18].", "startOffset": 155, "endOffset": 159}, {"referenceID": 1, "context": "We do not perform an in depth comparison on the full systems as defined in [2], [3], [4] as they are retrospective systems and have already been shown to perform far worse than our system [5].", "startOffset": 75, "endOffset": 78}, {"referenceID": 2, "context": "We do not perform an in depth comparison on the full systems as defined in [2], [3], [4] as they are retrospective systems and have already been shown to perform far worse than our system [5].", "startOffset": 80, "endOffset": 83}, {"referenceID": 3, "context": "We do not perform an in depth comparison on the full systems as defined in [2], [3], [4] as they are retrospective systems and have already been shown to perform far worse than our system [5].", "startOffset": 85, "endOffset": 88}, {"referenceID": 4, "context": "We do not perform an in depth comparison on the full systems as defined in [2], [3], [4] as they are retrospective systems and have already been shown to perform far worse than our system [5].", "startOffset": 188, "endOffset": 191}, {"referenceID": 15, "context": "In a variety of natural language tasks, recurrent neural networks (RNNs) have been used to capture meaningful temporal relationships among tokens in a sequence [19], [20], [21], [22].", "startOffset": 160, "endOffset": 164}, {"referenceID": 16, "context": "In a variety of natural language tasks, recurrent neural networks (RNNs) have been used to capture meaningful temporal relationships among tokens in a sequence [19], [20], [21], [22].", "startOffset": 166, "endOffset": 170}, {"referenceID": 17, "context": "In a variety of natural language tasks, recurrent neural networks (RNNs) have been used to capture meaningful temporal relationships among tokens in a sequence [19], [20], [21], [22].", "startOffset": 172, "endOffset": 176}, {"referenceID": 18, "context": "In a variety of natural language tasks, recurrent neural networks (RNNs) have been used to capture meaningful temporal relationships among tokens in a sequence [19], [20], [21], [22].", "startOffset": 178, "endOffset": 182}, {"referenceID": 19, "context": "The problem of vanishing gradients is a key motivation behind the application of the Long Short-Term Memory (LSTM) cell [23], [24], [25], which consists of a state that can be read, written or reset via a set of programmable gates.", "startOffset": 120, "endOffset": 124}, {"referenceID": 20, "context": "The problem of vanishing gradients is a key motivation behind the application of the Long Short-Term Memory (LSTM) cell [23], [24], [25], which consists of a state that can be read, written or reset via a set of programmable gates.", "startOffset": 126, "endOffset": 130}, {"referenceID": 21, "context": "The problem of vanishing gradients is a key motivation behind the application of the Long Short-Term Memory (LSTM) cell [23], [24], [25], which consists of a state that can be read, written or reset via a set of programmable gates.", "startOffset": 132, "endOffset": 136}, {"referenceID": 0, "context": "A binary decision only requires a single value from [0, 1] where 0 is the most benign and 1 is the most DGA.", "startOffset": 52, "endOffset": 58}, {"referenceID": 1, "context": "\u2022 a featureless HMM model3 defined in [2],", "startOffset": 38, "endOffset": 41}, {"referenceID": 1, "context": "\u2022 a random forest DGA classifier using manually-crafted domain features defined in [2], [3], [4], [18].", "startOffset": 83, "endOffset": 86}, {"referenceID": 2, "context": "\u2022 a random forest DGA classifier using manually-crafted domain features defined in [2], [3], [4], [18].", "startOffset": 88, "endOffset": 91}, {"referenceID": 3, "context": "\u2022 a random forest DGA classifier using manually-crafted domain features defined in [2], [3], [4], [18].", "startOffset": 93, "endOffset": 96}, {"referenceID": 14, "context": "\u2022 a random forest DGA classifier using manually-crafted domain features defined in [2], [3], [4], [18].", "startOffset": 98, "endOffset": 102}, {"referenceID": 14, "context": "Note that for the n-gram normality score, we use n = 3, n = 4 and n = 5 as three distinct features as opposed to n = 1, n = 2 and n = 3 as in [18] since the larger n-gram size performed better in preliminary experiments.", "startOffset": 142, "endOffset": 146}, {"referenceID": 14, "context": "In addition, features were trained in a random forest DGA classifier as opposed to a Mahalanobis distance classifier as used in [18] as the random forest DGA classifier produced better results.", "startOffset": 128, "endOffset": 132}, {"referenceID": 1, "context": "There are a few key differences from the HMM presented in [2].", "startOffset": 58, "endOffset": 61}, {"referenceID": 1, "context": "Authors in [2] use a distinct HMM for each family of DGA, while we only create an HMM for the three largest classes of DGAs in the training set.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "Preliminary results showed a significant improvement in ROC over the algorithm presented in [2] when using these updates.", "startOffset": 92, "endOffset": 95}, {"referenceID": 1, "context": "The original HMM algorithm in [2] was presented on only four classes, each with a significant support.", "startOffset": 30, "endOffset": 33}, {"referenceID": 4, "context": "We also compare our results with those of retrospective techniques as reported in [5].", "startOffset": 82, "endOffset": 85}, {"referenceID": 2, "context": "KL Divergence [3], [4] < 0.", "startOffset": 14, "endOffset": 17}, {"referenceID": 3, "context": "KL Divergence [3], [4] < 0.", "startOffset": 19, "endOffset": 22}, {"referenceID": 4, "context": "NXDomains [5] 0.", "startOffset": 10, "endOffset": 13}, {"referenceID": 1, "context": "The results presented in [2] only used a small number of homogenous DGA families (Conficker, Murofet, Bobax and, Sinowal) while the experiments in this paper use over 30 different families.", "startOffset": 25, "endOffset": 28}, {"referenceID": 22, "context": "In contrast, Conficker [28], Murofet [29], Bobax [30] and Sinowal [31] all use a generator that gives a uniform distribution over letters similar to Cryptolocker and ramnit.", "startOffset": 23, "endOffset": 27}, {"referenceID": 23, "context": "In contrast, Conficker [28], Murofet [29], Bobax [30] and Sinowal [31] all use a generator that gives a uniform distribution over letters similar to Cryptolocker and ramnit.", "startOffset": 37, "endOffset": 41}, {"referenceID": 24, "context": "In contrast, Conficker [28], Murofet [29], Bobax [30] and Sinowal [31] all use a generator that gives a uniform distribution over letters similar to Cryptolocker and ramnit.", "startOffset": 49, "endOffset": 53}, {"referenceID": 25, "context": "In contrast, Conficker [28], Murofet [29], Bobax [30] and Sinowal [31] all use a generator that gives a uniform distribution over letters similar to Cryptolocker and ramnit.", "startOffset": 66, "endOffset": 70}, {"referenceID": 26, "context": "Similar to [32], Fig.", "startOffset": 11, "endOffset": 15}, {"referenceID": 26, "context": "9 shows the tanh of a particular LSTM cell\u2019s state (called memory in [32]) as it is updated characterby-character during a prediction task.", "startOffset": 69, "endOffset": 73}, {"referenceID": 26, "context": "We note that our application of LSTMs for DGA classification does not yield quite as clearly the distinctive purpose of states as has been demonstrated for natural language models [32].", "startOffset": 180, "endOffset": 184}, {"referenceID": 26, "context": ", [32].", "startOffset": 2, "endOffset": 6}], "year": 2016, "abstractText": "Various families of malware use domain generation algorithms (DGAs) to generate a large number of pseudo-random domain names to connect to a command and control (C2) server. In order to block DGA C2 traffic, security organizations must first discover the algorithm by reverse engineering malware samples, then generate a list of domains for a given seed. The domains are then either preregistered, sink-holed or published in a DNS blacklist. This process is not only tedious, but can be readily circumvented by malware authors. An alternative approach to stop malware from using DGAs is to intercept DNS queries on a network and predict whether domains are DGA generated. Much of the previous work in DGA detection is based on finding groupings of like domains and using their statistical properties to determine if they are DGA generated. However, these techniques are run over large time windows and cannot be used for real-time detection and prevention. In addition, many of these techniques also use contextual information such as passive DNS and aggregations of all NXDomains throughout a network. Such requirements are not only costly to integrate, they may not be possible due to real-world constraints of many systems (such as endpoint detection). An alternative to these systems is a much harder problem: detect DGA generation on a per domain basis with no information except for the domain name. Previous work to solve this harder problem exhibits poor performance and many of these systems rely heavily on manual creation of features; a time consuming process that can easily be circumvented by malware authors. This paper presents a DGA classifier that leverages long short-term memory (LSTM) networks for real-time prediction of DGAs without the need for contextual information or manually created features. In addition, the presented technique can accurately perform multiclass classification giving the ability to attribute a DGA generated domain to a specific malware family. The technique is extremely easy to implement using open source tools allowing the technique to be deployed in almost any setting. Results are significantly better than all state-of-the-art techniques, providing 0.9993 area under the receiver operating characteristic curve for binary classification and a micro-averaged F1 score of 0.9906. In other terms, the LSTM technique can provide a 90% detection rate with a 1:10000 false positive (FP) rate\u2014a twenty times FP improvement over the next best method. Experiments in this paper are run on open datasets and code snippets are provided to reproduce the results.", "creator": "LaTeX with hyperref package"}}}