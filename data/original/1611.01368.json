{"id": "1611.01368", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Nov-2016", "title": "Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies", "abstract": "The success of long short-term memory (LSTM) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. Linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by LSTMs, which do not have explicit structural representations? We begin addressing this question using number agreement in English subject-verb dependencies. We probe the architecture's grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. In the strongly supervised settings, the LSTM achieved very high overall accuracy (less than 1% errors), but errors increased when sequential and structural information conflicted. The frequency of such errors rose sharply in the language-modeling setting. We conclude that LSTMs can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufficient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured.", "histories": [["v1", "Fri, 4 Nov 2016 13:36:32 GMT  (777kb,D)", "http://arxiv.org/abs/1611.01368v1", "15 pages; to appear in Transactions of the Association for Computational Linguistics"]], "COMMENTS": "15 pages; to appear in Transactions of the Association for Computational Linguistics", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["tal linzen", "emmanuel dupoux", "yoav goldberg"], "accepted": true, "id": "1611.01368"}, "pdf": {"name": "1611.01368.pdf", "metadata": {"source": "CRF", "title": "Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies", "authors": ["Tal Linzen", "Emmanuel Dupoux"], "emails": ["emmanuel.dupoux}@ens.fr", "yoav.goldberg@gmail.com"], "sections": [{"heading": null, "text": "The success of long short-term memory (LSTM) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. Linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by LSTMs, which do not have explicit structural representations? We begin addressing this question using number agreement in English subject-verb dependencies. We probe the architecture\u2019s grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. In the strongly supervised settings, the LSTM achieved very high overall accuracy (less than 1% errors), but errors increased when sequential and structural information conflicted. The frequency of such errors rose sharply in the language-modeling setting. We conclude that LSTMs can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufficient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured."}, {"heading": "1 Introduction", "text": "Recurrent neural networks (RNNs) are highly effective models of sequential data (Elman, 1990). The rapid adoption of RNNs in NLP systems in recent years, in particular of RNNs with gating mechanisms such as long short-term memory (LSTM) units\n(Hochreiter and Schmidhuber, 1997) or gated recurrent units (GRU) (Cho et al., 2014), has led to significant gains in language modeling (Mikolov et al., 2010; Sundermeyer et al., 2012), parsing (Vinyals et al., 2015; Kiperwasser and Goldberg, 2016; Dyer et al., 2016), machine translation (Bahdanau et al., 2015) and other tasks.\nThe effectiveness of RNNs1 is attributed to their ability to capture statistical contingencies that may span an arbitrary number of words. The word France, for example, is more likely to occur somewhere in a sentence that begins with Paris than in a sentence that begins with Penguins. The fact that an arbitrary number of words can intervene between the mutually predictive words implies that they cannot be captured by models with a fixed window such as n-gram models, but can in principle be captured by RNNs, which do not have an architecturally fixed limit on dependency length.\nRNNs are sequence models: they do not explicitly incorporate syntactic structure. Indeed, many word co-occurrence statistics can be captured by treating the sentence as an unstructured list of words (ParisFrance); it is therefore unsurprising that RNNs can learn them well. Other dependencies, however, are sensitive to the syntactic structure of the sentence (Chomsky, 1965; Everaert et al., 2015). To what extent can RNNs learn to model such phenomena based only on sequential cues?\nPrevious research has shown that RNNs (in particular LSTMs) can learn artificial context-free languages (Gers and Schmidhuber, 2001) as well as nesting and\n1In this work we use the term RNN to refer to the entire class of sequential recurrent neural networks. Instances of the class include long short-term memory networks (LSTM) and the Simple Recurrent Network (SRN) due to Elman (1990).\nar X\niv :1\n61 1.\n01 36\n8v 1\n[ cs\n.C L\n] 4\nN ov\n2 01\nindentation in a programming language (Karpathy et al., 2016). The goal of the present work is to probe their ability to learn natural language hierarchical (syntactic) structures from a corpus without syntactic annotations. As a first step, we focus on a particular dependency that is commonly regarded as evidence for hierarchical structure in human language: English subject-verb agreement, the phenomenon in which the form of a verb depends on whether the subject is singular or plural (the kids play but the kid plays; see additional details in Section 2). If an RNN-based model succeeded in learning this dependency, that would indicate that it can learn to approximate or even faithfully implement syntactic structure.\nOur main interest is in whether LSTMs have the capacity to learn structural dependencies from a natural corpus. We therefore begin by addressing this question under the most favorable conditions: training with explicit supervision. In the setting with the strongest supervision, which we refer to as the number prediction task, we train it directly on the task of guessing the number of a verb based on the words that preceded it (Sections 3 and 4). We further experiment with a grammaticality judgment training objective, in which we provide the model with full sentences annotated as to whether or not they violate subject-verb number agreement, without an indication of the locus of the violation (Section 5). Finally, we trained the model without any grammatical supervision, using a language modeling objective (predicting the next word).\nOur quantitative results (Section 4) and qualitative analysis (Section 7) indicate that most naturally occurring agreement cases in the Wikipedia corpus are easy: they can be resolved without syntactic information, based only on the sequence of nouns preceding the verb. This leads to high overall accuracy in all models. Most of our experiments focus on the supervised number prediction model. The accuracy of this model was lower on harder cases, which require the model to encode or approximate structural information; nevertheless, it succeeded in recovering the majority of agreement cases even when four nouns of the opposite number intervened between the subject and the verb (17% errors). Baseline models failed spectacularly on these hard cases, performing far below chance levels. Fine-grained analysis revealed that mistakes are much more common when no overt cues\nto syntactic structure (in particular function words) are available, as is the case in noun-noun compounds and reduced relative clauses. This indicates that the number prediction model indeed managed to capture a decent amount of syntactic knowledge, but was overly reliant on function words.\nError rates increased only mildly when we switched to more indirect supervision consisting only of sentence-level grammaticality annotations without an indication of the crucial verb. By contrast, the language model trained without explicit grammatical supervision performed worse than chance on the harder agreement prediction cases. Even a state-ofthe-art large-scale language model (Jozefowicz et al., 2016) was highly sensitive to recent but structurally irrelevant nouns, making more than five times as many mistakes as the number prediction model on these harder cases. These results suggest that explicit supervision is necessary for learning the agreement dependency using this architecture, limiting its plausibility as a model of child language acquisition (Elman, 1990). From a more applied perspective, this result suggests that for tasks in which it is desirable to capture syntactic dependencies (e.g., machine translation or language generation), language modeling objectives should be supplemented by supervision signals that directly capture the desired behavior."}, {"heading": "2 Background: Subject-Verb Agreement as Evidence for Syntactic Structure", "text": "The form of an English third-person present tense verb depends on whether the head of the syntactic subject is plural or singular:2\n(1) a. The key is on the table. b. *The key are on the table. c. *The keys is on the table. d. The keys are on the table.\nWhile in these examples the subject\u2019s head is adjacent to the verb, in general the two can be separated by some sentential material:3\n2 Identifying the head of the subject is typically straightforward. In what follows we will use the shorthand \u201cthe subject\u201d to refer to the head of the subject.\n3In the examples, the subject and the corresponding verb are marked in boldface, agreement attractors are underlined and intervening nouns of the same number as the subject are marked in italics. Asterisks mark unacceptable sentences.\n(2) The keys to the cabinet are on the table.\nGiven a syntactic parse of the sentence and a verb, it is straightforward to identify the head of the subject that corresponds to that verb, and use that information to determine the number of the verb (Figure 1).\nBy contrast, models that are insensitive to structure may run into substantial difficulties capturing this dependency. One potential issue is that there is no limit to the complexity of the subject NP, and any number of sentence-level modifiers and parentheticals\u2014and therefore an arbitrary number of words\u2014can appear between the subject and the verb:\n(3) The building on the far right that\u2019s quite old and run down is the Kilgore Bank Building.\nThis property of the dependency entails that it cannot be captured by an n-gram model with a fixed n. RNNs are in principle able to capture dependencies of an unbounded length; however, it is an empirical question whether or not they will learn to do so in practice when trained on a natural corpus.\nA more fundamental challenge that the dependency poses for structure-insensitive models is the possibility of agreement attraction errors (Bock and Miller, 1991). The correct form in (3) could be selected using simple heuristics such as \u201cagree with the most recent noun\u201d, which are readily available to sequence models. In general, however, such heuristics are unreliable, since other nouns can intervene between the subject and the verb in the linear sequence of the sentence. Those intervening nouns can have the same number as the subject, as in (4), or the opposite number as in (5)-(7):\n(4) Alluvial soils carried in the floodwaters add nutrients to the floodplains.\n(5) The only championship banners that are currently displayed within the building are for national or NCAA Championships.\n(6) The length of the forewings is 12-13.\n(7) Yet the ratio of men who survive to the women and children who survive is not clear in this story.\nIntervening nouns with the opposite number from the subject are called agreement attractors. The potential presence of agreement attractor entails that the model must identify the head of the syntactic subject that corresponds to a given verb in order to choose the correct inflected form of that verb.\nGiven the difficulty in identifying the subject from the linear sequence of the sentence, dependencies such as subject-verb agreement serve as an argument for structured syntactic representations in humans (Everaert et al., 2015); they may challenge models such as RNNs that do not have pre-wired syntactic representations. We note that subject-verb number agreement is only one of a number of structuresensitive dependencies; other examples include negative polarity items (e.g., any) and reflexive pronouns (herself ). Nonetheless, a model\u2019s success in learning subject-verb agreement would be highly suggestive of its ability to master hierarchical structure."}, {"heading": "3 The Number Prediction Task", "text": "To what extent can a sequence model learn to be sensitive to the hierarchical structure of natural language? To study this question, we propose the number prediction task. In this task, the model sees the sentence up to but not including a present-tense verb, e.g.:\n(8) The keys to the cabinet\nIt then needs to guess the number of the following verb (a binary choice, either PLURAL or SINGULAR). We examine variations on this task in Section 5.\nIn order to perform well on this task, the model needs to encode the concepts of syntactic number and syntactic subjecthood: it needs to learn that some words are singular and others are plural, and to be able to identify the correct subject. As we have illus-\ntrated in Section 2, correctly identifying the subject that corresponds to a particular verb often requires sensitivity to hierarchical syntax.\nData: An appealing property of the number prediction task is that we can generate practically unlimited training and testing examples for this task by querying a corpus for sentences with present-tense verbs, and noting the number of the verb. Importantly, we do not need to correctly identify the subject in order to create a training or test example. We generated a corpus of \u223c1.35 million number prediction problems based on Wikipedia, of which \u223c121,500 (9%) were used for training, \u223c13,500 (1%) for validation, and the remaining \u223c1.21 million (90%) were reserved for testing.4 The large number of test sentences was necessary to ensure that we had a good variety of test sentences representing less common constructions (see Section 4).5\nModel and baselines: We encode words as onehot vectors: the model does not have access to the characters that make up the word. Those vectors are then embedded into a 50-dimensional vector space. An LSTM with 50 hidden units reads those embedding vectors in sequence; the state of the LSTM at the end of the sequence is then fed into a logistic regression classifier. The network is trained6 in an end-to-end fashion, including the word embeddings.7\nTo isolate the effect of syntactic structure, we also consider a baseline which is exposed only to the nouns in the sentence, in the order in which they appeared originally, and is then asked to predict the number of the following verb. The goal of this base-\n4We limited our search to sentences that were shorter than 50 words. Whenever a sentence had more than one subject-verb dependency, we selected one of the dependencies at random.\n5Code and data are available at http://tallinzen. net/projects/lstm_agreement.\n6The network was optimized using Adam (Kingma and Ba, 2015) and early stopping based on validation set error. We trained the number prediction model 20 times with different random initializations, and report accuracy averaged across all runs. The models described in Sections 5 and 6 are based on 10 runs, with the exception of the language model, which is slower to train and was trained once.\n7The size of the vocabulary was capped at 10000 (after lowercasing). Infrequent words were replaced with their part of speech (Penn Treebank tagset, which explicitly encodes number distinctions); this was the case for 9.6% of all tokens and 7.1% of the subjects.\nline is to withhold the syntactic information carried by function words, verbs and other parts of speech. We explore two variations on this baseline: one that only receives common nouns (dogs, pipe), and another that also receives pronouns (he) and proper nouns (France). We refer to these as the noun-only baselines."}, {"heading": "4 Number Prediction Results", "text": "Overall accuracy: Accuracy was very high overall: the system made an incorrect number prediction only in 0.83% of the dependencies. The noun-only baselines performed significantly worse: 4.2% errors for the common-nouns case and 4.5% errors for the all-nouns case. This suggests that function words, verbs and other syntactically informative elements play an important role in the model\u2019s ability to correctly predict the verb\u2019s number. However, while the noun-only baselines made more than four times as many mistakes as the number prediction system, their still-low absolute error rate indicates that around 95% of agreement dependencies can be captured based solely on the sequence of nouns preceding the verb. This is perhaps unsurprising: sentences are often short and the verb is often directly adjacent to the subject, making the identification of the subject simple. To gain deeper insight into the syntactic capabilities of the model, then, the rest of this section investigates its performance on more challenging dependencies.8\nDistance: We first examine whether the network shows evidence of generalizing to dependencies where the subject and the verb are far apart. We focus in this analysis on simpler cases where no nouns intervened between the subject and the verb. As Figure 2a shows, performance did not degrade considerably when the distance between the subject and the verb grew up to 15 words (there were very few longer dependencies). This indicates that the network generalized the dependency from the common distances of 0 and 1 to rare distances of 10 and more.\nAgreement attractors: We next examine how the model\u2019s error rate was affected by nouns that intervened between the subject and the verb in the linear\n8These properties of the dependencies were identified by parsing the test sentences using the parser described in Goldberg and Nivre (2012).\n(e-f) Additional plots: (e) count of attractors per dependency in the corpus (note that the y-axis is on a log scale); (f) embeddings of singular and plural nouns, projected onto their first two principal components.\norder of the sentence. We first focus on whether or not there were any intervening nouns, and if there were, whether the number of the subject differed from the number of the last intervening noun\u2014the type of noun that would trip up the simple heuristic of agreeing with the most recent noun.\nAs Figure 2b shows, a last intervening noun of the same number as the subject increased error rates only moderately, from 0.4% to 0.7% in singular subjects and from 1% to 1.4% in plural subjects. On the other hand, when the last intervening noun was an agreement attractor, error rates increased by almost an order of magnitude (to 6.5% and 5.4% respectively). Note, however, that even an error rate of 6.5% is quite impressive considering uninformed strategies such as random guessing (50% error rate), always assigning the more common class label (32% error rate, since 32% of the subjects in our corpus are plural) and the number-of-most-recent-noun heuristic (100% error rate). The noun-only LSTM baselines performed much worse in agreement attraction cases, with error rates of 46.4% (common nouns) and 40% (all nouns).\nWe next tested whether the effect of attractors is cumulative, by focusing on dependencies with multiple attractors. To avoid cases in which the effect of an attractor is offset by an intervening noun with the same number as the subject, we restricted our search to dependencies in which all of the intervening nouns had the same number, which we term dependencies with homogeneous intervention. For example, (9) has homogeneous intervention whereas (10) does not:\n(9) The roses in the vase by the door are red.\n(10) The roses in the vase by the chairs are red.\nFigure 2c shows that error rates increased gradually as more attractors intervened between the subject and the verb. Performance degraded quite slowly, however: even with four attractors the error rate was only 17.6%. As expected, the noun-only baselines performed significantly worse in this setting, reaching an error rate of up to 84% (worse than chance) in the case of four attractors. This confirms that syntactic cues are critical for solving the harder cases.\nRelative clauses: We now look in greater detail into the network\u2019s performance when the words that intervened between the subject and verb contained a relative clause. Relative clauses with attractors are likely to be fairly challenging, for several reasons. They typically contain a verb that agrees with the attractor, reinforcing the misleading cue to noun number. The attractor is often itself a subject of an irrelevant verb, making a potential \u201cagree with the most recent subject\u201d strategy unreliable. Finally, the existence of a relative clause is sometimes not overtly indicated by a function word (relativizer), as in (11) (for comparison, see the minimally different (12)):\n(11) The landmarks this article lists here are also run-of-the-mill and not notable.\n(12) The landmarks that this article lists here are also run-of-the-mill and not notable.\nFor data sparsity reasons we restricted our attention to dependencies with a single attractor and no other intervening nouns. As Figure 2d shows, attraction errors were more frequent in dependencies with an overt relative clause (9.9% errors) than in dependencies without a relative clause (3.2%), and considerably more frequent when the relative clause was not introduced by an overt relativizer (25%). As in the case of multiple attractors, however, while the model struggled with the more difficult dependencies, its performance was much better than random guessing, and slightly better than a majority-class strategy.\nWord representations: We explored the 50- dimensional word representations acquired by the model by performing a principal component analysis. We assigned a part-of-speech (POS) to each word based on the word\u2019s most common POS in the corpus. We only considered relatively ambiguous words, in which a single POS accounted for more than 90% of the word\u2019s occurrences in the corpus. Figure 2f shows that the first principal component corresponded almost perfectly to the expected number of the noun, suggesting that the model learned the number of specific words very well; recall that the model did not have access during training to noun number annotations or to morphological suffixes such as -s that could be used to identify plurals.\nVisualizing the network\u2019s activations: We start investigating the inner workings of the number prediction network by analyzing its activation in response to particular syntactic constructions. To simplify the analysis, we deviate from our practice in the rest of this paper and use constructed sentences.\nWe first constructed sets of sentence prefixes based on the following patterns:\n(13) PP: The toy(s) of the boy(s)...\n(14) RC: The toy(s) that the boy(s)...\nThese patterns differ by exactly one function word, which determines the type of the modifier of the main clause subject: a prepositional phrase (PP) in the first sentence and a relative clause (RC) in the second. In PP sentences the correct number of the upcoming verb is determined by the main clause subject toy(s); in RC sentences it is determined by the embedded subject boy(s).\nWe generated all four versions of each pattern, and repeated the process ten times with different lexical items (the house(s) of/that the girl(s), the computer(s) of/that the student(s), etc.), for a total of 80 sentences. The network made correct number predictions for all 40 PP sentences, but made three errors in RC sentences. We averaged the word-by-word activations across all sets of ten sentences that had the same combination of modifier (PP or RC), first noun number and second noun number. Plots of the activation of all 50 units are provided in the Appendix (Figure 5). Figure 3a highlights a unit (Unit 1) that shows a particularly clear pattern: it tracks the number of the main clause subject throughout the PP modifier, resets when it reaches the relativizer that which introduces the RC modifier, and then switches to tracking the number of the embedded subject.\nTo explore how the network deals with dependencies spanning a larger number of words, we tracked its activation during the processing of the following two sentences:9\n(15) The houses of/that the man from the office across the street...\nThe network made the correct prediction for the PP 9We simplified this experiment in light of the relative robustness of the first experiment to lexical items and to whether each of the nouns was singular or plural.\nbut not the RC sentence (as before, the correct predictions are PLURAL for PP and SINGULAR for RC). Figure 3b shows that the network begins by making the correct prediction for RC immediately after that, but then falters: as the sentence goes on, the resetting effect of that diminishes. The activation time courses shown in Figure 3c illustrate that Unit 1, which identified the subject correctly when the prefix was short, gradually forgets that it is in an embedded clause as the prefix grows longer. By contrast, Unit 0 shows a stable capacity to remember the current embedding status. Additional representative units shown in Figure 3c are Unit 46, which consistently stores the number of the main clause subject, and Unit 27, which tracks the number of the most recent noun, resetting at noun phrase boundaries.\nWhile the interpretability of these patterns is encouraging, our analysis only scratches the surface of the rich possibilities of a linguistically-informed analysis of a neural network trained to perform a syntax-sensitive task; we leave a more extensive investigation for future work."}, {"heading": "5 Alternative Training Objectives", "text": "The number prediction task followed a fully supervised objective, in which the network identifies the number of an upcoming verb based only on the words preceding the verb. This section proposes three objectives that modify some of the goals and assumptions of the number prediction objective (see Table 1 for an overview).\nVerb inflection: This objective is similar to number prediction, with one difference: the network receives not only the words leading up to the verb, but also the singular form of the upcoming verb (e.g., writes). In practice, then, the network needs to decide between the singular and plural forms of a particular verb (writes or write). Having access to the semantics of the verb can help the network identify the noun that serves as its subject without using the syntactic subjecthood criteria. For example, in the following sentence:\n(16) People from the capital often eat pizza.\nonly people is a plausible subject for eat; the network can use this information to infer that the correct form of the verb is eat is rather than eats.\nThis objective is similar to the task that humans face during language production: after the speaker has decided to use a particular verb (e.g., write), he or she needs to decide whether its form will be write or writes (Levelt et al., 1999; Staub, 2009).\nGrammaticality judgments: The previous objectives explicitly indicate the location in the sentence in which a verb can appear, giving the network a cue to syntactic clause boundaries. They also explicitly direct the network\u2019s attention to the number of the verb. As a form of weaker supervision, we experimented with a grammaticality judgment objective. In this scenario, the network is given a complete sentence, and is asked to judge whether or not it is grammatical.\nTo train the network, we made half of the examples in our training corpus ungrammatical by flipping the number of the verb.10 The network read the entire sentence and received a supervision signal at the end. This task is modeled after a common human data collection technique in linguistics (Schu\u0308tze, 1996), although our training regime is of course very different to the training that humans are exposed to: humans rarely receive ungrammatical sentences labeled as such (Bowerman, 1988).\nLanguage modeling (LM): Finally, we experimented with a word prediction objective, in which the model did not receive any grammatically relevant supervision (Elman, 1990; Elman, 1991). In this scenario, the goal of the network is to predict the next word at each point in every sentence. It receives unlabeled sentences and is not specifically instructed to\n10In some sentences this will not in fact result in an ungrammatical sentence, e.g. with collective nouns such as group, which are compatible with both singular and plural verbs in some dialects of English (Huddleston and Pullum, 2002); those cases appear to be rare.\nattend to the number of the verb. In the network that implements this training scenario, RNN activation after each word is fed into a fully connected dense layer followed by a softmax layer over the entire vocabulary.\nWe evaluate the knowledge that the network has acquired about subject-verb noun agreement using a task similar to the verb inflection task. To perform the task, we compare the probabilities that the model assigns to the two forms of the verb that in fact occurred in the corpus (e.g., write and writes), and select the form with the higher probability.11 As this task is not part of the network\u2019s training objective, and the model needs to allocate considerable resources to predicting each word in the sentence, we expect the LM to perform worse than the explicitly supervised objectives.\nResults: When considering all agreement dependencies, all models achieved error rates below 7% (Figure 4a); as mentioned above, even the noun-only number prediction baselines achieved error rates below 5% on this task. At the same time, there were large differences in accuracy across training objectives. The verb inflection network performed slightly but significantly better than the number prediction one (0.8% compared to 0.83% errors), suggesting that the semantic information carried by the verb is moderately helpful. The grammaticality judgment objective performed somewhat worse, at 2.5% errors, but still outperformed the noun-only baselines by a large margin, showing the capacity of the LSTM architecture to learn syntactic dependencies even given fairly indirect evidence.\nThe worst performer was the language model. It\n11One could also imagine performing the equivalent of the number prediction task by aggregating LM probability mass over all plural verbs and all singular verbs. This approach may be more severely affected by part-of-speech ambiguous words than the one we adopted; we leave the exploration of this approach to future work.\nmade eight times as many errors as the original number prediction network (6.78% compared to 0.83%), and did substantially worse than the noun-only baselines (though recall that the noun-only baselines were still explicitly trained to predict verb number).\nThe differences across the networks are more striking when we focus on dependencies with agreement attractors (Figure 4b). Here, the language model does worse than chance in the most difficult cases, and only slightly better than the noun-only baselines. The worse-than-chance performance suggests that attractors actively confuse the networks rather than cause them to make a random decision. The other models degrade more gracefully with the number of agreement attractors; overall, the grammaticality judgment objective is somewhat more difficult than the number prediction and verb inflection ones. In summary, we conclude that while the LSTM is capable of learning syntax-sensitive agreement dependencies under various objectives, the language-modeling objective alone is not sufficient for learning such dependencies, and a more direct form of training signal\nis required.\nComparison to a large-scale language model: One objection to our language modeling result is that our LM faced a much harder objective than our other models\u2014predicting a distribution over 10,000 vocabulary items is certainly harder than binary classification\u2014but was equipped with the same capacity (50-dimensional hidden state and word vectors). Would the performance gap between the LM and the explicitly supervised models close if we increased the capacity of the LM?\nWe address this question using a very large publicly available LM (Jozefowicz et al., 2016), which we refer to as the Google LM.12 The Google LM represent the current state-of-the-art in language modeling: it is trained on a billion-word corpus (Chelba et al., 2013), with a vocabulary of 800,000 words. It is based on a two-layer LSTM with 8192 units in each layer, or more than 300 times as many units as our LM; at 1.04 billion parameters it has almost\n12 https://github.com/tensorflow/models/ tree/master/lm_1b\n2000 times as many parameters. It is a fine-tuned language model that achieves impressive perplexity scores on common benchmarks, requires a massive infrastructure for training, and pushes the boundaries of what\u2019s feasible with current hardware.\nWe tested the Google LM with the methodology we used to test ours.13 Due to computational resource limitations, we did not evaluate it on the entire test set, but sampled a random selection of 500 sentences for each count of attractors (testing a single sentence under the Google LM takes around 5 seconds on average). The results are presented in Figure 4c, where they are compared to the performance of the supervised verb inflection system. Despite having an order of magnitude more parameters and significantly larger training data, the Google LM performed poorly compared to the supervised models; even a single attractor led to a sharp increase in error rate to 28.5%, almost as high as our small-scale LM (32.6% on the same sentences). While additional attractors caused milder degradation than in our LM, the performance of the Google LM on sentences with four attractors was still worse than always guessing the majority class (SINGULAR).\nIn summary, our experiments with the Google LM do not change our conclusions: the contrast between the poor performance of the LMs and the strong performance of the explicitly supervised objectives suggests that direct supervision has a dramatic effect on the model\u2019s ability to learn syntax-sensitive dependencies. Given that the Google LM was already trained on several hundred times more data than the number prediction system, it appears unlikely that its relatively poor performance was due to lack of training data."}, {"heading": "6 Additional Experiments", "text": "Comparison to simple recurrent networks: How much of the success of the network is due to the LSTM cells? We repeated the number prediction experiment with a simple recurrent network (SRN) (Elman, 1990), with the same number of hidden units. The SRN\u2019s performance was inferior to the LSTM\u2019s, but the average performance for a given\n13One technical exception was that we did not replace lowfrequency words with their part-of-speech, since the Google LM is a large-vocabulary language model, and does not have parts-of-speech as part of its vocabulary.\nnumber of agreement attractors does not suggest a qualitative difference between the cell types: the SRN makes about twice as many errors as the LSTM across the board (Figure 4d).\nTraining only on difficult dependencies: Only a small proportion of the dependencies in the corpus had agreement attractors (Figure 2e). Would the network generalize better if dependencies with intervening nouns were emphasized during training? We repeated our number prediction experiment, this time training the model only on dependencies with at least one intervening noun (of any number). We doubled the proportion of training sentences to 20%, since the total size of the corpus was smaller (226K dependencies).\nThis training regime resulted in a 27% decrease in error rate on dependencies with exactly one attractor (from 4.1% to 3.0%). This decrease is statistically significant, and encouraging given that total number of dependencies in training was much lower, which complicates the learning of word embeddings. Error rates mildly decreased in dependencies with more attractors as well, suggesting some generalization (Figure 4d). Surprisingly, a similar experiment using the grammaticality judgment task led to a slight increase in error rate. While tentative at this point, these results suggest that oversampling difficult training cases may be beneficial; a curriculum progressing from easier to harder dependencies (Elman, 1993) may provide additional gains."}, {"heading": "7 Error Analysis", "text": "Singular vs. plural subjects: Most of the nouns in English are singular: in our corpus, the fraction of singular subjects is 68%. Agreement attraction errors in humans are much more common when the attractor is plural than when it is singular (Bock and Miller, 1991; Eberhard et al., 2005). Do our models\u2019 error rates depend on the number of the subject?\nAs Figure 2b shows, our LSTM number prediction model makes somewhat more agreement attraction errors with plural than with singular attractors; the difference is statistically significant, but the asymmetry is much less pronounced than in humans. Interestingly, the SRN version of the model does show a large asymmetry, especially as the count of attractors increases; with four plural attractors the error rate\nreaches 60% (Figure 4e).\nQualitative analysis: We manually examined a sample of 200 cases in which the majority of the 20 runs of the number prediction network made the wrong prediction. There were only 8890 such dependencies (about 0.6%). Many of those were straightforward agreement attraction errors; others were difficult to interpret. We mention here three classes of errors that can motivate future experiments.\nThe networks often misidentified the heads of noun-noun compounds. In (17), for example, the models predict a singular verb even though the number of the subject conservation refugees should be determined by its head refugees. This suggests that the networks didn\u2019t master the structure of English noun-noun compounds.14\n(17) Conservation refugees live in a world colored in shades of gray; limbo.\n(18) Information technology (IT) assets commonly hold large volumes of confidential data.\nSome verbs that are ambiguous with plural nouns seem to have been misanalyzed as plural nouns and consequently act as attractors. The models predicted a plural verb in the following two sentences even though neither of them has any plural nouns, possibly because of the ambiguous verbs drives and lands:\n(19) The ship that the player drives has a very high speed.\n(20) It was also to be used to learn if the area where the lander lands is typical of the surrounding terrain.\nOther errors appear to be due to difficulty not in identifying the subject but in determining whether it is plural or singular. In Example (22), in particular, there is very little information in the left context of the subject 5 paragraphs suggesting that the writer considers it to be singular:\n(21) Rabaul-based Japanese aircraft make three dive-bombing attacks.\n14The dependencies are presented as they appeared in the corpus; the predicted number was the opposite of the correct one (e.g., singular in (17), where the original is plural).\n(22) The lead is also rather long; 5 paragraphs is pretty lengthy for a 62 kilobyte article.\nThe last errors point to a limitation of the number prediction task, which jointly evaluates the model\u2019s ability to identify the subject and its ability to assign the correct number to noun phrases."}, {"heading": "8 Related Work", "text": "The majority of NLP work on neural networks evaluates them on their performance in a task such as language modeling or machine translation (Sundermeyer et al., 2012; Bahdanau et al., 2015). These evaluation setups average over many different syntactic constructions, making it difficult to isolate the network\u2019s syntactic capabilities.\nOther studies have tested the capabilities of RNNs to learn simple artificial languages. Gers and Schmidhuber (2001) showed that LSTMs can learn the context-free language anbn, generalizing to ns as high as 1000 even when trained only on n \u2208 {1, . . . , 10}. Simple recurrent networks struggled with this language (Rodriguez et al., 1999; Rodriguez, 2001). These results have been recently replicated and extended by Joulin and Mikolov (2015).\nElman (1991) tested an SRN on a miniature language that simulated English relative clauses, and found that the network was only able to learn the language under highly specific circumstances (Elman, 1993), though later work has called some of his conclusions into question (Rohde and Plaut, 1999; Cartling, 2008). Frank et al. (2013) studied the acquisition of anaphora coreference by SRNs, again in a miniature language. Recently, Bowman et al. (2015) tested the ability of LSTMs to learn an artificial language based on propositional logic. As in our study, the performance of the network degraded as the complexity of the test sentences increased.\nKarpathy et al. (2016) present analyses and visualization methods for character-level RNNs. Ka\u0301da\u0301r et al. (2016) and Li et al. (2016) suggest visualization techniques for word-level RNNs trained to perform tasks that aren\u2019t explicitly syntactic (image captioning and sentiment analysis).\nEarly work that used neural networks to model grammaticality judgments includes Allen and Seidenberg (1999) and Lawrence et al. (1996). More recently, the connection between grammaticality judg-\nments and the probabilities assigned by a language model was explored by Clark et al. (2013) and Lau et al. (2015). Finally, arguments for evaluating NLP models on a strategically sampled set of dependency types rather than a random sample of sentences have been made in the parsing literature (Rimell et al., 2009; Nivre et al., 2010; Bender et al., 2011)."}, {"heading": "9 Discussion and Future Work", "text": "Neural network architectures are typically evaluated on random samples of naturally occurring sentences, e.g., using perplexity on held-out data in language modeling. Since the majority of natural language sentence are grammatically simple, models can achieve high overall accuracy using flawed heuristics that fail on harder cases. This makes it difficult to distinguish simple but robust sequence models from more expressive architectures (Socher, 2014; Grefenstette et al., 2015; Joulin and Mikolov, 2015). Our work suggests an alternative strategy\u2014evaluation on naturally occurring sentences that are sampled based on their grammatical complexity\u2014which can provide more nuanced tests of language models (Rimell et al., 2009; Bender et al., 2011).\nThis approach can be extended to the training stage: neural networks can be encouraged to develop more sophisticated generalizations by oversampling grammatically challenging training sentences. We took a first step in this direction when we trained the network only on dependencies with intervening nouns (Section 6). This training regime indeed improved the performance of the network; however, the improvement was quantitative rather than qualitative: there was limited generalization to dependencies that were even more difficult than those encountered in training. Further experiments are needed to establish the efficacy of this method.\nA network that has acquired syntactic representations sophisticated enough to handle subject-verb agreement is likely to show improved performance on other structure-sensitive dependencies, including pronoun coreference, quantifier scope and negative polarity items. As such, neural models used in NLP applications may benefit from grammatically sophisticated sentence representations developed in a multitask learning setup (Caruana, 1998), where the model is trained concurrently on the task of interest and on\none of the tasks we proposed in this paper. Of course, grammatical phenomena differ from each other in many ways. The distribution of negative polarity items is highly sensitive to semantic factors (Giannakidou, 2011). Restrictions on unbounded dependencies (Ross, 1967) may require richer syntactic representations than those required for subject-verb dependencies. The extent to which the results of our study will generalize to other constructions and other languages, then, is a matter for empirical research.\nHumans occasionally make agreement attraction mistakes during language production (Bock and Miller, 1991) and comprehension (Nicol et al., 1997). These errors persist in human acceptability judgments (Tanner et al., 2014), which parallel our grammaticality judgment task. Cases of grammatical agreement with the nearest rather than structurally relevant constituent have been documented in languages such as Slovenian (Marus\u030cic\u030c et al., 2007), and have even been argued to be occasionally grammatical in English (Zwicky, 2005). In future work, exploring the relationship between these cases and neural network predictions can shed light on the cognitive plausibility of those networks."}, {"heading": "10 Conclusion", "text": "LSTMs are sequence models; they do not have builtin hierarchical representations. We have investigated how well they can learn subject-verb agreement, a phenomenon that crucially depends on hierarchical syntactic structure. When provided explicit supervision, LSTMs were able to learn to perform the verbnumber agreement task in most cases, although their error rate increased on particularly difficult sentences. We conclude that LSTMs can learn to approximate structure-sensitive dependencies fairly well given explicit supervision, but more expressive architectures may be necessary to eliminate errors altogether. Finally, our results provide evidence that the language modeling objective is not by itself sufficient for learning structure-sensitive dependencies, and suggest that a joint training objective can be used to supplement language models on tasks for which syntax-sensitive dependencies are important."}, {"heading": "Acknowledgments", "text": "We thank Marco Baroni, Grzegorz Chrupa\u0142a, Alexander Clark, Sol Lago, Paul Smolensky, Benjamin Spector and Roberto Zamparelli for comments and discussion. This research was supported by the European Research Council (grant ERC-2011-AdG 295810 BOOTPHON), the Agence Nationale pour la Recherche (grants ANR-10-IDEX-0001-02 PSL and ANR-10-LABX-0087 IEC) and the Israeli Science Foundation (grant number 1555/15)."}], "references": [{"title": "The emergence of grammaticality in connectionist networks", "author": ["Joseph Allen", "Mark S. Seidenberg."], "venue": "Brian MacWhinney, editor, Emergentist approaches to language: Proceedings of the 28th Carnegie symposium on cognition, pages 115\u2013151. Mahwah, NJ:", "citeRegEx": "Allen and Seidenberg.,? 1999", "shortCiteRegEx": "Allen and Seidenberg.", "year": 1999}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "International Conference for Learning Representations.", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Parser evaluation over local and non-local deep dependencies in a large corpus", "author": ["Emily M. Bender", "Dan Flickinger", "Stephan Oepen", "Yi Zhang."], "venue": "Proceedings of EMNLP, pages 397\u2013408.", "citeRegEx": "Bender et al\\.,? 2011", "shortCiteRegEx": "Bender et al\\.", "year": 2011}, {"title": "Broken agreement", "author": ["Kathryn Bock", "Carol A. Miller."], "venue": "Cognitive Psychology, 23(1):45\u201393.", "citeRegEx": "Bock and Miller.,? 1991", "shortCiteRegEx": "Bock and Miller.", "year": 1991}, {"title": "The \u201cno negative evidence\u201d problem: How do children avoid constructing an overly general grammar? In John A", "author": ["Melissa Bowerman."], "venue": "Hawkins, editor, Explaining language universals, pages 73\u2013101. Oxford: Basil Blackwell.", "citeRegEx": "Bowerman.,? 1988", "shortCiteRegEx": "Bowerman.", "year": 1988}, {"title": "Tree-structured composition in neural networks without tree-structured architectures", "author": ["Samuel R. Bowman", "Christopher D. Manning", "Christopher Potts."], "venue": "Proceedings of the NIPS Workshop on Cognitive Computation: Integrating Neural and Symbolic", "citeRegEx": "Bowman et al\\.,? 2015", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "On the implicit acquisition of a context-free grammar by a simple recurrent neural network", "author": ["Bo Cartling."], "venue": "Neurocomputing, 71(7):1527\u20131537.", "citeRegEx": "Cartling.,? 2008", "shortCiteRegEx": "Cartling.", "year": 2008}, {"title": "Multitask learning", "author": ["Rich Caruana."], "venue": "Sebastian Thrun and Lorien Pratt, editors, Learning to learn, pages 95\u2013133. Boston: Kluwer.", "citeRegEx": "Caruana.,? 1998", "shortCiteRegEx": "Caruana.", "year": 1998}, {"title": "One billion word benchmark for measuring progress in statistical language modeling", "author": ["Ciprian Chelba", "Tomas Mikolov", "Mike Schuster", "Qi Ge", "Thorsten Brants", "Phillipp Koehn", "Tony Robinson."], "venue": "arXiv preprint arXiv:1312.3005.", "citeRegEx": "Chelba et al\\.,? 2013", "shortCiteRegEx": "Chelba et al\\.", "year": 2013}, {"title": "Learning phrase representations using RNN encoder\u2013decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."], "venue": "Proceedings of EMNLP, pages", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Aspects of the Theory of Syntax", "author": ["Noam Chomsky."], "venue": "Cambridge, MA: MIT press.", "citeRegEx": "Chomsky.,? 1965", "shortCiteRegEx": "Chomsky.", "year": 1965}, {"title": "Statistical representation of grammaticality judgements: The limits of n-gram models", "author": ["Alexander Clark", "Gianluca Giorgolo", "Shalom Lappin."], "venue": "Proceedings of the Fourth Annual Workshop on Cognitive Modeling and Computational Linguistics (CMCL), pages", "citeRegEx": "Clark et al\\.,? 2013", "shortCiteRegEx": "Clark et al\\.", "year": 2013}, {"title": "Recurrent neural network grammars", "author": ["Chris Dyer", "Adhiguna Kuncoro", "Miguel Ballesteros", "A. Noah Smith."], "venue": "Proceedings of NAACL/HLT, pages 199\u2013209.", "citeRegEx": "Dyer et al\\.,? 2016", "shortCiteRegEx": "Dyer et al\\.", "year": 2016}, {"title": "Making syntax of sense: Number agreement in sentence production", "author": ["Kathleen M. Eberhard", "J. Cooper Cutting", "Kathryn Bock."], "venue": "Psychological Review, 112(3):531\u2013559.", "citeRegEx": "Eberhard et al\\.,? 2005", "shortCiteRegEx": "Eberhard et al\\.", "year": 2005}, {"title": "Finding structure in time", "author": ["Jeffrey L. Elman."], "venue": "Cognitive Science, 14(2):179\u2013211.", "citeRegEx": "Elman.,? 1990", "shortCiteRegEx": "Elman.", "year": 1990}, {"title": "Distributed representations, simple recurrent networks, and grammatical structure", "author": ["Jeffrey L. Elman."], "venue": "Machine Learning, 7(2-3):195\u2013225.", "citeRegEx": "Elman.,? 1991", "shortCiteRegEx": "Elman.", "year": 1991}, {"title": "Learning and development in neural networks: The importance of starting small", "author": ["Jeffrey L. Elman."], "venue": "Cognition, 48(1):71\u201399.", "citeRegEx": "Elman.,? 1993", "shortCiteRegEx": "Elman.", "year": 1993}, {"title": "Structures, not strings: Linguistics as part of the cognitive sciences", "author": ["Martin B.H. Everaert", "Marinus A.C. Huybregts", "Noam Chomsky", "Robert C. Berwick", "Johan J. Bolhuis."], "venue": "Trends in Cognitive Sciences, 19(12):729\u2013743.", "citeRegEx": "Everaert et al\\.,? 2015", "shortCiteRegEx": "Everaert et al\\.", "year": 2015}, {"title": "The acquisition of anaphora by simple recurrent networks", "author": ["Robert Frank", "Donald Mathis", "William Badecker."], "venue": "Language Acquisition, 20(3):181\u2013227.", "citeRegEx": "Frank et al\\.,? 2013", "shortCiteRegEx": "Frank et al\\.", "year": 2013}, {"title": "LSTM recurrent networks learn simple context-free and contextsensitive languages", "author": ["Felix Gers", "J\u00fcrgen Schmidhuber."], "venue": "IEEE Transactions on Neural Networks, 12(6):1333\u20131340.", "citeRegEx": "Gers and Schmidhuber.,? 2001", "shortCiteRegEx": "Gers and Schmidhuber.", "year": 2001}, {"title": "Negative and positive polarity items: Variation, licensing, and compositionality", "author": ["Anastasia Giannakidou."], "venue": "Claudia Maienborn, Klaus von Heusinger, and Paul Portner, editors, Semantics: An international handbook of natural language meaning. Berlin: Mouton de", "citeRegEx": "Giannakidou.,? 2011", "shortCiteRegEx": "Giannakidou.", "year": 2011}, {"title": "A dynamic oracle for arc-eager dependency parsing", "author": ["Yoav Goldberg", "Joakim Nivre."], "venue": "Proceedings of COLING 2012, pages 959\u2013976.", "citeRegEx": "Goldberg and Nivre.,? 2012", "shortCiteRegEx": "Goldberg and Nivre.", "year": 2012}, {"title": "Learning to transduce with unbounded memory", "author": ["Edward Grefenstette", "Karl Moritz Hermann", "Mustafa Suleyman", "Phil Blunsom."], "venue": "Advances in Neural Information Processing Systems, pages 1828\u20131836.", "citeRegEx": "Grefenstette et al\\.,? 2015", "shortCiteRegEx": "Grefenstette et al\\.", "year": 2015}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural Computation, 9(8):1735\u2013 1780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "The Cambridge Grammar of the English Language", "author": ["Rodney Huddleston", "Geoffrey K. Pullum."], "venue": "Cambridge University Press, Cambridge.", "citeRegEx": "Huddleston and Pullum.,? 2002", "shortCiteRegEx": "Huddleston and Pullum.", "year": 2002}, {"title": "Inferring algorithmic patterns with stack-augmented recurrent nets", "author": ["Armand Joulin", "Tomas Mikolov."], "venue": "Advances in Neural Information Processing Systems, pages 190\u2013198.", "citeRegEx": "Joulin and Mikolov.,? 2015", "shortCiteRegEx": "Joulin and Mikolov.", "year": 2015}, {"title": "Exploring the limits of language modeling", "author": ["Rafal Jozefowicz", "Oriol Vinyals", "Mike Schuster", "Noam Shazeer", "Yonghui Wu."], "venue": "arXiv preprint arXiv:1602.02410.", "citeRegEx": "Jozefowicz et al\\.,? 2016", "shortCiteRegEx": "Jozefowicz et al\\.", "year": 2016}, {"title": "Representation of linguistic form and function in recurrent neural networks", "author": ["\u00c1kos K\u00e1d\u00e1r", "Grzegorz Chrupa\u0142a", "Afra Alishahi."], "venue": "arXiv preprint arXiv:1602.08952.", "citeRegEx": "K\u00e1d\u00e1r et al\\.,? 2016", "shortCiteRegEx": "K\u00e1d\u00e1r et al\\.", "year": 2016}, {"title": "Visualizing and understanding recurrent networks", "author": ["Andrej Karpathy", "Justin Johnson", "Fei-Fei Li"], "venue": null, "citeRegEx": "Karpathy et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Karpathy et al\\.", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba."], "venue": "International Conference for Learning Representations.", "citeRegEx": "Kingma and Ba.,? 2015", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "Simple and accurate dependency parsing using bidirectional lstm feature representations", "author": ["Eliyahu Kiperwasser", "Yoav Goldberg."], "venue": "Transactions of the Association of Computational Linguistics, 4:313\u2013327.", "citeRegEx": "Kiperwasser and Goldberg.,? 2016", "shortCiteRegEx": "Kiperwasser and Goldberg.", "year": 2016}, {"title": "Unsupervised prediction of acceptability judgements", "author": ["Jey Han Lau", "Alexander Clark", "Shalom Lappin."], "venue": "Proceedings of ACL/IJCNLP, pages 1618\u20131628.", "citeRegEx": "Lau et al\\.,? 2015", "shortCiteRegEx": "Lau et al\\.", "year": 2015}, {"title": "Can recurrent neural networks learn natural language grammars", "author": ["Steve Lawrence", "Lee C. Giles", "Santliway Fong"], "venue": "In IEEE International Conference on Neural Networks,", "citeRegEx": "Lawrence et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Lawrence et al\\.", "year": 1996}, {"title": "A theory of lexical access in speech production", "author": ["Willem J.M. Levelt", "Ardi Roelofs", "Antje S. Meyer."], "venue": "Behavioral and Brain Sciences, 22(1):1\u201375.", "citeRegEx": "Levelt et al\\.,? 1999", "shortCiteRegEx": "Levelt et al\\.", "year": 1999}, {"title": "Visualizing and understanding neural models in NLP", "author": ["Jiwei Li", "Xinlei Chen", "Eduard H. Hovy", "Dan Jurafsky."], "venue": "Proceedings of NAACL-HLT 2016, pages 681\u2013691.", "citeRegEx": "Li et al\\.,? 2016", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Last-conjunct agreement in Slovenian", "author": ["Franc Maru\u0161i\u010d", "Andrew Nevins", "Amanda Saksida."], "venue": "Annual Workshop on Formal Approaches to Slavic Linguistics, pages 210\u2013227.", "citeRegEx": "Maru\u0161i\u010d et al\\.,? 2007", "shortCiteRegEx": "Maru\u0161i\u010d et al\\.", "year": 2007}, {"title": "Recurrent neural network based language model", "author": ["Tomas Mikolov", "Martin Karafi\u00e1t", "Lukas Burget", "Jan Cernock\u1ef3", "Sanjeev Khudanpur."], "venue": "INTERSPEECH, pages 1045\u20131048.", "citeRegEx": "Mikolov et al\\.,? 2010", "shortCiteRegEx": "Mikolov et al\\.", "year": 2010}, {"title": "Subject\u2013verb agreement processes in comprehension", "author": ["Janet L. Nicol", "Kenneth I. Forster", "Csaba Veres."], "venue": "Journal of Memory and Language, 36(4):569\u2013587.", "citeRegEx": "Nicol et al\\.,? 1997", "shortCiteRegEx": "Nicol et al\\.", "year": 1997}, {"title": "Evaluation of dependency parsers on unbounded dependencies", "author": ["Joakim Nivre", "Laura Rimell", "Ryan McDonald", "Carlos Gomez-Rodriguez."], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics, pages 833\u2013841. Association for Computa-", "citeRegEx": "Nivre et al\\.,? 2010", "shortCiteRegEx": "Nivre et al\\.", "year": 2010}, {"title": "Unbounded dependency recovery for parser evaluation", "author": ["Laura Rimell", "Stephen Clark", "Mark Steedman."], "venue": "Proceedings of EMNLP, pages 813\u2013821.", "citeRegEx": "Rimell et al\\.,? 2009", "shortCiteRegEx": "Rimell et al\\.", "year": 2009}, {"title": "A recurrent neural network that learns to count", "author": ["Paul Rodriguez", "Janet Wiles", "Jeffrey L. Elman."], "venue": "Connection Science, 11(1):5\u201340.", "citeRegEx": "Rodriguez et al\\.,? 1999", "shortCiteRegEx": "Rodriguez et al\\.", "year": 1999}, {"title": "Simple recurrent networks learn context-free and context-sensitive languages by counting", "author": ["Paul Rodriguez."], "venue": "Neural Computation, 13(9):2093\u20132118.", "citeRegEx": "Rodriguez.,? 2001", "shortCiteRegEx": "Rodriguez.", "year": 2001}, {"title": "Language acquisition in the absence of explicit negative evidence: How important is starting small", "author": ["Douglas L.T. Rohde", "David C. Plaut"], "venue": null, "citeRegEx": "Rohde and Plaut.,? \\Q1999\\E", "shortCiteRegEx": "Rohde and Plaut.", "year": 1999}, {"title": "Constraints on variables in syntax", "author": ["John Robert Ross."], "venue": "Ph.D. thesis, MIT.", "citeRegEx": "Ross.,? 1967", "shortCiteRegEx": "Ross.", "year": 1967}, {"title": "The empirical base of linguistics: Grammaticality judgments and linguistic methodology", "author": ["Carson T. Sch\u00fctze."], "venue": "Chicago, IL: University of Chicago Press.", "citeRegEx": "Sch\u00fctze.,? 1996", "shortCiteRegEx": "Sch\u00fctze.", "year": 1996}, {"title": "Recursive Deep Learning for Natural Language Processing and Computer Vision", "author": ["Richard Socher."], "venue": "Ph.D. thesis, Stanford University.", "citeRegEx": "Socher.,? 2014", "shortCiteRegEx": "Socher.", "year": 2014}, {"title": "On the interpretation of the number attraction effect: Response time evidence", "author": ["Adrian Staub."], "venue": "Journal of Memory and Language, 60(2):308\u2013327.", "citeRegEx": "Staub.,? 2009", "shortCiteRegEx": "Staub.", "year": 2009}, {"title": "LSTM neural networks for language modeling", "author": ["Martin Sundermeyer", "Ralf Schl\u00fcter", "Hermann Ney."], "venue": "INTERSPEECH.", "citeRegEx": "Sundermeyer et al\\.,? 2012", "shortCiteRegEx": "Sundermeyer et al\\.", "year": 2012}, {"title": "The time-course of feature interference in agreement comprehension: Multiple mechanisms and asymmetrical attraction", "author": ["Darren Tanner", "Janet Nicol", "Laurel Brehm."], "venue": "Journal of Memory and Language, 76:195\u2013 215.", "citeRegEx": "Tanner et al\\.,? 2014", "shortCiteRegEx": "Tanner et al\\.", "year": 2014}, {"title": "Grammar as a foreign language", "author": ["Oriol Vinyals", "\u0141ukasz Kaiser", "Terry Koo", "Slav Petrov", "Ilya Sutskever", "Geoffrey Hinton."], "venue": "Advances in Neural Information Processing Systems, pages 2755\u20132763.", "citeRegEx": "Vinyals et al\\.,? 2015", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Agreement with nearest always bad? http://itre.cis.upenn.edu/ \u0303myl/ languagelog/archives/001846.html", "author": ["Arnold Zwicky"], "venue": null, "citeRegEx": "Zwicky.,? \\Q2005\\E", "shortCiteRegEx": "Zwicky.", "year": 2005}], "referenceMentions": [{"referenceID": 14, "context": "1 Introduction Recurrent neural networks (RNNs) are highly effective models of sequential data (Elman, 1990).", "startOffset": 95, "endOffset": 108}, {"referenceID": 23, "context": "The rapid adoption of RNNs in NLP systems in recent years, in particular of RNNs with gating mechanisms such as long short-term memory (LSTM) units (Hochreiter and Schmidhuber, 1997) or gated recurrent units (GRU) (Cho et al.", "startOffset": 148, "endOffset": 182}, {"referenceID": 9, "context": "The rapid adoption of RNNs in NLP systems in recent years, in particular of RNNs with gating mechanisms such as long short-term memory (LSTM) units (Hochreiter and Schmidhuber, 1997) or gated recurrent units (GRU) (Cho et al., 2014), has led to significant gains in language modeling (Mikolov et al.", "startOffset": 214, "endOffset": 232}, {"referenceID": 36, "context": ", 2014), has led to significant gains in language modeling (Mikolov et al., 2010; Sundermeyer et al., 2012), parsing (Vinyals et al.", "startOffset": 59, "endOffset": 107}, {"referenceID": 47, "context": ", 2014), has led to significant gains in language modeling (Mikolov et al., 2010; Sundermeyer et al., 2012), parsing (Vinyals et al.", "startOffset": 59, "endOffset": 107}, {"referenceID": 49, "context": ", 2012), parsing (Vinyals et al., 2015; Kiperwasser and Goldberg, 2016; Dyer et al., 2016), machine translation (Bahdanau et al.", "startOffset": 17, "endOffset": 90}, {"referenceID": 30, "context": ", 2012), parsing (Vinyals et al., 2015; Kiperwasser and Goldberg, 2016; Dyer et al., 2016), machine translation (Bahdanau et al.", "startOffset": 17, "endOffset": 90}, {"referenceID": 12, "context": ", 2012), parsing (Vinyals et al., 2015; Kiperwasser and Goldberg, 2016; Dyer et al., 2016), machine translation (Bahdanau et al.", "startOffset": 17, "endOffset": 90}, {"referenceID": 1, "context": ", 2016), machine translation (Bahdanau et al., 2015) and other tasks.", "startOffset": 29, "endOffset": 52}, {"referenceID": 10, "context": "Other dependencies, however, are sensitive to the syntactic structure of the sentence (Chomsky, 1965; Everaert et al., 2015).", "startOffset": 86, "endOffset": 124}, {"referenceID": 17, "context": "Other dependencies, however, are sensitive to the syntactic structure of the sentence (Chomsky, 1965; Everaert et al., 2015).", "startOffset": 86, "endOffset": 124}, {"referenceID": 19, "context": "To what extent can RNNs learn to model such phenomena based only on sequential cues? Previous research has shown that RNNs (in particular LSTMs) can learn artificial context-free languages (Gers and Schmidhuber, 2001) as well as nesting and In this work we use the term RNN to refer to the entire class of sequential recurrent neural networks.", "startOffset": 189, "endOffset": 217}, {"referenceID": 1, "context": ", 2016), machine translation (Bahdanau et al., 2015) and other tasks. The effectiveness of RNNs1 is attributed to their ability to capture statistical contingencies that may span an arbitrary number of words. The word France, for example, is more likely to occur somewhere in a sentence that begins with Paris than in a sentence that begins with Penguins. The fact that an arbitrary number of words can intervene between the mutually predictive words implies that they cannot be captured by models with a fixed window such as n-gram models, but can in principle be captured by RNNs, which do not have an architecturally fixed limit on dependency length. RNNs are sequence models: they do not explicitly incorporate syntactic structure. Indeed, many word co-occurrence statistics can be captured by treating the sentence as an unstructured list of words (ParisFrance); it is therefore unsurprising that RNNs can learn them well. Other dependencies, however, are sensitive to the syntactic structure of the sentence (Chomsky, 1965; Everaert et al., 2015). To what extent can RNNs learn to model such phenomena based only on sequential cues? Previous research has shown that RNNs (in particular LSTMs) can learn artificial context-free languages (Gers and Schmidhuber, 2001) as well as nesting and In this work we use the term RNN to refer to the entire class of sequential recurrent neural networks. Instances of the class include long short-term memory networks (LSTM) and the Simple Recurrent Network (SRN) due to Elman (1990). ar X iv :1 61 1.", "startOffset": 30, "endOffset": 1527}, {"referenceID": 28, "context": "indentation in a programming language (Karpathy et al., 2016).", "startOffset": 38, "endOffset": 61}, {"referenceID": 26, "context": "Even a state-ofthe-art large-scale language model (Jozefowicz et al., 2016) was highly sensitive to recent but structurally irrelevant nouns, making more than five times as many mistakes as the number prediction model on these harder cases.", "startOffset": 50, "endOffset": 75}, {"referenceID": 14, "context": "These results suggest that explicit supervision is necessary for learning the agreement dependency using this architecture, limiting its plausibility as a model of child language acquisition (Elman, 1990).", "startOffset": 191, "endOffset": 204}, {"referenceID": 3, "context": "A more fundamental challenge that the dependency poses for structure-insensitive models is the possibility of agreement attraction errors (Bock and Miller, 1991).", "startOffset": 138, "endOffset": 161}, {"referenceID": 17, "context": "Given the difficulty in identifying the subject from the linear sequence of the sentence, dependencies such as subject-verb agreement serve as an argument for structured syntactic representations in humans (Everaert et al., 2015); they may challenge models such as RNNs that do not have pre-wired syntactic representations.", "startOffset": 206, "endOffset": 229}, {"referenceID": 29, "context": "The network was optimized using Adam (Kingma and Ba, 2015) and early stopping based on validation set error.", "startOffset": 37, "endOffset": 58}, {"referenceID": 21, "context": "Agreement attractors: We next examine how the model\u2019s error rate was affected by nouns that intervened between the subject and the verb in the linear These properties of the dependencies were identified by parsing the test sentences using the parser described in Goldberg and Nivre (2012).", "startOffset": 263, "endOffset": 289}, {"referenceID": 33, "context": ", write), he or she needs to decide whether its form will be write or writes (Levelt et al., 1999; Staub, 2009).", "startOffset": 77, "endOffset": 111}, {"referenceID": 46, "context": ", write), he or she needs to decide whether its form will be write or writes (Levelt et al., 1999; Staub, 2009).", "startOffset": 77, "endOffset": 111}, {"referenceID": 44, "context": "This task is modeled after a common human data collection technique in linguistics (Sch\u00fctze, 1996), although our training regime is of course very different to the training that humans are exposed to: humans rarely receive ungrammatical sentences labeled as such (Bowerman, 1988).", "startOffset": 83, "endOffset": 98}, {"referenceID": 4, "context": "This task is modeled after a common human data collection technique in linguistics (Sch\u00fctze, 1996), although our training regime is of course very different to the training that humans are exposed to: humans rarely receive ungrammatical sentences labeled as such (Bowerman, 1988).", "startOffset": 263, "endOffset": 279}, {"referenceID": 14, "context": "Language modeling (LM): Finally, we experimented with a word prediction objective, in which the model did not receive any grammatically relevant supervision (Elman, 1990; Elman, 1991).", "startOffset": 157, "endOffset": 183}, {"referenceID": 15, "context": "Language modeling (LM): Finally, we experimented with a word prediction objective, in which the model did not receive any grammatically relevant supervision (Elman, 1990; Elman, 1991).", "startOffset": 157, "endOffset": 183}, {"referenceID": 24, "context": "with collective nouns such as group, which are compatible with both singular and plural verbs in some dialects of English (Huddleston and Pullum, 2002); those cases appear to be rare.", "startOffset": 122, "endOffset": 151}, {"referenceID": 26, "context": "Figure 4: Alternative tasks and additional experiments: (a) overall error rate across tasks (note that the y-axis ends in 10%); (b) effect of count of attractors in homogeneous dependencies across training objectives; (c) comparison of the Google LM (Jozefowicz et al., 2016) to our LM and one of our supervised verb inflection systems, on a sample of sentences; (d) number prediction: effect of count of attractors using SRNs with standard training or LSTM with targeted training; (e) number prediction: difference in error rate between singular and plural subjects across RNN cell types.", "startOffset": 250, "endOffset": 275}, {"referenceID": 26, "context": "Would the performance gap between the LM and the explicitly supervised models close if we increased the capacity of the LM? We address this question using a very large publicly available LM (Jozefowicz et al., 2016), which we refer to as the Google LM.", "startOffset": 190, "endOffset": 215}, {"referenceID": 8, "context": "12 The Google LM represent the current state-of-the-art in language modeling: it is trained on a billion-word corpus (Chelba et al., 2013), with a vocabulary of 800,000 words.", "startOffset": 117, "endOffset": 138}, {"referenceID": 14, "context": "6 Additional Experiments Comparison to simple recurrent networks: How much of the success of the network is due to the LSTM cells? We repeated the number prediction experiment with a simple recurrent network (SRN) (Elman, 1990), with the same number of hidden units.", "startOffset": 214, "endOffset": 227}, {"referenceID": 16, "context": "While tentative at this point, these results suggest that oversampling difficult training cases may be beneficial; a curriculum progressing from easier to harder dependencies (Elman, 1993) may provide additional gains.", "startOffset": 175, "endOffset": 188}, {"referenceID": 3, "context": "Agreement attraction errors in humans are much more common when the attractor is plural than when it is singular (Bock and Miller, 1991; Eberhard et al., 2005).", "startOffset": 113, "endOffset": 159}, {"referenceID": 13, "context": "Agreement attraction errors in humans are much more common when the attractor is plural than when it is singular (Bock and Miller, 1991; Eberhard et al., 2005).", "startOffset": 113, "endOffset": 159}, {"referenceID": 47, "context": "8 Related Work The majority of NLP work on neural networks evaluates them on their performance in a task such as language modeling or machine translation (Sundermeyer et al., 2012; Bahdanau et al., 2015).", "startOffset": 154, "endOffset": 203}, {"referenceID": 1, "context": "8 Related Work The majority of NLP work on neural networks evaluates them on their performance in a task such as language modeling or machine translation (Sundermeyer et al., 2012; Bahdanau et al., 2015).", "startOffset": 154, "endOffset": 203}, {"referenceID": 40, "context": "Simple recurrent networks struggled with this language (Rodriguez et al., 1999; Rodriguez, 2001).", "startOffset": 55, "endOffset": 96}, {"referenceID": 41, "context": "Simple recurrent networks struggled with this language (Rodriguez et al., 1999; Rodriguez, 2001).", "startOffset": 55, "endOffset": 96}, {"referenceID": 16, "context": "Elman (1991) tested an SRN on a miniature language that simulated English relative clauses, and found that the network was only able to learn the language under highly specific circumstances (Elman, 1993), though later work has called some of his conclusions into question (Rohde and Plaut, 1999; Cartling, 2008).", "startOffset": 191, "endOffset": 204}, {"referenceID": 42, "context": "Elman (1991) tested an SRN on a miniature language that simulated English relative clauses, and found that the network was only able to learn the language under highly specific circumstances (Elman, 1993), though later work has called some of his conclusions into question (Rohde and Plaut, 1999; Cartling, 2008).", "startOffset": 273, "endOffset": 312}, {"referenceID": 6, "context": "Elman (1991) tested an SRN on a miniature language that simulated English relative clauses, and found that the network was only able to learn the language under highly specific circumstances (Elman, 1993), though later work has called some of his conclusions into question (Rohde and Plaut, 1999; Cartling, 2008).", "startOffset": 273, "endOffset": 312}, {"referenceID": 0, "context": ", 2012; Bahdanau et al., 2015). These evaluation setups average over many different syntactic constructions, making it difficult to isolate the network\u2019s syntactic capabilities. Other studies have tested the capabilities of RNNs to learn simple artificial languages. Gers and Schmidhuber (2001) showed that LSTMs can learn the context-free language anbn, generalizing to ns as high as 1000 even when trained only on n \u2208 {1, .", "startOffset": 8, "endOffset": 295}, {"referenceID": 0, "context": ", 2012; Bahdanau et al., 2015). These evaluation setups average over many different syntactic constructions, making it difficult to isolate the network\u2019s syntactic capabilities. Other studies have tested the capabilities of RNNs to learn simple artificial languages. Gers and Schmidhuber (2001) showed that LSTMs can learn the context-free language anbn, generalizing to ns as high as 1000 even when trained only on n \u2208 {1, . . . , 10}. Simple recurrent networks struggled with this language (Rodriguez et al., 1999; Rodriguez, 2001). These results have been recently replicated and extended by Joulin and Mikolov (2015). Elman (1991) tested an SRN on a miniature language that simulated English relative clauses, and found that the network was only able to learn the language under highly specific circumstances (Elman, 1993), though later work has called some of his conclusions into question (Rohde and Plaut, 1999; Cartling, 2008).", "startOffset": 8, "endOffset": 621}, {"referenceID": 0, "context": ", 2012; Bahdanau et al., 2015). These evaluation setups average over many different syntactic constructions, making it difficult to isolate the network\u2019s syntactic capabilities. Other studies have tested the capabilities of RNNs to learn simple artificial languages. Gers and Schmidhuber (2001) showed that LSTMs can learn the context-free language anbn, generalizing to ns as high as 1000 even when trained only on n \u2208 {1, . . . , 10}. Simple recurrent networks struggled with this language (Rodriguez et al., 1999; Rodriguez, 2001). These results have been recently replicated and extended by Joulin and Mikolov (2015). Elman (1991) tested an SRN on a miniature language that simulated English relative clauses, and found that the network was only able to learn the language under highly specific circumstances (Elman, 1993), though later work has called some of his conclusions into question (Rohde and Plaut, 1999; Cartling, 2008).", "startOffset": 8, "endOffset": 635}, {"referenceID": 0, "context": ", 2012; Bahdanau et al., 2015). These evaluation setups average over many different syntactic constructions, making it difficult to isolate the network\u2019s syntactic capabilities. Other studies have tested the capabilities of RNNs to learn simple artificial languages. Gers and Schmidhuber (2001) showed that LSTMs can learn the context-free language anbn, generalizing to ns as high as 1000 even when trained only on n \u2208 {1, . . . , 10}. Simple recurrent networks struggled with this language (Rodriguez et al., 1999; Rodriguez, 2001). These results have been recently replicated and extended by Joulin and Mikolov (2015). Elman (1991) tested an SRN on a miniature language that simulated English relative clauses, and found that the network was only able to learn the language under highly specific circumstances (Elman, 1993), though later work has called some of his conclusions into question (Rohde and Plaut, 1999; Cartling, 2008). Frank et al. (2013) studied the acquisition of anaphora coreference by SRNs, again in a miniature language.", "startOffset": 8, "endOffset": 956}, {"referenceID": 0, "context": ", 2012; Bahdanau et al., 2015). These evaluation setups average over many different syntactic constructions, making it difficult to isolate the network\u2019s syntactic capabilities. Other studies have tested the capabilities of RNNs to learn simple artificial languages. Gers and Schmidhuber (2001) showed that LSTMs can learn the context-free language anbn, generalizing to ns as high as 1000 even when trained only on n \u2208 {1, . . . , 10}. Simple recurrent networks struggled with this language (Rodriguez et al., 1999; Rodriguez, 2001). These results have been recently replicated and extended by Joulin and Mikolov (2015). Elman (1991) tested an SRN on a miniature language that simulated English relative clauses, and found that the network was only able to learn the language under highly specific circumstances (Elman, 1993), though later work has called some of his conclusions into question (Rohde and Plaut, 1999; Cartling, 2008). Frank et al. (2013) studied the acquisition of anaphora coreference by SRNs, again in a miniature language. Recently, Bowman et al. (2015) tested the ability of LSTMs to learn an artificial language based on propositional logic.", "startOffset": 8, "endOffset": 1075}, {"referenceID": 0, "context": ", 2012; Bahdanau et al., 2015). These evaluation setups average over many different syntactic constructions, making it difficult to isolate the network\u2019s syntactic capabilities. Other studies have tested the capabilities of RNNs to learn simple artificial languages. Gers and Schmidhuber (2001) showed that LSTMs can learn the context-free language anbn, generalizing to ns as high as 1000 even when trained only on n \u2208 {1, . . . , 10}. Simple recurrent networks struggled with this language (Rodriguez et al., 1999; Rodriguez, 2001). These results have been recently replicated and extended by Joulin and Mikolov (2015). Elman (1991) tested an SRN on a miniature language that simulated English relative clauses, and found that the network was only able to learn the language under highly specific circumstances (Elman, 1993), though later work has called some of his conclusions into question (Rohde and Plaut, 1999; Cartling, 2008). Frank et al. (2013) studied the acquisition of anaphora coreference by SRNs, again in a miniature language. Recently, Bowman et al. (2015) tested the ability of LSTMs to learn an artificial language based on propositional logic. As in our study, the performance of the network degraded as the complexity of the test sentences increased. Karpathy et al. (2016) present analyses and visualization methods for character-level RNNs.", "startOffset": 8, "endOffset": 1296}, {"referenceID": 0, "context": ", 2012; Bahdanau et al., 2015). These evaluation setups average over many different syntactic constructions, making it difficult to isolate the network\u2019s syntactic capabilities. Other studies have tested the capabilities of RNNs to learn simple artificial languages. Gers and Schmidhuber (2001) showed that LSTMs can learn the context-free language anbn, generalizing to ns as high as 1000 even when trained only on n \u2208 {1, . . . , 10}. Simple recurrent networks struggled with this language (Rodriguez et al., 1999; Rodriguez, 2001). These results have been recently replicated and extended by Joulin and Mikolov (2015). Elman (1991) tested an SRN on a miniature language that simulated English relative clauses, and found that the network was only able to learn the language under highly specific circumstances (Elman, 1993), though later work has called some of his conclusions into question (Rohde and Plaut, 1999; Cartling, 2008). Frank et al. (2013) studied the acquisition of anaphora coreference by SRNs, again in a miniature language. Recently, Bowman et al. (2015) tested the ability of LSTMs to learn an artificial language based on propositional logic. As in our study, the performance of the network degraded as the complexity of the test sentences increased. Karpathy et al. (2016) present analyses and visualization methods for character-level RNNs. K\u00e1d\u00e1r et al. (2016) and Li et al.", "startOffset": 8, "endOffset": 1385}, {"referenceID": 0, "context": ", 2012; Bahdanau et al., 2015). These evaluation setups average over many different syntactic constructions, making it difficult to isolate the network\u2019s syntactic capabilities. Other studies have tested the capabilities of RNNs to learn simple artificial languages. Gers and Schmidhuber (2001) showed that LSTMs can learn the context-free language anbn, generalizing to ns as high as 1000 even when trained only on n \u2208 {1, . . . , 10}. Simple recurrent networks struggled with this language (Rodriguez et al., 1999; Rodriguez, 2001). These results have been recently replicated and extended by Joulin and Mikolov (2015). Elman (1991) tested an SRN on a miniature language that simulated English relative clauses, and found that the network was only able to learn the language under highly specific circumstances (Elman, 1993), though later work has called some of his conclusions into question (Rohde and Plaut, 1999; Cartling, 2008). Frank et al. (2013) studied the acquisition of anaphora coreference by SRNs, again in a miniature language. Recently, Bowman et al. (2015) tested the ability of LSTMs to learn an artificial language based on propositional logic. As in our study, the performance of the network degraded as the complexity of the test sentences increased. Karpathy et al. (2016) present analyses and visualization methods for character-level RNNs. K\u00e1d\u00e1r et al. (2016) and Li et al. (2016) suggest visualization techniques for word-level RNNs trained to perform tasks that aren\u2019t explicitly syntactic (image captioning and sentiment analysis).", "startOffset": 8, "endOffset": 1406}, {"referenceID": 0, "context": "Early work that used neural networks to model grammaticality judgments includes Allen and Seidenberg (1999) and Lawrence et al.", "startOffset": 80, "endOffset": 108}, {"referenceID": 0, "context": "Early work that used neural networks to model grammaticality judgments includes Allen and Seidenberg (1999) and Lawrence et al. (1996). More recently, the connection between grammaticality judg-", "startOffset": 80, "endOffset": 135}, {"referenceID": 39, "context": "Finally, arguments for evaluating NLP models on a strategically sampled set of dependency types rather than a random sample of sentences have been made in the parsing literature (Rimell et al., 2009; Nivre et al., 2010; Bender et al., 2011).", "startOffset": 178, "endOffset": 240}, {"referenceID": 38, "context": "Finally, arguments for evaluating NLP models on a strategically sampled set of dependency types rather than a random sample of sentences have been made in the parsing literature (Rimell et al., 2009; Nivre et al., 2010; Bender et al., 2011).", "startOffset": 178, "endOffset": 240}, {"referenceID": 2, "context": "Finally, arguments for evaluating NLP models on a strategically sampled set of dependency types rather than a random sample of sentences have been made in the parsing literature (Rimell et al., 2009; Nivre et al., 2010; Bender et al., 2011).", "startOffset": 178, "endOffset": 240}, {"referenceID": 10, "context": "ments and the probabilities assigned by a language model was explored by Clark et al. (2013) and Lau et al.", "startOffset": 73, "endOffset": 93}, {"referenceID": 10, "context": "ments and the probabilities assigned by a language model was explored by Clark et al. (2013) and Lau et al. (2015). Finally, arguments for evaluating NLP models on a strategically sampled set of dependency types rather than a random sample of sentences have been made in the parsing literature (Rimell et al.", "startOffset": 73, "endOffset": 115}, {"referenceID": 45, "context": "This makes it difficult to distinguish simple but robust sequence models from more expressive architectures (Socher, 2014; Grefenstette et al., 2015; Joulin and Mikolov, 2015).", "startOffset": 108, "endOffset": 175}, {"referenceID": 22, "context": "This makes it difficult to distinguish simple but robust sequence models from more expressive architectures (Socher, 2014; Grefenstette et al., 2015; Joulin and Mikolov, 2015).", "startOffset": 108, "endOffset": 175}, {"referenceID": 25, "context": "This makes it difficult to distinguish simple but robust sequence models from more expressive architectures (Socher, 2014; Grefenstette et al., 2015; Joulin and Mikolov, 2015).", "startOffset": 108, "endOffset": 175}, {"referenceID": 39, "context": "Our work suggests an alternative strategy\u2014evaluation on naturally occurring sentences that are sampled based on their grammatical complexity\u2014which can provide more nuanced tests of language models (Rimell et al., 2009; Bender et al., 2011).", "startOffset": 197, "endOffset": 239}, {"referenceID": 2, "context": "Our work suggests an alternative strategy\u2014evaluation on naturally occurring sentences that are sampled based on their grammatical complexity\u2014which can provide more nuanced tests of language models (Rimell et al., 2009; Bender et al., 2011).", "startOffset": 197, "endOffset": 239}, {"referenceID": 7, "context": "As such, neural models used in NLP applications may benefit from grammatically sophisticated sentence representations developed in a multitask learning setup (Caruana, 1998), where the model is trained concurrently on the task of interest and on one of the tasks we proposed in this paper.", "startOffset": 158, "endOffset": 173}, {"referenceID": 20, "context": "The distribution of negative polarity items is highly sensitive to semantic factors (Giannakidou, 2011).", "startOffset": 84, "endOffset": 103}, {"referenceID": 43, "context": "Restrictions on unbounded dependencies (Ross, 1967) may require richer syntactic representations than those required for subject-verb dependencies.", "startOffset": 39, "endOffset": 51}, {"referenceID": 3, "context": "Humans occasionally make agreement attraction mistakes during language production (Bock and Miller, 1991) and comprehension (Nicol et al.", "startOffset": 82, "endOffset": 105}, {"referenceID": 37, "context": "Humans occasionally make agreement attraction mistakes during language production (Bock and Miller, 1991) and comprehension (Nicol et al., 1997).", "startOffset": 124, "endOffset": 144}, {"referenceID": 48, "context": "These errors persist in human acceptability judgments (Tanner et al., 2014), which parallel our grammaticality judgment task.", "startOffset": 54, "endOffset": 75}, {"referenceID": 35, "context": "Cases of grammatical agreement with the nearest rather than structurally relevant constituent have been documented in languages such as Slovenian (Maru\u0161i\u010d et al., 2007), and have even been argued to be occasionally grammatical in English (Zwicky, 2005).", "startOffset": 146, "endOffset": 168}, {"referenceID": 50, "context": ", 2007), and have even been argued to be occasionally grammatical in English (Zwicky, 2005).", "startOffset": 77, "endOffset": 91}], "year": 2016, "abstractText": "The success of long short-term memory (LSTM) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. Linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by LSTMs, which do not have explicit structural representations? We begin addressing this question using number agreement in English subject-verb dependencies. We probe the architecture\u2019s grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. In the strongly supervised settings, the LSTM achieved very high overall accuracy (less than 1% errors), but errors increased when sequential and structural information conflicted. The frequency of such errors rose sharply in the language-modeling setting. We conclude that LSTMs can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufficient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured.", "creator": "LaTeX with hyperref package"}}}