{"id": "1611.08657", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Nov-2016", "title": "Convolutional Experts Constrained Local Model for Facial Landmark Detection", "abstract": "Among the well-established methods for facial landmark detection is the family of Constrained Local Models (CLMs). An important part of CLM landmark alignment pipeline are the local detectors that estimate the alignment probability of each individual landmark over the facial region. In this paper we present Deep Constrained Local Model (DCLM) algorithm and the novel Dense-Projection Network (DPN) as a local detector. DPN is a deep neural network that consists of two important layers: Template Projection layer and Dense Aggregate layer. In Template Projection layer, patches of facial region are mapped to a higher dimensional space allowing the pose and rotation variations to be captured accurately. In Dense Aggregate layer an ensemble of experts is simulated within one network to make the landmark localization task more robust. In our extensive set of experiments we show that DPNs outperform previously proposed local detectors. Furthermore, we demonstrate that our proposed DCLM algorithm is state-of-the-art in facial landmark detection. We significantly outperform competitive baselines, that use both CLM-based and cascaded regression approaches, by a large margin on three publicly-available datasets for image and video landmark detection.", "histories": [["v1", "Sat, 26 Nov 2016 04:47:34 GMT  (1882kb,D)", "http://arxiv.org/abs/1611.08657v1", null], ["v2", "Tue, 29 Nov 2016 16:00:45 GMT  (1882kb,D)", "http://arxiv.org/abs/1611.08657v2", null], ["v3", "Wed, 30 Nov 2016 18:03:56 GMT  (1882kb,D)", "http://arxiv.org/abs/1611.08657v3", null], ["v4", "Sun, 23 Jul 2017 10:15:06 GMT  (6334kb,D)", "http://arxiv.org/abs/1611.08657v4", "Accepted at CVPR-W 2017"], ["v5", "Wed, 26 Jul 2017 19:46:15 GMT  (6386kb,D)", "http://arxiv.org/abs/1611.08657v5", "Accepted at CVPR-W 2017"]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["amir zadeh", "tadas baltru\\v{s}aitis", "louis-philippe morency"], "accepted": false, "id": "1611.08657"}, "pdf": {"name": "1611.08657.pdf", "metadata": {"source": "CRF", "title": "Deep Constrained Local Models for Facial Landmark Detection", "authors": ["Amir Zadeh", "Tadas Baltruaitis"], "emails": ["abagherz@cs.cmu.edu", "tbaltrus@cs.cmu.edu", "morency@cs.cmu.edu"], "sections": [{"heading": "1. Introduction", "text": "Facial landmark detection is an essential initial step for a number of research areas such as facial expression analysis, face 3D modeling, facial attribute analysis, emotion recognition and person identification [9, 22, 27]. It is a well researched problem with large amounts of annotated data and has seen a surge of interest in the past couple of years. Among the popular methods for facial landmark detection\nis the family of Constrained Local Models [26, 3]. Arguably the most important step in CLM pipeline is local detection of individual landmarks using local detectors (also called patch experts) that assign landmark alignment probability to different regions of the face. Local detection is also the first\nar X\niv :1\n61 1.\n08 65\n7v 1\n[ cs\n.C V\n] 2\n6 N\nstep, making accurate detection of landmarks crucial for the rest of the pipeline; and making patch expert design and training an active and challenging area of research. Based on the probability maps populated by applying patch experts to different areas of the image, position of landmarks are updated iteratively using a shape model until landmark alignment loss is minimized for a facial image.\nDeep neural networks have shown promising results in variety of computer vision tasks [30, 20, 28] not just due to abundance of computational power for their efficient training, but also their flexibility in designing problem specific architectures that lead to breakthroughs. In this paper we introduce Deep Constrained Local Model (DCLM), a new member of CLM family that uses a carefully designed and trained deep local detector called Dense-Projection Network (DPN). Figure 1 shows the pipeline of DCLM algorithm. In the first step the input image is convolved with the DPN networks populating an alignment probability response map. The response maps are then used alongside a Point Distribution Model (PDM) to compute the final position of the landmarks.\nThe novel DPN architecture contains two crucial layers called Template Projection (TP) and Dense Aggregate (DA) layers. In Template Projection layer, the input images are by design mapped to a larger space to allow for pose and head rotation variations to be captured accurately. In Dense Aggregate layer a large ensemble of models are simulated within one model and trained end-to-end to minimize the chances that failure of one expert will affect the final landmark detection task. In our experiments we compare DPN with Local Neural Field local detector [2] trained on the same data showing a significant improvement in performance across all landmarks.\nWe demonstrate the benefits of our DCLM facial landmark detection algorithm through extensive experiments on three publicly available datasets, 300W [23], 300VW [29], and a newly introduced dataset, IJB-FL [14] (a subset of IJB-A [17]), which includes a large proportion of profile face poses with extremely challenging conditions for landmark detection. In all of the datasets we achieve state-ofthe-art results.\nThe structure of this paper is as follows: we discuss related works in the next Section 2, DCLM is introduced in Section 3. In Section 4 the benefit and strength of our method is demonstrated by showing that DPN outperforms LNF local detectors drastically and DCLM consistently outperforms state-of-the-art landmark detection methods, specifically when detecting 68 landmarks. We conclude this paper in Section 5."}, {"heading": "2. Related Work", "text": "Facial landmark detection has been used in number of research directions such as facial attribute detection [18], fa-\ncial expression analysis [22], emotion recognition and sentiment analysis [36], and 3D facial reconstruction [13]. A large number of new approaches and techniques have been proposed, especially for landmark detection in faces from RGB images. A full review of work in facial landmark detection and head pose estimation is outside the scope of this paper, we refer the reader to some recent reviews of the field [10, 34]."}, {"heading": "2.1. Facial landmark detection", "text": "Modern facial landmark detection approaches can be split into two major categories - model based and regression. Model based approaches often model both appearance and shape of facial landmarks with the latter providing a form of regularization. Regression approaches on the other hand do not require an explicit shape model and landmark detection is directly performed on appearance. We provide a short overview of recent model and regression based methods.\nModel Based approaches are often made up of two steps: extracting an appearance descriptor around certain areas of interest and computing local response maps; fitting a shape model based on the local predictions. Such areas are often defined by the current estimate of facial landmarks. A popular local method for landmark detection is the Constrained Local Model [26] and its various extensions such as Constrained Local Neural Fields [2] and Discriminative Response Map Fitting [1] that use more advanced ways of computing local response maps and inferring the landmark locations. Project out Cascaded regression (PO-CR) [32] is another example of a local approach, but one that uses a cascaded regression to update the shape model parameters rather than predicting landmark locations directly.\nAnother noteworthy local approach is the mixture of trees model [39] that uses a tree based deformable parts model to jointly perform face detection, pose estimation and facial landmark detection. A notable extension to this approach is the Gauss-Newton Deformable Part Model (GNDPM) [33] which jointly optimizes a part-based flexible appearance model along with a global shape using GaussNewton optimization.\nRegression Nowadays majority of the regression approaches follow a cascaded regression framework, where facial landmark detection is updated in a cascaded fashion. That is the landmark detection is continually improved by applying a regressor on appearance given the current landmark estimate as performed by Cao et al. in explicit shape regression [6]. Other cascaded regression approaches include the Stochastic Descent Method (SDM) [35] which uses SIFT [21] features with linear regression to compute the shape update and Coarse-to-Fine Shape Searching (CFSS) [38] which attempts to avoid a local optima in cascade regression by performing a coarse to fine shape search.\nRecent work has also used deep learning techniques in a cascaded regression framework to extract visual features. Coarse-to-Fine Auto-encoder Networks (CFAN) [37] use visual features extracted by an auto-encoder together with linear regression. Sun et al. [31] proposed a Convolutional Neural Network (CNN) based cascaded regression approach for sparse landmark detection; however while their approach is robust it is not very accurate."}, {"heading": "3. Deep Constrained Local Model", "text": "Deep Constrained Local Model (DCLM) algorithm consists of two main parts: local detection and shape regularization. In local detection, individual landmarks are detected independent of the position of other landmarks. In shape regularization, the position of all landmarks are considered jointly and irregular shapes are discouraged using a point distribution model. The following objective function is thus optimized in DCLM framework:\np\u2217 = argmin p [ n\u2211 i=1 Di(xi; I) +R(p) ]\n(1)\nIn the above equation p\u2217 is the optimal set of parameters controlling the position of landmarks with p being the current estimate. D is inversely proportional to the output of DPN network as the alignment probability of landmark i in location xi for input facial image I (section 3.1). R is the regularization enforced by Point Distribution Model (section 3.2) . The optimization of Equation 1 is done using Non-Uniform Regularized Landmark Mean Shift algorithm (section 3.3)."}, {"heading": "3.1. Dense-Projection Network Patch Experts", "text": "The first and most important step in DCLM algorithm is to accurately localize individual landmarks by evaluating the landmark alignment over different regions of an input image. This can be done by calculating the alignment probability of a certain landmark over different regions of image using convolution. A local detector is moved across the image and assigns probability to each region of the image. If the probability is high, the evidence of landmark presence is strong.\nFor this task we choose the family of fully connected deep neural networks (DNN) and introduce a specially tailored deep network called Dense-Projection Network (DPN) patch expert (Figure 2) for this task. The first layer (shown as blue in Figure 2) is called template-projection (TP) layer which is designed to capture variety of facial appearance and poses by projecting the input to 500 dimensions, a much higher dimensional space than the 121 dimensional input. After the second fully connected layer, the final layer is called dense-aggregate (DA) layer (shown as red in Figure 2). It consists of 100 inputs that are connected\nto probability decision neuron with non-negative weights. This allows the last layer to act as a mixture of experts model; each of the 100 neurons act as an expert and the final decision is a linear combination of all the experts. The entire network is trained end-to-end, allowing the experts to adapt to the the input as well as to each other in the same framework. Both TP and DA layers have proven crucial and are studied in section 4.1. The receptive area of DPN is a contrast normalized 11 \u00d7 11 image patch and the output is the probability of landmark being located at the center of the patch. This is specifically important since it allows to pinpoint the position of landmark. An input image is then convolved with the DPN network to compute a probability response map in an area of interest around the current landmark estimate; each pixel in the output denotes the probability of that pixel being the right position for the landmark. Thus fitting the landmark i in position xi follows the equation:\n\u03c0ixi = p(li = 1, I\u0302 = Ixi) (2) li is an indicator for landmark number i being aligned. I\u0302 is the image patch at location xi for the image I. The response maps \u03c0i are then used for minimizing Equation 1. The detailed network training procedure to achieve state of the art is presented in section 4.1."}, {"heading": "3.2. Point Distribution Model Shape Regularization", "text": "Point Distribution Models [8, 26] are used as shape regularizers in DCLM framework. Complex and irregular shapes for final detected landmarks are penalized using the term R(p) in the Equation 1. If xi = [xi, yi]T is the location for ith facial landmark then parameters of the PDM are controlled using the following equation:\nxi = s \u00b7R2D \u00b7 (x\u0304i + \u03a6i) + t (3)\nwhere x\u0304i = [x\u0304i, y\u0304i, z\u0304i]T is the mean value of ith landmark, \u03a6i is a 3 \u00d7m principal component matrix, and q is an mdimensional vector of parameters controlling the non-rigid shape; s, R and t are the rigid paramters in 2D: s is the scale parameter and is a scalar, R is rotation defined based on axis angles w = [wx, wy, wz]T and is a 3 \u00d7 3 matrix in homogeneous coordinate system (R2D are the first two rows of this matrix), and t = [tx, ty]T is translation. The whole shape of landmarks can be described as p = [s, t,w,q]."}, {"heading": "3.3. Non-Uniform Regularized Landmark Mean", "text": "Shift\nThe most common method to solve equation 1 is using Non-Uniform Regularized Landmark Mean Shift (NURLMS) [2]. Given an initial DCLM parameter estimate p (denoting the 68 facial landmark positions) the goal is to find an update parameter \u2206p such that p\u2217 = p0 + \u2206p and\noptimal parameters based on equation 1 is reached. Based on this, RLMS finds the solution to the following problem:\nargmin \u2206p\n( \u2016p0 + \u2206p\u20162\u039b\u22121 + \u2016J\u2206p0 \u2212 v\u2016 2 W ) (4)\nwhere J is the Jacobian of the landmark locations with respect to parameters p. \u039b\u22121 is the matrix of priors on p with Gaussian priorN (q; 0,\u039b) for non-rigid shape and uniform for shape parameters. W in Equation 4 is a weighting matrix for weighting mean shift vectors \u2013 W = w \u00b7 diag(c1; ...; cn; c1; ...; cn) and ci is the landmark detector accuracy calculated during model training based on correlation coefficient. v = [vi|i \u2264 n = 68] is the meanshift vector calculated using a Gaussian Kernel Density Estimator using response maps of DPN:\nvi = \u2211\nyi\u2208\u03a8i\n\u03c0iyiN (xci ; yi, \u03c1I)\u2211 zi\u2208\u03a8i \u03c0 i ziN (xci ; zi, \u03c1I)\n(5)\nxci is the current estimate for the landmark position and \u03c1 is determined empirically.\nSubsequently the update rule of the Non-uniform RLMS is:\n\u2206p = \u2212(JTWJ + r\u039b\u22121)(r\u039b\u22121p\u2212 JTWv) (6)"}, {"heading": "4. Experiments", "text": "In our experiments we first we show that DPN networks significantly perform better than LNF [2] and SVR [26] lo-\ncal detectors (patch experts). We also evaluate the importance of TP and DA layers for DPN performance. Our final facial landmark detection experiments explore the use of our model in two settings - images and videos. All of our experiments were performed on challenging publicly available datasets and compared to a number of state-of-the-art baselines. We outperform the baselines in all setups specifically in dense 68 landmark detection. The DPN and DCLM training codes are publicly available on GitHub: Hidden for blind review."}, {"heading": "4.1. DPN Experiments", "text": "In this section we first describe training and inference methodology of the DPN patch experts. We then compare the performance of DPN with LNF [2] and SVR [26] patch experts followed by an ablation study to investigate the crucial role of TP and DA layers.\nFor all of the experiments DPN patch experts were trained on LFPW and Helen training sets as well as MultiPIE dataset. To train patch experts we sampled around the true location of the landmark and far away from it for negative samples. Each of the samples was an 11 \u00d7 11 pixel support region and was contrast normalized using their Zscore. If the landmark was located at the center of the 11\u00d7 11 region of interest, then the probability for the landmark presence was high, otherwise low. A total of 4 \u00d7 106 regions were extracted for train and 5\u00d7 105 for test set. We trained 28 sets of patch experts per landmark: at seven orientations \u00b170\u25e6,\u00b145\u25e6,\u00b120\u25e6, 0 yaw; and four scales 17, 23,\n30, and 60 pixel of interocular distance. To reduce the number of patch experts that needed to be trained we mirrored the patch experts at different yaw angles and used the same expert for left and right side of the face of the frontal view. The optimizer of DPN was Adam ([16]) with small learning rate of 5 \u00d7 10\u22124 and trained for 100 epochs with minibatches of 512 (roughly 800,000 updates per landmark). For each landmark, scale and view a DPN patch expert has been trained, which sums to a total of 1088 DPN models. Training each DPN model takes 6 hours on a Geforce GTX Titan X but once trained inference can be quickly done and parallelized.\nWe compare the performance improvement of DPN patch experts over LNF and SVR patch experts. Figure 3 shows the average performance for each individual landmark (higher is better). The train an test data for all the models are the same. Since alignment probability inference is a regression task we use square correlation (r2) between the ground truth validation set and patch expert output as a measure of accuracy. On average DPN patch experts perform 68% better than LNF. While this is an average, for\ncertain landmarks, views and scales performance improvement is more than 100%. This is specifically the case for 17 interocular distance scale since the DPN is able to model the location of landmark based on a bigger appearance of landmark neighborhood in the image.\nWe evaluate the importance of TP and DA layers in DPN patch experts by performing an ablation study. We train models that don\u2019t have TP or DA layers by removing one of the layers at a time. For TP ablation study we compare the model to a network that has only 128 while keeping the DA layer intact. This effectively removes the designed layer put in place to capture the pose and rotation variations. For DA ablation study we keep the TP layer and remove the DA constraint from the last layer. Removing the DA layer decreases the robustness of the DPN network drastically making it a weak local detector. The results of this study are presented in Figure 3 and compared to DCLM, LNF and SVR patch experts. It can be seen that both the models without TP and without DA show very poor performance.\nIn Figure 4 we visualize the improvement of DPN over LNF patch experts across different landmarks such as eyebrow region, lips and face outline. The ground truth response map is a normal distribution centered around the position of landmark. The output response map from DPN shows better certainty about the position of the landmark as its response map is more concentrated around the ground truth position, while LNF output is underperforming in localization with outliers in false positions. We therefore conclude that the major improvement from DPN comes from accurate local detection, and this directly transfers to improvement in landmark detection task."}, {"heading": "4.2. DCLM Experiments", "text": "In this section we first describe the datasets used to train and evaluate our DCLM method for facial landmark detection in images and videos. We then briefly discuss comparable state-of-the-art approaches for landmark detection. Finally we present the facial landmark detection results."}, {"heading": "4.2.1 Datasets", "text": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets. We used the full iBUG dataset and the test partitions of LFPW and HELEN. This led to 135, 224, and 330 images for testin respectively. They all contain uncontrolled images of faces in the wild: in indoor-outdoor environments, under varying illuminations, in presence of occlusions, under different poses, and from different quality cameras.\nIJB-FL [14] is a dataset which has a substantial proportion of non-frontal images. It is a subset of IJB-A [17] which is a face recognition benchmark and includes chal-\nlenging unconstrained faces with full pose. We use a labeled sample of 180 images (128 images for frontal and 52 images for profile) from IJB-A. This is a very challenging subset containing a number of images in non-frontal pose. None of the tested models have been trained on this dataset so it acts as a cross-dataset test set.\n300-VW[29] is a dataset with 114 videos labeled for 68 facial landmarks for every frame. with 50 videos in the training and 64 in the testing sets. The test videos are categorized in three scenarios. The first scenario includes videos in laboratory and naturalistic well-lit conditions. People recorded in these videos have arbitrary expressions and head poses. The second scenario consists\nof videos of people recorded in unconstrained conditions such as varied illumination, dark rooms and overexposed shots. The third scenario focuses on completely unconstrained conditions including illumination and occlusions such as occlusions by hand. We used the 64 test videos in our experiments. As none of the models were trained on this dataset, it can be seen as a cross-dataset generalization experiment."}, {"heading": "4.2.2 Baselines", "text": "We compared our approach to a number of established baselines for the facial landmark detection task, including both cascaded regression and local model based approaches.\n(CFSS) [38] \u2013 Coarse to Fine Shape Search is a cascaded regression approach which attempts to avoid a local optima\nby performing a coarse to fine shape search. It is the most recent state-of-the-art approach on the 300W competition data [23, 7]. We use the implementation provided by the authors that is trained on Helen and LFPW training sets and AFW.\nCLNF is an extension of the Constrained Local Model that uses Continuous Conditional Neural Fields as patch experts [3].\nPO-CR [32] \u2013 is another recent cascaded regression approach that updates the shape model parameters rather than predicting landmark locations directly in a projected-out space. We use an implementation provided by the author that was trained on LFPW and Helen training sets.\nDRMF \u2013 discriminative response map fitting performs regression on patch expert response maps directly rather than using optimization over the parameter space. We use\nthe implementation provided by the authors [1] that was trained on LFPW [5] and Multi-PIE [11] datasets.\nSDM \u2013 Supervised Descent Method is a very popular cascaded regression approach. We use implementation from the authors [35]. This approach is trained on the MultiPIE and LFW [12] datasets.\nGNDPM [33] \u2013 is a deformable parts model which jointly optimizes a part-based flexible appearance model. We use the implementation from the authors that was trained on LFPW and Helen training sets.\nTree based face and landmark detector, is a deformable parts model for jointly detecting faces, landmarks and head orientation proposed by Zhu and Ramanan [39]. It has shown good performance at locating the face and the landmark features on a number of datasets. We used a model trained on in-the-wild datasets [1].\nCLM+ model uses linear SVR patch experts and regularised landmark mean-shift fitting [26]. Same training data and initialisation was used for this model as for our DCLM. Note that we use a more accurate CLM model that was presented by Saragih et al. [26], as our model includes a multimodal (patch experts trained on raw pixel and gradient images) and multi-scale formulation leading to more accurate landmark detection. The model was trained on LFPW and Helen training sets and CMU Multi-PIE. We use a freely available implementation [4].\nAll of the above baselines were trained to detect either 49, 51, or 68 feature points, making exact comparisons difficult. However, they all share the same subset of 49 feature points."}, {"heading": "4.2.3 Landmark Detection Results", "text": "For fairness of model comparison all of the approaches have been initialized using the same protocol. For 300W dataset we initialized all of the approaches using the bounding boxes provided by the challenge organizers.\nFor IJB-FL we initialized the approaches by generating a face bounding box by adding noise to the ground truth landmarks (based on the noise properties of the bounding boxes in 300W dataset). To make the landmark detection more robust to pose variations we initialized DCLM at five different orientation given a bounding box - frontal, \u00b130\u25e6 yaw, and \u00b130\u25e6 pitch. We pick the landmarks with highest converged maximum a posteriori score as the final detection.\nFor 300VW we detected the face in every 30th frame of each video using the dlib [15] library. When the face was not detected in the frame we used the closest frame with a successful detection instead. We performed a linear mapping from the detected bounding box to a tighter fit around all 68 landmarks, as that is the format expected by all of our baselines. Each baseline was initialized from the detection and allowed to track for 30 frames, either using previously\ndetected landmarks or using the new bounding box.\nResults of landmark detection on the 300W dataset can be seen in Figure 5. Our approach outperforms all of the baselines in both the 68 and 49 point scenario. The improved accuracy of DCLM is especially apparent in the 68 point case, which is the more challenging due to the ambiguity of face outline. It is noteworthy that cascaded regression models underperform in the 68 point case even though they perform really well for 49 points.\nResults of landmark detection on the IJB-FL dataset can be see in Figure 6. DCLM model outperforms all of the baselines on this difficult task as well.\nResults on landmark detection and tracking in videos on the 300VW dataset are displayed in the Figure 7. DCLM outperforms all of the baselines in all three categories with\nthe biggest improvement in Category 1."}, {"heading": "5. Conclusion", "text": "In this paper we introduced Deep Constrained Local Model (DCLM), a new member of CLM family that uses a carefully designed and trained deep local detector called Dense-Projection Network (DPN). We compared DPN with the patch experts of related model based approaches and showed significant performance improvement. The DPN network is designed with two goals in mind: 1) input facial pose and orientation variation should be captured and 2) output probability should resemble the output of many models to be robust against detection failure. The Template Projection layer was designed to capture the appearance variations in the input and Dense Aggregate layer sim-\nulates a mixture of experts. We showed their crucial role with an ablation study. We brought state-of-art results in 3 publicly available datasets and we show great performance improvement for dense 68 facial landmark detection. Figure 8 shows a visual comparison between DCLM, CFSS and CLNF landmark detection methods on a set challenging images. DCLM is able to accurately align the 68 facial landmarks."}], "references": [{"title": "Robust discriminative response map fitting with constrained local models", "author": ["A. Asthana", "S. Zafeiriou", "S. Cheng", "M. Pantic"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3444\u20133451,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Constrained local neural fields for robust facial landmark detection in the wild", "author": ["T. Baltrusaitis", "L.-P. Morency", "P. Robinson"], "venue": "IEEE International Conference on Computer Vision Workshops,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Continuous conditional neural fields for structured regression", "author": ["T. Baltru\u0161aitis", "P. Robinson", "L.-P. Morency"], "venue": "Computer Vision\u2013ECCV 2014, pages 593\u2013608. Springer,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "3D Constrained Local Model for Rigid and Non-Rigid Facial Tracking", "author": ["T. Baltru\u0161aitis", "P. Robinson", "L.-P. Morency"], "venue": "CVPR,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Localizing parts of faces using a consensus of exemplars", "author": ["P.N. Belhumeur", "D.W. Jacobs", "D.J. Kriegman", "N. Kumar"], "venue": "CVPR,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Face alignment by Explicit Shape Regression", "author": ["X. Cao", "Y. Wei", "F. Wen", "J. Sun"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition, pages 2887\u20132894. Ieee, jun", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "A Comprehensive Performance Evaluation of Deformable Face Tracking \u201dIn-the-Wild", "author": ["G.G. Chrysos", "E. Antonakos", "P. Snape", "A. Asthana", "S. Zafeiriou"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Active appearance models", "author": ["T. Cootes", "G. Edwards", "C. Taylor"], "venue": "TPAMI, 23(6):681\u2013685, Jun", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2001}, {"title": "Feature detection and tracking with constrained local models", "author": ["D. Cristinacce", "T. Cootes"], "venue": "BMVC,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Active Media Technology: 10th International Conference, AMT 2014, Warsaw, Poland, August 11-14, 2014", "author": ["B. Czupry\u0144ski", "A. Strupczewski"], "venue": "Proceedings, chapter High Accuracy Head Pose Tracking Survey, pages 407\u2013420. Springer International Publishing, Cham,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Multi-pie", "author": ["R. Gross", "I. Matthews", "J. Cohn", "T. Kanade", "S. Baker"], "venue": "IVC, 28(5):807 \u2013 813,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments", "author": ["G.B. Huang", "M. Ramesh", "T. Berg", "E. Learned-Miller"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Dense 3d face alignment from 2d video for real-time use", "author": ["L.A. Jeni", "J.F. Cohn", "T. Kanade"], "venue": "Image and Vision Computing,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Holistically constrained local model: Going beyond frontal poses for facial landmark detection", "author": ["K. KangGeon", "T. Baltru\u0161aitis", "A. Zadeh", "L.-P. Morency", "G. Medioni"], "venue": "British Machine Vision Conference (BMVC),", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Dlib-ml: A machine learning toolkit", "author": ["D.E. King"], "venue": "JMLR,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Pushing the frontiers of unconstrained face detection and recognition: Iarpa janus benchmark a", "author": ["B.F. Klare", "B. Klein", "E. Taborsky", "A. Blanton", "J. Cheney", "K. Allen", "P. Grother", "A. Mah", "M. Burge", "A.K. Jain"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, pages 1931\u20131939. IEEE,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Attribute and simile classifiers for face verification", "author": ["N. Kumar", "A.C. Berg", "P.N. Belhumeur", "S.K. Nayar"], "venue": "Proceedings of the IEEE International Conference on Computer Vision, pages 365\u2013372,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Interactive facial feature localization", "author": ["V. Le", "J. Brandt", "Z. Lin", "L. Bourdev", "T.S. Huang"], "venue": "Computer Vision\u2013ECCV 2012, pages 679\u2013692. Springer,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Distinctive image features from scale invariant keypoints", "author": ["D.G. Lowe"], "venue": "Int\u2019l Journal of Computer Vision, 60:91\u2013 11020042,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "Advances, challenges, and opportunities in automatic facial expression recognition", "author": ["B. Martinez", "M. Valstar"], "venue": "B. S. M. Kawulok, E. Celebi, editor, Advances in Face Detection and Facial Image Analysis, pages 63 \u2013 100. Springer,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "300 faces in-the-wild challenge: The first facial landmark localization challenge", "author": ["C. Sagonas", "G. Tzimiropoulos", "S. Zafeiriou", "M. Pantic"], "venue": "Proceedings of the IEEE International Conference on Computer Vision Workshops, pages 397\u2013403,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "300 faces in-the-wild challenge: The first facial landmark localization challenge", "author": ["C. Sagonas", "G. Tzimiropoulos", "S. Zafeiriou", "M. Pantic"], "venue": "ICCV,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "A semi-automatic methodology for facial landmark annotation", "author": ["C. Sagonas", "G. Tzimiropoulos", "S. Zafeiriou", "M. Pantic"], "venue": "Proceedings of the IEE Conference on Computer Vision and Pattern Recognition Workshops (CVPR-W), Workshop on Analysis and Modeling of Faces and Gestures,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Deformable Model Fitting by Regularized Landmark Mean-Shift", "author": ["J. Saragih", "S. Lucey", "J. Cohn"], "venue": "IJCV,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic analysis of facial affect: A survey of registration, representation and recognition", "author": ["E. Sariyanidi", "H. Gunes", "A. Cavallaro"], "venue": "IEEE TPAMI,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "The First Facial Landmark Tracking in-the-Wild Challenge: Benchmark and Results", "author": ["J. Shen", "S. Zafeiriou", "G.G. Chrysos", "J. Kossaifi", "G. Tzimiropoulos", "M. Pantic"], "venue": "2015 IEEE International Conference on Computer Vision Workshop (ICCVW),", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep convolutional network cascade for facial point detection", "author": ["Y. Sun", "X. Wang", "X. Tang"], "venue": "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 3476\u20133483,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Project-Out Cascaded Regression with an application to Face Alignment", "author": ["G. Tzimiropoulos"], "venue": "CVPR,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Gauss-newton deformable part models for face alignment in-the-wild", "author": ["G. Tzimiropoulos", "M. Pantic"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1851\u20131858,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Facial Feature Point Detection: A Comprehensive Survey", "author": ["N. Wang", "X. Gao", "D. Tao", "X. Li"], "venue": "page 32,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2014}, {"title": "Supervised descent method and its applications to face alignment", "author": ["X. Xiong", "F. Torre"], "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 532\u2013539,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "Multimodal Sentiment Intensity Analysis in Videos: Facial Gestures and Verbal Messages", "author": ["A. Zadeh", "R. Zellers", "E. Pincus", "L.-P. Morency"], "venue": "2016 IEEE Intelligent Systems,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2016}, {"title": "Coarse-to-fine auto-encoder networks (cfan) for real-time face alignment", "author": ["J. Zhang", "S. Shan", "M. Kan", "X. Chen"], "venue": "ECCV. Springer,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2014}, {"title": "Face Alignment by Coarse-to-Fine Shape Searching", "author": ["S. Zhu", "C. Li", "C.C. Loy", "X. Tang"], "venue": "CVPR,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2015}, {"title": "Face detection, pose estimation, and landmark localization in the wild", "author": ["X. Zhu", "D. Ramanan"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 2879\u20132886. IEEE,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 8, "context": "Facial landmark detection is an essential initial step for a number of research areas such as facial expression analysis, face 3D modeling, facial attribute analysis, emotion recognition and person identification [9, 22, 27].", "startOffset": 213, "endOffset": 224}, {"referenceID": 19, "context": "Facial landmark detection is an essential initial step for a number of research areas such as facial expression analysis, face 3D modeling, facial attribute analysis, emotion recognition and person identification [9, 22, 27].", "startOffset": 213, "endOffset": 224}, {"referenceID": 24, "context": "Facial landmark detection is an essential initial step for a number of research areas such as facial expression analysis, face 3D modeling, facial attribute analysis, emotion recognition and person identification [9, 22, 27].", "startOffset": 213, "endOffset": 224}, {"referenceID": 23, "context": "is the family of Constrained Local Models [26, 3].", "startOffset": 42, "endOffset": 49}, {"referenceID": 2, "context": "is the family of Constrained Local Models [26, 3].", "startOffset": 42, "endOffset": 49}, {"referenceID": 1, "context": "In our experiments we compare DPN with Local Neural Field local detector [2] trained on the same data showing a significant improvement in performance across all landmarks.", "startOffset": 73, "endOffset": 76}, {"referenceID": 20, "context": "We demonstrate the benefits of our DCLM facial landmark detection algorithm through extensive experiments on three publicly available datasets, 300W [23], 300VW [29], and a newly introduced dataset, IJB-FL [14] (a subset of IJB-A [17]), which includes a large proportion of profile face poses with extremely challenging conditions for landmark detection.", "startOffset": 149, "endOffset": 153}, {"referenceID": 25, "context": "We demonstrate the benefits of our DCLM facial landmark detection algorithm through extensive experiments on three publicly available datasets, 300W [23], 300VW [29], and a newly introduced dataset, IJB-FL [14] (a subset of IJB-A [17]), which includes a large proportion of profile face poses with extremely challenging conditions for landmark detection.", "startOffset": 161, "endOffset": 165}, {"referenceID": 13, "context": "We demonstrate the benefits of our DCLM facial landmark detection algorithm through extensive experiments on three publicly available datasets, 300W [23], 300VW [29], and a newly introduced dataset, IJB-FL [14] (a subset of IJB-A [17]), which includes a large proportion of profile face poses with extremely challenging conditions for landmark detection.", "startOffset": 206, "endOffset": 210}, {"referenceID": 15, "context": "We demonstrate the benefits of our DCLM facial landmark detection algorithm through extensive experiments on three publicly available datasets, 300W [23], 300VW [29], and a newly introduced dataset, IJB-FL [14] (a subset of IJB-A [17]), which includes a large proportion of profile face poses with extremely challenging conditions for landmark detection.", "startOffset": 230, "endOffset": 234}, {"referenceID": 16, "context": "Facial landmark detection has been used in number of research directions such as facial attribute detection [18], facial expression analysis [22], emotion recognition and sentiment analysis [36], and 3D facial reconstruction [13].", "startOffset": 108, "endOffset": 112}, {"referenceID": 19, "context": "Facial landmark detection has been used in number of research directions such as facial attribute detection [18], facial expression analysis [22], emotion recognition and sentiment analysis [36], and 3D facial reconstruction [13].", "startOffset": 141, "endOffset": 145}, {"referenceID": 31, "context": "Facial landmark detection has been used in number of research directions such as facial attribute detection [18], facial expression analysis [22], emotion recognition and sentiment analysis [36], and 3D facial reconstruction [13].", "startOffset": 190, "endOffset": 194}, {"referenceID": 12, "context": "Facial landmark detection has been used in number of research directions such as facial attribute detection [18], facial expression analysis [22], emotion recognition and sentiment analysis [36], and 3D facial reconstruction [13].", "startOffset": 225, "endOffset": 229}, {"referenceID": 9, "context": "A full review of work in facial landmark detection and head pose estimation is outside the scope of this paper, we refer the reader to some recent reviews of the field [10, 34].", "startOffset": 168, "endOffset": 176}, {"referenceID": 29, "context": "A full review of work in facial landmark detection and head pose estimation is outside the scope of this paper, we refer the reader to some recent reviews of the field [10, 34].", "startOffset": 168, "endOffset": 176}, {"referenceID": 23, "context": "A popular local method for landmark detection is the Constrained Local Model [26] and its various extensions such as Constrained Local Neural Fields [2] and Discriminative Response Map Fitting [1] that use more advanced ways of computing local response maps and inferring the landmark locations.", "startOffset": 77, "endOffset": 81}, {"referenceID": 1, "context": "A popular local method for landmark detection is the Constrained Local Model [26] and its various extensions such as Constrained Local Neural Fields [2] and Discriminative Response Map Fitting [1] that use more advanced ways of computing local response maps and inferring the landmark locations.", "startOffset": 149, "endOffset": 152}, {"referenceID": 0, "context": "A popular local method for landmark detection is the Constrained Local Model [26] and its various extensions such as Constrained Local Neural Fields [2] and Discriminative Response Map Fitting [1] that use more advanced ways of computing local response maps and inferring the landmark locations.", "startOffset": 193, "endOffset": 196}, {"referenceID": 27, "context": "Project out Cascaded regression (PO-CR) [32] is another example of a local approach, but one that uses a cascaded regression to update the shape model parameters rather than predicting landmark locations directly.", "startOffset": 40, "endOffset": 44}, {"referenceID": 34, "context": "Another noteworthy local approach is the mixture of trees model [39] that uses a tree based deformable parts model to jointly perform face detection, pose estimation and facial landmark detection.", "startOffset": 64, "endOffset": 68}, {"referenceID": 28, "context": "A notable extension to this approach is the Gauss-Newton Deformable Part Model (GNDPM) [33] which jointly optimizes a part-based flexible appearance model along with a global shape using GaussNewton optimization.", "startOffset": 87, "endOffset": 91}, {"referenceID": 5, "context": "in explicit shape regression [6].", "startOffset": 29, "endOffset": 32}, {"referenceID": 30, "context": "Other cascaded regression approaches include the Stochastic Descent Method (SDM) [35] which uses SIFT [21] features with linear regression to compute the shape update and Coarse-to-Fine Shape Searching (CFSS) [38] which attempts to avoid a local optima in cascade regression by performing a coarse to fine shape search.", "startOffset": 81, "endOffset": 85}, {"referenceID": 18, "context": "Other cascaded regression approaches include the Stochastic Descent Method (SDM) [35] which uses SIFT [21] features with linear regression to compute the shape update and Coarse-to-Fine Shape Searching (CFSS) [38] which attempts to avoid a local optima in cascade regression by performing a coarse to fine shape search.", "startOffset": 102, "endOffset": 106}, {"referenceID": 33, "context": "Other cascaded regression approaches include the Stochastic Descent Method (SDM) [35] which uses SIFT [21] features with linear regression to compute the shape update and Coarse-to-Fine Shape Searching (CFSS) [38] which attempts to avoid a local optima in cascade regression by performing a coarse to fine shape search.", "startOffset": 209, "endOffset": 213}, {"referenceID": 32, "context": "Coarse-to-Fine Auto-encoder Networks (CFAN) [37] use visual features extracted by an auto-encoder together with linear regression.", "startOffset": 44, "endOffset": 48}, {"referenceID": 26, "context": "[31] proposed a Convolutional Neural Network (CNN) based cascaded regression approach for sparse landmark detection; however while their approach is robust it is not very accurate.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "Point Distribution Models [8, 26] are used as shape regularizers in DCLM framework.", "startOffset": 26, "endOffset": 33}, {"referenceID": 23, "context": "Point Distribution Models [8, 26] are used as shape regularizers in DCLM framework.", "startOffset": 26, "endOffset": 33}, {"referenceID": 1, "context": "The most common method to solve equation 1 is using Non-Uniform Regularized Landmark Mean Shift (NURLMS) [2].", "startOffset": 105, "endOffset": 108}, {"referenceID": 1, "context": "8 DPN patch experts LNF patch experts [2] SVR patch experts [26] DPN (no TP) patch expert DPN (no DA) patch expert", "startOffset": 38, "endOffset": 41}, {"referenceID": 23, "context": "8 DPN patch experts LNF patch experts [2] SVR patch experts [26] DPN (no TP) patch expert DPN (no DA) patch expert", "startOffset": 60, "endOffset": 64}, {"referenceID": 1, "context": "DPN consistently and significantly outperforms LNF [2] and SVR [26].", "startOffset": 51, "endOffset": 54}, {"referenceID": 23, "context": "DPN consistently and significantly outperforms LNF [2] and SVR [26].", "startOffset": 63, "endOffset": 67}, {"referenceID": 1, "context": "In our experiments we first we show that DPN networks significantly perform better than LNF [2] and SVR [26] local detectors (patch experts).", "startOffset": 92, "endOffset": 95}, {"referenceID": 23, "context": "In our experiments we first we show that DPN networks significantly perform better than LNF [2] and SVR [26] local detectors (patch experts).", "startOffset": 104, "endOffset": 108}, {"referenceID": 1, "context": "We then compare the performance of DPN with LNF [2] and SVR [26] patch experts followed by an ablation study to investigate the crucial role of TP and DA layers.", "startOffset": 48, "endOffset": 51}, {"referenceID": 23, "context": "We then compare the performance of DPN with LNF [2] and SVR [26] patch experts followed by an ablation study to investigate the crucial role of TP and DA layers.", "startOffset": 60, "endOffset": 64}, {"referenceID": 20, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 6, "endOffset": 14}, {"referenceID": 22, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 6, "endOffset": 14}, {"referenceID": 34, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 111, "endOffset": 115}, {"referenceID": 21, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 122, "endOffset": 126}, {"referenceID": 4, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 145, "endOffset": 152}, {"referenceID": 17, "context": "300-W [23, 25] is a meta-dataset of four different facial landmark datasets: Annotated Faces in the Wild (AFW) [39], iBUG [24], and LFPW + Helen [5, 19] datasets.", "startOffset": 145, "endOffset": 152}, {"referenceID": 13, "context": "IJB-FL [14] is a dataset which has a substantial proportion of non-frontal images.", "startOffset": 7, "endOffset": 11}, {"referenceID": 15, "context": "It is a subset of IJB-A [17] which is a face recognition benchmark and includes chal-", "startOffset": 24, "endOffset": 28}, {"referenceID": 25, "context": "300-VW[29] is a dataset with 114 videos labeled for 68 facial landmarks for every frame.", "startOffset": 6, "endOffset": 10}, {"referenceID": 33, "context": "(CFSS) [38] \u2013 Coarse to Fine Shape Search is a cascaded regression approach which attempts to avoid a local optima", "startOffset": 7, "endOffset": 11}, {"referenceID": 20, "context": "It is the most recent state-of-the-art approach on the 300W competition data [23, 7].", "startOffset": 77, "endOffset": 84}, {"referenceID": 6, "context": "It is the most recent state-of-the-art approach on the 300W competition data [23, 7].", "startOffset": 77, "endOffset": 84}, {"referenceID": 2, "context": "CLNF is an extension of the Constrained Local Model that uses Continuous Conditional Neural Fields as patch experts [3].", "startOffset": 116, "endOffset": 119}, {"referenceID": 27, "context": "PO-CR [32] \u2013 is another recent cascaded regression approach that updates the shape model parameters rather than predicting landmark locations directly in a projected-out space.", "startOffset": 6, "endOffset": 10}, {"referenceID": 0, "context": "We use the implementation provided by the authors [1] that was trained on LFPW [5] and Multi-PIE [11] datasets.", "startOffset": 50, "endOffset": 53}, {"referenceID": 4, "context": "We use the implementation provided by the authors [1] that was trained on LFPW [5] and Multi-PIE [11] datasets.", "startOffset": 79, "endOffset": 82}, {"referenceID": 10, "context": "We use the implementation provided by the authors [1] that was trained on LFPW [5] and Multi-PIE [11] datasets.", "startOffset": 97, "endOffset": 101}, {"referenceID": 30, "context": "We use implementation from the authors [35].", "startOffset": 39, "endOffset": 43}, {"referenceID": 11, "context": "This approach is trained on the MultiPIE and LFW [12] datasets.", "startOffset": 49, "endOffset": 53}, {"referenceID": 28, "context": "GNDPM [33] \u2013 is a deformable parts model which jointly optimizes a part-based flexible appearance model.", "startOffset": 6, "endOffset": 10}, {"referenceID": 34, "context": "Tree based face and landmark detector, is a deformable parts model for jointly detecting faces, landmarks and head orientation proposed by Zhu and Ramanan [39].", "startOffset": 155, "endOffset": 159}, {"referenceID": 0, "context": "We used a model trained on in-the-wild datasets [1].", "startOffset": 48, "endOffset": 51}, {"referenceID": 23, "context": "CLM+ model uses linear SVR patch experts and regularised landmark mean-shift fitting [26].", "startOffset": 85, "endOffset": 89}, {"referenceID": 23, "context": "[26], as our model includes a multimodal (patch experts trained on raw pixel and gradient images) and multi-scale formulation leading to more accurate landmark detection.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "We use a freely available implementation [4].", "startOffset": 41, "endOffset": 44}, {"referenceID": 14, "context": "For 300VW we detected the face in every 30th frame of each video using the dlib [15] library.", "startOffset": 80, "endOffset": 84}, {"referenceID": 33, "context": "Figure 8: Example images where our DCLM approach outperforms CFSS [38] and CLNF [2].", "startOffset": 66, "endOffset": 70}, {"referenceID": 1, "context": "Figure 8: Example images where our DCLM approach outperforms CFSS [38] and CLNF [2].", "startOffset": 80, "endOffset": 83}], "year": 2017, "abstractText": "Among the well-established methods for facial landmark detection is the family of Constrained Local Models (CLMs). An important part of CLM landmark alignment pipeline are the local detectors that estimate the alignment probability of each individual landmark over the facial region. In this paper we present Deep Constrained Local Model (DCLM) algorithm and the novel Dense-Projection Network (DPN) as a local detector. DPN is a deep neural network that consists of two important layers: Template Projection layer and Dense Aggregate layer. In Template Projection layer, patches of facial region are mapped to a higher dimensional space allowing the pose and rotation variations to be captured accurately. In Dense Aggregate layer an ensemble of experts is simulated within one network to make the landmark localization task more robust. In our extensive set of experiments we show that DPNs outperform previously proposed local detectors. Furthermore, we demonstrate that our proposed DCLM algorithm is stateof-the-art in facial landmark detection. We significantly outperform competitive baselines, that use both CLM-based and cascaded regression approaches, by a large margin on three publicly-available datasets for image and video landmark detection.", "creator": "LaTeX with hyperref package"}}}