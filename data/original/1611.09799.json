{"id": "1611.09799", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Nov-2016", "title": "Geometry of Compositionality", "abstract": "This paper proposes a simple test for compositionality (i.e., literal usage) of a word or phrase in a context-specific way. The test is computationally simple, relying on no external resources and only uses a set of trained word vectors. Experiments show that the proposed method is competitive with state of the art and displays high accuracy in context-specific compositionality detection of a variety of natural language phenomena (idiomaticity, sarcasm, metaphor) for different datasets in multiple languages. The key insight is to connect compositionality to a curious geometric property of word embeddings, which is of independent interest.", "histories": [["v1", "Tue, 29 Nov 2016 19:23:41 GMT  (1434kb,D)", "http://arxiv.org/abs/1611.09799v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["hongyu gong", "suma bhat", "pramod viswanath"], "accepted": true, "id": "1611.09799"}, "pdf": {"name": "1611.09799.pdf", "metadata": {"source": "CRF", "title": "Geometry of Compositionality", "authors": ["Hongyu Gong", "Pramod Viswanath"], "emails": ["hgong6@illinois.edu,", "spbhat2@illinois.edu,", "pramodv@illinois.edu"], "sections": [{"heading": "1 Introduction", "text": "Idiomatic expressions and figurative speech are key components of the creative process that embodies natural language. One expression type is multiword expressions (MWEs) \u2013 phrases with semantic idiosyncrasies that cross word boundaries (Sag et al., 2002). Examples of MWEs include by and large, spill the beans and part of speech. As such, these phrases are idiomatic, in that their meanings cannot be inferred from the meaning of their component words, and are hence termed non-compositional phrases as opposed to being compositional phrases.\nA particularly intriguing aspect of MWEs is their ability to take on degrees of compositionality depending on the context they are in. For example, consider two contexts in which the phrase bad egg occurs.\n(1) Ensure that one bad egg doesn\u2019t spoil good businesses for those that care for their clientele. (2) I don\u2019t know which hen is laying the bad egg but when I crack it, it explodes! It is all creamy yellowish with very little odor. In (1), the phrase has a non-compositional interpretation to mean \u2018an unpleasant person\u2019, whereas in (2), the phrase has the meaning of a noun phrase whose head is egg and modifier is bad. This contextdependent degree of compositionality of an MWE poses significant challenges to natural language processing applications. In machine translation, instead of processing the MWE as a whole, literal translation of its components could result in a meaningless phrase in the target language, e.g., chemin de fer from French to English to be way of iron in place of railway (Bouamor et al., 2012). In information retrieval, the retrieved document matching a component word is irrelevant given the meaning of the MWE hot dog. Hence, identifying the compositionality of MWEs is an important subtask in all these systems.\nAs another example, consider the word love in the following two contexts. In the first: \u201cI love going to the dentist. Been waiting for it all week!\u201d, the word has a non-literal (hence non-compositional) and sarcastic interpretation to actually mean the exact opposite of the literal (compositional) sense, which is to \u201clike\u201d. In the second: \u201cI love strawberry ice cream; it\u2019s simply my favorite\u201d, the same word has the compositional meaning. Again, the degree of compositionality is crucially context-dependent.\nYet another example of compositionality involves metaphors. Consider the word angel in the follow-\nar X\niv :1\n61 1.\n09 79\n9v 1\n[ cs\n.C L\n] 2\n9 N\nov 2\ning two contexts: (1) The girl is an angel; she is helpful to the children. (2) The angels are sure keeping busy, what with all his distractions and mishaps. In (1) the word has a figurative sense (i.e., noncompositional interpretation) whereas in (2), the word has the compositional meaning of a \u201cdivine being\u201d. Again, the degree of compositionality is crucially context-dependent.\nIn this paper our focus is to decide the compositionality of a word or a phrase using its local linguistic context. Our approach only relies on the use of word embeddings, which capture the \u201cmeaning\u201d of a word using a low-dimensional vector. Our compositionality prediction algorithm brings two key innovations: (1) It leverages the crucial contextual information that dictates the compositionality of a phrase or word; (2) The prediction mechanism is completely independent of external linguistic resources. Both these are significant improvements over recent works with similar goals: compositionality of MWEs (Salehi et al., 2015), works on sarcasm (Wallace et al., 2014) and metaphor detection (Tsvetkov et al., 2014) (the latter works rely significantly on external linguistic resources and access to labeled training data). To the best of our knowledge, this is the first study on context-dependent phrase compositionality in combination with word embeddings and the first resource-independent study on sarcasm and metaphor identification. This work is centered around two primary questions: (1) How can the semantics of a long context be represented by word embeddings? (2) How can we decide the compositionality of a phrase based on its embeddings and that of its context?\nWe answer these questions by connecting the notion of compositionality to a geometric property of word embeddings. The key insight is that the context word vectors (suitably compressed) reside roughly in a low dimensional linear subspace and compositionality turns out to be related to the projection of the word/phrase embeddings (suitably compresed to a single vector) onto this context subspace.\nThe key justification for our approach comes from empirical results that outperform state of the art methods on many metrics, while being competi-\ntive on the others. We use three standard datasets spanning two MWE construction types (noun compounds and verb particle constructions) in two languages (English and German) in addition to a dataset in Chinese (heretofore unexplored language), and standard datasets for detection of metaphor and sarcasm in addition to a new dataset for sarcasm detection from Twitter. We summarize our contributions: Compositional Geometry: We show that a word (or MWE) and its context are geometrically related as jointly lying in a linear subspace, when it appears in a compositional sense, but not otherwise. Compositionality decision: The only input to the algorithm is a set of trained word vectors after the preprocessing step of removing function words on which, the algorithm performs a simple principle component analysis (PCA) operation. Multi-lingual applicability: The algorithm is very general, relies on no external resources and is agnostic to the specifics of one language; we demonstrate strong test results across different languages.\nWe begin next with a discussion of the geometry of compositionality leading directly to our contextbased algorithm for compositionality detection. The test is competitive with or superior to state of the art in a variety of contexts and languages, and in various metrics."}, {"heading": "2 Compositionality and the Geometry of Word Embeddings", "text": "Our goal is to detect the compositionality level of a given occurrence of a word/phrase within a sentence (the context). Our main contribution is the discovery of a geometric property of vector embeddings of context words (excluding the function words) within a sentence: they roughly occupy a low dimensional linear subspace which can be empirically extracted via a standard dimensionality reduction technique: principal component analysis (PCA) (Shlens, 2014).\nWe stack the d-dimension vectors v1, . . . , vn, corresponding to n words in a sentence, to form a d\u00d7n matrix X . PCA finds a d \u00d7 m(m < n) matrix X \u2032 which maximizes the data variance with reduced dimension. Here X \u2032 consists of m new vectors, v\u20321, ..., v \u2032 m. Now the original data X is represented by fewer vectors of X \u2032, where vectors v and v\u2032 are d-dimensional (m is chosen such that a large enough\nfraction \u2013 a hyperparameter \u2013 of the variance of X is captured in X \u2032).\nWhen the phrase of interest occurs in a compositional sense, then the phrase\u2019s compositional embedding is roughly close to the subspace associated with the context embeddings (extracted using PCA from context words). Intuitively this happens because compositionality is tantamount to individual words themselves being directly related (i.e., occur together often enough) to (a majority of) the context words.\nWe illustrate this phenomenon via an example found in Table 1. Consider the phrase \u201ccutting edge\u201d. When words like sharp, side and tool appear in the context, \u201ccutting edge\u201d tends to have a compositional meaning. Conversely, when words like productions, technology and competitive are in the context, \u201ccutting edge\u201d is more likely to be an idiom. We project the embeddings of the phrase and the two contexts to three-dimensions to visualize the geometric relationship, cf. Figure 1.\nIt is immediate that the phrase embedding occupies the same subspace as the context when it is\nused in the compositional sense, while it is far from the subspace of the context when used in the noncompositional sense. The precise formulation of the projection operations used in this illustration is discussed next.\nSuppose a sentence t consists of n content words {w1, ..., wn} with respective vector embeddings {v1, ..., vn}. Two possible representations of the \u201cmeaning\u201d of t are the following: average vector representation: vt = v1 + ... + vn, adding all component word vectors together, as in (Mitchell and Lapata, 2010) and several works on phrase2vec (Gershman and Tenenbaum, 2015) and sentence2vec (Faruqui et al., 2015; Wieting et al., 2015; Adi et al., 2016). PCA subspace representation: Denote the word vectors by X = [v1, . . . , vn], and the PCA output X \u2032 = [v\u20321, ..., v \u2032 m], where v \u2032 i are the principal components extracted from X using the PCA operation. Now the sentence t is represented by the (span of columns of) matrix X \u2032 instead of a single vector as in average vector representation. Choosing to represent the sentence by multiple vectors is a key innovation of this paper and is fairly critical to the empirical results we demonstrate.\nNote that the PCA operation returns a (d\u00d7m) matrix X \u2032 and thus PCA is used to reduce the \u201cnumber of word vectors\u201d instead of the embedding dimension. In our experiments, d = 200, n \u2248 10\u221220, and m \u2248 3. PCA extracts the most important information conveyed in the sentence with only m vectors. Further, we only take the linear span of the m principal directions (column span of X \u2032), i.e., a subspace as the representation of sentence t.\nLet p be a single word (in the metaphor and sarcasm settings) or a bigram phrase (in the MWE setting) that we would like to test for compositional use. Suppose that p has a single-vector representation vp, and the context embedding is represented by the subspace Sc spanned by the m vectors (v\u20321, . . . , v \u2032 m). Our test involves projecting the phrase embedding vp on the context subspace Sc. Denote the orthogonal projection vector by v\u2032p, where v \u2032 p lies in Sc, and v\u2032p = argmax v\u2208Rd vT vp \u2016v\u2016\u00b7\u2016vp\u2016 . Compositionality Score is the cosine distance between vp and v\u2032p (the inner product between the vectors normalized by their lengths); this measures the\ndegree to which the word/phrase meaning agrees with its context: the larger the cosine similarity, the more the compositionality.\nBased on the commonly-used distributional hypothesis that the word or phrase meaning can be inferred from its context (Rubenstein and Goodenough, 1965), we note that the local context (neighboring words) is crucial in deciphering the compositional sense of the word or phrase. This is in contrast to prior works that use the global context alone (the whole document or corpus), without accounting for the context-dependence of polysemy (Reddy et al., 2011).\nAt times, the word(s) being tested exhibit polysemous behavior (example: check in blank check) (Mu et al., 2016). In such cases, it makes sense to consider multiple embeddings for different word senses (we use MSSG representations (Neelakantan et al., 2014)): each word has a single global embedding and two sense embeddings. We propose to use global word embeddings to represent the context, and use sense embeddings for phrase semantics, allowing for multiple compositionality scores. We then measure the relevance between a phrase and its context by the maximum of the different compositionality scores.\nOur compositionality detection algorithm uses only two hyperparameters: variance ratio (used to decide the amount of variance PCA should capture) and threshold (used to test if the compositionality score is above or below this value). Since compositionality testing is essentially a supervised learning task: in order to provide one of two labels, we need\nto tune these parameters based on a (gold) training set. We see in the experiment sections that these parameters are robustly trained on small training sets and are fairly invariant in their values across different datasets, languages and tasks (variance ratio equal to about 0.6 generally achieves good performance)."}, {"heading": "3 MWE Compositionality Detection", "text": "We evaluate our context-based compositionality detection method empirically by considering 3 specific, but vastly distinct, tasks: a) Predicting the compositionality of phrases that can have either the idiomatic sense or the literal sense depending on the context (the focus of this section), b) Sarcasm detection at the level of a specific word and at the level of a sentence, and c) Detecting whether a given phrase has been used in its metaphoric sense or literal sense. The latter two tasks are the focus of the next two sec-\ntions. For each of the tasks we use standard datasets used in state-of-the-art studies, as well as those we specifically constructed for the experiments. We include datasets in German and Chinese in addition to those available in English to highlight the multilingual and language-agnostic capabilities of our algorithm.\nThe training corpus of embeddings in English, Chinese and German are obtained from polyglot (Al-Rfou et al., 2013). Two types of word embeddings are used in the experiments: global ones using CBOW of word2vec (Mikolov et al., 2014), and sense-specific ones using NP-MSSG of MSSG (Neelakantan et al., 2014)."}, {"heading": "3.1 Experiment I: Phrase Compositionality", "text": "In this part, we evaluate the performance of our algorithm in capturing the semantics of the context and predicting the compositionality of phrases, which we cast as a binary classification task \u2013 to decide the phrase compositionality in each context. With reference to the examples in Table 1, the task is to predict that the phrase cutting edge is used in its compositional sense in the first instance and a noncompositional one in the second. We perform experiments with different word embeddings (CBOW and MSSG), as well as different composition representations for both the phrase and the context (average and PCA).\nBi-context Dataset: We construct 2 datasets 1 (one for English and the other for Chinese) consisting of a list of phrases and their respective contexts (compositional and non-compositional). The English dataset contains 104 polysemous phrases which are obtained from the idiom dictionary (TheFreeDictionary, 2016), and the Chinese dataset consists of 64 phrases obtained from (ChineseDictionary, 2016). Their respective contexts are extracted from the corpus provided by polyglot or electronic resources (GoogleBooks, 2016). Native English and native Chinese speakers annotated the phrase compositionality for each context.\nDetection Results: We used both average and PCA subspace representations for the target phrase and its context. The results, shown as accuracy values, obtained by comparing the predicted labels with the gold labels provided by human annotators, are available in Table 2. Since the average vector representation is commonly used in recent works, we take \u201cavg phrase + avg context\u201d as our baseline. We note that having a PCA approximation for both the phrase and the context, and the use of MSSG embedding yielded the best accuracy for this task in both the English and the Chinese datasets; this is an instance where the PCA subspace representation is superior to the average representation. We believe that unsu-\n1available at: https://github.com/HongyuGong/ Geometry-of-Compositionality.git\npervised improvement beyond the fairly high accuracy rates is likely to require substantially new ideas as compared to those in this paper."}, {"heading": "3.2 Experiment II: Lexical Idiomaticity", "text": "Unlike compositionality detection in Experiment I, here we detect component-wise idiomaticity of a two-word phrase in this experiment. For example, \u201cspelling\u201d is literal while \u201cbee\u201d is idiomatic in the phrase \u201cspelling bee\u201d. Modifying our method slightly, we take the cosine distance between the embedding of the target word (the first or the second word) and its projection to the space of its context as the measurement of lexical idiomaticity. The smaller the cosine distance, the more idiomatic the component word is. Here we use three datasets available from prior studies for the same task \u2013 ENC, EVPC and GNC \u2013 and compare our results with the state-of-art in idiomaticity detection.\nDataset: The English noun compounds dataset (ENC), has 90 English noun compounds annotated on a continuous [0, 5] scale for the phrase and component-wise compositionality (Reddy et al., 2011); the English verb particle constructions (EVPC) contains 160 English verb-particle compounds, whose componentwise compositionality are annotated on a binary scale (Bannard, 2006). German noun compounds (GNC), which contains 246 German noun compounds annotated on a continuous [1,7] scale for phrase and component compositionality (Schulte im Walde et al., 2013). In this paper, we cast compositionality prediction as a binary classification task. We set the same threshold of 2.5 to ENC as in (Salehi et al., 2014a), a threshold of 4 to GNC and use the binary labels of EVPC. The components with score higher than the threshold are regarded as literal, otherwise, they are idiomatic.\nDetection Results: Our subspace representation (SubSpace) uses CBOW and MSSG embeddings, and we use both average and PCA approximations as context embeddings. Their performance is shown in the row of \u201cSubSpace (CBOW)\u201d and \u201cSubSpace (MSSG)\u201d respectively. We have two baseline methods: (1) pointwise mutual information (PMI). PMI = log P (w1w2)P (w1)P (w2) , where P (\u00b7) is the probability of the unigram or bigram (Manning and Schu\u0308tze, 1999). Higher PMI indicates the phrase is more likely to be non-compositional. (2) Average sen-\ntence embedding method. While we use PCA, several recent works have shown average word vectors to be robust sentence embeddings (Ettinger et al., 2016; Adi et al., 2016; Wieting et al., 2015) and we measure compositionality by the cosine similarity between the target word vector and the sentence vector. The corresponding performance is reported in the rows of \u201cAvg Cxt (CBOW)\u201d and \u201cAvg Cxt (MSSG)\u201d. We only report the best performance of each method in Table 3. We compare with the state-of-the-art of (Salehi et al., 2014a), specifically their methods based on word definitions, synonyms and idiom tags (denoted by ALLDEFS+SYN, ITAG+SYN, ALLDEFS) provided by wikitionary. As we can see from Table 2, our method compares favorably to the state-ofart performance while outperforming two baseline methods. The key advantage of our method is its non-reliance on external resources like wikitionary or multilingual translations \u2013 these are heavily relied upon in the state-of-the-art methods (Salehi et al., 2014a; Salehi et al., 2014b). Also, unlike the assumption in (Salehi et al., 2015), we do not require that the test phrases appear in the training corpus."}, {"heading": "4 Sarcasm Detection", "text": "Sarcasms, also called irony, are expressions whose actual meaning is quite different - and often opposite to - their literal meaning \u2013 and are instances of noncompositional usage (Davidov et al., 2010; Riloff et al., 2013). For example, the word \u2018nice\u2019 is used in a sarcastic sense in \u2018It\u2019s so nice that a cute video of saving an animal can quickly turn the comments into politcal debates and racist attacks\u2019. The context clues identify sarcasm; in this example, \u2018nice\u2019 is inconsistent with its context words \u2018debate\u2019 and \u2018attacks\u2019. These ideas are used in prior works to create elaborate features (designed based on a large labeled training set) and build a sarcasm detection system (Ghosh et al., 2015). We evaluate our compositionality detection algorithm directly on this task."}, {"heading": "4.1 Qualitative Test", "text": "Datasets: Tweets are ideal sources of sarcasm datasets. We use a subset of the tweets in the dataset of (Ghosh et al., 2015) and study words that are used both literally and sarcastically (eg., love, like, fa-\nvorite, always) for their compositionality.\nWe choose six words \u201cgood\u201d, \u201clove\u201d, \u201cyeah\u201d, \u201cglad\u201d, \u201cnice\u201d and \u201calways\u201d, which occur with enough frequency in both literal and sarcastic senses in our downloaded dataset. Take the word \u2018nice\u2019 as an example and consider its occurrence in the sentence \u201cIt\u2019s so nice that a cute video of saving an animal can quickly turn the comments into politcal debates and racist attacks\u201d. Our compositionality scoring algorithm (cf. Section 2) is applicable here directly: we extract the neighboring content words:{cute, video, saving, animal, quickly, turn comments, into, political, debates, racist, attacks} and the result of PCA on the vectors associated with these words yields the subspace sentence representation. By projecting the word embedding of \u2018nice\u2019 onto this subspace, we get the compositionality score indicating how literal \u2018nice\u2019 is in the given sentence. The lower the score, the more sarcastic the word.\nThe histograms of the compositionality scores for these six words \u201cgood\u201d, \u201clove\u201d, \u201cyeah\u201d, \u201cglad\u201d, \u201cnice\u201d and \u201calways\u201d (for sarcastic and literal usages) are plotted in Fig. 2. We can visually see that the two\nhistograms (one for sarcastic usage and the other for literal usage) can be distinguished from each other, for each of these three words. The histogram of sarcastic usage occupies the low-score region with peak in the [0.3, 0.4) bin, while the histogram of literal usage occupies the high-score region with peak in the [0.4, 0.5) bin. This shows that our simple resourceindependent compositionality scoring method can distinguish sarcasm and non-sarcasm to some extent.\nTo quantify this extent, we report the accuracy and F1 scores of a simple threshold classifier in each of the six instances in Table 4. We emphasize that this performance is derived for a very small dataset (for each of the words) and is achieved using entirely only a trained set of word vectors \u2013 this would be a baseline to build on for the more sophisticated supervised learning systems."}, {"heading": "4.2 Quantitative Test", "text": "A quantitative test is provided via our study on a Reddit irony dataset (Wallace et al., 2014). This dataset consists of 3020 annotated comments containing 10401 sentences in total, and each comment is labeled with \u201cironic\u201d, \u201cdon\u2019t know\u201d and \u201cunironic\u201d. An example of an ironic comment is \u201cIt\u2019s amazing how Democrats view money. It has to come from somewhere you idiots and you signed up to foot the bill. Congratulations.\u201d The task is to identify whether a given comment is ironic or not. (Wallace et al., 2014) considers the 50,000 most frequently occurring unigrams and bigrams, and use binary bag-of-words and punctuations as features followed by a linear kernel SVM, grid-search for parameter tuning and five-fold cross validation. Instead, we generate compositionality-score features based on POS tags to allow a direct comparison with the state-of-the-art in (Wallace et al., 2014).\nAlgorithm Description: For a given comment, we first select words that might have sarcastic meaning based on their POS tags: adjectives (like \u2018favorite\u2019), adverbs (like \u2018happily\u2019) and verbs (like \u2018love\u2019) are likely to be used in irony, and we pick candidate words whose POS tag are JJ (adjective), RB (adverb), or VB (verb). For each of the selected words in a given sentence, we obtain its compositionality score with respect to its local context. Among all these scores, we choose k smallest scores as features (here k = 2, 3, 4 refers to a very small number of features, cf. Table 5). These features are then fed into the same supervised learning system as in (Wallace et al., 2014), providing a fair comparison between the two featureselection methods.\nResults: The experiment results of using compositionality scores as features instead are shown in Table 5 \u2013 we use much fewer features than the baseline and also get comparable results; indeed in some\ninstances (such as JJ+RB class), we achieve a 5% higher F1 score over the baseline system."}, {"heading": "5 Metaphor Detection", "text": "Metaphors are usually used to express the conceptual sense of a word in noncompositional contexts: in the sentence \u201cComprehensive solutions marry ideas favored by one party and opposed by the other\u201d, the intended meaning of \u201cmarry\u201d is \u201ccombine\u201d, a significant (and figurative) generalization of its literal meaning. As such, metaphors form a key part of noncompositional semantics and are natural targets to study in our generic framework.\nDataset: English datasets comprising of metaphoric and literal uses of two syntactic structures (subject-verb-object (SVO) and adjective-noun (AN) compounds) are provided in (Tsvetkov et al., 2014). An example of an SVO metaphor is \u201cThe twentieth century saw intensive development of new technologies\u201d, and an example of an AN metaphor is \u201cblack humor seems very Irish to me\u201d. Our task is to decide whether a given sentence containing either SVO or AN structure is used as a metaphor. The SVO dataset contains 111 literal and 111 metaphorical phrases while the AN dataset contains 100 literal and 100 metaphorical phrases.\nAlgorithm Description: The state-of-the-art work (Tsvetkov et al., 2014) uses training-datadriven feature engineering methods while relying on external resources like WordNet and the MRC psycholinguistic database. We depart by using the unsupervised scores generated by our compositionality detection algorithm, albeit specific to POS tags\n(critical for this particular dataset since it is focused on specific syntactic structures), as features for metaphor detection.\nFor each word in the SVO or AN structure, we obtain a compositionality score with respect to its local context and derive features from these scores: The features we derive for the SVO dataset from these scores are: (1) the lowest score in SVO; (2) verb score; (3) ratio between lowest score and highest score; (4) min (verb scoresubj score , subj score verb score , verb score obj score , obj score verb score).\nIn the sentence \u201cThe twentieth century saw intensive development of new technologies\u201d, \u2018century\u2019 (subject), \u2018saw\u2019 (verb) and \u2018development\u2019 (object) form the SVO structure. The compositionality scores of the subject, verb and object, are computed as outlined in Section 2.\nIf an SVO phrase is a metaphor, then we expect there will be at least one word which is inconsistent with the context. Thus we include the lowest score as one of the features. Also, the verb score is a feature since verbs are frequently used metaphorically in a phrase. The absolute score is very sensitive to the context, and we also include relative scores to make the features more robust. The relative scores are the ratio between the lowest score and the highest score, and the minimum ratio between verb and subject or object.\nThe features we get for AN dataset from these scores are: (1) the lowest score in AN; (2) the highest score; (3) ratio between the lowest and the highest score. In the sentence \u201cblack humor seems very Irish to me\u201d, \u2018black\u2019 (adjective) and \u2018humor\u2019 form the AN structure. We calculate compositionality scores for these two words \u2018black\u2019 and \u2018humor\u2019, and use them to generate the features described above.\nThese features are then fed into a supervised learning system (random forest), analogous to the one in (Tsvetkov et al., 2014) allowing for a fair comparison of the power of the features extracted.\nDetection Results: The experimental results on SVO and AN datasets are detailed in Table 6 where the baseline is provided by the results of (Tsvetkov et al., 2014) (which has access to the MRC psycholinguistic database and the supersense corpus). On the full set of original sentences, the performance of our compositionality detection algorithm (with only four features in stark contrast to the more than\n100 used in the state of the art) is not too far from the baseline.\nUpon a closer look, we find that some of the original sentences are too short, e.g. \u201cThe bus eventually arrived\u201d. Our context-based method naturally does better with longer sentences and we purified the dataset by replacing sentences whose non-functional words are fewer than 7 with longer sentences extracted from Google Books. We rerun our experiments and the performance on the longer sentences is improved, although it is still a bit below the baseline \u2013 again, contrast the very large number of features (extracted using significant external resources) used in the baseline to just 3 or 4 of our approach (extracted in a resource-independent fashion)."}, {"heading": "6 Related Works", "text": "Average sentence approximation: Using the average of word embeddings to represent the sentence is a simple, yet robust, approach in several settings. For instance, such a representation is successfully used for sentential sentiment prediction (Faruqui et al., 2015) and in (Kenter and de Rijke, 2015) to study text similarity. Average word embeddings are also used (Kenter et al., 2016) in conjunction with a neural network architecture to predict the surrounding sentences from the input sentence embeddings. Computational models of sentential semantics have also shown to be robustly handled by average word embeddings (Yu et al., 2014; Gershman and Tenenbaum, 2015; Adi et al., 2016; Wieting et al., 2015). In the compositionality testing experiments of this paper, the average representation performs reasonably well, although the subspace representation is statistically significantly superior. Compositionality Detection: Among the approaches to predict the idomaticity of MWEs, external linguistic resources are natural sources to rely on. Early approaches relied on the use of specific lexical and syntactic properties of MWEs (Lin, 1999; McCarthy et al., 2003; Cook et al., 2007; Fazly and Stevenson, 2007). More recent approaches include multilingual translations (Salehi and Cook, 2013; Salehi et al., 2014b) and using Wikitionary (one approach uses its word definitions, idiom tagging together with word synonyms to classify idiomatic phrases) (Salehi et al., 2014a). By their very\nnature, these approaches have limited coverage of semantics and are highly language dependent.\nIn terms of distributed representation, methods include Latent Semantic Analysis (Katz and Giesbrecht, 2006) and word embeddings which have been extaordinarily successful representations of word semantics, eg., word2vec and GloVe (Mikolov et al., 2014; Pennington et al., 2014; Neelakantan et al., 2014). (Salehi et al., 2015) is a recent work exploring compositionality in conjunction with word embeddings; however, an aspect not considered is that compositionality does not only depend on the phrase but also on its context \u2013 this results in an inability to identify the context-based compositionality of polysemous phrases like bad egg. Sarcasm Detection Sarcasm is a figurative expression conveying a meaning that is opposite of its literal one, usually in an implicit way, and is a crucial component in sentiment analysis. Such connections are explored in (Maynard and Greenwood, 2014) via a rule-based method of identifying known sarcastic phrases. Semi-supervised sarcasm identification algorithms are identified in (Davidov et al., 2010; Riloff et al., 2013; Liebrecht et al., 2013; Maynard and Greenwood, 2014), each using different sets of features (eg., word senses, uni, bi and trigrams) that are then fed into a classification system tuned on a large training dataset. Metaphor Detection Metaphors offer figurative interpretations and are a key feature of natural language (Lakoff and Johnson, 1980). (Mason, 2004) considers metaphor expression as a mapping from a source domain to a target domain, and develops a corpus-based system, CorMet, to discover such metaphorical equivalances based on WordNet. (Turney et al., 2011) hypothesises that metaphorical usage is related to the degreee of contextual abstractness, which they quantify relying on the MRC Psycholinguistic Database Machine Usable Dictionary (MRCPD) (Coltheart, 1981).\n(Broadwell et al., 2013) proposes a detection method according to lexical imaginability, topic chaining and semantic clustering. Their method is also based on the linguistic resource of MRCPD. (Tsvetkov et al., 2014) focuses on Subject-VerbObject and Adjective-Noun structures, and use word abstractness and imagineability as well as supersenses as features for metaphor detection. Besides\nMRCPD, they also have recourse to WordNet for word supersenses."}, {"heading": "7 Conclusion", "text": "We bring MWEs, sarcasms and metaphors under a common umbrella of compositionality, followed by a simple unified framework to study it; this is our central contribution. The method proposed to detect word/phrase compositionality based on local context is simple and affords a clear geometric view. We do not depend on external resources and perform very well across multiple languages and in a large variety of settings (metaphors, sarcastic and idiomatic usages). The method naturally scales to handle complications such as unseen phrases and polysemy, achieving comparable or superior results to the state-of-art (which are supervised methods based on elaborate feature engineering and using, at times, plentiful external linguistic resources) on standard datasets.\nA careful understanding of the geometry of our context representations (subspace of the principle components of the word vectors) and compositionality scoring method, along with a study of the connections to neural network methods of sentence representation (eg., LSTM (Greff et al., 2015)) are interesting future avenues of research."}], "references": [{"title": "Fine-grained analysis of sentence embeddings using auxiliary prediction tasks", "author": ["Yossi Adi", "Einat Kermany", "Yonatan Belinkov", "Ofer Lavi", "Yoav Goldberg."], "venue": "CoRR, abs/1608.04207.", "citeRegEx": "Adi et al\\.,? 2016", "shortCiteRegEx": "Adi et al\\.", "year": 2016}, {"title": "Polyglot: Distributed word representations for multilingual nlp", "author": ["Rami Al-Rfou", "Bryan Perozzi", "Steven Skiena."], "venue": "Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 183\u2013192, Sofia, Bulgaria, August. Association", "citeRegEx": "Al.Rfou et al\\.,? 2013", "shortCiteRegEx": "Al.Rfou et al\\.", "year": 2013}, {"title": "Acquiring Phrasal Lexicons from Corpora", "author": ["Colin James Bannard."], "venue": "Ph.D. thesis, University of Edinburgh.", "citeRegEx": "Bannard.,? 2006", "shortCiteRegEx": "Bannard.", "year": 2006}, {"title": "Identifying bilingual multiword expressions for statistical machine translation", "author": ["Dhouha Bouamor", "Nasredine Semmar", "Pierre Zweigenbaum."], "venue": "LREC, pages 674\u2013679.", "citeRegEx": "Bouamor et al\\.,? 2012", "shortCiteRegEx": "Bouamor et al\\.", "year": 2012}, {"title": "Using imageability and topic chaining to locate metaphors in linguistic corpora", "author": ["George Aaron Broadwell", "Umit Boz", "Ignacio Cases", "Tomek Strzalkowski", "Laurie Feldman", "Sarah Taylor", "Samira Shaikh", "Ting Liu", "Kit Cho", "Nick Webb."], "venue": "International", "citeRegEx": "Broadwell et al\\.,? 2013", "shortCiteRegEx": "Broadwell et al\\.", "year": 2013}, {"title": "Available at: http://www", "author": ["ChineseDictionary."], "venue": "chinese-dictionary.org. Accessed:2016-05-", "citeRegEx": "ChineseDictionary.,? 2016", "shortCiteRegEx": "ChineseDictionary.", "year": 2016}, {"title": "The mrc psycholinguistic database", "author": ["Max Coltheart."], "venue": "The Quarterly Journal of Experimental Psychology, 33(4):497\u2013505.", "citeRegEx": "Coltheart.,? 1981", "shortCiteRegEx": "Coltheart.", "year": 1981}, {"title": "Pulling their weight: Exploiting syntactic forms for the automatic identification of idiomatic expressions in context", "author": ["Paul Cook", "Afsaneh Fazly", "Suzanne Stevenson."], "venue": "Proceedings of the workshop on a broader perspective on multiword expressions, pages", "citeRegEx": "Cook et al\\.,? 2007", "shortCiteRegEx": "Cook et al\\.", "year": 2007}, {"title": "Semi-supervised recognition of sarcastic sentences in twitter and amazon", "author": ["Dmitry Davidov", "Oren Tsur", "Ari Rappoport."], "venue": "Proceedings of the fourteenth conference on computational natural language learning, pages 107\u2013116. Association for Computational", "citeRegEx": "Davidov et al\\.,? 2010", "shortCiteRegEx": "Davidov et al\\.", "year": 2010}, {"title": "Probing for semantic evidence of composition by means of simple classification tasks", "author": ["Allyson Ettinger", "Ahmed Elgohary", "Philip Resnik."], "venue": "the Association for Computational Linguistics, page 134.", "citeRegEx": "Ettinger et al\\.,? 2016", "shortCiteRegEx": "Ettinger et al\\.", "year": 2016}, {"title": "Retrofitting word vectors to semantic lexicons", "author": ["Manaal Faruqui", "Jesse Dodge", "Sujay Kumar Jauhar", "Chris Dyer", "Eduard Hovy", "Noah A Smith."], "venue": "Association for Computational Linguistics.", "citeRegEx": "Faruqui et al\\.,? 2015", "shortCiteRegEx": "Faruqui et al\\.", "year": 2015}, {"title": "Distinguishing subtypes of multiword expressions using", "author": ["Afsaneh Fazly", "Suzanne Stevenson"], "venue": null, "citeRegEx": "Fazly and Stevenson.,? \\Q2007\\E", "shortCiteRegEx": "Fazly and Stevenson.", "year": 2007}, {"title": "Phrase similarity in humans and machines", "author": ["Samuel J Gershman", "Joshua B Tenenbaum."], "venue": "Proceedings of the 37th Annual Conference of the Cognitive Science Society. Citeseer.", "citeRegEx": "Gershman and Tenenbaum.,? 2015", "shortCiteRegEx": "Gershman and Tenenbaum.", "year": 2015}, {"title": "Sarcastic or not: Word embeddings to predict the literal or sarcastic meaning of words", "author": ["Debanjan Ghosh", "Weiwei Guo", "Smaranda Muresan."], "venue": "pages 1003\u2013 1012.", "citeRegEx": "Ghosh et al\\.,? 2015", "shortCiteRegEx": "Ghosh et al\\.", "year": 2015}, {"title": "Available at: https://books", "author": ["GoogleBooks."], "venue": "google.com. Accessed: 2016-05-03.", "citeRegEx": "GoogleBooks.,? 2016", "shortCiteRegEx": "GoogleBooks.", "year": 2016}, {"title": "Lstm: A search space odyssey", "author": ["Klaus Greff", "Rupesh Kumar Srivastava", "Jan Koutn\u0131\u0301k", "Bas R Steunebrink", "J\u00fcrgen Schmidhuber"], "venue": "arXiv preprint arXiv:1503.04069", "citeRegEx": "Greff et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Greff et al\\.", "year": 2015}, {"title": "Automatic identification of non-compositional multi-word expressions using latent semantic analysis", "author": ["Graham Katz", "Eugenie Giesbrecht."], "venue": "Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, pages", "citeRegEx": "Katz and Giesbrecht.,? 2006", "shortCiteRegEx": "Katz and Giesbrecht.", "year": 2006}, {"title": "Short text similarity with word embeddings", "author": ["Tom Kenter", "Maarten de Rijke."], "venue": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, pages 1411\u20131420. ACM.", "citeRegEx": "Kenter and Rijke.,? 2015", "shortCiteRegEx": "Kenter and Rijke.", "year": 2015}, {"title": "Siamese cbow: Optimizing word embeddings for sentence representations", "author": ["Tom Kenter", "Alexey Borisov", "Maarten de Rijke."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, page 941951.", "citeRegEx": "Kenter et al\\.,? 2016", "shortCiteRegEx": "Kenter et al\\.", "year": 2016}, {"title": "Conceptual metaphor in everyday language", "author": ["George Lakoff", "Mark Johnson."], "venue": "The journal of Philosophy, 77(8):453\u2013486.", "citeRegEx": "Lakoff and Johnson.,? 1980", "shortCiteRegEx": "Lakoff and Johnson.", "year": 1980}, {"title": "The perfect solution for detecting sarcasm in tweets", "author": ["CC Liebrecht", "FA Kunneman", "APJ van den Bosch"], "venue": null, "citeRegEx": "Liebrecht et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liebrecht et al\\.", "year": 2013}, {"title": "Automatic identification of noncompositional phrases", "author": ["Dekang Lin."], "venue": "Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, pages 317\u2013 324. Association for Computational Linguistics.", "citeRegEx": "Lin.,? 1999", "shortCiteRegEx": "Lin.", "year": 1999}, {"title": "Collocations", "author": ["Chris Manning", "Hinrich Sch\u00fctze."], "venue": "Foundations of statistical natural language processing, pages 141\u201377.", "citeRegEx": "Manning and Sch\u00fctze.,? 1999", "shortCiteRegEx": "Manning and Sch\u00fctze.", "year": 1999}, {"title": "Cormet: a computational, corpus-based conventional metaphor extraction system", "author": ["Zachary J Mason."], "venue": "Computational linguistics, 30(1):23\u201344.", "citeRegEx": "Mason.,? 2004", "shortCiteRegEx": "Mason.", "year": 2004}, {"title": "Who cares about sarcastic tweets? investigating the impact", "author": ["Diana Maynard", "Mark A Greenwood"], "venue": null, "citeRegEx": "Maynard and Greenwood.,? \\Q2014\\E", "shortCiteRegEx": "Maynard and Greenwood.", "year": 2014}, {"title": "Detecting a continuum of compositionality in phrasal verbs", "author": ["Diana McCarthy", "Bill Keller", "John Carroll."], "venue": "Proceedings of the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatment-Volume 18, pages 73\u201380. Association for", "citeRegEx": "McCarthy et al\\.,? 2003", "shortCiteRegEx": "McCarthy et al\\.", "year": 2003}, {"title": "Composition in distributional models of semantics", "author": ["Jeff Mitchell", "Mirella Lapata."], "venue": "Cognitive science, 34(8):1388\u20131429.", "citeRegEx": "Mitchell and Lapata.,? 2010", "shortCiteRegEx": "Mitchell and Lapata.", "year": 2010}, {"title": "Geometry of polysemy", "author": ["Jiaqi Mu", "Suma Bhat", "Pramod Viswanath."], "venue": "CoRR, abs/1610.07569.", "citeRegEx": "Mu et al\\.,? 2016", "shortCiteRegEx": "Mu et al\\.", "year": 2016}, {"title": "Efficient nonparametric estimation of multiple embeddings per word in vector space", "author": ["Arvind Neelakantan", "Jeevan Shankar", "Alexandre Passos", "Andrew McCallum."], "venue": "Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "Neelakantan et al\\.,? 2014", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2014}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "EMNLP, volume 14, pages 1532\u20131543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "An empirical study on compositionality in compound nouns", "author": ["Siva Reddy", "Diana McCarthy", "Suresh Manandhar."], "venue": "IJCNLP, pages 210\u2013218.", "citeRegEx": "Reddy et al\\.,? 2011", "shortCiteRegEx": "Reddy et al\\.", "year": 2011}, {"title": "Sarcasm as contrast between a positive sentiment and negative situation", "author": ["Ellen Riloff", "Ashequl Qadir", "Prafulla Surve", "Lalindra De Silva", "Nathan Gilbert", "Ruihong Huang."], "venue": "EMNLP, volume 13, pages 704\u2013 714.", "citeRegEx": "Riloff et al\\.,? 2013", "shortCiteRegEx": "Riloff et al\\.", "year": 2013}, {"title": "Contextual correlates of synonymy", "author": ["Herbert Rubenstein", "John B Goodenough."], "venue": "Communications of the ACM, 8(10):627\u2013633.", "citeRegEx": "Rubenstein and Goodenough.,? 1965", "shortCiteRegEx": "Rubenstein and Goodenough.", "year": 1965}, {"title": "Multiword expressions: A pain in the neck for nlp", "author": ["Ivan A Sag", "Timothy Baldwin", "Francis Bond", "Ann Copestake", "Dan Flickinger."], "venue": "Computational Linguistics and Intelligent Text Processing, pages 1\u2013", "citeRegEx": "Sag et al\\.,? 2002", "shortCiteRegEx": "Sag et al\\.", "year": 2002}, {"title": "Predicting the compositionality of multiword expressions using translations in multiple languages", "author": ["Bahar Salehi", "Paul Cook."], "venue": "Second Joint Conference on Lexical and Computational Semantics, volume 1, pages 266\u2013275.", "citeRegEx": "Salehi and Cook.,? 2013", "shortCiteRegEx": "Salehi and Cook.", "year": 2013}, {"title": "Detecting non-compositional mwe components using wiktionary", "author": ["Bahar Salehi", "Paul Cook", "Timothy Baldwin."], "venue": "Conference on Empirical Methods in Natural Language Processing, pages 1792\u20131797.", "citeRegEx": "Salehi et al\\.,? 2014a", "shortCiteRegEx": "Salehi et al\\.", "year": 2014}, {"title": "Using distributional similarity of multi-way translations to predict multiword expression compositionality", "author": ["Bahar Salehi", "Paul Cook", "Timothy Baldwin."], "venue": "European Chapter of the Association for Computational Linguistics, pages 472\u2013481.", "citeRegEx": "Salehi et al\\.,? 2014b", "shortCiteRegEx": "Salehi et al\\.", "year": 2014}, {"title": "A word embedding approach to predicting the compositionality of multiword expressions", "author": ["Bahar Salehi", "Paul Cook", "Timothy Baldwin."], "venue": "the North American Chapter of the Association for Computational Linguistics, pages 977\u2013983.", "citeRegEx": "Salehi et al\\.,? 2015", "shortCiteRegEx": "Salehi et al\\.", "year": 2015}, {"title": "Exploring vector space models to predict the compositionality of german noun-noun compounds", "author": ["Sabine Schulte im Walde", "Stefan M\u00fcller", "Stephen Roller."], "venue": "Proceedings of the 2nd Joint Conference on Lexical and Computational Semantics, pages 255\u2013", "citeRegEx": "Walde et al\\.,? 2013", "shortCiteRegEx": "Walde et al\\.", "year": 2013}, {"title": "A tutorial on principal component analysis", "author": ["Jonathon Shlens."], "venue": "CoRR, abs/1404.1100.", "citeRegEx": "Shlens.,? 2014", "shortCiteRegEx": "Shlens.", "year": 2014}, {"title": "Metaphor detection with cross-lingual model transfer", "author": ["Yulia Tsvetkov", "Leonid Boytsov", "Anatole Gershman", "Eric Nyberg", "Chris Dyer"], "venue": null, "citeRegEx": "Tsvetkov et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2014}, {"title": "Literal and metaphorical sense identification through concrete and abstract context", "author": ["Peter D Turney", "Yair Neuman", "Dan Assaf", "Yohai Cohen."], "venue": "Proceedings of the 2011 Conference on the Empirical Methods in Natural Language Processing, pages 680\u2013", "citeRegEx": "Turney et al\\.,? 2011", "shortCiteRegEx": "Turney et al\\.", "year": 2011}, {"title": "Humans require context to infer ironic intent (so computers probably do, too)", "author": ["Byron C Wallace", "Laura Kertz Do Kook Choe", "Laura Kertz", "Eugene Charniak."], "venue": "the Association for Computational Linguistics, pages 512\u2013516.", "citeRegEx": "Wallace et al\\.,? 2014", "shortCiteRegEx": "Wallace et al\\.", "year": 2014}, {"title": "Towards universal paraphrastic sentence embeddings", "author": ["John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu."], "venue": "arXiv preprint arXiv:1511.08198.", "citeRegEx": "Wieting et al\\.,? 2015", "shortCiteRegEx": "Wieting et al\\.", "year": 2015}, {"title": "Deep learning for answer sentence selection", "author": ["Lei Yu", "Karl Moritz Hermann", "Phil Blunsom", "Stephen Pulman."], "venue": "arXiv preprint arXiv:1412.1632.", "citeRegEx": "Yu et al\\.,? 2014", "shortCiteRegEx": "Yu et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 33, "context": "One expression type is multiword expressions (MWEs) \u2013 phrases with semantic idiosyncrasies that cross word boundaries (Sag et al., 2002).", "startOffset": 118, "endOffset": 136}, {"referenceID": 3, "context": ", chemin de fer from French to English to be way of iron in place of railway (Bouamor et al., 2012).", "startOffset": 77, "endOffset": 99}, {"referenceID": 37, "context": "Both these are significant improvements over recent works with similar goals: compositionality of MWEs (Salehi et al., 2015), works on sarcasm (Wallace et al.", "startOffset": 103, "endOffset": 124}, {"referenceID": 42, "context": ", 2015), works on sarcasm (Wallace et al., 2014) and metaphor detection (Tsvetkov et al.", "startOffset": 26, "endOffset": 48}, {"referenceID": 40, "context": ", 2014) and metaphor detection (Tsvetkov et al., 2014) (the latter works rely significantly on external linguistic resources and access to labeled training data).", "startOffset": 31, "endOffset": 54}, {"referenceID": 39, "context": "Our main contribution is the discovery of a geometric property of vector embeddings of context words (excluding the function words) within a sentence: they roughly occupy a low dimensional linear subspace which can be empirically extracted via a standard dimensionality reduction technique: principal component analysis (PCA) (Shlens, 2014).", "startOffset": 326, "endOffset": 340}, {"referenceID": 26, "context": "+ vn, adding all component word vectors together, as in (Mitchell and Lapata, 2010) and several works on phrase2vec (Gershman and Tenenbaum, 2015) and sentence2vec (Faruqui et al.", "startOffset": 56, "endOffset": 83}, {"referenceID": 12, "context": "+ vn, adding all component word vectors together, as in (Mitchell and Lapata, 2010) and several works on phrase2vec (Gershman and Tenenbaum, 2015) and sentence2vec (Faruqui et al.", "startOffset": 116, "endOffset": 146}, {"referenceID": 10, "context": "+ vn, adding all component word vectors together, as in (Mitchell and Lapata, 2010) and several works on phrase2vec (Gershman and Tenenbaum, 2015) and sentence2vec (Faruqui et al., 2015; Wieting et al., 2015; Adi et al., 2016).", "startOffset": 164, "endOffset": 226}, {"referenceID": 43, "context": "+ vn, adding all component word vectors together, as in (Mitchell and Lapata, 2010) and several works on phrase2vec (Gershman and Tenenbaum, 2015) and sentence2vec (Faruqui et al., 2015; Wieting et al., 2015; Adi et al., 2016).", "startOffset": 164, "endOffset": 226}, {"referenceID": 0, "context": "+ vn, adding all component word vectors together, as in (Mitchell and Lapata, 2010) and several works on phrase2vec (Gershman and Tenenbaum, 2015) and sentence2vec (Faruqui et al., 2015; Wieting et al., 2015; Adi et al., 2016).", "startOffset": 164, "endOffset": 226}, {"referenceID": 32, "context": "Based on the commonly-used distributional hypothesis that the word or phrase meaning can be inferred from its context (Rubenstein and Goodenough, 1965), we note that the local context (neighboring words) is crucial in deciphering the compositional sense of the word or phrase.", "startOffset": 118, "endOffset": 151}, {"referenceID": 30, "context": "This is in contrast to prior works that use the global context alone (the whole document or corpus), without accounting for the context-dependence of polysemy (Reddy et al., 2011).", "startOffset": 159, "endOffset": 179}, {"referenceID": 27, "context": "At times, the word(s) being tested exhibit polysemous behavior (example: check in blank check) (Mu et al., 2016).", "startOffset": 95, "endOffset": 112}, {"referenceID": 28, "context": "In such cases, it makes sense to consider multiple embeddings for different word senses (we use MSSG representations (Neelakantan et al., 2014)): each word has a single global embedding and two sense embeddings.", "startOffset": 117, "endOffset": 143}, {"referenceID": 1, "context": "The training corpus of embeddings in English, Chinese and German are obtained from polyglot (Al-Rfou et al., 2013).", "startOffset": 92, "endOffset": 114}, {"referenceID": 28, "context": ", 2014), and sense-specific ones using NP-MSSG of MSSG (Neelakantan et al., 2014).", "startOffset": 55, "endOffset": 81}, {"referenceID": 5, "context": "The English dataset contains 104 polysemous phrases which are obtained from the idiom dictionary (TheFreeDictionary, 2016), and the Chinese dataset consists of 64 phrases obtained from (ChineseDictionary, 2016).", "startOffset": 185, "endOffset": 210}, {"referenceID": 14, "context": "Their respective contexts are extracted from the corpus provided by polyglot or electronic resources (GoogleBooks, 2016).", "startOffset": 101, "endOffset": 120}, {"referenceID": 30, "context": "Dataset: The English noun compounds dataset (ENC), has 90 English noun compounds annotated on a continuous [0, 5] scale for the phrase and component-wise compositionality (Reddy et al., 2011); the English verb particle constructions (EVPC) contains 160 English verb-particle compounds, whose componentwise compositionality are annotated on a binary scale (Bannard, 2006).", "startOffset": 171, "endOffset": 191}, {"referenceID": 2, "context": ", 2011); the English verb particle constructions (EVPC) contains 160 English verb-particle compounds, whose componentwise compositionality are annotated on a binary scale (Bannard, 2006).", "startOffset": 171, "endOffset": 186}, {"referenceID": 35, "context": "5 to ENC as in (Salehi et al., 2014a), a threshold of 4 to GNC and use the binary labels of EVPC.", "startOffset": 15, "endOffset": 37}, {"referenceID": 22, "context": "PMI = log P (w1w2) P (w1)P (w2) , where P (\u00b7) is the probability of the unigram or bigram (Manning and Sch\u00fctze, 1999).", "startOffset": 90, "endOffset": 117}, {"referenceID": 9, "context": "While we use PCA, several recent works have shown average word vectors to be robust sentence embeddings (Ettinger et al., 2016; Adi et al., 2016; Wieting et al., 2015) and we measure compositionality by the cosine similarity between the target word vector and the sentence vector.", "startOffset": 104, "endOffset": 167}, {"referenceID": 0, "context": "While we use PCA, several recent works have shown average word vectors to be robust sentence embeddings (Ettinger et al., 2016; Adi et al., 2016; Wieting et al., 2015) and we measure compositionality by the cosine similarity between the target word vector and the sentence vector.", "startOffset": 104, "endOffset": 167}, {"referenceID": 43, "context": "While we use PCA, several recent works have shown average word vectors to be robust sentence embeddings (Ettinger et al., 2016; Adi et al., 2016; Wieting et al., 2015) and we measure compositionality by the cosine similarity between the target word vector and the sentence vector.", "startOffset": 104, "endOffset": 167}, {"referenceID": 35, "context": "We compare with the state-of-the-art of (Salehi et al., 2014a), specifically their methods based on word definitions, synonyms and idiom tags (denoted by ALLDEFS+SYN, ITAG+SYN, ALLDEFS) provided by wikitionary.", "startOffset": 40, "endOffset": 62}, {"referenceID": 35, "context": "The key advantage of our method is its non-reliance on external resources like wikitionary or multilingual translations \u2013 these are heavily relied upon in the state-of-the-art methods (Salehi et al., 2014a; Salehi et al., 2014b).", "startOffset": 184, "endOffset": 228}, {"referenceID": 36, "context": "The key advantage of our method is its non-reliance on external resources like wikitionary or multilingual translations \u2013 these are heavily relied upon in the state-of-the-art methods (Salehi et al., 2014a; Salehi et al., 2014b).", "startOffset": 184, "endOffset": 228}, {"referenceID": 37, "context": "Also, unlike the assumption in (Salehi et al., 2015), we do not require that the test phrases appear in the training corpus.", "startOffset": 31, "endOffset": 52}, {"referenceID": 8, "context": "Sarcasms, also called irony, are expressions whose actual meaning is quite different - and often opposite to - their literal meaning \u2013 and are instances of noncompositional usage (Davidov et al., 2010; Riloff et al., 2013).", "startOffset": 179, "endOffset": 222}, {"referenceID": 31, "context": "Sarcasms, also called irony, are expressions whose actual meaning is quite different - and often opposite to - their literal meaning \u2013 and are instances of noncompositional usage (Davidov et al., 2010; Riloff et al., 2013).", "startOffset": 179, "endOffset": 222}, {"referenceID": 13, "context": "These ideas are used in prior works to create elaborate features (designed based on a large labeled training set) and build a sarcasm detection system (Ghosh et al., 2015).", "startOffset": 151, "endOffset": 171}, {"referenceID": 13, "context": "We use a subset of the tweets in the dataset of (Ghosh et al., 2015) and study words that are used both literally and sarcastically (eg.", "startOffset": 48, "endOffset": 68}, {"referenceID": 42, "context": "A quantitative test is provided via our study on a Reddit irony dataset (Wallace et al., 2014).", "startOffset": 72, "endOffset": 94}, {"referenceID": 42, "context": "(Wallace et al., 2014) considers the 50,000 most frequently occurring unigrams and bigrams, and use binary bag-of-words and punctuations as features followed by a linear kernel SVM, grid-search for parameter tuning and five-fold cross validation.", "startOffset": 0, "endOffset": 22}, {"referenceID": 42, "context": "Instead, we generate compositionality-score features based on POS tags to allow a direct comparison with the state-of-the-art in (Wallace et al., 2014).", "startOffset": 129, "endOffset": 151}, {"referenceID": 42, "context": "These features are then fed into the same supervised learning system as in (Wallace et al., 2014), providing a fair comparison between the two featureselection methods.", "startOffset": 75, "endOffset": 97}, {"referenceID": 40, "context": "Dataset: English datasets comprising of metaphoric and literal uses of two syntactic structures (subject-verb-object (SVO) and adjective-noun (AN) compounds) are provided in (Tsvetkov et al., 2014).", "startOffset": 174, "endOffset": 197}, {"referenceID": 40, "context": "Algorithm Description: The state-of-the-art work (Tsvetkov et al., 2014) uses training-datadriven feature engineering methods while relying on external resources like WordNet and the MRC psycholinguistic database.", "startOffset": 49, "endOffset": 72}, {"referenceID": 40, "context": "These features are then fed into a supervised learning system (random forest), analogous to the one in (Tsvetkov et al., 2014) allowing for a fair comparison of the power of the features extracted.", "startOffset": 103, "endOffset": 126}, {"referenceID": 40, "context": "Detection Results: The experimental results on SVO and AN datasets are detailed in Table 6 where the baseline is provided by the results of (Tsvetkov et al., 2014) (which has access to the MRC psycholinguistic database and the supersense corpus).", "startOffset": 140, "endOffset": 163}, {"referenceID": 10, "context": "For instance, such a representation is successfully used for sentential sentiment prediction (Faruqui et al., 2015) and in (Kenter and de Rijke, 2015) to study text similarity.", "startOffset": 93, "endOffset": 115}, {"referenceID": 18, "context": "Average word embeddings are also used (Kenter et al., 2016) in conjunction with a neural network architecture to predict the surrounding sentences from the input sentence embeddings.", "startOffset": 38, "endOffset": 59}, {"referenceID": 44, "context": "Computational models of sentential semantics have also shown to be robustly handled by average word embeddings (Yu et al., 2014; Gershman and Tenenbaum, 2015; Adi et al., 2016; Wieting et al., 2015).", "startOffset": 111, "endOffset": 198}, {"referenceID": 12, "context": "Computational models of sentential semantics have also shown to be robustly handled by average word embeddings (Yu et al., 2014; Gershman and Tenenbaum, 2015; Adi et al., 2016; Wieting et al., 2015).", "startOffset": 111, "endOffset": 198}, {"referenceID": 0, "context": "Computational models of sentential semantics have also shown to be robustly handled by average word embeddings (Yu et al., 2014; Gershman and Tenenbaum, 2015; Adi et al., 2016; Wieting et al., 2015).", "startOffset": 111, "endOffset": 198}, {"referenceID": 43, "context": "Computational models of sentential semantics have also shown to be robustly handled by average word embeddings (Yu et al., 2014; Gershman and Tenenbaum, 2015; Adi et al., 2016; Wieting et al., 2015).", "startOffset": 111, "endOffset": 198}, {"referenceID": 21, "context": "Early approaches relied on the use of specific lexical and syntactic properties of MWEs (Lin, 1999; McCarthy et al., 2003; Cook et al., 2007; Fazly and Stevenson, 2007).", "startOffset": 88, "endOffset": 168}, {"referenceID": 25, "context": "Early approaches relied on the use of specific lexical and syntactic properties of MWEs (Lin, 1999; McCarthy et al., 2003; Cook et al., 2007; Fazly and Stevenson, 2007).", "startOffset": 88, "endOffset": 168}, {"referenceID": 7, "context": "Early approaches relied on the use of specific lexical and syntactic properties of MWEs (Lin, 1999; McCarthy et al., 2003; Cook et al., 2007; Fazly and Stevenson, 2007).", "startOffset": 88, "endOffset": 168}, {"referenceID": 11, "context": "Early approaches relied on the use of specific lexical and syntactic properties of MWEs (Lin, 1999; McCarthy et al., 2003; Cook et al., 2007; Fazly and Stevenson, 2007).", "startOffset": 88, "endOffset": 168}, {"referenceID": 34, "context": "More recent approaches include multilingual translations (Salehi and Cook, 2013; Salehi et al., 2014b) and using Wikitionary (one approach uses its word definitions, idiom tagging together with word synonyms to classify idiomatic phrases) (Salehi et al.", "startOffset": 57, "endOffset": 102}, {"referenceID": 36, "context": "More recent approaches include multilingual translations (Salehi and Cook, 2013; Salehi et al., 2014b) and using Wikitionary (one approach uses its word definitions, idiom tagging together with word synonyms to classify idiomatic phrases) (Salehi et al.", "startOffset": 57, "endOffset": 102}, {"referenceID": 35, "context": ", 2014b) and using Wikitionary (one approach uses its word definitions, idiom tagging together with word synonyms to classify idiomatic phrases) (Salehi et al., 2014a).", "startOffset": 145, "endOffset": 167}, {"referenceID": 16, "context": "In terms of distributed representation, methods include Latent Semantic Analysis (Katz and Giesbrecht, 2006) and word embeddings which have been extaordinarily successful representations of word semantics, eg.", "startOffset": 81, "endOffset": 108}, {"referenceID": 29, "context": ", word2vec and GloVe (Mikolov et al., 2014; Pennington et al., 2014; Neelakantan et al., 2014).", "startOffset": 21, "endOffset": 94}, {"referenceID": 28, "context": ", word2vec and GloVe (Mikolov et al., 2014; Pennington et al., 2014; Neelakantan et al., 2014).", "startOffset": 21, "endOffset": 94}, {"referenceID": 37, "context": "(Salehi et al., 2015) is a recent work exploring compositionality in conjunction with word embeddings; however, an aspect not considered is that compositionality does not only depend on the phrase but also on its context \u2013 this results in an inability to identify the context-based compositionality of polysemous phrases like bad egg.", "startOffset": 0, "endOffset": 21}, {"referenceID": 24, "context": "Such connections are explored in (Maynard and Greenwood, 2014) via a rule-based method of identifying known sarcastic phrases.", "startOffset": 33, "endOffset": 62}, {"referenceID": 8, "context": "Semi-supervised sarcasm identification algorithms are identified in (Davidov et al., 2010; Riloff et al., 2013; Liebrecht et al., 2013; Maynard and Greenwood, 2014), each using different sets of features (eg.", "startOffset": 68, "endOffset": 164}, {"referenceID": 31, "context": "Semi-supervised sarcasm identification algorithms are identified in (Davidov et al., 2010; Riloff et al., 2013; Liebrecht et al., 2013; Maynard and Greenwood, 2014), each using different sets of features (eg.", "startOffset": 68, "endOffset": 164}, {"referenceID": 20, "context": "Semi-supervised sarcasm identification algorithms are identified in (Davidov et al., 2010; Riloff et al., 2013; Liebrecht et al., 2013; Maynard and Greenwood, 2014), each using different sets of features (eg.", "startOffset": 68, "endOffset": 164}, {"referenceID": 24, "context": "Semi-supervised sarcasm identification algorithms are identified in (Davidov et al., 2010; Riloff et al., 2013; Liebrecht et al., 2013; Maynard and Greenwood, 2014), each using different sets of features (eg.", "startOffset": 68, "endOffset": 164}, {"referenceID": 19, "context": "Metaphor Detection Metaphors offer figurative interpretations and are a key feature of natural language (Lakoff and Johnson, 1980).", "startOffset": 104, "endOffset": 130}, {"referenceID": 23, "context": "(Mason, 2004) considers metaphor expression as a mapping from a source domain to a target domain, and develops a corpus-based system, CorMet, to discover such metaphorical equivalances based on WordNet.", "startOffset": 0, "endOffset": 13}, {"referenceID": 41, "context": "(Turney et al., 2011) hypothesises that metaphorical usage is related to the degreee of contextual abstractness, which they quantify relying on the MRC Psycholinguistic Database Machine Usable Dictionary (MRCPD) (Coltheart, 1981).", "startOffset": 0, "endOffset": 21}, {"referenceID": 6, "context": ", 2011) hypothesises that metaphorical usage is related to the degreee of contextual abstractness, which they quantify relying on the MRC Psycholinguistic Database Machine Usable Dictionary (MRCPD) (Coltheart, 1981).", "startOffset": 198, "endOffset": 215}, {"referenceID": 4, "context": "(Broadwell et al., 2013) proposes a detection method according to lexical imaginability, topic chaining and semantic clustering.", "startOffset": 0, "endOffset": 24}, {"referenceID": 40, "context": "(Tsvetkov et al., 2014) focuses on Subject-VerbObject and Adjective-Noun structures, and use word abstractness and imagineability as well as supersenses as features for metaphor detection.", "startOffset": 0, "endOffset": 23}, {"referenceID": 15, "context": ", LSTM (Greff et al., 2015)) are interesting future avenues of research.", "startOffset": 7, "endOffset": 27}], "year": 2016, "abstractText": "This paper proposes a simple test for compositionality (i.e., literal usage) of a word or phrase in a context-specific way. The test is computationally simple, relying on no external resources and only uses a set of trained word vectors. Experiments show that the proposed method is competitive with state of the art and displays high accuracy in context-specific compositionality detection of a variety of natural language phenomena (idiomaticity, sarcasm, metaphor) for different datasets in multiple languages. The key insight is to connect compositionality to a curious geometric property of word embeddings, which is of independent interest.", "creator": "LaTeX with hyperref package"}}}