{"id": "1612.00686", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Dec-2016", "title": "Identifying and Categorizing Anomalies in Retinal Imaging Data", "abstract": "The identification and quantification of markers in medical images is critical for diagnosis, prognosis and management of patients in clinical practice. Supervised- or weakly supervised training enables the detection of findings that are known a priori. It does not scale well, and a priori definition limits the vocabulary of markers to known entities reducing the accuracy of diagnosis and prognosis. Here, we propose the identification of anomalies in large-scale medical imaging data using healthy examples as a reference. We detect and categorize candidates for anomaly findings untypical for the observed data. A deep convolutional autoencoder is trained on healthy retinal images. The learned model generates a new feature representation, and the distribution of healthy retinal patches is estimated by a one-class support vector machine. Results demonstrate that we can identify pathologic regions in images without using expert annotations. A subsequent clustering categorizes findings into clinically meaningful classes. In addition the learned features outperform standard embedding approaches in a classification task.", "histories": [["v1", "Fri, 2 Dec 2016 14:05:49 GMT  (669kb,D)", "http://arxiv.org/abs/1612.00686v1", "Extended Abstract, Accepted for NIPS 2016 Workshop \"Machine Learning for Health\""]], "COMMENTS": "Extended Abstract, Accepted for NIPS 2016 Workshop \"Machine Learning for Health\"", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["philipp seeb\\\"ock", "sebastian waldstein", "sophie klimscha", "bianca s gerendas", "ren\\'e donner", "thomas schlegl", "ursula schmidt-erfurth", "georg langs"], "accepted": false, "id": "1612.00686"}, "pdf": {"name": "1612.00686.pdf", "metadata": {"source": "CRF", "title": "Identifying and Categorizing Anomalies in Retinal Imaging Data", "authors": ["Philipp Seeb\u00f6ck", "Sebastian Waldstein", "Sophie Klimscha", "Bianca S. Gerendas", "Ren\u00e9 Donner", "Thomas Schlegl", "Ursula Schmidt-Erfurth", "Georg Langs"], "emails": ["philipp.seeboeck@meduniwien.ac.at"], "sections": [{"heading": null, "text": "Identifying and Categorizing Anomalies in Retinal Imaging Data\nPhilipp Seeb\u00f6ck, Sebastian Waldstein, Sophie Klimscha, Bianca S. Gerendas, Ren\u00e9 Donner, Thomas Schlegl, Ursula Schmidt-Erfurth and Georg Langs\nChristian Doppler Laboratory for Ophthalmic Image Analysis, Department for Ophthalmology CIR - Department of Biomedical Imaging and Image-guided Therapy, Medical University of Vienna\nphilipp.seeboeck@meduniwien.ac.at"}, {"heading": "1 Introduction", "text": "The detection of diagnostically relevant markers in imaging data is critical in medicine and treatment guidance. Typically, detectors are trained based on a priori defined categories, and annotated imaging data. This makes large-scale annotation necessary which is often not feasible, limits the use to known marker categories, and overall slows the process of discovering novel markers based on available evidence. Additionally, in contrast to natural images such as photographs, the relevant categories of retinal images cover only a small fraction of the overall imaging data, though they are the focus of diagnostic attention, and are often dominated by natural variability of even healthy anatomy.\nOptical Coherence Tomography (OCT) [11] is an important diagnostic modality in ophthalmology and offers a high-resolution 3D image of the layers and entities in the retina. Each position of the retina sampled by an optical beam results in a vector, the A-scan. Adjacent A-scans form a B-scan, which in turn form the entire volume. Anomaly detection [12] in retinal images is a difficult and unsolved task, though many patients are affected by retinal diseases that cause vision loss (e.g. age-related macular degeneration has a prevalence of 9% [19]). We propose to identify abnormal regions which can serve as potential biomarkers in retinal spectral-domain OCT (SD-OCT) images, using a Deep Convolutional Autoencoder (DCAE) trained unsupervised on healthy examples as feature extractor and a One-Class SVM to estimate the distribution of normal appearance. By using only healthy examples for training, we omit the need of collecting a dataset that represents all the variabilities which may occur in the data and contains sufficient amount of anomalies.\nResults show that the trained model is able to achieve a dice of 0.55 regarding annotated pathologies in OCT images. Since there are different pathologies and structures occurring in the regions detected as anomalous, a meaningful sub-classification of these areas is of particular medical interest. Therefore we further cluster regions identified as anomalous in order to retrieve a meaningful segmentation of these areas. In addition, we evaluate to which extent the learned features can be used in a classification task, where intraretinal cystoid fluid (IRC), subretinal fluid (SRF) and the remaining part of the retina are classified. A classification accuracy of 86.6% indicates the discriminative power of the learned feature representation.\nRelated Work Deep Convolutional Neural Networks (CNNs) in combination with large quantities of labeled data have recently improved the state-of-the-art in various tasks such as image classification [16] or object detection [13]. CNNs can automatically learn translation invariant visual input representations, enabling the adaptation of visual feature extractors to data, instead of manual feature engineering. While purely supervised training of networks is suitable if labeled data is abundant, unsupervised methods enable the exploitation of unlabeled data [2, 4, 5, 20], discovering the underlying structure of data.\nDoersch et al. [4] use spatial context as supervisory signal to train a CNN without labels, learning visual similarity across natural images, which does not necessarily extend to medical domain. Dosovitskiy et al. [5] train a CNN unsupervised by learning to discriminate between surrogate image classes which are created by data augmentation. A limitation of this approach is that it does not scale\n29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n61 2.\n00 68\n6v 1\n[ cs\n.L G\n] 2\nD ec\n2 01\n6\nto arbitrarily large amounts of unlabeled data. Zhao et al. [20] propose joint instead of layer-wise training of convolutional autoencoders, but they perform experiments in a semi-supervised setting.\nA variety of anomaly detection techniques are reported in the literature. Carrera et al. [1] use the technique of convolutional sparse models to detect anomalous structures in texture images. In the work of Erfani et al. [6] Deep Belief Networks are combined with One-Class SVMs in order to address the problem of anomaly detection in real-life datasets. In contrast to our paper, these works address problems regarding natural images and real-life datasets, which have considerable different characteristics compared to medical images, as explained above. An overview for anomaly detection methods can be found in [12].\nRegarding unsupervised learning in OCT images, Venhuizen et al. [18] train random forests with features from a bag-of-words approach in order to classify whole OCT volumes, as opposed to our pixel-wise segmentation approach. Schlegl et al. [14] use weakly supervised learning of CNNs to link image information to semantic descriptions of image content. In contrast to our work, the aim is to identify a priori defined categories in OCTs using clinical reports."}, {"heading": "2 Method", "text": "The following preprocessing is applied to all volumes. First we identify the top and bottom layer of the retina using a graph-based surface segmentation algorithm [7], where the bottom layer is used to project the retina on a horizontal plane. Then each B-scan is brightness and contrast normalized. Finally we perform over-segmentation of all B-scans to monoSLIC superpixels sp of an average size of 4\u00d7 4 pixels [9]. To capture visual information at different levels of detail, we use a multi-scale approach to perform superpixel-wise segmentation of the visual input. We conduct unsupervised training of two DCAEs on pairs of extracted patches sampled at the same positions for two scales (32 \u00d7 32 patches for DCAE1 and down-sampled 128\u00d7 32 to 32\u00d7 32 patches for DCAE2) in parallel. The used network architecture for both scales is 512c9-3p-2048f-512f for the encoder, implying a matching decoder structure that uses deconvolution and unpooling operations. All layers except pooling and unpooling are followed by Exponential Linear Units (ELUs) [3]. The loss function for training is defined as the Mean Squared Error function MSE(x, x\u0302), where x denotes the input patch and x\u0302 the reconstructed input. In addition, we use dropout in each layer, which corresponds to unsupervised joint training with local constraints in each layer.\nThe feature representations of both scales are concatenated and used as input for training a Denoising Autoencoder (DAE), its single-layer architecture denoted as 256f. All three models together form our final model DCAEent that gives us a 256 dimensional feature representation z for a specific superpixel in the B-Scan.\nWe then train the One-Class SVM [15] using a linear kernel to find a boundary that describes the distribution of healthy examples in the feature space z, which serves as decision boundary for unseen data. New samples can be classified either as coming from the same data distribution if lying within the boundary (normal) or not (anomaly). For each OCT, features z and the corresponding class are computed for each superpixel lying within the top and bottom layer of the retina. This provides a segmentation of the retina into two classes.\nSubsequently, we use spherical K-means clustering [10] with cosine distance to sub-segment regions which have been identified as anomalous in the former step into multiple clusters c. The number of cluster centroids is determined by an internal evaluation criterion called Davies-Bouldin (DB) index [8], where a small value indicates compact and well separated clusters. To segment an unseen OCT, each superpixel with the property \u201danomalous\u201d gets a cluster assignment, according to the nearest cluster centroid in the feature space z."}, {"heading": "3 Evaluation", "text": "The primary purpose of the evaluation is to test if we can identify novel marker candidates in imaging data algorithmically, instead of relying on a priori defined object categories. We evaluated (1) if we can segment anomalies, (2) if we can find categories of these regions that correspond to a fine-grained ontology of known findings, and (3) if the learned features have discriminative power for image classification.\nTable 1: Dice, Precision and Recall for anomalous regions with ground-truth annotations. The same One-Class SVM settings are used for all methods.\nAlgorithm Dice Precision Recall\nPCA256 0,33 0,31 0,39 PCA0.95 0,32 0,32 0,35 DCAEent 0,55 0,53 0,58\nTable 2: Mean classification accuracies of L2-SVMs on the generated OCT-dataset with balanced classes, trained with features from different models.\nAccuracy (in percent)\nAlgorithm IRC SRF Other Overall\nPCA256 71.9 74.0 73.9 73.4 (\u00b1 3.9) PCA0.95 73.3 76.9 70.0 73.4 (\u00b1 3.9) DCAEent 87.3 88.3 84.1 86.6 (\u00b1 1.6)\nWe used scans from 704 patients, where 283 healthy OCT volumes were used to create the healthy training set (277,340 pairs of image patches) for the DCAE and the SVM, 411 unlabeled OCTs were used to create the anomaly training set (295,920 patches) for clustering, and the validation and test set consisting of 5 volumes each, with voxel-wise ground truth annotations of anomalous regions and additional annotations for specific pathologies (IRC, SRF), were used for model selection and evaluation, respectively. The scans were acquired using Spectralis OCT instruments (Heidelberg Engineering, GER) and have a resolution of 512 \u00d7 496 \u00d7 49 depicting a 6mm \u00d7 2mm \u00d7 6mm volume of the retina, where the distance between voxel centers is about 11\u00b5m in the first, 4\u00b5m in the second, and 120\u00b5m in the third dimension.\nThe learned anomaly detection model is evaluated on the test set, where Dice, Precision and Recall are calculated for anomalous regions regarding the ground-truth annotation. Interpretation of these quantitative values is done carefully and only in combination with qualitative evaluation by clinical retina experts.\nIn addition, we compare our DCAEent model with conventional PCA embedding. To ensure fair comparison, we train two models. In the first model PCA256, the dimensionality is chosen to match the feature dimension z of our proposed model. For both scales, the first 128 principal components are kept and concatenated to obtain z. In the second model PCA0.95, for each scale the first components that describe 95% of the variance in the dataset are kept.\nFor the categorization of anomalous regions the number of clusters is varied between 2 and 30, where the model with the lowest DB-index on the anomaly training set is selected and applied to the test set. We qualitatively evaluate if the categories found in the regions identified as abnormal are clinically meaningful, to provide a link to actual disease.\nBeside anomaly detection, we test the learned models in a classification task in order to evaluate the discriminative power of the learned feature representation. Here, we train a linear Support Vector Machine (L2-SVM) on a balanced classification dataset with 15,000 labeled examples and three classes (33.3% IRC, 33.3% SRF, 33.3% remaining part of the retina) in feature space z. 5-fold-crossvalidation is performed so that samples of a patient are only present in one fold, where this labeled dataset is only used to train the L2-SVM."}, {"heading": "4 Results", "text": "We report quantitative and qualitative results illustrating anomaly segmentation, visualize anomaly categorization outcome, provide descriptions of clusters according to the experts and describe results regarding the classification task.\nAs can be seen in Table 1 our method achieves a dice of 0.55, which is a clear improvement in comparison with both PCA256 and PCA0.95. This is also reflected by the visualization provided in Figure 1 (a)-(d), which shows substantial overlap between ground truth annotations and DCAEent segmentation. DCAEent provides a less diffuse segmentation compared to PCA0.95, capturing the retinal pathology in a meaningful way.\nRegarding anomaly categorization, the lowest DB-index was found for 7 clusters, as illustrated in Figure 1 (f). Figure 1 (e) shows 2D t-SNE embedding [17] of the learned DCAEent features. Categories were identified and described as following by two clinical retina experts and are summarized in Figure 1 (g)-(h).\nBright horizontal edges are segmented in cluster \u201d1\u201d which is highlighted in blue. In the majority of cases this cluster corresponds to Retinal Pigment Epithelium (RPE). Cluster \u201d2\u201d is marked in light green and corresponds to areas below these horizontal structures. Both clusters segment areas situated next to fluid, which changes the local appearance of patches to abnormal. Cluster \u201d4\u201d is highlighted in yellow and corresponds to fluid within the retina. This finding is supported by the fact that 62% of manual IRC annotations located in anomalous regions are assigned to cluster \u201d4\u201d. Marked in grey-blue and pink, Cluster \u201d3\u201d and \u201d5\u201d both segment regions that correspond to fluid beneath the RPE. Cluster \u201d6\u201d (dark green) and \u201d7\u201d (brown) highlight the border between vitreous and retina due to irregular curvature or fluid situated below, which alters the appearance of extracted patches.\nThe classification results are illustrated in Table 2, where mean overall accuracy as well as class specific accuracies are reported. The proposed unsupervised feature learning approach DCAEent clearly outperforms both conventional methods PCA256 and PCA0.95. Our proposed method achieves a mean overall accuracy of 86.6%, while the PCA-models only achieve 73.4% and 73.3%."}, {"heading": "5 Discussion", "text": "In this paper we propose a method to detect anomalous regions in OCT images which needs only healthy training data. A deep convolutional autoencoder is used as feature extractor, while One-Class SVM is used to estimate the distribution of healthy retinal patches. In a second step, the identified anomalous regions are segmented into subclasses by clustering. Results show that our proposed method is not only capable of finding anomalies in unseen images, but also categorizes these findings into clinically meaningful classes. The identification of new anomalies, instead of the automation of expert annotation of known anomalies is a critical shift in medical image analysis. It will impact the categorization of diseases, the monitoring of treatment and the discovery of relationships between genetic factors and phenotypes. Additionally, the power of our learned feature extractor is also indicated by performance in a classification task."}, {"heading": "Acknowledgments", "text": "This work funded by the Austrian Federal Ministry of Science, Research and Economy, and the FWF (I2714-B31). A Tesla K40 used for this research was donated by the NVIDIA Corporation."}], "references": [{"title": "Detecting anomalous structures by convolutional sparse models", "author": ["D. Carrera", "G. Boracchi", "A. Foi", "B. Wohlberg"], "venue": "In Neural Networks (IJCNN),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Unsupervised object discovery and localization in the wild: Part-based matching with bottom-up region proposals", "author": ["M. Cho", "S. Kwak", "C. Schmid", "J. Ponce"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Fast and accurate deep network learning by exponential linear units (elus)", "author": ["D.-A. Clevert", "T. Unterthiner", "S. Hochreiter"], "venue": "arXiv preprint arXiv:1511.07289,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Unsupervised visual representation learning by context prediction", "author": ["C. Doersch", "A. Gupta", "A.A. Efros"], "venue": "In Proceedings of the IEEE International Conference on Computer Vision,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Discriminative unsupervised feature learning with convolutional neural networks", "author": ["A. Dosovitskiy", "J.T. Springenberg", "M. Riedmiller", "T. Brox"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "High-dimensional and large-scale anomaly detection using a linear one-class svm with deep learning", "author": ["S.M. Erfani", "S. Rajasegarar", "S. Karunasekera", "C. Leckie"], "venue": "Pattern Recognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Automated 3-d intraretinal layer segmentation of macular spectral-domain optical coherence tomography images", "author": ["M.K. Garvin", "M.D. Abr\u00e0moff", "X. Wu", "S.R. Russell", "T.L. Burns", "M. Sonka"], "venue": "Medical Imaging, IEEE Transactions on,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "On clustering validation techniques", "author": ["M. Halkidi", "Y. Batistakis", "M. Vazirgiannis"], "venue": "Journal of Intelligent Information Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Over-segmentation of 3d medical image volumes based on monogenic cues", "author": ["M. Holzer", "R. Donner"], "venue": "In Proceedings of the 19th CVWW,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Spherical k-means clustering", "author": ["K. Hornik", "I. Feinerer", "M. Kober", "C. Buchta"], "venue": "Journal of Statistical Software,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Optical coherence tomography", "author": ["D. Huang", "E.A. Swanson", "C.P. Lin", "J.S. Schuman", "W.G. Stinson", "W. Chang", "M.R. Hee", "T. Flotte", "K. Gregory", "C.A. Puliafito"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1991}, {"title": "A review of novelty detection", "author": ["M.A. Pimentel", "D.A. Clifton", "L. Clifton", "L. Tarassenko"], "venue": "Signal Processing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Faster r-cnn: Towards real-time object detection with region proposal networks", "author": ["S. Ren", "K. He", "R. Girshick", "J. Sun"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Predicting semantic descriptions from medical images with convolutional neural networks", "author": ["T. Schlegl", "S.M. Waldstein", "W.-D. Vogl", "U. Schmidt-Erfurth", "G. Langs"], "venue": "In Information Processing in Medical Imaging,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Estimating the support of a high-dimensional distribution", "author": ["B. Sch\u00f6lkopf", "J.C. Platt", "J. Shawe-Taylor", "A.J. Smola", "R.C. Williamson"], "venue": "Neural computation,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2001}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Visualizing data using t-sne", "author": ["L. Van der Maaten", "G. Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Automated age-related macular degeneration classification in oct using unsupervised feature learning", "author": ["F.G. Venhuizen", "B. van Ginneken", "B. Bloemen", "M.J. van Grinsven", "R. Philipsen", "C. Hoyng", "T. Theelen", "C.I. S\u00e1nchez"], "venue": "In SPIE Medical Imaging, pages 94141I\u201394141I. International Society for Optics and Photonics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Global prevalence of age-related macular degeneration and disease burden projection for 2020 and 2040: a systematic review and meta-analysis", "author": ["W.L. Wong", "X. Su", "X. Li", "C.M.G. Cheung", "R. Klein", "C.-Y. Cheng", "T.Y. Wong"], "venue": "The Lancet Global Health,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Stacked what-where auto-encoders", "author": ["J. Zhao", "M. Mathieu", "R. Goroshin", "Y. Lecun"], "venue": "arXiv preprint arXiv:1506.02351,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}], "referenceMentions": [{"referenceID": 10, "context": "Optical Coherence Tomography (OCT) [11] is an important diagnostic modality in ophthalmology and offers a high-resolution 3D image of the layers and entities in the retina.", "startOffset": 35, "endOffset": 39}, {"referenceID": 11, "context": "Anomaly detection [12] in retinal images is a difficult and unsolved task, though many patients are affected by retinal diseases that cause vision loss (e.", "startOffset": 18, "endOffset": 22}, {"referenceID": 18, "context": "age-related macular degeneration has a prevalence of 9% [19]).", "startOffset": 56, "endOffset": 60}, {"referenceID": 15, "context": "Related Work Deep Convolutional Neural Networks (CNNs) in combination with large quantities of labeled data have recently improved the state-of-the-art in various tasks such as image classification [16] or object detection [13].", "startOffset": 198, "endOffset": 202}, {"referenceID": 12, "context": "Related Work Deep Convolutional Neural Networks (CNNs) in combination with large quantities of labeled data have recently improved the state-of-the-art in various tasks such as image classification [16] or object detection [13].", "startOffset": 223, "endOffset": 227}, {"referenceID": 1, "context": "While purely supervised training of networks is suitable if labeled data is abundant, unsupervised methods enable the exploitation of unlabeled data [2, 4, 5, 20], discovering the underlying structure of data.", "startOffset": 149, "endOffset": 162}, {"referenceID": 3, "context": "While purely supervised training of networks is suitable if labeled data is abundant, unsupervised methods enable the exploitation of unlabeled data [2, 4, 5, 20], discovering the underlying structure of data.", "startOffset": 149, "endOffset": 162}, {"referenceID": 4, "context": "While purely supervised training of networks is suitable if labeled data is abundant, unsupervised methods enable the exploitation of unlabeled data [2, 4, 5, 20], discovering the underlying structure of data.", "startOffset": 149, "endOffset": 162}, {"referenceID": 19, "context": "While purely supervised training of networks is suitable if labeled data is abundant, unsupervised methods enable the exploitation of unlabeled data [2, 4, 5, 20], discovering the underlying structure of data.", "startOffset": 149, "endOffset": 162}, {"referenceID": 3, "context": "[4] use spatial context as supervisory signal to train a CNN without labels, learning visual similarity across natural images, which does not necessarily extend to medical domain.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] train a CNN unsupervised by learning to discriminate between surrogate image classes which are created by data augmentation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 19, "context": "[20] propose joint instead of layer-wise training of convolutional autoencoders, but they perform experiments in a semi-supervised setting.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1] use the technique of convolutional sparse models to detect anomalous structures in texture images.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Deep Belief Networks are combined with One-Class SVMs in order to address the problem of anomaly detection in real-life datasets.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "An overview for anomaly detection methods can be found in [12].", "startOffset": 58, "endOffset": 62}, {"referenceID": 17, "context": "[18] train random forests with features from a bag-of-words approach in order to classify whole OCT volumes, as opposed to our pixel-wise segmentation approach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] use weakly supervised learning of CNNs to link image information to semantic descriptions of image content.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "First we identify the top and bottom layer of the retina using a graph-based surface segmentation algorithm [7], where the bottom layer is used to project the retina on a horizontal plane.", "startOffset": 108, "endOffset": 111}, {"referenceID": 8, "context": "Finally we perform over-segmentation of all B-scans to monoSLIC superpixels sp of an average size of 4\u00d7 4 pixels [9].", "startOffset": 113, "endOffset": 116}, {"referenceID": 2, "context": "All layers except pooling and unpooling are followed by Exponential Linear Units (ELUs) [3].", "startOffset": 88, "endOffset": 91}, {"referenceID": 14, "context": "We then train the One-Class SVM [15] using a linear kernel to find a boundary that describes the distribution of healthy examples in the feature space z, which serves as decision boundary for unseen data.", "startOffset": 32, "endOffset": 36}, {"referenceID": 9, "context": "Subsequently, we use spherical K-means clustering [10] with cosine distance to sub-segment regions which have been identified as anomalous in the former step into multiple clusters c.", "startOffset": 50, "endOffset": 54}, {"referenceID": 7, "context": "The number of cluster centroids is determined by an internal evaluation criterion called Davies-Bouldin (DB) index [8], where a small value indicates compact and well separated clusters.", "startOffset": 115, "endOffset": 118}, {"referenceID": 16, "context": "Figure 1 (e) shows 2D t-SNE embedding [17] of the learned DCAEent features.", "startOffset": 38, "endOffset": 42}], "year": 2016, "abstractText": "The detection of diagnostically relevant markers in imaging data is critical in medicine and treatment guidance. Typically, detectors are trained based on a priori defined categories, and annotated imaging data. This makes large-scale annotation necessary which is often not feasible, limits the use to known marker categories, and overall slows the process of discovering novel markers based on available evidence. Additionally, in contrast to natural images such as photographs, the relevant categories of retinal images cover only a small fraction of the overall imaging data, though they are the focus of diagnostic attention, and are often dominated by natural variability of even healthy anatomy.", "creator": "LaTeX with hyperref package"}}}