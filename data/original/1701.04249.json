{"id": "1701.04249", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2017", "title": "Geometric features for voxel-based surface recognition", "abstract": "We introduce a library of geometric voxel features for CAD surface recognition/retrieval tasks. Our features include local versions of the intrinsic volumes (the usual 3D volume, surface area, integrated mean and Gaussian curvature) and a few closely related quantities. We also compute Haar wavelet and statistical distribution features by aggregating raw voxel features. We apply our features to object classification on the ESB data set and demonstrate accurate results with a small number of shallow decision trees.", "histories": [["v1", "Mon, 16 Jan 2017 11:30:31 GMT  (578kb,D)", "http://arxiv.org/abs/1701.04249v1", "13 pages"]], "COMMENTS": "13 pages", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["dmitry yarotsky"], "accepted": false, "id": "1701.04249"}, "pdf": {"name": "1701.04249.pdf", "metadata": {"source": "CRF", "title": "Geometric features for voxel-based surface recognition", "authors": ["Dmitry Yarotsky"], "emails": [], "sections": [{"heading": null, "text": "Keywords: CAD surface recognition and retrieval, feature vector, integral geometry, voxel, decision tree, Haar wavelet, Engineering Shape Benchmark"}, {"heading": "1 Introduction", "text": "Automated classification of CAD shapes, along with retrieval of similar shapes, is an old and well-studied area of research. The common approach to automated classification/retrieval consists in first representing the shape by a feature vector using some collection of descriptors, and then, for the classification task, training a classifier using some general classification algorithm applicable to array-like data, or, for the retrieval task, comparing feature vectors and finding nearby vectors in the feature space. Here, we use the notion of feature vector in a broad sense, as any standardized, fixed-size representation of the object. Replacing the original description by a feature vector serves the important purposes of reducing the complexity of the representation and making all the (otherwise possibly quite diverse) objects directly comparable with each other. There is a large variety of very different strategies to form the feature vector; see 3D retrieval surveys [2, 4, 5, 14,23,28].\nA simple class of features is global geometric properties such as the (properly rescaled) total area, volume, low degree moments, or Euler characteristic [8, 19, 27]. These global features are appealing thanks to their direct geometric meaning, but are relatively crude to distinguish complex shapes.\nAnother popular class of features comes from statistical description of local properties. In this approach, feature vectors can be thought of as histograms of quantities characterizing the local surface geometry (e.g., orientation, point-to-point distance, curvature, etc.) on a certain length scale [1, 13,21].\n\u2217Skolkovo Institute of Science and Technology, Skolkovo Innovation Center, Building 3, Moscow 143026, Russia, d.yarotsky at skoltech.ru \u2020Institute for Information Transmission Problems, Bolshoy Karetny per. 19, build.1, Moscow 127051, Russia\nar X\niv :1\n70 1.\n04 24\n9v 1\n[ cs\n.C V\n] 1\n6 Ja\nn 20\n17\nRecently, it has become very popular to approach the classification/retrieval tasks using deep learning and surface voxelization [3,10,20,26]. In this case, the feature vector is the assignment of Boolean values (\u201cempty/occupied\u201d) to the set of all voxels. In contrast to some other feature generation strategies, voxelization preserves information on spatial location of surface elements, which allows one to combine this approach with localization-aware learning methods such as convolutional neural networks.\nThe purpose of the present paper is to describe a unified framework combining voxel representation of CAD models with standard geometric properties such as area, curvature, orientation, etc. Specifically, instead of just marking a voxel as \u201cempty\u201d or \u201coccupied\u201d, we equip it with a detailed description of the local surface geometry. While this general idea is certainly not new (see, e.g., [9, 17, 18, 25]), some elements of our approach distinguish it from earlier research.\n\u2022 In each voxel, we aim to obtain a possibly rich yet consistent and compact characterization of the local geometry. In particular, our features include voxel-restricted versions of all four 3D morphological Minkowski functionals [19,22]. This also allows us to directly compare efficiency of different feature types.\n\u2022 We aim to consider geometric features on different length scales in a unified fashion, mostly through the additivity property (the value of the feature on the larger scale is the sum of the corresponding values on the smaller scale). When evaluated on the largest scale, some of our features become familiar global quantities: total area, volume, the complete integral of mean curvature, and Euler characteristic. This allows us to directly compare efficiency of different scales for feature representation.\n\u2022 We explicitly decouple feature generation in voxels from subsequent post-processing and learning phases. This allows us to directly evaluate effects of different feature aggregation strategies, e.g., the Haar wavelet transform and histograms of feature values.\n\u2022 The natural trend in voxelization-based 3D shape classification/retrieval is the increase in resolution, thanks to the constantly growing number and diversity of 3D models. As CAD models are essentially 2D surfaces, only a small share of voxels is occupied at high resolutions. Our implementation of voxel features is sparse-vectorbased, which allows us to consider resolutions N \u00d7N \u00d7N with N > 100.\nThe code for this work has been open-sourced as the library voxelfeatures.1 The library has a C++ feature-generation core and Python bindings, and can be installed in a conventional way as an importable Python module."}, {"heading": "2 Voxel features", "text": "The main focus of our work is a library of local features computed in each voxel of the rasterized representation. Given a surface \u03a3 and a cubic voxel V , a local feature is some quantity evaluated for the intersection \u03a3 \u2229 V and characterizing some geometric aspects of this piece of the surface: orientation, roughness, curvature, etc.\n1https://github.com/yarotsky/voxelfeatures/\nOur selection of features is primarily influenced by the integral geometry point of view. Our first choice is the voxel-restricted family of intrinsic volumes (also known by many other names: valuations, Minkowski functionals, etc.). In 3D, there are four intrinsic volumes: the usual 3D volume, the surface area, and the integrated mean and Gaussian curvatures of the surface [22]. The intrinsic volumes are known to generally play a major role in practical pattern recognition problems [19,24].\nOne important property of the instrinsic volumes is their Hausdorff-continuity on convex sets. Smooth surfaces \u03a3 are commonly represented in practice by triangle meshes \u03a3\u2032 approximating them with some accuracy. We are interested in those geometric features that are not too sensitive to such an approximation. In particular, a reasonable feature should not depend on the way in which a polygonal face is divided into triangles. One way to formulate a general requirement is to say that the feature should be continuous w.r.t. the Hausdorff distance between surfaces,\ndist(\u03a3,\u03a3\u2032) = max(max x\u2208\u03a3 min y\u2208\u03a3\u2032 |x\u2212 y|,max x\u2208\u03a3\u2032 min y\u2208\u03a3 |x\u2212 y|).\nThe intrinsic volumes are Hausdorff-continuous on the set of surfaces bounding convex\nbodies (though not on arbitrary surfaces, in general). Another important property of the intrinsic volumes is their Euclidean invariance (invariance with respect to rigid motions). Finally, the intrinsic volumes are additive, in the sense that F (A) + F (B) = F (A \u2229 B) + F (A \u222aB), where F (A) denotes an intrinsic volume of a body A. The central general result in integral geometry, Hadwiger\u2019s theorem, states that any additive, Euclidean invariant functional on d-dimensional bodies that is Hausdorffcontinuous on the set of convex bodies is a linear combination of the d + 1 intrinsic volumes (in particular, the four aforementioned volumes in the 3D case) [6, 12,16].\nWe slightly adapt the concept of intrinsic volumes for our purpose of defining voxel features, also taking into account the fact that computationally we work with surfaces rather than bodies. Namely, all the intrinsic volumes except for the 3D volume are surface integrals of elementary symmetric polynomials of the local curvatures; we define the respective voxel features (see the features SA, VAD, EAD below) by restricting the surface integral to the voxel. Since the 3D volume can also be written as a surface integral, we define the respective feature (see VE below) in the same fashion, by restricting this surface integral to the voxel.\nClearly, due to the Euclidean symmetry breaking and boundary effects associated with voxelization, the resulting voxel features do not retain the Euclidean invariance and continuity of the intrinsic volumes; however, we expect that our choice of features should in some sense minimize these negative effects. The additivity property is retained in the sense that if a voxel is represented as a union of disjoint voxels on a lower length scale, V = \u222akVk, then F (V ) = \u2211 k F (Vk). In particular, given a conventional single length scale voxelization, the total sum of the feature values in all voxels gives the full intrinsic volume.\nThe intrinsic volumes are orientation-independent, which is useful for rotation-invariant object classes, but in some cases information about orientation is important (e.g., to distinguish object\u2019s top from bottom). To this end, we also consider some features containing this information and defined, as before, by integrating over the surface restricted to the voxel (see AN, QF below).\nAs the discussion above shows, we are mostly interested in the case when the surface \u03a3 is a boundary of a solid body. In this case the triangle mesh \u03a3\u2032 is supposed to be consistent, in the sense that each edge is incident to exactly two faces, and the orientations of these two faces are compatible. Such consistent meshes are sometimes referred to as \u201cwatertight\u201d, while unconstrained collections of triangles are referred to as \u201cpolygon soups\u201d. Some of our voxel features, but not all, require consistent meshes.\nComputation of our features is based on first finding the polygonal decomposition of \u03a3\u2032 \u2229 V for each voxel V , which is done recursively by octree traversal; only non-empty voxels are analyzed so that the full feature vector is a sparse vector.\nBelow we list our features, primarily defining them in general integral-geometric terms, and detailing how they are computed from the polygonal mesh only where it is not obvious (otherwise, integrals are replaced by respective sums, etc.). Some properties of the features are summarized in Table 1 and examples are shown in Fig. 1.\nBool\nBool(\u03a3, V ) = { 1, \u03a3 \u2229 V = \u2205 0, otherwise\nThis is the trivial feature most often used in voxelization. In contrast to other features, Bool can in principle be computed without finding the detailed polygonal decomposition of \u03a3\u2032 \u2229 V .\nSurfaceArea (SA)\nSA(\u03a3, V ) = \u222b \u03a3\u2229V dS\nObviously, the total value of this additive feature (the value at the trivial 1 \u00d7 1 \u00d7 1 voxelization) is the total area of the surface.\nAreaNormal (AN)\nAN(\u03a3, V ) = \u222b \u03a3\u2229V \u2212\u2192n dS,\nwhere \u2212\u2192n is the local normal to the surface. This additive feature requires consistent meshes with a fixed surface orientation (with all normals either outward or inward). For a consistent mesh the total value of AN is 0.\nQuadForm (QF)\nQF(\u03a3, V ) = \u222b \u03a3\u2229V \u2212\u2192n\u2212\u2192n tdS,\nwhere \u2212\u2192n\u2212\u2192n t is the outer product, so that QF is a symmetric positive-definite 3 \u00d7 3 matrix (with 6 independent parameters). In contrast to AN, this feature is not affected by reversing the normal direction and so does not require mesh consistency. The trace of QF equals SA.\nEigenValues (EV) This feature represents the three sorted eigenvalues of the positivedefinite matrix QF defined above. EV contains the rotation-invariant information about QF, which makes it more suitable than QF for orientation independent tasks.\nVertexAngularDefect (VAD) This feature represents the integral of the Gaussian curvature:\nVAD(\u03a3, V ) = \u222b \u03a3\u2229V k1k2dS,\nwhere k1, k2 are the two principal curvatures at surface points. This feature requires a consistent mesh. Given such a mesh, VAD can be expressed as the total angular defect of all vertices found in the voxel V . The angular defect of a vertex is defined as 2\u03c0\u2212 \u2211 \u03b1n, where \u03b1n are the incident angles of the polygonal surface. This angular defect is the polyhedral analog of the Gaussian curvature: if a smooth surface is approximated by polyhedra, then the total angular defect in a given domain will converge to the integral of the Gaussian curvature in this domain (conversely, if a polyhedral surface is approximated by smooth surfaces, then the Gaussian curvature will concentrate at the vertices of the polyhedral surface). By Descartes\u2019 theorem (or GaussBonnet theorem in the smooth case), the total angular defect is a topological invariant and equals 2\u03c0 times the Euler characteristic of the surface (2\u2212 2 \u00b7 \u201cnumber of handles\u201d, assuming that the surface is connected).\nEdgeAngularDefect (EAD) This feature represents the integral of the mean curvature (with the factor 2):\nEAD(\u03a3, V ) = \u222b \u03a3\u2229V (k1 + k2)dS.\nThe version of this formula for a polygonal surface reads EAD(\u03a3\u2032, V ) = \u2211\nedges e\n(\u03c0 \u2212 \u03b2e)le\u2229V ,\nwhere \u03b2e is the dihedral angle at the edge e, and le\u2229V is the length of the intersection of the edge e with the voxel V .\nVolumeElement (VE)\nVE(\u03a3, V ) = 1\n3 \u222b \u03a3\u2229V \u2212\u2192r t\u2212\u2192n dS,\nwhere \u2212\u2192r is the radius vector and \u2212\u2192r t\u2212\u2192n the inner product of this vector with the normal. Assuming that the normal is outward, the total value of VE is the volume of the body bounded by the surface \u03a3. In contrast to other features, VE is not translation-invariant (as \u2212\u2192r depends on the position of the origin)."}, {"heading": "3 Feature aggregation", "text": "At high resolutions, the local features computed in voxels as described above tend to produce an excessively detailed description of the surface. A classifier trained on such\na description will likely overtrain substantially. One way to counteract this is to use a classification algorithm with overtraining prevention mechanisms \u2013 e.g., a convnet, as it utilizes weight sharing. Another way is to directly transform the initial, \u201craw\u201d voxel features into some more appropriate \u201caggregated\u201d features. The available grid-like structure of the raw voxel representation is essential for some aggregation strategies.\nOne example of such aggregation is a wavelet transformation of the voxel data. We consider the simplest case of Haar wavelets [11]. Suppose that a scalar voxel feature is evaluated at a resolution N = 2n, so that the total feature space can be written as W \u2297W \u2297W, where W is the 2n-dimensional space of feature values along one coordinate. The Haar transform can then be written as H\u2297H\u2297H, where H is the orthogonal 2n\u00d72n matrix with the entries\nHk,s =  2\u2212n/2, k = 1, 2\u2212(n\u2212m)/2, 2m < k \u2264 2m+1, (k \u2212 2m \u2212 1)2n\u2212m < s \u2264 (k \u2212 2m \u2212 1/2)2n\u2212m, \u22122\u2212(n\u2212m)/2, 2m < k \u2264 2m+1, (k \u2212 2m \u2212 1/2)2n\u2212m < s \u2264 (k \u2212 2m)2n\u2212m, 0, otherwise,\nwith m = 0, . . . , n \u2212 1 characterizing the length scale. As the Haar transform is linear and orthogonal, the transformed features contain the same information as the original raw features, but this information is now redistributed over several different length scales according to the value of m. This explicit exposure of the length scale hierarchy can help reduce overtraining and is an alternative to generating raw voxel features at several resolutions.\nAnother example of feature aggregation is to compute a histogram or some other statistical measure of feature values over the non-empty voxels. In the experiments below we consider a few feature percentiles. In particular, the 0\u2019th percentile corresponds to the minimal value, the 100\u2019th to the maximum value, and the 50\u2019th to the median value.\nIn the case of vector-valued features we perform feature aggregation separately for each component."}, {"heading": "4 Experiments", "text": "We have performed a series of classification experiments with the ESB (Engineering Shape Benchmark, [15]) collection of CAD models. This collection consists of 866 mechanical parts divided into 3 \u201csuperclasses\u201d (Flat-thin wall components, Rectangular cubic prisms, and Solids of revolution). Each superclass is further divided into finer classes (like Clips, Handles, Bolt like parts, etc.); there are 45 fine classes in total (hereafter referred to simply as classes). In particular, each superclass contains a Miscellaneous class for objects that cannot be easily assigned to other classes of this superclass. See Fig. 4 for some examples of ESB objects.\nWe have divided the collection into a training set of 675 objects and a test set of 191 objects, to be used in all the experiments. A classifier\u2019s prediction for a given object is a 45-dimensional vector of class probabilities. We measure the total prediction error simply as the fraction of test objects where the true class is different from the one with the highest predicted probability.\nAll the ESB models have consistent, watertight meshes, so all the features from Table 1 are applicable.\nAs the ESB collection is relatively small, classifiers tend to overfit on it substantially. A common strategy to somewhat reduce overfitting is to symmetrize the training set and the classifier. Specifically, if the class of a surface \u03a3 is supposed to be invariant under the action of some group of transformations G (for a g \u2208 G we denote the action of g on \u03a3 by g\u03a3), we can, first, augment the original training set T with the transformed surfaces \u222ag\u2208GgT and, second, symmetrize the predictions of the classifier C:\nCsym(\u03a3) = 1 |G| \u2211 g\u2208G C(g\u03a3).\nIf G is infinite, or finite but large, one takes a sample of G rather than the full group. Classification of the ESB models is clearly O(3)-invariant, and the models do not, in general, have a preferred orientation. One way to exploit this invariance is to rotate the surface to its principal axes and then symmetrize over the 23 \u00b7 3! = 48 reflections and permutations of these axes. We have found it, however, to be somewhat more efficient to directly sample the group O(3). The results described below have been obtained with the data and classifiers symmetrized using 20 random rotations followed by centering and rescaling the surfaces to fit the unit cube.\nOur classifiers are ensembles of gradient boosted trees trained using the XGBoost library [7]. While it is common to train voxelization-based classifiers with neural networks [10, 26], XGBoost has allowed us to easily mix raw and aggregated features as well as features on different length scales, and examine their relative effect and the complexity of the resulting classifiers.\nThe experiments were performed on a computer with Intel Core i5-3470 CPU and 16 GB RAM.\nIn the first series of experiments we compare the efficiency of different individual raw features at different resolutions, see Fig. 2a. The tree depth for these experiments was fixed at the default XGBoost value 6, which was found through preliminary testing to produce good results. We observe that the optimal resolutions are those between 4 and 16: at higher values the voxelized description is too detailed to be efficiently processed by XGBoost. Some features, namely QF and EV, turn out to be quite discriminative even at the trivial resolution 1. This is not surprising, since many classes have typical characteristics reflected in the global 3-dimensional feature EV, e.g. pipes and hollow bodies have a relatively large area (which is the sum of the EV values), some classes have a cylindrical symmetry (then two of the EV values are equal), some classes are characterized by an elongated shape (then two of the EV values are much larger than the third) or flatness (one EV value is much larger then the other two). QF is essentially EV with the added orientation data; at the trivial resolution 1 the orientation data is a noise that can only degrade the recognition accuracy, so QF\u2019s performance is worse than that of EV. At resolutions higher than 1 the classification accuracy is even higher, though the EV values are then not as easily interpretable. The trivial Bool feature catches up with more complex features at high resolutions, but on the whole is outperformed by other features.\nIn the second series of experiments we compare raw voxel EV features with the respective Haar wavelet features at different resolutions, see Fig. 2b. We see that, as\ndiscussed in Section 3, despite containing the same information, the Haar representation helps prevent overfitting at large resolutions.\nFinally, we construct a classifier using multiple local raw and statistical (percentile) features evaluated at multiple length scales. Specifically, we include in the set of features all raw non-Bool features from Section 2 at resolutions 1, 2 and 4, and all (non-Bool) statistical features at the resolutions {2n}7n=1. Note that we can consider statistical voxel features at high resolutions thanks to our sparse representation of voxel features. Our statistical features include the percentiles 0, 25, 50, 75 and 100. It was determined through preliminary experiments that with these features the optimal results are achieved with very shallow, depth-2 trees.\nIn Fig. 3a we show the error convergence history of the trained classifier. The test error is shown separately for the O(3)-symmetrized and non-symmetrized classifiers. We observe, in particular, that with the non-symmetrized classifier it takes about 10 (respectively, 30) depth-2 trees per class to reach the classification errors 0.3 (0.2), while with the symmetrized one it takes 5 (15) trees. At the end of training the test error is approximately 0.15.\nIn Fig. 3b we show the top 20 features (both raw and aggregated) in terms of the number of their occurrences in the trees of the final classifier. We observe that the top features include raw features at the trivial resolution 1 as well as statistical features at large resolutions. While the earlier experiment with individual features in Fig. 2a suggests that raw features can be useful at resolutions higher than 1 with deeper trees, in the present experiment they are clearly outperformed by statistical features. We also observe that the classifier especially favors the VAD-, EAD-, and EV-based features and does not favor the SA-, QF- and AN-based ones. Interestingly, neither the total area\n([1][SA]) nor the total volume ([1][VE]) is among the top-20 features, though some statistical VE features are.\nIn Fig. 4 we show typical predictions of the classifier. We remark that, not surprisingly, confusions involving the Miscellaneous classes seem to be especially frequent."}, {"heading": "5 Conclusion", "text": "We have introduced and examined several voxel features inspired by integral geometry, as well as some more complex (Haar and statistical) features derived from them. We have tested our features on the task of classifying ESB CAD models with gradient boosted trees and observed a reasonably good performance. Our framework has allowed us to compare efficiency of different features and different resolutions at which they are evaluated. In particular, we have found that, within this framework, the best ESB classification results were achieved with very shallow, depth-2 trees that favored high resolution statistical features as well as some global features such as the total integrals of the Gaussian and mean curvature.\nGeneration of complex features for high resolution voxelization is a relatively complex and time-consuming task, so, speaking about classification, there is some trade-off between using complex features with simple predictive models (as in our case) and using simple features with complex models (as with deep convnets applied to Boolean voxelization). The former alternative may be preferable, for example, if a possibly explicit description or in-depth analysis of the predictive model is desired.\nAs we have already mentioned, though our voxel features are primarily inspired by\nthe global intrinsic volumes, they, for obvious reasons, do not share the defining properties of the latter, in particular the Euclidean invariance. It would be interesting to develop some general integral-geometric theoretical framework for features compatible with voxelization."}, {"heading": "Acknowledgment", "text": "The author thanks Ermek Kapushev, Alexandr Notchenko and Evgeny Burnaev for many interesting discussions."}], "references": [{"title": "3d shape histograms for similarity search and classification in spatial databases", "author": ["Mihael Ankerst", "Gabi Kastenm\u00fcller", "Hans-Peter Kriegel", "Thomas Seidl"], "venue": "In International Symposium on Spatial Databases,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1999}, {"title": "Content-based retrieval of 3D models", "author": ["Alberto Del Bimbo", "Pietro Pala"], "venue": "ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Generative and discriminative voxel modeling with convolutional neural networks", "author": ["Andrew Brock", "Theodore Lim", "JM Ritchie", "Nick Weston"], "venue": "arXiv preprint arXiv:1608.04236,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Vrani\u0107. Feature-based similarity search in 3d object databases", "author": ["Benjamin Bustos", "Daniel A Keim", "Dietmar Saupe", "Tobias Schreck", "Dejan V"], "venue": "ACM Computing Surveys (CSUR),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "A survey of shape similarity assessment algorithms for product design and manufacturing applications", "author": ["Antonio Cardone", "Satyandra K Gupta", "Mukul Karnik"], "venue": "Journal of Computing and Information Science in Engineering,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "A simplified elementary proof of Hadwiger\u2019s volume theorem", "author": ["Beifang Chen"], "venue": "Geometriae Dedicata,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "XGBoost: A scalable tree boosting system", "author": ["Tianqi Chen", "Carlos Guestrin"], "venue": "arXiv preprint arXiv:1603.02754,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Coarse filters for shape matching", "author": ["Jonathan Corney", "Heather Rea", "Doug Clark", "John Pritchard", "Michael Breaks", "Roddy MacLeod"], "venue": "IEEE Computer Graphics and Applications,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}, {"title": "Salient local 3d features for 3d shape retrieval. In IS&T/SPIE Electronic Imaging, pages 78640S\u201378640S", "author": ["Afzal Godil", "Asim Imdad Wagan"], "venue": "International Society for Optics and Photonics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Spatially-sparse convolutional neural networks", "author": ["Benjamin Graham"], "venue": "arXiv preprint arXiv:1409.6070,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Zur Theorie der orthogonalen Funktionensysteme", "author": ["Alfred Haar"], "venue": "Mathematische Annalen,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1910}, {"title": "Vorlesungen \u00fcber inhalt, Oberfl\u00e4che und isoperimetrie, volume 93", "author": ["Hugo Hadwiger"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Extended Gaussian images", "author": ["Berthold Klaus Paul Horn"], "venue": "Proceedings of the IEEE,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1984}, {"title": "Three-dimensional shape searching: state-of-the-art review and future trends", "author": ["Natraj Iyer", "Subramaniam Jayanti", "Kuiyang Lou", "Yagnanarayanan Kalyanaraman", "Karthik Ramani"], "venue": "Computer-Aided Design,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Developing an engineering shape benchmark for cad models", "author": ["Subramaniam Jayanti", "Yagnanarayanan Kalyanaraman", "Natraj Iyer", "Karthik Ramani"], "venue": "Computer- Aided Design,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "A short proof of Hadwiger\u2019s characterization theorem. Mathematika", "author": ["Daniel A Klain"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1995}, {"title": "Effective similarity search on voxelized CAD objects", "author": ["H-P Kriegel", "Peer Kroger", "Zahi Mashael", "Martin Pfeifle", "Marc\u00f6 Potke", "Thomas Seidl"], "venue": "In Database Systems for Advanced Applications,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2003}, {"title": "Using sets of feature vectors for similarity search on voxelized CAD objects", "author": ["Hans-Peter Kriegel", "Stefan Brecheisen", "Peer Kr\u00f6ger", "Martin Pfeifle", "Matthias Schubert"], "venue": "In Proceedings of the 2003 ACM SIGMOD international conference on Management of data,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2003}, {"title": "Additivity, convexity, and beyond: applications of Minkowski Functionals in statistical physics", "author": ["Klaus R Mecke"], "venue": "In Statistical Physics and Spatial Statistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2000}, {"title": "Sparse 3d convolutional neural networks for large-scale shape retrieval", "author": ["Alexandr Notchenko", "Ermek Kapushev", "Evgeny Burnaev"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Integral Geometry and Geometric Probability", "author": ["L.A. Santal\u00f3"], "venue": "Cambridge Mathematical Library. Beijing World Publishing Corporation (BJWPC),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2004}, {"title": "A survey of content based 3D shape retrieval methods", "author": ["Johan WH Tangelder", "Remco C Veltkamp"], "venue": "Multimedia tools and applications,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "Quantification of soil structure based on Minkowski functions", "author": ["H-J Vogel", "Ulrich Weller", "Steffen Schl\u00fcter"], "venue": "Computers & Geosciences,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "3D shape descriptor based on 3D Fourier transform", "author": ["Dejan Vranic", "Dietmar Saupe"], "venue": "In EURASIP,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2001}, {"title": "3d shapenets: A deep representation for volumetric shapes", "author": ["Zhirong Wu", "Shuran Song", "Aditya Khosla", "Fisher Yu", "Linguang Zhang", "Xiaoou Tang", "Jianxiong Xiao"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Efficient feature extraction for 2D/3D objects in mesh representation", "author": ["Cha Zhang", "Tsuhan Chen"], "venue": "In Image Processing,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2001}], "referenceMentions": [{"referenceID": 1, "context": "There is a large variety of very different strategies to form the feature vector; see 3D retrieval surveys [2, 4, 5, 14,23,28].", "startOffset": 107, "endOffset": 126}, {"referenceID": 3, "context": "There is a large variety of very different strategies to form the feature vector; see 3D retrieval surveys [2, 4, 5, 14,23,28].", "startOffset": 107, "endOffset": 126}, {"referenceID": 4, "context": "There is a large variety of very different strategies to form the feature vector; see 3D retrieval surveys [2, 4, 5, 14,23,28].", "startOffset": 107, "endOffset": 126}, {"referenceID": 13, "context": "There is a large variety of very different strategies to form the feature vector; see 3D retrieval surveys [2, 4, 5, 14,23,28].", "startOffset": 107, "endOffset": 126}, {"referenceID": 21, "context": "There is a large variety of very different strategies to form the feature vector; see 3D retrieval surveys [2, 4, 5, 14,23,28].", "startOffset": 107, "endOffset": 126}, {"referenceID": 7, "context": "A simple class of features is global geometric properties such as the (properly rescaled) total area, volume, low degree moments, or Euler characteristic [8, 19, 27].", "startOffset": 154, "endOffset": 165}, {"referenceID": 18, "context": "A simple class of features is global geometric properties such as the (properly rescaled) total area, volume, low degree moments, or Euler characteristic [8, 19, 27].", "startOffset": 154, "endOffset": 165}, {"referenceID": 25, "context": "A simple class of features is global geometric properties such as the (properly rescaled) total area, volume, low degree moments, or Euler characteristic [8, 19, 27].", "startOffset": 154, "endOffset": 165}, {"referenceID": 0, "context": ") on a certain length scale [1, 13,21].", "startOffset": 28, "endOffset": 38}, {"referenceID": 12, "context": ") on a certain length scale [1, 13,21].", "startOffset": 28, "endOffset": 38}, {"referenceID": 2, "context": "Recently, it has become very popular to approach the classification/retrieval tasks using deep learning and surface voxelization [3,10,20,26].", "startOffset": 129, "endOffset": 141}, {"referenceID": 9, "context": "Recently, it has become very popular to approach the classification/retrieval tasks using deep learning and surface voxelization [3,10,20,26].", "startOffset": 129, "endOffset": 141}, {"referenceID": 19, "context": "Recently, it has become very popular to approach the classification/retrieval tasks using deep learning and surface voxelization [3,10,20,26].", "startOffset": 129, "endOffset": 141}, {"referenceID": 24, "context": "Recently, it has become very popular to approach the classification/retrieval tasks using deep learning and surface voxelization [3,10,20,26].", "startOffset": 129, "endOffset": 141}, {"referenceID": 8, "context": ", [9, 17, 18, 25]), some elements of our approach distinguish it from earlier research.", "startOffset": 2, "endOffset": 17}, {"referenceID": 16, "context": ", [9, 17, 18, 25]), some elements of our approach distinguish it from earlier research.", "startOffset": 2, "endOffset": 17}, {"referenceID": 17, "context": ", [9, 17, 18, 25]), some elements of our approach distinguish it from earlier research.", "startOffset": 2, "endOffset": 17}, {"referenceID": 23, "context": ", [9, 17, 18, 25]), some elements of our approach distinguish it from earlier research.", "startOffset": 2, "endOffset": 17}, {"referenceID": 18, "context": "In particular, our features include voxel-restricted versions of all four 3D morphological Minkowski functionals [19,22].", "startOffset": 113, "endOffset": 120}, {"referenceID": 20, "context": "In particular, our features include voxel-restricted versions of all four 3D morphological Minkowski functionals [19,22].", "startOffset": 113, "endOffset": 120}, {"referenceID": 20, "context": "In 3D, there are four intrinsic volumes: the usual 3D volume, the surface area, and the integrated mean and Gaussian curvatures of the surface [22].", "startOffset": 143, "endOffset": 147}, {"referenceID": 18, "context": "The intrinsic volumes are known to generally play a major role in practical pattern recognition problems [19,24].", "startOffset": 105, "endOffset": 112}, {"referenceID": 22, "context": "The intrinsic volumes are known to generally play a major role in practical pattern recognition problems [19,24].", "startOffset": 105, "endOffset": 112}, {"referenceID": 5, "context": "The central general result in integral geometry, Hadwiger\u2019s theorem, states that any additive, Euclidean invariant functional on d-dimensional bodies that is Hausdorffcontinuous on the set of convex bodies is a linear combination of the d + 1 intrinsic volumes (in particular, the four aforementioned volumes in the 3D case) [6, 12,16].", "startOffset": 325, "endOffset": 335}, {"referenceID": 11, "context": "The central general result in integral geometry, Hadwiger\u2019s theorem, states that any additive, Euclidean invariant functional on d-dimensional bodies that is Hausdorffcontinuous on the set of convex bodies is a linear combination of the d + 1 intrinsic volumes (in particular, the four aforementioned volumes in the 3D case) [6, 12,16].", "startOffset": 325, "endOffset": 335}, {"referenceID": 15, "context": "The central general result in integral geometry, Hadwiger\u2019s theorem, states that any additive, Euclidean invariant functional on d-dimensional bodies that is Hausdorffcontinuous on the set of convex bodies is a linear combination of the d + 1 intrinsic volumes (in particular, the four aforementioned volumes in the 3D case) [6, 12,16].", "startOffset": 325, "endOffset": 335}, {"referenceID": 10, "context": "We consider the simplest case of Haar wavelets [11].", "startOffset": 47, "endOffset": 51}, {"referenceID": 14, "context": "We have performed a series of classification experiments with the ESB (Engineering Shape Benchmark, [15]) collection of CAD models.", "startOffset": 100, "endOffset": 104}, {"referenceID": 6, "context": "Our classifiers are ensembles of gradient boosted trees trained using the XGBoost library [7].", "startOffset": 90, "endOffset": 93}, {"referenceID": 9, "context": "While it is common to train voxelization-based classifiers with neural networks [10, 26], XGBoost has allowed us to easily mix raw and aggregated features as well as features on different length scales, and examine their relative effect and the complexity of the resulting classifiers.", "startOffset": 80, "endOffset": 88}, {"referenceID": 24, "context": "While it is common to train voxelization-based classifiers with neural networks [10, 26], XGBoost has allowed us to easily mix raw and aggregated features as well as features on different length scales, and examine their relative effect and the complexity of the resulting classifiers.", "startOffset": 80, "endOffset": 88}, {"referenceID": 1, "context": "(a) 0 20 40 60 80 100 120 140 Weight [64][VAD][hist100] [32][VAD][hist0] [32][EV][hist75][0] [2][VAD][hist0] [64][EAD][hist75] [32][VE][hist100] [1][EV][1] [64][VAD][hist0] [128][EAD][hist0] [1][EV][2] [32][EAD][hist0] [128][VE][hist75] [32][EAD][hist75] [1][EV][0] [1][VAD] [8][VAD][hist75] [128][VAD][hist100] [1][EAD] [32][EAD][hist25] [128][VAD][hist0]", "startOffset": 93, "endOffset": 96}, {"referenceID": 0, "context": "(a) 0 20 40 60 80 100 120 140 Weight [64][VAD][hist100] [32][VAD][hist0] [32][EV][hist75][0] [2][VAD][hist0] [64][EAD][hist75] [32][VE][hist100] [1][EV][1] [64][VAD][hist0] [128][EAD][hist0] [1][EV][2] [32][EAD][hist0] [128][VE][hist75] [32][EAD][hist75] [1][EV][0] [1][VAD] [8][VAD][hist75] [128][VAD][hist100] [1][EAD] [32][EAD][hist25] [128][VAD][hist0]", "startOffset": 145, "endOffset": 148}, {"referenceID": 0, "context": "(a) 0 20 40 60 80 100 120 140 Weight [64][VAD][hist100] [32][VAD][hist0] [32][EV][hist75][0] [2][VAD][hist0] [64][EAD][hist75] [32][VE][hist100] [1][EV][1] [64][VAD][hist0] [128][EAD][hist0] [1][EV][2] [32][EAD][hist0] [128][VE][hist75] [32][EAD][hist75] [1][EV][0] [1][VAD] [8][VAD][hist75] [128][VAD][hist100] [1][EAD] [32][EAD][hist25] [128][VAD][hist0]", "startOffset": 152, "endOffset": 155}, {"referenceID": 0, "context": "(a) 0 20 40 60 80 100 120 140 Weight [64][VAD][hist100] [32][VAD][hist0] [32][EV][hist75][0] [2][VAD][hist0] [64][EAD][hist75] [32][VE][hist100] [1][EV][1] [64][VAD][hist0] [128][EAD][hist0] [1][EV][2] [32][EAD][hist0] [128][VE][hist75] [32][EAD][hist75] [1][EV][0] [1][VAD] [8][VAD][hist75] [128][VAD][hist100] [1][EAD] [32][EAD][hist25] [128][VAD][hist0]", "startOffset": 191, "endOffset": 194}, {"referenceID": 1, "context": "(a) 0 20 40 60 80 100 120 140 Weight [64][VAD][hist100] [32][VAD][hist0] [32][EV][hist75][0] [2][VAD][hist0] [64][EAD][hist75] [32][VE][hist100] [1][EV][1] [64][VAD][hist0] [128][EAD][hist0] [1][EV][2] [32][EAD][hist0] [128][VE][hist75] [32][EAD][hist75] [1][EV][0] [1][VAD] [8][VAD][hist75] [128][VAD][hist100] [1][EAD] [32][EAD][hist25] [128][VAD][hist0]", "startOffset": 198, "endOffset": 201}, {"referenceID": 0, "context": "(a) 0 20 40 60 80 100 120 140 Weight [64][VAD][hist100] [32][VAD][hist0] [32][EV][hist75][0] [2][VAD][hist0] [64][EAD][hist75] [32][VE][hist100] [1][EV][1] [64][VAD][hist0] [128][EAD][hist0] [1][EV][2] [32][EAD][hist0] [128][VE][hist75] [32][EAD][hist75] [1][EV][0] [1][VAD] [8][VAD][hist75] [128][VAD][hist100] [1][EAD] [32][EAD][hist25] [128][VAD][hist0]", "startOffset": 255, "endOffset": 258}, {"referenceID": 0, "context": "(a) 0 20 40 60 80 100 120 140 Weight [64][VAD][hist100] [32][VAD][hist0] [32][EV][hist75][0] [2][VAD][hist0] [64][EAD][hist75] [32][VE][hist100] [1][EV][1] [64][VAD][hist0] [128][EAD][hist0] [1][EV][2] [32][EAD][hist0] [128][VE][hist75] [32][EAD][hist75] [1][EV][0] [1][VAD] [8][VAD][hist75] [128][VAD][hist100] [1][EAD] [32][EAD][hist25] [128][VAD][hist0]", "startOffset": 266, "endOffset": 269}, {"referenceID": 7, "context": "(a) 0 20 40 60 80 100 120 140 Weight [64][VAD][hist100] [32][VAD][hist0] [32][EV][hist75][0] [2][VAD][hist0] [64][EAD][hist75] [32][VE][hist100] [1][EV][1] [64][VAD][hist0] [128][EAD][hist0] [1][EV][2] [32][EAD][hist0] [128][VE][hist75] [32][EAD][hist75] [1][EV][0] [1][VAD] [8][VAD][hist75] [128][VAD][hist100] [1][EAD] [32][EAD][hist25] [128][VAD][hist0]", "startOffset": 275, "endOffset": 278}, {"referenceID": 0, "context": "(a) 0 20 40 60 80 100 120 140 Weight [64][VAD][hist100] [32][VAD][hist0] [32][EV][hist75][0] [2][VAD][hist0] [64][EAD][hist75] [32][VE][hist100] [1][EV][1] [64][VAD][hist0] [128][EAD][hist0] [1][EV][2] [32][EAD][hist0] [128][VE][hist75] [32][EAD][hist75] [1][EV][0] [1][VAD] [8][VAD][hist75] [128][VAD][hist100] [1][EAD] [32][EAD][hist25] [128][VAD][hist0]", "startOffset": 312, "endOffset": 315}, {"referenceID": 0, "context": "([1][SA]) nor the total volume ([1][VE]) is among the top-20 features, though some statistical VE features are.", "startOffset": 1, "endOffset": 4}, {"referenceID": 0, "context": "([1][SA]) nor the total volume ([1][VE]) is among the top-20 features, though some statistical VE features are.", "startOffset": 32, "endOffset": 35}], "year": 2017, "abstractText": "We introduce a library of geometric voxel features for CAD surface recognition/retrieval tasks. Our features include local versions of the intrinsic volumes (the usual 3D volume, surface area, integrated mean and Gaussian curvature) and a few closely related quantities. We also compute Haar wavelet and statistical distribution features by aggregating raw voxel features. We apply our features to object classification on the ESB data set and demonstrate accurate results with a small number of shallow decision trees.", "creator": "LaTeX with hyperref package"}}}