{"id": "1702.03197", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2017", "title": "Arabic Language Sentiment Analysis on Health Services", "abstract": "The social media network phenomenon leads to a massive amount of valuable data that is available online and easy to access. Many users share images, videos, comments, reviews, news and opinions on different social networks sites, with Twitter being one of the most popular ones. Data collected from Twitter is highly unstructured, and extracting useful information from tweets is a challenging task. Twitter has a huge number of Arabic users who mostly post and write their tweets using the Arabic language. While there has been a lot of research on sentiment analysis in English, the amount of researches and datasets in Arabic language is limited. This paper introduces an Arabic language dataset which is about opinions on health services and has been collected from Twitter. The paper will first detail the process of collecting the data from Twitter and also the process of filtering, pre-processing and annotating the Arabic text in order to build a big sentiment analysis dataset in Arabic. Several Machine Learning algorithms (Naive Bayes, Support Vector Machine and Logistic Regression) alongside Deep and Convolutional Neural Networks were utilized in our experiments of sentiment analysis on our health dataset.", "histories": [["v1", "Fri, 10 Feb 2017 14:59:14 GMT  (669kb)", "http://arxiv.org/abs/1702.03197v1", "Authors accepted version of submission for ASAR 2017"]], "COMMENTS": "Authors accepted version of submission for ASAR 2017", "reviews": [], "SUBJECTS": "cs.CL cs.NE cs.SI", "authors": ["abdulaziz m alayba", "vasile palade", "matthew england", "rahat iqbal"], "accepted": false, "id": "1702.03197"}, "pdf": {"name": "1702.03197.pdf", "metadata": {"source": "CRF", "title": "Arabic Language Sentiment Analysis on Health Services", "authors": ["Abdulaziz M. Alayba", "Vasile Palade", "Matthew England", "Rahat Iqbal"], "emails": ["Alaybaa@uni.coventry.ac.uk", "Vasile.Palade@coventry.ac.uk", "Matthew.England@coventry.ac.uk", "R.Iqbal@coventry.ac.uk"], "sections": [{"heading": null, "text": "to access. Many users share images, videos, comments, reviews,\nnews and opinions on different social networks sites, with Twitter\nbeing one of the most popular ones. Data collected from Twitter is\nhighly unstructured, and extracting useful information from\ntweets is a challenging task. Twitter has a huge number of Arabic\nusers who mostly post and write their tweets using the Arabic\nlanguage. While there has been a lot of research on sentiment\nanalysis in English, the amount of researches and datasets in\nArabic language is limited.\nThis paper introduces an Arabic language dataset which is about\nopinions on health services and has been collected from Twitter.\nThe paper will first detail the process of collecting the data from\nTwitter and also the process of filtering, pre-processing and\nannotating the Arabic text in order to build a big sentiment\nanalysis dataset in Arabic. Several Machine Learning algorithms\n(Na\u00efve Bayes, Support Vector Machine and Logistic Regression)\nalongside Deep and Convolutional Neural Networks were utilized\nin our experiments of sentiment analysis on our health dataset.\nKeywords \u2014 Sentiment Analysis, Machine Learning, Deep Neural Networks, Arabic Language.\nI. INTRODUCTION\nIn the past ten years, many social network sites (Facebook, Twitter, Instagram etc.) have increased the presence on the web. These sites have an enormous number of users who produce a massive amount of data which include texts, images, videos, etc. According to [1], the estimated amount of data on the web will be about 40 thousand Exabytes, or 40 trillion gigabytes, in 2020. Analysis of such date could be valuable. There are many different techniques for data analytics on data collected from the web, with sentiment analysis a prominent one. Sentiment analysis (see for example [2]) is the study of people\u2019s attitudes, emotions and options, and involves a combination of text mining and natural language processing. Sentiment analysis focuses on analyzing text messages that hold people opinions. Examples of topics for analysis include opinions on products, services, food, educations, etc. [3].\nTwitter is a popular social media platform where a huge number of tweets are shared and many tweets contain valuable data. As [4] reported: in March 2014, active Arabic users wrote over 17 million tweets per day. There are huge numbers of tweets generated every minute and many of them in the Arabic language. Topics about health services appear frequently on Twitter trends. The aims of this paper is to introduce a new Arabic data set on health services for opinion mining purposes. Also, to explain the process of collecting data from Twitter, preprocessing Arabic text and Annotating the data set. After collecting and annotating the dataset, some data processing tasks are applied, such as feature selections, machine learning algorithms and deep neural networks. The efficiency of these methods are assessed and compared.\nThis paper continues in Section II with a brief survey of work on sentiment analysis in English and the Arabic languages. Section III details the process of collection, pre-processing and filtering that went into creating our data set; and then the annotating procedure. The use of deep neural networks and other machine learning methods, including text feature selection, on the dataset is described in Section IV. Finally, conclusions and ideas for future work are discussed in Section V.\nII. RELATED WORK\nThere are many studies on sentiment analysis and a variety of approaches have been developed. English has the greatest number of sentiment analysis studies, while research is more limited for other languages including Arabic. This section discusses several papers in the field of sentiment analysis using either English or Arabic.\nSperiosu et al. [5] compared three different approaches, by using lexicon-based, maximum entropy classification and label propagation respectively. Several English datasets were used as training, evaluating and testing sets, and only positive and negative tweets were included in the datasets, whereas neutral tweets were eliminated. The experiment illustrated that the maximum entropy algorithm had a better result than the lexiconbased predictor and the accuracy improved for the test set of the polarity dataset from 58.1% to 62.9%. The label propagation obtained a better accuracy of 71.2%, by combining tweets and lexical features.\nKumar and Sebastian [6] presented a novel way to do the sentiment analysis on a Twitter data set in English, by extracting opinion words from the corpus. The types of words that were focused on, were adjectives, verbs and adverbs. Two methods were used: the corpus-based method for finding semantic of adjectives and the dictionary-based method for finding semantic of verbs and adverbs. After extracting opinion words, each word gets a score, whether it is positive, negative or neutral. The comprehensive tweet\u2019s score is measured by using individual score of each word using a linear equation.\nSaif et al. [7] applied semantic features to the analysis of the Twitter users\u2019 opinions. There are three different English data sets used: Stanford Twitter Sentiment (STS), Health Care Reform (HCR) and Obama-McCain Debate (OMD). Three approaches were used to add semantic features for sentiment classification purposes, which were replacement, augmentation and interpolation. Baselines features like unigrams, parts of speech (POS), sentiment-topic and semantic sentiment analysis were used in the experiments. The best result in the experiments came from using the interpolation approach, unigram features and na\u00efve Bayes classifier. The paper showed that large datasets are best analyzed by semantic methods, while sentiment-topic is the best method for small datasets or limited topics.\nShoukry and Rafea [8] addressed the Arabic sentence-level to perform sentiment analysis on 1000 tweets. Support Vector Machines (SVM) and Na\u00efve Bayes (NB) were used in the experiment together with unigram and bigram text feature extraction. There were no differences between the results using different text feature extractions, but there were variations on the accuracy results using different classifiers: SVM \u2248 72% and NB \u2248 65%.\nBen Salamah and Elkhlifi [9] collected about 340,000 Arabic tweets about debates in the Kuwait National Assembly. The data was classified into positive and negative classes using decision trees (J48, alternating decision tree and random tree) and SVMs. The average precision results of the methods was 76% and the average recall was 61%.\nAbdulla et al [10] created an Arabic dataset for sentiment analysis which contains 2000 tweets divided into positive, the first half, and negative, the second half. Two methods were applied to the dataset, which were corpus-based \u201cSupervised Learning\u201d and lexicon-based \u201cUnsupervised Learning\u201d. Four supervised machine learning algorithms were applied, i.e., SVM, NB, D-Tree and K-Nearest Neighbor. The SVM and NB obtained better results, around 80%. On the other hand, the lexicon-based approach indicates that with a large lexicon the accuracy results were improving. There were three different phases, phase I has 1000 words, phase II has 2500 words and phase III has 3500 words. The accuracy started from 16.5% in phase one then it reached at 48.8% in phase two and it achieved 58.6% in phase three.\nKim [11] utilized convolutional neural networks to classify sentences using seven different English data sets, with the Movie Reviews dataset (introduced in [12]) being one of them. The experiment model built on top of \u201cword2vec\u201d [13] and various model variations were used. The experiments achieved good results of classifying sentences from different data sets.\nIII. AN ARABC DATA SET ON HEALTH\nThe work described in this paper involved several steps, which are retrieving the data, filtering, pre-processing and annotating the data set, and finally applying some machine learning on the collected dataset. Collecting the data from Twitter using the Twitter API and defining keyword based queries related to health is the first step. The second step is a challenging one because the retrieved data has much noise and needs to be cleaned. Annotating the tweets in the data set to either positive of negative classes will occur after filtering it. After annotating the data set, several machine learning algorithms can be applied to the data set using different text features extractions. Figure I shows the workflow of this project."}, {"heading": "A. Data Collection", "text": "The data was collected from 01/02/2016 to 31/07/2016 via Twitter. The first approach was to retrieve tweets using some general words related to health, such as \u201c\u0649\u0641\u0634\u062a\u0633\u0645, Hospital\u201d , \u201c\u0641\u0635\u0648\u062a\u0633\u0645 , Clinic\u201d , \u201c\u0647\u062d\u0635 , Health\u201d, etc. However, the majority of tweets found this was were not useful because they do not express any opinions, which is the aim of the study. Alternatively, observing trending hashtags, which are the most popular topics in Twitter at a specific time with many users involved in, was more useful. Three topics regarding to health were raised as trending hashtags and many users shared their opinions about them. They were as follows:\n #\u0649\u0641\u0634\u062a\u0633\u0645_\u0642\u0644\u063a\u062a_\u0629\u062d\u0635\u0644\u0627\nThis topic is about closing a private hospital (Closing Hospital).\n #\u0629\u062d\u0635\u0644\u0627_\u062c\u0644\u0627\u0639\u064a_\u0646\u0645\nThe meaning of this topic is asking a question about who will resolve the health problems (Solving Health).\n # \u0629\u062d\u0635\u0644\u0627_\u0646\u064a\u0633\u062d\u062a_\u0631\u0638\u062a\u0646\u062a\u0646\nThis topic means that people are waiting for an improvement in the health services (Improving Health).\nIn addition to these topics, one topic was launched and asked users to post their opinions and experience about health services which was:\n #\u0629\u064a\u062d\u0635\u0644\u0627_\u062a\u0627\u0645\u062f\u062e\u0644\u0627\u0628_\u0643\u064a\u0623\u0631\nThis topic was launched especially for this study, which is about users\u2019 opinions regarding health services (Opinions about Health).\nThe number of retrieved tweets was massive (over 126 thousand) but it decreased to 2026 tweets after filtering and preprocessing. Table I shows the number of tweets of each topic before and after the pre-processing of the data."}, {"heading": "B. Data Pre-processing and Normalization", "text": "The number of collected tweets was sufficient to do the sentiment analysis experiment as it contains a variety of words and sentence structures. In contrast, the total number of tweets (126959 tweets) contained much noisy data and as the study focused on only positive or negative tweets, all noisy data was removed. The following points are examples of noisy data that were removed.\n1) Spam tweets which are tweets that contain advertisements or harmful links [14].\n2) Neutral tweets which do not have any opinions, such as news tweets.\n3) Retweeted tweets, which start by \u201cRT\u201d [15]. 4) Duplicated tweets, which were retrieved more than once.\nIn addition, as indicated in [15], some pre-processing steps\nwere undertaken to the remaining tweets by removing:\n1) Opinions unrelated to health. 2) Twitter users name which are like @user_name [15]. 3) URLs which started by http:// until the next space,\nwhich indicates the end of the URL [15].\n4) Some words like \u201cavailable\u201d, \u201cvia\u201d [15]. 5) Hashtags topics. 6) Punctuations [15].\nIn addition to these tasks, normalization of some words or\nletters was performed as summarized below:\n1) Removing Arabic short vowels (diacritics) \u201c  \u064d ,  \u064d ,  \u064d ,  \u064d ,  \u064d ,  \u064d ,  \u064d ,  \u064d \u201d [16]. 2) Removing the Tatweel character \u201c\u0640\u0640\u0640\u201d which does not affect the meaning of the word [16].\n3) Replacing the letter \u201c \u0629 \u201d to the letter \u201c \u0647 \u201d [16]. 4) Replacing the letters \u201c \u0622 \u060c \u0625 \u060c \u0623 \u201d to the letter \u201c \u0627 \u201d [16]. 5) Normalizing some words, especially words which\ncontain the letter \u201c Hamzah \u201d \u201c \u0626 \u060c \u0624 \u201d to one form\nbecause some users write it with \u201c Hamzah \u201d and other write it without it. For example the word \u201c \u060c \u0626\u0631\u0627\u0648\u0637\u0644\u0627\n\u064a\u0631\u0627\u0648\u0637\u0644\u0627 \u201d can be written in two ways by users, but the\nwords were normalized to one form which is \u201c\u0626\u0631\u0627\u0648\u0637\u0644\u0627\u201d\n6) Normalizing any word with repeated letters, such as \u201c \u0631\u064a\u064a\u064a\u064a\u064a\u064a\u064a\u064a\u064a\u0628\u0643 \u201d to be \u201c \u0631\u064a\u0628\u0643 \u201d [16].\n7) Normalizing some special letters \u201c \u06d2 , \u06aa \u201d, which are not Arabic letters, but they have the same shape of\nsome Arabic letter.\n8) Normalizing compound words using MS Excel by joining them by the character \u201c _ \u201d; such as some city\nnames, for example \u201c\u0647\u0646\u064a\u062f\u0645\u0644\u0627 \u0647\u0631\u0648\u0646\u0645\u0644\u0627\u201d which will be normalized to \u201c \u0647\u0646\u064a\u062f\u0645\u0644\u0627_\u0647\u0631\u0648\u0646\u0645\u0644\u0627 \u201d.\n9) Correcting words manually which were either missing some letters, replacing a letter by a wrong one, or\nwriting the word in a wrong form.\n10) Some Twitter users compress two words or more by ignoring the space between the words because of the\ncharacters limit on Twitter. These are normalized by\nmanually returning the spaces between words.\n11) Some users post their opinions in more than one tweet and the solution here was to combine them in one long\ntweet. After that, the length of combined tweet was\nreduced by removing unwanted words."}, {"heading": "C. Data Anotating", "text": "The data set has been annotated manually by three annotators and each tweet can be either positive or negative only. The reason of having three judges is to get three different opinions about each tweet, then calculating the majority vote of them (\u201cThe Mode\u201d). There are eight rows in Table II for eight different situations of the annotators\u2019 classification. Also, the reasons of having only two classes are the difficulty of rating the opinions, the need of many annotators and the lack of scaled words in the corpus such as \u201cvery\u201d in English language and \u201c\u0627\u062f\u062c\u201d in the Arabic language.\nTable II details the number of each different situation of the annotators\u2019 classification occurred in the dataset. For example, when all of them agree as positive or negative tweets, when two of them agree as positive and another one disagree and when two of them agree as negative and another one disagree. In addition to that, it shows the total number of positive and negative tweets.\nFrom Table II the accuracies of each annotator can be measured. The accuracy of Annotator 1 is 93%, the accuracy of Annotator 2 is 95% and the accuracy of Annotator 3 is 97%.\nFigure II shows the distributions of positive and negative tweets numbers per each annotator. It is clear that Annotators 2 and 3 have almost similar number of positive and negative tweets, but the Annotator 1 is slightly different. Overall, the data set is unbalanced, with the negative tweets more prevalent than the positive tweets.\nThe objective of this experiment is to investigate the efficiency of utilizing Deep Neural Networks and other\nMachine Learning algorithms on a newly developed Arabic\nHealth Services Data Set. [17] The efficiency of them can be\nmeasured by calculating the Accuracy of the classification task,\nwhich is defined as:\n\ud835\udc34\ud835\udc50\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc4e\ud835\udc50\ud835\udc66 = (\ud835\udc47\ud835\udc43+\ud835\udc47\ud835\udc41)\n(\ud835\udc47\ud835\udc43+\ud835\udc47\ud835\udc41+\ud835\udc39\ud835\udc43+\ud835\udc39\ud835\udc41) ,\nwhere (TP) is the number of true positives, (TN) is the number of true negatives, (FP) is the number of false positives and (FN)\nis the number of false negatives.\nA. Machine Learning Algorithms In this section of the experiment, a combination of \u201cUnigram\u201d and \u201cBigram\u201d techniques were used for text feature selection in this experiment. TF-IDF (Term Frequency and Inverse Document Frequency) [17] weighting words was used to weight each feature in the corpus and the maximum 1000 weighted features were fed to the machine learning algorithm. There are three machine learning algorithms that were used: Na\u00efve Bayes (NB), Logistic Regression (LR) and Support\nVector Machines (SVMs). [18] The NB algorithm used involved Multinomial Naive Bayes and Bernoulli Naive Bayes, and the SVMs used involved Support Vector Classification, Linear Support Vector Classification, Stochastic Gradient Descent and Nu-Support Vector Classification. The experiment had three phases by using different sizes for the training set and the testing set. In Phase I the training set was 60% of the data set and the testing set was 40% of the data set. In Phase II the testing set reduced to 30% and the training set was 70%. In Phase III the training set was increased 10% and the testing set was reduced 10%. Table III shows the results of all different classifiers in different phases using the previously explained text feature selection.\nB. Deep Neural Networks Algorithms Deep learning is a popular approach in computational modeling today [19]. The model consists of a big number of hidden layers and neurons to represent the data with different abstractions. It works efficiently and effectively with large datasets. Neural Networks with many hidden layers, Convolutional Neural Networks and some Recurrent Neural Networks are examples of this [20].\nIn this section of the experiment, Deep and Convolutional Neural Networks were used. The Deep Neural Network model had three hidden layers and each layer has 1500 neurons. The input features used were 741 words, which were based on their frequency between 5 and 100 times in the corpus where the output of the model is either positive or negative. The data set was divided into 80% for training and 20% for testing. Figure III shows the obtained accuracy results of the experiment using Deep Neural Network, which reached about 85% in 500 epochs. Table IV shows the confusion matrix of the Deep Neural Network experiment on the test set. Also, it details the numbers of actual and predicted classes.\nConvolutional Neural Networks (CNNs) were also used in the experiment. All the vocabulary in the corpus was trained using \u201cword2vec\u201d [13] to create the input vectors of the models. The sequence length of each vector was 52 because the longest sentence in the data set has 52 words. A (3, 4) sliding window were used to filter the size of the matrix and the number of epochs was 100. The data set was divided into 80% for training and 20% for testing. The accuracy obtained in this experiment was about 90%. Figure IV shows the accuracy results on 500 epochs by using a Convolutional Neural Network. Moreover, the confusion matrix was measured on the test set and it can be found in Table IV.\nThis paper introduces a new Arabic data set for sentiment analysis about health services. The paper also detailed the process of collecting Twitter tweets, the way of filtering, preprocessing Arabic text by removing unwanted data, removing some unrelated words and text and normalizing the text. Moreover, it explained the procedure of annotating the data set manually by three annotators. The initial experiments were conducted by utilizing Deep Neural Networks and several other Machine Learning algorithms. NB, LR, SVM, DNNs and CNNs were used and the accuracy in each experiment was recorded. The accuracy results were roughly between 85% and 91% and the best classifiers were SVM using Linear Support Vector Classification and Stochastic Gradient Descent. The SVM classifier accuracy is similar to the first annotator\u2019s accuracy.\nThere will be further studies and experiments on using different text features extraction and other Deep Neural Network and Recurrent Neural Network architectures in order to increase the accuracy of the results. In addition to this, the negation words in Arabic will be studied to increase the prediction performance and, as the data set is unbalanced, dealing with unbalanced data set techniques will be another topic for our future studies.\nVI. REFERENCES\n[1] J. Gantz and D. Reinsel, \u201cBig Data , Bigger Digital Shadows , and\nBiggest Growth in the Far East Executive Summary: A Universe of Opportunities and Challenges,\u201d Idc, vol. 2007, no. December 2012, pp. 1\u201316, 2012.\n[2] B. Liu, \u201cSentiment Analysis and Opinion Mining,\u201d Synth. Lect. Hum. Lang. Technol., vol. 5, no. 1, pp. 1\u2013167, May 2012. [3] B. Agarwal, N. Mittal, P. Bansal, and S. Garg, \u201cSentiment Analysis\nUsing Common-Sense and Context Information,\u201d Comput. Intell.\nNeurosci., vol. 2015, pp. 1\u20139, 2015. [4] Mohammad Bin Rashid Sschool of Government, \u201cThe Arab Social\nMedia Report.\u201d [Online]. Available: http://www.arabsocialmediareport.com/home/index.aspx. [Accessed: 02-Apr-2016].\n[5] M. Speriosu, N. Sudan, S. Upadhyay, and J. Baldridge, \u201cTwitter Polarity\nClassification with Label Propagation over Lexical Links and the Follower Graph,\u201d Proc. Conf. Empir. Methods Nat. Lang. Process., pp.\n53\u201356, 2011. [6] A. Kumar and T. M. Sebastian, \u201cSentiment Analysis on Twitter,\u201d IJCSI\nInt. J. Comput. Sci. Issues, vol. 9, no. 4, pp. 372\u2013378, 2012.\n[7] H. Saif, Y. He, and H. Alani, \u201cSemantic Sentiment Analysis of Twitter,\u201d in The Semantic Web \u2013 ISWC 2012, 2012, pp. 508\u2013524. [8] A. Shoukry and A. Rafea, \u201cSentence-level Arabic sentiment analysis,\u201d Collab. Technol. Syst. (CTS), 2012 Int. Conf., pp. 546\u2013550, 2012. [9] J. Ben Salamah and A. Elkhlifi, \u201cMicroblogging Opinion Mining\nApproach for Kuwaiti Dialect,\u201d Int. Conf. Comput. Technol. Inf. Manag.,\npp. 388\u2013396, 2014. [10] N. A. Abdulla, N. A. Ahmed, M. A. Shehab, and M. Al-Ayyoub, \u201cArabic\nsentiment analysis: Lexicon-based and corpus-based,\u201d in 2013 IEEE Jordan Conference on Applied Electrical Engineering and Computing Technologies (AEECT), 2013, pp. 1\u20136.\n[11] Y. Kim, \u201cConvolutional Neural Networks for Sentence Classification,\u201d\nProc. 2014 Conf. Empir. Methods Nat. Lang. Process. (EMNLP 2014), pp. 1746\u20131751, 2014.\n[12] B. Pang and L. Lee, \u201cSeeing stars: Exploiting class relationships for\nsentiment categorization with respect to rating scales,\u201d in Proceedings of the ACL, 2005.\n[13] T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean, \u201cDistributed\nRepresentations of Words and Phrases and their Compositionality,\u201d Proc. NIPS, pp. 1\u20139, 2013.\n[14] Twitter, \u201cReporting spam on Twitter,\u201d 2016. [Online]. Available: https://support.twitter.com/articles/64986. [Accessed: 17-May-2016]. [15] A. Pak and P. Paroubek, \u201cTwitter as a Corpus for Sentiment Analysis\nand Opinion Mining.,\u201d Lrec, pp. 1320\u20131326, 2010.\n[16] S. Ahmed, M. Pasquier, and G. Qadah, \u201cKey issues in conducting sentiment analysis on Arabic social media text,\u201d in 2013 9th\nInternational Conference on Innovations in Information Technology\n(IIT), 2013, pp. 72\u201377. [17] H. Manning, C., Raghavan, P. and Schu\u0308tze, Introduction to information\nretrieval, 1st Ed. New York: Cambridge University Press, 2008.\n[18] scikit-learn developers, \u201cscikit-learn,\u201d 2010. . [19] Y. LeCun, Y. Bengio, G. Hinton, L. Y., B. Y., and H. G., \u201cDeep\nlearning,\u201d Nature, vol. 521, no. 7553, pp. 436\u2013444, 2015.\n[20] J. Schmidhuber, \u201cDeep Learning in neural networks: An overview,\u201d Neural Networks, vol. 61, pp. 85\u2013117, 2015."}], "references": [{"title": "Big Data , Bigger Digital Shadows , and Biggest Growth in the Far East Executive Summary: A Universe of Opportunities and Challenges", "author": ["J. Gantz", "D. Reinsel"], "venue": "Idc, vol. 2007, no. December 2012, pp. 1\u201316, 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Sentiment Analysis and Opinion Mining", "author": ["B. Liu"], "venue": "Synth. Lect. Hum. Lang. Technol., vol. 5, no. 1, pp. 1\u2013167, May 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Sentiment Analysis Using Common-Sense and Context Information", "author": ["B. Agarwal", "N. Mittal", "P. Bansal", "S. Garg"], "venue": "Comput. Intell. Neurosci., vol. 2015, pp. 1\u20139, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Sschool of Government, \u201cThe Arab Social Media Report.", "author": ["Mohammad Bin Rashid"], "venue": "[Online]. Available: http://www.arabsocialmediareport.com/home/index.aspx. [Accessed:", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Twitter Polarity Classification with Label Propagation over Lexical Links and the Follower Graph", "author": ["M. Speriosu", "N. Sudan", "S. Upadhyay", "J. Baldridge"], "venue": "Proc. Conf. Empir. Methods Nat. Lang. Process., pp. 53\u201356, 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Sentiment Analysis on Twitter", "author": ["A. Kumar", "T.M. Sebastian"], "venue": "IJCSI Int. J. Comput. Sci. Issues, vol. 9, no. 4, pp. 372\u2013378, 2012.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Semantic Sentiment Analysis of Twitter", "author": ["H. Saif", "Y. He", "H. Alani"], "venue": "The Semantic Web \u2013 ISWC 2012, 2012, pp. 508\u2013524.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Sentence-level Arabic sentiment analysis", "author": ["A. Shoukry", "A. Rafea"], "venue": "Collab. Technol. Syst. (CTS), 2012 Int. Conf., pp. 546\u2013550, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Microblogging Opinion Mining Approach for Kuwaiti Dialect", "author": ["J. Ben Salamah", "A. Elkhlifi"], "venue": "Int. Conf. Comput. Technol. Inf. Manag., pp. 388\u2013396, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Arabic sentiment analysis: Lexicon-based and corpus-based", "author": ["N.A. Abdulla", "N.A. Ahmed", "M.A. Shehab", "M. Al-Ayyoub"], "venue": "2013 IEEE Jordan Conference on Applied Electrical Engineering and Computing Technologies (AEECT), 2013, pp. 1\u20136.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Y. Kim"], "venue": "Proc. 2014 Conf. Empir. Methods Nat. Lang. Process. (EMNLP 2014), pp. 1746\u20131751, 2014.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales", "author": ["B. Pang", "L. Lee"], "venue": "Proceedings of the ACL, 2005.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G. Corrado", "J. Dean"], "venue": "Proc. NIPS, pp. 1\u20139, 2013.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Reporting spam on Twitter", "author": ["Twitter"], "venue": "2016. [Online]. Available: https://support.twitter.com/articles/64986. [Accessed: 17-May-2016].", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Twitter as a Corpus for Sentiment Analysis and Opinion Mining", "author": ["A. Pak", "P. Paroubek"], "venue": "Lrec, pp. 1320\u20131326, 2010.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Key issues in conducting sentiment analysis on Arabic social media text", "author": ["S. Ahmed", "M. Pasquier", "G. Qadah"], "venue": "2013 9th International Conference on Innovations in Information Technology (IIT), 2013, pp. 72\u201377.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Introduction to information retrieval, 1st Ed", "author": ["C.H. Manning", "P. Raghavan", "Sch\u00fctze"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "scikit-learn", "author": ["scikit-learn developers"], "venue": "2010. .", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "L.Y.G. Hinton", "B.Y.", "H.G."], "venue": "Nature, vol. 521, no. 7553, pp. 436\u2013444, 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep Learning in neural networks: An overview", "author": ["J. Schmidhuber"], "venue": "Neural Networks, vol. 61, pp. 85\u2013117, 2015.  40%  60%  80%  100% 0 100 200 300 400 500  A  C  C  U  R  A  C  Y P  E  R  C  E  N  T  A  G  E S NUMBER OF EPOCH The Accuracy for 100 Epochs (Arabic Health Dataset) - CNN", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "According to [1], the estimated amount of data on the web will be about 40 thousand Exabytes, or 40 trillion gigabytes, in 2020.", "startOffset": 13, "endOffset": 16}, {"referenceID": 1, "context": "Sentiment analysis (see for example [2]) is the study of people\u2019s attitudes, emotions and options, and involves a combination of text mining and natural language processing.", "startOffset": 36, "endOffset": 39}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "As [4] reported: in March 2014, active Arabic users wrote over 17 million tweets per day.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "[5] compared three different approaches, by using lexicon-based, maximum entropy classification and label propagation respectively.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "Kumar and Sebastian [6] presented a novel way to do the sentiment analysis on a Twitter data set in English, by extracting opinion words from the corpus.", "startOffset": 20, "endOffset": 23}, {"referenceID": 6, "context": "[7] applied semantic features to the analysis of the Twitter users\u2019 opinions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Shoukry and Rafea [8] addressed the Arabic sentence-level to perform sentiment analysis on 1000 tweets.", "startOffset": 18, "endOffset": 21}, {"referenceID": 8, "context": "Ben Salamah and Elkhlifi [9] collected about 340,000 Arabic tweets about debates in the Kuwait National Assembly.", "startOffset": 25, "endOffset": 28}, {"referenceID": 9, "context": "Abdulla et al [10] created an Arabic dataset for sentiment analysis which contains 2000 tweets divided into positive, the first half, and negative, the second half.", "startOffset": 14, "endOffset": 18}, {"referenceID": 10, "context": "Kim [11] utilized convolutional neural networks to classify sentences using seven different English data sets, with the Movie Reviews dataset (introduced in [12]) being one of them.", "startOffset": 4, "endOffset": 8}, {"referenceID": 11, "context": "Kim [11] utilized convolutional neural networks to classify sentences using seven different English data sets, with the Movie Reviews dataset (introduced in [12]) being one of them.", "startOffset": 157, "endOffset": 161}, {"referenceID": 12, "context": "The experiment model built on top of \u201cword2vec\u201d [13] and various model variations were used.", "startOffset": 48, "endOffset": 52}, {"referenceID": 13, "context": "1) Spam tweets which are tweets that contain advertisements or harmful links [14].", "startOffset": 77, "endOffset": 81}, {"referenceID": 14, "context": "3) Retweeted tweets, which start by \u201cRT\u201d [15].", "startOffset": 41, "endOffset": 45}, {"referenceID": 14, "context": "In addition, as indicated in [15], some pre-processing steps were undertaken to the remaining tweets by removing:", "startOffset": 29, "endOffset": 33}, {"referenceID": 14, "context": "2) Twitter users name which are like @user_name [15].", "startOffset": 48, "endOffset": 52}, {"referenceID": 14, "context": "3) URLs which started by http:// until the next space, which indicates the end of the URL [15].", "startOffset": 90, "endOffset": 94}, {"referenceID": 14, "context": "4) Some words like \u201cavailable\u201d, \u201cvia\u201d [15].", "startOffset": 38, "endOffset": 42}, {"referenceID": 14, "context": "6) Punctuations [15].", "startOffset": 16, "endOffset": 20}, {"referenceID": 15, "context": "In addition to these tasks, normalization of some words or letters was performed as summarized below: 1) Removing Arabic short vowels (diacritics) \u201c  \u064d ,  \u064d ,  \u064d ,  \u064d ,  \u064d ,  \u064d ,  \u064d ,  \u064d \u201d [16].", "startOffset": 189, "endOffset": 193}, {"referenceID": 15, "context": "2) Removing the Tatweel character \u201c\u0640\u0640\u0640\u201d which does not affect the meaning of the word [16].", "startOffset": 86, "endOffset": 90}, {"referenceID": 15, "context": "3) Replacing the letter \u201c  \u0629 \u201d to the letter \u201c \u0647 \u201d [16].", "startOffset": 51, "endOffset": 55}, {"referenceID": 15, "context": "4) Replacing the letters \u201c \u0622 \u060c \u0625 \u060c \u0623 \u201d to the letter \u201c \u0627 \u201d [16].", "startOffset": 59, "endOffset": 63}, {"referenceID": 15, "context": "For example the word \u201c \u060c \u0626\u0631\u0627\u0648\u0637\u0644\u0627 \u064a\u0631\u0627\u0648\u0637\u0644\u0627 \u201d can be written in two ways by users, but the words were normalized to one form which is \u201c\u0626\u0631\u0627\u0648\u0637\u0644\u0627\u201d 6) Normalizing any word with repeated letters, such as \u201c \u0631\u064a\u064a\u064a\u064a\u064a\u064a\u064a\u064a\u064a\u0628\u0643 \u201d to be \u201c \u0631\u064a\u0628\u0643 \u201d [16].", "startOffset": 228, "endOffset": 232}, {"referenceID": 16, "context": "[17] The efficiency of them can be measured by calculating the Accuracy of the classification task, which is defined as:", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "TF-IDF (Term Frequency and Inverse Document Frequency) [17] weighting words was used to weight each feature in the corpus and the maximum 1000 weighted features were fed to the machine learning algorithm.", "startOffset": 55, "endOffset": 59}, {"referenceID": 17, "context": "[18] The NB algorithm used involved Multinomial Naive Bayes and Bernoulli Naive Bayes, and the SVMs used involved Support Vector Classification, Linear Support Vector Classification, Stochastic Gradient Descent and Nu-Support Vector Classification.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "Deep Neural Networks Algorithms Deep learning is a popular approach in computational modeling today [19].", "startOffset": 100, "endOffset": 104}, {"referenceID": 19, "context": "Neural Networks with many hidden layers, Convolutional Neural Networks and some Recurrent Neural Networks are examples of this [20].", "startOffset": 127, "endOffset": 131}, {"referenceID": 12, "context": "All the vocabulary in the corpus was trained using \u201cword2vec\u201d [13] to create the input vectors of the models.", "startOffset": 62, "endOffset": 66}], "year": 2017, "abstractText": "The social media network phenomenon leads to a massive amount of valuable data that is available online and easy to access. Many users share images, videos, comments, reviews, news and opinions on different social networks sites, with Twitter being one of the most popular ones. Data collected from Twitter is highly unstructured, and extracting useful information from tweets is a challenging task. Twitter has a huge number of Arabic users who mostly post and write their tweets using the Arabic language. While there has been a lot of research on sentiment analysis in English, the amount of researches and datasets in Arabic language is limited. This paper introduces an Arabic language dataset which is about opinions on health services and has been collected from Twitter. The paper will first detail the process of collecting the data from Twitter and also the process of filtering, pre-processing and annotating the Arabic text in order to build a big sentiment analysis dataset in Arabic. Several Machine Learning algorithms (Na\u00efve Bayes, Support Vector Machine and Logistic Regression) alongside Deep and Convolutional Neural Networks were utilized in our experiments of sentiment analysis on our health dataset.", "creator": "Microsoft\u00ae Word 2013"}}}