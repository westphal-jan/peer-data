{"id": "1702.04594", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Feb-2017", "title": "Local Search for Minimum Weight Dominating Set with Two-Level Configuration Checking and Frequency Based Scoring Function", "abstract": "The Minimum Weight Dominating Set (MWDS) problem is an important generalization of the Minimum Dominating Set (MDS) problem with extensive applications. This paper proposes a new local search algorithm for the MWDS problem, which is based on two new ideas. The first idea is a heuristic called two-level configuration checking (CC2), which is a new variant of a recent powerful configuration checking strategy (CC) for effectively avoiding the recent search paths. The second idea is a novel scoring function based on the frequency of being uncovered of vertices. Our algorithm is called CC2FS, according to the names of the two ideas. The experimental results show that, CC2FS performs much better than some state-of-the-art algorithms in terms of solution quality on a broad range of MWDS benchmarks.", "histories": [["v1", "Wed, 15 Feb 2017 13:22:57 GMT  (414kb,D)", "http://arxiv.org/abs/1702.04594v1", "29 pages, 1 figure"]], "COMMENTS": "29 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["yiyuan wang", "shaowei cai", "minghao yin"], "accepted": false, "id": "1702.04594"}, "pdf": {"name": "1702.04594.pdf", "metadata": {"source": "CRF", "title": "Local Search for Minimum Weight Dominating Set with Two-Level Configuration Checking and Frequency Based Scoring Function", "authors": ["Yiyuan Wang", "Shaowei Cai", "Minghao Yin"], "emails": ["YIYUANWANGJLU@126.COM", "CAISW@IOS.AC.CN", "YMH@NENU.EDU.CN"], "sections": [{"heading": null, "text": "the Minimum Dominating Set (MDS) problem with extensive applications. This paper proposes a new local search algorithm for the MWDS problem, which is based on two new ideas. The first idea is a heuristic called two-level configuration checking (CC2), which is a new variant of a recent powerful configuration checking strategy (CC) for effectively avoiding the recent search paths. The second idea is a novel scoring function based on the frequency of being uncovered of vertices. Our algorithm is called CC2FS, according to the names of the two ideas. The experimental results show that, CC2FS performs much better than some state-of-the-art algorithms in terms of solution quality on a broad range of MWDS benchmarks."}, {"heading": "1. Introduction", "text": "Given an undirected graph G, a dominating set D is a subset of vertices such that every vertex not in D is adjacent to at least one member of D. The Minimum Dominating Set (MDS) problem consists in identifying the smallest dominating set in a graph. The Minimum Weight Dominating Set (MWDS) problem is a generalized version of MDS. In the MWDS problem, each vertex is associated with a positive value as its weight, and the task is to find a dominating set that minimizes the total weight of the vertices in it.\nThe MWDS problem has played a prominent role in various real-world domains such as social networks, communication networks, and industrial applications. For example, Houmaidi et al. make the first known attempt to solve the sparse wavelength converters placement problem, where the MWDS problem is used to reduce the number of full wavelength converters in the deployment of wavelength division multiplexing all-optical networks (El Houmaidi & Bassiouni, 2003). In the work of Subhadrabandhu, Sarkar, and Anjum (2004), the MWDS problem is used in determining the nodes in an adhoc network where the intrusion detection software for squandering detection needs to be installed. Shen et al. propose a new method for multi-document by encoding this problem to the MWDS problem (Shen & Li, 2010). Also, the problem of gateways placement, which places a minimum number of gateways such that quality-of-service requirements are satisfied, can\nar X\niv :1\n70 2.\n04 59\n4v 1\n[ cs\n.A I]\n1 5\nbe encoded into the MWDS problem and effectively solved by MWDS algorithms (Aoun, Boutaba, Iraqi, & Kenward, 2006). An important problem in Web databases is to find an optimal query selection plan, which has been proved to be equivalent to finding a MWDS of the corresponding database graph (Wu, Wen, Liu, & Ma, 2006).\nThe problems MDS and MWDS have been proved to be NP-hard (Gary & Johnson, 1979; Cockayne, Dawes, & Hedetniemi, 1980), which means that, unless P=NP, there is no polynomial-time algorithm for these problems. Several approximation algorithms have been introduced to solve the MWDS problem. An early constant-factor approximation algorithm for the MWDS problem in unit disk graphs is presented (Amb\u00fchl, Erlebach, Mihal\u00e1k, & Nunkesser, 2006). A new centralized and distributed approximation algorithm for the MWDS problem is proposed with application to form a backbone for adhoc wireless networks (Wang, Wang, & Li, 2006). Dai and Yu propose a (5+\u03b5)approximation algorithm to form a MWDS for UDG (Dai & Yu, 2009). A (4+\u03b5)-approximation dynamic programming algorithm for the MWDS problem is offered, which is the best approximation factor for unit disk graph without smooth weights (Zou, Wang, Xu, Li, Du, Wan, & Wu, 2011). The first polynomial time approximation scheme for MWDS with smooth weights on unit disk graphs is introduced (Zhu, Wang, Shan, Wang, & Wu, 2012), which achieves a (1+\u03b5)-approximation ratio, for any \u03b5>0.\nNevertheless, as is usual, approximation algorithms with guaranteed approximation ratios do not have good performance in practice. Most practical algorithms for solving the MWDS problem are heuristic algorithms. In the work of Jovanovic, Tuba, and Simian (2010), an ant colony optimization (ACO) algorithm for MWDS is proposed, which takes into account the weights of vertices being covered. An algorithm called ACO-PP-LS uses an ant colony optimization method by considering the pheromone deposit on the node and a preprocessing step immediately after pheromone initialization (Potluri & Singh, 2013). A hybrid steady-state genetic algorithm HGA is proposed by using binary tournament selection method, fitness-based crossover and a simple bit-flip mutation scheme (Potluri & Singh, 2013). In the work of Nitash and Singh (2014), a swarm intelligence algorithm called ABC uses an artificial bee colony method to solve MWDS. A hybrid approach EA/G-IR is presented, which combines an evolutionary algorithm with guided mutation and an improvement operator (Chaurasia & Singh, 2015). In the work of Bouamama and Blum (2016), a randomized population-based iterated greedy approach R-PBIG is proposed to tackle MWDS, which maintains a population of solutions and applies the basic steps of an iterated greedy algorithm to each member of the population. However, the efficiency of existing heuristic algorithm are still not satisfactory, especially for hard and large-scaled instances (as will be shown in our experiments). The reason may be that the heuristic functions used in previous algorithms do not have enough information during the search procedure, and the cycling search problems can not be overcome by most algorithms as well.\nIn this paper, we develop a novel local search algorithm for the MWDS problem based on two new ideas. The first idea is a new variant of the Configuration Checking (CC) strategy. Initially proposed in the work of Cai, Su, and Sattar (2011), the CC strategy aims to reduce the cycling phenomenon (i.e., revisiting candidate solutions which have been recently visited) in local search, by considering the circumstance of the solution components, which is formally defined as the configuration. The CC strategy has been successfully applied to a number of well-known combinatorial optimization problems, including Vertex Cover (Cai et al., 2011; Cai, Su, Luo, & Sattar, 2013; Fang, Chu, Qiao, Feng, & Xu, 2014; Li, Hu, Zhang, & Yin, 2016), Set Covering (Wang, Ouyang, Zhang, & Yin, 2015; Wang, Yin, Ouyang, & Zhang, 2016), Clique problem (Wang, Cai, & Yin, 2016),\nBoolean Satisfiability (Cai & Su, 2012, 2013; Abram\u00e9, Habet, & Toumi, 2014; Luo, Cai, Su, & Wu, 2015a) and Maximum Satisfiability (Luo, Cai, Wu, Jie, & Su, 2015b; Cai, Jie, & Su, 2015), as well as application problems such as Golomb Rulers optimization (Polash, Newton, & Sattar, 2015). It is straightforward to devise the CC strategy for MWDS, which works as follows. For a vertex, it is forbidden to be added into the candidate solution if its configuration has not been changed after the last time it was removed from the candidate solution. However, when applied to the MWDS problem, the CC strategy does not lead to good performance. The problem may be that the original CC strategy is too strict for solving MWDS, i.e. forbidding too many vertices to be selected, which limits the search area of the algorithm. In this work, we propose a variant of the CC strategy based on a new definition of configuration. In this strategy, the configuration of a vertex v refers to its two-level neighborhood, which is the union of the neighborhood N(v) and the neighborhood of each vertex in N(v). This new strategy is thus called two-level configuration checking (abbreviated as CC2).\nThe second idea is a frequency based scoring function for vertices, according to which the score of each vertex is calculated. Local search algorithms for the MWDS problem maintain a candidate solution, which is a set of vertices selected for dominating. Then the algorithms will use a scoring functions to decide which vertices will be selected to update the candidate solution, where the scores of vertices indicate the benefit (which may be positive or negative) produced by adding (or removing) a vertex to the candidate solution. Four greedy algorithms for the MWDS problem are developed by using four different scoring functions (Potluri & Singh, 2013). After that, some scoring functions have been proposed recently (Potluri & Singh, 2013; Nitash & Singh, 2014; Chaurasia & Singh, 2015; Bouamama & Blum, 2016). These functions are mostly designed based on the information of the graph itself, for example vertex degree and vertex uncovered neighbour weight. An augmented cost function is designed, whose costs are either predetermined or evaluated during search (Voudouris & Tsang, 2003). In this work, we also introduce a scoring function based on dynamic information of vertices, i.e., the frequency of being uncovered by the candidate solution. This scoring function exploits the information of the search process and that of the candidate solution. Moreover, different from the augmented cost function, our function does not have parameters and thus can be easily adapted to solve other optimization problems.\nBy incorporating these two ideas, we develop a local search algorithm for the MWDS problem termed CC2FS (as its two main ideas are CC2 and Frequency-based Score). We carry out experiments to compare CC2FS with five state-of-the-art MWDS algorithms on benchmarks in the literatures including unit disk graphs and random generated instances, as well as two classical graphs benchmarks namely BHOSLIB (Xu, Boussemart, Hemery, & Lecoutre, 2007) and DIMACS (Johnson & Trick, 1996), and a broad range of real world massive graphs with millions of vertices and dozens of millions of edges (Rossi & Ahmed, 2015). Experimental results show that CC2FS significantly outperforms previous algorithms and improves the best known solution quality for some difficult instances.\nIn the next section, we give some necessary background knowledge. After that, we propose a new configuration checking strategy CC2, a frequency based scoring function, and a vertex selection method. Then, we propose a novel local search algorithm CC2FS, followed with experimental evaluations and analyses. Finally, we give concluding remarks."}, {"heading": "2. Preliminaries", "text": "An undirected graph G = (V,E) comprises a vertex set V = {v1, v2, . . . , vn} of n vertices together with a set E = {e1, e2, . . . , em} of m edges, where each edge e = {v, u} connects two vertices u and v, and these two vertices are called the endpoints of edge e.\nThe distance between two vertices u and v, denoted by dist(u, v), is the number of edges in a shortest path from u to v, and dist(u, u) = 0 particularly. For a vertex v, we define its ith level neighborhood as Ni(v) = {u|dist(u, v) = i}, and we denote Nk(v) = \u22c3k i=1Ni(v). The first-level neighborhood N1(v) is usually denoted as N(v) as well, and we denote Ni[v] = Ni(v)\u222a{v}. Also, we define the closed neighborhood of a vertex set S, N [S] = \u22c3 v\u2208S N [v].\nA dominating set of G is a subset D \u2286 V such that every vertex in G either belongs to D or is adjacent to a vertex in D. The Minimum Dominating Set (MDS) problem calls for finding a dominating set of minimum cardinality. In the Minimum Weight Dominating Set (MWDS) problem, each vertex v is associated with a positive weight w(v), and the task is to find a dominating set D which minimizes the total weight of vertices in D (i.e., min \u2211 v\u2208D w(v))."}, {"heading": "2.1 Local Search for MWDS", "text": "Local search algorithms perform the search on problem\u2019s corresponding search space. The search space is implicitly defined by the way that the algorithm transforms a candidate solution into another. For the MWDS problem, local search algorithms usually maintain a candidate solution S \u2286 V during the search. A vertex v is covered by S if v \u2208 N [S], and is uncovered otherwise. Also, the state of a vertex v is denoted by sv \u2208 {1, 0}, such that sv=1 means a vertex v is covered by a candidate solution S, and sv=0 means it is uncovered. For a vertex, its age is defined as the number of steps since the last time it changed its state (being added or removed w.r.t. the maintained candidate solution S), and when we say the oldest vertex, we refer to the one with the minimum age value.\nAlgorithm 1: The general framework of a local search algorithm 1 S := InitFunction() and S\u2217 := S; 2 while not reach terminate condition do 3 if S is better than S\u2217 then 4 S\u2217 := S;\n5 S := MoveNeighbourPoisition(S);\n6 return S\u2217;\nWe first present a general framework of local search in Algorithm 1. As can be seen in this framework, the algorithm consists of two stage: the construction stage and the local search stage. At first, an initial dominating set is constructed by the greedy initialization process. After that, the solution is modified iteratively in the local search procedure, trying to find better solutions. In the local search stage, if a (redundant) dominating set is found, then the algorithm removes a vertex from S and begins to search for a dominating set with smaller weight, until some stop criterion is reached. When the current candidate solution is not a dominating set, the move to a neighboring candidate solution consists of two phases: (1) removing a vertex from S and (2) adding some vertices into S until S becomes a dominating set."}, {"heading": "2.2 Configuration Checking", "text": "Local search suffers from the cycling phenomenon, i.e., revisiting a candidate solution that has been recently visited. This phenomenon wastes much computation time of a local search algorithm and more importantly prevents it from escaping from local optima.\nTo overcome the cycling problem, a number of methods have been proposed. The random walk strategy (Selman, Kautz, & Cohen, 1994) picks the solution component randomly with a certain probability and greedily makes the best possible move with another probability. Random restarting (Houck, Joines, & Kay, 1996) is used to restart the search from another starting point of search space. Also, allowing non-improving moves with a probability, as in the Simulating Annealing algorithm, can provide more diversification to the search. Glover proposes the tabu method (Glover, 1989), which has been widely used in local search algorithms (Di Gaspero & Schaerf, 2007; Escobar, Linfati, Toth, & Baldoquin, 2014; Ahonen, de Alvarenga, & Amaral, 2014). To prevent the local search to immediately return to a previously visited candidate solution, the tabu method forbids reversing the recent changes, where the strength of forbidding is controlled by a parameter called tabu tenure. Besides these general methods dealing with the cycling phenomenon, there are also heuristics specialized for problems, such as the promising decreasing variable exploitation for the Boolean Satisfiability (SAT) problem (Li & Huang, 2005).\nRecently, an interesting strategy called Configuration Checking (CC) (Cai et al., 2011) was proposed to handle the cycling problem in local search. Also, CC does not have instance-dependent parameters and is easy to use. The relationship between the tabu and CC strategy has been thoroughly discussed (Cai & Su, 2013). If the tabu tenure is set to 1, it can be proved that given a variable, if it is forbidden to pick by the tabu method, it is also forbidden by the CC strategy, while its reverse is not necessarily true.\nThe MWDS problem is in some sense similar to the vertex cover problem in that their tasks are both to find a set of vertices. Thus, we can easily devise a CC strategy for the MWDS problem, following the one for the vertex cover problem (Cai et al., 2011). An important concept of the CC strategy is the configuration of vertices. Typically, the configuration of a vertex v refers to a vector consisting of the states of all v\u2019s neighboring vertices. The CC strategy for the MWDS problem can be described as following: given the candidate solution S, for a vertex v /\u2208 S, if its configuration has not changed since v\u2019s last removal from S, which means the circumstance of v has not changed, then v should not be added back to S.\nAn implementation of the CC strategy is to apply a Boolean array confchange for vertices, where confchange(v)=1 means that v is allowed to be added to S, and confchange(v)=0 on the contrary. In the beginning, for each vertex v, the value of confchange(v) is initialized as 1; afterwards, when removing vertex x, confchange(x) is set to 0; whenever a vertex v changes its state, for each vertex u \u2208 N(v), confchange(u) is set to 1."}, {"heading": "3. Two-Level Configuration Checking", "text": "Since the CC strategy has been successfully applied to solve several NP-hard combinatorial optimization problems, a natural question arises whether this strategy can also be applied to MWDS. Unfortunately, a direct application of the original CC strategy in local search for the MWDS problem does not result in an effective algorithm, and has poor performance on a large portion of the benchmark instances.\nWe observe that, the original CC strategy would mislead the search by forbidding too many candidate vertices. In CC strategy, only the first-level neighborhood of a vertex is considered to avoid cycling, and the configuration of a vertex is considered changed only if at least one of its neighboring vertices changed its state. However, some analysis suggests that not only the first-level neighborhood but the second-level neighborhood are related to the cycling phenomenon and should be considered in the configuration of a vertex.\nInspired by this consideration, we propose a new variant of CC for MWDS, which is referred to as two-level configuration checking (CC2 for short), by redefining the configuration of vertices. In the CC2 strategy, we consider not only the first-level neighborhood (N1) but also the second-level neighborhood (N2).\n3.1 Definition and Implementation of the CC2 Strategy\nIn this subsection, we define the CC2 strategy and present an implementation for it. We start from the formal definition of the configuration of a vertex v.\nDefinition 1 Given an undirected graph G = (V,E) and S the candidate solution, the configuration of a vertex v \u2208 V is a vector consisting of state of all vertices in N2(v).\nBased on the above definition, we can define an important vertex in local search as follows.\nDefinition 2 Given an undirected graph G = (V,E) and S the candidate solution, for a vertex v /\u2208 S, v is configuration changed if at least one vertex in N2(v) has changed its state since the last time v is removed from S.\nIn the CC2 strategy, only the configuration changed vertices are allowed to be added to the candidate solution S.\nWe implement CC2 with a Boolean array ConfChange whose size equals the number of vertices in the input graph. For a vertex v, the value of ConfChange[v] is an indicator \u2014 ConfChange[v]=1 means v is a configuration changed vertex and is allowed to be added to the candidate solution S; otherwise, ConfChange[v]=0 and it cannot be added to S. During the search procedure, the ConfChange array is maintained as follows.\nCC2-RULE1. At the start of search process, for each vertex v, ConfChange[v] is initialized as 1.\nCC2-RULE2. When removing a vertex v from the candidate solution S, ConfChange[v] is set to 0, and for each vertex u \u2208 N2(v), ConfChange[u] is set to 1.\nCC2-RULE3. When adding a vertex v into the candidate solution S, for each vertex u \u2208 N2(v), ConfChange[u] is set to 1.\nTo understand RULE2 and RULE3, we note that if u \u2208 N2(v), then v \u2208 N2(u). Thus, if a vertex v changes its state (i.e., either being removed or added w.r.t. the candidate solution), the Configuration of any vertex u \u2208 N2(v) is changed.\n3.2 Relationship between CC and CC2 Strategies\nConfiguration checking is a general idea, and both the original CC strategy and the CC2 strategy are evolved from this idea. Both strategies prefer to pick configuration changed vertices. The difference between these two strategies lies on the concept of configuration changed vertices.\nIn the following, we compare these two kinds of configuration changed vertices. Let us use CCV to denote the set of configuration changed vertices according to the original CC strategy, and use CCV 2 to denote the set of configuration changed vertices according to the CC2 strategy.\nProposition 1 Given an undirected graph G = (V,E) and S the maintained candidate solution, assuming that in some step t we have CCV = CCV 2, then we can conclude that in the next step, for any v \u2208 V , if v \u2208 CCV , then v \u2208 CCV 2.\nProof. Let us use v\u2217 to denote the vertex selected to change the state in step t of the local search stage for MWDS. In step t + 1, for any vertex v, we have two cases. 1) v was in CCV in step t. Since in step t we have CCV = CCV 2, thus we also have v \u2208 CCV 2; 2) v was not in CCV in step t. If v \u2208 CCV in step t + 1, according to the definition of CCV, this can happen only when v \u2208 N [v\u2217]. Because N [v\u2217] \u2282 N2[v\u2217], we also have v \u2208 N2[v\u2217], and thus v \u2208 CCV 2 in step t + 1.\nThe above proposition gives an insight that the size of CCV 2 is larger than that of CCV . It is easy to see that the reverse of Proposition 1 is not necessarily true. So, we can easily deduce the following conclusion.\nRemark 1 In most conditions, the CCV 2 set is a superset of CCV set. For an algorithm, in each step, there are more candidate vertices which could be added into the candidate solution under the CC2 strategy than under the CC strategy. For this reason, we have more options and thus can explore more search spaces by choosing vertex from CCV 2 than from CCV ."}, {"heading": "4. A Novel Scoring Function for MWDS", "text": "Local search algorithms decide which vertex to be selected according to their scores. Thus, the scoring function for vertices plays a critical role in the algorithm, which has direct impact on the intensification and diversification of the search."}, {"heading": "4.1 The Previous Scoring Function for MWDS", "text": "Recently, four scoring functions are presented to solve MWDS (Potluri & Singh, 2013). We list the definitions of these score as below.\nscore1(u) = d(u)\nw(u)\nscore2(u) = W (u) w(u) score3(u) = W (u)\u2212 w(u) score4(u) = d(u)\u00d7W (u) w(u) where u /\u2208 S, d(u) is the number of uncovered (non-dominated) neighbours of a given vertex u\nand W (u) is the sum of the weights of the uncovered neighbours of u. The results of this experiment (Potluri & Singh, 2013) show that the first, the second and the\nlast heuristic functions result in a similar performance with no clear pattern of a particular greedy heuristic being better for general graph instances. In contrast, the third greedy heuristic clearly results in the poorest performance.\nThe weight of vertices being covered in score2 is taken into account (Jovanovic et al., 2010). In ACO-PP-LS (Potluri & Singh, 2013), when a newly obtained solution may not be a dominating set, it is repaired by iteratively adding vertices from some vertices not in this obtained solution according\nto two strategies. With a certain probability, the first strategy is used, otherwise the second strategy is used. Specially, the first strategy is greedy and adds a vertex by using score2, while the second strategy adds a vertex into the candidate solution randomly. ABC (Nitash & Singh, 2014) prunes some redundant vertices according to the greedy strategy score1. In EA/G-IR (Chaurasia & Singh, 2015), there are two modifications in score2. The first modification uses the closed neighborhood N1[u] instead of N1(u) when computing score2(u). The second modification is a tie-breaking rule. Actually, when there are more than one vertex satisfying score2, then the next vertex to be added is selected by this tie-breaking rule. score1(u) is also computed by the closed neighborhood N1[u] and then the next vertex to be added is determined with this improved score1(u). In case there is still more than one vertices satisfying score1, then the next vertex to be added is selected arbitrarily from these vertices. In R-PBIG (Bouamama & Blum, 2016), each vertex is rated based on greedy functions score1 or score2 and how to select which greedy function is based on a random number."}, {"heading": "4.2 The Frequency based Scoring Function", "text": "In this paper, we introduce a novel scoring function by taking into account of the vertices\u2019 frequency, which can be viewed as some kind of dynamic information indicating the accumulative effectiveness that the search has on the vertex. Intuitively, if a vertex is usually uncovered, then we should encourage the algorithm to select a vertex to make it covered.\nIn detail, in a graph, each vertex v \u2208 V has an additional property, frequency, denoted by freq[v]. The freq of each vertex is initialized to 1. After each iteration of local search, the freq value of each uncovered vertex is increased by one. During the search process, we apply the freq of vertex to decide which vertex to be added or removed. Based on this consideration, we propose a new score function, which is formally defined as below.\nDefinition 3 For a graph G = (V,E), and a candidate solution S, the frequency based scoring function denoted by scoref , is a function such that\nscoref (u) =  1 w(u) \u00d7 \u2211 v\u2208C1 freq[v], u /\u2208 S,\n\u2212 1 w(u) \u00d7 \u2211 v\u2208C2 freq[v], u \u2208 S, (1)\nwhere C1=N [u] \\N [S] and C2=N [u] \\N [S \\ {u}].\nRemark that, in the above definition, C1 is indeed the set of uncovered vertices that would become covered by adding u into S and C2 is the set of covered vertices that would become uncovered by removing u from S."}, {"heading": "5. The Selection Vertex Strategy", "text": "During the search process, for preventing visiting previous candidate solutions, we not only use the CC2 strategy in the adding process, but also use the forbidding list in the removing process. The forbid_list used here is a tabu list which keeps track of the vertices added in the last step, and these vertices are prevented from being removed within the tabu tenure. In this sense, this frequency based\nprohibition mechanism can be viewed as an instantiation of the longer term memory tabu search, and the main difference is that our method also consider the information from the CC2 strategy.\nThe algorithm picks a vertex to add or remove, using the frequency based scoring function and the above two strategies. Firstly, we give two rules for removing vertices.\nREMOVE-RULE1. Removing one vertex v, which has the highest value of scoref (v), breaking ties by selecting the oldest one.\nREMOVE-RULE2. Removing one vertex v, which is not in forbid_list and has the highest value of scoref (v), breaking ties by selecting the oldest one.\nWhen the algorithm finds a solution, it removes one vertex from the solution and continues to search for a solution with smaller weight. In this process, we use REMOVE-RULE1 to pick the vertex. During the search for a solution, the algorithm exchanges some vertices, i.e., removing one vertex from the candidate solution and then iteratively adding vertices into the candidate solution. In this case, we select one vertex to remove according to REMOVE-RULE2.\nThe rule to select the adding vertices is given below. ADD-RULE. Adding one vertex v with ConfChange[v] 6= 0, which has the greatest value\nscoref (v), breaking ties by selecting the oldest one. When adding one vertex into the candidate solution, we try to make the resulting candidate\nsolution\u2019s cost (i.e., the total weight of uncovered vertices) as small as possible. When adding one configuration changed vertex with the highest value scoref (v), breaking ties by preferring the oldest vertex.\n6. CC2FS Algorithm\nBased on CC2 and the frequency based scoring function, we develop a local search algorithm named CC2FS. During the process of local search, we maintain a set from which the vertex to be added is chosen. The set for finding a vertex to be removed from the candidate solution is simply S.\nCCV 2 = {v|ConfChange[v] = 1, v /\u2208 S} The pseudo code of CC2FS is shown in Algorithm 2. At first, CC2FS initializes ConfChange,\nforbid_list and the frequency and scoref of vertices. Then it gets an initial candidate solution S greedily by iteratively adding the vertex that covers the most remaining uncovered vertices until S covers all vertices. At the end of initialization, the best solution S\u2217 is updated by S.\nAfter initialization, the main loop from lines 3 to 16 begins by checking whether S is a solution (i.e., covers all vertices). When the algorithm finds a better solution, S\u2217 is updated. Then one vertex with the highest scoref value in S is selected to be removed, breaking tie in favor of the oldest one. Finally, the values of ConfChange are updated by CC2-RULE2.\nIf there are uncovered vertices, CC2FS first picks one vertex to remove from S with the highest value scoref , breaking tie in favor of the oldest one. Note that when choosing a vertex to remove, we do not consider those vertices in forbid_list, as they are forbidden to be removed by the forbidden list. After removing a vertex, CC2FS updates the ConfChange values according to CC2-RULE2, and clear forbid_list. Additional, since the tabu tenure is set to be 1, the forbid_list shall be cleared to allow previous forbidden vertices to be added in subsequent loop.\nAfter the removing process, CC2FS iteratively adds one vertex into S until it covers all vertices, i.e. the candidate solution is a dominating set. CC2FS first selects v \u2208 CCV 2 with the greatest scoref (v), breaking ties in favor of the oldest one. When the picked uncovered vertex is added into the candidate solution, the ConfChange values are updated according to CC2-RULE3 and\nAlgorithm 2: CC2FS (G, cutoff) Input: a weighted graph G = (V,E,W ), the cutoff time Output: dominating set of G 1 initialize ConfChange, forbid_list, and the freq and scoref of of vertices; 2 S := InitGreedyConstruction() and S\u2217 := S; 3 while elapsed time < cutoff do 4 if there are no uncovered vertices then 5 if w(S) < w(S\u2217) then S\u2217 := S; 6 v := a vertex in S with the highest value scoref (v), breaking ties in the oldest one; 7 S := S \\ {v} and update ConfChange according to CC2-RULE2; 8 continue;\n9 v := a vertex in S with the highest value scoref (v) and v /\u2208 forbid_list, breaking ties in the oldest one; 10 S := S \\ {v} and update ConfChange according to CC2-RULE2; 11 forbid_list := \u2205; 12 while there are uncovered vertices do 13 v := a vertex in CCV 2 with the highest value scoref (v), breaking ties in the oldest one; 14 S := S \u222a {v} and update ConfChange according to CC2-RULE3; 15 forbid_list := forbid_list \u222a {v}; 16 freq[v] := freq[v] + 1, for v /\u2208 N [S];\n17 return S\u2217;\nthis added vertex is added into the forbid_list. After adding an uncovered vertex each time, the frequency of uncovered vertices is increased by one. When the time limit reaches, the best solution will be returned.\nNow we shall analyse the time complexity of CC2FS. For each iteration:\n\u2022 The algorithm first dedicates to find a dominate set (Line 4-8). The worst time complexity for finding the removal vertex vi is O(|S|) (Line 6), where |S| denotes the size of the candidate solution S. Then, the algorithm updates the value of the related scoref as well as ConfChange (Line 10) and the worst time complexity is O(\u2206(G)2), where \u2206(G) = max{|N [v]||v \u2208 V,G = (V,E)}.\n\u2022 Otherwise, the algorithm first decides which vertex vj should be deleted and the worst time complexity is also O(|S|+ \u2206(G)2) (Line 9-11). Let L denote the number of uncovered vertices of S (Line 12-16), and under the worst condition the step of the adding procedure is L = |N [vj ]|. During this adding procedure, the worst time complexity per step for adding one vertex is O((|V |\u2212 |S|)) (Line 13). When updating the related scoref and ConfChange (Line 14), the worst time complexity per step is also O(\u2206(G)2). Then, the worst time complexity for the whole adding procedure (Line 12-16) is O(|N [vj ]|(|V | \u2212 |S|+ \u2206(G)2)).\nTherefore, each iteration of the local search stage of CC2FS has a time complexity of O(|S| + \u2206(G)2+|N [vj ]|(|V |\u2212|S|+\u2206(G)2)) = O(\u2206(G)2+\u2206(G)(|V |\u2212|S|+\u2206(G)2)) = O(max{\u2206(G)|V |, \u2206(G)3})."}, {"heading": "7. Empirical Results", "text": "We compare CC2FS with five competitors on a broad range of benchmarks, with respect to both solution quality and run time. The run time is measured in CPU seconds. Firstly, we introduce the test instances, five competitors and the experimental preliminaries of our experiments.\nThere are eight benchmarks selected in our experiment, including T1, T2, UDG, two weighted versions of DIMACS, two weighted versions of BHOSLIB, as well as many real world massive graphs. We introduce the benchmarks in the following.\n\u2022 T1 benchmark (Jovanovic et al., 2010) (530 instances): all instances are connected undirected graphs with the vertex weights randomly distributed in the interval [20,70].\n\u2022 T2 benchmark (Jovanovic et al., 2010) (530 instances): the weight of all vertices in all instances is assigned as be a function based on the degree d(v) of the vertex v which is randomly set to in the interval [1, d(v)2].\n\u2022 UDG benchmark (Jovanovic et al., 2010) (120 instances): these instances are generated by using the topology generator (Michele, 2007). Transmission range of all vertices in UDG instances is fixed to either 150 or 200 units.\n\u2022 BHOSLIB benchmark with weighting function w(vi)=(i mod 200)+1 (41 instances): BHOSLIB instances (Xu, Boussemart, Hemery, & Lecoutre, 2005) were originally unweighted and generated randomly based on the model RB (Xu & Li, 2000, 2006; Xu et al., 2007).\n\u2022 BHOSLIB benchmark with weighting function w(vi)=1 (41 instances): this benchmark is to test algorithms on uniform weight BHOSLIB graphs.\n\u2022 DIMACS benchmark with weighting function w(vi)=(i mod 200)+1 (54 instances): DIMACS is the most frequently used for comparison and evaluation of graph algorithms. More specifically, the size of the DIMACS instances ranges from less than 150 vertices and 300 edges up to more than 4,000 vertices and 7,900,000 edges. We use the complement graphs of some instances, including the c-fat.clq and p-hat.clq set, to test the efficiency of our algorithm. The original DIMACS graphs are unweighted.\n\u2022 DIMACS benchmark with weighting function w(vi)=1 (54 instances): this benchmark is to test algorithms on uniform weighted DIMACS graphs.\n\u2022 Massive graph benchmark with weighting function w(vi)=(i mod 200)+1 (74 instances): these were transformed from the unweighted graphs in Network Data Repository online (Rossi & Ahmed, 2015).\nFor T1, T2, UDG instances, we note that ten instances are generated for each combination of number of nodes and transmission range. As for the weighting function: for the ith vertex vi, w(vi)=(i mod 200)+1, it was proposed in the work of Pullan (2008) and has been widely used in the literature for algorithms for solving problems on vertex weighted graphs.\nWe compare CC2FS with HGA (Potluri & Singh, 2013), ACO-PP-LS (Potluri & Singh, 2013), ABC (Nitash & Singh, 2014), EA/G-IR (Chaurasia & Singh, 2015), and R-PBIG (Bouamama &\nBlum, 2016). Among them, R-PBIG and ACO-PP-LS are the best available algorithms for solving MWDS. We have the source code of ACO-PP-LS, so in this paper we use its code to test all benchmarks to get better solution values than those values (Potluri & Singh, 2013).\nWe implement CC2FS in C++ and compile it by g++ with the -O2 option. All the experiments are run on Ubuntu Linux, with 3.1 GHZ CPU and 8GB memory. For T1, T2, and UDG instances, CC2FS and ACO-PP-LS are performed once, where one run is terminated upon reaching a given time limit. Among this, the parameter time limit is set to 50 seconds when the number of vertices is less than 500, otherwise the time limit is set to 1000 seconds. We report the real time RTime of ACO-PP-LS and CC2FS, while we also give the finial execution time FTime of EA/G-IR and R-PBIG. The real time is a time when ACO-PP-LS and CC2FS obtain the best solution respectively. The MEAN contains the average solution values for each of the ten instances of graphs of a particular size.\nFor DIMACS, BHOSLIB, and massive graphs instances, our algorithm and ACO-PP-LS are performed 10 independent runs with different random seeds, where each run is terminated upon reaching a given time limit 1000 seconds. The MIN and AVG column contains the minimal and average solution values for each instance by performing 10 runs with different random seeds. The SD column contains the standard deviation for each instance by performing 10 runs. The bold value indicates the best solution value among the different algorithms compared.\nNote that for DIMACS, BHOSLIB, and massive graphs benchmarks, we only compare our algorithm with ACO-PP-LS. This is because, 1) as we mentioned, seen from the literatures, RPBIG and ACO-PP-LS are the best available algorithms for solving MWDS; 2) we have the source code of ACO-PP-LS, while the source code of R-PBIG is not available to us."}, {"heading": "7.1 Results on T1 and T2 Benchmarks", "text": "The performance results of previous algorithms on the T1 benchmark are displayed in Table 1. More importantly, this table also summarizes the experimental results on the first benchmark for our algorithm.\nAmong previous algorithms, for most instances, R-PBIG and ACO-PP-LS can find better solutions than HGA, ABC and EA/G-IR, with only a few exceptions.\nFor our algorithm, we show the minimum solution value and the run time. As is clear from the Table 1, CC2FS shows significant superiority on the T1 benchmark, except v50e750. By comparing these algorithms, we can easily conclude that CC2FS outperforms other algorithms.\nThe experimental results on the T2 benchmark are presented in Table 2. The quality of the solutions found by CC2FS is always much smaller than those found by other algorithms on all instances with 2 exceptions, i.e. v250e250 and v800e10000."}, {"heading": "7.2 Results on UDG Benchmark", "text": "Table 3 shows the comparative results on the UDG benchmark. For these instances, the solution value obtained by EA/G-IR and ACO-PP-LS almost matches CC2FS, expert for one instance V1000U150. But, the real run time of all instances solved by CC2FS is always less than 0.2 seconds and thus CC2FS solves faster than EA/G-IR and ACO-PP-LS.\nObserved from Table 1, 2 and 3, our algorithm uses less time to get better values, while the run time of ACO-PP-LS grows quickly with increasing the number of vertices. Specially, for some\nbig graphs, such as v1000e1000 and V1000U200, the run time of our algorithm is two orders of magnitudes less than of ACO-PP-LS."}, {"heading": "7.3 Results on BHOSLIB Benchmarks", "text": "Tables 4 and 5 compare CC2FS with ACO-PP-LS on the two weighted BHOSLIB benchmarks, one of which adopts the weighting function w(vi)=(i mod 200)+1 (Table 4), while the other adopts the weighting function w(vi)=1 (Tables 5). We compare the number of optimal solutions found by the two algorithms. Once again, CC2FS dramatically outperforms its competitors ACO-PP-LS. All instances of this benchmark could be solved by our algorithm more quickly than ACO-PP-LS. More importantly, our algorithm could find better solution values."}, {"heading": "7.4 Results on DIMACS Benchmarks", "text": "The experimental results on the two weighted DIMACS benchmarks are presented in Tables 6 and 7. It is encouraging to see the performance of CC2FS remains surprisingly good on these instances, where ACO-PP-LS shows very poor performance. Despite the performance advantage of CC2FS, there are some exceptions in the weighting function of w(vi)=(i mod 200)+1, like gen200_p0.9_44 and C500.9. For the weighting function w(vi)=1, in the Table 7, our algorithms has a significant improvement than ACO-PP-LS in terms of real run time and best solution value. Given the good performance of CC2FS on the DIMACS benchmark with large vertices, we are confident it could be able to solve larger graph instances."}, {"heading": "7.5 Results on Massive Graph Benchmark", "text": "For some instances, ACO-PP-LS fails to find a dominating set within time limit, then we use \u201cn/a\u201d to mark it. From the results in Table 8 and Table 9, we observe that there are 58 graphs for which\nACO-PP-LS fails to provide a dominating set, which indicates the effectiveness of our algorithm. In the rest instances (16 ones), CC2FS finds better dominating sets than ACO-PP-LS. Moreover, CC2FS could find the good dominating sets of all given massive graphs (74 ones)."}, {"heading": "7.6 Comparison Frequency based Scoring Function with Previous Scoring Functions", "text": "To study the effectiveness of frequency based scoring function, we use four scoring functions (Potluri & Singh, 2013) instead of frequency based scoring function and design four alternative algorithms: CC2+S1 which uses score1 to select vertices, CC2+S2 based on score2, CC2+S3 with score3, as well as CC2+S4 by score4.\nIn Table 10, we can easily observe that CC2FS consistently obtains better solutions than other competitors for all selected instances. It demonstrates that our proposed frequency based scoring function is suitable for this problem and helps CC2FS find better solutions than previous scoring functions."}, {"heading": "7.7 Comparison with the Original Configuration Checking and the Breaking Strategy", "text": "To study the effectiveness of the CC2 strategy, we compare CC2FS with its alternative version named CCFS, which uses one-level neighborhood based configuration of vertices.\nWe also compare CC2FS with another version CC2FS+BREAK, which differs from CC2FS on the stopping criterion of adding vertices in each step: it stops the adding process when either the candidate solution becomes a dominating set, or the cost of the candidate solution is larger than that of the best found solution. The pseudo code of CC2FS+BREAK is introduced in Algorithm 3. Although CC2FS is similar to CC2FS+BREAK, there are two differences between CC2FS and CC2FS+BREAK.\nAlgorithm 3: CC2FS+BREAK (G, cutoff) Input: a weighted graph G = (V,E,W ), the cutoff time Output: dominating set of G 1 initialize ConfChange and forbid_list; 2 initialize the freq and scoref of of vertices; 3 S := InitGreedyConstruction(); 4 S\u2217 := S; 5 while elapsed time < cutoff do 6 if there are no uncovered vertices then 7 S\u2217 := S; 8 v := a vertex in S with the highest value scoref (v), breaking ties in the oldest one; 9 S := S \\ {v};\n10 update ConfChange according to CC2-RULE2; 11 continue;\n12 v := a vertex in S with the highest value scoref (v) and v /\u2208 forbid_list, breaking ties in the oldest one; 13 S := S \\ {v}; 14 update ConfChange according to CC2-RULE2; 15 forbid_list := \u2205; 16 while there are no uncovered vertices do 17 v := a vertex in CCV 2 with the highest value scoref (v) and ConfChange[v]6=false, breaking ties in the oldest one; 18 if w(S) + w(v) \u2265 w(S\u2217) then break; 19 S := S \u222a {v}; 20 update ConfChange according to CC2-RULE3; 21 forbid_list := forbid_list \u222a {v}; 22 freq[v] := freq[v] + 1, for v /\u2208 N [S];\n23 return S\u2217;\n\u2022 (1) When each iteration begins, both algorithms check whether there are no uncovered vertices (line 6). If this is the case, CC2FS+BREAK finds a better solution and updates S\u2217 by the candidate solution S, while CC2FS cannot ensure that S is better than S\u2217 and this has to be checked.\n\u2022 (2) In the inner loop (lines 12-16 in CC2FS, lines 16-22 in CC2FS+BREAK), CC2FS+BREAK turns to the next iteration when there are no uncovered vertices (line 16) or w(S) + w(v) \u2265 w(S\u2217) (line 18), while our algorithm CC2FS can only continue to the next iteration under meeting the first condition.\nThe results are summarized in Table 11, which shows that the CC2FS finds better solutions than CCFS on all benchmarks. This indicates that the new configuration checking CC2 plays a key role in the CC2FS algorithm. Compared with CC2FS+BREAK, CC2FS could get better or the same quality solutions. This indicates that the break strategy is not suitable for this problem. Furthermore, the visualized comparisons of CC2FS, CC2FS+BREAK, and CCFS can be seen by box-plot in Figure 1, which shows the distribution of the dominating set values of massive graphs."}, {"heading": "8. Summary and Future Work", "text": "This paper presented a local search algorithm called CC2FS for solving the minimum weight dominating set (MWDS) problem. We proposed a new configuration checking strategy namely CC2\nbased on the two-level neighborhood of vertices to remember the relevant information of removed and added vertices and prevent visiting the recent paths. Moreover, we introduced a new frequency based scoring function for solving MWDS. The experimental results showed that CC2FS performs essentially better than state of the art algorithms on almost all instances in terms of solution quality and run time.\nAs for future work, we consider to further improve the CC2FS algorithm by integrating some other ideas like strong configuration checking (Wang et al., 2016). Also we would like to test our algorithms on other instances including larger graphs. Envisioned research directions about the proposed strategies include applying the new score functions to other local search algorithms, and trying to find some other important properties and scoring functions of local search algorithms."}, {"heading": "Acknowledgments", "text": "The authors of this paper wish to extend their sincere gratitude to all the anonymous reviewers for their efforts. Shaowei Cai is also supported by Youth Innovation Promotion Association, Chinese Academy of Sciences. For any theoretical and experimental problem arising from this paper, please correspondence to Professor Minghao Yin. This work was supported in part by NSFC (under Grant Nos. 61370156, 61503074, 61502464, 61402070, 61403077, and 61403076), China National 973 program 2014CB340301 and the Program for New Century Excellent Talents in University (NCET13-0724)."}], "references": [{"title": "Improving configuration checking for satisfiable random k-SAT instances", "author": ["A. Abram\u00e9", "D. Habet", "D. Toumi"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "Abram\u00e9 et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Abram\u00e9 et al\\.", "year": 2014}, {"title": "Simulated annealing and tabu search approaches for the corridor allocation problem", "author": ["H. Ahonen", "A.G. de Alvarenga", "A. Amaral"], "venue": "European Journal of Operational Research,", "citeRegEx": "Ahonen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ahonen et al\\.", "year": 2014}, {"title": "Constant-factor approximation for minimum-weight (connected) dominating sets in unit disk graphs. In Approximation, Randomization, and Combinatorial Optimization", "author": ["C. Amb\u00fchl", "T. Erlebach", "M. Mihal\u00e1k", "M. Nunkesser"], "venue": "Algorithms and Techniques,", "citeRegEx": "Amb\u00fchl et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Amb\u00fchl et al\\.", "year": 2006}, {"title": "Gateway placement optimization in wireless mesh networks with QoS constraints", "author": ["B. Aoun", "R. Boutaba", "Y. Iraqi", "G. Kenward"], "venue": "Selected Areas in Communications, IEEE Journal on,", "citeRegEx": "Aoun et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Aoun et al\\.", "year": 2006}, {"title": "A hybrid algorithmic model for the minimum weight dominating set problem", "author": ["S. Bouamama", "C. Blum"], "venue": "Simulation Modelling Practice and Theory,", "citeRegEx": "Bouamama and Blum,? \\Q2016\\E", "shortCiteRegEx": "Bouamama and Blum", "year": 2016}, {"title": "An effective variable selection heuristic in SLS for weighted Max-2-SAT", "author": ["S. Cai", "Z. Jie", "K. Su"], "venue": "Journal of Heuristics,", "citeRegEx": "Cai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2015}, {"title": "Configuration checking with aspiration in local search for sat", "author": ["S. Cai", "K. Su"], "venue": "In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Cai and Su,? \\Q2012\\E", "shortCiteRegEx": "Cai and Su", "year": 2012}, {"title": "Local search for boolean satisfiability with configuration checking and subscore", "author": ["S. Cai", "K. Su"], "venue": "Artificial Intelligence,", "citeRegEx": "Cai and Su,? \\Q2013\\E", "shortCiteRegEx": "Cai and Su", "year": 2013}, {"title": "NuMVC: An efficient local search algorithm for minimum vertex cover", "author": ["S. Cai", "K. Su", "C. Luo", "A. Sattar"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Cai et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2013}, {"title": "Local search with edge weighting and configuration checking heuristics for minimum vertex cover", "author": ["S. Cai", "K. Su", "A. Sattar"], "venue": "Artificial Intelligence,", "citeRegEx": "Cai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2011}, {"title": "A hybrid evolutionary algorithm with guided mutation for minimum weight dominating set", "author": ["S.N. Chaurasia", "A. Singh"], "venue": "Applied Intelligence,", "citeRegEx": "Chaurasia and Singh,? \\Q2015\\E", "shortCiteRegEx": "Chaurasia and Singh", "year": 2015}, {"title": "A 5+\u03b5-approximation algorithm for minimum weighted dominating set in unit disk graph", "author": ["D. Dai", "C. Yu"], "venue": "Theoretical Computer Science,", "citeRegEx": "Dai and Yu,? \\Q2009\\E", "shortCiteRegEx": "Dai and Yu", "year": 2009}, {"title": "A composite-neighborhood tabu search approach to the traveling tournament problem", "author": ["L. Di Gaspero", "A. Schaerf"], "venue": "Journal of Heuristics,", "citeRegEx": "Gaspero and Schaerf,? \\Q2007\\E", "shortCiteRegEx": "Gaspero and Schaerf", "year": 2007}, {"title": "k-weighted minimum dominating sets for sparse wavelength converters placement under nonuniform traffic", "author": ["M. El Houmaidi", "M.A. Bassiouni"], "venue": "In Modeling, Analysis and Simulation of Computer Telecommunications Systems,", "citeRegEx": "Houmaidi and Bassiouni,? \\Q2003\\E", "shortCiteRegEx": "Houmaidi and Bassiouni", "year": 2003}, {"title": "A hybrid granular tabu search algorithm for the multi-depot vehicle routing problem", "author": ["J.W. Escobar", "R. Linfati", "P. Toth", "M.G. Baldoquin"], "venue": "Journal of Heuristics,", "citeRegEx": "Escobar et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Escobar et al\\.", "year": 2014}, {"title": "Combining edge weight and vertex weight for minimum vertex cover problem", "author": ["Z. Fang", "Y. Chu", "K. Qiao", "X. Feng", "K. Xu"], "venue": "In International Workshop on Frontiers in Algorithmics,", "citeRegEx": "Fang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fang et al\\.", "year": 2014}, {"title": "Computers and Intractability: A Guide to the Theory of NP-completeness", "author": ["M.R. Gary", "D.S. Johnson"], "venue": null, "citeRegEx": "Gary and Johnson,? \\Q1979\\E", "shortCiteRegEx": "Gary and Johnson", "year": 1979}, {"title": "Tabu search-part i", "author": ["F. Glover"], "venue": "ORSA Journal on computing, 1(3), 190\u2013206.", "citeRegEx": "Glover,? 1989", "shortCiteRegEx": "Glover", "year": 1989}, {"title": "Comparison of genetic algorithms, random restart and two-opt switching for solving large location-allocation problems", "author": ["C.R. Houck", "J.A. Joines", "M.G. Kay"], "venue": "Computers & Operations Research,", "citeRegEx": "Houck et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Houck et al\\.", "year": 1996}, {"title": "Cliques, coloring, and satisfiability: second DIMACS implementation challenge", "author": ["D.S. Johnson", "M.A. Trick"], "venue": "October 11-13,", "citeRegEx": "Johnson and Trick,? \\Q1996\\E", "shortCiteRegEx": "Johnson and Trick", "year": 1996}, {"title": "Ant colony optimization applied to minimum weight dominating set problem", "author": ["R. Jovanovic", "M. Tuba", "D. Simian"], "venue": "In Proceedings of the 12th WSEAS international conference on Automatic control, modelling & simulation,", "citeRegEx": "Jovanovic et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jovanovic et al\\.", "year": 2010}, {"title": "Diversification and determinism in local search for satisfiability", "author": ["C.M. Li", "W.Q. Huang"], "venue": "In International Conference on Theory and Applications of Satisfiability Testing,", "citeRegEx": "Li and Huang,? \\Q2005\\E", "shortCiteRegEx": "Li and Huang", "year": 2005}, {"title": "An efficient local search framework for the minimum weighted vertex cover problem", "author": ["R. Li", "S. Hu", "H. Zhang", "M. Yin"], "venue": "Information Sciences,", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Clause states based configuration checking in local search for satisfiability", "author": ["C. Luo", "S. Cai", "K. Su", "W. Wu"], "venue": "Cybernetics, IEEE Transactions on,", "citeRegEx": "Luo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Luo et al\\.", "year": 2015}, {"title": "CCLS: An efficient local search algorithm for weighted maximum satisfiability", "author": ["C. Luo", "S. Cai", "W. Wu", "Z. Jie", "K. Su"], "venue": "IEEE Trans. Computers,", "citeRegEx": "Luo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Luo et al\\.", "year": 2015}, {"title": "The clustering simulation framework: a simple manual", "author": ["M. Michele"], "venue": "http://www.michelemastrogiovanni.net/software/download/README.pdf.", "citeRegEx": "Michele,? 2007", "shortCiteRegEx": "Michele", "year": 2007}, {"title": "An artificial bee colony algorithm for minimum weight dominating set", "author": ["C. Nitash", "A. Singh"], "venue": "In Swarm Intelligence (SIS),", "citeRegEx": "Nitash and Singh,? \\Q2014\\E", "shortCiteRegEx": "Nitash and Singh", "year": 2014}, {"title": "Constraint-based local search for golomb rulers", "author": ["M.A. Polash", "M.H. Newton", "A. Sattar"], "venue": "In International Conference on AI and OR Techniques in Constriant Programming for Combinatorial Optimization Problems,", "citeRegEx": "Polash et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Polash et al\\.", "year": 2015}, {"title": "Hybrid metaheuristic algorithms for minimum weight dominating set", "author": ["A. Potluri", "A. Singh"], "venue": "Applied Soft Computing,", "citeRegEx": "Potluri and Singh,? \\Q2013\\E", "shortCiteRegEx": "Potluri and Singh", "year": 2013}, {"title": "Approximating the maximum vertex/edge weighted clique using local search", "author": ["W. Pullan"], "venue": "Journal of Heuristics, 14(2), 117\u2013134.", "citeRegEx": "Pullan,? 2008", "shortCiteRegEx": "Pullan", "year": 2008}, {"title": "The network data repository with interactive graph analytics and visualization", "author": ["R. Rossi", "N. Ahmed"], "venue": "In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Rossi and Ahmed,? \\Q2015\\E", "shortCiteRegEx": "Rossi and Ahmed", "year": 2015}, {"title": "Noise strategies for improving local search", "author": ["B. Selman", "H.A. Kautz", "B. Cohen"], "venue": "In Proceedings of the 12th National Conference on Artificial Intelligence,", "citeRegEx": "Selman et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Selman et al\\.", "year": 1994}, {"title": "Multi-document summarization via the minimum dominating set", "author": ["C. Shen", "T. Li"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics,", "citeRegEx": "Shen and Li,? \\Q2010\\E", "shortCiteRegEx": "Shen and Li", "year": 2010}, {"title": "Efficacy of misuse detection in ad hoc networks", "author": ["D. Subhadrabandhu", "S. Sarkar", "F. Anjum"], "venue": "In Sensor and Ad Hoc Communications and Networks,", "citeRegEx": "Subhadrabandhu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Subhadrabandhu et al\\.", "year": 2004}, {"title": "Guided local search", "author": ["C. Voudouris", "E.P. Tsang"], "venue": "In Handbook of metaheuristics,", "citeRegEx": "Voudouris and Tsang,? \\Q2003\\E", "shortCiteRegEx": "Voudouris and Tsang", "year": 2003}, {"title": "Two efficient local search algorithms for maximum weight clique problem", "author": ["Y. Wang", "S. Cai", "M. Yin"], "venue": "In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "A novel local search for unicost set covering problem using hyperedge configuration checking and weight diversity", "author": ["Y. Wang", "D. Ouyang", "L. Zhang", "M. Yin"], "venue": "SCIENCE CHINA Information Sciences,", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "A novel local search algorithm with configuration checking and scoring mechanism for the set k-covering problem", "author": ["Y. Wang", "M. Yin", "D. Ouyang", "L. Zhang"], "venue": "International Transactions in Operational Research,", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Efficient distributed low-cost backbone formation for wireless networks", "author": ["Y. Wang", "W. Wang", "Li", "X.-Y"], "venue": "Parallel and Distributed Systems, IEEE Transactions on,", "citeRegEx": "Wang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2006}, {"title": "Query selection techniques for efficient crawling of structured web sources", "author": ["P. Wu", "Wen", "J.-R", "H. Liu", "Ma", "W.-Y"], "venue": "In 22nd International Conference on Data Engineering", "citeRegEx": "Wu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2006}, {"title": "A simple model to generate hard satisfiable instances", "author": ["K. Xu", "F. Boussemart", "F. Hemery", "C. Lecoutre"], "venue": "In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence,", "citeRegEx": "Xu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2005}, {"title": "Random constraint satisfaction: Easy generation of hard (satisfiable) instances", "author": ["K. Xu", "F. Boussemart", "F. Hemery", "C. Lecoutre"], "venue": "Artificial Intelligence,", "citeRegEx": "Xu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2007}, {"title": "Exact phase transitions in random constraint satisfaction problems", "author": ["K. Xu", "W. Li"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Xu and Li,? \\Q2000\\E", "shortCiteRegEx": "Xu and Li", "year": 2000}, {"title": "Many hard examples in exact phase transitions", "author": ["K. Xu", "W. Li"], "venue": "Theoretical Computer Science,", "citeRegEx": "Xu and Li,? \\Q2006\\E", "shortCiteRegEx": "Xu and Li", "year": 2006}, {"title": "A PTAS for the minimum weighted dominating set problem with smooth weights on unit disk graphs", "author": ["X. Zhu", "W. Wang", "S. Shan", "Z. Wang", "W. Wu"], "venue": "Journal of combinatorial optimization,", "citeRegEx": "Zhu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2012}, {"title": "New approximations for minimum-weighted dominating sets and minimum-weighted connected dominating sets on unit disk graphs", "author": ["F. Zou", "Y. Wang", "Xu", "X.-H", "X. Li", "H. Du", "P. Wan", "W. Wu"], "venue": "Theoretical Computer Science,", "citeRegEx": "Zou et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zou et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 25, "context": "In the work of Nitash and Singh (2014), a swarm intelligence algorithm called ABC uses an artificial bee colony method to solve MWDS.", "startOffset": 15, "endOffset": 39}, {"referenceID": 4, "context": "In the work of Bouamama and Blum (2016), a randomized population-based iterated greedy approach R-PBIG is proposed to tackle MWDS, which maintains a population of solutions and applies the basic steps of an iterated greedy algorithm to each member of the population.", "startOffset": 15, "endOffset": 40}, {"referenceID": 9, "context": "The CC strategy has been successfully applied to a number of well-known combinatorial optimization problems, including Vertex Cover (Cai et al., 2011; Cai, Su, Luo, & Sattar, 2013; Fang, Chu, Qiao, Feng, & Xu, 2014; Li, Hu, Zhang, & Yin, 2016), Set Covering (Wang, Ouyang, Zhang, & Yin, 2015; Wang, Yin, Ouyang, & Zhang, 2016), Clique problem (Wang, Cai, & Yin, 2016),", "startOffset": 132, "endOffset": 243}, {"referenceID": 17, "context": "Glover proposes the tabu method (Glover, 1989), which has been widely used in local search algorithms (Di Gaspero & Schaerf, 2007; Escobar, Linfati, Toth, & Baldoquin, 2014; Ahonen, de Alvarenga, & Amaral, 2014).", "startOffset": 32, "endOffset": 46}, {"referenceID": 9, "context": "Recently, an interesting strategy called Configuration Checking (CC) (Cai et al., 2011) was proposed to handle the cycling problem in local search.", "startOffset": 69, "endOffset": 87}, {"referenceID": 9, "context": "Thus, we can easily devise a CC strategy for the MWDS problem, following the one for the vertex cover problem (Cai et al., 2011).", "startOffset": 110, "endOffset": 128}, {"referenceID": 20, "context": "The weight of vertices being covered in score2 is taken into account (Jovanovic et al., 2010).", "startOffset": 69, "endOffset": 93}, {"referenceID": 20, "context": "\u2022 T1 benchmark (Jovanovic et al., 2010) (530 instances): all instances are connected undirected graphs with the vertex weights randomly distributed in the interval [20,70].", "startOffset": 15, "endOffset": 39}, {"referenceID": 20, "context": "\u2022 T2 benchmark (Jovanovic et al., 2010) (530 instances): the weight of all vertices in all instances is assigned as be a function based on the degree d(v) of the vertex v which is randomly set to in the interval [1, d(v)2].", "startOffset": 15, "endOffset": 39}, {"referenceID": 20, "context": "\u2022 UDG benchmark (Jovanovic et al., 2010) (120 instances): these instances are generated by using the topology generator (Michele, 2007).", "startOffset": 16, "endOffset": 40}, {"referenceID": 25, "context": ", 2010) (120 instances): these instances are generated by using the topology generator (Michele, 2007).", "startOffset": 87, "endOffset": 102}, {"referenceID": 41, "context": "\u2022 BHOSLIB benchmark with weighting function w(vi)=(i mod 200)+1 (41 instances): BHOSLIB instances (Xu, Boussemart, Hemery, & Lecoutre, 2005) were originally unweighted and generated randomly based on the model RB (Xu & Li, 2000, 2006; Xu et al., 2007).", "startOffset": 213, "endOffset": 251}, {"referenceID": 29, "context": "As for the weighting function: for the ith vertex vi, w(vi)=(i mod 200)+1, it was proposed in the work of Pullan (2008) and has been widely used in the literature for algorithms for solving problems on vertex weighted graphs.", "startOffset": 106, "endOffset": 120}, {"referenceID": 35, "context": "As for future work, we consider to further improve the CC2FS algorithm by integrating some other ideas like strong configuration checking (Wang et al., 2016).", "startOffset": 138, "endOffset": 157}], "year": 2017, "abstractText": "The Minimum Weight Dominating Set (MWDS) problem is an important generalization of the Minimum Dominating Set (MDS) problem with extensive applications. This paper proposes a new local search algorithm for the MWDS problem, which is based on two new ideas. The first idea is a heuristic called two-level configuration checking (CC), which is a new variant of a recent powerful configuration checking strategy (CC) for effectively avoiding the recent search paths. The second idea is a novel scoring function based on the frequency of being uncovered of vertices. Our algorithm is called CCFS, according to the names of the two ideas. The experimental results show that, CCFS performs much better than some state-of-the-art algorithms in terms of solution quality on a broad range of MWDS benchmarks.", "creator": "TeX"}}}