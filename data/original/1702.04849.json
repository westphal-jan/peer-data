{"id": "1702.04849", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Feb-2017", "title": "Theoretical and Practical Advances on Smoothing for Extensive-Form Games", "abstract": "Sparse iterative methods, in particular first-order methods, are known to be among the most effective in solving large-scale two-player zero-sum extensive-form games. The convergence rates of these methods depend heavily on the properties of the distance-generating function that they are based on. We investigate the acceleration of first-order methods for solving extensive-form games through better design of the dilated entropy function---a class of distance-generating functions related to the domains associated with the extensive-form games. By introducing a new weighting scheme for the dilated entropy function, we develop the first distance-generating function for the strategy spaces of sequential games that has no dependence on the branching factor of the player. This result improves the convergence rate of several first-order methods by a factor of $\\Omega(b^dd)$, where $b$ is the branching factor of the player, and $d$ is the depth of the game tree.", "histories": [["v1", "Thu, 16 Feb 2017 03:39:07 GMT  (58kb,D)", "https://arxiv.org/abs/1702.04849v1", null], ["v2", "Tue, 9 May 2017 02:24:32 GMT  (4893kb,D)", "http://arxiv.org/abs/1702.04849v2", null]], "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["christian kroer", "kevin waugh", "fatma kilinc-karzan", "tuomas sandholm"], "accepted": false, "id": "1702.04849"}, "pdf": {"name": "1702.04849.pdf", "metadata": {"source": "CRF", "title": "Theoretical and Practical Advances on Smoothing for Extensive-Form Games", "authors": ["Christian Kroer", "Kevin Waugh"], "emails": ["ckroer@cs.cmu.edu", "kevin.waugh@gmail.com", "fkilinc@andrew.cmu.edu", "sandholm@cs.cmu.edu"], "sections": [{"heading": null, "text": "Thus far, counterfactual regret minimization methods have been faster in practice, and more popular, than first-order methods despite their theoretically inferior convergence rates. Using our new weighting scheme and practical tuning we show that, for the first time, the excessive gap technique can be made faster than the fastest counterfactual regret minimization algorithm, CFR+, in practice."}, {"heading": "1 Introduction", "text": "Extensive-form games (EFGs) are a broad class of games; they model sequential interaction, imperfect information, and outcome uncertainty. Nash equilibria prescribe a particular notion of rational behavior in such games. In the specific case of two-player zero-sum EFGs with perfect recall, an exact Nash equilibrium can be computed in polynomial time using a Linear Program (LP) whose\n\u2217Supported by a Facebook Fellowship, the NSF under grants IIS-1617590, IIS-1320620, and IIS-1546752, and the ARO under awards W911NF-16-1-0061 and W911NF-17-1-0082. \u2020Supported by NSF grant CMMI 1454548. \u2021Supported by the NSF under grants IIS-1617590, IIS-1320620, and IIS-1546752, and the ARO under awards W911NF-16-1-0061 and W911NF-17-1-0082.\nar X\niv :1\n70 2.\n04 84\n9v 2\n[ cs\n.G T\nsize is linear in the size of the game tree [von Stengel, 1996]. However, in practice the LP approach has two major drawbacks limiting its applicability. First, the LP may be prohibitively large and may not fit in memory. Second, even when it does, the iterations of interior-point methods or the simplex algorithm are prohibitively expensive [Sandholm, 2010]. Practical methods for EFG solving tackle this issue through two complementary approaches: Abstraction and iterative game solvers with low memory requirements [Sandholm, 2010]. In this paper we focus on the second approach. Iterative game solvers mainly fall in two categories: (i) counterfactual-regret-based methods [Zinkevich et al., 2007, Lanctot et al., 2009] achieving a convergence rate on the order of O( 1\n2 ), and (ii)\nfirst-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O(1 ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective.\nNash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs.\nHoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes\u2014a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al. [2010]. These bounds from Kroer et al. [2015] generate the current state-of-the-art parameters associated with the convergence rate for FOMs with O(1 ) convergence.\nIn this paper we construct a new weighting scheme for such entropy-based DGFs. This weighting scheme leads to new and improved bounds on the strong convexity parameter associated with general treeplex domains. In particular, our new bounds are first-of-their kind as they have no dependence on the branching operation of the treeplex. Informally, our strong convexity result allows us to improve the convergence rate of FOMs by a factor of \u2126(bdd) (where b is the average branching factor for a player and d is the depth of the EFG) compared to the prior state-of-the-art results from Kroer et al. [2015]. Our bounds parallel the simplex case for matrix games where the entropy function achieves a logarithmic dependence on the dimension of the simplex domain.\nFinally, we complement our theoretical results with numerical experiments to investigate the speed up of FOMs with convergence rate O(1 ) and compare the performance of these algorithms with the premier regret-based methods CFR and CFR+ [Tammelin et al., 2015]. CFR+ is the fastest prior algorithm for computing Nash equilibria in EFGs when the entire tree can be traversed (rather than sampled). Bowling et al. [2015] used it to essentially solve the game limit Texas hold\u2019em.\nCFR+ is also the algorithm used to accurately solve endgames in the Libratus agent, which showed superhuman performance against a team of top Heads-Up No-Limit Texas hold\u2019em poker\nspecialist professional players in the Brains vs AI event 1. A slight variation2 of CFR+ was used in the DeepStack agent Moravc\u030c\u0301\u0131k et al. [2017], which beat a group of professional players. Our experiments show that FOMs are substantially faster than both CFR algorithms when using a practically tuned variant of our DGF. We also test the impact of stronger bounds on the strong convexity parameter: we instantiate EGT with the parameters developed in this paper, and compare the performance to the parameters developed by Kroer et al. [2015]. These experiments illustrate that the tighter parameters developed here lead to better practical convergence rate.\nThe rest of the paper is organized as follows. Section 2 discusses related research. We present the general class of problems that we address\u2014bilinear saddle-point problems\u2014and describe how they relate to EFGs in Section 3. Then Section 4 describes our optimization framework. Section 5 introduces treeplexes, the class of convex polytopes that define our domains of the optimization problems. Our focus is on dilated entropy-based DGFs; we introduce these in Section 6 and present our main results\u2014bounds on the associated strong convexity parameter and treeplex diameter. In Section 7 we demonstrate the use of our results on instantiating EGT. We compare our approach with the current state-of-art in EFG solving and discuss the extent of theoretical improvements achievable via our approach in Section 7.1. Section 8 presents numerical experiments testing the effect of various parameters on the performance of our approach as well as comparing the performance of our approach to CFR and CFR+. We close with a summary of our results and a few compelling further research directions in Section 9."}, {"heading": "2 Related work", "text": "Nash equilibrium computation has received extensive attention in the literature [Littman and Stone, 2003, Lipton et al., 2003, Gilpin and Sandholm, 2007, Zinkevich et al., 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games.\nKoller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, was used to solve Rhode-Island hold\u2019em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion nodes (roughly size 5 \u00b7 107 after lossless abstraction). However, for games larger than this, the resulting LPs tend to not fit in the computer memory thus requiring approximate solution techniques. These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010].\nThe most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+). These regret-minimization algorithms perform local regret-based updates at each information set. Despite their slow convergence rate of O( 1\n2 ), they perform very well in pratice, especially CFR+. Recently, Waugh and Bagnell [2015]\nshowed, with some caveats, an interpretation of CFR as a FOM with O( 1 2\n) rate. Nonetheless, in this paper we make a distinction between regret-based methods and O(1 ) FOMs for ease of exposition.\nHoda et al. [2010] initially proposed DGFs for EFGs leading to O(1 ) convergence rate when used with EGT. Kroer et al. [2015] improved these result for the dilated entropy function. Gilpin\n1Confirmed through author communication 2This variation was chosen for implementation reasons, though, and has inferior practical iteration complexity.\net al. [2012] give an algorithm with convergence rate O(ln(1 )). Their bound has a dependence on a certain condition number of the payoff matrix, which is difficult to estimate; and as a result they show a bound of O(1 ) which is independent of the condition number. Detailed comparisons to all three algorithms discussed here are given in Section 7.1.\nFinally, Bosansky et al. [2014] develop an iterative double-oracle algorithm for exact equilibrium computation. This algorithm only scales for games where it can identify an equilibrium of small support, and thus suffers from the same performance issues as the general LP approach.\nIn addition to equilibrium-finding algorithms, another central topic in large-scale game solving has been automated abstraction [Sandholm, 2010, 2015]. Initially, this was used mostly for information abstraction [Gilpin and Sandholm, 2007, Shi and Littman, 2002, Zinkevich et al., 2007]. Lately, action abstraction approaches have gained considerable interest [Hawkin et al., 2011, 2012, Brown and Sandholm, 2014, Kroer and Sandholm, 2014, 2016]. Sequential game abstraction approaches with solution quality bounds have also emerged for stochastic [Sandholm and Singh, 2012] and extensive-form [Lanctot et al., 2012, Kroer and Sandholm, 2014, 2016] games more recently."}, {"heading": "3 Problem setup", "text": "Computing a Nash equilibrium in a two-player zero-sum EFG with perfect recall can be formulated as a Bilinear Saddle Point Problem (BSPP):\nmin x\u2208X max y\u2208Y \u3008x,Ay\u3009 = max y\u2208Y min x\u2208X \u3008x,Ay\u3009. (1)\nThis is known as the sequence-form formulation [Romanovskii, 1962, Koller et al., 1996, von Stengel, 1996]. In this formulation, x and y correspond to the nonnegative strategy vectors for players 1 and 2 and the sets X ,Y are convex polyhedral reformulations of the sequential strategy space of these players. Here X ,Y are defined by the constraints Ex = e, Fy = f , where each row of E,F encodes part of the sequential nature of the strategy vectors, the right hand-side vectors e, f are |I1| , |I2|-dimensional vectors, and Ii is the information sets for player i. For a complete treatment of this formulation, see von Stengel [1996].\nOur theoretical developments mainly exploit the treeplex domain structure and are independent of other structural assumptions resulting from EFGs. Therefore, we describe our results for general BSPPs. We follow the presentation and notation of Juditsky and Nemirovski [2011a,b] for BSPPs. For notation and presentation of treeplex structure, we follow Kroer et al. [2015]."}, {"heading": "3.1 Basic notation", "text": "We let \u3008x, y\u3009 denote the standard inner product of vectors x, y. Given a vector x \u2208 Rn, we let \u2016x\u2016p denote its `p norm given by \u2016x\u2016p := ( \u2211n i=1 |xi|p)\n1/p for p \u2208 [1,\u221e) and \u2016x\u2016\u221e := maxi\u2208[n] |xi| for p = \u221e. Throughout this paper, we use Matlab notation to denote vector and matrices, i.e., [x; y] denotes the concatenation of two column vectors x, y. For a given set Q, we let ri (Q) denote its relative interior. Given n \u2208 N, we denote the simplex \u2206n := {x \u2208 Rn+ : \u2211n i=1 xi = 1}."}, {"heading": "4 Optimization setup", "text": "In its most general form a BSPP is defined as\nOpt := max y\u2208Y min x\u2208X\n\u03c6(x, y), (S)\nwhere X ,Y are nonempty convex compact sets in Euclidean spaces Ex,Ey and \u03c6(x, y) = \u03c5 + \u3008a1, x\u3009+ \u3008a2, y\u3009+ \u3008y,Ax\u3009. We let Z := X \u00d7 Y; so \u03c6(x, y) : Z \u2192 R. In the context of EFG solving, \u03c6(x, y) is simply the inner product given in (1).\nThe BSPP (S) gives rise to two convex optimization problems that are dual to each other:\nOpt(P ) = minx\u2208X [\u03c6(x) := maxy\u2208Y \u03c6(x, y)] (P ), Opt(D) = maxy\u2208Y [\u03c6(y) := minx\u2208X \u03c6(x, y)] (D),\nwith Opt(P ) = Opt(D) = Opt. It is well known that the solutions to (S) \u2014 the saddle points of \u03c6 on X \u00d7 Y \u2014 are exactly the pairs z = [x; y] comprised of optimal solutions to the problems (P ) and (D). We quantify the accuracy of a candidate solution z = [x; y] with the saddle point residual\nsad(z) := \u03c6(x)\u2212 \u03c6(y) = [ \u03c6(x)\u2212Opt(P ) ]\ufe38 \ufe37\ufe37 \ufe38 \u22650 + [ Opt(D)\u2212 \u03c6(y) ]\ufe38 \ufe37\ufe37 \ufe38 \u22650 .\nIn the context of EFG, sad(z) measures the proximity to being an -Nash equilibrium."}, {"heading": "4.1 General framework for FOMs", "text": "Most FOMs capable of solving BSPP (S) are quite flexible in terms of adjusting to the geometry of the problem characterized by the domains X ,Y of the BSPP (S). The following components are standard in forming the setup for such FOMs (we present components for X , analogous components are used for Y):\n\u2022 Vector norm: \u2016 \u00b7 \u2016X on the Euclidean space E where the domain X of (S) lives, along with its dual norm \u2016\u03b6\u2016\u2217X = max\u2016x\u2016X\u22641 \u3008\u03b6, x\u3009.\n\u2022 Matrix norm: \u2016A\u2016 = maxy {\u2016Ay\u2016\u2217X : \u2016y\u2016Y = 1} based on the vector norms \u2016 \u00b7 \u2016X , \u2016 \u00b7 \u2016Y .\n\u2022 Distance-Generating Function (DGF): A function \u03c9X (x) : X \u2192 R, which is convex and continuous on X , and admits a continuous selection of subgradients \u03c9\u2032X (x) on the set X \u25e6 := {x \u2208 X : \u2202\u03c9X (x) 6= \u2205} (here \u2202\u03c9X (x) is a subdifferential of \u03c9X taken at x), and is strongly convex with modulus \u03d5X w.r.t. the norm \u2016 \u00b7 \u2016X :\n\u2200x\u2032, x\u2032\u2032 \u2208 X \u25e6 : \u3008\u03c9\u2032X (x\u2032)\u2212 \u03c9\u2032X (x\u2032\u2032), x\u2032 \u2212 x\u2032\u2032\u3009 \u2265 \u03d5X \u2016x\u2032 \u2212 x\u2032\u2032\u20162X . (2)\n\u2022 Bregman distance: V (u\u2016x) := \u03c9X (u)\u2212 \u03c9X (x)\u2212 \u3008\u03c9\u2032X (x), u\u2212 x\u3009 for all x \u2208 X \u25e6 and u \u2208 X .\n\u2022 Prox-mapping : Given a prox center x \u2208 X \u25e6,\nProxx(\u03be) := argmin u\u2208X\n{\u3008\u03be, u\u3009+ V (u\u2016x)} : E\u2192 X \u25e6.\nFor properly chosen stepsizes, the prox-mapping becomes a contraction. This is critical in the convergence analysis of FOMs. Furthermore, when the DGF is taken as the squared `2 norm, the prox mapping becomes the usual projection operation of the vector x\u2212 \u03be onto X .\n\u2022 \u03c9-center : x\u03c9 := argmin x\u2208X \u03c9X (x) \u2208 X \u25e6 of X .\n\u2022 Set width: \u2126x := max x\u2208X V (x\u2016x\u03c9) \u2264 max x\u2208X \u03c9X (x)\u2212min x\u2208X \u03c9X (x).\nThe distance-generating functions \u03c9X , \u03c9Y can be used to create smoothed approximations to \u03c6, \u03c6 as follows [Nesterov, 2005b]:\n\u03c6\u00b52(x) = maxy\u2208Y {\u03c6(x, y)\u2212 \u00b52\u03c9Y(y)} , (3)\n\u03c6 \u00b51 (y) = min x\u2208X {\u03c6(x, y) + \u00b51\u03c9X (x)} , (4)\nwhere \u00b51, \u00b52 > 0 are smoothness parameters denoting the amount of smoothing applied. Let y\u00b52(x) and x\u00b51(y) refer to the y and x values attaining the optima in (3) and (4). These can be thought of as smoothed best responses. Nesterov [2005b] shows that the gradients of the functions \u03c6\u00b52(x) and \u03c6\n\u00b51 (y) exist and are Lipschitz continuous. The gradient operators and Lipschitz constants are\ngiven as follows\n\u2207\u03c6\u00b52(x) = a1 +Ay\u00b52(x) and \u2207\u03c6\u00b51(y) = a2 +A >x\u00b51(y),\nL1 ( \u03c6\u00b52 ) = \u2016A\u20162\n\u03d5Y\u00b52 and L2\n( \u03c6 \u00b51 ) = \u2016A\u20162\n\u03d5X\u00b51 .\nBased on this setup, we formally state the Excessive Gap Technique (EGT) of Nesterov [2005a] in Algorithm 1.\nALGORITHM 1: EGT input : \u03c9-center z\u03c9, DGF weights \u00b51, \u00b52,\nand > 0 output: zt(= [xt; yt]) x0 = Proxx\u03c9 ( \u00b5\u221211 \u2207\u03c6\u00b52(x\u03c9) ) ; y0 = y\u00b52(x\u03c9); t = 0; z1 := z\u03c9; while sad(z\nt) > do \u03c4t = 2 t+3 ; if t is even then\n(\u00b5t+11 , x t+1, yt+1) =\nStep(\u00b5t1, \u00b5 t 2, x t, yt, \u03c4) else\n(\u00b5t+12 , y t+1, xt+1) =\nStep(\u00b5t2, \u00b5 t 1, y t, xt, \u03c4) end t = t+ 1;\nend\nALGORITHM 2: Step\ninput : \u00b51, \u00b52, x, y, \u03c4 output: \u00b5+1 , x+, y+ x\u0302 = (1\u2212 \u03c4)x+ \u03c4x\u00b51(y); y+ = (1\u2212 \u03c4) y + \u03c4y\u00b52(x\u0302); x\u0303 = Proxx\u00b51 (y) ( \u03c4 (1\u2212\u03c4)\u00b51\u2207\u03c6\u00b52(x\u0302) ) ; x+ = (1\u2212 \u03c4)x+ \u03c4 x\u0303; \u00b5+1 = (1\u2212 \u03c4)\u00b51;\nThe EGT algorithm alternates between taking steps focused on X and Y. Algorithm 2 shows a single step focused on X . Steps focused on y are completely analogous. Algorithm 1 shows how the alternating steps and stepsizes are computed, as well as how initial points are selected.\nSuppose the initial values \u00b51, \u00b52 in the EGT algorithm satisfy \u00b51 = \u03d5X\nL1(\u03c6\u00b52 ) . Then, at every\niteration t \u2265 1 of the EGT algorithm, the corresponding solution zt = [xt; yt] satisfies xt \u2208 X , yt \u2208 Y, and\n\u03c6(xt)\u2212 \u03c6(yt) = sad(zt) \u2264 4\u2016A\u2016 T + 1 \u221a \u2126X\u2126Y \u03d5X\u03d5Y .\nConsequently, [Nesterov, 2005a] proves that the EGT algorithm has a convergence rate of O(1 )."}, {"heading": "5 Treeplexes", "text": "Hoda et al. [2010] introduce the treeplex, a class of convex polytopes that encompass the sequenceform description of strategy spaces in perfect-recall EFGs.\nDefinition 1. Treeplexes are defined recursively:\n1. Basic sets: The standard simplex \u2206m is a treeplex.\n2. Cartesian product: If Q1, . . . , Qk are treeplexes, then Q1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7Qk is a treeplex.\n3. Branching: Given a treeplex P \u2286 [0, 1]p, a collection of treeplexes Q = {Q1, . . . , Qk} where Qj \u2286 [0, 1]nj , and l = {l1, . . . , lk} \u2286 {1, . . . , p}, the set defined by\nP l Q := { (u, q1, . . . , qk) \u2208 Rp+ \u2211 j nj : u \u2208 P, q1 \u2208 ul1 \u00b7Q1, . . . , qk \u2208 ulk \u00b7Qk } is a treeplex. In this setup, we say ulj is the branching variable for the treeplex Qj .\nA treeplex is a tree of simplexes where children are connected to their parents through the branching operation. In the branching operation, the child simplex domain is scaled by the value of the parent branching variable. Understanding the treeplex structure is crucial because the proofs of our main results rely on induction over these structures. For EFGs, the simplexes correspond to the information sets of a single player and the whole treeplex represents that player\u2019s strategy space. The branching operation has a sequential interpretation: The vector u represents the decision variables at certain stages, while the vectors qj represent the decision variables at the k potential following stages, depending on external outcomes. Here k \u2264 p since some variables in u may not have subsequent decisions. For treeplexes, von Stengel [1996] has suggested a polyhedral representation of the form Eu = e where the matrix E has its entries from {\u22121, 0, 1} and the vector e has its entries in {0, 1}.\nFor a treeplex Q, we denote by SQ the index set of the set of simplexes contained in Q (in an EFG SQ is the set of information sets belonging to the player). For each j \u2208 SQ, the treeplex rooted at the j-th simplex \u2206j is referred to as Qj . Given vector q \u2208 Q and simplex \u2206j , we let Ij denote the set of indices of q that correspond to the variables in \u2206j and define qj to be the sub vector of q corresponding to the variables in Ij . For each simplex \u2206j and branch i \u2208 Ij , the set Dij represents the set of indices of simplexes reached immediately after \u2206j by taking branch i (in an EFG Dij is the set of potential next-step information sets for the player). Given a vector q \u2208 Q, simplex \u2206j , and index i \u2208 Ij , each child simplex \u2206k for every k \u2208 Dij is scaled by qi. Conversely, for a given simplex \u2206j , we let pj denote the index in q of the parent branching variable qpj that \u2206 j is scaled by. We use the convention that qpj = 1 if Q is such that no branching operation precedes \u2206j . For each j \u2208 SQ, dj is the maximum depth of the treeplex rooted at \u2206j , that is, the maximum number of simplexes reachable through a series of branching operations at \u2206j . Then dQ gives the depth of Q. We use bjQ to identify the number of branching operations preceding the j-th simplex in Q. We will say that a simplex j such that bjQ = 0 is a root simplex. Figure 1 illustrates an example treeplex Q. Q is constructed from nine two-to-three-dimensional simplexes \u22061, . . . ,\u22069. At level 1, we have two root simplexes, \u22061,\u22062, obtained by a Cartesian product (denoted by \u00d7). We have maximum depths d1 = 2, d2 = 1 beneath them. Since there are no preceding branching operations, the parent variables for these simplexes \u22061 and \u22062 are qp1 = qp2 = 1. For \u2206\n1, the corresponding set of indices in the vector q is I1 = {1, 2}, while for \u22062 we have I2 = {3, 4, 5}. At level 2, we have the simplexes \u22063, . . . ,\u22067. The parent variable of\n\u22063 is qp3 = q1; therefore, \u2206 3 is scaled by the parent variable qp3 . Similarly, each of the simplexes \u22063, . . . ,\u22067 is scaled by their parent variables qpj that the branching operation was performed on. So on for \u22068 and \u22069 as well. The number of branching operations required to reach simplexes \u22061,\u22063 and \u22068 is b1Q = 0, b 3 Q = 1 and b 8 Q = 2, respectively.\nNote that we allow more than two-way branches; hence our formulation follows that of Kroer et al. [2015] and differs from that of Hoda et al. [2010]. As discussed in Hoda et al. [2010], it is possible to model sequence-form games by treeplexes that use only two-way branches. Yet, this can cause a large increase in the depth of the treeplex, thus leading to significant degradation in the strong convexity parameter. Because we handle multi-way branches directly in our framework, our approach is more effective in taking into account the structure of the sequence-form game and thereby resulting in better bounds on the associated strong convexity parameters and thus overall convergence rates.\nOur analysis requires a measure of the size of a treeplex Q. Thus, we define MQ := maxq\u2208Q \u2016q\u20161. In the context of EFGs, suppose Q encodes player 1\u2019s strategy space; then MQ is the maximum number of information sets with nonzero probability of being reached when player 1 has to follow a pure strategy while the other player may follow a mixed strategy. We also let\nMQ,r := max q\u2208Q \u2211 j\u2208SQ:bjQ\u2264r \u2016qj\u20161. (5)\nIntuitively, MQ,r gives the maximum value of the `1 norm of any vector q \u2208 Q after removing the variables corresponding to simplexes that are not within r branching operations of the root of Q.\nExample 1. In order to illustrate MQ and compare it to the size of |SQ|, let us now consider an example of an EFG and its corresponding treeplexes. Consider a game where two players take turns choosing among k actions, and each player chooses actions d times before leaf nodes are reached. In the treeplex Q of Player 1, each time Player 1 chooses among k actions constitutes a size k branching operation, and every time Player 2 chooses among k actions constitutes a size k Cartesian product operation. The total dimensionality of the treeplex, |SQ|, is k2d, while the value of MQ is k d (since only Cartesian products blow up). Thus, MQ is square root of the size of |SQ|."}, {"heading": "6 Dilated entropy functions with bounded strong convexity", "text": "In this section we introduce DGFs for domains with treeplex structures and establish their strong convexity parameters with respect to a given norm (see (2)).\nThe basic building block in our construction is the entropy DGF given by \u03c9e(z) = \u2211n\ni=1 zi log(zi), for the simplex \u2206n. It is well-known that \u03c9e(\u00b7) is strongly convex with modulus 1 with respect to the `1 norm on \u2206n (see Juditsky and Nemirovski [2011a]). We will show that a suitable modification of this function achieves a desirable strong convexity parameter for the treeplex domain.\nThe treeplex structure is naturally related to the dilation operation [Hiriart-Urruty and Lemare\u0301chal, 2001] defined as follows: Given a compact set K \u2286 Rd and a function f : K \u2192 R, we first define\nK\u0304 := { (t, z) \u2208 Rd+1 : t \u2208 [0, 1] , z \u2208 t \u00b7K } .\nDefinition 2. Given a function f(z), the dilation operation is the function f\u0304 : K\u0304 \u2192 R given by\nf\u0304(z, t) = { t \u00b7 f(z/t) if t > 0 0 if t = 0 .\nThe dilation operation preserves convexity, and thus we define the following convex function by dilating the entropy function over the simplexes of a treeplex:\nDefinition 3. Given a treeplex Q and weights \u03b2j > 0 for each j \u2208 SQ, we define the dilated entropy function as\n\u03c9(q) = \u2211 j\u2208SQ \u03b2j \u2211 i\u2208Ij qi log qi qpj for any q \u2208 Q,\nwhere we follow the treeplex notation and pj is the index of the branching variable preceding \u2206 j , with the convention that qpj = 1 if \u2206 j has no branching operation preceding it.\nRemark 1. Note that the dilated entropy function \u03c9(\u00b7) defined above is twice differentiable in the relative interior of treeplex Q and admits a continuous gradient selection. Moreover, for weights \u03b2j that scale appropriately with depth dj, we will demonstrate that it is strongly convex w.r.t. the `1 norm. Thus, the dilated entropy function is compatible with the `1 norm, as required by the BSPP setup.\nWe would also like the prox-mapping associated with our DGF to be efficiently computable. Hoda et al. [2010] show that for any dilated function, its prox operator on a treeplex can be easily computed through a recursive bottom-up traversal involving the prox mappings associated with the function being dilated on individual simplexes. Since the entropy prox function can be computed in closed form on a simplex, the dilated entropy function can be computed by a single treeplex traversal involving closed-form expressions on each simplex.\nDefinition 3 above leads to a subset of the DGFs considered by Hoda et al. [2010]. Our main theoretical result shows that by a careful selection of the weights \u03b2j , we can significantly improve the strong convexity bounds associated with the dilated entropy function. We will consider weights that satisfy the following recurrence:\n\u03b1j = 1 + max i\u2208Ij \u2211 k\u2208Dij \u03b1k\u03b2k \u03b2k \u2212 \u03b1k , \u2200j \u2208 SQ, \u03b2j > \u03b1j , \u2200i \u2208 Ij and \u2200j \u2208 SQ s.t. bjQ > 0, \u03b2j = \u03b1j , \u2200i \u2208 Ij and \u2200j \u2208 SQ s.t. bjQ = 0.\n(6)\nIntuitively, \u03b1j represents the negative terms that the weight \u03b2j has to cancel out: the constant 1 represents the negative term resulting from the squared norm in the strong convexity requirement; the summation term represents the amount of negative terms accumulated from the induction on simplexes descending from simplex j. The qualifications on \u03b2j ensure that \u03b2j is set such that it at least cancels out the negative terms; the difference \u03b2j \u2212 \u03b1j controls the amount of negative value the parent simplex has to make up. This is why we set \u03b2j = \u03b1j when b j Q = 0. As part of the proof of Lemma 2 we will see why we require a strict inequality \u03b2j > \u03b1j for non-root simplexes. Based on recurrence (6), our main results establish strong convexity of our dilated entropy DGF w.r.t. the `2 and `1 norms:\nTheorem 1. For a treeplex Q, the dilated entropy function with weights satisfying recurrence (6) is strongly convex with modulus 1 with respect to the `2 norm.\nTheorem 2. For a treeplex Q, the dilated entropy function with weights satisfying recurrence (6) is strongly convex with modulus 1MQ with respect to the `1 norm.\nWe give the proofs of Theorems 1 and 2 in Section 6.2. Based on Theorem 2, we get the following corollary:\nCorollary 1. For a treeplex Q, the dilated entropy function with weights \u03b2j = 2+ \u2211dj r=1 2 r(MQj ,r\u22121) for all j \u2208 SQ is strongly convex with modulus 1MQ w.r.t. the `1 norm.\nCorollary 1 follows easily from Theorem 2 and a recursive interpretation of the weights, which is presented as Fact 2 in the next section. In particular, a specific choice of weights in Fact 2 immediately satisfies the recurrence (6) and leads to Corollary 1.\nTo our knowledge, the best strong convexity bounds for general treeplexes were proved in Kroer et al. [2015]. Using weights \u03b2j = 2\ndjMQj they show strong convexity modulus 1 |SQ| w.r.t. the `1\nnorm. Corollary 1 improves the prior bounds by exchanging a factor of |SQ| with a factor of MQ. Note that |SQ| is tied to the branching factor associated with branching operations in the treeplex Q whereas MQ is not. Thus, our result removes the dependence of the strong convexity parameter on the branching factor and hence significantly improves upon Kroer et al. [2015].\nIn Theorem 3 we use our strong convexity result to establish a polytope diameter that has only a logarithmic dependence on the branching factor. As a consequence, the associated dilated entropy DGF when used in FOMs such as MP and EGT for solving EFGs leads to the same improvement in their convergence rate."}, {"heading": "6.1 Preliminary results for the proofs of our main results", "text": "We start with some simple facts and a few technical lemmas that are used in our proofs.\nFact 1. Given a treeplex Q, we have, respectively, for all i \u2208 Ij , j \u2208 SQ and all d = 1, . . . , dQ, q \u2208 Q:\n(a) MQj \u2265 1 + \u2211 l\u2208Dij MQl , (b) MQ \u2265 \u2211 j\u2208SQ:dj=d qpjMQj .\nProof. The first inequality was established in Kroer et al. [2015, Lemma 5.7]. The second follows by using MQ = \u2211 j qi for some q, and inductively replacing terms belonging to simplexes j at the bottom with MQj . The result follows because branching operations cancel out by summing to 1.\nOur next observation follows from Fact 1(a) and is advantageous in suggesting a practically useful choice of the weights \u03b2j that can be used for Theorem 2 to arrive at Corollary 1.\nFact 2. Let Q be a treeplex and \u03b2j = 2 + \u2211dj r=1 2 r(MQj ,r \u2212 1) for all j \u2208 SQ as in Corollary 1.\nThen Fact 1(a) implies \u03b2j \u2265 2 + \u2211\nk\u2208Dij 2\u03b2k, \u2200i \u2208 Ij and \u2200j \u2208 SQ.\nConsequently, by selecting \u03b2j = 2\u03b1j , and \u03b1j = 1 + \u2211dj r=1 2 r\u22121(MQj ,r \u2212 1) for all i \u2208 Ij and for all j \u2208 SQ such that bjQ > 0, we immediately satisfy the conditions of the recurrence in (6). Given a twice differentiable function f , we let \u22072f(z) denote its Hessian at z. Our analysis is based on the following sufficient condition for strong convexity of a twice differentiable function:\nFact 3. A twice-differentiable function f is strongly convex with modulus \u03d5 with respect to a norm \u2016 \u00b7 \u2016 on nonempty convex set C \u2282 Rn if h>\u22072f(z)h \u2265 \u03d5\u2016h\u20162, \u2200h \u2208 Rn, z \u2208 C\u25e6.\nFor simplexes \u2206j at depth 1, there is no preceding branching operation; so the variables hpj , qpj do not exist. We circumvent this with the convention hpj = 0, qpj = 1 for such j \u2208 SQ.\nIn our proofs we will use the following expression for h>\u22072\u03c9(q)h. Lemma 1. Given a treeplex Q and a dilated entropy function \u03c9(\u00b7) with weights \u03b2j > 0, we have\nh>\u22072\u03c9(q)h = \u2211 j\u2208SQ \u03b2j \u2211 i\u2208Ij ( h2i qi \u2212 2hihpj qpj ) + h2pj qpj  \u2200q \u2208 ri (Q) and \u2200h \u2208 Rn. (7) We provide the proof of Lemma 1 in the appendix. It simply follows from taking the second-\norder partial derivatives and rearranging terms."}, {"heading": "6.2 Proofs of our main theorems", "text": "The majority of the work for our strong-convexity results is performed by the following lemma, from which our strong convexity results follow easily.\nLemma 2. For any treeplex Q, the dilated entropy function with weights satisfying recurrence (6) satisfies the following inequality:\nh>\u22072\u03c9(q)h \u2265 \u2211 j\u2208SQ \u2211 i\u2208Ij h2i qi \u2200q \u2208 ri (Q) and \u2200h \u2208 Rn. (8)\nProof. We will first show the following inductive hypothesis over the set of non-root simplexes S\u0302Q = { j \u2208 SQ : bjQ > 0 } for any depth d \u2265 0:\n\u2211 j\u2208S\u0302Q:dj\u2264d \u03b2j \u2211 i\u2208Ij ( h2i qi \u2212 2hihpj qpj ) + h2pj qpj \u2212 \u2211 j\u2208S\u0302Q:dj\u2264d \u2211 i\u2208Ij h2i qi \u2265 \u2212 \u2211 j\u2208S\u0302Q:dj=d \u03b2j\u03b1j \u03b2j \u2212 \u03b1j h2pj qpj\nWe begin with the inductive step, as the base case will follow from the same logic. Consider a treeplex Q of depth d > 0. By applying the inductive hypothesis we have\n\u2211 j\u2208S\u0302Q:dj\u2264d \u03b2j \u2211 i\u2208Ij ( h2i qi \u2212 2hihpj qpj ) + h2pj qpj \u2212 \u2211 j\u2208S\u0302Q:dj\u2264d \u2211 i\u2208Ij h2i qi\n\u2265 \u2211\nj\u2208S\u0302Q:dj=d\n\u03b2j \u2211 i\u2208Ij ( h2i qi \u2212 2hihpj qpj ) + h2pj qpj \u2212 \u2211 j\u2208S\u0302Q:dj=d \u2211 i\u2208Ij h2i qi \u2212 \u2211 j\u2208S\u0302Q:dj=d\u22121 \u03b2j\u03b1j \u03b2j \u2212 \u03b1j h2pj qpj\n(9)\nNow we can rearrange terms: The sum over j \u2208 S\u0302Q such that dj = d\u22121 is equivalent to a sum over the immediate descendant information sets k \u2208 Dij inside the square brackets, and we can move the sum over i \u2208 Ij outside the square brackets by using the fact that \u2211 i\u2208Ij qi qpj = 1 and splitting the term h2pj qpj into separate terms multiplied by qiqpj , this gives\n(9) = \u2211\nj\u2208S\u0302Q:dj=d\n\u2211 i\u2208Ij\n \u03b2j \u2212 1\u2212 \u2211\nk\u2208Dij\n\u03b2k\u03b1k \u03b2k \u2212 \u03b1k  h2i qi \u2212 ( 2\u03b2jhihpj qpj ) + qi\u03b2jh 2 pj q2pj  \u2265\n\u2211 j\u2208S\u0302Q:dj=d \u2211 i\u2208Ij\n[ (\u03b2j \u2212 \u03b1j) h2i qi \u2212 ( 2\u03b2jhihpj qpj ) + qi\u03b2jh 2 pj q2pj ] , (10)\nwhere the last inequality follows from the definition of \u03b1j .\nFor indices j \u2208 SQ such that bjQ > 0 and i \u2208 Ij , the relations in (6) imply \u03b2j > \u03b1j , and so the expression inside the square brackets in (10) is a convex function of hi. Taking its derivative w.r.t. hi and setting it to zero gives hi = \u03b2j\n\u03b2j\u2212\u03b1j qi qpj hpj . Thus, we arrive at\n(10) \u2265 \u2211\nj\u2208S\u0302Q:dj=d\n\u2211 i\u2208Ij\n[ \u03b22j\n\u03b2j \u2212 \u03b1j qih\n2 pj\nq2pj \u2212 \u03b22j \u03b2j \u2212 \u03b1j 2qih 2 pj q2pj + qi\u03b2jh 2 pj q2pj\n]\n= \u2211\nj\u2208S\u0302Q:dj=d\nh2pj qpj [( \u2212\u03b22j \u03b2j \u2212 \u03b1j + \u03b2j )\u2211i\u2208Ij qi qpj ] = \u2212 \u2211 j\u2208S\u0302Q:dj=d \u03b2j\u03b1j \u03b2j \u2212 \u03b1j h2pj qpj .\nHence, the induction step is complete. For the base case d = 0 we do not need the inductive assumption: Because Dij = \u2205, \u03b1j = 1, and we get (10) by definition; we can then apply the same convexity argument. This proves our inductive hypothesis.\nThen using Lemma 1, we now have\nh>\u22072\u03c9(q)h\u2212 \u2211 j\u2208SQ \u2211 i\u2208Ij h2i qi = \u2211 j\u2208SQ \u03b2j \u2211 i\u2208Ij ( h2i qi \u2212 2hihpj qpj ) + h2pj qpj \u2212 \u2211 j\u2208SQ \u2211 i\u2208Ij h2i qi\n\u2265 \u2211\nj\u2208SQ:bjQ=0\n\u2211 i\u2208Ij \u03b2j h2i qi \u2212 \u2211 k\u2208Dij \u03b2k\u03b1k \u03b2k \u2212 \u03b1k h2i qi \u2212 h 2 i qi  \u2265 0. The first inequality follows from the fact that hpj = 0 for all j \u2208 SQ such that b j Q = 0, and for all j \u2208 SQ such that bjQ > 0, we used our induction. The last inequality follows from (6) and qi, h2i \u2265 0. This then proves (8).\nWe are now ready to prove our two main theorems, which we restate before proving them.\nTheorem 1. For a treeplex Q, the dilated entropy function with weights satisfying recurrence (6) is strongly convex with modulus 1 with respect to the `2 norm.\nProof. Since qi \u2264 1, Lemma 2 implies h>\u22072\u03c9(q)h \u2265 \u2211 j\u2208SQ \u2211 i\u2208Ij h 2 i = \u2016h\u201622 for all q \u2208 ri (Q) and for all h \u2208 Rn. Because the dilated entropy function \u03c9(q) is twice differentiable on ri (Q), from Fact 3, we conclude that \u03c9(\u00b7) is strongly convex w.r.t. the `2 norm on Q with modulus 1.\nThis analysis is tight: By choosing a vector q \u2208 {0, 1}|Q| such that \u2016q\u20161 = MQ, and setting hi =\n\u03b2j \u03b2j\u2212\u03b1j qi qpj hpj for all indices i such that qi = 1 and hi = 0 otherwise, every inequality in the\nproof of Lemma 2 becomes an equality.\nTheorem 2. For a treeplex Q, the dilated entropy function with weights satisfying recurrence (6) is strongly convex with modulus 1MQ with respect to the `1 norm.\nProof. To show strong convexity with modulus 1 w.r.t. the `1 norm, we lower bound the right-hand side of (8) in Lemma 2:\n\u2211 j\u2208SQ \u2211 i\u2208Ij h2i qi \u2265 1 MQ ( \u2211 j\u2208SQ \u2211 i\u2208Ij qi ) \u2211 j\u2208SQ \u2211 i\u2208Ij h2i qi \u2265 1 MQ ( \u2211 j\u2208SQ \u2211 i\u2208Ij |hi|\u221a qi \u221a qi )2 = 1 MQ \u2016h\u201621,\nwhere the first inequality follows from the fact that MQ is an upper bound on \u2016q\u20161 for any q \u2208 Q, and the second inequality follows from the Cauchy-Schwarz inequality.\nHence, we deduce h>\u22072\u03c9(q)h \u2265 1MQ \u2016h\u2016 2 1 holds for all q \u2208 ri (Q) and for all h \u2208 Rn. Because the dilated entropy function \u03c9(q) is twice differentiable on ri (Q), from Fact 3, we conclude that \u03c9(\u00b7) is strongly convex w.r.t. the `1 norm on Q with modulus \u03d5 = 1MQ ."}, {"heading": "6.3 Treeplex width", "text": "The convergence rates of FOMs such as MP and EGT algorithms depend on the diameter-to-strong convexity parameter ratio \u2126\u03d5 , as described in Section 4.1. In order to establish full results on the convergence rates of these FOMs, we now bound this ratio using Corollary 1 scaled by MQ. Theorem 3. For a treeplex Q, the dilated entropy function with simplex weights \u03b2j = MQ(2 +\u2211dj r=1 2 r(MQj ,r \u2212 1)) for each j \u2208 SQ results in \u2126\u03d5 \u2264 M 2 Q2 dQ+2 logm where m is the dimension of the largest simplex \u2206j for j \u2208 SQ in the treeplex structure."}, {"heading": "7 EGT for extensive-form game solving", "text": "We now describe how to instantiate EGT for solving two-player zero-sum EFGs of the form (1) with treeplex domains. Below we state the customization of all the definitions from Section 4 for our problem.\nLet m be the size of the largest simplex in either of the treeplexes X ,Y. Because X and Y are treeplexes, it is immediately apparent that they are closed, convex, and bounded. We use the `1 norm on both of the embedding spaces Ex,Ey. As our DGFs for X ,Y are compatible with the `1 norm, we use the dilated entropy DGF scaled with weights given in Theorem 3. Then Theorem 3 gives our bound on \u2126X\u03d5X and \u2126Y \u03d5Y . Because the dual norm of the `1 norm is the `\u221e norm, the matrix norm is given by: \u2016A\u2016 = maxy\u2208Y {\u2016Ay\u2016\u22171 : \u2016y\u20161 = 1} = maxi,j |Ai,j |.\nRemark 2. Note that \u2016A\u2016 is not at the scale of the maximum payoff difference in the original game. The values in A are scaled by the probability of the observed nature outcomes on the path of each sequence. Thus, \u2016A\u2016 is exponentially smaller (in the number of observed nature steps on the path to the maximizing sequence) than the maximum payoff difference in the original EFG.\nTheorem 3 immediately leads to the following convergence rate result for FOMs equipped with dilated entropy DGFs to solve EFGs (and more generally BSPPs over treeplex domains).\nTheorem 4. Consider a BSPP over treeplex domains X ,Y. Then EGT algorithm equipped with the dilated entropy DGF with weights \u03b2j = 2+ \u2211dj r=1 2\nr(MXj ,r\u22121) for all j \u2208 SX and the corresponding setup for Y will return an -accurate solution to the BSPP in at most the following number of iterations:\nmaxi,j |Ai,j | \u221a M2X 2 dX+2M2Y2 dY+2 logm\n.\nThis rate in Theorem 4, to our knowledge, establishes the state-of-the-art for FOMs with O(1 ) convergence rate for EFGs."}, {"heading": "7.1 Improvements in extensive-form game convergence rate", "text": "The ratio \u2126\u03d5 of set diameter over the strong convexity parameter is important for FOMs that rely on a prox function, such as EGT and MP. Compared to the rate obtained by [Kroer et al., 2015], we get the following improvement: for simplicity, assume that the number of actions available at each information set is on average a, then our bound improves the convergence rate of [Kroer et al., 2015] by a factor of \u2126(dX \u00b7 adX + dY \u00b7 adY ).\nAs mentioned previously, Hoda et al. [2010] proved only explicit bounds for the special case of uniform treeplexes that are constructed as follows: 1) A base treeplex Qb along with a subset of b indices from it for branching operations is chosen. 2) At each depth d, a Cartesian product operation of size k is applied. 3) Each element in a Cartesian product is an instance of the base treeplex with a size b branching operation leading to depth d \u2212 1 uniform treeplexes constructed in the same way. Given bounds \u2126b, \u03d5b for the base treeplex, the bound of Hoda et al. [2010] for a uniform treeplex with d uniform treeplex levels (note that the total depth of the constructed treeplex is d \u00b7 dQb , where dQb is the depth of the base treeplex Qb) is\n\u2126 \u03d5 \u2264 O ( b2d\u22122k2d+2d2M2Qb \u2126b \u03d5b ) .\nThen when the base treeplex is a simplex of dimension m, their bound for the dilated entropy on a uniform treeplex Q becomes\n\u2126 \u03d5 \u2264 O\n( |SQ|2 d2Q logm ) .\nEven for the special case of a uniform treeplex with a base simplex, comparing Theorem 3 to their bound, we see that our general bound improves the associated constants by exchanging O(|SQ|2 d2Q) with O(M2Q2\ndQ). Since MQ does not depend on the branching operation in the treeplex, whereas |SQ| does, these are also the first bounds to remove an exponential dependence on the branching operation (we have only a logarithmic dependence). In Example 1 we showed that there exist games where MQ = \u221a |SQ|, and in general MQ is much smaller than |SQ|. Consequently, our results establish the best known convergence results for all FOMs based on dilated entropy DGF such as EGT, MP, and stochastic variants of BSPP algorithms.\nCFR, CFR+, and EGT all need to keep track of a constant number of current and/or average iterates, so the memory usage of all three algorithms is of the same order; when gradients are computed using an iterative approach as opposed to storing matrices or matrix decompositions, each algorithm requires a constant times the number of sequences in the sequence-form representation. Therefore, we compare mainly the number of iterations required by each algorithm. Since the theoretical properties of CFR and CFR+ are comparable, we compare to CFR, with all statements being valid for CFR+ as well.\nCFR has a O( 1 2\n) convergence rate; but its dependence on the number of information sets is only linear (and sometimes sublinear [Lanctot et al., 2009]). Since our results have a quadratic dependence on M2Q, CFR sometimes has a better dependence on game constants and can be more attractive for obtaining low-quality solutions quickly for games with many information sets. MCCFR and CFR+ have a similar convergence rate [Lanctot et al., 2009], though MCCFR has cheaper iterations.\nGilpin et al. [2012] give an equilibrium-finding algorithm presented as O(ln(1 )); but this form of their bound has a dependence on a certain condition number of the A matrix. Specifically, their iteration bound for sequential games is O( \u2016A\u20162,2\u00b7ln(\u2016A\u20162,2/ )\u00b7 \u221a D\n\u03b4(A) ), where \u03b4(A) is the condition number\nof A, \u2016A\u20162,2 = supx 6=0 \u2016Ax\u20162 \u2016x\u20162 is the Euclidean matrix norm, and D = maxx,x\u0304\u2208X ,y,y\u0304\u2208Y \u2016(x, y) \u2212 (x\u0304, y\u0304)\u201622. Unfortunately, the condition number \u03b4(A) is only shown to be finite for these games. Without any such unknown quantities based on condition numbers, Gilpin et al. [2012] establish a convergence rate of O( \u2016A\u20162,2\u00b7D\n). This algorithm, despite having the same dependence on as ours in its convergence rate, i.e., O(1 ), suffers from worse constants. In particular, there exist matrices such\nthat \u2016A\u20162,2 = \u221a \u2016A\u20161,\u221e\u2016A\u2016\u221e,1, where \u2016A\u20161,\u221e and \u2016A\u2016\u221e,1 correspond to the maximum absolute column and row sums, respectively. Then together with the value of D, this leads to a cubic dependence on the dimension of Q. For games where the players have roughly equal-size strategy spaces, this is equivalent to a constant of O(M4Q) as opposed to our constant of O(M 2 Q)."}, {"heading": "8 Numerical experiments", "text": "We carry out numerical experiments to investigate the practical performance of EGT on EFGs when instantiated with our DGF.\nWe test these algorithms on a scaled up variant of the poker game Leduc holdem [Southey et al., 2005], a benchmark problem in the imperfect-information game-solving community. In our version, the deck consists of k pairs of cards 1 . . . k, for a total deck size of 2k. Each player initially pays one chip to the pot, and is dealt a single private card. After a round of betting, a community card is dealt face up. After a subsequent round of betting, if neither player has folded, both players reveal their private cards. If either player pairs their card with the community card they win the pot. Otherwise, the player with the highest private card wins. In the event both players have the same private card, they draw and split the pot.\nFirst, we investigate the impact of applying the weights used in recurrence (6), as compared to the previous scheme introduced in Kroer et al. [2015]. To instantiate recurrence (6) we have to choose a way to set \u03b2j relative to \u03b1j . Experimentally, we found that the best way to instantiate the recurrence is to use \u03b2j = \u03b1j for all j, in spite of the strict inequality required for our proof. This scheme will henceforth be referred to as new weights. We compare these new weights to the weights used in Kroer et al. [2015] (henceforth referred to as old weights). Figure 2 shows the result of running EGT with the old and the new weights. For both the old and the new weights, we found that the scalars MQ and |SQ| applied to each DGF in order to achieve strong convexity modulus 1 according to Corollary 1 and Theorem 5.4 of Kroer et al. [2015], respectively, are too conservative. Instead, we show the results after tuning these parameters for the corresponding algorithms to yield the best results for each weight scheme. Anecdotally, we found that the old weights are more sensitive and more difficult to tune. The performance also seems more jittery; this is evident even in the strongest parameter we found (especially noticeable on 10, 16, and 30-card Leduc in Figure 2).\nWe compare the performance of EGT to that of CFR and CFR+ algorithms on a scaled up variant of the poker game Leduc hold\u2019em [Southey et al., 2005], a benchmark problem in the\nimperfect-information game-solving community. In our version, the deck consists of k pairs of cards 1 . . . k, for a total deck size of 2k. Setting k = 3 yields the standard Leduc game. Each player initially pays one chip to the pot, and is dealt a single private card. After a round of betting, a community card is dealt face up. After a subsequent round of betting, if neither player has folded, both players reveal their private cards. If either player pairs their card with the community card, they win the pot. Otherwise, the player with the highest private card wins. In the event both players have the same private card, they draw and split the pot.\nThe results are shown in Figure 3. Each graph is a loglog plot that shows the results for a particular instance of Leduc with 6, 10, 16 and 30 card decks, respectively. For each graph, we show the performance of all three algorithms, with the x-axis showing the number of tree traversals, and the y-axis showing the sum of regrets over the two players. We note that tree-travels is a good proxy for overall computational effort because the majority of the time in FOMs is spent on gradient computations, which in our case directly translates into tree-traversals. We find that EGT instantiated with our DGF significantly outperforms both CFR and CFR+ across all four variants of Leduc. This is the case across all iterations; EGT finds a stronger initial point in x0, y0 (see Algorithm 1), and maintains a stronger convergence rate across all iterations.\nThe performance we get from EGT relative to CFR and CFR+ is surprising due to what the conventional wisdom in the field has been. In Kroer et al. [2015] it was found that, while EGT has better convergence rate, CFR (which performs worse than CFR+) had better initial performance, and it was only after a certain number of iterations that EGT took over. Furthermore, the switch point where EGT is preferable was found to shift outward on the x-axis as the Leduc game size was increased. This sentiment has been mirrored by Brown and Sandholm [2016]. In contrast to this, we find that our DGF along with proper initialization leads to EGT performing better than\nnot only CFR, but also CFR+, at every point on the x-axis. Furthermore, scaling up the game size does not seem to adversely affect this relationship.\nWhile the experiments in Figure 3 are very interesting from the perspective of which algorithm to use for large-scale EFG-solving in practice going forward, there are some caveats to keep in mind. First, we only considered number of tree traversals in our performance calculations. However, CFR algorithms have the ability to avoid parts of the tree traversal. For games where accelerated bestresponse calculation [Johanson et al., 2011] can be applied, e.g., poker-like games, this is unlikely to have a big effect. But, for some other games, this aspect can be important, though note that Brown et al. [2017] showed experimentally that pruning can be used in EGT as well. Second, to get superior performance from EGT, we had to hand-tune initialization parameters relating to our DGF, whereas CFR+ requires no tuning. Development of an algorithmic scheme for choosing this tuning parameter in EGT can make it significantly easier to apply the tuned variant of EGT in practice. Third, on another practical aspect, CFR+ is a conceptually very simple algorithm, and thus also easy to implement. In contrast to this, EGT and our DGF requires a safe-guarded numerical implementation because the prox operator associated with our DGF requires taking exponentials."}, {"heading": "9 Conclusions", "text": "We have investigated FOMs for computing Nash equilibria in two-player zero-sum perfect-recall EFGs. On the theoretical side, we analyzed the strong convexity properties of the dilated entropy DGF over treeplexes. By introducing specific weights that are tied to the structure of the treeplex, we improved prior results on treeplex diameter from O(|SQ|MQd2d logm) to O(M2Q2dQ+2 logm), thereby removing all but a logarithmic dependence on branching associated with the branching operator in the treeplex definition. These results lead to significant improvements in the convergence rates of many FOMs that can be equipped with dilated entropy DGFs and used for EFG solving including but not limited to EGT, MP, and Stochastic MP.\nWe numerically investigated the performance of EGT and compared it to the practical state-ofthe-art algorithms CFR and CFR+. Our experiments showed that EGT with the dilated entropy DGF, when tuned with a proper scaling, has better practical, as well as theoretical, convergence rate than CFR+, the current state-of-the-art algorithm in practice. While our scaling parameter for the DGF did not require extensive tuning, we believe a more principled way of setting it is worthy of further future investigation.\nTheorems 1 and 2 establish bounds for a general class of weights \u03b2j satisfying the recurrence (6). Then in Corollary 1, we have selected a particular weighting scheme for \u03b2j satisfying (6) and performed our numerical tests. There may be other interesting choices of \u03b2j satisfying the recurrence (6). Thus, finding a way to optimally choose among the set of weights satisfying (6) to minimize the polytope diameter for specific games is appealing.\nOn a separate note, in practice CFR is often paired with an abstraction technique [Sandholm, 2010] such as those mentioned in Section 2. This is despite the lack of any theoretical justification. Effective ways to pair FOMs such as MP and EGT with practical abstraction techniques [Brown et al., 2015] or abstraction techniques that achieve solution-quality guarantees [Lanctot et al., 2012, Kroer and Sandholm, 2014, 2016] are also worth further consideration."}, {"heading": "A Omitted proofs", "text": "A.1 Proof of Lemma 1\nProof. Consider q \u2208 ri (Q) and any h \u2208 Rn. For each j \u2208 SQ and i \u2208 Ij , the second-order partial derivates of \u03c9(\u00b7) w.r.t. qi are:\n\u22072q2i \u03c9(q) = \u03b2j qi + \u2211 k\u2208Dij \u2211 l\u2208Ik \u03b2kql q2i = \u03b2j qi + \u2211 k\u2208Dij \u03b2k qi , (11)\nwhere the last equality holds because k \u2208 Dij and thus \u2211 l\u2208Ik ql = \u2016q k\u20161 = qpk = qi. Also, for each j \u2208 SQ, i \u2208 Ij , k \u2208 Dij , and l \u2208 Ik, the second-order partial derivates w.r.t. qi, ql are given by:\n\u22072qi,ql\u03c9(q) = \u2207 2 ql,qi \u03c9(q) = \u2212\u03b2k qi . (12)\nThen equations (11) and (12) together imply\nh>\u22072\u03c9(q)h = \u2211 j\u2208SQ \u2211 i\u2208Ij h2i \u03b2j qi + \u2211 k\u2208Dij \u03b2k qi \u2212 \u2211 k\u2208Dij \u2211 l\u2208Ik hihl 2\u03b2k qi  . (13) Given j \u2208 SQ and i \u2208 Ij , we have pk = i for each k \u2208 Dij and for any k \u2208 Dij , there exists some other j\u2032 \u2208 SQ corresponding to k in the outermost summation. Then we can rearrange the following terms:\u2211\nj\u2208SQ \u2211 i\u2208Ij h2i \u2211 k\u2208Dij \u03b2k qi = \u2211 j\u2208SQ \u03b2j h2pj qpj and \u2211 j\u2208SQ \u2211 i\u2208Ij \u2211 k\u2208Dij \u2211 l\u2208Ik hihl 2\u03b2k qi = \u2211 j\u2208SQ \u2211 i\u2208Ij \u03b2j 2hihpj qpj .\nUsing these two equalities in (13) leads to (7) and proves the lemma.\nA.2 Proof of Theorem 3\nProof. For our choice of scaled weights \u03b2j , Corollary 1 implies that the resulting dilated entropy function is strongly convex with modulus \u03d5 = 1. Hence, we only need to bound \u2126.\nAny vector q \u2208 Q satisfying qi \u2208 {0, 1} for all i maximizes \u03c9(q) and results in maxq\u2208Q \u03c9(q) = 0. For the minimum value, consider any q \u2208 ri (Q). Applying the well-known lower bound of \u2212 logm for the negative entropy function on an m-dimensional simplex, we have\n\u03c9(q) = \u2211 j\u2208SQ \u03b2jqpj \u2211 i\u2208Ij qi qpj log qi qpj \u2265 \u2212 \u2211 j\u2208SQ \u03b2jqpj logm = \u2212 dQ\u2211 d=0 \u2211 j\u2208SQ:dj=d \u03b2jqpj logm\n= \u2212 dQ\u2211 d=1 \u2211 j\u2208SQ:dj=d \u03b2jqpj logm\u2212 \u2211 j\u2208SQ:dj=0 \u03b2jqpj logm = \u2212MQ logm dQ\u2211 d=1 \u2211 j\u2208SQ:dj=d qpj ( 2 + d\u2211 r=1 2r(MQj ,r \u2212 1) ) \u2212MQ \u2211 j\u2208SQ:dj=0 2qpj logm \u2265 \u2212MQ logm dQ\u2211 d=1 \u2211 j\u2208SQ:dj=d qpjMQj d\u2211 r=1 2r \u2212 2MQ logm \u2211 j\u2208SQ:dj=0 qpj , (14)\nwhere the last inequality follows because for each j \u2208 SQ with dj = 0, the definition of MQ implies \u2211 j\u2208SQ:dj=0 qpj \u2264MQ, and for each j \u2208 SQ with dj = d \u2265 1, we have 2+ \u2211d r=1 2\nr(MQj ,r\u22121) \u2264\u2211d r=1 2 rMQj ,r \u2264 \u2211d r=1 2 rMQj sinceMQj,r \u2264MQj . Also, from Fact 1(b), we have \u2211 j\u2208SQ:dj=d qpjMQj \u2264 MQ. Then we arrive at\n(14) \u2265 \u2212M2Q logm ( 2 + dQ\u2211 d=1 d\u2211 r=1 2r ) = \u2212M2Q logm ( 2 + dQ\u2211 d=1 (2d+1 \u2212 2) )\n= \u2212M2Q logm ( 2 + dQ\u2211 d=1 2d+1 \u2212 2dQ ) \u2265 \u2212M2Q(logm)2dQ+2,\nwhere the last inequality follows because for dQ = 0 we have 2 dQ+2 = 4 > 2 and for dQ \u2265 1 we have 2dQ \u2265 2. This lower bound on the minimum value, i.e., minq\u2208Q \u03c9(q) \u2265 \u2212M2Q(logm)2dQ+2, coupled with maxq\u2208Q \u03c9(q) \u2264 0, establishes the theorem."}], "references": [{"title": "An exact doubleoracle algorithm for zero-sum extensive-form games with imperfect information", "author": ["Branislav Bosansky", "Christopher Kiekintveld", "Viliam Lisy", "Michal Pechoucek"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Bosansky et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bosansky et al\\.", "year": 2014}, {"title": "Heads-up limit hold\u2019em poker is solved", "author": ["Michael Bowling", "Neil Burch", "Michael Johanson", "Oskari Tammelin"], "venue": "Science,", "citeRegEx": "Bowling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bowling et al\\.", "year": 2015}, {"title": "Regret transfer and parameter optimization", "author": ["Noam Brown", "Tuomas Sandholm"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Brown and Sandholm.,? \\Q2014\\E", "shortCiteRegEx": "Brown and Sandholm.", "year": 2014}, {"title": "Strategy-based warm starting for regret minimization in games", "author": ["Noam Brown", "Tuomas Sandholm"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Brown and Sandholm.,? \\Q2016\\E", "shortCiteRegEx": "Brown and Sandholm.", "year": 2016}, {"title": "Hierarchical abstraction, distributed equilibrium computation, and post-processing, with application to a champion no-limit Texas Hold\u2019em agent", "author": ["Noam Brown", "Sam Ganzfried", "Tuomas Sandholm"], "venue": "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS),", "citeRegEx": "Brown et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Brown et al\\.", "year": 2015}, {"title": "Dynamic thresholding and pruning for regret minimization", "author": ["Noam Brown", "Christian Kroer", "Tuomas Sandholm"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Brown et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Brown et al\\.", "year": 2017}, {"title": "The complexity of computing a nash equilibrium", "author": ["Constantinos Daskalakis", "Paul W Goldberg", "Christos H Papadimitriou"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Daskalakis et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Daskalakis et al\\.", "year": 2009}, {"title": "Near-optimal no-regret algorithms for zero-sum games", "author": ["Constantinos Daskalakis", "Alan Deckelbaum", "Anthony Kim"], "venue": "Games and Economic Behavior,", "citeRegEx": "Daskalakis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Daskalakis et al\\.", "year": 2015}, {"title": "Lossless abstraction of imperfect information games", "author": ["Andrew Gilpin", "Tuomas Sandholm"], "venue": "Journal of the ACM,", "citeRegEx": "Gilpin and Sandholm.,? \\Q2007\\E", "shortCiteRegEx": "Gilpin and Sandholm.", "year": 2007}, {"title": "First-order algorithm with O(ln(1/ )) convergence for -equilibrium in two-person zero-sum games", "author": ["Andrew Gilpin", "Javier Pe\u00f1a", "Tuomas Sandholm"], "venue": "Mathematical Programming,", "citeRegEx": "Gilpin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gilpin et al\\.", "year": 2012}, {"title": "Automated action abstraction of imperfect information extensive-form games", "author": ["John Hawkin", "Robert Holte", "Duane Szafron"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Hawkin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hawkin et al\\.", "year": 2011}, {"title": "Using sliding windows to generate action abstractions in extensive-form games", "author": ["John Hawkin", "Robert Holte", "Duane Szafron"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Hawkin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hawkin et al\\.", "year": 2012}, {"title": "Fundamentals of convex analysis", "author": ["Jean-Baptiste Hiriart-Urruty", "Claude Lemar\u00e9chal"], "venue": null, "citeRegEx": "Hiriart.Urruty and Lemar\u00e9chal.,? \\Q2001\\E", "shortCiteRegEx": "Hiriart.Urruty and Lemar\u00e9chal.", "year": 2001}, {"title": "Smoothing techniques for computing Nash equilibria of sequential games", "author": ["Samid Hoda", "Andrew Gilpin", "Javier Pe\u00f1a", "Tuomas Sandholm"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Hoda et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hoda et al\\.", "year": 2010}, {"title": "Polynomial-time computation of exact correlated equilibrium in compact games", "author": ["Albert Jiang", "Kevin Leyton-Brown"], "venue": "In Proceedings of the ACM Conference on Electronic Commerce (EC),", "citeRegEx": "Jiang and Leyton.Brown.,? \\Q2011\\E", "shortCiteRegEx": "Jiang and Leyton.Brown.", "year": 2011}, {"title": "Accelerating best response calculation in large extensive games", "author": ["Michael Johanson", "Kevin Waugh", "Michael Bowling", "Martin Zinkevich"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Johanson et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Johanson et al\\.", "year": 2011}, {"title": "First order methods for nonsmooth convex large-scale optimization, i: general purpose methods", "author": ["Anatoli Juditsky", "Arkadi Nemirovski"], "venue": "Optimization for Machine Learning,", "citeRegEx": "Juditsky and Nemirovski.,? \\Q2011\\E", "shortCiteRegEx": "Juditsky and Nemirovski.", "year": 2011}, {"title": "First order methods for nonsmooth convex large-scale optimization, ii: utilizing problems structure", "author": ["Anatoli Juditsky", "Arkadi Nemirovski"], "venue": "Optimization for Machine Learning,", "citeRegEx": "Juditsky and Nemirovski.,? \\Q2011\\E", "shortCiteRegEx": "Juditsky and Nemirovski.", "year": 2011}, {"title": "Efficient computation of equilibria for extensive two-person games", "author": ["Daphne Koller", "Nimrod Megiddo", "Bernhard von Stengel"], "venue": "Games and Economic Behavior,", "citeRegEx": "Koller et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Koller et al\\.", "year": 1996}, {"title": "Extensive-form game abstraction with bounds", "author": ["Christian Kroer", "Tuomas Sandholm"], "venue": "In Proceedings of the ACM Conference on Economics and Computation (EC),", "citeRegEx": "Kroer and Sandholm.,? \\Q2014\\E", "shortCiteRegEx": "Kroer and Sandholm.", "year": 2014}, {"title": "Imperfect-recall abstractions with bounds in games", "author": ["Christian Kroer", "Tuomas Sandholm"], "venue": "In Proceedings of the ACM Conference on Economics and Computation", "citeRegEx": "Kroer and Sandholm.,? \\Q2016\\E", "shortCiteRegEx": "Kroer and Sandholm.", "year": 2016}, {"title": "Faster first-order methods for extensive-form game solving", "author": ["Christian Kroer", "Kevin Waugh", "Fatma K\u0131l\u0131n\u00e7-Karzan", "Tuomas Sandholm"], "venue": "In Proceedings of the ACM Conference on Economics and Computation (EC),", "citeRegEx": "Kroer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kroer et al\\.", "year": 2015}, {"title": "Monte Carlo sampling for regret minimization in extensive games", "author": ["Marc Lanctot", "Kevin Waugh", "Martin Zinkevich", "Michael Bowling"], "venue": "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Lanctot et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lanctot et al\\.", "year": 2009}, {"title": "No-regret learning in extensive-form games with imperfect recall", "author": ["Marc Lanctot", "Richard Gibson", "Neil Burch", "Martin Zinkevich", "Michael Bowling"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Lanctot et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lanctot et al\\.", "year": 2012}, {"title": "Playing large games using simple strategies", "author": ["Richard Lipton", "Evangelos Markakis", "Aranyak Mehta"], "venue": "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC),", "citeRegEx": "Lipton et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Lipton et al\\.", "year": 2003}, {"title": "A polynomial-time Nash equilibrium algorithm for repeated games", "author": ["Michael Littman", "Peter Stone"], "venue": "In Proceedings of the ACM Conference on Electronic Commerce (ACM-EC),", "citeRegEx": "Littman and Stone.,? \\Q2003\\E", "shortCiteRegEx": "Littman and Stone.", "year": 2003}, {"title": "Deepstack: Expert-level artificial intelligence in no-limit poker", "author": ["Matej Morav\u010d\u0301\u0131k", "Martin Schmid", "Neil Burch", "Viliam Lis\u1ef3", "Dustin Morrill", "Nolan Bard", "Trevor Davis", "Kevin Waugh", "Michael Johanson", "Michael Bowling"], "venue": "arXiv preprint arXiv:1701.01724,", "citeRegEx": "Morav\u010d\u0301\u0131k et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Morav\u010d\u0301\u0131k et al\\.", "year": 2017}, {"title": "Prox-method with rate of convergence o (1/t) for variational inequalities with lipschitz continuous monotone operators and smooth convex-concave saddle point problems", "author": ["Arkadi Nemirovski"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nemirovski.,? \\Q2004\\E", "shortCiteRegEx": "Nemirovski.", "year": 2004}, {"title": "Excessive gap technique in nonsmooth convex minimization", "author": ["Yurii Nesterov"], "venue": "SIAM Journal of Optimization,", "citeRegEx": "Nesterov.,? \\Q2005\\E", "shortCiteRegEx": "Nesterov.", "year": 2005}, {"title": "Smooth minimization of non-smooth functions", "author": ["Yurii Nesterov"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov.,? \\Q2005\\E", "shortCiteRegEx": "Nesterov.", "year": 2005}, {"title": "Reduction of a game with complete memory to a matrix game", "author": ["I. Romanovskii"], "venue": "Soviet Mathematics,", "citeRegEx": "Romanovskii.,? \\Q1962\\E", "shortCiteRegEx": "Romanovskii.", "year": 1962}, {"title": "The state of solving large incomplete-information games, and application to poker", "author": ["Tuomas Sandholm"], "venue": "AI Magazine,", "citeRegEx": "Sandholm.,? \\Q2010\\E", "shortCiteRegEx": "Sandholm.", "year": 2010}, {"title": "Abstraction for solving large incomplete-information games", "author": ["Tuomas Sandholm"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Sandholm.,? \\Q2015\\E", "shortCiteRegEx": "Sandholm.", "year": 2015}, {"title": "Lossy stochastic game abstraction with bounds", "author": ["Tuomas Sandholm", "Satinder Singh"], "venue": "In Proceedings of the ACM Conference on Electronic Commerce (EC),", "citeRegEx": "Sandholm and Singh.,? \\Q2012\\E", "shortCiteRegEx": "Sandholm and Singh.", "year": 2012}, {"title": "Abstraction methods for game theoretic poker", "author": ["Jiefu Shi", "Michael Littman"], "venue": "In CG \u201900: Revised Papers from the Second International Conference on Computers and Games,", "citeRegEx": "Shi and Littman.,? \\Q2002\\E", "shortCiteRegEx": "Shi and Littman.", "year": 2002}, {"title": "bluff: Opponent modelling in poker", "author": ["Finnegan Southey", "Michael Bowling", "Bryce Larson", "Carmelo Piccione", "Neil Burch", "Darse Billings", "Chris Rayner. Bayes"], "venue": "In Proceedings of the 21st Annual Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Southey et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Southey et al\\.", "year": 2005}, {"title": "Solving heads-up limit Texas hold\u2019em", "author": ["Oskari Tammelin", "Neil Burch", "Michael Johanson", "Michael Bowling"], "venue": "In Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Tammelin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tammelin et al\\.", "year": 2015}, {"title": "Efficient computation of behavior strategies", "author": ["Bernhard von Stengel"], "venue": "Games and Economic Behavior,", "citeRegEx": "Stengel.,? \\Q1996\\E", "shortCiteRegEx": "Stengel.", "year": 1996}, {"title": "A unified view of large-scale zero-sum equilibrium computation", "author": ["Kevin Waugh", "Drew Bagnell"], "venue": "In Computer Poker and Imperfect Information Workshop at the AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Waugh and Bagnell.,? \\Q2015\\E", "shortCiteRegEx": "Waugh and Bagnell.", "year": 2015}, {"title": "Regret minimization in games with incomplete information", "author": ["Martin Zinkevich", "Michael Bowling", "Michael Johanson", "Carmelo Piccione"], "venue": "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Zinkevich et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Zinkevich et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 31, "context": "Second, even when it does, the iterations of interior-point methods or the simplex algorithm are prohibitively expensive [Sandholm, 2010].", "startOffset": 121, "endOffset": 137}, {"referenceID": 31, "context": "Practical methods for EFG solving tackle this issue through two complementary approaches: Abstraction and iterative game solvers with low memory requirements [Sandholm, 2010].", "startOffset": 158, "endOffset": 174}, {"referenceID": 27, "context": "The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains.", "startOffset": 59, "endOffset": 77}, {"referenceID": 36, "context": "Finally, we complement our theoretical results with numerical experiments to investigate the speed up of FOMs with convergence rate O( ) and compare the performance of these algorithms with the premier regret-based methods CFR and CFR+ [Tammelin et al., 2015].", "startOffset": 236, "endOffset": 259}, {"referenceID": 12, "context": ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes\u2014a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG.", "startOffset": 100, "endOffset": 1210}, {"referenceID": 12, "context": ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes\u2014a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al.", "startOffset": 100, "endOffset": 1577}, {"referenceID": 12, "context": ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes\u2014a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al. [2010]. These bounds from Kroer et al.", "startOffset": 100, "endOffset": 1782}, {"referenceID": 12, "context": ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes\u2014a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al. [2010]. These bounds from Kroer et al. [2015] generate the current state-of-the-art parameters associated with the convergence rate for FOMs with O( ) convergence.", "startOffset": 100, "endOffset": 1821}, {"referenceID": 12, "context": ", 2009] achieving a convergence rate on the order of O( 1 2 ), and (ii) first-order methods (FOMs) [Hoda et al., 2010, Kroer et al., 2015] achieving a convergence rate of O( ). The better convergence rate of FOMs makes them more attractive from a theoretical viewpoint. This paper investigates the acceleration of such FOMs for EFGs, from both a theoretical and a numerical perspective. Nash equilibrium computation of a two-player zero-sum EFG with perfect recall admits a Bilinear Saddle Point Problem (BSPP) formulation where the domains are given by the polytopes that encode strategy spaces of the players. The most efficient FOMs are designed to solve this BSPP. The classical FOMs to solve BSPPs such as mirror prox (MP) [Nemirovski, 2004] or the excessive gap technique (EGT) [Nesterov, 2005a] utilize distance-generating functions (DGFs) to measure appropriate notions of distances over the domains. Then the convergence rate of these FOMs relies on the DGFs and their relation to the domains in three critical ways: Through the strong convexity parameters of the DGFs, the norm associated with the strong convexity parameter, and set widths of the domains as measured by the DGFs. Hoda et al. [2010] introduced a general framework for constructing DGFs for treeplexes\u2014a class of convex polytopes that generalize the domains associated with the strategy spaces of an EFG. While they also established bounds on the strong convexity parameter for their DGFs in some special cases, these lead to very weak bounds and result in slow convergence rates. Kroer et al. [2015] developed explicit strong convexity-parameter bounds for entropy-based DGFs (a particular subclass of DGFs) for general EFGs, and improved the bounds for the special cases considered by Hoda et al. [2010]. These bounds from Kroer et al. [2015] generate the current state-of-the-art parameters associated with the convergence rate for FOMs with O( ) convergence. In this paper we construct a new weighting scheme for such entropy-based DGFs. This weighting scheme leads to new and improved bounds on the strong convexity parameter associated with general treeplex domains. In particular, our new bounds are first-of-their kind as they have no dependence on the branching operation of the treeplex. Informally, our strong convexity result allows us to improve the convergence rate of FOMs by a factor of \u03a9(bdd) (where b is the average branching factor for a player and d is the depth of the EFG) compared to the prior state-of-the-art results from Kroer et al. [2015]. Our bounds parallel the simplex case for matrix games where the entropy function achieves a logarithmic dependence on the dimension of the simplex domain.", "startOffset": 100, "endOffset": 2543}, {"referenceID": 1, "context": "Bowling et al. [2015] used it to essentially solve the game limit Texas hold\u2019em.", "startOffset": 0, "endOffset": 22}, {"referenceID": 25, "context": "A slight variation2 of CFR+ was used in the DeepStack agent Morav\u010d\u0301\u0131k et al. [2017], which beat a group of professional players.", "startOffset": 60, "endOffset": 84}, {"referenceID": 21, "context": "We also test the impact of stronger bounds on the strong convexity parameter: we instantiate EGT with the parameters developed in this paper, and compare the performance to the parameters developed by Kroer et al. [2015]. These experiments illustrate that the tighter parameters developed here lead to better practical convergence rate.", "startOffset": 201, "endOffset": 221}, {"referenceID": 31, "context": "These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010].", "startOffset": 122, "endOffset": 138}, {"referenceID": 39, "context": "The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al.", "startOffset": 146, "endOffset": 170}, {"referenceID": 22, "context": ", 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+).", "startOffset": 60, "endOffset": 82}, {"referenceID": 6, "context": ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree.", "startOffset": 8, "endOffset": 290}, {"referenceID": 6, "context": ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, was used to solve Rhode-Island hold\u2019em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion nodes (roughly size 5 \u00b7 107 after lossless abstraction). However, for games larger than this, the resulting LPs tend to not fit in the computer memory thus requiring approximate solution techniques. These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010]. The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+). These regret-minimization algorithms perform local regret-based updates at each information set. Despite their slow convergence rate of O( 1 2 ), they perform very well in pratice, especially CFR+. Recently, Waugh and Bagnell [2015] showed, with some caveats, an interpretation of CFR as a FOM with O( 1 2 ) rate.", "startOffset": 8, "endOffset": 1449}, {"referenceID": 6, "context": ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, was used to solve Rhode-Island hold\u2019em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion nodes (roughly size 5 \u00b7 107 after lossless abstraction). However, for games larger than this, the resulting LPs tend to not fit in the computer memory thus requiring approximate solution techniques. These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010]. The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+). These regret-minimization algorithms perform local regret-based updates at each information set. Despite their slow convergence rate of O( 1 2 ), they perform very well in pratice, especially CFR+. Recently, Waugh and Bagnell [2015] showed, with some caveats, an interpretation of CFR as a FOM with O( 1 2 ) rate. Nonetheless, in this paper we make a distinction between regret-based methods and O( ) FOMs for ease of exposition. Hoda et al. [2010] initially proposed DGFs for EFGs leading to O( ) convergence rate when used with EGT.", "startOffset": 8, "endOffset": 1665}, {"referenceID": 6, "context": ", 2007, Daskalakis et al., 2009, Jiang and Leyton-Brown, 2011, Kroer and Sandholm, 2014, Daskalakis et al., 2015]. The equilibrium-finding problems vary quite a bit based on their characteristics; here we restrict our attention to two-player zero-sum sequential games. Koller et al. [1996] present an LP whose size is linear in the size of the game tree. This approach, coupled with lossless abstraction techniques, was used to solve Rhode-Island hold\u2019em [Shi and Littman, 2002, Gilpin and Sandholm, 2007], a game with 3.1 billion nodes (roughly size 5 \u00b7 107 after lossless abstraction). However, for games larger than this, the resulting LPs tend to not fit in the computer memory thus requiring approximate solution techniques. These techniques fall into two categories: iterative -Nash equilibrium-finding algorithms and game abstraction techniques [Sandholm, 2010]. The most popular iterative Nash equilibrium algorithm is the counterfactual-regret-minimization framework instantiated with regret matching (CFR) [Zinkevich et al., 2007], its sampling-based variant monte-carlo CFR (MCCFR) [Lanctot et al., 2009], and CFR instantitated with a new regret minimization technique called regret matching plus (CFR+). These regret-minimization algorithms perform local regret-based updates at each information set. Despite their slow convergence rate of O( 1 2 ), they perform very well in pratice, especially CFR+. Recently, Waugh and Bagnell [2015] showed, with some caveats, an interpretation of CFR as a FOM with O( 1 2 ) rate. Nonetheless, in this paper we make a distinction between regret-based methods and O( ) FOMs for ease of exposition. Hoda et al. [2010] initially proposed DGFs for EFGs leading to O( ) convergence rate when used with EGT. Kroer et al. [2015] improved these result for the dilated entropy function.", "startOffset": 8, "endOffset": 1771}, {"referenceID": 33, "context": "Sequential game abstraction approaches with solution quality bounds have also emerged for stochastic [Sandholm and Singh, 2012] and extensive-form [Lanctot et al.", "startOffset": 101, "endOffset": 127}, {"referenceID": 0, "context": "Finally, Bosansky et al. [2014] develop an iterative double-oracle algorithm for exact equilibrium computation.", "startOffset": 9, "endOffset": 32}, {"referenceID": 16, "context": "This is known as the sequence-form formulation [Romanovskii, 1962, Koller et al., 1996, von Stengel, 1996]. In this formulation, x and y correspond to the nonnegative strategy vectors for players 1 and 2 and the sets X ,Y are convex polyhedral reformulations of the sequential strategy space of these players. Here X ,Y are defined by the constraints Ex = e, Fy = f , where each row of E,F encodes part of the sequential nature of the strategy vectors, the right hand-side vectors e, f are |I1| , |I2|-dimensional vectors, and Ii is the information sets for player i. For a complete treatment of this formulation, see von Stengel [1996]. Our theoretical developments mainly exploit the treeplex domain structure and are independent of other structural assumptions resulting from EFGs.", "startOffset": 67, "endOffset": 637}, {"referenceID": 16, "context": "We follow the presentation and notation of Juditsky and Nemirovski [2011a,b] for BSPPs. For notation and presentation of treeplex structure, we follow Kroer et al. [2015].", "startOffset": 43, "endOffset": 171}, {"referenceID": 28, "context": "Nesterov [2005b] shows that the gradients of the functions \u03c6\u03bc2(x) and \u03c6 \u03bc1 (y) exist and are Lipschitz continuous.", "startOffset": 0, "endOffset": 17}, {"referenceID": 28, "context": "Based on this setup, we formally state the Excessive Gap Technique (EGT) of Nesterov [2005a] in Algorithm 1.", "startOffset": 76, "endOffset": 93}, {"referenceID": 37, "context": "For treeplexes, von Stengel [1996] has suggested a polyhedral representation of the form Eu = e where the matrix E has its entries from {\u22121, 0, 1} and the vector e has its entries in {0, 1}.", "startOffset": 20, "endOffset": 35}, {"referenceID": 20, "context": "Note that we allow more than two-way branches; hence our formulation follows that of Kroer et al. [2015] and differs from that of Hoda et al.", "startOffset": 85, "endOffset": 105}, {"referenceID": 13, "context": "[2015] and differs from that of Hoda et al. [2010]. As discussed in Hoda et al.", "startOffset": 32, "endOffset": 51}, {"referenceID": 13, "context": "[2015] and differs from that of Hoda et al. [2010]. As discussed in Hoda et al. [2010], it is possible to model sequence-form games by treeplexes that use only two-way branches.", "startOffset": 32, "endOffset": 87}, {"referenceID": 12, "context": "The treeplex structure is naturally related to the dilation operation [Hiriart-Urruty and Lemar\u00e9chal, 2001] defined as follows: Given a compact set K \u2286 Rd and a function f : K \u2192 R, we first define", "startOffset": 70, "endOffset": 107}, {"referenceID": 15, "context": "It is well-known that \u03c9e(\u00b7) is strongly convex with modulus 1 with respect to the `1 norm on \u2206n (see Juditsky and Nemirovski [2011a]).", "startOffset": 101, "endOffset": 133}, {"referenceID": 13, "context": "Hoda et al. [2010] show that for any dilated function, its prox operator on a treeplex can be easily computed through a recursive bottom-up traversal involving the prox mappings associated with the function being dilated on individual simplexes.", "startOffset": 0, "endOffset": 19}, {"referenceID": 13, "context": "Hoda et al. [2010] show that for any dilated function, its prox operator on a treeplex can be easily computed through a recursive bottom-up traversal involving the prox mappings associated with the function being dilated on individual simplexes. Since the entropy prox function can be computed in closed form on a simplex, the dilated entropy function can be computed by a single treeplex traversal involving closed-form expressions on each simplex. Definition 3 above leads to a subset of the DGFs considered by Hoda et al. [2010]. Our main theoretical result shows that by a careful selection of the weights \u03b2j , we can significantly improve the strong convexity bounds associated with the dilated entropy function.", "startOffset": 0, "endOffset": 532}, {"referenceID": 21, "context": "To our knowledge, the best strong convexity bounds for general treeplexes were proved in Kroer et al. [2015]. Using weights \u03b2j = 2 MQj they show strong convexity modulus 1 |SQ| w.", "startOffset": 89, "endOffset": 109}, {"referenceID": 21, "context": "To our knowledge, the best strong convexity bounds for general treeplexes were proved in Kroer et al. [2015]. Using weights \u03b2j = 2 MQj they show strong convexity modulus 1 |SQ| w.r.t. the `1 norm. Corollary 1 improves the prior bounds by exchanging a factor of |SQ| with a factor of MQ. Note that |SQ| is tied to the branching factor associated with branching operations in the treeplex Q whereas MQ is not. Thus, our result removes the dependence of the strong convexity parameter on the branching factor and hence significantly improves upon Kroer et al. [2015]. In Theorem 3 we use our strong convexity result to establish a polytope diameter that has only a logarithmic dependence on the branching factor.", "startOffset": 89, "endOffset": 564}, {"referenceID": 21, "context": "Compared to the rate obtained by [Kroer et al., 2015], we get the following improvement: for simplicity, assume that the number of actions available at each information set is on average a, then our bound improves the convergence rate of [Kroer et al.", "startOffset": 33, "endOffset": 53}, {"referenceID": 21, "context": ", 2015], we get the following improvement: for simplicity, assume that the number of actions available at each information set is on average a, then our bound improves the convergence rate of [Kroer et al., 2015] by a factor of \u03a9(dX \u00b7 adX + dY \u00b7 adY ).", "startOffset": 192, "endOffset": 212}, {"referenceID": 13, "context": "As mentioned previously, Hoda et al. [2010] proved only explicit bounds for the special case of uniform treeplexes that are constructed as follows: 1) A base treeplex Qb along with a subset of b indices from it for branching operations is chosen.", "startOffset": 25, "endOffset": 44}, {"referenceID": 13, "context": "As mentioned previously, Hoda et al. [2010] proved only explicit bounds for the special case of uniform treeplexes that are constructed as follows: 1) A base treeplex Qb along with a subset of b indices from it for branching operations is chosen. 2) At each depth d, a Cartesian product operation of size k is applied. 3) Each element in a Cartesian product is an instance of the base treeplex with a size b branching operation leading to depth d \u2212 1 uniform treeplexes constructed in the same way. Given bounds \u03a9b, \u03c6b for the base treeplex, the bound of Hoda et al. [2010] for a uniform treeplex with d uniform treeplex levels (note that the total depth of the constructed treeplex is d \u00b7 dQb , where dQb is the depth of the base treeplex Qb) is", "startOffset": 25, "endOffset": 574}, {"referenceID": 22, "context": "CFR has a O( 1 2 ) convergence rate; but its dependence on the number of information sets is only linear (and sometimes sublinear [Lanctot et al., 2009]).", "startOffset": 130, "endOffset": 152}, {"referenceID": 22, "context": "MCCFR and CFR+ have a similar convergence rate [Lanctot et al., 2009], though MCCFR has cheaper iterations.", "startOffset": 47, "endOffset": 69}, {"referenceID": 9, "context": "Gilpin et al. [2012] give an equilibrium-finding algorithm presented as O(ln( )); but this form of their bound has a dependence on a certain condition number of the A matrix.", "startOffset": 0, "endOffset": 21}, {"referenceID": 9, "context": "Gilpin et al. [2012] give an equilibrium-finding algorithm presented as O(ln( )); but this form of their bound has a dependence on a certain condition number of the A matrix. Specifically, their iteration bound for sequential games is O( \u2016A\u20162,2\u00b7ln(\u2016A\u20162,2/ )\u00b7 \u221a D \u03b4(A) ), where \u03b4(A) is the condition number of A, \u2016A\u20162,2 = supx 6=0 \u2016Ax\u20162 \u2016x\u20162 is the Euclidean matrix norm, and D = maxx,x\u0304\u2208X ,y,\u0233\u2208Y \u2016(x, y) \u2212 (x\u0304, \u0233)\u20162. Unfortunately, the condition number \u03b4(A) is only shown to be finite for these games. Without any such unknown quantities based on condition numbers, Gilpin et al. [2012] establish a convergence rate of O( \u2016A\u20162,2\u00b7D ).", "startOffset": 0, "endOffset": 587}, {"referenceID": 35, "context": "We test these algorithms on a scaled up variant of the poker game Leduc holdem [Southey et al., 2005], a benchmark problem in the imperfect-information game-solving community.", "startOffset": 79, "endOffset": 101}, {"referenceID": 35, "context": "We compare the performance of EGT to that of CFR and CFR+ algorithms on a scaled up variant of the poker game Leduc hold\u2019em [Southey et al., 2005], a benchmark problem in the", "startOffset": 124, "endOffset": 146}, {"referenceID": 21, "context": "First, we investigate the impact of applying the weights used in recurrence (6), as compared to the previous scheme introduced in Kroer et al. [2015]. To instantiate recurrence (6) we have to choose a way to set \u03b2j relative to \u03b1j .", "startOffset": 130, "endOffset": 150}, {"referenceID": 21, "context": "First, we investigate the impact of applying the weights used in recurrence (6), as compared to the previous scheme introduced in Kroer et al. [2015]. To instantiate recurrence (6) we have to choose a way to set \u03b2j relative to \u03b1j . Experimentally, we found that the best way to instantiate the recurrence is to use \u03b2j = \u03b1j for all j, in spite of the strict inequality required for our proof. This scheme will henceforth be referred to as new weights. We compare these new weights to the weights used in Kroer et al. [2015] (henceforth referred to as old weights).", "startOffset": 130, "endOffset": 523}, {"referenceID": 21, "context": "First, we investigate the impact of applying the weights used in recurrence (6), as compared to the previous scheme introduced in Kroer et al. [2015]. To instantiate recurrence (6) we have to choose a way to set \u03b2j relative to \u03b1j . Experimentally, we found that the best way to instantiate the recurrence is to use \u03b2j = \u03b1j for all j, in spite of the strict inequality required for our proof. This scheme will henceforth be referred to as new weights. We compare these new weights to the weights used in Kroer et al. [2015] (henceforth referred to as old weights). Figure 2 shows the result of running EGT with the old and the new weights. For both the old and the new weights, we found that the scalars MQ and |SQ| applied to each DGF in order to achieve strong convexity modulus 1 according to Corollary 1 and Theorem 5.4 of Kroer et al. [2015], respectively, are too conservative.", "startOffset": 130, "endOffset": 846}, {"referenceID": 21, "context": "Figure 2: Regret as a function of the number of iterations for EGT with our weighting scheme (EGT new) and with the weighting scheme from Kroer et al. [2015] (EGT old).", "startOffset": 138, "endOffset": 158}, {"referenceID": 19, "context": "In Kroer et al. [2015] it was found that, while EGT has better convergence rate, CFR (which performs worse than CFR+) had better initial performance, and it was only after a certain number of iterations that EGT took over.", "startOffset": 3, "endOffset": 23}, {"referenceID": 2, "context": "This sentiment has been mirrored by Brown and Sandholm [2016]. In contrast to this, we find that our DGF along with proper initialization leads to EGT performing better than", "startOffset": 36, "endOffset": 62}, {"referenceID": 15, "context": "For games where accelerated bestresponse calculation [Johanson et al., 2011] can be applied, e.", "startOffset": 53, "endOffset": 76}, {"referenceID": 4, "context": "But, for some other games, this aspect can be important, though note that Brown et al. [2017] showed experimentally that pruning can be used in EGT as well.", "startOffset": 74, "endOffset": 94}, {"referenceID": 31, "context": "On a separate note, in practice CFR is often paired with an abstraction technique [Sandholm, 2010] such as those mentioned in Section 2.", "startOffset": 82, "endOffset": 98}, {"referenceID": 4, "context": "Effective ways to pair FOMs such as MP and EGT with practical abstraction techniques [Brown et al., 2015] or abstraction techniques that achieve solution-quality guarantees [Lanctot et al.", "startOffset": 85, "endOffset": 105}], "year": 2017, "abstractText": "Sparse iterative methods, in particular first-order methods, are known to be among the most effective in solving large-scale two-player zero-sum extensive-form games. The convergence rates of these methods depend heavily on the properties of the distance-generating function that they are based on. We investigate the acceleration of first-order methods for solving extensive-form games through better design of the dilated entropy function\u2014a class of distance-generating functions related to the domains associated with the extensive-form games. By introducing a new weighting scheme for the dilated entropy function, we develop the first distance-generating function for the strategy spaces of sequential games that only a logarithmic dependence on the branching factor of the player. This result improves the convergence rate of several first-order methods by a factor of \u03a9(bd), where b is the branching factor of the player, and d is the depth of the game tree. Thus far, counterfactual regret minimization methods have been faster in practice, and more popular, than first-order methods despite their theoretically inferior convergence rates. Using our new weighting scheme and practical tuning we show that, for the first time, the excessive gap technique can be made faster than the fastest counterfactual regret minimization algorithm, CFR+, in practice.", "creator": "LaTeX with hyperref package"}}}