{"id": "1703.00557", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2017", "title": "Diffusion Independent Semi-Bandit Influence Maximization", "abstract": "We consider \\emph{influence maximization} (IM) in social networks, which is the problem of maximizing the number of users that become aware of a product by selecting a set of \"seed\" users to expose the product to. While prior work assumes a known model of information diffusion, we propose a parametrization in terms of pairwise reachability which makes our framework agnostic to the underlying diffusion model. We give a corresponding monotone, submodular surrogate function, and show that it is a good approximation to the original IM objective. We also consider the case of a new marketer looking to exploit an existing social network, while simultaneously learning the factors governing information propagation. For this, we propose a pairwise-influence semi-bandit feedback model and develop a LinUCB-based bandit algorithm. Our model-independent regret analysis shows that our bound on the cumulative regret has a better (as compared to previous work) dependence on the size of the network. By using the graph Laplacian eigenbasis to construct features, we describe a practical LinUCB implementation. Experimental evaluation suggests that our framework is robust to the underlying diffusion model and can efficiently learn a near-optimal solution.", "histories": [["v1", "Wed, 1 Mar 2017 23:54:40 GMT  (847kb,D)", "http://arxiv.org/abs/1703.00557v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["sharan vaswani", "branislav kveton", "zheng wen", "mohammad ghavamzadeh", "laks lakshmanan", "mark schmidt"], "accepted": false, "id": "1703.00557"}, "pdf": {"name": "1703.00557.pdf", "metadata": {"source": "META", "title": "Diffusion Independent Semi-Bandit Influence Maximization", "authors": ["Sharan Vaswani", "Branislav Kveton", "Zheng Wen", "Mohammad Ghavamzadeh", "Laks V.S. Lakshmanan", "Mark Schmidt"], "emails": ["<sharanv@cs.ubc.ca>."], "sections": [{"heading": "1. Introduction", "text": "The aim of viral marketing is to spread awareness about a specific product via word-of-mouth information propagation over a social network. More precisely, marketers (agents) aim to select a fixed number of influential users (called seeds) and provide them with free products or discounts. They assume that these users will influence their neighbours and, transitively, other users in the social network to adopt the product. This will thus result in information propagating across the network as more users adopt or become aware of the product. The marketer has a budget on the number of free products and must choose seeds\n1University of British Columbia 2Adobe Research. Correspondence to: Sharan Vaswani <sharanv@cs.ubc.ca>.\nin order to maximize the influence spread which is the expected number of users that become aware of the product. This problem is referred to as Influence Maximization (IM).\nExisting solutions to the IM problem require as input, the underlying diffusion model which describes how information propagates through the network. The IM problem has been studied under various probabilistic diffusion models such as Independent Cascade (IC) and Linear Threshold (LT) models (Kempe et al., 2003). Under these common models, there has been substantial work on developing efficient heuristics and approximation algorithms (Chen et al., 2009; Leskovec et al., 2007; Goyal et al., 2011b;a; Tang et al., 2014; 2015).\nUnfortunately, knowledge of the underlying diffusion model and its parameters is essential for the existing IM algorithms to perform well. For example, Du et al. (2014) empirically showed that misspecification of the diffusion model can lead to choosing bad seeds and consequently to a low spread. In practice, it is not clear how to choose from amongst the increasing number of plausible diffusion models (Kempe et al., 2003; Gomez Rodriguez et al., 2012; Li et al., 2013). Even if we are able to choose a diffusion model according to some prior information, the number of parameters for these models scales with the size of the network (for example, it is equal to the number of edges for both the IC and LT models) and it is not clear how to set these. Goyal et al. (2011a) showed that even when assuming the IC or LT model, correct knowledge of the model parameters is critical to choosing good seeds that lead to a large spread. Some papers try to learn these parameters from past propagation data (Saito et al., 2008; Goyal et al., 2010; Netrapalli & Sanghavi, 2012). However in practice, such data is hard to obtain and the large number of parameters makes this learning inefficient.\nTo overcome these difficulties, we propose a novel parametrization for the IM problem in terms of pairwise reachability probabilities (Section 2). This parametrization depends only on the state of the network after the information diffusion has taken place. Since it does not depend on how information diffuses, it is agnostic to the underlying diffusion model (under a monotonicity assumption). To select seeds based on these reachability probabilities, we propose a monotone and submodular surrogate objective function based on the notion of maximum reachability\nar X\niv :1\n70 3.\n00 55\n7v 1\n[ cs\n.L G\n] 1\nM ar\n2 01\n7\n(Section 3). Our surrogate function can be optimized efficiently and is a a good approximation to the IM objective. We bound the quality of this approximation both theoretically and empirically. Our parametrization may be of independent interest to the IM community.\nNext, we consider learning how to choose good seeds in an online setting. Specifically, we focus on the case of a new marketer looking to exploit an existing network to market their product. They need to choose a good seed set, while simultaneously learning the factors affecting information propagation. This motivates the learning framework of IM semi-bandits (Vaswani et al., 2015; Chen et al., 2016; Wen et al., 2016). In these works, the marketer performs IM over multiple \u201crounds\u201d and learns about the factors governing the diffusion on the fly. Each round corresponds to an IM attempt for the same or similar products. Each IM attempt incurs a loss in the influence spread (measured in terms of cumulative regret) because of the lack of knowledge about the diffusion process. The aim is to minimize the cumulative regret incurred across multiple such rounds. This leads to the classic exploration-exploitation trade-off where the marketer must either choose seeds that improve their knowledge about the diffusion process (\u201cexploration\u201d) or find a seed set that leads to a large expected spread (\u201cexploitation\u201d). Note that all previous work on IM semi-bandits assumes the IC model.\nWe propose a novel semi-bandit feedback model based on pairwise influence (Section 4). Our feedback model is weaker than the edge-level feedback proposed in (Chen et al., 2016; Wen et al., 2016). Under this feedback, we formulate IM semi-bandit as a linear bandit problem and propose a scalable LinUCB-based algorithm (Section 5). We bound the cumulative regret of this algorithm (Section 6) and show that our regret bound has the optimal dependence on the time horizon, is linear in the cardinality of the seed set, and as compared to the previous literature, it has a better dependence on the size of the network. In Section 7, we describe how to construct features based on the graph Laplacian eigenbasis and describe a practical implementation for our algorithm. Finally, in Section 8, we empirically evaluate the proposed algorithm on a real-world network and show that our proposed algorithm is statistically efficient and robust to the underlying diffusion model."}, {"heading": "2. Influence Maximization", "text": "The influence maximization (IM) problem is characterized by the triple (G, C,D), where G is a directed graph encoding the topology of the social network, C is the collection of feasible seed sets, and D is the underlying diffusion model. Specifically, G = (V, E), where V = {1, 2, . . . , n} and E are the node and edge sets of G, with cardinalities n = |V| and m = |E|, respectively. The collection of feasible seed sets C is determined by a cardinality constraint |S| \u2264 K,\u2200S \u2208 C, for some K \u2264 n, and possibly some\ncombinatorial constraints (e.g. matroid constraints) that rule out some subsets of V implying C \u2286 {S \u2286 V : |S| \u2264 K}. The diffusion model D specifies the stochastic process under which influence is propagated across the social network once a seed set S \u2208 C is selected. Without loss of generality, we assume that all stochasticity in D is encoded in a random vector w, referred to as the diffusion random vector. We assume that each diffusion has a corresponding w sampled independently from an underlying probability distribution P specific to the diffusion model. For the widely-used models IC and LT, w corresponds to mdimensional binary vector encoding edge activations for all the edges in E , and P is parametrized by m influence probabilities, one for each edge. Once w is sampled, we use D(w) to refer to the particular realization of the diffusion model D. Note that by definition, D(w) is deterministic, conditioned on w.\nGiven the above definitions, a diffusion in a social network can be described as: the marketer first chooses a seed set S \u2208 C and then nature independently samples a diffusion random vector w \u223c P. Note that the influenced nodes in the diffusion are completely determined by S and D(w). We use the indicator I ( S, v,D(w) ) \u2208 {0, 1} to denote if the node v is influenced under the seed set S and the particular realization D(w). For a given (G,D), once a seed set S \u2286 C is chosen, for each node v \u2208 V , we use F (S, v) to denote the probability that v is influenced under the seed set S, i.e.,\nF (S, v) = E [ I ( S, v,D(w) )\u2223\u2223S] (1) where the expectation is over all possible realizations D(w). We denote by F (S) = \u2211 v\u2208V F (S, v), the expected number of nodes that are influenced when the seed set S is chosen. The aim of the IM problem is to maximize F (S) subject to the constraint S \u2208 C i.e. to find S\u2217 \u2208 arg maxS\u2208C F (S). Although IM is an NP-hard problem in general, under common diffusion models such as IC and LT, the objective function F (S) is monotone and submodular, and thus, a near-optimal solution can be efficiently computed using a greedy algorithm (Nemhauser et al., 1978). In this work, we assume that D is any diffusion model satisfying the following monotonicity assumption:\nAssumption 1. For any v \u2208 V , F (S, v) is monotone in S i.e. F (S1, v) \u2264 F (S2, v), if S1 \u2286 S2. Note that all progressive diffusion models (models where once the user is influenced, they can not change their state), including those in (Kempe et al., 2003; Gomez Rodriguez et al., 2012; Li et al., 2013) satisfy Assumption 1."}, {"heading": "3. Surrogate Objective", "text": "We now motivate and propose a surrogate objective for the IM problem based on the notion of maximal pairwise\nreachability. We start by defining some useful notation. For any set S \u2286 V and any set of \u201cpairwise probabilities\u201d p : V \u00d7 V \u2192 [0, 1], for all nodes v \u2208 V , we define\nf(S, v, p) = maxu\u2208S pu,v (2)\nwhere pu,v is the pairwise probability associated with the ordered node pair (u, v). We further define f(S, p) =\u2211 v\u2208V f(S, v, p). Note that for all p, f(S, p) is always monotone and submodular in S (Krause & Golovin, 2012).\nFor any pair of nodes u, v \u2208 V , we define the pairwise reachability from u to v as p\u2217u,v = F ({u}, v), i.e., the probability that v will be influenced, if u is the only seed node under graph G and diffusion model D. Moreover, we refer to f(S, v, p\u2217) = maxu\u2208S p\u2217u,v as the maximal pairwise reachability from the seed set S to the target node v.\nOur proposed surrogate objective for the IM problem is f(S, p\u2217) = \u2211 v\u2208V f(S, v, p\u2217). Based on this objective, an approximate solution S\u0303 to the IM problem can be obtained by maximizing f(S, p\u2217) under the constraint S \u2208 C,\nS\u0303 \u2208 arg maxS\u2208C f(S, p\u2217) (3)\nRecall that S\u2217 is the optimal solution to the IM problem. To quantify the quality of the surrogate, we define the surrogate approximation factor as \u03c1 = f(S\u0303, p\u2217)/F (S\u2217). The following theorem, (proved in Appendix A) states that we can obtain the following upper and lower bounds on \u03c1:\nTheorem 1. For any graph G, seed set S \u2208 C, and diffusion model D satisfying Assumption 1,\n1 f(S, p\u2217) \u2264 F (S),\n2 If F (S) is submodular in S, then 1/K \u2264 \u03c1 \u2264 1.\nThe above theorem implies that for any progressive model satisfying assumption 1, maximizing f(S, p\u2217) is the same as maximizing a lower-bound on the true spread F (S). In section 8, we empirically show that in cases of practical interest, f(S, p\u2217) is a good approximation to F (S). For both IC and LT models, F (S) is both monotone and submodular, and the approximation factor can be lower-bounded by 1/K. In Section 8, we empirically show that \u03c1 is much larger than 1/K.\nFinally, note that solving S\u0303 \u2208 arg maxS\u2208C f(S, p\u2217) is usually computationally intractable. Thus, in many practical cases, we need to compute a near-optimal solution of maxS\u2208C f(S, p\u2217) based on an approximation algorithm. In this paper, we refer to such approximation algorithms as oracles to distinguish them from learning algorithms. Let ORACLE be such an oracle and let S\u0302 \u2206= ORACLE(G, C, p) be the seed set output by it. For any \u03b1 \u2208 [0, 1], we say that ORACLE is an \u03b1-approximation algorithm if for all p : V \u00d7 V \u2192 [0, 1], f(S\u0302, p) \u2265 \u03b1maxS\u2208C f(S, p)."}, {"heading": "4. Influence Maximization Semi-Bandits", "text": "We now focus on the case of a new marketer trying to learn the factors governing diffusion, while repeatedly interacting with the network. We describe the observable feedback (Section 4.2) and the learning framework (Section 4.3)."}, {"heading": "4.1. Influence Maximization Semi-Bandits", "text": "In an influence maximization semi-bandit problem (also characterized by the triple (G, C,D)), the agent (marketer) knows both G and C, but does not know the diffusion model D. Specifically, the agent knows neither the model class of D (e.g., if D is IC or LT) nor its parameters. (e.g. influence probabilities for IC, LT). Consider a scenario in which the agent interacts with the social network for T rounds. At each round t \u2208 {1, . . . , T}, the agent first chooses a seed set St \u2208 C based on her prior knowledge and past observations and then nature independently samples a diffusion random vector wt \u223c P. Influence thus diffuses in the social network from St according to D(wt). The agent\u2019s reward at round t is the number of the influenced nodes\nrt = \u2211 v\u2208V I ( St, v,D(wt) ) .\nRecall that by definition, E [rt|St,D(wt); G] = F (St). After each such IM attempt, the agent observes the pairwise influence feedback (described next) and uses it to improve the subsequent IM attempts. The agent\u2019s objective is to maximize the expected cumulative reward across the T rounds, i.e., to maximize E [\u2211T t=1 rt ] , which is equivalent to minimizing the cumulative regret defined subsequently."}, {"heading": "4.2. Pairwise Influence Feedback Model", "text": "In this paper, we propose a novel IM semi-bandit feedback model referred to as pairwise influence feedback. Under this feedback model, at the end of each round t, the agent observes I ( {u}, v,D(wt) ) for all u \u2208 St and all v \u2208 V . In other words, she observes whether or not v would be influenced, if the agent selects S = {u} as the seed set under the diffusion modelD(wt). This form of semi-bandit feedback is plausible in most IM scenarios. For example, on sites like Facebook, we can identify the user who influenced another user to \u201cshare\u201d or \u201clike\u201d an article, and thus, can transitively trace the propagation to the seed which started the diffusion. Similarly, for product adoption, the company keeps track of the navigation behavior and can identify which other user caused the person to adopt a particular product. Note that our assumption is strictly weaker than (and implied by) edge level semi-bandit feedback (Chen et al., 2016; Wen et al., 2016), since in that case, we can identify the edges along which the diffusion travelled, and thus, determine whether a particular source node is responsible for activating a target node."}, {"heading": "4.3. Linear Generalization", "text": "Parametrizing the problem in terms of reachability probabilities results in O(n2) parameters that need to be learned. Without any structural assumptions, this becomes intractable for large networks. To develop statistically efficient algorithms for large-scale IM semi-bandits, similar to the existing work on linear bandits (Wen et al., 2015; 2016), we make a linear generalization assumption. Assume that each node v \u2208 V is associated with two vectors of dimension d, the seed (source) feature \u03b8\u2217v \u2208 <d and the target feature xv \u2208 <d. We assume that the target feature xv is known, whereas \u03b8\u2217v is unknown and needs to be learned. The linear generalization assumption is stated as:\nAssumption 2. For all u, v \u2208 V , p\u2217u,v can be \u201cwell approximated\u201d by the inner product of \u03b8\u2217u and xv , i.e.,\np\u2217u,v \u2248 \u3008\u03b8 \u2217 u,xv\u3009 \u2206 = x>v \u03b8 \u2217 u\nNote that for the tabular case (the case without generalization across p\u2217u,v\u2019s), we can always choose xv = ev \u2208 <n\nand \u03b8\u2217u = [ p\u2217u,1, . . . , p \u2217 u,n ]T , where ev is an indicator vector with the v-th element equal to 1 and all other elements equal to 0. However, in this case d = n, which is not desirable. Constructing target features when d n is nontrivial. We discuss a feature construction approach based on the unweighted graph Laplacian in Section 7. We use matrix X \u2208 <d\u00d7n to encode the target features. Specifically, for v = 1, . . . , n, the v-th column of X is set as xv . Note that X = I \u2208 <n\u00d7n in the tabular case.\nFinally, note that under Assumption 2, estimating the reachability probabilities becomes equivalent to estimating n (one for each source) d-dimensional seed feature vectors. This implies that Assumption 2 reduces the number of parameters to learn from O(n2) to O(dn), and thus, is important for developing statistically efficient algorithms for large-scale IM semi-bandits."}, {"heading": "4.4. Performance Metric", "text": "We benchmark the performance of a IM semi-bandit algorithm by comparing its spread against the attainable influence assuming perfect knowledge of D. Since various approximations might be used for computing the seed set, similar to (Wen et al., 2016; Chen et al., 2016), we measure the performance of an IM semi-bandit algorithm by scaled cumulative regret. Specifically, if St is the seed set selected by the IM semi-bandit algorithm at round t, for any \u03ba \u2208 (0, 1), the \u03ba-scaled cumulative regret R\u03ba(T ) in the first T rounds is defined as\nR\u03ba(T ) = T \u00b7 F (S\u2217)\u2212 1 \u03ba E [\u2211T t=1 F (St) ] . (4)\nAlgorithm 1 Diffusion-Independent LinUCB (DILinUCB) 1: Input: G = (V, E), C, oracle ORACLE, target feature\nmatrix X \u2208 Rd\u00d7n, algorithm parameters c, \u03bb, \u03c3 > 0 2: Initialize \u03a3u,0 \u2190 \u03bbId, bu,0 \u2190 0, \u03b8\u0302u,0 \u2190 0 for all u \u2208 V , and UCB pu,v \u2190 1 for all u, v \u2208 V 3: for t = 1 to T do 4: Choose St \u2190 ORACLE (G, C, p) 5: for u \u2208 St do 6: Get pairwise influence feedback yu,t 7: bu,t \u2190 bu,t\u22121 +Xyu,t 8: \u03a3u,t \u2190 \u03a3u,t\u22121 + \u03c3\u22122XXT\n9: \u03b8\u0302u,t \u2190 \u03c3\u22122\u03a3\u22121u,tbu,t 10: pu,v \u2190 Proj[0,1] [ \u03b8\u0302 T u,txv + c\u2016xv\u2016\u03a3\u22121u,t ] , \u2200v \u2208 V 11: end for 12: end for"}, {"heading": "5. Algorithm", "text": "In this section, we propose a novel LinUCB-based IM semi-bandit algorithm, called Diffusion-Independent LinUCB (DILinUCB), whose pseudocode is in Algorithm 1. As its name suggests, DILinUCB is independent of the underlying diffusion model D of the IM semi-bandit, and thus, is applicable to IM semi-bandits with any diffusion model D. The only requirement to apply DILinUCB is that the IM semi-bandit provides the pairwise influence feedback described in Section 4.2.\nThe inputs to DILinUCB include the network topology G, the collection of the feasible sets C, a combinatorial optimization algorithm ORACLE, the target feature matrix X , and three algorithm parameters c, \u03bb, \u03c3 > 0. Roughly speaking, \u03bb specifies the initial values of Gram matrices and can be viewed as a regularization parameter; \u03c3 controls the learning rate; and c controls the \u201cdegree of optimism\u201d in the UCB estimates and hence trades off exploration and exploitation. For each source node u \u2208 V and time t, we define the Gram matrix \u03a3u,t \u2208 <d\u00d7d, and bu,t \u2208 <d as the vector summarizing the past pairwise influences from u. Note that \u03a3u,t and bu,t are sufficient statistics for computing UCB estimates for p\u2217u,v for all v \u2208 V .\nAt each round t, DILinUCB first uses the existing UCB estimates to compute the seed set St based on the given oracle ORACLE (line 4 of Algorithm 1). Then, it observes the pairwise reachability vector yu,t for all the selected seeds in St. Specifically, the vector yu,t consists of n binary observations, such that yu,t(v) = I ({u}, v,D(wt)) indicating whether node v is reachable from the source u at round t. Finally, for each of theK selected seeds u \u2208 St, DILinUCB updates the sufficient statistics (lines 7 and 8) and updates the UCB estimates (line 10 of Algorithm 1). Note that Proj[0,1][\u00b7] projects a real number onto the interval [0, 1],\nand \u2016xv\u2016\u03a3\u22121u,t = \u221a xTv \u03a3 \u22121 u,txv ."}, {"heading": "6. Regret Bound", "text": "In this section, we derive a regret bound for DILinUCB, under (1) Assumption 1, (2) perfect linear generalization i.e. p\u2217u,v = \u3008\u03b8 \u2217 u,xv\u3009 for all u, v \u2208 V , and (3) the assumption that ||xv||2 \u2264 1 for all v \u2208 V . Notice that (2) is the standard assumption for linear bandit analysis (Dani et al., 2008), and (3) can always be satisfied by rescaling the target features. Our regret bound is stated below:\nTheorem 2. For any \u03bb, \u03c3 > 0, any feature matrix X , any \u03b1-approximation oracle ORACLE, and any c satisfying\nc \u2265 1 \u03c3\n\u221a dn log ( 1 + nT\n\u03c32\u03bbd\n) + 2 log (n2T ) +\n\u221a \u03bbmax u\u2208V \u2016\u03b8\u2217u\u20162,\n(5)\nif we apply DILinUCB with input (ORACLE, X, c, \u03bb, \u03c3), then its \u03c1\u03b1-scaled cumulative regret is upper-bounded as\nR\u03c1\u03b1(T ) \u2264 2c \u03c1\u03b1 n 3 2\n\u221a dKT log ( 1 + nT\nd\u03bb\u03c32 ) \u03bb log ( 1 + 1\n\u03bb\u03c32\n) + 1 \u03c1 . (6)\nFor the tabular case X = I , we obtain a tighter bound\nR\u03c1\u03b1(T ) \u2264 2c \u03c1\u03b1 n 3 2\n\u221a KT log ( 1 + T\n\u03bb\u03c32 ) \u03bb log ( 1 + 1\n\u03bb\u03c32\n) + 1 \u03c1 . (7)\nNotice that if we choose \u03bb = \u03c3 = 1, and choose c s.t. Inequality 5 is tight, then our regret bound is O\u0303(n2d \u221a KT/(\u03b1\u03c1)) for general feature matrix X , and O\u0303(n2.5 \u221a KT/(\u03b1\u03c1)) in the tabular case. We now briefly discuss the tightness of our regret bounds. First, note that theO(1/\u03c1) factor is due to the surrogate objective approximation discussed in Section 3, and theO(1/\u03b1) factor is due to the fact that ORACLE is an \u03b1-approximation algorithm. Second, note that the O\u0303( \u221a T )-dependence on time is nearoptimal, and the O\u0303( \u221a K)-dependence on the cardinality of the seed sets is standard in the combinatorial semi-bandit literature (Kveton et al., 2015). Third, for general X , notice that the O\u0303(d)-dependence on feature dimension is standard in linear bandit literature (Dani et al., 2008; Wen et al., 2015). To explain the O\u0303(n2) factor in this case, notice that one O(n) factor is due to the magnitude of the reward (the reward is from 0 to n, rather than 0 to 1), whereas one O\u0303( \u221a n) factor is due to the statistical dependence of the pairwise reachabilities. Assuming statistical independence between these reachabilities (similar to Chen et al. (2016)) can shave off this O\u0303( \u221a n) factor. However this assumption is unrealistic in practice. Another O\u0303( \u221a n) is due to the fact that we learn a \u03b8\u2217u for each source node u (i.e. there is no generalization across the source nodes). We conjecture that with an appropriate generalization across source nodes, it may be possible to get rid of this O\u0303( \u221a n) factor. Finally, for the tabular case X = I , the dependence on d no longer exists, but there is another O\u0303( \u221a n) factor due to the fact there is no generalization across target nodes.\nWe conclude this section by sketching the proof for Theorem 2 (the detailed proof is available in Appendix B and C). We define the \u201cgood event\u201d as\nF = {|xTv (\u03b8\u0302u,t\u22121 \u2212 \u03b8\u2217u)| \u2264 c\u2016xv\u2016\u03a3\u22121u,t\u22121 \u2200u, v \u2208 V, t \u2264 T},\nand the \u201cbad event\u201d F as the complement of F . We then decompose the \u03c1\u03b1-scaled regret R\u03c1\u03b1(T ) over F and F , and obtain the following inequality:\nR\u03c1\u03b1(T ) \u2264 2c \u03c1\u03b1 E { T\u2211 t=1 \u2211 u\u2208St \u2211 v\u2208V \u2016xv\u2016\u03a3\u22121u,t\u22121 \u2223\u2223\u2223\u2223\u2223F } + P (F) \u03c1 nT,\nwhere P (F) is the probability of F . The regret bounds in Theorem 2 are derived based on worst-case bounds on \u2211T t=1 \u2211 u\u2208St \u2211 v\u2208V \u2016xv\u2016\u03a3\u22121u,t\u22121 (Appendix B.2), and a bound on P (F) based on the \u201cself-normalized bound for matrix-valued Martingales\u201d developed in Theorem 3 (Appendix C)."}, {"heading": "7. Practical Implementation", "text": "In this section, we briefly discuss how to implement our proposed algorithm, DILinUCB, in practical semi-bandit IM problems. Specifically, we will discuss how to construct features in Section 7.1, how to enhance the practical performance of DILinUCB based on Laplacian regularization in Section 7.2, and how to implement DILinUCB computationally efficiently in real-world problems for Section 7.3."}, {"heading": "7.1. Target Feature Construction", "text": "Although DILinUCB is applicable with any target feature matrix X , in practice, its performance is highly dependent on the \u201cquality\u201d of X . In this subsection, we motivate and propose a systematic feature construction approach based on the unweighted Laplacian matrix of the network topology G. For all u \u2208 V , let p\u2217u \u2208 <n be the vector encoding the reachabilities from the seed u to all the target nodes v \u2208 V . Intuitively, p\u2217u tends to be a smooth graph function in the sense that target nodes v close to each other (e.g., in the same community) tend to have similar reachabilities from u. From (Belkin et al., 2006; Valko et al., 2014), we know that a smooth graph function (in this case, the reachability from a source) can be expressed as a linear combination of eigenvectors of the weighted Laplacian of the network. In our case, the edge weights correspond to influence probabilities and are unknown in the IM semibandit setting. However, we use the above intuition to construct target features based on the unweighted Laplacian of G, Specifically, for a given d = 1, 2, . . . , n, we set the feature matrix X to be the bottom d eigenvectors (associated with d smallest eigenvalues) of the unweighted Laplacian of G. Other approaches to construct target features include the neighbourhood preserving node-level features as described in (Grover & Leskovec, 2016; Perozzi et al.,\n2014). We leave the investigation of other feature construction approaches to future work."}, {"heading": "7.2. Laplacian Regularization", "text": "One limitation of our proposed DILinUCB algorithm is that it does not generalize across the seed nodes u. Specifically, it needs to learn the source node feature \u03b8\u2217u for each source node u separately, which is inefficient for large-scale semibandit IM problems. Note that similar to target features, the source features are also tend to be smooth in the sense that \u2016\u03b8\u2217u1 \u2212 \u03b8 \u2217 u2\u20162 is \u201csmall\u201d if nodes u1 and u2 are connected. We use this idea to design a prior which ties together the source features for different nodes, and hence transfers information between them. This idea of Laplacian regularization has been used in multi-task learning (Evgeniou et al., 2005) and for contextual-bandits (Cesa-Bianchi et al., 2013). Specifically, at each round t, we compute \u03b8\u0302u,t\u2019s by minimizing the following objective w.r.t \u03b8u\u2019s:\nt\u2211 j=1 \u2211 u\u2208St (yu,j \u2212XT\u03b8u)2 + \u03bb2 \u2211 (u1,u2)\u2208E ||\u03b8u1 \u2212 \u03b8u2 ||22\nwhere \u03bb2 \u2265 0 is the regularization parameter. The implementation details are provided in Appendix D."}, {"heading": "7.3. Computational Complexity", "text": "We now characterize the computational complexity of DILinUCB, and discuss how to implement it efficiently. Note that at each time t, DILinUCB needs to first compute a solution St based on ORACLE, and then update the UCBs. Since \u03a3u,t is positive semi-definite, the linear system in line 9 of algorithm 1 can be solved using conjugate gradient in O(d2) time. It is straightforward to see the computational complexity to update the UCBs is O(Knd2). The computational complexity to compute St is dependent on ORACLE. For the classical setting in which C = {S \u2286 V : |S| \u2264 K} and ORACLE is the greedy algorithm, the computational complexity is O(Kn). To speed this up, we use the idea of lazy evaluations for submodular maximization proposed in (Minoux, 1978; Leskovec et al., 2007). This results in sub-Kn time complexity for seed set selection."}, {"heading": "8. Experiments", "text": ""}, {"heading": "8.1. Empirical Verification of Surrogate Objective", "text": "In this subsection, we empirically verify that the surrogate f(S, p\u2217) proposed in Section 3 is a good approximation of the true IM objective F (S) in random Kronecker graphs, which are known to capture many properties of real-world social networks (Leskovec et al., 2010). Specifically, we randomly generate a social network instance (G,D) as follows: we randomly sample G as a Kronecker graph with\nn = 256 and sparsity equal to 0.03 1 (Leskovec et al., 2005). We choose D as an IC model and sample each of its influence probabilities independently from the uniform distribution U(0, 0.1). Note that this range of influence probabilities is guided by the empirical evidence in (Goyal et al., 2010; Barbieri et al., 2013). To weaken the dependence on a particular instance, all the results in this subsection are averaged over 10 randomly generated instances.\nWe first numerically estimate the pairwise reachabilities p\u2217 for all 10 instances based on social network simulation. In a simulation, we randomly sample a seed set S with cardinality K between 1 and 35, and record the pairwise influence indicator yu(v) from each source u \u2208 S to each target node v in this simulation. The reachability p\u2217u,v is estimated by averaging the yu(v) values across 50K such simulations.\nBased on these estimated p\u2217, we compare f(S, p\u2217) and F (S) as K, the seed set cardinality, varies from 2 to 35. For eachK and each social network instance, we uniformly randomly sample 100 seed sets S with cardinalityK. Then, we evaluate f(S, p\u2217) based on the estimated p\u2217; and numerically evaluate F (S) by averaging results of 500 influence simulations (diffusions). For eachK, we average both F (S) and f(S, p\u2217) across the 100 random seed sets in each instance as well as across the 10 instances. We plot the average F (S) and f(S, p\u2217) vs. K in figure 1(a). The plot shows that f(S) is a good lower bound on the true expected spread F (S), especially for low K.\nFinally, we empirically quantify the surrogate approximation factor \u03c1. As before, we vary K from 2 to 35 and average across 10 instances. Let \u03b1\u2217 = 1 \u2212 e\u22121. For each instance and each K, we first use the estimated p\u2217 and the greedy algorithm to find an \u03b1\u2217-approximation solution S\u0303g to the surrogate problem maxS f(S, p\u2217). We then use the state-of-the-art IM algorithm (Tang et al., 2014) to compute an \u03b1\u2217-approximation solution S\u2217g to the IM problem maxS F (S). Note that UB \u2206 = F (S\u2217g )/\u03b1\u2217 is an upper bound on F (S\u2217); and from Theorem 1, LB \u2206= F (S\u2217g )/K \u2264 F (S\u2217)/K is a lower bound on f(S\u0303, p\u2217). We plot the average (over 10 instances) F (S\u2217g ), f(S\u0303g, p\u2217), UB and LB\n1Based on the sparsity of typical social networks.\nagainst K in figure 1(b). We observe that the difference in spreads does not increase rapidly with K. Although \u03c1 is lower-bounded with 1K , in practice for all K \u2208 [2, 35], \u03c1 \u2265 \u03b1\n\u2217f(S\u0303g,p\u2217) F (S\u2217g )\n\u2265 0.55. This shows that in practice, our surrogate approximation is reasonable even for large K.\n8.2. Performance of DILinUCB\nWe now demonstrate the performances of variants of DILinUCB and compare them with the start of the art. We choose the social network topology G as a subgraph of the Facebook network available at (Leskovec & Krevl, 2014), which consists of n = 4K nodes and m = 88K edges. Since true diffusion model is unavailable, we assume the diffusion model D is either an IC model or an LT model, and sample the edge influence probabilities independently from the uniform distribution U(0, 0.1). We also choose T = 5K rounds.\nWe now briefly discuss the performance metrics used in this section. For all S \u2286 V and all t = 1, 2 . . ., we define rt(S) = \u2211 v\u2208V I (S, v,D(wt)), which is the realized reward at time t if S is chosen at that time. One performance metric is the per-step reward. Specifically, in one simulation, the per-step reward at time t is defined as \u2211t s=1 rs t . Another performance metric is the cumulative regret. Since it is computationally intractable to derive S\u2217, our regret is measured with respect to S\u2217g , the \u03b1\u2217approximation solution discussed in Section 8.1. In one simulation, the cumulative regret at time t is defined as R(t) = \u2211t s=1 [ rs(S\u2217g )\u2212 rs(Ss) ] . All results in this subsection are averaged across 5 independent simulations.\nWe compare DILinUCB against the CUCB algorithm (Chen et al., 2016) in both the IC model and the LT model, with K = 10. CUCB (referred to as CUCB(K) in plots) assumes the IC model, edge-level feedback and learns the influence probability for each edge independently. We demonstrate the performance of three variants of DILinUCB - the tabular case with X = I , independent estimation for each source node using target features (algorithm 1) and Laplacian regularized estimation with target features(section D). In the subsequent plots, to emphasize the dependence on K and d, these are referred to as TAB(K), I(K,d) and L(K,d) respectively. We construct features as described in section 7.1. Similar to spectral clustering (Von Luxburg, 2007), the gap in the eigenvalues of the unweighted Laplacian can be used to choose the number of eigenvectors d. In our case, we choose the bottom d = 50 eigenvectors for constructing target features (we show the effect of varying d in a subsequent experiment). Similar to (Gentile et al., 2014), all hyper-parameters for our algorithm are set using an initial validation set of 500 rounds. The best validation performance was observed for \u03bb = 1e-4 and \u03c3 = 1.\nFigures 2(a) and 2(b) show the cumulative regret when the underlying diffusion model is IC and LT respectively. We\nhave the following observations: (i) As compared to CUCB, the cumulative regret increases at a slower rate for all variants of DILinUCB, under both the IC and LT models, and for both the tabular case and case with features. (ii) Exploiting target features (linear generalization) in DILinUCB leads to a much smaller cumulative regret. (iii) CUCB is not robust to model misspecification, it has a near linear cumulative regret under LT model. (iv) Laplacian regularization has little effect on the cumulative regret in these two cases. These observations clearly demonstrate the two main advantages of DILinUCB: it is both statistically efficient and robust to diffusion model misspecification. To explain (iv), we argue that the current combination of T , K, d and n results in sufficient feedback for independent estimation to perform well and hence it is difficult to observe any additional benefit of Laplacian regularization. We provide additional evidence for this argument in the next experiment.\nIn figure 3(a), we quantify the effect of varying d when the underlying diffusion model is IC and make the following observations: (v) The cumulative regret for both d = 10 and d = 100 is higher than that for d = 50. (vi) Laplacian regularization leads to observably lower cumulative regret when d = 100. Observation (v) implies that d = 10 does not provide enough expressive power for linear generalization across the nodes of the network, whereas it is relatively difficult to estimate 100-dimensional \u03b8\u2217u vectors within 5K rounds. Observation (vi) implies that tying source node estimates together imposes an additional bias which becomes important while learning higher dimensional coefficients. This shows the potential benefit of using Laplacian regularization for larger networks, where we will need higher d for linear generalization across nodes. Note that we obtain similar results under the LT model.\nIn figures 3(b) and 3(c), we show the effect of varyingK on the per-step reward. We compare CUCB and the independent version of our algorithm when the underlying model is IC and LT. We make the following observations: (vii) For both IC and LT, the per-step reward for all methods increases with K. (viii) For the IC model, the per-step reward for our algorithm is higher than CUCB when K = {5, 10, 20}, but the difference in the two spreads decreases with K. For K = 50, CUCB outperforms our algorithm. (ix) For the LT model, the per-step reward of our algorithm is substantially higher than CUCB for all K. Observation (vii) is readily explained since both IC and LT are progressive models, and satisfy assumption 1. To explain (viii), note that CUCB is correctly specified for the IC model. As K becomes higher, more edges become active and CUCB observes more feedback. It is thus able to learn more efficiently, leading to a higher per-step reward compared to our algorithm when K = 50. Observation (ix) again demonstrates that CUCB is not robust to diffusion model misspecification, while DILinUCB is."}, {"heading": "9. Related Work", "text": "IM semi-bandits have been studied in several recent papers (Wen et al., 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model. They formulated it as a combinatorial multi-armed bandit problem and proposed a UCB algorithm (CUCB). They only consider the tabular case, and derive an O(n3) regret bound that also depends on the reciprocal of the minimum observation probability p of an edge. This can be problematic in for example, a line graph with L edges where all edge weights are 0.5. Then 1/p is 2L\u22121, implying an exponentially large regret. Moreover, they assume that source nodes influence the target nodes independently, which is not true in most practical social networks. In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016). Our regret bound isO(n2.5) in the tabular case andO(n2d) in the general linear bandit case. Vaswani et al. (2015) use \u03b5-greedy and Thompson sampling algorithms for a different and more challenging feedback model, where the learning agent observes influenced nodes but not the edges. They do not give any theoretical guarantees. Wen et al. (2016) consider a linear generalization model across edges and prove regret bounds for the special case of forests under\nedge-level feedback. It not clear how to extend their technique for deriving regret bounds on general graphs. Note that all of the above papers assume the IC diffusion model.\nCarpentier & Valko (2016); Fang & Tao (2014) consider a simpler local model of influence, in which information does not transitively diffuse across the network. Lei et al. (2015) consider the related problem of maximizing the number of unique nodes across multiple rounds. They also do not provide any theoretical analysis."}, {"heading": "10. Conclusion", "text": "In this paper, we described a novel model-independent parametrization and a corresponding surrogate objective function for the IM problem. We used this parametrization to propose DILinUCB, a diffusion-independent learning algorithm for IM semi-bandits. We derived a regret bound for DILinUCB, and empirically demonstrated that it is statistically efficient and robust to the diffusion model.\nOne future research direction is to develop and analyze a Thompson sampling algorithm based on the proposed surrogate objective. We also plan to investigate the construction of more representative node-level features. Another research direction is to address more challenging node-level feedback models such as in Vaswani et al. (2015)."}, {"heading": "A. Proof of Theorem 1", "text": "Proof. Theorem 1 can be proved based on the definitions of monotonicity and submodularity. Note that from Assumption 1, for any seed set S \u2208 C, any seed node u \u2208 S, and any target node v \u2208 V , we have F ({u}, v) \u2264 F (S, v), which implies that\nf(S, v, p\u2217) = max u\u2208S F ({u}, v) \u2264 F (S, v),\nhence f(S, p\u2217) = \u2211 v\u2208V f(S, v, p\u2217) \u2264 \u2211 v\u2208V F (S, v) = F (S).\nThis proves the first part of Theorem 1.\nWe now prove the second part of the theorem. First, note that from the first part, we have\nf(S\u0303, p\u2217) \u2264 F (S\u0303) \u2264 F (S\u2217),\nwhere the first inequality follows from the first part of this theorem, and the second inequality follows from the definition of S\u2217. Thus, we have \u03c1 \u2264 1. To prove that \u03c1 \u2265 1/K, we assume that S = {u1, u2, . . . , uK}, and define Sk = {u1, u2, . . . , uk} for k = 1, 2, . . . ,K. Thus, for any S \u2286 V with |S| = K, we have\nF (S) =F (S1) + K\u22121\u2211 k=1 [F (Sk+1)\u2212 F (Sk)]\n\u2264 K\u2211 k=1 F ({uk}) = K\u2211 k=1 \u2211 v\u2208V F ({uk}, v)\n\u2264 \u2211 v\u2208V K max u\u2208S F ({u}, v) = K \u2211 v\u2208V f(S, v, p\u2217) = Kf(S, p\u2217),\nwhere the first inequality follows from the submodularity of F (\u00b7). Thus we have\nF (S\u2217) \u2264 Kf(S\u2217, p\u2217) \u2264 Kf(S\u0303, p\u2217),\nwhere the second inequality follows from the definition of S\u0303. This implies that \u03c1 \u2265 1/K."}, {"heading": "B. Proof of Theorem 2", "text": "We start by defining some useful notations. We use Ht to denote the \u201chistory\u201d by the end of time t. For any node pair (u, v) \u2208 V \u00d7 V and any time t, we define the upper confidence bound (UCB) Ut(u, v) and the lower confidence bound (LCB) Lt(u, v) respectively as\nUt(u, v) = Proj[0,1] ( \u3008\u03b8\u0302u,t\u22121,xv\u3009+ c \u221a xTv \u03a3 \u22121 u,t\u22121xv ) Lt(u, v) = Proj[0,1] ( \u3008\u03b8\u0302u,t\u22121,xv\u3009 \u2212 c \u221a xTv \u03a3 \u22121 u,t\u22121xv ) (8)\nNotice that Ut is the same as the UCB estimate p defined in Algorithm 1. Moreover, we define the \u201cgood event\u201d F as F = { |xTv (\u03b8\u0302u,t\u22121 \u2212 \u03b8 \u2217 u)| \u2264 c \u221a xTv \u03a3 \u22121 u,t\u22121xv, \u2200u, v \u2208 V, \u2200t \u2264 T } , (9)\nand the \u201cbad event\u201d F as the complement of F .\nB.1. Regret Decomposition\nRecall that the realized scaled regret at time t is R\u03c1\u03b1t = F (S \u2217)\u2212 1\u03c1\u03b1F (St), thus we have\nR\u03c1\u03b1t =F (S \u2217)\u2212 1\n\u03c1\u03b1 F (St)\n(a) =\n1 \u03c1 f(S\u0303, p\u2217)\u2212 1 \u03c1\u03b1 F (St)\n(b) \u2264 1 \u03c1 f(S\u0303, p\u2217)\u2212 1 \u03c1\u03b1 f(St, p\u2217), (10)\nwhere equality (a) follows from the definition of \u03c1 (i.e. \u03c1 is defined as \u03c1 = f(S\u0303, p\u2217)/F (S\u2217)), and inequality (b) follows from f(St, p\u2217) \u2264 F (St) (see Theorem 1). Thus, we have\nR\u03c1\u03b1(T ) =E [ T\u2211 t=1 R\u03c1\u03b1t ]\n\u2264 1 \u03c1 E { T\u2211 t=1 [ f(S\u0303, p\u2217)\u2212 f(St, p\u2217)/\u03b1 ]}\n= P (F) \u03c1 E { T\u2211 t=1 [ f(S\u0303, p\u2217)\u2212 f(St, p\u2217)/\u03b1 ]\u2223\u2223\u2223\u2223\u2223F } + P (F) \u03c1 E { T\u2211 t=1 [ f(S\u0303, p\u2217)\u2212 f(St, p\u2217)/\u03b1 ]\u2223\u2223\u2223\u2223\u2223F }\n\u2264 1 \u03c1 E { T\u2211 t=1 [ f(S\u0303, p\u2217)\u2212 f(St, p\u2217)/\u03b1 ]\u2223\u2223\u2223\u2223\u2223F } + P (F) \u03c1 nT, (11)\nwhere the last inequality follows from the naive bounds P (F) \u2264 1 and f(S\u0303, p\u2217) \u2212 f(St, p\u2217)/\u03b1 \u2264 n. Notice that under \u201cgood\u201d event F , we have\nLt(u, v) \u2264 p\u2217uv = xTv \u03b8\u2217u \u2264 Ut(u, v) (12)\nfor all node pair (u, v) and for all time t \u2264 T . Thus, we have f(S, Lt) \u2264 f(S, p\u2217) \u2264 f(S, Ut) for all S and t \u2264 T under event F . So under event F , we have\nf(St, Lt) (a) \u2264 f(St, p\u2217) (b) \u2264 f(S\u0303, p\u2217) (c)\n\u2264 f(S\u0303, Ut) \u2264 max S\u2208C\nf(S, Ut) (d) \u2264 1 \u03b1 f(St, Ut)\nfor all t \u2264 T , where inequalities (a) and (c) follow from Equation 12, inequality (b) follows from S\u0303 \u2208 arg maxS\u2208C f(S, p\u2217), and inequality (d) follows from the fact that ORACLE is an \u03b1-approximation algorithm. Specifically, the fact that ORACLE is an \u03b1-approximation algorithm implies that f(St, Ut) \u2265 \u03b1maxS\u2208C f(S, Ut).\nConsequently, under event F , we have\nf(S\u0303, p\u2217)\u2212 1 \u03b1 f(St, p\u2217) \u2264 1 \u03b1 f(St, Ut)\u2212 1 \u03b1 f(St, Lt)\n= 1\n\u03b1 \u2211 v\u2208V [ max u\u2208St Ut(u, v)\u2212max u\u2208St Lt(u, v) ] \u2264 1 \u03b1 \u2211 v\u2208V \u2211 u\u2208St [Ut(u, v)\u2212 Lt(u, v)]\n\u2264 \u2211 v\u2208V \u2211 u\u2208St 2c \u03b1 \u221a xTv \u03a3 \u22121 u,t\u22121xv. (13)\nSo we have\nR\u03c1\u03b1(T ) \u2264 2c \u03c1\u03b1 E { T\u2211 t=1 \u2211 u\u2208St \u2211 v\u2208V \u221a xTv \u03a3 \u22121 u,t\u22121xv \u2223\u2223\u2223\u2223\u2223F } + P (F) \u03c1 nT. (14)\nIn the remainder of this section, we will provide a worst-case bound on \u2211T t=1 \u2211 u\u2208St \u2211 v\u2208V \u221a xTv \u03a3 \u22121 u,t\u22121xv (see Section B.2) and a bound on the probability of \u201cbad event\u201d P (F) (see Section B.3).\nB.2. Worst-Case Bound on \u2211T t=1 \u2211 u\u2208St \u2211 v\u2208V \u221a xTv \u03a3 \u22121 u,t\u22121xv\nNotice that T\u2211 t=1 \u2211 u\u2208St \u2211 v\u2208V \u221a xTv \u03a3 \u22121 u,t\u22121xv = \u2211 u\u2208V T\u2211 t=1 1 [u \u2208 St] \u2211 v\u2208V \u221a xTv \u03a3 \u22121 u,t\u22121xv\nFor each u \u2208 V , we define Ku = \u2211T t=1 1 [u \u2208 St] as the number of times at which u is chosen as a source node, then we have the following lemma:\nLemma 1. For all u \u2208 V , we have\nT\u2211 t=1 1 [u \u2208 St] \u2211 v\u2208V \u221a xTv \u03a3 \u22121 u,t\u22121xv \u2264 \u221a nKu\n\u221a dn log ( 1 + nKud\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32\n) . Moreover, when X = I , we have\nT\u2211 t=1 1 [u \u2208 St] \u2211 v\u2208V \u221a xTv \u03a3 \u22121 u,t\u22121xv \u2264 \u221a nKu\n\u221a n log ( 1 + Ku\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32 ) .\nProof. To simplify the exposition, we use \u03a3t to denote \u03a3u,t, and define zt,v = \u221a xTv \u03a3 \u22121 u,t\u22121xv for all t \u2264 T and all v \u2208 V . Recall that\n\u03a3t = \u03a3t\u22121 + 1 [u \u2208 St]\n\u03c32 XXT = \u03a3t\u22121 + 1 [u \u2208 St] \u03c32 \u2211 v\u2208V xvx T v .\nNote that if u /\u2208 St, \u03a3t = \u03a3t\u22121. If u \u2208 St, then for any v \u2208 V , we have det [\u03a3t] \u2265 det [ \u03a3t\u22121 + 1\n\u03c32 xvx\nT v ] = det [ \u03a3 1 2 t\u22121 ( I + 1\n\u03c32 \u03a3 \u2212 12 t\u22121xvx T v \u03a3 \u2212 12 t\u22121\n) \u03a3 1 2 t\u22121 ] = det [\u03a3t\u22121] det [ I + 1\n\u03c32 \u03a3 \u2212 12 t\u22121xvx T v \u03a3 \u2212 12 t\u22121 ] = det [\u03a3t\u22121] ( 1 + 1\n\u03c32 xTv \u03a3 \u22121 t\u22121xv\n) = det [\u03a3t\u22121] ( 1 +\nz2t\u22121,v \u03c32\n) .\nHence, we have\ndet [\u03a3t] n \u2265 det [\u03a3t\u22121]n \u220f v\u2208V\n( 1 +\nz2t\u22121,v \u03c32\n) . (15)\nNote that the above inequality holds for any X . However, if X = I , then all \u03a3t\u2019s are diagonal and we have\ndet [\u03a3t] = det [\u03a3t\u22121] \u220f v\u2208V\n( 1 +\nz2t\u22121,v \u03c32\n) . (16)\nAs we will show later, this leads to a tighter regret bound in the tabular (X = I) case.\nLet\u2019s continue our analysis for general X . The above results imply that\nn log (det [\u03a3t]) \u2265 n log (det [\u03a3t\u22121]) + 1 (u \u2208 St) \u2211 v\u2208V log\n( 1 +\nz2t\u22121,v \u03c32\n)\nand hence\nn log (det [\u03a3T ]) \u2265n log (det [\u03a30]) + T\u2211 t=1 1 (u \u2208 St) \u2211 v\u2208V log\n( 1 +\nz2t\u22121,v \u03c32\n)\n=nd log(\u03bb) + T\u2211 t=1 1 (u \u2208 St) \u2211 v\u2208V log\n( 1 +\nz2t\u22121,v \u03c32\n) . (17)\nOn the other hand, we have that\nTr [\u03a3T ] = Tr [ \u03a30 +\nT\u2211 t=1 1 [u \u2208 St] \u03c32 \u2211 v\u2208V xvx T v\n]\n= Tr [\u03a30] + T\u2211 t=1 1 [u \u2208 St] \u03c32 \u2211 v\u2208V Tr [ xvx T v ] =\u03bbd+\nT\u2211 t=1 1 [u \u2208 St] \u03c32 \u2211 v\u2208V \u2016xv\u20162 \u2264 \u03bbd+ nKu \u03c32 , (18)\nwhere the last inequality follows from the assumption that \u2016xv\u2016 \u2264 1 and the definition of Ku. From the trace-determinant inequality, we have 1d Tr [\u03a3T ] \u2265 det [\u03a3T ] 1 d . Thus, we have\ndn log ( \u03bb+\nnKu d\u03c32\n) \u2265 dn log ( 1\nd Tr [\u03a3T ]\n) \u2265 n log (det [\u03a3T ]) \u2265 dn log(\u03bb) + T\u2211 t=1 1 (u \u2208 St) \u2211 v\u2208V log ( 1 + z2t\u22121,v \u03c32 ) .\nThat is T\u2211 t=1 1 (u \u2208 St) \u2211 v\u2208V log\n( 1 +\nz2t\u22121,v \u03c32\n) \u2264 dn log ( 1 +\nnKu d\u03bb\u03c32 ) Notice that z2t\u22121,v = x T v \u03a3 \u22121 t\u22121xv \u2264 xTv \u03a3 \u22121 0 xv = \u2016xv\u20162 \u03bb \u2264 1 \u03bb . Moreover, for all y \u2208 [0, 1/\u03bb], we have log ( 1 + y\u03c32 ) \u2265\n\u03bb log ( 1 + 1\u03bb\u03c32 ) y based on the concavity of log(\u00b7). Thus, we have\n\u03bb log ( 1 + 1\n\u03bb\u03c32 ) T\u2211 t=1 1 (u \u2208 St) \u2211 v\u2208V z2t\u22121,v \u2264 dn log ( 1 + nKu d\u03bb\u03c32 ) .\nFinally, from Cauchy-Schwarz inequality, we have that\nT\u2211 t=1 1 (u \u2208 St) \u2211 v\u2208V zt\u22121,v \u2264 \u221a nKu \u221a\u221a\u221a\u221a T\u2211 t=1 1 (u \u2208 St) \u2211 v\u2208V z2t\u22121,v.\nCombining the above results, we have\nT\u2211 t=1 1 (u \u2208 St) \u2211 v\u2208V zt\u22121,v \u2264 \u221a nKu\n\u221a dn log ( 1 + nKud\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32\n) . (19) This concludes the proof for general X . Based on Equation 16, the analysis for the tabular (X = I) case is similar, and we omit the detailed analysis. In the tabular case, we have\nT\u2211 t=1 1 (u \u2208 St) \u2211 v\u2208V zt\u22121,v \u2264 \u221a nKu\n\u221a n log ( 1 + Ku\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32 ) . (20)\nWe now develop a worst-case bound. Notice that for general X , we have\n\u2211 u\u2208V T\u2211 t=1 1 [u \u2208 St] \u2211 v\u2208V \u221a xTv \u03a3 \u22121 u,t\u22121xv \u2264 \u2211 u\u2208V \u221a nKu\n\u221a dn log ( 1 + nKud\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32\n) (a) \u2264 n \u221a d log ( 1 + nTd\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32 ) \u2211 u\u2208V \u221a Ku\n(b) \u2264 n\n\u221a d log ( 1 + nTd\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32 ) \u221an\u221a\u2211 u\u2208V Ku\n(c) =n 3 2\n\u221a dKT log ( 1 + nTd\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32\n) , (21) where inequality (a) follows from the naive bound Ku \u2264 T , inequality (b) follows from Cauchy-Schwarz inequality, and equality (c) follows from \u2211 u\u2208V Ku = KT . Similarly, for the special case with X = I , we have\n\u2211 u\u2208V T\u2211 t=1 1 [u \u2208 St] \u2211 v\u2208V \u221a xTv \u03a3 \u22121 u,t\u22121xv \u2264 \u2211 u\u2208V \u221a nKu\n\u221a n log ( 1 + Ku\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32 ) \u2264 n 32\u221aKT log (1 + T\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32\n) . (22) This concludes the derivation of a worst-case bound. B.3. Bound on P ( F )\nWe now derive a bound on P ( F )\nbased on the \u201cSelf-Normalized Bound for Matrix-Valued Martingales\u201d developed in Appendix 3 (see Theorem 3). Before proceeding, we define Fu for all u \u2208 V as\nFu = { |xTv (\u03b8\u0302u,t\u22121 \u2212 \u03b8 \u2217 u)| \u2264 c \u221a xTv \u03a3 \u22121 u,t\u22121xv, \u2200v \u2208 V, \u2200t \u2264 T } , (23)\nand the Fu as the complement of Fu. Note that by definition, F = \u22c3 u\u2208V Fu. Hence, we first develop a bound on P ( Fu ) ,\nthen we develop a bound on P ( F ) based on union bound.\nLemma 2. For all u \u2208 V , all \u03c3, \u03bb > 0, all \u03b4 \u2208 (0, 1), and all\nc \u2265 1 \u03c3\n\u221a dn log ( 1 + nT\n\u03c32\u03bbd\n) + 2 log ( 1\n\u03b4\n) + \u221a \u03bb\u2016\u03b8\u2217u\u20162\nwe have P ( Fu ) \u2264 \u03b4.\nProof. To simplify the expositions, we omit the subscript u in this proof. For instance, we use \u03b8\u2217, \u03a3t, yt and bt to respectively denote \u03b8\u2217u, \u03a3u,t, yu,t and bu,t. We also use Ht to denote the \u201chistory\u201d by the end of time t, and hence {Ht}\u221et=0 is a filtration. Notice that Ut isHt\u22121-adaptive, and hence St and 1 [u \u2208 St] are alsoHt\u22121-adaptive. We define\n\u03b7t = { yt \u2212XT \u03b8\u2217 if u \u2208 St 0 otherwise \u2208 < n and Xt = { X if u \u2208 St 0 otherwise \u2208 < d\u00d7n (24)\nNote that Xt is Ht\u22121-adaptive, and \u03b7t is Ht-adaptive. Moreover, \u2016\u03b7t\u2016\u221e \u2264 1 always holds, and E [\u03b7t|Ht\u22121] = 0. To simplify the expositions, we further define yt = 0 for all t s.t. u /\u2208 St. Note that with this definition, we have\n\u03b7t = yt \u2212XTt \u03b8\u2217 for all t. We further define\nV t =n\u03c3 2\u03a3t = n\u03c3 2\u03bbI + n t\u2211 s=1 XsX T s\nSt = t\u2211 s=1 Xs\u03b7s = t\u2211 s=1 Xs [ ys \u2212XTs \u03b8\u2217 ] = bt \u2212 \u03c32 [\u03a3t \u2212 \u03bbI] \u03b8\u2217 (25)\nThus, we have \u03a3t\u03b8\u0302t = \u03c3\u22122bt = \u03c3\u22122St + [\u03a3t \u2212 \u03bbI]\u03b8\u2217, which implies\n\u03b8\u0302t \u2212 \u03b8\u2217 = \u03a3\u22121t [ \u03c3\u22122St \u2212 \u03bb\u03b8\u2217 ] . (26)\nConsequently, for any v \u2208 V , we have\u2223\u2223\u2223xTv (\u03b8\u0302t \u2212 \u03b8\u2217)\u2223\u2223\u2223 = \u2223\u2223xTv \u03a3\u22121t [\u03c3\u22122St \u2212 \u03bb\u03b8\u2217]\u2223\u2223 \u2264\u221axTv \u03a3\u22121t xv\u2016\u03c3\u22122St \u2212 \u03bb\u03b8\u2217\u2016\u03a3\u22121t \u2264 \u221a xTv \u03a3 \u22121 t xv [ \u2016\u03c3\u22122St\u2016\u03a3\u22121t + \u2016\u03bb\u03b8 \u2217\u2016\u03a3\u22121t ] , (27)\nwhere the first inequality follows from Cauchy-Schwarz inequality and the second inequality follows from triangular inequality. Note that \u2016\u03bb\u03b8\u2217\u2016\u03a3\u22121t = \u03bb\u2016\u03b8 \u2217\u2016\u03a3\u22121t \u2264 \u03bb\u2016\u03b8 \u2217\u2016\u03a3\u221210 = \u221a \u03bb\u2016\u03b8\u2217\u20162. On the other hand, since \u03a3\u22121t = n\u03c32V \u22121 t , we have \u2016\u03c3\u22122St\u2016\u03a3\u22121t = \u221a n \u03c3 \u2016St\u2016V \u22121t . Thus, we have\u2223\u2223\u2223xTv (\u03b8\u0302t \u2212 \u03b8\u2217)\u2223\u2223\u2223 \u2264\u221axTv \u03a3\u22121t xv [\u221an\u03c3 \u2016St\u2016V \u22121t +\u221a\u03bb\u2016\u03b8\u2217\u20162 ] . (28)\nFrom Theorem 3, we know with probability at least 1\u2212 \u03b4, for all t \u2264 T , we have\n\u2016St\u20162V \u22121t \u2264 2 log\n( det ( V t )1/2 det (V ) \u22121/2\n\u03b4\n) \u2264 2 log ( det ( V T )1/2 det (V ) \u22121/2\n\u03b4\n) ,\nwhere V = n\u03c32\u03bbI . Note that from the trace-determinant inequality, we have\ndet [ V T ] 1 d \u2264\nTr [ V T ]\nd \u2264 n\u03c3\n2\u03bbd+ n2T\nd ,\nwhere the last inequality follows from Tr [ XtX T t ] \u2264 n for all t. Note that det [V ] = [ n\u03c32\u03bb ]d , with a little bit algebra, we have\n\u2016St\u2016V \u22121t \u2264\n\u221a d log ( 1 + nT\n\u03c32\u03bbd\n) + 2 log ( 1\n\u03b4\n) \u2200t \u2264 T\nwith probability at least 1\u2212 \u03b4. Thus, if\nc \u2265 1 \u03c3\n\u221a dn log ( 1 + nT\n\u03c32\u03bbd\n) + 2 log ( 1\n\u03b4\n) + \u221a \u03bb\u2016\u03b8\u2217\u20162,\nthen Fu holds with probability at least 1\u2212 \u03b4. This concludes the proof of this lemma.\nHence, from the union bound, we have the following lemma:\nLemma 3. For all \u03c3, \u03bb > 0, all \u03b4 \u2208 (0, 1), and all\nc \u2265 1 \u03c3\n\u221a dn log ( 1 + nT\n\u03c32\u03bbd\n) + 2 log (n \u03b4 ) + \u221a \u03bbmax u\u2208V \u2016\u03b8\u2217u\u20162 (29)\nwe have P ( F ) \u2264 \u03b4. Proof. This lemma follows directly from the union bound. Note that for all c satisfying Equation 29, we have P ( Fu ) \u2264 \u03b4n\nfor all u \u2208 V , which implies P ( F ) = P (\u22c3 u\u2208V Fu ) \u2264 \u2211 u\u2208V P ( Fu ) \u2264 \u03b4.\nB.4. Conclude the Proof\nNote that if we choose\nc \u2265 1 \u03c3\n\u221a dn log ( 1 + nT\n\u03c32\u03bbd\n) + 2 log (n2T ) +\n\u221a \u03bbmax u\u2208V \u2016\u03b8\u2217u\u20162, (30)\nwe have P ( F ) \u2264 1nT . Hence for general X , we have\nR\u03c1\u03b1(T ) \u2264 2c \u03c1\u03b1 E { T\u2211 t=1 \u2211 u\u2208St \u2211 v\u2208V \u221a xTv \u03a3 \u22121 u,t\u22121xv \u2223\u2223\u2223\u2223\u2223F } + 1 \u03c1\n\u2264 2c \u03c1\u03b1 n 3 2\n\u221a dKT log ( 1 + nTd\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32 ) + 1 \u03c1 . (31)\nNote that with c = 1\u03c3\n\u221a dn log ( 1 + nT\u03c32\u03bbd ) + 2 log (n2T ) + \u221a \u03bbmaxu\u2208V \u2016\u03b8\u2217u\u20162, this regret bound is O\u0303 ( n2d \u221a KT \u03c1\u03b1 ) . Simi-\nlarly, for the special case X = I , we have\nR\u03c1\u03b1(T ) \u2264 2c \u03c1\u03b1 n 3 2\n\u221a KT log ( 1 + T\u03bb\u03c32 ) \u03bb log ( 1 + 1\u03bb\u03c32 ) + 1 \u03c1 . (32)\nNote that with c = n\u03c3 \u221a log ( 1 + T\u03c32\u03bb ) + 2 log (n2T ) + \u221a \u03bbmaxu\u2208V \u2016\u03b8\u2217u\u20162 \u2264 n\u03c3 \u221a log ( 1 + T\u03c32\u03bb ) + 2 log (n2T ) + \u221a \u03bbn,\nthis regret bound is O\u0303 ( n 5 2 \u221a KT\n\u03c1\u03b1\n) ."}, {"heading": "C. Self-Normalized Bound for Matrix-Valued Martingales", "text": "In this section, we derive a \u201cself-normalized bound\u201d for matrix-valued Martingales. This result is a natural generalization of Theorem 1 in Abbasi-Yadkori et al. (2011).\nTheorem 3. (Self-Normalized Bound for Matrix-Valued Martingales) Let {Ht}\u221et=0 be a filtration, and {\u03b7t} \u221e t=1 be a <Kvalued Martingale difference sequence with respect to {Ht}\u221et=0. Specifically, for all t, \u03b7t isHt-measurable and satisfies (1) E [\u03b7t|Ht\u22121] = 0 and (2) \u2016\u03b7t\u2016\u221e \u2264 1 with probability 1 conditioning on Ht\u22121. Let {Xt}\u221et=1 be a <d\u00d7K-valued stochastic process such that Xt isHt\u22121 measurable. Assume that V \u2208 <d\u00d7d is a positive-definite matrix. For any t \u2265 0, define\nV t = V +K t\u2211 s=1 XsX T s St = t\u2211 s=1 Xs\u03b7s. (33)\nThen, for any \u03b4 > 0, with probability at least 1\u2212 \u03b4, we have\n\u2016St\u20162V \u22121t \u2264 2 log\n( det ( V t )1/2 det (V ) \u22121/2\n\u03b4\n) \u2200t \u2265 0. (34)\nWe first define some useful notations. Similarly as Abbasi-Yadkori et al. (2011), for any \u03bb \u2208 <d and any t, we define D\u03bbt as\nD\u03bbt = exp ( \u03bbTXt\u03b7t \u2212 K\n2 \u2016XTt \u03bb\u201622\n) , (35)\nand M\u03bbt = \u220ft s=1D \u03bb s with convention M \u03bb 0 = 1. Note that both D \u03bb t and M \u03bb t are Ht-measurable, and { M\u03bbt }\u221e t=0 is a\nsupermartingale with respect to the filtration {Ht}\u221et=0. To see it, notice that conditioning onHt\u22121, we have\n\u03bbTXt\u03b7t = (X T t \u03bb) T \u03b7t \u2264 \u2016XTt \u03bb\u20161\u2016\u03b7t\u2016\u221e \u2264 \u2016XTt \u03bb\u20161 \u2264 \u221a K\u2016XTt \u03bb\u20162\nwith probability 1. This implies that \u03bbTXt\u03b7t is conditionally \u221a K\u2016XTt \u03bb\u20162-subGaussian. Thus, we have\nE [ D\u03bbt \u2223\u2223Ht\u22121] = E [exp (\u03bbTXt\u03b7t)\u2223\u2223Ht\u22121] exp(\u2212K\n2 \u2016XTt \u03bb\u201622\n) \u2264 exp ( K\n2 \u2016XTt \u03bb\u201622 \u2212\nK\n2 \u2016XTt \u03bb\u201622\n) = 1.\nThus, E [ M\u03bbt \u2223\u2223Ht\u22121] = M\u03bbt\u22121E [D\u03bbt \u2223\u2223Ht\u22121] \u2264M\u03bbt\u22121. So { M\u03bbt }\u221e t=0\nis a supermartingale with respect to the filtration {Ht}\u221et=0. Then, following Lemma 8 of Abbasi-Yadkori et al. (2011), we have the following lemma:\nLemma 4. Let \u03c4 be a stopping time with respect to the filtration {Ht}\u221et=0. Then for any \u03bb \u2208 <d, M\u03bb\u03c4 is almost surely well-defined and E [ M\u03bb\u03c4 ] \u2264 1.\nProof. First, we argue that M\u03bb\u03c4 is almost surely well-defined. By Doob\u2019s convergence theorem for nonnegative supermartingales, M\u03bb\u221e = limt\u2192\u221eM \u03bb t is almost surely well-defined. Hence M \u03bb \u03c4 is indeed well-defined independent of \u03c4 <\u221e\nor not. Next, we show that E [ M\u03bb\u03c4 ] \u2264 1. Let Q\u03bbt = M\u03bbmin{\u03c4,t} be a stopped version of { M\u03bbt }\u221e t=1\n. By Fatou\u2019s Lemma, we have E [ M\u03bb\u03c4 ] = E [ lim inft\u2192\u221eQ \u03bb t ] \u2264 lim inft\u2192\u221e E [ Q\u03bbt ] \u2264 1.\nThe following results follow from Lemma 9 of Abbasi-Yadkori et al. (2011), which uses the \u201cmethod of mixtures\u201d technique. Let \u039b be a Gaussian random vector in <d with mean 0 and covariance matrix V \u22121, and independent of all the other random variables. Let H\u221e be the tail \u03c3-algebra of the filtration, i.e. the \u03c3-algebra generated by the union of all events in the filtration. We further define Mt = E [ M\u039bt\n\u2223\u2223H\u221e] for all t = 0, 1, . . . and t = \u221e. Note that M\u221e is almost surely well-defined since M\u03bb\u221e is almost surely well-defined. Let \u03c4 be a stopping time with respect to the filtration {Ht}\u221et=0. Note that M\u03c4 is almost surely well-defined since M\u221e is almost surely well-defined. Since E [ M\u03bb\u03c4 ] \u2264 1 from Lemma 4, we have\nE [M\u03c4 ] = E [ M\u039b\u03c4 ] = E [ E [ M\u039b\u03c4 \u2223\u2223\u039b]] \u2264 1. The following lemma follows directly from the proof for Lemma 9 of Abbasi-Yadkori et al. (2011), which can be derived by algebra. The proof is omitted here.\nLemma 5. For all finite t = 0, 1, . . ., we have\nMt =\n( det(V )\ndet(V t)\n)1/2 exp ( 1\n2 \u2016St\u2016V \u22121t\n) . (36)\nNote that Lemma 5 implies that for finite t, \u2016St\u20162 V\n\u22121 t\n> 2 log\n( det(V t) 1/2 det(V )\u22121/2\n\u03b4\n) and Mt > 1\u03b4 are equivalent.\nConsequently, for any stopping time \u03c4 , the event{ \u03c4 <\u221e, \u2016S\u03c4\u20162V \u22121\u03c4 > 2 log ( det ( V \u03c4 )1/2 det (V ) \u22121/2 \u03b4 )} is equivalent to { \u03c4 <\u221e, M\u03c4 > 1\u03b4 } . Finally, we prove Theorem 3:\nProof. We define the \u201cbad event\u201d at time t = 0, 1, . . . as:\nBt(\u03b4) = { \u2016St\u20162V \u22121t > 2 log ( det ( V t )1/2 det (V ) \u22121/2 \u03b4 )} .\nWe are interested in bounding the probability of the \u201cbad event\u201d \u22c3\u221e t=1Bt(\u03b4). Let \u2126 denote the sample space, for any outcome \u03c9 \u2208 \u2126, we define \u03c4(\u03c9) = min{t \u2265 0 : \u03c9 \u2208 Bt(\u03b4)}, with the convention that min \u2205 = +\u221e. Thus, \u03c4 is a stopping time. Notice that \u22c3\u221e t=1Bt(\u03b4) = {\u03c4 < \u221e}. Moreover, if \u03c4 < \u221e, then by definition of \u03c4 , we have\n\u2016S\u03c4\u20162 V\n\u22121 \u03c4\n> 2 log\n( det(V \u03c4) 1/2 det(V )\u22121/2\n\u03b4\n) , which is equivalent to M\u03c4 > 1\u03b4 as discussed above. Thus we have\nP ( \u221e\u22c3 t=1 Bt(\u03b4) ) (a) = P (\u03c4 <\u221e)\n(b) = P ( \u2016S\u03c4\u20162V \u22121\u03c4 > 2 log ( det ( V \u03c4 )1/2 det (V ) \u22121/2 \u03b4 ) , \u03c4 <\u221e ) (c) = P (M\u03c4 > 1/\u03b4, \u03c4 <\u221e) \u2264P (M\u03c4 > 1/\u03b4)\n(d) \u2264 \u03b4,\nwhere equalities (a) and (b) follow from the definition of \u03c4 , equality (c) follows from Lemma 5, and inequality (d) follows from Markov\u2019s inequality. This concludes the proof for Theorem 3.\nWe conclude this section by briefly discussing a special case. If for any t, the elements of \u03b7t are statistically independent conditioning on Ht\u22121, then we can prove a variant of Theorem 3: with V t = V + \u2211t s=1XsX T s and St = \u2211t s=1Xs\u03b7s, Equation 34 holds with probability at least 1\u2212 \u03b4. To see it, notice that in this case\nE [ exp ( \u03bbTXt\u03b7t )\u2223\u2223Ht\u22121] =E[ K\u220f k=1 exp ( (XTt \u03bb)(k)\u03b7t(k) )\u2223\u2223\u2223\u2223\u2223Ht\u22121 ]\n(a) = K\u220f k=1 E [ exp ( (XTt \u03bb)(k)\u03b7t(k) )\u2223\u2223Ht\u22121] (b)\n\u2264 K\u220f k=1 exp ( (XTt \u03bb)(k) 2 2 ) = exp (\u2225\u2225XTt \u03bb\u2225\u22252 2 ) , (37)\nwhere (k) denote the k-th element of the vector. Note that the equality (a) follows from the conditional independence of the elements in \u03b7t, and inequality (b) follows from |\u03b7t(k)| \u2264 1 for all t and k. Thus, if we redefine D\u03bbt = exp ( \u03bbTXt\u03b7t \u2212 12\u2016X T t \u03bb\u201622 ) , and M\u03bbt = \u220ft s=1D \u03bb s , we can prove that {M\u03bbt }t is a supermartingale. Consequently, using similar analysis techniques, we can prove the variant of Theorem 3 discussed in this paragraph."}, {"heading": "D. Laplacian Regularization", "text": "As explained in section 7, enforcing Laplacian regularization leads to the following optimization problem:\n\u03b8\u0302t = arg min \u03b8 [ t\u2211 j=1 \u2211 u\u2208St (yu,j \u2212 \u03b8uX)2 + \u03bb2 \u2211 (u1,u2)\u2208E ||\u03b8u1 \u2212 \u03b8u2 ||22]\nHere, the first term is the data fitting term, whereas the second term is the Laplacian regularization terms which enforces smoothness in the source node estimates. This can optimization problem can be re-written as follows:\n\u03b8\u0302t = arg min \u03b8 [ t\u2211 j=1 \u2211 u\u2208St (yu,j \u2212 \u03b8uX)2 + \u03bb2\u03b8T (L\u2297 Id)\u03b8 ]\nHere, \u03b8 \u2208 <dn is the concatenation of the n d-dimensional \u03b8u vectors and A \u2297 B refers to the Kronecker product of matrices A and B. Setting the gradient of equation 38 to zero results in solving the following linear system:\n[XXT \u2297 In + \u03bb2L\u2297 Id]\u03b8\u0302t = bt (38)\nHere bt corresponds to the concatenation of the n d-dimensional vectors bu,t. This is the Sylvester equation and there exist sophisticated methods of solving it. For simplicity, we focus on the special case when the features are derived from the Laplacian eigenvectors (Section 7).\nLet \u03b2t be a diagonal matrix such that \u03b2tu, u refers to the number of times node u has been selected as the source. Since the Laplacian eigenvectors are orthogonal, when using Laplacian features, XXT \u2297 In = \u03b2\u2297 Id. We thus obtain the following system:\n[(\u03b2 + \u03bb2L)\u2297 Id]\u03b8\u0302t = bt (39)\nNote that (\u03b2 + \u03bb2L) and thus (\u03b2 + \u03bb2L)\u2297 Id is positive semi-definite and can be solved using conjugate gradient.\nFor conjugate gradient, the most expensive operation is the matrix-vector multiplication (\u03b2 + \u03bb2L)\u2297 Id]v for an arbitrary vector v. Let vec be an operation that takes a d\u00d7 n matrix and stacks it column-wise converting it into a dn-dimensional vector. Let V refer to the d \u00d7 n matrix obtained by partitioning the vector v into columns of V . Given this notation, we use the property that (BT \u2297 A)v = vec(AV B). This implies that the matrix-vector multiplication can then be rewritten as follows:\n(\u03b2 + \u03bb2L)\u2297 Idv = vec(V ( \u03b2 + \u03bb2L T ) ) (40)\nSince \u03b2 is a diagonal matrix, V \u03b2 is an O(dn) operation, whereas V LT is an O(dm) operation since there are only m non-zeros (corresponding to edges) in the Laplacian matrix. Hence the complexity of computing the mean \u03b8\u0302t is an order O((d(m + n))\u03ba) where \u03ba is the number of conjugate gradient iterations. In our experiments, by warm-starting with the solution at the previous round, we found that \u03ba = 5 was enough for convergence.\nUnlike independent estimation where we update the UCB estimates for only the selected nodes, when using Laplacian regularization, the upper confidence values for each reachability probability need to be recomputed in each round. Once we have an estimate of \u03b8, calculating the mean estimates for the reachabilities for all u, v requires O(dn2) computation. This is the most expensive step when using Laplacian regularization.\nWe now describe how to compute the confidence intervals. For this, letD denote the diagonal of (\u03b2 + \u03bb2L)\u22121. The UCB value zu,v,t can then be computed as:\nzu,v,t = \u221a Du||xv||2 (41)\nThe `2 norms for all the target nodes v can be pre-computed. If we maintain the D vector, the confidence intervals for all pairs can be computed in O(n2) time.\nNote thatDt requires O(n) storage and can be updated across rounds in O(K) time using the Sherman Morrison formula. Specifically, ifDu,t refers to the uth element in the vectorDt, then\nDu,t+1 =  Du,t (1 +Du,t) , ifu \u2208 St\nDu,t, otherwise\nHence, the total complexity of implementing Laplacian regularization is O(dn2). We need to store the \u03b8 vector, the Laplacian and the diagonal vectors \u03b2 andD. Hence, the total memory requirement is O(dn+m)."}], "references": [{"title": "Improved algorithms for linear stochastic bandits", "author": ["Abbasi-Yadkori", "Yasin", "P\u00e1l", "D\u00e1vid", "Szepesv\u00e1ri", "Csaba"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Abbasi.Yadkori et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Abbasi.Yadkori et al\\.", "year": 2011}, {"title": "Topic-aware social influence propagation models", "author": ["Barbieri", "Nicola", "Bonchi", "Francesco", "Manco", "Giuseppe"], "venue": "Knowledge and information systems,", "citeRegEx": "Barbieri et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Barbieri et al\\.", "year": 2013}, {"title": "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples", "author": ["Belkin", "Mikhail", "Niyogi", "Partha", "Sindhwani", "Vikas"], "venue": "Journal of machine learning research,", "citeRegEx": "Belkin et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Belkin et al\\.", "year": 2006}, {"title": "Revealing graph bandits for maximizing local influence", "author": ["Carpentier", "Alexandra", "Valko", "Michal"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Carpentier et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Carpentier et al\\.", "year": 2016}, {"title": "A gang of bandits", "author": ["Cesa-Bianchi", "Nicolo", "Gentile", "Claudio", "Zappella", "Giovanni"], "venue": "In Advances in Neural Information Processing Systems, pp", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2013}, {"title": "Efficient influence maximization in social networks", "author": ["Chen", "Wei", "Wang", "Yajun", "Yang", "Siyu"], "venue": "In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Chen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2009}, {"title": "Combinatorial multi-armed bandit and its extension to probabilistically triggered arms", "author": ["Chen", "Wei", "Wang", "Yajun", "Yuan", "Yang", "Qinshi"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Chen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Stochastic linear optimization under bandit feedback", "author": ["Dani", "Varsha", "Hayes", "Thomas P", "Kakade", "Sham M"], "venue": "In COLT, pp", "citeRegEx": "Dani et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Dani et al\\.", "year": 2008}, {"title": "Influence Function Learning in Information Diffusion Networks", "author": ["Du", "Nan", "Liang", "Yingyu", "Balcan", "Maria-Florina", "Song", "Le"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Du et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Du et al\\.", "year": 2014}, {"title": "Learning multiple tasks with kernel methods", "author": ["Evgeniou", "Theodoros", "Micchelli", "Charles A", "Pontil", "Massimiliano"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Evgeniou et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Evgeniou et al\\.", "year": 2005}, {"title": "Networked bandits with disjoint linear payoffs", "author": ["Fang", "Meng", "Tao", "Dacheng"], "venue": "In Internattional Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Fang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fang et al\\.", "year": 2014}, {"title": "Online clustering of bandits", "author": ["Gentile", "Claudio", "Li", "Shuai", "Zappella", "Giovanni"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Gentile et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gentile et al\\.", "year": 2014}, {"title": "Influence maximization in continuous time diffusion networks", "author": ["M Gomez Rodriguez", "B Sch\u00f6lkopf", "Pineau", "Langford J"], "venue": "In 29th International Conference on Machine Learning (ICML", "citeRegEx": "Rodriguez et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rodriguez et al\\.", "year": 2012}, {"title": "Learning influence probabilities in social networks", "author": ["Goyal", "Amit", "Bonchi", "Francesco", "Lakshmanan", "Laks VS"], "venue": "In Proceedings of the third ACM international conference on Web search and data mining,", "citeRegEx": "Goyal et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Goyal et al\\.", "year": 2010}, {"title": "A data-based approach to social influence maximization", "author": ["Goyal", "Amit", "Bonchi", "Francesco", "Lakshmanan", "Laks VS"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "Goyal et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Goyal et al\\.", "year": 2011}, {"title": "Simpath: An efficient algorithm for influence maximization under the linear threshold model", "author": ["Goyal", "Amit", "Lu", "Wei", "Lakshmanan", "Laks VS"], "venue": "In Data Mining (ICDM),", "citeRegEx": "Goyal et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Goyal et al\\.", "year": 2011}, {"title": "node2vec: Scalable feature learning for networks", "author": ["Grover", "Aditya", "Leskovec", "Jure"], "venue": "In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Grover et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Grover et al\\.", "year": 2016}, {"title": "Maximizing the spread of influence through a social network", "author": ["Kempe", "David", "Kleinberg", "Jon", "Tardos", "\u00c9va"], "venue": "In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Kempe et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kempe et al\\.", "year": 2003}, {"title": "Submodular function maximization. Tractability: Practical Approaches to Hard Problems", "author": ["Krause", "Andreas", "Golovin", "Daniel"], "venue": null, "citeRegEx": "Krause et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krause et al\\.", "year": 2012}, {"title": "Tight regret bounds for stochastic combinatorial semi-bandits", "author": ["Kveton", "Branislav", "Wen", "Zheng", "Ashkan", "Azin", "Szepesvari", "Csaba"], "venue": "In AISTATS,", "citeRegEx": "Kveton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kveton et al\\.", "year": 2015}, {"title": "Online influence maximization", "author": ["Lei", "Siyu", "Maniu", "Silviu", "Mo", "Luyi", "Cheng", "Reynold", "Senellart", "Pierre"], "venue": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data", "citeRegEx": "Lei et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lei et al\\.", "year": 2015}, {"title": "SNAP Datasets: Stanford large network dataset collection", "author": ["Leskovec", "Jure", "Krevl", "Andrej"], "venue": "http://snap. stanford.edu/data,", "citeRegEx": "Leskovec et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2014}, {"title": "Kronecker graphs: An approach to modeling networks", "author": ["Leskovec", "Jure", "Chakrabarti", "Deepayan", "Kleinberg", "Jon", "Faloutsos", "Christos", "Ghahramani", "Zoubin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Leskovec et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2010}, {"title": "Accelerated greedy algorithms for maximizing submodular set functions", "author": ["Minoux", "Michel"], "venue": "In Optimization Techniques,", "citeRegEx": "Minoux and Michel.,? \\Q1978\\E", "shortCiteRegEx": "Minoux and Michel.", "year": 1978}, {"title": "An analysis of approximations for maximizing submodular set functions", "author": ["Nemhauser", "George L", "Wolsey", "Laurence A", "Fisher", "Marshall L"], "venue": "Mathematical Programming,", "citeRegEx": "Nemhauser et al\\.,? \\Q1978\\E", "shortCiteRegEx": "Nemhauser et al\\.", "year": 1978}, {"title": "Learning the graph of epidemic cascades", "author": ["Netrapalli", "Praneeth", "Sanghavi", "Sujay"], "venue": "In ACM SIGMETRICS Performance Evaluation Review,", "citeRegEx": "Netrapalli et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Netrapalli et al\\.", "year": 2012}, {"title": "Deepwalk: Online learning of social representations", "author": ["Perozzi", "Bryan", "Al-Rfou", "Rami", "Skiena", "Steven"], "venue": "In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Perozzi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Perozzi et al\\.", "year": 2014}, {"title": "Prediction of information diffusion probabilities for independent cascade model", "author": ["Saito", "Kazumi", "Nakano", "Ryohei", "Kimura", "Masahiro"], "venue": "In Knowledge-Based Intelligent Information and Engineering Systems,", "citeRegEx": "Saito et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Saito et al\\.", "year": 2008}, {"title": "Influence maximization: Near-optimal time complexity meets practical efficiency", "author": ["Tang", "Youze", "Xiao", "Xiaokui", "Yanchen", "Shi"], "venue": null, "citeRegEx": "Tang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2014}, {"title": "Influence maximization in near-linear time: A martingale approach", "author": ["Tang", "Youze", "Shi", "Yanchen", "Xiao", "Xiaokui"], "venue": "In Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "Tang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2015}, {"title": "Spectral bandits for smooth graph functions", "author": ["Valko", "Michal", "Munos", "R\u00e9mi", "Kveton", "Branislav", "Koc\u00e1k", "Tom\u00e1\u0161"], "venue": "In 31th International Conference on Machine Learning,", "citeRegEx": "Valko et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Valko et al\\.", "year": 2014}, {"title": "Influence maximization with bandits", "author": ["Vaswani", "Sharan", "Lakshmanan", "Laks. V. S", "Mark Schmidt"], "venue": "Technical report,", "citeRegEx": "Vaswani et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vaswani et al\\.", "year": 2015}, {"title": "A tutorial on spectral clustering", "author": ["Von Luxburg", "Ulrike"], "venue": "Statistics and computing,", "citeRegEx": "Luxburg and Ulrike.,? \\Q2007\\E", "shortCiteRegEx": "Luxburg and Ulrike.", "year": 2007}, {"title": "Efficient learning in large-scale combinatorial semi-bandits", "author": ["Wen", "Zheng", "Kveton", "Branislav", "Ashkan", "Azin"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning, ICML 2015,", "citeRegEx": "Wen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2015}, {"title": "Influence maximization with semi-bandit feedback", "author": ["Wen", "Zheng", "Kveton", "Branislav", "Valko", "Michal"], "venue": "arXiv preprint arXiv:1605.06593,", "citeRegEx": "Wen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2016}, {"title": "Self-Normalized Bound for Matrix-Valued Martingales In this section, we derive a \u201cself-normalized bound\u201d for matrix-valued Martingales. This result is a natural generalization of Theorem 1 in Abbasi-Yadkori et al", "author": [], "venue": null, "citeRegEx": "C.,? \\Q2011\\E", "shortCiteRegEx": "C.", "year": 2011}, {"title": "The following results follow from Lemma 9 of Abbasi-Yadkori et al. (2011), which uses the \u201cmethod of mixtures\u201d technique. Let \u039b be a Gaussian random vector in < with mean 0 and covariance matrix V \u22121, and independent of all the other random variables", "author": [], "venue": null, "citeRegEx": "1.,? \\Q2011\\E", "shortCiteRegEx": "1.", "year": 2011}], "referenceMentions": [{"referenceID": 17, "context": "The IM problem has been studied under various probabilistic diffusion models such as Independent Cascade (IC) and Linear Threshold (LT) models (Kempe et al., 2003).", "startOffset": 143, "endOffset": 163}, {"referenceID": 5, "context": "Under these common models, there has been substantial work on developing efficient heuristics and approximation algorithms (Chen et al., 2009; Leskovec et al., 2007; Goyal et al., 2011b;a; Tang et al., 2014; 2015).", "startOffset": 123, "endOffset": 213}, {"referenceID": 28, "context": "Under these common models, there has been substantial work on developing efficient heuristics and approximation algorithms (Chen et al., 2009; Leskovec et al., 2007; Goyal et al., 2011b;a; Tang et al., 2014; 2015).", "startOffset": 123, "endOffset": 213}, {"referenceID": 17, "context": "In practice, it is not clear how to choose from amongst the increasing number of plausible diffusion models (Kempe et al., 2003; Gomez Rodriguez et al., 2012; Li et al., 2013).", "startOffset": 108, "endOffset": 175}, {"referenceID": 27, "context": "Some papers try to learn these parameters from past propagation data (Saito et al., 2008; Goyal et al., 2010; Netrapalli & Sanghavi, 2012).", "startOffset": 69, "endOffset": 138}, {"referenceID": 13, "context": "Some papers try to learn these parameters from past propagation data (Saito et al., 2008; Goyal et al., 2010; Netrapalli & Sanghavi, 2012).", "startOffset": 69, "endOffset": 138}, {"referenceID": 5, "context": "Under these common models, there has been substantial work on developing efficient heuristics and approximation algorithms (Chen et al., 2009; Leskovec et al., 2007; Goyal et al., 2011b;a; Tang et al., 2014; 2015). Unfortunately, knowledge of the underlying diffusion model and its parameters is essential for the existing IM algorithms to perform well. For example, Du et al. (2014) empirically showed that misspecification of the diffusion model can lead to choosing bad seeds and consequently to a low spread.", "startOffset": 124, "endOffset": 384}, {"referenceID": 5, "context": "Under these common models, there has been substantial work on developing efficient heuristics and approximation algorithms (Chen et al., 2009; Leskovec et al., 2007; Goyal et al., 2011b;a; Tang et al., 2014; 2015). Unfortunately, knowledge of the underlying diffusion model and its parameters is essential for the existing IM algorithms to perform well. For example, Du et al. (2014) empirically showed that misspecification of the diffusion model can lead to choosing bad seeds and consequently to a low spread. In practice, it is not clear how to choose from amongst the increasing number of plausible diffusion models (Kempe et al., 2003; Gomez Rodriguez et al., 2012; Li et al., 2013). Even if we are able to choose a diffusion model according to some prior information, the number of parameters for these models scales with the size of the network (for example, it is equal to the number of edges for both the IC and LT models) and it is not clear how to set these. Goyal et al. (2011a) showed that even when assuming the IC or LT model, correct knowledge of the model parameters is critical to choosing good seeds that lead to a large spread.", "startOffset": 124, "endOffset": 992}, {"referenceID": 31, "context": "This motivates the learning framework of IM semi-bandits (Vaswani et al., 2015; Chen et al., 2016; Wen et al., 2016).", "startOffset": 57, "endOffset": 116}, {"referenceID": 6, "context": "This motivates the learning framework of IM semi-bandits (Vaswani et al., 2015; Chen et al., 2016; Wen et al., 2016).", "startOffset": 57, "endOffset": 116}, {"referenceID": 34, "context": "This motivates the learning framework of IM semi-bandits (Vaswani et al., 2015; Chen et al., 2016; Wen et al., 2016).", "startOffset": 57, "endOffset": 116}, {"referenceID": 6, "context": "Our feedback model is weaker than the edge-level feedback proposed in (Chen et al., 2016; Wen et al., 2016).", "startOffset": 70, "endOffset": 107}, {"referenceID": 34, "context": "Our feedback model is weaker than the edge-level feedback proposed in (Chen et al., 2016; Wen et al., 2016).", "startOffset": 70, "endOffset": 107}, {"referenceID": 24, "context": "Although IM is an NP-hard problem in general, under common diffusion models such as IC and LT, the objective function F (S) is monotone and submodular, and thus, a near-optimal solution can be efficiently computed using a greedy algorithm (Nemhauser et al., 1978).", "startOffset": 239, "endOffset": 263}, {"referenceID": 17, "context": "Note that all progressive diffusion models (models where once the user is influenced, they can not change their state), including those in (Kempe et al., 2003; Gomez Rodriguez et al., 2012; Li et al., 2013) satisfy Assumption 1.", "startOffset": 139, "endOffset": 206}, {"referenceID": 6, "context": "Note that our assumption is strictly weaker than (and implied by) edge level semi-bandit feedback (Chen et al., 2016; Wen et al., 2016), since in that case, we can identify the edges along which the diffusion travelled, and thus, determine whether a particular source node is responsible for activating a target node.", "startOffset": 98, "endOffset": 135}, {"referenceID": 34, "context": "Note that our assumption is strictly weaker than (and implied by) edge level semi-bandit feedback (Chen et al., 2016; Wen et al., 2016), since in that case, we can identify the edges along which the diffusion travelled, and thus, determine whether a particular source node is responsible for activating a target node.", "startOffset": 98, "endOffset": 135}, {"referenceID": 33, "context": "To develop statistically efficient algorithms for large-scale IM semi-bandits, similar to the existing work on linear bandits (Wen et al., 2015; 2016), we make a linear generalization assumption.", "startOffset": 126, "endOffset": 150}, {"referenceID": 34, "context": "Since various approximations might be used for computing the seed set, similar to (Wen et al., 2016; Chen et al., 2016), we measure the performance of an IM semi-bandit algorithm by scaled cumulative regret.", "startOffset": 82, "endOffset": 119}, {"referenceID": 6, "context": "Since various approximations might be used for computing the seed set, similar to (Wen et al., 2016; Chen et al., 2016), we measure the performance of an IM semi-bandit algorithm by scaled cumulative regret.", "startOffset": 82, "endOffset": 119}, {"referenceID": 7, "context": "Notice that (2) is the standard assumption for linear bandit analysis (Dani et al., 2008), and (3) can always be satisfied by rescaling the target features.", "startOffset": 70, "endOffset": 89}, {"referenceID": 19, "context": "Second, note that the \u00d5( \u221a T )-dependence on time is nearoptimal, and the \u00d5( \u221a K)-dependence on the cardinality of the seed sets is standard in the combinatorial semi-bandit literature (Kveton et al., 2015).", "startOffset": 185, "endOffset": 206}, {"referenceID": 7, "context": "Third, for general X , notice that the \u00d5(d)-dependence on feature dimension is standard in linear bandit literature (Dani et al., 2008; Wen et al., 2015).", "startOffset": 116, "endOffset": 153}, {"referenceID": 33, "context": "Third, for general X , notice that the \u00d5(d)-dependence on feature dimension is standard in linear bandit literature (Dani et al., 2008; Wen et al., 2015).", "startOffset": 116, "endOffset": 153}, {"referenceID": 5, "context": "Assuming statistical independence between these reachabilities (similar to Chen et al. (2016)) can shave off this \u00d5( \u221a n) factor.", "startOffset": 75, "endOffset": 94}, {"referenceID": 2, "context": "From (Belkin et al., 2006; Valko et al., 2014), we know that a smooth graph function (in this case, the reachability from a source) can be expressed as a linear combination of eigenvectors of the weighted Laplacian of the network.", "startOffset": 5, "endOffset": 46}, {"referenceID": 30, "context": "From (Belkin et al., 2006; Valko et al., 2014), we know that a smooth graph function (in this case, the reachability from a source) can be expressed as a linear combination of eigenvectors of the weighted Laplacian of the network.", "startOffset": 5, "endOffset": 46}, {"referenceID": 9, "context": "This idea of Laplacian regularization has been used in multi-task learning (Evgeniou et al., 2005) and for contextual-bandits (Cesa-Bianchi et al.", "startOffset": 75, "endOffset": 98}, {"referenceID": 4, "context": ", 2005) and for contextual-bandits (Cesa-Bianchi et al., 2013).", "startOffset": 35, "endOffset": 62}, {"referenceID": 22, "context": "Empirical Verification of Surrogate Objective In this subsection, we empirically verify that the surrogate f(S, p\u2217) proposed in Section 3 is a good approximation of the true IM objective F (S) in random Kronecker graphs, which are known to capture many properties of real-world social networks (Leskovec et al., 2010).", "startOffset": 294, "endOffset": 317}, {"referenceID": 13, "context": "Note that this range of influence probabilities is guided by the empirical evidence in (Goyal et al., 2010; Barbieri et al., 2013).", "startOffset": 87, "endOffset": 130}, {"referenceID": 1, "context": "Note that this range of influence probabilities is guided by the empirical evidence in (Goyal et al., 2010; Barbieri et al., 2013).", "startOffset": 87, "endOffset": 130}, {"referenceID": 28, "context": "We then use the state-of-the-art IM algorithm (Tang et al., 2014) to compute an \u03b1\u2217-approximation solution S\u2217 g to the IM problem maxS F (S).", "startOffset": 46, "endOffset": 65}, {"referenceID": 6, "context": "We compare DILinUCB against the CUCB algorithm (Chen et al., 2016) in both the IC model and the LT model, with K = 10.", "startOffset": 47, "endOffset": 66}, {"referenceID": 11, "context": "Similar to (Gentile et al., 2014), all hyper-parameters for our algorithm are set using an initial validation set of 500 rounds.", "startOffset": 11, "endOffset": 33}, {"referenceID": 34, "context": "Related Work IM semi-bandits have been studied in several recent papers (Wen et al., 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016).", "startOffset": 72, "endOffset": 157}, {"referenceID": 6, "context": "Related Work IM semi-bandits have been studied in several recent papers (Wen et al., 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016).", "startOffset": 72, "endOffset": 157}, {"referenceID": 31, "context": "Related Work IM semi-bandits have been studied in several recent papers (Wen et al., 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016).", "startOffset": 72, "endOffset": 157}, {"referenceID": 6, "context": "In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016).", "startOffset": 153, "endOffset": 172}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model.", "startOffset": 8, "endOffset": 95}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model. They formulated it as a combinatorial multi-armed bandit problem and proposed a UCB algorithm (CUCB). They only consider the tabular case, and derive an O(n) regret bound that also depends on the reciprocal of the minimum observation probability p of an edge. This can be problematic in for example, a line graph with L edges where all edge weights are 0.5. Then 1/p is 2L\u22121, implying an exponentially large regret. Moreover, they assume that source nodes influence the target nodes independently, which is not true in most practical social networks. In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016). Our regret bound isO(n) in the tabular case andO(nd) in the general linear bandit case. Vaswani et al. (2015) use \u03b5-greedy and Thompson sampling algorithms for a different and more challenging feedback model, where the learning agent observes influenced nodes but not the edges.", "startOffset": 8, "endOffset": 1007}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model. They formulated it as a combinatorial multi-armed bandit problem and proposed a UCB algorithm (CUCB). They only consider the tabular case, and derive an O(n) regret bound that also depends on the reciprocal of the minimum observation probability p of an edge. This can be problematic in for example, a line graph with L edges where all edge weights are 0.5. Then 1/p is 2L\u22121, implying an exponentially large regret. Moreover, they assume that source nodes influence the target nodes independently, which is not true in most practical social networks. In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016). Our regret bound isO(n) in the tabular case andO(nd) in the general linear bandit case. Vaswani et al. (2015) use \u03b5-greedy and Thompson sampling algorithms for a different and more challenging feedback model, where the learning agent observes influenced nodes but not the edges. They do not give any theoretical guarantees. Wen et al. (2016) consider a linear generalization model across edges and prove regret bounds for the special case of forests under edge-level feedback.", "startOffset": 8, "endOffset": 1239}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model. They formulated it as a combinatorial multi-armed bandit problem and proposed a UCB algorithm (CUCB). They only consider the tabular case, and derive an O(n) regret bound that also depends on the reciprocal of the minimum observation probability p of an edge. This can be problematic in for example, a line graph with L edges where all edge weights are 0.5. Then 1/p is 2L\u22121, implying an exponentially large regret. Moreover, they assume that source nodes influence the target nodes independently, which is not true in most practical social networks. In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016). Our regret bound isO(n) in the tabular case andO(nd) in the general linear bandit case. Vaswani et al. (2015) use \u03b5-greedy and Thompson sampling algorithms for a different and more challenging feedback model, where the learning agent observes influenced nodes but not the edges. They do not give any theoretical guarantees. Wen et al. (2016) consider a linear generalization model across edges and prove regret bounds for the special case of forests under edge-level feedback. It not clear how to extend their technique for deriving regret bounds on general graphs. Note that all of the above papers assume the IC diffusion model. Carpentier & Valko (2016); Fang & Tao (2014) consider a simpler local model of influence, in which information does not transitively diffuse across the network.", "startOffset": 8, "endOffset": 1554}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model. They formulated it as a combinatorial multi-armed bandit problem and proposed a UCB algorithm (CUCB). They only consider the tabular case, and derive an O(n) regret bound that also depends on the reciprocal of the minimum observation probability p of an edge. This can be problematic in for example, a line graph with L edges where all edge weights are 0.5. Then 1/p is 2L\u22121, implying an exponentially large regret. Moreover, they assume that source nodes influence the target nodes independently, which is not true in most practical social networks. In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016). Our regret bound isO(n) in the tabular case andO(nd) in the general linear bandit case. Vaswani et al. (2015) use \u03b5-greedy and Thompson sampling algorithms for a different and more challenging feedback model, where the learning agent observes influenced nodes but not the edges. They do not give any theoretical guarantees. Wen et al. (2016) consider a linear generalization model across edges and prove regret bounds for the special case of forests under edge-level feedback. It not clear how to extend their technique for deriving regret bounds on general graphs. Note that all of the above papers assume the IC diffusion model. Carpentier & Valko (2016); Fang & Tao (2014) consider a simpler local model of influence, in which information does not transitively diffuse across the network.", "startOffset": 8, "endOffset": 1573}, {"referenceID": 5, "context": ", 2016; Chen et al., 2016; Vaswani et al., 2015; Carpentier & Valko, 2016). Chen et al. (2016) studied IM semi-bandit under edge-level feedback and the IC diffusion model. They formulated it as a combinatorial multi-armed bandit problem and proposed a UCB algorithm (CUCB). They only consider the tabular case, and derive an O(n) regret bound that also depends on the reciprocal of the minimum observation probability p of an edge. This can be problematic in for example, a line graph with L edges where all edge weights are 0.5. Then 1/p is 2L\u22121, implying an exponentially large regret. Moreover, they assume that source nodes influence the target nodes independently, which is not true in most practical social networks. In contrast, both our algorithm and analysis are diffusion independent, and our analysis does not require the \u201cindependent influence\u201d assumption made in (Chen et al., 2016). Our regret bound isO(n) in the tabular case andO(nd) in the general linear bandit case. Vaswani et al. (2015) use \u03b5-greedy and Thompson sampling algorithms for a different and more challenging feedback model, where the learning agent observes influenced nodes but not the edges. They do not give any theoretical guarantees. Wen et al. (2016) consider a linear generalization model across edges and prove regret bounds for the special case of forests under edge-level feedback. It not clear how to extend their technique for deriving regret bounds on general graphs. Note that all of the above papers assume the IC diffusion model. Carpentier & Valko (2016); Fang & Tao (2014) consider a simpler local model of influence, in which information does not transitively diffuse across the network. Lei et al. (2015) consider the related problem of maximizing the number of unique nodes across multiple rounds.", "startOffset": 8, "endOffset": 1707}, {"referenceID": 31, "context": "Another research direction is to address more challenging node-level feedback models such as in Vaswani et al. (2015).", "startOffset": 96, "endOffset": 118}, {"referenceID": 0, "context": "This result is a natural generalization of Theorem 1 in Abbasi-Yadkori et al. (2011). Theorem 3.", "startOffset": 56, "endOffset": 85}, {"referenceID": 0, "context": "Similarly as Abbasi-Yadkori et al. (2011), for any \u03bb \u2208 < and any t, we define D t as D t = exp ( \u03bbXt\u03b7t \u2212 K 2 \u2016X t \u03bb\u20162 ) , (35)", "startOffset": 13, "endOffset": 42}, {"referenceID": 0, "context": "Then, following Lemma 8 of Abbasi-Yadkori et al. (2011), we have the following lemma: Lemma 4.", "startOffset": 27, "endOffset": 56}, {"referenceID": 0, "context": "The following results follow from Lemma 9 of Abbasi-Yadkori et al. (2011), which uses the \u201cmethod of mixtures\u201d technique.", "startOffset": 45, "endOffset": 74}, {"referenceID": 0, "context": "The following lemma follows directly from the proof for Lemma 9 of Abbasi-Yadkori et al. (2011), which can be derived by algebra.", "startOffset": 67, "endOffset": 96}], "year": 2017, "abstractText": "We consider influence maximization (IM) in social networks, which is the problem of maximizing the number of users that become aware of a product by selecting a set of \u201cseed\u201d users to expose the product to. While prior work assumes a known model of information diffusion, we propose a parametrization in terms of pairwise reachability which makes our framework agnostic to the underlying diffusion model. We give a corresponding monotone, submodular surrogate function, and show that it is a good approximation to the original IM objective. We also consider the case of a new marketer looking to exploit an existing social network, while simultaneously learning the factors governing information propagation. For this, we propose a pairwise-influence semi-bandit feedback model and develop a LinUCB-based bandit algorithm. Our model-independent regret analysis shows that our bound on the cumulative regret has a better (as compared to previous work) dependence on the size of the network. By using the graph Laplacian eigenbasis to construct features, we describe a practical LinUCB implementation. Experimental evaluation suggests that our framework is robust to the underlying diffusion model and can efficiently learn a near-optimal solution.", "creator": "LaTeX with hyperref package"}}}