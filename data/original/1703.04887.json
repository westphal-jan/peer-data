{"id": "1703.04887", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2017", "title": "Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets", "abstract": "This paper proposes a new route for applying the generative adversarial nets (GANs) to NLP tasks (taking the neural machine translation as an instance) and the widespread perspective that GANs can't work well in the NLP area turns out to be unreasonable. In this work, we build a conditional sequence generative adversarial net which comprises of two adversarial sub models, a generative model (generator) which translates the source sentence into the target sentence as the traditional NMT models do and a discriminative model (discriminator) which discriminates the machine-translated target sentence from the human-translated sentence. From the perspective of Turing test, the proposed model is to generate the translation which is indistinguishable from the human-translated one. Experiments show that the proposed model achieves significant improvements than the traditional NMT model. In Chinese-English translation tasks, we obtain up to +2.0 BLEU points improvement. To the best of our knowledge, this is the first time that the quantitative results about the application of GANs in the traditional NLP task is reported. Meanwhile, we present detailed strategies for GAN training. In addition, We find that the discriminator of the proposed model shows great capability in data cleaning.", "histories": [["v1", "Wed, 15 Mar 2017 02:26:25 GMT  (1083kb,D)", "http://arxiv.org/abs/1703.04887v1", "9 pages , 3 figures, 3 tables"], ["v2", "Mon, 17 Apr 2017 02:24:05 GMT  (527kb,D)", "http://arxiv.org/abs/1703.04887v2", "More strong baselines, update the equation and pictures"]], "COMMENTS": "9 pages , 3 figures, 3 tables", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["zhen yang", "wei chen", "feng wang", "bo xu"], "accepted": false, "id": "1703.04887"}, "pdf": {"name": "1703.04887.pdf", "metadata": {"source": "CRF", "title": "Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets", "authors": ["Zhen Yang", "Wei Chen", "Feng Wang", "Bo Xu"], "emails": ["xubo}@ia.ac.cn"], "sections": [{"heading": "1 Introduction", "text": "Machine translation is one of the important and traditional NLP tasks which aims to translate one source-language sentence into the corresponding\n*Wei Chen is the corresponding author of this paper\ntarget-language sentence automatically. Recently, with the rapid development of deep neural network, the neural machine translation (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2014; Ranzato et al., 2015) which leverages a single neural network directly to transform the source sentence into the target sentence, has obtained state-of-the-art performance for several language pairs (Wu et al., 2016; Johnson et al., 2016; Bradbury and Socher, 2016). This end-toend NMT typically consists of two recurrent neural networks. The encoder network reads and encodes the source sentence into the context vector representation; and a decoder network generates the target sentence word by word based on the context vector. To dynamically generate a context vector for a target word being generated, the attention mechanism is usually deployed. Optimization for this NMT model is to directly maximize the likelihood of the training data. Specifically, at each decoding step, the NMT model is optimized to maximize the likelihood of the ground word at the current step. (Ranzato et al., 2015) indicates that loss function of the maximum likelihood estimation is only defined at the word level instead of sentence level. Hence the NMT model may generate the best candidate word for the current time step but a bad component of the whole sentence in the long run. (Shen et al., 2015) gives a solution by introducing the minimum risk training from the statistical machine translation (SMT). They incorporate the sentence-level BLEU (Chen and Cherry, 2014) into the loss function. Hence the NMT model is optimized to generate sentence which has higher BLEU point. As ar X iv :1 70 3. 04 88 7v 1 [ cs .C L ] 1 5 M\nar 2\nthe BLEU point is computed as the geometric mean of the modified n-gram precisions (Papineni et al., 2002), we conclude that almost all of the prior NMT models are trained to cover more n-grams with the ground target sentence (MLE can be viewed as training the NMT to cover more 1-gram with the target sentence).\nHowever, it is widely acknowledged that high n-gram precisions don\u2019t ensure a better sentence (Callison-Burch and Osborne, 2006; Chatterjee et al., 2007). Additionally, the manually defined loss function is unable to cover all crucial aspects and the NMT model may be trained to deviate from the data distribution and generate suboptimal sentences. Intuitively, The model should be trained to directly generate a human-like sentence instead of covering the human designed approximation features. From the Turing test perspective, we should enlighten the model to be aware of what is the human-generated sentence like and to generate the sentence indistinguishable form the human-generated one. Based on the analysis above, we propose that a good training objective for NMT includes: 1) The loss function should be defined on the sentence level instead of the word level; 2) No manually defined approximation feature is used to guide the NMT model; 3) The NMT model should be directly exposed to the true data distribution. Specifically, the model should be trained to directly generate the human-generated sentence and if one poor sentence is generated, the model should be penalized with how far the poor sentence is from the human-generated one.\nBorrowing the idea of generative adversarial training in computer vision (Goodfellow et al., 2014; Denton et al., 2015), we build a conditional sequence generative adversarial nets (CSGAN) which implements the training objective mentioned above. In the proposed CSGAN-NMT, we jointly train two models, a generator (implemented as the traditional NMT model) which generates the target-language sentence based on the input source-language sentence, and a discriminator which conditioned on the source-language sentence, predicts the probability of the target-language sentence being a humangenerated one. During the training process, the generator tries to fool the discriminator into believing that its output is a human-generated sentence, and the discriminator makes effort not to be fooled\nby improving its ability to distinguish the machinegenerated sentence from the human-generated one. This kind of adversarial training achieves a winwin situation when the generator and discriminator reaches a Nash Equilibrium (Zhao et al., 2016).\nIn summary, we mainly make the following contributions:\n\u2022 To directly train the NMT model to output the human-generated sentences, we firstly, to the best of our knowledge, introduce the generative adversarial training into NMT. We build a conditional generative adversarial nets which can be applied to any end-to-end NMT systems. We do not assume the specific architectures of NMT.\n\u2022 The extensive experiments on Chinese-toEnglish translation tasks show that the proposed CSGAN-NMT significantly outperforms the strong attention-based NMT model. We present detailed, quantitative results to demonstrate the effectiveness of the proposed CSGAN-NMT. This indicates the feasibility of applying the GANs into NLP tasks.\n\u2022 We successfully leverage the discriminator to clean the training data.\n\u2022 We test different architectures for the discriminator, the convolutional neural network (CNN) based and the recurrent neural network (RNN based one. We found that the RNNs are not applicable in the discriminator.\n\u2022 We report our specific training strategies for the proposed CSGAN-NMT. This provides a new reliable route for applying generative adversarial nets into the NLP tasks."}, {"heading": "2 Related work", "text": ""}, {"heading": "2.1 Neural machine translation", "text": "This subsection briefly describes the attentionbased NMT model which simultaneously conducts dynamic alignment and generation of the target sentence. The NMT model produces the translation sentence by generating one target word at every time step. Given an input sequence x = (x1, . . . , xTx)\nand previous translated words (y1, . . . , yi\u22121), the probability of next word yi is:\np(yi|y1, . . . , yi\u22121,x) = g(yi\u22121, si, ci) (1)\nwhere si is an decoder hidden state for time step i, which is computed as:\nsi = f(si\u22121, yi\u22121, ci) (2)\nHere f and g are nonlinear transform functions, which can be implemented as long short term memory network(LSTM) or gated recurrent unit (GRU), and ci is a distinct context vector at time step i, which is calculated as a weighted sum of the input annotations hj :\nci = Tx\u2211 j=1 ai,jhj (3)\nwhere hj is the annotation of xj from a bidirectional RNN. The weight aij for hj is calculated as:\nai,j = exp(eij)\u2211Tx t=1 exp(ei,t)\n(4)\nwhere\nei,j = vatanh(Wsi\u22121 + Uhj) (5)\nAll of the parameters of the NMT model are optimized to maximize the following conditional loglikelihood of the M sentence aligned bilingual samples:\n`(\u03b8) = 1\nM M\u2211 m=1 Ty\u2211 i=1 log p(ymi |ym<i,xm, \u03b8) (6)"}, {"heading": "2.2 Generative adversarial net", "text": "Generative adversarial network in which a generative model is trained to generate outputs to fool the discriminator, has enjoyed great success in computer vision and has been widely applied to image generation. The conditional generative adversarial nets apply an extension of generative adversarial network to a conditional setting, which enables the networks to condition on some arbitrary external data.\nHowever, to the best of our knowledge, this idea has not been applied in traditional NLP tasks with\ncomparable success and few quantitative experimental result has been reported. Some recent work has begun to apply the generative adversarial training into the NLP area: (Chen et al., 2016) apply the idea of generative adversarial training to sentiment analysis and (Zhang et al., 2017) use the idea to domain adaptation tasks.For sequence generation problem, (Yu et al., 2016) leverage policy gradient reinforcement learning to back-propagate the reward from the discriminator, showing presentable results for poem generation, speech language generation and music generation. Similarly, (Zhang et al., 2016) generate the text from random noise via adversarial training. A striking difference from works mentioned above, our work is in the conditional settings where the target-language sentence are generated conditioned on the source-language one.\nIn parallel to our work, (Li et al., 2017) propose a similar conditional sequence generative adversarial training for dialogue generation. They use a hierarchical LSTM architecture for the discriminator. In contrast to their approach, we apply the CNNbased discriminator for the machine translation task. Furthermore, we present detailed training strategies for the proposed model and extensive quantitative results are reported."}, {"heading": "3 The CSGAN-NMT", "text": "In this section, we describe in detail the CSGANNMT that consists of a generator G, which generates the target-language sentence based on the sourcelanguage sentence and a discriminator D, which distinguishes the machine-generated sentence from the human-generated one. The sentence generation process is viewed as a sequence of actions that are taken according to a policy regulated by the generator and we take the policy gradient training strategies which is the same as (Yu et al., 2016)."}, {"heading": "3.1 Generator", "text": "Resembling the traditional NMT model, the generator G generates the target-language sentence conditioned on the input source-language sentence. It defines the policy that generates the target sentence y given the source sentence x. The generator takes exactly the same architecture with the traditional NMT model. Note that we do not assume the specific\narchitecture of the generator. Here, we adopt the strong attention-based NMT model, which is implemented as the open-source system dl4mt *, as the generator."}, {"heading": "3.2 Discriminator", "text": "Recently, the deep discriminative models such as the convolutional neural network (CNN) and recurrent neural network (RNN) have shown a high performance in complicated sequence classification tasks. To test the efficacy of the discriminator, we propose two different architectures for the discriminator: the CNN-based and RNN-based one.\nCNN-based Since the generated sentence has a variable length, the CNN padding is used to transform the sentence to a sequence with the fixed length T , which is the maximum length for the input sequence set by the user beforehand. Given the sourcelanguage sequence x1, . . . , xT and target-language sequence y1, . . . , yT , we build the source matrix X1:T and target matrix Y1:T respectively as:\nX1:T = x1;x2; . . . ;xT (7)\nand Y1:T = y1; y2; . . . ; yT (8)\nwhere xt, yt \u2208 Rk is the k-dimensional word embedding and the semicolon is the concatenation operator. For the source matrix X1:T , a kernel wj \u2208 Rl\u00d7k applies a convolutional operation to a window size of l words to produce a series of feature maps:\ncji = \u03c1(BN(wj \u2297Xi:i+l\u22121 + b)) (9)\nwhere \u2297 operator is the summation of element-wise production and b is a bias term. \u03c1 is a non-linear activation function which is implemented as ReLU in this paper. Note that the batch normalization (Ioffe and Szegedy, 2015), which accelerates the training significantly, is applied to the input of the activation function (BN in equation 9). To get the final feature with respect to kernel wj , a max-over-time pooling operation is leveraged over the feature maps:\nc\u0303j = max{cj1, . . . , cjT\u2212l+1} (10)\nWe use various numbers of kernels with different window sizes to extract different features, which are\n*https://github.com/nyu-dl/dl4mt-tutorial\nfinally concatenated to form the vector representation for the source-language sentence cx. Identically, the target-language sentence representation cy can be extracted from the target matrix Y1:T . Finally, given the source-language sentence, the probability that the target-language sentence is being real can be computed as:\np = \u03c3(V [cx; cy]) (11)\nwhere V is the transform matrix which transforms the concatenation of cx and cy into a 2-dimension embedding and \u03c3 is the logistic function. The CNNbased discriminator is depicted as figure 1\nRNN-based Recurrent neural network has several different formations, such as the long shortterm memory network (LSTM), gated recurrent units (GRU) and the simple recurrent neural network (simple-RNN). This paper takes the LSTM as a instance. Given the source-language sequence x1, . . . , xs, a LSTM is used to map the sequence into a sequence of hidden states h1, . . . , hs by leveraging the update function of LSTM cells recursively:\nht = lstm(ht\u22121, xt) (12)\nThe vector representation for the source-language sentence cx is computed as the average of the hidden states. The sentence vector for the target sentence cy is computed by the same way. Finally, the probability that the target-language sentence is being real is computed as equation 11. We also take the bidirectional LSTM as an alternative for LSTM. The graphical illustration of the BiLSTM-based discriminator is depicted as figure 2."}, {"heading": "3.3 Policy gradient training", "text": "Following (Yu et al., 2016), the objective of the generator G is defined as to generate a sequence from the start state to maximize its expected end reward. Formally, the objective function is computed as:\nJ(\u03b8) = \u2211 yt G\u03b8(yt|y1:t\u22121, x) \u00b7RG\u03b8D ((y1:t\u22121, x), yt) (13)\nwhere RG\u03b8D is the action-value function of a targetlanguage sentence given the source sentence, i.e. the expected accumulative reward starting from the state\n(y1:t\u22121, x), taking action yt, and following the policy G\u03b8. To estimate the action-value function, we consider the estimated probability of being real by the discriminator D as the reward:\nRG\u03b8D ((y1:T\u22121, x), yT ) = D(x, y1:T )\u2212 b(x, y1:T ) (14)\nwhere b(x,y) denotes the baseline value to reduce the variance of the reward. Practically, we take b(x,y) as a constant, 0.5 for simplicity. The question is that, given the source sequence, the discriminator D only provides a reward value for a finished target sequence. If y1:T is not a finished target sequence, the value of D(x, y1:T ) makes no sense. Therefore, we can\u2019t get the action-value for an intermediate state directly. To evaluate the action-value for an intermediate state, the Monte Carlo search under the policy of G is applied to sample the unknown tokens. Each search ends when the end of sentence token is sampled or the sampled sentence meets the maximum length. To obtain more stable reward and reduce the variance, we represent an N-time Monte Carlo search as:\n{y11:L1 , . . . , y N 1:LN } =MCG\u03b8((y1:t, x), N) (15)\nwhere Li represents the length of the sentence sampled by the i\u2019th Monte Carlo search. (y1:t, x) = (y1, . . . , yt, x) is the current state and yNt+1:LN is sampled based on the policy G. The discriminator provides N rewards for the N sampled sentences respectively. The final reward for the intermediate state is calculated as the average of the N rewards.\nHence, for the target sentence with the length L, we get:\nRG\u03b8D ((y1:t\u22121, x), yt) = (16){ 1 N N\u2211 n=1 D(x, yn1:Ln)\u2212 b(x, y n 1:Ln ), yn1:Ln \u2208MC G\u03b8 ((y1:t, x), N) for t < L\nD(x, y1:t)\u2212 b(x, y1:t) for t = L\nUsing the discriminator as a reward function can further improve the generator iteratively by dynamically updating discriminator. Once we get more realistic generated sequences, we re-train the discriminator as:\nmin\u2212Ex,y\u2208pdata [logD(x, y)]\u2212 Ex,y\u2208G[log(1\u2212D(x, y))] (17)\nAfter updating the discriminator, we are ready to retrain the generator. Following (Yu et al., 2016), the gradient of the objective function J(\u03b8) w.r.t the generator\u2019s parameter \u03b8 is calculated as:\n\u2207J(\u03b8) = \u2211 yt RG\u03b8D (y1:t\u22121, x) \u00b7 \u2207\u03b8 log(G\u03b8(yt|y1:t\u22121, x))\n= \u2211 yt RG\u03b8D (y1:t\u22121, x) \u00b7 \u2207\u03b8 log p(yt|y1:t\u22121, x) (18)"}, {"heading": "4 Training strategies", "text": "It is hard to train the generative adversarial networks since the generator and discriminator need to be carefully synchronized. To make this work easier to reproduce, this paper gives detailed strategies for training the CSGAN-NMT model.\nFirstly, we use the maximum likelihood estimation to pre-train the generator on the parallel training set s until the best translation performance (measured by BLEU metric) is achieved.\nThen, generate the machine-generated sentences by using the generator to decode the training data. We simply use the greedy sampling method instead of the beam search method for decoding. Hence, it is very fast to decode all of the training set.\nNext, pre-train the discriminator on the combination of the true parallel data and the machinegenerated data until the classification accuracy achieves at f .\nFinally, we jointly train the generator and discriminator. The generator is trained with the policy gradient training method. We randomly sample a batch of source sentence from s as the training examples for the generator and the batch size is \u03b2g. Note that the target sentences are useless when the the generator is undergoing the policy gradient training. However, in our practice, we find that updating the generator only with the simple policy gradient training leads to unstable training. The translation performance goes down sharply after a few updating. We conjecture that this is because the generator can only indirectly access to the golden target sentence through the reward passed back from the discriminator, and this reward is used only to promote or discourage the machine-generated sentences. To alleviate this issue, we adopt the professor forcing approach which is similar to (Lamb et al., 2016). We directly make the discriminator to automatically assign a reward of 1 to the golden target-language sentence and the generator uses this reward to update itself on the true parallel examples. We run the professor forcing training for one time once the generator is updated by the policy gradient training. After the generator gets updated, we use the new stronger generator to generate \u03b7 more realistic sentences, which are then used to train the discriminator. The batch size for training the discriminator is referred as \u03b2d. Following (Arjovsky et al., 2017), we clamp the weights of the discriminator to a fixed box ( [\u2212 , ] ) after each gradient update. We perform one optimization step for the discriminator for each step of the generator.\nIn our practice, we set f as 0.82, \u03b2g as 100, \u03b2d as 64, \u03b7 as 5000, as 1 and the N for Monte\nCarlo search as 20. We use the Adam optimization method, with the initial learning rate 0.001, for the pre-training of the generator and discriminator. However, when generative adversarial training, we use the RMSProp optimization method, with the initial learning rate 0.0001, for the generator and discriminator."}, {"heading": "5 Experiments and Results", "text": "In this section, we detail our experimental results on the CSGAN-NMT model for Chinese-English translation tasks. The open-source NMT system, dl4mt, is used as the baseline model. Note that the generator of the CSGAN-NMT is identical with the baseline model."}, {"heading": "5.1 Setup", "text": "For the Chinese-English translation task, the training data consists of 1.0M pairs of sentences randomly extracted from LDC corpora. We choose the NIST02 as the development set. For testing, we use NIST03, NIST04 and NIST05 data sets. We apply word-level translation in our experiments and the Chinese sentences are segmented beforehand. To speed up the training procedure, the sentences of length over 50 words are removed. We limit the vocabulary in both Chinese and English to the most 30K words and the out-of-vocabulary words are replaced with UNK. The word embedding dimension is set as 512 and the size of the hidden layer is 1024. The other hyper-parameters are set according to the section 4. We use case-insensitive 4-gram BLEU score as the evaluation metric. We train the NMT models on 4 GPU K80 and it takes about 30 hours to train the baseline model. The training time for the proposed CSGAN-NMT model (pre-training included) is about 3 days."}, {"heading": "5.2 CNN or RNN for discriminator", "text": "We firstly test different architectures for the discriminator, CNN-based or RNN-based (LSTM for instance). Figure 3 shows the BLEU scores on the development set tested at different time steps. We can find that the performance of the RNNbased (LSTM and BiLSTM) discriminators deteriorate rapidly with the time going. Even more striking, the performance of the discriminator which based on the BiLSTM collapse sharply after several time\nsteps. The training for the RNN-based discriminator is not stable. On the contrary, the CNN-based discriminator performs very well. Empirically, with a few times of updating, the classification accuracy of RNN-based discriminators can easily achieves as high as 0.9, which is too strong for the generator. The sentences generated by the generator can be easily detected by the strong discriminator and the generator is discouraged all the time. We conjecture that this is why the RNN-based discriminators work badly in our CSGAN-NMT. If no otherwise specified, we use the CNN-based discriminator for the following experiments."}, {"heading": "5.3 Results on Chinese-English translation", "text": "Table 1 shows the BLEU score on ChineseEnglish test sets. Compared to the baseline model, the proposed CSGAN-NMT model leads to improvement up to +1.6 BLEU points on average (see (1) and (3) in table 1). Naturally, there is a doubt that this improvement may owe much to the small learning rate of the optimization method rather than the CSGAN-NMT itself. To dispel this doubt and verify the efficacy of the proposed model, we use stochastic gradient descend optimization method (with the learning rate of 0.0001 which is used in CSGAN-\nNMT) to finetune the baseline model and we only get +0.7 BLEU points improvement (see (2) in table 1). There is a gap as large as 1.0 BLEU points on average (0.71 vs 1.62) between the finetuned baseline model and the CSGAN-NMT model (see (2) and (3) in table 1). Additionally, we get another +0.4 BLEU points improvement when running the CSGAN-NMT on the basis of the finetuned baseline model (see (2) and (4) in table 1). To conclude, these experiments show that the NMT can be greatly improved by the generative adversarial training."}, {"heading": "5.4 Initial accuracy of the discriminator", "text": "The initial accuracy f of the discriminator which can be viewed as a hyper-parameter, can be controlled carefully during the process of pre-training. A natural question is that when shall we end the pretraining. Do we need to pre train the discriminator until that its accuracy reaches as high as possible? To test the impact of the initial accuracy of the discriminator, we pre train five discriminators which have the accuracy as 0.6, 0.7, 0.8, 0.9 and 0.95 respectively. With the five discriminators, we train five different CSGAN-NMT models and test their translation performance on the development set at regular intervals. Figure 4 reports the result and we can find\nthat the initial accuracy of the discriminator shows great impacts on the translation performance of the proposed model. From figure 4, the initial accuracy of the discriminator needs to be set carefully and no matter it is set too high (0.9 and 0.95) or too low (0.6 and 0.7), the CSGAN-NMT performs badly. Empirically, we pre train the discriminator until its accuracy reaches 0.82."}, {"heading": "N NIST02 NIST03 NIST04 NIST05", "text": ""}, {"heading": "5.5 Sample times for Monte Carlo search", "text": "We are also curious about the sample time N for Monte Carlo search. If N is set as a small number, the intermediate reward computed as equation 16 may be incorrect and if otherwise, the computation shall be very time consuming. There is a trade-off between the accuracy and computation complexity. Table 2 presents the translation performance of the CSGAN-NMT on the test sets when the N are set from 5 to 30. From table 2, the proposed CSGAN-NMT model achieves no improvement than the baseline when N are set less than 15. WithN set as 30, we get little improvement than the model with N set as 20. However, the training time has exceed our toleration."}, {"heading": "5.6 Discriminator for data cleaning", "text": "Since the discriminator of the CSGAN-NMT directly outputs the probability that, given the sourcelanguage sentence, the target-language sentence is being a human-generated one. This motivates us to test the feasibility of applying the discriminator into data cleaning. When we finished training the CSGAN-NMT model, the accuracy of the discriminator is near 0.6, which is a little weak of handling\nthe data cleaning task. Hence, we continue training the discriminator for 4 epoches (with the accuracy of 0.95). Then, by feeding the parallel training data into the discriminator, we get a probability of being human-translated for each sentence pair. We select a set of examples (s1) from the training data by the probability in a descending order. Additionally, we also randomly choose the other set s2 which has the same number of examples with s1. Two traditional NMT models are trained on the data set s1 and s2 respectively. The results are reported in table 3. We can find that the models trained on the cleaned data achieves better translation performance than the counterpart trained on the randomly sampled data. This indicates that the discriminator is capable of cleaning the training data for the NMT."}, {"heading": "6 Conclusions and Future work", "text": "In this work, we propose the CSGAN-NMT which leverages the generative adversarial training to improve the neural machine translation. We test different architectures (RNN-based and CNNbased) for the discriminator of the CSGAN-NMT. Experimental results show that our proposed model can significantly outperform the strong attentionbased NMT baseline, and the CNN-based discriminator performs better than the RNN-based one. Additionally, we provide detailed training strategies for the CSGAN-NMT model. We also find that the discriminator in the CSGAN-NMT demonstrates great capability in data cleaning.\nIn the future, we would like to try multiadversarial framework which consists of multi discriminators and generators for the generative adversarial training. Additionally, we plan to test our method in other NLP tasks, like dialogue system and question answering. Since higher BLEU points don\u2019t ensure a better sentence, another interesting direction is to apply the discriminator to measure the translation performance more equally."}, {"heading": "Acknowledgments", "text": "We would like to thank Xu Shuang for her preparing data used in this work. Additionally, we also want to thank Chen Zhineng, Geng Wang, Wang Wenfu, Zhang Xiaowei and Wang Chunqi for their invaluable discussions on this work."}], "references": [{"title": "Re-evaluating the role", "author": ["Miles Osborne"], "venue": null, "citeRegEx": "Osborne.,? \\Q2006\\E", "shortCiteRegEx": "Osborne.", "year": 2006}, {"title": "Deep generative image", "author": ["Rob Fergus"], "venue": null, "citeRegEx": "Fergus,? \\Q2015\\E", "shortCiteRegEx": "Fergus", "year": 2015}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167", "author": ["Ioffe", "Szegedy2015] Sergey Ioffe", "Christian Szegedy"], "venue": null, "citeRegEx": "Ioffe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ioffe et al\\.", "year": 2015}, {"title": "Recurrent continuous translation models", "author": ["Kalchbrenner", "Blunsom2013] Nal Kalchbrenner", "Phil Blunsom"], "venue": null, "citeRegEx": "Kalchbrenner et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2013}, {"title": "Professor forcing: A new algorithm for training recurrent networks", "author": ["Lamb et al.2016] Alex Lamb", "Anirudh Goyal", "Ying Zhang", "Saizheng Zhang", "Aaron Courville", "Yoshua Bengio"], "venue": "Advances In Neural Information Processing Systems,", "citeRegEx": "Lamb et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lamb et al\\.", "year": 2016}, {"title": "Adversarial learning for neural dialogue generation", "author": ["Li et al.2017] Jiwei Li", "Will Monroe", "Tianlin Shi", "Alan Ritter", "Dan Jurafsky"], "venue": "arXiv preprint arXiv:1701.06547", "citeRegEx": "Li et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Li et al\\.", "year": 2017}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "Association for Computational Linguistics,", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Sequence level training with recurrent neural networks. arXiv preprint arXiv:1511.06732", "author": ["Sumit Chopra", "Michael Auli", "Wojciech Zaremba"], "venue": null, "citeRegEx": "Ranzato et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2015}, {"title": "Minimum risk training for neural machine translation", "author": ["Shen et al.2015] Shiqi Shen", "Yong Cheng", "Zhongjun He", "Wei He", "Hua Wu", "Maosong Sun", "Yang Liu"], "venue": "arXiv preprint arXiv:1512.02433", "citeRegEx": "Shen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks. Advances in neural information processing systems, pages 3104\u20133112", "author": ["Oriol Vinyals", "Quoc VV Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Seqgan: Sequence generative adversarial nets with policy gradient. The Association for the Advancement of Artificial Intelligence 2017", "author": ["Yu et al.2016] Lantao Yu", "Weinan Zhang", "Jun Wang", "Yong Yu"], "venue": null, "citeRegEx": "Yu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2016}, {"title": "Generating text via adversarial training", "author": ["Zhang et al.2016] Yizhe Zhang", "Zhe Gan", "Lawrence Carin"], "venue": null, "citeRegEx": "Zhang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}, {"title": "Aspect-augmented adversarial networks for domain adaptation", "author": ["Zhang et al.2017] Yuan Zhang", "Regina Barzilay", "Tommi Jaakkola"], "venue": "arXiv preprint arXiv:1701.00188", "citeRegEx": "Zhang et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2017}, {"title": "Energy-based generative adversarial network. arXiv preprint arXiv:1609.03126", "author": ["Zhao et al.2016] Junbo Zhao", "Michael Mathieu", "Yann LeCun"], "venue": null, "citeRegEx": "Zhao et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 9, "context": "Recently, with the rapid development of deep neural network, the neural machine translation (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2014; Ranzato et al., 2015) which leverages a single neural network directly to transform the source sentence into the target sentence, has obtained state-of-the-art performance for several language pairs (Wu et al.", "startOffset": 92, "endOffset": 211}, {"referenceID": 7, "context": "Recently, with the rapid development of deep neural network, the neural machine translation (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2014; Ranzato et al., 2015) which leverages a single neural network directly to transform the source sentence into the target sentence, has obtained state-of-the-art performance for several language pairs (Wu et al.", "startOffset": 92, "endOffset": 211}, {"referenceID": 7, "context": "(Ranzato et al., 2015) indicates that loss function of the maximum likelihood estimation is only defined at the word level instead of sentence level.", "startOffset": 0, "endOffset": 22}, {"referenceID": 8, "context": "(Shen et al., 2015) gives a solution by introducing the minimum risk training from the statistical machine translation (SMT).", "startOffset": 0, "endOffset": 19}, {"referenceID": 6, "context": "the BLEU point is computed as the geometric mean of the modified n-gram precisions (Papineni et al., 2002), we conclude that almost all of the prior NMT models are trained to cover more n-grams with the ground target sentence (MLE can be viewed as training the NMT to cover more 1-gram with the target sentence).", "startOffset": 83, "endOffset": 106}, {"referenceID": 13, "context": "This kind of adversarial training achieves a winwin situation when the generator and discriminator reaches a Nash Equilibrium (Zhao et al., 2016).", "startOffset": 126, "endOffset": 145}, {"referenceID": 12, "context": ", 2016) apply the idea of generative adversarial training to sentiment analysis and (Zhang et al., 2017) use the idea to domain adaptation tasks.", "startOffset": 84, "endOffset": 104}, {"referenceID": 10, "context": "For sequence generation problem, (Yu et al., 2016) leverage policy gradient reinforcement learning to back-propagate the reward from the discriminator, showing presentable results for poem generation, speech language generation and music generation.", "startOffset": 33, "endOffset": 50}, {"referenceID": 11, "context": "Similarly, (Zhang et al., 2016) generate the text from random noise via adversarial training.", "startOffset": 11, "endOffset": 31}, {"referenceID": 5, "context": "In parallel to our work, (Li et al., 2017) propose a similar conditional sequence generative adversarial training for dialogue generation.", "startOffset": 25, "endOffset": 42}, {"referenceID": 10, "context": "The sentence generation process is viewed as a sequence of actions that are taken according to a policy regulated by the generator and we take the policy gradient training strategies which is the same as (Yu et al., 2016).", "startOffset": 204, "endOffset": 221}, {"referenceID": 10, "context": "Following (Yu et al., 2016), the objective of the generator G is defined as to generate a sequence from the start state to maximize its expected end reward.", "startOffset": 10, "endOffset": 27}, {"referenceID": 10, "context": "Following (Yu et al., 2016), the gradient of the objective function J(\u03b8) w.", "startOffset": 10, "endOffset": 27}, {"referenceID": 4, "context": "To alleviate this issue, we adopt the professor forcing approach which is similar to (Lamb et al., 2016).", "startOffset": 85, "endOffset": 104}], "year": 2017, "abstractText": "This paper proposes a new route for applying the generative adversarial nets (GANs) to NLP tasks (taking the neural machine translation as an instance) and the widespread perspective that GANs can\u2019t work well in the NLP area turns out to be unreasonable. In this work, we build a conditional sequence generative adversarial net which comprises of two adversarial sub models, a generative model (generator) which translates the source sentence into the target sentence as the traditional NMT models do and a discriminative model (discriminator) which discriminates the machinetranslated target sentence from the humantranslated sentence. From the perspective of Turing test, the proposed model is to generate the translation which is indistinguishable from the human-translated one. Experiments show that the proposed model achieves significant improvements than the traditional NMT model. In Chinese-English translation tasks, we obtain up to +2.0 BLEU points improvement. To the best of our knowledge, this is the first time that the quantitative results about the application of GANs in the traditional NLP task is reported. Meanwhile, we present detailed strategies for GAN training. In addition, We find that the discriminator of the proposed model shows great capability in data cleaning.", "creator": "LaTeX with hyperref package"}}}