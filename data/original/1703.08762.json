{"id": "1703.08762", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2017", "title": "Team Formation for Scheduling Educational Material in Massive Online Classes", "abstract": "Whether teaching in a classroom or a Massive Online Open Course it is crucial to present the material in a way that benefits the audience as a whole. We identify two important tasks to solve towards this objective, 1 group students so that they can maximally benefit from peer interaction and 2 find an optimal schedule of the educational material for each group. Thus, in this paper, we solve the problem of team formation and content scheduling for education. Given a time frame d, a set of students S with their required need to learn different activities T and given k as the number of desired groups, we study the problem of finding k group of students. The goal is to teach students within time frame d such that their potential for learning is maximized and find the best schedule for each group. We show this problem to be NP-hard and develop a polynomial algorithm for it. We show our algorithm to be effective both on synthetic as well as a real data set. For our experiments, we use real data on students' grades in a Computer Science department. As part of our contribution, we release a semi-synthetic dataset that mimics the properties of the real data.", "histories": [["v1", "Sun, 26 Mar 2017 03:47:54 GMT  (704kb,D)", "http://arxiv.org/abs/1703.08762v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["sanaz bahargam", "d\\'ora erdos", "azer bestavros", "evimaria terzi"], "accepted": false, "id": "1703.08762"}, "pdf": {"name": "1703.08762.pdf", "metadata": {"source": "CRF", "title": "Team Formation for Scheduling Educational Material in Massive Online Classes", "authors": ["Sanaz Bahargam", "D\u00f3ra Erd\u0151s", "Azer Bestavros", "Evimaria Terzi"], "emails": ["evimaria]@cs.bu.edu"], "sections": [{"heading": null, "text": "Keywords Team Formation; Clustering; Partitioning; Teams; MOOC; Large Classes"}, {"heading": "1. INTRODUCTION", "text": "Education has always been regarded as one of the most important tasks of society. Nowadays it is viewed as one of the best means to bridge the societal inequalities gap and to help individuals to achieve their full potential. Accordingly, many work has been dedicated to study how individuals learn and what is the best way to teach them (see [10, 5] for an overview). We recognize two substantial conclusions that studies in this area make on how to improve students\u2019 learning outcome. First, the use of personalized education; by shaping the content and delivery of the lessons to the individual ability and need of each student we can enhance\ntheir performance([32, 27, 25, 12, 37]. Second, grouping students; working in teams with their peers helps students to access the material from a different viewpoint as well [2, 6, 39, 27, 38].\nIn this paper we study the problem of creating personalized educational material for teams of students by taking a computational perspective. More specifically, we focus on two problems: the first problem is how to identify the right schedule for a group of students, when the group is apriori formed. The second problem is how to partition a set of students into groups and design personalized schedules per group so that the benefit of students in terms of how much they learn and absorb is maximized.\nSignificant amount of work has been carried out on designing personalized educational content, such as [29] in the context of online education services and more notably on designing personalized schedules by Novikoff et al. [32] which has inspired our current work. Team formation in education is another well-studied area [2, 14, 31] and it has been showed that students can improve their abilities by interaction and communication with other team members [34].\nHowever, to the best of our knowledge we are the first to formally define and study the two problems of team formation and personalized scheduling for teams in the context of education. Therefore, our contribution is to present formal definition of aforementioned problems, study their computational complexity and design algorithms for solving them. In addition to this we also apply our algorithms to a real dataset obtained from real students. We make our semisynthetic dataset BUCSSynth, generated to faithfully mimic the real student data available on our website.\nRoadmap: The rest of the paper is organized as follows: After reviewing the related work in Section 2, we define our framework and settings in Section 3. In Section 4 we define group schedule problem. In Section 5 we formally define Cohort Selection and also show its computational complexity. In the same section, we present our CohPart to solve Cohort Selection . In Section 6 we show usefulness of our CohPart on synthetic and real world datasets. Finally we conclude the paper in Section 7."}, {"heading": "2. RELATED WORK", "text": "Our problem is related to psychology, education and computer science including ability grouping, repetition in learn-\nar X\niv :1\n70 3.\n08 76\n2v 1\n[ cs\n.A I]\n2 6\nM ar\n2 01\n7\ning and team formation. We review some of these works here:\nAbility grouping: Majority of the studies in this area find that over the whole population, there definitely is a gain in academic performance due to ability grouping [17, 39, 23, 24, 21, 9]. Most of the studies agree, that there is high increase to learning of students in high-ability groups. Some say there is only small gain, while others say there is zero gain for low-ability groups. But even in this case, gain to the medium and high ability groups counters these negative effects. The benefits of grouping on students\u2019 attitude has also been studied in [23]. Authors have shown that students in grouped classes developed more positive attitudes toward the subjects they were studying than did students in ungrouped classes.\nRepetition in learning: Repetition has long been regarded as essential in learning. When learning a new activity for the first time, new information is gained and stored in the short-term memory. This information will be lost over time when there is no attempt to retain it [33, 36, 19, 11, 1, 16, 15] Repetition in learning and spacing effect has been even studied in computer science in [32]. In this work authors try to optimize a single student\u2019s learning in the light of Ebbinhaus\u2019s work. They model education process as a sequence of abstract units and these units are repeated over time. However they did not consider the importance of having a deadline for e.g. to prepare for a test and also the fact that after enough repetitions the information will move to long-term memory and there is negligible gain from repetition.\nTeam formation: An earlier version of this study has appeared in [7]. Team formation has been studied in operations research community [8, 13, 41, 42], which defines the problem as finding optimal match between people and demanded functional requirements. It is often solved using techniques such as simulated annealing, branch-and-cut or genetic algorithms [8, 41, 42]. It has also been studied in computer science [2, 3, 20, 26, 30, 35, 4] Majority of these work focus on team formation to complete a task and minimize the communication cost among team members. The focus of these studies is on finding only one team to perform a given task. [2] considers partitioning students in which each student has only one ability level for all the activities and each team has a set of leaders and followers. The goal is to maximize the gain of students where gain is defined as the number of students who can do better by interacting with the higher ability students. Our problem differs as we consider different ability levels for different activities."}, {"heading": "3. PRELIMINARIES", "text": "Already Aristotle said that \u201dit is frequent repetition that produces a natural tendency.\u201d The fundamental basis of our work is the realization that repetition is an essential part of learning; engaging with a topic multiple times 1 deepens and hastens students\u2019 engagement and understanding processes [11, 40]. In this paper we focus on developing optimal schedules for teaching groups of students (e.g. classes) that\n1For e.g. learning about a topic multiple times, reiterating it, possibly in different formats or from different viewpoints\nobserve this dependency of learning quality on reiteration of topics. We model a student\u2019s learning process by a sequence of topics that she learns about. In this sequence topics may appear multiple times, and repetitions of a topic may count with different weights towards the overall benefit of the student.\nLet S = {s1, s2, . . . , sn} be a set of students and T = {t1, t2, . . . , tm} be a set of topics. We assign topics to d timeslots based on two very simple rules; only one topic can be assigned to each timeslot but the same topic can appear in multiple slots. A schedule A is a collision free assignment of topics to the timeslots. A can be thought of as an ordered list of (possible multiple occurrences) of the topics. For a topic t \u2208 T the tuple \u3008t, i\u3009 denotes the ith occurrence of t in a schedule. The notation A[r] = \u3008t, i\u3009 refers to the tuple \u3008t, i\u3009 that is assigned to timeslot r in A.\nTopic requirements. For every student s \u2208 S and topic t \u2208 T there is a number of times that s has to hear about t in order for s to learn every aspect of this topic. We call this number the requirement of s on t and denote it by the integer function req(s, t).\nBenefits from topic. In order for a student s to be fully knowledgeable about topic t, he has a requirement to learn req(s, t) times about t. We assume that until s has met his requirements, he gains knowledge and hence, will benefit to some extent from every repetition of t. After req(s, t) repetitions of t, while there is no detriment, there is also no additional benefit to s from hearing about t. We call b(s, \u3008t, i\u3009) (Equation (1)) the benefit of s from topic t when hearing about it for the ith time. We assume that s benefits equally from each of the first req(s, t) occurrences of t in A, thus b(s, \u3008t, i\u3009) = 1\nreq(s,t) if i \u2264 req(s, t). Since after this\npoint s has already mastered topic t, there is no additional benefit from any later repetition of t and hence b(s, \u3008t, i\u3009) = 0.\nb(s, \u3008t, i\u3009) =\n{ 1\nreq(s.t) if i \u2264 req(s, t) 0 otherwise (1)\nNote that for ease of exposition, we assume that all repetitions of t before req(s, t) carry equal benefit to s. However, the definition and all of our later algorithms could easily be extended to use some other function b\u2032(s, \u3008t, i\u3009). A natural choice for example is a function, where earlier repetitions of t carry higher benefit than later ones, thus b\u2032(s, \u3008t, i\u3009) = 1\n2i .\nThe intuition is that first you learn about the fundamentals of t and later you add on additional information.\nGiven the benefits b(s, \u3008t, i\u3009) there is a natural extension to define the benefit B(s,A) that s gains from schedule A. This benefit is simply a summation over all timeslots in A,\nB(s,A) = d\u2211\nr=1\nb(s,A[r]) (2)\nRemember that in Equation (2), A[r] refers to the tuple \u3008t, i\u3009 that is scheduled at timeslot r in A.\nObserve, that every time topic t appears in the schedule A, it will contribute with the same amount of benefit towards\nB(s,A), regardless of the exact timeslot allocation within A."}, {"heading": "4. THE GROUP SCHEDULE PROBLEM", "text": "In this section we investigate the problem of how to divide students in such groups and assign schedules to each group to maximize the benefit of students in every group.\nGroup benefits. Let P \u2286 S be a subset of the students, we refer to P as a group. The notion of the benefit of a schedule A to a single student s lends itself to a straightforward extension to the benefit of a group. We define the benefit B(P,A) group P has from A in Equation (3) as the sum of the benefits over all students in P .\nB(P,A) = \u2211 s\u2208P d\u2211 r=1 b(s,A[r]) (3)\nThe group schedule problem. Given a group P , our first task is to find an optimal schedule for this group, that is to find a schedule that maximizes the group benefit of P . We call this the group schedule problem (problem 1).\nProblem 1 (group schedule ). Let P \u2286 S be a group of students and T be a set of topics. For every s \u2208 S and t \u2208 T let req(s, t) be the requirement of s on t given for every student-topic pair. Find a schedule AP , such that B(P,AP ) is maximized for a deadline d.\nThe Schedule algorithm. There is a simple polynomial time algorithm that solves problem 1. We cal this algorithm Schedule(P, d). We present Schedule(P, d) in Algorithm 1.\nRemember that for any topic t the requirement req(s, t) may be different for the different students in P . We say that the marginal benefit, m(P, \u3008t, i\u3009), from the ith repetition of t (thus \u3008t, i\u3009) to P is the increase in the group benefit if \u3008t, i\u3009 is added to A. The marginal benefit of \u3008t, i\u3009 can be computed as the sum of benefits over all students in P as given in Equation (4).\nm(P, \u3008t, i\u3009) = \u2211 s\u2208P b(s, \u3008t, i\u3009) (4)\nObserve that because students have different requirements for t, the subsequent repetitions of the same topic may have different (decreasing) marginal benefits.\nAlgorithm 1 is a greedy algorithm that at every timeslot chooses an instance of the topic with the largest marginal benefit. To achieve this we maintain an array B in which values are marginal benefit of topics t \u2208 T, if next repetition of t is added to the schedule AP . We keep the number that topic t has been added to AP in array R.\nThe Schedule algorithm is an iterative algorithm that repeats until all d timeslots in the schedule are filled; it selects the topic ut with the largest marginal benefit from B and adds it to the schedule AP (Lines 5 and 6) . Then it updates marginal benefit of ut, B[ut] (Lines 7- 8).\nAlgorithm 1 Schedule algorithm for computing an optimal schedule AP for a group P .\nInput: requirements req(s, t) for every s \u2208 P and every topic t \u2208 T, deadline d. Output: schedule AP .\n1: AP \u2190 [] 2: B \u2190 [m(P, \u3008t, 1\u3009)] for t \u2208 T 3: R\u2190 [0] for all t \u2208 T 4: while |AP | < d do 5: Find topic ut with maximum marginal benefit in B 6: AP \u2190 \u3008ut, R[ut]\u3009 7: R[ut] + + 8: Update B[ut] to m(P, \u3008t, R[ut]\u3009) 9: end while\nRuntime of Schedule. The runtime of Algorithm 1 is best computed from the point of view of computing marginal benefits of topics in B. In each iteration of the loop, the marginal benefit is only recomputed for one of the topics, ut with the largest benefit which has been added to the schedule AP most recently. The total runtime of algorithm is O(d(|P |+|T|)). If we keep the marginal benefits in a maxheap, we can reduce the running time to O(d(|P |+ log|T|)). Algorithm 1 yields an optimal schedule for a group P .\nProposition 1. The schedule AP output by Algorithm 1 yields maximal benefit B(P,A) for the group P .\nProof. Observe, that the benefit of adding the ith repetition \u3008t, i\u3009 of topic t to A is only dependent on i and t but not on any other topic. Hence the choice that we make in algorithm 1 in any iteration does not change the marginal benefit m(P, \u3008t, i\u3009). Thus choosing the topic t with the largest marginal benefit in any iteration of algorithm 1 results in a schedule with maximal total benefit for the group."}, {"heading": "5. THE COHORT SELECTION PROBLEM", "text": "So far we discussed how to find an optimal schedule of topics for a given group of students. The next natural question is, that given a certain teaching capacity K (i.e., there are K teachers or K classrooms available), how to divide students intoK groups so that each student benefits the most possible from this arrangement.\nAt a high level we solve an instance of a partition problem; we have to find a K-part partition P = P1\u222a\u2217P2\u222a\u2217 . . .\u222a\u2217PK of students into groups, so that the sum of the group benefits over all groups is maximized. We call the problem of finding a partition that yields the highest sum of group benefits the the Cohort Selection Problem .\nProblem 2 (Cohort Selection ). Let S be a set of students and T be a set of topics. For every s \u2208 S and t \u2208 T let req(s, t) be the requirement of s on t that is given for every student-topic pair. Find a partition P of students into K groups, such that\nB(P, d) = \u2211 P\u2208P B(P,AP ) (5)\nis maximized, where we assume that AP = Schedule(P, d) for every group.\nTheorem 1. Cohort Selection (Problem 2) is NPhard.\nProof. We reduce the catalog segmentation problem [22] to Cohort Selection problem. catalog segmentation is the following problem; there is a universe of items U = {u1, u2, . . . , um} and subsets S1,S2, . . . ,Sn \u2286 U given. Find two subsets X and Y of U , both of size |X | = |Y| = r, such that\nCS(X ,Y) = n\u2211\ni=1\nmax{|Si \u2229 X|, |Si \u2229 Y|} (6)\nis maximized. It is proven by Kleinberg et al. [22] that catalog segmentation is NP-hard.\nWe now show that if we can solve Cohort Selection then we can also solve the catalog segmentation problem. More specifically, we map an instance of catalog segmentation to an instance of Cohort Selection as follows: every subset Si in catalog segmentation is mapped to a student si in Cohort Selection and element of the universe ui \u2208 U of catalog segmentation is mapped to a topic ti in Cohort Selection. For student si and topic tj we set the requirement req(si, tj) = 1 if uj \u2208 Si, otherwise req(si, tj) = nm 3. We also set d = r and K = 2.\nWe can also map a solution of Cohort Selection to a solution of catalog segmentation and vice verse; let P = {X,Y } be a partition of the students S in Cohort Selection and let AX and AY be the optimal schedules for X and Y . We define the sets X and Y in catalog segmentation from AX and AY . Specifically, let {tx1 , tx2 , . . . , txr} be the topics (possible with multiplicity) that appear in AX . Then we define X = {utx1 , utx2 , . . . , utxr } to contain the elements in U corresponding to the topics in AX . Y is derived in a similar way from AY .\nGiven a solution X and Y to catalog segmentation, we can define the partition P = {X,Y } and the corresponding group schedules AX and AY . For every s \u2208 S we assign s to X if |S \u2229X | > |S \u2229Y| and assign s to Y otherwise, where S is the set in catalog segmentation that we identified with student s. Further, the group schedule AX is the schedule that contains topic t if and only if ut \u2208 X . Similar, Y = {t|ut \u2208 Y}.\nWe show if P = {X,Y } is an optimal solution to Cohort Selection, then the corresponding solution X , Y has to be an optimal solution to catalog segmentation. First, observe that because of the choice of the requirements in Cohort Selection, if B is the value of a solution to Cohort Selection, then the value of catalogsegmentation(X ,Y) \u2265 bBc. Further, bB({X,Y }, d)c = catalogsegmentation(X ,Y), where P = {X,Y } is derived from X and Y.\nLet us assume, that P = {X,Y } is an optimal solution to Cohort Selection, but the derived X and Y are not optimal for catalog segmentation. That means there exist X \u2032 and Y \u2032, such that catalogsegmentation(X ,Y) < catalogsegmentation(X \u2032,Y \u2032). However, in this case the partition P \u2032 = {X \u2032, Y \u2032} with the schedules AX\u2032 , AY \u2032 derived from X \u2032 and Y \u2032 would yield a higher value for Cohort Se-\nlectionproblem, contradicting the optimality of P."}, {"heading": "5.1 Partition algorithms.", "text": "We first describe briefly two popular algorithms for clustering, K_means and Random Partitioning and how it is applied to our problem. Then we proceed to present our solution, CohPart to the Cohort Selection and a samplingbased speedup, CohPart_S .\nRandom Partitioning is assigning each point randomly to a cluster. We use this partitioning as a baseline to compare our algorithm with. Also we use it as the initialization part of our CohPart algorithm.\nK_means is a clustering method used to minimize the average squared distance between points in the same cluster. Solving K_means problem [18] exactly is NP-hard. Lloyd\u2019s algorithm [28] solves this problem by choosing k centers randomly and assigning the points to the closest center. Then the centers are recomputed based on the points assigned to it. These two phases are repeated until there is no more improvement on the cost of clustering. In our setting the students are the data points and the repetition for each topic represent each dimension.\nCohPart algorithm. The CohPart algorithm (Cohort Partitioning) is presented in algorithm 3 and consists of two phases; first there is an initialization phase (Lines 3- 6), in which a random clustering is executed on all of the students (Line 3) and then for each partition pi, the centers are computed (Lines 4- 6) using algo 1. When initial cluster centers are chosen, then there is an iterative phase (Lines 7- 14) where students get reassigned to clusters and cluster centers are updated again.\nIn our notations A and R both show the schedules (of a group of students or a single student). A shows the vector of size d consisting of topics and their repetitions \u3008t, R[t]\u3009 for each time slot. R is a vector of size |T| and for each topic t, how many times it can be repeated in deadline d.\nAlgorithm 2 Benefit algorithm for computing the benefit of a single student s from a schedule R\nInput: requirements req(s, t) for a student s \u2208 P and every topic t \u2208 T and a single schedule R Output: b(s,R) Benefit of s from schedule R.\n1: b = 0 2: for all topics t \u2208 T do 3: b = b+ min(req(s,t),R[t])\nR[t]\n4: end for\nRuntime : CohPart is a heuristic to solve Cohort Selectionproblem. In each iteration of the algorithm, the group that each student can benefit the most is found and student is assign to that group. This will take O(k|T|) for each student. Then the schedule of each group is updated and algorithm iterates until convergence is achieved. The total running time of each iteration is O(k|S||T|). In our experiments we observed that our algorithm converges really fast, less than a few tens of iterations.\nAlgorithm 3 CohPart for computing the partition P based on the benefit of students from schedules.\nInput: requirement req(s, t) for every s \u2208 S and t \u2208 T, number of timeslots d, number of groups K. Output: partition P. 1: C = 2: P = {P1, P2, . . . , PK} 3: Run Random Partitioning on the students and obtain Pi\u2019s 4: for i = 1, . . . ,K do 5: ci = Schedule(Pi, d) 6: end for 7: while convergence is achieved do 8: for all students s \u2208 S do 9: Pi \u2190 s, such that i = argmaxj=1,...,k b(s, cj)\n10: end for 11: for i = 1, . . . ,K do 12: ci = Schedule(Pi, d) 13: end for 14: end while\nCohPart_S algorithm. The CohPart_S (Cohort Partitioning with Sampling,) resembles CohPart except that it performs clustering on a random sample of students of size n\u2032 and when clustering is finished assigns the remaining students to the cluster with the maximum benefit b(s, cj). It reduces the running time to O(kn\u2032|T|) . We set n\u2032 = k \u2217 c for different values of c."}, {"heading": "5.2 Constraints on Topic Order", "text": "In real-life, most often we cannot pick any scheduling of topics we like. Instead, there are strict precedence constraints among the topics. For example, one has to learn addition before he can learn about multiplication during a math course. Therefore, we assume that along with the topics, a set of constraints is also given. The constraints can be simple ones, such as the first occurrence of topic ti has to be before topic tj , or more complicated ones, topic tj can only be scheduled after at least r1 repetitions of ti1 and r2 repetitions of ti2 . Of course, the set of constraints can also be empty, if we do not have any of them. We can easily modify algorithm 1 to take into account these constraints and check for precedence constraints. To achieve this, after line 4 we can check for precedence constraints and in line 5 we choose only the topics which their precedence constraints are met."}, {"heading": "6. EXPERIMENTS", "text": "The goal of these experiments is to gain an understanding of how our clustering algorithm works in terms of performance (objective function). Furthermore, we want to understand how the deadline parameter impacts our algorithm. We used a real world dataset, semi synthetic and synthetic datasets. The semi synthetic dataset and the source code to generate it are available in our website. We first introduce Graded Response Model (GRM) briefly, then explain different datasets and finally show how well our algorithm is doing on each dataset.\nItem Response Theory and Graded Response Model: In psychometric, Item Response Theory (IRT) is a framework for designing and evaluating tests, questions and ques-\ntionnaires. In IRT models the probability of giving a correct answer by a student to a question is determined based on the ability of student and the difficulty of the question. For our work we used the Graded Response Model (GRM), an advanced IRT model which fits our data well and handles partial credit values. Using our data on grades of students for taken courses, GRM helps us to deduce ability scores for each student and difficulty scores for each course. Having these score parameters, then we can generate the missing grades for courses that a student did not take. We also used GRM to obtain a model to generate a larger dataset, i.e. BUCSSynth."}, {"heading": "6.1 Datasets", "text": "This subsection describes each dataset and their attributes.\nBUCS data: The original BUCS dataset consists of grades of students in CS courses at Boston University. This data was collected from Fall 2003 to Fall 2013. Each row of data looked like: FALL 2003, CS101, U12345, U1, C+ which shows the semester year, course number, students\u2019 BU id, undergraduate/graduate year and the grade. It consists of 9833 students. We only considered students who were taking CS330 and CS210 (required courses to obtain a major in CS) which consisted of 398 students and 41 courses. Here the courses correspond to topics. Obviously the new dataset had some missing values, not all 41 courses were taken by those 398 students. To fill the grades for missing (student, course) pairs, we used GRM. First using GRM, we obtained the ability and difficulty parameters for all students and all courses. The abilities 2 and difficulties\u2019 parameters are available online3. Then for each pair of (student, course) in which student s did not take course c, we used the ability of s and difficulty of c to predict the grade of course c for that student. After having all grades for all courses, we had to transform these grades to the number of required repetitions to learn a course. We assumed the number of required repetition to master a course (or topic) for the smartest student is 5 (base parameter). Note that throughout a semester students review the course materials to solve homework, do project and prepare for quizzes, midterm and final exams, so they review material for at least 5 times. Thus for students who got A, we considered 5 repetitions needed to fully master the course and as the ability (and grade) drops, number of repetition goes up (step parameter). We also tried different base and step values for our experiments.\nBUCSSynth data: In order to see how well our algorithm scales to a larger dataset, we generated a synthetic data, based on the obtained parameters from GRM. We call this dataset BUCSSynth. From BUCS dataset, we observed that the ability of students follows a normal distribution with \u00b5 = 1.13 and \u03c3 = 1.41. Applying GRM to BUCS data, we obtained difficulty parameters for 41 courses. In order to obtain difficulties for 100 courses, we used the following approach:\n1. Choose one of the 41 courses at random. 2. Use density estimation, smoothing and then get the\nCDF of the difficulties.\n2http://cs-people.bu.edu/bahargam/abilities 3http://cs-people.bu.edu/bahargam/difficulties\n3. Randomly sample from the CDF to get the difficulties for a new course. Using the aforementioned parameters, we generated the grades for 2000 students and 100 courses and we transformed the grades to number of repetitions similar to what we did for BUCS dataset. This dataset 4 and the code 5 to generate it are available online.\nSynthetic data: Our first synthetic dataset is to generate ground truth data to compare our algorithm to Random Partitioning and K_means . In this dataset we had generated 10 groups of students, each group containing 40 students. For each group we selected 5 courses and assigned repetitions randomly to those 5 courses such that the sum of repetition will be equal to the deadline6. Then for the remaining 35 courses, we filled the required number of repetitions with random numbers taken from a normal distribution with \u00b5 = deadline\n5 and \u03c3 = 3. We refer to this dataset\nas GroundTruth. We expect our algorithm to be able to find the right clusters of students while K_means cannot find this hidden structure.\nWe have also generated the repetitions for 400 students and 40 courses using Pareto, Normal and Uniform distributions. We refer to this datastes as pareto, normal and uniform. To generate number of repetitions for different courses using the pareto distribution, we used the shape parameter \u03b1 = 2. For normal distribution we used \u00b5 = 30 and \u03c3 = 5 and for uniform dataset we generated random numbers in the range of [5,100]."}, {"heading": "6.2 Results:", "text": "Our experiments compare our algorithm in terms of our objective function (students\u2019 benefit) with Random Parti-\ntioning and K_means R\u0307ecall that the students\u2019 benefit is defines in Equation (5). The current algorithm is implemented in Python 2.7 and all the experiments are run single threaded on a Macbook Air (OS-X 10.9.4, 4GB RAM). We compare our algorithm with Random Partitioning and the K_means algorithm, the built in k-means function in Scipy library. Each experiment was repeated 5 times and the average results are reported in this section. For sample size in CohPart_S algorithm, we set parameter c (explained earlier) to 4 in all experiments.\n6.2.1 Results on Real World Datasets\nBUCS: We executed our algorithm on BUCS dataset untill reaching convergence and show how well it maximized the benefit of learning while varying the number of clusters We compare CohPart and CohPart_S to Random Partitioning and K_means . The result is depicted in Figure 1e where each point shows the benefit of all students when partitioning them into k groups. As we see the Random Partitioning has the lowest benefit and our algorithm has the best benefit. As the number of clusters increases (having hence fewer students in each cluster), the benefit also increases, means the\n4http://cs-people.bu.edu/bahargam/BUCSSynth 5http://cs-people.bu.edu/bahargam/BUCSSynthCode 6The repetition for those selected courses are not equal for the students in the same group, but for all the students in the group the sum of selected courses is equal to the deadline.\nschedule for those students is more personalized and closer to their individual schedule, when having one tutor for each student. The benefit grows dramatically from 1 cluster to 10 cluster. But after 10 cluster the increase in the potential is slower. We also show the 95 confidence interval, but it was small that cannot be seen in some plots.\nBUCSdeadline: We also show the result for different values of deadline. As the deadline increases, the gap between K_means and our algorithm decreases. The reason is as deadline is greater we have to take into consideration more topics to teach to the students. Note that K_means algorithm behaves like our algorithm except it considers all the courses and ignores the deadline. So the greater the deadline is, the closer K_means gets to our algorithm. But in real life, we do not have enough time to repeat (or teach) all of the courses (for e.g. for preparation before SAT exam). Figure 1f illustrates the case when deadline is equal to the average sum of need vectors for different students.\nBUCSBase: We tried different values for base and step parameters (explained earlier) and the result is depicted in Figure 1g, when the base and step are equal to 1. We observe that when the base is equal to 1 and step is also small, K_means also performs well, but still our algorithm is doing better than K_means . The larger is the value of base and step parameter, the better our algorithm performs.\n6.2.2 Results on Semi-synthetic Dataset\nBUCSSynth dataset: We ran our algorithmon on BUCSSynth dataset to see how well our algorithm scales for large number of students. The result is depicted in Figure 1h.\n6.2.3 Results on Synthetic Datasets Our first set of experiments on synthetic data used the ground truth dataset. The result is illustrated in Figure 1a. As we see CohPart and CohPart_S both are performing really well. For all of the courses the mean required repetition is close to 10 with standard deviation 3. We expect that students in the same group (when generating the data) should be placed in the same cluster as well after running our algorithm and the schedule should include the selected courses in each group. In each group students have different repetition values for the selected courses, but the sum of these selected courses is equal to the deadline and our algorithm realized this structure and only considered these selected courses to obtain the schedule. But K_means lacked this ability and did not cluster these students together. The next studied datasets were uniform, pareto and normal datasets and the results are depicted in Figure 1b, 1c and 1d respectively. For these datasets also our algorithm outperformed K_means and Random Partitioning ."}, {"heading": "7. CONCLUSION", "text": "In this paper, we highlighted the importance of team formation and scheduling educational materials for students. We suggested a novel clustering algorithm to form different teams and teach the team members based on their abilities in different topics. Our algorithm maximized the potential and benefit of team members for learning . The encouraging results that we obtained shows that our proposed solution is\neffective and suggest that we have to consider personalized teaching for students and form more efficient teams."}, {"heading": "8. REFERENCES", "text": "[1] R. Agrawal, B. Golshan, and E. Terzi. Forming\nbeneficial teams of students in massive online classes. In Proceedings of the first ACM conference on Learning@ scale conference, pages 155\u2013156. ACM, 2014.\n[2] R. Agrawal, B. Golshan, and E. Terzi. Grouping students in educational settings. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201914, pages 1017\u20131026, New York, NY, USA, 2014. ACM.\n[3] A. Anagnostopoulos, L. Becchetti, C. Castillo, A. Gionis, and S. Leonardi. Power in unity: Forming teams in large-scale community systems. In Proceedings of the 19th ACM International Conference on Information and Knowledge Management, CIKM \u201910, pages 599\u2013608, New York, NY, USA, 2010. ACM.\n[4] A. Anagnostopoulos, L. Becchetti, C. Castillo, A. Gionis, and S. Leonardi. Online team formation in social networks. In Proceedings of the 21st International Conference on World Wide Web, WWW \u201912, pages 839\u2013848, New York, NY, USA, 2012. ACM.\n[5] J. Aronson, editor. Improving academic achievement : impact of psychological factors on education.\n[6] A. Ashman and R. Gillies. Cooperative Learning: The Social and Intellectual Outcomes of Learning in Groups. Taylor & Francis, 2003.\n[7] S. Bahargam, D. Erdos, A. Bestavros, and E. Terzi. Personalized education; solving a group formation and scheduling problem for educational content. In The 8th International Conference on Educational Data Mining, 2015.\n[8] A. Baykasoglu, T. Dereli, and S. Das. Project team selection using fuzzy optimization approach. Cybern. Syst., 38(2):155\u2013185, Feb. 2007.\n[9] B. S. Bloom. The 2 sigma problem: The search for methods of group instruction as effective as one-to-one tutoring. Educational Researcher, 13(6):4\u201316, 1984.\n[10] J. Bransford, A. Brown, and R. Cocking, editors. How People Learn: Brain, Mind, Experience, and School - Expanded Edition. 2000.\n[11] R. F. Bruner. Repetition is the first principle of all learning. Social Science Research Network, 2001.\n[12] P. Brusilovsky and C. Peylo. Adaptive and intelligent web-based educational systems. International Journal of Artificial Intelligence in Education, 13(2):159\u2013172, 2003.\n[13] S.-J. Chen and L. Lin. Modeling team member characteristics for the formation of a multifunctional team in concurrent engineering. Engineering Management, IEEE Transactions on, 51(2):111\u2013124, May 2004.\n[14] D. Esposito. Homogeneous and heterogeneous ability grouping: Principal findings and implications for evaluating and designing more effective educational environments. Review of Educational Research, 43(2):163\u2013179, 1973.\n[15] E. Galbrun, B. Golshan, A. Gionis, and E. Terzi. Finding low-tension communities. arXiv preprint arXiv:1701.05352, 2017.\n[16] B. Golshan, T. Lappas, and E. Terzi. Profit-maximizing cluster hires. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1196\u20131205. ACM, 2014.\n[17] B. Grossen. How should we group to achieve excellence\nwith equity. PhD thesis, Unviersity of Oregon, July 1996.\n[18] J. Hartigan and M. Wong. Algorithm AS 136: A K-means clustering algorithm. Applied Statistics, pages 100\u2013108, 1979.\n[19] M. Y. Jaber and H. V. Kher. Variant versus invariant time to total forgetting: The learn\u2013forget curve model revisited. Computers & Industrial Engineering, 46(4):697\u2013705, 2004.\n[20] M. Kargar and A. An. Discovering top-k teams of experts with/without a leader in social networks. In Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM \u201911, pages 985\u2013994, New York, NY, USA, 2011. ACM.\n[21] A. C. Kerckhoff. Effects of ability grouping in british secondary schools. American Sociological Review, 51(6):842\u2013858, 1986.\n[22] J. Kleinberg, C. Papadimitriou, and P. Raghavan. Segmentation problems. J. ACM, pages 263\u2013280, 2004.\n[23] C.-L. C. Kulik and J. A. Kulik. Effects of Ability Grouping on Secondary School Students: A Meta-analysis of Evaluation Findings. Am Educ Res J, 19(3):415\u2013428, Jan. 1982.\n[24] J. A. Kulik and C.-L. C. Kulik. Meta-analytic findings on grouping programs. Gifted Child Quarterly, 36(2):73\u201377, 1992.\n[25] A. I. Lakatos. Introduction. Journal of the Society for Information Display, 8(1):1\u20131, 2000.\n[26] T. Lappas, K. Liu, and E. Terzi. Finding a team of experts in social networks. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201909, pages 467\u2013476, New York, NY, USA, 2009. ACM.\n[27] C. F. Lin, Y. chu Yeh, Y. H. Hung, and R. I. Chang. Data mining for providing a personalized learning path in creativity: An application of decision trees. Computers & Education, 68(0):199 \u2013 210, 2013.\n[28] S. P. Lloyd. Least squares quantization in pcm. IEEE Transactions on Information Theory, 28:129\u2013137, 1982.\n[29] J. Lu. Personalized e-learning material recommender system. In International conference on information technology for application, pages 374\u2013379, 2004.\n[30] A. Majumder, S. Datta, and K. Naidu. Capacitated team formation problem on social networks. In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201912, pages 1005\u20131013, New York, NY, USA, 2012. ACM.\n[31] J. M. McPartland and M. Johns Hopkins Univ., Baltimore. School Structures and Classroom Practices in Elementary, Middle, and Secondary Schools. Report No. 14 [microform] / James M. McPartland and Others. Distributed by ERIC Clearinghouse [Washington, D.C.], 1987.\n[32] T. P. Novikoff, J. M. Kleinberg, and S. H. Strogatz. Education of a model student. Proceedings of the National Academy of Sciences, 109(6):1868\u20131873, 2012.\n[33] B. Pentland. The learning curve and the forgetting curve: The importance of time and timing in the implementation of technological innovations. In 49th annual meeting of the Academy of Management, Washington, DC, 1989.\n[34] N. M. Rachel Hertz-Lazarowitz. Interaction in cooperative groups: The theoretical anatomy of group learning. Cambridge University Press, 1995.\n[35] S. S. Rangapuram, T. Bu\u0308hler, and M. Hein. Towards realistic team formation in social networks based on densest subgraphs. In Proceedings of the 22Nd International Conference on World Wide Web, WWW \u201913, pages 1077\u20131088, Republic and Canton of Geneva, Switzerland, 2013. International World Wide Web Conferences Steering Committee.\n[36] H. Roediger and J. Nairne. The Foundations of Remembering: Essays in Honor of Henry L. Roediger III. Psychology Press Festschrift Series. Psychology Press, 2007.\n[37] A. Segal, Z. Katzir, K. Gal, G. Shani, and B. Shapira. Edurank: A collaborative filtering approach to personalization in e-learning. 2014.\n[38] A. P. Sergio Gutierrez-Santos, Manolis Mavrikis. Mining students\u2019 strategies to enable collaborative learning. 2014.\n[39] R. E. Slavin. Ability Grouping and Student Achievement in Elementary Schools: A Best-Evidence Synthesis. Review of Educational Research, 57(3):293\u2013336, 1987.\n[40] C. J. Weibell. Principles of learning: A conceptual framework for domain-specific theories of learning. PhD thesis, Brigham Young University. Department of Instructional Psychology and Technology, 2011.\n[41] H. Wi, S. Oh, J. Mun, and M. Jung. A team formation model based on knowledge and collaboration. Expert Systems with Applications, 36(5):9121 \u2013 9134, 2009.\n[42] A. Zakarian and A. Kusiak. Forming teams: an analytical approach. IIE Transactions, 31(1):85\u201397, 1999."}], "references": [{"title": "Forming beneficial teams of students in massive online classes", "author": ["R. Agrawal", "B. Golshan", "E. Terzi"], "venue": "Proceedings of the first ACM conference on Learning@ scale conference, pages 155\u2013156. ACM,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Grouping students in educational settings", "author": ["R. Agrawal", "B. Golshan", "E. Terzi"], "venue": "Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201914, pages 1017\u20131026, New York, NY, USA,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Power in unity: Forming teams in large-scale community systems", "author": ["A. Anagnostopoulos", "L. Becchetti", "C. Castillo", "A. Gionis", "S. Leonardi"], "venue": "Proceedings of the 19th ACM International Conference on Information and Knowledge Management, CIKM \u201910, pages 599\u2013608, New York, NY, USA,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Online team formation in social networks", "author": ["A. Anagnostopoulos", "L. Becchetti", "C. Castillo", "A. Gionis", "S. Leonardi"], "venue": "Proceedings of the 21st International Conference on World Wide Web, WWW \u201912, pages 839\u2013848, New York, NY, USA,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Cooperative Learning: The Social and Intellectual Outcomes of Learning in Groups", "author": ["A. Ashman", "R. Gillies"], "venue": "Taylor & Francis,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Personalized education; solving a group formation and scheduling problem for educational content", "author": ["S. Bahargam", "D. Erdos", "A. Bestavros", "E. Terzi"], "venue": "The 8th International Conference on Educational Data Mining,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Project team selection using fuzzy optimization approach", "author": ["A. Baykasoglu", "T. Dereli", "S. Das"], "venue": "Cybern. Syst., 38(2):155\u2013185, Feb.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "The 2 sigma problem: The search for methods of group instruction as effective as one-to-one tutoring", "author": ["B.S. Bloom"], "venue": "Educational Researcher, 13(6):4\u201316,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1984}, {"title": "How People Learn: Brain, Mind, Experience, and School - Expanded Edition", "author": ["J. Bransford", "A. Brown", "R. Cocking", "editors"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Repetition is the first principle of all learning", "author": ["R.F. Bruner"], "venue": "Social Science Research Network,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "Adaptive and intelligent web-based educational systems", "author": ["P. Brusilovsky", "C. Peylo"], "venue": "International Journal of Artificial Intelligence in Education, 13(2):159\u2013172,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Modeling team member characteristics for the formation of a multifunctional team in concurrent engineering", "author": ["S.-J. Chen", "L. Lin"], "venue": "Engineering Management, IEEE Transactions on, 51(2):111\u2013124, May", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Homogeneous and heterogeneous ability grouping: Principal findings and implications for evaluating and designing more effective educational environments", "author": ["D. Esposito"], "venue": "Review of Educational Research, 43(2):163\u2013179,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1973}, {"title": "Finding low-tension communities", "author": ["E. Galbrun", "B. Golshan", "A. Gionis", "E. Terzi"], "venue": "arXiv preprint arXiv:1701.05352,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2017}, {"title": "Profit-maximizing cluster hires", "author": ["B. Golshan", "T. Lappas", "E. Terzi"], "venue": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1196\u20131205. ACM,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "How should we group to achieve excellence  with equity", "author": ["B. Grossen"], "venue": "PhD thesis, Unviersity of Oregon, July", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1996}, {"title": "Algorithm AS 136: A K-means clustering algorithm", "author": ["J. Hartigan", "M. Wong"], "venue": "Applied Statistics, pages 100\u2013108,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1979}, {"title": "Variant versus invariant time to total forgetting: The learn\u2013forget curve model revisited", "author": ["M.Y. Jaber", "H.V. Kher"], "venue": "Computers & Industrial Engineering, 46(4):697\u2013705,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2004}, {"title": "Discovering top-k teams of experts with/without a leader in social networks", "author": ["M. Kargar", "A. An"], "venue": "Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM \u201911, pages 985\u2013994, New York, NY, USA,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Effects of ability grouping in british secondary schools", "author": ["A.C. Kerckhoff"], "venue": "American Sociological Review, 51(6):842\u2013858,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1986}, {"title": "Segmentation problems", "author": ["J. Kleinberg", "C. Papadimitriou", "P. Raghavan"], "venue": "J. ACM, pages 263\u2013280,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2004}, {"title": "Effects of Ability Grouping on Secondary School Students: A Meta-analysis of Evaluation Findings", "author": ["C.-L.C. Kulik", "J.A. Kulik"], "venue": "Am Educ Res J, 19(3):415\u2013428, Jan.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1982}, {"title": "Meta-analytic findings on grouping programs", "author": ["J.A. Kulik", "C.-L.C. Kulik"], "venue": "Gifted Child Quarterly, 36(2):73\u201377,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1992}, {"title": "Introduction", "author": ["A.I. Lakatos"], "venue": "Journal of the Society for Information Display, 8(1):1\u20131,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2000}, {"title": "Finding a team of experts in social networks", "author": ["T. Lappas", "K. Liu", "E. Terzi"], "venue": "Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201909, pages 467\u2013476, New York, NY, USA,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Data mining for providing a personalized learning path in creativity: An application of decision trees", "author": ["C.F. Lin", "Y. chu Yeh", "Y.H. Hung", "R.I. Chang"], "venue": "Computers & Education,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Least squares quantization in pcm", "author": ["S.P. Lloyd"], "venue": "IEEE Transactions on Information Theory, 28:129\u2013137,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1982}, {"title": "Personalized e-learning material recommender system", "author": ["J. Lu"], "venue": "International conference on information technology for application, pages 374\u2013379,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2004}, {"title": "Capacitated team formation problem on social networks", "author": ["A. Majumder", "S. Datta", "K. Naidu"], "venue": "Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201912, pages 1005\u20131013, New York, NY, USA,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "School Structures and Classroom Practices in Elementary, Middle, and Secondary Schools", "author": ["J.M. McPartland", "M. Johns Hopkins Univ", "Baltimore"], "venue": "Report No. 14 [microform] / James M. McPartland and Others. Distributed by ERIC Clearinghouse [Washington, D.C.],", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1987}, {"title": "Education of a model student", "author": ["T.P. Novikoff", "J.M. Kleinberg", "S.H. Strogatz"], "venue": "Proceedings of the National Academy of Sciences, 109(6):1868\u20131873,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "The learning curve and the forgetting curve: The importance of time and timing in the implementation of technological innovations", "author": ["B. Pentland"], "venue": "49th annual meeting of the Academy of Management, Washington, DC,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1989}, {"title": "Interaction in cooperative groups: The theoretical anatomy of group learning", "author": ["N.M. Rachel Hertz-Lazarowitz"], "venue": "Cambridge University Press,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1995}, {"title": "Towards realistic team formation in social networks based on densest subgraphs", "author": ["S.S. Rangapuram", "T. B\u00fchler", "M. Hein"], "venue": "Proceedings of the 22Nd International Conference on World Wide Web, WWW \u201913, pages 1077\u20131088, Republic and Canton of Geneva, Switzerland,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "The Foundations of Remembering: Essays in Honor of Henry L", "author": ["H. Roediger", "J. Nairne"], "venue": "Roediger III. Psychology Press Festschrift Series. Psychology Press,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2007}, {"title": "Edurank: A collaborative filtering approach to personalization in e-learning", "author": ["A. Segal", "Z. Katzir", "K. Gal", "G. Shani", "B. Shapira"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "Mining students\u2019 strategies to enable collaborative learning", "author": ["A.P. Sergio Gutierrez-Santos", "Manolis Mavrikis"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2014}, {"title": "Ability Grouping and Student Achievement in Elementary Schools: A Best-Evidence Synthesis", "author": ["R.E. Slavin"], "venue": "Review of Educational Research, 57(3):293\u2013336,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1987}, {"title": "Principles of learning: A conceptual framework for domain-specific theories of learning", "author": ["C.J. Weibell"], "venue": "PhD thesis, Brigham Young University. Department of Instructional Psychology and Technology,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2011}, {"title": "A team formation model based on knowledge and collaboration", "author": ["H. Wi", "S. Oh", "J. Mun", "M. Jung"], "venue": "Expert Systems with Applications, 36(5):9121 \u2013 9134,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2009}, {"title": "Forming teams: an analytical approach", "author": ["A. Zakarian", "A. Kusiak"], "venue": "IIE Transactions, 31(1):85\u201397,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1999}], "referenceMentions": [{"referenceID": 8, "context": "Accordingly, many work has been dedicated to study how individuals learn and what is the best way to teach them (see [10, 5] for an overview).", "startOffset": 117, "endOffset": 124}, {"referenceID": 30, "context": "First, the use of personalized education; by shaping the content and delivery of the lessons to the individual ability and need of each student we can enhance their performance([32, 27, 25, 12, 37].", "startOffset": 177, "endOffset": 197}, {"referenceID": 25, "context": "First, the use of personalized education; by shaping the content and delivery of the lessons to the individual ability and need of each student we can enhance their performance([32, 27, 25, 12, 37].", "startOffset": 177, "endOffset": 197}, {"referenceID": 23, "context": "First, the use of personalized education; by shaping the content and delivery of the lessons to the individual ability and need of each student we can enhance their performance([32, 27, 25, 12, 37].", "startOffset": 177, "endOffset": 197}, {"referenceID": 10, "context": "First, the use of personalized education; by shaping the content and delivery of the lessons to the individual ability and need of each student we can enhance their performance([32, 27, 25, 12, 37].", "startOffset": 177, "endOffset": 197}, {"referenceID": 35, "context": "First, the use of personalized education; by shaping the content and delivery of the lessons to the individual ability and need of each student we can enhance their performance([32, 27, 25, 12, 37].", "startOffset": 177, "endOffset": 197}, {"referenceID": 1, "context": "Second, grouping students; working in teams with their peers helps students to access the material from a different viewpoint as well [2, 6, 39, 27, 38].", "startOffset": 134, "endOffset": 152}, {"referenceID": 4, "context": "Second, grouping students; working in teams with their peers helps students to access the material from a different viewpoint as well [2, 6, 39, 27, 38].", "startOffset": 134, "endOffset": 152}, {"referenceID": 37, "context": "Second, grouping students; working in teams with their peers helps students to access the material from a different viewpoint as well [2, 6, 39, 27, 38].", "startOffset": 134, "endOffset": 152}, {"referenceID": 25, "context": "Second, grouping students; working in teams with their peers helps students to access the material from a different viewpoint as well [2, 6, 39, 27, 38].", "startOffset": 134, "endOffset": 152}, {"referenceID": 36, "context": "Second, grouping students; working in teams with their peers helps students to access the material from a different viewpoint as well [2, 6, 39, 27, 38].", "startOffset": 134, "endOffset": 152}, {"referenceID": 27, "context": "Significant amount of work has been carried out on designing personalized educational content, such as [29] in the context of online education services and more notably on designing personalized schedules by Novikoff et al.", "startOffset": 103, "endOffset": 107}, {"referenceID": 30, "context": "[32] which has inspired our current work.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "Team formation in education is another well-studied area [2, 14, 31] and it has been showed that students can improve their abilities by interaction and communication with other team members [34].", "startOffset": 57, "endOffset": 68}, {"referenceID": 12, "context": "Team formation in education is another well-studied area [2, 14, 31] and it has been showed that students can improve their abilities by interaction and communication with other team members [34].", "startOffset": 57, "endOffset": 68}, {"referenceID": 29, "context": "Team formation in education is another well-studied area [2, 14, 31] and it has been showed that students can improve their abilities by interaction and communication with other team members [34].", "startOffset": 57, "endOffset": 68}, {"referenceID": 32, "context": "Team formation in education is another well-studied area [2, 14, 31] and it has been showed that students can improve their abilities by interaction and communication with other team members [34].", "startOffset": 191, "endOffset": 195}, {"referenceID": 15, "context": "Ability grouping: Majority of the studies in this area find that over the whole population, there definitely is a gain in academic performance due to ability grouping [17, 39, 23, 24, 21, 9].", "startOffset": 167, "endOffset": 190}, {"referenceID": 37, "context": "Ability grouping: Majority of the studies in this area find that over the whole population, there definitely is a gain in academic performance due to ability grouping [17, 39, 23, 24, 21, 9].", "startOffset": 167, "endOffset": 190}, {"referenceID": 21, "context": "Ability grouping: Majority of the studies in this area find that over the whole population, there definitely is a gain in academic performance due to ability grouping [17, 39, 23, 24, 21, 9].", "startOffset": 167, "endOffset": 190}, {"referenceID": 22, "context": "Ability grouping: Majority of the studies in this area find that over the whole population, there definitely is a gain in academic performance due to ability grouping [17, 39, 23, 24, 21, 9].", "startOffset": 167, "endOffset": 190}, {"referenceID": 19, "context": "Ability grouping: Majority of the studies in this area find that over the whole population, there definitely is a gain in academic performance due to ability grouping [17, 39, 23, 24, 21, 9].", "startOffset": 167, "endOffset": 190}, {"referenceID": 7, "context": "Ability grouping: Majority of the studies in this area find that over the whole population, there definitely is a gain in academic performance due to ability grouping [17, 39, 23, 24, 21, 9].", "startOffset": 167, "endOffset": 190}, {"referenceID": 21, "context": "The benefits of grouping on students\u2019 attitude has also been studied in [23].", "startOffset": 72, "endOffset": 76}, {"referenceID": 31, "context": "This information will be lost over time when there is no attempt to retain it [33, 36, 19, 11, 1, 16, 15] Repetition in learning and spacing effect has been even studied in computer science in [32].", "startOffset": 78, "endOffset": 105}, {"referenceID": 34, "context": "This information will be lost over time when there is no attempt to retain it [33, 36, 19, 11, 1, 16, 15] Repetition in learning and spacing effect has been even studied in computer science in [32].", "startOffset": 78, "endOffset": 105}, {"referenceID": 17, "context": "This information will be lost over time when there is no attempt to retain it [33, 36, 19, 11, 1, 16, 15] Repetition in learning and spacing effect has been even studied in computer science in [32].", "startOffset": 78, "endOffset": 105}, {"referenceID": 9, "context": "This information will be lost over time when there is no attempt to retain it [33, 36, 19, 11, 1, 16, 15] Repetition in learning and spacing effect has been even studied in computer science in [32].", "startOffset": 78, "endOffset": 105}, {"referenceID": 0, "context": "This information will be lost over time when there is no attempt to retain it [33, 36, 19, 11, 1, 16, 15] Repetition in learning and spacing effect has been even studied in computer science in [32].", "startOffset": 78, "endOffset": 105}, {"referenceID": 14, "context": "This information will be lost over time when there is no attempt to retain it [33, 36, 19, 11, 1, 16, 15] Repetition in learning and spacing effect has been even studied in computer science in [32].", "startOffset": 78, "endOffset": 105}, {"referenceID": 13, "context": "This information will be lost over time when there is no attempt to retain it [33, 36, 19, 11, 1, 16, 15] Repetition in learning and spacing effect has been even studied in computer science in [32].", "startOffset": 78, "endOffset": 105}, {"referenceID": 30, "context": "This information will be lost over time when there is no attempt to retain it [33, 36, 19, 11, 1, 16, 15] Repetition in learning and spacing effect has been even studied in computer science in [32].", "startOffset": 193, "endOffset": 197}, {"referenceID": 5, "context": "Team formation: An earlier version of this study has appeared in [7].", "startOffset": 65, "endOffset": 68}, {"referenceID": 6, "context": "Team formation has been studied in operations research community [8, 13, 41, 42], which defines the problem as finding optimal match between people and demanded functional requirements.", "startOffset": 65, "endOffset": 80}, {"referenceID": 11, "context": "Team formation has been studied in operations research community [8, 13, 41, 42], which defines the problem as finding optimal match between people and demanded functional requirements.", "startOffset": 65, "endOffset": 80}, {"referenceID": 39, "context": "Team formation has been studied in operations research community [8, 13, 41, 42], which defines the problem as finding optimal match between people and demanded functional requirements.", "startOffset": 65, "endOffset": 80}, {"referenceID": 40, "context": "Team formation has been studied in operations research community [8, 13, 41, 42], which defines the problem as finding optimal match between people and demanded functional requirements.", "startOffset": 65, "endOffset": 80}, {"referenceID": 6, "context": "It is often solved using techniques such as simulated annealing, branch-and-cut or genetic algorithms [8, 41, 42].", "startOffset": 102, "endOffset": 113}, {"referenceID": 39, "context": "It is often solved using techniques such as simulated annealing, branch-and-cut or genetic algorithms [8, 41, 42].", "startOffset": 102, "endOffset": 113}, {"referenceID": 40, "context": "It is often solved using techniques such as simulated annealing, branch-and-cut or genetic algorithms [8, 41, 42].", "startOffset": 102, "endOffset": 113}, {"referenceID": 1, "context": "It has also been studied in computer science [2, 3, 20, 26, 30, 35, 4] Majority of these work focus on team formation to complete a task and minimize the communication cost among team members.", "startOffset": 45, "endOffset": 70}, {"referenceID": 2, "context": "It has also been studied in computer science [2, 3, 20, 26, 30, 35, 4] Majority of these work focus on team formation to complete a task and minimize the communication cost among team members.", "startOffset": 45, "endOffset": 70}, {"referenceID": 18, "context": "It has also been studied in computer science [2, 3, 20, 26, 30, 35, 4] Majority of these work focus on team formation to complete a task and minimize the communication cost among team members.", "startOffset": 45, "endOffset": 70}, {"referenceID": 24, "context": "It has also been studied in computer science [2, 3, 20, 26, 30, 35, 4] Majority of these work focus on team formation to complete a task and minimize the communication cost among team members.", "startOffset": 45, "endOffset": 70}, {"referenceID": 28, "context": "It has also been studied in computer science [2, 3, 20, 26, 30, 35, 4] Majority of these work focus on team formation to complete a task and minimize the communication cost among team members.", "startOffset": 45, "endOffset": 70}, {"referenceID": 33, "context": "It has also been studied in computer science [2, 3, 20, 26, 30, 35, 4] Majority of these work focus on team formation to complete a task and minimize the communication cost among team members.", "startOffset": 45, "endOffset": 70}, {"referenceID": 3, "context": "It has also been studied in computer science [2, 3, 20, 26, 30, 35, 4] Majority of these work focus on team formation to complete a task and minimize the communication cost among team members.", "startOffset": 45, "endOffset": 70}, {"referenceID": 1, "context": "[2] considers partitioning students in which each student has only one ability level for all the activities and each team has a set of leaders and followers.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "\u201d The fundamental basis of our work is the realization that repetition is an essential part of learning; engaging with a topic multiple times 1 deepens and hastens students\u2019 engagement and understanding processes [11, 40].", "startOffset": 213, "endOffset": 221}, {"referenceID": 38, "context": "\u201d The fundamental basis of our work is the realization that repetition is an essential part of learning; engaging with a topic multiple times 1 deepens and hastens students\u2019 engagement and understanding processes [11, 40].", "startOffset": 213, "endOffset": 221}, {"referenceID": 20, "context": "We reduce the catalog segmentation problem [22] to Cohort Selection problem.", "startOffset": 43, "endOffset": 47}, {"referenceID": 20, "context": "[22] that catalog segmentation is NP-hard.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Solving K_means problem [18] exactly is NP-hard.", "startOffset": 24, "endOffset": 28}, {"referenceID": 26, "context": "Lloyd\u2019s algorithm [28] solves this problem by choosing k centers randomly and assigning the points to the closest center.", "startOffset": 18, "endOffset": 22}], "year": 2017, "abstractText": "Whether teaching in a classroom or a Massive Online Open Course it is crucial to present the material in a way that benefits the audience as a whole. We identify two important tasks to solve towards this objective; (1.) group students so that they can maximally benefit from peer interaction and (2.) find an optimal schedule of the educational material for each group. Thus, in this paper, we solve the problem of team formation and content scheduling for education. Given a time frame d, a set of students S with their required need to learn different activities T and given k as the number of desired groups, we study the problem of finding k group of students. The goal is to teach students within time frame d such that their potential for learning is maximized and find the best schedule for each group. We show this problem to be NP-hard and develop a polynomial algorithm for it. We show our algorithm to be effective both on synthetic as well as a real data set. For our experiments, we use real data on students\u2019 grades in a Computer Science department. As part of our contribution, we release a semi-synthetic dataset that mimics the properties of the real data.", "creator": "LaTeX with hyperref package"}}}