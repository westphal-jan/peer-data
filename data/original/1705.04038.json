{"id": "1705.04038", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2017", "title": "Building a Semantic Role Labelling System for Vietnamese", "abstract": "Semantic role labelling (SRL) is a task in natural language processing which detects and classifies the semantic arguments associated with the predicates of a sentence. It is an important step towards understanding the meaning of a natural language. There exists SRL systems for well-studied languages like English, Chinese or Japanese but there is not any such system for the Vietnamese language. In this paper, we present the first SRL system for Vietnamese with encouraging accuracy. We first demonstrate that a simple application of SRL techniques developed for English could not give a good accuracy for Vietnamese. We then introduce a new algorithm for extracting candidate syntactic constituents, which is much more accurate than the common node-mapping algorithm usually used in the identification step. Finally, in the classification step, in addition to the common linguistic features, we propose novel and useful features for use in SRL. Our SRL system achieves an $F_1$ score of 73.53\\% on the Vietnamese PropBank corpus. This system, including software and corpus, is available as an open source project and we believe that it is a good baseline for the development of future Vietnamese SRL systems.", "histories": [["v1", "Thu, 11 May 2017 07:08:30 GMT  (82kb)", "http://arxiv.org/abs/1705.04038v1", "8 pages, ICDIM 2015"]], "COMMENTS": "8 pages, ICDIM 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["thai-hoang pham", "xuan-khoai pham", "phuong le-hong"], "accepted": false, "id": "1705.04038"}, "pdf": {"name": "1705.04038.pdf", "metadata": {"source": "CRF", "title": "Building a Semantic Role Labelling System for Vietnamese", "authors": ["Thai-Hoang Pham", "Phuong Le-Hong"], "emails": ["hoangpt@fpt.edu.vn", "khoaipxse02933@fpt.edu.vn", "phuonglh@vnu.edu.vn"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 5.\n04 03\n8v 1\n[ cs\n.C L\n] 1\n1 M\nay 2\n01 7\nI. INTRODUCTION\nSRL is the task of identifying semantic roles of predicates in the sentence. In particular, it answers a question Who did What to Whom, When, Where, Why?. A simple Vietnamese sentence Nam gi\u00fap Huy h\u1ecdc b\u00e0i v\u00e0o h\u00f4m qua (Nam helped Huy to do homework yesterday) is given in Figure 1.\nFigure 1: An example sentence\nNam Who giu\u0301p Huy\nWhom\nh\u1ecdc b\u00e0i\nWhat\nv\u00e0o h\u00f4m qua\nWhen\nTo assign semantic roles for the sentence above, we must analyse and label the propositions concerning the predicate gi\u00fap (helped) of the sentence. Figure 2 shows a result of the SRL for this example, where meaning of the labels will be described in detail in Section IV.\nSRL has been used in many natural language processing (NLP) applications such as question answering [1], machine translation [2], document summarization [3] and information extraction [4]. Therefore, SRL is an important task in NLP.\nThe first SRL system was developed by Gildea and Jurafsky [5]. This system was performed on the FrameNet corpus and was used for English. After that, SRL task has been widely researched by the NLP community. In particular, there have been two shared-tasks, CoNLL-2004 [6] and CoNLL2005 [7], focusing on SRL task for English. Most of the systems participating in these share-tasks treated this problem as a classification problem and applied some supervised machine learning techniques. In addition, there were some systems developed for other languages such as Chinese [8] or Japanese [9].\nIn this paper, we present the first SRL system for Vietnamese with encouraging accuracy. We first demonstrate that a simple application of SRL techniques developed for English or other languages could not give a good accuracy for Vietnamese. In particular, in the constituent identification step, the widely used 1-1 node-mapping algorithm for extracting argument candidates performs poorly on the Vietnamese dataset, having F1 score of 35.84%. We thus introduce a new algorithm for extracting candidates, which is much more accurate, achieving an F1 score of 83.63%.\nIn the classification step, in addition to the common linguistic features, we propose novel and useful features for use in SRL, including function tags and word clusters obtained by performing a Gaussian mixture analysis on the distributed representations of Vietnamese words. These features are employed in two statistical classification models, Maximum Entropy and Support Vector Machines, which are proved to be good at many classification problems.\nOur SRL system achieves an F1 score of 73.53% on the Vietnamese PropBank corpus. This system, including software and corpus, is available as an open source project and we believe that it is a good baseline for the development of future Vietnamese SRL systems.\nThe paper is structured as follows. Section II introduces briefly the SRL task and two well-known corpora for English. Section III describes the methodologies of some existing systems and of our system. Some difficulties of SRL for Vietnamese are also discussed. Section IV presents the evaluation results and discussion. Finally, Section V concludes the paper and suggests some directions for future work."}, {"heading": "II. BACKGROUND", "text": ""}, {"heading": "A. SRL Task Description", "text": "The SRL task is usually divided into two steps. The first step is argument identification. The goal of this step is to\nFigure 3: Example of identification task\nNam giu\u0301p Huy h\u1ecdc b\u00e0i v\u00e0o h\u00f4m qua\nidentify the syntactic constituents of a sentence which are the most likely to be semantic arguments of its predicates. This is a difficult problem since the number of constituent candidates is exponentially large, especially for long sentences.\nThe second step is argument classification which decides the exact semantic role for each constituent candidate identified in the first task. For example, the identification step of the sentence in the previous example Nam gi\u00fap Huy h\u1ecdc b\u00e0i v\u00e0o h\u00f4m qua is described in Figure 3 and in the classification task, semantic roles are labelled as shown Figure 2."}, {"heading": "B. Existing Corpora for SRL", "text": "1) FrameNet: The FrameNet project is a lexical database of English. It was built by annotating examples of how words are used in actual texts. It consists of more than 10,000 word senses, most of them with annotated examples that show the meaning and usage and more than 170,000 manually annotated sentences [10]. This is the most widely used dataset upon which SRL systems for English have been developed and tested.\nFrameNet is based on the Frame Semantics theory [11]. The basic idea is that the meanings of most words can be best understood on the basis of a semantic frame: a description of a type of event, relation, or entity and the participants in it. All members in semantic frames are called frame elements. For example, a sentence in FrameNet is annotated in cooking concept as shown in Figure 4.\n2) PropBank: PropBank is a corpus that is annotated with verbal propositions and their arguments [12]. PropBank tries to supply a general purpose labelling of semantic roles for a large corpus to support the training of automatic semantic role labelling systems. However, defining such a universal set of semantic roles for all types of predicates is a difficult task; therefore, only Arg0 and Arg1 semantic roles can be generalized. In addition to the core roles, PropBank defines several adjunct roles that can apply to any verb. It is called Argument Modifier. The semantic roles covered by the PropBank are the following:\n\u2022 Core Arguments (Arg0-Arg5, ArgA): Arguments define predicate specific roles. Their semantics depend on predicates in the sentence.\n\u2022 Adjunct Arguments (ArgM-): General arguments that can belong to any predicate. There are 13 types of adjuncts.\n\u2022 Reference Arguments (R-): Arguments represent arguments realized in other parts of the sentence.\nFor example, the sentence of Figure 4 can be annotated in the PropBank role schema as shown in Figure 5."}, {"heading": "III. METHODOLOGY", "text": ""}, {"heading": "A. Existing Approaches", "text": "This section summarizes existing approaches used by typical SRL systems for well-studied languages. We describe these systems by investigating two aspects, namely data type that the systems use and their strategies for labelling semantic roles, including model types, labelling strategies and degrees of granularity.\n1) Data Types: There are some kinds of data used in the training of SRL systems. Some systems use bracketed trees as the input data. A bracketed tree of a sentence is the tree of nested constituents representing its constituency structure. Some systems use dependency trees of a sentence, which represents dependencies between individual words of a sentence. The syntactic dependency represents the fact that the presence of a word is licensed by another word which is its governor. In a typed dependency analysis, grammatical labels are added to the dependencies to mark their grammatical relations, for example nominal subject (nsubj) or direct object (dobj). Figure 6 shows the bracketed tree and the dependency tree of an example sentence.\na) Model Types: There are two types of classification models: Independent Model and Joint Model. While independent model decides the label of each argument\u2019s candidate independently of other candidates, joint model finds the best overall labelling for all candidates in the sentence. Independent model runs fast but are prone to inconsistencies. For example, Figure 7 shows some typical inconsistencies, including overlapping arguments, repeating arguments and missing arguments of a sentence Do h\u1ecdc ch\u0103m, Nam \u0111\u00e3 \u0111\u1ea1t th\u00e0nh t\u00edch cao (By studying hard, Nam got a high achievement).\nb) Labelling Stategies: Strategies for labelling semantic roles are diverse, but we can summarize that there are three main strategies. Most of the systems use a two-step approach consisting of identification and classification [13], [14]. The first step identifies arguments from many candidates. It is essentially a binary classification problem. The second step classifies these arguments into particular semantic roles. Some systems use single classification step by adding a \u201cnull\u201d label into semantic roles, denoting that this is not an argument [15]. Other systems consider SRL as a sequence tagging [16], [17].\nc) Granularity: Existing SRL systems use different degrees of granularity when considering constituents. Some systems use individual words as their input and perform sequence tagging to identify arguments. This method is called Word-by-Word (W-by-W) approach. Other systems directly take syntactic phrases as input constituents. This method is called Constituent-by-Constituent (C-by-C) approach.\nCompared to the W-by-W approach, C-by-C approach has several advantages. First, phrase boundaries are usually consistent with argument boundaries. Second, C-by-C approach allows us to work with larger contexts due to a smaller number of candidates in comparison to the W-by-W approach."}, {"heading": "B. Our Approach", "text": "The previous subsection has reviewed existing techniques for SRL which have been published so far for well-studied languages. In this section, we first show that these techniques per se cannot give a good result for Vietnamese SRL, due to some inherent difficulties, both in terms of language characteristics and of the available corpus. We then develop a new algorithm for extracting candidate constituents for use in the identification step.\nSome difficulties of Vietnamese SRL are related to its SRL corpus. We use the Vietnamese PropBank [18] in the\ndevelopment of our SRL system.1 This SRL corpus has 5,000 annotated sentences, which is much smaller than SRL corpora of other languages. For example, the English PropBank contains about 50,000 sentences, which is ten times larger. While smaller in size, the Vietnamese PropBank has more semantic roles than the English PropBank has \u2013 25 roles compared to 21 roles. This makes the unavoidable data sparseness problem more severe for Vienamese SRL than for English SRL.\nIn addition, our extensive inspection and experiments on the Vietnamese PropBank have uncovered that this corpus has many annotation errors, largely due to encoding problems and inconsistencies in annotation. In many cases, we have to fix these annotation errors by ourselves. In other cases where only a proposition of a complex sentence is incorrectly annotated, we perform an automatic preprocessing procedure to drop it out, leave the correctly annotated propositions untouched. We finally come up with a corpus of 4,800 sentences which are semantic role annotated. This corpus will be released for free use for research purpose.\nA major difficulty of Vietnamese SRL is due to the nature of the language, where its linguistic characteristics are different from occidental languages [19]. We first try to apply the common node-mapping algorithm which are widely used in English SRL systems to the Vietnamese corpus. However, this application gives us a very poor performance. Therefore, in the identification step, we develop a new algorithm for extracting candidate constituents which is much more accurate for Vietnamese than the node-mapping algorithm. Details of experimental results will be provided in the Section IV\nIn order to improve the accuracy of the classification step, and hence of our SRL system as a whole, we have integrated many useful features for use in two statistical classification models, namely Maximum Entropy (ME) and Support Vector Machines (SVM). On the one hand, we adapt the features which have been proved to be good for SRL of English. On the other hand, we propose some novel features, including function tags and word clusters.\nIn the next paragraph, we present our constituent extraction algorithm for the identification step. Details of the features for use in the classification step will be presented in Section IV.\n1) Constituent Extraction Algorithm: This algorithm aims to extract constituents from a bracketed tree which are associated to their corresponding predicates of the sentence. If the sentence has multiple predicates, multiple constituent sets corresponding to the predicates are extracted. Pseudo code of the algorithm is described in Algorithm 1.\nThis algorithm uses several simple functions. The root() function gets the root of a tree. The children() function gets the children of a node. The sibling() function gets the sisters of a node. The isPhrase() function checks whether a node is of phrasal type or not. The phraseType() function and functionTag() function extracts the phrase type and function tag of a node, respectively. Finally, the collect(node) function collects words from leaves of the subtree rooted at a node and creates a constituent.\n1To our knowledge, this is the first SRL corpus for Vietnamese which has been published for free research.\nAlgorithm 1: Constituent Extraction Algorithm\ninput : A bracketed tree T and its predicate output : A tree with constituents for the predicate begin currentNode \u2190 predicateNode while currentNode 6= T.root() do\nfor S \u2208 currentNode.sibling() do if |S.children()| > 1 and S.children().get(0).isPhrase() then\nsameType \u2190 true diffTag \u2190 true phraseType \u2190 S.children().get(0).phraseType() funcTag \u2190 S.children().get(0).functionTag() for i \u2190 1 to |S.children()| \u2212 1 do if S.children().get(i).phraseType() 6= phraseType then\nsameType \u2190 false break\nif S.children().get(i).functionTag() = funcTag then\ndiffTag \u2190 false break\nif sameType and diffTag then for child \u2208 S.children() do\nT.collect(child)\nelse T.collect(S)\ncurrentNode \u2190 currentNode.parent()\nreturn T\nFigure 8 shows an example of running the algorithm on a sentence B\u00e0 n\u00f3i n\u00f3 l\u00e0 con trai t\u00f4i m\u00e0 (She said that he is my son). First, we find the current predicate node V-H l\u00e0 (is). The current node has only one sibling NP. This node has one child, so its associated words are collected. After that, we set current node to its parent and repeat the process until reaching the root of the tree. Finally, we obtain a tree with constituents: B\u00e0, n\u00f3i, n\u00f3, and con trai t\u00f4i m\u00e0.\n2) Our SRL System: Our SRL system is developed on the Vietnamese PropBank. It thus operates on fully bracketed trees. We employ ME and SVM as classifiers. Its classification model is of type independent and its input are C-by-C."}, {"heading": "IV. EXPERIMENT", "text": "In this section, we first introduce the Vietnamese PropBank upon which our SRL system has been trained and tested. We then propose two feature sets in use. Finally, we present and discuss experimental results."}, {"heading": "A. Dataset", "text": "We conduct experiments on the Vietnamese PropBank [18] containing about 5,460 sentences which are manually anno-\ntated with semantic roles. This corpus has a similar annotation schema to the English PropBank. Due to some inconsistency annotation errors of the corpus, notably in many complex sentences, we were not able to use all the corpus in our experiments. We focus ourselves in simple sentences which have only one predicate rather than complex sentences with multiple predicates. After extracting sentences, we have a corpus of about 4,860 simple sentences which are annotated with semantic roles.\nThe semantic roles covered by the Vietnamese PropBank are the following:\n\u2022 Core Arguments (Arg0-Arg4): Arguments define predicate specific roles. These core arguments are similar to those of the English PropBank, however, there are 5 roles instead of 7, compared to the English PropBank.\n\u2022 Adjunct Arguments (ArgM-): There are 20 types of adjuncts, as listed in Table I.\n\u2022 Predicate (V): In Vietnamese, a predicate is not only a verb, but it could be also a noun, an adjective or a preposition."}, {"heading": "B. Feature Sets", "text": "We use two feature sets in this study. The first one is composed of basic features which are commonly used in SRL system for English. This feature set is used in the SRL system of Gildea and Jurafsky on the FrameNet corpus [5].\n1) Basic Feature Set: This feature set consists of 6 feature templates, as follows:\n1) Phrase Type: This is very useful feature in classifying semantic roles because different roles tend to have different syntactic categories. For example, in the sentence in Figure 8 B\u00e0 n\u00f3i n\u00f3 l\u00e0 con trai t\u00f4i m\u00e0, the phrase type of constituent n\u00f3 is NP. 2) Parse Tree Path: This feature captures the syntactic relation between a constituent and a predicate in a bracketed tree. This is the shortest path from a constituent node to a predicate node in the tree. We use either symbol \u2191 or symbol \u2193 to indicate the upward direction or the downward direction, respectively. For example, the parse tree path from constituent n\u00f3 to the predicate l\u00e0 is NP\u2191S\u2193VP\u2193V. 3) Position: Position is a binary feature that describes whether the constituent occurs after or before the predicate. It takes value 0 if the constituent appears before the predicate in the sentence or value 1 otherwise. For example, the position of constituent n\u00f3 in Figure 8 is 0 since it appears before predicate l\u00e0. 4) Voice: Sometimes, the differentiation between active and passive voice is useful. For example, in an active sentence, the subject is usually an Arg0 while in a passive sentence, it is often an Arg1. Voice feature is also binary feature, taking value 1 for active voice or 0 for passive voice. The sentence in Figure 8 is of active voice, thus its voice feature value is 1. 5) Head Word: This is the first word of a phrase. For example, the head word for the phrase con trai t\u00f4i m\u00e0 is con trai. 6) Subcategorization: Subcategorization feature captures the tree that has the concerned predicate as its child. For example, in Figure 8, the subcategorization of the predicate l\u00e0 is VP(V, NP).\n2) Modified Features and New Features: Preliminary investigations on the basic feature set give us a rather poor result. Therefore, we propose some modified features and novel features so as to improve the accuracy of the system. These features are as follows:\n1) Function Tag: Function tag is a useful information, especially for classifying adjunct arguments. It determines a constituent\u2019s role, for example, the function tag of constituent n\u00f3 is SUB, indicating that this has a subjective role. 2) Partial Parse Tree Path: Many sentences have complicated structure. It can make parse tree path very long and infrequent. We propose to cut a path from"}, {"heading": "C. Results and Discussions", "text": "1) Evaluation Method: We use a 10-fold cross-validation method to evaluate our system. The final accuracy scores is the average scores of the 10 runs.\nThe evaluation metrics are the precision, recall and F1measure. The precision (P ) is the proportion of labelled arguments identified by the system which are correct; the recall (R) is the proportion of labelled arguments in the gold results which are correctly identified by the system; and the F1-measure is the harmonic mean of P and R, that is F1 = 2PR/(P +R).\n2) Baseline System: In the first experiment, we compare our constituent extraction algorithm to the 1-1 node mapping algorithm. Table II shows the performance of two extraction algorithms.\nWe see that our extraction algorithm outperforms significantly the 1-1 node mapping algorithm, in both of the precision and the recall ratios. In particular, the precision of the 1-1 node mapping algorithm is only 29.53%; this means that this method captures many candidates which are not arguments. In contrast, our algorithm is able to identify a large number of\n2Actually, there is an additional group for unknown words.\ncorrect argument candidates, particularly with the recall ratio of 86.43%. This result clearly demonstrates that we cannot take for granted that a good algorithm for English could also work well for another language of different characteristics.\nIn the second experiment, we continue to compare the performance of the two extraction algorithms, this time at the final classification step and get the baseline for Vietnamese SRL. The classifier we use in this experiment is a Maximum Entropy classifier.3 Table III shows the accuracy of the baseline system.\nOne again, this result confirms that our algorithm is much superior than the 1-1 node mapping algorithm. The F1 of our baseline SRL system is 50.45%, compared to 6.20% of the 1-1 node mapping system. This result can be explained by the fact that the 1-1 node mapping algorithm has a very low recall ratio, because it identifies incorrectly many argument candidates.\n3) Labelling Strategy: In the third experiment, we compare two labelling strategies for Vietnamese SRL (cf. Section III). In addition to the ME classifier, we also try the Support Vector Machine (SVM) classifier, which usually gives good accuracy in a wide variety of classification problems.4 Table IV shows the F1 scores of different labelling strategies.\nWe see that the SVM classifier outperforms ME the classifier by a large margin. The best accuracy is obtained by using 1-step stragegy with SVM classifier. The current SRL system achieves an F1 score of 68.91%.\n4) Feature Analysis: In the fourth experiment, we analyse and evaluate the impact of each individual feature to the accuracy of our system so as to find the best feature set for our Vietnamese SRL system. We start with the basic feature set presented previously, denoted by \u03a60 and augment it with modified and new features as shown in Table V. The accuracy of these feature sets are shown in Table VI.\n3We use the logistic regression classifier with L2 regularization provided by the scikit-learn software package. The regularization term is fixed at 1.\n4We use a linear SVM provided in the scikit-learn software package with default parameter values.\nWe notice that amongst the three features, function tag is the most important feature which increases the accuracy of the baseline feature set by about 4% of F1 score. The distance feature also helps increase slightly the accuracy. We thus consider the fourth feature set \u03a64 defined as\n\u03a64 = \u03a60 \u222a {Function Tag} \u222a {Distance}.\nIn the fifth experiment, we modify the feature set \u03a64 by replacing the predicate with its cluster and similarly, replacing the head word with its cluster, replacing the full path with its partial path, resulting in feature sets \u03a65, \u03a66, and \u03a67 respectively (see Table VII). The accuracy of these feature sets are shown in Table VIII.\nWe observe that using the predicate cluster instead of the predicate itself helps improve the accuracy of the system by about 0.47% of F1 score. For ease of later presentation, we rename the feature set \u03a65 as \u03a68.\nIn the sixth experiment, we investigate the significance of individual features to the system by removing them, one by one from the feature set \u03a68. By doing this, we can evaluate the importance of each feature to our overall system. The feature sets and their corresponding accuracy are presented in Table IX and Table X respectively.\nWe see that the accuracy increases slightly when either the predicate cluster feature (\u03a610) or the subcategorization feature (\u03a615) is removed. However, removing both of the two features (\u03a616) makes the accuracy decrease. For this reason, we remove only the subcategorization feature. The best feature set includes the following features: predicate cluster, phrase type, function tag, parse tree path, distance, voice, position and head word. The best accuracy of our system is 73.53% of F1 score.\n5) Learning Curve: In the last experiment, we investigate the dependence of accuracy to the size of the training dataset. Figure 9 depicts the learning curve of our system when the data size is varied.\nIt seems that the accuracy of our system improves only slightly starting from the dataset of about 2,000 sentences. Nevertheless, the curve has not converged, indicating that the system could achieve a better accuracy when a larger dataset is available."}, {"heading": "V. CONCLUSION", "text": "In this paper, we have presented the first system for Vietnamese semantic role labelling. Our system achieves a good accuracy of about 73.5% of F1 score in the Vietnamese PropBank.\nWe have argued that one cannot assume a good applicability of existing methods and tools developed for English and other Western languages and that they may not offer a cross-language validity. For an isolating language such as Vietnamese, techniques developed for inflectional languages cannot be applied \u201cas is\u201d. In particular, we have developed an algorithm for extracting argument candidates which has a better accuracy than the 1-1 node mapping algorithm. We have proposed some novel features which are proved to be useful for Vietnamese SRL, notably predicate clusters and function tags. Our SRL system, including software and corpus, is available as an open source project for free research purpose and we believe that it is a good baseline for the development and comparison of future Vietnamese SRL systems.\nIn the future, we plan to improve further our system, in the one hand, by enlarging our corpus so as to provide more data for the system. On the other hand, we would like to investigate different models used in SRL, for example joint models [14] and recent inference techniques, such as integer linear programming [22], [23]."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This work was supported by Vietnam National Foundation for Science and Technology Development (NAFOSTED Project No. 102.05-2014.28). We would also like to thank the FPT Technology Research Institute for providing us the corpora for use in the experiments."}], "references": [{"title": "Using semantic roles to improve question answering", "author": ["D. Shen", "M. Lapata"], "venue": "Proceedings of Conference on Empirical Methods on Natural Language Processing and Computational Natural Language Learning, Prague, Czech Republic, 2007, pp. 12\u201321.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Evaluating machine translation utility via semantic role labels.", "author": ["C. kiu Lo", "D. Wu"], "venue": "Proceedings of The International Conference on Language Resources and Evaluation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Semantic argument frequency-based multi-document summarization", "author": ["C. Aksoy", "A. Bugdayci", "T. Gur", "I. Uysal", "F. Can"], "venue": "Proceedings of the 24th of the International Symposium on Computer and Information Sciences, Guzelyurt, Turkey, 2009, pp. 460\u2013464.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Semantic role labeling for open information extraction", "author": ["J. Christensen", "S. Soderland", "O. Etzioni"], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics \u2013 Human Language Technologies, Los Angeles, CA, USA, 2010, pp. 52\u201360.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Automatic labeling of semantic roles", "author": ["D. Gildea", "D. Jurafsky"], "venue": "Computational Linguistics, vol. 28, no. 3, pp. 245\u2013288, 2002.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2002}, {"title": "Introduction to the CoNLL-2004 shared task: semantic role labeling", "author": ["X. Carreras", "L. M\u00e0rquez"], "venue": "Proceedings of the 8th Conference on Computational Natural Language Learning, Boston, MA, USA, 2004.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2004}, {"title": "Introduction to the CoNLL-2005 shared task: semantic role labeling", "author": ["\u2014\u2014"], "venue": "Proceedings of the 9th Conference on Computational Natural Language Learning, Ann Arbor, MI, USA, 2005, pp. 152\u2013164.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Automatic semantic role labeling for Chinese verbs", "author": ["N. Xue", "M. Palmer"], "venue": "Proceedings of International Joint Conferences on Artificial Intelligence, Edinburgh, Scotland, UK, 2005, pp. 1160\u20131165.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Automatic semantic role labeling based on Japanese FrameNet\u2013A Progress Report", "author": ["H. Tagami", "S. Hizuka", "H. Saito"], "venue": "Proceedings of Conference of the Pacific Association for Computational Linguistics, Hokkaido University, Sapporo, Japan, 2009, pp. 181\u2013186.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "The structure of the FrameNet database", "author": ["C.F. Baker", "C.J. Fillmore", "B. Cronin"], "venue": "International Journal of Lexicography, vol. 16, no. 3, pp. 281\u2013296, 2003.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "From theory to practice: Frame semantics and the design of Framenet", "author": ["H.C. Boas"], "venue": "Semantisches Wissen im Lexikon. T\u00fcbingen: Narr., 2005, pp. 129\u2013160.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "PropBank annotation guidelines", "author": ["O. Babko-Malaya"], "venue": "Colorado University, Tech. Rep., 2005.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Generalized inference with multiple semantic role labeling systems", "author": ["P. Koomen", "V. Punyakanok", "D. Roth", "W. tau Yih"], "venue": "Proceedings of the 9th Conference on Computational Natural Language Learning, Ann Arbor, MI, USA, 2005, pp. 181\u2013184.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "A joint model for semantic role labeling", "author": ["A. Haghighi", "K. Toutanova", "C.D. Manning"], "venue": "Proceedings of the 9th Conference on Computational Natural Language Learning, Ann Arbor, MI, USA, 2005, pp. 173\u2013176.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2005}, {"title": "Semantic role labeling using complete syntactic analysis", "author": ["M. Surdeanu", "J. Turmo"], "venue": "Proceedings of the 9th Conference on Computational Natural Language Learning, Ann Arbor, MI, USA, 2005, pp. 221\u2013224.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2005}, {"title": "Semantic role labeling as sequential tagging", "author": ["L. M\u00e0rquez", "P. Comas", "J. Gim\u00e9nez", "N. Catala"], "venue": "Proceedings of the 9th Conference on Computational Natural Language Learning, Ann Arbor, MI, USA, 2005, pp. 193\u2013196.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Semantic role chunking combining complementary syntactic views", "author": ["S. Pradhan", "K. Hacioglu", "W. Ward", "J.H. Martin", "D. Jurafsky"], "venue": "Proceedings of the 9th Conference on Computational Natural Language Learning, Ann Arbor, MI, USA, 2005, pp. 217\u2013220.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Building a semantic role annotated corpus for Vietnamese", "author": ["T.-L.N. My-Linh Ha", "V.-H. Nguyen", "T.-M.-H. Nguyen", "P. Le-Hong", "T.-H. Phan"], "venue": "Proceedings of the 17th National Symposium on Information and Communication Technology, Daklak, Vietnam, 2014, pp. 409\u2013414.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "A syntactic component for Vietnamese language processing", "author": ["P. Le-Hong", "A. Roussanaly", "T.-M.-H. Nguyen"], "venue": "Journal of Language Modelling, vol. 3, no. 1, pp. 145\u2013184, 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "Proceedings of Workshop at ICLR, Scottsdale, Arizona, USA, 2013.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in Neural Information Processing Systems 26, C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Weinberger, Eds. Curran Associates, Inc., 2013, pp. 3111\u20133119.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Efficient inference and structured learning for semantic role labeling", "author": ["O. T\u00e4ckstr\u00f6m", "K. Ganchev", "D. Das"], "venue": "Transactions of the Association for Computational Linguistics, vol. 3, pp. 29\u201341, 2015.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Semantic role labeling via integer linear programming inference", "author": ["V. Punyakanok", "D. Roth", "W. tau Yih", "D. Zimak"], "venue": "Proceedings of the 20th International Conference on Computational Linguistics, University of Geneva, Switzerland, 2004, pp. 1346\u20131352.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "SRL has been used in many natural language processing (NLP) applications such as question answering [1], machine translation [2], document summarization [3] and information extraction [4].", "startOffset": 100, "endOffset": 103}, {"referenceID": 1, "context": "SRL has been used in many natural language processing (NLP) applications such as question answering [1], machine translation [2], document summarization [3] and information extraction [4].", "startOffset": 125, "endOffset": 128}, {"referenceID": 2, "context": "SRL has been used in many natural language processing (NLP) applications such as question answering [1], machine translation [2], document summarization [3] and information extraction [4].", "startOffset": 153, "endOffset": 156}, {"referenceID": 3, "context": "SRL has been used in many natural language processing (NLP) applications such as question answering [1], machine translation [2], document summarization [3] and information extraction [4].", "startOffset": 184, "endOffset": 187}, {"referenceID": 4, "context": "The first SRL system was developed by Gildea and Jurafsky [5].", "startOffset": 58, "endOffset": 61}, {"referenceID": 5, "context": "In particular, there have been two shared-tasks, CoNLL-2004 [6] and CoNLL2005 [7], focusing on SRL task for English.", "startOffset": 60, "endOffset": 63}, {"referenceID": 6, "context": "In particular, there have been two shared-tasks, CoNLL-2004 [6] and CoNLL2005 [7], focusing on SRL task for English.", "startOffset": 78, "endOffset": 81}, {"referenceID": 7, "context": "In addition, there were some systems developed for other languages such as Chinese [8] or Japanese [9].", "startOffset": 83, "endOffset": 86}, {"referenceID": 8, "context": "In addition, there were some systems developed for other languages such as Chinese [8] or Japanese [9].", "startOffset": 99, "endOffset": 102}, {"referenceID": 9, "context": "It consists of more than 10,000 word senses, most of them with annotated examples that show the meaning and usage and more than 170,000 manually annotated sentences [10].", "startOffset": 165, "endOffset": 169}, {"referenceID": 10, "context": "FrameNet is based on the Frame Semantics theory [11].", "startOffset": 48, "endOffset": 52}, {"referenceID": 11, "context": "2) PropBank: PropBank is a corpus that is annotated with verbal propositions and their arguments [12].", "startOffset": 97, "endOffset": 101}, {"referenceID": 12, "context": "Most of the systems use a two-step approach consisting of identification and classification [13], [14].", "startOffset": 92, "endOffset": 96}, {"referenceID": 13, "context": "Most of the systems use a two-step approach consisting of identification and classification [13], [14].", "startOffset": 98, "endOffset": 102}, {"referenceID": 14, "context": "Some systems use single classification step by adding a \u201cnull\u201d label into semantic roles, denoting that this is not an argument [15].", "startOffset": 128, "endOffset": 132}, {"referenceID": 15, "context": "Other systems consider SRL as a sequence tagging [16], [17].", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "Other systems consider SRL as a sequence tagging [16], [17].", "startOffset": 55, "endOffset": 59}, {"referenceID": 17, "context": "We use the Vietnamese PropBank [18] in the development of our SRL system.", "startOffset": 31, "endOffset": 35}, {"referenceID": 18, "context": "A major difficulty of Vietnamese SRL is due to the nature of the language, where its linguistic characteristics are different from occidental languages [19].", "startOffset": 152, "endOffset": 156}, {"referenceID": 17, "context": "Dataset We conduct experiments on the Vietnamese PropBank [18] containing about 5,460 sentences which are manually annoFigure 8: Extracting constituents of the sentence \u201cB\u00e0 n\u00f3i n\u00f3 l\u00e0 con trai t\u00f4i m\u00e0\u201d at predicate \u201cl\u00e0\u201d", "startOffset": 58, "endOffset": 62}, {"referenceID": 4, "context": "This feature set is used in the SRL system of Gildea and Jurafsky on the FrameNet corpus [5].", "startOffset": 89, "endOffset": 92}, {"referenceID": 19, "context": "We first produce distributed word representations (or word embeddings) of Vietnamese words, where each word is represented by a dense, real-valued vector of 50 dimensions, by using a Skipgram model described in [20], [21].", "startOffset": 211, "endOffset": 215}, {"referenceID": 20, "context": "We first produce distributed word representations (or word embeddings) of Vietnamese words, where each word is represented by a dense, real-valued vector of 50 dimensions, by using a Skipgram model described in [20], [21].", "startOffset": 217, "endOffset": 221}, {"referenceID": 13, "context": "On the other hand, we would like to investigate different models used in SRL, for example joint models [14] and recent inference techniques, such as integer linear programming [22], [23].", "startOffset": 103, "endOffset": 107}, {"referenceID": 21, "context": "On the other hand, we would like to investigate different models used in SRL, for example joint models [14] and recent inference techniques, such as integer linear programming [22], [23].", "startOffset": 176, "endOffset": 180}, {"referenceID": 22, "context": "On the other hand, we would like to investigate different models used in SRL, for example joint models [14] and recent inference techniques, such as integer linear programming [22], [23].", "startOffset": 182, "endOffset": 186}], "year": 2017, "abstractText": "Semantic role labelling (SRL) is a task in natural language processing which detects and classifies the semantic arguments associated with the predicates of a sentence. It is an important step towards understanding the meaning of a natural language. There exists SRL systems for well-studied languages like English, Chinese or Japanese but there is not any such system for the Vietnamese language. In this paper, we present the first SRL system for Vietnamese with encouraging accuracy. We first demonstrate that a simple application of SRL techniques developed for English could not give a good accuracy for Vietnamese. We then introduce a new algorithm for extracting candidate syntactic constituents, which is much more accurate than the common node-mapping algorithm usually used in the identification step. Finally, in the classification step, in addition to the common linguistic features, we propose novel and useful features for use in SRL. Our SRL system achieves an F1 score of 73.53% on the Vietnamese PropBank corpus. This system, including software and corpus, is available as an open source project and we believe that it is a good baseline for the development of future Vietnamese SRL systems.", "creator": "LaTeX with hyperref package"}}}