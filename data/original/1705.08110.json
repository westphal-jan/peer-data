{"id": "1705.08110", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2017", "title": "Semi-Bandits with Knapsacks", "abstract": "This paper unifies two lines of work on multi-armed bandits, Bandits with Knapsacks (BwK) and semi-bandits. The former concerns scenarios with limited \"resources\" consumed by the algorithm, e.g., limited inventory in a dynamic pricing problem. The latter has a huge number of actions, but there is combinatorial structure and additional feedback which makes the problem tractable. Both lines of work has received considerable recent attention, and are supported by numerous application examples. We define a common generalization, and design a general algorithm for this model. Our regret rates are comparable with those for BwK and semi-bandits in general, and essentially optimal for important special cases.", "histories": [["v1", "Tue, 23 May 2017 07:46:32 GMT  (46kb)", "http://arxiv.org/abs/1705.08110v1", null], ["v2", "Mon, 16 Oct 2017 01:53:46 GMT  (1525kb,D)", "http://arxiv.org/abs/1705.08110v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["karthik abinav sankararaman", "aleksandrs slivkins"], "accepted": false, "id": "1705.08110"}, "pdf": {"name": "1705.08110.pdf", "metadata": {"source": "CRF", "title": "Semi-Bandits with Knapsacks", "authors": ["Karthik Abinav Sankararaman"], "emails": ["kabinav@cs.umd.edu", "slivkins@microsoft.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 5.\n08 11\n0v 1\n[ cs\n.L G\n] 2\n3 M\nay 2"}, {"heading": "1 Introduction", "text": "Multi-armed bandits (MAB) is an elegant model for studying the tradeoff between acquisition and usage of information, a.k.a. explore-exploit tradeoff. In each round an algorithm sequentially chooses from a fixed set of alternatives (a.k.a. actions, a.k.a. arms), and receives reward for the chosen action. Crucially, the algorithm does not have enough information to answer all \u201ccounterfactual\" questions about what would have happened if a different action were chosen in this round. MAB problems have been studied steadily since 1930-ies, with a huge surge of interest in the last decade. The work on MAB progresses across several directions, such as: what auxiliary information, if any, is revealed to the algorithm before or after it needs to make a decision, which \u201cprocess\" are the rewards coming from, do they have some known structure that can be leveraged, are there global constraints on the algorithm, etc. Many of these directions gave rise to prominent lines of work.\nThis paper unifies two lines of work on MAB: Bandits with Knapsacks (BwK) and semi-bandits. The former concerns scenarios when there are limited \u201cresources\" consumed by the algorithm, e.g., limited inventory in a dynamic pricing problem. In the latter, there may be a huge number of actions, but there is structure which makes the problem tractable. Namely, actions correspond to subsets of some \u201cground set\", rewards are additive across the elements of this ground set (atoms), and the reward for each chosen atom is revealed after each round. This happens, e.g., in an online routing problem, where each action is a path in a graph, i.e., a (feasible) subset of edges. Both lines of work has received considerable recent attention, and are supported by numerous application examples.\nOur contributions. We define a common generalization of the semi-bandits and BwK, termed SemiBandits with Knapsacks (SemiBwK). Following all prior work on BwK, we focus on an i.i.d. environment: in each round, the \u201coutcome\" is drawn independently from a fixed distribution over the possible outcomes. Here the \u201coutcome\" of a round is the matrix of reward and resource consumption for all atoms. Note that our model allows arbitrary correlations within a given round, both across rewards and consumption for the same atom and across multiple atoms. We design an algorithm for SemiBwK, achieving regret rates that are comparable with those for BwK and semi-bandits, and are near-optimal for important special cases.\nSpecifics are as follows. As usual, we assume \u201cbounded outcomes\": for each atom and each round, rewards and consumption of each resource is at most 1. Regret is relative to OPT, the expected\ntotal reward of the best all-knowing policy. For BwK problems,OPT is known to be a much stronger benchmark than the traditional best-fixed-arm benchmark. We upper-bound regret in terms of relevant parameters: time horizon T , (smallest) budget B, number of atoms n, and OPT itself. We obtain\nRegret \u2264 O\u0303( \u221a n)(OPT / \u221a B + \u221a T +OPT). (1.1)\nThis regret bound is optimal up to polylog factors for paradigmatic special cases of BwK and semibandits: for BwK with OPT > \u2126(T ) [11] and for semi-bandits when each feasible action corresponds to a subset of size k \u2264 n (and hence OPT \u2264 kT ) [32]. The \u201cshape\" of the regret bound is consistent with prior work: theOPT / \u221a B additive term appears in the optimal regret bound for BwK, and the \u221a T and \u221a OPT additive terms are very common in regret bounds for MAB. The per-round running time is polynomial in n, and near-linear in n for some important special cases.\nOur main result holds under assumption that the action set, i.e., the family of feasible subsets of atoms, is described by a matroid constraint. This is a rather general scenario which includes many paradigmatic special cases of semi-bandits such as cardinality constraints, partition matroid constraints, path constraints, and spanning tree constraints. We also assume that B > \u2126\u0303(n+ \u221a nT ).\nIn addition to the main result, we provide an extension to \u201clinearizable constraints\", under a somewhat restrictive assumption that each resource can be consumed by at most one atom. Further, we identify and work out several notable examples to illustrate the generality of our model.\nChallenges and techniques. BwK problems are challenging compared to traditional MAB problems with i.i.d. rewards because it no longer suffices to look for the best action and/or optimize expected per-round rewards; instead, one essentially needs to look for a distribution over actions with optimal expected total reward across all rounds. Generic challenges in semi-bandits concern handling exponentially many actions (both in terms of regret and in terms of the running time), and taking advantage of the additional feedback. And in SemiBwK, one needs to deal with distributions over subsets of atoms, rather than \u201cjust\" with distributions over actions.\nWe combine a technique from prior work on BwK with another existing technique which addresses the combinatorial aspect of the problem. More precisely, we zeroed in on one of five (!) existing techniques for BwK, and made a non-obvious connection to a randomized rounding technique from a very different problem space, approximation algorithms for combinatorial optimization.\nWe build on a BwK algorithm from [2], which combines linear relaxations and a well-known \"optimism-under-uncertainty\" paradigm. A generalization of this algorithm to SemiBwK results in a fractional solution x \u2014 a vector over the atoms \u2014 which needs to be converted to a feasible subset of atoms (or, more realistically, a distribution over feasible subsets). This is where randomized rounding techniques come in, constructing a distribution over feasible subsets that equals x in expectation. A notable conceptual challenge is to ensure that this distribution contains enough randomness so as to admit concentration bounds not only across rounds, but also across atoms. Our analysis \"opens up\" a fairly technical proof from prior work and intertwines it with a new argument based on negative correlation.\nWe present our algorithm and analysis so as to \"plug in\" any suitable randomized rounding technique, which leads to faster running times for some important special cases.\nSolving SemiBwK using prior work. Naively solving an instance of SemiBwK using an algorithm for BwK would result in a regret bound like (1.1) with n replaced with the number of actions, which could be on the order of nk if each action can consist of at most k atoms, or perhaps even exponential in n.\nSemiBwK can be solved as a special case of a much more general linear-contextual extension of BwK from Agrawal and Devanur [2, 4]. In their model, an algorithm takes advantage of the combinatorial structure of actions, yet it ignores the additional feedback from the atoms. Their regret bounds have a worse dependence on the parameters, and apply for a much more limited range of parameters. Their per-round running time is linear in the number of actions, which is often prohibitively large.\nFor a convenient comparison, let us focus on instances of SemiBwK in which at most one unit of each resource is consumed in each round. (This is the case all our motivating applications, except\nrepeated bidding.) Then [2, 4] assume B > \u221a nT 3/4, and achieve regret O\u0303(n \u221a T OPTB + n 2 \u221a T ). 1 It is easy to see that we improve upon both summands. In particular, we improves by the factor of n \u221a n in a lucid special case when B > \u2126(T ) and OPT < O(T ).\nRelated work. Multi-armed bandits have been studied since [40] in Operations Research, Economics, and several branches of Computer Science, see [22, 15] for background. Among broad directions in MAB, most relevant is MAB with i.i.d. rewards, starting from [33, 7].\nBandits with Knapsacks (BwK) were first introduced by Badanidiyuru et al. [11] as a common generalization of several models from prior work, as well as numerous motivating examples. Subsequent papers on BwK introduced new algorithms and \u201csmoother\" resource constraints [2], and generalized BwK to contextual bandits [12, 5, 4]. Prior work on various special cases of BwK (i.e., bandit problems with resources) includes dynamic pricing with limited supply [9, 13, 14, 43], dynamic procurement on a budget [10, 37, 39], dynamic ad allocation with advertisers\u2019 budgets [38], and bandits with a single deterministic resource [23, 24, 41, 42]. All BwK problems have only been studied under the i.i.d. assumption, to the best of our knowledge.\nThe semi-bandit model was first studied by [25] in the adversarial setting. In the i.i.d. setting, in a series of works by [20, 19, 32], an optimal algorithm was achieved. This result was then extended to atoms with linear rewards by [44]. [30] obtained improved results for the special case when action set is described by a matroid. Some work studied a closely related \u201ccascade model\", where the ordering of atoms matters [31, 27, 46]. Contextual semi-bandits have been studied in [29].\nRandomized rounding schemes (RRS) come from the literature on approximation algorithms in combinatorial optimization (see [45, 34] for background). RRS were introduced in [35]. [21, 6, 17, 18] among others, developed RRS for combinatorial optimization problems such that the rounded random variables are correlated in a way that gives rise to sharp concentration bounds.\nOpen questions. One question concerns an extension to linear rewards, in line with a large literature on linear bandits. Here, each atom is characterized by a known low-dimensional feature vector, and its reward and resource consumption is a linear function of the features. As in [44], the goal is to alleviate the dependence on #atoms by replacing it with the dependence on #features.\nOrganization of the paper. We formally define the model, describe the algorithm and the regret bounds, overview the analysis, and briefly discuss some of the notable examples. Due to the page limit, many details are deferred to the supplement, specifically: full proofs, a detailed discussion of examples, and some background on combinatorial constrains."}, {"heading": "2 Our model and preliminaries", "text": "Our model, called Semi-Bandits with Knapsacks (SemiBwK) is a generalization of multi-armed bandits (henceforth, MAB) with i.i.d. rewards. As such, in each round t = 1 , . . . , T , an algorithm chooses an action St from a fixed set of actions F , and receives a reward \u00b5t(St) for this action which is drawn independently from a fixed distribution that depends only on the chosen action. The number of rounds T , a.k.a. the time horizon, is known to the algorithm.\nThere are d resources being consumed by the algorithm. The algorithm starts out with budgetBj \u2265 0 of each resource j. All budgets are known to the algorithm. If in round t action S \u2208 F is chosen, the outcome of this round is not only the reward \u00b5t(S) but the consumption Ct(S, j) of each resource j \u2208 [d]. We refer toCt(S) = (Ct(S, j) : j \u2208 [d]) as the consumption vector. Following prior work on BwK, we assume that all budgets are the same: Bj = B for all resources j.\n2 Algorithm stops as soon as any one of the resources goes strictly below 0. The round in which this happens is called the stopping time and denoted \u03c4stop. The reward in collected in this last round does not count; so the total reward of the algorithm is rew = \u2211\nt<\u03c4stop \u00b5t(St).\n1Agrawal and Devanur [2, 4] state regret bound with term +n \u221a T rather than +n2 \u221a\nT , but they assume that per-round rewards lie in [0, 1]. Since per-round rewards can be as large as n in our setting, we need to scale down all rewards by a factor of n, apply their regret bound, and then scale back, which results in the regret bound with+n2 \u221a T . When per-round consumption can be as large as n, regret bound from Agrawal and Devanur [2, 4] becomes O\u0303(OPT \u221a T/B + n2 \u221a\nT ) due to rescaling. 2This is w.l.o.g. because we can divide all consumption of each resource j by Bj/minj\u2032\u2208[d] Bj\u2032 . Effec-\ntively, B is the smallest budget in the original problem instance.\nActions correspond to subsets of a finite ground set A, with n = |A|; we refer to elements of A as atoms. Thus, the set F of actions corresponds to the family of \u201cfeasible subsets\" of A. The rewards and resource consumption is additive over the atoms: for each round t and each atom a there is a reward \u00b5t(a) \u2208 [0, 1] and consumption vector Ct(a) \u2208 [0, 1]d such that for each action S \u2282 F it holds that \u00b5t(S) = \u2211 a\u2208S \u00b5t(a) and Ct(S) = \u2211 a\u2208S Ct(a).\nWe assume the i.i.d. property across rounds, but allow arbitrary correlations within the same round. Formally, for a given round t we consider the n\u00d7 (d+1) \u201coutcome matrix\" (\u00b5t(a),Ct(a) : a \u2208 A), which specifies rewards and resource consumption for all resources and all atoms. We assume that the outcome matrix is chosen independently from a fixed distribution DM over such matrices. The distribution DM is not revealed to the algorithm. The mean rewards and mean consumption is denoted \u00b5(a) := E[\u00b5t(a)] andC(a) := E[Ct(a)]. We extend the notation to actions, i.e., to subsets of atoms: \u00b5(S) := \u2211\na\u2208S \u00b5(a) andC(S) := \u2211 a\u2208S C(a).\nAn instance of SemiBwK consists of the action set F \u2282 2[n], the budgets B = (Bj : j \u2208 [d]), and the distribution DM. The F and and B are known to the algorithm, and DM is not. As explained in the introduction, SemiBwK subsumes Bandits with Knapsacks (BwK) and semi-bandits. BwK is the special case when F consists of singletons, and semi-bandits is the special case when all budgets are equal to Bj = nT (so that the resource consumption is irrelevant).\nFollowing the prior work on BwK, we compete against the \u201coptimal all-knowing algorithm\": an algorithm that optimizes the expected total reward for a given problem instance; its expected total reward is denotedOPT. As observed in [11],OPT can be much larger (e.g., factor of 2 larger) than the expected cumulative reward of the best action, for a variety of important special cases of BwK. Our goal is to minimize regret, defined as OPT minus the total reward: Regret := OPT\u2212rew. Recall that F is given by a combinatorial constraint, i.e., a family of subsets. Consider subsets of atoms as n-dimensional binary vectors; then F corresponds to a finite set of points in Rn. We assume that the convex hull H of F forms a polytope in Rn. In other words, there exists a set of linear constraints over Rn whose set of feasible integral solutions is F . We call such combinatorial constraint F linearizable; the convex hull H is called the polytope induced by F . Our main result is matroid constraints, a family of linearizable combinatorial constraints which subsumes several important special cases such as cardinality constraints, partition matroid constraints, spanning tree constraints and path constraints, see Appendix B for self-contained background.\nWe incorporate prior work on randomized rounding for linear programs. In our terms, assume action set F is linearizable, and consider the induced polytope P \u2282 [0, 1]n. The randomized rounding scheme (henceforth,RRS) for F is an algorithm that inputs a feasible fractional solution x \u2208 P and the linear equations describing P , and produces a random vector Y overF . For our main result, we consider RRS\u2019s such that E[Y ] = x and Y is negatively correlated; we call such RRS\u2019s negatively correlated. Several such RRS are known: e.g., for cardinality constraints and bipartite matching [21], for spanning trees [6], and for matroids [17]."}, {"heading": "2.1 Probability and concentration.", "text": "Let X = (X1, X2, . . . , Xm) denote a collection of random variables which take values in [0, 1]. Let X := 1m \u2211m i=1 Xi be the average, and \u00b5 := E[X ] be its expectation. Negative correlation. Family X is called negatively correlated iff\nE [ \u220f i\u2208S Xi ] \u2264 \u220fi\u2208S E[Xi] \u2200S \u2286 [m], (2.1) E [ \u220f\ni\u2208S(1\u2212Xi) ] \u2264 \u220fi\u2208S E[1\u2212Xi] \u2200S \u2286 [m], (2.2)\nNote that independent random variables are negatively correlated. Additionally, a family continues to be negatively correlated under non-negative scaling. Furthermore:\nClaim 2.1. If family X is negatively correlated, then families (1+Xi\u2212E[Xi]2 : i \u2208 [m]) and (1\u2212Xi+E[Xi]2 : i \u2208 [m]) are negatively correlated, too.\nWe are also interested in a closely related property:\nE [ \u220f i\u2208S Xi ] \u2264 (12 )|S| \u2200S \u2286 [m]. (2.3)\nTheorem 2.2 ([26]). If family X satisfies (2.3), then for some absolute constant c,\nPr[X \u2265 12 + \u03b7] \u2264 c \u00b7 e\u22122m\u03b7 2\n(\u2200\u03b7 > 0) (2.4)\nWhile Claim 2.1 is probably known, we provide a proof in the supplement. Theorem 2.2 easily follows from Theorem 3.3 of Impagliazzo and Kabanets [26], see the supplement for the easy details.\nConfidence radius. We use the notion of confidence radius from [28, 9, 11, 3]:\nRad\u03b1(x,m) = \u221a \u03b1x/m+ \u03b1/m. (2.5)\nThis notion allows to bound the deviations |X \u2212 \u00b5| in a way that gets sharper when the \u00b5 is small, without knowing the \u00b5 in advance. Specifically, if random variables X are independent, then\nPr [ |X \u2212 \u00b5| < Rad\u03b1(X,m) < 3Rad\u03b1(\u00b5,m)] > 1\u2212O(e\u2212\u2126(\u03b1)), \u2200\u03b1 > 0. (2.6)\nWe use the confidence radius (2.5) to define upper/lower confidence bounds on the mean rewards\nand mean consumption. Fix round t, atom a, and resource j. Let \u00b5\u0302t(a) and C\u0302t(a, j) denote the empirical average of the rewards and resource-j consumption, resp., between rounds 1 and t \u2212 1. Let Nt(a) be the number of times atom a has been chosen in these rounds (i.e., how many times it has been included in the chosen action). Fixing parameter \u03b1 > 0 to be chosen later, the upper/lower confidence bounds are defined as\n\u00b5\u00b1t (a) = proj ( \u00b5\u0302(a)\u00b1 Rad\u03b1(\u00b5\u0302(a), Nt(a)) ) C\u00b1t (a, j) = proj( C\u0302(a, j)\u00b1 Rad\u03b1(C\u0302(a, j), Nt(a)) ),\n(2.7)\nwhere proj(x) := argminy\u2208[0,1] |y \u2212 x| denotes the projection into [0, 1]. We always use Rad with the same parameter \u03b1 = log(ndT/\u03b4), which we suppress from the notation. We use a vector notation \u00b5\u00b1t and C \u00b1 t (j) to denote the corresponding n-dimensional vectors over all atoms a. By (2.6), it follows that with probability 1\u2212O(e\u2212\u2126(\u03b1)) we have the following: \u00b5+t (a) \u2265 \u00b5(a) \u2265 \u00b5\u2212t (a) and C+t (a, j) \u2265 C(a, j) \u2265 C\u2212t (a, j)."}, {"heading": "3 Main algorithm", "text": "Let us define our main algorithm, called SemiBwK-RRS. The algorithm builds on an arbitraryRRS for the action set F . It is parameterized by this RRS, the polytopeP induced by F (represented as a collection of linear constraints), and a number \u01eb > 0. In each round t, it recomputes the upper/lower confidence bounds, as defined in (2.7), and solves the following linear program:\nmaximize \u00b5 + t \u00b7 x subject to C\u2212t (j) \u00b7 x \u2264 B(1\u2212\u01eb)T , j = 1, ..., d x \u2208 P x \u2208 [0, 1]n.\n(LPALG)\nThis linear program defines a linear relaxation of the original problem which is \u201coptimistic\" in the sense that it uses upper confidence bounds for rewards and lower confidence bounds for consumption. The linear relaxation is also \u201cconservative\" in the sense that it rescales the budget by 1 \u2212 \u01eb. Essentially, this is to ensure that the algorithm does not run out of budget with high probability. Parameter \u01eb will be fixed throughout. For ease of notation, we will denote B\u01eb := (1\u2212 \u01eb)B henceforth. The LP solution x can be seen as a probability vector over the atoms. Finally, the algorithm uses the RRS to convert the LP solution into a feasible action. The pseudocode is given as Algorithm 1.\nIf action set F is described by a matroid constraint, we can use the negatively correlated RRS from [17]. In particular, we obtain a complete algorithm for several combinatorial constraints commonly used in the literature on semi-bandits, such as partition matroid constarints, paths and spanning trees. More background on matroid contraints can be found in the supplement (see Appendix B).\nTheorem 3.1. Consider the SemiBwK problem with a linearizable action set F that admits a negatively correlated RRS. Then algorithm SemiBwK-RRS with this RRS achieves\nRegret \u2264 O(log(ndT/\u03b4)) \u221a n ( OPT / \u221a B + \u221a T +OPT )\n(3.1)\nAlgorithm 1: SemiBwK-RRS\ninput :an RRS for action set F , induced polytope P (as a set of linear constraints), \u01eb > 0. 1 for t = 1, 2 , . . . , T do\n1. Recompute Confidence Bounds according to (2.7)\n2. Obtain fractional solution xt \u2208 [0, 1]n by solving LPALG. 3. Obtain a feasible action St \u2208 F by invoking the RRS on xt. 4. Semi-bandit Feedback: observe the rewards/consumption for all atoms a \u2208 St.\nwith probability at least 1 \u2212 \u03b4, for any \u03b4 > 0. Here T is the time horizon, n is the number of atoms, and B is the budget. The result holds as long as B > \u03b1n+ \u221a \u03b1nT , where \u03b1 = log(ndT/\u03b4). Parameter \u01eb in the algorithm is set to \u01eb = \u221a\n\u03b1n B + \u03b1n B + \u221a \u03b1nT B .\nCorollary 3.2. Consider the setting in Theorem 3.1 and assume that the action set F is defined by a matroid on the set of atoms. Then, using the negatively correlated RRS from [17], we obtain the regret in equation (3.1).\nWe overview the proof in Section 3.1. Full proofs can be found in the supplement.\nRunning time (for matroid constraints). At each round t, the algorithm does two computationally intensive steps: solves the linear program and runs the RRS. The RRS from [17] has O(n2) running time. Hence, in the general case the computational bottleneck is solving the LP, which has n variables and O(2n) constraints. Matroids are known to admit a polynomial-time seperation oracle [e.g., see 36]. It follows that the entire set of constraints in LPALG admits a polynomial-time separation oracle, and therefore we can use the Ellipsoid algorithm to solve LPALG in polynomial time. For some classes of matroid constraints the LP is much smaller: e.g., for cardinality constraints (just d+1 constraints) and for traversal matroids on bipartite graphs (just 2n+d constraints). Then faster (near-linear-time) algorithms can be used.\nUsing another RSS. Recall that our algorithm works under any negatively correlated RRS. We can use this flexibility to improve the per-round running time for some special cases. Note that making decisions extremely fast is often critical in practical applications of bandits, e.g., see [1]. Specifically, we obtain near-linear per-round running times for cardinality constraints and partition matroid constraints. Indeed, LPALG can be solved in near-linear time, as mentioned above, and we can use a negatively correlated RRS from [21] which runs in linear time. These classes of matroid constraints are important in applications, see the detailed discussion in the supplement (Section 7).\nExtension to linearizable action sets. We extend our analysis to any linearizable action set, assuming each resource is consumed by at most one atom. (E.g., this is the case for the \u201cdynamic assortment\" problem, see Section 4.) We use a very simple RRS: given a fractional solution x which lies in P , the polytope induced by the action set F , we represent x as a distribution Y over the vertices of P , and output Y . This is a valid RRS because vertices of P lie in F . However, while we get E[Y ] = x, we cannot guarantee negative correlation or any other similarly useful property.\nTheorem 3.3. Consider the SemiBwK problem with a linearizable action set. Assume each resource can be consumed by at most one atom. Use the same notation and same parameter \u01eb as in Theorem 3.1. Then algorithm SemiBwK-RRS with the simple RRS described above achieves:\nRegret \u2264 O(log(ndT/\u03b4)) ( OPT \u221a n/B + n \u221a OPT+ n ) . (3.2)\nwith probability at least 1\u2212 \u03b4, for any \u03b4 > 0. The result holds if B > \u03b1n, where \u03b1 = log(ndT/\u03b4). Parameter \u01eb in the algorithm is set to \u01eb = \u221a\n\u03b1n B + \u03b1n B .\nCompared to the main result, Theorem 3.3 makes a significant assumption that resources correspond to atoms. On the other hand, it relaxes the assumption on budget B. The regret bound is incomparable with Eq. 3.1: for example, it is worse when T/n \u226a OPT < B, and better when OPT \u226a T/n < nB. The theorem is proved similarly to Theorem 3.1; the main modification is a simpler-to-prove but less efficient version of Eq. 3.3 below.\nIn particular, this extension applies to independent set constraints, which in turn helps in the application to dynamic assortment with mutually exclusive products (see the supplement, Section 7)."}, {"heading": "3.1 Proof overview of Theorem 3.1", "text": "First, we argue that LPALG provides a good benchmark that we can use instead of OPT. Fix round t and let OPTALG, t denote the optimal value for LPALG in this round. Then:\nLemma 3.4. OPTALG, t \u2265 1T (1\u2212 \u01eb)OPT with probability at least 1\u2212 \u03b4.\nWe prove this by constructing a series of LPs, starting with a generic linear relaxation for BwK and ending with LPALG, and showing that along the series the optimal value does not decrease w.h.p.\nNext we define a series of events that occur with high probability, henceforth called clean events. Our first \u201cclean event\" concerns total rewards, and compares our algorithm against LPALG:\n|\u2211t\u2208[T ] rt \u2212 \u2211 t\u2208[T ] \u00b5 + t \u00b7 xt| \u2264 O\n( \u221a\n\u03b1n \u2211 t\u2208[T ] rt + \u221a \u03b1nT + \u03b1n ) . (3.3)\nTo prove that (3.3) is indeed a high-probability event, we show that the following happens w.h.p.:\n| \u2211 t\u2208[T ] rt \u2212 \u2211 t\u2208[T ] \u00b5 \u00b7 Yt| \u2264 3nT Rad ( 1 nT \u2211 t\u2208[T ] \u00b5 + t \u00b7 xt , nT )\n|\u2211t\u2208[T ] \u00b5 \u00b7 Yt \u2212 \u00b5 + t \u00b7 Yt| \u2264 12\n\u221a\n\u03b1n ( \u2211\nt\u2208[T ] \u00b5 + t \u00b7 xt\n) + 12 \u221a \u03b1n+ 12\u03b1n\n| \u2211 t\u2208[T ] \u00b5 + t \u00b7 Yt \u2212 \u00b5+t \u00b7 xt| \u2264\n\u221a \u03b1nT\nWe prove these three high-probability inequalities using several tools. First, we use the confidence radius from Section 2.1. Second, we use the negative correlation property of the RRS. To this end, we extend Theorem 2.2 to a random process that evolves over time, and only assumes that property (2.3) holds within each round conditional on the history. We apply this extension via the transformation from Claim 2.1. Third, we use a concentration bound from prior work which gets sharper when the expected sum is very small, and does not rely on independent random variables. Finally, we show that using these inequalities one can effectively upper-bound the \u2211\nt\u2208[T ]\u00b5 + t xt\nterm, and then massage the three inequalities to obtain Eq. 3.3.\nThe second \u201cclean event\u201d concerns the resources consumed by the algorithm, and implies (with a little more work) that the algorithm does not run out of resources before round T . Letting \u03c7t(j) denote the consumption of resource j at time t by the algorithm, the clean event is:\n\u2200j \u2208 [d] | \u2211 t\u2208[T ] \u03c7t(j)\u2212 \u2211 t\u2208[T ] C \u2212 t (j) \u00b7 xt| \u2264 \u221a \u03b1nB\u01eb + \u03b1n+ \u221a \u03b1nT . (3.4)\nThe proof that this is indeed a high-probability event is similar to that for Eq. 3.3.\nFinally, we condition on the intersection of the clean events, and obtain the final regret bound in Eq. 3.1 via a \u201cdeterministic\" argument, only relying on these high-probability inequalities."}, {"heading": "4 Applications and special cases", "text": "We briefly discuss some notable examples of SemiBwK (generalizing some of the numerous applications listed [11]). Our results for these examples improve exponentially over a naive application of the BwK framework. Compared to what can be derived from [2, 4], our results feature a substantially better dependence on parameters, a much better per-round running time, and apply to a wider range of parameters. However, we leave open the possibility that regret bounds can be improved for some special cases. A more detailed discussion, including framing the examples in the SemiBwK framework and comparisons to prior work, can be found in the supplement, see Section 7.\nThe dynamic pricing application is as follows. The algorithm has d products on sale with limited supply: for simplicity, say B units of each. Following Besbes and Zeevi [14], we also allow constraints that cut across products, such as limited inventory of a \u201cpart\" that goes into multiple products.3 In each round t, an agent arrives, the algorithm chooses a vector of prices pt \u2208 [0, 1]d to offer the agent, and the agent chooses what to buy at these prices. For simplicity, assume the agent is interested in buying (and/or is only allowed to buy) at most one item of each product. The algorithm maximizes\n3We re-scale so that at most one unit of each such \u201cpart\" is consumed per one unit of any product, and assume that the inventory of this part is at least B.\nthe total revenue from sales; there is no value in left-over times. The agent has a valuation vector over products, drawn as an independent sample from a fixed and unknown distribution. (However, agents\u2019 valuations across products may be correlated in an arbitrary way.) We assume prices are restricted to lie in a known finite subset S \u2282 [0, 1]. 4 We obtain regret O\u0303(d \u221a dB|S| + \u221a\nT |S|) using our main result in Corollary 3.2, whenever B > \u2126\u0303(n + \u221a nT ). For comparison, results of [2, 4] apply only when B > \u221a nT 3/4, and yield regret bound of O\u0303(d3|S|2 \u221a T ).\nThe dynamic assortment problem is similar to dynamic pricing in that the algorithm is selling d products to an agent, with a limited inventory B of each product, and is interested in maximizing the total revenue from sales. As before, agents can have arbitrary valuation vectors, drawn from a fixed but unknown distribution. However, the prices are fixed externally. Instead, the algorithm has a large number of products and offer only k \u226a d of them in each round. So the algorithm\u2019s actions are which products to offer in which rounds. We obtain regret O\u0303(k \u221a dT ) when B > \u2126(T ), and regret O\u0303(d \u221a dB+ \u221a dT ) in general. Since both resources and atoms correspond to products, the extension in Theorem 3.3 applies. It yields regret bound O\u0303(d \u221a dB), which is better whenB \u226a T/d2. We can also accommodate constraints on mutually exclusive products.\nIn the repeated auctions application, the auctioneer is running r simultaneous repeated auctions to sell a shared inventory of d products, with limited supply B of each product. (E.g., different auctions can cater to different audiences.) Each auction has a parameter such as a reserve price, which the algorithm can adjust over time. For simplicity, assume the auctions are synchronized with one another. As in prior work, we assume that in every round of each auction a fresh set of participants arrives, sampled independently from a fixed joint distribution, and only a minimal feedback is observed: the products sold and the combined revenue. If parameters are restricted to a finite set S, we obtain regret O\u0303(d \u221a r|S|B + \u221a\nr|S|T ). One can also consider a \u201cflipped version\" of the previous example: we have r simultaneous, synchronized auctions, but the algorithm is an auction bidder rather than the auction maker. We assume a stationary environment: bidder\u2019s utility from a given bid in a given round of a given auction is an independent sample from a fixed but unknown distribution. The only limited resource here is the bidder\u2019s budget B. Assuming the bids are constrained to lie in a finite subset S, we obtain regret O\u0303(OPT \u221a r|S|/B + \u221a r|S|T )."}, {"heading": "5 Proof of the main result (Theorem 3.1)", "text": "This section presents a detailed and self-contained proof of the main result: Theorem 3.1. Let us first recall the theorem statement.\nTheorem (Theorem 3.1). Consider the SemiBwK problem with a linearizable action set F that admits a negatively correlated RRS. Then algorithm SemiBwK-RRS with this RRS achieves\nRegret \u2264 O(log(ndT/\u03b4)) \u221a n ( OPT / \u221a B + \u221a T +OPT )\n(5.1)\nwith probability at least 1 \u2212 \u03b4, for any \u03b4 > 0. Here T is the time horizon, n is the number of atoms, and B is the budget. The result holds as long as B > \u03b1n+ \u221a \u03b1nT , where \u03b1 = log(ndT/\u03b4). Parameter \u01eb in the algorithm is set to \u01eb = \u221a\n\u03b1n B + \u03b1n B + \u221a \u03b1nT B ."}, {"heading": "5.1 Linear programs", "text": "We argue that LPALG provides a good benchmark that we can use instead of OPT. Fix round t and let OPTALG, t denote the optimal value for LPALG in this round. Then:\nLemma (Lemma 3.4). OPTALG, t \u2265 1T (1\u2212 \u01eb)OPT with probability at least 1\u2212 \u03b4.\nWe will prove this by constructing a series of LP\u2019s, starting with a generic linear relaxation for BwK and ending with LPALG. We show that along the series the optimal value does not decrease with high probability.\nThe first LP, adapted from [11], has one decision variable for each action, and applies generically to any BwK problem.\nmaximize \u2211\nS\u2208F \u00b5(S)x(S) subject to \u2211\nS\u2208F C(S, j)x(S) \u2264 B/T j = 1, ..., d 0 \u2264 \u2211S\u2208F x(S) \u2264 1.\n(LPBwK)\nLet OPTBwK(B) denote the optimal value of this LP with a given budget B. Then: Claim 5.1. OPTBwK(B\u01eb) \u2265 (1 \u2212 \u01eb)OPTBwK(B) \u2265 1T (1\u2212 \u01eb) OPT.\nProof. The second inequality in Claim 5.1 follows from [Lemma 3.1 in 11]. We will prove the first inequality as follows. Let x\u2217 denote an optimal solution to LPBwK(B). Consider (1 \u2212 \u01eb)x\u2217; this is feasible to LPBwK(B\u01eb), since for every S, (1 \u2212 \u01eb)x\u2217(S) \u2264 1 and \u2211\nS\u2286A:S\u2208S C(S, j)(1 \u2212 \u01eb)x(S) \u2264\nB\u01eb/T . Hence, this is a feasible solution. Now, consider the objective function. Let y denote an optimal solution to LPBwK(B\u01eb). We have that\nOPTBwK(B\u01eb) = \u2211 S\u2286A:S\u2208S \u00b5(S)y\u2217(S) \u2265 \u2211 S\u2286A:S\u2208S \u00b5(S)(1\u2212 \u01eb)x\u2217(S) = (1\u2212 \u01eb)OPTBwK(B).\nNow consider a simpler LP where the decision variables correspond to atoms. As before, P denotes the polytope induced by action set F .\nmaximize \u00b5 \u00b7 x subject to C\u2020 \u00b7 x 4 B\u01eb/T x \u2208 P x \u2208 [0, 1]n. (LPATOMS)\nHere C = (C(a, j) : a \u2208 A, j \u2208 d) is the n\u00d7 d matrix of expected consumption, and C\u2020 denotes its transpose. The notation 4 means that the inequality \u2264 holds for for each coordinate. Leting OPTatoms denote the optimal value for LPATOMS, we have: Claim 5.2. With probability at least 1\u2212 \u03b4 we have, OPTALG, t \u2265 OPTatoms \u2265 OPTBwK(B\u01eb).\nProof. We will first prove the second inequality.\nConsider the optimal solution vector x to LPBwK(B\u01eb). Define S \u2217 := {S : x(S) 6= 0}.\nWe will now map this to a feasible solution to LPATOMS and show that the objective value does not decrease. This will then complete the claim. Consider the following solution y defined as follows.\ny(a) = \u2211\nS\u2208S\u2217:a\u2208S x(S).\nWe will now show that y is a feasible solution to the polytope P . From the definition of y, we can write it as y = \u2211\nS\u2208S\u2217 x(S) \u00d7 I[S]. Here, I[S] is a binary vector, such that it has 1 at position a if\nand only if atom a is present in set S. Hence, y is a point in the polytope since it can be written as convex combination of its vertices.\nNow, we will show that, y also satisfies the resource consumption constraint.\nC(j) \u00b7 y = \u2211\na\u2208A C(a, j)\n\u2211\nS\u2208S\u2217:a\u2208S x(S)\n= \u2211\nS\u2208S\u2217\n\u2211 a\u2208S C(a, j)x(S)\n= \u2211\nS\u2208S\u2217 C(S, j)x(S) \u2264 B\u01eb/T.\nThe last inequality is because in the optimal solution, the x value corresponding to subset S\u2217 is 1 while rest all are 0. We will now show that y produces an objective value at least as large as x.\nOPTatoms = \u00b5 \u00b7 y\u2217 \u2265 \u00b5 \u00b7 y = n \u2211\na=1\n\u00b5(a) \u2211\nS\u2208S\u2217:a\u2208S x(S)\n= \u2211\nS\u2208S\u2217\n\u2211 a\u2208S \u00b5(a)x(S) = \u2211 S\u2208S\u2217 \u00b5(S)x(S)\n= OPTsubsets(B\u01eb)\nNowwe will prove the first inequality. We will assume the \u201cclean event\u201d that\u00b5+t \u2265 \u00b5 andC\u2212t \u2264 Ct for all t. Hence, the inequality holds with probability at least 1\u2212 \u03b4. Consider a time t. Given an optimal solution x\u2217 to LPATOMS we will show that this is feasible to LPALG,t. Note that, x\n\u2217 satisfies the constraint set x \u2208 P since that is same for both LPALG,t and LPATOMS. Now consider the constraint C \u2212 t (j) \u00b7 x \u2264 B\u01ebT . Note that C \u2212 t (a, j) \u2264 C(a, j). Hence, we have thatC \u2212\nt (j) \u00b7x\u2217 \u2264 C(j) \u00b7x\u2217 \u2264 B\u01ebT . The last inequality is because x\u2217 is a feasible solution\nto LPATOMS.\nNow consider the objective function. Let y\u2217 denote the optimal solution to LPALG,t. OPTALG, t = \u00b5 + t \u00b7 y\u2217 \u2265 \u00b5+ t \u00b7 x\u2217 \u2265 \u00b5 \u00b7 y\u2217 = OPTatoms.\nHence, combining Claim 5.1 and Claim 5.2, we obtain Lemma 3.4."}, {"heading": "5.2 Concentration bounds", "text": "Our analysis relies on several concentration bounds, which elaborate on those presented in Section 2.1.\nFirst, we extend Theorem 2.2 to a random process that evolves over time, and only assumes that property (2.3) holds within each round conditional on the history.\nTheorem 5.3. Let ZT = {\u03b6t,a : a \u2208 A, t \u2208 [T ]} be a family of random variables taking values in [0, 1]. Assume random variables {\u03b6t,a : a \u2208 A} are negatively correlated given Zt\u22121 and have expectation 12 given Zt\u22121, for each round t. Let Z = 1nT \u2211\na\u2208A,t\u2208[T ] \u03b6t,a be the average. Then for some absolute constant c,\nPr[Z \u2265 12 + \u03b7] \u2264 c \u00b7 e \u22122m\u03b72 (\u2200\u03b7 > 0). (5.2)\nProof. We prove that family Zt satisfies property (2.3), and then invoke Theorem 2.2. Let us restate property (2.3) for the sake of completeness:\nE\n\n\n\u220f\n(t,a)\u2208S \u03b6t,a\n\n \u2264 2\u2212|S| for any subset S \u2286 ZT . (5.3)\nLet S be an arbitrary subset of ZT . Partition S into subsets St = {\u03b6t,a \u2208 ZT \u2229 S}, for each round t. Fix round \u03c4 and denote\nG\u03c4 = \u220f t\u2208[\u03c4 ]Ht, where Ht = \u220f a\u2208St \u03b6t,a.\nWe will now prove the following statement by induction on \u03c4 :\nE[G\u03c4 ] \u2264 2\u2212k\u03c4 , where k\u03c4 = \u2211 t\u2208[\u03c4 ] |St|. (5.4)\nWe will prove this by induction on \u03c4 .\nBase case is when \u03c4 = 1. Note that G\u03c4 is just the product of elements in set \u03b61 and they are negatively correlated from the premise. Therefore we are done.\nNow for the inductive case of \u03c4 \u2265 2,\nE[H\u03c4 |Z\u03c4\u22121] \u2264 \u220f\na\u2208S\u03c4 E[\u03b6\u03c4,a|Z\u03c4\u22121] From negative correlation in the conditional space (5.5) \u2264 2\u2212|S\u03c4 | From assumption in Lemma 5.3 (5.6)\nTherefore, we have\nE[G\u03c4 ] = E[E[G\u03c4\u22121H\u03c4 |Z\u03c4\u22121]] Law of iterated expectation = E[G\u03c4\u22121 E[H\u03c4 |Z\u03c4\u22121]] Since G\u03c4\u22121 is a fixed value conditional on Z\u03c4\u22121 \u2264 2\u2212|S\u03c4 | E[G\u03c4\u22121] From Eq. 5.6 \u2264 2\u2212k\u03c4 From inductive hypothesis\nThis completes the proof of Eq. 5.4. We obtain Eq. 5.3 for \u03c4 = T .\nSecond, we invoke Eq. 2.6 for rewards and resource consumptions:\nLemma 5.4. With probability at least 1\u2212 e\u2212\u2126(\u03b1), we have the following: |\u00b5\u0302t(a)\u2212 \u00b5t(a)| \u2264 2Rad(\u00b5\u0302t(a), Nt(a) + 1)\n\u2200j \u2208 [d] |C\u0302t(a, j)\u2212 Ct(a, j)| \u2264 2Rad(C\u0302t(a, j), Nt(a) + 1). (5.7)\nThird, we use a concentration bound from prior work which gets sharper when the expected sum is very small, and does not rely on independent random variables:\nTheorem 5.5 (Babaioff et al. [9]). Let X1, X2, . . . , Xm denote a set of {0, 1} random variables. For each t, let \u03b1t denote the multiplier determined by random variables X1, X2, . . . , Xt\u22121. Let M =\n\u2211m t=1 Mt where Mt = E[Xt|X1, X2, . . . , Xt\u22121]. Then for any b \u2265 1, we have the following\nwith probability at least 1\u2212m\u2212\u2126(b):\n| m \u2211\nt=1\n\u03b1t(Xt \u2212Mt)| \u2264 b( \u221a M logm+ logm)"}, {"heading": "5.3 Analysis of the \u201cclean event\"", "text": "Let us set up several events, henceforth called clean events, and prove that they hold with high probability. Then the remainder of the analysis can proceed conditional on the intersection of these events. The clean events are similar to the ones in [3], but are somewhat \u201cstronger\", essentially because our algorithm has access to per-atom feedback and our analysis can use the negative correlation property of the RRS.\nIn what follows, it is convenient to consider a version of SemiBwK in which the algorithm does not stop, so that we can argue about what happens w.h.p. if our algorithm runs for the full T rounds. Then we show that our algorithm does indeed run for the full T rounds w.h.p.\nRecall that xt be the optimal fractional solution obtained by solving the LP in round t. Let Yt \u2208 {0, 1}n be the random binary vector obtained by invoking theRRS (so that the chosen action St \u2208 F corresponds to a particular realization of Yt, interpreted as a subset). Let Gt := {Yt\u2032 : \u2200t\u2032 \u2264 t} denote the family of RRS realizations up to round t."}, {"heading": "5.3.1 \u201cClean event\" for rewards", "text": "For brevity, for each round t let \u00b5t = (\u00b5t(a) : a \u2208 A) be the vector of realized rewards, and let rt := \u00b5t(St) = \u00b5t \u00b7 Yt be the algorithm\u2019s reward at this round. Lemma 5.6. Consider SemiBwK without stopping. Then with probability at least 1\u2212 nT e\u2212\u2126(\u03b1):\n|\u2211t\u2208[T ] rt \u2212 \u2211 t\u2208[T ] \u00b5 + t \u00b7 xt| \u2264 O\n( \u221a\n\u03b1n \u2211 t\u2208[T ] rt + \u221a \u03b1nT + \u03b1n ) .\nProof. We prove the Lemma by proving the following three high-probability inequalities.\nWith probability at least 1\u2212 nT e\u2212\u2126(\u03b1): the following holds:\n|\u2211t\u2208[T ] rt \u2212 \u2211 t\u2208[T ] \u00b5 \u00b7 Yt| \u2264 3nT Rad ( 1 nT \u2211 t\u2208[T ] \u00b5 + t \u00b7 xt , nT )\n(5.8)\n|\u2211t\u2208[T ] \u00b5 \u00b7 Yt \u2212 \u00b5 + t \u00b7 Yt| \u2264 12\n\u221a\n\u03b1n ( \u2211\nt\u2208[T ] \u00b5 + t \u00b7 xt\n) + 12 \u221a \u03b1n+ 12\u03b1n (5.9)\n|\u2211t\u2208[T ] \u00b5 + t \u00b7 Yt \u2212 \u00b5+t \u00b7 xt| \u2264\n\u221a \u03b1nT . (5.10)\nWe will use the properties of RRS to prove Eq. 5.10. Proof of Eq. 5.9 is similar to [3], while proof of Eq. 5.8 follows immediately from the setup of the model. Using the parts (5.8) and (5.10) we can\nnow find an appropriate upper bound on\n\u221a\n\u2211\nt\u2208[T ] \u00b5 + t \u00b7 xt and using this upper bound, we prove\nLemma 5.6.\nProof of Eq. 5.8. Recall that rt = \u00b5tYt. Note that, E[\u00b5tYt] = \u00b5Yt when the expectation is taken over just the independent samples of \u00b5. By Theorem 5.5, with probability 1\u2212 e\u2212\u2126(\u03b1) we have:\n|\u2211t\u2264T rt \u2212 \u2211 t\u2264T \u00b5 \u00b7 Yt| \u2264 3nT Rad ( 1 nT \u2211 t\u2264T \u00b5 \u00b7 Yt , nT )\n\u2264 3nT Rad (\n1 nT\n\u2211\nt\u2264T \u00b5 + t \u00b7 Yt , nT\n)\n\u2264 3nT Rad (\n1 nT\n\u2211\nt\u2264T \u00b5 + t \u00b7 xt , nT\n)\n.\nThe last inequality is because Yt is a feasible solution to LPALG.\nProof of Eq. 5.9. For this part, the arguments similar to [3] follow with some minor adaptations. For sake of completeness we describe the full proof. Note that we have,\n|\u2211t\u2264T \u00b5 \u00b7 Yt \u2212 \u00b5 + t \u00b7 Yt| \u2264 \u2211n a=1 | \u2211 t\u2264T \u00b5(a)Yt(a)\u2212 \u00b5+t (a)Yt(a)|.\nNow, using Lemma 5.4 in Appendix, we have that with probability 1\u2212 nTe\u2212\u2126(\u03b1)\n|\u2211t\u2264T \u00b5(a)Yt(a)\u2212 \u00b5+t (a)Yt(a)| \u2264 12 \u2211 t\u2264T Rad(\u00b5(a), Nt(a) + 1).\nHence, we have \u2211n\na=1 | \u2211 t\u2264T \u00b5(a)Yt(a)\u2212 \u00b5+t (a)Yt(a)| = 12 \u2211 a\u2208A \u2211NT (a)+1 r=1 Rad(\u00b5(a), r)\n\u2264 12\u2211a\u2208A(NT (a) + 1)Rad(\u00b5(a), NT (a) + 1) \u2264 12 \u221a\n\u03b1n (\u00b5 \u00b7 (NT + 1)) + 12\u03b1n. The last inequality is from the definition of Rad function and using the Cauchy-Swartz inequality. Note that \u00b5NT = \u2211\nt\u2264T \u00b5 \u00b7 Yt. Also, since we have with probability 1 \u2212 e\u2212\u2126(\u03b1), \u00b5(a) \u2264 \u00b5+t (a), we have,\n12 \u221a \u03b1n (\u00b5 \u00b7 (NT + 1)) + 12\u03b1n \u2264 12 \u221a \u03b1n ( \u2211 t\u2264T \u00b5 + t \u00b7 Yt ) + 12 \u221a \u03b1n+ 12\u03b1n.\nFinally note that Yt is a feasible solution to the semi-bandit polytope P . Hence, we have that \u00b5\n+ t \u00b7 Yt \u2264 \u00b5+t \u00b7 xt.\nHence,\n12\n\u221a\n\u03b1n ( \u2211\nt\u2264T \u00b5 + t \u00b7 Yt\n) + 12 \u221a \u03b1n+ 12\u03b1n \u2264 12\n\u221a\n\u03b1n ( \u2211\nt\u2264T \u00b5 + t \u00b7 xt\n) + 12 \u221a \u03b1n+ 12\u03b1n.\nProof of Eq. 5.10: Recall that for each round t, the UCB vector \u00b5+ t\nis determined by the random variables Gt\u22121 = {Yt\u2032 : \u2200t\u2032 < t}. Further, conditional on a realization of Gt\u22121, the random variables {Yt(a) : a \u2208 A} are negatively correlated. Consequently, the random variables \u03b6\u0303t(a) = \u00b5+t (a)Yt(a), a \u2208 A are negatively correlated given Gt\u22121. Note that E[\u03b6\u0303t(a)|Gt\u22121] = \u00b5+t (a)xt(a). Define\n\u03b6t(a) = 1 + \u03b6\u0303t(a)\u2212 \u00b5+t (a)xt(a)\n2 .\nFrom Claim 2.1, we have that {\u03b6t(a) : a \u2208 A} conditioned on Gt\u22121 are negatively correlated. Further,E[\u03b6t(a)|Gt\u22121] = 12 . Therefore, the family {\u03b6t(a) : t \u2208 [T ], a \u2208 A} satisfies the assumptions in Theorem 5.3 and hence satisfies Eq. 5.2 for some absolute constant c. Plugging back the \u03b6\u0303t(a)\u2019s, we obtain an upper-tail concentration bound:\nPr [\n1 nT ( \u2211T t=1 \u2211 a\u2208A \u03b6\u0303t(a)\u2212 \u00b5+t (a)xt(a)) \u2265 \u03b7 ] \u2264 c \u00b7 e\u22122nT\u03b72 .\nTo obtain a corresponding concentration bound for the lower tail, we apply a similar argument to\n\u03b6\u2032t(a) = 1 + \u00b5+t (a)xt(a)\u2212 \u03b6\u0303t(a)\n2 .\nOnce again from Claim 2.1, we have that {\u03b6\u2032t(a) : a \u2208 A} conditioned on Gt\u22121 are negatively correlated. The family {\u03b6\u2032t(a) : t \u2208 [T ], a \u2208 A} satisfies the assumptions in Theorem 5.3 and hence satisfies Eq. 5.2. Plugging back the \u03b6\u0303t(a)\u2019s, we obtain a lower-tail concentration bound:\nPr [\n1 nT ( \u2211T t=1 \u2211 a\u2208A \u00b5 + t (a)xt(a)\u2212 \u03b6\u0303t(a)) \u2265 \u03b7\n]\n\u2264 c \u00b7 e\u22122nT\u03b72 .\nCombining these two we have,\nPr [\n1 nT | \u2211T t=1 \u2211 a\u2208A \u00b5 + t (a)Yt(a)\u2212 \u00b5+t (a)xt(a)| \u2265 \u03b7\n]\n\u2264 2 c \u00b7 e\u22122nT\u03b72 . (5.11)\nHence setting \u03b7 = \u221a \u03b1 nT , we obtain Eq. 5.10 with probability at least 1\u2212 e\u2212\u2126(\u03b1).\nCombining Eq. (5.8), (5.9) and (5.10) Let us denote H := \u221a \u2211\nt\u2208[T ] \u00b5 + t \u00b7 xt. Adding the three\nequations we get\n| \u2211 t\u2208[T ] rt \u2212H2| \u2264 \u221a \u03b1H + \u03b1+ \u221a \u03b1nH + O(\u03b1n) + \u221a \u03b1nT (5.12)\nRearranging and solving forH , we have\nH \u2264 \u221a \u2211 t\u2208[T ] rt +O( \u221a \u03b1n) + (\u03b1nT )1/4\nPlugging this back into Eq. 5.12, we get Lemma 5.6."}, {"heading": "5.3.2 \u201cClean event\" for resource consumption", "text": "We define a similar \u201cclean event\" for consumption of each resource j. The proof is similar and is deferred to later in this paper.\nBy a slight abuse of notation, for each round t let Ct(j) = (Ct(a, j) : a \u2208 A) be the vector of realized consumption of resource j. Let \u03c7t(j) denote algorithm\u2019s consumption for resource j at round t (i.e., \u03c7t(j) = Ct(j) \u00b7 Yt). Lemma 5.7. Consider SemiBwK without stopping. Then with probability at least 1\u2212 nT e\u2212\u2126(\u03b1):\n\u2200j \u2208 [d] |\u2211t\u2208[T ] \u03c7t(j)\u2212 \u2211 t\u2208[T ] C \u2212 t (j) \u00b7 xt| \u2264 \u221a \u03b1nB\u01eb + \u03b1n+ \u221a \u03b1nT .\nProof. As we did for clean event described by Lemma 5.6, we will split the proof into following three equations. Fix an arbitrary resource j \u2208 [d]. With probability at least 1 \u2212 nTe\u2212\u2126(\u03b1) the following holds:\n| \u2211 t\u2264T \u03c7t(j)\u2212 \u2211 t\u2264T C(j) \u00b7 Yt| \u2264 3nT Rad ( 1 nT \u2211 t\u2264T C(j) \u00b7 Yt , nT ) . (5.13)\n| \u2211 t\u2264T C(j) \u00b7 Yt \u2212C \u2212 t (j) \u00b7 Yt| \u2264 12\n\u221a\n\u03b1n ( \u2211 t\u2264T C(j) \u00b7 Yt ) + 12 \u221a \u03b1n+ 12\u03b1n. (5.14)\n|\u2211t\u2264T C \u2212 t (j) \u00b7 Yt \u2212C\u2212t (j) \u00b7 xt| \u2264\n\u221a \u03b1nT . (5.15)\nUsing the parts 5.13, 5.14 and 5.15 we can find an upper bound on \u221a \u2211\nt\u2264T Ct(j) \u00b7 Yt. Hence, combining Lemmas 5.13, 5.14 and 5.15 with this bound and taking an Union Bound over all the resources, we get Lemma 5.7.\nProof of Eq. 5.13. We have that {Ct(a, j) : a \u2208 A} is a set of independent random variables over a probability spacee C\u2126. Note that, EC\u2126 Ct(a, j)Yt(a) = C(a, j)Yt(a). Hence, we can invoke Theorem 5.5 on independent random variables to get with probability 1\u2212 nTe\u2212\u2126(\u03b1)\n| \u2211 t\u2264T \u03c7t(j)\u2212 \u2211 t\u2264T C(j) \u00b7 Yt| \u2264 3nT Rad ( 1 nT \u2211 t\u2264T C(j) \u00b7 Yt , nT ) .\nProof of Eq. 5.14. This is very similar to proof of 5.9 and we will skip the repetitive parts. Hence, we have with probability 1\u2212 nTe\u2212\u2126(\u03b1)\n|\u2211t\u2264T C(j) \u00b7 Yt \u2212C \u2212 t (j) \u00b7 Yt| \u2264 12\n\u221a\n\u03b1n(C(j) \u00b7 (NT + 1)) + 12\u03b1n\n\u2264 12 \u221a \u03b1n ( \u2211\nt\u2264T C(j) \u00b7 Yt )\n+ 12 \u221a \u03b1n+ 12\u03b1n.\nProof of Eq. 5.15. Recall that for each round t and each resource j, the LCB vector C\u2212 t (j) is determined by the random variables Gt\u22121 = {Yt\u2032 : \u2200t\u2032 < t}. Similar to the proof of Eq. 5.10, random variables {Yt(a) : a \u2208 A} are negatively correlated given Gt\u22121. Random variables \u03b6\u0303t(a) = C \u2212 t (a)Yt(a), a \u2208 A are negatively correlated given Gt\u22121. Moreover, E[\u03b6t(a) | Gt\u22121] = C\u2212t (a)xt(a).\nBy Claim 2.1, random variables\n\u03b6t(a) = 1 + \u03b6\u0303t(a)\u2212 C\u2212t (a)xt(a)\n2 , a \u2208 A\nare negatively correlated given Gt\u22121. We conclude that family {\u03b6t(a) : t \u2208 [T ], a \u2208 A} satisfies the assumptions in Theorem 5.3, and therefore satisfies Eq. 5.2 for some absolute constant c. Therefore, we obtain an upper-tail concentration bound for \u03b6\u0303t(a)\u2019s:\nPr [\n1 nT ( \u2211T t=1 \u2211 a\u2208A \u03b6\u0303t(a)\u2212 C\u2212t (a)xt(a)) \u2265 \u03b7 ] \u2264 c \u00b7 e\u22122nT\u03b72 .\nTo obtain a corresponding concentration bound for the lower tail, we apply a similar argument to\n\u03b6\u2032t(a) = 1 + C\u2212t (a)xt(a)\u2212 \u03b6\u0303t(a)\n2 .\nOnce again, invoking Claim 2.1 we have that {\u03b6\u2032t(a) : a \u2208 A} conditioned on Gt\u22121 are negatively correlated. Thus, family {\u03b6t(a) : t \u2208 [T ], a \u2208 A} satisfies the assumptions in Theorem 5.3, and therefore satisfies Eq. 5.2. We obtain:\nPr [\n1 nT ( \u2211T t=1 \u2211 a\u2208A C \u2212 t (a)xt(a)\u2212 \u03b6\u0303t(a)) \u2265 \u03b7\n]\n\u2264 c \u00b7 e\u22122nT\u03b72 .\nCombing the two tails we have,\nPr [\n1 nT | \u2211T t=1 \u2211 a\u2208A C \u2212 t (a)Yt(a)\u2212 C\u2212t (a)xt(a)| \u2265 \u03b7\n]\n\u2264 2 c \u00b7 e\u22122nT\u03b72 . (5.16)\nOnce again, setting \u03b7 = \u221a \u03b1 nT , we obtain Eq. 5.15 with probability at least 1\u2212 e\u2212\u2126(\u03b1).\nProof of Lemma 5.7. DenoteG = \u221a \u2211\nt\u2264T C(j) \u00b7 Yt. From Equation 5.13, 5.14 and 5.15, we have thatG2\u22122\u2126(\u221a\u03b1n)G \u2264 \u2211t\u2264T C \u2212 t (j) \u00b7xt+O(\u03b1n)+ \u221a \u03b1nT . Note that \u2211 t\u2264T C \u2212 t (j) \u00b7xt \u2264 B\u01eb.\nHence, G2 \u2212 2\u2126(\u221a\u03b1n)G \u2264 B\u01eb +O(\u03b1n) + \u221a \u03b1nT . Hence, re-arranging this gives us G \u2264 \u221a B\u01eb + O( \u221a \u03b1n) + (\u03b1nT )1/4. Plugging this back in Equations 5.13, 5.14 and 5.15, we get Lemma 5.7."}, {"heading": "5.4 Putting it all together", "text": "Similar to [3], we will handle the hard constraint on budget, by choosing an appropriate value of \u01eb. We then combine the above Lemma on \"rewards\" clean event to compare the reward of the algorithm with that of the optimal value of LP to obtain the regret bound in Eq. 3.1. Additionally, we use the Lemma on \"consumption\" clean event to argue that the algorithm doesn\u2019t exhaust the resource budget before round T . Formally, consider the following.\nRecall that from Lemma 3.4, we haveOPTALG, \u2265 1T (1\u2212 \u01eb)OPT. Let us define the performance of the algorithm as ALG = \u2211\nt\u2264T rt. From Lemma 5.6, that with probability at least 1\u2212 ndT e\u2212\u2126(\u03b1)\nALG \u2265 (1\u2212 \u01eb)OPT\u2212O( \u221a \u03b1nALG)\u2212O(\u03b1n) \u2212 \u221a \u03b1nT\n\u2265 (1\u2212 \u01eb)OPT\u2212O( \u221a \u03b1nOPT)\u2212O(\u03b1n) \u2212 \u221a \u03b1nT (since ALG \u2264 OPT).\nChoosing \u01eb = \u221a \u03b1n B + \u03b1n B + \u221a \u03b1nT B and using the assumption that B > \u03b1n + \u221a \u03b1nT , we derive Eq. 5.1. For any given \u03b4, we set \u03b1 = \u2126(log(ndT\u03b4 )) to obtain a success probability of at least 1\u2212 \u03b4. Now we will argue that the algorithm does not exhaust the resource budget before round T with probability at least 1\u2212 ndT e\u2212\u2126(\u03b1). Note that for every resource j \u2208 [d],\n\u2211 t\u2264T C \u2212 t (j) \u00b7 xt \u2264 (1\u2212 \u01eb)B.\nHence, combining this with Lemma 5.7, we have \u2211 t\u2264T Ct(j)Yt \u2264 (1\u2212 \u01eb)B + \u01ebB \u2264 B."}, {"heading": "6 Proof sketch for an extension (Theorem 3.3)", "text": "Here, we will give a sketch for proving the regret in Eq. 3.2. Note that, the RRS guarantees no form of concenteration among the atoms. Hence, we analyze it atom-by-atom and take an union bound across all the atoms. For the rewards clean event, we obtain with probability 1\u2212 n2T e\u2212\u2126(\u03b1)\n| \u2211\nt\u2264T rt \u2212\n\u2211 t\u2264T \u00b5 + t \u00b7 xt| \u2264\nn \u2211\na=1\nO\n\n\n\u221a\n\u03b1n \u2211\nt\u2264T rt(a)\n\n+O(\u03b1n2)\nTranslating this to the final regret calculation, we obtain\nOPT \u2212ALG \u2264 O ( OPT \u221a \u03b1n\nB +\nn \u2211\na=1\n\u221a\n\u03b1nrt(a) + \u03b1n 2\n)\nNow, on the RHS we want to maximize \u2211n\na=1\n\u221a\nrt(a) subject to \u2211n a=1 rt(a) = OPT. Using a\nstandard Lagrangian calculation, we obtain that the maximizer is when rt(a) = OPT n for all the atoms a. Hence, we have the regret in Eq. 3.2.\nNow, let us look at the resources. Here, we will critically use the fact that each atom has a dedicated resource. Since, every atom has a dedicated resource, while analyzing a particular resource, we need to consider just the corresponding arm. In other words, we have\n\u2200j \u2208 [d] | \u2211\nt\u2264T \u03c7t(j)\u2212\n\u2211 t\u2264T C \u2212 t (j) \u00b7 xt| = | \u2211 t\u2264T Ct(aj , j).Yt(aj)\u2212 \u2211 t\u2264T C\u2212t (aj , j)xt(aj)|\nHere, aj is the arm dedicated to resource j. Since {Yt(aj) : t \u2264 T } form a Martingale, we can use the concenteration bounds similar to sampling a single atom and the arguments in [3] goes as-is. Hence, with probability 1 \u2212 ndT e\u2212\u2126(\u03b1) the algorithm does not run out of resources before round T ."}, {"heading": "7 A detailed discussion of examples", "text": "This section elaborates on the discussion of applications and special cases in Section 4. For ease of presentation, this section can be read independently from the brief discussion in Section 4. For citations to the prior work on these special cases, see the corresponding subsection of the Introduction.\nDynamic pricing. Consider the dynamic pricing problem in a general formulation, where the algorithm has d products on sale with limited supply of each. For simplicity, say we have B items of each product. Further, there may be constraints that cut across products, such as limited inventory of a \u201cpart\" that goes into multiple products (e.g., same type of nut that goes into many furniture products). We re-scale so that at most one unit of each \u201cpart\" is consumed per one unit of any product, and assume that the inventory of this part is at least B.\nIn each round t, an agent arrives. The algorithm chooses a vector of prices (pt,1, pt,2 , . . . , pt,d) \u2208 [0, 1]d to offer the agent. For simplicity, say, the agent is interested in buying (and/or is only allowed\nto buy) at most one item of each product. The algorithm strives to optimize the total revenue from the sales. In particular, it derives no value from left-over items.\nThe agent has a valuation vector over products v \u2208 [0, 1]d such that (s)he chooses to buy one item of product j if and only if pt,j \u2264 vj . As in most prior work on dynamic pricing, we assume i.i.d. environment, in this case: that the valuation vector is drawn from a fixed but unknown distribution. Note that agents\u2019 valuations across products may be correlated in an arbitrary way.\nLet us frame this problem as a special case of SemiBwK. To side-step price discretization issues, assume the algorithm can only choose prices form a given finite set S \u2282 [0, 1]. The atoms then correspond to the (price, product) pairs: A = S \u00d7 [d]. The constraint is that at most one price is chosen for each product i, i.e., that an action contains at most one atom from S \u00d7 {i}. This corresponds to partition matroid constraints, see Appendix B.2. There is a \u201cdefault price\" for each product which is announced if the chosen action does not specify a price for this product. (The default prices must lie in S; it does not matter for our regret bound what they are.) Algorithm\u2019s rewards correspond to sales: the reward from selling product i at price pt,i is simply pt,i. Resources correspond to the limited inventories: there is a resource for each product and each \u201cpart\" that is in limited supply. The expected rewards and consumptions can be arbitrarily correlated across atoms, which models arbitrary valuation vectors.\nFollowing [11], we restrict prices to a finite subset S \u2282 [0, 1]. Note that OPT \u2264 dB, since that is the maximum number of products available, and the number of atoms is n = d|S|. Hence, we obtain regret of O\u0303(d \u221a dB|S|+ \u221a dT |S|) using Corollary 3.2, wheneverB > \u2126\u0303(n+ \u221a nT ).\nThis result should be contrasted with a naive application of the BwK framework. There, arms correspond to every possible realization of prices for the d products. Thus, we have |S|d arms, with a corresponding exponential blow-up in regret. As discussed in the introduction, results of Agrawal and Devanur [2, 4] apply when B > \u221a nT 3/4. Plugging in OPT \u2264 dB and n = d|S|, they yield regret bound of O\u0303(d3|S|2 \u221a T ). 5 Thus, our regret bounds feature a better dependence on the number of allowed prices |S| (which can be very large) and the number of products d. Further, our regret bounds hold in a meaningful way for the much larger range of values for budget B.\nRemark 7.1. Some prior work on dynamic pricing with limited supply [e.g., 13, 9, 11] achieves regret boundswithout restricting itself to a particular finite set of prices. A typical approach is to pick an evenly spaced subset S, and optimize the tradeoff between |S| and the resulting \u201cdiscretization error\": the difference between OPT with unrestricted price set and the OPT with prices restricted to S. However, this requires upper-bounding the discretization error, which is often quite difficult. In particular, prior work only accomplishes this for a simple special case of (essentially) a single product. Current techniques for upper-bounding discretization error seem to break when carried over to SemiBwK scenarios.\nDynamic assortment. This problem is similar to dynamic pricing in that the algorithm is selling multiple products to agents. However, the prices are fixed externally. Instead, the algorithm has a large number of products and can offer only a limited number of those in each round.\nFormally, the algorithm has d products with limited inventory of each. For simplicity we will assume that the algorithm has B copies of each product. There is a fixed price pi \u2208 [0, 1] for each item of each product i. At each round an agent arrives and the algorithm has to choose a subset of at most k products to show to the agent; typically k \u226a d. Like in the dynamic pricing example, the agent can buy at most one unit of each item. The agent has a valuation vector over products v \u2208 [0, 1]d, and this valuation vector is sampled each time from a fixed but unknown distribution. The agent buys one item of each product j if and only if pt,j \u2264 vj . The algorithm strives to maximize the total revenue from sales, and there is no value in left-over items.\nTo frame this as a SemiBwK problem, there is an atom for each of the d products, and actions correspond to subsets of at most k atoms. Rewards correspond to sales, and resources correspond to products, exactly as in dynamic pricing. Since OPT \u2264 min(dB, kT ), our main result yields regret O\u0303(k \u221a dT ) when B = \u2126(T ), and regret O\u0303(d \u221a dB + \u221a dT ) in general.\n5This is because for dynamic pricing the total per-resource consumption is bounded by 1, so we can apply the results from [2, 4] without rescaling the consumptions.\nSince both resources and atoms correspond to products, each resource can be consumed by at most one atom, and hence the extension in Theorem 3.3 applies. It yields regret bound O\u0303(d \u221a dB), which is better when B \u226a T/d2. A naive application of the BwK framework would have arms corresponding to each subset of k products. Hence, the number of arms would be O(dk). The other parameters of the problem would remain the same. Hence, the regret obtained would be O\u0303(d \u221a Bdk). Hence, again we obtain an exponential improvement.\nDynamic assortment problem can involve side constraints. For example, some products are naturally sold in a mutually exclusive manner. In particular, when we have disjoint \u201cclusters\" of mutually exclusive products, we can encode them via partition matroid constraints (see Appendix B.2): an action can contain at most one atom from each cluster. Then our main result applies, again, and yields the same regret bounds as above.\nMore generally, we can have a graph of mutually exclusive products, and the side constraint is that actions must be independent sets in this graph. Independent set constraints are linearizable (see Appendix B.3), so the combined combinatorial constraint on F is linearizable, too. Therefore, we can apply the extension in Theorem 3.3 (and obtain the same regret bound as above).\nAdjustable repeated auctions. Consider a repeated auction with adjustable parameters, e.g., repeated second-price auction with reserve price that can be adjusted from one round to another. While prior work [16, 11] concerned running one repeated auction, we generalize this scenario to multiple repeated auctions with shared inventory. Indeed, the same inventory may be sold via multiple channels to different audiences.\nMore formally, the auctioneer is running r simultaneous repeated auctions to sell d products with limited supply of each. For simplicity, we assume the supply of each product is B. The inventory is shared across all auctions. In each round, the algorithm specifies a parameter (such as a reserve price) for each repeated auction. The parameter comes from a finite domain S. For simplicity, assume the auctions are synchronized: in each round, we have one iteration of every auction. As in prior work, we assume that in every round a fresh set of participants arrives to each action, sampled independently from a fixed joint distribution. The participants\u2019 types are not known to the algorithm. Algorithm\u2019s goal is to maximize total revenue from all auctions and all rounds.\nWe will assume that this adjustable parameter comes from a finite domain S \u2282 [0, 1]. Note that, at each time-step the algorithm fixes a value to this parameter in each of the r auctions. Then a random sample of participants types are drawn from a joint distribution across the auctions. The algorithm receives feedback after each round. Following prior work, we only assume minimal feedback: for each auction, what where the products sold and what was the combined revenue from this auction. In particular, we do not assume that the algorithm has access to participants\u2019 bids. Not using participants\u2019 bids is desirable for privacy considerations, and in order to reduce the participants\u2019 incentives to game the learning algorithm.\nWe will now solve this problem using the SemiBwK framework. The atoms are the auction-parameter pairs: A = [r]\u00d7S. The combinatorial constraint is that an action must specify at most one parameter value for each auction i, i.e., contain at most one atom from each subset {i} \u00d7 S. This corresponds to partition matroid constraints, see Appendix B.2. As in the dynamic pricing application, there is a \u201cdefault parameter\" for each auction which is chosen if the action does not specify a parameter for this auction. (The default parameters must lie in S; it does not matter for our regret bound what they are.) The resource correspond to the items being auctioned: we have a resource for each product. For simplicity, say each product has supply of B. Note that OPT \u2264 dB and number of atoms is n = r|S|. Hence, our main result yields regret O\u0303(d \u221a r|S|B + \u221a\nr|S|T ). A naive application of the BwK framework would have arms that correspond to all possible combinations of parameters, for the total of O(|S|r) arms. Again, we have an exponential blow-up in regret. Alternatively, one may try running r seperate instances of BwK, one for each auction, but that may result result in budgets being violated since the items are shared across the auctions and it is unclear a priori how much of each item will be sold in each auction.\nRepeated bidding. We can also consider a \u201cflipped\" version of the repeated action scenario, where the algorithm is an auction participant rather than the auction maker. More precisely, consider a bidder who is placing bids in r different repeated auctions. For simplicity, assume the auctions are\nsynchronized, so that in each round, the bidder chooses a bid for each auction, and subsequently observes the utility derived from each auction. We assume a stationary environment: the bidder\u2019s utility from a given bid in a given round of a given auction is an independent sample from a fixed but unknown distribution. For simplicity, suppose the utility derived from each auction lies in [0, 1] interval. Assume the bids are constrained to lie in a finite subset S. The only limited resource here is the bidder\u2019s budget B.\nWe will now frame this problem in the SemiBwK framework. The atoms correspond to the auctionbid pairs: A = [r] \u00d7 S. As before, each action must specify at most one bid for each auction i, i.e., choose at most one atom from each subset {i} \u00d7 S. There is a \u201cdefault bid\" for each auction which gets chosen when an action does not specify a bid for this auction. There is exactly one resource, which is money and the total budget is B. Note that the number of atoms is n = r|S|. Hence, our main result yields regret O\u0303(OPT \u221a r|S|/B + \u221a\nr|S|T ). As before, a naive application of the BwK framework would have arms that correspond to all possible combinations of bids, for the total of O(|S|r) arms; so we have an exponential blow-up in regret."}, {"heading": "A Probability and concentration: some proofs", "text": "Our analysis relied on some facts about probability and concentration that we stated in Preliminaries (Section 2.1). While we believe these results are known, we provide proofs below for the sake of completeness. In what follows, let X = (X1, X2, . . . , Xm) denote a collection of random variables which take values in [0, 1], and let X := 1m \u2211m i=1 Xi be their average.\nTheorem (Theorem 2.2). Suppose X satisfies (2.3), i.e., E[\u220fi\u2208S Xi] \u2264 (12 )|S| for every S \u2286 [m]. Then for some absolute constant c,\nPr[X \u2265 12 + \u03b7] \u2264 c \u00b7 e \u22122m\u03b72 (\u2200\u03b7 > 0). (A.1)\nProof. Fix \u03b7 > 0. From Theorem 3.3 in Impagliazzo and Kabanets [26], we have that\nPr[X \u2265 12 + \u03b7] \u2264 c \u00b7 e \u2212mDKL(1/2+\u03b7 \u2016 1/2),\nwhere DKL(\u00b7 \u2016 \u00b7) denotes KL-divergence, so that\nDKL(12 + \u03b7 \u2016 12 ) = (12 + \u03b7) log(1 + 2\u03b7) + (12 \u2212 \u03b7) log(1\u2212 2\u03b7). (A.2)\nFrom Taylor series expansion we have,\nlog(1 + x) = x\u2212 x2/2 + x3/3 + . . . log(1 \u2212 x) = \u2212x\u2212 x2/2\u2212 x3/3 . . . .\nPlugging this into (A.2), we deriveDKL(1/2 + \u03b7 \u2016 1/2) \u2265 2\u03b72, which implies (A.1).\nClaim (Claim 2.1). If family X is negatively correlated, then families (1+Xi\u2212E[Xi]2 : i \u2208 [m]) and (1\u2212Xi+E[Xi]2 : i \u2208 [m]) are negatively correlated, too.\nProof. We will show that the random variables {(1 + Xi \u2212 E[Xi])/2 : i \u2208 [m]} are negatively correlated. Note that if Xi\u2019s are neg. correlated then so are 1 \u2212 Xi\u2019s. This would imply that {(1 + (1 \u2212Xi)\u2212 E[(1 \u2212Xi)])/2 : i \u2208 [m]} are negatively correlated. Hence, we would have that {(1 + |Xi \u2212 E[Xi]|)/2 : i \u2208 [m]} Denote \u00b5i = E[Xi] and Yi := (1 + Xi \u2212 \u00b5i)/2 and zi := (1 \u2212 \u00b5i)/2 for all i \u2208 [m]. Note that Yi = Xi/2 + zi and zi \u2265 0, Xi \u2265 0.\nConsider a subset S \u2286 [m]. We have,\nE[ \u220f\ni\u2208S Yi] = E[\n\u2211\nT\u2286S\n\u220f i\u2208T (Xi/2) \u220f j\u2208S\\T zi]\n= \u2211 T\u2286S E[ \u220f i\u2208T (Xi/2)] \u220f j\u2208S\\T zi From Linearity of Expectation\n\u2264 \u2211\nT\u2286S\n\u220f i\u2208T (\u00b5i/2) \u220f j\u2208S\\T zi fact that zi, Xi \u2265 0 andXi are negatively correlated\n= \u220f\ni\u2208S ((1 \u2212 \u00b5i)/2 + \u00b5i/2) = 1/2 =\n\u220f\ni\nE[Yi]. From Binomial Theorem\nNow we will show that the second property in the definition of negative correlation (i.e., Eq. 2.2) holds for the random variables (1\u2212Xi\u2212\u00b5i)/2 . Consider Y \u2032i := 1\u2212(1+Xi\u2212\u00b5i)/2 for all i \u2208 [m]. Note that, we have Y \u2032i = (1 + \u00b5i \u2212Xi)/2 for all i \u2208 [m]. Hence, setting Z \u2032i := (1 \u2212Xi)/2 for all i \u2208 [m] and noting that Y \u2032i = \u00b5i/2 + Z \u2032i for \u00b5i \u2265 0, Z \u2032i \u2265 0, we have the following. Consider a subset S \u2286 [m]. We have,\nE[ \u220f i\u2208S Y \u2032i ] = E[ \u2211 T\u2286S \u220f i\u2208T Z \u2032i \u220f j\u2208S\\T (\u00b5i/2)]\n= \u2211 T\u2286S E[ \u220f i\u2208T Z \u2032i] \u220f j\u2208S\\T (\u00b5i/2) From Linearity of Expectation\n\u2264 \u2211\nT\u2286S\n\u220f i\u2208T ((1 \u2212 \u00b5i)/2) \u220f j\u2208S\\T (\u00b5i/2) fact that \u00b5i, Z \u2032 i \u2265 0 and Z \u2032i are negatively correlated\n= \u220f\ni\u2208S ((1 \u2212 \u00b5i)/2 + \u00b5i/2) = 1/2 =\n\u220f\ni\nE[Y \u2032i ]. From Binomial Theorem"}, {"heading": "B Combinatorial constraints: formal discussion", "text": "To make this paper more self-contained, we provide a formal discussion of combinatorial constraints for which our algorithms work, and define the corresponding linear relaxations.\nRecall that in SemiBwK, we have a finite ground set whose elements are called \u201catoms\", and a family F of \u201cfeasible subsets\" of the ground set which are the actions. Our main result in Theorem 3.1 holds as long as F forms a matroid. Thus, we define matroid constraints and list several important special cases thereof in Appendices B.1 and B.2, respectively. The extension in Theorem 3.3 holds for linearizable action sets. We provide an example in Appendix B.3, namely: we define constraints specified by independent sets of a graph, and show that they are linearizable.\nB.1 Matroid constraints\nTo be consistent with the literature on matroids, the ground set will be denoted E. Family F of subsets of E is called a matroid if it satisfies the following properties:\n\u2022 Empty set: The empty set \u03c6 is present in F \u2022 Hereditary property: For two subsets X,Y \u2286 E such thatX \u2286 Y , we have that\nY \u2208 F =\u21d2 X \u2208 F\n\u2022 Exchange property: ForX,Y \u2208 F and |X | > |Y |, we have that\n\u2203e \u2208 X \\ Y : Y \u222a {e} \u2208 F\nMatroids are linearizable, i.e., the convex hull of F forms a polytope in RE . (Here subsets of F are intepreted as binary vectors in RE .) In other words, there exists a set of linear constraints whose set of feasible integral solutions is F . In fact, the convex hull of F , a.k.a. the matroid polytope, can be represented via the following linear system:\nx(S) \u2264 rank(S) \u2200S \u2286 E xe \u2208 [0, 1]E \u2200e \u2208 E. (LP-Matroid)\nHere x(S) := \u2211 e\u2208S xe, and rank(S) = max{|Y | : Y \u2286 S, Y \u2208 F} is the \u201crank function\" for F . F is indeed the set of all feasible integral solutions of the above system. This is a standard fact in combinatorial optimization, e.g., see Theorem 40.2 and its corollaries in Schrijver [36].\nB.2 Examples of matroid constraints\nWe will now describe some well-studied special cases of matroids. That they indeed are special cases of matroids is well-known, we will not present the corresponding proofs here.\nIn all LPs presented below, we have variables xe for each arom e \u2208 E, and we use shorthand x(S) := \u2211\ne\u2208S xe for S \u2282 E. Cardinality constraints. Cardinality constraint is defined as follows: a subset S of atoms belongs to F if and only if |S| \u2264 K for some fixedK . This is perhaps the simplest constraint that our results are applicable to. In the context of SemiBwK, each action selects at mostK atoms.\nThe corresponding induced polytope is as follows:\nx(E) \u2264 K xe \u2208 [0, 1] \u2200e \u2208 E. (LP-Cardinality)\nPartition matroid constraints. A generalization of cardinality constraints, called partition matroid constraints, is defined as follows. Suppose we have a collection B1 , . . . , Bk of disjoint subsets of E, and numbers d1 , . . . , dk. A subset S of atoms belongs to F if and only if |S \u2229 Bi| \u2264 di for every i. Partition matroid constraints appear in several applications of SemiBwK such as dynamic pricing, adjusting repeated auctions, and repeated bidding. In these applications, each action selects one price/bid for each offered product. Also, partition matroid constraints can model clusters of mutually exclusive products in dynamic assortment application.\nThe induced polytope is as follows:\nx(Bi) \u2264 di \u2200i \u2208 [k] xe \u2208 [0, 1] \u2200e \u2208 E. (LP-PartitionMatroid)\nSpanning tree constraints. Spanning tree constraints describe spanning trees in a given undirected graph G = (V,E), where the atoms correspond to edges in the graph. A spanning tree in G is a subset E\u2032 \u2282 E of edges such that (V,E\u2032) is a tree. Action set F consists of all spanning trees of G. The induced polytope is as follows:\nx(ES) \u2264 |S| \u2212 1 \u2200S \u2286 V x(EV ) = |V | \u2212 1 xe \u2208 [0, 1] \u2200e \u2208 E.\n(LP-SpanningTree)\nHere, ES denotes the edge set in subgraph induced by node set S \u2282 V . Path constraints. Path constraints describe paths in a given graph G = (V,E), where the atoms correspond to edges in the graph. Path constraints are commonly used in conjunction with the online routing problem ([8] and much follow-up work), where each action is a path in the network.\nFormally, we are given an undirected graph G = (V,E) and a source sink pair (s, t) in this graph. Action set F consists of all s-t paths in G. We index edges as e = (i, j), where i, j \u2208 V . The corresponding induced polytope is as follows:\n\u2211 j\u2208V x(i,j) \u2212 x(j,i) = 0 \u2200i \u2208 V \\ {s, t} \u2211\nj\u2208V x(i,j) \u2212 x(j,i) = 1 i = s \u2211\nj\u2208V x(i,j) \u2212 x(j,i) = \u22121 i = t xe \u2208 [0, 1] \u2200e \u2208 E.\n(LP-Path)\nB.3 Independent set constraints\nIndependent set constraints are specified as follows. Suppose V is the set of atoms, andG = (V,E) is an undirected graph. Action set F consists of all independent sets in G, i.e., all subsets S \u2282 V such that (u, v) 6\u2208 E, for any nodes u, v \u2208 S. Independent set constraints arise in the dynamic assortment application with mutually exclusive products.\nIndependent set constraints are linearizable. The corresponding induced polytope is as follows:\nxu + xv \u2264 1 \u2200(u, v) \u2208 E xe \u2208 [0, 1] \u2200e \u2208 E. (LP-Path)"}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "This paper unifies two lines of work on multi-armed bandits, Bandits with Knap-<lb>sacks (BwK) and semi-bandits. The former concerns scenarios with limited \u201cre-<lb>sources\" consumed by the algorithm, e.g., limited inventory in a dynamic pricing<lb>problem. The latter has a huge number of actions, but there is combinatorial struc-<lb>ture and additional feedback which makes the problem tractable. Both lines of<lb>work has received considerable recent attention, and are supported by numerous<lb>application examples. We define a common generalization, and design a general<lb>algorithm for this model. Our regret rates are comparable with those for BwK and<lb>semi-bandits in general, and essentially optimal for important special cases.", "creator": "LaTeX with hyperref package"}}}