{"id": "1705.11122", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2017", "title": "Controllable Invariance through Adversarial Feature Learning", "abstract": "Learning meaningful representations that maintain the content necessary for a particular task while filtering away detrimental variations is a problem of great interest in machine learning. In this paper, we tackle the problem of learning representations invariant to a specific factor or trait of data, leading to better generalization. The representation learning process is formulated as an adversarial minimax game. We analyze the optimal equilibrium of such a game and find that it amounts to maximizing the uncertainty of inferring the detrimental factor given the representation while maximizing the certainty of making task-specific predictions. On three benchmark tasks, namely fair and bias-free classification, language-independent generation, and lighting-independent image classification, we show that the proposed framework induces an invariant representation, and leads to better generalization evidenced by the improved test performance.", "histories": [["v1", "Wed, 31 May 2017 14:57:33 GMT  (1664kb,D)", "http://arxiv.org/abs/1705.11122v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CL", "authors": ["qizhe xie", "zihang dai", "yulun du", "eduard hovy", "graham neubig"], "accepted": false, "id": "1705.11122"}, "pdf": {"name": "1705.11122.pdf", "metadata": {"source": "CRF", "title": "Controllable Invariance through Adversarial Feature Learning", "authors": ["Qizhe Xie", "Zihang Dai", "Yulun Du", "Eduard Hovy", "Graham Neubig"], "emails": ["gneubig}@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "How to produce a data representation that maintains meaningful variations of data while eliminating noisy signals is a consistent theme of machine learning research. In the last few years, the dominant paradigm for finding such a representation has shifted from manual feature engineering based on specific domain knowledge to representation learning that is fully data-driven, and often powered by deep neural networks [Bengio et al., 2013]. Being universal function approximators [Gybenko, 1989], deep neural networks can easily uncover the complicated variations in data [Zhang et al., 2017], leading to powerful representations. However, how to systematically incorporate a desired invariance into the learned representation in a controllable way remains an open problem.\nA possible avenue towards the solution is to devise a dedicated neural architecture that by construction has the desired invariance property. As a typical example, the parameter sharing scheme and pooling mechanism in modern deep convolutional neural networks (CNN) [LeCun et al., 1998] take advantage of the spatial structure of image processing problems, allowing them to induce more generic feature representations than fully connected networks. Since the invariance we care about can vary greatly across tasks, this approach requires us to design a new architecture each time a new invariance desideratum shows up, which is time-consuming and inflexible.\nWhen our belief of invariance is specific to some attribute of the input data, an alternative approach is to build a probabilistic model with a random variable corresponding to the attribute, and explicitly reason about the invariance. For instance, the variational fair auto-encoder (VFAE) [Louizos et al., 2016] employs the maximum mean discrepancy (MMD) to eliminate the negative influence of specific \u201cnuisance variables\u201d, such as removing the lighting conditions of images to predict the person\u2019s identity in the image. Similarly, under the setting of domain adaptation, standard binary adversarial cost [Ganin and Lempitsky, 2015] and central moment discrepancy (CMD) [Zellinger et al., 2017] have been utilized to learn features that are domain invariant. However, all these\nar X\niv :1\n70 5.\n11 12\n2v 1\n[ cs\n.L G\n] 3\n1 M\nay 2\ninvariance inducing criteria suffer from a similar drawback, which is they are defined to measure the divergence between a pair of distributions. Consequently, they can only express the invariance belief w.r.t. a pair of values of the random variable at a time. When the attribute is a multinomial variable that takes more than two values, combinatorial number of pairs (specifically, O(n2)) have to be added to express the belief that the representation should be invariant to the attribute. The problem is even more dramatic when the attribute represents a structure that has exponentially many possible values (e.g. the parse tree of a sentence) or when the attribute is simply a continuous variable.\nMotivated by the aforementioned drawbacks and difficulties, in this work, we consider the problem of learning a feature representation with the desired invariance. We aim at creating a unified framework that is (1) generic enough such that it can be easily plugged into different models, and (2) more flexible to express an invariance belief in quantities beyond discrete variables with limited value choices. Specifically, inspired by the recent advancement of adversarial learning [Goodfellow et al., 2014], we formulate the representation learning as a minimax game among three players: an encoder which maps the observed data deterministically into a feature space, a discriminator which looks at the representation and tries to identify a specific type of variation we hope to eliminate from the feature, and a predictor which makes use of the invariant representation to make predictions as in typical discriminative models. We provide theoretical analysis of the equilibrium condition of the minimax game, and give an intuitive interpretation. On three benchmark tasks from different domains, we show that the proposed approach not only improves upon vanilla discriminative approaches that do not encourage invariance, but also outperforms existing approaches that enforce invariant features."}, {"heading": "2 Related Work", "text": "As a specific case of our problem where s takes two values, domain adaption has attracted a large amount of research interest. Domain adaptation aims to learn domain-invariant representations that are transferable to other domains. For example, in image classification, adversarial training has been shown to able to learn an invariant representation across domains [Ganin and Lempitsky, 2015, Bousmalis et al., 2016, Tzeng et al., 2017] and enables classifiers trained on the source domain to be applicable to the target domain. Moment discrepancy regularizations can also effectively remove domain specific information [Zellinger et al., 2017, Bousmalis et al., 2016] for the same purpose. By learning language-invariant representations, classifiers trained on the source language can be applied to the target language [Chen et al., 2016b, Xu and Yang, 2017].\nWorks targeting the development of fair, bias-free classifiers also aim to learn representations invariant to \u201cnuisance variables\u201d that could induce bias and hence makes the predictions fair, as data-driven models trained using historical data easily inherit the bias exhibited in the data. Zemel et al. [2013] proposes to regularize the `1 distance between representation distributions for data with different nuisance variables to enforce fairness. The Variational Fair Autoencoder [Louizos et al., 2016] targets the problem with a Variational Autoencoder [Kingma and Welling, 2014, Rezende et al., 2014] approach with maximum mean discrepancy regularization.\nOur work is also related to learning disentangled representations, where the aim is to separate different influencing factors of the input data into different parts of the representation. Ideally, each part of the learned representation can be marginally independent to the other. An early work by Tenenbaum and Freeman [1997] propose a bilinear model to learn a representation with the style and content disentangled. From information theory perspective, Chen et al. [2016a] augments standard generative adversarial networks with an inference network, whose objective is to infer part of the latent code that leads to the generated sample. This way, the information carried by the chosen part of the latent code can be retained in the generative sample, leading to disentangled representation.\nAs we have discussed in Section 1, these methods bear the same drawback that the cost used to regularize the representation is pairwise, which does not scale well as the number of values that the attribute can take could be large."}, {"heading": "3 Adversarial Invariant Feature Learning", "text": "In this section, we formulate our problem and then present the proposed framework of learning invariant features.\nGiven paired observations \u3008x, y\u3009, we are interested in the task of predicting the target y based on the value of x using a discriminative approach, i.e. directly modeling the conditional distribution p(y | x). As the input x can have highly complicated structure, we employ a dedicated model or algorithm to extract an expressive representation h from x. In addition, we have access to some intrinsic attribute s of x as well as a prior belief that the prediction result should be invariant to s. Thus, when we extract the representation h from x, we want the representation h to preserve variations that are necessary to predict y while eliminating information of s.\nTo achieve the aforementioned goal, we employ a deterministic encoderE to obtain the representation by encoding x and s into h, namely, h = E(x, s). It should be noted here that we are using s as an additional input. Intuitively, this can inform and guide the encoder to remove information about undesired variations within the representation. For example, if we want to learn a representation of image x that is invariant to the lighting condition s, the model can learn to \u201cbrighten\u201d the representation if it knows the original picture is dark, and vice versa.\nGiven the obtained representation h, the target y is predicted by a predictor M , which effectively models the distribution qM (y | h). By construction, instead of modeling p(y | x) directly, the discriminative model we formulate captures the conditional distribution p(y | x, s) with additional information coming from s.\nSurely, feeding s into the encoder by no means guarantees the induced feature h will be invariant to s. Thus, in order to enforce the desired invariance and eliminate variations of factor s from h, we set up an adversarial game by introducing a discriminator D which inspects the representation h and ensure that it is invariant to s. Concretely, the discriminator D is trained to predict s based on the encoded representation h, which effectively maximizes the likelihood qD(s | h). Simultaneously, the encoder fights to minimize the same likelihood of inferring the correct s by the discriminator. Intuitively, the discriminator and the encoder form an adversarial game where the discriminator tries to detect an attribute of the data while the encoder learns to conceal it.\nNote that under our framework, in theory, s can be any type of data as long as it represents an attribute of x. For example, s can be a real value scalar/vector, which may take many possible values, or a complex sub-structure such as the parse tree of a natural language sentence. But in this paper, we focus mainly on instances where s is a discrete label with multiple choices. We plan to extend our framework to deal with continuous s and structured s in the future.\nFormally, E, M and D jointly play the following minimax game: min E,M max D J(E,M,D)\nwhere J(E,M,D) = E\nx,s,y\u223cp(x,s,y) [\u03b3 log qD(s | h = E(x, s))\u2212 log qM (y | h = E(x, s))] (1)\nwhere \u03b3 is a hyper-parameter to adjust the strength of the invariant constraint, and p(x, s, y) is the true underlying distribution that the empirical observations are drawn from.\nNote that the problem of domain adaption can be seen as a special case of our problem, where s is a Bernoulli variable representing the domain and the model only has access to the target y when s = \u201csource domain\u201d during training."}, {"heading": "4 Theoretical Analysis", "text": "In this section, we theoretically analyze, given enough capacity and training time, whether such a minimax game will converge to an equilibrium where variations of y are preserved and variations of s are removed. The theoretical analysis is done in a non-parametric limit, i.e., we assume a model with infinite capacity.\nSince both the discriminator and the predictor only use h which is transformed deterministically from x and s, we can substitute x with h and define a joint distribution p\u0303(h, s, y) of h, s and y as follows\np\u0303(h, s, y) = \u222b x p\u0303(x, s, h, y)dx = \u222b x p(x, s, y)pE(h | x, s)dx = \u222b x p(x, s, y)\u03b4(E(x, s) = h)dx\nHere, we have used the fact that the encoder is a deterministic transformation and thus the distribution pE(h | x, s) is merely a delta function denoted by \u03b4(\u00b7). Intuitively, h absorbs the randomness in x\nand has an implicit distribution of its own. Also, note that the joint distribution p\u0303(h, s, y) depends on the transformation defined by the encoder.\nThus, we can equivalently rewrite objective (1) as\nJ(E,M,D) = E h,s,y\u223cp\u0303(h,s,y) [\u03b3 log qD(s | h)\u2212 log qM (y | h)] (2)\nTo analyze the equilibrium condition of the new objective (2), we first deduce the optimal discriminator D and the optimal predictor M for a given encoder E and then prove the global optimality of the minimax game.\nClaim 1. Given a fixed encoder E, the optimal discriminator outputs q\u2217D(s | h) = p\u0303(s | h) and the optimal predictor corresponds to q\u2217M (y | h) = p\u0303(y | h).\nProof. The proof uses the fact that the objective is functionally convex w.r.t. each distribution, and by taking the variations we can obtain the stationary point for qD and qM as a function of q\u0303. The detailed proof is included in the supplementary material A.\nNote that the optimal q\u2217D(s | h) and q\u2217M (y | h) given in Claim 1 are both functions of the encoder E. Thus, by plugging q\u2217D and q \u2217 M into the original minimax objective (2), it can be simplified as a minimization problem only w.r.t. the encoder E with the following form:\nmin E J(E) = min E E h,s,y\u223cq\u0303(h,s,y) [\u03b3 log q\u0303(s | h)\u2212 log q\u0303(y | h)]\n= min E \u2212\u03b3H(q\u0303(s | h)) +H(q\u0303(y | h))\n(3)\nwhere H(q\u0303(s | h)) is the conditional entropy of the distribution q\u0303(s | h). As we can see, the objective (3) consists of two conditional entropies with different signs. Optimizing the first term amounts to maximizing the uncertainty of inferring s based on h, which is essentially filtering out any information of s from the representation. On the contrary, optimizing the second term leads to increasing the certainty of predicting y based on h. Implicitly, the objective defines the equilibrium of the minimax game.\n\u2022 Firstly, for cases where the attribute s is entirely irrelevant to the prediction task, the two terms can reach the optimum at the same time, leading to a win-win equilibrium. For example, with the lighting condition of an image removed, we can still/better classify the identity of the people in that image. With enough model capacity, the optimal equilibrium solution would be the same regardless of the value of \u03b3.\n\u2022 However, there are cases where these two optimization objectives are competing. For example, in fair classifications, sensitive factors such as gender and age may help the overall prediction accuracies. Hence learning a fair/invariant representation is harmful to predictions. In this case, the optimality of these two entropies cannot be achieved simultaneously, and \u03b3 defines the relative strengths of the two objectives in the final equilibrium."}, {"heading": "5 Parametric Instantiation of the Proposed Framework", "text": ""}, {"heading": "5.1 Models", "text": "To show the general applicability of our framework, we experiment on three different tasks including sentence generation, image classification and fair classifications. Due to the different natures of data of x and y, here we present the specific model instantiations we use.\nSentence Generation We use multi-lingual machine translation as the testbed for sentence generation. Concretely, we have translation pairs between several source languages and a target language. x is the source sentence to be translated and s is a scalar denoting which source language x belongs to. y is the translated sentence for the target language.\nRecall that s is used as an input of E to obtain a language-invariant representation. To make full use of s, we employ separate encoders Encs for sentences in each language s. In other words, h = E(s, x) = Encs(x) where each Encs is a different encoder. The representation of a sentence is\ncaptured by the hidden states of an LSTM encoder [Hochreiter and Schmidhuber, 1997] at each time step.\nWe employ a single LSTM predictor for different encoders. As often used in language generation, the probability qM output by the predictor is parametrized by an autoregressive process, i.e.,\nqM (y1:T | h) = T\u220f\nt=1\nqM (yt|y<t, h)\nwhere we use an LSTM with attention model [Bahdanau et al., 2015] to compute qM (yt|y<t, h). The discriminator is also parameterized as an LSTM which gives it enough capacity to deal with input of multiple timesteps. qD(s | h) is instantiated with the multinomial distribution computed by a softmax layer on the last hidden state of the discriminator LSTM.\nClassification For our classification experiments, the input is either a picture or a feature vector. All of the three players in the minimax game are constructed by feedforward neural networks. We feed s to the encoder as an embedding vector."}, {"heading": "5.2 Optimization", "text": "There are two possible approaches to optimize our framework in an adversarial setting. The first one is similar to the alternating approach used in Generative Adversarial Nets (GANs) [Goodfellow et al., 2014]. We can alternately train the two adversarial components while freezing the third one. This approach has more control in balancing the encoder and the discriminator, which effectively avoids saturation. Another method is to train all three components together with a gradient reversal layer [Ganin and Lempitsky, 2015]. In particular, the encoder admits gradients from both the discriminator and the predictor, with the gradient from the discriminator negated to push the encoder in the opposite direction desired by the discriminator. Chen et al. [2016b] found the second approach easier to optimize since the discriminator and the encoder are fully in sync being optimized altogether. Hence we adopt the latter approach. In all of our experiments, we use Adam [Kingma and Ba, 2014] with a learning rate of 0.001."}, {"heading": "6 Experiments", "text": "In this section, we perform empirical experiments to evaluate the effectiveness of proposed framework. We first introduce the tasks and corresponding datasets we consider. Then, we present the quantitative results showing the superior performance of our proposed framework, and discuss some qualitative analysis which verifies the learned representations have the desired invariance property."}, {"heading": "6.1 Datasets", "text": "Our experiments include three tasks in different domains: (1) fair classification, in which predictions should be unaffected by nuisance factors; (2) language-independent generation which is conducted on the multi-lingual machine translation problem; (3) lighting-independent image classification.\nFair Classification For fair classification, we use three datasets to predict the savings, credit ratings and health conditions of individuals with variables such as gender or age specified as \u201cnuisance variable\u201d that we would like to not consider in our decisions [Zemel et al., 2013, Louizos et al., 2016]. The German dataset [Frank et al., 2010] is a small dataset with 1, 000 samples describing whether a person has a good credit rating. The sensitive nuisance variable to be factored out is gender. The Adult income dataset [Frank et al., 2010] has 45, 222 data points and the objective is to predict whether a person has savings of over 50, 000 dollars with the sensitive factor being age. The task of the health dataset1 is to predict whether a person will spend any days in the hospital in the following year. The sensitive variable is also the age and the dataset contains 147, 473 entries. We follow the same 5-fold train/validation/test splits and feature preprocessing used in [Zemel et al., 2013, Louizos et al., 2016].\n1www.heritagehealthprize.com\nBoth the encoder and the predictor are parameterized by single-layer neural networks. A three-layer neural network with batch normalization [Ioffe and Szegedy, 2015] is employed for the discriminator. We use a batch size of 16 and the number of hidden units is set to 64. \u03b3 is set to 1 in our experiments.\nMulti-lingual Machine Translation For the multi-lingual machine translation task we use French to English (fr-en) and German to English (de-en) pairs from IWSLT 2015 dataset [Cettolo et al., 2012]. There are 198, 435 pairs of fr-en sentences and 188, 661 pairs of de-en sentences in the training set. In the test set, there are 4, 632 pairs of fr-en sentences and 7, 054 pairs of de-en sentences. We evaluate BLEU scores [Papineni et al., 2002] using the standard Moses multi-bleu.perl script. Here, s indicates the language of the source sentence.\nWe use the OpenNMT [Klein et al., 2017] in our multi-lingual MT experiments. The encoder is a two-layer bidirectional LSTM with 256 units for each direction. The discriminator is a one-layer single-directional LSTM with 256 units. The predictor is a two-layer LSTM with 512 units and attention mechanism [Bahdanau et al., 2015]. We follow Johnson et al. [2016] and use Byte Pair Encoding (BPE) subword units [Sennrich et al., 2016] as the cross-lingual input. Every model is run for 20 epochs. \u03b3 is set to 8 and the batch size is set to 64.\nImage Classification We use the Extended Yale B dataset [Georghiades et al., 2001] for our image classification task. It comprises face images of 38 people under 5 different lighting conditions: upper right, lower right, lower left, upper left, or the front. The variable s to be purged is the lighting condition. The label y is the identity of the person. We follow Li et al. [2014], Louizos et al. [2016]\u2019s train/test split and no validation is used: 38 \u00d7 5 = 190 samples are used for training and all other 1, 096 data points are used for testing.\nWe use a one-layer neural network for the encoder and a one-layer neural network for prediction. \u03b3 is set to 2. The discriminator is a two-layer neural network with batch normalization. The batch size is set to 16 and the hidden size is set to 100."}, {"heading": "6.2 Results", "text": "Fair Classification The results on three fairness tasks are shown in Figure 1. We compare our model with two prior works on learning fair representations: Learning Fair Representations (LFR) [Zemel et al., 2013] and Variational Fair Autoencoder (VFAE) [Louizos et al., 2016]. Results of VAE and directly using x as the representation are also shown.\nWe first study how much information about s is retained in the learned representation h by using a logistic regression to predict factor s. In the top row, we see that s cannot be recognized from the representations learned by three models targeting at fair representations. The accuracy of classifying s is similar to the trivial baseline predicting the majority label shown by the black line.\nThe performance on predicting label y is shown in the second row. We see that LFR and VFAE suffer on Adult and German datasets after removing information of s. In comparison, our model\u2019s performance does not suffer even when making fair predictions. Specifically, on German, our model\u2019s accuracy is 0.744 compared to 0.727 and 0.723 achieved by VFAE and LFR. On Adult, our model\u2019s accuracy is 0.846 while VFAE and LFR have accuracies of 0.813 and 0.823 respectively. On the health dataset, all models\u2019 performances are barely better than the majority baseline. The unsatisfactory performances of all models may be due to the extreme imbalance of the dataset, in which 85% of the data has the same label.\nWe also investigate how fair representations would alleviate biases of machine learning models. We measure the unbiasedness by evaluating models\u2019 performances on identifying minority groups. For instance, suppose the task is to predict savings with the nuisance factor being age, with savings above a threshold of $50, 000 being adequate, otherwise being insufficient. If people of advanced age generally have fewer savings, then a biased model would tend to predict insufficient savings for those with an advanced age. In contrast, an unbiased model can better factor out age information and recognize people that do not fit into these stereotypes.\nConcretely, for groups pooled by each possible value of y, we seek for the minority s in each of these groups and define the minority s as the biased category for the group. Then we first calculate the accuracy on each biased category and report the average performance for all categories. We do not\ncompute the instance-level average performance since one category may hold the dominant amount of data among all categories.\nAs shown in the third row of Figure 1, on German and Adult, we achieve higher accuracy on the biased categories, even though our overall accuracy is similar to or lower than the baseline which does not employ fairness constraints. Specifically, on Adult, our performance on the biased categories is 0.796 while the baseline\u2019s accuracy is 0.748. On German, our accuracy on biased categories is 0.674 while the baseline achieves 0.648. The results show that our model is able to learn a more unbiased representation.\nMulti-lingual Machine Translation The results of systems on multi-lingual machine translation are shown in Table 1. We compare our model with attention based encoder-decoder trained on bilingual data [Bahdanau et al., 2015] and multi-lingual data [Johnson et al., 2016]. The encoderdecoder trained on multi-lingual data employs a single encoder for both source languages. Firstly, both multi-lingual systems outperform the bilingual encoder-decoder even though multi-lingual\nsystems use similar number of parameters to translate two languages, which shows that learning invariant representation leads to better generalization in this case. The better generalization may be due to transferring statistical strength between data in two languages.\nComparing two multi-lingual systems, our model outperforms the baseline multi-lingual system on both languages, where the improvement on French-to-English is 0.6 BLEU score. We also verify the design decisions in our framework by ablation studies. Firstly, without the discriminator, the model\u2019s performance is worse than the standard multi-lingual system, which rules out the possibility that the gain of our model comes from more parameters of separate encoders. Secondly, when we do not employ separate encoders, the model\u2019s performance deteriorates and it is more difficult to learn a cross-lingual representation, which means that the encoder needs to have enough capacity to reach the equilibrium in the minimax game.\nImage Classification We report the results in Table 2 with two baselines [Li et al., 2014, Louizos et al., 2016] that use MMD regularizations to remove lighting conditions. The advantage of factoring out lighting conditions is shown by the improved accuracy 89% for classifying identities, while the best baseline achieves an accuracy of 85%.\nIn terms of removing s, our framework can filter the lighting conditions since the accuracy of classifying s drops from 0.96 to 0.57, as shown in Table 2. We also visualize the learned representation by t-SNE [Maaten and Hinton, 2008] in comparison to the visualization of original pictures in Figure 2. We see that, without removing lighting conditions, the images are clustered based on the lighting conditions. After removing information of lighting conditions, images are clustered according to the identity of each person."}, {"heading": "7 Conclusion", "text": "In sum, we propose a generic framework to learn representations invariant to a specified factor or trait. We cast the representation learning problem as an adversarial game among an encoder, a discriminator,\nand a predictor. We theoretically analyze the optimal equilibrium of the minimax game and evaluate the performance of our framework on three tasks from different domains empirically. We show that an invariant representation is learned, resulting in better generalization and improvements on the three tasks.\nWe plan to instantiate the framework with methods to deal with s with continuous values or structured values in the future."}, {"heading": "A Supplementary Material: Proofs", "text": "The proof for Claim 1: Claim. Given a fixed encoder E, the optimal discriminator outputs q\u2217D(s | h) = p\u0303(s | h). The optimal predictor corresponds to q\u2217M (y | h) = p\u0303(y | h).\nProof. We first prove the optimal solution of the discriminator. With a fixed encoder, we have the following optimization problem\nmin qD\n\u2212 J(E,M,D)\ns.t. \u2211 s qD(s | h) = 1,\u2200h\nThen L = J(E,M,D) \u2212 \u2211 h \u03bb(h) \u2211\ns qD(s | h) is the Lagrangian dual function of the above optimization problem where \u03bb(h) are the dual variables introduced for equality constraints.\nThe optimal D satisfies the following equation\n0 = \u2202L\n\u2202q\u2217D(s | h)\n\u21d0\u21d2 0 = \u2212 \u2202J \u2202q\u2217D(s | h) \u2212 \u03bb(h)\n\u21d0\u21d2 \u03bb(h) = \u2212 \u2211 y q\u0303(h, s, y) q\u2217D(s | h) \u21d0\u21d2 \u03bb(h)q\u2217D(s | h) = \u2212q\u0303(s, h)\n(4)\nSumming w.r.t. s on both sides of the last line of Eqn. (4) and using the fact that \u2211\ns q \u2217 D(s | h) = 1,\nwe get \u03bb(h) = \u2212q\u0303(h) (5)\nSubstituting Eqn. 5 back into Eqn. 4, we can prove the optimal discriminator is\nq\u2217D(s | h) = q\u0303(s | h)\nSimilarly, taking derivation w.r.t. qM (y | h) and setting it to 0, we can prove q\u2217M (y | h) = q\u0303(y | h)."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "venue": null, "citeRegEx": "Bahdanau et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Representation learning: A review and new perspectives", "author": ["Yoshua Bengio", "Aaron Courville", "Pascal Vincent"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Domain separation networks", "author": ["Konstantinos Bousmalis", "George Trigeorgis", "Nathan Silberman", "Dilip Krishnan", "Dumitru Erhan"], "venue": "In NIPS,", "citeRegEx": "Bousmalis et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bousmalis et al\\.", "year": 2016}, {"title": "Wit3: Web inventory of transcribed and translated talks", "author": ["Mauro Cettolo", "Christian Girardi", "Marcello Federico"], "venue": "In Proceedings of the 16th Conference of the European Association for Machine Translation (EAMT),", "citeRegEx": "Cettolo et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cettolo et al\\.", "year": 2012}, {"title": "Infogan: Interpretable representation learning by information maximizing generative adversarial nets", "author": ["Xi Chen", "Yan Duan", "Rein Houthooft", "John Schulman", "Ilya Sutskever", "Pieter Abbeel"], "venue": "In NIPS,", "citeRegEx": "Chen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Adversarial deep averaging networks for cross-lingual sentiment classification", "author": ["Xilun Chen", "Yu Sun", "Ben Athiwaratkun", "Claire Cardie", "Kilian Weinberger"], "venue": "arXiv preprint arXiv:1606.01614,", "citeRegEx": "Chen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Unsupervised domain adaptation by backpropagation", "author": ["Yaroslav Ganin", "Victor Lempitsky"], "venue": null, "citeRegEx": "Ganin and Lempitsky.,? \\Q2015\\E", "shortCiteRegEx": "Ganin and Lempitsky.", "year": 2015}, {"title": "From few to many: Illumination cone models for face recognition under variable lighting and pose", "author": ["Athinodoros S. Georghiades", "Peter N. Belhumeur", "David J. Kriegman"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "Georghiades et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Georghiades et al\\.", "year": 2001}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In NIPS,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Approximation by superposition of sigmoidal functions", "author": ["G Gybenko"], "venue": "Mathematics of Control, Signals and Systems,", "citeRegEx": "Gybenko.,? \\Q1989\\E", "shortCiteRegEx": "Gybenko.", "year": 1989}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Sergey Ioffe", "Christian Szegedy"], "venue": "arXiv preprint arXiv:1502.03167,", "citeRegEx": "Ioffe and Szegedy.,? \\Q2015\\E", "shortCiteRegEx": "Ioffe and Szegedy.", "year": 2015}, {"title": "Google\u2019s multilingual neural machine translation system: Enabling zero-shot translation", "author": ["Melvin Johnson", "Mike Schuster", "Quoc V Le", "Maxim Krikun", "Yonghui Wu", "Zhifeng Chen", "Nikhil Thorat", "Fernanda Vi\u00e9gas", "Martin Wattenberg", "Greg Corrado"], "venue": "arXiv preprint arXiv:1611.04558,", "citeRegEx": "Johnson et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma and Ba.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "ICLR,", "citeRegEx": "Kingma and Welling.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Welling.", "year": 2014}, {"title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation", "author": ["G. Klein", "Y. Kim", "Y. Deng", "J. Senellart", "A.M. Rush"], "venue": "ArXiv e-prints,", "citeRegEx": "Klein et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Klein et al\\.", "year": 2017}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Learning unbiased features", "author": ["Yujia Li", "Kevin Swersky", "Richard Zemel"], "venue": "arXiv preprint arXiv:1412.5244,", "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "The variational fair autoencoder", "author": ["Christos Louizos", "Kevin Swersky", "Yujia Li", "Max Welling", "Richard Zemel"], "venue": null, "citeRegEx": "Louizos et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Louizos et al\\.", "year": 2016}, {"title": "Visualizing data using t-sne", "author": ["Laurens van der Maaten", "Geoffrey Hinton"], "venue": null, "citeRegEx": "Maaten and Hinton.,? \\Q2008\\E", "shortCiteRegEx": "Maaten and Hinton.", "year": 2008}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "In ACL,", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Danilo Jimenez Rezende", "Shakir Mohamed", "Daan Wierstra"], "venue": null, "citeRegEx": "Rezende et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "Neural machine translation of rare words with subword units", "author": ["Rico Sennrich", "Barry Haddow", "Alexandra Birch"], "venue": null, "citeRegEx": "Sennrich et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sennrich et al\\.", "year": 2016}, {"title": "Separating style and content", "author": ["Joshua B Tenenbaum", "William T Freeman"], "venue": null, "citeRegEx": "Tenenbaum and Freeman.,? \\Q1997\\E", "shortCiteRegEx": "Tenenbaum and Freeman.", "year": 1997}, {"title": "Adversarial discriminative domain adaptation", "author": ["Eric Tzeng", "Judy Hoffman", "Kate Saenko", "Trevor Darrell"], "venue": "arXiv preprint arXiv:1702.05464,", "citeRegEx": "Tzeng et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Tzeng et al\\.", "year": 2017}, {"title": "Cross-lingual distillation for text classification", "author": ["Ruochen Xu", "Yiming Yang"], "venue": null, "citeRegEx": "Xu and Yang.,? \\Q2017\\E", "shortCiteRegEx": "Xu and Yang.", "year": 2017}, {"title": "SamingerPlatz. Central moment discrepancy (cmd) for domain-invariant representation learning", "author": ["Werner Zellinger", "Thomas Grubinger", "Edwin Lughofer", "Thomas Natschl\u00e4ger", "Susanne"], "venue": null, "citeRegEx": "Zellinger et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Zellinger et al\\.", "year": 2017}, {"title": "Learning fair representations", "author": ["Richard S Zemel", "Yu Wu", "Kevin Swersky", "Toniann Pitassi", "Cynthia Dwork"], "venue": null, "citeRegEx": "Zemel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zemel et al\\.", "year": 2013}, {"title": "Understanding deep learning requires rethinking generalization", "author": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "venue": null, "citeRegEx": "Zhang et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2017}], "referenceMentions": [{"referenceID": 1, "context": "In the last few years, the dominant paradigm for finding such a representation has shifted from manual feature engineering based on specific domain knowledge to representation learning that is fully data-driven, and often powered by deep neural networks [Bengio et al., 2013].", "startOffset": 254, "endOffset": 275}, {"referenceID": 9, "context": "Being universal function approximators [Gybenko, 1989], deep neural networks can easily uncover the complicated variations in data [Zhang et al.", "startOffset": 39, "endOffset": 54}, {"referenceID": 28, "context": "Being universal function approximators [Gybenko, 1989], deep neural networks can easily uncover the complicated variations in data [Zhang et al., 2017], leading to powerful representations.", "startOffset": 131, "endOffset": 151}, {"referenceID": 16, "context": "As a typical example, the parameter sharing scheme and pooling mechanism in modern deep convolutional neural networks (CNN) [LeCun et al., 1998] take advantage of the spatial structure of image processing problems, allowing them to induce more generic feature representations than fully connected networks.", "startOffset": 124, "endOffset": 144}, {"referenceID": 18, "context": "For instance, the variational fair auto-encoder (VFAE) [Louizos et al., 2016] employs the maximum mean discrepancy (MMD) to eliminate the negative influence of specific \u201cnuisance variables\u201d, such as removing the lighting conditions of images to predict the person\u2019s identity in the image.", "startOffset": 55, "endOffset": 77}, {"referenceID": 6, "context": "Similarly, under the setting of domain adaptation, standard binary adversarial cost [Ganin and Lempitsky, 2015] and central moment discrepancy (CMD) [Zellinger et al.", "startOffset": 84, "endOffset": 111}, {"referenceID": 26, "context": "Similarly, under the setting of domain adaptation, standard binary adversarial cost [Ganin and Lempitsky, 2015] and central moment discrepancy (CMD) [Zellinger et al., 2017] have been utilized to learn features that are domain invariant.", "startOffset": 149, "endOffset": 173}, {"referenceID": 8, "context": "Specifically, inspired by the recent advancement of adversarial learning [Goodfellow et al., 2014], we formulate the representation learning as a minimax game among three players: an encoder which maps the observed data deterministically into a feature space, a discriminator which looks at the representation and tries to identify a specific type of variation we hope to eliminate from the feature, and a predictor which makes use of the invariant representation to make predictions as in typical discriminative models.", "startOffset": 73, "endOffset": 98}, {"referenceID": 18, "context": "The Variational Fair Autoencoder [Louizos et al., 2016] targets the problem with a Variational Autoencoder [Kingma and Welling, 2014, Rezende et al.", "startOffset": 33, "endOffset": 55}, {"referenceID": 2, "context": "For example, in image classification, adversarial training has been shown to able to learn an invariant representation across domains [Ganin and Lempitsky, 2015, Bousmalis et al., 2016, Tzeng et al., 2017] and enables classifiers trained on the source domain to be applicable to the target domain. Moment discrepancy regularizations can also effectively remove domain specific information [Zellinger et al., 2017, Bousmalis et al., 2016] for the same purpose. By learning language-invariant representations, classifiers trained on the source language can be applied to the target language [Chen et al., 2016b, Xu and Yang, 2017]. Works targeting the development of fair, bias-free classifiers also aim to learn representations invariant to \u201cnuisance variables\u201d that could induce bias and hence makes the predictions fair, as data-driven models trained using historical data easily inherit the bias exhibited in the data. Zemel et al. [2013] proposes to regularize the `1 distance between representation distributions for data with different nuisance variables to enforce fairness.", "startOffset": 162, "endOffset": 941}, {"referenceID": 2, "context": "For example, in image classification, adversarial training has been shown to able to learn an invariant representation across domains [Ganin and Lempitsky, 2015, Bousmalis et al., 2016, Tzeng et al., 2017] and enables classifiers trained on the source domain to be applicable to the target domain. Moment discrepancy regularizations can also effectively remove domain specific information [Zellinger et al., 2017, Bousmalis et al., 2016] for the same purpose. By learning language-invariant representations, classifiers trained on the source language can be applied to the target language [Chen et al., 2016b, Xu and Yang, 2017]. Works targeting the development of fair, bias-free classifiers also aim to learn representations invariant to \u201cnuisance variables\u201d that could induce bias and hence makes the predictions fair, as data-driven models trained using historical data easily inherit the bias exhibited in the data. Zemel et al. [2013] proposes to regularize the `1 distance between representation distributions for data with different nuisance variables to enforce fairness. The Variational Fair Autoencoder [Louizos et al., 2016] targets the problem with a Variational Autoencoder [Kingma and Welling, 2014, Rezende et al., 2014] approach with maximum mean discrepancy regularization. Our work is also related to learning disentangled representations, where the aim is to separate different influencing factors of the input data into different parts of the representation. Ideally, each part of the learned representation can be marginally independent to the other. An early work by Tenenbaum and Freeman [1997] propose a bilinear model to learn a representation with the style and content disentangled.", "startOffset": 162, "endOffset": 1619}, {"referenceID": 2, "context": "For example, in image classification, adversarial training has been shown to able to learn an invariant representation across domains [Ganin and Lempitsky, 2015, Bousmalis et al., 2016, Tzeng et al., 2017] and enables classifiers trained on the source domain to be applicable to the target domain. Moment discrepancy regularizations can also effectively remove domain specific information [Zellinger et al., 2017, Bousmalis et al., 2016] for the same purpose. By learning language-invariant representations, classifiers trained on the source language can be applied to the target language [Chen et al., 2016b, Xu and Yang, 2017]. Works targeting the development of fair, bias-free classifiers also aim to learn representations invariant to \u201cnuisance variables\u201d that could induce bias and hence makes the predictions fair, as data-driven models trained using historical data easily inherit the bias exhibited in the data. Zemel et al. [2013] proposes to regularize the `1 distance between representation distributions for data with different nuisance variables to enforce fairness. The Variational Fair Autoencoder [Louizos et al., 2016] targets the problem with a Variational Autoencoder [Kingma and Welling, 2014, Rezende et al., 2014] approach with maximum mean discrepancy regularization. Our work is also related to learning disentangled representations, where the aim is to separate different influencing factors of the input data into different parts of the representation. Ideally, each part of the learned representation can be marginally independent to the other. An early work by Tenenbaum and Freeman [1997] propose a bilinear model to learn a representation with the style and content disentangled. From information theory perspective, Chen et al. [2016a] augments standard generative adversarial networks with an inference network, whose objective is to infer part of the latent code that leads to the generated sample.", "startOffset": 162, "endOffset": 1768}, {"referenceID": 10, "context": "captured by the hidden states of an LSTM encoder [Hochreiter and Schmidhuber, 1997] at each time step.", "startOffset": 49, "endOffset": 83}, {"referenceID": 0, "context": "where we use an LSTM with attention model [Bahdanau et al., 2015] to compute qM (yt|y<t, h).", "startOffset": 42, "endOffset": 65}, {"referenceID": 8, "context": "The first one is similar to the alternating approach used in Generative Adversarial Nets (GANs) [Goodfellow et al., 2014].", "startOffset": 96, "endOffset": 121}, {"referenceID": 6, "context": "Another method is to train all three components together with a gradient reversal layer [Ganin and Lempitsky, 2015].", "startOffset": 88, "endOffset": 115}, {"referenceID": 13, "context": "In all of our experiments, we use Adam [Kingma and Ba, 2014] with a learning rate of 0.", "startOffset": 39, "endOffset": 60}, {"referenceID": 4, "context": "Chen et al. [2016b] found the second approach easier to optimize since the discriminator and the encoder are fully in sync being optimized altogether.", "startOffset": 0, "endOffset": 20}, {"referenceID": 11, "context": "A three-layer neural network with batch normalization [Ioffe and Szegedy, 2015] is employed for the discriminator.", "startOffset": 54, "endOffset": 79}, {"referenceID": 3, "context": "Multi-lingual Machine Translation For the multi-lingual machine translation task we use French to English (fr-en) and German to English (de-en) pairs from IWSLT 2015 dataset [Cettolo et al., 2012].", "startOffset": 174, "endOffset": 196}, {"referenceID": 20, "context": "We evaluate BLEU scores [Papineni et al., 2002] using the standard Moses multi-bleu.", "startOffset": 24, "endOffset": 47}, {"referenceID": 15, "context": "We use the OpenNMT [Klein et al., 2017] in our multi-lingual MT experiments.", "startOffset": 19, "endOffset": 39}, {"referenceID": 0, "context": "The predictor is a two-layer LSTM with 512 units and attention mechanism [Bahdanau et al., 2015].", "startOffset": 73, "endOffset": 96}, {"referenceID": 22, "context": "[2016] and use Byte Pair Encoding (BPE) subword units [Sennrich et al., 2016] as the cross-lingual input.", "startOffset": 54, "endOffset": 77}, {"referenceID": 0, "context": "The predictor is a two-layer LSTM with 512 units and attention mechanism [Bahdanau et al., 2015]. We follow Johnson et al. [2016] and use Byte Pair Encoding (BPE) subword units [Sennrich et al.", "startOffset": 74, "endOffset": 130}, {"referenceID": 7, "context": "Image Classification We use the Extended Yale B dataset [Georghiades et al., 2001] for our image classification task.", "startOffset": 56, "endOffset": 82}, {"referenceID": 7, "context": "Image Classification We use the Extended Yale B dataset [Georghiades et al., 2001] for our image classification task. It comprises face images of 38 people under 5 different lighting conditions: upper right, lower right, lower left, upper left, or the front. The variable s to be purged is the lighting condition. The label y is the identity of the person. We follow Li et al. [2014], Louizos et al.", "startOffset": 57, "endOffset": 384}, {"referenceID": 7, "context": "Image Classification We use the Extended Yale B dataset [Georghiades et al., 2001] for our image classification task. It comprises face images of 38 people under 5 different lighting conditions: upper right, lower right, lower left, upper left, or the front. The variable s to be purged is the lighting condition. The label y is the identity of the person. We follow Li et al. [2014], Louizos et al. [2016]\u2019s train/test split and no validation is used: 38 \u00d7 5 = 190 samples are used for training and all other 1, 096 data points are used for testing.", "startOffset": 57, "endOffset": 407}, {"referenceID": 27, "context": "We compare our model with two prior works on learning fair representations: Learning Fair Representations (LFR) [Zemel et al., 2013] and Variational Fair Autoencoder (VFAE) [Louizos et al.", "startOffset": 112, "endOffset": 132}, {"referenceID": 18, "context": ", 2013] and Variational Fair Autoencoder (VFAE) [Louizos et al., 2016].", "startOffset": 48, "endOffset": 70}, {"referenceID": 0, "context": "Model test (fr-en) test (de-en) Bilingual Enc-Dec [Bahdanau et al., 2015] 35.", "startOffset": 50, "endOffset": 73}, {"referenceID": 12, "context": "3 Multi-lingual Enc-Dec [Johnson et al., 2016] 35.", "startOffset": 24, "endOffset": 46}, {"referenceID": 0, "context": "We compare our model with attention based encoder-decoder trained on bilingual data [Bahdanau et al., 2015] and multi-lingual data [Johnson et al.", "startOffset": 84, "endOffset": 107}, {"referenceID": 12, "context": ", 2015] and multi-lingual data [Johnson et al., 2016].", "startOffset": 31, "endOffset": 53}, {"referenceID": 17, "context": "78 NN + MMD [Li et al., 2014] 0.", "startOffset": 12, "endOffset": 29}, {"referenceID": 18, "context": "82 VFAE [Louizos et al., 2016] 0.", "startOffset": 8, "endOffset": 30}, {"referenceID": 19, "context": "We also visualize the learned representation by t-SNE [Maaten and Hinton, 2008] in comparison to the visualization of original pictures in Figure 2.", "startOffset": 54, "endOffset": 79}], "year": 2017, "abstractText": "Learning meaningful representations that maintain the content necessary for a particular task while filtering away detrimental variations is a problem of great interest in machine learning. In this paper, we tackle the problem of learning representations invariant to a specific factor or trait of data, leading to better generalization. The representation learning process is formulated as an adversarial minimax game. We analyze the optimal equilibrium of such a game and find that it amounts to maximizing the uncertainty of inferring the detrimental factor given the representation while maximizing the certainty of making task-specific predictions. On three benchmark tasks, namely fair and bias-free classification, language-independent generation, and lighting-independent image classification, we show that the proposed framework induces an invariant representation, and leads to better generalization evidenced by the improved test performance.", "creator": "LaTeX with hyperref package"}}}