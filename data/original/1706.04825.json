{"id": "1706.04825", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2017", "title": "Towards Grounding Conceptual Spaces in Neural Representations", "abstract": "The highly influential framework of conceptual spaces provides a geometric way of representing knowledge. It aims at bridging the gap between symbolic and subsymbolic processing. Instances are represented by points in a high-dimensional space and concepts are represented by convex regions in this space. In this paper, we present our approach towards grounding the dimensions of a conceptual space in latent spaces learned by an InfoGAN from unlabeled data.", "histories": [["v1", "Thu, 15 Jun 2017 11:59:06 GMT  (203kb,D)", "http://arxiv.org/abs/1706.04825v1", "accepted at NeSy 2017"]], "COMMENTS": "accepted at NeSy 2017", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["lucas bechberger", "kai-uwe k\\\"uhnberger"], "accepted": false, "id": "1706.04825"}, "pdf": {"name": "1706.04825.pdf", "metadata": {"source": "CRF", "title": "Towards Grounding Conceptual Spaces in Neural Representations", "authors": ["Lucas Bechberger", "Kai-Uwe K\u00fchnberger"], "emails": ["lucas.bechberger@uni-osnabrueck.de,", "kai-uwe.kuehnberger@uni-osnabrueck.de"], "sections": [{"heading": "1 Introduction", "text": "The cognitive framework of conceptual spaces [13,14] attempts to bridge the gap between symbolic and subsymbolic AI by proposing an intermediate conceptual layer based on geometric representations. A conceptual space is a highdimensional space spanned by a number of quality dimensions representing interpretable features. Convex regions in this space correspond to concepts. Abstract symbols can be grounded by linking them to concepts in a conceptual space whose dimensions are based on subsymbolic representations.\nThe framework of conceptual spaces has been highly influential in the last 15 years within cognitive science and cognitive linguistics [10,12,20]. It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].\nAlthough this framework provides means for representing concepts, it does not consider the question of how these concepts can be learned from mostly unlabeled data. Moreover, the framework assumes that the dimensions spanning the conceptual space are already given a priori. In practical applications of the framework, they thus often need to be handcrafted by a human expert.\nIn this paper, we argue that by using neural networks, one can automatically extract the dimensions of a conceptual space from unlabeled data. We propose that latent spaces learned by an InfoGAN [7] (a special class of Generative Adversarial Networks [16]) can serve as domains in the conceptual spaces framework. We further propose to use a clustering algorithm in these latent spaces in order to discover meaningful concepts.\nar X\niv :1\n70 6.\n04 82\n5v 1\n[ cs\n.A I]\n1 5\nJu n\n20 17\n2 The remainder of this paper is structured as follows: Section 2 presents the framework of conceptual spaces and Section 3 introduces the InfoGAN framework. In Section 4, we present our idea of combining these two frameworks. Section 5 gives an illustrative example and Section 6 concludes the paper."}, {"heading": "2 Conceptual Spaces", "text": "A conceptual space [13] is a high-dimensional space spanned by so-called \u201cquality dimensions\u201d. Each of these dimensions represents an interpretable way in which two stimuli can be judged to be similar or different. Examples for quality dimensions include temperature, weight, time, pitch, and hue. A domain is a set of dimensions that inherently belong together. Different perceptual modalities (like color, shape, or taste) are represented by different domains. The color domain for instance consists of the three dimensions hue, saturation, and brightness. Distance within a domain is measured by the Euclidean metric.\nThe overall conceptual space is defined as the product space of all dimensions. Distance within the overall conceptual space is measured by the Manhattan metric of the intra-domain distances. The similarity of two points in a conceptual space is inversely related to their distance \u2013 the closer two instances are in the conceptual space, the more similar they are considered to be.\nThe framework distinguishes properties like \u201cred\u201d, \u201cround\u201d, and \u201csweet\u201d from full-fleshed concepts like \u201capple\u201d or \u201cdog\u201d: Properties are represented as regions within individual domains (e.g., color, shape, taste), whereas full-fleshed concepts span multiple domains. Reasoning within a conceptual space can be done based on geometric relationships (e.g., betweenness and similarity) and geometric operations (e.g., intersection or projection).\nIf the dimensions of a conceptual space are based on perception and if regions in this space are linked to abstract symbols, this framework can be used for symbol grounding [17]."}, {"heading": "3 Representation Learning with InfoGAN", "text": "Within the research area of neural networks, there has been some substantial work on learning compressed representations of a given feature space. Bengio et al. [2] provide a thorough overview of different approaches in the representation learning area. They define representation learning as \u201clearning representations of the data that make it easier to extract useful information when building classifiers or other predictors\u201d. We will focus our discussion here on one specific approach that is particularly fitting to our proposal, namely InfoGAN [7]. InfoGAN is an extension of the GAN (Generative Adversarial Networks) framework [16] which has been applied to a variety of problems (e.g., [11,18,21,22,23]). We will first describe the original GAN framework before moving on to InfoGAN.\n3\nThe GAN framework (depicted in the left part of Figure 1) consists of two networks, the generator and the discriminator. The generator is fed with a lowdimensional vector of noise values. Its task is to create high-dimensional data vectors that have a similar distribution as real data vectors taken from an unlabeled training set. The discriminator receives a data vector that was either created by the generator or taken from the training set. Its task is to distinguish real inputs from generated inputs. Although the discriminator is trained on a classification task, the overall system works in an unsupervised way. The overall architecture can be interpreted as a two-player game: The generator tries to fool the discriminator by creating realistic inputs and the discriminator tries to avoid being fooled by the generator. When the GAN framework converges, the discriminator is expected to make predictions only at chance level and the generator is expected to create realistic data vectors. Although the overall framework works quite well, one cannot deliberately generate data vectors with specific desired properties, because the dimensions of the input noise vector are usually not interpretable.\nChen et al. [7] have extended the original framework by introducing latent variables: In the InfoGAN framework (shown in the right part of Figure 1), the generator receives an additional input vector. The entries of this vector are values of latent random variables, selected based on some probability distribution that was defined a priori (e.g., uniform or Gaussian). The discriminator has the additional task to reconstruct these latent variables. Chen et al. argue that this ensures that the mutual information between the latent variable vector and the generated data vector is high. They showed that after training an InfoGAN, the latent variables have an interpretable meaning. For instance, in an experiment on the MNIST data set, the latent variables corresponded to type of digit, digit rotation and stroke thickness. This finding is interesting in two respects: On the one hand, one can now generate data vectors with specific desired properties by manipulating the latent variables that are fed into the generator. On the other hand, one can extract interpretable dimensions from a given data vector by feeding it into the discriminator and observing the latent variable output.\n4"}, {"heading": "4 Using Representation Learning to Ground Domains", "text": "For some domains of a conceptual space, a dimensional representation is already available. For instance, the color domain can be represented by the threedimensional HSB space. For other domains, it is however quite unclear how to represent them based on a handful of dimensions. One prominent example is the shape domain: To the best of our knowledge, there are no widely accepted dimensional models for describing shapes.\nWe propose to use the InfoGAN framework in order to learn such a dimensional representation based on an unlabeled data set: Each of the latent variables can be interpreted as one dimension of the given domain of interest. For instance, the latent variables learned on a data set of shapes can be interpreted as dimensions of the shape domain. Three important properties of domains in a conceptual space are the following: interpretable dimensions, a distance-based notion of similarity, and a geometric way of describing semantic betweenness. We think that the latent space of an InfoGAN is a good candidate for representing domains of a conceptual space, because it fulfills all of the above requirements:\nAs described before, Chen et al. [7] found that the individual latent variables have an interpretable meaning. They can thus be used as interpretable dimensions of a domain.\nMoreover, the smoothness assumption used in representation learning (cf. [2] and [15, Ch. 15]) states that points with small distance in the input space should also have a small distance in the latent space. This means that a distance-based notion of similarity in the latent space is meaningful.\nFinally, Radford et al. [18] found that linear interpolations between points in the latent space of a GAN correspond to a meaningful \u201cmorph\u201d between generated images in the input space. This indicates that geometric betweenness in the latent space can represent semantic betweenness.\nThere are two important hyperparameters to the approach of grounding domains in InfoGANs: The number of latent variables (i.e., the dimensionality of the learned domain) and the type of distribution used for the latent variables (e.g., uniform vs. Gaussian). Note that one would probably aim for the lowestdimensional representation that still describes the domain sufficiently well.\nFinally, we would like to address a critical aspect of this proposal: How can one make sure that the representation learned by the neural network only represents information from the target domain (e.g., shape) and not anything related to other domains (e.g., color)? In our opinion, there are two complementary methods to \u201csteer\u201d the network towards the desired representation:\nThe first option consists of selecting only such inputs for the training set that do not exhibit major differences with respect to other domains. For instance, a training set for the shape domain should only include images of shapes that have the same color (e.g., black shape on white ground). If there is only very small variance in the data set with respect to other domains (e.g., color), the network is quite unlikely to incorporate this information into its latent representation.\n5\nThe second option concerns modifications of the network\u2019s loss function: One could for instance introduce an additional term into the loss function which measures the correlation between the learned latent representation and dimensions from other (already defined) domains. This would cause a stronger error signal if the network starts to re-discover already known dimensions from other domains and therefore drive the network away from learning redundant representations.\nA simple proof of concept implementation for the shape domain could be based on a data set of simple 2D shapes (circles, triangles, rectangles, etc.) in various orientations and locations. For a more thorough experiment, one could for instance use ShapeNet1 [3], a data base of over 50,000 3D models for more than 50 categories of objects. One could render these 3D models from various perspectives in order to get 2D inputs (for learning to represent 2D shapes) or work on a voxelized 3D input (for learning representations of 3D shapes)."}, {"heading": "5 An Illustrative Example", "text": "Figure 2 illustrates a simplified example of our envisioned overall system. Here, we consider only two domains: color and shape. Color can be represented by the HSB space using the three dimensions hue, saturation and brightness. This is an example for a hard-coded domain. The representation of the shape domain, however, needs to be learned. The artificial neural network depicted in Figure\n1 https://www.shapenet.org/\n6 2 corresponds to the discriminator of an InfoGAN trained on a data set of shapes.\nLet us consider two example concepts: The concept of an apple can be described by the \u201cred\u201d region in the color domain and the \u201cround\u201d region in the shape domain. The concept of a banana can be represented by the \u201cyellow\u201d region in the color domain and the \u201ccylindric\u201d region in the shape domain.\nIf the system makes a new observation (e.g., an apple as depticted in Figure 2), it will convert this observation into a point in the conceptual space. For the color domain, this is done by a hard-coded conversion to the HSB color space. For the shape domain, the observation is fed into the discriminator and its latent representation is extracted, resulting in the coordinates for the shape domain. Now in order to classify this observation, the system needs to check whether the resulting data point is contained in any of the defined regions. If the data point is an element of the apple region in both domains (which is the case in our example), this observation should be classified as an apple. If the data point is an element of the banana region, the object should be classified as a banana.\nBased on a new observation, the existing concepts can also be updated: If the observation was classified as an apple, but it is not close to the center of the apple region in one of the domains, this region might be enlarged or moved a bit, such that the observed instance is better matched by the concept description. If the observation does not match any of the given concepts at all, even a new concept might be created. This means that concepts cannot only be applied for classification, but they can also be learned and updated. Note that this can take place without explicit label information, i.e., in an unsupervised way. Our overall reserach goal is to develop a clustering algorithm that can take care of incrementally updating the regions in such a conceptual space.\nPlease note that the updates considered above only concern the connections between the conceptual and the symbolic layer. The connections between the subsymbolic and the conceptual layer remain fixed. The neural network thus only serves as a preprocessing step in our approach: It is trained before the overall system is used and remains unchanged afterwards. Simultaneous updates of both the neural network and the concept description might be desirable, but would probably introduce a great amount of additional complexity."}, {"heading": "6 Conclusion and Future Work", "text": "In this paper, we outlined how neural representations can be used to ground the domains of a conceptual space in perception. This is especially useful for domains like shape, where handcrafting a dimensional representation is difficult. We argued that the latent representations learned by an InfoGAN have suitable properties for being combined with the conceptual spaces framework. In future work, we will implement the proposed idea by giving a neural grounding to the domain of simple 2D shapes. Furthermore, we will devise a clustering algorithm for discovering and updating conceptual representations in a conceptual space.\n7"}], "references": [{"title": "Conceptual Space Markup Language (CSML): Towards the Cognitive Semantic Web", "author": ["Benjamin Adams", "Martin Raubal"], "venue": "IEEE International Conference on Semantic Computing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Representation Learning: A Review and New Perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "ShapeNet: An Information-Rich 3D Model Repository", "author": ["Angel X. Chang", "Thomas Funkhouser", "Leonidas Guibas", "Pat Hanrahan", "Qixing Huang", "Zimo Li", "Silvio Savarese", "Manolis Savva", "Shuran Song", "Hao Su", "Jianxiong Xiao", "Li Yi", "Fisher Yu"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Anchoring by Imitation Learning in Conceptual Spaces", "author": ["Antonio Chella", "Haris Dindo", "Ignazio Infantino"], "venue": "AI*IA 2005: Advances in Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Conceptual Spaces for Computer Vision Representations", "author": ["Antonio Chella", "Marcello Frixione", "Salvatore Gaglio"], "venue": "Artificial Intelligence Review,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Anchoring Symbols to Conceptual Spaces: The Case of Dynamic Scenarios", "author": ["Antonio Chella", "Marcello Frixione", "Salvatore Gaglio"], "venue": "Robotics and Autonomous Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets", "author": ["Xi Chen", "Yan Duan", "Rein Houthooft", "John Schulman", "Ilya Sutskever", "Pieter Abbeel"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Inducing Semantic Relations from Conceptual Spaces: A Data-Driven Approach to Plausible Reasoning", "author": ["Joaqun Derrac", "Steven Schockaert"], "venue": "Artificial Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Exploiting Conceptual Spaces for Ontology Integration. In Data Integration Through Semantic Technology (DIST2008) Workshop at 3rd Asian Semantic Web Conference (ASWC", "author": ["Stefan Dietze", "John Domingue"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Vagueness: A Conceptual Spaces Approach", "author": ["Igor Douven", "Lieven Decock", "Richard Dietz", "Paul \u00c9gr\u00e9"], "venue": "Journal of Philosophical Logic,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Generative Multi-Adversarial Networks", "author": ["Ishan Durugkar", "Ian Gemp", "Sridhar Mahadevan"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Representing Part-Whole Relations in Conceptual Spaces", "author": ["Sandro R. Fiorini", "Peter G\u00e4rdenfors", "Mara Abel"], "venue": "Cognitive Processing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Conceptual Spaces: The Geometry of Thought", "author": ["Peter G\u00e4rdenfors"], "venue": "MIT press,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2000}, {"title": "The Geometry of Meaning: Semantics Based on Conceptual Spaces", "author": ["Peter G\u00e4rdenfors"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Deep Learning", "author": ["Ian Goodfellow", "Yoshua Bengio", "Aaron Courville"], "venue": "http://www.deeplearningbook.org", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Generative Adversarial Networks", "author": ["Ian J. Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David WardeFarley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "The Symbol Grounding Problem", "author": ["Stevan Harnad"], "venue": "Physica D: Nonlinear Phenomena,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1990}, {"title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks", "author": ["Alec Radford", "Luke Metz", "Soumith Chintala"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Interpolation and Extrapolation in Conceptual Spaces: A Case Study in the Music Domain", "author": ["Steven Schockaert", "Henri Prade"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Event Structure, Conceptual Spaces and the Semantics of Verbs", "author": ["Massimo Warglien", "Peter G\u00e4rdenfors", "Matthijs Westera"], "venue": "Theoretical Linguistics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Learning a Probabilistic Latent Space of Object Shapes via 3D GenerativeAdversarial Modeling", "author": ["Jiajun Wu", "Chengkai Zhang", "Tianfan Xue", "Bill Freeman", "Josh Tenenbaum"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Energy-based Generative Adversarial Network", "author": ["Junbo Zhao", "Michael Mathieu", "Yann LeCun"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Unpaired Imageto-Image Translation using Cycle-Consistent Adversarial Networks", "author": ["Jun-Yan Zhu", "Taesung Park", "Phillip Isola", "Alexei A. Efros"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2017}], "referenceMentions": [{"referenceID": 12, "context": "The cognitive framework of conceptual spaces [13,14] attempts to bridge the gap between symbolic and subsymbolic AI by proposing an intermediate conceptual layer based on geometric representations.", "startOffset": 45, "endOffset": 52}, {"referenceID": 13, "context": "The cognitive framework of conceptual spaces [13,14] attempts to bridge the gap between symbolic and subsymbolic AI by proposing an intermediate conceptual layer based on geometric representations.", "startOffset": 45, "endOffset": 52}, {"referenceID": 9, "context": "The framework of conceptual spaces has been highly influential in the last 15 years within cognitive science and cognitive linguistics [10,12,20].", "startOffset": 135, "endOffset": 145}, {"referenceID": 11, "context": "The framework of conceptual spaces has been highly influential in the last 15 years within cognitive science and cognitive linguistics [10,12,20].", "startOffset": 135, "endOffset": 145}, {"referenceID": 19, "context": "The framework of conceptual spaces has been highly influential in the last 15 years within cognitive science and cognitive linguistics [10,12,20].", "startOffset": 135, "endOffset": 145}, {"referenceID": 3, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 133, "endOffset": 140}, {"referenceID": 4, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 133, "endOffset": 140}, {"referenceID": 5, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 133, "endOffset": 140}, {"referenceID": 0, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 188, "endOffset": 193}, {"referenceID": 8, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 188, "endOffset": 193}, {"referenceID": 7, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 217, "endOffset": 223}, {"referenceID": 18, "context": "It has also sparked considerable research in various subfields of artificial intelligence, ranging from robotics and computer vision [4,5,6] over the semantic web and ontology integration [1,9] to plausible reasoning [8,19].", "startOffset": 217, "endOffset": 223}, {"referenceID": 6, "context": "We propose that latent spaces learned by an InfoGAN [7] (a special class of Generative Adversarial Networks [16]) can serve as domains in the conceptual spaces framework.", "startOffset": 52, "endOffset": 55}, {"referenceID": 15, "context": "We propose that latent spaces learned by an InfoGAN [7] (a special class of Generative Adversarial Networks [16]) can serve as domains in the conceptual spaces framework.", "startOffset": 108, "endOffset": 112}, {"referenceID": 12, "context": "A conceptual space [13] is a high-dimensional space spanned by so-called \u201cquality dimensions\u201d.", "startOffset": 19, "endOffset": 23}, {"referenceID": 16, "context": "If the dimensions of a conceptual space are based on perception and if regions in this space are linked to abstract symbols, this framework can be used for symbol grounding [17].", "startOffset": 173, "endOffset": 177}, {"referenceID": 1, "context": "[2] provide a thorough overview of different approaches in the representation learning area.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "We will focus our discussion here on one specific approach that is particularly fitting to our proposal, namely InfoGAN [7].", "startOffset": 120, "endOffset": 123}, {"referenceID": 15, "context": "InfoGAN is an extension of the GAN (Generative Adversarial Networks) framework [16] which has been applied to a variety of problems (e.", "startOffset": 79, "endOffset": 83}, {"referenceID": 10, "context": ", [11,18,21,22,23]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 17, "context": ", [11,18,21,22,23]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 20, "context": ", [11,18,21,22,23]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 21, "context": ", [11,18,21,22,23]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 22, "context": ", [11,18,21,22,23]).", "startOffset": 2, "endOffset": 18}, {"referenceID": 6, "context": "[7] have extended the original framework by introducing latent variables: In the InfoGAN framework (shown in the right part of Figure 1), the generator receives an additional input vector.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] found that the individual latent variables have an interpretable meaning.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] and [15, Ch.", "startOffset": 0, "endOffset": 3}, {"referenceID": 17, "context": "[18] found that linear interpolations between points in the latent space of a GAN correspond to a meaningful \u201cmorph\u201d between generated images in the input space.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "For a more thorough experiment, one could for instance use ShapeNet [3], a data base of over 50,000 3D models for more than 50 categories of objects.", "startOffset": 68, "endOffset": 71}], "year": 2017, "abstractText": "The highly influential framework of conceptual spaces provides a geometric way of representing knowledge. It aims at bridging the gap between symbolic and subsymbolic processing. Instances are represented by points in a high-dimensional space and concepts are represented by convex regions in this space. In this paper, we present our approach towards grounding the dimensions of a conceptual space in latent spaces learned by an InfoGAN from unlabeled data.", "creator": "LaTeX with hyperref package"}}}