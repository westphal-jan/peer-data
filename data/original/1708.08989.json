{"id": "1708.08989", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Aug-2017", "title": "Deep Residual Bidir-LSTM for Human Activity Recognition Using Wearable Sensors", "abstract": "Human activity recognition (HAR) has become a popular topic in research because of its wide application. With the development of deep learning, new ideas have appeared to address HAR problems. Here, a deep network architecture using residual bidirectional long short-term memory (LSTM) cells is proposed. The advantages of the new network include that a bidirectional connection can concatenate the positive time direction (forward state) and the negative time direction (backward state). Second, residual connections between stacked cells act as highways for gradients, which can pass underlying information directly to the upper layer, effectively avoiding the gradient vanishing problem. Generally, the proposed network shows improvements on both the temporal (using bidirectional cells) and the spatial (residual connections stacked deeply) dimensions, aiming to enhance the recognition rate. When tested with the Opportunity data set and the public domain UCI data set, the accuracy was increased by 4.78% and 3.68%, respectively, compared with previously reported results. Finally, the confusion matrix of the public domain UCI data set was analyzed.", "histories": [["v1", "Tue, 22 Aug 2017 11:02:13 GMT  (1320kb)", "http://arxiv.org/abs/1708.08989v1", null], ["v2", "Thu, 7 Sep 2017 07:36:31 GMT  (1265kb)", "http://arxiv.org/abs/1708.08989v2", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["yu zhao", "rennong yang", "guillaume chevalier", "maoguo gong"], "accepted": false, "id": "1708.08989"}, "pdf": {"name": "1708.08989.pdf", "metadata": {"source": "CRF", "title": "Deep Residual Bidir-LSTM for Human Activity Recognition Using Wearable Sensors", "authors": ["Yu Zhao", "Rennong Yang", "Guillaume Chevalier", "Maoguo Gong"], "emails": [], "sections": [{"heading": null, "text": "Human activity recognition (HAR) has become a popular topic in research because of its wide application. With the development of deep learning, new ideas have appeared to address HAR problems. Here, a deep network architecture using residual bidirectional long short-term memory (LSTM) cells is proposed. The advantages of the new network include that a bidirectional connection can concatenate the positive time direction (forward state) and the negative time direction (backward state). Second, residual connections between stacked cells act as highways for gradients, which can pass underlying\ninformation directly to the upper layer, effectively avoiding the gradient vanishing problem. Generally, the proposed network shows improvements on both the temporal (using bidirectional cells) and the spatial (residual connections stacked deeply) dimensions, aiming to enhance the recognition rate. When tested with the Opportunity data set and the public domain UCI data set, the accuracy was increased by 4.78% and 3.68%, respectively, compared with previously reported results. Finally, the confusion matrix of the public domain UCI data set was analyzed. Key words: human activity recognition; bidirectional LSTM; residual network"}, {"heading": "1. Introduction", "text": "In real life, many problems can be described as time series problems.\nIndeed, human activity recognition (HAR) is of value in both theoretical research and actual practice. It can be used widely, including in health monitoring [1][2], smart homes [3][4], and human\u2013computer interactions [5][6]; for example, LSTM cells are a good choice for solving HAR problems. Unlike traditional algorithms, LSTM can catch relationships in data on the temporal dimension without having to mix the time steps together as a 1D convolutional\nneural network (CNN) would do. As more of what is commonly called \u201cbig data\u201d emerges, LSTM architecture can offer great performance and many potential applications.\nMore specifically, HAR is the process of obtaining action data with sensors;\nit symbolizes the action information and then allows understanding and extraction of the motion characteristics, which is what activity recognition refers to. Because of the spatial complexity and temporal divergence of behavior, there is no unified recognition method. A public domain benchmark of HAR has been introduced, and different methods of recognition have been analyzed [7]. The results showed that the K-Nearest Neighbor (KNN) algorithm outperforms other algorithms in most recognition tasks. Support Vector Machine (SVM) is another outstanding algorithm. A Multi-Class Hardware-Friendly Support Vector Machine (MC-HF-SVM), which uses fixed-point arithmetic for HAR instead of the typical floating-point arithmetic, has been proposed for sensor data [8]. Unlike the manual filtering features in previous algorithms, a systematic feature learning method that combines feature extraction with CNN training has also been proposed [9]. Subsequently, DeepConvLSTM networks outperformed previous algorithms in the Opportunity Challenge by an average\nof 4% of the F1 score [10]; the effects of parameters on the final result were also analyzed.\nAlthough researchers have made great strides in HAR, room for\nimprovement remains. Inspired by previous neural networks\u2019 architectures, we describe a novel Deep Residual Bidirectional Long Short-term Memory LSTM (Deep-Res-Bidir-LSTM) network. The deep LSTM has improved learning ability and, despite the time required to reach maximum accuracy, shows good accuracy early in training; it is especially suitable for complex, large-scale HAR problems where sensor fusion would be required. Residual connections and bidirectional communication through time are available to ensure the integrity of information flowing deeply through the neural network.\nIn recent years, deep learning has shown applicability to many fields, such\nas image processing [11][12], speech recognition [13][14][15], and natural language processing [16][17]. In ILSVRC 2012, AlexNet [18], proposed by Alex Krizhevsky, took first place, and, since then, deep learning has been considered to be applicable to solving real problems and has done so with impressive accuracy. Indeed, deep learning has become a popular area for scientists and engineers.\nAnother event in 2016 that drew considerable attention was the century\nman\u2013machine war at the end of the game in which AlphaGo achieved victory. This event also demonstrated that deep learning, based on big data, is a feasible way to solve the non-deterministic polynomial problem.\nLSTM cells, which were first proposed by Juergen Schmidhuber in 1997\n[19], are variants of recurrent neural networks (RNNs). They have special inner gates that allow for consistently better performance than RNN on a time series. Compared with those of other networks, such as CNN, restricted Boltzmann machines (RBM), and auto-encoder (AE), the structure of the LSTM renders it especially good at solving problems involving time series, such as those related to natural language processing, speech recognition, and weather prediction, because its design enables gradients to flow through time readily.\nSection 2 presents the baseline LSTM, Bidir-LSTM, and residual networks.\nIn Section 3, we provide an explicit introduction to the preprocessing in HAR and describe Deep-Res-Bidir-LSTM. Several experiments were performed with HAR benchmarks: the public domain UCI data set and the Opportunity data set. We compare the accuracy of recognition of our algorithm with those of other algorithm. Finally, we summarize the research and discuss our future work."}, {"heading": "2. Background", "text": ""}, {"heading": "2.1. Baseline LSTM", "text": "LSTM [18] is an extension of recurrent neural networks. Due to its special\narchitecture, which combats the vanishing and exploding gradient problems, it is good at handling time series problems up to a certain depth.\nIn Figure 1, We define the input set as 0 1 1{ }t tx ,x ,...,x ,x ,... , the output set as\n0 1 1{ }t ty , y ,..., y , y ,... , and hidden layers as 0 1 1{ }t t+h ,h ,...,h ,h ,... . Then, , ,U W V denote weight metrics from the input layer to the hidden layer, from the hidden layer to\nthe hidden layer, and from the hidden layer to the output layer, respectively. The transfer process of the network can be described as follows: the input tensor is transformed, along with the tensor of the hidden layer (at the last stage), to the hidden layer by a matrix transformation. Then, the output of the hidden layer passes through an activation function to the final value of the output layer.\nFormally, outputs of the hidden layer and output layer can be defined as\nfollows:\n1\n( ) 0\n( ) 1,2,...\n( ) 0,1,...\nU\nU W\nV\n\n    \n  \n  \nh\ni i\ni h\ni i i\ny\ni i i\ng x b i h\ng x h b i\ny g h b i\n(1)\nIn theory, RNN can estimate the output of current time based on past\ninformation. However, Bengio [20] found that RNN could remember the information for only a short time, because of the vanishing and exploding gradient problems. When back propagation with a deep network is used, gradients will vanish rapidly if preventative measures that permit gradients to flow deeply are not taken. Compared with the simple input concatenation and activation used in RNNs, LSTM has a particular structure for remembering information for a longer time as an input gate and a forget gate control how to overwrite the information by comparing the inner memory with the new\ninformation arriving; this enables gradients to flow through time easily.\nAs shown in Figure 2, the input gate, the forget gate, and the output gate of\nLSTM are designed to control what information should be forgotten, remembered, and updated. Gating is a method to selectively pass the information that is needed. It consists of a sigmoid function and an element-wise multiplication function. The output value is between [0, 1] to allow the multiplication to then happen to let information flow or not; thus, it is considered good practice to initialize these gates to a value of 1, or close to 1, so as to not impair training at the beginning.\nIn the LSTM cell, each parameter at moment t can be defined as follows:\n1\n1\n1\n1\n1\n( [ , ] )\n( [ , ] )\n( [ , ] )\n( [ , ] )\n( )\nW\nW\nW\nW\n\n\n\n\n\n\n\n\n \n \n   \n  \nt f t t f\nt i t t i\nt c t t C t t t t t\nt o t t o t t t\nf h x b\ni h x b C tanh h x b C f C i C o h x b h o tanh C\n(2)\nFirst, there is a need to forget old information, which involves the forget\ngate. The next step is to determine what new information needs to be kept in memory; this is done with an input gate. From that, it is possible to update the old cell state, 1tC , to the new cell state, tC . Finally, it should be decided which information should be output to the layer above with an output gate."}, {"heading": "2.2. Bidirectional LSTM", "text": "In real life, human trajectories are continuous. Baseline LSTM cells can\npredict the current status based only on former information. It is clear that some important information may not be captured properly by the cell if it runs in only one direction.\nThe improvement in bidirectional LSTM is that the current output is not\nonly related to previous information but also to subsequent information. For example, it is appropriate to predict a missing word based on context. Bidirectional LSTM [32] is made up of two LSTM cells, and the output is\ndetermined by the two together.\nIn Figure 3, there are forward sequences h and backward sequences h\nin the hidden layer. For the moment, ( 0,1,2...)t t , the hidden layer and the\ninput layer can be defined as follows:\n( ) ( ) ( ) U W U W V V    t t t -1h h h t t t -1h h h t t t yh h h g x + h +b h g x + h +b y g h + h +b\n(3)\nOur bidirectional LSTM cell differs slightly from this. We concatenated the\nresults of the two th to then reduce the number of features in half with a ReLU fully connected hidden layer, as follows:\n( * ( , ) )W t t ty ReLU concat h h b , (4)\nwhere ( )concat means concatenating sequences."}, {"heading": "2.3. Residual Network", "text": "The MSRA team built a 152-layer network, which was about eight times\nthat of the VGG network [21]. Due to its excellent performance, they took first place in the 2015 ILSVRC competition owing to an absolute advantage in image classification, image location, and image detection.\nAs the network deepens, the research emphasis shifts to how to overcome\nthe obstruction of information and gradient transmission. The MSRA uses residual networks. The main idea is that it is easier to optimize the residual mapping than to optimize the original, unreferenced mapping.\nAn important advantage of residual networks is that they are much easier\nto train because the gradients can be passed through the layers more directly with the addition operator that enables them to bypass some layers that would have otherwise been restrictive. This enables both better training and a deeper\nnetwork, because residual connections do not impede gradients and still contribute to refining the output of a highway layer composed of such residual connections. On top of a collection of residual connections is a bottleneck where the next layers stop being residual and where a batch normalization is generally applied to normalize and restrict the usage of the feature space represented by the layer [22].\nA residual network is shown in Figure 4. The lower information can\ntransmit to upper layer directly through a highway, which increases the freedom\nof the information flowing. The highway structure containing skip connections can connect many supplementary  0,1,2,...n n layers in height before the\nbottleneck. When n equals 0, there is no residual connection: it becomes like the baseline deep-stacked LSTMs layers. In Figure 4, n is 0, and the output of the hidden layer  1,2,...,Li i can be defined as follows:\n1 1 1\n1\n( ) 1 ( ) 2,3,..., 1 ( ) h x h h h y h h           i i i-1 i i-2\ny i y i-\nW +b i W +b i = L - W +b i L\n(5)\nIn the code implementation, indexing in the configuration file starts at 1\nrather than 0 because we included the count of the first layer that acts as a basis before the residual cells. The same counting rule applies for indicating how many blocks of residual highway layers are stacked one on top of the other."}, {"heading": "3. Our Model: Deep Residual Bidir-LSTM Network", "text": "3.1. Process Pipeline for HAR\nThe process pipeline of HAR can be divided into three parts: preprocess,\ntraining, and testing. In our case, testing was modified in parallel with training. First, testers performed activities of daily living with wearable sensors and gathered information to form the raw data set. When data were missing, we\nadded them and then normalized to a mean of zero and standard deviation of 0.5; we then reshaped the data to fit the designed network, with windows of 128 time steps. The data were split into training and testing data sets.\nSecond, a training data tensor was added to the designed network so it\ncould output a prediction. The difference between the predicted value and the real value was then compared with a sigmoid cross entropy loss with L2 weight decay to then back-propagate errors backward into the network layer by layer with the Adam Optimizer [31]. Thus, we could adjust the hyper-parameters in networks, such as the learning rate and L2 weight decay, to reduce the difference.\nFinally, during testing, we added the testing tensor to the neural network\narchitecture without affecting the learned parameters, so as to not corrupt the test. Testing did not affect the training and did not change the results. Predictions obtained from the neural network were compared with the real values. The metrics of accuracy and of the F1 score of HAR were then calculated throughout learning and, at the end, by running the tests frequently. Both the best in-training metrics and the final metrics obtained were kept for comparison.\n3.2. Architecture of Deep Res-Bidir-LSTM Network\nConsidering the networks in Section 2, we proposed the\nDeep-Res-Bidir-LSTM to deal with HAR. Although residual connections for CNN have been used [21], this method is also available for LSTM.\nSimilar to building blocks, we can select modules and combine them to\nbuild a network based on our mission. The input of HAR should be a time series, and the basic structure of the LSTM guarantees that it can preserve the characteristics on the temporal dimension.\nAdditionally, a large network can be optimized correctly for a problem\nwith sufficient regularization, such as L2 weight decay and dropout; however, if no regularization is used, this results in overfitting and bad operations on the test set. Complexity is good but only if countered with regularization. Too many layers and cells per layer will increase the computational complexity and waste computational resources. When the layer number and cell number reach a certain scale, the recognition accuracy will remain at a certain scale instead of increasing; by adding more depth, regularization is then needed to avoid overfitting while still improving accuracy.\nOur deep LSTM neural network is limited in terms of how many data\npoints it can access: it has access to only 128 time steps when making its predictions. Especially when deepened, the next forward/backward duo will see output from the other pass \u201cin advance,\u201d because, logically, a backward pass for our bidirectional LSTM reverses the input and the output before the concatenation. Thus, the Bidir-LSTM has the same input and output shape as the baseline LSTM but, through depth, at a given time step, it has access to more information in advance because of the backward passes.\nIn general, gradient vanishing is a widespread problem for deep networks.\nThe residual, bidirectional, and stacked layers (hence, the name \u201cDeep Residual Bidir-LSTM\u201d) help counter this problem, because some bottom layers would otherwise be too hard to optimize when using back propagation. Combined with batch normalization on the top of each highway layer, the residual connection act as a highway for gradients; this prevents restrictions in the hidden layer feature space from being too complex and avoids outlier values at test time, combatting overfitting.\nIn Figure 5, the information flows in the horizontal direction (temporal\ndimension) and in the vertical direction (depth dimension). With the exception\nof the input and output layers, there are 2 hidden layers who has residual connection inside (hence, called \u201cresidual layer\u201d). Moreover, each residual layer contains 2 bidirectional layers. The network in Figure 5 has a 2 2 architecture, which can also be thought of as 8 LSTM cells in sum. In our network, the activity function is unified with ReLU, because it always outperforms tanh with deep networks to counter gradient vanishing. Although the output is a tensor for a given time window, T , the time axis has been crunched by the neural network. That is, we need only the last element of the output and can discard the others. Thus, only the gradient from the prediction at the last time step is applied. This also causes a LSTM cell to be unnecessary: the uppermost backward LSTM in the bidirectional pass. Hopefully, this is not of great concern because TensorFlow, the library we use, should evaluate what to compute and what not to compute. Additionally, the training data set should be shuffled during the training process. The state of the neural network is reset at each new window for each new prediction.\n3.3. Tricks for Optimization\nOur Deep-Res-Bidir-LSTM for HAR makes it possible to see that the\naccuracy during testing is much worse than that during training. Overfitting is likely to occur, and balancing the regularization hyper-parameters becomes difficult because they are so numerous. The L2 norm of the weights for weight decay is added in the loss function.\nAlso, dropout is applied between each layer on the depth axis or,\nsometimes, just at the output, depending on what is specified in the configuration file, which is another hyper-parameter. Dropout refers to the fact that parts of tensors that are output by the hidden layer are shut down to a zero value to a certain probability for each value in each training epoch, while other values scale up accordingly to keep the same geometric norm of the tensor\u2019s values. The inoperative nodes can be regarded as dead nodes (or neurons) that are temporarily not in the network, which means that the weights and biases behind these dead notes temporarily neither learns nor contributes to the predictions during that training step for a batch. The weights are kept intact.\nTo avoid a sudden leveling off in the accuracy during learning, gradient\nclipping [22] is added with a maximal gradient step norm of 15. This threshold, ( 0)v v , for the gradient helps not to overshoot the weight update during\ntraining due to having sharp cliffs in the weight space, a characteristic of RNNs;\nif || ||>\n|| || \ng v\ngv g\ng\n, (6)\nwhere g is the gradient and || ||g is the normed gradient.\nBatch normalization [23] can also be useful in training residual\nconnections. The fundamental idea of batch normalization is that layers are simply normalized by mean and variance such that they have a mean of zero and a standard deviation of 1 over the whole batch, so one big rescaling factor multiplies the whole batch, and one big bias is also added. The result is then normalized and offset in a linear fashion. The scaling multiplier  and the offset parameter  are learned to rescale inputs in a custom way, and  can be initialized to 1, as is commonly done. The formula can be defined as:\n( ) ( ) ( )\n( )\n( ) ( ) ( ) ( )\n[ ] \u02c6\n[ ]\n\u02c6 \n   \nk k k\nk\nk k k k\nx E x x\nVar x\ny x\n, (7)\nwhere ( )kx means the thk parameter in the parameters vector, and ( )ky is the normed value of ( )kx .\nWe added many tricks to the network to provide better results. Generally,\nL2 norm for weight decay and dropout are used to prevent overfitting, and gradient clipping and batch normalization are used to prevent gradient vanishing\nor explosion as well as overshooting the learning updates."}, {"heading": "4. Experiments", "text": "We tested the Deep-Res-Bidir-LSTM network with the public domain UCI\ndata set [24] and the Opportunity data set [7]. Then, we compared it with the outcomes of other methods and analyzed the results. The computer for testing had an i7 CPU with 8 GB RAM as well as an NVIDIA GTX 960m GPU, which has 640 CUDA cores and 4 GB RAM. The GPU and CPU were used alternatively depending on the size of the neural network, which sometimes exceeded the available amount of memory on the graphics card during training.\n4.1. Data Sets\nThe research objects of recognition were activities in daily life. Thus, the\nbenchmark for HAR should meet two conditions: first, it should contain most behavioral classes so it reflects real life. Second, it should abstract features and labels for modeling and calculations. Human actions can be divided into several layers in terms of granularity, such as the gesture layer (including left-arm lift, trunk-back), the action layer (including jumping, running, sitting), and the\nbehavior layer (such as drinking water, typing, sleeping). A good HAR benchmark should include a clear understanding of the hierarchy. There are several open data sets that can be benchmarked, such as the public domain UCI [24], the Opportunity [7], and the KTH data sets [25]. Many studies have used these benchmarks. We chose the public domain UCI and the Opportunity data sets for our experiments. The neural network should be readily adaptable to a new data set with an architecture module and a changeable configuration file that also loads the data set.\nPublic domain UCI data set. Experiments were carried out with a group\nof 30 volunteers aged 19\u201348 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING_DOWN) wearing a smart phone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we were able to make three-axial linear acceleration and three-axial angular velocity available at a constant rate of 50 Hz and trimmed into windows of 128 time steps for a 2.56 seconds windows; this was enough to capture two steps, in the case of walking, for the classification. The experiments were video-recorded to label the data manually and obtain balanced classes; the data were of high quality. The data\nset obtained was partitioned randomly into two sets: 70% of the volunteers were selected for generating the training data, and 30% were selected for generating the test data. Each sample had 561 linear (time-independent) hand-made, preprocessed features from signal analysis (e.g., window\u2019s peak frequency), but only nine features were used in our study: triaxial gravity acceleration from the accelerometer (from a 0.3 Hz Butterworth low-pass filter) and triaxial body acceleration and triaxial angular velocity from the gyroscope. These are raw signals with a time component and do not fall in the frequency domain but rather in the time domain. The sensor data were pre-processed by applying denoising median filters, clipping the approximately 20 Hz mark; they were then sampled in fixed-width sliding windows of 2.56 seconds. Those windows were provided with an overlap of 50% to ease training. Additionally, all features were pre-normalized and bounded within [-1, 1].\nOpportunity data set. The Opportunity data set for HAR from wearable,\nobject, and ambient sensors is a data set devised to benchmark HAR algorithms. The data set includes activities from four subjects; each one has six recorded runs. For each subject, the first five records consist of runs of activities of daily living, characterized by the natural execution of daily activities. The sixth run\nwas a \u201cdrill\u201d run, where users executed a scripted sequence of activities. The activities of the user in the scenario were annotated on different levels. Notably, among others, 17 mid-level gesture classes were identified and used for our predictions; this group included the \u201cNULL\u201d class, which is common, for a total of 18 classes. The NULL class rendered the data set highly unbalanced; thus, following previous research [10], we used a weighted F1 score [10]. In total, 242 features from body-worn sensors, object sensors, and ambient sensors were provided for each sample; time stamps in milliseconds, starting from zero and having a sampling rate of 30 Hz, were also provided. Many of those 242 features are not useful for HAR; thus, we used only 113 features, such as DeepConvLSTM [10]. Due to the use of wireless sensors to transfer data, there may be missing data. We used linear interpolation to fill in the missing data. Also, the data were provided with a custom scale and different value ranges and resolutions for each feature; there were sometimes magnitudes of difference according to the cell used. Our architecture used mean and variance (standard deviation) normalization on the z-score scale with a standard deviation of 0.5. Such a small standard deviation is often useful in deep learning [30]. The transition function was defined as follows:\n* \n\n  x x , (8)\nwhere  is mean value and  is the standard deviation. As with DeepConvLSTM, we used a subset from subjects 1 to 3 as a training data set and used the remainder of this subset for the test data, using runs 3 and 4 of subjects 2 and 3 as testing data, for a total of 4 test runs. To obtain comparable results, we did not use the data from subject 4. To summarize, we used only a subset of the full data set to simulate the conditions of the competition, using 113 sensor channels and classifying the 17 categories of output (and the NULL class). Our LSTM\u2019s inner representation was always reset to 0 between series. We used mean and variance normalization rather than min-to-max rescaling.\nBecause of class imbalance in the Opportunity data set, we used the F1\nscore as a measurement of recognition. The F1 score can be regarded as a weighted average of accuracy and recall; it ranges between 0 and 1. For a dichotomous problem, the F1 score can be defined as follows:\n1 2 \n \nprec recall F\nprec recall , (9)\nwhere prec and recall indicate precision and recall, respectively.\nHowever, we needed a multi-class classification in this paper. So, the F1\nscore was defined as follows:\n1 2\n \n  c\nc total\nN prec recall F\nN prec recall , (8)\nwhere cN is the sample count of class c , and totalN is the total sample count of the data set.\n4.2. Hyper-parameters Setting\nThe hyper-parameters in the Deep-Res-Bidir-LSTM network affect the\nfinal result. Generally used methods of tuning parameters include experimental methods, grid searches [26], genetic algorithm (GA) [27], and particle swarm optimization (PSO) [28][29]. As experimental methods involve approximating the value by running many experiments, these methods are time consuming. GA and PSO are heuristic algorithms, and they are limited to dealing with large-scale network. We used grid search, which involved dividing hyper-parameter values into several steps to create a grid of a certain range, then traversing all points of the grid to find the best values for these parameters. We used a grid search, iteratively improved the neural network, and repeated the grid search.\nreflecting the intent as well as the possibly current behavior. Through a slide window process, the shape of the data set SequenceNum channels was converted to  sampleNum windowSize channels with overlap and, therefore, with duplication of the size of the contents.\n4.3. Results\nDavide Anguita [8]. It allows better preservation of the life of a smart phone battery than the conventional floating-point-based formulation while maintaining comparable system accuracy levels. The performances of Bidir-LSTM and Res-LSTM were almost the same; both were better than the baseline LSTM, because they are good at information transmission. Bidir-LSTM can get information in both forward and backward passes, and\nRes-LSTM uses a highway to transmit information directly. Among the algorithms in Table 1, Deep-Res-Bidir-LSTM achieved the best F1 score, 93.54%, because of both residual connections and bidirectional cells. Comparing accuracy and F1 scores, the two columns are almost the same for each model. We randomly selected a batch while training, and a complete calculation was almost able traverse the entire data set.\nabout 3.68% better in gesture recognition. Due to the dominant Null class, most samples tended to be classified into the Null class. This class imbalance occurred with all algorithms, but its severity, in the F1 score, is seen more for other algorithms.\nFigure 7 shows the F1 score trend with the training data and testing data\nfor each model. Generally, when training was finished, both the training and testing results oscillated around a fixed value. Moreover, the results in the four groups were convergent. The amplitude of baseline LSTM was significantly higher than those of the other three. Deep-Res-Bidir-LSTM achieved the best F1 score, ~0.9. Convergence rate can be arranged from slow to fast as baseline LSTM, Bidir-LSTM, Deep-Res-Bidir-LSTM, and Res-LSTM. However, the difference between Deep-Res-Bidir-LSTM and Res-LSTM was very small, and\nboth were obviously different from the others. The results also show that residual connection was outstanding in convergence.\nFigure 8. Normalized-to-percent matrix confusion on the test data set using Dee-Res-Bidir-LSTM. The columns represent the predicted classes, and the rows represent the actual classes.\nTable 3 shows the confusion matrix of Deep-Res-Bidir-LSTM with testing\ndata. The values of prediction in six classes were in the range of 87.30% to 99.26%, and the values of recall were in the range of 88.41% to 100%. The integral accuracy reached 93.57%. An intuitive confusion matrix is shown in Figure 8. The color from blue to red represents the increasing percentage. It can be seen that the LAYING_DOWN class was recognized best, likely because triaxial acceleration and triaxial angular velocity are quite different from the values in other classes. Standing and sitting were sometimes misrecognized as each other; both involve static behavior. In fact, they are seemingly almost the same from the point of view of a device placed on the belly, which is how the data set was gathered. Similarly, WALKING, WALKING_UPSTAIRS, and WALKING_DOWNSTAIRS all involve dynamic behavior, and there is some confusion among them. However, it is still possible to see a little clustering among these three classes in the matrix."}, {"heading": "5. Conclusions", "text": "In this paper, the significance of HAR research is analyzed, and an\noverview of emerging methods in the field is provided. LSTM neural networks have been used in many innovations in natural language processing, speech recognition, and weather prediction. This technology was adapted to the HAR task. We proposed the novel framework of the Deep-Res-Bidir-LSTM network. This deep network can enhance learning ability for faster learning in early training. The proposed network also guarantees the validity of information transmission through residual connections (on the depth dimension) and bidirectional cells (on the temporal dimension). In our experiments, the proposed network was able to improve the accuracy, by 4.78%, for the public domain UCI data set and increase the F1 score, by 3.68%, for the Opportunity data set in comparison with previous work.\nWe also found that window size was a key parameter. Too small a window\ndid not guarantee continuity of information, and too large a window caused classification errors. Usually, 500 ms to 5000 ms will be appropriate for the window size. During model training, the architecture of the network, such as the\nlayers and the cells in each layer, should be determined first, followed by the optimization of hyper-parameters, such as learning rate and the L2 weight decay multiplier. The values of hyper-parameters should be determined according to the specific architecture. For example, 28 cells were sufficient for the public domain UCI data set, but 128 cells were better for the Opportunity data set because it has more features and labels and, thus, increased overall complexity.\nFuture work should explore a more efficient way to tune parameters.\nAlthough the grid search was workable, the searching range must be changed manually, and the values are always fixed. It will be important to find an adaptive way to automatically adjust the searching process and also make the neural network\u2019s architecture evolve, such by as automatically reshaping, adding, and removing various layers. Also, exploring the effect of mixing 1D time-based convolutions at one or some points in the LSTM cells might improve results. Finally, applying the Deep-Res-Bidir-LSTM network to other fields could be revealing. A good model should have outstanding generalization. Indeed, focusing on time series prediction problems has value. Problems such as stock prediction and trajectory prediction may be explored."}, {"heading": "Acknowledgments", "text": "We thank Guillaume Chevalier, who supported this work by offering\nguidance and by contributing to building the neural network architecture. Our Github repository is located at the following address:\nhttps://github.com/guillaume-chevalier/HAR-stacked-residual-bidir-LSTMs.\nThe code is open source, and we sought to make it readily adaptable to new problems using a new configuration file. We also thank everyone who contributed to building and maintaining the openly available data sets on the UCI Machine Learning Repository; other links [33][34] are cited in the References."}, {"heading": "34(15) (2013) 2033\u20132042.", "text": "[8] Anguita D, Ghio A, Oneto L, et al. Energy efficient smartphone-based activity\nrecognition using fixed-point arithmetic, Journal of Universal Computerence. 19(9)\n(2013) 1295\u20131314.\n[9] Yang J B, Nguyen M N, San P P, et al. Deep convolutional neural networks on\nmultichannel time series for human activity recognition, in: International Conference on\nArtificial Intelligence. AAAI Press, 2015.\n[10] Ord\u00f3\u00f1ez F J, Roggen D. Deep Convolutional and LSTM Recurrent Neural Networks for\nMultimodal Wearable Activity Recognition, Sensors. 16(1) (2016) 115\u2013140.\n[11] Wang N, Yeung D Y. Learning a deep compact image representation for visual tracking,\nin: Advances in Neural Information Processing Systems, 2013.\n[12] Dong C, Loy C, He K, et al. Learning a deep convolutional network for image\nsuper-resolution, in: European Conference on Computer Vision, 2014.\n[13] Graves A, Mohamed A R, Hinton G. Speech recognition with deep recurrent neural\nnetworks, in: IEEE International Conference on Acoustics, Speech and Signal\nProcessing. 2013.\n[14] Hannun, Awni, et al. Deep speech: Scaling up end-to-end speech recognition, arXiv\npreprint, arXiv: 1412.5567, 2014.\n[15] Abdel-Hamid O, Mohamed A R, Jiang H, et al. Convolutional Neural Networks for\nSpeech Recognition, IEEE/ACM Transactions on Audio Speech & Language\nProcessing. 22(22) (2014) 1533\u20131545.\n[16] Kumar, Ankit, et al. Ask me anything: Dynamic memory networks for natural language\nprocessing, in: CoRR, 2015.\n[17] Cho, Kyunghyun, et al. Learning phrase representations using RNN encoder-decoder for\nstatistical machine translation, arXiv preprint arXiv: 1406.1078, 2014.\n[18] Krizhevsky A, Sutskever I, Hinton G E. ImageNet classification with deep convolutional\nneural networks, in: International Conference on Neural Information Processing\nSystems, 2012.\n[19] Hochreiter, Sepp, and J\u00fcrgen Schmidhuber. Long short-term memory, Neural\ncomputation. 9(8) (1997) 1735\u20131780.\n[20] Bengio Y, Simard P, Frasconi P. Learning long-term dependencies with gradient descent\nis difficult, IEEE Transactions on Neural Networks. 5(2) (1994) 157\u2013166.\n[21] He, Kaiming, et al. Deep residual learning for image recognition, in: Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition, 2016.\n[22] Pascanu, Razvan, Tomas Mikolov, and Yoshua Bengio. Understanding the exploding\ngradient problem, in: CoRR, 2012.\n[23] Ioffe, Sergey, and Christian Szegedy. Batch normalization: Accelerating deep network\ntraining by reducing internal covariate shift, arXiv preprint, arXiv:1502.03167, 2015.\n[24] Anguita, Davide, et al. A Public Domain Dataset for Human Activity Recognition using\nSmartphones, in: ESANN, 2013.\n[25] Maclean W J. Spatial Coherence for Visual Motion Analysis, Springer Berlin Heidelberg,\n2006.\n[26] Yao Y, Zhang L, Liu Y, et al. An improved grid search algorithm and its application in\nPCA and SVM based face recognition, Journal of Computational Information Systems."}, {"heading": "10(3) (2014) 1219\u20131229.", "text": "[27] Levy E, David O E, Netanyahu N S. Netanyahu. Genetic algorithms and deep learning\nfor automatic painter classification, in: proceedings of the 2014 Annual Conference on\nGenetic and Evolutionary Computation, 2014.\n[28] Fornarelli G, Giaquinto A. Adaptive particle swarm optimization for CNN associative\nmemories design, Neurocomputing. 72(16) (2009) 3851\u20133862.\n[29] Syulistyo A R, Purnomo D M J, Rachmadi M F, et al. PARTICLE SWARM\nOPTIMIZATION (PSO) FOR TRAINING OPTIMIZATION ON CONVOLUTIONAL\nNEURAL NETWORK (CNN), Jurnal Ilmu Komputer dan Informasi. 9(1) (2016):\n52-58.\n[30] Wiesler S, Richard A, Schluter R, et al. Mean-normalized stochastic gradient for\nlarge-scale deep learning, in: IEEE International Conference on Acoustics, Speech and\nSignal Processing, 2014.\n[31] Kingma, Diederik, Jimmy B. Adam: A method for stochastic optimization. arXiv preprint,\narXiv:1412.6980, 2014.\n[32] Wollmer M, Eyben F, Keshet J, et al. Robust discriminative keyword spotting for\nemotionally colored spontaneous speech using bidirectional LSTM networks, in: IEEE\nInternational Conference on Acoustics, Speech and Signal Processing, 2009.\n[33] David A, Oneto L. Human activity recognition using smartphone data set,\nhttps://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartpho\nnes, 2012.\n[34] Daniel R, Rossi M. Opportunity activity recognition dataset,\nhttps://archive.ics.uci.edu/ml/datasets/OPPORTUNITY+Activity+Recognition, 2012."}], "references": [{"title": "Dynamic computation offloading for low-power wearable health monitoring systems", "author": ["H Kalantarian", "C Sideris", "B Mortazavi"], "venue": "IEEE Transactions on Biomedical Engineering", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2017}, {"title": "A survey on wearable sensor-based systems for health monitoring and prognosis", "author": ["A Pantelopoulos", "G. Bourbakis N"], "venue": "IEEE Transactions on Systems Man & Cybernetics Part C Applications & Reviews", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Named data networking-based smart home, ICT Express", "author": ["H Ahmed S", "D. Kim"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Ubiquitous smart home system using android application", "author": ["Kumar", "Shiu"], "venue": "arXiv preprint,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Vision based hand gesture recognition for human computer interaction: a survey, Artificial Intelligence Review", "author": ["S Rautaray", "A. Agrawal"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Hand tracking and gesture recognition system for human\u2013computer interaction using low-cost hardware, Multimedia Tools and Applications", "author": ["S Yeo H", "G Lee B", "H. Lim"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "The Opportunity challenge: A benchmark database for on-body sensor-based activity recognition, Pattern Recognition Letters", "author": ["R Chavarriaga", "H Sagha", "A Calatroni"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Energy efficient smartphone-based activity recognition using fixed-point arithmetic, Journal of Universal Computerence", "author": ["D Anguita", "A Ghio", "L Oneto"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Deep convolutional neural networks on multichannel time series for human activity", "author": ["B Yang J", "N Nguyen M", "P San P"], "venue": "recognition, in: International Conference on Artificial Intelligence. AAAI Press,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition, Sensors", "author": ["J Ord\u00f3\u00f1ez F", "D. Roggen"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "Learning a deep compact image representation for visual tracking", "author": ["N Wang", "Y. Yeung D"], "venue": "in: Advances in Neural Information Processing Systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Learning a deep convolutional network for image super-resolution", "author": ["C Dong", "C Loy", "K He"], "venue": "in: European Conference on Computer Vision,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A Graves", "R Mohamed A", "G. Hinton"], "venue": "in: IEEE International Conference on Acoustics, Speech and Signal Processing", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Deep speech: Scaling up end-to-end speech recognition", "author": ["Hannun", "Awni"], "venue": "arXiv preprint,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Convolutional Neural Networks for Speech Recognition", "author": ["O Abdel-Hamid", "R Mohamed A", "H Jiang"], "venue": "IEEE/ACM Transactions on Audio Speech & Language Processing", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Ask me anything: Dynamic memory networks for natural language processing", "author": ["Kumar", "Ankit"], "venue": "in: CoRR,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "author": ["Cho", "Kyunghyun"], "venue": "arXiv preprint arXiv:", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A Krizhevsky", "I Sutskever", "E. Hinton G"], "venue": "in: International Conference on Neural Information Processing Systems,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Long short-term memory", "author": ["Hochreiter", "Sepp", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1997}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Y Bengio", "P Simard", "P. Frasconi"], "venue": "IEEE Transactions on Neural Networks", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1994}, {"title": "Deep residual learning for image recognition", "author": ["He", "Kaiming"], "venue": "in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Understanding the exploding gradient problem", "author": ["Pascanu", "Razvan", "Tomas Mikolov", "Yoshua Bengio"], "venue": "in: CoRR,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Ioffe", "Sergey", "Christian Szegedy"], "venue": "arXiv preprint,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "A Public Domain Dataset for Human Activity Recognition using Smartphones", "author": ["Anguita", "Davide"], "venue": "in: ESANN,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}, {"title": "Spatial Coherence for Visual Motion Analysis", "author": ["J. Maclean W"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}, {"title": "An improved grid search algorithm and its application in PCA and SVM based face recognition", "author": ["Y Yao", "L Zhang", "Y Liu"], "venue": "Journal of Computational Information Systems", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Genetic algorithms and deep learning for automatic painter classification", "author": ["E Levy", "E David O", "Netanyahu. Netanyahu N S"], "venue": "in: proceedings of the 2014 Annual Conference on Genetic and Evolutionary Computation,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Adaptive particle swarm optimization for CNN associative memories design, Neurocomputing", "author": ["G Fornarelli", "A. Giaquinto"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2009}, {"title": "PARTICLE SWARM OPTIMIZATION (PSO) FOR TRAINING OPTIMIZATION ON CONVOLUTIONAL  NEURAL NETWORK (CNN)", "author": ["R Syulistyo A", "J Purnomo D M", "F Rachmadi M"], "venue": "Jurnal Ilmu Komputer dan Informasi", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "Mean-normalized stochastic gradient for large-scale deep learning", "author": ["S Wiesler", "A Richard", "R Schluter"], "venue": "in: IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik", "Jimmy B"], "venue": "arXiv preprint,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2014}, {"title": "Robust discriminative keyword spotting for emotionally colored spontaneous speech using bidirectional LSTM networks", "author": ["M Wollmer", "F Eyben", "J Keshet"], "venue": "in: IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2009}, {"title": "Human activity recognition using smartphone data set, https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartpho nes", "author": ["A David", "L. Oneto"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Opportunity activity recognition", "author": ["R Daniel", "M. Rossi"], "venue": "dataset, https://archive.ics.uci.edu/ml/datasets/OPPORTUNITY+Activity+Recognition,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "It can be used widely, including in health monitoring [1][2], smart homes [3][4], and human\u2013computer interactions [5][6]; for example, LSTM cells are a good choice for solving HAR problems.", "startOffset": 54, "endOffset": 57}, {"referenceID": 1, "context": "It can be used widely, including in health monitoring [1][2], smart homes [3][4], and human\u2013computer interactions [5][6]; for example, LSTM cells are a good choice for solving HAR problems.", "startOffset": 57, "endOffset": 60}, {"referenceID": 2, "context": "It can be used widely, including in health monitoring [1][2], smart homes [3][4], and human\u2013computer interactions [5][6]; for example, LSTM cells are a good choice for solving HAR problems.", "startOffset": 74, "endOffset": 77}, {"referenceID": 3, "context": "It can be used widely, including in health monitoring [1][2], smart homes [3][4], and human\u2013computer interactions [5][6]; for example, LSTM cells are a good choice for solving HAR problems.", "startOffset": 77, "endOffset": 80}, {"referenceID": 4, "context": "It can be used widely, including in health monitoring [1][2], smart homes [3][4], and human\u2013computer interactions [5][6]; for example, LSTM cells are a good choice for solving HAR problems.", "startOffset": 114, "endOffset": 117}, {"referenceID": 5, "context": "It can be used widely, including in health monitoring [1][2], smart homes [3][4], and human\u2013computer interactions [5][6]; for example, LSTM cells are a good choice for solving HAR problems.", "startOffset": 117, "endOffset": 120}, {"referenceID": 6, "context": "A public domain benchmark of HAR has been introduced, and different methods of recognition have been analyzed [7].", "startOffset": 110, "endOffset": 113}, {"referenceID": 7, "context": "A Multi-Class Hardware-Friendly Support Vector Machine (MC-HF-SVM), which uses fixed-point arithmetic for HAR instead of the typical floating-point arithmetic, has been proposed for sensor data [8].", "startOffset": 194, "endOffset": 197}, {"referenceID": 8, "context": "Unlike the manual filtering features in previous algorithms, a systematic feature learning method that combines feature extraction with CNN training has also been proposed [9].", "startOffset": 172, "endOffset": 175}, {"referenceID": 9, "context": "of 4% of the F1 score [10]; the effects of parameters on the final result were also analyzed.", "startOffset": 22, "endOffset": 26}, {"referenceID": 10, "context": "In recent years, deep learning has shown applicability to many fields, such as image processing [11][12], speech recognition [13][14][15], and natural language processing [16][17].", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "In recent years, deep learning has shown applicability to many fields, such as image processing [11][12], speech recognition [13][14][15], and natural language processing [16][17].", "startOffset": 100, "endOffset": 104}, {"referenceID": 12, "context": "In recent years, deep learning has shown applicability to many fields, such as image processing [11][12], speech recognition [13][14][15], and natural language processing [16][17].", "startOffset": 125, "endOffset": 129}, {"referenceID": 13, "context": "In recent years, deep learning has shown applicability to many fields, such as image processing [11][12], speech recognition [13][14][15], and natural language processing [16][17].", "startOffset": 129, "endOffset": 133}, {"referenceID": 14, "context": "In recent years, deep learning has shown applicability to many fields, such as image processing [11][12], speech recognition [13][14][15], and natural language processing [16][17].", "startOffset": 133, "endOffset": 137}, {"referenceID": 15, "context": "In recent years, deep learning has shown applicability to many fields, such as image processing [11][12], speech recognition [13][14][15], and natural language processing [16][17].", "startOffset": 171, "endOffset": 175}, {"referenceID": 16, "context": "In recent years, deep learning has shown applicability to many fields, such as image processing [11][12], speech recognition [13][14][15], and natural language processing [16][17].", "startOffset": 175, "endOffset": 179}, {"referenceID": 17, "context": "In ILSVRC 2012, AlexNet [18], proposed by Alex Krizhevsky, took first place, and, since then, deep learning has been considered to be applicable to solving real problems and has done so with impressive accuracy.", "startOffset": 24, "endOffset": 28}, {"referenceID": 18, "context": "LSTM cells, which were first proposed by Juergen Schmidhuber in 1997 [19], are variants of recurrent neural networks (RNNs).", "startOffset": 69, "endOffset": 73}, {"referenceID": 17, "context": "LSTM [18] is an extension of recurrent neural networks.", "startOffset": 5, "endOffset": 9}, {"referenceID": 19, "context": "However, Bengio [20] found that RNN could remember the information for only a short time, because of the vanishing and exploding gradient problems.", "startOffset": 16, "endOffset": 20}, {"referenceID": 0, "context": "The output value is between [0, 1] to allow the multiplication to then happen to let information flow or not; thus, it is considered good practice to initialize these gates to a value of 1, or close to 1, so as to not impair training at the beginning.", "startOffset": 28, "endOffset": 34}, {"referenceID": 31, "context": "Bidirectional LSTM [32] is made up of two LSTM cells, and the output is", "startOffset": 19, "endOffset": 23}, {"referenceID": 20, "context": "The MSRA team built a 152-layer network, which was about eight times that of the VGG network [21].", "startOffset": 93, "endOffset": 97}, {"referenceID": 21, "context": "On top of a collection of residual connections is a bottleneck where the next layers stop being residual and where a batch normalization is generally applied to normalize and restrict the usage of the feature space represented by the layer [22].", "startOffset": 240, "endOffset": 244}, {"referenceID": 30, "context": "The difference between the predicted value and the real value was then compared with a sigmoid cross entropy loss with L2 weight decay to then back-propagate errors backward into the network layer by layer with the Adam Optimizer [31].", "startOffset": 230, "endOffset": 234}, {"referenceID": 20, "context": "Although residual connections for CNN have been used [21], this method is also available for LSTM.", "startOffset": 53, "endOffset": 57}, {"referenceID": 21, "context": "To avoid a sudden leveling off in the accuracy during learning, gradient clipping [22] is added with a maximal gradient step norm of 15.", "startOffset": 82, "endOffset": 86}, {"referenceID": 22, "context": "Batch normalization [23] can also be useful in training residual connections.", "startOffset": 20, "endOffset": 24}, {"referenceID": 23, "context": "We tested the Deep-Res-Bidir-LSTM network with the public domain UCI data set [24] and the Opportunity data set [7].", "startOffset": 78, "endOffset": 82}, {"referenceID": 6, "context": "We tested the Deep-Res-Bidir-LSTM network with the public domain UCI data set [24] and the Opportunity data set [7].", "startOffset": 112, "endOffset": 115}, {"referenceID": 23, "context": "There are several open data sets that can be benchmarked, such as the public domain UCI [24], the Opportunity [7], and the KTH data sets [25].", "startOffset": 88, "endOffset": 92}, {"referenceID": 6, "context": "There are several open data sets that can be benchmarked, such as the public domain UCI [24], the Opportunity [7], and the KTH data sets [25].", "startOffset": 110, "endOffset": 113}, {"referenceID": 24, "context": "There are several open data sets that can be benchmarked, such as the public domain UCI [24], the Opportunity [7], and the KTH data sets [25].", "startOffset": 137, "endOffset": 141}, {"referenceID": 0, "context": "Additionally, all features were pre-normalized and bounded within [-1, 1].", "startOffset": 66, "endOffset": 73}, {"referenceID": 9, "context": "The NULL class rendered the data set highly unbalanced; thus, following previous research [10], we used a weighted F1 score [10].", "startOffset": 90, "endOffset": 94}, {"referenceID": 9, "context": "The NULL class rendered the data set highly unbalanced; thus, following previous research [10], we used a weighted F1 score [10].", "startOffset": 124, "endOffset": 128}, {"referenceID": 9, "context": "Many of those 242 features are not useful for HAR; thus, we used only 113 features, such as DeepConvLSTM [10].", "startOffset": 105, "endOffset": 109}, {"referenceID": 29, "context": "Such a small standard deviation is often useful in deep learning [30].", "startOffset": 65, "endOffset": 69}, {"referenceID": 25, "context": "Generally used methods of tuning parameters include experimental methods, grid searches [26], genetic algorithm (GA) [27], and particle swarm optimization (PSO) [28][29].", "startOffset": 88, "endOffset": 92}, {"referenceID": 26, "context": "Generally used methods of tuning parameters include experimental methods, grid searches [26], genetic algorithm (GA) [27], and particle swarm optimization (PSO) [28][29].", "startOffset": 117, "endOffset": 121}, {"referenceID": 27, "context": "Generally used methods of tuning parameters include experimental methods, grid searches [26], genetic algorithm (GA) [27], and particle swarm optimization (PSO) [28][29].", "startOffset": 161, "endOffset": 165}, {"referenceID": 28, "context": "Generally used methods of tuning parameters include experimental methods, grid searches [26], genetic algorithm (GA) [27], and particle swarm optimization (PSO) [28][29].", "startOffset": 165, "endOffset": 169}, {"referenceID": 7, "context": "Algorithm Accuracy F1 score MC-SVM [8] 89.", "startOffset": 35, "endOffset": 38}, {"referenceID": 7, "context": "54% MultiClass Hardware Friendly SVM, or MC-HF-SVM, was proposed by Davide Anguita [8].", "startOffset": 83, "endOffset": 86}, {"referenceID": 6, "context": "F1 score with the NULL class of each algorithm with the Opportunity data set Algorithm F1 score LDA [7] 69% QDA [7] 53% NCC [7] 51% 1NN [7] 87% 3NN [7] 85% UP [7] 64% NStar [7] 84% SStar [7] 86% DBN [9] 73.", "startOffset": 100, "endOffset": 103}, {"referenceID": 6, "context": "F1 score with the NULL class of each algorithm with the Opportunity data set Algorithm F1 score LDA [7] 69% QDA [7] 53% NCC [7] 51% 1NN [7] 87% 3NN [7] 85% UP [7] 64% NStar [7] 84% SStar [7] 86% DBN [9] 73.", "startOffset": 112, "endOffset": 115}, {"referenceID": 6, "context": "F1 score with the NULL class of each algorithm with the Opportunity data set Algorithm F1 score LDA [7] 69% QDA [7] 53% NCC [7] 51% 1NN [7] 87% 3NN [7] 85% UP [7] 64% NStar [7] 84% SStar [7] 86% DBN [9] 73.", "startOffset": 124, "endOffset": 127}, {"referenceID": 6, "context": "F1 score with the NULL class of each algorithm with the Opportunity data set Algorithm F1 score LDA [7] 69% QDA [7] 53% NCC [7] 51% 1NN [7] 87% 3NN [7] 85% UP [7] 64% NStar [7] 84% SStar [7] 86% DBN [9] 73.", "startOffset": 136, "endOffset": 139}, {"referenceID": 6, "context": "F1 score with the NULL class of each algorithm with the Opportunity data set Algorithm F1 score LDA [7] 69% QDA [7] 53% NCC [7] 51% 1NN [7] 87% 3NN [7] 85% UP [7] 64% NStar [7] 84% SStar [7] 86% DBN [9] 73.", "startOffset": 148, "endOffset": 151}, {"referenceID": 6, "context": "F1 score with the NULL class of each algorithm with the Opportunity data set Algorithm F1 score LDA [7] 69% QDA [7] 53% NCC [7] 51% 1NN [7] 87% 3NN [7] 85% UP [7] 64% NStar [7] 84% SStar [7] 86% DBN [9] 73.", "startOffset": 159, "endOffset": 162}, {"referenceID": 6, "context": "F1 score with the NULL class of each algorithm with the Opportunity data set Algorithm F1 score LDA [7] 69% QDA [7] 53% NCC [7] 51% 1NN [7] 87% 3NN [7] 85% UP [7] 64% NStar [7] 84% SStar [7] 86% DBN [9] 73.", "startOffset": 173, "endOffset": 176}, {"referenceID": 6, "context": "F1 score with the NULL class of each algorithm with the Opportunity data set Algorithm F1 score LDA [7] 69% QDA [7] 53% NCC [7] 51% 1NN [7] 87% 3NN [7] 85% UP [7] 64% NStar [7] 84% SStar [7] 86% DBN [9] 73.", "startOffset": 187, "endOffset": 190}, {"referenceID": 8, "context": "F1 score with the NULL class of each algorithm with the Opportunity data set Algorithm F1 score LDA [7] 69% QDA [7] 53% NCC [7] 51% 1NN [7] 87% 3NN [7] 85% UP [7] 64% NStar [7] 84% SStar [7] 86% DBN [9] 73.", "startOffset": 199, "endOffset": 202}, {"referenceID": 8, "context": "0% CNN [9] 85.", "startOffset": 7, "endOffset": 10}, {"referenceID": 32, "context": "We also thank everyone who contributed to building and maintaining the openly available data sets on the UCI Machine Learning Repository; other links [33][34] are cited in the References.", "startOffset": 150, "endOffset": 154}, {"referenceID": 33, "context": "We also thank everyone who contributed to building and maintaining the openly available data sets on the UCI Machine Learning Repository; other links [33][34] are cited in the References.", "startOffset": 154, "endOffset": 158}], "year": 2017, "abstractText": "Human activity recognition (HAR) has become a popular topic in research because of its wide application. With the development of deep learning, new ideas have appeared to address HAR problems. Here, a deep network architecture using residual bidirectional long short-term memory (LSTM) cells is proposed. The advantages of the new network include that a bidirectional connection can concatenate the positive time direction (forward state) and the negative time direction (backward state). Second, residual connections between stacked cells act as highways for gradients, which can pass underlying information directly to the upper layer, effectively avoiding the gradient vanishing problem. Generally, the proposed network shows improvements on both the temporal (using bidirectional cells) and the spatial (residual connections stacked deeply) dimensions, aiming to enhance the recognition rate. When tested with the Opportunity data set and the public domain UCI data set, the accuracy was increased by 4.78% and 3.68%, respectively, compared with previously reported results. Finally, the confusion matrix of the public domain UCI data set was analyzed.", "creator": "Microsoft\u00ae Word 2010"}}}