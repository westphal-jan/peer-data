{"id": "1709.01144", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Aug-2017", "title": "Information Theoretic Analysis of DNN-HMM Acoustic Modeling", "abstract": "We propose an information theoretic framework for quantitative assessment of acoustic modeling for hidden Markov model (HMM) based automatic speech recognition (ASR). Acoustic modeling yields the probabilities of HMM sub-word states for a short temporal window of speech acoustic features. We cast ASR as a communication channel where the input sub-word probabilities convey the information about the output HMM state sequence. The quality of the acoustic model is thus quantified in terms of the information transmitted through this channel. The process of inferring the most likely HMM state sequence from the sub-word probabilities is known as decoding. HMM based decoding assumes that an acoustic model yields accurate state-level probabilities and the data distribution given the underlying hidden state is independent of any other state in the sequence. We quantify 1) the acoustic model accuracy and 2) its robustness to mismatch between data and the HMM conditional independence assumption in terms of some mutual information quantities. In this context, exploiting deep neural network (DNN) posterior probabilities leads to a simple and straightforward analysis framework to assess shortcomings of the acoustic model for HMM based decoding. This analysis enables us to evaluate the Gaussian mixture acoustic model (GMM) and the importance of many hidden layers in DNNs without any need of explicit speech recognition. In addition, it sheds light on the contribution of low-dimensional models to enhance acoustic modeling for better compliance with the HMM based decoding requirements.", "histories": [["v1", "Tue, 29 Aug 2017 10:03:05 GMT  (1287kb,D)", "http://arxiv.org/abs/1709.01144v1", null]], "reviews": [], "SUBJECTS": "cs.SD cs.CL cs.LG", "authors": ["pranay dighe", "afsaneh asaei", "herv\\'e bourlard"], "accepted": false, "id": "1709.01144"}, "pdf": {"name": "1709.01144.pdf", "metadata": {"source": "CRF", "title": "Information Theoretic Analysis of DNN-HMM Acoustic Modeling", "authors": ["Pranay Dighe", "Afsaneh Asaei"], "emails": [], "sections": [{"heading": null, "text": "The process of inferring the most likely HMM state sequence from the sub-word probabilities is known as decoding. HMM based decoding assumes that an acoustic model yields accurate state-level probabilities and the data distribution given the underlying hidden state is independent of any other state in the sequence. We quantify 1) the acoustic model accuracy and 2) its robustness to mismatch between data and the HMM conditional independence assumption in terms of some mutual information quantities. In this context, exploiting deep neural network (DNN) posterior probabilities leads to a simple and straightforward analysis framework to assess shortcomings of the acoustic model for HMM based decoding. This analysis enables us to evaluate the Gaussian mixture acoustic model (GMM) and the importance of many hidden layers in DNNs without any need of explicit speech recognition. In addition, it sheds light on the contribution of low-dimensional models to enhance acoustic modeling for better compliance with the HMM based decoding requirements.\nIndex Terms\u2014automatic speech recognition, acoustic modeling, information theory, deep neural networks, conditional mutual information, low-rank and sparsity.\nI. INTRODUCTION\nOver the last 40 years, hidden Markov models (HMMs, and more recently DNN-HMM) have served as the backbone1 of virtually all large scale Automatic Speech Recognition (ASR) systems [1], [2], [3]. However, HMMs are built upon several major assumptions which are well known and understood, yet often shattered in the speech community [4], [5], [6].\nMore specifically, the HMM theory relies on the following assumptions. Firstly, the probability distribution associated to a hidden state depends only on that state. Therefore, the acoustic observation is conditionally independent of all the rest given the underlying hidden state. This assumption limits the scope of temporal dependency captured by HMMs. Secondly, HMM is a first-order Markov model, i.e., the probability of the Markov chain to be in a particular state at a time step depends solely on the previously visited state and nothing else. Furthermore, traditional HMM based sequence modeling requires a-priori definition of the state probabilistic distribution, which\n1As a general framework, HMMs are often considered as the \u201cwheel\u201d of sequence processing in general, and speech processing in particular.\nwas often considered as a mixture of multivariate Gaussians in GMM based HMM systems.\nIn modern hybrid DNN-HMM architectures, the DNNs make no such assumption about the statistical distribution of the observations and directly estimate the state-specific posterior probabilities, possibly conditioned on some limited temporal context. Replacing GMM acoustic models by DNNs to achieve these hybrid speech recognition systems [4] has been the single largest source of ASR performance improvement in the last few years [7]. This leap in performance achieved by using DNN acoustic models necessitates the study of the following fundamental questions:\nDoes DNN based acoustic modeling specifically fulfil the HMM assumptions better than GMMs ? And if so, can we formally identify some properties desired in an acoustic model for improving ASR performance ?\nThe present work is an attempt towards answering the above questions by deriving an information theoretic analysis framework to probe multiple facets of DNN-HMM speech recognition. This work adds to the growing body of research (summarised in Section II-B) which has analysed the contribution of DNNs in improving HMM-based ASR. In a broader sense, it addresses the following open questions regarding the role of any acoustic model that can be considered for HMM based ASR:\n1) How to quantify the quality of the acoustic model in terms of its ability to make accurate predictions ? 2) How to evaluate the robustness of the acoustic model towards the violation of HMM assumptions ?\nThis work takes a novel information theoretic standpoint to gather evidence that the improved ASR performance due to DNN-HMMs is a result of more accurate acoustic modeling as well as better compliance with the HMM assumptions for state decoding. The core analysis in this paper depends upon conceptualising the traditional HMM formulation in a different manner. Instead of treating a continuous multi-dimensional acoustic feature (e.g. a MFCC vector) as an observation, we treat the acoustic model\u2019s state prediction as a discrete observable feature emitted by the hidden HMM state. This simple trick facilitates the computation of some important information theoretic terms which are otherwise highly nontrivial to compute using acoustic features. These information theoretic measurements can directly quantify the quality of the acoustic model for HMM based ASR instead of relying on fullfledged ASR related measurements like frame classification accuracy or word error rate (WER).\nar X\niv :1\n70 9.\n01 14\n4v 1\n[ cs\n.S D\n] 2\n9 A\nug 2\n01 7\n2\nThus, the result of the present study yields novel quantitative evaluation measures of an acoustic model without the need to perform explicit ASR. It also elucidates how DNN leads to ASR improvements and where should the research and design strategy of acoustic models be focused on to target the limitations in HMM-based decoding.\nThe rest of the paper is organised as follows: Section II provides background on HMM based speech recognition and discusses the relevant prior research in detail. Section III introduces a speaking-listening perspective to the process of ASR using a novel z-HMM formulation. Section IV introduces our information theoretic analysis of the desired acoustic model properties using z-HMM formulation. Section V describes the experimental results and analysis of our findings and finally, Section VI draws the conclusions of our work and discusses the directions for future work. The important notations for the mathematical expressions are listed in Table I."}, {"heading": "II. BACKGROUND AND PRIOR RESEARCH", "text": "Speech is a complex time-varying signal which is usually assumed as resulting from a piece-wise stationary stochastic process so that the observed signal can be modelled by a Hidden Markov Model (HMM). HMM is a probabilistic finite state model in which the state-specific emission probability distribution is assumed to be independent of previous states and previous observations, and the transition probabilities follow a first-order Markovian structure."}, {"heading": "A. Foundation of HMM based Speech Recognition", "text": "In a typical HMM based ASR framework, the hypothesised word sequence W\u0302 is estimated from the sequence of acoustic features X = {X1, . . . , Xt, . . . XT }, where Xt is a standard acoustic feature (e.g., MFCC with first and second order time derivatives) at time t, as\nW\u0302 = argmax W P (W|X ) = argmax W p(X|W)P (W) (1)\nwhere p(W) is the probability of word sequence W estimated from language model and p(X|W) is the likelihood of the acoustic sequence conditioned on the word sequence, estimated from the acoustic model (consisting here of a DNN, followed by a HMM). Marginalising over all possible (hidden) state sequences, p(X|W) is then computed as:\np(X|W) = \u2211 Q p(X|Q,W)P (Q|W)\n\u2248 max Q p(X|Q,W)P (Q|W)\n= \u03c0(Q1) T\u220f t=2 aQt\u22121Qt T\u220f t=1 p(Xt|Qt)\n(2)\nwhere Q =< Q1, . . . , QT > is the most probable state sequence obtained from Viterbi algorithm for decoding, \u03c0Q1 is the initial state probability, aQt\u22121Qt is the state transition probabilities, and p(Xt|Qt) is the likelihood of speech frame Xt given the hidden state Qt. In Bayesian acoustic modelling (GMM-HMM), the frame likelihood p(Xt|Qt) is modelled by a mixture of Gaussian distributions whereas in a hybrid deep neural network system (DNN-HMM), data (scaled) likelihood is approximated using state posteriors (obtained at the output of the DNN) and HMM-state prior probabilities as\np(Xt|Qt) \u2248 p(Xt|Qt) p(Xt) = P (Qt|Xt) P (Qt)\n(3)\nwhere the state posterior probabilities P (Qt|Xt) are computed by a DNN, while prior probabilities P (Qt) are estimated from the state frequency counts over the training data.\nThe best acoustic model for HMM decoding should yield accurate state-specific probabilities (ideally independent of previous frames and previous states) leading to correct classification of the hidden state Qt conditioned (only) on acoustic feature Xt. Moreover, the HMM structure requires that for a given hidden state Qt, the acoustic observation Xt is conditionally independent of all the past and future hidden states Q\u00act and observations X\u00act, where \u00act denotes time index other than t."}, {"heading": "B. Prior Research", "text": "Building upon work initiated in the early 90\u2019s [4], and fully exploiting the availability of larger amount of training data and processing power, DNNs are now recognised to outperform GMMs in HMM based ASR [7]. Several studies have been conducted to better understand the reasons behind superior performance of DNN acoustic models. We review the previous research findings to enlist some of these properties desired in an acoustic model for improving HMM based ASR.\n1) Towards Better State Conditional Probabilities: A detailed discussion in [5], [8] argues that accurate sequence decoding using HMM requires the acoustic model to be structurally discriminative of the underlying classes and the model should capture their distinctive features. Furthermore, the acoustic model should be designed to preserve a maximum of information (maximum mutual information) between the input features and its associated HMM state.\nRecent investigations on the key factors contributing to the success of DNNs highlighted their invariant representation learning power for class discrimination [7], [9]. Unlike the generative GMM models, DNNs derive discriminative representations of the data by applying non-linear transforms\n3 through multiple hidden layers. In [10], it was found that the individual neurons in each of the DNN hidden layers learn to be selectively active in different ways towards distinct phone patterns. At the same time, information irrelevant to phonetic discrimination such as gender are discarded by the deeper (closer to the output) layers. It was also confirmed analytically in [11] that DNNs are significantly better at phone classification compared to GMMs and, although robustness against unseen noise and data/channel mismatch is a challenge, they still outperform GMMs in these conditions. Finally, it has been shown theoretically and experimentally that a DNN alleviates the need for an explicit probability distribution to model the data, and its data-driven discriminative approach leads to more accurate modeling of the underlying class (HMM states) distribution.\nIn short, the first lesson learnt so far from prior research attributes DNNs success partly due to the accurate estimation of the state-specific probabilities and better discrimination of the boundaries, resulting in superior HMM state-level classification results.\n2) Acoustic Model Meets the Markovian Structure: Another body of works investigating the sources of the data-model mismatch are dedicated to studying the effects of HMM structural hypothesis on ASR failures. In particular, the conditional independence assumption of HMM is often acknowledged as the number one limiting factor resulting in poor ASR performance and lack of robustness [12].\nNatural speech exhibits strong temporal correlations and contextual dependencies. This correlation is partly present in the acoustic features. HMM conditional independence assumption requires that the acoustic features associated with a specific sub-word (senone) state are independent of the past and future states and acoustic features. To test this hypothesis, earlier works [13], [6] replaced real speech data with synthetic data which strictly follow HMM assumptions. When conditional independence assumptions are strictly followed by the synthetic data, the ASR performance was found to be nearly perfect even using GMM-HMM architecture.\nAlong this line, [12], [14] have studied how DNNs cope with violation of HMM assumptions. It was shown that using many hidden layers in DNNs yields acoustic models less sensitive to the contextual dependencies. Each hidden layer successively makes the system more robust towards the contextual dependencies existing in the real speech data, hence resulting in better ASR.\nA different approach to tackle the limitation of conditional independence assumption relies on alternative architectures that can capture longer temporal dependencies. For instance, the segmental models for stochastic modelling of speech [15] are employed to model a long duration of a speech segment as a unit instead of the frame-wise modeling procedure. In segmental models, the HMM conditional independence assumptions are not enforced within a segment, thus reducing the data-model mismatch. More recently, end-to-end ASR systems like attention-based mechanisms using long short term memory implementation of the recurrent neural networks (LSTM-RNNs) [16], [17], [18] are notable efforts in this direction.\nThe present work aims to theoretically quantify the contributions of DNNs and their impact on ASR performance to address the limitations imposed by HMM assumptions. Hence, building on the conclusions of earlier analytic studies and research objectives, we will show here that an important reason for the success of DNNs is their lower sensitivity to the contextual dependencies existing in the data which results in better fulfilment of the HMM conditional independence requirement.\nIn this paper, we consider the two desired properties of the acoustic model (discussed above and in Section II-B1), namely, the state conditional probabilities must be (1) accurate and (2) independent of each other."}, {"heading": "C. Our Approach and Contributions", "text": "This work presents a novel information theoretic framework to conduct quantitative analysis of acoustic models for HMMbased ASR. The motivation is to understand and quantify what makes an acoustic model superior to others. Specifically, the proposed method is based on analysing the state conditional posterior probabilities generated by an acoustic model to evaluate their accuracy and compliance with the HMM assumptions.\nOne limitation of the previous studies in identifying the key reasons for the success of DNN based acoustic modeling is that they mostly rely on empirical evidences such as phone classification errors and ASR accuracies for validation of their hypotheses. In contrast, a methodology to quantify the desired acoustic model properties without performing ASR can measure the deficiencies in disjoint aspects. The present work attempts to address this need through a simple and straightforward information theoretic analysis framework.\nThe proposed solution casts ASR as a communication channel where the input state probabilities convey the information about the output state sequence. ASR performance is expected to be better when this channel has a high information capacity. We quantify the amount of transmitted information and the mismatch between the acoustic model and the HMM assumptions using information theoretic notion of mutual information. We demonstrate that higher capacity (accurate state posterior probabilities) and lower conditional mutual information (fulfilment of HMM assumptions) leads to improvement in ASR performance.\nUnlike previous mutual information estimation using GMM that requires expectation maximization (EM) to learn a joint probability distribution [19], the proposed method directly uses the DNN based acoustic models in a simple and efficient information calculation procedure. Along this line, we introduce a novel z-HMM framework in Section III which facilitates quantifying the mutual information and leads to a novel perspective to ASR formulation.\nAs a use case, we apply the proposed evaluation framework to measure the effect of sparse and low-rank projections in improving DNN based acoustic modeling. It was shown in [20] that DNN based posterior probabilities live in a union of low-dimensional subspaces that can be characterized using\n4\nsparse [21] and low-rank representations [22], [23], [24]. Using the information theoretic analysis provided in this work, we are able to identify the specific contribution brought in by sparse and low-rank enhancements to the DNN acoustic models.\nThe next section introduces a speaking-listening perspective to the process of ASR.\nIII. SPEAKING-LISTENING z-HMM PERSPECTIVE\nThe graphical model for a traditional speech recognition HMM (in Figure 1(a)) as discussed in Section II consists of a sequence of hidden states which emit observable acoustic features at each time step. In terms of random variables, the hidden state Qt underlies the generation of feature Xt. Acoustic feature Xt can take a value xt \u2208 Rn and state Qt can take a value qt \u2208 Q from the set of senones.\nFor the sake of the proposed analysis of acoustic models in HMM based ASR, we introduce a novel z-HMM formulation here, as follows. The acoustic model estimates the posterior probabilities of senone classes based on the observed acoustic feature Xt. This probabilistic prediction about the value taken by the random variable Qt (denoting the hidden state) is distinguished from the hidden state itself and is used to define a new random variable Zt which is now considered as an observable feature. The graphical model in Figure 1(b) depicts this process. We call this model as z-HMM since the emission from the hidden state Qt is the discrete random variable Zt. Probability distribution over Zt is conditioned over Xt and is given by the acoustic model in form of the posterior feature zt.\nIn that framework, we thus introduce distinct interpretations for the HMM\u2019s hidden state and the acoustic model\u2019s prediction as separate random variables corresponding to \u2022 Qt: Speaking random variable \u2022 Zt: Listening random variable\nwhere the speaker intends the production of senone Qt at time t. The speech signal acoustic feature Xt serves as the information bearing medium through which the listener infers the senone Zt in a probabilistic manner using the posterior\nprobabilities P (Zt = qk|Xt = xt) for all qk \u2208 Q. The task of recognition is to find the most likely hidden state sequence Q given the probabilities of Zt\u2019s over t. Thus, we consider ASR as a communication channel (Figure 1(c)) where the input is the sequence of listening random variable Z , obtained from the acoustic model (e.g. DNN), and the output is the sequence of speaker random variable Q. From this perspective, z-HMM can be interpreted as a joint speaking-listening HMM where the speaking process is represented by the underlying sequence Q leading to the observation X and the listening process inferred from X is represented by Z .\nTo complete the definition of z-HMM, we define the conditional posterior probabilities of z-HMM hidden states as follows:\n\u2200qk \u2208 Q;P (Qt = qk|Zt = qk) := P (Zt = qk|Xt = xt) (4) = P (Qt = qk|Xt = xt) (5)\nwhere equality (4) is by definition of z-HMM and the equality (5) is due to the way we defined random variable Zt. In other words, a one-to-one relationship holds between the hidden states and the senone observation [25]. The other posterior probabilities given by acoustic model are distributed according to the one-to-one mapping (disjoint probabilities) and they are considered irrelevant to the current state probability for a particular senone observation.\nIt is important to note here that we do not actually have access to exact value taken by any particular Zt; what we have is only the acoustic model\u2019s probabilistic prediction about the random variable Zt taking values from the set of senones Q conditioned on the intermediate feature Xt.\nIn the next section, we present the information theoretic analysis of the acoustic models based on z-HMM formulation described above.\nIV. INFORMATION THEORETIC ANALYSIS\nIn the context of z-HMM described above, the desired properties of the acoustic model, namely, (1) high accuracy of the state conditional posterior probabilities and (2) compliance with the HMM assumptions are quantified as\n5 (i) I(Zt;Qt): the mutual information between the observed feature Zt and the underlying hidden state Qt, and\n(ii) I(Zt;Qt\u22121|Qt): the mutual information between the feature Zt and the former state Qt\u22121 if the current hidden state Qt is known,\nrespectively. The notion of mutual information is defined in Section IV-A. We will explain the relation between the above quantities and the desired acoustic model properties in Section IV-B."}, {"heading": "A. Mutual Information", "text": "In information theory, the mutual information of two random variables quantifies the information conveyed about one random variable, by the other random variable. This concept is defined through the notion of entropy which measures the quantity of information held in a random variable [26].\nFor a discrete random variable A which takes values a \u2208 A, the entropy H(A) is defined as\nH(A) = \u2212 \u2211 a\u2208A P (A = a) log(P (A = a)) (6)\nAccordingly, the conditional entropy H(A|B) of a random variable A given another random variable B, which takes values b \u2208 B, is defined as\nH(A|B) = \u2211 b\u2208B P (B = b)H(A|B = b) where\nH(A|B = b) = \u2212 \u2211 a\u2208A P (A = a|B = b) log(P (A = a|B = b))\n(7)\nEntropy quantifies the uncertainty of a random variable; thereby, it increases as the uncertainty about the underlying values grows or p(A) and p(B) approach a uniform distribution.\nMutual information I(A;B) between two random variables A and B is the measure of mutual dependence between the two variables. It quantifies reduction in uncertainty of A due to the knowledge of B, and vice versa. It is defined as\nI(A;B) = H(A)\u2212H(A|B) = H(B)\u2212H(B|A) (8)\nAccordingly, conditional mutual information is defined as\nI(A;B|C) = H(A|C)\u2212H(A|B,C) (9)"}, {"heading": "B. Desired Acoustic Model Properties", "text": "The z-HMM ASR communication channel discussed in Section III is most efficient when 1) the observed input feature Zt and the underlying hidden state Qt which is to be decoded have the highest mutual information I(Zt;Qt), and 2) the HMM conditional independence assumption is satisfied so that the mutual information between the feature and the former hidden state is minimized if the current hidden state is known, i.e. I(Zt;Qt\u22121|Qt) approaches zero. Thus, we discuss the following two properties of an ideal acoustic model for the best classification and compliance with the HMM structure:\n1) High Information Transmission Capacity (P1): To maximize the amount of information transmitted by the acoustic model for state decoding, it is desired to have a high mutual information between the feature Zt and the underlying state Qt expressed as\nI(Zt;Qt) = H(Zt)\u2212H(Zt|Qt) \u2200t \u2208 {1, . . . , T} (10)\nIn an ideal scenario, no uncertainty should be left in the acoustic model\u2019s prediction by revealing the underlying hidden state (i.e. H(Zt|Qt) should be zero) because of the one-to-one mapping between Q and Z. But, due to variability in the intermediate acoustic features Xt and correlations between senone states, the acoustic model\u2019s prediction Zt is not deterministic and the probabilities P (Zt|Qt)\u2019s are not binary, leading to a non-zero value of H(Zt|Qt) (more in Section V-F). We rely on I(Zt;Qt) as the measure of the information transmitted by the acoustic model in the ASR communication channel [27].\nDue to the data-processing inequality [26], I(Zt;Qt) \u2264 I(Xt;Qt) with the equality being achieved when Zt is the sufficient statistic of features Xt. Maximizing I(Zt;Qt) thus ensures deriving highly informative features Zt from Xt to transfer maximum information about Qt for state decoding.\n2) First-order Markovian HMM Structure (P2): It is desired that the acoustic model yields robustness to the HMM conditional independence assumption that is often violated by the speech acoustic features. In other words, the feature Zt emitted by an underlying state Qt should be independent of the past and future observations and states if the current state Qt is given. This property can be expressed as\nZt \u22a5 {Q\u00act, Z\u00act} |Qt (11)\nIn this work, we confine our analysis of conditional independence only to the preceding hidden state Qt\u22121 although our algorithmic approach is generally applicable to any order of dependency computation. We quantify the following condition:\nZt \u22a5 Qt\u22121|Qt (12)\nTo measure the amount of mutual dependence between Zt and Qt\u22121, we deploy conditional mutual information as\nI(Zt;Qt\u22121|Qt) = H(Zt|Qt)\u2212H(Zt|Qt\u22121, Qt) (13)\nIn an ideal scenario, I(Zt;Qt\u22121|Qt) = 0 indicates that the acoustic model fulfills the first-order Markovian requirement for HMM based decoding. Hence, the issue of data-model mismatch due to the long temporal correlations would be perfectly alleviated by the ideal acoustic model (DNN)."}, {"heading": "C. Computational Procedure using Posterior Features", "text": "In this section, we develop the procedure to quantify the desired properties P1 and P2 by using the posterior probability features generated by the acoustic model. This approach relies on DNN\u2019s capability as an acoustic model to directly generate posterior probabilities for underlying senone classes. Assuming that the acoustic models are trained on some transcribed training data, we perform this analysis on a separate development dataset (which has transcription available) because\n6 Algorithm 1 : I(Zt;Qt) and I(Zt;Qt\u22121|Qt) computation using DNN posteriors Require: : DNN posteriors zt and ground truth based forced senone alignment.\n1: P (Zt) is estimated by averaging all the posteriors from the training data. 2: H(Zt) is calculated using (6). 3: P (Zt|Qt = qk) is estimated through averaging all posteriors zt aligned to senone qk. 4: H(Zt|Qt = qk) is calculated using (6). 5: P (Zt|Qt\u22121 = qk\u2032 , Qt = qk) is estimated by averaging all posteriors zt aligned to senone qk preceded by senone qk\u2032 . 6: H(Zt|Qt\u22121 = qk\u2032 , Qt = qk) is calculated using (6). 7: H(Zt|Qt) is calculated using (7) using the senone specific entropies estimated in step 4. 8: H(Zt|Qt\u22121, Qt) is calculated using (7) using the senone entropy terms estimated in step 6. 9: I(Zt;Qt) is calculated using (10) and the entropies estimated in steps 2 and 7 .\n10: I(Zt;Qt\u22121|Qt) is calculated using (13) and the entropies estimated in steps 7 and 8 .\nwe need the ground truth based forced senone alignments to compute the various information theoretic terms explained above. Test data is not used for this analysis.\nTo measure P1 and P2, the following quantifies must be computed and used for calculation of the mutual information measures in (10) and (13):\n{H(Zt), H(Zt|Qt), H(Zt|Qt, Qt\u22121)} (14)\nThe above entropy terms in turn require computation of the following probabilities:\n{P (Zt), P (Zt|Qt), P (Zt|Qt, Qt\u22121)} (15)\nThe acoustic model yields posterior features zt as:\nzt = [P (Zt = q1|Xt = xt) . . . P (Zt = qK |Xt = xt)]>\n= P (Zt|Xt = xt) (16)\nas probability distribution for the random variable Zt conditioned on the acoustic feature Xt. We generate the posterior features zt\u2019s and forced alignments Q for all the utterances in the development data.\nTo compute P (Zt), we consider all the feature frames in a Monte Carlo method and approximate P (Zt) as the average posterior probability by marginalization over Xt:\nP (Zt) = [P (Zt = q1) . . . P (Zt = qK)] >\n\u2248 N\u2211 t=1 P (Zt|Xt = xt)P (Xt = xt) = 1 N N\u2211 t=1 zt (17)\nwhere N is the total number of frames in the data. A uniform probability distribution is assumed for the acoustic features Xt. Given a large sample size in analysis of the large vocabulary ASR, ensemble averaging yields a reliable estimate.\nTo obtain the state conditional probabilities P (Zt|Qt = qk), we consider only the frames aligned to the state Qt = qk in the forced alignments for marginalization over acoustic features.\nThus, we have\nP (Zt|Qt = qk) \u2248 \u2211 t s.t.\nQt=qk\nP (Zt|Xt = xt, Qt = qk)P (Xt = xt|Qt = qk)\n\u2248 1 Nqk \u2211 t s.t.\nQt=qk\nzt\n(18)\nwhere Nqk is the number of frames aligned to senone qk. In a similar manner, we compute P (Zt|Qt = qk, Qt\u22121 = qk\u2032) by considering only those frames that are aligned to state Qt = qk and the preceding frame is aligned to state Qt\u22121 = qk\u2032 :\nP (Zt|Qt = qk, Qt = qk\u2032) (19) \u2248 \u2211\nt s.t. Qt=qk Qt\u22121=qk\u2032\nP (Zt|Xt = xt, Qt = qk, Qt\u22121 = qk\u2032)\n\u00d7 P (Xt = xt|Qt = qk, Qt\u22121 = qk\u2032)\n\u2248= 1 Nqk,qk\u2032 \u2211 t s.t. Qt=qk Qt\u22121=qk\u2032 zt\nwhere Nqk,qk\u2032 is the number of frames aligned to senone qk such that preceding frame is aligned to senone qk\u2032 .\nThe steps to compute the entropies in (14) and calculation of the required mutual information quantities from probabilities computed in (17), (18) and (19) are listed in Algorithm 1. The state prior probabilities and state transition probabilities involved in computations shown in Algorithm 1:\n{P (Qt = qk), P (Qt = qk, Qt\u22121 = q\u2032k)}\nare obtained by the frequency count approach using the ground truth forced alignment. Quality of the acoustic model used for ASR is measured based on a high value of I(Zt;Qt) (P1) and a low value of I(Zt;Qt\u22121|Qt) (P2)."}, {"heading": "V. NUMERICAL EVALUATION AND ANALYSIS", "text": "Experiments are conducted on the challenging AMI corpus [28], consisting of conversational speech (in smart meeting rooms) in accented English. We use different acoustic models\n7\nand evaluate properties P1 and P2. The acoustic models considered are based on standard Gaussian mixture model (GMM) or DNNs with different architectures. These are studied in Section V-B. Furthermore, we investigate the effect of sparse and low-rank enhancements, as proposed in [22], on DNN acoustic models in Section V-E."}, {"heading": "A. Experimental Setup", "text": "AMI corpus contains recordings of spontaneous conversations in multiparty meeting scenario. We use recordings from individual head microphones (IHM) comprising of around 67 hours of train set, 9 hours of development (dev) set, and 7 hours test set. All acoustic models are trained using the same training data. 10% of the training data is used for crossvalidation during DNN training. Kaldi toolkit [29] is used for training of GMM and DNN-HMM systems.\nThe input features are 39 dimensional Mel frequency Cepstral coefficients (MFCC) together with their first order (\u2206) and second order (\u2206\u2206) temporal derivatives, hence resulting in 39\u00d79=351 dimensional input, and an output class space of dimension 4007, representing the senone probability vector space. A GMM-HMM system is used to get the ground truth based forced senone alignments over the train set and dev set. These alignments serve as the hidden state sequences Q for our analysis.\nBased on previous experiments, our best baseline DNN acoustic model has 4 hidden layers with 1200 nodes each and it is trained using hard targets from GMM-HMM alignment. DNN posteriors (probability distributions over Zt\u2019s) are obtained for the dev set using forward pass, whereas the GMM posteriors are computed as the scaled likelihoods using Gaussian mixture distributions learned from the training data.\nThe information theoretic analysis of different acoustic models is shown in Table II. The last row shows various quantities by treating forced senone alignments as binary posterior features. Hence, the entropy H(Zt) here refers to\nthe entropy of the prior probabilities of senone classes and this row essentially depicts the most ideal values we could hope to achieve from an acoustic model."}, {"heading": "B. Comparing DNN v/s GMM Acoustic Modeling", "text": "We compare the first two rows of Table II here. Our primary observation is that DNN based probabilities on Zt have lower entropy H(Zt) than GMM\u2019s. This means that the level of uncertainty in DNN outputs is typically lower than the GMM posteriors.\nMoreover, we observe higher mutual information I(Zt;Qt) in DNN acoustic models which indicates more information transmission through the ASR communication channel (cf. Figure 1(c)) as compared to GMMs. Thereby, the capacity of the channel is higher and the DNN posteriors are more accurate in discrimination of the underlying senone classes. This confirms the well known better modeling capability of DNN as compared to GMM.\nFurthermore, the HMM conditional independence criterion is better satisfied by the DNN acoustic model as the conditional mutual information between current observation and the former state if the current state is given, I(Zt;Qt\u22121|Qt), is lower for DNN as compared to GMM. When these models are used to perform ASR on test data, DNN performs significantly better than GMM as expected. Nonetheless, we can quantify the desired acoustic model properties individually regardless of the ASR results.\nSince the information theoretic criteria are computed prior to decoding for ASR, this study essentially disentangles the contribution of the language model. The additional information conveyed by the language model can be quantified nevertheless by re-estimation of the frame level senone posteriors after a full fledged ASR decoding."}, {"heading": "C. Effect of Increasing Depth in DNN Acoustic Models", "text": "A very interesting evaluation is to measure the contribution of increasing the number of DNN hidden layers. The results\n8\nare listed in Tables II. We compare DNN architectures in a manner similar to the study in [12] where number of hidden layers are increased with or without keeping the total number of network parameters equal to the baseline DNN. DNN with 0 hidden layer is simply a logistic regression model with input layer connected directly to the output layer.\nIt is a striking observation that the deeper architectures always have higher mutual information I(Zt;Qt) leading to higher acoustic model accuracy. This trend is observed in both the cases- when number of parameters are equal and when they are not. On the other hand, we observe quite negligible effect of the depth of DNN on the robustness towards violation of HMM conditional independence assumption. Regardless of this, we find that all DNN architectures have lower value of I(Zt;Qt\u22121|Qt) as compared to the baseline GMM acoustic model.\nThe zero hidden layer logistic regression network has the poorest performance in the ASR task despite having the lowest correlation between the features and the past state. This is partly explained by the very low mutual information I(Zt;Qt) between its predictions and the underlying senone states. We also note the high values of state conditional entropies H(Zt|Qt) and H(Zt|Qt, Qt\u22121) for this model which essentially indicate highly inaccurate senone predictions rendering the model inferior to GMM and DNN acoustic models."}, {"heading": "D. Sparse and Low-rank Acoustic Model Enhancement", "text": "In [22], [23], we modify the forward pass outputs of the baseline DNN using (1) principal component analysis (PCA) based low-rank reconstruction and (2) overcomplete dictionary based sparse reconstruction. We learn principal component matrix and dictionary for each senone separately. Then, lowrank or sparse reconstruction is done in a supervised fashion by picking the PCA matrix or dictionary corresponding to the ground truth senone label for reconstruction.\nThis idea is illustrated in Figure 2(a). PCA projects data onto a low-dimensional subspace whereas sparsity achieves the same goal by expressing data as a sparse linear combination of columns of an overcomplete dictionary. This process essen-\ntially computes the projection of DNN output posterior features on the correct senone subspace. In terms of information theory, the acoustic modeling component (Figure 2(b)) now consists of DNN acoustic model followed by an additional block of principal component transform or dictionary based sparse coding.\nWe observe in Table III that enhanced DNN models have lower entropies H(Zt) and H(Zt|Qt) than baseline DNN. Also, the mutual information I(Zt;Qt), between hidden senone state Qt and the observation Zt, increases significantly using low-rank and sparse enhancements. These observations support our claim that low-rank and sparse reconstruction enforce the posterior features to capture more information related to the underlying senone subspace. Specially, in the case of PCA based reconstruction, we observe that the mutual information I(Zt;Qt) is maximum.\nThe increase in mutual information I(Zt;Qt) from baseline DNN to low-rank and sparsity based models explicitly quantifies the additional information that is contributed by the enhancement process. Note that PCA and dictionary based reconstruction are able to exploit the global information about the senone subspaces and thus they ought to bring additional information to the DNN local estimates. This information is available in terms of global patterns within each senone\u2019s posterior features, but it is not accessible to the baseline DNN during a local forward pass of individual acoustic frames. It is only through the supervised enhancement using principal components or an overcomplete dictionary, that we are able to augment this global information in local framewise posterior features.\nAnother interesting observation is that the conditional independence assumption is also better satisfied (low values of I(Zt;Qt\u22121|Qt)) in case of low-rank and sparsity based reconstruction. We explain it as follows. The frames aligned with senone qk in the forced alignment can appear in different contexts in the data (see Figure 3) . They exhibit different contextual information in DNN posteriors due to different neighboring senones. This contextual information which is always present in the real data violates the conditional independence assumption of HMM and leads to compromise in\n9\nASR performance. When posterior features are reconstructed using PCA or an overcomplete dictionary, all the frames of senone qk are forced to lie on the common subspace which defines qk. By controlling the parameters of PCA and sparse reconstruction, we ensure that only the most important dynamics of the senone subspace are preserved during enhancement of posteriors. Context dependent information, which is local to an individual frame and does not appear in the global patterns of the subspace, is reduced after reconstruction. Thus, the enhanced posterior features fulfil the conditional independence assumption better than the posteriors before reconstruction.\nA caveat here is that the sparse and low-rank enhancements are done in a supervised fashion on the dev set by using the knowledge of forced alignments. Since we do not have alignments available for the test data, we can not directly evaluate the expected superiority of our acoustic model enhancement approach by performing ASR on test data. Instead, we use a simple methodology based on teacher-student DNN framework (used in [22]) to evaluate the ASR performance of our approach on test data. This is investigated in the following section."}, {"heading": "E. Learning Student Networks Using Sparse or Low-rank Soft Targets", "text": "Recently, in [22], [23], we proposed to train student DNN acoustic models using enhanced soft targets obtained from supervised sparse and low-rank projection. Enhanced soft targets are basically training data posteriors obtained from the forward pass of a DNN trained on binary labels and then reconstructed using PCA or sparse coding in a supervised manner as shown in Figure 2.\nThe main idea of the teacher-student DNN training is that a \u201cstudent\u201d DNN can be trained with soft targets (instead of the one-hot labels) obtained from a more sophisticated model\nserving as the \u201cteacher\u201d. In our approach, the student DNNs trained using enhanced soft targets try to learn- 1) the function modeled by the baseline DNN as well as 2) the reconstruction transformation performed by PCA or sparse coding.\nIn Table III, we provide the ASR performance of the sparse and low-rank soft targets based student DNNs to compare with the baseline DNN. By training student DNN models, we circumvent the issue that sparse and low-rank reconstruction requires forced alignments on the data. The student DNNs are expected to learn the reconstruction transformations implicitly in their parameters and enhance the test data posteriors accordingly during the forward pass. As expected, both the student models outperform the baseline DNN.\nTheoretical analysis provided in this work supports the importance of sparse and low-rank enhancements in improving DNN acoustic models which was confirmed in our previous works [21], [22], [23], [24] experimentally. We can now better predict the performance of an acoustic model in ASR communication channel based on its information capacity and ability to better fulfil the HMM assumptions."}, {"heading": "F. Further Implications", "text": "The speaking-listening z-HMM perspective provides different conceptual insights towards ASR. Assuming that the senone subspaces are independent, i.e. there is no correlation or contextual dependencies, a state Qt = qk should be deterministically mapped to the binary observation Zt = qk with the probability of one. However, as shown in [21], [22], senone subspaces are correlated with each other and they have ranks higher than unity for real data.\nThese correlations can arise from common parent nodes in senone decision trees or be the result of contextual dependencies of senones with each other as shown in Figure 4(a) and 4(b). Due to these correlations, a speaking (hidden) state\n10\nQt = qk does not necessarily emit the listening state Zt = qk deterministically. Instead, it can emit senone classes other than qk with non-zero probabilities (Fig.4(c)) and the one-to-one mapping is a limiting assumption.\nBuilding on the theories elaborated in Section III and discussion above, the KL-HMM approach in the prior work [30], [25] can be seen as associating a distribution P (Zt|Qt) to each state. A state-specific distribution enables capturing the senone correlations. It can also characterize a probabilistic listening process that can be easily adjusted/adapted for accented speech production or varied pronunciations.\nThe proposed information theoretic measures may also be applied in finding the optimal number of senones for higher capacity of the acoustic model. Complementarity of multiple features in a multi-stream architecture can be quantified and feature selection strategies can be devised accordingly. Moreover, we can evaluate the new paradigms for acoustic modeling relying on long short-term memory (LSTM) and recurrent neural network (RNN) deep learning architectures, and compare them with DNNs in terms of the desired acoustic model properties. In addition, the contribution of the language model in ASR decoding can be measured and evaluated independent of the acoustic model.\nThe bottom line is that this analysis can pinpoint the sources of failures and improvements in ASR and measure the distinct factors separately and independently. Beyond diagnosis of the ASR building blocks, analysis of failures in adversarial conditions due to the effect of recording channels and noise and interferences can be conducted to quantify and evaluate the amount of information loss for ASR decoding."}, {"heading": "VI. CONCLUSIONS", "text": "We presented an information theoretic approach to compare the quality of different acoustic models in HMM based ASR. We quantified the information transferred through an ASR communication channel as it decodes sequence of hidden HMM states. Higher amount of information transferred through this channel indicates better modeling capability of the acoustic model and higher accuracy. The conditional independence assumption of HMM is also evaluated in terms of the conditional mutual information between the current\nobservation and the previous state if the current state is given. Lower value of the conditional mutual information shows better compliance with the HMM structure. Our experimental analysis yields quantitative measurement for these different dimensions of the superiority of DNN based acoustic modelling over GMMs.\nIn addition, we measured the contribution of incremental increase in the depth of DNN in improving the quality of the acoustic modeling. Furthermore, we showed that low-rank and sparse reconstruction done by PCA transforms and overcomplete dictionaries for sparse coding respectively can further improve DNN acoustic modeling by bringing in additional global information about the senone subspaces to the DNN local estimations.\nThis analysis provides a novel approach to evaluate the quality of an acoustic model prior to using it for ASR on unseen test data. It also leads to a novel perspective to HMM based speech recognition exploiting the DNN acoustic model predictions as probabilistic features for state decoding. Future work will focus on the comprehensive ASR formulation and information theoretic evaluation of the acoustic modeling along with the language modeling component."}, {"heading": "ACKNOWLEDGEMENTS", "text": "The research leading to these results has received funding from by Swiss NSF project on \u201cParsimonious Hierarchical Automatic Speech Recognition and Query Detection (PHASERQUAD)\u201d grant number 200020-169398."}], "references": [{"title": "Continuous speech recognition by statistical methods", "author": ["Frederick Jelinek"], "venue": "Proceedings of the IEEE, vol. 64, no. 4, pp. 532\u2013556, 1976.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1976}, {"title": "A tutorial on hidden markov models and selected applications in speech recognition", "author": ["Lawrence R Rabiner"], "venue": "Proceedings of the IEEE, vol. 77, no. 2, pp. 257\u2013286, 1989.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1989}, {"title": "Statistical methods for speech recognition", "author": ["Frederick Jelinek"], "venue": "MIT press,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1997}, {"title": "Connectionist speech recognition: a hybrid approach, Springer", "author": ["Herve A Bourlard", "Nelson Morgan"], "venue": "Science & Business Media,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1994}, {"title": "What HMMs can do", "author": ["Jeff A Bilmes"], "venue": "IEICE Transactions on Information and Systems, vol. 89, no. 3, pp. 869\u2013891, 2006.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Don\u2019t multiply lightly: Quantifying problems with the acoustic model assumptions in speech recognition", "author": ["Dan Gillick", "Larry Gillick", "Steven Wegmann"], "venue": "IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU). IEEE, 2011, pp. 71\u201376.  11", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "author": ["Geoffrey Hinton", "Li Deng", "Dong Yu", "George E Dahl", "Abdel-rahman Mohamed", "Navdeep Jaitly", "Andrew Senior", "Vincent Vanhoucke", "Patrick Nguyen", "Tara N Sainath"], "venue": "IEEE Signal Processing Magazine, vol. 29, no. 6, pp. 82\u201397, 2012.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "What HMMs cant do", "author": ["Jeff A Bilmes"], "venue": "ATR Workshop, Invited paper and lecture, 2004.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Learning deep architectures for ai", "author": ["Yoshua Bengio"], "venue": "Foundations and trends R  \u00a9 in Machine Learning, vol. 2, no. 1, pp. 1\u2013127, 2009.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Exploring how deep neural networks form phonemic categories", "author": ["Tasha Nagamine", "Michael L Seltzer", "Nima Mesgarani"], "venue": "INTER- SPEECH, 2015, pp. 1912\u20131916.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "A Comparative Analytic Study on the Gaussian Mixture and Context Dependent Deep Neural Network Hidden Markov Models", "author": ["Dong Yu Chaojun Liu Yifan Gong Yan Huang"], "venue": "Interspeech 2014, 2014.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "How neural network depth compensates for hmm conditional independence assumptions in dnnhmm acoustic models", "author": ["Suman Ravuri", "Steven Wegmann"], "venue": "Interspeech 2016, pp. 2736\u20132740, 2016.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Studies with fabricated switchboard data: Exploring sources of modeldata mismatch", "author": ["Don McAllaster", "Larry Gillick", "Francesco Scattone", "Mike Newman"], "venue": "Proceedings of DARPA Broadcast News Transcription and Understanding Workshop, 1998.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1998}, {"title": "Discriminative training for speech recognition is compensating for statistical dependence in the hmm framework", "author": ["Dan Gillick", "Steven Wegmann", "Larry Gillick"], "venue": "2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2012, pp. 4745\u20134748.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "From hmm\u2019s to segment models: a unified view of stochastic modeling for speech recognition", "author": ["M. Ostendorf", "V.V. Digalakis", "O.A. Kimball"], "venue": "IEEE Transactions on Speech and Audio Processing, vol. 4, no. 5, pp. 360\u2013378, Sep 1996.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1996}, {"title": "Long shortterm memory recurrent neural network architectures for large scale acoustic modeling", "author": ["Hasim Sak", "Andrew W Senior", "Fran\u00e7oise Beaufays"], "venue": "2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "End-to-end attention-based large vocabulary speech recognition", "author": ["Dzmitry Bahdanau", "Jan Chorowski", "Dmitriy Serdyuk", "Yoshua Bengio"], "venue": "pp. 4945\u20134949, 2016.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Listen, attend and spell: A neural network for large vocabulary conversational speech recognition", "author": ["W. Chan", "N. Jaitly", "Q. Le", "O. Vinyals"], "venue": "2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2016, pp. 4960\u20134964.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Maximum mutual information based reduction strategies for cross-correlation based joint distributional modeling", "author": ["Jeff A Bilmes"], "venue": "Acoustics, Speech and Signal Processing, 1998. Proceedings of the 1998 IEEE International Conference on. IEEE, 1998, vol. 1, pp. 469\u2013472.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1998}, {"title": "Sparse modeling of neural network posterior probabilities for exemplar-based speech recognition", "author": ["Pranay Dighe", "Afsaneh Asaei", "Herv\u00e9 Bourlard"], "venue": "Speech Communication, vol. 76, pp. 230\u2013244, 2016.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "Exploiting lowdimensional structures to enhance dnn based acoustic modeling in speech recognition", "author": ["P. Dighe", "G. Luyet", "A. Asaei", "H. Bourlard"], "venue": "2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), March 2016, pp. 5690\u2013 5694.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Low-rank and sparse soft targets to learn better dnn acoustic models", "author": ["Pranay Dighe", "Afsaneh Asaei", "Herv\u00e9 Bourlard"], "venue": "2017.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2017}, {"title": "Exploiting eigenposteriors for semi-supervised training of dnn acoustic models with sequence discrimination", "author": ["Pranay Dighe", "Afsaneh Asaei", "Herv\u00e9 Bourlard"], "venue": "Proceedings of Interspeech, 2017.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2017}, {"title": "Lowrank representation of nearest neighbor phone posterior probabilities to enhance dnn acoustic modeling", "author": ["Gil Luyet", "Pranay Dighe", "Afsaneh Asaei", "Herv\u00e9 Bourlard"], "venue": "Interspeech, 2016.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "On modeling context-dependent clustered states: Comparing hmm/gmm, hybrid hmm/ann and kl-hmm approaches", "author": ["Marzieh Razavi", "Ramya Rasipuram", "Mathew Magimai-Doss"], "venue": "2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2014, pp. 7659\u20137663.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Entropy, relative entropy and mutual information", "author": ["Thomas M Cover", "Joy A Thomas"], "venue": "1991.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1991}, {"title": "Learning and generalization with the information bottleneck", "author": ["Ohad Shamir", "Sivan Sabato", "Naftali Tishby"], "venue": "International Conference on Algorithmic Learning Theory. Springer, 2008, pp. 92\u2013107.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "The ami meeting corpus", "author": ["Iain McCowan", "Jean Carletta", "W Kraaij", "S Ashby", "S Bourban", "M Flynn", "M Guillemot", "T Hain", "J Kadlec", "V Karaiskos"], "venue": "Proceedings of the 5th International Conference on Methods and Techniques in Behavioral Research, 2005, vol. 88.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2005}, {"title": "The kaldi speech recognition toolkit", "author": ["Daniel Povey", "Arnab Ghoshal", "Gilles Boulianne", "Luk\u00e1\u0161 Burget", "Ond\u0159ej Glembek", "Nagendra Goel", "Mirko Hannemann", "Petr Motl\u0131\u0301\u010dek", "Yanmin Qian", "Petr Schwarz"], "venue": "2011.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Using kl-based acoustic models in a large vocabulary recognition task", "author": ["Guillermo Aradilla", "Herve Bourlard", "Mathew Magimai-Doss"], "venue": "01 2008.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Over the last 40 years, hidden Markov models (HMMs, and more recently DNN-HMM) have served as the backbone1 of virtually all large scale Automatic Speech Recognition (ASR) systems [1], [2], [3].", "startOffset": 180, "endOffset": 183}, {"referenceID": 1, "context": "Over the last 40 years, hidden Markov models (HMMs, and more recently DNN-HMM) have served as the backbone1 of virtually all large scale Automatic Speech Recognition (ASR) systems [1], [2], [3].", "startOffset": 185, "endOffset": 188}, {"referenceID": 2, "context": "Over the last 40 years, hidden Markov models (HMMs, and more recently DNN-HMM) have served as the backbone1 of virtually all large scale Automatic Speech Recognition (ASR) systems [1], [2], [3].", "startOffset": 190, "endOffset": 193}, {"referenceID": 3, "context": "However, HMMs are built upon several major assumptions which are well known and understood, yet often shattered in the speech community [4], [5], [6].", "startOffset": 136, "endOffset": 139}, {"referenceID": 4, "context": "However, HMMs are built upon several major assumptions which are well known and understood, yet often shattered in the speech community [4], [5], [6].", "startOffset": 141, "endOffset": 144}, {"referenceID": 5, "context": "However, HMMs are built upon several major assumptions which are well known and understood, yet often shattered in the speech community [4], [5], [6].", "startOffset": 146, "endOffset": 149}, {"referenceID": 3, "context": "Replacing GMM acoustic models by DNNs to achieve these hybrid speech recognition systems [4] has been the single largest source of ASR performance improvement in the last few years [7].", "startOffset": 89, "endOffset": 92}, {"referenceID": 6, "context": "Replacing GMM acoustic models by DNNs to achieve these hybrid speech recognition systems [4] has been the single largest source of ASR performance improvement in the last few years [7].", "startOffset": 181, "endOffset": 184}, {"referenceID": 3, "context": "Building upon work initiated in the early 90\u2019s [4], and fully exploiting the availability of larger amount of training data and processing power, DNNs are now recognised to outperform GMMs in HMM based ASR [7].", "startOffset": 47, "endOffset": 50}, {"referenceID": 6, "context": "Building upon work initiated in the early 90\u2019s [4], and fully exploiting the availability of larger amount of training data and processing power, DNNs are now recognised to outperform GMMs in HMM based ASR [7].", "startOffset": 206, "endOffset": 209}, {"referenceID": 4, "context": "1) Towards Better State Conditional Probabilities: A detailed discussion in [5], [8] argues that accurate sequence decoding using HMM requires the acoustic model to be structurally discriminative of the underlying classes and the model should capture their distinctive features.", "startOffset": 76, "endOffset": 79}, {"referenceID": 7, "context": "1) Towards Better State Conditional Probabilities: A detailed discussion in [5], [8] argues that accurate sequence decoding using HMM requires the acoustic model to be structurally discriminative of the underlying classes and the model should capture their distinctive features.", "startOffset": 81, "endOffset": 84}, {"referenceID": 6, "context": "success of DNNs highlighted their invariant representation learning power for class discrimination [7], [9].", "startOffset": 99, "endOffset": 102}, {"referenceID": 8, "context": "success of DNNs highlighted their invariant representation learning power for class discrimination [7], [9].", "startOffset": 104, "endOffset": 107}, {"referenceID": 9, "context": "In [10], it was found that the individual neurons in each of the DNN hidden layers learn to be selectively active in different ways towards distinct phone patterns.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "It was also confirmed analytically in [11] that DNNs are significantly better at phone classification compared to GMMs and, although robustness against unseen noise and data/channel mismatch is a challenge, they still outperform GMMs in these conditions.", "startOffset": 38, "endOffset": 42}, {"referenceID": 11, "context": "In particular, the conditional independence assumption of HMM is often acknowledged as the number one limiting factor resulting in poor ASR performance and lack of robustness [12].", "startOffset": 175, "endOffset": 179}, {"referenceID": 12, "context": "To test this hypothesis, earlier works [13], [6] replaced real speech data with synthetic data which strictly follow HMM assumptions.", "startOffset": 39, "endOffset": 43}, {"referenceID": 5, "context": "To test this hypothesis, earlier works [13], [6] replaced real speech data with synthetic data which strictly follow HMM assumptions.", "startOffset": 45, "endOffset": 48}, {"referenceID": 11, "context": "Along this line, [12], [14] have studied how DNNs cope with violation of HMM assumptions.", "startOffset": 17, "endOffset": 21}, {"referenceID": 13, "context": "Along this line, [12], [14] have studied how DNNs cope with violation of HMM assumptions.", "startOffset": 23, "endOffset": 27}, {"referenceID": 14, "context": "For instance, the segmental models for stochastic modelling of speech [15] are employed to model a long duration of a speech segment as a unit instead of the frame-wise modeling procedure.", "startOffset": 70, "endOffset": 74}, {"referenceID": 15, "context": "More recently, end-to-end ASR systems like attention-based mechanisms using long short term memory implementation of the recurrent neural networks (LSTM-RNNs) [16], [17], [18] are notable efforts in this direction.", "startOffset": 159, "endOffset": 163}, {"referenceID": 16, "context": "More recently, end-to-end ASR systems like attention-based mechanisms using long short term memory implementation of the recurrent neural networks (LSTM-RNNs) [16], [17], [18] are notable efforts in this direction.", "startOffset": 165, "endOffset": 169}, {"referenceID": 17, "context": "More recently, end-to-end ASR systems like attention-based mechanisms using long short term memory implementation of the recurrent neural networks (LSTM-RNNs) [16], [17], [18] are notable efforts in this direction.", "startOffset": 171, "endOffset": 175}, {"referenceID": 18, "context": "Unlike previous mutual information estimation using GMM that requires expectation maximization (EM) to learn a joint probability distribution [19], the proposed method directly uses the DNN based acoustic models in a simple and efficient information calculation procedure.", "startOffset": 142, "endOffset": 146}, {"referenceID": 19, "context": "It was shown in [20] that DNN based posterior probabilities live in a union of low-dimensional subspaces that can be characterized using", "startOffset": 16, "endOffset": 20}, {"referenceID": 20, "context": "sparse [21] and low-rank representations [22], [23], [24].", "startOffset": 7, "endOffset": 11}, {"referenceID": 21, "context": "sparse [21] and low-rank representations [22], [23], [24].", "startOffset": 41, "endOffset": 45}, {"referenceID": 22, "context": "sparse [21] and low-rank representations [22], [23], [24].", "startOffset": 47, "endOffset": 51}, {"referenceID": 23, "context": "sparse [21] and low-rank representations [22], [23], [24].", "startOffset": 53, "endOffset": 57}, {"referenceID": 24, "context": "In other words, a one-to-one relationship holds between the hidden states and the senone observation [25].", "startOffset": 101, "endOffset": 105}, {"referenceID": 25, "context": "This concept is defined through the notion of entropy which measures the quantity of information held in a random variable [26].", "startOffset": 123, "endOffset": 127}, {"referenceID": 26, "context": "We rely on I(Zt;Qt) as the measure of the information transmitted by the acoustic model in the ASR communication channel [27].", "startOffset": 121, "endOffset": 125}, {"referenceID": 25, "context": "Due to the data-processing inequality [26], I(Zt;Qt) \u2264 I(Xt;Qt) with the equality being achieved when Zt is the sufficient statistic of features Xt.", "startOffset": 38, "endOffset": 42}, {"referenceID": 27, "context": "Experiments are conducted on the challenging AMI corpus [28], consisting of conversational speech (in smart meeting rooms) in accented English.", "startOffset": 56, "endOffset": 60}, {"referenceID": 21, "context": "Furthermore, we investigate the effect of sparse and low-rank enhancements, as proposed in [22], on DNN acoustic models in Section V-E.", "startOffset": 91, "endOffset": 95}, {"referenceID": 28, "context": "Kaldi toolkit [29] is used for training of GMM and DNN-HMM systems.", "startOffset": 14, "endOffset": 18}, {"referenceID": 21, "context": "2: (a) Supervised enhancement of DNN based posterior features is illustrated using low-rank and sparsity based reconstruction as proposed in [22].", "startOffset": 141, "endOffset": 145}, {"referenceID": 11, "context": "We compare DNN architectures in a manner similar to the study in [12] where number of hidden layers are increased with or without keeping the total number of network parameters equal to the baseline DNN.", "startOffset": 65, "endOffset": 69}, {"referenceID": 21, "context": "In [22], [23], we modify the forward pass outputs of the baseline DNN using (1) principal component analysis (PCA) based low-rank reconstruction and (2) overcomplete dictionary based sparse reconstruction.", "startOffset": 3, "endOffset": 7}, {"referenceID": 22, "context": "In [22], [23], we modify the forward pass outputs of the baseline DNN using (1) principal component analysis (PCA) based low-rank reconstruction and (2) overcomplete dictionary based sparse reconstruction.", "startOffset": 9, "endOffset": 13}, {"referenceID": 21, "context": "Instead, we use a simple methodology based on teacher-student DNN framework (used in [22]) to evaluate the ASR performance of our approach on test data.", "startOffset": 85, "endOffset": 89}, {"referenceID": 21, "context": "Recently, in [22], [23], we proposed to train student DNN acoustic models using enhanced soft targets obtained from supervised sparse and low-rank projection.", "startOffset": 13, "endOffset": 17}, {"referenceID": 22, "context": "Recently, in [22], [23], we proposed to train student DNN acoustic models using enhanced soft targets obtained from supervised sparse and low-rank projection.", "startOffset": 19, "endOffset": 23}, {"referenceID": 20, "context": "Theoretical analysis provided in this work supports the importance of sparse and low-rank enhancements in improving DNN acoustic models which was confirmed in our previous works [21], [22], [23], [24] experimentally.", "startOffset": 178, "endOffset": 182}, {"referenceID": 21, "context": "Theoretical analysis provided in this work supports the importance of sparse and low-rank enhancements in improving DNN acoustic models which was confirmed in our previous works [21], [22], [23], [24] experimentally.", "startOffset": 184, "endOffset": 188}, {"referenceID": 22, "context": "Theoretical analysis provided in this work supports the importance of sparse and low-rank enhancements in improving DNN acoustic models which was confirmed in our previous works [21], [22], [23], [24] experimentally.", "startOffset": 190, "endOffset": 194}, {"referenceID": 23, "context": "Theoretical analysis provided in this work supports the importance of sparse and low-rank enhancements in improving DNN acoustic models which was confirmed in our previous works [21], [22], [23], [24] experimentally.", "startOffset": 196, "endOffset": 200}, {"referenceID": 20, "context": "However, as shown in [21], [22], senone subspaces are correlated with each other and they have ranks higher than unity for real data.", "startOffset": 21, "endOffset": 25}, {"referenceID": 21, "context": "However, as shown in [21], [22], senone subspaces are correlated with each other and they have ranks higher than unity for real data.", "startOffset": 27, "endOffset": 31}, {"referenceID": 29, "context": "Building on the theories elaborated in Section III and discussion above, the KL-HMM approach in the prior work [30], [25] can be seen as associating a distribution P (Zt|Qt) to each state.", "startOffset": 111, "endOffset": 115}, {"referenceID": 24, "context": "Building on the theories elaborated in Section III and discussion above, the KL-HMM approach in the prior work [30], [25] can be seen as associating a distribution P (Zt|Qt) to each state.", "startOffset": 117, "endOffset": 121}], "year": 2017, "abstractText": "We propose an information theoretic framework for quantitative assessment of acoustic modeling for hidden Markov model (HMM) based automatic speech recognition (ASR). Acoustic modeling yields the probabilities of HMM sub-word states for a short temporal window of speech acoustic features. We cast ASR as a communication channel where the input sub-word probabilities convey the information about the output HMM state sequence. The quality of the acoustic model is thus quantified in terms of the information transmitted through this channel. The process of inferring the most likely HMM state sequence from the sub-word probabilities is known as decoding. HMM based decoding assumes that an acoustic model yields accurate state-level probabilities and the data distribution given the underlying hidden state is independent of any other state in the sequence. We quantify 1) the acoustic model accuracy and 2) its robustness to mismatch between data and the HMM conditional independence assumption in terms of some mutual information quantities. In this context, exploiting deep neural network (DNN) posterior probabilities leads to a simple and straightforward analysis framework to assess shortcomings of the acoustic model for HMM based decoding. This analysis enables us to evaluate the Gaussian mixture acoustic model (GMM) and the importance of many hidden layers in DNNs without any need of explicit speech recognition. In addition, it sheds light on the contribution of low-dimensional models to enhance acoustic modeling for better compliance with the HMM based decoding requirements.", "creator": "LaTeX with hyperref package"}}}