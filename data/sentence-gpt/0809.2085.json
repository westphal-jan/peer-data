{"id": "0809.2085", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2008", "title": "Clustered Multi-Task Learning: A Convex Formulation", "abstract": "In multi-task learning several related tasks are considered simultaneously, with the hope that by an appropriate sharing of information across tasks, each task may benefit from the others. In the context of learning linear functions for supervised classification or regression, this can be achieved by including a priori information about the weight vectors associated with the tasks, and how they are expected to be related to each other. In this paper, we assume that tasks are clustered into groups, which are unknown beforehand, and that tasks within a group have similar weight vectors.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Thu, 11 Sep 2008 19:01:39 GMT  (19kb)", "http://arxiv.org/abs/0809.2085v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["laurent jacob", "francis r bach", "jean-philippe vert"], "accepted": true, "id": "0809.2085"}, "pdf": {"name": "0809.2085.pdf", "metadata": {"source": "CRF", "title": "Clustered Multi-Task Learning: a Convex Formulation", "authors": ["Laurent Jacob"], "emails": ["laurent.jacob@mines-paristech.fr", "francis.bach@mines.org", "jean-philippe.vert@mines-paristech.fr"], "sections": [{"heading": null, "text": "ar X\niv :0\n80 9.\n\u2217To whom correspondance should be addressed: 35, rue Saint Honore\u0301, F-77300 Fontainebleau, France."}, {"heading": "1 Introduction", "text": "Regularization has emerged as a dominant theme in machine learning and statistics, providing an intuitive and principled tool for learning from high-dimensional data. In particular, regularization by squared Euclidean norms or squared Hilbert norms has been thoroughly studied in various settings, leading to efficient practical algorithms based on linear algebra, and to very good theoretical understanding (see, e.g., [1, 2]). In recent years, regularization by non Hilbert norms, such as \u2113p norms with p 6= 2, has also generated considerable interest for the inference of linear functions in supervised classification or regression. Indeed, such norms can sometimes both make the problem statistically and numerically better-behaved, and impose various a priori knowledge on the problem. For example, the \u21131-norm (the sum of absolute values) imposes some of the components to be equal to zero and is widely used to estimate sparse functions [3], while various combinations of \u2113p norms can be defined to impose various sparsity patterns.\nWhile most recent work has focused on studying the properties of simple wellknown norms, we take the opposite approach in this paper. That is, assuming a given prior knowledge, how can we design a norm that will enforce it?\nMore precisely, we consider the problem of multi-task learning, which has recently emerged as a very promising research direction for various applications [4]. In multitask learning several related inference tasks are considered simultaneously, with the hope that by an appropriate sharing of information across tasks, each one may benefit from the others. When linear functions are estimated, each task is associated with a weight vector, and a common strategy to design multi-task learning algorithm is to translate some prior hypothesis about how the tasks are related to each other into constraints on the different weight vectors. For example, such constraints are typically that the weight vectors of the different tasks belong (a) to a Euclidean ball centered at the origin [5], which implies no sharing of information between tasks apart from the size of the different vectors, i.e., the amount of regularization, (b) to a ball of unknown center [5], which enforces a similarity between the different weight vectors, or (c) to an unknown low-dimensional subspace [6, 7].\nIn this paper, we consider a different prior hypothesis that we believe could be more relevant in some applications: the hypothesis that the different tasks are in fact clustered into different groups, and that the weight vectors of tasks within a group are similar to each other. A key difference with [5], where a similar hypothesis is studied, is that we don\u2019t assume that the groups are known a priori, and in a sense our goal is both to identify the clusters and to use them for multi-task learning. An important situation that motivates this hypothesis is the case where most of the tasks are indeed related to each other, but a few \u201coutlier\u201d tasks are very different, in which case it may be better to impose similarity or low-dimensional constraints only to a subset of the tasks (thus forming a cluster) rather than to all tasks. Another situation of interest is when one can expect a natural organization of the tasks into\nclusters, such as when one wants to model the preferences of customers and believes that there are a few general types of customers with similar preferences within each type, although one does not know beforehand which customers belong to which types. Besides an improved performance if the hypothesis turns out to be correct, we also expect this approach to be able to identify the cluster structure among the tasks as a by-product of the inference step, e.g., to identify outliers or groups of customers, which can be of interest for further understanding of the structure of the problem.\nIn order to translate this hypothesis into a working algorithm, we follow the general strategy mentioned above which is to design a norm or a penalty over the set of weights which can be used as regularization in classical inference algorithms. We construct such a penalty by first assuming that the partition of the tasks into clusters is known, similarly to [5]. We then attempt to optimize the objective function of the inference algorithm over the set of partitions, a strategy that has proved useful in other contexts such as multiple kernel learning [8]. This optimization problem over the set of partitions being computationally challenging, we propose a convex relaxation of the problem which results in an efficient algorithm."}, {"heading": "2 Multi-task learning with clustered tasks", "text": "We consider m related inference tasks that attempt to learn linear functions over X = Rd from a training set of input/output pairs (xi, yi)i=1,...,n, where xi \u2208 X and yi \u2208 Y . In the case of binary classification we usually take Y = {\u22121,+1}, while in the case of regression we take Y = R. Each training example (xi, yi) is associated to a particular task t \u2208 [1, m], and we denote by I(t) \u2282 [1, n] the set of indices of training examples associated to the task t. Our goal is to infer m linear functions ft(x) = w \u22a4 t x, for t = 1, . . . , m, associated to the different tasks. We denote by W = (w1 . . . wm) the d \u00d7 m matrix whose columns are the successive vectors we want to estimate.\nWe fix a loss function l : R \u00d7 Y 7\u2192 R that quantifies by l(f(x), y) the cost of predicting f(x) for the input x when the correct output is y. Typical loss functions include the square error in regression l(u, y) = 1\n2 (u\u2212 y)2 or the hinge loss in binary\nclassification l(u, y) = max(0, 1\u2212 uy) with y \u2208 {\u22121, 1}. The empirical risk of a set of linear classifiers given in the matrix W is then defined as the average loss over the training set:\n\u2113(W ) = 1\nn\nm\u2211\nt=1\n\u2211\ni\u2208I(t) l(w\u22a4t xi, yi) . (1)\nIn the sequel, we will often use the m\u00d71 vector 1 composed of ones, the m\u00d7m projection matrices U = 11\u22a4/m whose entries are all equal to 1/m, as well as the projection matrix \u03a0=I \u2212 U .\nIn order to learn simultaneously the m tasks, we follow the now well-established approach which looks for a set of weight vectors W that minimizes the empirical risk regularized by a penalty functional, i.e., we consider the problem:\nmin W\u2208Rd\u00d7m \u2113(W ) + \u03bb\u2126(W ) , (2)\nwhere \u2126(W ) can be designed from prior knowledge to constrain some sharing of information between tasks. For example, [5] suggests to penalize both the norms of the wi\u2019s and their variance, i.e., to consider a function of the form:\n\u2126variance(W ) = \u2016w\u0304\u20162 + \u03b2\nm\nm\u2211\ni=1\n\u2016wi \u2212 w\u0304\u20162 , (3)\nwhere w\u0304 = ( \u2211n\ni=1wi) /m is the mean weight vector. This penalty enforces a clustering of the w\u2032is towards their mean when \u03b2 increases. Alternatively, [7] propose to penalize the trace norm of W :\n\u2126trace(W ) =\nmin(d,m)\u2211\ni=1\n\u03c3i(W ) , (4)\nwhere \u03c31(W ), . . . , \u03c3min(d,m)(W ) are the successive singular values of W . This enforces a low-rank solution in W , i.e., constrains the different wi\u2019s to live in a lowdimensional subspace.\nHere we would like to define a penalty function \u2126(W ) that encodes as prior knowledge that tasks are clustered into r < m groups. To do so, let us first assume that we know beforehand the clusters, i.e., we have a partition of the set of tasks into r groups. In that case we can follow an approach proposed by [5] which for clarity we rephrase with our notations and slightly generalize now. For a given cluster c \u2208 [1, r], let us denote J (c) \u2282 [1, m] the set of tasks in c, mc = |J (c)| the number of tasks in the cluster c, and E the m\u00d7r binary matrix which describes the cluster assignment for the m tasks, i.e., Eij = 1 if task i is in cluster j, 0 otherwise. Let us further denote by w\u0304c = ( \u2211 i\u2208J (c)wi)/mc the average weight vector for the\ntasks in c, and recall that w\u0304 = ( \u2211m\ni=1 wi) /m denotes the average weight vector over all tasks. Finally it will be convenient to introduce the matrix M = E(E\u22a4E)\u22121E\u22a4. M can also be written L \u2212 I, where L is the normalized Laplacian of the graph G whose nodes are the tasks connected by an edge if and only if they are in the same cluster. Then we can define three semi-norms of interest on W that quantify different orthogonal aspects:\n\u2022 A global penalty, which measures on average how large the weight vectors are:\n\u2126mean(W ) = n\u2016w\u0304\u20162 = trWUW\u22a4 .\n\u2022 A measure of between-cluster variance, which quantifies how close to each other the different clusters are:\n\u2126between(W ) =\nr\u2211\nc=1\nmc\u2016w\u0304c \u2212 w\u0304\u20162 = trW (M \u2212 U)W\u22a4.\n\u2022 A measure of within-cluster variance, which quantifies the compactness of the different clusters:\n\u2126within(W ) =\nr\u2211\nc=1\n   \u2211\ni\u2208J (c) \u2016wi \u2212 w\u0304c\u20162\n   = trW (I \u2212M)W \u22a4 .\nWe note that both \u2126between(W ) and \u2126within(W ) depend on the particular choice of clusters E, or equivalently of M . We now propose to consider the following general penalty function:\n\u2126(W ) = \u03b5M\u2126mean(W ) + \u03b5B\u2126between(W ) + \u03b5W\u2126within(W ) , (5)\nwhere \u03b5M , \u03b5B and \u03b5W are three non-negative parameters that can balance the importance of the different components of the penalty. Plugging this quadratic penalty into (2) leads to the general optimization problem:\nmin W\u2208Rd\u00d7m\n\u2113(W ) + \u03bbtrW\u03a3(M)\u22121W\u22a4 , (6)\nwhere \u03a3(M)\u22121 = \u03b5MU + \u03b5B(M \u2212 U) + \u03b5W (I \u2212M) . (7)\nHere we use the notation \u03a3(M) to insist on the fact that this quadratic penalty depends on the cluster structure through the matrixM . Observing that the matrices U , M \u2212 U and I \u2212 M are orthogonal projections onto orthogonal supplementary subspaces, we easily get from (7):\n\u03a3(M) = \u03b5\u22121M U+\u03b5 \u22121 B (M\u2212U)+\u03b5\u22121W (I\u2212M) = \u03b5\u22121W I+(\u03b5\u22121M \u2212\u03b5\u22121B )U+(\u03b5\u22121B \u2212\u03b5\u22121W )M . (8)\nBy choosing particular values for \u03b5M , \u03b5B and \u03b5W we can recover several situations, In particular:\n\u2022 For \u03b5W = \u03b5B = \u03b5M = \u03b5, we simply recover the Frobenius norm of W , which does not put any constraint on the relationship between the different tasks:\n\u2126(W ) = \u03b5trWW\u22a4 = \u03b5\nm\u2211\ni=1\n\u2016wi\u20162 .\n\u2022 For \u03b5W = \u03b5B > \u03b5M , we recover the penalty of [5] without clusters:\n\u2126(W ) = trW (\u03b5MU + \u03b5B(I \u2212 U))W\u22a4 = \u03b5Mn\u2016w\u0304\u20162 + \u03b5B m\u2211\ni=1\n\u2016wi \u2212 w\u0304\u20162 .\nIn that case, a global similarity between tasks is enforced, in addition to the general constraint on their mean. The structure in clusters plays no role since the sum of the between- and within-cluster variance is independent of the particular choice of clusters.\n\u2022 For \u03b5W > \u03b5B = \u03b5M we recover the penalty of [5] with clusters:\n\u2126(W ) = trW (\u03b5MM + \u03b5W (I \u2212M))W\u22a4\n= \u03b5M\nr\u2211\nc=1\n  mc\u2016w\u0304c\u2016 2 + \u03b5W \u03b5M \u2211 i\u2208J (c) \u2016wi \u2212 w\u0304c\u20162    . (9)\nIn order to enforce a cluster hypothesis on the tasks, we therefore see that a natural choice is to take \u03b5W > \u03b5B > \u03b5M in (5). This would have the effect of penalizing more the within-cluster variance than the between-cluster variance, hence promoting compact clusters. Of course, a major limitation at this point is that we assumed the cluster structure known a priori (through the matrix E, or equivalently M). In many cases of interest, we would like instead to learn the cluster structure itself from the data. We propose to learn the cluster structure in our framework by optimizing our objective function (6) both in W and M , i.e., to consider the problem:\nmin W\u2208Rd\u00d7m,M\u2208Mr\n\u2113(W ) + \u03bbtrW\u03a3(M)\u22121W\u22a4 , (10)\nwhere Mr denotes the set of matrices M = E(E\u22a4E)\u22121E\u22a4 defined by a clustering of the m tasks into r clusters and \u03a3(M) is defined in (8). Denoting by Sr = {\u03a3(M) : M \u2208 Mr} the corresponding set of positive semidefinite matrices, we can equivalently rewrite the problem as:\nmin W\u2208Rd\u00d7m,\u03a3\u2208Sr\n\u2113(W ) + \u03bbtrW\u03a3\u22121W\u22a4 . (11)\nThe objective function in (11) is jointly convex in W \u2208 Rd\u00d7m and \u03a3 \u2208 Sm+ , the set of m \u00d7m positive semidefinite matrices, however the (finite) set Sr is not convex, making this problem intractable. We are now going to propose a convex relaxation of (11) by optimizing over a convex set of positive semidefinite matrices that contains Sr."}, {"heading": "3 Convex relaxation", "text": "In order to formulate a convex relaxation of (11), let us first observe that in the penalty term (5) the cluster structure only contributes to the second and third terms \u2126between(W ) and \u2126within(W ), and that these penalties only depend on the centered version of W . In terms of matrices, only the last two terms of \u03a3(M)\u22121 in (7) depend on M , i.e., on the clustering, and these terms can be re-written as:\n\u03b5B(M \u2212 U) + \u03b5W (I \u2212M) = \u03a0(\u03b5BM + \u03b5W (I \u2212M))\u03a0. (12)\nIndeed, it is easy to check that M \u2212 U = M\u03a0 = \u03a0M\u03a0, and that I \u2212 M = I \u2212 U \u2212 (M \u2212 U) = \u03a0 \u2212 \u03a0M\u03a0 = \u03a0(I \u2212 M)\u03a0. Intuitively, multiplying by \u03a0 on the right (resp. on the left) centers the rows (resp. the columns) of a matrix, and both M \u2212 U and I \u2212M are row- and column-centered.\nTo simplify notations, let us introduce M\u0303 = \u03a0M\u03a0. Plugging (12) in (7) and (10), we get the penalty\ntrW\u03a3(M)\u22121W\u22a4 = \u03b5M ( trW\u22a4WU ) + (W\u03a0)(\u03b5BM\u0303 + \u03b5W (I \u2212 M\u0303))(W\u03a0)\u22a4, (13)\nin which, again, only the second part needs to be optimized with respect to the clustering M . Denoting \u03a3\u22121c (M) = \u03b5BM\u0303 + \u03b5W (I \u2212 M\u0303), one can express \u03a3c(M), using the fact that M\u0303 is a projection:\n\u03a3c(M) = ( \u03b5\u22121B \u2212 \u03b5\u22121W ) M\u0303 + \u03b5\u22121W I. (14)\n\u03a3c is characterized by M\u0303 = \u03a0M\u03a0, that is discrete by construction, hence the nonconvexity of Sr. We have the natural constraints M \u2265 0 (i.e., M\u0303 \u2265 \u2212U), 0 M I (i.e., 0 M\u0303 \u03a0 and trM = r (i.e., trM\u0303 = r \u2212 1). A possible convex relaxation of the discrete set of matrices M\u0303 is therefore {M\u0303 : 0 M\u0303 I, trM\u0303 = r \u2212 1}. This gives an equivalent convex set Sc for \u03a3c, namely:\nSc = { \u03a3c \u2208 Sm+ : \u03b1I \u03a3 \u03b2I, tr\u03a3 = \u03b3 } , (15)\nwith \u03b1 = \u03b5\u22121W , \u03b2 = \u03b5 \u22121 B and \u03b3 = (m \u2212 r + 1)\u03b5\u22121W + (r \u2212 1)\u03b5\u22121B . Incorporating the first part of the penalty (13) into the empirical risk term by defining \u2113c(W ) = \u03bb\u2113(W ) + \u03b5M ( trW\u22a4WU ) , we are now ready to state our relaxation of (11):\nmin W\u2208Rd\u00d7m,\u03a3c\u2208Sc\n\u2113c(W ) + \u03bbtr\u03a0W\u03a3 \u22121 c W \u22a4\u03a0 . (16)"}, {"heading": "3.1 Reinterpretation in terms of norms", "text": "We denote \u2016W\u20162c = min\u03a3c\u2208Sc trW\u03a3\u22121c W T the cluster norm (CN). For any convex set Sc, we obtain a norm on W (that we apply here to its centered version). By\nputting some different constraints on the set Sc, we obtain different norms on W , and in fact all previous multi-task formulations may be cast in this way, i.e., by choosing a specific set of positive matrices Sc (e.g., trace constraint for the trace norm, and simply a singleton for the Frobenius norm). Thus, designing norms for multi-task learning is equivalent to designing a set of positive matrices. In this paper, we have investigated a specific set adapted for clustered-tasks, but other sets could be designed in other situations.\nNote that we have selected a simple spectral convex set Sc in order to make the optimization simpler in Section 3.3, but we could also add some additional constraints that encode the point-wise positivity of the matrix M . Finally, when r = 1 (one clusters) and r = m (one cluster per task), we get back the formulation of [5]."}, {"heading": "3.2 Reinterpretation as a convex relaxation of K-means", "text": "In this section we show that the semi-norm \u2016\u03a0W\u20162c that we have designed earlier, can be interpreted as a convex relaxation of K-means on the tasks [9]. Indeed, given W \u2208 Rd\u00d7m, K-means aims to decompose it in the form W = \u00b5E\u22a4 where \u00b5 \u2208 Rd\u00d7r are cluster centers and E represents a partition. Given the partition E, the matrix \u00b5 is found by minimizing min\u00b5 \u2016W\u22a4 \u2212 E\u00b5\u22a4\u20162F . Thus, a natural strategy outlined by [9], is to alternate between optimizing \u00b5, the partition E and the weight vectors W . We now show that our convex norm is obtained when minimizing in closed form with respect to \u00b5 and relaxing.\nBy translation invariance, this is equivalent to minimizing min\u00b5 \u2016\u03a0W\u22a4\u2212\u03a0E\u00b5\u22a4\u20162F . If we add a penalization on \u00b5 of the form \u03bbtrE\u22a4E\u00b5\u00b5\u22a4, then a short calculation shows that the minimum with respect to \u00b5 (i.e., after optimization of the cluster centers) is equal to\ntr\u03a0W\u22a4W\u03a0(\u03a0E(E\u22a4E)\u22121E\u22a4\u03a0/\u03bb+ I)\u22121 = tr\u03a0W\u22a4W\u03a0(\u03a0M\u03a0/\u03bb+ I)\u22121.\nBy comparing with Eq. (14), we see that our formulation is indeed a convex relaxation of K-means."}, {"heading": "3.3 Primal optimization", "text": "Let us now show in more details how (16) can be solved efficiently. Whereas a dual formulation could be easily derived following [8], a direct approach is to rewrite (16) as\nmin W\u2208Rd\u00d7m\n( \u2113c(W ) + min\n\u03a3c\u2208Sc tr\u03a0W\u03a3\u22121c W T\u03a0\n) (17)\nwhich, if \u2113c is differentiable, can be directly optimized by gradient-based methods on W since \u2016\u03a0W\u20162c = min\u03a3c\u2208Sc tr\u03a0W\u03a3\u22121c W T\u03a0 is a quadratic semi-norm of W . This\nregularization term tr\u03a0W\u03a3\u22121c W \u22a4\u03a0 and its gradient can be computed efficiently using a semi-closed form. Indeed, since \u03a3c as defined in (15) is a spectral set (i.e., it does depend only on eigenvalues of covariance matrices), we obtain a function of the singular values of \u03a0W (or equivalently the eigenvalues of W\u22a4\u03a0W ):\nmin \u03a3c\u2208Sc\ntr\u03a0W\u03a3\u22121c W \u22a4\u03a0 = min \u03bb\u2208Rm, \u03b1\u2264\u03bbi\u2264\u03b2, \u03bb1=\u03b3, U\u2208Om trWU diag(\u03bb)\u22121U\u22a4W\u22a4,\nwhere Om is the set of orthogonal matrices in Rm\u00d7m. The optimal U is the matrix of the eigenvectors of W\u22a4\u03a0W , and we obtain the value of the objective function at the optimum:\nmin \u03a3\u2208S tr\u03a0W\u03a3\u22121W\u22a4\u03a0 = min \u03bb\u2208Rm, \u03b1\u2264\u03bbi\u2264\u03b2, \u03bb1=\u03b3\nm\u2211\ni=1\n\u03c32i \u03bbi ,\nwhere \u03c3 and \u03bb are the vectors containing the singular values of \u03a0W and \u03a3 respectively. Now, we simply need to be able to compute this function of the singular values.\nThe only coupling in this formulation comes from the trace constraint. The Lagrangian corresponding to this constraint is:\nL(\u03bb, \u03bd) = m\u2211\ni=1\n\u03c32i \u03bbi + \u03bd\n( m\u2211\ni=1\n\u03bbi \u2212 \u03b3 ) . (18)\nFor \u03bd \u2264 0, this is a decreasing function of \u03bbi, so the minimum on \u03bbi \u2208 [\u03b1, \u03b2] is reached for \u03bbi = \u03b2. The dual function is then a linear non-decreasing function of \u03bd (since \u03b1 \u2264 \u03b3/m \u2264 \u03b2 from the definition of \u03b1, \u03b2, \u03b3 in (15), which reaches it maximum value (on \u03bd \u2264 0) at \u03bd = 0. Let us therefore now consider the dual for \u03bd \u2265 0. (18) is then a convex function of \u03bbi. Canceling its derivative with respect to \u03bbi gives that the minimum in \u03bb \u2208 R is reached for \u03bbi = \u03c3i/ \u221a \u03bd. Now this may not be in\nthe constraint set (\u03b1, \u03b2), so if \u03c3i < \u03b1 \u221a \u03bd then the minimum in \u03bbi \u2208 [\u03b1, \u03b2] of (18)\nis reached for \u03bbi = \u03b1, and if \u03c3i > \u03b2 \u221a \u03bd it is reached for \u03bbi = \u03b2. Otherwise, it is\nreached for \u03bbi = \u03c3i/ \u221a \u03bd. Reporting this in (18), the dual problem is therefore\nmax \u03bd\u22650\n\u2211\ni,\u03b1 \u221a \u03bd\u2264\u03c3i\u2264\u03b2 \u221a \u03bd\n2\u03c3i \u221a \u03bd +\n\u2211\ni,\u03c3i<\u03b1 \u221a \u03bd\n( \u03c32i \u03b1 + \u03bd\u03b1 ) + \u2211\ni,\u03b2 \u221a \u03bd<\u03c3i\n( \u03c32i \u03b2 + \u03bd\u03b2 ) \u2212 \u03bd\u03b3 . (19)\nSince a closed form for this expression is known for each fixed value of \u03bd, one can obtain \u2016\u03a0W\u20162c (and the eigenvalues of \u03a3\u2217) by Algorithm 1. The cancellation condition in Algorithm 1 is that the value canceling the derivative belongs to (a, b), i.e.,\n\u03bd =\n(\u2211 i,\u03b1 \u221a \u03bd\u2264\u03c3i\u2264\u03b2 \u221a \u03bd \u03c3i\n\u03b3 \u2212 (\u03b1n\u2212 + \u03b2n+)\n)2 \u2208 (a, b) ,\nAlgorithm 1 Computing \u2016A\u20162c Require: A, \u03b1, \u03b2, \u03b3. Ensure: \u2016A\u20162c , \u03bb\u2217. Compute the singular values \u03c3i of A.\nOrder the \u03c32 i \u03b12 , \u03c32 i \u03b22 in a vector I (with an additional 0 at the beginning). for all interval (a, b) of I do\nif \u2202L(\u03bb\u2217,\u03bd)\n\u2202\u03bd is canceled on \u03bd \u2208 (a, b) then\nReplace \u03bd\u2217 in the dual function L(\u03bb\u2217, \u03bd) to get \u2016A\u20162c , compute \u03bb\u2217 on (a, b). return \u2016A\u20162c , \u03bb\u2217.\nend if\nend for\nwhere n\u2212 and n+ are the number of \u03c3i < \u03b1 \u221a \u03bd and \u03c3i > \u03b2 \u221a \u03bd respectively. In order to perform the gradient descent, we also need to compute \u2202\u2016\u03a0W\u2016 2 c\n\u2202W . This can\nbe computed directly using \u03bb\u2217, by:\n\u2200i, \u2202\u2016\u03a0W\u2016 2 c\n\u2202\u03c3i = 2\u03c3i \u03bb\u2217i and \u2202\u2016\u03a0W\u20162c \u2202W = \u2202\u2016\u03a0W\u20162c \u2202\u03a0W \u03a0."}, {"heading": "4 Experiments", "text": ""}, {"heading": "4.1 Artificial data", "text": "We generated synthetic data consisting of two clusters of two tasks. The tasks are vectors of Rd, d = 30. For each cluster, a center w\u0304c was generated in R\nd\u22122, so that the two clusters be orthogonal. More precisely, each w\u0304c had (d\u2212 2)/2 random features randomly drawn from N (0, \u03c32r), \u03c32r = 900, and (d \u2212 2)/2 zero features. Then, each tasks t was computed as wt + w\u0304c(t), where c(t) was the cluster of t. wt had the same zero feature as its cluster center, and the other features were drawn from N (0, \u03c32c ), \u03c32c = 16. The last two features were non-zero for all the tasks and drawn from N (0, \u03c32c ). For each task, 2000 points were generated and a normal noise of variance \u03c32n = 150 was added.\nIn a first experiment, we compared our cluster norm \u2016.\u20162c with the single-task learning given by the Frobenius norm, and with the trace norm, that corresponds to the assumption that the tasks live in a low-dimension space. The multi-task kernel approach being a special case of CN, its performance will always be between the performance of the single task and the performance of CN.\nIn a second setting, we compare CN to alternative methods that differ in the way they learn \u03a3:\n\u2022 The True metric approach, that simply plugs the actual clustering in E and\noptimizes W using this fixed metric. This necessitates to know the true clustering a priori, and can be thought of like a golden standard.\n\u2022 The k-means approach, that alternates between optimizing the tasks in W given the metric \u03a3 and re-learning \u03a3 by clustering the tasks wi [9]. The clustering is done by a k-means run 3 times. This is a non convex approach, and different initialization of k-means may result in different local minima.\nWe also tried one run of CN followed by a run of True metric using the learned \u03a3 reprojected in Sr by rounding,i.e., by performing k-means on the eigenvectors of the learned \u03a3 (Reprojected approach), and a run of k-means starting from the relaxed solution (CNinit approach).\nOnly the first method requires to know the true clustering a priori, all the other methods can be run without any knowledge of the clustering structure of the tasks.\nEach method was run with different numbers of training points. The training points were equally separated between the two clusters and for each cluster, 5/6th of the points were used for the first task and 1/6th for the second, in order to simulate a natural setting were some tasks have fewer data. We used the 2000 points of each task to build 3 training folds, and the remaining points were used for testing. We used the mean RMSE across the tasks as a criterion, and a quadratic loss for \u2113(W ).\nThe results of the first experiment are shown on Figure 1 (left). As expected, both multi-task approaches perform better than the approach that learns each task independently. CN penalization on the other hand always gives better testing error than the trace norm penalization, with a stronger advantage when very few training points are available. When more training points become available, all the methods give more and more similar performances. In particular, with large samples, it is not useful anymore to use a multi-task approach.\nFigure 1 (right) shows the results of the second experiment. Using the true metric always gives the best results. For 28 training points, no method recovers the correct clustering structure, as displayed on Figure 2, although CN performs slightly better than the k-means approach since the metric it learns is more diffuse. For 50 training points, CN performs much better than the k-means approach, which completely fails to recover the clustering structure as illustrated by the \u03a3 learned for 28 and 50 training points on Figure 2. In the latter setting, CN partially recovers the clusters. When more training points become available, the k-means approach perfectly recovers the clustering structure and outperforms the relaxed approach. The reprojected approach, on the other hand, performs always as well as the best of the two other methods. The CNinit approach results are not displayed since the are the same as for the reprojected method."}, {"heading": "4.2 MHC-I binding data", "text": "We also applied our method to the iedb MHC-I peptide binding benchmark proposed in [10]. This database contains binding affinities of various peptides, i.e., short amino-acid sequences, with different MHC-I molecules. This binding process is central in the immune system, and predicting it is crucial, for example to design vaccines. The affinities are thresholded to give a prediction problem. Each MHC-I molecule is considered as a task, and the goal is to predict whether a peptide binds a molecule. We used an orthogonal coding of the amino acids to represent the peptides and balanced the data by keeping only one negative example for each positive point, resulting in 15236 points involving 35 different molecules. We chose a logistic loss for \u2113(W ).\nMulti-task learning approaches have already proved useful for this problem, see for example [11, 12]. Besides, it is well known in the vaccine design community that some molecules can be grouped into empirically defined supertypes known to have similar binding behaviors.\n[12] showed in particular that the multi-task approaches were very useful for molecules with few known binders. Following this observation, we consider the mean error on the 10 molecules with less than 200 known ligands, and report the results in Table 1. We did not select the parameters by internal cross validation, but chose them among a small set of values in order to avoid overfitting. More accurate results could arise from such a cross validation, in particular concerning the number of clusters (here we limited the choice to 2 or 10 clusters).\nThe pooling approach simply considers one global prediction problem by pooling together the data available for all molecules. The results illustrate that it is better to consider individual models than one unique pooled model, even when few data\npoints are available. On the other hand, all the multitask approaches improve the accuracy, the cluster norm giving the best performance. The learned \u03a3, however, did not recover the known supertypes, although it may contain some relevant information on the binding behavior of the molecules. Finally, the reprojection methods (reprojected and CNinit) did not improve the performance, potentially because the learned structure was not strong enough."}, {"heading": "5 Conclusion", "text": "We have presented a convex approach to clustered multi-task learning, based on the design of a dedicated norm. Promising results were presented on synthetic examples and on the iedb dataset. We are currently investigating more refined convex relaxations and the natural extension to non-linear multi-task learning as well as the inclusion of specific features on the tasks, which has shown to improve performance in other settings [6]."}], "references": [{"title": "Spline Models for Observational Data, volume 59 of CBMS-NSF Regional Conference Series in Applied Mathematics", "author": ["G. Wahba"], "venue": "SIAM, Philadelphia,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1990}, {"title": "Regularization Theory and Neural Networks Architectures", "author": ["F. Girosi", "M. Jones", "T. Poggio"], "venue": "Neural Comput.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}, {"title": "Regression shrinkage and selection via the lasso", "author": ["R. Tibshirani"], "venue": "J. Royal. Statist. Soc. B.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1996}, {"title": "Task clustering and gating for bayesian multitask learning", "author": ["B. Bakker", "T. Heskes"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "Learning multiple tasks with kernel methods", "author": ["T. Evgeniou", "C. Micchelli", "M. Pontil"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Low-rank matrix factorization with attributes", "author": ["J. Abernethy", "F. Bach", "T. Evgeniou", "J.-P. Vert"], "venue": "Technical Report cs/0611124,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Multi-task feature learning", "author": ["A. Argyriou", "T. Evgeniou", "M. Pontil"], "venue": "Adv. Neural. Inform. Process Syst", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Learning the Kernel Matrix with Semidefinite Programming", "author": ["G.R.G. Lanckriet", "N. Cristianini", "P. Bartlett", "L. El Ghaoui", "M.I. Jordan"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2004}, {"title": "A framework for simultaneous coclustering and learning from complex data", "author": ["Meghana Deodhar", "Joydeep Ghosh"], "venue": "Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "A community resource benchmarking predictions of peptide binding to MHC-I molecules", "author": ["Bjoern Peters", "Huynh-Hoa Bui", "Sune Frankild", "Morten Nielson", "Claus Lundegaard", "Emrah Kostem", "Derek Basch", "Kasper Lamberth", "Mikkel Harndahl", "Ward Fleri", "Stephen S Wilson", "John Sidney", "Ole Lund", "Soren Buus", "Alessandro Sette"], "venue": "PLoS Comput Biol,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Leveraging information across HLA alleles/supertypes improves HLA-specific epitope", "author": ["David Heckerman", "Carl Kadie", "Jennifer Listgarten"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "Efficient peptide-MHC-I binding prediction for alleles with few known binders", "author": ["L. Jacob", "J.-P. Vert"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": ", [1, 2]).", "startOffset": 2, "endOffset": 8}, {"referenceID": 1, "context": ", [1, 2]).", "startOffset": 2, "endOffset": 8}, {"referenceID": 2, "context": "For example, the l-norm (the sum of absolute values) imposes some of the components to be equal to zero and is widely used to estimate sparse functions [3], while various combinations of l norms can be defined to impose various sparsity patterns.", "startOffset": 152, "endOffset": 155}, {"referenceID": 3, "context": "That is, assuming a given prior knowledge, how can we design a norm that will enforce it? More precisely, we consider the problem of multi-task learning, which has recently emerged as a very promising research direction for various applications [4].", "startOffset": 245, "endOffset": 248}, {"referenceID": 4, "context": "For example, such constraints are typically that the weight vectors of the different tasks belong (a) to a Euclidean ball centered at the origin [5], which implies no sharing of information between tasks apart from the size of the different vectors, i.", "startOffset": 145, "endOffset": 148}, {"referenceID": 4, "context": ", the amount of regularization, (b) to a ball of unknown center [5], which enforces a similarity between the different weight vectors, or (c) to an unknown low-dimensional subspace [6, 7].", "startOffset": 64, "endOffset": 67}, {"referenceID": 5, "context": ", the amount of regularization, (b) to a ball of unknown center [5], which enforces a similarity between the different weight vectors, or (c) to an unknown low-dimensional subspace [6, 7].", "startOffset": 181, "endOffset": 187}, {"referenceID": 6, "context": ", the amount of regularization, (b) to a ball of unknown center [5], which enforces a similarity between the different weight vectors, or (c) to an unknown low-dimensional subspace [6, 7].", "startOffset": 181, "endOffset": 187}, {"referenceID": 4, "context": "A key difference with [5], where a similar hypothesis is studied, is that we don\u2019t assume that the groups are known a priori, and in a sense our goal is both to identify the clusters and to use them for multi-task learning.", "startOffset": 22, "endOffset": 25}, {"referenceID": 4, "context": "We construct such a penalty by first assuming that the partition of the tasks into clusters is known, similarly to [5].", "startOffset": 115, "endOffset": 118}, {"referenceID": 7, "context": "We then attempt to optimize the objective function of the inference algorithm over the set of partitions, a strategy that has proved useful in other contexts such as multiple kernel learning [8].", "startOffset": 191, "endOffset": 194}, {"referenceID": 4, "context": "For example, [5] suggests to penalize both the norms of the wi\u2019s and their variance, i.", "startOffset": 13, "endOffset": 16}, {"referenceID": 6, "context": "Alternatively, [7] propose to penalize the trace norm of W :", "startOffset": 15, "endOffset": 18}, {"referenceID": 4, "context": "In that case we can follow an approach proposed by [5] which for clarity we rephrase with our notations and slightly generalize now.", "startOffset": 51, "endOffset": 54}, {"referenceID": 4, "context": "\u2022 For \u03b5W = \u03b5B > \u03b5M , we recover the penalty of [5] without clusters: \u03a9(W ) = trW (\u03b5MU + \u03b5B(I \u2212 U))W\u22a4 = \u03b5Mn\u2016w\u0304\u2016 + \u03b5B m \u2211", "startOffset": 47, "endOffset": 50}, {"referenceID": 4, "context": "\u2022 For \u03b5W > \u03b5B = \u03b5M we recover the penalty of [5] with clusters: \u03a9(W ) = trW (\u03b5MM + \u03b5W (I \u2212M))W\u22a4", "startOffset": 45, "endOffset": 48}, {"referenceID": 4, "context": "Finally, when r = 1 (one clusters) and r = m (one cluster per task), we get back the formulation of [5].", "startOffset": 100, "endOffset": 103}, {"referenceID": 8, "context": "2 Reinterpretation as a convex relaxation of K-means In this section we show that the semi-norm \u2016\u03a0W\u2016c that we have designed earlier, can be interpreted as a convex relaxation of K-means on the tasks [9].", "startOffset": 199, "endOffset": 202}, {"referenceID": 8, "context": "Thus, a natural strategy outlined by [9], is to alternate between optimizing \u03bc, the partition E and the weight vectors W .", "startOffset": 37, "endOffset": 40}, {"referenceID": 7, "context": "Whereas a dual formulation could be easily derived following [8], a direct approach is to rewrite (16) as min W\u2208Rd\u00d7m ( lc(W ) + min \u03a3c\u2208Sc tr\u03a0W\u03a3\u22121 c W \u03a0 ) (17)", "startOffset": 61, "endOffset": 64}, {"referenceID": 8, "context": "\u2022 The k-means approach, that alternates between optimizing the tasks in W given the metric \u03a3 and re-learning \u03a3 by clustering the tasks wi [9].", "startOffset": 138, "endOffset": 141}, {"referenceID": 9, "context": "2 MHC-I binding data We also applied our method to the iedb MHC-I peptide binding benchmark proposed in [10].", "startOffset": 104, "endOffset": 108}, {"referenceID": 10, "context": "Multi-task learning approaches have already proved useful for this problem, see for example [11, 12].", "startOffset": 92, "endOffset": 100}, {"referenceID": 11, "context": "Multi-task learning approaches have already proved useful for this problem, see for example [11, 12].", "startOffset": 92, "endOffset": 100}, {"referenceID": 11, "context": "[12] showed in particular that the multi-task approaches were very useful for molecules with few known binders.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "We are currently investigating more refined convex relaxations and the natural extension to non-linear multi-task learning as well as the inclusion of specific features on the tasks, which has shown to improve performance in other settings [6].", "startOffset": 240, "endOffset": 243}], "year": 2008, "abstractText": "In multi-task learning several related tasks are considered simultaneously, with the hope that by an appropriate sharing of information across tasks, each task may benefit from the others. In the context of learning linear functions for supervised classification or regression, this can be achieved by including a priori information about the weight vectors associated with the tasks, and how they are expected to be related to each other. In this paper, we assume that tasks are clustered into groups, which are unknown beforehand, and that tasks within a group have similar weight vectors. We design a new spectral norm that encodes this a priori assumption, without the prior knowledge of the partition of tasks into groups, resulting in a new convex optimization formulation for multi-task learning. We show in simulations on synthetic examples and on the iedb MHC-I binding dataset, that our approach outperforms well-known convex methods for multi-task learning, as well as related non convex methods dedicated to the same problem. \u2217To whom correspondance should be addressed: 35, rue Saint Honor\u00e9, F-77300 Fontainebleau, France.", "creator": "dvips(k) 5.95a Copyright 2005 Radical Eye Software"}}}