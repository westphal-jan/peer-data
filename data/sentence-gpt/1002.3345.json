{"id": "1002.3345", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Feb-2010", "title": "Interactive Submodular Set Cover", "abstract": "We introduce a natural generalization of submodular set cover and exact active learning with a finite hypothesis class (query learning). We call this new problem interactive submodular set cover. Applications include advertising in social networks with hidden information. We give an approximation guarantee for a greedy algorithm and give a hardness of approximation result which matches up to constant factors. We also discuss the adaptivity gap for the problem and present encouraging early experimental results.\n\n\n\n\n\nWe demonstrate that if you combine two different sets of neural networks (more broadly, deep networks). We propose a subset of an action-like model to allow an individual to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn how to learn", "histories": [["v1", "Wed, 17 Feb 2010 18:43:59 GMT  (116kb)", "https://arxiv.org/abs/1002.3345v1", "12 pages, 1 figure"], ["v2", "Thu, 20 May 2010 23:39:23 GMT  (133kb)", "http://arxiv.org/abs/1002.3345v2", "15 pages, 1 figure"]], "COMMENTS": "12 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["andrew guillory", "jeff a bilmes"], "accepted": true, "id": "1002.3345"}, "pdf": {"name": "1002.3345.pdf", "metadata": {"source": "CRF", "title": "Interactive Submodular Set Cover", "authors": ["Andrew Guillory", "Jeff Bilmes"], "emails": ["guillory@cs.washington.edu", "bilmes@ee.washington.edu", "guillory@cs.washington.edu", "bilmes@ee.washington.edu"], "sections": [{"heading": null, "text": ""}, {"heading": "1 Introduction", "text": "As a motivating example, we consider viral marketing in a social network. In the standard version of the problem, the goal is to send advertisements to influential members of a social network such that by sending advertisements to only a few people our message spreads to a large portion of the network. Previous work [13, 12] has shown that, for many models of influence, the influence of a set of nodes can be modelled as a submodular set function. Therefore, selecting a small set of nodes with maximal influence can be posed as a submodular function maximization problem. The related problem of selecting a minimal set of nodes to achieve a desired influence is a submodular set cover problem. Both of these problems can be approximately solved via a simple greedy approximation algorithm.\nConsider a variation of this problem in which the goal is not to send advertisements to people that are influential in the entire social network but rather to people that are influential in a specific target group. For example, our target group could be people that like snowboarding or people that listen to jazz music. If the members of the target group are unknown and we have no way of learning the members of the target group, there is little we can do except assume every member of the social network is a member of the target group. However, if we assume the group has some known structure and that we receive feedback from sending advertisements (e.g. in the form of ad clicks or survey responses), it may be possible to simultaneously discover the members of the group and find people that are influential in the group.\nWe call problems like this learning and covering problems. In our example, the learning aspect of the problem is discovering the members of the target group (the people that like snowboarding), and the covering aspect of the problem is to select a small set of people that achieve a desired level of influence in the target group (the people to target with advertisements). Other applications have similar structure. For example, we may want to select a small set of representative documents about a topic of interest (e.g. about linear algebra). If we do not initially know the topic labels for documents, this is also a learning and covering problem.\nWe propose a new problem called interactive submodular set cover that can be used to model many learning and covering problems. Besides addressing interesting new applications, interactive submodular set cover directly generalizes submodular set cover and exact active learning with a finite hypothesis class (query learning) giving new insight into many previous theoretical results. We derive and analyze a new algorithm that is guaranteed to perform approximately as well as any other algorithm and in fact has the best possible approximation ratio. Our algorithm considers simultaneously the learning and covering parts of the problem. It is tempting to try to treat these two parts of the problem separately for example by first solving the learning problem and then solving the covering problem. We prove this approach and other simple approaches may perform much worse than the optimal algorithm.\n1"}, {"heading": "2 Background", "text": ""}, {"heading": "2.1 Submodular Set Cover", "text": "A submodular function is a set function satisfying a natural diminishing returns property. We call a set function F defined over a ground set V submodular iff for all A \u2286 B \u2286 V and v \u2208 V \\B\nF (A+ v)\u2212 F (A) \u2265 F (B + v)\u2212 F (B) (1)\nIn other words, adding an element to A, a subset of B, results in a larger gain than adding the same element to B. F is called modular if Equation 1 holds with equality. F is monotone non-decreasing if for all A \u2286 B \u2286 V , F (A) \u2264 F (B). Note that if F is monotone non-decreasing and submodular iff Equation 1 holds for all v \u2208 V (including v \u2208 B).\nProposition 1. If F1(S), F2(S), ...Fn(S) are all submodular, monotone non-decreasing functions then F1(S) + F2(S) + ...+ Fn(S) is submodular, monotone non-decreasing.\nProposition 2. For any function f mapping set elements to real numbers the function F (S) , maxs\u2208S f(s) is a submodular, monotone non-deceasing function.\nIn the submodular set cover problem the goal is to find a set S \u2286 V minimizing a modular cost function c(S) = \u2211\ns\u2208S c(s) subject to the constraint F (S) = F (V ) for a monotone non-decreasing submodular F .\nSubmodular Set Cover Given:\n\u2022 Ground set V \u2022 Modular cost function c defined over V \u2022 Submodular monotone non-decreasing objective function F defined over V\nObjective: Minimize c(S) such that F (S) = F (V )\nThis problem is closely related to the problem of submodular function maximization under a modular cost constraint c(S) < k for a constant k. A number of interesting real world applications can be posed as submodular set cover or submodular function maximization problems including influence maximization in social networks [12], sensor placement and experiment design [14], and document summarization [15]. In the sensor placement problem, for example, the ground set V corresponds to a set of possible locations. An objective function F (S) measures the coverage achieved by deploying sensors to the locations corresponding to S \u2286 V . For many reasonable definitions of coverage, F (S) turns out to be submodular.\nSubmodular set cover is a generalization of the set cover problem. In particular, set cover corresponds to the case where each v \u2208 V is a set of items taken from a set \u22c3\nv\u2208V v. The goal is to find a small set of sets S \u2286 V such that | \u22c3\ns\u2208S s| = | \u22c3 v\u2208V v|. The function F (S) = | \u22c3\ns\u2208S s| is monotone non-decreasing and submodular, so this is a submodular set cover problem. As is the case for set cover, a greedy algorithm has approximation guarantees for submodular set cover [18]. In particular, if F is integer valued, then the greedy solution is within H(maxv\u2208V F ({v})) of the optimal solution where H(k) is the kth harmonic number. Up to lower order terms, this matches the hardness of approximation lower bound (1\u2212 o(1)) lnn [7] where n = | \u22c3\nv\u2208V v| = F (V ). We note a variation of submodular set cover uses a constraint F (S) \u2265 \u03b1 for a fixed threshold \u03b1. This variation does not add any difficulty to the problem because we can always define a new monotone non-decreasing submodular function F\u0302 (S) = min(F (S), \u03b1) [14, 16] to convert the constraint F (S) \u2265 \u03b1 into a new constraint F\u0302 (S) = F\u0302 (V ). We can also convert in the other direction from a constraint F (S) = F (V ) to F (S) \u2265 \u03b1 by setting \u03b1 = F (V ). Without loss of generality or specificity, we use the variation of the problem with an explicit threshold F (S) \u2265 \u03b1."}, {"heading": "2.2 Exact Active Learning", "text": "In the exact active learning problem we have a known finite hypothesis class given by a set of objects H , and we want to identify an initially unknown target hypothesis h\u2217 \u2208 H . We identify h\u2217 by asking questions. Define Q to be the known set of all possible questions. A question q maps an object h to a set of valid responses q(h) \u2286 R with q(h) 6= \u2205 where R , \u22c3\nq\u2208Q,h\u2208H q(h) is the set of all possible responses. We know the mapping for each q (i.e. we know q(h) for every q and h). Asking q reveals some element r \u2208 q(h\u2217) which may be chosen adversarially (chosen to impede the learning algorithm). Each question q \u2208 Q has a positive cost c(q) defined by the modular cost function c.\nUWEETR-2010-0001 2\nThe goal of active learning is to ask a sequence of questions with small total cost that identifies h\u2217. By identifying h\u2217, we mean that for every h 6= h\u2217 we have received some response r to a question q such that r /\u2208 q(h). Questions are chosen sequentially so that the response from a previous question can be used to decide which question to ask next. The problem is stated below.\nExact Active Learning Given:\n\u2022 Hypothesis class H containing an unknown target h\u2217 \u2022 Query set Q and response set R with q(h) \u2286 R for q \u2208 Q, h \u2208 H \u2022 Modular query cost function c defined over Q\nRepeat: Ask a question q\u0302i \u2208 Q and receive a response r\u0302i \u2208 q\u0302i(h\u2217) Until: h\u2217 is identified (for every h \u2208 H with h 6= h\u2217 there is a (q\u0302i, r\u0302i) with r\u0302i /\u2208 q\u0302i(h)) Objective: Minimize \u2211\ni c(q\u0302i)\nIn a typical exact learning problem, H is a set of different classifiers and h\u2217 is a unique zero-error classifier. Questions in Q can, for example, correspond to label (membership) queries for data points. If we have a fixed data set consisting of data points xi, we can create a question qi corresponding to each xi and set qi(h) = {h(xi)}. Questions can also correspond to more complicated queries. For example, a question can ask if any points in a set are positively labelled. The setting we have described allows for mixing arbitrary types of queries with different costs.\nFor a set of question-response pairs S\u0302, define the version space V (S\u0302) to be the subset of H consistent with S\u0302\nV (S\u0302) , {h \u2208 H : \u2200(q, r) \u2208 S\u0302, r \u2208 q(h)}\nIn terms of the version space, the goal of exact active learning is to ask a sequence of questions such that |V (S\u0302)| = 1. We note that the assumption that H and Q are finite is not a problem for many applications involving finite data sets. In particular, if we have an infinite a hypothesis class (e.g. linear classifiers with dimension d) and a finite data set, we can simply use the effective hypothesis class induced by the data set [4]. On the other hand, the assumption that we have direct access to the target hypothesis (every r\u0302i is in q\u0302i(h\u2217)) and that the target hypothesis is in our hypothesis class (h\u2217 \u2208 H) is a limiting assumption. Stated differently, we assume that there is no noise and that the hypothesis class is correct.\nBuilding on previous work [3], Hanneke [10] showed that a simple greedy active learning strategy is approximately optimal in the setting we have described. The greedy strategy selects the question which relative to cost distinguishes the greatest number of hypotheses from h\u2217. Hanneke [10] shows this strategy incurs no more than ln |H | times the cost of any other question asking strategy.\nThe algorithms and approximation factors for submodular set cover and exact active learning are quite similar. Both are simple greedy algorithms and the lnF (V ) approximation for submodular set cover is similar to the ln |H | approximation for active learning. These similarities suggest these problems may be special cases of some other more general problem. We show that in fact they are special cases of a problem which we call interactive submodular set cover."}, {"heading": "3 Problem Statement", "text": "We use notation similar to the exact active learning problem we described in the previous section. Assume we have a finite hypothesis class H containing an unknown target hypothesis h\u2217 \u2208 H . We again assume there is a finite set of questions Q, a question q maps each object h to a set of valid responses q(h) \u2286 R with q(h) 6= \u2205, and each question q \u2208 Q has a positive cost c(q) defined by the modular cost function c. We also again assume that we know the mapping for each q (i.e. we know q(h) for every q and h). Asking q reveals some adversarially chosen element r \u2208 q(h\u2217). In the exact active learning problem the goal is to identify h\u2217 through questions. In this work we consider a generalization of this problem in which the goal is instead to satisfy a submodular constraint that depends on h\u2217.\nWe assume that for each object h there is a corresponding monotone non-decreasing submodular function Fh defined over subsets of Q \u00d7 R (sets of question-response pairs). We repeatedly ask a question q\u0302i and receive a response r\u0302i. Let the sequence of questions be Q\u0302 = (q\u03021, q\u03022, . . . ) and sequence of responses be R\u0302 = (r\u03021, r\u03022, . . . ). Define S\u0302 = \u22c3\nq\u0302i\u2208Q\u0302 {(q\u0302i, r\u0302i)} to be the final set of question-response pairs corresponding to these sequences. Our\ngoal is to ask a sequence of questions with minimal total cost c(Q\u0302) which ensures Fh\u2217(S\u0302) \u2265 \u03b1 for some threshold \u03b1 without knowing h\u2217 beforehand. We call this problem interactive submodular set cover.\nUWEETR-2010-0001 3\nInteractive Submodular Set Cover Given:\n\u2022 Hypothesis class H containing an unknown target h\u2217 \u2022 Query set Q and response set R with known q(h) \u2286 R for every q \u2208 Q, h \u2208 H \u2022 Modular query cost function c defined over Q \u2022 Submodular monotone non-decreasing objective functions Fh for h \u2208 H defined over Q\u00d7R \u2022 Objective threshold \u03b1\nRepeat: Ask a question q\u0302i \u2208 Q and receive a response r\u0302i \u2208 q\u0302i(h\u2217) Until: Fh\u2217(S\u0302) \u2265 \u03b1 where S\u0302 = \u22c3\ni{(q\u0302i, r\u0302i)} Objective: Minimize \u2211\ni c(q\u0302i)\nNote that although we know the hypothesis class H and the corresponding objective functions Fh, we do not initially know h\u2217. Information about h\u2217 is only revealed as we ask questions and receive responses to questions. Responses to previous questions can be used to decide which question to ask next, so in this way the problem is \u201cinteractive.\u201d Furthermore, the objective function for each hypothesis Fh is defined over sets of question-response pairs (as opposed to, say, sets of questions), so when asking a new question we cannot predict how the value of Fh will change until after we receive a response. The only restriction on the response we receive is that it must be consistent with the initially unknown target h\u2217. It is this uncertainty about h\u2217 and the feedback we receive from questions that distinguishes the problem from submodular set cover and allows us to model learning and covering problems."}, {"heading": "3.1 Connection to Submodular Set Cover", "text": "If we know h\u2217 (e.g. if |H | = 1) and we assume |q(h)| = 1 \u2200q \u2208 Q, h \u2208 H (i.e. that there is only one valid response to every question), our problem reduces exactly to the standard submodular set cover problem. Under these assumptions, we can compute Fh\u2217(S\u0302) for any set of questions without actually asking these questions. Krause et al. [14] study a non-interactive version of interactive submodular set cover in which |q(h)| = 1 \u2200q \u2208 Q, h \u2208 H and the entire sequence of questions must be chosen before receiving any responses. This restricted version of the problem can also be reduced to standard submodular set cover Krause et al. [14]."}, {"heading": "3.2 Connection to Active Learning", "text": "Define Fh(S\u0302) , F (S\u0302) = |H \\ V (S\u0302)|\nwhere V (S\u0302) is again the version space (the set of hypotheses consistent with S\u0302). This objective is the number of hypotheses eliminated from the version space by S\u0302.\nLemma 1. Fh(S\u0302) , |H \\ V (S\u0302)| is submodular and monotone non-decreasing\nProof. To see this note that we can write Fh as Fh(S\u0302) = \u2211\nh\u2032\u2208H max(q,r)\u2208S\u0302 fh\u2032((q, r)) where fh\u2032((q, r)) = 1 if r /\u2208 q(h\u2032) and else fh\u2032((q, r)) = 0. The result then follows from Proposition 1 and Proposition 2.\nFor this objective, if we set \u03b1 = |H | \u2212 1 we get the standard exact active learning problem: our goal is to identify h\u2217 using a set of questions with small total cost. Note that in this case the objective Fh does not actually depend on h (i.e. Fh = Fh\u2032 for all h, h\u2032 \u2208 H) but the problem still differs from standard submodular set cover because Fh(S\u0302) is defined over question-response pairs.\nInteractive submodular set cover can also model an approximate variation of active learning with a finite hypothesis class and finite data set. Define\nFh(S\u0302) , |H \\ V (S\u0302)|(|X | \u2212 \u03ba) + \u2211\nh\u2032\u2208V (S\u0302)\nmin(|X | \u2212 \u03ba, \u2211\nx\u2208X\nI(h\u2032(x) = h(x)))\nwhere I is the indicator function, X is a finite data set, and \u03ba is an integer.\nProposition 3. Fh\u2217(S\u0302) = |H |(|X | \u2212 \u03ba) iff all hypotheses in the version space make at most \u03ba mistakes.\nUWEETR-2010-0001 4\nLemma 2. Fh(S\u0302) , |H \\ V (S\u0302)|(|X | \u2212 \u03ba) + \u2211 h\u2032\u2208V (S\u0302) min(|X | \u2212 \u03ba, \u2211 x\u2208X I(h \u2032(x) = h(x))) is submodular and monotone non-decreasing\nProof. We can write Fh as Fh(S\u0302) = \u2211 h\u2032\u2208H max(q,r)\u2208S\u0302 fh((q, r)) where fh\u2032((q, r)) = |X | \u2212 \u03ba if r /\u2208 q(h \u2032) and else fh\u2032((q, r)) = min(|X | \u2212 \u03ba, \u2211 x\u2208X I(h \u2032(x) = h(x))). The result then follows from Proposition 1 and Proposition 2.\nFor this objective, if we set \u03b1 = |H |(|X | \u2212 \u03ba) then our goal is to ask a sequence of questions such that all hypotheses in the version space make at most \u03ba mistakes. Balca\u0301zar et al. [3] study a similar approximate query learning setting, and Dasgupta et al. [5] consider a slightly different setting where the target hypothesis may not be in H ."}, {"heading": "3.3 Connection to Adaptive Submodularity", "text": "In concurrent work, Golovin and Krause [9] show results similar to ours for a different but related class of problems which also involve interactive (i.e. sequential, adaptive) optimization of submodular functions. What Golovin and Krause call realizations correspond to hypotheses in our work while items and states correspond to queries and responses respectively. Golovin and Krause consider both average-case and worst-case settings and both maximization and min-cost coverage problems. In contrast, we only consider worst-case, min-cost coverage problems. In this sense our results are less general.\nHowever, in other ways our results are more general. The main greedy approximation guarantees shown by Golovin and Krause require that the problem is adaptive submodular; adaptive submodularity depends not only on the objective but also on the set of possible realizations and the probability distribution over these realizations. In contrast we only require that for a fixed hypothesis the objective is submodular. Golovin and Krause call this pointwise submodularity. Pointwise submodularity does not in general imply adaptive submodularity (see the clustered failure model discussed by Golovin and Krause).\nIn fact, for problems that are pointwise modular but not adaptive submodular, Golovin and Krause show a hardness of approximation lower bound of O(|Q|1\u2212\u01eb); we note this does not contradict our results as their proof is for averagecase cost and uses a hypothesis class with |H | = 2|Q|. Golovin and Krause also propose a simple non greedy approach with explicit explore and exploit stages; this approach requires only a weaker assumption that the value of the exploitation stage is adaptive submodular with respect to exploration. However, it is not immediately obvious when this condition holds, and it is also not clear how to apply this approach to worst-case or min-cost coverage problems.\nThere are other smaller differences between our problem settings: we let queries map hypotheses to sets of valid responses (in general |q(h)| > 1) while Golovin and Krause define realizations as maps from items to single states. Also, in our work we allow for non uniform query costs (in general c(qi) 6= c(qj)) while Golovin and Krause require that every item has the same cost (Golovin and Krause do however mention that the extension to non uniform costs is straightforward). We finally note that the proof techniques we use are quite different.\nSome other previous work has also considered interactive versions of covering problems in an average-case model [1, 8]. The work of Asadpour et al. [1] is perhaps most similar and considers a submodular function maximization problem over independent random variables which are sequentially queried. The setting considered by Golovin and Krause [9] strictly generalizes this setting. Streeter and Golovin [17] study an online version of submodular function maximization where a sequence of submodular function maximization problems is solved. This problem is related in that it also involves learning and submodular functions, but the setting is very different than the one studied here where we solve a single interactive problem as opposed to a series of non-interactive problems."}, {"heading": "4 Example", "text": "In the advertising application we described in the introduction, the target hypothesis h\u2217 corresponds to the group of people we want to target with advertisements (e.g. the people that like snowboarding), and the hypothesis class H encodes our prior knowledge about h\u2217. For example, if we know the target group forms a small dense subgraph in the social network, then the hypothesis class H would be the set of all small dense subgraphs in the social network. The query set Q and response set R correspond to advertising actions and feedback respectively, and finally the objective function Fh measures advertising coverage within the group corresponding to h.\nUWEETR-2010-0001 5\nTo make the discussion concrete, assume the advertiser sends a single ad at a time and that after a person is sent an ad the advertiser receives a binary response indicating if that person is in the target group (i.e. likes snowboarding). Let qi correspond to sending an ad to user i (i.e. node i), and qi(h) = {1} if user i is in group h and qi(h) = {0} otherwise. For our coverage goal, assume the advertiser wants to ensure that every person in the target group either receives an ad or has a friend that receives an ad. We say a node is \u201ccovered\u201d if it has received an ad or has a neighbor that has received an ad. This is a variation of the minimum dominating set problem, and we use the following objective\nFh(S\u0302) , \u2211\nv\u2208Vh\nI ( v \u2208 VS\u0302 or \u2203s \u2208 VS\u0302 : (v, s) \u2208 E ) + |V \\ Vh|\nwhere V and E are the nodes and edges in the social network, Vh is the set of nodes in group h, and VS\u0302 is the set of nodes corresponding to ads we have sent. With this objective Fh\u2217(S\u0302) = |V | iff we have achieved the stated coverage goal.\nLemma 3. Fh(S\u0302) = \u2211\nv\u2208Vh I(v \u2208 VS\u0302 or \u2203s \u2208 VS\u0302 : (v, s) \u2208 E) + |V \\ Vh| is submodular and monotone non-\ndecreasing.\nProof. We can write Fh(S\u0302) as Fh(S\u0302) = \u2211\nv\u2208V max(q\u0302,r\u0302)\u2208S\u0302 fv((q\u0302, r\u0302)) where fv((q\u0302, r\u0302)) = 1 if the action q\u0302 covers v or v /\u2208 Vh and fv((q\u0302, r\u0302)) = 0 otherwise. The result then follows from Proposition 1 and Proposition 2.\nFigure 1 shows a cartoon social network. For this example, assume the advertiser knows the target group is one of the four clusters shown (marked A, B, C, and D) but does not know which. This is our hypothesis class H . The node marked v is initially very useful for learning the members of the target group: if we send an ad to this node, no matter what response we receive we are guaranteed to eliminate two of the four clusters (either A and B or C and D). However, this node has only a degree of 2 and therefore sending an ad to this node does not cover very many nodes. On the other hand, the nodes marked x and w are connected to every node in clusters B and D respectively. x (resp. w) is therefore very useful for achieving the coverage objective if the target group is B (resp. D). An algorithm for learning and covering must choose between actions more beneficial for learning vs. actions more beneficial for covering (although sometimes an action can be beneficial for both to a certain degree). The interplay between learning and covering is similar to the exploration-exploitation trade-off in reinforcement learning. In this example an optimal strategy is to first send an ad to v and then cover the remaining two clusters using two additional ads for a worst case cost of 3.\nA simple approach to learning and covering is to simply ignore feedback and solve the covering problem for all possible target groups. In our example application the resulting covering problem is a simple dominating set problem for which we can use standard submodular set cover methods. We call this the Cover All strategy. This approach is suboptimal because in many cases feedback can make the problem significantly easier. In our synthetic example, any strategy not using feedback must use worst case cost of 4: four ads are required to cover all of the nodes in the four clusters. Theorem 4 in Section 6 proves that in fact there are cases where the best strategy not using feedback incurs exponentially greater cost than the best strategy using feedback.\nAnother simple approach is to solve the learning problem first (identify h\u2217) and then solve the covering problem (satisfy Fh\u2217(S\u0302)). We can use, for example, query learning to solve the learning problem and then use standard submodular set cover to solve the covering problem. We call this the Learn then Cover strategy. This approach turns\nUWEETR-2010-0001 6\nout to match the optimal strategy in the example given by Figure 1. In this example the target group can be identified using 2 queries by querying v then w if the response is 1 and x if the response is 0. After identifying the target group, the target group can be covered in at most one more query. However, this approach is not optimal for other instances of this problem. For example, if we were to add an additional node which is connected to every other node then the covering problem would have a solution of cost 1 while the learning problem would still require cost of 2. Theorem 3 in Section 6 shows that in fact there are examples where solving a learning problem is much harder than solving the corresponding learning and covering problem. We therefore must consider other methods for balancing learning and covering.\nWe note that this problem setup can be modified to allow queries to have sometimes uninformative responses; this can be modeled by adding an additional response to R which corresponds to a \u201cno-feedback\u201d response and including this response in the set of allowable responses (q(h)) for certain query-hypothesis pairs . However, care must be taken to ensure that the resulting problem is still interesting for worst-case choice of responses; if we allow \u201cno-feedback\u201d responses for every question-hypothesis pair, then the in the worst-case we will never receive any feedback, so a worst case optimal strategy could ignore all responses."}, {"heading": "5 Greedy Approximation Guarantee", "text": "We are interested in approximately optimal polynomial time algorithms for the interactive submodular set cover problem. We call a question asking strategy correct if it always asks a sequence of questions such that Fh\u2217(S\u0302) \u2265 \u03b1 where S\u0302 is again the final set of question-response pairs. A necessary and sufficient condition to ensure Fh\u2217(S\u0302) \u2265 \u03b1 for worst case choice of h\u2217 is to ensure minh\u2208V (S\u0302) Fh(S\u0302) \u2265 \u03b1 where V (S\u0302) is the version space. Then a simple stopping condition which ensures a question asking strategy is correct is to continue asking questions until minh\u2208V (S\u0302) Fh(S\u0302) \u2265 \u03b1. We call a question asking strategy approximately optimal if it is correct and the worst case cost incurred by the strategy is not much worse than the worst case cost of any other strategy.\nAs discussed informally in the previous section, it is important for a question asking strategy to balance between learning (identifying h\u2217) and covering (increasing Fh\u2217 ). Ignoring either aspect of the problem is in general suboptimal (we show this formally in Section 6). We propose a reduction which converts the problem over many objective functions Fh into a problem over a single objective function F\u0304\u03b1 that encodes the trade-off between learning and covering. We can then use a greedy algorithm to maximize this single objective, and this turns out to overcome the shortcomings of simpler approaches. This reduction is inspired by the reduction used by Krause et al. [14] in the non-interactive setting to convert multiple covering constraints into a single covering constraint.\nDefine F\u0304\u03b1(S\u0302) , (1/|H |)( \u2211\nh\u2208V (S\u0302)\nmin(\u03b1, Fh(S\u0302)) + \u03b1|H \\ V (S\u0302)|)\nF\u0304\u03b1(S\u0302) \u2265 \u03b1 iff Fh(S\u0302) \u2265 \u03b1 for all h \u2208 V (S\u0302) so a question asking strategy is correct iff it satisfies F\u0304\u03b1(S\u0302) \u2265 \u03b1. This objective balances the value of learning and covering. The sum over h \u2208 V (S\u0302) measures progress towards satisfying the covering constraint for hypotheses h in the current version space (covering). The second term \u03b1|H \\ V (S\u0302)| measures progress towards identifying h\u2217 through reduction in version space size (learning). Note that the objective does not make a hard distinction between learning actions and covering actions. In fact, the objective will prefer actions that both increase Fh(S\u0302) for h \u2208 V (S\u0302) and decrease the size of V (S\u0302). Crucially, F\u0304\u03b1 retains submodularity.\nLemma 4. F\u0304\u03b1 is submodular and monotone non-decreasing when every Fh is submodular and monotone nondecreasing.\nProof. Note that the proof would be trivial if the sum were over all h \u2208 H . However, since the sum is over a subset of H which depends on S\u0302, the result is not obvious. We can write F\u0304\u03b1 as F\u0304\u03b1(S\u0302) = (1/|H |) \u2211 h\u2208H F\u0302\u03b1,h(S\u0302) where we define F\u0302\u03b1,h(S\u0302) , I(h \u2208 V (S\u0302))min(\u03b1, Fh(S\u0302)) + I(h /\u2208 V (S\u0302))\u03b1. It is not hard to see F\u0302\u03b1,h is monotone nondecreasing. We show F\u0302\u03b1,h is also submodular and the result then follows from Proposition 1. Consider any (q, r) /\u2208 B and A \u2286 B \u2286 (Q \u00d7 R). We show Equation 1 holds in three cases. Here we use as short hand Gain(F, S, s) , F (S + s)\u2212 F (S).\n\u2022 If h /\u2208 V (B) then Gain(F\u0302\u03b1,h, A, (q, r)) \u2265 0 = Gain(F\u0302\u03b1,h, B, (q, r))\nUWEETR-2010-0001 7\nAlgorithm 1 Worst Case Greedy\n1: H\u0302 \u21d0 H 2: S\u0302 \u21d0 \u2205 3: while F\u0304\u03b1(S\u0302) < \u03b1 do 4: q\u0302 \u21d0 argmaxqi\u2208Q minh\u2208V (S\u0302)minri\u2208qi(h)(F\u0304\u03b1(S\u0302 + (qi, ri))\u2212 F\u0304\u03b1(S\u0302))/c(qi) 5: Ask q\u0302 and receive response r\u0302 6: S\u0302 \u21d0 S\u0302 + (q\u0302, r\u0302) 7: end while\n\u2022 If r /\u2208 q(h) then\nGain(F\u0302\u03b1,h, A, (q, r)) = \u03b1\u2212 F\u0302\u03b1,h(A) \u2265 \u03b1\u2212 F\u0302\u03b1,h(B) = Gain(F\u0302\u03b1,h, B, (q, r))\n\u2022 If r \u2208 q(h) and h \u2208 V (B) then\nGain(F\u0302\u03b1,h, A, (q, r)) = min(Fh(A+ (q, r)), \u03b1) \u2212min(Fh(A), \u03b1)\n\u2265 min(Fh(B + (q, r)), \u03b1) \u2212min(Fh(B), \u03b1) = Gain(F\u0302\u03b1,h, B, (q, r))\nHere we used the submodularity of min(Fh(S), \u03b1) [16].\nAlgorithm 1 shows the worst case greedy algorithm which at each step picks the question qi that maximizes the worst case gain of F\u0304\u03b1\nmin h\u2208V (S\u0302) min ri\u2208qi(h) (F\u0304\u03b1(S\u0302 + (qi, ri))\u2212 F\u0304\u03b1(S\u0302))/c(qi)\nWe now argue that Algorithm 1 is an approximately optimal algorithm for interactive submodular set cover. Note that although it is a simple greedy algorithm over a single submodular objective, the standard submodular set cover analysis doesn\u2019t apply: the objective function is defined over question-response pairs, and the algorithm cannot predict the actual objective function gain until after selecting and commiting to a question and receiving a response. We use an Extended Teaching Dimension style analysis [10] inspired by previous work in query learning. We are the first to our knowledge to use this kind of proof for a submodular optimization problem.\nDefine an oracle (teacher) T \u2208 RQ to be a function mapping questions to responses. As a short hand, for a sequence of questions Q\u0302 define\nT (Q\u0302) , \u22c3\nq\u0302i\u2208Q\u0302\n{(q\u0302i, T (q\u0302i))}\nT (Q\u0302) is the set of question-response pairs received when T is used to answer the questions in Q\u0302. We now define a quantity analogous to the General Identification Cost for exact active learning [10]. Define the General Cover Cost, GCC\nGCC , max T\u2208RQ ( min Q\u0302:F\u0304\u03b1(T (Q\u0302))\u2265\u03b1 c(Q\u0302))\nGCC depends on H , Q, \u03b1, c, and the objective functions Fh, but for simplicity of notation this dependence is suppressed. GCC can be viewed as the cost of satisfying F\u0304\u03b1(T (Q\u0302)) \u2265 \u03b1 for worst case choice of T where the choice of T is known to the algorithm selecting Q\u0302. Here the worst case choice of T is over all mappings between Q and R. There is no restriction that T answer questions in a manner consistent with any hypothesis h \u2208 H .\nWe first show that GCC is a lower bound on the optimal worst case cost of satisfying Fh\u2217(S\u0302) \u2265 \u03b1.\nLemma 5. If there is a correct question asking strategy for satisfying Fh\u2217(S\u0302) \u2265 \u03b1 with worst case cost C\u2217 then GCC \u2264 C\u2217.\nProof. Assume the lemma is false and there is a correct question asking strategy with worst case cost C\u2217 and GCC > C\u2217. Using this assumption and the definition of GCC, there is some oracle T \u2217 such that\nmin Q\u0302:F\u0304\u03b1(T\u2217(Q\u0302))\u2265\u03b1\nc(Q\u0302) = GCC > C\u2217\nUWEETR-2010-0001 8\nWhen we use T \u2217 to answer questions, any sequence of questions Q\u0302 with total cost less than or equal to C\u2217 must have F\u0304\u03b1(S\u0302) < \u03b1. F\u0304\u03b1(S\u0302) < \u03b1 in turn implies Fh\u2217(S\u0302) < \u03b1 for some target hypothesis choice h\u2217 \u2208 V (S\u0302). This contradicts the assumption there is a correct strategy with worst case cost C\u2217.\nWe now establish that when GCC is small, there must be a question which increases F\u0304\u03b1.\nLemma 6. For any initial set of questions-response pairs S\u0302, there must be a question q \u2208 Q such that\nmin h\u2208V (S\u0302) min r\u2208q(h) F\u0304\u03b1(S\u0302 + (q, r)) \u2212 F\u0304\u03b1(S\u0302) \u2265 c(q)(\u03b1 \u2212 F\u0304\u03b1(S\u0302))/GCC\nProof. Assume the lemma is false and for every question q there is some h \u2208 V (S\u0302) and r \u2208 q(h) such that\nF\u0304\u03b1(S\u0302 + (q, r)) \u2212 F\u0304\u03b1(S\u0302) < c(q)(\u03b1 \u2212 F\u0304\u03b1(S\u0302))/GCC\nDefine an oracle T \u2032 which answers every question with a response satisfying this inequality. For example, one such T \u2032 is\nT \u2032(q) , argminr F\u0304\u03b1(S\u0302 + (q, r)) \u2212 F\u0304\u03b1(S\u0302)\nBy the definition of GCC\nmin Q\u0302:F\u0304\u03b1(T \u2032(Q\u0302))\u2265\u03b1 c(Q\u0302)) \u2264 max T\u2208RQ ( min Q\u0302:F\u0304\u03b1(T (Q\u0302))\u2265\u03b1 c(Q\u0302)) = GCC\nso there must be a sequence of questions Q\u0302 with c(Q\u0302) \u2264 GCC such that F\u0304\u03b1(T \u2032(Q\u0302)) \u2265 \u03b1. Because F\u0304\u03b1 is monotone non-decreasing, we also know F\u0304\u03b1(T \u2032(Q\u0302) \u222a S\u0302) \u2265 \u03b1. Using the submodularity of F\u0304\u03b1,\nF\u0304\u03b1(T \u2032(Q\u0302) \u222a S\u0302) \u2264 F\u0304\u03b1(S\u0302) +\n\u2211\nq\u2208Q\u0302\n(F\u0304\u03b1(S\u0302 \u222a {(q, T (q))})\u2212 F\u0304\u03b1(S\u0302))\n< F\u0304\u03b1(S\u0302) + \u2211\nq\u2208Q\u0302\nc(q)(\u03b1\u2212 F\u0304\u03b1(S\u0302))/GCC \u2264 \u03b1\nwhich is a contradiction.\nWe can now show approximate optimality.\nTheorem 1. Assume that \u03b1 is an integer and, for any h \u2208 H , Fh is an integral monotone non-decreasing submodular function. Algorithm 1 incurs at most GCC(1 + ln(\u03b1n)) cost.\nProof. Let q\u0302i be the question asked on the ith iteration, S\u0302i be the set of question-response pairs after asking q\u0302i and Ci be \u2211\nj\u2264i c(q\u0302j). By Lemma 6\nF\u0304\u03b1(S\u0302i)\u2212 F\u0304\u03b1(S\u0302i\u22121) \u2265 c(q\u0302i)(\u03b1\u2212 F\u0304\u03b1(S\u0302i\u22121))/GCC\nAfter some algebra we get \u03b1\u2212 F\u0304\u03b1(S\u0302i) \u2264 (\u03b1\u2212 F\u0304\u03b1(S\u0302i\u22121))(1 \u2212 c(q\u0302i)/GCC)\nNow using 1\u2212 x < e\u2212x\n\u03b1\u2212 F\u0304\u03b1(S\u0302i) \u2264 (\u03b1\u2212 F\u0304\u03b1(S\u0302i\u22121))e \u2212c(q\u0302i)/GCC = \u03b1e\u2212Ci/GCC\nWe have shown that the gap \u03b1 \u2212 F\u0304\u03b1(S\u0302i) decreases exponentially fast with the cost of the questions asked. The remainder of the proof proceeds by showing that (1) we can decrease the gap to 1/|H | using questions with at most GCC ln(\u03b1|H |) cost and (2) we can decrease the gap from 1/|H | to 0 with one question with cost at most GCC.\nLet j is the largest integer such that \u03b1\u2212 F\u0304\u03b1(S\u0302j) \u2265 1/|H | holds. Then\n1/|H | \u2264 \u03b1e\u2212Cj/GCC\nSolving for Cj we get Cj \u2264 GCC ln(\u03b1|H |). This completes (1). By Lemma 6, F\u0304\u03b1(S\u0302i) < F\u0304\u03b1(S\u0302i+1) (we strictly increase the objective on each iteration). Because \u03b1 is an integer and for every h Fh is an integral function, we can conclude F\u0304\u03b1(S\u0302i) < F\u0304\u03b1(S\u0302i+1) + 1/|H |. Then qj+1 will be the final question asked. By Lemma 6, qj+1 can have cost no greater than GCC. This completes (2). We can finally conclude the cost incurred by the greedy algorithm is at most GCC(1 + ln(\u03b1|H |))\nUWEETR-2010-0001 9\nBy combining Theorem 1 and Lemma 5 we get\nCorollary 1. For integer \u03b1 and integral monotone non-decreasing submodular Fh, the worst case cost of Algorithm 1 is within 1 + ln(\u03b1|H |) of that of any other correct question asking strategy\nWe have shown a result for integer valued \u03b1 and objective functions. We speculate that for more general noninteger objectives it should be possible to give results similar to those for standard submodular set cover [18]. These approximation bounds typically add an additional normalization term."}, {"heading": "6 Negative Results", "text": ""}, {"heading": "6.1 Na\u0131\u0308ve Greedy", "text": "The algorithm we propose is not the most obvious approach to the problem. A more direct extension of the standard submodular set cover algorithm is to choose at each time step a question qi which has not been asked before and that maximizes the worst case gain of Fh\u2217 . In other words, chose the question qi that maximizes\nmin h\u2208V (S\u0302) min ri\u2208qi(h) (Fh(S\u0302 + (qi, ri))\u2212 Fh(S\u0302))/c(qi)\nThis is in contrast to the method we propose that maximizes the worst-case gain of F\u0304\u03b1 instead of Fh. We call this strategy the Na\u0131\u0308ve Greedy Algorithm. This algorithm in general performs much worse than the optimal strategy. The counter example is very similar to that given by Krause et al. [14] for the equivalent approach in the non-interactive setting.\nTheorem 2. Assume Fh is integral for all h \u2208 H and \u03b1 is integer. The Na\u0131\u0308ve Greedy Algorithm has approximation ratio at least \u2126(\u03b1maxi c(qi)/mini c(qi)).\nProof. Consider the following example with |H | = 2, |Q| = \u03b1+ 2, |R| = 1 and \u03b1 > 1. When |R| = 1 responses reveal no information about h\u2217, so the interactive problem is equivalent to the non-interactive problem, and the objective function only depends on the set of questions asked. Let Fh1 and Fh2 be modular functions defined by\nFh1(q1) , \u03b1 Fh1(q2) , 0\nFh2(q1) , 0 Fh2(q2) , \u03b1\nand, for all h and all qi with i > 2, Fh(qi) , 1. The optimal strategy asks q1 and q2 (since h\u2217 is unknown we must ask both). However, the worst-case gain of asking q1 or q2 is zero while the gain of asking qi for i > 2 is 1/c(qi). The Na\u0131\u0308ve Greedy Algorithm will then always ask every qi for i > 2 before asking q1 and q2 no matter how large c(qi) is compared to c(q1) and c(q2). By making c(qi) for i > 2 large compared to c(q1) and c(q2) we get the claimed approximation ratio."}, {"heading": "6.2 Learn then Cover", "text": "The method we propose for interactive submodular set cover simultaneously solves the learning problem and covering problem in parallel, only solving the learning problem to the extent that it helps solve the covering problem. A simpler strategy is to solve these two problems in series (i.e. first identify h\u2217 using the standard greedy query learning algorithm and second solve the submodular set cover problem for Fh\u2217 using the standard greedy set cover algorithm). We call this the Learn then Cover approach. We show that this approach and in fact any approach that identifies h\u2217 exactly can perform very poorly. Therefore it is important to consider the learning problem and covering problem simultaneously.\nTheorem 3. Assume Fh is integer for all h and that \u03b1 is an integer. Any algorithm that exactly identifies h\u2217 has approximation ratio at least \u2126(|H |maxi c(qi)/mini c(qi)).\nProof. We give a simple example for which the learning problem (identifying h\u2217) is hard but the interactive submodular set cover problem (satisfying Fh\u2217(S\u0302) \u2265 \u03b1) is easy. For i \u2208 1...|H | let qi(hj) = {1} if i = j and qi(hj) = {0}\nUWEETR-2010-0001 10\nif i 6= j. For i = |H | + 1 let qi(hj) = {0} for all j. For worse case choice of h\u2217, we need ask every question qi for i \u2208 1...|H | in order to identify h\u2217. However, if we define the objective to be\nFh(S\u0302) , I((q|H|+1, 0) \u2208 S\u0302)\nfor all h with \u03b1 = 1, the interactive submodular set cover problem is easy. To satisfy Fh\u2217(S\u0302) \u2265 \u03b1 we simply need to ask question q|H|+1. By making the cost of q|H|+1 small and the cost of the other questions large, we get an approximation ratio of at least |H |maxi c(qi)/mini c(qi)."}, {"heading": "6.3 Adaptivity Gap", "text": "Another simple approach is to ignore feedback and solve the covering problem for all h \u2208 H . We call this the Cover All method. This method is an example of a non-adaptive method: a non-adaptive (i.e. non interactive) method is any method that does not use responses to previous questions in deciding which question to ask next. The adaptivity gap [6] for a problem characterizes how much worse the best non-adaptive method can perform as compared to the best adaptive method. For interactive submodular set cover we define the adaptivity gap to be the maximum ratio between the cost of the optimal non-adaptive strategy and the optimal adaptive strategy. With this definition, we can show that, in contrast to related problems [1] where the adaptivity gap is a constant, the adaptivity gap for interactive submodular set cover is quite large.\nTheorem 4. The adaptivity gap for interactive submodular set cover is at least \u2126(|H |/ ln |H |).\nProof. The result follows directly from the connection to active learning (Section 3.2) and in particular any example of exact active learning giving an exponential speed up over passive learning. A classic example is learning a threshold on a line [4]. Let |H | = 2k for some integer k > 0. Define the active learning objective as before\nFh(S\u0302) , |H \\ V (S\u0302)|\nfor all h. The goal of the problem is to identify h\u2217. We define the query set such that we can identify h\u2217 through binary search. Let there be a query qi corresponding to each hypothesis hi. Let qi(hj) = {1} if i \u2264 j and qi(hj) = {0} if i > j. Each qi can be thought of as a point on a line with hi the binary classifier which classifies all points as positive which are less than or equal to qi. By asking question q2k\u22121 we can eliminate half of H from the version space. We can then recurse on the remaining half of H and identify h\u2217 in k queries. Any non-adaptive strategy on the other hand must perform all 2k queries in order to ensure V (S\u0302)| = 1 for worst case choice of h\u2217.\nThis result shows, even if we optimally solve the submodular set cover problem, the Cover All method can incur exponentially greater cost than the optimal adaptive strategy."}, {"heading": "6.4 Hardness of Approximation", "text": "We show that the 1 + ln(\u03b1|H |) approximation factor achieved by the method we propose is in fact the best possible up to the constant factor assuming there are no slightly superpolynomial time algorithms for NP. The result and proof are very similar to those for the non-interactive setting [14].\nTheorem 5. Interactive submodular set cover cannot be approximated within a factor of (1\u2212 \u01eb)max(ln |H |, ln\u03b1) in polynomial time for any \u01eb > 0 unless NP has nO(log logn) time deterministic algorithms.\nProof. We show the result by reducing set cover to interactive submodular set cover in two different ways. In the first reduction, a set cover instance of size n gives an interactive submodular set cover of with |H | = 1 and \u03b1 = n. In the second reduction, a set cover instance of size n gives an interactive submodular set cover instance with |H | = n and \u03b1 = 1. The theorem then follows from the result of Feige [7] which shows a set cover cannot be approximated within a factor of (1\u2212 \u01eb) lnn in polynomial time for any \u01eb > 0 unless NP has nO(log logn) time deterministic algorithms.\nLet V be the set of sets defining the set cover problem. The ground set is \u22c3\nv\u2208V v. The goal of set cover is to find a small set of sets S \u2286 V such that \u22c3\ns\u2208S s = \u22c3 v\u2208V v. For both reductions we use |R| = 1 (all questions have only one\nresponse) and make each question in Q correspond to a set in V . For a set of question-response pairs S\u0302 define VS\u0302 to be the subset of V corresponding to the questions in S\u0302. For the first reduction with |H | = 1, we set the one objective function Fh(S\u0302) , | \u22c3\nv\u2208V S\u0302 v|. With \u03b1 = n, we have that F\u0304\u03b1(S\u0302) = \u03b1 iff VS\u0302 forms a cover.\nUWEETR-2010-0001 11\nFor the second reduction with |H | = n, define Fhi(S\u0302) for the ith hypothesis hi to be 1 iff the ith object in the ground set of the set cover problem is covered by VS\u0302 . More formally Fhi(S\u0302) , I(vi \u2208 VS\u0302) where vi is the ith item in the ground set (ordered arbitrarily). This is similar to the first reduction except we have broken down the objective into a sum over the ground set elements. With \u03b1 = 1, we then have that F\u0304\u03b1(S\u0302) = \u03b1 iff VS\u0302 forms a cover.\nThe approximation factor we have shown for the greedy algorithm is"}, {"heading": "1 + ln(\u03b1|H |) = 1 + ln\u03b1+ ln |H | < 1 + 2max(ln |H |, ln\u03b1)", "text": "so our hardness of approximation result matches up to the constant factor and lower order term."}, {"heading": "7 Experiments", "text": "We tested our method on the interactive dominating set problem described in Section 4. In this problem, we are given a graph and H is a set of possibly overlapping clusters of nodes. The goal is to find a small set of nodes which forms a dominating set of an initially unknown target group h\u2217 \u2208 H . After selecting each node, we receive feedback indicating if the selected node is in the target group. Our proposed method (Simultaneous Learning and Covering) simultaneously learns about the target group h\u2217 and finds a dominating set for it. We compare to two baselines: a method which first exactly identifies h\u2217 and then finds a dominating set for the target group (Learn then Cover) and a method which simply ignores feedback and finds a dominating set for the union of all clusters (Cover All). Note that Theorem 3 and Theorem 4 apply to Learn then Cover and Cover All respectively, so these methods do not have strong theoretical guarantees. However, we might hope however that for reasonable real world problems they perform well. We use real world network data sets with simple synthetic hypothesis classes designed to illustrate differences between the methods. The networks are from Jure Leskovec\u2019s collection of datasets available at http://snap.stanford.edu/data/index.html. We convert all the graphs into undirected graphs and remove self edges.\nTable 1 shows our results. Each reported result is the average number of queries over 100 trials. Bolded results are the best methods for each setting with multiple results bolded when differences are not statistically significant (within p = .01 with a paired t-test). In the first set of results (Clusters), we create H by using the METIS graph partition package 4 separate times partitioning the graph into 10, 20, 30, and 40 clusters. H is the combined set of 100 clusters, and these clusters overlap since they are taken from 4 separate partitions of the graph. The target h\u2217 is chosen at random from H . With this hypothesis class, we\u2019ve found that there is very little difference between the Simultaneous Learning and Covering and the Learn then Cover methods. The Cover All method performs significantly worse because without the benefit of feedback it must find a dominating set of the entire graph.\nIn the second set of results, we use a hypothesis class designed to make learning difficult (Noisy Clusters). We start with H generated as before. We then add to H 100 additional hypotheses which are each very similar to h\u2217. Each of these hypotheses consists of the target group h\u2217 with a random member removed. H is then the combined set of the 100 original hypotheses and these 100 variations of h\u2217. For this hypothesis class, Learn then Cover performs significantly worse than our Simultaneous Learning and Covering method on 3 of the 5 data sets. Learn then Cover exactly identifies h\u2217, which is difficult because of the many hypotheses similar to h\u2217. Our method learns about h\u2217 but\nUWEETR-2010-0001 12\nonly to the extent that it is helpful for finding a small dominating set. On the other two data sets Learn then Cover and Simultaneous Learning and Covering are almost identical. These are larger data sets, and we\u2019ve found that when the covering problem requires many more queries than the learning problem, our method is nearly identical to Learn then Cover. This makes sense since when \u03b1 is large compared to the sum over Fh(S\u0302) the second term in F\u0304\u03b1 dominates.\nIt is also possible to design hypothesis classes for which Cover All outperforms Learn then Cover: we found this is the case when the learning problem is difficult but the subgraph corresponding to the union of all clusters in H is small. In the appendix we give an example of this. In all cases, however, our approach does about as good or better than the best of these two baseline methods. Although we use real world graph data, the hypothesis classes and target hypotheses we use are very simple and synthetic, and as such these experiments are primarily meant to provide reasonable examples in support of our theoretical results."}, {"heading": "8 Future Work", "text": "We believe there are other interesting applications which can be posed as interactive submodular set cover. In some applications it may be difficult to compute F\u0304\u03b1 exactly because H may be very large or even infinite. In these cases, it may be possible to approximate this function by sampling from H . It\u2019s also important to consider methods that can handle misspecified hypothesis classes and noise within the learning. One approach could be to extend agnostic active learning [2] results to a similar interactive optimization setting."}, {"heading": "A Additional Experiments", "text": "Table 2 shows additional experimental results using different hypothesis classes. In the first set of results, we use a hypothesis class H consisting of 100 randomly chosen geodesic balls of radius 2 (Balls). Each group h \u2208 H is formed by choosing a node uniformly at random from the graph and then finding all nodes within a shortest path distance of 2. The target group h\u2217 is then selected at random from H . With this hypothesis class, we\u2019ve found that there is very little difference between the Simultaneous Learning and Covering and the Learn then Cover methods, similar to the Clusters hypothesis class in Table 1. Learn then Cover is better on 3 of the 5 data sets, but the difference is very small (around 1 query). The Cover All method again performs significantly worse because it must find a dominating set of all 100 of the geodesic balls.\nIn the second set of results, Noisy Balls, we use a hypothesis class similar to the Noisy Clusters hypothesis class in Table 1 but using random geodesic balls. We first generate 2 core groups by sampling random geodesic balls of radius 2 as before. We then generate 50 small variations of each of these 2 core groups, each consisting of the core group with a random member removed. H is this set of 100 variations, and the target group h\u2217 is again selected at random from H . For this hypothesis class, Simultaneous Learning and Covering outperforms the other methods because it learns about h\u2217 but only to the extent that it is helpful for finding a small dominating set. Cover All actually outperforms Learn then Cover with this hypothesis class, because the total number of vertices in the union of all clusters in H is small.\nIn the third set of results denoted Expanded Clusters, we create H by partitioning the graph into 100 clusters using the METIS [11] graph partitioning package and then expand each of these clusters to include its immediate neighbors. This creates a set of 100 overlapping clusters with shared vertices on the fringes of each cluster. As before the target hypothesis is selected at random from H . We have found that results with this hypothesis class are similar to those with the Balls and Clusters hypothesis class.\nUWEETR-2010-0001 14"}], "references": [{"title": "Stochastic submodular maximization", "author": ["A. Asadpour", "H. Nazerzadeh", "A. Saberi"], "venue": "Workshop on Internet and Network Economics", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Agnostic active learning", "author": ["M. Balcan", "A. Beygelzimer", "J. Langford"], "venue": "ICML", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "A general dimension for query learning", "author": ["J. Balc\u00e1zar", "J. Castro", "D. Guijarro", "J. K\u00f6bler", "W. Lindner"], "venue": "Journal of Computer and System Sciences, 73(6):924\u2013940", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Analysis of a greedy active learning strategy", "author": ["S. Dasgupta"], "venue": "NIPS", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "A theoretical analysis of query selection for collaborative filtering", "author": ["S. Dasgupta", "W. Lee", "P. Long"], "venue": "Machine Learning, 51 (3)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Approximating the stochastic knapsack problem: The benefit of adaptivity", "author": ["B. Dean", "M. Goemans", "J. Vondrak"], "venue": "FOCS", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2004}, {"title": "A threshold of ln n for approximating set cover", "author": ["U. Feige"], "venue": "Journal of the ACM, 45(4)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1998}, {"title": "Stochastic covering and adaptivity", "author": ["M. Goemans", "J. Vondr\u00e1k"], "venue": "LATIN", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2006}, {"title": "Adaptive submodularity: A new approach to active learning and stochastic optimization", "author": ["D. Golovin", "A. Krause"], "venue": "COLT", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "The cost complexity of interactive learning", "author": ["S. Hanneke"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "A fast and highly quality multilevel scheme for partitioning irregular graphs", "author": ["G. Karypis", "V. Kumar"], "venue": "SIAM Journal on Scientific Computing", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}, {"title": "Maximizing the spread of influence through a social network", "author": ["D. Kempe", "J. Kleinberg", "E. Tardos"], "venue": "KDD", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Influential nodes in a diffusion model for social networks", "author": ["D. Kempe", "J. Kleinberg", "E. Tardos"], "venue": "ICALP", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "Robust submodular observation selection", "author": ["A. Krause", "H. McMahan", "C. Guestrin", "A. Gupta"], "venue": "JMLR", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Multi-document summarization via budgeted maximization of submodular functions", "author": ["H. Lin", "J. Bilmes"], "venue": "NAACL/HLT", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Submodular Functions and Electrical Networks", "author": ["H. Narayanan"], "venue": "North Holland", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1997}, {"title": "An online algorithm for maximizing submodular functions", "author": ["M. Streeter", "D. Golovin"], "venue": "NIPS", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "An analysis of the greedy algorithm for the submodular set covering problem", "author": ["L. Wolsey"], "venue": "Combinatorica, 2", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1982}], "referenceMentions": [{"referenceID": 12, "context": "Previous work [13, 12] has shown that, for many models of influence, the influence of a set of nodes can be modelled as a submodular set function.", "startOffset": 14, "endOffset": 22}, {"referenceID": 11, "context": "Previous work [13, 12] has shown that, for many models of influence, the influence of a set of nodes can be modelled as a submodular set function.", "startOffset": 14, "endOffset": 22}, {"referenceID": 11, "context": "A number of interesting real world applications can be posed as submodular set cover or submodular function maximization problems including influence maximization in social networks [12], sensor placement and experiment design [14], and document summarization [15].", "startOffset": 182, "endOffset": 186}, {"referenceID": 13, "context": "A number of interesting real world applications can be posed as submodular set cover or submodular function maximization problems including influence maximization in social networks [12], sensor placement and experiment design [14], and document summarization [15].", "startOffset": 227, "endOffset": 231}, {"referenceID": 14, "context": "A number of interesting real world applications can be posed as submodular set cover or submodular function maximization problems including influence maximization in social networks [12], sensor placement and experiment design [14], and document summarization [15].", "startOffset": 260, "endOffset": 264}, {"referenceID": 17, "context": "As is the case for set cover, a greedy algorithm has approximation guarantees for submodular set cover [18].", "startOffset": 103, "endOffset": 107}, {"referenceID": 6, "context": "Up to lower order terms, this matches the hardness of approximation lower bound (1\u2212 o(1)) lnn [7] where n = | \u22c3", "startOffset": 94, "endOffset": 97}, {"referenceID": 13, "context": "This variation does not add any difficulty to the problem because we can always define a new monotone non-decreasing submodular function F\u0302 (S) = min(F (S), \u03b1) [14, 16] to convert the constraint F (S) \u2265 \u03b1 into a new constraint F\u0302 (S) = F\u0302 (V ).", "startOffset": 160, "endOffset": 168}, {"referenceID": 15, "context": "This variation does not add any difficulty to the problem because we can always define a new monotone non-decreasing submodular function F\u0302 (S) = min(F (S), \u03b1) [14, 16] to convert the constraint F (S) \u2265 \u03b1 into a new constraint F\u0302 (S) = F\u0302 (V ).", "startOffset": 160, "endOffset": 168}, {"referenceID": 3, "context": "linear classifiers with dimension d) and a finite data set, we can simply use the effective hypothesis class induced by the data set [4].", "startOffset": 133, "endOffset": 136}, {"referenceID": 2, "context": "Building on previous work [3], Hanneke [10] showed that a simple greedy active learning strategy is approximately optimal in the setting we have described.", "startOffset": 26, "endOffset": 29}, {"referenceID": 9, "context": "Building on previous work [3], Hanneke [10] showed that a simple greedy active learning strategy is approximately optimal in the setting we have described.", "startOffset": 39, "endOffset": 43}, {"referenceID": 9, "context": "Hanneke [10] shows this strategy incurs no more than ln |H | times the cost of any other question asking strategy.", "startOffset": 8, "endOffset": 12}, {"referenceID": 13, "context": "[14] study a non-interactive version of interactive submodular set cover in which |q(h)| = 1 \u2200q \u2208 Q, h \u2208 H and the entire sequence of questions must be chosen before receiving any responses.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14].", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[3] study a similar approximate query learning setting, and Dasgupta et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] consider a slightly different setting where the target hypothesis may not be in H .", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "3 Connection to Adaptive Submodularity In concurrent work, Golovin and Krause [9] show results similar to ours for a different but related class of problems which also involve interactive (i.", "startOffset": 78, "endOffset": 81}, {"referenceID": 0, "context": "Some other previous work has also considered interactive versions of covering problems in an average-case model [1, 8].", "startOffset": 112, "endOffset": 118}, {"referenceID": 7, "context": "Some other previous work has also considered interactive versions of covering problems in an average-case model [1, 8].", "startOffset": 112, "endOffset": 118}, {"referenceID": 0, "context": "[1] is perhaps most similar and considers a submodular function maximization problem over independent random variables which are sequentially queried.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "The setting considered by Golovin and Krause [9] strictly generalizes this setting.", "startOffset": 45, "endOffset": 48}, {"referenceID": 16, "context": "Streeter and Golovin [17] study an online version of submodular function maximization where a sequence of submodular function maximization problems is solved.", "startOffset": 21, "endOffset": 25}, {"referenceID": 13, "context": "[14] in the non-interactive setting to convert multiple covering constraints into a single covering constraint.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Gain(F\u0302\u03b1,h, A, (q, r)) = min(Fh(A+ (q, r)), \u03b1) \u2212min(Fh(A), \u03b1) \u2265 min(Fh(B + (q, r)), \u03b1) \u2212min(Fh(B), \u03b1) = Gain(F\u0302\u03b1,h, B, (q, r)) Here we used the submodularity of min(Fh(S), \u03b1) [16].", "startOffset": 175, "endOffset": 179}, {"referenceID": 9, "context": "We use an Extended Teaching Dimension style analysis [10] inspired by previous work in query learning.", "startOffset": 53, "endOffset": 57}, {"referenceID": 9, "context": "We now define a quantity analogous to the General Identification Cost for exact active learning [10].", "startOffset": 96, "endOffset": 100}, {"referenceID": 17, "context": "We speculate that for more general noninteger objectives it should be possible to give results similar to those for standard submodular set cover [18].", "startOffset": 146, "endOffset": 150}, {"referenceID": 13, "context": "[14] for the equivalent approach in the non-interactive setting.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "The adaptivity gap [6] for a problem characterizes how much worse the best non-adaptive method can perform as compared to the best adaptive method.", "startOffset": 19, "endOffset": 22}, {"referenceID": 0, "context": "With this definition, we can show that, in contrast to related problems [1] where the adaptivity gap is a constant, the adaptivity gap for interactive submodular set cover is quite large.", "startOffset": 72, "endOffset": 75}, {"referenceID": 3, "context": "A classic example is learning a threshold on a line [4].", "startOffset": 52, "endOffset": 55}, {"referenceID": 13, "context": "The result and proof are very similar to those for the non-interactive setting [14].", "startOffset": 79, "endOffset": 83}, {"referenceID": 6, "context": "The theorem then follows from the result of Feige [7] which shows a set cover cannot be approximated within a factor of (1\u2212 \u01eb) lnn in polynomial time for any \u01eb > 0 unless NP has n logn) time deterministic algorithms.", "startOffset": 50, "endOffset": 53}, {"referenceID": 1, "context": "One approach could be to extend agnostic active learning [2] results to a similar interactive optimization setting.", "startOffset": 57, "endOffset": 60}], "year": 2010, "abstractText": "We introduce a natural generalization of submodular set cover and exact active learning with a finite hypothesis class (query learning). We call this new problem interactive submodular set cover. Applications include advertising in social networks with hidden information. We give an approximation guarantee for a novel greedy algorithm and give a hardness of approximation result which matches up to constant factors. We also discuss negative results for simpler approaches and present encouraging early experimental results.", "creator": "dvips(k) 5.98 Copyright 2009 Radical Eye Software"}}}