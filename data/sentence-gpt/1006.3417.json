{"id": "1006.3417", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2010", "title": "Fictitious Play with Time-Invariant Frequency Update for Network Security", "abstract": "We study two-player security games which can be viewed as sequences of nonzero-sum matrix games played by an Attacker and a Defender. The evolution of the game is based on a stochastic fictitious play process, where players do not have access to each other's payoff matrix. Each has to observe the other's actions up to present and plays the action generated based on the best response to these observations. Each player chooses between the two strategies and chooses a player's position based on the best performance of the two strategies (and a player's actions) while also playing as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as the player who most plays as", "histories": [["v1", "Thu, 17 Jun 2010 10:13:22 GMT  (109kb)", "http://arxiv.org/abs/1006.3417v1", "Proceedings of the 2010 IEEE Multi-Conference on Systems and Control (MSC10), September 2010, Yokohama, Japan"]], "COMMENTS": "Proceedings of the 2010 IEEE Multi-Conference on Systems and Control (MSC10), September 2010, Yokohama, Japan", "reviews": [], "SUBJECTS": "cs.GT cs.CR cs.LG", "authors": ["kien c nguyen", "tansu alpcan", "tamer ba\\c{s}ar"], "accepted": false, "id": "1006.3417"}, "pdf": {"name": "1006.3417.pdf", "metadata": {"source": "CRF", "title": "Fictitious Play with Time-Invariant Frequency Update for Network Security", "authors": ["Kien C. Nguyen", "Tansu Alpcan"], "emails": ["basar1@illinois.edu,", "knguyen4@illinois.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n00 6.\n34 17\nv1 [\ncs .G\nT ]\n1 7\nJu n\n20 10\nI. INTRODUCTION\nGame theory has recently been used as an effective tool to model and solve many security problems in computer and communication networks. In a noncooperative matrix game between an Attacker and a Defender, if the payoff matrices are assumed to be known to both players, each player can compute the set of Nash equilibria of the game and play one of these strategies to maximize her expected gain (or minimize its expected loss). However, in practice, the players do not necessarily have full knowledge of each other\u2019s payoff matrix. For repeated games, a mechanism called fictitious play (FP) can be used for each player to learn her opponent\u2019s motivations. In a FP process, each player observes all the actions and makes estimates of the mixed strategy of her opponent. At each stage, she updates this estimate and plays the pure strategy that is the best response (or generated based on the best response) to the current estimate of the other\u2019s mixed strategy. It can be seen that in a FP process, if one player plays a fixed strategy (either of the pure or mixed type), the other player\u2019s sequence of strategies will converge to the best response to this fixed strategy. Furthermore, it has been shown that, for many classes of games, such a FP process will finally render both players playing a Nash equilibrium (NE).\nThis research was supported by grants from the Deutsche Telekom Laboratories (Berlin, Germany) and the Boeing Company.\nTamer Bas\u0327ar and Kien C. Nguyen are with the Department of Electrical and Computer Engineering and the Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, 1308 W Main St., Urbana, IL 61801, USA basar1@illinois.edu, knguyen4@illinois.edu\nTansu Alpcan is with the Deutsche Telekom Laboratories and the Technical University of Berlin, Ernst-Reuter-Platz 7, D-10587 Berlin, Germany tansu.alpcan@telekom.de\nSpecifically, we examine a two-player game, where an Attacker (denoted as player 1 or P1) and a Defender (denoted as player 2 or P2) participate in a discrete-time repeated nonzero-sum matrix game. In a general setting, the Attacker has m possible actions and the Defender has n posssible actions to choose from. For example, when m = n = 2, the Attacker\u2019s actions could be to attack one node in a two-node network, and those of the Defender are to defend one of these two nodes. Players do not have access to each other\u2019s payoff function. They adjust their strategies based on each other\u2019s actions which they observe.\nIn a stochastic FP process, each player makes a maximum likelihood estimation of her opponent\u2019s mixed strategy. As will be seen later on, this will result in a time-varying update of the opponent\u2019s empirical frequency, where the weight of the action at time step k is 1/k. In a practical repeated security game, however, we notice a couple of possible complications. First, players may not have the exact and synchronized time steps. Second, each player may want to adjust the weight of the other\u2019s current action to converge either faster or more accurately to the equilibrium. A more flexible scheme to update the estimate of the mixed strategy may be needed in such situations. Motivated by these practical considerations, we examine in this paper a time-invariant frequency update mechanism for fictitious play. Also, as a side note, such a time-invariant update mechanism will allow us to use the analysis tools applicable only to time-invariant systems.\nSecurity games have been examined extensively in a large number of papers, see for example, [1], [2], [3], [7], [18], [14]. Surveys on applications of game theory to network security can be found in [6], [17]. Relevant literature on fictitious play can be found in [16], [12], [5], [19], [20], [11], [13], [15]. A comprehensive exposition of learning in games can be found in [8].\nThe rest of this paper is organized as follows. In Section II, we provide an overview of the static game and the standard stochastic FP process, and then introduce the stochastic FP with time-invariant frequency update. The analysis for FP with time-invariant frequency update is given in Section III. In Section IV, we introduce an adaptive algorithm based on the time-invariant FP process. Next, simulation results are given in Section V. Finally, some concluding remarks will end the paper."}, {"heading": "II. FICTITIOUS PLAY WITH TIME-INVARIANT FREQUENCY UPDATE", "text": "In this Section, we present first an overview of a twoplayer static games, then the concept of Stochastic Fictitious Play with Time-Varying Frequency Update (TVFU-FP) [19], [20], [13], [15], and finally the concept of Stochastic Fictitious Play with Time-Invariant Frequency Update (TIFU-FP). While we introduce both classical version and stochastic version of static games, we restrict ourseves to only stochastic fictitious play in Subsections II-B and II-C and in the rest of the paper."}, {"heading": "A. Static Games", "text": "We consider here static security games, where each player Pi, i = 1, 2, has two possible actions (or pure strategies). We use vi, to denote the action of Pi. Let \u2206(2) be the simplex in \u211c2, i.e.,\n\u2206(2) \u2261 { s \u2208 \u211c2|s1, s2 \u2265 0 and s1 + s2 = 1 } . (1)\nEach vi takes value in the set of (two) vertices of \u2206(2): vi = [1 0]\nT for the first action, and vi = [0 1]T for the second action. In a static game, player Pi selects an action vi according to a mixed strategy pi \u2208 \u2206(2). The (instant) payoff for player Pi is1 vTi Miv\u2212i + \u03c4iH(pi), where Mi is the payoff matrix of Pi, and H(pi) is the entropy of the probability vector pi, H(pi) = \u2212pTi log(pi). The weighted entropy \u03c4iH(pi) with \u03c4i \u2265 0 is introduced to boost mixed strategies. In a security game, \u03c4i signifies how much player i wants to randomize its actions, and thus is not necessarily known to the other player. Also, for \u03c41 = \u03c42 = 0 (referred to as classical FP), the best response mapping can be setvalued, while it has a unique value when \u03c4i > 0 (referred to as stochastic FP). For a pair of mixed strategy (p1, p2), the utility functions are given by the expected payoffs:\nUi(pi, p\u2212i) = E [ vTi Miv\u2212i ] + \u03c4iH(pi)\n= pTi Mip\u2212i + \u03c4iH(pi). (2)\nNow, the best response mappings \u03b2i : \u2206(2) \u2192 \u2206(2) are defined as:\n\u03b2i(p\u2212i) = arg max pi\u2208\u2206(2) Ui(pi, p\u2212i). (3)\nIf \u03c4i > 0, the best response is unique as mentioned earlier, and is given by:\n\u03b2i(p\u2212i) = \u03c3\n(\nMip\u2212i \u03c4i\n)\n, (4)\nwhere the soft-max function \u03c3 : \u211c2 \u2192 Interior(\u2206(2)) is defined as\n(\u03c3(x))j = exj\nex1 + ex2 , j = 1, 2. (5)\nNote that (\u03c3(x))j > 0, and thus the range of the soft-max function is just the interior of the simplex.\n1As standard in the game theory literature, the index \u2212i is used to indicate those of other players, or the opponent in this case.\nFinally, a (mixed strategy) Nash equilibrium is defined to be a pair (p\u03041, p\u03042) \u2208 \u2206(2)\u00d7\u2206(2) such that for all pi \u2208 \u2206(2)\nUi(pi, p\u0304\u2212i) \u2264 Ui(p\u0304i, p\u0304\u2212i). (6)\nWe can also write a Nash equilibrium (p\u03041, p\u03042) as the fixed point of the best response mappings:\np\u0304i = \u03b2i(p\u0304\u2212i), i = 1, 2. (7)"}, {"heading": "B. Stochastic Fictitious Play with Time-Varying Frequency Update", "text": "From the static game described in Subsection II-A, we define the discrete-time TVFU-FP as follows. Suppose that the game is repeated at times k \u2208 {0, 1, 2, . . .}. The empirical frequency qi(k) of player Pi is given by\nqi(k + 1) = 1\nk + 1\nk \u2211\nj=0\nvi(j). (8)\nUsing induction, we can prove the following recursive relation:\nqi(k + 1) = k\nk + 1 qi(k) +\n1\nk + 1 vi(k). (9)\nFrom the equations of discrete-time TVFU-FP (8), (9), the continuous-time version of the iteration can be written down as follows [13]:\np\u0307i(t) = \u03b2i(p\u2212i(t))\u2212 pi(t), i = 1, 2. (10)"}, {"heading": "C. Stochastic Fictitious Play with Time-Invariant Frequency Update", "text": "In TVFU-FP, players take the maximum likelihood estimate of the mixed strategy of their opponent (8), (9). In TIFU-FP, the estimates of the mixed strategies will be calculated in a time-invariant manner as follows:\nri(1) = vi(0), (11)\nri(k + 1) = (1 \u2212 \u03b7)ri(k) + \u03b7vi(k), (12)\nwhere \u03b7 is a constant and 0 < \u03b7 < 1. For each player, this is basically the exponential smoothing formula used in time series analysis (See for example [9]). We will prove that with this formulation, at time k, ri(k) will be a weighted average of all the actions up to present of player i where more recent actions have higher weights. Suppose that the payoff matrices of player 1 and player 2 are, respectively,\nM1 =\n(\na b c d\n)\n, M2 =\n(\ne g f h\n)\n. (13)\nAssumption 1: Based on a realistic security game, we can make the following assumptions:\n\u2022 a < c: When the Defender defends, the payoff of the Attacker will be decreased if it attacks. \u2022 b > d: When the Defender does not defend, the payoff of the Attacker will be increased if it attacks. \u2022 e > f : When the Attacker attacks, the payoff of the Defender will be decreased if it does not defend. \u2022 g < h: When the Attacker does not attack, the payoff of the Defender will be increased if it does not defend.\n1: Given payoff matrix Mi, coefficient \u03c4i > 0, i = 1, 2. 2: for k \u2208 {0, 1, 2, . . .} do 3: Update the estimated frequency of the opponent using (11), (12). 4: Compute the best response using (4). (Note that the result is always a completely mixed strategy.) 5: Randomly play an action vi(k) according to the best response mixed strategy \u03b2i(r\u2212i(k)). 6: end for\nAlgorithm 1: Fictitious Play with Time-Invariant Frequency Update.\nIn TIFU-FP, both players employ Algorithm 1. The mean dynamic of the evolution of TIFU-FP can be written as:\nri(k + 1) = (1\u2212 \u03b7)ri(k) + \u03b7\u03b2i(r\u2212i(k)), i = 1, 2. (14)\nNote that Equations (14) are just evolution of the estimated frequencies; the empirical frequencies still evolve in a timevarying manner:\nqi(k + 1) = k\nk + 1 qi(k) +\n1\nk + 1 vi(k), i = 1, 2. (15)\nThe mean dynamic of empirical frequencies then can be written as\nqi(k + 1) = k\nk + 1 qi(k) +\n1\nk + 1 \u03b2i(r\u2212i(k)), i = 1, 2. (16)"}, {"heading": "III. ANALYSIS", "text": ""}, {"heading": "A. Nash Equilibrium of the Static Game", "text": "We start the analysis with the following result for the static games given in Subsection II-A.\nProposition 1: The static 2-player 2-action game in II-A with Assumption 1 and \u03c41, \u03c42 > 0 admits a unique Nash equilibrium.\nProof: In what follows, let r1 \u2261 (r11 , r 2 1) T , r2 \u2261 (r12 , r 2 2) T , \u03b21(r2) \u2261 (\u03b211(r2), \u03b2 2 1(r2))\nT , and \u03b22(r2) \u2261 (\u03b212(r2), \u03b2 2 2(r2))\nT . We first use the Brouwer fixed point theorem (see for example [4]) to prove the existence of a Nash equilibrium, then use monotonicity of \u03b211(r 1 2) and \u03b212(r 1 1) to prove that the fixed point is unique. Here we write\n\u03b211(r 1 2) as a scalar-valued function of the only independent variable r12 using the fact that r2 \u2208 \u2206(2), or r 1 2 + r 2 2 = 1. Function \u03b212(r 1 1) is defined similarly. Also, as r1, r2 \u2208 \u2206(2), a pair (r11 , r 1 2) completely specifies the estimated frequencies of the players. As seen from Equation (7), a Nash equilibrium (r\u03041, r\u03042) is a fixed point of the best response mapping:\nri = \u03b2i(r\u2212i), i = 1, 2.\nIt suffices to write this mapping as r = \u03b2(r), where r = (r11 , r 1 2) T . Specifically, the mapping \u03b2 can be detailed as:\nr11 = \u03b2 1 1(r 1 2) =\n(\n\u03c3\n(\nM1r2 \u03c41\n))\n1\n= e\n{\n1 \u03c41 [ar1 2 +b(1\u2212r1\n2 )] }\ne\n{\n1 \u03c41 [ar1 2 +b(1\u2212r1\n2 )] }\n+ e\n{\n1 \u03c41 [cr1 2 +d(1\u2212r1\n2 )] } .\nIt can be seen that \u03b211(r 1 2) \u2208 (0, 1). Similarly, we have\nr12 = \u03b2 1 2(r 1 1) \u2208 (0, 1).\nThus \u03b2 is a transformation from [0, 1]2 to [0, 1]2, which is a compact convex set. As both mappings \u03b211 and \u03b2 1 2 that constitute \u03b2 are continuous, \u03b2 is also a continuous transformation. Using the Brouwer fixed point theorem, there exists at least one fixed point r\u0304 such that r\u0304 = \u03b2(r\u0304), which is a Nash equilibrium of the static game. Now we examine the derivatives of \u03b211(r 1 2) and \u03b2 1 2(r 1 1) with respect to their own independent variables:\nd\u03b211(r2)\ndr12 =\n1 \u03c41 [(a\u2212 c) + (d\u2212 b)]\u03b211(r2)\u03b2 2 1(r2),\nd\u03b212(r1)\ndr11 =\n1 \u03c42 [(e\u2212 f) + (h\u2212 g)]\u03b221(r1)\u03b2 2 2(r1).\nFrom Assumption 1, (a \u2212 c) + (d \u2212 b) < 0 and (e \u2212 f) + (h \u2212 g) > 0. Thus \u03b211(r 1 2) is strictly decreasing in r12 , and \u03b2 1 2(r 1 1) is strictly increasing in r 1 1 . Now suppose that there exist two distinct Nash equilibria, (r\u20321, r \u2032 2) and (r \u2032\u2032 1 , r \u2032\u2032\n2 ). Obviously, r\u20321 6= r \u2032\u2032 1 , otherwise we will have r \u2032 2 = r \u2032\u2032\n2 , and these two points coincide. Without loss of generality, assume that r\u20321 < r \u2032\u2032 1 . As \u03b2 1 2(r 1 1) is strictly increasing in r 1 1 , we have that r\u20322 < r \u2032\u2032 2 . However, \u03b2 1 1(r 1 2) is strictly decreasing in r 1 2 , so r\u20321 > r \u2032\u2032\n1 , which is contradictory to the initial assumption. Thus the Nash equilibrium is unique. We illustrate in Figure 1 the curves \u03b211(r 1 2) and \u03b2 1 2(r 1 1) with the values of M1, M2, \u03c41, and \u03c42 as shown. The intersection of these two curves is the Nash equilibrium of the static game."}, {"heading": "B. Estimated Frequencies and Empirical Frequencies", "text": "We present here two propositions for TIFU-FP: The first shows the weights of each player\u2019s actions in the estimated frequency, and the second shows the relationship between estimated frequencies and empirical frequencies.\nProposition 2: For k \u2265 2, the estimated frequencies in TIFU-FP constructed using (11), (12) will satisfy\nri(k) = (1 \u2212 \u03b7) k\u22121vi(0) + (1 \u2212 \u03b7) k\u22122\u03b7vi(1)\n+(1\u2212 \u03b7)k\u22123\u03b7vi(2) + . . .+ (1\u2212 \u03b7)\u03b7vi(k \u2212 2)\n+\u03b7vi(k \u2212 1), (17)\nwhere i = 1, 2. Proof: This result can be proved using induction.\nProposition 3: In TIFU-FP, the empirical frequencies are related to the estimated frequencies calculated using (11), (12) through the following equation:\nqi(k + 1) = 1\nk + 1\n(\n2\u03b7 \u2212 1\n\u03b7 ri(1) + ri(2) + . . .+ ri(k)\n+ ri(k + 1)\n\u03b7\n)\n, i = 1, 2. (18)\nProof: This result can be proved by writing the actions of player Pi at times 0, 1, . . . , k in terms of the estimated frequencies at times 1, 2, . . . , (k + 1).\nC. Convergence Properties of the Mean Dynamic in TIFUFP\nTheorem 1: Consider a TIFU-FP with Assumption 1 and \u03c41, \u03c42 > 0. The mean dynamic given in Equations (14) is asymptotically stable if and only if\n\u03b7 < 2\n[(c\u2212a)+(b\u2212d)][(e\u2212f)+(h\u2212g)] \u03c41\u03c42 r\u030411 r\u0304 2 1 r\u0304 2 1 r\u0304 2 2 + 1\n. (19)\nProof: As can be seen in Equations (14), this is a deterministic nonlinear discrete-time time-invariant system. We linearize the system at the fixed point and examine stability properties of the linearized system using techniques described in standard textbooks for nonlinear systems (e.g., [10]). Using the mean dynamic (14), where\nr1(k) =\n(\nr11(k) r21(k)\n)\n, r2(k) =\n(\nr12(k) r22(k)\n)\n, (20)\nit can be seen that a pair (r\u03041, r\u03042) that satisfies r\u0304i = \u03b2i(r\u0304\u2212i), i = 1, 2, is a fixed point of the system. Consider the Jacobian matrix\nJ = \u2202F (r)\n\u2202r =\n(\n\u2202F1(r) \u2202r1\n1\n\u2202F1(r) \u2202r1\n2\n\u2202F2(r) \u2202r1\n1\n\u2202F2(r) \u2202r1\n2\n)\n.\nWe have that\n\u2202F1(r)\n\u2202r11 =\n\u2202F2(r)\n\u2202r12 = 1\u2212 \u03b7,\n\u2202F1(r)\n\u2202r12 = \u03b7\nd\u03b211(r2)\ndr12 .\nRecall that \u03b21(r2) = \u03c3 (\nM1r2 \u03c41\n)\n, where\nM1r2 \u03c41 =\n( 1 \u03c41 [ar12 + b(1\u2212 r 1 2)]\n1 \u03c41 [cr12 + d(1\u2212 r 1 2)]\n)\n.\nThus\n\u03b211(r2) = e\n{\n1 \u03c41 [ar1 2 +b(1\u2212r1\n2 )] }\ne\n{\n1 \u03c41 [ar1 2 +b(1\u2212r1\n2 )] }\n+ e\n{\n1 \u03c41 [cr1 2 +d(1\u2212r1\n2 )] } .\nThen\nd\u03b211(r2)\ndr12 =\n1 \u03c41 [(a\u2212 c) + (d\u2212 b)]\u03b211(r2)\u03b2 2 1(r2),\n\u2202F1(r)\n\u2202r12 =\n\u03b7 \u03c41 [(a\u2212 c) + (d\u2212 b)]\u03b211(r2)\u03b2 2 1(r2).\nAt the fixed point (r\u03041, r\u03042), we can write\n\u2202F1(r\u0304)\n\u2202r12 =\n\u03b7 \u03c41 [(a\u2212 c) + (d\u2212 b)]r\u030411 r\u0304 2 1 .\nSimilarly,\n\u2202F2(r\u0304)\n\u2202r11 =\n\u03b7 \u03c42 [(e \u2212 f) + (h\u2212 g)]r\u030412 r\u0304 2 2 .\nUsing the conditions for local stability, |\u00b51,2| \u2264 1, where \u00b51,2 are eigenvalues of the Jacobian matrix, we finally have the condition in Equation (19).\nRemark 1: Although this theorem only mentions the asymptotic stability of the estimated frequencies (of the mean dynamic), once these estimated frequencies converge to the Nash equilibrium, the best responses will also converge to the Nash equilibrium, and so will the empirical frequencies in the long run."}, {"heading": "IV. ADAPTIVE FICTITIOUS PLAY", "text": "In this section we examine an adaptive FP algorithm (hereafter referred to as AFP) based on FP with TimeInvariant Frequency Update, where the step size \u03b7 is piecewise constant and decreased over time. For the specific implementation shown in Algorithm 2, the step size is either kept fixed or halved, based on the variance of empirical frequency in the previous time window."}, {"heading": "V. SIMULATION RESULTS", "text": "We present in this section some simulation results for TIFU-FP and AFP where the payoff matrices and entropy coefficients are chosen to be\nM1 =\n(\n1 5 3 2\n)\n, M2 =\n(\n4 1 3 5\n)\n, \u03c41 = 0.5, \u03c42 = 0.3.\nThe Nash Equilibrium of the static game is (0.79, 0.21) and (0.47, 0.53). The local stability threshold (the RHS of Equation (19)) is \u03b70 = 0.2536. For simplicity, in the graphs shown here, we only plot the first component of each frequency vector."}, {"heading": "A. Fictitious Play with Time Invariant Frequency Update", "text": "Some simulation results for the mean dynamic of TIFUFP (Equations (14)) are given in Figures 2 and 3. When \u03b7 = 0.25 < \u03b70 = 0.2536, the estimated frequencies are shown in Figure 2. The simulation results show that both estimated frequencies and empirical frequencies (not presented here due to space limitations) converge to the NE as expected. When \u03b7 = 0.26 > \u03b70, however, the estimated frequencies do not converge anymore. These simulations thus confirm the theoretical result in Theorem 1. It is also worth noting that the empirical frequencies in the case \u03b7 = 0.26 still converge to the NE. Unlike the mean dynamic, a stochastic TIFU-FP process (generated with Algorithm 1) exhibits significant random fluctuations. The graph in Figure 4 shows the estimated frequencies of such a process where we choose \u03b7 = 0.01. However, the empirical frequencies\n1: Given payoff matrix Mi, coefficient \u03c4i, i = 1, 2, initial step size \u03b70, minimum step size \u03b7min, and window size T . 2: for k \u2208 {0, 1, 2, . . .} do 3: Update the estimated frequency of the opponent, r\u2212i, using (11), (12). 4: Compute the best response mixed strategy \u03b2i(r\u2212i(k)) using (4). 5: Randomly play an action ai(k) according to the best\nresponse mixed strategy \u03b2i(r\u2212i(k)), such that the expectation E [ai(k)] = \u03b2i(r\u2212i(k)).\n6: if at the end of a time window, mod (k, T ) = 0, then 7: Compute the standard deviation of the estimated frequencies (stdef) in the time window [r\u2212i(k \u2212 T + 1), . . . , r\u2212i(k)] (using an unbiased estimator):\nmef(k) = 1\nT\nk \u2211\nh=k\u2212T+1\nr\u2212i(h)\nstdef(k) =\n\u221a\n\u2211k h=k\u2212T+1 (r\u2212i(h)\u2212mef(k)) 2\n(T \u2212 1)\n8: if the computed stdef(k) has decreased compared to previous time window then 9: Decrease step size: \u03b7 = 0.5 \u03b7 and \u03b7 = max(\u03b7, \u03b7min).\n10: else 11: Keep step size \u03b7 constant. 12: end if 13: end if 14: end for\nAlgorithm 2: Adaptive Fictitious Play\n(whose graph is not shown here due to space limitations) still converge to the NE ."}, {"heading": "B. Adaptive Fictitious Play", "text": "Some simulation results for adaptive FP are shown in Figures 6 and 7. The payoff matrices and entropy coefficients are the same as those in V-A. Initial and minimum step sizes are chosen to be \u03b70 = 0.1 and \u03b7min = 0.0005, respectively. The time window for updating the step size is T = 50 steps. The evolution of the empirical frequencies are depicted in Figure 6, which shows that adaptive FP converges faster than the stochastic FP with time-varying frequency update (TVFU-FP) (Figure 5). We however remark that it is possible to incorporate a decreasing coefficient into the step size in TVFU-FP (which is originally 1/k) to make the TVFU-FP process converge faster [11]. The update of the step size in adaptive FP is shown in Figure 7. Note that when compared to the step size 1/k in TVFU-FP, the step sizes in adaptive FP are higher in the beginning and smaller afterwards, resulting in aggressive convergence first and less fluctuation in the stable phase."}, {"heading": "VI. CONCLUSIONS", "text": "In this paper, we have introduced a time-invariant scheme to estimate the frequency of the opponent\u2019s actions in a twoplayer two-action fictitious play process. We have proved local stability of the unique Nash equilibrium for the mean version of this FP dynamic. This frequency update scheme, when used adaptively, allows players to converge faster to the Nash equilibrium. For this two-player two-action FP, conditions for global stability, if they exist, are yet to be found. Also, having more than two possible actions for each player is an intriguing research extension."}], "references": [{"title": "A game theoretic approach to decision and analysis in network intrusion detection", "author": ["T. Alpcan", "T. Ba\u015far"], "venue": "In Proc. of the 42nd IEEE Conference on Decision and Control,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "A game theoretic analysis of intrusion detection in access control systems", "author": ["T. Alpcan", "T. Ba\u015far"], "venue": "In Proc. of the 43rd IEEE Conference on Decision and Control,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "An intrusion detection game with limited observations", "author": ["T. Alpcan", "T. Ba\u015far"], "venue": "In 12th Int. Symp. on Dynamic Games and Applications, Sophia Antipolis,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Dynamic Noncooperative Game Theory", "author": ["T. Ba\u015far", "G.J. Olsder"], "venue": "Society for Industrial and Applied Mathematics, Philadelphia,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1999}, {"title": "Fictitious play in 2xn games. Game theory and information, EconWPA", "author": ["U. Berger"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Security and Cooperation in Wireless Networks", "author": ["L. Buttyan", "J.-P. Hubaux"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "On Selfish and Malicious Behaviors in Wireless Networks - A Non-cooperative Game Theoretic Approach", "author": ["L. Chen"], "venue": "PhD thesis, Telecom ParisTech,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "The Theory of Learning in Games", "author": ["D. Fudenberg", "D.K. Levine"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "Statistics for Management and Economics", "author": ["G. Keller", "B. Warrack"], "venue": "Duxbury, California,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2000}, {"title": "Nonlinear systems. Prentice-Hall", "author": ["H.K. Khalil"], "venue": "Upper Saddle River, NJ,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Online calibrated forecasts: Efficiency vs universality for learning in games", "author": ["S. Mannor", "J.S. Shamma", "G. Arslan"], "venue": "Machine Learning - Special Issue on Learning and Computational Game Theory,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "On the convergence of learning processes in a 2 \u00d7 2 nonzero-sum two person", "author": ["K. Miyasawa"], "venue": "game. Econometrics Research Program,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1961}, {"title": "Security games with incomplete information", "author": ["K.C. Nguyen", "T. Alpcan", "T. Ba\u015far"], "venue": "In Proc. of IEEE Intl. Conf. on Communications (ICC", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Stochastic games for security in networks with interdependent nodes", "author": ["K.C. Nguyen", "T. Alpcan", "T. Ba\u015far"], "venue": "In Proc. of Intl. Conf. on Game Theory for Networks (GameNets", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Security games with decision and observation errors", "author": ["K.C. Nguyen", "T. Alpcan", "T. Ba\u015far"], "venue": "In Proc. of 2010 American Control Conference \u2013 ACC2010,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "An iterative method of solving a game", "author": ["J. Robinson"], "venue": "Ann. Math.,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1951}, {"title": "A survey of game theory as applied to network security", "author": ["S. Roy", "C. Ellis", "S. Shiva", "D. Dasgupta", "V. Shandilya", "Q. Wu"], "venue": "Technical report, University of Memphis,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Stochastic Models for Combined Security and Dependability Evaluation", "author": ["K. Sallhammar"], "venue": "PhD thesis, Norwegian University of Science and Technology,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Unified convergence proofs of continuous-time fictitious play", "author": ["J.S. Shamma", "G. Arslan"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "Dynamic fictitious play, dynamic gradient play, and distributed convergence to nash equilibria", "author": ["J.S. Shamma", "G. Arslan"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "Security games have been examined extensively in a large number of papers, see for example, [1], [2], [3], [7], [18], [14].", "startOffset": 92, "endOffset": 95}, {"referenceID": 1, "context": "Security games have been examined extensively in a large number of papers, see for example, [1], [2], [3], [7], [18], [14].", "startOffset": 97, "endOffset": 100}, {"referenceID": 2, "context": "Security games have been examined extensively in a large number of papers, see for example, [1], [2], [3], [7], [18], [14].", "startOffset": 102, "endOffset": 105}, {"referenceID": 6, "context": "Security games have been examined extensively in a large number of papers, see for example, [1], [2], [3], [7], [18], [14].", "startOffset": 107, "endOffset": 110}, {"referenceID": 17, "context": "Security games have been examined extensively in a large number of papers, see for example, [1], [2], [3], [7], [18], [14].", "startOffset": 112, "endOffset": 116}, {"referenceID": 13, "context": "Security games have been examined extensively in a large number of papers, see for example, [1], [2], [3], [7], [18], [14].", "startOffset": 118, "endOffset": 122}, {"referenceID": 5, "context": "Surveys on applications of game theory to network security can be found in [6], [17].", "startOffset": 75, "endOffset": 78}, {"referenceID": 16, "context": "Surveys on applications of game theory to network security can be found in [6], [17].", "startOffset": 80, "endOffset": 84}, {"referenceID": 15, "context": "Relevant literature on fictitious play can be found in [16], [12], [5], [19], [20], [11], [13], [15].", "startOffset": 55, "endOffset": 59}, {"referenceID": 11, "context": "Relevant literature on fictitious play can be found in [16], [12], [5], [19], [20], [11], [13], [15].", "startOffset": 61, "endOffset": 65}, {"referenceID": 4, "context": "Relevant literature on fictitious play can be found in [16], [12], [5], [19], [20], [11], [13], [15].", "startOffset": 67, "endOffset": 70}, {"referenceID": 18, "context": "Relevant literature on fictitious play can be found in [16], [12], [5], [19], [20], [11], [13], [15].", "startOffset": 72, "endOffset": 76}, {"referenceID": 19, "context": "Relevant literature on fictitious play can be found in [16], [12], [5], [19], [20], [11], [13], [15].", "startOffset": 78, "endOffset": 82}, {"referenceID": 10, "context": "Relevant literature on fictitious play can be found in [16], [12], [5], [19], [20], [11], [13], [15].", "startOffset": 84, "endOffset": 88}, {"referenceID": 12, "context": "Relevant literature on fictitious play can be found in [16], [12], [5], [19], [20], [11], [13], [15].", "startOffset": 90, "endOffset": 94}, {"referenceID": 14, "context": "Relevant literature on fictitious play can be found in [16], [12], [5], [19], [20], [11], [13], [15].", "startOffset": 96, "endOffset": 100}, {"referenceID": 7, "context": "A comprehensive exposition of learning in games can be found in [8].", "startOffset": 64, "endOffset": 67}, {"referenceID": 18, "context": "FICTITIOUS PLAY WITH TIME-INVARIANT FREQUENCY UPDATE In this Section, we present first an overview of a twoplayer static games, then the concept of Stochastic Fictitious Play with Time-Varying Frequency Update (TVFU-FP) [19], [20], [13], [15], and finally the concept of Stochastic Fictitious Play with Time-Invariant Frequency Update (TIFU-FP).", "startOffset": 220, "endOffset": 224}, {"referenceID": 19, "context": "FICTITIOUS PLAY WITH TIME-INVARIANT FREQUENCY UPDATE In this Section, we present first an overview of a twoplayer static games, then the concept of Stochastic Fictitious Play with Time-Varying Frequency Update (TVFU-FP) [19], [20], [13], [15], and finally the concept of Stochastic Fictitious Play with Time-Invariant Frequency Update (TIFU-FP).", "startOffset": 226, "endOffset": 230}, {"referenceID": 12, "context": "FICTITIOUS PLAY WITH TIME-INVARIANT FREQUENCY UPDATE In this Section, we present first an overview of a twoplayer static games, then the concept of Stochastic Fictitious Play with Time-Varying Frequency Update (TVFU-FP) [19], [20], [13], [15], and finally the concept of Stochastic Fictitious Play with Time-Invariant Frequency Update (TIFU-FP).", "startOffset": 232, "endOffset": 236}, {"referenceID": 14, "context": "FICTITIOUS PLAY WITH TIME-INVARIANT FREQUENCY UPDATE In this Section, we present first an overview of a twoplayer static games, then the concept of Stochastic Fictitious Play with Time-Varying Frequency Update (TVFU-FP) [19], [20], [13], [15], and finally the concept of Stochastic Fictitious Play with Time-Invariant Frequency Update (TIFU-FP).", "startOffset": 238, "endOffset": 242}, {"referenceID": 0, "context": "Each vi takes value in the set of (two) vertices of \u2206(2): vi = [1 0] T for the first action, and vi = [0 1] for the second action.", "startOffset": 63, "endOffset": 68}, {"referenceID": 0, "context": "Each vi takes value in the set of (two) vertices of \u2206(2): vi = [1 0] T for the first action, and vi = [0 1] for the second action.", "startOffset": 102, "endOffset": 107}, {"referenceID": 12, "context": "From the equations of discrete-time TVFU-FP (8), (9), the continuous-time version of the iteration can be written down as follows [13]:", "startOffset": 130, "endOffset": 134}, {"referenceID": 8, "context": "For each player, this is basically the exponential smoothing formula used in time series analysis (See for example [9]).", "startOffset": 115, "endOffset": 118}, {"referenceID": 3, "context": "We first use the Brouwer fixed point theorem (see for example [4]) to prove the existence of a Nash equilibrium, then use monotonicity of \u03b2 1(r 1 2) and \u03b2 2(r 1 1) to prove that the fixed point is unique.", "startOffset": 62, "endOffset": 65}, {"referenceID": 0, "context": "Thus \u03b2 is a transformation from [0, 1] to [0, 1], which is a compact convex set.", "startOffset": 32, "endOffset": 38}, {"referenceID": 0, "context": "Thus \u03b2 is a transformation from [0, 1] to [0, 1], which is a compact convex set.", "startOffset": 42, "endOffset": 48}, {"referenceID": 9, "context": ", [10]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 10, "context": "We however remark that it is possible to incorporate a decreasing coefficient into the step size in TVFU-FP (which is originally 1/k) to make the TVFU-FP process converge faster [11].", "startOffset": 178, "endOffset": 182}], "year": 2010, "abstractText": "We study two-player security games which can be viewed as sequences of nonzero-sum matrix games played by an Attacker and a Defender. The evolution of the game is based on a stochastic fictitious play process, where players do not have access to each other\u2019s payoff matrix. Each has to observe the other\u2019s actions up to present and plays the action generated based on the best response to these observations. In a regular fictitious play process, each player makes a maximum likelihood estimate of her opponent\u2019s mixed strategy, which results in a time-varying update based on the previous estimate and current action. In this paper, we explore an alternative scheme for frequency update, whose mean dynamic is instead time-invariant. We examine convergence properties of the mean dynamic of the fictitious play process with such an update scheme, and establish local stability of the equilibrium point when both players are restricted to two actions. We also propose an adaptive algorithm based on this time-invariant frequency update.", "creator": "LaTeX with hyperref package"}}}