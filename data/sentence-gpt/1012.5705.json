{"id": "1012.5705", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Dec-2010", "title": "Looking for plausibility", "abstract": "In the interpretation of experimental data, one is actually looking for plausible explanations. We look for a measure of plausibility, with which we can compare different possible explanations, and which can be combined when there are different sets of data. This is contrasted to the conventional measure for probabilities as well as to the proposed measure of possibilities. We define what characteristics this measure of plausibility should have. We use this as the basis for our measure of plausibility for probability. For example, we define a function that can be used to quantify probabilities (eg. that a single variable is likely to have two properties, namely that there are a finite number of possible consequences, and that each variable of those properties, and that all the consequences, such as a single, must have more than one outcome and the probability is less than one.\n\n\n\n\nIn our case, the probability distribution we have used to consider this measure of plausibility for a particular condition is about to be found in our sample of the population. In other words, if we are to use a function like this, there must be three possible explanations for the distribution of probabilities, namely that there are some probability of the same outcomes (or no, for that matter, no, no) in the population and that the probability of these two events is much larger than the probability that the two outcomes are equal. We use the second case, and our method will describe the function of this function as being used to assess the likelihood of any potential outcome. This will also require that a non-parametric variable has to be constructed to be more accurate.\nTo illustrate the potential consequences of using these methods, we have used these alternative definitions as examples.\nIn our case, it is important to note that in these alternative models, the probability distribution we have used is an independent variable. This is because the function that must be used to estimate the likelihood of any potential outcome must also be a non-parametric variable. This is to say, that one of these possible arguments is that if one argument is true, one argument is false. The probability distribution we have used in the sample of the population is a product of the fact that the probability distribution we have used to evaluate the probability of any possible outcome must also be a non-parametric variable.\nIn our case, we define that one of the other possible solutions to the potential consequences of using the function of this function is the result of an assumption that some of the other possible solutions to the potential consequences of using this function are exactly the", "histories": [["v1", "Tue, 28 Dec 2010 07:14:32 GMT  (104kb)", "http://arxiv.org/abs/1012.5705v1", "6 pages, invited paper presented at the International Conference on Advanced Computer Science and Information Systems 2010 (ICACSIS2010), Bali, Indonesia, 20-22 November 2010"]], "COMMENTS": "6 pages, invited paper presented at the International Conference on Advanced Computer Science and Information Systems 2010 (ICACSIS2010), Bali, Indonesia, 20-22 November 2010", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["wan ahmad tajuddin wan abdullah"], "accepted": false, "id": "1012.5705"}, "pdf": {"name": "1012.5705.pdf", "metadata": {"source": "CRF", "title": "Looking for plausibility", "authors": ["Wan Ahmad Tajuddin", "Wan Abdullah"], "emails": [], "sections": [{"heading": null, "text": "In the interpretation of experimental data, one is actually looking for plausible explanations. We look for a measure of plausibility, with which we can compare different possible explanations, and which can be combined when there are different sets of data. This is contrasted to the conventional measure for probabilities as well as to the proposed measure of possibilities. We define what characteristics this measure of plausibility should have.\nIn getting to the conception of this measure, we explore the relation of plausibility to abductive reasoning, and to Bayesian probabilities. We also compare with the Dempster-Schaefer theory of evidence, which also has its own definition for plausibility. Abduction can be associated with biconditionality in inference rules, and this provides a platform to relate to the Collins-Michalski theory of plausibility. Finally, using a formalism for wiring logic onto Hopfield neural networks, we ask if this is relevant in obtaining this measure."}, {"heading": "INTRODUCTION", "text": "Traditionally, uncertainty in propositions is handled through the concept of probability with its statistical interpretation. It is however, a bit strange when such an approach which is based on counting events, is applied to hypotheses, like explanatory propositions. For example, in the interpretation of experimental data, one is actually looking for plausible explanations to describe the observed data. Whilst probability may be seen to underlie data measurement, a statistical picture for explanations may be viable only in a multiple-world universe.\nWe thus seek a measure for plausibility, with which we can compare different possible explanations. Furthermore, this measure of plausibility should allow appropriate combination when different explanations and/or sets of data are combined."}, {"heading": "UNCERTAINTY MEASURES", "text": "Probabilities are calculated from the numbers of events satisfying respective propositions from a total set and are normalized. Thus probabilities for alternative explanations are exclusive, and the more\nalternatives there are, the less are the values for probabilities in general. Plausibility, on the other hand, should not behave as such.. The plausibility of a proposition should not depend on the plausibility of an alternative proposition, much less reduced by it.\nIn logical conjunctions, probabilities are combined by multiplication, and in disjunctions, by addition, when the atoms are exclusive:\nP(X\u2227Y) = P(X)\u00d7P(Y) P(X\u2228Y) = P(X)+P(Y)-P(X\u2227Y)\nThis does not necessarily follow for plausibilities; in fact, for example, intuitively it does not seem correct that the plausibility of (X or Y) is the sum of the individual plausibilities of X and Y.\nPlausibility seems closer to the notion of possibility [1] (based on fuzzy sets, thus rather similar to fuzzy logic [2]) when combinations are concerned. Disjunctions of possibilities return the maximum values, while conjunctions of possibilities involve the minimum values:\npos(X\u2227Y) \u2264 min(pos(X),pos(Y)) pos(X\u2228Y) = max(pos(X),pos(Y))\nOther than probabilities and possibilities, other uncertainty measures (sometimes with similar names) have been proposed by, for example Dempster and Shafer [3], further studied below, and others."}, {"heading": "PLAUSIBILITY", "text": "Let us now define what characteristics the measure of plausibility should have.\n\u2022 We can have a normalized scale from 0, which would denote something not at all plausible, to 1 denoting something fully plausible. Let us denote plausibility by 'pl':\npl(X) = 0 : X is not all plausible pl(X) = 1 : X is fully plausible\n\u2022 Plausibilities are not exclusive. For example, even when X and Y are not logically compatible, yet X can be fully plausible at the same time that Y is fully plausible:\npl(X) + pl(Y) > 1 though X \u2229 Y = \u2205\n\u2022 Like possibility, and unlike probability, plausibility is not self-dual. That is, pl(X) \u2260 1-pl(\u00acX).\nIn another words, when something is not at all plausible, it does not mean that it is fully plausible that that something is untrue. Let us include negative values for plausibility to enable the representation of negations, and require that\npl(\u00acX) = - pl(X). This means that now\npl(X) \u2208 [-1,1], giving values for fully plausibly false on the one end, and fully plausibly true on the other, with nonplausibility (\u2018non-relevance\u2019) in the middle.\nA Wiktionary definition of plausibility is \u201cseemingly or apparently valid, likely, or acceptable\u201d. This suggests that plausibility may be related to abduction."}, {"heading": "ABDUCTIVE REASONING", "text": "Abduction (see e.g. [4]), first described by Peirce more than a hundred years ago, is the process of arriving at the premise which would 'explain' some situation. Given that the set of propositions C formally follows from the set of propositions A subject to the set of logical rules T, then the derivation of C from T and A is deduction, that of T from C and A is induction, and that of A from T and C is abduction. Note that the abduced set is sufficient, but not necessary for C to follow from T, and may be one of many alternatives; in abduction one also usually looks for the most natural explanation in the form of the most economical one.\nGiven a set of true propositions, then, an abduced proposition is a plausible proposition. Plausibility then is a measure of how good is the proposition in explaining the available facts. It can be related to how much of the requirement for sufficiency has been satisfied."}, {"heading": "BAYESIAN PROBABILITIES", "text": "When propositions have probabilistic values, then abduction is related to conditional probabilities. Bayes' theorem states that the probability for \u03b8 given x,\nP(\u03b8 |x) = P(x |\u03b8 ) P(\u03b8 ) / P(x) depends on the conditional probability, or likelihood, of x given \u03b8, multiplied by the prior probability for \u03b8. Abduction being the 'reverse' of deduction is parallel to the conditional probability being the 'reverse' of likelihood.\nConditional probabilities then present a possible model for plausibilities. Combinations of plausibilities in inferences can copy those in Bayesian networks [5]. However, the determination of prior probabilities pose a problem for calculating conditional probabilities."}, {"heading": "DEMPSTER-SHAFER THEORY", "text": "The Dempster-Shafer theory of evidence [3] has its own definition for plausibility which is based on some belief function. Plausibility for a set of propositions is the sum of \u201cbelief masses\u201d of other sets of propositions which intersect with this set, while belief is that for those which are subsets, and they bound the probability:\nbel(X) \u2264 P(X) \u2264 pl(X) and are related,\npl(X) = 1 - bel(\u00acX). The theory prescribes a method for combining belief masses from different assignments, along the lines of Bayesian theory. To obtain the plausibility of a combined set of propositions, one has to recalculate using the primary definition.\nThe assignment of belief masses is problematic here, and also, their association with probabilities is misleading. Furthermore, plausibility being the upper bound for belief suggests a rather subjective definition."}, {"heading": "BICONDITIONALITY AND COLLINS-MICHALSKI", "text": "A theory for plausible reasoning has been proposed by Collins and Michalski [6]. It has several types of inferences, namely mutual implication, mutual dependency, generalization, specialization, and similarity/analogy. A drawback is that it has a restrictively large number of parameters to model uncertainty.\nThe inferences existing in Collins-Michalski theory are mostly explained by biconditionality, wherein implications are taken to also include some degree of equivalences [7]. This relates to abduction, as abduction coincides with deduction when implications are replaced by equivalences. In the probabilistic picture, this is like equating the conditional probability to the likelihood,\nP(\u03b8 |x) = P(x |\u03b8 ) Of course this is not rational; after all, this is plausible reasoning. However, this supports the notion that plausibility has an abductive basis."}, {"heading": "CONNECTIONIST", "text": "It has been shown [8,9] that logic can be hardwired onto a Hopfield neural network [10]. The Hopfield network minimizes a Lyapunov or \u201cenergy\u201d function related to the synaptic strengths [11]. By writing an expression yielding a value proportional to unsatisfied clauses, the network then searches for an optimum logical interpretation of the propositional atoms, represented by neurons. This then gives the values for the synapses. In some sense, the logic is contained in the synapses.\nFrom the synaptic strengths then, we can make inferences about the logical clauses [12]. This may be helpful in our search for a measure of plausibility."}, {"heading": "PLAUSIBILITY, PLAUSIBLY", "text": "Finally, we can make some preliminary moves in the direction of plausibility. Taking an abductive interpretation, the more of the set of existing \u2018measured\u2019 propositions C a hypothetical proposition Ai forces, the more plausible Ai should be. Perhaps then the plausibility of Ai corresponds to the fraction of propositions in C that is forced correct (both, either true or false) by Ai. If Ai does not have any effect on C then Ai should have plausibility 0, and if forces all of the known propositions C to be correct, then Ai have plausibility 1.\nWhat is of interest is the combination of plausibilities. Is it possible to have simple combining rules for conjunctions and disjunctions, for example? For propositions Ai and Aj each forcing disjoint subsets of C and having no joint effects on the correctness of any subset, then simply\npl(Ai\u2227 Aj) = pl(Ai) + pl(Aj). In the case of the existence of some common proposition Ci forced by both Ai and Aj, i.e. the rule base T contains\nAi \u2192 Ci Aj \u2192 Ci\nthen the value is less, as also implicated by the upper limit of 1 on the value of plausibilities, while in the case that Ai and Aj have a joint effect on Ci, e.g.\nAi\u2227 Aj \u2192 Ci\nthen the value is more. In general, plausibility of conjunctions can be complicated. It may simplify somewhat for singleton C\u2019s, whence the measure would involve some kind of probability, and these phenomena would be averaged out.\nHaving plausibility related to fraction of forced correctness is compatible with our previous definition of negative plausibilities. For disjoint hypotheses Ai and Aj, using de Morgan\u2019s theorem, the plausibility for a disjunction is similarly given,\npl(Ai\u2228Aj) = pl(Ai) + pl(Aj), a bit counter-intuitively. Proceeding, thus\npl(Ai \u2192 Aj) = pl(Aj) - pl(Ai). Interestingly, this has some similarity to synaptic weight assignment in connectionist logic previously discussed where whilst some weights are increased with the addition of a clause, some are decreased.\nUsing hardwired logic on connectionist networks, and forcing the correct values for the neurons in C, and that for a hypothesis, the final network state yields the least value for the energy function, which corresponds to the number of clauses unsatisfied. This intuitively should also represent the number of errors in C, allowing an estimation of the plausibility of the hypothesis. For this, synaptic weights, or equivalently, clauses in T need to be known explicitly; however, this can be obtained [12] through Hebbian learning."}, {"heading": "CONCLUSIONS", "text": "In summary, we have explored the concept of plausibility and attempted to characterize a measure for it. In particular, we have taken an abductive basis, and conjecture that a hypothesis is more plausible if it forces more of the measured truth. For simple cases we can write down the rules for combinations. We also indicated how plausibility can be measured using a logic neural network.\nThis exploratory proposal for plausibility needs to be further investigated, especially for the non-trivial cases of combinations. It is hoped that combination of plausibilities would help in the interpretation of combinations of measurements in experimental data."}, {"heading": "13 (1989) 1-49.", "text": "[7] W. A. T. Wan Abdullah, \u201cBiconditionality, Analogy, Induction and Predicate Logic\u201d, Malaysian J. Comput. Sci. 3 (1987) 21-28.\n[8] W. A. T. Wan Abdullah, \u201cNeural Network Logic\u201d, in O. Benhar, C. Bosio, P. del Giudice & E. Tabet (eds.), Neural Networks: From Biology to High Energy Physics, ETS Editrice, Pisa, 1991, pp. 135-142.\n[9] W. A. T. Wan Abdullah, \u201cLogic Programming on a Neural Network\u201d, J. of Intelligent Systems 7 (1992) 513-519.\n[10] J. J. Hopfield, \u201cNeural networks and physical systems with emergent collective computational abilities\u201d, Proc. Natl. Acad. Sci. USA 79 (1982) 2554-2558.\n[11] J. J. Hopfield & D. W. Tank, \u201c\u201cNeural\u201d Computation of Decisions in Optimization Problems\u201d, Biol. Cybern. 52 (1985) 141-152.\n[12] W. A. T. Wan Abdullah, \u201cThe Logic of Neural Networks\u201d, Phys. Lett. 176A (1993) 202-206."}], "references": [{"title": "Fuzzy Sets as the Basis for a Theory of Possibility", "author": ["L. Zadeh"], "venue": "Fuzzy Sets and Systems 1 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1978}, {"title": "Fuzzy sets", "author": ["L.A. Zadeh"], "venue": "Information and Control 8 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1965}, {"title": "A Mathematical Theory of Evidence", "author": ["G. Shafer"], "venue": "Princeton Univ. Press, Princeton NJ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1976}, {"title": "Abduction", "author": ["L. Magnani"], "venue": "Reason and Science: Processes of Discovery and Explanation, Kluwer, New York", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "Probabilistic Inferences in Bayesian Networks", "author": ["J. Ding"], "venue": "e-print arXiv:1011.0935", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Biconditionality", "author": ["W.A.T. Wan Abdullah"], "venue": "Analogy, Induction and Predicate Logic\u201d, Malaysian J. Comput. Sci. 3 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1987}, {"title": "Neural Network Logic", "author": ["W.A.T. Wan Abdullah"], "venue": "O. Benhar, C. Bosio, P. del Giudice & E. Tabet (eds.), Neural Networks: From Biology to High Energy Physics, ETS Editrice, Pisa", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1991}, {"title": "Logic Programming on a Neural Network", "author": ["W.A.T. Wan Abdullah"], "venue": "J. of Intelligent Systems 7 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1992}, {"title": "Neural networks and physical systems with emergent collective computational abilities", "author": ["J.J. Hopfield"], "venue": "Proc. Natl. Acad. Sci. USA 79 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1982}, {"title": "Neural\u201d Computation of Decisions in Optimization Problems", "author": ["J.J. Hopfield", "D.W. Tank"], "venue": "Biol. Cybern", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1985}, {"title": "The Logic of Neural Networks", "author": ["W.A.T. Wan Abdullah"], "venue": "Phys. Lett. 176A ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1993}], "referenceMentions": [{"referenceID": 0, "context": "Plausibility seems closer to the notion of possibility [1] (based on fuzzy sets, thus rather similar to fuzzy logic [2]) when combinations are concerned.", "startOffset": 55, "endOffset": 58}, {"referenceID": 1, "context": "Plausibility seems closer to the notion of possibility [1] (based on fuzzy sets, thus rather similar to fuzzy logic [2]) when combinations are concerned.", "startOffset": 116, "endOffset": 119}, {"referenceID": 2, "context": "Other than probabilities and possibilities, other uncertainty measures (sometimes with similar names) have been proposed by, for example Dempster and Shafer [3], further studied below, and others.", "startOffset": 157, "endOffset": 160}, {"referenceID": 0, "context": "This means that now pl(X) \u2208 [-1,1], giving values for fully plausibly false on the one end, and fully plausibly true on the other, with nonplausibility (\u2018non-relevance\u2019) in the middle.", "startOffset": 28, "endOffset": 34}, {"referenceID": 3, "context": "[4]), first described by Peirce more than a hundred years ago, is the process of arriving at the premise which would 'explain' some situation.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "Combinations of plausibilities in inferences can copy those in Bayesian networks [5].", "startOffset": 81, "endOffset": 84}, {"referenceID": 2, "context": "The Dempster-Shafer theory of evidence [3] has its own definition for plausibility which is based on some belief function.", "startOffset": 39, "endOffset": 42}, {"referenceID": 5, "context": "The inferences existing in Collins-Michalski theory are mostly explained by biconditionality, wherein implications are taken to also include some degree of equivalences [7].", "startOffset": 169, "endOffset": 172}, {"referenceID": 6, "context": "It has been shown [8,9] that logic can be hardwired onto a Hopfield neural network [10].", "startOffset": 18, "endOffset": 23}, {"referenceID": 7, "context": "It has been shown [8,9] that logic can be hardwired onto a Hopfield neural network [10].", "startOffset": 18, "endOffset": 23}, {"referenceID": 8, "context": "It has been shown [8,9] that logic can be hardwired onto a Hopfield neural network [10].", "startOffset": 83, "endOffset": 87}, {"referenceID": 9, "context": "The Hopfield network minimizes a Lyapunov or \u201cenergy\u201d function related to the synaptic strengths [11].", "startOffset": 97, "endOffset": 101}, {"referenceID": 10, "context": "From the synaptic strengths then, we can make inferences about the logical clauses [12].", "startOffset": 83, "endOffset": 87}, {"referenceID": 10, "context": "For this, synaptic weights, or equivalently, clauses in T need to be known explicitly; however, this can be obtained [12] through Hebbian learning.", "startOffset": 117, "endOffset": 121}], "year": 2010, "abstractText": "In the interpretation of experimental data, one is actually looking for plausible explanations. We look for a measure of plausibility, with which we can compare different possible explanations, and which can be combined when there are different sets of data. This is contrasted to the conventional measure for probabilities as well as to the proposed measure of possibilities. We define what characteristics this measure of plausibility should have. In getting to the conception of this measure, we explore the relation of plausibility to abductive reasoning, and to Bayesian probabilities. We also compare with the Dempster-Schaefer theory of evidence, which also has its own definition for plausibility. Abduction can be associated with biconditionality in inference rules, and this provides a platform to relate to the Collins-Michalski theory of plausibility. Finally, using a formalism for wiring logic onto Hopfield neural networks, we ask if this is relevant in obtaining this measure.", "creator": "Writer"}}}