{"id": "1103.0598", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2011", "title": "Learning transformed product distributions", "abstract": "We consider the problem of learning an unknown product distribution $X$ over $\\{0,1\\}^n$ using samples $f(X)$ where $f$ is a \\emph{known} transformation function. Each choice of a transformation function $f$ specifies a learning problem in this framework. This library has a library of other possible uses in this case. For example, a \"learning algorithm\" requires a subset of randomization algorithms to be used to represent a collection of a collection of randomly generated neural networks. In this way the distribution of learning neural networks will be treated as a function of the complexity of the distribution of learning neural networks.\n\n\n\nThe core set of algorithms of the proposed implementation are the algorithms of neural networks. The first generation neural networks were defined in the early 2000s. Although they were developed for learning learning and memory, they were not designed for learning and memory. The current generation neural networks were based on algorithms for learning and memory and a set of functions for learning and memory that we define in the standard library. In addition, we chose the most basic algorithm to generate the learning and memory model using a set of four ways to describe how learning and memory are used in this framework: learning (by group, group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.). In fact, learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group, time, model, etc.), learning (by group", "histories": [["v1", "Thu, 3 Mar 2011 02:46:51 GMT  (41kb)", "http://arxiv.org/abs/1103.0598v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["constantinos daskalakis", "ilias diakonikolas", "rocco a servedio"], "accepted": false, "id": "1103.0598"}, "pdf": {"name": "1103.0598.pdf", "metadata": {"source": "CRF", "title": "Learning transformed product distributions", "authors": ["Constantinos Daskalakis", "Ilias Diakonikolas", "Rocco A. Servedio"], "emails": ["costis@csail.mit.edu", "ilias@cs.berkeley.edu", "rocco@cs.columbia.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n10 3.\n05 98\nv1 [\ncs .L\nG ]\n3 M\nar 2\n01 1\nInformation-theoretic arguments show that for every transformation function f the corresponding learning problem can be solved to accuracy \u01eb, using O\u0303(n/\u01eb2) examples, by a generic algorithm whose running time may be exponential in n. We show that this learning problem can be computationally intractable even for constant \u01eb and rather simple transformation functions. Moreover, the above sample complexity bound is nearly optimal for the general problem, as we give a simple explicit linear transformation function f (x) = w \u00b7 x with integer weights wi \u2264 n and prove that the corresponding learning problem requires \u2126(n) samples.\nAs our main positive result we give a highly efficient algorithm for learning a sum of independent unknown Bernoulli random variables, corresponding to the transformation function f (x) = \u2211n i=1 xi. Our algorithm learns to \u01eb-accuracy in poly(n) time, using a surprising poly(1/\u01eb) number of samples that is independent of n. We also give an efficient algorithm that uses log n \u00b7 poly(1/\u01eb) samples but has running time that is only poly(log n, 1/\u01eb)."}, {"heading": "1 Introduction", "text": "We consider the problem of learning an unknown product distribution that has been transformed according to a known function f . This is a simple and natural learning problem, but one which does not seem to have been explicitly studied in a systematic way from a computational learning theory perspective.\nMore precisely, in this paper we restrict our model to the natural case when the input distribution is a a product distribution over the Boolean cube {0, 1}n. In this learning scenario the learner is provided with samples from the random variable f (X), where X = (X1, . . . , Xn) is a vector of independent 0/1 Bernoulli random variables Xi whose expectations are unknown to the learner. We write p = (p1, . . . , pn) \u2208 [0, 1]n to denote E[X], and refer to p as the target vector of probabilities; we shall sometimes write f (p) to denote the random variable f (X) described above. Using these samples, the learner must with probability 1 \u2212 \u03b4 1 output a hypothesis distribution H over f ({0, 1}n) such that the total variation distance dTV( f (X),H) is at most \u01eb. A proper learning algorithm in this framework outputs a hypothesis vector p\u0302 \u2208 [0, 1]n defining a hypothesis distribution f (X\u0302), where X\u0302 = (X\u03021, . . . , X\u0302n) is a vector of independent 0/1 Bernoulli random variables X\u0302i whose expectation is E[X\u0302] = p\u0302.\nWe emphasize that in this learning scenario, the transformation function f is fixed and known to the learner; the choice of a particular transformation function f specifies a particular learning problem in this model, much as the choice of a concept class C specifies a learning problem in Valiant\u2019s PAC learning model. We will be interested in both the computational complexity (running time) and sample complexity (number of samples required) for algorithms that solve this problem, for different transformation functions f .\n\u2217Research supported by NSF CAREER award CCF-0953960 and by a Sloan Foundation Fellowship. \u2020Research supported by a Simons Foundation Postdoctoral Fellowship. Most of this work was done while at Columbia University, supported by NSF grant CCF-0728736, and by an Alexander S. Onassis Foundation Fellowship. \u2021Supported by NSF grants CCF-0347282, CCF-0523664 and CNS-0716245, and by DARPA award HR0011-08-10069. 1For ease of exposition we state all our positive results throughout the paper with \u03b4 fixed to 1/10. All our results extend to general \u03b4 with a log(1/\u03b4) overhead in sample complexity."}, {"heading": "1.1 Motivation, examples, and connection to prior work", "text": "Our motivation for considering this model is twofold. First, we feel that it is so simple and natural as to warrant study for its own sake. Second, we believe that it offers a useful perspective on modeling probability distributions in settings where the underlying source of randomness is not directly accessible to the learner. In many settings we may wish to understand some phenomenon (in the physical world, in a market, etc.) where the available observations can be viewed as the output of a transformation f applied to some underlying random source X; learning an accurate approximation of the distribution of f (X) is a natural goal in such a setting. (The restriction on X imposed in this paper \u2013 that it is a product of independent Bernoulli random variables \u2013 admittedly represents an idealized scenario, but it is a natural starting point for theoretical study.) It is plausible that in such a situation the transformation function f may be well understood (as a consequence of our knowledge of the laws governing the physical world, the marketplace, etc.), but that much less is known about the parameters of the underlying random variable X (we may have no direct access to this random variable, it could represent private information, etc.). This corresponds to our model\u2019s assumption that f is \u201cknown\u201d and the task is to infer the parameters of X that give rise to the observed data.\nExamples: As a simple example to illustrate our learning model, we consider the product distribution learning problem for f where f is any read-once AND-gate function. A function f : {0, 1}n \u2192 {0, 1}m, f (x) = ( f1(x), . . . , fm(x)) is a read-once AND-gate function if each fi(x) is an AND over some subset S i \u2286 [n] of the n input bits x1, . . . , xn and the sets S 1, . . . , S m are pairwise disjoint. It is not hard to see that there is a straightforward proper learning algorithm based on linear programming that succeeds for any read-once AND-gate function regardless of the fanin of the AND gates (see Appendix A):\nObservation 1.1 Let f : {0, 1}n \u2192 {0, 1}m be any fixed read-once AND-gate function (known to the learner). There is an algorithm that uses poly(n, 1/\u01eb) samples from the target distribution f (p), runs in poly(n, 1/\u01eb) time, and with probability at least 9/10 outputs a hypothesis vector p\u0302 such that dTV( f (p), f ( p\u0302)) \u2264 \u01eb.\nAs a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). For simplicity we describe the case k = 2: there are unknown product distributions p, q over {0, 1}n and unknown mixing weights \u03c0p, \u03c0q = 1 \u2212 \u03c0p. The learner is given independent draws from the mixture distribution (each draw is independently taken from p with probability \u03c0p and from q with probability \u03c0q), and must output hypothesis product distributions p\u0302, q\u0302 and hypothesis mixing weights \u03c0\u0302p, \u03c0\u0302q. This problem is easily seen to be equivalent to the transformed product distribution learning problem for the function f : {0, 1}2n+1 \u2192 {0, 1}n which is such that on input (z, x1, . . . , xn, y1, . . . , yn) \u2208 {0, 1}2n+1 the i-th bit of f \u2019s output is zxi + (1 \u2212 z)yi. It is easy to see that if the target vector of probabilities for f is (\u03c0p, p1, . . . , pn, q1, . . .qn) then samples of f are distributed exactly according to the mixture of product distributions, and finding a good hypothesis vector in [0, 1]2n+1 amounts to finding a hypothesis mixing weight \u03c0\u0302p and hypothesis product distributions p\u0302, q\u0302 as required in the original \u201clearning mixtures of product distributions\u201d problem.\nConnection to prior work: The transformed product distribution learning model is related to the PACstyle model of learning discrete probability distributions that was introduced by Kearns et al. (1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). In the Kearns et al. (1994) framework a learning problem is defined by a class C of Boolean circuits, and an instance of the problem corresponds to the choice of a specific (unknown to the learner) target circuit C \u2208 C. The learner is given samples from C(X) where X is a uniform random string from {0, 1}m, and the learner must with high probability output a hypothesis circuit C\u2032 such that the random variable C\u2032(X) is \u01eb-close to C(X) (in KL-divergence).\nStrictly speaking the transformed product distribution learning model may be viewed as a special case of the Kearns et al model. This is done by considering a circuit class C that has a circuit C = Cp for each possible product distribution p over {0, 1}n; the circuit Cp first transforms the uniform distribution over {0, 1}m to the product distribution p over {0, 1}n and then applies the transformation function f to the output of p. However, learning problems C of this sort do not seem to have been previously considered in the Kearns et al. (1994) model, and we feel it is more natural to view our model as dual in spirit to the earlier model. In Kearns et al. (1994) the learner\u2019s task is to infer an unknown transformation (the circuit C) into which are fed n-bit strings that are known to be distributed uniformly. In our case the transformation function f is known to the learner but the underlying product distribution that is fed into f is unknown and must be inferred."}, {"heading": "1.2 Our results and techniques", "text": "We establish a range of positive and negative results for this learning problem, both for general functions and for particular transformation functions of interest. For most of this paper we focus on the case in which f (X) is simply a real-valued random variable, i.e. f is a transformation mapping {0, 1}n to R.\nWe begin by considering the most general possible setting, in which the transformation function f can be any function mapping the domain {0, 1}n into any range. By an approach similar to the algorithm of Devroye and Lugosi (2001) for choosing a density estimate, we show (Theorem 6) that if the space { f (p)}p\u2208[0,1]n of all f -transformed product distributions has an \u01eb-cover of size N, then there is a generic learning algorithm for the f -transformed product distribution problem that uses O((log N)/\u01eb2) samples. The algorithm works by carrying out a tournament that matches every pair of distributions in the cover against each other; our analysis shows that with high probability some \u01eb-accurate distribution in the cover will survive the tournament undefeated, and that any undefeated tournament will with high probability be highly accurate.\nAs an immediate consequence of the general result Theorem 6 we get that for any transformation function f there is an algorithm that learns to accuracy \u01eb using O\u0303(n/\u01eb2) samples:\nTheorem 1 (Information-theoretic upper bound for any f ) Let f : {0, 1}n \u2192 \u2126 be an arbitrary function where \u2126 is any range set. There is an algorithm that uses O((n/\u01eb2) \u00b7 log(n/\u01eb)) samples from the target distribution f (p), runs in time (n/\u01eb)O(n), and with probability at least 9/10 outputs a hypothesis vector p\u0302 such that dTV( f (p), f ( p\u0302)) \u2264 \u01eb.\nSince an \u01eb-cover of the space of all f -transformed product distributions may have size exponential in n, Theorem 1 does not in general provide a computationally efficient algorithm. Indeed, in Appendix C we show that the learning problem can be computationally hard even for rather simple transformation functions: using a reduction to the PARTITION problem, we prove:\nTheorem 2 (NP-hardness) Suppose NP * BPP. Then there is an explicit degree-2 polynomial f : {0, 1}n \u2192 R such that there is no polynomial-time algorithm that solves the transformed product distribution learning problem for f to accuracy \u01eb = 1/3.\nWe also show that even for a simple linear transformation function f (x) = w \u00b7 x with small integer weights, it can be impossible to significantly improve on the O\u0303(n) sample complexity of the generic algorithm from Theorem 1. In Appendix D we prove:\nTheorem 3 (Sample complexity lower bound) Fix any even k \u2264 n and let f (x) = \u2211k\ni=k/2+1 ixi. Let L be any learning algorithm that outputs a hypothesis vector p\u0302 such that dTV( f (p), f ( p\u0302)) \u2264 1/40 with probability at least e\u2212o(k). Then L must use \u2126(k) samples from f (p).\nThese negative results provide strong motivation for considering what is perhaps the most natural of all transformation functions mapping {0, 1}n to R, the sum f (x) = \u2211n i=1 xi; we refer to the corresponding learning problem as \u201clearning an unknown sum of Bernoulli random variables.\u201d Our main contribution is a detailed study of this learning problem.\nLearning sums of Bernoullis from constantly many samples. As our main result, we show that any sum of independent unknown Bernoulli random variables can be efficiently approximated to \u01eb-accuracy by a proper learning algorithm that uses poly(1/\u01eb) samples, independent of n. More precisely, we prove:\nTheorem 4 (Learning sums of Bernoullis from constantly many samples) Let f (x) = \u2211n\ni=1 xi. There is an algorithm that uses poly(1/\u01eb) samples from the target distribution f (p), runs in time n3 \u00b7 poly(1/\u01eb) + n \u00b7 (1/\u01eb)O(log\n2(1/\u01eb)), and with probability at least 9/10 outputs a hypothesis vector p\u0302 \u2208 [0, 1]n which is such that dTV( f (p), f ( p\u0302)) \u2264 \u01eb.\nIt should be stressed that the generic algorithm of Theorem 6 requires\u2126((1/\u01eb2)\u00b7log n) samples for this learning problem (easy arguments give an n\u2126(1) lower bound on the size of any cover for sums of Bernoullis). We view this sample complexity independent of n as a surprising result which may find subsequent applications. We next give a brief overview of the obstacles that appear and the techniques involved in our proof.\nAs a first step in the proof of Theorem 4, we observe that a simple learning algorithm using O(1/\u01eb2) samples gives a hypothesis which has error at most \u01eb with respect to the Kolmogorov distance (see Section 2). While the algorithm itself is simple, its analysis relies on a fundamental result from probability theory, known as the Dvoretzky-Kiefer-Wolfowitz inequality (Dvoretzky et al. (1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)). In Appendix E we give a self-contained proof of the DKW inequality using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)); this proof is significantly different from the proofs we know of in the probability literature (see Dvoretzky et al. (1956), Massart (1990), and Chapter 3 of Devroye and Lugosi (2001)).\nA natural attempt is to use Kolmogorov approximation as a black box to obtain an approximation in total variation distance. In the special case when X is a sum of Bernoulli random variables and Y is a binomial\ndistribution B(n, p) (i.e. all the Bernoullis Y1, . . . , Yn have the same mean p), it is indeed possible to bound the total variation distance between X and Y as a function of their Kolmogorov distance. It can be shown that in this case the distributions of X and Y cross each other at most a constant number of times, and this is easily seen to imply that the two distances (total variation and Kolmogorov) are within a constant factor. This fact about crossings goes back to an argument by Newton (c.f. Hardy et al. (1934) section 2.22), establishing that the sequence ak = Pr[X = k]/ Pr[Y = k] is log-concave if Y is binomially distributed.\nUnfortunately, if X and Y are both generic sums of independent Bernoullis with arbitrary means (as in our setting), then such a bound is not known in the literature, and indeed it seems that essentially nothing is known about the relation between the two distances in this general case. Without such a bound, it is rather unclear whether a number of samples that does not scale with n suffices to accurately learn in total variation distance. Nevertheless, we extend the Kolmogorov distance learning algorithm to total variation distance via a delicate algorithm that exploits the detailed structure of a small \u01eb-cover (Daskalakis and Papadimitriou (2011), Daskalakis (2008)) of the space of all distributions that are sums of independent Bernoulli random variables (see Theorem 9). Interestingly, this becomes feasible by establishing an analog of the aforementioned argument by Newton to a class of distributions used in the cover that are called heavy (see Lemma 15). This in turn relies on probabilistic approximation results via translated Poisson distributions (see Definition 18, Ro\u0308llin (2006)).\nLearning sums of Bernoullis in sublinear time. While the poly(1/\u01eb) sample complexity of Theorem 4 is essentially optimal2, the running time is poly(n) (and superpoly(1/\u01eb)). Moreover, generating a single sample from the hypothesis product distribution requires \u2126(n) uniformly random bits. In general, any proper learning algorithm that explicitly outputs a hypothesis vector p\u0302 \u2208 [0, 1]n will take \u2126(n) running time, and generating a sample from the hypothesis f ( p\u0302) will require \u2126(n) random bits.\nMore broadly, any algorithm (not necessarily proper) for learning sums of Bernoullis must have running time \u2126((1/\u01eb2) \u00b7 log n) in the bit model (since each sample is an \u2126(log n) bit string and \u2126(1/\u01eb2) samples are needed). Generating a sample from an arbitrary hypothesis distribution will in general require \u2126(log n) bits (since the entropy of the binomial distribution is \u2126(log n)). Hence a natural goal is to have a learning algorithm that runs in poly(log n, 1/\u01eb) time and requires O(log n) bits of randomness to generate a draw from its hypothesis distribution. As discussed in the previous paragraph, such an algorithm needs to be non-proper.\nWe show that there is an algorithm that satisfies all of these efficiency considerations, at the cost of a log n factor in the sample complexity:\nTheorem 5 (Learning sums of Bernoullis in polylog(n) time with efficient hypotheses) Let f (x) = \u2211n\ni=1 xi. There is an algorithm that uses log(n) \u00b7poly(1/\u01eb) samples from the target distribution f (p), performs log2(n) \u00b7 poly(1/\u01eb) bit operations, and with probability at least 9/10 outputs a (succinct representation of a) hypothesis distribution H over {0, 1, . . . , n} such that dTV ( f (X),H) \u2264 \u01eb. Moreover, a draw from the hypothesis distribution H can be obtained in poly(log n, 1/\u01eb) time using O(log(n/\u01eb)) bits of randomness.\nThe key to Theorem 5 is the simple observation that any sum of Bernoullis is a unimodal distribution over the domain {0, 1, . . . , n}. This lets us apply a powerful algorithm due to Birge\u0301 (1997) that can learn any unimodal distribution to accuracy \u01eb using O(log n)/\u01eb3 samples. The algorithm outputs a hypothesis distribution that is a histogram over O((log n)/\u01eb) intervals that cover {0, . . . , n}: more precisely, the hypothesis is uniform within each interval, and for each interval the total mass it assigns to the interval is simply the fraction of samples that landed in that interval. Thus, the hypothesis distribution has a succinct description and can be efficiently evaluated using a small amount of randomness. We give details in Appendix F.\nWe remark that by applying the algorithm of Theorem 5 to the hypothesis distribution that is provided by Theorem 4, one can obtain a 2\u01eb-accurate hypothesis satisfying the efficiency conditions of Theorem 5 (i.e. the hypothesis can be evaluated in poly-logarithmic time and a sample from it can be generated using O(log(n/\u01eb)) random bits). Thus, it is possible to construct an \u01eb-accurate efficient hypothesis using poly(1/\u01eb) samples and poly(n) time. Whether this can be achieved in poly-logarithmic time is an interesting and challenging open problem; we discuss this and other questions for future work in Section 6."}, {"heading": "2 Preliminaries", "text": "Recall that the total variation distance between two distributionsP andQ over a finite domain D is dTV (P,Q) := (1/2) \u00b7 \u2211 \u03b1\u2208D |P(\u03b1) \u2212 Q(\u03b1)|. Similarly, if X and Y are two random variables ranging over a finite set, their total variation distance dTV(X, Y) is defined as the total variation distance between their distributions. Another notion of distance between distributions/random variables that we use is the Kolmogorov distance. For two distributionsP andQ supported on R, their Kolmogorov distance is dK (P,Q) := supx\u2208R |P((\u2212\u221e, x]) \u2212 Q((\u2212\u221e, x])| .\n2An easy reduction to distinguishing a fair coin from an \u01eb-biased coin shows that any learning algorithm for this problem needs \u2126(1/\u01eb2) samples.\nSimilarly, if X and Y are two random variables ranging over a subset of R, their Kolmogorov distance, denoted dK(X, Y), is the Kolmogorov distance between their distributions. If two distributions P and Q are supported on a finite subset of R we obtain immediately that dK (P,Q) \u2264 2 \u00b7 dTV (P,Q) .\nFix a finite domain D, and let P denote some set of distributions over D. Given \u03b4 > 0, a subset Q \u2286 P is said to be a \u03b4-cover of P (w.r.t. total variation distance) if for every P in P there exists some Q in Q such that dTV(P,Q) \u2264 \u03b4.\nWe write S = Sn to denote the set of all product distributions over {0, 1}n, and f (S) to denote the set of all transformed product distributions { f (p)}p\u2208S. We write f (p)(\u03b1) to denote the probability of outcome \u03b1 under distribution f (p). Finally, for \u2113 \u2208 Z+ we write [\u2113] to denote {1, . . . , \u2113}."}, {"heading": "3 A generic algorithm for any f and some lower bounds", "text": "In this section we give a simple generic algorithm to solve the transformed product distribution learning problem for any transformation function f , and state some lower bounds showing that even for rather simple functions f , the time and sample complexity of the generic algorithm may be essentially the best possible."}, {"heading": "3.1 A generic algorithm", "text": "The key ingredient in the generic algorithm is the following:\nTheorem 6 Fix a function f : {0, 1}n \u2192 \u2126 where \u2126 is any range set. Suppose there exists a \u03b4-cover for f (S) of size N = N(n, \u03b4). Then there is an algorithm that uses O(\u03b4\u22122 log N) samples and solves the f -transformed product distribution learning problem to accuracy 6\u03b4.\nThe high-level idea behind Theorem 6 is as follows: for a pair of distributions Q1,Q2 \u2208 S, we define a competition between Q1 and Q2 that takes as input a sample from the target distribution f (X) and either crowns one of Q1,Q2 as the winner of the competition or calls the competition a draw. Let Q \u2286 S be a \u03b4-cover for f (S) of cardinality N = N(n, \u03b4). The algorithm performs a tournament between every pair of distributions from Q and outputs a distribution Q\u2217 \u2208 Q that was never a loser, i.e. won or achieved a draw in all competitions. (If no such distribution exists, the algorithm outputs \u201cfailure.\u201d)\nThis basic approach of running a tournament between distributions in an \u03b4-cover is quite similar to the algorithm of Devroye and Lugosi for choosing a density estimate (see Devroye and Lugosi (1996a,b) and Chapters 6 and 7 of Devroye and Lugosi (2001)), which in turn built closely on the work of Yatracos (1985). Our algorithm achieves essentially the same bounds as these earlier approaches but there are some small differences. (The DL approach uses a notion of the \u201ccompetition\u201d between two tournaments which is not symmetric under swapping the two competing tournaments, whereas our competition is symmetric; also, the DL approach chooses a distribution which wins the maximum number of competitions as the output distribution, whereas our algorithm chooses a distribution that is never defeated.) We give our proof of Theorem 6 in Appendix B.\nTheorem 1 is an easy consequence of Theorem 6. Recall Theorem 1:\nTheorem 1 (Information-theoretic upper bound for any f ) Let f : {0, 1}n \u2192 \u2126 be an arbitrary function where \u2126 is any range set. There is an algorithm that uses O((n/\u01eb2) \u00b7 log(n/\u01eb)) samples from the target distribution f (p), runs in time (n/\u01eb)O(n), and with probability at least 9/10 outputs a hypothesis vector p\u0302 such that dTV( f (p), f ( p\u0302)) \u2264 \u01eb.\nProof: We argue that for any f there is a \u03b4-cover for f (S) of size at most (n/\u03b4)n. The desired result then follows from Theorem 6. Since for any pair of distributions P,Q \u2208 S and any function f we have dTV( f (P), f (Q)) \u2264 dTV(P,Q), it suffices to exhibit a \u03b4-cover of the desired cardinality for S.\nWe claim that if we discretize each individual expectation of our input Bernoulli random variables to integer multiples of \u03b1 := \u03b4n , we obtain a \u03b4-cover for S. Let us call the set of all such discretized product\ndistributions Q. Clearly, |Q| \u2264 (\nn \u03b4 )n . Let P = (P1, . . . , Pn) \u2208 S. Consider a point Q = (Q1, . . . ,Qn) \u2208 Q\nsuch that dTV (Qi, Pi) \u2264 \u03b4/n for all i. Since both P and Q are product distributions, we have that dTV(P,Q) \u2264\u2211n i=1 dTV(Qi, Pi) \u2264 \u03b4. This completes the proof."}, {"heading": "3.2 Learning transformed product distributions can be computationally hard", "text": "Though Theorem 1 shows that any learning problem f in our framework can be solved with O\u0303(n) sample complexity, it is natural to expect that some learning problems can be computationally hard. We confirm this intuition by establishing an NP-hardness result for a specific function f that is computed by an explicit degree2 polynomial. We show that if there is a poly(n)-time algorithm for the transformed product distribution learning problem for this f , even for learning to constant accuracy, then NP \u2286 BPP. Recall Theorem 2:\nTheorem 2 Suppose NP * BPP. Then there is an explicit degree-2 polynomial f such that there is no polynomial-time algorithm that solves the transformed product distribution learning problem for f to accuracy \u01eb = 1/3.\nThe proof is a reduction from the PARTITION problem and is given in Appendix C."}, {"heading": "3.3 Linear transformation functions can require \u2126(n) samples", "text": "We now show that even for a simple linear transformation function f (x) = w \u00b7 x with small integer weights, it can be impossible to significantly improve on the O\u0303(n) sample complexity of the generic algorithm from Theorem 1. Recall Theorem 3: Theorem 3 (Sample complexity lower bound) Fix any even k \u2264 n and let f (x) = \u2211k\ni=k/2+1 ixi. Let L be any learning algorithm that outputs a hypothesis vector p\u0302 such that dTV( f (p), f ( p\u0302)) \u2264 1/40 with probability at least e\u2212o(k). Then L must use \u2126(k) samples from f (p).\nTheorem 3 is proved in Appendix D."}, {"heading": "4 Learning an unknown sum of Bernoullis from poly(1/\u01eb) samples", "text": ""}, {"heading": "4.1 Learning with respect to Kolmogorov distance", "text": "Let X be any random variable supported on {0, 1, . . . , n}. We write FX and fX to denote respectively the cumulative distribution and the probability density function of X.\nLet Z1, . . . , Zk be independent samples of the random variable X, and define Z (\u2113) i := 1Zi\u2264\u2113 for all \u2113 =\n0, . . . , n and i = 1, . . . , k. Clearly we have E [ \u2211\ni Z (\u2113) i /k ] = FX(\u2113), which suggests that F\u0302X(\u2113) := \u2211 i Z (\u2113) i /k\nmay be a good estimator of FX(\u2113) for all values of \u2113, if k is large enough. The Dvoretzky-Kiefer-Wolfowitz inequality (Dvoretzky et al. (1956), Massart (1990)) confirms this, and in fact shows that a surprisingly small value of k \u2013 independent of n \u2013 suffices. The bound on k given below is optimal up to constant factors.\nTheorem 7 (DKW Inequality) Let k = max{576, (9/8) ln(1/\u03b4)} \u00b7 (1/\u01eb2). Then with probability at least 1 \u2212 \u03b4 we have max0\u2264\u2113\u2264n \u2223\u2223\u2223F\u0302X(\u2113) \u2212 FX(\u2113) \u2223\u2223\u2223 \u2264 \u01eb.\nIn Appendix E we give a self-contained proof of the theorem using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)). We start by defining a coupling between the process of learning the cumulative distribution function as our samples are revealed and a random walk on the line. Then Kolmogorov\u2019s trick is invoked to get a handle on the maximum estimation error, proving a weaker version of the theorem in which k equals \u0398( 1\n\u03b4\u01eb2 ). We then\napply McDiarmid\u2019s inequality to bootstrap the weaker bound and obtain the tighter bound. Now we specialize to the case in which X = \u2211n i=1 Xi is a sum of independent Bernoulli random variables. We use the DKW inequality to prove the following:\nTheorem 8 (Proper Learning under Kolmogorov Distance) Let X = \u2211n\ni=1 Xi be a sum of independent Bernoulli random variables. There is an algorithm which, given k = max{9216, 18 ln(1/\u03b4)} \u00b7 (1/\u01eb2) independent samples from FX , produces with probability at least 1 \u2212 \u03b4 a set of independent Bernoullis Y1, . . . , Yn such that dK(X, Y) \u2264 \u01eb, where Y := \u2211n i=1 Yi. The running time of the algorithm is poly(n/\u01eb) + n \u00b7 ( 1 \u01eb )O(log 2 1 \u01eb ).\nProof of Theorem 8: Use Theorem 7 to produce an \u01eb4 -approximation {F\u0302X(\u2113)}\u2113 of the cumulative distribution of X. Theorem 9 below gives us that for all \u03b3 > 0, there exists a \u03b3-cover in total variation distance of the set of all sums of n Bernoulli random variables that has size poly(n/\u03b3) + n \u00b7 ( 1 \u03b3 )O(log 2 1 \u03b3 ) . Construct such a cover using \u03b3 = \u01eb/8. Given that the Kolmogorov distance between two distributions is always at most twice their total variation distance, this cover is in fact a \u01eb/4-cover in the Kolmogorov distance. Output any Y = \u2211n i=1 Yi in the cover whose cumulative distribution FY satisfies\nmax 0\u2264\u2113\u2264n |FY (\u2113) \u2212 F\u0302X(\u2113)| \u2264 \u01eb/2. (1)\nIt is easy to see that a Y satisfying (1) exists in the cover. Indeed, if Y is the closest point of the cover to X in Kolmogorov distance, then it must be that max0\u2264\u2113\u2264n |FY(\u2113) \u2212 FX(\u2113)| \u2264 \u01eb/4. Given that {F\u0302X(\u2113)}\u2113 is an \u01eb/4-approximation to FX the above inequality implies (1).\nMoreover, it is easy to check that any Y satisfying (1) will satisfy max0\u2264\u2113\u2264n |FY(\u2113) \u2212 FX(\u2113)| \u2264 3\u01eb/4 < \u01eb, using again that {F\u0302X(\u2113)}\u2113 is an \u01eb/4-approximation to FX . Hence, we have dK(X, Y) < \u01eb."}, {"heading": "4.2 From Kolmogorov distance to total variation distance", "text": "The algorithm of the previous subsection learns the target sum of Bernoullis to high accuracy with respect to Kolmogorov distance. Ideally, we would like to use this approximation as a black box to obtain an approximation in total variation distance. As we discussed in the introduction, this runs to a very basic, apparently unresolved question in probability theory: is there a bound on the total variation distance between two sums of independent indicators in terms of their Kolmogorov distance? If at least one of the two sums is a Binomial distribution, then an argument due to Newton gives a positive answer. However nothing is known about the relation between the two distances in this general case. Without such a bound, it is rather unclear whether constantly many samples (independent of n) suffices to accurately learn in total variation distance...\nNevertheless, we manage to extend our Kolmogorov distance learning algorithm to the total variation distance via a delicate algorithm that exploits the structure of a small \u01eb-cover (in total variation distance) of the space of all distributions that are sums of independent Bernoulli random variables. Interestingly, this becomes feasible by establishing an analog of the aforementioned argument by Newton to a class of distributions used in the cover that are called heavy; and this argument relies on probabilistic approximation results via translated Poisson distributions (see Definition 18).\nWe give more details below. Let us start by formally stating a theorem that defines a cover (in total variation distance) of the space of sums of independent indicators. The following is Theorem 9 of the full version of (Daskalakis and Papadimitriou (2011)):\nTheorem 9 (Cover for sums of Bernoullis) For all \u01eb > 0, there exists a set S\u01eb \u2286 S such that (i) |S\u01eb | \u2264 n3 \u00b7 O(1/\u01eb)+n\u00b7 (\n1 \u01eb )O(log2 1/\u01eb) ; (ii) For every {Xi}i \u2208 S there exists some {Yi}i \u2208 S\u01eb such that dTV( \u2211 i Xi, \u2211 i Yi) \u2264 \u01eb (i.e.\nf (S\u01eb ) is an \u01eb-cover of f (S)); and (iii) the set S\u01eb can be constructed in time O ( n3 \u00b7 O(1/\u01eb) + n \u00b7 ( 1 \u01eb )O(log2 1/\u01eb)) .\nMoreover, if {Yi}i \u2208 S\u01eb , then the collection {Yi}i has one of the following forms, where k = k(\u01eb) = O(1/\u01eb) is a positive integer:\n\u2022 (Sparse Form) There is a value \u2113 \u2264 k3 = O(1/\u01eb3) such that for all i \u2264 \u2113 we have E[Yi] \u2208 { 1 k2 , 2 k2 , . . . , k2\u22121 k2 } ,\nand for all i > \u2113 we have E[Yi] \u2208 {0, 1}.\n\u2022 (k-heavy Binomial Form) There is a value \u2113 \u2208 {0, 1, . . . , n} and a value q \u2208 {\n1 kn , 2 kn , . . . , kn\u22121 kn\n} such that for\nall i \u2264 \u2113 we have E[Yi] = q; for all i > \u2113 we have E[Yi] \u2208 {0, 1}; and \u2113, q satisfy the bounds \u2113q \u2265 k2 \u2212 1k and \u2113q(1 \u2212 q) \u2265 k2 \u2212 k \u2212 1 \u2212 3k .\n(We remark that Daskalakis (2008) establishes the same theorem, except that the size of the cover given there, as well as the time needed to produce it, are n3 \u00b7O(1/\u01eb)+n \u00b7 (\n1 \u01eb\n)O(1/\u01eb2) . Indeed, this weaker bound is obtained by\nenumerating over all possible collections {Yi}i in sparse form and all possible collections in k-heavy Binomial Form, for k = O(1/\u01eb) specified by the theorem.)\nUsing the cover described in Theorem 9, we prove the following, which immediately gives Theorem 4:\nTheorem 10 (Learning under Total Variation Distance) Let X = \u2211n\ni=1 Xi be a sum of independent Bernoullis. Fix any \u03c4 > 0. There is an algorithm which, given O( 1\n\u01eb8+\u03c4 ) independent samples from X, produces with proba-\nbility at least 9/10 a list of Bernoulli random variables Y1, . . . , Yn such that dTV(X, Y) \u2264 \u01eb, where Y := \u2211n\ni=1 Yi. The running time of the algorithm is n3 \u00b7 poly(1/\u01eb) + n \u00b7 (1/\u01eb)O(log 2 1/\u01eb).\nWe first give a high-level outline of our argument. The proof works by considering the points in a cover S\u01eb\u03b2 where \u03b2 is some constant > 1. We define two tests that can be performed on points (i.e. distributions) in S\u01eb\u03b2 . The first of these, called the \u2206-test, is run on every sparse form distribution in S\u01eb\u03b2 , and is designed to identify a sparse form distribution that is close to X if such a distribution exists. The second test, called the H-test, is run on every k-heavy Binomial form distribution in S\u01eb\u03b2 and is designed to identify a Binomial form distribution that is close to X if such a distribution exists. Since S\u01eb\u03b2 is a cover, some test will succeed. (Of course, we must also show that for each test, any distribution it outputs is indeed legitimately close to X; this is part of our analysis as well.)\nWe now enter into the detailed proof. Let \u03b2 = 1 + \u03c412 and let \u03b1 = 4 + \u03c4 2 . Using Theorem 7, from O(\u01eb \u22122\u03b1) independent samples of X we can obtain estimates {F\u0302X(\u2113)}n\u2113=0 such that |F\u0302X(\u2113) \u2212 FX(\u2113)| \u2264 \u01eb\n\u03b1, for all \u2113, with probability at least 9/10. For the rest of the proof we condition on the event that each of our estimates F\u0302X(\u2113) is indeed within \u01eb\u03b1 of the actual value FX(\u2113). Define f\u0302X(0) = F\u0302X(0) and f\u0302X(z) = F\u0302X(z) \u2212 F\u0302X(z \u2212 1), for all z \u2208 [n]."}, {"heading": "4.2.1 Handling sparse form distributions in the cover.", "text": "Let Y = \u2211 i Yi, where Y := {Yi} n i=1 \u2208 S\u01eb\u03b2 , and suppose that Y is of the sparse form, as defined in statement of Theorem 9. Let supp(Y) denote the support of Y. By the definition of the sparse form, we have that |supp(Y)| \u2264 (c\u01eb)\u22123\u03b2, where c is some universal constant. Define \u2206Y as follows:\n\u2206Y = 1 2 ( \u2211 z\u2208supp(Y) | fY (z) \u2212 f\u0302X(z)| + 1 \u2212 \u2211 z\u2208supp(Y) | f\u0302X(z)| ) .\nWe observe that given {F\u0302X(\u2113)}n\u2113=0 and Y, the value of \u2206Y can be straightforwardly computed in time poly(1/\u01eb) using dynamic programming.\nThe following two claims (whose proofs we defer to Section 4.3) say that if dTV(X, Y) is large (at least \u01eb) then \u2206Y must be fairly large, while if dTV(X, Y) is small (at most \u01eb\u03b2) then \u2206Y must also be fairly small.\nClaim 11 If dTV(X, Y) \u2265 \u01eb, then \u2206Y \u2265 \u01eb \u2212 2(c\u01eb)\u22123\u03b2 \u00b7 \u01eb\u03b1.\nClaim 12 If dTV(X, Y) \u2264 \u01eb\u03b2, then \u2206Y \u2264 \u01eb\u03b2 + 2(c\u01eb)\u22123\u03b2 \u00b7 \u01eb\u03b1.\nBy our choice of \u03b2 = 1 + \u03c412 and \u03b1 = 4 + \u03c4 2 , for \u01eb smaller than a certain constant (depending on c and \u03c4)\nthe following condition holds:\n\u01eb > \u01eb\u03b2 + 4c\u22123\u03b2\u01eb\u03b1\u22123\u03b2. (2)\nClaims 11 and 12 imply that if we use the S\u01eb\u03b2 cover of Theorem 9, we can filter collections {Yi}i \u2208 S\u01eb\u03b2 in the sparse form whose sum Y is \u01eb-far in total variation distance from X, by computing \u2206Y and thresholding at the value \u01eb\u03b2 + 2(c\u01eb)\u22123\u03b2 \u00b7 \u01eb\u03b1. Moreover, this filtration is not going to get rid of any collections in sparse form that are within \u01eb\u03b2 total variation distance from the target distribution. Formally, let us define the following test, which takes as input the estimates {F\u0302X(\u2113)}n\u2113=0 and decides whether or not to reject a point in S\u01eb\u03b2 in sparse form.\nDefinition 13 (\u2206-test) The input is Y = {Yi}i \u2208 S\u01eb\u03b2 in the sparse form. Let Y = \u2211 i Yi. If \u2206Y \u2264 \u01eb \u03b2+2(c\u01eb)\u22123\u03b2 \u00b7\u01eb\u03b1 then the \u2206-test accepts Y, otherwise it rejects Y.\nSince \u2206Y can be computed in poly(1/\u01eb) time, an execution of the \u2206-test can be performed in poly(1/\u01eb) time. If (2) is satisfied, Claims 11 and 12 imply the following: Lemma 14 (Correctness of the \u2206-test) Let {Yi}i \u2208 S\u01eb\u03b2 be in the sparse form and Y = \u2211\ni Yi. If Y is accepted by the \u2206-test then dTV(X, Y) \u2264 \u01eb, and if dTV(X, Y) \u2264 \u01ebb then Y is accepted by the \u2206-test.\nLemma 14 implies in particular that if {Xi}i has an \u01eb\u03b2-neighbor {Yi}i in S\u01eb\u03b2 that is in the sparse form, then this neighbor will be accepted by the \u2206-test. Moreover, no element {Yi}i \u2208 S\u01eb\u03b2 in sparse form that is accepted by the \u2206-test has \u2211 i Yi further than \u01eb in total variation distance from \u2211 i Xi."}, {"heading": "4.2.2 Handling Binomial form distributions in the cover.", "text": "We can use the \u2206-test for the sparse points in the cover, but it could be that the target collection X = {Xi}i has no sparse \u01eb\u03b2-neighbor in S\u01eb\u03b2 and the \u2206-test fails to accept any sparse point in the cover. We need to devise a procedure which similarly filters the points of heavy Binomial form in the cover so that we do not eliminate any \u01eb\u03b2-close point, while at the same time not admitting any \u01eb-far point. Since X has no sparse \u01eb\u03b2-neighbor in the cover, it follows from Theorem 9 that there is a collection X\u2032 := {X\u2032i }i \u2208 S\u01eb\u03b2 in k(\u01eb\n\u03b2)-heavy Binomial form such that \u2211 i Xi and \u2211 i X \u2032 i are within \u01eb\n\u03b2 in total variation distance. We show that the total variation distance is essentially within a constant factor of the Kolmogorov distance\nfor two collections of random variables in heavy Binomial form:\nLemma 15 Let X := {Xi}i and Y := {Yi}i be two collections of independent indicators in k-heavy Binomial form and set X = \u2211 i Xi, Y = \u2211 i Yi. Then 1 2 dK(X, Y) \u2264 dTV(X, Y) \u2264 2 \u00b7 dK(X, Y) + O(1/k).\nThe proof is somewhat lengthy so we defer it to Section 4.4. Given Lemma 15, we are inspired to define the H-test as follows. The test takes as input the estimates {F\u0302X(\u2113)}n\u2113=0 and needs to decide whether or not to reject a point in S\u01eb\u03b2 in k(\u01eb\u03b2)-heavy Binomial form. Definition 16 (H-test) The input is Y = {Yi}i \u2208 S\u01eb\u03b2 in the k(\u01eb\u03b2)-heavy Binomial form. Let Y = \u2211\ni Yi. If max0\u2264\u2113\u2264n |FY (\u2113) \u2212 F\u0302X(\u2113)| \u2264 2\u01eb\u03b2 + \u01eb\u03b1 then the H-test accepts Y, otherwise it rejects Y.\nLike the \u2206-test, the H-test can be performed in poly(1/\u01eb) time. We now prove:\nLemma 17 (Correctness of the H-test) Suppose that X is not \u01eb\u03b2-close to any point in S\u01eb\u03b2 of the sparse form. Let Y = {Yi}i \u2208 S\u01eb\u03b2 be of the k(\u01eb\u03b2)-heavy Binomial form, and let Y = \u2211 i Yi. If Y is accepted by the H-test, then dTV(X, Y) \u2264 4\u01eb\u03b1 + O(\u01eb\u03b2). On the other hand, if dTV(X, Y)) \u2264 \u01eb\u03b2, then Y is accepted by the H-test.\nProof of Lemma 17: Since X is not \u01eb\u03b2-close to any sparse point in the cover, it follows from Theorem 9 that there exists a collection X\u2032 := {X\u2032i }i \u2208 S in the k(\u01eb \u03b2)-heavy Binomial form such that X := \u2211\ni Xi and X\u2032 := \u2211 i X \u2032 i are within \u01eb\n\u03b2 in total variation distance. Suppose that Y passes the H-test. For all \u2113, we have |FY(\u2113) \u2212 FX(\u2113)| \u2264 |FY(\u2113) \u2212 F\u0302X(\u2113)| + |F\u0302X(\u2113) \u2212 FX(\u2113)|,\nand hence dK(X, Y) \u2264 2\u01eb\u03b2 + 2\u01eb\u03b1. Given this, we have\ndTV(X, Y) \u2264 dTV(X, X \u2032) + dTV(X \u2032, Y) (using the triangle inequality)\n\u2264 \u01eb\u03b2 + dTV(X \u2032, Y)\n\u2264 \u01eb\u03b2 + 2dK(X\u2032, Y) + O(1/k(\u01eb\u03b2)) (using Lemma 15)\n\u2264 2dK(X\u2032, Y) + O(\u01eb\u03b2) (since Theorem 9 gives 1/k(\u01eb\u03b2) = O(\u01eb\u03b2))\n\u2264 2dK(X\u2032, X) + 2dK(X, Y) + O(\u01eb\u03b2) (using the triangle inequality)\n\u2264 4dTV(X\u2032, X) + 2dK(X, Y) + O(\u01eb\u03b2) (using that dK \u2264 2 \u00b7 dTV )\n\u2264 2dK(X, Y) + O(\u01eb\u03b2) \u2264 4\u01eb\u03b1 + O(\u01eb\u03b2).\nOn the other hand, if dTV(X, Y)) \u2264 \u01eb\u03b2, it follows that dK(X, Y)) \u2264 2\u01eb\u03b2. Hence, for all \u2113,\n|FY (\u2113) \u2212 F\u0302X(\u2113)| \u2264 |FY(\u2113) \u2212 FX(\u2113)| + |F\u0302X(\u2113) \u2212 FX(\u2113)|\n\u2264 dK(X, Y) + \u01eb \u03b1 \u2264 2dTV(X, Y) + \u01eb \u03b1 \u2264 2\u01eb\u03b2 + \u01eb\u03b1.\nHence, Y is accepted by the H-test."}, {"heading": "4.2.3 Finishing the Proof of Theorem 10", "text": "Let c\u0302 be the constant hidden in the O(\u00b7)-notation in the statement of Lemma 17. We may assume that \u01eb is smaller than any fixed constant, and hence that it satisfies \u01eb \u2265 4\u01eb\u03b1 + c\u0302 \u00b7 \u01eb\u03b2 as well as (2). We now describe the algorithm promised in Theorem 10. The algorithm takes as input the estimates {F\u0302X(\u2113)}n\u2113=0 (which, as described at the beginning of the proof, can be obtained from the samples from X using Theorem 7).\nAlgorithm\n1. Compute the cover S\u01eb\u03b2 defined in Theorem 9.\n2. If any Y \u2208 S\u01eb\u03b2 in the sparse form passes the \u2206-test, output such a Y and halt.\n3. Otherwise, if any Y \u2208 S\u01eb\u03b2 in the k(\u01eb\u03b2)-heavy Binomial form passes the H-test, output such a Y. It follows from Theorem 9 that there exists some {Yi}i \u2208 S\u01eb\u03b2 such that \u2211 i Yi is within \u01eb \u03b2 in total variation\ndistance from \u2211\ni Xi. If there exists such an element in the cover that is also in the sparse form, it follows from Lemma 14 that this point will pass the test at the second test of the algorithm and hence be returned in the output. On the other hand, any element {Yi}i of the cover returned by the second step of the algorithm will satisfy that \u2211 i Yi is within \u01eb in total variation distance from \u2211 i Xi. If the second step of the algorithm fails to return any element of the cover, it follows that X has an \u01eb\u03b2-neighbor in the cover in heavy Binomial form. Lemma 17 implies then that such a neighbor will be output in the third step of the algorithm. Moreover, the lemma implies that any element returned in the third step is an \u01eb-neighbor of X. Hence the algorithm is correct and always succeeds in returning an \u01eb-neighbor of X. Finally, the running time is dominated by the time to run the \u2206-test or the H-test on each point in the coverS\u01eb\u03b2 , which is easily seen to be n3\u00b7poly(1/\u01eb)+n\u00b7(1/\u01eb)O(log 2 1/\u01eb). This concludes the proof of Theorem 10 and thus also of Theorem 4."}, {"heading": "4.3 Proof of Claims 11 and 12", "text": "Recall that Y = \u2211\ni Yi where Y := {Yi} n i=1 \u2208 S\u01eb\u03b2 is of the sparse form, as defined in statement of Theorem 9.\nRecall Claim 11:\nClaim 11 If dTV(X, Y) \u2265 \u01eb, then \u2206Y \u2265 \u01eb \u2212 2(c\u01eb)\u22123\u03b2 \u00b7 \u01eb\u03b1.\nProof of Claim 11: By the definition of the total variation distance, the hypothesis implies\n1 2\n\u2211\nz\n| fY (z) \u2212 fX (z)| \u2265 \u01eb. (3)\nWe can bound the left hand side of the above as follows\u2211\nz\n| fY (z) \u2212 fX(z)| = \u2211\nz\u2208supp(Y)\n| fY (z) \u2212 fX(z)| + \u2211\nz<supp(Y)\n| fX(z)|\n\u2264 \u2211\nz\u2208supp(Y)\n| fY (z) \u2212 f\u0302X(z)| + \u2211\nz\u2208supp(Y)\n| fX(z) \u2212 f\u0302X (z)| + \u2211\nz<supp(Y)\n| fX(z)|\n\u2264 \u2211\nz\u2208supp(Y)\n| fY (z) \u2212 f\u0302X(z)| + 2(c\u01eb) \u22123\u03b2 \u00b7 \u01eb\u03b1 +\n\u2211\nz<supp(Y)\n| fX(z)|. (4)\nIn the last line of the above we used the bound on the support of Y and the fact that for all z \u2208 [n]:\n| fX(z) \u2212 f\u0302X(z)| = |(FX(z) \u2212 FX(z \u2212 1)) \u2212 (F\u0302X(z) \u2212 F\u0302X(z \u2212 1)|\n\u2264 |FX(z) \u2212 F\u0302X(z)| + |FX(z \u2212 1) \u2212 F\u0302X(z \u2212 1)| \u2264 2 \u00b7 \u01eb\u03b1,\nwhile | fX(0) \u2212 f\u0302X(0)| = |FX(0) \u2212 F\u0302X(0)| \u2264 \u01eb\u03b1. Finally, note that\n\u2211\nz\u2208supp(Y)\n| fX(z)| = \u2211\nz\u2208supp(Y)\n| f\u0302X(z) \u2212 ( f\u0302X(z) \u2212 fX (z))|\n\u2265 \u2211\nz\u2208supp(Y)\n(| f\u0302X(z)| \u2212 | f\u0302X(z) \u2212 fX(z)|).\nHence, \u2211\nz<supp(Y)\n| fX(z)| = 1 \u2212 \u2211\nz\u2208supp(Y)\n| fX(z)|\n\u2264 1 \u2212 \u2211\nz\u2208supp(Y)\n| f\u0302X(z)| + \u2211\nz\u2208supp(Y)\n| f\u0302X(z) \u2212 fX(z)|\n\u2264 1 \u2212 \u2211\nz\u2208supp(Y)\n| f\u0302X(z)| + 2(c\u01eb) \u22123\u03b2 \u00b7 \u01eb\u03b1. (5)\nUsing (3), (4), (5) we obtain that \u2206Y \u2265 \u01eb \u2212 2(c\u01eb)\u22123\u03b2 \u00b7 \u01eb\u03b1.\nRecall Claim 12:\nClaim 12 If dTV(X, Y) \u2264 \u01eb\u03b2, then \u2206Y \u2264 \u01eb\u03b2 + 2(c\u01eb)\u22123\u03b2 \u00b7 \u01eb\u03b1.\nProof of Claim 12: By definition of the total variation distance, the hypothesis implies\n1 2\n\u2211\nz\n| fY (z) \u2212 fX(z)| \u2264 \u01eb\u03b2.\nWe can bound the left hand side of the above as follows\u2211\nz\n| fY (z) \u2212 fX(z)| = \u2211\nz\u2208supp(Y)\n| fY (z) \u2212 fX(z)| + \u2211\nz<supp(Y)\n| fX(z)|\n\u2265 \u2211\nz\u2208supp(Y)\n| fY (z) \u2212 f\u0302X(z)| \u2212 \u2211\nz\u2208supp(Y)\n| fX(z) \u2212 f\u0302X (z)| + \u2211\nz<supp(Y)\n| fX(z)|\n\u2265 \u2211\nz\u2208supp(Y)\n| fY (z) \u2212 f\u0302X(z)| \u2212 2(c\u01eb)\u22123\u03b2 \u00b7 \u01eb\u03b1 + \u2211\nz<supp(Y)\n| fX(z)|.\nIn the last line of the above we used the same bound we used for deriving (4). Finally, note that\n\u2211\nz<supp(Y)\n| fX(z)| = 1 \u2212 \u2211\nz\u2208supp(Y)\n| fX(z)|\n\u2265 1 \u2212 \u2211\nz\u2208supp(Y)\n| f\u0302X(z)| \u2212 \u2211\nz\u2208supp(Y)\n| f\u0302X(z) \u2212 fX(z)|\n\u2265 1 \u2212 \u2211\nz\u2208supp(Y)\n| f\u0302X(z)| \u2212 2(c\u01eb) \u22123\u03b2 \u00b7 \u01eb\u03b1\nUsing the bounds above we obtain \u2206Y \u2264 \u01eb\u03b2 + 2(c\u01eb)\u22123\u03b2 \u00b7 \u01eb\u03b1."}, {"heading": "4.4 Proof of Lemma 15", "text": "Recall Lemma 15:\nLemma 15 Let X := {Xi}i and Y := {Yi}i be two collections of independent indicators in k-heavy Binomial form and set X = \u2211 i Xi, Y = \u2211 i Yi. Then\n1 2 dK(X, Y) \u2264 dTV (X, Y) \u2264 2 \u00b7 dK(X, Y) + O(1/k).\nProof of Lemma 15: The first inequality is immediate from the definition of the Kolmogorov and Total Variation distances. To show the other bound, let ZX , ZY \u2286 [n] be the indices of the variables in the collections {Xi}i and {Yi}i respectively that are deterministically zero, OX ,OY the indices of variables that are deterministically 1, and define EX = [n] \\ ZX \\ OX , EY = [n] \\ ZY \\ OY , n1 = |EX |, n2 = |EY |, and m = |OX | \u2212 |OY |. Moreover, let p1 be the common mean of the variables Xi, i \u2208 EX , and p2 the common mean of the variables in Yi, i \u2208 EY . Without loss of generality, we can assume that m \u2265 0. Now we define X\u2032 = m + Bin(n1, p1) and Y\u2032 = Bin(n2, p2). It is straightforward to check that\ndTV (X, Y) = dTV(X\u2032, Y\u2032)\nand dK(X, Y) = dK(X\u2032, Y\u2032).\nGiven that X and Y are in k-heavy Binomial form, it follows that for i = 1, 2:\n\u00b5i := ni \u00b7 pi \u2265 k2 \u2212 1 k ;\n\u03c32i := ni \u00b7 pi(1 \u2212 pi) \u2265 k 2 \u2212 k \u2212 1 \u2212 3 k .\nWe recall that the Translated Poisson distribution is defined as follows.\nDefinition 18 (Ro\u0308llin (2006)) We say that an integer random variable Y has a translated Poisson distribution with paremeters \u00b5 and \u03c32 and write L(Y) = T P(\u00b5, \u03c32) if L(Y \u2212 \u230a\u00b5 \u2212 \u03c32\u230b) = Poisson(\u03c32 + {\u00b5 \u2212 \u03c32}), where {\u00b5 \u2212 \u03c32} represents the fractional part of \u00b5 \u2212 \u03c32.\nGiven the above, and following Daskalakis (2008) (see Section 6.1), we can show the following for i = 1, 2:\ndTV ( Bin(ni, pi), T P(\u00b5i, \u03c32i ) ) = O(1/k). (6)\nNow we show the following:\nLemma 19 For \u03bb, \u03bb\u0302 > 0, m, m\u0302 \u2208 N0, let Y = m + Poisson(\u03bb) and Y\u0302 = m\u0302 + Poisson(\u0302\u03bb). Then\ndTV(Y, Y\u0302) \u2264 2dK(Y, Y\u0302).\nProof of Lemma 19: Without loss of generality assume that m\u2032 := m \u2212 m\u0302 \u2265 0. Then it is enough to compare Y\u2032 = m\u2032 + Poisson(\u03bb) and Y\u0302\u2032 = Poisson(\u0302\u03bb), since dTV(Y, Y\u0302) = dTV(Y\u2032, Y\u0302\u2032) and dK(Y, Y\u0302) = dK(Y\u2032, Y\u0302\u2032). For i \u2265 0, define\nRi := Pr[Y\u2032 = i]\nPr[Y\u0302\u2032 = i] .\nClearly, Ri = 0, for i = 0, 1, . . . ,m\u2032 \u2212 1, since Y\u2032 is not supported on that set. On the other hand for all i \u2265 m\u2032, we have\nRi := \u03bbi\u2212m\n\u2032 \u00b7e\u2212\u03bb\n(i\u2212m\u2032)!\n\u03bb\u0302i \u00b7e\u2212\u0302\u03bb i!\n,\nand for all i \u2265 m\u2032 + 1:\nRi Ri+1 = \u03bb\u0302 \u00b7 (i + 1 \u2212 m\u2032) \u03bb \u00b7 (i + 1) .\nLet us distinguish the following cases:\n\u2022 If \u03bb > \u03bb\u0302, then RiRi+1 < 1 for all i. Hence, Ri is increasing in i, so that it can change from a value \u2264 1 to a\nvalue \u2265 1 at most one time. Hence, there exists a single i\u2217 such that Pr[Y\u2032 = i] < Pr[Y\u0302\u2032 = i] for all i < i\u2217, and Pr[Y\u2032 = i] < Pr[Y\u0302\u2032 = i] for all i > i\u2217. In this case, it is easy to see that\ndTV(Y \u2032, Y\u0302\u2032) = dK(Y \u2032, Y\u0302\u2032).\n\u2022 If \u03bb = \u03bb\u0302 and m\u2032 = 0 the variables Y\u2032 and Y\u0302\u2032 are identically distributed so that their total variation distance and Kolmogorov distance are both identically 0. If \u03bb = \u03bb\u0302 and m\u2032 > 0, then RiRi+1 < 1 for all i and from our argument in the previous case we obtain\ndTV (Y\u2032, Y\u0302\u2032) = dK(Y\u2032, Y\u0302\u2032).\n\u2022 Finally, if \u03bb < \u03bb\u0302, then RiRi+1 \u2265 1 for all i \u2264 m\u2032\n1\u2212 \u03bb \u03bb\u0302\n\u2212 1 and RiRi+1 > 1 for all i > m\u2032\n1\u2212 \u03bb \u03bb\u0302\n\u2212 1. So Ri is increasing\nup to some i\u2217 and decreasing above i\u2217. So the distributions of Y\u2032 and Y\u0302\u2032 have at most two intersections. Hence, we obtain\ndTV(Y\u2032, Y\u0302\u2032) \u2264 2dK(Y\u2032, Y\u0302\u2032).\nGiven the above we have,\ndTV (X\u2032, Y\u2032) \u2261 dTV(m + Bin(n1, p1),Bin(n2, p2))\n\u2264 dTV ( m + Bin(n1, p1), m + T P(\u00b51, \u03c3 2 1) ) + dTV ( m + T P(\u00b51, \u03c3 2 1), T P(\u00b52, \u03c3 2 2) )\n+ dTV ( Bin(n2, p2), T P(\u00b52, \u03c3 2 2) )\n(using the triangle inequality)\n\u2264 O(1/k) + dTV ( m + T P(\u00b51, \u03c3 2 1), T P(\u00b52, \u03c3 2 2) )\n(using (6))\n\u2264 O(1/k) + 2dK ( m + T P(\u00b51, \u03c321), T P(\u00b52, \u03c3 2 2) )\n(using Lemma 19)\n\u2264 O(1/k) + 2dK ( m + Bin(n1, p1),m + T P(\u00b51, \u03c321) ) + 2dK ( Bin(n2, p2), T P(\u00b52, \u03c322) )\n+ 2dK (m + Bin(n1, p1), Bin(n2, p2)) (using the triangle inequality)\n\u2264 O(1/k) + 2dK (m + Bin(n1, p1), Bin(n2, p2)) (using that dK \u2264 2 \u00b7 dTV and (6)). = O(1/k) + 2dK ( X\u2032, Y\u2032 )\nThis concludes the proof of Lemma 15.\n5 An intermediate case: Linear transformation functions with O(1) distinct weights\nRecall that Theorem 2 shows that the exponential running time of Theorem 6 cannot be significantly improved even if the transformation function f is a degree-2 polynomial, and Theorem 3 shows that the O\u0303(n) sample complexity cannot be significantly improved even if f is a simple linear function. In contrast with these strong negative results, we have also seen that the sum-of-Bernoullis transformation function f (x) = \u2211n i=1 xi admits highly efficient algorithms both in terms of running time and sample complexity. We close this paper by showing that in an intermediate case \u2013 if the transformation function f is a linear function with constantly many different weights \u2013 then it is also possible to improve on the generic time and sample complexity bounds of Theorem 6, though not quite as dramatically as for sums of Bernoullis:\nTheorem 20 (Linear transformation functions with O(1) different weights) Let f (x) = \u2211n\ni=1 aixi be any function such that there are at most k different values in the set {a1, . . . , an}. Then there is an algorithm that uses k log(n) \u00b7 O\u0303(\u01eb\u22122) samples from the target distribution f (p), runs in time poly(nk \u00b7 \u01eb\u2212k log\n2(1/\u01eb)), and with probability at least 9/10 outputs a hypothesis vector p\u0302 such that dTV( f (p), f ( p\u0302)) \u2264 \u01eb.\nNote that setting a1 = \u00b7 \u00b7 \u00b7 = an = 1 in Theorem 20 gives a weaker result than Theorem 4 since the resulting sample complexity is log(n) \u00b7 O\u0303(\u01eb\u22122), whereas Theorem 4 gives a poly(1/\u01eb) sample complexity bound independent of n.\nProof of Theorem 20: We claim that the algorithm of Theorem 6 has the desired sample complexity and can be implemented to run in polynomial time.\nLet {b j}kj=1 denote the set of distinct weights and n j = \u2223\u2223\u2223i \u2208 [n] | ai = b j \u2223\u2223\u2223, where k = O(1). With this notation, we can write f (X) = \u2211k j=1 b jS j = g(S ), where S = (S 1, . . . , S k) with each S j a sum of n j many\nindependent Bernoulli random variables and g(y1, . . . , yk) = \u2211k j=1 b jy j. Clearly, \u2211k j=1 n j = n. By Theorem 9, S j has an explicit \u01eb-cover S j \u01eb of size |S j \u01eb | \u2264 n3j \u00b7 O(1/\u01eb) + n \u00b7 (1/\u01eb) O(log2 1/\u01eb). By independence across S j\u2019s, the product Q = \u220fk\nj=1 S j \u01eb is an \u01eb-cover for S , hence also for f (X). That is, f (X) has an explicit \u01eb-cover of size\n|Q| = \u220fk\nj=1 |S j \u01eb | \u2264 (n/k)3k \u00b7 (1/\u01eb)k\u00b7O(log 2 1/\u01eb). The sample complexity bound follows directly. It remains to argue about the time complexity. Note that the running time of the algorithm is O(|Q|2) times the running time of a competition. We will show that a competition between Q1,Q2 \u2208 Q can be efficiently computed. This amounts to efficiently computing the probabilities p1 = f (Q1)(W1) and q1 = f (Q2)(W1). Note that W = f ({0, 1}n) = \u2211k j=1 bi \u00b7 {0, 1, . . . , n j}. Clearly, |W| \u2264 \u220fk j=1(n j + 1) = O((n/k)\nk). It is thus easy to see that p1, q1 can be efficiently computed as long as there is an efficient algorithm for the following problem: given Q \u2208 Q and w \u2208 W, compute f (Q)(w). Indeed, fix any such Q, w. We have that f (Q)(w) =\u2211\nm1,...,mk \u220fk j=1 PrX\u223cQ[S j = m j], where the sum is over all k-tuples (m1, . . . ,mk) such that 0 \u2264 m j \u2264 n j for all j and b1m1 + \u00b7 \u00b7 \u00b7 + bkmk = w (as noted above there are at most O((n/k)k) such k-tuples). To complete the proof of Theorem 20 we note that PrX\u223cQ[S j = m j] can be computed in O(n2j) time by standard dynamic programming."}, {"heading": "6 Conclusion and open problems", "text": "We feel that the transformed product distribution learning model offers a rich field for further study, with many natural directions to explore. We close this paper with some specific questions and suggestions for future work.\nOptimally learning sums of Bernoullis? An obvious question is whether the competing advantages of Theorems 4 and 5 can be simultaneously achieved by a single algorithm: is there an algorithm to learn sums of Bernoullis that uses poly(1/\u01eb) samples and runs in poly(log n, 1/\u01eb) time?\nLearning weighted sums of Bernoullis? In Section 5 we observed that a poly(n)-time algorithm exists for any linear transformation function f (x1, . . . , xn) = \u2211n i=1 aixi in which there are only O(1) many different ai\u2019s.\nCan a poly(n)-time algorithm be obtained for every linear transformation function f (x) = \u2211n\ni=1 aixi, where (a1, . . . , an) is an arbitrary vector in Rn? What if each ai is a positive integer that is at most poly(n)?\nLearning when the transformation function is in NC0? Suppose that the transformation function f maps {0, 1}n to {0, 1}n, i.e. f = ( f1, . . . , fn), where each fi : {0, 1}n \u2192 {0, 1} is a k-junta \u2013 a function that depends only on k of the n input variables \u2013 for some constant k. Is the corresponding transformed product distribution learning problem solvable in poly(n, 1/\u01eb) time? We conjecture that the answer is yes. (Note that as suggested by the second example of the Introduction, an algorithm for a special case of this question (in which each fi is a particular (2k\u2212 1)-junta) yields a poly(n/\u01eb)-time algorithm for learning a mixture of k product distributions over {0, 1}n. This mixture learning problem is indeed known to be solvable in poly(n/\u01eb) time for constant k but the algorithm is somewhat involved, see Feldman et al. (2008).)\nWhen do O(1) samples information-theoretically suffice? Our main result in Section 4 shows that for the transformation function f (x) = \u2211n i=1 xi, the sample complexity required for learning to accuracy \u01eb is poly(1/\u01eb) independent of n. But as we show in Appendix D, the seemingly similar linear transformation function f (x) = \u2211n i=n/2+1 ixi requires \u2126(n) samples, which is close to the worst possible for any f . This disparity motivates the following question: what necessary or sufficient conditions can be given on a function f : {0, 1}n \u2192 R that cause the corresponding learning problem to have sample complexity depending only on \u01eb (independent of n)? More ambitiously, is there a quantitative measure of the \u201ccomplexity\u201d of a function f that gives a tight quantitative bound on the sample complexity of the product distribution learning problem for f ? The Vapnik-Chervonenkis dimension of a concept class C plays such a role in the PAC learning model, since it tightly characterizes the number of examples that are required to solve the learning problem for C. Is there an analogous measure of the \u201ccomplexity\u201d of a transformation f for our product distribution learning problem?"}, {"heading": "A Proof of Observation 1.1: AND-gate functions", "text": "Let p = (p1, . . . , pn) be the unknown target vector of probabilities. For each i \u2208 [m] let Pi denote the true probability PrX[ fi(X) = 1] where the probability is over X drawn from the product distribution p. Using poly(n, 1/\u01eb) random samples of f (X) it is straightforward to obtain upper and lower bounds 0 \u2264 Pi,\u2212 < Pi,+ \u2264 1 such that Pi,+ \u2212 Pi,\u2212 \u2264 \u01ebn and with probability at least 9/10, every i \u2208 [m] has Pi,\u2212 \u2264 Pi \u2264 Pi,+.\nFor each i \u2208 [m] we have that the function fi(x) is \u2227 i\u2208S i xi; by independence we have\nPi = \u220f\ni\u2208S i\npi and thus log Pi = \u2211\ni\u2208S i\nlog pi.\nUsing the bounds Pi,\u2212 and Pi,+ it is straightforward to set up a system of linear inequalities in variables q1, . . . , qn where each qi plays the role of log pi, i.e. for a given i we have the inequalities\nlog Pi,\u2212 \u2264 \u2211\ni\u2208S i\nqi \u2264 log Pi,+.\n(We also include the inequalities qi \u2264 0 for each i since the pi\u2019s must be probabilities, i.e. values at most 1.) With probability at least 9/10 the system is feasible (since setting each qi to be log pi gives a feasible solution), so we can use polynomial-time linear programming to obtain a feasible solution q\u03021, . . . , q\u0302n. The corresponding product distribution p\u0302 = ( p\u03021, . . . , p\u0302n) where p\u0302i = 2q\u0302i has the property that for each i, we have | PrX\u223cp\u0302[ fi(X) = 1] \u2212 Pi| \u2264 \u01ebm . A simple argument (using independence between the different fi(X)\u2019s, which holds since the sets S i are pairwise disjoint) then shows that the total variation distance dTV( f ( p\u0302), f (p)) is at most \u01eb, and Observation 1.1 is proved."}, {"heading": "B Proof of Theorem 6: A tournament between distributions in a cover", "text": "Recall Theorem 6:\nTheorem 6 Fix a function f : {0, 1}n \u2192 \u2126 where \u2126 is any range set. Suppose there exists a \u03b4-cover for f (S) of size N = N(n, \u03b4). Then there is an algorithm that uses O(\u03b4\u22122 log N) samples and solves the f -transformed product distribution learning problem to accuracy 6\u03b4.\nProof: Let P \u2208 S be the input distribution fed to the circuit f . We will describe an algorithm that, given m = O(\u03b4\u22122 log N) independent samples s = {si}mi=1 from f (P), finds a distribution Q\n\u2217 \u2208 S that satisfies dTV( f (P), f (Q\u2217)) \u2264 6\u03b4 with probability at least 9/10.\nRecall that the high-level idea of the proof is as follows. For a pair of distributions Q1,Q2 \u2208 S, we will define a competition between Q1 and Q2 that takes as input the sample s and either crowns one of Q1,Q2 as the winner of the competition or calls the competition a draw. Let Q \u2286 S be a \u03b4-cover for f (S) of cardinality N = N(n, \u03b4). The algorithm performs a tournament between every pair of distributions from Q and outputs a distribution Q\u2217 \u2208 Q that was never a loser (i.e. won or was a draw in all competitions). If no such distribution exists, the algorithm outputs \u201cfailure.\u201d\nTo describe the competition procedure between two distributions Q1,Q2 \u2208 S, we define the following partition of the range space W = f ({0, 1}n) \u2286 \u2126:\nW1 := {w \u2208 W | f (Q1)(w) \u2265 f (Q2)(w)}; W2 := W\\W1.\nLet p1 = f (Q1)(W1) and q1 = f (Q2)(W1), and define p2 = 1 \u2212 p1 and q2 = 1 \u2212 q1. Clearly, p1 \u2265 q1 and p2 < q2. Moreover, dTV( f (Q1), f (Q2)) = p1 \u2212 q1. Finally, let T (s) = 1m |{i | si \u2208 W1}| be the fraction of samples falling in the set W1. The outcome of the competition between Q1 and Q2 is decided as follows:\n\u2022 If p1 \u2212 q1 \u2264 5\u03b4, return \u201cdraw\u201d;\n\u2022 else if T (s) > p1 \u2212 32\u03b4, return Q1;\n\u2022 else if T (s) < q1 + 32\u03b4, return Q2;\n\u2022 else return \u201cdraw\u201d.\nObserve that the outcome of the competition does not depend on the ordering of the pair of distributions given in the input; i.e. on inputs (Q1,Q2) and (Q2,Q1) the competition outputs the same result for a fixed sequence of samples s1, . . . , sm.\nWe now prove correctness. Our first lemma quantifies the following intuitive fact: If f (Q1) is \u201cclose\u201d to f (P) while f (Q2) is \u201cfar\u201d from f (P), then with very high probability over the sample Q1 will be the winner of the competition.\nLemma 21 Let Q1 \u2208 S be such that dTV( f (P), f (Q1)) \u2264 \u03b4. (i) If Q2 \u2208 S is such that dTV( f (P), f (Q2)) > 6\u03b4, the probability that the competition between Q1 and Q2 does not return Q1 as the winner is at most e\u2212m\u03b4 2/8.\n(ii) If Q2 \u2208 S is such that dTV( f (P), f (Q2)) > 4\u03b4, the probability that the competition between Q1 and Q2 returns Q2 as the winner is at most e\u2212m\u03b4 2/8.\nProof: Let r denote f (P)(W1). The definition of the total variation distance implies that |r \u2212 p1| \u2264 \u03b4. Let us define the 0/1 (indicator) random variables {Zi}mi=1, as Zi = 1 iff si \u2208 W1. Clearly, T (s) = 1 m \u2211m i=1 Zi and E[T ] = E[Zi] = r. Since the Zi\u2019s are mutually independent, it follows from the Chernoff bound that Pr[T \u2264 r \u2212 \u03b4/2] \u2264 e\u2212m\u03b4 2/8. Using |r \u2212 p1| \u2264 \u03b4 we get that Pr[T \u2264 p1 \u2212 3\u03b4/2] \u2264 e\u2212m\u03b4 2/8.\nWe prove part (i) first. Since dTV ( f (P), f (Q2)) > 6\u03b4, the triangle inequality implies that p1 \u2212 q1 = dTV( f (Q1), f (Q2)) > 5\u03b4. Hence, with probability at least 1 \u2212 e\u2212m\u03b4\n2/8 the competition between Q1 and Q2 will output Q1 as the winner.\nNow we prove part (ii). If p1 \u2212 q1 \u2264 5\u03b4 then the competition returns \u201cdraw\u201d and Q2 is not the winner. If p1 \u2212 q1 > 5\u03b4 then the above implies that the competition between Q1 and Q2 will output Q2 as the winner with probability at most e\u2212m\u03b4 2/8.\nOur second lemma completes the proof of Theorem 6.\nLemma 22 If m = \u2126(\u03b4\u22122 log N), then with probability at least 9/10 the tournament outputs some distribution Q\u2217 \u2208 Q such that dTV ( f (Q\u2217), f (P)) \u2264 6\u03b4.\nProof: Since Q is a \u03b4-cover of f (S), there exists Q\u0303 \u2208 Q such that dTV( f (Q\u0303), f (P)) \u2264 \u03b4. We first argue that with high probability this distribution Q\u0303 never loses a competition against any other Q\u2032 \u2208 Q (so the tournament does not output \u201cfailure\u201d). Consider any Q\u2032 \u2208 Q. If dTV( f (P), f (Q\u2032)) > 4\u03b4, by Lemma 21(ii) the probability that Q\u0303 loses to Q\u2032 is at most e\u2212m\u03b4\n2/8 = O(1/N). On the other hand, if dTV( f (P), f (Q\u2032)) \u2264 4\u03b4, the triangle inequality gives that dTV( f (Q\u0303), f (Q\u2032)) \u2264 5\u03b4 and thus Q\u0303 draws against Q\u2032. A union bound over all N distributions in Q shows that with probability 19/20, the distribution Q\u0303 never loses a competition.\nWe next argue that with probability at least 19/20, every distribution Q\u2032 \u2208 Q that never loses has f (Q\u2032) close to f (P). Fix a distribution Q\u2032 such that dTV( f (Q\u2032), f (P)) > 6\u03b4; Lemma 21(i) implies that Q\u2032 loses to Q\u0303 with probability 1\u2212e\u2212m\u03b4\n2/8 = 1\u2212O(1/N). A union bound gives that with probability 19/20, every distribution Q\u2032 that has dTV( f (Q\u2032), f (P)) > 6\u03b4 loses some competition.\nThus, with overall probability at least 9/10, the tournament does not output \u201cfailure\u201d and outputs some distribution Q\u2217 such that dTV ( f (P), f (Q\u2217)) is at most 6\u03b4. This proves Lemma 22 and Theorem 6."}, {"heading": "C Learning transformed product distributions can be computationally hard", "text": "Recall Theorem 2:\nTheorem 2 Suppose NP * BPP. Then there is an explicit degree-2 polynomial f (given in Equation (7) below) such that there is no polynomial-time algorithm that solves the transformed product distribution learning problem for f to accuracy \u01eb = 1/3.\nProof: The function f is quite simple. It takes m = n2 + n bits of input\n(w, s) = (w1,1, . . . , w1,n, w2,1, . . . , w2,n, . . . , wn,1, . . . , wn,n, s1, . . . , sn).\nHere we think of each n-bit substring wi,1 . . . wi,n \u2208 {0, 1}n as the binary representation of the number Wi =\u2211n j=1 2\nn\u2212 jwi, j \u2208 {0, 1, . . . , 2n \u2212 1}. We think of s1, . . . , sn as representing a subset S \u2286 [n], where i \u2208 S if and only if si = 1. The function f (w, s) is defined to be\nf (w, s) = n\u2211\ni=1 22inWn+1\u2212i + n\u2211 i=1 Wi(2si \u2212 1) (7)\nwhich is easily seen to be a degree-2 polynomial. Recall that an input to the NP-complete PARTITION problem is a list of n numbers W1, . . . ,Wn. The input\nis a yes-instance if there is a set S \u2286 [n] such that \u2211 i\u2208S Wi = \u2211\ni<S Wi ( equivalently, if there is a bitstring (s1, . . . , sn) such that \u2211n i=1 Wi(2si \u2212 1) = 0).\nIt is easy to see from the definition of f that the output number f (w, s) can be viewed (reading from most significant bit to least significant bit) as specifying\n\u2022 the n numbers W1, . . . ,Wn; and \u2022 the value \u2211n\ni=1 Wi(2si \u2212 1) of the candidate solution S \u2286 [n]. Note that this value is 0 if and only if S is a legitimate solution to the PARTITION instance specified by (W1, . . . ,Wn).\nSo we may view the input to f as the tuple (W1, . . . ,Wn, S ) and its corresponding output as the tuple (W1, . . . ,Wn, v) where v = \u2211n i=1 Wi(2si \u2212 1) \u2208 N is the value of the candidate solution S .\nThe proof is by contradiction, so let us suppose that L is a learning algorithm that runs in polynomial time and learns to accuracy \u01eb = 1/3. For any \u201ctarget distribution\u201d p \u2208 [0, 1]m, if L is given access to q(n) = poly(n) many independent draws from f (p), then with probability 9/10 algorithm L outputs a vector p\u0302 = ( p\u03021, . . . , p\u0302m) of probabilities s.t. the total variation distance dTV( f (p), f ( p\u0302)) is at most 1/3.\nWe now explain how L yields a randomized poly(n)-time algorithm A to solve PARTITION. Given a PARTITION instance (W1, . . . ,Wn) as input, algorithm A runs L on a data set consisting of q(n) copies of the tuple (W1, . . . ,Wn, 0). If L fails to return a vector p\u0302 then A outputs \u201cno\u201d (meaning that the PARTITION instance has no solution). If L returns a vector p\u0302 then:\n\u2022 A checks that \u220fn2\ni=1 max{p\u0302i, 1 \u2212 p\u0302i} \u2265 2/3; if not it returns \u201cno.\u201d\n\u2022 If A reaches this step, for each i \u2208 [n2] let bi be the result of rounding p\u0302i to the nearest integer (0 or 1) and let (W\u20321, . . . ,W \u2032 n) be the PARTITION instance represented by the string (b1, . . . , bn2). A checks that\n(W\u20321, . . . ,W \u2032 n) is identical to (W1, . . . ,Wn); if not it outputs \u201cno.\u201d\n\u2022 If A reaches this step, then A draws 100 random n-bit strings x1, . . . , x100 independently from the product distribution ( p\u0302n2+1, . . . , p\u0302n2+n) and evaluates \u2211n i=1 W \u2032 i (2xi \u2212 1) on each of them. If any evaluation yields 0\nthen A outputs \u201cyes\u201d and otherwise it evaluates \u201cno.\u201d\nWe now prove correctness. Suppose first that (W1, . . . ,Wn) is a yes-instance of PARTITION. With probability 1 the data set consisting of q(n) copies of (W1, . . . ,Wn, 0) is identical to the outcome of q(n) draws from the distribution f (p\u22c6), where each coordinate of p\u22c6 is either 0 or 1, the first n2 coordinates p\u22c61 , . . . , p \u22c6 n2\nencode the numbers (W1, . . . ,Wn), and the last n coordinates encode a legitimate solution S for (W1, . . . ,Wn). Thus, with probability at least 9/10 the algorithm L outputs a vector p\u0302 = ( p\u03021, . . . , p\u0302m) s.t. dTV( f ( p\u0302), f (p\u22c6)) \u2264 1/3. Since f (p\u22c6) puts all its weight on one output string (W1, . . . ,Wn, 0), it must indeed be the case that \u220fn2 i=1 max{p\u0302i, 1 \u2212 p\u0302i} \u2265 2/3, and it is easy to see that the string b = (b1, . . . , bn2 ) defined in the second bullet will be identical to (W1, . . . ,Wn). Thus (W\u20321, . . . ,W \u2032 n) is identical to (W1, . . . ,Wn), and A makes it through the second bullet. Finally, since dTV( f ( p\u0302), f (p\u22c6)) \u2264 1/3, in expectation at least 2/3 of the 100 strings independently drawn from ( p\u0302n2+1, . . . , p\u0302m) should be legitimate solutions, and the probablity that none of x1, . . . , x100 is a legitimate solution is at most 0.001. Thus, if (W1, . . . ,Wn) is a yes-instance of PARTITION, the overall probability that A outputs \u201cyes\u201d is at least 0.89.\nNow suppose that (W1, . . . ,Wn) is a no-instance of PARTITION, but that A outputs \u201cyes\u201d on (W1, . . . ,Wn) with probability at least 0.1. This means that with probability at least 0.1, L outputs a vector p\u0302 such that\u220fn2\ni=1 max{p\u0302i, 1 \u2212 p\u0302i} \u2265 2/3, which can be uniquely decoded into a PARTITION instance (W \u2032 1, . . . ,W \u2032 n) which must equal (W1, . . . ,Wn). The PARTITION instance (W\u20321, . . . ,W \u2032 n) = (W1, . . . ,Wn) must be satisfied with probability at least 1/1000 by a random string drawn from the probability distribution ( p\u0302n+1, . . . , p\u0302m) (for otherwise the probability of a \u201cyes\u201d output would be less than 1/10). But this violates the assumption that (W1, . . . ,Wn) is a no-instance. So if (W1, . . . ,Wn) is a no-instance of PARTITION, then it must be the case that A outputs \u201cno\u201d on (W1, . . . ,Wn) with probability less than 0.1.\nThus we have shown that A is a BPP algorithm for the PARTITION problem, and Theorem 2 is proved.\nD Proof of Theorem 3: f (x) = \u2211k\ni=k/2+1 ixi requires \u2126(k) samples\nWe define a probability distribution over problem instances (i.e. target probability vectors p) as follows: A subset S \u2282 {k/2+1, . . . , k} of size |S | = k/100 is drawn uniformly at random, i.e. each of the ( k/2\nk/100\n) outcomes\nfor S is equally likely. For each i \u2208 S the value pi equals 100/k = 1/|S |, and for all other i the value pi equals 0. We will need two easy lemmas:\nLemma 23 Fix any S , p as described above. For any j \u2208 {k/2 + 1, . . . , k} we have f (p)( j) , 0 if and only if j \u2208 S . For any j \u2208 S the value f (p)( j) is exactly (100/k)(1 \u2212 100/k)k/100\u22121 > 35/k (for k sufficiently large), and similarly f (p)({k/2 + 1, . . . , k}) > 0.35 (again for k sufficiently large).\nThe first claim of the lemma holds because any set of c \u2265 2 numbers from {k/2 + 1, . . . , k} must sum to more than k. The second claim holds because the only way a draw of X from p can have f (X) = j is if X j = 1 and all other Xi are 0 (and uses limx\u21900+ (1 \u2212 1/x)x = 1/e).\nThe next lemma is an easy consequence of Chernoff bounds:\nLemma 24 Fix any p as defined above, and consider a sequence of k/2000 independent draws of X from p. With probability 1 \u2212 e\u2212\u2126(k) the total number of indices j \u2208 [k] such that X j = 1 in any of the k/2000 draws is at most k/1000.\nProof of Theorem 3: Let L be a learning algorithm that receives k/2000 samples. Let S \u2282 {k/2 + 1, . . . , k} and the target distribution p be chosen randomly as defined above.\nWe consider an augmented learner L\u2032 that is given \u201cextra information.\u201d For each point f (X) in the sample, instead of receiving f (X) = \u2211k i=k/2+1 iXi, the learner L\n\u2032 is given the entire vector (X1, . . . , Xk) \u2208 {0, 1}k. Let T denote the set of elements j \u2208 {k/2+1, . . . , k} for which the learner is given some vector X that has X j = 1. By Lemma 24 we have |T | \u2264 k/1000 with probability at least 1 \u2212 e\u2212\u2126(k); we condition on the event |T | \u2264 k/1000 going forth.\nFix any value \u2113 \u2264 k/1000. Conditioned on |T | = \u2113, the set T is equally likely to be any \u2113-element subset of S , and all possible \u201ccompletions\u201d of T with an additional k/100\u2212\u2113 \u2265 9k/1000 elements of {k/2+1, . . . , k}\\T are equally likely to be the true set S .\nLet p\u0302 = ( p\u03021, . . . , p\u0302k) denote the hypothesis vector of probabilities that L\u2032 outputs. Let R denote the set {k/2 + 1, . . . , k} \\ T ; note that since |T | = \u2113 \u2264 k/1000, we have |R| \u2265 499k/1000. We consider two possible cases for p\u0302 and show that in either case the learner\u2019s hypothesis distribution f ( p\u0302) has high error (in the first case because of outcomes in R, in the second case because of the outcome 0) with high probability.\nCase 1: Fewer than k/4 of the (at least 499k/1000) elements i \u2208 R have p\u0302i \u2265 10/k. Let U be the set of those (fewer than k/4) elements. Since every (k/100 \u2212 \u2113)-element subset of R is equally likely to be the correct completion S \\T , and as observed above k/100\u2212\u2113 is at least 9k/1000, an elementary argument shows that with probability 1\u2212 e\u2212\u2126(k) we have that U contains at most 8k/1000 of the k/100\u2212 \u2113 \u2265 9k/1000 elements of S \\T. Assuming this happens, Lemma 23 now implies that each of the (at least) k/1000 \u201cmissed\u201d elements (that are in S \\ T but not in U) contributes at least 35/k \u2212 10/k > 25/k to the total variation distance between f (p) and f ( p\u0302). (This is because each point in (S \\ T ) \\ U has probability at most 10/k under f ( p\u0302); the only way to get such an outcome i from f ( p\u0302) is for the draw of X\u0302 from p\u0302 to have X\u0302i = 1, which occurs with probability 10/k.) So in this case dTV( f (p, f ( p\u0302)) is at least 25/1000 = 1/40.\nCase 2: At least k/4 of the (at least 499k/1000) elements i \u2208 R have p\u0302i \u2265 10/k. In this case, we have f ( p\u0302)(0) \u2264 (1 \u2212 10/k)k/4 < 1/10. Since the target distribution f (p) has f (p)(0) = (1 \u2212 100/k)k/100 > 0.35, it follows that dTV( f (p), f ( p\u0302)) \u2265 1/4 in this case."}, {"heading": "E A Simple Proof of the DKW Inequality", "text": "Recall the framework of the DKW inequality: X is any random variable supported on {0, 1, . . . , n}. Z1, . . . , Zk are independent copies of X, and Z(\u2113)i is defined to be 1Zi\u2264\u2113, for all \u2113 = 0, . . . , n and i = 1, . . . , k. Finally, define F\u0302X(\u2113) := \u2211 i Z (\u2113) i /k.\nWe prove:\nTheorem 7 (DKW Inequality) Let k = max{576, (9/8) ln(1/\u03b4)} \u00b7 (1/\u01eb2). Then with probability at least 1 \u2212 \u03b4 we have\nmax 0\u2264\u2113\u2264n\n\u2223\u2223\u2223F\u0302X(\u2113) \u2212 FX(\u2113) \u2223\u2223\u2223 \u2264 \u01eb.\nWe first prove the following weaker version of the inequality:\nTheorem 25 Let k = 4 \u03b4\u01eb2 . Then with probability at least 1 \u2212 \u03b4 we have\nmax 0\u2264\u2113\u2264n\n\u2223\u2223\u2223F\u0302X(\u2113) \u2212 FX(\u2113) \u2223\u2223\u2223 \u2264 \u01eb.\nProof of Theorem 25: Let L be the smallest index in {0, . . . , n} such that 12 < FX(L). We first show the following.\nLemma 26 Let k = 1 \u01eb2c , where c > 0. Then\nPr [\nmax 0\u2264\u2113\u2264L\u22121\n\u2223\u2223\u2223F\u0302X(\u2113) \u2212 FX(\u2113) \u2223\u2223\u2223 > \u01eb ] \u2264 2c.\nProof of Lemma 26: If L = 0 the statement is vacuously true. If L > 0, let us denote \u039b\u2113 := F\u0302X(\u2113) \u2212 FX(\u2113), for \u2113 = 0, . . . ,L \u2212 1, and define\n\u2126\u22121 := 0\n\u2126\u2113 :=  \u039b\u2113 1\u2212FX (\u2113) , if \u039b j \u2264 \u01eb for all 0 \u2264 j \u2264 \u2113 \u2212 1\n\u2126\u2113\u22121, otherwise , for \u2113 = 0, . . . ,L \u2212 1.\nAlso, define \u2126\u2217 \u22121 = 0 and \u2126 \u2217 \u2113 := \u039b\u21131\u2212FX (\u2113) , for \u2113 = 0, . . . ,L \u2212 1.\nClaim 27 Both {\u2126\u2217 \u2113 }\u2113=\u22121,...,L\u22121 and {\u2126\u2113}\u2113=\u22121,...,L\u22121 are martingale sequences.\nProof: Clearly, E [ \u2126\u22170 ] = 0 = E [\u21260]. Moreover, for \u2113 = 1, . . . ,L \u2212 1:\nE [ \u039b\u2113 \u039b\u2113\u22121 =\nm k \u2212 FX(\u2113 \u2212 1)\n] =\nm k + k \u2212 m k Pr[Z1 = \u2113 | Z1 \u2265 \u2113] \u2212 FX(\u2113)\n= m k + k \u2212 m k FX(\u2113) \u2212 FX(\u2113 \u2212 1) 1 \u2212 FX(\u2113 \u2212 1) \u2212 FX(\u2113) = 1 \u2212 FX(\u2113)\n1 \u2212 FX(\u2113 \u2212 1) \u00b7 [m k \u2212 FX(\u2113 \u2212 1) ]\n= 1 \u2212 FX(\u2113)\n1 \u2212 FX(\u2113 \u2212 1) \u00b7 \u039b\u2113\u22121.\nIt follows that the sequence {\u2126\u2217 \u2113 }\u2113=\u22121,...,L\u22121 is a martingale sequence. Hence, {\u2126\u2113}\u2113=\u22121,...,L\u22121 is also a martingale sequence.\nNote that\nL\u22121\u2211\n\u2113=0\nE [ (\u2126\u2113 \u2212\u2126\u2113\u22121)2 ] = L\u22121\u2211\n\u2113=0\nE [ (\u21262\u2113 + \u2126 2 \u2113\u22121 \u2212 2\u2126\u2113\u2126\u2113\u22121 ]\n=\nL\u22121\u2211\n\u2113=0\nE [ (\u21262\u2113 + \u2126 2 \u2113\u22121 \u2212 2(\u2126\u2113 \u2212\u2126\u2113\u22121 + \u2126\u2113\u22121)\u2126\u2113\u22121 ]\n=\nL\u22121\u2211\n\u2113=0\nE [ (\u21262\u2113 \u2212\u2126 2 \u2113\u22121 \u2212 2(\u2126\u2113 \u2212\u2126\u2113\u22121)\u2126\u2113\u22121 ]\n= E [ \u21262L\u22121 ] \u2212 E [ \u21262\u22121 ] \u2212 L\u22121\u2211\n\u2113=0\n2E [(\u2126\u2113 \u2212\u2126\u2113\u22121)\u2126\u2113\u22121]\n= E [ \u21262L\u22121 ] \u2212 E [ \u21262\u22121 ] = E [ \u21262L\u22121 ] ,\nwhere in the second to last line we used the martingale property and in the last line we used that \u2126\u22121 = 0. The same analysis holds true for the martingale sequence \u2126\u2217\n\u2113 giving:\nL\u22121\u2211\n\u2113=0\nE [ (\u2126\u2217\u2113 \u2212\u2126 \u2217 \u2113\u22121) 2 ] = E [ (\u2126\u2217L\u22121) 2 ] .\nIn particular, the above imply that E [ (\u2126L\u22121)2 ] \u2264 E [ (\u2126\u2217 L\u22121) 2 ] . Now we have:\nPr[max \u2113 \u039b\u2113 > \u01eb] \u2264 Pr\n[ \u2126L\u22121 >\n\u01eb\n1 \u2212 FX(0)\n]\n\u2264 Pr [ \u2126L\u22121 > \u01eb ]\n\u2264 1 \u01eb2\nE [ \u21262L\u22121 ]\n\u2264 1 \u01eb2\nE [ (\u2126\u2217L\u22121) 2 ]\n= 1 \u01eb2 \u00b7 1 (1 \u2212 FX(L \u2212 1))2 \u00b7 E\n[ (\u039bL\u22121)2 ]\n= 1 \u01eb2 \u00b7 1 (1 \u2212 FX(L \u2212 1))2 \u00b7 Var[\u039bL\u22121] \u2264 4 \u01eb2 \u00b7 Var[\u039bL\u22121]\n\u2264 4 \u01eb2 \u00b7 Var\n \u2211 i Z (L\u22121) i\nk\n\n= 4 \u01eb2 \u00b7 1 k FX(L \u2212 1) \u00b7 (1 \u2212 FX(L \u2212 1)) \u2264 1 \u01eb2 \u00b7 1 k\nConsidering the random variables \u039b\u2032 \u2113 := \u2212\u039b\u2113 and repeating the analysis above, we can establish in a similar fashion that\nPr[min \u2113 \u039b\u2113 < \u2212\u01eb] \u2264 1 \u01eb2 \u00b7 1 k .\nCombining the above together with a union bound completes the proof of the lemma.\nNow let us denote by L\u2032 the smallest index in {0, . . . , n} such that 1/2 < 1 \u2212 FX(n \u2212 L\u2032 \u2212 1). Applying Lemma 26 to the random variable n \u2212 X we obtain the following.\nLemma 28 Let k = 1 \u01eb2c , where c > 0. Then\nPr [\nmax n\u2212L\u2032\u2264\u2113\u2264n\u22121\n\u2223\u2223\u2223F\u0302X(\u2113) \u2212 FX(\u2113) \u2223\u2223\u2223 > \u01eb ] \u2264 2c.\nRecall that FX(L) > 1/2 > FX(n \u2212 L\u2032 \u2212 1). Hence, L > n \u2212 L\u2032 \u2212 1, which implies that L \u2212 1 \u2265 n \u2212 L\u2032 \u2212 1.\nThis observation, a union bound and Lemmas 26 and 28 (applied for c = \u03b4/4) imply Theorem 25.\nWe are now ready to prove the actual DKW inequality. Let M denote the random variable\nmax 0\u2264\u2113\u2264n |\u039b\u2113| = max 0\u2264\u2113\u2264n\n\u2223\u2223\u2223F\u0302X(\u2113) \u2212 FX(\u2113) \u2223\u2223\u2223 .\nSince M is defined by the outcomes of Z1, . . . , Zk, we can write M = g(Z1, . . . , Zk), for some function g : Rk \u2192 R. It is also easy to see that g(Z1, . . . , Zk) is 1/k-Lipschitz as a function of its arguments Z1, . . . , Zk. Since the Zis are independent, we can apply McDiarmid\u2019s inequality to obtain\nPr [M \u2212 E[M] > \u01eb] \u2264 exp(\u22122\u01eb2k).\nBy repeated applications of Theorem 25 we show the following:\nClaim 29 Let k \u2265 256 \u01eb2 . Then\nEZ1 ,...,Zk [M] \u2264 \u01eb\n2 .\nProof of Claim 29: Note that M is supported in [0, 1]. We have\nE[M] \u2264 \u01eb\n4 \u00b7 Pr[0 \u2264 M \u2264 \u01eb/4] +\n\u2308log(4/\u01eb)\u2309\u2211\ni=1\n( 2i\u01eb 4 ) \u00b7 Pr[ 2i\u22121\u01eb 4 < M \u2264 2i\u01eb 4 ]\n\u2264 \u01eb\n4 +\n\u2308log(4/\u01eb)\u2309\u2211\ni=1\n( 2i\u01eb 4 ) \u00b7 Pr[M > 2i\u22121\u01eb 4 ]\n\u2264 \u01eb\n4 +\n\u2308log(4/\u01eb)\u2309\u2211\ni=1\n( 2i\u01eb 4 ) \u00b7 2\u22122i\n\u2264 \u01eb\n4 +\n\u221e\u2211\ni=1\n\u01eb\n4 \u00b7 2i =\n\u01eb\n2\nwhere we used Theorem 25 for the third inequality.\nNote that Claim 29 imposes a lower bound on the sample complexity. From this claim and McDiarmid\u2019s inequality we get\nPr [M > 3\u01eb/2] \u2264 Pr [M \u2212 E[M] > \u01eb] \u2264 exp(\u22122\u01eb2k).\nTheorem 7 immediately follows by setting 2\u01eb/3 in place of \u01eb.\nF Proof of Theorem 5: Learning sums of Bernoullis in poly(log(n), 1/\u01eb) time with efficient hypotheses\nIn this section we observe that the probability theory literature already provides a non-proper algorithm (Birge\u0301 (1997)) that can be used as an alternative to our Theorem 4 for learning a sum of n Bernoulli random variables. This algorithm has faster running time, requiring only poly(log n, 1/\u01eb) time steps, but significantly worse sample complexity of log(n) \u00b7poly(1/\u01eb) samples (recall that Theorem 4 requires only poly(1/\u01eb) samples independent of n).\nWe say that a distribution p over domain {0, 1, . . . , n} is unimodal if there exists some mode M \u2208 {0, 1, . . . , n} (not necessarily unique) such that the probability density function (pdf) of p is monotone nonincreasing on {0, . . . , M} and monotone nondecreasing on {M, . . . , n}. Our starting point is the observation that any sum of n Bernoullis is a unimodal distribution over {0, 1, . . . , n}. (This can be shown by a straightforward induction on n, see e.g. Keilson and Gerber (1971).) This observation lets us use a powerful algorithm due to Birge\u0301 (1997) that can learn any unimodal distribution to accuracy \u01eb in total variation distance using sample complexity is optimal up to constant factors (Birge\u0301 (1987)). (Birge\u0301\u2019s work deals with unimodal distributions over the continuous interval [0, n], but it is easily modified to apply to our discrete setting.) His algorithm uses O(log n/\u01eb3) samples and has overall running time of O(log2 n)/\u01eb3 bit operations (note that this running time is best possible, given the sample complexity, since each sample is an \u2126(log n) bit string.). It outputs a hypothesis distribution that is a histogram over O((log n)/\u01eb) intervals that cover {0, . . . , n}: more precisely, the hypothesis is uniform within each interval, and for each interval the total mass it assigns to the interval is simply the fraction of samples that landed in that interval. Thus the hypothesis distribution has a succinct description and can be efficiently evaluated using a small amount of randomness as claimed in Theorem 5."}], "references": [{"title": "Nearly tight bounds on the learnability of evolution", "author": ["Andris Ambainis", "Richard Desper", "Martin Farach", "Sampath Kannan"], "venue": "In FOCS,", "citeRegEx": "Ambainis et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Ambainis et al\\.", "year": 1997}, {"title": "Estimating a density under order restrictions: Nonasymptotic minimax risk", "author": ["L. Birg\u00e9"], "venue": "Annals of Statistics,", "citeRegEx": "Birg\u00e9.,? \\Q1987\\E", "shortCiteRegEx": "Birg\u00e9.", "year": 1987}, {"title": "Estimation of unimodal densities without smoothness assumptions", "author": ["L. Birg\u00e9"], "venue": "Annals of Statistics,", "citeRegEx": "Birg\u00e9.,? \\Q1997\\E", "shortCiteRegEx": "Birg\u00e9.", "year": 1997}, {"title": "Evolutionary trees can be learned in polynomial time in the two state general Markov model", "author": ["M. Cryan", "L. Goldberg", "P. Goldberg"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Cryan et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Cryan et al\\.", "year": 2002}, {"title": "An efficient ptas for two-strategy anonymous games", "author": ["Constantinos Daskalakis"], "venue": "WINE 2008; full version in CoRR,", "citeRegEx": "Daskalakis.,? \\Q2008\\E", "shortCiteRegEx": "Daskalakis.", "year": 2008}, {"title": "On oblivious ptas\u2019s for nash equilibrium", "author": ["Constantinos Daskalakis", "Christos H. Papadimitriou"], "venue": "STOC 2009; full version in,", "citeRegEx": "Daskalakis and Papadimitriou.,? \\Q2011\\E", "shortCiteRegEx": "Daskalakis and Papadimitriou.", "year": 2011}, {"title": "A universally acceptable smoothing factor for kernel density estimation", "author": ["L. Devroye", "G. Lugosi"], "venue": "Annals of Statistics,", "citeRegEx": "Devroye and Lugosi.,? \\Q1996\\E", "shortCiteRegEx": "Devroye and Lugosi.", "year": 1996}, {"title": "Nonasymptotic universal smoothing factors, kernel complexity and Yatracos classes", "author": ["L. Devroye", "G. Lugosi"], "venue": "Annals of Statistics,", "citeRegEx": "Devroye and Lugosi.,? \\Q1996\\E", "shortCiteRegEx": "Devroye and Lugosi.", "year": 1996}, {"title": "Combinatorial methods in density estimation", "author": ["L. Devroye", "G. Lugosi"], "venue": null, "citeRegEx": "Devroye and Lugosi.,? \\Q2001\\E", "shortCiteRegEx": "Devroye and Lugosi.", "year": 2001}, {"title": "Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator", "author": ["A. Dvoretzky", "J. Kiefer", "J. Wolfowitz"], "venue": "Ann. Mathematical Statistics,", "citeRegEx": "Dvoretzky et al\\.,? \\Q1956\\E", "shortCiteRegEx": "Dvoretzky et al\\.", "year": 1956}, {"title": "Efficient algorithms for inverting evolution", "author": ["Martin Farach", "Sampath Kannan"], "venue": "J. ACM,", "citeRegEx": "Farach and Kannan.,? \\Q1999\\E", "shortCiteRegEx": "Farach and Kannan.", "year": 1999}, {"title": "Learning mixtures of product distributions over discrete domains", "author": ["Jon Feldman", "Ryan O\u2019Donnell", "Rocco A. Servedio"], "venue": "SIAM J. Comput.,", "citeRegEx": "Feldman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2008}, {"title": "Estimating a mixture of two product distributions", "author": ["Y. Freund", "Y. Mansour"], "venue": "In Proceedings of the Twelfth Annual Conference on Computational Learning Theory,", "citeRegEx": "Freund and Mansour.,? \\Q1999\\E", "shortCiteRegEx": "Freund and Mansour.", "year": 1999}, {"title": "Polya. Inequalities", "author": ["G.H. Hardy", "J.E. Littlewood"], "venue": null, "citeRegEx": "Hardy et al\\.,? \\Q1934\\E", "shortCiteRegEx": "Hardy et al\\.", "year": 1934}, {"title": "On the learnability of discrete distributions", "author": ["M. Kearns", "Y. Mansour", "D. Ron", "R. Rubinfeld", "R. Schapire", "L. Sellie"], "venue": "In Proceedings of the 26th Symposium on Theory of Computing,", "citeRegEx": "Kearns et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Kearns et al\\.", "year": 1994}, {"title": "Some Results for Discrete Unimodality", "author": ["J. Keilson", "H. Gerber"], "venue": "J. American Statistical Association,", "citeRegEx": "Keilson and Gerber.,? \\Q1971\\E", "shortCiteRegEx": "Keilson and Gerber.", "year": 1971}, {"title": "The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality", "author": ["P. Massart"], "venue": "Annals of Probability,", "citeRegEx": "Massart.,? \\Q1990\\E", "shortCiteRegEx": "Massart.", "year": 1990}, {"title": "Evaluation may be easier than generation", "author": ["M. Naor"], "venue": "In Proceedings of the 28th Symposium on Theory of Computing (STOC),", "citeRegEx": "Naor.,? \\Q1996\\E", "shortCiteRegEx": "Naor.", "year": 1996}, {"title": "The unreasonable effectiveness of martingales", "author": ["Y. Peres"], "venue": "Plenary talk at SODA,", "citeRegEx": "Peres.,? \\Q2009\\E", "shortCiteRegEx": "Peres.", "year": 2009}, {"title": "Translated Poisson Approximation Using Exchangeable Pair Couplings", "author": ["A. R\u00f6llin"], "venue": "ArXiV Report,", "citeRegEx": "R\u00f6llin.,? \\Q2006\\E", "shortCiteRegEx": "R\u00f6llin.", "year": 2006}, {"title": "Rates of convergence of minimum distance estimators and Kolmogorov\u2019s entropy", "author": ["Y.G. Yatracos"], "venue": "Annals of Statistics,", "citeRegEx": "Yatracos.,? \\Q1985\\E", "shortCiteRegEx": "Yatracos.", "year": 1985}], "referenceMentions": [{"referenceID": 8, "context": "As a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al.", "startOffset": 226, "endOffset": 252}, {"referenceID": 2, "context": "As a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al. (2002), Feldman et al.", "startOffset": 253, "endOffset": 273}, {"referenceID": 2, "context": "As a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). For simplicity we describe the case k = 2: there are unknown product distributions p, q over {0, 1}n and unknown mixing weights \u03c0p, \u03c0q = 1 \u2212 \u03c0p.", "startOffset": 253, "endOffset": 296}, {"referenceID": 2, "context": "As a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). For simplicity we describe the case k = 2: there are unknown product distributions p, q over {0, 1}n and unknown mixing weights \u03c0p, \u03c0q = 1 \u2212 \u03c0p. The learner is given independent draws from the mixture distribution (each draw is independently taken from p with probability \u03c0p and from q with probability \u03c0q), and must output hypothesis product distributions p\u0302, q\u0302 and hypothesis mixing weights \u03c0\u0302p, \u03c0\u0302q. This problem is easily seen to be equivalent to the transformed product distribution learning problem for the function f : {0, 1}2n+1 \u2192 {0, 1}n which is such that on input (z, x1, . . . , xn, y1, . . . , yn) \u2208 {0, 1}2n+1 the i-th bit of f \u2019s output is zxi + (1 \u2212 z)yi. It is easy to see that if the target vector of probabilities for f is (\u03c0p, p1, . . . , pn, q1, . . .qn) then samples of f are distributed exactly according to the mixture of product distributions, and finding a good hypothesis vector in [0, 1]2n+1 amounts to finding a hypothesis mixing weight \u03c0\u0302p and hypothesis product distributions p\u0302, q\u0302 as required in the original \u201clearning mixtures of product distributions\u201d problem. Connection to prior work: The transformed product distribution learning model is related to the PACstyle model of learning discrete probability distributions that was introduced by Kearns et al. (1994) and studied in several subsequent works of Naor (1996), Ambainis et al.", "startOffset": 253, "endOffset": 1596}, {"referenceID": 2, "context": "As a second example, we point out that the transformed product distribution learning model is broad enough to encompass the problem of learning an unknown mixture of k product distributions over {0, 1}n that was considered by Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). For simplicity we describe the case k = 2: there are unknown product distributions p, q over {0, 1}n and unknown mixing weights \u03c0p, \u03c0q = 1 \u2212 \u03c0p. The learner is given independent draws from the mixture distribution (each draw is independently taken from p with probability \u03c0p and from q with probability \u03c0q), and must output hypothesis product distributions p\u0302, q\u0302 and hypothesis mixing weights \u03c0\u0302p, \u03c0\u0302q. This problem is easily seen to be equivalent to the transformed product distribution learning problem for the function f : {0, 1}2n+1 \u2192 {0, 1}n which is such that on input (z, x1, . . . , xn, y1, . . . , yn) \u2208 {0, 1}2n+1 the i-th bit of f \u2019s output is zxi + (1 \u2212 z)yi. It is easy to see that if the target vector of probabilities for f is (\u03c0p, p1, . . . , pn, q1, . . .qn) then samples of f are distributed exactly according to the mixture of product distributions, and finding a good hypothesis vector in [0, 1]2n+1 amounts to finding a hypothesis mixing weight \u03c0\u0302p and hypothesis product distributions p\u0302, q\u0302 as required in the original \u201clearning mixtures of product distributions\u201d problem. Connection to prior work: The transformed product distribution learning model is related to the PACstyle model of learning discrete probability distributions that was introduced by Kearns et al. (1994) and studied in several subsequent works of Naor (1996), Ambainis et al.", "startOffset": 253, "endOffset": 1651}, {"referenceID": 0, "context": "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al.", "startOffset": 63, "endOffset": 86}, {"referenceID": 0, "context": "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al.", "startOffset": 63, "endOffset": 112}, {"referenceID": 0, "context": "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al.", "startOffset": 63, "endOffset": 139}, {"referenceID": 0, "context": "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al.", "startOffset": 63, "endOffset": 160}, {"referenceID": 0, "context": "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). In the Kearns et al.", "startOffset": 63, "endOffset": 183}, {"referenceID": 0, "context": "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). In the Kearns et al. (1994) framework a learning problem is defined by a class C of Boolean circuits, and an instance of the problem corresponds to the choice of a specific (unknown to the learner) target circuit C \u2208 C.", "startOffset": 63, "endOffset": 212}, {"referenceID": 0, "context": "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). In the Kearns et al. (1994) framework a learning problem is defined by a class C of Boolean circuits, and an instance of the problem corresponds to the choice of a specific (unknown to the learner) target circuit C \u2208 C. The learner is given samples from C(X) where X is a uniform random string from {0, 1}m, and the learner must with high probability output a hypothesis circuit C such that the random variable C(X) is \u01eb-close to C(X) (in KL-divergence). Strictly speaking the transformed product distribution learning model may be viewed as a special case of the Kearns et al model. This is done by considering a circuit class C that has a circuit C = Cp for each possible product distribution p over {0, 1}n; the circuit Cp first transforms the uniform distribution over {0, 1}m to the product distribution p over {0, 1}n and then applies the transformation function f to the output of p. However, learning problems C of this sort do not seem to have been previously considered in the Kearns et al. (1994) model, and we feel it is more natural to view our model as dual in spirit to the earlier model.", "startOffset": 63, "endOffset": 1192}, {"referenceID": 0, "context": "(1994) and studied in several subsequent works of Naor (1996), Ambainis et al. (1997), Farach and Kannan (1999), Freund and Mansour (1999), Cryan et al. (2002), Feldman et al. (2008). In the Kearns et al. (1994) framework a learning problem is defined by a class C of Boolean circuits, and an instance of the problem corresponds to the choice of a specific (unknown to the learner) target circuit C \u2208 C. The learner is given samples from C(X) where X is a uniform random string from {0, 1}m, and the learner must with high probability output a hypothesis circuit C such that the random variable C(X) is \u01eb-close to C(X) (in KL-divergence). Strictly speaking the transformed product distribution learning model may be viewed as a special case of the Kearns et al model. This is done by considering a circuit class C that has a circuit C = Cp for each possible product distribution p over {0, 1}n; the circuit Cp first transforms the uniform distribution over {0, 1}m to the product distribution p over {0, 1}n and then applies the transformation function f to the output of p. However, learning problems C of this sort do not seem to have been previously considered in the Kearns et al. (1994) model, and we feel it is more natural to view our model as dual in spirit to the earlier model. In Kearns et al. (1994) the learner\u2019s task is to infer an unknown transformation (the circuit C) into which are fed n-bit strings that are known to be distributed uniformly.", "startOffset": 63, "endOffset": 1312}, {"referenceID": 6, "context": "By an approach similar to the algorithm of Devroye and Lugosi (2001) for choosing a density estimate, we show (Theorem 6) that if the space { f (p)}p\u2208[0,1]n of all f -transformed product distributions has an \u01eb-cover of size N, then there is a generic learning algorithm for the f -transformed product distribution problem that uses O((log N)/\u01eb2) samples.", "startOffset": 43, "endOffset": 69}, {"referenceID": 6, "context": "While the algorithm itself is simple, its analysis relies on a fundamental result from probability theory, known as the Dvoretzky-Kiefer-Wolfowitz inequality (Dvoretzky et al. (1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)).", "startOffset": 159, "endOffset": 183}, {"referenceID": 6, "context": "(1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)).", "startOffset": 112, "endOffset": 138}, {"referenceID": 6, "context": "(1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)). In Appendix E we give a self-contained proof of the DKW inequality using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)); this proof is significantly different from the proofs we know of in the probability literature (see Dvoretzky et al.", "startOffset": 112, "endOffset": 359}, {"referenceID": 6, "context": "(1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)). In Appendix E we give a self-contained proof of the DKW inequality using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)); this proof is significantly different from the proofs we know of in the probability literature (see Dvoretzky et al. (1956), Massart (1990), and Chapter 3 of Devroye and Lugosi (2001)).", "startOffset": 112, "endOffset": 485}, {"referenceID": 6, "context": "(1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)). In Appendix E we give a self-contained proof of the DKW inequality using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)); this proof is significantly different from the proofs we know of in the probability literature (see Dvoretzky et al. (1956), Massart (1990), and Chapter 3 of Devroye and Lugosi (2001)).", "startOffset": 112, "endOffset": 501}, {"referenceID": 6, "context": "(1956)), which may be viewed as a special case of the fundamental Vapnik-Chervonenkis theorem (see Chapter 3 of Devroye and Lugosi (2001)). In Appendix E we give a self-contained proof of the DKW inequality using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)); this proof is significantly different from the proofs we know of in the probability literature (see Dvoretzky et al. (1956), Massart (1990), and Chapter 3 of Devroye and Lugosi (2001)).", "startOffset": 112, "endOffset": 545}, {"referenceID": 11, "context": "Hardy et al. (1934) section 2.", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "Nevertheless, we extend the Kolmogorov distance learning algorithm to total variation distance via a delicate algorithm that exploits the detailed structure of a small \u01eb-cover (Daskalakis and Papadimitriou (2011), Daskalakis (2008)) of the space of all distributions that are sums of independent Bernoulli random variables (see Theorem 9).", "startOffset": 177, "endOffset": 213}, {"referenceID": 4, "context": "Nevertheless, we extend the Kolmogorov distance learning algorithm to total variation distance via a delicate algorithm that exploits the detailed structure of a small \u01eb-cover (Daskalakis and Papadimitriou (2011), Daskalakis (2008)) of the space of all distributions that are sums of independent Bernoulli random variables (see Theorem 9).", "startOffset": 177, "endOffset": 232}, {"referenceID": 4, "context": "Nevertheless, we extend the Kolmogorov distance learning algorithm to total variation distance via a delicate algorithm that exploits the detailed structure of a small \u01eb-cover (Daskalakis and Papadimitriou (2011), Daskalakis (2008)) of the space of all distributions that are sums of independent Bernoulli random variables (see Theorem 9). Interestingly, this becomes feasible by establishing an analog of the aforementioned argument by Newton to a class of distributions used in the cover that are called heavy (see Lemma 15). This in turn relies on probabilistic approximation results via translated Poisson distributions (see Definition 18, R\u00f6llin (2006)).", "startOffset": 177, "endOffset": 658}, {"referenceID": 1, "context": "This lets us apply a powerful algorithm due to Birg\u00e9 (1997) that can learn any unimodal distribution to accuracy \u01eb using O(log n)/\u01eb3 samples.", "startOffset": 47, "endOffset": 60}, {"referenceID": 6, "context": "\u201d) This basic approach of running a tournament between distributions in an \u03b4-cover is quite similar to the algorithm of Devroye and Lugosi for choosing a density estimate (see Devroye and Lugosi (1996a,b) and Chapters 6 and 7 of Devroye and Lugosi (2001)), which in turn built closely on the work of Yatracos (1985).", "startOffset": 120, "endOffset": 255}, {"referenceID": 6, "context": "\u201d) This basic approach of running a tournament between distributions in an \u03b4-cover is quite similar to the algorithm of Devroye and Lugosi for choosing a density estimate (see Devroye and Lugosi (1996a,b) and Chapters 6 and 7 of Devroye and Lugosi (2001)), which in turn built closely on the work of Yatracos (1985). Our algorithm achieves essentially the same bounds as these earlier approaches but there are some small differences.", "startOffset": 120, "endOffset": 316}, {"referenceID": 9, "context": "The Dvoretzky-Kiefer-Wolfowitz inequality (Dvoretzky et al. (1956), Massart (1990)) confirms this, and in fact shows that a surprisingly small value of k \u2013 independent of n \u2013 suffices.", "startOffset": 43, "endOffset": 67}, {"referenceID": 9, "context": "The Dvoretzky-Kiefer-Wolfowitz inequality (Dvoretzky et al. (1956), Massart (1990)) confirms this, and in fact shows that a surprisingly small value of k \u2013 independent of n \u2013 suffices.", "startOffset": 43, "endOffset": 83}, {"referenceID": 18, "context": "In Appendix E we give a self-contained proof of the theorem using elementary techniques (martingales and the method of bounded differences) and an interesting trick that goes back to Kolmogorov (see Peres (2009)).", "startOffset": 199, "endOffset": 212}, {"referenceID": 4, "context": "The following is Theorem 9 of the full version of (Daskalakis and Papadimitriou (2011)):", "startOffset": 51, "endOffset": 87}, {"referenceID": 4, "context": "(We remark that Daskalakis (2008) establishes the same theorem, except that the size of the cover given there, as well as the time needed to produce it, are n3 \u00b7O(1/\u01eb)+n \u00b7 ( 1 \u01eb )O(1/\u01eb2) .", "startOffset": 16, "endOffset": 34}, {"referenceID": 19, "context": "Definition 18 (R\u00f6llin (2006)) We say that an integer random variable Y has a translated Poisson distribution with paremeters \u03bc and \u03c32 and write L(Y) = T P(\u03bc, \u03c32) if L(Y \u2212 \u230a\u03bc \u2212 \u03c32\u230b) = Poisson(\u03c32 + {\u03bc \u2212 \u03c32}), where {\u03bc \u2212 \u03c32} represents the fractional part of \u03bc \u2212 \u03c32.", "startOffset": 15, "endOffset": 29}, {"referenceID": 4, "context": "Given the above, and following Daskalakis (2008) (see Section 6.", "startOffset": 31, "endOffset": 49}], "year": 2011, "abstractText": "We consider the problem of learning an unknown product distribution X over {0, 1}n using samples f (X) where f is a known transformation function. Each choice of a transformation function f specifies a learning problem in this framework. Information-theoretic arguments show that for every transformation function f the corresponding learning problem can be solved to accuracy \u01eb, using \u00d5(n/\u01eb2) examples, by a generic algorithm whose running time may be exponential in n. We show that this learning problem can be computationally intractable even for constant \u01eb and rather simple transformation functions. Moreover, the above sample complexity bound is nearly optimal for the general problem, as we give a simple explicit linear transformation function f (x) = w \u00b7 x with integer weights wi \u2264 n and prove that the corresponding learning problem requires \u03a9(n) samples. As our main positive result we give a highly efficient algorithm for learning a sum of independent unknown Bernoulli random variables, corresponding to the transformation function f (x) = \u2211n i=1 xi. Our algorithm learns to \u01eb-accuracy in poly(n) time, using a surprising poly(1/\u01eb) number of samples that is independent of n. We also give an efficient algorithm that uses log n \u00b7 poly(1/\u01eb) samples but has running time that is only poly(log n, 1/\u01eb).", "creator": "LaTeX with hyperref package"}}}