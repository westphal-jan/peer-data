{"id": "1106.1770", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2011", "title": "Reinforcement learning based sensing policy optimization for energy efficient cognitive radio networks", "abstract": "This paper introduces a machine learning based collaborative multi band spectrum sensing policy for cognitive radios. The proposed sensing policy guides secondary users to focus the search of unused radio spectrum to those frequencies that persistently provide them high data rate. The proposed policy is based on machine learning, which makes it adaptive with the temporally and spatially varying radio spectrum (TAS). This strategy would include an implementation of the first public radio protocol in the US, the ARS, as well as an effort to develop a technology for measuring the radio frequency. The proposed ARS would include a range of ARS protocols, and a new interface (the ARS) for tracking radio frequencies in the US and around the world, all to a certain degree.\n\n\nThe ARS is currently in the early stages of its implementation, and will have several major technical challenges. First, the network itself needs to be very sensitive, and can rely on network traffic to manage the high-bandwidth signals for low-bandwidth signals. Second, there is insufficient demand for the technology and could not meet the expected demand from large, highly-traffic parts of the US.\nThe ARS is currently at its peak, with the need to implement a new approach, but its future in the ARS is in flux. While this issue has not been resolved, the potential for it to be explored is likely to be very difficult to accomplish. In particular, the ARS will require a much larger set of layers of equipment.\nThe ARS will be based on ARS-based systems, and will allow us to implement a network-wide service plan for managing data. It will require users to perform the same network-wide service plan that is currently being implemented, but with different architectures. These components will be in development, and will be available for use in the following areas:\n* All communications with the wireless network will be encrypted;\n* All communication with the internet will be encrypted;\n* All communication with the internet will be encrypted;\n* All communications with the internet will be encrypted; and\n* All communications with the internet will be encrypted; and\n* All communications with the internet will be encrypted; and\n* All communications with the internet will be encrypted; and\n* All communications with the internet will be encrypted; and\n* All communications with the internet will be encrypted; and\n* All communications with the internet will be encrypted; and\n* All communications with the internet will be encrypted; and\n* All communications with the internet will be", "histories": [["v1", "Thu, 9 Jun 2011 10:40:08 GMT  (441kb,D)", "https://arxiv.org/abs/1106.1770v1", "10 pages, 13 figures, Submitted to Neurocomputing June 2011"], ["v2", "Wed, 27 Jul 2011 11:08:21 GMT  (753kb,D)", "http://arxiv.org/abs/1106.1770v2", "10 pages, 13 figures, Accepted to Neurocomputing special issue: MLSP 2011"], ["v3", "Tue, 4 Oct 2011 06:02:16 GMT  (586kb,D)", "http://arxiv.org/abs/1106.1770v3", "10 pages, 13 figures, Accepted to Neurocomputing special issue: Machine learning for signal processing, 2011"]], "COMMENTS": "10 pages, 13 figures, Submitted to Neurocomputing June 2011", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jan oksanen", "jarmo lund\\'en", "visa koivunen"], "accepted": false, "id": "1106.1770"}, "pdf": {"name": "1106.1770.pdf", "metadata": {"source": "CRF", "title": "Reinforcement learning based sensing policy optimization for energy efficient cognitive radio networks", "authors": ["Jan Oksanena", "Jarmo Lund\u00e9na", "Visa Koivunena"], "emails": ["jhoksane@wooster.hut.fi", "jrlunden@wooster.hut.fi", "visa@wooster.hut.fi"], "sections": [{"heading": null, "text": "This paper introduces a machine learning based collaborative multi-band spectrum sensing policy for cognitive radios. The proposed sensing policy guides secondary users to focus the search of unused radio spectrum to those frequencies that persistently provide them high data rate. The proposed policy is based on machine learning, which makes it adaptive with the temporally and spatially varying radio spectrum. Furthermore, there is no need for dynamic modeling of the primary activity since it is implicitly learned over time. Energy efficiency is achieved by minimizing the number of assigned sensors per each subband under a constraint on miss detection probability. It is important to control the missed detections because they cause collisions with primary transmissions and lead to retransmissions at both the primary and secondary user. Simulations show that the proposed machine learning based sensing policy improves the overall throughput of the secondary network and improves the energy efficiency while controlling the miss detection probability.\nKeywords: Cognitive radio, Frequency hopping, Machine learning, Sensing policy, Spatial diversity, Spectrum sensing"}, {"heading": "1. Introduction", "text": "The increasing demand for wireless services has made the usable radio spectrum a scarce and expensive resource. Part of the scarcity problem are the spectrum allocation policies that do not exploit the fact that the state of the radio frequency spectrum is time and location varying. Measurement campaigns [1] have in fact shown that large parts of the spectrum are underutilized because the license holders are not using the spectrum or because the fact that wireless signals attenuate in 2\u2212 4 power of distance is not fully exploited. Underutilized spectrum is time-frequencylocation varying resource and radio wave propagation and signal attenuation are important factors in determining where spectrum opportunities or areas of harmful interference occur. Identifying temporal and spatial spectrum holes has been the key motivation behind cognitive radio (CR) and dynamic spectrum access (DSA) [2]. Figure 1 illustrates how spectrum holes emerge in time and frequency.\nCR systems try to use the licensed radio spectrum in an agile manner while guaranteeing that the licensed users will not be interfered (see figure 1). A spectrum opportunity is a situation in which secondary users (SU) are able\n\u2217Corresponding author Email addresses: jhoksane@wooster.hut.fi (Jan Oksanen),\njrlunden@wooster.hut.fi (Jarmo Lund\u00e9n), visa@wooster.hut.fi (Visa Koivunen)\n1J. Lund\u00e9n\u2019s work has been supported by the Qatar National Research Fund and the Finnish Cultural Foundation.\nto communicate on a licensed frequency without interfering the primary user (PU) and without being themselves interfered by the PU [3]. In order to find such spectrum opportunities CR systems need to sense the spectrum (see figure 2).\nA CR network can be considered to consist of NS spatially distributed wireless terminals that identify free frequencies across a wide spectrum of interest that is assumed to have been divided into NB subbands. In order to mitigate the effects of fading, cooperative detection schemes have been proposed in the literature [2, 4, 5]. This means that a part of the spectrum is simultaneously sensed by multiple SUs that send their local test statistics to a fusion center (FC) which then makes a global decision about the state of the spectrum. With such cooperation, the prob-\nPreprint submitted to Neurocomputing October 5, 2011\nar X\niv :1\n10 6.\n17 70\nv3 [\ncs .L\nG ]\n4 O\nct 2\n01 1\nability of detection at a given signal-to-noise ratio (SNR) is increased, or for equal performance, simpler detector structures may be employed.\nAn important function performed by the FC is the spectrum sensing policy, which is also the focus of this paper. A spectrum sensing policy guides the SUs about who is sensing, which part of the spectrum and when. One of the main targets of a sensing policy is to select those frequency bands for sensing that persistently provide more spectrum opportunities and throughput for the SU network."}, {"heading": "1.1. Contribution of the paper", "text": "In this paper a reinforcement learning based multi-user, multi-band spectrum sensing policy is proposed. The proposed sensing policy balances between exploring and exploiting different parts of the radio spectrum and different sensing assignments. It decides which frequency bands to sense as well as which SU is assigned to do the sensing. In the exploitation phase the sensing assignment for the high throughput subbands is found by minimizing the number of assigned SUs subject to a constraint on the miss detection probability. Moreover, the probability of false alarm is constrained by using Neyman-Pearson detectors. Minimization of the number of simultaneously sensing SUs improves the energy efficiency of the battery operated SUs. The minimization is formulated as a binary integer programming (BIP) problem that may be solved exactly by a branch-and-bound type algorithm or approximately by using approximative methods such as the iterative Hungarian method considered in this paper. The proposed policy may reduce the number of active sensors up to a factor of 1/D, where D is the diversity order of a fixed sensing policy. In the exploration phase different pseudorandom sensing assignments with fixed diversity order are explored in order to re-adapt to possible changes in the PU activity and channel conditions. On one hand, spatial diversity improves the detector performance in the face of fading and shadowing but on the other hand reduces the\nnumber of simultaneously sensed frequency bands by the secondary network. Cognitive network may use multiple idle frequency bands in order to improve rate or reliability of the network.\nSome preliminary ideas and results related to this paper were presented in [6]. The contributions of this paper are:\n\u2022 We propose a machine learning based spectrum sensing policy for cognitive radio that:\n\u2013 provides high throughput for the SUs,\n\u2013 reduces missed detections,\n\u2013 is energy efficient,\n\u2013 is adaptive to non-stationary PU behavior and channel conditions.\n\u2022 Analytical expressions for the convergence of the proposed sensing policy in stationary scenarios are derived.\n\u2022 Extensive simulation results highlighting the excellent performance of the proposed sensing policy in various stationary and non-stationary scenarios are shown.\n\u2022 We show that a simple and fast approximative algorithm based on the Hungarian method may be used to find near optimal sensing assignments.\nThe main difference with this paper and the related work in the literature, in addition to the methodology, is the exploitation of the information about the sensing performances of the SUs to optimize the sensing assignments in an energy efficient manner.\nThis paper is organized as follows. In section 2 the related work to this paper is briefly summarized. The system model of cooperative multi-band sensing is described in section 3. In section 4 an energy efficient reinforcement learning based sensing policy is proposed and analytical results on the convergence rate of the Q-values in the sensing policy are derived. Section 5 shows and discusses the simulation results of the performance of the proposed sensing policy. The paper is concluded in section 6."}, {"heading": "2. Related work", "text": "The task of choosing which frequency band to sense may be formulated as a restless multi-armed bandit (RMAB) problem. In RMAB problems a player bets on L out of N slot machines (L \u2265 1, N \u2265 L) targeting to maximize its long term profit. The term restless comes from the fact that also the states of the non-played machines may change; similarly as the state of the not sensed frequency bands may change in a CR setting. In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs). In [13] a closed form Whittle index policy for perfectly known Markovian reward distributions was derived and shown to be optimal under certain conditions.\nIn a case where the player does not have prior knowledge about the reward distributions of the different machines (or as in this case about the throughputs of the different frequency bands), it is obviously impossible to derive optimal action selection policies. In such case machine learning is an attractive approach for solving the problem. A known issue with machine learning methods is the so-called exploitation-exploration trade-off, which emerges when the player has to decide whether to try to exploit the seemingly best machine (or frequency band) at the moment or to explore other machines in hope of finding even better one. A standard method for tackling multi-armed bandit problems is the Q-learning algorithm [14] with -greedy exploration [15]. An alternative way for balancing the trade-off between exploration and exploitation is to use confidence bounds. Namely, in [16] a simple policy based on upper confidence bounds (UCB) was proposed and shown to reach the optimal regret rate when the rewards are independent and stationary. An UCB policy that suits better for non-stationary rewards was developed in [17]. In [18] a single-user reinforcement learning method was proposed for selecting between 3 future actions: continuing sensing at the current frequency band b and transmitting data, sensing an out-of-band frequency band b\u0303, and switching the SU system to an out-of-band frequency band b\u0303. Action selection is done using the softmax method."}, {"heading": "3. System model", "text": "The SU network consists of NS cooperating wireless SU terminals sensing the radio spectrum. The spectrum of interest is assumed to be divided into NB frequency subbands that may have different bandwidths and may be occupied by different primary operators. The subbands may be scattered in frequency. Depending on the frontend design of the SU device, one SU can sense up to Ks subbands at a time.\nIn this paper it is assumed that the SUs cooperate by sending their local binary decisions to a FC, that makes a global decision about the availability of the spectrum for all SUs. This brings spatial diversity and increased scanning speed. Spatial diversity is obtained when multiple SUs sense the same part of the spectrum simultaneously from different locations and then form a global decision. Scanning speed is increased since each SU may get sensing information about up to \u2211 sKs subbands simultaneously.\nThe SUs are assumed to be synchronized and their operation to be divided into sensing mini time slots and potential transmission slots as illustrated in figure 3. In a sensing time slot the SU senses up to Ks subbands and then sends its local binary decision(s) to the FC via a dedicated control channel. The global decisions about the state of the sensed subbands is formed at the FC by combining the local binary decisions according a fusion rule.\nThe FC may be a dedicated node or one or multiple nodes could serve as a FC in an ad hoc scenario. A dedicated FC makes a global decision on behalf of all other\nSUs, whereas individual FCs in an ad hoc scenario could make independent decisions based on their own test statistics and the test statistics received from other SUs.\nOne proposed approach to model the PU activity is a two-state Markov chain shown in figure 4 [9]. In the model state 0 means that the primary subband is idle (PU not transmitting) and state 1 that the subband is occupied (PU transmitting). However, the policy proposed in this paper is not limited to the Markovian assumption. Markov model is merely used for illustration purposes in the experimental part of this paper."}, {"heading": "4. Reinforcement learning based sensing policy", "text": "In the PU network, as in most communication systems, the traffic load may vary depending on time and location. The expected amount of available radio spectrum for opportunistic secondary use may, for example, be much less during rush hours and in densely populated areas than during night time and in rural areas. Also the radio channel conditions fluctuate in time depending on location, velocity and frequency. Hence, the design of a sensing policy for CR has to be approached as a dynamic problem."}, {"heading": "4.1. The -greedy method", "text": "Let Qk(a) denote the estimated value of action a at time step k and a\u2217k denote the selected action at time step k. The -greedy policy is an ad-hoc method that balances between exploration and exploitation by selecting the action that has the highest estimated action value, i.e. a\u2217k = arg maxaQk(a), with probability 1\u2212 , or a random action, uniformly, with probability regardless of the action-value estimates [15].\nThe -greedy method is a simple and robust method that has minor computation and memory requirements.\nThe random exploration phase allows replacing the random action selections with more carefully designed pseudorandom action selection with desired properties that are described in detail in section 4.2.1.\nAfter taking action a reward r(a) is collected after which the Q-value of action a is updated as [15]\nQk+1(a) = Qk(a) + \u03b1k[rk+1(a)\u2212Qk(a)], (1)\nwhere rk+1(a) is the reward at time step k + 1 for taking action a and \u03b1k (0 < \u03b1k \u2264 1) is a step size parameter.\nIn a stationary scenario convergence is guaranteed with probability 1 when the step size parameter \u03b1k satisfies the following conditions [15]\n\u221e\u2211 k=1 \u03b1k =\u221e and \u221e\u2211 k=1 \u03b12k <\u221e. (2)\nThe first condition in (2) guarantees that the step size is large enough to overcome the initial conditions, while the second condition guarantees that the step size is small enough to assure eventual convergence. Step size \u03b1k = 1/(k + 1) fulfills the conditions of (2) and results in the standard sample-average of the past rewards. On the other hand, for constant \u03b1k = \u03b1 the estimates will never completely converge, but continue varying in response to the latest observed rewards. In case of tracking a nonstationary process this is in fact desirable since the policy should react rapidly to the changes in subband occupancy statistics. A constant \u03b1k = \u03b1 results in a weighted average of the observed rewards, i.e. [15]\nQk+1(a) = (1\u2212\u03b1)k+1Q0(a)+ k+1\u2211 i=1 \u03b1(1\u2212\u03b1)k+1\u2212iri(a). (3)\nA constant step size \u03b1 is suitable for tracking nonstationary processes such as the channel qualities in CR networks. It can be noticed in (3) that when \u03b1 is large more emphasis is given on the most recent rewards whereas when \u03b1 is close to 0 the algorithm will give emphasis on rewards obtained in the more distant past as well. This suggests that for heavily non-stationary processes large values of \u03b1 would be more suitable, whereas for stationary processes small \u03b1 would give better results."}, {"heading": "4.2. The proposed sensing policy", "text": "In this paper we propose a sensing policy using -greedy exploration for selecting the frequency subbands to be sensed and for selecting the corresponding sensing assignments in a CR network. The policy is managed by the FC that tracks two kinds of Q-values: the Q-values for the subbands and the Q-values of all SUs to all subbands. A natural way to define the reward rk+1(b) for selecting subband b to be sensed is the obtained throughput:\nrk+1(b) = { Rk+1(b), if b is accessed and free 0, if b is occupied,\n(4)\nwhere Rk+1(b) is the instantaneous throughput on subband b. In this paper it is assumed that the SU who has been granted the permission to access the band will feed back an estimate of the achieved throughput. For example, this may be an estimate based on the measured channel quality between the communicating SUs. Using this feedback the FC updates the Q-values of each subband according to (1).\nThe SU Q-values for particular subbands are updated by comparing the SUs\u2019 decision to the global decision:\nrk+1(s, b) =\n{ dk+1(s, b), dk+1(FC, b) = 1\nQk(s, b), dk+1(FC, b) = 0, (5)\nwhere dk+1(s, b) denotes the local decision by SU s for subband b at time instant k+1 and dk+1(FC, b) denotes the corresponding decision at the FC. The SU\u2019s Q-value is then updated again according to (1). Hence, the SU\u2019s Q-value indicates its sensing performance at subband b, assuming that the global decision based on the local decisions from multiple SUs made at the FC is correct.\nAfter all the Q-value updates, with probability 1\u2212 the FC exploits its knowledge and selects L subbands to be sensed that have the highest Q-values (stage 1 in figure 5). In this paper it is assumed that the FC has an estimate of the desired throughput and is able to select the parameter L appropriately. After selecting the subbands the FC finds an appropriate sensing assignment for them (stage 2 in figure 5). With probability the sensing is done according to predefined pseudorandom frequency hopping codes with a fixed diversity order D, where D is the number of SUs simultaneously sensing the same subband. In the exploitation phase the sensing assignment is the one that minimizes the number of sensings in the SU network while maintaining the detection performance at a desired level. Finally, the FC sends to the SUs information about which subbands they should sense."}, {"heading": "4.2.1. Exploration", "text": "In this section the pseudorandom frequency hopping based sensing policy proposed in [20] is briefly summarized, since it constitutes the exploration phase of the sensing policy developed in this paper. The pseudorandom frequency hopping based sensing policy provides quick scanning of the spectrum of interest with minimal control signaling, thus being extremely suitable for exploring the spectrum. The frequency hopping code design allows for trading off scanning speed and diversity (and consequently detector performance) in an elegant manner. Moreover, by guaranteeing the desired diversity order D, reliable performance is ensured in demanding propagation environments. In the pseudorandom frequency hopping based multi-band spectrum sensing policy the design of the sensing policy has been converted into designing and allocating pseudorandom frequency hopping codes to the SUs guiding them which subbands are sensed and when. After each hopping code period different D-tuples of the NS SUs will be\nemployed to scan the spectrum of interest together. The design is made such that over time all possible SU combinations of size D will be employed to sense each subband. Fig. 6 shows an example design of the hopping codes for NS = 4, NB = 3 and D = 2.\nIn frequency hopping based sensing each SU hops according to its hopping sequence to sense one of the subbands of interest. The subband to be sensed at time index i is given by f(i) = F [Sq(i)], where Sq(i) is the qth frequency hopping sequence, F is a table containing the mappings to the physical subbands. Table F may include links to the subbands\u2019 center frequencies and bandwidths. It is assumed that F is same for all SUs in the network.\nSince it is desirable to scan as much spectrum as possible at once, the hopping sequences are made orthogonal. The simplest way to generate an orthogonal code family is to cyclically shift any full sequence of integer numbers. A full sequence is a sequence that contains all integer numbers up to a certain number. Cyclic shifts may be generated by the modulo operation as\nSq(i) \u2261 (i+ \u2206q) mod NB , (6)\nwhere i \u2208 [0, NB \u2212 1], q \u2208 [0, bNSD c\u2212 1] and \u2206q is the shift parameter. For more information about the choice of \u2206q and the design of the frequency hopping sequences as well\nas simulation results see [20]."}, {"heading": "4.2.2. Exploitation", "text": "In many practical scenarios the cooperating SUs, although being in the vicinity of each others, may be in very different channel conditions due to fading. Then the cooperation among the SUs may be optimized better in order to save energy of the SUs.\nAssume that the secondary network of NS SUs wants to sense L < NB subbands in hope of spectral opportunities. These subbands have been selected in the first stage of the sensing policy as the ones that are most likely going to produce high reward (throughput) for the SU network. Denote the set of all the chosen L subband indices as B and the set of all SU indices as S. Furthermore, assume that the SU network has knowledge about the SUs\u2019 probabilities of detection Psb, where s \u2208 S and b \u2208 B. In order to conserve the SUs\u2019 energy, we would like to minimize the number of SUs assigned for sensing while pursuing to guarantee a desired level of detection performance at the subbands of interest. Hence, the sensing assignment problem (SAP) can be formulated as\nmin X\n\u2211 b\u2208B \u2211 s\u2208S wsxsb (7)\ns.t. P\u0302 bmiss,FC(X) \u2264 P bmiss,target\u2211 b\u2208B xsb \u2264 Ks\nxsb \u2208 {0, 1},\nwhereKs is a positive integer corresponding to the number of subbands SU s can sense simultaneously and ws is the weight of user s. X = [xsb] is NS \u00d7L the unknown binary sensing assignment matrix. The elements of X are\nxsb = { 1 , if SU s is assigned to sense subband b 0 , otherwise . (8)\nIn equation (7) P\u0302 bmiss,FC(X) is the estimate of the miss detection probability at the FC at subband b obtained with sensing assignment X. P bmiss,target is the maximum probability of miss detection that the secondary network is allowed to have at band b. The first constraint in (7) requires that the probability of miss detection at the FC should be below the constraint, whereas the second constraint restricts the number of subbands SU s can sense simultaneously to be Ks or less. The weight ws of SU s may be chosen, for example, according to the SUs\u2019 battery charge. If SU s is known to have low battery charge it may be given relatively large weights compared to other users so that it will unlikely to be assigned for sensing.\nThere are many ways to design distributed detection such that the detection performance constraint in (7) is met. As an example we consider here hard decision combining of multiple Neyman-Pearson detectors [21]. Neyman-Pearson detectors maximize the detection prob-\nability under a constraint on false alarm rate and hence false alarm rate is not included in (7) as a separate constraint. Typically the false alarm rate constraint is set small since false alarms equal to overlooked spectral opportunities. For hard decision combining, such as the ORrule considered in the next subsection, the false alarm rate constraint at the FC is simply met by controlling the local detection thresholds according to the number of SUs assigned to sense the same subband [21]."}, {"heading": "4.2.3. Sensing assignment for the OR-fusion rule", "text": "Next the sensing assignment is illustrated for the ORrule where the SUs send only their local decisions to the FC. The FC then decides a subband to be free only if all sensing SUs have reported it to be free. Other fusion rules such as K-out-of-N -rule could be used as well. Assuming conditional independence of the observations at different SUs given H0 or H1 the probability of missed detection at the FC at subband b for the OR-rule is given by\nP bmiss,FC = Ns\u220f s=1 (1\u2212 Psb)xsb , (9)\nwhich as such would lead to a nonlinear constraint in the SAP given by equation (7). However, the detection performance constraint can be linearized by simply taking the logarithm of the missed detection probabilities, i.e.\nln(P bmiss,FC) = Ns\u2211 s=1 ln(1\u2212 Psb)xsb. (10)\nThen the SAP for the OR-rule can be formulated as a linear binary integer programming (BIP) problem as\nmin x\nwTx (11)\ns.t. Ax \u2264 c x is binary,\nwhere w is an NSL \u00d7 1 vector of weights for the SUs at different subbands, x = vec(X) is a binary vector of size NSL \u00d7 1, A is the (L + NS) \u00d7 LNS constraint matrix containing the logarithms of the estimated local miss detection probabilities ln(1 \u2212 P\u0302sb)\u2019s and L identity matrices INS at the bottom and c is the vector of the constraints. The constraint vector is given as c = [ln(P 1miss,target), ..., ln(P L miss,target),K1, ...,KNS ]\nT . Since the detection probability can be known only up to a certain margin of error, the constraint vector c should in practice include a safety margin defined by a spectrum regulator. The constraint matrix A is given by\nA =  p\u03021miss 0 \u00b7 \u00b7 \u00b7 p\u03022miss 0 \u00b7 \u00b7 \u00b7 . . .\n\u00b7 \u00b7 \u00b7 0 p\u0302Lmiss INS INS \u00b7 \u00b7 \u00b7 INS\n , (12)\nwhere p\u0302bmiss = [ln(1 \u2212 P\u03021b), ln(1 \u2212 P\u03022b), ..., ln(1 \u2212 P\u0302Nsb)] and INS is the identity matrix of size NS .\nThis BIP problem is NP-hard but solvable by branchand-bound (BB) type algorithms. The worst case running time of BB search, although unlikely, is 2NSL, that corresponds to the case where no branching is possible. In practice NSL maybe assumed to be small.\nIn cases where the product NSL is large, the probability that there exists multiple near optimal assignments is high. In such cases heuristic approximation algorithms may be applied. In [22] an iterative Hungarian algorithm is proposed to find a sensing assignment that minimizes the probability of miss detection. The policy assigns SUs to sense the subbands one by one using the Hungarian method [23]. In our problem formulation, the Hungarian method can be employed iteratively, similarly to [22], to find a near optimal solution for the SAP with ws = 1 by modifying the algorithm to stop immediately once a feasible solution is found. Since the Hungarian algorithm runs in polynomial time, this method is also polynomial time."}, {"heading": "4.3. SU Q-value and the local detection probability", "text": "Solving the optimization problem of (7) requires the estimates of the probabilities of missed detection at the FC. Defining the reward as in (5) provides simultaneously a simple estimate for the SUs\u2019 probabilities of detection.\nSince the SU Q-values are updated according to equation (1) similarly to the subband Q-values, it can be shown that the asymptotic expected Q-values E[Qk(s, b)] approach the expected reward as k \u2192 \u221e. From equation (5) assuming that E[Qk+1(s, b)] =\nk\u2192\u221e E[Qk(s, b)] we get\nlim k\u2192\u221e E[Qk+1(s, b)] = lim k\u2192\u221e E[rk(s, b)] =\nP1P(d(FC) = 1 \u2229 d(s) = 1|H1) P1Pd,FC + P0Pf,FC + P0P(d(FC) = 1 \u2229 d(s) = 1|H0) P1Pd,FC + P0Pf,FC ,\nwhere P0 is the probability of the subband being free, P1 = 1\u2212P0, d(s) and d(FC) are the decision at SU s and at the FC, respectively, and Pd,FC and Pf,FC are, respectively, the probabilities of detection and false alarm at the FC. For notational convenience the subband index b has been dropped.\nFor the OR-rule P(d(FC) = 1 \u2229 d(s) = 1|H1) = P(d(s) = 1|H1) = Pd,s and P(d(FC) = 1\u2229d(s) = 1|H0) = P(d(s) = 1|H0) = Pf,s, since P(d(FC) = 1|d(s) = 1) = 1. Then,\nlim k\u2192\u221e\nE[Qk+1(s, b)] = P1Pd,s + P0Pf,s P1Pd,FC + P0Pf,FC \u2248 Pd,s Pd,FC ,\nassuming that P0Pf,s \u2248 0 and P0Pf,FC \u2248 0. It can be seen that in order for the local detection probability estimates to be close enough to the detection probability at the FC Pd,FC should be close to one. This can be achieved\nthrough spatial diversity if the decision at the FC is based on multiple SUs\u2019 local test statistics or decisions.\nFigure 7 shows converged SU Q-values ordered by mean SNR and the true probability of detection curve. The detection scheme is Neyman-Pearson energy detection with a sample size 50 and Pf,FC = 0.01. The fusion rule is the OR-rule with D = 2 and \u03b1 = 0.1. It can be seen that the Q-values align with the true probabilities of detection."}, {"heading": "4.4. Convergence of the subband Q-values", "text": "Since all the subbands are not necessarily sensed all the time, we need to introduce another time variable Tk(b) \u2264 k denoting the number of sensing instances (and value updates) at band b up to the kth run of the -greedy algorithm. Regrouping the components in equation (1) the Q-value of subband b can be expressed as\nQTk(b)+1(b) = (1\u2212 \u03b1)QTk(b)(b) + \u03b1rk(b).\nTaking the expectation of both sides results to\nE[QTk(b)+1(b)] = (1\u2212 \u03b1)E[QTk(b)(b)] + \u03b1\u00b5(b),\nwhere \u00b5(b) = E[rk(b)]. This is a linear recurrence, whose solution is given by\nE[QTk(b)+1(b)] = \u03b1 Tk(b)+1E[Q0(b)]+\n( 1\u2212 (1\u2212 \u03b1)Tk(b)+1 ) \u00b5(b).\nAssuming E[Q0(b)] = 0 the expected Q-value of band b at the Tk(b)th update is\nE[QTk(b)(b)] = (1\u2212 (1\u2212 \u03b1) Tk(b))\u00b5(b) = \u00b5(b).\nas Tk(b)\u2192\u221e. Then the expected Q-value of band b after the kth run of the -greedy algorithm is given by\nE[Qk(b)] = \u00b5(b) k\u2211\nTk(b)=0\nP(Tk(b))(1\u2212 (1\u2212 \u03b1)Tk(b)), (13)\nwhere P(Tk(b)) is the probability that band b has been updated Tk(b) times within the k runs of -greedy algorithm.\nUpper and lower bounds can be easily obtained for P(Tk(b)) in a stationary case:\nB(Tk(b), k, L\nNB ) \u2264 P(Tk(b)) \u2264 B(Tk(b), k, 1\u2212 (1\u2212\nL\nNB )),\nwhere B(Tk(b), k, p) = (\nk Tk(b)\n) pTk(b)(1\u2212 p)k\u2212Tk(b) is the bi-\nnomial probability density function. The lower bound corresponds to the probability that the Q-value is updated only in the exploration phase and the upper bound to the case that in the exploitation phase the Q-value is updated with probability one.\nThe analysis for the convergence of the SU Q-values is almost identical to the analysis above for the Q-values of the subbands. The probability P(Tk(b, s)) that SU s has sensed subband b during k runs Tk(b, s) times is then bounded as\nB(Tk(b, s), k, L\nN2B ) \u2264 P(Tk(b, s)) \u2264 B(Tk(b, s), k, 1\u2212 (1\u2212\nL\nN2B )).\nEstablishing a lower bound for the probability of the number of sensings is important for guaranteeing a desired convergence rate for the estimates of the probability of missed detections in the second stage of the proposed sensing policy.\nFigure 8 shows the simulated convergence of the expected Q-values of 5 subbands and the upper and lower bounds for them. The number of sensed bands is set to L = 1. The rewards are assumed to be Bernoulli distributed with probability P0 = 0.5 and means \u00b5(1) = \u00b5(2) = \u00b5(3) = \u00b5(4) = 1 and \u00b5(5) = 10."}, {"heading": "5. Simulation examples", "text": "In this section simulation results for the proposed sensing policy are shown. The main focus is put on the obtained throughput of the secondary network and miss detection probability."}, {"heading": "5.1. Stationary case", "text": "This subsection provides the results for a stationary scenario in which the occupancy statistics of the primary bands stay constant during the whole simulation period. The results are shown for the throughput, average miss detection probability and relative number of sensings in the SU network with different values of . Furthermore, the simulations are shown for comparison using the exact BB search and an approximative iterative Hungarian (IH) method adapted from [22]. In the stationary case the mean detection performances of the SUs remain constant. The simulations are done for NS = 6 SUs and NP = 10 primary subbands. The availability of each subband is modeled according to a two state Markov chain (see figure 4) with state transition probabilities P11 = P00 = 0.9. Different subbands are assumed to be independent of each other. The mean SNRs of the primary signal in the secondary network is assumed to be distributed according to the log-normal shadow model with a standard deviation of 9 dBs. The fast fading component of the channel is modeled as a block fading Rayleigh channel with expected power gain of 1. Furthermore, it is assumed that 3 of the subbands are able to provide 10 times higher throughputs on average. For spectrum sensing Neyman-Pearson energy detection with a sample size of 50 is used. The global decisions at the FC are formed using the hard decision OR-rule with a constant false alarm rate Pf,FC = 0.01. In the exploration phase the pseudorandom frequency hopping code design is made using a fixed diversity order D = 2 that has been selected such that on average the desired miss detection probability is close to Pmiss,target. In the exploitation phase the number of subbands SUs can sense simultaneously is set to Ks = 1,\u2200s \u2208 S, and the target probability of miss detection at the subbands Pmiss,target(b) = 0.1. The weights ws in the SAP have been set to 1 for all SUs. The number of subbands that the SU network wants to find is constant during the whole simulation, i.e., L = 3. For clarity in this section the step sizes in the first and seconds stage of the sensing policy are denoted as \u03b11 and \u03b12 respectively. In the simulations \u03b11 = 0.01 and \u03b12 = 0.1.\nFigure 9 shows the cumulative throughput relative to an ideal, genie aided policy. An ideal policy is assumed to be able to find all spectrum opportunities and select the L subbands with highest instantaneous throughputs. The obtained throughput using the exact BB search and the throughput using the heuristic IH method are practically the same. However, in this case the IH method found the assignment on average 80 times faster than the BB search. It can be noticed that with = 0.1 the proposed policy is finally obtaining 83% of the throughput of an ideal policy.\nAs can be seen the trade-off with small comes naturally with a slower rate of convergence.\nFigure 10 shows the probability of miss detection for different choices of . The diversity order for the fixed policy (curve corresponding to = 1) was selected such that on the average the target miss detection probability is achieved. The resulting average miss detection probability using the exact BB search and using the heuristic IH method are almost the same. When is decreased the policy starts assigning those SUs with high probability of detection to sense the corresponding subbands more often thus decreasing the overall number of miss detections. For = 0.1 and = 0.3 the average miss detection probability is finally at the end of the simulation close to 0.04.\nFigure 11 shows the number of sensings over time compared to a sensing policy with fixed diversity order D = 2 (exploration only). The savings in the number of sensings using the exact BB search and using the heuristic IH method are again practically same. For the case = 0.1 the number of sensings and transmissions of the local sensing results to the FC are reduced to 56%."}, {"heading": "5.2. Expected throughput for non-stationary cases", "text": "For a non-stationary scenario the throughput of the proposed sensing policy is compared against two other methods. The results are shown only for the first stage of the proposed sensing policy that attempts to maximize the throughput of the secondary network. The results are shown for a case in which the availability of the subbands is Markov process and for a case in which the availability is a Bernoulli process (i.e. a special case of a two-state Markov chain). Moreover, the proposed policy is compared to two other state-of-the-art policies. Namely, the comparison is done against the discounted UCB (DUCB) policy with a discount factor \u03b3 [17] and a near-optimal sensing policy [13], the Whittle index policy, that assumes the state transition probabilities in the Markov chain to be known. The comparison between the Whittle index policy and the two machine learning-based policies is therefore not entirely fair since the assumptions about prior knowledge are different.\nHere the number of subbands has been set to NB = 5 and the number of simultaneously sensed bands to L = 1. The missed detection probability at the FC is assumed to be Pmiss,FC = 0.1 and the false alarm rate Pf,FC = 0.01 using Neyman-Pearson detectors. The mean throughputs of the bands bands are [11, 21, 31, 41, 51]. In the first scenario the transition probabilities of the Markov\nchain are initialized as P00 = [0.5, 0.9, 0.6, 0.8, 0.8] and P11 = [0.9, 0.31, 0.7, 0.9, 0.3]. In the Bernoulli case the probabilities of the subbands being free are initialized as P0 = [0.87, 0.17, 0.43, 0.33, 0.78]. To simulate nonstationary behavior the transition probabilities and the mean rewards are randomly permutated among the subbands at random time instances.\nFigure 12 shows the expected mean throughput for the non-stationary Markovian case. Since it is assumed that the Whittle index policy knows the throughput distributions perfectly at each time, the optimized policy is naturally giving the highest throughput. It can be seen that DUCB adapts fast at the beginning when the discounted mean throughputs in the algorithm have been set to zero. However, after the first change in the throughput distributions the convergence of DUCB slows down significantly. The proposed sensing policy with -greedy exploration seems to provide more consistent convergence at all times.\nFigure 13 shows the expected throughput for the nonstationary Bernoulli case. Here only results are shown for the two machine learning-based policies, since neither of them does not assume any prior knowledge about the underlying Bernoulli process. The two machine learning based sensing policies perform almost alike as in the first non-stationary scenario, with the proposed policy giving slightly better overall performance than the DUCB policy."}, {"heading": "6. Conclusions", "text": "In this paper a machine learning based multi-band spectrum sensing policy is proposed. In the proposed policy the\n-greedy method is employed to track the occupancy statistics of the PU and to estimate the detection performance of the SUs. Using the -greedy method the proposed policy exploits the gained knowledge about the throughputs of different subbands by selecting the sensed subbands as the ones with the highest Q-value. Furthermore, knowledge about the detection performances of different SUs is exploited by minimizing the number of SUs assigned for sensing that are collaboratively able to meet a desired miss detection probability threshold.\nExploration of the radio spectrum and different sensing assignments is realized using pseudorandom frequency hopping codes with fixed diversity order. Firstly, the pseudorandom exploration with fixed diversity order guarantees reliable sensing, and secondly, eventually all possible SU combinations of size D will be considered.\nIn the exploitation phase the sensing assignment problem is formulated as a binary integer programming problem in which the objective is to minimize the number of sensorsD per subband while ensuring the desired detection performance at each subband. By minimizing the number of sensing SUs per subband energy of the battery operated users is conserved and the amount of transmitted local test statistics is reduced. The optimal sensing assignment may be found by using exact branch-and-bound search or an approximative algorithm such as the iterative Hungarian method.\nIn this paper we demonstrate the performance of the proposed sensing policy and derive analytical expressions about the convergence of the policy. The simulation results show that the proposed sensing policy provides excellent performance in terms of throughput, detection probability and energy efficiency."}], "references": [{"title": "Implementation Issues in Spectrum Sensing for Cognitive Radios", "author": ["D. Cabric", "S.M. Mishra", "R.W. Brodersen"], "venue": "in: Proc. of the Asilomar Conference on Signals, Systems and Computers, vol. 1, 772\u2013776", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Cognitive Radio: Brain-Empowered Wireless Communications", "author": ["S. Haykin"], "venue": "IEEE J. Sel. Areas Commun. 23 (2) ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "A Survey of Dynamic Spectrum Access", "author": ["Q. Zhao", "B.M. Sadler"], "venue": "IEEE Signal Process. Mag. 24 (3) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "Collaborative Cyclostationary Spectrum Sensing for Cognitive Radio Systems", "author": ["J. Lund\u00e9n", "V. Koivunen", "A. Huttunen", "H.V. Poor"], "venue": "IEEE Trans. Signal Process. 57 (11) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Autocorrelation-Based Decentralized Sequential Detection of OFDM Signals in Cognitive Radios", "author": ["S. Chaudhari", "V. Koivunen", "H.V. Poor"], "venue": "IEEE Trans. Signal Process. 57 (7) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Reinforcement Learning Method for Energy Efficient Cooperative Multiband Spectrum Sensing", "author": ["J. Oksanen", "J. Lund\u00e9n", "V. Koivunen"], "venue": "in: Proc. of the MLSP Conference, Kittil\u00e4, Finland, 59\u201364", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "On Myopic Sensing for Multi-Channel Opportunistic Access: Structure", "author": ["Q. Zhao", "B. Krishnamachari", "K. Liu"], "venue": "Optimality and Performance, IEEE Trans. Wireless Commun. ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Opportunistic Spectrum Access via Periodic Channel Sensing", "author": ["Q. Zhao", "S. Geirhofer", "L. Tong", "B.M. Sadler"], "venue": "IEEE Trans. Signal Process. 56 (2) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Decentralized Cognitive MAC for Opportunistic Spectrum Access in Ad Hoc Networks: A POMDP Framework", "author": ["Q. Zhao", "L. Tong", "A. Swami", "Y. Chen"], "venue": "IEEE J. Sel. Areas Commun. 25 (3) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "A Near Optimal Policy for Channel Allocation in Cognitive Radio", "author": ["S. Filippi", "O. Capp\u00e9", "F. Cl\u00e9rot", "E. Moulines"], "venue": "in: Proc. of the EWRL workshop, 69\u201381", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Cooperation and Learning in Multiuser Opportunistic Spectrum Access", "author": ["H. Liu", "B. Krishnamachari", "Q. Zhao"], "venue": "in: Proc. of ICC Workshops, 487\u2013492", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Dynamic Multichannel Access With Imperfect Channel State Detection", "author": ["K. Liu", "Q. Zhao", "B. Krishnamachari"], "venue": "IEEE Trans. Signal Process. 58 (5) ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Indexability of Restless Bandit Problems and Optimality of Whittle Index for Dynamic Multichannel Access", "author": ["K. Liu", "Q. Zhao"], "venue": "IEEE Trans. Inf. Theory 56 ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Technical Note: Q-Learning", "author": ["C. Watkins", "P. Dayan"], "venue": "Machine Learning 8 ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1992}, {"title": "Reinforcement Learning: An Introduction", "author": ["R.S. Sutton", "A.G. Barto"], "venue": "Cambridge, MA: MIT Press", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1998}, {"title": "Finite-time Analysis of the Multiarmed Bandit Problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine Learning 47 ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Discounted-UCB", "author": ["L. Kocsis", "C. Szepesv\u00e1ri"], "venue": "in: 2nd PASCAL Challenges Workshop", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2006}, {"title": "M", "author": ["U. Berthold", "F. Fu"], "venue": "van der Schaar, F. Jondral, Detection of Spectral Resources in Cognitive Radios Using Reinforcement Learning, in: Proc. of DySPAN, 1\u20135", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Capacity of Burst-noise Channels", "author": ["E.N. Gilbert"], "venue": "Bell Syst. Tech. J. 39 ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1960}, {"title": "Diversitybased Spectrum Sensing Policy for Detecting Primary Signal Over Multiple Frequency Bands", "author": ["J. Oksanen", "V. Koivunen", "J. Lund\u00e9n", "A. Huttunen"], "venue": "in: Proc. of the ICASSP Conference, Dallas Texas, 3130\u20133133", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "An Iterative Hungarian Algorithm Based Coordinated Spectrum Sensing Strategy", "author": ["Z. Wang", "Z. Feng", "P. Zhang"], "venue": "IEEE Commun. Lett. 15 (1) ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "The Hungarian Method for the Assignment Problem", "author": ["H.W. Kuhn"], "venue": "Naval Res. Logistics Q. 2 ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1955}], "referenceMentions": [{"referenceID": 0, "context": "Measurement campaigns [1] have in fact shown that large parts of the spectrum are underutilized because the license holders are not using the spectrum or because the fact that wireless signals attenuate in 2\u2212 4 power of distance is not fully exploited.", "startOffset": 22, "endOffset": 25}, {"referenceID": 1, "context": "Identifying temporal and spatial spectrum holes has been the key motivation behind cognitive radio (CR) and dynamic spectrum access (DSA) [2].", "startOffset": 138, "endOffset": 141}, {"referenceID": 2, "context": "interfered by the PU [3].", "startOffset": 21, "endOffset": 24}, {"referenceID": 1, "context": "In order to mitigate the effects of fading, cooperative detection schemes have been proposed in the literature [2, 4, 5].", "startOffset": 111, "endOffset": 120}, {"referenceID": 3, "context": "In order to mitigate the effects of fading, cooperative detection schemes have been proposed in the literature [2, 4, 5].", "startOffset": 111, "endOffset": 120}, {"referenceID": 4, "context": "In order to mitigate the effects of fading, cooperative detection schemes have been proposed in the literature [2, 4, 5].", "startOffset": 111, "endOffset": 120}, {"referenceID": 5, "context": "Some preliminary ideas and results related to this paper were presented in [6].", "startOffset": 75, "endOffset": 78}, {"referenceID": 2, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 6, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 7, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 8, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 9, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 10, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 11, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 12, "context": "In [3, 7\u201313] spectrum sensing policies are derived based on the framework of partially observable Markov decision processes (POMDPs).", "startOffset": 3, "endOffset": 12}, {"referenceID": 12, "context": "In [13] a closed form Whittle index policy for perfectly known Markovian reward distributions was derived and shown to be optimal under certain conditions.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "A standard method for tackling multi-armed bandit problems is the Q-learning algorithm [14] with -greedy exploration [15].", "startOffset": 87, "endOffset": 91}, {"referenceID": 14, "context": "A standard method for tackling multi-armed bandit problems is the Q-learning algorithm [14] with -greedy exploration [15].", "startOffset": 117, "endOffset": 121}, {"referenceID": 15, "context": "Namely, in [16] a simple policy based on upper confidence bounds (UCB) was proposed and shown to reach the optimal regret rate when the rewards are independent and stationary.", "startOffset": 11, "endOffset": 15}, {"referenceID": 16, "context": "An UCB policy that suits better for non-stationary rewards was developed in [17].", "startOffset": 76, "endOffset": 80}, {"referenceID": 17, "context": "In [18] a single-user reinforcement learning method was proposed for selecting between 3 future actions: continuing sensing at the current frequency band b and transmitting data, sensing an out-of-band frequency band b\u0303, and switching the SU system to an out-of-band frequency band b\u0303.", "startOffset": 3, "endOffset": 7}, {"referenceID": 8, "context": "One proposed approach to model the PU activity is a two-state Markov chain shown in figure 4 [9].", "startOffset": 93, "endOffset": 96}, {"referenceID": 18, "context": "Figure 4: The Gilbert-Elliot channel model [19].", "startOffset": 43, "endOffset": 47}, {"referenceID": 14, "context": "ak = arg maxaQk(a), with probability 1\u2212 , or a random action, uniformly, with probability regardless of the action-value estimates [15].", "startOffset": 131, "endOffset": 135}, {"referenceID": 14, "context": "After taking action a reward r(a) is collected after which the Q-value of action a is updated as [15]", "startOffset": 97, "endOffset": 101}, {"referenceID": 14, "context": "In a stationary scenario convergence is guaranteed with probability 1 when the step size parameter \u03b1k satisfies the following conditions [15]", "startOffset": 137, "endOffset": 141}, {"referenceID": 14, "context": "[15]", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "In this section the pseudorandom frequency hopping based sensing policy proposed in [20] is briefly summarized, since it constitutes the exploration phase of the sensing policy developed in this paper.", "startOffset": 84, "endOffset": 88}, {"referenceID": 19, "context": "For more information about the choice of \u2206q and the design of the frequency hopping sequences as well as simulation results see [20].", "startOffset": 128, "endOffset": 132}, {"referenceID": 20, "context": "In [22] an iterative Hungarian algorithm is proposed to find a sensing assignment that minimizes the probability of miss detection.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "The policy assigns SUs to sense the subbands one by one using the Hungarian method [23].", "startOffset": 83, "endOffset": 87}, {"referenceID": 20, "context": "In our problem formulation, the Hungarian method can be employed iteratively, similarly to [22], to find a near optimal solution for the SAP with ws = 1 by modifying the algorithm to stop immediately once a feasible solution is found.", "startOffset": 91, "endOffset": 95}, {"referenceID": 20, "context": "Furthermore, the simulations are shown for comparison using the exact BB search and an approximative iterative Hungarian (IH) method adapted from [22].", "startOffset": 146, "endOffset": 150}, {"referenceID": 16, "context": "Namely, the comparison is done against the discounted UCB (DUCB) policy with a discount factor \u03b3 [17] and a near-optimal sensing policy [13], the Whittle index policy, that assumes the state transition probabilities in the Markov chain to be known.", "startOffset": 97, "endOffset": 101}, {"referenceID": 12, "context": "Namely, the comparison is done against the discounted UCB (DUCB) policy with a discount factor \u03b3 [17] and a near-optimal sensing policy [13], the Whittle index policy, that assumes the state transition probabilities in the Markov chain to be known.", "startOffset": 136, "endOffset": 140}, {"referenceID": 10, "context": "The mean throughputs of the bands bands are [11, 21, 31, 41, 51].", "startOffset": 44, "endOffset": 64}], "year": 2011, "abstractText": "This paper introduces a machine learning based collaborative multi-band spectrum sensing policy for cognitive radios. The proposed sensing policy guides secondary users to focus the search of unused radio spectrum to those frequencies that persistently provide them high data rate. The proposed policy is based on machine learning, which makes it adaptive with the temporally and spatially varying radio spectrum. Furthermore, there is no need for dynamic modeling of the primary activity since it is implicitly learned over time. Energy efficiency is achieved by minimizing the number of assigned sensors per each subband under a constraint on miss detection probability. It is important to control the missed detections because they cause collisions with primary transmissions and lead to retransmissions at both the primary and secondary user. Simulations show that the proposed machine learning based sensing policy improves the overall throughput of the secondary network and improves the energy efficiency while controlling the miss detection probability.", "creator": "LaTeX with hyperref package"}}}