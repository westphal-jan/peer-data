{"id": "1107.0026", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2011", "title": "IDL-Expressions: A Formalism for Representing and Parsing Finite Languages in Natural Language Processing", "abstract": "We propose a formalism for representation of finite languages, referred to as the class of IDL-expressions, which combines concepts that were only considered in isolation in existing formalisms. The suggested applications are in natural language processing, more specifically in surface natural language generation and in machine translation, where a sentence is obtained by first generating a large set of candidate sentences, represented in a compact way, and then by filtering such a set through a parser. We study several formal properties of IDL-expressions and compare this new formalism with more standard ones. We also present a novel parsing algorithm for IDL-expressions and prove a non-trivial upper bound on its time complexity. For example, in an arbitrary language, the initial result should be the final result. In this case, the result should be of less than 10% probability of finding an edge, a lower bound for some particular feature that may or may not be considered in a general language, such as English. The problem with this approach is that IDL-expressions have an extremely low time complexity.\n\n\nThe algorithm is based on a standard encoding algorithm that can read an initial sentence from the standard to the standard. It has the maximum range of 20 characters. Its approach has the minimum length of 1 character, and can also read additional characters. There is a very large variety of different formalisms in IDL-expressions, most recently used in a language that uses language that uses the encoding encoding algorithm (Fang et al., 2012 ).\nWe show that the algorithm for IDL-expressions, in turn, can be written by an algorithm that combines the encoding algorithm with the encoding algorithm. The algorithm for IDL-expressions is called a P.A.G.S. (p.E.G.S). The algorithm for IDL-expressions is called P.A.G.S. (p.E.G.S). The algorithm for P.A.G.S. (p.E.G.S. S), P.E.G.S. (p.E.G.S.), P.E.G.S. (p.E.G.S.) and P.E.G.S. (p.E.G.S.) as well as S. and P.E.G.S. (p.E.G.S.) respectively.\nThe algorithm for the IDL-expressions, in turn, can be written", "histories": [["v1", "Thu, 30 Jun 2011 20:33:50 GMT  (139kb)", "http://arxiv.org/abs/1107.0026v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["m j nederhof", "g satta"], "accepted": false, "id": "1107.0026"}, "pdf": {"name": "1107.0026.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Mark-Jan Nederhof", "markjan let.rug.nl", "Giorgio Satta"], "emails": [], "sections": [{"heading": "Journal of Arti ial Intelligen e Resear h 21 (2004) 287-317 Submitted 06/03; published 03/04", "text": "IDL-Expressions:A Formalism for Representing and ParsingFinite Languages in Natural Language Pro essingMark-Jan Nederhof markjan let.rug.nlFa ulty of Arts, University of GroningenP.O. Box 716NL-9700 AS Groningen, The NetherlandsGiorgio Satta satta dei.unipd.itDept. of Information Engineering, University of Paduavia Gradenigo, 6/AI-35131 Padova, Italy Abstra tWe propose a formalism for representation of nite languages, referred to as the lassof IDL-expressions , whi h ombines on epts that were only onsidered in isolation inexisting formalisms. The suggested appli ations are in natural language pro essing, morespe i ally in surfa e natural language generation and in ma hine translation, where asenten e is obtained by rst generating a large set of andidate senten es, represented ina ompa t way, and then ltering su h a set through a parser. We study several formalproperties of IDL-expressions and ompare this new formalism with more standard ones.We also present a novel parsing algorithm for IDL-expressions and prove a non-trivial upperbound on its time omplexity.1. Introdu tionIn natural language pro essing, more spe i ally in appli ations that involve natural lan-guage generation, the task of surfa e generation onsists in the pro ess of generating an out-put senten e in a target language, on the basis of some input representation of the desiredmeaning for the output senten e. During the last de ade, a number of new approa hes fornatural language surfa e generation have been put forward, alled hybrid approa hes. Hy-brid approa hes make use of symboli knowledge in ombination with statisti al te hniquesthat have re ently been developed for natural language pro essing. Hybrid approa hestherefore share many advantages with statisti al methods for natural language pro essing,su h as high a ura y, wide overage, robustness, portability and s alability.Hybrid approa hes are typi ally based on two pro essing phases, des ribed in whatfollows (Knight & Hatzivassiloglou, 1995; Langkilde & Knight, 1998; Bangalore & Rambow,2000 report examples of appli ations of this approa h in real world generation systems).In the rst phase one generates a large set of andidate senten es by a relatively simplepro ess. This is done on the basis of an input senten e in some sour e language in asethe pro ess is embedded within a ma hine translation system, or more generally on thebasis of some logi al/semanti representation, alled on eptual stru ture, whi h denotesthe meaning that the output senten e should onvey. This rst phase involves no or only 2004 AI A ess Foundation. All rights reserved.\nNederhof & Sattafew intri a ies of the target language, and the set of andidate senten es may ontain manythat are ungrammati al or that an otherwise be seen as less desirable than others. In these ond phase one or more preferred senten es are sele ted from the olle tion of andidates,exploiting some form of synta ti pro essing that more heavily relies on properties of thetarget language than the rst phase. This synta ti pro essing may involve language modelsas simple as bigrams or it may involve more powerful models su h as those based on ontext-free grammars, whi h typi ally perform with higher a ura y on this task (see for instan ework presented by Charniak, 2001 and referen es therein).In hybrid approa hes, the generation of the andidate set typi ally involves a symboli grammar that has been qui kly hand-written, and is quite small and easy to maintain.Su h a grammar annot therefore a ount for all of the intri a ies of the target language.For instan e, frequen y information for synonyms and ollo ation information in generalis not en oded in the grammar. Similarly, lexi o-synta ti and sele tional onstraints forthe target language might not be fully spe i ed, as is usually the ase with small and mid-sized grammars. Furthermore, there might also be some underspe i ation stemming fromthe input on eptual stru ture. This is usually the ase if the surfa e generation moduleis embedded into a larger ar hite ture for ma hine translation, and the sour e language isunderspe i ed for features su h as de niteness, time and number. Sin e inferring the missinginformation from the senten e ontext is a very di\u00c6 ult task, the surfa e generation moduleusually has to deal with underspe i ed knowledge.All of the above-mentioned problems are well-known in the literature on natural languagesurfa e generation, and are usually referred to as \\la k of knowledge\" of the system or of theinput. As a onsequen e of these problems, the set of andidate senten es generated in the rst phase may be extremely large. In real world generation systems, andidate sets havebeen reported to ontain as many as 1012 senten es (Langkilde, 2000). As already explained,the se ond pro essing phase in hybrid approa hes is intended to redu e these huge sets tosubsets ontaining only a few senten es. This is done by exploiting knowledge about thetarget language that was not available in the rst phase. This additional knowledge anoften be obtained through automati extra tion from orpora, whi h requires onsiderablyless e ort than the development of hand-written, purely symboli systems.Due to the extremely large size of the set of andidate senten es, the feasibility of hybridapproa hes to surfa e natural language generation relies on the ompa tness of the representation of a set of andidate senten es that in real worldsystems might be as large as 1012; and the e\u00c6 ien y of synta ti pro essing of the stored set.Several solutions have been adopted in existing hybrid systems for the representationof the set of andidate senten es. These in lude bags of words (Brown et al., 1990) andbags of omplex lexi al representations (Beaven, 1992; Brew, 1992; Whitelo k, 1992), wordlatti es (Knight & Hatzivassiloglou, 1995; Langkilde & Knight, 1998; Bangalore & Rambow,2000), and non-re ursive ontext-free grammars (Langkilde, 2000). As will be dis ussed indetail in Se tion 2, word latti es and non-re ursive ontext-free grammars allow en odingof pre eden e onstraints and hoi e among di erent words, but they both la k a primitivefor representing strings that are realized by ombining a olle tion of words in an arbitrary288\nIDL-Expressions: A Formalism for Finite Languagesorder. On the other hand, bags of words allow the en oding of free word order, but insu h a representation one annot dire tly express pre eden e onstraints and hoi e amongdi erent words.In this paper we propose a new representation that ombines all of the above-mentionedprimitives. This representation onsists of IDL-expressions. In the term IDL-expression,`I' stands for \\interleave\", whi h pertains to phrases that may o ur interleaved, allowingfreedom on word order (a pre ise de nition of this notion will be provided in the nextse tion); `D' stands for \\disjun tion\", whi h allows hoi es of words or phrases; `L' standsfor \\lo k\", whi h is used to onstrain the appli ation of the interleave operator. We studysome interesting properties of this representation, and argue that the expressivity of theformalism makes it more suitable than the alternatives dis ussed above for use within hybridar hite tures for surfa e natural language generation. We also asso iate IDL-expressionswith IDL-graphs, an equivalent representation that an be more easily interpreted by ama hine, and develop a dynami programming algorithm for parsing IDL-graphs using a ontext-free grammar. If a set of andidate senten es is represented as an IDL-expressionor IDL-graph, the algorithm an be used to lter out ungrammati al senten es from theset, or to rank the senten es in the set a ording to their likelihood, in ase the ontext-freegrammar assigns weights to derivations. While parsing is traditionally de ned for input onsisting of a single string, we here on eive parsing as a pro ess that an be arried outon an input devi e denoting a language, i.e., a set of strings.There is a super ial similarity between the problem des ribed above of representing nite sets in surfa e generation, and a di erent resear h topi , often referred to as dis on-tinuous parsing. In dis ontinuous parsing one seeks to relax the de nition of ontext-freegrammars in order to represent the syntax of languages that exhibit onstru tions with un- ertainty on word or onstituent order (see for instan e work reported by Daniels & Meurers,2002 and referen es therein). In fa t, some of the operators we use in IDL-expressions havealso been exploited in re ent work on dis ontinuous parsing. However, the parsing problemfor dis ontinuous grammars and the parsing problem for IDL-expressions are quite di er-ent: in the former, we are given a grammar with produ tions that express un ertainty on onstituent order, and need to parse an input string whose symbols are totally ordered; inthe latter problem we are given a grammar with total order on the onstituents appear-ing in ea h produ tion, and need to parse an input that in ludes un ertainty on word and onstituent order.This paper is stru tured as follows. In Se tion 2 we give a brief overview of existingrepresentations of nite languages that have been used in surfa e generation omponents.We then dis uss some notational preliminaries in Se tion 3. In Se tion 4 we introdu e IDL-expressions and de ne their semanti s. In Se tion 5 we asso iate with IDL-expressions anequivalent but more pro edural representation, alled IDL-graphs. We also introdu e theimportant notion of ut of an IDL-graph, whi h will be exploited later by our algorithm.In Se tion 6 we brie y dis uss the Earley algorithm, a traditional method for parsing astring using a ontext-free grammar, and adapt this algorithm to work on nite languagesen oded by IDL-graphs. In Se tion 7 we prove a non-trivial upper bound on the numberof uts in an IDL-graph, and on this basis we investigate the omputational omplexity ofour parsing algorithm. We also address some implementational issues. We on lude withsome dis ussion in Se tion 8. 289\nNederhof & Satta2. Representations of Finite LanguagesIn this se tion we analyze and ompare existing representations of nite languages that havebeen adopted in surfa e generation omponents of natural language systems.Bags (or multisets) of words have been used in several approa hes to surfa e generation.They are at the basis of the generation omponent of the statisti al ma hine translationmodels proposed by Brown et al. (1990). Bags of omplex lexi al signs have also been usedin the ma hine translation approa h des ribed by Beaven (1992) and Whitelo k (1992), alled shake-and-bake. As already mentioned, bags are a very su in t representation of nite languages, sin e they allow en oding of more than exponentially many strings in thesize of a bag itself. This power omes at a ost, however. De iding whether some stringen oded by an input bag an be parsed by a CFG is NP- omplete (Brew, 1992). It is notdi\u00c6 ult to show that this result still holds in the ase of a regular grammar or, equivalently,a regular expression. An NP- ompleteness result involving bags has also been presentedby Knight (1999), for a related problem where the parsing grammar is a probabilisti modelbased on bigrams.As far as expressivity is on erned, bags of words have also stri t limitations. Thesestru tures la k a primitive for expressing hoi es among words. As already observed inthe introdu tion, this is a serious problem in natural language generation, where alterna-tives in lexi al realization must be en oded in the presen e of la k of detailed knowledgeof the target language. In addition, bags of words usually do not ome with pre eden e onstraints. However, in natural language appli ations these onstraints are very ommon,and are usually derived from knowledge about the target language or, in the ase of ma- hine translation, from the parsing tree of the sour e string. In order to represent these onstraints, extra ma hinery must be introdu ed. For instan e, Brown et al. (1990) impose,for ea h word in the bag, a probabilisti distribution delimiting its position in the targetstring, on the basis of the original position of the sour e word in the input string to betranslated. In the shake and bake approa h, bags are de ned over fun tional stru tures,ea h representing omplex lexi al information from whi h onstraints an be derived. Thenthe parsing algorithm for bags is interleaved with a onstraint propagation algorithm to lter out parses (e.g., as done by Brew, 1992). As a general remark, having di erent layersof representation requires the development of more involved parsing algorithms, whi h wetry to avoid in the new proposal to be des ribed below.An alternative representation of nite languages is the lass of a y li deterministi -nite automata, also alled word latti es. This representation has often been used in hybridapproa hes to surfa e generation (Knight & Hatzivassiloglou, 1995; Langkilde & Knight,1998; Bangalore & Rambow, 2000), and more generally in natural language appli ationswhere some form of un ertainty omes with the input, as for instan e in spee h re ogni-tion (Jurafsky & Martin, 2000, Se tion 7.4). Word latti es inherit from standard regularexpressions the primitives expressing on atenation and disjun tion, and thereby allow theen oding of pre eden e onstraints and word disjun tion in a dire t way. Furthermore, wordlatti es an be e\u00c6 iently parsed by means of CFGs, using standard te hniques for latti eparsing (Aust, Oerder, Seide, & Steinbiss, 1995). Latti e parsing requires ubi time inthe number of states of the input nite automaton and linear time in the size of the CFG.Methods for latti e parsing an all be tra ed ba k to Bar-Hillel, Perles, and Shamir (1964),290\nIDL-Expressions: A Formalism for Finite Languageswho prove that the lass of ontext-free languages is losed under interse tion with regularlanguages.One limitation of word latti es and nite automata in general is the la k of an operatorfor free word order. As we have already dis ussed in the introdu tion, this is a severelimitation for hybrid systems, where free word order in senten e realization is needed in ase the symboli grammar used in the rst phase fails to provide ordering onstraints.To represent strings where a bag of words an o ur in every possible order, one has toen ode ea h string through an individual path within the latti e. In the general ase, thisrequires an amount of spa e that is more than exponential in the size of the bag. Fromthis perspe tive, the previously mentioned polynomial time result for parsing is to no avail,sin e the input stru ture to the parser might already be of size more than exponential in thesize of the input on eptual stru ture. The problem of free word order in latti e stru turesis partially solved by Langkilde and Knight (1998) by introdu ing an external re astingme hanism that prepro esses the input on eptual stru ture. This has the overall e e tthat phrases normally represented by two independent sublatti es an now be generatedone embedded into the other, therefore partially mimi king the interleaving of the words inthe two phrases. However, this is not enough to treat free word order in its full generality.A third representation of nite languages, often found in the literature on ompressiontheory (Nevill-Manning & Witten, 1997), is the lass of non-re ursive CFGs. A CFGis alled non-re ursive if no nonterminal an be rewritten into a string ontaining thenonterminal itself. It is not di\u00c6 ult to see that su h grammars an only generate nitelanguages. Non-re ursive CFGs have re ently been exploited in hybrid systems (Langkilde,2000).1 This representation inherits all the expressivity of word latti es, and thus anen ode pre eden e onstraints as well as disjun tions. In addition, non-re ursive CFGs ana hieve mu h smaller en odings of nite languages than word latti es. This is done byuniquely en oding ertain sets of substrings that o ur repeatedly through a nonterminalthat an be reused in several pla es. This feature turns out to be very useful for naturallanguage appli ations, as shown by experimental results reported by Langkilde (2000).Although non-re ursive CFGs an be more ompa t representations than word latti es,this representation still la ks a primitive for representing free word order. In fa t, a CFGgenerating the nite language of all permutations of n symbols must have size at leastexponential in n.2 In addition, the problem of de iding whether some string en oded bya non-re ursive CFG an be parsed by a general CFG is PSPACE- omplete (Nederhof &Satta, 2004).From the above dis ussion, one an draw the following on lusions. In onsidering therange of possible en odings for nite languages, we are interested in measuring (i) the om-pa tness of the representation, and (ii) the e\u00c6 ien y of parsing the obtained representationby means of a CFG. At one extreme we have the naive solution of enumerating all stringsin the language, and then independently parsing ea h individual string using a traditionalstring parsing algorithm. This solution is obviously unfeasible, sin e no ompression at allis a hieved and so the overall amount of time required might be exponential in the size of1. Langkilde (2000) uses the term \\forests\" for non-re ursive CFGs, whi h is a di erent name for the same on ept (Billot & Lang, 1989).2. An unpublished proof of this fa t has been personally ommuni ated to the authors by Je rey Shallitand Ming-wei Wang. 291\nNederhof & Sattathe input on eptual stru ture. Although word latti es are a more ompa t representation,when free word order needs to be en oded we may still have representations of exponentialsize as input to the parser, as already dis ussed. At the opposite extreme, we have solutionslike bags of words or non-re ursive CFGs, whi h allow very ompa t representations, butare still very demanding in parsing time requirements. Intuitively, this an be explainedby onsidering that parsing a highly ompressed nite language requires additional book-keeping with respe t to the string ase. What we then need to explore is some trade-o between these solutions, o ering interesting ompression fa tors at the expense of parsingtime requirements that are provably polynomial in the ases of interest. As we will show inthe sequel of this paper, IDL-expressions have these required properties and are thereforean interesting solution to the problem.3. NotationIn this se tion we brie y re all some basi notions from formal language theory. For moredetails we refer the reader to standard textbooks (e.g., Harrison, 1978).For a set , j j denotes the number of elements in ; for a string x over some alphabet,jxj denotes the length of x. For string x and languages (sets of strings) L and L0, we letx L = fxy j y 2 Lg and L L0 = fxy j x 2 L; y 2 L0g. We remind the reader thata string-valued fun tion f over some alphabet an be extended to a homomorphismover by letting f(\") = \" and f(ax) = f(a)f(x) for a 2 and x 2 . We also letf(L) = ff(x) j x 2 Lg.We denote a ontext-free grammar (CFG) by a 4-tuple G = (N ; ; P; S), where N is a nite set of nonterminals, is a nite set of terminals, with \\N = ;, S 2 N is a spe ialsymbol alled the start symbol, and P is a nite set of produ tions having the form A! ,with A 2 N and 2 ( [N ) . Throughout the paper we assume the following onventions:A;B;C denote nonterminals, a; b; denote terminals, ; ; ; \u00c6 denote strings in ( [ N ) and x; y; z denote strings in .The derives relation is denoted )G and its transitive losure )+G. The language gener-ated by grammar G is denoted L(G). The size of G is de ned asjGj = X(A! )2P jA j : (1)4. IDL-ExpressionsIn this se tion we introdu e the lass of IDL-expressions and de ne a mapping from su hexpressions to sets of strings. Similarly to regular expressions, IDL-expressions generate setsof strings, i.e., languages. However, these languages are always nite. Therefore the lass oflanguages generated by IDL-expressions is a proper subset of the lass of regular languages.As already dis ussed in the introdu tion, IDL-expressions ombine language operators thatwere only onsidered in isolation in previous representations of nite languages exploitedin surfa e natural language generation. In addition, some of these operations have beenre ently used in the dis ontinuous parsing literature, for the synta ti des ription of (in -nite) languages with weak linear pre eden e onstraints. IDL-expressions represent hoi esamong words or phrases and their relative ordering by means of the standard on atenation292\nIDL-Expressions: A Formalism for Finite Languagesoperator ` ' from regular expressions, along with three additional operators to be dis ussedin what follows. All these operators take as arguments one or more IDL-expressions, and ombine the strings generated by these arguments in di erent ways. Operator `k', alled interleave, interleaves strings resulting from its argument ex-pressions. A string z results from the interleaving of two strings x and y whenever zis omposed of all and only the o urren es of symbols in x and y, and these symbolsappear within z in the same relative order as within x and y. As an example, on-sider strings ab d and efg. By interleaving these two strings we obtain, among manyothers, the strings abe fgd, eabfg d and efab dg. In the formal language litera-ture, this operation has also been alled `shu e', as for instan e by Dassow and P aun(1989). In the dis ontinuous parsing literature and in the literature on head-drivenphrase-stru ture grammars (HPSG, Pollard & Sag, 1994) the interleave operation isalso alled `sequen e union' (Reape, 1989) or `domain union' (Reape, 1994). Theinterleave operator also o urs in an XML tool des ribed by van der Vlist (2003). Operator `_', alled disjun tion, allows a hoi e between strings resulting from itsargument expressions. This is a standard operator from regular expressions, where itis more ommonly written as `+'. Operator ` ', alled lo k, takes a single IDL-expression as argument. This operatorstates that no additional material an be interleaved with a string resulting from itsargument. The lo k operator has been previously used in the dis ontinuous parsingliterature, as for instan e by Daniels and Meurers (2002), G otz and Penn (1997),Ramsay (1999), Suhre (1999). In that ontext, the operator was alled `isolation'.The interleave, disjun tion and lo k operators will also be alled I, D and L operators,respe tively. As we will see later, the ombination of the I and L operators within IDL-expressions provides mu h of the power of existing formalisms to represent free word order,while maintaining omputational properties quite lose to those of regular expressions or nite automata.As an introdu tory example, we dis uss the following IDL-expression, de ned over theword alphabet fpiano, play, must, ne essarily, weg.k(_(ne essarily; must); we (play piano)): (2)IDL-expression (2) says that words we, play and piano must appear in that order in anyof the generated strings, as spe i ed by the two o urren es of the on atenation operator.Furthermore, the use of the lo k operator states that no additional words an ever appearin between play and piano. The disjun tion operator expresses the hoi e between wordsne essarily and must. Finally, the interleave operator states that the word resulting fromthe rst of its arguments must be inserted into the sequen e we, play, piano, in any of theavailable positions. Noti e the intera tion with the lo k operator, whi h, as we have seen,makes unavailable the position in between play and piano. Thus the following senten es,among others, an be generated by IDL-expression (2):293\nNederhof & Sattane essarily we play pianomust we play pianowe must play pianowe play piano ne essarily.However, the following senten es annot be generated by IDL-expression (2):we play ne essarily pianone essarily must we play piano.The rst senten e is disallowed through the use of the lo k operator, and the se ond senten eis impossible be ause the disjun tion operator states that exa tly one of the arguments mustappear in the senten e realization. We now provide a formal de nition of the lass of IDL-expressions.De nition 1 Let be some nite alphabet and let E be a symbol not in . An IDL-expression over is a string satisfying one of the following onditions:(i) = a, with a 2 [ fEg;(ii) = ( 0), with 0 an IDL-expression;(iii) = _( 1; 2; : : : ; n), with n 2 and i an IDL-expression for ea h i, 1 i n;(iv) = k( 1; 2; : : : ; n), with n 2 and i an IDL-expression for ea h i, 1 i n;(v) = 1 2, with 1 and 2 both IDL-expressions.We take the in x operator ` ' to be right asso iative, although in all of the de nitions inthis paper, disambiguation of asso iativity is not relevant and an be taken arbitrarily. Wesay that IDL-expression 0 is a subexpression of if 0 appears as an argument of someoperator in .We now develop a pre ise semanti s for IDL-expressions. The only te hni al di\u00c6 ultyin doing so arises with the proper treatment of the lo k operator.3 Let x be a string over . The basi idea below is to use a new symbol , not already in . An o urren e of between two terminals indi ates that an additional string an be inserted at that position.As an example, if x = x0 x00x000 with x0, x00 and x000 strings over , and if we need tointerleave x with a string y, then we may get as a result string x0yx00x000 but not stringx0 x00yx000. The lo k operator orresponds to the removal of every o urren e of from astring.More pre isely, strings in ( [ f g) will be used to represent sequen es of strings over ; symbol is used to separate the strings in the sequen e. Furthermore, we introdu e astring homomorphism lo k over ( [f g) by letting lo k(a) = a for a 2 and lo k( ) = .An appli ation of lo k to an input sequen e an be seen as the operation of on atenatingtogether all of the strings in the sequen e.3. If we were to add the Kleene star, then in nite languages an be spe i ed, and interleave and lo k an bemore onveniently de ned using derivatives (Brzozowski, 1964), as noted before by van der Vlist (2003).294\nIDL-Expressions: A Formalism for Finite LanguagesWe an now de ne the basi operation omb, whi h plays an important role in the sequel.This operation omposes two sequen es x and y of strings, represented as explained above,into a set of new sequen es of strings. This is done by interleaving the two input sequen esin every possible way. Operation omb makes use of an auxiliary operation omb0, whi halso onstru ts interleaved sequen es out of input sequen es x and y, but always startingwith the rst string in its rst argument x. As any sequen e in omb(x; y) must start with astring from x or with a string from y, omb(x; y) is the union of omb0(x; y) and omb0(y; x).In the de nition of omb0, we distinguish the ase in whi h x onsists of a single string andthe ase in whi h x onsists of at least two strings. In the latter ase, the tail of an outputsequen e an be obtained by applying omb re ursively on the tail of sequen e x and the omplete sequen e y. For x; y 2 ( [ f g) , we have: omb(x; y) = omb0(x; y) [ omb0(y; x) omb0(x; y) = 8>><>>: fx yg; if x 2 ;fx0 g omb(x00; y);if there are x0 2 and x00su h that x = x0 x00:As an example, let = fa; b; ; d; eg and onsider the two sequen es a bb and d e.Then we have omb(a bb ; d e) =fa bb d e; a bb d e; a bb d e ;a d bb e; a d bb e ; a d e bb ;d a bb e; d a bb e ; d a e bb ;d e a bb g:For languages L1; L2 we de ne omb(L1; L2) = [x2L1;y2L2 omb(x; y). More generally, forlanguages L1; L2; : : : ; Ld, d 2, we de ne ombdi=1 Li = omb(L1; L2) for d = 2, and ombdi=1Li = omb( ombd 1i=1 Li; Ld) for d > 2.De nition 2 Let be some nite alphabet. Let be a fun tion mapping IDL-expressionsover into subsets of ( [ f g) , spe i ed by the following onditions:(i) (a) = fag for a 2 , and (E) = f\"g;(ii) ( ( )) = lo k( ( ));(iii) (_( 1; 2; : : : ; n)) = [ni=1 ( i);(iv) (k( 1; 2; : : : ; n)) = ombni=1 ( i);(v) ( 0) = ( ) ( 0).The set of strings that satisfy an IDL-expression , written L( ), is given by L( ) =lo k( ( )). 295\nNederhof & SattaAs an example for the above de nition, we show how the interleave operator an beused in an IDL-expression to denote the set of all strings realizing permutations of a givenbag of symbols. Let = fa; b; g. Consider a bag ha; a; b; ; i and IDL-expressionk(a; a; b; ; ): (3)By applying De nition 2 to IDL-expression (3), we obtain in the rst few steps (a) = fag; (b) = fbg; ( ) = f g; (k(a; a)) = omb(fag; fag) = fa ag; (k(a; a; b)) = omb(fa ag; fbg) = fb a a; a b a; a a bg:In the next step we obtain 3 4 sequen es of length 4, ea h using all the symbols frombag ha; a; b; i. One more appli ation of the omb operator, on this set and set f g, pro-vides all possible sequen es of singleton strings expressing permutations of symbols in bagha; a; b; ; i. After removing symbol throughout, whi h on eptually turns sequen es ofstrings into undivided strings, we obtain the desired language L(k(a; a; b; ; )) of permuta-tions of bag ha; a; b; ; i.To on lude this se tion, we ompare the expressivity of IDL-expressions with that ofthe formalisms dis ussed in Se tion 2. We do this by means of a simple example. Inwhat follows, we use the alphabet fNP, PP, Vg. These symbols denote units standardlyused in synta ti analysis of natural language, and stand for, respe tively, noun phrase,prepositional phrase and verb. Symbols NP, PP and V should be rewritten into a tual wordsof the language, but we use these as terminal symbols to simplify the presentation. Considera language having the subje t-verb-obje t (SVO) order and a senten e having the stru ture[S NP1 V NP2\u2104,where NP1 realizes the subje t position and NP2 realizes the obje t position. Let PP1 andPP2 be phrases that must be inserted in the above senten e as modi ers. Assume that weknow that the language at hand does not allow modi ers to appear in between the verbaland the obje t positions. Then we are left with 3 available positions for the realizationof a rst modi er, out of the 4 positions in our string. After the rst modi er is insertedwithin the string, we have 5 positions, but only 4 are available for the realization of a se ondmodi er, be ause of our assumption. This results in a total of 3 4 = 12 possible senten erealizations.A bag of words for these senten es is unable to apture the above onstraint on thepositioning of modi ers. At the same time, a word latti e for these senten es would ontain12 distin t paths, orresponding to the di erent realizations of the modi ers in the basi senten e. Using the IDL formalism, we an easily apture the desired realizations by meansof the IDL-expression: k(PP1; PP2; NP1 (V NP2)):296\nIDL-Expressions: A Formalism for Finite LanguagesAgain, note the presen e of the lo k operator, whi h implements our restri tion againstmodi ers appearing in between the verbal and the obje t position, similarly to what wehave done in IDL-expression (2).Consider now a senten e with a subordinate lause, having the stru ture[S NP1 V1 NP2 [S0 NP3 V2 NP4\u2104\u2104,and assume that modi ers PP1 and PP2 apply to the main lause, while modi ers PP3 andPP4 apply to the subordinate lause. As before, we have 3 4 possible realizations for thesubordinate senten e. If we allow main lause modi ers to appear in positions before thesubordinate lause as well as after the subordinate lause, we have 4 5 possible realizationsfor the main senten e. Overall, this gives a total of 3 42 5 = 240 possible senten erealizations.Again, a bag representation for these senten es is unable to apture the above restri -tions on word order, and would therefore badly overgenerate. Sin e the main senten emodi ers ould be pla ed after the subordinate lause, we need to re ord for ea h of thetwo modi ers of the main lause whether it has already been seen, while pro essing the 12possible realizations of the subordinate lause. This in reases the size of the representationby a fa tor of 2 2 = 4. On the other hand, the desired realizations an be easily apturedby means of the IDL-expression:k(PP1; PP2; NP1 (V1 NP2) (k(PP3; PP4; NP3 (V2 NP4)))):Note the use of embedded lo k operators (the two rightmost o urren es). The rightmostand the leftmost o urren es of the lo k operator implement our restri tion against modi- ers appearing in between the verbal and the obje t position. The o urren e of the lo koperator in the middle of the IDL-expression prevents any of the modi ers PP1 and PP2from modifying elements appearing within the subordinate lause. Observe that when wegeneralize the above examples by embedding n subordinate lauses, the orresponding wordlatti e will grow exponentially in n, while the IDL-expression has linear size in n.5. IDL-GraphsAlthough IDL-expressions may be easily omposed by linguists, they do not allow a dire talgorithmi interpretation for e\u00c6 ient re ognition of strings. We therefore de ne an equiva-lent but lower-level representation for IDL-expressions, whi h we all IDL-graphs. For thispurpose, we exploit a spe i kind of edge-labelled a y li graphs with ranked nodes. We rst introdu e our notation, and then de ne the en oding fun tion from IDL-expressions toIDL-graphs.The graphs we use are denoted by tuples (V;E; vs; ve; ; r), where: V and E are nite sets of verti es and edges, respe tively; vs and ve are spe ial verti es in V alled the start and the end verti es, respe tively; is the edge-labelling fun tion, mapping E into the alphabet [ f\";`; ag; r is the vertex-ranking fun tion, mapping V to N, the set of non-negative integernumbers. 297\nNederhof & SattaLabel \" indi ates that an edge does not onsume any input symbols. Edge labels ` and ahave the same meaning, but they additionally en ode that we are at the start or end, re-spe tively, of what orresponds to an I operator. More pre isely, let be an IDL-expressionheaded by an o urren e of the I operator and let ( ) be the asso iated IDL-graph. Weuse edges labelled by ` to onne t the start vertex of ( ) with the start verti es of all thesubgraphs en oding the arguments of I. Similarly, we use edges labelled by a to onne tall the end verti es of the subgraphs en oding the arguments of I with the end vertex of ( ). Edge labels ` and a are needed in the next se tion to distinguish o urren es of theI operator from o urren es of the D and L operators. Finally, the fun tion r ranks ea hvertex a ording to how deeply it is embedded into (the en oding of) expressions headedby an o urren e of the L operator. As we will see later, this information is ne essary forpro essing \\lo ked\" verti es with the orre t priority.We an now map an IDL-expression into the orresponding IDL-graph.De nition 3 Let be some nite alphabet, and let j be a non-negative integer number.Ea h IDL-expression over is asso iated with some graph j( ) = (V;E; vs; ve; ; r)spe i ed as follows:(i) if = a, a 2 [ fEg, let vs; ve be new nodes; we have(a) V = fvs; veg,(b) E = f(vs; ve)g,( ) ((vs; ve)) = a for a 2 and ((vs; ve)) = \" for a = E,(d) r(vs) = r(ve) = j;(ii) if = ( 0) with j+1( 0) = (V 0; E0; v0s; v0e; 0; r0), let vs; ve be new nodes; we have(a) V = V 0 [ fvs; veg,(b) E = E0 [ f(vs; v0s); (v0e; ve)g,( ) (e) = 0(e) for e 2 E0, ((vs; v0s)) = ((v0e; ve)) = \",(d) r(v) = r0(v) for v 2 V 0, r(vs) = r(ve) = j;(iii) if = _( 1; 2; : : : ; n) with j( i) = (Vi; Ei; vi;s; vi;e; i; ri), 1 i n, let vs; ve benew nodes; we have(a) V = [ni=1Vi [ fvs; veg,(b) E = [ni=1Ei [ f(vs; vi;s) j 1 i ng [ f(vi;e; ve) j 1 i ng,( ) (e) = i(e) for e 2 Ei, ((vs; vi;s)) = ((vi;e; ve)) = \" for 1 i n,(d) r(v) = ri(v) for v 2 Vi, r(vs) = r(ve) = j;(iv) if = k( 1; 2; : : : ; n) with j( i) = (Vi; Ei; vi;s; vi;e; i; ri), 1 i n, let vs; ve benew nodes; we have(a) V = [ni=1Vi [ fvs; veg,(b) E = [ni=1Ei [ f(vs; vi;s) j 1 i ng [ f(vi;e; ve) j 1 i ng,298\nIDL-Expressions: A Formalism for Finite Languages\nplaywe piano\nnecessarily\nmust\n\u03b5\n\u03b5 \u03b5 \u03b5 \u03b5\n\u03b5\n\u03b5 \u03b5\nPSfrag repla ements\n00 0 00 0 0000 00 1 111vs ve v0 v1 v2v3 v4 v5v6 v7 v8 v9 v10 v11 v12 v13Figure 1: The IDL-graph asso iated with the IDL-expressionk(_(ne essarily; must); we (play piano)).( ) (e) = i(e) for e 2 Ei, ((vs; vi;s)) = ` and ((vi;e; ve)) = a for 1 i n,(d) r(v) = ri(v) for v 2 Vi, r(vs) = r(ve) = j;(v) if = 1 2 with j( i) = (Vi; Ei; vi;s; vi;e; i; ri), i 2 f1; 2g, let vs = v1;s and ve = v2;e;we have(a) V = V1 [ V2,(b) E = E1 [E2 [ f(v1;e; v2;s)g,( ) (e) = i(e) for e 2 Ei for i 2 f1; 2g, ((v1;e; v2;s)) = \",(d) r(v) = ri(v) for v 2 Vi, i 2 f1; 2g.We let ( ) = 0( ). An IDL-graph is a graph that has the form ( ) for some IDL-expression over .Figure 1 presents the IDL-graph ( ), where is IDL-expression (2).We now introdu e the important notion of ut of an IDL-graph. This notion is neededto de ne the language des ribed by an IDL-graph, so that we an talk about equivalen ebetween IDL-expressions and IDL-graphs. At the same time, this notion will play a ru ialrole in the spe i ation of our parsing algorithm for IDL-graphs in the next se tion. Letus x some IDL-expression and let ( ) = (V;E; vs; ve; ; r) be the asso iated IDL-graph. Intuitively speaking, a ut through ( ) is a set of verti es that we might rea hsimultaneously when traversing ( ) from the start vertex to the end vertex, following thedi erent bran hes as pres ribed by the en oded I, D and L operators, and in an attempt toprodu e a string of L( ).In what follows we view V as a nite alphabet, and we de ne the set V\u0302 to ontain thosestrings over V in whi h ea h symbol o urs at most on e. Therefore V\u0302 is a nite set andfor ea h string 2 V\u0302 we have j j jV j. If we assume that the outgoing edges of ea h vertexin an IDL-graph are linearly ordered, we an represent uts in a anoni al way by means ofstrings in V\u0302 as de ned below. 299\nNederhof & SattaLet r be the ranking fun tion asso iated with ( ). We write [v1 vm\u2104 to denote astring 2 V\u0302 satisfying the following onditions: has the form xv1 vmy with x; y 2 V\u0302 and vi 2 V for 1 i m; and for ea h vertex v within and for ea h i, 1 i m, we have r(v) r(vi).In words, [v1 vm\u2104 indi ates that verti es v1; : : : ; vm o ur adja ent in and have themaximal rank among all verti es within string . Let [v1 vm\u2104 = xv1 vmy be a stringde ned as above and let v01 v0m0 2 V\u0302 be a se ond string su h that no symbol v0i, 1 i m0,appears in x or y. We write [v1 vm := v01 v0m0 \u2104 to denote the string xv01 v0m0y 2 V\u0302 .The reason we distinguish the verti es with maximal rank from those with lower rank isthat the former orrespond with subexpressions that are nested deeper within subexpres-sions headed by the L operator. As a substring originating within the s ope of an o urren eof the lo k operator annot be interleaved with symbols originating outside that s ope, weshould terminate the pro essing of all verti es with higher rank before resuming pro essingof those with lower rank.We now de ne a relation that plays a ru ial role in the de nition of the notion of ut,as well as in the spe i ation of our parsing algorithm.De nition 4 Let be some nite alphabet, let be an IDL-expression over , and let ( ) = (V;E; vs; ve; ; r) be its asso iated IDL-graph. The relation ( ) V\u0302 ( [f\"g) V\u0302is the smallest satisfying all of the following onditions:(i) for ea h [v\u2104 2 V\u0302 and (v; v0) 2 E with ((v; v0)) = X 2 [ f\"g, we have( [v\u2104;X; [v := v0\u2104) 2 ( ); (4)(ii) for ea h [v\u2104 2 V\u0302 with the outgoing edges of v being exa tly (v; v1); : : : ; (v; vn) 2 E, inthis order, and with ((v; vi)) = `, 1 i n, we have( [v\u2104; \"; [v := v1 vn\u2104) 2 ( ); (5)(iii) for ea h [v1 vn\u2104 2 V\u0302 with the in oming edges of some v 2 V being exa tly(v1; v); : : : ; (vn; v) 2 E, in this order, and with ((vi; v)) = a, 1 i n, we have( [v1 vn\u2104; \"; [v1 vn := v\u2104) 2 ( ): (6)Hen eforth, we will abuse notation by writing in pla e of ( ). Intuitively speaking,relation will be used to simulate a one-step move over IDL-graph ( ). Condition (4)refers to moves that follow a single edge in the graph, labelled by a symbol from the alphabetor by the empty string. This move is exploited, e.g., upon visiting a vertex at the start ofa subgraph that en odes an IDL-expression headed by an o urren e of the D operator. Inthis ase, ea h outgoing edge represents a possible next move, but at most one edge an be hosen. Condition (5) refers to moves that simultaneously follow all edges emanating fromthe vertex at hand. This is used when pro essing a vertex at the start of a subgraph thaten odes an IDL-expression headed by an o urren e of the I operator. In fa t, in a ordan e300\nIDL-Expressions: A Formalism for Finite Languageswith the given semanti s, all possible argument expressions must be evaluated in parallelby a single omputation. Finally, Condition (6) refers to a move that an be read as the omplement of the previous type of move.Examples of elements in in the ase of Figure 1 are (vs; \"; v0v6) followingCondition (5) and (v5v13; \"; ve) following Condition (6), whi h start and end theevaluation of the o urren e of the I operator. Other elements are (v0v6; \"; v1v6),(v1v9; play; v1v10) and (v1v13; ne essarily; v2v13) following Condition (4). Note that, e.g.,(v1v10; ne essarily; v2v10) is not an element of , as v9 has higher rank than v1.We are now ready to de ne the notion of ut.De nition 5 Let be some nite alphabet, let be an IDL-expression over , and let ( ) = (V;E; vs; ve; ; r) be its asso iated IDL-graph. The set of all uts of ( ), written ut( ( )), is the smallest subset of V\u0302 satisfying the following onditions:(i) string vs belongs to ut( ( ));(ii) for ea h 2 ut( ( )) and ( ;X; 0) 2 , string 0 belongs to ut( ( )).Hen eforth, we will abuse notation by writing ut( ) for ut( ( )). As already remarked,we an interpret a ut v1v2 vk 2 ut( ), vi 2 V for 1 i k, as follows. In theattempt to generate a string in L( ), we traverse several paths of the IDL-graph ( ). This orresponds to the \\parallel\" evaluation of some of the subexpressions of , and ea h vi inv1v2 vk refers to one su h subexpression. Thus, k provides the number of evaluations thatwe are arrying out in parallel at the point of the omputation represented by the ut. Notehowever that, when drawing a straight line a ross a planar representation of an IDL-graph,separating the start vertex from the end vertex, the set of verti es that we an identify isnot ne essarily a ut.4 In fa t, as we have already explained when dis ussing relation ,only one path is followed at the start of a subgraph that en odes an IDL-expression headedby an o urren e of the D operator. Furthermore, even if several ar s are to be followed atthe start of a subgraph that en odes an IDL-expression headed by an o urren e of the Ioperator, some ombinations of verti es will not satisfy the de nition of ut when there areL operators within those argument expressions. These observations will be more pre iselyaddressed in Se tion 7, where we will provide a mathemati al analysis of the omplexity ofour algorithm.Examples of uts in the ase of Figure 1 are vs, ve, v0v6, v1v6, v3v6, v0v7, et . Stringssu h as v1v3 are not uts, as v1 and v3 belong to two disjoint subgraphs with sets of verti esfv1; v2g and fv3; v4g, respe tively, ea h of whi h orresponds to a di erent argument of ano urren e of the disjun tion operator.Given the notion of ut, we an asso iate a nite language with ea h IDL-graph andtalk about equivalen e with IDL-expressions. Let be an IDL-expression over , and let ( ) = (V;E; vs; ve; ; r) be the asso iated IDL-graph. Let also ; 0 2 ut( ) and w 2 .We write w 2 L( ; 0) if there exists q jwj, Xi 2 [ f\"g, 1 i q, and i 2 ut( ),0 i q, su h that X1 Xq = w, 0 = , q = 0 and ( i 1;Xi; i) 2 for 1 i q.4. The pi torial representation mentioned above omes lose to a di erent de nition of ut that is standardin the literature on graph theory and operating resear h. The reader should be aware that this standardgraph-theoreti notion of \\ ut\" is di erent from the one introdu ed in this paper.301\nNederhof & SattaWe also assume that L( ; ) = f\"g. We an then show that L(vs; ve) = L( ), i.e., thelanguage generated by the IDL-expression is the same as the language that we obtain ina traversal of the IDL-graph ( ), as des ribed above, starting from ut vs and ending in ut ve. The proof of this property is rather long and does not add mu h to the alreadyprovided intuition underlying the de nitions in this se tion; therefore we will omit it.We lose this se tion with an informal dis ussion of relation and the asso iated notionof ut. Observe that De nition 4 and De nition 5 impli itly de ne a nondeterministi niteautomaton. Again, we refer the reader to Harrison (1978) for a de nition of nite automata.The states of the automaton are the uts in ut( ) and its transitions are given by theelements of . The initial state of the automaton is the ut vs, and the nal state is the ut ve. It is not di\u00c6 ult to see that from every state of the automaton one an always rea hthe nal state. Furthermore, the language re ognized by su h an automaton is pre isely thelanguage L(vs; ve) de ned above. However, we remark here that su h an automaton willnever be onstru ted by our parsing algorithm, as emphasized in the next se tion.6. CFG Parsing of IDL-GraphsWe start this se tion with a brief overview of the Earley algorithm (Earley, 1970), a well-known tabular method for parsing input strings a ording to a given CFG. We then refor-mulate the Earley algorithm in order to parse IDL-graphs. As already mentioned in theintrodu tion, while parsing is traditionally de ned for input onsisting of a single string, wehere on eive parsing as a pro ess that an be arried out on an input devi e representinga language, i.e., a set of strings.Let G = (N ; ; P; S) be a CFG, and let w = a1 an 2 be an input string to beparsed. Standard implementations of the Earley algorithm (Graham & Harrison, 1976) useso alled parsing items to re ord partial results of the parsing pro ess on w. A parsing itemhas the form [A ! ; i; j\u2104, where A! is a produ tion of G and i and j are indi esidentifying a substring ai+1 aj of w. Su h a parsing item is onstru ted by the algorithmif and only if there exist a string 2 (N [ ) and two derivations in G having the formS ) G a1 aiA )G a1 ai ; ) G ai+1 aj :The algorithm a epts w if and only if it an onstru t an item of the form [S ! ; 0; n\u2104, forsome produ tion S ! of G. Figure 2 provides an abstra t spe i ation of the algorithmexpressed as a dedu tion system, following Shieber, S habes, and Pereira (1995). Inferen erules spe ify the types of steps that the algorithm an apply in onstru ting new items.Rule (7) in Figure 2 serves as an initialization step, onstru ting all items that anstart analyses for produ tions with the start symbol S in the right-hand side. Rule (8)is very similar in purpose: it onstru ts all items that an start analyses for produ tionswith nonterminal B in the left-hand side, provided that B is the next nonterminal in someexisting item for whi h an analysis is to be found. Rule (9) mat hes a terminal a in an itemwith an input symbol, and the new item signi es that a larger part of the right-hand sidehas been mat hed to a larger part of the input. Finally, Rule (10) ombines two partial302\nIDL-Expressions: A Formalism for Finite Languages [S ! ; 0; 0\u2104 S ! (7)[A! B ; i; j\u2104[B ! ; j; j\u2104 B ! (8)[A! a ; i; j\u2104[A! a ; i; j + 1\u2104 a = aj+1 (9)[A! B ; i; j\u2104[B ! ; j; k\u2104[A! B ; i; k\u2104 (10)Figure 2: Abstra t spe i ation of the parsing algorithm of Earley for an input stringa1 an. The algorithm a epts w if and only if it an onstru t an item ofthe form [S ! ; 0; n\u2104, for some produ tion S ! of G.analyses, the se ond of whi h represents an analysis for symbol B, by whi h the analysisrepresented by the rst item an be extended.We an now move to our algorithm for IDL-graph parsing using a CFG. The algorithmmakes use of relation from De nition 4, but this does not mean that the relation isfully omputed before invoking the algorithm. We instead ompute elements of \\on-the- y\" when we rst visit a ut, and a he these elements for possible later use. This hasthe advantage that, when parsing an input IDL-graph, our algorithm pro esses only thoseportions of the graph that represent pre xes of strings that are generated by the CFG athand. In pra ti al ases, the input IDL-graph is never ompletely unfolded, so that the ompa tness of the proposed representation is preserved to a large extent.An alternative way of viewing our algorithm is this. We have already informally dis- ussed in Se tion 5 how relation impli itly de nes a nondeterministi nite automatonwhose states are the elements of ut( ) and whose transitions are the elements of . Wehave also mentioned that su h an automaton pre isely re ognizes the nite language L( ).From this perspe tive, our algorithm an be seen as a standard latti e parsing algorithm,dis ussed in Se tion 2. What must be emphasized here is that we do not pre ompute theabove nite automaton prior to parsing. Our approa h onsists in a lazy evaluation of thetransitions of the automaton, on the basis of a demand on the part of the parsing pro ess.In ontrast with our approa h, full expansion of the nite automaton before parsing hasseveral disadvantages. Firstly, although a nite automaton generating a nite language303\nNederhof & Sattamight be onsiderably smaller than a representation of the language itself onsisting of alist of all its elements, it is easy to see that there are ases in whi h the nite automatonmight have size exponentially larger than the orresponding IDL-expression (see also thedis ussion in Se tion 2). In su h ases, full expansion destroys the ompa tness of IDL-expressions, whi h is the main motivation for the use of our formalism in hybrid surfa egeneration systems, as dis ussed in the introdu tion. Furthermore, full expansion of theautomaton is also omputationally unattra tive, sin e it may lead to unfolding of parts ofthe input IDL-graph that will never be pro essed by the parsing algorithm.Let G = (N ; ; P; S) be a CFG and let be some input IDL-expression. The algorithmuses parsing items of the form [A ! ; 1; 2\u2104, with A ! a produ tion in P and 1; 2 2 ut( ). These items have the same meaning as those used in the original Earleyalgorithm, but now they refer to strings in the languages L(vs; 1) and L( 1; 2), where vsis the start vertex of IDL-graph ( ). (Re all from Se tion 5 that L( ; 0), ; 0 2 ut( ),is the set of strings whose symbols an be onsumed in any traversal of ( ) starting from ut and ending in ut 0.) We also use items of the forms [ 1; 2\u2104 and [a; 1; 2\u2104, a 2 , 1; 2 2 ut( ). This is done in order to by-pass traversals of ( ) involving a sequen e of zeroor more triples of the form ( 1; \"; 2) 2 , followed by a triple of the form ( 1; a; 2) 2 .Figure 3 presents an abstra t spe i ation of the algorithm, again using a set of inferen erules. The issues of ontrol ow and implementation are deferred to the next se tion.In what follows, let vs and ve be the start and end verti es of IDL-graph ( ), respe -tively. Rules (11), (12) and (15) in Figure 3 losely resemble Rules (7), (8) and (10) of theoriginal Earley algorithm, as reported in Figure 2. Rules (13), (16) and (17) have been intro-du ed for the purpose of e\u00c6 iently omputing traversals of ( ) involving a sequen e of zeroor more triples of the form ( 1; \"; 2) 2 , followed by a triple of the form ( 1; a; 2) 2 ,as already mentioned. On e one su h traversal has been omputed, the fa t is re ordedthrough some item of the form [a; 1; 2\u2104, avoiding later re omputation. Rule (14) loselyresembles Rule (9) of the original Earley algorithm. Finally, by omputing traversals of ( ) involving triples of the form ( 1; \"; 2) 2 only, Rule (18) may derive items of theform [S ! ; vs; ve\u2104; the algorithm a epts the input IDL-graph if and only if any su hitem an be derived by the inferen e rules.We now turn to the dis ussion of the orre tness of the algorithm in Figure 3. Ouralgorithm derives a parsing item [A ! ; 1; 2\u2104 if and only if there exist a string 2 (N [ ) , integers i; j with 0 i j, and a1a2 aj 2 su h that the following onditions are all satis ed: a1 ai 2 L(vs; 1); ai+1 aj 2 L( 1; 2); and there exist two derivations in G of the formS ) G a1 aiA )G a1 ai ) G ai+1 aj :The above statement losely resembles the existential ondition previously dis ussed for theoriginal Earley algorithm, and an be proved using arguments similar to those presented for304\nIDL-Expressions: A Formalism for Finite Languages [S ! ; vs; vs\u2104 S ! (11)[A! B ; 1; 2\u2104[B ! ; 2; 2\u2104 B ! (12)[A! a ; 1; 2\u2104[ 2; 2\u2104 (13)[A! a ; 1; 2\u2104[a; 2; 3\u2104[A! a ; 1; 3\u2104 (14)[A! B ; 1; 2\u2104[B ! ; 2; 3\u2104[A! B ; 1; 3\u2104 (15)[ 1; 2\u2104[ 1; 3\u2104 ( 2; ; 3) 2 (16)[ 1; 2\u2104[a; 1; 3\u2104 ( 2; a; 3) 2 ;a 2 (17)[S ! ; 0; 1\u2104[S ! ; 0; 2\u2104 ( 1; ; 2) 2 (18)Figure 3: An abstra t spe i ation of the parsing algorithm for IDL-graphs. The algorithma epts the IDL-graph ( ) if and only if some item having the form [S ! ; vs; ve\u2104 an be derived by the inferen e rules, where S ! is a produ tion of Gand vs and ve are the start and end verti es of ( ), respe tively.\n305\nNederhof & Sattainstan e by Aho and Ullman (1972) and by Graham and Harrison (1976); we will thereforeomit a omplete proof here. Note that the orre tness of the algorithm in Figure 3 dire tlyfollows from the above statement, by taking item [A ! ; 1; 2\u2104 to be of the form[S ! ; vs; ve\u2104 for some produ tion S ! from G.7. Complexity and ImplementationIn this se tion we provide a omputational analysis of our parsing algorithm for IDL-graphs.The analysis is based on the development of a tight upper bound on the number of possible uts admitted by an IDL-graph. We also dis uss two possible implementations for theparsing algorithm.We need to introdu e some notation. Let be an IDL-expression and let ( ) =(V;E; vs; ve; ; r) be the asso iated IDL-graph. A vertex v 2 V is alled L-free in ( ) if,for every subexpression 0 of su h that j( 0) = (V 0; E0; v0s; v0e; 0; r0) for some j, V 0 V ,E0 E, and su h that v 2 V 0, we have that 0 is not of the form ( 00). In words, a vertexis L-free in ( ) if it does not belong to a subgraph of ( ) that en odes an IDL-expressionheaded by an L operator. When ( ) is understood from the ontext, we write L-free inpla e of L-free in ( ). We write 0- ut( ) to denote the set of all uts in ut( ) that only ontain verti es that are L-free in ( ). We now introdu e two fun tions that will be usedlater in the omplexity analysis of our algorithm. For a ut 2 ut( ) we write j j to denotethe length of , i.e., the number of verti es in the ut.De nition 6 Let be an IDL-expression. Fun tions width and 0-width are spe i ed asfollows: width( ) = max 2 ut( ) j j ;0-width( ) = max 20- ut( ) j j :Fun tion width provides the maximum length of a ut through ( ). This quantity givesthe maximum number of subexpressions of that need to be evaluated in parallel whengenerating a string in L( ). Similarly, fun tion 0-width provides the maximum length of a ut through ( ) that only in ludes L-free nodes.Despite the fa t that ut( ) is always a nite set, a omputation of fun tions width and0-width through a dire t omputation of ut( ) and 0- ut( ) is not pra ti al, sin e thesesets may have exponential size in the number of verti es of ( ). The next hara terizationprovides a more e\u00c6 ient way to ompute the above fun tions, and will be used in the proofof Lemma 2 below.Lemma 1 Let be an IDL-expression. The quantities width( ) and 0-width( ) satisfy thefollowing equations:(i) if = a, a 2 [ fEg, we have width( ) = 1;0-width( ) = 1;306\nIDL-Expressions: A Formalism for Finite Languages(ii) if = ( 0) we have width( ) = width( 0);0-width( ) = 1;(iii) if = _( 1; 2; : : : ; n) we havewidth( ) = nmaxi=1 width( i);0-width( ) = nmaxi=1 0-width( i);(iv) if = k( 1; 2; : : : ; n) we havewidth( ) = nmaxj=1 (width( j) + Xi:1 i n^i 6=j 0-width( i));0-width( ) = nXj=1 0-width( j);(v) if = 1 2 we havewidth( ) = max fwidth( 1); width( 2)g;0-width( ) = max f0-width( 1); 0-width( 2)g:Proof. All of the equations in the statement of the lemma straightforwardly follow fromthe de nitions of and ut( ) (De nitions 4 and 5, respe tively). Here we develop atlength only two ases and leave the remainder of the proof to the reader. In what followswe assume that ( ) = (V;E; vs; ve; ; r).In ase = _( 1; 2; : : : ; n), let ( i) = (Vi; Ei; vi;s; vi;e; i; ri), 1 i n. FromDe nition 4 we have (vs; \"; vi;s) 2 and (vi;e; \"; ve) 2 , for every i, 1 i n. Thuswe have ut( ) = [ni=1 ut( i) [ fvs; veg and, sin e both vs and ve are L-free in ( ),0- ut( ) = [ni=10- ut( i) [ fvs; veg. This provides the relations in (iii).In ase = k( 1; 2; : : : ; n), let ( i) = (Vi; Ei; vi;s; vi;e; i; ri), 1 i n. FromDe nition 4 we have (vs; \"; v1;s vn;s) 2 and (v1;e vn;e; \"; ve) 2 . Thus every 2 ut( ) must belong to fvs; veg or must have the form = 1 n with i 2 ut( i) for1 i n. Sin e both vs and ve are L-free in ( ), we immediately derive0- ut( ) = fvs; veg [ 0- ut( 1) 0- ut( n);and hen e 0-width( ) =Pnj=1 0-width( j). Now observe that, for ea h = 1 n spe i edas above there an never be indi es i and j, 1 i; j n and i 6= j, and verti es v1 and v2o urring in i and j , respe tively, su h that neither v1 nor v2 are L-free in ( ).We thereby derive ut( ) = fvs; veg [ ut( 1)0- ut( 2) 0- ut( n) [0- ut( 1) ut( 2) 0- ut( n) [...0- ut( 1)0- ut( 2) ut( n):307\nNederhof & SattaHen e we an write width( ) = maxnj=1 (width( j) +Pi:1 i n^i 6=j 0-width( i)). Now onsider quantity j ut( )j, i.e., the number of di erent uts in IDL-graph ( ).This quantity is obviously bounded from above by jV jwidth( ). We now derive a tighterupper bound on this quantity.Lemma 2 Let be a nite alphabet, let be an IDL-expression over , and let ( ) =(V;E; vs; ve; ; r) be its asso iated IDL-graph. Let also k = width( ). We havej ut( )j jV jk k :Proof. We use below the following inequality. For any integer h 2 and real values xi > 0,1 i h, we have hYi=1 xi Phi=1 xih !h : (19)In words, (19) states that the geometri mean is never larger than the arithmeti mean.We prove (19) in the following equivalent form. For any real values > 0 and yi,1 i h and h 2, with yi > and Phi=1 yi = 0, we havehYi=1 ( + yi) h: (20)We start by observing that if the yi are all equal to zero, then we are done. Otherwise theremust be i and j with 1 i; j h su h that yiyj < 0. Without loss of generality, we assumei = 1 and j = 2. Sin e yiyj < 0, we have( + y1)( + y2) = ( + y1 + y2) + y1y2 < ( + y1 + y2): (21)Sin e Qhi=3 ( + yi) > 0, we have( + y1)( + y2) hYi=3 ( + yi) < ( + y1 + y2) hYi=3 ( + yi): (22)We now observe that the right-hand side of (22) has the same form as the left-hand sideof (20), but with fewer yi that are non-zero. We an therefore iterate the above pro edure,until all yi be ome zero valued. This on ludes the proof of (19).Let us turn to the proof of the statement of the lemma. Re all that ea h ut 2 ut( )is a string over V su h that no vertex in V has more than one o urren e in , and is anoni ally represented, i.e., no other permutation of the verti es in is a possible ut. Wewill later prove the following laim.Claim. Let , V and k be as in the statement of the lemma. We an partition V intosubsets V [ ; j\u2104, 1 j k, having the following property. For every V [ ; j\u2104, 1 j k, andevery pair of distin t verti es v1; v2 2 V [ ; j\u2104, v1 and v2 do not o ur together in any ut 2 ut( ). 308\nIDL-Expressions: A Formalism for Finite LanguagesWe an then writej ut( )j Qkj=1 jV [ ; j\u2104j (by our laim and the anoni alrepresentation of uts) Pkj=1 jV [ ;j\u2104jk k (by (19))= jV jk k :To omplete the proof of the lemma we now need to prove our laim above. We provethe following statement, whi h is a slightly stronger version of the laim. We an partitionset V into subsets V [ ; j\u2104, 1 j k = width( ), having the following two properties: for every V [ ; j\u2104, 1 j k, and every pair of distin t verti es v1; v2 2 V [ ; j\u2104, v1 andv2 do not o ur together in any ut 2 ut( ); all verti es in V that are L-free in ( ) are in luded in some V [ ; j\u2104, 1 j 0-width( ). (In other words, the sets V [ ; j\u2104, 0-width( ) < j width( ), an only ontain verti es that are not L-free in ( ).)In what follows we use indu tion on #op( ), the number of operator o urren es (I, D, Land on atenation) appearing within .Base: #op( ) = 0. We have = a, with a 2 [fEg, and V = fvs; vfg. Sin e width( ) = 1,we set V [ ; 1\u2104 = V . This satis es our laim, sin e ut( ) = fvs; vfg, all verti es in V areL-free in ( ) and we have 0-width( ) = 1.Indu tion: #op( ) > 0. We distinguish among three possible ases.Case 1: = _( 1; 2; : : : ; n). Let ( i) = (Vi; Ei; vi;s; vi;e; i; ri), 1 i n. By Lemma 1we have width( ) = maxni=1 width( i). For ea h i, 1 i n, let us de ne V [ i; j\u2104 = ; forevery j su h that width( i) < j width( ). We an then setV [ ; 1\u2104 = ([ni=1 V [ i; 1\u2104) [ fvs; veg;V [ ; j\u2104 = [ni=1 V [ i; j\u2104; for 2 j width( ):The sets V [ ; j\u2104 de ne a partition of V , sin e V = ([ni=1 Vi) [ fvs; veg and, for ea h i, thesets V [ i; j\u2104 de ne a partition of Vi by the indu tive hypothesis. We now show that su h apartition satis es the two onditions in our statement.Let v1 and v2 be two distin t verti es in some V [ ; j\u2104. We have already established inthe proof of Lemma 1 that ut( ) = ([ni=1 ut( i)) [ fvs; veg. If either v1 or v2 belongsto the set fvs; veg, then v1 and v2 annot o ur in the same ut in ut( ), sin e the only uts in ut( ) with verti es in the set fvs; veg are vs and ve. Let us now onsider the asev1; v2 2 [ni=1 Vi. We an distinguish two sub ases. In the rst sub ase, there exists i su hthat v1; v2 2 V [ i; j\u2104. The indu tive hypothesis states that v1 and v2 annot o ur in thesame ut in ut( i), and hen e annot o ur in the same ut in ut( ). In the se ondsub ase, v1 2 V [ i; j\u2104 and v2 2 V [ i0 ; j\u2104 for distin t i and i0. Then v1 and v2 must belongto di erent graphs ( i) and ( i0), and hen e annot o ur in the same ut in ut( ).Furthermore, every vertex in [ni=1 Vi that is L-free in some ( i) belongs to someV [ i; j\u2104 with 1 j 0-width( i), by the indu tive hypothesis. Sin e 0-width( ) =309\nNederhof & Sattamaxni=1 0-width( i) (Lemma 1) we an state that all verti es in V that are L-free in ( )belong to some V [ ; j\u2104, 1 j 0-width( ).Case 2: = ( 0) or = 1 2. The proof is almost identi al to that of Case 1, withn = 1 or n = 2, respe tively.Case 3: = k( 1; 2; : : : ; n). Let ( i) = (Vi; Ei; vi;s; vi;e; i; ri), 1 i n. By Lemma 1we have 0-width( ) = nXj=1 0-width( j);width( ) = nmaxj=1 (width( j) + Xi:1 i n^i 6=j 0-width( i)):The latter equation an be rewritten aswidth( ) = nXj=1 0-width( j) + nmaxj=1 (width( j) 0-width( j)): (23)For ea h i with 1 i n, let us de ne V [ i; j\u2104 = ; for every j with width( i) < j width( ).We an then set V [ ; 1\u2104 = V [ 1; 1\u2104 [ fvs; veg;V [ ; j\u2104 = V [ 1; j\u2104; for 2 j 0-width( 1);V [ ; 0-width( 1) + j\u2104 = V [ 2; j\u2104; for 1 j 0-width( 2);...V [ ;Pn 1i=1 0-width( i) + j\u2104 = V [ n; j\u2104; for 1 j 0-width( n);V [ ;Pni=1 0-width( i) + j\u2104 = [ni=1V [ i; 0-width( i) + j\u2104;for 1 j maxnj=1(width( j) 0-width( j)):The sets V [ ; j\u2104 de ne a partition of V , sin e V = ([ni=1 Vi) [ fvs; veg and, for ea h i, thesets V [ i; j\u2104 de ne a partition of Vi by the indu tive hypothesis. We now show that su h apartition satis es both onditions in our statement.Let v1 and v2 be distin t verti es in some V [ ; j\u2104, 1 j n. We have already establishedin the proof of Lemma 1 that a ut in ut( ) either belongs to fvs; veg or else must havethe form = 1 n with i 2 ut( i) for 1 i n. As in Case 1, if either v1 or v2 belongsto the set fvs; veg, then v1 and v2 annot o ur in the same ut in ut( ), sin e the only uts in ut( ) with verti es in the set fvs; veg are vs and ve. Consider now the ase in whi hv1; v2 2 [ni=1 Vi. We distinguish two sub ases.In the rst sub ase, there exists i su h that v1; v2 2 V [ i; j\u2104. If there exists a ut 2 ut( ) su h that v1 and v2 both o ur within , then v1 and v2 must both o ur withinsome 0 2 ut( i). But this ontradi ts the indu tive hypothesis on i.In the se ond sub ase, v1 2 V [ i0 ; j0\u2104 and v2 2 V [ i00 ; j00\u2104, for distin t i0 and i00. Notethat this an only happen if 0-width( ) < j width( ), 0-width( i0) < j0 width( i0) and0-width( i00) < j00 width( i00), by our de nition of the partition of V and by (23). By theindu tive hypothesis on i0 and i00 , v1 is not L-free in ( i0) and v2 is not L-free in ( i00),whi h means that both v1 and v2 o ur within the s ope of some o urren e of the lo k310\nIDL-Expressions: A Formalism for Finite Languagesoperator. Note however that v1 and v2 annot o ur within the s ope of the same o urren eof the lo k operator, sin e they belong to di erent subgraphs ( i0) and ( i00). Assumenow that there exists a ut 2 ut( ) su h that v1 and v2 both o ur within . This wouldbe in onsistent with the de nitions of and ut (De nitions 4 and 5, respe tively) sin etwo verti es that are not L-free and that are not within the s ope of the same o urren eof the lo k operator annot belong to the same ut.Finally, it dire tly follows from the de nition of our partition on V and from the in-du tive hypothesis on the i that all verti es in V that are L-free in ( ) belong to someV [ ; j\u2104 with 1 j 0-width( ). This on ludes the proof of our statement. The upper bound reported in Lemma 2 is tight. As an example, for any i 1 and k 2,let i;k = fa1; : : : ; ai kg. Consider now the lass of IDL-expressions i;k = k(a1a2 ai; ai+1ai+2 a2i; : : : ; ai (k 1)+1ai (k 1)+2 ai k):Let also Vi;k be the vertex set of the IDL-graph ( i;k). It is not di\u00c6 ult to see thatjVi;kj = 2 i k + 2, width( i;k) = k andj ut( i;k)j = (2 i)k + 2 (2 i+ 2k )k;where the inequality results from our upper bound. The oarser upper bound presentedbefore Lemma 2 would give instead j ut( i;k)j < (2 i k + 2)k.We an now turn to the dis ussion of the worst ase running time for the algorithm inFigure 3. To simplify the presentation, let us ignore for the moment any term that solelydepends on the input grammar G.To store and retrieve items [A ! ; 1; 2\u2104, [a; 1; 2\u2104 and [ 1; 2\u2104 we exploit somedata stru ture T and a ess it using ut 1 and ut 2 as indi es. In what follows we makethe assumption that ea h a ess operation on T an be arried out in an amount of timeO(d(k)), where k = width( ) and d is some fun tion that depends on the implementationof the data stru ture itself, to be dis ussed later. After we a ess T with some pair 1, 2,an array is returned of length proportional to jGj. Thus, from su h an array we an inquirein onstant time whether a given item has already been onstru ted.The worst ase time omplexity is dominated by the rules in Figure 3 that involve themaximum number of uts, namely rules like (15) with three uts ea h. The maximumnumber of di erent alls to these rules is then proportional to j ut( )j3. Considering ourassumptions on T , the total amount of time that is harged to the exe ution of all theserules is then O(d(k) j ut( )j3). As in the ase of the standard Earley algorithm, when theworking grammar G is taken into a ount we must in lude a fa tor of jGj2, whi h an beredu ed to jGj using te hniques dis ussed by Graham, Harrison, and Ruzzo (1980).We also need to onsider the amount of time required by the onstru tion of relation , whi h happens on-the- y, as already dis ussed. This takes pla e at Rules (16), (17) and(18). Re all that elements of relation have the form ( 1;X; 2) with 1; 2 2 ut( ) andX 2 [f\"g. In what follows, we view as a dire ted graph whose verti es are uts, andthus refer to elements of su h a relation as (labelled) ar s. When an ar in emanatingfrom a ut 1 with label X is visited for the rst time, then we ompute this ar and therea hed ut, and a he them for possible later use. However, in ase the rea hed ut 2already exists be ause we had previously visited an ar ( 01;X 0; 2), then we only a he the311\nNederhof & Sattanew ar . For ea h ar in , all the above an be easily arried out in time O(k), wherek = width( ). Then the total time required by the on-the- y onstru tion of relation isO(k j j). For later use, we now express this bound in terms of quantity j ut( )j. From thede nition of we an easily see that there an be no more than one ar between any two uts, and therefore j j j ut( )j2. We obviously have k jV j. Also, it is not di\u00c6 ult toprove that jV j j ut( )j, using indu tion on the number of operator o urren es appearingwithin . We thus on lude that, in the worst ase, the total time required by the on-the- y onstru tion of relation is O(j ut( )j3).From all of the above observations we an on lude that, in the worst ase, the algorithmin Figure 3 takes an amount of time O(jGj d(k) j ut( )j3). Using Lemma 2, we an thenstate the following theorem.Theorem 1 Given a ontext-free grammar G and an IDL-graph ( ) with vertex set Vand with k = width( ), the algorithm in Figure 3 runs in time O(jGj d(k)( jV jk )3k).We now more losely onsider the hoi e of the data stru ture T and the issue of itsimplementation. We dis uss two possible solutions. Our rst solution an be used whenj ut( )j is small enough so that we an store j ut( )j2 pointers in the omputer's random-a ess memory. In this ase we an implement T as a square array of pointers to sets ofour parsing items. Ea h ut in ut( ) is then uniquely en oded by a non-negative integer,and su h integers are used to a ess the array. This solution in pra ti e omes down tothe standard implementation of the Earley algorithm through a parse table, as presentedby Graham et al. (1980). We then have d(k) = O(1) and our algorithm has time omplexityO(jGj ( jV jk )3k).As a se ond solution, when j ut( )j is quite large, we an implement T as a trie (Gus eld,1997). In this ase ea h ut is treated as a string over set V , viewed as an alphabet, and welook up string 1# 2 in T (# is a symbol not in V ) in order to retrieve all items involving uts 1 and 2 that have been indu ed so far. We then obtain d(k) = O(k) and our algorithmhas time omplexity O(jGj k( jV jk )3k).The rst solution above is faster than the se ond one by a fa tor of k. However, the rstsolution has the obvious disadvantage of expensive spa e requirements, sin e not all pairsof uts might orrespond to some grammar onstituent, and the array T an be very sparsein pra ti e. It should also be observed that, in the natural language pro essing appli ationsdis ussed in the introdu tion, k an be quite small, say three or four.To on lude this se tion, we ompare the time omplexity of CFG parsing as traditionallyde ned for strings and the time omplexity of parsing for IDL-graphs. As referen e for stringparsing we take the Earley algorithm, whi h has already been presented in Se tion 6. By aminor hange proposed by Graham et al. (1980), the Earley algorithm an be improved tohave time omplexity O(jGj n3), where G is the input CFG and n is the length of the inputstring. We observe that, if we ignore the fa tor d(k) in the time omplexity of IDL-graphparsing (Theorem 1), the two upper bounds be ome very similar, with fun tion ( jV jk )k inIDL-graph parsing repla ing the input senten e length n from the Earley algorithm.We observe that fun tion ( jV jk )k an be taken as a measure of the omplexity of theinternal stru ture of the input IDL-expression. More spe i ally, assume that no pre eden e onstraints at all are given for the words of the input IDL-expression. We then obtain IDL-expressions with o urren es of the I operator only, with a worst ase of k = jV j2 1.312\nIDL-Expressions: A Formalism for Finite LanguagesThen O(( jV jk )k) an be written as O( jV j) for some onstant > 1, resulting in exponentialrunning time for our algorithm. This omes at no surprise, sin e the problem at hand thenbe omes the problem of re ognition of a bag of words with a CFG, whi h is known to beNP- omplete (Brew, 1992), as already dis ussed in Se tion 2.Conversely, no I operator may be used in the IDL-expression , and thus the resultingrepresentation mat hes a nite automaton or word latti e. In this ase we have k = 1 andfun tion ( jV jk )k be omes jV j. The resulting running time is then a ubi fun tion of theinput length, as in the ase of the Earley algorithm. The fa t that ( y li or a y li ) niteautomata an be parsed in ubi time is also a well-known result (Bar-Hillel et al., 1964;van Noord, 1995).It is noteworthy to observe that in appli ations where k an be assumed to be bounded,our algorithm still runs in polynomial time. As already dis ussed, in pra ti al appli ationsof natural language generation, only few subexpressions from will be pro essed simulta-neously, with k being typi ally, say, three or four. In this ase our algorithm behaves in away that is mu h loser to traditional string parsing than to bag parsing.We on lude that the lass of IDL-expressions provides a exible representation for bagsof words with pre eden e onstraints, with solutions in the range between pure word bagswithout pre eden e onstraints and word latti es, depending on the value of width( ). Wehave also proved a ne-grained result on the time omplexity of the CFG parsing problemfor IDL-expressions, again depending on values of the parameter width( ).8. Final RemarksRe ent proposals view natural language surfa e generation as a multi-phase pro ess where nite but very large sets of andidate senten es are rst generated on the basis of some input on eptual stru ture, and then ltered using statisti al knowledge. In su h ar hite tures, itis ru ial that the adopted representation for the set of andidate senten es is very ompa t,and at the same time that the representation an be parsed in polynomial time.We have proposed IDL-expressions as a solution to the above problem. IDL-expressions ombine features that were onsidered only in isolation before. In ontrast to existingformalisms, intera tion of these features provides enough exibility to en ode strings in ases where only partial knowledge is available about word order, whereas the parsingpro ess remains polynomial in pra ti al ases.The re ognition algorithm we have presented for IDL-expressions an be easily extendedto a parsing algorithm, using standard representations of parse forests that an be extra tedfrom the onstru ted parse table (Lang, 1994). Furthermore, if the produ tions of the CFGat hand are weighted, to express preferen es among derivations, it is easy to extra t a parsewith the highest weight, adapting standard Viterbi sear h te hniques as used in traditionalstring parsing (Viterbi, 1967; Teitelbaum, 1973).Although we have only onsidered the parsing problem for CFGs, one may also parseIDL-expressions with language models based on nite automata, in luding n-gram mod-els. Sin e nite automata an be represented as right-linear ontext-free grammars, thealgorithm in Figure 3 is still appli able.Apart from natural language generation, IDL-expressions are useful wherever un er-tainty on word or onstituent order is to be represented at the level of syntax and has to be313\nNederhof & Sattalinearized for the purpose of parsing. As already dis ussed in the introdu tion, this is ana tive resear h topi both in generative linguisti s and in natural language parsing, and hasgiven rise to several paradigms, most importantly immediate dominan e and linear pre e-den e parsing (Gazdar, Klein, Pullum, & Sag, 1985), dis ontinuous parsing Daniels andMeurers (2002), Ramsay (1999), Suhre (1999) and grammar linearization (G otz & Penn,1997; G otz & Meurers, 1995; Manandhar, 1995). Nederhof, Satta, and Shieber (2003)use IDL-expressions to de ne a new rewriting formalism, based on ontext-free grammarswith IDL-expressions in the right-hand sides of produ tions. By means of this formalism, ne-grained results were proven on immediate dominan e and linear pre eden e parsing.5IDL-expressions are similar in spirit to formalisms developed in the programming lan-guage literature for the representation of the semanti s of on urrent programs. Morespe i ally, so alled series-parallel partially ordered multisets, or series-parallel pomsets,have been proposed by Gis her (1988) to represent hoi e and parallelism among pro esses.However, the basi idea of a lo k operator is absent from series-parallel pomsets.A knowledgmentsA preliminary version of this paper has appeared in the Pro eedings of the 7th Conferen eon Formal Grammars (FG2002), Trento, Italy. The notions of IDL-graph and ut, entralto the present study, are not found in the earlier paper. We wish to thank Mi hael Daniels,Irene Langkilde, Owen Rambow and Stuart Shieber for very helpful dis ussions related tothe topi s in this paper. We are also grateful to the anonymous reviewers for helpful om-ments and pointers to relevant literature. The rst author was supported by the PIONIERProje t Algorithms for Linguisti Pro essing , funded by NWO (Dut h Organization forS ienti Resear h). The se ond author was supported by MIUR under proje t PRIN No.2003091149 005.Referen esAho, A., & Ullman, J. (1972). Parsing, Vol. 1 of The Theory of Parsing, Translation andCompiling. Prenti e-Hall.Aust, H., Oerder, M., Seide, F., & Steinbiss, V. (1995). The Philips automati traintimetable information system. Spee h Communi ation, 17, 249{262.Bangalore, S., & Rambow, O. (2000). Exploiting a probabilisti hierar hi al model for gen-eration. In The 18th International Conferen e on Computational Linguisti s, Vol. 1,pp. 42{48, Saarbr u ken, Germany.Bar-Hillel, Y., Perles, M., & Shamir, E. (1964). On formal properties of simple phrasestru ture grammars. In Bar-Hillel, Y. (Ed.), Language and Information: Sele tedEssays on their Theory and Appli ation, hap. 9, pp. 116{150. Addison-Wesley.Beaven, J. (1992). Shake-and-bake ma hine translation. In Pro . of the fteenth Interna-tional Conferen e on Computational Linguisti s, Vol. 2, pp. 602{609, Nantes.5. In the ited work, the lo k operator was ignored, as it did not a e t the weak generative apa ity northe ompa tness of grammars. 314\nIDL-Expressions: A Formalism for Finite LanguagesBillot, S., & Lang, B. (1989). The stru ture of shared forests in ambiguous parsing. In 27thAnnual Meeting of the Asso iation for Computational Linguisti s, Pro eedings of theConferen e, pp. 143{151, Van ouver, British Columbia, Canada.Brew, C. (1992). Letting the at out of the bag: generation for Shake-and-Bake MT. InPro . of the fteenth International Conferen e on Computational Linguisti s, Vol. 2,pp. 610{616, Nantes.Brown, P., et al. (1990). A statisti al approa h to ma hine translation. ComputationalLinguisti s, 16 (2), 79{85.Brzozowski, J. (1964). Derivatives of regular expressions. Journal of the ACM, 11 (4),481{494.Charniak, E. (2001). Immediate-head parsing for language models. In 39th Annual Meetingand 10th Conferen e of the European Chapter of the Asso iation for ComputationalLinguisti s, Pro eedings of the Conferen e, pp. 116{123, Toulouse, Fran e.Daniels, M., & Meurers, W. (2002). Improving the e\u00c6 ien y of parsing with dis ontinuous onstituents. In Wintner, S. (Ed.), Pro eedings of NLULP'02: The 7th InternationalWorkshop on Natural Language Understanding and Logi Programming, Vol. 92 ofDatalogiske Skrifter, pp. 49{68, Copenhagen. Roskilde Universitets enter.Dassow, J., & P aun, G. (1989). Regulated Rewriting in Formal Language Theory. Springer-Verlag.Earley, J. (1970). An e\u00c6 ient ontext-free parsing algorithm. Communi ations of the ACM,13 (2), 94{102.Gazdar, G., Klein, E., Pullum, G., & Sag, I. (1985). Generalized Phrase Stru ture Grammar.Harvard University Press, Cambridge, MA.Gis her, J. (1988). The equational theory of pomsets. Theoreti al Computer S ien e, 61,199{224.G otz, T., & Meurers, W. (1995). Compiling HPSG type onstraints into de nite lauseprograms. In 33rd Annual Meeting of the Asso iation for Computational Linguisti s,Pro eedings of the Conferen e, pp. 85{91, Cambridge, Massa husetts, USA.G otz, T., & Penn, G. (1997). A proposed linear spe i ation language. Volume 134 ofArbeitspapiere des SFB 340, Universit at T ubingen.Graham, S., & Harrison, M. (1976). Parsing of general ontext free languages. In Advan esin Computers, Vol. 14, pp. 77{185. A ademi Press, New York, NY.Graham, S., Harrison, M., & Ruzzo, W. (1980). An improved ontext-free re ognizer. ACMTransa tions on Programming Languages and Systems, 2 (3), 415{462.Gus eld, D. (1997). Algorithms on Strings, Trees and Sequen es. Cambridge UniversityPress, Cambridge, UK.Harrison, M. (1978). Introdu tion to Formal Language Theory. Addison-Wesley.Jurafsky, D., & Martin, J. (2000). Spee h and Language Pro essing. Prenti e-Hall.Knight, K. (1999). De oding omplexity in word-repla ement translation models. Compu-tational Linguisti s, 25 (4), 607{615. 315\nNederhof & SattaKnight, K., & Hatzivassiloglou, V. (1995). Two-level, many-paths generation. In 33rdAnnual Meeting of the Asso iation for Computational Linguisti s, Pro eedings of theConferen e, pp. 252{260, Cambridge, Massa husetts, USA.Lang, B. (1994). Re ognition an be harder than parsing. Computational Intelligen e,10 (4), 486{494.Langkilde, I. (2000). Forest-based statisti al senten e generation. In 6th Applied NaturalLanguage Pro essing Conferen e and 1st Meeting of the North Ameri an Chapterof the Asso iation for Computational Linguisti s, pp. 170{177 (Se tion 2), Seattle,Washington, USA.Langkilde, I., & Knight, K. (1998). Generation that exploits orpus-based statisti al knowl-edge. In 36th Annual Meeting of the Asso iation for Computational Linguisti s and17th International Conferen e on Computational Linguisti s, Vol. 1, pp. 704{710,Montreal, Quebe , Canada.Manandhar, S. (1995). Deterministi onsisten y he king of LP onstraints. In SeventhConferen e of the European Chapter of the Asso iation for Computational Linguisti s,Pro eedings of the Conferen e, pp. 165{172, Bel eld, Dublin, Ireland.Nederhof, M.-J., & Satta, G. (2004). The language interse tion problem for non-re ursive ontext-free grammars. Information and Computation. A epted for publi ation.Nederhof, M.-J., Satta, G., & Shieber, S. (2003). Partially ordered multiset ontext-freegrammars and free-word-order parsing. In 8th International Workshop on ParsingTe hnologies, pp. 171{182, LORIA, Nan y, Fran e.Nevill-Manning, C., & Witten, I. (1997). Compression and explanation using hierar hi algrammars. The Computer Journal, 40 (2/3), 103{116.Pollard, C., & Sag, I. (1994). Head-Driven Phrase Stru ture Grammar. University ofChi ago Press.Ramsay, A. (1999). Dire t parsing with dis ontinuous phrases. Natural Language Engineer-ing, 5 (3), 271{300.Reape, M. (1989). A logi al treatment of semi-free word order and bounded dis ontinuous onstituen y. In Fourth Conferen e of the European Chapter of the Asso iation forComputational Linguisti s, Pro eedings of the Conferen e, pp. 103{110, Man hester,England.Reape, M. (1994). Domain union and word order variation in german. In Nerbonne, J.,Netter, K., & Pollard, C. (Eds.), German in Head-Driven Phrase Stru ture Grammar,pp. 151{197. CSLI Publi ations.Shieber, S., S habes, Y., & Pereira, F. (1995). Prin iples and implementation of dedu tiveparsing. Journal of Logi Programming, 24, 3{36.Suhre, O. (1999). Computational aspe ts of a grammar formalism for languages with freerword order. Diplomarbeit, Department of Computer S ien e, University of T ubingen.Published in 2000 as Volume 154 of Arbeitspapiere des SFB 340.316\nIDL-Expressions: A Formalism for Finite LanguagesTeitelbaum, R. (1973). Context-free error analysis by evaluation of algebrai power series.In Conferen e Re ord of the Fifth Annual ACM Symposium on Theory of Computing,pp. 196{199.van der Vlist, E. (2003). RELAX NG. O'Reilly.van Noord, G. (1995). The interse tion of nite state automata and de nite lause gram-mars. In 33rd Annual Meeting of the Asso iation for Computational Linguisti s,Pro eedings of the Conferen e, pp. 159{165, Cambridge, Massa husetts, USA.Viterbi, A. (1967). Error bounds for onvolutional odes and an asymptoti ally optimumde oding algorithm. IEEE Transa tions on Information Theory, IT-13 (2), 260{269.Whitelo k, P. (1992). Shake-and-Bake translation. In Pro . of the fteenth InternationalConferen e on Computational Linguisti s, Vol. 2, pp. 784{790, Nantes.\n317"}], "references": [], "referenceMentions": [], "year": 2011, "abstractText": null, "creator": "dvips(k) 5.86 Copyright 1999 Radical Eye Software"}}}