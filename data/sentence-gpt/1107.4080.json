{"id": "1107.4080", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jul-2011", "title": "On the Universality of Online Mirror Descent", "abstract": "We show that for a general class of convex online learning problems, Mirror Descent can always achieve a (nearly) optimal regret guarantee.\n\n\n\nTo learn more about Mirror Descent, click the links below to see how to use Mirror Descent as an online learning system.\nMirror Descent is available to all interested school students.\nMirror Descent is an online platform to learn about all problems in the world, including mathematics, the theory of evolution, the history of evolution, and computer programming.\nThe Mirror Descent Platform is open source and provides access to all major Internet websites including Microsoft, Amazon, Amazon Web Services, Amazon Web Services, Google, Facebook, Reddit, Google+ and YouTube.\nThere is also an online marketplace to share your experience and how you can use Mirror Descent for learning in the classroom.", "histories": [["v1", "Wed, 20 Jul 2011 19:34:00 GMT  (32kb,D)", "http://arxiv.org/abs/1107.4080v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["nati srebro", "karthik sridharan", "ambuj tewari"], "accepted": true, "id": "1107.4080"}, "pdf": {"name": "1107.4080.pdf", "metadata": {"source": "CRF", "title": "On the Universality of Online Mirror Descent", "authors": ["Nathan Srebro", "Karthik Sridharan", "Ambuj Tewari"], "emails": ["nati@ttic.edu", "karthik@ttic.edu", "ambuj@cs.utexas.edu"], "sections": [{"heading": "1 Introduction", "text": "Mirror Descent is a first-order optimization procedure which generalizes the classic Gradient Descent procedure to non-Euclidean geometries by relying on a \u201cdistance generating function\u201d specific to the geometry (the squared `2- norm in the case of standard Gradient Descent) [14, 4]. Mirror Descent is also applicable, and has been analyzed, in a stochastic optimization setting [9] and in an online setting, where it can ensure bounded online regret [20]. In fact, many classical online learning algorithms can be viewed as instantiations or variants of Online Mirror Descent, generally either with the Euclidean geometry (e.g. the Perceptron algorithm [5] and Online Gradient Descent [27]), or in the simplex (`1 geometry), using an entropic distance generating function (Winnow [13] and Multiplicative Weights / Online Exponentiated Gradient algorithm [11]). More recently, the Online Mirror Descent framework has been applied, with appropriate distance generating functions derived for a variety of new learning problems like multi-task learning and other matrix learning problems [10], online PCA [26] etc.\nIn this paper, we show that Online Mirror Descent is, in a sense, universal. That is, for any convex online learning problem, of a general form (specified in Section 2), if the problem is online learnable, then it is online learnable, with a nearly optimal regret rate, using Online Mirror Descent, with an appropriate distance generating function. Since Mirror descent is a first order method and often has simple and computationally efficient update rules, this makes the result especially attractive. Viewing online learning as a sequentially repeated game, this means that Online Mirror Descent is a near optimal strategy, guaranteeing an outcome very close to the value of the game.\nIn order to show such universality, we first generalize and refine the standard Mirror Descent analysis to situations where the constraint set is not the dual of the data domain, obtaining a general upper bound on the regret of Online Mirror Descent in terms of the existence of an appropriate uniformly convex distance generating function (Section 3). We then extend the notion of a martingale type of a Banach space to be sensitive to both the constraint set and the data domain, and building on results of [24], we relate the value of the online learning repeated game to this generalized notion of martingale type (Section 4). Finally, again building on and generalizing the work of [16], we show how having appropriate martingale type guarantees the existence of a good uniformly convex function (Section 5), that in turn establishes the desired nearly-optimal guarantee on Online Mirror Descent (Section 6). We mainly build on the analysis of [24], who related the value of the online game to the notion of martingale type of a Banach space and uniform convexity when the constraint set and data domain are dual to each other. The main technical advance here is a non-trivial generalization of their analysis (as well as the Mirror Descent analysis) to the more general situation where the constraint set and data domain are chosen independently of each other. In Section 7 several examples are provided that demostrate the use of our analysis.\nMirror Descent was initially introduced as a first order deterministic optimization procedure, with an `p constraint and a matching `q Lipschitz assumption (1 \u2264 p \u2264 2, 1/q + 1/p = 1), was shown to be optimal in terms of the number of exact gradient evaluations [15]. Shalev-Shwartz and Singer later observed that the online version of Mirror\nar X\niv :1\n10 7.\n40 80\nv1 [\ncs .L\nG ]\n2 0\nJu l 2\n01 1\nDescent, again with an `p bound and matching `q Lipschitz assumption (1 \u2264 p \u2264 2, 1/q+ 1/p = 1), is also optimal in terms of the worst-case (adversarial) online regret. In fact, in such scenarios stochastic Mirror Descent is also optimal in terms of the number of samples used. We emphasize that although in most, if not all, settings known to us these three notions of optimality coincide, here we focus only on the worst-case online regret.\nSridharan and Tewri [24] generalized the optimality of online Mirror Descent (w.r.t. the worst case online regret) to scenarios where learner is constrained to a unit ball of an arbitrary Banach space (not necessarily and `p space) and the objective functions have sub-gradients that lie in the dual ball of the space\u2014for reasons that will become clear shortly, we refer to this as the data domain. However, often we encounter problems where the constraint set and data domain are not dual balls, but rather are arbitrary convex subsets. In this paper, we explore this more general, \u201cnon-dual\u201d, variant, and show that also in such scenarios online Mirror Descent is (nearly) optimal in terms of the (asymptotic) worst-case online regret."}, {"heading": "2 Online Convex Learning Problem", "text": "An online convex learning problem can be viewed as a multi-round repeated game where on round t, the learner first picks a vector (predictor) wt from some fixed set W , which is a closed convex subset of a vector space B. Next, the adversary picks a convex cost function ft : W 7\u2192 R from a class of convex functions F . At the end of the round, the learner pays instantaneous cost ft(wt). We refer to the strategy used by the learner to pick the ft\u2019s as an online learning algorithm. More formally, an online learning algorithmA for the problem is specified by the mapping A : \u22c3 n\u2208N Fn\u22121 7\u2192 W . The regret of the algorithm A for a given sequence of cost functions f1, . . . , fn is given by\nRn(A, f1, . . . , fn) = 1\nn n\u2211 t=1 ft(A(f1:t\u22121))\u2212 inf w\u2208W 1 n n\u2211 t=1 ft(w) .\nThe goal of the learner (or the online learning algorithm), is to minimize the regret for any n. In this paper, we consider cost function classes F specified by a convex subset X \u2282 B? of the dual space B?. We consider various types of classes, where for all of them, subgradients1 of the functions in F lie inside X (we use the notation \u3008x,w\u3009 to mean applying linear functional x \u2208 B? on w \u2208 B) :\nFLip(X ) = {f : f is convex \u2200w \u2208 W,\u2207f(w) \u2208 X} , Flin(X ) = {w 7\u2192 \u3008x,w\u3009 : x \u2208 X} , Fsup(X ) = {w 7\u2192 |\u3008x,w\u3009 \u2212 y| : x \u2208 X , y \u2208 [\u2212b, b]}\nThe value of the game is then the best possible worst-case regret guarantee an algorithm can enjoy. Formally the value is defined as :\nVn(F ,X ,W) = inf A sup f1:n\u2208F(X ) Rn(A, f1:n) (1)\nIt is well known that the value of a game for all the above sets F is the same. More generally:\nProposition 1. If for a convex function class F , we have that \u2200f \u2208 F ,w \u2208 W,\u2207f(w) \u2208 X then,\nVn(F ,X ,W) \u2264 Vn(Flin,X ,W)\nFurthermore, Vn(FLip,X ,W) = Vn(Fsup,X ,W) = Vn(Flin,X ,W)\nThat is, the value for any class F with subgradients inW , which include all the above classes, is upper bounded by the value of the class of linear functionals in W , see e.g. [1]. In particular, this includes the class FLip which is the class of all functions with subgradients inW , and thus, since Flin(X ) \u2282 FLip(X ) we get the first equality. The second equality is shown in [18].\n1Throughout we commit to a slight abuse of notation, with \u2207f(w) indicating some sub-gradient of f at w and \u2207f(w) \u2208 X meaning that at least one of the sub-gradients is in X .\nThe class Fsup(X ) corresponds to linear prediction with an absolute-difference loss, and thus its value is the best possible guarantee for online supervised learning with this loss. We can define more generally a class F` = {`(\u3008x,w\u3009, y) : x \u2208 X , y \u2208 [\u2212b, b]} for any 1-Lipschitz loss `, and this class would also be of the desired type, with its value upper bounded by Vn(Flin,X ,W). In fact, this setting includes supervised learning fairly generally, including problems such as multitask learning and matrix completion, where in all cases X specifies the data domain2. The equality in the above proposition can also be essentially extended to most other commonly occurring convex loss function classes like say the hinge loss class with some extra constant factors.\nOwing to Proposition 1, we can focus our attention on the class Flin (as the other two will behave similarly), and so use the shorthand\nVn(W,X ) := Vn(Flin,X ,W) (2)\nand henceforth the term value without any qualification refers to value of the linear game. Further, for any p \u2208 [1, 2] we us also define :\nVp := inf { V \u2223\u2223\u2223 \u2200n \u2208 N,Vn(W,X ) \u2264 V n\u2212(1\u2212 1p )} (3)\nMost prior work on online learning and optimization considers the case whenW is the unit ball of some Banach space, and X is the unit ball of the dual space, i.e.W and X are related to each other through duality. In this work, however, we analyze the general problem where X \u2208 B? is not necessarily the dual ball ofW . It will be convenient for us, however, to relate the notions of a convex set and a corresponding norm. The Minkowski functional of a subset K of a vector space V is defined as \u2016v\u2016K := inf {\u03b1 > 0 : v \u2208 \u03b1K}. If K is convex and centrally symmetric (i.e. K = \u2212K), then \u2016\u00b7\u2016K is a semi-norm. Throughout this paper, we will require that W and X are convex and centrally symmetric. Further, if the set K is bounded then \u2016\u00b7\u2016K is a norm. Although not strictly required for our results, for simplicity we will assumeW and X are are such that \u2016\u00b7\u2016W and \u2016\u00b7\u2016X (the Minkowski functionals of the sets W and X ) are norms. Even though we do this for simplicity, we remark that all the results go through for semi-norms. We use X ? and W? to represent the dual of balls X and W respectively, i.e. the unit balls of the dual norms \u2016\u00b7\u2016\u2217X and \u2016\u00b7\u2016 \u2217 X ."}, {"heading": "3 Mirror Descent and Uniform Convexity", "text": "A key tool in the analysis mirror descent is the notion of strong convexity, or more generally uniform convexity:\nDefinition 1. \u03a8 : B \u2192 R is q-uniformly convex w.r.t. \u2016 \u00b7 \u2016 inW \u2282 B:\n\u2200w,w\u2032\u2208W\u2200\u03b1\u2208[0,1] \u03a8 (\u03b1w + (1\u2212 \u03b1)w\u2032) \u2264 \u03b1\u03a8(w) + (1\u2212 \u03b1)\u03a8(w\u2032)\u2212 \u03b1(1\u2212\u03b1)q \u2016w \u2212w \u2032\u2016q\nIt is important to emphasize that in the definition above, the norm \u2016.\u2016 and the subsetW need not be related, and we only require uniform convexity insideW . This allows us to relate a norm with a non-matching \u201cball\u201d. To this end define,\nDp := inf {( sup w\u2208W \u03a8(w) ) p\u22121 p \u2223\u2223\u2223\u2223\u2223 \u03a8 :W 7\u2192 R+ is pp\u22121 -uniformly convex w.r.t. \u2016\u00b7\u2016X\u2217 onW,\u03a8(0) = 0 }\nGiven a function \u03a8, the Mirror Descent algorithm, AMD is given by\nwt+1 = argmin w\u2208W\n\u2206\u03a8 (w|wt) + \u03b7\u3008\u2207ft(wt),w \u2212wt\u3009 (4)\nor equivalently w\u2032t+1 = \u2207\u03a8\u2217 (\u2207\u03a8(wt)\u2212 \u03b7\u2207ft(wt)) , wt+1 = argmin w\u2208W\n\u2206\u03a8 ( w \u2223\u2223w\u2032t+1) (5)\n2Note that any convex supervised learning problem can necessarily be viewed as linear classification with some convex constraint W on the predictors.\nwhere \u2206\u03a8 (w|w\u2032) := \u03a8(w)\u2212\u03a8(w\u2032)\u2212\u3008\u2207\u03a8(w\u2032),w \u2212w\u2032\u3009 is the Bregman divergence and \u03a8\u2217 is the convex conjugate of \u03a8. As an example notice that when \u03a8(w) = 12 \u2016w\u2016 2 2 then we get back the gradient descent algorithm and when\nW is the d dimensional simplex and \u03a8(w) = \u2211d i=1 wi log(1/wi) then we get the multiplicative weights update algorithm.\nLemma 2. Let \u03a8 : B 7\u2192 R be non-negative and q-uniformly convex w.r.t. norm \u2016\u00b7\u2016X\u2217 on W . For the Mirror\nDescent algorithm with this \u03a8, using w1 = argmin w\u2208W\n\u03a8(w) and \u03b7 = ( supw\u2208W \u03a8(w)\nnB\n)1/p we can guarantee that for any\nf1, . . . , fn s.t. 1n \u2211n t=1 \u2016\u2207ft\u2016 p X \u2264 1 (where p = q q\u22121 ),\nR(AMD, f1, . . . , fn) \u2264 2 ( supw\u2208W \u03a8(w)\nn\n) 1 q\n.\nNote that in our case we have \u2207f \u2208 X , i.e. \u2016\u2207f\u2016X \u2264 1, and so certainly 1 n \u2211n t=1 \u2016\u2207ft\u2016 p X \u2264 1. Similarly to the\nvalue of the game, for any p \u2208 [1, 2], we define:\nMDp := inf\n{ D : \u2203\u03a8, \u03b7 s.t. \u2200n \u2208 N, sup\nf1:n\u2208F(X ) Rn(AMD, f1:n) \u2264 Dn\u2212(1\u2212 1 p )\n} (6)\nwhere the Mirror Descent algorithm in the above definition is run with the corresponding \u03a8 and \u03b7. The constant MDp is a characterization of the best guarantee the Mirror Descent algorithm can provide. Lemma 2 therefore implies:\nCorollary 3. Vp \u2264 MDp \u2264 2Dp.\nProof. The first inequality is essentially by the definition of Vp and MDp. The second inequality follows directly from previous lemma.\nThe Mirror Descent bound suggests that as long as we can find an appropriate function \u03a8 that is uniformly convex w.r.t. \u2016\u00b7\u2016\u2217X we can get a diminishing regret guarantee using Mirror Descent. This suggests constructing the following function:\n\u03a8\u0303q := argmin \u03c8:\u03c8 is q-uniformly convex\nw.r.t. \u2016\u00b7\u2016X\u2217 onW and \u03c8\u22650\nsup w\u2208W \u03a8(w) . (7)\nIf no q-uniformly convex function exists then \u03a8\u0303q =\u221e is assumed by default. The above function is in a sense the best choice for the Mirror Descent bound in (2). The question then is: when can we find such appropriate functions and what is the best rate we can guarantee using Mirror Descent?"}, {"heading": "4 Martingale Type and Value", "text": "In [24], it was shown that the concept of the Martingale type (also sometimes called the Haar type) of a Banach space and optimal rates for online convex optimization problem, where X andW are duals of each other, are closely related. In this section we extend the classic notion of Martingale type of a Banach space (see for instance [16]) to one that accounts for the pair (W?,X ). Before we proceed with the definitions we would like to introduce a few necessary notations. First, throughout we shall use \u2208 {\u00b11}N to represent infinite sequence of signs drawn uniformly at random (i.e. each i has equal probability of being +1 or \u22121). Also throughout (xn)n\u2208N represents a sequence of mappings where each xn : {\u00b11}n\u22121 7\u2192 B?. We shall commit to the abuse of notation and use xn( ) to represent xn( ) = xn( 1, . . . , n\u22121) (i.e. although we used entire as argument, xn only depends on first n\u2212 1 signs). We are now ready to give the extended definition of Martingale type (or M-type) of a pair (W?,X ).\nDefinition 2. A pair (W?,X ) of subsets of a vector space B? is said to be of M-type p if there exists a constant C \u2265 1 such that for all sequence of mappings (xn)n\u22651 where each xn : {\u00b11}n\u22121 7\u2192 B? and any x0 \u2208 B? :\nsup n\nE [\u2225\u2225\u2225\u2225\u2225x0 + n\u2211 i=1 ixi( ) \u2225\u2225\u2225\u2225\u2225 p\nW?\n] \u2264 Cp \u2016x0\u2016pX +\u2211 n\u22651 E [\u2016xn( )\u2016pX ]  (8) The concept is called Martingale type because ( nxn( ))n\u2208N is a martingale difference sequence and it can be shown that rate of convergence of martingales in Banach spaces is governed by the rate of convergence of martingales of the form Zn = x0 + \u2211n i=1 ixi( ) (which are incidentally called Walsh-Paley martingales). We point the reader to [16, 17] for more details. Further, for any p \u2208 [1, 2] we also define,\nCp := inf C \u2223\u2223\u2223\u2223\u2223\u2223 \u2200x0 \u2208 B?, \u2200(xn)n\u2208N, supn E [\u2225\u2225\u2225\u2225\u2225x0 + n\u2211 i=1 ixi( ) \u2225\u2225\u2225\u2225\u2225 p\nW?\n] \u2264 Cp \u2016x0\u2016pX +\u2211 n\u22651 E \u2016xn( )\u2016pX  Cp is useful in determining if the pair (W?,X ) has Martingale type p.\nThe results of [24, 18] showing that a Martingale type implies low regret, actually apply also for \u201cnon-matching\u201d W and X and, in our notation, imply that Vp \u2264 2Cp. Specifically we have the following theorem from [24, 18] :\nTheorem 4. [24, 18] For anyW \u2208 B and any X \u2208 B? and any n \u2265 1,\nsup x\nE [\u2225\u2225\u2225\u2225\u2225 1n n\u2211 i=1 ixi( ) \u2225\u2225\u2225\u2225\u2225 W? ] \u2264 Vn(W,X ) \u2264 2 sup x E [\u2225\u2225\u2225\u2225\u2225 1n n\u2211 i=1 ixi( ) \u2225\u2225\u2225\u2225\u2225 W? ]\nwhere the supremum above is over sequence of mappings (xn)n\u22651 where each xn : {\u00b11}n\u22121 7\u2192 X .\nOur main interest here will is in establishing that low regret implies Martingale type. To do so, we start with the above theorem to relate value of the online convex optimization game to rate of convergence of martingales in the Banach space. We then extend the result of Pisier in [16] to the \u201cnon-matching\u201d setting combining it with the above theorem to finally get :\nLemma 5. If for some r \u2208 (1, 2] there exists a constant D > 0 such that for any n,\nVn(W,X ) \u2264 Dn\u2212(1\u2212 1 r )\nthen for all p < r, we can conclude that any x0 \u2208 B? and any B? sequence of mappings (xn)n\u22651 where each xn : {\u00b11}n\u22121 7\u2192 B? will satisfy :\nsup n\nE [\u2225\u2225\u2225\u2225\u2225x0 + n\u2211 i=1 ixi( ) \u2225\u2225\u2225\u2225\u2225 p\nW?\n] \u2264 ( 1104 D\n(r \u2212 p)2 )p\u2016x0\u2016pX +\u2211 i\u22651 E [\u2016xi( )\u2016pX ]  That is, the pair (W,X ) is of martingale type p.\nThe following corollary is an easy consequence of the above lemma.\nCorollary 6. For any p \u2208 [1, 2] and any p\u2032 < p : Cp\u2032 \u2264 1104 Vp(p\u2212p\u2032)2"}, {"heading": "5 Uniform Convexity and Martingale Type", "text": "The classical notion of Martingale type plays a central role in the study of geometry of Banach spaces. In [16], it was shown that a Banach space has Martingale type p (the classical notion) if and only if uniformly convex functions with certain properties exist on that space (w.r.t. the norm of that Banach space). In this section, we extend this result and show how the Martingale type of a pair (W?,X ) are related to existence of certain uniformly convex functions. Specifically, the following theorem shows that the notion of Martingale type of pair (W?,X ) is equivalent to the existence of a non-negative function that is uniformly convex w.r.t. the norm \u2016\u00b7\u2016X? onW .\nLemma 7. If, for some p \u2208 (1, 2], there exists a constant C > 0, such that for all sequences of mappings (xn)n\u22651 where each xn : {\u00b11}n\u22121 7\u2192 B? and any x0 \u2208 B?:\nsup n\nE [\u2225\u2225\u2225\u2225\u2225x0 + n\u2211 i=1 ixi( ) \u2225\u2225\u2225\u2225\u2225 p\nW?\n] \u2264 Cp \u2016x0\u2016pX +\u2211 n\u22651 E [\u2016xn( )\u2016pX ]  (i.e. (W?,X ) has Martingale type p), then there exists a convex function \u03a8 : B 7\u2192 R+ with \u03a8(0) = 0, that is q-uniformly convex w.r.t. norm \u2016\u00b7\u2016X? s.t. \u2200w \u2208 B, 1 q \u2016w\u2016 q X? \u2264 \u03a8(w) \u2264 Cq q \u2016w\u2016 q W .\nThe following corollary follows directly from the above lemma.\nCorollary 8. For any p \u2208 [1, 2], Dp \u2264 Cp.\nThe proof of Lemma 7 goes further and gives a specific uniformly convex function \u03a8 satisfying the desired requirement (i.e. establishing Dp \u2264 Cp) under the assumptions of the previous lemma:\n\u03a8\u2217q(x) := sup  1Cp supn E [\u2225\u2225\u2225\u2225\u2225x + n\u2211 i=1 ixi( ) \u2225\u2225\u2225\u2225\u2225 p\nW?\n] \u2212 \u2211 i\u22651 E [ \u2016xi( )\u2016pX ] , \u03a8q := (\u03a8\u2217q)\u2217 . (9) where the supremum above is over sequences (xn)n\u2208N and p = qq\u22121 ."}, {"heading": "6 Optimality of Mirror Descent", "text": "In the Section 3, we saw that if we can find an appropriate uniformly convex function to use in the mirror descent algorithm, we can guarantee diminishing regret. However the pending question there was when can we find such a function and what is the rate we can gaurantee. In Section 4 we introduced the extended notion of Martingale type of a pair (W?,X ) and how it related to the value of the game. Then, in Section 5, we saw how the concept of M-type related to existence of certain uniformly convex functions. We can now combine these results to show that the mirror descent algorithm is a universal online learning algorithm for convex learning problems. Specifically we show that whenever a problem is online learnable, the mirror descent algorithm can guarantee near optimal rates:\nTheorem 9. If for some constant V > 0 and some q \u2208 [2,\u221e), Vn(W,X ) \u2264 V n\u2212 1 q for all n, then for any n > eq\u22121, there exists regularizer function \u03a8 and step-size \u03b7, such that the regret of the mirror descent algorithm using \u03a8 against any f1, . . . , fn chosen by the adversary is bounded as:\nRn(AMD, f1:n) \u2264 6002V log2(n) n\u2212 1 q (10)\nProof. Combining Mirror descent guarantee in Lemma 2, Lemma 7 and the lower bound in Lemma 5 with p = q q\u22121 \u2212 1 log(n) we get the above statement.\nThe above Theorem tells us that, with appropriate \u03a8 and learning rate \u03b7, mirror descent will obtain regret at most a factor of 6002 log(n) from the best possible worst-case upper bound. We would like to point out that the constant V in the value of the game appears linearly and there is no other problem or space related hidden constants in the bound.\nThe following figure summarizes the relationship between the various constants. The arrow mark from Cp\u2032 to Cp indicates that for any n, all the quantities are within log2 n factor of each other.\nWe now provide some general guidelines that will help us in picking out appropriate function \u03a8 for mirror descent. First we note that though the function \u03a8q in the construction (9) need not be such that (q\u03a8q(w))1/q is a norm, with a simple modification as noted in [17] we can make it a norm. This basically tells us that the pair (W,X ) is online learnable, if and only if we can sandwich a q-uniformly convex norm in-between X ? and a scaled version ofW (for some q <\u221e). Also note that by definition of uniform convexity, if any function \u03a8 is q-uniformly convex w.r.t. some norm \u2016\u00b7\u2016 and we have that \u2016\u00b7\u2016 \u2265 c \u2016\u00b7\u2016X , then \u03a8(\u00b7) cq is q-uniformly convex w.r.t. norm \u2016\u00b7\u2016X . These two observations together suggest that given pair (W,X ) what we need to do is find a norm \u2016\u00b7\u2016 in between \u2016\u00b7\u2016?X and C \u2016\u00b7\u2016W (C <\u221e, smaller the C better the bound ) such that \u2016\u00b7\u2016q is q-uniformly convex w.r.t \u2016\u00b7\u2016."}, {"heading": "7 Examples", "text": "We demonstrate our results on several online learning problems, specified byW and X .\n`p non-dual pairs It is usual in the literature to consider the case whenW is the unit ball of the `p norm in some finite dimension d while X is taken to be the unit ball of the dual norm `q where p, q are Ho\u0308lder conjugate exponents. Using the machinery developed in this paper, it becomes effortless to consider the non-dual case whenW is the unit ball Bp1 of some `p1 norm while X is the unit ballBp2 for arbitrary p1, p2 in [1,\u221e]. We shall use q1 and q2 to represent Holder conjugates of p1 and p2. Before we proceed we first note that for any r \u2208 (1, 2], \u03c8r(w) := 12(r\u22121)\u2016w\u2016 2 r is 2-uniformly w.r.t. norm \u2016\u00b7\u2016r (see for instance [25]). On the other hand by Clarkson\u2019s inequality, we have that for r \u2208 (2,\u221e), \u03c8r(w) := 2r r \u2016w\u2016 r r is r-uniformly convex w.r.t. \u2016\u00b7\u2016r. Putting it together we see that for any r \u2208 (1,\u221e), the function \u03c8r defined above, is Q-uniformly convex w.r.t \u2016\u00b7\u2016r for Q = max{r, 2}. The basic technique idea is to be to select \u03c8r based on the guidelines in the end of the previous section. Finally we show that using \u03c8\u0303r := d Qmax{ 1q2\u2212 1 r ,0}\u03c8r in Mirror descent Lemma 2 yields the bound that for any f1, . . . , fn \u2208 F :\nRn(AMD, f1:n) \u2264 2 max{2, 1\u221a 2(r\u22121) }dmax{ 1 q2 \u2212 1r ,0}+max{ 1 r\u2212 1 p1 ,0}\nn1/max{r,2}\nThe following table summarizes the scenarios where a value of r = 2, i.e. a rate of D2/ \u221a n, is possible, and lists\nthe corresponding values of D2 (up to numeric constant of at most 16):\np1 Range q2 = p2p2\u22121 Range D2 1 \u2264 p1 \u2264 2 q2 > 2 1 1 \u2264 p1 \u2264 2 p1 \u2264 q2 \u2264 2 \u221a p2 \u2212 1 1 \u2264 p1 \u2264 2 1 \u2264 q2 < p1 d1/q2\u22121/p1 \u221a p2 \u2212 1 p1 > 2 q2 > 2 d(1/2\u22121/p1) p1 > 2 1 \u2264 q2 \u2264 2 d(1/q2\u22121/p1) 1 \u2264 p1 \u2264 2 q2 =\u221e \u221a log(d)\nNote that the first two rows are dimension free, and so apply also in infinite-dimensional settings, whereas in the other scenarios, D2 is finite only when the dimension is finite. An interesting phenomena occurs when d is\u221e, p1 > 2 and q2 \u2265 p1. In this case D2 = \u221e and so one cant expect a rate of O( 1\u221an ). However we have Dp2 < 16 and so can still get a rate of n\u2212 1 q2 .\nBall et al [3] tightly calculate the constants of strong convexity of squared `p norms, establishing the tightness of D2 when p1 = p2. By extending their constructions it is also possible to show tightness (up to a factor of 16) for all other values in the table. Also, Agarwal et al [2] recently showed lower bounds on the sample complexity of stochastic optimization when p1 =\u221e and p2 is arbitrary\u2014their lower bounds match the last two rows in the table.\nNon-dual Schatten norm pairs in finite dimensions Exactly the same analysis as above can be carried out for Schatten p-norms, i.e. when W = BS(p1), X = BS(p2) are the unit balls of Schatten p-norm (the p-norm of the singular values) for matrix of dimensions d1 \u00d7 d2. We get the same results as in the table above (as upper bounds on D2), with d = min{d1, d2}. These results again follow using similar arguments as `p case and tight constants for strong convexity parameters of the Schatten norm from [3].\nNon-dual group norm pairs in finite dimensions In applications such as multitask learning, groups norms such as \u2016w\u2016q,1 are often used on matrices w \u2208 Rk\u00d7d where (q, 1) norm means taking the `1-norm of the `q-norms of the columns of w. Popular choices include q = 2,\u221e. Here, it may be quite unnatural to use the dual norm (p,\u221e) to define the space X where the data lives. For instance, we might want to considerW = B(q,1) and X = B(\u221e,\u221e) = B\u221e. In such a case we can calculate that D2(W,X ) = \u0398(k1\u2212 1 q \u221a log(d)) using \u03a8(w) = 1q+r\u22122 \u2016w\u2016 2 q,r where r = log d log d\u22121 .\nMax Norm Max-norm has been proposed as a convex matrix regularizer for application such as matrix completion [21]. In the online version of the matrix completion problem at each time step one element of the matrix is revealed, corresponding to X being the set of all matrices with a single element being 1 and the rest 0. Since we need X to be convex we can take the absolute convex hull of this set and use X to be the unit element-wise `1 ball. Its dual is \u2016W\u2016X? = maxi,j |Wi,j |. On the other hand given a matrix W , its max-norm is given by \u2016W\u2016max = minU,V :W=UV > (maxi \u2016Ui\u20162) ( maxj \u2016Vj\u20162 ) . The set W is the unit ball under the max norm. As noted in [22] the max-norm ball is equivalent, up to a factor two, to the convex hull of all rank one sign matrices. Let us now make a more general observation.\nProposition 10. LetW = abscvx({w1, . . . ,wK}). The Minkowski norm for thisW is given by\n\u2016w\u2016W := inf \u03b11,...,\u03b1K :w= \u2211K i=1 \u03b1iwi K\u2211 i=1 |\u03b1i|\nIn this case, for any q \u2208 (1, 2], if we define the norm :\n\u2016w\u2016W,q = inf \u03b11,...,\u03b1K :w= \u2211K i=1 \u03b1iwi ( K\u2211 i=1 |\u03b1i|q )1/q\nthen the function \u03a8(w) = 12(q\u22121) \u2016w\u2016 2 W,q is 2-uniformly convex w.r.t. \u2016\u00b7\u2016W,q . Further if we use q = logK logK\u22121 , then supw\u2208W \u221a \u03a8(w) = O( \u221a logK).\nProof of the above proposition is similar to proof of strong convexity of `q norms. For the max norm case as noted before the norm is equivalent to the norm got by the taking the absolute convex hull of the set of all rank one sign matrices. Cardinality of this set is of course 2N+M . Hence using the above proposition and noting that X ? is the unit ball of | \u00b7 |\u221e we see that \u03a8 is obviously 2-uniformly convex w.r.t. \u2016\u00b7\u2016X? and so we get a regret bound O (\u221a M+N n ) . This matches the stochastic (PAC) learning guarantee [22], and is the first guarantee we are aware of for the max norm matrix completion problem in the online setting.\nInterpolation Norms Another interesting setting is when the set W is got by interpolating between unit balls of two other norms \u2016\u00b7\u2016W1 and \u2016\u00b7\u2016W2 . Specifically one can considerW to be the unit ball of two such interpolated norms, the first type of interpolation norm is given by,\n\u2016w\u2016W = \u2016w\u2016W1 + \u2016w\u2016W2 (11)\nThe second type of interpolation norm one can consider is given by \u2016w\u2016W = infw1+w2=w ( \u2016w1\u2016W1 + \u2016w2\u2016W2 ) (12)\nIn learning problems such interpolation norms are often used to induce certain structures or properties into the regularization. For instance one might want sparsity along with grouping effect in the linear predictors for which elastic-net type regularization introduced by Zou and Hastie [28] (this is captured by interpolation of the first type between `1 and `2 norms). Another example is in matrix completion problems when we would like the predictor matrix to be decomposable into sum of sparse and low rank matrices as done by Chanrdasekaran et. al [6] (here one can use the interpolation norm of second type to interpolate between trace norm and element wise `1 norm). Another example\nwhere interpolation norms of type two are useful are in multi-task learning problems (with linear predictors) as done by Jalali et. al [8]. The basic idea is that the matrix of linear predictors can is decomposed into sum of two matrices one with for instance low entry-wise `1 norm and other with low B(2,\u221e) group norm (group sparsity). While in these applications the setW used is obtained through interpolation norms, it is typically not natural for the set X to be the dual ball ofW but rather something more suited to the problem at hand. For instance, for the elastic net regularization case, the set X usually considered are either the vectors with bounded `\u221e norm or bounded `2. Similarly for the [8] case X could be either matrices with bounded entries or some other natural assumption that suits the problem. It can be shown that in general for any interpolation norm of first type specified in Equation 11,\nD2(W,X ) \u2264 2 min{D2(W1,X ), D2(W2,X )} (13)\nSimilarly for the interpolation norm of type two one can in general show that,\nD2(W,X ) \u2264 1\n2 max{D2(W1,X ), D2(W2,X )} (14)\nUsing the above bounds one can get regret bounds for mirror descent algorithm with appropriate \u03a8 and step size \u03b7 for specific examples like the ones mentioned.\nThe bounds given in Equations (13) and (14) are only upper bounds and it would be interesting to analyze these cases in more detail and also to analyze interpolation between several norms instead of just two."}, {"heading": "8 Conclusion and Discussion", "text": "In this paper we showed that for a general class of convex online learning problems, there always exists a distance generating function \u03a8 such that Mirror Descent using this function achieves a near-optimal regret guarantee. This shows that a fairly simple first-order method, in which each iteration requires a gradient computation and a proxmap computation, is sufficient for online learning in a very general sense. Of course, the main challenge is deriving distance generating functions appropriate for specific problems\u2014although we give two mathematical expressions for such functions, in equations (7) and (9), neither is particularly tractable in general. In the end of Section 6 we do give some general guidelines for choosing the right distance generating function. However obtaining a more explicit and simple procedure at least for reasonable Banach spaces is a very interesting question.\nFurthermore, for the Mirror Descent procedure to be efficient, the prox-map of the distance generating function must be efficiently computable, which means that even though a Mirror Descent procedure is always theoretically possible, we might in practice choose to use a non-optimal distance generating function, or even a non-MD procedure. Furthermore, we might also find other properties of w desirable, such as sparsity, which would bias us toward alternative methods [12, 7]. Nevertheless, in most instances that we are aware of, Mirror Descent, or slight variations of it, is truly an optimal procedure and this is formalized and rigorously establish here.\nIn terms of the generality of the problems we handle, we required that the constraint set W be convex, but this seems unavoidable if we wish to obtain efficient algorithms (at least in general). Furthermore, we know that in terms of worst-case behavior, both in the stochastic and in the online setting, for convex cost functions, the value is unchained when the convex hull of a non-convex constraint set [18]. The requirement that the data domain X be convex is perhaps more restrictive, since even with non-convex data domain, the objective is still convex. Such non-convex X are certainly relevant in many applications, e.g. when the data is sparse, or when x \u2208 X is an indicator, as in matrix completion problems and total variation regularization. In the total variation regularization problem, W is the set of all functions on the interval [0, 1] with total variation bounded by 1 which is in fact a Banach space. However set X we consider here is not the entire dual ball and in fact is neither convex nor symmetric. It only consists of evaluations of the functions inW at points on interval [0, 1] and one can consider a supervised learning problem where the goal is to use the set of all functions with bounded variations to predict targets which take on values in [\u22121, 1] . Although the total-variation problem is not learnable, the matrix completion problem certainly is of much interest. In the matrix completion case, taking the convex hull of X does not seem to change the value, but we are unaware of neither a\nguarantee that the value of the game is unchanged when a non-convex X is replaced by its convex hull, nor of an example where the value does change\u2014it would certainly be useful to understand this issue. We view the requirement thatW and X be symmetric around the origin as less restrictive and mostly a matter of convenience.\nWe also focused on a specific form of the cost class F , which beyond the almost unavoidable assumption of convexity, is taken to be constrained through the cost sub-gradients. This is general enough for considering supervised learning with an arbitrary convex loss in a worst-case setting, as the sub-gradients in this case exactly correspond to the data points, and so restricting F through its sub gradients corresponds to restricting the data domain. Following Proposition 1, any optimality result for FLip also applies to Fsup, and this statement can also be easily extended to any other reasonable loss function, including the hinge-loss, smooth loss functions such as the logistic loss, and even strongly-convex loss functions such as the squared loss (in this context, note that a strongly convex scalar function for supervised learning does not translate to a strongly convex optimization problem in the worst case). Going beyond a worst-case formulation of supervised learning, one might consider online repeated games with other constraints on F , such as strong convexity, or even constraints on {ft} as a sequence, such as requiring low average error or conditions on the covariance of the data\u2014these are beyond the scope of the current paper.\nEven for the statistical learning setting, online methods along with online to batch conversion are often preferred due to their efficiency especially in high dimensional problems. In fact for `p spaces in the dual case, using lower bounds on the sample complexity for statistical learning of these problems, one can show that for large dimensional problems, mirror descent is an optimal procedure even for the statistical learning problem. We would like to consider the question of whether Mirror Descent is optimal for stochastic convex optimization, or equivalently convex statistical learning, setting [9, 19, 23] in general. Establishing such universality would have significant implications, as it would indicate that any (convex) problem that is learnable, is learnable using a one-pass first-order online method (i.e. a Stochastic Approximation approach)."}], "references": [{"title": "Optimal strategies and minimax lower bounds for online convex games", "author": ["J. Abernethy", "P.L. Bartlett", "A. Rakhlin", "A. Tewari"], "venue": "In Proceedings of the Nineteenth Annual Conference on Computational Learning Theory,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Sharp uniform convexity and smoothness inequalities for trace norms", "author": ["Keith Ball", "Eric A. Carlen", "Elliott H. Lieb"], "venue": "Invent. Math.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1994}, {"title": "Mirror descent and nonlinear projected subgradient methods for convex optimization", "author": ["A. Beck", "M. Teboulle"], "venue": "Operations Research Letters,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "The perceptron: A model for brain functioning", "author": ["H.D. Block"], "venue": "Reviews of Modern Physics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1962}, {"title": "Sparse and low-rank matrix decompositions", "author": ["V. Chandrasekaran", "S. Sanghavi", "P. Parrilo", "A. Willsky"], "venue": "In IFAC Symposium on System Identification,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Efficient projections onto the `1-ball for learning in high dimensions", "author": ["J. Duchi", "S. Shalev-Shwartz", "Y. Singer", "T. Chandra"], "venue": "In Proceedings of the 25th International Conference on Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "A Dirty Model for Multi-task Learning", "author": ["Ali Jalali", "Pradeep Ravikumar", "Sujay Sanghavi", "Chao Ruan"], "venue": "In NIPS,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Stochastic approximation approach to stochastic programming", "author": ["A. Juditsky", "G. Lan", "A. Nemirovski", "A. Shapiro"], "venue": "SIAM J. Optim,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "On the duality of strong convexity and strong smoothness: Learning applications and matrix regularization", "author": ["Sham M. Kakade", "Shai Shalev-shwartz", "Ambuj Tewari"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Exponentiated gradient versus gradient descent for linear predictors", "author": ["J. Kivinen", "M. Warmuth"], "venue": "Information and Computation,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "Sparse online learning via truncated gradient", "author": ["J. Langford", "L. Li", "T. Zhang"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm", "author": ["N. Littlestone"], "venue": "Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1988}, {"title": "On cesaro\u2019s convergence of the gradient descent method for finding saddle points of convex-concave functions", "author": ["A. Nemirovski", "D. Yudin"], "venue": "Doklady Akademii Nauk SSSR,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1978}, {"title": "Problem complexity and method efficiency in optimization", "author": ["A. Nemirovski", "D. Yudin"], "venue": "Nauka Publishers,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1978}, {"title": "Martingales with values in uniformly convex spaces. Israel", "author": ["G. Pisier"], "venue": "Journal of Mathematics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1975}, {"title": "Martingales in banach spaces (in connection with type and cotype)", "author": ["G. Pisier"], "venue": "Winter School/IHP Graduate Course,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Online learning: Random averages, combinatorial parameters, and learnability", "author": ["A. Rakhlin", "K. Sridharan", "A. Tewari"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Stochastic convex optimization", "author": ["S. Shalev-Shwartz", "O. Shamir", "N. Srebro", "K. Sridharan"], "venue": "In COLT,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Convex repeated games and fenchel duality", "author": ["S. Shalev-Shwartz", "Y. Singer"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": "Maximum-margin matrix factorization", "author": ["Nathan Srebro", "Jason D.M. Rennie", "Tommi S. Jaakola"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2005}, {"title": "Rank, trace-norm and max-norm", "author": ["Nathan Srebro", "Adi Shraibman"], "venue": "In Proceedings of the 18th Annual Conference on Learning Theory,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "Stochastic optimization for machine learning", "author": ["Nathan Srebro", "Ambuj Tewari"], "venue": "In ICML 2010, tutorial,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Convex games in Banach spaces", "author": ["K. Sridharan", "A. Tewari"], "venue": "In Proceedings of the 23nd Annual Conference on Learning Theory,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Randomized online pca algorithms with regret bounds that are logarithmic in the dimension", "author": ["Manfred K. Warmuth", "Dima Kuzmin"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2007}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["M. Zinkevich"], "venue": "In ICML,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2003}], "referenceMentions": [{"referenceID": 12, "context": "1 Introduction Mirror Descent is a first-order optimization procedure which generalizes the classic Gradient Descent procedure to non-Euclidean geometries by relying on a \u201cdistance generating function\u201d specific to the geometry (the squared `2norm in the case of standard Gradient Descent) [14, 4].", "startOffset": 289, "endOffset": 296}, {"referenceID": 2, "context": "1 Introduction Mirror Descent is a first-order optimization procedure which generalizes the classic Gradient Descent procedure to non-Euclidean geometries by relying on a \u201cdistance generating function\u201d specific to the geometry (the squared `2norm in the case of standard Gradient Descent) [14, 4].", "startOffset": 289, "endOffset": 296}, {"referenceID": 7, "context": "Mirror Descent is also applicable, and has been analyzed, in a stochastic optimization setting [9] and in an online setting, where it can ensure bounded online regret [20].", "startOffset": 95, "endOffset": 98}, {"referenceID": 18, "context": "Mirror Descent is also applicable, and has been analyzed, in a stochastic optimization setting [9] and in an online setting, where it can ensure bounded online regret [20].", "startOffset": 167, "endOffset": 171}, {"referenceID": 3, "context": "the Perceptron algorithm [5] and Online Gradient Descent [27]), or in the simplex (`1 geometry), using an entropic distance generating function (Winnow [13] and Multiplicative Weights / Online Exponentiated Gradient algorithm [11]).", "startOffset": 25, "endOffset": 28}, {"referenceID": 24, "context": "the Perceptron algorithm [5] and Online Gradient Descent [27]), or in the simplex (`1 geometry), using an entropic distance generating function (Winnow [13] and Multiplicative Weights / Online Exponentiated Gradient algorithm [11]).", "startOffset": 57, "endOffset": 61}, {"referenceID": 11, "context": "the Perceptron algorithm [5] and Online Gradient Descent [27]), or in the simplex (`1 geometry), using an entropic distance generating function (Winnow [13] and Multiplicative Weights / Online Exponentiated Gradient algorithm [11]).", "startOffset": 152, "endOffset": 156}, {"referenceID": 9, "context": "the Perceptron algorithm [5] and Online Gradient Descent [27]), or in the simplex (`1 geometry), using an entropic distance generating function (Winnow [13] and Multiplicative Weights / Online Exponentiated Gradient algorithm [11]).", "startOffset": 226, "endOffset": 230}, {"referenceID": 8, "context": "More recently, the Online Mirror Descent framework has been applied, with appropriate distance generating functions derived for a variety of new learning problems like multi-task learning and other matrix learning problems [10], online PCA [26] etc.", "startOffset": 223, "endOffset": 227}, {"referenceID": 23, "context": "More recently, the Online Mirror Descent framework has been applied, with appropriate distance generating functions derived for a variety of new learning problems like multi-task learning and other matrix learning problems [10], online PCA [26] etc.", "startOffset": 240, "endOffset": 244}, {"referenceID": 22, "context": "We then extend the notion of a martingale type of a Banach space to be sensitive to both the constraint set and the data domain, and building on results of [24], we relate the value of the online learning repeated game to this generalized notion of martingale type (Section 4).", "startOffset": 156, "endOffset": 160}, {"referenceID": 14, "context": "Finally, again building on and generalizing the work of [16], we show how having appropriate martingale type guarantees the existence of a good uniformly convex function (Section 5), that in turn establishes the desired nearly-optimal guarantee on Online Mirror Descent (Section 6).", "startOffset": 56, "endOffset": 60}, {"referenceID": 22, "context": "We mainly build on the analysis of [24], who related the value of the online game to the notion of martingale type of a Banach space and uniform convexity when the constraint set and data domain are dual to each other.", "startOffset": 35, "endOffset": 39}, {"referenceID": 13, "context": "Mirror Descent was initially introduced as a first order deterministic optimization procedure, with an `p constraint and a matching `q Lipschitz assumption (1 \u2264 p \u2264 2, 1/q + 1/p = 1), was shown to be optimal in terms of the number of exact gradient evaluations [15].", "startOffset": 261, "endOffset": 265}, {"referenceID": 22, "context": "Sridharan and Tewri [24] generalized the optimality of online Mirror Descent (w.", "startOffset": 20, "endOffset": 24}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "The second equality is shown in [18].", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "Further, for any p \u2208 [1, 2] we us also define : Vp := inf { V \u2223\u2223\u2223 \u2200n \u2208 N,Vn(W,X ) \u2264 V n\u2212(1\u2212 1 p )} (3) Most prior work on online learning and optimization considers the case whenW is the unit ball of some Banach space, and X is the unit ball of the dual space, i.", "startOffset": 21, "endOffset": 27}, {"referenceID": 0, "context": "\u2016 \u00b7 \u2016 inW \u2282 B: \u2200w,w\u2032\u2208W\u2200\u03b1\u2208[0,1] \u03a8 (\u03b1w + (1\u2212 \u03b1)w\u2032) \u2264 \u03b1\u03a8(w) + (1\u2212 \u03b1)\u03a8(w\u2032)\u2212 \u03b1(1\u2212\u03b1) q \u2016w \u2212w \u2032\u2016 It is important to emphasize that in the definition above, the norm \u2016.", "startOffset": 25, "endOffset": 30}, {"referenceID": 0, "context": "Similarly to the value of the game, for any p \u2208 [1, 2], we define:", "startOffset": 48, "endOffset": 54}, {"referenceID": 22, "context": "4 Martingale Type and Value In [24], it was shown that the concept of the Martingale type (also sometimes called the Haar type) of a Banach space and optimal rates for online convex optimization problem, where X andW are duals of each other, are closely related.", "startOffset": 31, "endOffset": 35}, {"referenceID": 14, "context": "In this section we extend the classic notion of Martingale type of a Banach space (see for instance [16]) to one that accounts for the pair (W,X ).", "startOffset": 100, "endOffset": 104}, {"referenceID": 14, "context": "We point the reader to [16, 17] for more details.", "startOffset": 23, "endOffset": 31}, {"referenceID": 15, "context": "We point the reader to [16, 17] for more details.", "startOffset": 23, "endOffset": 31}, {"referenceID": 0, "context": "Further, for any p \u2208 [1, 2] we also define,", "startOffset": 21, "endOffset": 27}, {"referenceID": 22, "context": "The results of [24, 18] showing that a Martingale type implies low regret, actually apply also for \u201cnon-matching\u201d W and X and, in our notation, imply that Vp \u2264 2Cp.", "startOffset": 15, "endOffset": 23}, {"referenceID": 16, "context": "The results of [24, 18] showing that a Martingale type implies low regret, actually apply also for \u201cnon-matching\u201d W and X and, in our notation, imply that Vp \u2264 2Cp.", "startOffset": 15, "endOffset": 23}, {"referenceID": 22, "context": "Specifically we have the following theorem from [24, 18] : Theorem 4.", "startOffset": 48, "endOffset": 56}, {"referenceID": 16, "context": "Specifically we have the following theorem from [24, 18] : Theorem 4.", "startOffset": 48, "endOffset": 56}, {"referenceID": 22, "context": "[24, 18] For anyW \u2208 B and any X \u2208 B and any n \u2265 1,", "startOffset": 0, "endOffset": 8}, {"referenceID": 16, "context": "[24, 18] For anyW \u2208 B and any X \u2208 B and any n \u2265 1,", "startOffset": 0, "endOffset": 8}, {"referenceID": 14, "context": "We then extend the result of Pisier in [16] to the \u201cnon-matching\u201d setting combining it with the above theorem to finally get : Lemma 5.", "startOffset": 39, "endOffset": 43}, {"referenceID": 0, "context": "For any p \u2208 [1, 2] and any p\u2032 < p : Cp\u2032 \u2264 1104 Vp (p\u2212p\u2032)2", "startOffset": 12, "endOffset": 18}, {"referenceID": 14, "context": "In [16], it was shown that a Banach space has Martingale type p (the classical notion) if and only if uniformly convex functions with certain properties exist on that space (w.", "startOffset": 3, "endOffset": 7}, {"referenceID": 0, "context": "For any p \u2208 [1, 2], Dp \u2264 Cp.", "startOffset": 12, "endOffset": 18}, {"referenceID": 15, "context": "First we note that though the function \u03a8q in the construction (9) need not be such that (q\u03a8q(w)) is a norm, with a simple modification as noted in [17] we can make it a norm.", "startOffset": 147, "endOffset": 151}, {"referenceID": 14, "context": "p\u2032 < p, Cp\u2032 \u2264 Vp \u2264 MDp \u2264 Dp \u2264 Cp Lemma 5 (extending Pisier\u2019s result [16]) Definition of Vp (Generalized MD guarantee) Lemma 2 Construction of \u03a8, Lemma 11 (extending Pisier\u2019s result [16])", "startOffset": 68, "endOffset": 72}, {"referenceID": 14, "context": "p\u2032 < p, Cp\u2032 \u2264 Vp \u2264 MDp \u2264 Dp \u2264 Cp Lemma 5 (extending Pisier\u2019s result [16]) Definition of Vp (Generalized MD guarantee) Lemma 2 Construction of \u03a8, Lemma 11 (extending Pisier\u2019s result [16])", "startOffset": 181, "endOffset": 185}, {"referenceID": 1, "context": "Ball et al [3] tightly calculate the constants of strong convexity of squared `p norms, establishing the tightness of D2 when p1 = p2.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "These results again follow using similar arguments as `p case and tight constants for strong convexity parameters of the Schatten norm from [3].", "startOffset": 140, "endOffset": 143}, {"referenceID": 19, "context": "Max Norm Max-norm has been proposed as a convex matrix regularizer for application such as matrix completion [21].", "startOffset": 109, "endOffset": 113}, {"referenceID": 20, "context": "As noted in [22] the max-norm ball is equivalent, up to a factor two, to the convex hull of all rank one sign matrices.", "startOffset": 12, "endOffset": 16}, {"referenceID": 20, "context": "This matches the stochastic (PAC) learning guarantee [22], and is the first guarantee we are aware of for the max norm matrix completion problem in the online setting.", "startOffset": 53, "endOffset": 57}, {"referenceID": 4, "context": "al [6] (here one can use the interpolation norm of second type to interpolate between trace norm and element wise `1 norm).", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "al [8].", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "Similarly for the [8] case X could be either matrices with bounded entries or some other natural assumption that suits the problem.", "startOffset": 18, "endOffset": 21}, {"referenceID": 10, "context": "Furthermore, we might also find other properties of w desirable, such as sparsity, which would bias us toward alternative methods [12, 7].", "startOffset": 130, "endOffset": 137}, {"referenceID": 5, "context": "Furthermore, we might also find other properties of w desirable, such as sparsity, which would bias us toward alternative methods [12, 7].", "startOffset": 130, "endOffset": 137}, {"referenceID": 16, "context": "Furthermore, we know that in terms of worst-case behavior, both in the stochastic and in the online setting, for convex cost functions, the value is unchained when the convex hull of a non-convex constraint set [18].", "startOffset": 211, "endOffset": 215}, {"referenceID": 0, "context": "In the total variation regularization problem, W is the set of all functions on the interval [0, 1] with total variation bounded by 1 which is in fact a Banach space.", "startOffset": 93, "endOffset": 99}, {"referenceID": 0, "context": "It only consists of evaluations of the functions inW at points on interval [0, 1] and one can consider a supervised learning problem where the goal is to use the set of all functions with bounded variations to predict targets which take on values in [\u22121, 1] .", "startOffset": 75, "endOffset": 81}, {"referenceID": 7, "context": "We would like to consider the question of whether Mirror Descent is optimal for stochastic convex optimization, or equivalently convex statistical learning, setting [9, 19, 23] in general.", "startOffset": 165, "endOffset": 176}, {"referenceID": 17, "context": "We would like to consider the question of whether Mirror Descent is optimal for stochastic convex optimization, or equivalently convex statistical learning, setting [9, 19, 23] in general.", "startOffset": 165, "endOffset": 176}, {"referenceID": 21, "context": "We would like to consider the question of whether Mirror Descent is optimal for stochastic convex optimization, or equivalently convex statistical learning, setting [9, 19, 23] in general.", "startOffset": 165, "endOffset": 176}, {"referenceID": 0, "context": "References [1] J.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[3] Keith Ball, Eric A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[5] H.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[6] V.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[8] Ali Jalali, Pradeep Ravikumar, Sujay Sanghavi, and Chao Ruan.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[10] Sham M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[11] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[13] N.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[14] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[20] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[21] Nathan Srebro, Jason D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[22] Nathan Srebro and Adi Shraibman.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[23] Nathan Srebro and Ambuj Tewari.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[24] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[26] Manfred K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[27] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "They use similar techniques as in [16].", "startOffset": 34, "endOffset": 38}, {"referenceID": 15, "context": "We restate below a proposition from Pisier\u2019s note (in [17]) Proposition 16 (Proposition 8.", "startOffset": 54, "endOffset": 58}, {"referenceID": 15, "context": "53 of [17]).", "startOffset": 6, "endOffset": 10}], "year": 2011, "abstractText": "We show that for a general class of convex online learning problems, Mirror Descent can always achieve a (nearly) optimal regret guarantee.", "creator": "LaTeX with hyperref package"}}}