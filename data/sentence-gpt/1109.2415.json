{"id": "1109.2415", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2011", "title": "Convergence Rates of Inexact Proximal-Gradient Methods for Convex Optimization", "abstract": "We consider the problem of optimizing the sum of a smooth convex function and a non-smooth convex function using proximal-gradient methods, where an error is present in the calculation of the gradient of the smooth term or in the proximity operator with respect to the non-smooth term. We show that both the basic proximal-gradient method and the accelerated proximal-gradient method achieve the same convergence rate as in the error-free case, provided that the errors decrease at appropriate rates.Using these rates, we perform as well as or better than a carefully chosen fixed error level on a set of structured sparsity problems, providing that the solutions of the two types of problems are more accurately represented than they are on the first problem.", "histories": [["v1", "Mon, 12 Sep 2011 09:45:02 GMT  (134kb,D)", "http://arxiv.org/abs/1109.2415v1", null], ["v2", "Thu, 1 Dec 2011 16:06:06 GMT  (120kb,D)", "http://arxiv.org/abs/1109.2415v2", "Neural Information Processing Systems (2011)"]], "reviews": [], "SUBJECTS": "cs.LG math.OC", "authors": ["mark w schmidt", "nicolas le roux", "francis r bach"], "accepted": true, "id": "1109.2415"}, "pdf": {"name": "1109.2415.pdf", "metadata": {"source": "CRF", "title": "Convergence Rates of Inexact Proximal-Gradient Methods for Convex Optimization", "authors": ["Mark Schmidt", "Nicolas Le Roux"], "emails": ["mark.schmidt@inria.fr", "nicolas@le-roux.name", "francis.bach@ens.fr"], "sections": [{"heading": "1 Introduction", "text": "In recent years the importance of taking advantage of the structure of convex optimization problems has become a topic of intense research in the machine learning community. This is particularly true of techniques for non-smooth optimization, where taking advantage of the structure of non-smooth terms seems to be crucial to obtaining good performance. Proximal-gradient methods and accelerated proximal-gradient methods [1, 2] are among the most important methods for taking advantage of the structure of many of the nonsmooth optimization problems that arise in practice. In particular, these methods address composite optimization problems of the form\nminimize x\u2208Rd f(x) := g(x) + h(x), (1)\nwhere g and h are convex functions but only g is smooth. One of the most well-studied instances of this type of problem is `1-regularized least squares [3, 4],\nminimize x\u2208Rd\n\u2016Ax\u2212 b\u20162 + \u03bb\u2016x\u20161,\nar X\niv :1\n10 9.\n24 15\nv1 [\ncs .L\nG ]\nwhere we use \u2016 \u00b7 \u2016 to denote the standard `2 norm.\nProximal-gradient methods are an appealing approach for solving these types of non-smooth optimization problems because of their fast theoretical convergence rates and strong practical performance. While classical subgradient methods only achieve an error level on the objective function of O(1/ \u221a k) after k iterations, proximal-gradient methods have an error of O(1/k) while accelerated proximal-gradient methods futher reduce this to O(1/k2) [1, 2]. That is, accelerated proximal-gradient methods for non-smooth convex optimization achieve the same optimal convergence rate that accelerated gradient methods achieve for smooth optimization.\nEach iteration of a proximal-gradient method requires the calculation of the proximity operator,\nproxL(y) = arg min x\u2208Rd\nL 2 \u2016x\u2212 y\u20162 + h(x), (2)\nwhere L is the Lipschitz constant of the gradient of g. We can efficiently compute an analytic solution to this problem for several notable choices of h, including the case of `1-regularization and disjoint group `1-regularization [5, 6]. However, in many scenarios the proximity operator may not have an analytic solution, or it may be very expensive to compute this solution exactly. This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12]. Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].\nIt is known that proximal-gradient methods that use an approximate proximity operator converge under only weak assumptions [16, 17]; we briefly review this and other related work in the next section. However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods. In this work we show in several contexts that, provided the error in the proximity operator calculation is controlled in an appropriate way, inexact proximal-gradient strategies achieve the same convergence rates as the corresponding exact methods. In particular, we first consider convex objectives and analyze the inexact proximal-gradient (Section 4.1) and accelerated proximal-gradient methods (Section 4.2). We then analyze these two algorithms for strongly convex objectives (Sections 4.3 and 4.4). Note that in these analyses, we also consider the possibility that there is an error in the calculation of the gradient of g. We\nthen present an experimental comparison of various inexact proximal-gradient strategies in the context of solving a structured sparsity problem (Section 5)."}, {"heading": "2 Related Work", "text": "The algorithm we shall focus on in this paper is the proximal-gradient method\nxk = proxL(yk\u22121 \u2212 (1/L)(g\u2032(yk\u22121) + ek)) , (3)\nwhere ek is the error in the calculation of the gradient and the proximity problem (2) is solved inexactly so that xk has an error of \u03b5k in terms of the proximal objective function (2). In the basic proximal-gradient method we choose yk = xk, while in the accelerated proximalgradient method we choose\nyk = xk + \u03b2k(xk \u2212 xk\u22121),\nwhere the sequence {\u03b2k} is chosen in order yield an improved convergence rate.\nThere is a substantial amount of work on methods that use an exact proximity operator but have an error in the gradient calculation, corresponding to the special case where \u03b5k = 0 but ek is non-zero. For example, when the ek are independent, zero-mean, and finitevariance random variables then proximal-gradient methods achieve the (optimal) error level of O(1/ \u221a k) [18, 19]. This is different than the scenario we analyze in this paper, since we do not assume that the errors are unbiased and independent, but instead consider a sequence of errors converging to 0. This leads to faster convergence rates, and makes our analysis applicable to the case of deterministic (and even adversarial) errors.\nSeveral authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level. This contrasts with our analysis, where by allowing the error to change on every iteration we can achieve convergence to the optimal solution. Also, we can tolerate a large error in early iterations when we are far from the solution, which may lead to substantial computational gains. Other authors have analyzed the convergence rate of the gradient and projected-gradient methods with a decreasing sequence of errors [24, 25], but this analysis does not consider the important class of accelerated gradient methods. In contrast, the analysis of [22] allows a decreasing sequence of errors without assuming strong convexity (though convergence rates in this context are not explicitly mentioned) and considers the accelerated projectedgradient method. However, the authors of this work only consider the case of an exact projection step, and they assume the availability of an oracle that yields global lower and upper bounds on the function. This non-intuitive oracle leads to a novel analysis of smoothing methods, but leads to slower convergence rates than proximal-gradient methods. The analysis of [21] considers errors in both the gradient and projection operators for accelerated projected-gradient methods, but this analysis requires that the domain of the function is compact. None of these works consider proximal-gradient methods.\nIn the context of proximal-point algorithms, there is a substantial literature on using inexact proximity operators with a decreasing sequence of errors, dating back to the seminal work of Rockafeller [26]. Accelerated proximal-point methods with a decreasing sequence of errors have also been examined, beginning with [27]. However, unlike proximal-gradient methods where the proximity operator is computed with respect to the non-smooth function h, proximal-point methods require the calculation of the proximity operator with respect to the full objective function. In the context of composite optimization problems of the form (1), this requires the calculation of the proximity operator with respect to g+h. Since it ignores the structure of the problem, this proximity operator will typically be as difficult to compute (even approximately) as the minimizer of the original problem.\nConvergence of inexact proximal-gradient methods can be established with only weak assumptions on the method used to approximately solve (2). For example, we can establish that inexact proximal-gradient methods converge under some minor closedness assumptions on the mapping induced by the approximate proximity operator, and the assumption that the algorithm used to compute the inexact proximity operator achieves sufficient descent on problem (2) compared to the previous iteration xk\u22121 [16]. Convergence of inexact proximalgradient methods can also be established under the assumption that the norms of the errors are summable [17]. However, these prior works did not consider the rate of convergence of inexact proximal-gradient methods, nor did they consider accelerated proximal-gradient methods. Indeed, as pointed out by [7], even convergence of the accelerated proximalgradient method has not been established under an inexact proximity operator. This gap in the theory is one of the reasons why the authors of [7] chose to use the non-accelerated variant of the proximal-gradient algorithm."}, {"heading": "3 Notation and Assumptions", "text": "In this work we shall assume that the smooth function g in (1) is convex and differentiable, and we will assume that its gradient g\u2032 is Lipschitz-continuous with constant L, meaning that for all x and y in Rd we have\n\u2016g\u2032(x)\u2212 g\u2032(y)\u2016 6 L\u2016x\u2212 y\u2016 .\nThis is a standard assumption in differentiable optimization, see [28, \u00a72.1.1]. If g is twicedifferentiable, this corresponds to the assumption that the eigenvalues of its Hessian are bounded above by L. For the proofs in Sections 4.3 and 4.4, we will also assume that g is \u00b5-strongly convex (see [28, \u00a72.1.3]), meaning that for all x and y in Rd we have\ng(y) > g(x) + \u3008g\u2032(x), y \u2212 x\u3009+ \u00b5 2 ||y \u2212 x||2.\nHowever, apart from the Sections 4.3 and 4.4, we only assume that this holds with \u00b5 = 0, which is equivalent to convexity of g.\nIn contrast to these assumptions on g, we will only assume that h in (1) is a lower semicontinuous proper convex function (see [29, \u00a71.2]), but will not assume that h is differentiable or Lipschitz-continuous. This allows h to be any real-valued convex function, but also allows\nfor the possibility that h is an extended real-valued convex function. For example, h could be the indicator function of a convex set, and in this case the proximity operator becomes the projection operator.\nWe will use xk to denote the parameter vector at iteration k, and x \u2217 to denote a minimizer of f . We assume that such an x\u2217 exists, but do not assume that it is unique. We use ek to denote the error in the calculation of the gradient at iteration k, and we use \u03b5k to denote the error in the proximal objective function achieved by xk, meaning that\nL 2 \u2016xk \u2212 y\u20162 + h(xk) 6 \u03b5k + min x\u2208Rd\n{ L\n2 \u2016x\u2212 y\u20162 + h(x)\n} . (4)\nwhere y = yk\u22121 \u2212 (1/L)(g\u2032(yk\u22121) + ek)). In practice, our framework requires such a bound on the optimality of the approximate proximity operator. However, note that the proximal optimization problem (2) is strongly convex and in practice we are often able to obtain such bounds via a duality gap (e.g., see [12] for the case of overlapping group `1-regularization)."}, {"heading": "4 Convergence Rates of Inexact Proximal-Gradient Methods", "text": "In this section we present the analysis of the convergence rates of inexact proximal-gradient methods as a function of the sequences of solution accuracies to the proximal problems {\u03b5k}, and the sequences of magnitudes of the errors in the gradient calculations {\u2016ek\u2016}."}, {"heading": "4.1 Basic proximal-gradient method with errors in the convex case", "text": "We first consider the basic proximal-gradient method in the convex case:\nProposition 1 (Basic proximal-gradient method with errors - Convexity) Assume that\n\u2022 g is convex and has L-Lipschitz-continuous gradient;\n\u2022 h is a lower semi-continuous proper convex function;\n\u2022 The function f = g + h attains its minimum at a certain x\u2217 \u2208 Rn;\n\u2022 We iterate recursion (3) with yk = xk;\n\u2022 xk is an \u03b5k-optimal solution to the proximal problem (2) in the sense of (4).\nThen, for all k > 1, we have\nf\n( 1\nk k\u2211 i=1 xi\n) \u2212 f(x\u2217) 6 L\n2k\n( \u2016x0 \u2212 x\u2217\u2016+ 2Ak + \u221a 2Bk )2 , (5)\nwith\nAk = k\u2211 i=1 ( \u2016ei\u2016 L + \u221a 2\u03b5i L ) , Bk = k\u2211 i=1 \u03b5i L .\nThe proof is given in the Appendix. Note that while we have stated the proposition in terms of the function value achieved by the average of the iterates, it trivially also holds for the iteration that achieves the lowest function value. Note, however, that the convergence of the iterates themselves is not possible in general since there may be multiple minima.\nThis result implies that the well-known O(1/k) convergence rate for the gradient method without errors still holds when both {\u2016ek\u2016} and { \u221a \u03b5k} are summable. A sufficient condition to achieve this is that \u2016ek\u2016 decreases as O(1/k1+\u03b4) while \u03b5k decreases as O(1/k2+\u03b4 \u2032 ) for any \u03b4, \u03b4\u2032 > 0. Note that a faster convergence of these two errors will not improve the convergence rate, but will yield a better constant factor. It is interesting to consider what happens if {\u2016ek\u2016} or { \u221a \u03b5k} is not summable. For instance, if \u2016ek\u2016 and \u221a \u03b5k decrease as O(1/k), then Ak grows as O(log k) (note that Bk is always\nsmaller than Ak) and the convergence of the function values is in O ( log2 k k ) . Finally, a necessary condition to obtain convergence is that the partial sums Ak and Bk need to be in o( \u221a k)."}, {"heading": "4.2 Accelerated proximal-gradient method with errors in the convex case", "text": "We now turn to the case of accelerated proximal-gradient methods in the convex case. We focus on a basic variant of the algorithm where \u03b2k is set to (k \u2212 1)/(k + 2) [30]:\nProposition 2 (Accelerated proximal-gradient method with errors) Assume that\n\u2022 g is convex and has L-Lipschitz-continuous gradient;\n\u2022 h is a lower semi-continuous proper convex function;\n\u2022 The function f = g + h attains its minimum at a certain x\u2217 \u2208 Rn;\n\u2022 We iterate recursion (3) with yk = xk + k\u22121k+2(xk \u2212 xk\u22121);\n\u2022 xk is an \u03b5k-optimal solution to the proximal problem (2) in the sense of (4).\nThen, for all k > 1, we have\nf(xk)\u2212 f(x\u2217) 6 2L\n(k + 1)2\n( \u2016x0 \u2212 x\u2217\u2016+ 2A\u0303k + \u221a 2B\u0303k )2 , (6)\nwith\nA\u0303k = k\u2211 i=1 i ( \u2016ei\u2016 L + \u221a 2\u03b5i L ) , B\u0303k = k\u2211 i=1 i2\u03b5i L .\nIn this case, we require the series {k\u2016ek\u2016} and {k \u221a \u03b5k} to be summable to achieve the optimal O(1/k2) rate, which is an (unsurprisingly) stronger constraint than in the basic case. A sufficient condition is for \u2016ek\u2016 and \u221a \u03b5k to decrease as O(1/k\n2+\u03b4) for any \u03b4 > 0. Note that, as opposed to Proposition 1 that is stated for the average iterate, this bound is for the last iterate xk.\nOnce again, it is interesting to see what happens when the summability assumption is not met. First, if \u2016ek\u2016 or \u221a \u03b5k decreases at a rate of O(1/k 2), then k(\u2016ek\u2016 + \u221a ek) decreases as O(1/k) and A\u0303k grows as O(log k) (note that B\u0303k is always smaller than A\u0303k), yielding\na convergence rate of O ( log2 k k2 ) for f(xk) \u2212 f(x\u2217). Also, and perhaps more interestingly, if \u2016ek\u2016 or \u221a \u03b5k decreases at a rate of O(1/k), Eq. (6) does not guarantee convergence of the function values. More generally, the form of A\u0303k and B\u0303k indicates that errors have a greater effect on the accelerated method than they do on the basic method. Hence, as also discussed in [22], unlike in the error-free case the accelerated method may not necessarily be better than the basic method because it is more sensitive to errors in the computation."}, {"heading": "4.3 Basic proximal-gradient method with errors in the strongly convex case", "text": "In the case where g is strongly convex it is possible to obtain linear convergence rates that depend on the ratio\n\u03b3 = \u00b5\nL ,\nas opposed to the sublinear convergence rates discussed above. In particular, we obtain the following convergence rate on the iterates of the basic proximal-gradient method for strongly convex objectives:\nProposition 3 (Basic proximal-gradient method with errors - Strong convexity) Assume that\n\u2022 g is \u00b5-strongly convex and has L-Lipschitz-continuous gradient;\n\u2022 h is a lower semi-continuous proper convex function;\n\u2022 The function f = g + h attains its minimum at a certain x\u2217 \u2208 Rn;\n\u2022 We iterate recursion (3) with yk = xk;\n\u2022 xk is an \u03b5k-optimal solution to the proximal problem (2) in the sense of (4).\nThen, for all k > 1, we have:\n\u2016xk \u2212 x\u2217\u2016 6 (1\u2212 \u03b3)k (\u2016x0 \u2212 x\u2217\u2016+ A\u0304k) , (7)\nwith\nA\u0304k = k\u2211 i=1 (1\u2212 \u03b3)\u2212i ( \u2016ei\u2016 L + \u221a 2\u03b5i L ) .\nA consequence of this proposition is that we obtain a linear rate of convergence even in the presence of errors, provided that \u2016ek\u2016 and \u221a \u03b5k decrease linearly to 0. If they do so at a rate of Q\u2032 < (1\u2212 \u03b3), then the convergence rate of \u2016xk \u2212x\u2217\u2016 is linear with constant (1\u2212 \u03b3), as in the error-free algorithm. If we have Q\u2032 > (1\u2212 \u03b3), then the convergence of \u2016xk \u2212 x\u2217\u2016 will be linear with constant Q\u2032. If we have Q\u2032 = (1\u2212 \u03b3), then \u2016xk \u2212 x\u2217\u2016 converges to 0 as O(k (1\u2212 \u03b3)k) = o ( [(1\u2212 \u03b3) + \u03b4\u2032]k ) for all \u03b4\u2032 > 0."}, {"heading": "4.4 Accelerated proximal-gradient method with errors in the strongly convex case", "text": "Finally, we consider the accelerated proximal-gradient algorithm when g is strongly convex. We focus on a basic variant of the algorithm where \u03b2k is set to (1 \u2212 \u221a \u03b3)/(1 + \u221a \u03b3) [28, \u00a72.2.1]:\nProposition 4 (Accelerated proximal-gradient method with errors - Strong convexity) Assume that\n\u2022 g is \u00b5-strongly convex and has L-Lipschitz-continuous gradient;\n\u2022 h is a lower semi-continuous proper convex function;\n\u2022 The function f = g + h attains its minimum at a certain x\u2217 \u2208 Rn; \u2022 We iterate recursion (3) with yk = xk + 1\u2212\u221a\u03b3 1+ \u221a \u03b3 (xk \u2212 xk\u22121);\n\u2022 xk is an \u03b5k-optimal solution to the proximal problem (2) in the sense of (4).\nThen, for all k > 1, we have\nf(xk)\u2212 f(x\u2217) 6 (1\u2212 \u221a \u03b3)k (\u221a 2(f(x0)\u2212 f(x\u2217)) +Ak \u221a 2 \u00b5 + \u221a Bk )2 , (8)\nwith\nAk = k\u2211 i=1 ( \u2016ei\u2016+ \u221a 2L\u03b5i ) (1\u2212\u221a\u03b3)\u2212i/2 ,\nBk = k\u2211 i=1 \u03b5i (1\u2212 \u221a \u03b3)\u2212i .\nThis proposition implies that we obtain a linear rate of convergence in the presence of errors provided that ||ek||2 and \u03b5k decrease linearly to 0. If they do so at a rate Q\u2032 < (1 \u2212 \u221a \u03b3), then the constant is (1\u2212\u221a\u03b3), while if Q\u2032 > (1\u2212\u221a\u03b3) then the constant will be Q\u2032. Thus, the accelerated inexact proximal-gradient method will have a faster convergence rate than the exact basic proximal-gradient method provided that Q\u2032 < (1\u2212 \u03b3).\nOddly, in our analysis of the strongly convex case, the accelerated method is less sensitive to errors than the basic method. However, unlike the basic method, the accelerated method requires knowing \u00b5 in addition to L. If \u00b5 is misspecified, then the convergence rate of the accelerated method may be slower than the basic method."}, {"heading": "5 Experiments", "text": "We tested the basic inexact proximal-gradient and accelerated proximal-gradient methods on the CUR-like factorization optimization problem introduced in [31] to approximate a\ngiven matrix W ,\nmin X\n1 2\u2016W \u2212WXW\u2016 2 F + \u03bbrow nr\u2211 i=1 ||Xi||p + \u03bbcol nc\u2211 j=1 ||Xj ||p .\nUnder an appropriate choice of p, this optimization problem yields a matrix X with sparse rows and sparse columns, meaning that entire rows and columns of the matrix X are set to exactly zero. In [31], the authors used an accelerated proximal-gradient method and chose p = \u221e since under this choice the proximity operator can be computed exactly. However, this has the undesirable effect that it also encourages all values in the same row (or column) to have the same magnitude. The more natural choice of p = 2 was not explored since in this case there is no known algorithm to exactly compute the proximity operator.\nOur experiments focused on the case of p = 2. In this case, it is possible to very quickly compute an approximate proximity operator using the block coordinate descent (BCD) algorithm presented in [12], which is equivalent to the proximal variant of Dykstra\u2019s algorithm introduced by [32]. In our implementation of the BCD method, we alternate between computing the proximity operator with respect to the rows and to the columns. Since the BCD method allows us to compute a duality gap when solving the proximal problem, we can run the method until the duality gap is below a given error threshold \u03b5k to find an xk+1 satisfying (4).\nIn our experiments, we used the four data sets examined by [31]1 and we choose \u03bbrow = .01 and \u03bbcol = .01, which yielded approximately 25\u201340% non-zero entries in X (depending on the data set). Rather than assuming we are given the Lipschitz constant L, on the first iteration we set L to 1 and we double our estimate of L anytime f(xk+1) > f(yk). This rudimentary linesearch will always terminate for sufficiently large L because of the Lipschitz-continuity of g, provided that the BCD method returns a solution with error \u03b5k lower than the error obtained at yk. We tested three different ways to terminate the approximate proximal problem, each parameterized by a parameter \u03b1:\n\u2022 \u03b5k = 1/k\u03b1: Running the BCD algorithm until the duality gap is below 1/k\u03b1.\n\u2022 \u03b5k = \u03b1: Running the BCD algorithm until the duality gap is below \u03b1.\n\u2022 n = \u03b1: Running the BCD algorithm for a fixed number of iterations \u03b1.\nNote that all three strategies lead to global convergence in the case of the basic proximalgradient method, the first two give a convergence rate up to some fixed optimality tolerance, and in this paper we have shown that the first one (for large enough \u03b1) yields a convergence rate for an arbitrary optimality tolerance. Note that the iterates produced by the BCD iterations are sparse, so we expected the algorithms to spend the majority of their time solving the proximity problem. Thus, we used the function value against the number of BCD iterations as a measure of performance. We plot the results after 500 BCD iterations for the proximal-gradient method in Figure 1, and the accelerated proximal-gradient method\n1The datasets are freely available at http://www.gems-system.org.\nin Figure 2. In these plots, the first column varies \u03b1 using the choice \u03b5k = 1/k \u03b1, the second column varies \u03b1 using the choice \u03b5k = \u03b1, and the third column varies \u03b1 using the choice n = \u03b1. We also include one of the best methods from the first column in the second and third columns as a reference.\nIn the context of proximal-gradient methods the choice of \u03b5k = 1/k 3, which is one choice that achieves the fastest convergence rate according to our analysis, gives the best performance across all four data sets. However, in these plots we also see that reasonable performance can be achieved by any of the three strategies above provided that \u03b1 is chosen carefully. For example, choosing n = 3 or choosing \u03b5k = 10\n\u22126 both give reasonable performance. However, these are only empirical observations for these data sets and they may be ineffective for other data sets or if we change the number of iterations, while we have given theoretical justification for the choice \u03b5k = 1/k 3.\nSimilar trends are observed for the case of accelerated proximal-gradient methods, though the choice of \u03b5k = 1/k\n3 (which no longer achieves the fastest convergence rate according to our analysis) no longer dominates the other methods in the accelerated setting. For two data sets the choice \u03b5k = 1/k\n4, which is a choice that achieves the fastest convergence rate up to a poly-logarithmic factor, yields better performance than \u03b5k = 1/k\n3. Interestingly, the only choice that yields the fastest possible convergence rate (\u03b5k = 1/k\n5), did not give the best performance on any data set. This seems to reflect the trade-off between performing inner BCD iterations to achieve a small duality gap and performing outer gradient iterations to decrease the value of f . Also, the constant terms which were not taken into account in the analysis do play an important role here, due to the relatively small number of outer iterations performed."}, {"heading": "6 Discussion", "text": "An alternative to inexact proximal methods for solving structured sparsity problems are smoothing methods [33] and alternating direction methods [34]. However, a major disadvantage of both these approaches is that the iterates are not sparse, so they can not take advantage of the sparsity of the problem when running the algorithm. In contrast, the method proposed in this paper has the appealing property that it tends to generate sparse iterates. Further, the accelerated smoothing method only has a convergence rate of O(1/k), and the performance of alternating direction methods is often sensitive to the exact choice of their penalty parameter. On the other hand, while our analysis suggests using a sequence of errors like O(1/k\u03b1) for \u03b1 large enough, the practical performance of inexact proximal-gradients methods will be sensitive to the exact choice of this sequence.\nAlthough we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization. This work provides a theoretical justification for using inexact proximal-gradient methods in these and other applications, and suggests some guidelines for practioners that do not want to lose the appealing convergence rates of these methods. Further, although our experiments and much of our discussion\nfocus on errors in the calculation of the proximity operator, our analysis also allows for an error in the calculation of the gradient. This may also be useful in a variety of contexts. For example, errors in the calculation of the gradien arise when fitting undirected graphical models and using an iterative method to approximate the gradient of the log-partition function [35]. Other examples include using a reduced set of training examples within kernel methods [36], or subsampling to solve semidefinite programming problems [37].\nIn our analysis we assume that L is known, and our experiments use a heuristic to estimate L. It would be interesting to extend methods for estimating L in the exact case [2] to the case of inexact algorithms. In the context of accelerated methods for strongly convex optimization, our analysis also assumes that \u00b5 is known, and it would be interesting to explore variants that do not make this assumption. Finally, we note that there has been recent interest in inexact proximal Newton-like methods [38], and it would be interesting to analyze the effect of errors on the convergence rates of these methods."}, {"heading": "Acknowledgements", "text": "Mark Schmidt, Nicolas Le Roux, and Francis Bach are supported in part by the European Research Council (SIERRA-ERC-239993)."}, {"heading": "Appendix: Proofs of the propositions", "text": "We first prove a lemma which will be used for the propositions.\nLemma 1 Assume that the nonnegative sequence uk satisfies the following recursion for all k > 1:\nu2k 6 Bk + k\u2211 i=1 \u03bbiui,\nwith {Bk} an increasing sequence, B0 > u20 and \u03bbi > 0 for all i. Then, for all k > 1, then\nuk 6 1\n2 k\u2211 i=1 \u03bbi +\nBk + ( 1\n2 k\u2211 i=1 \u03bbi\n)21/2\nProof We prove the result by induction. It is true for k = 0 (by assumption). We assume it is true for k \u2212 1, and we denote by vk\u22121 = max{u1, . . . , uk\u22121}. From the recursion, we thus get\n(uk \u2212 \u03bbk/2)2 6 Bk + \u03bb2k 4 + vk\u22121 k\u22121\u2211 i=1 \u03bbi\nleading to\nuk 6 \u03bbk 2 +\n( Bk +\n\u03bb2k 4 + vk\u22121 k\u22121\u2211 i=1 \u03bbi\n)1/2\nand thus\nvk 6 max { vk\u22121,\n\u03bbk 2 +\n( Bk +\n\u03bb2k 4 + vk\u22121 k\u22121\u2211 i=1 \u03bbi )1/2 } The two terms in the maximum are equal if v2k\u22121 = Bk + vk\u22121 \u2211k i=1 \u03bbi, i.e., for v \u2217 k\u22121 =\n1 2 \u2211k i=1 \u03bbi + ( Bk + ( 1 2 \u2211k i=1 \u03bbi )2)1/2 . If vk\u22121 6 v\u2217k\u22121, then vk 6 v \u2217 k\u22121 since the two terms in the max are increasing functions of vk\u22121. If vk\u22121 > v\u2217k\u22121, then vk\u22121 > \u03bbk 2 +(\nBk + \u03bb2k 4 + vk\u22121 \u2211k\u22121 i=1 \u03bbi )1/2 . Hence, vk 6 vk\u22121, and the induction hypotheses ensure that\nthe property is satisfied for k.\nThe following lemma will allow us to characterize the elements of the \u03b5k-subdifferential of h at xk, \u2202\u03b5kh(xk).\nLemma 2 If xi is an \u03b5i-optimal solution to the proximal problem (2) in the sense of (4), then there exists fi such that \u2016fi\u2016 6 \u221a 2\u03b5i L and\nL ( yi\u22121 \u2212 xi \u2212 1\nL (g\u2032(yi\u22121) + ei)\u2212 fi\n) \u2208 \u2202\u03b5ih(xi) .\nProof We first recall some properties of \u03b5-subdifferentials (see, e.g., [39, Section 4.3] for more details). By definition, x is an \u03b5-minimizer of a convex function a if and only if a(x) 6 infy\u2208Rn a(y) + \u03b5. This is equivalent to 0 belonging to the \u03b5-subdifferential \u2202\u03b5a(x). If a = a1 + a2, where both a1 and a2 are convex, we have \u2202\u03b5a(x) \u2282 \u2202\u03b5a1(x) + \u2202\u03b5a2(x).\nIf a1(x) = L 2 \u2016x\u2212 z\u2016 2, then\n\u2202\u03b5a1(x) =\n{ y \u2208 Rn \u2223\u2223\u2223\u2223 L2 \u2016x\u2212 z \u2212 yL\u20162 6 \u03b5 }\n= { y \u2208 Rn, y = Lx\u2212 Lz + Lf \u2223\u2223\u2223\u2223 L2 \u2016f\u20162 6 \u03b5 } .\nIf a2 = h and x is an \u03b5-minimizer of a1 + a2, then 0 belongs to \u2202\u03b5a(x). Since \u2202\u03b5a(x) \u2282 \u2202\u03b5a1(x) + \u2202\u03b5a2(x), we have that\nLz \u2212 Lx\u2212 Lf \u2208 \u2202\u03b5h(x) with \u2016f\u2016 6 \u221a 2\u03b5\nL .\nUsing z = yi\u22121 \u2212 (1/L)(g\u2032(yi\u22121) + ei and x = xi, this implies that there exists fi such that \u2016fi\u2016 6 \u221a 2\u03b5i L and\nL ( xi\u22121 \u2212 xi \u2212 1\nL (g\u2032(xi\u22121) + ei)\u2212 fi\n) \u2208 \u2202\u03b5ih(xi) ."}, {"heading": "6.1 Basic proximal-gradient method with errors in the convex case", "text": "We now give the proof of Proposition of 1.\nProof Since xk is an \u03b5k-optimal solution to the proximal problem (2) in the sense of (4), we can use Lemma 2 to yield that there exists fk such that \u2016fk\u2016 6 \u221a 2\u03b5k L and\nL ( xk\u22121 \u2212 xk \u2212 1\nL (g\u2032(xk\u22121) + ek)\u2212 fk\n) \u2208 \u2202\u03b5ih(xk) .\nWe now bound g(xi) and h(xi) as follows:\ng(xi) 6 g(xi\u22121) + \u2329 g\u2032(xi\u22121), xi \u2212 xi\u22121 \u232a + L\n2 \u2016xi \u2212 xi\u22121\u20162\nusing L-Lipschitz gradient and the convexity of g, 6 g(x\u2217) + \u2329 g\u2032(xi\u22121), xi\u22121 \u2212 x\u2217 \u232a + \u2329 g\u2032(xi\u22121), xi \u2212 xi\u22121 \u232a + L\n2 \u2016xi \u2212 xi\u22121\u20162\nusing convexity of g.\nUsing the \u03b5i-subgradient, we have\nh(xi) 6 h(x \u2217)\u2212 \u2329 g\u2032(xi\u22121) + ei + L(xi + fi \u2212 xi\u22121), xi \u2212 x\u2217 \u232a + \u03b5i .\nAdding the two together, we get:\nf(xi) = g(xi) + h(xi)\n= f(x\u2217) + L\n2 \u2016xi \u2212 xi\u22121\u20162 \u2212 L \u3008xi \u2212 xi\u22121, xi \u2212 x\u2217\u3009+ \u03b5i \u2212 \u3008ei + Lfi, xi \u2212 x\u2217\u3009\n= f(x\u2217) + L\n2 \u3008xi \u2212 xi\u22121, xi \u2212 xi\u22121 \u2212 2xi + 2x\u2217\u3009+ \u03b5i \u2212 \u3008ei + Lfi, xi \u2212 x\u2217\u3009\n= f(x\u2217) + L\n2 \u3008xi \u2212 x\u2217 \u2212 (xi\u22121 \u2212 x\u2217), (x\u2217 \u2212 xi) + (x\u2217 \u2212 xi\u22121)\u3009+ \u03b5i \u2212 \u3008ei + Lfi, xi \u2212 x\u2217\u3009\n= f(x\u2217)\u2212 L 2 \u2016xi \u2212 x\u2217\u20162 + L 2 \u2016xi\u22121 \u2212 x\u2217\u20162 + \u03b5i \u2212 \u3008ei + Lfi, xi \u2212 x\u2217\u3009\nf(xi) 6 f(x \u2217)\u2212 L 2 \u2016xi \u2212 x\u2217\u20162 + L 2 \u2016xi\u22121 \u2212 x\u2217\u20162 + \u03b5i + (\u2016ei\u2016+\n\u221a 2L\u03b5i) \u00b7 \u2016xi \u2212 x\u2217\u2016\nusing Cauchy-Schwartz and \u2016fi\u2016 6 \u221a 2\u03b5i L .\nMoving f(x\u2217) on the other side and summing from i = 1 to k, we get: k\u2211 i=1 [f(xi)\u2212f(x\u2217)] 6 \u2212 L 2 \u2016xk\u2212x\u2217\u20162+ L 2 \u2016x0\u2212x\u2217\u20162+ k\u2211 i=1 \u03b5i+ k\u2211 i=1 [ (\u2016ei\u2016+ \u221a 2L\u03b5i) \u00b7 \u2016xi \u2212 x\u2217\u2016 ] ,\ni.e. k\u2211 i=1 [f(xi)\u2212 f(x\u2217)] + L 2 \u2016xk \u2212 x\u2217\u20162 6 L 2 \u2016x0 \u2212 x\u2217\u20162 + k\u2211 i=1 \u03b5i + k\u2211 i=1 [ (\u2016ei\u2016+ \u221a 2L\u03b5i) \u00b7 \u2016xi \u2212 x\u2217\u2016 ] .\n(9)\nEq. (9 has two purposes. The first one is to bound the values of \u2016xi\u2212x\u2217\u2016 using the recursive definition. Once we have a bound on these quantities, we shall be able to bound the function values using only \u2016x0 \u2212 x\u2217\u2016 and the values of the errors."}, {"heading": "6.1.1 Bounding \u2016xi \u2212 x\u2217\u2016", "text": "We now need to bound the quantities \u2016xi \u2212 x\u2217\u2016 in terms of \u2016x0 \u2212 x\u2217\u2016, ei and \u03b5i. Dropping the first term in Eq. (9), which is positive due to the optimality of f(x\u2217), we have:\n\u2016xk \u2212 x\u2217\u20162 6 \u2016x0 \u2212 x\u2217\u20162 + 2\nL k\u2211 i=1 \u03b5i + 2 k\u2211 i=1 [( \u2016ei\u2016 L + \u221a 2\u03b5i L ) \u00b7 \u2016xi \u2212 x\u2217\u2016 ]\nWe may now use Lemma 1 (using A = \u2016x0 \u2212 x\u2217\u20162 + 2L \u2211k i=1 \u03b5i and \u03bbi = 2( \u2016ei\u2016 L + \u221a 2\u03b5i L ) to get \u2016xk\u2212x\u2217\u2016 6 k\u2211 i=1 ( \u2016ei\u2016 L + \u221a 2\u03b5i L ) + \u2016x0 \u2212 x\u2217\u20162 + 2 L k\u2211 i=1 \u03b5i + [ k\u2211 i=1 ( \u2016ei\u2016 L + \u221a 2\u03b5i L\n)]21/2 . Denoting Ak = \u2211k i=1 ( \u2016ei\u2016 L + \u221a 2\u03b5i L ) and Bk = \u2211k i=1 \u03b5i L , we get\n\u2016xk \u2212 x\u2217\u2016 6 Ak + ( \u2016x0 \u2212 x\u2217\u20162 + 2Bk +A2k )1/2 .\nSince Ai and Bi are increasing sequences (\u2016ei\u2016 and \u03b5i being positive), we have for i 6 k\n\u2016xi \u2212 x\u2217\u2016 6 Ai + ( \u2016x0 \u2212 x\u2217\u20162 + 2Bi +A2i )1/2 6 Ak + ( \u2016x0 \u2212 x\u2217\u20162 + 2Bk +A2k\n)1/2 6 Ak + \u2016x0 \u2212 x\u2217\u2016+ \u221a 2Bk +Ak\nusing the positivity of \u2016x0 \u2212 x\u2217\u20162, Bk and A2k."}, {"heading": "6.1.2 Bounding the function values", "text": "Now that we have a common bound for all \u2016xi \u2212 x\u2217\u2016 with i 6 k, we can upper-bound the right-hand side of Eq. (9) using only terms depending on \u2016x0 \u2212 x\u2217\u2016, ei and \u03b5i. Indeed, discarding L2 \u2016xk \u2212 x \u2217\u20162 which is positive, Eq. (9) becomes\nk\u2211 i=1 [f(xi)\u2212 f(x\u2217)] 6 L 2 \u2016x0 \u2212 x\u2217\u20162 + LBk + LAk(Ak + \u2016x0 \u2212 x\u2217\u2016+ \u221a 2Bk +Ak)\n6 L\n2 \u2016x0 \u2212 x\u2217\u20162 + LBk + 2LA2k + LAk\u2016x0 \u2212 x\u2217\u2016+ LAk\n\u221a 2Bk\n6 L\n2\n( \u2016x0 \u2212 x\u2217\u2016+ 2Ak + \u221a 2Bk )2 .\nSince f is convex, we get\nf\n( 1\nk k\u2211 i=1 xi\n) \u2212 f(x\u2217) 6 1\nk k\u2211 i=1 [f(xi)\u2212 f(x\u2217)]\n6 L\n2k\n( \u2016x0 \u2212 x\u2217\u2016+ 2Ak + \u221a 2Bk )2 ."}, {"heading": "6.2 Accelerated proximal-gradient method with errors in the convex case", "text": "We now give the proof of Proposition 2.\nProof Defining\n\u03b8k = 2/(k + 1) vk = xk\u22121 + 1\n\u03b8k (xk \u2212 xk\u22121) ,\nwe can rewrite the update for yk as\nyk = (1\u2212 \u03b8k+1)xk + \u03b8k+1vk ,\nbecause\n(1\u2212 \u03b8k+1)xk + \u03b8k+1vk = (1\u2212 2\nk + 2 )xk +\n2\nk + 2 [xk\u22121 +\nk + 1\n2 (xk \u2212 xk\u22121)]\n= xk \u2212 2\nk + 2 (xk \u2212 xk\u22121) +\nk + 1 k + 2 (xk \u2212 xk\u22121)\n= xk \u2212 k \u2212 1 k + 2 (xk \u2212 xk\u22121) = yk.\nBecause g\u2032 is Lipschitz and g is convex, we get for any z that\ng(xk) 6 g(yk\u22121) + \u2329 g\u2032(yk\u22121), xk \u2212 yk\u22121 \u232a + L\n2 \u2016xk \u2212 yk\u22121\u20162\n6 g(z) + \u2329 g\u2032(yk\u22121), yk\u22121 \u2212 z \u232a + \u2329 g\u2032(yk\u22121), xk \u2212 yk\u22121 \u232a + L\n2 \u2016xk \u2212 yk\u22121\u20162 .\nBecause \u2212[g\u2032(yk\u22121) + ek + L(xk + fk \u2212 yk\u22121)] \u2208 \u2202\u03b5kh(xk), we have for any z that\nh(xk) 6 \u03b5k + h(z) + \u2329 L(yk\u22121 \u2212 xk)\u2212 g\u2032(yk\u22121)\u2212 ek + Lfk, xk \u2212 z \u232a = \u03b5k + h(z) + \u2329 g\u2032(yk\u22121), z \u2212 xk \u232a + L \u3008xk \u2212 yk\u22121, z \u2212 xk\u3009+ \u3008ek + Lfk, z \u2212 xk\u3009\nAdding these bounds together gives:\ng(xk) + h(xk) = f(xk) 6 \u03b5k + f(z) + L \u3008xk \u2212 yk\u22121, z \u2212 xk\u3009+ L\n2 \u2016xk \u2212 yk\u22121\u20162 + \u3008ek + Lfk, z \u2212 xk\u3009\nChoosing z = \u03b8kx \u2217 + (1\u2212 \u03b8k)xk\u22121 gives\nf(xk) 6 \u03b5k + f(\u03b8kx \u2217 + (1\u2212 \u03b8)xk\u22121) + L \u3008xk \u2212 yk\u22121, \u03b8kx\u2217 + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009+\nL 2 \u2016xk \u2212 yk\u22121\u20162\n+ \u3008ek + Lfk, \u03b8kx\u2217 + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009\n6 \u03b5k + \u03b8kf(x \u2217) + (1\u2212 \u03b8k)f(xk\u22121) + L \u3008xk \u2212 yk\u22121, \u03b8kx\u2217 + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009+\nL 2 \u2016xk \u2212 yk\u22121\u20162\n+ \u3008ek + Lfk, \u03b8kx\u2217 + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009 (10) using the convexity of f and the fact that \u03b8k is in [0, 1].\nSince \u03b8kx \u2217 + (1\u2212 \u03b8k)xk\u22121 \u2212 xk = \u03b8k(x\u2217 \u2212 vk)\nand\nxk \u2212 yk\u22121 = \u03b8kvk + (1\u2212 \u03b8k)xk\u22121 \u2212 yk\u22121 = \u03b8kvk \u2212 \u03b8kvk\u22121 ,\nwe have\nL \u3008xk \u2212 yk\u22121, \u03b8kx\u2217 + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009 = L\u03b82k \u3008vk \u2212 vk\u22121, x\u2217 \u2212 vk\u3009 = \u2212L\u03b82k\u2016vk \u2212 x\u2217\u20162 + L\u03b82k \u3008vk \u2212 x\u2217, vk\u22121 \u2212 x\u2217\u3009\n(11)\nL 2 \u2016xk \u2212 yk\u22121\u20162 = L\u03b82k 2 \u2016vk \u2212 vk\u22121\u20162\n= L\u03b82k\n2\n( \u2016vk \u2212 x\u2217\u20162 + \u2016vk\u22121 \u2212 x\u2217\u20162 \u2212 2 \u3008vk \u2212 x\u2217, vk\u22121 \u2212 x\u2217\u3009 ) (12)\n\u3008ek + Lfk, \u03b8kx\u2217 + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009 = \u03b8k \u3008ek + Lfk, x\u2217 \u2212 vk\u3009 .\nSumming Eq. (11) and (12), we get\nL \u3008xk \u2212 yk\u22121, \u03b8kx\u2217 + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009+ L\n2 \u2016xk\u2212yk\u22121\u20162 = L\u03b82k 2\n( \u2016vk\u22121 \u2212 x\u2217\u20162 \u2212 \u2016vk \u2212 x\u2217\u20162 ) Moving all function values in Eq. (10) to the left-side, we then get\nf(xk)\u2212 \u03b8kf(x\u2217)\u2212 (1\u2212 \u03b8k)f(xk\u22121) 6 L\u03b82k ( \u2016vk\u22121 \u2212 x\u2217\u20162 \u2212 \u2016vk \u2212 x\u2217\u20162 ) + \u03b5k + \u03b8k \u3008ek + Lfk, x\u2217 \u2212 vk\u3009 .\nReordering the terms and dividing by \u03b82k gives\n1\n\u03b82k (f(xk)\u2212f(x\u2217))+\nL 2 \u2016vk\u2212x\u2217\u20162 6 1\u2212 \u03b8k \u03b82k (f(xk\u22121)\u2212f(x\u2217))+ L 2 \u2016vk\u22121\u2212x\u2217\u20162+ \u03b5k \u03b82k + 1 \u03b8k \u3008ek + Lfk, x\u2217 \u2212 vk\u3009 .\nNow we use that for all k greater than or equal to 1,\n1\u2212 \u03b8k \u03b82k 6 1 \u03b82k\u22121\nto apply this recursively and obtain\n1\n\u03b82k (f(xk)\u2212 f(x\u2217)) +\nL 2 \u2016vk \u2212 x\u2217\u20162 6 1\u2212 \u03b80 \u03b820 (f(x0)\u2212 f(x\u2217)) + L 2 \u2016v0 \u2212 x\u2217\u20162 + k\u2211 i=1 \u03b5i \u03b82i\n+ k\u2211 i=1 1 \u03b8i (\u2016ej\u2016+ \u221a 2L\u03b5i) \u00b7 \u2016x\u2217 \u2212 vi\u2016\nusing \u2016fi\u2016 6 \u221a 2\u03b5i L . Since v0 = x0 and \u03b80 = 2, we get\nf(xk)\u2212f(x\u2217)+ L\u03b82k\n2 \u2016vk\u2212x\u2217\u20162 6 L\u03b82k 2 \u2016x0\u2212x\u2217\u20162+\u03b82k k\u2211 i=1 \u03b5i \u03b82i +\u03b82k k\u2211 i=1 1 \u03b8i ( \u2016ej\u2016+ \u221a 2L\u03b5i ) \u00b7\u2016x\u2217\u2212vi\u2016 .\n(13)\nAs in the previous proof, we will now use Eq. (13) to first bound the values of \u2016vi \u2212 x\u2217\u2016 then, using these bounds, bound the function values."}, {"heading": "6.2.1 Bounding \u2016vi \u2212 x\u2217\u2016", "text": "We now need to bound the quantities \u2016vi \u2212 x\u2217\u2016 in terms of \u2016x0 \u2212 x\u2217\u2016, ei and \u03b5i.\n\u2016vk \u2212 x\u2217\u20162 6 \u2016x0 \u2212 x\u2217\u20162 + 2\nL k\u2211 i=1 \u03b5i \u03b82i + k\u2211 i=1 2 \u03b8i ( \u2016ej\u2016 L + \u221a 2\u03b5i L ) \u00b7 \u2016x\u2217 \u2212 vi\u2016 .\nSince \u03b8i = 2/(i+ 1), 1 \u03b8i = i+12 6 i since i > 1. Thus, we have\n\u2016vk \u2212 x\u2217\u20162 6 \u2016x0 \u2212 x\u2217\u20162 + 2\nL k\u2211 i=1 i2\u03b5i + k\u2211 i=1 2i ( \u2016ej\u2016 L + \u221a 2\u03b5i L ) \u00b7 \u2016x\u2217 \u2212 vi\u2016 .\nWe now denote A\u0303k = \u2211k i=1 i ( \u2016ei\u2016 L + \u221a 2\u03b5i L ) and B\u0303k = \u2211k i=1 i2\u03b5i L . From Lemma 1, we get\n\u2016vk \u2212 x\u2217\u2016 6 A\u0303k + ( \u2016x0 \u2212 x\u2217\u20162 + 2B\u0303k + A\u03032k )1/2 .\nSince A\u0303i and B\u0303i are increasing sequences, we also have for i 6 k:\n\u2016vi \u2212 x\u2217\u2016 6 A\u0303i + ( \u2016x0 \u2212 x\u2217\u20162 + 2B\u0303i + A\u03032i )1/2 6 \u2016x0 \u2212 x\u2217\u2016+ 2A\u0303i + B\u03031/2i \u221a 2\n6 \u2016x0 \u2212 x\u2217\u2016+ 2A\u0303k + B\u0303 1/2 k\n\u221a 2 ."}, {"heading": "6.2.2 Bounding the function values", "text": "Dropping L\u03b82k 2 \u2016vk \u2212 x \u2217\u20162 in Eq. (13) (since it is positive), we thus have\nf(xk)\u2212 f(x\u2217) 6 L\u03b82k\n2\n( \u2016x0 \u2212 x\u2217\u20162 + 2B\u0303k + 2A\u0303k [ \u2016x0 \u2212 x\u2217\u2016+ 2A\u0303k + \u221a 2B\u0303k ]) 6 L\u03b82k\n2\n( \u2016x0 \u2212 x\u2217\u20162 + 2B\u0303k + 2A\u0303k\u2016x0 \u2212 x\u2217\u2016+ 4A\u03032k + 2A\u0303k \u221a 2B\u0303k ) 6 L\u03b82k\n2\n( \u2016x0 \u2212 x\u2217\u2016+ 2A\u0303k + \u221a 2B\u0303k )2 and\n1\n\u03b82k (f(xk)\u2212 f(x\u2217)) 6\nL\n2\n( \u2016x0 \u2212 x\u2217\u2016+ 2A\u0303k + \u221a 2B\u0303k )2 ."}, {"heading": "6.3 Basic proximal-gradient method with errors in the strongly convex case", "text": "Below is the proof of Proposition 3 Proof As in section 4.1, there exists fi such that \u2016fi\u2016 6 \u221a 2\u03b5i L and\nL ( xi\u22121 \u2212 xi \u2212 1\nL (g\u2032(xi\u22121) + ei)\u2212 fi\n) \u2208 \u2202\u03b5ih(xi) .\nSince x\u2217 is optimal, we have that x\u2217 = proxL ( x\u2217 \u2212 1Lg \u2032(x\u2217) ) .\nWe first separate fk, the error in the proximal, from the rest: \u2016xk \u2212 x\u2217\u20162 = \u2225\u2225\u2225\u2225proxL(xk\u22121 \u2212 1Lg\u2032(xk\u22121)\u2212 1Lek ) + fk \u2212 proxL ( x\u2217 \u2212 1 L g\u2032(x\u2217) )\u2225\u2225\u2225\u22252 = \u2225\u2225\u2225\u2225proxL(xk\u22121 \u2212 1Lg\u2032(xk\u22121)\u2212 1Lek ) \u2212 proxL ( x\u2217 \u2212 1 L g\u2032(x\u2217)\n)\u2225\u2225\u2225\u22252 + \u2016fk\u20162 + 2 \u2329 fk,proxL ( xk\u22121 \u2212 1\nL g\u2032(xk\u22121)\u2212\n1 L ek\n) \u2212 proxL ( x\u2217 \u2212 1\nL g\u2032(x\u2217) )\u232a 6 \u2225\u2225\u2225\u2225proxL(xk\u22121 \u2212 1Lg\u2032(xk\u22121)\u2212 1Lek ) \u2212 proxL ( x\u2217 \u2212 1 L g\u2032(x\u2217)\n)\u2225\u2225\u2225\u22252 + 2\u03b5kL + 2 \u221a 2\u03b5k L \u2225\u2225\u2225\u2225proxL(xk\u22121 \u2212 1Lg\u2032(xk\u22121)\u2212 1Lek ) \u2212 proxL ( x\u2217 \u2212 1 L g\u2032(x\u2217)\n)\u2225\u2225\u2225\u2225 using Cauchy-Schwartz and \u2016fk\u2016 6 \u221a 2\u03b5k L\n6 \u2225\u2225\u2225\u2225xk\u22121 \u2212 1Lg\u2032(xk\u22121)\u2212 1Lek \u2212 x\u2217 + 1Lg\u2032(x\u2217) \u2225\u2225\u2225\u22252 + 2\u03b5kL\n+ 2 \u221a 2\u03b5k L \u2225\u2225\u2225\u2225xk\u22121 \u2212 1Lg\u2032(xk\u22121)\u2212 1Lek \u2212 x\u2217 + 1Lg\u2032(x\u2217) \u2225\u2225\u2225\u2225\nusing the non-expansiveness of the proximal\n6 \u2225\u2225\u2225\u2225xk\u22121 \u2212 1Lg\u2032(xk\u22121)\u2212 1Lek \u2212 x\u2217 + 1Lg\u2032(x\u2217) \u2225\u2225\u2225\u22252 + 2\u03b5kL\n+ 2 \u221a 2\u03b5k L (\u2225\u2225\u2225\u2225xk\u22121 \u2212 x\u2217 \u2212 1L(g\u2032(xk\u22121)\u2212 g\u2032(x\u2217)) \u2225\u2225\u2225\u2225+ \u2016ek\u2016L ) using the triangular inequality.\nWe continue this computation, but now separating ek, the error in the gradient, from the rest:\n\u2016xk \u2212 x\u2217\u20162 = \u2016xk\u22121 \u2212 x\u2217 \u2212 1 L (g\u2032(xk\u22121)\u2212 g\u2032(x\u2217))\u20162 +\n\u2016ek\u20162\nL2 \u2212 2 L\n\u2329 ek, xk\u22121 \u2212 x\u2217 \u2212 1\nL (g\u2032(xk\u22121)\u2212\n1 L g\u2032(x\u2217)) \u232a +\n2\u03b5k L + 2 \u221a 2\u03b5k L ( \u2016xk\u22121 \u2212 x\u2217 \u2212 1 L (g\u2032(xk\u22121)\u2212 g\u2032(x\u2217))\u2016+ \u2016ek\u2016 L ) 6 \u2016xk\u22121 \u2212 x\u2217 \u2212 1\nL (g\u2032(xk\u22121)\u2212 g\u2032(x\u2217))\u20162 +\n\u2016ek\u20162\nL2 +\n2 L \u2016ek\u2016\u2016xk\u22121 \u2212 x\u2217 \u2212 1 L (g\u2032(xk\u22121)\u2212 g\u2032(x\u2217))\u2016\n+ 2\u03b5k L + 2 \u221a 2\u03b5k L ( \u2016xk\u22121 \u2212 x\u2217 \u2212 1 L (g\u2032(xk\u22121)\u2212 g\u2032(x\u2217))\u2016+ \u2016ek\u2016 L ) using Cauchy-Schwartz\n6 \u2016xk\u22121 \u2212 x\u2217 \u2212 1 L (g\u2032(xk\u22121)\u2212 g\u2032(x\u2217))\u20162 +\n\u2016ek\u20162\nL2 + 2\u03b5k L + 2 L \u221a 2\u03b5k L \u2016ek\u2016\n+ ( 2\u2016ek\u2016 L + 2 \u221a 2\u03b5k L )\u2225\u2225\u2225\u2225xk\u22121 \u2212 x\u2217 \u2212 1L(g\u2032(xk\u22121)\u2212 g\u2032(x\u2217)) \u2225\u2225\u2225\u2225 .\nWe now need to bound \u2225\u2225xk\u22121 \u2212 x\u2217 \u2212 1L(g\u2032(xk\u22121)\u2212 g\u2032(x\u2217))\u2225\u2225 to get the final result. We have:\n\u2016xk\u22121 \u2212 x\u2217 \u2212 1 L (g\u2032(xk\u22121)\u2212 g\u2032(x\u2217))\u20162 = \u2016xk\u22121 \u2212 x\u2217\u20162 + 1 L2 \u2016g\u2032(xk\u22121)\u2212 g\u2032(x\u2217)\u20162\n\u2212 2 L\n\u2329 g\u2032(xk\u22121)\u2212 g\u2032(x\u2217), xk\u22121 \u2212 x\u2217 \u232a 6 \u2016xk\u22121 \u2212 x\u2217\u20162 + 1\nL2 \u2016g\u2032(xk\u22121)\u2212 g\u2032(x\u2217)\u20162\n\u2212 2 L\n( 1\nL+ \u00b5 \u2016g\u2032(xk\u22121)\u2212 g\u2032(x\u2217)\u20162 +\nL\u00b5\nL+ \u00b5 \u2016xk\u22121 \u2212 x\u2217\u20162 ) using theorem 2.1.12 of [28]\n= (1\u2212 2\u00b5 L+ \u00b5 )\u2016xk\u22121 \u2212 x\u2217\u20162 + 1 L\n( 1\nL \u2212 2 L+ \u00b5\n) \u2016g\u2032(xk\u22121)\u2212 g\u2032(x\u2217)\u20162\n6 (1\u2212 2\u00b5 L+ \u00b5 )\u2016xk\u22121 \u2212 x\u2217\u20162 + \u00b52 L ( 1 L \u2212 2 L+ \u00b5 )\u2016xk\u22121 \u2212 x\u2217\u20162\nusing the negativity of 1L \u2212 2 L+\u00b5 and the strong convexity of g = (\n1\u2212 \u00b5 L\n)2 \u2016xk\u22121 \u2212 x\u2217\u20162.\nThus\n\u2016xk \u2212 x\u2217\u20162 6 (\n1\u2212 \u00b5 L\n)2 \u2016xk\u22121 \u2212 x\u2217\u20162 + \u2016ek\u20162\nL2 + 2\u03b5k L + 2 L \u221a 2\u03b5k L \u2016ek\u2016\n+ ( 2\u2016ek\u2016 L + 2 \u221a 2\u03b5k L )( 1\u2212 \u00b5 L ) \u2016xk\u22121 \u2212 x\u2217\u2016\n= [( 1\u2212 \u00b5\nL\n) \u2016xk\u22121 \u2212 x\u2217\u2016+\n\u2016ek\u2016 L + \u221a 2\u03b5k L ]2 .\nTaking the square root of both sides and applying the bound recursively yields\n\u2016xk \u2212 x\u2217\u2016 6 (\n1\u2212 \u00b5 L\n)k \u2016x0 \u2212 x\u2217\u2016+ k\u2211 i=1 ( 1\u2212 \u00b5 L )k\u2212i(\u2016ei\u2016 L + \u221a 2\u03b5i L ) ."}, {"heading": "6.4 Accelerated proximal-gradient method with errors in the strongly convex case", "text": "We now give the proof of Proposition 4.\nProof We have (following [28])\nxk = yk\u22121 \u2212 1 L g\u2032(yk\u22121) .\nWe define\n\u03b12k = (1\u2212 \u03b1k)\u03b12k\u22121 + \u00b5\nL \u03b1k\nvk = xk\u22121 + 1\n\u03b1k\u22121 (xk \u2212 xk\u22121)\n\u03b8k = \u03b1k \u2212 \u00b5L 1\u2212 \u00b5L yk = xk + \u03b8k(vk \u2212 xk) .\nIf we choose \u03b10 = \u221a \u03b3, then this yields\nyk = xk + 1\u2212\u221a\u03b3 1 + \u221a \u03b3 (xk \u2212 xk\u22121) .\nWe can bound g(xk) with\ng(xk) 6 g(yk\u22121) + \u3008g\u2032(yk\u22121), xk \u2212 yk\u22121\u3009+ L\n2 \u2016xk \u2212 yk\u22121\u20162\nusing the convexity of g\n6 g(z) + \u3008g\u2032(yk\u22121), yk\u22121 \u2212 z\u3009+ \u3008g\u2032(yk\u22121), xk \u2212 yk\u22121\u3009+ L\n2 \u2016xk \u2212 yk\u22121\u20162 \u2212\n\u00b5 2 \u2016yk\u22121 \u2212 z\u20162\nusing the \u00b5-strong convexity of g.\nUsing Lemma 2, we have that \u2212[g\u2032(yk\u22121) + ek + L(xk + fk \u2212 yk\u22121)] \u2208 \u2202\u03b5kh(xk). Hence, we have for any z that\nh(xk) 6 \u03b5k + h(z) + \u2329 L(yk\u22121 \u2212 xk)\u2212 g\u2032(yk\u22121)\u2212 ek \u2212 Lfk, xk \u2212 z \u232a = \u03b5k + h(z) + \u2329 g\u2032(yk\u22121), z \u2212 xk \u232a + L \u3008xk \u2212 yk\u22121, z \u2212 xk\u3009+ \u3008ek + Lfk, z \u2212 xk\u3009\nAdding these two bounds, we get for any z\nf(xk) 6 \u03b5k + f(z) + L \u3008xk \u2212 yk\u22121, z \u2212 xk\u3009+ L\n2 \u2016xk \u2212 yk\u22121\u20162 \u2212\n\u00b5 2 \u2016yk\u22121 \u2212 z\u20162 + \u3008ek + Lfk, z \u2212 xk\u3009 .\nUsing z = \u03b1k\u22121x \u2217 + (1\u2212 \u03b1k\u22121)xk\u22121, we get\nf(xk) 6 \u03b5k + f(\u03b1k\u22121x \u2217 + (1\u2212 \u03b1k\u22121)xk\u22121) + L \u3008xk \u2212 yk\u22121, \u03b1k\u22121x\u2217 + (1\u2212 \u03b1k\u22121)xk\u22121 \u2212 xk\u3009\n+ L\n2 \u2016xk \u2212 yk\u22121\u20162 \u2212\n\u00b5 2 \u2016yk\u22121 \u2212 \u03b1k\u22121x\u2217 \u2212 (1\u2212 \u03b1k\u22121)xk\u22121\u20162\n+ \u3008ek + Lfk, \u03b1k\u22121x\u2217 + (1\u2212 \u03b1k\u22121)xk\u22121 \u2212 xk\u3009 6 \u03b5k + \u03b1k\u22121f(x \u2217) + (1\u2212 \u03b1k\u22121)f(xk\u22121) + L \u3008xk \u2212 yk\u22121, \u03b1k\u22121x\u2217 + (1\u2212 \u03b1k\u22121)xk\u22121 \u2212 xk\u3009\n+ L\n2 \u2016xk \u2212 yk\u22121\u20162 \u2212\n\u00b5 2 \u2016yk\u22121 \u2212 \u03b1k\u22121x\u2217 \u2212 (1\u2212 \u03b1k\u22121)xk\u22121\u20162 \u2212 \u00b5 2 \u03b1k\u22121(1\u2212 \u03b1k\u22121)\u2016x\u2217 \u2212 xk\u22121\u20162\n+ \u3008ek + Lfk, \u03b1k\u22121x\u2217 + (1\u2212 \u03b1k\u22121)xk\u22121 \u2212 xk\u3009 using the \u00b5-strong convexity of f .\nWe can replace xk \u2212 yk\u22121 using\nxk \u2212 yk\u22121 = xk \u2212 xk\u22121 \u2212 \u03b8k\u22121(vk\u22121 \u2212 xk\u22121)\n= \u03b8k\u22121xk\u22121 + \u03b8k\u22121 \u03b1k\u22121\n(xk \u2212 xk\u22121) + (\n1\u2212 \u03b8k\u22121 \u03b1k\u22121\n) (xk \u2212 xk\u22121)\u2212 \u03b8k\u22121vk\u22121\n= \u03b8k\u22121(vk \u2212 vk\u22121) + (\n1\u2212 \u03b8k\u22121 \u03b1k\u22121\n) (xk \u2212 xk\u22121) .\nWe also have\n(1\u2212 \u03b1k\u22121)xk\u22121 \u2212 xk = \u2212\u03b1k\u22121vk \u03b1k\u22121x \u2217 + (1\u2212 \u03b1k\u22121)xk\u22121 \u2212 xk = \u03b1k\u22121(x\u2217 \u2212 vk) ,\nand\nyk\u22121 \u2212 \u03b1k\u22121x\u2217 \u2212 (1\u2212 \u03b1k\u22121)xk\u22121 = yk\u22121 \u2212 \u03b1k\u22121(x\u2217 \u2212 vk)\u2212 xk = \u03b1k\u22121(vk \u2212 x\u2217)\u2212 \u03b8k\u22121(vk \u2212 vk\u22121)\u2212 (\n1\u2212 \u03b8k\u22121 \u03b1k\u22121\n) (xk \u2212 xk\u22121)\nThus,\nf(xk) 6 \u03b5k + \u03b1k\u22121f(x \u2217) + (1\u2212 \u03b1k\u22121)f(xk\u22121)\n\u2212 L\u03b8k\u22121\u03b1k\u22121\u3008vk \u2212 vk\u22121, vk \u2212 x\u2217\u3009 \u2212 L(\u03b1k\u22121 \u2212 \u03b8k\u22121)\u3008xk \u2212 xk\u22121, vk \u2212 x\u2217\u3009\n+ L\u03b82k\u22121\n2 \u2016vk \u2212 vk\u22121\u20162 +\nL ( 1\u2212 \u03b8k\u22121\u03b1k\u22121 )2\n2 \u2016xk \u2212 xk\u22121\u20162\n+ L\u03b8k\u22121\n( 1\u2212 \u03b8k\u22121\n\u03b1k\u22121\n) \u3008vk \u2212 vk\u22121, xk \u2212 xk\u22121\u3009\n\u2212 \u00b5\u03b12k\u22121\n2 \u2016vk \u2212 x\u2217\u20162 \u2212 \u00b5\u03b82k\u22121 2 \u2016vk \u2212 vk\u22121\u20162 \u2212\n\u00b5 ( 1\u2212 \u03b8k\u22121\u03b1k\u22121 )2\n2 \u2016xk \u2212 xk\u22121\u20162\n+ \u00b5\u03b1k\u22121\u03b8k\u22121\u3008vk \u2212 x\u2217, vk \u2212 vk\u22121\u3009+ \u00b5(\u03b1k\u22121 \u2212 \u03b8k\u22121)\u3008vk \u2212 x\u2217, xk \u2212 xk\u22121\u3009 \u2212 \u00b5\u03b8k\u22121 (\n1\u2212 \u03b8k\u22121 \u03b1k\u22121\n) \u3008vk \u2212 vk\u22121, xk \u2212 xk\u22121\u3009 \u2212 \u00b5\n2 \u03b1k\u22121(1\u2212 \u03b1k\u22121)\u2016x\u2217 \u2212 xk\u22121\u20162\n+ \u03b1k\u22121 \u3008ek + Lfk, x\u2217 \u2212 vk\u3009 .\nTo avoid unnecessary clutter, we shall denote Ek the additional term induced by the errors, i.e.\nEk = \u03b5k + \u03b1k\u22121 \u3008ek + Lfk, x\u2217 \u2212 vk\u3009 .\nBefore reordering the terms together, we shall also replace all instances of vk \u2212 vk\u22121 with vk \u2212 x\u2217 \u2212 (vk\u22121 \u2212 x\u2217):\nf(xk) 6 Ek + \u03b1k\u22121f(x \u2217) + (1\u2212 \u03b1k\u22121)f(xk\u22121)\u2212 L\u03b8k\u22121\u03b1k\u22121\u2016vk \u2212 x\u2217\u20162 + L\u03b8k\u22121\u03b1k\u22121\u3008vk\u22121 \u2212 x\u2217, vk \u2212 x\u2217\u3009\n\u2212 L(\u03b1k\u22121 \u2212 \u03b8k\u22121)\u3008xk \u2212 xk\u22121, vk \u2212 x\u2217\u3009 + (L\u2212 \u00b5)\u03b82k\u22121\n2 \u2016vk \u2212 x\u2217\u20162 + (L\u2212 \u00b5)\u03b82k\u22121 2 \u2016vk\u22121 \u2212 x\u2217\u20162 \u2212 (L\u2212 \u00b5)\u03b82k\u22121\u3008vk \u2212 x\u2217, vk\u22121 \u2212 x\u2217\u3009\n+ (L\u2212 \u00b5)\n( 1\u2212 \u03b8k\u22121\u03b1k\u22121 )2 2 \u2016xk \u2212 xk\u22121\u20162\n+ L\u03b8k\u22121\n( 1\u2212 \u03b8k\u22121\n\u03b1k\u22121\n) \u3008vk \u2212 x\u2217, xk \u2212 xk\u22121\u3009 \u2212 L\u03b8k\u22121 ( 1\u2212 \u03b8k\u22121\n\u03b1k\u22121\n) \u3008vk\u22121 \u2212 x\u2217, xk \u2212 xk\u22121\u3009\n\u2212 \u00b5\u03b12k\u22121\n2 \u2016vk \u2212 x\u2217\u20162\n+ \u00b5\u03b1k\u22121\u03b8k\u22121\u2016vk \u2212 x\u2217\u20162 \u2212 \u00b5\u03b1k\u22121\u03b8k\u22121\u3008vk \u2212 x\u2217, vk\u22121 \u2212 x\u2217\u3009 + \u00b5(\u03b1k\u22121 \u2212 \u03b8k\u22121)\u3008vk \u2212 x\u2217, xk \u2212 xk\u22121\u3009\n\u2212 \u00b5\u03b8k\u22121 (\n1\u2212 \u03b8k\u22121 \u03b1k\u22121\n) \u3008vk \u2212 x\u2217, xk \u2212 xk\u22121\u3009+ \u00b5\u03b8k\u22121 ( 1\u2212 \u03b8k\u22121\n\u03b1k\u22121\n) \u3008vk\u22121 \u2212 x\u2217, xk \u2212 xk\u22121\u3009\n\u2212 \u00b5 2 \u03b1k\u22121(1\u2212 \u03b1k\u22121)\u2016x\u2217 \u2212 xk\u22121\u20162 .\nWith a bit of well-needed cleaning, this becomes\nf(xk) 6 Ek + \u03b1k\u22121f(x \u2217) + (1\u2212 \u03b1k\u22121)f(xk\u22121)\n+\n[ L\u2212 \u00b5\n2 (\u03b8k\u22121 \u2212 \u03b1k\u22121)2 \u2212 L\u03b12k\u22121 2\n] \u2016vk \u2212 x\u2217\u20162\n+ (L\u2212 \u00b5)\u03b82k\u22121\n2 \u2016vk\u22121 \u2212 x\u2217\u20162\n+ (L\u2212 \u00b5)\u03b8k\u22121(\u03b1k\u22121 \u2212 \u03b8k\u22121)\u3008vk\u22121 \u2212 x\u2217, vk \u2212 x\u2217\u3009 + (L\u2212 \u00b5)(\u03b8k\u22121 \u2212 \u03b1k\u22121) (\n1\u2212 \u03b8k\u22121 \u03b1k\u22121\n) \u3008xk \u2212 xk\u22121, vk \u2212 x\u2217\u3009\n\u2212 (L\u2212 \u00b5)\u03b8k\u22121 (\n1\u2212 \u03b8k\u22121 \u03b1k\u22121\n) \u3008vk\u22121 \u2212 x\u2217, xk \u2212 xk\u22121\u3009\n+ (L\u2212 \u00b5)\n( 1\u2212 \u03b8k\u22121\u03b1k\u22121 )2 2 \u2016xk \u2212 xk\u22121\u20162\n\u2212 \u00b5 2 \u03b1k\u22121(1\u2212 \u03b1k\u22121)\u2016x\u2217 \u2212 xk\u22121\u20162 .\nWe can rewrite xk \u2212 xk\u22121 using\nxk \u2212 xk\u22121 = \u03b1k\u22121(vk \u2212 xk\u22121) = \u03b1k\u22121(vk \u2212 x\u2217)\u2212 \u03b1k\u22121(xk\u22121 \u2212 x\u2217) .\nWe may now compute the coefficients for the following terms: \u2016vk \u2212 x\u2217\u20162, \u2016vk\u22121 \u2212 x\u2217\u20162, \u3008vk\u22121 \u2212 x\u2217, vk \u2212 x\u2217\u3009, \u3008xk\u22121 \u2212 x\u2217, vk \u2212 x\u2217\u3009, \u3008xk\u22121 \u2212 x\u2217, vk\u22121 \u2212 x\u2217\u3009 and \u2016x\u2217 \u2212 xk\u22121\u20162.\nFor \u2016vk \u2212 x\u2217\u20162, we have\nL\u2212 \u00b5 2 (\u03b8k\u22121 \u2212 \u03b1k\u22121)2 \u2212 L\u03b12k\u22121\n2\ufe38 \ufe37\ufe37 \ufe38 \u2016vk \u2212 x\u2217\u20162 term \u2212 (L\u2212 \u00b5)(\u03b8k\u22121 \u2212 \u03b1k\u22121)2\ufe38 \ufe37\ufe37 \ufe38 \u3008xk \u2212 xk\u22121, vk \u2212 x\u2217\u3009 term + (L\u2212 \u00b5)(\u03b8k\u22121 \u2212 \u03b1k\u22121)2 2\ufe38 \ufe37\ufe37 \ufe38 \u2016xk \u2212 xk\u22121\u20162 term = \u2212 L\u03b12k\u22121 2 .\nFor \u2016vk\u22121 \u2212 x\u2217\u20162, there is only one term and we keep (L\u2212\u00b5)\u03b82k\u22121\n2 .\nFor \u3008vk\u22121 \u2212 x\u2217, vk \u2212 x\u2217\u3009, we get\n(L\u2212 \u00b5)\u03b8k\u22121(\u03b1k\u22121 \u2212 \u03b8k\u22121)\ufe38 \ufe37\ufe37 \ufe38 \u3008vk\u22121 \u2212 x\u2217, vk \u2212 x\u2217\u3009 term \u2212 (L\u2212 \u00b5)\u03b8k\u22121 (\u03b1k\u22121 \u2212 \u03b8k\u22121)\ufe38 \ufe37\ufe37 \ufe38 \u3008vk\u22121 \u2212 x\u2217, xk \u2212 xk\u22121\u3009 term = 0 .\nFor \u3008xk\u22121 \u2212 x\u2217, vk \u2212 x\u2217\u3009, we get\n(L\u2212 \u00b5)(\u03b8k\u22121 \u2212 \u03b1k\u22121)2\ufe38 \ufe37\ufe37 \ufe38 \u3008xk \u2212 xk\u22121, vk \u2212 x\u2217\u3009 term \u2212 (L\u2212 \u00b5)(\u03b8k\u22121 \u2212 \u03b1k\u22121)2\ufe38 \ufe37\ufe37 \ufe38 \u2016xk \u2212 xk\u22121\u20162 term = 0 .\nFor \u3008xk\u22121 \u2212 x\u2217, vk\u22121 \u2212 x\u2217\u3009, we get\n(L\u2212 \u00b5)\u03b8k\u22121 (\u03b1k\u22121 \u2212 \u03b8k\u22121)\ufe38 \ufe37\ufe37 \ufe38 \u3008vk\u22121 \u2212 x\u2217, xk \u2212 xk\u22121\u3009 term = (L\u2212 \u00b5)\u03b8k\u22121 (\u03b1k\u22121 \u2212 \u03b8k\u22121) .\nFor \u2016x\u2217 \u2212 xk\u22121\u20162, we get\n(L\u2212 \u00b5)(\u03b8k\u22121 \u2212 \u03b1k\u22121)2 2\ufe38 \ufe37\ufe37 \ufe38 \u2016xk \u2212 xk\u22121\u20162 term \u2212 \u00b5 2 \u03b1k\u22121(1\u2212 \u03b1k\u22121)\ufe38 \ufe37\ufe37 \ufe38 \u2016x\u2217 \u2212 xk\u22121\u20162 term = \u2212\u00b5 2 \u03b8k\u22121(1\u2212 \u03b1k\u22121) .\nHence, we have\nf(xk) 6 Ek + \u03b1k\u22121f(x \u2217) + (1\u2212 \u03b1k\u22121)f(xk\u22121)\n\u2212 L\u03b12k\u22121\n2 \u2016vk \u2212 x\u2217\u20162\n+ (L\u2212 \u00b5)\u03b82k\u22121\n2 \u2016vk\u22121 \u2212 x\u2217\u20162\n+ (L\u2212 \u00b5)\u03b8k\u22121 (\u03b1k\u22121 \u2212 \u03b8k\u22121) \u3008vk\u22121 \u2212 x\u2217, xk\u22121 \u2212 x\u2217\u3009 \u2212 \u00b5 2 \u03b8k\u22121(1\u2212 \u03b1k\u22121)\u2016xk\u22121 \u2212 x\u2217\u20162 \u2212 \u03b8k\u22121(L\u2212 \u00b5) 2(\u03b8k\u22121 \u2212 \u03b1k\u22121)2\n2\u00b5(1\u2212 \u03b1k\u22121) \u2016vk\u22121 \u2212 x\u2217\u20162\n+ \u03b8k\u22121(L\u2212 \u00b5)2(\u03b8k\u22121 \u2212 \u03b1k\u22121)2\n2\u00b5(1\u2212 \u03b1k\u22121) \u2016vk\u22121 \u2212 x\u2217\u20162 ,\nthe last two lines allowing us to complete the square. We may now factor it to get\nf(xk) 6 Ek + \u03b1k\u22121f(x \u2217) + (1\u2212 \u03b1k\u22121)f(xk\u22121)\n\u2212 L\u03b12k\u22121\n2 \u2016vk \u2212 x\u2217\u20162\n+ (L\u2212 \u00b5)\u03b82k\u22121\n2 \u2016vk\u22121 \u2212 x\u2217\u20162\n\u2212 \u00b5 2 \u03b8k\u22121(1\u2212 \u03b1k\u22121) \u2225\u2225\u2225\u2225xk\u22121 \u2212 x\u2217 \u2212 (L\u2212 \u00b5)(\u03b1k\u22121 \u2212 \u03b8k\u22121)\u00b5(1\u2212 \u03b1k\u22121) (vk\u22121 \u2212 x\u2217) \u2225\u2225\u2225\u22252 + \u03b8k\u22121(L\u2212 \u00b5)2(\u03b8k\u22121 \u2212 \u03b1k\u22121)2\n2\u00b5(1\u2212 \u03b1k\u22121) \u2016vk\u22121 \u2212 x\u2217\u20162 .\nDiscarding the term depending on xk\u22121\u2212x\u2217 and regrouping the terms depending on \u2016vk\u22121\u2212 x\u2217\u20162, we have\nf(xk) 6 Ek + \u03b1k\u22121f(x \u2217) + (1\u2212 \u03b1k\u22121)f(xk\u22121)\n\u2212 L\u03b12k\u22121\n2 \u2016vk \u2212 x\u2217\u20162\n+ (L\u03b1k\u22121 \u2212 \u00b5)\u03b1k\u22121\n2 \u2016vk\u22121 \u2212 x\u2217\u20162 .\nReordering the terms, we have\nf(xk)\u2212f(x\u2217)+ L\u03b12k\u22121\n2 \u2016vk\u2212x\u2217\u20162 6 (1\u2212\u03b1k\u22121) (f(xk\u22121)\u2212 f(x\u2217))+ (L\u03b1k\u22121 \u2212 \u00b5)\u03b1k\u22121 2\n\u2016vk\u22121\u2212x\u2217\u20162+Ek . (14)\nWe can rewrite Eq. (14) as\nf(xk)\u2212 f(x\u2217) + L\u03b12k\u22121\n2 \u2016vk \u2212 x\u2217\u20162 6 (1\u2212 \u03b1k\u22121)\n( f(xk\u22121)\u2212 f(x\u2217) +\nL\u03b12k\u22122 2 \u2016vk\u22121 \u2212 x\u2217\u20162\n)\n+ L\u03b12k\u22121 \u2212 \u00b5\u03b1k\u22121 \u2212 (1\u2212 \u03b1k\u22121)L\u03b12k\u22122\n2 \u2016vk\u22121 \u2212 x\u2217\u20162\n+ Ek .\nUsing\n\u03b1k =\n\u221a \u00b5\nL\nand denoting\n\u03b4k = f(xk)\u2212 f(x\u2217) + \u00b5 2 \u2016vk \u2212 x\u2217\u20162 , (15)\nwe get the following recursion:\n\u03b4k 6\n( 1\u2212 \u221a \u00b5\nL\n) \u03b4k\u22121 + Ek . (16)\nApplying this relationship recursively, we get\n\u03b4k 6\n( 1\u2212 \u221a \u00b5\nL\n)k \u03b40 + k\u2211 t=1 Et ( 1\u2212 \u221a \u00b5 L )k\u2212t . (17)\nSince Ek = \u03b5k + \u03b1k\u22121 \u3008ek + Lfk, x\u2217 \u2212 vk\u3009, we can bound it by\nEk 6 \u03b5k +\n\u221a \u00b5\nL\n( \u2016ek\u2016+ \u221a 2L\u03b5k ) \u2016vk \u2212 x\u2217\u2016\nusing \u2016fk\u2016 6 \u221a 2\u03b5k L . Again, we shall use Eq. (17) to first bound the values of \u2016vi\u2212 x\u2217\u2016, then the function values themselves."}, {"heading": "6.4.1 Bounding \u2016vi \u2212 x\u2217\u2016", "text": "We will now use Lemma 1 to bound the value of \u2016vk \u2212 x\u2217\u2016. Since \u2016vk \u2212 x\u2217\u20162 is bounded by 2\u03b4k \u00b5 (using Eq. (15)), we can use Eq. (17) to get\n\u2016vk \u2212 x\u2217\u20162 6 2\n\u00b5\n( 1\u2212 \u221a \u00b5\nL\n)k [ \u03b40 +\nk\u2211 t=1 \u03b5t ( 1\u2212 \u221a \u00b5 L )\u2212t]\n+ 2\u221a L\u00b5 k\u2211 t=1 ( \u2016et\u2016+ \u221a 2L\u03b5t )( 1\u2212 \u221a \u00b5 L )k\u2212t \u2016vt \u2212 x\u2217\u2016 .\nMultiplying both sides by ( 1\u2212 \u221a\n\u00b5 L )\u2212k yields(\n1\u2212 \u221a \u00b5\nL\n)\u2212k \u2016vk \u2212 x\u2217\u20162 6 2\n\u00b5\n[ \u03b40 +\nk\u2211 t=1 \u03b5t ( 1\u2212 \u221a \u00b5 L )\u2212t]\n+ 2\u221a L\u00b5 k\u2211 t=1 ( \u2016et\u2016+ \u221a 2L\u03b5t )( 1\u2212 \u221a \u00b5 L )\u2212t/2( 1\u2212 \u221a \u00b5 L )\u2212t/2 \u2016vt \u2212 x\u2217\u2016 .\n(18)\nUsing\nBk = k\u2211 t=1 \u03b5t ( 1\u2212 \u221a \u00b5 L )\u2212t\n\u03bb\u0303t =\n\u221a \u00b5\nL\n( \u2016et\u2016+ \u221a 2L\u03b5t )( 1\u2212 \u221a \u00b5\nL\n)\u2212t/2 ,\nLemma 1 yields( 1\u2212 \u221a \u00b5\nL\n)\u2212k/2 \u2016vk \u2212 x\u2217\u2016 6 1\n\u00b5 k\u2211 t=1 \u03bb\u0303t +  2 \u00b5 \u03b40 + 2 \u00b5 Bk + ( 1 \u00b5 k\u2211 t=1 \u03bb\u0303t )21/2 . (19)\nSince Bt is an increasing sequence and the \u03bb\u0303t are positive, we have for i 6 k\n( 1\u2212 \u221a \u00b5\nL\n)\u2212i/2 \u2016vi \u2212 x\u2217\u2016 6 1\n\u00b5 i\u2211 t=1 \u03bb\u0303t +  2 \u00b5 \u03b40 + 2 \u00b5 Bi + ( 1 \u00b5 i\u2211 t=1 \u03bb\u0303t )21/2\n6 1\n\u00b5 i\u2211 t=1 \u03bb\u0303t + \u221a 2\u03b40 \u00b5 + \u221a 2Bi \u00b5 + 1 \u00b5 i\u2211 t=1 \u03bb\u0303t\n= 2\n\u00b5 k\u2211 t=1 \u03bb\u0303t + \u221a 2\u03b40 \u00b5 + \u221a 2Bk \u00b5 ."}, {"heading": "6.4.2 Bounding the function values", "text": "Denoting Ak = \u2211k t=1 \u03bb\u0303t = \u221a \u00b5 L \u2211 t ( \u2016et\u2016+ \u221a 2L\u03b5t ) ( 1\u2212 \u221a \u00b5 L )\u2212t/2 , we have\n\u03b4k 6\n( 1\u2212 \u221a \u00b5\nL\n)k [ \u03b40 +\nk\u2211 t=1 \u03b5t ( 1\u2212 \u221a \u00b5 L )\u2212t]\n+\n\u221a \u00b5\nL k\u2211 t=1 ( \u2016et\u2016+ \u221a 2L\u03b5t )( 1\u2212 \u221a \u00b5 L )k\u2212t/2( 2Ak \u00b5 + \u221a 2\u03b40 \u00b5 + \u221a 2Bk \u00b5 )\n= ( 1\u2212 \u221a \u00b5\nL\n)k( \u03b40 +Bk +\n\u2211 t \u03bb\u0303t ( 2Ak \u00b5 + \u221a 2\u03b40 \u00b5 + \u221a 2Bk \u00b5 ))\n= ( 1\u2212 \u221a \u00b5\nL\n)k( \u03b40 +Bk +Ak ( 2Ak \u00b5 + \u221a 2\u03b40 \u00b5 + \u221a 2Bk \u00b5 ))\n6 ( 1\u2212 \u221a \u00b5\nL\n)k (\u221a \u03b40 +Ak \u221a 2 \u00b5 + \u221a Bk )2 .\nUsing the L-Lipschitz gradient of f and the fact that v0 = x0, we have\u221a \u03b40 = \u221a f(x0)\u2212 f(x\u2217) + \u00b5\n2 \u2016v0 \u2212 x\u2217\u20162 6 \u221a 2(f(x0)\u2212 f(x\u2217)) .\nHence, discarding the term \u2016vk \u2212 x\u2217\u20162 of \u03b4k, we have\nf(xk)\u2212 f(x\u2217) 6 ( 1\u2212 \u221a \u00b5\nL\n)k (\u221a 2(f(x0)\u2212 f(x\u2217)) +Ak \u221a 2 \u00b5 + \u221a Bk )2 . (20)"}], "references": [{"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM Journal on Imaging Sciences, 2(1):183\u2013202", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Gradient methods for minimizing composite objective function", "author": ["Y. Nesterov"], "venue": "CORE Discussion Papers, ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Regression shrinkage and selection via the Lasso", "author": ["R. Tibshirani"], "venue": "Journal of the Royal Statistical Society: Series B, 58(1):267\u2013288", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "Atomic decomposition by basis pursuit", "author": ["S.S. Chen", "D.L. Donoho", "M.A. Saunders"], "venue": "SIAM Journal on Scientific Computing, 20(1):33\u201361", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1998}, {"title": "Sparse reconstruction by separable approximation", "author": ["S.J. Wright", "R.D. Nowak", "M.A.T. Figueiredo"], "venue": "IEEE Transactions on Signal Processing, 57(7):2479\u20132493", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Convex optimization with sparsityinducing norms", "author": ["F. Bach", "R. Jenatton", "J. Mairal", "G. Obozinski"], "venue": "S. Sra, S. Nowozin, and S.J. Wright, editors, Optimization for Machine Learning. MIT Press", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Total variation projection with first order schemes", "author": ["J. Fadili", "G. Peyr\u00e9"], "venue": "IEEE Transactions on Image Processing, 20(3):657\u2013669", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Graph-structured multi-task regression and an efficient optimization method for general fused Lasso", "author": ["X. Chen", "S. Kim", "Q. Lin", "J.G. Carbonell", "E.P. Xing"], "venue": "arXiv:1005.3579v1", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "A singular value thresholding algorithm for matrix completion", "author": ["J.-F. Cai", "E.J. Cand\u00e8s", "Z. Shen"], "venue": "SIAM Journal on Optimization, 20(4)", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Fixed point and Bregman iterative methods for matrix rank minimization", "author": ["S. Ma", "D. Goldfarb", "L. Chen"], "venue": "Mathematical Programming, 128(1):321\u2013353", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Group Lasso with overlap and graph Lasso", "author": ["L. Jacob", "G. Obozinski", "J.-P. Vert"], "venue": "ICML", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Proximal methods for sparse hierarchical dictionary learning", "author": ["R. Jenatton", "J. Mairal", "G. Obozinski", "F. Bach"], "venue": "ICML", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Fast Newton-type methods for total variation regularization", "author": ["A. Barbero", "S. Sra"], "venue": "ICML", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Fast overlapping group Lasso", "author": ["J. Liu", "J. Ye"], "venue": "arXiv:1009.0306v1", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Convex structure learning in log-linear models: Beyond pairwise potentials", "author": ["M. Schmidt", "K. Murphy"], "venue": "AISTATS", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "A unified framework of descent algorithms for nonlinear programs and variational inequalities", "author": ["M. Patriksson"], "venue": "PhD thesis, Department of Mathematics, Link\u00f6ping University, Sweden", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1995}, {"title": "Solving monotone inclusions via compositions of nonexpansive averaged operators", "author": ["P.L. Combettes"], "venue": "Optimization, 53(5-6):475\u2013504", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2004}, {"title": "Efficient online and batch learning using forward backward splitting", "author": ["J. Duchi", "Y. Singer"], "venue": "JMLR, 10:2873\u20132898", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Sparse online learning via truncated gradient", "author": ["J. Langford", "L. Li", "T. Zhang"], "venue": "JMLR, 10:777\u2013801", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Smooth optimization with approximate gradient", "author": ["A. d\u2019Aspremont"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Estimate sequence methods: extensions and approximations", "author": ["M. Baes"], "venue": "Ifor internal report, ETH Zurich, Switzerland", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "First-order methods of smooth convex optimization with inexact oracle", "author": ["O. Devolder", "F. Glineur", "Y. Nesterov"], "venue": "CORE Discussion Papers, ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Convergence rate of incremental subgradient algorithms", "author": ["A. Nedic", "D. Bertsekas"], "venue": "Stochastic Optimization: Algorithms and Applications, pages 263\u2013304", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}, {"title": "Error bounds and convergence analysis of feasible descent methods: A general approach", "author": ["Z.-Q. Luo", "P. Tseng"], "venue": "Annals of Operations Research, 46-47(1):157\u2013178", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1993}, {"title": "Hybrid deterministic-stochastic methods for data fitting", "author": ["M.P. Friedlander", "M. Schmidt"], "venue": "arXiv:1104.2373", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Monotone operators and the proximal point algorithm", "author": ["R.T. Rockafellar"], "venue": "SIAM Journal on Control and Optimization, 14(5):877\u2013898", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1976}, {"title": "New proximal point algorithms for convex minimization", "author": ["O. G\u00fcler"], "venue": "SIAM Journal on Optimization, 2(4):649\u2013664", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1992}, {"title": "Introductory Lectures on Convex Optimization: A Basic Course", "author": ["Y. Nesterov"], "venue": "Springer", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2004}, {"title": "Convex optimization theory", "author": ["D.P. Bertsekas"], "venue": "Athena Scientific", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2009}, {"title": "On accelerated proximal gradient methods for convex-concave optimization", "author": ["P. Tseng"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "Convex and network flow optimization for structured sparsity", "author": ["J. Mairal", "R. Jenatton", "G. Obozinski", "F. Bach"], "venue": "arXiv:1104.1872v1", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "A Dykstra-like algorithm for two monotone operators", "author": ["H.H. Bauschke", "P.L. Combettes"], "venue": "Pacific Journal of Optimization, 4(3):383\u2013391", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2008}, {"title": "Smooth minimization of non-smooth functions", "author": ["Y. Nesterov"], "venue": "Mathematical Programming, 103(1):127\u2013152", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "Proximal splitting methods in signal processing", "author": ["P.L. Combettes", "J.C. Pesquet"], "venue": "arXiv:0912.3522v4", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Tree-reweighted belief propagation algorithms and approximate ML estimation by pseudo-moment matching", "author": ["M.J. Wainwright", "T.S. Jaakkola", "A.S. Willsky"], "venue": "AISTATS", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2003}, {"title": "Online learning with kernels", "author": ["J. Kivinen", "A.J. Smola", "R.C. Williamson"], "venue": "IEEE Transactions on Signal Processing, 52(8):2165\u20132176", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2004}, {"title": "Subsampling algorithms for semidefinite programming", "author": ["A. d\u2019Aspremont"], "venue": "arXiv:0803.1990v5,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "Projected Newton-type methods in machine learning", "author": ["M. Schmidt", "D. Kim", "S. Sra"], "venue": "S. Sra, S. Nowozin, and S Wright, editors, Optimization for Machine Learning. MIT Press", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2011}, {"title": "Convex Analysis and Optimization", "author": ["D.P. Bertsekas", "A. Nedi\u0107", "A.E. Ozdaglar"], "venue": "Athena Scientific", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Proximal-gradient methods and accelerated proximal-gradient methods [1, 2] are among the most important methods for taking advantage of the structure of many of the nonsmooth optimization problems that arise in practice.", "startOffset": 68, "endOffset": 74}, {"referenceID": 1, "context": "Proximal-gradient methods and accelerated proximal-gradient methods [1, 2] are among the most important methods for taking advantage of the structure of many of the nonsmooth optimization problems that arise in practice.", "startOffset": 68, "endOffset": 74}, {"referenceID": 2, "context": "One of the most well-studied instances of this type of problem is `1-regularized least squares [3, 4], minimize x\u2208Rd \u2016Ax\u2212 b\u2016 + \u03bb\u2016x\u20161,", "startOffset": 95, "endOffset": 101}, {"referenceID": 3, "context": "One of the most well-studied instances of this type of problem is `1-regularized least squares [3, 4], minimize x\u2208Rd \u2016Ax\u2212 b\u2016 + \u03bb\u2016x\u20161,", "startOffset": 95, "endOffset": 101}, {"referenceID": 0, "context": "While classical subgradient methods only achieve an error level on the objective function of O(1/ \u221a k) after k iterations, proximal-gradient methods have an error of O(1/k) while accelerated proximal-gradient methods futher reduce this to O(1/k2) [1, 2].", "startOffset": 247, "endOffset": 253}, {"referenceID": 1, "context": "While classical subgradient methods only achieve an error level on the objective function of O(1/ \u221a k) after k iterations, proximal-gradient methods have an error of O(1/k) while accelerated proximal-gradient methods futher reduce this to O(1/k2) [1, 2].", "startOffset": 247, "endOffset": 253}, {"referenceID": 4, "context": "We can efficiently compute an analytic solution to this problem for several notable choices of h, including the case of `1-regularization and disjoint group `1-regularization [5, 6].", "startOffset": 175, "endOffset": 181}, {"referenceID": 5, "context": "We can efficiently compute an analytic solution to this problem for several notable choices of h, including the case of `1-regularization and disjoint group `1-regularization [5, 6].", "startOffset": 175, "endOffset": 181}, {"referenceID": 6, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 130, "endOffset": 136}, {"referenceID": 7, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 130, "endOffset": 136}, {"referenceID": 8, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 223, "endOffset": 230}, {"referenceID": 9, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 223, "endOffset": 230}, {"referenceID": 10, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 318, "endOffset": 326}, {"referenceID": 11, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 318, "endOffset": 326}, {"referenceID": 6, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 392, "endOffset": 399}, {"referenceID": 12, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 392, "endOffset": 399}, {"referenceID": 8, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 558, "endOffset": 565}, {"referenceID": 9, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 558, "endOffset": 565}, {"referenceID": 11, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 742, "endOffset": 754}, {"referenceID": 13, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 742, "endOffset": 754}, {"referenceID": 14, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 742, "endOffset": 754}, {"referenceID": 15, "context": "It is known that proximal-gradient methods that use an approximate proximity operator converge under only weak assumptions [16, 17]; we briefly review this and other related work in the next section.", "startOffset": 123, "endOffset": 131}, {"referenceID": 16, "context": "It is known that proximal-gradient methods that use an approximate proximity operator converge under only weak assumptions [16, 17]; we briefly review this and other related work in the next section.", "startOffset": 123, "endOffset": 131}, {"referenceID": 6, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 12, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 8, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 9, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 13, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 14, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 17, "context": "For example, when the ek are independent, zero-mean, and finitevariance random variables then proximal-gradient methods achieve the (optimal) error level of O(1/ \u221a k) [18, 19].", "startOffset": 167, "endOffset": 175}, {"referenceID": 18, "context": "For example, when the ek are independent, zero-mean, and finitevariance random variables then proximal-gradient methods achieve the (optimal) error level of O(1/ \u221a k) [18, 19].", "startOffset": 167, "endOffset": 175}, {"referenceID": 19, "context": "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.", "startOffset": 235, "endOffset": 247}, {"referenceID": 20, "context": "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.", "startOffset": 235, "endOffset": 247}, {"referenceID": 21, "context": "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.", "startOffset": 235, "endOffset": 247}, {"referenceID": 22, "context": "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.", "startOffset": 275, "endOffset": 279}, {"referenceID": 23, "context": "Other authors have analyzed the convergence rate of the gradient and projected-gradient methods with a decreasing sequence of errors [24, 25], but this analysis does not consider the important class of accelerated gradient methods.", "startOffset": 133, "endOffset": 141}, {"referenceID": 24, "context": "Other authors have analyzed the convergence rate of the gradient and projected-gradient methods with a decreasing sequence of errors [24, 25], but this analysis does not consider the important class of accelerated gradient methods.", "startOffset": 133, "endOffset": 141}, {"referenceID": 21, "context": "In contrast, the analysis of [22] allows a decreasing sequence of errors without assuming strong convexity (though convergence rates in this context are not explicitly mentioned) and considers the accelerated projectedgradient method.", "startOffset": 29, "endOffset": 33}, {"referenceID": 20, "context": "The analysis of [21] considers errors in both the gradient and projection operators for accelerated projected-gradient methods, but this analysis requires that the domain of the function is compact.", "startOffset": 16, "endOffset": 20}, {"referenceID": 25, "context": "In the context of proximal-point algorithms, there is a substantial literature on using inexact proximity operators with a decreasing sequence of errors, dating back to the seminal work of Rockafeller [26].", "startOffset": 201, "endOffset": 205}, {"referenceID": 26, "context": "Accelerated proximal-point methods with a decreasing sequence of errors have also been examined, beginning with [27].", "startOffset": 112, "endOffset": 116}, {"referenceID": 15, "context": "For example, we can establish that inexact proximal-gradient methods converge under some minor closedness assumptions on the mapping induced by the approximate proximity operator, and the assumption that the algorithm used to compute the inexact proximity operator achieves sufficient descent on problem (2) compared to the previous iteration xk\u22121 [16].", "startOffset": 348, "endOffset": 352}, {"referenceID": 16, "context": "Convergence of inexact proximalgradient methods can also be established under the assumption that the norms of the errors are summable [17].", "startOffset": 135, "endOffset": 139}, {"referenceID": 6, "context": "Indeed, as pointed out by [7], even convergence of the accelerated proximalgradient method has not been established under an inexact proximity operator.", "startOffset": 26, "endOffset": 29}, {"referenceID": 6, "context": "This gap in the theory is one of the reasons why the authors of [7] chose to use the non-accelerated variant of the proximal-gradient algorithm.", "startOffset": 64, "endOffset": 67}, {"referenceID": 11, "context": ", see [12] for the case of overlapping group `1-regularization).", "startOffset": 6, "endOffset": 10}, {"referenceID": 29, "context": "We focus on a basic variant of the algorithm where \u03b2k is set to (k \u2212 1)/(k + 2) [30]: Proposition 2 (Accelerated proximal-gradient method with errors) Assume that", "startOffset": 80, "endOffset": 84}, {"referenceID": 21, "context": "Hence, as also discussed in [22], unlike in the error-free case the accelerated method may not necessarily be better than the basic method because it is more sensitive to errors in the computation.", "startOffset": 28, "endOffset": 32}, {"referenceID": 30, "context": "We tested the basic inexact proximal-gradient and accelerated proximal-gradient methods on the CUR-like factorization optimization problem introduced in [31] to approximate a", "startOffset": 153, "endOffset": 157}, {"referenceID": 30, "context": "In [31], the authors used an accelerated proximal-gradient method and chose p = \u221e since under this choice the proximity operator can be computed exactly.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "In this case, it is possible to very quickly compute an approximate proximity operator using the block coordinate descent (BCD) algorithm presented in [12], which is equivalent to the proximal variant of Dykstra\u2019s algorithm introduced by [32].", "startOffset": 151, "endOffset": 155}, {"referenceID": 31, "context": "In this case, it is possible to very quickly compute an approximate proximity operator using the block coordinate descent (BCD) algorithm presented in [12], which is equivalent to the proximal variant of Dykstra\u2019s algorithm introduced by [32].", "startOffset": 238, "endOffset": 242}, {"referenceID": 30, "context": "In our experiments, we used the four data sets examined by [31]1 and we choose \u03bbrow = .", "startOffset": 59, "endOffset": 63}, {"referenceID": 32, "context": "An alternative to inexact proximal methods for solving structured sparsity problems are smoothing methods [33] and alternating direction methods [34].", "startOffset": 106, "endOffset": 110}, {"referenceID": 33, "context": "An alternative to inexact proximal methods for solving structured sparsity problems are smoothing methods [33] and alternating direction methods [34].", "startOffset": 145, "endOffset": 149}, {"referenceID": 6, "context": "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.", "startOffset": 195, "endOffset": 201}, {"referenceID": 7, "context": "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.", "startOffset": 195, "endOffset": 201}, {"referenceID": 8, "context": "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.", "startOffset": 219, "endOffset": 226}, {"referenceID": 9, "context": "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.", "startOffset": 219, "endOffset": 226}, {"referenceID": 34, "context": "For example, errors in the calculation of the gradien arise when fitting undirected graphical models and using an iterative method to approximate the gradient of the log-partition function [35].", "startOffset": 189, "endOffset": 193}, {"referenceID": 35, "context": "Other examples include using a reduced set of training examples within kernel methods [36], or subsampling to solve semidefinite programming problems [37].", "startOffset": 86, "endOffset": 90}, {"referenceID": 36, "context": "Other examples include using a reduced set of training examples within kernel methods [36], or subsampling to solve semidefinite programming problems [37].", "startOffset": 150, "endOffset": 154}, {"referenceID": 1, "context": "It would be interesting to extend methods for estimating L in the exact case [2] to the case of inexact algorithms.", "startOffset": 77, "endOffset": 80}, {"referenceID": 37, "context": "Finally, we note that there has been recent interest in inexact proximal Newton-like methods [38], and it would be interesting to analyze the effect of errors on the convergence rates of these methods.", "startOffset": 93, "endOffset": 97}, {"referenceID": 0, "context": "Choosing z = \u03b8kx \u2217 + (1\u2212 \u03b8k)xk\u22121 gives f(xk) 6 \u03b5k + f(\u03b8kx \u2217 + (1\u2212 \u03b8)xk\u22121) + L \u3008xk \u2212 yk\u22121, \u03b8kx + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009+ L 2 \u2016xk \u2212 yk\u22121\u2016 + \u3008ek + Lfk, \u03b8kx + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009 6 \u03b5k + \u03b8kf(x \u2217) + (1\u2212 \u03b8k)f(xk\u22121) + L \u3008xk \u2212 yk\u22121, \u03b8kx + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009+ L 2 \u2016xk \u2212 yk\u22121\u2016 + \u3008ek + Lfk, \u03b8kx + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009 (10) using the convexity of f and the fact that \u03b8k is in [0, 1].", "startOffset": 352, "endOffset": 358}, {"referenceID": 27, "context": "12 of [28] = (1\u2212 2\u03bc L+ \u03bc )\u2016xk\u22121 \u2212 x\u2217\u20162 + 1 L ( 1 L \u2212 2 L+ \u03bc ) \u2016g(xk\u22121)\u2212 g\u2032(x\u2217)\u20162 6 (1\u2212 2\u03bc L+ \u03bc )\u2016xk\u22121 \u2212 x\u2217\u20162 + \u03bc2 L ( 1 L \u2212 2 L+ \u03bc )\u2016xk\u22121 \u2212 x\u2217\u20162 using the negativity of 1 L \u2212 2 L+\u03bc and the strong convexity of g = ( 1\u2212 \u03bc L )2 \u2016xk\u22121 \u2212 x\u2217\u20162.", "startOffset": 6, "endOffset": 10}, {"referenceID": 27, "context": "Proof We have (following [28]) xk = yk\u22121 \u2212 1 L g(yk\u22121) .", "startOffset": 25, "endOffset": 29}], "year": 2017, "abstractText": "We consider the problem of optimizing the sum of a smooth convex function and a non-smooth convex function using proximal-gradient methods, where an error is present in the calculation of the gradient of the smooth term or in the proximity operator with respect to the non-smooth term. We show that both the basic proximal-gradient method and the accelerated proximal-gradient method achieve the same convergence rate as in the error-free case, provided that the errors decrease at appropriate rates. Using these rates, we perform as well as or better than a carefully chosen fixed error level on a set of structured sparsity problems.", "creator": "LaTeX with hyperref package"}}}