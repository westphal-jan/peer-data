{"id": "1201.2719", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jan-2012", "title": "Ultrametric Model of Mind, II: Application to Text Content Analysis", "abstract": "In a companion paper, Murtagh (2012), we discussed how Matte Blanco's work linked the unrepressed unconscious (in the human) to symmetric logic and thought processes. We showed how ultrametric topology provides a most useful representational and computational framework for this. Now we look at the extent to which we can find ultrametricity in text. We use coherent and meaningful collections of nearly 1000 texts to show how we can measure inherent ultrametricity. On the basis of our findings we hypothesize that inherent ultrametricty is a basis for further exploring unconscious thought processes.", "histories": [["v1", "Fri, 13 Jan 2012 01:00:41 GMT  (23kb)", "https://arxiv.org/abs/1201.2719v1", "21 pages, 6 tables. arXiv admin note: substantial text overlap witharXiv:cs/0701181"], ["v2", "Mon, 6 Feb 2012 19:49:54 GMT  (23kb)", "http://arxiv.org/abs/1201.2719v2", "21 pages, 6 tables. arXiv admin note: substantial text overlap witharXiv:cs/0701181"], ["v3", "Mon, 16 Jul 2012 12:48:24 GMT  (23kb)", "http://arxiv.org/abs/1201.2719v3", "21 pages, 6 tables. arXiv admin note: substantial text overlap witharXiv:cs/0701181(V3: minor corrections)"]], "COMMENTS": "21 pages, 6 tables. arXiv admin note: substantial text overlap witharXiv:cs/0701181", "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["fionn murtagh"], "accepted": false, "id": "1201.2719"}, "pdf": {"name": "1201.2719.pdf", "metadata": {"source": "CRF", "title": "Ultrametric Model of Mind, II: Application to Text Content Analysis", "authors": ["Fionn Murtagh"], "emails": ["fmurtagh@acm.org"], "sections": [{"heading": null, "text": "ar X\niv :1\n20 1.\n27 19\nv3 [\ncs .A\nIn a companion paper, Murtagh (2012), we discussed howMatte Blanco\u2019s work linked the unrepressed unconscious (in the human) to symmetric logic and thought processes. We showed how ultrametric topology provides a most useful representational and computational framework for this. Now we look at the extent to which we can find ultrametricity in text. We use coherent and meaningful collections of nearly 1000 texts to show how we can measure inherent ultrametricity. On the basis of our findings we hypothesize that inherent ultrametricty is a basis for further exploring unconscious thought processes."}, {"heading": "1 Introduction", "text": "Any agglomerative hierarchical procedure (cf. Benze\u0301cri, 1979a,b; Lerman, 1981; Murtagh, 1983, 1985) can impose hierarchical structure. Our first aim in this work is to assess inherent extent of hierarchical or ultrametric structure.\nWe take a large number of meaningful texts in order to see how they can be distinguished and/or what other conclusions can be drawn, in regard to their inherent ultrametricity, or hierarchical structure.\nOur procedure is as follows.\n1. Meaningful component parts of texts are used, such as chapters, reports, tales, or very approximately similar sized segments of contiguous text. Our aim is natural division and also very roughly comparable text component sizes. In regard to the latter experimental design choice, very varied text component lengths are easily accommodated.\n2. Then both text units and the word set are projected into a Euclidean space. Correspondence analysis allows us to do this. This projection\nmethod takes \u201cprofiles\u201d of counts, or frequencies of occurrence, endowed with the \u03c72 metric, into a Euclidean space. Both text units and words are projected into the same Euclidean space. All pairwise relationships \u2013 between text units, between words, and between both sets \u2013 are taken into account in this mapping of the \u03c72 metric endowed space into the Euclidean metric endowed space.\n3. Within each text, based on its Euclidean factor space representation, we then proceed to investigate how ultrametric it is. By design, the \u201csemantic network\u201d used and expressed by the Euclidean factor space is metric. How ultrametric it is is the question we raise.\n4. In one study, we look at the words, and seek out ultrametrically-related words.\nIn section 2 we discuss how we quantify ultrametricity. In section 3, the semantic mapping methodology through correspondence analysis is described. This is the mapping of recorded or input data endowed with the \u03c72 metric into a Euclidean, factor space. In this Euclidean space, we then pose the question: how ultrametric is the given space?\nIn section 4 we summarize and discuss our experimental results. We characterize texts and collections of text, \u201cfingerprinting\u201d them in terms of inherent ultrametricity.\nIn section 5 we look within a text, to determine just where ultrametricity arises."}, {"heading": "2 Quantifying Ultrametricity", "text": "In the companion article (Murtagh, 2012), we described how ultrametricity provides a representation (in this sense a model) of Matte Blanco\u2019s symmetric reasoning. Symmetric reasoning, as we have seen, is associated with repressed or otherwise unconscious thought processes.\nBefore introducing our method of quantifying ultrametricity, we look at some other ways we could do so, albeit in a less satisfactory way (as we will argue)."}, {"heading": "2.1 Ultrametricity Coefficient of Lerman", "text": "The principle adopted in any constructive assessment of ultrametricity is to construct an ultrametric on data and see what discrepancy there is between input data and induced ultrametric data structure. Quantifying ultrametricity using a constructive approach is less than perfect as a solution, given the potential complications arising from known problems, e.g. chaining in single link, and non-uniqueness, or even inversions, with other methods. The conclusion here is that the \u201cmeasurement tool\u201d used for quantifying ultrametricity itself occupies an overly prominent role relative to that which we seek to measure. For such reasons, we need an independent way to quantify ultrametricity.\nLerman\u2019s (1981) H-classifiability index is as follows. From the isosceles triangle principle, given a distance d where d(x, y) 6= d(y, z) we have d(x, z) \u2264 max{d(x, y), d(y, z)}, it follows that the largest and second largest of the numbers d(x, y), d(y, z), d(x, z) are equal. Lerman\u2019s H-classifiability measure essentially looks at how close these two numbers (largest, second largest) are. So as to avoid influence of distribution of the distance values, Lerman\u2019s measure is based on ranks (of these distances) only. For further discussion of it, see Murtagh (2004).\nThere are two drawbacks with Lerman\u2019s index. Firstly, ultrametricity is associated with H = 0 but non-ultrametricity is not bounded. In extensive experimentation, we found maximum values for H in the region of 0.24. The second problem with Lerman\u2019s index is that for floating point coordinate values, especially in high dimensions, the strict equality necessitated for an equilateral triangle is nearly impossible to achieve. However our belief is that approximate equilateral triangles are very likely to arise in important cases of highdimensional spaces with data points at hypercube vertex locations. We would prefer therefore that the quantifying of ultrametricity should \u201cgracefully\u201d take account of triplets which are \u201cclose to\u201d equilateral. Note that for some authors, the equilateral case is considered to be \u201ctrivial\u201d or a \u201ctrivial limit\u201d (Treves, 1997). For us, however, it is an important case, together with the other important case of ultrametricity (i.e., isosceles with small base)."}, {"heading": "2.2 Ultrametricity Coefficient of Rammal, Toulouse and Virasoro", "text": "The quantifying of how ultrametric a data set is by Rammal et al. (1985, 1986) was influential for us in this work. The Rammal ultrametricity index is given by \u2211\nx,y(d(x, y) \u2212 dc(x, y))/ \u2211\nx,y d(x, y) where d is the metric distance being assessed, and dc is the subdominant ultrametric. The latter is also the ultrametric associated with the single link hierarchical clustering method. The Rammal et al. index is bounded by 0 (= ultrametric) and 1. As pointed out in Rammal et al. (1985, 1986), this index suffers from \u201cthe chaining effect and from sensitivity to fluctuations\u201d. The single link hierarchical clustering method, yielding the subdominant ultrametric, is, as is well known, subject to such difficulties."}, {"heading": "2.3 Ultrametricity Coefficients of Treves and of Hartman", "text": "Treves (1997) considers triplets of points giving rise to minimal, median and maximal distances. In the plot of dmin/dmax against dmed/dmax, the triangular inequality, the ultrametric inequality, and the \u201ctrivial limit\u201d of equilateral triangles, occupy definable regions.\nHartmann (1998) considers dmax \u2212 dmed. Now, Lerman (1981) uses ranks in order to give (translation, scale, etc.) invariance to the sensitivity (i.e., instability, lack of robustness) of distances. Hartmann instead fixes the remaining distance dmin.\nWe seek to avoid, as far as possible, lack of invariance due to use of distances. We seek to quantify both isosceles with small base configurations, as well as equilateral configurations. Finally, we seek a measure of ultrametricity bounded by 0 and 1."}, {"heading": "2.4 Bayesian Network Modeling", "text": "Latent ultrametric distances were estimated by Schweinberger and Snijders (2003) using a Bayesian and maximum likelihood approach in order to represent transitive structures among pairwise relationships. As they state, \u201cThe observed network is generated by hierarchically nested latent transitive structures, expressed by ultrametrics\u201d. Multiple, nested transitive structures are at issue. \u201cUltrametric structures imply transitive structures\u201d and as an informal way to characterize ultrametric structures (arising from embedded clusters, comprising \u201cfriends\u201d and \u201cclose friends\u201d): \u201cFriends are likely to agree, and unlikely to disagree; close friends are very likely to agree, and very unlikely to disagree.\u201d\nIssues however in the statistical model-based approach to determining ultrametricity include that convergence to an optimal fit is not guaranteed and there can be an appreciable computational requirement. Our approach (to be described in the next subsection) in contrast is fast and can be achieved through sampling which supposes that there is a homogenous ultrametricity pertaining to the data used. If sampling is used (for computational reasons) then we assume that the text is \u201ctextured\u201d in the same way throughout, or that it is sufficiently \u201cunified\u201d. For one theme in regard to content, or one origin, or one author, such an assumption seems a reasonable one."}, {"heading": "2.5 Our Ultrametricity Coefficient", "text": "We define a coefficient of ultrametricity termed \u03b1 which is specified algorithmically as follows.\n1. All triplets of points are considered, with a distance (by default, Euclidean) defined on these points. Since for a large number of points, n, the number of triplets, n(n \u2212 1)(n \u2212 2)/6 would be computationally prohibitive, we may wish to randomly (uniformly) sample coordinates (i \u223c {1..n}, j \u223c {1..n}, k \u223c {1..n}).\n2. We check for possible alignments (implying degenerate triangles) and exclude such cases.\n3. Next we select the smallest angle as less than or equal to 60 degrees. (We use the well-known definition of the cosine of the angle facing side of length x as: (y2 + z2 \u2212 x2)/2yz.) This is our first necessary property for being a strictly isosceles (< 60 degrees) or equilateral (= 60 degrees) ultrametric triangle.\n4. For the two other angles subtended at the triangle base, we seek an angular difference of strictly less than 2 degrees (0.03490656 radians). This condition is an approximation to the ultrametric configuration, based on an arbitrary choice of small angle. This condition is targeting a configuration that may not be exactly ultrametric but nonetheless is very close to ultrametric.\n5. Among all triplets (1) satisfying our exact properties (2, 3) and close approximation property (4), we define our ultrametricity coefficient as the relative proportion of these triplets. Approximately ultrametric data will yield a value of 1. On the other hand, data that is non-ultrametric in the sense of not respecting conditions 3 and 4 will yield a low value, potentially reaching 0.\nIn summary, the \u03b1 index is defined in this way: Consider a triplet of points, that defines a triangle. If the smallest internal angle, a, in this triangle is \u2264 60 degrees, and, for the two other internal angles, b and c, if |b\u2212 c| < 2 degrees, then this triangle is an ultrametric one. We look for the overall proportion of such ultrametric triangles in our data.\nIn the Appendix we give the essential pseudo-code used."}, {"heading": "2.6 What the Ultrametricity Coefficient Reveals", "text": "A wide range of case studies are used in Murtagh (2004) to explore this coefficient of ultrametricity.\nIt is found that:\n\u2022 the number of points (i.e., either words or text components), n, does not effect the value of the ultrametricity coefficient, \u03b1;\n\u2022 ultrametricity as quantified in this way increases with sparsity of data encoding (e.g., word presences in text components);\n\u2022 ultrametricity increases with dimensionality (of either word set, or text component set);\n\u2022 dimensionality and spatial (embedding space \u2013 each word in the text component space, and each text component in the word space) sparsity, combined, force the tendency towards ultrametricity, but the compounding of these two data properties is not as pronounced as one might have expected;\n\u2022 and ultrametricity very noticeably increases with spatial dimensionality.\nFurthermore in Murtagh (2004) a connection is made with sparse forms of coding in regard to how complex stimuli are represented in the cortex. Among other implications, this points to the possibility that semantic pattern matching is best accomplished through ultrametric computation.\nIn regard to such ultrametric computation, search can benefit from prior ultrametric structuring \u2013 such as through inducing a hierarchical clustering on\nthe data \u2013 and then nearest neighbor search can be shown to be achievable in constant worst-case computational time. This very powerful result is in keeping with the human ability to pattern-match in thought in what appears to be real time. Murtagh (2004) concludes by noting that it may be the case that human thinking is computationally efficient precisely because such computation is carried out in an ultrametric space.\nSo much for the background on the experimental work now to be presented. With regard to Matte Blanco (1998), the human thinking at issue is \u201cunrepressed unconscious\u201d thinking, expressing symmetrical reasoning, or more the symmetrical mode of being. This is one facet of the bi-logical system in the human mind process."}, {"heading": "3 Semantic Mapping: Mapping Interrelation-", "text": "ships into a Euclidean, Factor Space\nWe employ correspondence analysis for metric embedding, followed by determination of the extent of ultrametricity, in factor space, based on the \u03b1 coefficient of ultrametricity. Our motivation for using precisely this Euclidean embedding is as follows. Our input data is in the form of frequencies of occurrence. Now, a Euclidean distance defined on vectors with such values is not appropriate.\nThe \u03c72 distance is an appropriate weighted Euclidean distance for use with such data (Benze\u0301cri, 1979; Murtagh, 2005b). Consider texts i and i\u2032 crossed by words j. Let kij be the number of occurrences of word j in text i. Then, omitting a constant, the \u03c72 distance between texts i and i\u2032 is given by \u2211\nj 1/kj(kij/ki \u2212 ki\u2032j/ki\u2032)\n2. The weighting term is 1/kj. The weighted Euclidean distance is between the profile of text i, viz. kij/ki for all j, and the analogous profile of text i\u2032."}, {"heading": "3.1 Correspondence Analysis: Mapping \u03c72 into Euclidean Distances", "text": "As a dimensionality reduction technique correspondence analysis is particularly appropriate for handling frequency data. As an example of the latter, frequencies of word occurrence in text will be studied below.\nThe given contingency table (or numbers of occurrence) data is denoted kIJ = {kIJ(i, j) = k(i, j); i \u2208 I, j \u2208 J}. I is the set of text indexes, and J is the set of word indexes. We have k(i) = \u2211\nj\u2208J k(i, j). Analogously k(j) is defined, and k = \u2211\ni\u2208I,j\u2208J k(i, j). Next, fIJ = {fij = k(i, j)/k; i \u2208 I, j \u2208 J} \u2282 RI\u00d7J , similarly fI is defined as {fi = k(i)/k; i \u2208 I, j \u2208 J} \u2282 RI , and fJ analogously. What we have described here is taking numbers of occurrences into relative frequencies.\nThe conditional distribution of fJ knowing i \u2208 I, also termed the jth profile with coordinates indexed by the elements of I, is:\nf iJ = {f ij = fij/fi = (kij/k)/(ki/k); fi 6= 0; j \u2208 J}\nand likewise for f jI . Note that the input data values here are always non-negative reals. The output factor projections (and contributions to the principal directions of inertia) will be reals."}, {"heading": "3.2 Input: Cloud of Points Endowed with the Chi Squared Metric", "text": "The cloud of points consists of the couple: profile coordinate and mass. We have NJ(I) = {(f iJ , fi); i \u2208 I} \u2282 RJ , and again similarly for NI(J).\nThe moment of inertia is as follows:\nM2(NJ(I)) = M 2(NI(J)) = \u2016fIJ \u2212 fIfJ\u20162fIfJ\n= \u2211\ni\u2208I,j\u2208J\n(fij \u2212 fifj)2/fifj (1)\nThe term \u2016fIJ \u2212fIfJ\u20162fIfJ is the \u03c72 metric between the probability distribution fIJ and the product of marginal distributions fIfJ , with as center of the metric the product fIfJ . Decomposing the moment of inertia of the cloud NJ(I) \u2013 or of NI(J) since both analyses are inherently related \u2013 furnishes the principal axes of inertia, defined from a singular value decomposition."}, {"heading": "3.3 Output: Cloud of Points Endowed with the Euclidean Metric in Factor Space", "text": "From the initial frequencies data matrix, a set of probability data, fij , is defined by dividing each value by the grand total of all elements in the matrix. In correspondence analysis, each row (or column) point is considered to have an associated weight. The weight of the ith row point is given by fi = \u2211\nj fij , and the weight of the jth column point is given by fj = \u2211\ni fij . We consider the row points to have coordinates fij/fi, thus allowing points of the same profile to be identical (i.e., superimposed). The following weighted Euclidean distance, the \u03c72 distance, is then used between row points:\nd2(i, k) = \u2211\nj\n1\nfj\n(\nfij fi \u2212 fkj fk\n)2\nand an analogous distance is used between column points. The mean row point is given by the weighted average of all row points:\n\u2211\ni\nfi fij fi = fj\nfor j = 1, 2, . . . ,m. Similarly the mean column profile has ith coordinate fi. We first consider the projections of the n profiles in Rm onto an axis, u. This is given by \u2211\nj\nfij fi 1 fj uj\nfor all i (note the use of the scalar product here). For details on determining the new axis, u, see Murtagh (2005).\nThe projections of points onto axis u were with respect to the 1/fi weighted Euclidean metric. This makes interpreting projections very difficult from a human/visual point of view, and so it is more natural to present results in such a way that projections can be simply appreciated. Therefore factors are defined, such that the projections of row vectors onto factor \u03c6 associated with axis u are given by\n\u2211\nj\nfij fi \u03c6j\nfor all i. Taking\n\u03c6j = 1\nfj uj\nensures this and projections onto \u03c6 are with respect to the ordinary (unweighted) Euclidean distance.\nAn analogous set of relationships hold in Rn where the best fitting axis, v, is searched for. A simple mathematical relationship holds between u and v, and between \u03c6 and \u03c8 (the latter being the factor associated with axis or eigenvector v):\n\u221a \u03bb\u03c8i = \u2211\nj\nfij fi \u03c6j\n\u221a \u03bb\u03c6j = \u2211\ni\nfij fj \u03c8i\nThese are termed transition formulas. Axes u and v, and factors \u03c6 and \u03c8, are associated with eigenvalue \u03bb and best fitting higher-dimensional subspaces are associated with decreasing values of \u03bb (see Murtagh, 2005b, for further details).\nIn this work, \u03c6j are coordinates of words in the new, factor and Euclidean, space. The \u03c8i are coordinates of text segments in the factor space. In the Euclidean, factor space, the transition formulas have the following interpretation. Each text point is the weighted average of its associated word points. Similarly, each word is located at the center of gravity of its associated texts. In this way the factor space of the text segments and the factor space of the words furnish one semantic space."}, {"heading": "3.4 Conclusions on Correspondence Analysis and Introduction to the Numerical Experiments to Follow", "text": "Some important points for the analyses to follow are \u2013 firstly in relation to correspondence analysis:\n1. From numbers of occurrence data we always get (by design) a Euclidean embedding using correspondence analysis. The factors are embedded in a Euclidean metric.\n2. Due to centering the data, the numbers of factors, i.e. number of non-zero eigenvalues, are given by one less than the minimum of the number of observations studied (indexed by set I) and the number of variables or attributes used (indexed by set J).\n3. The number of dimensions in factor space may be less than full rank if there are linear dependencies present.\n4. In the experiments to follow in the next section, we have n < m always, implying that inherent (full rank) dimensionality of the projected Euclidean factor space is n\u2212 1.\n5. We also take m = 1000, 2000 and the full attribute set (say, mtot) in each case, where the attributes are ordered in terms of decreasing marginal frequency. In other words, we take the 1000 most frequent words to characterize our texts; then the 2000 most frequent words; and finally all words. Since n < m it is not surprising that similar results are found irrespective of the value of m. The inherent, projected, Euclidean, factor space dimensionality is the same in each case, viz., n\u2212 1.\n6. From the previous remark, viz. that the results obtained for the m = 1000, 2000, and all most frequent words, are of the same inherent dimensionality we motivate our use of these different characterizations of the text set by the need to study the stability of our results. We will show quite convincingly that our results are characteristic of the texts used, in each case, and are not \u201cone off\u201d or arbitrary.\nSome important points related to our numerical assessments below, in relation to data used, determining of ultrametricity coefficient, and software used, are as follows.\n1. In line with one tradition of textual analysis associated with Benze\u0301cri\u2019s correspondence analysis (see Chapter 5, \u201cContent analysis of text\u201d, in Murtagh, 2005b) we take the unique full words and rank them in order of importance. Thus for the Brothers Grimm work, below, we find function words: \u201cthe\u201d, 19,696 occurrences; \u201cand\u201d, 14,582 occurrences; \u201cto\u201d, 7380 occurrences; \u201che\u201d, 5951 occurrences; \u201cwas\u201d, 4122 occurrences; and so on. Last three, with one occurrence each: \u201cyolk\u201d, \u201czeal\u201d, \u201czest\u201d.\n2. The \u03b1 ultrametricity coefficient is based on triangles. Now, with n graph nodes we have O(n3) possible triangles which is computationally prohibitive, so we instead sample. The means and standard deviations below are based on 2000 random triangle vertex realizations, repeated 20 times; hence, in each case, in total 40,000 random selections of triangles.\n3. All text collections reported on below (section 4) are publicly accessible (and web addresses are cited). All texts were obtained by us in straight (ascii) text format.\nThe preparation of the input data was carried out with programs written in C, and available at www.correspondances.info (accompanying Murtagh, 2005b). The correspondence analysis software was written in the public R statistical software environment (www.r-project.org, again see Murtagh, 2005b) and is available at this same web address. Some simple statistical calculations were carried out by us also in the R environment."}, {"heading": "4 Determining Ultrametricity through Interre-", "text": "lationships between Text Units based on Shared\nWords\nWe use in all over 900 short texts, given by short stories, or chapters, or short reports. All are in English. Unique words are determined through delimitation by white space and by punctuation characters with no distinction of upper and lower case. In all, over one million words are used in our studies of these texts.\nWe carried out some assessments of Porter stemming (Porter, 1980) as an alternative to use of whitespace- or punctuation-delimited words, without much difference in our findings."}, {"heading": "4.1 Brothers Grimm", "text": "As a homogeneous collection of texts we take 209 fairy tales of the Brothers Grimm (Ockerbloom, 2003), containing 7443 unique (in total 280,629) spaceor punctuation-delimited words. Story lengths were between 650 and 44,400 words.\nTo define a semantic context of increasing resolution we took the most frequent 1000 words, followed by the most frequent 2000 words, and finally all 7443 words. We constructed a cross-tabulation of numbers of occurrences of each word in each one of the 209 fairy tales. This led therefore to a set of frequency tables (contingency tables) of dimensions: 209 \u00d7 1000, 209\u00d7 2000 and 209\u00d7 7443. The factor space, of dimension 209\u2212 1 = 208 (cf. subsection 3.4), is Euclidean, so the correspondence analysis can be said to be a mapping from the \u03c72 metric into a Euclidean metric space.\nTable 1 (columns 4, 5) shows remarkable stability of the \u03b1 ultrametricity coefficient results, and such stability will be seen in all further results to be\npresented below. In the table, means and standard deviations were calculated in each case from 2000 random triangles, repeated 20 times (cf. subsection 3.4). The ultrametricity is not high for the Grimm Brothers\u2019 data: we recall that an \u03b1 value of 0 means no triangle is isosceles/equilateral. We see that there is very little ultrametric (hence hierarchical) structure in the Brothers Grimm data (based on our particular definition of ultrametricity/hierarchy)."}, {"heading": "4.2 Jane Austen", "text": "To further study stories of a general sort, we use some works of the English novelist, Jane Austen.\n1. Sense and Sensibility (Austen, 1811), 50 chapters = files, chapter lengths from 1028 to 5632 words.\n2. Pride and Prejudice (Austen, 1813), 61 chapters each containing between 683 and 5227 words.\n3. Persuasion (Austen, 1817), 24 chapters, chapter lengths 1579 to 7007 words.\n4. Sense and Sensibility split into 131 separate texts, each containing around 1000 words (i.e., each chapter was split into files containing 5000 or fewer characters). We did this to check on any influence by the size (total number of words) of the text unit used (and we found no such influence).\nIn all there were 266 texts containing a total of 9723 unique words. We looked at the 1000, 2000 most frequent, and all 9723, words to characterize the texts by frequency of occurrence.\nTable 2, again displaying very stable \u03b1 values, indicates that the Austen corpus is a small amount more ultrametric than the Grimms\u2019 corpus, Table 1."}, {"heading": "4.3 Air Accident Reports", "text": "We used air accident reports to explore documents with very particular, technical, vocabulary. The NTSB aviation accident database (Aviation Accident Database and Synopses, 2003) contains information about civil aviation accidents in the United States and elsewhere. We selected 50 reports. Examples of two such reports used by us: occurred Sunday, January 02, 2000 in Corning, AR, aircraft Piper PA-46-310P, injuries \u2013 5 uninjured; occurred Sunday, January 02, 2000 in Telluride, TN, aircraft: Bellanca BL-17-30A, injuries \u2013 1 fatal. In the 50 reports, there were 55,165 words. Report lengths ranged between approximately 2300 and 28,000 words. The number of unique words was 4261.\nExample of the start of our 30th report: On January 16, 2000, about 1630 eastern standard time (all times are eastern standard time, based on the 24 hour clock), a Beech P-35, N9740Y, registered to a private owner, and operated as a Title 14 CFR Part 91 personal flight, crashed into Clinch Mountain, about 6 miles north of Rogersville, Tennessee. Instrument meteorological conditions prevailed in the area, and no flight plan was filed. The aircraft incurred substantial damage, and the private-rated pilot, the sole occupant, received fatal injuries. The flight originated from Louisville, Kentucky, the same day about 1532.\nIn Table 3 we find ultrametricity values that are marginally greater than those found for the Brothers Grimm (Table 1). It could be argued that the latter, too, uses its own technical vocabulary. We would need to use more data to see if we can clearly distinguish between the (small) ultrametricity levels of these two corpora."}, {"heading": "4.4 DreamBank", "text": "With dream reports (i.e., reports by individuals on their remembered dreams) we depart from a technical vocabulary, and instead raise the question as to whether dream reports can perhaps be considered as types of fairy tale or story, or even akin to accident reports.\nFrom the Dreambank repository (Domhoff, 2003; DreamBank, 2004; Schneider and Domhoff, 2004) we selected the following collections:\n(1) \u201cAlta: a detailed dreamer,\u201d in period 1985\u20131997, 422 dream reports. (2) \u201cChuck: a physical scientist,\u201d in period 1991\u20131993, 75 dream reports. (3) \u201cCollege women,\u201d in period 1946\u20131950, 681 dream reports. (4) \u201cMiami Home/Lab,\u201d in period 1963\u20131965, 445 dream reports. (5) \u201cThe Natural Scientist,\u201d 1939, 234 dream reports. (6) \u201cUCSC women,\u201d 1996, 81 dream reports.\nTo have adequate length reports, we requested report sizes of between 500 and 1500 words. With this criterion, from (1) we obtained 118 reports, from (2) and (6) we obtained no reports, from (3) we obtained 15 reports, from (4) we obtained 73 reports, and finally from (5) we obtained 8 reports. In all, we used 214 dream reports, comprising 13696 words.\nAs an example, here is the start of the 100th (for us) report: I\u2019m delivering a car to a man \u2013 something he\u2019s just bought, a Lincoln Town Car, very nice. I park it and go down the street to find him \u2013 he turns out to be an old guy, he\u2019s buying the car for nostalgia \u2013 it turns out to be an old one, too, but very nicely restored, in excellent condition. I think he\u2019s black, tall, friendly, maybe wearing overalls. I show him the car and he drives off. I\u2019m with another girl who drove another car and we start back for it but I look into a shop first \u2013 it\u2019s got outdoor gear in it \u2013 we\u2019re on a sort of mall, outdoors but the shops face on a courtyard of bricks. I\u2019ve got something from the shop just outside the doors, a quilt or something, like I\u2019m trying it on, when it\u2019s time to go on for sure so I leave it on the bench. We go further, there\u2019s a group now, and we\u2019re looking at this office facade for the Honda headquarters.\nWith the above we took another set of dream reports, from one individual, Barbara Sanders. A more reliable (according to DreamBank, 2004) set of reports comprised 139 reports, and a second comprised 32 reports. In all 171 reports\nwere used from this person. Typical lengths were about 2500 up to 5322. The total number of words in the Barbara Sanders set of dream reports was 107,791.\nFirst we analyzed all dream reports, furnishing Table 4. In order to look at a more homogeneous subset of dream reports, we then analyzed separately the Barbara Sanders set of 171 reports, leading to Table 5. (Note that this analysis is on a subset of the previously analyzed dream reports, Table 4). The Barbara Sanders subset of 171 reports contained 7044 unique words in all.\nCompared to Table 4 based on the entire dream report collection, Table 5 which is based on one person shows, on average, higher ultrametricity levels. It is interesting to note that the dream reports, collectively, are higher in ultrametricity level than our previous values for \u03b1; and that the ultrametricity level is raised again when the data used relates to one person.\nWe carried out a preliminary study of James Joyce\u2019s Ulysses, comprising 304,414 words in total. We broke this text into 183 separate sequential files, comprising approximately between 1400 and 2000 words each. The number of unique words in these 183 files was found to be 28,649 words. The ultrametricity \u03b1 values for this collection of 183 Joycean texts were found to be less than the Barbara Sanders values, but higher than the global set of all dream reports."}, {"heading": "5 Ultrametric Properties of Words", "text": ""}, {"heading": "5.1 Objectives and Choice of Data", "text": "The foregoing analyses have been based on text segments and their interrelationships. As noted earlier however, correspondence analysis projects both text segments and words, both endowed initially with the \u03c72 metric, into the one Euclidean space. As also observed, this Euclidean factor space takes all interrelationships into consideration. We stress too that we are not using a reduced dimensionality approximation of the factor space, as is often done so as to filter out from the data what is considered to be noise. Instead we use the full Eu-\nclidean and factor space dimensionality because we wish to study the data as given to us but simply endowed with the usual (i.e. unweighted) Euclidean distance. (We also assume no recoding of the input data such as through complete disjunctive or fuzzy or other forms of coding which could turn the \u03c72 distance right away into a Euclidean distance: see Murtagh, 2005, for discussion of such input data recoding.)\nIn order to have a text that ought to contain vestiges of ultrametricity because of subconscious thinking, admittedly subconscious thinking that was afterwards reported on in a fully conscious way, we took the Barbara Sanders dream reports. In section 4.4 we have seen how ultrametric we found this data to be. In discussion of this data provided in Domhoff (2002) he notes that there is \u201castonishing consistency\u201d shown in dreams such as these over long periods of time.\nTaking a set of 139 of the Barbara Sanders dream reports, as used in section 4.4, we used the 2000 most frequently occurring words used in these dream reports including function words. Then we took 30 words to carry out some experimentation with their ultrametric properties. These are listed in Table 6. We selected these words to have some personal names, some words that could be metaphors for the commonplace or the fearful, and some words that could be commonplace and hence banal.\nTwo sets of experiments were carried out. For both experiments, the 30 selected words were given by their Euclidean space vectors resulting from the correspondence analysis, carried out on the 139 dream reports \u00d7 2000 words. So the 30 selected words are vectors in a space of dimensionality min(139 \u2212 1, 2000 \u2212 1) = 138. In the first experiment the ultrametric triangles formed between triples solely on the 30-word set were determined. So for each word, the number of triangles checked was 1\u00d7 (30\u2212 1)\u00d7 (30\u2212 2)/2 = 406. In the second experiment, the ultrametric triangles formed between the selected word and all pairs of the full set of 2000 words were used. The number of triangles checked for each word was 1 \u00d7 (2000\u2212 1)\u00d7 (2000\u2212 2)/2 = 1997001. However some of these have overlapping points, implying zero distances. Rather than 1997001\ntriangles to be checked for each of the 2000 words, instead 1996997 involved no zero-valued distance."}, {"heading": "5.2 General Discussion of Ultrametricity of Words", "text": "General discussion of Table 6 follows.\n\u2022 Note the semantic similarity between \u201croad\u201d and \u201ccar\u201d, clearest when dealing with the 30-word set in isolation, rather than the 30-word set in the full 2000-word context.\n\u2022 Similarly note the semantic similarity between \u201cballoon\u201d and \u201cballoons\u201d.\n\u2022 Regarding the following words, our information is from Domhoff (2002; and further discussion is in Domhoff, 2012).\n\u2022 \u201cDerek\u201d (\u201cH\u201d, high number of ultrametric relationships found with this word): the dreamer, Barbara Sanders, had a former relationship with him.\n\u2022 \u201cMabel\u201d (\u201cL\u201d, relatively low number of ultrametric relationships): coworker. The relatively low number of ultrametric relationships found was based on the full 2000-word set, \u2013 cf. 135192 cases; but when the restricted 30-word set alone was used in isolation a much larger relative number of 60 ultrametric cases was noted.\n\u2022 \u201ccat\u201d (\u201cH\u201d, high number of ultrametric relationships): Barbara Sanders has several cats, treats them well in real life, thinks of them as mistreated in dreams.\n\u2022 \u201cgun\u201d (\u201cH\u201d, high number of ultrametric relationships): Her dreams seem to infer that she used guns when young, but this was not in fact the case.\n\u2022 \u201cHoward\u201d (\u201cH\u201d, high number of ultrametric relationships): ex-husband.\n\u2022 \u201chorse\u201d (\u201cL\u201d, relatively low number of ultrametric relationships): she rides in dreams, fears in real life."}, {"heading": "5.3 Conclusions on the Word Analysis", "text": "Derek, with whom there was a former relationship, and Howard, an ex-husband of Barbara Sanders, both figure relatively highly in terms of ultrametric relationships, as can be seen in Table 6. Admittedly these ultrametric-respecting triplets are few in number compared to the total number of these triplets, viz. 1,996,997 or nearly two million per word.\nThe distribution of the ultrametric-respecting triangles in a data set such as this allows us to assess the statistical significance of ultrametricity of any given word. Our approach is to determine the empirical distribution function (rather than, say, a stochastic graph model). Justification is to have a data-driven baselining rather than an a priori model for the data. Therefore we looked at\nthe approximately two million triangles that are with reference to any word among the 2000 words retained.\nHence for this distribution we used approximately 4000 million triangles. With reference to the third column, therefore, of Table 6, the very maximum number of ultrametric-respecting triangles with account taken of all 2000 words was found as 206,496. To determine this we checked all 2000 words. The very minimum number of ultrametric-respecting triangles is 31,346. These correspond respectively to our \u03b1 ultrametricity coefficients of 0.103403 and 0.015697.\nNote that the results of Table 5 were based on the dream reports. While the word results are different, this just points to different ultrametricity properties in the two dual spaces. Our provisional conclusion is regard to the difference in ultrametricity properties in the dual spaces is that it may be useful to experiment with content tagging (see the Hall/Van de Castle coding system, described at Dreambank, 2004).\nThe measured ultrametricity of the word \u201cDerek\u201d (former relationship) is at the 73.887 percentile, implying a 26% chance of being bettered in this data. The measured ultrametricity of the word \u201cHoward\u201d (ex-husband) is at the 65.583 percentile.\nOur objective in this word analysis has been to indicate the type of vantage points that can be opened up through the topology analysis that has been our focus in this work."}, {"heading": "6 Conclusion", "text": "We studied a range of text corpora, comprising about 1000 texts, or text segments, containing over 1.3 million words. We found very stable ultrametricity quantifications of the text collections, across numbers of most frequent words used to characterize the texts, and sampling of triplets of texts. Notable aspects of our data analysis include: full inherent dimensionality used; full set of words used too in many cases; and finally in section 5, sampling was not used but rather exhaustive processing.\nWe found that in all cases (save, perhaps, the Brothers Grimm versus air accident reports) there was a clear distinction between the ultrametricity values of the text collections.\nSome very intriguing ultrametricity characterizations were found in our work. For example, we found that the technical vocabulary of air accidents did not differ greatly in terms of inherent ultrametricity compared to the Brothers Grimm fairy tales. Secondly we found that novelist Austen\u2019s works were clearly distinguishable from the Grimm fairy tales. Thirdly we found dream reports to have higher ultrametricity level than the other text collections.\nValues of our \u03b1 ultrametricity coefficient were small but revealing and valuable, in the sense of being consistent (i.e. with small variability) and being discriminatory (i.e. between genres).\nIt is interesting to speculate on how one would exploit the \u201cstrands\u201d or \u201cthreads\u201d of ultrametricity, and hence hierarchical structure, that we find. We\nuse these metaphors (\u201cstrands\u201d, \u201cthreads\u201d) with care because an ultrametric triangle possibly shares vertices with a non-ultrametric triangle.\nAll in all however we have presented excellent proof of concept that from empirical \u2013 textual \u2013 data we can determine measures of ultrametricity, or hierarchical symmetry. To that extent we have developed an operational procedure for ranking (at least as a good first stage of processing) manifestations of reasoning in terms of Matte Blanco\u2019s symmetric, on the one hand, and asymmetric, on the other hand, logic."}, {"heading": "Appendix: Pseudo-Code for Assessing Ultrametric-", "text": "Respecting Triplet\nAssumed: vectors i, j, k are in a Euclidean space.\n\u2022 For all triplets i, j, k, consider their Euclidean distances, d1 = d(i, j); d2 = d(j, k); d3 = d(i, k).\n\u2022 Set \u01eb = 1.0e\u221210\n\u2022 Exclude near-0 distances: only if (d1 > \u01eb & d2 > \u01eb & d3 > \u01eb) do the following:\n\u2022 Determine cosines of the three angles in the triangle using scalar product, denoted \u00b7. c1 = (d1 \u00b7 d1 + d2 \u00b7 d2 \u2212 d3 \u00b7 d3)/(2.0 \u00b7 d1 \u00b7 d2) c2 = (d2 \u00b7 d2 + d3 \u00b7 d3 \u2212 d1 \u00b7 d1)/(2.0 \u00b7 d2 \u00b7 d3) c3 = (d1 \u00b7 d1 + d3 \u00b7 d3 \u2212 d2 \u00b7 d2)/(2.0 \u00b7 d1 \u00b7 d3) Order these and we will take the case such that c1 \u2264 c2 \u2264 c3\n\u2022 Wanting the largest cosine to correspond to an angle less than 60 degrees and greater than 0 degree, implying that we have a sufficient condition for an isosceles with small base triangle, we require the following. Allowing less than or equal to 60 degrees encompasses the equilateral triangle case. Angle and cosine vary inversely.\n\u2022 if (c3 \u2265 0.5 & c3 < 1.0) then: Assess difference of angles. Note: 2 degrees = 0.03490656 radians.\na1 = arccos(c1)\na2 = arccos(c2) if ( |a1\u2212a2| < 0.03490656) then we have we have an ultrametric-respecting triplet."}], "references": [{"title": "Using content analysis to study dreams: applications and implications for the humanities", "author": ["G.W. Domhoff"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "The Scientific Study of Dreams: Neural Networks, Cognitive Development and Content Analysis", "author": ["G.W. Domhoff"], "venue": "American Psychological Association,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "Barb Sanders:  our best case study to date, and one that can be built upon", "author": ["G.W. Domhoff"], "venue": "http://www2.ucsc.edu/dreams/Findings/barb sanders.html (accessed", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Are ground states of 3D \u00b1 J spin glasses ultrametric?", "author": ["A.K. Hartmann"], "venue": "Europhysics Letters,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Classification et Analyse", "author": ["I.C. Lerman"], "venue": "Ordinale des Donne\u0301es, Dunod, Paris,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1981}, {"title": "The Unconscious as Infinite Sets: An Essay in Bi-Logic, With a New Foreword by Eric Rayner, Karnac", "author": ["I. Matte Blanco"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1998}, {"title": "A survey of recent advances in hierarchical clustering algorithms", "author": ["F. Murtagh"], "venue": "The Computer Journal,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1983}, {"title": "Multidimensional Clustering Algorithms, Physica-Verlag", "author": ["F. Murtagh"], "venue": "Wu\u0308rzburg,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1985}, {"title": "On ultrametricity, data coding, and computation", "author": ["F. Murtagh"], "venue": "Journal of Classification,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "Correspondence Analysis and Data Coding with Java and R", "author": ["F. Murtagh"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "Ultrametric model of mind, I: Review", "author": ["F. Murtagh"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "An algorithm for suffix stripping", "author": ["M.F. Porter"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1980}, {"title": "Angles D\u2019Auriac and B. Doucot, \u201cOn the degree of ultrametricity", "author": ["J.C.R. Rammal"], "venue": "Le Journal de Physique \u2013 Lettres,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1985}, {"title": "Virasoro, \u201cUltrametricity for physicists", "author": ["R. Rammal", "M.A.G. Toulouse"], "venue": "Reviews of Modern Physics,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1986}, {"title": "Domhoff, The Quantitative Study of Dreams, http://dreamresearch.net", "author": ["G.W.A. Schneider"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}, {"title": "Setting in social networks: A measurement model", "author": ["M. Schweinberger", "T.A.B. Snijders"], "venue": "Sociological Methodology,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "On the perceptual structure of face", "author": ["A. Treves"], "venue": "space\u201d, BioSystems,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1997}], "referenceMentions": [], "year": 2012, "abstractText": "In a companion paper, Murtagh (2012), we discussed howMatte Blanco\u2019s work linked the unrepressed unconscious (in the human) to symmetric logic and thought processes. We showed how ultrametric topology provides a most useful representational and computational framework for this. Now we look at the extent to which we can find ultrametricity in text. We use coherent and meaningful collections of nearly 1000 texts to show how we can measure inherent ultrametricity. On the basis of our findings we hypothesize that inherent ultrametricty is a basis for further exploring unconscious thought processes.", "creator": "LaTeX with hyperref package"}}}