{"id": "1203.3531", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2012", "title": "Solving Multistage Influence Diagrams using Branch-and-Bound Search", "abstract": "A branch-and-bound approach to solving influ- ence diagrams has been previously proposed in the literature, but appears to have never been implemented and evaluated - apparently due to the difficulties of computing effective bounds for the branch-and-bound search. In this paper, we describe how to efficiently compute effective bounds, and we develop a practical implementa- tion of depth-first branch-and-bound search for influence diagram evaluation that outperforms existing methods for solving influence diagrams with multiple stages. It will therefore be possible to combine multiple stages of analysis of the top-tier results of the relevant level of the classification hierarchy to determine the relevance of the relevant data sources to the problem-solving problem.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Thu, 15 Mar 2012 11:17:56 GMT  (287kb)", "http://arxiv.org/abs/1203.3531v1", "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["changhe yuan", "xiaojian wu", "eric a hansen"], "accepted": false, "id": "1203.3531"}, "pdf": {"name": "1203.3531.pdf", "metadata": {"source": "CRF", "title": "Solving Multistage Influence Diagrams using Branch-and-Bound Search", "authors": ["Changhe Yuan", "Xiaojian Wu", "Eric A. Hansen"], "emails": ["cyuan@cse.msstate.edu,", "hansen@cse.msstate.edu,", "xw83@msstate.edu"], "sections": [{"heading": null, "text": "A branch-and-bound approach to solving influence diagrams has been previously proposed in the literature, but appears to have never been implemented and evaluated \u2013 apparently due to the difficulties of computing effective bounds for the branch-and-bound search. In this paper, we describe how to efficiently compute effective bounds, and we develop a practical implementation of depth-first branch-and-bound search for influence diagram evaluation that outperforms existing methods for solving influence diagrams with multiple stages."}, {"heading": "1 Introduction", "text": "An influence diagram [7] is a compact representation of the relations among random variables, decisions, and preferences in a domain that provides a framework for decision making under uncertainty. Many algorithms have been developed to solve influence diagrams [2, 3, 8, 15, 17, 18, 19, 21]. Most of these algorithms, whether they build a secondary structure or not, are based on the bottom-up dynamic programming approach. They start by solving small low-level decision problems and gradually build on these results to solve larger problems until the solution to the global-level decision problem is found. The drawback of these methods is that they can waste computation in solving decision scenarios that have zero probability or that are unreachable from any initial state by following an optimal decision policy.\nThis drawback can be overcome by adopting a branch-andbound approach to solving an influence diagram that uses a search tree to represent all possible decision scenarios. This approach can use upper bounds on maximum utility to prune branches of the search tree that correspond to lowquality decisions that cannot be part of an optimal policy; it can also prune branches that have zero probability.\nA branch-and-bound approach to influence diagram evaluation appears to have been first suggested by Pearl [16]. He proposed it as an improvement over the classic method of unfolding an influence diagram into a decision tree and solving it using the rollback method, which itself is a form of dynamic programming [7]. In Pearl\u2019s words:\nA hybrid method of evaluating influence diagrams naturally suggests itself. It is based on the realization that decision trees need not actually be generated and stored in their totality to produce the optimal policy. A decision tree can also be evaluated by traversing it in a depth-first, backtracking manner using a meager amount of storage space (proportional to the depth of the tree). Moreover, branch-and-bound techniques can be employed to prune the search space and permit an evaluation without exhaustively traversing the entire tree... an influence diagram can be evaluated by sequentially instantiating the decision and observation nodes (in chronological order) while treating the remaining chance nodes as a Bayesian network that supplies the probabilistic parameters necessary for tree evaluation. (p. 311)\nHowever, neither Pearl nor anyone else appears to have followed up on this suggestion and implemented such an algorithm. The apparent reason is the difficulty of computing effective bounds to prune the search tree. Qi and Poole [17] proposed a similar search-based method for solving influence diagrams, but with no method for computing bounds; in fact, their implementation relied on the trivial infinity upper bound to guide the search. Recently, Marinescu [12] proposed a related search-based approach to influence diagram evaluation. But again, he proposed no method for computing bounds; his implementation relies on brute-force search. Even without bounds to prune the search space, note that both Qi and Poole and Marinescu argue that a search-based approach has advantages \u2013 for example, it can prune branches that have zero probability.\nIn this paper, we describe an implemented depth-first branch-and-bound search algorithm for influence diagram evaluation that includes efficient techniques for computing bounds to prune the search tree. To compute effective bounds, our algorithm adapts and integrates two previous contributions. First, we adapt the work of Nilsson and Ho\u0308hle [14] on computing an upper bound on the maximum expected utility of an influence diagram. The motivation for their work was to bound the quality of strategies found by an approximation algorithm for solving limitedmemory influence diagrams, and their bounds are not in a form that can be directly used for branch-and-bound search. We show how to adapt their approach to branchand-bound search. Second, we adapt the recent work of Yuan and Hansen [20] on solving the MAP problem for Bayesian networks using branch-and-bound search. Their work describes an incremental method for computing upper bounds based on join tree evaluation that we show allows such bounds to be computed efficiently during branch-andbound search. In addition, we describe some novel methods for constructing the search tree and computing probabilities and bounds that contribute to an efficient implementation. Our experimental results show that this approach leads to an exact algorithm for solving influence diagrams that outperforms existing methods for solving multistage influence diagrams."}, {"heading": "2 Background", "text": "We begin with a brief review of influence diagrams and algorithms for solving them. We also introduce an example of multi-stage decision making that will serve to illustrate the results of the paper."}, {"heading": "2.1 Influence Diagrams", "text": "An influence diagram is a directed acyclic graphG containing variablesV of a decision domain. The variables can be classified into three groups, V = X \u222aD \u222aU, where X is the set of oval-shaped chance variables that specify the uncertain decision environment,D is the set of square-shaped decision variables that specify the possible decisions to be made in the domain, and U are the diamond-shaped utility variables representing a decision maker\u2019s preferences. As in a Bayesian network, each chance variable Xi \u2208 X is associated with a conditional probability distribution P (Xi|Pa(Xi)), where Pa(Xi) is the set of parents of Xi inG. Each decision variableDj \u2208 D has multiple information states, where an information state is an instantiation of the variables with arcs leading into Dj ; the selected action is conditioned on the information state. Incoming arcs into a decision variable are called information arcs; variables at the origin of these arcs are assumed to be observed before the decision is made. These variables are called the information variables of the decision. No-forgetting is typically\nassumed for an influence diagram, which means the information variables of earlier decisions are also information variables of later decisions. We call these past information variables the history, and, for convenience, we assume that there are explicit information arcs from history information variables to decision variables. Finally, each utility node Ui \u2208 U represents a function that maps each configuration of its parents to a utility value the represents the preference of the decision maker. (Utility variables typically do not have other variables as children except multi-attribute utility/super-value variables.)\nThe decision variables in an influence diagram are typically assumed to be temporally ordered, i.e., the decisions have to be made in a particular order. Suppose there are n decision variablesD1, D2, ..., Dn in an influence diagram. The decision variables partition the variables in X into a collection of disjoint sets I0, I1, ..., In. For each k, where 0 < k < n, Ik is the set of chance variables that must be observed between Dk and Dk+1. I0 is the set of initial evidence variables that must be observed before D1. In is the set of variables left unobserved when decision Dn is made. Therefore, a partial order \u227a is defined on the influence diagram overX \u222aD, as follows:\nI0 \u227a D1 \u227a I1 \u227a ... \u227a Dn \u227a In. (1)\nA solution to the decision problem defined by an influence diagram is a series of decision rules for the decision variables. A decision rule for Dk is a mapping from each configuration of its parents to one of the actions defined by the decision variable. A decision policy (or strategy) is a series of decision rules with one decision rule for each decision variable. The goal of solving an influence diagram is to find an optimal decision policy that maximizes the expected utility. The maximum expected utility is equal to\u2211\nI0\nmax D1 ... \u2211 In\u22121 max Dn \u2211 In P (X|D) \u2211 j Uj(Pa(Uj)).\nIn general, the summations and maximizations are not commutable. The methods presented in Section 2.3 differ in the various techniques they use to carry out the summations and maximizations in this order.\nRecent research has begun to relax the assumption of ordered decisions. In particular, Jensen proposes the framework of unconstrained influence diagrams to allow a partial ordering among the decisions [9]. Other research relaxes the no-forgetting assumption, in particular, the framework of limited-memory influence diagrams [10]. Although the approach we develop can be extended to these frameworks, we do not consider the extension in this paper."}, {"heading": "2.2 Example", "text": "To illustrate decision making using multi-stage influence diagrams, consider a simple maze navigation problem [6,\n14]. Figure 1 shows four instances of the problem. The shaded tiles represent walls, the white tiles represent movable space, and the white tiles with a star represent goal states. An agent is randomly placed in a non-goal state. It has five available actions that it can use to move toward the goal: it can move a single step in any of the four compass directions, or it can stay in place. The effect of a movement action is stochastic. The agent successfully moves in the intended direction with probability 0.89. It fails to move with probability 0.089, it moves sideways with probability 0.02 (0.01 for each side), and it moves backward with probability 0.001. If movement in some direction would take it into a wall, that movement has probability zero, and the remaining probabilities are normalized. The agent has four sensors, one for each direction, which sense whether the neighboring tile in that direction is a wall. Each sensor is noisy; it detects the presence of a wall correctly with probability 0.9 and mistakenly senses a wall when none is present with probability 0.05. The agent chooses an action at each of a sequence of stages. If the agent is in the goal state after the final stage, it receives a utility value of 1.0; otherwise, it receives a utility value of 0.0.\nFigure 2(a) shows the influence diagram for a two-stage version of the maze problem. The variables xi and yi represent the location coordinates of the agent at time i, the variables {nsi, esi, ssi, wsi} are the sensor readings in four directions at the same time point, and the variable di represents the action taken by the agent. The utility variable u assigns a value depending on whether or not the agent is in the goal state after the last action is taken. Since the same variables occur at each stage, we can make the influence diagram arbitrarily large by increasing the number of stages."}, {"heading": "2.3 Evaluation algorithms", "text": "Many approaches have been developed for solving influence diagrams. The simplest is to unfold an influence diagram into an equivalent decision tree and solve it in that form [7]. Another approach called arc reversal solves an influence diagram directly using techniques such as arcreversal and node-removal [15, 18]; when a decision variable is removed, we obtain the optimal decision rule for the decision. Several methods reduce influence diagrams into\nBayesian networks by converting decision nodes into random variables such that the solution of an inference problem in the Bayesian network correspond to the optimal decision policy for the influence diagram [3, 21]. Another method [19] transforms an influence diagram into a valuation network and applies variable elimination to solve the valuation network. Recent work compiles influence diagrams into decision circuits and uses the decision circuits to compute optimal policies [2]; this approach takes advantage of local structure present in an influence diagram, such as deterministic relations.\nIn the following, we describe a state-of-the-art method for solving an influence diagram using a strong join tree [8]. This method is viewed by many as the fastest general algorithm, and we use its performance as a benchmark for our branch-and-bound approach. A join tree is strong if it has at least one clique, R, called the strong root, such that for any pair of adjacent cliques, C1 and C2, with C1 closer to R than C2, the variables in separator S = C1 \u2229 C2 must appear earlier in the partial order defined in Equation (1) than C2 \\ C1. A strong join tree for the influence diagram in Figure 2(a) is shown in Figure 2(b).\nAn influence diagram can be solved exactly by message passing on the strong join tree. Each clique C in the join tree contains two potentials, a probability potential \u03d5C and a utility potential \u03c8C . For clique C2 to send a message to clique C1, \u03d5C1 and \u03c8C1 should be updated as follows [8]:\n\u03d5\u2032C1 = \u03d5C1 \u00d7 \u03c8S ; \u03c8 \u2032 C1 = \u03c8C1 + \u03c8S \u03d5S ;\nwhere \u03d5S = \u2211 C2\\S \u03d5C2 ; \u03c8S = max C2\\S \u03d5C2 \u00d7 \u03c8C2 .\nIn contrast to the join tree algorithm for Bayesian networks [11], only the collection phase of the algorithm is needed to solve an influence diagram. After the collection phase, we can obtain the maximum expected utility by carrying out the remaining summations and maximizations in the root. In addition, we can extract the optimal decision rules for the decision variables from some of the cliques that contain these variables.\nBuilding a join tree for a Bayesian network may fail if the join tree is too large to fit in memory. This is also true for influence diagrams. In fact, the memory requirement of a strong join tree for an influence diagram is even higher because of the constrained order in Equation (1). Consequently, the join tree algorithm is typically infeasible for solving all but very small influence diagrams."}, {"heading": "3 Computing bounds", "text": "To implement a branch-and-bound algorithm for solving influence diagrams, we need a method for computing bounds \u2013 in particular, for computing upper bounds on the utility that can be achieved beginning at a particular stage of the problem, given the history up to that stage. A trivial upper bound is the largest state-dependent value of the utility node of the influence diagram. In this section, we discuss how to compute more informative bounds. There has been little previous work on this topic. Nilsson and Ho\u0308hle [14] develop an approach to bounding the suboptimality of policies for limited-memory influence diagrams that are found by an approximation algorithm. Dechter [4] describes an approach to computing upper bounds in an influence diagram that is based on mini-bucket partitioning. Neither work considers how to use these bounds in a branch-and-bound search algorithm.\nThe approach we develop in the rest of this paper is based on the work of Nilsson and Ho\u0308hle [14], which we extend by showing how it can be used to compute bounds for branchand-bound search. The general strategy is to create an influence diagram with a value that is guaranteed to be an upper bound on the value of the original influence diagram, but that is also much easier to solve. We use the fact that additional information can only increase the value of an influence diagram. Since this reflects the well-known fact that information value is non-negative, we omit (for space reasons) a proof of the following theorem. Theorem 1. Let G be an influence diagram and D a decision variable in G. Let I be D\u2019s information variables and R another set of random variables in G that are nondescendants of D. Then the influence diagram G\u2217 that results from making R into information variables by adding\ninformation arcs from each variable in R to D is guaranteed to have a maximum expected utility that is greater than or equal to the maximum expected utility forG. We callG\u2217 an upper-bound influence diagram for G.\nUse of an upper-bound influence diagram to compute bounds only makes sense if the upper-bound influence diagram is simpler and much easier to solve than the original influence diagram. In fact, adding information arcs to an influence diagram can simplify its evaluation by making some other information variables non-requisite. An information variable Ii is said to be non-requisite [10, 13] for a decision node D if\nIi \u22a5 (U \u2229 de(D))|D \u222a (Pa(D) \\ {Ii}), (2)\nwhere de(D) are the descendants of D. A reduction of an influence diagram is obtained by deleting all the nonrequisite information arcs [14].\nBecause of the no-forgetting assumption, a decision variable at a late stage may have a large number of history information variables. For decision making under imperfect information, all of these information variables are typically requisite. As a result, the size of the decision rules grows exponentially as the number of decision stages increases, which is the primary reason multi-stage influence diagrams are very difficult to solve.\nIn constructing an upper-bound influence diagram, we want to add information arcs that make some or all of the history information variables for a decision node non-requisite, in order to simplify the influence diagram and make it easier to solve. We adopt the strategy proposed by Nilsson and Ho\u0308hle [14]. Let nd(X) be the non-descendant variables of variable X , let fa(X) = Pa(X) \u222a {X} be the family of variable X (i.e., the variable and its parents), let fa(X) = \u222aXi\u2208Xfa(Xi) be the family of the set of variables X (i.e., the variables and their parents), and let\u25b3j be {D1, ...Dj} be a sequence of decision variables from stage 1 to stage j. The following theorem is proved by Nilsson and Ho\u0308hle [14]. Theorem 2. For an influence diagram with the constrained order in Equation (1), if we add to each decision variable Dj the following new information variables in the order of j = n, ..., 1,\nNj = argminB\u2286(Bj\u2229nd(Dj)){|B||fa(\u25b3j) \u22a5 (U \u2229 de(Dj))|(B \u222a {Dj})}, (3)\nwhere\nBj = { U \u222aD j=k, \u2229ki=j+1{n \u2208 V |n \u22a5 (U \u2229 de(Dj))|fa(Di)} j<k,\nthe following holds for any Dj in the resulting influence diagram:\n(de(Dj) \u2229U) \u22a5 fa(\u25b3i\u22121)|fa(Dj). (4)\nWhat this theorem means is that for each decision variable Dj in an influence diagram, there is a set of information variables Nj such that the optimal policy for Dj depends only on these information variables, and is otherwise history-independent. Note that the setNj for decision variable Dj can contain both information variables from the original influence diagram and information variables created by adding new information arcs to the diagram. The set Nj of information variables can be interpreted as the current \u201cstate\u201d of the decision problem, such that if the decision maker knows the current state, it does not need to know any previous history in order to select an optimal action; in this sense, the state satisfies the Markov property.\nConsider a decision-making problem in a partially observable domain, such as the maze domain of Section 2.2. The agent cannot directly observe its location in the maze and must rely on imperfect sensor readings to infer its location. In this domain, adding information arcs from the location variables to a decision variable, so that the agent know the current location at the time it chooses an action, makes both current and history sensor readings non-requisite, which results in a much simpler influence diagram, which in this case serves as an upper-bound influence diagram.\nWe callNj a sufficient information set (SIS) forDj . The intuition behind this approach is illustrated by Figure 3. The shaded oval shows the SIS set ND for decision D. The past state affects the variables in ND \u222a {D}, illustrated by the arc labeled 1, and ND \u222a {D} affects the future state, as illustrated by arc 2. The future state further determines the values of the utility variables. ND \u222a {D} d-separates the past and future states and prevents the direct influence shown by arc 3. The concept of a sufficient information set is related to the concept of extremality, as defined in [21], and the concept of blocking, as defined in [13].\nTo construct an upper-bound influence diagram, we find the SIS set for each decision in the order of Dn, ..., D1 and make the variables in each SIS set information variables for the corresponding decisions. We then delete the nonrequisite information arcs. Consider the influence diagram in Figure 4(a) as an example. The information set for d1 is originally {ns0, es0, ss0, ws0, d0, ns1, es1, ss1, ws1}. We find that its sufficient information (SIS) set is {x1, y1}. We\nalso find that the SIS set for d0 is {x0, y0}. By making {x1, y1} and {x0, y0} information variables for d1 and d0 respectively, and reducing the influence diagram, we obtain the much simpler influence diagram in Figure 4(a). The strong join tree for the new influence diagram is shown in Figure 4(b), which is also much smaller than the strong join tree for the original model. Since the upper-bound influence diagram assumes the actual location is directly observable to the agent, it effectively transforms a partially observable decision problem into a fully observable one. The resulting influence diagram and, hence, its join tree is much easier to solve.\nFinding the sufficient information set (SIS) for a decision variable in an influence diagram is equivalent to finding a minimum separating set in the moralized graph of the influence diagram [14]. Acid and de Campos [1] propose an algorithm based on the Max-flow Min-cut algorithm [5] for finding a minimum separating set between two sets of nodes in a Bayesian network with some of the separating variables being fixed. We use their algorithm to find the SIS sets. The two sets of nodes are fa(\u25b3j) and U \u2229 de(Dj). The only fixed separating variable is Dj . The algorithm first introduces two dummy variables, source and sink, to the moralized graph. The source is connected to the neighboring variables of fa(\u25b3j), and the sink to the variables in de(Dj)\u2229an(U\u2229de(Dj)). We then create a max-flow network out of the undirected graph by assigning each edge capacity 1.0. A solution gives a minimum separating set between the sink and source that contains Dj .\nWe briefly mention some issues that are not described by Nilsson and Ho\u0308hle [14], but that need to be considered in an implementation. The first issue is how to define the size of an SIS set. Theorem 2 uses the cardinality of the SIS set as the minimization criterion. Another viable choice is to use weight, defined as the product of number of states, of the variables in an SIS set as the minimization criterion.\nThe relation between these two criteria is similar to the relation between treewidth and weight in constructing a junction tree. While treewidth tells us how complex a Bayesian network is at the structure level, weight provides an idea on how large the potentials of the junction tree are at the quantitative level. Both methods have been used. In our implementation, we use the cardinality.\nA second issue is that multiple candidate SIS sets may exist for a decision variable. In that case, we need some criterion for selecting the best one. In our implementation, we select the candidate SIS set that is closest to the descendant utility variables of the decision. Note that other candidate sets are all d-separated from the utility node by the closest SIS set. This choice has the advantage that the resulting influence diagram is easiest to evaluate; however, other choices may result in an influence diagram that gives a tighter bound."}, {"heading": "4 Branch-and-bound search", "text": "In this section, we describe how to use the upper-bound influence diagram to compute bounds for a depth-first branch-and-bound search algorithm that solves the original influence diagram. We begin by showing how to represent the search space as an AND/OR tree. A naive approach to computing bounds requires evaluating the entire upper-bound influence diagram at each OR node of the search tree, which is computationally prohibitive. To make branch-and-bound search feasible, we rely on an incremental approach to computing bounds proposed by Yuan and Hansen [20] for solving the MAP problem in Bayesian networks using branch-and-bound search. We show how to adapt that approach in order to solve influence diagrams efficiently."}, {"heading": "4.1 AND/OR tree search", "text": "We represent the search space for influence diagram evaluation as an AND/OR tree. The nodes in an AND/OR tree are of two types: AND nodes and OR nodes. AND nodes correspond to chance variables; a probability is associated with each arc originating from an AND node and the probabilities of all the arcs from an AND node sum to 1.0. The OR nodes correspond to decision variables. Each of the leaf nodes of the tree has a utility value that is derived from the utility node of the influence diagram.\nQi and Poole [17] create an AND/OR tree in which each layer of AND nodes alternates with a layer of OR nodes. Each AND node in this tree corresponds to the information set of a decision variable in the influence diagram, which is a set of information variables. To compute the probability for each arc emanating from an AND node in this tree, however, it is necessary to have the joint probability distributions of all the information sets; these are often not readily available, since variables in the same informa-\ntion set can belong to different clusters of a join tree. For computational convenience, our AND/OR tree is based on the structure of the strong join tree in Figure 4(b). For the maze example, we order the variables in the information set {ns0, es0, ss0, ws0} according to the order in Equation (5). Note that the join tree does not have a clique that contains all four variables; in fact, they are all in different cliques. So we consider the variables one by one. That means that our AND/OR tree allows several layers of AND nodes to alternate with a layer of OR nodes. See Figure 5 for an example of the kind of AND/OR tree constructed by our search algorithm, and note that the first four layers of this AND/OR tree are all AND layers.\nEach path from the root of the AND/OR tree to a leaf corresponds to a complete instantiation of the information variables and decision variables of the influence diagram, that is, a complete history. Since we use the AND/OR tree to find an optimal decision policy for the original influence diagram, we have to construct an AND/OR tree that is consistent with the original constrained order. For the influence diagram in Figure 2(a), the partial order is\n{ns0, es0, ss0, ws0} \u227a {d0} \u227a {ns1, es1, ss1, ws1} \u227a {d1} \u227a {x0, y0, x1, y1, x2, y2, u}, (5)\nand the decision variables must occur in this order along any branch.\nWe define a valuation function for each node in an AND/OR tree as follows: (a) for a leaf node, the value is its utility value; (b) for an AND node, the value of is the sum of the values of its child nodes weighted by the probabilities of the outgoing arcs; (c) for an OR node, the value is the maximum of the summed utility values of each child node and corresponding arc. We use this valuation function to find an optimal strategy for the influence diagram.\nWe represent a strategy for a multi-stage influence diagram as a policy tree that is defined as follows. A policy tree of an AND/OR tree is a subtree such that: (a) it consists of the root of the AND/OR tree; (b) if a non-terminal AND node is in the policy tree, all its children are in the policy tree; and (c) if a non-terminal OR node is in the policy\ntree, exactly one of its children is in the policy tree. Given an AND/OR tree that represents all possible histories and strategies for an influence diagram, the influence diagram is solved by finding a policy tree with the maximum value at the root, where the value of the policy tree is computed based on the valuation function. Depth-first branch-andbound search can be used to find an optimal policy tree.\nThe AND/OR tree is constructed on-the-fly during the branch-and-bound search, and it is important to do so in a way that allows the probabilities and values to be computed as efficiently as possible. We use the maze problem and the AND/OR tree in Figure 5 as an example. (The upper-bound influence diagram and join tree are shown in Figure 4.) We have already pointed out that including more layers in our AND/OR tree allows us to more easily use the probabilities and utilities computed by the join tree. If we start by expanding ns0 (where expanding a node refers to generating its child nodes in the AND/OR tree), we need the probabilities of P (ns0) to label the outgoing arcs. We can readily look up the probabilities from clique (0, 1, 2) after an initial full join tree evaluation. Note that we use the join tree of the upper-bound influence diagram to compute the probabilities. We can do that because these probabilities are the same as those computed from the original influence diagram. This is due to the fact that the same set of actions will reduce both models into the same Bayesian networks. Adding information arcs to an influence diagram, in order to create an upper-bound influence diagram, only changes the expected utilities of the decision variables.\nAfter expanding ns0, we expand any of {es0, ss0, ws0}. Suppose the next variable is es0, we need the conditional probabilities of es0 given ns0. These probabilities can be computed by setting the state of ns0 as new evidence to the join tree and evaluating the join tree again. The same process is used in expanding {ss0, ws0}.\nNote that we do not have to expand one variable at a time. If a clique has multiple variables in the same information set, the variables can be expanded together because a joint probability distribution over them can be easily computed. Expanding them together also saves the need to do marginalization. For example, variables x1, y1, x2, y2 (7,8,14,15) are in the same information group and also reside in a same clique. In this case, we can expand them as a single layer in the AND/OR tree.\nAfter {ns0, es0, ss0, ws0} are expanded, we expand d0 as an OR layer. This is where the upper bounds are needed. We set the states of {ns0, es0, ss0, ws0} as evidence to the join tree and compute the expected utility values for d0 by reevaluating the join tree. The expected utilities of d0 are upper bounds for the same decision scenarios of the original model. We can use the upper bounds to select the most promising decision alternative to search first. The exact value will be returned once the subtree is searched. If the\nvalue is higher than the upper bounds of the remaining decision alternatives, these alternatives are immediately pruned because they cannot be part of an optimal decision policy. We repeat the above process until a complete policy tree is found."}, {"heading": "4.2 Incremental join tree evaluation", "text": "It is clear that repeated join tree evaluation has to be performed in computing the upper bounds and conditional probabilities. A naive approach is at each time to set the states of instantiated variables as evidence and perform a full join tree evaluation. However, that is too costly. We can use an efficient incremental join tree evaluation method to compute the probabilities and upper-bound utilities, based on the incremental join tree evaluation method proposed by Yuan and Hansen [20] for solving the MAP problem.\nThe key idea is that we can choose a particular order of the variables that satisfies the constraints of Equation (5) such that an incremental join tree evaluation scheme can be used to compute the information. Given such an order, we know exactly which variables have been searched and which variable will be searched next at each search step. We only need to send messages from the parts of the join tree that contain the already searched variables to a clique with the next search variable. For example, after we search es0, the only message needs to be sent to obtain P (ns0|es0) is the message from clique (0, 1, 3) to (0, 1, 2). There is no need to evaluate the whole join tree. If we choose the following search order for the maze problem\nns0, es0, ss0, ws0, d0, ns1, es1, ss1, ws1, d1, x0, y0,\nx1, y1, x2, y2,\nwe can use an incremental message passing in the direction of the dashed arc in Figure 4(b) to compute the probabilities and upper bounds needed in one downward pass of a depthfirst search.\nBoth message collection and distribution are needed in this new scheme, unlike evaluating a strong join tree for the original influence diagram. The messages being propagated contain two parts: utility potentials and probability potentials. The distribution phase is typically needed to compute the conditional probabilities. For example, suppose we decide to expand es0 before ns0, we have to send a message from clique (0, 1, 3) to (0, 1, 2) to obtain P (ns0|es0). We only need to send the probability potential in message distribution. We do not need to send utility potentials because past payoffs do not count towards the expected utilities of future decisions."}, {"heading": "4.3 Efficient backtracking", "text": "We use depth-first branch-and-bound (DFBnB) to utilize the efficient incremental bound computation. Depth-first\nsearch makes sure that the search need not jump to a different search branch before backtracking is needed. In other words, the join tree only needs to work with one search history at a time.\nWe do need to backtrack to a previous search node once we finish a search branch or realize that a search branch is not promising and should be pruned. We need to retract all the newly set evidence since the generation of that search node and restore the join tree to a previous state. One way to achieve this is to reinitialize the join tree with correct evidence and perform a full join tree evaluation, which we have already pointed out is too costly. Instead, we cache the potentials and separators along the message propagation path before changing them by either setting evidence or overriding them with new messages. When backtracking, we simply restore the most recently cached potentials and separators in the reverse order. The join tree will be restored to the previous state with no additional computations. This backtracking method is much more efficient than reevaluating the whole join tree. For solving the MAP problem for Bayesian networks, Yuan and Hansen [20] show that the incremental method is more than ten times faster than full join tree evaluation in depth-first branchand-bound search."}, {"heading": "5 Empirical Evaluation", "text": "We compared the performance of our algorithm against both the join tree algorithm [8] and exhaustive search of the AND/OR tree (i.e., no bounds are used for pruning). Experiments were run on a 2.4 GHz Duo processor with 3 gigabytes of RAM running Windows XP.\nThe results in Table 1 are for the two maze problems in Figure 1, which we solved for different numbers of stages. When there are only two or three stages, the join tree al-\ngorithm is most efficient. This is because the strong join trees for these influence diagrams are rather small and can be built successfully. Once the join trees are built, only one collection phase is necessary to solve the influence diagram; by contrast, the depth-first branch-and-bound algorithm (DFBnB) algorithm must perform repeated message propagations to compute upper bounds and probabilities during the search. For more then three stages, however, the join tree algorithm cannot solve the maze models because the strong join trees are too large to fit in memory. Because the exhaustive search algorithm only needs to store the search tree and policy, it can solve the maze models for up to four stages, although it takes more then 45 minutes to do so. The DFBnB algorithm can solve the maze models for up to five stages in less time than it takes the exhaustive search algorithm to solve them for four stages, demonstrating the advantage of using bounds to prune the search tree. Table 1 includes the number of times a branch of the search tree is pruned based on bounds, as well as the number of times a branch with zero probability is pruned. For the maze models with their original parameter settings, every branch of the search tree has non-zero probability.\nPrevious work has argued that one of the advantages of search algorithms for influence diagram evaluation is that they can prune branches of the search tree that have zero probability, even without bounds [12, 17]. To test this argument, as well as to illustrate the effect of different problem characteristics on algorithm performance, we modified the maze models described in Section 2.2. First, we removed some noise from the sensors. Each of the four sensors reports a wall in the corresponding direction of the compass. In the original problem, each sensor is noisy; it detects the presence of a wall correctly with probability 0.9 and mistakenly senses a wall when none is present with probability 0.05. As a result, every sensor reading is possible in every state and there are no zero-probability branches. We\nmodified the model so that each sensor accurately detects whether a wall is present in its direction of the compass. With this change, the maze problem remains partially observable, but the search tree contains many zero-probability branches, as can be seen from the results in Table 2. Since the search algorithms can prune zero-probability branches, the exhaustive search algorithm can now solve the problem for up to five stages and the DFBnB algorithm can solve the problem for up to six stages.\nWe next made an additional change to the transition probabilities for actions. In the original problem, the agent successfully moves in the intended direction with probability 0.89 (as long as there is not a wall). It fails to move with probability 0.089, it moves sideways with probability 0.02 (0.01 for each side), and it moves backward with probability 0.001. We modified these transition probabilities so that the agent still moves in the intended direction with probability 0.89; but otherwise, it stays in the same position with probability 0.11. The effects of the agent\u2019s actions are still stochastic, but they are more predictable, and this allows the search tree to be pruned even further. As a result, the\nexhaustive search algorithm can solve the problem for up to six stages and the DFBnB algorithm can solve the problem for up to seven stages.\nNote that changing the problem characteristics has no effect on the performance of the join tree algorithm. The join tree algorithm solves the influence diagram for all information states, including those that have zero probability and those that are unreachable from the initial state; as a result, its memory requirements explode exponentially in the number of stages and the algorithm quickly becomes infeasible. Although the policy tree that is returned by the search algorithms can also grow exponentially in the number of stages, it does so much more slowly because so many branches can be pruned. As is vividly shown by the results for the two different mazes and for different parameter settings, the performance of the search algorithms is sensitive to problem characteristics \u2013 precisely because the search algorithms exploit a form of problem structure that is not exploited by the join tree algorithm. In addition, the results show the effectiveness of bounds in scaling up the searchbased approach."}, {"heading": "6 Conclusion", "text": "We have described the first implementation of a depthfirst branch-and-bound search algorithm for influence diagram evaluation. Although the idea has been proposed before, we adapted and integrated contributions from related work and introduced a number of new ideas to make the approach computationally feasible. In particular, we described an efficient approach for using the join tree algorithm to compute upper bounds to prune the search tree. The idea is to generate an upper-bound influence diagram by allowing each decision variable to be conditioned on additional information that makes the remaining history nonrequisite, thus simplifying the influence diagram. Then a join tree of the upper-bound influence diagram is used to incrementally compute upper bounds for the depth-first branch-and-bound search. We have also described a new approach to constructing the search tree based on the structure of the strong join tree of the upper-bound influence diagram. Experiments show that the resulting depth-first branch-and-bound search algorithm outperforms the stateof-the-art join tree algorithm in solving multistage influence diagrams, at least when there are more than three stages.\nWe are currently considering how to extend this approach to solve limited-memory influence diagrams [10], which typically have many more stages. We are also exploring approaches to compute more accurate bounds for pruning the search tree. Finally, we are considering approximate and bounded-optimal search algorithms for solving larger influence diagrams using the same upper bounds and AND/OR search tree.\nAcknowledgments This research was support in part by NSF grants IIS-0953723 and EPS-0903787, and by the Mississippi Space Grant Consortium and NASA EPSCoR program."}], "references": [{"title": "An algorithm for finding minimum d-separating sets in belief networks", "author": ["S. Acid", "L. de Campos"], "venue": "In Proceedings of the 12th Annual Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1996}, {"title": "Evaluating influence diagrams with decision circuits", "author": ["D. Bhattacharjya", "R. Shachter"], "venue": "In Proceedings of the Twenty- Third Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "A method for using belief networks as influence diagrams", "author": ["G. Cooper"], "venue": "In Proceedings of the Fourth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1988}, {"title": "An anytime approximation for optimizing policies under uncertainty", "author": ["R. Dechter"], "venue": "In Workshop on Decision Theoretic Planning, at the 5th International Conference on Artificial  Intelligence Planning Systems", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "Maximal flow through a network", "author": ["L.R. Ford", "D.R. Fulkerson"], "venue": "Canadian Journal of Mathematics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1956}, {"title": "An anytime algorithm for decision making under uncertainty", "author": ["M.C. Horsch", "D. Poole"], "venue": "In Proceedings of the 14th Annual Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1998}, {"title": "Influence diagrams", "author": ["R.A. Howard", "J.E. Matheson"], "venue": "The Principles and Applications of Decision Analysis,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1981}, {"title": "From influence diagrams to junction trees", "author": ["F. Jensen", "F.V. Jensen", "S.L. Dittmer"], "venue": "In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1994}, {"title": "Unconstrained influence diagrams", "author": ["F.V. Jensen"], "venue": "In Proc. of the 18th International Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2002}, {"title": "Representing and solving decision problems with limited information", "author": ["S.L. Lauritzen", "D. Nilsson"], "venue": "Management Science,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "Local computations with probabilities on graphical structures and their application to expert systems", "author": ["S.L. Lauritzen", "D.J. Spiegelhalter"], "venue": "Journal of the Royal Statistical Society, Series B (Methodological),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1988}, {"title": "A new approach to influence diagram evaluation", "author": ["R. Marinescu"], "venue": "In Proceedings of the 29th SGAI International Conference on Innovative Techniques and Applications of Artificial Intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Welldefined decision scenarios", "author": ["T.D. Nielsen", "F.V. Jensen"], "venue": "In Proceedings of the 15th Annual Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1999}, {"title": "Computing bounds on expected utilities for optimal policies based on limited information", "author": ["D. Nilsson", "M. Hohle"], "venue": "Technical Report", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2001}, {"title": "On representing and solving decision problems", "author": ["S.M. Olmsted"], "venue": "PhD thesis,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1983}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1988}, {"title": "A new method for influence diagram evaluation", "author": ["R. Qi", "D. Poole"], "venue": "Computational Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1995}, {"title": "Evaluating influence diagrams", "author": ["R.D. Shachter"], "venue": "Oper. Res.,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1986}, {"title": "Valuation based systems for Bayesian decision analysis", "author": ["P. Shenoy"], "venue": "Operations Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1992}, {"title": "Efficient computation of jointree bounds for systematic MAP search", "author": ["C. Yuan", "E.A. Hansen"], "venue": "In Proceedings of 21st International Joint Conference on Artificial Intelligence", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Probabilistic inference in influence diagrams", "author": ["N.L. Zhang"], "venue": "In Computational Intelligence,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1998}], "referenceMentions": [{"referenceID": 6, "context": "An influence diagram [7] is a compact representation of the relations among random variables, decisions, and preferences in a domain that provides a framework for decision making under uncertainty.", "startOffset": 21, "endOffset": 24}, {"referenceID": 1, "context": "Many algorithms have been developed to solve influence diagrams [2, 3, 8, 15, 17, 18, 19, 21].", "startOffset": 64, "endOffset": 93}, {"referenceID": 2, "context": "Many algorithms have been developed to solve influence diagrams [2, 3, 8, 15, 17, 18, 19, 21].", "startOffset": 64, "endOffset": 93}, {"referenceID": 7, "context": "Many algorithms have been developed to solve influence diagrams [2, 3, 8, 15, 17, 18, 19, 21].", "startOffset": 64, "endOffset": 93}, {"referenceID": 14, "context": "Many algorithms have been developed to solve influence diagrams [2, 3, 8, 15, 17, 18, 19, 21].", "startOffset": 64, "endOffset": 93}, {"referenceID": 16, "context": "Many algorithms have been developed to solve influence diagrams [2, 3, 8, 15, 17, 18, 19, 21].", "startOffset": 64, "endOffset": 93}, {"referenceID": 17, "context": "Many algorithms have been developed to solve influence diagrams [2, 3, 8, 15, 17, 18, 19, 21].", "startOffset": 64, "endOffset": 93}, {"referenceID": 18, "context": "Many algorithms have been developed to solve influence diagrams [2, 3, 8, 15, 17, 18, 19, 21].", "startOffset": 64, "endOffset": 93}, {"referenceID": 20, "context": "Many algorithms have been developed to solve influence diagrams [2, 3, 8, 15, 17, 18, 19, 21].", "startOffset": 64, "endOffset": 93}, {"referenceID": 15, "context": "A branch-and-bound approach to influence diagram evaluation appears to have been first suggested by Pearl [16].", "startOffset": 106, "endOffset": 110}, {"referenceID": 6, "context": "He proposed it as an improvement over the classic method of unfolding an influence diagram into a decision tree and solving it using the rollback method, which itself is a form of dynamic programming [7].", "startOffset": 200, "endOffset": 203}, {"referenceID": 16, "context": "Qi and Poole [17] proposed a similar search-based method for solving influence diagrams, but with no method for computing bounds; in fact, their implementation relied on the trivial infinity upper bound to guide the search.", "startOffset": 13, "endOffset": 17}, {"referenceID": 11, "context": "Recently, Marinescu [12] proposed a related search-based approach to influence diagram evaluation.", "startOffset": 20, "endOffset": 24}, {"referenceID": 13, "context": "First, we adapt the work of Nilsson and H\u00f6hle [14] on computing an upper bound on the maximum expected utility of an influence diagram.", "startOffset": 46, "endOffset": 50}, {"referenceID": 19, "context": "Second, we adapt the recent work of Yuan and Hansen [20] on solving the MAP problem for Bayesian networks using branch-and-bound search.", "startOffset": 52, "endOffset": 56}, {"referenceID": 8, "context": "In particular, Jensen proposes the framework of unconstrained influence diagrams to allow a partial ordering among the decisions [9].", "startOffset": 129, "endOffset": 132}, {"referenceID": 9, "context": "Other research relaxes the no-forgetting assumption, in particular, the framework of limited-memory influence diagrams [10].", "startOffset": 119, "endOffset": 123}, {"referenceID": 6, "context": "The simplest is to unfold an influence diagram into an equivalent decision tree and solve it in that form [7].", "startOffset": 106, "endOffset": 109}, {"referenceID": 14, "context": "Another approach called arc reversal solves an influence diagram directly using techniques such as arcreversal and node-removal [15, 18]; when a decision variable is removed, we obtain the optimal decision rule for the decision.", "startOffset": 128, "endOffset": 136}, {"referenceID": 17, "context": "Another approach called arc reversal solves an influence diagram directly using techniques such as arcreversal and node-removal [15, 18]; when a decision variable is removed, we obtain the optimal decision rule for the decision.", "startOffset": 128, "endOffset": 136}, {"referenceID": 2, "context": "Bayesian networks by converting decision nodes into random variables such that the solution of an inference problem in the Bayesian network correspond to the optimal decision policy for the influence diagram [3, 21].", "startOffset": 208, "endOffset": 215}, {"referenceID": 20, "context": "Bayesian networks by converting decision nodes into random variables such that the solution of an inference problem in the Bayesian network correspond to the optimal decision policy for the influence diagram [3, 21].", "startOffset": 208, "endOffset": 215}, {"referenceID": 18, "context": "Another method [19] transforms an influence diagram into a valuation network and applies variable elimination to solve the valuation network.", "startOffset": 15, "endOffset": 19}, {"referenceID": 1, "context": "Recent work compiles influence diagrams into decision circuits and uses the decision circuits to compute optimal policies [2]; this approach takes advantage of local structure present in an influence diagram, such as deterministic relations.", "startOffset": 122, "endOffset": 125}, {"referenceID": 7, "context": "In the following, we describe a state-of-the-art method for solving an influence diagram using a strong join tree [8].", "startOffset": 114, "endOffset": 117}, {"referenceID": 7, "context": "For clique C2 to send a message to clique C1, \u03c6C1 and \u03c8C1 should be updated as follows [8]:", "startOffset": 87, "endOffset": 90}, {"referenceID": 10, "context": "In contrast to the join tree algorithm for Bayesian networks [11], only the collection phase of the algorithm is needed to solve an influence diagram.", "startOffset": 61, "endOffset": 65}, {"referenceID": 13, "context": "Nilsson and H\u00f6hle [14] develop an approach to bounding the suboptimality of policies for limited-memory influence diagrams that are found by an approximation algorithm.", "startOffset": 18, "endOffset": 22}, {"referenceID": 3, "context": "Dechter [4] describes an approach to computing upper bounds in an influence diagram that is based on mini-bucket partitioning.", "startOffset": 8, "endOffset": 11}, {"referenceID": 13, "context": "The approach we develop in the rest of this paper is based on the work of Nilsson and H\u00f6hle [14], which we extend by showing how it can be used to compute bounds for branchand-bound search.", "startOffset": 92, "endOffset": 96}, {"referenceID": 9, "context": "An information variable Ii is said to be non-requisite [10, 13] for a decision node D if", "startOffset": 55, "endOffset": 63}, {"referenceID": 12, "context": "An information variable Ii is said to be non-requisite [10, 13] for a decision node D if", "startOffset": 55, "endOffset": 63}, {"referenceID": 13, "context": "A reduction of an influence diagram is obtained by deleting all the nonrequisite information arcs [14].", "startOffset": 98, "endOffset": 102}, {"referenceID": 13, "context": "We adopt the strategy proposed by Nilsson and H\u00f6hle [14].", "startOffset": 52, "endOffset": 56}, {"referenceID": 13, "context": "The following theorem is proved by Nilsson and H\u00f6hle [14].", "startOffset": 53, "endOffset": 57}, {"referenceID": 20, "context": "The concept of a sufficient information set is related to the concept of extremality, as defined in [21], and the concept of blocking, as defined in [13].", "startOffset": 100, "endOffset": 104}, {"referenceID": 12, "context": "The concept of a sufficient information set is related to the concept of extremality, as defined in [21], and the concept of blocking, as defined in [13].", "startOffset": 149, "endOffset": 153}, {"referenceID": 13, "context": "Finding the sufficient information set (SIS) for a decision variable in an influence diagram is equivalent to finding a minimum separating set in the moralized graph of the influence diagram [14].", "startOffset": 191, "endOffset": 195}, {"referenceID": 0, "context": "Acid and de Campos [1] propose an algorithm based on the Max-flow Min-cut algorithm [5] for finding a minimum separating set between two sets of nodes in a Bayesian network with some of the separating variables being fixed.", "startOffset": 19, "endOffset": 22}, {"referenceID": 4, "context": "Acid and de Campos [1] propose an algorithm based on the Max-flow Min-cut algorithm [5] for finding a minimum separating set between two sets of nodes in a Bayesian network with some of the separating variables being fixed.", "startOffset": 84, "endOffset": 87}, {"referenceID": 13, "context": "We briefly mention some issues that are not described by Nilsson and H\u00f6hle [14], but that need to be considered in an implementation.", "startOffset": 75, "endOffset": 79}, {"referenceID": 19, "context": "To make branch-and-bound search feasible, we rely on an incremental approach to computing bounds proposed by Yuan and Hansen [20] for solving the MAP problem in Bayesian networks using branch-and-bound search.", "startOffset": 125, "endOffset": 129}, {"referenceID": 16, "context": "Qi and Poole [17] create an AND/OR tree in which each layer of AND nodes alternates with a layer of OR nodes.", "startOffset": 13, "endOffset": 17}, {"referenceID": 19, "context": "We can use an efficient incremental join tree evaluation method to compute the probabilities and upper-bound utilities, based on the incremental join tree evaluation method proposed by Yuan and Hansen [20] for solving the MAP problem.", "startOffset": 201, "endOffset": 205}, {"referenceID": 19, "context": "For solving the MAP problem for Bayesian networks, Yuan and Hansen [20] show that the incremental method is more than ten times faster than full join tree evaluation in depth-first branchand-bound search.", "startOffset": 67, "endOffset": 71}, {"referenceID": 7, "context": "We compared the performance of our algorithm against both the join tree algorithm [8] and exhaustive search of the AND/OR tree (i.", "startOffset": 82, "endOffset": 85}, {"referenceID": 11, "context": "Previous work has argued that one of the advantages of search algorithms for influence diagram evaluation is that they can prune branches of the search tree that have zero probability, even without bounds [12, 17].", "startOffset": 205, "endOffset": 213}, {"referenceID": 16, "context": "Previous work has argued that one of the advantages of search algorithms for influence diagram evaluation is that they can prune branches of the search tree that have zero probability, even without bounds [12, 17].", "startOffset": 205, "endOffset": 213}, {"referenceID": 9, "context": "We are currently considering how to extend this approach to solve limited-memory influence diagrams [10], which typically have many more stages.", "startOffset": 100, "endOffset": 104}], "year": 2010, "abstractText": "A branch-and-bound approach to solving influence diagrams has been previously proposed in the literature, but appears to have never been implemented and evaluated \u2013 apparently due to the difficulties of computing effective bounds for the branch-and-bound search. In this paper, we describe how to efficiently compute effective bounds, and we develop a practical implementation of depth-first branch-and-bound search for influence diagram evaluation that outperforms existing methods for solving influence diagrams with multiple stages.", "creator": " TeX output 2010.06.12:2215"}}}