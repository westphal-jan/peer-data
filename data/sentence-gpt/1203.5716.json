{"id": "1203.5716", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2012", "title": "Credal Classification based on AODE and compression coefficients", "abstract": "Bayesian model averaging (BMA) is an approach to average over alternative models; yet, it usually gets excessively concentrated around the single most probable model, therefore achieving only sub-optimal classification performance. The compression-based approach (Boulle, 2007) overcomes this problem, averaging over the different models by applying a logarithmic smoothing over the models' posterior probabilities. This approach has shown excellent performances when applied to ensembles of naive Bayes classifiers. (Boulle, 2008)\n\n\nThe optimal fit for an efficient model should be derived from our recent research (Gardner, 2005, 2011). The optimal fit is expressed as:\n(C) The optimum fit is expressed as:\n(D) The optimal fit is expressed as:\n(E) The optimal fit is expressed as:\n(F) The optimal fit is expressed as:\n(G) The optimal fit is expressed as:\n(H) The optimal fit is expressed as:\n(A) The optimal fit is expressed as:\n(C) The optimal fit is expressed as:\n(D) The optimal fit is expressed as:\n(F) The optimal fit is expressed as:\n(H) The optimal fit is expressed as:\n(J) The optimal fit is expressed as:\n(M) The optimal fit is expressed as:\n(R) The optimal fit is expressed as:\n(A) The optimal fit is expressed as:\n(R) The optimal fit is expressed as:\n(S) The optimal fit is expressed as:\n(S) The optimal fit is expressed as:\n(S) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:\n(T) The optimal fit is expressed as:", "histories": [["v1", "Mon, 26 Mar 2012 16:25:35 GMT  (88kb,S)", "https://arxiv.org/abs/1203.5716v1", null], ["v2", "Tue, 27 Mar 2012 10:27:30 GMT  (30kb)", "http://arxiv.org/abs/1203.5716v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["giorgio corani", "alessandro antonucci"], "accepted": false, "id": "1203.5716"}, "pdf": {"name": "1203.5716.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["giorgio@idsia.ch"], "sections": [{"heading": null, "text": "ar X\niv :1\n20 3.\n57 16\nv2 [\ncs .L\nG ]\n2 7\nM ar\nBayesian model averaging (BMA) is a common approach to average over alternative models; yet, it usually gets excessively concentrated around the single most probable model, therefore achieving only sub-optimal classification performance. The compression-based approach (Boulle\u0301, 2007) overcomes this problem; it averages over the different models by applying a logarithmic smoothing over the models\u2019 posterior probabilities. This approach has shown excellent performances when applied to ensembles of naive Bayes classifiers. AODE is another ensemble of models with high performance (Webb et al., 2005): it consists of a collection of non-naive classifiers (called SPODE) whose probabilistic predictions are aggregated by simple arithmetic mean. Aggregating the SPODEs via BMA rather than by arithmetic mean deteriorates the performance; instead, we propose to aggregate the SPODEs via the compression coefficients and we show that the resulting classifier obtains a slight but consistent improvement over AODE. However, an important issue in any Bayesian ensemble of models is the arbitrariness in the choice of the prior over the models. We address this problem by adopting the paradigm of credal classification, namely by substituting the unique prior with a set of priors. Credal classifier are able to automatically recognize the prior-dependent instances, namely the instances whose most probable class varies, when different priors are considered; in these cases, credal classifiers remain reliable by returning a set of classes rather than a single class. We thus develop the credal version\n\u2217Corresponding author: giorgio@idsia.ch\nPreprint submitted to Elsevier January 1, 2014\nof both the BMA-based and the compression-based ensemble of SPODEs, substituting the single prior over the models by a set of priors. By experiments we show that both credal classifiers provide overall higher classification reliability than their determinate counterparts. Moreover, the compression-based credal classifier compares favorably to previous credal classifiers.\nKeywords: classification, Bayesian Model Averaging, compression coefficients, AODE, credal classification, imprecise probability"}, {"heading": "1. Introduction", "text": "Bayesian model averaging (BMA) (Hoeting et al., 1999) is a sound solution to the uncertainty which characterizes the identification of the supposedly best model for a certain data set; given a set of alternative models, BMA weights the inferences produced by the various models, using the models\u2019 posterior probabilities as weights. BMA assumes the data to be generated by one of the considered models; under this assumption, it provides better predictive accuracy than any single model (Hoeting et al., 1999). However, such an assumption is generally not true; for this reason, on real data sets BMA does not generally perform very well; see the discussion and the references in Cerquides et al. (2005) for more details. The problem is that BMA gets excessively concentrated around the single most probable model (Domingos, 2000; Minka, 2002): especially on large data sets, \u201caveraging using the posterior probabilities to weight the models is almost the same as selecting the MAP model\u201d (Boulle\u0301, 2007). To overcome the problem of BMA getting excessively concentrated around the most probable model, a compression-based approach has been introduced in (Boulle\u0301, 2007); it computes more evenly-distributed weights, by applying a logarithmic smoothing to the models posterior probabilities. The compression-based weights, which can be justified from an information-theoretic viewpoint, have been used in Boulle\u0301 (2007) to average over different naive Bayes classifiers, characterized by different feature sets, obtaining excellent rank in international competitions on classification.\nAnother ensemble of Bayesian networks classifiers known for its good performance is AODE (Webb et al., 2005), which is instead based on a set of SPODE (SuperParent-\nOne-Dependence Estimator) models. Each SPODE adopts a certain feature as a superparent, namely it models all the remaining features as depending on both the class and the super-parent. AODE then simply averages the posterior probabilities computed by the different SPODEs. Alternative methods to aggregate SPODEs, more complex than AODE, have been considered (Yang et al., 2007), but AODE generally outperforms them: \u201cAODE, which simply linearly combines every SPODE without any selection or weighting, is actually more effective than the majority of rival schemes\u201d. As reported in (Cerquides et al., 2005; Yang et al., 2007), AODE outperforms aggregating SPODEs via BMA; in both (Yang et al., 2007; Cerquides et al., 2005) the best results were instead obtained using an algorithm (called MAPLMG), which estimates the most probable linear mixture of SPODEs; this overcomes the problem of assuming a single SPODE to be the true model. In this paper, we address this problem by means of the compression coefficients.\nAs a preliminary step we develop BMA-AODE, namely BMA over SPODEs, with some computational differences with respect to the framework of Yang et al. (2007) and Cerquides et al. (2005); our results confirm however that BMA over SPODEs is outperformed by AODE. Then we develop the novel COMP-AODE classifier, which weights the SPODEs using the compression-based coefficients, and we show that it yields a slight but consistent improvement in the classification performance over the standard AODE. Considering the high performance of AODE, we regard this result as noteworthy.\nAn important issue in any Bayesian ensemble is choosing the prior over the models. A common choice is to adopt a uniform mass function, as we do in both BMA-AODE and COMP-AODE; this however can be criticized from different standpoints; see for instance the rejoinder in Hoeting et al. (1999). In Boulle\u0301 (2007), a prior which favors simpler models over complex ones is adopted. Although all these choices are reasonable, the specification of any single prior implies some arbitrariness, which entails the risk of prior-dependent, and hence potentially fragile, conclusions.\nIn fact, the specification of the prior over the models is a serious open problem for Bayesian ensembles of models. We address this problem by adopting the paradigm of credal classification (Corani et al., 2012; Corani and Zaffalon, 2008b), namely drop-\nping the unique prior in favor of a set of priors (prior credal set) (Levi, 1980). While a traditional non-informative priors represents a condition of indifference between the alternative models, a credal set describes a condition of prior ignorance, letting thus vary the prior probability of each model over a wide interval, instead of fixing it to a specific number. Credal classifiers are able to automatically detect the instances whose most probable class varies when different priors are considered; such instances are called prior-dependent. Credal classifiers remain reliable on prior-dependent instances by returning a set of classes; traditional classifiers have instead typically low accuracy on the prior-dependent instances (Corani and Zaffalon, 2008a,b).\nWe then develop BMA-AODE* and COMP-AODE*, namely the credal counterparts of respectively BMA-AODE and COMP-AODE. By extensive experiments we show that both credal classifiers are sensible extension of their single-prior counterparts; in fact, they return a small-sized but highly accurate set of classes on the priordependent instances, over which instead their single-prior counterparts have reduced accuracy. We conclude by showing that COMP-AODE* compares favorably to both BMA-AODE* and other existing credal classifiers."}, {"heading": "2. Methods", "text": "We consider a classification problem with k features; we denote by C the class variable (taking values in C) and by A := (A1, . . . , Ak) the set of features, taking values respectively in A1, . . . ,Ak. For a generic variable A, we denote as P (A) the probability mass function over its values and as P (a) the probability that A = a. We assume the data to be complete and the training data D to contain n instances. We learn the model parameters from the training data by adopting Dirichlet priors and setting the equivalent sample size to 1. Under 0-1 loss a traditional probabilistic classifier returns, for a test instance a\u0303 = {a\u03031, . . . , a\u0303k} whose class is unknown, the most probable class c\u2217:\nc\u2217 := argmax c\u2208C P (c|a\u0303).\nClassifiers based on imprecise-probabilities (credal classifiers) change this paradigm, by occasionally returning more classes; this happens in particular when the most proba-\nble class is prior-dependent. We discuss this point more in detail later, when presenting credal classifiers."}, {"heading": "2.1. From Naive Bayes to AODE", "text": "The Naive Bayes classifier assumes the stochastic independence of the features\ngiven the class; it therefore factorizes the joint probability as follows:\nP (c, a) := P (c) \u00b7 k \u220f\nj=1\nP (aj |c), (1)\ncorresponding to the topology of Fig.1(a). Despite the biased estimate of probabilities due to the above (so-called naive) assumption, naive Bayes performs well under 0- 1 loss (Domingos and Pazzani, 1997); it thus constitutes a reasonable choice if the goal is simple classification, without the need for accurate probability estimates; it is especially competitive on data sets of small and medium size , thanks to its low variance error (Friedman, 1997).\nTo improve the model, weaker assumptions about the conditional independence of the features have to be considered; for instance, the tree-augmented naive classifier (TAN) allows each feature to depend on the class and on possibly another single feature, constraining however the subgraph involving only the features to be a tree; an example is shown in Fig.1(b). Generally, TAN outperforms naive Bayes in classification (Friedman et al., 1997).\nThe AODE classifier (Webb et al., 2005) is an ensemble of k SPODE (SuperParent One Dependence Estimator) classifiers; each SPODE is characterized by a certain super-parent feature, so that the other features are modeled as depending on both the class and the super-parent, as shown in in Fig.2. In fact, each single SPODE is a TAN.\nWe denote the set of SPODEs as S := {s1, . . . , sk}, where sj indicates the SPODE\nwith super-parent Aj . The joint probability of SPODE sj factorizes as:\nP (c, a|sj) = P (c) \u00b7 P (aj |c) \u00b7 k \u220f\nl=1..k,l 6=j\nP (al|aj, c).\nIn order to classify the test instance a\u0303, AODE averages the posterior probabilityP (c|a\u0303, sj) computed by each single SPODE:\nP (c|a) = 1\nk\nj=k \u2211\nj=1\nP (c, a|sj)\nIn this paper we focus on more sophisticated approaches for aggregating the predictions of the SPODEs."}, {"heading": "2.2. Bayesian Model Averaging (BMA) with SPODEs", "text": "BMA assumes that one of the models in the ensemble is the true one. Under this assumption, the optimal strategy is to weight the inferences produced by the models of the ensemble using as weights the models\u2019 posterior probabilities. By applying BMA on top of different SPODEs, we thus assume one of the SPODEs to be the true model. We thus introduce a variable S over S, where P (S = sj) denotes the prior probability of SPODE sj to be the true model. Considering that every SPODE has the same number of variables, the same number of arcs and the same in-degree1, we adopt a uniform prior, thus assigning prior probability 1/k to each SPODE. In fact, the uniform prior over the models is frequently adopted within BMA. To classify the test\n1The in-degree is the maximum number of parents per node: it is two for any SPODE.\ninstance a\u0303, BMA computes the following posterior mass function:\nP (c|a\u0303) = k \u2211\nj=1\nP (c|a\u0303, sj) \u00b7 P (sj |D) \u221d k \u2211\nj=1\nP (c|a\u0303, sj) \u00b7 P (D|sj) \u00b7 P (sj),\nwhere P (D|sj) is the marginal likelihood of sj , namely\nP (D|sj) =\n\u222b\nP (D|sj , \u03b8j) \u00b7 P (\u03b8j |sj) \u00b7 d\u03b8j ,\nwith \u03b8j denoting the parameters of SPODE sj . This computational schema has been adopted to implement BMA over SPODEs in (Cerquides et al., 2005; Yang et al., 2007), and has been outperformed by AODE.\nThe marginal likelihood measures how good the model is at representing the joint distribution; yet, a classifier has instead to estimate the posterior probability of the classes conditionally on the features. Therefore, a model can perform badly at classification despite having high marginal likelihood (Cowell, 2001; Kontkanen et al., 1999); for this reason, scoring rules more appropriate for classification should be considered. Following Boulle\u0301 (2007), we thus substitute the marginal likelihood with conditional likelihood:\nLj :=\nn \u220f\ni=1\nP (c(i)|a(i), sj, \u03b8\u0302j), (2)\nwhere P (c(i)|a(i), sj , \u03b8\u0302j) denotes the probability assigned by model sj to the true class of the i-th instance, and \u03b8\u0302j is the estimate of the parameters of model sj .\nWe call BMA-AODE the classifier which estimates the posterior probabilities of\nthe class, given the test instance a\u0303, as follows:\nP (c|a\u0303) \u221d k \u2211\nj=1\nP (c|a\u0303, sj) \u00b7 Lj \u00b7 P (sj). (3)\nEspecially on large data sets, the difference between the likelihoods of the different SPODEs might be of several order of magnitudes. We remove from the ensemble the SPODEs whose conditional likelihood is smaller than Lmax/104, where Lmax is the maximum conditional likelihood among all SPODEs; discarding models with very low posterior probability is in fact common when dealing with BMA; this procedure can be seen as a belief revision (Dubois and Prade, 1997). Given the joint\nbeliefs P (X,Y ), the revision P \u2032(X,Y ) induced by a marginal P \u2032(Y ) is defined by P \u2032(x, y) := P (x|y) \u00b7 P \u2032(y). In other words, if P \u2032(y) is known to be a better model than P (y) for the marginal beliefs about y, this information can be used in the above described way to redefine the joint. Accordingly, in BMA-AODE, the marginal beliefs about S have been replaced by a better candidates, inducing a revision in the corresponding joint model."}, {"heading": "2.2.1. Exponentiation of the Log-Likelihoods", "text": "Regardless whether the marginal likelihood or the conditional likelihood is considered, it is common to compute the log-likelihood rather than the likelihood, in order to avoid numerical problems due to the multiplication of many probabilities. However, if the log-likelihoods are very negative, as it happen on large data sets, their exponentiation can suffer numerical problems too. This issue has been addressed in Yang et al. (2007) by means of high numerical precision: \u201cBMA often lead to arithmetic overflow when calculating very large exponentials or factorials. One solution is to use the Java class BigDecimal which unfortunately can be very slow.\u201d Algorithm 1 describes a procedure for exponentiating the log-likelihoods, which is both numerically robust and computationally fast. The procedure has been communicated to us by D. Dash, who published several works on BMA (Dash and Cooper, 2004)."}, {"heading": "2.3. BMA-AODE*: Extending BMA-AODE to Sets of Probabilities", "text": "By BMA-AODE* we extend BMA-AODE to imprecise probabilities (Walley, 1991),\nallowing multiple specifications of the prior mass function P (S); we denote the credal set containing such prior mass functions as P(S). While a uniform prior represents prior indifference between the different SPODEs, the credal set represents a condition of prior ignorance about S, letting the prior probability of each SPODE vary within a large range. In principle we could let the prior probability of each SPODE vary exactly between zero and one (vacuous model). Yet, this would generate vacuous posterior inferences, thus preventing learning from data (Piatti et al., 2009). To obtain non-vacuous posterior inferences, we introduce non-zero lower bounds for the prior probability of\nAlgorithm 1 Robust exponentiation of log-likelihoods.\nRequire: Array log liks of log-likelihoods, assumed of length k.\nminVal=min(log liks)\nfor i = 1:k do shifted logliks(i)=logliks(i)-minVal; tmp liks(i)=exp(shifted logliks(i)); end for\ntotal=sum(tmp liks)\nfor i = 1:k do liks(i)=tmp liks(i)/total; end for\nreturn liks {Array proportional to the exponentiated likelihoods}\nthe models. The resulting credal set is defined by the following constraints:\nP(S) :=\n \n\nP (S)\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 P (sj) \u2265 \u01eb \u2200j = 1, . . . , k \u2211k\nj=1 P (sj) = 1\n \n\n. (4)\nThe prior probability of each SPODE varies thus between \u01eb and 1 \u2212 (k \u2212 1)\u01eb. The set of mass functions in Eq.(4) is convex; its k extreme mass functions are those assigning mass \u01eb to all the SPODEs apart from a single one, to which 1\u2212(k\u22121)\u01eb is assigned. The constant \u01eb appears in other places of this paper; in the implementation we set \u01eb = 0.01 for all occurrences of \u01eb.\nThe credal set in (4) models the fact that, before observing the data, we are ignorant about the probability of each SPODE to be the true model. Considering that P(S) is a set a prior mass functions, BMA-AODE* can be regarded as a set of BMA-AODE classifiers, each corresponding to a different prior. The most probable class of an instance might happen to vary, when all the different priors of the credal set are considered; in this case the classification is prior-dependent. When dealing with prior-dependent instances, credal classifiers (Corani et al., 2012; Corani and Zaffalon, 2008b) become indeterminate, by returning a set of classes instead of a single class.\nBefore discussing how this set of classes is identified, let us introduce the concept\nof credal dominance (or, for short, dominance): class c\u2032 dominates class c\u2032\u2032 if c\u2032 is more probable than c\u2032\u2032 under each prior of the credal set. If no class dominates c\u2032, then c\u2032 is non-dominated. Credal classifiers return in particular all the non-dominated classes, identified performing different by pairwise dominance tests among classes. This criterion is called maximality (Walley, 1991, Section 3.9.2) and is described by Algorithm 2. We point the reader to (Troffaes, 2007) for a discussion of alternative criteria for taking decisions under imprecise probabilities.\nAlgorithm 2 Identification of the non-dominated classes ND through maximality\nND := C\nfor c\u2032 \u2208 C do for c\u2032\u2032 \u2208 C (c\u2032\u2032 6= c\u2032) do\ncheck whether c\u2032 dominates c\u2032\u2032\nif c\u2032 dominates c\u2032\u2032 then remove c\u2032\u2032 from ND end if\nend for end for\nreturn ND\nNon-dominated classes are incomparable, namely there is no available information to rank them. Credal classifiers can be thus seen as dropping the dominated classes and expressing indecision about the non-dominated ones.\nWithin BMA-AODE*, c\u2032 dominates c\u2032\u2032 if the solution of the following optimization\nproblem is greater than one:\nminimize:\n\u2211k\nj=1 P (c \u2032|a\u0303, sj) \u00b7 Lj \u00b7 P (sj)\n\u2211k\nj=1 P (c \u2032\u2032|a\u0303, sj) \u00b7 Lj \u00b7 P (sj)\nsubject to: P (sj) \u2265 \u01eb \u2200j = 1, . . . , k \u2211k\nj=1 P (sj) = 1,\nNote that the constrains of the problem correspond to the definition of credal set given in Eq.4. The above optimization task is a fractional-linear program; it can be mapped into a linear program by the Charnes-Cooper transformation (see Appendix Appendix A) and then solved exactly.\nAs already discussed for BMA-AODE, we include in the computation only the SPODEs whose conditional likelihood is at least Lmax/104. This can be regarded as a belief revision process, involving the credal set. The marginal credal set P \u2032(Y ) induces the following revision of the joint credal set P(X,Y ):\nP \u2032(X,Y ) :=\n \n\nP \u2032(X,Y )\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 P \u2032(x, y) := P (x|y) \u00b7 P \u2032(y) P \u2032(Y ) \u2208 P \u2032(Y )    .\nIt is worth emphasizing that the prior credal of BMA-AODE* includes the uniform prior adopted by BMA-AODE; therefore, the set of non-dominated classes identified by BMA-AODE* includes the most probable class returned by BMA-AODE; if in particular BMA-AODE* returns a single non-dominated class, this coincides to the class returned by BMA-AODE."}, {"heading": "2.4. Compression-Based averaging", "text": "Compression-based averaging has been introduced by (Boulle\u0301, 2007) as a remedy against the tendency of BMA at getting excessively concentrated around the most probable model, which indeed deteriorates the performances (Boulle\u0301, 2007; Domingos, 2000). This approach replaces the posterior probabilities P (sj |D) of the models by smoother compression weights, which we denote as P \u2032(sj |D) for model sj . Note that also the adoption of the compression coefficients in place of the posterior probabilities can be seen as a belief revision.\nTo present the method, we need some further notation. In particular, we denote by LLj the log of the conditional likelihood of model sj . We moreover introduce the null classifier as a Bayesian network with no arcs, which models the class as independent from the features and whose probabilistic classifications correspond to the marginal probabilities of the classes. The null classifier will be used for the computation of the compression coefficients. We denote the null classifier as s0; therefore we associated a further state s0 to S, whose domain thus becomes {s0, s1, . . . , sk}. We denote as LL0\nthe conditional log-likelihood of the null classifier. It has been shown (Boulle\u0301, 2007) that LL0 = \u2212nH(C), where H(C) := \u2212 \u2211 c\u2208C P (c) logP (c) is the entropy 2 of the class.\nSince we are dealing with a traditional single-prior classifier, we set a single prior mass function over the models, assigning uniform prior probability to the various SPODEs but prior probability \u01eb to the null model; assigning a prior probability to the null model is necessary, since its posterior probability appears in the compression coefficients. Thus, we define the prior over variable S as follows:\nP (sj) =\n \n\n\u01eb j = 0, 1\u2212\u01eb k j = 1, . . . , k. (5)\nThe compression coefficients are computed in two steps: computation of the raw compression coefficients and normalization. The raw compression coefficient associated to SPODE sj is:\n\u03c0j := 1\u2212 logP (sj |D)\nlogP (s0|D) = 1\u2212\nLLj + logP (sj) LL0 + logP (s0) = 1\u2212\nLLj + log 1\u2212\u01eb k\n\u2212nH(C) + log \u01eb , (6)\nA negative \u03c0j means that sj is a worse predictor than the null model; a positive \u03c0j means that sj is a better predictor than the null model, which is the general case in practical situations. The upper limit of \u03c0j is one: in this case sj is a perfect predictor, with likelihood 1, and thus log-likelihood 0. Following (Boulle\u0301, 2007), we keep in the ensemble only the feasible models, namely those with \u03c0j > 0; we instead discard the models with \u03c0j < 0. Also this procedure corresponds to a belief revision induced by the removal from the ensemble of the models whose posterior probability falls below a certain threshold. Note also that, since \u03c00 = 0 by definition, the null model is not part of the resulting ensemble. The compression coefficients can be justified as follows (Boulle\u0301, 2007): LLj+logP (sj) \u201crepresents the quantity of information required to encode the model plus the class values given the model. The code length of the null model can be interpreted as the quantity of information necessary to describe the classes, when no explanatory data is used to induce the model. Each model can poten-\n2For this equivalence to hold, it is necessary computing the entropy using the natural logarithm, instead of the log2 as usual.\ntially exploit the explanatory data to better compress the class conditional information. The ratio of the code length of a model to that of the null model stands for a relative gain in compression efficiency.\u201d\nWith no loss of generality, assume the features to be ordered so that A1, A2, . . . , Ak\u0303 yield a feasible model when used as super-parent; thus, SPODEs s1, s2, . . . , sk\u0303 are feasible, while SPODEs sj with j > k\u0303 are removed from the ensemble. The normalized compression coefficients P \u2032(sj |D) are obtained by normalizing the raw compression coefficients of the feasible SPODEs:\nP \u2032(sj |D) =\n  \n \n\u03c0j \u2211\nk\u0303 l=1 \u03c0l\nif j = 1, . . . , k\u0303,\n0 otherwise.\n(7)\nThe posterior probabilities are estimated as:\nP (c|a\u0303) = k \u2211\nj=1\nP (c|a\u0303, sj) \u00b7 P \u2032(sj |D). (8)\nWe call this classifier COMP-AODE, where COMP stands for compression-based. COMP-AODE performs a weighted linear combination of probabilities estimated by different models; in risk analysis, a weighted linear combination of probabilities estimated by different experts is referred to as linear opinion pool (Clemen and Winkler, 1999)."}, {"heading": "2.5. COMP-AODE*: Extending COMP-AODE to Sets of Probabilities", "text": "We extend COMP-AODE to imprecise probabilities by allowing for multiple specifications of the prior P (S) over the models, collected into a credal set Pc(S), where the subscript denotes compression. Differently from the credal set P(S) used by the BMA-AODE*, here we also consider the null model. We assign to the null model a fixed prior probability \u01eb, while the prior probability of the SPODEs are free to vary under constraints analogous to those of BMA-AODE*; in this way we model a condition of prior ignorance. The credal set Pc(S) adopted by COMP-AODE* is therefore:\nPc(S) :=\n    \n   \nP (S)\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 P (s0) = \u01eb, P (sj) \u2265 \u01eb \u2200j = 1, . . . , k, \u2211k\nj=0 P (sj) = 1\n    \n   \n. (9)\nThe bounds of the raw compression coefficient defined in Eq.(6) are obtained by\nletting vary P (S) in Pc(S):\n\u03c0j \u2208\n[\n1\u2212 LLj + log \u01eb\n\u2212nH(C) + log \u01eb , 1\u2212\nLLj + log (1\u2212 k\u01eb)\n\u2212nH(C) + log \u01eb\n]\n. (10)\nSince the prior used by COMP-AODE (Eq. 5) belongs to the credal set of COMPAODE*, the point estimate of the compression coefficient adopted by COMP-AODE (Eq.6) lies in the above interval. Note also that the upper bound of the above interval (upper coefficient of compression) is obtained in correspondence of the extreme mass function which assigns prior probability 1 \u2212 k\u01eb to model sj and prior probability \u01eb to all the remaining models. The various \u03c0j cannot vary independently from each other; they are instead linked by the normalization constraint in Eq.(9).\nCOMP-AODE* regards SPODE sj as non-feasible if the upper coefficient of compression is non-positive: this approach thus preserves all the models which are feasible, in the sense of Section 2.4, for at least a prior in the set Pc(S). COMP-AODE* is thus more conservative than COMP-AODE, namely it discards a lower number of models. However, generally neither COMP-AODE* nor COMP-AODE remove any SPODE from the ensemble. Since the prior adopted by COMP-AODE is contained in the credal set of COMP-AODE*, the most probable class identified by COMP-AODE is part of the non-dominated classes identified by COMP-AODE*. 3\nLike BMA-AODE*, COMP-AODE* identifies for each instance the non-dominated classes through maximality (Algorithm 2). In the following, we explain how to compute the test of dominance among two classes.\nTesting dominance\nWithout loss of generality, we assume the features to have be re-ordered, so that the first k\u0303 features yield a model with positive upper coefficient of compression when used as super-parent; in other words, SPODEs {s1, . . . , sk\u0303} are the feasible ones. In this case the dominance test corresponds to evaluate whether or not the solution of the following optimization problem is greater than one.\n3Exception to this statement are in principle possible if the set of feasible SPODEs differs between COMP-AODE* and COMP-AODE. However, this did not happen in our extensive experiments.\nminimize: P (c\u2032|a)\nP (c\u2032\u2032|a) \u221d\n\u2211k\u0303\nj=1 P (c \u2032|a\u0303, sj) \u00b7 \u03c0j\n\u2211k\u0303\nj=1 P (c \u2032\u2032|a\u0303, sj) \u00b7 \u03c0j\n(11)\nw.r.t.: P (s0), P (s1), . . . , P (sk) (12)\nsubject to: P (s0) = \u01eb (13)\nP (sj) \u2265 \u01eb \u2200j = 1, . . . , k\n\u2211k\nj=1 P (sj) = 1,\nwhere the normalization term \u2211k\u0303\nj=1 \u03c0j has been already simplified, being positive by\ndefinition. Recalling that P (s0) = \u01eb and introducing Eq.(6) which shows how \u03c0j depends on the optimization variable P (sj), we rewrite the objective function as:\n\u2211k\u0303\nj=1 P (c \u2032|a, sj) \u00b7\n(\n1\u2212 logP (sj)+LLjlog \u01eb+LL0\n)\n\u2211k\u0303\nj=1 P (c \u2032\u2032|a, sj) \u00b7\n(\n1\u2212 logP (sj)+LLjlog \u01eb+LL0\n) ,\nand hence \u2211k\u0303\nj=1 P (c \u2032|a, sj) \u00b7 (log \u01eb+ LL0 \u2212 LLj)\u2212\n\u2211k\u0303\nj=1 P (c \u2032|a, sj) \u00b7 logP (sj)\n\u2211k\u0303\nj=1 P (c \u2032\u2032|a, sj) \u00b7 (log \u01eb+ LL0 \u2212 LLj)\u2212\n\u2211k\u0303\nj=1 P (c \u2032\u2032|a, sj) \u00b7 logP (sj)\n.\nWe then introduce the constants a := \u2211k\u0303 j=1 P (c \u2032|a, sj) (log \u01eb+ LL0 \u2212 LLj), b := \u2211j=k\u0303 j=1 P (c \u2032\u2032|a, sj) (log \u01eb+ LL0 \u2212 LLj), \u03b1j := P (c\u2032|a, sj), \u03b2j := P (c\u2032\u2032|a, sj). After changing the sign of both numerator and denominator of the objective function, we rewrite the optimization problem, with respect to the variables x1, x2, . . . , xk\u0303, where xj := logP (sj), as follows:\nminimize:\n\u2211k\u0303\nj=1 \u03b1jxj \u2212 a \u2211k\u0303\nj=1 \u03b2jxj \u2212 b\nw.r.t.: x1, . . . , xk\u0303\nsubject to: xj \u2265 log \u01eb \u2200j = 1, . . . , k\u0303,\n\u2211k\u0303\nj=1 expxj = 1\u2212 \u01eb\u2212 (k \u2212 k\u0303)\u01eb.\nwhere the constrains are derived from the definition of credal set (9). The last constraint is justified as follows: (k \u2212 k\u0303) models have been removed from the ensemble as unfeasible and therefore they do not appear in the optimization problem. Without changing the credal set, we set their priors to \u01eb; since these models do not impact on the objective function, the best solution is attained by allocating to them the minimum possible prior probability. We then substitute yj := expxj to avoid numerical problems in the optimization, thus getting the following non-linear optimization problem with linear constraints:\nminimize:\n\u2211k\u0303\nj=1 \u03b1j \u00b7 log yj \u2212 a \u2211k\u0303\nj=1 \u03b2j \u00b7 log yj \u2212 b\n(14)\nw.r.t.: y1, . . . , yk\u0303 (15)\nsubject to: yj \u2265 \u01eb, (16) \u2211k\u0303\nj=1 yj = 1\u2212 (k \u2212 k\u0303 \u2212 1)\u01eb."}, {"heading": "2.6. Computational Complexity of the Classifiers", "text": "We now analyze the computational complexity of the proposed classifiers and compare it with that of the standard AODE. We distinguish between learning and classification complexity, the latter referring to the classification of a single instance. Both the space and the time required for computations are evaluated. The orders of magnitude of these descriptors are reported as a function of the dataset size n, the number of attributes/SPODEs k, the number of classes l := |C|, and average number of states for the attributes v := k\u22121 \u2211k\ni=1 |Ai|. A summary of this analysis is in Table 1 and the\ndiscussion below.\nLet us first evaluate the AODE. For a single SPODE sj , the tables P (C), P (Aj |C) and P (Ai|C,Aj), with i = 1, . . . , k and i 6= j should be stored, this implying space complexity O(lkv2) for learning each SPODE and O(lk2v2) for the AODE ensemble.\nThese tables should be available during learning and classification for both classifiers; thus, space requirements of these two stages are the same.\nTime complexity to scan the dataset and learn the probabilities is O(nk) for each SPODE, and hence O(nk2) for the AODE. The time required to compute the posterior probabilities is O(lk) for each SPODE, and hence O(lk2) for AODE.\nLearning BMA-AODE or COMP-AODE takes the same space as AODE, but higher computational time, due to the evaluation of the conditional likelihood as in Eq.(2). The additional computational time is O(nlk), thus requiringO(n(l+k)k) time overall. For classification, time and space complexity during learning and classification are just the same.\nThe credal classifiers BMA-AODE* and COMP-AODE* require the same space complexity and the same time complexity in learning of their non-credal counterparts. However, credal classifiers have higher time complexity in classification. The pairwise dominance tests in Algorithm 2 requires the solution of a number of optimization problems for each test instance which is quadratic in the number of classes. We can roughly describe as cubic in the number of variables the time complexity of solving the linear programming problem for BMA-AODE* and the optimization of the non-linear function, with linear constraints, for COMP-AODE*. Summing up credal classifiers increase of one unit, compared to their single-prior counterparts, the exponents of the number of classes and attributes in the time complexity of the classification stage."}, {"heading": "3. Experiments", "text": "We run experiments on 40 data sets, whose characteristics are given in the Appendix (Table B.2). On each data set we perform 10 runs of 5-fold cross-validation. In order to have complete data, we replace missing values with the median and the mode\nfor respectively numerical and categorical features. We discretize numerical features by the entropy-based method of (Fayyad and Irani, 1993). For pairwise comparison of of classifiers over the collection of data sets we use the non-parametric Wilcoxon signed-rank test.4 The Wilcoxon signed-rank test is indeed recommended for comparing two classifiers on multiple data sets (Demsar, 2006): being non-parametric it avoids strong assumptions and robustly deals with outliers."}, {"heading": "3.1. Determinate classifiers", "text": "We call determinate the classifiers which always return a single class, namely AODE, BMA-AODE and COMP-AODE. For determinate classifiers we use two indicators: the accuracy, namely the percentage of correct classifications, and the Brier loss 1\nnte\nnte \u2211\ni\n( 1\u2212 P (c(i)|a(i)) )2 ,\nwhere nte denotes the number of instances in the test set, while P (c(i)|a(i)) is the probability estimated by the classifier for the true class of the i-th instance. The Brier loss assesses the quality of the estimated probabilities in a more sensitive way than accuracy.\nA first finding is that AODE outperforms BMA-AODE, having both higher accuracy (p-value < .01) and lower Brier loss. We present in Figure 3(a) the scatter plot of accuracies and in Figure 4(a) the relative Brier losses, namely the Brier loss of BMAAODE divided, data set by data set, by the Brier loss of AODE. On average, BMAAODE has 3% higher Brier loss than AODE. The fact that AODE outperforms BMAAODE could be expected; the same finding was already given in (Yang et al., 2007) and in (Cerquides et al., 2005), with the main difference that the BMA-AODE of these works was based on the marginal likelihood rather than on the conditional likelihood. Our results show that BMA-AODE is outperformed by AODE, even when using the conditional likelihood. BMA-AODE is outperformed by AODE both because its excessive concentration around the most probable model (Boulle\u0301, 2007; Cerquides et al.,\n4For each indicator of performance, we generate two paired vectors: the same position in both vectors refers to the same data set. The two vectors are then used as input for the test.\n2005; Domingos, 2000; Minka, 2002) which tends to cancel the advantage of averaging over models, and because of the effectiveness of simply averaging over SPODEs, as done by AODE, in terms of reduction of the variance error.\nAs outlined by Figure 3(b), the difference between accuracies is instead not significant when comparing COMP-AODE and AODE. However COMP-AODE outperforms AODE on the Brier loss (p-value < .01); in Figure 4(b) we show the relative Brier losses, namely the Brier loss of COMP-AODE divided, data set by data set, by the Brier loss of AODE. Averaging over data sets, COMP-AODE reduces the Brier loss of about 3% compared to AODE. We see this result as noteworthy, since AODE is a high performance classifier. These positive results with the compression-based approach broaden the scope of the experiments of (Boulle\u0301, 2007), in which the compression approach was applied to an ensemble of naive Bayes classifiers."}, {"heading": "3.2. Credal classifiers", "text": "A credal classifier can be seen as separating the instances into two groups: the safe ones, for which it returns a single class is returned, and the prior-dependent ones, for which it returns two or more classes. Note that prior-dependence is not an intrinsic property to the instance: an instance can be judged as prior-dependent by a certain credal classifier and as safe by a different credal classifier. To characterize the performance of a credal classifier, the following four indicators are considered (Corani and Zaffalon, 2008b):\n\u2022 determinacy: % of instances recognized as safe, namely classified with a single\nclass;\n\u2022 single-accuracy: the accuracy achieved over the instances recognized as safe;\n\u2022 set-accuracy: the accuracy achieved, by returning a set of classes, over the prior-\ndependent instances;\n\u2022 indeterminate output size: the average number of classes returned on the prior-\ndependent instances.\nAveraging over data sets, BMA-AODE* has 94% determinacy; it is completely determinate on 7 data sets. However, this determinacy fluctuates among data sets, showing for instance a significant correlation with the sample size n (\u03c1 = 0.3). The choice of the prior is less important on large data sets: bigger data sets tend to contain a lower percentage of prior-dependent instances, thus increasing determinacy. BMAAODE* performs well when indeterminate: averaging over all data sets, it achieves 90% set-accuracy by returning 2.3 classes (the average number of classes in the collection of data sets is 3.6). It is worth analyze the performance of BMA-AODE on the prior-dependent instances. In Figure 5(a) we compare, data set by data set, the accuracy achieved by BMA-AODE on the instances judged respectively as safe and as prior-dependent by BMA-AODE*; the plot shows a sharp drop of accuracy on the prior-dependent instances, which is statistically significant (p-value < .01). As a rough\nindication, averaging over data sets, the accuracy of BMA-AODE is 83% on the safe instances but only 52% on the instances recognizes as prior-dependent by BMA-AODE*. Thus, on the prior-dependent instances, BMA-AODE provides fragile classifications; on the same instances, BMA-AODE* returns a small-sized but highly accurate set of classes.\nAccuracy BMA-AODE\nAccuracy COMP-AODE\nLet us now analyze the performance of COMP-AODE*; it has higher determinacy than BMA-AODE*; averaging over data sets, its determinacy is 99%, with only minor fluctuations across data sets; the classifier is moreover completely determinate on 18 data sets. The determinacy of COMP-AODE* is very high and stable across data sets. Therefore, under the compression-based approach only a small fraction of the instances is prior-dependent; this robustness to the choice of the prior is likely to contribute to the good performance of compression-based ensemble of classifiers and constitutes a desirable but previously unknown property of the compression-based approach. Numerical inspection shows that the logarithmic smoothing of the models\u2019 posterior probabilities makes indeed the compression weights only little sensitive to the choice of the prior. COMP-AODE* performs well when indeterminate: averaging over all data sets, it achieves 95% set-accuracy by returning 2 classes (note that the indeterminate output size cannot be less than two).\nAgain, it is worth checking the behavior of the corresponding determinate classifier, namely COMP-AODE, on the instances that are prior-dependent for the COMPAODE*. In Figure 5(b) we compare, data set by data set, the accuracy achieved by COMP-AODE on the instances judged respectively safe and prior-dependent by COMP-AODE*; there is a large drop of accuracy on the prior-dependent instances, and the drop is significant (p-value < .01). Averaging over data sets, the accuracy of COMP-AODE drops from 82% on the safe instances to only 47% on the instances judged as prior-dependent by COMP-AODE*. Even COMP-AODE, despite its robustness to the specification of the prior, undergoes a severe loss of accuracy on the instances recognized as prior-dependent by COMP-AODE*. On the very same instances, COMP-AODE* returns a small sized but highly reliable set of classes, thus enhancing the overall classification reliability."}, {"heading": "3.3. Utility-based Measures", "text": "We have seen so far that the credal classifiers extend in a sensible way their determinate counterparts, being able to recognize prior-dependent instances and to robustly deal with them. Yet, it is not obvious how to compare credal and determinate classifiers by means of a synthetic indicator. In fact, to fairly compare determinate and indeterminate predictions is very challenging; to the best of our knowledge, a satisfactory solution exists only for 0-1 loss, while comparing determinate and indeterminate predictions in a cost-sensitive setting, in which different kind of errors imply different costs, is still an open problem. In the following we thus reason under 0-1 loss. The discounted accuracy rewards a prediction made of m classes with 1/m if it contains the true class, and with 0 otherwise. Discounted accuracy is then compared to the accuracy achieved by a determinate classifier. A theoretical justification for discounted-accuracy has been given by Zaffalon et al. (2011) showing that, within a betting framework based on fairly general assumptions, discounted-accuracy is the only score which satisfies some fundamental properties for assessing both determinate and indeterminate classifications. Yet Zaffalon et al. (2011) also shows some severe limits of discounted-accuracy, which we illustrate by means of an example: we consider two different medical doctors, doctors random and doctor vacuous, who should decide whether a patient is healthy or\ndiseased. Doctor random issues random diagnosis, using a uniform distribution over the two categories. Doctor vacuous instead always return both categories, admitting to be ignorant. Let us assume that the hospital profits a quantity of money proportional to the discounted-accuracy achieved by its doctors at each visit. Both doctors have the same expected discounted-accuracy for each visit, namely 1/2. For the hospital, both doctors provide the same expected profit on each visit, but with a substantial difference: the profit of doctor vacuous is deterministic, while the profit of doctor random is affected by considerable variance. Any risk-averse hospital manager should thus prefer doctor vacuous over doctor random, since it yields the same expected profit with less variance. In fact, under risk-aversion, the expected utility increases with expectation of the rewards and decreases with their variance (Levy and Markowitz, 1979). To capture this point it is necessary introducing a utility function, to be then applied on the discounted-accuracy score assigned on each instance. In Zaffalon et al. (2011) the utility function is designed as follows: the utility of a correct and determinate classification (discounted-accuracy 1) is 1; the utility of a wrong classification (discounted-accuracy 0) is 0; the utility of an accurate but indeterminate classification consisting of two classes (discounted-accuracy 0.5) is assumed to lie between 0.65 and 0.8. Two quadratic utility functions are then derived corresponding to these boundary values, and passing respectively through {u(0) = 0, u(0.5) = 0.65, u(1) = 1} and {u(0) = 0, u(0.5) = 0.8, u(1) = 1}, denoted as u65 and u80 respectively5. Since u(1) = 1, utility and accuracy coincide for determinate classifiers; therefore, utility of credal classifiers and accuracy of determinate classifiers can be directly compared. In del Coz and Bahamonde (2009) classifiers which return indeterminate classifications are scored through the F1-metric, originally designed for Information Retrieval tasks. The F1 metric, when applied to indeterminate classifications, returns a score which is always comprised between u65 and u80, further confirming the reasonableness of both utility functions. More details on the links between F1, u65 and u80 are given in Zaffalon et al. (2012). We remark that in real applications the utility function should\n5The mathematical expression of these utility functions are as follows: u65(x) = \u22121.2x2 + 2.2x, u80(x) = \u22120.6x2 + 1.6x, where x is the value of discounted accuracy.\nbe elicited by discussion with the decision maker; in this paper we use u65 and u80 to model two reasonable but different degrees of risk-aversion.\nWe now analyze the utilities generated by the various classifiers, comparing each\ncredal classifier with its determinate counterpart. BMA-AODE* has significantly higher utility (p-value < .01) than BMA-AODE under both u65 and u80. This confirms that extending the model to imprecise probability is a sensible approach. In the first row of Figure 6 we show the relative utility, namely the utility of BMA-AODE* divided, data set by data set, by the utility (i.e., accuracy) of BMA-AODE; the two plots refer respectively to u65 and u80. Averaging over data sets, the improvement of utility is about 1% and 2% under u65 and u80; although the improvement might look small, we recall that it is obtained by modifying the classifications of the prior-dependent instances only, 6% of the total on average. If we focus on the prior-dependent instances only, the increase of utility generally varies between +10% and +40% depending on the data set and on the utility function. Clearly, the improvement is even larger under u80 which\nassigns higher utility than u65 to the indeterminate but accurate classifications.\nThe analysis is similar when comparing COMP-AODE* with COMP-AODE. In the second row of Figure 6 we show the relative utility, namely the utility of COMPAODE* divided, data set by data set, by the utility (i.e., accuracy) of COMP-AODE. The increase of utility is in this case generally under 1%, as a consequence of the higher determinacy of COMP-AODE (99% on average), which allows less room for improving utility through indeterminate classifications. In fact, the robustness of COMPAODE to the choice of the prior reduces the portion of instances where it is necessary making the classification indeterminate. Focusing however on the (rare) indeterminate instances, the increase of utility deriving to the extension to imprecise probability lies between 39% and 60%, depending on the data set and on the utility function. Eventually, COMP-AODE* has significantly (p-value< .01) higher utility than COMP-AODE under both u65 and u80; also in this case the extension to the credal paradigm is beneficial.\nThe utilities of COMP-AODE* and BMA-AODE* are also compared; under u65 COMP-AODE* yields significantly (p-value < .05) higher utility than BMA-AODE*, while under u80 the difference among the two classifiers is not significant, although the utility generated by COMP-AODE* is generally slightly higher. The point is that BMA-AODE* is more often indeterminate than COMP-AODE*; under u80 the indeterminate but accurate classifications are rewarded more than under u65, thus allowing BMA-AODE* to almost close the gap with COMP-AODE*. We conclude however that COMP-AODE* should be generally preferred over BMA-AODE*.\nEventually we point out that COMP-AODE* generates significantly (p-value < .01) higher utility than AODE, under both u65 and u80. The extension to imprecise probability has thus concretely improved the overall performance of the compressionbased ensemble: recall that the determinate COMP-AODE yields better probability estimates but not better accuracy than AODE."}, {"heading": "3.4. Comparison with previous credal classifiers", "text": "In this section we compare COMP-AODE* with previous credal classifiers. A well-known credal classifier is the naive credal classifier (NCC) (Corani and Zaffalon,\n2008b), which is an extension of naive Bayes to imprecise probability. We have ran NCC on the same collection of data sets following the experimental setup of Section 3; under both u65 and u80, the utility produced by COMP-AODE* is significantly higher (p <0.01) than that produced by NCC. Thus, COMP-AODE* outperforms NCC.\nHowever, over time algorithms more sophisticated than NCC have been developed,\nsuch as:\n\u2022 credal model averaging (CMA) (Corani and Zaffalon, 2008a), namely a gener-\nalization of BMA (in the same spirit of BMA-AODE) for naive Bayes classifier;\n\u2022 credal decision tree (CDT) (Abella\u0301n and Moral, 2005), namely an extension of\nclassification trees to imprecise probability.\nWe then compare CDT, CMA and COMP-AODE* via the Friedman test; this is the approach recommended by (Demsar, 2006) for comparing multiple classifiers on multiple data sets. First, the procedure ranks on each data set the classifiers according to the utility they generate; then, it tests the null hypothesis of all classifiers having the same average rank across the data sets. If the null hypothesis is rejected, a post-hoc test is adopted to identify the significant differences among classifiers. Adopting a 95% con-\nfidence, no significant difference is detected among classifiers; the result is the same under both utilities. However, under both utilities COMP-AODE* has the best average rank, as shown in Figure 3.4. Lowering the confidence to 90%, two significant differences are found: a) COMP-AODE* produces significantly higher utility than CMA under u65 and b) COMP-AODE* produces significantly higher utility than CDT under u80. These results, though not completely conclusive, suggest that COMP-AODE* compares favorably to previous credal classifiers."}, {"heading": "3.5. Some comments on credal classification vs reject option", "text": "Determinate classifiers can be equipped with a reject option (Herbei and Wegkamp, 2006), thus refusing to classify an instance if the posterior probability of the most probable class is less than a threshold. For the sake of simplicity we consider a case with two classes only; to formally introduce the reject option, it is necessary setting a cost d (0 < d < 1/2), which is incurred when rejecting an instance. A cost 0, 1, d is therefore incurred when respectively correctly classifying, wrongly classifying and rejecting an instance. Under 0-1 loss, the expected cost for classifying an instance corresponds to the probability of misclassification; it is thus 1 \u2212 p\u2217, where p\u2217 denotes the posterior probability of the most probable class. The optimal behavior is thus to reject the classification whenever the expected classification cost is higher than the rejection cost, namely when (1 \u2212 p\u2217) > d; this is equivalent to rejecting the instance whenever p\u2217 < 1\u2212 d, where (1\u2212 d) constitutes the rejection threshold.\nThe behavior induced by the reject option is quite different from that of a credal classifier, as we show in the following example. On an a very large data set the posterior probability of the classes is little sensitive on the choice of the prior, because of the wide amount of data available for learning; in this condition, instance are rarely priordependent and therefore a credal classifier will mostly return a single class. On the other hand, the determinate classifier with reject option (RO in the following) rejects all the instances for which p\u2217 < 1\u2212d; if d is small, there can be even a high number of rejected instances. The difference between these behaviors is due to the credal classifier being unaware of the cost d associated with rejecting an instance, which is instead driving the behavior of RO. To rigorously compare RO against a credal classifier, it is\nthus necessary making the credal classifier aware of the cost d. Recalling that the credal classifier already returns both classes on the instances which are prior dependent, this will change the behavior of the credal classifier only on the instances which are not prior-dependent. In particular, the credal classifier should reject all the instances for which p\u2217 < 1 \u2212 d, where p\u2217 is the lower probability of the most probable class; the instances rejected by means of this criterion will be thus a superset of those rejected by RO. Therefore, the credal classifier will reject the instances which are prior-dependent and those for which p\u2217 < 1\u2212 d. Eventually, the cost generated by the credal classifier should be compared with those generated by the RO. In the case with more than 2 classes the analysis might become slightly more complicated than what discussed here; however, we leave the analysis of credal classifiers with reject option as a topic for future research. Note also that this kind of experiment will require the computation of upper and lower posterior probability of the classes, which is not always trivial with credal classifiers."}, {"heading": "4. Conclusions", "text": "Applying Bayesian Model Averaging over SPODEs actually worsens the classification performance compared to the standard AODE. Instead the COMP-AODE classifier proposed here, which applies the compression-based approach over SPODEs, obtains overall slightly better classification performance than AODE; our results thus broadens the scope of (Boulle\u0301, 2007), in which the compression-based approach was applied over an ensemble of naive Bayes classifiers. The two credal classifiers BMAAODE* and COMP-AODE* extend respectively BMA-AODE and COMP-AODE to imprecise probability, replacing the uniform prior over the SPODEs by a credal set; both credal classifiers automatically identify the prior-dependent instances, and cope reliably with them by returning a small-sized but highly accurate set of classes. On the prior-dependent instances both BMA-AODE and COMP-AODE undergo a severe drop of accuracy. Both BMA-AODE* and COMP-AODE* provide overall higher performance than their determinate counterparts as measured by the utility-based measures, which to our knowledge constitute the state of the art for comparing determinate\nand credal classifiers. According to the same metrics, COMP-AODE* shows better performance than previous credal classifiers."}, {"heading": "Acknowledgements", "text": "The research in this paper has been partially supported by the Swiss NSF grants no.\n200020-132252 and by the Hasler foundation grant n. 10030."}, {"heading": "Appendix A. Mapping linear-fractional programs to linear programs by the CharnesCooper transformation", "text": "In this appendix, we adapt the classical Charnes-Cooper transformation to the particular linear-fractional program to be solved to test dominance for the BMA-AODE* as described in Section 2.3. Let us write the optimization variables as xj := P (sj) (with j = 1, . . . , k) and the coefficients as: \n\n\u03b3i \u03b4i\n\n :=\n\n\nP (c\u2032|a\u0303,mj) P (c\u2032\u2032|a\u0303,mj)\n\n \u00b7 Lj . (A.1)\nThe objective function rewrites therefore as:\n\u2211k\nj=1 \u03b3jxj \u2211k\nj=1 \u03b4jxj . (A.2)\nwith j = 1, . . . , k. Let us indeed change the variables as follows:\nyj := xj \u2211\nj \u03b4jxj , (A.3)\nand introduce the auxiliary variable\nt := 1 \u2211\nj \u03b4jxj . (A.4)\nAfter this, non-linear, transformation, the objective function takes a linear form:\n\u2211\nj\n\u03b3jyj , (A.5)\nwhile each linear constraint xj \u2265 \u01eb, rewrites as yj \u2265 \u01ebt, thus being still linear. Similarly, the normalization rewrites as:\n\u2211\nj\nyj = t.\nWe have therefore mapped the original problem into a standard linear program and the solutions of the two problems are known to coincide (Bajalinov, 2003, Chap. 3). Note that the transformation only increases by one the number of constraints."}, {"heading": "Appendix B. Data sets list", "text": ""}], "references": [{"title": "Upper entropy of credal sets. applications to credal classification", "author": ["J. Abell\u00e1n", "S. Moral"], "venue": "International Journal of Approximate Reasoning", "citeRegEx": "Abell\u00e1n and Moral,? \\Q2005\\E", "shortCiteRegEx": "Abell\u00e1n and Moral", "year": 2005}, {"title": "Linear-fractional programming: theory, methods, applications and software", "author": ["E. Bajalinov"], "venue": null, "citeRegEx": "Bajalinov,? \\Q2003\\E", "shortCiteRegEx": "Bajalinov", "year": 2003}, {"title": "Compression-based averaging of selective naive bayes classifiers", "author": ["M. Boull\u00e9"], "venue": "Journal of Machine Learning Research", "citeRegEx": "Boull\u00e9,? \\Q2007\\E", "shortCiteRegEx": "Boull\u00e9", "year": 2007}, {"title": "Robust Bayesian linear classifier ensembles", "author": ["J. Cerquides", "R De M\u00e0ntaras"], "venue": "Lecture notes in computer science", "citeRegEx": "Cerquides and M\u00e0ntaras,? \\Q2005\\E", "shortCiteRegEx": "Cerquides and M\u00e0ntaras", "year": 2005}, {"title": "Combining probability distributions from experts in risk analysis", "author": ["R. Clemen", "R. Winkler"], "venue": "Risk Analysis", "citeRegEx": "Clemen and Winkler,? \\Q1999\\E", "shortCiteRegEx": "Clemen and Winkler", "year": 1999}, {"title": "Bayesian networks with imprecise probabilities: Theory and application to classification", "author": ["G. Corani", "A. Antonucci", "M. Zaffalon"], "venue": "Data Mining: Foundations and Intelligent Paradigms", "citeRegEx": "Corani et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Corani et al\\.", "year": 2012}, {"title": "Credal model averaging: an extension of Bayesian model averaging to imprecise probabilities", "author": ["G. Corani", "M. Zaffalon"], "venue": "Proc. 12th European Conference on Machine Learning (ECML-PKDD", "citeRegEx": "Corani and Zaffalon,? \\Q2008\\E", "shortCiteRegEx": "Corani and Zaffalon", "year": 2008}, {"title": "Learning reliable classifiers from small or incomplete data sets: the naive credal classifier 2", "author": ["G. Corani", "M. Zaffalon"], "venue": "Journal of Machine Learning Research", "citeRegEx": "Corani and Zaffalon,? \\Q2008\\E", "shortCiteRegEx": "Corani and Zaffalon", "year": 2008}, {"title": "On searching for optimal classifiers among bayesian networks", "author": ["R. Cowell"], "venue": "Proceedings of the Eighth International Conference on Artificial Intelligence and Statistics", "citeRegEx": "Cowell,? \\Q2001\\E", "shortCiteRegEx": "Cowell", "year": 2001}, {"title": "Model Averaging for Prediction with Discrete Bayesian Networks", "author": ["D. Dash", "G. Cooper"], "venue": "Journal of Machine Learning Research", "citeRegEx": "Dash and Cooper,? \\Q2004\\E", "shortCiteRegEx": "Dash and Cooper", "year": 2004}, {"title": "Learning nondeterministic classifiers", "author": ["J. del Coz", "A. Bahamonde"], "venue": "Journal of Machine Learning Research", "citeRegEx": "Coz and Bahamonde,? \\Q2009\\E", "shortCiteRegEx": "Coz and Bahamonde", "year": 2009}, {"title": "Statistical comparisons of classifiers over multiple data sets", "author": ["J. Demsar"], "venue": "Journal of Machine Learning Research", "citeRegEx": "Demsar,? \\Q2006\\E", "shortCiteRegEx": "Demsar", "year": 2006}, {"title": "Bayesian averaging of classifiers and the overfitting problem", "author": ["P. Domingos"], "venue": "Proc. of the 17th International Conference on Machine Learning", "citeRegEx": "Domingos,? \\Q2000\\E", "shortCiteRegEx": "Domingos", "year": 2000}, {"title": "On the optimality of the simple Bayesian classifier under zero-one loss", "author": ["P. Domingos", "M. Pazzani"], "venue": "Machine Learning", "citeRegEx": "Domingos and Pazzani,? \\Q1997\\E", "shortCiteRegEx": "Domingos and Pazzani", "year": 1997}, {"title": "A synthetic view of belief revision with uncertain inputs in the framework of possibility theory", "author": ["D. Dubois", "H. Prade"], "venue": "International Journal of Approximate Reasoning", "citeRegEx": "Dubois and Prade,? \\Q1997\\E", "shortCiteRegEx": "Dubois and Prade", "year": 1997}, {"title": "Multi-interval discretization of continuous-valued attributes for classification learning. In: Proceedings of the 13th international joint conference on artificial intelligence", "author": ["U.M. Fayyad", "K.B. Irani"], "venue": null, "citeRegEx": "Fayyad and Irani,? \\Q1993\\E", "shortCiteRegEx": "Fayyad and Irani", "year": 1993}, {"title": "On bias, variance, 0/1 - loss, and the curse-of-dimensionality", "author": ["J. Friedman"], "venue": "Data Mining and Knowledge Discovery", "citeRegEx": "Friedman,? \\Q1997\\E", "shortCiteRegEx": "Friedman", "year": 1997}, {"title": "Bayesian networks classifiers", "author": ["N. Friedman", "D. Geiger", "M. Goldszmidt"], "venue": "Machine Learning", "citeRegEx": "Friedman et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 1997}, {"title": "Classification with reject option", "author": ["R. Herbei", "M. Wegkamp"], "venue": "Canadian Journal of Statistics", "citeRegEx": "Herbei and Wegkamp,? \\Q2006\\E", "shortCiteRegEx": "Herbei and Wegkamp", "year": 2006}, {"title": "Bayesian Model Averaging: a Tutorial", "author": ["J. Hoeting", "D. Madigan", "A. Raftery", "C. Volinsky"], "venue": "Statistical Science", "citeRegEx": "Hoeting et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Hoeting et al\\.", "year": 1999}, {"title": "On supervised selection of bayesian networks", "author": ["P. Kontkanen", "P. Myllymaki", "T. Silander", "H. Tirri"], "venue": "Proc. of the Fifteenth Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "Kontkanen et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Kontkanen et al\\.", "year": 1999}, {"title": "The Enterprise of Knowledge", "author": ["I. Levi"], "venue": null, "citeRegEx": "Levi,? \\Q1980\\E", "shortCiteRegEx": "Levi", "year": 1980}, {"title": "Approximating expected utility by a function of mean and variance", "author": ["H. Levy", "H. Markowitz"], "venue": "The American Economic Review", "citeRegEx": "Levy and Markowitz,? \\Q1979\\E", "shortCiteRegEx": "Levy and Markowitz", "year": 1979}, {"title": "Bayesian model averaging is not model combination", "author": ["T. Minka"], "venue": "Tech. rep., MIT Media Lab note. URL http://research.microsoft.com/ \u0303{}minka/papers/minka-bma-isnt-mc.pdf", "citeRegEx": "Minka,? \\Q2002\\E", "shortCiteRegEx": "Minka", "year": 2002}, {"title": "Limits of learning about a categorical latent variable under prior near-ignorance", "author": ["A. Piatti", "M. Zaffalon", "F. Trojani", "M. Hutter"], "venue": "International Journal of Approximate Reasoning", "citeRegEx": "Piatti et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Piatti et al\\.", "year": 2009}, {"title": "Decision making under uncertainty using imprecise probabilities", "author": ["M. Troffaes"], "venue": "International Journal of Approximate Reasoning", "citeRegEx": "Troffaes,? \\Q2007\\E", "shortCiteRegEx": "Troffaes", "year": 2007}, {"title": "Statistical Reasoning with Imprecise Probabilities", "author": ["P. Walley"], "venue": null, "citeRegEx": "Walley,? \\Q1991\\E", "shortCiteRegEx": "Walley", "year": 1991}, {"title": "Not so naive bayes: Aggregating onedependence estimators", "author": ["G. Webb", "J. Boughton", "Z. Wang"], "venue": "Machine Learning", "citeRegEx": "Webb et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Webb et al\\.", "year": 2005}, {"title": "To select or to weigh: A comparative study of linear combination schemes for superparentone-dependence estimators. Knowledge and Data Engineering", "author": ["Y. Yang", "G. Webb", "J. Cerquides", "K. Korb", "J. Boughton", "K. Ting"], "venue": "IEEE Transactions on", "citeRegEx": "Yang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2007}, {"title": "Utility-based accuracy measures to empirically evaluate credal classifiers", "author": ["M. Zaffalon", "G. Corani", "D. Mau\u00e1"], "venue": "ISIPTA\u201911: Proceedings of the Seventh International Symposium on Imprecise Probability: Theories and Applications. SIPTA,", "citeRegEx": "Zaffalon et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zaffalon et al\\.", "year": 2011}, {"title": "Evaluating credal classifiers by utilitydiscounted predictive accuracy", "author": ["M. Zaffalon", "G. Corani", "D. Maua"], "venue": "Tech. Rep. IDSIA-03-12, IDSIA (Istituto Dalle Molle Intelligenza Artificiale", "citeRegEx": "Zaffalon et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zaffalon et al\\.", "year": 2012}, {"title": "We have therefore mapped the original problem into a standard linear program and the solutions of the two problems are known to coincide (Bajalinov", "author": [], "venue": "Chap", "citeRegEx": "t.,? \\Q2003\\E", "shortCiteRegEx": "t.", "year": 2003}], "referenceMentions": [{"referenceID": 2, "context": "The compression-based approach (Boull\u00e9, 2007) overcomes this problem; it averages over the different models by applying a logarithmic smoothing over the models\u2019 posterior probabilities.", "startOffset": 31, "endOffset": 45}, {"referenceID": 27, "context": "AODE is another ensemble of models with high performance (Webb et al., 2005): it consists of a collection of non-naive classifiers (called SPODE) whose probabilistic predictions are aggregated by simple arithmetic mean.", "startOffset": 57, "endOffset": 76}, {"referenceID": 19, "context": "Introduction Bayesian model averaging (BMA) (Hoeting et al., 1999) is a sound solution to the uncertainty which characterizes the identification of the supposedly best model for a certain data set; given a set of alternative models, BMA weights the inferences produced by the various models, using the models\u2019 posterior probabilities as weights.", "startOffset": 44, "endOffset": 66}, {"referenceID": 19, "context": "BMA assumes the data to be generated by one of the considered models; under this assumption, it provides better predictive accuracy than any single model (Hoeting et al., 1999).", "startOffset": 154, "endOffset": 176}, {"referenceID": 12, "context": "The problem is that BMA gets excessively concentrated around the single most probable model (Domingos, 2000; Minka, 2002): especially on large data sets, \u201caveraging using the posterior probabilities to weight the models is almost the same as selecting the MAP model\u201d (Boull\u00e9, 2007).", "startOffset": 92, "endOffset": 121}, {"referenceID": 23, "context": "The problem is that BMA gets excessively concentrated around the single most probable model (Domingos, 2000; Minka, 2002): especially on large data sets, \u201caveraging using the posterior probabilities to weight the models is almost the same as selecting the MAP model\u201d (Boull\u00e9, 2007).", "startOffset": 92, "endOffset": 121}, {"referenceID": 2, "context": "The problem is that BMA gets excessively concentrated around the single most probable model (Domingos, 2000; Minka, 2002): especially on large data sets, \u201caveraging using the posterior probabilities to weight the models is almost the same as selecting the MAP model\u201d (Boull\u00e9, 2007).", "startOffset": 267, "endOffset": 281}, {"referenceID": 2, "context": "To overcome the problem of BMA getting excessively concentrated around the most probable model, a compression-based approach has been introduced in (Boull\u00e9, 2007); it computes more evenly-distributed weights, by applying a logarithmic smoothing to the models posterior probabilities.", "startOffset": 148, "endOffset": 162}, {"referenceID": 27, "context": "Another ensemble of Bayesian networks classifiers known for its good performance is AODE (Webb et al., 2005), which is instead based on a set of SPODE (SuperParent-", "startOffset": 89, "endOffset": 108}, {"referenceID": 17, "context": "Introduction Bayesian model averaging (BMA) (Hoeting et al., 1999) is a sound solution to the uncertainty which characterizes the identification of the supposedly best model for a certain data set; given a set of alternative models, BMA weights the inferences produced by the various models, using the models\u2019 posterior probabilities as weights. BMA assumes the data to be generated by one of the considered models; under this assumption, it provides better predictive accuracy than any single model (Hoeting et al., 1999). However, such an assumption is generally not true; for this reason, on real data sets BMA does not generally perform very well; see the discussion and the references in Cerquides et al. (2005) for more details.", "startOffset": 45, "endOffset": 717}, {"referenceID": 2, "context": "The problem is that BMA gets excessively concentrated around the single most probable model (Domingos, 2000; Minka, 2002): especially on large data sets, \u201caveraging using the posterior probabilities to weight the models is almost the same as selecting the MAP model\u201d (Boull\u00e9, 2007). To overcome the problem of BMA getting excessively concentrated around the most probable model, a compression-based approach has been introduced in (Boull\u00e9, 2007); it computes more evenly-distributed weights, by applying a logarithmic smoothing to the models posterior probabilities. The compression-based weights, which can be justified from an information-theoretic viewpoint, have been used in Boull\u00e9 (2007) to average over different naive Bayes classifiers, characterized by different feature sets, obtaining excellent rank in international competitions on classification.", "startOffset": 268, "endOffset": 694}, {"referenceID": 28, "context": "Alternative methods to aggregate SPODEs, more complex than AODE, have been considered (Yang et al., 2007), but AODE generally outperforms them: \u201cAODE, which simply linearly combines every SPODE without any selection or weighting, is actually more effective than the majority of rival schemes\u201d.", "startOffset": 86, "endOffset": 105}, {"referenceID": 28, "context": "As reported in (Cerquides et al., 2005; Yang et al., 2007), AODE outperforms aggregating SPODEs via BMA; in both (Yang et al.", "startOffset": 15, "endOffset": 58}, {"referenceID": 28, "context": ", 2007), AODE outperforms aggregating SPODEs via BMA; in both (Yang et al., 2007; Cerquides et al., 2005) the best results were instead obtained using an algorithm (called MAPLMG), which estimates the most probable linear mixture of SPODEs; this overcomes the problem of assuming a single SPODE to be the true model.", "startOffset": 62, "endOffset": 105}, {"referenceID": 5, "context": "We address this problem by adopting the paradigm of credal classification (Corani et al., 2012; Corani and Zaffalon, 2008b), namely drop-", "startOffset": 74, "endOffset": 123}, {"referenceID": 23, "context": "Alternative methods to aggregate SPODEs, more complex than AODE, have been considered (Yang et al., 2007), but AODE generally outperforms them: \u201cAODE, which simply linearly combines every SPODE without any selection or weighting, is actually more effective than the majority of rival schemes\u201d. As reported in (Cerquides et al., 2005; Yang et al., 2007), AODE outperforms aggregating SPODEs via BMA; in both (Yang et al., 2007; Cerquides et al., 2005) the best results were instead obtained using an algorithm (called MAPLMG), which estimates the most probable linear mixture of SPODEs; this overcomes the problem of assuming a single SPODE to be the true model. In this paper, we address this problem by means of the compression coefficients. As a preliminary step we develop BMA-AODE, namely BMA over SPODEs, with some computational differences with respect to the framework of Yang et al. (2007) and Cerquides et al.", "startOffset": 87, "endOffset": 898}, {"referenceID": 23, "context": "Alternative methods to aggregate SPODEs, more complex than AODE, have been considered (Yang et al., 2007), but AODE generally outperforms them: \u201cAODE, which simply linearly combines every SPODE without any selection or weighting, is actually more effective than the majority of rival schemes\u201d. As reported in (Cerquides et al., 2005; Yang et al., 2007), AODE outperforms aggregating SPODEs via BMA; in both (Yang et al., 2007; Cerquides et al., 2005) the best results were instead obtained using an algorithm (called MAPLMG), which estimates the most probable linear mixture of SPODEs; this overcomes the problem of assuming a single SPODE to be the true model. In this paper, we address this problem by means of the compression coefficients. As a preliminary step we develop BMA-AODE, namely BMA over SPODEs, with some computational differences with respect to the framework of Yang et al. (2007) and Cerquides et al. (2005); our results confirm however that BMA over SPODEs is outperformed by AODE.", "startOffset": 87, "endOffset": 926}, {"referenceID": 15, "context": "A common choice is to adopt a uniform mass function, as we do in both BMA-AODE and COMP-AODE; this however can be criticized from different standpoints; see for instance the rejoinder in Hoeting et al. (1999). In Boull\u00e9 (2007), a prior which favors simpler models over complex ones is adopted.", "startOffset": 187, "endOffset": 209}, {"referenceID": 2, "context": "In Boull\u00e9 (2007), a prior which favors simpler models over complex ones is adopted.", "startOffset": 3, "endOffset": 17}, {"referenceID": 21, "context": "ping the unique prior in favor of a set of priors (prior credal set) (Levi, 1980).", "startOffset": 69, "endOffset": 81}, {"referenceID": 13, "context": "Despite the biased estimate of probabilities due to the above (so-called naive) assumption, naive Bayes performs well under 01 loss (Domingos and Pazzani, 1997); it thus constitutes a reasonable choice if the goal is simple classification, without the need for accurate probability estimates; it is especially competitive on data sets of small and medium size , thanks to its low variance error (Friedman, 1997).", "startOffset": 132, "endOffset": 160}, {"referenceID": 16, "context": "Despite the biased estimate of probabilities due to the above (so-called naive) assumption, naive Bayes performs well under 01 loss (Domingos and Pazzani, 1997); it thus constitutes a reasonable choice if the goal is simple classification, without the need for accurate probability estimates; it is especially competitive on data sets of small and medium size , thanks to its low variance error (Friedman, 1997).", "startOffset": 395, "endOffset": 411}, {"referenceID": 17, "context": "Generally, TAN outperforms naive Bayes in classification (Friedman et al., 1997).", "startOffset": 57, "endOffset": 80}, {"referenceID": 27, "context": "The AODE classifier (Webb et al., 2005) is an ensemble of k SPODE (SuperParent One Dependence Estimator) classifiers; each SPODE is characterized by a certain super-parent feature, so that the other features are modeled as depending on both the class and the super-parent, as shown in in Fig.", "startOffset": 20, "endOffset": 39}, {"referenceID": 28, "context": "This computational schema has been adopted to implement BMA over SPODEs in (Cerquides et al., 2005; Yang et al., 2007), and has been outperformed by AODE.", "startOffset": 75, "endOffset": 118}, {"referenceID": 8, "context": "Therefore, a model can perform badly at classification despite having high marginal likelihood (Cowell, 2001; Kontkanen et al., 1999); for this reason, scoring rules more appropriate for classification should be considered.", "startOffset": 95, "endOffset": 133}, {"referenceID": 20, "context": "Therefore, a model can perform badly at classification despite having high marginal likelihood (Cowell, 2001; Kontkanen et al., 1999); for this reason, scoring rules more appropriate for classification should be considered.", "startOffset": 95, "endOffset": 133}, {"referenceID": 2, "context": "Following Boull\u00e9 (2007), we thus substitute the marginal likelihood with conditional likelihood: Lj := n", "startOffset": 10, "endOffset": 24}, {"referenceID": 14, "context": "We remove from the ensemble the SPODEs whose conditional likelihood is smaller than Lmax/10, where Lmax is the maximum conditional likelihood among all SPODEs; discarding models with very low posterior probability is in fact common when dealing with BMA; this procedure can be seen as a belief revision (Dubois and Prade, 1997).", "startOffset": 303, "endOffset": 327}, {"referenceID": 9, "context": "Dash, who published several works on BMA (Dash and Cooper, 2004).", "startOffset": 41, "endOffset": 64}, {"referenceID": 26, "context": "BMA-AODE*: Extending BMA-AODE to Sets of Probabilities By BMA-AODE* we extend BMA-AODE to imprecise probabilities (Walley, 1991), allowing multiple specifications of the prior mass function P (S); we denote the credal set containing such prior mass functions as P(S).", "startOffset": 114, "endOffset": 128}, {"referenceID": 24, "context": "Yet, this would generate vacuous posterior inferences, thus preventing learning from data (Piatti et al., 2009).", "startOffset": 90, "endOffset": 111}, {"referenceID": 25, "context": "This issue has been addressed in Yang et al. (2007) by means of high numerical precision: \u201cBMA often lead to arithmetic overflow when calculating very large exponentials or factorials.", "startOffset": 33, "endOffset": 52}, {"referenceID": 5, "context": "When dealing with prior-dependent instances, credal classifiers (Corani et al., 2012; Corani and Zaffalon, 2008b) become indeterminate, by returning a set of classes instead of a single class.", "startOffset": 64, "endOffset": 113}, {"referenceID": 25, "context": "We point the reader to (Troffaes, 2007) for a discussion of alternative criteria for taking decisions under imprecise probabilities.", "startOffset": 23, "endOffset": 39}, {"referenceID": 2, "context": "Compression-Based averaging Compression-based averaging has been introduced by (Boull\u00e9, 2007) as a remedy against the tendency of BMA at getting excessively concentrated around the most probable model, which indeed deteriorates the performances (Boull\u00e9, 2007; Domingos, 2000).", "startOffset": 79, "endOffset": 93}, {"referenceID": 2, "context": "Compression-Based averaging Compression-based averaging has been introduced by (Boull\u00e9, 2007) as a remedy against the tendency of BMA at getting excessively concentrated around the most probable model, which indeed deteriorates the performances (Boull\u00e9, 2007; Domingos, 2000).", "startOffset": 245, "endOffset": 275}, {"referenceID": 12, "context": "Compression-Based averaging Compression-based averaging has been introduced by (Boull\u00e9, 2007) as a remedy against the tendency of BMA at getting excessively concentrated around the most probable model, which indeed deteriorates the performances (Boull\u00e9, 2007; Domingos, 2000).", "startOffset": 245, "endOffset": 275}, {"referenceID": 2, "context": "It has been shown (Boull\u00e9, 2007) that LL0 = \u2212nH(C), where H(C) := \u2212 \u2211 c\u2208C P (c) logP (c) is the entropy 2 of the class.", "startOffset": 18, "endOffset": 32}, {"referenceID": 2, "context": "Following (Boull\u00e9, 2007), we keep in the ensemble only the feasible models, namely those with \u03c0j > 0; we instead discard the models with \u03c0j < 0.", "startOffset": 10, "endOffset": 24}, {"referenceID": 2, "context": "The compression coefficients can be justified as follows (Boull\u00e9, 2007): LLj+logP (sj) \u201crepresents the quantity of information required to encode the model plus the class values given the model.", "startOffset": 57, "endOffset": 71}, {"referenceID": 4, "context": "COMP-AODE performs a weighted linear combination of probabilities estimated by different models; in risk analysis, a weighted linear combination of probabilities estimated by different experts is referred to as linear opinion pool (Clemen and Winkler, 1999).", "startOffset": 231, "endOffset": 257}, {"referenceID": 15, "context": "We discretize numerical features by the entropy-based method of (Fayyad and Irani, 1993).", "startOffset": 64, "endOffset": 88}, {"referenceID": 11, "context": "4 The Wilcoxon signed-rank test is indeed recommended for comparing two classifiers on multiple data sets (Demsar, 2006): being non-parametric it avoids strong assumptions and robustly deals with outliers.", "startOffset": 106, "endOffset": 120}, {"referenceID": 28, "context": "The fact that AODE outperforms BMAAODE could be expected; the same finding was already given in (Yang et al., 2007) and in (Cerquides et al.", "startOffset": 96, "endOffset": 115}, {"referenceID": 2, "context": "These positive results with the compression-based approach broaden the scope of the experiments of (Boull\u00e9, 2007), in which the compression approach was applied to an ensemble of naive Bayes classifiers.", "startOffset": 99, "endOffset": 113}, {"referenceID": 29, "context": "A theoretical justification for discounted-accuracy has been given by Zaffalon et al. (2011) showing that, within a betting framework based on fairly general assumptions, discounted-accuracy is the only score which satisfies some fundamental properties for assessing both determinate and indeterminate classifications.", "startOffset": 70, "endOffset": 93}, {"referenceID": 29, "context": "A theoretical justification for discounted-accuracy has been given by Zaffalon et al. (2011) showing that, within a betting framework based on fairly general assumptions, discounted-accuracy is the only score which satisfies some fundamental properties for assessing both determinate and indeterminate classifications. Yet Zaffalon et al. (2011) also shows some severe limits of discounted-accuracy, which we illustrate by means of an example: we consider two different medical doctors, doctors random and doctor vacuous, who should decide whether a patient is healthy or", "startOffset": 70, "endOffset": 346}, {"referenceID": 22, "context": "In fact, under risk-aversion, the expected utility increases with expectation of the rewards and decreases with their variance (Levy and Markowitz, 1979).", "startOffset": 127, "endOffset": 153}, {"referenceID": 21, "context": "In fact, under risk-aversion, the expected utility increases with expectation of the rewards and decreases with their variance (Levy and Markowitz, 1979). To capture this point it is necessary introducing a utility function, to be then applied on the discounted-accuracy score assigned on each instance. In Zaffalon et al. (2011) the utility function is designed as follows: the utility of a correct and determinate classification (discounted-accuracy 1) is 1; the utility of a wrong classification (discounted-accuracy 0) is 0; the utility of an accurate but indeterminate classification consisting of two classes (discounted-accuracy 0.", "startOffset": 128, "endOffset": 330}, {"referenceID": 10, "context": "In del Coz and Bahamonde (2009) classifiers which return indeterminate classifications are scored through the F1-metric, originally designed for Information Retrieval tasks.", "startOffset": 7, "endOffset": 32}, {"referenceID": 10, "context": "In del Coz and Bahamonde (2009) classifiers which return indeterminate classifications are scored through the F1-metric, originally designed for Information Retrieval tasks. The F1 metric, when applied to indeterminate classifications, returns a score which is always comprised between u65 and u80, further confirming the reasonableness of both utility functions. More details on the links between F1, u65 and u80 are given in Zaffalon et al. (2012). We remark that in real applications the utility function should", "startOffset": 7, "endOffset": 450}, {"referenceID": 0, "context": "However, over time algorithms more sophisticated than NCC have been developed, such as: \u2022 credal model averaging (CMA) (Corani and Zaffalon, 2008a), namely a generalization of BMA (in the same spirit of BMA-AODE) for naive Bayes classifier; \u2022 credal decision tree (CDT) (Abell\u00e1n and Moral, 2005), namely an extension of classification trees to imprecise probability.", "startOffset": 270, "endOffset": 295}, {"referenceID": 11, "context": "We then compare CDT, CMA and COMP-AODE* via the Friedman test; this is the approach recommended by (Demsar, 2006) for comparing multiple classifiers on multiple data sets.", "startOffset": 99, "endOffset": 113}, {"referenceID": 18, "context": "Some comments on credal classification vs reject option Determinate classifiers can be equipped with a reject option (Herbei and Wegkamp, 2006), thus refusing to classify an instance if the posterior probability of the most probable class is less than a threshold.", "startOffset": 117, "endOffset": 143}, {"referenceID": 2, "context": "Instead the COMP-AODE classifier proposed here, which applies the compression-based approach over SPODEs, obtains overall slightly better classification performance than AODE; our results thus broadens the scope of (Boull\u00e9, 2007), in which the compression-based approach was applied over an ensemble of naive Bayes classifiers.", "startOffset": 215, "endOffset": 229}], "year": 2014, "abstractText": "Bayesian model averaging (BMA) is a common approach to average over alternative models; yet, it usually gets excessively concentrated around the single most probable model, therefore achieving only sub-optimal classification performance. The compression-based approach (Boull\u00e9, 2007) overcomes this problem; it averages over the different models by applying a logarithmic smoothing over the models\u2019 posterior probabilities. This approach has shown excellent performances when applied to ensembles of naive Bayes classifiers. AODE is another ensemble of models with high performance (Webb et al., 2005): it consists of a collection of non-naive classifiers (called SPODE) whose probabilistic predictions are aggregated by simple arithmetic mean. Aggregating the SPODEs via BMA rather than by arithmetic mean deteriorates the performance; instead, we propose to aggregate the SPODEs via the compression coefficients and we show that the resulting classifier obtains a slight but consistent improvement over AODE. However, an important issue in any Bayesian ensemble of models is the arbitrariness in the choice of the prior over the models. We address this problem by adopting the paradigm of credal classification, namely by substituting the unique prior with a set of priors. Credal classifier are able to automatically recognize the prior-dependent instances, namely the instances whose most probable class varies, when different priors are considered; in these cases, credal classifiers remain reliable by returning a set of classes rather than a single class. We thus develop the credal version Corresponding author: giorgio@idsia.ch Preprint submitted to Elsevier January 1, 2014 of both the BMA-based and the compression-based ensemble of SPODEs, substituting the single prior over the models by a set of priors. By experiments we show that both credal classifiers provide overall higher classification reliability than their determinate counterparts. Moreover, the compression-based credal classifier compares favorably to previous credal classifiers.", "creator": "LaTeX with hyperref package"}}}