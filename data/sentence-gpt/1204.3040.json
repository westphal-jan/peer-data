{"id": "1204.3040", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Apr-2012", "title": "Tractable Answer-Set Programming with Weight Constraints: Bounded Treewidth is not Enough", "abstract": "Cardinality constraints or, more generally, weight constraints are well recognized as an important extension of answer-set programming. Clearly, all common algorithmic tasks related to programs with cardinality or weight constraints - like checking the consistency of a program - are intractable. Many intractable problems in the area of knowledge representation and reasoning have been shown to become linear time tractable if the treewidth of the programs or formulas under consideration is bounded by some constant. The goal of this paper is to apply the notion of treewidth to programs with cardinality or weight constraints and to identify tractable fragments. It will turn out that the straightforward application of treewidth to such class of programs does not suffice to obtain tractability. However, by imposing further restrictions, tractability can be achieved. The paper outlines how to generate a series of geometric numbers, one for each program, or for each of them, by combining them in two units.\n\n\nThe mathematics for computations, which are typically bounded by the geometric numbers of a program, has been described as a \"problem theory\". Its principal feature is the idea of making a geometric equation that satisfies a particular set of mathematical requirements. The basic problem for solving the problem is the definition of a problem. The number of instructions the program has to do can be a problem in which case the number of instructions a program has to do is not infinite. As in the problem of solving a function, the program must be efficient and is therefore useful for all computations involving the type of operations it has to do. This is an important limitation of the mathematical problems used for computations, because for this reason the mathematicians would be unable to achieve computations without a complete set of geometric numbers. The problem is solved in the following simple manner: The geometric number is determined using the equation specified by the mathematical algorithm, i.e., using a set of mathematics requirements. The equation defined by the mathematical algorithm is the geometric number, and the calculation will take place in a finite state. In general, the formula given by the mathematics algorithm must not be a problem.\nThe mathematical problem problem is the general mathematical problem of solving the problem of solving a function. The problem is the general mathematical problem of solving a function. The problem is the general mathematical problem of solving a function. The problem is the general mathematical problem of solving a function. The problem is the general mathematical problem of solving a function. The problem is the general mathematical problem of solving a function.\nThis is the mathematical problem of", "histories": [["v1", "Fri, 13 Apr 2012 16:25:30 GMT  (27kb,D)", "https://arxiv.org/abs/1204.3040v1", "Under consideration for publication in Theory and Practice of Logic Programming"], ["v2", "Tue, 29 May 2012 13:28:54 GMT  (27kb,D)", "http://arxiv.org/abs/1204.3040v2", "To appear in Theory and Practice of Logic Programming (TPLP)"]], "COMMENTS": "Under consideration for publication in Theory and Practice of Logic Programming", "reviews": [], "SUBJECTS": "cs.LO cs.AI cs.CC", "authors": ["reinhard pichler", "stefan r\\\"ummele", "stefan szeider", "stefan woltran"], "accepted": false, "id": "1204.3040"}, "pdf": {"name": "1204.3040.pdf", "metadata": {"source": "CRF", "title": "Tractable Answer-Set Programming with Weight Constraints: Bounded Treewidth is not Enough", "authors": ["Reinhard Pichler", "Stefan R\u00fcmmele", "Stefan Szeider", "Stefan Woltran"], "emails": ["woltran}@dbai.tuwien.ac.at,", "stefan@szeider.net"], "sections": [{"heading": "1 Introduction", "text": "Answer-set programming (ASP) has evolved as a paradigm that allows for very elegant solutions to many combinatorial problems [14]. The basic idea is to describe a problem by a logic program in such a way that the stable models correspond to the solutions of the considered problem. By extending logic programs with cardinality or, more generally, weight constraints, an even larger class of problems is accessible to this method [16]. For instance, in the product configuration domain, we need to express cardinality, cost, and resource constraints, which are very difficult to capture using logic programs without weights.\nIn this paper, we restrict ourselves to normal logic programs with cardinality constraints (PCCs, for short) or weight constraints (PWCs, for short). Clearly, all common algorithmic tasks related to PCCs and PWCs \u2013 like checking the consistency of a program \u2013 are intractable, since intractability even holds without such constraints. An interesting approach to dealing with intractable problems comes from parameterized complexity theory and is based on the following observation: Many hard problems become tractable if some parameter that represents a structural aspect of the problem instance is small. One important parameter is treewidth, which measures the \u201ctree-likeness\u201d of a graph or, more generally, of a structure. In the area of knowledge representation and reasoning (KR & R), many tractability results for instances of bounded treewidth have been recently proven [8]. The goal of this work is to obtain tractability results via bounded treewidth also for PCCs and PWCs. Hereby, the treewidth of a PCC or PWC is\n\u2217To appear in Theory and Practice of Logic Programming (TPLP). A preliminary version appeared in the Proceedings of the Twelfth International Conference on Principles of Knowledge Representation and Reasoning (KR 2010). \u2020Supported by the Austrian Science Fund (FWF): P20704-N18. \u2021Supported by the European Research Council (ERC), project 239962. \u00a7Supported by Vienna University of Technology special fund \u201cInnovative Projekte 9006.09/008\u201d.\nar X\niv :1\n20 4.\n30 40\nv2 [\ncs .L\nO ]\n2 9\nM ay\n2 01\ndefined in terms of its incidence graph (see Section 2). It will turn out that the straightforward application of treewidth to PWCs does not suffice to obtain tractability. However, by imposing further restrictions, tractability can be achieved.\nMain results of the paper.\n\u2022 We show that the consistency problem of PWCs remains NP-complete even if the treewidth of the considered programs is bounded by a constant (actually, even if this constant is 1). Hence, we have to search for further restrictions on the PWCs to ensure tractability.\n\u2022 We thus consider the largest integer occurring in (lower or upper) bounds of the constraints in the PWC, and call this parameter constraint-width. If also the constraint-width is bounded by an arbitrary but fixed constant, then the consistency problem of PWCs becomes linear time tractable (the bound on the running time entails a constant factor that is exponential in constraint-width and treewidth).\n\u2022 For PCCs (i.e., PWCs where all weights are equal to 1) we obtain non-uniform polynomial time tractability by designing a new dynamic programming algorithm. Let w denote the treewidth of a PCC \u03a0 and let n denote the size of \u03a0. Then our algorithm works in time O(f(w) \u00b7 n2w) for some function f that only depends on the treewidth, but not on the size n of the program. The term \u201cnon-uniform\u201d refers to the factor n2w in the time bound, where the size n of the program is raised to the power of an expression that depends on the treewidth w. We shall also discuss further extensions of this dynamic programming algorithm for PCCs. For example, it can be used to solve in non-uniform polynomial time the consistency problem of PWCs if the weights are given in unary representation.\n\u2022 Of course, an algorithm for the PCC consistency problem that operates in time O(f(w) \u00b7 nO(1)) would be preferable, i.e., the parameter w does not occur in the exponent of the program size n. A problem with such an algorithm is called fixed-parameter tractable. Alas, we show that under common complexity theoretical assumptions no such algorithm exists. Technically, we prove that the consistency problem of PCCs parameterized by treewidth is hard for the parameterized complexity class W [1]. In other words, a non-uniform polynomial-time running time of our dynamic programming algorithm is the best that one can expect.\nStructure of the paper. After recalling the necessary background in Section 2, we prove in Section 3 the NP-completeness of the consistency problem of PWCs in case of binary representation of the weights. In Section 4, we show the linear fixed-parameter tractability of the problem if we consider the treewidth plus the size of the bounds as parameter. In Section 5, the non-uniform polynomial-time upper bound for the consistency problem of PCCs is established by presenting a dynamic programming algorithm. Section 6 contains the extensions of the dynamic programming algorithm. By giving a W [1]-hardness proof in case of unary representation in Section 7, we show that it is unlikely that this result can be significantly improved. Section 8 contains a discussion and a conclusion is given in Section 9."}, {"heading": "2 Background", "text": "Weight constraint programs. A program with weight constraints (PWC) is a triple \u03a0 = (A, C,R), where A is a set of atoms, C is a set of weight constraints (or constraints for short), and R is a set of rules. Each constraint c \u2208 C is a triple (S, l, u) where S is a set of weight literals over A representing a clause and l \u2264 u are nonnegative integers, the lower and upper bound. A weight literal over A is a pair (a, j) or (\u00aca, j) for a \u2208 A and 1 \u2264 j \u2264 u + 1, the weight of the literal. Unless stated otherwise, we assume that the bounds and weights are given in binary representation. For a constraint c = (S, l, u) \u2208 C, we write Cl(c) := S, l(c) := l, and u(c) := u. Moreover, we use a \u2208 Cl(c) and \u00aca \u2208 Cl(c) as an abbreviation for (a, j) \u2208 Cl(c)\nrespectively (\u00aca, j) \u2208 Cl(c) for an arbitrary j. A rule r \u2208 R is a pair (h, b) where h \u2208 C is the head and b \u2286 C is the body. We write H(r) := h and B(r) := b. We denote by \u2016\u03a0\u2016 the size of a reasonable encoding of program \u03a0 and call it the size of \u03a0. Unless otherwise stated, weights are assumed to be encoded in binary notation. For instance taking \u2016\u03a0\u2016 = |A| + \u2211 (S,l,u)\u2208C(1 + log l + log u + \u2211 (lit,j)\u2208S(1 + log j)) + \u2211 (h,b)\u2208R(1 + |b|) would do. Given a constraint c \u2208 C and an interpretation I \u2286 A over atoms A, we denote the weight of c in I by\nW (c, I) = \u2211\n(a,j)\u2208Cl(c) a\u2208I\nj + \u2211\n(\u00aca,j)\u2208Cl(c) a 6\u2208I\nj .\nI is a model of c, denoted by I |= c, if l(c) \u2264W (c, I) \u2264 u(c). For a set C \u2286 C, I |= C if I |= c for all c \u2208 C. Moreover, C is a model of a rule r \u2208 R, denoted by C |= r, if H(r) \u2208 C or B(r) 6\u2286 C. I is a model of program \u03a0 (denoted by I |= \u03a0) if {c \u2208 C : I |= c} |= r for all r \u2208 R. If the lower bound of a constraint c \u2208 C is missing, we assume l(c) = 0. If the upper bound is missing, I |= c if l(c) \u2264 W (c, I). A program with cardinality constraints (PCC) can be seen as a special case of a PWC, where each literal has weight 1.\nStable model semantics. Given a PWC \u03a0 = (A, C,R) and an interpretation I \u2286 A. Following [16], the reduct cI of a constraint c \u2208 C w.r.t. I is obtained by removing all negative literals and the upper bound from c, and replacing the lower bound by\nl\u2032 = max(0, l(c)\u2212 \u2211\n(\u00aca,j)\u2208Cl(c) a 6\u2208I\nj).\nThe reduct \u03a0I of program \u03a0 w.r.t. I can be obtained by first removing each rule r \u2208 R which contains a constraint c \u2208 B(r) with W (c, I) > u(c). Afterwards, each remaining rule r is replaced by the set of rules1 (h, b), where h \u2208 I \u2229 Cl(H(r)) and b = {cI : c \u2208 B(r)}, i.e., the head of the new rules is an atom instead of a constraint. Interpretation I is called a stable model (or answer set) of \u03a0 if I is a model of \u03a0 and there exists no J \u2282 I such that J is a model of \u03a0I . The set of all answer sets of \u03a0 is denoted by AS(\u03a0). The consistency problem for PWCs is to decide whether AS(\u03a0) 6= \u2205.\nTree decompositions and treewidth. A tree decomposition of a graph G = (V,E) is a pair T = (T, \u03c7), where T is a tree and \u03c7 maps each node n of T (we use n \u2208 T as a shorthand below) to a bag \u03c7(n) \u2286 V such that\n(1) for each v \u2208 V , there is an n \u2208 T with v \u2208 \u03c7(n);\n(2) for each (v, w) \u2208 E, there is an n \u2208 T with v, w \u2208 \u03c7(n);\n(3) for each n1, n2, n3 \u2208 T such that n2 lies on the path from n1 to n3, \u03c7(n1) \u2229 \u03c7(n3) \u2286 \u03c7(n2) holds.\nA tree decomposition (T, \u03c7) is called normalized (or nice) [11], if T is a rooted tree and the following conditions hold: (1) each n \u2208 T has \u2264 2 children; (2) for each n \u2208 T with two children n1, n2, \u03c7(n) = \u03c7(n1) = \u03c7(n2); and (3) for each n \u2208 T with one child n\u2032, \u03c7(n) and \u03c7(n\u2032) differ in exactly one element.\nThe width of a tree decomposition is defined as the cardinality of its largest bag \u03c7(n) minus one. It is known that every tree decomposition can be normalized in linear time without increasing the width [11]. The treewidth of a graph G, denoted as tw(G), is the minimum width over all tree decompositions of G. For arbitrary but fixed w \u2265 1, it is feasible in linear time to decide whether a graph has treewidth \u2264 w and, if so, to compute a tree decomposition of width w, see [1].\n1With some abuse of notation, we sometimes write for an atom h, (h, b) as a shorthand for the rule (({(h, 1)}, 1, 1), b).\nTreewidth and constraint-width of PWCs. To build tree decompositions for programs, we use incidence graphs. For a PWC \u03a0 = (A, C,R), such a graph has vertex set A\u222aC \u222aR. There is an edge between a \u2208 A and c \u2208 C if a \u2208 Cl(c) or \u00aca \u2208 Cl(c), and there is an edge between c \u2208 C and r \u2208 R if c \u2208 {H(r)} \u222a B(r). The treewidth of \u03a0, denoted by tw(\u03a0), is the treewidth of its incidence graph. The constraint-width of \u03a0, denoted by cw(\u03a0), is the largest (lower or upper) bound occurring in the constraints of C (or 0 if there are no bounds).\nExample 1. Consider the following system configuration problem, where one has to choose among the given parts: p1 : 4000$, p2 : 2000$, and p3 : 1000$ such that the total cost is \u2264 5000$. Thereby one of {p1, p2} has to be selected and p3 requires p2.\nThis scenario can be represented by the PWC\n\u03a0Ex = ({p1, p2, p3}, {c1, c2, c3, c4}, {r1, r2, r3})\nwith\nc1 = ({(p1, 4), (p2, 2), (p3, 1)}, 0, 5) r1 = (c1, \u2205) c2 = ({(p1, 1), (p2, 1)}, 1, 2) r2 = (c2, \u2205) c3 = ({(p2, 1)}, 1, 1) r3 = (c3, {c4}) c4 = ({(p3, 1)}, 1, 1)\nThe incidence graph GEx of \u03a0Ex as well as a normalized tree decomposition TEx for \u03a0Ex of width 2 are depicted in Figure 1."}, {"heading": "3 NP-Completeness", "text": "Theorem 2. The consistency problem for PWCs is NP-complete already for programs having treewidth 1.\nProof. Clearly the problem is in NP. To show NP-hardness we reduce from the well-known NP-complete problem Partition. An instance of Partition is a collection of positive integers X = {x1, . . . , xn} (encoded in binary); the question is whether there exists a set I \u2286 {1, . . . , n} such that \u2211 i\u2208I xi = \u2211 i/\u2208I xi. Given an instance X = {x1, . . . , xn}, we construct a PWC \u03a0 =\n(A, C,R) as follows. Let S = \u2211n i=1 xi; we may assume that S is even since otherwise X is\na no-instance and can immediately be rejected. We put A = {a1, . . . , an}, C = {c} where c = ({(a1, x1), . . . , (an, xn)}, S/2, S/2), and R = {(c, \u2205)}.\nClaim 1: \u03a0 has treewidth 1. By construction the incidence graph of \u03a0 is a tree, hence of treewidth 1.\nClaim 2: X is a yes-instance of Partition if and only if \u03a0 has a model. This claim follows easily from the definitions.\nClaim 3: All models of \u03a0 are stable. Let M be a model of \u03a0. Since each atom appears positively in a constraint at the head of a rule, and since all the rules have an empty body, it follows that the reduct \u03a0M is the conjunction of all the elements of M . Hence M is stable since no proper subset of M can satisfy \u03a0M . We conclude that X is a yes-instance of Partition if and only if \u03a0 is consistent.\nIt is evident that \u03a0 can be constructed from X in polynomial time. Hence, by Claims 1\u20133 we have a polynomial-time reduction from Partition to the consistency problem of PWCs of treewidth 1, and the theorem follows.\nNote that Partition is \u201cweakly NP-hard\u201d since its NP-hardness depends on the binary encoding of the given integers. Accordingly, our reduction provides only weak NP-hardness for the consistency of PWCs of bounded treewidth. In fact, we shall prove in Section 6 that if we assume the weights to be given in unary the consistency problem is feasible in (non-uniform) polynomial time for PWCs of bounded treewidth."}, {"heading": "4 Linear-Time Tractability", "text": "Theorem 3. The consistency problem for PWCs can be solved in linear time for instances whose treewidth and constraint-width are bounded by constants.\nTo prove this result we shall take a logic approach and use Courcelle\u2019s Theorem [4], see also [6, 7]. To this aim we consider Monadic Second Order (MSO) logic on labeled graphs in terms of their incidence structure whose universe contains vertices and edges. We assume an infinite supply of individual variables x, x1, x2, . . . and set variables X,X1, X2, . . . The atomic formulas are E(x) (\u201cx is an edge\u201d), V (x) (\u201cx is a vertex\u201d), I(x, y) (\u201cvertex x is incident with edge y\u201d), x = y (equality), and X(y) (\u201celement y belongs to set X\u201d). Further we assume that a vertex or edge x can be labeled with an element a of some fixed finite set, denoted by the atomic formula Pa(x). MSO formulas are built up from atomic formulas using the usual Boolean connectives (\u00ac,\u2227,\u2228), quantification over individual variables (\u2200x, \u2203x), and quantification over set variables (\u2200X, \u2203X).\nWe writeG |= \u03d5 to indicate that an MSO formula \u03d5 is true for the labeled graphG. Courcelle\u2019s Theorem states thatG |= \u03d5 can be checked in linear time for labeled graphs if a tree decomposition of constant width is provided as an input. The latter is no restriction for proving Theorem 3, since by Bodlaender\u2019s Theorem [1], we can compute in linear time a tree decomposition of smallest width for graphs whose treewidth is bounded by a constant.\nLet k be a constant and consider a PWC \u03a0 = (A, C,R) of constraint-width k. We encode all the information of \u03a0 by adding edge and vertex labels to the incidence graph of \u03a0. We use the edge labels +,\u2212 to indicate polarity of literals and the labels h, b to distinguish between head and body of rules. That is, an edge {a, c} for a \u2208 A and c \u2208 C has label + if a \u2208 Cl(c), and label \u2212 if \u00aca \u2208 Cl(c); an edge {c, r} for c \u2208 C and r \u2208 R has label h if c = H(r) and label b if c \u2208 B(r). We use edge labels 1, . . . , k + 1 to encode weights of literals (literals of weight 0 can be omitted, weights exceeding k + 1 can be replaced by k + 1). That is, an edge {a, c} for a \u2208 A and c \u2208 C has label j if the constraint c contains the weight literal (a, j) or (\u00aca, j). We use vertex labels low[i] for i \u2208 {0 . . . , k} and up[j] for j \u2208 {0 . . . , k,\u221e} to encode the bounds of constraints (we use low[0] and up[\u221e] in case the lower or upper bound is missing, respectively).\nFinally we use vertex labels A, C,R to indicate whether a vertex represents an atom, a clause or a rule, respectively.\nLet G denote the incidence graph of the PWC \u03a0 with added labels as described above. In the following we will explain how to construct an MSO formula \u03d5 such that G |= \u03d5 if and only if \u03a0 has a stable model. For convenience we will slightly abuse notation and use meta-language terms as shorthands for their obvious definitions in the MSO language; for example we will write X \u2286 Y instead of \u2200x(X(x)\u2192 Y (x)), and a \u2208 A instead of V (a) \u2227 PA(a).\nLet X and Y be set variables and c an individual variable. For each integer s \u2208 {0, . . . , k+ 1} we define an MSO formula Sums(X,Y, c) that is true for G if and only if X and Y are interpreted as sets of atoms, c is interpreted as a constraint, and we have\ns = \u2211\n(a,j)\u2208Cl(c) a\u2208X\nj + \u2211\n(\u00aca,j)\u2208Cl(c) a/\u2208Y\nj.\nWe use the fact that it is always sufficient to choose at most k + 1 literals from c (say r positive and r\u2032 negative literals) to witness that the above equality holds.\nSums(X,Y, c) \u2261 X,Y \u2286 A \u2227 c \u2208 C (1) \u2227 \u2228\n1\u2264r+r\u2032\u2264k, 1\u2264n1,...,nr+r\u2032\u2264k+1, s=n1+\u00b7\u00b7\u00b7+nr+r\u2032 \u2203e1, . . . , er+r\u2032 (2)[\u2227r+r\u2032\ni=1 (Pni(ei) \u2227 I(c, ei) \u2227 \u2203a \u2208 A, I(a, ei)) (3) \u2227 \u2227\n1\u2264i<i\u2032\u2264r+r\u2032 ei 6= ei\u2032 (4) \u2227\u2200e \u2208 E (\u00acI(c, e) \u2228 \u2200a \u2208 A,\u00acI(a, e) \u2228 \u2228r+r\u2032 i=1 e = ei) (5)\n\u2227 \u2227r i=1(P+(ei) \u2227 \u2203a \u2208 X, I(a, ei)) (6)\n\u2227 \u2227r\u2032 i=r+1(P\u2212(ei) \u2227 \u00ac\u2203a \u2208 Y, I(a, ei)) ] (7)\nSome further explanation: Each of the r + r\u2032 literals is represented by an edge ei of weight ni. The disjunction in line (2) runs over all possible combinations of weights n1, . . . , nr+r\u2032 that give the sum s. Line (3) makes sure that each edge ei has weight ni and runs between constraint c and some atom. Lines (4) and (5) make sure that the edges are mutually different and that no other edge runs between constraint c and an atom. Lines (6) and (7) make sure that e1, . . . , er represent positive literals over atoms that belong to X, and er+1, . . . , er+r\u2032 represent negative literals over atoms that do not belong to Y .\nThe following formula is true if and only if X satisfies c.\nSat(X, c) \u2261 SatL(X,X, c) \u2227 SatU(X,X, c), where SatL(X,Y, c) \u2261 Plow[0] \u2228 \u2228\ni\u2208{1,...,k}\n(Plow[i](c) \u2227 \u2228\ni\u2264s\u2264k+1\nSums(X,Y, c)), and\nSatU(X,Y, c) \u2261 Pup[\u221e] \u2228 \u2228\nj\u2208{0,...,k}\n(Pup[j](c) \u2227 \u2228\n0\u2264s\u2264j\nSums(X,Y, c)).\nThe next formula is true if and only if Y is a model of \u03a0. Mod(Y ) \u2261 \u2200r \u2208 R \u2203c \u2208 C [ (H(c, r) \u2227 Sat(Y, c)) \u2228 (B(c, r) \u2227 \u00acSat(Y, c)) ] , where\nH(c, r) \u2261 \u2203e \u2208 E (I(c, e) \u2227 I(r, e) \u2227 Ph(e)), and B(c, r) \u2261 \u2203e \u2208 E (I(c, e) \u2227 I(r, e) \u2227 Pb(e)).\nFinally, the formula SMod(Y ) is true if and only if Y is a stable model of \u03a0. We make use of the\nformula Red(X,Y ) that states that X satisfies the reduct \u03a0Y .\nSMod(Y ) \u2261 Mod(Y ) \u2227 \u2200X \u2286 Y (X = Y \u2228 \u00acRed(X,Y )), where Red(X,Y ) \u2261 \u2200r \u2208 R \u2200a \u2208 A [a \u2208 X \u2228 a /\u2208 Y \u2228 \u00acInH(a, r)\n\u2228 \u2203c (B(c, r) \u2227 (\u00acSatU(Y, Y, c) \u2228 \u00acSatL(X,Y, c)))], and InH(a, r) \u2261 \u2203c \u2208 C \u2203e, e\u2032 \u2208 E [I(a, e) \u2227 I(c, e) \u2227 P+(e)\n\u2227 I(r, e\u2032) \u2227 I(c, e\u2032) \u2227 Ph(e\u2032)],\nthat is, a is an atom that occurs as a positive literal in the constraint at the head of rule r. We summarize the correctness of the construction in the following lemma.\nLemma 4. Let \u03d5 = \u2203Y SMod(Y ). Then \u03a0 has a stable model if and only if G |= \u03d5.\nSince the labeled graph G can be constructed in linear time, Theorem 3 now follows directly by Courcelle\u2019s Theorem."}, {"heading": "5 Dynamic Programming Approach", "text": "Recently, [9] presented a dynamic programming algorithm for answer-set programming that works for programs without cardinality or weight constraints, but possibly with disjunction in the head of the rules. One way to obtain a dynamic programming algorithm for PCCs is to try to extend that algorithm of Jakl et al. by methods to handle the cardinality constraints. In principle, this should be feasible. However, computationally, this approach has a serious drawback, namely: the aforementioned algorithm is tractable for bounded treewidth, but it is double exponential w.r.t. the treewidth (basically this is due to the handling of disjunctions). Our goal here is to present an algorithm that is only single exponential w.r.t. the treewidth. In order to achieve this goal, we have to manipulate a slightly more complicated data structure along the bottom-up traversal of the tree decomposition. In particular, we have to deal with orderings on the atoms in a model.\nTo this end, we need an alternative characterization of stable models. Slightly rephrasing a result by [13] we can characterize answer sets of PCCs as follows:\nProposition 5. Given a PCC \u03a0 = (A, C,R), M \u2286 A is an answer set (stable model) of \u03a0 if and only if the following conditions are jointly satisfied:\n\u2022 M is a model of \u03a0, i.e., M |= \u03a0,\n\u2022 there exists a strict linear order < over M , such that for each atom a \u2208 M , there exists a rule r \u2208 R with (R1) a \u2208 Cl(H(r)), (R2) M |= B(r), (R3) for each c \u2208 B(r), l(c) \u2264 |{b \u2208 Cl(c) : b < a} \u222a {\u00acb \u2208 Cl(c) : b \u2208 A \\M}|.\nSince the handling of linear orders is crucial for utilizing the above characterization, we will fix some notation first. We denote by [x1, x2, . . . , xn] a (strict) linear order x1 < x2 < . . . < xn on a set X = {x1, . . . , xn}. Moreover, [[X]] denotes the set of all possible linear orders over X. Two linear orders [x1, . . . , xn] and [y1, . . . , ym] are called inconsistent, if there are xi, xj , yk, yl such that xi < xj , yk < yl, xi = yl and xj = yk. Otherwise, we call them consistent. Given two consistent linear orders [x1, . . . , xn] \u2208 [[X]] and [y1, . . . , ym] \u2208 [[Y ]], we denote by [x1, . . . , xn]+ [y1, . . . , ym] = S the set of their possible combinations. S contains those linear orders [z1, . . . , zp] \u2208 [[X \u222a Y ]] such that for every pair xi < xj (respectively yi < yj), there exists zk < zl with zk = xi and zl = xj (respectively zk = yi and zl = yj). Note that in general, there exists more than one possible combination. Furthermore, we denote by [x1, . . . , xi\u22121, xi, xi+1, . . . , xn]\u2212 [xi] the linear order [x1, . . . , xi\u22121, xi+1, . . . , xn].\nThroughout the whole section, let T = (T, \u03c7) be a normalized tree decomposition of a PCC \u03a0 = (A, C,R). We present a dynamic programming algorithm, traversing T in bottom-up direction in order to compute whether \u03a0 admits an answer set. Ultimately, we will state properties about subtrees of T and inductively add more and more nodes, until we get a statement about the whole tree. To this end, the following notions become handy. Given a node n \u2208 T , we denote by Tn the subtree of T rooted at n. For a set S \u2286 A \u222a C \u222a R, n|S is a shorthand for \u03c7(n) \u2229 S. Moreover, n\u2193S := \u22c3 m\u2208Tn m|S and n\u21d3S := n\u2193S \\ n|S . Since the scope of a solution will always be limited to a subtree of the whole tree decomposition, the notion of a model has to be refined with respect to a universe U = n\u2193A. To this end, the cardinality of a constraint c \u2208 C with respect to an interpretation I \u2286 U is given by\n\u0393(c, I, U) = |{b \u2208 Cl(c) : b \u2208 I}|+ |{\u00acb \u2208 Cl(c) : b \u2208 U \\ I}| .\nThen I is a model of c under universe U (denoted by I |=U c) if l(c) \u2264 \u0393(c, I, U) \u2264 u(c). Note that |=U and |= coincide for U = A. Similarly, for a subset of constraints C\u2032 \u2286 C, set C \u2286 C\u2032 is a model of a rule r \u2208 R under restriction C\u2032, denoted by C |=C\u2032 r, if H(r) \u2208 C or B(r) \u2229 C\u2032 6\u2286 C.\nIn order to facilitate the discussion below, we define the following sum for constraint c \u2208 C, interpretation I \u2286 U over a set of atoms U \u2286 A and linear order L< containing at least I \u222a {c}:\n\u0393<(c, I, U, L<) = |{b \u2208 Cl(c) : b \u2208 I \u2227 b < c}|+ |{\u00acb \u2208 Cl(c) : b \u2208 U \\ I}| .\nThe following definition helps us to find partial answer sets, limited to the scope of a subtree of T .\nDefinition 6. A partial solution (for node n \u2208 T ) is a tuple \u03d1\u0302 = (n, M\u0302, C\u0302, R\u0302, L\u0302<, \u03b3\u0302, \u03b3\u0302<, \u2206\u0302), with interpretation M\u0302 \u2286 n\u2193A, satisfied constraints C\u0302 \u2286 n\u2193C, satisfied rules R\u0302 \u2286 n\u2193R, linear order L\u0302< \u2208 [[M\u0302 \u222a C\u0302 \u222a n\u2193R]], cardinality functions \u03b3\u0302 : n\u2193C \u2192 N and \u03b3\u0302< : C\u0302 \u2192 N, and derivation witness \u2206\u0302 = (\u03b4\u0302R, \u03b4\u0302M , \u03b4\u0302h, \u03b4\u0302b, \u03c3\u0302) with derivation rules \u03b4\u0302R \u2286 n\u2193R, derived atoms \u03b4\u0302M \u2286 M\u0302 , derivation head constraints \u03b4\u0302h \u2286 C\u0302, derivation body constraints \u03b4\u0302b \u2286 C\u0302, and check function \u03c3\u0302 : \u03b4\u0302h \u2192 {0, 1} such that the following conditions are jointly satisfied:\n1. C\u0302 \u2229 n\u21d3C = {c \u2208 n\u21d3C : M\u0302 |=n\u2193A c}\n2. R\u0302 = {r \u2208 n\u2193R : C\u0302 |=n\u2193C r} and n\u21d3R \u2286 R\u0302\n3. \u03b3\u0302(c) = \u0393(c, M\u0302 , n\u2193A) for all c \u2208 n\u2193C\n4. \u03b3\u0302<(c) = \u0393<(c, M\u0302 , n\u2193A, L\u0302<) for all c \u2208 C\u0302\n5. \u03b4\u0302M = {a \u2208 M\u0302 : c \u2208 \u03b4\u0302h, a \u2208 Cl(c), a > c} and M\u0302 \u2229 n\u21d3A \u2286 \u03b4\u0302M 6. \u03b4\u0302b = \u22c3 r\u2208\u03b4\u0302R B(r) and \u03b4\u0302b \u2286 C\u0302\n7. c \u2208 B(r)\u21d2 r > c for all c \u2208 \u03b4\u0302b and r \u2208 \u03b4\u0302R\n8. l(c) \u2264 \u03b3\u0302<(c) for all c \u2208 \u03b4\u0302b \u2229 n\u21d3C\n9. \u03c3\u0302(c) = 1\u21d4 \u2203r \u2208 \u03b4\u0302R with H(r) = c and c > r\n10. \u03c3\u0302(c) = 1 for all c \u2208 \u03b4\u0302h \u2229 n\u21d3C\nThe idea of this data structure is that, for some atom, clause, or rule that is no longer \u201cvisible\u201d in the current bag but was included in the subtree, the containment in one of the sets of \u03d1\u0302 is strictly what one would expect from an answer set, while for elements that are still visible this containment does not have to fulfill that many conditions and can be seen as some sort of \u201cguess\u201d.\nFor example, C\u0302 \u2229 n\u21d3C , the set of constraints in C\u0302 that are no longer visible, indeed contains exactly the constraints that are satisfied under interpretation M\u0302 , i.e., {c \u2208 n\u21d3C : M\u0302 |=n\u2193A c}, while C\u0302 \u2229 n|C represents the guess of those constraints, we still want to become true when we further traverse the tree towards the root node. M\u0302, C\u0302, R\u0302, and \u03b3\u0302 are used to ensure that the answer set is a model of our program. L\u0302< is the strict linear order, whose existence is demanded in the definition of answer sets. \u03b3\u0302< will be used to check condition (R3) of stable models, i.e., it will contain the cardinality on the left side of the equation in (R3). The derivation of atoms a \u2208 M\u0302 is represented by \u2206\u0302. The definition of answer sets requires for each a \u2208 M\u0302 the existence of some rule r \u2208 R satisfying (R1)-(R3). The set of those rules will be represented by \u03b4\u0302R. Sets \u03b4\u0302h and \u03b4\u0302b contain the head, and respectively, body constraints of the rules in \u03b4\u0302R. The set \u03b4\u0302M contains those atoms, for which we already found a head constraint to derive it. \u03c3\u0302 is a utility function, which ensures that each (guessed) constraint in \u03b4\u0302h is indeed the head of some rule in \u03b4\u0302R. Thereby \u03c3\u0302(c) = 1 marks that such a rule was found. Note that, w.l.o.g., we may assume that the root node of a normalized tree decomposition has an empty bag. Indeed, this can always be achieved by introducing at most tw(\u03a0) + 1 additional nodes above the root of a given tree decomposition. Then the following proposition shows the correspondence between answer sets and partial solutions for the root node of a given normalized tree decomposition.\nProposition 7. Let nroot be the root node of T and let \u03c7(nroot) = \u2205. Then AS(\u03a0) 6= \u2205 if and only if there exists a partial solution \u03d1\u0302 = (nroot, M\u0302 , C\u0302, R\u0302, L\u0302<, \u03b3\u0302, \u03b3\u0302<, \u2206\u0302) for nroot.\nProof. (\u21d2) Given an answer set M \u2208 AS(\u03a0), we construct a partial solution \u03d1\u0302 for nroot with derivation witness \u2206\u0302 = (\u03b4\u0302R, \u03b4\u0302M , \u03b4\u0302h, \u03b4\u0302b, \u03c3\u0302) as follows. Let M\u0302 := M , let C\u0302 := {c \u2208 C : M |= c} and let R\u0302 := R. Let L< := [a1, . . . , a|M |] \u2208 [[M ]] be the linear order from Proposition 5 and let f : M \u2192 R be the function that assigns each atom a \u2208M the rule r \u2208 R that satisfies conditions (R1)\u2013(R3) of Proposition 5 for a. Furthermore, let \u03b4\u0302R := {f(a) : a \u2208M}. In order to create L\u0302<, we modify L< as follows. For every r \u2208 \u03b4\u0302R let ar be the smallest atom in L< such that f(ar) = r. Atom ar is then replaced in L< by the sequence c1, . . . , cj , r, cj+1, ar, where {c1, . . . , cj} = B(r) and cj+1 = H(r). Note that by construction {c1, . . . , cj+1} \u2286 C\u0302. The remaining clauses from C\u0302 as well as the rulesR\\R are arbitrarily appended at the end of L\u0302<. For every constraint c \u2208 C we set \u03b3\u0302(c) := \u0393(c,M,A). For every constraint c \u2208 C\u0302 we set \u03b3\u0302<(c) := \u0393<(c,M,A, L\u0302<). Let \u03b4\u0302M := M , let \u03b4\u0302h := {H(r) : r \u2208 \u03b4\u0302R}, and let \u03b4\u0302b := \u22c3 r\u2208\u03b4\u0302R B(r). Finally, let \u03c3\u0302(c) := 1 for all c \u2208 \u03b4\u0302h. We show now that \u03d1\u0302 is indeed a partial solution by checking conditions 1\u201310 of Definition 6. Conditions 1\u20134, 6\u20137, and 9\u201310 are satisfied by construction. For each a \u2208 M let ca := H(f(a)). Then ca \u2208 \u03b4\u0302h, a \u2208 Cl(ca), and ca < a. Therefore, \u03b4\u0302M = {a \u2208 M\u0302 : c \u2208 \u03b4\u0302h, a \u2208 Cl(c), a > c} which satisfies condition 5. Condition 8 is satisfied because of (R3) of Proposition 5. Hence \u03d1\u0302 is a partial solution for nroot.\n(\u21d0) For the other direction, the requirement that \u03c7(nroot) = \u2205 ensures, that the guessing part of a given partial solution \u03d1\u0302 is nonexistent. Therefore, C\u0302 = {c \u2208 C : M\u0302 |= c} and R\u0302 = {r \u2208 R : C\u0302 |= r} = R. This ensures that M\u0302 |= \u03a0 and is therefore a model of \u03a0. Let the linear order L< be the restriction of L\u0302< to the set M\u0302 . Let a \u2208 M\u0302 be an arbitrary atom. By condition 5 of Proposition 5 there exists a constraint c \u2208 \u03b4\u0302h with a \u2208 Cl(c) and a > c. Therefore, by condition 9 and 10 there exists a rule r \u2208 \u03b4\u0302R with H(r) = c and c > r. We now show that rule r is the one fulfilling (R1)\u2013(R3) of Proposition 5 for atom a. (R1) is satisfied by construction. By condition 6, B(r) \u2286 C\u0302. Therefore, M\u0302 |= B(r), satisfying (R2). Finally, (R3) is satisfied through condition 8. This shows that M\u0302 is indeed an answer set of \u03a0.\nAn algorithm that computes all partial solutions at each node of the tree decomposition is highly inefficient, since the size and the number of such solutions can grow exponentially in the input size. Therefore we introduce bag assignments, which is a data structure similar to partial\nsolutions, but instead of ranging over the whole subtree, their scope is restricted to a single bag of the tree decomposition. But we are not interested in arbitrary bag assignments. Instead we consider only those, which can be seen as the projection of a partial solution for node n to the bag of node n. Formally this is stated as follows:\nDefinition 8. A bag assignment (for node n \u2208 T ) is a tuple \u03d1 = (n,M,C,R,L<, \u03b3, \u03b3<,\u2206), with partial model M \u2286 n|A, satisfied constraints C \u2286 n|C, satisfied rules R \u2286 n|R, linear order L< \u2208 [[M \u222a C \u222a n|R]], cardinality functions \u03b3 : n|C \u2192 N and \u03b3< : C \u2192 N, and derivation witness \u2206 = (\u03b4R, \u03b4M , \u03b4h, \u03b4b, \u03c3) with derivation rules \u03b4R \u2286 n|R, derived atoms \u03b4M \u2286 M , derivation head constraints \u03b4h \u2286 C, derivation body constraints \u03b4b \u2286 C, and check function \u03c3 : \u03b4h \u2192 {0, 1}.\nDefinition 9. A bag assignment \u03d1 for node n with \u03d1 = (n,M,C,R,L<, \u03b3, \u03b3<,\u2206) and \u2206 = (\u03b4R, \u03b4M , \u03b4h, \u03b4b, \u03c3) is called a bag model (for node n) if there exists a partial solution \u03d1\u0302 = (n, M\u0302, C\u0302, R\u0302, L\u0302<, \u03b3\u0302, \u03b3\u0302<, \u2206\u0302), with \u2206\u0302 = (\u03b4\u0302R, \u03b4\u0302M , \u03b4\u0302h, \u03b4\u0302b, \u03c3\u0302) such that\n\u2022 M\u0302 \u2229 \u03c7(n) = M , C\u0302 \u2229 \u03c7(n) = C, R\u0302 \u2229 \u03c7(n) = R,\n\u2022 L\u0302< and L< are consistent,\n\u2022 \u03b3\u0302(c) = \u03b3(c), \u03b3\u0302<(c) = \u03b3<(c) for all c \u2208 n|C,\n\u2022 \u03b4\u0302R \u2229 \u03c7(n) = \u03b4R, \u03b4\u0302M \u2229 \u03c7(n) = \u03b4M ,\n\u2022 \u03b4\u0302h \u2229 \u03c7(n) = \u03b4h, \u03b4\u0302b \u2229 \u03c7(n) = \u03b4b,\n\u2022 \u03c3\u0302(c) = \u03c3(c) for all c \u2208 \u03b4h.\nIndeed, it turns out that it is sufficient to maintain only bag models during the tree traversal.\nProposition 10. Let nroot be the root node of T , and let \u03c7(nroot) = \u2205. Then AS(\u03a0) 6= \u2205 if and only if \u03d1 = (nroot, \u2205, \u2205, \u2205, [], \u2205, \u2205,\u2206) with \u2206 = (\u2205, \u2205, \u2205, \u2205, \u2205) is a bag model for nroot.\nProof. Since \u03c7(nroot) = \u2205, every partial solution for nroot is an extension of \u03d1 according to the conditions of Definition 9. Therefore, this statement follows from Proposition 7.\nBy the same argument as for the root node, we may assume that \u03c7(n) = \u2205 for leaf nodes n. Now a dynamic programming algorithm can be achieved, by creating the only possible bag model \u03d1 = (n, \u2205, \u2205, \u2205, [], \u2205, \u2205,\u2206) with \u2206 = (\u2205, \u2205, \u2205, \u2205, \u2205) for each leaf n, and then propagating these bag models along the paths to the root node. Thereby the bag models are altered according to rules, which depend only on the bag of the current node. In order to sketch the cornerstones of the dynamic programming algorithm more clearly, we distinguish between eight types of nodes in the tree decomposition: leaf (L), branch (B), atom introduction (AI), atom removal (AR), rule introduction (RI), rule removal (RR), constraint introduction (CI), and constraint removal (CR) node. The last six types will be often augmented with the element e (either an atom, a rule, or a constraint) which is removed or added compared to the bag of the child node.\nNext we define a relation \u227aT between bag assignments, which will be used to propagate bag models in a bottom-up direction along the tree decomposition T . Afterwards we demonstrate the intuition of these rules with the help of a small example.\nDefinition 11. Let \u03d1 = (n,M,C,R,L<, \u03b3, \u03b3<,\u2206) and \u03d1 \u2032 = (n\u2032,M \u2032, C \u2032, R\u2032, L\u2032<, \u03b3 \u2032, \u03b3\u2032<,\u2206 \u2032) with \u2206 = (\u03b4R, \u03b4M , \u03b4h, \u03b4b, \u03c3) and \u2206 \u2032 = (\u03b4\u2032R, \u03b4 \u2032 M , \u03b4 \u2032 h, \u03b4 \u2032 b, \u03c3 \u2032) be bag assignments for nodes n, n\u2032 \u2208 T . We relate \u03d1\u2032 \u227aT \u03d1 if n has a single child n\u2032 and the following properties are satisfied, depending on the node type of n:\n(r-RR): r \u2208 R\u2032 and\n\u03d1 = (n,M \u2032, C \u2032, R\u2032 \\ {r}, L\u2032< \u2212 [r], \u03b3\u2032, \u03b3\u2032<,\u2206), with \u2206 = (\u03b4\u2032R \\ {r}, \u03b4\u2032M , \u03b4\u2032h, \u03b4\u2032b, \u03c3\u2032).\n(r-RI): \u03d1 \u2208 {(n,M \u2032, C \u2032, R\u2217, L\u2217<, \u03b3\u2032, \u03b3\u2032<,\u2206) : L\u2217< \u2208 (L\u2032< + [r])}, with\nR\u2217 = { R\u2032 \u222a {r} if C \u2032 |=n|C r R\u2032 otherwise\nand one of the following two groups of properties has to be satisfied:\n\u2022 \u201cr is used\u201d: H(r) \u2208 n|C \u21d2 (H(r) \u2208 \u03b4\u2032h\u2227H(r) > r), for all b \u2208 B(r)\u2229n|C : b \u2208 C \u2032\u2227b < r, and\n\u2206 = (\u03b4\u2032R \u222a {r}, \u03b4\u2032M , \u03b4\u2032h, \u03b4\u2032b \u222a (B(r) \u2229 n|C), \u03c3\u2217), with\n\u03c3\u2217(c) =\n{ 1 if c = H(r)\n\u03c3\u2032(c) otherwise.\n\u2022 \u201cr is not used\u201d: \u2206 = \u2206\u2032.\n(a-AR): a \u2208M \u2032 \u21d2 a \u2208 \u03b4\u2032M and\n\u03d1 = (n,M \u2032 \\ {a}, C \u2032, R\u2032, L\u2032< \u2212 [a], \u03b3\u2032, \u03b3\u2032<,\u2206), with \u2206 = (\u03b4\u2032R, \u03b4 \u2032 M \\ {a}, \u03b4\u2032h, \u03b4\u2032b, \u03c3\u2032).\n(a-AI): One of the following two groups of properties has to be satisfied:\n\u2022 \u201cset a to false\u201d: \u03d1 = (n,M \u2032, C \u2032, R\u2032, L\u2032<, \u03b3 \u2217, \u03b3\u2217<,\u2206 \u2032), with\n\u03b3\u2217(c) = \u03b3\u2032(c) + \u0393(c,M \u2032, n|A)\u2212 \u0393(c,M \u2032, n\u2032|A), and \u03b3\u2217<(c) = \u03b3 \u2032 <(c) + \u0393<(c,M\n\u2032, n|A, L\u2032<)\u2212 \u0393<(c,M \u2032, n\u2032|A, L\u2032<). \u2022 \u201cset a to true\u201d:\n\u03d1 \u2208 {(n,M\u2217 = M \u2032 \u222a {a}, C \u2032, R\u2032, L\u2217<, \u03b3\u2217, \u03b3\u2217<,\u2206) : L\u2217< \u2208 (L\u2032< + [a])}, with\n\u2206 = (\u03b4\u2032R, \u03b4 \u2032 M \u222a \u03b4\u2217M , \u03b4\u2032h, \u03b4\u2032b, \u03c3\u2032), where\n\u03b4\u2217M = { {a} if \u2203c \u2208 \u03b4\u2032h, a \u2208 Cl(c), a > c \u2205 otherwise,\n\u03b3\u2217(c) = \u03b3\u2032(c) + \u0393(c,M\u2217, n|A)\u2212 \u0393(c,M \u2032, n\u2032|A), and \u03b3\u2217<(c) = \u03b3 \u2032 <(c) + \u0393<(c,M \u2217, n|A, L\u2217<)\u2212 \u0393<(c,M \u2032, n\u2032|A, L\u2032<).\n(c-CR): c \u2208 C \u2032 \u21d4 l(c) \u2264 \u03b3\u2032(c) \u2264 u(c), c \u2208 \u03b4\u2032h \u21d2 \u03c3\u2032(c) = 1, c \u2208 \u03b4\u2032b \u21d2 \u03b3\u2032<(c) \u2265 l(c), and\n\u03d1 = (n,M \u2032, C \u2032 \\ {c}, R\u2032, L\u2032< \u2212 [c], \u03b3\u2032, \u03b3\u2032<,\u2206), with \u2206 = (\u03b4\u2032R, \u03b4 \u2032 M , \u03b4 \u2032 h \\ {c}, \u03b4\u2032b \\ {c}, \u03c3\u2032).\n(c-CI): One of the following two groups of properties has to be satisfied:\n\u2022 \u201cset c to false\u201d: c 6\u2208 B(r) \u2227 c 6= H(r) for all r \u2208 \u03b4\u2032R, and\n\u03d1 = (n,M \u2032, C \u2032, R\u2032 \u222aR\u2217, L\u2032<, \u03b3\u2032 \u222a \u03b3\u2217, \u03b3\u2032<,\u2206\u2032), with\nR\u2217 = {r \u2208 n|R : C \u2032 |=n|C r}, and \u03b3\u2217 = {(c,\u0393(c,M \u2032, n|A)}.\n\u2022 \u201cset c to true\u201d: (c \u2208 B(r)\u21d2 r > c) \u2227 (c = H(r)\u21d2 r < c) for all r \u2208 \u03b4\u2032R, and\n\u03d1 \u2208 {(n,M \u2032, C\u2217 = C \u2032 \u222a {c}, R\u2032 \u222aR\u2217, L\u2217<, \u03b3\u2217, \u03b3\u2217<,\u2206) : L\u2217< \u2208 (L\u2032< + [c])}, with\n\u2206 = (\u03b4\u2032R, \u03b4 \u2032 M \u222a \u03b4\u2217M , \u03b4\u2032h \u222a \u03b4\u2217h, \u03b4\u2032b \u222a \u03b4\u2217b , \u03c3\u2217), where\nR\u2217 = {r \u2208 n|R : C\u2217 |=n|C r}, \u03b3\u2217 = \u03b3\u2032 \u222a {(c,\u0393(c,M \u2032, n|A)}, \u03b3\u2217< = \u03b3 \u2032 < \u222a {(c,\u0393<(c,M \u2032, n|A, L\u2217<)},\n\u03b4\u2217b = { {c} if \u2203r \u2208 \u03b4\u2032R : c \u2208 B(r) \u2205 otherwise,\n\u03b4\u2217h \u2208 { {{c}} if \u2203r \u2208 \u03b4\u2032R : c = H(r) {\u2205, {c}} otherwise,\n\u03b4\u2217M = {a \u2208M \u2032 : a \u2208 Cl(c), c \u2208 \u03b4\u2217h, a > c}, and \u03c3\u2217(c) = 1\u21d4 c \u2208 \u03b4\u2217h \u2227 \u2203r \u2208 \u03b4R : H(r) = c.\nFor branch nodes, we extend (with slight abuse of notation) \u227aT to a ternary relation.\nDefinition 12. Let \u03d1 = (n,M,C,R,L<, \u03b3, \u03b3<,\u2206), \u03d1 \u2032 = (n\u2032,M \u2032, C \u2032, R\u2032, L\u2032<, \u03b3 \u2032, \u03b3\u2032<,\u2206 \u2032), and \u03d1\u2032\u2032 = (n\u2032\u2032,M \u2032\u2032, C \u2032\u2032, R\u2032\u2032, L\u2032\u2032<, \u03b3 \u2032\u2032, \u03b3\u2032\u2032<,\u2206\n\u2032\u2032) be bag assignments for nodes n, n\u2032, n\u2032\u2032 \u2208 T with \u2206 = (\u03b4R, \u03b4M , \u03b4h, \u03b4b, \u03c3), \u2206 \u2032 = (\u03b4\u2032R, \u03b4 \u2032 M , \u03b4 \u2032 h, \u03b4 \u2032 b, \u03c3 \u2032), and \u2206\u2032\u2032 = (\u03b4\u2032\u2032R, \u03b4 \u2032\u2032 M , \u03b4 \u2032\u2032 h, \u03b4 \u2032\u2032 b , \u03c3\n\u2032\u2032). We relate (\u03d1\u2032, \u03d1\u2032\u2032) \u227aT \u03d1 if n has two children n\u2032 and n\u2032\u2032 and the following conditions are fulfilled.\n\u2022 M = M \u2032 = M \u2032\u2032 C = C \u2032 = C \u2032\u2032\n\u2022 R = R\u2032 \u222aR\u2032\u2032 L< = L\u2032< = L\u2032\u2032<\n\u2022 \u03b3(c) = \u03b3\u2032(c) + \u03b3\u2032\u2032(c)\u2212 \u0393(c,M, n|A) for all c \u2208 n|C\n\u2022 \u03b3<(c) = \u03b3\u2032<(c) + \u03b3\u2032\u2032<(c)\u2212 \u0393<(c,M, n|A, L<) for all c \u2208 C\n\u2022 \u03b4R = \u03b4\u2032R = \u03b4\u2032\u2032R \u03b4M = \u03b4\u2032M \u222a \u03b4\u2032\u2032M\n\u2022 \u03b4h = \u03b4\u2032h = \u03b4\u2032\u2032h \u03b4b = \u03b4\u2032b \u222a \u03b4\u2032\u2032b\n\u2022 \u03c3(c) = max{\u03c3\u2032(c), \u03c3\u2032\u2032(c)} for all c \u2208 \u03b4h\nWhat follows is a small example which demonstrates how this \u227aT relation is used to solve the consistency problem for PCCs. Thereby we start with the only possible bag model \u03d1 = (n, \u2205, \u2205, \u2205, [], \u2205, \u2205,\u2206) and \u2206 = (\u2205, \u2205, \u2205, \u2205, \u2205) for each leaf node. Now we traverse through the tree decomposition and calculate for each node all the bag assignments according to the relation \u227aT . Finally, we check whether for the root node any such bag assignment could be generated.\nExample 13. We are given a PCC \u03a0 = ({p1, p2}, {c1, c2}, {r1}) with c1 = ({(p1, 1)}, 1, 1), c2 = ({(\u00acp2, 1)}, 1, 1), and r1 = (c1, {c2}).\nIts incidence graph as well as a normalized tree decomposition of width 1 are depicted in Figure 2. What follows is a list of all the bag assignments that can be computed according to the relation \u227aT , starting from the trivial bag assignments of the empty leaf nodes. Node n1: (L)\n\u03d11 = (n1, \u2205, \u2205, \u2205, [], \u2205, \u2205, (\u2205, \u2205, \u2205, \u2205, \u2205))\nNode n2: (p1-AI)\n\u03d12,1 = (n2, \u2205, \u2205, \u2205, [], \u2205, \u2205, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d12,2 = (n2, {p1}, \u2205, \u2205, [p1], \u2205, \u2205, (\u2205, \u2205, \u2205, \u2205, \u2205))\nNode n3: (c1-CI)\n\u03d13,1 = (n3, \u2205, \u2205, \u2205, [], {(c1, 0)}, \u2205, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d13,2 = (n3, \u2205, {c1}, \u2205, [c1], {(c1, 0)}, {(c1, 0)}, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d13,3 = (n3, \u2205, {c1}, \u2205, [c1], {(c1, 0)}, {(c1, 0)}, (\u2205, \u2205, {c1}, \u2205, {(c1, 0)})) \u03d13,4 = (n3, {p1}, \u2205, \u2205, [p1], {(c1, 1)}, \u2205, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d13,5 = (n3, {p1}, {c1}, \u2205, [c1, p1], {(c1, 1)}, {(c1, 0)}, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d13,6 = (n3, {p1}, {c1}, \u2205, [c1, p1], {(c1, 1)}, {(c1, 0)}, (\u2205, {p1}, {c1}, \u2205, {(c1, 0)})) \u03d13,7 = (n3, {p1}, {c1}, \u2205, [p1, c1], {(c1, 1)}, {(c1, 1)}, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d13,8 = (n3, {p1}, {c1}, \u2205, [p1, c1], {(c1, 1)}, {(c1, 1)}, (\u2205, \u2205, {c1}, \u2205, {(c1, 0)}))\nNode n4: (p1-AR)\n\u03d14,1 = (n4, \u2205, \u2205, \u2205, [], {(c1, 0)}, \u2205, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d14,2 = (n4, \u2205, {c1}, \u2205, [c1], {(c1, 0)}, {(c1, 0)}, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d14,3 = (n4, \u2205, {c1}, \u2205, [c1], {(c1, 0)}, {(c1, 0)}, (\u2205, \u2205, {c1}, \u2205, {(c1, 0)})) \u03d14,4 = (n4, \u2205, {c1}, \u2205, [c1], {(c1, 1)}, {(c1, 0)}, (\u2205, \u2205, {c1}, \u2205, {(c1, 0)}))\nNode n5: (r1-RI)\n\u03d15,1 = (n5, \u2205, \u2205, \u2205, [r1], {(c1, 0)}, \u2205, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d15,2 = (n5, \u2205, {c1}, {r1}, [r1, c1], {(c1, 0)}, {(c1, 0)}, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d15,3 = (n5, \u2205, {c1}, {r1}, [c1, r1], {(c1, 0)}, {(c1, 0)}, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d15,4 = (n5, \u2205, {c1}, {r1}, [r1, c1], {(c1, 0)}, {(c1, 0)}, ({r1}, \u2205, {c1}, \u2205, {(c1, 1)})) \u03d15,5 = (n5, \u2205, {c1}, {r1}, [r1, c1], {(c1, 0)}, {(c1, 0)}, (\u2205, \u2205, {c1}, \u2205, {(c1, 0)})) \u03d15,6 = (n5, \u2205, {c1}, {r1}, [c1, r1], {(c1, 0)}, {(c1, 0)}, (\u2205, \u2205, {c1}, \u2205, {(c1, 0)})) \u03d15,7 = (n5, \u2205, {c1}, {r1}, [r1, c1], {(c1, 1)}, {(c1, 0)}, ({r1}, \u2205, {c1}, \u2205, {(c1, 1)})) \u03d15,8 = (n5, \u2205, {c1}, {r1}, [r1, c1], {(c1, 1)}, {(c1, 0)}, (\u2205, \u2205, {c1}, \u2205, {(c1, 0)})) \u03d15,9 = (n5, \u2205, {c1}, {r1}, [c1, r1], {(c1, 1)}, {(c1, 0)}, (\u2205, \u2205, {c1}, \u2205, {(c1, 0)}))\nNode n6: (c1-CR)\n\u03d16,1 = (n6, \u2205, \u2205, \u2205, [r1], \u2205, \u2205, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d16,2 = (n6, \u2205, \u2205, {r1}, [r1], \u2205, \u2205, ({r1}, \u2205, \u2205, \u2205, \u2205))\nThe branch of nodes n7 till n12 is very similar to nodes n1 till n6. Therefore we just present the bag assignments for n12.\nNode n12: (c2-CR)\n\u03d112,1 = (n12, \u2205, \u2205, \u2205, [r1], \u2205, \u2205, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d112,2 = (n12, \u2205, \u2205, \u2205, [r1], \u2205, \u2205, ({r1}, \u2205, \u2205, \u2205, \u2205))\nNode n13: (B)\n\u03d113,1 = (n13, \u2205, \u2205, \u2205, [r1], \u2205, \u2205, (\u2205, \u2205, \u2205, \u2205, \u2205)) \u03d113,2 = (n13, \u2205, \u2205, {r1}, [r1], \u2205, \u2205, ({r1}, \u2205, \u2205, \u2205, \u2205))\nNode n14: (r1-RR)\n\u03d114 = (n14, \u2205, \u2205, \u2205, [], \u2205, \u2205, (\u2205, \u2205, \u2205, \u2205, \u2205))\nSince \u03d114 could be derived, the example is a yes-instance of the consistency problem. Indeed it has exactly one answer set {p1}. a\nLet us look exemplarily at (CR) nodes in more detail. Consider nodes n which remove a constraint c, i.e., \u03c7(n) = \u03c7(n\u2032) \\ {c}, where n\u2032 is the child of n (see, for instance, the node with bag {p3, c3} in the left branch of TEx in Figure 1, which is a c4-removal node). Let \u03d1\u2032 = (n\u2032,M \u2032, C \u2032, R\u2032, L\u2032<, \u03b3 \u2032, \u03b3\u2032<,\u2206 \u2032) with \u2206\u2032 = (\u03b4\u2032R, \u03b4 \u2032 M , \u03b4 \u2032 h, \u03b4 \u2032 b, \u03c3 \u2032) be a bag model for n\u2032. We then create a bag model for n as follows: First we have to check whether the conditions c \u2208 C \u2032 \u21d4 l(c) \u2264 \u03b3\u2032(c) \u2264 u(c), c \u2208 \u03b4\u2032h \u21d2 \u03c3\u2032(c) = 1, and c \u2208 \u03b4\u2032b \u21d2 \u03b3\u2032<(c) \u2265 l(c) are satisfied. Note that those checks correspond to the conditions 1, 10, and 8 of Definition 6. They ensure that all guesses with respect to c are correct. In the case of an affirmative answer, we remove c from all sets of \u03d1\u2032 in order to create the new bag model \u03d1 = (n,M \u2032, C \u2032 \\ {c}, R\u2032, L\u2032< \u2212 [c], \u03b3\u2032, \u03b3\u2032<,\u2206) with \u2206 = (\u03b4\u2032R, \u03b4 \u2032 M , \u03b4 \u2032 h \\ {c}, \u03b4\u2032b \\ {c}, \u03c3\u2032).\nThe following two theorems state that the rules defined above indeed help in finding bag models.\nTheorem 14 (Soundness). Given a bag model \u03d1\u2032 (respectively bag models \u03d1\u2032 and \u03d1\u2032\u2032). Then each bag assignment \u03d1 with \u03d1\u2032 \u227aT \u03d1 (respectively (\u03d1\u2032, \u03d1\u2032\u2032) \u227aT \u03d1) is a bag model.\nProof. Let \u03d1\u2032 be a bag model for n\u2032 \u2208 T and let \u03d1 be a bag assignment for node n \u2208 T with \u03d1\u2032 \u227aT \u03d1. Then n\u2032 is the single child of n, with n being of type (RR), (RI), (AR), (AI), (CR), or (CI). Assume n is a (r-RR) node. According to Definition 11, we have r \u2208 R\u2032 with \u03d1 and \u03d1\u2032 differing only in R = R\u2032 \\ {r}, L< = L\u2032< \u2212 [r], and \u03b4R = \u03b4\u2032R \\ {r}. Since \u03d1\u2032 is a bag model, there exists a partial solution \u03d1\u0302 of n\u2032, satisfying all the conditions of Definition 9.\nClaim: \u03d1\u0302 is also a partial solution of n. To verify this claim, we have to check the conditions of Definition 6. Since n\u2032\u21d3C = n\u21d3C , n\u2032\u2193C = n\u2193C , n\u2032\u21d3A = n\u21d3A, n\u2032\u2193A = n\u2193A, and n\u2032\u2193R = n\u2193R, the only non-trivial condition is number 2 where we have to check n\u21d3R \u2286 R\u0302. Since r \u2208 R\u2032 and R\u2032 = R\u0302 \u2229 n\u2032|R, we have r \u2208 R\u0302. Hence, from n\u2032\u21d3R \u2286 R\u0302 follows that n\u21d3R = n\u2032\u21d3R \u222a {r} \u2286 R\u0302.\nFurthermore, the projection of \u03d1\u0302 to the bag \u03c7(n) is exactly \u03d1, since \u03d1\u2032 and \u03d1 differ only by the fact, that r is removed from every set in \u03d1. Therefore \u03d1 is a bag model. Analogously the theorem can be checked for the other five node types above.\nNow let \u03d1\u2032 and \u03d1\u2032\u2032 be bag models for n\u2032, n\u2032\u2032 \u2208 T and let \u03d1 be a bag assignment for node n \u2208 T with (\u03d1\u2032, \u03d1\u2032\u2032) \u227aT \u03d1. Then n has two children n\u2032 and n\u2032\u2032 and all the properties of Definition 12 are satisfied. Since \u03d1\u2032 and \u03d1\u2032\u2032 are bag models, there exist partial solutions \u03d1\u0302\u2032 of n\u2032 and \u03d1\u0302\u2032\u2032 of n\u2032\u2032. Using these two partial solutions we construct \u03d1\u0302 = (n, M\u0302 \u2032 \u222a M\u0302 \u2032\u2032, C\u0302 \u2032 \u222a C\u0302 \u2032\u2032, R\u0302\u2032 \u222a R\u0302\u2032\u2032, L\u0302<, \u03b3\u0302, \u03b3\u0302<, \u2206\u0302) with \u2206\u0302 = (\u03b4\u0302\u2032R \u222a \u03b4\u0302\u2032\u2032R, \u03b4\u0302\u2032M \u222a \u03b4\u0302\u2032\u2032M , \u03b4\u0302\u2032h \u222a \u03b4\u0302\u2032\u2032h, \u03b4\u0302\u2032b \u222a \u03b4\u0302\u2032\u2032b , \u03c3\u0302). Thereby L\u0302< \u2208 (L\u0302\u2032< + L\u0302\u2032\u2032<),\n\u03b3\u0302(c) =  \u03b3\u0302\u2032(c) c \u2208 n\u2032\u21d3C , \u03b3\u0302\u2032\u2032(c) c \u2208 n\u2032\u2032\u21d3C , \u03b3\u0302\u2032(c) + \u03b3\u0302\u2032\u2032(c)\u2212 \u0393(c, n|M\u0302 , n|A) otherwise,\n\u03b3\u0302<(c) =  \u03b3\u0302\u2032<(c) c \u2208 n\u2032\u21d3C , \u03b3\u0302\u2032\u2032<(c) c \u2208 n\u2032\u2032\u21d3C , \u03b3\u0302\u2032<(c) + \u03b3\u0302 \u2032\u2032 <(c)\u2212 \u0393<(c, n|M\u0302 , n|A, L\u0302<) otherwise,\n\u03c3\u0302(c) =  \u03c3\u0302\u2032(c) c \u2208 \u03b4\u0302\u2032h \\ \u03b4\u0302\u2032\u2032h, \u03c3\u0302\u2032\u2032(c) c \u2208 \u03b4\u0302\u2032\u2032h \\ \u03b4\u0302\u2032h, max{\u03c3\u0302\u2032(c), \u03c3\u0302\u2032\u2032(c)} otherwise.\nOne can now check the conditions of Definition 6 in order to verify that \u03d1\u0302 is a partial solution for n. Furthermore, our construction ensures that the projection of \u03d1\u0302 to the bag \u03c7(n) is exactly \u03d1, which is therefore a bag model.\nTheorem 15 (Completeness). Given a bag model \u03d1 for node n \u2208 T . Then either n is a leaf node, or there exists a bag model \u03d1\u2032 (respectively two bag models \u03d1\u2032 and \u03d1\u2032\u2032) with \u03d1\u2032 \u227aT \u03d1 (respectively (\u03d1\u2032, \u03d1\u2032\u2032) \u227aT \u03d1).\nProof. Again, we have to distinguish between the node type of n. For instance, let n \u2208 T be an (r-RR) node with child n\u2032, let \u03d1 be a bag model for n. We have to show that there exists a bag model \u03d1\u2032 for n\u2032 with \u03d1\u2032 \u227aT \u03d1. Since \u03d1 is a bag model, there exists a partial solution \u03d1\u0302 of n, satisfying all the conditions of Definition 9. From r \u2208 n\u21d3R follows, that r \u2208 R\u0302. Now consider the projection of \u03d1\u0302 onto the bag of n\u2032. Then the result is a bag model \u03d1\u2032 of n\u2032 satisfying the conditions of Definition 9 and having r \u2208 R\u2032. But then it is easy to check, that \u03d1\u2032 \u227aT \u03d1, which closes the proof for (RR) nodes. Analogously the theorem can be checked for the other six node types.\nTheorem 14 and Theorem 15 show, that starting from the trivial bag models for empty leafs, the dynamic programming algorithm creates all bag models for the root node. According to Proposition 10, those bag models are all we need to know. Thus, this dynamic programming algorithm solves the consistency problem.\nTheorem 16. The consistency problem for PCCs \u03a0 can be solved in time O(26ww!k4w \u00b7 \u2016\u03a0\u2016) with w = tw(\u03a0) and k = cw(\u03a0).\nProof. We first show that the number of different bag models at each node n \u2208 T is bounded. The number of possible sets M,C,R is bounded by 2w, there are at most w! different orderings L<, the number of cardinality functions \u03b3, \u03b3< is bounded by k\n2w, the number of possible sets \u03b4R, \u03b4h as well as \u03b4M , \u03b4b is bounded by 2\nw each, and finally the number of check functions \u03c3 is bounded by 2w. This leads to at most 24ww!k2w many different bag models at node n. At each node the effort to compute a single bag model is constant with the exception of branch nodes, where one has to compare possible pairs of bag models of each child node. Thereby only pairs are combined which have identical M,C,R,L<, \u03b4R, \u03b4h. This means for each bag model of the first child node there are at most 22wk2w (the number of possible functions/sets \u03b3, \u03b3<, \u03b4M , \u03b4b, \u03c3) bag\nmodels at the second child to consider. The time per node is therefore bounded by 26ww!k4w and since the number of nodes in our tree decomposition is bounded by O(\u2016\u03a0\u2016), the total time of O(26ww!k4w \u00b7 \u2016\u03a0\u2016) follows."}, {"heading": "6 Extensions", "text": "In this section, we discuss some extensions of our dynamic programming approach and of Theorem 16.\nPWCs with unary weights. Our dynamic programming algorithm for the consistency problem of PCCs can be easily extended to PWCs with unary representation both, of the weights and of the constraint bounds (PWCs with unary weights, for short).\nTheorem 17. Given an arbitrary PWC \u03a0. The consistency problem for PWCs with unary weights can be solved in time O(26ww!k4w \u00b7 \u2016\u03a0\u2016) with w = max(3, tw(\u03a0)) and k = cw(\u03a0).\nProof. It suffices to show that every PWC \u03a0 with unary weights can be efficiently transformed into a PCC \u03a0\u2032 such that \u03a0 is only linearly bigger than \u03a0, the constraint-width remains the same, and the treewidth is max(3, tw(\u03a0)). The transformation from \u03a0 to \u03a0\u2032 processes each literal ` with weight j > 1 in each constraint c of \u03a0 as follows: reduce the weight of ` to 1 and add j \u2212 1 fresh atoms `2, . . . , `j (each of weight 1) to c. Moreover, we add, for \u03b1 \u2208 {2, . . . , j}, new constraints c\u03b1 := ({(`, 1), (\u00ac`\u03b1, 1)}, 1, 1) and new rules r\u03b1 := (c\u03b1, \u2205) to ensure that the fresh variables `2, . . . , `j have the same truth value as ` in every model of \u03a0. It is easy to check that \u03a0\u2032 is only linearly bigger than \u03a0 (since j is given in unary representation) and that the constraint-width and treewidth are not increased (resp. changed from treewidth \u2264 2 to treewidth 3).\nReasoning with PCCs and PWCs with unary weights. In non-monotonic reasoning, two kinds of reasoning are usually considered, namely skeptical and credulous reasoning. Recall that an atom a is skeptically implied by a program \u03a0 if a is true (i.e., contained) in every stable model of \u03a0. Likewise, an atom a is credulously implied by \u03a0 if a is true in some stable model of \u03a0. Our algorithm for the consistency problem can be easily extended to an algorithm for skeptical or credulous reasoning with PCCs and PWCs with unary weights. The above upper bounds on the complexity thus carry over from the consistency problem to the reasoning problems. We only work out the PCC-case below:\nTheorem 18. Both the skeptical and the credulous reasoning problem for PCCs \u03a0 can be solved in time O(26ww!k4w \u00b7 \u2016\u03a0\u2016) with w = tw(\u03a0) and k = cw(\u03a0).\nProof. Suppose that we are given a PCC \u03a0 and an atom a. The dynamic programming algorithm for the consistency problem has to be extended in such a way that we additionally maintain two flags cr(\u03d1) and sk(\u03d1) for every bag assignment \u03d1. These flags may take one of the values {\u22a5,>} with the intended meaning that cr(\u03d1) = > (resp. sk(\u03d1) = >) if and only if there exists a partial solution \u03d1\u0302 = (n, M\u0302, . . . ), (resp. if and only if for all partial solutions \u03d1\u0302 = (n, M\u0302, . . . )) the atom a is true in M\u0302 . Otherwise this flag is set to \u22a5. Then a is credulously (resp. skeptically) implied by \u03a0 if and only if there exists a bag model (resp. if and only if for all bag models) \u03d1 of the root node nroot of T , we have cr(\u03d1) = > (resp. sk(\u03d1) = >). Clearly, maintaining the two flags fits within the desired complexity bound.\nBounded treewidth and bounded constraint-width. Recall that we have proved the fixedparameter linearity of the consistency problem of PWCs when treewidth and constraint-width are taken as parameter (see Theorem 3). This fixed-parameter linearity result (as well as the\nanalogous result for the skeptical and credulous reasoning problem which can be easily seen to be expressible in MSO logic) could also be obtained as a corollary of Theorem 17. Indeed, consider a PWC \u03a0 whose treewidth w and constraint-width k are bounded by some fixed constant. By previous considerations, we may thus assume that all weights occurring in \u03a0 are bounded by a constant. Therefore, we can transform all weights and bounds into unary representation such that the size of the resulting PWC with unary weights differs from \u2016\u03a0\u2016 only by a constant factor (namely 2k). The upper bound on the complexity in Theorem 17 immediately yields the desired fixed-parameter linearity result since f(w) \u00b7O(k2w) is bounded by a constant that is independent of the size of \u03a0."}, {"heading": "7 W[1]-Hardness", "text": "In this section we will show that it is unlikely that one can improve the non-uniform polynomialtime result of Theorem 16 to a fixed-parameter tractability result (without bounding the constraint-width as in Theorem 3). We will develop our hardness result within the framework of parameterized complexity. Therefore we first outline some of the main concepts of the subject, for an in-depth treatment we refer to other sources [6, 7, 15].\nAn instance of a parameterized problem is a pair (x, k), where x is the main part and k (usually a non-negative integer) is the parameter. A parameterized problem is fixed-parameter tractable if an instance (x, k) of size n can be solved in time O(f(k)nc) where f is a computable function and c is a constant independent of k. If c = 1 then we speak of linear-time fixed-parameter tractability. FPT denotes the class of all fixed-parameter tractable decision problems. Parameterized complexity theory offers a completeness theory similar to the theory of NP-completeness. An fpt-reduction from a parameterized decision problem P to a parameterized decision problem Q is a transformation that maps an instance (x, k) of P of size n to an instance (x\u2032, k\u2032) of Q with k\u2032 \u2264 g(k) in time O(f(k)nc) (f, g are arbitrary computable functions, c is a constant) such that (x, k) is a yes-instance of P if and only if (x\u2032, k\u2032) is a yes-instance of Q. A parameterized complexity class C is the class of parameterized decision problems fpt-reducible to a certain parameterized decision problem Q. A parameterized problem P is C-hard, if every problem in C is fpt-reducible to P . Problem P is called C-complete, if it is additionally contained in C. Of particular interest is the class W [1] which is considered as the parameterized analog to NP. For example, the Clique problem (given a graph G and an integer k, decide whether G contains a complete subgraph on k vertices), parameterized by k, is a well-known W [1]-complete problem. It is believed that FPT 6= W [1], and there is strong theoretical evidence that supports this belief, for example, FPT = W [1] would imply that the Exponential Time Hypothesis fails, see [7].\nIn the proof of Theorem 19 below we will devise an fpt-reduction from the Minimum Maximum Outdegree problem (or MMO, for short). To state this problem we need to introduce some concepts. A (positive integral) edge weighting of a graph H = (V,E) is a mapping w that assigns to each edge of H a positive integer. An orientation of H is a mapping \u039b : E \u2192 V \u00d7 V with \u039b({u, v}) \u2208 {(u, v), (v, u)}. The weighted outdegree of a vertex v \u2208 V with respect to an edge weighting w and an orientation \u039b is defined as\nd+H,w,\u039b(v) = \u2211\n{v,u}\u2208E with \u039b({v,u})=(v,u)\nw({v, u}).\nAn instance of MMO consists of a graph H, an edge weighting w of H, and a positive integer r; the question is whether there exists an orientation \u039b of H such that d+H,w,\u039b(v) \u2264 r for each v \u2208 V . The MMO problem with edge weights (and therefore also r) given in unary is W [1]-hard when parameterized by the treewidth of H [17].\nTheorem 19. The consistency problem for PCCs is W [1]-hard when parameterized by treewidth.\nProof. Let (H,w, r) be an instance of MMO of treewidth t, H = (V,E). We may assume that no edge is of weight larger than r since otherwise we can reject the instance. Let \u227a be an arbitrary linear ordering of V . We form a PWC \u03a0 = (A, C,R) with unary weights as follows: The set A contains an atom auv = avu for each edge {u, v} \u2208 E; C contains a constraint cv = (Sv, 0, r) for each vertex v \u2208 V where Sv = { (auv, w({v, u})) : {u, v} \u2208 E, v \u227a u } \u222a { (\u00acauv, w({v, u})) : {u, v} \u2208 E, u \u227a v }; R contains a rule rv = (cv, \u2205) for each vertex v \u2208 V .\nClaim 1. tw(\u03a0) \u2264 max(2, t). Let (T, \u03c7) be a tree decomposition of H of width t. We extend (T, \u03c7) to a tree decomposition of \u03a0 as follows. For each edge {u, v} \u2208 E we pick a node nuv of T with u, v \u2208 \u03c7(nuv) and for each vertex v \u2208 V we pick a node nv of T with v \u2208 \u03c7(nv) (such nodes exist by the definition of a tree decomposition). We attach to nuv a new neighbor n \u2032 uv (of degree 1) and put \u03c7(n\u2032uv) = {u, v, auv}, and we attach to nv a new neighbor n\u2032v (of degree 1) and put \u03c7(n\u2032v) = {v, rv}. It is easy to verify that we obtain this way a tree decomposition of \u03a0 of width max(t, 2), hence the claim follows. Note that in fact we have tw(\u03a0) \u2265 tw(H) since H is a graph minor of the incidence graph of \u03a0.\nClaim 2. H has an orientation \u039b with maxv\u2208V d + H,w,\u039b(v) \u2264 r if and only if \u03a0 has a model. We associate with an orientation \u039b the subset A\u039b = { auv \u2208 A\u039b : u \u227a v and \u039b({u, v}) = (u, v) }. This gives a natural one-to-one correspondence between orientations of H and subsets of A. We observe that for each v \u2208 V , the sum of weights of the literals in constraint cv satisfied by A\u039b is exactly the weighted outdegree of v with respect to \u039b. Hence A\u039b is a model of \u03a0 if and only if d+H,w,\u039b(v) \u2264 r for all v \u2208 V .\nClaim 3. All models of \u03a0 are stable. This claim follows by exactly the same argument as in the proof of Theorem 2.\n\u03a0 can certainly be obtained from (H,w, r) in polynomial time. We can even encode the weights of literals in unary since we assumed that that the edge weighting w is given in unary. Hence, by Claims 1\u20133 we have an fpt-reduction from MMO to the consistency problem for PWCs with unary weights. Using the construction as described in the proof of Theorem 17, we can transform \u03a0 in polynomial time into a decision-equivalent PCC \u03a0\u2032 by increasing the treewidth at most by a small constant. In total we have an fpt-reduction from MMO to the consistency problem for PCCs (both problems parameterized by treewidth). The theorem now follows by the W [1]-hardness of MMO for parameter treewidth."}, {"heading": "8 Discussion", "text": "In this work, we have proved several results for PWCs and PCCs of bounded treewidth without addressing the problem of actually computing a tree decomposition of appropriate width. As has been mentioned earlier, [1] showed that deciding if a graph has treewidth \u2264 w and, if this is the case, computing a tree decomposition of width w is fixed-parameter linear for parameter w. Unfortunately, this linear time algorithm is only of theoretical interest and the practical usefulness is limited [12]. However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].\nRecently a meta-theorem for MSO problems on graphs with cardinality and weight constraints was shown [18]. This meta-theorem allows one to handle cardinality constraints with respect to sets that occur as free variables in the corresponding MSO formula. It provides a polynomial time algorithm for checking whether a PCC (or a PWC with weights in unary) of bounded treewidth has a model. However, in order to check whether a PCC has a stable model, one needs to handle cardinality constraints with respect to sets that occur as quantified variables in the MSO formula, which is not possible with the above mentioned meta-theorem.\nWe have already mentioned a dynamic programming algorithm for ASP [9]. This algorithm works for programs without cardinality or weight constraints, but possibly with disjunction in the head of the rules. The data structure manipulated at each node for this ASP algorithm is\nconceptually much simpler than the one used here: Potential models of the given program are represented by so-called tree-models. A tree-model consists of a subset of the atoms in a bag (the ones which are true in the models thus represented) and a subset of the rules in a bag (the ones which are validated by the models thus represented). However, to handle the minimality condition on stable models, it is not sufficient to propagate potential models along the bottomup traversal of the tree decomposition. In addition, it is required, for each potential model M , to keep track of all those models of the reduct w.r.t. M which would prevent M from being minimal. Those models are represented by a set of tree-models accompanying each tree-model. Hence, despite the simplicity of the data structure, the time complexity of the algorithm from [9] is double exponential in the treewidth, since it has to handle sets of subsets of the bag at each node. Therefore, rather than extending that algorithm by mechanisms to handle weight or cardinality constraints, we have presented here an algorithm based on a completely different data structure \u2013 in particular, keeping track of orderings of the atoms. We have thus managed to obtain an algorithm whose time complexity is single exponential in the treewidth."}, {"heading": "9 Conclusion", "text": "In this paper we have shown how the notion of bounded treewidth can be used to identify tractable fragments of answer-set programming with weight constraints. However, by proving hardness results, we have also shown that a straightforward application of treewidth is not sufficient to achieve the desired tractability.\nThe upper bounds on the time complexity of our dynamic programming algorithms were obtained by very coarse estimates (see Theorems 16, 17, 18). In particular, we assumed straightforward methods for storing and manipulating bag assignments. For an actual implementation of our algorithm, we plan to use the SHARP framework2, a C++ interface that enables rapid development of algorithms which are based on tree or hypertree decompositions by providing (hyper-)tree decomposition routines and algorithm interfaces. It thus allows the designer to focus on the problem-specific part of the algorithm. SHARP itself uses the htdecomp library3 which implements several heuristics for (hyper)tree decompositions, see also [5]. Using sophisticated methods and data structures in implementing the functionality of the different node types of our algorithm should eventually result in a further improvement of the (theoretical) upper bounds on the time complexity provided in this paper.\nFor future work, we plan to extend the parameterized complexity analysis and the development of efficient algorithms to further problems where weights or cardinalities play a role. Note that weights are a common feature in the area of knowledge representation and reasoning, for instance, to express costs or probabilities."}], "references": [{"title": "A linear-time algorithm for finding tree-decompositions of small treewidth", "author": ["H.L. Bodlaender"], "venue": "SIAM J. Comput.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1996}, {"title": "Safe separators for treewidth", "author": ["H.L. Bodlaender", "A.M.C.A. Koster"], "venue": "Discrete Mathematics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Combinatorial optimization on graphs of bounded treewidth", "author": ["H.L. Bodlaender", "A.M.C.A. Koster"], "venue": "Comput. J.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Recognizability and second-order definability for sets of finite graphs", "author": ["B. Courcelle"], "venue": "Technical Report I-8634, Universite\u0301 de Bordeaux,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1987}, {"title": "Heuristic methods for hypertree decomposition", "author": ["A. Dermaku", "T. Ganzow", "G. Gottlob", "B.J. McMahan", "N. Musliu", "M. Samer"], "venue": "In Proc. MICAI,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Parameterized Complexity", "author": ["R.G. Downey", "M.R. Fellows"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1999}, {"title": "Parameterized Complexity Theory", "author": ["J. Flum", "M. Grohe"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Bounded treewidth as a key to tractability of knowledge representation and reasoning", "author": ["G. Gottlob", "R. Pichler", "F. Wei"], "venue": "Artif. Intell.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Answer-set programming with bounded treewidth", "author": ["M. Jakl", "R. Pichler", "S. Woltran"], "venue": "In C. Boutilier, editor, Proc. IJCAI\u201909,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Pushing the power of stochastic greedy ordering schemes for inference in graphical models", "author": ["K. Kask", "A. Gelfand", "L. Otten", "R. Dechter"], "venue": "Proc. AAAI\u201911,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Treewidth, Computations and Approximations", "author": ["T. Kloks"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1994}, {"title": "Treewidth: Computational experiments", "author": ["A.M.C.A. Koster", "H.L. Bodlaender", "S.P.M. van Hoesel"], "venue": "Electronic Notes in Discrete Mathematics,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2001}, {"title": "Level mapping induced loop formulas for weight constraint and aggregate programs", "author": ["G. Liu"], "venue": "Proc. LPNMR\u201909,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Stable models and an alternative logic programming paradigm", "author": ["V.W. Marek", "M. Truszczy\u0144ski"], "venue": "The Logic Programming Paradigm: A 25-Year Perspective,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1999}, {"title": "Invitation to Fixed-Parameter Algorithms", "author": ["R. Niedermeier"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "Stable model semantics of weight constraint rules", "author": ["I. Niemel\u00e4", "P. Simons", "T. Soininen"], "venue": "Proc. LPNMR\u201999,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1999}, {"title": "Not so easy problems for tree decomposable graphs. In Advances in discrete mathematics and applications: Mysore, 2008, volume", "author": ["S. Szeider"], "venue": "Ramanujan Math. Soc. Lect. Notes Ser.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Monadic second order logic on graphs with local cardinality constraints", "author": ["S. Szeider"], "venue": "ACM Trans. Comput. Log.,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Safe reduction rules for weighted treewidth", "author": ["F. van den Eijkhof", "H.L. Bodlaender", "A.M.C.A. Koster"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}], "referenceMentions": [{"referenceID": 13, "context": "Answer-set programming (ASP) has evolved as a paradigm that allows for very elegant solutions to many combinatorial problems [14].", "startOffset": 125, "endOffset": 129}, {"referenceID": 15, "context": "By extending logic programs with cardinality or, more generally, weight constraints, an even larger class of problems is accessible to this method [16].", "startOffset": 147, "endOffset": 151}, {"referenceID": 7, "context": "In the area of knowledge representation and reasoning (KR & R), many tractability results for instances of bounded treewidth have been recently proven [8].", "startOffset": 151, "endOffset": 154}, {"referenceID": 0, "context": "Technically, we prove that the consistency problem of PCCs parameterized by treewidth is hard for the parameterized complexity class W [1].", "startOffset": 135, "endOffset": 138}, {"referenceID": 0, "context": "By giving a W [1]-hardness proof in case of unary representation in Section 7, we show that it is unlikely that this result can be significantly improved.", "startOffset": 14, "endOffset": 17}, {"referenceID": 15, "context": "Following [16], the reduct c of a constraint c \u2208 C w.", "startOffset": 10, "endOffset": 14}, {"referenceID": 10, "context": "A tree decomposition (T, \u03c7) is called normalized (or nice) [11], if T is a rooted tree and the following conditions hold: (1) each n \u2208 T has \u2264 2 children; (2) for each n \u2208 T with two children n1, n2, \u03c7(n) = \u03c7(n1) = \u03c7(n2); and (3) for each n \u2208 T with one child n\u2032, \u03c7(n) and \u03c7(n\u2032) differ in exactly one element.", "startOffset": 59, "endOffset": 63}, {"referenceID": 10, "context": "It is known that every tree decomposition can be normalized in linear time without increasing the width [11].", "startOffset": 104, "endOffset": 108}, {"referenceID": 0, "context": "For arbitrary but fixed w \u2265 1, it is feasible in linear time to decide whether a graph has treewidth \u2264 w and, if so, to compute a tree decomposition of width w, see [1].", "startOffset": 165, "endOffset": 168}, {"referenceID": 3, "context": "To prove this result we shall take a logic approach and use Courcelle\u2019s Theorem [4], see also [6, 7].", "startOffset": 80, "endOffset": 83}, {"referenceID": 5, "context": "To prove this result we shall take a logic approach and use Courcelle\u2019s Theorem [4], see also [6, 7].", "startOffset": 94, "endOffset": 100}, {"referenceID": 6, "context": "To prove this result we shall take a logic approach and use Courcelle\u2019s Theorem [4], see also [6, 7].", "startOffset": 94, "endOffset": 100}, {"referenceID": 0, "context": "The latter is no restriction for proving Theorem 3, since by Bodlaender\u2019s Theorem [1], we can compute in linear time a tree decomposition of smallest width for graphs whose treewidth is bounded by a constant.", "startOffset": 82, "endOffset": 85}, {"referenceID": 8, "context": "Recently, [9] presented a dynamic programming algorithm for answer-set programming that works for programs without cardinality or weight constraints, but possibly with disjunction in the head of the rules.", "startOffset": 10, "endOffset": 13}, {"referenceID": 12, "context": "Slightly rephrasing a result by [13] we can characterize answer sets of PCCs as follows:", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "7 W[1]-Hardness", "startOffset": 3, "endOffset": 6}, {"referenceID": 5, "context": "Therefore we first outline some of the main concepts of the subject, for an in-depth treatment we refer to other sources [6, 7, 15].", "startOffset": 121, "endOffset": 131}, {"referenceID": 6, "context": "Therefore we first outline some of the main concepts of the subject, for an in-depth treatment we refer to other sources [6, 7, 15].", "startOffset": 121, "endOffset": 131}, {"referenceID": 14, "context": "Therefore we first outline some of the main concepts of the subject, for an in-depth treatment we refer to other sources [6, 7, 15].", "startOffset": 121, "endOffset": 131}, {"referenceID": 0, "context": "Of particular interest is the class W [1] which is considered as the parameterized analog to NP.", "startOffset": 38, "endOffset": 41}, {"referenceID": 0, "context": "For example, the Clique problem (given a graph G and an integer k, decide whether G contains a complete subgraph on k vertices), parameterized by k, is a well-known W [1]-complete problem.", "startOffset": 167, "endOffset": 170}, {"referenceID": 0, "context": "It is believed that FPT 6= W [1], and there is strong theoretical evidence that supports this belief, for example, FPT = W [1] would imply that the Exponential Time Hypothesis fails, see [7].", "startOffset": 29, "endOffset": 32}, {"referenceID": 0, "context": "It is believed that FPT 6= W [1], and there is strong theoretical evidence that supports this belief, for example, FPT = W [1] would imply that the Exponential Time Hypothesis fails, see [7].", "startOffset": 123, "endOffset": 126}, {"referenceID": 6, "context": "It is believed that FPT 6= W [1], and there is strong theoretical evidence that supports this belief, for example, FPT = W [1] would imply that the Exponential Time Hypothesis fails, see [7].", "startOffset": 187, "endOffset": 190}, {"referenceID": 0, "context": "The MMO problem with edge weights (and therefore also r) given in unary is W [1]-hard when parameterized by the treewidth of H [17].", "startOffset": 77, "endOffset": 80}, {"referenceID": 16, "context": "The MMO problem with edge weights (and therefore also r) given in unary is W [1]-hard when parameterized by the treewidth of H [17].", "startOffset": 127, "endOffset": 131}, {"referenceID": 0, "context": "The consistency problem for PCCs is W [1]-hard when parameterized by treewidth.", "startOffset": 38, "endOffset": 41}, {"referenceID": 0, "context": "The theorem now follows by the W [1]-hardness of MMO for parameter treewidth.", "startOffset": 33, "endOffset": 36}, {"referenceID": 0, "context": "As has been mentioned earlier, [1] showed that deciding if a graph has treewidth \u2264 w and, if this is the case, computing a tree decomposition of width w is fixed-parameter linear for parameter w.", "startOffset": 31, "endOffset": 34}, {"referenceID": 11, "context": "Unfortunately, this linear time algorithm is only of theoretical interest and the practical usefulness is limited [12].", "startOffset": 114, "endOffset": 118}, {"referenceID": 11, "context": "However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].", "startOffset": 189, "endOffset": 207}, {"referenceID": 1, "context": "However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].", "startOffset": 189, "endOffset": 207}, {"referenceID": 18, "context": "However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].", "startOffset": 189, "endOffset": 207}, {"referenceID": 2, "context": "However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].", "startOffset": 189, "endOffset": 207}, {"referenceID": 9, "context": "However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].", "startOffset": 189, "endOffset": 207}, {"referenceID": 17, "context": "Recently a meta-theorem for MSO problems on graphs with cardinality and weight constraints was shown [18].", "startOffset": 101, "endOffset": 105}, {"referenceID": 8, "context": "We have already mentioned a dynamic programming algorithm for ASP [9].", "startOffset": 66, "endOffset": 69}, {"referenceID": 8, "context": "Hence, despite the simplicity of the data structure, the time complexity of the algorithm from [9] is double exponential in the treewidth, since it has to handle sets of subsets of the bag at each node.", "startOffset": 95, "endOffset": 98}, {"referenceID": 4, "context": "SHARP itself uses the htdecomp library which implements several heuristics for (hyper)tree decompositions, see also [5].", "startOffset": 116, "endOffset": 119}], "year": 2012, "abstractText": "Cardinality constraints or, more generally, weight constraints are well recognized as an important extension of answer-set programming. Clearly, all common algorithmic tasks related to programs with cardinality or weight constraints \u2013 like checking the consistency of a program \u2013 are intractable. Many intractable problems in the area of knowledge representation and reasoning have been shown to become linear time tractable if the treewidth of the programs or formulas under consideration is bounded by some constant. The goal of this paper is to apply the notion of treewidth to programs with cardinality or weight constraints and to identify tractable fragments. It will turn out that the straightforward application of treewidth to such class of programs does not suffice to obtain tractability. However, by imposing further restrictions, tractability can be achieved.", "creator": "TeX"}}}