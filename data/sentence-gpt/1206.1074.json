{"id": "1206.1074", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2012", "title": "Memetic Artificial Bee Colony Algorithm for Large-Scale Global Optimization", "abstract": "Memetic computation (MC) has emerged recently as a new paradigm of efficient algorithms for solving the hardest optimization problems. On the other hand, artificial bees colony (ABC) algorithms demonstrate good performances when solving continuous and combinatorial optimization problems. This study tries to use these technologies under the same roof. As a result, a memetic ABC (MABC) algorithm has been developed that is hybridized with two local search heuristics: the Nelder-Mead algorithm (NMA) and the random walk with direction exploitation (RWDE). The former is attended more towards exploration, while the latter more towards exploitation of the search space. The stochastic adaptation rule was employed in order to control the balancing between exploration and exploitation. This MABC algorithm was applied to a Special suite on Large Scale Continuous Global Optimization at the 2012 IEEE Congress on Evolutionary Computation. The obtained results the MABC are comparable with the results of DECC-G, DECC-G*, and MLCC.\n\n\n\nTo further enhance the understanding of neural networks, we presented our research in the Proceedings of the National Academy of Sciences.\n\nThis article was made available online here.", "histories": [["v1", "Tue, 5 Jun 2012 21:04:10 GMT  (187kb,D)", "http://arxiv.org/abs/1206.1074v1", "CONFERENCE: IEEE Congress on Evolutionary Computation, Brisbane, Australia, 2012"]], "COMMENTS": "CONFERENCE: IEEE Congress on Evolutionary Computation, Brisbane, Australia, 2012", "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["iztok fister", "iztok fister jr", "janez brest", "viljem \\v{z}umer"], "accepted": false, "id": "1206.1074"}, "pdf": {"name": "1206.1074.pdf", "metadata": {"source": "CRF", "title": "Memetic Artificial Bee Colony Algorithm for Large-Scale Global Optimization", "authors": ["Iztok Fister", "Iztok Fister Jr.", "Janez Brest", "Viljem \u017dumer"], "emails": ["iztok.fister@uni-mb.si", "iztok.fister@guest.arnes.si", "janez.brest@uni-mb.si", "zumer@uni-mb.si"], "sections": [{"heading": null, "text": "Memetic computation (MC) has emerged recently as a new paradigm of efficient algorithms for\nsolving the hardest optimization problems. On the other hand, artificial bees colony (ABC) algo-\nrithms demonstrate good performances when solving continuous and combinatorial optimization\nproblems. This study tries to use these technologies under the same roof. As a result, a memetic\nABC (MABC) algorithm has been developed that is hybridized with two local search heuristics:\nthe Nelder-Mead algorithm (NMA) and the random walk with direction exploitation (RWDE).\nThe former is attended more towards exploration, while the latter more towards exploitation of\nthe search space. The stochastic adaptation rule was employed in order to control the balancing\nbetween exploration and exploitation. This MABC algorithm was applied to a Special suite on\nLarge Scale Continuous Global Optimization at the 2012 IEEE Congress on Evolutionary Compu-\ntation. The obtained results the MABC are comparable with the results of DECC-G, DECC-G*,\nand MLCC.\nTo cite paper as follows: I. Fister, I. Fister Jr., J. Brest, V. Zumer, Memetic Artificial Bee\nColony Algorithm for Large-Scale Global Optimization, in Proc. IEEE Congress on Evolutionary\nComputation, Brisbane, Australia, 2012\n\u2217University of Maribor, Faculty of electrical engineering and computer science Smetanova 17, 2000 Maribor;\nElectronic address: iztok.fister@uni-mb.si \u2020University of Maribor, Faculty of electrical engineering and computer science Smetanova 17, 2000 Maribor;\nElectronic address: iztok.fister@guest.arnes.si \u2021University of Maribor, Faculty of electrical engineering and computer science Smetanova 17, 2000 Maribor;\nElectronic address: janez.brest@uni-mb.si \u00a7University of Maribor, Faculty of electrical engineering and computer science Smetanova 17, 2000 Maribor;\nElectronic address: zumer@uni-mb.si\nar X\niv :1\n20 6.\n10 74\nv1 [\ncs .N\nE ]\n5 J\nun 2\n01 2\nI. INTRODUCTION\nA large-scale global optimization problem is defined as follows. Let us assume, an objective function f(x) is given, where x = (x1, . . . , xD) is a vector of D design variables in a decision space S. The design variables xi \u2208 {xlb, xub} are limited by their lower xlb \u2208 R and upper bounds xub \u2208 R. The task of optimization is to find the minimum of the objective function. Note that large-scale refers to a huge number of variables, i.e. n \u2265 1, 000. Moreover, this problem belongs to the domain of function optimization.\nThe domain of function optimization serves as a \u2019test-bed\u2019 for many new comparisons and new features of various algorithms [25]. Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12]. EAs hybridized with local search algorithms [1] have been successful within this domain. These kinds of EAs are often named as memetic algorithms (MAs) [24, 27]. Memetic computation (MC) [33] has emerged recently as a widening of MAs. MC uses a composition of memes that represent those units of information encoded within complex structures and interact with each other for the purpose of problemsolving. Namely, the meme denotes an abstract concept that can be, for example: a strategy, an operator or a local search algorithm.\nAs analog to EA, swarm intelligence (SI) [4] has been inspired by nature. For foraging and defending, it simulates the collective behavior of social insects, flock of birds, ant-colonies, and fish schools. These particles are looking for good food sources and due to the interaction between them move to the more promising regions within an environment. This concept has been exploited also by the Artificial Bees Colony (ABC) algorithm proposed by Karaboga and Basturk [19] and achieved excellent results when solving continuous optimization problems [20] as well as combinatorial optimization problems [15, 37].\nArtificial bees form colonies within which each bee has limited capabilities and limited knowledge of its environment. However, such a colony is capable of developing a collective intelligence that is used for foraging. The foraging process is divided into three components: food sources, employed foragers, and unemployed foragers. On the other hand, Iacca et al. [18] assert that an optimal memetic exploration of the search space is composed of three\nmemes: the first stochastic with long-search radius, the second stochastic with a moderatesearch radius, and the third deterministic with short-search radius. In line with this, it has been identified that the original ABC algorithm also explores the search space over three stages that could correspond to three memes: the first stochastic with a long-search radius (food sources), the second stochastic with a moderate-search radius (employed foragers), and the third random with long-search radius (unemployed foragers).\nUnfortunately, the deterministic meme with a short-search radius is missing from this identification. Therefore, the original ABC algorithm has been hybridized with the local search heuristics representing this deterministic meme. Two local search methods were applied within the proposed memetic ABC (MABC) algorithm: the Nelder/Mead (NM) simplex method [35] and the random walk method with direction exploitation (RWDE) [35]. The former is designed more towards exploration, whilst the latter more towards exploitation of the continuous search space. The stochastic adaptive rule as specified by Neri [9] was applied for balancing the exploration and exploitation.\nIn order to prevent a slow convergence of the original ABC algorithm caused because of a single-dimension update by the crossover operator, a new crossover operator capable of updating multiple dimensions was developed within MABC. Additionally, new mutation strategies similar to DE strategies were incorporated into this algorithm.\nFinally, this MABC algorithm was applied to a Special suite on Large Scale Continuous\nGlobal Optimization at the 2012 IEEE Congress on Evolutionary Computation.\nThis paper is structured as follows. Section II describes the MABC algorithm. In Section III, the test suite together with the experimental setup is discussed in detail. In Section IV, the obtained results are presented and compared with other algorithms. In Section V, the final remarks are presented, and a look is taken on future work."}, {"heading": "II. MEMETIC ARTIFICIAL BEES COLONY ALGORITHM FOR LARGE-SCALE", "text": "GLOBAL OPTIMIZATION\nIn the original ABC algorithm, the foraging process is performed by three groups of bees: employed bees, onlookers, and scouts. Each food source is discovered by only one employed bee. On the basis of information obtained by the employed foragers, the onlooker bees make a decision, which food source to visit. When the food source is exhausted, the corresponding\nunemployed foragers become scouts.\nIn order to make a super-fit individual [9] that guides the direction in which the search space needs to be explored by the bee colony, an additional step is added to the original ABC algorithm, i.e. locally improving the best bee. As a result, the final scheme for the MABC algorithm is obtained as follows:\nAlgorithm 1 Pseudo code of the MABC algorithm\n1: Init(); 2: while !TerminationConditionMeet() do 3: SendEmployedBees(); 4: SendOnlookerBees(); 5: LocalImproveBestBee(); 6: SendScouts(); 7: end while\nMABC is a population-based algorithm of size NP , where the candidate solutions xi are vectors of D design variables within a decision space S. Initial population (function Init() in Algorithm 1) is randomly sampled within decision space S, as follows:\nx (0) i,j = rand (0, 1) . (ub\u2212 lb) + lb, for j = 1 . . . D, (1)\nwhere function rand (0, 1) returns a random value between 0 and 1, and lb, ub denote the lower and upper bounds of the candidate solution xi.\nThe core of the foraging process (sequence of function calls in the while loop in Algo-\nrithm 1) consists of four functions:\n\u2022 SendEmployedBees(): sending the employed bees onto the food sources and evaluating\ntheir nectar amounts,\n\u2022 SendOnlookerBees(): sharing information about food sources with employed bees,\nselecting the proper food source and evaluating their nectar amounts,\n\u2022 LocalImproveBestBee(): determining the best food source and improve it,\n\u2022 SendScouts(): determining the scout bees and then sending them to find new possibly\nbetter food sources.\nIn the sense of MC analysis due to [18], each of these four functions perform certain\nexploration task, as follows:\n\u2022 stochastic long-distance exploration (function SendEmployedBees()),\n\u2022 stochastic moderate-distance exploration (function SendOnlookerBees()),\n\u2022 deterministic short-distance exploration (function LocalImproveBestBee()),\n\u2022 random long-distance exploration (function SendScouts()).\nIn continuation, these exploration tasks are discussed in detail."}, {"heading": "A. Stochastic long-distance exploration", "text": "The stochastic long-distance exploration is performed in the DE fashion [34] as follows. In order to obtain a trial solution, three operators are applied on each candidate\u2019s solution, i.e. mutation, crossover and selection. The mutation operator in MABC implements a \u2032rand/1/bin \u2032 like DE mutation strategy, according to Eq. (2):\nv (t) i = x (t) r1 + ( x (t) r2 \u2212 x (t) r3 ) , (2)\nwhere r1, r2, r3 denote randomly-selected candidate solutions, and t is the generation number. This operator is slightly different from the original ABC modification operator. Conversely to DE, the constant scale parameter F is unused in the Eq. (2).\nIn place of the original ABC expression for producing a new food position that modifies only single dimension of trial solution, the new expression is developed in MABC that is capable to modify multiple dimensions in trial solution. The number of modifications are controlled by CR parameter as follows:\nu (t) i,j = v (t) i,j if (randj(0, 1) \u2264 CR || j == jr4) ,\nx (t) i,j otherwise,\n(3)\nwhere jr4 denotes a random dimension within the trial solution. According to the minimum value of the objective function, the selection operator selects the best between the candidate and trial solution, as expressed in Eq. (4):\nxt+1i = u (t) i if ( f ( u (t) i ) \u2264 f ( x (t) i )) x (t) i,j otherwise.\n(4)\nThe long-distance exploration comprises two stochastic mechanisms: the mutation strategy and crossover operators. The first mechanism focuses on exploration because the modified dimensions of the trial solution is independent of the current value, i.e. the new value is sampled as three dimensions of randomly-selected candidate solutions. The second mechanism determines how many modifications should be applied to the trial solution. As a result, this exploration attempts to detect new promising regions within the entire decision space S."}, {"heading": "B. Stochastic moderate-distance exploration", "text": "Onlooker bees visit a food source after making a decision if the appropriate food source lacks sufficient nectar amounts. Within more nectar amounts, more bees can be expected in the vicinity of this food source. The property q that the i-th onlooker bee should visit the nectar amount is expressed as follows:\nqi = fi \u2212 fworst fbest \u2212 fworst , (5)\nwhere fi, fworst and fbest denotes the nectar amounts of i-th, worst and best food sources.\nThe stochastic moderate-distance exploration is performed similarly to long-distance exploration, i.e. a trial solution undergoes acting the three operators: mutation, crossover and selection. Here, MABC implements a \u2032currenttobest/1/bin \u2032 like DE strategy as the mutation operator, expressed as:\nv (t) i = x (t) i + ( x (t) best \u2212 x (t) i ) + ( x (t) r1 \u2212 x (t) r2 )  if (qi < r0)else i = i+ 1 (6) where r0 denotes the randomly generated number between 0 and 1 (rand(0, 1)), r1 and r2 are the randomly-selected candidate solutions and qi is expressed according to Eq. (5). The crossover and selection operators are implemented according to Eqs (3) and (4).\nNote that the trial solution is only generated if the nectar amounts are sufficient. If not, the next food source is selected. This process repeats until the number of onlooker bees does not exceed NP . In this manner, the food sources with more nectar amounts are likely to be visited by onlookers. As a results, onlookers are collected in the vicinity of more promising food sources.\nIn summary, the function SendOnlookerBees() directs onlookers to more promising regions of the search space. The applied mutation operator also contributes to this directed search."}, {"heading": "C. Deterministic short-distance exploration", "text": "The deterministic short-distance exploration tries to fully exploit promising search directions. The goal of this exploration is to bring a candidate solution into the local optimum. In the case that the solution is the global optimum, the search needs to be finished. In MABC, short-distance exploration concerns for maintaining a diversity of population.\nIn population-based algorithms, diversity plays a crucial role in the success of the optimization [29]. The diversity of a population is a measure of the different solutions present [14]. This measure can be expressed as the number of different fitness values present, the number of different phenotypes present, or the number of different genotypes present. In this study, the fitness diversity metric is expressed as [30]:\n\u03a8 = 1\u2212 \u2223\u2223\u2223\u2223 favg \u2212 fbestfworst \u2212 fbest \u2223\u2223\u2223\u2223 , (7) where favg, fbest, and fworst denote the average, best, and worst fitness of individuals in the population. Note that the metric returns values between 0 and 1.\nThe main characteristic of this metric is that its value is independent on the range of variability the fitness values. It is very sensible to small variations and thus, especially suitable for fitness landscapes containing plateaus and low gradient areas [29]. Although more fitness diversity metrics were used in the experiments, this metric demonstrated that it is the most suitable for the MABC algorithm.\nIn the sense of deterministic short-distance exploration, two local search algorithms were developed that run within the ABC framework. The first is the Nelder-Mead Algorithm (NMA) [28] with exploration features and the second the Random Walk with Direction Exploitation (RWDE) [35] with exploitation features. In order to coordinate the exploration/exploitation process, the following exponential distribution is used:\np (\u03a8) = e \u2212(\u03a8\u2212\u00b5p) 2\u03c32p , (8)\nwhere \u03a8 are the fitness diversity metric, and variable \u00b5p denotes the mean value and \u03c3p is the standard deviation of diversity metric \u03a8 calculated so far. Both values \u00b5p and \u03c3p are calculated incrementally in each generation according to the Knuth\u2019s algorithm [22].\nThe following adaptive scheme is applied for balancing between both local search algo-\nrithms:\nif rand (0, 1) > p (\u03a8) => use NMAotherwise => use RWDE, (9) where rand (0, 1) denotes a randomly generated value between 0 and 1. From Eq. (9) it can be seen that when the population looses the diversity, i.e. p (\u03a8) > 0.5, the NMA exploration algorithm is executed, whilst in contrary the RWDE exploitation algorithm takes the initiative."}, {"heading": "D. Random long-distance exploration", "text": "In nature, when the food source is exhausted the foragers become scouts. These scouts look for a new food sources within the environment. In MABC, scouts are simulated by new randomly generated food source that should be discovered by the foragers in the remaining cycles of this algorithm. The food is exhausted when the predefined number of cycles (also named scout limit) has expired, in which no further improvement of the nectar amounts are detected.\nThe scouts are generated according to Eq. (1). Note that this exploration is treated as long-distance because the new food sources are sampled within the whole decision space S. On the other hand, the exploration is blind without any history information explored so far."}, {"heading": "E. MABC framework", "text": "In the spirit of MC, the mentioned kinds of explorations can be seen as memes. These memes interact between each other in order to problem-solving. In MABC, the original ABC framework does not exploit the MC paradigm as a whole. That is, the memes are executed sequential within each generation. Let us emphasis that the stochastic long-distance (function SendEmployesBees()) and the stochastic moderate-distance (function SendOnlookerBees()) explorations are performed unconditionally, i.e. in each generation. On the other hand, the\nperformances of the deterministic short-distance (function LocalImproveBestBee()) and the random long-distance (function SendScouts()) explorations are controlled by the parameters local search ratio and scouts limit. The first parameter regulates the ratio between the global and local search, whilst the second determines when to start exploring new regions of the continuous search space."}, {"heading": "III. EXPERIMENTS", "text": "A goal of the experiments was the applying of MABC to the specific test-suite proposed in the Special session on Large Scale Continuous Global Optimization at the 2012 IEEE Congress on Evolutionary Computation, the obtaining of results, and then comparing these with the results of DECC-G*, DECC-G, and MLCC as proposed by the organizing committee, to see how many competitive results were achieved."}, {"heading": "A. Test suite", "text": "The test-suite consists of five problem classes, i.e. various high-dimensional problems\n(D = 1, 000):\n1. Separable functions:\n\u2022 F1: Shifted Elliptic Function.\n\u2022 F2: Shifted Rastrigin\u2019s Function.\n\u2022 F3: Shifted Ackley\u2019s Function.\n2. Single-group m-nonseparable functions (m = 50):\n\u2022 F4: Single-group Shifted and m-rotated Elliptic Function.\n\u2022 F5: Single-group Shifted and m-rotated Rastrigin\u2019s Function.\n\u2022 F6: Single-group Shifted and m-rotated Ackley\u2019s Function.\n\u2022 F7: Single-group Shifted and m-dimensional Schwefel\u2019s Problem 1.2.\n\u2022 F8: Single-group Shifted and m-dimensional Rosenbrock\u2019s Function.\n3. D2m -group m-nonseparable functions (m = 50):\n\u2022 F9: D2m -group Shifted and m-rotated Elliptic Function. \u2022 F10: D2m -group Shifted and m-rotated Rastrigin\u2019s Function. \u2022 F11: D2m -group Shifted and m-rotated Ackley\u2019s Function. \u2022 F12: D2m -group Shifted and m-dimensional Schwefel\u2019s Problem 1.2. \u2022 F13: D2m -group Shifted and m-dimensional Rosenbrock\u2019s Function.\n4. Dm -group m-nonseparable functions (m = 50):\n\u2022 F14: Dm -group Shifted and m-rotated Elliptic Function. \u2022 F15: Dm -group Shifted and m-rotated Rastrigin\u2019s Function. \u2022 F16: Dm -group Shifted and m-rotated Ackley\u2019s Function. \u2022 F17: Dm -group Shifted and m-dimensional Schwefel\u2019s Problem 1.2. \u2022 F18: Dm -group Shifted and m-dimensional Rosenbrock\u2019s Function.\n5. Fully-nonseparable:\n\u2022 F19: Shifted Schwefel\u2019s Problem 1.2.\n\u2022 F20: Shifted Rosenbrock\u2019s Function.\nNote that the separability of a function determines how difficult the function is to solve. That is, the function f(x) is separable if its parameters xi are independent. In general, the separable functions are considered to be the easiest. In contrast, the fully-nonseparable functions are usually the more difficult to solve [36]. The degree of separability could be controlled by randomly dividing the object variables into several groups, each of which contains a particular number of variables. Although some of used functions are separable in their original forms, applying techniques as Salomon\u2019s random coordinate rotation make them non-separable. Furthermore, the global optimum of the function could also be shifted."}, {"heading": "B. Experimental setup", "text": "Table I presents the characteristics of MABC used in the experiments. Note that all values of algorithm parameters presented in this table were the best found during extensive\nexperiments.\nThe number of independent runs of the MABC algorithm was limited to 25. The maximum number of function evaluations FEs was fixed at 3 millions. Besides the final result, the error values by FEs = 120, 000 and FEs = 600, 000 were recorded. All these values were prescribed by the organizing committee of this competition.\nThe population size was set to 20. MABC, with higher population sizes, converged slowly, whilst the same algorithm with smaller population sizes remained in local optimum. The crossover probability CR was set to 0.01. That is, each crossover modified 10 dimensions of the trial solution. The higher values of this parameter decreases the results of MABC drastically, whilst decreasing the number had a harmful impact on the results. The higher values for the local search ratio had deteriorating effect on the results. In this context, the value r = 0.006 was demonstrated the best results. The scout\u2019s limit of 200 presented the best bias between the search progress (exploitation) and exploration of new regions within the search space."}, {"heading": "C. PC configuration", "text": "All runs were made on HP Compaq with the following configurations:\n1. Processor - Intel Core i7-2600 3.4 (3.8) GHz"}, {"heading": "2. RAM - 4GB DDR3", "text": "3. Operating system - Linux Mint 12\nMABC was implemented within the Eclipse Indigo CDT framework."}, {"heading": "IV. RESULTS", "text": "The purpose of this section is to illustrate the results obtained by MABC. The results are analyzed from different points of view and summarized within the following subsections:\n\u2022 convergence plots,\n\u2022 summary of results and\n\u2022 comparison with other algorithms.\nThe obtained results are presented in detail in the reminder of this paper."}, {"heading": "A. Convergence Plots", "text": "When a convergence of the results by solving different functions is analyzed four characteristic curves can be obtained. The characteristic plots, for example, of the functions F2, F11, F15, and F16, are illustrated in Figs. 1-4. Note that the average results over 25 runs are considered in all plots."}, {"heading": "B. Summary of Results", "text": "conclusions can be derived:\n\u2022 Separable functions F1 \u2212 F3 are the easiest to solve for MABC;\n\u2022 Partial-separable Elliptic functions (F4, F9, F14) are the hardest nut to crack for\nMABC;\n\u2022 On average, the D 2m -group shifted and m-rotated functions are easier to solve than the\nD m -group shifted and m-rotated, but the single-group shifted and m-rotated functions are the hardest to solve.\nEven though, it should be valid that fully-nonseparable functions are the hardest to solve,\nthis truth could not be seen from the results of the experiments."}, {"heading": "C. Comparison with other algorithms", "text": "In this experiment, the results of the following algorithms are compared with the results\nof MABC (Table III):\n\u2022 DECC-G,\n\u2022 DECC-G* and\n\u2022 MLCC.\nDescription, characteristics and results of the mentioned algorithms are published on the conference sites [31]. The comparison was performed similarly to rules prescribed by the organizing committee of the competition on LSGO CEC\u20192011. That is, the results for each algorithm are divided into three categories determined by the FEs limits 1.2e5, 6.0e5, and 3.0e6, i.e. at the 1 25 , 1 5 and the final evaluation numbers. In the absence of results from the first two categories, only the final results have been dealt with. Then, the algorithms in the experiment are ranked according to their decreasing mean-values with ranks from 1-4. Finally, rank 1 is rewarded with 25, rank 2 with 18, rank 3 with 15, and rank 4 with 12 points. The outcome of this estimation is presented in Table IV.\nNote that the points in Table IV are divided into five groups according their problem classes. The MABC algorithm outperformed the other algorithms by solving the problem classes II and V, whilst DECC-G* the problem classes III and IV, and MLCC the problem class I. In summary, the best results were obtained by DECC-G*. However, the performance of MABC was comparable with DECC-G*.\nIn order to check how significant these results are, the Friedman nonparametric test as proposed in [16] was performed with significant level \u03b1 = 0.05. According to this test, DECC-G* and MABC significantly improved the results of DECC-G."}, {"heading": "V. CONCLUSION", "text": "This study presented a MABC algorithm that hybridizes the original ABC using two local search heuristics, i.e. NMA and RWDE. The first is dedicated more to exploration,\nwhilst the second more to exploitation of the search space. An adaptive stochastic function was employed in order to balance the process of exploration/exploitation. The results of MABC were performed in the Special Suite on LSGO in the 2012 IEEE CEC, and compared with the results of algorithms: DECC-G, DECC-G* and MLCC. These results were very competitive when compared with the other algorithms. In addition, this algorithm has been analyzed in the spirit of MC, where four exploration stages are identified: stochastic long-distance, stochastic moderate-distance, deterministic short-distance, and random longdistance explorations. Each of these stages should correspond to the particular meme. However, the interaction between memes leaves additional options for further development of this algorithm. Finally, the adaptive stochastic function for balancing the process of exploration/exploitation bases on phenotypic diversity that could be less important in a well-balanced multi-modal landscapes. In order to show how a genotypic diversity influences the results, other diversity measures should be observed in the future."}, {"heading": "Acknowledgment", "text": "The authors would like to acknowledge the efforts of the organizers of this session and availability of source code of benchmark functions. In addition, we thank to prof. Fatih Tasgetiren for help by searching the new directions in development of the ABC algorithm.\n[1] E. Aarts and J.K. Lenstra. Local search in combinatorial optimization. Princeton University\nPress, Princeton and Oxford, 1997.\n[2] F. Ba\u0308ck, D.B. Fogel, and Z. Michalewicz. Handbook of Evolutionary Computation. Computa-\ntional Intelligence Library. Oxford University Press, Inc., Bristol, UK, 1997.\n[3] T. Ba\u0308ck. Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary\nProgramming, Genetic Algorithms. Oxford University Press, Inc., New York, USA, 1996.\n[4] C. Blum and D. Merkle. Swarm intelligence: introduction and applications. Natural computing\nseries. Springer-Verlag, Berlin, Germany, 2008.\n[5] J. Brest, S. Greiner, B. Boskovic, M. Mernik, and V. Zumer. Self-adapting control parameters\nin differential evolution: A comparative study on numerical benchmark problems. IEEE Trans.\nEvolutionary Computation, 10(6):646\u2013657, 2006.\n[6] J. Brest and M.S. Mauc\u030cec. Self-adaptive differential evolution algorithm using population size\nreduction and three strategies. Soft Computing - A Fusion of Foundations, Methodologies and\nApplications, 15(11):2157\u20132174, 2011.\n[7] M. Clerc. Particle Swarm Optimization. ISTE Publishing Company, London, UK, 2006.\n[8] C.A.C. Coello, G.B. Lamont, and D.A. van Veldhuizen, editors. Evolutionary Algorithms for\nSolving Multi-Objective Problems, volume 5 of Genetic Algorithms and Evolutionary Compu-\ntation. Kluwer Academic Press, Dordrecht, Netherlands, 2007.\n[9] C. Cotta and F. Neri. Memetic Algorithms in Continuous Optimization, pages 153\u2013165.\nHandbook of Memetic Algorithms. Springer-Verlag, Berlin, Germany, 2011.\n[10] S. Das and P.N. Suganthan. Differential evolution: A survey of the state-of-the-art. IEEE\nTransaction on Evolutionary Computation, 15(1):4\u201331, 2011.\n[11] M. Dorigo, V. Maniezzo, and A. Colorni. The ant system: Optimization by a colony of coop-\nerating agents. IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics,\n26(1):29\u201341, 1996.\n[12] M. Dorigo and T. Stu\u0308tzle. Ant colony optimization. MIT Press, 2004.\n[13] R.C. Eberhart and J. Kennedy. A new optimizer using particle swarm theory. In Proceedings\nof the Sixth International Symposium on Micro Machine and Human Science (MHS\u201995), pages\n39\u201343, Piscataway, NJ, USA, October 1995.\n[14] A.E. Eiben and J.E. Smith. Introduction to evolutionary computing. Springer-Verlag, Berlin,\n2003.\n[15] I. Fister Jr., I. Fister, and J. Brest. A hybrid artificial bee colony for graph 3-coloring. Artificial\nIntelligence and Soft Computing \u2013ICAISC 2012, 2012 in press.\n[16] S. Garcia, D. Molina, M. Lozano, and F. Herrera. A study on the use of non-parametric tests\nfor analyzing the evolutionary algorithms\u2019 behaviour: a case study on the cec\u20192005 special\nsession on real parameter optimization. Journal of Heuristics, 15:617\u2013644, 2009.\n[17] F. Glover and G.A. Kochenberger. Handbook of metaheuristics, volume 57 of International\nseries in operations research & management science. Kluwer Academic Publishers, Dordrecht,\nNetherlands, 2003.\n[18] G. Iacca, F. Neri, E. Mininno, Y.-S. Ong, and M.-H. Lim. Ockham\u2019s razor in memetic\ncomputing: Three stage optimal memetic exploration. Information Sciences, 188:17\u201343, 2012.\n[19] D. Karaboga and B. Bahriye. A survey: algorithms simulating bee swarm intelligence. Artif-\nficial Intelligence Review, 31(1\u20134):61\u201385, 2009.\n[20] D. Karaboga and B. Basturk. A powerful and efficient algorithm for numerical function\noptimization: artificial bee colony (abc) algorithm. Journal of Global Optimization, 39(3):459\u2013\n471, 2007.\n[21] S. Kirkpatrick, C.D. Gelatt, Jr., and M.P. Vecchi. Optimization by simulated annealing.\nScience Magazine, 220(4598):671\u2013680, 1983.\n[22] D.E. Knuth. The Art of Computer Programming, Volume II: Seminumerical Algorithms. 2nd\nEdition Addison-Wesley, Reading Massachusetts, 1981.\n[23] T. Lozano, D. Molina, and F. Herrera. Editorial scalability of evolutionary algorithms and\nother metaheuristics for large-scale continuous optimization problems. Soft Computing - A\nFusion of Foundations, Methodologies and Applications, 15(11):2085\u20132087, 2011.\n[24] P. Merz. Memetic Algorithms for Combinatorial Problems: Fitness Landscapes and Effective\nSearch Strategy. PhD thesis, Gesamthochschule Siegen, University of Siegen, Germany, 2000.\n[25] Z. Michalewicz. Genetic Algorithms + Data Structures = Evolutionary Programs. Springer-\nVerlag, Berlin, 1996.\n[26] Z. Michalewicz and D.B. Fogel. How to Solve It: Modern Heuristics. Springer-Verlag, Berlin,\n2004.\n[27] P. Moscato. On evolutionary search, optimization, genetic algorithms and martial arts: To-\nward memetic algorithms. Technical Report Caltech Concurrent Computation Program Report\n826, Caltech, Pasadena, California, 1989.\n[28] A. Nelder and R. Mead. A simplex method for function optimization. Computation Journal,\n7:308\u2013313, 1965.\n[29] F. Neri. Diversity Management in Memetic Algorithms, pages 153\u2013165. Handbook of Memetic\nAlgorithms. Springer-Verlag, Berlin, Germany, 2011.\n[30] F. Neri, J. Toivanen, G.L. Cascella, and Y.-S. Ong. An adaptive multimeme algorithm for\ndesigning HIV multidrug therapies. IEEE/ACM Transactions on Computational Biology and\nBioinformatics, 4(2):264\u2013278, 2007.\n[31] NICAL. Special session on ec lsgo, January 2011.\n[32] A. Nolte and R. Schrader. A note on the finite time behaviour of dimulated annealing.\nMathematics of Operations Research, 25(3):476\u2013484, 2000.\n[33] Y.-S. Ong, M.-H. Lim, and X. Chen. Memetic computation - past, present & future [research\nfrontier]. IEEE Computational Intelligence Magazine, 5(2):24\u201331, 2010.\n[34] K. Price, R.M. Storn, and J.A. Lampinen. Differential Evolution: A Practical Approach to\nGlobal Optimization. Springer-Verlag, New York, NY, USA, 2005.\n[35] S.S. Rao. Engineering optimization: theory and practice. John Willey & Sons, New Jersey,\nUS, 2009.\n[36] K. Tang, Xiaodong Li, P. N. Suganthan, Z. Yang, and T. Weise. Benchmark Functions for the\nCEC 2010 Special Session and Competition on Large Scale Global Optimization. Technical\nreport, Nature Inspired Computation and Applications Laboratory, USTC, China, 2009.\n[37] M.F. Tasgetiren, Q.-K. Pan, P.N. Suganthan, and A.H.-L. Chen. A discrete artificial bee\ncolony algorithm for the total flowtime minimization in permutation flow shops. Information\nSciences, 181(16):3459\u20133475, 2011.\nUpdated 4 June 2012."}], "references": [{"title": "Local search in combinatorial optimization", "author": ["E. Aarts", "J.K. Lenstra"], "venue": "Princeton University Press, Princeton and Oxford,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1997}, {"title": "Handbook of Evolutionary Computation", "author": ["F. B\u00e4ck", "D.B. Fogel", "Z. Michalewicz"], "venue": "Computational Intelligence Library. Oxford University Press, Inc., Bristol, UK,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms", "author": ["T. B\u00e4ck"], "venue": "Oxford University Press, Inc., New York, USA,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "Swarm intelligence: introduction and applications", "author": ["C. Blum", "D. Merkle"], "venue": "Natural computing series. Springer-Verlag, Berlin, Germany,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Self-adapting control parameters in differential evolution: A comparative study on numerical benchmark problems", "author": ["J. Brest", "S. Greiner", "B. Boskovic", "M. Mernik", "V. Zumer"], "venue": "IEEE Trans. 16  Evolutionary Computation, 10(6):646\u2013657,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Self-adaptive differential evolution algorithm using population size reduction and three strategies", "author": ["J. Brest", "M.S. Mau\u010dec"], "venue": "Soft Computing - A Fusion of Foundations, Methodologies and Applications, 15(11):2157\u20132174,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Particle Swarm Optimization", "author": ["M. Clerc"], "venue": "ISTE Publishing Company, London, UK,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Evolutionary Algorithms for Solving Multi-Objective Problems, volume 5 of Genetic Algorithms and Evolutionary Computation", "author": ["C.A.C. Coello", "G.B. Lamont", "D.A. van Veldhuizen", "editors"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Memetic Algorithms in Continuous Optimization, pages 153\u2013165", "author": ["C. Cotta", "F. Neri"], "venue": "Handbook of Memetic Algorithms. Springer-Verlag, Berlin, Germany,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Differential evolution: A survey of the state-of-the-art", "author": ["S. Das", "P.N. Suganthan"], "venue": "IEEE Transaction on Evolutionary Computation, 15(1):4\u201331,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "The ant system: Optimization by a colony of cooperating agents", "author": ["M. Dorigo", "V. Maniezzo", "A. Colorni"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics, 26(1):29\u201341,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1996}, {"title": "Ant colony optimization", "author": ["M. Dorigo", "T. St\u00fctzle"], "venue": "MIT Press,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2004}, {"title": "A new optimizer using particle swarm theory", "author": ["R.C. Eberhart", "J. Kennedy"], "venue": "Proceedings of the Sixth International Symposium on Micro Machine and Human Science (MHS\u201995), pages 39\u201343, Piscataway, NJ, USA, October", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1995}, {"title": "Introduction to evolutionary computing", "author": ["A.E. Eiben", "J.E. Smith"], "venue": "Springer-Verlag, Berlin,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "A hybrid artificial bee colony for graph 3-coloring", "author": ["I. Fister Jr.", "I. Fister", "J. Brest"], "venue": "Artificial Intelligence and Soft Computing \u2013ICAISC 2012,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "A study on the use of non-parametric tests for analyzing the evolutionary algorithms\u2019 behaviour: a case study on the cec\u20192005 special session on real parameter optimization", "author": ["S. Garcia", "D. Molina", "M. Lozano", "F. Herrera"], "venue": "Journal of Heuristics, 15:617\u2013644,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Handbook of metaheuristics, volume 57 of International series in operations research & management science", "author": ["F. Glover", "G.A. Kochenberger"], "venue": "Kluwer Academic Publishers, Dordrecht, Netherlands,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "Ockham\u2019s razor in memetic computing: Three stage optimal memetic exploration", "author": ["G. Iacca", "F. Neri", "E. Mininno", "Y.-S. Ong", "M.-H. Lim"], "venue": "Information Sciences, 188:17\u201343,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "A survey: algorithms simulating bee swarm intelligence", "author": ["D. Karaboga", "B. Bahriye"], "venue": "Artifficial Intelligence Review, 31(1\u20134):61\u201385,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "A powerful and efficient algorithm for numerical function optimization: artificial bee colony (abc) algorithm", "author": ["D. Karaboga", "B. Basturk"], "venue": "Journal of Global Optimization, 39(3):459\u2013 471,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "Optimization by simulated annealing", "author": ["S. Kirkpatrick", "C.D. Gelatt", "Jr.", "M.P. Vecchi"], "venue": "Science Magazine,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1983}, {"title": "The Art of Computer Programming, Volume II: Seminumerical Algorithms", "author": ["D.E. Knuth"], "venue": "2nd Edition Addison-Wesley, Reading Massachusetts,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1981}, {"title": "Editorial scalability of evolutionary algorithms and other metaheuristics for large-scale continuous optimization problems", "author": ["T. Lozano", "D. Molina", "F. Herrera"], "venue": "Soft Computing - A Fusion of Foundations, Methodologies and Applications, 15(11):2085\u20132087,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Memetic Algorithms for Combinatorial Problems: Fitness Landscapes and Effective Search Strategy", "author": ["P. Merz"], "venue": "PhD thesis, Gesamthochschule Siegen, University of Siegen, Germany,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2000}, {"title": "Genetic Algorithms + Data Structures = Evolutionary Programs", "author": ["Z. Michalewicz"], "venue": "Springer- Verlag, Berlin,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1996}, {"title": "How to Solve It: Modern Heuristics", "author": ["Z. Michalewicz", "D.B. Fogel"], "venue": "Springer-Verlag, Berlin,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "On evolutionary search, optimization, genetic algorithms and martial arts: Toward memetic algorithms", "author": ["P. Moscato"], "venue": "Technical Report Caltech Concurrent Computation Program Report 826, Caltech, Pasadena, California,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1989}, {"title": "A simplex method for function optimization", "author": ["A. Nelder", "R. Mead"], "venue": "Computation Journal, 7:308\u2013313,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1965}, {"title": "Diversity Management in Memetic Algorithms, pages 153\u2013165", "author": ["F. Neri"], "venue": "Handbook of Memetic Algorithms. Springer-Verlag, Berlin, Germany,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "An adaptive multimeme algorithm for designing HIV multidrug therapies", "author": ["F. Neri", "J. Toivanen", "G.L. Cascella", "Y.-S. Ong"], "venue": "IEEE/ACM Transactions on Computational Biology and Bioinformatics, 4(2):264\u2013278,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "A note on the finite time behaviour of dimulated annealing", "author": ["A. Nolte", "R. Schrader"], "venue": "Mathematics of Operations Research, 25(3):476\u2013484,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2000}, {"title": "Memetic computation - past, present & future [research frontier", "author": ["Y.-S. Ong", "M.-H. Lim", "X. Chen"], "venue": "IEEE Computational Intelligence Magazine, 5(2):24\u201331,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Differential Evolution: A Practical Approach to Global Optimization", "author": ["K. Price", "R.M. Storn", "J.A. Lampinen"], "venue": "Springer-Verlag, New York, NY, USA,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2005}, {"title": "Engineering optimization: theory and practice", "author": ["S.S. Rao"], "venue": "John Willey & Sons, New Jersey, US,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "Benchmark Functions for the CEC 2010 Special Session and Competition on Large Scale Global Optimization", "author": ["K. Tang", "Xiaodong Li", "P.N. Suganthan", "Z. Yang", "T. Weise"], "venue": "Technical report, Nature Inspired Computation and Applications Laboratory, USTC, China,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2009}, {"title": "A discrete artificial bee colony algorithm for the total flowtime minimization in permutation flow shops", "author": ["M.F. Tasgetiren", "Q.-K. Pan", "P.N. Suganthan", "A.H.-L. Chen"], "venue": "Information Sciences, 181(16):3459\u20133475, 2011. Updated 4 June", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 24, "context": "The domain of function optimization serves as a \u2019test-bed\u2019 for many new comparisons and new features of various algorithms [25].", "startOffset": 123, "endOffset": 127}, {"referenceID": 16, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 79, "endOffset": 87}, {"referenceID": 25, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 79, "endOffset": 87}, {"referenceID": 20, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 172, "endOffset": 180}, {"referenceID": 30, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 172, "endOffset": 180}, {"referenceID": 1, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 212, "endOffset": 225}, {"referenceID": 2, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 212, "endOffset": 225}, {"referenceID": 7, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 212, "endOffset": 225}, {"referenceID": 22, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 212, "endOffset": 225}, {"referenceID": 4, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 255, "endOffset": 269}, {"referenceID": 5, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 255, "endOffset": 269}, {"referenceID": 9, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 255, "endOffset": 269}, {"referenceID": 32, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 255, "endOffset": 269}, {"referenceID": 6, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 305, "endOffset": 312}, {"referenceID": 12, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 305, "endOffset": 312}, {"referenceID": 10, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 347, "endOffset": 355}, {"referenceID": 11, "context": "Over the past decade, different kinds of metaheuristic optimization algorithms [17, 26] have been developed for solving this problem, for example: Simulated Annealing (SA) [21, 32], Evolutionary Algorithms (EAs) [2, 3, 8, 23], Differential Evolution (DE) [5, 6, 10, 34], Particle Swarm Optimization (PSO) [7, 13] and Ant Colony Optimization (ACO) [11, 12].", "startOffset": 347, "endOffset": 355}, {"referenceID": 0, "context": "EAs hybridized with local search algorithms [1] have been successful within this domain.", "startOffset": 44, "endOffset": 47}, {"referenceID": 23, "context": "These kinds of EAs are often named as memetic algorithms (MAs) [24, 27].", "startOffset": 63, "endOffset": 71}, {"referenceID": 26, "context": "These kinds of EAs are often named as memetic algorithms (MAs) [24, 27].", "startOffset": 63, "endOffset": 71}, {"referenceID": 31, "context": "Memetic computation (MC) [33] has emerged recently as a widening of MAs.", "startOffset": 25, "endOffset": 29}, {"referenceID": 3, "context": "As analog to EA, swarm intelligence (SI) [4] has been inspired by nature.", "startOffset": 41, "endOffset": 44}, {"referenceID": 18, "context": "This concept has been exploited also by the Artificial Bees Colony (ABC) algorithm proposed by Karaboga and Basturk [19] and achieved excellent results when solving continuous optimization problems [20] as well as combinatorial optimization problems [15, 37].", "startOffset": 116, "endOffset": 120}, {"referenceID": 19, "context": "This concept has been exploited also by the Artificial Bees Colony (ABC) algorithm proposed by Karaboga and Basturk [19] and achieved excellent results when solving continuous optimization problems [20] as well as combinatorial optimization problems [15, 37].", "startOffset": 198, "endOffset": 202}, {"referenceID": 14, "context": "This concept has been exploited also by the Artificial Bees Colony (ABC) algorithm proposed by Karaboga and Basturk [19] and achieved excellent results when solving continuous optimization problems [20] as well as combinatorial optimization problems [15, 37].", "startOffset": 250, "endOffset": 258}, {"referenceID": 35, "context": "This concept has been exploited also by the Artificial Bees Colony (ABC) algorithm proposed by Karaboga and Basturk [19] and achieved excellent results when solving continuous optimization problems [20] as well as combinatorial optimization problems [15, 37].", "startOffset": 250, "endOffset": 258}, {"referenceID": 17, "context": "[18] assert that an optimal memetic exploration of the search space is composed of three", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "Two local search methods were applied within the proposed memetic ABC (MABC) algorithm: the Nelder/Mead (NM) simplex method [35] and the random walk method with direction exploitation (RWDE) [35].", "startOffset": 124, "endOffset": 128}, {"referenceID": 33, "context": "Two local search methods were applied within the proposed memetic ABC (MABC) algorithm: the Nelder/Mead (NM) simplex method [35] and the random walk method with direction exploitation (RWDE) [35].", "startOffset": 191, "endOffset": 195}, {"referenceID": 8, "context": "The stochastic adaptive rule as specified by Neri [9] was applied for balancing the exploration and exploitation.", "startOffset": 50, "endOffset": 53}, {"referenceID": 8, "context": "In order to make a super-fit individual [9] that guides the direction in which the search space needs to be explored by the bee colony, an additional step is added to the original ABC algorithm, i.", "startOffset": 40, "endOffset": 43}, {"referenceID": 17, "context": "In the sense of MC analysis due to [18], each of these four functions perform certain exploration task, as follows:", "startOffset": 35, "endOffset": 39}, {"referenceID": 32, "context": "The stochastic long-distance exploration is performed in the DE fashion [34] as follows.", "startOffset": 72, "endOffset": 76}, {"referenceID": 28, "context": "In population-based algorithms, diversity plays a crucial role in the success of the optimization [29].", "startOffset": 98, "endOffset": 102}, {"referenceID": 13, "context": "The diversity of a population is a measure of the different solutions present [14].", "startOffset": 78, "endOffset": 82}, {"referenceID": 29, "context": "In this study, the fitness diversity metric is expressed as [30]:", "startOffset": 60, "endOffset": 64}, {"referenceID": 28, "context": "It is very sensible to small variations and thus, especially suitable for fitness landscapes containing plateaus and low gradient areas [29].", "startOffset": 136, "endOffset": 140}, {"referenceID": 27, "context": "The first is the Nelder-Mead Algorithm (NMA) [28] with exploration features and the second the Random Walk with Direction Exploitation (RWDE) [35] with exploitation features.", "startOffset": 45, "endOffset": 49}, {"referenceID": 33, "context": "The first is the Nelder-Mead Algorithm (NMA) [28] with exploration features and the second the Random Walk with Direction Exploitation (RWDE) [35] with exploitation features.", "startOffset": 142, "endOffset": 146}, {"referenceID": 21, "context": "Both values \u03bcp and \u03c3p are calculated incrementally in each generation according to the Knuth\u2019s algorithm [22].", "startOffset": 105, "endOffset": 109}, {"referenceID": 34, "context": "In contrast, the fully-nonseparable functions are usually the more difficult to solve [36].", "startOffset": 86, "endOffset": 90}, {"referenceID": 15, "context": "In order to check how significant these results are, the Friedman nonparametric test as proposed in [16] was performed with significant level \u03b1 = 0.", "startOffset": 100, "endOffset": 104}, {"referenceID": 0, "context": "[1] E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] F.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] T.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] F.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] Z.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] Z.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[27] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] F.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] F.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[32] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[33] Y.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[34] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[35] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[36] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "[37] M.", "startOffset": 0, "endOffset": 4}], "year": 2012, "abstractText": "Large-Scale Global Optimization Iztok Fister,\u2217 Iztok Fister Jr.,\u2020 Janez Brest,\u2021 and Viljem \u017dumer\u00a7 Abstract Memetic computation (MC) has emerged recently as a new paradigm of efficient algorithms for solving the hardest optimization problems. On the other hand, artificial bees colony (ABC) algorithms demonstrate good performances when solving continuous and combinatorial optimization problems. This study tries to use these technologies under the same roof. As a result, a memetic ABC (MABC) algorithm has been developed that is hybridized with two local search heuristics: the Nelder-Mead algorithm (NMA) and the random walk with direction exploitation (RWDE). The former is attended more towards exploration, while the latter more towards exploitation of the search space. The stochastic adaptation rule was employed in order to control the balancing between exploration and exploitation. This MABC algorithm was applied to a Special suite on Large Scale Continuous Global Optimization at the 2012 IEEE Congress on Evolutionary Computation. The obtained results the MABC are comparable with the results of DECC-G, DECC-G*, and MLCC. To cite paper as follows: I. Fister, I. Fister Jr., J. Brest, V. Zumer, Memetic Artificial Bee Colony Algorithm for Large-Scale Global Optimization, in Proc. IEEE Congress on Evolutionary Computation, Brisbane, Australia, 2012", "creator": "LaTeX with hyperref package"}}}