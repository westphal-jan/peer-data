{"id": "1206.4604", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Learning the Experts for Online Sequence Prediction", "abstract": "Online sequence prediction is the problem of predicting the next element of a sequence given previous elements. This problem has been extensively studied in the context of individual sequence prediction, where no prior assumptions are made on the origin of the sequence. Individual sequence prediction algorithms work quite well for long sequences, where the algorithm has enough time to learn the temporal structure of the sequence. However, they might give poor predictions for short sequences. A possible remedy is to rely on the general model of prediction with expert advice, where the learner has access to a set of $r$ experts, each of which makes its own predictions on the sequence. It is well known that it is possible to predict almost as well as the best expert if the sequence length is order of $\\log(r)$. But, without firm prior knowledge on the problem, it is not clear how to choose a small set of {\\em good} experts. In this paper we describe and analyze a new algorithm that learns a good set of experts using a training set of previously observed sequences. We demonstrate the merits of our approach by applying it on the task of click prediction on the web. The current paper describes the most recent search engine, the SOPA, which was first announced in 2012. It has been described as the most successful and most popular search engine.\n\n\n\nMethods of study\n\n\n\nThe study was initiated on a case-by-case basis in cooperation with the National Center for Online Statistics and other scientific agencies. In addition to this study, it involved using multiple search engines, with an active search engine that also uses a web-based search engine to search for information about new Internet sites and applications. In this particular study we present a set of search engines, each with a specific search engine, with different methods. This search engine includes several other methods.\nThe search engines are used in an order to identify the most recent search and to detect the most recent search for current Internet searches. We describe a set of search engines that uses the following algorithms.\nThe main search engine consists of:\nA search engine, which has two search engines of different sizes and multiple search engines of different sizes: the one for the search engine; the one for the search engine; and the one for the search engine. The search engine.\nAn additional search engine, which has two search engines of different sizes, as the search engine; the one for the search engine. The search engine.\nThe search engine.\nThe search engine.\nThe search engine.\nThe search", "histories": [["v1", "Mon, 18 Jun 2012 14:42:16 GMT  (174kb)", "http://arxiv.org/abs/1206.4604v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["elad eban", "aharon birnbaum", "shai shalev-shwartz", "amir globerson"], "accepted": true, "id": "1206.4604"}, "pdf": {"name": "1206.4604.pdf", "metadata": {"source": "META", "title": "Learning the Experts for Online Sequence Prediction", "authors": ["Elad Eban", "Aharon Birnbaum", "Shai Shalev-Shwartz", "Amir Globerson"], "emails": ["elade@cs.huji.ac.il", "aharob01@cs.huji.ac.il", "shais@cs.huji.ac.il", "gamir@cs.huji.ac.il"], "sections": [{"heading": "1. Introduction", "text": "Sequence prediction is a key task in machine learning and statistics. It involves predicting the next element in a sequence given the previous elements. Typical applications include stock market prediction, click prediction in web browsing and consumption predic-\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\ntion in smart grids. Although the sequence prediction problem has been well studied, current solutions either work for long sequences or require strong prior knowledge. In this work we provide a method that uses training data to learn how to predict a novel sequence. As we shall show, we use the training sequences to obtain the prior knowledge needed for predicting novel sequences.\nSequence prediction is most naturally cast as an online prediction problem (Cesa-Bianchi and Lugosi, 2006), where at every step we predict the next element, and then receive the true value of the element while suffering a loss if we made a prediction error. We are then allowed to improve the model, and predict the next step. The online formulation is natural in most applications since the new element\u2019s true value unfolds in real time and we are interested in minimizing the prediction loss of this process.\nOne classical approach to the problem is the so called universal sequence prediction class of methods (Feder et al., 1992; Hutter, 2006). Such methods guarantee that asymptotically (with sequence size) the model will achieve optimal prediction error. However, the price we pay for universality is that good performance will be reached only after seeing long sequences. Intuitively, the reason for this is that no prior knowledge about the sequence is used, so it may take a while until we have a good model of it.\nAn alternative approach which does introduce prior knowledge is predicting with expert advice (Littlestone and Warmuth, 1994; Vovk, 1990). Here one has a set of r experts, where each expert is a sequence predictor. The Weighted-Majority algorithm (Littlestone and Warmuth, 1994) uses such experts to do online prediction, and is guaranteed to perform almost as well as the best expert. More formally, for any sequence of length T , the average number of prediction mistakes of Weighted-Majority (WM ) is bounded above by the average number of prediction mistakes made by the best\nexpert plus \u221a log(r)/T . Thus, the WM algorithm will perform well when for every sequence there exists an expert that performs well on it and when the sequence is long enough.\nGiven the above, it\u2019s clear that learning from experts will work when the experts fit the sequences we want to predict. Thus a key question, which we address here, is how to choose a good set of experts. We propose to learn these experts from a set of training sequences. In the spirit of empirical risk minimization we shall seek a set of experts that perform well on our training set. This is a highly non-trivial task in our case due to several reasons. First, the performance of a pool of experts is measured by the performance of an online algorithm whose parameters are the experts, and it\u2019s not clear how to optimize this function. We shall see that the hindsight loss is a simpler function to optimize and results in comparable theoretical guarantees. Second, we would like our experts to use arbitrarily long histories in making predictions, but do so without over fitting. We shall show that this can be done by using a variant of context trees (a.k.a. prediction suffix trees). Finally, it\u2019s not clear what generalization guarantees, if any, can be expected from such a scheme. We perform a detailed generalization analysis, providing theoretical bounds on the sample complexity of learning a good set of experts.\nOur learning task is thus as follows: given a training set of sequences, learn a set of experts that will work well for online sequence prediction. In a sense, this can be viewed as a collaborative version of sequence prediction. We provide an objective that corresponds to this discriminative setting and analyze the generalization error of its minimizer. Our theoretical analysis provides generalization bounds that show no over fitting for longer histories, and quantify the advantage of learning in the collaborative setting.\nWe apply our model to synthetic and real-world problems and show that it outperforms methods which do not use temporal and collaborative approaches."}, {"heading": "2. Problem Formulation", "text": "Let \u03a3 be a finite alphabet. A sequence of symbols is a member of \u03a3\u2217 and is denoted by x = (x1, . . . , xT ). Online sequence prediction takes place in consecutive rounds. On round t, the forecaster observes the prefix x1:t\u22121 = (x1, . . . , xt\u22121) and predicts x\u0302t \u2208 \u03a3. Then, the next symbol, xt, is revealed and the forecaster pays 1[xt \u0338=x\u0302t]. That is, it pays 1 if xt \u0338= x\u0302t and 0 otherwise.\nAn \u201cexpert\u201d for sequence prediction is a function f : \u03a3\u2217 \u2192 \u03a3. Such an expert can be used for predicting\nthe t\u2019th symbol by setting x\u0302t = f(x1:t\u22121).\nGiven a set of r such experts, the Weighted-Majority (WM) algorithm (Littlestone andWarmuth, 1994) (see pseudocode below), can be used for predicting almost as well as the best expert.\nA performance guarantee for WM is provided in the following theorem (Littlestone and Warmuth, 1994).\nWeighted Majority (WM)\nparameter: \u03b7 > 0 initialize: w1 = (1/r, . . . , 1/r) for t = 1, 2, . . . , T choose i \u223c wt at random predict x\u0302t = fi(x1:t\u22121) update rule \u2200i, wt+1[i] \u221d wt[i]e\u2212\u03b71[fi(x1:t\u22121) \u0338=xt]\nTheorem 1 The Weighted Majority algorithm (with \u03b7 = \u221a log(r)/T ) obtains the following regret bound:\n1 T T\u2211 t=1 P[x\u0302t \u0338= xt] \u2264 min i 1 T T\u2211 t=1 1[fi(x1:t\u22121) \u0338=xt]+\n\u221a 4 log(r)\nT .\nIt follows that we can predict the sequence reasonably well if two conditions hold:\n1. log(r) is sufficiently small compared to T .\n2. At least one of the experts makes a small number of mistakes on the sequence.\nTherefore, when choosing a set of experts we face the classical bias-complexity tradeoff: On one hand we want r to be small enough so that the regret term\u221a log(r)/T will be small. On the other hand, different experts will work well on different sequences, and since we do not know the type of sequence we are going to get, we would like to increase r so that the set of experts will be rich enough to explain many types of sequences.\nIn this paper we propose to learn a good set of experts based on a sample of sequences. Formally, let H be a hypothesis class of experts. It is convenient to allow experts to output predictions from a set Y , where we have some way to convert an element from Y into a prediction in \u03a3. For example, we can use Y = R|\u03a3|, where we interpret the prediction y \u2208 Y as a score for each of the symbols in \u03a3. The mapping from a score vector in Y to an actual prediction in \u03a3 is via argmax\u03c3\u2208\u03a3 y\u03c3. Therefore, each f \u2208 H is a function from \u03a3\u2217 to Y . The loss of a prediction f(x1:t\u22121) is measured by a loss function \u2113 : Y \u00d7 \u03a3 \u2192 R. The loss\nfunction can be the 0-1 loss 1[xt \u0338=x\u0302t]. Later, we use other loss measures that are convex surrogates of the zero-one loss.\nThe problem that we consider in this paper can be formalized as follows: We are given a sample of sequences, S = (x(1), . . . ,x(m)), where each x(i) is assumed to be sampled i.i.d. from an unknown distribution D over \u03a3\u2217. Our goal is to use S for learning a set of experts, F \u2282 H, of size |F | \u2264 r, where r is a parameter of the learning problem (which should depend on the typical size of T ). We wish to learn F such that when running WM on a new sequence with the set F it will have a small number of mistakes.\nGiven an expert f and a sequence x, we denote by L(f,x) the average loss of f on x, specifically:\nL(f,x) = 1 T T\u2211 t=1 \u2113(f(x1:t\u22121), xt) .\nGiven a set of experts, F \u2282 H, we denote by WM(F,x) the averaged loss of applying the WM algorithm on the sequence x with the set of experts F . Therefore, our ultimate goal is to learn a set of experts F which (approximately) minimizes\nE x\u223cD [WM(F,x)] .\nBefore we describe how we learn F , let us first consider two extreme situations. First, for r = 1, i.e. F = {f}, then WM(F,x) = L(f,x). That is, at prediction time, we simply follow the predictions of the single expert f . This is exactly the standard traditional setting of statistical batch learning, where we would like to learn a model f from a hypothesis classH whose expected loss over a randomly chosen example (in our case x \u223c D) is as small as possible. The problem with this approach is that it might be the case that the sequences are of different types, where no single expert from H is able to accurately predict all of the sequences. On the other extreme, if we set r = \u221e, i.e. F = H, then we revert to the problem of online learning with a hypothesis class H. The problem with this approach is that if H is \u201ccomplex\u201d,1 then the sequence length required in order to guarantee good performance of the online learning might be very large."}, {"heading": "3. The Learning Algorithm", "text": "A straightforward approach for learning F when r > 1 is to follow the empirical risk minimization (ERM)\n1As measured, for example, by its Littlestone dimension (Ben-David et al., 2009).\nprinciple, namely, to solve the optimization problem\nmin F\u2282H:|F |=r 1 m m\u2211 i=1 WM(F,x(i)) .\nThis problem might be difficult to optimize since the objective function involves the activation of an algorithm and does not have a simple mathematical formulation. To overcome this difficulty, we show how a simpler objective may be used. In light of Theorem 1 (generalized to convex surrogate losses) we know that for any sequence x,\nWM(F,x) \u2264 min f\u2208F L(f,x) +\n\u221a 4 log(|F |)\nT . (1)\nLet us slightly overload notation and denote\nL(F,x) = min f\u2208F L(f,x) .\nThus L(F,x) is the hindsight loss when learning the sequence x with experts F . Taking expectation of both sides of Eq. 1 we obtain that\nE x\u223cD [WM(F,x)] \u2264 E x\u223cD [L(F,x)] + E x\u223cD\n\u221a 4 log(|F |)\nT .\n(2)\nThe second summand only depends on F via its size. Therefore, for a fixed size of F , we can follow a standard bound minimization approach and aim at minimizing Ex\u223cD[L(F,x)] instead of Ex\u223cD[WM(F,x)]. In other words, we minimize the hindsight loss instead of the online loss. An ERM approach to this minimization yields the following minimization problem on the training set of sequences:\nmin F\u2282H:|F |=r 1 m m\u2211 i=1 L(F,x(i)) . (3)\nBy definition of L(F,x), this can be written equivalently as\nmin f1,...,fr\u2208H 1 m m\u2211 i=1 min w\u2208\u2206r r\u2211 j=1 wjL(fj ,x(i)) (4)\nwhere \u2206r = {w \u2208 Rr : w \u2265 0, \u2225w\u22251 = 1}.\nAssuming that H can be encoded as a convex set and L(f,x) is a convex function,2 we obtain that the objective of Eq. 4 is convex in f1, . . . , fr and w(1), . . . ,w(r) individually but not jointly. This suggests an alternating optimization scheme where one alternates between\n2This will be the case for the class H and loss function we use in Section 3.1\noptimizing over w\u2019s and over f \u2019s. This scheme is especially attractive since minimizing over w for fixed F is straightforward: for each sequence x(i) find the best expert and set w(i) to 1 for that expert and 0 otherwise. Optimizing fi for fixed w can be done via gradient descent when using a smooth loss as we do here (see Sections 3.1 and 3.2)."}, {"heading": "3.1. The class of bounded norm context trees", "text": "Thus far we have given a general scheme and have not described the particular set of experts we will use. In what follows we specify those. Any function f : \u03a3\u2217 \u2192 \u03a3 can be described using a multiclass context tree. For our experts, we will be using a generalization of multiclass context trees following Dekel et al. (2010), described below.\nTo simplify notation, denote \u03a3 = [k] = {1, . . . , k}. A multiclass context-tree is a k-ary rooted tree, where each node of the tree is associated with a vector z \u2208 Rk. The prediction of the tree on a sequence x1:t\u22121 is determined as follows. We initially start with the vector z = 0 \u2208 Rk, and set the current node to be the root of the tree. We then add to z the vector associated with the current node and traverse to its xt\u22121 child, which becomes the current node. We add again the vector associated with the current node and traverse to its xt\u22122 child. This process is repeated until we arrive either to x1 or to a leaf of the tree. The final value of z gives a score value to each of the elements in \u03a3, and the actual prediction is argmaxi zi.\nIt is convenient to represent a context tree as a matrix with k rows as follows. Let us order the nodes of a full k-ary tree in a breadth first manner. For simplicity, we restrict ourselves to trees of bounded depth (which can be very large, so this is not a serious limitation). To represent a context tree as a matrix, we set column i of the matrix to be the vector associated with the i\u2019th node of the tree (where if the node does not exist in the tree we simply set the column to be the all zeros vector). Similarly, we can map a sequence x1:t\u22121 to a vector \u03c8(x1:t\u22121) \u2208 {0, 1}|\u03a3\n\u2217| as follows. Suppose that we traverse from the root of a full k-ary tree according to the symbols xt\u22121, xt\u22122, . . . , x1, as we described before. Then, we set all the coordinates of \u03c8(x1:t\u22121) corresponding to nodes we visited in this path to be 1, and set all the rest of the coordinates to be zero.\nIt is easy to verify that the vector z constructed by a context tree for the history x1:t\u22121 is U\u03c8(x1:t\u22121), where U is the matrix describing the context tree (the size of U is thus |\u03a3|\u00d7|\u03a3\u2217| and the columns correspond to the vectors z at each node).\nAs mentioned before, any function f : \u03a3\u2217 \u2192 \u03a3 can be described by a context tree (as long as we allow its depth to be large enough). Therefore, without additional constraints, learning the class of all context trees from a finite sample will lead to over-fitting. To overcome this, one can constrain the depth of the tree. Alternatively, we can allow any depth but carefully discount long histories as described next.\nFollowing (Dekel et al., 2010), we aim to balance between long histories (can be very informative but are rare in the data hence are hard to learn) and short histories (less informative but easier to learn). This can be done by defining a norm over matrices corresponding to context trees, where longer histories are penalized more. Formally, for each column i of a context tree matrix U, let d(i) be the depth of its corresponding node in the tree. Let a1 \u2265 a2 \u2265 . . . be a sequence such that \u2211\u221e i=1 ai \u2264 1.3 Then, we define a norm of vectors to be such that\n\u2225u\u22252 = \u2211 i ad(i)u 2 i , (5)\nand a norm over matrices to be \u2225U\u22252 = \u2211\nj \u2225Uj\u22252, where Uj is the j\u2019th row of U. Put another way, the squared norm of U is a weighted sum of the squared Euclidean norms of columns of U, where the weight of column i is ad(i). Thus, we assign a higher penalty to columns corresponding to deep nodes of the trees.\nConsequently, we define the hypothesis class of bounded norm context trees to be\nHB = {U : \u2225U\u2225 \u2264 B} . (6)\nFinally, we also need to define scale sensitive loss functions. A common choice is the multiclass log-loss:\n\u2113(z, y) = log ( \u2211\ny\u2032\u2208\u03a3 exp\n( 1[y\u2032 \u0338=y] \u2212 zy + zy\u2032 )) .\nThis loss function has the advantages of being a convex surrogate loss for the zero-one loss."}, {"heading": "3.2. The LEX algorithm", "text": "We are now ready to describe our algorithm, which we call LEX (for Learning Experts). Our goal is to minimize the loss in Eq. 4 with respect to the vectors wi and the parameters of the experts. As described in Section 3.1, we parameterize each expert by a context tree matrix U \u2208 Rk \u00d7 |\u03a3\u2217|. As mentioned earlier, we can minimize Eq. 4 via alternating optimization where minimizing over w can be done in closed form\n3Here we take ai = i \u22122.\nand minimizing over U can be done with gradient descent. Calculating the gradient w.r.t. U is easy for the log loss. In our implementation we use stochastic gradient descent, where an update is performed after each training sequence is processed."}, {"heading": "4. Analysis", "text": "Define the generalization loss for the set of experts F :\nLD(F ) = E x\u223cD L(F,x) .\nIn light of Eq. 2, in order to bound Ex[WM(F,x)] it suffices to bound LD(F ). In this section we derive bounds on LD(F ). Our bounds depend on the following measures: the number of experts |F |, a complexity measure of the hypothesis class H, the number of training examples, and the training loss:\nLS(F ) = 1 |S| \u2211 x\u2208S L(F,x) .\nWe first define a complexity measure for a hypothesis class H with respect to a loss function \u2113.\nDefinition 1 Let H be a class of functions from Z to Q, let Y be a target set, and let \u2113 : Q\u00d7Y \u2192 R be a loss function. We say that the complexity of H is C(H) if for any sequence (z1, y1), . . . , (zq, yq) \u2208 (Z \u00d7 Q)q and for any \u03f5 > 0, there exists H\u2032 \u2282 H of size |H\u2032| \u2264 (2q)C(H)/\u03f5 2 , such that for all h \u2208 H exists h\u2032 \u2208 H\u2032 that satisfies\n\u2200i \u2208 [q], |\u2113(h(zi), yi)\u2212 \u2113(h\u2032(zi), yi)| \u2264 \u03f5 .\nThe reader familiar with covering number bounds can easily recognize C(H) as determining the size of a cover of H. It is also easy to verify that if H is a class of binary classifiers then C(H) is upper bounded by the VC dimension of H (this follows directly from Sauer\u2019s lemma). We will later show that the class of bounded norm context trees has a bounded C(H) as well.\nTheorem 2 Let D be a probability over \u03a3\u2217 such that there exists some constant T with P[len(x) \u2264 T ] = 1. Assume also that for all x and F \u2282 H we have L(F,x) \u2208 [0, \u221a C(H)]. Then, with probability of at least 1\u2212 \u03b4 over S \u223c Dm, for all F \u2282 H, with |F | = r, we have\nLD(F ) \u2264 LS(F ) + O\u0303\n(\u221a r C(H)\nm\n) .\nThe above theorem tells us that if H is of bounded complexity, then the number of samples required to\nhave LD(F ) \u2264 LS(F ) + \u03f5 is order of r C(H)/\u03f52. In particular, the sample complexity of learning a set of r experts is r times larger than the sample complexity of learning a single expert.\nThe proof of the theorem is given in the long version of this article. The main ideas of the proof are as follows. First, we construct a cover for the loss class {x 7\u2192 L(F,x) : F \u2282 H, |F | = r}. Then, we bound the Rademacher complexity of this class using a generalization of Dudley\u2019s chaining technique, which is similar to a technique recently proposed in Srebro et al. (2010).\nNext, we turn our attention to the specific class of context trees with bounded norm. The following lemma bounds its complexity.\nLemma 1 Let HB be the class of multiclass context trees which maps \u03a3\u2217 into R|\u03a3| as defined in Section 3.1. Let \u2113 : R|\u03a3| \u00d7 \u03a3 \u2192 R be a loss function such that\n\u2200l \u2208 \u03a3, u, v \u2208 R|\u03a3|, |\u2113(u, l)\u2212 \u2113(v, l)| \u2264 \u2225u\u2212 v\u2225\u221e .\nThen: C(HB) \u2264 O(B2 log(k)).\nThe proof of the lemma is given in the long version of this article. The main idea is a nice trick showing how to bound the cover of a linear class based on known bounds on the convergence rate of sub-gradient mirror descent algorithms (e.g., see Nemirovski and Yudin, 1978). This is similar to a method due to Zhang (2002), although our bound is slightly better.\nThe multiclass log-loss function satisfies the conditions of the above lemma, hence:\nCorollary 1 Let HB be the class of multiclass context trees and let \u2113 be the multiclass log-loss. Let D be a probability over \u03a3\u2217 such that there exists some constant T with P[len(x) \u2264 T ] = 1. Then, with probability of at least 1\u2212\u03b4 over S \u223c Dm, for all F \u2282 HB, with |F | = r, we have\nLD(F ) \u2264 LS(F ) + O\u0303\n(\u221a r B2\nm\n) .\nIn summary, if we manage to find a set F \u2282 HB of size r that achieves a small hindsight training loss, then it will also achieve a small hindsight generalization loss. Combining this with Eq. 2 yields\nE[WM(F,x)] \u2264 LS(F )+ O\u0303\n(\u221a r B2\nm\n) +E \u221a 4 log(r)\nT .\nTherefore, the performance of the Weighted-Majority algorithm is upper bounded by three terms: The training loss of F (which can decrease when increasing r),\nthe estimation error term (which increases with r), and the online regret term (which also increases with r)."}, {"heading": "5. Related Work", "text": "The problem of sequence prediction has a fairly long history and has received much attention from game theorists (Robbins, 1951; Blackwell, 1956; Hannan, 1957), information theorists (Cover and Hart, 1967; Cover and Shenhar, 1977; Feder et al., 1992; Willems et al., 1995), and machine learning researchers (Helmbold and Schapire, 1997; Pereira and Singer, 1999; Cesa-Bianchi and Lugosi, 2006; Dekel et al., 2010). One of the most useful tools is context trees, which store informative histories and the probability of the next symbol given these. However, all of these works consider predicting a sequence from a single source. Indeed, our work extends these single sequence predictions to the collaborative setting where we model different sequences, but constrain the predictors to share some common structure (i.e., the experts used in prediction).\nAnother related line of work is multitask prediction (e.g., see Ando and Zhang, 2005; Abernethy et al., 2007), in which one considers several different multiclass prediction problems and seeks a common feature space for those. This setting is different from ours in several ways. First, in the multitask setting one receives a set of training instances from each task, where it is known which sample belongs to each class. In our case, we receive only a set of individual sequences. Furthermore, in the multitask setting, the test data comes from one of the known tasks, whereas we again receive a novel sequence from an unknown source.\nA more recent approach to sequence modeling is the \u201csequence memoizer\u201d, which is based on nonparametric Bayesian models (Wood et al., 2009). So far these have been applied to a single type model (e.g., language modeling), and not for multiple distinct models as we have here. It is conceivable that a fully Bayesian model for collaborative sequence prediction can be built using these models, and it would be interesting to contrast it with our approach.\nAnother possible approach to the problem is to use probabilistic latent variable models (Hofmann, 1999) or their discriminative counterparts (Felzenszwalb et al., 2008; Yu and Joachims, 2009). Here each sequence will be mapped to a latent variable corresponding to the best expert. Next, given the class and the previous history, a probabilistic suffix tree will be used to generate the next action. However, such a model will not handle long histories appropriately and\nis likely to result in overfitting (as our empirical results also show). While it may be possible to add history discounting to such a model, it will be considerably more complex than what we suggest here.\nIn our formulation, the state space \u03a3 is unstructured. There are cases of interest, where \u03a3 has structure. For example, it may correspond to the items in an online shopping basket. Prediction in such a setting was recently addressed in Rendle et al. (2010). Unlike in our case, they have access to multiple training sequences from particular users, and prediction is done on these users. Furthermore, the temporal model itself is only first order and thus very different from ours. Note that we can easily extend our approach to structured state spaces by using structured prediction instead of multiclass as we do here."}, {"heading": "6. Experiments", "text": "In what follows, we evaluate the performance of the LEX algorithm (see Section 3.2) on two datasets: synthetic and real-world. We compare it to the baselines described below."}, {"heading": "6.1. Baselines Models", "text": "We consider three different baselines models. The first is our LEX algorithm with r = 1 (we denote this baseline by 1-LEX), which is in fact a batch trained PST (where training uses the log loss). In this approach all training sequences are modeled via a single PST corresponding to one expert. It thus does not directly model multiple temporal behaviors of the sequences in the data.\nOur second baseline is an online PST model which is evaluated on each test sequence individually. Training is done using the algorithm in (Dekel et al., 2010). Being an online algorithm, it does not use the training data. However, given long enough sequences it will be able to model any deterministic temporal behavior optimally. In other words, this algorithm has the benefit of adaptation but its performance crucially depends on the length of the sequence. We denote this baseline by Online PST.\nFinally, we consider a generative latent variable model (denoted by LMM) which is a mixture of Markov chains. An order d Markov chain is a basic yet powerful tool for modeling sequences. In LMM we generalize Markov chains by allowing each sequence to be generated by one of r regular Markov models. We think of these r models as different chain types similarly to the r experts of LEX. Specifically, for a sequence x1, . . . xt\u22121 the r-LMM model of order d is defined by:\nPr(xt|x1:t\u22121) def= \u2211r q=1 P(xt|xt\u2212d:t\u22121, z = q)P(z = q) Where z is the latent (unobserved) variable which \u201dassigns\u201c a chain type to a sequence. Note that the standard Markov chain is simply a 1-LMM. We learn the parameters of a LMM from training data using EM. The (online) prediction using this model is done by the maximum a-posteriori assignment at each point in time. Since LMM does not discount long histories, it is not expected to perform well when d is large and not enough training data is available. Parameters for all algorithms (i.e., r and d) were tuned using cross validation."}, {"heading": "6.2. Synthetic Data", "text": "We begin by considering sequences that follow one of two temporal patterns. The sequences are generated as follows: First randomly select j \u2208 {1, 2} then draw T samples according to the (independent) distribution:\nPr(xt = x) = { 2\u22121 if x = j (2(|\u03a3| \u2212 1))\u22121 otherwise . We used\n|\u03a3| = 200 and generated a set of m = 1000 sequences, each of length T = 250 (these parameters where selected to resemble the browsing data characteristics). We note that by construction, the maximal possible generalization accuracy on this data is 0.5. We evaluate the accuracy of online prediction on 400 test sequences.\nIn Fig. 1 we show the accuracy (on test data) of LEX and the three baselines. We notice that LEX approaches 0.5 accuracy using about 50 sequences, 1-LEX and LMM require substantially more samples in order to approach this performance (over 500 sequences for 0.45 accuracy). In other words, in agreement with our theoretical analysis, the sample complexity of LEX is smaller than both 1-LEX and LMM. The accuracy of online PST is much lower\ndue to the conservative training of this algorithm."}, {"heading": "6.3. Click Prediction Data", "text": "Here we consider a challenging task of predicting the browsing pattern of web users. Specifically, we use browsing logs for users in an intra-net site. For each session the sequence of urls visited by every user was recorded by the web server. The dataset contains 2000 such sequences of length 70-150. The domain of the prediction problem, is of distinct urls and its magnitude is |\u03a3| = 189. The data was split into train, validation and test sets, the sizes of the training sets vary, while the validation and test set sizes were fixed at 200 and 800 sequences respectively. We applied the three baseline models, and compared their performance to LEX. In this experiment the r experts learned by LEX were combined with an additional expert obtained from training a 1-LEX algorithm, resulting in a pool of r+1 learned experts. This addition smoothes performance on short sequences where the WM algorithm might not have enough time to decide which of the r experts to follow.\nResults are shown in Fig. 2. It can be seen that LEX outperforms the other methods. When considering the difference in accuracy between LEX and 1-LEX we notice that the added accuracy from multiple experts shrinks as training size increases. This trend agrees with theory, since as more data is available to 1-LEX, it can use longer histories and eventually will be able to model any temporal behavior. However, as we show in the synthetic experiments, the gap for small data sizes can be considerable."}, {"heading": "7. Discussion", "text": "We have described and analyzed a method for learning the experts for online sequence prediction. In particular, we specified it to the class of prediction suffix trees. Thus, our experts can capture dependencies on arbitrarily long histories. This is achieved by mapping context trees into a vector space and designing a norm on this space which discounts long histories. As our generalization results show, the complexity of the model is not penalized by the maximal possible length of histories (dimensionality of the matrix U) but rather by the effective needed context based history (captured by the norm of U). Our empirical results show that temporal user specific structure can indeed be used to improve prediction accuracy.\nThe proposed approach can be extended in several ways. First, we can consider different prediction goals: instead of predicting the next symbol in the sequence, corresponding to the next URL, we can have a binary classifier that returns one if a user is likely to take a given action and zero otherwise. Alternatively, we can consider a ranking task where we want to sort actions according to their interest to the user. To use such objectives we will just need to replace our multiclass log loss with the corresponding loss.\nFinally, we note that our model can be applied to a wide array of practical problems. Some examples are ad placements, course enrollment systems, and enhanced user interface automation.\nAcknowledgements: This research is supported by the HP Labs Innovation Research Program."}, {"heading": "R. K. Ando and T. Zhang. A framework for learning predictive structures from multiple tasks and unlabeled data.", "text": "JMLR, 6:1817\u20131853, 2005."}, {"heading": "S. Ben-David, D. Pa\u0301l, and S. Shalev-Shwartz. Agnostic", "text": "online learning. In COLT, 2009."}, {"heading": "D. Blackwell. An analog of the minimax theorem for vector", "text": "payoffs. Pacific Journal of Math., 6(1):1\u20138, 1956.\nN. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games. Cambridge University Press, 2006.\nT. Cover and P. Hart. Nearest neighbor pattern classification. IEEE Trans. on Information Theory, IT-13(1): 21\u201327, Jan. 1967."}, {"heading": "T. Cover and A. Shenhar. Compound Bayes predictors", "text": "for sequences with apparent Markov structure. IEEE Transactions on Systems, Man, and Cybernetics, SMC7(6):421\u2013424, June 1977."}, {"heading": "O. Dekel, S. Shalev-Shwartz, and Y. Singer. Individual sequence prediction using memory-efficient context trees.", "text": "IEEE Trans. on Information Theory, 2010.\nM. Feder, N. Merhav, and M. Gutman. Universal prediction of individual sequences. IEEE Trans. on Information Theory, 38:1258\u20131270, 1992."}, {"heading": "P. F. Felzenszwalb, D. A. McAllester, and D. Ramanan.", "text": "A discriminatively trained, multiscale, deformable part model. In CVPR, 2008."}, {"heading": "J. Hannan. Approximation to Bayes risk in repeated play.", "text": "In M. Dresher, A. W. Tucker, and P. Wolfe, editors, Contributions to the Theory of Games, volume III, pages 97\u2013139. 1957."}, {"heading": "D. P. Helmbold and R. E. Schapire. Predicting nearly as", "text": "well as the best pruning of a decision tree. Machine Learning, 27(1):51\u201368, Apr. 1997."}, {"heading": "T. Hofmann. Probabilistic latent semantic analysis. In", "text": "Proc. of Uncertainty in Artificial Intelligence, 1999.\nM. Hutter. On the foundations of universal sequence prediction. Theory and Applications of Models of Computation, pages 408\u2013420, 2006."}, {"heading": "N. Littlestone and M. K. Warmuth. The weighted majority", "text": "algorithm. Information and Computation, 108:212\u2013261, 1994.\nA. Nemirovski and D. Yudin. Problem complexity and method efficiency in optimization. Nauka Publishers, Moscow, 1978."}, {"heading": "F. Pereira and Y. Singer. An efficient extension to mixture", "text": "techniques for prediction and decision trees. Machine Learning, 36(3):183\u2013199, 1999.\nS. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. Factorizing personalized markov chains for next-basket recommendation. In Inter. Conf. on WWW, pages 811\u2013820, 2010.\nH. Robbins. Asymptotically subminimax solutions of compound statistical decision problems. In Proceedings of the 2nd Berkeley symposium on mathematical statistics and probability, pages 131\u2013148, 1951.\nN. Srebro, K. Sridharan, and A. Tewari. Smoothness, lownoise and fast rates. NIPS, 2010.\nV. G. Vovk. Aggregating strategies. In COLT, 1990.\nF. Willems, Y. Shtarkov, and T. Tjalkens. The contexttree weighting method: basic properties. IEEE Trans. on Information Theory, 41(3):653 \u2013664, 1995."}, {"heading": "F. Wood, C. Archambeau, J. Gasthaus, L. James, and", "text": "Y. W. Teh. A stochastic memoizer for sequence data. In ICML, pages 1129\u20131136, 2009.\nC.-N. J. Yu and T. Joachims. Learning structural svms with latent variables. In ICML, 2009."}, {"heading": "T. Zhang. Covering number bounds of certain regularized", "text": "linear function classes. Journal of Machine Learning Research, 2:527\u2013550, 2002."}], "references": [{"title": "Multitask learning with expert advice", "author": ["J. Abernethy", "P. Bartlett", "A. Rakhlin"], "venue": "In COLT,", "citeRegEx": "Abernethy et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Abernethy et al\\.", "year": 2007}, {"title": "A framework for learning predictive structures from multiple tasks and unlabeled data", "author": ["R.K. Ando", "T. Zhang"], "venue": "JMLR, 6:1817\u20131853,", "citeRegEx": "Ando and Zhang.,? \\Q2005\\E", "shortCiteRegEx": "Ando and Zhang.", "year": 2005}, {"title": "Agnostic online learning", "author": ["S. Ben-David", "D. P\u00e1l", "S. Shalev-Shwartz"], "venue": "In COLT,", "citeRegEx": "Ben.David et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 2009}, {"title": "An analog of the minimax theorem for vector payoffs", "author": ["D. Blackwell"], "venue": "Pacific Journal of Math.,", "citeRegEx": "Blackwell.,? \\Q1956\\E", "shortCiteRegEx": "Blackwell.", "year": 1956}, {"title": "Prediction, learning, and games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Nearest neighbor pattern classification", "author": ["T. Cover", "P. Hart"], "venue": "IEEE Trans. on Information Theory,", "citeRegEx": "Cover and Hart.,? \\Q1967\\E", "shortCiteRegEx": "Cover and Hart.", "year": 1967}, {"title": "Compound Bayes predictors for sequences with apparent Markov structure", "author": ["T. Cover", "A. Shenhar"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics,", "citeRegEx": "Cover and Shenhar.,? \\Q1977\\E", "shortCiteRegEx": "Cover and Shenhar.", "year": 1977}, {"title": "Individual sequence prediction using memory-efficient context trees", "author": ["O. Dekel", "S. Shalev-Shwartz", "Y. Singer"], "venue": "IEEE Trans. on Information Theory,", "citeRegEx": "Dekel et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dekel et al\\.", "year": 2010}, {"title": "Universal prediction of individual sequences", "author": ["M. Feder", "N. Merhav", "M. Gutman"], "venue": "IEEE Trans. on Information Theory,", "citeRegEx": "Feder et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Feder et al\\.", "year": 1992}, {"title": "A discriminatively trained, multiscale, deformable part model", "author": ["P.F. Felzenszwalb", "D.A. McAllester", "D. Ramanan"], "venue": "In CVPR,", "citeRegEx": "Felzenszwalb et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2008}, {"title": "Approximation to Bayes risk in repeated play", "author": ["J. Hannan"], "venue": "Contributions to the Theory of Games,", "citeRegEx": "Hannan.,? \\Q1957\\E", "shortCiteRegEx": "Hannan.", "year": 1957}, {"title": "Predicting nearly as well as the best pruning of a decision tree", "author": ["D.P. Helmbold", "R.E. Schapire"], "venue": "Machine Learning,", "citeRegEx": "Helmbold and Schapire.,? \\Q1997\\E", "shortCiteRegEx": "Helmbold and Schapire.", "year": 1997}, {"title": "Probabilistic latent semantic analysis", "author": ["T. Hofmann"], "venue": "In Proc. of Uncertainty in Artificial Intelligence,", "citeRegEx": "Hofmann.,? \\Q1999\\E", "shortCiteRegEx": "Hofmann.", "year": 1999}, {"title": "On the foundations of universal sequence prediction", "author": ["M. Hutter"], "venue": "Theory and Applications of Models of Computation,", "citeRegEx": "Hutter.,? \\Q2006\\E", "shortCiteRegEx": "Hutter.", "year": 2006}, {"title": "The weighted majority algorithm", "author": ["N. Littlestone", "M.K. Warmuth"], "venue": "Information and Computation,", "citeRegEx": "Littlestone and Warmuth.,? \\Q1994\\E", "shortCiteRegEx": "Littlestone and Warmuth.", "year": 1994}, {"title": "Problem complexity and method efficiency in optimization", "author": ["A. Nemirovski", "D. Yudin"], "venue": "Nauka Publishers,", "citeRegEx": "Nemirovski and Yudin.,? \\Q1978\\E", "shortCiteRegEx": "Nemirovski and Yudin.", "year": 1978}, {"title": "An efficient extension to mixture techniques for prediction and decision trees", "author": ["F. Pereira", "Y. Singer"], "venue": "Machine Learning,", "citeRegEx": "Pereira and Singer.,? \\Q1999\\E", "shortCiteRegEx": "Pereira and Singer.", "year": 1999}, {"title": "Factorizing personalized markov chains for next-basket recommendation", "author": ["S. Rendle", "C. Freudenthaler", "L. Schmidt-Thieme"], "venue": "In Inter. Conf. on WWW,", "citeRegEx": "Rendle et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rendle et al\\.", "year": 2010}, {"title": "Asymptotically subminimax solutions of compound statistical decision problems", "author": ["H. Robbins"], "venue": "In Proceedings of the 2nd Berkeley symposium on mathematical statistics and probability,", "citeRegEx": "Robbins.,? \\Q1951\\E", "shortCiteRegEx": "Robbins.", "year": 1951}, {"title": "Smoothness, lownoise and fast rates", "author": ["N. Srebro", "K. Sridharan", "A. Tewari"], "venue": null, "citeRegEx": "Srebro et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2010}, {"title": "Aggregating strategies", "author": ["V.G. Vovk"], "venue": "In COLT,", "citeRegEx": "Vovk.,? \\Q1990\\E", "shortCiteRegEx": "Vovk.", "year": 1990}, {"title": "The contexttree weighting method: basic properties", "author": ["F. Willems", "Y. Shtarkov", "T. Tjalkens"], "venue": "IEEE Trans. on Information Theory,", "citeRegEx": "Willems et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Willems et al\\.", "year": 1995}, {"title": "A stochastic memoizer for sequence data", "author": ["F. Wood", "C. Archambeau", "J. Gasthaus", "L. James", "Y.W. Teh"], "venue": "In ICML,", "citeRegEx": "Wood et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Wood et al\\.", "year": 2009}, {"title": "Learning structural svms with latent variables", "author": ["C.-N.J. Yu", "T. Joachims"], "venue": "In ICML,", "citeRegEx": "Yu and Joachims.,? \\Q2009\\E", "shortCiteRegEx": "Yu and Joachims.", "year": 2009}, {"title": "Covering number bounds of certain regularized linear function classes", "author": ["T. Zhang"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Zhang.,? \\Q2002\\E", "shortCiteRegEx": "Zhang.", "year": 2002}], "referenceMentions": [{"referenceID": 4, "context": "Sequence prediction is most naturally cast as an online prediction problem (Cesa-Bianchi and Lugosi, 2006), where at every step we predict the next element, and then receive the true value of the element while suffering a loss if we made a prediction error.", "startOffset": 75, "endOffset": 106}, {"referenceID": 8, "context": "One classical approach to the problem is the so called universal sequence prediction class of methods (Feder et al., 1992; Hutter, 2006).", "startOffset": 102, "endOffset": 136}, {"referenceID": 13, "context": "One classical approach to the problem is the so called universal sequence prediction class of methods (Feder et al., 1992; Hutter, 2006).", "startOffset": 102, "endOffset": 136}, {"referenceID": 14, "context": "An alternative approach which does introduce prior knowledge is predicting with expert advice (Littlestone and Warmuth, 1994; Vovk, 1990).", "startOffset": 94, "endOffset": 137}, {"referenceID": 20, "context": "An alternative approach which does introduce prior knowledge is predicting with expert advice (Littlestone and Warmuth, 1994; Vovk, 1990).", "startOffset": 94, "endOffset": 137}, {"referenceID": 14, "context": "The Weighted-Majority algorithm (Littlestone and Warmuth, 1994) uses such experts to do online prediction, and is guaranteed to perform almost as well as the best expert.", "startOffset": 32, "endOffset": 63}, {"referenceID": 14, "context": "A performance guarantee for WM is provided in the following theorem (Littlestone and Warmuth, 1994).", "startOffset": 68, "endOffset": 99}, {"referenceID": 2, "context": "As measured, for example, by its Littlestone dimension (Ben-David et al., 2009).", "startOffset": 55, "endOffset": 79}, {"referenceID": 7, "context": "For our experts, we will be using a generalization of multiclass context trees following Dekel et al. (2010), described below.", "startOffset": 89, "endOffset": 109}, {"referenceID": 7, "context": "Following (Dekel et al., 2010), we aim to balance between long histories (can be very informative but are rare in the data hence are hard to learn) and short histories (less informative but easier to learn).", "startOffset": 10, "endOffset": 30}, {"referenceID": 19, "context": "Then, we bound the Rademacher complexity of this class using a generalization of Dudley\u2019s chaining technique, which is similar to a technique recently proposed in Srebro et al. (2010).", "startOffset": 163, "endOffset": 184}, {"referenceID": 15, "context": ", see Nemirovski and Yudin, 1978). This is similar to a method due to Zhang (2002), although our bound is slightly better.", "startOffset": 6, "endOffset": 83}, {"referenceID": 18, "context": "The problem of sequence prediction has a fairly long history and has received much attention from game theorists (Robbins, 1951; Blackwell, 1956; Hannan, 1957), information theorists (Cover and Hart, 1967; Cover and Shenhar, 1977; Feder et al.", "startOffset": 113, "endOffset": 159}, {"referenceID": 3, "context": "The problem of sequence prediction has a fairly long history and has received much attention from game theorists (Robbins, 1951; Blackwell, 1956; Hannan, 1957), information theorists (Cover and Hart, 1967; Cover and Shenhar, 1977; Feder et al.", "startOffset": 113, "endOffset": 159}, {"referenceID": 10, "context": "The problem of sequence prediction has a fairly long history and has received much attention from game theorists (Robbins, 1951; Blackwell, 1956; Hannan, 1957), information theorists (Cover and Hart, 1967; Cover and Shenhar, 1977; Feder et al.", "startOffset": 113, "endOffset": 159}, {"referenceID": 5, "context": "The problem of sequence prediction has a fairly long history and has received much attention from game theorists (Robbins, 1951; Blackwell, 1956; Hannan, 1957), information theorists (Cover and Hart, 1967; Cover and Shenhar, 1977; Feder et al., 1992; Willems et al., 1995), and machine learning researchers (Helmbold and Schapire, 1997; Pereira and Singer, 1999; Cesa-Bianchi and Lugosi, 2006; Dekel et al.", "startOffset": 183, "endOffset": 272}, {"referenceID": 6, "context": "The problem of sequence prediction has a fairly long history and has received much attention from game theorists (Robbins, 1951; Blackwell, 1956; Hannan, 1957), information theorists (Cover and Hart, 1967; Cover and Shenhar, 1977; Feder et al., 1992; Willems et al., 1995), and machine learning researchers (Helmbold and Schapire, 1997; Pereira and Singer, 1999; Cesa-Bianchi and Lugosi, 2006; Dekel et al.", "startOffset": 183, "endOffset": 272}, {"referenceID": 8, "context": "The problem of sequence prediction has a fairly long history and has received much attention from game theorists (Robbins, 1951; Blackwell, 1956; Hannan, 1957), information theorists (Cover and Hart, 1967; Cover and Shenhar, 1977; Feder et al., 1992; Willems et al., 1995), and machine learning researchers (Helmbold and Schapire, 1997; Pereira and Singer, 1999; Cesa-Bianchi and Lugosi, 2006; Dekel et al.", "startOffset": 183, "endOffset": 272}, {"referenceID": 21, "context": "The problem of sequence prediction has a fairly long history and has received much attention from game theorists (Robbins, 1951; Blackwell, 1956; Hannan, 1957), information theorists (Cover and Hart, 1967; Cover and Shenhar, 1977; Feder et al., 1992; Willems et al., 1995), and machine learning researchers (Helmbold and Schapire, 1997; Pereira and Singer, 1999; Cesa-Bianchi and Lugosi, 2006; Dekel et al.", "startOffset": 183, "endOffset": 272}, {"referenceID": 11, "context": ", 1995), and machine learning researchers (Helmbold and Schapire, 1997; Pereira and Singer, 1999; Cesa-Bianchi and Lugosi, 2006; Dekel et al., 2010).", "startOffset": 42, "endOffset": 148}, {"referenceID": 16, "context": ", 1995), and machine learning researchers (Helmbold and Schapire, 1997; Pereira and Singer, 1999; Cesa-Bianchi and Lugosi, 2006; Dekel et al., 2010).", "startOffset": 42, "endOffset": 148}, {"referenceID": 4, "context": ", 1995), and machine learning researchers (Helmbold and Schapire, 1997; Pereira and Singer, 1999; Cesa-Bianchi and Lugosi, 2006; Dekel et al., 2010).", "startOffset": 42, "endOffset": 148}, {"referenceID": 7, "context": ", 1995), and machine learning researchers (Helmbold and Schapire, 1997; Pereira and Singer, 1999; Cesa-Bianchi and Lugosi, 2006; Dekel et al., 2010).", "startOffset": 42, "endOffset": 148}, {"referenceID": 0, "context": "Another related line of work is multitask prediction (e.g., see Ando and Zhang, 2005; Abernethy et al., 2007), in which one considers several different multiclass prediction problems and seeks a common feature space for those.", "startOffset": 53, "endOffset": 109}, {"referenceID": 22, "context": "A more recent approach to sequence modeling is the \u201csequence memoizer\u201d, which is based on nonparametric Bayesian models (Wood et al., 2009).", "startOffset": 120, "endOffset": 139}, {"referenceID": 12, "context": "Another possible approach to the problem is to use probabilistic latent variable models (Hofmann, 1999) or their discriminative counterparts (Felzenszwalb et al.", "startOffset": 88, "endOffset": 103}, {"referenceID": 9, "context": "Another possible approach to the problem is to use probabilistic latent variable models (Hofmann, 1999) or their discriminative counterparts (Felzenszwalb et al., 2008; Yu and Joachims, 2009).", "startOffset": 141, "endOffset": 191}, {"referenceID": 23, "context": "Another possible approach to the problem is to use probabilistic latent variable models (Hofmann, 1999) or their discriminative counterparts (Felzenszwalb et al., 2008; Yu and Joachims, 2009).", "startOffset": 141, "endOffset": 191}, {"referenceID": 17, "context": "Prediction in such a setting was recently addressed in Rendle et al. (2010). Unlike in our case, they have access to multiple training sequences from particular users, and prediction is done on these users.", "startOffset": 55, "endOffset": 76}, {"referenceID": 7, "context": "Training is done using the algorithm in (Dekel et al., 2010).", "startOffset": 40, "endOffset": 60}], "year": 2012, "abstractText": "Online sequence prediction is the problem of predicting the next element of a sequence given previous elements. This problem has been extensively studied in the context of individual sequence prediction, where no prior assumptions are made on the origin of the sequence. Individual sequence prediction algorithms work quite well for long sequences, where the algorithm has enough time to learn the temporal structure of the sequence. However, they might give poor predictions for short sequences. A possible remedy is to rely on the general model of prediction with expert advice, where the learner has access to a set of r experts, each of which makes its own predictions on the sequence. It is well known that it is possible to predict almost as well as the best expert if the sequence length is order of log(r). But, without firm prior knowledge on the problem, it is not clear how to choose a small set of good experts. In this paper we describe and analyze a new algorithm that learns a good set of experts using a training set of previously observed sequences. We demonstrate the merits of our approach by applying it on the task of click prediction on the web.", "creator": "LaTeX with hyperref package"}}}