{"id": "1206.4612", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Exact Soft Confidence-Weighted Learning", "abstract": "In this paper, we propose a new Soft Confidence-Weighted (SCW) online learning scheme, which enables the conventional confidence-weighted learning method to handle non-separable cases. Unlike the previous confidence-weighted learning algorithms, the proposed soft confidence-weighted learning method enjoys all the four salient properties: (i) large margin training, (ii) confidence weighting, (iii) capability to handle non-separable data, and (iv) adaptive margin. Our experimental results show that the proposed SCW algorithms significantly outperform the original CW algorithm, while that the observed results were different. We further develop a more general SCW algorithm for training with the same parameters in addition to the original CW algorithm.", "histories": [["v1", "Mon, 18 Jun 2012 15:00:20 GMT  (255kb)", "http://arxiv.org/abs/1206.4612v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["steven c h hoi", "jialei wang", "peilin zhao"], "accepted": true, "id": "1206.4612"}, "pdf": {"name": "1206.4612.pdf", "metadata": {"source": "META", "title": "Exact Soft Confidence-Weighted Learning", "authors": ["Jialei Wang", "Peilin Zhao", "Steven C.H. Hoi"], "emails": ["jl.wang@ntu.edu.sg", "zhao0106@ntu.edu.sg", "chhoi@ntu.edu.sg"], "sections": [{"heading": "1. Introduction", "text": "Online learning algorithms (Rosenblatt, 1958; Crammer et al., 2006; Jin et al., 2010; Zhao et al., 2011a;b) represent a family of fast and simple machine learning techniques, which usually make few statistical assumptions and can be applied to a wide range of applications (Li et al., 2012). Online learning has been actively studied in machine learning community, in which a variety of online learning algorithms have been proposed, including a number of first-order algorithms such as the well-known Perceptron algorithm (Rosenblatt, 1958) and the Passive-Aggressive (PA) algorithms (Crammer et al., 2006).\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nRecent years have seen a surge of studies on the second-order online learning algorithms (Cesa-Bianchi et al., 2005; Dredze et al., 2008; Crammer et al., 2009b; Orabona & Crammer, 2010; Duchi et al., 2011), which have shown that parameter confidence information can be explored to guide and improve online learning performance (Cesa-Bianchi et al., 2005). For example, Confidence-weighted (CW) learning (Dredze et al., 2008; Crammer et al., 2009a) maintains a Gaussian distribution over some linear classifier hypotheses and applies it to control the direction and scale of parameter updates (Dredze et al., 2008). Although CW learning has formal guarantees in the mistakebound model (Crammer et al., 2008), it can overfit in certain situations due to its aggressive update rules based upon a separable data assumption. Recently, an improved online algorithm, i.e., Adaptive Regularization of Weights (AROW) (Crammer et al., 2009b; Orabona & Crammer, 2010), relaxes such separable assumption by employing an adaptive regularization for each training example based upon its current confidence. This regularization comes in the form of minimizing a combination of the Kullback-Leibler divergence between Gaussian distributed weight vectors and a confidence penalty of vectors.\nAlthough AROW is able to improve the original CW learning by handling noisy and non-separable cases, it is not the exact corresponding soft extending part of CW (Like PA with PA-I and PA-II). In particular, the directly added loss and confidence regularization make AROW lose an important property of Confidence-weighted learning, i.e., Adaptive Margin property. Following the similar idea of soft margin support vector machines, the adaptive margin assigns different margins for different instances via a probability formulation, which enables CW to gain extra efficiency and effectiveness.\nIn this work, we extend the confidence-weighted learning for soft margin learning, which makes our Soft\nConfidence-Weighted (SCW) learning method more robust than the original CW learning when handling noisy and non-separable data, and more effective and efficient than the state-of-the-art AROW algorithm.\nThe rest of this paper is organized as follows. Section 2 reviews related work. Section 3 proposes the soft confidence-weighted learning method. Section 4 analyzes the mistake bounds and properties of our algorithms. Section 5 conducts an extensive set of empirical experiments, and Section 6 concludes this work."}, {"heading": "2. Related Work and Background", "text": ""}, {"heading": "2.1. Overview of Online Learning", "text": "Online learning operates on a sequence of data examples with time stamps. At time step t, the algorithm processes an incoming example xt \u2208 Rd by first predicting its label y\u0302t \u2208 {\u22121,+1}. After the prediction, the true label yt \u2208 {\u22121,+1} is revealed and then the loss \u2113(yt, y\u0302t), which is the difference between its prediction and the revealed true label yt, is suffered. Finally, the loss is used to update the weights of the model based on some criterion. Overall, the goal of online learning is to minimize the cumulative mistake over the entire sequence of data examples.\nOur work is closely related to several first and second order online learning algorithms, including Passive-Aggressive (PA) learning (Crammer et al., 2006), Confidence-Weighted learning (Dredze et al., 2008), and Adaptive Regularization of Weights learning (Crammer et al., 2009b). Below we review the basics of these algorithms."}, {"heading": "2.2. Passive-Aggressive Learning", "text": "As the state-of-the-art first order online learning algorithm, the optimization of Passive-Aggressive (PA) learning is formulated as:\nwt+1 = arg min w\u2208Rd\n1 2 \u2016w \u2212wt\u20162s.t.\u2113(w; (xt, yt)) = 0 (1)\nwhere the loss function is based on the hinge loss:\n\u2113(w; (xt, yt)) =\n{\n0 if yt(w \u00b7 xt) \u2265 1 1\u2212 yt(w \u00b7 xt) otherwise\nThe above optimization has the closed-form solution:\nwt+1 = wt + \u03b7 PA t ytxt (2)\nwhere \u03b7PAt = \u2113(wt;(xt,yt))\n\u2016xt\u20162 . Further, to let PA be able to handle non-separable instances and more robust, a slack variable \u03be was introduced into the optimization (1) using one of two types of penalty: linear and quadratic, leading to the following two formulations of\nsoft-margin PA algorithms:\nwPA\u2212It+1 = arg min w\u2208Rd\n1 2 \u2016w\u2212wt\u20162 + C\u2113(w; (xt, yt))\nwPA\u2212IIt+1 = arg min w\u2208Rd\n1 2 \u2016w\u2212wt\u20162 + C\u2113(w; (xt, yt))2\nwhere C is a parameter to tradeoff between passiveness and aggressiveness. The resulting weight updates to the soft-margin PA algorithms have the same form as that of (2), but different coefficients \u03b7t as follows:\n\u03b7PA\u2212It = min{C, \u2113(wt; (xt, yt)) \u2016xt\u20162 }, \u03b7PA\u2212IIt = \u2113(wt; (xt, yt))\n\u2016xt\u20162 + 12C"}, {"heading": "2.3. Confidence-Weighted Learning", "text": "To better exploring the underlying structure between features, the Confidence-Weighted (CW) learning algorithm assumes a Gaussian distribution of weights with mean vector \u00b5 \u2208 Rd and covariance matrix \u03a3 \u2208 Rd\u00d7d. The weight distribution is updated by minimizing the Kullback-Leibler divergence between the new weight distribution and the old one while ensuring that the probability of correct classfication is greater than a threshold as follows:\n(\u00b5t+1,\u03a3t+1) = argmin \u00b5,\u03a3\nDKL(N (\u00b5,\u03a3),N (\u00b5t,\u03a3t))\ns.t. P r w\u223cN (\u00b5,\u03a3)[yt(w \u00b7 xt) \u2265 0] \u2265 \u03b7\nThis optimization problem has a closed-form solution\n\u00b5t+1 = \u00b5t + \u03b1tyt\u03a3txt \u03a3t+1 = \u03a3t \u2212 \u03b2t\u03a3txtTxt\u03a3t (3) The updating coefficients are calculated as follows:\n\u03b1t = max { 0, 1\n\u03c5t\u03b6 (\u2212mt\u03c8 +\n\u221a\nmt2 \u03c64\n4 + \u03c5t\u03c62\u03b6)\n}\n\u03b2t = \u03b1t\u03c6\u221a\nut + \u03c5t\u03b1t\u03c6\nwhere ut = 1 4 (\u2212\u03b1t\u03c5t\u03c6 +\n\u221a\n\u03b1t2\u03c5t2\u03c62 + 4\u03c5t) 2, \u03c5t =\nxt T\u03a3txt, mt = yt(\u00b5t \u00b7 xt), \u03c6 = \u03a6\u22121(\u03b7)(\u03a6 is the cumulative function of the normal distribution), \u03c8 = 1+ \u03c6 2\n2 , and \u03b6 = 1 + \u03c62."}, {"heading": "2.4. Adaptive Regularization of Weights", "text": "Unlike the original CW learning algorithm, the Adaptive Regularization Of Weights (AROW) learning introduces adaptive regularization of the prediction function when processing a new instance in each learning step, making it more robust than CW to sudden changes of label noise in the learning tasks. In particular, the optimization of AROW is formulated as:\n(\u00b5t+1,\u03a3t+1) = argmin \u00b5,\u03a3\nDKL(N (\u00b5,\u03a3),N (\u00b5t,\u03a3t))\n+ 1\n2\u03b3 \u21132(\u00b5; (xt, yt)) +\n1\n2\u03b3 xt\nT\u03a3txt\nwhere \u21132(\u00b5; (xt, yt)) = (max{0, 1\u2212 yt(\u00b5 \u00b7 xt)})2 and \u03b3 is a regularization parameter. The optimization has a closed-form solution similar with CW of (3), but different updating coefficients:\n\u03b1t = \u2113(\u00b5t; (xt, yt))\u03b2t, \u03b2t = 1\nxtT\u03a3txt + \u03b3"}, {"heading": "3. Soft Confidence-Weighted Learning", "text": "In this section we present a new online learning method that aims to address the limitation of the CW and AROW learning. Following the same problem settings of the Confidence-Weighted learning, we assume the weight vectorw follows the Gaussian distribution with the mean vector\u00b5 and the covariance matrix \u03a3. Notice that the probability constraint in the CW learning, i.e., Pr w\u223cN (\u00b5,\u03a3)[yt(w \u00b7 xt) \u2265 0] \u2265 \u03b7 can be rewritten as\nyt(\u00b5 \u00b7 xt) \u2265 \u03c6 \u221a x\u22a4t \u03a3xt,\nwhere \u03c6 = \u03a6\u22121(\u03b7). Further, we introduce a loss function as follows:\n\u2113\u03c6 ( N (\u00b5,\u03a3); (xt, yt) ) = max ( 0, \u03c6\n\u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt )\nIt is easy to verify that satisfying the probability constraint (i.e., yt(\u00b5 \u00b7 xt) \u2265 \u03c6 \u221a\nx\u22a4t \u03a3xt for any \u03c6 > 0) is equivalent to satisfying \u2113\u03c6 ( N (\u00b5,\u03a3); (xt, yt) )\n= 0. Therefore, the optimization problem of the original CW can be re-written as follows\n(\u00b5t+1,\u03a3t+1) = argmin \u00b5,\u03a3\nDKL ( N (\u00b5,\u03a3)\u2016N (\u00b5t,\u03a3t) )\ns.t. \u2113\u03c6 ( N (\u00b5,\u03a3); (xt, yt) ) = 0, \u03c6 > 0\nThe original CW learning method employs a very aggressive updating strategy by changing the distribution as much as necessary to satisfy the constraint imposed by the current example. Although it results in the rapid learning effect, it could force to wrongly change the parameters of the distribution dramatically when handling a mislabeled instance. Such undesirable property makes the original CW algorithm performs poorly in many real-world applications with relatively large noise.\nTo overcome the above limitation of the CW learning problem, we propose a Soft Confidence-Weighted (SCW) learning method, which aims to soften the aggressiveness of the CW updating strategy. The idea of the SCW learning is inspired by the variants of PA algorithms (PA-I and PA-II) and the adaptive margin. In particular, we formulate the optimization of SCW for learning the soft-margin classifiers as follows:\n(\u00b5t+1,\u03a3t+1) = argmin \u00b5,\u03a3\nDKL ( N (\u00b5,\u03a3)\u2016N (\u00b5t,\u03a3t) )\n+ C\u2113\u03c6 ( N (\u00b5,\u03a3); (xt, yt) )\n(4)\nwhere C is a parameter to tradeoff the passiveness and aggressiveness. We denoted the above formulation of the Soft Confidence-Weighted algorithm, as \u201cSCW-I\u201d for short. Similar to the variant of PA, we can also modify the above formulation by employing a squared penalty, leading to the second formulation of SCW learning (denoted as \u201cSCW-II\u201d for short):\n(\u00b5t+1,\u03a3t+1) = argmin \u00b5,\u03a3\nDKL ( N (\u00b5,\u03a3)\u2016N (\u00b5t,\u03a3t) )\n+ C\u2113\u03c6 ( N (\u00b5,\u03a3); (xt, yt) )2\n(5)\nFor the optimization of SCW-I, the following proposition gives the closed-form solution.\nProposition 1. The closed-form solution of the optimization problem (4) is expressed as follows:\n\u00b5t+1 = \u00b5t + \u03b1tyt\u03a3txt,\u03a3t+1 = \u03a3t \u2212 \u03b2t\u03a3txtTxt\u03a3t where the updating coefficients are as follows:\n\u03b1t = min{C,max{0, 1\n\u03c5t\u03b6 (\u2212mt\u03c8 +\n\u221a\nmt2 \u03c64\n4 + \u03c5t\u03c62\u03b6)}}\n\u03b2t = \u03b1t\u03c6\u221a\nut + \u03c5t\u03b1t\u03c6\nwhere ut = 1 4 (\u2212\u03b1t\u03c5t\u03c6 +\n\u221a\n\u03b1t2\u03c5t2\u03c62 + 4\u03c5t) 2,\u03c5t =\nxt T\u03a3txt,mt = yt(\u00b5t \u00b7 xt),\u03c6 = \u03a6\u22121(\u03b7),\u03c8 = 1 + \u03c6 2\n2 and \u03b6 = 1 + \u03c62.\nSimilarly, the following proposition gives the closedform solution to the optimization of SCW-II.\nProposition 2. The closed-form solution of the optimization problem (5) is:\n\u00b5t+1 = \u00b5t + \u03b1tyt\u03a3txt,\u03a3t+1 = \u03a3t \u2212 \u03b2t\u03a3txtTxt\u03a3t The updating coefficients are as follows:\n\u03b1t = max{0, \u2212(2mtnt + \u03c62mt\u03c5t) + \u03b3t\n2(n2t + nt\u03c5t\u03c6 2)\n}\n\u03b2t = \u03b1t\u03c6\u221a\nut + \u03c5t\u03b1t\u03c6\nwhere \u03b3t = \u03c6 \u221a \u03c62m2t\u03c5 2 t + 4nt\u03c5t(nt + \u03c5t\u03c6\n2), and nt = \u03c5t + 1 2C .\nThe detailed proofs of Proposition 1 and 2 can be found in Appendix section. Finally, Algorithm 1 summarizes the proposed SCW-I and SCW-II algorithms."}, {"heading": "4. Analysis and Discussions", "text": "We first give an overview about the comparison of the proposed SCW methods with respect to several existing first-order and second-order online learning algorithms, followed by the discussions on the nonlinear extension and the bound analysis.\nAlgorithm 1 SCW learning algorithms (SCW)\nINPUT: parameters C > 0, \u03b7 > 0. INITIALIZATION: \u00b50 = (0, . . . , 0)\n\u22a4, \u03a30 = I. for t = 1, . . . , T do Receive an example xt \u2208 Rd; Make prediction: y\u0302t = sgn(\u00b5t\u22121 \u00b7 xt); Receive true label yt; suffer loss \u2113\u03c6 ( N (\u00b5t\u22121,\u03a3t\u22121); (xt, yt) ) ;\nif \u2113\u03c6 ( N (\u00b5t\u22121,\u03a3t\u22121); (xt, yt) )\n> 0 then \u00b5t+1 = \u00b5t+\u03b1tyt\u03a3txt,\u03a3t+1 = \u03a3t\u2212\u03b2t\u03a3txtTxt\u03a3t where \u03b1t and \u03b2t are computed by either Proposition 1 (SCW-I) or Proposition 2 (SCW-II);\nend if\nend for"}, {"heading": "4.1. Comparison with the existing methods", "text": "Following the study of AROW, we qualitatively examine the properties of different algorithms in Table 1. Unlike the previous second-order algorithms, the proposed SCW algorithm enjoys all the four salient properties. In particular, SCW improves over the original CW algorithm by adding the capability to handle the non-separable cases, and improves over AROW by adding the adaptive margin property. To the best of our knowledge, SCW is the first second-order online learning that holds all the four properties."}, {"heading": "4.2. Extension to Nonlinear Cases", "text": "Similar to other linear online learning methods, the proposed SCW learning can be extended to nonlinear cases. The following lemma shows the possibility of extending the proposed SCW algorithms to nonlinear cases using kernel tricks.\nLemma 1. (Representer Theorem) The mean \u00b5i and covariance \u03a3i parameters computed by the soft confidence weight algorithm can be written as linear combinations of the input vectors with coefficients that depend only on inner products of input\nvectors, i.e.,\n\u03a3i =\ni\u22121 \u2211\np,q=1\n\u03c0(i)p,qxpxq T + aI, \u00b5i =\ni\u22121 \u2211\np\n\u03bdp (i)xp\nwhere \u03bdi (i) = 1 and \u03bdp (i+1) = \u03bdp (i) + \u03b1iyi \u2211i\u22121 q \u03c0p,q (i)xq Txi for p < i, and \u03c0p,q (i+1) = \u2212\u03b2i \u2211 r,s \u03c0p,r (i)\u03c0s,q (i)xr Txs + \u03c0p,q (i), \u03c0p,i (i) = \u03c0i,p (i) = \u2212\u03b2i \u2211i\u22121 p,r \u03c0p,r (i)(xr Txi), \u03c0i,i (i+1) = \u2212\u03b2i.\nThe above lemma can be proved by induction similar to the proof in (Crammer et al., 2008)."}, {"heading": "4.3. Analysis of the Loss Bound", "text": "Our analysis begins with the definition of confidence loss, which is used in (Crammer et al., 2008). The loss is a function of the margin mi normalized by\u221a v, i.e., m\u0303i =\nmi\u221a vi . We modified the confidence loss\nin (Crammer et al., 2008) as an upper-bounded loss by:\n\u2113\u03c6i(m\u0303i) =\n{\n0 m\u0303i \u2265 \u03c6 min{f\u03c6(m\u0303i), C 2(1+\u03c62)\u03c5i \u03c62 } m\u0303i < \u03c6\nwhere f\u03c6(m\u0303) = (\u2212m\u0303\u03c8+\n\u221a\nm\u03032 \u03c64\n4 +\u03c62\u03b6)2\n\u03c62\u03b6 . It is easy to see\nthat the loss \u2113\u03c6(m\u0303) holds the properties of Lemma 5 in (Crammer et al., 2008) for SCW-I.\nWe have the following loss bound.\nTheorem 1. Let (x1, y1)...(xn, yn) be an input sequence for SCW-I. Assume there exist \u00b5\u2217 and \u03a3\u2217 such that for all i for which the algorithm made an update(\u03b1i > 0),\n\u00b5\u2217Txiyi \u2265 \u00b5i+1Txiyi, xiT\u03a3\u2217xi \u2264 xiT\u03a3i+1xi Then the following bound holds:\n\u2211\ni\n\u2113\u03c6i(m\u0303i) \u2264 \u2211\ni\n(\u03b1i) 2 \u03c5i\n\u2264 (1 + \u03c6 2)\n\u03c62 (\u2212 log det\u03a3\u2217 + Tr(\u03a3\u2217) + \u00b5\u2217T\u03a3n+1\u22121\u00b5\u2217 \u2212 d)\nThe above theorem can be proved by applying Lemma 7 and property 6 in Lemma 5 in (Crammer et al., 2008). If we let \u2113\u03c6i(m\u0303i) upper bound the 0 \u2212 1 loss by choosing an appropriate C, then our mistake number is also bounded by\n(1 + \u03c62)\n\u03c62 (\u2212 log det\u03a3\u2217 +Tr(\u03a3\u2217) +\u00b5\u2217T\u03a3n+1\u22121\u00b5\u2217 \u2212 d)."}, {"heading": "5. Empirical Evaluation", "text": ""}, {"heading": "5.1. Datasets and compared algorithms", "text": "We adopt a variety of datasets from different domains:\n\u2022 synthetic data: we generated this data set by the method described in (Crammer et al., 2008), which is used to examine the effectiveness of second-order algorithms. Following (Crammer et al., 2009b), we also generated another version with 0.1 noise to examine the robustness of second-order algorithms. \u2022 Digital recognition: we use two benchmarks: \u201cUSPS\u201d 1 and \u201cMNIST\u201d 2. For binary classification, we choose \u201c1\u201d vs \u201call\u201d for \u201cUSPS\u201d, and \u201c1\u201d vs \u201c2\u201d for \u201cMNIST\u201d. \u2022 Face data: we use the MIT-CBCL face imags 3. \u2022 Machine Learning datasets: we randomly choose several public machine learning datasets from 4. Table 2 shows the statistics of the list of datasets used.\nWe compare our methods with various online learning algorithms, including Perceptron (Rosenblatt, 1958), PA (Crammer et al., 2006), ROMMA (Li & Long, 1999) and its aggressive version agg-ROMMA, SecondOrder Perceptron (Cesa-Bianchi et al., 2005), Confidence Weighted Learning (Crammer et al., 2008), Improved Ellipsoid Method for Online Learning(IELLIP) (Yang et al., 2009), AROW (Crammer et al., 2009b), Normal HERD (NHERD) (Crammer & D.Lee, 2010) and NAROW (Orabona & Crammer, 2010). Following the similar parameter setting methods in (Dredze et al., 2008) and (Crammer et al., 2009b). The parameter r in AROW, paramter b in NAROW and parameters C in PA-I, PA-II, NHERD, SCW-I and SCW-II are all determined by cross validation to select the best one from {2\u22124, 2\u22123, ..., 23, 24}, the parameter \u03b7 in CW, SCW-I and SCW-II are determined by cross validation to select the best one from\n1 http://www-i6.informatik.rwth-aachen.de/~keysers/usps.html 2 http://yann.lecun.com/exdb/mnist/ 3 http://cbcl.mit.edu/software-datasets/FaceData2.html 4 http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/\n{0.5, 0.55, ..., 0.9, 0.95}, the parameter b in IELLIP is determined by cross validation to select the best one from {0.1, 0.2, ..., 0.9}. After the best parameters are determined, all the experiments were conducted over 20 random permutations for each dataset. All the results were reported by averaging over these 20 runs. We evaluate the performance by three metrics: (i) online cumulative mistake rate, (ii) number of updates (which would be closely related to the potential number of support vectors in kernel extension), and (iii) running time cost."}, {"heading": "5.2. Experimental Results", "text": "Table 3 summarizes the results of our empirical evaluation, where we only show margin-based second-order learning algorithms due to space limitation. For a more complete comparison, please refer to our supplemental material. The bold elements indicate the best performance with paired t-test at 95% significance level. We can draw several observations as follows.\nFirst of all, by examining the overall mistakes, we found that second-order algorithms usually outperforms first-order algorithms, and margin based algorithms usually outperforms non-margin based methods. This shows the efficacy of \u201cLarge Margin\u201d and \u201cConfidence\u201d properties for learning better classifiers.\nSecond, by examining the original CW algorithm, we found that, it significantly outperforms the first-order algorithms (e.g. Perceptron, ROMMA, and PA algorithms) on the synthetic data without noise, but fails to outperform the first-order algorithms on some real-world datasets that often have noisy data. This empirical result verifies the importance of \u201cHandling Non-separable\u201d property in producing robust classifiers when dealing with noisy data.\nFurther, we found that AROW significantly outperforms CW in many real-world datasets (except minist). However, AROW usually produces considerably more updates and spends more running time than CW. This verifies that the importance of \u201cadaptive margin\u201d property of both CW and SCW to reduce the number of updates as well as the running time.\nMoreover, among all the compared algorithms, SCW often achieves the best or close to the best performance in terms of accuracy, number of updates, and running time cost. Finally, Figure 1 shows the online results of 13 algorithms with respect to varied numbers of samples in online learning process. The results again validate the advantages of SCW in both efficacy and efficiency among all the state-of-the-art algorithms."}, {"heading": "6. Conclusion", "text": "This paper proposed the Soft Confidence-Weighted (SCW) learning, a new second-order online learning method with state-of-the-art empirical performance. Unlike the existing second-order algorithms, SCW enjoys all the four properties: (i) large margin training, (ii) confidence weighting, (iii) adaptive margin, and (iv) capability of handling non-separable data. Empirically, we found the proposed SCW algorithms perform significantly better than the original CW algorithm, and outperform the state-of-the-art AROW algorithm for most cases in terms of both accuracy and efficiency. Future work will conduct more in-depth analysis of the mistake bounds and its multi-class extension (Crammer et al., 2009a)."}, {"heading": "Appendix: Proof of Proposition 1 and 2", "text": "Proof. First, when \u2113\u03c6 ( N (\u00b5t,\u03a3t); (xt, yt) )\n= 0, it is easy to see the solution is valid. When \u2113\u03c6 ( N (\u00b5t,\u03a3t); (xt, yt) ) > 0, it is easy to see the op-\ntimization problem is equivalent to\nDKL ( N (\u00b5,\u03a3)\u2016N (\u00b5t,\u03a3t) ) + C\u03be, s.t. \u2113 \u03c6 ( N (\u00b5,\u03a3); (xt, yt) ) \u2264 \u03be and \u03be \u2265 0\nSince \u2211\nis positive semi-definite (PSD), it can be written as \u2211\n= \u03a52 to make the optimization with a convex constraint in \u00b5 and \u03a5 simultaneously. But for convenient, we will still use \u03a3 instead of \u03a52 in the following analysis. The Lagrangian of the above optimization is\nL(\u00b5,\u03a3, \u03be, \u03c4, \u03bb) = DKL ( N (\u00b5,\u03a3)\u2016N (\u00b5t,\u03a3t) ) + C\u03be +\u03c4 (\u03c6 \u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt \u2212 \u03be)\u2212 \u03bb\u03be = DKL ( N (\u00b5,\u03a3)\u2016N (\u00b5t,\u03a3t) ) +\u03be(C \u2212 \u03c4 \u2212 \u03bb) + \u03c4 (\u03c6 \u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt)\n= 1\n2 log( det\u03a3t det\u03a3 ) + 1 2 Tr(\u03a3\u22121t \u03a3) + 1 2 (\u00b5t \u2212\u00b5)\u22a4\u03a3\u22121t (\u00b5t \u2212\u00b5)\n\u2212d 2 + \u03be(C \u2212 \u03c4 \u2212 \u03bb) + \u03c4 (\u03c6\n\u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt)\nwhere \u03c4 \u2265 0 and \u03bb \u2265 0 are Lagrange multipliers. We now find the minimum of the Lagrangian with respect to the primal variables \u00b5, \u03a3 and \u03be.\n\u2202L \u2202\u00b5 = \u03a3\u22121t (\u00b5 \u2212\u00b5t) + \u03c4 (\u2212ytxt) = 0 \u21d2 \u00b5 = \u00b5t + \u03c4yt\u03a3txt \u2202L \u2202\u03a3 = 0 \u21d2 \u03a3\u22121t+1 = \u03a3\u22121t + \u03c4\u03c6 xtx \u22a4 t \u221a\nx\u22a4t \u03a3t+1xt\nand C \u2212 \u03c4 \u2212 \u03bb = 0, so \u03c4 = C \u2212 \u03bb \u2264 C, thus \u03c4 \u2208 [0, C] The KKT conditions for the optimization are:\n\u03c6\n\u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt \u2212 \u03be \u2264 0,\u2212\u03be \u2264 0, \u03c4, \u03bb \u2265 0\n\u03c4 (\u03c6 \u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt \u2212 \u03be) = 0, \u03bb\u03be = 0\nCase 1. \u03c4 6= 0 As \u03c4(\u03c6 \u221a\nx\u22a4t \u03a3xt\u2212yt\u00b5 \u00b7xt\u2212\u03be) = 0 implies (\u03c6 \u221a x\u22a4t \u03a3xt\u2212 yt\u00b5 \u00b7 xt \u2212 \u03be) = 0, the KKT conditions are simplified:\n\u2212\u03be \u2264 0, \u03c4 > 0, \u03bb \u2265 0\n\u03c6\n\u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt \u2212 \u03be = 0, \u03bb\u03be = 0\nSub-case 1.1. \u03bb 6= 0 When \u03bb 6= 0, \u03bb\u03be = 0, implies \u03be = 0. The KKT conditions are simplified as\n\u03c4 > 0, \u03bb > 0, \u03be = 0, \u03c6 \u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt = 0\nFinally, we have the following:\n\u03a3t+1 = ( \u03a3\u22121t + \u03c4\u03c6 xtx\n\u22a4 t\n\u221a\nx\u22a4t \u03a3t+1xt\n)\u22121\n= \u03a3t \u2212 \u03a3txt ( \u03c4\u03c6 \u221a\nx\u22a4t \u03a3t+1xt + \u03c4\u03c6x \u22a4 t \u03a3txt\n)\nx \u22a4\nt \u03a3t\nLet ut = x \u22a4 t \u03a3t+1xt, vt = x \u22a4 t \u03a3txt, mt = yt(\u00b5t \u00b7xt), multiplying by x\u22a4t (left) and xt (right), we get ut = vt \u2212 vt( \u03c4\u03c6\u221aut+\u03c4\u03c6vt )vt, which can be used to solve ut:\n\u221a ut = \u2212\u03c4\u03c6vt + \u221a \u03c42\u03c62v2t + 4vt 2 .\nAnd \u03c6 \u221a x\u22a4t \u03a3xt\u2212yt\u00b5 \u00b7xt = 0 implies \u03c6 \u221a ut\u2212mt\u2212\u03c4vt = 0. Thus, \u03c6 \u2212\u03c4\u03c6vt+ \u221a \u03c42\u03c62v2t+4vt 2 \u2212 mt \u2212 \u03c4vt = 0, which can be rearranged as: v2t (1+\u03c6 2)\u03c42+2mtvt(1+ \u03c62\n2 )\u03c4 + (m2t \u2212 \u03c62vt). The larger root is then\n\u03c4 = \u2212mtvt(1 + \u03c6\n2\n2 ) +\n\u221a \u2206\nv2t (1 + \u03c6 2)\n,\nwhere \u2206 = m2tv 2 t (1 +\n\u03c62\n2 ) 2 \u2212 v2t (1 + \u03c62)(m2t \u2212 \u03c62vt).\nIf \u03c4 \u2208 (0, C), then \u03bb = C \u2212 \u03c4 \u2208 (0, C). Sub-case 1.2. \u03bb = 0 C \u2212 \u03c4 \u2212 \u03bb = 0 implies \u03c4 = C. The KKT conditions can be simplified as:\n\u2212\u03be \u2264 0, \u03c4 = C, \u03bb = 0, \u03c6 \u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt \u2212 \u03be = 0\nWe thus have:\n\u03c6\n\u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt\n= [\u03c6 \u2212\u03c4\u03c6vt +\n\u221a\n\u03c4 2\u03c62v2t + 4vt 2 \u2212mt \u2212 \u03c4vt]|\u03c4=C = \u03be \u2265 0\nIt is easy to verify that\nf \u2032(\u03c4 ) = \u2212\u03c62vt 2 + \u03c63v2t \u03c4 2 \u221a \u03c4 2\u03c62v2t + 4vt \u2212 vt = 0\nhas no solution on [0,+\u221e) and f \u2032(0) = \u2212\u03c62vt2 \u2212vt < 0. As a result, f \u2032(\u03c4) < 0, \u03c4 \u2208 [0,+\u221e), which implies f(\u03c4) is decreasing on [0,+\u221e).\nf(C) \u2265 0 = f(\u03b8)\nwhere \u03b8 = \u2212mtvt(1+\u03c6\n2 2 )+\n\u221a\nm2tv 2 t (1+ \u03c62 2 )2\u2212v2t (1+\u03c62)(m2t\u2212\u03c62vt)\nv2t (1+\u03c6 2)\n,\nwhich thus implies C \u2264 \u03b8. Case 2. \u03c4 = 0 When \u03c4 = 0, since C \u2212 \u03c4 \u2212 \u03bb = 0, \u03bb = C, the KKT condtions are simplified as\n\u03c6\n\u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt \u2264 0, \u03c4 = 0, \u03bb = C, \u03be = 0\nThus, \u00b5t+1 = \u00b5t and \u03a3t+1 = \u03a3t; as a result, \u03c6 \u221a\nx\u22a4t \u03a3txt \u2212 yt\u00b5t \u00b7 xt \u2264 0, which contradicts with \u2113\u03c6 ( N (\u00b5,\u03a3); (xt, yt) ) > 0.\nFor SCW-II, the Lagrangian of the optimization is\nL(\u00b5,\u03a3, \u03be, \u03c4, \u03bb) = DKL ( N (\u00b5,\u03a3)\u2016N (\u00b5t,\u03a3t) ) + C\u03be2 +\u03c4 (\u03c6 \u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt \u2212 \u03be)\u2212 \u03bb\u03be = DKL ( N (\u00b5,\u03a3)\u2016N (\u00b5t,\u03a3t) ) +\u03be(C\u03be \u2212 \u03c4 \u2212 \u03bb) + \u03c4 (\u03c6 \u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt)\n= 1\n2 log( det\u03a3t det\u03a3 ) + 1 2 Tr(\u03a3\u22121t \u03a3) + 1 2 (\u00b5t \u2212\u00b5)\u22a4\u03a3\u22121t (\u00b5t \u2212\u00b5)\n\u2212d 2 + \u03be(C\u03be \u2212 \u03c4 \u2212 \u03bb) + \u03c4 (\u03c6\n\u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt)\nwhere \u03c4 \u2265 0 and \u03bb \u2265 0 are Lagrange multipliers. We now find the minimum of the Lagrangian with respect to the primal variables \u00b5, \u03a3 and \u03be.\n\u2202L \u2202\u00b5 = \u03a3\u22121t (\u00b5 \u2212\u00b5t) + \u03c4 (\u2212ytxt) = 0 \u21d2 \u00b5 = \u00b5t + \u03c4yt\u03a3txt \u2202L \u2202\u03a3 = 0 \u21d2 \u03a3\u22121t+1 = \u03a3\u22121t + \u03c4\u03c6 xtx \u22a4 t \u221a\nx\u22a4t \u03a3t+1xt\nand 2C\u03be\u2212\u03c4\u2212\u03bb = 0, so \u03be = \u03c4+\u03bb2C . The KKT conditions for the optimization are:\n\u03c6\n\u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt \u2212 \u03be \u2264 0 \u03be \u2265 0, \u03c4 \u2265 0, \u03bb \u2265 0\n\u03c4 (\u03c6 \u221a\nx\u22a4t \u03a3xt \u2212 yt\u00b5 \u00b7 xt \u2212 \u03be) = 0 \u03bb\u03be = 0\nThe rest proof is similar to that of SCW-I."}, {"heading": "Acknowledgments", "text": "This work was in part supported by Singapore MOE tier 1 project (RG33/11) and Microsoft Research project (M4060936)."}], "references": [{"title": "A second-order perceptron algorithm", "author": ["Cesa-Bianchi", "Nicol\u00f2", "Conconi", "Alex", "Gentile", "Claudio"], "venue": "SIAM J. Comput.,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2005}, {"title": "Learning via gaussian herding", "author": ["Crammer", "Koby", "D.Lee", "Daniel"], "venue": "In NIPS, pp", "citeRegEx": "Crammer et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2010}, {"title": "Online passiveaggressive algorithms", "author": ["Crammer", "Koby", "Dekel", "Ofer", "Keshet", "Joseph", "ShalevShwartz", "Shai", "Singer", "Yoram"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Crammer et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2006}, {"title": "Exact convex confidence-weighted learning", "author": ["Crammer", "Koby", "Dredze", "Mark", "Pereira", "Fernando"], "venue": "In NIPS, pp", "citeRegEx": "Crammer et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2008}, {"title": "Multiclass confidence weighted algorithms", "author": ["Crammer", "Koby", "Dredze", "Mark", "Kulesza", "Alex"], "venue": "In EMNLP, pp", "citeRegEx": "Crammer et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2009}, {"title": "Adaptive regularization of weight vectors", "author": ["Crammer", "Koby", "Kulesza", "Alex", "Dredze", "Mark"], "venue": "In NIPS,", "citeRegEx": "Crammer et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Crammer et al\\.", "year": 2009}, {"title": "Confidence-weighted linear classification", "author": ["Dredze", "Mark", "Crammer", "Koby", "Pereira", "Fernando"], "venue": "In ICML, pp", "citeRegEx": "Dredze et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Dredze et al\\.", "year": 2008}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["Duchi", "John C", "Hazan", "Elad", "Singer", "Yoram"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Online multiple kernel learning: Algorithms and mistake bounds", "author": ["Jin", "Rong", "Hoi", "Steven C. H", "Yang", "Tianbao"], "venue": "In ALT,", "citeRegEx": "Jin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jin et al\\.", "year": 2010}, {"title": "Pamr: Passive aggressive mean reversion strategy for portfolio selection", "author": ["Li", "Bin", "Zhao", "Peilin", "Hoi", "Steven C. H", "Gopalkrishnan", "Vivekanand"], "venue": "Machine Learning,", "citeRegEx": "Li et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Li et al\\.", "year": 2012}, {"title": "The relaxed online maximum margin algorithm", "author": ["Li", "Yi", "Long", "Philip M"], "venue": "In NIPS, pp", "citeRegEx": "Li et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Li et al\\.", "year": 1999}, {"title": "New adaptive algorithms for online classification", "author": ["Orabona", "Francesco", "Crammer", "Koby"], "venue": "In NIPS,", "citeRegEx": "Orabona et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Orabona et al\\.", "year": 2010}, {"title": "The perceptron: A probabilistic model for information storage and organization in the brain", "author": ["Rosenblatt", "Frank"], "venue": "Psych. Rev.,", "citeRegEx": "Rosenblatt and Frank.,? \\Q1958\\E", "shortCiteRegEx": "Rosenblatt and Frank.", "year": 1958}, {"title": "Online learning by ellipsoid method", "author": ["Yang", "Liu", "Jin", "Rong", "Ye", "Jieping"], "venue": "In ICML, pp", "citeRegEx": "Yang et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2009}, {"title": "Double updating online learning", "author": ["Zhao", "Peilin", "Hoi", "Steven C. H", "Jin", "Rong"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Zhao et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2011}, {"title": "Online auc maximization", "author": ["Zhao", "Peilin", "Hoi", "Steven C. H", "Jin", "Rong", "Yang", "Tianbao"], "venue": "In ICML, pp", "citeRegEx": "Zhao et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 9, "context": ", 2011a;b) represent a family of fast and simple machine learning techniques, which usually make few statistical assumptions and can be applied to a wide range of applications (Li et al., 2012).", "startOffset": 176, "endOffset": 193}, {"referenceID": 2, "context": "Online learning has been actively studied in machine learning community, in which a variety of online learning algorithms have been proposed, including a number of first-order algorithms such as the well-known Perceptron algorithm (Rosenblatt, 1958) and the Passive-Aggressive (PA) algorithms (Crammer et al., 2006).", "startOffset": 293, "endOffset": 315}, {"referenceID": 0, "context": "Recent years have seen a surge of studies on the second-order online learning algorithms (Cesa-Bianchi et al., 2005; Dredze et al., 2008; Crammer et al., 2009b; Orabona & Crammer, 2010; Duchi et al., 2011), which have shown that parameter confidence information can be explored to guide and improve online learning performance (Cesa-Bianchi et al.", "startOffset": 89, "endOffset": 205}, {"referenceID": 6, "context": "Recent years have seen a surge of studies on the second-order online learning algorithms (Cesa-Bianchi et al., 2005; Dredze et al., 2008; Crammer et al., 2009b; Orabona & Crammer, 2010; Duchi et al., 2011), which have shown that parameter confidence information can be explored to guide and improve online learning performance (Cesa-Bianchi et al.", "startOffset": 89, "endOffset": 205}, {"referenceID": 7, "context": "Recent years have seen a surge of studies on the second-order online learning algorithms (Cesa-Bianchi et al., 2005; Dredze et al., 2008; Crammer et al., 2009b; Orabona & Crammer, 2010; Duchi et al., 2011), which have shown that parameter confidence information can be explored to guide and improve online learning performance (Cesa-Bianchi et al.", "startOffset": 89, "endOffset": 205}, {"referenceID": 0, "context": ", 2011), which have shown that parameter confidence information can be explored to guide and improve online learning performance (Cesa-Bianchi et al., 2005).", "startOffset": 129, "endOffset": 156}, {"referenceID": 6, "context": "For example, Confidence-weighted (CW) learning (Dredze et al., 2008; Crammer et al., 2009a) maintains a Gaussian distribution over some linear classifier hypotheses and applies it to control the direction and scale of parameter updates (Dredze et al.", "startOffset": 47, "endOffset": 91}, {"referenceID": 6, "context": ", 2009a) maintains a Gaussian distribution over some linear classifier hypotheses and applies it to control the direction and scale of parameter updates (Dredze et al., 2008).", "startOffset": 153, "endOffset": 174}, {"referenceID": 3, "context": "Although CW learning has formal guarantees in the mistakebound model (Crammer et al., 2008), it can overfit in certain situations due to its aggressive update rules based upon a separable data assumption.", "startOffset": 69, "endOffset": 91}, {"referenceID": 2, "context": "Our work is closely related to several first and second order online learning algorithms, including Passive-Aggressive (PA) learning (Crammer et al., 2006), Confidence-Weighted learning (Dredze et al.", "startOffset": 133, "endOffset": 155}, {"referenceID": 6, "context": ", 2006), Confidence-Weighted learning (Dredze et al., 2008), and Adaptive Regularization of Weights learning (Crammer et al.", "startOffset": 38, "endOffset": 59}, {"referenceID": 3, "context": "The above lemma can be proved by induction similar to the proof in (Crammer et al., 2008).", "startOffset": 67, "endOffset": 89}, {"referenceID": 3, "context": "Our analysis begins with the definition of confidence loss, which is used in (Crammer et al., 2008).", "startOffset": 77, "endOffset": 99}, {"referenceID": 3, "context": "We modified the confidence loss in (Crammer et al., 2008) as an upper-bounded loss by:", "startOffset": 35, "endOffset": 57}, {"referenceID": 3, "context": "It is easy to see that the loss l\u03c6(m\u0303) holds the properties of Lemma 5 in (Crammer et al., 2008) for SCW-I.", "startOffset": 74, "endOffset": 96}, {"referenceID": 3, "context": "The above theorem can be proved by applying Lemma 7 and property 6 in Lemma 5 in (Crammer et al., 2008).", "startOffset": 81, "endOffset": 103}, {"referenceID": 3, "context": "We adopt a variety of datasets from different domains: \u2022 synthetic data: we generated this data set by the method described in (Crammer et al., 2008), which is used to examine the effectiveness of second-order algorithms.", "startOffset": 127, "endOffset": 149}, {"referenceID": 2, "context": "We compare our methods with various online learning algorithms, including Perceptron (Rosenblatt, 1958), PA (Crammer et al., 2006), ROMMA (Li & Long, 1999) and its aggressive version agg-ROMMA, SecondOrder Perceptron (Cesa-Bianchi et al.", "startOffset": 108, "endOffset": 130}, {"referenceID": 0, "context": ", 2006), ROMMA (Li & Long, 1999) and its aggressive version agg-ROMMA, SecondOrder Perceptron (Cesa-Bianchi et al., 2005), Confidence Weighted Learning (Crammer et al.", "startOffset": 94, "endOffset": 121}, {"referenceID": 3, "context": ", 2005), Confidence Weighted Learning (Crammer et al., 2008), Improved Ellipsoid Method for Online Learning(IELLIP) (Yang et al.", "startOffset": 38, "endOffset": 60}, {"referenceID": 13, "context": ", 2008), Improved Ellipsoid Method for Online Learning(IELLIP) (Yang et al., 2009), AROW (Crammer et al.", "startOffset": 63, "endOffset": 82}, {"referenceID": 6, "context": "Following the similar parameter setting methods in (Dredze et al., 2008) and (Crammer et al.", "startOffset": 51, "endOffset": 72}], "year": 2012, "abstractText": "In this paper, we propose a new Soft Confidence-Weighted (SCW) online learning scheme, which enables the conventional confidence-weighted learning method to handle non-separable cases. Unlike the previous confidence-weighted learning algorithms, the proposed soft confidence-weighted learning method enjoys all the four salient properties: (i) large margin training, (ii) confidence weighting, (iii) capability to handle non-separable data, and (iv) adaptive margin. Our experimental results show that the proposed SCW algorithms significantly outperform the original CW algorithm. When comparing with a variety of state-of-theart algorithms (including AROW, NAROW and NHERD), we found that SCW generally achieves better or at least comparable predictive accuracy, but enjoys significant advantage of computational efficiency (i.e., smaller number of updates and lower time cost).", "creator": "LaTeX with hyperref package"}}}