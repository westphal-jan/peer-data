{"id": "1206.4642", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Fast Computation of Subpath Kernel for Trees", "abstract": "The kernel method is a potential approach to analyzing structured data such as sequences, trees, and graphs; however, unordered trees have not been investigated extensively. Kimura et al. (2011) proposed a kernel function for unordered trees on the basis of their subpaths, which are vertical substructures of trees responsible for hierarchical information in them (Koltenberg et al. 2011; Ziegler et al. 2012; and O\u2019Neill et al. 2013). This function is similar to that described above, which has been used to characterize network tree structure in networks of trees. Furthermore, the most recent version of the function was previously used to perform a network analysis on network tree structure as described above.\n\n\n\nThe kernel can be used to investigate the relationship between tree structure and subpaths. However, the analysis has not been carried out with the following functions:\n\n\nThe kernel can be used to investigate network tree structure in network tree structure as described above. This function, by contrast, is used in network tree structure as described above.\nThe kernel can be used to investigate network tree structure in network tree structure as described above. This function, by contrast, is used in network tree structure as described above. This function, by contrast, is used in network tree structure as described above.\nThe kernel can be used to examine network tree structure in network tree structure as described above. This function, by contrast, is used in network tree structure as described above.\nFor the purposes of this section, the most recent version of the function was available for download and in the comments section of the article. However, the following are not implemented.\nAn array of sequences can be generated from a matrix. This can be used to identify subpaths that contain multiple subpaths and then use the algorithm to search subpaths of the subpaths that contain the same subpaths.\nFor the purposes of this section, the most recent version of the function was available for download and in the comments section of the article. However, the following are not implemented.\nA list of subpaths and subpaths containing subpaths is generated from a matrix. This can be used to identify subpaths that contain multiple subpaths and then use the algorithm to search subpaths that contain the same subpaths.\nFor the purposes of this section, the most recent version of the function was available for download and in the comments section of the article. However, the following", "histories": [["v1", "Mon, 18 Jun 2012 15:18:51 GMT  (345kb)", "http://arxiv.org/abs/1206.4642v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.DS cs.LG stat.ML", "authors": ["daisuke kimura", "hisashi kashima"], "accepted": true, "id": "1206.4642"}, "pdf": {"name": "1206.4642.pdf", "metadata": {"source": "CRF", "title": "Fast Computation of Subpath Kernel for Trees", "authors": ["Daisuke Kimura", "Hisashi Kashima"], "emails": ["kimura@mist.i.u-tokyo.ac.jp", "kashima@mist.i.u-tokyo.ac.jp"], "sections": [{"heading": "1. Introduction", "text": ""}, {"heading": "1.1. Kernels for structured data", "text": "Numerous studies on the research in machine learning are concerned with real-valued vectors. However, a considerable part of real world data is represented not as vectors, but as sequences, trees, and graphs. For example, we can represent biological sequences and natural language texts as sequences, parsed texts and semistructured data, such as HTML and XML, as trees, and chemical compounds as graphs. Extensive studies have been conducted to analyze structured data such as sequences, trees, and graphs, owing to their\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nwidespread use in recent years. Among the various existing approaches, a popular approach to such analysis is the kernel method (Scho\u0308lkopf & Smola, 2002) because it can efficiently work with high-dimensional (possibly, infinite-dimensional) feature vectors if appropriate kernel functions are provided to access data. A framework called the convolution kernel (Haussler, 1999) is widely used for designing kernel functions for structured data, where the structured data are (implicitly) decomposed into substructures, and a kernel function is defined as the sum of kernel functions among the substructures. It is important to design a good kernel function to balance the expressive power of the substructures with efficient algorithms for computing the kernel. In the framework of the convolution kernel, various kernel functions have been proposed for sequences (Lodhi et al., 2002; Leslie et al., 2002), trees (Collins & Duffy, 2001; Kashima & Koyanagi, 2002; Aiolli et al., 2009), and graphs (Kashima et al., 2003; Ga\u0308rtner et al., 2003)."}, {"heading": "1.2. Tree kernels", "text": "In this paper, we focus on tree kernels. The first tree kernel was proposed by Collins and Duffy (2001) for parse trees, and it was then extended to general ordered trees (Kashima & Koyanagi, 2002). More recently, various kernels for ordered trees have been proposed (Moschitti, 2006; Kuboyama et al., 2006; Aiolli et al., 2009; Sun et al., 2011).\nAmong the existing tree kernels, only a few kernels can handle unordered trees (Fig. 1(a)). In their seminal work, Vishwanathan and Smola (2003) proposed an efficient kernel for unordered trees. Their work is pioneering in two ways: computation can be performed in linear time with respect to the size of two trees by converting the trees into strings. Moreover, in the prediction phase, prediction for a newly coming tree can be made in linear time with respect to the size of the tree. Their kernel employs complete subtrees as features. Figure 1(b) shows all the complete subtrees in the tree shown in Fig. 1(a). More efficient implementa-\ntion using the enhanced suffix array (ESA) for strings was proposed by Teo and Vishwanathan (2006).\nMore recently, Kimura et al. (2011) proposed another tree kernel using vertical substructures called subpaths. Figure 1(c) shows all the subpaths in the tree shown in Fig. 1(a). Their kernel is useful for capturing vertical substructures responsible for hierarchical information in trees. Note that neither of the complete subtree features and the subpath feature is a superset of the other. Figure 2 shows the experimental comparison of the predictive accuracy of their kernel with that of four other tree kernels using three datasets, including one XML dataset (Zaki & Aggarwal, 2006) and two glycan datasets (Hashimoto et al., 2003; Doubet & Albersheim, 1992)1. Note that three kernels were designed by Kashima & Koyanagi (2002), Moschitti (2006) and Aiolli et al. (2009) for ordered trees; hence, we used the order information appearing in the datasets as it is. The results show that the subpath kernel proposed by Kimura et al. (2011) is competitive with the other kernels. Interestingly, the subpath kernel and the kernel proposed by Vishwanathan and Smola (2003) work complementarily.\nKimura et al. (2011) also showed that their subpath kernel is practically fast and that it is competitive with the linear-time kernel (Teo & Vishwanathan, 2006). However, despite its practical usefulness, the time complexity of the subpath kernel is theoretically O(nlogn) on average, and it is O(n2) in the worst case, where n is the sum of the sizes of the input trees, because their algorithm for computing the kernel uses the multi-key quick sort (Bentley & Sedgewick, 1997). Moreover, in contrast to the lineartime kernel (Vishwanathan & Smola, 2003; Teo & Vishwanathan, 2006), we need to evaluate the subpath kernel between a given tree and all the support vectors in the prediction phase, which is a\n1We used LIBSVM (Chang & Lin, 2001) as the SVM implementation. The accuracy is measured using 10-fold cross-validation. Kernels by Kimura et al. (2011) and Moschitti (2006) have tunable weight parameters, which were also tuned by cross-validation. As for datasets, see Table 1.\nserious drawback with large-scale data."}, {"heading": "1.3. Proposed methods", "text": "By improving the result of Kimura et al. (2011), we aim to develop (i) a theoretically guaranteed lineartime kernel computation algorithm that is practically fast, and (ii) an efficient prediction algorithm whose running time depends only on the size of the input tree.\nThe key to achieving these two objectives is an efficient data structure that accesses vertical substructures in trees. The suffix tree (ST) of trees (Shibuya, 2003) is a potential candidate. However, despite its theoretical merits, its performance (especially its memory usage) is not sufficient for practical use, as pointed out in literature (e.g., Abouelhoda et al. (2004)). In order to overcome this challenge, we use a more space-efficient data structure called the enhanced suffix array (ESA) for unordered trees, and we develop its linear-time construction algorithm. To the best our knowledge, this is the first algorithm that constructs the ESA for trees in linear time.\nUsing the ESA for trees, we devise a linear-time computation algorithm for the subpath tree kernel by simulating bottom-up traversal in the ST. Note that Vishwanathan et al. calculated their kernel by simulating top-down traversal in the ST, using the ESA for strings.\nWe also devise a fast algorithm for prediction, whose complexity is independent of the number of support vectors. This algorithm can be considered as a gener-\nalization of that of Teo & Vishwanathan (2006), which simulates top-down traversal in the ST. Our algorithm guarantees quadratic time with respect to the size of an input tree in the worst case. Note that a naive implementation using the ESA results in cubic time complexity. Experimental results show the proposed algorithms are also quite efficient in practice."}, {"heading": "1.4. Contributions", "text": "Our study makes the following three contributions:\n1. We propose a linear-time algorithm for constructing an enhanced suffix arrays for a tree (Section 3). 2. We propose a linear-time algorithm for computing the subpath kernel (Section 4). 3. We present a fast algorithm for making predictions with the subpath kernel whose time complexity does not depend on the number of support vectors (Section 5)."}, {"heading": "2. Subpath Kernel for Unordered Trees", "text": "Kimura et al. (2011) proposed a tree kernel on the basis subpaths to capture vertical substructures responsible for hierarchical information in trees. Formally, a subpath is a substring of a path from the root to one of the leaves (Fig 1(c)). By using subpaths, they proposed a kernel function between two trees T1 and T2 as\nK(T1, T2) \u2261 \u2211 p\u2208P \u03bb|p|num(T1p)num(T2p), (1)\nwhere P is the set of all subpaths in T1 and T2, and num(T1p) and num(T2p) are the number of times a subpath p \u2208 P appears in T1 and T2, respectively. \u03bb (0 < \u03bb \u2264 1) is a constant giving an exponentially decaying weight to each subpath p, according to its length |p|.\nKimura et al. pointed out that there is a one-to-one correspondence between a subpath and a prefix of a suffix of a tree. Intuitively, a prefix of a suffix of a tree is a reversed subpath (whose formal definition is given in Section 3). They utilized this fact, and computed\nK(T1, T2) = \u2211 s\u2208S \u03bb|s|num(T1s)num(T2s) (2)\nby extending the idea of multi-key quicksort instead of computing Eq. (1) directly, where S is the set of all prefixes of suffixes in T1 and T2. The time complexity of their algorithm is O((|T1|+ |T2|)log(|T1|+ |T2|)) on average, and O((|T1|+ |T2|)2) in the worst case.\nIn Section 4, we will improve this result to O(|T1| + |T2|), even in the worst case, by using the ESA for trees proposed in Section 3."}, {"heading": "3. Efficient Data Structure for Unordered Trees", "text": "First, we review the suffix tree and ESA for a tree. Both of them are essential for constructing fast algorithms for the subpath kernel in Section 4. Then, we propose a novel algorithm for constructing the ESA in linear time."}, {"heading": "3.1. Suffix Trees and Enhaced Suffix Arrays for a Tree", "text": "Let T be a rooted tree consisting of n nodes, whose node labels are drawn from alphabet \u03a3 of size \u03c3 = |\u03a3|. The i-th suffix of T (denoted by Si) is the string associated with the path from the i-th node to the root of T . For a string s, each substring beginning with the first character is called a prefix. The suffix tree (ST) of a tree T is a patricia trie for all suffixes of T (Fig. 3(a)), where a common prefix of suffixes is associated with a pass from the root to an internal node. Although ST provides fast access to any suffix of the tree, it is known that it requires a large amount of memory, and hence, it is inefficient for practical purposes. The ESA (Abouelhoda et al., 2004) is a more spaceefficient data structure that allows many of the operations provided by the ST, and therefore, it is often used in many practical applications instead of the ST.\nThe ESA of a tree T consists of two data structures, a suffix array (SA) and an lcp array (LCP). The suffix array SA[1, |T |] is an array of integers that maintains the starting positions of lexicographically ordered suffixes. The lcp array LCP[1, |T |] is an array of integers that stores the lengths of the longest common prefixes of the adjacent suffixes in the SA, that is, LCP[i] \u2261 lcp(SSA[i], SSA[i+1]) for 1 \u2264 i < |T |, and LCP[|T |] \u2261 \u22121, where lcp(s, t) denotes the longest common prefix of two strings s and t. The LCP provides information about the depth of internal nodes of\nthe ST. We present an example of the SA and LCP in Fig 3(b)."}, {"heading": "3.2. Linear-time construction algorithm of an ESA for a tree", "text": "There exists a linear-time algorithm that constructs an ESA for a string (Ka\u0308rkka\u0308inen & Sanders, 2003). However, to the best of our knowledge, there is no algorithm for constructing an ESA for a tree in linear time. Therefore, we propose an O(|T |) algorithm for constructing an ESA for a tree T , which is described as Algorithm 1. Our algorithm is designed by carefully combining two algorithms, namely, the skew algorithm for ESA construction of strings (Ka\u0308rkka\u0308inen & Sanders, 2003) and the linear-time construction algorithm of an SA for a tree (Ferragina et al., 2005). The following theorem guarantees that this algorithm constructs an ESA of a tree in linear time.\nTheorem 1 Algorithm 1 constructs the ESA for a tree T in O(|T |) time.\nAlgorithm 1 Constructing the ESA for a tree T in O(|T |) time Input: Tree T Output: SA[1, |T |] and LCP[1, |T |] for T 1. Apply Algorithm 1 recursively to a tree T \u2032 obtain SA1[1, |T \u2032|] and LCP1[1, |T \u2032|], where T \u2032 consists of some of the nodes in T whose depth is not equal to d in modulo 3 2. Construct SA2[1, |T |\u2212|T \u2032|] for nodes whose depth is equal to d in modulo 3 by using SA1[1, |T \u2032|] 3. Construct SA[1, |T |] by merging SA1[1, |T \u2032|] and SA2[1, |T | \u2212 |T \u2032|] 4. Construct LCP[1, |T |] by using LCP1[1, |T \u2032|], SA1[1, |T \u2032|], and SA[1, |T |] return SA[1, |T |] and LCP[1, |T |]\nIn what follows, we give how the algorithm works and a skech of the proof of Thorem 1 by construction.\nAlgorithm 1 works recursively; it calls itself to construct an ESA for tree T \u2032, whose size is at most 2|T |3 (in Step 1). We focus only on the suffixes starting at nodes whose depths are not equal to d \u2208 {0, 1, 2} in modulo 3, and apply the radix sorting to them using only the first three labels in each suffix. The parameter d is appropriately chosen so that the number of nodes staring at depth d (in modulo 3) is at least |T |/3. Next, we rename the label of each node with the rank of the suffix starting at the node in the sorting result, and construct T \u2032 whose size is at most 2|T |/3. If the all of the renamed node labels are different, their order directly gives the order of suffixes (SA1[1, |T \u2032|]). Oth-\nerwise, the algorithm calls itself to construct an ESA for tree T \u2032.\nIn Step 2, it constructs an SA for the nodes not included in the ESA of T \u2032. This can be done in O(|T |) time by the radix sort using the first two node labels. (Note that we already know the order of the second node label from SA1[1, |T \u2032|].) In Step 3, it constructs an SA for T by merging the (E)SA obtained in Step 1 and the SA obtained in Step 2. This can be done in O(|T |) time (Ferragina et al., 2005).\nThe key to the linear-time construction is in Step 4, which is originated from the algorithm of Ka\u0308rkka\u0308inen and Sanders (2003) for updating the LCP for strings. Let k and l be k \u2261 SA[i] and l \u2261 SA[i + 1] for T , respectively. There are two possible cases: (i) neither of the depths of k and l is equal to d in modulo 3, or (ii) either of them is equal to d in modulo 3.\nIn the first case, k and l are both included in T \u2032. Let k\u2032 and l\u2032 be the nodes in T \u2032 corresponding to k and l, respectively. We can know the positions of k\u2032 and l\u2032 in SA1[1, |T \u2032|] by using a reversed suffix array (RSA), which is defined as RSA[SA[i ]] \u2261 i . Note that the RSA can also be constructed in linear time. Without loss of generality, we assume that RSA[k\u2032] < RSA[l\u2032]. Since k and l are adjacent in SA[1, |T |], k\u2032 and l\u2032 are also adjacent in SA1[1, |T \u2032|]. Since we already have LCP1[1, |T \u2032|], we obtain m = lcp(k\u2032, l\u2032) = LCP1[RSA[k\n\u2032]] with a constant time by accessing LCP1[1, |T \u2032|]. Then, we can calculate LCP[i] = 3m + lcp(anc(k, 3m), anc(l, 3m)), where anc(vi, j) returns the j-th ancestor of node vi. Note that three successive node labels in T is renamed with one character in T \u2032. In the case with trees, we need preprocessing for all nodes T to achieve O(1)access to their arbitrary ancestor nodes (whereas this is trivial in strings by using the indices). This problem is called the level ancestor problem. It can be solved by O(|T |) preprocessing (Bender & Farach-Colton, 2004). Since the lcp(anc(k, 3m), anc(l, 3m)) is at most 2, we can obtain the value in constant time. Consequently, we can compute LCP[i] in O(1) time after O(|T |) preprocessing.\nIn the latter case, while at least one of k and l is not included in T \u2032, anc(k, z) and anc(l, z) (z \u2208 {1, 2}) are both included in T \u2032. In contrast with the previous case, k\u2032 and l\u2032 are not necessarily adjacent in SA1[1, |T \u2032|]. However, we can obtain m = lcp(k\u2032, l\u2032) = RMQ(LCP1[1, |T \u2032|],RSA[k \u2032],RSA[l \u2032]\u22121 ), where RMQ(Array, x , y) returns the minimum value of Array[i] (x \u2264 i \u2264 y). This problem is called the range minimum query, and it can be solved in O(1) time after O(|T |) preprocessing. Consequently, we can compute LCP[i] in O(1) time after O(|T |) preprocessing.\nIn conclusion, we can compute LCP[1, |T |] in O(|T |) time, and hence the total running time of the algorithm represented as f(T ) = f(2|T |/3) + O(|T |) = O(|T |)."}, {"heading": "4. Linear-time Algorithm for Computing the Subpath Kernel", "text": "We propose a linear-time algorithm for computing the subpath kernel (2) by using the ESA for the trees introduced in Section 3. The proposed algorithm consists of the following three steps.\n1. Add special terminal characters $1 and $2 ($1 < $2) just above the root nodes of T1 and T2, respectively; then, merge the two trees. (We assume that $1 and $2 are lexicographically smaller than any character in \u03a3.) 2. Construct an ESA for the merged tree by using Algorithm 1. 3. Calculate Eq. (2) by simulating bottom-up traversal in the ST for the merged tree, with the ESA.\nFirst, the algorithm merges the input trees T1 and T2 in Step 1, in which the special terminal characters are added to ensure that no suffix can be a prefix of any other suffix. Next, it constructs the ESA for the merged tree using Algorithm 1 in linear time. Finally, it calculates Eq. (2) with the ESA. Since Eq. (2) can be calculated by enumerating all the common prefixes of suffixes in T1 and T2, it can be computed as\nK(T1, T2) = \u2211\nv\u2208STin\n(W[depth(v)]\u2212W[depth(parent(v))])\n\u00d7 lvs(T1v)lvs(T2v),\nby a bottom-up traversal of the ST for the merged tree. In the above equation, STin denotes the set of inner nodes in ST, depth(v) denotes the depth of node v, parent(v) denotes the parent node of v, and lvs(T1v) denotes the number of leaves belonging to T1 among the leaves of the subtree rooted at v. W is an array whose elements are defined as W[n] \u2261 \u2211n i=1 \u03bb\ni , where \u03bb is the decaying rate in Eq. (2). Since we constructed an ESA instead of a ST, we use the ESA to simulate bottom-up traversals in the ST (Kasai et al., 2001). Algorithm 2 shows the pseudocode of a bottomup traversal in the ST and calculation of Eq. (2) with the ESA. Since the number of nodes in the ST for a T is 2|T | at most, Algorithm 2 runs in O(|T1| + |T2|) time. Figure 4 shows an example of (a) the merged tree obtained in Step 1, (b) the ST for the merged tree, and (c) the ESA for the merged tree.\nThe following theorem shows that the three steps listed above compute the subpath kernel (2) in linear time.\nTheorem 2 The proposed algorithm computes the subpath kernel (2) for T1 and T2 in O(|T1|+ |T2|) time.\nProof 1 We can merge T1 and T2 in O(1) time in Step 1. In Step 2, Algorithm 1 constructs the ESA in O(|T1|+ |T2|) time. Finally, Algorithm 2 computes Eq. (2) in O(|T1|+|T2|) time. Therefore, the total time complexity of the proposed algorithm is O(|T1|+ |T2|).\nAlgorithm 2 Algorithm for computing Eq. (2) inO(|T1|+ |T2|)"}, {"heading": "5. Fast Prediction", "text": "A serious drawback in applying kernel methods to large-scale data sets is that we need to evaluate a kernel function between an input data T and all the support vectors Ti (i = 1, ...,m) in the prediction phase. For the subpath kernel, prediction for a tree T needs\nto evaluate f(T ) = m\u2211 i=1 \u03b1iK(Ti, T )\n= \u2211\ns\u2032\u2208PSi \u2211 s\u2208PS ( m\u2211 i=1 \u03b1inum(Ti s) ) \u03bb|s|\u03b4(s\u2032, s), (3)\nwhere PSi and PS are the set of all prefixes of suffixes in Ti and T , respectively. Note that Eq. (3) is identical to the one of Teo and Vishwanathan (2006) when {Ti}i and T are strings. They proposed a sophisticated O(|T |)-time algorithm whose running time does not depend on the number of support vectors. We briefly describe the algorithm. The computation of Eq. (3) comes down to finding the longest common prefix (lcp) between Si and the \u201cmaster string\u201d, which is the concatenation of all the strings corresponding to the support vectors. First, the algorithm constructs an ESA of the master string, Then, when an input string T comes, the algorithm simulates a top-down traversal of a ST with the ESA to find the lcp between Si and the master string. The algorithm utilizes the fact that li \u2265 li\u22121 \u2212 1, where li is the length of the lcp between Si and the master string. This implies that we can skip the first li\u22121 characters and start comparison from the next character when we find li.\nWe extend their algorithm to trees. First, we construct an ESA for the \u201cmaster tree\u201d obtained by concatenating all the support vector trees. Then, when an input tree T comes, the algorithm simulates a top-down traversal of a ST with the ESA to find the lcp between Si and the master tree. The difference from the previous algorithm is in its skipping strategy. Since node i may have more than one children in trees, li \u2265 max lCh(i) \u2212 1 holds, where Ch(i) is the set of children of node i. Thus, we can skip max lCh(i) \u2212 1 nodes when we find li. The following theorem guarantees that the prediction for a newly coming tree T is computed in O(|T |2) time in the worst case.\nTheorem 3 The time complexity of prediction for a tree T is O(|T |2).\nProof 2 We evaluate the total length which we traverse the ST to find all the lcp between Si and the master tree.\u2211 i:max lCh(i)=0 (li + 1) + \u2211 i:max lCh(i) 6=0 (li \u2212max lCh(i) + 2)\n\u2264 2|T |+ \u2211\ni:li 6=max lSib(i)\nli\n\u2264 2|T |+ (L\u2212 1)H \u2264 O(|T |2).\nFor any node i satisfying max lCh(i) = 0, we cannot skip any node; hence, we have to walk down the ST of\nthe master tree (corresponding to the first term in the first line). For any node i satisfying max lCh(i) 6= 0, we can skip max lCh(i) \u2212 1 nodes (the second term in the first line). Sib(i) in the right term in the second line denotes the siblings of node i. Since the number of nodes in this term is L \u2212 1 (where L is the number of leaves in T ) and li is upper bounded by H(= maxdepth(T )), the time complexity is upper bounded by O(|T |2).\nNote that the time complexity of the algorithm becomes O(|T |) for some trees (for example, when either L or H is bounded by a constant). Finally, we point out that the algorithms in Section 4 and this section can also be applied to the route kernel (Aiolli et al., 2009) for ordered trees."}, {"heading": "6. Experiments", "text": "We demonstrate the performance of the linear time algorithm for the subpath kernel and the fast computation algorithm in the prediction phase.\nFirst, we compare the execution time of the proposed linear-time algorithm (denoted by \u2018Proposed\u2019) with that of the existing algorithm of Kimura et al. (2011) (\u2018Multikey\u2019) for the subpath kernel. We also compare them with the the linear-time tree kernel (Teo & Vishwanathan, 2006) (\u2018Vishwanathan\u2019) implemented by Teo and Vishwanathan2.\nNext, we examine the execution time of the algorithm in the prediction phase (denoted by \u2018Prediction\u2019). We study the effect of the size of an input tree and the number of support vectors. We also compare the execution time with the direct computation of Eq. (3) (\u2018Direct\u2019) and the linear-time tree kernel (Teo & Vishwanathan, 2006) (\u2018Vishwanathan\u2019).\nWe run all the experiments on an Intel Core2 Duo 2.40GHz system with 4GB of main memory under Windows Vista. For all the kernels we use in the experiments, we set \u03bb = 1 in Eq. (2) since the choice does not affect the computation time."}, {"heading": "6.1. Experiment 1: Fast kernel evaluation", "text": "We compare the execution times using three real data sets, including one XML data set (Zaki & Aggarwal, 2006) and two glycan data sets (Hashimoto et al., 2003; Doubet & Albersheim, 1992). Table 1 lists the statistics of these datasets.\nWe measured the average computation time needed for a single evaluation of each kernel function. Figure 5 (a) shows the average times of \u2018Proposed\u2019, \u2018Multikey\u2019, and \u2018Vishwanathan\u2019 for the three datasets. The\n2http://users.cecs.anu.edu.au/~chteo/SASK.html\nresults show that our proposed linear-time algorithm is consistently the fastest, which shows that our kernel is quite efficient in practice as well as in theory.\nNext, we examine the scalability of the algorithms with artificial datasets. We fixed the label size at 5, and we varied the tree size. Figure 5 (b) shows the average times of the three algorithms. Again, our proposed linear-time algorithm outperforms the others."}, {"heading": "6.2. Experiment 2: Fast prediction", "text": "We compare the execution times in the prediction phase with the XML dataset. We give all support vectors a uniform weight of \u03b1i = 1.\nFirst, we study the effect of the number of support vectors. We merge the first 100 XML data to make an input tree. We use the other XML data as support vectors, and vary the number of support vectors. Figure 6 (a) shows the average times of \u2018Prediction\u2019, \u2018Direct\u2019, and \u2018Vishwanathan\u2019. The results show that the execution times of Prediction and Vishwanathan are not dependent on the number of support vectors, whereas that of Direct scales linearly.\nNext, we study the effect of the size of an input tree on the \u2019Prediction\u2019 algorithm. We fix the number of support vectors at 100, and we vary the size of an input tree. Figure 6 (b) shows the average times of Prediction. Although the time complexity of the algorithm\nis theoretically quadratic with respect to the size of an input tree in the worst case, the execution time scales linearly in practice."}, {"heading": "7. Related Work", "text": "Since Haussler (1999) introduced the framework of the convolution kernel, various kernel functions for trees have been proposed. The first tree kernel was proposed for parse trees by Collins and Duffy (Collins & Duffy, 2001), and then, it was generalized for labeled ordered trees (Kashima & Koyanagi, 2002; Kuboyama et al., 2006), syntactic trees (Daume\u0301 III & Marcu, 2004), and positional trees (Aiolli et al., 2009). However, all these kernels (explicitly or implicitly) exploit edge order information at each node in their definitions or algorithms, and therefore, they cannot be directly applied to unordered trees. For unordered trees, a hardness result for tree kernels using general treestructured features was shown by Kashima (2007). Vishwanathan et al. (2003) proposed an efficient linear-time kernel based on subtrees. While this kernel can be computed efficiently with the ESA for strings, it is pointed out that its predictive performance is usually worse than that of the other tree kernels in the previous work of Aiolli et al. (2009). Kimura et al. (2011) proposed another tree kernel for unordered trees using vertical substructures called subpaths."}, {"heading": "8. Conclusion", "text": "In this paper, we focused on the subpath kernel for unordered trees proposed by Kimura et al. (2011), and we proposed a linear-time algorithm for computing it with an enhanced suffix array for trees. To achieve the desired time complexity, we proposed, for the first time, a linear-time algorithm for constructing an enhanced suffix array for trees. In addition, we presented a fast algorithm for prediction, which is independent of the number of support vectors because it exploits the algorithm of (Teo & Vishwanathan, 2006). Exper-\nimental results showed that the proposed algorithm is faster than the existing algorithm, and its practical running time scales linearly in practice. Moreover, the running time in prediction is independent of the number of support vectors. A possible future development is to combine the subpath kernel with a fast training framework of SVM with kernels. Recently, Severyn and Moschitti (2011) proposed a fast training algorithm for structured kernels with a cutting plane method, which might be applied for the subpath kernel."}, {"heading": "Acknowledgments", "text": "This work was supported by MEXT KAKENHI 80545583."}], "references": [{"title": "Replacing suffix trees with enhanced suffix arrays", "author": ["M.I. Abouelhoda", "S. Kurtz", "E. Ohlebusch"], "venue": "J. Discrete Algorithms,", "citeRegEx": "Abouelhoda et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Abouelhoda et al\\.", "year": 2004}, {"title": "Route kernels for trees", "author": ["F. Aiolli", "Martino", "G. Da San", "A. Sperduti"], "venue": "In ICML,", "citeRegEx": "Aiolli et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Aiolli et al\\.", "year": 2009}, {"title": "The level ancestor problem simplified. Theo", "author": ["M.A. Bender", "M. Farach-Colton"], "venue": "Compute. Sci.,", "citeRegEx": "Bender and Farach.Colton,? \\Q2004\\E", "shortCiteRegEx": "Bender and Farach.Colton", "year": 2004}, {"title": "Fast algorithms for sorting and searching strings", "author": ["J.L. Bentley", "R. Sedgewick"], "venue": "In SODA,", "citeRegEx": "Bentley and Sedgewick,? \\Q1997\\E", "shortCiteRegEx": "Bentley and Sedgewick", "year": 1997}, {"title": "LIBSVM: a library for support vector machines", "author": ["Chang", "C.-C", "Lin", "C.-J"], "venue": null, "citeRegEx": "Chang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2001}, {"title": "Convolution kernels for natural language", "author": ["M. Collins", "N. Duffy"], "venue": "In NIPS,", "citeRegEx": "Collins and Duffy,? \\Q2001\\E", "shortCiteRegEx": "Collins and Duffy", "year": 2001}, {"title": "A tree-position kernel for document compression", "author": ["H. Daum\u00e9 III", "D. Marcu"], "venue": "In DUC,", "citeRegEx": "III and Marcu,? \\Q2004\\E", "shortCiteRegEx": "III and Marcu", "year": 2004}, {"title": "Structuring labeled trees for optimal succinctness, and beyond", "author": ["P. Ferragina", "F. Luccio", "G. Manzini", "S. Muthukrishnan"], "venue": "In FOCS,", "citeRegEx": "Ferragina et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Ferragina et al\\.", "year": 2005}, {"title": "On graph kernels: Hardness results and efficient alternatives", "author": ["T. G\u00e4rtner", "P. Flach", "S. Wrobel"], "venue": "In COLT,", "citeRegEx": "G\u00e4rtner et al\\.,? \\Q2003\\E", "shortCiteRegEx": "G\u00e4rtner et al\\.", "year": 2003}, {"title": "Glycan: The database of carbohydrate structures", "author": ["K. Hashimoto", "M. Hamajima", "S. Goto", "S. Masumoto", "M. Kawashima", "M. Kanehisa"], "venue": "In GIW,", "citeRegEx": "Hashimoto et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Hashimoto et al\\.", "year": 2003}, {"title": "Convolution kernels on discrete structures", "author": ["D. Haussler"], "venue": "Technical Report UCSC-CRL-99-10, University of Calfornia in Santa Cruz,", "citeRegEx": "Haussler,? \\Q1999\\E", "shortCiteRegEx": "Haussler", "year": 1999}, {"title": "Simple linear work suffix array construction", "author": ["J. K\u00e4rkk\u00e4inen", "P. Sanders"], "venue": "In ICALP,", "citeRegEx": "K\u00e4rkk\u00e4inen and Sanders,? \\Q2003\\E", "shortCiteRegEx": "K\u00e4rkk\u00e4inen and Sanders", "year": 2003}, {"title": "Linear-time longest-common-prefix computation in suffix arrays and its applications", "author": ["T. Kasai", "G. Lee", "H. Arimura", "S. Arikawa", "K. Park"], "venue": "CPM,", "citeRegEx": "Kasai et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Kasai et al\\.", "year": 2001}, {"title": "Machine Learning Approaches for Structureddata", "author": ["H. Kashima"], "venue": "PhD thesis, Kyoto University,", "citeRegEx": "Kashima,? \\Q2007\\E", "shortCiteRegEx": "Kashima", "year": 2007}, {"title": "Kernels for semi-structured data", "author": ["H. Kashima", "T. Koyanagi"], "venue": "In ICML,", "citeRegEx": "Kashima and Koyanagi,? \\Q2002\\E", "shortCiteRegEx": "Kashima and Koyanagi", "year": 2002}, {"title": "Marginalized kernels between labeled graphs", "author": ["H. Kashima", "K. Tsuda", "A. Inokuchi"], "venue": "In ICML,", "citeRegEx": "Kashima et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kashima et al\\.", "year": 2003}, {"title": "A subpath kernel for rooted unordered trees", "author": ["D. Kimura", "T. Kuboyama", "T. Shibuya", "H. Kashima"], "venue": "In PAKDD,", "citeRegEx": "Kimura et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kimura et al\\.", "year": 2011}, {"title": "A gram distribution kernel applied to glycan classification and motif extraction", "author": ["T. Kuboyama", "K. Hirata", "K.F. Aoki-Kinoshita", "H. Kashima", "H. Yasuda"], "venue": "In GIW,", "citeRegEx": "Kuboyama et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kuboyama et al\\.", "year": 2006}, {"title": "The spectrum kernel: a string kernel for SVM protein classification", "author": ["C. Leslie", "E. Eskin", "W.S. Noble"], "venue": "In PSB,", "citeRegEx": "Leslie et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Leslie et al\\.", "year": 2002}, {"title": "Text classification using string kernels", "author": ["H. Lodhi", "C. Saunders", "J. Shawe-Taylor", "N. Cristianini", "C. Watkins"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Lodhi et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Lodhi et al\\.", "year": 2002}, {"title": "Efficient convolution kernels for dependency and constituent syntactic trees", "author": ["A. Moschitti"], "venue": "In ECML,", "citeRegEx": "Moschitti,? \\Q2006\\E", "shortCiteRegEx": "Moschitti", "year": 2006}, {"title": "Learning with Kernels", "author": ["B. Sch\u00f6lkopf", "A.J. Smola"], "venue": null, "citeRegEx": "Sch\u00f6lkopf and Smola,? \\Q2002\\E", "shortCiteRegEx": "Sch\u00f6lkopf and Smola", "year": 2002}, {"title": "Fast support vector machines for structural kernels", "author": ["A. Severyn", "A. Moschitti"], "venue": "In ECML PKDD,", "citeRegEx": "Severyn and Moschitti,? \\Q2011\\E", "shortCiteRegEx": "Severyn and Moschitti", "year": 2011}, {"title": "Constructing the suffix tree of a tree with a large alphabet", "author": ["T. Shibuya"], "venue": "IEICE Trans,", "citeRegEx": "Shibuya,? \\Q2003\\E", "shortCiteRegEx": "Shibuya", "year": 2003}, {"title": "Tree sequence kernel for natural language", "author": ["J. Sun", "M. Zhang", "C.L. Tan"], "venue": "In AAAI,", "citeRegEx": "Sun et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2011}, {"title": "Fast and space efficient string kernels using suffix arrays", "author": ["C.H. Teo", "S.V.N. Vishwanathan"], "venue": "In ICML,", "citeRegEx": "Teo and Vishwanathan,? \\Q2006\\E", "shortCiteRegEx": "Teo and Vishwanathan", "year": 2006}, {"title": "Fast kernels for string and tree matching", "author": ["S.V.N. Vishwanathan", "A. Smola"], "venue": "In NIPS,", "citeRegEx": "Vishwanathan and Smola,? \\Q2003\\E", "shortCiteRegEx": "Vishwanathan and Smola", "year": 2003}, {"title": "Xrules: An effective structural classifier for xml data", "author": ["M.J. Zaki", "C.C. Aggarwal"], "venue": "Mach. Learn.,", "citeRegEx": "Zaki and Aggarwal,? \\Q2006\\E", "shortCiteRegEx": "Zaki and Aggarwal", "year": 2006}], "referenceMentions": [{"referenceID": 16, "context": "Kimura et al. (2011) proposed a kernel function for unordered trees on the basis of their subpaths, which are vertical substructures of trees responsible for hierarchical information in them.", "startOffset": 0, "endOffset": 21}, {"referenceID": 16, "context": "Kimura et al. (2011) proposed a kernel function for unordered trees on the basis of their subpaths, which are vertical substructures of trees responsible for hierarchical information in them. Their kernel exhibits practically good performance in terms of accuracy and speed; however, lineartime computation is not guaranteed theoretically, unlike the case of the other unordered tree kernel proposed by Vishwanathan and Smola (2003). In this paper, we propose a theoretically guaranteed linear-time kernel computation algorithm that is also practically fast, and we present an efficient prediction algorithm whose running time depends only on the size of the input tree.", "startOffset": 0, "endOffset": 433}, {"referenceID": 10, "context": "A framework called the convolution kernel (Haussler, 1999) is widely used for designing kernel functions for structured data, where the structured data are (implicitly) decomposed into substructures, and a kernel function is defined as the sum of kernel functions among the substructures.", "startOffset": 42, "endOffset": 58}, {"referenceID": 19, "context": "In the framework of the convolution kernel, various kernel functions have been proposed for sequences (Lodhi et al., 2002; Leslie et al., 2002), trees (Collins & Duffy, 2001; Kashima & Koyanagi, 2002; Aiolli et al.", "startOffset": 102, "endOffset": 143}, {"referenceID": 18, "context": "In the framework of the convolution kernel, various kernel functions have been proposed for sequences (Lodhi et al., 2002; Leslie et al., 2002), trees (Collins & Duffy, 2001; Kashima & Koyanagi, 2002; Aiolli et al.", "startOffset": 102, "endOffset": 143}, {"referenceID": 1, "context": ", 2002), trees (Collins & Duffy, 2001; Kashima & Koyanagi, 2002; Aiolli et al., 2009), and graphs (Kashima et al.", "startOffset": 15, "endOffset": 85}, {"referenceID": 15, "context": ", 2009), and graphs (Kashima et al., 2003; G\u00e4rtner et al., 2003).", "startOffset": 20, "endOffset": 64}, {"referenceID": 8, "context": ", 2009), and graphs (Kashima et al., 2003; G\u00e4rtner et al., 2003).", "startOffset": 20, "endOffset": 64}, {"referenceID": 20, "context": "More recently, various kernels for ordered trees have been proposed (Moschitti, 2006; Kuboyama et al., 2006; Aiolli et al., 2009; Sun et al., 2011).", "startOffset": 68, "endOffset": 147}, {"referenceID": 17, "context": "More recently, various kernels for ordered trees have been proposed (Moschitti, 2006; Kuboyama et al., 2006; Aiolli et al., 2009; Sun et al., 2011).", "startOffset": 68, "endOffset": 147}, {"referenceID": 1, "context": "More recently, various kernels for ordered trees have been proposed (Moschitti, 2006; Kuboyama et al., 2006; Aiolli et al., 2009; Sun et al., 2011).", "startOffset": 68, "endOffset": 147}, {"referenceID": 24, "context": "More recently, various kernels for ordered trees have been proposed (Moschitti, 2006; Kuboyama et al., 2006; Aiolli et al., 2009; Sun et al., 2011).", "startOffset": 68, "endOffset": 147}, {"referenceID": 4, "context": "The first tree kernel was proposed by Collins and Duffy (2001) for parse trees, and it was then extended to general ordered trees (Kashima & Koyanagi, 2002).", "startOffset": 38, "endOffset": 63}, {"referenceID": 1, "context": ", 2006; Aiolli et al., 2009; Sun et al., 2011). Among the existing tree kernels, only a few kernels can handle unordered trees (Fig. 1(a)). In their seminal work, Vishwanathan and Smola (2003) proposed an efficient kernel for unordered trees.", "startOffset": 8, "endOffset": 193}, {"referenceID": 9, "context": "Figure 2 shows the experimental comparison of the predictive accuracy of their kernel with that of four other tree kernels using three datasets, including one XML dataset (Zaki & Aggarwal, 2006) and two glycan datasets (Hashimoto et al., 2003; Doubet & Albersheim, 1992).", "startOffset": 219, "endOffset": 270}, {"referenceID": 20, "context": "tion using the enhanced suffix array (ESA) for strings was proposed by Teo and Vishwanathan (2006). More recently, Kimura et al.", "startOffset": 71, "endOffset": 99}, {"referenceID": 13, "context": "More recently, Kimura et al. (2011) proposed another tree kernel using vertical substructures called subpaths.", "startOffset": 15, "endOffset": 36}, {"referenceID": 8, "context": "Figure 2 shows the experimental comparison of the predictive accuracy of their kernel with that of four other tree kernels using three datasets, including one XML dataset (Zaki & Aggarwal, 2006) and two glycan datasets (Hashimoto et al., 2003; Doubet & Albersheim, 1992). Note that three kernels were designed by Kashima & Koyanagi (2002), Moschitti (2006) and Aiolli et al.", "startOffset": 220, "endOffset": 339}, {"referenceID": 8, "context": "Figure 2 shows the experimental comparison of the predictive accuracy of their kernel with that of four other tree kernels using three datasets, including one XML dataset (Zaki & Aggarwal, 2006) and two glycan datasets (Hashimoto et al., 2003; Doubet & Albersheim, 1992). Note that three kernels were designed by Kashima & Koyanagi (2002), Moschitti (2006) and Aiolli et al.", "startOffset": 220, "endOffset": 357}, {"referenceID": 1, "context": "Note that three kernels were designed by Kashima & Koyanagi (2002), Moschitti (2006) and Aiolli et al. (2009) for ordered trees; hence, we used the order information appearing in the datasets as it is.", "startOffset": 89, "endOffset": 110}, {"referenceID": 1, "context": "Note that three kernels were designed by Kashima & Koyanagi (2002), Moschitti (2006) and Aiolli et al. (2009) for ordered trees; hence, we used the order information appearing in the datasets as it is. The results show that the subpath kernel proposed by Kimura et al. (2011) is competitive with the other kernels.", "startOffset": 89, "endOffset": 276}, {"referenceID": 1, "context": "Note that three kernels were designed by Kashima & Koyanagi (2002), Moschitti (2006) and Aiolli et al. (2009) for ordered trees; hence, we used the order information appearing in the datasets as it is. The results show that the subpath kernel proposed by Kimura et al. (2011) is competitive with the other kernels. Interestingly, the subpath kernel and the kernel proposed by Vishwanathan and Smola (2003) work complementarily.", "startOffset": 89, "endOffset": 406}, {"referenceID": 16, "context": "(c) Subpath features of Kimura et al. . Kimura et al. (2011) also showed that their subpath kernel is practically fast and that it is competitive with the linear-time kernel (Teo & Vishwanathan, 2006).", "startOffset": 24, "endOffset": 61}, {"referenceID": 16, "context": "(c) Subpath features of Kimura et al. . Kimura et al. (2011) also showed that their subpath kernel is practically fast and that it is competitive with the linear-time kernel (Teo & Vishwanathan, 2006). However, despite its practical usefulness, the time complexity of the subpath kernel is theoretically O(nlogn) on average, and it is O(n) in the worst case, where n is the sum of the sizes of the input trees, because their algorithm for computing the kernel uses the multi-key quick sort (Bentley & Sedgewick, 1997). Moreover, in contrast to the lineartime kernel (Vishwanathan & Smola, 2003; Teo & Vishwanathan, 2006), we need to evaluate the subpath kernel between a given tree and all the support vectors in the prediction phase, which is a We used LIBSVM (Chang & Lin, 2001) as the SVM implementation. The accuracy is measured using 10-fold cross-validation. Kernels by Kimura et al. (2011) and Moschitti (2006) have tunable weight parameters, which were also tuned by cross-validation.", "startOffset": 24, "endOffset": 897}, {"referenceID": 16, "context": "(c) Subpath features of Kimura et al. . Kimura et al. (2011) also showed that their subpath kernel is practically fast and that it is competitive with the linear-time kernel (Teo & Vishwanathan, 2006). However, despite its practical usefulness, the time complexity of the subpath kernel is theoretically O(nlogn) on average, and it is O(n) in the worst case, where n is the sum of the sizes of the input trees, because their algorithm for computing the kernel uses the multi-key quick sort (Bentley & Sedgewick, 1997). Moreover, in contrast to the lineartime kernel (Vishwanathan & Smola, 2003; Teo & Vishwanathan, 2006), we need to evaluate the subpath kernel between a given tree and all the support vectors in the prediction phase, which is a We used LIBSVM (Chang & Lin, 2001) as the SVM implementation. The accuracy is measured using 10-fold cross-validation. Kernels by Kimura et al. (2011) and Moschitti (2006) have tunable weight parameters, which were also tuned by cross-validation.", "startOffset": 24, "endOffset": 918}, {"referenceID": 20, "context": "(2011) is competitive with the three other kernels (Vishwanathan & Smola, 2003; Kashima & Koyanagi, 2002; Moschitti, 2006; Aiolli et al., 2009).", "startOffset": 51, "endOffset": 143}, {"referenceID": 1, "context": "(2011) is competitive with the three other kernels (Vishwanathan & Smola, 2003; Kashima & Koyanagi, 2002; Moschitti, 2006; Aiolli et al., 2009).", "startOffset": 51, "endOffset": 143}, {"referenceID": 14, "context": "The subpath kernel proposed by Kimura et al. (2011) is competitive with the three other kernels (Vishwanathan & Smola, 2003; Kashima & Koyanagi, 2002; Moschitti, 2006; Aiolli et al.", "startOffset": 31, "endOffset": 52}, {"referenceID": 23, "context": "The suffix tree (ST) of trees (Shibuya, 2003) is a potential candidate.", "startOffset": 30, "endOffset": 45}, {"referenceID": 15, "context": "Proposed methods By improving the result of Kimura et al. (2011), we aim to develop (i) a theoretically guaranteed lineartime kernel computation algorithm that is practically fast, and (ii) an efficient prediction algorithm whose running time depends only on the size of the input tree.", "startOffset": 44, "endOffset": 65}, {"referenceID": 0, "context": ", Abouelhoda et al. (2004)).", "startOffset": 2, "endOffset": 27}, {"referenceID": 0, "context": "The ESA (Abouelhoda et al., 2004) is a more spaceefficient data structure that allows many of the operations provided by the ST, and therefore, it is often used in many practical applications instead of the ST.", "startOffset": 8, "endOffset": 33}, {"referenceID": 7, "context": "Our algorithm is designed by carefully combining two algorithms, namely, the skew algorithm for ESA construction of strings (K\u00e4rkk\u00e4inen & Sanders, 2003) and the linear-time construction algorithm of an SA for a tree (Ferragina et al., 2005).", "startOffset": 216, "endOffset": 240}, {"referenceID": 7, "context": "This can be done in O(|T |) time (Ferragina et al., 2005).", "startOffset": 33, "endOffset": 57}, {"referenceID": 7, "context": "This can be done in O(|T |) time (Ferragina et al., 2005). The key to the linear-time construction is in Step 4, which is originated from the algorithm of K\u00e4rkk\u00e4inen and Sanders (2003) for updating the LCP for strings.", "startOffset": 34, "endOffset": 185}, {"referenceID": 12, "context": "Since we constructed an ESA instead of a ST, we use the ESA to simulate bottom-up traversals in the ST (Kasai et al., 2001).", "startOffset": 103, "endOffset": 123}, {"referenceID": 25, "context": "(3) is identical to the one of Teo and Vishwanathan (2006) when {Ti}i and T are strings.", "startOffset": 31, "endOffset": 59}, {"referenceID": 1, "context": "Finally, we point out that the algorithms in Section 4 and this section can also be applied to the route kernel (Aiolli et al., 2009) for ordered trees.", "startOffset": 112, "endOffset": 133}, {"referenceID": 16, "context": "First, we compare the execution time of the proposed linear-time algorithm (denoted by \u2018Proposed\u2019) with that of the existing algorithm of Kimura et al. (2011) (\u2018Multikey\u2019) for the subpath kernel.", "startOffset": 138, "endOffset": 159}, {"referenceID": 9, "context": "Experiment 1: Fast kernel evaluation We compare the execution times using three real data sets, including one XML data set (Zaki & Aggarwal, 2006) and two glycan data sets (Hashimoto et al., 2003; Doubet & Albersheim, 1992).", "startOffset": 172, "endOffset": 223}, {"referenceID": 17, "context": "The first tree kernel was proposed for parse trees by Collins and Duffy (Collins & Duffy, 2001), and then, it was generalized for labeled ordered trees (Kashima & Koyanagi, 2002; Kuboyama et al., 2006), syntactic trees (Daum\u00e9 III & Marcu, 2004), and positional trees (Aiolli et al.", "startOffset": 152, "endOffset": 201}, {"referenceID": 1, "context": ", 2006), syntactic trees (Daum\u00e9 III & Marcu, 2004), and positional trees (Aiolli et al., 2009).", "startOffset": 73, "endOffset": 94}, {"referenceID": 8, "context": "Since Haussler (1999) introduced the framework of the convolution kernel, various kernel functions for trees have been proposed.", "startOffset": 6, "endOffset": 22}, {"referenceID": 1, "context": ", 2006), syntactic trees (Daum\u00e9 III & Marcu, 2004), and positional trees (Aiolli et al., 2009). However, all these kernels (explicitly or implicitly) exploit edge order information at each node in their definitions or algorithms, and therefore, they cannot be directly applied to unordered trees. For unordered trees, a hardness result for tree kernels using general treestructured features was shown by Kashima (2007). Vishwanathan et al.", "startOffset": 74, "endOffset": 419}, {"referenceID": 1, "context": ", 2006), syntactic trees (Daum\u00e9 III & Marcu, 2004), and positional trees (Aiolli et al., 2009). However, all these kernels (explicitly or implicitly) exploit edge order information at each node in their definitions or algorithms, and therefore, they cannot be directly applied to unordered trees. For unordered trees, a hardness result for tree kernels using general treestructured features was shown by Kashima (2007). Vishwanathan et al. (2003) proposed an efficient linear-time kernel based on subtrees.", "startOffset": 74, "endOffset": 447}, {"referenceID": 1, "context": ", 2006), syntactic trees (Daum\u00e9 III & Marcu, 2004), and positional trees (Aiolli et al., 2009). However, all these kernels (explicitly or implicitly) exploit edge order information at each node in their definitions or algorithms, and therefore, they cannot be directly applied to unordered trees. For unordered trees, a hardness result for tree kernels using general treestructured features was shown by Kashima (2007). Vishwanathan et al. (2003) proposed an efficient linear-time kernel based on subtrees. While this kernel can be computed efficiently with the ESA for strings, it is pointed out that its predictive performance is usually worse than that of the other tree kernels in the previous work of Aiolli et al. (2009). Kimura et al.", "startOffset": 74, "endOffset": 727}, {"referenceID": 1, "context": ", 2006), syntactic trees (Daum\u00e9 III & Marcu, 2004), and positional trees (Aiolli et al., 2009). However, all these kernels (explicitly or implicitly) exploit edge order information at each node in their definitions or algorithms, and therefore, they cannot be directly applied to unordered trees. For unordered trees, a hardness result for tree kernels using general treestructured features was shown by Kashima (2007). Vishwanathan et al. (2003) proposed an efficient linear-time kernel based on subtrees. While this kernel can be computed efficiently with the ESA for strings, it is pointed out that its predictive performance is usually worse than that of the other tree kernels in the previous work of Aiolli et al. (2009). Kimura et al. (2011) proposed another tree kernel for unordered trees using vertical substructures called subpaths.", "startOffset": 74, "endOffset": 749}, {"referenceID": 16, "context": "In this paper, we focused on the subpath kernel for unordered trees proposed by Kimura et al. (2011), and we proposed a linear-time algorithm for computing it with an enhanced suffix array for trees.", "startOffset": 80, "endOffset": 101}, {"referenceID": 20, "context": "Recently, Severyn and Moschitti (2011) proposed a fast training algorithm for structured kernels with a cutting plane method, which might be applied for the subpath kernel.", "startOffset": 22, "endOffset": 39}], "year": 2012, "abstractText": "The kernel method is a popular approach to analyzing structured data such as sequences, trees, and graphs; however, unordered trees have not been investigated extensively. Kimura et al. (2011) proposed a kernel function for unordered trees on the basis of their subpaths, which are vertical substructures of trees responsible for hierarchical information in them. Their kernel exhibits practically good performance in terms of accuracy and speed; however, lineartime computation is not guaranteed theoretically, unlike the case of the other unordered tree kernel proposed by Vishwanathan and Smola (2003). In this paper, we propose a theoretically guaranteed linear-time kernel computation algorithm that is also practically fast, and we present an efficient prediction algorithm whose running time depends only on the size of the input tree. Experimental results show that the proposed algorithms are quite efficient in practice.", "creator": " TeX output 2012.05.15:1039"}}}