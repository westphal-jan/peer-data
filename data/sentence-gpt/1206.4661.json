{"id": "1206.4661", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Predicting accurate probabilities with a ranking loss", "abstract": "In many real-world applications of machine learning classifiers, it is essential to predict the probability of an example belonging to a particular class. This paper proposes a simple technique for predicting probabilities based on optimizing a ranking loss, followed by isotonic regression. This semi-parametric technique offers both good ranking and regression performance, and models a richer set of probability distributions than statistical workhorses such as logistic regression.\n\n\nThe technique is presented in a paper titled \u201cThe Role of Machine Learning in Machine Learning in Learning Systems.\u201d The paper has been submitted in this issue and has received a number of contributions. The authors acknowledge their contributions in their research. The authors further acknowledge the contribution of the field's support department.", "histories": [["v1", "Mon, 18 Jun 2012 15:30:13 GMT  (218kb)", "http://arxiv.org/abs/1206.4661v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["aditya krishna menon", "xiaoqian jiang", "shankar vembu", "charles elkan", "lucila ohno-machado"], "accepted": true, "id": "1206.4661"}, "pdf": {"name": "1206.4661.pdf", "metadata": {"source": "META", "title": "Predicting accurate probabilities with a ranking loss", "authors": ["Aditya Krishna Menon", "Xiaoqian Jiang", "Shankar Vembu", "Charles Elkan", "Lucila Ohno-Machado"], "emails": ["AKMENON@UCSD.EDU", "XLJIANG@UCSD.EDU", "SHANKAR.VEMBU@UTORONTO.CA", "ELKAN@UCSD.EDU", "MACHADO@UCSD.EDU"], "sections": [{"heading": "1. Introduction", "text": "Classification is the problem of learning a mapping from examples to labels, with the goal of categorizing future examples into one of several classes. However, many realworld applications instead require that we estimate the probability of an example having a particular label. For example, when studying the click behaviour of ads in computational advertising, it is essential to model the probability of an ad being clicked, rather than just predicting whether or not it will be clicked (Richardson et al., 2007). Accurate probabilities are also essential for medical screening tools to trigger early assessment and admission to an ICU (Subbe et al., 2001).\nIn this paper, we propose a simple semi-parametric model for predicting accurate probabilities that uses isotonic regression in conjunction with scores derived from optimizing a ranking loss. We analyze theoretically and empiri-\nAppearing in Proceedings of the 29th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\ncally where our approach can provide more reliable estimates than standard statistical workhorses for probability estimation, such as logistic regression. The model attempts to achieve good ranking (in an area under ROC sense) and regression (in a squared error sense) performance simultaneously, which is important in many real-world applications (Sculley, 2010). Further, our model is much less expensive to train than full-blown nonparametric methods, such as kernel logistic regression. It is thus an appealing choice in situations where parameteric models are employed for probability estimation, such as medical informatics and credit scoring.\nThe paper is organized as follows. First, we provide motivating examples for predicting probabilities, and define the fundamental concept of proper losses. We then review existing methods used to predict probabilities, and discuss their limitations. Next, we detail our method to estimate probabilities, based on optimizing a ranking loss and feeding the results into isotonic regression. Finally, we provide experimental results on real-world datasets to validate our analysis and to test the efficacy of our method.\nWe first fix our notation. We focus on probability estimation for examples x \u2208 X with labels y \u2208 {0,1}. Each x has a conditional probability function \u03b7(x) := Pr[y = 1|x]. For our purposes, a model is some deterministic mapping s\u0302 : X \u2192R. A probabilistic model \u03b7\u0302 is a model whose outputs are in [0,1], and may be derived by composing a model with a link function f : R\u2192 [0,1]. The scores of a model may be thresholded to give a classifier y\u0302 : X \u2192{0,1}. We assume s\u0302 is learned from a training set {(xi,yi)}ni=1 of n iid draws from X \u00d7{0,1}."}, {"heading": "2. Background and motivation", "text": "Classically, the supervised learning literature has focussed on the scenario where we want to minimize the number of misclassified examples on test data. However, practical\napplications of machine learning models often have more complex constraints and requirements, which demand that we output the probability of an example possessing a label. Examples of such applications include:\nBuilding meta-classifiers, where the output of a model is fed to a meta-classifier that uses additional domain knowledge to make a prediction. For example, doctors prefer to use a classifier\u2019s prediction as evidence to aid their own decision-making process (Manickam & Abidi, 1999). In such scenarios, it is essential that the classifier assess the confidence in its predictions being correct, which may be captured using probabilities;\nUsing predictions to take actions, such as deciding whether or not to contact a person for a marketing campaign. Such actions have an associated utility that is to be maximized, and maximization of expected utility is most naturally handled by estimating probabilities rather than making hard decisions (Zadrozny & Elkan, 2001);\nNon-standard learning tasks, where problem constraints demand estimating uncertainty. For example, in the task of learning from only positive and unlabelled examples, training a probabilistic model that distinguishes labelled versus unlabelled examples is a provably (under some assumptions) sufficient strategy (Elkan & Noto, 2008).\nIntuitively, probability estimates \u03b7\u0302(\u00b7) are accurate if, on average, they are close to the true probability \u03b7(\u00b7). Quantifying \u201cclose to\u201d requires picking some sensible discrepancy measure, and this idea is formalized by the theory of proper loss functions, which we now discuss. A model for binary classification uses a loss function ` : {0,1}\u00d7R\u2192 R+ to measure the discrepancy between a label y and the model\u2019s prediction s\u0302 for some example x. If our model outputs probability estimates \u03b7\u0302 by transforming scores with a link function f (\u00b7), we may equivalently think of there being a probabilistic loss `P(\u00b7, \u00b7) such that `(y, s\u0302) = `P(y, f (s\u0302)). The empirical error of s\u0302 with respect to the loss ` is\nEemp(s\u0302(\u00b7)) = 1 n\nn\n\u2211 i=1 `(yi, s\u0302(xi)),\nwhich is a surrogate for the generalization error\nE (s\u0302(\u00b7)) = ExEy|x`(y, s\u0302(x)) = Ex [\u03b7(x)`(1, s\u0302(x))+(1\u2212\u03b7(x))`(0, s\u0302(x))] := ExL`(\u03b7(x), s\u0302(x)). (1)\nThe term L`(\u03b7 , s\u0302) is a measure of discrepancy between an example\u2019s probability of being positive and its predicted score. Let s\u2217(\u03b7) = argmins L`(\u03b7 ,s). Then, we call a loss function ` Bayes consistent (Buja et al., 2005) if for every \u03b7 \u2208 [0,1], s\u2217(\u03b7) \u00b7 (\u03b7 \u2212 12 ) \u2265 0, meaning that we have the same sign as the optimal prediction under the 0-1 loss `(y, s\u0302) = 1[ys\u0302 \u2264 0]. If s\u2217(\u03b7) is invertible,\nthen (s\u2217)\u22121(s\u2217(\u03b7)) = \u03b7 , so that the optimal scores are some transformation of \u03b7(x). In such cases, we call the corresponding probabilistic loss `P a proper (or Fisherconsistent) loss (Buja et al., 2005), and say that ` corresponds to a proper loss.\nMany commonly used loss functions, such as square loss `(y, s\u0302) = (y\u2212 s\u0302)2, and logistic loss `(y, s\u0302) = log(1 + e\u2212(2y\u22121)s\u0302), correspond to a proper loss function. Thus, a model with good regression performance according to squared error, say, can be thought to yield meaningful probability estimates. The hinge loss of SVMs, `(y, s\u0302) = max(0,1\u2212 (2y\u22121)s\u0302), is Bayes consistent but does not correspond to a proper loss function, which is why SVMs do not output meaningful probabilities (Platt, 1999)."}, {"heading": "3. Analysis of existing paradigms to learn accurate probabilities", "text": "We now analyze two major paradigms for probability estimation, and study their possible failure modes."}, {"heading": "3.1. Optimization of a proper loss", "text": "A direct approach to predicting probabilities is to optimize a proper loss function on the training data using some hypothesis class, e.g. linear separators. Examples include logistic regression and linear regression (after truncation to [0,1]), which are instances of the generalized linear model framework, which assumes E[y|x] = f (wT x) for some link function f (\u00b7). The loss-dependent error measure, L`(\u03b7 , s\u0302), is one metric by which we can choose amongst proper losses. For example, the discrepancy measures for square and logistic loss are (Zhang, 2004)\nLsquare(\u03b7 , s\u0302) = (\u03b7\u2212 s\u0302)2 +C1 (2) Llogistic(\u03b7 , s\u0302) = KL ( \u03b7 \u2223\u2223\u2223\u2223 1\n1+ e\u2212s\u0302\n) +C2, (3)\nwhere KL denotes the Kullback-Leibler divergence, and C1,C2 are independent of the prediction s\u0302. Based on this, Zhang (2004) notes that logistic regression has difficulty when \u03b7(x)(1\u2212\u03b7(x)) \u2248 0 for some x, by virtue of requiring |s\u0302(x)| \u2192 \u221e. This has been observed in practical uses of logistic regression with imbalanced classes (King & Zeng, 2001; Foster & Stine, 2004), with the latter proposing the use of linear regression as a more robust alternative."}, {"heading": "3.2. Post-processing methods", "text": "A distinct strategy is to train a model in some manner, and then extract probability estimates from it in a postprocessing step. Three popular techniques of this type are Platt scaling (Platt, 1999), binning (Zadrozny & Elkan, 2001), and isotonic regression (Zadrozny & Elkan, 2002). We focus on the latter, as it is more flexible than the former\ntwo approaches by virtue of being nonparametric, and has been shown to work well empirically for a range of input models (Niculescu-Mizil & Caruana, 2005).\nIsotonic regression is a nonparametric technique to find a monotone fit to a set of target values. In a learning context, the method was used in (Zadrozny & Elkan, 2002) to learn meaningful probabilities from the scores of an input model. Mathematically, suppose we have predictions {s\u0302i}ni=1 from some input model, with corresponding true labels {yi}ni=1, and WLOG suppose that s\u03021 \u2264 s\u03022 \u2264 . . .\u2264 s\u0302n. Then, isotonic regression learns scores {s\u0303i}ni=1 via the optimization\nmin s\u03031,...,s\u0303n\nn\n\u2211 i=1 (yi\u2212 s\u0303i)2 : s\u0303i \u2264 s\u0303i+1 \u2200 i \u2208 {1, . . . ,n\u22121}.\nThis finds the best monotone fit to the training labels (as ordered by the input model\u2019s scores) in a squared loss sense. (In fact, the optimal solution will minimize any proper loss (Bru\u0308mmer & Preez, 2007).) If the input scores {s\u0302i} are sorted, then there is an O(n) algorithm to solve this problem, called pool adjacent violators (PAV) (Barlow et al., 1972).\nWhen yi \u2208 {0,1}, it is easy to verify that s\u0303i \u2208 [0,1], so that the result is a probabilistic model. Indeed, isotonic regression can be thought of as nonparametrically learning a monotone link function f (\u00b7) to create a probabilistic model f (s\u0302(\u00b7)). However, the resulting model is only defined on the training examples, and we need to define some interpolation scheme to make predictions on future examples. One natural scheme is a linear interpolation between the training scores (Cosslett, 1983). Observe that isotonic regression preserves the ordering of the input model\u2019s scores, although potentially introducing ties i.e. f (s\u0302(\u00b7)) is not injective. To break ties on training examples, we may simply refer to the corresponding original model\u2019s scores. Linear interpolation breaks most ties1 on test examples."}, {"heading": "3.3. Possible failure modes", "text": "There are at least two main reasons why the above paradigms may not yield accurate probabilities:\nMisspecification. In practice, simple models based on parametric assumptions will often be misspecified: for example, logistic regression assumes the parametric form \u03b7(x) = 1/(1+ e\u2212wT x) for some w, but this assumption may not always hold. While we cannot learn \u03b7(x) if we cannot represent it in our hypothesis class, Equation 1 says that our model\u2019s predictions will in expectation be close to \u03b7(x) according to some discrepancy measure. It is possible for a model like logistic regression to be correctly specified\n1If the training example with largest score has corresponding isotonic regression prediction of 1, every test example with a larger score will also have a prediction of 1.\nup to the choice of link function, i.e. \u03b7(x) = f (wT x), but f (\u00b7) is not the sigmoid function. The maximum likelihood estimates of a generalized linear model with a misspecified link function are known to be asymptotically biased (Czado & Santner, 1992). Isotonic regression alleviates this particular type of misspecification, but is still vulnerable if its input scores are misspecified.\nA natural defense against misspecification is using a nonparametric method such as kernel logistic regression (KLR). This model will be able to learn any measurable \u03b7(x) with a universal kernel (Zhang, 2004). In many practical applications, such methods are seen as too expensive to both train (requiring O(n3) time (Zhu & Hastie, 2005)) and test (requiring O(n) time to make a prediction, since the weights on training examples generally have full support, unlike a kernel SVM).\nFinite-sample effects. When optimizing an unregularized proper loss on a finite training set of n examples, the probability estimates may be biased. Indeed, the finite sample MLE for the parameters of a generalized linear model (such as logistic regression) have a bias of O(1/n) (Cordeiro & McCullagh, 1991), and thus the probability estimates are also biased. King and Zeng (2001) show that the constant in the O(\u00b7) depends on the imbalance in the classes, meaning that logistic regression can give biased probability estimates when attempting to model a rare event. It is possible to perform bias correction explicitly via a post-hoc modification of the learned parameters (King & Zeng, 2001), or implicitly by choosing a Jeffrey\u2019s prior regularizer (Firth, 1993).\nSimilarly, isotonic regression may overfit even if the input scores give a good ranking on test data. This can happen when there are \u201cgaps\u201d amongst the input scores. The simplest example is when the largest input score s\u0302max is associated with a positive label. Assuming there is only one example with this score, isotonic regression will predict the probability for any test example with score \u2265 s\u0302max to be 1, which is too optimistic and will likely be a poor model in this region of input space. The problem arises because we have insufficient representation of scores in [s\u0302max,\u221e)."}, {"heading": "4. Extracting probabilities from a ranker", "text": "The semi-parametric route of isotonic regression is appealing because it involves a simple post-processing step, while strictly enhancing the hypothesis class of the input model. For this reason, we focus on this semi-parametric paradigm in what follows. Our hope is to design a model that is at least as accurate, and not much more difficult to train than workhorses such as logistic regression.\nTo use isotonic regression to get accurate estimates, we must specify what scores we will feed it as input. We may\nthus ask what characteristics such scores should possess so as to yield accurate probability estimates. We make the simple observation that isotonic regression interacts with the scores of the input model in only one way: it uses them to enforce the monotonicity constraint on the output. Thus, intuitively, isotonic regression will perform well when the (pairwise) ranking of the original scores is good, and so this should be our objective when training our input model. We now attempt to formalize this intuition, and present our proposed method."}, {"heading": "4.1. Isotonic regression and ranking performance", "text": "The real-valued score that a model assigns to each example may be used to rank examples according to confidence of having a positive label. The pairwise ranking performance of a model may be measured using the area under the ROC curve (AUC), being the probability that a randomly drawn positive example has a higher score than a randomly drawn negative example. It is formally defined below.\nDefinition 1. (Cle\u0301menc\u0327on et al., 2006) The AUC A (s\u0302(\u00b7)) of a model s\u0302 : X \u2192 R is\nA (s\u0302(\u00b7)) = Pr (x1,y1),(x2,y2) [s\u0302(x1)\u2265 s\u0302(x2)|y1 = 1,y2 = 0].\nWe henceforth think of a model s\u0302(\u00b7) as equivalently representing a ranker of examples. A natural quantity to study is the model s\u0302(\u00b7) that induces the Bayes-optimal ranker, meaning A (s\u0302(\u00b7)) \u2265 A (s\u0303(\u00b7)). Intuitively, we expect this optimal ranker to be \u03b7(x), or some (strictly) monotone transform c(\u00b7) thereof, and indeed this may be proven (Cle\u0301menc\u0327on et al., 2006). Therefore, finding accurate probabilities can conceptually be cast as finding accurate ranking, and then recovering the correct transformation c(\u00b7).\nWe may now show that isotonic regression applied to a Bayes-optimal ranker (in the sense of AUC performance) will recover the true probabilities, by inferring the c(\u00b7) discussed above. This can be proven by observing that isotonic regression returns calibrated scores (see e.g. (Kalai & Sastry, 2009) for a proof). Calibration of probability estimates is defined as follows.\nDefinition 2. (Schervish, 1989) We say that a model s\u0302 is calibrated if, for every \u03b1 \u2208 s\u0302[X ], \u03b1 = Pr[y = 1|s\u0302 = \u03b1].\nWe now show that calibration and Bayes-optimal AUC performance implies accuracy of estimates.\nProposition 1. Let the model s\u0302 be a Bayes-optimal ranker, meaning A (s\u0302(\u00b7)) \u2265 A (s\u0303(\u00b7)) for every model s\u0303. Then, if s\u0302 is calibrated, s\u0302(x) = \u03b7(x) for all x.\nProof. Recall that for an optimal ranker, s\u0302(x) = c(\u03b7(x)) for some strictly monotone c(\u00b7). Let S = s\u0302[X ]. If s\u0302 is cali-\nbrated, then by definition\nPr[y = 1|c(\u03b7(x)) = s] = s , \u2200s \u2208 S.\nAny strictly monotone transformation c(\u00b7) must have an inverse c\u22121(\u00b7). Thus the above may be rewritten as\nPr[y = 1|\u03b7(x) = c\u22121(s)] = s , \u2200s \u2208 S.\nBut we know that \u03b7(x) is a calibrated predictor:\nPr[y = 1|\u03b7(x) = c\u22121(s)] = c\u22121(s) , \u2200s \u2208 S.\nTherefore, c\u22121(s) = s for all s, meaning c(s) = s, and thus, s\u0302(x) = \u03b7(x)."}, {"heading": "4.2. Our proposal: ranking loss + isotonic regression", "text": "The above suggests a natural idea: directly optimize the AUC on the training set, and post-process its scores with isotonic regression. This can be viewed as learning a model that has good ranking performance (by virtue of first optimizing a ranking loss) as well as good probability estimation performance (by virtue of isotonic regression optimizing every proper loss). With appropriate handling of ties, isotonic regression enforces strict monotonicity, and so its scores will have the same AUC as the original model. On a finite training set with n+ positive and n\u2212 negative examples, the empirical AUC Aemp can be computed as\nAemp = 1\nn+n\u2212 \u2211i, j 1[s\u0302(xi)\u2265 s\u0302(x j)]yi(1\u2212 y j), (4)\nwhich can be seen to measure the number of concordant pairs in the training set i.e. pairs of examples where the predicted scores respect the ordering according to the label.\nTo maximize AUC, we may follow the pairwise ranking framework (Herbrich et al., 2000; Joachims, 2002), which uses a regularized convex approximation to the RHS of Equation 4:\nmin w \u2211i, j `(s\u0302(x j;w)\u2212 s\u0302(xi;w),1)yi(1\u2212 y j)+\u03bb\u2126(w), (5)\nwhere `(\u00b7, \u00b7) is some convex loss function, and \u2126(\u00b7) is a regularization function with strength \u03bb > 0. We use a linear scoring function2 i.e. s\u0302(x;w) = wT x, for which the regularizer is generally taken to be the `2 norm 12 ||w|| 2 2. While the above loss function nominally requires O(n2) time to compute the gradient, clever algorithms can speed this up (Joachims, 2006). Empirically, it has been observed that stochastic gradient descent on the objective converges in a fraction of an epoch (Sculley, 2009).\n2The ranker may of course be kernelized, but in this case there is no clear reason to eschew kernel logistic regression.\nThe issue of how best to maximize AUC is not settled. For example, Kotlowski et al. (2011) show that the ranking error (viz. 1\u2212A ) of a model can be upper bounded by its balanced logistic loss (viz. the logistic loss balanced by the respective class priors), suggesting that in practice one may approximately maximize AUC using logistic regression. (We say \u201capproximately\u201d because the result only provides a lower bound on the resulting AUC.) Consequently, postprocessing the output of logistic regression with an isotonic regression fit is a worthwhile strategy to explore, and is indeed something we look at in our experiments. (Results such as (King & Zeng, 2001) suggest that logistic regression is not appropriate for imbalanced data because its raw probabilities are biased, not its ranking of examples.)"}, {"heading": "4.3. Justification of model", "text": "Our model operates by finding some s\u0302(x) = wT x that optimizes Equation 5, and then post-processing these scores with isotonic regression. To argue that this model learns something meaningful, we need to show two things: (a) the solution to the convex optimization problem of Equation 5 will (asymptotically) yield a Bayes-optimal ranker, assuming the model is correctly specified, and (b) isotonic regression on top of a Bayes-optimal ranker will recover \u03b7(x). Point (a) can be established if the underlying classification model uses a universal kernel (Cle\u0301menc\u0327on et al., 2006). For a linear kernel, this means that we can learn the optimal ranking if the underlying probability is of the form c(wT x) for some monotone increasing c(\u00b7). Point (b) was established in Section 4.1, and it is further the case that the isotonic regression estimate on a finite training set is consistent, under mild regularity assumptions (Brunk, 1958).\nIf our model is misspecified \u2013 that is, \u03b7(x) is not a monotone transformation of wT x \u2013 then the above analysis does not hold: the optimal ranker and the optimal regressor within our hypothesis class may be different. We can however show the following weaker result about the empirical squared error resulting from our isotonic regression step.\nProposition 2. Suppose a model s\u0302 : X \u2192R has empirical AUC Aemp on a training set with empirical base rate \u03c0\u0302 . Then, there is a model s\u0303 with the same empirical AUC, and empirical square loss at worst 12 \u221a \u03c0\u0302(1\u2212 \u03c0\u0302)(1\u2212Aemp).\nProof. We previously established that isotonic regression will maintain the empirical AUC, and so we focus on the resulting squared error. Recall that the empirical AUC penalizes the number of discordant positive and negative example pairs. We may rewrite it as Aemp = 1\u2212 k/n+n\u2212, so that there are k discordant pairs. Suppose these pairs arise due to a positive and b negative examples, a\u2264 n+,b\u2264 n\u2212. The worst placement of these pairs is if all the a positives have lower scores than the b negatives. In this case, we have\nk = ab, and it is easy to check that the resulting square loss is 1n ab (a+b) . This score is largest when a \u2217 = min(n+,d \u221a\nke), where it attains the value ka \u2217\nn(k+(a\u2217)2) . This may be bounded\nby \u221a\nk 2n , and so the worst possible square loss for isotonic\nregression is \u221a\nn+n\u2212 2(n++n\u2212) \u221a 1\u2212Aemp, proving the claim.\nSince the empirical AUC is concentrated around the true AUC (Agarwal et al., 2005), the above is easily extended to a bound in terms of the true AUC. However, this is still a bound on the training squared error, and so is not a true generalization bound."}, {"heading": "4.4. Comparison to existing methods", "text": "The first step of our method attempts to maximize the pairwise ranking performance, and the isotonic regression step attempts to achieve low squared error. By construction, then, our method attempts to achieve both good ranking and regression (in a squared error sense) performance. Good performance in both metrics is important in many applications, such as computational advertising (Richardson et al., 2007). The idea of learning models with good ranking and regression performance was proposed in the combined regression and ranking (CRR) framework of Sculley (2010). A similar model for logistic loss was proposed by Ertekin and Rudin (2011). The basic idea of such an approach is to simultaneously optimize the ranking and regression losses in a parametric manner, by minimizing a linear combination of both losses. The hope is that this yields \u201cbest of both worlds\u201d performance in these objectives. Empirically, Sculley (2010) observed that generally the AUC obtained from such an approach was no worse than that of optimizing the ranking loss alone, while in some cases there was an improvement in the regression performance. By contrast, while we do make a parametric assumption for the ranking loss, our regression component is nonparametric and hence more powerful. Thus, in light of Sculley (2010)\u2019s finding, we expect to achieve equitable ranking performance to methods like CRR, and better regression performance.\nAs the previous section makes clear, the idea of postprocessing scores with isotonic regression is not new. However, to our knowledge, prior work has not studied the implications of applying this processing to a model that optimizes ranking performance; the idea is hinted at in (Sculley et al., 2011), but not discussed formally. Indeed, we argue that the scores from optimizing a ranking loss are the \u201ccorrect\u201d ones to use as input to isotonic regression, in the sense of recovering the true probability when the ranker is correctly specified. (Previous work has looked at applying isotonic regression to a general ranker that assigns scores to pairs of examples (Flach & Matsubara, 2007), but does not specifically consider finding the optimal pairwise ranker.)\nOur approach is related to the single-index model (Manski, 1975) class of probabilities, Pr[y = 1|x] = f (wT x), where f (\u00b7) is an unknown link function, in contrast to a generalized linear model which assumes a specific link function. The isotonic single-index model is where f (\u00b7) is assumed to be monotone increasing. Many existing methods to learn single-index models rely on some form of iteration between optimizing for w and learning f (\u00b7). For example, the recent Isotron algorithm (Kalai & Sastry, 2009) also uses isotonic regression to provably learn single index models, and relies on alternately updating w via a perceptron-like update, and running PAV to learn f (\u00b7). Our approach does not have similar generalization bounds, but is more direct and timeefficient, as it requires only a single call to the PAV algorithm."}, {"heading": "5. Experimental results", "text": "Our experiments aim to study the conditions under which our method may improve performance over linear or logistic regression, both on synthetic and real-world datasets."}, {"heading": "5.1. Methods compared", "text": "We denote our method by Rank + IR. For comparison, we used linear (LinReg) and logistic (LogReg) regression, as well as the results of post-processing these methods with isotonic regression. We also used the combined regression and ranking model (CRR) of Sculley (2010). We do not post-process CRR because that framework is explicitly designed with the aim of providing a good ranking as well as regression, which we would like to compare to our approach; our hypothesis is that our method should provide the most accurate probabilities, while additionally providing an equitable ranking to the CRR model.\nFollowing Sculley (2010), we use the pairwise ranking framework (Herbrich et al., 2000; Joachims, 2002) with logistic loss to optimize for AUC directly, which lends itself naturally to large-scale implementation using stochastic gradient descent. For this and the CRR model, we used the Sofia-ML package3. All models were regularized. To test the accuracy of probability estimates, where available, we use the domain-specific metric of interest e.g. overall utility, else we measure the mean squared error between test labels and model predictions."}, {"heading": "5.2. Results on synthetic dataset", "text": "We first study the performance of our proposed method on a synthetic dataset, to see the conditions under which we can expect it to improve performance over existing methods. In particular, we study the performance of various methods\n3http://code.google.com/p/sofia-ml/\nwhere the true probability model is\nPr[y = 1|x;w] = a1[wT x < 0]+ (1\u2212a)1[wT x\u2265 0],\nwhere 0\u2264 a\u2264 12 controls the floor and ceiling of the probability distribution. Such capped distributions arise in e.g. item response theory (Hambleton et al., 1991), where the probability of a student answering a question correctly is bounded from below by the success rate of random guessing. Logistic regression is misspecified for this link, although for a = 0 the sigmoid is a reasonable approximation, while for a = 12 the probability is independent of x and thus can be modelled entirely by a bias term.\nWe proceed as follows: we first pick some value for a, and drawn n samples in R2 from N (0, I). We then draw their corresponding labels, and train the various methods. We then create a separate test set through this same procedure, and evaluate the squared error of each model\u2019s predictions to the true probabilities of the data points (as opposed to the labels for these points.) We repeat the process multiple times and find the average error. We do this for a \u2208 {2\u22129,2\u22127, . . . ,2\u22121}.\nOur results for n = 1000 samples are shown in Figure 1. As expected, at the endpoints of a\u2192 0+ and a = 12 , we see that there is not much to choose between the methods. However, for intermediate values of a, logistic regression\u2019s performance severely deteriorates. Post-processing these scores with isotonic regression reliably estimates the floor and ceiling of the link function, and significantly improves performance. Using our method, where we post-process the scores obtained from a ranking loss, we get a small further boost in performance."}, {"heading": "5.3. Results on real-world datasets", "text": "We provide experimental results on datasets drawn from the three motivating problems described in Section 2.\nHospital Discharge. The first dataset is from medical informatics (El-Kareh et al., 2010), where the goal is to predict follow-up errors on microbiology cultures. Predicting the probability of an example having a follow-up error helps an expert determine an appropriate action to take.\nThere are 8668 examples with 10 features, and we create 20 random 80\u2212 20 train-test splits. Table 1 shows that our method does manage to achieve both good regression and ranking performance. Interestingly, isotonic regression slightly worsens the MSE for both linear and logistic regression, suggesting that the majority of the error arises from the basic parametric model for ranking examples itself, rather than the choice of link function.\nKDDCup \u201998. The second dataset is from the 1998 KDD Cup4. Here, the goal is to predict how much a individual will donate, so as to decide whether to contact them for a mail campaign (which costs money). The final utility measure is the expected profit in dollars if one contacts all individuals that the model predicts will donate (the profit takes into account the cost of contacting each individual). The data consists of 95,412 training examples and 96,367 test examples. We follow the strategy of (Zadrozny & Elkan, 2001): we selected the 15 features it recommends, compute the probability an individual will respond to the campaign, and then compute the expected donation given a response.\nTable 2 summarizes the utility of the compared methods, as well as the AUC for the label of whether a person donates or not, on the provided test set. Our method gets an additional profit of around $300 over logistic regression, along with a small improvement in AUC. Such additional revenue may be important in practice, especially with a larger pool of candidate donors. (Note that IR sometimes modifies AUC of the input model; this is because regularization strength is picked based on utility, rather than AUC.)\nGCAT. Lastly, we consider a classification scenario where the training set comprises only positive and unlabelled data. Based on (Elkan & Noto, 2008), one way to solve this is to\n4http://www.kdnuggets.com/meetings/kdd98/ kdd-cup-98.html\npredict the probability of an example being labelled, call this Pr[l = 1|x], based on which we can estimate the probability that it is positive by the identity Pr[y = 1|x] = Pr[l = 1|x]/c, where c = Pr[l = 1|y = 1] may be estimated by taking the average value of Pr[l = 1|x] on the positive examples. We simulate this scenario on the GCAT dataset5, comprising 23,149 examples and 47,236 features: we construct a training set by first picking 30% of the positives (which are assigned a positive label), and then 80% of the other examples (which are treated as unlabelled). We report the primary error measures in this problem, MSE and AUC in distinguishing positive versus negative examples.\nTable 3 summarizes the results from 20 random train-test splits. We see that post-processing logistic regression significantly improves the MSE performance over logistic regression and CRR, indicating the sigmoid link function is misspecified for this problem. Our method manages to further improve MSE, while achieving equitable ranking to other methods.\nOverall, on all three datasets, we see our method achieves both good ranking and regression performance, and on the KDDCup and GCAT datasets manages to improve overall regression performance. Note that logistic and linear regression are strong baselines, and that even small improvements in performance may be significant in practical applications (Sculley, 2010)."}, {"heading": "6. Conclusion and future work", "text": "Many real-world applications of predictive models require predicting accurate probabilities of class membership. We studied the principles behind predicting accurate probabilities, and proposed a simple method to achieve it. Our method is based on post-processing the results of a model that optimizes a ranking loss with isotonic regression. The model is shown to have good empirical performance. In the future, it would be interesting to study the theoretical properties of the model more closely, and evaluate the model in other scenarios requiring probability estimates."}, {"heading": "Acknowledgements", "text": "XJ and LOM were funded in part by the National Library of Medicine (R01LM009520) and NHLBI (U54 HL10846).\n5http://vikas.sindhwani.org/svmlin.html"}], "references": [{"title": "Generalization Bounds for the Area Under the ROC Curve", "author": ["S. Agarwal", "T. Graepel", "R. Herbrich", "S. Har-Peled", "D. Roth"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Agarwal et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2005}, {"title": "Statistical Inference under Order Restrictions: The Theory and Application of Isotonic Regression", "author": ["R.E. Barlow", "D.J. Bartholomew", "J.M. Bremner", "H.D. Brunk"], "venue": null, "citeRegEx": "Barlow et al\\.,? \\Q1972\\E", "shortCiteRegEx": "Barlow et al\\.", "year": 1972}, {"title": "The PAV-Algorithm optimized binary proper scoring", "author": ["N. Br\u00fcmmer", "J.D. Preez"], "venue": null, "citeRegEx": "Br\u00fcmmer and Preez,? \\Q2007\\E", "shortCiteRegEx": "Br\u00fcmmer and Preez", "year": 2007}, {"title": "On the Estimation of Parameters Restricted by Inequalities", "author": ["H.D. Brunk"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "Brunk,? \\Q1958\\E", "shortCiteRegEx": "Brunk", "year": 1958}, {"title": "Loss Functions for Binary Class Probability Estimation: Structure and Applications", "author": ["A. Buja", "W. Stuetzle", "Y. Shen"], "venue": "Technical report, University of Pennsylvania,", "citeRegEx": "Buja et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Buja et al\\.", "year": 2005}, {"title": "Ranking and empirical minimization of U-statistics", "author": ["S. Cl\u00e9men\u00e7on", "G. Lugosi", "N. Vayatis"], "venue": "The Annals of Statistics,", "citeRegEx": "Cl\u00e9men\u00e7on et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cl\u00e9men\u00e7on et al\\.", "year": 2006}, {"title": "Bias Correction in Generalized Linear Models", "author": ["G.M. Cordeiro", "P. McCullagh"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "Cordeiro and McCullagh,? \\Q1991\\E", "shortCiteRegEx": "Cordeiro and McCullagh", "year": 1991}, {"title": "Distribution-Free Maximum Likelihood Estimator of the Binary Choice", "author": ["S.R. Cosslett"], "venue": "Model. Econometrica,", "citeRegEx": "Cosslett,? \\Q1983\\E", "shortCiteRegEx": "Cosslett", "year": 1983}, {"title": "The effect of link misspecification on binary regression inference", "author": ["C. Czado", "T.J. Santner"], "venue": "Journal of Statistical Planning and Inference,", "citeRegEx": "Czado and Santner,? \\Q1992\\E", "shortCiteRegEx": "Czado and Santner", "year": 1992}, {"title": "Incidence and predictors of microbiology results returning post-discharge and requiring follow-up", "author": ["R. El-Kareh", "C. Roy", "G. Brodsky", "M. Perencevich", "E.G. Poon"], "venue": "Journal of Hospital Medicine,", "citeRegEx": "El.Kareh et al\\.,? \\Q2010\\E", "shortCiteRegEx": "El.Kareh et al\\.", "year": 2010}, {"title": "Learning classifiers from only positive and unlabeled data", "author": ["C. Elkan", "K. Noto"], "venue": "In KDD, pp", "citeRegEx": "Elkan and Noto,? \\Q2008\\E", "shortCiteRegEx": "Elkan and Noto", "year": 2008}, {"title": "Bias Reduction of Maximum Likelihood Estimates", "author": ["D. Firth"], "venue": "Biometrika, 80(1):27\u201338,", "citeRegEx": "Firth,? \\Q1993\\E", "shortCiteRegEx": "Firth", "year": 1993}, {"title": "A simple lexicographic ranker and probability estimator", "author": ["P. Flach", "E. Matsubara"], "venue": "In ECML, pp", "citeRegEx": "Flach and Matsubara,? \\Q2007\\E", "shortCiteRegEx": "Flach and Matsubara", "year": 2007}, {"title": "Variable Selection in Data Mining", "author": ["D.P. Foster", "R.A. Stine"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Foster and Stine,? \\Q2004\\E", "shortCiteRegEx": "Foster and Stine", "year": 2004}, {"title": "Fundamentals of Item Response Theory (Measurement Methods for the Social Science)", "author": ["R.K. Hambleton", "H. Swaminathan", "H.J. Rogers"], "venue": "Sage Publications,", "citeRegEx": "Hambleton et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Hambleton et al\\.", "year": 1991}, {"title": "Large margin rank boundaries for ordinal regression", "author": ["R. Herbrich", "T. Graepel", "K. Obermayer"], "venue": "Advances in Large Margin Classifiers,", "citeRegEx": "Herbrich et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Herbrich et al\\.", "year": 2000}, {"title": "Optimizing search engines using clickthrough data", "author": ["T. Joachims"], "venue": "In KDD, pp", "citeRegEx": "Joachims,? \\Q2002\\E", "shortCiteRegEx": "Joachims", "year": 2002}, {"title": "Training linear SVMs in linear time", "author": ["T. Joachims"], "venue": "In KDD, pp", "citeRegEx": "Joachims,? \\Q2006\\E", "shortCiteRegEx": "Joachims", "year": 2006}, {"title": "The Isotron Algorithm: HighDimensional Isotonic Regression", "author": ["A. Kalai", "R. Sastry"], "venue": "In COLT, pp", "citeRegEx": "Kalai and Sastry,? \\Q2009\\E", "shortCiteRegEx": "Kalai and Sastry", "year": 2009}, {"title": "Logistic Regression in Rare Events Data", "author": ["G. King", "L. Zeng"], "venue": "Political Analysis,", "citeRegEx": "King and Zeng,? \\Q2001\\E", "shortCiteRegEx": "King and Zeng", "year": 2001}, {"title": "Bipartite Ranking through Minimization of Univariate Loss", "author": ["W. Kotlowski", "K. Dembczynski", "E. H\u00fcllermeier"], "venue": "In ICML, pp", "citeRegEx": "Kotlowski et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kotlowski et al\\.", "year": 2011}, {"title": "Experienced Based Medical Diagnostics System Over The World Wide Web (WWW)", "author": ["S. Manickam", "S.S.R. Abidi"], "venue": "In AIAI,", "citeRegEx": "Manickam and Abidi,? \\Q1999\\E", "shortCiteRegEx": "Manickam and Abidi", "year": 1999}, {"title": "Maximum score estimation of the stochastic utility model of choice", "author": ["C.F. Manski"], "venue": "Journal of Econometrics,", "citeRegEx": "Manski,? \\Q1975\\E", "shortCiteRegEx": "Manski", "year": 1975}, {"title": "Predicting good probabilities with supervised learning", "author": ["A. Niculescu-Mizil", "R. Caruana"], "venue": "In ICML, pp", "citeRegEx": "Niculescu.Mizil and Caruana,? \\Q2005\\E", "shortCiteRegEx": "Niculescu.Mizil and Caruana", "year": 2005}, {"title": "Probabilistic Output for Support Vector Machines and Comarisons to Regularized Likelihood Methods", "author": ["J. Platt"], "venue": "Advances in Large Margin Classifiers,", "citeRegEx": "Platt,? \\Q1999\\E", "shortCiteRegEx": "Platt", "year": 1999}, {"title": "Predicting clicks: Estimating the Click-Through Rate for New Ads", "author": ["M. Richardson", "E. Dominowska", "R. Ragno"], "venue": "In WWW,", "citeRegEx": "Richardson et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Richardson et al\\.", "year": 2007}, {"title": "On Equivalence Relationships Between Classification and Ranking Algorithms", "author": ["C. Rudin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Rudin,? \\Q2011\\E", "shortCiteRegEx": "Rudin", "year": 2011}, {"title": "A General Method for Comparing Probability Assessors", "author": ["M.J. Schervish"], "venue": "Annals of Statistics,", "citeRegEx": "Schervish,? \\Q1989\\E", "shortCiteRegEx": "Schervish", "year": 1989}, {"title": "Large Scale Learning to Rank", "author": ["D. Sculley"], "venue": "In NIPS Workshop on Advances in Ranking,", "citeRegEx": "Sculley,? \\Q2009\\E", "shortCiteRegEx": "Sculley", "year": 2009}, {"title": "Combined regression and ranking", "author": ["D. Sculley"], "venue": "In KDD,", "citeRegEx": "Sculley,? \\Q2010\\E", "shortCiteRegEx": "Sculley", "year": 2010}, {"title": "Detecting adversarial advertisements in the wild", "author": ["D. Sculley", "M.E. Otey", "M. Pohl", "B. Spitznagel", "J. Hainsworth", "Y. Zhou"], "venue": "In KDD, pp", "citeRegEx": "Sculley et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sculley et al\\.", "year": 2011}, {"title": "Validation of a modified Early Warning Score in medical admissions", "author": ["C.P. Subbe", "M. Kruger", "P. Rutherford", "L. Gemmel"], "venue": "QJM: An International Journal of Medicine,", "citeRegEx": "Subbe et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Subbe et al\\.", "year": 2001}, {"title": "Learning and making decisions when costs and probabilities are both unknown", "author": ["B. Zadrozny", "C. Elkan"], "venue": "In KDD,", "citeRegEx": "Zadrozny and Elkan,? \\Q2001\\E", "shortCiteRegEx": "Zadrozny and Elkan", "year": 2001}, {"title": "Transforming classifier scores into accurate multiclass probability estimates", "author": ["B. Zadrozny", "C. Elkan"], "venue": "In KDD,", "citeRegEx": "Zadrozny and Elkan,? \\Q2002\\E", "shortCiteRegEx": "Zadrozny and Elkan", "year": 2002}, {"title": "Statistical behavior and consistency of classification methods based on convex risk minimization", "author": ["T. Zhang"], "venue": "Annals of Statistics,", "citeRegEx": "Zhang,? \\Q2004\\E", "shortCiteRegEx": "Zhang", "year": 2004}, {"title": "Kernel Logistic Regression and the Import Vector Machine", "author": ["J. Zhu", "T. Hastie"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "Zhu and Hastie,? \\Q2005\\E", "shortCiteRegEx": "Zhu and Hastie", "year": 2005}], "referenceMentions": [{"referenceID": 25, "context": "For example, when studying the click behaviour of ads in computational advertising, it is essential to model the probability of an ad being clicked, rather than just predicting whether or not it will be clicked (Richardson et al., 2007).", "startOffset": 211, "endOffset": 236}, {"referenceID": 31, "context": "Accurate probabilities are also essential for medical screening tools to trigger early assessment and admission to an ICU (Subbe et al., 2001).", "startOffset": 122, "endOffset": 142}, {"referenceID": 29, "context": "The model attempts to achieve good ranking (in an area under ROC sense) and regression (in a squared error sense) performance simultaneously, which is important in many real-world applications (Sculley, 2010).", "startOffset": 193, "endOffset": 208}, {"referenceID": 4, "context": "Then, we call a loss function ` Bayes consistent (Buja et al., 2005) if for every \u03b7 \u2208 [0,1], s\u2217(\u03b7) \u00b7 (\u03b7 \u2212 1 2 ) \u2265 0, meaning that we have the same sign as the optimal prediction under the 0-1 loss `(y, \u015d) = 1[y\u015d \u2264 0].", "startOffset": 49, "endOffset": 68}, {"referenceID": 4, "context": "In such cases, we call the corresponding probabilistic loss `P a proper (or Fisherconsistent) loss (Buja et al., 2005), and say that ` corresponds to a proper loss.", "startOffset": 99, "endOffset": 118}, {"referenceID": 24, "context": "The hinge loss of SVMs, `(y, \u015d) = max(0,1\u2212 (2y\u22121)\u015d), is Bayes consistent but does not correspond to a proper loss function, which is why SVMs do not output meaningful probabilities (Platt, 1999).", "startOffset": 181, "endOffset": 194}, {"referenceID": 34, "context": "For example, the discrepancy measures for square and logistic loss are (Zhang, 2004)", "startOffset": 71, "endOffset": 84}, {"referenceID": 34, "context": "Based on this, Zhang (2004) notes that logistic regression has difficulty when \u03b7(x)(1\u2212\u03b7(x)) \u2248 0 for some x, by virtue of requiring |\u015d(x)| \u2192 \u221e.", "startOffset": 15, "endOffset": 28}, {"referenceID": 24, "context": "Three popular techniques of this type are Platt scaling (Platt, 1999), binning (Zadrozny & Elkan, 2001), and isotonic regression (Zadrozny & Elkan, 2002).", "startOffset": 56, "endOffset": 69}, {"referenceID": 1, "context": ") If the input scores {\u015di} are sorted, then there is an O(n) algorithm to solve this problem, called pool adjacent violators (PAV) (Barlow et al., 1972).", "startOffset": 131, "endOffset": 152}, {"referenceID": 7, "context": "One natural scheme is a linear interpolation between the training scores (Cosslett, 1983).", "startOffset": 73, "endOffset": 89}, {"referenceID": 34, "context": "This model will be able to learn any measurable \u03b7(x) with a universal kernel (Zhang, 2004).", "startOffset": 77, "endOffset": 90}, {"referenceID": 11, "context": "It is possible to perform bias correction explicitly via a post-hoc modification of the learned parameters (King & Zeng, 2001), or implicitly by choosing a Jeffrey\u2019s prior regularizer (Firth, 1993).", "startOffset": 184, "endOffset": 197}, {"referenceID": 18, "context": "King and Zeng (2001) show that the constant in the O(\u00b7) depends on the imbalance in the classes, meaning that logistic regression can give biased probability estimates when attempting to model a rare event.", "startOffset": 0, "endOffset": 21}, {"referenceID": 5, "context": "(Cl\u00e9men\u00e7on et al., 2006) The AUC A (\u015d(\u00b7)) of a model \u015d : X \u2192 R is", "startOffset": 0, "endOffset": 24}, {"referenceID": 5, "context": "Intuitively, we expect this optimal ranker to be \u03b7(x), or some (strictly) monotone transform c(\u00b7) thereof, and indeed this may be proven (Cl\u00e9men\u00e7on et al., 2006).", "startOffset": 137, "endOffset": 161}, {"referenceID": 27, "context": "(Schervish, 1989) We say that a model \u015d is calibrated if, for every \u03b1 \u2208 \u015d[X ], \u03b1 = Pr[y = 1|\u015d = \u03b1].", "startOffset": 0, "endOffset": 17}, {"referenceID": 15, "context": "To maximize AUC, we may follow the pairwise ranking framework (Herbrich et al., 2000; Joachims, 2002), which", "startOffset": 62, "endOffset": 101}, {"referenceID": 16, "context": "To maximize AUC, we may follow the pairwise ranking framework (Herbrich et al., 2000; Joachims, 2002), which", "startOffset": 62, "endOffset": 101}, {"referenceID": 17, "context": "While the above loss function nominally requires O(n2) time to compute the gradient, clever algorithms can speed this up (Joachims, 2006).", "startOffset": 121, "endOffset": 137}, {"referenceID": 28, "context": "Empirically, it has been observed that stochastic gradient descent on the objective converges in a fraction of an epoch (Sculley, 2009).", "startOffset": 120, "endOffset": 135}, {"referenceID": 20, "context": "For example, Kotlowski et al. (2011) show that the ranking error (viz.", "startOffset": 13, "endOffset": 37}, {"referenceID": 5, "context": "Point (a) can be established if the underlying classification model uses a universal kernel (Cl\u00e9men\u00e7on et al., 2006).", "startOffset": 92, "endOffset": 116}, {"referenceID": 3, "context": "1, and it is further the case that the isotonic regression estimate on a finite training set is consistent, under mild regularity assumptions (Brunk, 1958).", "startOffset": 142, "endOffset": 155}, {"referenceID": 0, "context": "Since the empirical AUC is concentrated around the true AUC (Agarwal et al., 2005), the above is easily extended to a bound in terms of the true AUC.", "startOffset": 60, "endOffset": 82}, {"referenceID": 25, "context": "Good performance in both metrics is important in many applications, such as computational advertising (Richardson et al., 2007).", "startOffset": 102, "endOffset": 127}, {"referenceID": 25, "context": "Good performance in both metrics is important in many applications, such as computational advertising (Richardson et al., 2007). The idea of learning models with good ranking and regression performance was proposed in the combined regression and ranking (CRR) framework of Sculley (2010). A similar model for logistic loss was proposed by Ertekin and Rudin (2011).", "startOffset": 103, "endOffset": 288}, {"referenceID": 25, "context": "Good performance in both metrics is important in many applications, such as computational advertising (Richardson et al., 2007). The idea of learning models with good ranking and regression performance was proposed in the combined regression and ranking (CRR) framework of Sculley (2010). A similar model for logistic loss was proposed by Ertekin and Rudin (2011). The basic idea of such an approach is to simultaneously optimize the ranking and regression losses in a parametric manner, by minimizing a linear combination of both losses.", "startOffset": 103, "endOffset": 364}, {"referenceID": 25, "context": "Good performance in both metrics is important in many applications, such as computational advertising (Richardson et al., 2007). The idea of learning models with good ranking and regression performance was proposed in the combined regression and ranking (CRR) framework of Sculley (2010). A similar model for logistic loss was proposed by Ertekin and Rudin (2011). The basic idea of such an approach is to simultaneously optimize the ranking and regression losses in a parametric manner, by minimizing a linear combination of both losses. The hope is that this yields \u201cbest of both worlds\u201d performance in these objectives. Empirically, Sculley (2010) observed that generally the AUC obtained from such an approach was no worse than that of optimizing the ranking loss alone, while in some cases there was an improvement in the regression performance.", "startOffset": 103, "endOffset": 651}, {"referenceID": 25, "context": "Good performance in both metrics is important in many applications, such as computational advertising (Richardson et al., 2007). The idea of learning models with good ranking and regression performance was proposed in the combined regression and ranking (CRR) framework of Sculley (2010). A similar model for logistic loss was proposed by Ertekin and Rudin (2011). The basic idea of such an approach is to simultaneously optimize the ranking and regression losses in a parametric manner, by minimizing a linear combination of both losses. The hope is that this yields \u201cbest of both worlds\u201d performance in these objectives. Empirically, Sculley (2010) observed that generally the AUC obtained from such an approach was no worse than that of optimizing the ranking loss alone, while in some cases there was an improvement in the regression performance. By contrast, while we do make a parametric assumption for the ranking loss, our regression component is nonparametric and hence more powerful. Thus, in light of Sculley (2010)\u2019s finding, we expect to achieve equitable ranking performance to methods like CRR, and better regression performance.", "startOffset": 103, "endOffset": 1027}, {"referenceID": 30, "context": "mizes ranking performance; the idea is hinted at in (Sculley et al., 2011), but not discussed formally.", "startOffset": 52, "endOffset": 74}, {"referenceID": 22, "context": "Our approach is related to the single-index model (Manski, 1975) class of probabilities, Pr[y = 1|x] = f (wT x), where f (\u00b7) is an unknown link function, in contrast to a generalized linear model which assumes a specific link function.", "startOffset": 50, "endOffset": 64}, {"referenceID": 28, "context": "We also used the combined regression and ranking model (CRR) of Sculley (2010). We do not post-process CRR because that framework is explicitly designed with the aim of providing a good ranking as well as regression, which we would like to compare to our approach; our hypothesis is that our method should provide the most accurate probabilities, while additionally providing an equitable ranking to the CRR model.", "startOffset": 64, "endOffset": 79}, {"referenceID": 15, "context": "Following Sculley (2010), we use the pairwise ranking framework (Herbrich et al., 2000; Joachims, 2002) with logistic loss to optimize for AUC directly, which lends itself naturally to large-scale implementation using stochastic gradient descent.", "startOffset": 64, "endOffset": 103}, {"referenceID": 16, "context": "Following Sculley (2010), we use the pairwise ranking framework (Herbrich et al., 2000; Joachims, 2002) with logistic loss to optimize for AUC directly, which lends itself naturally to large-scale implementation using stochastic gradient descent.", "startOffset": 64, "endOffset": 103}, {"referenceID": 25, "context": "Following Sculley (2010), we use the pairwise ranking framework (Herbrich et al.", "startOffset": 10, "endOffset": 25}, {"referenceID": 14, "context": "item response theory (Hambleton et al., 1991), where the probability of a student answering a question correctly is bounded from below by the success rate of random guessing.", "startOffset": 21, "endOffset": 45}, {"referenceID": 9, "context": "The first dataset is from medical informatics (El-Kareh et al., 2010), where the goal is to predict follow-up errors on microbiology cultures.", "startOffset": 46, "endOffset": 69}, {"referenceID": 29, "context": "Note that logistic and linear regression are strong baselines, and that even small improvements in performance may be significant in practical applications (Sculley, 2010).", "startOffset": 156, "endOffset": 171}], "year": 2012, "abstractText": "In many real-world applications of machine learning classifiers, it is essential to predict the probability of an example belonging to a particular class. This paper proposes a simple technique for predicting probabilities based on optimizing a ranking loss, followed by isotonic regression. This semi-parametric technique offers both good ranking and regression performance, and models a richer set of probability distributions than statistical workhorses such as logistic regression. We provide experimental results that show the effectiveness of this technique on real-world applications of probability prediction.", "creator": "LaTeX with hyperref package"}}}