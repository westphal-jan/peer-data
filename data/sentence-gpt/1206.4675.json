{"id": "1206.4675", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Finding Botnets Using Minimal Graph Clusterings", "abstract": "We study the problem of identifying botnets and the IP addresses which they comprise, based on the observation of a fraction of the global email spam traffic. Observed mailing campaigns constitute evidence for joint botnet membership, they are represented by cliques in the graph of all messages. No evidence against an association of nodes is ever available in the study of this problem.\n\n\n\nAn interesting question arises: What does a botnet really do?\nIf a botnet really was composed of botnets (anonymity or social networks), it is capable of creating a distributed and decentralized network.\nTo summarize, in addition to receiving messages, the botnets might be able to detect and respond to any single attack, for instance by sending multiple messages and sending multiple ones to various groups.\nIn this case, the botnet could also detect and respond to any other malicious attack. Such a response could generate significant amounts of information for the victim and the attacker, as the botnet might be able to detect and respond to any attack without affecting the target.\nGiven that the botnet could be active in the background, the botnet could be capable of creating a network of bots and distributing malicious messages.\nFigure 1: The IP addresses of a botnet.\nFigure 2: The IP addresses of a botnet.\nFigure 3: The IP addresses of a botnet.\nFigure 4: The IP addresses of a botnet.\nFigure 5: The IP addresses of a botnet.\nFigure 6: The IP addresses of a botnet.\nFigure 7: The IP addresses of a botnet.\nFigure 8: The IP addresses of a botnet.\nFigure 9: The IP addresses of a botnet.\nFigure 10: The IP addresses of a botnet.\nFigure 11: The IP addresses of a botnet.\nFigure 12: The IP addresses of a botnet.\nFigure 13: The IP addresses of a botnet.\nFigure 14: The IP addresses of a botnet.\nFigure 15: The IP addresses of a botnet.\nFigure 16: The IP addresses of a botnet.\nFigure 17: The IP addresses of a botnet.\nFigure 18: The IP addresses of a botnet.\nFigure 19: The IP addresses of a botnet.\nFigure 20: The IP addresses of a botnet.\nFigure 21: The IP addresses of a botnet.\nFigure 22: The IP addresses of a botnet.\nFigure 23: The IP", "histories": [["v1", "Mon, 18 Jun 2012 15:36:32 GMT  (391kb)", "http://arxiv.org/abs/1206.4675v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.CR cs.DC cs.LG", "authors": ["peter haider", "tobias scheffer"], "accepted": true, "id": "1206.4675"}, "pdf": {"name": "1206.4675.pdf", "metadata": {"source": "META", "title": "Finding Botnets Using Minimal Graph Clusterings", "authors": ["Peter Haider", "Tobias Scheffer"], "emails": ["haider@cs.uni-potsdam.de", "scheffer@cs.uni-potsdam.de"], "sections": [{"heading": "1. Introduction", "text": "We address the problem of identifying botnets that are capable of exploiting the internet in a coordinated, distributed, and harmful manner. Botnets consist of computers that have been infected with a software virus which allows them to be controlled remotely by a botnet operator. Botnets are used primarily to disseminate email spam, to stage distributed denial-of-service (DDoS) attacks, and to harvest personal information from the users of infected computers (Stern, 2008).\nProviders of computing, storage, and communication services on the internet, law enforcement and prosecution are interested in identifying and tracking these threats. An accurate model of the set of IP addresses over which each existing botnet extends would make it possible to protect services against distributed denial-\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nof-service attacks by selectively denying service requests from the nodes of the offending botnet.\nEvaluating botnet models is difficult, because the ground truth about the sets of IP addresses that constitute each botnet at any given time is entirely unavailable (Dittrich & Dietrich, 2008). Many studies on botnet identification conclude with an enumeration of the conjectured number and size of botnets (Zhuang et al., 2008). Reliable estimates of the current size of one particular botnet require an in-depth analysis of the communication protocol used by the network. For instance, the size of the Storm botnet has been assessed by issuing commands that require all active nodes to respond (Holz et al., 2008). However, once the communication protocol of a botnet is understood, the botnet is usually taken down by law enforcement, and one is again ignorant of the remaining botnets.\nWe develop an evaluation protocol that is guided by the basic scientific principle that a model has to be able to predict future observable events. We focus on email spam campaigns which can easily be observed by monitoring the stream of messages that reach an email service provider. Our evaluation metric quantifies the model\u2019s ability to predict which email spam campaign a given IP address is going to participate in.\nPrevious studies have employed clustering heuristics to aggregate IP addresses that participated in joint campaigns into conjectured botnets (Xie et al., 2008; Zhuang et al., 2008). Because an IP address can be a part of multiple botnets during an observation interval, this approach is intrinsicaly inaccurate. The problem is furthermore complicated as it is possible that a botnet processes multiple campaigns simultaneously, and multiple botnets may be employed for large campaigns. We possess very little background knowledge about whether multiple networks, each of which has been observed to act in a coordinated way, really form one bigger, joint network. Also, distributional assumptions about the generation of the observable events are very hard to motivate. We address this lack of prior knowledge by directly modeling the conditional distri-\nbution of clusterings given the observable data, and by searching for minimal clusterings that refrain from merging networks as long as empirical evidence does not render joint membership in a botnet likely.\nOther studies have leveraged different types of data in order to identify botnets. For example Mori et al. (2010); DiBenedetto et al. (2010) record and cluster fingerprints of the spam-sending hosts\u2019 TCP behavior, exploiting that most bot types use their own protocol stacks with unique characteristics. Yu et al. (2010) identify bot-generated search traffic from query and click logs of a search engine by detecting shifts in the query and click distributions compared to a background model. Another angle to detect bots is to monitor traffic from a set of potentially infected hosts and find clusters in their outgoing and incoming packets (Gu et al., 2008; John et al., 2009); for example, DNS requests of bots used to connect to control servers (Choi et al., 2009) or IRC channel activity (Goebel & Holz, 2007). The major difference here is that access to all the traffic of the hosts is required, and thus these methods only work for finding infected hosts in a network under one\u2019s control.\nThe rest of this paper is organized as follows. In Section 2, we discuss our approach to evaluating botnet models by predicting participation in spamming campaigns. In Section 3, we establish the problem of minimal graph clustering, devise a probabilistic model of the conditional distribution of clusterings given the input graph, and derive a Gibbs sampler. Section 4 presents a case study that we carried out with an email service provider. Section 5 concludes."}, {"heading": "2. Problem Setting and Evaluation", "text": "The ground truth about the sets of IP addresses that constitute each botnet is unavailable. Instead, we focus on the botnet model\u2019s ability to predict observable events. We consider email spam campaigns which are one of the main activities that botnets are designed for, and which we can easily observe by monitoring the stream of emails that reach an email service provider. Most spam emails are based on a campaign template which is instantiated at random by the nodes of a botnet. Clustering tools can identify sets of messages that are based on the same campaign template with a low rate of errors (Haider & Scheffer, 2009). A single campaign can be disseminated from the nodes of a single botnet, but it is also possible that a botnet processes multiple campaigns simultaneously, and multiple botnets may be employed for large campaigns.\nWe formalize this setting as follows. Over a fixed pe-\nriod of time, n messages are observed. An adjacency matrix X of the graph of messages reflects evidence that pairs of messages originate from the same botnet. An edge between nodes i and j\u2014represented by an entry of Xij = 1\u2014is present if messages i and j have been sent from the same IP address within the fixed time slice, or if a campaign detection tool has assigned the messages to the same campaign cluster. Both types of evidence are uncertain, because IP addresses may have been reassigned within the time slice and the campaign detection tool may incur errors. The absence of an edge is only very weak and unreliable evidence against joint botnet membership, because the chance of not observing a link between nodes that are really part of the same botnet is strongly dependent on the observation process.\nThe main part of this paper will address the problem of inferring a reflexive, symmetric edge selector matrix Y in which entries of Yij = 1 indicate that the messages represented by nodes i and j originate from the same botnet. The transitive closure Y + of matrix Y defines a clustering CY of the nodes. The clustering places each set of nodes that are connected to one another by the transitive closure Y + in one cluster; the clustering is the union of clusters:\nCY = \u22c3n\ni=1 {{j : Y +ij = +1}}. (1)\nBecause Y + is reflexive, symmetric and transitive, it partitions all nodes into disjoint clusters; that is, c\u2229 c\u2032 = \u2205 for all c, c\u2032 \u2208 CY , and \u22c3 c\u2208CY c = {1, . . . , n}.\nAn unknown process generates future messages which are characterized by two observable and one latent variable. Let the multinomial random variables s indicate the campaign cluster of a newly received message, a indicate the IP address, and let latent variable c indicate the originating cluster, associated with a botnet. We quantify the ability of a model CY to predict the observable variable s of a message given a in terms of the likelihood\nP (s|a,CY ) = \u2211\nc P (s|c, CY )P (c|a,CY ). (2)\nEquation 2 assumes that the distribution over campaigns is conditionally independent of the IP address given the botnet; that is, botnet membership alone determines the distribution over campaigns.\nMultinomial distribution P (s|c, CY ) quantifies the likelihood of campaign s within the botnet c. It can be estimated easily on training data because model CY fixes the botnet membership of each message. Multinomial distribution P (c|a,CY ) quantifies the probability that IP address a is part of botnet c given model\nCY . Model CY assigns each node\u2014that is, message\u2014 to a botnet. However, an address can be observed multiple times within the fixed time slice, and the botnet membership can change withing the time interval. Hence, a multinomial distribution P (c|a,CY ) has to be estimated for each address a on the training data, based on the model CY . Note that at application time, P (c|a,CY ) and hence the right hand side of Equation 2 can only be determined for addresses a that occur in the training data on which CY has been inferred."}, {"heading": "3. Minimal Graph Clustering", "text": "Let X be the adjacency matrix of the input graph with n nodes. Entries of Xij = 1 indicate an edge between nodes i and j which constitutes uncertain evidence for joint membership of these nodes in a botnet. The input matrix is assumed to be reflexive (Xii = 1 for all i), and symmetric (Xij = Xji).\nThe outcome of the clustering process is represented by a reflexive, symmetric edge selector matrix Y in which entries of Yij = 1 indicate that nodes i and j are assigned to the same cluster, which indicates that the messages originate from the same botnet. The transitive closure Y + of matrix Y defines a clustering CY of the nodes according to Equation 1. Intuitively, the input matrix X can be thought of as data, whereas output matrix Y should be thought of as the model that encodes a clustering of the nodes. A trivial baseline would be to use X itself as edge selector matrix Y . In our application, this would typically lead to all messages being grouped in one single cluster.\nNo prior knowledge is available on associations between botnets in the absence of empirical evidence. If the adjacency matrix X does not contain evidence that links nodes i and j, there is no justification for grouping them into the same cluster. This is reflected in the concept of a minimal edge selector matrix.\nDefinition 1. A selector matrix Y and, equivalently, the corresponding graph clustering CY , is minimal with respect to adjacency matrix X if it satisfies\nY = Y + \u25e6X, (3)\nwhere (Y + \u25e6 X)ij = Y +ij Xij is the Hadamard product that gives the intersection of the edges of Y + and X.\nIntuitively, for every pair of nodes that are connected by the adjacency matrix, selector matrix Y decides whether they are assigned into the same cluster. Nodes that are not connected by the adjacency matrix X must not be linked by Y , but can still end up in the same cluster if they are connected by the transitive\nclosure Y +. Equation 3 also ensures that the transitive closure Y + does not differ from Y for any pair of nodes i, j that are connected by the adjacency matrix. This enforces that no two different minimal selector matrices have the same transitive closures and therefore induce identical clusterings, which would inflate the search space."}, {"heading": "3.1. Probabilistic Model", "text": "This section derives a probabilistic model for the minimal graph clustering problem. Its most salient property is that it is not based on a generative model of the graph, but instead directly models the conditional probability of the clustering given the adjacency matrix X. This circumnavigates systematic errors caused by inaccurate distributional assumptions for the generation of the adjacency matrix X.\nWe define the posterior distribution over all reflexive and symmetric matrices Y that are minimal with respect to X.\nDefinition 2. Let X \u2208 {0, 1}n\u00d7n be a reflexive and symmetric adjacency matrix. Then, YX \u2286 {0, 1}n\u00d7n is the set of matrices that are reflexive, symmetric, and minimal with respect to X.\nIn our application, each node is an element of at most two cliques because each message is connected to all other messages that have been sent from the same IP address, and to all other messages that match the same campaign template. If a template or an address has been observed only once, either of these cliques may resolve to just the node itself. Let QX denote the set of cliques in X, and let CqY be the projection of clustering CY to the elements of q \u2208 QX . Within each clique q \u2208 QX , any clustering CqY is minimal with respect to X because Xij = 1 for all i, j \u2208 q, and therefore any reflexive, symmetric, and transitive clustering of q is possible. We model the probability distribution over clusterings of each clique q \u2208 QX as a Chinese Restaurant process (Pitman & Picard, 2006) with concentration parameter \u03b1q > 0:\nP (CqY |\u03b1q, nq) = \u03b1 |CqY | q \u0393(\u03b1q)\n\u0393(\u03b1q + nq) \u220f c\u2208CqY \u0393(|c|). (4)\nEquation 5 now defines the distribution over all partition matrices Y \u2208 YX as a product over all cliques in QX , where the clique specific concentration parameters are collected into \u03b1 = {\u03b1q : q \u2208 QX}.\nP (CY |X,\u03b1) \u221d { \u220f q\u2208QX P (CqY |\u03b1q, nq) if Y \u2208 YX\n0 otherwise (5)\nEquation 5 can be seen in analogy to the factorization of the posterior over cliques in conditional random fields. However, because the minimality property has non-local effects on the possible values that edges can assume, this factorization is not equivalent to the assumption of the Markov property on which the factorization theorem for random fields is based (Hammersley & Clifford, 1971).\nNormalization of Equation 5 is computationally intractable because it requires the enumeration of the elements of YX . However, the Gibbs sampler that we will derive in the following only has to normalize over all values of the random variables that are reassigned in each step of the sampling process."}, {"heading": "3.2. Inference", "text": "Computing the posterior distribution P (CY |X,\u03b1) is a generalization of the inference problem for conventional Chinese Restaurant process models. When all entries of X are one, the graph has only one clique and the special case of a Chinese Restaurant process is obtained. In this case, depending on the concentration parameter, the outcome may be one single cluster of all nodes. Maximization of the posterior as well as full Bayesian inference are intractable even for this special case because of the non-convexity of the posterior and the exponential number of possible clusterings. Hence, in this section we describe a Gibbs sampler that generates unbiased samples from the posterior.\nAlgorithm 1 Assignment space YYi for Gibbs sampler Input: Current partitioning matrix Y 1: let q1, . . . , qk be the cliques with element i 2: let Yi = \u2205 3: for all combinations c1 \u2208 Cq1Y \u222a {{i}}, . . . , ck \u2208 CqkY \u222a {{i}} do\n4: let Y \u2032\u2212i = Y\u2212i 5: let Y \u2032il = Y \u2032 li = 1 if and only if l \u2208 cj for any j 6: if (Y \u2032\u2212i) + = Y \u2032\u2212i then 7: add Y \u2032 to YYi 8: else 9: discard Y \u2032\n10: end if 11: end for Return: YYi , all reflexive, symmetric, minimal parti-\ntioning matrices derived from Y by reassigning Yi.\nGibbs samplers divide the set of random variables into smaller subsets and iteratively draw new values for one subset given the values of the remaining variables. For the observations to form an unbiased sample, the random variables have to be partitioned such that the\nsequence of assignments formes an ergodic Markov chain; that is, each state has to be reachable from each other state. In our case, perhaps the most obviousseeming approach would be to factor the posterior over individual edges. However, since many matrices Y violate the minimality condition, the chain of alterations of single matrix entries would not in general be ergodic.\nTherefore, we devise a sampling algorithm that jointly samples the i-th row and column (the i-th row and column are identical because Y is symmetric). Let Y \u2032i refer to the i-th row and column of the new matrix Y \u2032, and let Y \u2032\u2212i = Y\u2212i refer to the remaining matrix entries, such that Y \u2032 = Y \u2032i \u222a Y \u2032\u2212i. Equation 6 expands the definition of the conditional probability; Equation 7 factorizes over the cliques, according to Equation 5. Equation 8 omits all terms that are constant in Y \u2032i : the denominator, and all cliques in which node i does not occur. Normalization of the right hand side of Equation 8 is now over all values for Y \u2032i that render Y \u2032 reflexive, symmetric, and minimal with respect to X.\nP (Y \u2032i |Y\u2212i, X,\u03b1) = P (Y \u2032i , Y \u2032 \u2212i|X,\u03b1)\nP (Y\u2212i|X,\u03b1) (6) \u221d \u220f q\u2208QX P (C q Y \u2032 |\u03b1q, nq)\nP (Y\u2212i|X,\u03b1) (7) \u221d \u220f\nq\u2208QX :i\u2208q P (CqY \u2032 |\u03b1q, nq) (8)\nThe main computational challenge here is to determine the set YYi of reflexive, symmetric, minimal matrices that can be derived from Y by changing row and column i. Since Equation 8 has to be normalized, all of its elements have to be enumerated. An obvious but inefficient strategy would be to enumerate all up to 2n assignments of Yi and test the resulting matrix for reflexivity, symmetry, and minimality.\nHowever, most values of Y \u2032i violate minimality and need not be enumerated. Algorithm 1 constructs the set YYi in O(nk), where k is the maximal number of cliques that each node is a member of. In our application, each node is an element of up to two cliques\u2014the set of messages with a shared IP address, and the set of messages that follow the same campaign template. Hence, in our case, the algorithm has a worst-case execution time of O(n2). In most cases, the number of clusters in each of the two cliques is much lower than n, and thus much fewer than n2 cases are considered.\nTheorem 1. Given an adjacency matrix X and an edge selector matrix Y, Algorithm 1 constructs a set YYi that contains all Y \u2032 = Y \u2032i \u222a Y\u2212i which are reflexive, symmetric, and minimal with respect to X. The execution time of Algorithm 1 is in O(nk) when each node is a member of at most k cliques in X.\nProof. Let node i be an element of cliques q1, . . . , qk. On these cliques, the current partitioning matrix Y induces clusterings Cq1Y , . . . , C qk Y with at most n clusters each. When Y \u2032i links node i to more than one cluster from any CqlY , then by the definition of a clustering in Equation 1 these clusters are merged in CY \u2032 . However, when Y \u2032i links node i to two clusters with at least one other element in ql each, say j and l with Yjl = 0, the transitive closure Y \u2032+ has to add at least an edge to Y \u2032\u2212i that links j and l. Since j and l are in clique ql, they have to be connected by the adjacency matrix, Xjl = 1. But Y \u2032 jl = 0, Y \u2032+ jl = 1 and Xjl = 1 violates the minimality condition defined in Equation 3. Therefore, Y \u2032 must only merge clusters that have elements in different cliques, and so at most nk combinations of clusters can lead to minimal matrices Y \u2032 when merged. Reflexivity and symmetry of Y \u2032 follow from reflexivity and symmetry of X. The execution time is dominated by the enumeration of all nk many combinations of clusters in Line 3.\nThe Gibbs sampler iteratively samples Y t+1 according to P (Y \u2032it |Y t \u2212it , X,\u03b1), given by Equation 8. Each Y t+1 is created from the predecessor by cycling over the rows that are resampled\u2014that is, it = t mod n. The conditional is defined over the set YY tit . We will now argue that a sequence of matrices created by the Gibbs sampler is an ergodic Markov chain.\nTheorem 2. For \u03b1q > 0, the sequence Y 0, . . . , Y T with Y t+1 \u223c P (Y t+1(t mod n)|Y t \u2212(t mod n), X,\u03b1) is an ergodic Markov chain.\nProof. The sequence is a Markov chain because each element is sampled from a distribution that is parameterized only with the preceding matrix and the row that is to be resampled. For it to be ergodic we have to prove that from any state Y, every other state Y \u2032 can be reached. With the \u03b1q > 0, Equation 5 is positive for all states in YX that are reflexive, symmetric, and minimal with respect to X. In each step the sampler can only change row and column i. Hence, any chain of states with Y t+1 \u2208 YY t(t mod n) can be reached because by Theorem 1, all elements of YY t(t mod n) are reflexive, symmetric, minimal with respect to X and differ from Y t only in row and column i.\nTo begin with, we argue that from any state Y the identity matrix I can be reached which connects each node only to itself. To prove this, it suffices to show that for any i and any Y , a state IY,i with IY,iii = 1 for all i, IY,iij = 0 for all j 6= i, and IY,ijk = Yjk for all j, k 6= i can be reached directly from state Y by sampling row and column Yi. By the definition of YYi , the Gibbs sampler can directly reach state IY,i from Y\nif IY,i is symmetric, reflexive, minimal with respect to X, and differs from Y only in the i-th row and column. By its definition, it is clear that IY,i differs from Y only in the i-th column and row, and that it is reflexive. Since Y is symmetric and the i-th row and column of IY,i are identical, IY,i has to be symmetric as well. It remains to be shown that IY,i = IY,i + \u25e6 X. We split the proof of this claim into two parts. First, we show that the i-th row and column of IY,i are equal to the i-th row and column of IY,i + \u25e6X. Intuitively, because IY,i connects node i only to itself, the transitive closure adds nothing, and the Hadamard product has no effect because X is reflexive. Formally, this can be shown via an inductive proof along the following construction of the transitive closure of IY,i. Let R0 = IY,i. For all l > 0, let Rlij = 1 if R l\u22121 ij = 1 or if there is a k such that Rl\u22121ik = 1 and R l\u22121 kj = 1; otherwise, R l ij = 0. When Rl\u22121 contains an open triangle of edges Rl\u22121ik = 1 and Rl\u22121kj = 1, then R l is defined to add an edge Rlij = 1. Then the limit liml\u2192\u221eR l is the transitive closure (IY,i)+. Now inductively, if for all j : Rl\u22121ij = 0, then for all j : Rlij = 0, and from I Y,i i = 0 it follows that IY,i + i = I Y,i i, and (I Y,i+ \u25e6X)i = IY,ii.\nSecondly, we show that all elements in IY,i +\nexcept the i-th row and column remain unchanged from Y +: From the monotonicity of the transitive closure operator and IY,i \u2264 Y it follows that (IY,i+ \u25e6 X)\u2212i \u2264 (Y + \u25e6X)\u2212i. Furthermore, since the transitive closure operator only adds positive edges, (IY,i\n+ \u25e6 X)\u2212i \u2265 (IY,i \u25e6 X)\u2212i = (Y \u25e6 X)\u2212i, which is in turn equal to (Y + \u25e6X)\u2212i because Y itself is minimal with respect to X. Both inequalities together give us (IY,i\n+ \u25e6X)\u2212i = (Y + \u25e6 X)\u2212i, and because IY,i\u2212i = Y\u2212i we have that IY,i\u2212i = (I\nY,i+ \u25e6 X)\u2212i. Together with the first part finally IY,i = IY,i + \u25e6X.\nThis establishes that IY,i can be reached by the Gibbs sampler from any state Y for any i, and thus by repeatedly using this state transition for all i, I is reachable. The reachability relation is symmetric because Y t+1 is constructed from Y t by reassigning one column and row which can be reversed, and Y t is required to be in YX , and therefore can be reached from Y t+1. Hence, from any state Y , every other state Y \u2032 can be reached via the state I, and ergodicity holds."}, {"heading": "3.3. Prediction", "text": "The Gibbs sampler creates a chain Y 0, . . . , Y T of matrices, governed by the posterior P (Y |X,\u03b1). In order to predict which campaign s a given IP address a will participate in, we can approximate the Bayesian infer-\nence of c (Equation 9) using the chain (Equation 10). P (s|a,X,\u03b1) = \u2211\nY \u2208YX\nP (CY |X,\u03b1)P (s|a,CY ) (9)\n\u2248 \u2211\nY \u2208{Y 0,...,Y T }\nP (s|a,CY ) (10)\nEquation 1 decomposes P (s|a,CY ) into two multinomial distributions that can be estimated from the available data."}, {"heading": "4. Case Study", "text": "In this section, we conduct a case study on botnet detection. Since the gound truth about which botnets are currently active and which hosts they are composed of is not available, we evaluate the model in terms of its accuracy of predicting which spam campaign a given IP address will participate in.\nWe record incoming spam emails over a period of 11 days in January 2012 at a large email service provider. We select only emails that have been blacklisted on the grounds of three content-based filtering techniques: The first is a set of manually maintained regular expressions, each tailored to match against all spams of one particular campaign. The second is a list of semi-automatically generated, campaign-specific feature sets (Haider & Scheffer, 2009). A feature set consists of words and structure flags and is the intersection of all previously observed emails from the campaign. The third is a blacklist of URLs that spam emails link to. Thus, we have a reliable partitioning of all emails into spam campaigns.\nWe exclude IP addresses of known legitimate forwarding servers that relay inbound emails according to their users\u2019 personal filtering policies. To this end, we track the IP address from the last hop in the transmission chain. If the address has a valid reverse DNS entry that matches a domain from a list of well-known email service providers, we omit the message.\nEquation 5 allows for individual values of the concentration parameters \u03b1q for each clique q in the email graph X. We use two distinct values: a value of \u03b1a for all cliques that share a joint IP address, and a value of \u03b1s for all cliques that match a joint campaign. Parameters \u03b1a and \u03b1s are tuned to maximize the AUC metric on the data recorded on the first day. The data of the remaining ten days is then used for evaluation. Within each day, the Gibbs sampler infers a chain of clusterings on the data of the first 16 hours. The emails of the last 8 hours with a sender IP address that has previously occurred are used as test data. Emails from IP addresses that have not been seen before are ex-\ncluded, since no informed decision can be made for them. The proportion of IP addresses that have not previously been observed depends on the proportion of the global email traffic that the server gets to observe. Also, we exclude emails from campaigns that appear less than 100 times. In total, this data collection procedure results in 701,207 unique pairs of campaigns and IP addresses in the training sets and 71,528 in the test sets. Each test email serves as a positive example for its campaign and a negative example for all other campaigns."}, {"heading": "4.1. Reference Methods", "text": "We compare the Minimal Graph Clustering model to three baselines. The first, threshold-based baseline is an agglomerative clustering algorithm based on a threshold heuristic, adapted from Zhuang et al. (2008). It operates on the assumption that each campaign is sent by only one botnet. Initially, every campaign constitutes its own cluster. Clusters c and c\u2032 are greedily merged if their fraction of overlapping IP addresses exceeds a threshold. This fraction is defined as\u2211\ni\u2208c I(\u2203j \u2208 c\u2032 : si = sj) 2|c| +\n\u2211 j\u2208c\u2032 I(\u2203i \u2208 c : sj = si)\n2|c\u2032| ,\nwhere I is the indicator function and si the campaign of the i-th email. Given a clustering C of emails, P (s|a,C) = \u2211 c\u2208C P (s|c, C)P (c|a,C) is inferred after multinomial distributions P (s|c) and P (c|a,C) have been estimated on the training data. The clustering threshold is tuned for performance on the first day.\nThe second baseline is spectral clustering, where we tune the number of clusters and similarity values for emails with matching campaign or IP address. We use the implementation of Chen et al. (2011).\nThe third baseline is a straightforward generative clustering model for email graphs with a Chinese Restaurant process prior and a likelihood function that factorizes over the edges of the email graph X, assuming independence for the edges inX. The likelihood function has a set of four parameters \u03b8 = {\u03b8ins , \u03b8ins , \u03b8outa , \u03b8outa } that quantify the probability of the presence of a link when the nodes are and are not elements of a joint botnet. The likelihood for an edge that connects two emails from the same campaign is given as\nP (Xij = 1|C,\u03b8) =\n{ \u03b8ins , if C(i) = C(j)\n\u03b8outs , if C(i) 6= C(j),\nwhere C(i) denotes the cluster that clustering C assigns email i to. The likelihood of an edge between two emails from the same IP address is defined analogously,\n0.55\n0.6\n0.65\n0.7\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\nA U\nC\nFraction of training sample\nMin. Graph Clustering Threshold-based\nSpectral clustering Generative edge model\nFigure 3. AUC depending on training set size.\nusing the paramters \u03b8outa and \u03b8 out a . The joint probability of the email matrix and a clustering C is then given as P (X,C|\u03b1,\u03b8) = PCRP (C|\u03b1) \u220f i,j<i P (Xij |C,\u03b8). The parameters are adjusted using gradient-ascent on the joint data likelihood."}, {"heading": "4.2. Results", "text": "We measure ROC curves; IP addresses for which the likelihood P (s|a,X,\u03b1) of the correct campaign exceeds the threshold are counted as true positives, addresses for which the likelihood of an incorrect campaign exceeds the threshold as false positives. Figure 4 shows ROC curves for the four methods under study.\nMinimal graph clustering attains the highest area under the ROC curve of 0.784, compared to 0.675 for threshold-based clustering, 0.671 for spectral clustering, and 0.651 for the generative edge model baseline. The threshold-based method is marginally more accurate than the Minimal Graph Clustering model for low threshold values, and less accurate for all other threshold values. Threshold-based clustering infers P (s|c) and P (c|a,C) and consequently P (s|a,C) to be zero for many values of s and a. Therefore, a large interval of points on the ROC curve cannot be attained by any threshold value; this is indicated by a dashed line.\nTypically, the number of requests during a DDoS attack exceeds the capacity to serve requests by far. An unprotected system will serve only a small, random fraction of requests and will be unable to serve all others; this amounts to a false positive rate of close to one. In order to defend against such an attack, one has to select a small proportion of requests which can be served. Therefore, in defending against DDoS attacks, the right hand side of the ROC curve that allows high true positive rates is practically relevant.\nFigure 4 shows execution times for running all four methods until convergence depending on the number\nof examples. The Minimal Graph Clustering model is computationally more expensive than the baselines. For continuously maintaining a clustering that subsequently incorporates newly available messages, it is thus advisable to use the previous clustering as a starting point of the Gibbs sampler in order to reduce the number of necessary iterations until convergence.\nFigure 4 shows area under ROC curve depending on what fraction of the training sample is used. For testing, only emails with IP addresses that are present in the smallest subset are used. The plots indicate that having access to a larger sample of the overall email traffic could increase performance considerably."}, {"heading": "5. Conclusion and Discussion", "text": "The identification of spam-disseminating botnets can be reduced to the problem of clustering the graph of email messages in which messages are linked if they originate from the same IP address or match the same campaign template. We devised a probabilistic model that directly describes the conditional probability of a clustering given the input graph without making distributional assumptions about the generation of the observable data. We derived a Gibbs sampler; we showed that resampling rows and edges of the output matrix creates an ergodic Markov chain, and that each sampling step can be carried out in O(n2). We argue that botnet models can be evaluated in terms of their ability to predict which spam campaign a given IP address is going to participate in. From a case study carried out with an email service provider we conclude that the minimal graph clustering model outperforms a number of reference methods\u2014spectral clustering, a generative model, and a threshold-based, agglomerative clustering model\u2014in terms of its area under the ROC curve.\nThe botnet model draws a picture of the current size\nand activity of botnets. From the IP addresses, the geographical distribution of each botnet can be derived. The botnet model can be used to select particularly prolific botnets for in-depth analysis and possible legal action. Widespread botnet software is versatile and supports both, dissemination of email spam and the staging of network attacks (Stern, 2008). When both, a mailing campaign and a network attack are carried out by a single network within the typical IPaddress reassignment interval of one day, then the botnet model which has been trained on email data can score HTTP requests by the likelihood that their sender IP address is part of an attacking botnet. This allows to prioritize requests and to maintain a service during an attack. Alternatively, the botnet model can be trained with HTTP requests instead of emails; the recipient domain of an HTTP request plays the role of the campaign template. Again, the botnet model allows to infer the likelihood that an individual sender IP address acts as part of an attacking botnet.\nDirect evaluation of the model\u2019s ability to decide whether an IP request is part of a network attack would require evaluation data in the form of a collection of individual HTTP requests labeled with the botnet that has sent the request. While it is relatively easy to collect the entire stream of legitimate and attacking HTTP requests that reach a domain during an attack, there is no practical means of labeling individual requests. In general, HTTP requests contain no information that allows even a human expert to decide whether a request is part of an attack, let alone which botnet a request has really been sent from."}, {"heading": "6. Acknowledgments", "text": "This work was funded by a grant from STRATO AG."}, {"heading": "DiBenedetto, S., Gadkari, K., Diel, N., Steiner, A., Massey,", "text": "D., and Papadopoulos, C. Fingerprinting custom botnet protocol stacks. In Secure Network Protocols (NPSec), 2010 6th IEEE Workshop on, pp. 61\u201366. IEEE, 2010.\nDittrich, D. and Dietrich, S. Discovery techniques for p2p botnets, 2008."}, {"heading": "Goebel, J. and Holz, T. Rishi: Identify bot contaminated", "text": "hosts by irc nickname evaluation. In Proceedings of the first conference on First Workshop on Hot Topics in Understanding Botnets, pp. 8\u20138. USENIX Association, 2007."}, {"heading": "Gu, G., Perdisci, R., Zhang, J., and Lee, W. Botminer:", "text": "Clustering analysis of network traffic for protocol-and structure-independent botnet detection. In Proceedings of the 17th conference on Security symposium, pp. 139\u2013 154. USENIX Association, 2008.\nHaider, P. and Scheffer, T. Bayesian clustering for email campaign detection. In Proceeding of the International Conference on Machine Learning, 2009.\nHammersley, J. and Clifford, P. Markov fields on finite graphs and lattices, 1971.\nHolz, T., Steiner, M., Frederic, D., Biersack, E., and Freiling, F. Measurements and mitigation of peer-to-peerbased botnets: a case study on storm worm. In Proceedings of the USENIX Workshop on Large-Scale Exploits and Emergent Threats, 2008.\nJohn, J.P., Moshchuk, A., Gribble, S.D., and Krishnamurthy, A. Studying spamming botnets using botlab. In Proceedings of the 6th USENIX symposium on Networked systems design and implementation, pp. 291\u2013306. USENIX Association, 2009."}, {"heading": "Mori, T., Esquivel, H., Akella, A., Shimoda, A., and Goto,", "text": "S. Understanding large-scale spamming botnets from internet edge sites. In Proceedings of the Conference on E-Mail and Anti-Spam. CEAS, 2010.\nPitman, J. and Picard, J. Combinatorial stochastic processes. Springer, 2006. ISBN 354030990X.\nStern, H. A survey of modern spam tools. In Proceedings of the Conference on Email and Anti-Spam, 2008."}, {"heading": "Xie, Y., Yu, F., Achan, K., Panigrahy, R., Hulten, G., and", "text": "Osipkov, I. Spamming botnets: Signatures and characteristics. ACM SIGCOMM Computer Communication Review, 38(4):171\u2013182, 2008.\nYu, F., Xie, Y., and Ke, Q. Sbotminer: Large scale search bot detection. In Proceedings of the third ACM international conference on Web search and data mining, pp. 421\u2013430. ACM, 2010."}, {"heading": "Zhuang, L., Dunagan, J., Simon, D.R., Wang, H.J., and", "text": "Tygar, JD. Characterizing botnets from email spam records. In Proceedings of the 1st Usenix Workshop on Large-Scale Exploits and Emergent Threats, pp. 1\u2013 9. USENIX Association, 2008."}], "references": [], "referenceMentions": [], "year": 2012, "abstractText": "We study the problem of identifying botnets and the IP addresses which they comprise, based on the observation of a fraction of the global email spam traffic. Observed mailing campaigns constitute evidence for joint botnet membership, they are represented by cliques in the graph of all messages. No evidence against an association of nodes is ever available. We reduce the problem of identifying botnets to a problem of finding a minimal clustering of the graph of messages. We directly model the distribution of clusterings given the input graph; this avoids potential errors caused by distributional assumptions of a generative model. We report on a case study in which we evaluate the model by its ability to predict the spam campaign that a given IP address is going to participate in.", "creator": "LaTeX with hyperref package"}}}