{"id": "1206.6396", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Joint Optimization and Variable Selection of High-dimensional Gaussian Processes", "abstract": "Maximizing high-dimensional, non-convex functions through noisy observations is a notoriously hard problem, but one that arises in many applications. In this paper, we tackle this challenge by modeling the unknown function as a sample from a high-dimensional Gaussian process (GP) distribution. Assuming that the unknown function only depends on few relevant variables, we show that it is possible to perform joint variable selection and GP optimization. We provide strong performance guarantees for our algorithm, bounding the sample complexity of variable selection, and as well as providing cumulative regret bounds. We further provide empirical evidence on the effectiveness of our algorithm on several benchmark optimization problems.\n\n\n\nIn this paper, we define a discrete vector of the Gaussian distribution, which is a function of the Gaussian distribution. This is a function of the Gaussian distribution and the Gaussian distribution for the Gaussian distribution in general (i.e., the distribution is a measure of the mean number of points the Gaussian distribution can provide as a parameter of the Gaussian distribution). We assume that the Gaussian distribution contains only the least known variables, which represent a probability of an estimate of an estimate of an estimate of an estimate of a confidence interval of some 10.2. We also show that this estimate of the average Gaussian distribution is obtained in the form of the expected estimate of the probability of a confidence interval of about 50.9%. A probability of about 60.6.2. We then estimate the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected value of the expected", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (572kb)", "http://arxiv.org/abs/1206.6396v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["bo chen", "rui m castro", "andreas krause 0001"], "accepted": true, "id": "1206.6396"}, "pdf": {"name": "1206.6396.pdf", "metadata": {"source": "META", "title": "Joint Optimization and Variable Selection of High-dimensional Gaussian Processes", "authors": ["Bo Chen", "Rui M. Castro"], "emails": ["bchen3@caltech.edu", "rmcastro@tue.nl", "krausea@ethz.ch"], "sections": [{"heading": "1. Introduction", "text": "We consider the problem of function optimization in high dimensions. In many situations one wishes to find the maximum of a function quickly, from (noisy) evaluation at a small number of points. This problem occurs in various domains, for instance when learning optimal control strategies for robots (Lizotte et al., 2007), or when optimizing industrial processes that depend on many variables. It is particularly interesting to consider the case where the domain of the function f we desire to optimize is high-dimensional (say [\u22121, 1]D), but when the values of the function depend only on a reduced, albeit unknown, set of variables. If there\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nare d such \u201cactive\u201d variables, where d D, it is somewhat plausible that the performance of such a function optimization procedure depends mostly on the intrinsic dimension d, and only depends mildly on the extrinsic dimension D. In this paper we formalize such insight, and provide a suite of algorithms based on Hierarchical Diagonal Sampling (HDS), which are able to perform both variable selection and function optimization in such settings. We provide strong theoretical guarantees, including a sample complexity bound that depends only logarithmically on the extrinsic dimensionality, as well as cumulative regret bounds on the performance of joint variable selection and optimization. We evaluate our proposed algorithms on several benchmark optimization problems.\nRelated Work Variable selection and optimization have both been extensively studied separately from each other. In variable selection one seeks an active set of variables, among many others, that explain a response function well. One family of models called sparse linear models study the case where the response function is linear in the variables. For example, Lasso (Tibshirani, 1996) tackles this combinatorial problem using an continuous approximation, which has been shown to be optimal under certain conditions (Donoho, 2006). Alternative models have been proposed to handle non-linear response functions. Automatic Relevance Determination (ARD, MacKay (1992)) is a Bayesian variable selection procedure that imposes a Gaussian prior on the bandwidths of the variables, which can be combined with a GP likelihood to handle non-linear functions. Yet there is little formal analysis regarding its sample complexity rate. Rodeo (Lafferty & Wasserman, 2008) is an efficient algorithm that simultaneously estimates bandwidths and selects variables in non-parametric regressions. It has favorable theoretical properties of risks and con-\nvergence rates. Also bearing similarities to our work is Distilled Sensing (Haupt et al., 2011), which attempts to quickly identify large portions of the variable space that are irrelevant, therefore reducing the search complexity as more data is collected, and effectively shedding the dependency on the extrinsic dimension. However, none of these models address the problem of function optimization in an active learning setting. The goal of active function optimization is to optimize an unknown function with as few samples as possible. One line of work called Bayesian global optimization (Ginsbourger & Riche, 2010; Brochu et al., 2010) assumes the unknown function is sampled from a GP. In particular, the GP-UCB (Srinivas et al., 2010) algorithm has been shown to have sub-linear regret and work well emprically. However, dealing with high dimensional domains is a notoriously hard challenge for these approaches. Most of this existing work has considered variable selection and function optimization separately. Recently, the problem of joint variable selection and linear optimization has been tackled by (Abbasi-Yadkori et al., 2012), who exploit sparsity to alleviate the curse of dimensionality. Concurrently, (Carpentier et al., 2012) combines compress sensing and bandit theory to achieve sub-linear regret bounds for sparse functions. However, they deal only with linear or approximately linear reward functions whereas our method handles non-linear functions."}, {"heading": "2. Model and Problem Statement", "text": "We focus on functions of bounded domain, which, w.l.o.g., we assume to be [\u22121, 1]D, where D is called the extrinsic dimension. Let f : [\u22121, 1]D \u2192 R be a fixed, but unknown function. The value and location of the maximum of this function are our main quantities of interest. We assume that this function depends only on a subset of the domain variables, which we call the active variables or active dimensions, denoted by A \u2282 {1, . . . , D}. We are particularly interested in the case where the set of active dimensions is rather small relative to the extrinsic dimension, namely d = |A| D.\nWithout some regularity assumptions on f , optimization would be hopeless. We choose to model smoothness of f by assuming that it is a sample from a Gaussian Process (GP, Rasmussen & Williams (2006)) with zero mean1 and a squaredexponential2 kernel K. In order to model the fact\n1The assumption that the GP has zero mean is not critical, but greatly simplifies the description later. See Sec 2.7 of Rasmussen & Williams (2006) for a treatment of nonzero means.\n2It is straightforward to extend our analysis to other isotropic kernel functions.\nthat the function depends on only a subset of the variables A, we assume that the kernel is of the form K(x,x\u2032) = \u03c32s exp ( \u2212 \u2211 i\u2208A (xi\u2212x\u2032i) 2 b2 ) , where x,x\u2032 \u2208 [\u22121, 1]D, \u03c32s is the self variance of the kernel, and b > 0 is the bandwidth corresponding to the active dimensions, respectively.\nAlthough the function f is modeled as a sample from a stochastic process, we assume it to be fixed throughout the data collection process. In particular we are allowed to collect data of the form yt = f(xt) + t where t = {1, 2, . . .}, t are independent and identically distributed (i.i.d.) normal random variables with zero mean and variance \u03c32 > 0 (assumed known), also independent of f . We are interested in developing an algorithm that chooses xt as a function of all the past observations {x`, y`}t\u22121`=1, in order to locate the maximum x\u2217 = argmaxx f(x) of f as quickly as possible. We evaluate any candidate algorithm in\nterms of its regret, RT = \u2211T t=1[f(x\n\u2217)\u2212 f(xt)]. Notice that the average regret, RT /T is an upper bound on the minimum regret, mint=1,...,T [f(x\n\u2217) \u2212 f(xt)], therefore minimizing the cumulative regret will lead to algorithms with good anytime performance."}, {"heading": "3. Variable Selection", "text": "We propose a two-staged method for variable selection and function optimization, tied together through proper choice of certain parameters as described below. Variable selection is attained by means of a hierarchical diagonal sampling (HDS) stage. After the identification of active variables, we apply the GP-UCB algorithm (Srinivas et al., 2010) to optimize over the variables deemed active."}, {"heading": "3.1. Hierarchical Diagonal Sampling", "text": "In a nutshell, the HDS algorithm recursively splits the set of variables into two sets of equal size, and keeps splitting the sets that are more likely to contain active variables. More specifically, HDS sequentially constructs a tree where each node corresponds to a set of variables, meaning each node can be uniquely identified by a subset of {1, . . . , D}. Any node that is not a leaf has two children, corresponding to two disjoint subsets of dimensions, each with half of the size of the parent node. Each node in this tree can be in one of three states: active nodes contain at least one active dimension, inactive nodes are guaranteed (w.h.p.) to contain no active dimensions, and for undetermined nodes we have insufficient evidence to draw any conclusions about their activeness. All the nodes start undetermined, but as more samples are collected, a node will either become active, which implies that at least one of its children is active, or inactive, which renders\nits entire subtree inactive. Naturally, if a leaf node (which contains a single dimension) is active, then the dimension is deemed an active dimension.\nThe crucial step in this algorithm is to determine if a node I \u2286 {1, . . . , D} is (in-)active. With that in mind, we construct a one-dimensional projection fI(\u00b7) of the function defined as follows: Let x(0) \u2208 [\u22121, 1]D denote a randomly chosen background vector (this choice is made before any observations are collected). Define the function xI : [\u22121, 1]\u2192 [\u22121, 1]D such that\nxI,i(z) = { z if i \u2208 I x (0) i otherwise ,\nwhere z \u2208 [\u22121, 1]. The one-dimensional projection of f in I is then simply defined as\nfI(z) = f(xI(z)) .\nThe function fI : [\u22121, 1]\u2192 R is a sample from a onedimensional GP, with kernel KI\nKI(x, x \u2032) = \u03c32s exp ( \u2212aI (x\u2212x \u2032)2\nb2\n) ,\nwhere x, x\u2032 \u2208 [\u22121, 1] and aI = |A \u2229 I| is the number of active variables in node I. In other words, KI is a squared-exponential kernel whose bandwidth depends on the number of active variables.\nTherefore, to identify if I contains any active variable it suffices to test which kernel best characterizes the landscape of noisy observations of fI . We propose two methods for doing so: the Finite Difference Sequential Likelihood Ratio Test (FDT), and the GP Sequential Likelihood Ratio Test (GPT), each with their respective advantages."}, {"heading": "3.2. Finite Difference Sequential Likelihood Ratio Test (FDT)", "text": "We use hypothesis testing in order to determine, whether node I contains any active variables3. We consider two hypothesis: the null hypothesis H0: I contains no active variable; the alternative H1: I contains at least one active variable. We begin by considering a non-sequential testing approach to this problem.\nFinite Difference Testing: The key idea is the following: If node I contains no active variables, then fI(x) should be constant. In contrast, if the node I contains active variables, fI(x) should exhibit a significant amount of variation as we vary x. In the following, we formalize this intuition. Suppose we pick two random points x and x\u2032, independently\n3Using hypothesis testing for GP active learning was proposed by Krause & Guestrin (2007). However, their approach does not apply to our variable selection setting.\nand uniformly distributed over [\u22121, 1]. Consider \u2206 = \u2206(x, x\u2032) = fI(x)\u2212fI(x\u2032). Both under H0 and H1 E[\u2206] = 0. Further, in the null hypothesis, the variance V[\u2206] = 0 as well. In contrast, under H1, V[\u2206] = c > 0. Unfortunately we cannot observe \u2206(x, x\u2032) directly due to measurement noise. However, we can try to estimate V[\u2206] by picking n pairs of points xi, x\u2032i independently at random and computing the test statistic\nXn = 1\n2\u03c32 n\u2211 i=1 [y(xi)\u2212 y(x\u2032i)]2,\nwhere y(xi) and y(x \u2032 i) are all independent noisy point observations of fI(\u00b7), corrupted by additive Gaussian noise with zero mean and variance \u03c32. Under H0, Xn is distributed according to a central \u03c72n distribution with n degrees of freedom. In contrast, under H1, Xn is distributed according to a non-central \u03c7\n2 n,Bn\ndistribution with (unknown) non-centrality parameter Bn = \u2211 i \u2206 2 i , and \u2206i = (fI(xi) \u2212 fI(x\u2032i))/ \u221a 2\u03c32. The following Proposition provides a testing procedure, along with a sample-complexity bound, for distinguishing H0 and H1 with arbitrarily low failure probability.\nProposition 3.1. Let Bn = \u2211n i=1 \u2206 2 i , where \u2206 2 i \u2208 [0,M ] are independent random variables satisfying E[\u22062i ] \u2265 c. Consider testing between two hypothesis\nH0 : Xn \u223c \u03c72n and H1 : Xn|Bn \u223c \u03c72n,Bn , where in the alternative hypothesis we assume that, conditioned on Bn, the distribution of Xn is a noncentral \u03c72 with n degrees of freedom and non-centrality parameter Bn. Provided\nn \u2265 max { 2, 16 ( 1 + \u221a 1 + c )2\nc2 ,\n2M2\nc2\n} log(2/\u03b1) .\nthere is a thresholding test procedure that guarantees that both type I and type II error are less than \u03b1. In other words, there is a value \u03c4n such that PH0(Xn > \u03c4n) \u2264 \u03b1 and PH1(Xn < \u03c4n) \u2264 \u03b1 .\nNotice that the sample complexity given by Proposition 3.1 crucially depends on the lower bound c on the variance, which can be viewed naturally as parameterizing the problem difficulty.\nIn order to apply this hypothesis testing strategy to our setting, we must ensure that samples from a GP satisfy c = c(f) > 0 with high probability over the random function f . We have the following result:\nTheorem 3.1. Let \u03b4 > 0 and \u03c32s > 0. Suppose f is a sample from a GP on [\u22121, 1] with constant mean and covariance k(x, x\u2032) = \u03c32s exp(\u2212|x\u2212 x\u2032|2/h2), for some h \u2264 2\n(log 8\u03b4 ) 2 . Let x, x \u2032 \u223c U([\u22121, 1]) be two independent, uniformly distributed random variables and define \u2206 = f(x)\u2212 f(x\u2032).\nThere exist constants a > 0 and b > 0 such that with probability at least 1\u2212 \u03b4 over f it holds for the conditional variance of \u2206 that\nVx,x\u2032 [\u2206 | f ] \u2265 \u03c32sh 2\n4096b2 log(2a/(h\u03b4)) .\nThus, as long as h is sufficiently small, the variance c of \u2206 is lower bounded with high probability. Asymptotically, if h\u22121 = \u0398(log(1/\u03b4)2), then, as \u03b4 \u2192 0,\nVx,x\u2032 [\u2206 | f ] = \u2126 (\n\u03c32s (log(1/\u03b4))4\n) ,\nwith probability at least 1\u2212 \u03b4.\nA Sequential Testing Procedure: While providing sample complexity guarantees, the bounds of Proposition 3.1 in conjunction with Theorem 3.1 are very loose in practice. Furthermore, in order to determine the threshold \u03c4n, the lower bound c on the variance must be taken in the worst-case scenario. As a more practical alternative, we consider a sequential testing strategy, which is able to adjust the sample complexity depending on the problem difficulty. The key idea behind our sequential approximation is that under the GP prior, we can characterize the distribution of yI(x) \u2212 yI(x + \u03b4), the difference for point samples at a distance \u03b4.\nFirst, we focus on the concrete case where node I has either no active variables, or a known number of exactly a active variables. In this case, the data distribution under each scenario is entirely known. The case a = 1 is the hardest, intuitively because yI varies less the fewer active variables I has. Later we show that the composite case of distinguishing none vs. at least one active variable is of exactly the same difficulty. Setting dyI = yI(x) \u2212 yI(x + \u03b4), we have that the marginal distribution of this quantity is given by\ndyI \u223c N (0, \u03c32a); \u03c32a \u2261 2 [( 1\u2212 exp ( \u2212a\u03b4 2 b2 )) \u03c32s + \u03c3 2 ] .\nNow suppose a = 1. If we pick \u03b4 at random, then dyI is distributed according to a scale-mixture of Gaussians. Instead, in our sequential test, we simply fix \u03b4 = 3b. In this case, the variance under H0 is \u03c3 2 0 \u2261 2\u03c32 whereas the variance under H1 is 2((1 \u2212 1/e\u22123)\u03c32s + \u03c32) \u2265 2(.95\u03c32s + \u03c3\n2) \u2261 \u03c321 . Thus by estimating the variance of the finite differences for this fixed choice of \u03b4, we expect to be able to distinguish between H0 and H1.\nWe now employ sequential hypothesis testing using the sequential likelihood ratio test (SLRT) as described in Siegmund (1985). This is an incremental procedure that sequentially computes the log likelihood ratio (LLR) between two hypotheses, and makes a decision once this ratio crosses two predetermined boundaries. In our finite differences setting, a pair of samples\nare collected each time to update the LLR between H1 and H0. The test terminates as soon as LLR is either larger than an upper threshold \u03981 (and we accept H1) or smaller than a lower threshold \u03980 (and we accept H0). The LLR given a collection of T samples {dyI(xt)}Tt=1 can be computed in an additive fashion:\nLLR({dyI(xt)}Tt=1) = T\u2211 t=1 LLR(dyI(xt)), (1)\nwhere the LLR for each individual dyI(xt) = dy is:\nLLR(dy) = logN (dy|0, \u03c321)\u2212 logN (dy|0, \u03c320) = ( 1\n2\u03c320 \u2212 1 2\u03c321 )dy2 + log \u03c30 \u03c31 . (2)\nSeveral remarks are in order. First, for a fixed value of dy, under H1, E[LLR(dy)] is a monotonic function in \u03c31, which indicates that I containing one active variable is indeed the hardest case. Secondly, the classical SLRT requires independent samples, and under the GP prior, two finite differences dyI(x) = yI(x)\u2212yI(x+ \u03b4) and dyI(x\u2032) = yI(x\u2032)\u2212yI(x\u2032+ \u03b4) will be correlated. However, if |x\u2212 x\u2032| is sufficiently large, dyI(x) and dyI(x \u2032) will be nearly independent.\nLastly, since SLRT is carried out separately for each undetermined node in the tree, we would like to invest more samples on nodes that are the most likely to be active so as to reach all the active leaf nodes with minimum sample complexity. For this purpose, we allocate samples one at a time and always pick the node I that has the largest LLR so far. According to Eq. 2, statistics of LLR per finite difference depend only on \u03c31 and \u03c30, hence all the nodes for which H1 is true share the same upward slope for LLR, and the largest LLR naturally is the most likely to reach \u03981."}, {"heading": "3.3. GP Seq. Likelihood Ratio Test (GPT)", "text": "Instead of making an independence assumption, one can explicitly model the correlation between samples. Knowing the underlying hypothesis completely determines the data distribution, as it follows a GP with known covariance structure determined by KI,a, where this kernel depends on a, the number of active variables in I. To avoid notational clutter, we drop the explicit dependence on node I when its identity is clear from the context.\nWe focus first on a single node I. Given past observations of x1:t\u22121 and y1:t\u22121, we can compute the posterior distribution of yI t given xt under each hypothesis.\nyI t |xt,x1:t\u22121,y1:t\u22121 \u223c N ( \u00b5ta(xt), (\u03c3 t a(xt)) 2 ) .\n\u00b5ta(x) \u2261 ka(x)T (Ka + \u03c32I)\u22121y1:t\u22121, \u03c3ta(x) \u2261 \u03c32 +Ka(x, x)\u2212 ka(x)T (Ka + \u03c32I)\u22121ka(x), ka(x) \u2261 [Ka(x, x1), \u00b7 \u00b7 \u00b7 ,Ka(x, xt\u22121)]T ,\nKa \u2261 [ka(x1), \u00b7 \u00b7 \u00b7 ,ka(xt\u22121)].\nConsider the conditional LLRt(y |xt,x1:t\u22121,y1:t\u22121), denoted by LLRt(y) for convenience. Suppose we have sampled at x\u2217t and observed y \u2217 t . Then LLRt(y \u2217 t ) is:\nLLRt(y \u2217 t ) = logN (y\u2217t |\u00b5t1(x\u2217t ), (\u03c3t1(x\u2217t ))2) \u2212 logN (y\u2217t |\u00b5t0(x\u2217t ), (\u03c3t0(x\u2217t ))2).\nFinally, the LLR of all the observed samples, LLR1:t is given by:\nLLR1:t = LLR1:t\u22121 + LLRt(y \u2217 t ). (3)\nAfter each observation we compare LLR1:t with two thresholds \u03981 and \u03980. If the LLR is above the first one, then we stop sampling and decide the node is active. If below the second threshold, we decide the node is inactive. Finally, if neither of these conditions holds we continue collecting data.\nSampling Strategy: The only remaining issue for this hypothesis testing procedure is to decide on the next sample. Note that, under H1, the conditional distribution of the likelihood ratio for a sample at point xt follows a shifted non-central Chi-squared distribution:\nLLRt(yt) \u223c w2\u03c72(1, \u03bb) + w0,\nwhere w2 \u2261 0.5 ( \u03c3t1(xt) 2/\u03c3t0(xt) 2 \u2212 1 ) , w0 \u2261 log(\u03c3t0(xt)/\u03c3 t 1(xt)) \u2212 (\u00b5t1(xt)\u2212\u00b5 t 0(xt)) 2\n2(\u03c3t1(xt) 2\u2212\u03c3t0(xt)2) and \u03bb =( \u03c3t1(xt)(\u00b5 t 1(xt)\u2212\u00b5 t 0(xt))\n\u03c3t1(xt) 2\u2212\u03c3t0(xt)2\n)2 .\nGiven that we want to decide as quickly as we can if a node is active, it makes sense to choose the point xt that tends to maximize LLRt(yt) the most. A natural choice is to take xt maximizing E(LLRt(yt)) + \u221a V(LLRt(yt)). This choice is easily justified in light of tail bounds for Chi-squared distributions, such as those in the long version of the paper. Finally, as at each moment we are considering multiple nodes in the tree, we choose the node I that maximizes the above quantity over all nodes. Let UCB(I, xt) = E(LLRI,t(yt)) + \u221a V(LLRI,t(yt)). We choose point xt and node I so to maximize this index. In other words, we choose the node I that is more likely to be deemed active after sampling. The complete procedure is described in Algorithm 1. Fig 1 shows an example of the search tree.\nThe following theorem characterizes the accuracy and sample complexity of HDS when using an arbitrary testing procedure block.\nAlgorithm 1 Hierarchical Diagonal Sampling\nInput: Sample budget; Thresholds \u03981, \u03980; D. Initialize root I0 \u2190\u2212 D, LLR(I0)\u2190\u2212 0 Initialize tree T \u2190\u2212 {I0}, active set A \u2190\u2212 \u2205. while # samples \u2264 budget and |T | > 0 do\nif FDT then Sample node I \u2190\u2212 arg maxI\u2032\u2208T LLR(I \u2032), then sample x\u2032 \u2208 [\u22121 1] uniformly at random. else if GPT then Sample I, x\u2190\u2212 arg maxI\u2032\u2208T ,x\u2032\u2208[\u22121 1] UCB(I \u2032, x\u2032) update index UCB(I, x\u2032) \u2200x\u2032 \u2208 [\u22121 1] Compute LLR(I) using Eq 1 or 3 if LLR(I) \u2265 \u03981 (I is active) then\nTheorem 3.2. Let A\u2032 denote the set of active dimensions identified by the HDS algorithm, also let \u03b1 and \u03b2 denote respectively the false positive and false negative rates for the testing procedure used. All logs are base-2. Accuracy: For an arbitrary > 0, provided \u03b1, \u03b2 \u2264 ( /D)1/dlogDe the probability of perfect recovery is P (A\u2032 = A) \u2265 1\u2212 . Sample Complexity: Let Tmax be the maximum expected sample usage per node, and N be the sample complexity of the HDS algorithm. The expected sample complexity is bounded by:\nE(N) \u2264 2(1\u2212 \u03b1) 1\u2212 2\u03b1 ddlogDeTmax (4)\nThe proof of the first part expresses the probability of any particular leaf node being correctly classified,\nand then applies a union bound on the event that all the leaf nodes are classified correctly. For the second part we study how testing errors change the tree generated by HDS under perfect conditions. Since every node incorrectly deemed active can spawn at most 2 inactive children with probability \u03b1 we can get an upper bound on expected number of active nodes, and in turn, the worst case expected sample complexity. See the extended paper for details.\nTheorem 3.3. Given > 0, set \u03b4 = 6ddlogDe and \u03b1 = ( /(2D))1/dlogDe. Assume is small enough so that \u03b1 < 1/4. Assume b \u2264 2(log(1/\u03b4)2 . Consider the HDS algorithm with non-sequential FDT using a fixed sample size per node A log (2/\u03b1),\nwhere A \u2261 max { 2, 16(1+ \u221a 1+B ) 2\nB2 , 8B2\n} and B \u2261\n\u03c32sb 2/(4096c22 log(4c1/(b\u03b4))), where c1, c2 > 0 are constants. Then, for a judicious choice of c1 and c2 the HDS-FDT procedure is correct with probability at least 1\u2212 , and the sample complexity:\nN < N \u2261 A ddlogDe(log 16 + log (1/ )\ndlogDe ). (5)\nNote that A = \u0398 ((log(1/ ) + log(ddlogDe))8), and N = \u0398 ( (log 1 + log(ddlogDe)) 8d(dlogDe+ log 1 ) ) . The proof (given in the extended paper) consists essentially in plugging in the results of Theorem 3.1 in Proposition 3.1, and applying theorem 3.2."}, {"heading": "4. Optimization", "text": "After identifying the set A of active variables, we focus on optimizing f over these relevant dimensions. In principle, various algorithms can be used for this purpose. We consider the GP-UCB algorithm (Srinivas et al., 2010). GP-UCB is a greedy algorithm, which iteratively picks the point\nxt+1 = argmax x\u2208[\u22121,1]D\n\u00b5t(x) + \u03b2 1/2 t \u03c3t(x),\nwhere \u00b5t(x) and \u03c3 2 t (x) are the posterior mean and variance at input x, conditioned on the first samples x1, . . . ,xt and associated observations y1, . . . , yt. \u03b21, . . . , \u03b2T is an appropriate sequence of constants for balancing exploration (choosing uncertain x with large variance) and exploitation (choosing x with large means), as specified in detail by Srinivas et al. (2010). For GP-UCB, strong performance guarantees are known: In particular, Theorem 2 of Srinivas et al. (2010) bounds the cumulative regret of GP-UCB in terms of the maximum information gain \u03b3T obtainable by observing f at an arbitrary set of T inputs x1:T . Hereby, \u03b3T is a monotonically increasing function of T , depending on the covariance function and domain of the GP. For the squared exponential kernel it is bounded by O((log T )d\n\u2032+1), where d\u2032 is the dimensionality of the underlying space. The cumulative\nregret of GP-UCB is bounded by O\u2217( \u221a T\u03b3T ) (where the O\u2217 notation hides logarithmic factors).\nStraightforward application of GP-UCB without variable selection would lead to regret bounds depending on the extrinsic dimensionality d\u2032 = D. However, after variable selection we can apply GP-UCB only to variables that are deemed active, obtaining a regret bound depending on d\u2032 = d, the intrinsic dimensionality only.\nAssume that function value f(x) is bounded so that the maximum regret per sample is bounded by C0. Let N be the termination time of the HDS procedure, x\u2217\na global optimum of f and RT = \u2211T t=1[f(x\n\u2217)\u2212 f(xt)] the cumulative regret.\nTheorem 4.1. \u2200T \u2208 N\u2217, \u03b4o > 0, set = 1/T and\n\u03b2t = 2 log( t22\u03c02\n3\u03b4o ) + 2d log ( 2t2d\u03c3s b \u221a log( 4d \u03b4o ) ) .\nRunning HDS with FDT and recovery rate 1 \u2212 , followed by the GP-UCB algorithm on the variables deemed active guarantees that with probability \u2265 1\u2212\u03b4o:\nE(RT ) \u2264 A\u2032T \u221a T + (N + 1)C0 + 2 +\nN C0 T .\nwhere A\u2032T = \u221a C1\u03b2T \u03b3T = O((log T )\nd/2+1, C1 = 8/ log(1 + b\u22122), and N = O(log(1/ ) 9) = O((log T )9).\nThus, the regret depends only logarithmically on the extrinsic dimension D.\nThe proof (given in the extended paper) bounds the worst case regret separately for the variable selection and optimization phases, assuming that maximum regret is incurred during HDS and, if HDS fails, during every round of the GP-UCB procedure. The former cases incurs linear regret for finite numbers of samples, and the latter does so for all samples but with a small probability . When HDS is successful, Theorem 2 of Srinivas et al. (2010) guarantees a sub-linear regret bound for GP-UCB."}, {"heading": "5. Experiments and Results", "text": "We compare HDS with a natural baseline called Coordinate-wise Sampling (CWS). CWS computes finite differences along each dimension separately using the same number of samples, and outputs the dimensions with the largest variance. We clairvoyantly choose the number of samples CWS needs to successfully recover all the active dimensions. Doing so favors the CWS algorithm in comparison to HDS.\nFunctions sampled from a GP: We consider the case where the test function is a sample from a GP with a squared-exponential kernel: b = 0.1\nand self variance \u03c32s = 1. We vary the total number of dimensions D \u2208 {10, 20, 40, 80, 200, 400}, \u03c32n \u2208 {0.05, 0.1, 0.25, 0.36}, and compare FDT, GPT and CWS in terms of accuracy (recovery probability) and sample complexity. The thresholds {\u03981,\u03980} were optimized using grid search over \u03981 \u2208 {5, 10, 20} and \u03980 \u2208 {\u22125,\u221210,\u221220} to ensure maximum recovery accuracy with the minimum sample complexity for the setting of D = 200, \u03c32n = 0.1. The optimal value is then used for all settings. We repeat each setting for 20 random trials and report the mean \u00b1 3 standard error. Accuracies of HDS under all settings are 100%. Fig 2 shows how sample complexity varies as a function of dimensionality D and noise parameters \u03c32. As predicted, the complexity grows linearly with log(D), the logarithm of the extrinsic dimension, and linearly with the noise level. GPT consistently uses about 50% less samples than FDT. In contrast, CWS is less stable and scales linearly as D. Using the oracle parameter setting CWS has little dependence on \u03c32, yet HDS remains more efficient even in highly noisy situations.\nWe also examine the sensitivity of HDS w.r.t. the assumption that the noise parameter \u03c32 and the bandwidth b are known. Fig 3 shows accuracy and sample complexity as a function of the ratio between the misestimated \u03c3 and the truth. FDT can tolerate overand under-estimation of the noise level by a factor of 2, while GPT is more stable, withstanding misestimation by factors of 0.5 to 10. Both methods are robust w.r.t. b. Sample complexity and accuracy remain constant (FDT: 412 samples, 100% accuracy, GPT, 228 samples, 100% accuracy) when b is misestimated by factors of 0.01 to 10.\nFunctions embedded in high dimensions: We also take the following low dimensional functions and hide them in a D = 200 dimensional space:\nQuad: quadratic function (d = {2, 4, 6}). Quad(x) = (P (x\u2212x\u2217))T (P (x\u2212x\u2217))+\u03c32n where x\u2217 is a random vector and P is a diagonal projection matrix: Pii = 1/b if i \u2208 A and Pii = 1/100 otherwise. QuadMix: quadratic with linear mixture (d =\n{2, 4, 6}). Similar to Quad(x), QuadMix(x) = (MP (x \u2212 x\u2217))T (MP (x \u2212 x\u2217)) + \u03c32n where M = (1 \u2212 rmix)I+ rmix. rmix = 1/D controls how the irrelevant dimensions interfere with the relevant ones. Branin: (d = 2) is a classical test function for unconstrained global optimization. It has a broad global landscape and peaks at (\u22121,\u22121). Beale: (d = 2) is a challenging test function. It remains flat for 90% in the domain, and gets flatter the closer it gets to the optimum.\nWe compare accuracy and sample complexity for the FDT, GPT and CWS. All functions are rescaled to [\u22121 1] and the best parameter set found in the previous section is used4. The sample size is limited at 2000 per function. Error bars are obtained from 20 trials. The accuracies for Quad and QuadMix are shown in Table 1. The sample complexity for Quad and QuadMix are shown in Fig 4. The complexity for Branin is: FDT (267 \u00b1 28), GPT(236 \u00b1 12) and CWS (1703 \u00b1 96). The complexity for Beale is: FDT(280\u00b110), GPT(674\u00b144) and CWS (1802\u00b182).\nThe results for Quad, QuadMix and Branin agree with the case of GP test functions and the theoretical analysis, showing the sample complexity\u2019s linear dependence on the relevant dimensions and logarithmic dependence on the extrinsic dimensionality. HDS (with testing blocks FDT or GPT) does not work for Beale because it is mostly constant, and therefore it is severely different than a typical sample from a GP.\nJoint Variable Selection and Optimization Finally we compare the optimization performance of our 2-step procedure of HDS followed by GP-UCB against the conventional GP-UCB algorithm on all D dimensions. Note that if D is large, GP-UCB becomes in-\n4In practice these parameters could be learned from a small set of held-out samples, or refined online.\nfeasible, in which case our method has a clear advantage. Even with small D, however, we show in Fig 5(b) and 5(c) that our method achieves a faster reduction in the average regret RT /T , and obtains better minimum regrets mint[f(x \u2217)\u2212 f(xt)]."}, {"heading": "6. Conclusions", "text": "We considered the problem of optimizing high dimensional functions that only depend on few active variables. We proposed HDS for variable selection and analyzed its sampling complexity in terms of properties of a modular hypothesis testing subroutine. For a classical (non-sequential) subroutine we proved sample complexity bounds, implying strong end-to-end performance guarantees for GP optimization in high dimensions. We also explored two practical alternatives based on sequential hypothesis testing and demonstrated their effectiveness on several high-dimensional optimization problems. We believe that our results provide important insights towards solving high dimensional optimization problems under uncertainty.\nAcknowledgments. This work was partially supported by SNSF grant 200021 137971, NSF IIS\u22120953413 and DARPA MSEE FA8650-11-17156."}], "references": [{"title": "Onlineto-confidence-set conversions and application to sparse stochastic bandits", "author": ["Y. Abbasi-Yadkori", "D. P\u00e1l", "C. Szepesv\u00e1ri"], "venue": "In AISTATS,", "citeRegEx": "Abbasi.Yadkori et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Abbasi.Yadkori et al\\.", "year": 2012}, {"title": "A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning", "author": ["E. Brochu", "V.M. Cora", "N. de Freitas"], "venue": "Arxiv preprint arXiv:1012.2599,", "citeRegEx": "Brochu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Brochu et al\\.", "year": 2010}, {"title": "Bandit theory meets compressed sensing for high dimensional stochastic linear bandit", "author": ["A. Carpentier", "R Munos"], "venue": null, "citeRegEx": "Carpentier and Munos,? \\Q2012\\E", "shortCiteRegEx": "Carpentier and Munos", "year": 2012}, {"title": "For most large underdetermined systems of linear equations the minimal l1-norm solution is also the sparsest solution", "author": ["D.L. Donoho"], "venue": "Communications on pure and applied mathematics,", "citeRegEx": "Donoho,? \\Q2006\\E", "shortCiteRegEx": "Donoho", "year": 2006}, {"title": "Towards gaussian processbased optimization with finite time horizon", "author": ["D. Ginsbourger", "R. Riche"], "venue": "Adv. ModelOr. Design & Analysis, pp", "citeRegEx": "Ginsbourger and Riche,? \\Q2010\\E", "shortCiteRegEx": "Ginsbourger and Riche", "year": 2010}, {"title": "Distilled sensing: Adaptive sampling for sparse detection and estimation", "author": ["J. Haupt", "R. Castro", "R. Nowak"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Haupt et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Haupt et al\\.", "year": 2011}, {"title": "Nonmyopic active learning of gaussian processes: An exploration\u2013exploitation approach", "author": ["A. Krause", "C. Guestrin"], "venue": "In ICML,", "citeRegEx": "Krause and Guestrin,? \\Q2007\\E", "shortCiteRegEx": "Krause and Guestrin", "year": 2007}, {"title": "Rodeo: sparse, greedy nonparametric regression", "author": ["J. Lafferty", "L. Wasserman"], "venue": "The Annals of Statistics,", "citeRegEx": "Lafferty and Wasserman,? \\Q2008\\E", "shortCiteRegEx": "Lafferty and Wasserman", "year": 2008}, {"title": "Automatic gait optimization with Gaussian process regression", "author": ["D. Lizotte", "T. Wang", "M. Bowling", "D. Schuurmans"], "venue": "In IJCAI, pp", "citeRegEx": "Lizotte et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Lizotte et al\\.", "year": 2007}, {"title": "Bayesian interpolation", "author": ["D.J.C. MacKay"], "venue": "Neural computation,", "citeRegEx": "MacKay,? \\Q1992\\E", "shortCiteRegEx": "MacKay", "year": 1992}, {"title": "Gaussian Processes for Machine Learning", "author": ["C.E. Rasmussen", "C.K.I. Williams"], "venue": null, "citeRegEx": "Rasmussen and Williams,? \\Q2006\\E", "shortCiteRegEx": "Rasmussen and Williams", "year": 2006}, {"title": "Sequential analysis: tests and confidence intervals", "author": ["D. Siegmund"], "venue": null, "citeRegEx": "Siegmund,? \\Q1985\\E", "shortCiteRegEx": "Siegmund", "year": 1985}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["N. Srinivas", "A. Krause", "S. Kakade", "M. Seeger"], "venue": "In ICML,", "citeRegEx": "Srinivas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srinivas et al\\.", "year": 2010}, {"title": "Regression shrinkage and selection via the lasso", "author": ["R. Tibshirani"], "venue": "J Royal Stat Soc B, pp", "citeRegEx": "Tibshirani,? \\Q1996\\E", "shortCiteRegEx": "Tibshirani", "year": 1996}], "referenceMentions": [{"referenceID": 8, "context": "This problem occurs in various domains, for instance when learning optimal control strategies for robots (Lizotte et al., 2007), or when optimizing industrial processes that depend on many variables.", "startOffset": 105, "endOffset": 127}, {"referenceID": 13, "context": "For example, Lasso (Tibshirani, 1996) tackles this combinatorial problem using an continuous approximation, which has been shown to be optimal under certain conditions (Donoho, 2006).", "startOffset": 19, "endOffset": 37}, {"referenceID": 3, "context": "For example, Lasso (Tibshirani, 1996) tackles this combinatorial problem using an continuous approximation, which has been shown to be optimal under certain conditions (Donoho, 2006).", "startOffset": 168, "endOffset": 182}, {"referenceID": 3, "context": "For example, Lasso (Tibshirani, 1996) tackles this combinatorial problem using an continuous approximation, which has been shown to be optimal under certain conditions (Donoho, 2006). Alternative models have been proposed to handle non-linear response functions. Automatic Relevance Determination (ARD, MacKay (1992)) is a Bayesian variable selection procedure that imposes a Gaussian prior on the bandwidths of the variables, which can be combined with a GP likelihood to handle non-linear functions.", "startOffset": 169, "endOffset": 317}, {"referenceID": 5, "context": "Also bearing similarities to our work is Distilled Sensing (Haupt et al., 2011), which attempts to quickly identify large portions of the variable space that are irrelevant, therefore reducing the search complexity as more data is collected, and effectively shedding the dependency on the extrinsic dimension.", "startOffset": 59, "endOffset": 79}, {"referenceID": 1, "context": "One line of work called Bayesian global optimization (Ginsbourger & Riche, 2010; Brochu et al., 2010) assumes the unknown function is sampled from a GP.", "startOffset": 53, "endOffset": 101}, {"referenceID": 12, "context": "In particular, the GP-UCB (Srinivas et al., 2010) algorithm has been shown to have sub-linear regret and work well emprically.", "startOffset": 26, "endOffset": 49}, {"referenceID": 0, "context": "Recently, the problem of joint variable selection and linear optimization has been tackled by (Abbasi-Yadkori et al., 2012), who exploit sparsity to alleviate the curse of dimensionality.", "startOffset": 94, "endOffset": 123}, {"referenceID": 12, "context": "After the identification of active variables, we apply the GP-UCB algorithm (Srinivas et al., 2010) to optimize over the variables deemed active.", "startOffset": 76, "endOffset": 99}, {"referenceID": 11, "context": "We now employ sequential hypothesis testing using the sequential likelihood ratio test (SLRT) as described in Siegmund (1985). This is an incremental procedure that sequentially computes the log likelihood ratio (LLR) between two hypotheses, and makes a decision once this ratio crosses two predetermined boundaries.", "startOffset": 110, "endOffset": 126}, {"referenceID": 12, "context": "We consider the GP-UCB algorithm (Srinivas et al., 2010).", "startOffset": 33, "endOffset": 56}, {"referenceID": 12, "context": ", \u03b2T is an appropriate sequence of constants for balancing exploration (choosing uncertain x with large variance) and exploitation (choosing x with large means), as specified in detail by Srinivas et al. (2010). For GP-UCB, strong performance guarantees are known: In particular, Theorem 2 of Srinivas et al.", "startOffset": 188, "endOffset": 211}, {"referenceID": 12, "context": ", \u03b2T is an appropriate sequence of constants for balancing exploration (choosing uncertain x with large variance) and exploitation (choosing x with large means), as specified in detail by Srinivas et al. (2010). For GP-UCB, strong performance guarantees are known: In particular, Theorem 2 of Srinivas et al. (2010) bounds the cumulative regret of GP-UCB in terms of the maximum information gain \u03b3T obtainable by observing f at an arbitrary set of T inputs x1:T .", "startOffset": 188, "endOffset": 316}, {"referenceID": 12, "context": "When HDS is successful, Theorem 2 of Srinivas et al. (2010) guarantees a sub-linear regret bound for GP-UCB.", "startOffset": 37, "endOffset": 60}], "year": 2012, "abstractText": "Maximizing high-dimensional, non-convex functions through noisy observations is a notoriously hard problem, but one that arises in many applications. In this paper, we tackle this challenge by modeling the unknown function as a sample from a high-dimensional Gaussian process (GP) distribution. Assuming that the unknown function only depends on few relevant variables, we show that it is possible to perform joint variable selection and GP optimization. We provide strong performance guarantees for our algorithm, bounding the sample complexity of variable selection, and as well as providing cumulative regret bounds. We further provide empirical evidence on the effectiveness of our algorithm on several benchmark optimization problems.", "creator": "LaTeX with hyperref package"}}}