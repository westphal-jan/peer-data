{"id": "1206.6454", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Hierarchical Exploration for Accelerating Contextual Bandits", "abstract": "Contextual bandit learning is an increasingly popular approach to optimizing recommender systems via user feedback, but can be slow to converge in practice due to the need for exploring a large feature space. In this paper, we propose a coarse-to-fine hierarchical approach for encoding prior knowledge that drastically reduces the amount of exploration required. Intuitively, user preferences can be reasonably embedded in a coarse low-dimensional feature space that can be explored efficiently, requiring exploration in the high-dimensional space only as necessary. We introduce a bandit algorithm that explores within this coarse-to-fine spectrum, and prove performance guarantees that depend on how well the coarse space captures the user's preferences. We demonstrate substantial improvement over conventional bandit algorithms through extensive simulation as well as a live user study in the setting of personalized news recommendation.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (1601kb)", "http://arxiv.org/abs/1206.6454v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["yisong yue", "sue ann hong", "carlos guestrin"], "accepted": true, "id": "1206.6454"}, "pdf": {"name": "1206.6454.pdf", "metadata": {"source": "CRF", "title": "Hierarchical Exploration for Accelerating Contextual Bandits", "authors": ["Yisong Yue", "Sue Ann Hong", "Carlos Guestrin"], "emails": ["yisongyue@cmu.edu", "sahong@cs.cmu.edu", "guestrin@cs.cmu.edu"], "sections": [{"heading": "1. Introduction", "text": "User feedback (e.g., ratings and clicks) has become a crucial source of training data for optimizing recommender systems. When making recommendations, one must balance the needs for exploration (gathering informative feedback) and exploitation (maximizing estimated user utility). A common formalization of such a problem is the linear stochastic bandit problem (Li et al., 2010), which models user utility as a linear function of user and content features.\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nUnfortunately, conventional bandit algorithms can converge slowly with even moderately large feature spaces. For instance, the well-studied LinUCB algorithm (Dani et al., 2008; Abbasi-Yadkori et al., 2011) achieves a regret bound that is linear in the dimensionality of the feature space, which cannot be improved without further assumptions.1\nIntuitively, any bandit algorithm make recommendations that cover the entire feature space in order to guarantee learning a reliable user model. Therefore, a common approach to dealing with slow convergence is dimensionality reduction based on prior knowledge, such as previously learned user profiles, by representing new users as linear combinations of \u201cstereotypical users\u201d (Li et al., 2010; Yue & Guestrin, 2011).\nHowever, if a user deviates from stereotypical users, then a reduced space may not be expressive enough to adequately learn her preferences. The challenge lies in appropriately leveraging prior knowledge to reduce the cost of exploration for new users, while maintaining the representational power of the full feature space.\nOur solution is a coarse-to-fine hierarchical approach for encoding prior knowledge. Intuitively, a coarse, low-rank subspace of the full feature space may be sufficient to accurately learn a stereotypical user\u2019s preferences. At the same time, this coarse-to-fine feature hierarchy allows exploration in the full space when a user is not perfectly modeled by the coarse space.\nWe propose an algorithm, CoFineUCB, that automatically balances exploration within the coarse-to-fine feature hierarchy. We prove regret bounds that depend on how well the user\u2019s preferences project onto the coarse subspace. We also present a simple and general method for constructing feature hierarchies using prior knowledge. We perform empirical valida-\n1The regret bound is information-theoretically optimal up to log factors (Dani et al., 2008).\ntion through simulation as well as a live user study in personalized news recommendation, demonstrating that CoFineUCB can substantially outperform conventional methods utilizing only a single feature space."}, {"heading": "2. The Learning Problem", "text": "We study the linear stochastic bandit problem (Abbasi-Yadkori et al., 2011), which formalizes a recommendation system as a bandit algorithm that iteratively performs actions and learns from rewards received per action. At each iteration t = 1, . . . , T , our algorithm interacts with the user as follows:\n\u2022 The system recommends an item (i.e., performs an action) associated with feature vector xt \u2208 Xt \u2282 \nD, which encodes content and user features.\n\u2022 The user provides feedback (i.e., reward) y\u0302t.\nRewards y\u0302t are modeled as a linear function of actions x \u2208 D such that E[y\u0302t|x] = w\u2217x, where the weight vector w\u2217 denotes the user\u2019s (unknown) preferences. We assume feedback to be independently sampled and bounded within [0, 1],2 and that x \u2264 1 holds for all x. We quantify performance using the notion of regret which compares the expected rewards of the selected actions versus the optimal expected rewards:\nRT (w \u2217) =\nT\nt=1\nw\u2217x\u2217t \u2212 w\u2217xt, (1)\nwhere x\u2217t = argmaxx\u2208Xt w \u2217Tx.3\nWe further suppose that user preferences are distributed according to some distribution W. We can then define the expected regret over W as\nRT (W) = Ew\u2217\u223cW [RT (w\u2217)] , (2)\nand the goal now for the bandit algorithm is to perform well with respect to W. We will present an approach for optimizing (2) given a collection of existing user profiles sampled i.i.d. from W."}, {"heading": "3. Feature Hierarchies", "text": "To learn a reliable user model (i.e., a reliable estimate of w\u2217) from user feedback, bandit algorithms must make recommendations that explore the entire D-dimensional feature space. Conventional bandit algorithms such as LinUCB place uniform a priori importance on each dimension, which can be inefficient\n2Our results also hold when each y\u0302t is independent with sub-Gaussian noise and mean w\u2217xt (see Appendix A).\n3Since the rewards are sampled independently, any guarantee on (1) translates into a high probability guarantee on the regret of the observed feedback T t=1 w \u2217x\u2217t\u2212y\u0302t.\nin practice, especially if additional structure can be assumed. We now motivate and formalize one such structure: the feature hierarchy.\nFor example, suppose that two of the D features correspond to interest in articles about baseball and cricket. Suppose also that our prior knowledge suggests that users are typically interested in one or the other, but rarely both. Then we can design a feature subspace where baseball and cricket topics project along opposite directions in a single dimension. A bandit algorithm leveraging this structure should, ideally, first explore at a coarse level to determine whether the user is more interested in articles about baseball or cricket.\nWe can formalize the different levels of exploration as a hierarchy that is composed of the full feature space and a subspace. We define a K-dimensional subspace using a matrix U \u2208 D\u00d7K , and denote the projection of action x \u2208 D into the subspace as\nx\u0303 \u2261 Ux.\nLikewise, we can write the user\u2019s preferences w\u2217 as\nw\u2217 = Uw\u0303\u2217 + w\u2217\u22a5, (3)\nwhere we call w\u2217\u22a5 the residual, or orthogonal component, of w\u2217 w.r.t. U . Then,\nw\u2217x = w\u0303\u2217x\u0303+ w\u2217\u22a5 x.\nFigure 1 illustrates a feature hierarchy with a two dimensional subspace. Here, w\u2217 projects well to the subspace, so we expect w\u2217x \u2248 w\u0303\u2217x\u0303 (i.e., w\u2217\u22a5 is small). In such cases, a bandit algorithm can focus exploration on the subspace to achieve faster convergence."}, {"heading": "3.1. Extension to Deeper Hierarchies", "text": "For the -th level, we define the projected w\u2217 as\nw\u2217\u22121 = Uw \u2217  + w \u2217 ,\u22a5.\nThen,\nw\u2217 = U1(U2(. . . (ULw \u2217 L + w \u2217 L\u22121,\u22a5) . . . w \u2217 1,\u22a5) + w \u2217 \u22a5.\nAlgorithm 1 CoFineUCB\n1: input: \u03bb, \u03bb\u0303, U , ct(\u00b7), c\u0303t(\u00b7) 2: for t = 1, . . . , T do 3: Define Xt \u2261 [x1, x2, . . . , xt\u22121] 4: Define X\u0303t \u2261 U\nXt 5: Define Yt \u2261 [y\u03021, y\u03022, . . . , y\u0302t\u22121] 6: M\u0303t \u2190 \u03bb\u0303IK + X\u0303tX\u0303  t 7: w\u0303t \u2190 M\u0303 \u22121 t X\u0303tY  t //least squares on coarse level 8: Mt \u2190 \u03bbID +XtX  t 9: wt \u2190M \u22121 t (XtY  t + \u03bbUw\u0303t) //least sq on fine level\n10: Define \u00b5t(x) \u2261 w  t x 11: xt \u2190 argmaxx\u2208Xt \u00b5t(x)+ct(x)+c\u0303t(x) //play action with highest upper confidence bound 12: Recommend xt, observe reward y\u0302t 13: end for\nFor simplicity and practical relevance, we focus on twolevel hierarchies."}, {"heading": "4. Algorithm & Main Results", "text": "We now present a bandit algorithm that exploits feature hierarchies. Our algorithm, CoFineUCB, is an upper confidence bound algorithm that generalizes the well-studied LinUCB algorithm, and automatically trades off between exploring the coarse and full feature spaces. CoFineUCB is described in Algorithm 1. At each iteration t, CoFineUCB estimates the user\u2019s preferences in the subspace, w\u0303t, as well as the full feature space, wt. Both estimates are solved via regularized least-squares regression. First, w\u0303t is estimated via\nw\u0303t = argmin w\u0303\nt\u22121\n\u03c4=1\n(w\u0303x\u0303\u03c4 \u2212 y\u0302\u03c4 )2 + \u03bb\u0303w\u03032, (4)\nwhere x\u0303\u03c4 \u2261 Ux\u03c4 denotes the projected features of the action taken at time \u03c4 . Then wt is estimated via\nwt = argmin w\nt\u22121\n\u03c4=1\n(wx\u03c4 \u2212 y\u0302\u03c4 )2 + \u03bbw \u2212 Uw\u0303t2, (5)\nwhich regularizes wt to the projection of w\u0303t back into the full space. Both optimization problems have closed form solutions (Lines 7 & 9 in Algorithm 1).\nCoFineUCB is an optimistic algorithm that chooses the action with the largest potential reward (given some target confidence). Selecting such an action requires computing confidence intervals around the mean estimate wt. We maintain confidence intervals for both the full space and the subspace, denoted ct(\u00b7) and c\u0303t(\u00b7), respectively. Intuitively, a valid 1\u2212 \u03b4 confidence interval should satisfy the property that\n|x(wt \u2212 w\u2217)| \u2264 ct(x) + c\u0303t(x) (6)\nholds with probability at least 1\u2212 \u03b4.\nWe will show that the following definitions of ct(\u00b7) and c\u0303t(\u00b7) yield a valid 1\u2212 \u03b4 confidence interval:\nc\u0303t(x) = \u03b1\u0303 (v) t UM\u22121t x  M\u0303\u22121t + \u03b1\u0303(b)t M\u0303\u22121t UM\u22121t x  (7) ct(x) = \u03b1 (v) t xM\u22121t + \u03b1(b)t M\u22121t x  , (8)\nwhere \u03b1\u0303(v)t , \u03b1\u0303 (b) t , \u03b1 (v) t , and \u03b1 (b) t are coefficients that must be set properly (Lemma 1).\nBroadly speaking, there are two types of uncertainty affecting an estimate, wt x, of the utility of x: variance and bias. In our setting, variance is due to the stochasticity of user feedback y\u0302t. Bias, on the other hand, is due to regularization when estimating w\u0303t and wt. Intuitively, as our algorithm receives more feedback, it becomes less uncertain (w.r.t. both bias and variance) of its estimates, w\u0303t and wt. This notion of uncertainty is captured via the inverse feature covariance matrices M\u0303t andMt (Lines 6 & 8 in Algorithm 1). Table 1 provides an interpretation of the four sources of uncertainty described in (7) and (8).\nLemma 1 below describes how to set the coefficients such that ct(x)+c\u0303t(x) is a valid 1\u2212\u03b4 confidence bound. Lemma 1. Define S\u0303 = w\u0303\u2217 and S\u22a5 = w\u2217\u22a5, and let\n\u03b1(v)t =  log  det (Mt) 1/2 det (\u03bbID) 1/2 /\u03b4 \n\u03b1\u0303(v)t = \u03bb\n\nlog  det  M\u0303t 1/2 det  \u03bb\u0303IK 1/2 /\u03b4 \n\u03b1(b)t = \u221a 2\u03bbS\u22a5 \u03b1\u0303(b)t = \u03bb\u03bb\u0303S\u0303.\nThen (6) is a valid 1\u2212 \u03b4 confidence interval.\nWith the confidence intervals defined, we are now ready to present our main result on the regret bound.\nTheorem 1. Define c\u0303t(\u00b7) and ct(\u00b7) as in (7), (8) and Lemma 1. For \u03bb \u2265 maxx x2 and \u03bb\u0303 \u2265 maxx x\u03032, with probability 1\u2212 \u03b4, CoFineUCB achieves regret\nRT (w \u2217) \u2264  \u03b2T \u221a D + \u03b2\u0303T \u221a K  2T log(1 + T ),\nwhere\n\u03b2T =  D log((1 + T/\u03bb)/\u03b4) + \u221a 2\u03bbS\u22a5 (9) \u03b2\u0303T =  K log((1 + T/\u03bb\u0303)/\u03b4) +  \u03bb\u0303S\u0303. (10)\nLemma 1 and Theorem 1 are proved in Appendix A.\nTheorem 1 essentially bounds the regret as\nRT (w \u2217) = O  \u03bb\u0303w\u0303\u2217K + \u221a 2\u03bbw\u2217\u22a5D \u221a T  , (11)\nignoring log factors. In contrast, the conventional LinUCB algorithm only explores in the full feature space and achieves an analogous regret bound of\nRT (w \u2217) = O \u221a \u03bbw\u2217D \u221a T  . (12)\nComparing (11) with (12) suggests that, when K << D and w\u2217\u22a5 is small, CoFineUCB suffers much less regret due to more efficient exploration. Depending on U , w\u0303\u2217 can also be much smaller than w\u2217. Section 5 describes an approach for computing such a U .\nIntuitively, CoFineUCB enjoys a superior regret bound to LinUCB due to its use of tighter confidence regions. Figure 2 depicts a comparative example. LinUCB employs ellipsoid confidence regions. CoFineUCB utilizes confidence regions that are essentially the convolution of two smaller ellipsoids, which can be much smaller than the confidence regions of LinUCB."}, {"heading": "5. Constructing Feature Hierarchies", "text": "We now show how to construct a subspace U using preexisting user profiles W = {w\u2217i }Ni=1, where each profile is sampled independently from a common distribution w\u2217i \u223c W. In this setting, a reasonable objective is to find a U that minimizes an empirical estimate of the bound on RT (W), which comprises w\u0303 and w\u22a5. Our approach is outlined in Algorithm 2. We assume that finding a K-dimensional subspace with low residual norms w\u2217\u22a5 is straightfoward. In our experiments, we simply use the top K singular vectors of W .\nAlgorithm 2 LearnU: learning projection matrix\n1: input: W \u2208 D\u00d7N , K \u2208 {1, . . . , D} 2: (A,\u03a3, B)\u2190 SV D(W ) 3: U0 \u2190 A1:K //top K singular vectors 4: Solve for \u2126 via (16) using U0 and W 5: return: U0\u2126 1/2\nGiven an orthonormal basis U0 \u2208 K\u00d7D, one can choose U \u2208 span(U0) to minimize its total contribution to the regret bound in (11) over the users in W :\nargmin U\u2208span(U0)\nC\u0303 \nw\u2208W w\u0303, (13)\nwhere w\u0303 \u2261 (UU)\u22121Uw, and C\u0303 = maxx Ux constrains the magnitude of U .\nIt is difficult to optimize (13) directly, so we approximate it using a smooth formulation,4\nargmin U\u2208span(U0):U2Fro=K\n\nw\u2208W w\u03032, (14)\nwhere we now constrain U via U2Fro = K. We further restrict U to be U \u2261 U0\u21261/2 for \u2126  0. Under this restriction, (14) is equivalent to\nargmin \u2126:trace(\u2126)=K\n\nw\u2208W w\u03030 \u2126\u22121w\u030302, (15)\nwhere w\u03030 \u2261 (U0 U0)\u22121U0 w = U0 w. This formulation is akin to multi-task structure learning, where W0 would denote the various tasks and \u2126 denotes feature relationships common across tasks (Argyriou et al., 2007; Zhang & Yeung, 2010). One can show that (15) is convex and is minimized by\n\u2126 = K\ntrace \nW\u03030W\u03030\n W\u03030W\u03030 , (16)\nwhere W\u03030 \u2261 (U0 U0)\u22121U0 W = U0 W . See Appendix B for a more detailed derivation."}, {"heading": "6. Experiments", "text": "We evaluate CoFineUCB via both simulations and a live user study in the personalized news recommendation domain. We first describe alternative methods, or baselines, for leveraging prior knowledge (pre-existing profiles W \u2208 D\u00d7N ) that do not use a feature hierarchy. These baselines can conceptually be phrased as special cases of CoFineUCB. The key idea is to alter\n4One can also regularize by inserting an axis-aligned \u201cridge\u201d into W (i.e., W \u2190 [W, ID]).\nthe feature space such that w\u2217 in the new space is small. Thus, running LinUCB in the altered feature space yields an improved bound on the regret (12), which is linear in w\u2217."}, {"heading": "6.1. Baseline Approaches", "text": "Mean-Regularized One simple approach is to regularize to w\u0304 (e.g., the mean of W ) when estimating wt in LinUCB. The estimation problem can be written as\nwt = argmin w\nt\u22121\n\u03c4=1\n(wx\u03c4 \u2212 y\u0302\u03c4 )2 + \u03bbw \u2212 w\u03042. (17)\nTypically, w\u2217 \u2212 w\u0304 < w\u2217, implying lower regret.\nReshape Another approach is to use LinUCB with a feature space \u201creshaped\u201d via a transform UD \u2208 D\u00d7D:\nwt = argmin w\nt\u22121\n\u03c4=1\n(wUDx\u03c4 \u2212 y\u0302\u03c4 )2 + \u03bbw2. (18)\nAs in the mean-regularization approach above, here we would like the representation of w\u2217 in the reshaped space to have a small norm. In our experiments, we use UD = LearnU(W,D) (Algorithm 2).\nWe can incorporate such reshaping into CoFineUCB. We first project W into the space defined by UD, denoted by W\u0302 ,5 then compute U via LearnU(W\u0302 ,K). During model estimation, we replace (5) with\nwt = argmin w\nt\u22121\n\u03c4=1\n(wUDx\u03c4 \u2212 y\u0302\u03c4 )2 + \u03bbw \u2212 Uw\u0303t2.\nIncorporating reshaping into CoFineUCB can lead to a decrease in S\u22a5 = w\u0302\u2217\u22a5. We found the modification to be quite effective in practice; all our experiments in the following sections employ this variant of CoFineUCB.\nSubspaceUCB Finally, we can simply ignore the full space and only apply LinUCB in the subspace. While the method seems to perform well given a good subspace (as seen in (Li et al., 2010; Chapelle & Li, 2011; Yue & Guestrin, 2011), among others), it can yield linear regret if the residual of the user\u2019s preference is strong, as we will see in the experiments."}, {"heading": "6.2. Experimental Setting", "text": "We employ the submodular bandit extension of linear stochastic bandits (Yue & Guestrin, 2011) to model the news recommendation setting. Here, the algorithm\n5W\u0302 \u2261  UDUD \u22121 UDW.\nmust choose a set of L actions and receives rewards based on both the quality as well as diversity of the actions chosen (L = 1 is the conventional bandit setting). Using this structured action space leads to a more realistic setting for content recommendation, since recommender systems often must recommend multiple items at a time. It is straightforward to extend CoFineUCB to the submodular bandit setting (see Appendix C)."}, {"heading": "6.3. Simulations", "text": "We performed simulation evaluations using data collected from a previous user study in personalized news recommendation by (Yue & Guestrin, 2011). The data includes featurized articles (D = 100) and N = 77 user profiles. We employed leave-one-out validation: for each user, the transformations UD and U (K = 5) were trained using the remaining users\u2019 profiles. For each user, we ran 25 simulations (T = 10000). All algorithms used the same U and UD projections, where applicable. We also compared with a variant of CoFineUCB, CoFineUCB-focus, which scales down exploration in the full space ct by a factor of 0.25.\nFigure 3(a) shows the cumulative regret of each algorithm averaged over all users when recommending one article per iteration (L = 1). All algorithms dramatically outperform Naive LinUCB, with the exception of Mean-Regularized which performs almost identically. While Reshape shows good eventual convergence behavior, it incurs higher initial regret than the CoFineUCB algorithms and SubspaceUCB. The trends also hold when recommending multiple articles per iteration (L = 5), as seen in Figure 3(b).\nThe performance of the two variants of CoFineUCB and SubspaceUCB demonstrate the benefit of exploring in the subspace. However, Figure 3(c) reveals the critical shortfall of SubspaceUCB by comparing average cumulative regret for the ten users with the largest residual w\u2217\u22a5. For these atypical users, the subspace is not sufficient to adequately learn their preferences, resulting in linear regret for SubspaceUCB.\nFigure 3(d) shows the behavior of CoFineUCB as we vary K. Larger subspaces require more exploration, which in general leads to increased regret.\nFigure 3(e) shows the behavior of CoFineUCB as we vary the scaling of exploration in the full space ct (CoFineUCB-focus is the special case where the scaling factor is 0.25). More conservative exploration in the full space tends to reduce regret. However, no exploration of the full space can lead to higher regret.\nSynthetic Dataset. We used a 25-dimensional synthetic dataset to study the effect of mismatch between\nw\u2217 and U . This dataset allows for a more systematic analysis by forcing every x and w\u2217 to have unit norm. For residual magnitude \u03b2 \u2208 [0, 1], we sampled w\u2217 uniformly in a 5-dimensional subspace with magnitude  1\u2212 \u03b22, and uniformly in the remaining dimensions with magnitude \u03b2. Figure 3(f) shows the regret of both SubspaceUCB and CoFineUCB-focus increase with the residual, with SubspaceUCB exhibiting more dramatic increase, beyond that of even Naive LinUCB."}, {"heading": "6.4. User Study", "text": "Our user study design follows the study conducted in (Yue & Guestrin, 2011). We presented each user with ten articles per day over ten days from January 21, 2012 to February 8, 2012. Each day comprised approximately ten thousand articles. We represented articles usingD = 100 features corresponding to topics learned via latent Dirichlet Allocation (Blei et al., 2003). For each day, articles shown are selected using an interleaving of two bandit algorithms. The user is instructed to briefly skim each article and mark each article as \u201cinterested in reading in detail\u201dor \u201cnot interested\u201d.\nWe conducted the user study in two phases. Prior to the first phase, we conducted a preliminary study to collect preferences for constructing U (K = 5). In the\nfirst phase, we compared CoFineUCB with Naive. Afterwards, we took all the user profiles learned so far to estimate a reshaping of the full space UD, and compared against Reshape. Due to the short duration of each session (T = 10), we did not expect a meaningful comparison between CoFineUCB and SubspaceUCB, so we omitted it (We expect both methods to perform equally well in early iterations, as seen in the simulation experiments.). For each user session, we counted the total number of liked articles recommended by each algorithm. An algorithm wins a session if the user liked more articles recommended by it.\nTable 2 shows that over the two stages, about 80% of the users prefer CoFineUCB. We see a smaller gain against Reshape, a stronger baseline. On average, users liked over half an additional article per day from CoFineUCB over Naive, and about a quarter addi-\n1 2 3 4 5 6 1\n0.5\n0\n0.5\n1\nwCoF wNaiv\n1 2 3 4 5 6 1\n0.5\n0\n0.5\n1\nwCoF wNaiv\n1 2 3 4 5 6 1\n0.5\n0\n0.5\n1\nwCoF wNaiv\nw\u0303 w\u22a5\n1 2 3 4 5 6 \u22120.8\n\u22120.6\n\u22120.4\n\u22120.2\n0\n0.2\n0.4\n0.6\n0.8\n1\nCoFineUCB Naive\n1\n0.5\n-0.5\n-1\n0\nFigure 4. Each column of word clouds represents a dimension in the subspace. The bar lengths denote the magnitude in each dimension of preferences vectors learned by CoFineUCB (blue) and Naive LinUCB (red). The rightmost column shows the norm of residual w\u2217\u22a5 of weight vectors learned by CoFineUCB and Naive LinUCB.\ntional per day over Reshape. These results show that CoFineUCB is effective in reducing the amount of exploration required.\nFigure 4 shows a representation of four dimensions of U learned from user profiles. Each dimension is a combination of features, i.e., topics from LDA. In the top row, the i-th word cloud contains representative words from topics associated with high positive weights in i-th column of U , and the bottom row those with high negative weights. Examining Figure 4 can reveal tendencies in the user preferences collected in our study; for example, the third column shows that users interested in Republican politics also tend to follow healthcare debates, but tend to be uninterested in videogaming. Figure 4 also shows a comparison of weights estimated by CoFineUCB and Naive LinUCB for one user. Since Naive LinUCB does not utilize the subspace, the weights it estimates tend to have much higher residual norm, whereas CoFineUCB puts higher weights on the subspace dimensions."}, {"heading": "7. Related Work", "text": "Optimizing recommender systems via user feedback has become increasingly popular in recent years (ElArini et al., 2009; Li et al., 2010; 2011; Yue & Guestrin, 2011; Ahmed et al., 2012). Most prior work do not address the issue of exploration and often train with precollected feedback, which may lead to a biased model.\nThe exploration-exploitation tradeoff inherent in learning from user feedback is naturally modeled as a contextual bandit problem (Langford & Zhang, 2007; Li et al., 2010; Slivkins, 2011; Chapelle & Li, 2011; Krause & Ong, 2011). In contrast to most prior work, we focus on principled approaches for encoding prior\nknowledge for accelerated bandit learning.\nOur work builds upon a long line of research on linear stochastic bandits (Dani et al., 2008; Rusmevichientong & Tsitsiklis, 2010; Abbasi-Yadkori et al., 2011). Although often practical, one limitation is the assumption of realizability. In other words, we assume that the true model of user behavior lies within our class.\nThe use of hierarchies in bandit learning is not new. For instance, the work of (Pandey et al., 2007b;a) encode prior knowledge by hierarchically clustering articles into a taxonomy. However, their setting is featurefree, which can make it difficult to generalize to new articles and users. In contrast, our approach makes use of readily available feature-based prior knowledge such as the learned preferences of existing users.\nAnother related line of work is that of sparse linear bandits (Abbasi-Yadkori et al., 2012; Carpentier & Munos, 2012). The assumption is that the true w\u2217 is sparse, and one can achieve regret bounds that depend on the sparsity of w\u2217. In contrast, we consider settings where user profiles are not necessarily sparse, but can be well-approximated by a low-rank subspace.\nIt may be possible to integrate our feature hierarchy approach with other bandit learning algorithms, such as Thompson Sampling (Chapelle & Li, 2011). Thompson Sampling is a probability matching algorithm that samples wt from the posterior distribution. Using feature hierarchies, one can define a hierarchical sampling approach that first samples w\u0303t in the subspace, and then samples wt around w\u0303t in the full space.\nOur approach can be applied to many structured classes of bandit problems (e.g., (Streeter & Golovin, 2008; Cesa-Bianchi & Lugosi, 2009)), assuming that\nactions can be featurized and modeled linearly. For instance, our experiments demonstrated substantial improvements upon naive UCB algorithms for the linear submodular bandit problem (Yue & Guestrin, 2011).\nThe problem of learning a good subspace U is related to finding a good regularization structure for multitask learning (Argyriou et al., 2007; Zhang & Yeung, 2010). Given a sample of user profiles (task weights), our goal is essentially to learn a regularization structure so that future users (tasks) are solved efficiently. However, the coarse subspace of our feature hierarchy was estimated using a relatively small number of imperfectly estimated existing user profiles. A more general problem would be to learn the feature hierarchy on-the-fly as an online learning problem itself."}, {"heading": "8. Conclusion", "text": "We have presented a general approach to encoding prior knowledge for accelerating contextual bandit learning. In particular, our approach employs a coarseto-fine feature hierarchy which dramatically reduces the amount of exploration required. We evaluated our approach in the setting of personalized news recommendation, where we showed significant improvements over existing approaches for encoding prior knowledge.\nAcknowledgements. The authors thank the anonymous\nreviewers for their helpful comments. The authors also\nthank Khalid El-Arini for help with data collection and\nprocessing. This work was supported in part by ONR\n(PECASE) N000141010672, ONR Young Investigator Pro-\ngram N00014-08-1-0752, and by the Intel Science and Tech-\nnology Center for Embedded Computing."}], "references": [{"title": "Improved algorithms for linear stochastic bandits", "author": ["Abbasi-Yadkori", "Yasin", "P\u00e1l", "David", "Szepesv\u00e1ri", "Csaba"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "Abbasi.Yadkori et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Abbasi.Yadkori et al\\.", "year": 2011}, {"title": "Online-to-confidence-set conversions and application to sparse stochastic bandits", "author": ["Abbasi-Yadkori", "Yasin", "Pal", "David", "Szepesvari", "Csaba"], "venue": "In Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Abbasi.Yadkori et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Abbasi.Yadkori et al\\.", "year": 2012}, {"title": "Fair and balanced: Learning to present news stories", "author": ["Ahmed", "Amr", "Teo", "Choon Hui", "S.V.N. Vishwanathan", "Smola", "Alexander"], "venue": "In ACM Conference on Web Search and Data Mining (WSDM),", "citeRegEx": "Ahmed et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ahmed et al\\.", "year": 2012}, {"title": "A spectral regularization framework for multi-task structure learning", "author": ["Argyriou", "Andreas", "Micchelli", "Charles A", "Pontil", "Massimiliano", "Ying", "Yiming"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "Argyriou et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Argyriou et al\\.", "year": 2007}, {"title": "Latent dirichlet allocation", "author": ["Blei", "David", "Ng", "Andrew", "Jordan", "Michael"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Bandit theory meets compressed sensing for high dimensional stochastic linear bandit", "author": ["Carpentier", "Alexandra", "Munos", "Remi"], "venue": "In Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Carpentier et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Carpentier et al\\.", "year": 2012}, {"title": "Combinatorial bandits", "author": ["Cesa-Bianchi", "Nicol", "Lugosi", "Gabor"], "venue": "In Conference on Learning Theory (COLT),", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2009}, {"title": "An empirical evaluation of thompson sampling", "author": ["Chapelle", "Olivier", "Li", "Lihong"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "Chapelle et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2011}, {"title": "Stochastic linear optimization under bandit feedback", "author": ["Dani", "Varsha", "Hayes", "Thomas", "Kakade", "Sham"], "venue": "In Conference on Learning Theory (COLT),", "citeRegEx": "Dani et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Dani et al\\.", "year": 2008}, {"title": "Turning down the noise in the blogosphere", "author": ["El-Arini", "Khalid", "Veda", "Gaurav", "Shahaf", "Dafna", "Guestrin", "Carlos"], "venue": "In ACM Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "El.Arini et al\\.,? \\Q2009\\E", "shortCiteRegEx": "El.Arini et al\\.", "year": 2009}, {"title": "Contextual gaussian process bandit optimization", "author": ["Krause", "Andreas", "Ong", "Cheng Soon"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "Krause et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Krause et al\\.", "year": 2011}, {"title": "The epoch-greedy algorithm for contextual multi-armed bandits", "author": ["Langford", "John", "Zhang", "Tong"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "Langford et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Langford et al\\.", "year": 2007}, {"title": "Scene: A scalable two-stage personalized news recommendation system", "author": ["Li", "Lei", "Wang", "Dingding", "Tao", "Knox", "Daniel", "Padmanabhan", "Balaji"], "venue": "In ACM Conference on Information Retrieval (SIGIR),", "citeRegEx": "Li et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Li et al\\.", "year": 2011}, {"title": "A contextual-bandit approach to personalized news article recommendation", "author": ["Li", "Lihong", "Chu", "Wei", "Langford", "John", "Schapire", "Robert"], "venue": "In World Wide Web Conference (WWW),", "citeRegEx": "Li et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Li et al\\.", "year": 2010}, {"title": "Bandits for taxonomies: A model-based approach", "author": ["Pandey", "Sandeep", "Agarwal", "Deepak", "Chakrabarti", "Deepayan", "Josifovski", "Vanja"], "venue": "In SIAM Conference on Data Mining (SDM),", "citeRegEx": "Pandey et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Pandey et al\\.", "year": 2007}, {"title": "Multi-armed bandit problems with dependent arms", "author": ["Pandey", "Sandeep", "Chakrabarti", "Deepayan", "Agarwal", "Deepak"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Pandey et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Pandey et al\\.", "year": 2007}, {"title": "Linearly parameterized bandits", "author": ["Rusmevichientong", "Paat", "Tsitsiklis", "John"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Rusmevichientong et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rusmevichientong et al\\.", "year": 2010}, {"title": "Contextual bandits with similarity information", "author": ["Slivkins", "Aleksandrs"], "venue": "In Conference on Learning Theory (COLT),", "citeRegEx": "Slivkins and Aleksandrs.,? \\Q2011\\E", "shortCiteRegEx": "Slivkins and Aleksandrs.", "year": 2011}, {"title": "An online algorithm for maximizing submodular functions", "author": ["Streeter", "Matthew", "Golovin", "Daniel"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "Streeter et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Streeter et al\\.", "year": 2008}, {"title": "Linear submodular bandits and their application to diversified retrieval", "author": ["Yue", "Yisong", "Guestrin", "Carlos"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "Yue et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Yue et al\\.", "year": 2011}, {"title": "A convex formulation for learning task relationships in multi-task learning", "author": ["Zhang", "Yu", "Yeung", "Dit-Yan"], "venue": "In Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Zhang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 13, "context": "A common formalization of such a problem is the linear stochastic bandit problem (Li et al., 2010), which models user utility as a linear function of user and content features.", "startOffset": 81, "endOffset": 98}, {"referenceID": 8, "context": "For instance, the well-studied LinUCB algorithm (Dani et al., 2008; Abbasi-Yadkori et al., 2011) achieves a regret bound that is linear in the dimensionality of the feature space, which cannot be improved without further assumptions.", "startOffset": 48, "endOffset": 96}, {"referenceID": 0, "context": "For instance, the well-studied LinUCB algorithm (Dani et al., 2008; Abbasi-Yadkori et al., 2011) achieves a regret bound that is linear in the dimensionality of the feature space, which cannot be improved without further assumptions.", "startOffset": 48, "endOffset": 96}, {"referenceID": 13, "context": "Therefore, a common approach to dealing with slow convergence is dimensionality reduction based on prior knowledge, such as previously learned user profiles, by representing new users as linear combinations of \u201cstereotypical users\u201d (Li et al., 2010; Yue & Guestrin, 2011).", "startOffset": 232, "endOffset": 271}, {"referenceID": 8, "context": "We perform empirical validaThe regret bound is information-theoretically optimal up to log factors (Dani et al., 2008).", "startOffset": 99, "endOffset": 118}, {"referenceID": 0, "context": "We study the linear stochastic bandit problem (Abbasi-Yadkori et al., 2011), which formalizes a recommendation system as a bandit algorithm that iteratively performs actions and learns from rewards received per action.", "startOffset": 46, "endOffset": 75}, {"referenceID": 3, "context": "This formulation is akin to multi-task structure learning, where W0 would denote the various tasks and \u03a9 denotes feature relationships common across tasks (Argyriou et al., 2007; Zhang & Yeung, 2010).", "startOffset": 155, "endOffset": 199}, {"referenceID": 13, "context": "While the method seems to perform well given a good subspace (as seen in (Li et al., 2010; Chapelle & Li, 2011; Yue & Guestrin, 2011), among others), it can yield linear regret if the residual of the user\u2019s preference is strong, as we will see in the experiments.", "startOffset": 73, "endOffset": 133}, {"referenceID": 4, "context": "We represented articles usingD = 100 features corresponding to topics learned via latent Dirichlet Allocation (Blei et al., 2003).", "startOffset": 110, "endOffset": 129}, {"referenceID": 13, "context": "Optimizing recommender systems via user feedback has become increasingly popular in recent years (ElArini et al., 2009; Li et al., 2010; 2011; Yue & Guestrin, 2011; Ahmed et al., 2012).", "startOffset": 97, "endOffset": 184}, {"referenceID": 2, "context": "Optimizing recommender systems via user feedback has become increasingly popular in recent years (ElArini et al., 2009; Li et al., 2010; 2011; Yue & Guestrin, 2011; Ahmed et al., 2012).", "startOffset": 97, "endOffset": 184}, {"referenceID": 13, "context": "The exploration-exploitation tradeoff inherent in learning from user feedback is naturally modeled as a contextual bandit problem (Langford & Zhang, 2007; Li et al., 2010; Slivkins, 2011; Chapelle & Li, 2011; Krause & Ong, 2011).", "startOffset": 130, "endOffset": 228}, {"referenceID": 8, "context": "Our work builds upon a long line of research on linear stochastic bandits (Dani et al., 2008; Rusmevichientong & Tsitsiklis, 2010; Abbasi-Yadkori et al., 2011).", "startOffset": 74, "endOffset": 159}, {"referenceID": 0, "context": "Our work builds upon a long line of research on linear stochastic bandits (Dani et al., 2008; Rusmevichientong & Tsitsiklis, 2010; Abbasi-Yadkori et al., 2011).", "startOffset": 74, "endOffset": 159}, {"referenceID": 1, "context": "Another related line of work is that of sparse linear bandits (Abbasi-Yadkori et al., 2012; Carpentier & Munos, 2012).", "startOffset": 62, "endOffset": 117}, {"referenceID": 3, "context": "The problem of learning a good subspace U is related to finding a good regularization structure for multitask learning (Argyriou et al., 2007; Zhang & Yeung, 2010).", "startOffset": 119, "endOffset": 163}], "year": 2012, "abstractText": "Contextual bandit learning is an increasingly popular approach to optimizing recommender systems via user feedback, but can be slow to converge in practice due to the need for exploring a large feature space. In this paper, we propose a coarse-to-fine hierarchical approach for encoding prior knowledge that drastically reduces the amount of exploration required. Intuitively, user preferences can be reasonably embedded in a coarse low-dimensional feature space that can be explored efficiently, requiring exploration in the high-dimensional space only as necessary. We introduce a bandit algorithm that explores within this coarse-to-fine spectrum, and prove performance guarantees that depend on how well the coarse space captures the user\u2019s preferences. We demonstrate substantial improvement over conventional bandit algorithms through extensive simulation as well as a live user study in the setting of personalized news recommendation.", "creator": "Preview"}}}