{"id": "1210.2085", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Oct-2012", "title": "Privacy Aware Learning", "abstract": "We study statistical risk minimization problems under a privacy model in which the data is kept confidential even from the learner. In this local privacy framework, we establish sharp upper and lower bounds on the convergence rates of statistical estimation procedures. As a consequence, we exhibit a precise tradeoff between the amount of privacy the data preserves and the utility, as measured by convergence rate, of any statistical estimator or learning procedure in the local model. A tradeoff between the level of privacy and the validity of this tradeoff is illustrated in Table 2: The correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure is found in Table 3: The correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure is found in Table 4: The correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the level of privacy and the validity of a learning procedure. In fact, the correlation between the", "histories": [["v1", "Sun, 7 Oct 2012 18:27:03 GMT  (63kb)", "https://arxiv.org/abs/1210.2085v1", "51 pages"], ["v2", "Thu, 10 Oct 2013 17:53:36 GMT  (75kb)", "http://arxiv.org/abs/1210.2085v2", "60 pages"]], "COMMENTS": "51 pages", "reviews": [], "SUBJECTS": "stat.ML cs.IT cs.LG math.IT", "authors": ["john c duchi", "michael i jordan", "martin j wainwright"], "accepted": true, "id": "1210.2085"}, "pdf": {"name": "1210.2085.pdf", "metadata": {"source": "CRF", "title": "Privacy Aware Learning", "authors": ["John C. Duchi", "Michael I. Jordan", "Martin J. Wainwright"], "emails": ["jduchi@eecs.berkeley.edu", "jordan@eecs.berkeley.edu", "wainwrig@eecs.berkeley.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n21 0.\n20 85\nv2 [\nst at\n.M L\n] 1\n0 O\nct 2"}, {"heading": "1 Introduction", "text": "Natural tensions between learning and privacy arise whenever a learner must aggregate data across multiple individuals. The learner wishes to make optimal use of each data point, whereas the providers of the data may wish to limit detailed exposure, either to the learner or to other individuals. A characterization of such tensions in the form of quantitative tradeoffs is of great utility: it can inform public discourse surrounding the design of systems that learn from data, and the tradeoffs can be exploited as controllable degrees of freedom whenever such a system is deployed.\nIn this paper, we approach this problem from the point of view of statistical decision theory. The decision-theoretic perspective offers a number of advantages. First, the use of loss functions and risk functions provides a compelling formal foundation for defining \u201clearning\u201d, one that dates back to Wald [46], and that has seen continued development in the context of research on machine learning over the past two decades. Second, by formulating the goals of a learning system in terms of loss functions, we make it possible for individuals to assess whether the goals of a learning system align with their own personal utility, and thereby determine the extent to which they are willing to sacrifice some privacy. Third, an appeal to decision theory permits abstraction over the details of specific learning procedures, allowing for the derivation of minimax lower bounds that apply to any specific procedure. Fourth, the use of loss functions\u2014and more specifically, convex loss functions\u2014in the design of a learning system allows the powerful tools of optimization theory to be brought to bear. Not only are optimization-based learning systems often successful in practice, but they are also often amenable to theoretical analysis. Finally, the decision-theoretic framework is a probabilistic framework, with probabilistic models definining the transformation from losses to risks. This connection provides a natural mechanism for the use of randomization to provide control over privacy.\nIn more formal detail, the analysis of this paper takes place within the following framework. Given a compact convex set \u0398 \u2282 Rd, we wish to find a parameter value \u03b8 \u2208 \u0398 achieving good\naverage performance under a loss function \u2113 : X \u00d7 Rd \u2192 R+. Here the value \u2113(X, \u03b8) measures the performance of the parameter vector \u03b8 \u2208 \u0398 on the sample X \u2208 X , and \u2113(x, \u00b7) : Rd \u2192 R+ is convex for x \u2208 X . We measure the expected performance of \u03b8 \u2208 \u0398 via the risk function\n\u03b8 7\u2192 R(\u03b8) := EP [\u2113(X, \u03b8)], (1)\nwhere the expectation is taken over some unknown distribution P over the space X . In the standard formulation of statistical risk minimization, a method M is given n samples X1, . . . ,Xn, each drawn independently from P , and its goal to to output an estimate \u03b8\u0302n that approximately minimizes the risk function R. In this paper, instead of providing the method M with access to the samples X1, . . . ,Xn, however, we study the effect of giving only some disguised view Zi of each datum Xi. With \u03b8\u0302n now denoting an estimator based on the perturbed samples Zi, we explicitly quantify the rate of convergence of R(\u03b8\u0302n) to inf\u03b8\u2208\u0398R(\u03b8) as a function of the number of samples n and the amount of privacy provided by Zi."}, {"heading": "1.1 Prior work", "text": "There is a long history of research at the intersection of privacy and statistics, going back at least to the 1960s, when Warner [47] suggested privacy-preserving methods for survey sampling, and to later work related to census taking and presentation of tabular data (e.g., [20]). More recently, there has been a large amount of computationally-oriented work on privacy [17, 15, 51, 48, 24, 11, 5, 7, 42]. We overview some of the key ideas in this section, but cannot hope to do justice to the large body of relevant work, referring the reader to the comprehensive survey by Dwork [15] and the statistical treatment by Wasserman and Zhou [48] for background and references.\nMost work on privacy attempts to limit disclosure risk: the probability that some adversary can link a released record to a particular member of the population or identify that someone belongs to a dataset that generates a statistic [13, 14, 41, 28]. In the statistical literature, work on disclosure limitation and so-called linkage risk, for example as in the framework of Duncan and Lambert [13], has yielded several techniques for maintaining privacy, such as aggregation, swapping features or responses among different datums, or perturbation of data. Other authors have proposed measures for measuring utility of released data (e.g., [28, 9]). The currently standard measure of privacy is differential privacy, due to Dwork et al. [17], which roughly states that \u03b8\u0302n must not depend too much on the n samples, and it should be difficult to ascertain whether a vector x belongs to the set {X1, . . . ,Xn} given \u03b8\u0302n. Formally, paraphrasing the definition of Wasserman and Zhou [48], the method M has \u03b1-differential privacy if\nsup S\u2208\u03c3(\u0398) sup x1,...,xn sup x\u2032 1 ,...,x\u2032n Q(S | X1 = x1, . . . ,Xn = xn) Q(S | X1 = x\u20321, . . . ,Xn = x\u2032n) \u2264 exp(\u03b1). (2)\nwhere the sets x1, . . . , xn and x \u2032 1, . . . , x \u2032 n differ in at most one element, Q(\u00b7 | X1, . . . ,Xn) is (a version of) the conditional probability of the estimator \u03b8\u0302 constructed by the method M using the n samples, and \u03c3(\u0398) is a suitable \u03c3-algebra on \u0398.\nDifferentially private algorithms enjoy many desirable properties [17, 15, 21] and essentially guarantee that even if an adversary knows all the entries in a dataset but the nth, it is difficult to discern whether a vector x is equal to Xn given the output of the method M. Indeed, differential privacy protects against side information and many adversarial attacks that break previous definitions of privacy, such as k-anonymity [21]. Several researchers have studied differentially private\nalgorithms for empirical risk minimization, providing guarantees on the excess risk of differentially private estimators \u03b8\u0302. Chaudhuri et al. [7] use the stability of the output of regularized empirical risk minimization algorithms to show that by adding Laplace-distributed noise to an empirical estimator \u03b8 or by adding an additional random term to the empirical risk 1n \u2211n i=1 \u2113(Xi, \u03b8), it is possible to obtain differential privacy and consistency of \u03b8\u0302. Dwork and Lei [16] obtain similar results using robust statistical estimators, and Smith [44] shows that if one has suitably unbiased estimators, then differential privacy is possible without compromising asymptotic rates of convergence. Rubinstein et al. [42] use similar stability and perturbation techniques to demonstrate that it is possible to obtain differential privacy when solving support vector machine problems, and also show that if the desired privacy level \u03b1 in the definition (2) is too small, it is actually impossible to obtain a parameter \u03b8\u0302n minimizing the risk R.\nOur goal is to understand the fundamental tradeoffs between maintaining privacy while still providing a useful output from the statistical learning procedure M. Though intuitively there must be some tradeoff, quantifying it precisely has been difficult. As alluded to above, Rubinstein et al. [42] are able to show that it is impossible to obtain what they call an (\u01eb, \u03b4)-useful parameter vector \u03b8 that enjoys any differential privacy guarantees; however, it is unknown whether or not their guarantees might be improvable. Hall et al. [24] show that if a given histogram, based on a sample {xi}ni=1, has d bins and we must guarantee \u03b1-differential privacy (2), then the (expected) L1-distance between the sample and released histograms must be at least d/(n\u03b1), and Hardt and Talwar [25] give similar lower bounds on the amount of noise necessary to answer linear database queries. Nikolov et al. [38] followed this work with extensions to relaxed notions (so called (\u03b1, \u03b4)-approximate differential privacy) of privacy and providing higher-dimensional settings, while Kasiviswanathan et al. [30] give bounds on amounts of additive noise to protect against blatant failures of privacy in similar linear settings. Blum et al. [5] also give lower bounds on the closeness of certain statistical quantities computed from the dataset, though their upper and lower bounds do not match. Sankar et al. [43] provide rate-distortion theorems for utility models involving information-theoretic quantities, which has some similarity to our risk-based framework, but it appears somewhat challenging to explicitly map their setting onto ours. With the goal of characterizing what it means to be both useful and private, Ghosh et al. [22] show that for a one-time computation of counts on a dataset X1, . . . ,Xn (i.e., the number of variables satisfying Xi \u2208 C for some set C), perturbing the output of a counting function using geometrically distributed noise is the unique optimal way to guarantee differential privacy while maximizing a natural notion of utility.\nMuch of the work providing sharp lower bounds, however, focuses on showing that if one wishes to accurately report a statistic \u03b8\u0302(x1:n) computed on a sample {xi}ni=1, then there must be some worst-case sample such that the error is large (see, e.g., [25, 24, 38, 22]). In contrast, we focus on population quantities\u2014which are substantially different\u2014in that we wish to return a private estimator \u03b8\u0302n approximately minimizing the population risk R(\u03b8) = E[\u2113(X, \u03b8)] rather than the sample risk 1n \u2211n i=1 \u2113(Xi, \u03b8). Providing guarantees on the population risk performance of \u03b8\u0302n, rather than on the observed sample, has been a driving force behind much of the theoretical work in statistics and machine learning, and thus provides a natural focus for our work."}, {"heading": "1.2 Our setting", "text": "In contrast to the above work, we study a more local notion of privacy [19, 29], in which each datum Xi is kept private from the method M. The goal of many types of privacy is to guarantee that the output \u03b8\u0302n of the method M based on the data cannot be used to discover information about the\nindividual samples X1, . . . ,Xn, but locally private algorithms only access disguised views of each datum Xi. Local algorithms are among the most classical approaches to privacy, tracing back to work on randomized response in the statistical literature [47], and rely on communication only of some disguised view Zi of each true sample Xi. In this setting, for example, the natural variant of \u03b1-differential privacy (2) is the non-interactive (in the sense that Zi depends only on Xi and not on any other private variables Zj) local privacy guarantee\nsup S sup x,x\u2032 Q(Zi \u2208 S | Xi = x) Q(Zi \u2208 S | Xi = x\u2032) \u2264 exp(\u03b1). (3)\nLocally private algorithms are natural when the providers of the data\u2014the population sampled to give X1, . . . ,Xn\u2014do not even trust the statistician or statistical method M, but the providers are interested in the parameter vector \u03b8\u2217 that minimizes the risk function. For example, in medical applications, a participant may be embarrassed about his use of drugs, or perhaps about his marital status, but if the loss \u2113 is able to measure the likelihood of developing cancer, then the participant has high utility for access to the optimal parameters \u03b8\u2217. Internet applications, where a user\u2019s activity is logged across multiple websites or searches, provide another example: the user has a utility for a search engine to have a ranking function \u03b8 that returns relevant results for web searches, yet may not wish to reveal his or her search data. In essence, we would like the statistical procedure M to learn from the data X1, . . . ,Xn but not about it.\nThe work most related to ours seems to be that of Kasiviswanathan et al. [29], who show that that (in some settings) locally private algorithms coincide with concepts that can be learned with polynomial sample complexity in Kearns\u2019s statistical query (SQ) model [31]. This result is powerful, but has some limitations, as the statistical query model relies exclusively on count queries, and we are interested in measures more precise than polynomial sample complexity to quantity convergence rates. In contrast, our analysis applies to estimators deriving from a broad class of convex risks (1), and it provides sharp rates of convergence.\nWe develop our approach to local privacy in the setting of three related privacy measures. The first is a worst-case measure of mutual information, where we view privacy preservation as a game between the providers of the data, who wish to preserve privacy, and nature. The second is based on differential privacy, where the provider of each datum communicates\u2014subject to some constraints we make explicit later\u2014the most differentially private view Zi of his or her datum Xi. In this general setting we allow interactivity (i.e., the mapping between Zi and Xi may depend on other Zj for j 6= i). The third setting is a non-interactive version of local differential privacy.\nTurning first to the information-theoretic formulation, and recalling that the method M sees only the perturbed version Zi of Xi, we use a uniform variant of mutual information I(Zi;Xi) between the random variables Xi and Zi as a measure for privacy. Using mutual information and related information-theoretic ideas in the privacy and security context is by no means original; see, for example, the survey by Liang et al. [34]. It is important to note, however, that standard mutual information has deficiencies as a measure of privacy (e.g. [19]). Accordingly, our uniform notion of mutual information is as follows: we say that the distribution Q generating Z from X is private only if I(X;Z) is small for all possible distributions P on X, possibly subject to some constraints.\nIn this setting, we design procedures that allow consistent estimation of the parameter \u03b8\u2217 minimizing R(\u03b8) = EP [\u2113(X, \u03b8)], for any convex loss \u2113 and distribution P on the data X. One\ncentral consequence of our analysis is a sharp characterization of the excess risk,\n\u2206n(\u03b8\u0302; \u2113,\u0398) := E [ R ( \u03b8\u0302(Z1, . . . , Zn) )] \u2212 inf\n\u03b8\u2208\u0398 R(\u03b8), (4)\nassociated with any estimator \u03b8\u0302 that satisfies a pre-specified privacy constraint. For particular collections L of loss functions \u2113 \u2208 L, we bound the minimax convergence rate of all estimation procedures. More precisely, let us focus on d-dimensional problems, i.e., those for which the domain \u0398 \u2282 Rd and observations Xi \u2208 Rd. If one wishes to uniformly guarantee a level of privacy I(Xi;Zi) \u2264 I\u2217, then we show that there exists a constant a(L,\u0398) \u2208 R+\u2014dependent only on the properties of the collection L and domain \u0398\u2014such that for any estimator \u03b8\u0302 for the family L, the excess risk is lower bounded as\nsup \u2113\u2208L \u2206n(\u03b8\u0302; \u2113,\u0398) \u2265 \u221a d\u221a I\u2217 a(L,\u0398)\u221a n , (5a)\nwhere a(L,\u0398) is a constant characterizing the non-private minimax rate of estimation (see, e.g., Agarwal et al. [1] for such constants). Moreover, we also prove that there exists another constant b(L,\u0398) \u2265 a(L,\u0398) and provide explicit estimators \u03b8\u0302 with privacy guarantee I\u2217 such that\nsup \u2113\u2208L \u2206n(\u03b8\u0302; \u2113,\u0398) \u2264 \u221a d\u221a I\u2217 b(L,\u0398)\u221a n . (5b)\nTurning to the setting of differential privacy, we are able to show similar results to the bounds (5a) and (5b). Namely, there exist constants b\u2032(L,\u0398) \u2265 a\u2032(L,\u0398) such that if we wish to guarantee \u03b1differential privacy, then for any estimator \u03b8\u0302, the risk is lower bounded by\nsup \u2113\u2208L\n\u2206n(\u03b8\u0302; \u2113,\u0398) \u2265 \u221a d\n\u03b1 a\u2032(L,\u0398)\u221a n , (6a)\nwhile there exist estimators \u03b8\u0302 such that\nsup \u2113\u2208L\n\u2206n(\u03b8\u0302; \u2113,\u0398) \u2264 \u221a d\n\u03b1 b\u2032(L,\u0398)\u221a n . (6b)\nHere again, the constant a\u2032(L,\u0398) controls the non-private minimax rate of estimation. Finally, we show that stochastic gradient descent is one procedure that achieves the above upper bounds, and moreover, that the ratios b(L,\u0398)/a(L,\u0398) and b\u2032(L,\u0398)/a\u2032(L,\u0398) are bounded above by a universal (numerical) constant. The bounds (5) and (6) thus establish and quantify explicitly the sharp tradeoff between learning and statistical estimation and the amount of privacy provided to the population. More concretely, we can evaluate the effective sample size of learning procedures receiving private observations. In the case of information-based privacy, the sample size of any learning procedure receiving maximally privatized observations from the data providers is decreased from n to roughly nI\u2217/d, while in differentially private settings, we see that the effective sample size decreases from n to n\u03b12/d. The first of these is perhaps intuitive: in rough terms, a d-dimensional observation Xi contains about d-bits of information, and so we expect a loss in (statistical) efficiency by a factor I\u2217/d. For the second, recent results suggest scalings of I\u2217 \u2248 \u03b12 (e.g. [18, Lemma 3.2]), so the loss n 7\u2192 n\u03b12/d is also perhaps intuitive.\nOur subsequent analysis will build on this favorable property of gradient-based methods. Indeed, in the remainder of the paper, we will assume that the communication protocol\u2014except in the noninteractive \u03b1-differentially private case, which allows any protocol\u2014by which data is conveyed to the learner M is based on (sub)gradients of the loss. As further motivation for this choice, note that the subgradient (more generally, a score function) of the loss \u2113 is asymptotically sufficient in the sense of Le Cam [32]. A bit more precisely, gradients (in an asymptotic sense) contain all of the statistical information for risk minimization problems. Secondly, estimation procedures based on stochastic gradient information are asymptotically efficient [40], in the sense of both Bahadur and minimax efficiency [45, Chapter 8], and are thus essentially sample optimal; they also have minimaxoptimality guarantees in finite-sample settings [1]. Moreover, many estimation procedures are gradient-based [36, 6], and distributed optimization procedures that send subgradient information across a network to a centralized procedure M are natural (e.g. [3]). Our arguments also show that in many settings, disguising subgradients is equivalent to disguising the data X itself. Thus, as an additional consequence of our gradient-based focus, our algorithmic bounds also apply in streaming and online settings, requiring only a fixed-size memory footprint."}, {"heading": "1.3 Outline and techniques", "text": "We spend the remainder of the paper deriving the bounds (5) and (6). Our route to obtaining these bounds is based on a two-part analysis. First, we consider saddle points of the mutual information I(X;Z), when viewed as a function of the distribution P of X and the conditional distribution Q(\u00b7 | X) of Z, under natural constraints that still allow estimation. We consider related saddle points for differentially private conditional distributions. Having computed these saddle points, we can apply information-theoretic techniques for obtaining lower bounds on estimation and optimization [49, 1] to prove the results of the form (5a) or (6a). Our upper bounds then follow by application of known convergence rates for computationally efficient methods, such as the stochastic gradient and mirror descent algorithms [36, 37]. We provide full proofs\u2014except for technical results deferred to appendices\u2014and a more complete outline of our technique in Section 5.\nThe remainder of the paper is organized as follows. We give a precise definition of our notions of local privacy in Section 2. Section 3 is devoted to information-theoretic lower bounds on the convergence rate of any statistical method M in terms of the mutual information I\u2217 between what the method M observes and each sample Xi. We characterize the unique privacy guaranteeing distributions in Section 4, which provides a constructive mechanism for trading off privacy and learning. We present our conclusions in Section 6.\nNotation Before continuing, we give our notation and a few standard definitions. The KullbackLeibler (KL) divergence between distributions P and Q defined on a set S, where P and Q are assumed to have densities p and q with respect to a base measure \u03bd1 is given by\nDkl (P\u2016Q) := \u222b\nS p(s) log\np(s) q(s) d\u03bd(s).\nSimilarly, the total-variation distance between the distributions P and Q is defined as\n\u2016P \u2212Q\u2016TV := sup A\u2282S |P (A)\u2212Q(A)| = 1 2\n\u222b\nS |p(s)\u2212 q(s)|d\u03bd(s).\n1This is no loss of generality, as P and Q are absolutely continuous with respect to \u03bd = 1 2 (P +Q).\nFor a convex function f : Rd \u2192 R \u222a {+\u221e}, the subgradient set \u2202f(\u03b8) of f at the point \u03b8 is\n\u2202f(\u03b8) := { g \u2208 Rd : f(\u03b8\u2032) \u2265 f(\u03b8) + g\u22a4(\u03b8\u2032 \u2212 \u03b8), for all \u03b8\u2032 \u2208 Rd } .\nWe use \u2202\u2113(x, \u03b8) to denote the subgradient set of the function \u03b8 7\u2192 \u2113(x, \u03b8), and for a convex function, \u2207\u2113(x, \u03b8) denotes an arbitrary element of \u2202\u2113(x, \u03b8). We say that a function f is L-Lipschitz with respect to the norm \u2016\u00b7\u2016 over the set \u0398 if\n\u2223\u2223f(\u03b8)\u2212 f(\u03b8\u2032) \u2223\u2223 \u2264 L \u2225\u2225\u03b8 \u2212 \u03b8\u2032 \u2225\u2225 for all \u03b8, \u03b8\u2032 \u2208 \u0398.\nThe notation \u2016\u00b7\u2016p denotes a standard \u2113p-norm. We use the abbreviation r.c.d. throughout for regular conditional distribution [4]. The extreme points of a set C \u2282 Rd are denoted by Ext(C), the convex hull of C is denoted by Conv(C), and the support of a distribution P is denoted suppP . We say values an \u224d bn if limn(an/bn) = 1. The symbol ei denotes the ith standard basis vector in R d. Lastly, the symbol \u21d2 denotes a set-valued mapping [26]."}, {"heading": "2 Problem Formulation", "text": "We begin with a formal description of the communication protocol by which information about the random variables X is communicated to the procedure M. We then define the notion of optimal local privacy studied in this paper and the minimax framework in which we state our main results."}, {"heading": "2.1 Communication protocol", "text": "In this paper, we focus on statistical learning procedures that have access to data through the subgradients \u2202\u2113(X, \u03b8) of the loss functions. More formally, at each round, the method M is given access to a random vector Zi such that\nE[Zi | Xi, \u03b8] \u2208 \u2202\u2113(Xi, \u03b8), (7)\nwhere \u03b8 \u2208 \u0398 is a parameter chosen by the method. In Appendix A we present an argument that shows that the unbiasedness of the subgradient inclusion (7) is not only intuitively appealing but is, in a certain sense, necessary. In detail, our communication protocol consists of the following three steps:\n\u2022 the method M sends the parameter vector \u03b8 to the owner of the ith sample Xi;\n\u2022 owner i computes a subgradient vector g \u2208 \u2202\u2113(Xi, \u03b8) to be communicated privately;\n\u2022 the vector Zi is communicated to M under the constraint that\nE[Zi | Xi, \u03b8] = g \u2208 \u2202\u2113(Xi, \u03b8).\nWe assume throughout that there is a compact set C \u2282 Rd such that \u2202\u2113(x, \u03b8) \u2286 C for all pairs (\u03b8, x) \u2208 \u0398\u00d7 X . Our goal is \u201cdisguise\u201d the subgradient information with a random variable Z satisfying Z \u2208 D, for some compact set D such that C \u2282 intD \u2282 Rd. For instance, a common choice of these sets are norm balls, say of the form\nC = {g \u2208 Rd : \u2016g\u2016 \u2264 L}, and D = {g \u2208 Rd : \u2016g\u2016 \u2264 M},\nwhere \u2016\u00b7\u2016 is a given norm on Rd, and the radius choice M > L ensures that C \u2282 intD. This choice covers a variety of online optimization and stochastic approximation algorithms [53, 2, 37, 1], for which it is assumed that for any x \u2208 X and \u03b8 \u2208 \u0398, if g \u2208 \u2202\u2113(x, \u03b8) then \u2016g\u2016 \u2264 L for some norm \u2016\u00b7\u2016. We may obtain privacy by allowing perturbation of the subgradient g, which is then required to live in a (larger) norm ball of radius M > L."}, {"heading": "2.2 Optimal local privacy", "text": "Suppose that X has distribution P , and for each x \u2208 X , let Q(\u00b7 | x) denote the regular conditional probability measure of Z given that X = x. This pair defines the marginal distribution Q(\u00b7) via Q(A) = E[Q(A | X)], where the expectation taken with respect to X \u223c P . The mutual information between X and Z is the expected Kullback-Leibler (KL) divergence between Q(\u00b7 | X) and Q(\u00b7):\nI(P,Q) = I(X;Z) := EP [Dkl (Q(\u00b7 | X)\u2016Q(\u00b7))] . (8)\nWe view the problem of privacy as a game between the adversary controlling P and the data owners, who use Q to obscure the samples X. In particular, we say a distribution Q guarantees a level of privacy I\u2217 if and only if supP I(P,Q) \u2264 I\u2217. Note that this guarantee is worst-case, ensuring that for any choice of distribution P , the publicly available random variable Z provides at most mutual information I\u2217 about the sample X.\nOur goal is to find a saddle point P \u2217, Q\u2217 such that\nsup P I(P,Q\u2217) \u2264 I(P \u2217, Q\u2217) \u2264 inf Q I(P \u2217, Q), (9)\nwhere the first supremum is taken over all distributions P on X such that \u2207\u2113(X, \u03b8) \u2208 C with P -probability 1, and the infimum is taken over all regular conditional distributions Q such that if Z \u223c Q(\u00b7 | X) (meaning that Z is drawn from Q conditional on X), then Z \u2208 D and EQ[Z | X, \u03b8] = \u2207\u2113(X, \u03b8). Indeed, if we can find P \u2217 and Q\u2217 satisfying the saddle point (9), then combination with the trivial direction of the max-min inequality yields\nsup P inf Q I(P,Q) = I(P \u2217, Q\u2217) = inf Q sup P I(P,Q).\nTo fully formalize this idea and our notions of privacy, we define two collections of probability measures and associated losses. For sets C \u2282 D \u2282 Rd, we define the source set\nP (C) := {Distributions P such that suppP \u2282 C} (10a)\nand the set of communicating distributions as the following regular conditional distributions (r.c.d.\u2019s):\nQ (C,D) := { r.c.d.\u2019s Q s.t. suppQ(\u00b7 | c) \u2282 D and \u222b\nD zdQ(z | c) = c for c \u2208 C\n} . (10b)\nThe definitions (10a) and (10b) formally define the sets over which we may take infima and suprema in the saddle point calculations, and they capture what may be communicated. The conditional distributions Q \u2208 Q (C,D) are defined so that for any loss \u2113 with \u2207\u2113(x, \u03b8) \u2208 C, we have\nEQ[Z | X = x, \u03b8] := \u222b\nD zdQ (z | \u2207\u2113(x, \u03b8)) = \u2207\u2113(x, \u03b8).\nWe now make the following key definition:\nDefinition 1. The conditional distributionQ\u2217 satisfies optimal local privacy for the sets C \u2282 D \u2282 Rd if\nsup P I(P,Q\u2217) = inf Q sup P I(P,Q)\nwhere the supremum is taken over distributions P \u2208 P (C) and the infimum is taken over regular conditional distributions Q \u2208 Q (C,D). We say Q\u2217 satisfies optimal local privacy at level I\u2217 if in addition supP I(P,Q \u2217) = I\u2217.\nWe also formulate a corresponding notion of local optimality in the differentially private setting. For given sets C \u2282 D, define the differential privacy measure\n\u03b1\u22c6(C,D) := inf Q log\n[ sup\nS\u2208\u03c3(D) sup x,x\u2032\u2208C Q(S | X = x) Q(S | X = x\u2032)\n] , (11)\nwhere the infimum is taken over all regular conditional distributions Q \u2208 Q (C,D) such that EQ[Z | X = x] = x. We define optimal local differential privacy as follows:\nDefinition 2. The conditional distribution Q\u2217 satisfies optimal local differential privacy for the sets C \u2282 D \u2282 Rd if Q\u2217 \u2208 Q (C,D) and\n1. The distribution Q\u2217 is \u03b1\u22c6(C,D)-differentially private.\n2. We have supP I(P,Q \u2217) \u2264 supP I(P,Q), for all \u03b1\u22c6(C,D)-differentially private Q \u2208 Q (C,D),\nwhere the supremum is taken over all distributions P \u2208 P (C).\nIf a distribution Q\u2217 satisfies optimal local privacy or optimal local differential privacy, then it guarantees that even for the worst possible distribution on X, the information communicated about X is limited. (Part of our results consist in showing that for suitable sets C \u2282 D, it is possible to attain \u03b1\u22c6(C,D), so it is sensible to, in addition, choose the distribution that minimizes mutual information.)\nIn a sense, Definitions 1 and 2 capture the natural competition between privacy and learnability. The method M specifies the set D to which the data Z it receives must belong; the \u201cteachers,\u201d or owners of the data X, choose the distribution Q to guarantee as much privacy as possible subject to this constraint. Using these mechanisms, if we can characterize a unique distribution Q\u2217 attaining the infimum (9) for P \u2217 (and by extension, for any P ), then we may study the effects of requiring a bounded amount of information to be communicated to the method M about X, which we do in Section 3."}, {"heading": "2.3 Minimax error", "text": "Given an estimate \u03b8\u0302 based on n samples X from a distribution P , we assess its quality in terms of the risk function (1), i.e. R(\u03b8) = E[\u2113(X, \u03b8)]. In this section, we describe the minimax framework for obtaining bounds uniformly over all possible estimators. Let M denote any statistical procedure or method that operates on stochastic gradient samples, and let \u03b8\u0302n denote the output of M after receiving n such samples. The excess risk of the method M on the risk R(\u03b8) after receiving n sample gradients is\n\u01ebn(M, \u2113,\u0398, P ) := R(\u03b8\u0302n)\u2212 inf \u03b8\u2208\u0398 R(\u03b8) = EP [\u2113(X, \u03b8\u0302n)]\u2212 inf \u03b8\u2208\u0398 EP [\u2113(X, \u03b8)]. (12)\nThe excess risk is a random variable, since the output \u03b8\u0302n of the method is random. In our settings, in addition to the randomness in the sampling distribution P , there is additional randomness from the perturbation applied to stochastic gradients of the objective \u2113(X, \u00b7) to mask X from the statistitician or method M. Let Q denote the regular conditional probability\u2014the channel distribution\u2014whose conditional part is defined on the range of the (set-valued) subgradient mapping \u2202\u2113(X, \u00b7) : \u0398 \u21d2 Rd. Since the output \u03b8\u0302n of the statistical procedureM is a random function of both P and Q, we take the expectation and measure the expected sub-optimality of the risk according to P and Q. We let L denote a collection of loss functions, where for a distribution P on X , the set L(P ) denotes the losses \u2113 : suppP \u00d7\u0398 \u2192 R+ belonging to L. The minimax error is then given by\n\u01eb\u2217n(L,\u0398) := inf M sup P sup \u2113\u2208L(P ) EP,Q[\u01ebn(M, \u2113,\u0398, P )], (13)\nwhere the expectation is taken over the random samples X \u223c P and Z \u223c Q(\u00b7 | X, \u03b8). In this paper, we provide characterizations of the minimax error (13) for several classes of loss functions L(P ), giving sharp results when the privacy distribution Q satisfies optimal local privacy for any loss function \u2113 \u2208 L(P ) and distribution P ."}, {"heading": "3 Optimal Learning Rates and Tradeoffs", "text": "With the basic framework in place, we now turn to statements of our main results. We begin by imposing certain (weak) conditions on the families of loss functions that we consider, and subsequently turn to the main results of this section (Theorems 1 and 2, which apply to informationbased privacy, and Theorems 3\u20135, which apply to \u03b1-differential privacy) as well as some of their consequences (Corollaries 1, 2, and 3). After describing the optimal privacy-preserving distributions in Section 4, we provide proofs of the results in this section in Section 5."}, {"heading": "3.1 Families of loss functions and stochastic gradient methods", "text": "We assume that our collection of loss functions obey certain natural smoothness conditions. For each p \u2208 [1,\u221e], we use \u2016\u00b7\u2016p to denote the usual \u2113p-norm, and we use q = pp\u22121 to denote the conjugate exponent satisfying the relation 1/p+1/q = 1. With this notation, we have the following definition:\nDefinition 3. For parameters L > 0 and p \u2265 1, an (L, p)-loss function is a measurable function \u2113 : X \u00d7\u0398 \u2192 R such that for x \u2208 X , the function \u03b8 7\u2192 \u2113(x, \u03b8) is convex and L-Lipschitz continuous with respect to the norm \u2016\u00b7\u2016q. A convex loss \u2113 satisfies Definition 3 if and only if for all \u03b8 \u2208 \u0398, we have the inequality \u2016g\u2016p \u2264 L for any subgradient g \u2208 \u2202\u2113(x, \u03b8) (e.g. [26]).\nTo illustrate this definition, let us consider a few examples:\nExample 1. Consider the problem of finding a multi-dimensional median, in which case each sample x \u2208 Rd, and the loss function takes the form\n\u2113(x, \u03b8) = L \u2016\u03b8 \u2212 x\u20161 . This loss is L-Lipschitz with respect to the \u21131-norm, subgradients belonging to [\u2212L,L]d, and hence it belongs to the class of (L,\u221e)-loss functions.\nExample 2 (Classification). We may also consider classification based on either the hinge loss or logistic regression loss. In this setting, the data comes in pairs x = (a, b), where a \u2208 Rd is the set of regressors or predictors and b \u2208 {\u22121, 1} is the label; the losses are\n\u2113(x, \u03b8) = [1\u2212 b \u3008a, \u03b8\u3009]+ and \u2113(x, \u03b8) = log (1 + exp(\u2212b \u3008a, \u03b8\u3009)) .\nBy computing (sub)gradients, we may verify that each of these is an (L, p)-loss if and only if the covariate vector a \u2208 Rd satisfies \u2016a\u2016p \u2264 L, which is a common assumption [7, 42].\nDefinition 3 is natural given the communication strategy we outline in Section 2.1. Since our loss functions satisfy \u2016\u2202\u2113(X, \u03b8)\u2016 \u2264 L, the channel distribution Q amounts to perturbing subgradients to larger norm balls while maintaining the appropriate expectations.\nBefore proceeding, we briefly review standard algorithms for solving problems of the forms outlined above, since they are essential to our results: for each of our main results, the optimal convergence rate is attained by (a variant of) mirror descent [36, 2, 37], which is a non-Euclidean generalization of the stochastic gradient method [36, 40, 53]. Stochastic gradient methods are iterative methods that update a parameter \u03b8t over iterations t of an algorithm using stochastic gradient information. At iteration t, the algorithm receives a vector gt \u2208 Rd with conditional expectation E[gt | \u03b8t] \u2208 \u2202R(\u03b8t), then performs the update\n\u03b8t+1 = argmin \u03b8\u2208\u0398\n{ \u03b7 \u3008gt, \u03b8\u3009+\u03a8(\u03b8, \u03b8t) } .\nHere \u03b7 is a step-size and \u03a8 is a Bregman divergence, which keeps \u03b8t+1 relatively close to \u03b8t. (See the papers [2, 37] for further details.) With appropriate choice of \u03a8, the mirror descent algorithm enjoys the following convergence guarantees. Define \u03b8\u0302n = 1 n \u2211n t=1 \u03b8\nt. If E[\u2016gt\u20162\u221e | \u03b8t] \u2264 M2\u221e for all t and \u0398 is contained in the \u21131-ball of radius r1, then with appropriate choice of \u03a8 and \u03b7\nE[R(\u03b8\u0302n)]\u2212R(\u03b8\u2217) = O ( M\u221er1 \u221a log d\u221a\nn\n) . (14a)\nSee, for example, Beck and Teboulle [2, Section 5] or Nemirovski et al. [37, Section 2.3]. Similarly, with the choice \u03a8(\u03b8, \u03b8\u2032) = \u2016\u03b8 \u2212 \u03b8\u2032\u201622, if E[\u2016gt\u201622 | \u03b8t] \u2264 M22 and \u0398 is contained in the \u21132-ball of radius r2, then\nE[R(\u03b8\u0302n)]\u2212R(\u03b8\u2217) = O ( M2r2\u221a\nn\n) . (14b)\nFor instance, see the references [53, 37] for results of this type."}, {"heading": "3.2 Minimax error bounds under privacy", "text": "We now state our main theorems, and discuss some of their consequences. All proofs are deferred to Section 5."}, {"heading": "3.2.1 Minimax errors with mutual information-based privacy", "text": "Our first two main results consider privacy mechanisms Q satisfying optimal local privacy, Definition 1. We state the theorems first focusing on their dependence on the geometry of the subdifferential sets (in which the subgradients live); in the corollaries to follow we show how these choices correspond to particular mutual information guarantees on privacy.\nOur first theorem applies to the class of (L,\u221e) loss functions as given in Definition 3. For this theorem, we assume that the set to which the perturbed data Z must belong is [\u2212M\u221e,M\u221e]d, where M\u221e \u2265 L. In the notation of Definition 1, this corresponds to taking C = [\u2212L,L]d and D = [\u2212M\u221e,M\u221e]d. We state two variants of the first theorem, as one version gives slightly sharper results for an important special case.\nTheorem 1. Let L be the collection of (L,\u221e) loss functions, assume the conditions of the preceding paragraph, and let Q be optimally locally private (Definition 1) for L. Then\n(a) If \u0398 contains the \u2113\u221e ball of radius r, then\n\u01eb\u2217n(L,\u0398) \u2265 1\n20 min\n{ rLd, M\u221erd\n9 \u221a n\n} .\n(b) If \u0398 = {\u03b8 \u2208 Rd : \u2016\u03b8\u20161 \u2264 r}, then\n\u01eb\u2217n(L,\u0398) \u2265 1\n8 min\n{ rL, M\u221e r \u221a log(2d)\n2 \u221a n\n} .\nOur second main theorem applies to loss functions and objectives with a different geometry. Now we assume that the loss functions L consist of (L, 1) losses, and that the perturbed data must belong to the \u21131 ball of radius M1, i.e., Z \u2208 {z \u2208 Rd : \u2016z\u20161 \u2264 M1}. Thus in the notation of Definition 1, we have D = (M1/L)C, where C = {g \u2208 Rd : \u2016g\u20161 \u2264 L}. If we define M = M1/L, we may define the constants\n\u03b3 := log\n( 2d\u2212 2 + \u221a (2d\u2212 2)2 + 4(M2 \u2212 1) 2(M \u2212 1) ) and \u2206(\u03b3) := e\u03b3 \u2212 e\u2212\u03b3 e\u03b3 + e\u2212\u03b3 + 2(d\u2212 1) , (15)\nwhich are related to the unique distribution achieving optimal local privacy for the (L, 1) losses and the larger \u21131-ball above (see equation (20) and Proposition 2). We have the following theorem.\nTheorem 2. Let L be the collection of (L, 1) loss functions, assume the conditions of the preceding paragraph, and let Q be optimally private for the collection L. If \u0398 contains the \u2113\u221e-ball of radius r,\n\u01eb\u2217n(L,\u0398) \u2265 1\n20 min\n{ rL, rL \u221a d\n9 \u221a n\u2206(\u03b3)\n} .\nRemarks We make a few remarks on Theorems 1 and 2. First, we note that, when reduced to the special case of having no random distribution Q, Theorems 1 and 2 each yield a minimax rate for stochastic optimization problems. Indeed, in Theorem 1, we may take M\u221e = L, in which case (focusing on the second statement of the theorem) we obtain that for \u0398 = {\u03b8 \u2208 Rd : \u2016\u03b8\u20161 \u2264 r},\n\u01eb\u2217n(L,\u0398) \u2265 rL\n16\n\u221a log(2d)\nn .\nMirror descent algorithms [36, 37] can be used to minimize this class of loss functions, and their convergence rate matches this lower bound up to constant factors (also see our results in the sequel,\nas well as the explanation of Agarwal et al. [1]). When specialized to this setting our result is thus unimprovable. Moreover, our analysis is sharper than previous analyses: none of the existing lower bounds recover the logarithmic dependence on the dimension d, which is evidently necessary.\nOur second remark is that while our results appear to require disguising only gradient information, based on our communication formulation in Section 2.1, this restriction is not actually substantial. Indeed, when the domain \u0398 is a norm ball we can establish each of our lower bounds using the loss function \u2113(x, \u03b8) = \u3008x, \u03b8\u3009. In this case, \u2207\u2113(x, \u03b8) = x, so that the communication scheme explicitly disguises exactly the individual data Xi.\nWe now turn to some consequences of Theorems 1 and 2, where we exhibit the tradeoffs between rates of convergence for any statistical procedure and the desired privacy of a user. We present two corollaries that characterize this tradeoff. Looking ahead to Section 4, we may use Propositions 1 and 2 in that section to derive a bijection between the sizes M\u221e andM1 of the perturbation sets and the amount of privacy as measured by the worst case mutual information I\u2217. We can then combine the lower bounds of Theorems 1 and 2 with results on stochastic approximation (the mirror descent convergence rates (14)) to obtain the following tradeoffs. We provide the full proofs in Sections 5.7 and 5.8, respectively.\nCorollary 1. Under the conditions of Theorem 1(b), assume moreover that M\u221e \u2265 2L, and that Q\u2217 satisfies optimal local privacy at information level I\u2217 in the sense of Definition 1. Then for universal constants 0 < c\u2113 \u2264 cu < \u221e, the minimax error is sandwiched as\nc\u2113 \u221a d\u221a I\u2217 \u00b7 rL \u221a log(2d)\u221a n \u2264 \u01eb\u2217n(L,\u0398) \u2264 cu \u221a d\u221a I\u2217 \u00b7 rL \u221a log(2d)\u221a n .\nSimilar upper and lower bounds can be obtained under the conditions of part (a) of Theorem 1, again by using mirror descent, but we lose a factor of \u221a log d in the lower bound. (There is an additional factor of d in the statement (a), and \u0398 \u2287 {\u03b8 \u2208 Rd : \u2016\u03b8\u2016\u221e \u2264 r/d}.) In this case we would not need to assume that \u0398 is an \u21131-ball for the lower bound.\nWe now turn to an analogous result based on an application of Theorem 2 and Proposition 2.\nCorollary 2. Under the conditions of Theorem 2, assume that M1 \u2265 2L and Q\u2217 satisfies optimal local privacy at information level I\u2217. Moreover, suppose that \u0398 contains an \u2113\u221e-ball of radius c1r and is contained in an \u2113\u221e-ball of radius c2r, where 0 < c1 \u2264 c2 are constants. Then for universal constants 0 < c\u2113 \u2264 cu < \u221e, the minimax error is sandwiched as\nc\u2113 \u221a d\u221a I\u2217 \u00b7 rL \u221a d\u221a n \u2264 \u01eb\u2217n(L,\u0398) \u2264 cu \u221a d\u221a I\u2217 \u00b7 rL \u221a d\u221a n .\nAs a final remark, we have stated results that depend on specific geometric properties of the loss functions L. While these geometric properties are natural, as illustrated by the example Section 3.1, it is also possible to use our techniques to derive alternative results. Such extensions require computing the optimal distribution attaining local privacy according to Definitions 1 or 2, then applying the lower-bounding techniques to developed in Section 5."}, {"heading": "3.2.2 Minimax errors under differential privacy", "text": "We now turn to the setting of differentially private algorithms. We focus on two settings for differential privacy: in the first (Theorem 3), we assume that communication respects optimal local\ndifferential privacy, as given by Definition 2. For the second two results, Theorems 4 and 5, we change the setting slightly, assuming only that the mechanism by which the private quantity Zi is communicated to the method M is \u03b1-differentially private and non-interactive (recall Eq. (3)).\nOptimal local differential privacy We begin with the result assuming optimal local differential privacy. We use the same collection of loss functions L as in Theorem 1, that is, (L,\u221e)-loss functions. We also assume that the set to which the perturbed data Z belong is [\u2212M\u221e,M\u221e]d, though the specific value of M\u221e is not important for the statement of the theorem.\nTheorem 3. Let L be the collection of (L,\u221e) loss functions, and assume that Z is optimally locally differentially private (Definition 2), attaining \u03b1-differential privacy for the set L. Let d \u2265 2 and assume \u03b1 \u2264 5/4. Then\n\u01eb\u2217n(L,\u0398) \u2265 1\n8 min\n{ rL, \u221a d\n\u03b1\nrL \u221a log(2d)\n4 \u221a n\n} .\nAs a corollary to this result, we can show an upper bound on the necessary magnitude of the gradient bound M\u221e to allow \u03b1-differential privacy, again applying the mirror descent result (14a). See Section 5.9 for a proof.\nCorollary 3. Under the conditions of Theorem 3, assume that Q\u2217 satisfies Definition 2, attaining \u03b1-differential privacy. Then for universal constants 0 < c\u2113 \u2264 cu, the minimax error is sandwiched as\nc\u2113\n\u221a d\n\u03b1 \u00b7 rL \u221a log(2d)\u221a n \u2264 \u01eb\u2217n(L,\u0398) \u2264 cu \u221a d \u03b1 \u00b7 rL \u221a log(2d)\u221a n .\nNon-interactive local differential privacy We turn to our two results under non-interactive differential privacy, where we no longer assume that the channel is optimally private (the data provider simply guarantees \u03b1-differential privacy). In this setting, we give a minor refinement of the definition of minimax error (13). We let Q\u03b1 denote the family of \u03b1-differentially private distributions where the channel Q is \u03b1-differentially private and non-interactive, meaning that the private variable Zi is conditionally independent of Zj for j 6= i given Xi; recall the definition (3). With this, the minimax error is defined as\n\u01eb\u2217n(L,\u0398, \u03b1) := inf M,Q\u2208Q\u03b1 sup P sup \u2113\u2208L(P ) EP,Q[\u01ebn(M, \u2113,\u0398, P )],\nwhere now the infimum is taken over all \u03b1-private, non-interactive local mechanisms Q, as well as all methods M. Thus, the channel Q and M work together to find the best possible estimator, subject to the differential privacy constraint.\nOur first lower bound applies to a class of functions that are Lipschitz with respect to the \u21131norm, where the optimization takes place over the ball B1(r) := {\u03b8 \u2208 Rd | \u2016\u03b8\u20161 \u2264 r}. We define the set L(B1(r);L) to be the collection of convex (L,\u221e)-loss functions defined on B1(r). By Example 1, this loss class covers the problem of the multi-dimensional median. In stating our minimax bounds, we use a more restrictive (i.e., simpler to optimize) class, the collection of (L,\u221e)-linear losses:\nLlin(L,\u221e) := { \u2113 : X \u00d7 Rd \u2192 R | \u2203 \u03c6 : X \u2192 Rd s.t. \u2113(x, \u03b8) = \u3008\u03c6(x), \u03b8\u3009 , sup\nx \u2016\u03c6(x)\u2016\u221e \u2264 L\n} .\nFor this class, we have the following minimax rate (see Section 5.5 for a proof):\nTheorem 4. For the loss class L = Llin(L,\u221e) and privacy parameter \u03b1 = O(1), assuming that the channel Q is non-interactive and \u03b1-differentially private, there are universal constants 0 < c\u2113 \u2264 cu < \u221e such that\nc\u2113 min\n{\u221a d\n\u03b1 rL \u221a log(2d)\u221a n , rL } \u2264 \u01eb\u2217n(L,B1(r), \u03b1) \u2264 cu min {\u221a d \u03b1 rL \u221a log(2d)\u221a n , rL } . (16)\nWe can also give a result for a larger class of domains and related optimization functions. In particular, consider the loss class\nL(\u0398;L, p) := {\u2113 : X \u00d7\u0398 \u2192 R | \u2113 is a convex (L, p)-loss function } , (17)\nfor some p \u2208 [1, 2]. Restricting the set (17) to the smaller collection of linear functionals, we define\nLlin(\u0398;L, p) := { \u2113 : X \u00d7\u0398 \u2192 R | \u2203 \u03c6 : X \u2192 Rd s.t. \u2113(x, \u03b8) = \u3008\u03c6(x), \u03b8\u3009 , sup\nx \u2016\u03c6(x)\u2016p \u2264 L\n} .\nWe then have the following result, which captures rates of convergence for optimization of linear functionals over \u2113q-norm balls of the form\nBq(rq) := {\u03b8 \u2208 Rd : \u2016\u03b8\u2016q \u2264 rq}, where q \u2208 [2,\u221e].\nTheorem 5. For the loss class L = Llin(Bq(rq);L, p) with q \u2208 [2,\u221e] and non-interactive \u03b1differentially private channel Q with \u03b1 = O(1), there exist universal constants 0 < c\u2113 \u2264 cu < \u221e such that\nc\u2113 rqLmin\n{\u221a d\n\u03b1\nd 1 2 \u2212 1 q\n\u221a n\n, ( \u221a n\u03b12) \u2212 1 q , 1 } \u2264 \u01eb\u2217n(L,Bq(rq), \u03b1) \u2264 cu rqLmin {\u221a d\n\u03b1\nd 1 2 \u2212 1 q\n\u221a n , 1\n} . (18)\nFor the loss class L = L(\u0398;L, p) from Eq. (17), if \u0398 \u2283 Bq(rq), there exists a universal (numerical) constant 0 < c\u2113 such that\nc\u2113min\n{\u221a d\n\u03b1\nrqLd 1 2 \u2212 1 q\n\u221a n , rqL\n} \u2264 \u01eb\u2217n(L,\u0398, \u03b1). (19)\nSee Section 5.6 for a proof.\nRemarks Each of our theorems and corollaries provide sharp characterizations of the minimax rate of estimation up to the constant factors (c\u2113, cu). As noted in the previous section, the nonprivate minimax rate for the class L(B1(r);L) is rL \u221a log(2d)/ \u221a n. We may compare this with the rate in Theorems 3 and 4, as well as Corollary 3. We see that \u03b1-local differential privacy has a dimension-dependent effect on the minimax rate: the effective sample size is reduced from n to \u03b12n/d. This is a substantial reduction, as instead of a logarithmic dependence on the dimension d\u2014which one hopes for in high-dimensional settings such as those specified by the theorem\u2014we have a linear dependence, which is unavoidable under the conditions of the theorems.\nIn Theorem 5 as well, the inequalities (18) provide a characterization of the \u03b1-private minimax rate that is tight up to constant factors. Again, it is worthwhile to relate this minimax rate to the non-private setting: from Theorem 1 and Eq. (11) of Agarwal et al. [1], the non-private minimax\nrate for the function class Llin(\u0398;L, p) is lower bounded by rqLd 1 2 \u2212 1 q / \u221a n. Consequently, the price for \u03b1-privacy is again a reduction in effective sample size by the dimension-dependent factor \u03b12/d. In general, stochastic gradient descent methods require interactivity\u2014they iteratively process the data and query for gradients at points \u03b8 depending on the data observed\u2014except in linear settings. We do, however, obtain matching upper bounds for the general convex case in both Theorems 4 and 5 using stochastic gradient methods (which is unsurprising, as the linear setting is, in a sense, the hardest [36, 1]). This leads to the intriguing open question of whether interactivity can sharpen the results of Theorems 4 and 5. (For Theorems 1\u20133, the optimal privacy game played by the data providers allows interactivity, and hence the results cannot be improved.) It is also interesting to note that in Theorems 3\u20135, in the \u03b1-differentially private setting, adding Laplace noise\u2014the most common mechanism for achieving privacy [15]\u2014appears to be substantially suboptimal: the magnitude of noise necessary to privatize the user\u2019s data is \u2126(d) larger than that provided by the optimal sampling mechanisms we develop in the sequel.\nSummarizing, each of the preceding results indicates that\u2014no matter the type of privacy\u2014 there is a dimension-dependent increase in sample complexity. From Corollaries 1 and 2 we see that incorporating privacy induces a penalty of roughly \u221a d/ \u221a I\u2217 in convergence rate, or an effective sample size reduction from n to nI\u2217/d; in the differential privacy case we have n 7\u2192 n\u03b12/d. While we do not know of an explicit comparison between these two bounds, work by Dwork et al. [18, Lemma 3.2] shows that KL divergence between \u03b1-differentially private distributions scales as \u03b12, which implies roughly that I\u2217 \u2248 \u03b12 (though this is informal). We see roughly similar results, though there does not appear to be a simple mapping between information-theoretic notions of privacy and differential privacy."}, {"heading": "4 Optimal privacy-preserving distributions", "text": "In this section, we explore conditions for a distribution Q\u2217 to satisfy optimal local privacy as given by Definitions 1 and 2. We give a few characterizations of necessary (and sometimes sufficient) conditions based on the compact sets C \u2282 D for distributions P \u2217 and Q\u2217 to achieve the saddle point (9). Our results can be viewed as rate distortion theorems [23, 8, 10] (with source P and channel Q) for certain compact alphabets, though as far as we know, they are all new. Thus, we refer to the conditional distribution Q, which is designed to maintain the privacy of the data X by communication of Z, interchangeably as the privacy-preserving distribution or the channel distribution.\nNote that since we wish to bound I(X;Z) for general losses \u2113, as captured in the definitions of the source P (C) and communication set Q (C,D) in Eqs. (10a) and (10b), we must address the case when \u2113(X, \u03b8) = \u3008\u03b8,X\u3009, in which case \u2207\u2113(X, \u03b8) = X; this shows (by the data-processing inequality [23, Chapter 5]) that it is no loss of generality to assume that X \u2208 C with probability 1 and that we must have E[Z | X] = X. Thus we present each of our results assuming that \u2113(X, \u03b8) = \u3008\u03b8,X\u3009, since a distribution Q\u2217 is optimally locally private or optimally differentially locally private if and only if it attains the saddle point with this choice of loss."}, {"heading": "4.1 General saddle point characterizations", "text": "We begin with a general characterization, first defining the types of sets C and D that we use in our characterization of privacy. Such sets are reasonable for many applications (recall Section 3.1).\nWe focus on the case when the compact sets C and D are (suitably symmetric) norm balls:\nDefinition 4. Let C \u2282 Rd be a compact convex set with extreme points ui \u2208 Rd, i \u2208 I for some index set I. Then C is a rotationally invariant through its extreme points if \u2016ui\u20162 = \u2016uj\u20162 for each i, j, and for any unitary matrix U such that Uui = uj for some i 6= j, then UC = C.\nSome examples of convex sets rotationally invariant through their extreme points include \u2113p-norm balls for p = 1, 2,\u221e, though \u2113p-balls for p 6\u2208 {1, 2,\u221e} are not.\nThe following theorem gives a general characterization of the minimax mutual information for such rotationally invariant sets by providing saddle point distributions P \u2217 and Q\u2217. We provide the proof of Theorem 6 in Section E.1.\nTheorem 6. Let C be a compact convex polytope rotationally invariant through its m < \u221e extreme points {ui}mi=1 and D = (1 + \u03ba)C for some \u03ba > 0. Let Q\u2217 be the conditional distribution of Z | X that maximizes the entropy H(Z | X = x) subject to the constraints that\nEQ[Z | X = x] = x\nfor x \u2208 C and that Z is supported on (1 + \u03ba)ui for i = 1, . . . ,m. Then Q\u2217 satisfies Definition 1, optimal local privacy, and Q\u2217 is (up to measure zero sets) unique. Moreover, the distribution P \u2217 that is uniform on {ui}mi=1 attains the saddle point (9).\nRemarks: We make a few brief remarks here, deferring a somewhat deeper discussion of the implications of Theorem 6 to Appendix E.1, as an understanding of the proof helps. The theorem requires that for Q\u2217 to attain the saddle point guaranteeing optimal local privacy, Q\u2217(\u00b7 | X = x) should maximize the entropy of Z for each x \u2208 C, but this is not essential. If x 6\u2208 {ui}mi=1, a twophase approach still obtains optimal local privacy. We construct a Markov chain X \u2192 X \u2032 \u2192 Z, where X \u2032 is supported on the extreme points {ui}mi=1 of C. The distribution X \u2192 X \u2032 may then be any distribution satisfying E[X \u2032 | X] = X; we then take the conditional distribution Q\u2217(\u00b7 | ui) defined for X \u2032 \u2192 Z to be the maximum entropy distribution Q\u2217(\u00b7 | ui) defined in the theorem. By the data processing inequality [23, Chapter 5], this Markov chain X \u2192 X \u2032 \u2192 Z guarantees the minimax information bound I(X;Z) \u2264 infQ supP I(P,Q)."}, {"heading": "4.2 Specific saddle point computations", "text": "With Theorem 6 in place, we can explicitly characterize the minimax mutual information for \u21131 and \u2113\u221e balls by computing maximum entropy distributions. That is, we compute the unique distributions that attain optimal local privacy\u2014the distributions that guarantee as much (of our definition of) privacy as possible subject to certain constraints. We present two propositions in this regard, providing some discussion and giving proofs in Sections E.2 and E.3.\nFirst, consider the case where X \u2208 [\u2212L,L]d and Z \u2208 [\u2212M,M ]d, where M \u2265 L. For notational convenience, we define the binary entropy h(p) = \u2212p log p\u2212 (1\u2212 p) log(1\u2212 p). We have\nProposition 1. For constants M \u2265 L > 0, let X \u2208 [\u2212L,L]d and Z \u2208 [\u2212M,M ]d be random variables such that E[Z | X] = X almost surely. Define Q\u2217 to be the conditional distribution on Z | X such that the coordinates of Z are independent, have range {\u2212M,M}, and satisfy\nQ\u2217(Zi = M | X) = 1\n2 + Xi 2M and Q\u2217(Zi = \u2212M | X) = 1 2 \u2212 Xi 2M .\nThen Q\u2217 satisfies Definition 1, optimal local privacy, and moreover,\nsup P\nI(P,Q\u2217) = d\u2212 d \u00b7 h ( 1\n2 +\nL\n2M\n) .\nBefore continuing, we give a slightly more intuitive understanding of Proposition 1. Let L = 1 for simplicity (this is no loss of generality by scaling). Concavity implies that for a, b > 0, log(a) \u2264 log b+ b\u22121(a\u2212 b), or \u2212 log(a) \u2265 \u2212 log(b) + b\u22121(b\u2212 a), so\n\u2212 log ( 1\n2 \u2212 1 2M\n) \u2265 \u2212 log 1\n2 + 2 \u00b7 1 2M and \u2212 log\n( 1\n2 +\n1\n2M\n) \u2265 \u2212 log 1\n2 \u2212 2 \u00b7 1 2M .\nIn particular, we see that\nh\n( 1\n2 +\n1\n2M\n) \u2265 \u2212 ( 1\n2 +\n1\n2M\n)( \u2212 log 2\u2212 1\nM\n) \u2212 ( 1\n2 \u2212 1 2M\n)( \u2212 log 2 + 1\nM\n) = log 2\u2212 1\nM2 .\nThat is, we have for any distribution P on X, where X \u2208 [\u2212L,L]d, that (in natural logarithms)\nI(P,Q\u2217) \u2264 dL 2\nM2 ,\nand this bound is tight to O((M/L)\u22123). We now consider the case when X \u2208 { x \u2208 Rd : \u2016x\u20161 \u2264 1 } and Z \u2208 { z \u2208 Rd : \u2016z\u20161 \u2264 M } . Here the arguments are slightly more complicated, as the coordinates of the random variables are no longer independent, but Theorem 6 still allows us to explicitly characterize the saddle point of the mutual information. Before stating the proposition, we recall that if ei \u2208 Rd are the standard basis vectors, then the extreme points of the \u21131-ball of radius 1 are the 2d vectors {\u00b1ei}di=1.\nProposition 2. For a constant M > 1, let X \u2208 {x \u2208 Rd : \u2016x\u20161 \u2264 1} and Z \u2208 {z \u2208 Rd : \u2016z\u20161 \u2264 M} be random variables. Define the parameter\n\u03b3 := log\n( 2d\u2212 2 + \u221a (2d\u2212 2)2 + 4(M2 \u2212 1) 2(M \u2212 1) ) , (20)\nand let Q\u2217 be the conditional distribution on Z | X such that Z is supported on {\u00b1Mei}di=1, and\nQ\u2217(Z = Mei | X = ei) = e\u03b3\ne\u03b3 + e\u2212\u03b3 + (2d\u2212 2) , (21a)\nQ\u2217(Z = \u2212Mei | X = ei) = e\u2212\u03b3\ne\u03b3 + e\u2212\u03b3 + (2d\u2212 2) , (21b)\nQ\u2217(Z = \u00b1Mej | X = ei, j 6= i) = 1\ne\u03b3 + e\u2212\u03b3 + (2d\u2212 2) . (21c)\n(For X 6\u2208 {\u00b1ei}, define X \u2032 to be randomly selected in any way from among {\u00b1ei} such that E[X \u2032 | X] = X, then sample Z from X \u2032 according to (21a)\u2013(21c).) Then Q\u2217 satisfies Definition 1, optimal local privacy, and\nsup P\nI(P,Q\u2217) = log(2d)\u2212 log ( e\u03b3 + e\u2212\u03b3 + 2d\u2212 2 ) + \u03b3\ne\u03b3 e\u03b3 + e\u2212\u03b3 + 2d\u2212 2 \u2212 \u03b3 e\u2212\u03b3 e\u03b3 + e\u2212\u03b3 + 2d\u2212 2 .\nBy scaling, if we have X \u2208 {x \u2208 Rd : \u2016x\u20161 \u2264 L} and Z \u2208 {z \u2208 Rd : \u2016Z\u20161 \u2264 M1}, then the theorem holds with M = M1/L in Eq. (20) and with X = ei replaced by X = Lei in Eq. (21).\nProposition 2 is somewhat more complex than the \u2113\u221e case. We remark that the additional sampling to guarantee that X \u2032 \u2208 {\u00b1ei} (where the conditional distribution Q\u2217 is defined) can be accomplished simply: define the random variable X \u2032 so that X \u2032 = ei sign(xi) with probability |xi|/ \u2016x\u20161. Evidently E[X \u2032 | X] = x, and X \u2192 X \u2032 \u2192 Z for Z distributed according to Q\u2217 defines a Markov chain as in our remarks following Theorem 6. An asymptotic expansion allows us to gain a somewhat clearer picture of the values of the mutual information, though we do not derive upper bounds as we did for Proposition 1. We have the following corollary, proved in Appendix E.5.\nCorollary 4. Let Q\u2217 denote the conditional distribution in Proposition 2, where X and Z lie in \u21131-balls of radii L and M , respectively. Then\nsup P\nI(P,Q\u2217) = dL2\n2M2 +\u0398\n( min { d3L4\nM4 , log4(d) d\n}) ."}, {"heading": "4.3 Saddle points for differentially private communication", "text": "Our final result in this section characterizes saddle points for distributions satisfying Definition 2. Such calculations are, in general, non-trivial, so we restrict our attention to results necessary for the setting of Theorem 3. To that end, we focus on the case where C and D are \u2113\u221e balls, which is relevant for high-dimensional statistical and optimization settings. Without loss of generality (by scaling), we may take C = [\u22121, 1]d and D = [\u2212M,M ]d. We have Proposition 3. For a constant M \u2265 1, let X \u2208 [\u22121, 1]d and Z \u2208 [\u2212M,M ]d be random variables such that E[Z | X] = X almost surely. Fix any x \u2208 {\u22121, 1}d and for k = {0, 2, 4, . . . , 2 \u2308d/2\u2309 \u2212 2} define the constants q+k \u2265 0 and q\u2212k \u2265 0 to satisfy the linear equations\nMq+k\n\u2211\nz\u2208{\u22121,1}d:\u3008z,x\u3009>k\nz +Mq\u2212k\n\u2211\nz\u2208{\u22121,1}d:\u3008z,x\u3009\u2264k\nz = x and q+k + q \u2212 k = 1.\nSet k\u2217 \u2208 argmink{q+k /q\u2212k }. The optimal differential privacy (11) for the sets C = [\u22121, 1]d and D = [\u2212M,M ]d is\n\u03b1\u22c6(C,D) = log q+k\u2217\nq\u2212k\u2217 = min k\u2208{0,2,...,2\u2308d/2\u2309\u22122} log q+k q\u2212k .\nThe distributions attaining optimal local differential privacy are characterized as follows. Define Q\u2217k to be the distribution supported on {\u2212M,M}d with probability mass function defined by\nQ\u2217k(Z = Mz | X = x) = { q+k if \u3008z, x\u3009 > k q\u2212k if \u3008z, x\u3009 \u2264 k\n(22)\nfor z, x \u2208 {\u22121, 1}d. (For X 6\u2208 {\u22121, 1}d, define X \u2032 to be randomly chosen from {\u22121, 1}d such that E[X \u2032 | X] = X, then sample Z according to the above p.m.f.) A distribution Q\u2217 satisfies Definition 2, optimal local differential privacy, if and only if it can be written as a convex combination of those Q\u2217k for which k \u2208 argmink{q+k , q\u2212k }, that is,\nQ\u2217 = \u2211\nk\u2208argmink{q + k ,q\u2212 k }\n\u03b2kQ \u2217 k, where \u03b2k \u2265 0 and\n\u2211\nk\u2208argmink{q + k ,q\u2212 k }\n\u03b2k = 1.\nThe proof of Proposition 3 is technical, and we defer it to Section E.4. We make a few remarks, however. First, we provide a simplified explanation of the linear equations in the proposition. By symmetry, no matter the value of x \u2208 {\u22121, 1}d chosen, the same q+k and q\u2212k solve the linear equations. Proposition 3 shows the structure of the distribution attaining optimal local differential privacy. That is, the proposition shows that the distribution Q\u2217(\u00b7 | x) assigns mass only on the points z \u2208 {\u2212M,M}d, and moreover, it assigns one of two masses: either q+ or q\u2212. To sample from this distribution given an initial point x, one simply flips a coin with bias probabilities {q+k , q\u2212k }, and depending on the result of the coint flip, samples Z \u2208 {\u2212M,M}d uniformly from one of the sets {z : \u3008z, x\u3009 > k/M} or {z : \u3008z, x\u3009 \u2264 k/M}."}, {"heading": "5 Proofs of Statistical Rates", "text": "In this section, we prove Theorems 1\u20135 as well as Corollaries 1, 2, and 3. Our proofs are based on classical information-theoretic techniques from statistical minimax theory [49, 50], and also exploit some additional results due to Agarwal et al. [1]. At a high level, our approach consists of the following steps. Beginning with an appropriately chosen finite set V, we assign a risk function Rv to each member v \u2208 V. The resulting collection {Rv}v\u2208V of risk functions is chosen so that they \u201cseparate\u201d points in the set V, meaning that if \u03b8 \u2208 \u0398 is a point that approximately minimizes the function Rv, then for any w 6= v, the point \u03b8 cannot also be an approximate minimizer of Rw. This separation property allows us to deduce that statistical estimation implies the existence of a testing procedure that distinguishes v from w for w 6= v. We then use lower bounds on the error probability in tests, such asFano\u2019s and Le Cam\u2019s inequalities [50], to obtain a lower bound on the testing error. These inequalities depend on the mutual information between the random variable Xi and the vector Zi communicated, so the final step is to obtain good upper bounds on this mutual information. In the next section, we describe in more detail this reduction, finishing with an outline of the proofs to follow."}, {"heading": "5.1 Reduction to testing", "text": "We begin by describing the reduction that lower bounds the minimax error by the error of a testing problem. It assumes a given collection of risk functions {Rv}v\u2208V indexed by a finite set V; see the individual theorem proofs to follow for constructions of the particular collections used in our analysis. For each v \u2208 V, we choose some representative \u03b8\u2217v \u2208 argmin\u03b8\u2208\u0398Rv(\u03b8) of the set of all minimizing vectors. Our reduction is based on a discrepancy measure between pairs of risk functions, first introduced by Agarwal et al. [1], defined as\n\u03c1(Rv, Rw) := inf \u03b8\u2208\u0398\n[Rv(\u03b8) +Rw(\u03b8)\u2212Rv(\u03b8\u2217v)\u2212Rw(\u03b8\u2217w)] .\nThe \u03c1-separation of the set V is defined as\n\u03c1\u22c6(V) := min {\u03c1(Rv, Rw) : v,w \u2208 V, v 6= w} . (23)\nWhen the set V is clear from context, we use \u03c1\u22c6 as shorthand for this separation. The key to the definition (23) is that the separation allows us to lower bound the expected optimality gap of a statistical method M by the probability of error in a hypothesis test. That is, with the family {Rv}v\u2208V , we can define the canonical hypothesis testing problem: nature chooses\na uniformly random V \u2208 V, and conditional on V = v, the n observations Xi, i = 1, . . . , n, are drawn independently from a distribution Pv satisfying Rv(\u03b8) = EPv [\u2113(X, \u03b8)]. In the private setting, instead of observing Xi, the learner observes the privatized vector Zi, and given the set {Zi}ni=1, the goal is to determine the underlying index v.\nRecall the definition (12) of the excess risk \u01ebn. The previously described hypothesis testing problem can be used to establish lower bounds on the estimation error, as demonstrated in the following:\nLemma 1. Let P be a joint distribution over X \u2208 Rd and V \u2208 V such that X are i.i.d. given V and EP [\u2113(X, \u03b8) | V = v] = Rv(\u03b8). Let Q be the conditional distribution of Z given the observations X. Then for any minimization procedure M, there exists a hypothesis test v\u0302M : (Z1, . . . , Zn) \u2192 V such that\nEP,Q [\u01ebn(M, \u2113,\u0398, P )] \u2265 \u03c1\u22c6(V) 2 PP,Q [v\u0302M(Z1, . . . , Zn) 6= V ] .\nThis result is a variant of Lemma 2 due to Agarwal et al. [1]) It shows that if we can bound the probability of error of any hypothesis test for identifying V based on the sample Z1, . . . , Zn, we have lower bounded the rate at which it is possible to minimize the risk R.\nThe remaining challenge is to provide a lower bound on the error of hypothesis testing problems. To do so, we apply one of two well-known inequalities: Fano\u2019s inequality [8], which applies when |V| > 2, or Le Cam\u2019s method [33, 50], which we apply when |V| = 2. Let V \u2208 V be chosen uniformly at random from V. If a procedure observes random variables Z1, . . . , Zn, Fano\u2019s inequality ensures that for any estimate v\u0302 of V\u2014that is, any measurable function v\u0302 of Z1, . . . , Zn\u2014the test error probability satisfies the lower bound\nP(v\u0302(Z1, . . . , Zn) 6= V ) \u2265 1\u2212 I(Z1, . . . , Zn;V ) + log 2\nlog |V| . (24)\nBy contrast, Le Cam\u2019s method provides lower bounds on the probability of error in binary hypothesis testing problems. In this setting, assume that V = {\u22121, 1} has two elements, and let V \u2208 V be chosen uniformly at random from V. If a procedure observes random variables Z1, . . . , Zn distributed according to Qn1 if V = 1 and Q n \u22121 if V = \u22121, then any estimate v\u0302 of V satisfies the lower bound\nP (v\u0302(Z1, . . . , Zn) 6= V ) \u2265 1 2 \u2212 1 2 \u2225\u2225Qn1 \u2212Qn\u22121 \u2225\u2225 TV . (25)\nSee, for example, Le Cam [33, Section 2] or Yu [50, Lemma 1]. Using the lower bound provided by Lemma 1 and Fano\u2019s inequality (24) or Le Cam\u2019s inequality (25), the structure of our remaining proofs becomes more apparent. Each lower bound argument proceeds in three steps:\n(1) We construct a collection of loss functions satisfying Definition 3, computing the minimal separation (23) so that we may apply Lemma 1.\n(2) The second step is to provide an upper bound on the appropriate information theoretic quantity in order to apply Fano\u2019s inequality (24), in which case we bound I(Z1, . . . , Zn;V ), or Le Cam\u2019s inequality (25), where we bound \u2225\u2225Qn1 \u2212Qn\u22121 \u2225\u2225 TV\n. This step requires the most work and constitutes the major arguments in this section. We provide these bounds using one of two techniques:\n(a) In the proofs of Theorems 1, 2, and 3, we use a distribution Q that satisfies Definition 1 of optimal local privacy (Theorems 1 and 2) or Definition 2 of optimal local differential privacy (Theorem 3). We can then explicitly upper bound the mutual information I(Z1:n;V ) using the definition ofQ and the losses \u2113 from step 1. (See Lemmas 4, 5, 7, and 8 in the subsequent sections.)\n(b) In the proofs of Theorems 4 and 5, we use a bound on mutual information in non-interactive locally differentially private schemes, which we recently presented [12]. This requires a careful packing construction in conjunction with the loss choice from step 1.\n(3) The final step is to use the results of Steps 1 and 2 in the application of Lemma 1 and Fano\u2019s inequality (24) (when the dimension d is low, we use Le Cam\u2019s inequality (25)). This then yields the theorems.\nWe now turn to the proofs of the theorems. We provide each proof in turn, following the steps in the preceding outline."}, {"heading": "5.2 Proof of Theorem 1", "text": "We provide the most detail in the proof of this theorem, as it closely exhibits the blueprint by which we prove the other results."}, {"heading": "5.2.1 Constructing well-separated losses", "text": "The first step in proving our minimax lower bounds is to construct a family of well-separated risks. For Theorem 1, we use one of two families of loss functions: linear losses and median-based losses. Each of these gives a well-separated family with subgradients bounded in \u2113\u221e-norm.\nLinear losses Our first collection of risk functionals is relatively simple, based on families of linear loss functions; we describe the sampling scheme for X to generate them. Let V = {\u00b1ei}di=1, where the vectors ei are the standard basis vectors in R\nd, whence |V| = 2d. Fix \u03b4 \u2208 (0, 1], which we specify later. We choose the distribution P on X to be nearly uniform on X \u2208 {\u22121, 1}d. Conditional on the parameter v \u2208 V, we use the following sampling distribution for X:\nChoose X \u2208 {\u22121, 1}d with independent coordinates, where Xj = { 1 w.p. 1+\u03b4vj 2\n\u22121 w.p. 1\u2212\u03b4vj2 . (26)\nNow for L \u2208 R+ we may define the linear loss functions\n\u2113(X, \u03b8) := L \u3008X, \u03b8\u3009 = L d\u2211\nj=1\nXj\u03b8j. (27)\nBy inspection, the final risk is Rv(\u03b8) = EP [\u3008\u03b8,X\u3009] = L\u03b4 \u3008v, \u03b8\u3009. We obtain the following result on the separation of the risks.\nLemma 2. Given the sampling scheme (26),\n(a) The loss (27) is L-Lipschitz with respect to the \u21131-norm.\n(b) For the optimization domain \u0398 = {\u03b8 \u2208 Rd : \u2016\u03b8\u20161 \u2264 r}, the \u03c1-separation of the set V = {\u00b1ei}di=1 is \u03c1\u22c6(V) = Lr\u03b4.\nProof The first statement of the lemma is immediate, since \u2207\u2113(X, \u03b8) = LX and \u2016X\u2016\u221e \u2264 1 (cf. [26]). For the second, we verify that inf\u03b8\u2208\u0398[Rv(\u03b8) + Rw(\u03b8)] \u2212 Rv(\u03b8\u2217v) \u2212 Rw(\u03b8\u2217w) \u2265 Lr\u03b4. To do so, we compute the minimizers of Rv: since \u21131 and \u2113\u221e are dual norms, we see that for v \u2208 V,\ninf \u2016\u03b8\u20161\u2264r Rv(\u03b8) = inf \u2016\u03b8\u20161\u2264r\nL\u03b4 \u3008v, \u03b8\u3009 = \u2212L\u03b4r \u2016v\u2016\u221e = \u2212L\u03b4r,\nand the minimizer is uniquely attained at \u03b8\u2217v = \u2212rv. Then we have for any w 6= v that\ninf \u2016\u03b8\u2016\n1 \u22641\n[\u3008v +w, \u03b8\u3009] + \u2016v\u2016\u221e + \u2016w\u2016\u221e = \u2212\u2016v +w\u2016\u221e + \u2016v\u2016\u221e + \u2016w\u2016\u221e \u2265 \u22121 + 1 + 1 = 1,\nsince any non-zero coefficients of v and w have differing signs. Multiplying the result by Lr\u03b4 completes the proof.\nMedian-type losses We now describe a class of median-type losses, one with more general applicability than the linear losses of Section 5.2.1. Let V \u2282 {\u22121, 1}d be a subset of the binary hypercube such that for all distinct pairs v 6= v\u2032, we have \u2016v \u2212 v\u2032\u20161 \u2265 d/2, or equivalently \u2016v \u2212 v\u2032\u20160 \u2265 d/4. From the Gilbert-Varshamov bound [50, Lemma 4] there are sets of this form with cardinality at least card(V) \u2265 exp(d/8). We define the distribution on X, conditional on v \u2208 V, as\nChoose X \u2208 {\u22121, 1}d with independent coordinates, where Xj = { 1 w.p. 1+\u03b4vj 2\n\u22121 w.p. 1\u2212\u03b4vj2 . (28)\nFor L > 0, we then define the median-type loss function\n\u2113(X, \u03b8) = L \u2016rX \u2212 \u03b8\u20161 , (29)\nwhich under the sampling scheme (28) gives rise to the risk functional\nRv(\u03b8) = L\nd\u2211\nj=1\n1 + \u03b4vj 2 |\u03b8j \u2212 r|+ 1\u2212 \u03b4vj 2 |\u03b8j + r| = L\n( 1 + \u03b4\n2 \u2016\u03b8 \u2212 rv\u20161 + 1\u2212 \u03b4 2 \u2016\u03b8 + rv\u20161 ) .\nBy construction, whenever \u0398 contains the \u2113\u221e ball of radius r, this risk function has the unique minimizer\n\u03b8\u2217v := argmin \u03b8\u2208\u0398 Rv(\u03b8) = rv \u2208 r{\u22121, 1}d \u2282 \u0398.\nThe following lemma, due to Agarwal et al. [1], captures the separation properties of the collection {Rv}v\u2208V of risk functionals: Lemma 3. Assume that \u0398 contains [\u2212r, r]d and let Rv be defined as in the preceding paragraph. If v,w \u2208 V with v 6= w, the discrepancy \u03c1(Rv, Rw) \u2265 rLd\u03b4/2.\nAs a final remark, for random variables X \u2208 Rd, the loss function (29) is Lipschitz continuous (for appropriate choice of L) for any distribution P on X. Specifically, defining the sign(\u00b7) function coordinate-wise, we have the subgradient equality \u2202\u2113(x, \u03b8) = L sign(\u03b8\u2212rx). Thus, for any p \u2208 [1,\u221e] and Lp \u2265 0, setting L = Lpd\u22121/p yields a member of the collection of (Lp, p)-loss functions."}, {"heading": "5.2.2 Bounding the mutual information", "text": "As outlined in Section 5.1, the second step in our lower bound proofs is to bound the mutual information I(Z1, . . . , Zn;V ), where Zi are the private views available to the learning method. Here we provide mutual information bounds for the family of linear losses (Lemma 4) and medianbased losses (Lemma 5). Each of these mutual information bounds\u2014and our subsequent bounds on mutual information\u2014proceed by using independence to reduce the problem to estimating the mutual information I(Z;V | \u03b8) for a single randomized gradient sample Z. Then, careful calculation of the distribution of Z | V yields the final inequalities. As the proofs are somewhat long and technical, we defer them to Appendix B.\nLemma 4. Let V be drawn uniformly at random from V = {\u00b1ei}di=1. Let X have the distribution (26) conditional on V = v and assume \u2113(X, \u03b8) = L \u3008X, \u03b8\u3009. Let Z be constructed according to the conditional distribution specified by Proposition 1 given a subgradient \u2202\u2113(Xi; \u03b8) with Z \u2208 [\u2212M\u221e,M\u221e]d, where M\u221e \u2265 L. Then\nI(Z1, . . . , Zn;V ) \u2264 n \u03b42L2\nM2\u221e .\nSee Appendix B.1 for a proof of Lemma 4.\nLemma 5. Let V be drawn uniformly at random from a set V \u2282 {\u22121, 1}d. Let X have the distribution (28) conditional on V = v and assume \u2113(X, \u03b8) = L \u2016rX \u2212 \u03b8\u20161, where r > 0 is a constant. Let Z be constructed according to the distribution specified by Proposition 1 conditional on a subgradient \u2202\u2113(Xi; \u03b8), where Z \u2208 [\u2212M\u221e,M\u221e]d and M\u221e \u2265 L. Then\nI(Z1, . . . , Zn;V ) \u2264 n \u03b42L2d\nM2\u221e .\nSee Appendix B.2 for a proof of Lemma 5."}, {"heading": "5.2.3 Applying testing inequalities", "text": "Having established the two families of loss functions we consider and the resultant mutual information bounds, it remains to apply Lemma 1 and a testing inequality. We begin by proving part (a) of the theorem.\nProof of Theorem 1(a) We divide the proof of part (a) of the theorem into two parts: one assuming the dimension d \u2265 9 and the other assuming d < 9. For the first, we use Fano\u2019s inequality (24), while for the second, an application of Le Cam\u2019s method (25) completes the result. For both results, we use the median-type loss \u2113(X, \u03b8) = L \u2016rX \u2212 \u03b8\u20161. We first recall the beginning of the previous section, stating the following application of Lemma 1 and Fano\u2019s inequality (24):\n2 \u03c1\u22c6(V)EP,Q [\u01ebn(M, \u2113,\u0398, P )] \u2265 PP,Q (v\u0302(M) 6= V ) \u2265 1\u2212 I(Z1, . . . , Zn;V ) + log 2 log |V| . (30)\nNow we give the proof of the first statement of the theorem in the case that d \u2265 9. Applying Lemmas 3 and 5, we immediately have the following specialization of the inequality (30):\n4\nrLd\u03b4 EP,Q [\u01ebn(M, \u2113,\u0398, P )] \u2265 1\u2212\nlog 2 log |V| \u2212 n \u03b42L2d M2\u221e log |V| .\nTaking the set V \u2282 {\u22121, 1}d to be a d/4 packing of the hypercube {\u22121, 1}d satisfying |V| \u2265 exp(d/8), as in our construction of median-type losses in Section 5.2.1, we see that\n4\nrLd\u03b4 EP,Q [\u01ebn(M, \u2113,\u0398, P )] \u2265 1\u2212\n8 log 2 d \u2212 n8\u03b4\n2L2\nM2\u221e .\nThe numerical inequality 8 log 2 < 6 coupled with the preceding bound implies\n4\nrdL\u03b4 EP,Q [\u01ebn(M, \u2113,\u0398, P )] > 1\u2212\n6 d \u2212 8n\u03b4\n2L2\nM2\u221e .\nBy our assumption that d \u2265 9, if we choose \u03b4 = min{M\u221e/8L \u221a n, 1}, we are guaranteed the lower bound 4rdL\u03b4EP,Q [\u01ebn(M, \u2113,\u0398, P )] > 15 , or equivalently\nEP,Q [\u01ebn(M, \u2113,\u0398, P )] > rdL\u03b4\n20 =\n1\n20 \u00b7min\n{ rdL, M\u221erd\n8 \u221a n\n} .\nWhen d < 9, we may reduce to the case that d = 1, since a lower bound in this setting extends to higher dimensions (though we may lose dimension dependence). For this case, we use the packing set V = {\u22121, 1} with the linear loss function from Lemma 2, which has \u03c1\u22c6(V) = Lr\u03b4. In this case, the marginal distribution Q(\u00b7 | V ) is given by\nQ(Z = z | V = 1) = 1 2 +\n{ \u03b4L 2M if z = M\n\u2212 \u03b4L2M otherwise, i.e. if z = \u2212M.\nNow, let Qn(\u00b7 | V ) denote the distribution of Z1, . . . , Zn conditional on V . Then applying Lemma 1 and Le Cam\u2019s lower bound (25), we obtain the inequality\n2\nrL\u03b4 EP,Q[\u01ebn(M, \u2113,\u0398, P )] \u2265 PP,Q (v\u0302(M) 6= V ) \u2265\n1 2 \u2212 1 2 \u2016Qn(\u00b7 | V = 1)\u2212Qn(\u00b7 | V = \u22121)\u2016TV .\nA standard result on the total variation distance of Bernoulli distributions (see Lemma 13 in Appendix B.5) implies that\n\u2016Qn(\u00b7 | V = 1)\u2212Qn(\u00b7 | V = \u22121)\u2016TV \u2264 \u03b4L\nM\n\u221a (3/2)n\nif \u03b4 \u2264 M/(3L). Thus we have the bound\n2\nrL\u03b4 EP,Q[\u01ebn(M, \u2113,\u0398, P )] \u2265\n1 2 \u2212\n\u221a 3n\n2 \u221a 2 \u00b7 \u03b4L M . (31)\nMultiplying both sides by rL\u03b4, then setting \u03b4 = min{M/(3L\u221an), 1} \u2264 M/(3L), we have\nEP,Q[\u01ebn(M, \u2113,\u0398, P )] \u2265 ( 1\n2 \u2212 1 2 \u221a 6\n) rL\u03b4\n2 \u2265 \u221a 6\u2212 1 4 \u221a 6 rLmin { M 3L \u221a n , 1 } .\nIn turn, for any d \u2264 8, we immediately find that ( \u221a 6 \u2212 1)/4 \u221a 6 \u2265 d/(9 \u00b7 20), which completes the proof of Theorem 1(a).\nProof of Theorem 1(b) For the second statement of the theorem, we use the linear losses of Section 5.2.1 and apply Lemmas 2 and 4 with the choice V = {\u00b1ei}di=1. In this case, the lower bound (30) and Lemma 2\u2019s separation guarantee imply that\n2\nLr\u03b4 EP,Q [\u01ebn(M, \u2113,\u0398, P )] \u2265 1\u2212\nlog 2 log(2d) \u2212 I(Z1, . . . , Zn;V ) log(2d) .\nWe may assume that d \u2265 2 (using the result of part (a) for d = 1), and we have log 2/ log(2d) \u2264 1/2, which, after an application of Lemma 4, yields\n2\nLr\u03b4 EP,Q [\u01ebn(M, \u2113,\u0398, P )] \u2265\n1 2 \u2212 n \u03b4\n2L2\nM2\u221e log(2d) .\nIf we choose \u03b4 = min{M\u221e \u221a log(2d)/2L \u221a n, 1}, we see that we have\n2\nLr\u03b4 EP,Q [\u01ebn(M, \u2113,\u0398, P )] \u2265\n1 4 ,\nwhich is equivalent in this case to\nEP,Q [\u01ebn(M, \u2113,\u0398, P )] \u2265 rL\u03b4\n8 =\n1 8 min\n{ Lr, M\u221er \u221a log(2d)\n2 \u221a n\n} ."}, {"heading": "5.3 Proof of Theorem 2", "text": "The proof of Theorem 2 is quite similar to that of Theorem 1, again following our outline from Section 5.1. In this section, however, we construct a different family of loss functions, necessitating a new mutual information bound."}, {"heading": "5.3.1 Constructing well-separated losses", "text": "We construct families of losses that are useful for analyzing the case of stochastic subgradients bounded in \u21131-norm. As was the case with median losses (recall Section 5.2.1), let V \u2282 {\u22121, 1}d be a d/4-packing of the hypercube in \u21130-norm; we know there is such a set with cardinality |V| \u2265 exp(d/8). As our sampling process for the data, we choose X from among the 2d positive and negative standard basis vectors \u00b1ej , namely\nChoose index j \u2208 {1, . . . , d} uniformly at random, and set X = { ej w.p. 1+\u03b4vj 2\n\u2212ej w.p. 1\u2212\u03b4vj2 , (32)\nwhere \u03b4 \u2208 (0, 1] is fixed. For a fixed L > 0, we define the hinge loss, common in classification problems, \u2113(x, \u03b8) = L [r \u2212 \u3008x, \u03b8\u3009]+ . (33) The combination of hinge loss (33) and sampling strategy (32) yields the risk functional\nRv(\u03b8) = L\nd\nd\u2211\nj=1\n1 + \u03b4vj 2 [r \u2212 \u3008ej , \u03b8\u3009]+ + L d\nd\u2211\nj=1\n1\u2212 \u03b4vj 2 [r + \u3008ej, \u03b8\u3009]+ .\nAssuming that \u0398 contains the \u2113\u221e ball of radius r, the (unique) minimizer of the risk over \u0398 is\n\u03b8\u2217v := argmin \u03b8\u2208\u0398 Rv(\u03b8) = rv \u2208 r{\u22121, 1}d \u2282 \u0398.\nMoreover, this risk has the following properties:\nLemma 6. For any set \u0398 \u2287 [\u2212r, r]d, we have:\n(a) For P with support suppP \u2286 {x \u2208 Rd : \u2016x\u20161 \u2264 1}, the loss function (33) is L-Lipschitz with respect to the \u2113\u221e-norm.\n(b) If v,w \u2208 V with v 6= w, the discrepancy \u03c1(Rv, Rw) \u2265 rL\u03b4/2.\nProof The first claim is immediate (cf. [26]), since \u2016\u2202\u2113(x, \u03b8)\u20161 \u2264 L \u2016x\u20161 \u2264 L. For the second statement of the lemma, as in the proof of Lemma 2 we verify the separation condition directly by computing the minimizers of Rv. The minimum of\nRv(\u03b8)+Rw(\u03b8) = L\nd\nd\u2211\nj=1\n( [r \u2212 \u3008ej, \u03b8\u3009]+ + [r + \u3008ej , \u03b8\u3009]+ ) + L\u03b4\nd\n\u2211\nj:vj=wj\nvj ( [r \u2212 \u3008ej , \u03b8\u3009]+ \u2212 [r + \u3008ej , \u03b8\u3009]+ )\nis attained by any \u03b8 \u2208 Rd with \u03b8j \u2208 [\u2212r, r] for j such that vj 6= wj and \u03b8j = rvj for j such that vj = wj; a minimizer of Rv is \u03b8 \u2217 v = rv. Thus we have\ninf \u03b8\u2208\u0398\n{Rv(\u03b8) +Rw(\u03b8)} \u2212Rv(\u03b8\u2217v)\u2212Rw(\u03b8\u2217w) = L\nd\nd\u2211\nj=1\n2r \u2212 2L d\n\u2211\nj:vj=wj\nr\u03b4 \u2212 Lr(1\u2212 \u03b4)\u2212 Lr(1\u2212 \u03b4)\n= 2Lr \u2212 2Lr + 2Lr\u03b4 \u2212 2Lr\u03b4 d (d\u2212 \u2016v \u2212 w\u20160) = 2Lr\u03b4 d \u2016v \u2212 w\u20160 .\nSince \u2016v \u2212 w\u20160 \u2265 d/4 by construction, we have \u03c1(Rv , Rw) \u2265 rL\u03b4/2, as desired."}, {"heading": "5.3.2 Bounding the mutual information", "text": "For Theorem 2, we require a somewhat careful bound on the mutual information between the subgradients and the unknown index. We have the following lemma, whose proof we provide in Appendix B.3.\nLemma 7. Let V be drawn uniformly at random from a set V \u2282 {\u22121, 1}d. Define the distribution P (\u00b7 | A) on X as in the random sampling scheme (32) and use the loss (33). Let Z be constructed according to the conditional distribution specified by Proposition 2, where Z \u2208 {z \u2208 Rd : \u2016z\u20161 \u2264 M1}, and define M = M1/L. Then\nI(Z1, . . . , Zn;V ) \u2264 n\u03b42\u2206(\u03b3)2,\nwhere\n\u03b3 := log\n( 2d\u2212 2 + \u221a (2d \u2212 2)2 + 4(M2 \u2212 1) 2(M \u2212 1) ) and \u2206(\u03b3) := e\u03b3 \u2212 e\u2212\u03b3 e\u03b3 + e\u2212\u03b3 + 2(d\u2212 1) ."}, {"heading": "5.3.3 Applying testing inequalities", "text": "The remainder of the proof is similar to that of Theorem 1, except that we apply Lemma 7 in place of Lemmas 4 or 5. Indeed, following identical steps to those in the proof of Theorem 1, we see that with the specified packing V \u2282 {\u22121, 1}d of size |V| \u2265 exp(d/8), we have (recall Eq. (30))\n4\nrL\u03b4 EP,Q[\u01ebn(M, \u2113,\u0398, P )] \u2265 1\u2212\nlog 2 log |V| \u2212 n \u03b42\u2206(\u03b3)2 log |V| \u2265 1\u2212 6 d \u2212 8n\u03b4 2\u2206(\u03b3)2 d .\nConsequently, if we choose \u03b4 = min{ \u221a d/(8\u2206(\u03b3) \u221a n), 1}, then for all d \u2265 9, we have the lower bound\n4 rL\u03b4EP,Q[\u01ebn(M, \u2113,\u0398, P )] \u2265 15 , or equivalently\nEP,Q[\u01ebn(M, \u2113,\u0398, P )] \u2265 rL\u03b4\n20 =\n1\n20 min\n{ rL, rL \u221a d\n8 \u221a n\u2206(\u03b3)\n} ,\nwhich completes the proof (the case d \u2264 8 is identical to that in Theorem 1)."}, {"heading": "5.4 Proof of Theorem 3", "text": "We are somewhat more terse in our proof of Theorem 3 than the previous two, though we repeat the same steps to emphasize our technique."}, {"heading": "5.4.1 Constructing well-separated losses", "text": "We begin by choosing the family of loss functions we require: since our optimization domain \u0398 = {\u03b8 \u2208 Rd : \u2016\u03b8\u20161 \u2264 r}, we use the linear losses of Section 5.2.1 with the sampling scheme (26) as in Theorem 1. Thus, using the packing set V = {\u00b1ei}di=1, we find that \u03c1\u22c6(V) = Lr\u03b4, and consequently\n2\nLr\u03b4 EP,Q [\u01ebn(M, \u2113,\u0398, P )] \u2265 1\u2212\nlog 2 log(2d) \u2212 I(Z1, . . . , Zn;V ) log(2d)\nas earlier."}, {"heading": "5.4.2 Bounding the mutual information", "text": "The mutual information bound in this theorem is somewhat more complicated than the previous bounds, as the optimal privacy-preserving distribution (recall Proposition 3) is more complex. We begin by stating a lemma.\nLemma 8. Let V be drawn uniformly at random from V = {\u00b1ei}di=1. Let X | V be sampled according to the distribution (26), and let Z | X = x have support on {\u22121, 1}d and have p.m.f.\nq(z | x) \u221d { exp(\u03b1) if z\u22a4x > k\n1 if z\u22a4x \u2264 k\nfor some k \u2265 0. Define the constants Cd(k) and \u2206(\u03b4, \u03b1, d, k) by\nCd(k) := card { z \u2208 {\u22121, 1}d : \u3008z, x\u3009 > k } = \u2308(d\u2212k)/2\u2309\u22121\u2211\ni=0\n( d\ni\n) .\nand\n\u2206(\u03b4, \u03b1, d, k) := \u03b4 \u00b7 e \u03b1 \u2212 1\n(e\u03b1 + 1)Cd(k) + 2d\n( d\u2212 1\n\u2308(d\u2212 k)/2\u2309 \u2212 1\n) .\nThen I(Z;V ) \u2264 \u2206(\u03b4, \u03b1, d, k)2 .\nWe provide the proof of the lemma in Appendix B.4.\nFor any \u03b1 \u2264 5/4, we have e\u03b1 \u2212 1 \u2264 2\u03b1, and by properties of binomial coefficients and Stirling\u2019s approximation we have\n1\n2d\n( d\u2212 1\n\u2308(d\u2212 k)/2\u2309 \u2212 1\n) \u2264 1\n2d\n( d\u2212 1\n\u2308d/2\u2309 \u2212 1\n) \u2264 1\u221a\nd\nfor any k. For any distributionQ satisfying optimal local differential privacy at a differential privacy level \u03b1, Proposition 3 implies Q is a convex combination of distributions with p.m.f.s of the form in Lemma 8. That is, we sample with a channel Q whose p.m.f. is a convex combination of p.m.f.s of the form\nqk(z | x) = 1 e\u03b1Cd(k) + (2d \u2212 Cd(k)) \u00b7 { exp(\u03b1) if z\u22a4x/M > k 1 if z\u22a4x/M \u2264 k for z \u2208 {\u2212M,M}d,\nso Q(Z = z | x) = \u2211 k \u03b2kqk(z | x) for some \u03b2k \u2265 0 with \u2211\nk \u03b2k = 1. Applying the convexity of mutual information\u2014taking a convex combination of channel distributions Q can only reduce mutual information\u2014and Lemma 8, we thus obtain\nI(Z1, . . . , Zn;V ) \u2264 nmax k\u22650 \u2206(\u03b4, \u03b1, d, k)2 (34)\n\u2264 n\u03b42(e\u03b1 \u2212 1)2 max k\n( 1\n(e\u03b1 + 1)Cd(k) + 2d\n( d\u2212 1\n\u2308(d\u2212 k)/2\u2309 \u2212 1\n))2 \u2264 4n\u03b42\u03b12 \u00b7 1\nd ."}, {"heading": "5.4.3 Applying testing inequalities", "text": "As a consequence of the display (34), we have the lower bound\n2\nLr\u03b4 EP,Q [\u01ebn(M, \u2113,\u0398, P )] \u2265\n1 2 \u2212max k\nn\u2206(\u03b4, \u03b1, d, k)2\nlog(2d) \u2265 1 2 \u2212 4n\u03b4\n2\u03b12\nd log(2d) .\nBy choosing \u03b4 = min{ \u221a d log(2d)/4\u03b1 \u221a n, 1}, we find that\n2\nLr\u03b4 EP,Q[\u01ebn(M, \u2113,\u0398, P )] \u2265\n1 4 ,\nwhich is equivalent to the bound given in the theorem."}, {"heading": "5.5 Proof of Theorem 4", "text": "In our proofs of Theorems 4 and 5, we exploit some of our own recent results [12] on the contractive properties of mutual information and KL-divergence under local differential privacy. A few definitions are required in order to state these results. As usual, we have an indexed set of probability measures {Pv}v\u2208V , and we let Qn(\u00b7 | x1, . . . , xn) denote the joint probability of the n released private random variables Z1, . . . , Zn. For each v \u2208 V, we then define the marginal distribution\nMnv (A) := \u222b Qn(A | x1, . . . , xn)dPnv (x1, . . . , xn) for A \u2208 \u03c3(Zn). (35)\nDuchi et al. [12] establish two results that provide bounds on \u2016Mnv \u2212Mnw\u2016TV and I(Z1, . . . , Zn;V ) as a function of the amount of privacy provided and the distances between the underlying distributions Pv.\nThe bounds apply to any channel distribution Q that is \u03b1-locally differentially private (for the first result) and to any non-interactive \u03b1-locally differentially private channel (for the second result; recall the definition (3)). Let Pv be the distribution of X conditional on the random packing element V = v, and let Mnv be the marginal distribution (35) induced by passing Xi through Q. Define the mixture distribution P = 1|V| \u2211 v\u2208V Pv, and let \u03c3(X ) denote the \u03c3-field on X over which Pv are defined. With this notation we can state the following proposition, which summarizes the results we need from Duchi et al. [12, Theorems 1\u20132, Corollaries 1\u20132]:\nProposition 4 (Information bounds). Let the conditions of the previous paragraph hold and assume that Q is \u03b1-locally differentially private.\n(a) For all \u03b1 \u2265 0, Dkl (M n v \u2016Mnw) \u2264 4n(e\u03b1 \u2212 1)2 \u2016Pv \u2212 Pw\u20162TV . (36)\n(b) If Q is non-interactive, then for all \u03b1 \u2265 0,\nI(Z1, . . . , Zn;V ) \u2264 e\u03b1n ( e\u03b1 \u2212 e\u2212\u03b1 )2 sup\nS\u2208\u03c3(X )\n1 |V| \u2211\nv\u2208V\n( Pv(S)\u2212 P (S) )2 . (37)\nWith Proposition 4 in place, we proceed with the proof of Theorem 4. To establish the lower bound, we follow the outline of Section 5.1. Establishing the upper bound requires a few additional steps. We defer the formal proofs of achievability to Appendix C (see C.1), as the proofs are similar to Corollaries 1\u20133."}, {"heading": "5.5.1 Constructing well-separated losses", "text": "Our lower bound uses an identical construction to that in Section 5.2.1. We let the loss function \u2113(x, \u03b8) = L \u3008x, \u03b8\u3009, and we use the distribution (26) on x; that is, we have V = {\u00b1ej}dj=1 and for \u03b4 \u2208 [0, 1/2], we sample vectors from X = {\u22121, 1}d with probability Pv(X = x) = (1 + \u03b4v\u22a4x)/2d. We then have \u03c1\u22c6(V) = Lr\u03b4 and |V| = 2d (recall Lemma 2)."}, {"heading": "5.5.2 Bounding the mutual information", "text": "With the construction of the (nearly) uniform sampling scheme, we have the following lemma [12, Lemma 7].\nLemma 9. Under the conditions of the previous paragraph, let \u03b4 \u2264 1 and V be sampled uniformly from {\u00b1ej}dj=1. For any non-interactive \u03b1-differentially private channel Q,\nI(Z1, . . . , Zn;V ) \u2264 n e\u03b1\n4d\n( e\u03b1 \u2212 e\u2212\u03b1 )2 \u03b42."}, {"heading": "5.5.3 Applying testing inequalities", "text": "Using Lemma 9, we can give an almost immediate proof of the lower bound in Theorem 4. Indeed, using Fano\u2019s inequality (24), Lemmas 1 and 9, and the separation \u03c1\u22c6(V) = Lr\u03b4 from Lemma 2(b), we obtain\n\u01eb\u2217n(L,\u0398, \u03b1) \u2265 Lr\u03b4\n2\n( 1\u2212 ne\n\u03b1(e\u03b1 \u2212 e\u2212\u03b1)2\u03b42/4d + log 2 log(2d)\n) .\nSo long as d \u2265 2, setting\n\u03b4 = min { \u221a d log(2d)\u221a\ne\u03b1n(e\u03b1 \u2212 e\u2212\u03b1) , 1\n}\nand noting that e\u03b1 = O(1) and e\u03b1 \u2212 e\u2212\u03b1 \u2264 c\u03b1 for a universal constant c if \u03b1 = O(1) completes the proof.\nWhen d = 1, an argument via Le Cam\u2019s method (25) yields an identical result. Given Proposition 4, the argument is quite similar to that used in the proof of Theorem 1. We use the packing set V = {\u00b11} and conditional on V = v, set X = 1 with probability (1 + v\u03b4)/2 and X = \u22121 with probability (1 \u2212 v\u03b4)/2, which yields separation \u03c1\u22c6(V) = Lr\u03b4 by Lemma 2. We also have the marginal contraction\n\u2225\u2225Mn1 \u2212Mn\u22121 \u2225\u22252 TV \u2264 1 2 Dkl ( Mn1 \u2016Mn\u22121 ) \u2264 2(e\u03b1 \u2212 1)2n \u2016P1 \u2212 P\u22121\u20162TV\nby Pinsker\u2019s inequality and Proposition 4. By construction, the total variation \u2016P1 \u2212 P\u22121\u2016TV = \u03b4, whence we find that \u2225\u2225Mn1 \u2212Mn\u22121 \u2225\u22252 TV\n\u2264 2(e\u03b1 \u2212 1)2n\u03b42. Applying Le Cam\u2019s method (25) and Lemma 1, we obtain\n\u01eb\u2217n(L,\u0398, \u03b1) \u2265 Lr\u03b4\n2\n( 1\n2 \u2212\n\u221a n(e\u03b1 \u2212 1)\u03b4\u221a\n2\n) .\nTake \u03b4 = min{ ( 2 \u221a 2 \u221a n(e\u03b1 \u2212 1) )\u22121 , 1} to complete the proof in this case."}, {"heading": "5.6 Proof of Theorem 5", "text": "The proof of this theorem follows the outline established in Section 5.1, as did the previous results. We defer the attainability results to Appendix C.2."}, {"heading": "5.6.1 Constructing well-separated losses", "text": "Before constructing the well-separated loss functions, we exhibit the set V that underlies our sampling distributions. The following lemma exhibits the existence of a special packing of the Boolean hypercube [12, Lemma 5]:\nLemma 10. There exists a packing V of the d-dimensional hypercube {\u22121, 1}d with \u2016v \u2212 w\u20161 \u2265 d/2 for each v,w \u2208 V with v 6= w such that the cardinality of V is at least \u2308exp(d/16)\u2309 and\n1 |V| \u2211\nv\u2208V\nvv\u22a4 25Id\u00d7d.\nWith this packing V, we as usual let V \u2208 V, and conditional on V = v, we sample X \u2208 {\u00b1ej}dj=1 according the sampling scheme (32).\nLinear losses (for the bound (18)) We first consider the case that the loss functions are linear functionals that are L-Lipschitz with respect to the \u2113p\u2032-norm for some p\n\u2032 \u2265 2, and we optimize over \u2113q balls Bq(rq). In this case, we define the loss \u2113(x, \u03b8) = L \u3008x, \u03b8\u3009, and we note that since \u2016x\u20161 \u2264 1 for x \u2208 X , the function \u2113(x, \u00b7) is L-Lipschitz with respect to the \u2113\u221e-norm. With the sampling scheme (32), Rv(\u03b8) = L\u03b4 \u3008v, \u03b8\u3009 /d. Since inf\u03b8\u2208Bq(rq) \u3008v, \u03b8\u3009 = \u2212\u2016v\u2016p when p = (1 \u2212 1/q)\u22121 is the conjugate of q, we have the pairwise separation\n\u03c1(Rv , Rw) = \u2212 rqL\u03b4\nd\n( \u2016v + w\u2016p \u2212 \u2016v\u2016p \u2212 \u2016w\u2016p ) .\nWith the packing set V exhibited by Lemma 10, we have\n\u2016v + w\u2016pp = d\u2211\nj=1\n(vj + wj) p =\n\u2211\nj:vj=wj\n2p \u2264 3d 4 2p,\nand \u2016v\u2016p = d1/p for each v \u2208 V. This implies the following lower bound on the discrepancy:\n\u03c1\u22c6(V) \u2265 max v 6=w\n\u03c1(Rv, Rw) \u2265 rL\u03b4\nd\n( 2d1/p(1\u2212 (3/4)1/p) ) \u2265 3\n5 rL\u03b4d\n1 p \u22121\n. (38)\nGeneral loss functions (for the bound (19)) For the general lower bound of the theorem, we use the hinge loss \u2113(x, \u03b8) = L [r \u2212 \u3008x, \u03b8\u3009]+ as our loss function. In this case, as in Theorem 2 (recall Lemma 6), our sampling strategy yields that the loss \u2113(x, \u03b8) is an (L, 1) loss, since \u2016x\u20161 \u2264 1, and we have the discrepancy bound \u03c1\u22c6(V) \u2265 rL\u03b42 , since the separation depends only on the distance \u2016v \u2212 w\u20161, which Lemma 10 lower bounds."}, {"heading": "5.6.2 Bounding the mutual information", "text": "Using Lemma 10, we may bound the mutual information between samples Z from a particular distribution and a random sample V from a set V of the form in the lemma. Indeed, let V be a packing of the d-dimensional hypercube specified in Lemma 10. Conditional on V = v \u2208 {\u22121, 1}d, we sample the random vector X \u2208 {\u00b1ej}dj=1 according to the sampling scheme (32). Then we have the following lemma [12, Lemma 6], which applies as long as the channel Q is non-interactive and \u03b1-locally differentially private.\nLemma 11. Let Zi be \u03b1-locally differentially private for Xi and the conditions of the previous paragraph hold. Then\nI(Z1, . . . , Zn;V ) \u2264 n 25e\u03b1\n16\n\u03b42\nd (e\u03b1 \u2212 e\u2212\u03b1)2."}, {"heading": "5.6.3 Applying testing inequalities", "text": "Our last step is to apply the usual testing inequalities. We first prove the lower bound in inequality (18). Let Llin = Llin(Bq(rq);L, p). Then by applying Lemma 11 and Fano\u2019s inequality (24) to Lemma 1\u2014using the separation (38)\u2014we obtain\n\u01eb\u2217n(Llin,\u0398, \u03b1) \u2265 3rqL\u03b4d\n1 p \u22121\n10\n( 1\u2212 25ne\n\u03b1\u03b42(e\u03b1 \u2212 e\u2212\u03b1)2/16d + log 2 d/16\n) .\nSo long as d \u2265 16, we have 16 log 2/d \u2264 log 2 < 7/10. Thus choosing\n\u03b4 = min\n{ d\n10 \u221a nC\u03b1(e\u03b1 \u2212 e\u2212\u03b1) , 1\n}\nand noting that e\u03b1 \u2212 e\u2212\u03b1 = O(\u03b1) and e\u03b1 = O(1) for \u03b1 = O(1) we obtain\n\u01eb\u2217n(L,\u0398, \u03b1) \u2265 3rqL\u03b4d\n1 p \u22121\n10 \u00b7 1 20\n\u2265 cmin { rqLd 1 p\n\u221a n\u03b12\n, rqLd 1 p \u22121 } = crqLmin { d 1\u2212 1 q\n\u221a n\u03b12\n, d 1 p \u22121 } .\nfor a universal constant c. As in the proof of Theorem 4, when d < 16, we apply an essentially similar argument but with Le Cam\u2019s method (25), which gives the desired result. (The proof of the case d = 1 from Theorem 4 applies here as well.) Finally, we remark that we may repeat a completely identical proof as that above replacing d with any k \u2264 d, which mutatis mutandis implies the lower bound\n\u01eb\u2217n(L,\u0398, \u03b1) \u2265 cLrq max k\u2208[d] min\n{ k 1\u2212 1 q\n\u221a n\u03b12\n, k 1 p \u22121 } \u2265 cLrq min { d 1\u2212 1 q\n\u221a n\u03b12\n, (n\u03b12)\n1 2p\n\u221a n\u03b12 , 1\n} ,\nwhere for the rightmost bound we have taken k = max{1,min{ \u221a n\u03b12, d}}. Noting that 1/p = 1\u22121/q completes the proof of the lower bound (18). To prove inequality (19), we apply the same reasoning as in the proof of the inequality (18). Use Lemma 11 and Fano\u2019s inequality (24) (via Lemma 1 and the separation from Lemma 6) to obtain\n\u01eb\u2217n(L,\u0398, \u03b1) \u2265 rL\u03b4\n4\n( 1\u2212 25ne\n\u03b1(e\u03b1 \u2212 e\u2212\u03b1)2\u03b42/16d + log 2 d/16\n) .\nThen choosing \u03b4 \u224d d/(\u221an(e\u03b1 \u2212 e\u2212\u03b1)) as in the proof of inequality (18) gives the desired result."}, {"heading": "5.7 Proof of Corollary 1", "text": "Since \u0398 \u2286 {\u03b8 \u2208 Rd : \u2016\u03b8\u20161 \u2264 r}, the bound (14a) guarantees that mirror descent obtains convergence rate O(M\u221er \u221a log(2d)/ \u221a n). This matches the second statement of Theorem 1. Now fix our desired amount of mutual information I\u2217. From the remarks following Proposition 1, if we must guarantee\nthat I\u2217 \u2265 supP I(P,Q) for any distribution P and loss function \u2113 whose gradients are bounded in \u2113\u221e-norm by L, we must (because of the uniqueness of the optimal privacy distribution Q) have\nI\u2217 \u224d dL 2\nM2\u221e . (39)\nUp to higher order terms, to guarantee a level of privacy with mutual information I\u2217, we must allow gradient noise up to a level M\u221e = L \u221a d/I\u2217. The equality (39) establishes that for a given level of allowed mutual information I\u2217, if optimal local privacy holds, then we must have M\u221e \u224d L \u221a d/ \u221a I\u2217. That is, we have a bijection between I\u2217 and M\u221e whenever optimal local privacy holds,\nso substituting M\u221e = L \u221a d/ \u221a I\u2217 into our upper and lower bounds yields the claim."}, {"heading": "5.8 Proof of Corollary 2", "text": "According to the conditions of optimal local privacy, if we must guarantee that I\u2217 \u2265 supP I(P,Q) for any loss function \u2113 whose gradients are bounded in \u21131-norm by L, we must have\nI\u2217 \u224d dL 2\n2M21 ,\nusing Corollary 4 after the statement of Proposition 2. Rewriting this, we see that we must have M1 = L \u221a d/2I\u2217 (to higher order terms) to be able to guarantee an amount of privacy I\u2217. As in the \u2113\u221e case, we have a bijection between the multiplier M1 and the amount of information I \u2217 and can apply similar techniques. Now recall the convergence guarantee (14b) provided by stochastic gradient descent. Since the \u2113\u221e-ball of radius r is contained in the \u21132-ball of radius r2 = r \u221a d, and\n\u2016g\u20161 \u2264 \u2016g\u20162 for all g \u2208 Rd, stochastic gradient descent guarantees that \u01eb\u2217n(L,\u0398) \u2264 CM1r \u221a d/ \u221a n. Applying the lower bound provided by Theorem 2 and substituting for M1 completes the proof."}, {"heading": "5.9 Proof of Corollary 3", "text": "Without loss of generality (by scaling), we assume that L = 1. Now we consider Proposition 3, which characterizes the distributions satisfying optimal local differential privacy. We use the proposition to find an upper bound on M\u221e in terms of the differential privacy level \u03b1, which in turn allows us to apply the bound from mirror descent (14a). Instead of directly using Proposition 3, it is simpler to use the linear program (61) in its proof, and note that finding a lower bound on t (in the LP) as a function of \u03b1 provides an upper bound on M\u221e since M\u221e = 1/t. Now, in the linear program (61), we choose the values for q(z) specified by Lemma 19. Let q+ and q\u2212 denote the larger and smaller probabilities, respectively. Fix an x \u2208 {\u22121, 1}d, and let z range over {\u22121, 1}d. With those choices, we note that for d odd,\n\u2211\nz:\u3008z,x\u3009>0\nz = \u2211\nz:\u3008z,x\u3009=1\nz + \u2211\nz:\u3008z,x\u3009=3\nz + . . .+ \u2211\nz:\u3008z,x\u3009=d\nz\n= [( d\u2212 1 d\u22121 2 ) \u2212 ( d\u2212 1 d+1 2 )] x+ [( d\u2212 1 d+1 2 ) \u2212 ( d\u2212 1 d+3 2 )] x+ . . . = ( d\u2212 1 d\u22121 2 ) x.\nFor d even, a similar calculation yields \u2211 z:\u3008z,x\u3009>0 z = ( d\u22121 d/2 ) x. As a consequence, we find that\n\u2211\nz\nzq(z | x) = q+ \u2211\nz:\u3008z,x\u3009>0\nz + q\u2212 \u2211\nz:\u3008z,x\u3009\u22640\nz = x(q+ \u2212 q\u2212) \u00b7 {(d\u22121 d\u22121 2 ) d odd\n( d\u22121 d/2 ) d even.\nFocusing on the odd case for simplicity\u2014identical bounds hold in the even case\u2014we have for a universal constant c > 0 that\n(q+ \u2212 q\u2212) ( d\u2212 1 d\u22121 2 ) = e\u03b1 \u2212 1 2d\u22121(e\u03b1 + 1) ( d\u2212 1 d\u22121 2 ) \u2265 ce \u03b1 \u2212 1 e\u03b1 + 1 1\u221a d \u2265 c \u03b1\u221a d ,\nthe first inequality following from Stirling\u2019s approximation and the second from convexity of the function \u03b1 7\u2192 e\u03b1. In particular, we see that the minimizing value t in the linear program (61) will satisfy t \u2265 c\u03b1/ \u221a d, which in turn yields M\u221e = 1/t \u2264 \u221a d/(c\u03b1). Noting that the lower bound in the corollary is given by Theorem 3, applying the convergence guarantee (14a) of mirror descent based on M\u221e completes the proof."}, {"heading": "6 Discussion", "text": "We have studied methods for protecting privacy in general statistical risk minimization problems, and have described general techniques for obtaining sharp tradeoffs between privacy protection and estimation rates. The latter are a natural measure of utility for statistical problems.\nWe believe that there are a number of interesting open issues and areas for future work. First, we studied procedures that access each datum only once, and through a perturbed view Zi of the subgradient \u2202\u2113(Xi, \u03b8), which is natural in the context of convex risk minimization. A natural question is whether there are restrictions of the class of loss functions so that a transformed version (Z1, . . . , Zn) of the data are sufficient for inference. For instance, other researchers [51, 52] have studied applications in which a data matrix X = [X1 \u00b7 \u00b7 \u00b7 Xn]\u22a4 \u2208 Rn\u00d7d is pre-multiplied by a normal matrix \u03a6 \u2208 Rm\u00d7n, where m \u226a n, and statistical inference is performed using \u03a6X. For problems such as linear regression and PCA, the resulting estimators enjoy good statistical properties. This transformation, however, cannot be computed without the entire dataset at one\u2019s disposal. Nonparametric data releases, such as those studied by Hall et al. [24], could provide insights here, though again, current approaches require the data to be aggregated by a trusted curator before release.\nOur constraints on the privacy-inducing channel distribution Q require that its support lie in some compact set. We find this restriction useful, but perhaps it possible to achieve faster estimation rates if all we require are moment conditions, for example, EQ[\u2016Z \u2212X\u20162p | X] \u2264 M2. A better understanding of general privacy-preserving channels Q for alternative constraints to those we have proposed is also desirable. Moreover, one might consider attempting only to guarantee that \u03c6(X) is private, where \u03c6 is some (known) function. For example, members of a dataset may not care if their genders are known, but more personal features of X may be more sensitive.\nThese questions do not appear to have easy answers, especially when we wish to allow each provider of a single datum to be able to guarantee his or her own privacy. Nevertheless, we hope that our view of privacy and the techniques we have developed herein prove fruitful, and we hope to investigate some of the above issues in future work."}, {"heading": "A Unbiasedness", "text": "In this appendix, we show that if an optimization procedure receives biased subgradients it is possible to be arbitrarily wrong. We do so by constructing a simple problem instance. Fix a bias b > 0 and consider the following one-dimensional problem:\nminimize f(\u03b8) := b\u03b8\n2 subject to \u03b8 \u2208 [\u2212c, c].\nIf a gradient oracle returns biased gradients of the form \u2212b/2 at each point \u03b8 \u2208 [\u2212c, c], it is impossible to distinguish the objective from \u2212b\u03b8/2. The minimizer of this objective is \u03b8bias = sign(b)c. The true optimal point is \u03b8\u2217 = \u2212 sign(b)c, yielding the worst possible error\nf(\u03b8bias)\u2212 f(\u03b8\u2217) = sup \u03b8\u2208[\u2212c,c] f(\u03b8)\u2212 inf \u03b8\u2208[\u2212c,c] f(\u03b8).\nWe can show this more formally using an information theoretic derivation similar to that in Section 5. Omitting details, the argument is as follows. In the notation of Section 5, if a bias is chosen independently of the parameters v \u2208 V of the risk Rv, then there is a bounded amount of mutual information that can be communicated to any optimization procedure. Consequently, Fano\u2019s inequality (24) guarantees that the estimation accuracy of any procedure must be bounded away from zero."}, {"heading": "B Calculation of the Mutual Information for Sampling Strategies", "text": "This appendix is devoted to the proofs of our bounds on mutual information: Lemma 4, Lemma 5, Lemma 7, and Lemma 8. Before proving the lemmas, we make an observation that allows us to tensorize the mutual information, making our arguments simpler (we need only compute the single observation information I(Z1;V )). For each of Lemmas 4, 5, 7, and 8, recall that Z1, . . . , Zn are constructed based on an evaluation of the subgradient set \u2202\u03b8\u2113(Xi, \u03b8), where Xi are independent samples according to a distribution P (\u00b7 | V ). Then the samples Zi are conditionally independent of V given Xi and the parameters \u03b8, since Z is a random function of \u2202\u2113(Xi, \u03b8). Our goal is to upper bound the mutual information between the sequence Z1, . . . , Zn of observed (stochastic) gradients and the random element V \u2208 V.\nBy the general definition of mutual information [23, Chapter 5], it is no loss of generality to assume (temporarily) that the random variable Zi are supported on finite sets. Thus (using the chain rule for mutual information [8, 23, Chapter 5]) we have the decomposition\nI(Z1, . . . , Zn;V ) =\nn\u2211\ni=1\n[H(Zi | Z1, . . . , Zi\u22121)\u2212H(Zi | V,Z1, . . . , Zi\u22121)] .\nLet \u03b8i denote the point at which the ith gradient is computed. Then by inspection, we must have \u03b8i \u2208 \u03c3(Z1, . . . , Zi\u22121). Since Zi is conditionally independent of Z1, . . . , Zi\u22121 given V and \u03b8i and conditioning decreases entropy, we have\nH(Zi | Z1, . . . , Zi\u22121)\u2212H(Zi | V,Z1, . . . , Zi\u22121) = H(Zi | Z1, . . . , Zi\u22121)\u2212H(Zi | V, \u03b8i) \u2264 H(Zi | \u03b8i)\u2212H(Zi | V, \u03b8i) = I(Zi;V | \u03b8i).\nIn particular, letting Fi denote the distribution of \u03b8i, we have\nI(Z1, . . . , Zn;V ) \u2264 n\u2211\ni=1\n\u222b\n\u0398 I(Zi;V | \u03b8)dFi(\u03b8) \u2264\nn\u2211\ni=1\nsup \u03b8\u2208\u0398\nI(Zi;V | \u03b8). (40)\nThe representation (40) is the key to our calculations in this appendix.\nIn addition, the proofs of Lemmas 5 and 7 require a minor lemma, which we present here before giving the proofs proper.\nLemma 12. Let 1 > p > \u03b4 > 0 and p+ \u03b4 \u2264 1. Then\n(p+ \u03b4) log(p + \u03b4) + (p\u2212 \u03b4) log(p\u2212 \u03b4) > 2p log p.\nProof Since the function p 7\u2192 f(p) = p log p is strictly convex over [0,\u221e), we may apply convexity. Indeed, p = 12 (p+ \u03b4) + 1 2(p \u2212 \u03b4), so\np log p = f\n( 1\n2 (p+ \u03b4) +\n1 2 (p\u2212 \u03b4)\n) < 1\n2 f(p+ \u03b4) +\n1 2 f(p\u2212 \u03b4),\nwhich is the desired result.\nB.1 Proof of Lemma 4\nThe subgradient set \u2202\u2113(Xi; \u03b8) is independent of \u03b8, so we may use the inequality (40) to bound the mutual information of V and a single sample Z while ignoring the dependence on \u03b8. Define M = M\u221e/L. Since the sampling scheme (26) is independent per-coordinate, we see immediately that if Zj denotes the jth coordinate of Z then\nI(Z;V ) = H(Z)\u2212H(Z | V ) \u2264 d log(2) \u2212 d\u2211\nj=1\nH(Zj | V ).\nSince V is uniformly chosen from one of 2d vectors, we additionally find that\nI(Z;V ) \u2264 d [ log 2\u2212 1\n2d\n\u2211\nv\u2208V\nH(Z | V = v) ] .\nBy the choice of our sampling scheme for X and Z, we see that H(Z | V = v) is identical for each v \u2208 V, and we have\nQ(Zj = M\u221e | Vj = vj = 0) = Q(Zj = \u2212M\u221e | Vj = vj = 0) = 1\n2 .\nOn the other hand, by our choice of sampling scheme, for the \u201con\u201d index in V , we have\nQ(Zj = \u2212M\u221e | Vj = vj = \u22121) = Q(Zj = M\u221e | Vj = vj = 1) = Q(Zj = M\u221e | Xj = 1)P (Xj = 1 | Vj = vj = 1)\n+Q(Zj = M\u221e | Xj = \u22121)P (Xj = \u22121 | Vj = vj = 1)\n=\n( M + 1\n2M\n)( 1 + \u03b4\n2\n) + ( M \u2212 1 2M )( 1\u2212 \u03b4 2 ) = 1 2 + \u03b4 2M .\nConsequently, defining the Bernoulli entropy h(p) = \u2212p log p\u2212 (1\u2212 p) log(1\u2212 p), then\nI(Z;V ) \u2264 d [ log 2\u2212 1\n2d\n( (2d \u2212 2) log 2 + 2h ( 1\n2 +\n\u03b4\n2M\n))]\n= log 2 +\n( 1\n2 +\n\u03b4\n2M\n) log ( 1\n2 +\n\u03b4\n2M\n) + ( 1\n2 \u2212 \u03b4 2M\n) log ( 1\n2 \u2212 \u03b4 2M\n) .\nThe concavity of the function p 7\u2192 log(p) yields that log(1/2 + p) \u2264 log(1/2) + 2p, so\nI(Z;V ) \u2264 log 2 + ( 1\n2 +\n\u03b4\n2M\n)( \u2212 log 2 + \u03b4\nM\n) + ( 1\n2 \u2212 \u03b4 2M\n)( \u2212 log 2\u2212 \u03b4\nM\n) = \u03b42\nM2 .\nMaking the substitution M = M\u221e/L completes the proof.\nB.2 Proof of Lemma 5\nBy using the inequality (40), a bound on the mutual information I(Z;V | \u03b8) implies a bound on the joint information in the statement of the lemma, so we focus on bounding the mutual information of a single sample Z. In addition, it is no loss of generality to assume that r = 1.\nDefine M = M\u221e/L to be the multiple of the \u2113\u221e-norm of the subgradients that we take, and let Zj denote the jth coordinate of Z. Using the coordinate-wise independence of the sampling, we have\nI(Z;V | \u03b8) = H(Z | \u03b8)\u2212H(Z | V, \u03b8) \u2264 d log(2)\u2212 d\u2211\nj=1\nH(Zj | Vj, \u03b8j).\nNow consider the distribution of Zj given Vj and \u03b8j. By symmetry, the distribution has identical entropy for any value of Vj , so we may fix V = v and assume vj = without loss of generality. Then for \u03b8j \u2208 (\u22121, 1), the jth component of the subgradient \u2202\u2113(X; \u03b8) is \u2212Xj, whence we see that Q(Zj = M\u221e | vj = 1, \u03b8j) = Q(Zj = M\u221e | Xj = 1, \u03b8j)P (Xj = 1 | vj = 1) +Q(Zj = M\u221e | Xj = \u22121, \u03b8j)P (Xj = \u22121 | vj = 1)\n= ( M \u2212 1 2M )( 1 + \u03b4 2 ) + ( M + 1 2M )( 1\u2212 \u03b4 2 ) = 2M \u2212 2\u03b4\n4M =\n1 2 \u2212 \u03b4 2M .\nSimilarly, Q(Zj = \u2212M\u221e | vj = 1, \u03b8j) = 12 + \u03b42M . If \u03b8j \u2265 1, then we have that the subgradient \u2202|\u03b8j \u2212Xj | = 1 with probability 1, and thus\nQ(Zj = M\u221e | vj = 1, \u03b8j) = ( M + 1\n2M\n)( 1 + \u03b4\n2\n) + ( M + 1\n2M )( 1\u2212 \u03b4 2 ) = 1 2 ,\nwhich increases the entropy H(Zj | Vj , \u03b8j) by Lemma 12. Thus we see that the value \u03b8j minimizing the entropy H(Zj | Vj, \u03b8j) is given by any \u03b8j \u2208 (\u22121, 1), yielding Bernoulli marginal (12 + \u03b4/2M, 12 \u2212 \u03b4/2M) on Zj | Vj . Summarizing, we have\nI(Z;V | \u03b8) \u2264 d log(2) + d [( 1\n2 +\n\u03b4\n2M\n) log ( 1\n2 +\n\u03b4\n2M\n) + ( 1\n2 \u2212 \u03b4 2M\n) log ( 1\n2 \u2212 \u03b4 2M\n)] .\nAs in the proof of Lemma 4, we use the concavity of log to see that\nI(Z;V | \u03b8) \u2264 d log(2) + d [( 1\n2 +\n\u03b4\n2M\n) (\u2212 log(2) + \u03b4/M) + ( 1\n2 \u2212 \u03b4 2M\n) (\u2212 log(2)\u2212 \u03b4/M) ]\n= d\n( 1\n2 +\n\u03b4\n2M\n)( \u03b4\nM\n) + d ( 1\n2 \u2212 \u03b4 2M )( \u2212 \u03b4 M ) = d\u03b42 M2 .\nApplying the bound (40) and replacing M = M\u221e/L completes the proof.\nB.3 Proof of Lemma 7\nLetting Z denote a single subgradient sample using the conditional distribution Q specified by Proposition 2, we prove that\nI(Z;V | \u03b8) \u2264 \u03b42\u2206(\u03b3)2 for any \u03b8 \u2208 Rd, (41) which implies the lemma by the representation (40). Recall the SVM risk defined using the individual hinge losses (33): by construction, whenever X = ei, then the loss is equal to L [r \u2212 \u03b8i]+. We have\n\u2202\u2113(ei, \u03b8) = L { 0 if \u03b8i > r \u2212ei otherwise\nand \u2202\u2113(\u2212ei, \u03b8) = L {\n0 if \u03b8i < \u2212r ei otherwise.\nFor the remainder of this proof, we use the shorthand\nD\u03b3 := e \u03b3 + e\u2212\u03b3 + 2(d \u2212 2)\nfor the denominator in many of our expressions. If X = ei, then \u2202\u2113(ei, \u03b8) = Lei or 0 as \u03b8i \u2264 r or \u03b8i > r. Therefore, as we wish to communicate Lei or 0, the construction in Proposition 2 implies\nQ(Z = M1ei | X = ei, \u03b8) = { e\u2212\u03b3 D\u03b3 if \u03b8i \u2264 r\n1 2d if \u03b8i > r,\n(42)\nand similarly we have for j 6= i that\nQ(Z = M1ej | X = ei, \u03b8) = { 1 D\u03b3\nif \u03b8i \u2264 r 1 2d if \u03b8i > r.\n(43)\nFor X = \u2212ei, we have the conditional distribution parallel to (42):\nQ(Z = M1ei | X = \u2212ei, \u03b8) = { e\u03b3 D\u03b3 if \u03b8i \u2265 \u2212r\n1 D\u03b3 if \u03b8i < \u2212r.\nFor any given \u03b8, we have that\nI(Z;V | \u03b8) = H(Z | \u03b8)\u2212H(Z | V, \u03b8) \u2264 log(2d) \u2212 1|V| \u2211\nv\u2208V\nH(Z | \u03b8, V = v) (44)\nsince the choice of V is uniform and Z takes on at most 2d values. We thus use the conditional distributions (42) and (43) to compute the entropy H(Z | \u03b8, V ) (specifically, the minimal such entropy across all values of \u03b8). To do this, we compute the marginal distribution Q(z | v), arguing that H(Z | \u03b8, V ) is minimal for \u03b8 \u2208 int[\u2212r, r]d. When \u03b8j \u2208 (\u2212r, r) for all j, we have\nQ(Z = M1ei | V = v, \u03b8) = d\u2211\nj=1\nQ(Z = M1ei | X = ej , \u03b8)P (X = ej | V = v)\n+\nd\u2211\nj=1\nQ(Z = M1ei | X = \u2212ej , \u03b8)P (X = \u2212ej | V = v).\nWhen vi = 1, we thus have that\nQ(Z = M1ei | V = v, \u03b8) = 1 + \u03b4\n2d\ne\u2212\u03b3 D\u03b3 + 1\u2212 \u03b4 2d e\u03b3 D\u03b3 +\n\u2211\nj 6=i\n1\nD\u03b3\n( 1 + \u03b4vj\n2d + 1\u2212 \u03b4vj 2d\n)\n= e\u03b3 + e\u2212\u03b3 + \u03b4(e\u2212\u03b3 \u2212 e\u03b3)\n2dD\u03b3 + d\u2212 1 dD\u03b3 = 1 2d + \u03b4(e\u2212\u03b3 \u2212 e\u03b3) 2dD\u03b3 , (45a)\nand under the same condition,\nQ(Z = \u2212M1ei | A = v, \u03b8) = e\u03b3 + e\u2212\u03b3 + \u03b4(e\u03b3 + e\u2212\u03b3)\n2dD\u03b3 + d\u2212 1 dD\u03b3 = 1 2d + \u03b4(e\u03b3 \u2212 e\u2212\u03b3) 2dD\u03b3 . (45b)\nIf for any (possibly multiple) indices j we have \u03b8j 6\u2208 (\u2212r, r), then via a bit of algebra and the conditional distributions (42) and (43), we see that there exists an \u01eb \u2208 (0, 1) such that\nQ(Z = M1ei | V = v, \u03b8) = \u01eb 1\n2d + (1\u2212 \u01eb)\n( 1\n2d + \u03b4(e\u2212\u03b3 \u2212 e\u03b3) 2dD\u03b3\n) .\nLemma 12 then implies that if \u03b8 \u2208 int[\u2212r, r]d while \u03b8\u2032 6\u2208 int[\u2212r, r]d, then\nH(Z | \u03b8, V = v) < H(Z | \u03b8\u2032, V = v).\nSince we seek an upper bound on the mutual information, we may thus assume without loss of generality that \u03b8 \u2208 int[\u2212r, r]d.\nNow we compute the entropy H(Z | \u03b8, v) using the marginal conditional distributions (45a) and (45b), which describe Z | V when \u03b8 \u2208 int[\u2212r, r]d. Indeed, recall the definition in the statement of the lemma of the difference \u2206(\u03b3). For z \u2208 {\u00b1M1ej}dj=1, define the relation z \u223c v to mean that if z = M1ei, then vi = 1 and if z = \u2212M1ei then vi = \u22121. We then see that the entropy is H(Z | \u03b8, V = v) = \u2212 \u2211\nz\u223cv\nQ(z | v, \u03b8) logQ(z | v, \u03b8)\u2212 \u2211\nz 6\u223cv\nQ(z | v, \u03b8) logQ(z | v, \u03b8)\n= \u2212d ( 1\n2d +\n\u03b4\u2206(\u03b3)\n2d\n) log ( 1\n2d +\n\u03b4\u2206(\u03b3)\n2d\n) \u2212 d ( 1\n2d \u2212 \u03b4\u2206(\u03b3) 2d\n) log ( 1\n2d \u2212 \u03b4\u2206(\u03b3) 2d\n) .\nAs in the proofs of Lemmas 4 and 5, we use the concavity of log(\u00b7) to see that\n\u2212H(Z | \u03b8, V = v) = ( 1\n2 +\n\u03b4\u2206(\u03b3)\n2\n) log ( 1\n2d +\n\u03b4\u2206(\u03b3)\n2d\n) + ( 1\n2 \u2212 \u03b4\u2206(\u03b3) 2\n) log ( 1\n2d \u2212 \u03b4\u2206(\u03b3) 2d\n)\n\u2264 ( 1\n2 +\n\u03b4\u2206(\u03b3)\n2\n) (\u2212 log(2d) + \u03b4\u2206(\u03b3)) + ( 1\n2 \u2212 \u03b4\u2206(\u03b3) 2\n) (\u2212 log(2d)\u2212 \u03b4\u2206(\u03b3))\n= \u2212 log(2d) + \u03b42\u2206(\u03b3)2.\nInvoking the earlier bound (44) and adding log(2d) to the above expression completes the proof of the claim (41).\nB.4 Proof of Lemma 8\nLet Zj denote the jth coordinate of Z. We first argue that conditional on V , the random variable Z has independent coordinates. Indeed, let q+ = q(z | x) for z such that z\u22a4x > k and q\u2212 = e\u2212\u03b1q+. Without loss of generality, we may take V = e1, the first basis vector, and hence\nQ(Z = z | V = e1) = \u2211\nx\u2208{\u22121,1}d\nQ(Z = z | X = x)P (X = x | V = e1)\n= 1\n2d\u22121\n\u2211\nx\u2208{\u22121,1}d\nQ(Z = z | X = x) \u00b7 1 + x1\u03b4 2\n= 1\n2d\u22121\n[ \u2211\nx:\u3008z,x\u3009>k\nq+ 1 + x1\u03b4\n2 +\n\u2211\nx:\u3008z,x\u3009\u2264k\nq\u2212 1 + x1\u03b4\n2\n] . (46)\nNow, if z1 = 1, then\n\u2211\nx:\u3008x,z\u3009>k\n1 + x1\u03b4\n2 =\n\u2211\nx:\u3008x,z\u3009>k,x1=1\n1 + \u03b4\n2 +\n\u2211\nx:\u3008x,z\u3009>k,x1=\u22121\n1\u2212 \u03b4 2 = 1 + \u03b4 2 Cd\u22121(k\u22121)+ 1\u2212 \u03b4 2 Cd\u22121(k+1)\nand similarly\n\u2211\nx:\u3008x,z\u3009\u2264k\n1 + x1\u03b4\n2 =\n1 + \u03b4\n2\n( 2d\u22121 \u2212 Cd\u22121(k \u2212 1) ) +\n1\u2212 \u03b4 2\n( 2d\u22121 \u2212 Cd\u22121(k + 1) ) .\nOn the other hand, we find that if z1 = \u22121, then similar equalities hold, but with the counters Cd\u22121(k \u2212 1) and Cd\u22121(k + 1) flipped:\n\u2211\nx:\u3008x,z\u3009>k\n1 + x1\u03b4\n2 =\n1 + \u03b4\n2 Cd\u22121(k + 1) + 1\u2212 \u03b4 2 Cd\u22121(k \u2212 1)\n\u2211\nx:\u3008x,z\u3009\u2264k\n1 + x1\u03b4\n2 =\n1 + \u03b4\n2\n( 2d\u22121 \u2212 Cd\u22121(k + 1) ) +\n1\u2212 \u03b4 2\n( 2d\u22121 \u2212 Cd\u22121(k \u2212 1) ) .\nIn particular, we find that so long as the first coordinate z1 = z \u2032 1 of z remains constant, then Q(Z = z | V = e1) = Q(Z = z\u2032 | V = e1), and that we thus have Z2, . . . , Zd are distributed uniformly at random in {\u22121, 1}d.\nWe now determine q+ and compute the marginal value Q(Z1 = 1 | V = e1). For the first, we note that\nCd(k)q + + (2d \u2212 Cd(k))q\u2212 = 1, or Cd(k)q+ + e\u2212\u03b1(2d \u2212 Cd(k))q+ = 1,\nwhich yields the expressions\nq+ = e\u03b1\n(e\u03b1 \u2212 1)Cd(k) + 2d and q\u2212 =\n1\n(e\u03b1 \u2212 1)Cd(k) + 2d .\nBy the expression (46) and calculations following, we thus find that when z1 = 1, we have\nq(z | e1) = 1 2d\u22121 \u00b7 [ q+ (1 + \u03b4 2 Cd\u22121(k \u2212 1) + 1\u2212 \u03b4 2 Cd\u22121(k + 1) )\n+ q\u2212 (1 + \u03b4\n2 (2d\u22121 \u2212 Cd\u22121(k \u2212 1)) + 1\u2212 \u03b4 2\n(2d\u22121 \u2212 Cd\u22121(k + 1)) )]\n= 1 2d\u22121 \u00b7 [ 2d\u22121q\u2212 + 1 2 (q+ \u2212 q\u2212)(Cd\u22121(k \u2212 1) + Cd\u22121(k + 1))\n+ \u03b4\n2 (q+ \u2212 q\u2212)(Cd\u22121(k \u2212 1)\u2212 Cd\u22121(k + 1))\n] , (47a)\nand similarly when z1 = \u22121 we have\nq(z | e1) = 1 2d\u22121 \u00b7 [ 2d\u22121q\u2212 + 1 2 (q+ \u2212 q\u2212)(Cd\u22121(k \u2212 1) + Cd\u22121(k + 1))\n\u2212 \u03b4 2 (q+ \u2212 q\u2212)(Cd\u22121(k \u2212 1)\u2212 Cd\u22121(k + 1))\n] . (47b)\nNow note that\nCd\u22121(k \u2212 1)\u2212 Cd\u22121(k + 1) = \u2308(d\u2212k)/2\u2309\u22121\u2211\ni=0\n( d\u2212 1 i ) \u2212 \u2308(d\u2212k)/2\u2309\u22122\u2211\ni=0\n( d\u2212 1 i ) = ( d\u2212 1 \u2308(d\u2212 k)/2\u2309 \u2212 1 )\nand that the difference\nq+ \u2212 q\u2212 = e \u03b1 \u2212 1\n(e\u03b1 \u2212 1)Cd(k) + 2d .\nRecalling the definition of the constant \u2206, we thus find from the expansions (47a) and (47b)\u2014since they must sum to 1\u2014that\nQ(Z = z | V = e1) = 1 2d\u22121 \u00b7 { 1 2 + \u2206(\u03b4,\u03b1,d,k) 2 if z1 = 1\n1 2 \u2212 \u2206(\u03b4,\u03b1,d,k) 2 if z1 = \u22121.\n(48)\nIt is clear that similar statements hold in the other symmetric cases (i.e. if V = \u2212e2, then the probabilities depend on z2 = \u22121 or 1).\nIt remains to use the marginalized representation (48) to compute the bound on the mutual information in the statement of the lemma. Given V = v, Z \u2208 {\u2212M,M}d is uniform except on the coordinate j for which vj 6= 0, by symmetry. (Marginally, Z is uniform on {\u2212M,M}d.) By a direct calculation, we have H(Z) = d log 2 and\nH(Z | V = e1) = d\u2211\nj=1\nH(Zj | Z1:j\u22121, V = e1) = H(Z1 | V = e1) + (d\u2212 1) log 2,\nand similarly for the other possible values of V . Therefore, using the probabilities (48), we have the mutual information bound\nI(Z;V ) = H(Z)\u2212H(Z | V ) \u2264 d log 2\u2212 1 2d\n\u2211\nv\nH(Z | V = v)\n= d log 2\u2212 (d\u2212 1) log 2\n+\n( 1\n2 +\n\u2206(\u03b4, \u03b1, d, k)\n2\n) log ( 1\n2 +\n\u2206(\u03b4, \u03b1, d, k)\n2\n) + ( 1\n2 \u2212 \u2206(\u03b4, \u03b1, d, k) 2\n) log ( 1\n2 \u2212 \u2206(\u03b4, \u03b1, d, k) 2\n)\n\u2264 log 2 + ( 1\n2 +\n\u2206(\u03b4, \u03b1, d, k)\n2\n)[ log 1\n2 + \u2206(\u03b4, \u03b1, d, k)\n] + ( 1\n2 \u2212 \u2206(\u03b4, \u03b1, d, k) 2\n)[ log 1\n2 \u2212\u2206(\u03b4, \u03b1, d, k)\n]\n= \u2206(\u03b4, \u03b1, d, k)2 ,\nwhere the inequality follows from the concavity of p 7\u2192 log(p).\nB.5 Bounds on total variation norm\nLemma 13. Let Q1 and Q\u22121 be distributions on {\u22121, 1}, where\nQ1(Z = z) = 1\n2 +\n1 2 \u00b7 { \u03b4 if z = 1 \u2212\u03b4 otherwise and Q\u22121(Z = z) = 1 2 + 1 2 \u00b7 { \u2212\u03b4 if z = 1 \u03b4 otherwise.\nLet Qni denote the n-fold product distribution of Qi. Then for \u03b4 \u2208 [0, 1/3], \u2225\u2225Qn1 \u2212Qn\u22121 \u2225\u2225 TV \u2264 \u03b4 \u221a (3/2)n.\nProof For any two probability distributions P,Q, Pinsker\u2019s inequality [8] asserts that the total variation norm is bounded as \u2016P \u2212Q\u2016TV \u2264 \u221a Dkl (P\u2016Q) /2. Applying this inequality in our setting, we find that\n\u2225\u2225Qn1 \u2212Qn\u22121 \u2225\u2225 TV \u2264 \u221a 1\n2 Dkl\n( Qn1\u2016Qn\u22121 ) =\n1\u221a 2\n\u221a nDkl (Q1\u2016Q\u22121),\nwhere we have exploited the product nature of Qni . Now we note that by the concavity of the log, we have (via the first-order inequality) that log 1+\u03b41\u2212\u03b4 \u2264 2\u03b4/(1 \u2212 \u03b4), so\n1 + \u03b4\n2 log\n1+\u03b4 2 1\u2212\u03b4 2 + 1\u2212 \u03b4 2 log 1\u2212\u03b4 2 1+\u03b4 2 = 1 + \u03b4 2 log 1 + \u03b4 1\u2212 \u03b4 + 1\u2212 \u03b4 2 log 1\u2212 \u03b4 1 + \u03b4 = \u03b4 log 1 + \u03b4 1\u2212 \u03b4 \u2264 2\u03b42 1\u2212 \u03b4 .\nAssuming that \u03b4 \u2264 1/3, the final term is upper bounded by 3\u03b42. But of course by definition of Q1 and Q\u22121, we have\nDkl (Q1\u2016Q\u22121) = 1 + \u03b4\n2 log\n1+\u03b4 2 1\u2212\u03b4 2 + 1\u2212 \u03b4 2 log 1\u2212\u03b4 2 1+\u03b4 2 \u2264 3\u03b42,\nwhich completes the proof."}, {"heading": "C Achievability by stochastic mirror descent", "text": "In this appendix, we provide further details on the algorithm used to achieve the upper bounds in Theorems 4 and 5. Both of our achievability results rely on stochastic gradient mechanisms, and their most important ingredient is a conditional distribution Q that satisfies \u03b1-local differential privacy. In particular, if g \u2208 Rd is a (sub)gradient of the loss \u2113(x, \u03b8), we construct Z \u2208 Rd by perturbing g in such a way that E[Z | g] = g. Thus, each of the achievability guarantees consists of describing an \u03b1-differentially private sampling distribution, then bounding the expected norm of Z and applying one of the convergence guarantees (14).\nC.1 Achievability in Theorem 4\nThe sampling strategy we use is essentially identical to that used in Corollary 3 (and the optimal \u03b1-private scheme of Proposition 3; see also Strategy B in our paper [12]). Let \u03c0\u03b1 := e\n\u03b1/(e\u03b1+1) and T be a Bernoulli(\u03c0\u03b1)-random variable, and let B \u2265 L be a fixed constant (to be specified). Then given a vector g \u2208 Rd with \u2016g\u2016\u221e \u2264 L, construct g\u0303 \u2208 Rd with coordinates g\u0303j sampled independently from {\u2212L,L} with probabilities 1/2 \u2212 gj/(2L) and 1/2 + gj/(2L). Then sample T and set\nZ \u223c { Uniform(z \u2208 {\u2212B,B}d : \u3008z, g\u0303\u3009 > 0) if T = 1 Uniform(z \u2208 {\u2212B,B}d : \u3008z, g\u0303\u3009 \u2264 0) if T = 0.\n(49)\nBy inspection, the scheme (49) is \u03b1-differentially private. Moreover, we have by the calculations in the proof of Corollary 3 (see Section 5.9) that by the sampling strategy (49)\nE[Z | g] = E[E[Z | g\u0303] | g] = g B 2d\u22121L e\u03b1 \u2212 1 e\u03b1 + 1\n\u00b7 {(d\u22121 d\u22121 2 ) d odd\n(d\u22121 d/2 ) d even.\nThus, w.l.o.g. assuming d is odd, choosing\nB = 2d\u22121L e\u03b1 + 1\ne\u03b1 \u2212 1 ( d\u2212 1 d\u22121 2 )\u22121 implies E[Z | g] = g and \u2016Z\u2016\u221e = B = O(1)(L/\u03b1) \u221a d.\nApplying the mirror descent method to the gradients provided from the sampling strategy (49), we obtain the bound (14a) with M\u221e = B = O(1)(L/\u03b1) \u221a d, which is our desired result.\nC.2 Achievability in Theorem 5\nThe achievability result for Theorem 5 is similar to that for Theorem 4, but we use a modified sampling distribution. Now, using the same notation as that for the strategy (49), we use the following. Given a vector g with \u2016g\u20162 \u2264 L, set g\u0303 = Lg/ \u2016g\u20162 with probability 12 + \u2016g\u20162 /2L and g\u0303 = \u2212Lg/ \u2016g\u20162 with probability 12 \u2212 \u2016g\u20162 /2L. Then sample T \u223c Bernoulli(\u03c0\u03b1) and set\nZ \u223c { Uniform(z \u2208 Rd : \u3008z, g\u0303\u3009 > 0, \u2016z\u20162 = B) if T = 1 Uniform(z \u2208 Rd : \u3008z, g\u0303\u3009 \u2264 0, \u2016z\u20162 = B) if T = 0.\n(50)\n(This is Strategy A in our paper [12].) Then we have [12, Appendix D.1] that\nE[Z | g] = B L e\u03b1 \u2212 1 e\u03b1 + 1 \u0393(d2 + 1)\u221a \u03c0d\u0393(d\u221212 + 1) ,\nso choosing\nB = L e\u03b1 + 1\ne\u03b1 \u2212 1\n\u221a \u03c0d\u0393(d\u221212 + 1)\n\u0393(d2 + 1) \u2264 Le\n\u03b1 + 1 e\u03b1 \u2212 1 3 \u221a \u03c0 \u221a d 2\nimplies that E[Z | g] = g and \u2016Z\u20162 \u2264 B = O(1)(L/\u03b1) \u221a d. Applying the stochastic gradient descent method to the gradients provided by the sampling scheme (50), we obtain the bound (14b) with M2 = B, which implies that if \u0398 \u2282 B2(r2) then\nE[R(\u03b8\u0302n)]\u2212R(\u03b8\u2217) = O (\u221a d\n\u03b1 Lr2\u221a n\n) .\nNoting that Bq(rq) \u2282 d 1 2 \u2212 1 qB2(rq) completes the proof of the achievability result."}, {"heading": "D Background on Conditional Probabilities", "text": "In this appendix, we present some basic lemmas on conditional independence and regular conditional probabilities that will be useful in Appendix E.\nWe first recall the following classical data-processing inequality, which holds for essentially arbitrary random variables [23, Chapter 5]:\nLemma 14 (Data processing). Let X \u2192 Z \u2192 Y be a Markov chain. Then I(X;Y ) \u2264 I(X;Z), with equality if and only if X is conditionally independent of Y given Z.\nThis inequality, in conjunction with with Carathe\u0301odory and Minkowski\u2019s finite-dimensional version of the Krein-Milman theorem (e.g. [26]), allows us to argue any Q minimizing I(P,Q) must be supported on the extreme points of D. To make this point precise, however, we need to address certain measurability issues involved in the choice of the extreme points.\nWe begin with a precise definition of a regular conditional probability.\nDefinition 5. Let (\u2126,F) and (T, \u03c3(T )) be measurable spaces. A regular conditional probability, also known as a Markov kernel or transition probability, is a function \u03bd : T \u00d7F \u2192 [0, 1] such that\nt 7\u2192 \u03bd(t, A) is measurable for all A \u2208 F \u03bd(t, \u00b7) : F \u2192 [0, 1] is a probability measure for all t \u2208 T.\nAny Markov chain has a transition probability; conversely, any set of consistent transition probabilities define a Markov chain (see, e.g., Chapter 5 of Kallenberg [27]).\nSome difficulties with measurability arise in constructing the appropriate Markov chain for our setting. To deal with them, we use results from Choquet theory, which extend Krein-Milman theorems to integral representations [39]. We begin our proof by stating a measurable selection theorem [39, Theorem 11.4], though we restrict the theorem\u2019s statement to subsets of finite dimensional space.\nProposition 5. Let D \u2282 Rd be a compact convex set. For each x, there exists a probability measure \u00b5x supported on Ext(D) such that \u222b D yd\u00b5x(y) = x. Moreover, the mapping x 7\u2192 \u00b5x can be taken to be measurable.\nIn the statement of this result, measurability is taken with respect to the \u03c3-field generated by the topology of weak convergence. As a consequence of the proposition, however, it is clear that since for any continuous function f the mapping x 7\u2192 \u222b fd\u00b5x is measurable, we have that for relatively open sets A \u2282 C the mapping x 7\u2192 \u00b5x(A) is measurable, whence for any measurable set A \u2282 C the mapping x 7\u2192 \u00b5x(A) is measurable. That is, we can define the Markov kernel \u03bd : Rd\u00d7\u03c3(C) \u2192 [0, 1] according to the mapping specified by Proposition 5 (we take \u03bd(x, \u00b7) = \u00b5x) with the additional properties that\n\u222b\nD y\u03bd(x, dy) = x and \u03bd(x,D \\ Ext(D)) = 0 for all x \u2208 D.\nIn finite dimensions, a trivial extension of Proposition 5 allows us to drop the assumption that D is convex. Indeed, we have that since D is compact, then Ext(D) = Ext(Conv(D)) [26, Chapter III.2].\nGiven this measure-theoretic background, we turn to a key lemma that we will need in Appendix E. In this lemma, we assume as usual that C \u2282 D \u2282 Rd are compact sets, and that Q \u2208 Q(C,D) (recall the definition (10b)).\nLemma 15. Let P be a distribution supported on C. If there exists a set A \u2282 C with P (A) > 0 and a set B \u2282 D \\ Ext(D) with Q(B | X = x) > 0 for x \u2208 A, there exists a regular conditional probability distribution Q\u2032 \u2208 Q(C,D) where Q\u2032(\u00b7 | x) has support contained in Ext(D) and\nI(P,Q) > I(P,Q\u2032).\nParaphrasing the lemma slightly, we have that any conditional distribution Q minimizing I(P,Q) must (outside of a set of measure zero) be completely supported on the extreme points Ext(D). Proof For any y \u2208 D, Proposition 5 guarantees that we can represent y as the (regular conditional) measure \u03bd(y, \u00b7). Thus we can define a random variable Zy distributed according to \u03bd(y, \u00b7), whose existence we are guaranteed by standard constructions [4, 27] with regular conditional probability. Then E[Zy] = \u222b D z\u03bd(y, dz) = y, and moreover, we can define the measurable version of the conditional expectation E[ZY | Y ] via\nE[ZY | Y ] = \u222b\nD z\u03bd(Y, dz) = Y\nso we have the (almost sure) chain of equalities\nE[ZY | X = x] = E[E[ZY | Y ] | X = x] = \u222b\nD E[ZY | Y = y]dQ(y | X = x)\n=\n\u222b\nD\n\u222b\nD z\u03bd(y, dz)dQ(y | X = x) =\n\u222b\nD ydQ(y | X = x) = x.\nBy construction, X \u2192 Y \u2192 Z is a valid Markov chain, and since the sets A and B satisfy P (A) > 0 and \u222b AQ(B | X = x)dP (x) > 0, we see that I(X;Y ) > I(X;Z) by Lemma 14.\nWe turn to an analogue of Lemma 15 in the differentially private setting.\nLemma 16. Let the conditions of Lemma 15 hold, and let P be a distribution supported on C. If there exists a set A \u2282 C with P (A) > 0 and a set B \u2282 D \\ Ext(D) with Q(B | X = x) > 0 for x \u2208 A, there exists a regular conditional probability distribution Q\u2032 \u2208 Q (C,D) where Q\u2032(\u00b7 | x) has support contained in Ext(D), satisfies\nI(P,Q) > I(P,Q\u2032),\nand has no worse differential privacy than Q:\nsup S\u2208\u03c3(D) sup x,x\u2032\u2208C Q\u2032(S | X = x) Q\u2032(S | X = x\u2032) \u2264 supS\u2208\u03c3(D) sup x,x\u2032\u2208C Q(S | X = x) Q(S | X = x\u2032) .\nProof Let \u03bd : Rd \u00d7 \u03c3(C) \u2192 [0, 1] be the Markov kernel defined in the proof of Lemma 15, and without loss of generality assume that Q(\u00b7 | X = x) and Q(\u00b7 | X = x\u2032) have density q with respect to an underlying measure \u00b5x,x\u2032. Define the distribution\nQ\u2032(S | X = x) := \u222b\nD\n\u222b\nD \u03bd(y, dz)q(y | x)d\u00b5x,x\u2032(y).\nBy assumption, if Q is \u03b1-differentially private, then for \u00b5-almost all y \u2208 D, we have q(y | x) \u2264 e\u03b1q(y | x\u2032). We find that\nQ\u2032(S | X = x) = \u222b\nD\n\u222b\nD \u03bd(y, dz)q(y | x)d\u00b5x,x\u2032(y)\n\u2264 \u222b\nD\n\u222b\nD \u03bd(y, dz)e\u03b1q(y | x\u2032)d\u00b5x,x\u2032(y) = e\u03b1Q\u2032(S | X = x\u2032),\nso Q\u2032 is at least as differentially private as Q.\nFinally, we will need the following standard maximum entropy result. Let z denote a discrete random variable and let q(z | x) denote the conditional probability mass function of Z | X = x. Consider the finite dimensional entropy maximization problem\nminimize q\n\u2211\nz\nq(z | x) log q(z | x) (51)\nsubject to \u2211\nz\nzq(z | x) = x, \u2211\nz\nq(z | x) = 1, q(z | x) \u2265 0 for all z.\nWe have the following lemma, which establishes the form of the solution to the problem (51). We include a proof for completeness.\nLemma 17. The p.m.f. q(\u00b7 | x) solving problem (51) is given by\nq(z | x) = exp(\u2212\u00b5 \u22a4z)\u2211\nz\u2032 exp(\u2212\u00b5\u22a4z\u2032) , (52)\nwhere \u00b5 \u2208 Rd is any vector chosen to satisfy the constraint \u2211\nz zq(z | x) = x. Such a \u00b5 \u2208 Rd exists. Proof We may write the Lagrangian with dual variables \u00b5 \u2208 Rd, \u03bb(z) \u2265 0, and \u03b8 \u2208 R, L(q, \u00b5, \u03bb, \u03b8) = \u2211\nz\nq(z | x) log q(z | x)+\u00b5\u22a4 (\u2211\nz\nzq(z | x)\u2212x ) +\u03b8 (\u2211\nz\nq(z | x)\u22121 ) \u2212 \u2211\nz\n\u03bb(z)q(z | x).\nSince the problem (51) has convex cost, linear constraints, and non-empty domain, strong duality obtains [6, Chapter 5], and the KKT conditions hold for the problem. Thus, minimizing q out of L to find the dual, we take derivatives with respect to the m variables q(z | x) for z = (1 + \u03b1)ui and find the optimal conditional p.m.f. q must satisfy\nlog q(z | x) + 1 + \u00b5\u22a4z + \u03b8 \u2212 \u03bb(z) = 0, or q(z | x) = exp(\u03bb(z) \u2212 1\u2212 \u03b8) exp(\u2212\u00b5\u22a4z). In particular, we see that since q(z | x) > 0, we must have \u03bb(z) = 0 by complementarity, and (satisfying the summability constraint \u2211 z q(z | x) = 1) we see that\nq(z | x) = exp(\u2212\u00b5 \u22a4z)\u2211\nz\u2032 exp(\u2212\u00b5\u22a4z\u2032) ,\nwhere \u00b5 \u2208 Rd is any vector chosen to satisfy the constraint \u2211z zq(z | x) = x. The existence of such a \u00b5 is guaranteed by the attainment of the KKT conditions."}, {"heading": "E Proofs of Minimax Mutual Information Characterizations", "text": "In this section, we provide the proofs of the results stated in Section 4, all of which follow a broadly similar outline. We make use of Lemma 15 to guarantee that any conditional distribution Q minimizing the mutual information I(P,Q) must be supported on the extreme points of the set D. This allows us to reduce computing maximal entropies and minimal mutual information values to finite dimensional convex programs, whose optimality we can check using results from convex analysis and optimization.\nE.1 Proof of Theorem 6\nWe begin by considering supP , where Q \u2217 is defined as in the statement of the theorem. Since the support of Q\u2217 is finite (there are m extreme points of D), we have\nI(P,Q\u2217) = I(X;Z) = H(Z)\u2212H(Z | X) \u2264 log(m)\u2212H(Z | X)\n= log(m)\u2212 \u222b H(Z | X = x)dP (x).\nNow, for any distribution P on the set C and for any x \u2208 suppP , we can write x as x = \u2211i \u03b2i(x)ui, where ui are the extreme points of C, and where \u03b2i(x) \u2265 0 and \u2211 i \u03b2i(x) = 1 (using the KreinMilman theorem). Define the individual probability mass functions qi to be the maximum entropy p.m.f. (52) for each of the extreme points ui. Then we can define the conditional probability mass function by\nq(\u00b7 | x) = \u2211\ni\n\u03b2i(x)q i(\u00b7).\n(Without loss of generality, we may assume the \u03b2i are continuous, since the set of extreme points is finite, and thus q(\u00b7 | x) can be viewed as a regular conditional probability. We can make this formal using the techniques in the proof of Lemma 15.) Denoting H(q(\u00b7 | x)) := H(Z | X = x), we can use the convexity of the negative entropy to see that\nI(P,Q\u2217) \u2264 log(m)\u2212 \u222b \u2211\ni\n\u03b2i(x)H(q i(\u00b7))dP (x). (53)\nBy symmetry, the entropy H(qi(\u00b7)) = H(Q\u2217(\u00b7 | X = ui)) is a constant determined by the maximum entropy distribution (52), and thus\nI(P,Q\u2217) \u2264 log(m)\u2212H(Q\u2217(\u00b7 | X = ui)). (54)\nEquality in the upper bound (54) is attained by taking P \u2217 to be the uniform distribution on the extreme points {ui} of C.\nIt remains to establish an identical lower bound for I(P \u2217, Q) over all conditional distributions Q satisfying the constraints of the theorem statement. We know from Lemma 15 that Q must be supported on (1 + \u03ba)ui for i = 1, . . . ,m. Denoting by q(z | x) the p.m.f. of Q conditional on x (for x in the finite set of extreme points of C that make up the support suppP \u2217), we can write minimizing the mutual information as the parametric convex optimization problem\nminimize q\n\u2211\nz\n( \u2211\nx\nq(z | x)p(x) ) log ( \u2211\nx\nq(z | x)p(x) ) \u2212 \u2211\nx\np(x) \u2211\nz\nq(z | x) log q(z | x) (55)\nsubject to \u2211\nz\nq(z | x) = 1 for all x, \u2211\nz\nzq(z | x) = x for all x, q(z | x) \u2265 0 for all x, z.\nIn the problem (55), the sums over x and z are over the extreme points of C and D, respectively and p is the uniform distribution with p(x) = 1/m. Mutual information is convex in the conditional distribution q; moreover, it is strictly convex except when q(z | x) = \u2211x\u2032 q(z | x\u2032)p(x\u2032) for all x, z. (This can be seen by an inspection of the proof of Theorem 2.7.4 by Cover and Thomas [8].) In our case, since Q\u2217 does not satisfy this equality, the uniqueness of Q\u2217 as the minimizer of I(P \u2217, Q\u2217) will follow if we show that Q\u2217 is a minimizer at all.\nWe proceed to solve the problem (55). Writing I(p, q) as a shorthand for the mutual information, we introduce Lagrange multiplers \u03b8(x) \u2208 R for the normalization constraints, \u00b5(x) \u2208 Rd for the conditional expectation constraints, and \u03bb(x, z) \u2265 0 for the nonnegativity constraints. This yields the Lagrangian L(q, \u00b5, \u03bb, \u03b8) = I(p, q)\u2212 \u2211\nx,z\n\u03bb(x, z)q(z | x)+ \u2211\nx\n\u00b5(x)\u22a4 (\u2211\nz\nzq(z | x)\u2212x ) + \u2211\nx\n\u03b8(x)\n(\u2211\nz\nq(z | x)\u22121 ) .\nIf we can satisfy the Karush-Kuhn-Tucker (KKT) conditions (see, e.g., [6]) for optimality of the problem (55), we will be done. Taking derivatives with respect to q(z | x), we see\n\u2202 \u2202q(z | x)L(q, \u00b5, \u03bb, \u03b8) = p(x) [log(q(z | x)) + 1]\u2212 p(x) log (\u2211\nx\u2032\nq(z | x\u2032)p(x\u2032) )\n\u2212 q(z) \u00b7 1 q(z) p(x)\u2212 \u03bb(z, x) + \u03b8(x) + \u00b5(x)\u22a4z\n= p(x) log q(z | x)\u2212 p(x) log (\u2211\nx\u2032\nq(z | x\u2032)p(x\u2032) ) \u2212 \u03bb(z, x) + \u03b8(x) + \u00b5(x)\u22a4z,\nwhere we set q(z) = \u2211\nx\u2032 q(z | x\u2032)p(x\u2032) for shorthand. Now, we use symmetry to note that since we have chosen q to be the maximum entropy distribution (52) for each x in the extreme points {ui} of C, the marginal q(z) = \u2211 x\u2032 q(z | x\u2032)p(x\u2032) = 1/m is uniform by the symmetry of the set D and since p is uniform. In addition, since q(z | x) > 0 strictly, we have \u03bb(z, x) = 0 by complementarity. Thus, at q chosen to be the maximum entropy distribution, we can rewrite the derivative of the Lagrangian\n\u2202 \u2202q(z | x)L(q, \u00b5, \u03bb, \u03b8) = 1 m log q(z | x)\u2212 1 m log 1 m + \u03b8(x) + \u00b5(x)\u22a4z.\nRecalling the definition (52) of q(z | x), and denoting the maximum entropy parameters \u00b5 there by \u00b5\u2217(x), we have\n\u2202 \u2202q(z | x)L(q, \u00b5, \u03bb, \u03b8) = \u2212 1 m \u00b5\u2217(x)\u22a4z + 1 m log\n( \u2211\nz\u2032\nexp(\u2212\u00b5\u2217(x)\u22a4z\u2032) )\n\u2212 1 m log 1 m + \u03b8(x) + \u00b5(x)\u22a4z.\nNow, by inspection we may set\n\u03b8(x) = 1\nm log\n1 m \u2212 1 m log\n( \u2211\nz\u2032\nexp(\u2212\u00b5\u2217(x)\u22a4z\u2032) ) and \u00b5(x) = 1\nm \u00b5\u2217(x),\nand we satisfy the KKT conditions for the mutual information minimization problem (55). Summarizing, the conditional distribution Q\u2217 specified in the statement of the theorem as the maximum entropy distribution (52) satisfies\ninf Q\nI(P \u2217, Q) \u2265 I(P \u2217, Q\u2217),\nwhich, when combined with the first part of the proof, gives the saddle point inequality\nsup P I(P,Q\u2217) \u2264 log(m)\u2212H(q(\u00b7 | X = ui)) = I(P \u2217, Q\u2217) \u2264 inf Q I(P \u2217, Q),\nas claimed.\nRemarks In the proof of the theorem, we have defined Q\u2217(\u00b7 | x) as a conditional distribution only for x \u2208 Ext(C), the extreme points of C. This can easily be remedied: take Q\u2217(\u00b7 | x) to be the distribution maximizing the entropy H(Z | X = x) for each x \u2208 C under the constraint that the support of Z be contained in Ext(D). This is equivalent to\u2014for each x \u2208 C\u2014choosing Z = zi for zi \u2208 Ext(D), i = 1, . . . ,m, with probability qi, where q \u2208 Rm solves the entropy maximization problem\nmaximize q\u2208Rm\n\u2212 \u2211\ni\nqi log qi subject to \u2211\ni\nziqi = x, \u2211\ni\nqi = 1, qi \u2265 0.\nInspecting the proof of Theorem 6 (see the bound (53)) shows that this choice can only decrease the mutual information I(X;Z). Additionally, the strong convexity of the entropy over the simplex guarantees that the solutions to this optimization problem are continuous in x (see Chapter X of Hiriart-Urruty and Lemare\u0301chal [26]) so this distribution q(\u00b7 | x) defines a measurable random variable as desired.\nE.2 Proof of Proposition 1\nBy scaling, we may assume w.l.o.g. that L = 1 and M \u2265 1. Using Theorem 6 (and the remarks immediately following its proof), we can focus on maximizing the entropy of the random variable Z conditional on X = x for each fixed x \u2208 [\u22121, 1]d. Let Zi denote the ith coordinate of the random vector Z; we take the conditional distribution of Zi to be independent of Zj and let Z be distributed as\nZi | X = { M w.p. 12 + Xi 2M\n\u2212M w.p. 12 \u2212 Xi 2M .\n(56)\nLet us now verify that the distribution (56) maximizes the entropy H(Z | X = x). Indeed, we may fix x (leaving it implicit in the vector [q(z)]z := [q(z | x)]z), and we solve the entropy maximization problem\nminimize q\n\u2212H(q) subject to \u2211\nz\nq(z) = 1, q(z) \u2265 0, \u2211\nz\nzq(z) = x, (57)\nwhere all sums are taken over z \u2208 Ext([\u2212M,M ]d) = {\u2212M,M}d. Introducing the Lagrange multipliers \u00b5 \u2208 Rd, \u03bb(z) \u2265 0, and \u03b8 \u2208 R, we find that problem (57) has the Lagrangian\nL(q, \u00b5, \u03bb, \u03b8) = \u2212H(q)\u2212 \u2211\nz\n\u03bb(z)q(z) + \u00b5\u22a4 (\u2211\nz\nzq(z)\u2212 x ) + \u03b8 (\u2211\nz\nq(z)\u2212 1 ) .\nTo find the infimum of the Lagrangian with respect to q, we take derivatives (since we make the identification q \u2208 R2d). We see that\n\u2202\n\u2202q(z) L(q, \u00b5, \u03bb, \u03b8) = log(q(z)) + 1\u2212 \u03bb(z) + \u03b8 + \u00b5\u22a4z.\nWith the definition (56) of the probability mass function q (that zi are independent Bernoulli random variables with parameters 12 + xi/2M), the coordinate conditional distributions are\nq(zi | xi) = ( 1\n2 +\n1\n2M\n) 1 2 + xizi 2M ( 1\n2 \u2212 1 2M\n) 1 2 \u2212 xizi 2M\n.\nTheorem 6 says that without loss of generality we may assume that x \u2208 {\u22121, 1}d, the full probability mass function q can be written\nq(z) =\n( 1\n2 +\n1\n2M\n) d 2 +x \u22a4z 2M ( 1\n2 \u2212 1 2M\n) d 2 \u2212x \u22a4z 2M\n. (58)\nPlugging the conditional (58) results in\n\u2202\n\u2202q(z) L(q, \u00b5, \u03bb, \u03b8)\n=\n( d\n2 +\nx\u22a4z\n2M\n) log ( 1\n2 +\n1\n2M\n) + ( d\n2 \u2212 x\n\u22a4z\n2M\n) log ( 1\n2 \u2212 1 2M\n) + 1\u2212 \u03bb(z) + \u03b8 + \u00b5\u22a4z\n= d\n2\n[ log ( 1\n2 +\n1\n2M\n) + log ( 1\n2 \u2212 1 2M\n)] + x\u22a4z\n2M\n[ log ( 1\n2 +\n1\n2M\n) \u2212 log ( 1\n2 \u2212 1 2M\n)]\n+ 1\u2212 \u03bb(z) + \u03b8 + \u00b5\u22a4z.\nPerforming a few algebraic manipulations with the logarithmic terms, the final equality becomes\nd log\n(\u221a (M + 1)(M \u2212 1)\nM\n) + x\u22a4z\nM log\n(\u221a M + 1\nM \u2212 1\n) + 1\u2212 \u03bb(z) + \u03b8 + \u00b5\u22a4z.\nThe complementarity conditions for optimality [6] imply that \u03bb(z) = 0, and since the equality constraints in the problem (57) are satisfied, we can choose \u03b8 and \u00b5 arbitrarily. Taking\n\u03b8 = \u2212d log (\u221a\n(M + 1)(M \u2212 1) M\n) \u2212 1 and \u00b5 = \u2212x 1\nM log\n(\u221a M + 1\nM \u2212 1\n)\nyields that the partial derivatives of L are 0, which shows that indeed our choice of Q\u2217 is optimal.\nE.3 Proof of Proposition 2\nThe proof follows along lines similar to the \u2113\u221e case: we compute the maximum entropy distribution subject to the constraint that E[Z] = x for some x \u2208 Rd with \u2016x\u20161 \u2264 1, and Z must be supported on the extreme points \u00b1Mei of the \u21131-ball of radius M . (Recall that ei \u2208 Rd are the standard basis vectors.) Based on Theorem 6, in order to find the minimax mutual information, we need only consider the cases where x = \u00b1ei for some i \u2208 {1, . . . , d}.\nFollowing this plan, we recall the entropy maximization problem (57), where now x = \u00b1ei and the sums are over z \u2208 M{\u00b1ei}di=1. As in the proof of Proposition 1, we can write the Lagrangian and take its derivatives, finding that for z = \u00b1Mei we have\n\u2202\n\u2202q(z) L(q, \u00b5, \u03bb, \u03b8) = log(q(z)) + 1\u2212 \u03bb(z) + \u03b8 \u2212 \u00b5\u22a4z.\nSolving for q(z), we find that\nq(z) = exp(\u03bb(z)\u2212 1\u2212 \u03b8) exp(\u00b5\u22a4z),\nbut complementarity [6] guarantees that \u03bb(z) = 0 since q(z) > 0, and normalizing we may write q(z) = exp(\u2212\u00b5\u22a4z)/ exp(\u2212\u00b5\u22a4\u2211z\u2032 z\u2032), where the sum is over the extreme points of the \u21131-ball of radius M . In particular, q(Mei) \u221d e\u2212\u00b5i and q(\u2212Mei) \u221d e\u00b5i . Without loss of generality, let x = ei. Symmetry suggests we take (and we verify this to be true)\nq(z) = exp(\u22121\u2212 \u03b8)    exp(\u00b5i) if z = Mei\nexp(\u2212\u00b5i) if z = \u2212Mei exp(0) otherwise.\n(59)\nIndeed, with the choice (59) of q, we have q(Mej)\u2212 q(\u2212Mej) = 0 for j 6= i, while (setting \u03b3 = \u00b5i and normalizing appropriately)\nq(Mei)\u2212 q(\u2212Mei) = e\u03b3 e\u2212\u03b3 + e\u03b3 + 2(d \u2212 1) \u2212 e\u2212\u03b3 e\u2212\u03b3 + e\u03b3 + 2(d \u2212 1) .\nThus, if we can solve the equation Mq(Mei) \u2212 Mq(\u2212Mei) = 1, we will be nearly done. To that end, we write\ne\u03b3 \u2212 e\u2212\u03b3 e\u03b3 + e\u2212\u03b3 + 2(d\u2212 1) = 1 M or \u03b2 \u2212 \u03b2\u22121 = 1 M ( \u03b2 + \u03b2\u22121 + 2(d\u2212 1) ) ,\nwhere we identified \u03b2 = e\u03b3 . Multiplying both sides by \u03b2, we have a quadratic equation in \u03b2:\n\u03b22 \u2212 1 = 1 M\n( \u03b22 + 2\u03b2(d\u2212 1) + 1 ) or (M \u2212 1)\u03b22 \u2212 2(d\u2212 1)\u03b2 \u2212 (M + 1) = 0,\nwhose solution is the positive root of\n\u03b2 = 2d\u2212 2\u00b1 \u221a (2d \u2212 2)2 + 4(M2 \u2212 1) 2(M \u2212 1) or \u03b3 = log ( 2d\u2212 2 + \u221a (2d \u2212 2)2 + 4(M2 \u2212 1) 2(M \u2212 1) ) .\nBy our construction, with \u03b3 so defined, we satisfy the constraints that M [q(Mei)\u2212 q(\u2212Mei)] = 1 and q(Mej) \u2212 q(\u2212Mej) = 0 for j 6= i. Since q belongs to the exponential family and satisfies the constraints, it maximizes the entropy H(Z) as desired [8].\nAlgebraic manipulations and the computation of the conditional entropy H(Z | X = ei) give the remainder of the statement of the proposition.\nE.4 Proof of Proposition 3\nThe outline of the proof of Proposition 3 is as follows. Lemma 16 implies that any distribution satisfying optimal local differential privacy must be supported on the extreme points of the outer set D (as in the proof of Theorem 6). Given this result, we reduce the problem of finding an optimally private distribution to a linear program, using symmetry arguments to simplify the LP. Finally, we show that the solution to the linear program is unique, which means that we have found the unique distribution satisfying optimal local differential privacy.\nWe begin by developing a reduction of the problem of finding a distribution with optimal local differential privacy to a linear program. Note that there is a non-increasing mapping between M\u2014 the radius of the larger \u2113\u221e ball\u2014and \u03b1 \u22c6. Indeed, whenever M increases, the set of distributions\nQ from which to choose a privacy channel increases, so \u03b1\u22c6 decreases. Put inversely, for a given differential privacy level \u03b1, we can find the smallest M such that it is possible to construct an \u03b1-differentially private channel Q mapping from [\u22121, 1]d to [\u2212M,M ]d. (Lemma 19 shows that the mapping from M to \u03b1\u22c6 is implicitly invertible.)\nThus, rather than solving for \u03b1 as a function of M , we take the converse view of finding the largest M such that an \u03b1-differentially private distribution exists. Fix d \u2208 N and (with some abuse of notation) let Z \u2208 {\u22121, 1}d\u00d72d be the matrix whose columns are the edges of the hypercube {\u22121, 1}d. For each z, x \u2208 {\u22121, 1}d, define the variables q(z | x) \u2265 0 to represent the conditional probability of observing Mz given x. Let q(\u00b7 | x) = [q(z | x)]z\u2208{\u22121,1}d denote the vector version of q(z | x). Then we have that a \u03b1-differentially private channel providing an unbiased perturbtation of vectors in [\u22121, 1]d to [\u2212M,M ]d, exists only if we can find settings of q(z | x) such that\nZq(\u00b7 | x)\u2212 1 M x = 0 for all x \u2208 {\u22121, 1}d\nwhile additionally q(z | x) \u2264 e\u03b1q(z | x\u2032) and \u2211z q(z | x) = 1, q(z | x) \u2265 0 for all z, x, x\u2032. Thus, if we make the change of variables t = 1/M , we see that finding the smallest possible M\u2014which corresponds to the least perturbation possible for a given privacy level \u03b1\u2014can be cast as solving the linear program\nminimize \u2212 t (60) subject to Zq(\u00b7 | x)\u2212 tx = 0 for all x \u2208 {\u22121, 1}d\nq(z | x) \u2264 e\u03b1q(z | x\u2032) for all x, x\u2032, z \u2208 {\u22121, 1}d \u2211\nz\nq(z | x) = 1, q(\u00b7 | x) 0 for all x \u2208 {\u22121, 1}d.\nThe solution vectors q(\u00b7 | x), x \u2208 {\u22121, 1}d, give the probability mass function for an \u03b1-differentially private channel perturbing from [\u22121, 1]d to [\u2212M,M ]d, where M = 1/t\u2217 and t\u2217 denotes the solution to the LP. This p.m.f. is then optimally locally differentially private with \u03b1 = \u03b1\u22c6([\u22121, 1]d, [\u2212M,M ]d).\nIt is possible to calculate the solution of the LP (60) by hand, but it is tedious. We thus use the structure of optimal local differential privacy to reduce the problem to a single minimization problem over a vector q \u2208 R2d (rather than a matrix [q(z | x)] \u2208 R2d\u00d72d). We have\nLemma 18. A distribution satisfying optimal local differential privacy must, for each x \u2208 {\u22121, 1}d, satisfy q(\u00b7 | x) = \u03a0(x)q, where \u03a0(x) \u2208 {0, 1}2d\u00d72d is a permutation matrix and q is a fixed vector.\nProof Suppose for the sake of contradiction that this is not the case, but the vectors q(x) and t solve the linear program (60). Let Q1 denote the matrix of the vectors q(\u00b7 | x). Choose vectors q(\u00b7 | x) and q(\u00b7 | x\u2032) such that q(\u00b7 | x) 6= \u03a0q(\u00b7 | x\u2032) for any permutation matrix \u03a0. Now construct vectors q2(\u00b7 | x) and q2(\u00b7 | x\u2032) such that q2(z | x) = q(z\u2032 | x\u2032), where z\u2032 is chosen so that z\u2032ix\u2032i = zixi, and similarly choose q2 so that q2(z | x\u2032) = q(z\u2032 | x), where zix\u2032i = z\u2032ixi. Let Q2 denote the matrix of vectors q, but where q2(\u00b7 | x) and q2(\u00b7 | x\u2032) replace q(\u00b7 | x), q(\u00b7 | x\u2032). Then by construction, all the constraints of the original linear program (60) are satisfied. By symmetry and the strict convexity of the mutual information in the channel distribution Q, however, we see that\nI(P,Q1) = I(P,Q2) = 1\n2 (I(P,Q1) + I(P,Q2)) > I\n( P, 1\n2 (Q1 +Q2)\n) .\nThe decrease in mutual information gives the necessary contradiction.\nWith Lemma 18 in hand, we can now turn to the smaller linear program\u2014in a single vector q and for a single vector x \u2208 {\u22121, 1}d\u2014that will give us the locally optimal differentially private channel. Indeed, we consider the linear program in the variables t \u2208 R and q \u2208 R2d , where we let q(z) denote the entry of q corresponding to column z of Z:\nminimize \u2212 t subject to Zq \u2212 tx = 0, q(z) \u2264 e\u03b1q(z\u2032) for all z, z\u2032, \u2211\nz\nq(z) = 1, q \u2265 0. (61)\nDefine the constants\nKd =\n\u230ad/2\u230b\u2211\ni=0\n(d\u2212 2i) ( d\ni\n) and Cd = card { z \u2208 {\u22121, 1}d : z\u22a4x > 0 } = { 2d\u22121 if d odd\n2d\u22121 \u2212 12 ( d d/2 ) if d even.\nWe have the following lemma, which characterizes the structure of the solution vector q.\nLemma 19. Define \u03b1\u2217 = log Kd+2 d\u2212Cd\nKd\u2212Cd . For any \u03b1 < \u03b1\u2217, the unique solution to the linear pro-\ngram (61) is given by\nq(z) =\n{ e\u03b1\ne\u03b1Cd+2d\u2212Cd if \u3008z, x\u3009 > 0 1 e\u03b1Cd+2d\u2212Cd otherwise.\nProof First, problem (61) is clearly equivalent to the linear program\nminimize \u2212 t subject to Zq \u2212 tx = 0, max\nz {q(z)} + e\u03b1 max z {\u2212q(z)} \u2264 0,\n\u2211\nz\nq(z) = 1, q \u2265 0. (62)\nOur proof proceeds in two large steps: first, we argue that a q of the form specified in the lemma is indeed the solution to the problem (62), then we use results on uniqueness of solutions to linear programs due to Mangasarian [35].\nFor the first step, we begin by writing the Lagrangian to the problem (62). We introduce dual variables \u03b8 \u2208 R2d for the constraint Zq \u2212 tx = 0, \u03bb \u2265 0 for the first inequality, \u03c4 \u2208 R for the sum constraint, and \u03b2 \u2208 R2d+ for the non-negativity of q. With this, we have Lagrangian\nL(q, t, \u03b8, \u03bb, \u03c4, \u03b2) = \u2212t+\u03b8\u22a4 ( \u2211\nz\nq(z)\u2212 tx ) +\u03bbmax\nz {q(z)}+e\u03b1 max z {\u2212q(z)}+\u03c4(1\u22a4q\u22121)\u2212\u03b2\u22a4q. (63)\nRecall the generalized subgradient KKT conditions for optimality of the solution to an optimization problem [26, Chapter VII]. A vector q > 0 is optimal for the problem (62) if the constraints maxi{qi} \u2264 e\u03b1 mini{qi} and \u2211 i qi = 1 hold, there is a t \u2265 0 such that Zq\u2212 tx = 0, and we can find \u03b8, \u03bb, and \u03c4 such that\nZ\u22a4\u03b8 + \u03bb [v+ \u2212 e\u03b1v\u2212] + \u03c41 = 0, \u03b2 = 0, and \u03b8\u22a4x = \u22121, (64)\nwhere v+ and v\u2212 are vectors satisfying\nv+ \u2208 Conv { ei : qi = max\nj {qj}\n} and v\u2212 \u2208 Conv { ei : qi = min\nj {qj}\n} .\nThat \u03b2 = 0 follows by complementarity (recall that q > 0 is assumed). If we can find settings for the vectors \u03b8, \u03bb, \u03c4, and v\u00b1 satisfying the KKT conditions (64), we are done. To that end, set \u03b8 = \u2212x/d. Then by inspection \u03b8\u22a4x = \u2212\u2016x\u201622 /d = \u22121, and we can rewrite the remaining KKT condition by noting that we must find vectors v+, v\u2212, and \u03c4 \u2208 R such that\n\u2212 1 d Z\u22a4x+ v+ \u2212 e\u03b1v\u2212 + \u03c41 = 0, v\u22a4+1 = v\u22a4\u22121, v+ \u2265 0, v\u2212 \u2265 0,\nv+(z) = 0 if q(z) < max z {q(z)}, and v\u2212(z) = 0 if q(z) > min z\n{q(z)}. (65)\nNote that we have eliminated \u03bb as it is a non-negative homogeneous scaling term on v+ and v\u2212. We choose values q+, q\u2212 with 0 < q\u2212 < q+ and set q(z) = q+ when z\u22a4x > 0 and q(z) = q\u2212 when z\u22a4x \u2264 0, where q+, q\u2212 are chosen so that \u2211z q(z) = 1. We now choose the values of v+, v\u2212, and \u03c4 satisfying the KKT conditions in expression (65) based on the values q+, q\u2212. Indeed, set\nv+(z) =\n{ z\u22a4x d \u2212 \u03c4 if z\u22a4x > 0\n0 otherwise and v\u2212(z) = { \u2212e\u2212\u03b1 z\u22a4xd + e\u2212\u03b1\u03c4 if z\u22a4x \u2264 0 0 otherwise\n(66)\nBy inspection, we see that \u2212Z\u22a4x/d+ v+\u2212 e\u03b1v\u2212+ \u03c4 = 0, so the only question remaining is whether we can choose \u03c4 such that v\u00b1 \u2265 0 and v\u22a4+1 = v\u22a4\u22121.\nTo that end, we recall the definition of the constant Kd, and we seek \u03c4 such that\n\u2211\nz\nv+(z) = 1\nd Kd \u2212 \u03c4Cd = e\u2212\u03b1\n1 d Kd + e\n\u2212\u03b1\u03c4(2d \u2212 Cd) = \u2211\nz\nv\u2212(z)\nby the symmetry in the sums. Rewriting the equation, we find that for equality we must have\n\u03c4 ( e\u2212\u03b1(2d \u2212 Cd) + Cd ) = 1\nd Kd(1\u2212 e\u2212\u03b1) or \u03c4 = Kd d \u00b7 e \u03b1 \u2212 1 e\u03b1Cd + 2d \u2212 Cd = Kd dCd \u00b7 e \u03b1 \u2212 1 e\u03b1 + 2d/Cd \u2212 1 .\nThus we find that if \u03b1 is such that\nKd dCd e\u03b1 \u2212 1 e\u03b1 + 2d/Cd \u2212 1 < 1 d , (67)\nthen by our choice (66) of the vectors v+ and v\u2212, we have v+(z) > 0 whenever z \u22a4x > 0, and v\u2212(z) > 0 whenever z \u22a4x \u2264 0. Noting that by our setting of q(z), we have by symmetry of Z that there exists a t > 0 such that Zq = tx, we find that our choice of q is optimal (since the KKT conditions (65) hold).\nWe have two arguments remaining in the proof. The first is to show that for \u03b1 < \u03b1\u2217 defined in the statement of the lemma, the inequality (67) holds. Rewriting the inequality, we solve\ne\u03b1 \u2212 1 = Cd Kd\n( e\u03b1 + 2d/Cd \u2212 1 ) or e\u03b1 ( 1\u2212 Cd\nKd\n) =\n2d \u2212 Cd Kd + 1, i.e. \u03b1\u2217 = log Kd + 2 d \u2212 Cd Kd \u2212 Cd .\nFor any \u03b1 < \u03b1\u2217, the strict inequality (67) holds, so the setting (66) of v+ and v\u2212 satisfy the KKT conditions.\nOur last argument regards the uniqueness of the two-valued solution vector q. For that, we apply Mangasarian\u2019s result [35, Theorem 1] that if there exists an \u01eb > 0 such that for any vector u \u2208 R2d with \u2016u\u20162 = 1, q is a solution of the linear program (61) when the objective is \u2212t+ \u01ebu\u22a4q, then q is unique. Luckily, this is not difficult given our previous work. The Lagrangian (63) for the modified linear program becomes\n\u01ebu\u22a4q \u2212 t+ \u03b8\u22a4 ( \u2211\nz\nq(z)\u2212 tx )\n+ \u03bbmax z {q(z)} + e\u03b1 max z {\u2212q(z)} + \u03c4(1\u22a4q \u2212 1)\u2212 \u03b2\u22a4q.\nThe only modification in our KKT conditions (64) is that the first equality becomes\n\u01ebu+ Z\u22a4\u03b8 + \u03bb [v+ \u2212 e\u03b1v\u2212] + \u03c41 = 0.\nBy the strictness of the inequalities v+(z) > 0 for z such that z \u22a4x > 0 (and similarly for v\u2212) in the definitions (66) whenever \u03b1 < \u03b1\u2217, we see that for suitably small \u01eb > 0, the vectors v+ and v\u2212 can be perturbed so that the KKT conditions are still satisfied. This proves the uniqueness of the two-valued solution vector q.\nRemarks Following an argument with completely the same structure as the proof, we see that for any d \u2208 N (say d \u2265 3), there are different \u201cregimes\u201d of \u03b1, that is, there exists a sequence \u03b1\u22170, \u03b1 \u2217 2, . . . , \u03b1 \u2217 d\u22121 (or \u03b1 \u2217 d\u22122 if d is even) such that for \u03b1 \u2208 (\u03b1\u22172i, \u03b1\u22172i+2), the unique optimal solution to the linear program (61) is given by taking\nq(z) \u221d { exp(\u03b1) for z s.t. \u3008z, x\u3009 > 2(i+ 1) 1 for z s.t. \u3008z, x\u3009 \u2264 2(i+ 1)\n(for \u03b1 < \u03b1\u22170, we say i = \u22121 above). For \u03b1 = \u03b1\u22172i, the set of solutions is given by the convex combinations of the solution vectors\nq<(z) \u221d { exp(\u03b1) for z s.t. \u3008z, x\u3009 > 2i 1 for z s.t. \u3008z, x\u3009 \u2264 2i and q>(z) \u221d { exp(\u03b1) for z s.t. \u3008z, x\u3009 > 2(i+ 1) 1 for z s.t. \u3008z, x\u3009 \u2264 2(i+ 1),\nwhich follows from arguments similar to our application of Mangasarian\u2019s results [35]. Now we may complete the proof of Proposition 3. Indeed, we see from Lemma 19 that the distribution satisfying optimal local differential privacy must assign probability masses at two levels\u2014at least when the point being perturbed comes from {\u22121, 1}d. Now let Q be a distribution specified in the lemma. An argument identical to that in our proof of Proposition 1\u2014by symmetry\u2014 shows that the distribution P maximizing the mutual information I(P,Q) is uniform on {\u22121, 1}d. The uniqueness of Q then follows from Lemmas 18 and 19, which show that such Q is the only distribution that minimizes the radius M of the ball [\u2212M,M ]d; inverting this bound gives the proposition.\nE.5 Proof of Corollary 4\nBy scaling, we may assume that M \u2265 L = 1 in the proof of the corollary. First, we claim that as \u03b3 \u2192 0, the following expansion holds:\nlog(2d)\u2212log ( e\u03b3 + e\u2212\u03b3 + 2d\u2212 2 ) +\u03b3\ne\u03b3 e\u03b3 + e\u2212\u03b3 + 2d\u2212 2\u2212\u03b3 e\u2212\u03b3 e\u03b3 + e\u2212\u03b3 + 2d\u2212 2 = \u03b32 2d +\u0398\n( \u03b34\nd\n) . (68)\nBefore proving this, we use the expansion (68) to prove Corollary 4. Noting that\n2d\u2212 2 + \u221a\n(2d\u2212 2)2 + 4(M2 \u2212 1) 2(M \u2212 1) =\n\u221a M + 1\nM \u2212 1 + d\u2212 1 M \u2212 1 + \u0398(d 2/M2),\nwe see that since log(1 + x) = x \u2212 x2/2 + \u0398(x3), we have \u03b3 = dM + \u0398 ( d2 M2 ) . Thus the mutual information in Proposition 2 is\nI(P \u2217, Q\u2217) = log2(\n\u221a (M + 1)/(M \u2212 1) + d/M +\u0398(d2/M2))\n2d +\u0398\n( log4(1 + d/M)\nd\n)\n= d\n2M2 +\u0398\n( min { d3\nM4 , log4(d) d\n}) .\nNow we return to showing the claim (68). Indeed, define f(\u03b3) = log(e\u03b3 + e\u2212\u03b3 +2d\u2212 2). Letting f (i) denote the ith derivative of f , we have\nf (1)(\u03b3) = e\u03b3 \u2212 e\u2212\u03b3\ne\u03b3 + e\u2212\u03b3 + 2d\u2212 2 , f (2)(\u03b3) = (e\u03b3 + e\u2212\u03b3)(2d \u2212 2) + 4 (e\u03b3 + e\u2212\u03b3 + 2d\u2212 2)2 ,\nand\nf (3)(\u03b3) = \u2212(e2\u03b3 \u2212 e\u22122\u03b3)(2d \u2212 2)\u2212 8(e\u03b3 \u2212 e\u2212\u03b3) + (2d\u2212 2)2(e\u03b3 \u2212 e\u2212\u03b3)\n(e\u03b3 + e\u2212\u03b3 + 2d\u2212 2)3 .\nVia a Taylor expansion, we have f(0) = f(\u03b3)\u2212 \u03b3f (1)(\u03b3) + \u03b322 f (2)(\u03b3) +O(f (3)(\u03b3)\u03b33), and so substituting values for f(\u03b3) and f (1)(\u03b3), we have\nlog(2d) \u2212 log ( e\u03b3 + e\u2212\u03b3 + 2d\u2212 2 ) + \u03b3\ne\u03b3 e\u03b3 + e\u2212\u03b3 + 2d\u2212 2 \u2212 \u03b3 e\u2212\u03b3 e\u03b3 + e\u2212\u03b3 + 2d\u2212 2\n= (e\u03b3 + e\u2212\u03b3)(2d \u2212 2) + 4 (e\u03b3 + e\u2212\u03b3 + 2d\u2212 2)2 \u00b7 \u03b32 2 +O\n( f (3)(\u03b3)\u03b33 ) .\nA few simpler Taylor expansions yield that f (3)(\u03b3) = O(\u03b3/d), which means that all we have left to tackle is f (2)(\u03b3). But noting that\n2 ( e\u03b3 + e\u2212\u03b3 ) = 4 ( 1 + \u03b32\n2! +\n\u03b34 4! + \u00b7 \u00b7 \u00b7\n) = 4 +O(\u03b32)\nimplies that f (2)(\u03b3) = (4d+O(d\u03b32))/4d2, and hence (\u03b32/2)f (2)(\u03b3) = \u03b32/2d+O(\u03b34/d), which yields the result."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "<lb>We study statistical risk minimization problems under a privacy model in which the data<lb>is kept confidential even from the learner. In this local privacy framework, we establish sharp<lb>upper and lower bounds on the convergence rates of statistical estimation procedures. As a<lb>consequence, we exhibit a precise tradeoff between the amount of privacy the data preserves and<lb>the utility, as measured by convergence rate, of any statistical estimator or learning procedure.", "creator": "LaTeX with hyperref package"}}}