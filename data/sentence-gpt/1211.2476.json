{"id": "1211.2476", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2012", "title": "Random Utility Theory for Social Choice", "abstract": "Random utility theory models an agent's preferences on alternatives by drawing a real-valued score on each alternative (typically independently) from a parameterized distribution, and then ranking the alternatives according to scores. A special case that has received significant attention is the Plackett-Luce model, for which fast inference methods for maximum likelihood estimators are available. This paper develops conditions on general random utility models that enable fast inference within a Bayesian framework through MC-EM, providing concave loglikelihood functions and bounded sets of global maxima solutions. Results on both real-world and simulated data provide support for the scalability of the approach and capability for model selection among general random utility models including Plackett-Luce. We present an extended dataset that includes a variety of sample sizes and methods, as well as models that provide a variety of utility models for the general model selection. These methods are presented in a paper and should not be considered in any way in general paper.", "histories": [["v1", "Sun, 11 Nov 2012 23:09:02 GMT  (2140kb,D)", "http://arxiv.org/abs/1211.2476v1", null]], "reviews": [], "SUBJECTS": "cs.MA cs.LG stat.ML", "authors": ["hossein azari soufiani", "david c parkes", "lirong xia"], "accepted": true, "id": "1211.2476"}, "pdf": {"name": "1211.2476.pdf", "metadata": {"source": "CRF", "title": "Random Utility Theory for Social Choice", "authors": ["Hossein Azari Soufiani", "David C. Parkes", "Lirong Xia"], "emails": ["azari@fas.harvard.edu", "parkes@eecs.harvard.edu", "lxia@seas.harvard.edu"], "sections": [{"heading": null, "text": "Random utility theory models an agent\u2019s preferences on alternatives by drawing a real-valued score on each alternative (typically independently) from a parameterized distribution, and then ranking the alternatives according to scores. A special case that has received significant attention is the Plackett-Luce model, for which fast inference methods for maximum likelihood estimators are available. This paper develops conditions on general random utility models that enable fast inference within a Bayesian framework through MC-EM, providing concave loglikelihood functions and bounded sets of global maxima solutions. Results on both real-world and simulated data provide support for the scalability of the approach and capability for model selection among general random utility models including Plackett-Luce."}, {"heading": "1 Introduction", "text": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years. In part, this is due to the explosion of socio-economic platforms, where opinions of users need to be aggregated; e.g., judges in crowd-sourcing contests, ranking of movies or user-generated content.\nIn the problem of social choice, users submit ordinal preferences consisting of partial or total ranks on the alternatives and a single rank order must be selected to be representative of the reports. Since Condorcet [6], one approach to this problem is to formulate social choice as the problem of estimating a true underlying world state (e.g., a true quality ranking of alternatives), where the individual reports are viewed as noisy data in regard to the true state. In this way, social choice can be framed as a problem of inference.\nIn particular, Condorcet assumed the existence of a true ranking over alternatives, with a voter\u2019s preference between any pair of alternatives a, b generated to agree with the true ranking with probability p > 1/2 and disagree otherwise. Condorcet proposed to choose as the outcome of social choice the ranking that maximizes the likelihood of observing the voters\u2019 preferences. Later, Kemeny\u2019s rule was shown to provide the maximum likelihood estimator (MLE) for this model [32].\nBut Condorcet\u2019s probabilistic model assumes identical and independent distributions on pairwise comparisons. This ignores the strength in agents\u2019 preferences (the same probability p is adopted for all pairwise comparisons), and allows for cyclic preferences. In addition, computing the winner through the Kemeny rule is \u0398P2 -complete [13].\nTo overcome the first criticism, a more recent literature adopts the random utility model (RUM) from economics [26]. Consider C = {c1, .., cm} alternatives. In RUM, there is a ground truth utility (or score) associated with each alternative. These are real-valued parameters, denoted by ~\u03b8 = (\u03b81, . . . , \u03b8m). Given this, an agent independently samples a random utility (Xj) for each alternative cj with conditional distribution \u00b5j(\u00b7|\u03b8j).\nar X\niv :1\n21 1.\n24 76\nv1 [\ncs .M\nA ]\n1 1\nN ov\n2 01\nUsually \u03b8j is the mean of \u00b5j(\u00b7|\u03b8j).1 Let \u03c0 denote a permutation of {1, . . . ,m}, which naturally corresponds to a linear order: [c\u03c0(1) c\u03c0(2) \u00b7 \u00b7 \u00b7 c\u03c0(m)]. Slightly abusing notation, we also use \u03c0 to denote this linear order. Random utility (X1, . . . , Xm) generates a distribution on preference orders, as\nPr(\u03c0 | ~\u03b8) = Pr(X\u03c0(1) > X\u03c0(2) > . . . > X\u03c0(m)) (1)\nThe generative process is illustrated in Figure 1.\nAdopting RUMs rules out cyclic preferences, because each agent\u2019s outcome corresponds to an order on real numbers, and it also captures the strength of preference, and thus overcomes the second criticism, by assigning a different parameter (\u03b8j) to each alternative.\nA popular RUM is Plackett-Luce (P-L) [18, 21], where the random utility terms are generated according to Gumbel distributions with fixed shape parameter [2,31]. For P-L, the likelihood function has a simple analytical solution, making MLE inference tractable. P-L has been extensively applied in econometrics [1, 19], and more recently in machine learning and information retrieval (see [16] for an overview). Efficient methods of EM inference [5, 14], and more recently expectation propagation [12], have been developed for P-L and its variants.\nIn application to social choice, the P-L model has been used to analyze political elections [10]. EM algorithm has also been used to learn the Mallows model, which is closely related to the Condorcet\u2019s probabilistic model [17].\nAlthough P-L overcomes the two difficulties of the Condorcet-Kemeny approach, it is still quite restricted, by assuming that the random utility terms are distributed as Gumbel, with each alternative is characterized by one parameter, which is the mean of its corresponding distribution. In fact, little is known about inference in RUMs beyond P-L. Specifically, we are not aware of either an analytical solution or an efficient algorithm for MLE inference for one of the most natural models proposed by Thurstone [26], where each Xj is normally distributed."}, {"heading": "1.1 Our Contributions", "text": "In this paper we focus on RUMs in which the random utilities are independently generated with respect to distributions in the exponential family (EF) [20]. This extends the P-L model, since the Gumbel distribution with fixed shape parameters belonging to the EF. Our main theoretical contributions are Theorem 1 and Theorem 2, which propose conditions such that the log-likelihood function is concave and the set of global maxima solutions is bounded for the location family, which are RUMs where the shape of each distribution \u00b5j is fixed and the only latent variables are the locations, i.e., the means of \u00b5j\u2019s. These results hold for existing special cases, such as the P-L model, and many other RUMs, for example the ones where each \u00b5j is chosen from Normal, Gumbel, Laplace and Cauchy.\n1\u00b5j(\u00b7|\u03b8j) might be parameterized by other parameters, for example variance.\nWe also propose a novel application of MC-EM. We treat the random utilities ( ~X) as latent variables, and adopt the Expectation Maximization (EM) method to estimate parameters ~\u03b8. The E-step for this problem is not analytically tractable, and for this we adopt a Monte Carlo approximation. We establish through experiments that the Monte-Carlo error in the E-step is controllable and does not affect inference, as long as numerical parameterizations are chosen carefully. In addition, for the Estep we suggest a parallelization over the agents and alternatives and a Rao-Blackwellized method, which further increases the scalability of our method.\nWe generally assume that the data provides total orders on alternatives from voters, but comment on how to extend the method and theory to the case where the input preferences are partial orders.\nWe evaluate our approach on synthetic data as well as two real-world datasets, a public election dataset and one involving rank preferences on sushi. The experimental results suggest that the approach is scalable despite providing significantly improved modeling flexibility over existing approaches.\nFor the two real-world datasets we have studied, we compare RUMs with normal distributions and P-L in terms of four criteria: log-likelihood, predictive log-likelihood, Akaike information criterion (AIC), and Bayesian information criterion (BIC). We observe that when the amount of data is not too small, RUMs with normal distributions fit better than P-L. Specifically, for the log-likelihood, predictive log-likelihood, and AIC criteria, RUMs with normal distributions outperform P-L with 95% confidence in both datasets."}, {"heading": "2 RUMs and Exponential Families", "text": "In social choice, each agent i \u2208 {1, . . . , n} has a strict preference order on alternatives. This provides the data for an inferential approach to social choice. In particular. let L(C) denote the set of all linear orders on C. Then, a preference-profile, D, is a set of n preference orders, one from each agent, so that D \u2208 L(C)n. A voting rule r is a mapping that assigns to each preference-profile a set of winning rankings, r : L(C)n 7\u2192 (2L(C) \\ \u2205). In particular, in the case of ties the set of winning rankings may include more than a singleton ranking. In the maximum likelihood (MLE) approach to social choice, the preference profile is viewed as data, D = {\u03c01, . . . , \u03c0n}.\nGiven this, the probability (likelihood) of the data given ground truth ~\u03b8 (and for a particular ~\u00b5) is Pr(D | ~\u03b8) = \u220fn i=1 Pr(\u03c0 i | ~\u03b8), where,\nP (\u03c0|~\u03b8)= \u222b \u221e x\u03c0(n)=\u2212\u221e \u222b \u221e x\u03c0(n\u22121)=x\u03c0(n) .. \u222b \u221e x\u03c0(1)=x\u03c0(2) \u00b5\u03c0(n)(x\u03c0(n))..\u00b5\u03c0(1)(x\u03c0(1))dx\u03c0(1)dx\u03c0(2)..dx\u03c0(n) (2)\nThe MLE approach to social choice selects as the winning ranking that which corresponds to the ~\u03b8 that maximizes Pr(D | ~\u03b8). In the case of multiple parameters that maximize the likelihood then the MLE approach returns a set of rankings, one ranking corresponding to each parameterization.\nIn this paper, we focus on probabilistic models where each \u00b5j belongs to the exponential family (EF). The density function for each \u00b5 in EF has the following format:\nPr(X = x) = \u00b5(x) = e\u03b7(\u03b8)T (x)\u2212A(\u03b8)+B(x), (3)\nwhere \u03b7(\u00b7) and A(\u00b7) are functions of \u03b8, B(\u00b7) is a function of x, and T (x) denotes the sufficient statistics for x, which could be multidimensional. Example 1 (Plackett-Luce as an RUM [2]) In the RUM, let \u00b5j\u2019s be Gumbel distributions. That is, for alternative j \u2208 {1, . . . ,m} we have \u00b5j(xj |\u03b8j) = e\u2212(xj\u2212\u03b8j)e\u2212e\n\u2212(xj\u2212\u03b8j) . Then, we have: Pr(\u03c0 | ~\u03bb) = Pr(x\u03c0(1) > x\u03c0(2) > .. > x\u03c0(m)) = \u220fm j=1 \u03bb\u03c0(j)\u2211m j\u2032=j \u03bb\u03c0(j\u2032) , where \u03b7(\u03b8j) = \u03bbj = e\u03b8j , T (xj) = \u2212e\u2212xj , B(xj) = \u2212xj and A(\u03b8j) = \u2212\u03b8j .This gives us the Plackett-Luce model."}, {"heading": "3 Global Optimality and Log-Concavity", "text": "In this section, we provide a condition on distributions that guarantees that the likelihood function (2) is log-concave in parameters ~\u03b8. We also provide a condition under which the set of MLE solutions\nis bounded when any one latent parameter is fixed. Together, this guarantees the convergence of our MC-EM approach to a global mode with an accurate enough E-step. We focus on the location family, which is a subset of RUMs where the shapes of all \u00b5j\u2019s are fixed, and the only parameters are the means of the distributions. For the location family, we can writeXj = \u03b8j+\u03b6j , whereXj \u223c \u00b5j(\u00b7|\u03b8j) and \u03b6j = Xj \u2212 \u03b8j is a random variable whose mean is 0 and models an agent\u2019s subjective noise. The random variables \u03b6j\u2019s do not need to be identically distributed for all alternatives j; e.g., they can be normal with different fixed variances.\nWe focus on computing solutions (~\u03b8) to maximize the log-likelihood function,\nl(~\u03b8;D) = n\u2211 i=1 log Pr(\u03c0i | ~\u03b8) (4)\nTheorem 1 For the location family, if for every j \u2264 m the probability density function for \u03b6j is log-concave, then l(~\u03b8;D) is concave.\nProof sketch: The theorem is proved by applying the following lemma, which is Theorem 9 in [22].\nLemma 1 Suppose g1(~\u03b8, ~\u03b6), ..., gR(~\u03b8, ~\u03b6) are concave functions in R2m where ~\u03b8 is the vector of m parameters and ~\u03b6 is a vector ofm real numbers that are generated according to a distribution whose pdf is logarithmic concave in Rm. Then the following function is log-concave in Rm.\nLi(~\u03b8,G) = Pr(g1(~\u03b8, ~\u03b6) \u2265 0, ..., gR(~\u03b8, ~\u03b6) \u2265 0), ~\u03b8 \u2208 Rm (5)\nTo apply Lemma 1, we define a setGi of function gi\u2019s that is equivalent to an order \u03c0i in the sense of inequalities implied by RUM for \u03c0i and Gi (the joint probability in (5) for Gi to be the same as the probity of \u03c0i in RUM with parameters ~\u03b8). Suppose gir(~\u03b8, ~\u03b6) = \u03b8\u03c0i(r) + \u03b6 i \u03c0i(r)\u2212 \u03b8\u03c0i(r+1)\u2212 \u03b6 i \u03c0i(r+1) for r = 1, ..,m\u2212 1. Then considering that the length of order \u03c0i is R+ 1, we have:\nLi(~\u03b8, \u03c0 i) = Li(~\u03b8,G i) = Pr(gi1( ~\u03b8, ~\u03b6) \u2265 0, ..., giR(~\u03b8, ~\u03b6) \u2265 0), ~\u03b8 \u2208 Rm (6)\nThis is because gir(~\u03b8, ~\u03b6) \u2265 0 is equivalent to that in \u03c0i alternative \u03c0i(r) is preferred to alternative \u03c0i(r + 1) in the RUM sense.\nTo see how this extends to the case where preferences are specified as partial orders, we consider in particular an interpretation where an agent\u2019s report for the ranking of mi alternatives implies that all other alternatives are worse for the agent, in some undefined order. Given this, define gir(~\u03b8, ~\u03b6) = \u03b8\u03c0i(r) + \u03b6 i \u03c0i(r) \u2212 \u03b8\u03c0i(r+1) \u2212 \u03b6 i \u03c0i(r+1) for r = 1, ..,mi \u2212 1 and g i r( ~\u03b8, ~\u03b6) = \u03b8\u03c0i(mi) + \u03b6 i \u03c0i(mi)\n\u2212 \u03b8\u03c0i(r+1) \u2212 \u03b6i\u03c0i(r+1) for r = mi, ..,m \u2212 1. Considering that g i r(\u00b7)s are linear (hence, concave) and using log concavity of the distributions of ~\u03b6i = (\u03b6i1, \u03b6 i 2, .., \u03b6 i m)\u2019s, we can apply Lemma 1 and prove log-concavity of the likelihood function.\nIt is not hard to verify that pdfs for normal and Gumbel are log-concave under reasonable conditions for their parameters, made explicit in the following corollary. Corollary 1 For the location family where each \u03b6j is a normal distribution with mean zero and with fixed variance, or Gumbel distribution with mean zeros and fixed shape parameter, l(~\u03b8;D) is concave. Specifically, the log-likelihood function for P-L is concave.\nThe concavity of log-likelihood of P-L has been proved [9] using a different technique. Using Fact 3.5. in [24], the set of global maxima solutions to the likelihood function, denoted by SD, is convex since the likelihood function is log-concave. However, we also need that SD is bounded, and would further like that it provides one unique order as the estimation for the ground truth.\nFor P-L, Ford, Jr. [9] proposed the following necessary and sufficient condition for the set of global maxima solutions to be bounded (more precisely, unique) when \u2211m j=1 e \u03b8j = 1.\nCondition 1 Given the data D, in every partition of the alternatives C into two nonempty subsets C1 \u222aC2, there exists c1 \u2208 C1 and c2 \u2208 C2 such that there is at least one ranking in D where c1 c2.\nWe next show that Condition 1 is also a necessary and sufficient condition for the set of global maxima solutions SD to be bounded in location families, when we set one of the values \u03b8j to be 0 (w.l.o.g., let \u03b81 = 0). If we do not bound any parameter, then SD is unbounded, because for any ~\u03b8, any D, and any number s \u2208 R, l(~\u03b8;D) = l(~\u03b8 + s;D). Theorem 2 Suppose we fix \u03b81 = 0. Then, the set SD of global maxima solutions to l(\u03b8;D) is bounded if and only if the data D satisfies Condition 1. Proof sketch:\nIf Condition 1 does not hold, then SD is unbounded because the parameters for all alternatives in C1 can be increased simultaneously to improve the log-likelihood. For sufficiency, we first present the following lemma. Lemma 2 If alternative j is preferred to alternative j\u2032 in at least in one ranking then the difference of their mean parameters \u03b8j\u2032 \u2212 \u03b8j is bounded from above (\u2203Q where \u03b8j\u2032 \u2212 \u03b8j < Q) for all the ~\u03b8 that maximize the likelihood function. Proof: Suppose that j j\u2032 in rank i, then for any ~\u03b8 \u2208 Rm:\nLi(~\u03b8, \u03c0 i) = Li(~\u03b8,G i) = Pr(g1(~\u03b8, ~\u03b6) \u2265 0, ..., gR(~\u03b8, ~\u03b6) \u2265 0)\n\u2264Pr(g\u03c0i(r)(~\u03b8, ~\u03b6) \u2265 0, g\u03c0i(r+1)(~\u03b8, ~\u03b6) \u2265 0, . . . , g\u03c0i(r\u2032)(~\u03b8, ~\u03b6) \u2265 0) \u2264 Pr(\u03b6j \u2212 \u03b6j\u2032 \u2265 \u03b8j\u2032 \u2212 \u03b8j), (7) where j = \u03c0i(r) and j\u2032 = \u03c0i(r\u2032).\nLet K = l(~0;D). Since the log-likelihood is always smaller than 0, it follows that for any ~\u03b8 \u2208 SD and any i \u2264 n, Li(~\u03b8;\u03c0i) \u2265 K. Hence, Pr(\u03b6j \u2212 \u03b6j\u2032 \u2265 \u03b8j\u2032 \u2212 \u03b8j) \u2265 K. Therefore, there exists K \u2032 such that \u03b8j\u2032 \u2212 \u03b8j < K \u2032, where K \u2032 depends on the fixed \u03b6j\u2032 and \u03b6j . Now consider a directed graph GD, where the nodes are the alternatives, and there is an edge between cj to cj\u2032 if in at least one ranking cj cj\u2032 . By Condition 1, for any pair j 6= j\u2032, there is a path from cj to cj\u2032 (and conversely, a path from cj\u2032 to cj). To see this, consider building a path between j and j\u2032 by starting from a partition with C1 = {j} and following an edge from j to j1 in the graph where j1 is an alternatives in C2 for which there must be such an edge, by Condition 1. Consider the partition with C1 = {j, j1}, and repeat until an edge can be followed to vertex j\u2032 \u2208 C2. It follows from Lemma 2 that for any ~\u03b8 \u2208 SD we have |\u03b8j \u2212 \u03b8j\u2032 | < Qm, using the telescopic sum of bounded values of the difference of mean parameters along the edges of the path, since the length of the path is no more than m (and tracing the path from j to j\u2032 and j\u2032 to j), meaning that SD is bounded.\nNow that we have the log concavity and bounded property, we need to declare conditions under which the bounded convex space of estimated parameters corresponds to a unique order. The next theorem provides a necessary and sufficient condition for all global maxima to correspond to the same order on alternatives. Suppose that we order the alternatives based on estimated \u03b8\u2019s (meaning that cj is ranked higher than cj\u2032 iff \u03b8j > \u03b8j\u2032 ).\nTheorem 3 The order over parameters is strict and is the same across all ~\u03b8 \u2208 SD if, for all ~\u03b8 \u2208 SD and all alternatives j 6= j\u2032, \u03b8j 6= \u03b8j\u2032 . Proof: Suppose for the sake of contradiction there exist two maxima, ~\u03b8, ~\u03b8\u2217 \u2208 SD and a pair of alternatives j 6= j\u2032 such that \u03b8j > \u03b8j\u2032 and \u03b8\u2217j\u2032 > \u03b8\u2217j . Then, there exists an \u03b1 < 1 such that the jth and j\u2032th components of \u03b1~\u03b8 + (1\u2212 \u03b1)~\u03b8\u2217 are equal, which contradicts the assumption.\nHence, if there is never a tie in the scores in any ~\u03b8 \u2208 SD, then any vector in SD will reveal the unique order."}, {"heading": "4 Monte Carlo EM for Parameter Estimation", "text": "In this section, we propose an MC-EM algorithm for MLE inference for RUMs where every \u00b5j belongs to the EF.2\n2Our algorithm can be naturally extended to compute a maximum a posteriori probability (MAP) estimate, when we have a prior over the parameters ~\u03b8. Still, it seems hard to motivate the imposition of a prior on parameters in many social choice domains.\nThe EM algorithm determines the MLE parameters ~\u03b8 iteratively, and proceeds as follows. In each iteration t + 1, given parameters ~\u03b8t from the previous iteration, the algorithm is composed of an E-step and an M-step. For the E-step, for any given ~\u03b8 = (\u03b81, . . . , \u03b8m), we compute the conditional expectation of the complete-data log-likelihood (latent variables ~x and data D), where the latent variables ~x are distributed according to data D and parameters ~\u03b8t from the last iteration.\nFor the M-step, we optimize ~\u03b8 to maximize the expected log-likelihood computed in the E-step, and use it as the input ~\u03b8t+1 for the next iteration:\nE-Step : Q(~\u03b8, ~\u03b8t) = E ~X\n{ log\nn\u220f i=1\nPr(~xi, \u03c0i | ~\u03b8) | D, ~\u03b8t }\nM-step : ~\u03b8t+1 \u2208 arg max ~\u03b8 Q(~\u03b8, ~\u03b8t)"}, {"heading": "4.1 Monte Carlo E-step by Gibbs sampler", "text": "The E-step can be simplified using (3) as follows:\nE ~X{log n\u220f i=1 Pr(~xi, \u03c0i | ~\u03b8) | D, ~\u03b8t} = E ~X{log n\u220f i=1 Pr(~xi| ~\u03b8) Pr(\u03c0i|~xi) | D, ~\u03b8t}\n= n\u2211 i=1 m\u2211 j=1 EXij{log\u00b5j(x i j |\u03b8j) | \u03c0i, ~\u03b8t} = n\u2211 i=1 m\u2211 j=1 (\u03b7(\u03b8j)EXij{T (x i j) | \u03c0i, ~\u03b8t} \u2212A(\u03b8j) +W,\nwhere W = EXij{B(x i j) | \u03c0i, ~\u03b8t} only depends on ~\u03b8t and D (not on ~\u03b8), which means that it can be treated as a constant in the M-step. Hence, in the E-step we only need to compute Si,t+1j = EXij{T (x i j) | \u03c0i, ~\u03b8t} where T (xij) is the sufficient statistic for the parameter \u03b8j in the model. We are not aware of an analytical solution for EXij{T (x i j) | \u03c0i, ~\u03b8t}. However, we can use a Monte Carlo approximation, which involves sampling ~xi from the distribution Pr(~xi | \u03c0i, ~\u03b8t) using a Gibbs sampler, and then approximates Si,t+1j by 1 N \u2211N k=1 T (x i,k j ) where N is the number of samples in the Gibbs sampler.\nIn each step of our Gibbs sampler for voter i, we randomly choose a position j in \u03c0i and sample xi\u03c0i(j) according to a TruncatedEF distribution Pr(\u00b7| x\u03c0i(\u2212j), ~\u03b8t, \u03c0\ni), where x\u03c0i(\u2212j) = ( x\u03c0i(1), . . . , x\u03c0i(j\u22121), x\u03c0i(j+1), . . . , x\u03c0i(m)). The TruncatedEF is obtained by truncating the tails of \u00b5\u03c0i(j)(\u00b7|\u03b8t\u03c0i(j)) at x\u03c0i(j\u22121) and x\u03c0i(j+1), respectively. For example, a truncated normal distribution is illustrated in Figure 2."}, {"heading": "4.2 M-step", "text": "In the E-step we have (approximately) computed Si,t+1j . In the M-step we compute ~\u03b8 t+1 to maximize \u2211n i=1 \u2211m j=1(\u03b7(\u03b8j)EXij{T (x i j) | \u03c0i, ~\u03b8t} \u2212 A(\u03b8j) + EXij{B(x i j) | \u03c0i, ~\u03b8t}). Equivalently, we\ncompute \u03b8t+1j for each j \u2264 m separately to maximize \u2211n i=1{\u03b7(\u03b8j)EXij{T (x i j) | \u03c0i, ~\u03b8t}\u2212A(\u03b8j)} =\n\u03b7(\u03b8j) \u2211n i=1 S i,t+1 j \u2212 nA(\u03b8j).\nFor the case of the normal distribution with fixed variance, where \u03b7(\u03b8j) = 2\u03b8j and A(\u03b8j) = (\u03b8j)2, we have \u03b8t+1j = 1 n \u2211n i=1 S i,t+1 j . The algorithm is illustrated in Figure 3."}, {"heading": "4.3 Convergence", "text": "In the last section we showed that if the RUM satisfies the premise in Theorem 1 and Theorem 2 the data satisfies Condition 1, then the log-likelihood function is concave, and the set of global maxima solutions is bounded. This guarantee the convergence of MC-EM for an exact E-step.\nIn general, MC-EM methods do not have the uniform convergence property of EM methods. In order to control the error of approximation in the MC-E step we can increase the number of samples with the iterations [28]. However, in our application, we are not concerned with the exact estimation of ~\u03b8, as we are only interested in their orders relative to each-other. Therefore, as long as the approximation error remains relatively small, such that the differences of \u03b8js are much larger than the error, we are safe to stop.\nA known problem with Gibbs sampling is that it can introduce correlation among samples. To address this, we sub-sample the samples to reduce the correlation, and call the ratio of sub-sampling the thinning factor (0 < F \u2264 1). A suitable thinning ratio can be set using empirical results from the sampler.\nWith an approach similar to [3], we can derive a relationship between the variance of error in ~\u03b8t+1 and the Monte-Carlo error in the E-step approximation:\nVar(\u03b8j t+1) =\n1\nn2 n\u2211 i=1 Var(Si,t+1j ) = 1 MNn2 n\u2211 i=1 Var(xij) \u2264 FV MNn , (8)\nwhere N is number of samples in Gibbs sampler, M is the number of samples for RaoBlackwellization, n is number of agents, F is the thinning factor and V = maxj(Varx\u223c\u00b5j (x)), and samples xij are assumed to be independent. Given, T , V and n, we can make Var(\u03b8j\nt+1) arbitrarily small by increasing MN ."}, {"heading": "5 Experimental Results", "text": "We evaluate the proposed MC-EM algorithm on synthetic data as well as two real world data sets, namely an election data set and a dataset representing preference orders on sushi. For simulated data\nwe use the Kendall correlation [11] between two rank orders (typically between the true order and the method\u2019s result) as a measure of performance."}, {"heading": "5.1 Experiments for Synthetic Data", "text": "We first generate data from Normal models for the random utility terms, with means \u03b8j = j and equal variance for all terms, for different choices of variance (Var = 2, 4). We evaluate the performance of the method as the number of agents n varies. The results show that a limited number of iterations in the EM algorithm (at most 3), and samples MN = 4000 (M=5, N=800) are sufficient for inferring the order in most cases. The performance in terms of Kendall correlation for recovering ground truth improves for larger number of agents, which corresponds to more data. See Figure 4, which shows the asymptotic behavior of the maximum likelihood estimator in recovering the true parameters. Figure 4 left and middle panels show that the more the size of dataset the better the performance of the method.\nMoreover, for large variances in data generation, due to increasing noise in the data, the rate that performance gets better is slower than that for the case for smaller variances. Notice that the scales on the y-axis are different in the left and middle panels."}, {"heading": "5.2 Experiments for Model Robustness", "text": "We apply our method to a public election dataset collected by Nicolaus Tideman [27], where the voters provided partial orders on candidates. A partial order includes comparisons among a subset of alternative, and the non-mentioned alternatives in the partial order are considered to be ranked lower than the lowest ranked alternative among mentioned alternatives.\nThe total number of votes are n = 280 and the number of alternatives m = 15. For the purpose of our experiments, we adopt the order on alternatives obtained by applying our method on the entire dataset as an assumed ground truth, since no ground truth is given as part of the data. After finding the ground truth by using all 280 votes (and adopting a normal model), we compare the performance of our approach as we vary the amount of data available. We evaluate the performance for subsamples consisting of 10, 20, . . . , 280 of samples randomly chosen from the full dataset. For each sub-sample size, the experiment is repeated 200 times and we report the average performance and the variance. See the right panel in Figure 4. This experiment shows the robustness of the method, in the sense that the result of inference on a subset of the dataset shows consistent behavior with the case that the result on the full dataset. For example, the ranking obtained by using half of the data can still achieve a fair estimate to the results with full data, with an average Kendall correlation of greater than 0.4."}, {"heading": "5.3 Experiments for Model Fitness", "text": "In addition to a public election dataset, we have tested our algorithm on a sushi dataset, where 5000 users give rankings over 10 different kinds of sushi [15]. For each experiment we randomly choose\nn \u2208 {10, 20, 30, 40, 50} rankings, apply our MC-EM for RUMs with normal distributions where variances are also parameters.\nIn the former experiments, both the synthetic data generation and the model for election data, the variances were fixed to 1 and hence we had the theoretical guarantees for the convergence to global optimal solutions by Theorem 1 and Theorem 2. When we let the variances to be part of parametrization we lose the theoretical guarantees. However, the EM algorithm can still be applied, and since the variances are now parameters (rather than being fixed to 1), the model fits better in terms of log-likelihood.\nFor this reason, we adopt RUMs with normal distributions in which the variance is a parameter that is fit by EM along with the mean. We call this model a normal model. We compute the difference between the normal model and P-L in terms of four criteria: log-likelihood (LL), predictive loglikelihood (predictive LL), AIC, and BIC. For (predictive) log-likelihood, a positive value means that normal model fits better than P-L, whereas for AIC and BIC, a negative number means that normal model fits better than P-L. Predictive likelihood is different from likelihood in the sense that we compute the likelihood of the estimated parameters for a part of the data that is not used for parameter estimation.3 In particular, we compute predictive likelihood for a randomly chosen subset of 100 votes. The results and standard deviations for n = 10, 50 are summarized in Table 1.\nWhen n is small (n = 10), the variance is high and we are unable to obtain statistically significant results in comparing fitness. When n is not too small (n = 50), RUMs with normal distributions fit better than P-L. Specifically, for log-likelihood, predictive log-likelihood, and AIC, RUMs with normal distributions outperform P-L with 95% confidence in both datasets."}, {"heading": "5.4 Implementation and Run Time", "text": "The running time for our MC-EM algorithm scales linearly with number of agents on real world data (Election Data) with slope 13.3 second per agent on an Intel i5 2.70GHz PC. This is for 100 iterations of EM algorithm with Gibbs sampling number increasing with iterations as 2000 + 300 \u2217 iteration steps."}, {"heading": "Acknowledgments", "text": "This work is supported in part by NSF Grant No. CCF- 0915016. Lirong Xia is supported by NSF under Grant #1136996 to the Computing Research Association for the CIFellows Project. We thank Craig Boutilier, Jonathan Huang, Tyler Lu, Nicolaus Tideman, Paolo Viappiani, and anonymous NIPS-12 reviewers for helpful comments and suggestions, or help on the datasets."}], "references": [{"title": "Automobile prices in market", "author": ["Steven Berry", "James Levinsohn", "Ariel Pakes"], "venue": "equilibrium. Econometrica,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1995}, {"title": "Random orderings and stochastic theories of responses", "author": ["Henry David Block", "Jacob Marschak"], "venue": "In Contributions to Probability and Statistics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1960}, {"title": "Maximizing Generalized Linear Mixed Model Likelihoods with an Automated Monte Carlo EM Algorithm", "author": ["James G. Booth", "James P. Hobert"], "venue": "JRSS. Series B,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Handbook of Markov Chain Monte Carlo", "author": ["Steve Brooks", "Andrew Gelman", "Galin Jones", "Xiao-Li Meng", "editors"], "venue": "Chapman and Hall/CRC,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Efficient Bayesian Inference for Generalized Bradley-Terry Models", "author": ["Francois Caron", "Arnaud Doucet"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Preference functions that score rankings and maximum likelihood estimation", "author": ["Vincent Conitzer", "Matthew Rognlie", "Lirong Xia"], "venue": "In Proc. IJCAI,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Common voting rules as maximum likelihood estimators", "author": ["Vincent Conitzer", "Tuomas Sandholm"], "venue": "In Proc. UAI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "Solution of a ranking problem from binary comparisons", "author": ["Lester R. Ford", "Jr."], "venue": "The American Mathematical Monthly,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1957}, {"title": "A grade of membership model for rank data", "author": ["Isobel Claire Gormley", "Thomas Brendan Murphy"], "venue": "Bayesian Analysis,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Kendall\u2019s correlation coefficient for vague preferences", "author": ["Przemyslaw Grzegorzewski"], "venue": "Soft Computing,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Bayesian inference for Plackett-Luce ranking models", "author": ["John Guiver", "Edward Snelson"], "venue": "In Proc. ICML,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "The complexity of Kemeny elections", "author": ["Edith Hemaspaandra", "Holger Spakowski", "J\u00f6rg Vogel"], "venue": "Theoretical Computer Science,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "MM algorithms for generalized Bradley-Terry models", "author": ["David R. Hunter"], "venue": "In The Annals of Statistics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "Nantonac collaborative filtering: Recommendation based on order responses", "author": ["Toshihiro Kamishima"], "venue": "In Proc. KDD,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "Learning to Rank for Information", "author": ["Tie-Yan Liu"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Learning mallows models with pairwise preferences", "author": ["Tyler Lu", "Craig Boutilier"], "venue": "In Proc. ICML,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Individual Choice Behavior: A Theoretical Analysis", "author": ["R. Duncan Luce"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1959}, {"title": "Conditional logit analysis of qualitative choice behavior", "author": ["Daniel McFadden"], "venue": "In Frontiers of Econometrics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1974}, {"title": "Natural Exponential Families with Quadratic Variance Functions", "author": ["Carl N. Morris"], "venue": "Annals of Statistics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1982}, {"title": "The analysis of permutations", "author": ["R.L. Plackett"], "venue": "JRSS. Series C,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1975}, {"title": "Logarithmic concave measures and related topics. In Stochastic Programming, pages 63\u201382", "author": ["Andr\u015b Pr\u00e9kopa"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1980}, {"title": "A maximum likelihood approach for selecting sets of alternatives", "author": ["Ariel D. Procaccia", "Sashank J. Reddi", "Nisarg Shah"], "venue": "In Proc. UAI,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Chapter 29. log-concavity property of probability measures. FSU techinical report", "author": ["Frank Proschan", "Yung L. Tong"], "venue": "Number M-805,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1989}, {"title": "How to calibrate the scores of biased reviewers by quadratic programming", "author": ["Magnus Roos", "J\u00f6rg Rothe", "Bj\u00f6rn Scheuermann"], "venue": "In Proc. AAAI,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Thurstone. A law of comparative judgement", "author": ["Louis Leon"], "venue": "Psychological Review,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1927}, {"title": "Collective Decisions and Voting: The Potential for Public Choice", "author": ["Nicolaus Tideman"], "venue": "Ashgate Publishing,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "A Monte Carlo Implementation of the EM Algorithm and the Poor Man\u2019s Data", "author": ["Greg C.G. Wei", "Martin A. Tanner"], "venue": "Augmentation Algorithms. JASA,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1990}, {"title": "A maximum likelihood approach towards aggregating partial orders", "author": ["Lirong Xia", "Vincent Conitzer"], "venue": "In Proc. IJCAI,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2011}, {"title": "Aggregating preferences in multi-issue domains by using maximum likelihood estimators", "author": ["Lirong Xia", "Vincent Conitzer", "J\u00e9r\u00f4me Lang"], "venue": "In Proc. AAMAS,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}, {"title": "The relationship between Luce\u2019s Choice Axiom, Thurstone\u2019s Theory of Comparative Judgment, and the double exponential distribution", "author": ["John I. Jr. Yellott"], "venue": "J. of Mathematical Psychology,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1977}, {"title": "Optimal voting rules", "author": ["H. Peyton Young"], "venue": "Journal of Economic Perspectives,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1995}], "referenceMentions": [{"referenceID": 14, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 51, "endOffset": 55}, {"referenceID": 5, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 6, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 21, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 23, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 27, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 28, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 30, "context": "Later, Kemeny\u2019s rule was shown to provide the maximum likelihood estimator (MLE) for this model [32].", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "In addition, computing the winner through the Kemeny rule is \u03982 -complete [13].", "startOffset": 74, "endOffset": 78}, {"referenceID": 24, "context": "To overcome the first criticism, a more recent literature adopts the random utility model (RUM) from economics [26].", "startOffset": 111, "endOffset": 115}, {"referenceID": 16, "context": "A popular RUM is Plackett-Luce (P-L) [18, 21], where the random utility terms are generated according to Gumbel distributions with fixed shape parameter [2,31].", "startOffset": 37, "endOffset": 45}, {"referenceID": 19, "context": "A popular RUM is Plackett-Luce (P-L) [18, 21], where the random utility terms are generated according to Gumbel distributions with fixed shape parameter [2,31].", "startOffset": 37, "endOffset": 45}, {"referenceID": 1, "context": "A popular RUM is Plackett-Luce (P-L) [18, 21], where the random utility terms are generated according to Gumbel distributions with fixed shape parameter [2,31].", "startOffset": 153, "endOffset": 159}, {"referenceID": 29, "context": "A popular RUM is Plackett-Luce (P-L) [18, 21], where the random utility terms are generated according to Gumbel distributions with fixed shape parameter [2,31].", "startOffset": 153, "endOffset": 159}, {"referenceID": 0, "context": "P-L has been extensively applied in econometrics [1, 19], and more recently in machine learning and information retrieval (see [16] for an overview).", "startOffset": 49, "endOffset": 56}, {"referenceID": 17, "context": "P-L has been extensively applied in econometrics [1, 19], and more recently in machine learning and information retrieval (see [16] for an overview).", "startOffset": 49, "endOffset": 56}, {"referenceID": 14, "context": "P-L has been extensively applied in econometrics [1, 19], and more recently in machine learning and information retrieval (see [16] for an overview).", "startOffset": 127, "endOffset": 131}, {"referenceID": 4, "context": "Efficient methods of EM inference [5, 14], and more recently expectation propagation [12], have been developed for P-L and its variants.", "startOffset": 34, "endOffset": 41}, {"referenceID": 12, "context": "Efficient methods of EM inference [5, 14], and more recently expectation propagation [12], have been developed for P-L and its variants.", "startOffset": 34, "endOffset": 41}, {"referenceID": 10, "context": "Efficient methods of EM inference [5, 14], and more recently expectation propagation [12], have been developed for P-L and its variants.", "startOffset": 85, "endOffset": 89}, {"referenceID": 8, "context": "In application to social choice, the P-L model has been used to analyze political elections [10].", "startOffset": 92, "endOffset": 96}, {"referenceID": 15, "context": "EM algorithm has also been used to learn the Mallows model, which is closely related to the Condorcet\u2019s probabilistic model [17].", "startOffset": 124, "endOffset": 128}, {"referenceID": 24, "context": "Specifically, we are not aware of either an analytical solution or an efficient algorithm for MLE inference for one of the most natural models proposed by Thurstone [26], where each Xj is normally distributed.", "startOffset": 165, "endOffset": 169}, {"referenceID": 18, "context": "1 Our Contributions In this paper we focus on RUMs in which the random utilities are independently generated with respect to distributions in the exponential family (EF) [20].", "startOffset": 170, "endOffset": 174}, {"referenceID": 1, "context": "Example 1 (Plackett-Luce as an RUM [2]) In the RUM, let \u03bcj\u2019s be Gumbel distributions.", "startOffset": 35, "endOffset": 38}, {"referenceID": 20, "context": "Proof sketch: The theorem is proved by applying the following lemma, which is Theorem 9 in [22].", "startOffset": 91, "endOffset": 95}, {"referenceID": 7, "context": "The concavity of log-likelihood of P-L has been proved [9] using a different technique.", "startOffset": 55, "endOffset": 58}, {"referenceID": 22, "context": "in [24], the set of global maxima solutions to the likelihood function, denoted by SD, is convex since the likelihood function is log-concave.", "startOffset": 3, "endOffset": 7}, {"referenceID": 7, "context": "[9] proposed the following necessary and sufficient condition for the set of global maxima solutions to be bounded (more precisely, unique) when \u2211m j=1 e \u03b8j = 1.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Rao-Blackwellized: To further improve the Gibbs sampler, we use Rao-Blackwellized [4] estimation using E{T (x j ) | x i,k \u2212j , \u03c0 , ~ \u03b8} instead of the sample x j , where x i,k \u2212j is all of ~x except for x j .", "startOffset": 82, "endOffset": 85}, {"referenceID": 26, "context": "In order to control the error of approximation in the MC-E step we can increase the number of samples with the iterations [28].", "startOffset": 122, "endOffset": 126}, {"referenceID": 2, "context": "With an approach similar to [3], we can derive a relationship between the variance of error in ~ \u03b8 and the Monte-Carlo error in the E-step approximation:", "startOffset": 28, "endOffset": 31}, {"referenceID": 9, "context": "we use the Kendall correlation [11] between two rank orders (typically between the true order and the method\u2019s result) as a measure of performance.", "startOffset": 31, "endOffset": 35}, {"referenceID": 25, "context": "We apply our method to a public election dataset collected by Nicolaus Tideman [27], where the voters provided partial orders on candidates.", "startOffset": 79, "endOffset": 83}, {"referenceID": 13, "context": "In addition to a public election dataset, we have tested our algorithm on a sushi dataset, where 5000 users give rankings over 10 different kinds of sushi [15].", "startOffset": 155, "endOffset": 159}], "year": 2012, "abstractText": "Random utility theory models an agent\u2019s preferences on alternatives by drawing a real-valued score on each alternative (typically independently) from a parameterized distribution, and then ranking the alternatives according to scores. A special case that has received significant attention is the Plackett-Luce model, for which fast inference methods for maximum likelihood estimators are available. This paper develops conditions on general random utility models that enable fast inference within a Bayesian framework through MC-EM, providing concave loglikelihood functions and bounded sets of global maxima solutions. Results on both real-world and simulated data provide support for the scalability of the approach and capability for model selection among general random utility models including Plackett-Luce.", "creator": "LaTeX with hyperref package"}}}