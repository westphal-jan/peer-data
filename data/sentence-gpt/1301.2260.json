{"id": "1301.2260", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Confidence Inference in Bayesian Networks", "abstract": "We present two sampling algorithms for probabilistic confidence inference in Bayesian networks. These two algorithms (we call them AIS-BN-mu and AIS-BN-sigma algorithms) guarantee that estimates of posterior probabilities are with a given probability within a desired precision bound. Our algorithms are based on recent advances in sampling algorithms for (1) estimating the mean of bounded random variables and (2) adaptive importance sampling in Bayesian networks. Our algorithm is based on previous models that provided the estimate of (1) accuracy in Bayesian networks in Bayesian networks. Our algorithm performs the same general optimization (from 2) with Bayesian networks (5) and (6) using this algorithm for estimating the total likelihood of a given value in Bayesian networks.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Thu, 10 Jan 2013 16:22:53 GMT  (1128kb)", "http://arxiv.org/abs/1301.2260v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jian cheng", "marek j druzdzel"], "accepted": false, "id": "1301.2260"}, "pdf": {"name": "1301.2260.pdf", "metadata": {"source": "CRF", "title": "Confidence Inference in Bayesian Networks", "authors": ["Jian Cheng", "Marek J. Druzdzel"], "emails": ["mjdruzdzel@rea.sonedge.com."], "sections": null, "references": [{"title": "20(5):661-685", "author": ["Martin R. Chavez", "Gregory F. Cooper. A randomized approximation algorithm for probabilistic inference on Bayesian belief networks. Networks"], "venue": "August", "citeRegEx": "Chavez and Cooper. 1990", "shortCiteRegEx": null, "year": 1990}, {"title": "AIS-BN: An adaptive importance sam\u00ad pling algorithm for evidential reasoning in large Ba\u00ad yesian networks", "author": ["Cheng", "Druzdzel", "2000) Jian Cheng", "Marek J. Druzdzel"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Cheng et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Cheng et al\\.", "year": 2000}, {"title": "Computational Statistics", "author": ["Jian Cheng. Sampling algorithms for estimating the mean of bounded random variables"], "venue": "16(1):1-23,", "citeRegEx": "Cheng. 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "A Bayesian analysis of simulation algo\u00ad rithms for inference in belief networks", "author": ["Paul Dagum", "Eric Horvitz"], "venue": "Networks, 23:499\ufffd516,", "citeRegEx": "Dagum and Horvitz. 1993", "shortCiteRegEx": null, "year": 1993}, {"title": "An optimal approximation algorithm for Ba\u00ad yesian inference", "author": ["Paul Dagum", "Michael Luby"], "venue": "Artificial Intelligence, 93:1\ufffd27,", "citeRegEx": "Dagum and Luby. 1997", "shortCiteRegEx": null, "year": 1997}, {"title": "An optimal al\u00ad gorithm for Monte Carlo estimation", "author": ["Paul Dagum", "Richard Karp", "Michael Luby", "Sheldon Ross"], "venue": "SIAM Journal on computing, 29(5):1481\ufffd1496,", "citeRegEx": "Dagum et al.. 2000", "shortCiteRegEx": null, "year": 2000}, {"title": "Monte Carlo: concepts", "author": ["George S. Fishman"], "venue": "algorithms, and applications. Springer\u00ad Verlag,", "citeRegEx": "Fishman. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "In Un\u00ad certainty in Artificial Intelligence 5", "author": ["Robert Fung", "Kuo-Chu Chang. Weighing", "integrating evidence for stochastic simulation in Bayesian networks"], "venue": "pages 209\ufffd219, New York, N. Y.,", "citeRegEx": "Fung and Chang. 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Infer\u00ad ence", "author": ["Judea Pearl"], "venue": "Morgan Kaufmann Publishers, Inc., San Ma\u00ad teo, CA,", "citeRegEx": "Pearl. 1988", "shortCiteRegEx": null, "year": 1988}, {"title": "In Proceedings of the Twelfth Annual Conference on Uncertainty in Artificial Intelligence (UAI-96)", "author": ["Malcolm Pradhan", "Paul Dagum. Optimal Monte Carlo inference"], "venue": "pages 446\ufffd453, San Francisco, CA,", "citeRegEx": "Pradhan and Dagum. 1996", "shortCiteRegEx": null, "year": 1996}, {"title": "Knowledge engineering for large belief networks", "author": ["Pradhan et al", "1994] Malcolm Pradhan", "Gregory Provan", "Blackford Middleton", "Max Henrion"], "venue": "In Proceedings of the Tenth Annual Conference on Un\u00ad certainty in Artificial Intelligence (UAI-94),", "citeRegEx": "al. et al\\.,? \\Q1994\\E", "shortCiteRegEx": "al. et al\\.", "year": 1994}, {"title": "In Un\u00ad certainty in Artificial Intelligence 5", "author": ["Ross D. Shachter", "Mark A. Peat. Simulation approaches to general probabilistic inference on belief networks"], "venue": "pages 221\ufffd231, New York, N. Y.,", "citeRegEx": "Shachter and Peat. 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Artificial Intelli\u00ad gence", "author": ["Solomon E. Shimony. Finding MAPs for belief networks is NP-hard"], "venue": "68(2):399-410, August", "citeRegEx": "Shimony. 1994", "shortCiteRegEx": null, "year": 1994}], "referenceMentions": [{"referenceID": 4, "context": "The best existing algorithms that address this problem are the bounded variance algorithm [Dagum and Luby, 1997] and the AA algorithm [Dagum et al.", "startOffset": 90, "endOffset": 112}, {"referenceID": 5, "context": "The best existing algorithms that address this problem are the bounded variance algorithm [Dagum and Luby, 1997] and the AA algorithm [Dagum et al., 2000].", "startOffset": 134, "endOffset": 154}, {"referenceID": 2, "context": "cent advances in simulation algorithms, notably the AIS-BN algorithm [Cheng and Druzdzel, 2000] and stopping rules [Cheng, 2001], address both of these problems.", "startOffset": 115, "endOffset": 128}, {"referenceID": 2, "context": "After each learning step, we use the SA-Jl or SA-li algo\u00ad rithm [Cheng, 2001] to produce the estimated number", "startOffset": 64, "endOffset": 77}, {"referenceID": 2, "context": "As far as we know, currently the tightest estimates are those reported in [Cheng, 2001], based on the follow\u00ad ing two theorems.", "startOffset": 74, "endOffset": 87}, {"referenceID": 2, "context": "But based on the stopping rules, the SA-J-1 and SA-a algorithms [Cheng, 2001] circumvent this problem.", "startOffset": 64, "endOffset": 77}, {"referenceID": 2, "context": "1 [Cheng, 2001].", "startOffset": 2, "endOffset": 15}, {"referenceID": 8, "context": "As a matter of fact, calculation of the tightest bound tb is isomorphic to the Maximum A-Posteriori assigment problem (MAP) [Pearl, 1988].", "startOffset": 124, "endOffset": 137}, {"referenceID": 6, "context": "for example by a\ufffd= lj(N- 1) \u00b7 O:=f=,1 ZJ \ufffd N \u00b7 z\\ or by the technique addressed in [Fishman, 1995] to avoid possible numerical errors caused by the limited precision.", "startOffset": 83, "endOffset": 98}, {"referenceID": 2, "context": "Its definition and the table listing the rela\u00ad tionship between 65, 6, and er can be found in [Cheng, 2001].", "startOffset": 94, "endOffset": 107}, {"referenceID": 4, "context": "This stopping rule and the likelihood weighting algo\u00ad rithm form the foundations of both the bounded vari\u00ad ance [Dagum and Luby, 1997] and the AA algorithms [Dagum et al.", "startOffset": 112, "endOffset": 134}, {"referenceID": 5, "context": "This stopping rule and the likelihood weighting algo\u00ad rithm form the foundations of both the bounded vari\u00ad ance [Dagum and Luby, 1997] and the AA algorithms [Dagum et al., 2000].", "startOffset": 157, "endOffset": 177}], "year": 2011, "abstractText": "We present two sampling algorithms for prob\u00ad abilistic confidence inference in Bayesian net\u00ad works. These two algorithms (we call them AIS-BN-p and AIS-BN-li algorithms) guar\u00ad antee that estimates of posterior probabilities are with a given probability within a desired precision bound. Our algorithms are based on recent advances in sampling algorithms for (1) estimating the mean of bounded random variables and (2) adaptive importance sam\u00ad pling in Bayesian networks. In addition to a simple stopping rule for sampling that they provide, the AIS-BN-p and AIS-BN-0' al\u00ad gorithms are capable of guiding the learning process in the AIS-BN algorithm. An em\u00ad pirical evaluation of the proposed algorithms shows excellent performance, even for very unlikely evidence.", "creator": "pdftk 1.41 - www.pdftk.com"}}}