{"id": "1301.2319", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Planning and Acting under Uncertainty: A New Model for Spoken Dialogue Systems", "abstract": "Uncertainty plays a central role in spoken dialogue systems. Some stochastic models like Markov decision process (MDP) are used to model the dialogue manager. But the partially observable system state and user intention hinder the natural representation of the dialogue state.\n\n\n\nThe goal of this article is to create a framework for the production of an effective system that addresses the problem of self-regulation: one that addresses the problem of self-regulation: one that addresses the problem of self-regulation.\nThis article is designed to help the people of the United States and Europe find ways to better implement and enforce norms in their respective countries. In addition, we will provide some examples of examples of how the actions and actions of the actors in the system can be used to produce successful norms on the grounds that their actions were justified.\nAs a follow up article on this topic, we will look at a few examples of the actions and actions of the actors, by how the actors behaved in various situations.\nExample 1\nExample 2\nExample 3\nExample 4\nExample 5\nExample 6\nExample 7\nNote: This is the first example that shows how the actors behaved in different situations. The two examples are in the same class:\nExample 8\nExample 9\nExample 10\nThe third example shows how the actors behaved in different circumstances. The third example shows how the actors behaved in different situations. The fourth example shows how the actors behaved in different situations. The fourth example shows how the actors behaved in different situations.\nFor example, there is another example of the actor acting in different situations. The fourth example shows how the actors behaved in different situations. The fifth example shows how the actors behaved in different situations.\nAs the other examples, there is one example of the actor acting in different situations. The fifth example shows how the actors behaved in different situations. The fifth example shows how the actors behaved in different situations.\nThe third example shows how the actors behaved in different situations. The fourth example shows how the actors behaved in different situations. The fourth example shows how the actors behaved in different situations. The fourth example shows how the actors behaved in different situations. The fourth example shows how the actors behaved in different situations. The fourth example shows how the actors behaved in different situations. The fourth example shows how the actors behaved in different situations.\nWhat does this mean for all of us?\nLet me say that we all have to consider ourselves more and more, if we are to be successful in achieving our goals and", "histories": [["v1", "Thu, 10 Jan 2013 16:27:11 GMT  (1088kb)", "http://arxiv.org/abs/1301.2319v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["bo zhang", "qingsheng cai", "jianfeng mao", "baining guo"], "accepted": false, "id": "1301.2319"}, "pdf": {"name": "1301.2319.pdf", "metadata": {"source": "CRF", "title": "Planning and Acting under Uncertainty: A New Model for Spoken Dialogue Systems", "authors": ["Bo Zhang", "Qingsheng Cai", "Jianfeng Mao", "Baining Guo"], "emails": [], "sections": null, "references": [{"title": "Dynamic programming", "author": ["E. R"], "venue": "Journal of Artificial Intelligence", "citeRegEx": "R.,? \\Q1957\\E", "shortCiteRegEx": "R.", "year": 1957}, {"title": "Computing optimal policies for partially observable decision processes using compact representations", "author": ["C. Boutilier", "D. Poole"], "venue": "In Proceedings of the 13th National Conference on Artificial Intelligence (AAAI-96),", "citeRegEx": "Boutilier and Poole,? \\Q1996\\E", "shortCiteRegEx": "Boutilier and Poole", "year": 1996}, {"title": "Exact and approximate", "author": ["A.R. Cassandra"], "venue": null, "citeRegEx": "Cassandra,? \\Q1998\\E", "shortCiteRegEx": "Cassandra", "year": 1998}, {"title": "Value-function approximations for", "author": ["M. Hauskrecht"], "venue": null, "citeRegEx": "Hauskrecht,? \\Q2000\\E", "shortCiteRegEx": "Hauskrecht", "year": 2000}, {"title": "Conversation as action", "author": ["T. Paek", "E. Horvitz"], "venue": null, "citeRegEx": "Paek and Horvitz,? \\Q2000\\E", "shortCiteRegEx": "Paek and Horvitz", "year": 2000}, {"title": "The optimal control of partially", "author": ["J. E"], "venue": "Sondik", "citeRegEx": "E.,? \\Q1971\\E", "shortCiteRegEx": "E.", "year": 1971}], "referenceMentions": [{"referenceID": 2, "context": "Q I\u00b7 In each step of the iteration, all the dominated vectors (Cassandra, 1998) are removed.", "startOffset": 62, "endOffset": 79}, {"referenceID": 2, "context": "There exist many exact algorithms to solve the optimal solution for POMDP (Cassandra, 1998).", "startOffset": 74, "endOffset": 91}, {"referenceID": 3, "context": "We are interested in four algorithms (Hauskrecht, 2000):", "startOffset": 37, "endOffset": 55}, {"referenceID": 3, "context": "An incremental approach (Hauskrecht, 2000) was proposed since the grid-based method is not guaranteed to converge.", "startOffset": 24, "endOffset": 42}, {"referenceID": 3, "context": "1 In (Hauskrecht, 2000), only one value function is used for each belief state.", "startOffset": 5, "endOffset": 23}, {"referenceID": 3, "context": "We use direct and look-ahead methods (Hauskrecht, 2000) to get the policy from the value function.", "startOffset": 37, "endOffset": 55}], "year": 2011, "abstractText": "Uncertainty plays a central role in spoken dialogue systems. Some stochastic models like the Markov decision process (MDP) are used to model the dialogue manager. But the partially observable system state and user intentions hinder the natural representation of the dialogue state. A MDP-based system degrades quickly when uncertainty about a user's intention increases. We propose a novel dialogue model based on the partially observable Markov decision process (POMDP). We use hidden system states and user intentions as the state set, parser results and low-level information as the observation set, and domain actions and dialogue repair actions as the action set. Here, low-level information is extracted from different input modalities, including speech, keyboard, mouse, etc., using Bayesian networks. Because of the limitation of the exact algorithms, we focus on heuristic approximation algorithms and their applicability in POMDP for dialogue management. We also propose two methods for grid point selection in grid-based algorithms.", "creator": "pdftk 1.41 - www.pdftk.com"}}}