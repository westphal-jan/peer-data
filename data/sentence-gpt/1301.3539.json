{"id": "1301.3539", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Learning Features with Structure-Adapting Multi-view Exponential Family Harmoniums", "abstract": "We proposea graphical model for multi-view feature extraction that automatically adapts its structure to achieve better representation of data distribution. The proposed model, structure-adapting multi-view harmonium (SA-MVH) has switch parameters that control the connection between hidden nodes and input views, and learn the switch parameter while training. Numerical experiments on synthetic and a real-world dataset demonstrate the useful behavior of the SA-MVH, compared to existing multi-view feature extraction methods.", "histories": [["v1", "Wed, 16 Jan 2013 01:07:38 GMT  (347kb)", "http://arxiv.org/abs/1301.3539v1", "3 pages, 2 figures, ICLR2013 workshop track submission"]], "COMMENTS": "3 pages, 2 figures, ICLR2013 workshop track submission", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yoonseop kang", "seungjin choi"], "accepted": false, "id": "1301.3539"}, "pdf": {"name": "1301.3539.pdf", "metadata": {"source": "CRF", "title": "Learning Features with Structure-Adapting Multi-view Exponential Family Harmoniums", "authors": ["Yoonseop Kang", "Seungjin Choi"], "emails": ["e0en@postech.ac.kr", "seungjin@postech.ac.kr"], "sections": [{"heading": null, "text": "ar X\niv :1\n30 1.\n35 39\nv1 [\ncs .L\nG ]"}, {"heading": "1 Introduction", "text": "Earlier multi-view feature extraction methods including canonical correlation analysis [1] and dualwing harmonium (DWH) [2] assume that all views can be described using a single set of shared hidden nodes. However, these methods fail when real-world data with partially correlated views are given. More recent methods like factorized orthogonal latent space [3] or multi-view harmonium (MVH) [4] assume that views are generated from two sets of hidden nodes: view-specific hidden nodes and shared ones. Still, these models rely on the pre-defined connection structure, and deciding the number of shared and view-specific hidden nodes requires a great human effort.\nIn this paper, we propose structure-adapting multi-view harmonium (SA-MVH) which avoids all of the problems mentioned above. Instead of explicitly defining view-specific and hidden nodes in prior to the training, we only use one set of hidden nodes and let each one of them to decide the existence of connection to views using switch parameters during the training. In this manner, SAMVH automatically decides the number of view-specific latent variables and also captures partial correlation among views."}, {"heading": "2 The Proposed Model", "text": "The definition of SA-MVH begins with choosing marginal distributions of visible node sets v(k) and a set of hidden nodes h from exponential family distributions:\np(v (k) i ) \u221d exp(\n\u2211\na\n\u03be (k) ia f (k) ia (v (k) i )\u2212A (k) i ({\u03be (k) ia })),\np(hj) \u221d exp( \u2211\nb\n\u03bbjbgjb(hj)\u2212Bj({\u03bbjb})), (1)\nf(\u00b7), g(\u00b7) are sufficient statistics, \u03be, \u03bb are natural parameters, and A, B are log-partition functions.\nConnections between visible nodes and hidden nodes of SA-MVH are defined by weight matrices {W (k)} and switch parameters \u03c3(skj) \u2208 [0, 1], where \u03c3(\u00b7) is a sigmoid function. A switch skj controls the connection between k-th view and j-th hidden node by being multiplied to the j-th column of weight matrix W (k) (Figure 1). When \u03c3(skj) is large (> 0.5), we consider the view and the hidden node to be connected. With the quadratic term including weights and switch parameters, the joint distribution of SA-MVH is defined as below:\np({v(k)},h) \u221d exp (\n\u2211\nk,i,j\n\u03c3(skj)W (k) ij f (k) i (v (k) i )gj(hj)\u2212\n\u2211\nk,i\n\u03be (k) i f (k) i (v (k) i )\u2212\n\u2211\nj\n\u03bbjgj(hj) ) . (2)\nnote that indices a and b are omitted to keep the notations uncluttered.\nWe learn the parameters W (k), \u03be(k), \u03bb, and switch parameters skj by maximizing the likelihood of model via gradient ascent. The likelihood of SA-MVH is defined as the joint distribution of nodes summed over hidden nodes h:\nL = \u3008log p({v(k)})\u3009data = \u2329 log \u2211\nh\np({v(k)},h) \u232a\ndata , (3)\nwhere \u3008\u00b7\u3009data represents expectation over data distribution. Then the gradient of log-likelihood with respect to the parameters W (k), \u03be(k), \u03bb, and skj are derived as follows:\n\u2202L\n\u2202W (k) ij\n\u221d \u2329 \u03c3(skj)fi(v (k) i )B \u2032 j(\u03bb\u0302j) \u232a data \u2212 \u2329 \u03c3(skj)fi(v (k) i )B \u2032 j(\u03bb\u0302j) \u232a model (4)\n\u2202L\n\u2202\u03be (k) i\n\u221d \u2329 f (k) i (v (k) i ) \u232a data \u2212 \u2329 f (k) i (v (k) i ) \u232a model (5)\n\u2202L \u2202\u03bbj \u221d \u2329 B\u2032j(\u03bb\u0302j) \u232a data \u2212 \u2329 B\u2032j(\u03bb\u0302j) \u232a model , (6)\n\u2202L\n\u2202skj \u221d\n\u2329\n\u03c3\u2032(skj)W (k) ij fi(v (k) i )B \u2032 j(\u03bb\u0302j) \u232a data \u2212 \u2329 \u03c3\u2032(skj)W (k) ij fi(v (k) i )B \u2032 j(\u03bb\u0302j) \u232a model (7)\nwhere \u3008\u00b7\u3009model represents expectation over model distribution p({v(k)},h) and \u03be\u0302 (k) i = \u03be (k) i + \u2211\nj \u03c3(skj)W (k) ij gj(hj), \u03bb\u0302j = \u03bbj + \u2211 k,i \u03c3(skj)W (k) ij fi(v (k) i ) are shifted parameters."}, {"heading": "3 Numerical Experiments", "text": ""}, {"heading": "3.1 Feature Extraction on Noisy Arabic-Roman Digit Dataset", "text": "To simulate the view-specific and shared properties of multi-view data, we designed a synthetic dataset which contains 11,800 pairs of Arabic digits and the corresponding Roman digits written in various fonts. For each pair, we added random vertical line noises to Arabic digits, and horizontal line noises to Roman digits (Figure 2-(a)). SA-MVH trained with 200 hidden nodes found 95 shared features (with connection to both views), and 47 view-specific features for Roman digits, and 32 for Arabic digits. Remaining 26 were not connected to any views and ignored. Most of the shared features were noise-free and encoded parts of Roman and Arabic numbers (Figure 2-(b)). On the other hand, the view-specific features had components with horizontal or vertical noises, as well as the parts of the numbers (Figure 2-(c)). In this example, SA-MVH automatically separated viewspecific and shared information without any prior specification of the graph structure."}, {"heading": "3.2 Image Classification on Caltech-256 Dataset", "text": "We extracted 512 dimensions of GIST features and 1,536 dimensions of histogram of gradients (HoG) features from Caltech-256 dataset to simulate multi-view settings. SA-MVH and other multiview feature extraction methods based on harmonium \u2013 DWH and MVH were trained on the dataset for comparison. We also compared our method to Sparse Filtering [5], which is not a harmoniumbased method. We trained the feature extraction methods and tested the methods with k-nearest neighbor classifiers (Table 1). SA-MVH resulted better than other feature extraction models in this experiment, regardless of the value of k for nearest neighbor classifier."}, {"heading": "4 Conclusion", "text": "In this paper, we have proposed the multi-view feature extraction model that automatically decides relations between latent variables and input views. The proposed method, SA-MVH models multiview data distribution with less restrictive assumption and also reduces the number of parameters to tune by human hand. SA-MVH introduces switch parameters that control the connections between hidden nodes and input views, and find the desirable configuration while training. We have demonstrated the effectiveness of our approach by comparing our model to existing models in experiments on synthetic dataset, and image classification with simulated multi-view setting."}], "references": [{"title": "Canonical correlation analysis: An overview with applications to learning methods", "author": ["D.R. Hardoon", "S. Szedmak", "J. Shawe-Taylor"], "venue": "Neural Computation, vol. 16, pp. 2639\u20132664, 2004.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Mining associated text and images with dual-wing harmonium", "author": ["E.P. Xing", "R. Yan", "A.G. Hauptmann"], "venue": "Proceedings of the Annual Conference on Uncertainty in Artificial Intelligence (UAI), Edinburgh, UK, 2005.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Factorized orthogonal latent spaces", "author": ["M. Salzmann", "C.H. Ek", "R. Urtasun", "T. Darrell"], "venue": "Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS), Sardinia, Italy, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Restricted deep belief networks for multi-view learning", "author": ["Y. Kang", "S. Choi"], "venue": "Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD), Athens, Greece, 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Sparse filtering", "author": ["J. Ngiam", "P.W. Koh", "Z. Chen", "S.A. Bhaskar", "A.Y. Ng"], "venue": "Advances in Neural Information Processing Systems (NIPS), vol. 23. MIT Press, 2011. 3", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "1 Introduction Earlier multi-view feature extraction methods including canonical correlation analysis [1] and dualwing harmonium (DWH) [2] assume that all views can be described using a single set of shared hidden nodes.", "startOffset": 102, "endOffset": 105}, {"referenceID": 1, "context": "1 Introduction Earlier multi-view feature extraction methods including canonical correlation analysis [1] and dualwing harmonium (DWH) [2] assume that all views can be described using a single set of shared hidden nodes.", "startOffset": 135, "endOffset": 138}, {"referenceID": 2, "context": "More recent methods like factorized orthogonal latent space [3] or multi-view harmonium (MVH) [4] assume that views are generated from two sets of hidden nodes: view-specific hidden nodes and shared ones.", "startOffset": 60, "endOffset": 63}, {"referenceID": 3, "context": "More recent methods like factorized orthogonal latent space [3] or multi-view harmonium (MVH) [4] assume that views are generated from two sets of hidden nodes: view-specific hidden nodes and shared ones.", "startOffset": 94, "endOffset": 97}, {"referenceID": 0, "context": "Connections between visible nodes and hidden nodes of SA-MVH are defined by weight matrices {W } and switch parameters \u03c3(skj) \u2208 [0, 1], where \u03c3(\u00b7) is a sigmoid function.", "startOffset": 128, "endOffset": 134}], "year": 2013, "abstractText": "We propose a graphical model for multi-view feature extraction that automatically adapts its structure to achieve better representation of data distribution. The proposed model, structure-adapting multi-view harmonium (SA-MVH) has switch parameters that control the connection between hidden nodes and input views, and learn the switch parameter while training. Numerical experiments on synthetic and a real-world dataset demonstrate the useful behavior of the SA-MVH, compared to existing multi-view feature extraction methods.", "creator": "LaTeX with hyperref package"}}}